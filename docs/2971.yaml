- en: Building Better ML Systems — Chapter 4\. Model Deployment and Beyond
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建更好的 ML 系统——第4章：模型部署及其发展
- en: 原文：[https://towardsdatascience.com/building-better-ml-systems-chapter-4-model-deployment-and-beyond-eae3a75496ec?source=collection_archive---------2-----------------------#2023-09-28](https://towardsdatascience.com/building-better-ml-systems-chapter-4-model-deployment-and-beyond-eae3a75496ec?source=collection_archive---------2-----------------------#2023-09-28)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/building-better-ml-systems-chapter-4-model-deployment-and-beyond-eae3a75496ec?source=collection_archive---------2-----------------------#2023-09-28](https://towardsdatascience.com/building-better-ml-systems-chapter-4-model-deployment-and-beyond-eae3a75496ec?source=collection_archive---------2-----------------------#2023-09-28)
- en: '*About deployment, monitoring, data distribution drifts, model updates, and
    tests in production.*'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*关于部署、监控、数据分布漂移、模型更新和生产环境中的测试。*'
- en: '[](https://olga-chernytska.medium.com/?source=post_page-----eae3a75496ec--------------------------------)[![Olga
    Chernytska](../Images/3a1a1b5f3c92d3b86283911cd90a9259.png)](https://olga-chernytska.medium.com/?source=post_page-----eae3a75496ec--------------------------------)[](https://towardsdatascience.com/?source=post_page-----eae3a75496ec--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----eae3a75496ec--------------------------------)
    [Olga Chernytska](https://olga-chernytska.medium.com/?source=post_page-----eae3a75496ec--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://olga-chernytska.medium.com/?source=post_page-----eae3a75496ec--------------------------------)[![Olga
    Chernytska](../Images/3a1a1b5f3c92d3b86283911cd90a9259.png)](https://olga-chernytska.medium.com/?source=post_page-----eae3a75496ec--------------------------------)[](https://towardsdatascience.com/?source=post_page-----eae3a75496ec--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----eae3a75496ec--------------------------------)
    [Olga Chernytska](https://olga-chernytska.medium.com/?source=post_page-----eae3a75496ec--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcc932e019245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-better-ml-systems-chapter-4-model-deployment-and-beyond-eae3a75496ec&user=Olga+Chernytska&userId=cc932e019245&source=post_page-cc932e019245----eae3a75496ec---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----eae3a75496ec--------------------------------)
    ·13 min read·Sep 28, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Feae3a75496ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-better-ml-systems-chapter-4-model-deployment-and-beyond-eae3a75496ec&user=Olga+Chernytska&userId=cc932e019245&source=-----eae3a75496ec---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcc932e019245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-better-ml-systems-chapter-4-model-deployment-and-beyond-eae3a75496ec&user=Olga+Chernytska&userId=cc932e019245&source=post_page-cc932e019245----eae3a75496ec---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----eae3a75496ec--------------------------------)
    ·13分钟阅读·2023年9月28日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Feae3a75496ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-better-ml-systems-chapter-4-model-deployment-and-beyond-eae3a75496ec&user=Olga+Chernytska&userId=cc932e019245&source=-----eae3a75496ec---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feae3a75496ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-better-ml-systems-chapter-4-model-deployment-and-beyond-eae3a75496ec&source=-----eae3a75496ec---------------------bookmark_footer-----------)![](../Images/2c0498ae65314b5963a18c5c21e81094.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feae3a75496ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-better-ml-systems-chapter-4-model-deployment-and-beyond-eae3a75496ec&source=-----eae3a75496ec---------------------bookmark_footer-----------)![](../Images/2c0498ae65314b5963a18c5c21e81094.png)'
- en: '[Image Source](https://unsplash.com/photos/iM8dxccK1sY)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[图片来源](https://unsplash.com/photos/iM8dxccK1sY)'
- en: '**Deploying models and supporting them in production is more about engineering
    and less about machine learning.**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**部署模型并在生产环境中支持它们更多是工程问题，而非机器学习问题。**'
- en: 'When an ML project approaches production, more and more people get involved:
    Backend Engineers, Frontend Engineers, Data Engineers, DevOps, Infrastructure
    Engineers...'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个 ML 项目接近生产阶段时，越来越多的人参与其中：后端工程师、前端工程师、数据工程师、DevOps、基础设施工程师……
- en: They choose data storages, introduce workflows and pipelines, integrate service
    into the backend and UI codebase, automate releases, make backups and rollbacks,
    decide on compute instances, set up monitoring and alerts… Today, literally no
    one expects a Data Scientist / ML Engineer to do it all. Even in a tiny startup,
    people are specialized to some extent.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 他们选择数据存储，介绍工作流和管道，将服务集成到后端和UI代码库中，自动化发布，进行备份和回滚，决定计算实例，设置监控和警报……如今，几乎没有人期望数据科学家/机器学习工程师能做到这一切。即使在一个小型初创公司中，人们也在某种程度上有所专门化。
- en: “Why should a Data Scientist / ML Engineer know about production?” — you may
    ask.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: “数据科学家/机器学习工程师为什么需要了解生产环境？”——你可能会问。
- en: 'Here is my answer:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我的回答：
- en: 'Having the model in production does not mean we are done with all ML-related
    tasks. Ha! Not even close. Now it’s time to tackle a whole new set of challenges:
    how to evaluate your model in production and monitor whether its accuracy is still
    satisfactory, how to detect data distribution shifts and deal with them, how often
    to retrain the model, and how to make sure that a newly trained model is better.
    There are ways, and we are going to extensively discuss them.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一个在生产环境中的模型并不意味着我们已经完成了所有与机器学习相关的任务。哈！远远没有。现在是时候面对一整套新的挑战了：如何在生产环境中评估你的模型并监控其准确性是否仍然令人满意，如何检测数据分布的变化并应对这些变化，多久重新训练一次模型，以及如何确保新训练的模型更好。这里有一些方法，我们将对此进行详细讨论。
- en: In this post, I intentionally focus on ML topics only and omit many engineering
    concepts or cover them at a high level — to keep it simple and understandable
    for people with varying levels of experience.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我有意只专注于机器学习话题，并省略了许多工程概念或以高层次的方式进行介绍——以便使不同经验水平的人都能简单易懂。
- en: This is the finale of the “Building Better ML Systems” series. The series aims
    to help you master the art, science, and (sometimes) magic of designing and building
    Machine Learning systems. In the previous chapters, we have already talked about
    project planning and business value ([Chapter 1](/building-better-ml-systems-chapter-1-every-project-must-start-with-a-plan-907a36774a32));
    data collection, labeling, and validation ([Chapter 2](/building-better-ml-systems-chapter-2-taming-data-chaos-841d5a04b39));
    model development, experiment tracking, and offline evaluation … ([Chapter 3](/building-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5)).
    If you’ve missed the previous posts, I’d recommend giving them a read either before
    or after you go through this one.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这是“构建更好的机器学习系统”系列的最终篇。本系列旨在帮助你掌握设计和构建机器学习系统的艺术、科学和（有时的）魔法。在之前的章节中，我们已经讨论了项目规划和商业价值（[第1章](/building-better-ml-systems-chapter-1-every-project-must-start-with-a-plan-907a36774a32)）；数据收集、标注和验证（[第2章](/building-better-ml-systems-chapter-2-taming-data-chaos-841d5a04b39)）；模型开发、实验跟踪和离线评估……（[第3章](/building-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5)）。如果你错过了之前的帖子，我建议你在阅读这篇之前或之后看看它们。
- en: Deployment
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署
- en: 'When deploying a model to production, there are two important questions to
    ask:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在将模型部署到生产环境时，有两个重要的问题需要问：
- en: Should the model return predictions in real time?
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型是否应该实时返回预测结果？
- en: Could the model be deployed to the cloud?
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型是否可以部署到云端？
- en: The first question forces us to choose between real-time vs. batch inference,
    and the second one — between cloud vs. edge computing.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个问题迫使我们在实时推断与批量推断之间做出选择，第二个问题则在云计算与边缘计算之间做出选择。
- en: Real-Time vs. Batch Inference
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实时与批量推断
- en: 'Real-time inference is a straightforward and intuitive way to work with a model:
    you give it an input, and it returns you a prediction. This approach is used when
    prediction is required immediately. For example, a bank might use real-time inference
    to verify whether a transaction is fraudulent before finalizing it.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 实时推断是一种直接且直观的与模型互动的方式：你提供一个输入，它返回一个预测。这种方法在需要立即获取预测时使用。例如，银行可能会使用实时推断来验证一笔交易是否存在欺诈行为，然后再最终确认它。
- en: 'Batch inference, on the other hand, is cheaper to run and easier to implement.
    Inputs that have been previously collected are processed all at once. Batch inference
    is used for evaluations (when running on static test datasets), ad-hoc campaigns
    (such as selecting customers for email marketing campaigns), or in situations
    where immediate predictions aren’t necessary. Batch inference can also be a cost
    or speed optimization of real-time inference: you precompute predictions in advance
    and return them when requested.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 批处理推断则更便宜且更容易实现。之前收集的输入会一次性处理。批处理推断用于评估（在静态测试数据集上运行时）、临时活动（如选择客户进行电子邮件营销活动）或在不需要立即预测的情况下。批处理推断也可以是实时推断的成本或速度优化：你提前计算预测并在请求时返回它们。
- en: '![](../Images/4f2977a15581931d62f6efc8f443ad4c.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f2977a15581931d62f6efc8f443ad4c.png)'
- en: '*Real-time vs. Batch Inference. Image by Author*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*实时推断与批处理推断。图片来源于作者*'
- en: Running real-time inference is much more challenging and costly than batch inference.
    This is because the model must be always up and return predictions with low latency.
    It requires a clever infrastructure and monitoring setup that may be unique even
    for different projects within the same company. Therefore, if getting a prediction
    immediately is not critical for the business — stick to the batch inference and
    be happy.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 实时推断比批处理推断要具有更大的挑战性和成本。这是因为模型必须始终在线并以低延迟返回预测。它需要一个聪明的基础设施和监控设置，这可能甚至在同一公司内部的不同项目中也会有所不同。因此，如果立即获得预测对业务并不关键——那么坚持使用批处理推断会更好。
- en: However, for many companies, real-time inference does make a difference in terms
    of accuracy and revenue. This is true for search engines, recommendation systems,
    and ad click predictions, so investing in real-time inference infrastructure is
    more than justified.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于许多公司来说，实时推断在准确性和收入方面确实有所不同。这对搜索引擎、推荐系统和广告点击预测都是如此，因此投资于实时推断基础设施是非常值得的。
- en: 'For more details on real-time vs. batch inference, check out these posts:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 关于实时推断与批处理推断的更多详细信息，请查看这些帖子：
- en: '- [Deploy machine learning models in production environments](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-practices/ml-deployment-inference)
    by Microsoft'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '- [在生产环境中部署机器学习模型](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-practices/ml-deployment-inference)
    作者: Microsoft'
- en: '- [Batch Inference vs Online Inference](https://mlinproduction.com/batch-inference-vs-online-inference/)
    by Luigi Patruno'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '- [批处理推断与在线推断](https://mlinproduction.com/batch-inference-vs-online-inference/)
    作者: Luigi Patruno'
- en: '**Cloud vs. Edge Computing**'
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**云计算与边缘计算**'
- en: In cloud computing, data is usually transferred over the internet and processed
    on a centralized server. On the other hand, in edge computing data is processed
    on the device where it was generated, with each device handling its own data in
    a decentralized way. Examples of edge devices are phones, laptops, and cars.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在云计算中，数据通常通过互联网传输并在集中式服务器上处理。另一方面，在边缘计算中，数据在生成数据的设备上处理，每个设备以去中心化的方式处理其自身的数据。边缘设备的例子包括手机、笔记本电脑和汽车。
- en: '![](../Images/d52a5b600cdb8433692bed73fc71eea2.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d52a5b600cdb8433692bed73fc71eea2.png)'
- en: '*Cloud vs. Edge Computing. Image by Author*'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*云计算与边缘计算。图片来源于作者*'
- en: Streaming services like Netflix and YouTube are typically running their recommender
    systems in the cloud. Their apps and websites send user data to data servers to
    get recommendations. Cloud computing is relatively easy to set up, and you can
    scale computing resources almost indefinitely (or at least until it’s economically
    sensible). However, cloud infrastructure heavily depends on a stable Internet
    connection, and sensitive user data should not be transferred over the Internet.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 像 Netflix 和 YouTube 这样的流媒体服务通常在云端运行其推荐系统。它们的应用程序和网站将用户数据发送到数据服务器以获得推荐。云计算相对容易设置，你可以几乎无限制地扩展计算资源（或至少在经济上合理的情况下）。然而，云基础设施高度依赖稳定的互联网连接，敏感的用户数据不应通过互联网传输。
- en: 'Edge computing is developed to overcome cloud limitations and is able to work
    where cloud computing cannot. The self-driving engine is running on the car, so
    it can still work fast without a stable internet connection. Smartphone authentication
    systems (like iPhone’s FaceID) run on smartphones because transferring sensitive
    user data over the internet is not a good idea, and users do need to unlock their
    phones without an internet connection. However, for edge computing to be viable,
    the edge device needs to be sufficiently powerful, or alternatively, the model
    must be lightweight and fast. This gave rise to the model compression methods,
    such as low-rank approximation, knowledge distillation, pruning, and quantization.
    If you want to learn more about model compression, here is a great place to start:
    [Awesome ML Model Compression](https://github.com/cedrickchee/awesome-ml-model-compression).'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘计算的发展是为了克服云计算的局限性，并且能够在云计算无法工作的地方进行工作。自动驾驶引擎运行在汽车上，因此即使没有稳定的互联网连接也能快速工作。智能手机认证系统（如
    iPhone 的 FaceID）运行在智能手机上，因为通过互联网传输敏感用户数据不是一个好主意，用户确实需要在没有互联网连接的情况下解锁手机。然而，为了使边缘计算可行，边缘设备需要足够强大，或者模型必须足够轻量和快速。这催生了模型压缩方法，如低秩近似、知识蒸馏、剪枝和量化。如果你想了解更多关于模型压缩的信息，这里是一个很好的起点：[超棒的机器学习模型压缩](https://github.com/cedrickchee/awesome-ml-model-compression)。
- en: 'For a deeper dive into Edge and Cloud Computing, read these posts:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 若要深入了解边缘计算和云计算，请阅读以下文章：
- en: '- [What’s the Difference Between Edge Computing and Cloud Computing?](https://blogs.nvidia.com/blog/2022/01/05/difference-between-cloud-and-edge-computing/)
    by NVIDIA'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '- [边缘计算与云计算有什么区别？](https://blogs.nvidia.com/blog/2022/01/05/difference-between-cloud-and-edge-computing/)
    作者：NVIDIA'
- en: '- [Edge Computing vs Cloud Computing: Major Differences](https://www.knowledgehut.com/blog/cloud-computing/edge-computing-vs-cloud-computing)
    by Mounika Narang'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '- [边缘计算与云计算：主要区别](https://www.knowledgehut.com/blog/cloud-computing/edge-computing-vs-cloud-computing)
    作者：Mounika Narang'
- en: '**Easy Deployment & Demo**'
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**轻松部署与演示**'
- en: '*“Production is a spectrum. For some teams, production means generating nice
    plots from notebook results to show to the business team. For other teams, production
    means keeping your models up and running for millions of users per day.”* Chip
    Huyen, [Why data scientists shouldn’t need to know Kubernetes](https://huyenchip.com/2021/09/13/data-science-infrastructure.html)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*“生产是一个连续体。对于一些团队来说，生产意味着从笔记本结果生成漂亮的图表来展示给业务团队。而对于其他团队来说，生产意味着确保你的模型每天能为数百万用户持续运行。”*
    Chip Huyen, [为什么数据科学家不必了解 Kubernetes](https://huyenchip.com/2021/09/13/data-science-infrastructure.html)'
- en: Deploying models to serve millions of users is the task for a large team, so
    as a Data Scientist / ML Engineer, you won’t be left alone.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型部署以服务数百万用户是一个大团队的任务，因此作为数据科学家/机器学习工程师，你不会被单独留下。
- en: However, sometimes you do need to deploy alone. Maybe you are working on a pet
    or study project and would like to create a demo. Maybe you are the first Data
    Scientist / ML Engineer in the company and you need to bring some business value
    before the company decides to scale the Data Science team. Maybe all your colleagues
    are so busy with their tasks, so you are asking yourself whether it’s easier to
    deploy yourself and not wait for support. You are not the first and definitely
    not the last who faces these challenges, and there are solutions to help you.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有时你确实需要单独进行部署。也许你正在进行一个个人或学习项目，并希望创建一个演示。也许你是公司里的第一位数据科学家/机器学习工程师，你需要在公司决定扩展数据科学团队之前带来一些业务价值。也许你的所有同事都忙于各自的任务，因此你在考虑是否自己进行部署而不等待支持。你不是第一个，也绝对不会是最后一个面对这些挑战的人，且有解决方案可以帮助你。
- en: To deploy a model, you need a server (instance) where the model will be running,
    an API to communicate with the model (send inputs, get predictions), and (optionally)
    a user interface to accept input from users and show them predictions.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署一个模型，你需要一个运行模型的服务器（实例），一个与模型通信的 API（发送输入，获取预测），以及（可选的）一个用户界面，用于接收用户输入并展示预测结果。
- en: '**Google Colab** is Jupyter Notebook on steroids. It is a great tool to create
    demos that you can share. It does not require any specific installation from users,
    it offers free servers with GPU to run the code, and you can easily customize
    it to accept any inputs from users (text files, images, videos). It is very popular
    among students and ML researchers ([here is how DeepMind researchers use it](https://github.com/google-deepmind/tapnet#tapir-demos)).
    If you are interested in learning more about Google Colab, start [here](https://colab.research.google.com/).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**Google Colab** 是 Jupyter Notebook 的升级版。它是一个很棒的工具，可以创建你可以分享的演示。它不需要用户进行任何特定的安装，提供免费的
    GPU 服务器来运行代码，并且你可以轻松定制它以接受用户的任何输入（文本文件、图像、视频）。它在学生和机器学习研究人员中非常受欢迎（[这是 DeepMind
    研究人员如何使用它的](https://github.com/google-deepmind/tapnet#tapir-demos)）。如果你对了解更多关于
    Google Colab 的信息感兴趣，请从 [这里](https://colab.research.google.com/) 开始。'
- en: '**FastAPI** is a framework for building APIs in Python. You may have heard
    about [Flask](https://flask.palletsprojects.com/en/2.3.x/), FastAPI is similar,
    but simpler to code, more specialized towards APIs, and faster. For more details,
    check out the [official documentation](https://fastapi.tiangolo.com/). For practical
    examples, read [APIs for Model Serving](https://madewithml.com/courses/mlops/api/)
    by Goku Mohandas.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**FastAPI** 是一个用于构建 Python API 的框架。你可能听说过 [Flask](https://flask.palletsprojects.com/en/2.3.x/)，FastAPI
    类似，但代码更简单，更专注于 API，速度更快。有关更多详细信息，请查看 [官方文档](https://fastapi.tiangolo.com/)。有关实际示例，请阅读
    [Goku Mohandas 的《模型服务的 API》](https://madewithml.com/courses/mlops/api/)。'
- en: '**Streamlit** is an easy tool to create web applications. It is easy, I really
    mean it. And applications turn out to be nice and interactive — with images, plots,
    input windows, buttons, sliders,… Streamlit offers [Community Cloud](https://streamlit.io/cloud)
    where you can publish apps for free. To get started, refer to [the official tutorial](https://docs.streamlit.io/library/get-started/create-an-app).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**Streamlit** 是一个易于创建 Web 应用程序的工具。它很简单，我真的这么认为。应用程序看起来很漂亮且互动性强——有图像、图表、输入窗口、按钮、滑块等。Streamlit
    提供 [Community Cloud](https://streamlit.io/cloud)，你可以免费发布应用程序。要开始使用，请参阅 [官方教程](https://docs.streamlit.io/library/get-started/create-an-app)。'
- en: '**Cloud Platforms**. Google and Amazon do a great job making the deployment
    process painless and accessible. They offer paid end-to-end solutions to train
    and deploy models (storage, compute instance, API, monitoring tool, workflows,…).
    Solutions are easy to start with and also have a wide functionality to support
    specific needs, so many companies build their production infrastructure with cloud
    providers.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**云平台**。Google 和 Amazon 在使部署过程无缝且易于访问方面做得很好。它们提供付费的端到端解决方案，用于训练和部署模型（存储、计算实例、API、监控工具、工作流等）。这些解决方案易于上手，并且功能广泛以支持特定需求，因此许多公司选择使用云服务提供商构建其生产基础设施。'
- en: 'If you would like to learn more, here are the resources to review:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多内容，请查看以下资源：
- en: '- [Deploy your side-projects at scale for basically nothing](https://alexolivier.me/posts/deploy-container-stateless-cheap-google-cloud-run-serverless/)
    by Alex Olivier'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '- [以基本上免费的方式大规模部署你的副项目](https://alexolivier.me/posts/deploy-container-stateless-cheap-google-cloud-run-serverless/)
    由 Alex Olivier 提供'
- en: '- [Deploy models for inference](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html)
    by Amazon'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '- [由 Amazon 部署模型以进行推理](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html)'
- en: '- [Deploy a model to an endpoint](https://cloud.google.com/vertex-ai/docs/general/deployment)
    by Google'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '- [将模型部署到端点](https://cloud.google.com/vertex-ai/docs/general/deployment) 由
    Google 提供'
- en: Monitoring
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控
- en: Like all software systems in production, ML systems must be monitored. It helps
    quickly detect and localize bugs and prevent catastrophic system failures.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 像所有生产中的软件系统一样，机器学习系统必须进行监控。这有助于快速检测和定位错误，防止系统发生灾难性故障。
- en: Technically, monitoring means collecting logs, calculating metrics from them,
    displaying these metrics on dashboards like [Grafana](https://grafana.com/), and
    setting up alerts for when metrics fall outside expected ranges.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术上讲，监控意味着收集日志，从中计算指标，将这些指标显示在类似于 [Grafana](https://grafana.com/) 的仪表板上，并设置警报以在指标超出预期范围时提醒。
- en: '**What metrics should be monitored?** Since an ML system is a subclass of a
    software system, start with operational metrics. Examples are CPU/GPU utilization
    of the machine, its memory, and disk space; number of requests sent to the application
    and response latency, error rate; network connectivity. For a deeper dive into
    monitoring of the operation metrics, check out the post [An Introduction to Metrics,
    Monitoring, and Alerting](https://www.digitalocean.com/community/tutorials/an-introduction-to-metrics-monitoring-and-alerting#what-type-of-information-is-important-to-track)
    by Justin Ellingwood.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**应该监控哪些指标？** 由于ML系统是软件系统的一个子类，因此可以从操作指标开始。示例包括机器的CPU/GPU利用率、内存和磁盘空间；发送到应用程序的请求数量和响应延迟、错误率；网络连接性。要深入了解操作指标的监控，请查看Justin
    Ellingwood的文章[指标、监控与警报介绍](https://www.digitalocean.com/community/tutorials/an-introduction-to-metrics-monitoring-and-alerting#what-type-of-information-is-important-to-track)。'
- en: While operational metrics are about machine, network, and application health,
    ML-related metrics check model accuracy and input consistency.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 操作指标关注机器、网络和应用程序的健康状态，而与ML相关的指标检查模型准确性和输入一致性。
- en: '**Accuracy is the most important thing we care about**. This means the model
    might still return predictions, but those predictions could be entirely off-base,
    and you won’t realize it until the model is evaluated. If you’re fortunate to
    work in a domain where natural labels become available quickly (as in recommender
    systems), simply collect these labels as they come in, evaluate the model, and
    do so continuously. However, in many domains, labels might either take a long
    time to arrive or not come in at all. In such cases, it’s beneficial to monitor
    something that could indirectly indicate a potential drop in accuracy.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**准确性是我们最关心的事情**。这意味着模型可能仍然会返回预测，但这些预测可能完全不准确，你直到模型被评估时才会意识到。如果你有幸在一个自然标签快速可用的领域工作（如推荐系统），只需收集这些标签，并持续评估模型。然而，在许多领域，标签可能需要很长时间才能到达，或者根本不会出现。在这种情况下，监控一些可能间接指示准确性下降的指标是有益的。'
- en: '**Why could model accuracy drop at all? The most widespread reason is that
    production data has drifted from training/test data**. In the Computer Vision
    domain, you can visually see that data has drifted: images became darker, or lighter,
    or resolution changes, or now there are more indoor images than outdoor.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**为什么模型准确率会下降？最普遍的原因是生产数据已从训练/测试数据中漂移**。在计算机视觉领域，你可以直观地看到数据已经漂移：图像变得更暗或更亮，或分辨率发生变化，或现在室内图像比室外图像更多。'
- en: 'To automatically detect data drift (it is also called “data distribution shift”),
    continuously monitor model inputs and outputs. The inputs to the model should
    be consistent with those used during training; for tabular data, this means that
    column names as well as the mean and variance of the features must be the same.
    Monitoring the distribution of model predictions is also valuable. In classification
    tasks, for example, you can track the proportion of predictions for each class.
    If there’s a notable change — like if a model that previously categorized 5% of
    instances as Class A now categorizes 20% as such — it’s a sign that something
    definitely happened. To learn more about data drift, check out this great post
    by Chip Huyen: [Data Distribution Shifts and Monitoring](https://huyenchip.com/2022/02/07/data-distribution-shifts-and-monitoring.html).'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 要自动检测数据漂移（也称为“数据分布变化”），需要持续监控模型的输入和输出。模型的输入应该与训练期间使用的一致；对于表格数据，这意味着列名以及特征的均值和方差必须相同。监控模型预测的分布也是有价值的。例如，在分类任务中，你可以跟踪每个类别预测的比例。如果发生了显著变化——比如一个模型以前将5%的实例分类为A类，现在将20%分类为A类——这就是一个明确的信号，表明确实发生了某些事情。要了解更多关于数据漂移的内容，请查看Chip
    Huyen的这篇精彩文章：[数据分布变化与监控](https://huyenchip.com/2022/02/07/data-distribution-shifts-and-monitoring.html)。
- en: 'There is much more left to say about monitoring, but we must move on. You can
    check these posts if you feel like you need more information:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 关于监控还有很多要说的内容，但我们必须继续前进。如果你觉得需要更多信息，可以查看这些文章：
- en: '- [Monitoring Machine Learning Systems](https://madewithml.com/courses/mlops/monitoring/)
    by Goku Mohandas'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '- [监控机器学习系统](https://madewithml.com/courses/mlops/monitoring/) 作者：Goku Mohandas'
- en: '- [A Comprehensive Guide on How to Monitor Your Models in Production](https://neptune.ai/blog/how-to-monitor-your-models-in-production-guide)
    by Stephen Oladele'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '- [关于如何监控生产环境中模型的综合指南](https://neptune.ai/blog/how-to-monitor-your-models-in-production-guide)
    作者：Stephen Oladele'
- en: Model Updates
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型更新
- en: '**If you deploy the model to production and do nothing to it, its accuracy
    diminishes over time.** In most cases, it is explained by data distribution shifts.
    The input data may change format. User behavior continuously changes without any
    valid reasons. Epidemics, crises, and wars may suddenly happen and break all the
    rules and assumptions that worked previously. “Change is the only constant.”-
    Heraclitus.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果你将模型部署到生产环境中并不加以更新，它的准确性会随着时间的推移而降低。** 在大多数情况下，这可以通过数据分布的变化来解释。输入数据可能会改变格式。用户行为不断变化，没有有效的理由。流行病、危机和战争可能会突然发生，打破之前有效的所有规则和假设。“变化是唯一的不变。”-
    赫拉克利特。'
- en: 'That is why production models must be regularly updated. There are two types
    of updates: model update and data update. During the model update an algorithm
    or training strategy is changed. The model update does not need to happen regularly,
    it’s usually done ad-hoc — when a business task is changed, a bug is found, or
    the team has time for the research. In contrast, a data update is when the same
    algorithm is trained on newer data. Regular data update is a must for any ML system.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么生产模型必须定期更新的原因。更新分为两种类型：模型更新和数据更新。在模型更新中，更改算法或训练策略。模型更新不需要定期进行，通常是根据具体情况进行的——当业务任务发生变化、发现错误或团队有时间进行研究时。相比之下，数据更新是在新数据上训练相同的算法。定期的数据更新是任何
    ML 系统的必备条件。
- en: '**A prerequisite for regular data updates is setting up an infrastructure that
    can support automatic dataflows, model training, evaluation, and deployment.**'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**定期数据更新的前提是建立一个能够支持自动数据流、模型训练、评估和部署的基础设施。**'
- en: It’s crucial to highlight that data updates should occur with little to no manual
    intervention. Manual efforts should be primarily reserved for data annotation
    (while ensuring that data flow to and from annotation teams is fully automated),
    maybe making final deployment decisions, and addressing any bugs that may surface
    during the training and deployment phases.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 关键在于，数据更新应尽量减少人工干预。人工工作应主要用于数据标注（同时确保数据流向和来自标注团队的流动完全自动化），可能需要做出最终部署决策，并解决在训练和部署阶段可能出现的任何问题。
- en: 'Once the infrastructure is set up, the frequency of updates is merely a value
    you need to adjust in the config file. **How often should the model be updated
    with the newer data?** The answer is: as frequently as feasible and economically
    sensible. If increasing the frequency of updates brings more value than consumes
    costs — definitely go for the increase. However, in some scenarios, training every
    hour might not be feasible, even if it would be highly profitable. For instance,
    if a model depends on human annotations, this process can become a bottleneck.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦基础设施建立起来，更新的频率只是你需要在配置文件中调整的一个值。**模型应该多频繁地用更新的数据进行更新？** 答案是：尽可能频繁且经济合理。如果增加更新频率带来的价值大于成本——绝对应该增加。然而，在某些情况下，即使训练每小时进行一次可能会非常有利，也可能不可行。例如，如果模型依赖于人工标注，这个过程可能会成为瓶颈。
- en: '**Training from scratch or fine-tuning on new data only?** It’s not a binary
    decision but rather a blend of both. Frequently fine-tuning the model is sensible
    since it’s more cost-effective and quicker than training from scratch. However,
    occasionally, training from scratch is also necessary. It’s crucial to understand
    that fine-tuning is primarily an optimization of cost and time. Typically, companies
    start with the straightforward approach of training from scratch initially, gradually
    incorporating fine-tuning as the project expands and evolves.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**从头开始训练还是仅在新数据上进行微调？** 这不是一个二元的决策，而是两者的结合。频繁地对模型进行微调是合理的，因为它比从头开始训练更具成本效益且更快。然而，有时从头开始训练也是必要的。理解微调主要是对成本和时间的优化至关重要。通常，公司最初会采用从头开始训练的直接方法，随着项目的扩展和发展，逐渐纳入微调。'
- en: 'To find out more about model updates, check out this post:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关模型更新的更多信息，请查看此帖子：
- en: '[To retrain, or not to retrain? Let’s get analytical about ML model updates](https://www.evidentlyai.com/blog/retrain-or-not-retrain)
    by Emeli Dral et al.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[重训练，还是不重训练？让我们分析一下 ML 模型更新](https://www.evidentlyai.com/blog/retrain-or-not-retrain)
    由 Emeli Dral 等人编写。'
- en: Testing in Production
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试生产环境
- en: Before the model is deployed to production, it must be thoroughly evaluated.
    We have already discussed the pre-production (offline) evaluation in the [previous
    post](/building-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5)
    (check section “Model Evaluation”). However, you never know how the model will
    perform in production until you deploy it. This gave rise to testing in production,
    which is also referred to as online evaluation.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在将模型部署到生产环境之前，必须对其进行彻底评估。我们已经在[上一篇文章](/building-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5)中讨论了生产前（离线）评估（请参见“模型评估”部分）。然而，直到你将模型部署到生产环境，你永远不知道它在生产环境中的表现如何。这促生了生产环境中的测试，也称为在线评估。
- en: Testing in production doesn’t mean recklessly swapping out your reliable old
    model for a newly trained one and then anxiously awaiting the first predictions,
    ready to roll back at the slightest hiccup. Never do that. There are smarter and
    safer strategies to test your model in production without risking losing money
    or customers.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中测试并不意味着草率地将你可靠的旧模型替换为新训练的模型，然后焦急地等待第一次预测，随时准备在出现轻微问题时回滚。绝不要这样做。有更聪明、更安全的策略来在生产环境中测试你的模型，而不会冒着失去资金或客户的风险。
- en: '**A/B testing** is the most popular approach in the industry. With this method,
    traffic is randomly divided between existing and new models in some proportion.
    Existing and new models make predictions for real users, the predictions are saved
    and later carefully inspected. It is useful to compare not only model accuracies
    but also some business-related metrics, like conversion or revenue, which sometimes
    may be negatively correlated with accuracy.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**A/B 测试**是业界最流行的方法。通过这种方法，流量在现有模型和新模型之间以某种比例随机划分。现有模型和新模型对真实用户进行预测，预测结果被保存并随后仔细检查。比较的不仅仅是模型准确性，还可以比较一些与业务相关的指标，如转化率或收入，这些有时可能与准确性负相关。'
- en: 'A/B testing highly relies on statistical hypothesis testing. If you want to
    learn more about it, here is the post for you: [A/B Testing: A Complete Guide
    to Statistical Testing](/a-b-testing-a-complete-guide-to-statistical-testing-e3f1db140499)
    by Francesco Casalegno. For engineering implementation of the A/B tests, check
    out [Online AB test pattern](https://github.com/mercari/ml-system-design-pattern/blob/master/QA-patterns/Online-ab-test-pattern/design_en.md).'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: A/B 测试高度依赖于统计假设检验。如果你想了解更多，可以查看这篇文章：[A/B 测试：统计检验的完整指南](/a-b-testing-a-complete-guide-to-statistical-testing-e3f1db140499)
    作者：弗朗切斯科·卡萨列尼奥。有关 A/B 测试的工程实现，请查看[在线 AB 测试模式](https://github.com/mercari/ml-system-design-pattern/blob/master/QA-patterns/Online-ab-test-pattern/design_en.md)。
- en: '**Shadow deployment** is the safest way to test the model. The idea is to send
    all the traffic to the existing model and return its predictions to the end user
    in the usual way, and at the same time, also send all the traffic to a new (shadow)
    model. Shadow model predictions are not used anywhere, only stored for future
    analysis.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**Shadow 部署**是测试模型的最安全方式。其理念是将所有流量发送到现有模型，并以通常的方式将其预测返回给最终用户，同时也将所有流量发送到新的（Shadow）模型。Shadow
    模型的预测不会被使用，仅仅是存储以备未来分析。'
- en: '![](../Images/aace33b0946dae80228ced8998c4910e.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aace33b0946dae80228ced8998c4910e.png)'
- en: '*A/B Testing vs. Shadow Deployment. Image by Author*'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '*A/B 测试与 Shadow 部署。图片由作者提供*'
- en: '**Canary release**. You may think of it as “dynamic” A/B testing. A new model
    is deployed in parallel with the existing one. At the beginning only a small share
    of traffic is sent to a new model, for instance, 1%; the other 99% is still served
    by an existing model. If the new model performance is good enough its share of
    traffic is gradually increased and evaluated again, and increased again and evaluated,
    until all traffic is served by a new model. If at some stage, the new model does
    not perform well, it is removed from production and all traffic is directed back
    to the existing model.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**Canary 发布**。你可以将其视为“动态”A/B 测试。新的模型与现有模型并行部署。一开始，只有一小部分流量（例如 1%）会发送到新模型，其余
    99% 仍由现有模型提供服务。如果新模型的表现足够好，其流量份额会逐渐增加并再次评估，再次增加并评估，直到所有流量都由新模型提供服务。如果在某个阶段，新模型的表现不佳，它会被从生产环境中移除，所有流量将重新指向现有模型。'
- en: 'Here is the post that explains it a bit more:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是进一步解释的文章：
- en: '[Shadow Deployment Vs. Canary Release of ML Models](https://www.qwak.com/post/shadow-deployment-vs-canary-release-of-machine-learning-models)
    by Bartosz Mikulski.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[Shadow 部署与 ML 模型的 Canary 发布](https://www.qwak.com/post/shadow-deployment-vs-canary-release-of-machine-learning-models)
    作者：巴尔托什·米库尔斯基。'
- en: Conclusion
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this chapter, we learned about a whole new set of challenges that arise,
    once the model is deployed to production. The operational and ML-related metrics
    of the model must be continuously monitored to quickly detect and fix bugs if
    they arise. The model must be regularly retrained on newer data because its accuracy
    diminishes over time primarily due to the data distribution shifts. We discussed
    high-level decisions to make before deploying the model — real-time vs. batch
    inference and cloud vs. edge computing, each of them has its own advantages and
    limitations. We covered tools for easy deployment and demo when in infrequent
    cases you must do it alone. We learned that the model must be evaluated in production
    in addition to offline evaluations on the static datasets. You never know how
    the model will work in production until you actually release it. This problem
    gave rise to “safe” and controlled production tests — A/B tests, shadow deployments,
    and canary releases.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们了解了一系列新的挑战，这些挑战在模型部署到生产环境后会出现。模型的运营和与 ML 相关的指标必须持续监控，以便快速检测和修复可能出现的错误。模型必须定期在更新的数据上重新训练，因为其准确性会随着时间的推移而降低，主要是由于数据分布的变化。我们讨论了在部署模型之前需要做出的高层次决策——实时推理与批量推理以及云计算与边缘计算，每种都有其自身的优点和限制。我们介绍了用于简单部署和演示的工具，当你必须单独完成时可以使用。我们了解到，模型必须在生产环境中进行评估，除了对静态数据集的离线评估外。你永远不知道模型在生产环境中的表现如何，直到你实际发布它。这一问题催生了“安全”和受控的生产测试——A/B
    测试、影子部署和金丝雀发布。
- en: This was also the final chapter of the “Building Better ML Systems” series.
    If you have stayed with me from the beginning, you know now that an ML system
    is much more than just a fancy algorithm. I really hope this series was helpful,
    expanded your horizons, and taught you how to build better ML systems.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这也是“打造更好的 ML 系统”系列的最后一章。如果你从一开始就跟随我，你现在应该知道，ML 系统远不只是一个复杂的算法。我真的希望这个系列对你有所帮助，拓宽了你的视野，并教会了你如何构建更好的
    ML 系统。
- en: Thank you for reading!
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢你的阅读！
- en: 'In case you’ve missed previous chapters, here is the complete list:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你错过了前面的章节，这里是完整的列表：
- en: '[](/building-better-ml-systems-chapter-1-every-project-must-start-with-a-plan-907a36774a32?source=post_page-----eae3a75496ec--------------------------------)
    [## Building Better ML Systems. Chapter 1: Every project must start with a plan.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 打造更好的 ML 系统。第一章：每个项目都必须从计划开始](https://towardsdatascience.com/building-better-ml-systems-chapter-1-every-project-must-start-with-a-plan-907a36774a32?source=post_page-----eae3a75496ec--------------------------------)'
- en: About ML project lifecycle, designs doc, business value, and requirements. About
    starting small and failing fast.
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关于 ML 项目生命周期、设计文档、业务价值和需求。关于从小做起和快速失败。
- en: 'towardsdatascience.com](/building-better-ml-systems-chapter-1-every-project-must-start-with-a-plan-907a36774a32?source=post_page-----eae3a75496ec--------------------------------)
    [](/building-better-ml-systems-chapter-2-taming-data-chaos-841d5a04b39?source=post_page-----eae3a75496ec--------------------------------)
    [## Building Better ML Systems. Chapter 2: Taming Data Chaos.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 打造更好的 ML 系统。第二章：驯服数据混乱](https://towardsdatascience.com/building-better-ml-systems-chapter-2-taming-data-chaos-841d5a04b39?source=post_page-----eae3a75496ec--------------------------------)'
- en: About data-centric AI, training data, data labeling and cleaning, synthetic
    data, and a bit of Data Engineering and…
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关于以数据为中心的 AI、训练数据、数据标注和清洗、合成数据，以及一些数据工程和…
- en: 'towardsdatascience.com](/building-better-ml-systems-chapter-2-taming-data-chaos-841d5a04b39?source=post_page-----eae3a75496ec--------------------------------)
    [](/building-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5?source=post_page-----eae3a75496ec--------------------------------)
    [## Building Better ML Systems — Chapter 3: Modeling. Let the fun begin'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 打造更好的 ML 系统 — 第三章：建模。让乐趣开始](https://towardsdatascience.com/building-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5?source=post_page-----eae3a75496ec--------------------------------)'
- en: About baselines, experiment tracking, proper test sets, and metrics. About making
    the algorithm work.
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关于基准线、实验跟踪、适当的测试集和指标。关于让算法发挥作用。
- en: towardsdatascience.com](/building-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5?source=post_page-----eae3a75496ec--------------------------------)
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 打造更好的 ML 系统。第三章：建模。让乐趣开始](https://towardsdatascience.com/building-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5?source=post_page-----eae3a75496ec--------------------------------)'
