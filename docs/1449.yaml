- en: A Serverless Query Engine from Spare Parts
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从备用零件构建的无服务器查询引擎
- en: 原文：[https://towardsdatascience.com/a-serverless-query-engine-from-spare-parts-bd6320f10353?source=collection_archive---------0-----------------------#2023-04-27](https://towardsdatascience.com/a-serverless-query-engine-from-spare-parts-bd6320f10353?source=collection_archive---------0-----------------------#2023-04-27)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-serverless-query-engine-from-spare-parts-bd6320f10353?source=collection_archive---------0-----------------------#2023-04-27](https://towardsdatascience.com/a-serverless-query-engine-from-spare-parts-bd6320f10353?source=collection_archive---------0-----------------------#2023-04-27)
- en: '***An open-source implementation of a Data Lake with DuckDB and AWS Lambdas***'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '***一个基于 DuckDB 和 AWS Lambdas 的开源数据湖实现***'
- en: '[](https://medium.com/@ciro.greco?source=post_page-----bd6320f10353--------------------------------)[![Ciro
    Greco](../Images/4a20e5d435998e8d8ff7aeac1f8ff60d.png)](https://medium.com/@ciro.greco?source=post_page-----bd6320f10353--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bd6320f10353--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bd6320f10353--------------------------------)
    [Ciro Greco](https://medium.com/@ciro.greco?source=post_page-----bd6320f10353--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@ciro.greco?source=post_page-----bd6320f10353--------------------------------)[![Ciro
    Greco](../Images/4a20e5d435998e8d8ff7aeac1f8ff60d.png)](https://medium.com/@ciro.greco?source=post_page-----bd6320f10353--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bd6320f10353--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bd6320f10353--------------------------------)
    [Ciro Greco](https://medium.com/@ciro.greco?source=post_page-----bd6320f10353--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1a8912e69301&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-serverless-query-engine-from-spare-parts-bd6320f10353&user=Ciro+Greco&userId=1a8912e69301&source=post_page-1a8912e69301----bd6320f10353---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bd6320f10353--------------------------------)
    ·9 min read·Apr 27, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbd6320f10353&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-serverless-query-engine-from-spare-parts-bd6320f10353&user=Ciro+Greco&userId=1a8912e69301&source=-----bd6320f10353---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1a8912e69301&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-serverless-query-engine-from-spare-parts-bd6320f10353&user=Ciro+Greco&userId=1a8912e69301&source=post_page-1a8912e69301----bd6320f10353---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bd6320f10353--------------------------------)
    ·9分钟阅读·2023年4月27日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbd6320f10353&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-serverless-query-engine-from-spare-parts-bd6320f10353&user=Ciro+Greco&userId=1a8912e69301&source=-----bd6320f10353---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbd6320f10353&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-serverless-query-engine-from-spare-parts-bd6320f10353&source=-----bd6320f10353---------------------bookmark_footer-----------)![](../Images/85ce8738302baf64cec9764042261d18.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbd6320f10353&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-serverless-query-engine-from-spare-parts-bd6320f10353&source=-----bd6320f10353---------------------bookmark_footer-----------)![](../Images/85ce8738302baf64cec9764042261d18.png)'
- en: A duck in the cloud. Photo by [László Glatz](https://unsplash.com/ko/@glatz0?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 云中的一只鸭子。照片由[László Glatz](https://unsplash.com/ko/@glatz0?utm_source=medium&utm_medium=referral)拍摄，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)。
- en: 'In this post we will show how to build a simple end-to-end application in the
    cloud on a serverless infrastructure. The purpose is simple: we want to show that
    we can develop directly against the cloud while minimizing the cognitive overhead
    of designing and building infrastructure. Plus, we will put together a design
    that minimizes costs compared to modern data warehouses, such as Big Query or
    Snowflake.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将展示如何在无服务器基础设施上构建一个简单的端到端应用程序。我们的目标很简单：我们想展示可以直接在云中开发，同时最小化设计和构建基础设施的认知负担。此外，我们将提出一个设计方案，与现代数据仓库（如
    Big Query 或 Snowflake）相比，能够最小化成本。
- en: As data practitioners we want (and love) to build applications on top of our
    data as seamlessly as possible. Whether you work in BI, Data Science or ML all
    that matters is the final application and how fast you can see it working end-to-end.
    The infrastructure often gets in the way though.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据从业者，我们希望（并且喜欢）尽可能无缝地在我们的数据上构建应用程序。无论你是从事 BI、数据科学还是机器学习，最终的应用程序和你看到它端到端运行的速度才是最重要的。然而，基础设施往往会成为障碍。
- en: Imagine, as a practical example, that we need to build a new customer-facing
    analytics application for our product team. Because it’s client-facing we have
    performance constraints we need to respect, such as low latency.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，作为一个实际例子，我们需要为我们的产品团队构建一个新的面向客户的分析应用。因为这是面向客户的，所以我们需要尊重一些性能约束，例如低延迟。
- en: 'We can start developing it directly in the cloud, but it would immediately
    bring us to some infra questions: where do we run it? How big a machine do we
    need? Because of the low-latency requirement, do we need to build a caching layer?
    If so, how do we do it?'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以直接在云中开始开发，但这会立即引出一些基础设施问题：我们在哪里运行它？我们需要多大的机器？由于低延迟的要求，我们是否需要构建一个缓存层？如果是的话，我们该怎么做？
- en: Alternatively, we can develop our app locally. It will probably be more intuitive
    from the developer experience point of view but it only postpones the infra questions,
    since in the end we will have to find a way to go from our local project to actual
    pipelines. Moreover, the data will need to leave the cloud env to go on our machine,
    which is not exactly secure and auditable.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，我们可以在本地开发我们的应用。从开发者体验的角度来看，这可能更直观，但这只是推迟了基础设施问题，因为最终我们必须找到一种方法将本地项目转移到实际的管道中。此外，数据需要离开云环境到达我们的机器，这并不完全安全和可审计。
- en: To make the cloud experience as smooth as possible we designed a data lake architecture
    where data are sitting in a simple cloud storage (AWS S3) and a serverless infrastructure
    that embeds DuckDB works as a query engine. At the end of the cycle, we will have
    an analytics app that can be used to both visualize and query the data in real
    time with virtually no infra costs.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使云体验尽可能顺畅，我们设计了一个数据湖架构，其中数据存储在一个简单的云存储（AWS S3）中，嵌入 DuckDB 的无服务器基础设施作为查询引擎。在周期结束时，我们将拥有一个分析应用，可以实时可视化和查询数据，几乎没有基础设施成本。
- en: 'Of course, this is a bit of a simplification, as some tweaks would be needed
    to run this project in real production scenarios. What we provide is a general
    blueprint to leverage the separation of storage and compute to build a data lake
    with a query engine in the cloud. We show how to power an interactive data app
    with an (almost) free cloud endpoint, no warehouse setup, and lighting fast performance.
    In our implementation, the final application is a simple [Streamlit](https://streamlit.io/)
    app, but that’s merely for explanatory purposes: you can easily think of plugging
    in your favorite BI tool.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这有些简化，因为在实际生产场景中运行这个项目还需要一些调整。我们提供的是一个通用蓝图，利用存储和计算的分离来在云端构建数据湖和查询引擎。我们展示了如何通过一个（几乎）免费的云端终端、无需仓库设置以及闪电般的性能来支持一个交互式数据应用。在我们的实现中，最终的应用是一个简单的
    [Streamlit](https://streamlit.io/) 应用，但这仅仅是为了说明目的：你可以轻松地考虑将其与自己喜欢的 BI 工具连接起来。
- en: '![](../Images/1b264fdda718c5e216ad75968adfa68a.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1b264fdda718c5e216ad75968adfa68a.png)'
- en: A lightinign fast analytics app built with our system. Image from the authors.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 用我们的系统构建的闪电般快速的分析应用。图片来自作者。
- en: '**Ducks go serverless**'
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**鸭子无服务器化**'
- en: Y’all know DuckDB at this point. It is an open-source in-process SQL OLAP database
    built specifically for analytical queries. It is somewhat still unclear how much
    DuckDB is actually [used in production](https://dlthub.com/docs/blog/duckdb-1M-downloads-users),
    but for us today the killer feature is the possibility of querying parquet files
    directly in S3 with SQL syntax.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你们现在都知道 DuckDB 了。它是一个开源的内存中 SQL OLAP 数据库，专为分析查询而构建。DuckDB 实际上在 [生产环境中使用](https://dlthub.com/docs/blog/duckdb-1M-downloads-users)
    的情况还不太清楚，但对我们来说，杀手级功能是可以用 SQL 语法直接查询 S3 中的 parquet 文件。
- en: So most practitioners seem to be using it right now as a local engine for data
    exploration, *ad hoc* analysis, POCs and prototyping (with some [creative ideas](https://duckdb.org/2022/10/12/modern-data-stack-in-a-box.html)
    on how to extend its initial purpose to cover more surface). People create notebooks
    or small data apps with embedded DuckDB to prototype and experiment with production
    data locally.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，大多数从业者现在似乎将其作为本地引擎进行数据探索，*临时*分析，POC 和原型制作（同时一些[创新的想法](https://duckdb.org/2022/10/12/modern-data-stack-in-a-box.html)则扩展其初始目的以涵盖更多领域）。人们使用嵌入
    DuckDB 的笔记本或小型数据应用程序来原型设计和实验生产数据。
- en: The cloud is better. And if we often feel it isn’t, it’s because something is
    wrong with the tool chain we use, but there is a very big difference between a
    [bad idea](https://www.facebook.com/CoachBillHart/videos/yep-worst-idea-ever/682926339663235/)
    and a [good idea badly executed](https://www.ebay.com/itm/256040369567).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 云更好。如果我们常常感觉不是这样，那是因为我们使用的工具链出了问题，但是一个[坏主意](https://www.facebook.com/CoachBillHart/videos/yep-worst-idea-ever/682926339663235/)和一个[好主意糟糕执行](https://www.ebay.com/itm/256040369567)之间有很大的区别。
- en: 'If we combine a data lake architecture, a serverless design, DuckDB and a bit
    of ingenuity we can build a very fast data stack from spare parts: no warehouse
    setup, lighting fast performance and outrageously cheap costs — S3 most expensive
    standard pricing is $0.023 per GB, AWS Lambda is very fast and scales to zero
    when not in use, so it is a no-fat computation bill, plus AWS gives you 1M calls
    for free.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们结合数据湖架构、无服务器设计、DuckDB 和一些机智，我们可以从备件构建一个非常快速的数据堆栈：无需仓库设置，性能极快，成本非常便宜 —— S3
    最昂贵的标准价格是每 GB $0.023，AWS Lambda 很快，并在不使用时缩减至零，因此它是一个无负担的计算账单，而且 AWS 还免费提供 100
    万次调用。
- en: Buckle up, [clone the repo](https://github.com/BauplanLabs/quack-reduce/), sing
    along and for more details, please refer to the [README](https://github.com/BauplanLabs/quack-reduce#quack-reduce).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好，[克隆仓库](https://github.com/BauplanLabs/quack-reduce/)，跟着唱，更多细节，请参阅[README](https://github.com/BauplanLabs/quack-reduce#quack-reduce)。
- en: '**Architecture**'
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**架构**'
- en: This project is pretty self-contained and requires only introductory-level familiarity
    with cloud services and Python.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目非常自包含，只需要对云服务和Python有入门级别的熟悉度。
- en: The idea is to start from a Data Lake where our data are stored. Once the data
    is uploaded in our S3 in a parquet format, we can then trigger the lambda with
    a SQL query. At that point, our lambda goes up, spins up a DuckDB instance in
    memory, computes the query and gets back to the user with the results, which can
    be directly rendered as tables in the Terminal.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 思路是从存储数据的数据湖开始。一旦数据以 Parquet 格式上传到我们的 S3 中，我们就可以使用 SQL 查询触发 Lambda。此时，我们的 Lambda
    启动，在内存中启动 DuckDB 实例，计算查询并将结果返回给用户，可以直接在终端中呈现为表格。
- en: 'The architecture has a number of advantages mostly coming from the serverless
    design: speed, proximity to the data and one line deployment are nice; plus, of
    course, the system scales to zero when not used, so we only pay per query.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 该架构具有多个优点，主要来自无服务器设计：速度快，接近数据，一键部署很好；当然，系统在不使用时可以缩减至零，因此我们只需按查询付费。
- en: '![](../Images/71a6d21d82c6f47b8725b63078a62a92.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/71a6d21d82c6f47b8725b63078a62a92.png)'
- en: General architecture of our system. Image from the authors
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们系统的总体架构。来自作者的图片
- en: '**Your first query engine + data lake from spare parts**'
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**您的第一个查询引擎 + 数据湖来自备件**'
- en: 'We provide a simple script that will create an S3 bucket and populate it with
    a portion of the [NYC TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)
    (available under the [nyc.gov terms of use](https://www.nyc.gov/home/terms-of-use.page)),
    both as a unique file and as a hive-partitioned directory (you can run it with
    [Make](https://github.com/BauplanLabs/quack-reduce/blob/74846468fd7b5dd2087691d1bc3d7aaa8417aa39/src/Makefile#L15)).
    Once the data are in the data lake we can set up and use our lambda: if you have
    the Serverless CLI setup correctly, deploying the lambda is [one command of Make
    again](https://github.com/BauplanLabs/quack-reduce/blob/74846468fd7b5dd2087691d1bc3d7aaa8417aa39/src/Makefile#L7).'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了一个简单的脚本，将创建一个 S3 存储桶，并将[纽约市 TLC 行程记录数据](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)的一部分填充进去（可在[nyc.gov
    使用条款](https://www.nyc.gov/home/terms-of-use.page)下使用），分别作为唯一文件和分区目录（您可以使用[Make](https://github.com/BauplanLabs/quack-reduce/blob/74846468fd7b5dd2087691d1bc3d7aaa8417aa39/src/Makefile#L15)运行）。一旦数据存储在数据湖中，我们可以设置和使用我们的
    Lambda：如果您已正确设置 Serverless CLI，则部署 Lambda 又是[一条 Make 命令](https://github.com/BauplanLabs/quack-reduce/blob/74846468fd7b5dd2087691d1bc3d7aaa8417aa39/src/Makefile#L7)的事情。
- en: 'The lambda can be invoked in any of the usual ways, and accepts a query as
    its main payload: when it runs, it uses DuckDB (re-using an instance if on a warm
    start) to execute the query on the data lake. DuckDb does not know anything about
    the data before and after the execution, making the lambda purely stateless as
    far as data semantics is concerned.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda 可以通过任何常见方式调用，并接受一个查询作为其主要负载：当它运行时，它使用 DuckDB（如果是热启动，则重用实例）在数据湖中执行查询。DuckDb
    在执行前后对数据一无所知，使得 lambda 在数据语义上完全无状态。
- en: 'For instance, you can use the simple Python script in the project to send this
    query to the lambda, and display the results:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可以使用项目中的简单 Python 脚本将这个查询发送到 lambda，并显示结果：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/921e7cc43ed0ce165484df9dbcb1bfcc.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/921e7cc43ed0ce165484df9dbcb1bfcc.png)'
- en: The results are visualized directly in your terminal. Image from the authors.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 结果会直接在你的终端中可视化。图片来自作者。
- en: 'Et voilà! You can now query your data lake, securely in the cloud. This very
    simple design addresses directly two of the typical frictions for working in cloud
    data warehouses:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 看！你现在可以在云端安全地查询你的数据湖。这种非常简单的设计直接解决了在云数据仓库中工作的两个典型摩擦点：
- en: 'The setup is significantly simplified since all the user needs to do is to
    have her AWS credential. Once the setup is done, the user only needs access to
    the lambda (or any proxy to it!): that is good, as it gives the user full query
    capabilities without access to the underlying storage.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于所有用户需要做的只是拥有她的 AWS 凭证，设置过程显著简化。一旦设置完成，用户只需访问 lambda（或任何代理！）：这很好，因为它使用户在没有访问底层存储的情况下拥有完整的查询能力。
- en: The performances are so good that it feels like developing locally, even if
    we always go through the cloud. A snappy cloud experience helps tame the too familiar
    feeling that advantages of working on remote machines is paid in the coin of good
    developer experience.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能如此出色，以至于即使我们总是通过云端，也感觉像是在本地开发。一个快速的云体验有助于驯服那种在远程机器上工作的优势以良好的开发者体验为代价的过于熟悉的感觉。
- en: '**(Almost) Free Analytics**'
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**（几乎）免费分析**'
- en: It’s all good and boujee, but let us say that we want to do a bit more than
    query data on the fly. Let’s say that we want to build an application on top of
    a table. It’s a very simple app, there is no orchestration and no need to calibrate
    the workload.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一切都很好而且奢华，但假设我们想做的事情比即时查询数据更多。假设我们想在一个表的基础上构建一个应用程序。它是一个非常简单的应用，没有编排，也不需要校准工作负载。
- en: At the same time, let’s say that this application needs to be responsive, it
    needs to be fast. Anyone who deals with clients directly, for instance, knows
    how it is important to provide a fresh responsive experience to the clients who
    want to see their data. The one thing nobody likes is a dashboard that takes minutes
    to load.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，假设这个应用需要具备响应能力，它还需要快速。直接与客户打交道的人都知道，为那些希望查看数据的客户提供一个新鲜的响应式体验是多么重要。没有人喜欢一个加载需要几分钟的仪表盘。
- en: To see how this architecture can bridge the gap between data pipelines and real-time
    querying for analytics, we provide a small dbt DAG to simulate running some offline
    SQL transformations over the original dataset resulting in a new artifact in the
    data lake (the equivalent of a dashboard view).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解这种架构如何弥合数据管道与实时分析查询之间的差距，我们提供了一个小型的 dbt DAG 以模拟对原始数据集进行一些离线 SQL 转换，从而在数据湖中生成一个新成果（相当于仪表盘视图）。
- en: To keep things as self contained as possible, we included a version that you
    can run locally on your machine (see README for more details — nor dbt nor the
    engine behind it matter for this pattern to work). However, you can use a different
    runtime for dbt and export the final artifact as a parquet file, with [Snowflake](https://docs.snowflake.com/en/user-guide/script-data-load-transform-parquet)
    or [BigQuery](https://cloud.google.com/dataflow/docs/guides/templates/provided/bigquery-to-parquet).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了尽可能保持自给自足，我们包括了一个可以在本地机器上运行的版本（请参阅 README 获取更多细节—— dbt 或其背后的引擎对该模式的工作无关紧要）。然而，你可以使用不同的
    dbt 运行时，并将最终成果导出为 parquet 文件，使用 [Snowflake](https://docs.snowflake.com/en/user-guide/script-data-load-transform-parquet)
    或 [BigQuery](https://cloud.google.com/dataflow/docs/guides/templates/provided/bigquery-to-parquet)。
- en: '![](../Images/ba65662b5f905758611fba300eb28d9d.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ba65662b5f905758611fba300eb28d9d.png)'
- en: Architecture of our system paired with a dbt project. Image from the authors.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的系统架构与一个 dbt 项目配对。图片来自作者。
- en: 'For the time being, we’ll stick to our super simple DAG made of two nodes.
    The first node takes the pickup_location_id from our data lake and order them
    by the number of trips:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们将坚持使用我们由两个节点构成的超级简单DAG。第一个节点从我们的数据湖中提取pickup_location_id，并按旅行次数排序：
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The second that gives as the top 200 pick up locations in our data set:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个节点提供了数据集中前200个取车地点：
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can visualize the DAG with dbt docs:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用dbt文档可视化DAG：
- en: '![](../Images/f1fd934196a5b64422be3235ad0c551a.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f1fd934196a5b64422be3235ad0c551a.png)'
- en: 'Once our pipeline is done, the final artifact is uploaded back to our data
    lake in:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的管道完成，最终工件将上传回我们的数据湖中：
- en: '[PRE3]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We can then reuse the query engine we built before to query the second (and
    final) node of our DAG to visualize the data in a Streamlit app, simply by running
    in the terminal:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以重用之前构建的查询引擎，查询DAG的第二个（也是最后一个）节点，以在Streamlit应用中可视化数据，只需在终端中运行：
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Every time we hit the dashboard, the dashboard hits the lambda behind the scenes.
    If you like this simple architecture, the same pattern can be used in your own
    Streamlit app, or in your favorite BI tool.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 每次我们访问仪表盘时，仪表盘都会访问幕后运行的lambda。如果你喜欢这种简单的架构，相同的模式可以在你自己的Streamlit应用或你喜欢的BI工具中使用。
- en: '**A few remarks on the “Reasonable Scale”**'
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**关于“合理规模”的几点说明**'
- en: '[A while ago](https://tenor.com/view/yeah-i-member-memberberries-south-park-i-remember-oh-yeah-gif-20408218),
    we wrote a series of posts on what we called [MLOps at Reasonable Scale](https://towardsdatascience.com/tagged/mlops-without-much-ops)
    where we talked about the best strategies to build reliable ML applications in
    companies that do not process data at internet scale and have a number of constraints
    that truly Big-Data companies typically do not have. We mostly talked about it
    from the point of view of ML and MLOps because operationalizing successfully ML
    was a major problem for organizations at the time (maybe it still is, I am not
    sure), but one general observation remains: most data organizations are “Reasonable
    Scale” and they should design their systems around this assumption. Note that
    being a reasonable scale organization does not necessarily mean being a small
    company. The enterprise world is full of data teams who deal with a lot of complexity
    within large — sometimes enormous — organizations and yet have many reasonable
    scale pipelines, often for internal stakeholders, ranging from a few GB to at
    most a TB.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[不久前](https://tenor.com/view/yeah-i-member-memberberries-south-park-i-remember-oh-yeah-gif-20408218)，我们写了一系列关于我们称之为[合理规模下的MLOps](https://towardsdatascience.com/tagged/mlops-without-much-ops)的文章，讨论了在不处理互联网规模数据的公司中构建可靠ML应用的最佳策略，并且这些公司具有真正的大数据公司通常不具备的一些约束条件。我们主要从ML和MLOps的角度进行了讨论，因为成功地运作ML曾经是组织面临的一个主要问题（也许现在仍然是，我不确定），但有一个普遍的观察结果仍然存在：大多数数据组织都是“合理规模”的，他们应该围绕这一假设来设计他们的系统。需要注意的是，成为合理规模的组织并不一定意味着成为小公司。企业界充满了在大型——有时是巨大的——组织中处理复杂性的团队，但这些团队通常有许多合理规模的管道，通常是为了内部利益相关者，从几GB到最多TB不等。'
- en: Recently, we happily witnessed a growing debate around whether companies need
    Big Data systems to deal with their data problems,. The most important takeaway
    from our point of view remains that, if you are a Reasonable Scale organization,
    dealing with unnecessary infrastructure can be a very serious burden with plenty
    of nefarious ramifications in your organization processes. You could in principle
    build an entire data stack to support low latency dashboards — maybe you could
    use a Data Warehouse and a caching layer -, but since your resources are limited,
    wouldn’t it be nice to have a simpler and cheaper way?
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，我们高兴地见证了一个关于公司是否需要大数据系统来解决数据问题的激烈辩论。从我们的观点来看，最重要的结论仍然是，如果你是一个“合理规模”的组织，处理不必要的基础设施可能会给你的组织流程带来很大的负担，产生许多不利影响。理论上，你可以构建一个完整的数据堆栈来支持低延迟仪表盘——也许你可以使用数据仓库和缓存层——但由于你的资源有限，是否可以有一种更简单、更便宜的方法呢？
- en: In this post, we showed that the combination of data-first storage formats,
    on-demand compute and in-memory OLAP processing opens up for new possibilities
    at Reasonable Scale. The system is far from perfect and [could use many improvements](https://github.com/BauplanLabs/quack-reduce#whats-next),
    but it shows that one can build an interactive data app with no warehouse setup,
    lighting fast performances and virtually no costs. By removing the db from DuckDB,
    we can combine what is fundamentally right about local (“single node processing
    is all you need”) with what is fundamentally right about the cloud (“data is better
    processed elsewhere”).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们展示了数据优先存储格式、按需计算和内存OLAP处理的组合如何在合理规模下开辟新的可能性。该系统虽然远未完善，且[还需要许多改进](https://github.com/BauplanLabs/quack-reduce#whats-next)，但它表明，人们可以构建一个无需数据仓库设置、性能极快且几乎无成本的互动数据应用。通过从DuckDB中移除数据库，我们可以将本地（“单节点处理是你所需的一切”）和云端（“数据在其他地方处理效果更好”）的优点结合起来。
- en: I am spending most of my time thinking about serverless data infra. If you are
    interested, you have feedback on this post or simply want to chat, drop me a line
    at ciro.greco@bauplanlabs.com
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我大部分时间都在思考无服务器数据基础设施。如果你感兴趣，或者对这篇文章有反馈，或者只是想聊聊，可以通过 ciros.greco@bauplanlabs.com
    联系我。
