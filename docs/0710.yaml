- en: 'Awesome Data Science Tools to Master in 2023: Data Profiling Edition'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/awesome-data-science-tools-to-master-in-2023-data-profiling-edition-29d29310f779?source=collection_archive---------0-----------------------#2023-02-22](https://towardsdatascience.com/awesome-data-science-tools-to-master-in-2023-data-profiling-edition-29d29310f779?source=collection_archive---------0-----------------------#2023-02-22)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Data Tools Review*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 5 Open Source Python Packages for EDA and Visualization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@miriam.santos?source=post_page-----29d29310f779--------------------------------)[![Miriam
    Santos](../Images/decbc6528a641e7b02934a03e136284a.png)](https://medium.com/@miriam.santos?source=post_page-----29d29310f779--------------------------------)[](https://towardsdatascience.com/?source=post_page-----29d29310f779--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----29d29310f779--------------------------------)
    [Miriam Santos](https://medium.com/@miriam.santos?source=post_page-----29d29310f779--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F243289394aaa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fawesome-data-science-tools-to-master-in-2023-data-profiling-edition-29d29310f779&user=Miriam+Santos&userId=243289394aaa&source=post_page-243289394aaa----29d29310f779---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----29d29310f779--------------------------------)
    ·15 min read·Feb 22, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F29d29310f779&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fawesome-data-science-tools-to-master-in-2023-data-profiling-edition-29d29310f779&user=Miriam+Santos&userId=243289394aaa&source=-----29d29310f779---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F29d29310f779&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fawesome-data-science-tools-to-master-in-2023-data-profiling-edition-29d29310f779&source=-----29d29310f779---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: '*This is a column series focusing on open-source tools for data science: each
    article focuses on a specific topic and introduces the reader to a set of different
    tools, showcasing their features with a real-world dataset.* ***This piece focuses
    on data profiling******and reviews***`*ydata-profiling*`*,* `*dataprep*`*,* `*sweetviz*`*,*
    `*autoviz*`*, and* `*lux*`*.* ***Readers are encouraged to follow along the tutorial:***
    *I’ll be referring to all projects on their individual GitHub repositories, but
    a curated list of tools, as well as the Google Colab notebooks used throughout
    this article are* ***available in the*** [***awesome-data-centric-ai***](https://github.com/Data-Centric-AI-Community/awesome-data-centric-ai)
    ***repository.***'
  prefs: []
  type: TYPE_NORMAL
- en: In ***a world of Data Imperfection, a carefully-designed tool for data understanding
    is the philosopher’s stone.***
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4b29e5607c38a5b9f16bd511633cb65c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A “multidimensional” philosopher stone: data cubes. Analyzing data often involves
    twisting and twirling our datasets around to find the most insightful perspectives.
    Photo by [aaron boris](https://unsplash.com/@aaron_boris?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral).'
  prefs: []
  type: TYPE_NORMAL
- en: Data Quality plays a vital role in the outcome of our machine learning models.
    Some [data imperfections](https://medium.com/towards-data-science/data-quality-issues-that-kill-your-machine-learning-models-961591340b40)
    may severely handicap the internal workings of models themselves, rendering them
    inapplicable (e.g., missing data). Others may pass unnoticed during the model
    development stage and come back with nefarious consequences when models are deployed
    to production (e.g., class imbalance, underrepresented data, dataset shift).
  prefs: []
  type: TYPE_NORMAL
- en: After struggling long and hard with producing more robust machine learning models,
    **both academics and engineers are now moving towards a Data-Centric AI paradigm**.
    We’ve collectively realized that data can make or break our models, and that oftentimes,
    a problem may be solved with a “simpler” model, if data is *smart.*
  prefs: []
  type: TYPE_NORMAL
- en: '*But how can we move from imperfect to smart data?*'
  prefs: []
  type: TYPE_NORMAL
- en: Data Profiling is the essence of Data Understanding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Since models are fed by data and data is curated by people, people need to
    understand the peculiarities of the data they’re asking models to digest.*'
  prefs: []
  type: TYPE_NORMAL
- en: Data Profiling is deeply linked to the concept of Exploratory Data Analysis.
    However, when talking about *profiling* data, we tend to associate it withan **automated
    reporting — i.e., “taking a *profile*” — of data characteristics**, ideally alerting
    us for potential issues that may occur immediately or further down the line.
  prefs: []
  type: TYPE_NORMAL
- en: '**More importantly, data profiling is an essential skill to master by all roles
    in data teams, from data scientists, machine learning engineers, data engineers,
    and data analysts.**'
  prefs: []
  type: TYPE_NORMAL
- en: '*“Our imputation method is returning high deviation values, did the input change?
    The model is outputting invalid predictions, we need to adjust it quickly, what
    happened? This data flow is completely breaking today, what went wrong? I need
    these results in a dashboard fast to discuss them in the next meeting, can someone
    get me a snapshot of the current state of data?”*'
  prefs: []
  type: TYPE_NORMAL
- en: These are just some of the many “data rants” that data teams face in the wild.
  prefs: []
  type: TYPE_NORMAL
- en: '**Fortunately, they can be minimized with the help of data profiling profiling
    tools.**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Let’s see how by exploring a real-world use case? Get ready to open your Google
    Colabs!*'
  prefs: []
  type: TYPE_NORMAL
- en: The HCC dataset… with slight modifications!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this article I will be using the HCC dataset which I personally curated
    during my MSc thesis. You can find it on [Kaggle](https://www.kaggle.com/datasets/mrsantos/hcc-dataset)
    and [UCI Repository](https://archive.ics.uci.edu/ml/datasets/HCC+Survival). Feel
    free to use it, it is licensed and we only appreciate proper referencing.
  prefs: []
  type: TYPE_NORMAL
- en: '**For the purpose of this review, I’ve taken a subset of features from the
    original dataset and further modified the data by artificially introducing some
    issues. The idea is to see how the different data profiling tools are able to
    identify and characterize them.**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the details regarding the data we’ll be using:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following subset of original features is considered: `Gender`, `Age`, `Alcohol`,
    `Hallmark`, `PS`, `Encephalopathy`, `Hemoglobin`, `MCV`, `Total_Bil`, `Dir_Bil`,
    `Ferritin`, `HBeAg`, and `Outcome`. Essentially, I’ve chosen a set of numeric
    and categorical (nominal and binary) features, with and without missing values,
    some category underrepresentation, and some high correlations;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The original `MCV` contained some missing values, which were replaced with other
    values in the feature (just for the sake of having another complete numerical
    feature besides `Age`);
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `O2` feature was artificially introduced: it contains only “999” values
    and represents an error in the data acquisition or collection. Imagine that a
    sensor has blown off and started outputting absurd values, or that the person
    collecting the data decided to code their absence as “999”;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `Hallmark` was modified: I concatenated its values with a “A, B, C, D,
    (…)” coding, which could represent the concatenation of the patient ID with the
    actual hallmark results. This represents an error during data processing or storage
    (an “ETL hitch”, if you will);'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `HBeAg` was also modified. In this case, I simply deleted all “Yes” values.
    This could mimic a [Missing Not At Random mechanism](https://ieeexplore.ieee.org/document/8605316),
    where all the missing values would be “Yes”, had they been observed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Since the data contains some modifications, I [added it to the repository](https://github.com/Data-Centric-AI-Community/awesome-data-centric-ai/tree/master/medium/data-profiling-tools/data)
    as well. Recall that this is for purely academic discussion: you can access the
    complete and untouched data in Kaggle or UCI Repository, as mentioned.'
  prefs: []
  type: TYPE_NORMAL
- en: '*So now without further due, let’s get cracking the actual code!*'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. ydata-profiling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You may know it as `pandas-profiling`, since the new name is very recent still:
    in short, version 4.0.0 now also supports Spark DataFrames beyond only Pandas
    DataFrames, and for this reason it changed its name to [YData Profiling](https://github.com/ydataai/ydata-profiling).'
  prefs: []
  type: TYPE_NORMAL
- en: The package is currently a crowd favorite for exploratory data analysis. Its
    efficiency and simplicity seem to win the hearts of technical and non-technical
    audiences alike, as it enables a very fast and straightforward visual understanding
    of the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let me show you how to get it up to speed! First, install the package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, the generation of a data profiling report is straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The report is quickly generated as follows, containing a general overview of
    the dataset’s properties, summary statistics for each feature, interaction and
    correlation plots, and insightful visualizations for missing values and duplicate
    records:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6483c24ed9cd908b648aa3e5cdfbae54.png)'
  prefs: []
  type: TYPE_IMG
- en: YData Profiling Report. Screencast by author.
  prefs: []
  type: TYPE_NORMAL
- en: Yet, the most praised feature of `ydata-profiling` is perhaps the **automatic
    detection of potential data quality issues**.
  prefs: []
  type: TYPE_NORMAL
- en: This is exceptional when working with a new dataset for which we do not have
    any prior insights. It saves us a lot of time as it immediately highlights data
    inconsistencies and other complex data characteristics that we might want to analyze
    prior to model development.
  prefs: []
  type: TYPE_NORMAL
- en: 'In what concerns our use case, note how the following alerts are generated:'
  prefs: []
  type: TYPE_NORMAL
- en: '`CONSTANT`: for HBeAg and 02;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`HIGH CORRELATION`: between Total Bil and Dir Bil, and Encephalopathy and Total
    Bil;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`IMBALANCE`: for Encephalopathy;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MISSING`: for Hemoglobin, HBeAg, Total Bil, Dir Bil, and Ferritin with the
    highest missing data percentage (nearly 50%);'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`UNIFORM`, `UNIQUE`, and `HIGH CARDINALITY` regarding Hallmark.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With such a comprehensive support for data quality issues, `ydata-profiling`
    is able to detect all inconsistencies introduced, being especially informative
    as it generates several different alerts for the same feature.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, *how could Hallmark simultaneously raise high cardinality, unique,
    and uniform alerts?*
  prefs: []
  type: TYPE_NORMAL
- en: 'This immediately raises a red flag that would make a data scientist suspect
    of a possible association with an ID of some sort. When further inspecting the
    feature, this “data smell” would become rather obvious:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/63c37486a9e0167c7b053fd1163479ef.png)'
  prefs: []
  type: TYPE_IMG
- en: 'YData Profiling Report: Inspecting Hallmark. Image by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The same is true for HBeAg: it raises both `CONSTANT` and `MISSING` alerts,
    which could ring a bell in the mind of an experienced data scientist: more complex
    missing mechanisms can be at play.'
  prefs: []
  type: TYPE_NORMAL
- en: '`ydata-profiling` has several other useful features such as the **support for
    time-series data and the comparison of datasets side-by-side**, which we could
    use to enhance some data quality transformations on our dataset, such as missing
    data imputation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To further investigate this possibility, I’ve performed a simple imputation
    (e.g., mean imputation) on `Ferritin` and produced the comparison report between
    the original and imported data. Here’s the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2d0a2deb73ae6cf9d7e6c3ddab1bf752.png)'
  prefs: []
  type: TYPE_IMG
- en: 'YData Profiling: Comparison Report. Screencast by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: The source code, documentation, and several examples for `ydata-profiling` are
    available on this [GitHub repository](https://github.com/ydataai/ydata-profiling).
    You can replicate the example above using this [Google Colab notebook](https://colab.research.google.com/github/Data-Centric-AI-Community/awesome-data-centric-ai/blob/master/medium/data-profiling-tools/notebooks/ydata_profiling_demo.ipynb),
    and further investigate [additional features of the package here](https://medium.com/ydata-ai/auditing-data-quality-with-pandas-profiling-b1bf1919f856).
  prefs: []
  type: TYPE_NORMAL
- en: 2\. DataPrep
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[DataPrep](https://github.com/sfu-db/dataprep) also creates interactive data
    profiling reports with one line of code. The installation is rather simple, and
    after the modules are imported, the report generation is performed by calling
    the `create_report`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In terms of overall look and feel, `dataprep` seems to build extensively over
    the previous package, including similar summary statistics and visuals (the report
    similarities are uncanny!):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fa08f854e278c25982a33e8b2d687d4b.png)'
  prefs: []
  type: TYPE_IMG
- en: DataPrep Profiling Report. Screencast by Author.
  prefs: []
  type: TYPE_NORMAL
- en: However, a useful feature of this package is the **ability to explore feature
    interactions more deeply**.
  prefs: []
  type: TYPE_NORMAL
- en: We may explore insightful interactions between features (both numerical and
    categorical), using several types of plots.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how to explore the relationship between several types of features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/c43180db193cf11307c0bf13a4812907.png)'
  prefs: []
  type: TYPE_IMG
- en: 'DataPrep Profiling Report: Exploring Feature Interactions. Screencast by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: '`dataprep` also allows to investigate the impact of missing values (comparing
    the data before and after dropping missing values) across all features.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the visualization of the impact of dropping missing values on `Ferritin`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fc9ce10f7595d1908b684e53b1748545.png)'
  prefs: []
  type: TYPE_IMG
- en: 'DataPrep Profiling Report: Missing Impact of Ferritin. Screencast by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: You can explore all the generated visualizations in the respective [Colab notebook](https://colab.research.google.com/github/Data-Centric-AI-Community/awesome-data-centric-ai/blob/master/medium/data-profiling-tools/notebooks/dataprep_demo.ipynb)
    for you to explore. `dataprep` has a great documentation on [GitHub](https://github.com/sfu-db/dataprep)
    and also a [dedicated website](https://dataprep.ai), in case you’d like to check
    additional resources and details.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. SweetViz
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Similarly to the previous tools, [SweetViz](https://github.com/fbdesignpro/sweetviz)
    also boosts EDA by generating simple visualizations and summarizing important
    feature statistics. You may get started with `sweetviz` by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '`sweetviz` has a more “retro” look, and the summary statistics are not so neatly
    displayed as for the other packages we’ve reviewed so far.'
  prefs: []
  type: TYPE_NORMAL
- en: Regarding data quality, it alerts for the presence of missing values and their
    impact on the data (e.g., using green, yellow, and red highlighting, depending
    on the percentage of missing data). Other inconsistencies are not directly highlighted
    and may pass unnoticed (low correlation values are however signaled inside each
    feature’s details).
  prefs: []
  type: TYPE_NORMAL
- en: Beyond the “Associations” matrix, it does not focus on extensively exploring
    feature interactions or missing data behavior.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the look and feel of the report:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f9619c1e996ec2a4759624b7bd05e6e2.png)'
  prefs: []
  type: TYPE_IMG
- en: Sweetviz Profiling Report. Screencast by Author.
  prefs: []
  type: TYPE_NORMAL
- en: However, its greatest feature is that it is built around **visualizing target
    values** and **comparing datasets**.
  prefs: []
  type: TYPE_NORMAL
- en: In this regard, an interesting use case for `sweetviz` would be simultaneously
    performing *target analysis* (investigating how the target values relate to other
    features in the data) while comparing either *different sets* (e.g., training
    versus test sets) or *intra-set feature characteristics* (e.g., comparing sub-populations
    such as “Male” versus “Female” groups).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how to tweak the “Outcome” feature to enable the exploration of categories
    (“Male” and “Female”) and compare the insights:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/83e9b481e663c3dd7111755e779db73b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Sweetviz Profiling Report: Comparing “Male” and “Female” subgroups. Screencast
    by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: All of the documentation of `sweetviz` can be found in this [GitHub repository](https://github.com/fbdesignpro/sweetviz).
    Please feel free to [use this notebook](https://colab.research.google.com/github/Data-Centric-AI-Community/awesome-data-centric-ai/blob/master/medium/data-profiling-tools/notebooks/sweetviz_demo.ipynb)
    to perform further transformations on the data, and even explore other use cases
    with the help of [this dedicated post](/powerful-eda-exploratory-data-analysis-in-just-two-lines-of-code-using-sweetviz-6c943d32f34).
  prefs: []
  type: TYPE_NORMAL
- en: 4\. AutoViz
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[AutoViz](https://github.com/AutoViML/AutoViz) is another simple and straightforward
    EDA package that offers extensive support for visualizations and customization.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly to previous packages, it is as simple to install as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You can then import the package, but `autoviz` does not display plots automatically,
    so you need to run `%matplotlib inline` before trying it on your data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you are good to go! Running the following line will generate a plethora
    of visualizations that you can later customize and refine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/79c36a51ad02ef2db5b1b248c7a0830c.png)'
  prefs: []
  type: TYPE_IMG
- en: AutoViz Profiling Report. Screencast by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Interesting features of `autoviz` are the **automatic data cleaning recommendations**
    and the ability to **perform “supervised” visualizations** — i.e., categorizing
    the results by a given target feature, similarly to what we have done with `sweetviz`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data cleaning recommendations are given during the report generation, as
    shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6f4886c97ac4b13ac1190d9e6c66057e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'AutoViz Profiling Report: Cleaning Recommendatins. Image by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As far as cleaning recommendations go, `autoviz` does a really great job:'
  prefs: []
  type: TYPE_NORMAL
- en: It associates `Hallmark` with a “possible ID column”, suggesting that it should
    be dropped;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It identifies several missing or skewed features, such as `Ferritin`, `Hemoglobin`,
    `Total_Bil`, `Dir_Bil`, `Encephalopathy`, and `HBeAg`;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It recognizes that `HBeAg` and `O2` with invariant values, and suggests to drop
    `O2`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The generated alerts are not as comprehensive as those generated by `ydata-profiling`,
    and their are not as intuitive to spot (e.g., `autoviz` shows a heat map of the
    number of unique values, but other alerts such as `HIGH CARDINALITY`, `UNIQUE`,
    or `CONSTANT` could be more insightful to pin out specific details regarding the
    issues we’re facing.
  prefs: []
  type: TYPE_NORMAL
- en: Yet, I truly appreciated the explainability it introduces on its cleaning recommendations,
    which for a newcomer to the data science field would be surely a helpful guide.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you’d like to try out the “supervised” analysis I mentioned before, you
    first need to define a `depVar` parameter as the target feature. In this case
    I set it up to “Outcome”, but I could have set it to “Gender” to get similar plots
    to those returned by `sweetviz`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the generated report taking the “Outcome” into account:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/199444916c6af662e096964f5e922125.png)'
  prefs: []
  type: TYPE_IMG
- en: 'AutoViz Profiling Report: Comparing “Outcome” categories. Screencast by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: Play around with [this Google Colab notebook](https://colab.research.google.com/github/Data-Centric-AI-Community/awesome-data-centric-ai/blob/master/medium/data-profiling-tools/notebooks/autoviz_demo.ipynb)
    to explore additional features of `autoviz`. You can also take a look at [this
    post](/autoviz-a-new-tool-for-automated-visualization-ec9c1744a6ad), where they
    are beautifully detailed, or refer back to the [documentation on GitHub](https://github.com/AutoViML/AutoViz).
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Lux
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Lux](https://github.com/lux-org/lux) enables a fast and easy EDA in perhaps
    the most beginner-friendly way possible since it can be used by simply creating
    a Pandas DataFrame: once you install it, you just need to print out a DataFrame
    and it will automatically recommend a set of visualizations that best suits the
    discovery of interesting trends and patterns in your data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by installing the package and reading the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, you can browse through an interactive widget and choose the one that
    best fits your needs. Here’s how it looks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4b0f88df345d4846493e422668e6c094.png)'
  prefs: []
  type: TYPE_IMG
- en: Lux Profiling Report. Screencast by Author.
  prefs: []
  type: TYPE_NORMAL
- en: The package does not analyze any potential data quality issues and the analysis
    is not very comprehensive, but it still covers the basics.
  prefs: []
  type: TYPE_NORMAL
- en: 'The widget toggles between Pandas and Lux and focuses on 3 main visualizations:
    **Correlation and Distribution** for numeric features, and **Occurrence** for
    categorical features.'
  prefs: []
  type: TYPE_NORMAL
- en: A perhaps underrated feature, however, is the possibility to export or delete
    visualizations directly from the widget by selecting the desired plot. When producing
    a quick report this simplicity is actually really valuable.
  prefs: []
  type: TYPE_NORMAL
- en: '`lux` also tries to support us through the EDA process itself. Imagine that
    we’re interested in further exploring specific features, say, “PS” and “Encephalopathy”.
    We can specify your “intent” and `lux` will guide us towards potential next steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The newly generated recommendations are divided by **Enhance**, **Filter**,
    and **Generalize** tabs.
  prefs: []
  type: TYPE_NORMAL
- en: The **Enhance tab** adds an additional feature to the visualization regarding
    the “intent features”, essentially exploring what type of information additional
    dimensions could introduce.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Filter tab** is self-explanatory: it keeps intent features fixed and
    introduces filters such as `Gender = Male` or `Outcome = Alive` in the visualizations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the **Generalize tab** shows the intent features on their own to determine
    whether more general trends can be derived:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/314f0fc7660c7e95a53348f5ebaa6bf0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Lux Profiling Report: Exploring the “intent” functionality. Screencast by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to fidget around [my Colab notebook](https://colab.research.google.com/github/Data-Centric-AI-Community/awesome-data-centric-ai/blob/master/medium/data-profiling-tools/notebooks/lux_demo.ipynb)
    and play with examples of your own. Both the [documentation page of Lux](https://lux-api.readthedocs.io/en/latest/index.html)
    and the [GitHub repository](https://github.com/lux-org/lux) are quite comprehensive,
    but take a look at [this post](https://medium.com/analytics-vidhya/lets-discover-the-data-intelligently-using-lux-a40f1c63995d)
    to fill in any additional gaps.
  prefs: []
  type: TYPE_NORMAL
- en: 'Final Thoughts: Is there a best way to go?'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*In all fairness, no. The listed tools all share similarities as well as introduce
    different flavors.*'
  prefs: []
  type: TYPE_NORMAL
- en: With the exception of `lux`, which seems a bit limited, all of the remaining
    packages would serve us just fine for a basic exploratory data analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Now, depending on your level of expertise, your particular use case, or the
    goal you aim to achieve with your data, you might want to try out different packages,
    or even combine some of their functionalities.
  prefs: []
  type: TYPE_NORMAL
- en: 'All in all, here’s my take on it:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ydata-profiling` would be the best way to go for a professional data scientist
    hoping to get a handle of a new dataset, due to its**extensive support of automatic
    data quality alerts**. With the new support for Spark DataFrames, the package
    is also extremely useful for data engineers that need to troubleshoot their data
    flows, and for machine learning engineers to understand the reasons why their
    models are behaving erratically. **An excellent bet for experienced data professionals
    who need to understand the behavior of their data, especially in what concerns
    data quality.** The provided visualizations are also a good asset, but the package
    could improve in terms of interactivity (e.g., allowing us to “mouse over” plots
    and checking particular feature or correlation values).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dataprep` seems to build over `ydata-profiling`, which means that there could
    be a mismatch between both project’s roadmap (e.g., the latter having more functionalities
    “faster” than the former) especially in what concerns support data quality alerts.
    Or vice-versa, depending on which components we’re interested in following up
    with! However, **I did enjoy the additional features enabled for interactions,
    but I would say that in some cases “less is more’’.** If you’re an experienced
    data scientist, you’ll know what to look into more deeply and what to discard,
    but the same is not true when you’re entering the field. You can spend quite some
    time trying to understand why a certain plot is available if it is not insightful
    (e.g., Line Charts for Numeric - Categorical features, Box Plots for Numeric -
    Numeric features). Yet, **the individual plots for missing values (before and
    after dropping them) are genuinely useful**. I can see myself using them in the
    future **to diagnose some missing mechanisms**, especially Missing At Random,
    where the missing values in one feature are related to the observed values of
    another.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`autoviz` is a very **interesting tool for an entry-level data scientist**.
    It gives a well-round characterization of the data and reports truly useful cleaning
    recommendations. For an experienced professional they may not be necessary, but
    for someone starting out these could be fundamental to follow up on and guide
    the data preparation process. The **profiling report is also very comprehensive**,
    automatically listing all possible combinations between features. Although verbose,
    this is **helpful for someone without a lot of experience**, since the next step
    is simply skimming through the generated plots and see if something “stands out”.
    The code is not super friendly but still easy to grasp for a junior, and I particularly
    liked the “supervised” analysis: the **visuals are clean and beautiful** and I
    would definitely use them for my own research.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sweetviz` has a really insightful feature, although it could be better designed.
    Overall the report looks **quite retro** and the quality alerts are **not very
    intuitive** (e.g., why highlighting the lowest correlations rather then the highest?).
    Yet, **the idea of simultaneously checking up on target features and subgroups
    is something I’d love to see integrated in other packages!** For more complex
    datasets, we need to start analyzing more than 2, 3, or 4 dimensions of the data
    at once, and keeping track of the target value is extremely useful (in most cases,
    this is what we’re trying to map out, right?). I can tell you that this is the
    case for the HCC dataset: it is an heterogeneous disease where patients in similar
    stages can map onto different survival outcomes. I had to jump through hoops to
    get a quick and proper visualization of some sub-clusters back then, and this
    tool would have been instrumental to look for that type of insights and communicate
    them to the medical team taking care of the patients.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, `lux` could be used as a **learning tool, for a basic exploration
    of the data**, and to teach students or newcomers into the field the foundations
    of statistics and data-handling: types of features, types of plots, data distribution,
    positive and negative correlations, representation of missing values (e.g., `null`
    , `NaN`). **It is super low-code and the perfect tool to “test the waters”**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So there you have it, *it seems that there are no free lunches.* I sincerely
    hope that you’ve enjoyed this review! Feedback and suggestions are always appreciated:
    you can leave me a comment, [star and contribute to the repo](https://github.com/Data-Centric-AI-Community/awesome-data-centric-ai),
    or even contact me at the [Data-Centric AI Community](https://tiny.ydata.ai/dcai-medium)
    to discuss other data-related topics. See you soon, and happy science-ing!'
  prefs: []
  type: TYPE_NORMAL
- en: About me
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ph.D., Machine Learning Researcher, Educator, Data Advocate, and overall “jack-of-all-trades”.
    Here on Medium, I write about **Data-Centric AI and Data Quality**, educating
    the Data Science & Machine Learning communities on how to move from imperfect
    to intelligent data.
  prefs: []
  type: TYPE_NORMAL
- en: '[Data-Centric AI Community](https://tiny.ydata.ai/dcai-medium) | [GitHub](https://github.com/Data-Centric-AI-Community)
    | [Google Scholar](https://scholar.google.com/citations?user=isaI6u8AAAAJ&hl=en)
    | [LinkedIn](https://www.linkedin.com/in/miriamseoanesantos/)'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: M. Santos, P. Abreu, P. J. García-Laencina, A. Simão, A. Carvalho, [A new cluster-based
    oversampling method for improving survival prediction of hepatocellular carcinoma
    patients](https://www.sciencedirect.com/science/article/pii/S1532046415002063)
    (2015), *Journal of Biomedical Informatics 58*, 49–59.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
