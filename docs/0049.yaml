- en: First Steps in Machine Learning with Apache Spark
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Apache Spark 进行机器学习的第一步
- en: 原文：[https://towardsdatascience.com/first-steps-in-machine-learning-with-apache-spark-672fe31799a3?source=collection_archive---------8-----------------------#2023-01-04](https://towardsdatascience.com/first-steps-in-machine-learning-with-apache-spark-672fe31799a3?source=collection_archive---------8-----------------------#2023-01-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/first-steps-in-machine-learning-with-apache-spark-672fe31799a3?source=collection_archive---------8-----------------------#2023-01-04](https://towardsdatascience.com/first-steps-in-machine-learning-with-apache-spark-672fe31799a3?source=collection_archive---------8-----------------------#2023-01-04)
- en: Basic concepts and topics of Spark MLlib package
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Spark MLlib 包的基本概念和主题
- en: '[](https://joaopedro214.medium.com/?source=post_page-----672fe31799a3--------------------------------)[![João
    Pedro](../Images/64a0e14527be213e5fde0a02439fbfa7.png)](https://joaopedro214.medium.com/?source=post_page-----672fe31799a3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----672fe31799a3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----672fe31799a3--------------------------------)
    [João Pedro](https://joaopedro214.medium.com/?source=post_page-----672fe31799a3--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://joaopedro214.medium.com/?source=post_page-----672fe31799a3--------------------------------)[![João
    Pedro](../Images/64a0e14527be213e5fde0a02439fbfa7.png)](https://joaopedro214.medium.com/?source=post_page-----672fe31799a3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----672fe31799a3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----672fe31799a3--------------------------------)
    [João Pedro](https://joaopedro214.medium.com/?source=post_page-----672fe31799a3--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb111eee95c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffirst-steps-in-machine-learning-with-apache-spark-672fe31799a3&user=Jo%C3%A3o+Pedro&userId=b111eee95c&source=post_page-b111eee95c----672fe31799a3---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----672fe31799a3--------------------------------)
    ·11 min read·Jan 4, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F672fe31799a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffirst-steps-in-machine-learning-with-apache-spark-672fe31799a3&user=Jo%C3%A3o+Pedro&userId=b111eee95c&source=-----672fe31799a3---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb111eee95c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffirst-steps-in-machine-learning-with-apache-spark-672fe31799a3&user=Jo%C3%A3o+Pedro&userId=b111eee95c&source=post_page-b111eee95c----672fe31799a3---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----672fe31799a3--------------------------------)
    ·11 分钟阅读·2023年1月4日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F672fe31799a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffirst-steps-in-machine-learning-with-apache-spark-672fe31799a3&user=Jo%C3%A3o+Pedro&userId=b111eee95c&source=-----672fe31799a3---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F672fe31799a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffirst-steps-in-machine-learning-with-apache-spark-672fe31799a3&source=-----672fe31799a3---------------------bookmark_footer-----------)![](../Images/b6f9154e2eb16e7cf1f6b67fc5e34280.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F672fe31799a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffirst-steps-in-machine-learning-with-apache-spark-672fe31799a3&source=-----672fe31799a3---------------------bookmark_footer-----------)![](../Images/b6f9154e2eb16e7cf1f6b67fc5e34280.png)'
- en: Photo by [Element5 Digital](https://unsplash.com/es/@element5digital?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 照片来自 [Element5 Digital](https://unsplash.com/es/@element5digital?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: 'Apache Spark is one of the main tools for data processing and analysis in the
    BigData context. It’s a very complete (and complex) data processing framework,
    with functionalities that can be roughly divided into four groups: SparkSQL &
    DataFrames, the all-purpose data processing needs; Spark Structured Streaming,
    used to handle data-streams; Spark MLlib, for machine learning and data science
    and GraphX, the graph processing API.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark 是大数据背景下数据处理和分析的主要工具之一。它是一个非常完整（且复杂）的数据处理框架，其功能大致可以分为四组：SparkSQL
    & DataFrames，用于通用数据处理需求；Spark Structured Streaming，用于处理数据流；Spark MLlib，专注于机器学习和数据科学；GraphX，图形处理
    API。
- en: '![](../Images/114fdcdf4bf192579d828ab3f5628c35.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/114fdcdf4bf192579d828ab3f5628c35.png)'
- en: Spark libraries section on the official documentation. Print by Author.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 官方文档中的 Spark 库部分。打印由作者提供。
- en: 'I’ve already featured the first two in other posts: [creating an ETL process
    for a Data Warehouse](https://joaopedro214.medium.com/creating-a-simple-etl-pipeline-with-apache-spark-825cc17c8cf6)
    and [integrating Spark and Kafka for stream processing](/a-fast-look-at-spark-structured-streaming-kafka-f0ff64107325).
    Today is the time for the third one — Let’s play with Machine Learning using Spark
    MLlib.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经在其他文章中介绍了前两个：[创建一个数据仓库的 ETL 过程](https://joaopedro214.medium.com/creating-a-simple-etl-pipeline-with-apache-spark-825cc17c8cf6)
    和 [将 Spark 和 Kafka 集成进行流处理](/a-fast-look-at-spark-structured-streaming-kafka-f0ff64107325)。今天我们要讨论第三个——让我们使用
    Spark MLlib 进行机器学习。
- en: Machine Learning has a special place in my heart, because it was my entrance
    door to the data science field and, as probably many of yours, I started it with
    the classic [Scikit-Learn](https://scikit-learn.org/stable/) library.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习在我心中占有特殊的位置，因为它是我进入数据科学领域的入口门槛，并且像你们中的许多人一样，我是通过经典的 [Scikit-Learn](https://scikit-learn.org/stable/)
    库开始的。
- en: I’ve could write an entire post on why the Scikit-learn library is such a marvelous
    piece of software. It’s beginner-friendly, easy to use, covers most of the machine
    learning cycle, has very well-written documentation, and so on.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我本可以写一整篇文章来说明为什么 Scikit-learn 库是如此出色的软件。它对初学者友好，易于使用，涵盖了大部分机器学习周期，文档写得非常好，等等。
- en: But why am I talking about this? If you are like me, used to coding with sklearn,
    keep in mind that the path in Apache Spark is not SO straightforward. It’s not
    hard but has a steeper learning curve.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 但我为什么要谈论这个呢？如果你像我一样，习惯于使用 sklearn 编码，请记住 Apache Spark 的路径并不那么直接。虽然不难，但学习曲线更陡峭。
- en: Along this post, we’ll learn how to make the ‘full machine learning cycle’ of
    data preprocessing, feature engineering, model training, and validation with a
    Hands-On example.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将学习如何通过一个动手示例完成数据预处理、特征工程、模型训练和验证的“完整机器学习周期”。
- en: Apache Spark in a Nutshell
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache Spark 概述
- en: Apache Spark is a distributed memory-based data transformation engine. It is
    geared to operate in distributed environments to parallelize processing between
    machines, achieving high-performance transformations by using its lazy evaluation
    philosophy and query optimizations.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark 是一个基于分布式内存的数据转换引擎。它旨在在分布式环境中运行，通过在机器之间并行处理，利用其惰性计算哲学和查询优化来实现高性能转换。
- en: And that’s the main reason to learn such a tool — Performance.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是学习这种工具的主要原因——性能。
- en: Even with optimizations, the Sklearn package (and other python packages) struggle
    when the dataset gets too big. That’s one of the potential blind spots Spark covers.
    As it scales horizontally, it is easier to increase the computational power to
    train models on BigData.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 即使进行了优化，当数据集变得过大时，Sklearn 包（以及其他 Python 包）也会遇到困难。这是 Spark 能够覆盖的潜在盲点之一。由于 Spark
    具有横向扩展的能力，因此更容易增加计算能力来训练大数据上的模型。
- en: The problem
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: I’ve chosen the [Avocado Price Dataset](https://www.kaggle.com/datasets/neuromusic/avocado-prices)
    to make this project. Our task in this dataset is to predict the mean avocado
    price given the avocado type, date, the amount of avocado bags available and other
    features. See the [dataset page on Kaggle](https://www.kaggle.com/datasets/neuromusic/avocado-prices)
    for more information.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我选择了 [Avocado Price Dataset](https://www.kaggle.com/datasets/neuromusic/avocado-prices)
    来进行这个项目。我们在这个数据集中的任务是预测给定牛油果类型、日期、可用牛油果袋数及其他特征的平均牛油果价格。有关更多信息，请查看 [Kaggle 数据集页面](https://www.kaggle.com/datasets/neuromusic/avocado-prices)。
- en: Setting up the environment
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 环境设置
- en: All you need is docker and docker-compose installed. The code is available on
    [GitHub](https://github.com/jaumpedro214/spark-ml-first-steps/settings).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 你只需要安装 docker 和 docker-compose。代码可以在 [GitHub](https://github.com/jaumpedro214/spark-ml-first-steps/settings)
    上找到。
- en: The architecture described (in the *docker-compose.yaml*) is depicted in the
    image below.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 文章中描述的架构（在 *docker-compose.yaml* 文件中）如下面的图像所示。
- en: '![](../Images/0bc69dd0959c25391ac31ea5829a090b.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0bc69dd0959c25391ac31ea5829a090b.png)'
- en: Project’s architecture & Docker Containers. Image by Author.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 项目的架构与 Docker 容器。图片由作者提供。
- en: All the code was developed inside a [jupyter/pyspark-notebook](https://hub.docker.com/r/jupyter/pyspark-notebook)
    container with all the pyspark dependencies already configured.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 所有代码都在一个 [jupyter/pyspark-notebook](https://hub.docker.com/r/jupyter/pyspark-notebook)
    容器内开发，所有 pyspark 依赖项都已配置好。
- en: 'To start the environment, just run:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动环境，只需运行：
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The implementation
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现
- en: 'Our objective is to learn how to implement our usual ML pipeline using Spark,
    which covers: Loading data and splitting it into train/test, cleaning the data,
    preprocessing+feature engineering, model definition, hyperparameter-tuning and
    final scorings.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是学习如何使用 Spark 实现我们通常的机器学习流水线，涵盖内容包括：加载数据并将其分为训练集/测试集，清理数据，预处理+特征工程，模型定义，超参数调整和最终评分。
- en: The following sections will detail how to make each of these steps.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 以下章节将详细说明如何完成这些步骤。
- en: Connect to Spark
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接到 Spark
- en: The first thing to do is connect to the Spark cluster, which is quite straightforward.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 首先需要连接到 Spark 集群，这一步相当简单。
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: It may take a few seconds in the first run.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一次运行时可能需要几秒钟。
- en: Loading the data
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载数据
- en: Now it’s time to work with the data. This part still has nothing to do with
    Spark’s MLlib package, just the usual data loading using Spark SQL.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是处理数据的时候了。这部分与 Spark 的 MLlib 包无关，仅涉及使用 Spark SQL 加载数据。
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As Spark is [lazily evaluated](https://stackoverflow.com/questions/38027877/spark-transformation-why-is-it-lazy-and-what-is-the-advantage),
    it’s interesting to cache the dataset in memory to speed up the execution of the
    next steps.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Spark 是 [惰性计算](https://stackoverflow.com/questions/38027877/spark-transformation-why-is-it-lazy-and-what-is-the-advantage)
    的，缓存数据集在内存中可以加快后续步骤的执行。
- en: 'Let’s have a look at the data:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看一下数据：
- en: '![](../Images/41e5e436d69f75fd4547288f7fcc8daa.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/41e5e436d69f75fd4547288f7fcc8daa.png)'
- en: Again, more details about the columns can be found on the original dataset’s
    Kaggle page.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 关于列的更多细节可以在原始数据集的 Kaggle 页面上找到。
- en: Let’s move on and split the DataFrame into train (75%) and test (25%) set using
    the *randomSplit()* method.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用 *randomSplit()* 方法将 DataFrame 拆分为训练集（75%）和测试集（25%）。
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Preprocess data
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预处理数据
- en: 'Before continuing, let’s know the tools we’ll be using. The Spark MLlib package
    has two main types of objects: [Transformers and Estimators](https://spark.apache.org/docs/1.6.0/ml-guide.html).'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，让我们了解一下我们将使用的工具。Spark MLlib 包有两种主要类型的对象：[变换器和估算器](https://spark.apache.org/docs/1.6.0/ml-guide.html)。
- en: A **Transformer** is an object that’s able to transform Dataframes. They receive
    a raw DataFrame and return a processed one. Common transformers include PolynomialExpansion,
    SQLTransformer, and VectorAssembler (very important, discussed later).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**变换器** 是能够变换 DataFrame 的对象。它们接收原始 DataFrame 并返回处理后的 DataFrame。常见的变换器包括 PolynomialExpansion、SQLTransformer
    和 VectorAssembler（非常重要，后面会讨论）。'
- en: '**Estimators**, on the other hand, are objects that need to be fitted/trained
    on the data to generate a Transformer. These include machine learning predictors
    (Linear Regression, Logistic Regression, Decision Trees, etc), dimensionality
    reduction algorithms (PCA, ChiSquare Selector), and also other column transformers
    (StandardScaler, MinMaxScaler, TF-IDF, etc).'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**估算器**，另一方面，是需要在数据上进行拟合/训练以生成变换器的对象。这些包括机器学习预测器（线性回归、逻辑回归、决策树等）、降维算法（PCA、卡方选择器），以及其他列变换器（标准化器、最小最大缩放器、TF-IDF等）。'
- en: '![](../Images/66e637a5d0dae1f23fd8e1cd6aa7d0f8.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/66e637a5d0dae1f23fd8e1cd6aa7d0f8.png)'
- en: Transformers and Estimators on Spark MLlib. Image by Author.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Spark MLlib 上的变换器和估算器。作者提供的图片。
- en: Let’s start by using the **SQLTransformer** on our Data. This is a powerful
    transformer, that allows one to select and transform columns using SQL queries.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们先用 **SQLTransformer** 来处理数据。这是一个强大的变换器，允许使用 SQL 查询选择和变换列。
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The code above selects the *AveragePrice* and *type* columns, transforms the
    numerical columns using the Log function, and creates two new columns extracting
    the *year* (after 2000) and the *month*.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码选择了 *AveragePrice* 和 *type* 列，使用对数函数转换了数值列，并创建了两个新列，提取 *year*（2000 年后）和
    *month*。
- en: __THIS__ is the default name of the DataFrame currently being transformed.
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: __THIS__ 是当前正在变换的 DataFrame 的默认名称。
- en: 'The result:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/f64d500d4fa54ec5f666bde14553c2e8.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f64d500d4fa54ec5f666bde14553c2e8.png)'
- en: Scaling is a prevalent practice in data preprocessing. Let’s scale the **month**
    column using the Min-Max scaling technique, putting all values in the [0, 1] interval.
    The MinMaxScaler is of type **estimator** so it needs to be fitted to the data
    before being used to transform it.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放是在数据预处理中的一种常见做法。让我们使用最小-最大缩放技术缩放 **month** 列，将所有值放在 [0, 1] 区间内。MinMaxScaler
    是一种 **估算器**，因此需要先在数据上进行拟合，然后才能用来变换数据。
- en: Most of the estimators (including all the prediction models) require the input
    columns to be in Vector form. Vector is a special column type used mostly in Spark
    MLlib. It is just what the name suggests, a fixed-size array of numbers.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数估算器（包括所有预测模型）要求输入列为向量形式。向量是一种在Spark MLlib中主要使用的特殊列类型。它正如名字所示，是一个固定大小的数字数组。
- en: To join columns into a single Vector column, we use the VectorAssembler Transformer.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将列合并成一个单一的向量列，我们使用VectorAssembler Transformer。
- en: '![](../Images/10d7f1182d8aae534012fae3ebcf64a5.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/10d7f1182d8aae534012fae3ebcf64a5.png)'
- en: Vector Assembler in action. Image by Author.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Vector Assembler正在运行。图片来自作者。
- en: '[PRE5]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The image below details the process.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图片详细说明了这个过程。
- en: '![](../Images/947a6e4950f72e96ca89f39f97b78dda.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/947a6e4950f72e96ca89f39f97b78dda.png)'
- en: The process to apply the MinMaxScaler to a column. Image by Author.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 对列应用MinMaxScaler的过程。图片来自作者。
- en: 'The result:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/4266dc8f0f8d22a0be0135035e63f918.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4266dc8f0f8d22a0be0135035e63f918.png)'
- en: With these concepts in mind, is just a matter of knowing the available transformers
    and using them in our pipeline.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 牢记这些概念，只需了解可用的变换器并在我们的管道中使用它们。
- en: For example, the column **type** has two values, “*conventional”* and “*organic*”,
    that need to be mapped into numbers. The transformer responsible for this is the
    StringIndexer.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，列**type**有两个值，"*conventional*"和"*organic*"，需要映射成数字。负责此操作的变换器是StringIndexer。
- en: 'It assigns a numerical value to each category in a column. As the column “type”
    only has two categories, it will be transformed into a column with only two values:
    0 and 1, which is equivalent to applying the one-hot encoding technique.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 它将列中的每个类别分配一个数值。由于“type”列只有两个类别，它将被转换成一个只有两个值的列：0和1，这相当于应用了独热编码技术。
- en: '[PRE6]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/4023608a0496a7586241d873e67675f5.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4023608a0496a7586241d873e67675f5.png)'
- en: From now on I’ll summarize what was done.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在开始，我将总结所做的工作。
- en: The numerical features (all columns except the *type_index*) generated were
    assembled in a single Vector called “features_num”, this final vector passes by
    a StandardScaler.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的数值特征（所有列，除了*type_index*）被组装成一个名为“features_num”的单一向量，这个最终向量通过一个StandardScaler。
- en: '[PRE7]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/2f535578bd130098b42226615bc4641b.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2f535578bd130098b42226615bc4641b.png)'
- en: '[PRE8]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/0e457d208950ce3e100e5b51d4c2c76b.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0e457d208950ce3e100e5b51d4c2c76b.png)'
- en: The categorical column “type_index” is then added to the final vector.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将类别列“type_index”添加到最终向量中。
- en: The final step is to join all the transformers created into a **pipeline**.
    A pipeline is just an object used to encapsulate a set of transformers and estimators
    to apply them to data sequentially. This helps us to avoid dealing with each intermediate
    transformation step individually (as we’re doing so far).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是将创建的所有变换器合并成一个**管道**。管道只是一个用于封装一组变换器和估算器的对象，以便将它们顺序应用于数据。这有助于避免单独处理每个中间转换步骤（如我们至今所做的）。
- en: '[PRE9]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The final result:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 最终结果：
- en: '[PRE10]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Model training
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型训练
- en: That’s the moment we’re all waiting for.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们都在等待的时刻。
- en: After the long path of data preprocessing, all the features are already in their
    desired final vector form and we’re ready to train the model.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在经过漫长的数据预处理路径之后，所有特征已经以其所需的最终向量形式存在，我们准备好训练模型了。
- en: Unfortunately, this part will be very short compared with the previous one ¯\_(ツ)_/¯
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这部分将比前一部分短很多 ¯\_(ツ)_/¯
- en: 'As mentioned earlier, ML models are just estimators, so the process repeats:
    Instantiate, Fit and Transform.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，ML模型只是估算器，因此过程会重复：实例化、拟合和转换。
- en: 'Let’s train a Linear Regression model:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们训练一个线性回归模型：
- en: '[PRE11]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: It's necessary to specify the features column, the target/label column, and
    a name for the prediction column. Just like the other estimators we’ve met, an
    ML model will just add another column to the DataFrame.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 必须指定特征列、目标/标签列以及预测列的名称。就像我们遇到的其他估算器一样，ML模型只会向DataFrame中添加另一列。
- en: '![](../Images/321df60ec602669af3dbf906e9cd169f.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/321df60ec602669af3dbf906e9cd169f.png)'
- en: A Machine Learning model is just an estimator. Image by Author.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型只是一个估算器。图片来自作者。
- en: '[PRE12]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'See the result below:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 见下图结果：
- en: '[PRE13]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Model evaluation
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型评估
- en: To measure the model’s performance, we need an **evaluator**. I think its name
    is self-explanatory, it will compute a performance metric between the real labels
    and the model predictions.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 要评估模型的性能，我们需要一个**评估器**。我认为它的名字已经很直观了，它将计算真实标签与模型预测之间的性能指标。
- en: '![](../Images/31ce091d0a576d2f5998b40f939d0e27.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/31ce091d0a576d2f5998b40f939d0e27.png)'
- en: Evaluator in action. Image by Author.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 评估器在操作中。图像来源：作者。
- en: In the cell below, a RegressionEvaluator is instantiated to measure the RMSE
    (*Rooted Mean Squared Error*) between predictions and real values (on train data).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的单元格中，实例化一个RegressionEvaluator来测量预测值与实际值（在训练数据上）之间的RMSE（*均方根误差*）。
- en: '[PRE14]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Hyperparameter Tuning with Cross Validation
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用交叉验证进行超参数调优
- en: '[Hyperparameter Tuning](https://en.wikipedia.org/wiki/Hyperparameter_optimization)
    is one of the last stages in a Machine Learning Pipeline, so our adventure is
    coming to an end.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[超参数调优](https://en.wikipedia.org/wiki/Hyperparameter_optimization)是机器学习管道中的最后阶段之一，因此我们的冒险即将结束。'
- en: In this step, we test several variations of hyperparameters of our model/pipeline
    to pick the best one according to the chosen metric. A common way of doing this
    is using a [cross-validation technique](https://scikit-learn.org/stable/modules/cross_validation.html).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，我们测试模型/管道的多个超参数变体，以根据选择的指标挑选最佳的一个。常用的方法是使用[交叉验证技术](https://scikit-learn.org/stable/modules/cross_validation.html)。
- en: Here, we met the last building blocks of today’s post — The **ParamGridBuilder**
    and the **CrossValidator**.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们遇到了今天文章中的最后构建块——**ParamGridBuilder**和**CrossValidator**。
- en: 'Starting with the ParamGridBuilder: It is the object used to build a hyperparameter
    grid.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 从ParamGridBuilder开始：这是用来构建超参数网格的对象。
- en: '[PRE15]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: In the code above, several values are specified for the linear regression’s
    *regParam* and *elasticNetParam.* It’s important to note that the original object
    is used to reference the parameters.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的代码中，为线性回归的*regParam*和*elasticNetParam*指定了几个值。重要的是要注意，原始对象用于引用这些参数。
- en: The **CrossValidator** then joins everything together (estimator, hyperparameter
    grid, and evaluator) …
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，**CrossValidator**将所有内容（估计器、超参数网格和评估器）结合起来……
- en: '[PRE16]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: … and performs a cross-validation for the given number of folds when the method
    *fit*() is called with training data.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: … 并在调用方法*fit*()时，对给定数量的折数进行交叉验证。
- en: '[PRE17]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The results are accessed through the fitted Cross Validation object. The code
    below prints the best model’s name and score.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 结果通过拟合的交叉验证对象来访问。下面的代码打印出最佳模型的名称和得分。
- en: '[PRE18]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Let’s also see the linear regression’s best parameters.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们还查看一下线性回归的最佳参数。
- en: '[PRE19]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Output:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE20]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Evaluate the best model on the test set
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在测试集上评估最佳模型
- en: And all come to this moment. This is the step where we measure the performance
    of the best model on test data.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的一切都汇聚到这一刻。这是我们在测试数据上衡量最佳模型性能的步骤。
- en: Fortunately, there is nothing new to learn here, it’s just a matter of applying
    the best model to the test data and passing the result to the evaluator.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，这里没有新的内容需要学习，这只是将最佳模型应用于测试数据，并将结果传递给评估器的问题。
- en: '[PRE21]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The performance was very similar to the one obtained in the cross-validation
    step.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 性能与交叉验证步骤中获得的性能非常相似。
- en: Conclusion
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: As ML applications become popular and their requirements become more complex,
    knowledge of a wider variety of tools with different purposes becomes essential.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 随着ML应用的普及和其要求的复杂化，掌握各种用途不同的工具知识变得至关重要。
- en: In this post, we learned a little about how Apache Spark can be used in the
    context of Machine Learning through the Spark MLlib module. With a hands-on project,
    we created a generic ML pipeline, covering the main concepts and basic topics
    of this module.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们了解了如何通过Spark MLlib模块在机器学习的背景下使用Apache Spark。通过一个实际项目，我们创建了一个通用的ML管道，涵盖了该模块的主要概念和基本主题。
- en: 'Learning a new tool mainly involves becoming familiar with its vocabulary,
    *i.e.,* understanding the fundamental parts that compose it and how they can be
    used to solve a problem. Therefore, we focused on understanding the basics of
    Spark MLlib: Estimators, Transformers, Evaluators, and Pipelines.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 学习一种新工具主要涉及熟悉其词汇，*即*，理解组成它的基本部分以及如何利用它们来解决问题。因此，我们专注于理解Spark MLlib的基础知识：估计器、转换器、评估器和管道。
- en: I hope this brief post helped you understand how Spark can be used in Machine
    Learning applications.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这篇简短的文章能帮助你理解Spark如何在机器学习应用中使用。
- en: As always, this post just scratches the surface of the topics explored, so I
    strongly encourage further reading, see the references below.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，这篇文章只是略微触及了所探讨主题的表面，因此我强烈建议进一步阅读，见下文的参考文献。
- en: Thank you for reading ;)
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读 ;)
- en: References
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: All the code is available in this [GitHub repository](https://github.com/jaumpedro214/spark-ml-first-steps).
  id: totrans-136
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 所有代码都可以在这个[GitHub 仓库](https://github.com/jaumpedro214/spark-ml-first-steps)中找到。
- en: 'Data used — [Avocado Prices](https://www.kaggle.com/datasets/neuromusic/avocado-prices)*,*
    [*ODbL v1.0: Open database*](https://opendatacommons.org/licenses/odbl/1-0/)*,
    Kaggle.*'
  id: totrans-137
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用的数据 — [鳄梨价格](https://www.kaggle.com/datasets/neuromusic/avocado-prices)*,*
    [*ODbL v1.0：开放数据库*](https://opendatacommons.org/licenses/odbl/1-0/)*, Kaggle.*
- en: '[1] Chambers, B., & Zaharia, M. (2018). *Spark: The definitive guide: Big data
    processing made simple*. “ O’Reilly Media, Inc.”'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Chambers, B., & Zaharia, M. (2018). *Spark: 终极指南：简化的大数据处理*。“ O’Reilly Media,
    Inc.”'
- en: '[2] Spark by examples — [https://sparkbyexamples.com/](https://sparkbyexamples.com/)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Spark 示例 — [https://sparkbyexamples.com/](https://sparkbyexamples.com/)'
- en: '[3] Géron, A. (2022). *Hands-on machine learning with Scikit-Learn, Keras,
    and TensorFlow*. “ O’Reilly Media, Inc.”.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Géron, A. (2022). *动手实践机器学习：使用 Scikit-Learn、Keras 和 TensorFlow*。“ O’Reilly
    Media, Inc.”.'
- en: '[4] Overview: estimators, transformers and pipelines — spark.ml. [Spark Official
    documentation](https://spark.apache.org/docs/1.6.0/ml-guide.html).'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] 概述：估算器、转换器和管道 — spark.ml。[Spark 官方文档](https://spark.apache.org/docs/1.6.0/ml-guide.html).'
