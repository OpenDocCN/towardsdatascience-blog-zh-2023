- en: A simple introduction to Quantum enhanced SVM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/a-simple-introduction-to-quantum-enhanced-svm-bee893a4377c?source=collection_archive---------3-----------------------#2023-10-03](https://towardsdatascience.com/a-simple-introduction-to-quantum-enhanced-svm-bee893a4377c?source=collection_archive---------3-----------------------#2023-10-03)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How to combine interesting quantum computing properties with a classic Machine
    Learning technique
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://matheuscammarosanohidalgo.medium.com/?source=post_page-----bee893a4377c--------------------------------)[![Matheus
    Cammarosano Hidalgo](../Images/deebcedad4aebcc32caf0267e32995d3.png)](https://matheuscammarosanohidalgo.medium.com/?source=post_page-----bee893a4377c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bee893a4377c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bee893a4377c--------------------------------)
    [Matheus Cammarosano Hidalgo](https://matheuscammarosanohidalgo.medium.com/?source=post_page-----bee893a4377c--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2d8a0d1399be&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-simple-introduction-to-quantum-enhanced-svm-bee893a4377c&user=Matheus+Cammarosano+Hidalgo&userId=2d8a0d1399be&source=post_page-2d8a0d1399be----bee893a4377c---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bee893a4377c--------------------------------)
    ·7 min read·Oct 3, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbee893a4377c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-simple-introduction-to-quantum-enhanced-svm-bee893a4377c&user=Matheus+Cammarosano+Hidalgo&userId=2d8a0d1399be&source=-----bee893a4377c---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbee893a4377c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-simple-introduction-to-quantum-enhanced-svm-bee893a4377c&source=-----bee893a4377c---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although quantum computers are not yet accessible for everyone, Quantum Machine
    Learning (QML) is a promising field of study as it uses the intrinsic probabilistic
    nature of quantum systems to develop models. Right now, data scientists around
    the world are trying to understand how to leverage the quantum paradigm to produce
    better, scalable models. It is not possible to quantify when this will happen
    because it also depends on the evolution of quantum hardware, but there is accelerated
    growth in this matter.
  prefs: []
  type: TYPE_NORMAL
- en: In my last studies I was trying to design Variational Quantum Classifiers (VQCs),
    as you could see in a [previous post](https://medium.com/@matheuscammarosanohidalgo/a-very-simple-variational-quantum-classifier-vqc-64e8ec26589d)
    I wrote. This is an interesting case of study if you are starting to study QML
    like me.
  prefs: []
  type: TYPE_NORMAL
- en: However, lately I also started to study a quantum approach to the Support Vector
    Machine (SVM) and I was intrigued by how SVM could be translated into the quantum
    world.
  prefs: []
  type: TYPE_NORMAL
- en: As I was studying VQCs, I was very biased and I was trying to guess how the
    SVM could be translated into a parameterizable quantum circuit, but I found that
    the quantum enhancement here works differently, which was a nice surprise and
    helped me to open my mind about this subject.
  prefs: []
  type: TYPE_NORMAL
- en: In this post I start with a brief introduction of SVM followed by how to do
    a Quantum Machine Learning (QML) approach to this technique and I finish with
    an example of quantum enhanced SVM (QSVM) using the Titanic dataset.
  prefs: []
  type: TYPE_NORMAL
- en: SVM and kernels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I present here the SVM focused on classification problems, that is, the Support
    Vector Classifier (SVC). The objective of SVC is to find a hyperplane that separates
    data from different classes with the best possible margin. This doesn’t seem very
    helpful at first, right?
  prefs: []
  type: TYPE_NORMAL
- en: But what is this hyperplane that separates the classes? Suppose we are working
    with data in a two-dimensional vector space and we have two classes, as in Figure
    1.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0c1583f188b881277c2cda5012cc966f.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1— 2D data with a very clear linear separator — Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: In this example we have data points from 2 different classes and we can easily
    draw a line separating both. Our solid line is the hyperplane that separates our
    data with the best possible margin, as seen by the dashed lines. Thus, SVM tries
    to find the best separator.
  prefs: []
  type: TYPE_NORMAL
- en: You may think that my example was too naive and a line is a very particular
    case of a hyperplane, which is a valid point. What if our two-dimensional data
    looks like Figure 2?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/74db098f58e4ffce84c700f3dd6c73c3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2— 2D data with nonlinear separator — Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: In this case we can’t draw a line that separates our data correctly. If we look
    at this figure, we could draw a circle as a good separator. However, this shape
    is neither a line nor a plane, so SVM isn’t able to directly solve this problem.
    However, this is the coolest SVM trick and the part where a high dimensional hyperplane
    occurs!
  prefs: []
  type: TYPE_NORMAL
- en: 'What if we have the transformation of this data into a higher dimension vector
    space? As:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1d8d23b77aea4288c4da687f87b0e3f7.png)'
  prefs: []
  type: TYPE_IMG
- en: (equation image by the author)
  prefs: []
  type: TYPE_NORMAL
- en: 'So we would could draw a plane:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/361498fbdb8df34b8ebcf3ad30086673.png)'
  prefs: []
  type: TYPE_IMG
- en: (equation image by the author)
  prefs: []
  type: TYPE_NORMAL
- en: 'Which separates the two classes optimally, as seen in Figure 3:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/673c309a3e287d8215c1a34815668176.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3— Plane that separates our data in a higher dimensional space — Image
    by the author
  prefs: []
  type: TYPE_NORMAL
- en: In our case, the function f is what we call the kernel, which projects data
    into a higher dimensional space, which makes it easier to find a hyperplane that
    can correctly identify data from different classes.
  prefs: []
  type: TYPE_NORMAL
- en: This was a very brief introduction about kernels and SVM, if you are interested
    in more explanation about SVM I recommend you to read these two posts ([1](/svm-and-kernel-svm-fed02bef1200)
    and [2](/https-medium-com-pupalerushikesh-svm-f4b42800e989)), which are really
    good introductions to SVM and I used both of them as references in this post.
  prefs: []
  type: TYPE_NORMAL
- en: You might be thinking now that my example was very convenient to explain the
    kernel concept, but how in real life do we find a suitable kernel that solves
    our problems? There are some kernels that are very flexible and are very helpful
    to solve a good number of problems, like the Radial Basis Function (RBF), which
    is the default option of scikit-learn’s SVC. If you are interested in learning
    more about this kernel, I recommend [this post](/radial-basis-function-rbf-kernel-the-go-to-kernel-acf0d22c798a).
    An important detail about kernels such as the RBF is that they aren’t described
    by an analytic function, but as a similarity matrix between data points based
    on the kernel.
  prefs: []
  type: TYPE_NORMAL
- en: However, what if we want to be more creative? If you have read [my previous
    posts](https://medium.com/@matheuscammarosanohidalgo/why-you-should-start-studying-quantum-machine-learning-418bb5e0ad14)
    you might remember that one of the most interesting properties of quantum computing
    is the exponential relation between qubits and quantum states. Thus, a quantum
    system is a very interesting candidate for a good kernel, as it tends to drive
    our system towards a high-dimensional vector space, depending on the quantity
    of qubits we are using.
  prefs: []
  type: TYPE_NORMAL
- en: Quantum Kernels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Quantum kernels are usually defined by an similarity matrix based on a quantum
    circuit, that might be parameterizable or not. Both Pennylane and Qiskit have
    built-in functions that create kernels that can be used in scikit-learn’s SVC.
  prefs: []
  type: TYPE_NORMAL
- en: 'The project of a quantum kernel has some steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Embedding data into quantum states**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/64d5aab9d11fecbe808010ad2d6a340a.png)'
  prefs: []
  type: TYPE_IMG
- en: (equation image by the author)
  prefs: []
  type: TYPE_NORMAL
- en: '**Designing a quantum circuit that might be parameterizable or not**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8f9fc16207ab169067c6d0741caf0784.png)'
  prefs: []
  type: TYPE_IMG
- en: (equation image by the author)
  prefs: []
  type: TYPE_NORMAL
- en: At this stage, it is highly recommended to work with some degree of superposition
    and entanglement between states to obtain the best that quantum computing can
    provide.
  prefs: []
  type: TYPE_NORMAL
- en: '**Building the similarity matrix**'
  prefs: []
  type: TYPE_NORMAL
- en: Here we work with the unitary U(|x>) that we built in the last step and its
    adjoint to design a similarity matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here we are designing a simple quantum kernel with Pennylane to use it with
    an SVC from scikit-learn for the Titanic Classification dataset, where we want
    to predict whether a person survived the Titanic tragedy based on variables such
    as age, gender and boarding class.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example we are using the following variables:'
  prefs: []
  type: TYPE_NORMAL
- en: 'is_child: if the age of the person is less than 12 (boolean)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pclass_1: if the person boarded in the first class (boolean)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pclass_2: if the person boarded in the second class (boolean)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sex_female: if the gender of the person is female (boolean)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, this is a very simple model with four boolean variables. We
    are embedding our data into quantum states using quantum embedding (Basis Embedding),
    applying Hadamard gates to apply superposition into our qubits and CNOT gates
    to generate entanglement.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3a5351f7bf675f43e299c91a8f315909.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4— Ansatz for our kernel example — Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: This is a simple and non-parameterizable ansatz, but it generates superposition
    and entanglement between our variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code to create the kernel and SVM is here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/83b524f7e6c801b997582836293b4de8.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5— Print of tests results — Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the SVC with the RBF kernel outperformed our SVC with quantum
    kernel. Our quantum approach had good precision, which means that we managed to
    avoid false positives at a good rate, but our recall wasn’t so good, implying
    that we got a significant number of false negatives.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to read more about SVMs with quantum kernel, these posts are good
    references: [1](https://medium.com/mit-6-s089-intro-to-quantum-computing/quantum-support-vector-machine-qsvm-134eff6c9d3b),
    [2](https://medium.com/@patrick.huembeli/introduction-into-quantum-support-vector-machines-727f3ccfa2b4)
    and these texts from Pennylane about the subject: [3](https://pennylane.ai/qml/demos/tutorial_kernel_based_training)
    and [4](https://pennylane.ai/qml/demos/tutorial_kernels_module).'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Quantum kernels can be a powerful tool to increase SVM performance. However,
    as we could see in our example, a SVM with a simple quantum kernel isn’t able
    to outperform SVM with an RBF kernel. Quantum kernels require careful design in
    order to be competitive with classical techniques.
  prefs: []
  type: TYPE_NORMAL
- en: I have been deepening my studies to design parameterizable quantum kernels and
    I hope to have good news on this subject soon.
  prefs: []
  type: TYPE_NORMAL
