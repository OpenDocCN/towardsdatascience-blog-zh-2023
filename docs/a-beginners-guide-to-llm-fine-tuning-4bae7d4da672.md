# LLM å¾®è°ƒçš„åˆå­¦è€…æŒ‡å—

> åŸæ–‡ï¼š[`towardsdatascience.com/a-beginners-guide-to-llm-fine-tuning-4bae7d4da672`](https://towardsdatascience.com/a-beginners-guide-to-llm-fine-tuning-4bae7d4da672)

## å¦‚ä½•ä½¿ç”¨ä¸€ä¸ªå·¥å…·å¾®è°ƒ Llama åŠå…¶ä»– LLM

[](https://medium.com/@mlabonne?source=post_page-----4bae7d4da672--------------------------------)![Maxime Labonne](https://medium.com/@mlabonne?source=post_page-----4bae7d4da672--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4bae7d4da672--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----4bae7d4da672--------------------------------) [Maxime Labonne](https://medium.com/@mlabonne?source=post_page-----4bae7d4da672--------------------------------)

Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page-----4bae7d4da672--------------------------------) Â·8 åˆ†é’Ÿé˜…è¯»Â·2023 å¹´ 8 æœˆ 30 æ—¥

--

![](img/3cd56f68c14e07ab9ae3eb624bd064ed.png)

å›¾ç‰‡ç”±ä½œè€…æä¾›

å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ—¥ç›Šå…³æ³¨å¯¼è‡´äº†**æ—¨åœ¨ç®€åŒ–å…¶è®­ç»ƒè¿‡ç¨‹çš„å·¥å…·å’Œå°è£…çš„æ¿€å¢**ã€‚

æµè¡Œçš„é€‰é¡¹åŒ…æ‹¬ LMSYS çš„[FastChat](https://github.com/lm-sys/FastChat)ï¼ˆç”¨äºè®­ç»ƒ[Vicuna](https://huggingface.co/lmsys/vicuna-13b-v1.5)ï¼‰å’Œ Hugging Face çš„[transformers](https://github.com/huggingface/transformers)/[trl](https://github.com/huggingface/trl)åº“ï¼ˆç”¨äºæˆ‘ä¹‹å‰çš„æ–‡ç« ï¼‰ã€‚æ­¤å¤–ï¼Œæ¯ä¸ªå¤§å‹ LLM é¡¹ç›®ï¼Œå¦‚[WizardLM](https://github.com/nlpxucan/WizardLM/tree/main)ï¼Œé€šå¸¸éƒ½æœ‰è‡ªå·±ç‹¬ç‰¹çš„è®­ç»ƒè„šæœ¬ï¼Œçµæ„Ÿæ¥è‡ªäºæœ€åˆçš„[Alpaca](https://github.com/tatsu-lab/stanford_alpaca)å®ç°ã€‚

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç”± OpenAccess AI Collective åˆ›å»ºçš„[**Axolotl**](https://github.com/OpenAccess-AI-Collective/axolotl)å·¥å…·ã€‚æˆ‘ä»¬å°†ä½¿ç”¨å®ƒåœ¨ä¸€ä¸ªåŒ…å« 1,000 ä¸ª Python ä»£ç æ ·æœ¬çš„ evol-instruct æ•°æ®é›†ä¸Šå¾®è°ƒä¸€ä¸ª[**Code Llama 7b**](https://github.com/OpenAccess-AI-Collective/axolotl/blob/main/examples/llama-2/qlora.yml)æ¨¡å‹ã€‚

# ğŸ¤” ä¸ºä»€ä¹ˆé€‰æ‹© Axolotlï¼Ÿ

Axolotl çš„ä¸»è¦å¸å¼•åŠ›åœ¨äºå®ƒæä¾›äº†ä¸€ç«™å¼è§£å†³æ–¹æ¡ˆï¼Œå…¶ä¸­åŒ…æ‹¬ä¼—å¤šåŠŸèƒ½ã€æ¨¡å‹æ¶æ„å’Œä¸€ä¸ªæ´»è·ƒçš„ç¤¾åŒºã€‚ä»¥ä¸‹æ˜¯æˆ‘æœ€å–œæ¬¢çš„å‡ ç‚¹ï¼š

+   **é…ç½®**ï¼šç”¨äºè®­ç»ƒ LLM çš„æ‰€æœ‰å‚æ•°éƒ½æ•´é½åœ°å­˜å‚¨åœ¨ yaml é…ç½®æ–‡ä»¶ä¸­ã€‚è¿™ä½¿å¾—æ¨¡å‹çš„å…±äº«å’Œå†ç°å˜å¾—æ–¹ä¾¿ã€‚ä½ å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/OpenAccess-AI-Collective/axolotl/tree/main/examples/llama-2)æŸ¥çœ‹ Llama 2 çš„ç¤ºä¾‹ã€‚

+   **æ•°æ®é›†çµæ´»æ€§**ï¼šAxolotl å…è®¸æŒ‡å®šå¤šä¸ªæ•°æ®é›†ï¼Œæ”¯æŒå„ç§æç¤ºæ ¼å¼ï¼Œå¦‚ alpacaï¼ˆ`{"instruction": "...", "input": "...", "output": "..."}`ï¼‰ï¼Œsharegpt:chatï¼ˆ`{"conversations": [{"from": "...", "value": "..."}]}`ï¼‰å’ŒåŸå§‹å®Œæˆï¼ˆ`{"text": "..."}`ï¼‰ã€‚ç»„åˆæ•°æ®é›†éå¸¸é¡ºç•…ï¼Œå¹¶ä¸”é¿å…äº†ç»Ÿä¸€æç¤ºæ ¼å¼çš„éº»çƒ¦ã€‚

+   **åŠŸèƒ½**ï¼šAxolotl é…å¤‡äº† SOTA æŠ€æœ¯ï¼Œå¦‚ FSDPã€deepspeedã€LoRAã€QLoRAã€ReLoRAã€æ ·æœ¬æ‰“åŒ…ã€GPTQã€FlashAttentionã€xformers å’Œ rope scalingã€‚

+   **å·¥å…·**ï¼šé›†æˆäº†ä¼—å¤šç”¨æˆ·å‹å¥½çš„å·¥å…·ï¼ŒåŒ…æ‹¬æ·»åŠ æˆ–æ›´æ”¹ç‰¹æ®Š tokenï¼Œæˆ–è‡ªå®šä¹‰ wandb é…ç½®ã€‚

ä¸€äº›ä½¿ç”¨æ­¤å·¥å…·è®­ç»ƒçš„çŸ¥åæ¨¡å‹åŒ…æ‹¬ OpenAccess AI Collective çš„[Manticore-13b](https://huggingface.co/openaccess-ai-collective/manticore-13b)å’Œ Eric Hartford çš„[Samantha-1.11â€“70b](https://huggingface.co/ehartford/Samantha-1.11-70b)ã€‚åƒå…¶ä»–åŒ…è£…å™¨ä¸€æ ·ï¼Œå®ƒå»ºç«‹åœ¨ transformers åº“ä¹‹ä¸Šï¼Œå¹¶ä½¿ç”¨äº†è®¸å¤šå…¶åŠŸèƒ½ã€‚

# âš™ï¸ åˆ›å»ºä½ è‡ªå·±çš„é…ç½®æ–‡ä»¶

åœ¨å¼€å§‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªé…ç½®æ–‡ä»¶ã€‚ä½ å¯ä»¥é‡ç”¨`[examples](https://github.com/OpenAccess-AI-Collective/axolotl/tree/main/examples)`æ–‡ä»¶å¤¹ä¸­çš„ç°æœ‰é…ç½®ã€‚æˆ‘ä»¬å°†è°ƒæ•´[QLoRA é…ç½®](https://github.com/OpenAccess-AI-Collective/axolotl/blob/main/examples/llama-2/qlora.yml)ä»¥åˆ›å»ºæˆ‘ä»¬è‡ªå·±çš„**Code Llama**æ¨¡å‹ã€‚è¯¥æ¨¡å‹å°†åœ¨`[nickrosh/Evol-Instruct-Code-80k-v1](https://huggingface.co/datasets/nickrosh/Evol-Instruct-Code-80k-v1)`æ•°æ®é›†ä¸­çš„ 1,000 ä¸ª Python æ ·æœ¬å­é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬å¿…é¡»å°†`base_model`å’Œ`base_model_config`å­—æ®µæ›´æ”¹ä¸º"codellama/CodeLlama-7b-hf"ã€‚ä¸ºäº†å°†æˆ‘ä»¬è®­ç»ƒçš„é€‚é…å™¨æ¨é€åˆ° Hugging Face Hubï¼Œæˆ‘ä»¬éœ€è¦æ·»åŠ ä¸€ä¸ªæ–°çš„å­—æ®µ`hub_model_id`ï¼Œå¯¹åº”æˆ‘ä»¬çš„æ¨¡å‹åç§°"EvolCodeLlama-7b"ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å¿…é¡»å°†æ•°æ®é›†æ›´æ–°ä¸º`[mlabonne/Evol-Instruct-Python-1k](https://huggingface.co/datasets/mlabonne/Evol-Instruct-Python-1k)`å¹¶å°†`type`è®¾ç½®ä¸º"alpaca"ã€‚

æ•°æ®é›†ä¸­æ²¡æœ‰å¤§äº 2048 ä¸ª token çš„æ ·æœ¬ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥å°†`sequence_len`å‡å°‘åˆ°"2048"ä»¥èŠ‚çœä¸€äº› VRAMã€‚è¯´åˆ° VRAMï¼Œæˆ‘ä»¬å°†ä½¿ç”¨`micro_batch_size`ä¸º 10 å’Œ`gradient_accumulation_steps`ä¸º 1ï¼Œä»¥æœ€å¤§åŒ–å…¶ä½¿ç”¨ã€‚åœ¨å®é™…æ“ä½œä¸­ï¼Œä½ å¯ä»¥å°è¯•ä¸åŒçš„å€¼ï¼Œç›´åˆ°ä½¿ç”¨è¶…è¿‡ 95%çš„å¯ç”¨ VRAMã€‚

ä¸ºäº†æ–¹ä¾¿ï¼Œæˆ‘å°†"axolotl"æ·»åŠ åˆ°`wandb_project`å­—æ®µä¸­ï¼Œä»¥ä¾¿åœ¨æˆ‘çš„è´¦æˆ·ä¸Šæ›´å®¹æ˜“è¿½è¸ªã€‚æˆ‘è¿˜å°†`warmup_steps`è®¾ç½®ä¸º"100"ï¼ˆä¸ªäººåå¥½ï¼‰ï¼Œå°†`eval_steps`è®¾ç½®ä¸º 0.01ï¼Œä»¥ä¾¿è¿›è¡Œ 100 æ¬¡è¯„ä¼°ã€‚

æœ€ç»ˆçš„é…ç½®æ–‡ä»¶åº”è¯¥æ˜¯è¿™æ ·çš„ï¼š

```py
base_model: codellama/CodeLlama-7b-hf
base_model_config: codellama/CodeLlama-7b-hf
model_type: LlamaForCausalLM
tokenizer_type: LlamaTokenizer
is_llama_derived_model: true
hub_model_id: EvolCodeLlama-7b

load_in_8bit: false
load_in_4bit: true
strict: false

datasets:
  - path: mlabonne/Evol-Instruct-Python-1k
    type: alpaca
dataset_prepared_path: last_run_prepared
val_set_size: 0.02
output_dir: ./qlora-out

adapter: qlora
lora_model_dir:

sequence_len: 2048
sample_packing: true

lora_r: 32
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules:
lora_target_linear: true
lora_fan_in_fan_out:

wandb_project: axolotl
wandb_entity:
wandb_watch:
wandb_run_id:
wandb_log_model:

gradient_accumulation_steps: 1
micro_batch_size: 10
num_epochs: 3
optimizer: paged_adamw_32bit
lr_scheduler: cosine
learning_rate: 0.0002

train_on_inputs: false
group_by_length: false
bf16: true
fp16: false
tf32: false

gradient_checkpointing: true
early_stopping_patience:
resume_from_checkpoint:
local_rank:
logging_steps: 1
xformers_attention:
flash_attention: true

warmup_steps: 100
eval_steps: 0.01
save_strategy: epoch
save_steps:
debug:
deepspeed:
weight_decay: 0.0
fsdp:
fsdp_config:
special_tokens:
  bos_token: "<s>"
  eos_token: "</s>"
  unk_token: "<unk>"
```

ä½ ä¹Ÿå¯ä»¥åœ¨[è¿™é‡Œ](https://gist.github.com/mlabonne/8055f6335e2b85f082c8c75561321a66)æ‰¾åˆ°è¿™ä¸ªé…ç½®æ–‡ä»¶ï¼Œä½œä¸ºä¸€ä¸ª GitHub gistã€‚

åœ¨å¼€å§‹è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œæˆ‘æƒ³ä»‹ç»å‡ ä¸ªé‡è¦çš„å‚æ•°ï¼š

+   **QLoRA**ï¼šæˆ‘ä»¬ä½¿ç”¨ QLoRA è¿›è¡Œå¾®è°ƒï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬ä»¥ 4 ä½ç²¾åº¦ï¼ˆNF4 æ ¼å¼ï¼‰åŠ è½½åŸºç¡€æ¨¡å‹ã€‚ä½ å¯ä»¥æŸ¥çœ‹[è¿™ç¯‡æ–‡ç« ](https://medium.com/towards-data-science/qlora-fine-tune-a-large-language-model-on-your-gpu-27bed5a03e2b)æ¥äº†è§£æ›´å¤šå…³äº QLoRA çš„å†…å®¹ï¼Œä½œè€…æ˜¯[æœ¬æ°æ˜Â·ç›ä¸½](https://medium.com/u/ad2a414578b3?source=post_page-----4bae7d4da672--------------------------------)ã€‚

+   **æ¢¯åº¦æ£€æŸ¥ç‚¹**ï¼šé€šè¿‡åˆ é™¤åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­æŒ‰éœ€é‡æ–°è®¡ç®—çš„ä¸€äº›æ¿€æ´»æ¥é™ä½ VRAM éœ€æ±‚ã€‚æ ¹æ® Hugging Face çš„[æ–‡æ¡£](https://huggingface.co/docs/transformers/v4.18.0/en/performance)ï¼Œå®ƒè¿˜ä¼šä½¿è®­ç»ƒé€Ÿåº¦é™ä½çº¦ 20%ã€‚

+   **FlashAttention**ï¼šè¿™å®ç°äº†[FlashAttention](https://github.com/Dao-AILab/flash-attention)æœºåˆ¶ï¼Œé€šè¿‡å·§å¦™èåˆ GPU æ“ä½œæ¥æé«˜æ¨¡å‹çš„é€Ÿåº¦å’Œå†…å­˜æ•ˆç‡ï¼ˆäº†è§£æ›´å¤šå†…å®¹ï¼Œè¯·å‚é˜…[è¿™ç¯‡æ–‡ç« ](https://gordicaleksa.medium.com/eli5-flash-attention-5c44017022ad)ï¼Œä½œè€…æ˜¯[Aleksa GordiÄ‡](https://medium.com/u/37f02ae83e8c?source=post_page-----4bae7d4da672--------------------------------)ï¼‰ã€‚

+   **æ ·æœ¬æ‰“åŒ…**ï¼šä¸€ç§é€šè¿‡é‡æ–°ç»„ç»‡æ ·æœ¬é¡ºåºæ¥åˆ›å»ºå°½å¯èƒ½å°‘å¡«å……çš„æ‰¹æ¬¡çš„æ™ºèƒ½æ–¹æ³•ï¼ˆ[è£…ç®±é—®é¢˜](https://en.wikipedia.org/wiki/Bin_packing_problem)ï¼‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦æ›´å°‘çš„æ‰¹æ¬¡æ¥è®­ç»ƒç›¸åŒçš„æ•°æ®é›†ã€‚å®ƒçš„çµæ„Ÿæ¥è‡ªäº[Multipack Sampler](https://github.com/imoneoi/multipack_sampler/tree/master)ï¼ˆè§[æˆ‘çš„ç¬”è®°](https://mlabonne.github.io/blog/notes/Large%20Language%20Models/multipack_sampler.html)ï¼‰å’Œ[Krell ç­‰äºº](https://arxiv.org/pdf/2107.02027.pdf)ã€‚

ä½ å¯ä»¥åœ¨å…¶ä»–ä¸€äº›å·¥å…·ä¸­æ‰¾åˆ° FlashAttentionï¼Œä½†æ ·æœ¬æ‰“åŒ…ç›¸å¯¹è¾ƒæ–°ã€‚æ®æˆ‘æ‰€çŸ¥ï¼Œ[OpenChat](https://github.com/imoneoi/openchat)æ˜¯ç¬¬ä¸€ä¸ªåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ä½¿ç”¨æ ·æœ¬æ‰“åŒ…çš„é¡¹ç›®ã€‚æ„Ÿè°¢ Axolotlï¼Œæˆ‘ä»¬å¯ä»¥å…è´¹ä½¿ç”¨è¿™äº›æŠ€æœ¯ã€‚

# ğŸ¦™ å¾®è°ƒ Code Llama

é…ç½®æ–‡ä»¶å‡†å¤‡å¥½ä¹‹åï¼Œå°±è¯¥å¼€å§‹å®é™…çš„å¾®è°ƒå·¥ä½œäº†ã€‚ä½ å¯ä»¥è€ƒè™‘åœ¨ Colab ç¬”è®°æœ¬ä¸Šè¿è¡Œè®­ç»ƒã€‚ç„¶è€Œï¼Œå¯¹äºé‚£äº›æ²¡æœ‰é«˜æ€§èƒ½ GPU çš„äººæ¥è¯´ï¼Œä¸€ä¸ªæ›´å…·æˆæœ¬æ•ˆç›Šçš„è§£å†³æ–¹æ¡ˆæ˜¯ç§Ÿç”¨**åŸºäºäº‘çš„ GPU æœåŠ¡**ï¼Œå¦‚ AWSã€[Lambda Labs](https://lambdalabs.com/)ã€[Vast.ai](https://vast.ai/)ã€[Banana](https://www.banana.dev/)æˆ–[RunPod](https://www.runpod.io/)ã€‚

å°±æˆ‘ä¸ªäººè€Œè¨€ï¼Œæˆ‘ä½¿ç”¨ RunPodï¼Œè¿™æ˜¯å¾®è°ƒç¤¾åŒºä¸­ä¸€ä¸ªå—æ¬¢è¿çš„é€‰é¡¹ã€‚å®ƒä¸æ˜¯æœ€ä¾¿å®œçš„æœåŠ¡ï¼Œä½†åœ¨ç•Œé¢æ¸…æ™°åº¦å’Œæˆæœ¬ä¹‹é—´è¾¾åˆ°äº†ä¸€ä¸ªè‰¯å¥½çš„æŠ˜ä¸­ã€‚ä½ å¯ä»¥ä½¿ç”¨ä½ å–œæ¬¢çš„æœåŠ¡è½»æ¾å¤åˆ¶ä»¥ä¸‹æ­¥éª¤ã€‚

å½“ä½ çš„ RunPod è´¦æˆ·è®¾ç½®å¥½åï¼Œè½¬åˆ°â€œç®¡ç†â€>â€œæ¨¡æ¿â€å¹¶ç‚¹å‡»â€œæ–°å»ºæ¨¡æ¿â€ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„æ¨¡æ¿ï¼š

![](img/827c395c5294c1d157914fe4661ef301.png)

ä½œè€…æä¾›çš„å›¾åƒ

è®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹ä¸åŒçš„å­—æ®µåŠå…¶å¯¹åº”çš„å€¼ï¼š

+   **æ¨¡æ¿åç§°**ï¼šAxolotlï¼ˆä½ å¯ä»¥é€‰æ‹©ä»»ä½•ä½ æƒ³è¦çš„åç§°ï¼‰

+   **å®¹å™¨é•œåƒ**: winglian/axolotl-runpod:main-py3.10-cu118â€“2.0.1

+   **å®¹å™¨ç£ç›˜**: 100 GB

+   **å­˜å‚¨å·**: 0 GB

+   **å·æŒ‚è½½è·¯å¾„**: /workspace

æ­¤å¤–ï¼Œè¿˜æœ‰ä¸¤ä¸ªæœ‰ç”¨çš„ç¯å¢ƒå˜é‡å¯ä»¥åŒ…å«ï¼š

+   **HUGGING_FACE_HUB_TOKEN**: ä½ å¯ä»¥åœ¨ [æ­¤é¡µé¢](https://huggingface.co/settings/tokens) ä¸Šæ‰¾åˆ°ä½ çš„ä»¤ç‰Œï¼ˆéœ€è¦è´¦æˆ·ï¼‰

+   **WANDB_API_KEY**: ä½ å¯ä»¥åœ¨ [æ­¤é¡µé¢](https://wandb.ai/authorize) ä¸Šæ‰¾åˆ°ä½ çš„å¯†é’¥ï¼ˆéœ€è¦è´¦æˆ·ï¼‰

å¦å¤–ï¼Œä½ å¯ä»¥ç¨ååœ¨ç»ˆç«¯ç™»å½•ï¼ˆä½¿ç”¨ huggingface-cli login å’Œ wandb loginï¼‰ã€‚è®¾ç½®å®Œæˆåï¼Œå‰å¾€ Community Cloud å¹¶éƒ¨ç½² RTX 3090ã€‚ä½ å¯ä»¥åœ¨è¿™é‡Œæœç´¢ä½ çš„æ¨¡æ¿åç§°å¹¶é€‰æ‹©å®ƒï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

![](img/93732516ab48d2df1b5b62b9641f1117.png)

å›¾ç‰‡ç”±ä½œè€…æä¾›

ä½ å¯ä»¥ç‚¹å‡»â€œç»§ç»­â€ï¼ŒRunPod å°†éƒ¨ç½²ä½ çš„æ¨¡æ¿ã€‚ä½ å¯ä»¥åœ¨ä½ çš„ pod çš„æ—¥å¿—ä¸­æŸ¥çœ‹å®‰è£…æƒ…å†µï¼ˆç®¡ç† > Podsï¼‰ã€‚å½“é€‰é¡¹å¯ç”¨æ—¶ï¼Œç‚¹å‡»â€œè¿æ¥â€ã€‚åœ¨è¿™é‡Œï¼Œç‚¹å‡»â€œå¯åŠ¨ Web ç»ˆç«¯â€ï¼Œç„¶åâ€œè¿æ¥åˆ° Web ç»ˆç«¯â€ã€‚ä½ ç°åœ¨å·²è¿æ¥åˆ°ä½ çš„ podï¼

ä»¥ä¸‹æ­¥éª¤æ˜¯**æ— è®ºä½ é€‰æ‹©å“ªä¸ªæœåŠ¡éƒ½ç›¸åŒ**çš„ï¼š

1.  æˆ‘ä»¬æŒ‰å¦‚ä¸‹æ–¹å¼å®‰è£… Axolotl å’Œ PEFT åº“ï¼š

```py
git clone https://github.com/OpenAccess-AI-Collective/axolotl
cd axolotl

pip3 install -e .[flash-attn]
pip3 install -U git+https://github.com/huggingface/peft.git
```

2\. ä¸‹è½½æˆ‘ä»¬åˆ›å»ºçš„é…ç½®æ–‡ä»¶ï¼š

```py
wget https://gist.githubusercontent.com/mlabonne/8055f6335e2b85f082c8c75561321a66/raw/93915a9563fcfff8df9a81fc0cdbf63894465922/EvolCodeLlama-7b.yaml
```

3\. ä½ ç°åœ¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ **å¼€å§‹å¾®è°ƒæ¨¡å‹**ï¼š

```py
accelerate launch scripts/finetune.py EvolCodeLlama-7b.yaml
```

å¦‚æœä¸€åˆ‡é…ç½®æ­£ç¡®ï¼Œä½ åº”è¯¥èƒ½å¤Ÿåœ¨ **ä¸€ä¸ªå¤šå°æ—¶** å†…è®­ç»ƒæ¨¡å‹ï¼ˆæˆ‘èŠ±äº† 1 å°æ—¶ 11 åˆ†é’Ÿ 44 ç§’ï¼‰ã€‚å¦‚æœä½ æ£€æŸ¥ä½¿ç”¨çš„ GPU å†…å­˜ï¼Œä½ ä¼šå‘ç°å‡ ä¹è¾¾åˆ° 100%ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬æ­£åœ¨å¾ˆå¥½åœ°ä¼˜åŒ–å®ƒã€‚å¦‚æœä½ ä½¿ç”¨å…·æœ‰æ›´å¤š VRAM çš„ GPUï¼ˆå¦‚ A100ï¼‰ï¼Œä½ å¯ä»¥å¢åŠ å¾®æ‰¹é‡å¤§å°ä»¥ç¡®ä¿å……åˆ†åˆ©ç”¨å®ƒã€‚

ä¸æ­¤åŒæ—¶ï¼Œå¯ä»¥å…³é—­ Web ç»ˆç«¯ï¼Œå¹¶åœ¨ Weights & Biases ä¸Šæ£€æŸ¥ä½ çš„æŸå¤±ã€‚æˆ‘ä»¬ä½¿ç”¨ tmuxï¼Œæ‰€ä»¥å³ä½¿ä½ å…³é—­ç»ˆç«¯ï¼Œè®­ç»ƒä¹Ÿä¸ä¼šåœæ­¢ã€‚ä»¥ä¸‹æ˜¯æˆ‘çš„æŸå¤±æ›²çº¿ï¼š

![](img/fab0126f54062cf424f89f11e300d20c.png)

å›¾ç‰‡ç”±ä½œè€…æä¾›

æˆ‘ä»¬çœ‹åˆ°è¯„ä¼°æŸå¤±ç¨³æ­¥æ”¹å–„ï¼Œè¿™æ˜¯ä¸€ä¸ªå¥½å…†å¤´ã€‚ç„¶è€Œï¼Œä½ ä¹Ÿå¯ä»¥å‘ç°è¯„ä¼°æŸå¤±çš„ä¸‹é™å¹¶æœªä¸è¾“å‡ºè´¨é‡çš„é™ä½ç›¸å…³è”â€¦ è¯„ä¼°ä½ çš„æ¨¡å‹çš„æœ€ä½³æ–¹å¼æ˜¯ç›´æ¥ä½¿ç”¨å®ƒï¼šä½ å¯ä»¥åœ¨ç»ˆç«¯ä¸­è¿è¡Œå‘½ä»¤ `accelerate launch scripts/finetune.py EvolCodeLlama-7b.yaml --inference --lora_model_dir="./qlora-out"`ã€‚

QLoRA é€‚é…å™¨åº”è¯¥å·²ç»ä¸Šä¼ åˆ° Hugging Face Hubã€‚ç„¶è€Œï¼Œä½ ä¹Ÿå¯ä»¥é€šè¿‡ä»¥ä¸‹æ­¥éª¤**å°†åŸºç¡€ Code Llama æ¨¡å‹ä¸æ­¤é€‚é…å™¨åˆå¹¶å¹¶å°†åˆå¹¶åçš„æ¨¡å‹æ¨é€**åˆ°é‚£é‡Œï¼š

1.  ä¸‹è½½ [è¿™ä¸ªè„šæœ¬](https://gist.github.com/mlabonne/a3542b0519708b8871d0703c938bba9f)ï¼š

```py
wget https://gist.githubusercontent.com/mlabonne/a3542b0519708b8871d0703c938bba9f/raw/60abc5afc07f9d843bc23d56f4e0b7ab072c4a62/merge_peft.py
```

2\. ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ‰§è¡Œï¼š

```py
python merge_peft.py --base_model=codellama/CodeLlama-7b-hf --peft_model=./qlora-out --hub_id=EvolCodeLlama-7b
```

æ­å–œï¼Œä½ ç°åœ¨åº”è¯¥åœ¨ Hugging Face Hub ä¸Šæ‹¥æœ‰**ä½ è‡ªå·±çš„ EvolCodeLlama-7b**ï¼ä½œä¸ºå‚è€ƒï¼Œä½ å¯ä»¥åœ¨è¿™é‡Œè®¿é—®æˆ‘ç”¨è¿™ä¸ªè¿‡ç¨‹è®­ç»ƒçš„æ¨¡å‹: `[mlabonne/EvolCodeLlama-7b](https://huggingface.co/mlabonne/EvolCodeLlama-7b)`

è€ƒè™‘åˆ°æˆ‘ä»¬çš„ EvolCodeLlama-7b æ˜¯ä¸€ä¸ªä»£ç  LLMï¼Œæ¯”è¾ƒå®ƒåœ¨**æ ‡å‡†åŸºå‡†**ä¸Šçš„è¡¨ç°ä¸å…¶ä»–æ¨¡å‹ä¼šå¾ˆæœ‰è¶£ï¼Œä¾‹å¦‚[HumanEval](https://github.com/openai/human-eval)å’Œ[MBPP](https://github.com/google-research/google-research/tree/master/mbpp)ã€‚ä½œä¸ºå‚è€ƒï¼Œä½ å¯ä»¥åœ¨ä»¥ä¸‹åœ°å€æ‰¾åˆ°æ’è¡Œæ¦œï¼š[å¤šè¯­è¨€ä»£ç è¯„ä¼°](https://huggingface.co/spaces/bigcode/multilingual-code-evals)ã€‚

å¦‚æœä½ å¯¹è¿™ä¸ªæ¨¡å‹æ»¡æ„ï¼Œä½ å¯ä»¥ä½¿ç”¨ GGML è¿›è¡Œ**é‡åŒ–**ä»¥ä¾¿æœ¬åœ°æ¨ç†ï¼Œä½¿ç”¨[è¿™ä¸ªå…è´¹çš„ Google Colab ç¬”è®°æœ¬](https://colab.research.google.com/drive/1pL8k7m04mgE5jo2NrjGi8atB0j_37aDD?usp=sharing)ã€‚ä½ è¿˜å¯ä»¥åˆ©ç”¨[deepspeed](https://github.com/microsoft/DeepSpeed)å¯¹**æ›´å¤§çš„æ¨¡å‹**ï¼ˆä¾‹å¦‚ï¼Œ70b å‚æ•°ï¼‰è¿›è¡Œå¾®è°ƒï¼Œåªéœ€é¢å¤–çš„é…ç½®æ–‡ä»¶å³å¯ã€‚

# ç»“è®º

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è¦†ç›–äº†**å¦‚ä½•é«˜æ•ˆå¾®è°ƒ LLMs**çš„åŸºæœ¬è¦ç‚¹ã€‚æˆ‘ä»¬è‡ªå®šä¹‰äº†å‚æ•°ï¼Œåœ¨ä¸€ä¸ªå°çš„ Python æ•°æ®é›†ä¸Šè®­ç»ƒäº†æˆ‘ä»¬çš„ Code Llama æ¨¡å‹ã€‚æœ€åï¼Œæˆ‘ä»¬åˆå¹¶äº†æƒé‡ï¼Œå¹¶å°†ç»“æœä¸Šä¼ åˆ° Hugging Faceã€‚

æˆ‘å¸Œæœ›ä½ è§‰å¾—è¿™ä»½æŒ‡å—æœ‰ç”¨ã€‚æˆ‘æ¨èä½¿ç”¨ Axolotl ä¸åŸºäºäº‘çš„ GPU æœåŠ¡æ¥è·å–ä¸€äº›ç»éªŒï¼Œå¹¶åœ¨ Hugging Face ä¸Šä¸Šä¼ å‡ ä¸ªæ¨¡å‹ã€‚æ„å»ºè‡ªå·±çš„æ•°æ®é›†ï¼Œè°ƒæ•´å‚æ•°ï¼Œè¿‡ç¨‹ä¸­å¯èƒ½ä¼šé‡åˆ°ä¸€äº›é—®é¢˜ã€‚å°±åƒä½¿ç”¨ä»»ä½•åŒ…è£…å™¨ä¸€æ ·ï¼Œä¸è¦çŠ¹è±«å»æŸ¥çœ‹æºä»£ç ï¼Œä»¥ä¾¿å¯¹å…¶å®é™…æ“ä½œæœ‰ä¸€ä¸ªå¾ˆå¥½çš„ç›´è§‚äº†è§£ã€‚è¿™æ ·åœ¨é•¿æœŸå†…ä¼šå¤§å¤§å—ç›Šã€‚

æ„Ÿè°¢ OpenAccess AI Collective å’Œæ‰€æœ‰è´¡çŒ®è€…ï¼

å¦‚æœä½ å¯¹ LLMs çš„æ›´å¤šæŠ€æœ¯å†…å®¹æ„Ÿå…´è¶£ï¼Œ[åœ¨ Medium ä¸Šå…³æ³¨æˆ‘](https://medium.com/@mlabonne)ã€‚

# ç›¸å…³æ–‡ç« 

[åœ¨ Colab ç¬”è®°æœ¬ä¸­å¾®è°ƒä½ è‡ªå·±çš„ Llama 2 æ¨¡å‹](https://towardsdatascience.com/fine-tune-your-own-llama-2-model-in-a-colab-notebook-df9823a04a32?source=post_page-----4bae7d4da672--------------------------------)

### LLM å¾®è°ƒçš„å®ç”¨ä»‹ç»

[4 ä½é‡åŒ–ä¸ GPTQ](https://towardsdatascience.com/fine-tune-your-own-llama-2-model-in-a-colab-notebook-df9823a04a32?source=post_page-----4bae7d4da672--------------------------------) 

### ä½¿ç”¨ AutoGPTQ å¯¹è‡ªå·±çš„ LLMs è¿›è¡Œé‡åŒ–

[4 ä½é‡åŒ–ä¸ GPTQ](https://towardsdatascience.com/4-bit-quantization-with-gptq-36b0f4f02c34?source=post_page-----4bae7d4da672--------------------------------)

*äº†è§£æ›´å¤šå…³äºæœºå™¨å­¦ä¹ çš„å†…å®¹ï¼Œå¹¶é€šè¿‡ä¸€é”®æ”¯æŒæˆ‘çš„å·¥ä½œâ€”â€”åœ¨è¿™é‡Œæˆä¸º Medium ä¼šå‘˜ï¼š*

[åŠ å…¥ Mediumï¼Œä½¿ç”¨æˆ‘çš„æ¨èé“¾æ¥ - Maxime Labonne](https://medium.com/@mlabonne/membership?source=post_page-----4bae7d4da672--------------------------------)

### ä½œä¸º Medium ä¼šå‘˜ï¼Œä½ çš„ä¼šå‘˜è´¹ç”¨çš„ä¸€éƒ¨åˆ†ä¼šç»™ä½ é˜…è¯»çš„ä½œè€…ï¼ŒåŒæ—¶ä½ å¯ä»¥å…¨é¢è®¿é—®æ¯ä¸ªæ•…äº‹â€¦

[medium.com](https://medium.com/@mlabonne/membership?source=post_page-----4bae7d4da672--------------------------------)
