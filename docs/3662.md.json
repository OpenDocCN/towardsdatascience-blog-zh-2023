["```py\nimport pandas as pd\n\ndf = pd.read_parquet(\"articles.parquet\")\ndf.tail()\n```", "```py\nfrom sentence_transformers import SentenceTransformer\n\nmodel_name = \"neuralmind/bert-base-portuguese-cased\"\nencoder = SentenceTransformer(model_name_or_path=model_name)\n\ntitle = \"\"\"\n  Paraguaios vão às urnas neste domingo (30) para escolher novo presidente\n\"\"\"\n\nsentence = title\n\nsentence_embedding = encoder.encode(sentence)\nprint (sentence_embedding)\n# output: np.array([-0.2875876, 0.0356041, 0.31462672, 0.06252239, ...])\n```", "```py\ndef generate_item_sentence(item: pd.Series, text_columns=[\"title\"]) -> str:\n    return ' '.join([item[column] for column in text_columns])\n\ndf[\"sentence\"] = df.apply(generate_item_sentence, axis=1)\ndf[\"sentence_embedding\"] = df[\"sentence\"].apply(encoder.encode)\n```", "```py\nfrom qdrant_client import QdrantClient\nclient = QdrantClient(path=\"./qdrant_data\")\n```", "```py\nfrom qdrant_client import models\nfrom qdrant_client.http.models import Distance, VectorParams\n\nclient.create_collection(\n    collection_name = \"news-articles\",\n    vectors_config = models.VectorParams(\n        size = encoder.get_sentence_embedding_dimension(),\n        distance = models.Distance.COSINE,\n    ),\n)\n\nprint (client.get_collections())\n# output: CollectionsResponse(collections=[CollectionDescription(name='news-articles')])\n```", "```py\nfrom qdrant_client.http.models import PointStruct\n\nmetadata_columns = df.drop([\"newsId\", \"sentence\", \"sentence_embedding\"], axis=1).columns\n\ndef create_vector_point(item:pd.Series) -> PointStruct:\n    \"\"\"Turn vectors into PointStruct\"\"\"\n    return PointStruct(\n        id = item[\"newsId\"],\n        vector = item[\"sentence_embedding\"].tolist(),\n        payload = {\n            field: item[field]\n            for field in metadata_columns\n            if (str(item[field]) not in ['None', 'nan'])\n        }\n    )\n\npoints = df.apply(create_vector_point, axis=1).tolist()\n```", "```py\nCHUNK_SIZE = 500\nn_chunks = np.ceil(len(points)/CHUNK_SIZE)\n\nfor i, points_chunk in enumerate(np.array_split(points, n_chunks)):\n    client.upsert(\n        collection_name=\"news-articles\",\n        wait=True,\n        points=points_chunk.tolist()\n    )\n```", "```py\nquery_text = \"Donald Trump\"\nquery_vector = encoder.encode(query_text).tolist()\nprint (query_vector)\n# output: [-0.048, -0.120, 0.695, ...]\n```", "```py\nfrom qdrant_client.models import Filter\nfrom qdrant_client.http import models\n\nclient.search(\n    collection_name=\"news-articles\",\n    query_vector=query_vector,\n    with_payload=[\"newsId\", \"title\", \"topics\"],\n    query_filter=None\n)\n```", "```py\nseed_id = '8bc22460-532c-449b-ad71-28dd86790ca2'\n# title (translated): 'Learn why Joe Biden launched his bid for re-election this Tuesday'\n```", "```py\nclient.recommend(\n    collection_name=\"news-articles\",\n    positive=[seed_id],\n    negative=None,\n    with_payload=[\"newsId\", \"title\", \"topics\"]\n)\n```"]