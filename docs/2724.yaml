- en: Teaching Language Models to use Tools
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 教授语言模型使用工具
- en: 原文：[https://towardsdatascience.com/teaching-language-models-to-use-tools-7fd58916c66b?source=collection_archive---------1-----------------------#2023-08-27](https://towardsdatascience.com/teaching-language-models-to-use-tools-7fd58916c66b?source=collection_archive---------1-----------------------#2023-08-27)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/teaching-language-models-to-use-tools-7fd58916c66b?source=collection_archive---------1-----------------------#2023-08-27](https://towardsdatascience.com/teaching-language-models-to-use-tools-7fd58916c66b?source=collection_archive---------1-----------------------#2023-08-27)
- en: Using tools makes us more capable as humans. Is the same true of LLMs?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用工具让我们作为人类变得更有能力。这对大语言模型（LLMs）是否也一样？
- en: '[](https://wolfecameron.medium.com/?source=post_page-----7fd58916c66b--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----7fd58916c66b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7fd58916c66b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7fd58916c66b--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----7fd58916c66b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://wolfecameron.medium.com/?source=post_page-----7fd58916c66b--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----7fd58916c66b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7fd58916c66b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7fd58916c66b--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----7fd58916c66b--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F28aa6026c553&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-language-models-to-use-tools-7fd58916c66b&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=post_page-28aa6026c553----7fd58916c66b---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7fd58916c66b--------------------------------)
    ·17 min read·Aug 27, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7fd58916c66b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-language-models-to-use-tools-7fd58916c66b&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=-----7fd58916c66b---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F28aa6026c553&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-language-models-to-use-tools-7fd58916c66b&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=post_page-28aa6026c553----7fd58916c66b---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7fd58916c66b--------------------------------)
    · 17分钟阅读 · 2023年8月27日'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7fd58916c66b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-language-models-to-use-tools-7fd58916c66b&source=-----7fd58916c66b---------------------bookmark_footer-----------)![](../Images/72793c5d61d43b3d37b876b47eba27a0.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7fd58916c66b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-language-models-to-use-tools-7fd58916c66b&source=-----7fd58916c66b---------------------bookmark_footer-----------)![](../Images/72793c5d61d43b3d37b876b47eba27a0.png)'
- en: (Photo by [Barn Images](https://unsplash.com/@barnimages?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/t5YUoHW6zRo?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText))
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: （图片来源：[Barn Images](https://unsplash.com/@barnimages?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    于 [Unsplash](https://unsplash.com/photos/t5YUoHW6zRo?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)）
- en: As we learn more about them, large language models (LLMs) become increasingly
    interesting. These models can solve a variety of complex tasks accurately. At
    the same time, however, they struggle with certain functionality that we, as humans,
    consider basic! For example, LLMs commonly make arithmetic mistakes, lack access
    to current information, and even struggle to comprehend the progression of time.
    Given these limitations, we might wonder what can be done to make LLMs more capable.
    *Are LLMs doomed to suffer these limitations forever?*
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们对大型语言模型（LLMs）的了解越来越多，它们变得越来越有趣。这些模型可以准确解决各种复杂任务。然而，它们在某些我们认为基本的功能上却表现不佳！例如，LLMs通常会出现算术错误，缺乏当前信息的访问，甚至难以理解时间的进程。鉴于这些限制，我们可能会想知道如何使LLMs更具能力。*LLMs是否注定要永远承受这些限制？*
- en: Many advancements in the human race have been catalyzed by access to new and
    innovative tools (e.g., the [printing press](https://www.history.com/news/printing-press-renaissance)
    or [computer](https://www.youtube.com/watch?v=L40B08nWoMk)). *Might the same finding
    apply to LLMs?* Within this overview, we will study a recent direction of research
    that aims to teach LLMs how to use external tools, which are made available via
    simple, text-to-text APIs. Using these tools, LLMs can delegate tasks like performing
    arithmetic or looking up current information to a specialized tool. Then, information
    returned by this tool can be used as context by the LLM when generating output,
    leading to more accurate and grounded responses.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 人类的许多进步都受到新型和创新工具（例如，[印刷机](https://www.history.com/news/printing-press-renaissance)或[计算机](https://www.youtube.com/watch?v=L40B08nWoMk)）的催化。*相同的发现是否适用于LLMs？*
    在这个概述中，我们将深入研究一个新的研究方向，旨在教会LLMs如何使用外部工具，这些工具通过简单的文本到文本API提供。利用这些工具，LLMs可以将执行算术运算或查找当前信息等任务委托给专门的工具。然后，这些工具返回的信息可以作为LLM生成输出时的上下文，从而导致更准确且有根据的回答。
