- en: Translating Terms with LLMs (GPT and Vertex AI/Google Bard)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/translating-terms-with-llms-gpt-and-vertex-ai-google-bard-f1410b8d49f2?source=collection_archive---------12-----------------------#2023-09-21](https://towardsdatascience.com/translating-terms-with-llms-gpt-and-vertex-ai-google-bard-f1410b8d49f2?source=collection_archive---------12-----------------------#2023-09-21)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@shafquat?source=post_page-----f1410b8d49f2--------------------------------)[![Shafquat
    Arefeen](../Images/a52f40380207c523acd2feff7d2c4d4a.png)](https://medium.com/@shafquat?source=post_page-----f1410b8d49f2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f1410b8d49f2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f1410b8d49f2--------------------------------)
    [Shafquat Arefeen](https://medium.com/@shafquat?source=post_page-----f1410b8d49f2--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F73abef6f209b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftranslating-terms-with-llms-gpt-and-vertex-ai-google-bard-f1410b8d49f2&user=Shafquat+Arefeen&userId=73abef6f209b&source=post_page-73abef6f209b----f1410b8d49f2---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f1410b8d49f2--------------------------------)
    ·6 min read·Sep 21, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff1410b8d49f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftranslating-terms-with-llms-gpt-and-vertex-ai-google-bard-f1410b8d49f2&user=Shafquat+Arefeen&userId=73abef6f209b&source=-----f1410b8d49f2---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff1410b8d49f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftranslating-terms-with-llms-gpt-and-vertex-ai-google-bard-f1410b8d49f2&source=-----f1410b8d49f2---------------------bookmark_footer-----------)![](../Images/3d6348c7aafe453c0c1aca222ec00686.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Mojahid Mottakin](https://unsplash.com/@iammottakin?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/qkAUuWW_YHk?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: Can LLMs like ChatGPT accurately make translations better than humans? What
    options of LLMs do we have to work with? Learn more about using generative AI
    to make translations in multiple different languages.
  prefs: []
  type: TYPE_NORMAL
- en: The Background
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the time of writing this post, I have been working with data for nearly a
    decade and within localization for 2 years. I have experience with various forms
    of artificial intelligence including, but not limited to, clustering, classification,
    and sentiment analysis. Machine translation (MT) is commonly used in localization.
    Think of it like entering some text into Google Translate and requesting it to
    be translated into another language. From my experience, machine translation generally
    is correct 80% of the time, but still requires a human to review/fix mistranslations.
  prefs: []
  type: TYPE_NORMAL
- en: With the rise of large language models (LLMs) like ChatGPT and Google Bard,
    we might be able to get closer accuracy to human translation by providing additional
    context to the LLMs (like definitions and parts of speech).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/557569e79fc2091cf7292e696eabcb5b.png)'
  prefs: []
  type: TYPE_IMG
- en: The Hypothesis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: LLMs work with a prompt based input. This means the more information and context
    you can provide in the prompt, the better the output from the LLM. Given a sample
    of English terms, their definitions and their parts of speech, we would like to
    see if LLMs can produce better results at translating terms into different languages.
    The two LLMs we will be using are GPT (through a Jupyter Notebook via an OpenAI
    API) and Vertex AI (through Google BigQuery’s ML.GENERATE_TEXT function). The
    latter of which requires a lot more setup, but can be run directly in your querying
    console with SQL.
  prefs: []
  type: TYPE_NORMAL
- en: Using LLMs to Translate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GPT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We start off by installing the OpenAI python library in our jupyter notebook
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Import pandas to work with dataframes. Import the previously installed openai
    library and set your API key. Read in your data into a dataframe. If you’d like
    to follow along, the data that I’ll be working with can be found [here](https://shafquatarefeen.com/wp-content/uploads/2023/09/terms_sample.csv).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In a list, set the languages you’d like the word to be translated into.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Create a function that iterates over the rows in your dataframe and languages
    in your list to translate the terms respectively. The prompt will be entered into
    the “messages” section. We will be using GPT 3.5 and setting the temperature to
    a very small number to ensure that we get precise/less creative responses from
    the LLM.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The final step is to iterate the translation function over the dataframe for
    each language in the list and create a new column for the terms in those respective
    languages. Please find the full [code](https://shafquatarefeen.com/wp-content/uploads/2023/09/gpt-terms.pdf)
    for your reference.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/0ca63057418f35de4d924084a9458fb2.png)'
  prefs: []
  type: TYPE_IMG
- en: dataframe with translated terms
  prefs: []
  type: TYPE_NORMAL
- en: Google Bard / text-bisonm / Vertex AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will be using the [ML.GENERATE_TEXT](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-generate-text#arguments)
    function within Google’s text-bison model to translate the same terms as before.
    This process does take a little more resources to set up, but once up and running,
    we will be able to call an LLM directly in our SQL query.
  prefs: []
  type: TYPE_NORMAL
- en: Setup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I will not be providing a detailed setup guide as everyone’s Google Cloud infrastructure
    is unique to their needs. Rather, I’ll provide a high level overview with links
    on how to get the ball rolling.
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that there is a [Vertex AI User role](https://cloud.google.com/vertex-ai/docs/general/access-control)
    enabled to access your service account.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set up a remote cloud connection by following the instructions on [Google Cloud](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Create an LLM Model](https://cloud.google.com/bigquery/docs/generate-text-tutorial#create_the_remote_model)
    with the remote cloud connection'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You should now be able to run your LLM Model using the ML.GENERATE_TEXT function.
    I would recommend looking into the [function’s arguments](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-generate-text#arguments)
    to understand what parameters are required.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Upload your data into your billing project so it can be queried.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The code that was used to generate the translations can be found below. Due
    to a combination of my own limitations and the restrictions of our query engine,
    I decided to individually run the code for each language (manually replacing the
    bolded text) instead of looping over the languages ARRAY like I did with the previous
    jupyter notebook.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Interpreting the Results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Qualifier: I do not speak any of these languages besides English so take my
    conclusions with a grain of salt.*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8b4548e8734b00ebeefcbfe9f2348079.png)'
  prefs: []
  type: TYPE_IMG
- en: GPT translated terms
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/49c75449feeb3da3bbab802a36bdbd96.png)'
  prefs: []
  type: TYPE_IMG
- en: Vertex AI translated terms
  prefs: []
  type: TYPE_NORMAL
- en: 'The results can be found [here](https://shafquatarefeen.com/wp-content/uploads/2023/09/ML.GENERATE_TEXT-translations.pdf).
    Some findings that I made note of:'
  prefs: []
  type: TYPE_NORMAL
- en: 47 / 84 (56%) of translations by both LLMs were exactly the same.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '- GPT included a period (.) at the end of the word often. By removing these,
    the match percentage increases to **63%.**'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: It seems that Japanese and French were the most unaligned translations between
    the two LLMs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPT understood the term “make up” as make-up (ie. cosmetics), which is concerning
    because the it seems like it didn’t leverage the definition and part of speech
    for that term before making a translation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '- This could be because my prompt structure was not optimal. For example, I
    could’ve provided the definition before the term to allow the LLM to process that
    information first.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Heavy metal (proper noun) seems to be literally translated by GPT, especially
    in German, where it was translated to a term that does not correspond with the
    music genre
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ultimately I’d say both LLMs have their advantages and disadvantages. GPT is
    easy to setup and run in python, while Vertex AI understands prompts clearer and
    takes in all the context before making a translation. I think it’s fair to say
    that the LLMs do a much better job than regular machine translation because they
    are able to process additional context in their prompts. Let me know what you
    think. Could I have made things better?
  prefs: []
  type: TYPE_NORMAL
- en: '*Originally published at* [*https://shafquatarefeen.com*](https://shafquatarefeen.com/gpt/)*.*'
  prefs: []
  type: TYPE_NORMAL
