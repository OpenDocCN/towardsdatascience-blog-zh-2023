- en: A Framework for a Human-Centered AI Based on the Laws of Nature
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/a-framework-for-a-human-centered-ai-based-on-the-laws-of-nature-a8bfbb233250?source=collection_archive---------16-----------------------#2023-05-08](https://towardsdatascience.com/a-framework-for-a-human-centered-ai-based-on-the-laws-of-nature-a8bfbb233250?source=collection_archive---------16-----------------------#2023-05-08)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Integrating natural and artificial intelligence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://tom-kehler.medium.com/?source=post_page-----a8bfbb233250--------------------------------)[![Tom
    Kehler](../Images/c2fea6fed3b1632399bdf4e4c11717bb.png)](https://tom-kehler.medium.com/?source=post_page-----a8bfbb233250--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a8bfbb233250--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a8bfbb233250--------------------------------)
    [Tom Kehler](https://tom-kehler.medium.com/?source=post_page-----a8bfbb233250--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F64cea19482ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-framework-for-a-human-centered-ai-based-on-the-laws-of-nature-a8bfbb233250&user=Tom+Kehler&userId=64cea19482ea&source=post_page-64cea19482ea----a8bfbb233250---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a8bfbb233250--------------------------------)
    ·9 min read·May 8, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa8bfbb233250&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-framework-for-a-human-centered-ai-based-on-the-laws-of-nature-a8bfbb233250&user=Tom+Kehler&userId=64cea19482ea&source=-----a8bfbb233250---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa8bfbb233250&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-framework-for-a-human-centered-ai-based-on-the-laws-of-nature-a8bfbb233250&source=-----a8bfbb233250---------------------bookmark_footer-----------)![](../Images/cd1fe976f75bc45753629684192902c4.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Nature’s emergent order (image source iStock Getty Images **2090608323**)
  prefs: []
  type: TYPE_NORMAL
- en: '*Presented to the Boston Global Forum High-level Conference “AI Assistant Regulation
    Summit: Fostering a Tech Enlightenment Economy Alliance” at the Harvard Faculty
    Club. The paper presented here is an expansion of that talk.*'
  prefs: []
  type: TYPE_NORMAL
- en: We are at many crossroads. The one in sharp view in recent months is AI, resulting
    in a spectrum of responses from terror to glee. No doubt you have by now experienced
    the delight of playing with ChatGPT. Many have joined the rush to adoption. Others
    suggest this current expression of AI is yet another race to the bottom where
    we throw caution to the wind because we must. Everyone else is doing it, so we
    must do so as well. Aggregate bad behavior that no one wants — but exists because
    no one knows how to build trust is a shadow that comes with technological advances.
    Technology is not the enemy. F*ailure to collaborate and come together in trust
    leads to reckless adoption that could lead to harm.*
  prefs: []
  type: TYPE_NORMAL
- en: In this brief overview, I hope to provide you with a framework for an AI future
    that builds trust and reduces risk.
  prefs: []
  type: TYPE_NORMAL
- en: That framework was first unveiled by the founders of science and the scientific
    method dating back to the Enlightenment. The scientific method that followed formed
    the foundation for building trusted knowledge — a collaborative process dependent
    on collective human intelligence and trust in the emergent elegance offered in
    nature.
  prefs: []
  type: TYPE_NORMAL
- en: '**We recommend employing the power of collective human intelligence and the
    intelligence built into the physics of living systems to guide us forward.¹**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: For nearly 70 years, the scientific pursuits of AI centered on building handcrafted
    models of the natural intelligence and cognitive skills of humans using the tools
    of symbolic representation and reasoning. They were capable of explaining how
    they solved a problem. Trust was built by observing their reasoning.
  prefs: []
  type: TYPE_NORMAL
- en: For the past 20 years, statistical learning from the explosion of data offered
    by the Internet has yielded spectacular results — from self-driving cars to the
    large language models that bring us together today. In particular, transformer
    deep learning architectures unlocked generative AI's powerful potential, which
    has created the impressive results we see today.
  prefs: []
  type: TYPE_NORMAL
- en: The concern that brings us here today relates to three fundamental problems.
    ***For the first time in the history of information technology, we are not enforcing
    the concept of data provenance.*** Thus, these tremendous generative powers can
    be persuasive purveyors of misinformation and undermine trust in knowledge. ***The
    second concern is explainability — the systems are black boxes. The third concern
    is they need a sense of context.***
  prefs: []
  type: TYPE_NORMAL
- en: '***These three points of weakness go crossways with the three pillars of the
    scientific method of citation, reproducibility, and contextualization of results.***
    What do we do?'
  prefs: []
  type: TYPE_NORMAL
- en: Judea Pearl says, ‘You are smarter than your data,’ We agree. The human capacity
    for counterfactual thinking is far more powerful than anything we can learn from
    correlative patterns in our past data.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Large Language Models and deep learning architectures generally develop models
    of intelligent behavior based on pattern recognition and correlation models from
    data. Generative output from LLMs employs humans in the loop to filter and train
    the results. The risk remains. The filtering process may miss the generation of
    content containing misinformation.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/caeca149c32cfca6b6aa053c03127671.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1 (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: 'Five years ago, in an *MIT Technology Review* interview, one of the fathers
    of deep learning, Yoshua Bengio, stated:'
  prefs: []
  type: TYPE_NORMAL
- en: “I think we need to consider the hard challenges of AI and not be satisfied
    with short-term, incremental advances. I’m not saying I want to forget deep learning.
    On the contrary, I want to build on it. But we must extend it to do things like
    reasoning, learning causality, and exploring the world to learn and acquire information.”²
  prefs: []
  type: TYPE_NORMAL
- en: It is unlikely that current models based on the correlation of patterns in historical
    data capture the complexity of the human brain's abilities. The imaginative power
    of the human brain and its ability to generate cause models based on experience
    must be an integral part of future AI models. We propose an approach that incorporates
    human collective intelligence and a human brain model.
  prefs: []
  type: TYPE_NORMAL
- en: Larry Page, Sergey Brin, and Terry Winograd found that citation indexing could
    lead to a scalable way to order information on the web.³ The PageRank algorithm
    brought order to the web. The mathematics of citation indexing brings order to
    understanding information sharing in human collaboration.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e8c5d20a2088a31443a484cd57356aa4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Image by author'
  prefs: []
  type: TYPE_NORMAL
- en: A next generation of AI that integrates human collective reasoning, developed
    in the past eight years, uses a citation indexing approach as a knowledge discovery
    process. It allows knowledge discovery at scale, supporting citation, reproducibility,
    and contextualization. We propose this as part of a framework going forward.
  prefs: []
  type: TYPE_NORMAL
- en: Collective reasoning seeks to learn a community or group's aggregated preferences
    and beliefs about a forecasted outcome. Will a product launch create the results
    we want? If we change our work-from-home policy, will we increase or decrease
    productivity? What policy for using ChatGPT and LLMs will be best for our organization?
    These questions require learning a group's ‘collective mind’ on the predicted
    outcome. The collective reasoning process employs AI technology to learn a model
    of the collective mind. The process is single-blind, reducing bias. The system
    was tested for four years on groups of 20 to 30 experts/investors predicting startup
    success, and it was >80% accurate.⁴ The collective beliefs and predictions for
    each investment were mapped into collective knowledge models — Bayesian Belief
    Networks⁵. These causal models are generative executable representations of the
    group's collective reasoning.
  prefs: []
  type: TYPE_NORMAL
- en: We can embed the critical elements of the scientific knowledge discovery process
    in how we co-create or collaborate to solve complex problems. Rather than have
    AI undermine trust in knowledge, we propose using AI to learn collective knowledge
    models, causal models that retain provenance, explainability, and context. ***This
    is a critical component of a new enlightenment — bringing the scientific method
    to collaboration.***
  prefs: []
  type: TYPE_NORMAL
- en: Collective reasoning allows learning the intentions of a group. An agent-based
    simulation is useful in forecasting the impact of a proposed solution. Synthetic
    models of populations based on public data allow scaling and forecasting the impact
    of co-created solutions, and we propose that as part of the framework. One of
    the partner companies in this initiative has built a significant capability to
    simulate impact at scale, applying it to the social implications of disease propagation.⁶
  prefs: []
  type: TYPE_NORMAL
- en: What about the foundation of AI going forward? What have we learned in 68 years
    since the summer of 1956 when AI was born? The first few decades developed the
    components that form the current AI landscape. The mathematics of cooperative
    phenomena and the physics of magnetism play an exciting role in linking it all
    together. Hopfield, in 1982, demonstrated that the emergent collective computational
    capabilities of artificial neural networks mapped directly to the mathematical
    physics of spin glasses.⁷ The same mathematics of cooperative phenomena describes
    the emergence of order out of chaos, as shown in the murmuration of starlings
    photo at the beginning of this article.
  prefs: []
  type: TYPE_NORMAL
- en: Recently, Lin, Rolnick, and Tegmark at MIT showed that the reason deep and cheap
    learning work so well is tied to the laws of physics. Bayesian learning is reformulated
    as a fundamental method used in quantum and classical physics — The Hamiltonian.⁸
    Explicitly focusing on the roots of AI in natural laws should be the focus of
    future AI development.
  prefs: []
  type: TYPE_NORMAL
- en: Central to it all is learning order out of disorder. A new wave of studies in
    the brain takes learning at the order/disorder boundary to a theory for creating
    living intelligence systems — the Free Energy Principle.⁹.
  prefs: []
  type: TYPE_NORMAL
- en: The FEP is a framework based on Bayesian learning. The brain is thought of as
    a Bayesian probability machine. If sensory inputs do not match expectations, active
    inference seeks to minimize the uncertainty going forward. The difference between
    what we expect and sense is called surprisal and is represented as free energy
    (energy available for action). Finding a path with minimum free energy is equivalent
    to finding a path that reduces surprise (uncertainty).
  prefs: []
  type: TYPE_NORMAL
- en: An AI based on FEP adapts locally and scales based on variational free energy
    minimization principles used throughout the physical and biological sciences.
    Bioform Labs is building out a Biotic AI that adapts and learns.¹⁰ Unlike second-generation
    AI, which requires massive training data sets and complicated cost functions,
    AI based on the physics of living systems is adaptive and lives within an ecosystem.
    It can be designed to respect the states that lead to the needs of living systems.
  prefs: []
  type: TYPE_NORMAL
- en: Technology to get started on this new framework is applicable today. We don’t
    need to halt the development of AI. Collective reasoning applies to questions
    we need to ask ourselves about the impact of AI in a wide variety of specific
    contexts. How will AI affect investments in technology? How will it change our
    hiring practices? What impact will it have on our community?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0cfbd0712b1e631296fbb12214329db1.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3 (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: In addition, it is possible to engage ChatGPT and LLMs in ideation while retaining
    a privacy boundary. Ideas streamed in from an LLM can be curated and employed
    in specific private contexts. Curated and contextualized contributions are managed
    in a patented private LLM environment.¹¹
  prefs: []
  type: TYPE_NORMAL
- en: Collective reasoning learns intentions and possible solutions. Agent-based simulations
    forecast impact. We no longer need to think of organizations as rigid. New types
    of organizational governance, based on active inference, support adaptively learning
    a survival path forward. We believe this framework is a vision for the future
    that will create the foundation for
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/12fc57daca9bf68cd39fe5e4523b6724.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4 (image by author)
  prefs: []
  type: TYPE_NORMAL
- en: a new AI-empowered Enlightenment. As the Enlightenment freed science from the
    tyranny of religious authority, a new initiative, AI-empowered Enlightenment,
    provides a path to collaborate and co-create solutions — to free us from unintended
    consequences of the current wave of AI frenzy.
  prefs: []
  type: TYPE_NORMAL
- en: In conclusion, Large Language Models provide highly useful capabilities that
    are unfolding at an impressive rate. Read the warning labels! ChatGPT does warn
    not to trust the results implicitly but to use critical thinking. Don’t expose
    private data. For private data, Figures 3 and 4 demonstrate a way to experiment
    by allowing ChatGPT or other ‘agents’ to provide inputs to a curated collaboration
    with human experts with results kept in a privately managed LLM context. This
    approach allows exploring the generative power of LLMs while retaining control
    of private intellectual property.
  prefs: []
  type: TYPE_NORMAL
- en: (1) The proposed framework presented in this paper results from collaborative
    work initiated at a meeting on March 6 at MIT Media Lab organized by John Clippinger
    of BioForms, Kim Polese of Crowdsmart, and several other participants. Tuan Nguyen,
    CEO of Boston Global Forum, was in attendance, and following that meeting, the
    initiative aligned with the Boston Global Forum in creating a Framework for AI
    Governance [https://bostonglobalforum.org/](https://bostonglobalforum.org/)
  prefs: []
  type: TYPE_NORMAL
- en: (2)’Knight, Will, (November 17, 2018) “One of the fathers of AI is worried about
    its future” MIT Technology Review
  prefs: []
  type: TYPE_NORMAL
- en: '(3) Page, L., Brin, S., Motwani, R. and Winograd, T. (1998) The PageRank Citation
    Ranking: Bringing Order to the Web. Technical Report SIDL-WP-1999–0120, Stanford
    Digital Library Technologies Project.'
  prefs: []
  type: TYPE_NORMAL
- en: (4) For more information, see [AI-guided Co-creation](https://medium.com/@tom-kehler/ai-guided-co-creation-120784af8fe0).
  prefs: []
  type: TYPE_NORMAL
- en: (5) Patent US11366972 assigned to [CrowdSmart.ai](http://crowdsmart.ai)
  prefs: []
  type: TYPE_NORMAL
- en: (6) [Epistemix.com](https://www.epistemix.com/)
  prefs: []
  type: TYPE_NORMAL
- en: (7) Hopfield JJ. 1982\. Neural networks and physical systems with emergent collective
    computational abilities. Proc. Natl Acad. Sci. USA 79, 2554–2558
  prefs: []
  type: TYPE_NORMAL
- en: (8)Lin, H.W., Tegmark, M. & Rolnick, D. Why Does Deep and Cheap Learning Work
    So Well?. J Stat Phys 168, 1223–1247 (2017). [https://doi.org/10.1007/s10955-017-1836-5](https://doi.org/10.1007/s10955-017-1836-5)
  prefs: []
  type: TYPE_NORMAL
- en: '(9) Friston, K. The free-energy principle: a unified brain theory?. *Nat Rev
    Neurosci* **11**, 127–138 (2010). [https://doi.org/10.1038/nrn2787](https://doi.org/10.1038/nrn2787)'
  prefs: []
  type: TYPE_NORMAL
- en: (10) [https://bioformlabs.org/](https://bioformlabs.org/)
  prefs: []
  type: TYPE_NORMAL
- en: (11) Patent — Managing and measuring semantic coverage in knowledge discovery
    processes. 2022/072895
  prefs: []
  type: TYPE_NORMAL
