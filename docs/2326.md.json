["```py\nfrom PyPDF2 import PdfReader\nimport nltk\nnltk.download('punkt')\n\n# Extracting Text from PDF\ndef extract_text_from_pdf(file_path):\n    with open(file_path, 'rb') as file:\n        pdf = PdfReader(file)\n        text = \" \".join(page.extract_text() for page in pdf.pages)\n    return text\n\n# Extract text from the PDF and split it into sentences\ntext = extract_text_from_pdf(file_path)\n```", "```py\nsample = text[1015:3037]\nprint(sample)\n\n\"\"\"\n=======\nOutput:\n=======\n\nBrazil is the world's fifth-largest country by area and the seventh most popul ous. Its capital\nis Brasília, and its most popul ous city is São Paulo. The federation is composed of the union of the 26\nstates and the Federal District. It is the only country in the Americas to have Portugue se as an official\nlangua ge.[11][12] It is one of the most multicultural and ethnically diverse nations, due to over a century of\nmass immigration from around t he world,[13] and the most popul ous Roman Catholic-majority country.\nBounde d by the Atlantic Ocean on the east, Brazil has a coastline of 7,491 kilometers (4,655 mi).[14] It\nborders all other countries and territories in South America except Ecuador and Chile and covers roughl y\nhalf of the continent's land area.[15] Its Amazon basin includes a vast tropical forest, home to diverse\nwildlife, a variety of ecological systems, and extensive natural resources spanning numerous protected\nhabitats.[14] This unique environmental heritage positions Brazil at number one of 17 megadiverse\ncountries, and is the subject of significant global interest, as environmental degradation through processes\nlike deforestation has direct impacts on gl obal issues like climate change and biodiversity loss.\nThe territory which would become know n as Brazil was inhabited by numerous tribal nations prior to the\nlanding in 1500 of explorer Pedro Álvares Cabral, who claimed the discovered land for the Portugue se\nEmpire. Brazil remained a Portugue se colony until 1808 when the capital of the empire was transferred\nfrom Lisbon to Rio de Janeiro. In 1815, the colony was elevated to the rank of kingdom  upon the\nformation of the United Kingdom  of Portugal, Brazil and the Algarves. Independence was achieved in\n1822 with the creation of the Empire of Brazil, a unitary state gove rned unde r a constitutional monarchy\nand a parliamentary system. The ratification of the first constitution in 1824  led to the formation of a\nbicameral legislature, now called the National Congress.\n\"\"\"\n```", "```py\nimport nltk\nnltk.download('punkt')\n\n# Splitting Text into Sentences\ndef split_text_into_sentences(text):\n    sentences = nltk.sent_tokenize(text)\n    return sentences\n\nsentences = split_text_into_sentences(text)\n```", "```py\nimport spacy\n\nnlp = spacy.load('en_core_web_sm')\ndoc = nlp(text)\nsentences = list(doc.sents)\n```", "```py\n# Initialize the text splitter with custom parameters\ncustom_text_splitter = RecursiveCharacterTextSplitter(\n    # Set custom chunk size\n    chunk_size = 100,\n    chunk_overlap  = 20,\n    # Use length of the text as the size measure\n    length_function = len,\n\n)\n\n# Create the chunks\ntexts = custom_text_splitter.create_documents([sample])\n\n# Print the first two chunks\nprint(f'### Chunk 1: \\n\\n{texts[0].page_content}\\n\\n=====\\n')\nprint(f'### Chunk 2: \\n\\n{texts[1].page_content}\\n\\n=====')\n\n\"\"\"\n=======\nOutput:\n=======\n\n### Chunk 1: \n\nBrazil is the world's fifth-largest country by area and the seventh most popul ous. Its capital\n\n=====\n\n### Chunk 2: \n\nis Brasília, and its most popul ous city is São Paulo. The federation is composed of the union of\n\n=====\n\n\"\"\"\n```", "```py\n# Initialize the text splitter with custom parameters\ncustom_text_splitter = RecursiveCharacterTextSplitter(\n    # Set custom chunk size\n    chunk_size = 300,\n    chunk_overlap  = 30,\n    # Use length of the text as the size measure\n    length_function = len,\n    # Use only \"\\n\\n\" as the separator\n    separators = ['\\n']\n)\n\n# Create the chunks\ncustom_texts = custom_text_splitter.create_documents([sample])\n\n# Print the first two chunks\nprint(f'### Chunk 1: \\n\\n{custom_texts[0].page_content}\\n\\n=====\\n')\nprint(f'### Chunk 2: \\n\\n{custom_texts[1].page_content}\\n\\n=====')\n```", "```py\n# Print the sampled chunks\nprint(\"====   Sample chunks from 'Standard Parameters':   ====\\n\\n\")\nfor i, chunk in enumerate(texts):\n  if i < 4:\n    print(f\"### Chunk {i+1}: \\n{chunk.page_content}\\n\")\n\nprint(\"====   Sample chunks from 'Custom Parameters':   ====\\n\\n\")\nfor i, chunk in enumerate(custom_texts):\n  if i < 4:\n    print(f\"### Chunk {i+1}: \\n{chunk.page_content}\\n\")\n\n\"\"\"\n=======\nOutput:\n=======\n\n====   Sample chunks from 'Standard Parameters':   ====\n\n### Chunk 1: \nBrazil is the world's fifth-largest country by area and the seventh most popul ous. Its capital\n\n### Chunk 2: \nis Brasília, and its most popul ous city is São Paulo. The federation is composed of the union of\n\n### Chunk 3: \nof the union of the 26\n\n### Chunk 4: \nstates and the Federal District. It is the only country in the Americas to have Portugue se as an\n\n====   Sample chunks from 'Custom Parameters':   ====\n\n### Chunk 1: \nBrazil is the world's fifth-largest country by area and the seventh most popul ous. Its capital\nis Brasília, and its most popul ous city is São Paulo. The federation is composed of the union of the 26\n\n### Chunk 2: \nstates and the Federal District. It is the only country in the Americas to have Portugue se as an official\nlangua ge.[11][12] It is one of the most multicultural and ethnically diverse nations, due to over a century of\n\n### Chunk 3: \nmass immigration from around t he world,[13] and the most popul ous Roman Catholic-majority country.\nBounde d by the Atlantic Ocean on the east, Brazil has a coastline of 7,491 kilometers (4,655 mi).[14] It\n\n### Chunk 4: \nborders all other countries and territories in South America except Ecuador and Chile and covers roughl y\nhalf of the continent's land area.[15] Its Amazon basin includes a vast tropical forest, home to diverse\n\"\"\"\n```", "```py\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.cluster import KMeans\n\n# Load the Sentence Transformer model\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\n# Define a list of sentences (your text data)\nsentences = [\"This is an example sentence.\", \"Another sentence goes here.\", \"...\"]\n\n# Generate embeddings for the sentences\nembeddings = model.encode(sentences)\n\n# Choose an appropriate number of clusters (here we choose 5 as an example)\nnum_clusters = 3\n\n# Perform K-means clustering\nkmeans = KMeans(n_clusters=num_clusters)\nclusters = kmeans.fit_predict(embeddings)\n```", "```py\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport string\n\nnltk.download('stopwords')\n\n# Define a list of stop words\nstop_words = set(stopwords.words('english'))\n\n# Define a function to clean sentences\ndef clean_sentence(sentence):\n    # Tokenize the sentence\n    tokens = word_tokenize(sentence)\n    # Convert to lower case\n    tokens = [w.lower() for w in tokens]\n    # Remove punctuation\n    table = str.maketrans('', '', string.punctuation)\n    stripped = [w.translate(table) for w in tokens]\n    # Remove non-alphabetic tokens\n    words = [word for word in stripped if word.isalpha()]\n    # Filter out stop words\n    words = [w for w in words if not w in stop_words]\n    return words\n\n# Compute and print Word Clouds for each cluster\nfor i in range(num_clusters):\n    cluster_sentences = [sentences[j] for j in range(len(sentences)) if clusters[j] == i]\n    cleaned_sentences = [' '.join(clean_sentence(s)) for s in cluster_sentences]\n    text = ' '.join(cleaned_sentences)\n\n    wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(text)\n    plt.figure()\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.title(f\"Cluster {i}\")\n    plt.show()\n```", "```py\nimport numpy as np\nimport spacy\n\n# Load the Spacy model\nnlp = spacy.load('en_core_web_sm')\n\ndef process(text):\n    doc = nlp(text)\n    sents = list(doc.sents)\n    vecs = np.stack([sent.vector / sent.vector_norm for sent in sents])\n\n    return sents, vecs\n\ndef cluster_text(sents, vecs, threshold):\n    clusters = [[0]]\n    for i in range(1, len(sents)):\n        if np.dot(vecs[i], vecs[i-1]) < threshold:\n            clusters.append([])\n        clusters[-1].append(i)\n\n    return clusters\n\ndef clean_text(text):\n    # Add your text cleaning process here\n    return text\n\n# Initialize the clusters lengths list and final texts list\nclusters_lens = []\nfinal_texts = []\n\n# Process the chunk\nthreshold = 0.3\nsents, vecs = process(text)\n\n# Cluster the sentences\nclusters = cluster_text(sents, vecs, threshold)\n\nfor cluster in clusters:\n    cluster_txt = clean_text(' '.join([sents[i].text for i in cluster]))\n    cluster_len = len(cluster_txt)\n\n    # Check if the cluster is too short\n    if cluster_len < 60:\n        continue\n\n    # Check if the cluster is too long\n    elif cluster_len > 3000:\n        threshold = 0.6\n        sents_div, vecs_div = process(cluster_txt)\n        reclusters = cluster_text(sents_div, vecs_div, threshold)\n\n        for subcluster in reclusters:\n            div_txt = clean_text(' '.join([sents_div[i].text for i in subcluster]))\n            div_len = len(div_txt)\n\n            if div_len < 60 or div_len > 3000:\n                continue\n\n            clusters_lens.append(div_len)\n            final_texts.append(div_txt)\n\n    else:\n        clusters_lens.append(cluster_len)\n        final_texts.append(cluster_txt)\n```", "```py\n====   Sample chunks from 'Langchain Splitter with Custom Parameters':   ====\n\n### Chunk 1: \nBrazil is the world's fifth-largest country by area and the seventh most popul ous. Its capital\nis Brasília, and its most popul ous city is São Paulo. The federation is composed of the union of the 26\n\n### Chunk 2: \nstates and the Federal District. It is the only country in the Americas to have Portugue se as an official\nlangua ge.[11][12] It is one of the most multicultural and ethnically diverse nations, due to over a century of\n\n====   Sample chunks from 'Adjacent Sentences Clustering':   ====\n\n### Chunk 1: \nBrazil is the world's fifth-largest country by area and the seventh most popul ous. Its capital\nis Brasília, and its most popul ous city is São Paulo.\n\n### Chunk 2: \nThe federation is composed of the union of the 26\nstates and the Federal District. It is the only country in the Americas to have Portugue se as an official\nlangua ge.[11][12]\n```", "```py\nfinal_texts_lengths = [len(chunk) for chunk in final_texts]\n```"]