- en: 'Temporal Differences with Python: First Sample-Based Reinforcement Learning
    Algorithm'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/temporal-differences-with-python-first-sample-based-reinforcement-learning-algorithm-54c11745a0ee?source=collection_archive---------4-----------------------#2023-01-27](https://towardsdatascience.com/temporal-differences-with-python-first-sample-based-reinforcement-learning-algorithm-54c11745a0ee?source=collection_archive---------4-----------------------#2023-01-27)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Coding up and understanding the TD(0) algorithm using Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://eligijus-bujokas.medium.com/?source=post_page-----54c11745a0ee--------------------------------)[![Eligijus
    Bujokas](../Images/061fd30136caea2ba927140e8b3fae3c.png)](https://eligijus-bujokas.medium.com/?source=post_page-----54c11745a0ee--------------------------------)[](https://towardsdatascience.com/?source=post_page-----54c11745a0ee--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----54c11745a0ee--------------------------------)
    [Eligijus Bujokas](https://eligijus-bujokas.medium.com/?source=post_page-----54c11745a0ee--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd61597e07b4d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-differences-with-python-first-sample-based-reinforcement-learning-algorithm-54c11745a0ee&user=Eligijus+Bujokas&userId=d61597e07b4d&source=post_page-d61597e07b4d----54c11745a0ee---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----54c11745a0ee--------------------------------)
    ·13 min read·Jan 27, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F54c11745a0ee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-differences-with-python-first-sample-based-reinforcement-learning-algorithm-54c11745a0ee&user=Eligijus+Bujokas&userId=d61597e07b4d&source=-----54c11745a0ee---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F54c11745a0ee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-differences-with-python-first-sample-based-reinforcement-learning-algorithm-54c11745a0ee&source=-----54c11745a0ee---------------------bookmark_footer-----------)![](../Images/36f274e9692bf335a901977271968109.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Kurt Cotoaga](https://unsplash.com/@kydroon?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a continuation article from my previous article:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/first-steps-in-the-world-of-reinforcement-learning-using-python-b843b76538e3?source=post_page-----54c11745a0ee--------------------------------)
    [## First Steps in the World Of Reinforcement Learning using Python'
  prefs: []
  type: TYPE_NORMAL
- en: Original Python implementation of how to find the best places to be in one of
    the fundamental worlds of reinforcement…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/first-steps-in-the-world-of-reinforcement-learning-using-python-b843b76538e3?source=post_page-----54c11745a0ee--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I want to familiarize the reader with the sample-based algorithm
    logic in Reinforcement Learning (**RL**). To do this, we will create a grid world
    with holes (much like the one in the thumbnail) and let our agent freely traverse
    our created world.
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, by the end of the agent's journey, he will have learnt where in the
    world is a good place to be and which locations should be avoided. To help our
    agent in the learning process we will use the famous **TD(0)** algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Before diving into the algorithms, let us define the objective that we want
    to solve.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this article, we will create a grid world with 5 rows and 7 columns, meaning,
    our agent will be able to be in one of 35 states. The rules of movement are:'
  prefs: []
  type: TYPE_NORMAL
- en: The agent cannot go outside the…
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
