- en: 'Temporal Differences with Python: First Sample-Based Reinforcement Learning
    Algorithm'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Python 的时间差异：第一个基于样本的强化学习算法
- en: 原文：[https://towardsdatascience.com/temporal-differences-with-python-first-sample-based-reinforcement-learning-algorithm-54c11745a0ee?source=collection_archive---------4-----------------------#2023-01-27](https://towardsdatascience.com/temporal-differences-with-python-first-sample-based-reinforcement-learning-algorithm-54c11745a0ee?source=collection_archive---------4-----------------------#2023-01-27)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/temporal-differences-with-python-first-sample-based-reinforcement-learning-algorithm-54c11745a0ee?source=collection_archive---------4-----------------------#2023-01-27](https://towardsdatascience.com/temporal-differences-with-python-first-sample-based-reinforcement-learning-algorithm-54c11745a0ee?source=collection_archive---------4-----------------------#2023-01-27)
- en: Coding up and understanding the TD(0) algorithm using Python
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Python 编写和理解 TD(0) 算法
- en: '[](https://eligijus-bujokas.medium.com/?source=post_page-----54c11745a0ee--------------------------------)[![Eligijus
    Bujokas](../Images/061fd30136caea2ba927140e8b3fae3c.png)](https://eligijus-bujokas.medium.com/?source=post_page-----54c11745a0ee--------------------------------)[](https://towardsdatascience.com/?source=post_page-----54c11745a0ee--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----54c11745a0ee--------------------------------)
    [Eligijus Bujokas](https://eligijus-bujokas.medium.com/?source=post_page-----54c11745a0ee--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://eligijus-bujokas.medium.com/?source=post_page-----54c11745a0ee--------------------------------)[![Eligijus
    Bujokas](../Images/061fd30136caea2ba927140e8b3fae3c.png)](https://eligijus-bujokas.medium.com/?source=post_page-----54c11745a0ee--------------------------------)[](https://towardsdatascience.com/?source=post_page-----54c11745a0ee--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----54c11745a0ee--------------------------------)
    [Eligijus Bujokas](https://eligijus-bujokas.medium.com/?source=post_page-----54c11745a0ee--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd61597e07b4d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-differences-with-python-first-sample-based-reinforcement-learning-algorithm-54c11745a0ee&user=Eligijus+Bujokas&userId=d61597e07b4d&source=post_page-d61597e07b4d----54c11745a0ee---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----54c11745a0ee--------------------------------)
    ·13 min read·Jan 27, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F54c11745a0ee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-differences-with-python-first-sample-based-reinforcement-learning-algorithm-54c11745a0ee&user=Eligijus+Bujokas&userId=d61597e07b4d&source=-----54c11745a0ee---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd61597e07b4d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-differences-with-python-first-sample-based-reinforcement-learning-algorithm-54c11745a0ee&user=Eligijus+Bujokas&userId=d61597e07b4d&source=post_page-d61597e07b4d----54c11745a0ee---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----54c11745a0ee--------------------------------)
    ·13 分钟阅读·2023年1月27日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F54c11745a0ee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-differences-with-python-first-sample-based-reinforcement-learning-algorithm-54c11745a0ee&user=Eligijus+Bujokas&userId=d61597e07b4d&source=-----54c11745a0ee---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F54c11745a0ee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-differences-with-python-first-sample-based-reinforcement-learning-algorithm-54c11745a0ee&source=-----54c11745a0ee---------------------bookmark_footer-----------)![](../Images/36f274e9692bf335a901977271968109.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F54c11745a0ee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-differences-with-python-first-sample-based-reinforcement-learning-algorithm-54c11745a0ee&source=-----54c11745a0ee---------------------bookmark_footer-----------)![](../Images/36f274e9692bf335a901977271968109.png)'
- en: Photo by [Kurt Cotoaga](https://unsplash.com/@kydroon?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Kurt Cotoaga](https://unsplash.com/@kydroon?utm_source=medium&utm_medium=referral)
    提供，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'This is a continuation article from my previous article:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我之前文章的续篇：
- en: '[](/first-steps-in-the-world-of-reinforcement-learning-using-python-b843b76538e3?source=post_page-----54c11745a0ee--------------------------------)
    [## First Steps in the World Of Reinforcement Learning using Python'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/first-steps-in-the-world-of-reinforcement-learning-using-python-b843b76538e3?source=post_page-----54c11745a0ee--------------------------------)
    [## 使用 Python 进行强化学习的第一步'
- en: Original Python implementation of how to find the best places to be in one of
    the fundamental worlds of reinforcement…
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 原始 Python 实现了如何在强化学习的基本世界之一中找到最佳去处……
- en: towardsdatascience.com](/first-steps-in-the-world-of-reinforcement-learning-using-python-b843b76538e3?source=post_page-----54c11745a0ee--------------------------------)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/first-steps-in-the-world-of-reinforcement-learning-using-python-b843b76538e3?source=post_page-----54c11745a0ee--------------------------------)'
- en: In this article, I want to familiarize the reader with the sample-based algorithm
    logic in Reinforcement Learning (**RL**). To do this, we will create a grid world
    with holes (much like the one in the thumbnail) and let our agent freely traverse
    our created world.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我想让读者熟悉强化学习（**RL**）中的基于样本的算法逻辑。为此，我们将创建一个有孔的网格世界（类似于缩略图中的世界），并让我们的代理自由地在这个世界中游历。
- en: Hopefully, by the end of the agent's journey, he will have learnt where in the
    world is a good place to be and which locations should be avoided. To help our
    agent in the learning process we will use the famous **TD(0)** algorithm.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 希望在代理完成旅程时，它能学会在世界中哪些地方是好去处，哪些地方应该避免。为了帮助我们的代理进行学习，我们将使用著名的**TD(0)**算法。
- en: Before diving into the algorithms, let us define the objective that we want
    to solve.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解算法之前，让我们定义一下我们想要解决的目标。
- en: 'In this article, we will create a grid world with 5 rows and 7 columns, meaning,
    our agent will be able to be in one of 35 states. The rules of movement are:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将创建一个有5行7列的网格世界，这意味着我们的代理将能够处于35个状态中的一个。移动规则是：
- en: The agent cannot go outside the…
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代理不能离开……
