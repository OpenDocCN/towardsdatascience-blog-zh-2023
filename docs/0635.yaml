- en: 'Other ML Jargons: Sparse and Dense Representations of Texts for Machine Learning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/other-ml-jargons-sparse-and-dense-representations-of-texts-for-machine-learning-21fcd7a01410?source=collection_archive---------15-----------------------#2023-02-15](https://towardsdatascience.com/other-ml-jargons-sparse-and-dense-representations-of-texts-for-machine-learning-21fcd7a01410?source=collection_archive---------15-----------------------#2023-02-15)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: OTHER ML JARGONS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A Brief Introduction to Vectorization and its Importance in the Context of NLP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://nroy0110.medium.com/?source=post_page-----21fcd7a01410--------------------------------)[![Nabanita
    Roy](../Images/83ab7766a28c79371ebf9517e1f273d2.png)](https://nroy0110.medium.com/?source=post_page-----21fcd7a01410--------------------------------)[](https://towardsdatascience.com/?source=post_page-----21fcd7a01410--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----21fcd7a01410--------------------------------)
    [Nabanita Roy](https://nroy0110.medium.com/?source=post_page-----21fcd7a01410--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd36a8b28c928&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fother-ml-jargons-sparse-and-dense-representations-of-texts-for-machine-learning-21fcd7a01410&user=Nabanita+Roy&userId=d36a8b28c928&source=post_page-d36a8b28c928----21fcd7a01410---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----21fcd7a01410--------------------------------)
    ·9 min read·Feb 15, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F21fcd7a01410&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fother-ml-jargons-sparse-and-dense-representations-of-texts-for-machine-learning-21fcd7a01410&user=Nabanita+Roy&userId=d36a8b28c928&source=-----21fcd7a01410---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F21fcd7a01410&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fother-ml-jargons-sparse-and-dense-representations-of-texts-for-machine-learning-21fcd7a01410&source=-----21fcd7a01410---------------------bookmark_footer-----------)![](../Images/a2550ebb25c16994eb499f8e089b474a.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Compare Fibre](https://unsplash.com/@comparefibre?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '**Introduction**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Matrices and vectors are quantified information that Machine Learning(ML) algorithms
    require for learning patterns and making predictions. For applying these techniques
    to textual data as well, numeric representations of the texts are engineered to
    form matrices that hold the relevant information from those texts. The concepts
    of “Sparsity” and “Density” arrive at efficiently designing and constructing these
    matrices for all high-dimensional data processing use-cases in the world of Artificial
    Intelligence.
  prefs: []
  type: TYPE_NORMAL
- en: Significance of Vector Representations for NLP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Representing text data as vectors are necessary for applying Machine Learning
    techniques to make predictions, recommendations, or clusters. In NLP, the concept
    of “*similar words occur in similar contexts”* is fundamental. Let’s see how:'
  prefs: []
  type: TYPE_NORMAL
- en: In **Text Classification** use-cases like categorizing support tickets, spam
    detection, fake news detection, and feedback sentiment analysis, texts having
    similar words are classified into a…
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
