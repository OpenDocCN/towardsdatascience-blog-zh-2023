- en: 'Mixed Effects Machine Learning for High-Cardinality Categorical Variables —
    Part II: GPBoost library'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高基数分类变量的混合效应机器学习 — 第二部分：GPBoost库
- en: 原文：[https://towardsdatascience.com/mixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-ii-gpboost-3bdd9ef74492?source=collection_archive---------6-----------------------#2023-07-11](https://towardsdatascience.com/mixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-ii-gpboost-3bdd9ef74492?source=collection_archive---------6-----------------------#2023-07-11)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/mixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-ii-gpboost-3bdd9ef74492?source=collection_archive---------6-----------------------#2023-07-11](https://towardsdatascience.com/mixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-ii-gpboost-3bdd9ef74492?source=collection_archive---------6-----------------------#2023-07-11)
- en: A demo of GPBoost in Python & R using real-world data
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个使用真实数据的GPBoost在Python和R中的演示
- en: '[](https://medium.com/@fabsig?source=post_page-----3bdd9ef74492--------------------------------)[![Fabio
    Sigrist](../Images/f7bc2adc17255ae1efd0886a19ec202c.png)](https://medium.com/@fabsig?source=post_page-----3bdd9ef74492--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3bdd9ef74492--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3bdd9ef74492--------------------------------)
    [Fabio Sigrist](https://medium.com/@fabsig?source=post_page-----3bdd9ef74492--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@fabsig?source=post_page-----3bdd9ef74492--------------------------------)[![Fabio
    Sigrist](../Images/f7bc2adc17255ae1efd0886a19ec202c.png)](https://medium.com/@fabsig?source=post_page-----3bdd9ef74492--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3bdd9ef74492--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3bdd9ef74492--------------------------------)
    [Fabio Sigrist](https://medium.com/@fabsig?source=post_page-----3bdd9ef74492--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb5b503a0c329&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-ii-gpboost-3bdd9ef74492&user=Fabio+Sigrist&userId=b5b503a0c329&source=post_page-b5b503a0c329----3bdd9ef74492---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3bdd9ef74492--------------------------------)
    ·8 min read·Jul 11, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3bdd9ef74492&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-ii-gpboost-3bdd9ef74492&user=Fabio+Sigrist&userId=b5b503a0c329&source=-----3bdd9ef74492---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb5b503a0c329&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-ii-gpboost-3bdd9ef74492&user=Fabio+Sigrist&userId=b5b503a0c329&source=post_page-b5b503a0c329----3bdd9ef74492---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3bdd9ef74492--------------------------------)
    ·8分钟阅读·2023年7月11日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3bdd9ef74492&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-ii-gpboost-3bdd9ef74492&user=Fabio+Sigrist&userId=b5b503a0c329&source=-----3bdd9ef74492---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3bdd9ef74492&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-ii-gpboost-3bdd9ef74492&source=-----3bdd9ef74492---------------------bookmark_footer-----------)![](../Images/e5dd3c4f7bc91e17c444088bc24348ba.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3bdd9ef74492&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-ii-gpboost-3bdd9ef74492&source=-----3bdd9ef74492---------------------bookmark_footer-----------)![](../Images/e5dd3c4f7bc91e17c444088bc24348ba.png)'
- en: '**Illustration of high-cardinality categorical data**: box plots and raw data
    (red points) of the response variable for different levels of a categorical variable
    — Image by author'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**高基数分类数据的示意图**：不同分类变量水平的响应变量的箱线图和原始数据（红点）— 图片作者提供'
- en: High-cardinality categorical variables are variables for which the number of
    different levels is large relative to the sample size of a data set. In [Part
    I](https://medium.com/towards-data-science/mixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-i-an-empirical-df0a43dce059)
    of this series, we did an empirical comparison of different machine learning methods
    and found that random effects are an effective tool for handling high-cardinality
    categorical variables with the [GPBoost algorithm](https://www.jmlr.org/papers/v23/20-322.html)
    [Sigrist, 2022, 2023] having the highest prediction accuracy. In this article,
    we demonstrate how the GPBoost algorithm, which combines tree-boosting with random
    effects, can be applied with the Python and R packages of the `[GPBoost](https://github.com/fabsig/GPBoost)`
    [library](https://github.com/fabsig/GPBoost). `GPBoost` version 1.2.1 is used
    in this demo.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Table of contents
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ∘ [1 Introduction](#c2dc)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '∘ [2 Data: description, loading, and sample split](#c3cf)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [3 Training a GPBoost model](#a119)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [4 Choosing tuning parameter](#d562)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [5 Prediction](#9914)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [6 Interpretation](#7784)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [7 Further modeling options](#6d73)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: · · [7.1 Interaction between categorical variables and other predictor variables](#b005)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: · · [7.2 (Generalized) linear mixed effects models](#49d6)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [8 Conclusion and references](#4ebe)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Applying a GPBoost model involves the following main steps:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: 'Define a `GPModel` in which one specifies the following:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '— A random effects model: grouped random effects via `group_data` and/or Gaussian
    processes via `gp_coords`'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: — The `likelihood` *(= distribution of the response variable conditional on
    fixed and random effects)*
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Create a `Dataset` containing the response variable (`label`) and fixed effects
    predictor variables (`data`)
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose tuning parameters, e.g., using the function `gpb.grid.search.tune.parameters`
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the model
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make predictions and/or interpret the trained model
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the following, we go through these points step-by-step.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '2 Data: description, loading, and sample split'
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The data used in this demo is the wages data which was also analyzed in [Sigrist
    (2022)](https://www.jmlr.org/papers/v23/20-322.html). It can be downloaded from
    [here](https://raw.githubusercontent.com/fabsig/Compare_ML_HighCardinality_Categorical_Variables/master/data/wages.csv.gz).
    The data contains 28’013 samples and one high-cardinality categorical variable
    (person ID = `idcode`) with 4’711 different levels. The response variable is the
    logarithmic real wage (`ln_wage`), and the data includes several predictor variables
    such as age, total work experience, job tenure in years, date, and others.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: In the code below, we first load the data and randomly partition the data into
    80% training data and 20% test data. The latter is left aside and will be used
    later for measuring prediction accuracy.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '***Python***'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '***R***'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 3 Training a GPBoost model
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The code below shows how to train a GPBoost model. We first define a random
    effects model (`gp_model`), a `Dataset` (`data_bst`), tuning parameters (`params`
    and `nrounds` = number of trees / boosting iteration), and then run the GPBoost
    algorithm by calling the `gpb.train` function. Note that we use tuning parameters
    that have been selected beforehand (see below).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码展示了如何训练一个GPBoost模型。我们首先定义一个随机效应模型（`gp_model`）、一个`Dataset`（`data_bst`）、调整参数（`params`和`nrounds`
    = 树的数量/提升迭代次数），然后通过调用`gpb.train`函数运行GPBoost算法。请注意，我们使用了事先选择的调整参数（见下文）。
- en: '***Python***'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '***Python***'
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '***R***'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '***R***'
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'For this data, there is only one high-cardinality categorical variable. If
    there are multiple categorical variables that should be modeled using random effects,
    this can be specified in the `gp_model` as shown in the following code. *Note:
    computations can become slower when having multiple random effects compared to
    only one. Also, it can be faster to use* `*nelder_mead*` *instead of* `*gradient_descent*`
    *(=default) as optimizer when having multiple random effects. This can be set
    as follows before calling* `*gpb.train*`*.*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个数据，只有一个高基数的分类变量。如果有多个分类变量需要使用随机效应建模，这可以在`gp_model`中指定，如以下代码所示。*注意：当有多个随机效应时，计算可能会比只有一个随机效应时更慢。此外，使用`*nelder_mead*`
    *代替`*gradient_descent*`（=默认值）作为优化器在有多个随机效应时可能会更快。这可以在调用`*gpb.train*`*之前进行设置。*
- en: '***Python***'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '***Python***'
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '***R***'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '***R***'
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 4 Choosing tuning parameter
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 选择调整参数
- en: 'It is important that tuning parameters are appropriately chosen for boosting.
    There are no universal default values and every data set will likely need different
    tuning parameters. Below, we show how tuning parameters can be chosen using the
    `gpb.grid.search.tune.parameters` function. We use a deterministic grid search
    with the parameter combinations shown below in the code. Note that we tune the
    `max_depth` parameter and thus set the `num_leaves` to a large value. We randomly
    split the training data into 80% inner training data 20% validation data and use
    the mean squared error (`mse`) as a prediction accuracy measure on the validation
    data. Alternatively, one can also use, e.g., the test negative log-likelihood
    (`test_neg_log_likelihood` = default) which also takes prediction uncertainty
    into account. *Note: depending on the data set and the grid size, this can take
    some time (a few minutes on my laptop for this data set). Instead of a deterministic
    grid search as below, one can also do a random grid search (see* `*num_try_random*`*)
    or another approach such as Bayesian optimization to speed things up.*'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 调整参数的选择对于提升效果至关重要。没有通用的默认值，每个数据集可能需要不同的调整参数。以下展示了如何使用`gpb.grid.search.tune.parameters`函数来选择调整参数。我们使用了一个确定性的网格搜索，并在代码中展示了参数组合。请注意，我们调整了`max_depth`参数，因此将`num_leaves`设置为一个大值。我们随机将训练数据拆分为80%的内训练数据和20%的验证数据，并使用均方误差（`mse`）作为验证数据上的预测准确度衡量标准。或者，也可以使用，例如，测试负对数似然（`test_neg_log_likelihood`
    = 默认值），它还考虑了预测的不确定性。*注意：根据数据集和网格大小，这可能需要一些时间（在我的笔记本电脑上，对于这个数据集需要几分钟）。除了下面的确定性网格搜索外，也可以进行随机网格搜索（见*
    `*num_try_random*`*）或其他方法如贝叶斯优化来加快速度。*
- en: '***Python***'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '***Python***'
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '***R***'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '***R***'
- en: '[PRE7]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 5 Prediction
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 预测
- en: Predictions can be obtained via the `predict` function. We need to provide both
    test predictor variables (`data`) for the tree ensemble and test categorical variables
    (`group_data_pred`) for the random effects model. Below, we make predictions on
    the left-out test data and calculate the test mean squared error (MSE).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过`predict`函数获得预测。我们需要提供树集合的测试预测变量（`data`）和随机效应模型的测试分类变量（`group_data_pred`）。以下是对留下的测试数据进行预测并计算测试均方误差（MSE）。
- en: '***Python***'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '***Python***'
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '***R***'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '***R***'
- en: '[PRE10]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 6 Interpretation
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6 解释
- en: Information on the estimated random effects model can be obtained as follows.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 估计随机效应模型的信息可以通过以下方式获得。
- en: '***Python***'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '***Python***'
- en: '[PRE11]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '***R***'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '***R***'
- en: '[PRE13]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'There are several tools for understanding the form of the fixed effects tree
    ensemble function supported by the `GPBoost` library:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个工具可以帮助理解`GPBoost`库支持的固定效应树集合函数的形式：
- en: SHAP values
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SHAP值
- en: SHAP & partial dependence plots (one and two-dimensional)
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SHAP和部分依赖图（二维和一维）
- en: SHAP force plots
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SHAP力图
- en: Interaction statistics
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交互统计
- en: Split-based variable importances
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于拆分的变量重要性
- en: Below we look at SHAP values and a SHAP dependence plot.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 以下我们查看SHAP值和SHAP依赖图。
- en: '***Python***'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '***Python***'
- en: '[PRE14]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/74fb408e7c6fe5a23df8be4bf03aafaa.png)![](../Images/8966198e2b3bcfc1ad60eb8283de210b.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
- en: SHAP values and SHAP dependence plot — Image by author
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '***R***'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 7 Further modeling options
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 7.1 Interaction between categorical variables and other predictor variables
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the above model, there is no interaction between the random effects and
    the fixed effects predictor variables, i.e., between the high-cardinality categorical
    variable and the other predictor variables. Such interaction can be modeled by
    additionally including the categorical variable in the tree ensemble. The following
    code shows how this can be done. Below, we also calculate the test MSE of this
    model. The test MSE is slightly smaller compared to a model without such interaction.
    *Note: the tuning parameters used below have been chosen beforehand, but for the
    sake of brevity, we omit this code.*'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '***Python***'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '***R***'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 7.2 (Generalized) linear mixed effects models
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `GPBoost` library also supports (generalized) linear mixed effects models
    (GLMMs). In a GLMM, one assumes that the fixed effects function F() is a linear
    function instead of a tree ensemble. The code below shows how this can be done.
    Note that one needs to manually add a column of 1s to include an intercept. With
    the option `params={"std_dev": True}` / `params = list(std_dev=TRUE)`, one obtains
    standard deviations and p-values in the `summary` function.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '***Python***'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '***R***'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 8 Conclusion and references
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have demonstrated how tree-boosting combined with random effects can be applied
    with the Python and R packages of the `[GPBoost](https://github.com/fabsig/GPBoost)`
    [library](https://github.com/fabsig/GPBoost). There are several more features
    of the `GPBoost` library that we did not show here. You may want to have a look
    at the [Python examples](https://github.com/fabsig/GPBoost/tree/master/examples/python-guide)
    and [R examples](https://github.com/fabsig/GPBoost/tree/master/R-package/demo).
    In [Part III](https://medium.com/towards-data-science/mixed-effects-machine-learning-for-longitudinal-panel-data-with-gpboost-part-iii-523bb38effc)
    of this series, we will show how longitudinal data (aka panel data) can be modeled
    with the `GPBoost` library.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: F. Sigrist. Gaussian Process Boosting. The Journal of Machine Learning Research,
    23(1):10565–10610, 2022.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: F. Sigrist. Latent Gaussian Model Boosting. IEEE Transactions on Pattern Analysis
    and Machine Intelligence, 45(2):1894–1905, 2023.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://github.com/fabsig/GPBoost](https://github.com/fabsig/GPBoost)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
