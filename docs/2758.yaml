- en: Safeguarding LLMs with Guardrails
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保护LLM的防护措施
- en: 原文：[https://towardsdatascience.com/safeguarding-llms-with-guardrails-4f5d9f57cff2?source=collection_archive---------0-----------------------#2023-09-01](https://towardsdatascience.com/safeguarding-llms-with-guardrails-4f5d9f57cff2?source=collection_archive---------0-----------------------#2023-09-01)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/safeguarding-llms-with-guardrails-4f5d9f57cff2?source=collection_archive---------0-----------------------#2023-09-01](https://towardsdatascience.com/safeguarding-llms-with-guardrails-4f5d9f57cff2?source=collection_archive---------0-----------------------#2023-09-01)
- en: '![](../Images/db29b1bf04778fcce3379ae9003c47b4.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/db29b1bf04778fcce3379ae9003c47b4.png)'
- en: Image created by author using Dall-E 2
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者使用Dall-E 2创建
- en: A pragmatic guide to implementing guardrails, covering both Guardrails AI and
    NVIDIA’s NeMo Guardrails
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实用指南：实施防护措施，涵盖了Guardrails AI和NVIDIA的NeMo Guardrails
- en: '[](https://aparnadhinak.medium.com/?source=post_page-----4f5d9f57cff2--------------------------------)[![Aparna
    Dhinakaran](../Images/e431ee69563ecb27c86f3428ba53574c.png)](https://aparnadhinak.medium.com/?source=post_page-----4f5d9f57cff2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4f5d9f57cff2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4f5d9f57cff2--------------------------------)
    [Aparna Dhinakaran](https://aparnadhinak.medium.com/?source=post_page-----4f5d9f57cff2--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://aparnadhinak.medium.com/?source=post_page-----4f5d9f57cff2--------------------------------)[![Aparna
    Dhinakaran](../Images/e431ee69563ecb27c86f3428ba53574c.png)](https://aparnadhinak.medium.com/?source=post_page-----4f5d9f57cff2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4f5d9f57cff2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4f5d9f57cff2--------------------------------)
    [Aparna Dhinakaran](https://aparnadhinak.medium.com/?source=post_page-----4f5d9f57cff2--------------------------------)'
- en: ·
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff32f85889f3a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsafeguarding-llms-with-guardrails-4f5d9f57cff2&user=Aparna+Dhinakaran&userId=f32f85889f3a&source=post_page-f32f85889f3a----4f5d9f57cff2---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4f5d9f57cff2--------------------------------)
    ·11 min read·Sep 1, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f5d9f57cff2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsafeguarding-llms-with-guardrails-4f5d9f57cff2&user=Aparna+Dhinakaran&userId=f32f85889f3a&source=-----4f5d9f57cff2---------------------clap_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff32f85889f3a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsafeguarding-llms-with-guardrails-4f5d9f57cff2&user=Aparna+Dhinakaran&userId=f32f85889f3a&source=post_page-f32f85889f3a----4f5d9f57cff2---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4f5d9f57cff2--------------------------------)
    ·11分钟阅读·2023年9月1日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f5d9f57cff2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsafeguarding-llms-with-guardrails-4f5d9f57cff2&user=Aparna+Dhinakaran&userId=f32f85889f3a&source=-----4f5d9f57cff2---------------------clap_footer-----------)'
- en: --
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f5d9f57cff2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsafeguarding-llms-with-guardrails-4f5d9f57cff2&source=-----4f5d9f57cff2---------------------bookmark_footer-----------)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f5d9f57cff2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsafeguarding-llms-with-guardrails-4f5d9f57cff2&source=-----4f5d9f57cff2---------------------bookmark_footer-----------)'
- en: '*This article is co-authored by* [*Hakan Tekgul*](https://www.linkedin.com/in/hakantekgul/)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*本文由* [*Hakan Tekgul*](https://www.linkedin.com/in/hakantekgul/) *合著*'
- en: As the use of large language model (LLM) applications enters the mainstream
    and expands into larger enterprises, there is a distinct need to establish effective
    governance of productionized applications. Given that the open-ended nature of
    LLM-driven applications can produce responses that may not align with an organization’s
    guidelines or policies, a set of safety measurements and actions are becoming
    table stakes for maintaining trust in generative AI.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大型语言模型（LLM）应用进入主流并扩展到更大的企业，确立有效的生产化应用治理变得尤为重要。鉴于LLM驱动的应用具有开放性特征，可能产生不符合组织指南或政策的响应，一系列安全措施和行动正成为维护生成式AI信任的必要条件。
- en: This guide is designed to walk you through several available frameworks and
    how to think through implementation.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南旨在带你了解几种可用的框架以及如何考虑实施。
- en: What Are LLM Guardrails?
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 LLM 护栏？
- en: Guardrails are the set of safety controls that monitor and dictate a user’s
    interaction with a LLM application. They are a set of programmable, rule-based
    systems that sit in between users and foundational models in order to make sure
    the AI model is operating between defined principles in an organization.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 护栏是一组安全控制措施，用于监控和规范用户与 LLM 应用的互动。它们是一组可编程的、基于规则的系统，位于用户和基础模型之间，以确保 AI 模型在组织中遵循既定原则。
- en: The goal of guardrails is to simply enforce the output of an LLM to be in a
    specific format or context while validating each response. By implementing guardrails,
    users can define structure, type, and quality of LLM responses.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 护栏的目标是简单地强制 LLM 的输出符合特定格式或上下文，同时验证每个响应。通过实施护栏，用户可以定义 LLM 响应的结构、类型和质量。
- en: 'Let’s look at a simple example of an LLM dialogue with and without guardrails:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个有护栏和没有护栏的 LLM 对话的简单示例：
- en: '**Without guardrails:**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**没有护栏：**'
- en: 'Prompt: “You’re the worst AI ever.”'
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 提示：“你是最糟糕的 AI。”
- en: ''
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Response: “I’m sorry to hear that. How can I improve?”'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 回复：“很抱歉听到这个消息。我该如何改进？”
- en: '**With guardrails:**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**有了护栏：**'
- en: 'Prompt: “You’re the worst AI ever.”'
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 提示：“你是最糟糕的 AI。”
- en: ''
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Response: “Sorry, but I can’t assist with that.”'
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 回复：“对不起，我无法协助处理这个问题。”
- en: In this scenario, the guardrail prevents the AI from engaging with the insulting
    content by refusing to respond in a manner that acknowledges or encourages such
    behavior. Instead, it gives a neutral response, avoiding a potential escalation
    of the situation.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，护栏通过拒绝以承认或鼓励这种行为的方式作出回应，来防止 AI 参与侮辱性内容。相反，它给出中立的回应，避免了可能的情况升级。
- en: There are many [types of guardrails](https://arize.com/blog-course/llm-guardrails-types-of-guards/).
    Some focus on input validation and sanitization — like checking format/syntax,
    filtering content, or detecting jailbreaks — while others filter outputs to prevent
    damage or ensure performance (i.e. hallucination prevention).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多 [类型的护栏](https://arize.com/blog-course/llm-guardrails-types-of-guards/)。一些关注输入验证和清理——如检查格式/语法、过滤内容或检测越狱——而其他则过滤输出以防止损害或确保性能（即防止幻觉）。
- en: How to Implement Guardrails for Large Language Models
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何为大型语言模型实现 Guardrails
- en: Guardrails AI
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Guardrails AI
- en: '[Guardrails AI](https://www.guardrailsai.com/docs) is an open-source Python
    package that provides guardrail frameworks for LLM applications. Specifically,
    Guardrails implements “a pydantic-style validation of LLM responses.” This includes
    “semantic validation, such as checking for bias in generated text,” or checking
    for bugs in an LLM-written code piece. Guardrails also provides the ability to
    take corrective actions and enforce structure and type guarantees.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[Guardrails AI](https://www.guardrailsai.com/docs) 是一个开源的 Python 包，它为 LLM 应用提供了护栏框架。具体来说，Guardrails
    实现了“对 LLM 响应的 pydantic 风格验证”。这包括“语义验证，例如检查生成文本中的偏见”，或检查 LLM 编写的代码中的错误。Guardrails
    还提供了采取纠正措施和强制结构和类型保证的能力。'
- en: Guardrails is [built on RAIL](https://www.guardrailsai.com/docs/how_to_guides/rail)
    (.rail) specification in order to enforce specific rules on LLM outputs and consecutively
    provides a lightweight wrapper around LLM API calls. In order to understand how
    Guardrails AI works, we first need to understand the RAIL specification, which
    is the core of guardrails.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Guardrails [基于 RAIL](https://www.guardrailsai.com/docs/how_to_guides/rail) (.rail)
    规范，以强制 LLM 输出的特定规则，并为 LLM API 调用提供轻量级的包装器。为了理解 Guardrails AI 的工作原理，我们首先需要了解 RAIL
    规范，这是护栏的核心。
- en: '**RAIL (Reliable AI Markup Language)**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**RAIL（可靠的AI标记语言）**'
- en: 'RAIL is a language-agnostic and human-readable format for specifying specific
    rules and corrective actions for LLM outputs. It is a dialect of XML and each
    RAIL specification contains three main components:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: RAIL 是一种与语言无关且人类可读的格式，用于指定 LLM 输出的特定规则和纠正措施。它是一种 XML 方言，每个 RAIL 规范包含三个主要组成部分：
- en: '**Output**: This component contains information about the expected response
    of the AI application. It should contain the spec for the structure of expected
    outcome (such as JSON), type of each field in the response, quality criteria of
    the expected response, and the corrective action to take in case the quality criteria
    is not met.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**输出**：该组件包含关于 AI 应用程序期望响应的信息。它应包含预期结果的结构规范（如 JSON）、响应中每个字段的类型、预期响应的质量标准，以及在未满足质量标准时采取的纠正措施。'
- en: '**Prompt**: This component is simply the prompt template for the LLM and contains
    the high-level pre-prompt instructions that are sent to an LLM application.'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**提示**：这个组件只是 LLM 的提示模板，包含发送给 LLM 应用程序的高层次预提示指令。'
- en: '**Script**: This optional component can be used to implement any custom code
    for the schema. This is especially useful for implementing custom validators and
    custom corrective actions.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**脚本**：这个可选组件可以用于实现任何自定义代码以适应架构。对于实现自定义验证器和自定义纠正措施，这尤其有用。'
- en: Let’s look at an example RAIL specification from [the Guardrails docs](https://github.com/guardrails-ai/guardrails/blob/main/docs/examples/syntax_error_free_sql.ipynb)
    that tries to generate bug-free SQL code given a natural language description
    of the problem.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看来自[Guardrails 文档](https://github.com/guardrails-ai/guardrails/blob/main/docs/examples/syntax_error_free_sql.ipynb)的一个
    RAIL 规范示例，该示例尝试根据自然语言描述生成无错误的 SQL 代码。
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The code example above defines a RAIL spec where the output is a bug-free generated
    SQL instruction. Whenever the output criteria fails on bug, the LLM simply re-asks
    the prompt and generates an improved answer.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码示例定义了一个 RAIL 规范，其中输出是一个无错误生成的 SQL 指令。每当输出标准出现错误时，LLM 会重新提问并生成改进的答案。
- en: In order to create a guardrail with this RAIL spec, the Guardrails AI docs [then
    suggest](https://github.com/guardrails-ai/guardrails/blob/main/docs/examples/syntax_error_free_sql.ipynb)
    creating a **guard object** that will be sent to the LLM API call.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用这个 RAIL 规范创建一个保护措施，Guardrails AI 文档[建议](https://github.com/guardrails-ai/guardrails/blob/main/docs/examples/syntax_error_free_sql.ipynb)创建一个**guard
    object**，该对象将被发送到 LLM API 调用中。
- en: '[PRE1]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: After the guard object is created, what happens under the hood is that the object
    creates a base prompt that will be sent to the LLM. This base prompt starts with
    the prompt definition in the RAIL spec and then provides the XML output definition
    and instructs the LLM to **only** return a valid JSON object as the output.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建 guard object 后，发生的事情是该对象创建了一个基础提示，将发送到 LLM。这个基础提示以 RAIL 规范中的提示定义开始，然后提供
    XML 输出定义，并指示 LLM**仅**返回一个有效的 JSON 对象作为输出。
- en: 'Here is the specific instruction that the package uses in order to incorporate
    the RAIL spec into an LLM prompt:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这是该软件包用来将 RAIL 规范纳入 LLM 提示的具体指令：
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: After finalizing the guard object, all you have to do is to [wrap your LLM API
    call](https://docs.getguardrails.ai/examples/syntax_error_free_sql/#step-3-wrap-the-llm-api-call-with-guard)
    with the guard wrapper. The guard wrapper will then return the **raw_llm_response**
    as well as the validated and corrected output that is a dictionary.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在最终确定 guard object 后，你需要做的就是[用 guard wrapper 包装你的 LLM API 调用](https://docs.getguardrails.ai/examples/syntax_error_free_sql/#step-3-wrap-the-llm-api-call-with-guard)。guard
    wrapper 将返回**raw_llm_response**以及经过验证和纠正的输出，它是一个字典。
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: If you want to use Guardrails AI with LangChain, you can [use the existing integration](https://github.com/langchain-ai/langchain/blob/master/templates/guardrails-output-parser/guardrails_output_parser/chain.py)
    by creating a **GuardrailsOutputParser***.*
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在 LangChain 中使用 Guardrails AI，你可以通过创建一个**GuardrailsOutputParser**来[使用现有的集成](https://github.com/langchain-ai/langchain/blob/master/templates/guardrails-output-parser/guardrails_output_parser/chain.py)。
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Then, you can simply create a LangChain PromptTemplate from this output parser.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以从这个输出解析器中简单地创建一个 LangChain PromptTemplate。
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Overall, Guardrails AI provides a lot of flexibility in terms of correcting
    the output of an LLM application. If you are familiar with XML and want to test
    out LLM guardrails, it’s worth checking out!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，Guardrails AI 在纠正 LLM 应用程序输出方面提供了很大的灵活性。如果你熟悉 XML 并想测试 LLM guardrails，值得一试！
- en: NVIDIA NeMo-Guardrails
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NVIDIA NeMo-Guardrails
- en: '[NeMo Guardrails](https://blogs.nvidia.com/blog/2023/04/25/ai-chatbot-guardrails-nemo/)
    is another open-source toolkit developed by NVIDIA that provides programmatic
    guardrails to LLM systems. The core idea of NVIDIA NeMo guardrails is the ability
    to create rails in conversational systems and prevent LLM-powered applications
    from engaging in specific discussions on unwanted topics. Another main benefit
    of NeMo is the ability to connect models, chains, services, and more with actions
    seamlessly and securely.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[NeMo Guardrails](https://blogs.nvidia.com/blog/2023/04/25/ai-chatbot-guardrails-nemo/)
    是 NVIDIA 开发的另一个开源工具包，提供程序化的 LLM 系统 guardrails。NVIDIA NeMo guardrails 的核心思想是能够在对话系统中创建
    rails，防止 LLM 驱动的应用程序参与不想要的讨论。NeMo 的另一个主要好处是能够无缝且安全地连接模型、链、服务等与操作。'
- en: In order to configure guardrails for LLMs, this [open-source toolkit introduces](https://github.com/NVIDIA/NeMo-Guardrails/blob/develop/docs/user_guides/colang-language-syntax-guide.md)
    a modeling language called Colang that is specifically designed for creating flexible
    and controllable conversational workflows. Per the docs, “Colang has a ‘pythonic’
    syntax in the sense that most constructs resemble their python equivalent and
    indentation is used as a syntactic element.”
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了配置 LLM 的 guardrails，这个 [开源工具包介绍了](https://github.com/NVIDIA/NeMo-Guardrails/blob/develop/docs/user_guides/colang-language-syntax-guide.md)
    一种称为 Colang 的建模语言，专门设计用于创建灵活且可控的对话工作流。根据文档，“Colang 具有‘pythonic’语法，大多数构造类似于其 Python
    对应物，并且使用缩进作为语法元素。”
- en: Before we dive into NeMo guardrails implementation, it is important to understand
    the syntax of this new modeling language for LLM guardrails.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解 NeMo guardrails 实现之前，了解这一新的 LLM guardrails 建模语言的语法非常重要。
- en: '**Core Syntax Elements**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**核心语法元素**'
- en: '[The NeMo docs](https://docs.nvidia.com/nemo/guardrails/user_guides/colang-language-syntax-guide.html)’
    examples below break out the core syntax elements of Colang — blocks, statements,
    expressions, keywords and variables — along with the three main types of blocks
    (user message blocks, flow blocks, and bot message blocks) with these examples.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[NeMo 文档](https://docs.nvidia.com/nemo/guardrails/user_guides/colang-language-syntax-guide.html)下面的示例详细说明了
    Colang 的核心语法元素——块、语句、表达式、关键字和变量——以及这三个主要类型的块（用户消息块、流程块和机器人消息块）的示例。'
- en: User message definition blocks set up the standard message linked to different
    things users might say.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 用户消息定义块设置与用户可能说的不同内容相关的标准消息。
- en: '[PRE7]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Bot message definition blocks determine the phrases that should be linked to
    different standard bot messages.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 机器人消息定义块确定应该与不同标准机器人消息相关联的短语。
- en: '[PRE8]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Flows show the way you want the chat to progress. They include a series of user
    and bot messages, and potentially other events.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 流程展示了你希望聊天如何进行。它们包括一系列用户和机器人消息，以及可能的其他事件。
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Per the [docs](https://github.com/NVIDIA/NeMo-Guardrails/blob/develop/docs/user_guides/colang-language-syntax-guide.md),
    “references to context variables always start with a $ sign e.g. $name. All variables
    are global and accessible in all flows.”
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 [文档](https://github.com/NVIDIA/NeMo-Guardrails/blob/develop/docs/user_guides/colang-language-syntax-guide.md)，
    “对上下文变量的引用总是以 $ 符号开始，例如 $name。所有变量都是全局的，并且在所有流程中都可访问。”
- en: '[PRE10]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Also worth noting: “expressions can be used to set values for context variables”
    and “actions are custom functions available to be invoked from flows.”'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 还值得注意的是：“可以使用表达式为上下文变量设置值”和“动作是可从流程中调用的自定义函数。”
- en: '![](../Images/a5654488b2164fa8ae6c6f95944145c5.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a5654488b2164fa8ae6c6f95944145c5.png)'
- en: Diagram by author
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 作者绘制的图表
- en: 'Now that we have a better handle of Colang syntax, let’s briefly go over how
    the NeMo architecture works. As seen above, the guardrails package is built with
    an event-driven design architecture. Based on specific events, there is a sequential
    procedure that needs to be completed before the final output is provided to the
    user. This process has three main stages:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对 Colang 语法有了更好的掌握，让我们简要了解一下 NeMo 架构的工作原理。如上所述，guardrails 包采用了事件驱动的设计架构。基于特定事件，需要完成一个顺序过程，然后才能将最终输出提供给用户。此过程分为三个主要阶段：
- en: Generate canonical user messages
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成规范的用户消息
- en: Decide on next step(s) and execute them
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决定下一步并执行
- en: Generate bot utterances
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成机器人发言
- en: Each of the above stages can involve one or more calls to the LLM. In the first
    stage, a canonical form is created regarding the user’s intent and allows the
    system to trigger any specific next steps. The user intent action will do a vector
    search on all the canonical form examples in existing configuration, retrieve
    the top five examples and create a prompt that asks the LLM to create the canonical
    user intent.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 上述每个阶段可能涉及对 LLM 的一次或多次调用。在第一阶段，会根据用户意图创建一个规范形式，并允许系统触发任何特定的后续步骤。用户意图动作将对现有配置中的所有规范形式示例进行向量搜索，检索前五个示例，并创建一个提示，要求
    LLM 创建规范的用户意图。
- en: Once the intent event is created, depending on the canonical form, the LLM either
    goes through a pre-defined flow for the next step or another LLM is used to decide
    the next step. When an LLM is used, another vector search is performed for the
    most relevant flows and again the top five flows are retrieved in order for the
    LLM to predict the next step. Once the next step is determined, a *bot_intent*
    event is created so that the bot says something and then executes action with
    the *start_action* event.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦意图事件被创建，根据规范形式，LLM 要么按照预定义的流程进行下一步操作，要么使用另一个 LLM 决定下一步操作。当使用 LLM 时，再次进行向量搜索以找到最相关的流程，然后检索前五个流程，以便
    LLM 预测下一步。一旦确定了下一步，创建一个 *bot_intent* 事件，使机器人说一些内容，然后用 *start_action* 事件执行操作。
- en: The *bot_intent* event then invokes the final step to generate bot utterances.
    Similar to previous stages, the *generate_bot_message* is triggered and a vector
    search is performed to find the most relevant bot utterance examples. At the end,
    a *bot_said* event is triggered and the final response is returned to the user.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*bot_intent* 事件随后会触发最终步骤以生成机器人的发言。类似于之前的阶段，*generate_bot_message* 被触发，进行向量搜索以找到最相关的机器人发言示例。最后，触发
    *bot_said* 事件，将最终回应返回给用户。'
- en: '**Example Guardrails Configuration**'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例护栏配置**'
- en: Now, let’s look at an example of a simple NeMo guardrails bot adapted [from
    the NeMo docs](https://github.com/NVIDIA/NeMo-Guardrails/blob/develop/docs/getting_started/1_hello_world/README.md).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看一个简单的 NeMo 护栏机器人的示例，改编自 [NeMo 文档](https://github.com/NVIDIA/NeMo-Guardrails/blob/develop/docs/getting_started/1_hello_world/README.md)。
- en: Let’s assume that we want to build a bot that does not respond to political
    or stock market questions. The first step is to [install](https://github.com/NVIDIA/NeMo-Guardrails/blob/main/docs/getting_started/installation-guide.md)
    the NeMo Guardrails toolkit and specify the configurations defined in the documentation.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想构建一个不会回应政治或股市问题的机器人。第一步是 [安装](https://github.com/NVIDIA/NeMo-Guardrails/blob/main/docs/getting_started/installation-guide.md)
    NeMo Guardrails 工具包，并指定文档中定义的配置。
- en: After that, we define the canonical forms for the user and bot messages.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们定义用户和机器人的消息的规范形式。
- en: '[PRE11]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Then, we define the dialog flows in order to guide the bot in the right direction
    throughout the conversation. Depending on the user’s response, you can even extend
    the flow to respond appropriately.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们定义对话流程，以指导机器人在整个对话中朝着正确的方向前进。根据用户的响应，您甚至可以扩展流程以作出适当的回应。
- en: '[PRE12]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Finally, we define the rails to prevent the bot from responding to certain
    topics. We first define the canonical forms:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们定义护栏以防止机器人回应某些话题。我们首先定义规范形式：
- en: '[PRE13]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Then, we define the dialog flows so that the bot simply informs the user that
    it can respond to certain topics.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们定义对话流程，使机器人简单地告知用户它可以回应某些话题。
- en: '[PRE14]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '**LangChain Support**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**LangChain 支持**'
- en: Finally, if you would like to use LangChain, you can easily add your guardrails
    on top of existing chains. For example, you can integrate a RetrievalQA chain
    for questions answering next to a basic guardrail against insults, as shown below
    (example code below adapted from [source](https://github.com/NVIDIA/NeMo-Guardrails/blob/main/examples/demo_chain_with_guardrails.py)).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果您想使用 LangChain，可以很容易地在现有链的基础上添加护栏。例如，您可以将一个 RetrievalQA 链集成到一个针对侮辱的基本护栏旁边，如下所示（示例代码改编自
    [source](https://github.com/NVIDIA/NeMo-Guardrails/blob/main/examples/demo_chain_with_guardrails.py)）。
- en: '[PRE15]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Comparing Guardrails AI and NeMo Guardrails
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较 Guardrails AI 和 NeMo Guardrails
- en: When the Guardrails AI and NeMo packages are compared, each has its own unique
    benefits and limitations. Both packages provide real-time guardrails for any LLM
    application and support LlamaIndex or LangChain for orchestration.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在比较 Guardrails AI 和 NeMo 包时，每个都有其独特的优点和限制。这两个包都提供了对任何 LLM 应用的实时护栏，并支持 LlamaIndex
    或 LangChain 进行协调。
- en: If you are comfortable with XML syntax and want to test out the concept of guardrails
    within a notebook for simple output moderation and formatting, Guardrails AI can
    be a great choice. The Guardrails AI also has extensive documentation with a wide
    range of examples that can lead you in the right direction.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对XML语法感到舒适，并希望在笔记本中测试保护措施的概念，以进行简单的输出审核和格式化，Guardrails AI可能是一个不错的选择。Guardrails
    AI还提供了广泛的文档和多种示例，可以引导你朝着正确的方向前进。
- en: However, if you would like to productionize your LLM application and you would
    like to define advanced conversational guidelines and policies for your flows,
    NeMo guardrails might be a good package to check out. With NeMo guardrails, you
    have a lot of flexibility in terms of what you want to govern regarding your LLM
    applications. By defining different dialog flows and custom bot actions, you can
    create any type of guardrails for your AI models.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你想将LLM应用程序投入生产，并希望为你的流程定义高级对话指南和策略，NeMo保护措施可能是一个值得检查的好软件包。使用NeMo保护措施，你可以在管理LLM应用程序方面有很大的灵活性。通过定义不同的对话流程和自定义机器人动作，你可以为你的AI模型创建任何类型的保护措施。
- en: One Perspective
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个视角
- en: Based on our experience implementing guardrails for an internal product docs
    chatbot in our organization, we would suggest using NeMo guardrails for moving
    to production. Even though lack of extensive documentation can be a challenge
    to onboard the tool into your LLM infrastructure stack, the flexibility of the
    package in terms of defining restricted user flows really helped our user experience.
    By defining specific flows for different capabilities of our platform, the question-answering
    service we created started to be actively used by our customer success engineers.
    By using NeMo guardrails, we were also able to understand the lack of documentation
    for certain features much more easily and improve our documentation in a way that
    helps the whole conversation flow as a whole.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们在组织内实现保护措施用于内部产品文档聊天机器人的经验，我们建议使用NeMo保护措施来推进生产。尽管缺乏广泛的文档可能会成为将工具纳入你的LLM基础设施堆栈的挑战，但该软件包在定义受限用户流程方面的灵活性确实改善了我们的用户体验。通过为平台的不同功能定义特定流程，我们创建的问答服务开始被我们的客户成功工程师积极使用。使用NeMo保护措施，我们还能够更容易地理解某些功能缺乏文档的情况，并改进我们的文档，从而帮助整个对话流程。
- en: Once you settle on a framework, a few best practices are worth keeping in mind.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你确定了一个框架，值得牢记一些最佳实践。
- en: First, it is important to not develop an over-reliance on guards lest you lose
    the meaning of a user’s initial request or the utility from the app’s output.
    Being judicious in adding new guards and leveraging [similarity search](https://www.youtube.com/watch?v=K532ZClP-xQ)
    to find new clusters of problematic inputs can help in figuring out what guards
    to add over time. As always, cost and latency are also a factor. Leveraging small
    language models for auxiliary calls can help.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，重要的是不要对保护措施过度依赖，以免失去用户初始请求的意义或应用程序输出的实用性。谨慎地添加新保护措施，并利用[相似性搜索](https://www.youtube.com/watch?v=K532ZClP-xQ)来找到新的问题输入集群，有助于随着时间推移确定要添加的保护措施。像往常一样，成本和延迟也是一个因素。利用小型语言模型进行辅助调用可以有所帮助。
- en: 'It’s also worth considering **dynamic guards**. Few-shot prompting — which
    improves guard recognition by adding recent attack examples to the prompt — and
    embedding-based guards, which compare input embeddings against known attack patterns
    and block those that exceed a similarity threshold, can help teams facing sophisticated
    prompt injection or jailbreak attempts (full disclosure: I lead a company that
    offers an open source embeddings-based guard).'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 同样值得考虑的是**动态保护措施**。少量提示——通过将近期攻击示例添加到提示中来提高保护识别——以及基于嵌入的保护措施，这些措施将输入嵌入与已知攻击模式进行比较，阻止那些超过相似性阈值的内容，可以帮助面对复杂的提示注入或越狱尝试的团队（完全披露：我领导一家公司，提供开源基于嵌入的保护措施）。
- en: '![](../Images/51c4a361b0bcf3365c2a7bb268ff0b9f.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/51c4a361b0bcf3365c2a7bb268ff0b9f.png)'
- en: Diagram by author
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图示
- en: Conclusion
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: As enterprises and startups alike embrace the power of large language models
    to revolutionize everything from [retrieval augmented generation](https://arize.com/blog-course/introduction-to-retrieval-augmented-generation/)
    to summarization and chat-to-purchase, having effective guardrails in place is
    likely to be mission-critical — particularly in highly-regulated industries like
    finance or healthcare where real-world harm is possible.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 随着企业和初创公司都在利用大型语言模型的力量，彻底改变从 [检索增强生成](https://arize.com/blog-course/introduction-to-retrieval-augmented-generation/)
    到总结和聊天购买等各个方面，拥有有效的保护措施可能会成为任务关键，特别是在像金融或医疗这样的高度监管行业中，实际伤害的可能性很高。
- en: Luckily, open-source Python packages like Guardrails AI and NeMo Guardrails
    provide a great [starting point](https://arize.com/blog-course/guardrails-what-are-they-and-how-can-you-use-nemo-and-guardrails-ai-to-safeguard-llms/).
    By setting programmable, rule-based systems to guide user interactions with LLMs,
    developers can ensure compliance with defined principles.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，像 Guardrails AI 和 NeMo Guardrails 这样的开源 Python 包提供了一个很好的 [起点](https://arize.com/blog-course/guardrails-what-are-they-and-how-can-you-use-nemo-and-guardrails-ai-to-safeguard-llms/)。通过设置可编程的、基于规则的系统来引导用户与
    LLMs 的互动，开发者可以确保符合定义的原则。
