- en: Hyperparameter Optimization With Hyperopt — Intro & Implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/hyperparameter-optimization-with-hyperopt-intro-implementation-dfc1c54d0ba7?source=collection_archive---------2-----------------------#2023-06-05](https://towardsdatascience.com/hyperparameter-optimization-with-hyperopt-intro-implementation-dfc1c54d0ba7?source=collection_archive---------2-----------------------#2023-06-05)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Improving machine learning models’ performance with hyperparameter optimization.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@fmnobar?source=post_page-----dfc1c54d0ba7--------------------------------)[![Farzad
    Mahmoodinobar](../Images/2d75209693b712300e6f0796bd2487d0.png)](https://medium.com/@fmnobar?source=post_page-----dfc1c54d0ba7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dfc1c54d0ba7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dfc1c54d0ba7--------------------------------)
    [Farzad Mahmoodinobar](https://medium.com/@fmnobar?source=post_page-----dfc1c54d0ba7--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3c56b7d4893e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-optimization-with-hyperopt-intro-implementation-dfc1c54d0ba7&user=Farzad+Mahmoodinobar&userId=3c56b7d4893e&source=post_page-3c56b7d4893e----dfc1c54d0ba7---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----dfc1c54d0ba7--------------------------------)
    ·11 min read·Jun 5, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdfc1c54d0ba7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-optimization-with-hyperopt-intro-implementation-dfc1c54d0ba7&user=Farzad+Mahmoodinobar&userId=3c56b7d4893e&source=-----dfc1c54d0ba7---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdfc1c54d0ba7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-optimization-with-hyperopt-intro-implementation-dfc1c54d0ba7&source=-----dfc1c54d0ba7---------------------bookmark_footer-----------)![](../Images/ba34fe1074371d14f74e66344336a40b.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Te NGuyen](https://unsplash.com/@tenguyen?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/Wt7XT1R6sjU?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: '[Hyperopt](https://github.com/hyperopt/hyperopt) is an open-source hyperparameter
    optimization tool that I personally use to improve my machine learning projects
    and have found it to be quite easy to implement. Hyperparameter optimization,
    is the process of identifying the best combination of hyperparameters for a machine
    learning model to satisfy an objective function (this is usually defined as “minimizing”
    the objective function for consistency). To use a different analogy, each machine
    learning model comes with various knobs and levers that we can tune, until we
    get the outcome that we have been looking for from the model. The act of finding
    the right combination of hyperparameters that results in the outcome that we have
    been looking for is called hyperparameter optimization. Some examples of such
    parameters are: learning rate, architecture of a neural network (e.g. number of
    hidden layers), choice of the optimizer, etc.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are interested in exploring other hyperparameter optimization strategies,
    such as grid search, random search and bayesian optimization, check out the post
    below:'
  prefs: []
  type: TYPE_NORMAL
