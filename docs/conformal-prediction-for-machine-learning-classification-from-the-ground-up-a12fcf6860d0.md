# æœºå™¨å­¦ä¹ åˆ†ç±»ä¸­çš„ç¬¦åˆé¢„æµ‹â€”â€”ä»åŸºç¡€å¼€å§‹

> åŸæ–‡ï¼š[`towardsdatascience.com/conformal-prediction-for-machine-learning-classification-from-the-ground-up-a12fcf6860d0?source=collection_archive---------1-----------------------#2023-11-24`](https://towardsdatascience.com/conformal-prediction-for-machine-learning-classification-from-the-ground-up-a12fcf6860d0?source=collection_archive---------1-----------------------#2023-11-24)

## å®ç°åˆ†ç±»çš„ç¬¦åˆé¢„æµ‹ï¼Œæ— éœ€å®šåˆ¶è½¯ä»¶åŒ…ï¼Œä»¥åŠå¦‚ä½•åœ¨å„ç±»åˆ«ä¹‹é—´å¹³è¡¡è¦†ç›–ç‡ï¼ˆå¬å›ç‡ï¼‰

[](https://medium.com/@michael.allen1966?source=post_page-----a12fcf6860d0--------------------------------)![è¿ˆå…‹å°”Â·è‰¾ä¼¦](https://medium.com/@michael.allen1966?source=post_page-----a12fcf6860d0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a12fcf6860d0--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----a12fcf6860d0--------------------------------) [è¿ˆå…‹å°”Â·è‰¾ä¼¦](https://medium.com/@michael.allen1966?source=post_page-----a12fcf6860d0--------------------------------)

Â·

[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F82abbb73efe6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconformal-prediction-for-machine-learning-classification-from-the-ground-up-a12fcf6860d0&user=Michael+Allen&userId=82abbb73efe6&source=post_page-82abbb73efe6----a12fcf6860d0---------------------post_header-----------) å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a12fcf6860d0--------------------------------) Â·11 min readÂ·2023 å¹´ 11 æœˆ 24 æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa12fcf6860d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconformal-prediction-for-machine-learning-classification-from-the-ground-up-a12fcf6860d0&user=Michael+Allen&userId=82abbb73efe6&source=-----a12fcf6860d0---------------------clap_footer-----------)

--

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa12fcf6860d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconformal-prediction-for-machine-learning-classification-from-the-ground-up-a12fcf6860d0&source=-----a12fcf6860d0---------------------bookmark_footer-----------)

è¿™ç¯‡åšå®¢æ–‡ç« çš„çµæ„Ÿæ¥è‡ªå…‹é‡Œæ–¯Â·è«å°”çº³ï¼ˆChris Molnerï¼‰çš„ä¹¦â€”â€”[ã€Šç¬¦åˆé¢„æµ‹ç®€ä»‹ã€‹ï¼ˆIntroduction to Conformal Predictionï¼‰](https://christophmolnar.com/books/conformal-prediction/)ä¸ Pythonã€‚å…‹é‡Œæ–¯æ“…é•¿å°†æ–°çš„æœºå™¨å­¦ä¹ æŠ€æœ¯å‘ˆç°ç»™ä»–äººã€‚æˆ‘ç‰¹åˆ«æ¨èä»–å…³äºå¯è§£é‡Šæœºå™¨å­¦ä¹ çš„ä¹¦ç±ã€‚

å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°å¸¦æœ‰å®Œæ•´ä»£ç ï¼ˆä»¥åŠåœ¨çº¿è¿è¡Œä»£ç çš„é“¾æ¥ï¼‰çš„ GitHub ä»“åº“ï¼š[ç¬¦åˆé¢„æµ‹](https://github.com/MichaelAllen1966/conformal_prediction)ã€‚

# **ä»€ä¹ˆæ˜¯ç¬¦åˆé¢„æµ‹ï¼Ÿ**

ç¬¦åˆé¢„æµ‹æ—¢æ˜¯ä¸ç¡®å®šæ€§é‡åŒ–çš„ä¸€ç§æ–¹æ³•ï¼Œä¹Ÿæ˜¯åˆ†ç±»å®ä¾‹çš„ä¸€ç§æ–¹æ³•ï¼ˆå¯ä»¥ä¸ºç±»åˆ«æˆ–å­ç»„è¿›è¡Œå¾®è°ƒï¼‰ã€‚ä¸ç¡®å®šæ€§é€šè¿‡å°†åˆ†ç±»è¡¨ç¤ºä¸ºæ½œåœ¨ç±»åˆ«çš„é›†åˆè€Œä¸æ˜¯å•ä¸ªé¢„æµ‹æ¥ä¼ è¾¾ã€‚

ç¬¦åˆé¢„æµ‹æŒ‡å®šäº†*è¦†ç›–ç‡*ï¼Œè¯¥è¦†ç›–ç‡æŒ‡å®šäº†çœŸå®ç»“æœè¢«é¢„æµ‹åŒºåŸŸè¦†ç›–çš„æ¦‚ç‡ã€‚åœ¨ç¬¦åˆé¢„æµ‹ä¸­ï¼Œé¢„æµ‹åŒºåŸŸçš„è§£é‡Šå–å†³äºä»»åŠ¡ã€‚å¯¹äºåˆ†ç±»ï¼Œæˆ‘ä»¬å¾—åˆ°é¢„æµ‹é›†ï¼Œè€Œå¯¹äºå›å½’ï¼Œæˆ‘ä»¬å¾—åˆ°é¢„æµ‹åŒºé—´ã€‚

ä¸‹é¢æ˜¯ä¼ ç»Ÿåˆ†ç±»ï¼ˆæœ€å¯èƒ½ç±»åˆ«çš„å¹³è¡¡ï¼‰å’Œç¬¦åˆé¢„æµ‹ï¼ˆé›†åˆï¼‰ä¹‹é—´å·®å¼‚çš„ç¤ºä¾‹ã€‚

![](img/db455810fcc3fac08b3ad198877d9226.png)

åŸºäºæœ€å¯èƒ½ç±»åˆ«çš„â€œæ­£å¸¸â€åˆ†ç±»å’Œåˆ›å»ºå¯èƒ½ç±»åˆ«é›†çš„ç¬¦åˆé¢„æµ‹ä¹‹é—´çš„åŒºåˆ«ã€‚

æ­¤æ–¹æ³•çš„ä¼˜ç‚¹åŒ…æ‹¬ï¼š

+   **ä¿è¯è¦†ç›–ç‡**ï¼šç¬¦åˆé¢„æµ‹ç”Ÿæˆçš„é¢„æµ‹é›†å…·æœ‰çœŸå®ç»“æœçš„è¦†ç›–ä¿è¯ â€” å³å®ƒä»¬å°†æ£€æµ‹åˆ°ä½ è®¾ç½®ä¸ºæœ€å°ç›®æ ‡è¦†ç›–ç‡çš„ä»»ä½•çœŸå®å€¼ç™¾åˆ†æ¯”ã€‚ç¬¦åˆé¢„æµ‹ä¸ä¾èµ–äºè‰¯å¥½æ ¡å‡†çš„æ¨¡å‹ â€” å”¯ä¸€é‡è¦çš„æ˜¯ï¼Œåƒæ‰€æœ‰æœºå™¨å­¦ä¹ ä¸€æ ·ï¼Œè¢«åˆ†ç±»çš„æ–°æ ·æœ¬å¿…é¡»æ¥è‡ªäºä¸è®­ç»ƒå’Œæ ¡å‡†æ•°æ®ç±»ä¼¼çš„æ•°æ®åˆ†å¸ƒã€‚è¦†ç›–ç‡è¿˜å¯ä»¥åœ¨ç±»åˆ«æˆ–å­ç»„ä¹‹é—´ä¿è¯ï¼Œå°½ç®¡è¿™éœ€è¦æ–¹æ³•ä¸­çš„é¢å¤–æ­¥éª¤ï¼Œæˆ‘ä»¬å°†ä»‹ç»ã€‚

+   **æ˜“äºä½¿ç”¨**ï¼šç¬¦åˆé¢„æµ‹æ–¹æ³•å¯ä»¥ä»å¤´å¼€å§‹å®ç°ï¼Œåªéœ€å‡ è¡Œä»£ç ï¼Œæˆ‘ä»¬å°†åœ¨è¿™é‡Œåšã€‚

+   **æ¨¡å‹æ— å…³**ï¼šç¬¦åˆé¢„æµ‹é€‚ç”¨äºä»»ä½•æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚å®ƒä½¿ç”¨ä½ åå¥½çš„æ¨¡å‹çš„æ­£å¸¸è¾“å‡ºã€‚

+   **æ— åˆ†å¸ƒå‡è®¾**ï¼šç¬¦åˆé¢„æµ‹å¯¹æ•°æ®çš„æ½œåœ¨åˆ†å¸ƒä¸åšä»»ä½•å‡è®¾ï¼›å®ƒæ˜¯ä¸€ç§éå‚æ•°æ–¹æ³•ã€‚

+   **æ— éœ€é‡æ–°è®­ç»ƒ**ï¼šç¬¦åˆé¢„æµ‹å¯ä»¥åœ¨ä¸é‡æ–°è®­ç»ƒæ¨¡å‹çš„æƒ…å†µä¸‹ä½¿ç”¨ã€‚è¿™æ˜¯æŸ¥çœ‹å’Œä½¿ç”¨æ¨¡å‹è¾“å‡ºçš„å¦ä¸€ç§æ–¹å¼ã€‚

+   **å¹¿æ³›åº”ç”¨**ï¼šç¬¦åˆé¢„æµ‹é€‚ç”¨äºè¡¨æ ¼æ•°æ®åˆ†ç±»ã€å›¾åƒæˆ–æ—¶é—´åºåˆ—åˆ†ç±»ã€å›å½’ç­‰å¤šç§ä»»åŠ¡ï¼Œå°½ç®¡æˆ‘ä»¬åœ¨è¿™é‡Œåªå±•ç¤ºåˆ†ç±»ã€‚

# **ä¸ºä»€ä¹ˆæˆ‘ä»¬è¦å…³å¿ƒä¸ç¡®å®šæ€§é‡åŒ–ï¼Ÿ**

ä¸ç¡®å®šæ€§é‡åŒ–åœ¨è®¸å¤šæƒ…å†µä¸‹è‡³å…³é‡è¦ï¼š

+   å½“æˆ‘ä»¬ä½¿ç”¨æ¨¡å‹é¢„æµ‹åšå‡ºå†³ç­–æ—¶ï¼Œæˆ‘ä»¬å¯¹è¿™äº›é¢„æµ‹æœ‰å¤šç¡®å®šï¼Ÿä»…ä»…ä½¿ç”¨â€œæœ€å¯èƒ½çš„ç±»åˆ«â€å¯¹æˆ‘ä»¬çš„ä»»åŠ¡æ˜¯å¦è¶³å¤Ÿå¥½ï¼Ÿ

+   å½“æˆ‘ä»¬å¸Œæœ›å‘åˆ©ç›Šç›¸å…³è€…ä¼ è¾¾ä¸æˆ‘ä»¬çš„é¢„æµ‹ç›¸å…³çš„ä¸ç¡®å®šæ€§æ—¶ï¼Œè€Œä¸è°ˆè®ºæ¦‚ç‡ã€èµ”ç‡ç”šè‡³å¯¹æ•°èµ”ç‡ï¼

# **ç¬¦åˆé¢„æµ‹ä¸­çš„ Alpha â€” æè¿°** *è¦†ç›–èŒƒå›´*

*è¦†ç›–èŒƒå›´*æ˜¯ç¬¦åˆé¢„æµ‹çš„å…³é”®ã€‚åœ¨åˆ†ç±»ä¸­ï¼Œå®ƒæ˜¯ç‰¹å®šç±»åˆ«æ‰€å æ®çš„æ•°æ®çš„æ­£å¸¸åŒºåŸŸã€‚è¦†ç›–èŒƒå›´ç­‰åŒäº*æ•æ„Ÿæ€§*æˆ–*å¬å›ç‡*ï¼›å®ƒæ˜¯åˆ†ç±»é›†ä¸­è¢«è¯†åˆ«çš„è§‚å¯Ÿå€¼çš„æ¯”ä¾‹ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡è°ƒæ•´ğ›¼ï¼ˆ*è¦†ç›–èŒƒå›´ = 1 â€”* ğ›¼ï¼‰æ¥æ”¶ç´§æˆ–æ”¾å®½è¦†ç›–åŒºåŸŸã€‚

# è®©æˆ‘ä»¬å¼€å§‹ç¼–ç¨‹å§ï¼

## å¯¼å…¥åŒ…

```py
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.datasets import make_blobs
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
```

## **ä¸ºåˆ†ç±»åˆ›å»ºåˆæˆæ•°æ®**

ç¤ºä¾‹æ•°æ®å°†ä½¿ç”¨ SK-Learn çš„`make_blobs`æ–¹æ³•ç”Ÿæˆã€‚

```py
n_classes = 3
# Make train and test data
X, y = make_blobs(n_samples=10000, n_features=2, centers=n_classes, cluster_std=3.75, random_state=42)

# Reduce the size of the first class to create an imbalanced dataset

# Set numpy random seed
np.random.seed(42)
# Get index of when y is class 0
class_0_idx = np.where(y == 0)[0]
# Get 30% of the class 0 indices
class_0_idx = np.random.choice(class_0_idx, int(len(class_0_idx) * 0.3), replace=False)
# Get the index for all other classes
rest_idx = np.where(y != 0)[0]
# Combine the indices
idx = np.concatenate([class_0_idx, rest_idx])
# Shuffle the indices
np.random.shuffle(idx)
# Split the data
X = X[idx]
y = y[idx]

# Split off model training set
X_train, X_rest, y_train, y_rest = train_test_split(X, y, test_size=0.5, random_state=42)
# Split rest into calibration and test
X_Cal, X_test, y_cal, y_test = train_test_split(X_rest, y_rest, test_size=0.5, random_state=42)

# Set class labels
class_labels = ['blue', 'orange', 'green']
```

```py
# Plot the data
fig = plt.subplots(figsize=(5, 5))
ax = plt.subplot(111)
for i in range(n_classes):
    ax.scatter(X_test[y_test == i, 0], X_test[y_test == i, 1], label=class_labels[i], alpha=0.5, s=10)
legend = ax.legend()
legend.set_title("Class")
ax.set_xlabel("Feature 1")
ax.set_ylabel("Feature 2")
plt.show()
```

![](img/6ffd685be074b4e5c58e77947acd8a3b.png)

ç”Ÿæˆçš„æ•°æ®ï¼ˆè¿™äº›æ•°æ®è¢«åˆ›å»ºä¸ºä¸å¹³è¡¡â€”â€”è“è‰²ç±»åˆ«çš„æ•°æ®ç‚¹ä»…å ç»¿è‰²æˆ–æ©™è‰²ç±»åˆ«çš„çº¦ 30%ï¼‰ã€‚

## **æ„å»ºåˆ†ç±»å™¨**

æˆ‘ä»¬å°†åœ¨è¿™é‡Œä½¿ç”¨ä¸€ä¸ªç®€å•çš„é€»è¾‘å›å½’æ¨¡å‹ï¼Œä½†è¯¥æ–¹æ³•å¯ä»¥é€‚ç”¨äºä»»ä½•æ¨¡å‹ï¼Œä»åŸºäºè¡¨æ ¼æ•°æ®çš„ç®€å•é€»è¾‘å›å½’æ¨¡å‹åˆ°ç”¨äºå›¾åƒåˆ†ç±»çš„ 3D å·ç§¯ç¥ç»ç½‘ç»œã€‚

```py
# Build and train the classifier
classifier = LogisticRegression(random_state=42)
classifier.fit(X_train, y_train)

# Test the classifier
y_pred = classifier.predict(X_test)
accuracy = np.mean(y_pred == y_test)
print(f"Accuracy: {accuracy:0.3f}")

# Test recall for each class
for i in range(n_classes):
    recall = np.mean(y_pred[y_test == i] == y_test[y_test == i])
    print(f"Recall for class {class_labels[i]}: {recall:0.3f}")
```

```py
Accuracy: 0.930
Recall for class blue: 0.772
Recall for class orange: 0.938
Recall for class green: 0.969
```

æ³¨æ„å°‘æ•°ç±»çš„å¬å›ç‡ä½äºå…¶ä»–ç±»åˆ«ã€‚å¬å›ç‡ï¼Œä¹Ÿç§°ä¸ºæ•æ„Ÿæ€§ï¼Œæ˜¯åˆ†ç±»å™¨æ­£ç¡®è¯†åˆ«çš„æŸä¸€ç±»åˆ«ä¸­çš„æ•°é‡ã€‚

## S_i**ï¼Œæˆ–** *éä¸€è‡´æ€§å¾—åˆ†* **å¾—åˆ†**

åœ¨ç¬¦åˆé¢„æµ‹ä¸­ï¼Œéä¸€è‡´æ€§å¾—åˆ†ï¼Œé€šå¸¸è¡¨ç¤ºä¸º*s_i*ï¼Œæ˜¯è¡¡é‡æ–°å®ä¾‹ä¸è®­ç»ƒé›†ä¸­ç°æœ‰å®ä¾‹åå·®çš„ä¸€ä¸ªåº¦é‡ã€‚å®ƒç”¨äºç¡®å®šæ–°å®ä¾‹æ˜¯å¦å±äºç‰¹å®šç±»åˆ«ã€‚

åœ¨åˆ†ç±»çš„èƒŒæ™¯ä¸‹ï¼Œæœ€å¸¸è§çš„éä¸€è‡´æ€§åº¦é‡æ˜¯*1 â€” é¢„æµ‹ç±»åˆ«æ¦‚ç‡*ã€‚å› æ­¤ï¼Œå¦‚æœæ–°å®ä¾‹å±äºæŸä¸€ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡å¾ˆé«˜ï¼Œé‚£ä¹ˆéä¸€è‡´æ€§å¾—åˆ†å°†å¾ˆä½ï¼Œåä¹‹äº¦ç„¶ã€‚

å¯¹äºç¬¦åˆé¢„æµ‹ï¼Œæˆ‘ä»¬è·å¾—æ‰€æœ‰ç±»åˆ«çš„*s_i*å¾—åˆ†ï¼ˆæ³¨æ„ï¼šåœ¨è¿™é‡Œæˆ‘ä»¬ä»…æŸ¥çœ‹å®ä¾‹çš„çœŸå®ç±»åˆ«çš„æ¨¡å‹è¾“å‡ºï¼Œå³ä½¿é¢„æµ‹æ¦‚ç‡æ›´é«˜çš„æ˜¯å…¶ä»–ç±»åˆ«ï¼‰ã€‚ç„¶åï¼Œæˆ‘ä»¬æ‰¾åˆ°ä¸€ä¸ªå¾—åˆ†é˜ˆå€¼ï¼Œè¯¥é˜ˆå€¼åŒ…å«ï¼ˆæˆ–*è¦†ç›–*ï¼‰95%çš„æ•°æ®ã€‚åˆ†ç±»å°†è¯†åˆ« 95%çš„æ–°å®ä¾‹ï¼ˆåªè¦æˆ‘ä»¬çš„æ–°æ•°æ®ä¸è®­ç»ƒæ•°æ®ç±»ä¼¼ï¼‰ã€‚

## **è®¡ç®—ç¬¦åˆé¢„æµ‹é˜ˆå€¼**

æˆ‘ä»¬ç°åœ¨å°†é¢„æµ‹æ ¡å‡†é›†çš„åˆ†ç±»æ¦‚ç‡ã€‚è¿™å°†ç”¨äºä¸ºæ–°æ•°æ®è®¾ç½®åˆ†ç±»é˜ˆå€¼ã€‚

```py
# Get predictions for calibration set
y_pred = classifier.predict(X_Cal)
y_pred_proba = classifier.predict_proba(X_Cal)

# Show first 5 instances
y_pred_proba[0:5]
```

```py
array([[4.65677826e-04, 1.29602253e-03, 9.98238300e-01],
       [1.73428257e-03, 1.20718182e-02, 9.86193899e-01],
       [2.51649788e-01, 7.48331668e-01, 1.85434981e-05],
       [5.97545130e-04, 3.51642214e-04, 9.99050813e-01],
       [4.54193815e-06, 9.99983628e-01, 1.18300819e-05]])
```

## **è®¡ç®—éä¸€è‡´æ€§å¾—åˆ†**

æˆ‘ä»¬å°†ä»…åŸºäºè§‚å¯Ÿåˆ°çš„ç±»åˆ«ç›¸å…³æ¦‚ç‡è®¡ç®—*s_i*å¾—åˆ†ã€‚å¯¹äºæ¯ä¸ªå®ä¾‹ï¼Œæˆ‘ä»¬å°†è·å–è¯¥å®ä¾‹ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡ã€‚*s_i*å¾—åˆ†ï¼ˆéä¸€è‡´æ€§ï¼‰æ˜¯*1-æ¦‚ç‡*ã€‚*s_i*å¾—åˆ†è¶Šé«˜ï¼Œè¯¥ç¤ºä¾‹ç›¸å¯¹äºå…¶ä»–ç±»åˆ«çš„ç¬¦åˆåº¦è¶Šä½ã€‚è¿˜æœ‰å…¶ä»–è®¡ç®—éä¸€è‡´æ€§å¾—åˆ†çš„æ–¹æ³•ï¼

```py
si_scores = []
# Loop through all calibration instances
for i, true_class in enumerate(y_cal):
    # Get predicted probability for observed/true class
    predicted_prob = y_pred_proba[i][true_class]
    si_scores.append(1 - predicted_prob)    

# Convert to NumPy array
si_scores = np.array(si_scores)

# Show first 5 instances
si_scores[0:5]
```

```py
array([1.76170035e-03, 1.38061008e-02, 2.51668332e-01, 9.49187344e-04,
       1.63720201e-05])
```

## **è·å– 95 ç™¾åˆ†ä½é˜ˆå€¼**

é˜ˆå€¼å†³å®šäº†æˆ‘ä»¬åˆ†ç±»çš„*è¦†ç›–èŒƒå›´*ã€‚è¦†ç›–èŒƒå›´æŒ‡çš„æ˜¯å®é™…åŒ…å«çœŸå®ç»“æœçš„é¢„æµ‹æ¯”ä¾‹ã€‚

é˜ˆå€¼æ˜¯å¯¹åº”äº*1 â€”* ğ›¼çš„ç™¾åˆ†ä½æ•°ã€‚ä¸ºäº†è·å¾— 95%çš„è¦†ç›–ç‡ï¼Œæˆ‘ä»¬å°†ğ›¼è®¾ç½®ä¸º 0.05ã€‚

åœ¨å®é™…åº”ç”¨ä¸­ï¼ŒåŸºäºğ›¼çš„åˆ†ä½æ•°æ°´å¹³éœ€è¦æœ‰é™æ ·æœ¬æ ¡æ­£ä»¥è®¡ç®—ç›¸åº”çš„åˆ†ä½æ•°ğ‘ã€‚æˆ‘ä»¬å°† 0.95 ä¹˜ä»¥*(n+1)/n*ï¼Œè¿™æ„å‘³ç€å¯¹äº n = 1000ï¼Œğ‘ğ‘™ğ‘’ğ‘£ğ‘’ğ‘™å°†æ˜¯ 0.951ã€‚

```py
number_of_samples = len(X_Cal)
alpha = 0.05
qlevel = (1 - alpha) * ((number_of_samples + 1) / number_of_samples)
threshold = np.percentile(si_scores, qlevel*100)
print(f'Threshold: {threshold:0.3f}')
```

```py
Threshold: 0.598
```

æ˜¾ç¤º s_i å€¼çš„å›¾è¡¨ï¼Œå¸¦æœ‰æˆªæ­¢é˜ˆå€¼ã€‚

```py
x = np.arange(len(si_scores)) + 1
sorted_si_scores = np.sort(si_scores)
index_of_95th_percentile = int(len(si_scores) * 0.95)

# Color by cut-off
conform = 'g' * index_of_95th_percentile
nonconform = 'r' * (len(si_scores) - index_of_95th_percentile)
color = list(conform + nonconform)

fig = plt.figure(figsize=((6,4)))
ax = fig.add_subplot()

# Add bars
ax.bar(x, sorted_si_scores, width=1.0, color = color)

# Add lines for 95th percentile
ax.plot([0, index_of_95th_percentile],[threshold, threshold], 
        c='k', linestyle='--')
ax.plot([index_of_95th_percentile, index_of_95th_percentile], [threshold, 0],
        c='k', linestyle='--')

# Add text
txt = '95th percentile conformality threshold'
ax.text(5, threshold + 0.04, txt)

# Add axis labels
ax.set_xlabel('Sample instance (sorted by $s_i$)')
ax.set_ylabel('$S_i$ (non-conformality)')

plt.show()
```

![](img/83e794b29b74b30e8a4999cffa8e1377.png)

å¯¹æ‰€æœ‰æ•°æ®è®¡ç®— s_i å¾—åˆ†ã€‚é˜ˆå€¼æ˜¯åŒ…å« 95%æ‰€æœ‰æ•°æ®çš„ s_i æ°´å¹³ï¼ˆå¦‚æœğ›¼è®¾ç½®ä¸º 0.05ï¼‰ã€‚

## ä»æµ‹è¯•é›†ä¸­è·å–è¢«åˆ†ç±»ä¸ºæ­£ç±»çš„æ ·æœ¬/ç±»åˆ«ã€‚

æˆ‘ä»¬ç°åœ¨å¯ä»¥æ‰¾åˆ°æ‰€æœ‰ä½äºé˜ˆå€¼çš„æ¨¡å‹è¾“å‡ºã€‚

ä¸ªåˆ«ç¤ºä¾‹å¯èƒ½æ²¡æœ‰é¢„æµ‹å€¼ï¼ˆç©ºé›†åˆï¼‰ï¼Œä¹Ÿå¯èƒ½æœ‰å¤šä¸ªä½äºé˜ˆå€¼çš„å€¼ã€‚

è®©æˆ‘ä»¬è·å–ä½äºéç¬¦åˆæ€§é˜ˆå€¼çš„åˆ†ç±»ï¼Œå¹¶æŸ¥çœ‹å‰ 10 ä¸ªç¤ºä¾‹ã€‚æ¯ä¸ªé›†åˆæ˜¯æ¯ä¸ªå¯èƒ½ç±»åˆ«çš„çœŸ/å‡åˆ—è¡¨ã€‚

```py
prediction_sets = (1 - classifier.predict_proba(X_test) <= threshold)
# Show first ten instances
prediction_sets[0:10]
```

```py
array([[ True, False, False],
       [False, False,  True],
       [ True, False, False],
       [False, False,  True],
       [False,  True, False],
       [False,  True, False],
       [False,  True, False],
       [ True,  True, False],
       [False,  True, False],
       [False,  True, False]])
```

**è·å–é¢„æµ‹é›†åˆæ ‡ç­¾ï¼Œå¹¶ä¸æ ‡å‡†åˆ†ç±»è¿›è¡Œæ¯”è¾ƒã€‚**

```py
# Get standard predictions
y_pred = classifier.predict(X_test)

# Function to get set labels
def get_prediction_set_labels(prediction_set, class_labels):
    # Get set of class labels for each instance in prediction sets
    prediction_set_labels = [
        set([class_labels[i] for i, x in enumerate(prediction_set) if x]) for prediction_set in 
        prediction_sets]
    return prediction_set_labels

# Collate predictions
results_sets = pd.DataFrame()
results_sets['observed'] = [class_labels[i] for i in y_test]
results_sets['labels'] = get_prediction_set_labels(prediction_sets, class_labels)
results_sets['classifications'] = [class_labels[i] for i in y_pred]
results_sets.head(10)
```

```py
 observed  labels           classifications
0  blue      {blue}           blue
1  green     {green}          green
2  blue      {blue}           blue
3  green     {green}          green
4  orange    {orange}         orange
5  orange    {orange}         orange
6  orange    {orange}         orange
7  orange    {blue, orange}   blue
8  orange    {orange}         orange
9  orange    {orange}         orange
```

æ³¨æ„å®ä¾‹ 7 å®é™…ä¸Šæ˜¯æ©™è‰²ç±»åˆ«ï¼Œä½†è¢«ç®€å•åˆ†ç±»å™¨åˆ†ç±»ä¸ºè“è‰²ã€‚ç¬¦åˆé¢„æµ‹å°†å…¶åˆ†ç±»ä¸ºæ©™è‰²å’Œè“è‰²çš„é›†åˆã€‚

**ç»˜åˆ¶æ•°æ®ï¼Œæ˜¾ç¤ºå®ä¾‹ 7 å¯èƒ½å±äº 2 ä¸ªç±»åˆ«ï¼š**

```py
# Plot the data
fig = plt.subplots(figsize=(5, 5))
ax = plt.subplot(111)
for i in range(n_classes):
    ax.scatter(X_test[y_test == i, 0], X_test[y_test == i, 1],
               label=class_labels[i], alpha=0.5, s=10)
# Add instance 7
set_label = results_sets['labels'].iloc[7]
ax.scatter(X_test[7, 0], X_test[7, 1], color='k', s=100, marker='*', label=f'Instance 7')
legend = ax.legend()
legend.set_title("Class")
ax.set_xlabel("Feature 1")
ax.set_ylabel("Feature 2")
txt = f"Prediction set for instance 7: {set_label}"
ax.text(-20, 18, txt)
plt.show()
```

![](img/3abd04aeff55e2e5748a4a17712beccc.png)

æ•£ç‚¹å›¾æ˜¾ç¤ºæµ‹è¯•å®ä¾‹ 7 è¢«åˆ†ç±»ä¸ºä¸¤ä¸ªå¯èƒ½é›†åˆï¼š{â€˜è“è‰²â€™ï¼Œâ€˜æ©™è‰²â€™}ã€‚

**æ˜¾ç¤ºè¦†ç›–ç‡å’Œå¹³å‡é›†åˆå¤§å°ã€‚**

*è¦†ç›–ç‡*æ˜¯å®é™…åŒ…å«çœŸå®ç»“æœçš„é¢„æµ‹é›†åˆçš„æ¯”ä¾‹ã€‚

*å¹³å‡é›†åˆå¤§å°*æ˜¯æ¯ä¸ªå®ä¾‹çš„é¢„æµ‹ç±»åˆ«çš„å¹³å‡æ•°ã€‚

æˆ‘ä»¬å°†å®šä¹‰ä¸€äº›å‡½æ•°æ¥è®¡ç®—ç»“æœã€‚

```py
# Get class counts
def get_class_counts(y_test):
    class_counts = []
    for i in range(n_classes):
        class_counts.append(np.sum(y_test == i))
    return class_counts

# Get coverage for each class
def get_coverage_by_class(prediction_sets, y_test):
    coverage = []
    for i in range(n_classes):
        coverage.append(np.mean(prediction_sets[y_test == i, i]))
    return coverage

# Get average set size for each class
def get_average_set_size(prediction_sets, y_test):
    average_set_size = []
    for i in range(n_classes):
        average_set_size.append(
            np.mean(np.sum(prediction_sets[y_test == i], axis=1)))
    return average_set_size     

# Get weighted coverage (weighted by class size)
def get_weighted_coverage(coverage, class_counts):
    total_counts = np.sum(class_counts)
    weighted_coverage = np.sum((coverage * class_counts) / total_counts)
    weighted_coverage = round(weighted_coverage, 3)
    return weighted_coverage

# Get weighted set_size (weighted by class size)
def get_weighted_set_size(set_size, class_counts):
    total_counts = np.sum(class_counts)
    weighted_set_size = np.sum((set_size * class_counts) / total_counts)
    weighted_set_size = round(weighted_set_size, 3)
    return weighted_set_size
```

æ˜¾ç¤ºæ¯ä¸ªç±»åˆ«çš„ç»“æœã€‚å¹³å‡é›†åˆå¤§å°æ˜¯æ¯ä¸ªç±»åˆ«æ¯ä¸ªå®ä¾‹çš„é¢„æµ‹ç±»åˆ«çš„å¹³å‡æ•°ã€‚è¾ƒé«˜çš„æ•°å­—è¡¨ç¤ºä¸åŒç±»åˆ«çš„åˆ†ç±»åŒºåŸŸä¹‹é—´çš„é‡å æ›´å¤šã€‚

```py
results = pd.DataFrame(index=class_labels)
results['Class counts'] = get_class_counts(y_test)
results['Coverage'] = get_coverage_by_class(prediction_sets, y_test)
results['Average set size'] = get_average_set_size(prediction_sets, y_test)
results
```

```py
 Class counts  Coverage   Average set size
blue    241           0.817427   1.087137
orange  848           0.954009   1.037736
green   828           0.977053   1.016908
```

**æ˜¾ç¤ºæ•´ä½“ç»“æœã€‚**

```py
weighted_coverage = get_weighted_coverage(
    results['Coverage'], results['Class counts'])

weighted_set_size = get_weighted_set_size(
    results['Average set size'], results['Class counts'])

print (f'Overall coverage: {weighted_coverage}')
print (f'Average set size: {weighted_set_size}')
```

```py
Overall coverage: 0.947
Average set size: 1.035
```

æ³¨æ„ï¼šå°½ç®¡æˆ‘ä»¬çš„æ€»ä½“è¦†ç›–ç‡æ¥è¿‘ 95%ï¼Œä¸åŒç±»åˆ«çš„è¦†ç›–ç‡æœ‰æ‰€ä¸åŒï¼Œå¹¶ä¸”å¯¹äºæˆ‘ä»¬æœ€å°çš„ç±»åˆ«æ˜¯æœ€ä½çš„ï¼ˆ83%ï¼‰ã€‚å¦‚æœä¸ªåˆ«ç±»åˆ«çš„è¦†ç›–ç‡å¾ˆé‡è¦ï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºæ¯ä¸ªç±»åˆ«ç‹¬ç«‹è®¾ç½®é˜ˆå€¼ï¼Œè¿™ä¹Ÿæ˜¯æˆ‘ä»¬æ¥ä¸‹æ¥è¦åšçš„ã€‚

# åœ¨å„ç±»åˆ«ä¹‹é—´è¿›è¡Œç­‰è¦†ç›–ç‡çš„ç¬¦åˆåˆ†ç±»ã€‚

å½“æˆ‘ä»¬å¸Œæœ›ç¡®ä¿æ‰€æœ‰ç±»åˆ«çš„è¦†ç›–ç‡æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ç‹¬ç«‹ä¸ºæ¯ä¸ªç±»åˆ«è®¾ç½®é˜ˆå€¼ã€‚

æ³¨æ„ï¼šæˆ‘ä»¬è¿˜å¯ä»¥å¯¹æ•°æ®çš„å­ç»„è¿›è¡Œæ­¤æ“ä½œï¼Œä¾‹å¦‚ç¡®ä¿åœ¨ä¸åŒç§æ—ç¾¤ä½“ä¸­å¯¹è¯Šæ–­çš„è¦†ç›–ç‡ç›¸ç­‰ï¼Œå¦‚æœæˆ‘ä»¬å‘ç°ä½¿ç”¨å…±äº«é˜ˆå€¼çš„è¦†ç›–ç‡å¯¼è‡´äº†é—®é¢˜ã€‚

## ä¸ºæ¯ä¸ªç±»åˆ«ç‹¬ç«‹è·å–é˜ˆå€¼ã€‚

å¯¹äºæ¯ä¸ªç±»åˆ«ï¼Œæˆ‘ä»¬å°†æ‰¾åˆ°è¦†ç›–è¯¥ç±»åˆ«ä¸­ 95%å®ä¾‹çš„é˜ˆå€¼ s_i å¾—åˆ†ã€‚

```py
# Set alpha (1 - coverage)
alpha = 0.05
thresholds = []
# Get predicted probabilities for calibration set
y_cal_prob = classifier.predict_proba(X_Cal)
# Get 95th percentile score for each class's s-scores
for class_label in range(n_classes):
    mask = y_cal == class_label
    y_cal_prob_class = y_cal_prob[mask][:, class_label]
    s_scores = 1 - y_cal_prob_class
    q = (1 - alpha) * 100
    class_size = mask.sum()
    correction = (class_size + 1) / class_size
    q *= correction
    threshold = np.percentile(s_scores, q)
    thresholds.append(threshold)

print(thresholds)
```

```py
[0.9030202125697161, 0.6317149025299887, 0.26033562285411]
```

## **å°†ç±»åˆ«ç‰¹å®šçš„é˜ˆå€¼åº”ç”¨äºæ¯ä¸ªç±»åˆ«çš„åˆ†ç±»ã€‚**

æˆ‘ä»¬å°†æµ‹è¯•å®ä¾‹æ˜¯å¦ä½äºæ¯ä¸ªç±»åˆ«çš„é˜ˆå€¼ã€‚

```py
# Get Si scores for test set
predicted_proba = classifier.predict_proba(X_test)
si_scores = 1 - predicted_proba

# For each class, check whether each instance is below the threshold
prediction_sets = []
for i in range(n_classes):
    prediction_sets.append(si_scores[:, i] <= thresholds[i])
prediction_sets = np.array(prediction_sets).T

# Get prediction set labels and show first 10
prediction_set_labels = get_prediction_set_labels(prediction_sets, class_labels)

# Get standard predictions
y_pred = classifier.predict(X_test)

# Collate predictions
results_sets = pd.DataFrame()
results_sets['observed'] = [class_labels[i] for i in y_test]
results_sets['labels'] = get_prediction_set_labels(prediction_sets, class_labels)
results_sets['classifications'] = [class_labels[i] for i in y_pred]

# Show first 10 results
results_sets.head(10)
```

```py
 observed  labels           classifications
0 blue     {blue}            blue
1 green    {green}           green
2 blue     {blue}            blue
3 green    {green}           green
4 orange   {orange}          orange
5 orange   {orange}          orange
6 orange   {orange}          orange
7 orange   {blue, orange}    blue
8 orange   {orange}          orange
9 orange   {orange}          orange
```

## **æ£€æŸ¥å„ç±»åˆ«ä¹‹é—´çš„è¦†ç›–ç‡å’Œé›†åˆå¤§å°ã€‚**

ç°åœ¨æˆ‘ä»¬åœ¨æ‰€æœ‰ç±»åˆ«ä¸­å¤§çº¦æœ‰ 95%çš„è¦†ç›–ç‡ã€‚é¢„æµ‹é€‚åº”æ–¹æ³•æ¯”åˆ†ç±»çš„æ ‡å‡†æ–¹æ³•ç»™æˆ‘ä»¬æ›´å¥½çš„å°‘æ•°ç±»è¦†ç›–ç‡ã€‚

```py
results = pd.DataFrame(index=class_labels)
results['Class counts'] = get_class_counts(y_test)
results['Coverage'] = get_coverage_by_class(prediction_sets, y_test)
results['Average set size'] = get_average_set_size(prediction_sets, y_test)
results
```

```py
 Class counts  Coverage   Average set size
blue    241           0.954357   1.228216
orange  848           0.956368   1.139151
green   828           0.942029   1.006039
```

```py
weighted_coverage = get_weighted_coverage(
    results['Coverage'], results['Class counts'])

weighted_set_size = get_weighted_set_size(
    results['Average set size'], results['Class counts'])

print (f'Overall coverage: {weighted_coverage}')
print (f'Average set size: {weighted_set_size}')
```

```py
Overall coverage: 0.95
Average set size: 1.093
```

# æ€»ç»“

é¢„æµ‹é€‚åº”è¢«ç”¨æ¥å¯¹é›†åˆä¸­çš„å®ä¾‹è¿›è¡Œåˆ†ç±»ï¼Œè€Œä¸æ˜¯å•ä¸ªé¢„æµ‹ã€‚å¤„äºä¸¤ä¸ªç±»ä¹‹é—´è¾¹ç•Œçš„å®ä¾‹è¢«æ ‡è®°ä¸ºä¸¤ä¸ªç±»ï¼Œè€Œä¸æ˜¯é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ç±»ã€‚

å½“é‡è¦çš„æ˜¯æ‰€æœ‰ç±»åˆ«éƒ½ä»¥ç›¸åŒçš„è¦†ç›–ç‡è¢«æ£€æµ‹åˆ°æ—¶ï¼Œå¯ä»¥å•ç‹¬è®¾ç½®åˆ†ç±»å®ä¾‹çš„é˜ˆå€¼ï¼ˆä¾‹å¦‚ï¼Œè¿™ç§æ–¹æ³•ä¹Ÿå¯ä»¥ç”¨äºæ•°æ®çš„å­ç»„ï¼Œä¾‹å¦‚ç¡®ä¿è·¨ä¸åŒæ—ç¾¤çš„ç›¸åŒè¦†ç›–ç‡ï¼‰ã€‚

é¢„æµ‹é€‚åº”å¹¶ä¸æ”¹å˜æ¨¡å‹çš„é¢„æµ‹ã€‚å®ƒåªæ˜¯ä»¥ä¸ä¼ ç»Ÿåˆ†ç±»ä¸åŒçš„æ–¹å¼ä½¿ç”¨å®ƒä»¬ã€‚å®ƒå¯ä»¥ä¸æ›´ä¼ ç»Ÿçš„æ–¹æ³•å¹¶ç”¨ã€‚

ï¼ˆæ‰€æœ‰å›¾ç‰‡å‡ä¸ºä½œè€…æä¾›ï¼‰
