- en: Geospatial Index 102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/geospatial-index-102-cb90c9effb2c?source=collection_archive---------16-----------------------#2023-04-11](https://towardsdatascience.com/geospatial-index-102-cb90c9effb2c?source=collection_archive---------16-----------------------#2023-04-11)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A hands-on example of how to apply geospatial index
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@thanakornpanyapiang?source=post_page-----cb90c9effb2c--------------------------------)[![Thanakorn
    Panyapiang](../Images/4e68a74a2039c8404c5873d7d364be43.png)](https://medium.com/@thanakornpanyapiang?source=post_page-----cb90c9effb2c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cb90c9effb2c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cb90c9effb2c--------------------------------)
    [Thanakorn Panyapiang](https://medium.com/@thanakornpanyapiang?source=post_page-----cb90c9effb2c--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3946a0d40f8c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeospatial-index-102-cb90c9effb2c&user=Thanakorn+Panyapiang&userId=3946a0d40f8c&source=post_page-3946a0d40f8c----cb90c9effb2c---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cb90c9effb2c--------------------------------)
    ·7 min read·Apr 11, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcb90c9effb2c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeospatial-index-102-cb90c9effb2c&user=Thanakorn+Panyapiang&userId=3946a0d40f8c&source=-----cb90c9effb2c---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcb90c9effb2c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeospatial-index-102-cb90c9effb2c&source=-----cb90c9effb2c---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Geospatial Indexing is an indexing technique that provides an elegant way to
    manage location-based data. It makes geospatial data can be searched and retrieved
    efficiently so that the system can provide the best experience to its users. This
    article is going to demonstrate how this works in practice by applying a geospatial
    index to real-world data and demonstrating the performance gain by doing that.
    Let’s get started. *(Note: If you have never heard of the geospatial index or
    would like to learn more about it, check out* [*this article*](https://medium.com/towards-data-science/geospatial-index-101-df2c011da04b)*)*'
  prefs: []
  type: TYPE_NORMAL
- en: Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The data used in this article is the [Chicago Crime Data](https://console.cloud.google.com/marketplace/details/city-of-chicago-public-data/chicago-crime)
    which is a part of the [Google Cloud Public Dataset Program](https://cloud.google.com/bigquery/public-data).
    Anyone with a Google Cloud Platform account can access this dataset for free.
    It consists of approximately 8 million rows of data (with a total amount of 1.52
    GB) recording incidents of crime that occurred in Chicago since 2001, where each
    record has geographic data indicating the incident’s location.
  prefs: []
  type: TYPE_NORMAL
- en: Platform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Not only that we’ll use the data from Google Cloud, but also we’ll use Google
    Big Query as a data processing platform. Big Query provides the job execution
    details for every query executed. This includes the amount of data used and the
    number of rows processed which will be very useful to illustrate the performance
    gain after optimization.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What we’re going to do to demonstrate the power of the geospatial index is to
    optimize the performance of the location-based query. In this example, we’re going
    to use [*Geohash*](https://en.wikipedia.org/wiki/Geohash#:~:text=Geohash%20is%20a%20public%20domain,Morton%20in%201966.)
    as an index because of its simplicity and native support by Google BigQuery.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’re going to retrieve all records of crimes that occurred within 2 km of
    the *Chicago Union Station*. Before the optimization, let’s see what the performance
    looks like when we run this query on the original dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Below is what the job information and execution details look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5a9071f2857845eb83a5a8cf8cee8403.png)'
  prefs: []
  type: TYPE_IMG
- en: Job information(Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ea4e015ea548cd43aa2f2f79b8af4d8b.png)'
  prefs: []
  type: TYPE_IMG
- en: Execution details(Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: From the number of *Bytes processed* and *Records read*, you can see that the
    query scans the whole table and processes every row in order to get the final
    result. This means the more data we have, the longer the query will take, and
    the more expensive the processing cost will be. Can this be more efficient? Of
    course, and that’s where the geospatial index comes into play.
  prefs: []
  type: TYPE_NORMAL
- en: The problem with the above query is that even though many records are distant
    from the point-of-interest(Chicago Union Station), it has to be processed anyway.
    If we can eliminate those records, that would make the query a lot more efficient.
  prefs: []
  type: TYPE_NORMAL
- en: Geohash can be the solution to this issue. In addition to encoding coordinates
    into a text, another power of geohash is the hash also contains geospatial properties.
    The similarity between hashes can infer geographical similarity between the locations
    they represent. For example, the two areas represented by `wxcgh` and `wxcgd`
    are close because the two hashes are very similar, while `accgh` and `dydgh` are
    distant from each other because the two hashes are very different.
  prefs: []
  type: TYPE_NORMAL
- en: We can use this property with the [clustered table](https://cloud.google.com/bigquery/docs/clustered-tables)
    to our advantage by calculating the geohash of every row in advance. Then, we
    calculate the geohash of the Chicago Union Station. This way, we can eliminate
    all records that the hashes are not *close enough* to the Chicago Union Station’s
    geohash beforehand.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how to implement it:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Create a new table with a new column that stores a geohash of the coordinates.**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**2\. Create a clustered table using a geohash column as a cluster key**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: By using geohash as a cluster key, we create a table in which the rows that
    share the same hash are physically stored together. If you think about it, what
    actually happens is that the dataset is partitioned by geolocation because the
    closer the rows geographically are, the more likely they will have the same hash.
  prefs: []
  type: TYPE_NORMAL
- en: '**3\. Compute the geohash of the Chicago Union Station.**'
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we use [*this website*](https://www.movable-type.co.uk/scripts/geohash.html)
    but there are plenty of libraries in various programming languages that allow
    you to do this programmatically.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2ec306ddc119f65cc73ea6ffdeb21e60.png)'
  prefs: []
  type: TYPE_IMG
- en: Geohash of the Chicago Union Station(Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: '**4\. Add the geohash to the query condition.**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This time the query should only scan the records located in the `dp3wj` since
    the geohash is a cluster key of the table. This supposes to save a lot of processing.
    Let's see what happens.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6da1e87a82d8e8f37c360c66615f8f34.png)'
  prefs: []
  type: TYPE_IMG
- en: Job information after creating a clustered table(Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cc1df2e52830f58cc0abaf6f6603b535.png)'
  prefs: []
  type: TYPE_IMG
- en: Execution details after creating a clustered table(Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: From the job info and execution details, you can see the number of bytes processed
    and records scanned reduced significantly(from 1.5 GB to 55 MB and 7M to 260k).
    By introducing a geohash column and using it as a cluster key, we eliminate all
    the records that clearly do not satisfy the query beforehand just by looking at
    one column.
  prefs: []
  type: TYPE_NORMAL
- en: However, we are not finished yet. Look at the number of output rows carefully,
    you’ll see that it only has 100k records where the correct result must have 380k.
    The result we got is still not correct.
  prefs: []
  type: TYPE_NORMAL
- en: '**5\. Compute the neighbor zones and add them to the query.**'
  prefs: []
  type: TYPE_NORMAL
- en: In this example, all the neighbor hashes are `dp3wk`, `dp3wm`, `dp3wq`, `dp3wh`,
    `dp3wn`, `dp3wu`, `dp3wv`, and `dp3wy` . We use online [*geohash explore*](https://chrishewett.com/blog/geohash-explorer/)
    for this but, again, this can totally be written as a code.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7b540290a4d435d840fa9c82c8223071.png)'
  prefs: []
  type: TYPE_IMG
- en: Neighbors of the dp3wj(Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: Why do we need to add the neighbor zones to the query? Because geohash is only
    *an approximation* of location. Although we know Chicago Union Station is in the
    `dp3wj` , we still don't know where exactly it is in the zone. At the top, bottom,
    left, or right? We have no idea. If it's at the top, it's possible some data in
    the `dp3wm` may be closer to it than 2km. If it's on the right, it's possible
    some data in the `dp3wn` zone may closer than 2km. And so on. That's why all the
    neighbor hashes have to be included in the query to get the correct result.
  prefs: []
  type: TYPE_NORMAL
- en: Note that geohash level 5 has a precision of 5km. Therefore, all zones other
    than those in the above figure will be too far from the Chicago Union Station.
    This is another important design choice that has to be made because it has a huge
    impact. We’ll gain very little if it’s too coarse. On the other hand, using too
    fine precision-level will make the query sophisticated.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s what the final query looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'And this is what happens when executing the query:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9b7f234072d4f08729a578b8d41ce331.png)'
  prefs: []
  type: TYPE_IMG
- en: Job information after adding neighbor hashes(Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/11ee2dfe07a9d4fc63b6d7838a205b63.png)'
  prefs: []
  type: TYPE_IMG
- en: Execution details after adding neighbor hashes(Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: Now the result is correct and the query processes 527 MB and scans 2.5M records
    in total. In comparison with the original query, using geohash and clustered table
    saves the processing resource around 3 times. However, nothing comes for free.
    Applying geohash adds complexity to the way data is preprocessed and retrieved
    such as the choice of precision level that has to be chosen in advance and the
    additional logic of the SQL query.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article, we’ve seen how the geospatial index can help improve the processing
    of geospatial data. However, it has a cost that should be well considered in advance.
    At the end of the day, it’s not a free lunch. To make it work properly, a good
    understanding of both the algorithm and the system requirements is required.
  prefs: []
  type: TYPE_NORMAL
- en: '*Originally published at* [*https://thanakornp.com*](https://thanakornp.com/geospatial-index-in-practice)*.*'
  prefs: []
  type: TYPE_NORMAL
