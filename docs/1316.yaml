- en: Are Prompts Generated by Large Language Models (LLMs) Reliable?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）生成的提示是否可靠？
- en: 原文：[https://towardsdatascience.com/are-prompt-generated-by-large-language-models-llms-reliable-4162fd10c845?source=collection_archive---------11-----------------------#2023-04-14](https://towardsdatascience.com/are-prompt-generated-by-large-language-models-llms-reliable-4162fd10c845?source=collection_archive---------11-----------------------#2023-04-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/are-prompt-generated-by-large-language-models-llms-reliable-4162fd10c845?source=collection_archive---------11-----------------------#2023-04-14](https://towardsdatascience.com/are-prompt-generated-by-large-language-models-llms-reliable-4162fd10c845?source=collection_archive---------11-----------------------#2023-04-14)
- en: Unleashing the Power of LLMs with Auto-Generated Prompts
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 释放大型语言模型的力量与自动生成的提示
- en: '[](https://medium.com/@a0987284901?source=post_page-----4162fd10c845--------------------------------)[![Henry
    Lai](../Images/eaa1b4eb6f6cebc131f4cf0cfdd4cda7.png)](https://medium.com/@a0987284901?source=post_page-----4162fd10c845--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4162fd10c845--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4162fd10c845--------------------------------)
    [Henry Lai](https://medium.com/@a0987284901?source=post_page-----4162fd10c845--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@a0987284901?source=post_page-----4162fd10c845--------------------------------)[![Henry
    Lai](../Images/eaa1b4eb6f6cebc131f4cf0cfdd4cda7.png)](https://medium.com/@a0987284901?source=post_page-----4162fd10c845--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4162fd10c845--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4162fd10c845--------------------------------)
    [Henry Lai](https://medium.com/@a0987284901?source=post_page-----4162fd10c845--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd5548707b59&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-prompt-generated-by-large-language-models-llms-reliable-4162fd10c845&user=Henry+Lai&userId=d5548707b59&source=post_page-d5548707b59----4162fd10c845---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4162fd10c845--------------------------------)
    ·6 min read·Apr 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4162fd10c845&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-prompt-generated-by-large-language-models-llms-reliable-4162fd10c845&user=Henry+Lai&userId=d5548707b59&source=-----4162fd10c845---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd5548707b59&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-prompt-generated-by-large-language-models-llms-reliable-4162fd10c845&user=Henry+Lai&userId=d5548707b59&source=post_page-d5548707b59----4162fd10c845---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4162fd10c845--------------------------------)
    · 6 min 阅读 · 2023年4月14日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4162fd10c845&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-prompt-generated-by-large-language-models-llms-reliable-4162fd10c845&user=Henry+Lai&userId=d5548707b59&source=-----4162fd10c845---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4162fd10c845&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-prompt-generated-by-large-language-models-llms-reliable-4162fd10c845&source=-----4162fd10c845---------------------bookmark_footer-----------)![](../Images/427afef3b6084a0384d5114014f7246c.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4162fd10c845&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-prompt-generated-by-large-language-models-llms-reliable-4162fd10c845&source=-----4162fd10c845---------------------bookmark_footer-----------)![](../Images/427afef3b6084a0384d5114014f7246c.png)'
- en: Figure 1\. An example of performance variability of two different ChatGPT-generated
    prompts
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图1\. 两种不同 ChatGPT 生成提示的性能变异示例
- en: The rapid development of large language models (LLMs), including [ChatGPT](https://openai.com/blog/chatgpt)
    and [GPT-4](https://cdn.openai.com/papers/gpt-4.pdf), has revolutionized data
    science. In the past, data scientists typically devoted a substantial amount of
    time to preparing data, designing models, and fine-tuning them to solve various
    problems. Nowadays, with the advent of LLMs, we can accomplish many tasks in a
    pure data-centric manner without spending any effort on modeling (see the [data-centric
    AI framework](https://github.com/daochenzha/data-centric-AI)).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的快速发展，包括[ChatGPT](https://openai.com/blog/chatgpt)和[GPT-4](https://cdn.openai.com/papers/gpt-4.pdf)，彻底改变了数据科学。过去，数据科学家通常会花费大量时间来准备数据、设计模型并对其进行微调以解决各种问题。而如今，随着LLMs的出现，我们可以以纯数据驱动的方式完成许多任务，而无需花费任何建模方面的努力（参见[数据驱动的AI框架](https://github.com/daochenzha/data-centric-AI)）。
- en: One key idea drives the advancement is prompting, which refers to use of specific
    input text or questions to guide a language model in generating a desired output.
    For instance, when summarizing a lengthy article, we can provide the LLM with
    a prompt, such as “*Summarize the above in one sentence*”, and input the article
    text. This enables the LLM to generate a concise summary of the article, making
    it easier for researchers to extract relevant information quickly. The use of
    prompts has opened up new opportunities in data science, enabling scientists to
    streamline their workflows and increase their productivity.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 推动这一进展的关键概念是提示（prompting），指的是使用特定的输入文本或问题来引导语言模型生成所需的输出。例如，在总结一篇长文章时，我们可以向LLM提供一个提示，例如“*用一句话总结上述内容*”，然后输入文章文本。这使得LLM能够生成文章的简洁总结，方便研究人员快速提取相关信息。提示的使用为数据科学开辟了新的机会，使科学家能够简化工作流程，提高生产力。
- en: Creating effective prompts remains a significant challenge, as even prompts
    that seem similar can produce vastly different outputs. For example…
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 创建有效的提示仍然是一个重大挑战，因为即使是看似相似的提示也可能产生截然不同的输出。例如…
