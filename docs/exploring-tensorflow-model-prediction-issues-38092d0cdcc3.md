# æ¢ç´¢ TensorFlow æ¨¡å‹é¢„æµ‹é—®é¢˜

> åŸæ–‡ï¼š[`towardsdatascience.com/exploring-tensorflow-model-prediction-issues-38092d0cdcc3`](https://towardsdatascience.com/exploring-tensorflow-model-prediction-issues-38092d0cdcc3)

## åœ¨ä¸ªäººç”µè„‘ä¸Šè°ƒè¯• BERTï¼ˆä»¥åŠå…¶ä»– LLMï¼‰æ…¢é¢„æµ‹æ—¶é—´çš„æ­¥éª¤

[](https://adam1brownell.medium.com/?source=post_page-----38092d0cdcc3--------------------------------)![Adam Brownell](https://adam1brownell.medium.com/?source=post_page-----38092d0cdcc3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----38092d0cdcc3--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----38092d0cdcc3--------------------------------) [Adam Brownell](https://adam1brownell.medium.com/?source=post_page-----38092d0cdcc3--------------------------------)

Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page-----38092d0cdcc3--------------------------------) Â·7 åˆ†é’Ÿé˜…è¯»Â·2023 å¹´ 2 æœˆ 2 æ—¥

--

ä¸€åˆ‡å§‹äºæˆ‘ç©å¼„ BERT æ¨¡å‹æ—¶ï¼Œæ”¶åˆ°äº†ä¸€æ¡æ‰€æœ‰æ•°æ®ç§‘å­¦å®¶éƒ½å¸Œæœ›é¿å…çš„å‡¶å…†æ¶ˆæ¯ï¼š

![](img/a40d7372b0c9206a3e531750beabb71d.png)

ä»¤äººææƒ§çš„â€œå†…æ ¸å´©æºƒâ€æ¶ˆæ¯ ğŸ’€

å½“æˆ‘åœ¨ Jupyter Notebook ä¸Šè¿è¡Œæˆ‘çš„ TensorFlow BERT æ¨¡å‹æ—¶ï¼Œè¿™ç§æƒ…å†µå‘ç”Ÿäº†ã€‚è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€šå¸¸éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—ï¼Œå› æ­¤æˆ‘çš„ç›¸å¯¹å¾®ä¸è¶³é“çš„ç¬”è®°æœ¬ç”µè„‘åœ¨è¿™é‡Œå´©æºƒæ˜¯æœ‰é“ç†çš„â€¦â€¦

â€¦åªæ˜¯è¿™æ¬¡å´©æºƒå‘ç”Ÿåœ¨*é¢„æµ‹*æœŸé—´ï¼Œè€Œä¸æ˜¯*è®­ç»ƒ*æœŸé—´ï¼Œè¿™å¾ˆå¥‡æ€ªï¼Œå› ä¸ºæˆ‘è®¤ä¸ºè®­ç»ƒæ—¶ä½¿ç”¨çš„å†…å­˜æ¯”é¢„æµ‹æ—¶å¤šã€‚

â€œKernel Diedâ€é”™è¯¯æä¾›çš„ä¿¡æ¯ä¸å¤Ÿå…·ä½“ï¼Œè€Œé€è¡Œè°ƒè¯• TensorFlow å¬èµ·æ¥åƒæ˜¯ä¸€é¡¹è‰°å·¨çš„ä»»åŠ¡ã€‚

ä¸€äº›åœ¨ Stack Overflow ä¸Šçš„å¿«é€Ÿæœç´¢ä¹Ÿæ²¡æœ‰å®Œå…¨å›ç­”æˆ‘æ‚¬è€Œæœªå†³çš„é—®é¢˜ã€‚ä½†æˆ‘ä»ç„¶éœ€è¦ä¸€ä¸ªå‰è¿›çš„æ–¹å‘ã€‚

è¿™æ˜¯æˆ‘å¯¹å†…æ ¸å´©æºƒé—®é¢˜çš„æ¢ç´¢ä»¥åŠæˆ‘æ‰¾åˆ°è§£å†³æ–¹æ¡ˆçš„è¿‡ç¨‹ã€‚ ğŸš€

# æ·±å…¥æ¢ç´¢

ç”±äºæˆ‘å¯¹é—®é¢˜çš„å”¯ä¸€äº†è§£æ˜¯å†…æ ¸å´©æºƒï¼Œæˆ‘éœ€è¦æ”¶é›†æ›´å¤šçš„èƒŒæ™¯ä¿¡æ¯ã€‚ä»[å…¶ä»–å‡ ä¸ªçº¿ç¨‹](https://stackoverflow.com/questions/39328658/how-to-debug-dying-jupyter-python3-kernel)æ¥çœ‹ï¼Œä¼¼ä¹å†…æ ¸å´©æºƒçš„åŸå› æ˜¯æˆ‘çš„æ¨¡å‹é¢„æµ‹éœ€è¦çš„å†…å­˜è¶…å‡ºäº†æˆ‘çš„ CPU å¯ä»¥æä¾›çš„ï¼ˆ8GBï¼‰ï¼Œå³ä½¿åœ¨é¢„æµ‹æœŸé—´ä¹Ÿæ˜¯å¦‚æ­¤ã€‚

ç°åœ¨ï¼Œä¸€ä¸ªéå¸¸ç›´æ¥çš„è§£å†³æ–¹æ¡ˆï¼ˆå¤§å¤šæ•°äººä¼šå‡è®¾ï¼‰æ˜¯é€šè¿‡[Google Colab](https://colab.research.google.com/)æˆ–ç±»ä¼¼çš„æœåŠ¡è·å–æˆ–ç§Ÿç”¨ GPUã€‚æˆ‘è®¤ä¸ºè¿™ç¡®å®æ˜¯ä¸€ä¸ªå¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚

ä½†æˆ‘æƒ³çŸ¥é“åœ¨ RAM æˆä¸ºé—®é¢˜ä¹‹å‰ï¼Œæˆ‘èƒ½åœ¨æœ¬åœ°æœºå™¨å­¦ä¹ é¡¹ç›®ä¸­å°† CPU æ¨åˆ°å¤šè¿œã€‚è€ƒè™‘åˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬éœ€è¦æ¢ç´¢æ¨¡å‹å’Œç³»ç»Ÿæœ¬èº«çš„å‡ ä¸ªæ–¹é¢ã€‚

# æ‰¹é‡å¤§å°

é‰´äºè¿™æ˜¯ä¸€ä¸ª RAM é—®é¢˜ï¼Œæˆ‘è®¤ä¸ºæ‰¹é‡å¤§å°å‘æŒ¥äº†é‡è¦ä½œç”¨ï¼Œæ‰€ä»¥æˆ‘æƒ³å¯¹è¿™ä¸ªè¶…å‚æ•°è¿›è¡Œå‹åŠ›æµ‹è¯•ã€‚

é¦–å…ˆï¼Œæˆ‘å†™äº†ä¸‰ä¸ªç®€åŒ–ç‰ˆæœ¬çš„ BERTï¼Œä»…æ”¹å˜æ¨¡å‹ä½¿ç”¨çš„æ‰¹é‡å¤§å°ã€‚æˆ‘è¿è¡Œäº†è¿™ä¸‰ç§ç‰ˆæœ¬ï¼š

+   **FULL**ï¼šBERT ä¸€æ¬¡æ€§å¯¹æ•´ä¸ªè¾“å…¥è¿›è¡Œé¢„æµ‹

+   **SINGLE**ï¼šBERT ä¸€æ¬¡å¯¹ä¸€ä¸ªè¾“å…¥è¿›è¡Œé¢„æµ‹

+   **BATCH (100)**ï¼šBERT ä»¥æ¯æ¬¡ 100 ä¸ªè¾“å…¥çš„æ‰¹é‡è¿›è¡Œé¢„æµ‹

ä»¥ä¸‹æ˜¯ç›¸å…³ä»£ç ï¼š

```py
from transformers import BertTokenizer, BertForSequenceClassification, TFBertForSequenceClassification
import tensorflow as tf

class BERT_model_full:
    """
    BERT model predicting on all inputs at once
    """

    def __init__(self):

        self.model = TFBertForSequenceClassification.from_pretrained("bert-base-uncased")
        self.tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

    def predict(self,inputs):

        tf_batch = self.tokenizer(inputs, max_length=128, padding=True, truncation=True, return_tensors='tf')
        tf_outputs = self.model(tf_batch)

        return(tf_outputs.logits.numpy())

class BERT_model_batch:
    """
    BERT model predicting on batches of 100 inputs at a time
    """

    def __init__(self):

        self.model = TFBertForSequenceClassification.from_pretrained("bert-base-uncased")
        self.tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

    def predict(self,inputs):

        # Pred by batchsize
        i = 0
        batch_size = 100
        og_preds = []
        int_preds = []

        while i < len(inputs):

            j = min([len(inputs),i+batch_size])
            tf_batch = self.tokenizer(inputs[i:j], max_length=128, padding=True, truncation=True, return_tensors='tf')
            tf_outputs = self.model(tf_batch)

            i = j

        return(True)

class BERT_model_single:
    """
    BERT model predicting on a single input at a time
    """

    def __init__(self):

        self.model = TFBertForSequenceClassification.from_pretrained("bert-base-uncased")
        self.tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

    def predict(self,inputs):

        for i in inputs:
            tf_batch = self.tokenizer([i], max_length=128, padding=True, truncation=True, return_tensors='tf')
            tf_outputs = self.model(tf_batch)

        return(tf_outputs.logits.numpy())
```

ç„¶åæˆ‘å°†è¿™äº›æ¨¡å‹é€šè¿‡ç›¸åŒçš„æµ‹è¯•ç”¨ä¾‹è¿è¡Œï¼Œé€æ­¥å¢åŠ è¾“å…¥å¤§å°ã€‚*æˆ‘ä½¿ç”¨äº†* [*ç»å…¸ imdb æ•°æ®é›†*](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) *æ¥è¿›è¡Œæµ‹è¯•ã€‚*

```py
size_list = [1,10,100,1000,2000,4000,6000,8000]
single_time_list = []
batch_time_list = []
full_time_list = []

BERT = BERT_model_single()
print("BERT Single Input:")
for s in size_list:
    data = imdb_data.sample(s)['DATA_COLUMN']

    start = time.time()

    _ = BERT.predict(data)

    end = time.time()

    single_time_list.append(end-start)
    print(f"{s} samples: {(end-start)/60:.2f} minutes")

BERT = BERT_model_batch()
print("\nBERT Small Batch:")
for s in size_list:
    data = list(imdb_data.sample(s)['DATA_COLUMN'])

    start = time.time()

    _ = BERT.predict(data)

    end = time.time()

    batch_time_list.append(end-start)
    print(f"{s} samples: {(end-start)/60:.2f} minutes")

BERT = BERT_model_full()
print("\nBERT Full Batch:")
for s in size_list:
    data = list(imdb_data.sample(s)['DATA_COLUMN'])

    start = time.time()

    _ = BERT.predict(data)

    end = time.time()

    full_time_list.append(end-start)
    print(f"{s} samples: {(end-start)/60:.2f} minutes")
```

ç»˜åˆ¶è¾“å‡ºå›¾è¡¨æ˜¾ç¤ºå‡ºæœ‰è¶£çš„è¶‹åŠ¿ï¼š

![](img/f199ff54e24353720ed7cb52ad7534e6.png)

BATCH ä¼˜äº SINGLE æ˜¯æœ‰é“ç†çš„ï¼Œå› ä¸ºå¤§å¤šæ•°æœºå™¨å­¦ä¹ æ¨¡å‹å’Œåƒ Tensorflow è¿™æ ·çš„åŒ…è®¾è®¡ç”¨æ¥åˆ©ç”¨å‘é‡åŒ–ã€‚

ä½†ä»¤äººæƒŠè®¶çš„æ˜¯**FULL ä¸ BATCH çš„å·®è·æœ‰å¤šå¤§**ã€‚

æˆ‘æ›¾å‡è®¾ FULL ä¼šå› ä¸ºå‘é‡åŒ–è¡¨ç°æœ€ä½³ï¼Œç›´åˆ°å®ƒå› å†…å­˜é™åˆ¶å´©æºƒï¼Œä½†å®é™…ä¸Š***å³ä½¿æ˜¯å‡ åƒä¸ªæ ·æœ¬çš„å†…å­˜é™åˆ¶åœ¨æˆ‘çš„ç¬”è®°æœ¬ä¸Šä¹Ÿæå¤§åœ°å¢åŠ äº†é¢„æµ‹æ—¶é—´ã€‚***

åœ¨å¤„ç†è¾ƒå¤§çš„è¾“å…¥æ—¶ï¼ŒFULL çš„è¡¨ç°å®é™…ä¸Š*æ›´å·®*ï¼Œæ¯”èµ·é€ä¸ªè¾“å…¥å¤„ç†è€Œä¸è¿›è¡Œå‘é‡åŒ–ã€‚ğŸ¤¯

åœ¨å¤§çº¦ 2,000 ä¸ªæ ·æœ¬æ—¶ï¼Œè¿™äº› RAM è¦æ±‚å¼€å§‹å¯¹æˆ‘çš„ CPU é€ æˆè´Ÿæ‹…ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œåœ¨è¾¾åˆ° 2K ä¹‹å‰ï¼ŒBATCH å’Œ FULL ä¹‹é—´çš„å·®å¼‚å¹¶ä¸å¤§ã€‚

æ ¹æ®ä¸Šé¢çš„å›¾è¡¨ï¼Œæˆ‘å‡è®¾ä½¿ç”¨ 2,000 çš„æ‰¹é‡å¤§å°ä¼šäº§ç”Ÿæœ€ä½³ç»“æœã€‚

æˆ‘é”™äº†ã€‚

**ä¼¼ä¹æœ€ä½³çš„æ‰¹é‡å¤§å°æ›´æ¥è¿‘ 1K**ï¼Œå› ä¸ºå¦‚æœä½¿ç”¨ 2K çš„æ‰¹é‡å¤§å°ï¼Œé¢„æµ‹æ—¶é—´å¼€å§‹ä¸Šå‡ï¼š

![](img/a2c8d06153e517c8199fda54935a6ea3.png)

æ‰¹é‡å¤§å°å¯¹ 4K è¾“å…¥çš„é¢„æµ‹æ—¶é—´çš„å½±å“

# Tokenizer

æˆ‘æ¥ä¸‹æ¥æ¢ç´¢çš„ä»£ç æ˜¯ Tokenizerã€‚é‰´äºè¿™ä¸€è¡ŒåŒ…å«äº†è®¸å¤šè¶…å‚æ•°ï¼Œæˆ‘è®¤ä¸ºè¿™ä¹Ÿæ˜¯ä¸€ä¸ªä¼˜åŒ–çš„åœ°æ–¹ï¼š

```py
tf_batch = self.tokenizer(inputs, max_length=128, 
                          padding=True, truncation=True, 
                          return_tensors='tf')
```

ç„¶è€Œï¼Œå½“æˆ‘è®¡æ—¶æ£€æŸ¥æˆ‘çš„ FULL æ¨¡å‹æ€§èƒ½æ—¶ï¼Œåœ¨ 1K è¾“å…¥ä¸‹å®ƒä¸ BATCH è¡¨ç°ç›¸å½“ï¼Œè€Œåœ¨ 4K è¾“å…¥ä¸‹è¡¨ç°æ˜¾è‘—è¾ƒå·®ï¼Œ**Tokenizer æ€§èƒ½æ—¶é—´æ˜¯æ€»æ—¶é—´çš„å¾®ä¸è¶³é“çš„ä¸€éƒ¨åˆ†ï¼š**

```py
1000 samples:
Tokenizer Time: 0.06 minutes
Predictionn Time: 1.97 minutes
Tokenizer takes up 3.06%  of prediction time

4000 samples:
Tokenizer Time: 0.29 minutes
Predictionn Time: 27.25 minutes
Tokenizer takes up 1.06%  of prediction time
```

è™½ç„¶ Tokenizer æ—¶é—´çš„å¢åŠ ç¡®å®ç•¥å¾®è¶…è¿‡äº†è¾“å…¥å¤§å°çš„å¢åŠ ï¼ˆè¾“å…¥å¤§å°å¢åŠ å››å€å¯¼è‡´ Tokenizer æ—¶é—´å¢åŠ  4.8 å€ï¼‰ï¼Œä½†é¢„æµ‹æ—¶é—´å´æƒŠäººåœ°å¢åŠ äº†**13.8 å€**ï¼

**æ˜¾ç„¶ï¼Œé—®é¢˜å‡ºåœ¨** `**.predict()**` **ç®¡é“çš„éƒ¨åˆ†ã€‚**

# Tensorflow ç‰ˆæœ¬

æ ¹æ®ä¸Šé¢å·²æåˆ°çš„ Stack Overflow çº¿ç¨‹ï¼Œæœ€å—æ¬¢è¿çš„è§£å†³æ–¹æ¡ˆæ˜¯å°† Tensorflow é™çº§ä»¥åŠ å¿«é¢„æµ‹é€Ÿåº¦ã€‚

æˆ‘è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªå€¼å¾—æ€€ç–‘çš„è§£å†³æ–¹æ¡ˆï¼Œå› ä¸ºæˆ‘å‡è®¾å‡çº§ç‰ˆæœ¬ä¼šæœ‰æ›´å¤šçš„ä¼˜åŒ–å’Œæ›´å¥½çš„è¿è¡Œæ—¶é—´ï¼Œè€Œä¸æ˜¯æ›´å·®ã€‚ä½†æˆ‘è¿˜æ˜¯å°è¯•äº†ã€‚

è®¿é—® [tensorflow Pypi é¡µé¢](https://pypi.org/project/tensorflow/#history)ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°åŒ…çš„æ—§ç‰ˆæœ¬ã€‚é€‰æ‹©å‘å¸ƒå¤§çº¦ç›¸éš”ä¸€å¹´çš„åŒ…ï¼Œæˆ‘ä»¬å¾—åˆ°ä»¥ä¸‹åŒ…ç‰ˆæœ¬ï¼š

+   `2.10.0`ï¼Œå‘å¸ƒäº 2022 å¹´ 9 æœˆ

+   `2.6.1`ï¼Œå‘å¸ƒäº 2021 å¹´ 11 æœˆ

+   `1.15.4`ï¼Œå‘å¸ƒäº 2020 å¹´ 9 æœˆ

+   `1.15.0`ï¼Œå‘å¸ƒäº 2019 å¹´ 10 æœˆ

è¦è¿­ä»£å®‰è£…åŒä¸€åŒ…çš„ä¸åŒç‰ˆæœ¬ï¼Œæˆ‘ä»¬éœ€è¦åˆ©ç”¨ `os` åŒ…ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿä» Python ä»£ç ä¸­è¿è¡Œç»ˆç«¯å‘½ä»¤ï¼š

```py
import os
data = list(imdb_data.sample(4000)['DATA_COLUMN'])
full_time_list = []
versions = ["2.10.0","2.6.1","1.15.4","1.15.0"]
for version in versions:
    print(version,":")
    os.system(f"pip install tensorflow=={version}")

    try:
        from transformers import BertTokenizer, BertForSequenceClassification, TFBertForSequenceClassification
        import tensorflow as tf
    except:
        print("Cannot import relevant packages")
        continue

    BERT = BERT_model_full()

    start = time.time()

    _ = BERT.predict(data)

    end = time.time()

    minutes = (end-start)/60
    full_time_list.append(minutes)
    print(f"{s} batch size: {minutes:.2f} minutes")
```

+   `try/except` è¯­å¥å­˜åœ¨æ˜¯å› ä¸ºæˆ‘ä»¬ä¸çŸ¥é“è¿™äº›å‡½æ•°æ˜¯å¦å­˜åœ¨äºåŒ…çš„æ—©æœŸç‰ˆæœ¬ä¸­ã€‚*å¹¸è¿çš„æ˜¯ï¼Œå®ƒä»¬éƒ½å­˜åœ¨*

+   åœ¨å¾ªç¯ä¸­çš„ `import` è¯­å¥çœ‹èµ·æ¥ä¸å¯¹ï¼Œä½†è¿™æ˜¯å¿…è¦çš„ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦åœ¨å®‰è£…æ­£ç¡®çš„åŒ…ç‰ˆæœ¬åé‡æ–°å¯¼å…¥è¿™äº›å‡½æ•°

ç»è¿‡æ¯ä¸ªç‰ˆæœ¬çš„è¿­ä»£ï¼Œæˆ‘ä»¬å‘ç°**é™çº§ TensorFlow å¯ä»¥å°†è¿è¡Œæ—¶é—´æé«˜å¤šè¾¾ 15%ï¼**

![](img/cf122c9f782c3b77ee13f09e5fb0715e.png)

æˆ‘ä¸ªäººçš„ç†è®ºæ˜¯ï¼Œä¹‹æ‰€ä»¥å‡ºç°è¿™ç§æƒ…å†µï¼Œæ˜¯å› ä¸ºè¾ƒæ–°çš„ TensorFlow ç‰ˆæœ¬å‡å®šé‡åº¦ä½¿ç”¨ GPUï¼Œè¿™æ„å‘³ç€å®ƒé’ˆå¯¹è¿™ç§ç‰¹å®šçš„ä½¿ç”¨åœºæ™¯è¿›è¡Œäº†ä¼˜åŒ–ï¼Œä½†ç‰ºç‰²äº†æœ¬åœ° CPU æ€§èƒ½ã€‚

*å¦‚æœæœ‰äººçŸ¥é“ä¸ºä»€ä¹ˆæ—§ç‰ˆæœ¬çš„ TensorFlow è¿è¡Œæ›´å¿«çš„çœŸå®åŸå› ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼*

# ç»“è®ºä¸æ€»ç»“

å…³äº TensorFlow è¿è¡Œæ—¶çš„ä»¥ä¸‹è§è§£ï¼š

+   **æœ€ä½³é¢„æµ‹æ‰¹é‡å¤§å°çº¦ä¸º 1,000**

+   **åˆ†è¯å™¨å‚æ•°ç¡®å®åœ¨é¢„æµ‹æ—¶é—´ä¸­èµ·ç€é‡è¦ä½œç”¨**

+   **TensorFlow 1.X.X åœ¨é¢„æµ‹æ—¶é—´ä¸Šæå‡äº† 15%**

æˆ‘ä»¬å¯ä»¥å°†è¿™äº›ä¿¡æ¯ç»¼åˆèµ·æ¥ï¼Œçœ‹çœ‹å®ƒä¸æˆ‘ä»¬æœ€åˆçš„æ‰¹é‡å¤§å°å®éªŒçš„è¡¨ç°å¦‚ä½•ï¼š

![](img/a80018713ea66fb7bd6bc271eaa93300.png)

> åœ¨æµ‹è¯•çš„æœ€å¤§æ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä»¬çš„æœ€ä½³è¿è¡Œæ¯” Batch(100) å¿« 20%ï¼Œæ¯” Single å¿« 57%!

æ€»çš„æ¥è¯´ï¼Œè¿™ä¸ªè¿‡ç¨‹æ˜¯å¯¹æ•°æ®ç§‘å­¦å®¶èº«ä»½çš„ä¸€ç§ç®€å•è€Œæ„‰å¿«çš„è¡¨è¾¾ã€‚ä½ éœ€è¦è¯†åˆ«é—®é¢˜ï¼Œå»ºç«‹å‡è®¾ï¼Œåˆ¶å®šä¸¥æ ¼çš„æµ‹è¯•ï¼Œå¹¶åˆ†æç»“æœã€‚åœ¨è¿™ä¸ªæ¡ˆä¾‹ä¸­ï¼Œå°±æ˜¯æˆ‘çš„ TensorFlow è¿è¡Œæ—¶ã€‚å°†æ¥ï¼Œæˆ‘ç›¸ä¿¡ä½ ä¼šåœ¨è‡ªå·±çš„å·¥ä½œä¸­å‘ç°ä»¤äººå›°æƒ‘çš„æ•°æ®/é—®é¢˜/éš¾é¢˜ã€‚

ä¸‹æ¬¡ï¼Œå¸Œæœ›ä½ ä¸è¦ä»…ä»…æ˜¯æŸ¥çœ‹ Stack Overflowï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°ç­”æ¡ˆå°±æ”¾å¼ƒï¼Œè€Œæ˜¯å·èµ·è¢–å­è‡ªå·±æ¢ç´¢é—®é¢˜ç©ºé—´ã€‚ä½ æ°¸è¿œä¸çŸ¥é“ä½ å¯èƒ½ä¼šå­¦åˆ°ä»€ä¹ˆ ğŸ’¡

å¸Œæœ›è¿™å¯¹è°ƒè¯•ä½ çš„ TensorFlow é¢„æµ‹æ—¶é—´é—®é¢˜æœ‰æ‰€å¸®åŠ©ï¼ ğŸ‰

*æ‰€æœ‰å›¾åƒï¼Œé™¤éå¦æœ‰è¯´æ˜ï¼Œå‡ç”±ä½œè€…æä¾›*
