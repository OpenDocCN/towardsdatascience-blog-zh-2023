- en: Unleashing the ChatGPT Tokenizer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/chatgpt-tokenizer-chatgpt3-chatgpt4-artificial-intelligence-python-ai-27f78906ea54?source=collection_archive---------3-----------------------#2023-07-06](https://towardsdatascience.com/chatgpt-tokenizer-chatgpt3-chatgpt4-artificial-intelligence-python-ai-27f78906ea54?source=collection_archive---------3-----------------------#2023-07-06)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Hands-On! How ChatGPT Manages Tokens?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@andvalenzuela?source=post_page-----27f78906ea54--------------------------------)[![Andrea
    Valenzuela](../Images/ddfc1534af92413fd91076f826cc49b6.png)](https://medium.com/@andvalenzuela?source=post_page-----27f78906ea54--------------------------------)[](https://towardsdatascience.com/?source=post_page-----27f78906ea54--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----27f78906ea54--------------------------------)
    [Andrea Valenzuela](https://medium.com/@andvalenzuela?source=post_page-----27f78906ea54--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa6f3f1654c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchatgpt-tokenizer-chatgpt3-chatgpt4-artificial-intelligence-python-ai-27f78906ea54&user=Andrea+Valenzuela&userId=a6f3f1654c3&source=post_page-a6f3f1654c3----27f78906ea54---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----27f78906ea54--------------------------------)
    ·9 min read·Jul 6, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F27f78906ea54&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchatgpt-tokenizer-chatgpt3-chatgpt4-artificial-intelligence-python-ai-27f78906ea54&user=Andrea+Valenzuela&userId=a6f3f1654c3&source=-----27f78906ea54---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F27f78906ea54&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchatgpt-tokenizer-chatgpt3-chatgpt4-artificial-intelligence-python-ai-27f78906ea54&source=-----27f78906ea54---------------------bookmark_footer-----------)![](../Images/d6d00dc92aaafbfe984040c4f28c2509.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Self-made gif.
  prefs: []
  type: TYPE_NORMAL
- en: '**Have you ever wondered which are the key components behind ChatGPT?**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We all have been told the same: ChatGPT predicts the next word. But actually,
    there is a bit of a lie in this statement. **It does not predict the next word,
    ChatGPT predicts the next token**.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Token?* Yes, a token is the unit of text for Large Language Models (LLMs).'
  prefs: []
  type: TYPE_NORMAL
- en: Indeed **one of the first steps that ChatGPT does when processing any prompt
    is splitting the user input into tokens**. And that is the job of the so-called
    **tokenizer**.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we will uncover how the ChatGPT tokenizer works with hands-on
    practice with the original library used by OpenAI, the `tiktoken` library.
  prefs: []
  type: TYPE_NORMAL
- en: '*TikTok-en… Funny enough :)*'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s dive deep and comprehend the actual steps performed by the tokenizer,
    and how its behavior really impacts the quality of the ChatGPT output.
  prefs: []
  type: TYPE_NORMAL
- en: How the Tokenizer Works
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the article [Mastering ChatGPT: Effective Summarization with LLMs](/chatgpt-summarization-llms-chatgpt3-chatgpt4-artificial-intelligence-16cf0e3625ce)
    we already saw some of the mysteries behind the ChatGPT tokenizer, but let’s start
    from scratch.'
  prefs: []
  type: TYPE_NORMAL
- en: The tokenizer appears at the first step in the process of text generation. **It
    is**…
  prefs: []
  type: TYPE_NORMAL
