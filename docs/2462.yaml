- en: How to Build a Fully Automated Data Drift Detection Pipeline
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何构建一个完全自动化的数据漂移检测管道
- en: 原文：[https://towardsdatascience.com/how-to-build-a-fully-automated-data-drift-detection-pipeline-e9278584e58d?source=collection_archive---------2-----------------------#2023-08-01](https://towardsdatascience.com/how-to-build-a-fully-automated-data-drift-detection-pipeline-e9278584e58d?source=collection_archive---------2-----------------------#2023-08-01)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-build-a-fully-automated-data-drift-detection-pipeline-e9278584e58d?source=collection_archive---------2-----------------------#2023-08-01](https://towardsdatascience.com/how-to-build-a-fully-automated-data-drift-detection-pipeline-e9278584e58d?source=collection_archive---------2-----------------------#2023-08-01)
- en: An Automate Guide to Detect and Handle Data Drift
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动化指南：检测和处理数据漂移
- en: '[](https://khuyentran1476.medium.com/?source=post_page-----e9278584e58d--------------------------------)[![Khuyen
    Tran](../Images/98aa66025ad29b618e875c75f1c400a5.png)](https://khuyentran1476.medium.com/?source=post_page-----e9278584e58d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e9278584e58d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e9278584e58d--------------------------------)
    [Khuyen Tran](https://khuyentran1476.medium.com/?source=post_page-----e9278584e58d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://khuyentran1476.medium.com/?source=post_page-----e9278584e58d--------------------------------)[![Khuyen
    Tran](../Images/98aa66025ad29b618e875c75f1c400a5.png)](https://khuyentran1476.medium.com/?source=post_page-----e9278584e58d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e9278584e58d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e9278584e58d--------------------------------)
    [Khuyen Tran](https://khuyentran1476.medium.com/?source=post_page-----e9278584e58d--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F84a02493194a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-fully-automated-data-drift-detection-pipeline-e9278584e58d&user=Khuyen+Tran&userId=84a02493194a&source=post_page-84a02493194a----e9278584e58d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e9278584e58d--------------------------------)
    ·10 min read·Aug 1, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe9278584e58d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-fully-automated-data-drift-detection-pipeline-e9278584e58d&user=Khuyen+Tran&userId=84a02493194a&source=-----e9278584e58d---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F84a02493194a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-fully-automated-data-drift-detection-pipeline-e9278584e58d&user=Khuyen+Tran&userId=84a02493194a&source=post_page-84a02493194a----e9278584e58d---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e9278584e58d--------------------------------)
    · 10分钟阅读 · 2023年8月1日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe9278584e58d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-fully-automated-data-drift-detection-pipeline-e9278584e58d&user=Khuyen+Tran&userId=84a02493194a&source=-----e9278584e58d---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe9278584e58d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-fully-automated-data-drift-detection-pipeline-e9278584e58d&source=-----e9278584e58d---------------------bookmark_footer-----------)![](../Images/c433a55c93060b21965daf484c047144.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe9278584e58d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-fully-automated-data-drift-detection-pipeline-e9278584e58d&source=-----e9278584e58d---------------------bookmark_footer-----------)![](../Images/c433a55c93060b21965daf484c047144.png)'
- en: Image by Author
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Motivation
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动机
- en: Data drift occurs when the distribution of input features in the production
    environment differs from the training data, leading to potential inaccuracies
    and decreased model performance.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 数据漂移发生在生产环境中的输入特征分布与训练数据不同，从而可能导致不准确性和模型性能下降。
- en: '![](../Images/1a58af829c62bf069cfd2e99d4203f0d.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1a58af829c62bf069cfd2e99d4203f0d.png)'
- en: Image by Author
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: To mitigate the impact of data drift on model performance, we can design a workflow
    that detects drift, notifies the data team, and triggers model retraining.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减轻数据漂移对模型性能的影响，我们可以设计一个工作流，检测漂移，通知数据团队，并触发模型重训练。
- en: '![](../Images/677b5b6931730a825eff3e9288beab99.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/677b5b6931730a825eff3e9288beab99.png)'
- en: Image by Author
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Workflows
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作流
- en: 'The workflow comprises the following tasks:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流包括以下任务：
- en: Fetch reference data from the Postgres database.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Postgres 数据库中获取参考数据。
- en: Get the current production data from the web.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从网络获取当前生产数据。
- en: Detect data drift by comparing the reference and current data.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过比较参考数据和当前数据来检测数据漂移。
- en: Append the current data to the existing Postgres database.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将当前数据附加到现有的 Postgres 数据库中。
- en: 'When there is data drift, the following actions are taken:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当出现数据漂移时，采取以下措施：
- en: Send a Slack message to alert the data team.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发送 Slack 消息以提醒数据团队。
- en: Retrain the model to update its performance.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新训练模型以更新其性能。
- en: Push the updated model to S3 for storage.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将更新后的模型推送到 S3 存储。
- en: This workflow is scheduled to run at specific times, such as 11:00 AM every
    Monday.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这个工作流程被安排在特定时间运行，例如每周一上午 11:00。
- en: '![](../Images/b5b8d48a2b308df0226e2b5963b320e1.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b5b8d48a2b308df0226e2b5963b320e1.png)'
- en: Image by Author
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'Overall, the workflow includes two types of tasks: data science and data engineering
    tasks.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，工作流程包括两种类型的任务：数据科学任务和数据工程任务。
- en: Data science tasks, represented by pink boxes, are performed by data scientists
    and involve data drift detection, data processing, and model training.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学任务，用粉色框表示，由数据科学家执行，涉及数据漂移检测、数据处理和模型训练。
- en: Data engineering tasks, represented by blue and purple boxes, are performed
    by data engineers and involve tasks related to data movement and sending notifications.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程任务，用蓝色和紫色框表示，由数据工程师执行，涉及数据移动和发送通知的任务。
- en: Data Science Tasks
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学任务
- en: Detect Data Drift
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检测数据漂移
- en: To detect data drift, we will create a Python script that takes two CSV files
    “data/reference.csv” (reference data) and “data/current.csv” (current data).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检测数据漂移，我们将创建一个 Python 脚本，该脚本接受两个 CSV 文件“data/reference.csv”（参考数据）和“data/current.csv”（当前数据）。
- en: '![](../Images/12ed1960bcc3d5295dacaa4c1ba12e6c.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/12ed1960bcc3d5295dacaa4c1ba12e6c.png)'
- en: Image by Author
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: We will use [Evidently](https://www.evidentlyai.com/), an open-source ML observability
    platform, to compare the reference data, serving as a baseline, with the current
    production data.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用[Evidently](https://www.evidentlyai.com/)，一个开源的机器学习可观测性平台，来将参考数据（作为基线）与当前生产数据进行比较。
- en: If dataset drift is detected, the “drift_detected” output will be True; otherwise,
    it will be False.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果检测到数据漂移，则“drift_detected”输出为 True；否则为 False。
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[Full code.](https://github.com/khuyentran1401/detect-data-drift-pipeline/blob/main/src/detect/detect_data_drift.py)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[完整代码。](https://github.com/khuyentran1401/detect-data-drift-pipeline/blob/main/src/detect/detect_data_drift.py)'
- en: Retrain the Model
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重新训练模型
- en: Next, we will create a Python script responsible for model training. This script
    takes the combined past and current data as input and saves the trained model
    as a “model.pkl” file.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个负责模型训练的 Python 脚本。该脚本以过去和当前数据的结合作为输入，并将训练好的模型保存为“model.pkl”文件。
- en: '![](../Images/d7a01c96325ffca329b924fe15b782c4.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d7a01c96325ffca329b924fe15b782c4.png)'
- en: Image by Author
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[Full code.](https://github.com/khuyentran1401/detect-data-drift-pipeline/blob/main/src/train/train_model.py)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[完整代码。](https://github.com/khuyentran1401/detect-data-drift-pipeline/blob/main/src/train/train_model.py)'
- en: Push to GitHub
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推送到 GitHub
- en: After finishing developing these two scripts, data scientists can push them
    to GitHub, allowing data engineers to use them in creating workflows.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发完这两个脚本后，数据科学家可以将它们推送到 GitHub，从而允许数据工程师在创建工作流时使用它们。
- en: 'View the GitHub repository for these files here:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里查看这些文件的 GitHub 仓库：
- en: '[](https://github.com/khuyentran1401/detect-data-drift-pipeline?source=post_page-----e9278584e58d--------------------------------)
    [## GitHub - khuyentran1401/detect-data-drift-pipeline: A pipeline to detect data
    drift and retrain the…'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/khuyentran1401/detect-data-drift-pipeline?source=post_page-----e9278584e58d--------------------------------)
    [## GitHub - khuyentran1401/detect-data-drift-pipeline: 一个检测数据漂移并重新训练模型的流水线]'
- en: A pipeline to detect data drift and retrain the model when there is drift -
    GitHub …
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一个检测数据漂移并在出现漂移时重新训练模型的流水线 - GitHub …
- en: github.com](https://github.com/khuyentran1401/detect-data-drift-pipeline?source=post_page-----e9278584e58d--------------------------------)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/khuyentran1401/detect-data-drift-pipeline?source=post_page-----e9278584e58d--------------------------------)
- en: Data Engineering Tasks
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据工程任务
- en: Popular orchestration libraries such as Airflow, Prefect, and Dagster require
    modifications to the Python code to use their functionalities.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 流行的协调库如 Airflow、Prefect 和 Dagster 需要修改 Python 代码以使用其功能。
- en: When Python scripts are tightly integrated into the data workflows, the overall
    codebase can become more complex and harder to maintain. Without independent Python
    script development, data engineers may need to modify the data science code to
    add orchestration logic.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/64c035d84a1ea8d5f62045eacc58bb41.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, [Kestra](https://kestra.io/), an open-source library, allows
    you to develop your Python scripts independently and then ​​seamlessly incorporate
    them into data workflows using YAML files.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: This way, data scientists can focus on model processing and training, while
    data engineers can focus on handling orchestration.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: Thus, we will use Kestra to design a more modular and efficient workflow.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7723cb5f1e607561113267c99407f63a.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: 'Clone the [detect-data-drift-pipeline repository](https://github.com/khuyentran1401/detect-data-drift-pipeline)
    to get the docker-compose file for Kestra, then run:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Navigate to [localhost:8080](http://localhost:8080/) to access and explore the
    Kestra UI.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1a838ca283c40d4d82b9376507f305fd.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: Follow these [instructions](https://github.com/khuyentran1401/detect-data-drift-pipeline)
    to configure the required environment for this tutorial.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Before developing the target flows, let’s get familiar with Kestra by creating
    some simple flows.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Access Postgres Tables From a Python Script
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will create a flow that includes the following tasks:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '`getReferenceTable`: Exports a CSV file from a Postgres table.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`saveReferenceToCSV`: Creates a local CSV file that can be accessed by the
    Python task.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`runPythonScript`: Reads the local CSV file with Python.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To enable data passing between the `saveReferenceToCSV` and `runPythonScript`
    tasks, we will place these two tasks in the same working directory by enclosing
    them inside the `wdir` task.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/44e62914c8c5b0c999d474d9d9666370.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: 'Executing the flow will show the following logs:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0229ba03295229c369b01a8935459d49.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Parameterize Flow with Inputs
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s create another flow that can be parameterized with inputs. This flow
    will have the following inputs: `startDate`, `endDate`, and `dataURL`.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: The `getCurrentCSV` task can access these inputs using the `{{inputs.name}}`
    notation.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/87d1ffd8c99d5157d0a0150b8d72fe34.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: The values of these inputs can be specified in each flow execution.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d1b49a9a4e18af13b7733b23d54cbc33.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Load a CSV File into a Postgres Table
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following flow does the following tasks:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '`getCurrentCSV`: Runs a Python script to create a CSV file in the working directory.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`saveFiles`: Sends the CSV file from the working directory to Kestra''s internal
    storage.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`saveToCurrentTable`: Loads the CSV file into a Postgres table.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/1de966b034e4885dacb6ac0314a3e300.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: After running this flow, you will see the resulting data in the “current” table
    within your Postgres database.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此流程后，你将在 Postgres 数据库中的“current”表中看到结果数据。
- en: '![](../Images/fbc70170398295680a9ac5bbb5719cd4.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fbc70170398295680a9ac5bbb5719cd4.png)'
- en: Image by Author
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Run a File From a GitHub Repository
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从 GitHub 仓库中运行文件
- en: 'This flow includes the following tasks:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 此流程包括以下任务：
- en: '`cloneRepository`: Clones a public GitHub repository'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cloneRepository`：克隆一个公共 GitHub 仓库'
- en: '`runPythonCommand`: Executes a Python script from a CLI'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`runPythonCommand`：从 CLI 执行一个 Python 脚本'
- en: Both of these tasks will operate within the same working directory.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个任务将在同一工作目录中操作。
- en: '[PRE6]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/6b2586cf15d9c1f6c82c384c0c489220.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6b2586cf15d9c1f6c82c384c0c489220.png)'
- en: Image by Author
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'After running the flow, you will see the following logs:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 运行流程后，你将看到以下日志：
- en: '![](../Images/0c4413d165a8d794188b80e3da871b71.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0c4413d165a8d794188b80e3da871b71.png)'
- en: Image by Author
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Run a Flow on Schedule
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 按计划运行一个流程
- en: We will create another flow that runs a flow based on a specific schedule. The
    following flow runs at 11:00 AM every Monday.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建另一个基于特定时间表运行的流程。以下流程在每周一上午 11:00 运行。
- en: '[PRE7]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Upload to S3
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 上传到 S3
- en: 'This flow includes the following tasks:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 此流程包括以下任务：
- en: '`createPickle`: Generates a pickle file in Python'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`createPickle`：在 Python 中生成一个 pickle 文件'
- en: '`savetoPickle`: Transfers the pickle file to Kestra''s internal storage'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`savetoPickle`：将 pickle 文件转移到 Kestra 的内部存储'
- en: '`upload`: Uploads the pickle file to an S3 bucket'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`upload`：将 pickle 文件上传到 S3 桶'
- en: '[PRE8]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/fd9fb0b08e7002ba19882ac87c1d13f4.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fd9fb0b08e7002ba19882ac87c1d13f4.png)'
- en: Image by Author
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: After running this flow, the `data.pkl` file will be uploaded to the "bike-sharing"
    bucket.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此流程后，`data.pkl` 文件将上传到“bike-sharing”桶中。
- en: '![](../Images/fb126a6249d2ca4bcaa71dd87ca96432.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fb126a6249d2ca4bcaa71dd87ca96432.png)'
- en: Image by Author
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Put Everything Together
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将一切整合在一起
- en: Build a Flow to Detect Data Drift
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建一个流程来检测数据漂移
- en: 'Now, let’s combine what we have learned to create a flow to detect data drift.
    At 11:0 AM every Monday, this flow executes the following tasks:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们结合所学创建一个检测数据漂移的流程。每周一上午 11:00，这个流程执行以下任务：
- en: Fetches reference data from the Postgres database.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 Postgres 数据库中获取参考数据。
- en: Runs a Python script to get the current production data from the web.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行一个 Python 脚本以从网络获取当前生产数据。
- en: Clones the GitHub repository containing the drift detection code
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 克隆包含漂移检测代码的 GitHub 仓库
- en: Runs a Python script to data drift by comparing the reference and current data.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行一个 Python 脚本，通过比较参考数据和当前数据来检测数据漂移。
- en: Appends the current data to the existing Postgres database.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将当前数据附加到现有的 Postgres 数据库中。
- en: '![](../Images/47a206ff95c59d1fcf51066f79f58875.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/47a206ff95c59d1fcf51066f79f58875.png)'
- en: Image by Author
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: '[PRE9]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Build a Flow to Send Slack Messages
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建一个流程来发送 Slack 消息
- en: Next, we will create a flow to send Slack messages via a [Slack Webhook URL](https://api.slack.com/messaging/webhooks)
    when the `detectDataDrift` task inside the `detect-data-drift` flow returns `drift_detected=true`.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个流程，通过一个 [Slack Webhook URL](https://api.slack.com/messaging/webhooks)
    在 `detect-data-drift` 流程中的 `detectDataDrift` 任务返回 `drift_detected=true` 时发送 Slack
    消息。
- en: '![](../Images/def45e005820f105f401b936d94c72c7.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/def45e005820f105f401b936d94c72c7.png)'
- en: Image by Author
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: '[PRE10]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: After running the `detect-data-drift` flow, the `send-slack-message` flow will
    send a message on Slack.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 `detect-data-drift` 流程后，`send-slack-message` 流程将发送一条 Slack 消息。
- en: '![](../Images/354ca0f5c2948f71f2d0d3d6e697e04d.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/354ca0f5c2948f71f2d0d3d6e697e04d.png)'
- en: Image by Author
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Build a Flow to Retrain the Model
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建一个流程以重新训练模型
- en: 'Lastly, we will create a flow to retrain the model. This flow executes the
    following tasks:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将创建一个流程来重新训练模型。这个流程执行以下任务：
- en: Exports a CSV file from the current table in the Postgres database
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 Postgres 数据库的当前表导出一个 CSV 文件
- en: Clones the GitHub repository containing the model training code
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 克隆包含模型训练代码的 GitHub 仓库
- en: Runs a Python script to train the model and generates a pickle file
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行一个 Python 脚本来训练模型并生成一个 pickle 文件
- en: Uploads the pickle file to S3
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上传 pickle 文件到 S3
- en: '![](../Images/253b848b5ef7fa84acbb3d646ff324ac.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/253b848b5ef7fa84acbb3d646ff324ac.png)'
- en: Image by Author
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: '[PRE11]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: After running this flow, the `model.pkl` file will be uploaded to the “bike-sharing”
    bucket.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此流程后，`model.pkl` 文件将上传到“bike-sharing”桶中。
- en: '![](../Images/032f439354c4a375bd0af16db6b4a192.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/032f439354c4a375bd0af16db6b4a192.png)'
- en: Image by Author
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Ideas to Extend This Workflow
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展此工作流程的想法
- en: Rather than relying on scheduled data pulls to identify data drift, we can leverage
    [Grafana’s outgoing webhook](https://grafana.com/docs/oncall/latest/outgoing-webhooks/)
    and [Kestra’s inbound webhook](https://kestra.io/plugins/core/triggers/io.kestra.core.models.triggers.types.webhook)
    to establish real-time data monitoring and trigger a flow instantly when data
    drift occurs. This approach enables the detection of data drift as soon as it
    happens, eliminating the need to wait for a scheduled script to run.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 与其依赖计划的数据提取来识别数据漂移，我们可以利用[Grafana的外发Webhook](https://grafana.com/docs/oncall/latest/outgoing-webhooks/)和[Kestra的入站Webhook](https://kestra.io/plugins/core/triggers/io.kestra.core.models.triggers.types.webhook)来建立实时数据监控，并在数据漂移发生时立即触发流程。这种方法能够在数据漂移发生时立即检测，避免了等待计划脚本运行的需要。
- en: '![](../Images/4f595292d9b246c072b5f1a5e60c0e39.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f595292d9b246c072b5f1a5e60c0e39.png)'
- en: Image by Author
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Let me know in the comments how you think this workflow could be extended and
    what other use cases you would like to see in future content.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 请在评论中告诉我你认为这个工作流程可以如何扩展，以及你希望在未来的内容中看到其他什么用例。
- en: 'I love writing about data science concepts and playing with different data
    science tools. You can stay up-to-date with my latest posts by:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我喜欢撰写关于数据科学概念的文章，并玩弄不同的数据科学工具。你可以通过以下方式保持更新我的最新帖子：
- en: Subscribing to my newsletter on [Data Science Simplified](https://mathdatasimplified.com/).
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 订阅我在[数据科学简化](https://mathdatasimplified.com/)上的新闻通讯。
- en: Connect with me on [LinkedIn](https://www.linkedin.com/in/khuyen-tran-1401/)
    and [Twitter](https://twitter.com/KhuyenTran16).
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[LinkedIn](https://www.linkedin.com/in/khuyen-tran-1401/)和[Twitter](https://twitter.com/KhuyenTran16)上与我联系。
