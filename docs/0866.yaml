- en: 'Unleash the Hidden Patterns: A Guide to Unsupervised Machine Learning for Article
    Recommender System'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/unleash-the-hidden-patterns-a-guide-to-unsupervised-machine-learning-for-article-recommender-d1e7eb219c8d?source=collection_archive---------12-----------------------#2023-03-07](https://towardsdatascience.com/unleash-the-hidden-patterns-a-guide-to-unsupervised-machine-learning-for-article-recommender-d1e7eb219c8d?source=collection_archive---------12-----------------------#2023-03-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Build an article recommender system with unsupervised machine learning and generate
    features and patterns that aid in the recommendation
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://suhas-maddali007.medium.com/?source=post_page-----d1e7eb219c8d--------------------------------)[![Suhas
    Maddali](../Images/933f27eab8ba9ee1f06ed2f24746d788.png)](https://suhas-maddali007.medium.com/?source=post_page-----d1e7eb219c8d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d1e7eb219c8d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d1e7eb219c8d--------------------------------)
    [Suhas Maddali](https://suhas-maddali007.medium.com/?source=post_page-----d1e7eb219c8d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2a74f90399ae&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funleash-the-hidden-patterns-a-guide-to-unsupervised-machine-learning-for-article-recommender-d1e7eb219c8d&user=Suhas+Maddali&userId=2a74f90399ae&source=post_page-2a74f90399ae----d1e7eb219c8d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d1e7eb219c8d--------------------------------)
    ·8 min read·Mar 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd1e7eb219c8d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funleash-the-hidden-patterns-a-guide-to-unsupervised-machine-learning-for-article-recommender-d1e7eb219c8d&user=Suhas+Maddali&userId=2a74f90399ae&source=-----d1e7eb219c8d---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd1e7eb219c8d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funleash-the-hidden-patterns-a-guide-to-unsupervised-machine-learning-for-article-recommender-d1e7eb219c8d&source=-----d1e7eb219c8d---------------------bookmark_footer-----------)![](../Images/ad11778233ec9ecd731942319dd78857.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Salomé Watel](https://unsplash.com/@samefaisrire?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: There have been a lot of talks lately about the incredible capabilities of **artificial
    intelligence** and **machine learning**. As we go on to see various frontiers
    at which ML could be applied, there is a growing possibility of higher value generated
    as a result of this transition. Companies such as **Google**, **Microsoft**, and
    **NVIDIA** are pushing the boundaries at which AI and machine learning are used
    to build a great society with technological advancements.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 最近有很多关于**人工智能**和**机器学习**令人难以置信的能力的讨论。随着我们看到机器学习应用的各种前沿领域，这一转变所产生的更高价值的可能性也在不断增长。像**谷歌**、**微软**和**英伟达**这样的公司正在推动人工智能和机器学习的边界，以利用技术进步建设一个伟大的社会。
- en: Now that there is a lot of **hype** in this AI, an often less talked about topic
    is that of unsupervised machine learning. I bet that people might have had the
    opportunity to enjoy some of the greatest streaming services such as **Netflix**
    and **Amazon Videos** with their state-of-the-art recommendation systems. However,
    there has been less talk about the incredible capabilities of recommendation system
    which is also part of the unsupervised machine learning.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，人工智能的**炒作**非常多，一个常被忽视的话题是无监督机器学习。我敢打赌，人们可能已经有机会享受一些最先进的流媒体服务，如**Netflix**和**Amazon
    Videos**，它们拥有最先进的推荐系统。然而，对于作为无监督机器学习一部分的推荐系统的惊人能力却鲜有讨论。
- en: In this article, we will mainly focus on building an article recommender system
    based on the previously read articles by the user, giving them a positive experience
    and an inclination to read more of these similar types of articles. This comes
    under unsupervised machine learning as we do not have **labels** about whether
    a particular article is related to others or not. Instead, we are only given **textual
    information** based on which, we must highlight and visualize the similarities
    before recommending items to users.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将主要关注基于用户之前阅读的文章构建文章推荐系统，为他们提供积极的体验，并促使他们阅读更多类似类型的文章。这属于无监督机器学习，因为我们没有关于特定文章是否与其他文章相关的**标签**。相反，我们仅提供**文本信息**，我们必须在向用户推荐项目之前突出和可视化相似性。
- en: Initially, we start with the data and understand their types before continuing
    our effort to recommend articles. After going through the data, we will visualize
    key insights from the data. Finally, we build a recommender system based on **cosine
    similarity** scores between an article and a list of all the articles to get a
    recommendation.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，我们从数据开始，并在继续推荐文章的努力之前了解它们的类型。在浏览数据后，我们将可视化数据中的关键见解。最后，我们根据文章与所有文章列表之间的**余弦相似度**分数构建推荐系统以获取推荐。
- en: Reading the Data
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 阅读数据
- en: The first step would be to read the data. Below is the code for reading the
    data. After reading the data, we would be performing exploratory data analysis.
    Here is the code and the representation of data.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是读取数据。以下是读取数据的代码。读取数据后，我们将进行探索性数据分析。这里是数据的代码和表示。
- en: '**Note:** The dataset was taken from [Articles sharing and reading from CI&T
    DeskDrop | Kaggle](https://www.kaggle.com/datasets/gspmoreira/articles-sharing-reading-from-cit-deskdrop?select=shared_articles.csv)
    under [Database Contents License (DbCL) v1.0 — Open Data Commons: legal tools
    for open data](https://opendatacommons.org/licenses/dbcl/1-0/) license'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 数据集来自 [CI&T DeskDrop 文章分享与阅读 | Kaggle](https://www.kaggle.com/datasets/gspmoreira/articles-sharing-reading-from-cit-deskdrop?select=shared_articles.csv)，根据
    [数据库内容许可证 (DbCL) v1.0 — 开放数据公约：开放数据的法律工具](https://opendatacommons.org/licenses/dbcl/1-0/)
    许可证'
- en: '![](../Images/357c5fa254723584339801ef66c9b52f.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/357c5fa254723584339801ef66c9b52f.png)'
- en: Input Data (Image by Author)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 输入数据（作者提供的图片）
- en: There are title, text, and language features that are most important in our
    data. Other features such as content type and author user agent are not very suitable
    for this task of building a recommendation system. Steps would be taken to **remove**
    such features and only consider the features such as title, text, and language
    respectively. Note that not all the features are shown in the figure as this would
    become a large image.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的数据中，标题、文本和语言特征是最重要的。其他特征，如内容类型和作者用户代理，对于构建推荐系统的任务并不十分适用。我们将采取步骤**去除**这些特征，仅考虑标题、文本和语言等特征。请注意，图中未显示所有特征，因为这将成为一张大图。
- en: '![](../Images/51fe2588cb6962002f249a003357111b.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/51fe2588cb6962002f249a003357111b.png)'
- en: Data Information (Image by Author)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 数据信息（作者提供的图片）
- en: We get the information about the data and determine the number of **non-null**
    values present in the dataset. It is seen that there are features such as authorSessionID
    and authorUserAgent that contain more than **50 percent** missing values. We are
    going to be removing all of these features along with others as discussed above
    and would be focusing only on the title, text, and language features.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获取数据的信息，并确定数据集中存在的**非空**值的数量。我们发现有些特征如authorSessionID和authorUserAgent包含超过**50%**的缺失值。我们将删除这些特征以及上面讨论的其他特征，专注于标题、文本和语言特征。
- en: '**Exploratory Data Analysis (EDA)**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**探索性数据分析（EDA）**'
- en: Let us now explore the dataset and get an understanding of it by using visuals
    and graphs. The first step would be to explore the type of text content present
    in the data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们通过使用视觉效果和图表来探索数据集并理解它。第一步是探索数据中存在的文本内容类型。
- en: '![](../Images/b237e493067952b2625ea4b637cc48bc.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b237e493067952b2625ea4b637cc48bc.png)'
- en: Countplot of content types (Image by Author)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 内容类型的计数图（作者提供的图片）
- en: Observing from the plot, a large portion of the contents are in the form of
    **HTML links** to be used for recommendation. These HTML links contain the actual
    text data and the titles. Our focus here is to extract meaningful insights from
    text instead of using other formats such as ‘video’ and ‘rich’ formats. Therefore,
    we can remove these categories from our project.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 从图中观察，大部分内容以**HTML链接**的形式存在，用于推荐。这些HTML链接包含实际的文本数据和标题。我们在这里的重点是从文本中提取有意义的见解，而不是使用其他格式，如‘视频’和‘富媒体’格式。因此，我们可以从项目中删除这些类别。
- en: '![](../Images/59d222818e2d296342ecb3ff074f885c.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/59d222818e2d296342ecb3ff074f885c.png)'
- en: Countplot of languages (Image of Author)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 语言的计数图（作者提供的图片）
- en: A large portion of our text and titles are English titles. Since our focus is
    only on the English language, we can take the steps to remove other categories
    to improve our recommendation model efficiency.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的大部分文本和标题都是英文标题。由于我们只关注英语语言，我们可以采取措施删除其他类别，以提高我们的推荐模型效率。
- en: '![](../Images/d3ee51376c882208a425f67167ff63ab.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d3ee51376c882208a425f67167ff63ab.png)'
- en: Title Wordcloud (Image by Author)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 标题词云（作者提供的图片）
- en: Wordcloud gives a good understanding of the most frequently occurring words
    in our corpus of text. The higher the **occurrence** of words in a corpus, the
    **bigger** the text sizes in a word cloud plot. As seen from the plot, word titles
    having terms such as ‘Google’, ‘Machine Learning’, and ‘Apple’ are often used
    in our title space.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 词云提供了对我们文本语料库中最常出现的词汇的良好理解。词汇在语料库中的**出现频率**越高，词云图中的文本大小就**越大**。从图中可以看出，包含‘Google’、‘机器学习’和‘Apple’等词汇的标题在我们的标题空间中经常出现。
- en: '![](../Images/099d57db38d7844dbaf9fa6604a82fef.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/099d57db38d7844dbaf9fa6604a82fef.png)'
- en: Text Wordcloud (Image by Author)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 文本词云（作者提供的图片）
- en: Now that we explored the title and found the most commonly occurring words,
    it is time to explore the **text** itself in our list of articles to find interesting
    trends and patterns. A large proportion of articles contain words such as ‘data’,
    ‘user’, and ‘time’.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探索了标题并找出了最常见的词汇，是时候在我们的文章列表中探索**文本**本身，寻找有趣的趋势和模式了。大量文章包含‘数据’、‘用户’和‘时间’等词汇。
- en: '![](../Images/1134156961b15899686a8f994dcd2f12.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1134156961b15899686a8f994dcd2f12.png)'
- en: Percentage of Variance explained (Image by Author)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 方差解释百分比（作者提供的图片）
- en: Converting the given set of titles into a **TFIDF** format and applying **principal
    component analysis**, the above plot showcases the cumulative percentage of variance
    explained by each of the components. It is to be noted that with the increase
    in the number of components, there is an increase in the variance explained as
    more information from components leads to more explanation and information.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 将给定的一组标题转换为**TFIDF**格式并应用**主成分分析**，上述图表展示了每个组件解释的方差累计百分比。值得注意的是，随着组件数量的增加，解释的方差也在增加，因为更多的组件信息导致了更多的解释和信息。
- en: '![](../Images/3ad5a2a5a74e670bb48fa69f0861f8a5.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3ad5a2a5a74e670bb48fa69f0861f8a5.png)'
- en: Percentage of Variance explained (Image by Author)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 方差解释百分比（作者提供的图片）
- en: This plot shows the variance explained by the tfidf components on the entire
    text instead of only considering the title. This plot is quite different from
    the previous plot in that only a few sets of principal components are able to
    explain a large portion of the variance in the data. Therefore, this can help
    in dimensionality reduction as fewer features are able to explain a large portion
    of the variance.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 此图显示了 tfidf 组件对整个文本解释的方差，而不仅仅是考虑标题。这个图与之前的图大相径庭，因为只有少数主成分集能够解释数据方差的大部分。因此，这可以帮助降维，因为更少的特征能够解释大部分方差。
- en: '![](../Images/c0c53704dd1dce352c0b037c23a1df32.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c0c53704dd1dce352c0b037c23a1df32.png)'
- en: K-means clustering plot (Image by Author)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: K-means 聚类图（图片来源：作者）
- en: Clustering is a technique where data points that are similar are grouped together
    to find interesting patterns and commonalities among them. In this way, recommendations
    are given based on the cluster at which a data point is present.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类是一种将相似的数据点分组在一起的技术，以寻找有趣的模式和共同点。通过这种方式，基于数据点所在的簇，可以给出推荐。
- en: In order to determine the right number of clusters, it is handy to use the **k-means
    clustering model** and follow the **elbow method** to find the optimum number
    of clusters. In our case, the best value of **k is 11** as this follows the shape
    of an elbow.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定正确的簇数，使用**k-means 聚类模型**并遵循**肘部法则**来找到最佳簇数是很方便的。在我们的案例中，最佳值**k 为 11**，因为它符合肘部的形状。
- en: '![](../Images/6834bec07faa8e4bc45bcbd4c8463084.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6834bec07faa8e4bc45bcbd4c8463084.png)'
- en: PCA with clustering 2D plot (Image by Author)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: PCA 与聚类 2D 图（图片来源：作者）
- en: After performing PCA and clustering based on the optimum number of clusters,
    it is time to visualize the results of the clustering. Based on the plot above,
    the clustering is working quite well as there is a pattern found in the clusters.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行 PCA 和基于最佳簇数的聚类后，到了可视化聚类结果的时刻。根据上述图，聚类效果相当不错，因为在簇中发现了模式。
- en: '![](../Images/519d128c07d150757e9e564f1fc2e106.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/519d128c07d150757e9e564f1fc2e106.png)'
- en: PCA with clustering 3D plot (Image by Author)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: PCA 与聚类 3D 图（图片来源：作者）
- en: Let’s determine how the plot looks in **3D** to find the underlying patterns.
    As can be seen, there is a lot of room for the separation of clusters, hence guiding
    our recommender system to give good suggestions to the user based on the previously
    read text.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们确定**3D** 图的外观，以发现潜在的模式。可以看到，有很多空间可以分隔簇，因此可以指导我们的推荐系统根据之前阅读的文本给出好的建议。
- en: There are other dimensionality reduction techniques such as **TSNE** and **Kernal
    PCA**. Going through each of them to determine the best clustering would be handy
    for a recommender system. Steps must be taken to visualize the data points from
    the text and generate interesting patterns.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他降维技术，如**TSNE**和**Kernal PCA**。逐一了解它们以确定最佳聚类对于推荐系统将很有帮助。必须采取步骤可视化文本数据点并生成有趣的模式。
- en: '![](../Images/dd356cc21d74bc6c1a684b5f869e9e59.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dd356cc21d74bc6c1a684b5f869e9e59.png)'
- en: TSNE with clustering 2D plot (Image by Author)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: TSNE 与聚类 2D 图（图片来源：作者）
- en: Reducing the dimensions using TSNE and visualizing the representations with
    11 clusters, it is seen that the data points are spread out quite well. Therefore,
    there are lower chances for articles that are similar to be in the same cluster.
    As a result, PCA was performing well in terms of clustering and determining the
    optimum number of clusters. We will also use 3D visualizations to guide our thinking
    and understanding of clustering mechanisms.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 TSNE 降维并以 11 个簇可视化表示，可以看到数据点分布得很好。因此，相似的文章在同一簇中的机会较小。结果，PCA 在聚类和确定最佳簇数方面表现良好。我们还将使用
    3D 可视化来指导我们的思考和理解聚类机制。
- en: '![](../Images/cea23c0ebc383f52dd08393f6aed5cd1.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cea23c0ebc383f52dd08393f6aed5cd1.png)'
- en: TSNE with clustering 3D plot (Image by Author)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: TSNE 与聚类 3D 图（图片来源：作者）
- en: After performing the task of clustering, it is seen that a lot of data embeddings
    of the text are quite **close** to each other. Therefore, it can be challenging
    to accurately perform clustering when the points are not spread in various directions.
    Hence, we might look for alternative clustering approaches and dimensionality
    reduction techniques.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行聚类任务后，可以看到许多文本的数据嵌入非常**接近**。因此，当数据点没有在各个方向上分布时，准确执行聚类可能具有挑战性。因此，我们可能会寻找替代的聚类方法和降维技术。
- en: '![](../Images/66066aa94a40745751f618b8b3e3a95b.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/66066aa94a40745751f618b8b3e3a95b.png)'
- en: Kernel PCA with clustering 2D Plot (Image by Author)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 核PCA与聚类2D图（作者提供的图片）
- en: Kernel PCA is another popular method that is used for dimensionality reduction.
    As could be seen, the data representations are spread out well for determining
    and using the number of clusters. Overall, the algorithm reduces the dimensions
    well and separated data points well. Let us also go over the **3d representation**
    of clusters as a result of performing dimensionality reduction with this technique.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 核PCA是另一种用于维度缩减的流行方法。如所见，数据表示的分布良好，有助于确定和使用聚类的数量。总体而言，算法很好地减少了维度并分离了数据点。让我们也来看一下使用这种技术进行维度缩减后的**3D表示**的聚类结果。
- en: '![](../Images/04c47e153c7e68f581fd4b107379e71d.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/04c47e153c7e68f581fd4b107379e71d.png)'
- en: Kernel PCA with clustering 3D Plot (Image by Author)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 核PCA与聚类3D图（作者提供的图片）
- en: After plotting a 3d generated representation with kernel PCA, clustering took
    place quite well and the points are quite spread out. Therefore, this approach
    can help generate recommendations based on the clustering approach.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在用核PCA绘制了3D生成的表示后，聚类效果相当好，点分布也相当均匀。因此，这种方法可以帮助基于聚类方法生成推荐。
- en: Say, a user visits a **particular website** and reads an interesting piece of
    text. After this step, the items that are present in the cluster based on kernel
    PCA representation would be recommended to the user. The user can find these articles
    fascinating, resulting in the growth of the business.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 比如，用户访问一个**特定的网站**并阅读了一段有趣的文本。在这一步之后，基于核主成分分析（PCA）表示的簇中的项目将推荐给用户。用户可能会觉得这些文章很吸引人，从而促进业务增长。
- en: After performing the previous steps, we define a function that generates a list
    of **useful features** that could be used by various recommender system models
    to make recommendations. These features used in the function below are important
    and give a good representation of the type of text along with its content and
    readability.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行了之前的步骤后，我们定义了一个函数，生成一组**有用的特征**，这些特征可以被各种推荐系统模型用于进行推荐。以下函数中使用的特征是重要的，能够很好地表示文本的类型及其内容和可读性。
- en: We apply this function to our data frame and generate a new set of features
    that are used by recommender systems. Finally, **cosine similarity** is taken
    into account when determining the distance between the text of interest with the
    list of all the other possible texts and articles.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这个函数应用于数据框，并生成一组新的特征，这些特征被推荐系统所使用。最后，**余弦相似度**在确定感兴趣的文本与所有其他可能的文本和文章列表之间的距离时被考虑在内。
- en: After getting the cosine difference between the present text based on the features
    generated and a kernel PCA representation, it is compared with the list of existing
    articles to determine the ones with the lowest distance from clusters. As a result,
    those articles are recommended to users which makes them engaging and fun to read.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在根据生成的特征和核PCA表示获取当前文本的余弦差异后，将其与现有文章列表进行比较，以确定距离簇最小的文章。结果是，这些文章被推荐给用户，使他们的阅读体验变得引人入胜和有趣。
- en: We import various useful libraries for measuring the cosine similarities and
    generating recommendations for articles that are mostly similar in structure and
    content.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们导入了各种用于测量余弦相似度和生成结构和内容相似的文章推荐的有用库。
- en: Conclusion
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: After going through this exhaustive article, you should be getting a good idea
    about the working details of a particular implementation of **recommendation systems**
    on articles. Performing dimensionality reduction can ensure that we would reduce
    **compute resources** and also reduce the **impact of outliers** when making predictions
    or providing recommendations. Thanks for taking the time to read this article.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读了这篇详尽的文章之后，你应该对**推荐系统**在文章上的具体实现细节有了较好的了解。进行维度缩减可以确保我们减少**计算资源**的消耗，同时在进行预测或提供推荐时减少**异常值的影响**。感谢你花时间阅读这篇文章。
- en: '*Below are the ways where you could contact me or take a look at my work.*'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*以下是你可以联系我或查看我工作的方式。*'
- en: '***GitHub:***[*suhasmaddali (Suhas Maddali ) (github.com)*](https://github.com/suhasmaddali)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '***GitHub:***[*suhasmaddali (Suhas Maddali ) (github.com)*](https://github.com/suhasmaddali)'
- en: '***YouTube:***[*https://www.youtube.com/channel/UCymdyoyJBC_i7QVfbrIs-4Q*](https://www.youtube.com/channel/UCymdyoyJBC_i7QVfbrIs-4Q)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '***YouTube:***[*https://www.youtube.com/channel/UCymdyoyJBC_i7QVfbrIs-4Q*](https://www.youtube.com/channel/UCymdyoyJBC_i7QVfbrIs-4Q)'
- en: '***LinkedIn:***[*(1) Suhas Maddali, Northeastern University, Data Science |
    LinkedIn*](https://www.linkedin.com/in/suhas-maddali/)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '***LinkedIn:***[*(1) Suhas Maddali，东北大学，数据科学 | LinkedIn*](https://www.linkedin.com/in/suhas-maddali/)'
- en: '***Medium:*** [*Suhas Maddali — Medium*](https://suhas-maddali007.medium.com/)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '***Medium:*** [*Suhas Maddali — Medium*](https://suhas-maddali007.medium.com/)'
- en: '***Kaggle:***[*Suhas Maddali | Contributor | Kaggle*](https://www.kaggle.com/suhasmaddali007)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '***Kaggle:***[*Suhas Maddali | 贡献者 | Kaggle*](https://www.kaggle.com/suhasmaddali007)'
