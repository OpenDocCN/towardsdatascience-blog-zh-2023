- en: 'Similarity Search, Part 4: Hierarchical Navigable Small World (HNSW)'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/similarity-search-part-4-hierarchical-navigable-small-world-hnsw-2aad4fe87d37?source=collection_archive---------0-----------------------#2023-06-16](https://towardsdatascience.com/similarity-search-part-4-hierarchical-navigable-small-world-hnsw-2aad4fe87d37?source=collection_archive---------0-----------------------#2023-06-16)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Discover how to construct efficient multi-layered graphs to boost search speed
    in massive volumes of data
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@slavahead?source=post_page-----2aad4fe87d37--------------------------------)[![Vyacheslav
    Efimov](../Images/db4b02e75d257063e8e9d3f1f75d9d6d.png)](https://medium.com/@slavahead?source=post_page-----2aad4fe87d37--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2aad4fe87d37--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2aad4fe87d37--------------------------------)
    [Vyacheslav Efimov](https://medium.com/@slavahead?source=post_page-----2aad4fe87d37--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc8a0ca9d85d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimilarity-search-part-4-hierarchical-navigable-small-world-hnsw-2aad4fe87d37&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=post_page-c8a0ca9d85d8----2aad4fe87d37---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2aad4fe87d37--------------------------------)
    ·13 min read·Jun 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2aad4fe87d37&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimilarity-search-part-4-hierarchical-navigable-small-world-hnsw-2aad4fe87d37&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=-----2aad4fe87d37---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2aad4fe87d37&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimilarity-search-part-4-hierarchical-navigable-small-world-hnsw-2aad4fe87d37&source=-----2aad4fe87d37---------------------bookmark_footer-----------)![](../Images/d9c57ffdc93575971084c70c2b6d6e38.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: S**imilarity search** is a problem where given a query the goal is to find the
    most similar documents to it among all the database documents.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In data science, similarity search often appears in the NLP domain, search engines
    or recommender systems where the most relevant documents or items need to be retrieved
    for a query. There exists a large variety of different ways to improve search
    performance in massive volumes of data.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '[**Hierarchical Navigable Small World**](https://arxiv.org/pdf/1603.09320.pdf)
    (HNSW) is a state-of-the-art algorithm used for an approximate search of nearest
    neighbours. Under the hood, HNSW constructs optimized graph structures making
    it very different from other approaches that were discussed in previous parts
    of this article series.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: The main idea of HNSW is to construct such a graph where a path between any
    pair of vertices could be traversed in a small number of steps.
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'A well-known analogy on the famous [six handshakes rule](https://en.wikipedia.org/wiki/Six_degrees_of_separation)
    is related to this method:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: All people are six or fewer social connections away from each other.
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Before proceeding to inner workings of HNSW let us first discuss skip lists
    and navigable small words — crucial data structures used inside the HNSW implementation.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Skip lists
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Skip list](https://en.wikipedia.org/wiki/Skip_list) is a probabilistic data
    structure that allows inserting and searching elements within a sorted list for
    *O(logn)* on average. A skip list is constructed by several layers of linked lists.
    The lowest layer has the original linked list with all the elements in it. When
    moving to higher levels, the number of skipped elements increases, thus decreasing
    the number of connections.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2504b3cea528c33a5d4d7ff24c2d8778.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
- en: Finding element 20 in skip list
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: The search procedure for a certain value starts from the highest level and compares
    its next element with the value. If the value is less or equal to the element,
    then the algorithm proceeds to its next element. Otherwise, the search procedure
    descends to the lower layer with more connections and repeats the same process.
    At the end, the algorithm descends to the lowest layer and finds the desired node.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Based on the information from [Wikipedia](https://en.wikipedia.org/wiki/Skip_list),
    a skip list has the main parameter *p* which defines the probability of an element
    appearing in several lists. If an element appears in layer *i*, then the probability
    that it will appear in layer *i + 1* is equal to *p (p* is usually set to 0.5
    or 0.25*)*. On average, each element is presented in *1 / (1 — p)* lists.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, this process is much faster than the normal linear search in
    the linked list. In fact, HNSW inherits the same idea but instead of linked lists,
    it uses graphs.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Navigable Small World
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[**Navigable small world**](https://en.wikipedia.org/wiki/Small-world_network)
    is a graph with polylogarithmic *T = O(logᵏn)* search complexity which uses greedy
    routing. **Routing** refers to the process of starting the search process from
    low-degree vertices and ending with high-degree vertices. Since low-degree vertices
    have very few connections, the algorithm can rapidly move between them to efficiently
    navigate to the region where the nearest neighbour is likely to be located. Then
    the algorithm gradually zooms in and switches to high-degree vertices to find
    the nearest neighbour among the vertices in that region.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Vertex is sometimes also referred to as a **node**.
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Search
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the first place, search is proceeded by choosing an entry point. To determine
    the next vertex (or vertices) to which the algorithm makes a move, it calculates
    the distances from the query vector to the current vertex’s neighbours and moves
    to the closest one. At some point, the algorithm terminates the search procedure
    when it cannot find a neighbour node that is closer to the query than the current
    node itself. This node is returned as the response to the query.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a4eb5d43f3a843ea5c4d77ac2b3b8846.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
- en: Greedy search process in a navigable small world. Node A is used as an entry
    point. It has two neighbours B and D. Node D is closer to the query than B. As
    a result, we move to D. Node D has three neighbours C, E and F. E is the closest
    neighbour to the query, so we move to E. Finally, the search process will lead
    to node L. Since all neighbours of L are located further from the query than L
    itself, we stop the algorithm and return L as the answer to the query.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: This greedy strategy does not guarantee that it will find the exact nearest
    neighbour as the method uses only local information at the current step to take
    decisions. **Early stopping** is one of the problems of the algorithm. It occurs
    especially at the beginning of the search procedure when there are no better neighbour
    nodes than the current one. For the most part, this might happen when the starting
    region has too many low-degree vertices.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0f13febee8fe41bde554255204c8a1dc.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
- en: Early stopping. Both neighbours of the current node are further away from the
    query. Thus, the algorithm returns the current node as the response, though there
    exist much closer nodes to the query.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: The search accuracy can be improved by using several entry points.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: Construction
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The NSW graph is built by shuffling dataset points and inserting them one by
    one in the current graph. When a new node is inserted, it is then linked by edges
    to the *M* nearest vertices to it.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1b03640a542eb8fadb8ccfb27ff34f1c.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
- en: Sequential insertion of nodes (from left to right) with M = 2\. At each iteration,
    a new vertex is added to the graph and linked to its M = 2 nearest neighbours.
    Blue lines represent the connected edges to a newly inserted node.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: In most scenarios, long-range edges will likely be created at the beginning
    phase of the graph construction. They play an important role in graph navigation.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，长距离边缘可能会在图构建的初始阶段创建。它们在图导航中扮演着重要角色。
- en: Links to the closest neighbors of the elements inserted in the beginning of
    the construction later become bridges between the network hubs that keep the overall
    graph connectivity and allow the logarithmic scaling of the number of hops during
    greedy routing. — Yu. A. Malkov, D. A. Yashunin
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在构建开始时插入的元素的最近邻链接随后变成了网络中心之间的桥梁，这些桥梁保持了整个图的连通性，并允许在贪婪路由过程中对跳数进行对数缩放。 — Yu. A.
    Malkov, D. A. Yashunin
- en: From the example in the figure above, we can see the importance of the long-range
    edge *AB* that was added in the beginning. Imagine a query requiring the traverse
    of a path from the relatively far-located nodes *A* and I. Having the edge *AB*
    allows doing it rapidly by directly navigating from one side of the graph to the
    opposite one.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 从上图中的示例可以看出，在开始时添加的长距离边缘*AB*的重要性。设想一个查询需要遍历从相对远离的节点*A*到*I*的路径。拥有边缘*AB*允许通过直接从图的一侧导航到另一侧来快速完成这个过程。
- en: As the number of vertices in the graph increases, it increases the probability
    that the lengths of newly connected edges to a new node will be smaller.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 随着图中顶点数量的增加，新连接到新节点的边的长度变短的概率也增加。
- en: HNSW
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HNSW
- en: '[**HNSW**](https://arxiv.org/pdf/1603.09320.pdf) is based on the same principles
    as skip list and navigable small world. Its structure represents a multi-layered
    graph with fewer connections on the top layers and more dense regions on the bottom
    layers.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[**HNSW**](https://arxiv.org/pdf/1603.09320.pdf) 基于与跳表和可导航小世界相同的原理。它的结构表现为一个多层次的图，其中顶部层次的连接较少，而底部层次的区域则更为密集。'
- en: Search
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 搜索
- en: The search starts from the highest layer and proceeds to one level below every
    time the local nearest neighbour is greedily found among the layer nodes. Ultimately,
    the found nearest neighbour on the lowest layer is the answer to the query.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索从最高层开始，每次在层节点中贪婪地找到局部最近邻，然后逐层向下。最终，找到的最低层上的最近邻即为查询的答案。
- en: '![](../Images/5a334283e8e94afb5a71acfb241e76ca.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5a334283e8e94afb5a71acfb241e76ca.png)'
- en: Search in HNSW
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: HNSW中的搜索
- en: Similarly to NSW, the search quality of HNSW can be improved by using several
    entry points. Instead of finding only one nearest neighbour on each layer, the
    *efSearch* (a hyperparameter)closest nearest neighbours to the query vector are
    found and each of these neighbours is used as the entry point on the next layer.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于NSW，通过使用多个入口点可以提高HNSW的搜索质量。与其在每层上仅找到一个最近邻，不如使用*efSearch*（一个超参数）找到与查询向量最接近的最近邻，并将每个邻居作为下一层的入口点。
- en: Complexity
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 复杂度
- en: The authors of the [original paper](https://arxiv.org/pdf/1603.09320.pdf) claim
    that the number of operations required to find the nearest neighbour on any layer
    is bounded by a constant. Taking into consideration that the number of all layers
    in a graph is logarithmic, we get the total search complexity which is *O(logn)*.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[原始论文](https://arxiv.org/pdf/1603.09320.pdf)的作者声称，在任何层上查找最近邻所需的操作数都由一个常数限制。考虑到图中的所有层数是对数级的，我们得到了总的搜索复杂度，即*O(logn)*。'
- en: Construction
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建
- en: Choosing the maximum layer
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择最大层
- en: Nodes in HNSW are inserted sequentially one by one. Every node is randomly assigned
    an integer *l* indicating the maximum layer at which this node can present in
    the graph. For example, if *l = 1*, then the node can only be found on layers
    0 and 1\. The authors select *l* randomly for each node with an *exponentially
    decaying probability distribution* normalized by the non-zero multiplier *mL (mL
    = 0* results in a single layer in HNSW and non-optimized search complexity*)*.
    Normally, the majority of *l* values should be equal to 0, so most of the nodes
    are present only on the lowest level. The larger values of *mL* increase the probability
    of a node appearing on higher layers.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 节点在HNSW中是一个接一个地顺序插入的。每个节点会随机分配一个整数*l*，表示该节点可以出现在图中的最大层。例如，如果*l = 1*，则该节点只能在第0层和第1层找到。作者为每个节点随机选择*l*，其*指数衰减概率分布*由非零乘数*mL（mL
    = 0* 结果是HNSW中的单层和非优化的搜索复杂度）*进行归一化*。通常，大多数*l*值应该等于0，因此大多数节点仅存在于最低层。较大的*mL*值增加了节点出现在更高层的概率。
- en: '![](../Images/a1bcb306f30647ddfd33ea0369dab2bd.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a1bcb306f30647ddfd33ea0369dab2bd.png)'
- en: The number of layers l for every node is chosen randomly with *exponentially
    decaying probability distribution.*
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 每个节点的层数l是根据*指数衰减概率分布*随机选择的。
- en: '![](../Images/80559580b66a286c3abbfeaaf5127e17.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/80559580b66a286c3abbfeaaf5127e17.png)'
- en: Distribution of the number of layers based on normalization factor mL. The horizontal
    axis represents values of the uniform(0, 1) distribution.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 基于标准化因子*mL*的层数分布。横轴表示均匀分布(0, 1)的值。
- en: To achieve the optimum performance advantage of the controllable hierarchy,
    the overlap between neighbors on different layers (i.e. percent of element neighbors
    that are also belong to other layers) has to be small. — Yu. A. Malkov, D. A.
    Yashunin.
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为了实现可控层次结构的最佳性能优势，不同层之间的邻居重叠（即也属于其他层的元素邻居的百分比）必须很小。 — Yu. A. Malkov, D. A. Yashunin。
- en: One of the ways to decrease the overlap is to decrease *mL*. But it is important
    to keep in mind that reducing *mL* also leads on average to more traversals during
    a greedy search on each layer. That is why it is essential to choose such a value
    of *mL* that will balance both the overlap and the number of traversals.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 减少重叠的一个方法是减小*mL*。但重要的是要记住，减少*mL*通常会导致在每层贪婪搜索过程中需要更多的遍历。因此，选择一个能够平衡重叠和遍历次数的*mL*值至关重要。
- en: The authors of the paper propose choosing the optimal value of *mL* which is
    equal to *1 / ln(M)*. This value corresponds to the parameter *p = 1 / M* of the
    skip list being an average single element overlap between the layers.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 论文的作者建议选择*mL*的最佳值，即*1 / ln(M)*。该值对应于跳表的参数*p = 1 / M*，它是层间的平均单元素重叠。
- en: Insertion
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 插入
- en: 'After a node is assigned the value *l*, there are two phases of its insertion:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 节点被分配*l*值后，有两个插入阶段：
- en: The algorithm starts from the upper layer and greedily finds the nearest node.
    The found node is then used as an entry point to the next layer and the search
    process continues. Once the layer *l* is reached*,* the insertion proceeds to
    the second step.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 算法从上层开始，贪婪地找到最近的节点。找到的节点随后被用作下一层的入口点，搜索过程继续。一旦达到层*l*，插入过程就进入第二步。
- en: Starting from layer *l* the algorithm inserts the new node at the current layer.
    Then it acts the same as before at step 1 but instead of finding only one nearest
    neighbour, it greedily searches for *efConstruction* (hyperparameter) nearest
    neighbours. Then *M* out of *efConstruction* neighbours are chosen and edges from
    the inserted node to them are built. After that, the algorithm descends to the
    next layer and each of found *efConstruction* nodes acts as an entry point. The
    algorithm terminates after the new node and its edges are inserted on the lowest
    layer 0.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从层*l*开始，算法在当前层插入新节点。然后，它像之前一样执行第1步，但不是仅找到一个最近邻，而是贪婪地搜索*efConstruction*（超参数）个最近邻。然后从*efConstruction*个邻居中选择*M*个，并建立从插入节点到它们的边。之后，算法下降到下一层，每个找到的*efConstruction*节点作为入口点。算法在新节点及其边被插入到最低层0后终止。
- en: '![](../Images/9344c9f75ac1c76b943f2eb9edbe6d69.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9344c9f75ac1c76b943f2eb9edbe6d69.png)'
- en: Insertion of a node (in blue) in HNSW. The maximum layer for a new node was
    randomly chosen as l = 2\. Therefore, the node will be inserted on layers 2, 1
    and 0\. On each of these layers, the node will be connected to its M = 2 nearest
    neighbours.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在HNSW中插入一个节点（蓝色）。新节点的最大层随机选择为l = 2。因此，节点将被插入到层2、1和0。在每一层，节点将连接到其M = 2个最近邻。
- en: Choosing values for construction parameters
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择构造参数的值
- en: 'The original paper provides several useful insights on how to choose hyperparameters:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 原始论文提供了如何选择超参数的几个有用见解：
- en: According to simulations, good values for *M* lie between 5 and 48\. Smaller
    values of *M* tend to be better for lower recalls or low-dimensional data while
    higher values of M are suited better for high recalls or high-dimensional data.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据模拟，*M*的良好值在5到48之间。较小的*M*值适合较低的召回率或低维数据，而较大的M值则更适合较高的召回率或高维数据。
- en: Higher values of *efConstruction* imply a more profound search as more candidates
    are explored. However, it requires more computations. Authors recommend choosing
    such an *efConstruction* value that results at recall being close to *0.95–1*
    during training.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更高的*efConstruction*值意味着更深层次的搜索，因为会探索更多的候选项。然而，这也需要更多的计算。作者建议选择一个*efConstruction*值，以便在训练过程中回忆接近*0.95–1*。
- en: Additionally, there is another important parameter *Mₘₐₓ* — the maximum number
    of edges a vertex can have. Apart from it, there exists the same parameter *Mₘₐₓ₀*
    but separately for the lowest layer. It is recommended to choose a value for *Mₘₐₓ*
    close to *2 * M*. Values greater than *2 * M* can lead to performance degradation
    and excessive memory usage. At the same time, *Mₘₐₓ = M* results in poor performance
    at high recall.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Candidate selection heuristic
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It was noted above that during node insertion, *M* out of *efConstruction* candidates
    are chosen to build edges to them. Let us discuss possible ways of choosing these
    *M* nodes.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: The naïve approach takes *M* closest candidates. Nevertheless, it is not always
    the optimal choice. Below is an example demonstrating it.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Imagine a graph with the structure in the figure below. As you can see, there
    are three regions with two of them not being connected to each other (on the left
    and on the top). As a result, getting, for example, from point *A* to *B* requires
    a long path through another region. It would be logical to somehow connect these
    two regions for better navigation.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5d9fd78eec3c946eaa9179ffc20e6f7b.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
- en: Node X is inserted into the graph. The objective is to optimally connect it
    to other M = 2 points.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Then a node *X* is inserted into the graph and needs to be linked to *M* *=
    2* othervertices.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the naïve approach directly takes the *M = 2* nearest neighbours
    (*B* and *C*) and connects *X* to them. Though *X* is connected to its real nearest
    neighbours, it does not solve the problem. Let us look at the heuristical approach
    invented by the authors.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: The heuristic considers not only the closest distances between nodes but also
    the connectivity of different regions on the graph.
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The heuristic chooses the first nearest neighbour (*B* in our case) and connects
    the inserted node (*X*) to it. Then the algorithm sequentially takes another most
    closest nearest neighbour in the sorted order (*C*) and builds an edge to it only
    if the distance from this neighbour to the new node (*X*) is smaller than any
    distance from this neighbour to all already connected vertices (*B*) to the new
    node (*X*). After that, the algorithm proceeds to the next closest neighbour until
    *M* edges are built.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Getting back to the example, the heuristical procedure is illustrated in the
    figure below. The heuristic chooses *B* as the closest nearest neighbour for X
    and builds the edge *BX*. Then the algorithm chooses *C* as the next closest nearest
    neighbour. However, this time *BC < CX*. This indicates that adding the edge *CX*
    to the graph is not optimal because there already exists the edge *BX* and the
    nodes *B* and *C* are very close to each other. The same analogy proceeds with
    the nodes *D* and *E*. After that, the algorithm examines the node *A*. This time,
    it satisfies the condition since *BA* *> AX*. As a result, the new edge *AX* and
    both initial regions become connected to each other.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e6c85eede8fe13f3ede4e8fe2c082bed.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e6c85eede8fe13f3ede4e8fe2c082bed.png)'
- en: The example on the left uses the naïve approach. The example on the right uses
    the selection heuristic which results in two initial disjoint regions being connected
    to each other.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧的示例使用了简单的方法。右侧的示例使用了选择启发式，使两个初始不相交的区域相互连接。
- en: Complexity
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 复杂度
- en: The insertion process works very similarly, compared to the search procedure,
    without any significant differences which could require a non-constant number
    of operations. Thus, the insertion of a single vertex imposes *O(logn)* of time.
    To estimate the total complexity, the number of all inserted nodes *n* in a given
    dataset should be considered. Ultimately, HNSW construction requires *O(n * logn)*
    time.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 插入过程与搜索过程非常相似，没有显著的差异需要非恒定数量的操作。因此，单个顶点的插入需要 *O(logn)* 的时间。要估计总复杂度，应该考虑给定数据集中的所有插入节点
    *n*。最终，HNSW 构建需要 *O(n * logn)* 时间。
- en: Combining HNSW with other methods
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 HNSW 与其他方法结合使用
- en: HNSW can be used together with other similarity search methods to provide better
    performance. One of the most popular ways to do it is to combine it with an inverted
    file index and product quantization (*IndexIVFPQ*) which were described in other
    parts of this article series.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: HNSW 可以与其他相似性搜索方法结合使用，以提供更好的性能。最常见的方法之一是将其与倒排文件索引和产品量化（*IndexIVFPQ*）结合使用，这在本系列文章的其他部分中已有描述。
- en: '[](https://medium.com/@slavahead/similarity-search-blending-inverted-file-index-and-product-quantization-a8e508c765fa?source=post_page-----2aad4fe87d37--------------------------------)
    [## Similarity Search, Part 3: Blending Inverted File Index and Product Quantization'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@slavahead/similarity-search-blending-inverted-file-index-and-product-quantization-a8e508c765fa?source=post_page-----2aad4fe87d37--------------------------------)
    [## 相似性搜索，第 3 部分：融合倒排文件索引和产品量化'
- en: 'In the first two parts of this series we have discussed two fundamental algorithms
    in information retrieval: inverted…'
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在本系列的前两部分中，我们讨论了信息检索中的两个基本算法：倒排……
- en: medium.com](https://medium.com/@slavahead/similarity-search-blending-inverted-file-index-and-product-quantization-a8e508c765fa?source=post_page-----2aad4fe87d37--------------------------------)
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@slavahead/similarity-search-blending-inverted-file-index-and-product-quantization-a8e508c765fa?source=post_page-----2aad4fe87d37--------------------------------)
- en: Within this paradigm, HNSW plays the role of a **coarse quantizer** for *IndexIVFPQ*
    meaning that it will be responsible for finding the nearest Voronoi partition,
    so the search scope can be reduced. To do it, an HNSW index has to be built on
    all Voronoi centroids. When given a query, HNSW is used to find the nearest Voronoi
    centroid (instead of brute-force search as it was previously by comparing distances
    to every centroid). After that, the query vector is quantized within a respective
    Voronoi partition and distances are calculated by using PQ codes.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个范式中，HNSW 充当**粗量化器**的角色，负责找到最近的 Voronoi 划分，从而可以缩小搜索范围。为此，必须在所有 Voronoi 质心上构建
    HNSW 索引。给定查询时，使用 HNSW 找到最近的 Voronoi 质心（而不是之前通过比较每个质心的距离进行的暴力搜索）。之后，查询向量在相应的 Voronoi
    划分中被量化，并通过 PQ 代码计算距离。
- en: '![](../Images/e6c54daac1c43ee24feaa3ed5f5c0e5e.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e6c54daac1c43ee24feaa3ed5f5c0e5e.png)'
- en: Choosing the nearest Voronoi centroid by finding the nearest neighbour in HNSW
    built on top of Voronoi centroids.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在 Voronoi 质心上建立的 HNSW 中找到最近邻，选择最接近的 Voronoi 质心。
- en: When using only an inverted file index, it is better to set the number of Voronoi
    partitions not too large (256 or 1024, for instance) because brute-force search
    is performed to find the nearest centroids. By choosing a small number of Voronoi
    partitions, the number of candidates inside each partition becomes relatively
    large. Therefore, the algorithm rapidly identifies the nearest centroid for a
    query and most of its runtime is concentrated on finding the nearest neighbour
    inside a Voronoi partition.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 当仅使用倒排文件索引时，最好将 Voronoi 划分的数量设置得不太大（例如 256 或 1024），因为会执行暴力搜索以找到最近的质心。通过选择较少的
    Voronoi 划分，划分内的候选项数量变得相对较大。因此，算法迅速识别查询的最近质心，并且大部分运行时间集中在 Voronoi 划分内找到最近邻上。
- en: 'However, introducing HNSW into the workflow requires an adjustment. Consider
    running HNSW only on a small number of centroids (256 or 1024): HNSW would not
    bring any significant benefits because, with a small number of vectors, HNSW performs
    relatively the same in terms of execution time as naïve brute-force search. Moreover,
    HNSW would require more memory to store the graph structure.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: That is why when merging HNSW and inverted file index, it is recommended to
    set the number of Voronoi centroids much bigger than usual. By doing so, the number
    of candidates inside each Voronoi partition becomes much smaller.
  id: totrans-97
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This shift in paradigm results in the following settings:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: HNSW rapidly identifies the nearest Voronoi centroids in logarithmic time.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After that, an exhaustive search inside respective Voronoi partitions is performed.
    It should not be a trouble because the number of potential candidates is small.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Faiss implementation
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[**Faiss**](https://github.com/facebookresearch/faiss) (Facebook AI Search
    Similarity) is a Python library written in C++ used for optimised similarity search.
    This library presents different types of indexes which are data structures used
    to efficiently store the data and perform queries.'
  id: totrans-102
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Based on the information from the [Faiss documentation](https://faiss.ai), we
    will see how HNSW can be utilized and merged together with inverted file index
    and product quantization.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: IndexHNSWFlat
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'FAISS has a class *IndexHNSWFlat* implementing the HNSW structure. As usual,
    the suffix “*Flat*” indicates that dataset vectors are fully stored in index.
    The constructor accepts 2 parameters:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '**d**: data dimensionality.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**M**: the number of edges that need to be added to every new node during insertion.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Additionally, via thr **hnsw** field, *IndexHNSWFlat* provides several useful
    attributes (which can be modified) and methods:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '**hnsw.efConstruction**: number of nearest neighbours to explore during construction.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**hnsw.efSearch**: number of nearest neighbours to explore during search.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**hnsw.max_level**: returns the maximum layer.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**hnsw.entry_point**: returns the entry point.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**faiss.vector_to_array(index.hnsw.levels)**: returns a list of maximum layers
    for each vector'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**hnsw.set_default_probas(M: int, level_mult: float)**: allows setting *M*
    and *mL* values respectively. By default, *level_mult* is set to *1 / ln(M)*.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/d8aa815a66893b9d4185852daa96c27b.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
- en: Faiss implementation of IndexHNSWFlat
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '*IndexHNSWFlat* sets values for *Mₘₐₓ = M* and *Mₘₐₓ₀ = 2 * M.*'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: IndexHNSWFlat + IndexIVFPQ
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*IndexHNSWFlat* can be combined with other indexes as well. One of the examples
    is *IndexIVFPQ* described in the previous part. Creation of this composite index
    proceeds in two steps:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '*IndexHNSWFlat* is initialized as a coarse quantizer.'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The quantizer is passed as a parameter to the constructor of *IndexIVFPQ*.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Training and adding can be done by using different or the same data.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a2c65f1fd3db6f3c74764b883b6e46aa.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
- en: FAISS implementation of IndexHNSWFlat + IndexIVFPQ
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article, we have studied a robust algorithm which works especially well
    for large dataset vectors. By using multi-layer graph representations and the
    candidate selection heuristic its search speed scales efficiently while maintaining
    a decent prediction accuracy. It is also worth noting that HNSW can be used in
    combination with other similarity search algorithms making it very flexible.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Resources
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Six degrees of separation | Wikipedia](https://en.wikipedia.org/wiki/Six_degrees_of_separation)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Skip List | Wikipedia](https://en.wikipedia.org/wiki/Skip_list)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Efficient and robust approximate nearest neighbor search using Hierarchical
    Navigable Small World graphs. Yu. A. Malkov, D. A. Yashunin](https://arxiv.org/pdf/1603.09320.pdf)'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Faiss documentation](https://faiss.ai)'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Faiss repository](https://github.com/facebookresearch/faiss)'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Summary of Faiss indexes](https://github.com/facebookresearch/faiss/wiki/Faiss-indexes)'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*All images unless otherwise noted are by the author.*'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
