- en: Best Practices in Prompt Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/best-practices-in-prompt-engineering-a18d6bab904b?source=collection_archive---------2-----------------------#2023-05-01](https://towardsdatascience.com/best-practices-in-prompt-engineering-a18d6bab904b?source=collection_archive---------2-----------------------#2023-05-01)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learnings and Thoughts from Andrew Ng‚Äôs New Course
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://sophiamyang.medium.com/?source=post_page-----a18d6bab904b--------------------------------)[![Sophia
    Yang, Ph.D.](../Images/c133f918245ea4857dc46df3a07fc2b1.png)](https://sophiamyang.medium.com/?source=post_page-----a18d6bab904b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a18d6bab904b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a18d6bab904b--------------------------------)
    [Sophia Yang, Ph.D.](https://sophiamyang.medium.com/?source=post_page-----a18d6bab904b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fae9cae9cbcd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-in-prompt-engineering-a18d6bab904b&user=Sophia+Yang%2C+Ph.D.&userId=ae9cae9cbcd2&source=post_page-ae9cae9cbcd2----a18d6bab904b---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a18d6bab904b--------------------------------)
    ¬∑8 min read¬∑May 1, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa18d6bab904b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-in-prompt-engineering-a18d6bab904b&user=Sophia+Yang%2C+Ph.D.&userId=ae9cae9cbcd2&source=-----a18d6bab904b---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa18d6bab904b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-in-prompt-engineering-a18d6bab904b&source=-----a18d6bab904b---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Deep Learning AI has recently launched a new **ChatGPT Prompt Engineering for
    Developers** course led by Isa Fulford and Andrew Ng. It‚Äôs a free 1.5-hour short
    [course](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)
    and this course is amazing. In this article, I‚Äôd like to discuss these two parts:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 1: Course summary'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Part 2: My thoughts about the best practices in prompt engineering with ü¶úüîó**LangChain**
    and various **OpenAI tips and tricks**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Part 1: Course Summary'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This course includes three parts: two prompt principles, an iterative development
    process, and capabilities including summarizing, inferring, transforming, expanding,
    and building a chatbot.'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Two Principles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Principle 1: Write clear and specific instructions**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Tactic 1*: *Use delimiters like [PRE0] delimiters are used to indicate which
    text we‚Äôd like to summarize.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]{text}[PRE2]'
  prefs: []
  type: TYPE_NORMAL
- en: '*Tactic 2: Ask for structured output.* For example, we can the output to be
    in a JSON format, which we can later easily read into a list or a dictionary in
    Python.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/6b8b7a73257fe46a9e478d404604ff41.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Tactic 3: Check whether conditions are satisfied.* We can ask in the prompt
    to check assumptions first. It could also be helpful to think about edges and
    how models should handle them. In this example, the text doesn‚Äôt contain instructions,
    we gave the instruction for it to write ‚ÄúNo steps provided‚Äù.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/791cd61b03a677ccb521fa04a80ac009.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Tactic 4: few-shot prompting.* We give successful examples of completing tasks
    and then ask the model to perform the task.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/9e7bf3433415639379bdf186269b04a9.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Principle 2: Give the model time to ‚Äúthink‚Äù**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Tactic 1: specify the steps required to complete a task and ask for output
    in a specific format.* Sometimes it‚Äôs difficult for the models or the humans to
    come to an answer directly. For complicated tasks, step-by-step instructions are
    often helpful. Similar to how humans work, we can request the model to have a
    chain or a series of relevant reasoning before the model provides its final answer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/05ae19d163d959ca67b28b9d7fe5c85f.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Tactic 2: instruct the model to work out its own solution before rushing to
    a conclusion.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/cc29fdcdd2c6e19a8f1d709e101c17d9.png)'
  prefs: []
  type: TYPE_IMG
- en: '**2\. Iterative Prompt Development**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The iterative prompt development process is very similar to how we code. We
    try something and if it doesn‚Äôt work, we refine and retry:'
  prefs: []
  type: TYPE_NORMAL
- en: try something
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: analyze where the result does not give what you want
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: clarify instructions, give more time to think
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: refine prompts with a batch of examples
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: repeat
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the course example, Andrew walked through an example to generate marketing
    copy from a product fact sheet. He iteratively uncover and solved these three
    issues with refined prompts at each step.
  prefs: []
  type: TYPE_NORMAL
- en: 'Issue 1: The text is too long -> Solution: ‚ÄúUse at most 50 words‚Äù.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Issue 2\. Text focuses on the wrong details -> Solution: add intended audiences
    ‚ÄúThe description is intended for furniture retailers‚Ä¶‚Äù'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Issue 3\. Description needs a table of dimensions -> Solution:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ‚ÄúFormat everything as HTML‚Äù
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 3\. Capabilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Summarizing**: many people have used Large Language Models to summarize texts.
    You can specify your prompt to summarize the text with a specific focus for example
    on price and value:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]{prod_review}[PRE4]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, you can write a for loop to summarize multiple texts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]{reviews[i]}[PRE6]'
  prefs: []
  type: TYPE_NORMAL
- en: '**Inferring:** You can use Large Language Models to infer sentiment, infer
    emotions, extract product names, extract company names, infer topics, and more.
    You don‚Äôt need to train a model for a specific task anymore, Large Language Models
    can infer all these things for you without training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/2798b74b7105da43a9b03b740d8d42ba.png)![](../Images/48f643a66b203f3693002632fe7ecadf.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Transforming**: Large Language Models can do text transformation tasks such
    as language translation, spelling and grammar checking, tone adjustment, and format
    conversion.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/fc676f31da9ef77301e054a1d508cc8b.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Expanding:** Large Language Models can generate customer service emails that
    are tailored to each customer‚Äôs review:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/59e70e07e490867704fafc4d50c4cd95.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Building a chatbot:** I‚Äôm super grateful that they have chosen to use [**Panel**](https://panel.holoviz.org/)
    to build a chatbot!'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/7535bd90b2e0dbaa3d1c6f15f4def42a.png)'
  prefs: []
  type: TYPE_IMG
- en: Panel Chatbot
  prefs: []
  type: TYPE_NORMAL
- en: 'I have written several Panel blog posts and Panel chatbots. Please check out
    my previous blog posts on this topic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Building a Question Answering PDF Chatbot: LangChain + OpenAI + Panel + HuggingFace](/building-a-question-answering-pdf-chatbot-3e3b6372528c?sk=c7a34f5698689ab5caf4e456aba70da7)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[How to Make an AI Image Editing Chatbot: Stable Diffusion InstructPix2Pix
    in a Panel app](/how-to-make-an-ai-image-editing-chatbot-1ddd0209884?sk=6026446d930c62a9a407693050aeb72e)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[How to deploy a Panel app to Hugging Face using Docker](/how-to-deploy-a-panel-app-to-hugging-face-using-docker-6189e3789718?sk=9c2bbd9bdbc3917e39dbd1fc9d1a5771)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[ChatGPT and DALL¬∑E 2 in a Panel App](https://sophiamyang.medium.com/chatgpt-and-dall-e-2-in-a-panel-app-1c921d7d9021?sk=37f97ad29e6388ef79f29504fa82ba05)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[How to Deploy a Panel Visualization Dashboard to GitHub Pages](/how-to-deploy-a-panel-visualization-dashboard-to-github-pages-2f520fd8660?sk=72df0282cf53dc3afb957b2ed7033939)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[3 ways to build a Panel visualization dashboard](https://sophiamyang.medium.com/3-ways-to-build-a-panel-visualization-dashboard-6e14148f529d?sk=2cd93ae39586305bae8cfaead2bf7bb4)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Part 2: My Thoughts'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is a great course introducing many best practices and capabilities with
    ChatGPT prompt engineering. I especially like the two guiding principles. There
    are many other interesting issues remaining like how to deal with long tokens,
    how to use LLMs with other tools, how to handle rate limits, how to stream completions,
    and more. Building on top of this amazing course, I‚Äôd like to expand with two
    areas of thought: one is LangChain, and another is OpenAI tips and tricks.'
  prefs: []
  type: TYPE_NORMAL
- en: '**1\.** ü¶úüîó **LangChain**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ‚ú® **Do you have trouble getting started writing clear and specific instructions?**
    LangChain provides many prompt templates for you to use. You don‚Äôt need to write
    instructions from scratch every time.
  prefs: []
  type: TYPE_NORMAL
- en: ‚ú® **Would you like get more structured information than just text back?**LangChain
    provides [output parsers](https://python.langchain.com/en/latest/modules/prompts/output_parsers.html)
    to help structure language model responses.
  prefs: []
  type: TYPE_NORMAL
- en: '‚ú® **Is your text exceed token limits?** For example, if you would like to summarize
    or ask questions about a 500-page book. What do you do? With `map_reduce`, `refine`,
    `map-rerank`, LangChain allows you to separate text into batches and work through
    each batch:'
  prefs: []
  type: TYPE_NORMAL
- en: '`map_reduce`: It separates texts into batches, feeds each batch with the question
    to LLM separately, and comes up with the final answer based on the answers from
    each batch.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`refine` : It separates texts into batches, feeds the first batch to LLM, and
    feeds the answer and the second batch to LLM. It refines the answer by going through
    all the batches.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`map-rerank`: It separates texts into batches, feeds each batch to LLM, returns
    a score of how fully it answers the question, and comes up with the final answer
    based on the high-scored answers from each batch.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ‚ú® **Would you like to keep chat histories?** LangChain solves this problem by
    providing several different options for dealing with chat history ‚Äî keep all conversations,
    keep the latest k conversations, summarize the conversation, and a combination
    of the above.
  prefs: []
  type: TYPE_NORMAL
- en: ‚ú® **Would you like to use an LLM with another LLM or other tools?** LangChain
    can chain various LLMs together and use LLMs with a suite of tools like Google
    Search, Python REPL, and more.
  prefs: []
  type: TYPE_NORMAL
- en: ‚ú® **Would you like to ask the prompt to automatically write prompts, i.e., auto-GPT?**
    LangChain has implementations on ‚ÄúWestworld‚Äù simulation, Camel, BabyAGI, and AutoGPT.
    Check out my previous blog post [4 Autonomous AI Agents you need to Know](/4-autonomous-ai-agents-you-need-to-know-d612a643fa92?sk=01085386a4006466aadaffb20574d489).
  prefs: []
  type: TYPE_NORMAL
- en: 'To learn how LangChain works, check out my previous blog post and [my video](/the-easiest-way-to-interact-with-language-models-4da158cfb5c5?sk=271c9c82a16282f93ef3df37f034babe):'
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. OpenAI tips and tricks**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The OpenAI Cookbook provides many useful tips and tricks for us to use.
  prefs: []
  type: TYPE_NORMAL
- en: ‚ú® **How to avoid rate limit errors?** You can retrying with exponential backoff.
    Check [examples here](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_handle_rate_limits.ipynb).
  prefs: []
  type: TYPE_NORMAL
- en: Retrying with exponential backoff means performing a short sleep when a rate
    limit error is hit, then retrying the unsuccessful request. If the request is
    still unsuccessful, the sleep length is increased and the process is repeated.
    This continues until the request is successful or until a maximum number of retries
    is reached.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ‚ú® **How to maximize throughput of batch processing given rate limits?** Whenprocessing
    large volumes of batch data, two methods 1) proactively adding delay between requests
    and 2) batching requests by passing in a list of strings to prompt. Check [examples
    here](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_handle_rate_limits.ipynb).
  prefs: []
  type: TYPE_NORMAL
- en: ‚ú® **How to stream completions?** Simply set `stream=True` to stream completions.
    Check [examples here](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb).
  prefs: []
  type: TYPE_NORMAL
- en: By default, when you request a completion from the OpenAI, the entire completion
    is generated before being sent back in a single response. If you‚Äôre generating
    long completions, waiting for the response can take many seconds. To get responses
    sooner, you can ‚Äòstream‚Äô the completion as it‚Äôs being generated. This allows you
    to start printing or processing the beginning of the completion before the full
    completion is finished.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article, I provide a summary of the ChatGPT Prompt Engineering for Developers
    course. Additionally, I shared my thoughts around the prompt engineering best
    practices, including the use of ü¶úüîóLangChain and a few tips and tricks from OpenAI.
    I hope you find this article helpful! Feel free to share any other best practices
    for prompt engineering that you have come across.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f88950f024e00f6f0b62ac8f4fa59e76.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Eric Krull](https://unsplash.com/@ekrull?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/Ejcuhcdfwrs?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: . . .
  prefs: []
  type: TYPE_NORMAL
- en: By [Sophia Yang](https://www.linkedin.com/in/sophiamyang/) on April 30, 2023
  prefs: []
  type: TYPE_NORMAL
- en: Sophia Yang is a Senior Data Scientist. Connect with me on [LinkedIn](https://www.linkedin.com/in/sophiamyang/),
    [Twitter](https://twitter.com/sophiamyang), and [YouTube](https://www.youtube.com/SophiaYangDS)
    and join the DS/ML [Book Club](https://dsbookclub.github.io/) ‚ù§Ô∏è
  prefs: []
  type: TYPE_NORMAL
