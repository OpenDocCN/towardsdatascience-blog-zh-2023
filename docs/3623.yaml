- en: Temporal Graph Benchmark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/temporal-graph-benchmark-bb5cc26fcf11?source=collection_archive---------2-----------------------#2023-12-09](https://towardsdatascience.com/temporal-graph-benchmark-bb5cc26fcf11?source=collection_archive---------2-----------------------#2023-12-09)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Challenging and realistic datasets for temporal graph learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@shenyanghuang1996?source=post_page-----bb5cc26fcf11--------------------------------)[![Shenyang(Andy)
    Huang](../Images/ab63c37868db97b19480d536388930c5.png)](https://medium.com/@shenyanghuang1996?source=post_page-----bb5cc26fcf11--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bb5cc26fcf11--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bb5cc26fcf11--------------------------------)
    [Shenyang(Andy) Huang](https://medium.com/@shenyanghuang1996?source=post_page-----bb5cc26fcf11--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8aa224c5cedd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-graph-benchmark-bb5cc26fcf11&user=Shenyang%28Andy%29+Huang&userId=8aa224c5cedd&source=post_page-8aa224c5cedd----bb5cc26fcf11---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bb5cc26fcf11--------------------------------)
    ·10 min read·Dec 9, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbb5cc26fcf11&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-graph-benchmark-bb5cc26fcf11&user=Shenyang%28Andy%29+Huang&userId=8aa224c5cedd&source=-----bb5cc26fcf11---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbb5cc26fcf11&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-graph-benchmark-bb5cc26fcf11&source=-----bb5cc26fcf11---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: In recent years, significant advances have been made in machine learning on
    *static* graphs, accelerated by the availability of public datasets and standardized
    evaluation protocols, such as the widely adopted [Open Graph Benchmark](https://ogb.stanford.edu/)
    (OGB). However, many real-world systems such as social networks, transportation
    networks, and financial transaction networks evolve over time with nodes and edges
    constantly added or deleted. They are often modeled as temporal graphs. Until
    now, progress in temporal graph learning has been held back by the lack of large
    high-quality datasets, as well as the lack of proper evaluation thus leading to
    over-optimistic performance.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/55b9a02b0395a19d3392ea3ce09bde92.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Real world networks evolve over time. Image Credit: [Armand Khoury](https://unsplash.com/@armand_khoury?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral).'
  prefs: []
  type: TYPE_NORMAL
- en: To address this, we present [Temporal Graph Benchmark](https://tgb.complexdatalab.com/)
    (TGB), a collection of challenging and diverse benchmark datasets for realistic,
    reproducible, and robust evaluation for machine learning on temporal graphs. Inspired
    by the success of OGB, TGB automates dataset downloading and processing as well
    as evaluation protocols, and allows users to compare model performance using a
    leaderboard. We hope TGB would become a standardized benchmark for the temporal
    graph community and facilitate the development of novel methods and improve the
    understanding of large temporal networks.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4d62ef740fc78412625bdf79bdce99fc.png)'
  prefs: []
  type: TYPE_IMG
- en: Challenging and Realistic Benchmark for Temporal Graph Learning
  prefs: []
  type: TYPE_NORMAL
- en: 'Website: [https://tgb.complexdatalab.com/](https://tgb.complexdatalab.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Paper: [https://arxiv.org/abs/2307.01026](https://arxiv.org/abs/2307.01026)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Github: [https://github.com/shenyangHuang/TGB](https://github.com/shenyangHuang/TGB)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*This post is based on our paper* [*Temporal Graph Benchmark for Machine Learning
    on Temporal Graphs*](https://arxiv.org/abs/2307.01026) *(NeurIPS 2023 Datasets
    and Benchmarks Track) and was co-authored with* [*Emanuele Rossi*](https://emanuelerossi.co.uk/)*.
    Find more temporal graph work from* [*my website*](https://cs.mcgill.ca/~shuang43/)*.
    Want to learn more about temporal graphs? Join the* [*Temporal Graph Reading Group*](https://www.cs.mcgill.ca/~shuang43/rg.html)
    *and* [*Temporal Graph Learning Workshop @ NeurIPS 2023*](https://sites.google.com/view/tglworkshop-2023/home)
    *to learn more about state-of-the-art TG research.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Table of Contents:**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Motivation](#4c5e)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Problem Setting](#7eaf)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Dataset Details](#68dd)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Dynamic Link Property Prediction](#baea)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Dynamic Node Property Prediction](#3d58)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Get Started with TGB](#59dc)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Conclusion and Future Work](#f629)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Motivation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the last few years, the field of machine learning for static graphs has
    experienced a significant boost, largely due to the advent of public datasets
    and established benchmarks like the [Open Graph Benchmark](https://ogb.stanford.edu/)
    (OGB), the [Long Range Graph Benchmark](https://arxiv.org/abs/2206.08164), and
    the [TDC Benchmark](https://tdcommons.ai/benchmark/admet_group/overview/). However,
    many real-world systems such as social networks, transportation networks, and
    financial transaction networks are temporal: they evolve over time. Until now,
    the advancement in temporal graphs has been significantly hampered by the lack
    of large, high-quality datasets and comprehensive evaluation frameworks. This
    scarcity, coupled with evaluation limitations, has resulted in almost perfect
    AP or AUROC scores across models on popular datasets such as Wikipedia and Reddit,
    leading to an over-optimistic assessment of model performance and a challenge
    in differentiating between competing models.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Lack of datasets.** Common TG datasets only contain a few million edges,
    significantly smaller than the scale seen in real temporal networks. Furthermore,
    these datasets are mostly restricted to the domain of social and interaction networks.
    As network properties often vary significantly across domains, it is important
    to benchmark on a variety of domains as well. Lastly, there is a lack of datasets
    for node-level tasks, causing most of the methods to only focus on link prediction.
    To solve this challenge, TGB contains *nine* datasets from *five* distinct domains
    which are *orders of magnitude larger* in terms of the number of nodes, edges
    and timestamps. In addition, TGB proposes four datasets for the novel node affinity
    prediction task.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c25741e77b0898abc3075c7354c8799b.png)'
  prefs: []
  type: TYPE_IMG
- en: TGB datasets are significantly larger than common TG datasets
  prefs: []
  type: TYPE_NORMAL
- en: '**Simplistic Evaluation.** Dynamic link prediction was commonly framed as a
    binary classification task: positive (true) edges have a label of one, while negative
    (non-existing) edges have a label of zero. When evaluating, one negative edge
    per positive one was sampled by keeping the source node fixed and choosing the
    destination node uniformly at random. This evaluation only considers a small amount
    of easy to predict negative edges, leading to inflated model performance with
    many models obtaining >95% AP on Wikipedia and Reddit ([Poursafaei et al. 2022](https://openreview.net/forum?id=1GVpwr2Tfdg),
    [Rossi et al. 2020](https://arxiv.org/pdf/2006.10637.pdf), [Wang et al. 2021](https://arxiv.org/pdf/2101.05974.pdf),
    [Souza et al. 2022](https://arxiv.org/pdf/2209.15059.pdf)). In TGB we treat the
    link prediction task as a *ranking problem* and make the evaluation more robust.
    We show that the improved evaluation results in more realistic performance and
    highlights clear gaps between different models.'
  prefs: []
  type: TYPE_NORMAL
- en: Problem Setting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In TGB, we focus on continuous time temporal graphs, as defined by [Kazemi et
    al. 2020](https://www.jmlr.org/papers/volume21/19-447/19-447.pdf). In this setting,
    we denote temporal graphs as timestamped edge streams consisting of triplets of
    *(source, destination, , timestamp)*. Note that temporal edges can be weighted,
    directed, while both nodes and edges can optionally have features.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we consider the *streaming setting,* where a model can incorporate
    new information at inference time. In particular, when predicting a test edge
    at time *t*, the model can access[1] all edges occurred before *t*, including
    test edges. However, back-propagation and weight updates with the test information
    are not permitted.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset Details
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'TGB contains *nine* datasets, seven of which are curated for this work while
    two are from previous literature. The datasets are temporally split into training,
    validation and test sets with ratio of 70/15/15\. Datasets are categorized based
    on their number of edges: **small** (<5 million), **medium** (5–25 million) and
    **large** (> 25 million).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8341d3cbaab16d783ff26c6224c0d584.png)'
  prefs: []
  type: TYPE_IMG
- en: dataset statistics for TGB datasets
  prefs: []
  type: TYPE_NORMAL
- en: TGB datasets also have distinct domains and time granularities (from UNIX timestamp
    to annually). Lastly, dataset statistics are highly diverse too. For example,
    the *Surprise Index*, defined by the ratio of test edges never observed in the
    training set, varies significantly across datasets. Many TGB datasets also contain
    many novel nodes in the test set which requires inductive reasoning.
  prefs: []
  type: TYPE_NORMAL
- en: TGB datasets are also tied to real world tasks. For example, `tgbl-flight` dataset
    is a crowd sourced international flight network from 2019 to 2022 where the airports
    are modeled as nodes while edges are flights between airports for a given day.
    The task is to predict whether a flight will happen between two specific airports
    on a future date. This is useful for forecasting potential flight disruptions
    such as cancellation and delays. For instance, during the COVID-19 pandemic, many
    flight routes were canceled to combat the spread of COVID-19\. The prediction
    of the global flight network is also important for studying and forecasting the
    spread of disease such as COVID-19 to new regions as seen in [Ding et al. 2021](https://appliednetsci.springeropen.com/articles/10.1007/s41109-021-00378-3).
    Detailed dataset and task descriptions are provided in Section 4 of the paper.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic Link Property Prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The goal of dynamic link property prediction is to predict the property (often
    the existence) of a link between a node pair at a future timestamp.
  prefs: []
  type: TYPE_NORMAL
- en: '**Negative Edge Sampling.** In real applications, the true edges are not known
    in advance. Therefore, a large number of node pairs are queried, and onlypairs
    with the highest scores are treated as edges. Motivated by this, we frame the
    link prediction task as a ranking problem and sample multiple negative edges per
    each positive edge. In particular, for a given positive edge *(s,d,t)*, we fix
    the source node *s* and timestamp *t* and sample *q* different destination nodes
    *d*. For each dataset, *q* is selected based on the trade-off between evaluation
    completeness and test set inference time. Out of the *q* negative samples, half
    are sampled uniformly at random, while the other half are historic negative edges
    (edges that were observed in the training set but are not present at time *t*).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Performance metric.** We use the filtered Mean Reciprocal Rank (MRR) as the
    metric for this task, as it is designed for ranking problems. The MRR computes
    the reciprocal rank of the true destination node among the negative or fake destinations
    and is commonly used in recommendation systems and knowledge graph literature.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2de26668a84d4f95678cdf9552315def.png)'
  prefs: []
  type: TYPE_IMG
- en: MRR performance on tgbl-wiki and tgbl-review datasets
  prefs: []
  type: TYPE_NORMAL
- en: '**Results on small datasets.** On the small `tgbl-wiki` and `tgbl-review`datasets,
    we observe that the best performing models are quite different. In addition, the
    top performing models on `tgbl-wiki` such as CAWN and NAT have a significant reduction
    in performance on `tgbl-review`. One possible explanation is that the `tgbl-review`dataset
    has a much higher surprise index when compared to the `tgbl-wiki`dataset. The
    high surprise index shows that a high ratio of test set edges is never observed
    in the training set thus `tgbl-review`requires more inductive reasoning. In `tgbl-review`,
    GraphMixer and TGAT are the best performing models. Due to their smaller size,
    we are able to sample all possible negatives for `tgbl-wiki`and one hundred negatives
    for `tgbl-review`per positive edge.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5d52562b0d3c68165cc4af122a624934.png)'
  prefs: []
  type: TYPE_IMG
- en: MRR performance on tgbl-coin, tgbl-comment and tgbl-flight datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Most methods run out of GPU memory for these datasets thus we compare TGN, DyRep
    and Edgebank on these datasets due to their lower GPU memory requirement. Note
    that some datasets such as `tgbl-comment`or `tgbl-flight`spanning multiple years
    thus potentially resulting in distribution shift over its long time span.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5e47ed9b91ff0b50a011703067d1074f.png)'
  prefs: []
  type: TYPE_IMG
- en: effect of number of negative samples on tgbl-wiki
  prefs: []
  type: TYPE_NORMAL
- en: '**Insights.** As seen above in `tgbl-wiki`, the number of negative samples
    used for evaluation can significantly impact model performance: we see a significant
    performance drop across most methods, when the number of negative samples increases
    from 20 to all possible destinations. This verifies that indeed, more negative
    samples are required for robust evaluation. Curiously, methods such as CAWN and
    Edgebank have relatively minor drop in performance and we leave it as future work
    to investigate why certain methods are less impacted.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9f9c7a438f6e295e79c7d2ad309a32cd.png)'
  prefs: []
  type: TYPE_IMG
- en: total training and validaiton time of TG models
  prefs: []
  type: TYPE_NORMAL
- en: Next, we observe up to two orders of magnitude difference in training and validation
    time of TG methods, with the heuristic baseline Edgebank always being the fastest
    (as it is implemented simply as a hashtable). This shows that improving the model
    efficiency and scalability is an important future direction such that novel and
    existing models can be tested on large datasets provided in TGB.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic Node Property Prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The goal of dynamic node property prediction is to predict the property of a
    node at any given timestamp *t*. As there is a lack of large public TG datasets
    with dynamic node labels, we introduce the *node affinity prediction* task to
    investigate node level tasks on temporal graphs. If you would like to contribute
    a novel dataset with node labels, please reach out to us.
  prefs: []
  type: TYPE_NORMAL
- en: '**Node affinity prediction.** This task considers the affinity of a subset
    of nodes (e.g., users) towards other nodes (e.g. items) as its property, and how
    the affinity naturally changes over time. This task is relevant for example in
    recommendation systems, where it is important to provide personalized recommendations
    for a user by modeling their preference towards different items over time. Here,
    we use the Normalized Discounted Cumulative Gain of the top 10 items (NDCG@10)
    to compare the relative order of the predicted items to that of the ground truth.
    The label is generated by counting the frequency of user interaction with different
    items over a future period.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/036bffdb35c0e99ac55a19aa42e8bbac.png)'
  prefs: []
  type: TYPE_IMG
- en: empirical results for the node affinity prediction task.
  prefs: []
  type: TYPE_NORMAL
- en: '**Results.** For this task, we compare TG models with two simple heuristics:
    *persistence forecast*, predicting the most recent observed node label for the
    current time and *moving average*, the average over node labels in the past few
    steps. The key observation here is that on this task, simple heuristics such as
    persistence forecast and moving average are strong contenders to TG methods and
    in most cases, outperforming them. This highlights the need to develop more TG
    methods for node-level tasks in the future.'
  prefs: []
  type: TYPE_NORMAL
- en: Get Started with TGB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/700f411b91e1d6830ed846f9a8ff713b.png)'
  prefs: []
  type: TYPE_IMG
- en: ML pipeline for TGB
  prefs: []
  type: TYPE_NORMAL
- en: 'How to use TGB? The above shows the ML pipeline in TGB. You can automatically
    download datasets and processes them into `numpy`, `PyTorch`and `PyG`compatible
    data formats. Users only need to design their own TG models which can be easily
    tested via TGB evaluators *to* standardize evaluation*.* Lastly, the public and
    online TGB leaderboards help researchers track recent progress in the temporal
    graph domain. You can install the package easily:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Finally, you can submit your model performance to the TGB leaderboard. We ask
    that you provide link to your code and a paper describing your approach for reproducibility.
    To submit, please fill in the [google form](https://forms.gle/SEsXvN1QHo9tSFwx9).
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion and Future Work
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To enable realistic, reproducible, and robust evaluation for machine learning
    on temporal graphs, we present the Temporal Graph Benchmark, a collection of challenging
    and diverse datasets. With TGB datasets and evaluation, we found that model performance
    varies significantly across datasets, thus demonstrating the necessity to evaluate
    on a diverse range of temporal graph domains. In addition, on the node affinity
    prediction task, simple heuristics outperform TG methods thus motivating the development
    of more node-level TG models in the future.
  prefs: []
  type: TYPE_NORMAL
- en: '**Integration into PyG.** Matthias Fey (Kumo.AI), Core lead of [PyG](https://pyg.org/),
    announced at the [Stanford Graph Learning Workshop 2023](https://snap.stanford.edu/graphlearning-workshop-2023/)
    that TGB will be integrated into future versions of PyG. Stay tuned!'
  prefs: []
  type: TYPE_NORMAL
- en: '**TGX library.** We are currently developing an utility and visualization Python
    library for temporal graphs, named [TGX](https://github.com/shenyangHuang/TGX).
    TGX supports 20 built in temporal graph datasets from TGB and [Poursafaei et al.
    2022](https://openreview.net/forum?id=1GVpwr2Tfdg).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Community Feedback and Dataset Contributions.** TGB is a community driven
    project and we would like to thank all the community members who provided suggestions
    to us via email or Github issues. If you have any suggestions or want to contribute
    new datasets to TGB, please reach out to us via [email](http://shenyang.huang@mail.mcgill.ca)
    or [create an issue on Github](https://github.com/shenyangHuang/TGB/issues). We
    are looking for large scale datasets, especially those for dynamic node or graph
    classification tasks.'
  prefs: []
  type: TYPE_NORMAL
