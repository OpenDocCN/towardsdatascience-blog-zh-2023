# 为什么语言模型无处不在？

> 原文：[https://towardsdatascience.com/why-are-language-models-everywhere-36d9961dd9e1?source=collection_archive---------6-----------------------#2023-05-26](https://towardsdatascience.com/why-are-language-models-everywhere-36d9961dd9e1?source=collection_archive---------6-----------------------#2023-05-26)

## 答案在于75年的自然语言处理历史

[](https://medium.com/@dataemporium?source=post_page-----36d9961dd9e1--------------------------------)[![Ajay Halthor](../Images/1be821c8d8ed336b9ecedcf94f960ede.png)](https://medium.com/@dataemporium?source=post_page-----36d9961dd9e1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----36d9961dd9e1--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----36d9961dd9e1--------------------------------) [Ajay Halthor](https://medium.com/@dataemporium?source=post_page-----36d9961dd9e1--------------------------------)

·

[点击这里](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb0a3e7e495ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-are-language-models-everywhere-36d9961dd9e1&user=Ajay+Halthor&userId=b0a3e7e495ca&source=post_page-b0a3e7e495ca----36d9961dd9e1---------------------post_header-----------) 发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----36d9961dd9e1--------------------------------) · 6 min read · 2023年5月26日

--

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F36d9961dd9e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-are-language-models-everywhere-36d9961dd9e1&source=-----36d9961dd9e1---------------------bookmark_footer-----------)![](../Images/fcff59340752837048b7aa666ca9d1ec.png)

图片由 [Romain Vignes](https://unsplash.com/@rvignes?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) 提供

你是否曾经想过我们是如何来到今天的 [ChatGPT](https://youtu.be/NpmnWgQgcsA) 和大型语言模型的？答案在于自然语言处理（NLP）本身的发展。所以让我们来谈谈这个话题。别担心，历史比你想象的更有趣！第一部分将描述人工智能和NLP的诞生。第二部分将讨论该领域的主要支柱。第三至第五部分将详细介绍过去75年的时间线。最后，第六部分，我们将描述这些领域如何汇聚成今天如此流行的*语言建模*！

# 1 起源

起初，是艾伦·图灵1950年的发表论文 [*计算机械与智能*](https://phil415.pbworks.com/f/TuringComputing.pdf)，在其中他提出了“机器能思考吗”的问题。这篇论文常被誉为人工智能的诞生。尽管它没有明确讨论自然语言，但它为未来的NLP研究奠定了基础。这也是为什么NLP的最早研究出现在1950年代的原因。

# 2 NLP的支柱

1.  **机器翻译**：这是指人工智能将一种语言的句子输入，并输出另一种语言的句子。例如，Google翻译。

1.  **语音处理**：人工智能将音频作为输入……
