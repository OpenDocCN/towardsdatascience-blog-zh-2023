- en: Using ChatGPT for Efficient Debugging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/using-chatgpt-for-efficient-debugging-fc9e065b7856?source=collection_archive---------6-----------------------#2023-06-22](https://towardsdatascience.com/using-chatgpt-for-efficient-debugging-fc9e065b7856?source=collection_archive---------6-----------------------#2023-06-22)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Enhance your debugging experience and learn faster with the power of Large Language
    Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@andimid?source=post_page-----fc9e065b7856--------------------------------)[![Dmytro
    Nikolaiev (Dimid)](../Images/4121156b9c08ed20e7aa620712a391d9.png)](https://medium.com/@andimid?source=post_page-----fc9e065b7856--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fc9e065b7856--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fc9e065b7856--------------------------------)
    [Dmytro Nikolaiev (Dimid)](https://medium.com/@andimid?source=post_page-----fc9e065b7856--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F97b5279dad26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-chatgpt-for-efficient-debugging-fc9e065b7856&user=Dmytro+Nikolaiev+%28Dimid%29&userId=97b5279dad26&source=post_page-97b5279dad26----fc9e065b7856---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fc9e065b7856--------------------------------)
    ·15 min read·Jun 22, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffc9e065b7856&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-chatgpt-for-efficient-debugging-fc9e065b7856&user=Dmytro+Nikolaiev+%28Dimid%29&userId=97b5279dad26&source=-----fc9e065b7856---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc9e065b7856&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-chatgpt-for-efficient-debugging-fc9e065b7856&source=-----fc9e065b7856---------------------bookmark_footer-----------)![](../Images/eaccf4d8ab5127f53e8f34b436af3116.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Pavel Danilyuk](https://www.pexels.com/photo/elderly-man-thinking-while-looking-at-a-chessboard-8438918/)
    on [Pexels](https://www.pexels.com/)
  prefs: []
  type: TYPE_NORMAL
- en: It’s hard to deny that Large Language Models (LLMs) are making a profound impact
    on various industries and applications, revolutionizing the way we work and interact.
    Even though the initial hype around ChatGPT has calmed down since its release
    about six months ago (in November 2022), its influence remains significant. It
    seems that autoregressive LLMs will continue to be a part of our lives in the
    near future, and **it is worth developing skills to interact with them**, both
    as a developer and a user.
  prefs: []
  type: TYPE_NORMAL
- en: As [Chip Huyen stated in her blog post](https://huyenchip.com/2023/04/11/llm-engineering.html),
    *it is relatively easy to achieve something impressive with LLMs, but it is quite
    challenging to build something production-ready* considering the [limitations
    and potential issues that LLMs currently have](https://www.honeycomb.io/blog/hard-stuff-nobody-talks-about-llm).
    However, while the research and engineering community is actively working to address
    these challenges, it is worth acknowledging the fact that **individuals can already
    benefit greatly from LLMs**, at least using them as personal assistants for everyday
    non-critical tasks or as collaborators for brainstorming.
  prefs: []
  type: TYPE_NORMAL
- en: In my previous article, I discussed the [best practices of prompt engineering](/summarising-best-practices-for-prompt-engineering-c5e86c483af4),
    providing insights to help you develop local LLMs-based applications. In this
    post, I will share a set of techniques that enable you to utilize models such
    as ChatGPT for **effective code debugging** and **accelerated learning of programming**.
    We will also take a look at the example prompts for writing and explaining code.
    These techniques will be valuable not only when interacting with ChatGPT but also
    when seeking assistance from your colleagues or even tackling programming challenges
    independently.
  prefs: []
  type: TYPE_NORMAL
- en: This article is primarily targeted toward beginners, so I tried to provide illustrative
    examples and explanations. I hope these techniques will assist you in understanding
    and troubleshooting code more efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: General Framework for Code Debugging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In fact, ChatGPT has not made **significant** changes to the debugging process.
    The great thing is, now you can easily connect with a *virtual colleague* without
    worrying about being a bother or feeling hesitant to ask stupid questions! But
    the techniques that we will consider **exist as long as software engineering exists**,
    and therefore will be useful not only when interacting with LLMs, but also for
    a better understanding of the process and more effective interaction with coworkers.
  prefs: []
  type: TYPE_NORMAL
- en: 'To find a bug in your code, you only need two essential steps (there’s three
    actually):'
  prefs: []
  type: TYPE_NORMAL
- en: '*Isolate the bug and demonstrate it with the minimum amount of code*;'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Make an assumption* about your error and test it;'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Iterate* with more assumptions until you find a fix.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: While you can start using ChatGPT right away, it’s actually a better idea to
    begin by reproducing the error for a few reasons. First of all, it might be challenging
    to include all the related points and explain exactly what you’re trying to achieve
    within the context of the language model. Secondly, it will allow you to gain
    a better understanding of the issue and possibly find the error yourself. Let’s
    see.
  prefs: []
  type: TYPE_NORMAL
- en: By the way, in this post I am using the vanilla version of ChatGPT (GPT-3.5),
    but for coding tasks, GPT-4 is typically more proficient.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Step 1: Isolate and Reproduce the Problem with the Minimum Amount of Code'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first step is to reproduce the problem. As we know, the majority of issues
    can still be resolved with the classic **“turn it off and on again”**. It’s possible
    that you might have become tangled up with the code execution order in Jupyter
    Notebook.
  prefs: []
  type: TYPE_NORMAL
- en: If possible (and it typically is), it’s recommended to **write new code that
    throws the same error and keep it as simple as possible**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s consider the example of a `TypeError: ‘int'' object is not iterable`,
    which occurs when you try to iterate over `some_integer` instead of using the
    `range(some_integer)` construct.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Bad example: a function calls another function that then invokes a method of
    a class. At first glance, it may require some time to determine where the actual
    computation occurs, despite this being a relatively simple example. Similarly,
    for models, it becomes more challenging to *locate the relevant information among
    unrelated details*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Better example: get rid of the class by moving the functionality of `do_some_work()`
    function (which is causing the error) directly into the function we are calling.'
  prefs: []
  type: TYPE_NORMAL
- en: Besides the fact that we still do a terrible job with the variable naming conventions
    (remember, **variable names should be descriptive and meaningful!**), this code
    is still easier to debug and understand.
  prefs: []
  type: TYPE_NORMAL
- en: 'Even better example: we can get rid of `some_function()` as well.'
  prefs: []
  type: TYPE_NORMAL
- en: Overall, we have shortened the code by more than half. Compare how much easier
    it is to find a bug in it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the context of pandas, for example, this principle can mean not using the
    original dataframe. Let’s consider a situation where we want to calculate the
    average salary for each position using our data and encounter a `KeyError`. Here
    is a bad example:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we can’t be sure that the dataframe contains the data provided in the
    comments. Indeed, we only need two columns from it, and if we create a similar
    mini version, it will be much easier to understand that we simply misspelled the
    salary column (`Salary` vs `salary`).
  prefs: []
  type: TYPE_NORMAL
- en: By the way, ChatGPT is quite good at **generating dummy data**, so it can be
    helpful here too!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: There are countless types of errors, and it’s impossible to list them all, of
    course. Overall, try to modify the code in such a way that **it produces the same
    error** as you encountered, but **make it as easy as possible to understand quickly**.
  prefs: []
  type: TYPE_NORMAL
- en: Due to the so-called “[rubber duck debugging](https://en.wikipedia.org/wiki/Rubber_duck_debugging),”
    this step often helps you understand the cause of the problem on your own, without
    seeking external assistance. For example, if your mini-code doesn’t generate the
    same error, you’re already halfway toward finding a solution. However, even if
    it does, it’s still a positive outcome. :)
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 2: *Make an Assumption, Test It, and Iterate*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you still can’t find a way to fix the error, it’s worth seeking assistance.
    But it’s helpful to have your own assumptions about what could be wrong.
  prefs: []
  type: TYPE_NORMAL
- en: Find the Exact Line
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, **find the** **expression and the exact line of code** that are causing
    the problem. You probably already know that it is inside the last line of the
    mini-code you wrote earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that [Python traceback](https://realpython.com/python-traceback/#how-do-you-read-a-python-traceback)
    displays the **error message** *at the bottom* and the corresponding **executed
    code** *at the top* with internal functions’ calls in between.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c1c119d27a2e584f80b68ceffa6a422e.png)'
  prefs: []
  type: TYPE_IMG
- en: Python traceback. Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: This can be quite easy for straightforward bugs, but it can be more challenging
    when dealing with *logical errors* that don’t generate any error messages but
    result in unexpected outputs due to logical mistakes. In such cases, it’s helpful
    to observe the values step by step with a *debugger* or simple `print()` statements
    and define the line of code that doesn’t align with your expectations.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the error is caused by a complex expression, such as `df.groupby(‘Occupation’)[‘Address’].apply(lambda
    x: ‘, ‘.join(x))`, you can first break it into parts and explore the output step
    by step, e.g. first run `df.groupby(‘Occupation’)`, then `df.groupby(‘Occupation’)[‘Address’]`,
    and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: Think about Common Reasons
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After that, consider some common reasons for the error:'
  prefs: []
  type: TYPE_NORMAL
- en: Could it be that the necessary **library is not installed** or installed with
    the wrong version?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maybe there’s a simple **typo** or **syntax error** somewhere?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Might it be that the error is related to **data types**, e.g. you sum a string
    and a number?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And so forth.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ask ChatGPT
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If nothing comes to mind, it’s time to ask ChatGPT for assistance. Simple issues
    can often be resolved by simply pasting your code and asking *what’s wrong*. However,
    for more complex problems, you may need to provide additional relevant information.
    For instance, if you’re encountering a system error, it might be helpful to include
    the version of Python you’re using. Overall, try to always include the **error
    message** and **describe what you’re trying to achieve**. You may have to try
    several wordings, so don’t be afraid to experiment.
  prefs: []
  type: TYPE_NORMAL
- en: Situations can vary greatly, so let’s move on to some examples. First, let’s
    take a look at the pandas `KeyError` we encountered earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sample prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Insert your code here
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: import pandas as pd
  prefs: []
  type: TYPE_NORMAL
- en: df = pd.DataFrame({
  prefs: []
  type: TYPE_NORMAL
- en: '''Occupation'': [''Engineer'', ''Doctor'', ''Engineer''],'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '''Salary'': [56056, 61304, 86850],'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '})'
  prefs: []
  type: TYPE_NORMAL
- en: average_salary_per_occupation = df.groupby('Occupation')['salary'].mean()
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/ebce750f4572403e8da6a1d57978f203.png)'
  prefs: []
  type: TYPE_IMG
- en: Output for a debugging pandas example. Image by Author created using [ChatGPT](https://chat.openai.com/chat)
  prefs: []
  type: TYPE_NORMAL
- en: Looks good! Let’s see a more challenging example with a logical error.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sample prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Insert your code here
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: from sklearn.datasets import load_iris
  prefs: []
  type: TYPE_NORMAL
- en: from sklearn.ensemble import RandomForestClassifier
  prefs: []
  type: TYPE_NORMAL
- en: from sklearn.metrics import accuracy_score
  prefs: []
  type: TYPE_NORMAL
- en: from sklearn.model_selection import train_test_split, GridSearchCV
  prefs: []
  type: TYPE_NORMAL
- en: load the Iris dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: iris = load_iris()
  prefs: []
  type: TYPE_NORMAL
- en: X = iris.data
  prefs: []
  type: TYPE_NORMAL
- en: y = iris.target
  prefs: []
  type: TYPE_NORMAL
- en: split the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: X_test, X_train, y_test, y_train = train_test_split(
  prefs: []
  type: TYPE_NORMAL
- en: X, y, test_size=0.2, random_state=42)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: X_train, X_val, y_train, y_val = train_test_split(
  prefs: []
  type: TYPE_NORMAL
- en: X_train, y_train, test_size=0.2, random_state=42)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: param_grid = {
  prefs: []
  type: TYPE_NORMAL
- en: '''n_estimators'': [3, 7, 15, 25, 50, 100]'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: create a random forest classifier and
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: use grid search to find the best number of trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: rf_classifier = RandomForestClassifier()
  prefs: []
  type: TYPE_NORMAL
- en: grid_search = GridSearchCV(estimator=rf_classifier,
  prefs: []
  type: TYPE_NORMAL
- en: param_grid=param_grid, cv=5)
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: grid_search.fit(X_train, y_train)
  prefs: []
  type: TYPE_NORMAL
- en: get the best estimator from grid search and test it
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: best_rf = grid_search.best_estimator_
  prefs: []
  type: TYPE_NORMAL
- en: y_pred = best_rf.predict(X_test)
  prefs: []
  type: TYPE_NORMAL
- en: test_accuracy = accuracy_score(y_test, y_pred)
  prefs: []
  type: TYPE_NORMAL
- en: print("Test accuracy:", test_accuracy)
  prefs: []
  type: TYPE_NORMAL
- en: get the best number of trees from the grid search
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: best_n_estimators = grid_search.best_params_['n_estimators']
  prefs: []
  type: TYPE_NORMAL
- en: print("Best number of trees:", best_n_estimators)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/94e0c1edf0a1d00ac00e37b8b9c29ee5.png)'
  prefs: []
  type: TYPE_IMG
- en: Output for a debugging sklearn example. Image by Author created using [ChatGPT](https://chat.openai.com/chat)
  prefs: []
  type: TYPE_NORMAL
- en: The model was able to find the hidden problem and fix it. Great!
  prefs: []
  type: TYPE_NORMAL
- en: Since ChatGPT remembers your previous messages, the *possibilities opening here
    are endless*. You can ask it to explain some concepts you’re having trouble understanding,
    suggest alternative solutions, translate code from one language to another, and
    so on.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, since ChatGPT can understand the code, it can also write it.
  prefs: []
  type: TYPE_NORMAL
- en: Use ChatGPT to Write and Explain Code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will explore a couple of tricks that can be used when coding
    with ChatGPT. But first, I think it is important to remember that before the emergence
    of ChatGPT, **Google** was the primary tool for software developers.
  prefs: []
  type: TYPE_NORMAL
- en: And I think it’s important to *not forget how to use Google*, for various reasons.
    In the end, with Google you can probably do everything you can do with ChatGPT
    (in coding settings), it just might be slower. Although, when it comes to specific
    tasks like creating a diagonal matrix with numpy, I would likely do it faster
    using Google.
  prefs: []
  type: TYPE_NORMAL
- en: I think the fitting analogy is the process of learning a foreign language (although
    one can say that you are doing exactly that by learning a **programming** language
    :). Using Google is translating **individual words** using a vocabulary while
    utilizing ChatGPT is akin to **translating entire sentences and paragraphs of
    text** using online translators. While ChatGPT can be incredibly powerful, you
    may face challenges in identifying hidden errors or understanding certain code
    blocks, especially as a beginner.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Given the immense capabilities of ChatGPT, it can be employed in various ways.
    I advise you to use it for **generating short code snippets** — acting as a dictionary
    for idioms or stable expressions. Making sure you have a solid understanding of
    the generated code is essential because it can help prevent future troubles and
    complications.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: So, use ChatGPT, but remember to google things as well!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[This article](https://codeeasy.io/blog/how-to-effectively-google-as-a-software-devel)
    offers some valuable tips on effective googling for software developers.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One technique that is helpful in these situations is called [role prompting](https://learnprompting.org/docs/basics/roles).
    Instead of simply asking the model to generate code, you can ask it to write code
    *by being a junior developer*, for instance. By assuming this role, the model
    is more likely to produce code comprehensible to beginners and avoid overly complex
    constructs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sample prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/774bdc72f6c19dfe22ee95db4751b57e.png)'
  prefs: []
  type: TYPE_IMG
- en: Output for a code generation prompt. Image by Author created using [ChatGPT](https://chat.openai.com/chat)
  prefs: []
  type: TYPE_NORMAL
- en: In this example, ChatGPT did a pretty good job following all of our instructions,
    including examples and detailed explanations.
  prefs: []
  type: TYPE_NORMAL
- en: Don’t forget to compare the code with your initial assumptions and draw conclusions
    that will allow you not to make such a request in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, remember that LLMs have no prior knowledge about you or the specific
    problem you’re facing, so the more information you provide, the better output
    you’ll get:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Describe your task**;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Define code structure**: e.g. it is full script, class, or function;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Specify inputs and outputs**: e.g. the function takes two integer arguments
    and outputs float;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mention tools/libraries** you want to use, such as numpy or pandas, as well
    as a programming language;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If feasible, **add your suggestions** on what the solution might look like:
    e.g. I suggest using the `pandas.DataFrame.groupby` function to calculate the
    average salary by position.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimize
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we previously asked the model to behave like a junior developer, we want
    it to be stronger in programming for tasks such as code optimization.
  prefs: []
  type: TYPE_NORMAL
- en: By the way, you can use the same role prompting trick for debugging as well.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Sample prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Insert your code here
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'def unique_list(l):'
  prefs: []
  type: TYPE_NORMAL
- en: Get a list of distinct elements from the given list
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
- en: x = []
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'for a in l:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'if a not in x:'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: x.append(a)
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: return x
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/12f0aabb7685d6f0c5264a868e9daf1a.png)'
  prefs: []
  type: TYPE_IMG
- en: Output for a code optimization prompt. Image by Author created using [ChatGPT](https://chat.openai.com/chat)
  prefs: []
  type: TYPE_NORMAL
- en: Here, to extract unique elements from the list, ChatGPT suggests using the `set`
    datatype (that does not allow duplicate values by definition), instead of a for
    loop. A good choice, since it’s basically a one-line solution.
  prefs: []
  type: TYPE_NORMAL
- en: Explain
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can use the same notation requesting comments and code explanations. Often
    this tends to output redundant comments, like `import numpy as np # importing
    numpy library`. However, this can still be useful at the start of your journey,
    and help the model to *express its internal thoughts* as discussed in the [Chain-of-Thought
    reasoning](https://learnprompting.org/docs/intermediate/chain_of_thought) section
    in [my previous article](/summarising-best-practices-for-prompt-engineering-c5e86c483af4).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sample prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Insert your code here
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'def func(n):'
  prefs: []
  type: TYPE_NORMAL
- en: trow = [1]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: y = [0]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'for x in range(max(n, 0)):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: print(trow)
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: trow = [l + r for l, r in zip(trow + y, y + trow)]
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: return n >= 1
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: func(6)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/9d5b8a36c34fbe2dad3d1c274aab16c9.png)'
  prefs: []
  type: TYPE_IMG
- en: Output for a code explanation prompt. Image by Author created using [ChatGPT](https://chat.openai.com/chat)
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, the model was able to identify the task behind this code: generate rows
    of [Pascal’s triangle](https://en.wikipedia.org/wiki/Pascal%27s_triangle). Good
    job!'
  prefs: []
  type: TYPE_NORMAL
- en: While there are numerous useful applications for ChatGPT you can come up with,
    it’s important to note that it may not always be able to solve every problem you
    encounter. It’s worth discussing this aspect further.
  prefs: []
  type: TYPE_NORMAL
- en: Few Notes about Potential Pitfalls
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While ChatGPT can be very useful and perform various tasks, it is important
    to keep in mind the potential drawbacks which can be tricky.
  prefs: []
  type: TYPE_NORMAL
- en: As Autoregressive LLM, ChatGPT is not Deterministic …
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ChatGPT is an example of a Large Language Model, and current Large Language
    Models are **autoregressive**, meaning that *they are trained to predict the next
    token in a sequence*. The output of a model is a probability distribution across
    all possible tokens, and we sample the final text from this distribution token
    by token. As a result, the sampling process is **non-deterministic**, meaning
    that *you can have different outputs for the same input* due to probabilistic
    reasons.
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate this, we can imagine the sampling process as a tree. Here the
    initial sentence is shown in blue, selected tokens are shown in green, and non-selected
    ones are represented in red (without their further evolution). The probabilities
    are picked randomly just for illustration reasons.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b691129872ca6693fa841de166d63d2e.png)'
  prefs: []
  type: TYPE_IMG
- en: Simplified visualization of the sampling process for LLM. Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'The input sequence is: “*My name is*” and ChatGPT completes it with “*ChatGPT,
    pleased to assist you!*”. This is an example from [my previous article](/behind-the-millions-estimating-the-scale-of-large-language-models-97bd7287fb6b),
    where I discuss the basics of LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: … and That’s Why ChatGPT can be Wrong
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In practice, this means that you can get suboptimal output just because you
    got some rare unlikely tokens at the start. As a result, **you may need several
    runs of the same input** to examine the different outputs and select the most
    suitable one or even *combine different parts from different outputs*.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, it’s important to highlight that modern language models, especially
    GPT-4, possess impressive *self-correction capabilities*. If the generated code
    contains errors, you can simply return it and indicate that it is not functioning
    correctly. GPT-4 is adept at **debugging its own code** and offering relevant
    suggestions. You’ll often be able to obtain the correct code after a couple of
    iterations.
  prefs: []
  type: TYPE_NORMAL
- en: Overconfidence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Despite the fact that LLMs can sometimes provide incorrect outputs, they have
    been trained to prioritize accuracy. This can make their **output appear very
    convincing, even when it is incorrect**. As a result, identifying hidden errors
    can be challenging because the model often cannot explicitly say *“I need more
    information”*, although ongoing research is actively exploring ways to address
    this limitation.
  prefs: []
  type: TYPE_NORMAL
- en: In this sense, using ChatGPT for generating **small snippets of code** to solve
    specific tasks, as I mentioned earlier when referring to Googling, can be safer.
    It is essential to ensure that you have a solid understanding of the code you
    receive which allow you to navigate potential pitfalls effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article, we have explored methods that can assist you in debugging,
    not only with ChatGPT but also with yourself.
  prefs: []
  type: TYPE_NORMAL
- en: By **isolating** the problem and **rewriting it in minimal lines of code**,
    you are likely to gain insights into the underlying issue. Or let ChatGPT help
    you by providing **complete information about what is happening**, making assumptions,
    and experimenting.
  prefs: []
  type: TYPE_NORMAL
- en: You can also utilize ChatGPT for tasks such as writing, optimizing, or explaining
    code, as we discussed in the example of role prompting. The other code-related
    applications are endless and include creating dummy data, writing tests, generating
    documentation, and more.
  prefs: []
  type: TYPE_NORMAL
- en: But remember the limitations of LLMs, as they can introduce hidden problems.
    Due to their autoregressive nature, LLMs **can be wrong while appearing confident**,
    which may require asking more questions or running multiple iterations to select
    the best output.
  prefs: []
  type: TYPE_NORMAL
- en: Wishing you the best of luck on your learning journey!
  prefs: []
  type: TYPE_NORMAL
- en: Resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Check out [this article](https://realpython.com/chatgpt-coding-mentor-python/)
    for a broader guide of making ChatGPT your personal coding mentor.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Here are my other articles about LLMs that may be useful to you. I have already
    covered:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Estimating the Scale of Large Language Models](/behind-the-millions-estimating-the-scale-of-large-language-models-97bd7287fb6b):
    what are LLMs, how are they trained, and how much data and compute do they need;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Best Practices for Prompt Engineering](/summarising-best-practices-for-prompt-engineering-c5e86c483af4):
    how to apply prompt engineering techniques to interact with LLMs effectively and
    how to build local LLM-based applications with OpenAI API and Streamlit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can be also interested in:'
  prefs: []
  type: TYPE_NORMAL
- en: Free [Learn Prompting course](https://learnprompting.org/) to gain a deeper
    understanding of prompting and various techniques associated with it;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recently released [short courses by DeepLearning.AI](https://www.deeplearning.ai/short-courses/)
    to build applications with OpenAI API.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thank you for reading!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I hope these materials were useful to you. [Follow me on Medium](https://medium.com/@andimid)
    to get more articles like this.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you have any questions or comments, I will be glad to get any feedback. Ask
    me in the comments, or connect via [LinkedIn](https://www.linkedin.com/in/andimid/)
    or [Twitter](https://twitter.com/dimid_ml).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To support me as a writer and to get access to thousands of other Medium articles,
    get Medium membership using [my referral link](https://medium.com/@andimid/membership)
    (no extra charge for you).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
