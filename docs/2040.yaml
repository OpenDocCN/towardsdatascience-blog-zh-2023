- en: Using ChatGPT for Efficient Debugging
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 ChatGPT 进行高效调试
- en: 原文：[https://towardsdatascience.com/using-chatgpt-for-efficient-debugging-fc9e065b7856?source=collection_archive---------6-----------------------#2023-06-22](https://towardsdatascience.com/using-chatgpt-for-efficient-debugging-fc9e065b7856?source=collection_archive---------6-----------------------#2023-06-22)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/using-chatgpt-for-efficient-debugging-fc9e065b7856?source=collection_archive---------6-----------------------#2023-06-22](https://towardsdatascience.com/using-chatgpt-for-efficient-debugging-fc9e065b7856?source=collection_archive---------6-----------------------#2023-06-22)
- en: Enhance your debugging experience and learn faster with the power of Large Language
    Models
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用大型语言模型提升你的调试体验，快速学习
- en: '[](https://medium.com/@andimid?source=post_page-----fc9e065b7856--------------------------------)[![Dmytro
    Nikolaiev (Dimid)](../Images/4121156b9c08ed20e7aa620712a391d9.png)](https://medium.com/@andimid?source=post_page-----fc9e065b7856--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fc9e065b7856--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fc9e065b7856--------------------------------)
    [Dmytro Nikolaiev (Dimid)](https://medium.com/@andimid?source=post_page-----fc9e065b7856--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@andimid?source=post_page-----fc9e065b7856--------------------------------)[![Dmytro
    Nikolaiev (Dimid)](../Images/4121156b9c08ed20e7aa620712a391d9.png)](https://medium.com/@andimid?source=post_page-----fc9e065b7856--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fc9e065b7856--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fc9e065b7856--------------------------------)
    [Dmytro Nikolaiev (Dimid)](https://medium.com/@andimid?source=post_page-----fc9e065b7856--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F97b5279dad26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-chatgpt-for-efficient-debugging-fc9e065b7856&user=Dmytro+Nikolaiev+%28Dimid%29&userId=97b5279dad26&source=post_page-97b5279dad26----fc9e065b7856---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fc9e065b7856--------------------------------)
    ·15 min read·Jun 22, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffc9e065b7856&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-chatgpt-for-efficient-debugging-fc9e065b7856&user=Dmytro+Nikolaiev+%28Dimid%29&userId=97b5279dad26&source=-----fc9e065b7856---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F97b5279dad26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-chatgpt-for-efficient-debugging-fc9e065b7856&user=Dmytro+Nikolaiev+%28Dimid%29&userId=97b5279dad26&source=post_page-97b5279dad26----fc9e065b7856---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fc9e065b7856--------------------------------)
    · 15分钟阅读 · 2023年6月22日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffc9e065b7856&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-chatgpt-for-efficient-debugging-fc9e065b7856&user=Dmytro+Nikolaiev+%28Dimid%29&userId=97b5279dad26&source=-----fc9e065b7856---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc9e065b7856&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-chatgpt-for-efficient-debugging-fc9e065b7856&source=-----fc9e065b7856---------------------bookmark_footer-----------)![](../Images/eaccf4d8ab5127f53e8f34b436af3116.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc9e065b7856&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-chatgpt-for-efficient-debugging-fc9e065b7856&source=-----fc9e065b7856---------------------bookmark_footer-----------)![](../Images/eaccf4d8ab5127f53e8f34b436af3116.png)'
- en: Photo by [Pavel Danilyuk](https://www.pexels.com/photo/elderly-man-thinking-while-looking-at-a-chessboard-8438918/)
    on [Pexels](https://www.pexels.com/)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Pavel Danilyuk](https://www.pexels.com/photo/elderly-man-thinking-while-looking-at-a-chessboard-8438918/)
    于 [Pexels](https://www.pexels.com/)
- en: It’s hard to deny that Large Language Models (LLMs) are making a profound impact
    on various industries and applications, revolutionizing the way we work and interact.
    Even though the initial hype around ChatGPT has calmed down since its release
    about six months ago (in November 2022), its influence remains significant. It
    seems that autoregressive LLMs will continue to be a part of our lives in the
    near future, and **it is worth developing skills to interact with them**, both
    as a developer and a user.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 难以否认，大型语言模型（LLMs）正在对各行各业和应用产生深远的影响，彻底改变了我们的工作和互动方式。尽管自从约六个月前（2022年11月）发布以来，围绕
    ChatGPT 的最初炒作已平息，但它的影响仍然显著。看来自回归 LLMs 将在不久的将来继续成为我们生活的一部分，并且 **值得培养与它们互动的技能**，无论作为开发者还是用户。
- en: As [Chip Huyen stated in her blog post](https://huyenchip.com/2023/04/11/llm-engineering.html),
    *it is relatively easy to achieve something impressive with LLMs, but it is quite
    challenging to build something production-ready* considering the [limitations
    and potential issues that LLMs currently have](https://www.honeycomb.io/blog/hard-stuff-nobody-talks-about-llm).
    However, while the research and engineering community is actively working to address
    these challenges, it is worth acknowledging the fact that **individuals can already
    benefit greatly from LLMs**, at least using them as personal assistants for everyday
    non-critical tasks or as collaborators for brainstorming.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: In my previous article, I discussed the [best practices of prompt engineering](/summarising-best-practices-for-prompt-engineering-c5e86c483af4),
    providing insights to help you develop local LLMs-based applications. In this
    post, I will share a set of techniques that enable you to utilize models such
    as ChatGPT for **effective code debugging** and **accelerated learning of programming**.
    We will also take a look at the example prompts for writing and explaining code.
    These techniques will be valuable not only when interacting with ChatGPT but also
    when seeking assistance from your colleagues or even tackling programming challenges
    independently.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: This article is primarily targeted toward beginners, so I tried to provide illustrative
    examples and explanations. I hope these techniques will assist you in understanding
    and troubleshooting code more efficiently.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: General Framework for Code Debugging
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In fact, ChatGPT has not made **significant** changes to the debugging process.
    The great thing is, now you can easily connect with a *virtual colleague* without
    worrying about being a bother or feeling hesitant to ask stupid questions! But
    the techniques that we will consider **exist as long as software engineering exists**,
    and therefore will be useful not only when interacting with LLMs, but also for
    a better understanding of the process and more effective interaction with coworkers.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: 'To find a bug in your code, you only need two essential steps (there’s three
    actually):'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '*Isolate the bug and demonstrate it with the minimum amount of code*;'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Make an assumption* about your error and test it;'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Iterate* with more assumptions until you find a fix.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: While you can start using ChatGPT right away, it’s actually a better idea to
    begin by reproducing the error for a few reasons. First of all, it might be challenging
    to include all the related points and explain exactly what you’re trying to achieve
    within the context of the language model. Secondly, it will allow you to gain
    a better understanding of the issue and possibly find the error yourself. Let’s
    see.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: By the way, in this post I am using the vanilla version of ChatGPT (GPT-3.5),
    but for coding tasks, GPT-4 is typically more proficient.
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Step 1: Isolate and Reproduce the Problem with the Minimum Amount of Code'
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first step is to reproduce the problem. As we know, the majority of issues
    can still be resolved with the classic **“turn it off and on again”**. It’s possible
    that you might have become tangled up with the code execution order in Jupyter
    Notebook.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是重现问题。众所周知，大多数问题仍然可以通过经典的 **“重启”** 来解决。可能你已经在 Jupyter Notebook 中与代码执行顺序纠缠不清。
- en: If possible (and it typically is), it’s recommended to **write new code that
    throws the same error and keep it as simple as possible**.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果可能（通常是），建议 **编写新的代码以抛出相同的错误，并尽可能保持简单**。
- en: 'Let’s consider the example of a `TypeError: ‘int'' object is not iterable`,
    which occurs when you try to iterate over `some_integer` instead of using the
    `range(some_integer)` construct.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '让我们考虑一个 `TypeError: ‘int'' object is not iterable` 的例子，这种错误发生在你尝试迭代 `some_integer`
    而不是使用 `range(some_integer)` 构造时。'
- en: 'Bad example: a function calls another function that then invokes a method of
    a class. At first glance, it may require some time to determine where the actual
    computation occurs, despite this being a relatively simple example. Similarly,
    for models, it becomes more challenging to *locate the relevant information among
    unrelated details*.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 糟糕的例子：一个函数调用另一个函数，该函数又调用一个类的方法。乍一看，可能需要一些时间来确定实际计算发生的位置，尽管这是一个相对简单的例子。类似地，对于模型而言，在无关细节中
    *定位相关信息* 变得更加具有挑战性。
- en: 'Better example: get rid of the class by moving the functionality of `do_some_work()`
    function (which is causing the error) directly into the function we are calling.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的例子：通过将 `do_some_work()` 函数（引发错误的函数）的功能直接移到我们调用的函数中，来去掉类。
- en: Besides the fact that we still do a terrible job with the variable naming conventions
    (remember, **variable names should be descriptive and meaningful!**), this code
    is still easier to debug and understand.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们在变量命名约定上仍然做得很糟糕（记住，**变量名应该具有描述性和意义！**），这段代码仍然更容易调试和理解。
- en: 'Even better example: we can get rid of `some_function()` as well.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的例子：我们还可以去掉 `some_function()`。
- en: Overall, we have shortened the code by more than half. Compare how much easier
    it is to find a bug in it.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，我们将代码缩短了超过一半。比较一下找出其中错误的难度。
- en: 'In the context of pandas, for example, this principle can mean not using the
    original dataframe. Let’s consider a situation where we want to calculate the
    average salary for each position using our data and encounter a `KeyError`. Here
    is a bad example:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在 pandas 的背景下，这一原则可能意味着不使用原始的数据框。假设我们想计算每个职位的平均工资，并遇到 `KeyError`。这是一个糟糕的例子：
- en: First, we can’t be sure that the dataframe contains the data provided in the
    comments. Indeed, we only need two columns from it, and if we create a similar
    mini version, it will be much easier to understand that we simply misspelled the
    salary column (`Salary` vs `salary`).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们不能确定数据框中是否包含注释中提供的数据。实际上，我们只需要其中的两列，如果我们创建一个类似的迷你版本，会更容易理解我们只是拼写错误了工资列（`Salary`
    vs `salary`）。
- en: By the way, ChatGPT is quite good at **generating dummy data**, so it can be
    helpful here too!
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 顺便说一下，ChatGPT 在 **生成虚拟数据** 方面相当出色，所以它在这里也可能有帮助！
- en: There are countless types of errors, and it’s impossible to list them all, of
    course. Overall, try to modify the code in such a way that **it produces the same
    error** as you encountered, but **make it as easy as possible to understand quickly**.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 错误类型繁多，当然不可能一一列举。总体而言，尝试以 **产生相同错误** 的方式修改代码，但 **尽可能让其容易理解**。
- en: Due to the so-called “[rubber duck debugging](https://en.wikipedia.org/wiki/Rubber_duck_debugging),”
    this step often helps you understand the cause of the problem on your own, without
    seeking external assistance. For example, if your mini-code doesn’t generate the
    same error, you’re already halfway toward finding a solution. However, even if
    it does, it’s still a positive outcome. :)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 由于所谓的 “[橡皮鸭调试](https://en.wikipedia.org/wiki/Rubber_duck_debugging)”，这一步通常能帮助你自己理解问题的原因，而无需寻求外部帮助。例如，如果你的迷你代码没有产生相同的错误，你已经找到了解决方案的一半。然而，即使它产生了相同的错误，这也是一个积极的结果。
    :)
- en: 'Step 2: *Make an Assumption, Test It, and Iterate*'
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第2步：*做出假设、测试并迭代*
- en: If you still can’t find a way to fix the error, it’s worth seeking assistance.
    But it’s helpful to have your own assumptions about what could be wrong.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仍然找不到修复错误的方法，值得寻求帮助。但对可能出错的地方有自己的假设会很有帮助。
- en: Find the Exact Line
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查找确切的行
- en: First, **find the** **expression and the exact line of code** that are causing
    the problem. You probably already know that it is inside the last line of the
    mini-code you wrote earlier.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Remember that [Python traceback](https://realpython.com/python-traceback/#how-do-you-read-a-python-traceback)
    displays the **error message** *at the bottom* and the corresponding **executed
    code** *at the top* with internal functions’ calls in between.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c1c119d27a2e584f80b68ceffa6a422e.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
- en: Python traceback. Image by Author
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: This can be quite easy for straightforward bugs, but it can be more challenging
    when dealing with *logical errors* that don’t generate any error messages but
    result in unexpected outputs due to logical mistakes. In such cases, it’s helpful
    to observe the values step by step with a *debugger* or simple `print()` statements
    and define the line of code that doesn’t align with your expectations.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: 'If the error is caused by a complex expression, such as `df.groupby(‘Occupation’)[‘Address’].apply(lambda
    x: ‘, ‘.join(x))`, you can first break it into parts and explore the output step
    by step, e.g. first run `df.groupby(‘Occupation’)`, then `df.groupby(‘Occupation’)[‘Address’]`,
    and so on.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Think about Common Reasons
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After that, consider some common reasons for the error:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Could it be that the necessary **library is not installed** or installed with
    the wrong version?
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maybe there’s a simple **typo** or **syntax error** somewhere?
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Might it be that the error is related to **data types**, e.g. you sum a string
    and a number?
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And so forth.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ask ChatGPT
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If nothing comes to mind, it’s time to ask ChatGPT for assistance. Simple issues
    can often be resolved by simply pasting your code and asking *what’s wrong*. However,
    for more complex problems, you may need to provide additional relevant information.
    For instance, if you’re encountering a system error, it might be helpful to include
    the version of Python you’re using. Overall, try to always include the **error
    message** and **describe what you’re trying to achieve**. You may have to try
    several wordings, so don’t be afraid to experiment.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: Situations can vary greatly, so let’s move on to some examples. First, let’s
    take a look at the pandas `KeyError` we encountered earlier.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: 'Sample prompt:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Insert your code here
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Example:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: import pandas as pd
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: df = pd.DataFrame({
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '''Occupation'': [''Engineer'', ''Doctor'', ''Engineer''],'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '''Salary'': [56056, 61304, 86850],'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '})'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: average_salary_per_occupation = df.groupby('Occupation')['salary'].mean()
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/ebce750f4572403e8da6a1d57978f203.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
- en: Output for a debugging pandas example. Image by Author created using [ChatGPT](https://chat.openai.com/chat)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: Looks good! Let’s see a more challenging example with a logical error.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: 'Sample prompt:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Insert your code here
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Example:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: from sklearn.datasets import load_iris
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: from sklearn.ensemble import RandomForestClassifier
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: from sklearn.metrics import accuracy_score
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: from sklearn.model_selection import train_test_split, GridSearchCV
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: load the Iris dataset
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: iris = load_iris()
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: X = iris.data
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: y = iris.target
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: split the data
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: X_test, X_train, y_test, y_train = train_test_split(
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: X, y, test_size=0.2, random_state=42)
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: X_train, X_val, y_train, y_val = train_test_split(
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: X_train, y_train, test_size=0.2, random_state=42)
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: param_grid = {
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '''n_estimators'': [3, 7, 15, 25, 50, 100]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: create a random forest classifier and
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: use grid search to find the best number of trees
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: rf_classifier = RandomForestClassifier()
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: grid_search = GridSearchCV(estimator=rf_classifier,
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: param_grid=param_grid, cv=5)
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: grid_search.fit(X_train, y_train)
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: get the best estimator from grid search and test it
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: best_rf = grid_search.best_estimator_
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: y_pred = best_rf.predict(X_test)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: test_accuracy = accuracy_score(y_test, y_pred)
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: print("Test accuracy:", test_accuracy)
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: get the best number of trees from the grid search
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: best_n_estimators = grid_search.best_params_['n_estimators']
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: print("Best number of trees:", best_n_estimators)
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/94e0c1edf0a1d00ac00e37b8b9c29ee5.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
- en: Output for a debugging sklearn example. Image by Author created using [ChatGPT](https://chat.openai.com/chat)
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: The model was able to find the hidden problem and fix it. Great!
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Since ChatGPT remembers your previous messages, the *possibilities opening here
    are endless*. You can ask it to explain some concepts you’re having trouble understanding,
    suggest alternative solutions, translate code from one language to another, and
    so on.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, since ChatGPT can understand the code, it can also write it.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Use ChatGPT to Write and Explain Code
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will explore a couple of tricks that can be used when coding
    with ChatGPT. But first, I think it is important to remember that before the emergence
    of ChatGPT, **Google** was the primary tool for software developers.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: And I think it’s important to *not forget how to use Google*, for various reasons.
    In the end, with Google you can probably do everything you can do with ChatGPT
    (in coding settings), it just might be slower. Although, when it comes to specific
    tasks like creating a diagonal matrix with numpy, I would likely do it faster
    using Google.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: I think the fitting analogy is the process of learning a foreign language (although
    one can say that you are doing exactly that by learning a **programming** language
    :). Using Google is translating **individual words** using a vocabulary while
    utilizing ChatGPT is akin to **translating entire sentences and paragraphs of
    text** using online translators. While ChatGPT can be incredibly powerful, you
    may face challenges in identifying hidden errors or understanding certain code
    blocks, especially as a beginner.
  id: totrans-114
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-115
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Given the immense capabilities of ChatGPT, it can be employed in various ways.
    I advise you to use it for **generating short code snippets** — acting as a dictionary
    for idioms or stable expressions. Making sure you have a solid understanding of
    the generated code is essential because it can help prevent future troubles and
    complications.
  id: totrans-116
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-117
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: So, use ChatGPT, but remember to google things as well!
  id: totrans-118
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[This article](https://codeeasy.io/blog/how-to-effectively-google-as-a-software-devel)
    offers some valuable tips on effective googling for software developers.'
  id: totrans-119
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One technique that is helpful in these situations is called [role prompting](https://learnprompting.org/docs/basics/roles).
    Instead of simply asking the model to generate code, you can ask it to write code
    *by being a junior developer*, for instance. By assuming this role, the model
    is more likely to produce code comprehensible to beginners and avoid overly complex
    constructs.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: 'Sample prompt:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Example:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/774bdc72f6c19dfe22ee95db4751b57e.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
- en: Output for a code generation prompt. Image by Author created using [ChatGPT](https://chat.openai.com/chat)
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: In this example, ChatGPT did a pretty good job following all of our instructions,
    including examples and detailed explanations.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: Don’t forget to compare the code with your initial assumptions and draw conclusions
    that will allow you not to make such a request in the future.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, remember that LLMs have no prior knowledge about you or the specific
    problem you’re facing, so the more information you provide, the better output
    you’ll get:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '**Describe your task**;'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Define code structure**: e.g. it is full script, class, or function;'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Specify inputs and outputs**: e.g. the function takes two integer arguments
    and outputs float;'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mention tools/libraries** you want to use, such as numpy or pandas, as well
    as a programming language;'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If feasible, **add your suggestions** on what the solution might look like:
    e.g. I suggest using the `pandas.DataFrame.groupby` function to calculate the
    average salary by position.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimize
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we previously asked the model to behave like a junior developer, we want
    it to be stronger in programming for tasks such as code optimization.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: By the way, you can use the same role prompting trick for debugging as well.
  id: totrans-138
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Sample prompt:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Insert your code here
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Example:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'def unique_list(l):'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Get a list of distinct elements from the given list
  id: totrans-146
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
- en: x = []
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'for a in l:'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'if a not in x:'
  id: totrans-149
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: x.append(a)
  id: totrans-150
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: return x
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](../Images/12f0aabb7685d6f0c5264a868e9daf1a.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
- en: Output for a code optimization prompt. Image by Author created using [ChatGPT](https://chat.openai.com/chat)
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: Here, to extract unique elements from the list, ChatGPT suggests using the `set`
    datatype (that does not allow duplicate values by definition), instead of a for
    loop. A good choice, since it’s basically a one-line solution.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Explain
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can use the same notation requesting comments and code explanations. Often
    this tends to output redundant comments, like `import numpy as np # importing
    numpy library`. However, this can still be useful at the start of your journey,
    and help the model to *express its internal thoughts* as discussed in the [Chain-of-Thought
    reasoning](https://learnprompting.org/docs/intermediate/chain_of_thought) section
    in [my previous article](/summarising-best-practices-for-prompt-engineering-c5e86c483af4).'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: 'Sample prompt:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Insert your code here
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Example:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'def func(n):'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: trow = [1]
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: y = [0]
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'for x in range(max(n, 0)):'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: print(trow)
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: trow = [l + r for l, r in zip(trow + y, y + trow)]
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: return n >= 1
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: func(6)
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](../Images/9d5b8a36c34fbe2dad3d1c274aab16c9.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
- en: Output for a code explanation prompt. Image by Author created using [ChatGPT](https://chat.openai.com/chat)
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, the model was able to identify the task behind this code: generate rows
    of [Pascal’s triangle](https://en.wikipedia.org/wiki/Pascal%27s_triangle). Good
    job!'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: While there are numerous useful applications for ChatGPT you can come up with,
    it’s important to note that it may not always be able to solve every problem you
    encounter. It’s worth discussing this aspect further.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: Few Notes about Potential Pitfalls
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While ChatGPT can be very useful and perform various tasks, it is important
    to keep in mind the potential drawbacks which can be tricky.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: As Autoregressive LLM, ChatGPT is not Deterministic …
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ChatGPT is an example of a Large Language Model, and current Large Language
    Models are **autoregressive**, meaning that *they are trained to predict the next
    token in a sequence*. The output of a model is a probability distribution across
    all possible tokens, and we sample the final text from this distribution token
    by token. As a result, the sampling process is **non-deterministic**, meaning
    that *you can have different outputs for the same input* due to probabilistic
    reasons.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate this, we can imagine the sampling process as a tree. Here the
    initial sentence is shown in blue, selected tokens are shown in green, and non-selected
    ones are represented in red (without their further evolution). The probabilities
    are picked randomly just for illustration reasons.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b691129872ca6693fa841de166d63d2e.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
- en: Simplified visualization of the sampling process for LLM. Image by Author
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: 'The input sequence is: “*My name is*” and ChatGPT completes it with “*ChatGPT,
    pleased to assist you!*”. This is an example from [my previous article](/behind-the-millions-estimating-the-scale-of-large-language-models-97bd7287fb6b),
    where I discuss the basics of LLMs.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: … and That’s Why ChatGPT can be Wrong
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In practice, this means that you can get suboptimal output just because you
    got some rare unlikely tokens at the start. As a result, **you may need several
    runs of the same input** to examine the different outputs and select the most
    suitable one or even *combine different parts from different outputs*.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, it’s important to highlight that modern language models, especially
    GPT-4, possess impressive *self-correction capabilities*. If the generated code
    contains errors, you can simply return it and indicate that it is not functioning
    correctly. GPT-4 is adept at **debugging its own code** and offering relevant
    suggestions. You’ll often be able to obtain the correct code after a couple of
    iterations.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，重要的是要强调现代语言模型，特别是GPT-4，具有令人印象深刻的*自我纠正能力*。如果生成的代码有错误，你可以简单地返回它并指出它的功能不正确。GPT-4擅长**调试自己的代码**并提供相关建议。你通常可以在几次迭代后获得正确的代码。
- en: Overconfidence
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 过度自信
- en: Despite the fact that LLMs can sometimes provide incorrect outputs, they have
    been trained to prioritize accuracy. This can make their **output appear very
    convincing, even when it is incorrect**. As a result, identifying hidden errors
    can be challenging because the model often cannot explicitly say *“I need more
    information”*, although ongoing research is actively exploring ways to address
    this limitation.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管LLMs有时可能提供不正确的输出，但它们经过训练优先考虑准确性。这可能使它们的**输出看起来非常令人信服，即使它是错误的**。因此，识别隐藏的错误可能具有挑战性，因为模型通常不能明确地说*“我需要更多的信息”*，尽管正在进行的研究正积极探索解决这一限制的方法。
- en: In this sense, using ChatGPT for generating **small snippets of code** to solve
    specific tasks, as I mentioned earlier when referring to Googling, can be safer.
    It is essential to ensure that you have a solid understanding of the code you
    receive which allow you to navigate potential pitfalls effectively.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个意义上讲，使用ChatGPT生成**小段代码**以解决特定任务，如我之前提到的谷歌搜索，可以更安全。确保你对所收到的代码有扎实的理解，这样可以有效避免潜在的陷阱。
- en: Conclusion
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this article, we have explored methods that can assist you in debugging,
    not only with ChatGPT but also with yourself.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们探讨了可以帮助你调试的方法，不仅仅是与ChatGPT一起，还有你自己。
- en: By **isolating** the problem and **rewriting it in minimal lines of code**,
    you are likely to gain insights into the underlying issue. Or let ChatGPT help
    you by providing **complete information about what is happening**, making assumptions,
    and experimenting.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 通过**隔离**问题和**用最少的代码行重新编写**，你很可能会洞察到潜在的问题。或者，让ChatGPT帮助你，提供**关于发生了什么的完整信息**，进行假设并进行实验。
- en: You can also utilize ChatGPT for tasks such as writing, optimizing, or explaining
    code, as we discussed in the example of role prompting. The other code-related
    applications are endless and include creating dummy data, writing tests, generating
    documentation, and more.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以利用ChatGPT进行任务，例如编写、优化或解释代码，就像我们在角色提示示例中讨论的那样。其他与代码相关的应用几乎无穷无尽，包括创建虚拟数据、编写测试、生成文档等。
- en: But remember the limitations of LLMs, as they can introduce hidden problems.
    Due to their autoregressive nature, LLMs **can be wrong while appearing confident**,
    which may require asking more questions or running multiple iterations to select
    the best output.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 但要记住LLMs的局限性，因为它们可能引入隐藏的问题。由于其自回归性质，LLMs**可能在表现自信的同时犯错**，这可能需要更多的问题或多次迭代以选择最佳输出。
- en: Wishing you the best of luck on your learning journey!
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 祝你学习顺利！
- en: Resources
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源
- en: Check out [this article](https://realpython.com/chatgpt-coding-mentor-python/)
    for a broader guide of making ChatGPT your personal coding mentor.
  id: totrans-198
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 查看[这篇文章](https://realpython.com/chatgpt-coding-mentor-python/)以获取将ChatGPT作为个人编码导师的更广泛指南。
- en: 'Here are my other articles about LLMs that may be useful to you. I have already
    covered:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我关于LLMs的其他文章，可能对你有用。我已经涵盖了：
- en: '[Estimating the Scale of Large Language Models](/behind-the-millions-estimating-the-scale-of-large-language-models-97bd7287fb6b):
    what are LLMs, how are they trained, and how much data and compute do they need;'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[估计大型语言模型的规模](/behind-the-millions-estimating-the-scale-of-large-language-models-97bd7287fb6b)：LLMs是什么，它们是如何训练的，需要多少数据和计算资源；'
- en: '[Best Practices for Prompt Engineering](/summarising-best-practices-for-prompt-engineering-c5e86c483af4):
    how to apply prompt engineering techniques to interact with LLMs effectively and
    how to build local LLM-based applications with OpenAI API and Streamlit.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[提示工程的最佳实践](/summarising-best-practices-for-prompt-engineering-c5e86c483af4)：如何应用提示工程技术与LLMs有效互动，以及如何使用OpenAI
    API和Streamlit构建本地LLM应用程序。'
- en: 'You can be also interested in:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还感兴趣：
- en: Free [Learn Prompting course](https://learnprompting.org/) to gain a deeper
    understanding of prompting and various techniques associated with it;
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 免费的[Learn Prompting课程](https://learnprompting.org/)帮助你深入了解提示工程及其相关技术；
- en: Recently released [short courses by DeepLearning.AI](https://www.deeplearning.ai/short-courses/)
    to build applications with OpenAI API.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最近发布了[DeepLearning.AI的短课程](https://www.deeplearning.ai/short-courses/)，用于构建OpenAI
    API应用程序。
- en: Thank you for reading!
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 感谢你的阅读！
- en: I hope these materials were useful to you. [Follow me on Medium](https://medium.com/@andimid)
    to get more articles like this.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 希望这些材料对你有帮助。[关注我在Medium上的更新](https://medium.com/@andimid)以获取更多类似的文章。
- en: If you have any questions or comments, I will be glad to get any feedback. Ask
    me in the comments, or connect via [LinkedIn](https://www.linkedin.com/in/andimid/)
    or [Twitter](https://twitter.com/dimid_ml).
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你有任何问题或意见，我很乐意收到任何反馈。可以在评论中问我，或者通过[LinkedIn](https://www.linkedin.com/in/andimid/)或[Twitter](https://twitter.com/dimid_ml)与我联系。
- en: To support me as a writer and to get access to thousands of other Medium articles,
    get Medium membership using [my referral link](https://medium.com/@andimid/membership)
    (no extra charge for you).
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了支持我作为作家，并获得其他数千篇Medium文章的访问权限，可以使用[我的推荐链接](https://medium.com/@andimid/membership)来获取Medium会员（对你没有额外费用）。
