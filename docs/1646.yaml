- en: Optimizing Vector Quantization Methods by Machine Learning Algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/optimizing-vector-quantization-methods-by-machine-learning-algorithms-77c436d0749d?source=collection_archive---------4-----------------------#2023-05-17](https://towardsdatascience.com/optimizing-vector-quantization-methods-by-machine-learning-algorithms-77c436d0749d?source=collection_archive---------4-----------------------#2023-05-17)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Machine learning optimization of vector quantization methods used in end-to-end
    training of neural networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@mohammad.vali?source=post_page-----77c436d0749d--------------------------------)[![Mohammad
    Hassan Vali](../Images/b057aa7bd9e1c629fc3743a7f69f013e.png)](https://medium.com/@mohammad.vali?source=post_page-----77c436d0749d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----77c436d0749d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----77c436d0749d--------------------------------)
    [Mohammad Hassan Vali](https://medium.com/@mohammad.vali?source=post_page-----77c436d0749d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F840f2c687344&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-vector-quantization-methods-by-machine-learning-algorithms-77c436d0749d&user=Mohammad+Hassan+Vali&userId=840f2c687344&source=post_page-840f2c687344----77c436d0749d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----77c436d0749d--------------------------------)
    ·10 min read·May 17, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F77c436d0749d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-vector-quantization-methods-by-machine-learning-algorithms-77c436d0749d&user=Mohammad+Hassan+Vali&userId=840f2c687344&source=-----77c436d0749d---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F77c436d0749d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-vector-quantization-methods-by-machine-learning-algorithms-77c436d0749d&source=-----77c436d0749d---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: This post is a short explanation of our paper [1] published at ICASSP 2023 conference.
    For more details, please look at the paper [under this link](https://ieeexplore.ieee.org/abstract/document/10096204).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/1b6c41b4f07a4b381d9da086ab84a80c.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Alina Grubnyak](https://unsplash.com/@alinnnaaaa?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/ZiQkhI7417A?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: Vector Quantization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Vector quantization (VQ) is a data compression technique similar to k-means
    algorithm which can model any data distribution. Vector quantization has been
    used in a wide range of applications for speech, image, and video data, such as
    image generation [2], speech and audio coding [3], voice conversion [4,5], music
    generation [6], and text-to-speech synthesis [7,8]. The figure below shows how
    vector quantization (VQ) works. For VQ process, we require a codebook which includes
    a number of codewords. Applying VQ on a data point (gray dots) means to map it
    to the closest codeword (blue dots), i.e. replace the value of data point with
    the closest codeword value. Each voronoi cell (black lines) contains one codeword
    such that all data points located in that cell will be mapped to that codeword,
    since it is the closest codeword to data points located in that voronoi cell.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/30dacbc81108406f7bfe0f64f3a26d52.png)'
  prefs: []
  type: TYPE_IMG
- en: Vector Quantization Operation (image by author)
  prefs: []
  type: TYPE_NORMAL
- en: 'In other words, vector quantization maps the input vector x to the closest
    codeword within the codebook (CB) using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d2801e8776ea39def212b62f395038ab.png)'
  prefs: []
  type: TYPE_IMG
- en: The computational complexity of VQ increases exponentially with the increase
    in the codebook size (increase in VQ bitrate). Hence, this plain form of VQ is
    applicable only for limited bitrates (limited codebook sizes). To solve this challenge
    and apply VQ for higher bitrates and higher dimensional data, we use some variants
    of VQ such as Residual VQ, Additive VQ, and Product VQ. These methods considers
    more than one codebook to apply VQ on the data. We will explain these three VQ
    methods in the following.
  prefs: []
  type: TYPE_NORMAL
- en: '**Residual Vector Quantization (RVQ)**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Residual VQ quantizes the input vector x by applying M consecutive VQ modules
    on it. According to the following figure, suppose M=3\. We apply the first VQ
    module on input vector x using the first codebook (CB¹). Then, after finding the
    closest codeword form first codebook, we calculate the remainder (R1). Afterwards,
    we pass R1 as input to the next VQ module using the second codebook (CB²). This
    process will continue for M stages where we would find three closest codeword
    coming from separate codebooks. At the end, we quantize the input vector x as
    a summation of M closest codewords.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/69fd7ea5e5d1eb9d65bf47d3894eddc9.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Additive Vector Quantization (AVQ)**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a similar way as Residual VQ, Additive VQ quantizes the input vector x by
    applying M consecutive VQ modules. However, Additive VQ adopts the complex beam
    searching algorithm to find the closest codewords for the quantization process
    (you can find the details of beam searching algorithm in this paper [9]). According
    to the following figure, we suppose M=3\. In Additive VQ, first we search for
    the closest codeword from the union of all three codebooks (here CB¹, CB², CB³).
    Then, suppose we find the best codeword from CB². After that, we calculate the
    residual (R1) and pass it as input to the next VQ module. Since the first codeword
    is selected from CB², now we search for the closest codeword from the union of
    CB¹ and CB³. After calculating the residual R2, we pass it as input to the last
    VQ module, where we do the search using the last codebook (in this case CB¹) which
    is not yet contributed to the quantization process. At the end, we quantize the
    input vector x as a summation of M closest codewords.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/263661bd4201cde99f7aa75e27321c13.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Product Vector Quantization (PVQ)**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Product VQ splits the input vector x of dimension D to M independent subspaces
    of dimension D/M. Then it applies M independent VQ modules to the existing subspaces.
    At the end, Product VQ quantizes the input vector x as a concatenation of M closest
    codewords (one per each codebook). The figure below shows the Product VQ when
    M=3.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3a9223cfafc720daab683a4a52f0254a.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Codebooks Optimization**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Vector quantization (VQ) training means to optimize the codebook(s) such that
    they model the data distribution in a way that the error of quantization (such
    as mean squared error) between data points and codebook elements is minimized.
    To optimize the codebooks for these three above-mentioned variants of VQ (Residual
    VQ, Additive VQ, and Product VQ) there are different approaches which we will
    mention in the following.
  prefs: []
  type: TYPE_NORMAL
- en: '1\. K-means Algorithm (traditional approach):'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Based on the literature review, in most of the papers, codebooks for these three
    VQ methods have been optimized by [k-means algorithm](https://en.wikipedia.org/wiki/K-means_clustering).
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Stochastic Optimization (machine learning algorithms):'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Machine learning optimization algorithms are based on gradient calculation.
    Therefore, it is impossible to optimize vector quantization methods using machine
    learning optimization, since the argmin function in vector quantization function
    (first equation above) is not differentiable. In other words, we cannot pass the
    gradients over vector quantization function in backpropagation. Here we have mentioned
    two solutions to solve this problem.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1\. Straight Through Estimator (STE)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: STE [10] solves the problem by simply copying the gradients intactly over VQ
    module in backpropagation. Hence, it does not consider the influence of vector
    quantization and leads to a mismatch between the gradients and true behavior of
    the VQ function.
  prefs: []
  type: TYPE_NORMAL
- en: '2.2\. Noise Substitution in Vector Quantization (NSVQ):'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The NSVQ technique [11] is our recently proposed method, in which the vector
    quantization error is simulated by adding noise to the input vector, such that
    the simulated noise would gain the shape of original VQ error distribution (you
    can read shortly about NSVQ [in this post](https://medium.com/towards-data-science/improving-vector-quantization-in-vector-quantized-variational-autoencoders-vq-vae-915f5814b5ce)).
  prefs: []
  type: TYPE_NORMAL
- en: NSVQ technique [11] has some advantages over STE method [10] which are listed
    in the following. 1) NSVQ yields more accurate gradients for VQ function. 2) NSVQ
    achieves faster convergence for VQ training (codebook optimization). 3) NSVQ does
    not need any additional hyper-parameter tuning for VQ training (does not require
    additional loss term for VQ training to be added to the global optimization loss
    function).
  prefs: []
  type: TYPE_NORMAL
- en: Experiments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our paper, we have used our recently proposed NSVQ technique [11] to optimize
    three above-mentioned variants of VQ by machine learning optimization. To evaluate
    the performance of these three VQ methods and study the trade-offs between accuracy,
    bitrate, and complexity of them, we conducted four different scenarios for experiments.
    We will explain all these scenarios of experiments in the following.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Approximate Nearest Neighbor (ANN) Search
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this experiment, we modeled the distribution of SIFT1M dataset [12] (128-D
    image descriptors) by training three VQ methods on its learning set. The SIFT1M
    image descriptors dataset [12] includes 10⁶ base vectors, 10⁵ learning vectors,
    and 10⁴ query vectors for testing purposes. The ground truth contains the set
    of actual nearest neighbors, from the base vectors to the query vectors. In the
    ANN search, we first compress the base vectors using the corresponding learnt
    codebooks trained on the learning set. Then, for each query vector, we find the
    approximate nearest neighbors from the compressed base vectors by performing an
    exhaustive search. To assess the quality of data compression, we calculate the
    *recall metric* at different values for parameter ***T***, which shows whether
    the actual nearest neighbor (from groundtruth) exists in the first ***T*** computed
    nearest neighbors. The figure below illustrates the comparison of three variants
    of VQ optimized by our proposed NSVQ technique with the baseline methods under
    *recall metric*. In general, all three machine learning-based optimized VQ methods
    achieve comparable (even slightly better in case of RVQ) recall values to the
    baselines.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4d3653f5b7b5e01742b3a668f9b16e2b.png)'
  prefs: []
  type: TYPE_IMG
- en: Comparison of recall values for compression of SIFT1M dataset by applying our
    proposed VQ methods and baselines at 64 bits (8 codebooks each with 256 codewords);
    Recall@T shows whether the actual nearest neighbor (from groundtruth) exists in
    the T computed nearest neighbors. (image by author)
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Image Compression using VQ-VAE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this experiment, we trained a vector quantized variational autoencoder (VQ-VAE)
    on the training set of CIFAR10 dataset to compress it. To apply the vector quantization
    in the bottleneck of VQ-VAE, we used each of these three VQ methods. After training,
    we reconstructed the test images of CIFAR10 using the trained encoder, decoder,
    and learnt codebooks for each VQ method. To evaluate the quality of reconstructed
    images, we employ Peak Signal to Noise Ratio (Peak SNR) metric. In addition, we
    computed the complexity of each VQ method using Weighted Million Operations Per
    Second (WMOPS) metric, which is under [ITU-T standard](https://en.wikipedia.org/wiki/ITU-T).
    The following figure shows the results of this experiment.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/202eabf11a048f6dae696b130a20e8ee.png)'
  prefs: []
  type: TYPE_IMG
- en: Peak SNR and complexity of proposed VQ methods over 15 k training batches and
    10 individual experiments in the image compression scenario; lines refer to the
    mean values and the corresponding filled areas refer to their 95 % quantiles.
    For all VQ bitrates we used four codebooks i.e. M=4\. (image by author)
  prefs: []
  type: TYPE_NORMAL
- en: According to the complexity figure (in the right), we found that for the same
    use of computational resources (left vertical red line) and a higher bitrate,
    Product VQ performs better than Residual VQ. In addition, for the same use of
    computational resources (right vertical red line) and a higher bitrate, Residual
    VQ performs better than Additive VQ. Therefore, depending on how much computational
    resources are available, we can conclude which is the best VQ method to use.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Speech Coding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this experiment, we model the spectral envelope of speech signals by three
    VQ methods using the speech codec presented in [13]. To evaluate the quality of
    decoded speech signals, we used perceptual evaluation of speech quality (PESQ)
    and perceptually weighted signal to noise ratio (pSNR) as objective metrics. The
    following figure shows the performance of all three VQ methods under PESQ and
    pSNR criteria. According to the results, we observe that Additive VQ gains higher
    mean and lower variance than both Residual VQ and Product VQ in both metrics.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fda41b0e398776828c7acfb72c87cb0e.png)'
  prefs: []
  type: TYPE_IMG
- en: Performance of proposed VQ methods in terms of PESQ and pSNR metrics for 16
    bit VQ (with 4 codebooks i.e. M=4) at overall bitrates of 8, 9.6, 13.2, 16.4,
    24.4 and 32 kbit/s in the speech coding scenario; solid lines refer to the mean
    values of PESQ and pSNR, and the corresponding filled areas refer to their 95%
    quantiles. (image by author)
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Toy Examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this experiment, we intend to compare the performance of three VQ methods
    with respect to the correlation in the data. Hence, we prepared two correlated
    and uncorrelated datasets of dimension 64\. Then, we compressed these datasets
    using these three VQ methods. To evaluate the performance, we computed the mean
    squared error (MSE) between each dataset and its quantized version. The following
    figure shows the results for this experiment.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b18dd11707979378d90e576912295e49.png)'
  prefs: []
  type: TYPE_IMG
- en: Vector quantization error for correlated and uncorrelated datasets using all
    three proposed VQ methods (data dimension=64, and for all VQ bitrates we used
    four codebooks i.e. M=4). (image by author)
  prefs: []
  type: TYPE_NORMAL
- en: In correlated dataset, since Residual VQ and Additive VQ take the correlation
    among all data dimensions into account, they have much lower quantization error
    than Product VQ as expected. On the other hand, Product VQ has better performance
    than Additive VQ and Residual VQ for uncorrelated data, since there is no correlation
    among data dimensions and that is exactly what Product VQ presumes.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using variants of Vector Quantization (VQ) such as Residual VQ, Additive VQ,
    and Product VQ allows to apply VQ for high bitrates and high dimensional data.
    These VQ methods have been optimized by classic expectation maximization and k-menas
    algorithm so far. In this paper, we optimize these VQ methods by machine learning
    optimization using our recently proposed Noise Substitution in Vector Quantization
    (NSVQ) [11] technique. In addition, NSVQ allows end-to-end optimization of VQ
    methods in Neural Netwroks. We also study the trade-offs between bitrate, accuracy,
    and complexity of these three VQ methods. Hence, our open-source implementation
    [14] helps to make the best choice of VQ method for a particular use-case.
  prefs: []
  type: TYPE_NORMAL
- en: GitHub Repository
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We provide the PyTorch implementation of these VQ methods in the following webpage.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/MHVali/Additive-Residual-Product-Vector-Quantization-Methods.git?source=post_page-----77c436d0749d--------------------------------)
    [## GitHub - MHVali/Additive-Residual-Product-Vector-Quantization-Methods'
  prefs: []
  type: TYPE_NORMAL
- en: Contribute to MHVali/Additive-Residual-Product-Vector-Quantization-Methods development
    by creating an account on…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/MHVali/Additive-Residual-Product-Vector-Quantization-Methods.git?source=post_page-----77c436d0749d--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Special thanks to my doctoral program supervisor [Prof. Tom Bäckström](https://research.aalto.fi/en/persons/tom-bäckström),
    who supported me and was the other contributor for this work.
  prefs: []
  type: TYPE_NORMAL
- en: '**References**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] M. H. Vali and T. Bäckström, “Stochastic Optimization of Vector Quantization
    Methods in Application to Speech and Image Processing,” in *Proceedings of ICASSP*,
    2023.'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] A. Razavi, A. van den Oord, and O. Vinyals, “Generating diverse high-fidelity
    images with VQ-VAE-2,” in *Proceedings of NeurIPS*, 2019.'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] C. Gârbacea, A. van den Oord, Y. Li, F. S. C. Lim, A. Luebs, O. Vinyals,
    and T. C. Walters, “Low bit-rate speech coding with VQ-VAE and a Wavenet decoder,”
    in *Proceedings of ICASSP*, 2019.'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] B. van Niekerk, L. Nortje, and H. Kamper, “Vector-quantized neural networks
    for acoustic unit discovery in the zerospeech 2020 challenge,” in *Proceedings
    of Interspeech*, 2020.'
  prefs: []
  type: TYPE_NORMAL
- en: '[5] S. Ding and R. Gutierrez-Osuna, “Group latent embedding for vector quantized
    variational autoencoder in non-parallel voice conversion,” in *Proceedings of
    Interspeech*, 2019.'
  prefs: []
  type: TYPE_NORMAL
- en: '[6] P. Dhariwal, H. Jun, C. Payne, J. W. Kim, A. Radford, and I. Sutskever,
    “Jukebox: a generative model for music,” *arXiv preprint arXiv:2005.00341*, 2020.'
  prefs: []
  type: TYPE_NORMAL
- en: '[7] A. Tjandra, B. Sisman, M. Zhang, S. Sakti, H. Li, and S. Nakamura, “VQVAE
    unsupervised unit discovery and multi-scale code2spec inverter for Zerospeech
    challenge 2019,” in *Proceedings of Interspeech*, 2019.'
  prefs: []
  type: TYPE_NORMAL
- en: '[8] X. Wang, S. Takaki, J. Yamagishi, S. King, and K. Tokuda, “A vector quantized
    variational autoencoder (VQ-VAE) autoregressive neural F0 model for statistical
    parametric speech synthesis,” *IEEE Transactions on Audio, Speech, and Language
    Processing*, 2020.'
  prefs: []
  type: TYPE_NORMAL
- en: '[9] A. Babenko and V. Lempitsky, “Additive quantization for extreme vector
    compression,” in *Proceedings of CVPR*, 2014.'
  prefs: []
  type: TYPE_NORMAL
- en: '[10] Y. Bengio, N. Léonard, and A. Courville, “Estimating or Propagating Gradients
    Through Stochastic Neurons for Conditional Computation,” a*rXiv preprint arXiv:1308.3432,*
    2013.'
  prefs: []
  type: TYPE_NORMAL
- en: '[11] M. H. Vali and T. Bäckström, “NSVQ: Noise Substitution in Vector Quantization
    for Machine Learning,” *IEEE Access*, vol. 10, 2022.'
  prefs: []
  type: TYPE_NORMAL
- en: '[12] H. Jegou, M. Douze, and C. Schmid, “Product Quantization for Nearest Neighbor
    Search,” *IEEE Transactions on Pattern Analysis and Machine Intelligence*, vol.
    33, no. 1, pp. 117–128, 2010.'
  prefs: []
  type: TYPE_NORMAL
- en: '[13] M. H. Vali and T. Bäckström, “End-to-End Optimized Multi-Stage Vector
    Quantization of Spectral Envelopes for Speech and Audio Coding,” in *Proceedings
    of Interspeech*, 2021.'
  prefs: []
  type: TYPE_NORMAL
- en: '[14] [https://gitlab.com/speech-interaction-technology-aalto-university/vq-variants](https://gitlab.com/speech-interaction-technology-aalto-university/vq-variants)'
  prefs: []
  type: TYPE_NORMAL
