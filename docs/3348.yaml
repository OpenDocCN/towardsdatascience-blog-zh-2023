- en: Towards Generative AI for Model Architecture
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 朝向生成式 AI 的模型架构
- en: 原文：[https://towardsdatascience.com/towards-generative-ai-for-model-architecture-ea3be303166b?source=collection_archive---------4-----------------------#2023-11-10](https://towardsdatascience.com/towards-generative-ai-for-model-architecture-ea3be303166b?source=collection_archive---------4-----------------------#2023-11-10)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/towards-generative-ai-for-model-architecture-ea3be303166b?source=collection_archive---------4-----------------------#2023-11-10](https://towardsdatascience.com/towards-generative-ai-for-model-architecture-ea3be303166b?source=collection_archive---------4-----------------------#2023-11-10)
- en: How “MAD” AI will help us discover the next transformer
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: “MAD” AI 如何帮助我们发现下一个变压器
- en: '[](https://medium.com/@drwiner?source=post_page-----ea3be303166b--------------------------------)[![David
    R. Winer](../Images/b35dd80eba0ee2f04fbf58bc1d90587c.png)](https://medium.com/@drwiner?source=post_page-----ea3be303166b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ea3be303166b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ea3be303166b--------------------------------)
    [David R. Winer](https://medium.com/@drwiner?source=post_page-----ea3be303166b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@drwiner?source=post_page-----ea3be303166b--------------------------------)[![David
    R. Winer](../Images/b35dd80eba0ee2f04fbf58bc1d90587c.png)](https://medium.com/@drwiner?source=post_page-----ea3be303166b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ea3be303166b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ea3be303166b--------------------------------)
    [David R. Winer](https://medium.com/@drwiner?source=post_page-----ea3be303166b--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb2e18ae49c3e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftowards-generative-ai-for-model-architecture-ea3be303166b&user=David+R.+Winer&userId=b2e18ae49c3e&source=post_page-b2e18ae49c3e----ea3be303166b---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ea3be303166b--------------------------------)
    ·11 min read·Nov 10, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fea3be303166b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftowards-generative-ai-for-model-architecture-ea3be303166b&user=David+R.+Winer&userId=b2e18ae49c3e&source=-----ea3be303166b---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb2e18ae49c3e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftowards-generative-ai-for-model-architecture-ea3be303166b&user=David+R.+Winer&userId=b2e18ae49c3e&source=post_page-b2e18ae49c3e----ea3be303166b---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ea3be303166b--------------------------------)
    ·11分钟阅读·2023年11月10日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fea3be303166b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftowards-generative-ai-for-model-architecture-ea3be303166b&user=David+R.+Winer&userId=b2e18ae49c3e&source=-----ea3be303166b---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fea3be303166b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftowards-generative-ai-for-model-architecture-ea3be303166b&source=-----ea3be303166b---------------------bookmark_footer-----------)![](../Images/153affe1659f64de6f69bc02d4531694.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fea3be303166b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftowards-generative-ai-for-model-architecture-ea3be303166b&source=-----ea3be303166b---------------------bookmark_footer-----------)![](../Images/153affe1659f64de6f69bc02d4531694.png)'
- en: 'Credit: [https://unsplash.com/photos/person-wearing-gas-mask-in-grayscale-photography-2PV6wdWVAMM](https://unsplash.com/photos/person-wearing-gas-mask-in-grayscale-photography-2PV6wdWVAMM)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 版权： [https://unsplash.com/photos/person-wearing-gas-mask-in-grayscale-photography-2PV6wdWVAMM](https://unsplash.com/photos/person-wearing-gas-mask-in-grayscale-photography-2PV6wdWVAMM)
- en: The “Attention is All You Need” transformer revolution has had a profound effect
    on the design of deep learning model architectures. Not long after BERT, there
    was RoBERTa, ALBERT, DistilBERT, SpanBERT, DeBERTa, and many more. Then there’s
    ERNIE (which still goes strong with “Ernie 4.0”), GPT series, BART, T5, and so
    it goes. A museum of transformer architectures has formed on the [HuggingFace](https://huggingface.co/docs/transformers/model_doc/bert)
    side panel, and the pace of new models has only quickened. Pythia, Zephyr, Llama,
    Mistral, MPT, and many more, each making a mark on accuracy, speed, training efficiency,
    and other metrics.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: By model architecture, I’m referring to the computational graph underlying the
    execution of the model. For example, below is a snippet from [Netron](https://github.com/lutzroeder/netron)
    showing part of the computational graph of T5\. Each node is either an operation
    or a variable (input or output of an operation), forming a [node graph architecture](https://en.wikipedia.org/wiki/Node_graph_architecture).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cfbf5f61a2251a9f7147279d1ed89529.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Even though there are so many architectures, we can be pretty sure that the
    future holds even more modifications and new breakthroughs. But each time, it’s
    human researchers that have to understand the models, make hypotheses, troubleshoot,
    and test. While there’s boundless human ingenuity, the task of understanding architectures
    gets tougher as the models get larger and more complex. With AI guidance, perhaps
    humans can discovery model architectures that would take humans many more years
    or decades to discovery without AI assistance.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Intelligent **M**odel **A**rchitecture **D**esign (**MAD**) is the idea that
    generative AI can guide scientists and AI researchers to better, more effective
    model architectures faster and easier. We already see large language models (LLMs)
    providing immense value and creativity for everything from summarizing, analyzing,
    image generation, writing assistance, code generation, and much more. The question
    is, *can we harness the same intelligent assistance and creativity for designing
    model architecture as well?* Researchers could be guided by intuition and prompt
    the AI system with their ideas, like “self attention that scales hierarchically”,
    or even for more specific actions like “add LoRA to my model at the last layer”.
    By associating text-based descriptions of model architectures, e.g., using [Papers
    with Code,](https://paperswithcode.com/) we could learn what kinds of techniques
    and names are associated with specific model architectures.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: First, I’ll start with why model architecture is important. After, I’ll cover
    some of the trajectories towards intelligence MAD in neural architecture search,
    code assistance, and graph learning. Finally, I put together some project steps
    and discuss some of the implications for AI designing and self-improving via autonomous
    MAD.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Return of Model-Centric AI
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Andrew Ng’s push and coining of “[data-centric](https://landing.ai/data-centric-ai/)”
    AI was very important for the AI field. With deep learning, the ROI for having
    clean and high quality data is immense, and this is realized in every phase of
    training. For context, the era right before BERT in the text classification world
    was one where you wanted an abundance of data, even at the expense of quality.
    It was more important to have representation via examples than for the examples
    to be perfect. This is because many AI systems did not use pre-trained embeddings
    (or they weren’t any good, anyway) that could be leveraged by a model to apply
    practical generalizability. In 2018, BERT was a breakthrough for down-stream text
    tasks, but it took even more time for leaders and practitioners to reach consensus
    and the idea of “data-centric” AI helped change the way we feed data into AI models.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dbade515ee3749cabab4b7fc79e7c26c.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
- en: Image By Author
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Today, there are many that see the current architectures out there as “good
    enough”, and that it’s much more important to focus on improving the data quality
    than it is on editing the model. There is now a huge community push for high quality
    datasets for training, like [Red Pajama Data](https://github.com/togethercomputer/RedPajama-Data)
    for example. Indeed we see that many of the great improvements between LLMs lie
    not in model architecture but in the data quality and preparation methodology.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: At the same time, every week there is a new method that involves a kind of model
    surgery that is showing to have some great impact on training efficiency, inference
    speed, or overall accuracy. When a paper claims to be “the new transformer” like
    [RETNET](https://arxiv.org/abs/2307.08621) did, it has everyone talking. *Because
    as good as the existing architectures are, another breakthrough like self attention
    will have a profound impact on the field and what AI can be productionized to
    accomplish*. And even for small breakthroughs, training is expensive so you want
    to minimize the number of times you train. Thus, if you have a specific goal in
    mind, MAD is also important for getting the best return for your buck.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Transformer architectures are huge and complex and that makes it more difficult
    to focus on model-centric AI. We’re at a time when generative AI methods are becoming
    more advanced and intelligent MAD is in sight.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Neural Architecture Search
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/08781f5149cdfddeb8c7a7e3b8ec7424.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
- en: '[https://arxiv.org/pdf/1808.05377.pdf](https://arxiv.org/pdf/1808.05377.pdf)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: The premise and goal of [**Neural Architecture Search**](https://en.wikipedia.org/wiki/Neural_architecture_search)
    **(NAS)** is aligned with intelligent MAD, to alleviate the burden of researchers
    designing and discovering the best architectures. Generally, this has been realized
    as a kind of AutoML where hyper-parameters include architecture designs, and I’ve
    seen it become incorporated into many hyper-parameter configurations.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: A NAS dataset (i.e., [NAS benchmark](https://arxiv.org/pdf/2008.09777.pdf))
    is a machine learning dataset, <X, Y>, where X is a machine learning architecture
    expressed as a graph, and Y is an evaluation metric when that architecture is
    trained and tested on a specific dataset. NAS benchmarks are still evolving. Initially,
    the learning representation in the NAS benchmarks were just ordered lists, so
    each list represented a neural architecture as a sequence of operations e.g.,
    [3x3Conv, 10x10Conv, …], etc. This isn’t low-level enough to capture the partial
    ordering we find in modern architectures, such as “skip connections” where layers
    feed forward as well as to layers later in the model. Later, the [DARTS](/intuitive-explanation-of-differentiable-architecture-search-darts-692bdadcc69c)
    representation used nodes to represent variables and edges to represent operations.
    Much more recently, some new techniques for NAS have been created to avoid requiring
    a predefined search space, such as [AGNN](https://arxiv.org/pdf/2206.09166.pdf)
    which is applying NAS for learning GNNs to improve performance on graph-based
    datasets.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: At the end of the day, there are only about 250 primitive-level tensor operations
    in a deep learning tensor library like TensorFlow or PyTorch. If the search space
    is from first principles and includes all possible models, then it should include
    the next SOTA architecture variation in its search space. But in practice, this
    is not how NAS is set up. *Techniques can take the equivalent of 10 years of GPU
    compute, and that’s when the search space is relaxed and limited in various ways.*
    Thus, NAS has mostly focused on recombining existing components of model architectures.
    For example, [NAS-BERT](https://arxiv.org/abs/2105.14444) used a masked modeling
    objective to train over smaller variations of BERT architectures that perform
    well on the GLUE downstream tasks, thus functioning to distill or compress itself
    into less parameters. The [Autoformer](https://arxiv.org/abs/2106.13008) did something
    similar with a different search space.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '[Efficient NAS](https://arxiv.org/abs/1802.03268) (ENAS) overcomes the problem
    of needing to exhaustively train and evaluate every model in the search space.
    This is done by first training a super network containing many candidate models
    as sub-graphs that share the same weights. In general, parameter-sharing between
    candidate models makes NAS more practical and allow the search to focus on architecture
    variation to best use the existing weights.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Text-based MAD versus Graph-based MAD
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From the generative AI perspective, there is an opportunity to pre-train on
    model architectures and use this foundation model for generating architectures
    as a language. This could be used for NAS as well as a general guidance system
    for researchers such as using prompts and for context-based suggestions.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: The main question from this point of view is whether to represent architectures
    as text or directly as graphs. We have seen the recent rise of code generation
    AI assistance, and some of that code is the PyTorch, TensorFlow, Flax, etc., related
    to deep learning model architecture. However, code generation has numerous limitations
    for this use case, mostly because much of code generation is about the surface
    form i.e., text representation.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个角度来看，主要的问题是是否将架构表示为文本还是直接表示为图。我们已经看到代码生成 AI 辅助工具的最近崛起，其中一些代码涉及 PyTorch、TensorFlow、Flax
    等，相关于深度学习模型架构。然而，代码生成在这个用例中有许多限制，主要因为代码生成大多涉及表面形式，即文本表示。
- en: On the other hand, Graph Neural Networks (GNNs) like graph transformers are
    very effective because graph structure is everywhere, including MAD. The benefit
    of working on graphs directly is that the model is learning on an underlying representation
    of the data, closer to the ground truth than the surface-level text representation.
    Even with some recent work to make LLMs amazing at generating graphs, like [InstructGLM](https://arxiv.org/abs/2308.07134),
    there is promise for graph transformers in the limit and especially conjunction
    with LLMs.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，像图变换器这样的图神经网络（GNNs）非常有效，因为图结构无处不在，包括在 MAD 中。直接处理图的好处在于模型学习的是数据的底层表示，比表面文本表示更接近真实情况。尽管最近一些工作使得
    LLMs 在生成图方面表现出色，比如 [InstructGLM](https://arxiv.org/abs/2308.07134)，但图变换器在极限情况下，尤其是与
    LLMs 结合使用时，仍然有很大的潜力。
- en: '![](../Images/ac92f493b8d9d5f15ab3bfa5f0d8b112.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ac92f493b8d9d5f15ab3bfa5f0d8b112.png)'
- en: '[https://arxiv.org/pdf/2308.07134.pdf](https://arxiv.org/pdf/2308.07134.pdf)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://arxiv.org/pdf/2308.07134.pdf](https://arxiv.org/pdf/2308.07134.pdf)'
- en: Whether you use GNNs or LLMs, graphs are better representations than text for
    model architecture because what’s important is the underlying computation. The
    API for TensorFlow and PyTorch is constantly changing, and the lines of code deal
    with more than just model architecture, such as general software engineering principles
    and resource infrastructure.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你使用 GNNs 还是 LLMs，图比文本更适合作为模型架构的表示，因为重要的是底层计算。TensorFlow 和 PyTorch 的 API 不断变化，代码行涉及的不仅仅是模型架构，还包括一般的软件工程原则和资源基础设施。
- en: 'There are several ways to represent model architectures as graphs, and here
    I review just a few categories. First, there are code machine learning compilers
    like [GLOW](https://github.com/pytorch/glow/blob/master/docs/IR.md), [MLIR](https://mlir.llvm.org/),
    and [Apache TVM](https://tvm.apache.org/). These can compile code like PyTorch
    code into intermediate representations that can take the form of a graph. TensorFlow
    already has an intermediate graph representation you can visualize with TensorBoard.
    There’s also an [ONNX](https://onnx.ai/) format which can be compiled from an
    existing saved model, e.g., using [HuggingFace](https://huggingface.co/docs/transformers/serialization),
    as easy as:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方式可以将模型架构表示为图，这里我仅回顾了几种类别。首先，有像 [GLOW](https://github.com/pytorch/glow/blob/master/docs/IR.md)、[MLIR](https://mlir.llvm.org/)
    和 [Apache TVM](https://tvm.apache.org/) 这样的代码机器学习编译器。这些可以将像 PyTorch 代码这样的代码编译成中间表示，形式可以是图。TensorFlow
    已经有一个中间图表示，你可以使用 TensorBoard 进行可视化。还有一个 [ONNX](https://onnx.ai/) 格式，可以从现有的保存模型编译而来，例如，使用
    [HuggingFace](https://huggingface.co/docs/transformers/serialization)，非常简单：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This ONNX graph serialized looks something like (small snippet):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 ONNX 图序列化看起来类似于（小片段）：
- en: '![](../Images/483a102cd859f6e1d8a5e1b992ee7645.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/483a102cd859f6e1d8a5e1b992ee7645.png)'
- en: Image by the author
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: One problem with these compiled intermediate representations is that they are
    difficult to understand at a high level. An ONNX graph of T5 in Netron, is immense.
    A more human-readable option for model architecture graphs is [Graphbook](https://github.com/cerbrec/graphbook).
    The free-to-use Graphbook platform can show you the [values being produced](https://medium.com/towards-artificial-intelligence/visual-walkthrough-for-vectorized-bertscore-to-evaluate-text-generation-b9ed61e6fdfe)
    by each operation in the graph and can show you where tensor shapes and types
    don’t match, plus it supports editing. In addition, the AI-generated model architectures
    may not be perfect, so having an easy way to go inside and edit the graph and
    troubleshoot why it doesn’t work is very useful.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ac99e40a0f439e8144486c08201ae95c.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
- en: Example view of Graphbook graph, Image by the author
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: While Graphbook models are just JSON, they are hierarchical and therefore allow
    better [levels of abstraction](https://medium.com/@drwiner/a-fully-visualized-and-honest-implementation-of-bert-9dbc066e7bd)
    for model layers. See below, a side view of the hierarchical structure of GPT2’s
    architecture.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8ebaf0205c6ea8f4237a52ea57400a3b.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
- en: 'Image showing the hierarchical structure of Graphbook graphs, with GPT as example
    here. Full image: [https://photos.app.goo.gl/rgJch8y94VN8jjZ5A](https://photos.app.goo.gl/rgJch8y94VN8jjZ5A),
    image by the author'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: MAD Steps
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is an outline for a proposal for generative MAD. I wanted to include these
    sub-steps to be more concrete about how one would approach the task.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '*Code-to-Graph*. Create a MAD dataset from code such as HuggingFace model card,
    converting the model to a graph format such as ONNX or Graphbook.'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Create datasets.* These would be datasets like classifying the operation type
    of an operation in the graph, classifying the graph itself, masking/recovering
    operations and links, detect when a graph is incomplete, convert an incomplete
    graph into a complete one, etc. These can be self-supervised.'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Graph-Tokenizer*. Tokenize the graph. For example, let each variable in the
    graph be a unique vocabulary ID and generate the adjacency matrix that can feed
    into a GNN layers.'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*GNN design.* Develop a GNN that uses the graph tokenizer output to feed through
    transformer layers.'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Train and Test*. Test the GNN on the datasets, and iterate.'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once these steps are fleshed out, they could be used as part of a NAS approach
    to help guide the design of the GNN (step 4).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'Final Note: Implication of Self-Improvement'
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/0ddc40735a5f09eb1752ec0fd4ef435e.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: I want to give some notes about the implications of autonomous MAD. The implications
    of AI being able to design model architectures is that it can improve the structure
    of its own brain. With some kind chain/graph of thought process, the model could
    iteratively generate successor states for its own architecture and test them out.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: Initially, AI has given model architecture, is trained on specific data for
    generating model architectures, and can be prompted to generate architectures.
    It has access to the training source which includes its own architecture design,
    and the training sources include a variety of tests around architecture tasks
    like graph classification, operation/node classification, link-completion, etc.
    These follow general tasks you find in the [Open Graph Benchmark](https://ogb.stanford.edu/).
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initially, at the application-level there is some kind of agent that can train
    and tests model architectures and add these to the AI’s training source, and perhaps
    it can prompt the AI with some kind of instructions about what works and what
    doesn’t work.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Iteratively, the AI generates a set of new model architectures, and agent (let’s
    call it MAD-agent) trains and tests them, gives them a score, adds these to the
    training source, directs the model to retrain itself, and so on.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In essence, instead of only using AutoML/NAS to search the space of model architectures,
    learn model architectures as graphs and then use graph transformers to learn and
    generate. Let the graph-based dataset itself be a model architecture represented
    as graphs. The model architectures representing graph datasets **and** the space
    of possible model architectures for learning graph datasets become the same.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: What’s the implication? Whenever a system has the capability of improving itself,
    there’s some potential risk to having a runaway effect. If one designed the above
    AND it was designed in the context of a more complex agent, one where the agent
    could indefinitely pick data sources and tasks and coordinate itself into becoming
    a multi-trillion parameter end-to-end deep learning system, then perhaps there
    is some risk. But the unsaid difficult part is the design of a more complex agent,
    resource allocation, as well as the many difficulties in supporting the wider
    set of capabilities.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AI techniques in autonomous AI model architecture design (MAD) may help AI researchers
    in the future discover new breakthrough techniques. Historically, MAD has been
    approached through neural architecture search (NAS). In conjunction with generative
    AI and transformers, there could be new opportunities to aid researchers and make
    discoveries.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
