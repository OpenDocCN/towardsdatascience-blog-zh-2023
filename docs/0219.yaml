- en: First Steps in the World Of Reinforcement Learning using Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/first-steps-in-the-world-of-reinforcement-learning-using-python-b843b76538e3?source=collection_archive---------6-----------------------#2023-01-13](https://towardsdatascience.com/first-steps-in-the-world-of-reinforcement-learning-using-python-b843b76538e3?source=collection_archive---------6-----------------------#2023-01-13)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Original Python implementation of how to find the best places to be in one of
    the fundamental worlds of reinforcement learning — the grid world
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://eligijus-bujokas.medium.com/?source=post_page-----b843b76538e3--------------------------------)[![Eligijus
    Bujokas](../Images/061fd30136caea2ba927140e8b3fae3c.png)](https://eligijus-bujokas.medium.com/?source=post_page-----b843b76538e3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b843b76538e3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b843b76538e3--------------------------------)
    [Eligijus Bujokas](https://eligijus-bujokas.medium.com/?source=post_page-----b843b76538e3--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd61597e07b4d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffirst-steps-in-the-world-of-reinforcement-learning-using-python-b843b76538e3&user=Eligijus+Bujokas&userId=d61597e07b4d&source=post_page-d61597e07b4d----b843b76538e3---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b843b76538e3--------------------------------)
    ·15 min read·Jan 13, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb843b76538e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffirst-steps-in-the-world-of-reinforcement-learning-using-python-b843b76538e3&user=Eligijus+Bujokas&userId=d61597e07b4d&source=-----b843b76538e3---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb843b76538e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffirst-steps-in-the-world-of-reinforcement-learning-using-python-b843b76538e3&source=-----b843b76538e3---------------------bookmark_footer-----------)![](../Images/b476cbb9f0b2f5a0f39114a7b0ebca24.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Gridworld matrices; Photo by author
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of this article is to present fundamental concepts and definitions
    in Reinforcement Learning (from here on — **RL**) using Python code and comments.
  prefs: []
  type: TYPE_NORMAL
- en: 'The article was heavily inspired by the great RL course: [https://www.coursera.org/learn/fundamentals-of-reinforcement-learning](https://www.coursera.org/learn/fundamentals-of-reinforcement-learning)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The theory is laid out in the book¹: [http://www.incompleteideas.net/book/RLbook2020.pdf](http://www.incompleteideas.net/book/RLbook2020.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for all my RL experiments can be seen in my Gitlab repo: [https://github.com/Eligijus112/rl-snake-game](https://github.com/Eligijus112/rl-snake-game)'
  prefs: []
  type: TYPE_NORMAL
- en: The grid world problem is a classic problem in RL where we want to create an
    optimal strategy for an agent to traverse a grid.
  prefs: []
  type: TYPE_NORMAL
- en: A grid is a square matrix of cells, and the agent can move in any of the four
    directions (up, down, left, right) in each cell. The agent receives a reward of
    -1 for each step it takes, and a reward of +10 if it reaches the goal cell. The
    numbers for the rewards are arbitrary and can be defined by the user.
  prefs: []
  type: TYPE_NORMAL
