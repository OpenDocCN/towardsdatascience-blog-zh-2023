- en: Advanced Prompt Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/advanced-prompt-engineering-f07f9e55fe01?source=collection_archive---------0-----------------------#2023-08-07](https://towardsdatascience.com/advanced-prompt-engineering-f07f9e55fe01?source=collection_archive---------0-----------------------#2023-08-07)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What to do when few-shot learning isn’t enough…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://wolfecameron.medium.com/?source=post_page-----f07f9e55fe01--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----f07f9e55fe01--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f07f9e55fe01--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f07f9e55fe01--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----f07f9e55fe01--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F28aa6026c553&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-prompt-engineering-f07f9e55fe01&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=post_page-28aa6026c553----f07f9e55fe01---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f07f9e55fe01--------------------------------)
    ·17 min read·Aug 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff07f9e55fe01&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-prompt-engineering-f07f9e55fe01&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=-----f07f9e55fe01---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff07f9e55fe01&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-prompt-engineering-f07f9e55fe01&source=-----f07f9e55fe01---------------------bookmark_footer-----------)![](../Images/c81386dd2900922e3779e5a589170682.png)'
  prefs: []
  type: TYPE_NORMAL
- en: (Photo by [Mike Tinnion](https://unsplash.com/@m15ky?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/3ym6i13Y9LU?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText))
  prefs: []
  type: TYPE_NORMAL
- en: The popularization of large language models (LLMs) has completely shifted how
    we solve problems as humans. In prior years, solving any task (e.g., reformatting
    a document or classifying a sentence) with a computer would require a program
    (i.e., a set of commands precisely written according to some programming language)
    to be created. With LLMs, solving such problems requires no more than a textual
    prompt. For example, we can prompt an LLM to reformat any document via a prompt
    similar to the one shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f0e2c7c36f265458b3c1eaa3d0a17396.png)'
  prefs: []
  type: TYPE_IMG
- en: Using prompting to reformat an XML document (created by author)
  prefs: []
  type: TYPE_NORMAL
- en: As demonstrated in the example above, the generic text-to-text format of LLMs
    makes it easy for us to solve a wide variety of problems. We first saw a glimpse
    of this potential with the proposal of [GPT-3](https://cameronrwolfe.substack.com/p/language-model-scaling-laws-and-gpt)
    [18], showing that sufficiently-large language models can use [few-shot learning](https://cameronrwolfe.substack.com/i/117151147/few-shot-learning)
    to solve many tasks with surprising accuracy. However, as the research surrounding
    LLMs progressed, we began to move beyond these basic (but still very effective!)
    prompting techniques like zero/few-shot learning.
  prefs: []
  type: TYPE_NORMAL
- en: '[Instruction-following LLMs](https://cameronrwolfe.substack.com/i/117151147/instruction-prompting)
    (e.g., [InstructGPT](https://cameronrwolfe.substack.com/i/93578656/training-language-models-to-follow-instructions-with-human-feedback)
    and [ChatGPT](https://openai.com/blog/chatgpt)) led us to explore whether language
    models could…'
  prefs: []
  type: TYPE_NORMAL
