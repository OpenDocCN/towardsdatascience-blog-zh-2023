- en: Exposing the Power of the Kalman Filter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/exposing-the-power-of-the-kalman-filter-1b78621c3f56?source=collection_archive---------0-----------------------#2023-11-07](https://towardsdatascience.com/exposing-the-power-of-the-kalman-filter-1b78621c3f56?source=collection_archive---------0-----------------------#2023-11-07)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@jceweaver?source=post_page-----1b78621c3f56--------------------------------)[![Jimmy
    Weaver](../Images/2d487e7ee2f13bd3381aad718bafde69.png)](https://medium.com/@jceweaver?source=post_page-----1b78621c3f56--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1b78621c3f56--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1b78621c3f56--------------------------------)
    [Jimmy Weaver](https://medium.com/@jceweaver?source=post_page-----1b78621c3f56--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F73e4cc6810b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexposing-the-power-of-the-kalman-filter-1b78621c3f56&user=Jimmy+Weaver&userId=73e4cc6810b7&source=post_page-73e4cc6810b7----1b78621c3f56---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1b78621c3f56--------------------------------)
    ·17 min read·Nov 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1b78621c3f56&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexposing-the-power-of-the-kalman-filter-1b78621c3f56&user=Jimmy+Weaver&userId=73e4cc6810b7&source=-----1b78621c3f56---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1b78621c3f56&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexposing-the-power-of-the-kalman-filter-1b78621c3f56&source=-----1b78621c3f56---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: 'As a data scientist we are occasionally faced with situations where we need
    to model a trend to predict future values. Whilst there is a temptation to focus
    on statistical or machine learning based algorithms, I am here to present a different
    option: the Kalman Filter (KF).'
  prefs: []
  type: TYPE_NORMAL
- en: In the early 1960’s Rudolf E. Kalman revolutionised how complex systems can
    be modelled with the KF. From guiding aircrafts or spacecrafts to their destination
    to allowing you smartphone to find its place in this world, this algorithm blends
    data and mathematics to provide estimates of future states with incredible accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: In this blog we will go in-depth to cover how the Kalman Filter works, showing
    examples in Python that will emphasise the true power of this technique. Starting
    with a simple 2D example, we will see how we can modify the code to adapt it to
    more advanced 4D spaces and end by covering the Extended Kalman Filter (the sophisticated
    successor). Join me on this journey as we embark through the world of predictive
    algorithms and filters.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d1ccd4d9a5ad02bbe5bd97e1b3a01a1e.png)'
  prefs: []
  type: TYPE_IMG
- en: The basics of a Kalman filter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The KF provides an estimate of the state of a system by building and continuously
    updating a set of covariance matrices (representing the statistical distribution
    of noise and past states) collected from observations and other measurements in
    time. Unlike other out-of-the-box algorithms, it is possible to directly expand
    and refine the solution by defining the mathematical relationships between the
    system and external sources. Whilst this might sound quite complex and intricate,
    the process can be summarised down to two steps: predict and update. These phases
    work together to iteratively correct and refine the state estimates of the system.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Predict step:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'This phase is all about forecasting the next future state of the system based
    on the model’s known posteriori estimates and step in time of Δk. Mathematically
    we represent the estimates of the state space as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9a7f6bf3298a7acb84f1e3c0e8795dfd.png)'
  prefs: []
  type: TYPE_IMG
- en: where, F, our state transition matrix models how the states evolve one step
    to another irrespective of the control input and process noise. Our matrix B models
    the control input, uₖ, impact on the state.
  prefs: []
  type: TYPE_NORMAL
- en: Alongside our estimates of the next state, the algorithm also calculates the
    uncertainty of the estimate represented by the covariance matrix *P:*
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e04d6ab7ffdba757c20d1fa18b3ef9e0.png)'
  prefs: []
  type: TYPE_IMG
- en: The predicted state covariance matrix represents the confidence and accuracy
    of our predictions, influenced by *Q* the process noise covariance matrix from
    the system itself. We apply this matrix to subsiquent equations in the update
    step to correct the information the Kalman Filter holds on the system, subsiquently
    improving future state estimates.
  prefs: []
  type: TYPE_NORMAL
- en: '**Update step:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the update step the algorithm performs updates to the Kalman Gain, State
    estimates and the Covariance matrix. The Kalman Gain determines how much influence
    a new measurement should have on the state estimates. The calculation includes
    the observation model matrix, *H*, which relates the state to the measurement
    we expect to receive, and *R* the measurement noise covariance matrix of errors
    in the measurments:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/18ebee0a5cd3c232bf647cd6be1c1c24.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In essence, *K* attempts to balance uncertainty in the predictions with that
    present in the measurements. As mentioned above, the Kalman Gain is applied to
    correct the state estimates and covariance, as presented by the following equations
    respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fa3017a9e34edaabecfcd4e9f21522e6.png)![](../Images/552552eb1816dcfd5e27ff4b7972bc05.png)'
  prefs: []
  type: TYPE_IMG
- en: where the calculation in the brackets for the state estimate is the residual,
    the difference between the actual measurement and that which the model predicted.
  prefs: []
  type: TYPE_NORMAL
- en: The true beauty of how a Kalman Filter works lies in its recursive nature, continuously
    updating both the state and covariance as new information is received. This allows
    the model to refine in a statistically optimal way over time which is particularly
    powerful approach to modelling systems that receive a stream of noisy observations.
  prefs: []
  type: TYPE_NORMAL
- en: The Kalman filter in action
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is possible to become quite overwhelmed by the equations that underpin the
    Kalman Filter, and to fully appreciate how it works from the mathematics alone
    would require an understanding of state space (out of the scope of this blog),
    but I will try to bring it to life with some Python examples. In it’s simplest
    form, we can define a Kalman Filter object as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use the `predict()` and `update()` functions to iterate through the
    steps outlined earlier. The above design of the filter will work for any time-series,
    and to show how our estimates compare to actuals let’s construct a simple example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/87f0b50ac60ff388549717a1f08dec03.png)'
  prefs: []
  type: TYPE_IMG
- en: In reality the ‘True Position’ would be unknown but we will plot it here for
    reference, the ‘Noisy Measurements’ are the observation points that are fed into
    our Kalman Filter. We will perform a very basic instantiation of the matrices,
    and to some degree it does not matter as the Kalman model will converge quickly
    through application of the Kalman Gain, but it might be reasonable under certain
    circumstances to perform a warm start to the model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/0179b2da7519157326636eee6d960e5b.png)'
  prefs: []
  type: TYPE_IMG
- en: Even with this very simple design of a solution, the model does an okay job
    piercing through the noise to find the true position. This might work okay for
    simple applications but often trends are more nuanced and impacted by external
    events. To handle this we typically need to modify both the state space representation
    but also the way we calculate estimates and correct the covariance matrix when
    new information arrives, let’s explore this more with another example
  prefs: []
  type: TYPE_NORMAL
- en: Tracking a moving object in 4D
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s assume we want to track the movement of an object in space and time, and
    to make this example even more realistic we will simulate some force acting upon
    it resulting in angular rotation. To show the adaptability of this algorithm to
    higher dimensional state space representations we will assume a linear force,
    although in actuality this will not be the case (we will explore a more realistic
    example after this). The below code shows an example of how we would modify our
    Kalman Filter for this particular scenario.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/1ac7158c6251fb32c7f652c45560b60a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A few interesting point to note here, in the graph above we can see how the
    model quickly corrects to the estimated true state as we start iterating over
    the observations. The model also performs reasonably well at identifying the true
    state of the system, with estimations intersecting with the true states (‘true
    trajectory’). This design might be appropriate for some real world applications
    but not for those where the force acting upon the system is nonlinear. Instead
    we need to consider a different application of the Kalman Filter: the Extended
    Kalman Filter, a predecessor to what we have explored until now that linearises
    nonlinearity of the incoming observations.'
  prefs: []
  type: TYPE_NORMAL
- en: The Extended Kalman Filter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When attempting to model a system where either the observations or dynamics
    of the system are nonlinear we need to apply the Extended Kalman Filter (EKF).
    This algorithm differs to the last by incorporating the Jacobian matrix into the
    solution and performing Taylor series expansion to find first-order linear approximations
    of the state transition and observation models. To express this extension mathematically,
    our key algorithmic calculations now become:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7ccf117c6488b728a44c7b4a040ee626.png)'
  prefs: []
  type: TYPE_IMG
- en: for the state prediction, where f is our nonlinear state transition function
    applied to the previous state estimate and *u* the control input at the previous
    time step.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c853abcf286fbd043a6ebbdd14bc8b13.png)'
  prefs: []
  type: TYPE_IMG
- en: for the error covariance prediction, where *F* is the Jacobian of the state
    transition function with respect to *P* the previous error covariance and *Q*
    the process noise covariance matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/135aebaac8c834b514a18c65471cdc8e.png)'
  prefs: []
  type: TYPE_IMG
- en: the observation of our measurement, *z*, at time step *k*, where *h* is the
    nonlinear observation function applied to our state prediction with some additive
    observation noise *v*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0831f568a757d076c6c693b526c38a5f.png)'
  prefs: []
  type: TYPE_IMG
- en: our update to the Kalman Gain calculation, with *H* the Jacobian of the observation
    function with respect to the state and *R* the measurement noise covariance matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/20e6763fa200c70bb52fd743bbb7dd89.png)'
  prefs: []
  type: TYPE_IMG
- en: 'the modified calculation for the state estimate that incorporates the kalman
    gain and the nonlinear observation function, and finally our equation to update
    the error covariance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c3b5e9ccdbfdb86511a1385d1685376c.png)'
  prefs: []
  type: TYPE_IMG
- en: In the last example this will use the Jocabian to linearise the non-linear affect
    of angular rotation on our object, modifying the code appropriately. Designing
    an EKF is more challenged than the KF as we our assumption of first-order linear
    approximations may inadvertently introduce errors into our state estimates. In
    addition, the Jacobian calculation can become complex, computationally expensive
    and difficult to define for certain situations which may also lead to errors.
    However, if designed correctly, the EKF will often outperform the KF implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Building on our last Python example I have presented the implementation of
    the EKF:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b08887b58202e09f5d2f1fb8e33e2df7.png)'
  prefs: []
  type: TYPE_IMG
- en: A simple summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this blog we have explored in depth how to build and apply a Kalman Filter
    (KF), as well as covering how to implement an Extended Kalman Filter (EKF). Let’s
    end by summarising the use cases, advantages and disadvantages of these models.
  prefs: []
  type: TYPE_NORMAL
- en: '**KF:** This model is applicable to linear systems, where we can assume that
    the state transitions and obeservation matrices are linear functions of the state
    (with some gaussian noise). You might consider applying this algorithm for:'
  prefs: []
  type: TYPE_NORMAL
- en: tracking the position and velocity of an object moving at a constant speed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: signal processing applications if the noise is stochastic or can be represented
    by linear models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: economic forecasting if the underlining relationships can be modelled linearly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The key advantage for the KF is that (once you follow the matrix calculations)
    the algorithm is quite simple, computationally less intensive than other approaches
    and can provide very accurate forecasts and estimations of the true state of the
    system in time. The disadvantage is the assumption of linearity which typically
    does not hold true in complex real-world scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: '**EKF:** We can essentially consider the EKF as the nonlinear equivalent of
    the KF, supported by the use of the Jacobian. You would consider the EKF if you
    are dealing with:'
  prefs: []
  type: TYPE_NORMAL
- en: robotic systems where the measurement and system dynamics are typically nonlinear
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: tracking and navigation systems that often involve non-constant velocities or
    changes in angular rate such as that from tracking aircrafts or spacecrafts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: automotive systems when implementing cruise control or lane-keeping that is
    found in the most modern ‘smart’ cars.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The EKF often produces better estimates that the KF, in particular for nonlinear
    systems, however it can become far more computationally intensive due to the calculation
    of the Jacobian matrix. This approach also relies on first-order linear approximations
    from the Taylor series expansion, which might not be an appropriate assumption
    for highly nonlinear systems. The addition of the Jacobian can also make the model
    more challenging to design and as such despite its advantages it may be more appropriate
    to implement the KF for simplicity and interoperability.
  prefs: []
  type: TYPE_NORMAL
- en: '*Unless otherwise noted, all images are by the author.*'
  prefs: []
  type: TYPE_NORMAL
