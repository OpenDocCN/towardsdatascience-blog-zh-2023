- en: How to Build a Multi-GPU System for Deep Learning in 2023
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何在 2023 年构建多 GPU 系统进行深度学习
- en: 原文：[https://towardsdatascience.com/how-to-build-a-multi-gpu-system-for-deep-learning-in-2023-e5bbb905d935?source=collection_archive---------0-----------------------#2023-09-16](https://towardsdatascience.com/how-to-build-a-multi-gpu-system-for-deep-learning-in-2023-e5bbb905d935?source=collection_archive---------0-----------------------#2023-09-16)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-build-a-multi-gpu-system-for-deep-learning-in-2023-e5bbb905d935?source=collection_archive---------0-----------------------#2023-09-16](https://towardsdatascience.com/how-to-build-a-multi-gpu-system-for-deep-learning-in-2023-e5bbb905d935?source=collection_archive---------0-----------------------#2023-09-16)
- en: '[](https://benuix.medium.com/?source=post_page-----e5bbb905d935--------------------------------)[![Antonis
    Makropoulos](../Images/5bdd3826eeb31dfb6d8e6fc393b24d8b.png)](https://benuix.medium.com/?source=post_page-----e5bbb905d935--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e5bbb905d935--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e5bbb905d935--------------------------------)
    [Antonis Makropoulos](https://benuix.medium.com/?source=post_page-----e5bbb905d935--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://benuix.medium.com/?source=post_page-----e5bbb905d935--------------------------------)[![Antonis
    Makropoulos](../Images/5bdd3826eeb31dfb6d8e6fc393b24d8b.png)](https://benuix.medium.com/?source=post_page-----e5bbb905d935--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e5bbb905d935--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e5bbb905d935--------------------------------)
    [Antonis Makropoulos](https://benuix.medium.com/?source=post_page-----e5bbb905d935--------------------------------)'
- en: ·
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F866c99d649d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-multi-gpu-system-for-deep-learning-in-2023-e5bbb905d935&user=Antonis+Makropoulos&userId=866c99d649d0&source=post_page-866c99d649d0----e5bbb905d935---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e5bbb905d935--------------------------------)
    ·10 min read·Sep 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe5bbb905d935&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-multi-gpu-system-for-deep-learning-in-2023-e5bbb905d935&user=Antonis+Makropoulos&userId=866c99d649d0&source=-----e5bbb905d935---------------------clap_footer-----------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F866c99d649d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-multi-gpu-system-for-deep-learning-in-2023-e5bbb905d935&user=Antonis+Makropoulos&userId=866c99d649d0&source=post_page-866c99d649d0----e5bbb905d935---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e5bbb905d935--------------------------------)
    ·10 min read·2023年9月16日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe5bbb905d935&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-multi-gpu-system-for-deep-learning-in-2023-e5bbb905d935&user=Antonis+Makropoulos&userId=866c99d649d0&source=-----e5bbb905d935---------------------clap_footer-----------)'
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe5bbb905d935&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-multi-gpu-system-for-deep-learning-in-2023-e5bbb905d935&source=-----e5bbb905d935---------------------bookmark_footer-----------)![](../Images/4bd3724494a1436a98b96b853132d183.png)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe5bbb905d935&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-multi-gpu-system-for-deep-learning-in-2023-e5bbb905d935&source=-----e5bbb905d935---------------------bookmark_footer-----------)![](../Images/4bd3724494a1436a98b96b853132d183.png)'
- en: My deep learning build — always work in progress :).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我的深度学习搭建——始终在进行中 :).
- en: This story provides a guide on how to build a multi-GPU system for deep learning
    and hopefully save you some research time and experimentation.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提供了如何构建多 GPU 系统进行深度学习的指南，希望能节省你的研究时间和实验。
- en: Target
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标
- en: Build a multi-GPU system for training of computer vision and LLMs models without
    breaking the bank! *🏦*
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 构建一个多 GPU 系统，用于计算机视觉和 LLMs 模型的训练，而不会破坏预算！ *🏦*
- en: Step 1\. GPUs
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一步\. GPU
- en: Let’s start with the fun (and expensive 💸💸💸) part!
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从有趣（和昂贵的 💸💸💸）部分开始吧！
- en: '![](../Images/24f9a6334f3f16d591f251fdff672c5f.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/24f9a6334f3f16d591f251fdff672c5f.png)'
- en: The H100 beast! Image from [NVIDIA](https://developer.nvidia.com/blog/nvidia-hopper-architecture-in-depth/).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: H100 怪兽！图片来自 [NVIDIA](https://developer.nvidia.com/blog/nvidia-hopper-architecture-in-depth/)。
- en: 'The main considerations when buying a GPU are:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 购买 GPU 时的主要考虑因素是：
- en: memory (VRAM)
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存（VRAM）
- en: performance (Tensor cores, clock speed)
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能（张量核心，时钟速度）
- en: slot width
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 插槽宽度
- en: power (TDP)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 功率（TDP）
- en: Memory
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内存
- en: For deep learning tasks nowadays we need a loooot of memory. LLMs are huge even
    to fine-tune and computer vision tasks can get memory-intensive especially with
    3D networks. Naturally the most important aspect to look for is the GPU **VRAM**.
    For LLMs I recommend at least 24 GB memory and for computer vision tasks I wouldn’t
    go below 12 GB.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在深度学习任务需要大量内存。即使是微调LLMs也很庞大，而计算机视觉任务，特别是3D网络，也可能变得内存密集。自然，最重要的方面是GPU的**VRAM**。对于LLMs，我建议至少24
    GB内存，对于计算机视觉任务，我建议不低于12 GB。
- en: Performance
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能
- en: 'The second criterion is performance which can be estimated with FLOPS (Floating-point
    Operations per Second):'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个标准是性能，可以通过FLOPS（每秒浮点运算）来估算：
- en: '![](../Images/8ffc752fed94dc4a6083ed15312f4173.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8ffc752fed94dc4a6083ed15312f4173.png)'
- en: The crucial number in the past was the number of CUDA cores in the circuit.
    However, with the emergence of deep learning, NVIDIA has introduced specialized
    **tensor cores** that can perform many more FMA (Fused Multiply-Add) operations
    per clock. These are already supported by the main deep learning frameworks and
    are what you should look for in 2023.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 过去的关键数字是电路中的CUDA核心数量。然而，随着深度学习的兴起，NVIDIA推出了专门的**张量核心**，每时钟周期可以执行更多的FMA（融合加法）操作。这些已经被主要深度学习框架支持，2023年您应该关注这些。
- en: 'Below you can find a chart of raw performance of GPUs grouped by memory that
    I compiled after quite some manual work:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我在经过大量手动工作后编制的按内存分组的GPU原始性能图表：
- en: '![](../Images/f43767df7f7dec9bff9c18fc1abdeb8b.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f43767df7f7dec9bff9c18fc1abdeb8b.png)'
- en: Raw performance of GPUs based on the CUDA and tensor cores (TFLOPs).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 基于CUDA和张量核心（TFLOPs）的GPU原始性能。
- en: Note that you have to be *extra careful* when comparing performance of different
    GPUs. Tensor cores of different generations / architectures are not comparable.
    For instance, the A100 performs 256 FP16 FMA operations / clock while the V100
    “only” 64\. Additionally, older architectures (Turing, Volta) do not support 32-bit
    tensor operations. What makes the comparison more difficult is that NVIDIA doesn’t
    always report the FMA, not even in the whitepapers, and GPUs of the same architecture
    can have different FMAs. I kept banging my head with [this](https://forums.developer.nvidia.com/t/tf32-tflops-of-geforce-rtx-3090-vs-a40/265828)
    😵‍💫. Also note that NVIDIA often advertises the tensor FLOPS with sparsity which
    is a feature usable only at inference time.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 注意在比较不同GPU的性能时必须*格外小心*。不同代/架构的Tensor核心不可比。例如，A100每时钟周期执行256 FP16 FMA操作，而V100“仅”执行64个。此外，较旧的架构（Turing,
    Volta）不支持32位张量操作。更难比较的是NVIDIA并不总是报告FMA，甚至在白皮书中也没有，且相同架构的GPU可能有不同的FMA。我一直在[这个](https://forums.developer.nvidia.com/t/tf32-tflops-of-geforce-rtx-3090-vs-a40/265828)上碰壁😵‍💫。还要注意，NVIDIA通常用稀疏性来宣传张量FLOPS，而这一特性仅在推理时可用。
- en: 'In order to identify the best GPU with respect to price, I collected the ebay
    prices using the ebay API and computed the relative performance per dollar (USD)
    for new cards:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了识别性价比最高的GPU，我使用eBay API收集了eBay价格，并计算了新卡的每美元相对性能：
- en: '![](../Images/f37be6f51d3986e0438c27fffaafd20f.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f37be6f51d3986e0438c27fffaafd20f.png)'
- en: Relative performance per USD of GPUs based on the CUDA and tensor cores (TFLOPs
    / USD). Prices are based on current ebay prices (September 2023).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 基于CUDA和张量核心（TFLOPs / USD）的GPU相对性能。价格基于当前eBay价格（2023年9月）。
- en: I did the same for used cards but since the rankings don’t change too much I
    omit the plot.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我对二手卡做了相同的处理，但由于排名变化不大，所以省略了图表。
- en: 'To select the best GPU for your budget, you can pick one of the top GPUs for
    the largest memory you can afford. My recommendation would be:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了选择最适合您预算的GPU，您可以选择拥有最大内存的顶级GPU。我的推荐是：
- en: '![](../Images/97e05d42f4b815f70b2fe279adf077eb.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97e05d42f4b815f70b2fe279adf077eb.png)'
- en: Recommendation of GPUs for different budgets based on current ebay prices (September
    2023).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 根据当前eBay价格（2023年9月），不同预算的GPU推荐。
- en: If you want to dive into more technical aspects I advise to read Tim Dettmers’
    excellent guide on [Which GPU(s) to Get for Deep Learning](https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想深入了解更多技术细节，建议阅读Tim Dettmers的优秀指南[选择适合深度学习的GPU](https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/)。
- en: Slot width
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 插槽宽度
- en: 'When building a multi-GPU system, we need to plan how to physically fit the
    GPUs into a PC case. Since GPUs grow larger and larger, especially the gaming
    series, this becomes more of an issue. Consumer motherboards have up to 7 PCIe
    slots and PC cases are built around this setup. A 4090 can easily take up 4 slots
    depending on manufacturer, so you can see why this becomes an issue. Additionally
    we should leave at least 1 slot between GPUs that are not blower style or watercooled
    to avoid overheating. We have the following options:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建多GPU系统时，我们需要规划如何将GPU物理安装到PC机箱中。由于GPU越来越大，尤其是游戏系列，这成为了一个问题。消费级主板最多有7个PCIe插槽，PC机箱也围绕这个设置进行设计。一块4090根据制造商的不同，可能会占用4个插槽，因此你可以理解为什么这会成为问题。此外，我们应该在非风冷或水冷的GPU之间至少留出1个插槽，以避免过热。我们有以下选项：
- en: '**Watercooling**'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**水冷**'
- en: Watercooled variants will take up to 2 slots but they are more expensive. You
    can alternatively convert an air-cooled GPU but this will void the warranty. If
    you don’t get All-in-One (AIO) solutions you will need to build a custom watercooling
    loop. This is also true if you want to fit multiple watercooled GPUs since the
    AIO radiators may not fit in the case. Building your own loop is risky and I wouldn’t
    personally do it with expensive cards. I would only buy AIO solutions straight
    from the manufactures (risk averse 🙈).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 水冷变体将占用最多2个插槽，但它们价格更贵。你也可以将风冷GPU改装成水冷，但这会使保修失效。如果你不选择一体式（AIO）解决方案，你将需要构建自定义水冷系统。如果你想安装多个水冷GPU，这一点尤其重要，因为AIO散热器可能无法适配机箱。自行构建系统有风险，我个人不会在昂贵的显卡上尝试。我只会直接从制造商处购买AIO解决方案（风险规避
    🙈）。
- en: '**Aircooled 2–3 slot cards and PCIe risers**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**风冷2-3槽显卡和PCIe扩展卡**'
- en: In this scenario you interleave cards on PCIe slots and cards connected with
    PCIe riser cables. The PCIe riser cards can be placed somewhere inside the PC
    case or in the open air. In either case you should make sure the GPUs are secured
    (see also the section about PC cases).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，你可以将显卡交错地安装在PCIe插槽上，并通过PCIe扩展卡连接显卡。PCIe扩展卡可以放置在PC机箱内部的某个位置，或放在开放空气中。在任何情况下，你都应该确保GPU固定好（另见关于PC机箱的部分）。
- en: Power (TDP)
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 功率（TDP）
- en: Modern GPUs get more and more power hungry. For instance, A 4090 requires 450
    W while a H100 can get up to 700 W. Apart from the power bill, fitting three or
    more GPUs becomes an issue. This is especially true in the US that the power sockets
    can deliver up to around 1800w.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现代GPU的功耗越来越大。例如，一块4090需要450W，而H100可以达到700W。除了电费，安装三块或更多显卡也成为了一个问题。这在美国尤其如此，因为电源插座的最大功率约为1800w。
- en: 'A solution to this problem if you are getting close to the max power you can
    draw from your PSU / power socket is power-limiting. All you need to reduce the
    max power a GPU can draw is:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你接近电源/电源插座的最大功率，解决这个问题的一个方案是功率限制。要减少GPU可以吸取的最大功率，你只需：
- en: '[PRE0]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Power-limiting by 10-20% has been shown to reduce performance by less than 5%
    and keeps the cards cooler ([experiment by Puget Systems](https://www.pugetsystems.com/labs/hpc/NVIDIA-GPU-Power-Limit-vs-Performance-2296/?utm=)).
    Power-limiting four 3090s for instance by 20% will reduce their consumption to
    1120w and can easily fit in a 1600w PSU / 1800w socket (assuming 400w for the
    rest of the components).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将功率限制在10-20%之间，已被证明可以将性能降低不到5%，并且能使显卡保持更凉爽（[Puget Systems的实验](https://www.pugetsystems.com/labs/hpc/NVIDIA-GPU-Power-Limit-vs-Performance-2296/?utm=)）。例如，将四块3090显卡的功率限制为20%会将其功耗降低到1120w，并且可以轻松适配1600w的电源/1800w的插座（假设其余组件消耗400w）。
- en: Step 2\. Motherboard and CPU
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 步骤2\. 主板和CPU
- en: The next step of the build is to pick a motherboard that allows multiple GPUs.
    Here the main consideration is the PCIe lanes. We need at **minimum PCIe 3.0 slots
    with x8 lanes** each for each of the cards (see [Tim Dettmers’ post](https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/#PCIe_Lanes_and_Multi-GPU_Parallelism)).
    PCIe 4.0 or 5.0 are rarer and not needed for most deep learning usecases.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 构建的下一步是选择一个允许多个GPU的主板。在这里主要考虑的是PCIe通道。我们需要**每块显卡至少有PCIe 3.0 x8通道**（见[Tim Dettmers的帖子](https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/#PCIe_Lanes_and_Multi-GPU_Parallelism)）。PCIe
    4.0或5.0更为稀有，对于大多数深度学习用途并不必要。
- en: Apart from the slot type, the spacing of the slots will determine where you
    can place the GPUs. Make sure you have checked the spacing and that your GPUs
    can actually go where you want them to. Note that most motherboards will use x8
    configuration for some x16 slots when you use multiple GPUs. The only real way
    to get this information is on the manual of the card.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 除了插槽类型外，插槽的间距将决定你可以放置 GPU 的位置。确保你已经检查了间距，并且你的 GPU 确实可以放在你想要的位置。请注意，大多数主板在使用多个
    GPU 时会将一些 x16 插槽配置为 x8。获取这些信息的唯一可靠途径是查阅显卡的手册。
- en: 'The easiest way to not spend hours of research and also future-proof your system
    is to pick a motherboard that has x16 slots everywhere. You can use PCPartPicker
    and filter motherboards that have [7+ PCIe x16 slots](https://pcpartpicker.com/products/motherboard/#h=7,8&xcx=0).
    This gives us 21 products to choose from. We then [reduce the list](https://pcpartpicker.com/products/motherboard/#h=7,8&xcx=0&D=137438953472,2199023255552&mt=ddr4,ddr5)
    by selecting the minimum amount of RAM we want (e.g. 128 GB) with DDR4 / DDR5
    type to bring it down to 10 products:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的方法是避免花费数小时的研究，并使你的系统未来-proof，是选择一个到处都有 x16 插槽的主板。你可以使用 PCPartPicker 并筛选出具有
    [7+ PCIe x16 插槽](https://pcpartpicker.com/products/motherboard/#h=7,8&xcx=0) 的主板。这给我们提供了
    21 种产品选择。然后我们 [缩减列表](https://pcpartpicker.com/products/motherboard/#h=7,8&xcx=0&D=137438953472,2199023255552&mt=ddr4,ddr5)
    选择我们想要的最小 RAM 数量（例如 128 GB），并选择 DDR4 / DDR5 类型，将产品数量减少到 10 种：
- en: '![](../Images/69337ca759a3ca823c2e554bc1134b3a.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/69337ca759a3ca823c2e554bc1134b3a.png)'
- en: Motherboards with at least 7 PCIe x16 slots and 128 GB DDR4/DDR5 RAM based on
    [PCPartPicker](https://pcpartpicker.com/products/motherboard/#h=7,8&xcx=0&D=137438953472,2199023255552&mt=ddr4,ddr5).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 [PCPartPicker](https://pcpartpicker.com/products/motherboard/#h=7,8&xcx=0&D=137438953472,2199023255552&mt=ddr4,ddr5)
    的主板至少有 7 个 PCIe x16 插槽和 128 GB DDR4/DDR5 RAM。
- en: 'The supported CPU sockets of the above list are LGA2011–3 and LGA2066\. We
    then move to the CPU selection and select CPUs with the desired number of cores.
    These are mainly needed for data loading and batch preparation. Aim to have at
    least **2 cores / 4 threads per GPU**. For the CPU we should also check the PCIe
    lanes it supports. Any CPU of the last decade should support at least 40 lanes
    (covering 4 GPUs at x8 lanes) but better be safe than sorry. With a filtering
    of e.g. [16+ cores with the above sockets](https://pcpartpicker.com/products/cpu/#C=16,64&k=28,35&xcx=0)
    we get the following CPUs:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 上述列表中支持的 CPU 插槽是 LGA2011–3 和 LGA2066。接下来，我们转到 CPU 选择，选择具有所需核心数量的 CPU。这些主要用于数据加载和批处理准备。每个
    GPU 至少应有 **2 核心 / 4 线程**。对于 CPU，我们还应检查它支持的 PCIe 通道。过去十年的任何 CPU 应该至少支持 40 条通道（覆盖
    4 个 GPU，每个 GPU x8 通道），但最好还是谨慎为好。通过筛选例如 [具有上述插槽的 16+ 核 CPU](https://pcpartpicker.com/products/cpu/#C=16,64&k=28,35&xcx=0)，我们得到以下
    CPU：
- en: 'Intel Xeon E5 (LGA2011–3): 8 results'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Intel Xeon E5 (LGA2011–3)：8 个结果
- en: 'Intel Core i9 (LGA2066): 9 results'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Intel Core i9 (LGA2066)：9 个结果
- en: We then pick our favorite combination of motherboard and CPU based on the number
    of cores, availability and price.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们根据核心数量、可用性和价格选择我们喜欢的主板和 CPU 组合。
- en: Both LGA2011–3 and LGA2066 sockets are very old (2014 and 2017 respectively),
    and therefore you can find good deals on ebay for both the motherboard and CPU.
    An ASRock X99 WS-E motherboard and a 18-core Intel Xeon E5–2697 V4 can cost you
    less than 300$ in used condition. Don’t buy the cheaper ES or QS versions for
    CPUs as these are engineering samples and may fail ⚠️️.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: LGA2011–3 和 LGA2066 插槽都已经非常老旧（分别是 2014 年和 2017 年），因此你可以在 eBay 上找到这两个主板和 CPU
    的好交易。一块 ASRock X99 WS-E 主板和一颗 18 核的 Intel Xeon E5–2697 V4 在二手状态下可能花费不到 300 美元。不要购买便宜的
    ES 或 QS 版本的 CPU，因为这些是工程样品，可能会出现故障 ⚠️️。
- en: If you want to buy something more powerful and/or more recent and/or an AMD
    CPU you can look into motherboards with e.g. 4+ PCIe x16 slots but make sure you
    check the slot spacings.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想购买更强大和/或更新的组件和/或 AMD CPU，可以查看例如 4+ PCIe x16 插槽的主板，但确保检查插槽间距。
- en: At this stage it’s a good idea to start a [PCPartPicker build](https://pcpartpicker.com/list/).
    🛠️
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在这个阶段，开始一个 [PCPartPicker 构建](https://pcpartpicker.com/list/) 是个好主意。 🛠️
- en: PCPartPicker will check compatibilities between components for you and will
    make your life easier.
  id: totrans-62
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: PCPartPicker 会为你检查组件之间的兼容性，让你的生活更轻松。
- en: Step 3\. RAM 🐏
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 3 步。RAM 🐏
- en: 'Here the most important aspect is the amount of RAM. RAM is used in different
    places of the deep learning cycle: loading data from disk for batch creation,
    loading the model and of course prototyping. The amount needed depends a lot on
    your application (e.g. 3D image data will need much more additional RAM) but you
    should aim for 1x–2x the total amount of VRAM of your GPUs. The type should be
    at least DDR4 but the RAM clock is not very important, so don’t spend your money
    there 🕳️.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，最重要的方面是 RAM 的数量。RAM 在深度学习循环中的不同地方使用：从硬盘加载数据以创建批次、加载模型以及当然是原型设计。所需的 RAM 数量很大程度上取决于您的应用程序（例如，3D
    图像数据需要更多的额外 RAM），但您应该以 GPU VRAM 总量的 1 倍到 2 倍为目标。类型至少应为 DDR4，但 RAM 时钟不是非常重要，所以不要把钱花在这里
    🕳️。
- en: When buying RAM you should make sure that the form factor, type, number of modules
    and memory per module all agree with your motherboard specs (PCPartPicker is your
    friend!).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在购买 RAM 时，您应该确保其形状因素、类型、模块数量和每个模块的内存都与您的主板规格一致（PCPartPicker 是您的好帮手！）。
- en: Step 4\. Disks
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 4 步。硬盘
- en: Another component that you can save on is the disks 😌. Again the amount of disk
    space is important and depends on the application. You don’t necessarily need
    ultra-fast disks or NVMEs as they won’t affect your deep learning performance.
    The data will be anyway loaded to RAM and in order to not create a bottleneck
    you can simply use more parallel CPU workers.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个可以节省开支的组件是硬盘 😌。硬盘空间的大小很重要，并且取决于应用程序。您不一定需要超高速硬盘或 NVME，因为它们不会影响您的深度学习性能。数据最终会加载到
    RAM 中，为了避免成为瓶颈，您可以简单地使用更多的并行 CPU 工作线程。
- en: Step 5\. Power supply (PSU) 🔌
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 5 步。电源供应器 (PSU) 🔌
- en: As we saw GPUs are power-hungry components. When setting up a multi-GPU system,
    the selection of the PSU becomes an important consideration. The majority of PSUs
    can deliver up to 1600w — this is in line with the power limits of US sockets.
    There are a few PSUs that can deliver more than that but need some research and
    they target especially miners.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，GPU 是高功耗组件。在设置多 GPU 系统时，选择 PSU 成为一个重要的考虑因素。大多数 PSU 能提供高达 1600w 的功率 ——
    这符合美国插座的功率限制。有一些 PSU 可以提供更高的功率，但需要一些研究，并且它们特别针对矿工。
- en: '![](../Images/8fe334aa8016473809c613cf470581b1.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8fe334aa8016473809c613cf470581b1.png)'
- en: Estimated wattage provided by PCPartPicker for your builds.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: PCPartPicker 为您的构建提供的估算功率。
- en: To determine the wattage of your system, you can use again PCPartPicker that
    computes the total amount of your build. To this we need to add an extra 10%+
    for peace of mind since GPUs will have spikes of power more than what is on their
    specs.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 要确定系统的功率，您可以再次使用 PCPartPicker 来计算您构建的总功率。为了确保安全，我们需要额外增加10%以上的功率，因为 GPU 的实际功耗有时会超过其规格。
- en: An important criterion is the **PSU efficiency** that is marked with the 80
    PLUS rating. The supply will reach the wattage it advertises but will lose some
    power in the process. 80 PLUS Bronze supplies are rated with 82% efficiency vs
    e.g. a Gold that will reach 87% efficiency. If we have a system that draws 1600w
    and we use it 20% of the time, we would save 22$ per year with a GPU with Gold
    rating, assuming a cost of 0.16$ / KWh. When comparing prices take that into account
    in your calculations.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的标准是**PSU 效率**，这由 80 PLUS 评级标记。电源将达到其宣传的功率，但在过程中会损失一些功率。80 PLUS 铜牌电源的效率为
    82%，而例如金牌电源的效率为 87%。如果我们有一个功率需求为 1600w 的系统，并且我们在 20% 的时间内使用它，我们将节省 22 美元每年，前提是电价为
    0.16 美元/千瓦时。在比较价格时，请将这一点纳入您的计算中。
- en: '![](../Images/f2c585bf5a9b2f3468913cc0cb4d5159.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2c585bf5a9b2f3468913cc0cb4d5159.png)'
- en: PSU efficiency ratings. Table from [techguided](https://techguided.com/80-plus-bronze-vs-gold-vs-platinum-vs-titanium-which-psu-rating-do-you-need/).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: PSU 效率评级。表格来源于 [techguided](https://techguided.com/80-plus-bronze-vs-gold-vs-platinum-vs-titanium-which-psu-rating-do-you-need/)。
- en: When running at full load some PSUs are more **noisy** than others since they
    use a fan at high RPMs. If you are working (or sleeping!) close to your case this
    can have some effect, so it’s a good idea to check the decibels from the manual
    😵.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在满负荷运行时，一些 PSU 比其他的**噪音**更大，因为它们使用高速运转的风扇。如果您在靠近机箱的地方工作（或睡觉！），这可能会有一些影响，因此查看手册中的分贝数是个好主意
    😵。
- en: When selecting a supply, we need to verify that it has enough connectors for
    all our parts. GPUs in particular use 8 (or 6+2) pin cables. One important note
    here is that for each power slot of the GPU we should use **a separate 8 pin cable**
    and not use multiple outputs of the same cable (daisy-chaining). 8 pin cables
    are generally rated to ~150w. When using a single cable for more than one power
    slot the GPU may not get enough power and throttle.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择电源时，我们需要确认它是否有足够的连接器来支持所有部件。特别是 GPU 使用 8 针（或 6+2）电缆。这里有一个重要的提示：对于 GPU 的每个电源插槽，我们应该使用**单独的
    8 针电缆**，而不是使用同一根电缆的多个输出（串联连接）。8 针电缆通常额定功率约为 150w。当使用单根电缆为多个电源插槽供电时，GPU 可能无法获得足够的电力，从而导致降频。
- en: Step 6\. PC case
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 步骤 6\. 机箱
- en: Last but not least, selecting a PC case is not trivial. GPUs can get humongous
    and some cases will not fit them. A 4090 for instance can reach 36 cm length 👻!
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，选择一个 PC 机箱并不简单。GPU 可以非常庞大，一些机箱可能无法容纳它们。例如，4090 的长度可以达到 36 厘米 👻！
- en: On top of that, mounting GPUs with PCIe risers may require some hacks. There
    are some some newer cases that allow to mount an additional card, especially dual
    system cases like the Phanteks Enthoo 719\. Another option is the Lian-Li O11D
    EVO that can house a GPU in upright position with the Lian-Li Upright GPU Bracket.
    I don’t have these cases so I’m not sure how well they would fit e.g. multiple
    3090 / 4090\. However you can still mount a GPU upright even if your PC case doesn’t
    directly support it with the Lian-Li bracket. You will need to drill 2–3 holes
    to the case but is not crazy.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，使用 PCIe 延长条安装 GPU 可能需要一些技巧。有一些较新的机箱允许安装额外的显卡，特别是像 Phanteks Enthoo 719 这样的双系统机箱。另一个选择是
    Lian-Li O11D EVO，它可以通过 Lian-Li Upright GPU Bracket 以直立位置容纳 GPU。我没有这些机箱，所以不确定它们如何适配，例如多个
    3090 / 4090。然而，即使你的 PC 机箱不直接支持直立安装，你仍然可以使用 Lian-Li 支架来直立安装 GPU。你需要在机箱上钻 2-3 个孔，但并不是很复杂。
- en: '![](../Images/f678cf20bc13c76aa0594d1d51c3c98a.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f678cf20bc13c76aa0594d1d51c3c98a.png)'
- en: Mounting a GPU in an upright position with the Lian Li upright bracket.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Lian Li 直立支架将 GPU 安装在直立位置。
- en: The end
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结束
- en: I hope you enjoyed reading this guide and that you found some useful tips. The
    guide is aimed to help in your research on building a multi-GPU system, and not
    replace it. Feel free to send me any questions or comments you may have. If I
    am wrong on anything in the above I would really appreciate a comment or DM to
    make it even better 🙏!
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你喜欢阅读本指南，并且发现了一些有用的提示。本指南旨在帮助你研究如何构建多 GPU 系统，而不是替代研究。如果你有任何问题或意见，请随时发给我。如果我在上述内容中有任何错误，我非常感谢你留下评论或私信，以便进一步改进
    🙏！
- en: 'Note: Unless otherwise noted, all images are by the author.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：除非另有说明，所有图片均由作者提供。
