- en: Running SQL Queries in Jupyter Notebook using JupySQL, DuckDB, and MySQL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/running-sql-queries-in-jupyter-notebook-using-jupysql-duckdb-and-mysql-3c53fbe40f8d?source=collection_archive---------7-----------------------#2023-02-24](https://towardsdatascience.com/running-sql-queries-in-jupyter-notebook-using-jupysql-duckdb-and-mysql-3c53fbe40f8d?source=collection_archive---------7-----------------------#2023-02-24)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learn how to run SQL in your Jupyter Notebooks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://weimenglee.medium.com/?source=post_page-----3c53fbe40f8d--------------------------------)[![Wei-Meng
    Lee](../Images/10fc13e8a6858502d6a7b89fcaad7a10.png)](https://weimenglee.medium.com/?source=post_page-----3c53fbe40f8d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3c53fbe40f8d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3c53fbe40f8d--------------------------------)
    [Wei-Meng Lee](https://weimenglee.medium.com/?source=post_page-----3c53fbe40f8d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6599e1e08a48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frunning-sql-queries-in-jupyter-notebook-using-jupysql-duckdb-and-mysql-3c53fbe40f8d&user=Wei-Meng+Lee&userId=6599e1e08a48&source=post_page-6599e1e08a48----3c53fbe40f8d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3c53fbe40f8d--------------------------------)
    ·8 min read·Feb 24, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3c53fbe40f8d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frunning-sql-queries-in-jupyter-notebook-using-jupysql-duckdb-and-mysql-3c53fbe40f8d&user=Wei-Meng+Lee&userId=6599e1e08a48&source=-----3c53fbe40f8d---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3c53fbe40f8d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frunning-sql-queries-in-jupyter-notebook-using-jupysql-duckdb-and-mysql-3c53fbe40f8d&source=-----3c53fbe40f8d---------------------bookmark_footer-----------)![](../Images/243efc1d9e9a6b0829180fe106bd4934.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Wafer WAN](https://unsplash.com/@waferwan?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditionally, data scientists use Jupyter Notebook to pull data from database
    servers, or from external datasets (such as CSV, JSON files, etc) and store them
    into Pandas dataframes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/045e46113ac1e7638be1dcd0a1163924.png)'
  prefs: []
  type: TYPE_IMG
- en: All images by author unless otherwise stated
  prefs: []
  type: TYPE_NORMAL
- en: 'They then use the dataframes for visualization purposes. This approach has
    a couple of drawbacks:'
  prefs: []
  type: TYPE_NORMAL
- en: Querying a database server may degrade the performance of the database server,
    which may not be optimized for analytical workloads.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading the data into dataframes take up precious resources. For example, if
    the intention is to visualize certain aspects of the dataset, you need to first
    load the entire dataset into memory before visualization can be performed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To improve the performance of the above, ideally the processing of the data
    (all the data wrangling and filtering) should be offloaded to a client which is
    able to perform the data analytics efficiently, and return the result to be used
    for visualization. And this is the topic of this article — **JupySQL**.
  prefs: []
  type: TYPE_NORMAL
