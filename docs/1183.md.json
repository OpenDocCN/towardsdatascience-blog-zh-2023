["```py\nimport numpy as np\n\n#Generate some data\nnp.random.seed(1)\nx = np.linspace(0, 100, 1000)\nm = np.random.randint(0, 100)\nb = np.random.randint(-5000, 5000)\ny = m*x + b + np.random.randn(1000)*700\n```", "```py\ndef rmse(m, b):\n    '''\n    Consumes coeffiecients for our linear model and returns RMSE.\n\n    m (float): line slope\n    m (float): line intercept\n    y (np.array): ground truth for model prediction\n    '''\n    preds = m*x + b\n    return np.sqrt(((preds - y)**2).sum()/len(preds))\n```", "```py\nclass UniformDist:\n    '''\n    Class encapsulates behavior for a uniform distribution.\n    '''\n    def __init__(self, min_, max_):\n        '''\n        Initializes our distribution with provided bounds\n        '''\n        self.min = min_\n        self.max = max_\n\n    def sample(self, n_samples):\n        '''\n        Returns samples from our distribution\n        '''\n        return np.random.uniform(self.min, self.max, n_samples)\n```", "```py\n#Define hyperparameter search space\nsearch_space = {'m':UniformDist(10,100), 'b':UniformDist(-6000,-3000)}\n```", "```py\nimport pandas as pd\n\ndef sample_priors(space, n_samples):\n    '''\n    Consumes search space defined by priors and returns\n    n_samples.\n    '''\n    seed = np.array([space[hp].sample(n_samples) for hp in space])\n\n    #Calculate rmse for each slope intercept pair in the seed\n    seed_rmse = np.array([rmse(m, b) for m, b in seed.T]) \n\n    #Concatenate and convert to dataframe\n    data = np.stack([seed[0], seed[1], seed_rmse]).T\n    trials = pd.DataFrame(data, columns=['m', 'b', 'rmse'])\n\n    return trials\n```", "```py\nfrom sklearn.neighbors import KernelDensity\n\ndef segment_distributions(trials, gamma):\n    '''\n    Splits samples into l(x) and g(x) distributions based on our\n    quantile cutoff gamma (using rmse as criteria).\n\n    Returns a kerned density estimator (KDE) for l(x) and g(x), \n    respectively.\n    '''\n    cut = np.quantile(trials['rmse'], gamma)\n\n    l_x = trials[trials['rmse']<cut][['m','b']]\n    g_x = trials[~trials.isin(l_x)][['m','b']].dropna()\n\n    l_kde = KernelDensity(kernel='gaussian', bandwidth=5.0)\n    g_kde = KernelDensity(kernel='gaussian', bandwidth=5.0)\n\n    l_kde.fit(l_x)\n    g_kde.fit(g_x)\n\n    return l_kde, g_kde \n```", "```py\ndef choose_next_hps(l_kde, g_kde, n_samples):\n    '''\n    Consumes KDE's for l(x) and g(x), samples n_samples from \n    l(x) and evaluates each sample with respect to g(x)/l(x).\n    The sample which maximizes this quantity is returned as the\n    next set of hyperparameters to test.\n    '''\n    samples = l_kde.sample(n_samples)\n\n    l_score = l_kde.score_samples(samples)\n    g_score = g_kde.score_samples(samples)\n\n    hps = samples[np.argmax(g_score/l_score)]\n\n    return hps\n```", "```py\ndef tpe(space, n_seed, n_total, gamma):\n    '''\n    Consumes a hyperparameter search space, number of iterations for seeding\n    and total number of iterations and performs Bayesian Optimization. TPE\n    can be sensitive to choice of quantile cutoff, which we control with gamma.\n    '''\n\n    #Seed priors\n    trials = sample_priors(space, n_seed)\n\n    for i in range(n_seed, n_total):\n\n        #Segment trials into l and g distributions\n        l_kde, g_kde = segment_distributions(trials, gamma)\n\n        #Determine next pair of hyperparameters to test\n        hps = choose_next_hps(l_kde, g_kde, 100)\n\n        #Evaluate with rmse and add to trials\n        result = np.concatenate([hps, [rmse(hps[0], hps[1])]])\n\n        trials = trials.append(\n            {col:result[i] for i, col in enumerate(trials.columns)},\n            ignore_index=True\n        )\n\n    return trials\n```", "```py\n#Define hyperparameter search space\nnp.random.seed(1)\nsearch_space = {'m':UniformDist(10,100), 'b':UniformDist(-6000,-3000)}\n\ndf = tpe(search_space, \n         n_seed=30, \n         n_total=200, \n         gamma=.2)\n```"]