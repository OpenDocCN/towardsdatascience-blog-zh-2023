["```py\nMATCH (m:Movie)\nMATCH (m)-[r:ACTED_IN|DIRECTED]-(t)\nWITH m, type(r) as type, collect(t.name) as names\nWITH m, type+\": \"+reduce(s=\"\", n IN names | s + n + \", \") as types\nWITH m, collect(types) as contexts\nWITH m, \"Movie title: \"+ m.title + \" year: \"+coalesce(m.released,\"\") +\" plot: \"+ coalesce(m.tagline,\"\")+\"\\n\" +\n       reduce(s=\"\", c in contexts | s + substring(c, 0, size(c)-2) +\"\\n\") as context\nRETURN context LIMIT 1\n```", "```py\nMovie title: The Matrix year: 1999 plot: Welcome to the Real World\nACTED_IN: Emil Eifrem, Hugo Weaving, Laurence Fishburne, Carrie-Anne Moss, Keanu Reeves\nDIRECTED: Lana Wachowski, Lilly Wachowski\n```", "```py\nCALL apoc.periodic.iterate(\n  'MATCH (m:Movie) RETURN id(m) AS id',\n  'MATCH (m:Movie)\n   WHERE id(m) = id\n   MATCH (m)-[r:ACTED_IN|DIRECTED]-(t)\n   WITH m, type(r) as type, collect(t.name) as names\n   WITH m, type+\": \"+reduce(s=\"\", n IN names | s + n + \", \") as types\n   WITH m, collect(types) as contexts\n   WITH m, \"Movie title: \"+ m.title + \" year: \"+coalesce(m.released,\"\") +\" plot: \"+ coalesce(m.tagline,\"\")+\"\\n\" +\n        reduce(s=\"\", c in contexts | s + substring(c, 0, size(c)-2) +\"\\n\") as context\n   CALL apoc.ml.openai.embedding([context], $apiKey) YIELD embedding\n   SET m.embedding = embedding',\n  {batchSize:1, retries:3, params: {apiKey: $apiKey}})\n```", "```py\nsystem_prompt = \"\"\"\nYou are an assistant that helps to generate text to form nice and human understandable answers based.\nThe latest prompt contains the information, and you need to generate a human readable response based on the given information.\nMake the answer sound as a response to the question. Do not mention that you based the result on the given information.\nDo not add any additional information that is not explicitly provided in the latest prompt.\nI repeat, do not add any information that is not explicitly given.\n\"\"\"\n```", "```py\ndef generate_user_prompt(question, context):\n   return f\"\"\"\n   The question is {question}\n   Answer the question by using the provided information:\n   {context}\n   \"\"\"\n```", "```py\ndef retrieve_context(question, k=3):\n  data = run_query(\"\"\"\n    // retrieve the embedding of the question\n    CALL apoc.ml.openai.embedding([$question], $apiKey) YIELD embedding\n    // match relevant movies\n    MATCH (m:Movie)\n    WITH m, gds.similarity.cosine(embedding, m.embedding) AS score\n    ORDER BY score DESC\n    // limit the number of relevant documents\n    LIMIT toInteger($k)\n    // retrieve graph context\n    MATCH (m)--()--(m1:Movie)\n    WITH m,m1, count(*) AS count\n    ORDER BY count DESC\n    WITH m, apoc.text.join(collect(m1.title)[..3], \", \") AS similarMovies\n    MATCH (m)-[r:ACTED_IN|DIRECTED]-(t)\n    WITH m, similarMovies, type(r) as type, collect(t.name) as names\n    WITH m, similarMovies, type+\": \"+reduce(s=\"\", n IN names | s + n + \", \") as types\n    WITH m, similarMovies, collect(types) as contexts\n    WITH m, \"Movie title: \"+ m.title + \" year: \"+coalesce(m.released,\"\") +\" plot: \"+ coalesce(m.tagline,\"\")+\"\\n\" +\n          reduce(s=\"\", c in contexts | s + substring(c, 0, size(c)-2) +\"\\n\") + \"similar movies:\" + similarMovies + \"\\n\" as context\n    RETURN context\n  \"\"\", {'question': question, 'k': k, 'apiKey': openai_api_key})\n  return data['context'].to_list()\n```", "```py\ndef generate_answer(question):\n    # Retrieve context\n    context = retrieve_context(question)\n    # Print context\n    for c in context:\n        print(c)\n    # Generate answer\n    response = run_query(\n        \"\"\"\n  CALL apoc.ml.openai.chat([{role:'system', content: $system},\n                      {role: 'user', content: $user}], $apiKey) YIELD value\n  RETURN value.choices[0].message.content AS answer\n  \"\"\",\n        {\n            \"system\": system_prompt,\n            \"user\": generate_user_prompt(question, context),\n            \"apiKey\": openai_api_key,\n        },\n    )\n    return response[\"answer\"][0]\n```"]