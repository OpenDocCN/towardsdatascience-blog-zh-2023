- en: Generalized Advantage Estimation in Reinforcement Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/generalized-advantage-estimation-in-reinforcement-learning-bf4a957f7975?source=collection_archive---------14-----------------------#2023-03-27](https://towardsdatascience.com/generalized-advantage-estimation-in-reinforcement-learning-bf4a957f7975?source=collection_archive---------14-----------------------#2023-03-27)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Bias and Variance tradeoff in Policy Gradient
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://siwei-causevic.medium.com/?source=post_page-----bf4a957f7975--------------------------------)[![Siwei
    Causevic](../Images/bb8e4ec911272a8e381e94129eabe166.png)](https://siwei-causevic.medium.com/?source=post_page-----bf4a957f7975--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bf4a957f7975--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bf4a957f7975--------------------------------)
    [Siwei Causevic](https://siwei-causevic.medium.com/?source=post_page-----bf4a957f7975--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F301dc9114da0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeneralized-advantage-estimation-in-reinforcement-learning-bf4a957f7975&user=Siwei+Causevic&userId=301dc9114da0&source=post_page-301dc9114da0----bf4a957f7975---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bf4a957f7975--------------------------------)
    ·6 min read·Mar 27, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbf4a957f7975&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeneralized-advantage-estimation-in-reinforcement-learning-bf4a957f7975&user=Siwei+Causevic&userId=301dc9114da0&source=-----bf4a957f7975---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbf4a957f7975&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeneralized-advantage-estimation-in-reinforcement-learning-bf4a957f7975&source=-----bf4a957f7975---------------------bookmark_footer-----------)![](../Images/f6ba99d09255dd7c15926e13695c4125.png)'
  prefs: []
  type: TYPE_NORMAL
- en: photo by the author
  prefs: []
  type: TYPE_NORMAL
- en: Policy gradient methods are one of the most widely used learning algorithms
    in reinforcement learning. They aim to optimize a parameterized policy and use
    value functions to help estimate how the policy should be improved.
  prefs: []
  type: TYPE_NORMAL
- en: One of the major issues in reinforcement learning though, especially for policy
    gradient methods, is the long time delay between actions and their positive or
    negative effect on rewards, which makes reward estimation extremely difficult.
    That being said, RL researchers usually estimate the long term rewards(return)
    with either the bootstrapped rewards from episodes or the value function, and
    sometimes both. However, both methods have their drawbacks. The issue with the
    former is the high variance from the samples, and the latter is the high bias
    in the estimated value function.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we will go over Generalized Advantage Estimation(GAE), a family
    of policy gradient estimators that significantly reduce variance while maintaining
    a tolerable level of bias.
  prefs: []
  type: TYPE_NORMAL
- en: The content below assumes a basic understanding of the policy gradient methods.
    If you are new to reinforcement learning, check out my previous article on [RL
    basics and algorithm overview](/an-overview-of-classic-reinforcement-learning-algorithms-part-1-f79c8b87e5af),
    and a [deep dive into](https://medium.com/towards-data-science/policy-gradient-reinforce-algorithm-with-baseline-e95ace11c1c4)…
  prefs: []
  type: TYPE_NORMAL
