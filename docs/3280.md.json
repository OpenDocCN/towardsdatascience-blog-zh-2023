["```py\nloader = PDFReader()\ndocs0 = loader.load_data(file=Path(\"llama2.pdf\"))\ndoc_text = \"\\n\\n\".join([d.get_content() for d in docs0])\ndocs = [Document(text=doc_text)]\n```", "```py\nnode_parser = SimpleNodeParser.from_defaults(chunk_size=1024)\nbase_nodes = node_parser.get_nodes_from_documents(docs)\nfor idx, node in enumerate(base_nodes):\nnode.id_ = f\"node-{idx}\"\n```", "```py\nembed_model = resolve_embed_model(“local:BAAI/bge-small-en”)\nllm = OpenAI(model=\"gpt-3.5-turbo\")\nservice_context = ServiceContext.from_defaults(llm=llm, embed_model=embed_model)\n```", "```py\nbase_index = VectorStoreIndex(base_nodes, service_context=service_context)\n```", "```py\nbase_retriever = base_index.as_retriever(similarity_top_k=2)\n```", "```py\nquery_engine_base = RetrieverQueryEngine.from_args(\n    base_retriever, service_context=service_context\n)\nresponse = query_engine_base.query(\n    \"Can you tell me about the key concepts for safety finetuning\"\n)\nprint(str(response))\n```", "```py\nsub_chunk_sizes = [128, 256, 512]\nsub_node_parsers = [\n    SimpleNodeParser.from_defaults(chunk_size=c) for c in sub_chunk_sizes\n]\n\nall_nodes = []\nfor base_node in base_nodes:\n    for n in sub_node_parsers:\n        sub_nodes = n.get_nodes_from_documents([base_node])\n        sub_inodes = [\n            IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes\n        ]\n        all_nodes.extend(sub_inodes)\n\n    # also add original node to node\n    original_node = IndexNode.from_text_node(base_node, base_node.node_id)\n    all_nodes.append(original_node)\nall_nodes_dict = {n.node_id: n for n in all_nodes}\n```", "```py\nvector_index_chunk = VectorStoreIndex(\n    all_nodes, service_context=service_context\n)\n```", "```py\nvector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=2)\nretriever_chunk = RecursiveRetriever(\n    \"vector\",\n    retriever_dict={\"vector\": vector_retriever_chunk},\n    node_dict=all_nodes_dict,\n    verbose=True,\n)\n```", "```py\nquery_engine_chunk = RetrieverQueryEngine.from_args(\n    retriever_chunk, service_context=service_context\n)\nresponse = query_engine_chunk.query(\n    \"Can you tell me about the key concepts for safety finetuning\"\n)\nprint(str(response))\n```", "```py\n# create the sentence window node parser w/ default settings\nnode_parser = SentenceWindowNodeParser.from_defaults(\n    window_size=3,\n    window_metadata_key=\"window\",\n    original_text_metadata_key=\"original_text\",\n)\nsentence_nodes = node_parser.get_nodes_from_documents(docs)\nsentence_index = VectorStoreIndex(sentence_nodes, service_context=service_context)\n```", "```py\nquery_engine = sentence_index.as_query_engine(\n    similarity_top_k=2,\n    # the target key defaults to `window` to match the node_parser's default\n    node_postprocessors=[\n        MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n    ],\n)\nwindow_response = query_engine.query(\n    \"Can you tell me about the key concepts for safety finetuning\"\n)\nprint(window_response)\n```"]