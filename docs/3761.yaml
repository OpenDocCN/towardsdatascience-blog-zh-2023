- en: Getting Started with Multimodality
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/getting-started-with-multimodality-eab5f6453080?source=collection_archive---------3-----------------------#2023-12-27](https://towardsdatascience.com/getting-started-with-multimodality-eab5f6453080?source=collection_archive---------3-----------------------#2023-12-27)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/ae8e7dbea616220acfe1963d16441f60.png)'
  prefs: []
  type: TYPE_IMG
- en: Image created with Microsoft Designer
  prefs: []
  type: TYPE_NORMAL
- en: Understanding vision capabilities of Large Multimodal Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://valentinaalto.medium.com/?source=post_page-----eab5f6453080--------------------------------)[![Valentina
    Alto](../Images/888b8aa17759d8dd5332d8fd4653cf05.png)](https://valentinaalto.medium.com/?source=post_page-----eab5f6453080--------------------------------)[](https://towardsdatascience.com/?source=post_page-----eab5f6453080--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----eab5f6453080--------------------------------)
    [Valentina Alto](https://valentinaalto.medium.com/?source=post_page-----eab5f6453080--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F341264d69dd4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-multimodality-eab5f6453080&user=Valentina+Alto&userId=341264d69dd4&source=post_page-341264d69dd4----eab5f6453080---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----eab5f6453080--------------------------------)
    ·9 min read·Dec 27, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Feab5f6453080&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-multimodality-eab5f6453080&user=Valentina+Alto&userId=341264d69dd4&source=-----eab5f6453080---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feab5f6453080&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-multimodality-eab5f6453080&source=-----eab5f6453080---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: The recent advances in Generative AI have enabled the development of Large Multimodal
    Models (LMMs) that can process and generate different types of data, such as text,
    images, audio, and video.
  prefs: []
  type: TYPE_NORMAL
- en: LMMs share with “standard” Large Language Models (LLMs) the capability of generalization
    and adaptation typical of Large Foundation Models. However, LMMs are capable of
    processing data that goes beyond text, including images, audio, and video.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most prominent examples of large multimodal models is GPT4V(ision),
    the latest iteration of the Generative Pre-trained Transformer (GPT) family. GPT-4
    can perform various tasks that require both natural language understanding and
    computer vision, such as image captioning, visual question answering, text-to-image
    synthesis, and image-to-text translation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The GPT4V (along with its newer version, the GPT-4-turbo vision), has proved
    extraordinary capabilities, including:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Mathematical reasoning over numerical problems:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/22d6be0bb9790388f39c6d37bdf13ce6.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the Author
  prefs: []
  type: TYPE_NORMAL
- en: 'Generating code from sketches:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
