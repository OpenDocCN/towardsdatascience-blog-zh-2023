- en: BYOL â€”The Alternative to Contrastive Self-Supervised Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BYOL â€” å¯¹æ¯”è‡ªç›‘ç£å­¦ä¹ çš„æ›¿ä»£æ–¹æ¡ˆ
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/byol-the-alternative-to-contrastive-self-supervised-learning-5d0a26983d7c?source=collection_archive---------4-----------------------#2023-09-07](https://towardsdatascience.com/byol-the-alternative-to-contrastive-self-supervised-learning-5d0a26983d7c?source=collection_archive---------4-----------------------#2023-09-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/byol-the-alternative-to-contrastive-self-supervised-learning-5d0a26983d7c?source=collection_archive---------4-----------------------#2023-09-07](https://towardsdatascience.com/byol-the-alternative-to-contrastive-self-supervised-learning-5d0a26983d7c?source=collection_archive---------4-----------------------#2023-09-07)
- en: '[ğŸš€Saschaâ€™s Paper Club](https://towardsdatascience.com/tagged/saschas-paper-club)'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[ğŸš€Saschaçš„è®ºæ–‡ä¿±ä¹éƒ¨](https://towardsdatascience.com/tagged/saschas-paper-club)'
- en: 'Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning by J.
    Grill et. al.'
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'Bootstrap Your Own Latent: J. Grill ç­‰äººçš„è‡ªç›‘ç£å­¦ä¹ æ–°æ–¹æ³•'
- en: '[](https://medium.com/@SaschaKirch?source=post_page-----5d0a26983d7c--------------------------------)[![Sascha
    Kirch](../Images/a0d45da9dc9c602075b2810786c660c9.png)](https://medium.com/@SaschaKirch?source=post_page-----5d0a26983d7c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5d0a26983d7c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5d0a26983d7c--------------------------------)
    [Sascha Kirch](https://medium.com/@SaschaKirch?source=post_page-----5d0a26983d7c--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@SaschaKirch?source=post_page-----5d0a26983d7c--------------------------------)[![Sascha
    Kirch](../Images/a0d45da9dc9c602075b2810786c660c9.png)](https://medium.com/@SaschaKirch?source=post_page-----5d0a26983d7c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5d0a26983d7c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5d0a26983d7c--------------------------------)
    [Sascha Kirch](https://medium.com/@SaschaKirch?source=post_page-----5d0a26983d7c--------------------------------)'
- en: Â·
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5c38dace9d5e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbyol-the-alternative-to-contrastive-self-supervised-learning-5d0a26983d7c&user=Sascha+Kirch&userId=5c38dace9d5e&source=post_page-5c38dace9d5e----5d0a26983d7c---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5d0a26983d7c--------------------------------)
    Â·10 min readÂ·Sep 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5d0a26983d7c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbyol-the-alternative-to-contrastive-self-supervised-learning-5d0a26983d7c&user=Sascha+Kirch&userId=5c38dace9d5e&source=-----5d0a26983d7c---------------------clap_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5c38dace9d5e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbyol-the-alternative-to-contrastive-self-supervised-learning-5d0a26983d7c&user=Sascha+Kirch&userId=5c38dace9d5e&source=post_page-5c38dace9d5e----5d0a26983d7c---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5d0a26983d7c--------------------------------)
    Â· 10åˆ†é’Ÿé˜…è¯» Â· 2023å¹´9æœˆ7æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5d0a26983d7c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbyol-the-alternative-to-contrastive-self-supervised-learning-5d0a26983d7c&user=Sascha+Kirch&userId=5c38dace9d5e&source=-----5d0a26983d7c---------------------clap_footer-----------)'
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5d0a26983d7c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbyol-the-alternative-to-contrastive-self-supervised-learning-5d0a26983d7c&source=-----5d0a26983d7c---------------------bookmark_footer-----------)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5d0a26983d7c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbyol-the-alternative-to-contrastive-self-supervised-learning-5d0a26983d7c&source=-----5d0a26983d7c---------------------bookmark_footer-----------)'
- en: In todayâ€™s paper analysis we will have a close look into the paper behind BYOL
    (**B**ootstrap **Y**our **O**wn **L**atent). It provides an alternative to contrastive
    self-supervised learning techniques for representation learning removing the need
    for a large corpus of negative samples and gigantic batch sizes. Furthermore it
    is a landmark paper on the path of understanding todayâ€™s state-of-the-art foundation
    models such as the [DINO](https://arxiv.org/abs/2104.14294) family, including
    [DINOv2](https://arxiv.org/abs/2304.07193).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä»Šå¤©çš„è®ºæ–‡åˆ†æä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥ç ”ç©¶ BYOLï¼ˆ**B**ootstrap **Y**our **O**wn **L**atentï¼‰èƒŒåçš„è®ºæ–‡ã€‚å®ƒæä¾›äº†ä¸€ç§å¯¹æ¯”è‡ªç›‘ç£å­¦ä¹ æŠ€æœ¯çš„æ›¿ä»£æ–¹æ¡ˆï¼Œé€šè¿‡å»é™¤å¯¹å¤§é‡è´Ÿæ ·æœ¬å’Œåºå¤§æ‰¹é‡çš„éœ€æ±‚ï¼Œä¸ºè¡¨ç¤ºå­¦ä¹ æä¾›æ”¯æŒã€‚æ­¤å¤–ï¼Œå®ƒä¹Ÿæ˜¯ç†è§£å½“ä»Šæœ€å…ˆè¿›çš„åŸºç¡€æ¨¡å‹ï¼ˆå¦‚
    [DINO](https://arxiv.org/abs/2104.14294) ç³»åˆ—ï¼ŒåŒ…æ‹¬ [DINOv2](https://arxiv.org/abs/2304.07193)ï¼‰çš„ä¸€ä¸ªé‡Œç¨‹ç¢‘å¼çš„è®ºæ–‡ã€‚
- en: While contrastive self-supervised learning frameworks still feel kind of intuitive,
    BYOL can be confusing and intimidating at first. Therefore, itâ€™s a great paper
    to analyze together. So letâ€™s dive into it and strip it down to uncover its core
    ideas!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹æ¯”è‡ªç›‘ç£å­¦ä¹ æ¡†æ¶ä»ç„¶æ„Ÿè§‰æœ‰äº›ç›´è§‚ï¼Œä½†BYOLèµ·åˆå¯èƒ½ä»¤äººå›°æƒ‘å’Œå®³æ€•ã€‚å› æ­¤ï¼Œè¿™æ˜¯ä¸€ç¯‡éå¸¸å¥½çš„è®ºæ–‡ï¼Œå¯ä»¥ä¸€èµ·åˆ†æã€‚æ‰€ä»¥è®©æˆ‘ä»¬æ·±å…¥ç ”ç©¶ï¼Œå¹¶å‰¥ç¦»å…¶æ ¸å¿ƒæ€æƒ³ï¼
- en: '![](../Images/63946f35ab17c2db935b29bf3105ec08.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63946f35ab17c2db935b29bf3105ec08.png)'
- en: Image created from [publication](https://arxiv.org/abs/2006.07733) by [Sascha
    Kirch](https://medium.com/@SaschaKirch)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºäº[Sascha Kirch](https://medium.com/@SaschaKirch)çš„[å‡ºç‰ˆç‰©](https://arxiv.org/abs/2006.07733)
- en: '**Paper:** [Bootstrap your own latent: A new approach to self-supervised Learning](https://arxiv.org/abs/2006.07733)
    by Jean-Bastien Grill et. al., 13 Jun. 2020'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**Paper:** [Bootstrap your own latent: A new approach to self-supervised Learning](https://arxiv.org/abs/2006.07733)
    by Jean-Bastien Grill et. al., 13 Jun. 2020'
- en: ''
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Resources:** [GitHub](https://github.com/deepmind/deepmind-research/tree/master/byol)'
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**Resources:** [GitHub](https://github.com/deepmind/deepmind-research/tree/master/byol)'
- en: ''
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Category:** similarity learning, representation learning, computer vision,
    foundation models'
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**Category:** similarity learning, representation learning, computer vision,
    foundation models'
- en: ''
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[**Other Walkthroughs**](https://medium.com/@SaschaKirch/list/paper-walkthroughs-by-sascha-kirch-89c7847da8e2)**:**'
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[**Other Walkthroughs**](https://medium.com/@SaschaKirch/list/paper-walkthroughs-by-sascha-kirch-89c7847da8e2)**:**'
- en: '[[CLIP](/the-clip-foundation-model-7770858b487d?sk=a7b10ba1d0c3a20ecd4adb8200a48500)]
    â€” [[GLIP](/glip-introducing-language-image-pre-training-to-object-detection-5ddb601873aa?sk=4f0acb404a38d342b7669f861c013a05)]
    â€” [[Segment Anything](/segment-anything-promptable-segmentation-of-arbitrary-objects-f28958c5612d?sk=bd1311a6d8b1e0e6d3369d536dba0700)]
    â€” [[Depth Anything](https://medium.com/towards-data-science/depth-anything-a-foundation-model-for-monocular-depth-estimation-8a7920b5c9cc?sk=fc6197edd68e6137c3396c83e50f65cb)]
    â€” [[DINO](/segment-anything-promptable-segmentation-of-arbitrary-objects-f28958c5612d?sk=bd1311a6d8b1e0e6d3369d536dba0700)]
    â€” [[DDPM](/the-rise-of-diffusion-models-a-new-era-of-generative-deep-learning-3ef4779f6e1b?sk=8c178422a977c6f49ec24b13502be4fd)]'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[[CLIP](/the-clip-foundation-model-7770858b487d?sk=a7b10ba1d0c3a20ecd4adb8200a48500)]
    â€” [[GLIP](/glip-introducing-language-image-pre-training-to-object-detection-5ddb601873aa?sk=4f0acb404a38d342b7669f861c013a05)]
    â€” [[Segment Anything](/segment-anything-promptable-segmentation-of-arbitrary-objects-f28958c5612d?sk=bd1311a6d8b1e0e6d3369d536dba0700)]
    â€” [[Depth Anything](https://medium.com/towards-data-science/depth-anything-a-foundation-model-for-monocular-depth-estimation-8a7920b5c9cc?sk=fc6197edd68e6137c3396c83e50f65cb)]
    â€” [[DINO](/segment-anything-promptable-segmentation-of-arbitrary-objects-f28958c5612d?sk=bd1311a6d8b1e0e6d3369d536dba0700)]
    â€” [[DDPM](/the-rise-of-diffusion-models-a-new-era-of-generative-deep-learning-3ef4779f6e1b?sk=8c178422a977c6f49ec24b13502be4fd)]'
