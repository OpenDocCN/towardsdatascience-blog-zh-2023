["```py\npip install polars[all]\n```", "```py\n# Scanning in 9 million rows and 51 columns. \n# We ignore any potential errors in the dataset due to encoding / dirty null values.\ntemp_df = pl.scan_csv(\"/kaggle/input/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv\", \n                      ignore_errors = True)\n\n# Read the data\nresult_df = temp_df.collect()\n\n# Reading dataset\nresult_df\n\n# Time taken: 14.1 s ± 3.29 s per loop\n```", "```py\n# Lazily read (scan) in 9 million rows and 51 columns.\ntemp_df = pl.scan_csv(\"/kaggle/input/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv\", ignore_errors = True)\n\n# Filtering for rows with the \"Registration State\" in NY\nresult_df = temp_df.filter(pl.col(['Registration State'])==\"NY\")\n\n# Run the filtering using collect.\nresult_df.collect()\n\n# Time taken: 12.6 s ± 205 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n```", "```py\n# Lazily read (scan) in 9 million rows and 51 columns.\ntemp_df = pl.scan_csv(\"/kaggle/input/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv\", ignore_errors = True)\n\n# Find all carplates that contain the letter 'a' or '1'. \nresult_df = temp_df.filter(pl.col(\"Plate ID\").str.contains(r\"[a1]\"))\n\n# Run the filter using collect.\nresult_df.collect()\n\n# Time taken: 12 s ± 176 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n```", "```py\n# Eagerly read in 9 million rows and 51 columns.\n# Note that we use read_csv, not scan_csv here.\ntemp_df = pl.read_csv(\"/kaggle/input/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv\", ignore_errors = True)\n\n# Filtering for rows with the \"Registration State\" in NY\nresult_df = temp_df[['Registration State']==\"NY\"]\n\n# Time taken: 15 s ± 3.72 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n```", "```py\n# Lazily read (scan) in 9 million rows and 51 columns.\ntemp_df = pl.scan_csv(\"/kaggle/input/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv\", ignore_errors = True)\n\n# Selecting a particular column called Plate ID. \n# In pandas, this will look like result_df = temp_df['Plate ID']\nresult_df = temp_df.select(['Plate ID']).collect()\n\n# Run it using the collect()\nresult_df.collect()\n\n# Time taken: 1.59 s ± 24.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n```", "```py\n# Eagerly read in all 9 million rows and 51 columns.\ntemp_df = pl.read_csv(\"/kaggle/input/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv\", ignore_errors = True)\n\n# Selecting the Plate ID column\nresult_df = temp_df['Plate ID']\n\n# Time taken: 12.8 s ± 304 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n```", "```py\n# Lazily read (scan) in 9 million rows and 51 columns.\ntemp_df = pl.scan_csv(\"/kaggle/input/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv\", ignore_errors = True)\n\n# String functions to find all Plate ID that contain the letter 'a' or '1'\nresult_df = temp_df\\\n            .with_column(pl.col(\"Plate ID\").str.lengths().alias(\"plate_id_letter_count\"))\\\n\n# Evaluate the string function.\nresult_df.collect()\n\n# Time taken: 14.8 s ± 5.79 s per loop\n```", "```py\n# Lazily read (scan) in 9 million rows and 51 columns.\ntemp_df = pl.scan_csv(\"/kaggle/input/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv\", ignore_errors = True)\n\n# Create a new column called \"Clean Violation Code\"\n# using the formula 10000 + df[\"Violation Code\"]\nresult_df = temp_df.with_columns([\n    pl.col(\"Violation Code\").\\\n    map(lambda x: x+10000).\\\n    alias(\"Clean Violation Code\")\n])\n\n# Evaluate the function.\nresult_df.collect()\n\n# Time taken: 13.8 s ± 796 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) \n```", "```py\n# Lazily read (scan) in 9 million rows and 51 columns.\ntemp_df = pl.scan_csv(\"/kaggle/input/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv\", ignore_errors = True)\n\n# For each vehicle registration state, calculate the number of tikcets \n# and create a list of all violation codes.\nresult_df = temp_df\\\n            .groupby(\"Registration State\").agg(\n    [\n        pl.count(),\n        pl.col(\"Violation Code\").list(),\n\n    ]\n).sort('Registration State')\\\n.collect()\n\nresult_df\n\n# time taken: 2.3 s ± 29.1 ms per loop\n```", "```py\n# Lazily read (scan) in 9 million rows and 51 columns.\ntemp_df = pl.scan_csv(\"/kaggle/input/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv\", ignore_errors = True)\n\n# Combine multiple steps into one\n# Convert \"Issue Date\" intoa date column, \n# Then group by Registration State and perform some aggregation.\nresult_df = temp_df\\\n            .with_column(pl.col(\"Issue Date\").str.strptime(pl.Date, fmt=\"%m/%d/%Y\"))\\\n            .groupby(\"Registration State\").agg(\n                [pl.first(\"Issue Date\")]\n              ).sort('Registration State')\\\n\n# Run the steps\nresult_df.collect()\n\n# Took 1.69 s ± 18.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n```", "```py\n# Lazily scan two dataframes \ntemp_df1 = pl.scan_csv(\"/kaggle/input/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv\", ignore_errors = True)\ntemp_df2 = pl.scan_csv(\"/kaggle/input/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2015.csv\", ignore_errors = True)\n\n# Concatenating datasets\nresult_df = pl.concat(\n    [\n        temp_df1,\n        temp_df2,\n    ],\n    how=\"vertical\",\n)\n\n# Reading dataset\nresult_df.collect()\n\n# Time taken: \n```", "```py\ndf_cars = pl.DataFrame(\n    {\n        \"id\": [\"a\", \"b\", \"c\"],\n        \"make\": [\"ford\", \"toyota\", \"bmw\"],\n    }\n)\ndf_repairs = pl.DataFrame(\n    {\n        \"id\": [\"c\", \"c\"],\n        \"cost\": [100, 200],\n    }\n)\n\ndf_inner_join = df_cars.join(df_repairs, on=\"id\", how=\"inner\")\nprint(df_inner_join)\n```", "```py\nshape: (2, 3)\n┌─────┬──────┬──────┐\n│ id  ┆ make ┆ cost │\n│ --- ┆ ---  ┆ ---  │\n│ str ┆ str  ┆ i64  │\n╞═════╪══════╪══════╡\n│ c   ┆ bmw  ┆ 100  │\n├╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┤\n│ c   ┆ bmw  ┆ 200  │\n└─────┴──────┴──────┘\n```", "```py\nimport polars as pl\n\n# Read four dataframes to form a 42.3M parking ticket datasets\ntemp_df1 = pl.scan_csv(\"/kaggle/input/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv\", ignore_errors = True)\ntemp_df2 = pl.scan_csv(\"/kaggle/input/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2015.csv\", ignore_errors = True)\ntemp_df3 = pl.scan_csv(\"/kaggle/input/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2017.csv\", ignore_errors = True)\ntemp_df4 = pl.scan_csv(\"/kaggle/input/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2016.csv\", ignore_errors = True)\n\n# Concatenating dataset\nresult_df = pl.concat(\n    [\n        temp_df1,\n        temp_df2,\n        temp_df3,\n        temp_df4,\n    ],\n    how=\"vertical\",\n)\n\n# Reading dataset\nresult_df.collect()\n\n# Could not be run since it causes out-of-memory issue. \n```", "```py\nimport vaex \n\n# Read four dataframes to form a 42.3M parking ticket datasets\ntemp_df1 = vaex.open(\"/kaggle/input/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv\", schema_infer_fraction=1)\ntemp_df2 = vaex.open(\"/kaggle/input/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2015.csv\", schema_infer_fraction=1)\ntemp_df3 = vaex.open(\"/kaggle/input/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2017.csv\", schema_infer_fraction=1)\ntemp_df4 = vaex.open(\"/kaggle/input/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2016.csv\", schema_infer_fraction=1)\n\n# Concatenating dataset\nresult_df = vaex.concat([\n        temp_df1,\n        temp_df2,\n        temp_df3,\n        temp_df4\n    ])\n\n# Reading dataset\nresult_df\n\n# Could be run without out-of-memory problem.\n```"]