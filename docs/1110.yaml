- en: Custom YOLOv7 Object Detection with TensorFlow.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/training-a-custom-yolov7-in-pytorch-and-running-it-directly-in-the-browser-with-tensorflow-js-96a5ecd7a530?source=collection_archive---------6-----------------------#2023-03-28](https://towardsdatascience.com/training-a-custom-yolov7-in-pytorch-and-running-it-directly-in-the-browser-with-tensorflow-js-96a5ecd7a530?source=collection_archive---------6-----------------------#2023-03-28)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/9b4d0e99afd60aaf9cf2530e000da490.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Martijn Baudoin](https://unsplash.com/@martijnbaudoin?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/4z0-2mQE7io?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: Training a custom YOLOv7 model in PyTorch and converting it to TensorFlow.js
    for real-time offline detection on the browser
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@zaninihugo?source=post_page-----96a5ecd7a530--------------------------------)[![Hugo
    Zanini](../Images/cbda793f1cf82f34b29c6e136556361d.png)](https://medium.com/@zaninihugo?source=post_page-----96a5ecd7a530--------------------------------)[](https://towardsdatascience.com/?source=post_page-----96a5ecd7a530--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----96a5ecd7a530--------------------------------)
    [Hugo Zanini](https://medium.com/@zaninihugo?source=post_page-----96a5ecd7a530--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8f4c63386bac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-a-custom-yolov7-in-pytorch-and-running-it-directly-in-the-browser-with-tensorflow-js-96a5ecd7a530&user=Hugo+Zanini&userId=8f4c63386bac&source=post_page-8f4c63386bac----96a5ecd7a530---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----96a5ecd7a530--------------------------------)
    ·6 min read·Mar 28, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F96a5ecd7a530&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-a-custom-yolov7-in-pytorch-and-running-it-directly-in-the-browser-with-tensorflow-js-96a5ecd7a530&user=Hugo+Zanini&userId=8f4c63386bac&source=-----96a5ecd7a530---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F96a5ecd7a530&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-a-custom-yolov7-in-pytorch-and-running-it-directly-in-the-browser-with-tensorflow-js-96a5ecd7a530&source=-----96a5ecd7a530---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Recently, I open-sourced an implementation of [**YOLOv7 in Tensorflow.js**](https://github.com/hugozanini/yolov7-tfjs?linkId=8607585)
    and the most common question I received was:'
  prefs: []
  type: TYPE_NORMAL
- en: How did you **convert** the model from PyTorch to Tensorflow**.js**?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This post will cover this process by solving a real-world problem using a custom
    **YOLOv7** model running **directly on the browser and offline**.
  prefs: []
  type: TYPE_NORMAL
- en: The industry we will tackle is **physical retail**. Besides the digitalization
    that happened recently — mostly during the pandemic — [the physical store remains
    the customers' most preferred shopping destination](https://www.forbes.com/sites/sap/2022/02/07/retail-trends-2022-in-search-of-the-ultimate-customer-experience/?sh=13a0809c52ad).
  prefs: []
  type: TYPE_NORMAL
- en: Everything in a store is about the experience. The [Retail Feedback Group](https://feedbackgroup.com/)
    (RFG), which has been tracking the grocery shopping experience for around 15 years,
    [consistently finds](https://www.winsightgrocerybusiness.com/retailers/supermarket-experience-its-time-integrate)
    that the most crucial factor affecting customer satisfaction is whether shoppers
    are able to **find everything they need during their visit, whether it be in-store
    or online**.
  prefs: []
  type: TYPE_NORMAL
- en: So retailers are constantly focused on ensuring **product availability** and
    the **right mix of items** for their customers.
  prefs: []
  type: TYPE_NORMAL
- en: In a previous article, I showed [how to create a TensorFlow.js model to recognize
    SKUs](https://blog.tensorflow.org/2022/05/real-time-sku-detection-in-browser.html).
    In this post, we will explore how to **identify empty shelves** using a custom
    YOLOv7 model — everything running in **real-time, offline, and in the browser
    of a smartphone**.
  prefs: []
  type: TYPE_NORMAL
- en: 'What this post will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the environment;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gathering the data;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preparing the model for training;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training and reparametrizing the model;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating the model;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Converting to TensorFlow.js;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying the model on a web browser.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring the environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The entire training pipeline will be executed using the free GPU provided by
    Google Colab. If you want to access the notebook with all the consolidated steps,
    [click here](https://colab.research.google.com/drive/185pYr5D2us666KxGim3INaJNAx8vIkcS?usp=sharing).
  prefs: []
  type: TYPE_NORMAL
- en: Gathering the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The dataset we will use to train the model is the [Retail empty shelves — stockout](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi%3A10.7910%2FDVN%2F8RET7B&version=DRAFT)
    ([CC0 1.0 License](https://creativecommons.org/publicdomain/zero/1.0/)). It has
    3608 annotations from 1155 images and a unique class: *Stockout*.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/70b73d9895d065c5c32565ee121080d5.png)'
  prefs: []
  type: TYPE_IMG
- en: Dataset sample from [Harvard Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi%3A10.7910%2FDVN%2F8RET7B&version=DRAFT)
  prefs: []
  type: TYPE_NORMAL
- en: The annotations should be in the YOLOv7 format, where each image has its corresponding
    `txt` file. The first value in each line represents the class — for the Stockout
    dataset, all classes are the same and equal to `0`. The remaining four numbers
    in the line indicate the coordinates of the bounding box.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to create your own dataset, you can use a tool like [CVAT](https://github.com/opencv/cvat).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/d5c36d8d43a31dd9c75c83234e7adae3.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of aYOLOv7 annotation | Image by author
  prefs: []
  type: TYPE_NORMAL
- en: 'To download and extract the [stockout dataset](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi%3A10.7910%2FDVN%2F8RET7B),
    use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the model for training
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first step is to clone the YOLOv7 repository and install the dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: Then, download the weights pre-trained on the [COCO 2017 Dataset](https://cocodataset.org/#home).
    They will be used to initialize the model and speed up the training — this technique
    is known as [transfer learning](https://www.tensorflow.org/tutorials/images/transfer_learning).
  prefs: []
  type: TYPE_NORMAL
- en: Since we are working on a one-class problem, we opted for YOLOv7-tiny, a lightweight
    variation of YOLOv7.
  prefs: []
  type: TYPE_NORMAL
- en: And before starting the training, we have to configure a .yaml file with the
    parameters we want to use.
  prefs: []
  type: TYPE_NORMAL
- en: Training and reparametrizing the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The training process is straightforward and customizable, allowing you to adjust
    parameters such as the number of epochs and batches to suit your dataset’s requirements.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of the execution, you will have the weights saved at `yolov7/runs/train/your-model-name/weights/best.pt`
    .
  prefs: []
  type: TYPE_NORMAL
- en: To view the training metrics in a visual format, launch TensorBoard or open
    the image `yolov7/runs/train/your-model-name/results.png` .
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cd8431647b1ccbc7dc39022a64a6d612.png)'
  prefs: []
  type: TYPE_IMG
- en: Running tensorboard | Image by author
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/66f74eb7cfef6723a38067d512565204.png)'
  prefs: []
  type: TYPE_IMG
- en: results.png | Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have the model trained, it is time to **reparametrize the weights
    for inference**.
  prefs: []
  type: TYPE_NORMAL
- en: Along with its architecture optimizations for real-time object detection, YOLOv7
    introduces additional modules and methods that can enhance training efficiency
    and improve object detection accuracy. These modules, known as **bag-of-freebies**,
    must be streamlined for efficient inference. For more information, refer to the
    [model paper](https://arxiv.org/abs/2207.02696).
  prefs: []
  type: TYPE_NORMAL
- en: Check the weight's path on the code below and execute it to generate a reparametrized
    model.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that the model is optimized for inference, it's time to run it in some testing
    images to see if it detects empty spaces on the shelves.
  prefs: []
  type: TYPE_NORMAL
- en: Converting to TensorFlow.js
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Converting the model can be challenging, as it requires passing through several
    transformations: PyTorch to ONNX, ONNX to TensorFlow, and finally, TensorFlow
    to TensorFlow.js.'
  prefs: []
  type: TYPE_NORMAL
- en: The following code will handle everything for you. Just make sure the **model
    paths** are correctly configured and then run it!
  prefs: []
  type: TYPE_NORMAL
- en: Upon completion, the resulting TensorFlow.js model will be automatically downloaded
    by Google Colab.
  prefs: []
  type: TYPE_NORMAL
- en: Assuming everything has been executed successfully, the model will now be converted
    to the ***TensorFlow.js layers format***.
  prefs: []
  type: TYPE_NORMAL
- en: 'The folder downloaded on your local machine should contain a *model.json* file
    and a set of sharded weights files in a binary format. The *model.json* has both
    the model topology (aka “architecture” or “graph”: a description of the layers
    and how they are connected) and a manifest of the weight files.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Deploying the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The model is now ready to be loaded into JavaScript. As mentioned in the beginning,
    I open-sourced a YOLOv7 code in JavaScript. Therefore, we can utilize the same
    repository and replace the model with the one that we have just trained
  prefs: []
  type: TYPE_NORMAL
- en: 'Clone the [repository](https://github.com/hugozanini/yolov7-tfjs.git):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Install the packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Go to the `[public](https://github.com/hugozanini/yolov7-tfjs/tree/master/public)`
    folder and past the model trained. You should have a structure like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Go to `[src/App.jsx](https://github.com/hugozanini/yolov7-tfjs/blob/master/src/App.jsx)`
    and change the model name on `[line 29](https://github.com/hugozanini/yolov7-tfjs/blob/4efa4cba39d1168d4bcf7bfe79274e54e87d2eaa/src/App.jsx#L29)`
    to stockout:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'To execute the application go to the root folder and run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'A local server will be started, and you should see something similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/741d69af65df9bc8058117a62bbad714.png)'
  prefs: []
  type: TYPE_IMG
- en: Running example | Image by author
  prefs: []
  type: TYPE_NORMAL
- en: This model was deployed on CodesSandbox too. Access the link below to see it
    running.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://codesandbox.io/p/github/hugozanini/yolov7-tfjs/stockout?file=%2FREADME.md&workspace=%257B%2522activeFileId%2522%253A%2522clffv5qby000yg1fw2ridgthd%2522%252C%2522openFiles%2522%253A%255B%2522%252FREADME.md%2522%255D%252C%2522sidebarPanel%2522%253A%2522EXPLORER%2522%252C%2522gitSidebarPanel%2522%253A%2522COMMIT%2522%252C%2522spaces%2522%253A%257B%2522clfjm1t8i00733b6idq6lqztm%2522%253A%257B%2522key%2522%253A%2522clfjm1t8i00733b6idq6lqztm%2522%252C%2522name%2522%253A%2522Default%2522%252C%2522devtools%2522%253A%255B%257B%2522type%2522%253A%2522PREVIEW%2522%252C%2522taskId%2522%253A%2522start%2522%252C%2522port%2522%253A3000%252C%2522key%2522%253A%2522clfjm1t8i00743b6iw255o0qk%2522%252C%2522isMinimized%2522%253Afalse%257D%255D%257D%257D%252C%2522currentSpace%2522%253A%2522clfjm1t8i00733b6idq6lqztm%2522%252C%2522spacesOrder%2522%253A%255B%2522clfjm1t8i00733b6idq6lqztm%2522%255D%252C%2522hideCodeEditor%2522%253Afalse%257D&source=post_page-----96a5ecd7a530--------------------------------)
    [## CondeSandbox'
  prefs: []
  type: TYPE_NORMAL
- en: Stockout](https://codesandbox.io/p/github/hugozanini/yolov7-tfjs/stockout?file=%2FREADME.md&workspace=%257B%2522activeFileId%2522%253A%2522clffv5qby000yg1fw2ridgthd%2522%252C%2522openFiles%2522%253A%255B%2522%252FREADME.md%2522%255D%252C%2522sidebarPanel%2522%253A%2522EXPLORER%2522%252C%2522gitSidebarPanel%2522%253A%2522COMMIT%2522%252C%2522spaces%2522%253A%257B%2522clfjm1t8i00733b6idq6lqztm%2522%253A%257B%2522key%2522%253A%2522clfjm1t8i00733b6idq6lqztm%2522%252C%2522name%2522%253A%2522Default%2522%252C%2522devtools%2522%253A%255B%257B%2522type%2522%253A%2522PREVIEW%2522%252C%2522taskId%2522%253A%2522start%2522%252C%2522port%2522%253A3000%252C%2522key%2522%253A%2522clfjm1t8i00743b6iw255o0qk%2522%252C%2522isMinimized%2522%253Afalse%257D%255D%257D%257D%252C%2522currentSpace%2522%253A%2522clfjm1t8i00733b6idq6lqztm%2522%252C%2522spacesOrder%2522%253A%255B%2522clfjm1t8i00733b6idq6lqztm%2522%255D%252C%2522hideCodeEditor%2522%253Afalse%257D&source=post_page-----96a5ecd7a530--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: With YOLOv7, it’s possible to detect up to 80 different classes. For businesses
    in the retail industry, this presents a great opportunity to improve their in-store
    product execution.
  prefs: []
  type: TYPE_NORMAL
- en: By training the model to recognize all of their company’s products, retailers
    can ensure that their **products are properly placed on the shelves and that customers
    are able to easily find what they are looking for**.
  prefs: []
  type: TYPE_NORMAL
- en: To validate the effectiveness of the model trained, I went to a grocery and
    drug store with my phone and recorded some examples of the detector running in
    real time.
  prefs: []
  type: TYPE_NORMAL
- en: In the video below, you can verify the solution's ability to accurately detect
    empty shelves in a real environment.
  prefs: []
  type: TYPE_NORMAL
- en: A stockout detector in conjunction with an [SKU recognition model](https://blog.tensorflow.org/2022/05/real-time-sku-detection-in-browser.html)
    can greatly enhance the efficiency and effectiveness of retail operations.
  prefs: []
  type: TYPE_NORMAL
- en: While cloud-based solutions exist, they can sometimes be slow, taking up to
    24 hours to process a single detection. In comparison, using TensorFlow.js models
    on a smartphone browser allows for offline, real-time recognition — allowing businesses
    to make more immediate decisions and respond to stockouts faster.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, combining a stockout detector with an SKU recognition model can provide
    a powerful way for optimizing retail operations and enhancing the shopping experience
    for customers. By using real-time analysis and offline recognition capabilities,
    businesses can make informed decisions and respond quickly to changing conditions.
  prefs: []
  type: TYPE_NORMAL
- en: If you have any questions or want to share about a user case, feel reach me
    on [Linkedin](https://www.linkedin.com/in/hugozanini/?locale=en_US) or [Twitter](https://twitter.com/hugoznn).
    All the source code used in this post is available on the [project repo](https://github.com/hugozanini/yolov7-tfjs/tree/stockout).
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading :)
  prefs: []
  type: TYPE_NORMAL
