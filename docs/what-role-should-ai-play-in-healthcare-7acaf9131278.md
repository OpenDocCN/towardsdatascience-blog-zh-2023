# 人工智能在医疗保健中应扮演什么角色？

> 原文：[https://towardsdatascience.com/what-role-should-ai-play-in-healthcare-7acaf9131278?source=collection_archive---------2-----------------------#2023-11-30](https://towardsdatascience.com/what-role-should-ai-play-in-healthcare-7acaf9131278?source=collection_archive---------2-----------------------#2023-11-30)

## **关于机器学习在医疗保健中的应用及美国医疗保健AI丑闻**

[](https://medium.com/@s.kirmer?source=post_page-----7acaf9131278--------------------------------)[![Stephanie Kirmer](../Images/f9d9ef9167febde974c223dd4d8d6293.png)](https://medium.com/@s.kirmer?source=post_page-----7acaf9131278--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7acaf9131278--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7acaf9131278--------------------------------) [Stephanie Kirmer](https://medium.com/@s.kirmer?source=post_page-----7acaf9131278--------------------------------)

·

[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa8dc77209ef3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-role-should-ai-play-in-healthcare-7acaf9131278&user=Stephanie+Kirmer&userId=a8dc77209ef3&source=post_page-a8dc77209ef3----7acaf9131278---------------------post_header-----------) 发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7acaf9131278--------------------------------) ·11 分钟阅读·2023年11月30日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7acaf9131278&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-role-should-ai-play-in-healthcare-7acaf9131278&user=Stephanie+Kirmer&userId=a8dc77209ef3&source=-----7acaf9131278---------------------clap_footer-----------)

--

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7acaf9131278&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-role-should-ai-play-in-healthcare-7acaf9131278&source=-----7acaf9131278---------------------bookmark_footer-----------)![](../Images/35a45b006a418cf960be7d468acae718.png)

图片来源：国家癌症研究所，来源于 Unsplash

你们中的一些人可能知道我受过社会学培训——准确地说，我在研究生院学习了医学社会学。这意味着我专注于人们和群体如何与疾病、医学、医疗机构以及围绕健康的概念和想法互动。*

当我担任兼职教授时，我曾向进入医疗领域的本科生讲授这些问题，我认为医疗服务提供者对我们社会、经济和种族状况如何与健康互动有深入了解是非常重要的。每个生病的人都不是相同的，认识到这一点是提供高质量护理之前必须做到的。

我解释这些只是为了为今天的话题——机器学习在医疗中的应用——提供一些背景。我之所以等到现在才谈论这个话题，是因为它实在太大了，但最近的一些新闻报道激励我开始讨论。很可能，我会在未来继续谈论这个话题。

# 关于生命与死亡

我发现很难讨论在医疗领域使用机器学习的原因之一是因为失败的风险极其严重。如果我预测你在线订购的袜子的到达日期错误，最坏的情况就是你可能有一两天的冷脚。如果机器学习模型在医疗环境中出错，风险就会真正上升到生命丧失或生活质量严重下降的程度。

> 如果机器学习模型在医疗环境中出错，风险就会真正上升到生命丧失或生活质量严重下降的程度。

当然，我们的医疗服务提供者在日常工作中已经意识到了这种风险，并学会了应对它。但总体来说，数据科学家和机器学习模型开发者对这些模型所涉及的结果并不熟悉。在建模时，以分类模型为例，任务的一个重要部分是估计我们称之为假阳性和假阴性的成本——本质上，就是当我们预测某个事件实际上没有发生（FP）或我们预测不会发生任何事件但它实际上发生了（FN）时，可能会出现什么坏事。在其他类型的模型中，我们也会花时间考虑模型预测的结果与期望值或实际情况的差异。共同点是模型总是会有某种程度的不可避免的错误，即使是生成式人工智能也是如此。正如我过去多次提到的，模型输出在某种程度上是基于概率的，这些概率留有一定的错误（不良行为）的空间。

在医疗环境中，假阳性或假阴性等错误的成本意味着什么？如果还不够明显的话，金钱只是模型潜在错误中的一小部分，无论是在医疗领域还是其他行业。与“生命损失”或“失去独立生活能力”相比，金钱损失应当是一个较低的优先级。虽然我们的法律系统尝试为这些问题分配货币价值，以便在法院案件中分配赔偿金，但这真的不是同一回事，尤其是当问题涉及到你自己的生命或生活质量时。

# 联合健康

[最近报道的关于联合医疗如何](https://www.cbsnews.com/news/unitedhealth-lawsuit-ai-deny-claims-medicare-advantage-health-insurance-denials/) 使用机器学习的案例，突显了当“金钱”在医疗决策中被赋予比“生命”更高的优先级时，情况变得多么糟糕。这与模型本身没有太大关系，因为你可以教会一个模型更好地优先考虑医疗结果 *如果你愿意的话*。

不幸的是，我们的医疗系统在护理质量和利润这两个竞争的优先级之间摇摆。我坚决拒绝这两者可以和谐共存的观点，因为它们总是处于紧张状态，但美国的系统仍然基于这种可疑的基础。我们在讨论联合医疗所做的事情时，牢记这一点是重要的。

联合医疗（在实际支付护理方面被普遍认为是美国最差的大型健康保险公司）所做的就是：

+   人员已支付了他们的保险费用，并且做了所有应做的事情以获得保险覆盖；

+   人员变老和/或生病，需要住院护理来恢复病情或伤害；

+   联合医疗的模型提供了案件和患者的一般特征，并预测恢复护理可能需要的时间。这一预测所需的护理时间远远短于医生建议的时间；

+   联合医疗信任模型而非医生，并拒绝支付更长的护理时间，将患者在未康复前赶出了护理设施。

许多医生和医疗系统的学者讨论了[健康保险公司如何“无证行医”](https://www.propublica.org/article/cigna-health-insurance-denials-pxdx-congress-investigation#:~:text=The%20letter%20follows%20an%20investigation,PXDX%20system%2C%20spending%20an%20average) 当他们对医生关于患者所需护理的专业医学意见提出质疑时，这种行为正是这种情况的体现。当联合医疗的员工（在模型的支持下）改变患者的护理方案时，我们还能怎么称呼这种行为？

但这并不新鲜，实际上，保险公司不需要模型来支持他们对医生的质疑。这在我们的健康保险系统中是常见的，每天都会发生，形式包括事先授权。保险公司会争辩说，他们有其他医生在做最终决定，因此“无证行医”并不适用，但这些医生明显的激励是站在保险公司一边，而非患者。可以确定，这些医生从未推荐比主要医生更昂贵的护理方案。

# 应用机器学习

那么，为什么UHC的行为现在成为新闻？这与机器学习到底有什么关系？UHC用于确定这些老年患者的急性后护理应该持续多久的模型来自一家名为naviHealth的公司，该公司专门处理这些案例。[从他们的网站阅读](https://navihealth.com/)，我了解到，naviHealth寻找减少老年患者在护理设施中停留时间的方法。他们可能还提供一些关于案例管理的服务，在患者被送回家之前与他们进行咨询。他们在网站上明确表示，他们可以为保险公司提供“显著的成本节约”。

但关键在于，这个模型“nH Predict”声称能够确定患者在护理环境中停留的最佳时间长度， ostensibly 为了最佳的护理效果，而实际上模型的阈值设置使得这些预测与护理效果并不一致，而仅仅是为了成本节约。

换句话说：如果你允许病人留在医院或康复设施，但他们准备提前回家并且真的这样做了，那是很好的。没有人愿意在医院待得过久（你尝过医院的食物吗？）。这是一种你可能通过提供高质量的护理、他们所描述的案例管理以及其他有用服务来实现的成本节约，同时病人也能得到他们所需的护理。但UHC所做的却是，通过拒绝支付病人在医院的费用来获得成本节约，因此不论病人是否准备好，他们都会被赶出医院送回家。

> UHC所做的却是，通过拒绝支付病人在医院的费用来获得成本节约，而不是提供这些服务并让病人准备好提前离开医院，因此无论病人是否准备好，他们都会被赶出医院送回家。

# 模型如何了解健康

我想澄清的是，这不是“人工智能失控”——这是人类做出了不道德的决定，并利用机器学习来推卸责任。如果你想将老年人赶出医院，不考虑他们的生活或健康后果，那么如果你今天是美国的保险公司，你可以这样做。你不需要一个模型来给你许可。但我认为UHC意识到，如果他们有一个模型给出这些建议，而人工审核者可以只是走个过场，那么他们就有了掩护，因为人们认为模型具有一定的独立准确性。毕竟，模型肯定不会查看这项护理的价格标签！

但请记住，模型只是一个试图将模式融合成可以复制的数学语言的尝试，它不控制你提供给它的信息，也不控制你教它回答的问题。在创建一个预测住院天数的模型时，你可以这样进行。

+   收集大量的过去患者档案数据，其中有人受伤或生病，进入医院，接受康复住院护理，并有结果（不论是康复、需要回医院还是去世）。

+   将这些文件转化为数字数据。把每个患者看作是电子表格中的一行，开始收集诸如患者年龄、初始伤害的严重程度、患者的过去病史数据、是否有其他疾病（糖尿病、心脏病、痴呆等）。这些成为训练数据。最重要的是，你需要包括A. 康复住院护理的天数和B. 结果是什么。

+   现在你需要框定问题。在这种情况下，塑造模型训练的一种方式可能是：“在考虑到所有病例特征的情况下，治疗效果良好的患者有多少天的康复？” 然后你可能会将其与“在考虑到所有病例特征的情况下，治疗效果差的患者有多少天的康复？”进行比较。这只是一个假设性的框定方式，还有许多其他方法可以构建问题并整合训练数据。

最终你会得到每个患者的康复天数估计值，这个估计值适用于良好的结果。可能会得到一个范围，或者基于天数的良好结果的概率，如果你将天数增加到某个点，那么概率也会增加，如果超过某个点，它又会开始变得有风险。

请记住，康复天数并不是与其他一切无关——你可能会有感染、并发症或其他疾病，这意味着长时间住院是必要的，并不是为了愉快的原因（康复），而是为了不幸的原因（额外的疾病）。所以住院时间过长也可能是一个坏事，但原因与住院天数无关。考虑时间顺序，帮助理解因果关系可能存在的地方。

# 使用模型的结果

所以我们有一个模型，如果我们告诉它有关患者的信息，它就会给出一个估计值，说明如果这个人要有好的结果，康复住院的时间可能需要多久。真正关键的问题是我们如何利用这些信息！

如果我们是全民医疗保险（UHC），我们的目标是节省开支。我们以非常非常低的估算值为准，可能甚至低于模型推荐的良好结果范围，并在此时停止支付医疗费用。这就是这个故事的经过，依据报道来看。

如果我们的目标是病人的结果，那么我们应该退一步思考一下。我们是否认为病人因非医学原因在医院或住院康复中心待了很长时间？我们是否认为医生因不适当的原因将病人送往康复中心？这些原因可能是什么？老实说，我很难想到许多医生在这种情况下会有什么合理的行为。正如我所提到的，谁愿意在病情好转后仍然待在医院？如果确实发生了这种情况，我们应该寻找改变医生行为的方法，但不应以牺牲病人护理质量为代价。也许医院高管们希望病人待得更久，而医生的薪水与病人的住院时间无关。医生的激励是让病人尽快康复。

我在这里想表达的是，如果我们的目标只是让病人康复，我不确定引入这个模型是否有意义。毫无疑问，过长的康复住院时间目前不是对病人健康的最大威胁。

这篇文章讲述了机器学习，这也是大多数读者来这里的原因，但它还涉及了医疗经济学的问题。这些问题对所有美国人来说都很重要，因为医疗系统迟早会影响到我们所有人。我还认为，对于数据科学家来说，思考将模型投入生产环境的真正意义是一个很好的练习，这不仅仅是从召回率和精确度的角度来看，而是从真实人类生活受影响的角度来看。你对你的模型的优化负责。你在构建模型时做出的决策将使该模型对人们和社会的影响是积极的还是消极的，你不能仅仅耸耸肩说“模型做的”。

即使你的模型不会对人们的医疗保健做出决定，它仍然会对人们产生一些影响。（如果没有，那你为什么要构建它？）我鼓励所有从业者在工作中时刻牢记这一点。

*医学社会学关心的这些问题的例子可能包括：

+   患有慢性疾病的人如何看待自己及其在社会中的位置？

+   当人们成为医疗服务提供者时，他们的生活和身份有什么不同？

+   少数群体或弱势群体的长期健康结果是什么？这些结果与多数群体有何不同，为什么会有这种差异？

+   环境问题如何影响人们的健康，这些问题如何与社会结构/特权互动？

这只是其中的一部分——这个社会学领域涵盖了对人们生活和福祉至关重要的广泛内容。

在[www.stephaniekirmer.com](http://www.stephaniekirmer.com)上查看更多我的作品。

# 参考文献

[国会委员会和监管机构质疑Cigna系统，允许其医生拒绝索赔而无需…](https://www.propublica.org/article/cigna-health-insurance-denials-pxdx-congress-investigation?source=post_page-----7acaf9131278--------------------------------#:~:text=The%20letter%20follows%20an%20investigation,PXDX%20system%2C%20spending%20an%20average)

### 这些探查跟随ProPublica和Capitol Forum的调查，揭示了Cigna允许其医生拒绝数百个…

[UnitedHealth被指控使用有缺陷的AI拒绝老年患者必要的医疗覆盖](https://www.cbsnews.com/news/unitedhealth-lawsuit-ai-deny-claims-medicare-advantage-health-insurance-denials/?source=post_page-----7acaf9131278--------------------------------) [## 由诉讼声称]

### 过去受益者的家庭声称，UnitedHealth的AI系统“积极”拒绝了必要的医疗索赔…

[naviHealth官网](https://navihealth.com/?source=post_page-----7acaf9131278--------------------------------) [## 首页]

### 老年中心护理的未来已来

[navihealth官网](https://navihealth.com/?source=post_page-----7acaf9131278--------------------------------)
