- en: Using GPT-3.5-Turbo and GPT-4 for Predicting Humanitarian Data Categories
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨GPT-3.5-Turboå’ŒGPT-4è¿›è¡Œäººé“ä¸»ä¹‰æ•°æ®ç±»åˆ«é¢„æµ‹
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/using-gpt-3-5-turbo-and-gpt-4-to-apply-text-defined-data-quality-checks-on-humanitarian-datasets-6f02219c693c?source=collection_archive---------5-----------------------#2023-03-29](https://towardsdatascience.com/using-gpt-3-5-turbo-and-gpt-4-to-apply-text-defined-data-quality-checks-on-humanitarian-datasets-6f02219c693c?source=collection_archive---------5-----------------------#2023-03-29)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/using-gpt-3-5-turbo-and-gpt-4-to-apply-text-defined-data-quality-checks-on-humanitarian-datasets-6f02219c693c?source=collection_archive---------5-----------------------#2023-03-29](https://towardsdatascience.com/using-gpt-3-5-turbo-and-gpt-4-to-apply-text-defined-data-quality-checks-on-humanitarian-datasets-6f02219c693c?source=collection_archive---------5-----------------------#2023-03-29)
- en: '[](https://medium.com/@astrobagel?source=post_page-----6f02219c693c--------------------------------)[![Matthew
    Harris](../Images/4fa3264bb8a028633cd8d37093c16214.png)](https://medium.com/@astrobagel?source=post_page-----6f02219c693c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6f02219c693c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6f02219c693c--------------------------------)
    [Matthew Harris](https://medium.com/@astrobagel?source=post_page-----6f02219c693c--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@astrobagel?source=post_page-----6f02219c693c--------------------------------)[![Matthew
    Harris](../Images/4fa3264bb8a028633cd8d37093c16214.png)](https://medium.com/@astrobagel?source=post_page-----6f02219c693c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6f02219c693c--------------------------------)[![æ•°æ®ç§‘å­¦ä¹‹é“](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6f02219c693c--------------------------------)
    [Matthew Harris](https://medium.com/@astrobagel?source=post_page-----6f02219c693c--------------------------------)'
- en: Â·
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4a2cd25b8ff9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-gpt-3-5-turbo-and-gpt-4-to-apply-text-defined-data-quality-checks-on-humanitarian-datasets-6f02219c693c&user=Matthew+Harris&userId=4a2cd25b8ff9&source=post_page-4a2cd25b8ff9----6f02219c693c---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6f02219c693c--------------------------------)
    Â·23 min readÂ·Mar 29, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f02219c693c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-gpt-3-5-turbo-and-gpt-4-to-apply-text-defined-data-quality-checks-on-humanitarian-datasets-6f02219c693c&user=Matthew+Harris&userId=4a2cd25b8ff9&source=-----6f02219c693c---------------------clap_footer-----------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4a2cd25b8ff9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-gpt-3-5-turbo-and-gpt-4-to-apply-text-defined-data-quality-checks-on-humanitarian-datasets-6f02219c693c&user=Matthew+Harris&userId=4a2cd25b8ff9&source=post_page-4a2cd25b8ff9----6f02219c693c---------------------post_header-----------)
    å‘è¡¨åœ¨[æ•°æ®ç§‘å­¦ä¹‹é“](https://towardsdatascience.com/?source=post_page-----6f02219c693c--------------------------------)
    Â· 23åˆ†é’Ÿé˜…è¯» Â· 2023å¹´3æœˆ29æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f02219c693c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-gpt-3-5-turbo-and-gpt-4-to-apply-text-defined-data-quality-checks-on-humanitarian-datasets-6f02219c693c&user=Matthew+Harris&userId=4a2cd25b8ff9&source=-----6f02219c693c---------------------clap_footer-----------)'
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f02219c693c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-gpt-3-5-turbo-and-gpt-4-to-apply-text-defined-data-quality-checks-on-humanitarian-datasets-6f02219c693c&source=-----6f02219c693c---------------------bookmark_footer-----------)![](../Images/cdad9a981470d96cf832f828beeed3b8.png)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f02219c693c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-gpt-3-5-turbo-and-gpt-4-to-apply-text-defined-data-quality-checks-on-humanitarian-datasets-6f02219c693c&source=-----6f02219c693c---------------------bookmark_footer-----------)![](../Images/cdad9a981470d96cf832f828beeed3b8.png)'
- en: Image created by [Stable Diffusion](https://stablediffusionweb.com/#demo) with
    prompt â€˜Predicting Catsâ€™.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾åƒç”±[ç¨³å®šæ‰©æ•£](https://stablediffusionweb.com/#demo)åˆ›å»ºï¼Œæç¤ºè¯ä¸ºâ€œé¢„æµ‹çŒ«â€ã€‚
- en: '*TL;DR*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ€»ç»“*'
- en: '*In this article, I explore using GPT-3.5-Turbo and GPT-4 to categorize datasets
    without the need for labeled data or model training, by prompting the model with
    data excerpts and category definitions. Using a small sample of categorized â€˜Data
    Gridâ€™ datasets found on the amazing Humanitarian Data Exchange (HDX), zero-shot
    prompting of GPT-4 resulted in 96% accuracy when predicting category and 89% accuracy
    when predicting both category and sub-category. GPT-4 outperformed GPT-3.5-turbo
    for the same prompts, with 96% accuracy versus 66% for category. Especially useful
    was that the model could provide reasoning for its predictions which helped to
    identify improvements to the process. This is just a quick analysis involving
    a small number of records due to cost limitations, but it shows some promise for
    using Large Language Models for data quality checks and summarization. Limitations
    exist due to the maximum number of tokens allowed in prompts affecting the amount
    of data that can be included in data excerpts, as well as performance and cost
    challenges â€” especially if youâ€™re a small non-profit! â€” at this early stage of
    commercial generative AI.*'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘æ¢è®¨äº†ä½¿ç”¨GPT-3.5-Turboå’ŒGPT-4å¯¹æ•°æ®é›†è¿›è¡Œåˆ†ç±»ï¼Œè€Œä¸éœ€è¦æ ‡è®°æ•°æ®æˆ–æ¨¡å‹è®­ç»ƒï¼Œé€šè¿‡å‘æ¨¡å‹æä¾›æ•°æ®æ‘˜å½•å’Œç±»åˆ«å®šä¹‰ã€‚ä½¿ç”¨ä»ä»¤äººæƒŠå¹çš„äººé“ä¸»ä¹‰æ•°æ®äº¤æ¢ï¼ˆHDXï¼‰æ‰¾åˆ°çš„ä¸€å°éƒ¨åˆ†å·²åˆ†ç±»çš„â€œæ•°æ®ç½‘æ ¼â€æ•°æ®é›†ï¼ŒGPT-4çš„é›¶-shotæç¤ºåœ¨é¢„æµ‹ç±»åˆ«æ—¶è¾¾åˆ°äº†96%çš„å‡†ç¡®ç‡ï¼Œè€Œåœ¨é¢„æµ‹ç±»åˆ«å’Œå­ç±»åˆ«æ—¶è¾¾åˆ°äº†89%çš„å‡†ç¡®ç‡ã€‚GPT-4åœ¨ç›¸åŒæç¤ºä¸‹çš„è¡¨ç°ä¼˜äºGPT-3.5-Turboï¼Œç±»åˆ«å‡†ç¡®ç‡ä¸º96%å¯¹66%ã€‚å°¤å…¶æœ‰ç”¨çš„æ˜¯ï¼Œæ¨¡å‹èƒ½å¤Ÿæä¾›å…¶é¢„æµ‹çš„æ¨ç†ï¼Œè¿™æœ‰åŠ©äºè¯†åˆ«æ”¹è¿›è¿‡ç¨‹ã€‚è¿™åªæ˜¯ç”±äºæˆæœ¬é™åˆ¶è€Œæ¶‰åŠå°‘é‡è®°å½•çš„å¿«é€Ÿåˆ†æï¼Œä½†å®ƒæ˜¾ç¤ºäº†ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œæ•°æ®è´¨é‡æ£€æŸ¥å’Œæ€»ç»“çš„ä¸€äº›å‰æ™¯ã€‚ç”±äºæç¤ºä¸­å…è®¸çš„æœ€å¤§ä»¤ç‰Œæ•°é‡å½±å“æ•°æ®æ‘˜å½•ä¸­å¯ä»¥åŒ…å«çš„æ•°æ®é‡ï¼Œä»¥åŠæ€§èƒ½å’Œæˆæœ¬æŒ‘æˆ˜â€”â€”ç‰¹åˆ«æ˜¯å¦‚æœä½ æ˜¯ä¸€ä¸ªå°å‹éè¥åˆ©ç»„ç»‡ï¼â€”â€”åœ¨å•†ä¸šç”ŸæˆAIçš„æ—©æœŸé˜¶æ®µå­˜åœ¨å±€é™æ€§ã€‚*'
- en: The [Humanitarian Data Exchange](https://data.humdata.org/) (HDX) platform has
    a great feature called the [HDX Data Grid](https://centre.humdata.org/introducing-the-hdx-data-grid-a-way-to-find-and-fill-data-gaps/)
    which provides an overview of high-quality data coverage in six key crisis categories
    by country, see [here](https://data.humdata.org/group/tcd) for an example for
    Chad. The datasets which make it into the grid undergo a [series of rigorous tests](https://humanitarian.atlassian.net/wiki/spaces/HDX/pages/682393601/Data+Grid+Data+Completeness+Curation+Procedures)
    by the HDX team to determine coverage and quality, the first of which is to determine
    if the dataset is in an approved category.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[äººé“ä¸»ä¹‰æ•°æ®äº¤æ¢](https://data.humdata.org/)ï¼ˆHDXï¼‰å¹³å°æœ‰ä¸€ä¸ªå¾ˆæ£’çš„åŠŸèƒ½å«åš[HDXæ•°æ®ç½‘æ ¼](https://centre.humdata.org/introducing-the-hdx-data-grid-a-way-to-find-and-fill-data-gaps/)ï¼Œå®ƒæä¾›äº†æŒ‰å›½å®¶åˆ’åˆ†çš„å…­ä¸ªå…³é”®å±æœºç±»åˆ«çš„é«˜è´¨é‡æ•°æ®è¦†ç›–æ¦‚è¿°ï¼ŒæŸ¥çœ‹[è¿™é‡Œ](https://data.humdata.org/group/tcd)äº†è§£ä¹å¾—çš„ä¾‹å­ã€‚è¿›å…¥ç½‘æ ¼çš„æ•°æ®é›†ä¼šç»è¿‡HDXå›¢é˜Ÿ[ä¸€ç³»åˆ—ä¸¥æ ¼çš„æµ‹è¯•](https://humanitarian.atlassian.net/wiki/spaces/HDX/pages/682393601/Data+Grid+Data+Completeness+Curation+Procedures)ä»¥ç¡®å®šè¦†ç›–èŒƒå›´å’Œè´¨é‡ï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªæµ‹è¯•æ˜¯ç¡®å®šæ•°æ®é›†æ˜¯å¦åœ¨æ‰¹å‡†çš„ç±»åˆ«ä¸­ã€‚'
- en: I wondered if perhaps Large Language Models (LLMs) might be an efficient way
    to apply data quality and classification rules in situations where there might
    not be any labeled training data. It would also be convenient to provide rules
    in a human-readable text form that non-technical teams could easily maintain,
    and use these directly in order to eliminate the requirement for features engineering
    and model management.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨æƒ³ï¼Œä¹Ÿè®¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯èƒ½æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æ–¹æ³•æ¥åº”ç”¨æ•°æ®è´¨é‡å’Œåˆ†ç±»è§„åˆ™ï¼Œåœ¨é‚£äº›å¯èƒ½æ²¡æœ‰æ ‡è®°è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ã€‚è¿™ä¹Ÿå¾ˆæ–¹ä¾¿ï¼Œä»¥äººç±»å¯è¯»çš„æ–‡æœ¬å½¢å¼æä¾›è§„åˆ™ï¼ŒéæŠ€æœ¯å›¢é˜Ÿå¯ä»¥è½»æ¾ç»´æŠ¤ï¼Œå¹¶ç›´æ¥ä½¿ç”¨è¿™äº›è§„åˆ™ä»¥æ¶ˆé™¤å¯¹ç‰¹å¾å·¥ç¨‹å’Œæ¨¡å‹ç®¡ç†çš„éœ€æ±‚ã€‚
- en: Oh, and I also recently got early access to GPT-4 and wanted to take it for
    a bit of a spin! ğŸ™‚ â€¦ So decided to also do some analysis comparing performance
    with GPT-3.5-Turbo.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å“¦ï¼Œæˆ‘æœ€è¿‘ä¹Ÿè·å¾—äº†GPT-4çš„æ—©æœŸè®¿é—®æƒé™ï¼Œæƒ³è¦è¯•ä¸€è¯•ï¼ğŸ™‚â€¦â€¦æ‰€ä»¥å†³å®šä¹Ÿè¿›è¡Œä¸€äº›åˆ†æï¼Œæ¯”è¾ƒGPT-3.5-Turboçš„è¡¨ç°ã€‚
- en: Is the Dataset in an Approved Category?
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ•°æ®é›†æ˜¯å¦åœ¨å·²æ‰¹å‡†çš„ç±»åˆ«ä¸­ï¼Ÿ
- en: Looking at [The State of Humanitarian Data 2023 Annex B](https://data.humdata.org/dataset/2048a947-5714-4220-905b-e662cbcd14c8/resource/9d4121c6-b32b-4eb8-a707-209c79241970/download/state-of-open-humanitarian-data-2023.pdf),
    which outlines the criteria and categories used when assessing if data is of sufficient
    quality and coverage â€¦
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹[ã€Š2023å¹´äººé“ä¸»ä¹‰æ•°æ®ç°çŠ¶ é™„å½•Bã€‹](https://data.humdata.org/dataset/2048a947-5714-4220-905b-e662cbcd14c8/resource/9d4121c6-b32b-4eb8-a707-209c79241970/download/state-of-open-humanitarian-data-2023.pdf)ï¼Œå…¶ä¸­æ¦‚è¿°äº†åœ¨è¯„ä¼°æ•°æ®æ˜¯å¦å…·æœ‰è¶³å¤Ÿè´¨é‡å’Œè¦†ç›–èŒƒå›´æ—¶ä½¿ç”¨çš„æ ‡å‡†å’Œç±»åˆ«â€¦â€¦
- en: The first step in determining whether a dataset should be included in a Data
    Grid is to check whether the dataset meets the thematic requirement defined in
    Annex A. Datasets that are not considered relevant are automatically excluded.
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç¡®å®šæ•°æ®é›†æ˜¯å¦åº”åŒ…å«åœ¨æ•°æ®ç½‘æ ¼ä¸­çš„ç¬¬ä¸€æ­¥æ˜¯æ£€æŸ¥æ•°æ®é›†æ˜¯å¦ç¬¦åˆé™„å½•Aä¸­å®šä¹‰çš„ä¸»é¢˜è¦æ±‚ã€‚ä¸ç›¸å…³çš„æ•°æ®é›†å°†è¢«è‡ªåŠ¨æ’é™¤ã€‚
- en: The categories in Annex A are â€¦
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: é™„å½•Aä¸­çš„ç±»åˆ«æ˜¯â€¦â€¦
- en: '![](../Images/e935a601b4060d8d5788b7c76f5754aa.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e935a601b4060d8d5788b7c76f5754aa.png)'
- en: Accepted data categories for HDX Data Grid datasets (See HDXâ€™s yearly report,
    Annex A [[1](https://data.humdata.org/dataset/2048a947-5714-4220-905b-e662cbcd14c8/resource/9d4121c6-b32b-4eb8-a707-209c79241970/download/state-of-open-humanitarian-data-2023.pdf)])
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: HDXæ•°æ®ç½‘æ ¼æ•°æ®é›†çš„æ¥å—æ•°æ®ç±»åˆ«ï¼ˆè§HDXå¹´åº¦æŠ¥å‘Šï¼Œé™„å½•A [[1](https://data.humdata.org/dataset/2048a947-5714-4220-905b-e662cbcd14c8/resource/9d4121c6-b32b-4eb8-a707-209c79241970/download/state-of-open-humanitarian-data-2023.pdf)]ï¼‰
- en: We could write a classifier to assign these categories to our datasets based
    on the data they contain, but we only know categories for the subset of datasets
    that were approved for HDX Data Grid. If prompting alone can classify our data
    without having to manually label it, that would be fantastic. This is a zero-shot
    task[[2](https://arxiv.org/pdf/2005.14165.pdf)], one of the amazing properties
    of Large Language Models where classification can occur without training specifically
    for the task or providing examples.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ç¼–å†™åˆ†ç±»å™¨å°†è¿™äº›ç±»åˆ«åˆ†é…ç»™æˆ‘ä»¬çš„æ•°æ®é›†ï¼Œä½†æˆ‘ä»¬åªçŸ¥é“å·²æ‰¹å‡†çš„HDXæ•°æ®ç½‘æ ¼æ•°æ®é›†çš„å­é›†çš„ç±»åˆ«ã€‚å¦‚æœä»…é€šè¿‡æç¤ºå°±èƒ½å¯¹æˆ‘ä»¬çš„æ•°æ®è¿›è¡Œåˆ†ç±»è€Œä¸éœ€è¦æ‰‹åŠ¨æ ‡è®°ï¼Œé‚£å°†æ˜¯å¤ªæ£’äº†ã€‚è¿™æ˜¯ä¸€ä¸ªé›¶-shotä»»åŠ¡[[2](https://arxiv.org/pdf/2005.14165.pdf)]ï¼Œè¿™æ˜¯å¤§è¯­è¨€æ¨¡å‹çš„ä¸€ä¸ªæƒŠäººç‰¹æ€§ï¼Œå³å¯ä»¥åœ¨æ²¡æœ‰ä¸“é—¨ä¸ºä»»åŠ¡è®­ç»ƒæˆ–æä¾›ç¤ºä¾‹çš„æƒ…å†µä¸‹è¿›è¡Œåˆ†ç±»ã€‚
- en: Predicting Dataset Category for a Single Table
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸ºå•ä¸ªè¡¨é¢„æµ‹æ•°æ®é›†ç±»åˆ«
- en: Letâ€™s read the categories data and use it to generate prompt text defining each
    one â€¦
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è¯»å–ç±»åˆ«æ•°æ®ï¼Œå¹¶ä½¿ç”¨å®ƒç”Ÿæˆå®šä¹‰æ¯ä¸€ç±»çš„æç¤ºæ–‡æœ¬â€¦â€¦
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Which gives â€¦
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç»™å‡ºâ€¦â€¦
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here is a test file related to agriculture which is an unsupported category
    and which doesnâ€™t appear on HDXâ€™s Data Grid â€¦
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€ä¸ªä¸å†œä¸šç›¸å…³çš„æµ‹è¯•æ–‡ä»¶ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸å—æ”¯æŒçš„ç±»åˆ«ï¼Œå¹¶ä¸”ä¸å‡ºç°åœ¨HDXçš„æ•°æ®ç½‘æ ¼ä¸­â€¦â€¦
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/e2483882c28d40f0030fe8f55976ba5d.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e2483882c28d40f0030fe8f55976ba5d.png)'
- en: Excerpt of a dataset table which doesnâ€™t fall into one of the supported HDX
    categories
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæ•°æ®é›†è¡¨çš„æ‘˜å½•ï¼Œè¯¥è¡¨ä¸å±äºHDXæ”¯æŒçš„ç±»åˆ«ä¹‹ä¸€
- en: In the above, I have intentionally avoided parsing the table to tidy things
    up (see [here](https://medium.com/towards-data-science/parsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45)
    for more on that). Instead, weâ€™ll throw the raw table at GPT to see how it performs.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šè¿°å†…å®¹ä¸­ï¼Œæˆ‘æ•…æ„é¿å…äº†å¯¹è¡¨æ ¼è¿›è¡Œè§£æä»¥æ•´ç†å†…å®¹ï¼ˆæœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§[è¿™é‡Œ](https://medium.com/towards-data-science/parsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45)ï¼‰ã€‚ç›¸åï¼Œæˆ‘ä»¬å°†åŸå§‹è¡¨æ ¼æ‰”ç»™GPTï¼Œçœ‹çœ‹å®ƒçš„è¡¨ç°å¦‚ä½•ã€‚
- en: Represented as a CSV string for the prompt, the table looks like this â€¦
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºæç¤ºçš„CSVå­—ç¬¦ä¸²è¡¨ç¤ºï¼Œè¡¨æ ¼å¦‚ä¸‹æ‰€ç¤ºâ€¦â€¦
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: For the prompt, weâ€™ll combine category definitions into one chat prompt, and
    some instructions and the table being analyzed into a second â€¦
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæç¤ºï¼Œæˆ‘ä»¬å°†ç±»åˆ«å®šä¹‰åˆå¹¶ä¸ºä¸€ä¸ªèŠå¤©æç¤ºï¼Œå¹¶å°†ä¸€äº›æŒ‡ä»¤å’Œæ­£åœ¨åˆ†æçš„è¡¨æ ¼åˆå¹¶ä¸ºç¬¬äºŒä¸ªâ€¦â€¦
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: So prompt 1 â€¦
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æç¤º1â€¦â€¦
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: And prompt 2 â€¦
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæç¤º2â€¦â€¦
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Letâ€™s try this with both **GPT-3.5-turbo** and **GPT-4** â€¦
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å°è¯•ä½¿ç”¨**GPT-3.5-turbo**å’Œ**GPT-4**â€¦â€¦
- en: '[PRE7]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We get â€¦
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¾—åˆ°â€¦â€¦
- en: '[PRE8]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Both GPT-3.5-turbo and GPT-4 worked perfectly and identified that our table
    does *not* fall into one of the required categories (itâ€™s related to agriculture).
    I also like the reasoning, which is exactly correct at least in this one example.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**GPT-3.5-turbo**å’Œ**GPT-4**éƒ½å®Œç¾åœ°å·¥ä½œï¼Œå¹¶è¯†åˆ«å‡ºæˆ‘ä»¬çš„è¡¨æ ¼*ä¸*å±äºæ‰€éœ€ç±»åˆ«ä¹‹ä¸€ï¼ˆå®ƒä¸å†œä¸šç›¸å…³ï¼‰ã€‚æˆ‘ä¹Ÿå–œæ¬¢è¿™ç§æ¨ç†ï¼Œè‡³å°‘åœ¨è¿™ä¸ªä¾‹å­ä¸­å®Œå…¨æ­£ç¡®ã€‚'
- en: Letâ€™s try with a table that is in a supported category, [Food prices for Chad](https://data.humdata.org/dataset/wfp-food-prices-for-chad)
    as found on the [Chad HDX Data Grid](https://data.humdata.org/group/tcd). The
    CSV string for this file, taking the top 20 rows, looks like this â€¦
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç”¨ä¸€ä¸ªåœ¨å—æ”¯æŒç±»åˆ«ä¸­çš„è¡¨è¿›è¡Œå°è¯•ï¼Œ[æŸ¥å¾·çš„é£Ÿå“ä»·æ ¼](https://data.humdata.org/dataset/wfp-food-prices-for-chad)ï¼Œå¦‚åœ¨[æŸ¥å¾·HDXæ•°æ®ç½‘æ ¼](https://data.humdata.org/group/tcd)ä¸Šæ‰¾åˆ°çš„ã€‚è¿™ä¸ªæ–‡ä»¶çš„CSVå­—ç¬¦ä¸²ï¼Œå–å‰20è¡Œï¼Œå¦‚ä¸‹æ‰€ç¤ºâ€¦â€¦
- en: '[PRE9]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Prompting with the same format we get â€¦
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ç›¸åŒæ ¼å¼çš„æç¤ºï¼Œæˆ‘ä»¬å¾—åˆ°â€¦â€¦
- en: '[PRE10]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'So again, both models were correct. The category for this dataset is indeed
    â€˜Food Security & Nutrition : Food Pricesâ€™.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å†è¯´ä¸€æ¬¡ï¼Œä¸¤ç§æ¨¡å‹éƒ½æ˜¯æ­£ç¡®çš„ã€‚è¯¥æ•°æ®é›†çš„ç±»åˆ«ç¡®å®æ˜¯â€œé£Ÿå“å®‰å…¨ä¸è¥å…»ï¼šé£Ÿå“ä»·æ ¼â€ã€‚
- en: OK, looking good for some quick examples using a single table. What about identifying
    the category based on the contents of *multiple* tables?
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œå¯¹äºä½¿ç”¨å•ä¸ªè¡¨è¿›è¡Œçš„ä¸€äº›å¿«é€Ÿç¤ºä¾‹ï¼Œçœ‹èµ·æ¥ä¸é”™ã€‚é‚£ä¹ˆï¼ŒåŸºäº*å¤šä¸ª*è¡¨çš„å†…å®¹æ¥è¯†åˆ«ç±»åˆ«å‘¢ï¼Ÿ
- en: Predicting a Dataset Category Using Excerpts from Multiple Tables
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ¥è‡ªå¤šä¸ªè¡¨çš„æ‘˜å½•é¢„æµ‹æ•°æ®é›†ç±»åˆ«
- en: In HDX a dataset can have multiple â€˜Resourcesâ€™ (files), and for data in Excel,
    these files can have multiple tables in sheets. So just looking at just one table
    from the dataset might not tell the whole story, we need to make a decision based
    on multiple tables. This is important because among all the tables in a dataset
    there might be tabs for documentation about the dataset, field lookups, and more,
    which by themselves wouldnâ€™t be enough to deduce the category of all data in the
    dataset.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨HDXä¸­ï¼Œä¸€ä¸ªæ•°æ®é›†å¯ä»¥æœ‰å¤šä¸ªâ€œèµ„æºâ€ï¼ˆæ–‡ä»¶ï¼‰ï¼Œè€Œå¯¹äºExcelä¸­çš„æ•°æ®ï¼Œè¿™äº›æ–‡ä»¶å¯èƒ½åœ¨å·¥ä½œè¡¨ä¸­åŒ…å«å¤šä¸ªè¡¨ã€‚å› æ­¤ï¼ŒåªæŸ¥çœ‹æ•°æ®é›†ä¸­çš„ä¸€ä¸ªè¡¨å¯èƒ½æ— æ³•å®Œå…¨äº†è§£æƒ…å†µï¼Œæˆ‘ä»¬éœ€è¦æ ¹æ®å¤šä¸ªè¡¨åšå‡ºå†³ç­–ã€‚è¿™ä¸€ç‚¹å¾ˆé‡è¦ï¼Œå› ä¸ºåœ¨æ•°æ®é›†ä¸­çš„æ‰€æœ‰è¡¨ä¸­å¯èƒ½ä¼šæœ‰å…³äºæ•°æ®é›†ã€å­—æ®µæŸ¥æ‰¾ç­‰çš„æ–‡æ¡£æ ‡ç­¾ï¼Œè€Œè¿™äº›æ ‡ç­¾æœ¬èº«ä¸è¶³ä»¥æ¨æ–­æ•°æ®é›†ä¸­æ‰€æœ‰æ•°æ®çš„ç±»åˆ«ã€‚
- en: Before ChatGPT API was launched, this would have been difficult due to token
    limits. However, ChatGPT allows us to specify [multiple prompts](https://platform.openai.com/docs/guides/chat)
    as well as having [increased token limits](https://platform.openai.com/docs/guides/rate-limits/overview).
    As weâ€™ll see, still a limiting factor, but an improvement on previous models.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ChatGPT APIæ¨å‡ºä¹‹å‰ï¼Œè¿™ä¼šç”±äºä»¤ç‰Œé™åˆ¶è€Œå˜å¾—å›°éš¾ã€‚ç„¶è€Œï¼ŒChatGPTå…è®¸æˆ‘ä»¬æŒ‡å®š[å¤šä¸ªæç¤º](https://platform.openai.com/docs/guides/chat)ï¼Œå¹¶ä¸”æœ‰[å¢åŠ çš„ä»¤ç‰Œé™åˆ¶](https://platform.openai.com/docs/guides/rate-limits/overview)ã€‚å¦‚æˆ‘ä»¬æ‰€è§ï¼Œè¿™ä»ç„¶æ˜¯ä¸€ä¸ªé™åˆ¶å› ç´ ï¼Œä½†æ¯”ä»¥å‰çš„æ¨¡å‹æœ‰æ‰€æ”¹è¿›ã€‚
- en: The sample data for this analysis â€” provided in the notebook repo â€” was extracted
    from HDX by â€¦
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬åˆ†æçš„æ ·æœ¬æ•°æ®â€”â€”åœ¨ç¬”è®°æœ¬ä»“åº“ä¸­æä¾›â€”â€”æ˜¯ä»HDXä¸­æå–çš„ï¼Œç”±â€¦
- en: Looping over datasets
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: éå†æ•°æ®é›†
- en: For each dataset loop over files
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ªæ•°æ®é›†ï¼Œéå†æ–‡ä»¶
- en: For each tabular file, download it
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ªè¡¨æ ¼æ–‡ä»¶ï¼Œä¸‹è½½å®ƒ
- en: For each tab in the file create an excerpt of the table (first 20 rows) in CSV
    format
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹äºæ–‡ä»¶ä¸­çš„æ¯ä¸ªæ ‡ç­¾ï¼Œåˆ›å»ºä¸€ä¸ªè¡¨æ ¼æ‘˜å½•ï¼ˆå‰20è¡Œï¼‰ä»¥CSVæ ¼å¼
- en: '*Note: I havenâ€™t included this code to avoid too much traffic on HDX, but if
    interested in this code, message me here on Medium.*'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ³¨æ„ï¼šæˆ‘æ²¡æœ‰åŒ…å«è¿™æ®µä»£ç ä»¥é¿å…HDXä¸Šçš„æµé‡è¿‡å¤šï¼Œä½†å¦‚æœå¯¹è¿™æ®µä»£ç æ„Ÿå…´è¶£ï¼Œå¯ä»¥åœ¨Mediumä¸Šç»™æˆ‘ç•™è¨€ã€‚*'
- en: So each dataset has a field like this â€¦
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æ¯ä¸ªæ•°æ®é›†éƒ½æœ‰ä¸€ä¸ªè¿™æ ·çš„å­—æ®µâ€¦
- en: '[PRE11]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Having this structure for each dataset allows us to generate multiple prompts
    for each table â€¦
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ªæ•°æ®é›†ï¼Œè¿™ç§ç»“æ„å…è®¸æˆ‘ä»¬ä¸ºæ¯ä¸ªè¡¨ç”Ÿæˆå¤šä¸ªæç¤ºâ€¦
- en: '[PRE12]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Which generates prompts like this â€¦
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼šç”Ÿæˆåƒè¿™æ ·çš„æç¤ºâ€¦
- en: '**Prompt 1 â€” Defining the categories**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**æç¤º 1 â€” å®šä¹‰ç±»åˆ«**'
- en: '[PRE13]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '**Prompt 2 â€” Specifying Dataset name and introducing table excerpts**'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**æç¤º 2 â€” æŒ‡å®šæ•°æ®é›†åç§°å¹¶ä»‹ç»è¡¨æ ¼æ‘˜å½•**'
- en: '[PRE14]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '**Prompt 3, 4, etc â€”Providing Table Excerpts**'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**æç¤º 3ã€4 ç­‰ â€” æä¾›è¡¨æ ¼æ‘˜å½•**'
- en: '[PRE15]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '**Final Prompt â€” Our request to classify the data**'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**æœ€ç»ˆæç¤º â€” æˆ‘ä»¬è¯·æ±‚å¯¹æ•°æ®è¿›è¡Œåˆ†ç±»**'
- en: '[PRE16]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Youâ€™ll notice in the last prompt that weâ€™ve been a bit demanding:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¼šæ³¨æ„åˆ°åœ¨æœ€åçš„æç¤ºä¸­ï¼Œæˆ‘ä»¬è¦æ±‚æœ‰ç‚¹å¤šï¼š
- en: We request that the model indicates if the data *doesnâ€™t* align with our categories
    so we catch negative cases and the model doesnâ€™t try and assign a category to
    every dataset. Some will fall outside of the approved categories
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¦æ±‚æ¨¡å‹æŒ‡æ˜æ•°æ®*ä¸*ç¬¦åˆæˆ‘ä»¬çš„ç±»åˆ«ï¼Œä»¥ä¾¿æˆ‘ä»¬æ•æ‰è´Ÿé¢æƒ…å†µï¼Œæ¨¡å‹ä¸ä¼šå°è¯•ä¸ºæ¯ä¸ªæ•°æ®é›†åˆ†é…ä¸€ä¸ªç±»åˆ«ã€‚æœ‰äº›å°†ä¸ç¬¦åˆæ‰¹å‡†çš„ç±»åˆ«
- en: Request that category â€˜exactly matchesâ€™. Without this GPT-3.5-Turbo would merrily
    construct new ones!
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯·æ±‚ç±»åˆ«â€œå®Œå…¨åŒ¹é…â€ã€‚å¦‚æœæ²¡æœ‰è¿™ä¸ªè¦æ±‚ï¼ŒGPT-3.5-Turboå¯èƒ½ä¼šéšæ„æ„é€ æ–°çš„ç±»åˆ«ï¼
- en: If the model does identify a category, wrap it in â€˜|â€™ for easier parsing
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæ¨¡å‹ç¡®å®è¯†åˆ«å‡ºä¸€ä¸ªç±»åˆ«ï¼Œå°†å…¶ç”¨â€˜|â€™æ‹¬èµ·æ¥ï¼Œä»¥ä¾¿æ›´å®¹æ˜“è§£æ
- en: We ask the model to provide its reasoning as this has been shown to improve
    results [[3](https://arxiv.org/pdf/2205.11916.pdf)]. Itâ€™s also useful to see why
    the category decision was made to highlight cases of hallucination
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¦æ±‚æ¨¡å‹æä¾›å…¶æ¨ç†è¿‡ç¨‹ï¼Œå› ä¸ºè¿™å·²è¢«è¯æ˜å¯ä»¥æ”¹å–„ç»“æœ[[3](https://arxiv.org/pdf/2205.11916.pdf)]ã€‚äº†è§£ç±»åˆ«å†³ç­–çš„åŸå› ä¹Ÿæœ‰åŠ©äºçªå‡ºè™šå‡ä¿¡æ¯çš„æƒ…å†µ
- en: Finally, for our discussion later, we request the second most likely category
    as well
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€åï¼Œä¸ºäº†åç»­è®¨è®ºï¼Œæˆ‘ä»¬è¿˜è¯·æ±‚ç¬¬äºŒä¸ªæœ€å¯èƒ½çš„ç±»åˆ«
- en: Also, if you look closely at the code in the predict function, I have used a
    [temperature](https://platform.openai.com/docs/api-reference/chat/create) of 0.0
    for this study. Temperature controls how random the output is, and since we want
    things to be nice and specific rather than text describing quantum physics in
    the voice of [cookie monster](https://www.youtube.com/watch?v=Ye8mB6VsUHw), I
    set it as low as possible.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œå¦‚æœä½ ä»”ç»†æŸ¥çœ‹é¢„æµ‹å‡½æ•°ä¸­çš„ä»£ç ï¼Œæˆ‘åœ¨è¿™é¡¹ç ”ç©¶ä¸­ä½¿ç”¨äº†[æ¸©åº¦](https://platform.openai.com/docs/api-reference/chat/create)ä¸º0.0ã€‚æ¸©åº¦æ§åˆ¶è¾“å‡ºçš„éšæœºç¨‹åº¦ï¼Œç”±äºæˆ‘ä»¬å¸Œæœ›ç»“æœæ—¢å‡†ç¡®åˆå…·ä½“ï¼Œè€Œä¸æ˜¯æè¿°é‡å­ç‰©ç†çš„æ–‡æœ¬ï¼Œæ‰€ä»¥æˆ‘å°†å…¶è®¾ç½®ä¸ºå°½å¯èƒ½ä½ã€‚
- en: Making our predictions â€¦
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆæˆ‘ä»¬çš„é¢„æµ‹â€¦
- en: '[PRE17]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: How did we do?
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åšå¾—æ€ä¹ˆæ ·ï¼Ÿ
- en: '[PRE18]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '*Note: Though we passed in 150 datasets to predict, the API timed out quite
    a bit for GPT-4 and calls werenâ€™t retried to save costs. This is entirely to be
    expected for GPT-4 which is in early preview. Some prompts also exceeded the token
    length for GPT-3.5-Turbo. The following results therefore apply to 53 predictions
    made by both GPT-3.5-turbo and GPT-4.*'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ³¨æ„ï¼šè™½ç„¶æˆ‘ä»¬æä¾›äº†150ä¸ªæ•°æ®é›†è¿›è¡Œé¢„æµ‹ï¼Œä½†GPT-4çš„APIæ—¶å¸¸è¶…æ—¶ï¼Œä¸”æœªé‡è¯•è°ƒç”¨ä»¥èŠ‚çœæˆæœ¬ã€‚è¿™å¯¹äºå¤„äºæ—©æœŸé¢„è§ˆé˜¶æ®µçš„GPT-4æ˜¯å®Œå…¨å¯ä»¥é¢„æœŸçš„ã€‚æœ‰äº›æç¤ºä¹Ÿè¶…å‡ºäº†GPT-3.5-Turboçš„ä»¤ç‰Œé•¿åº¦ã€‚å› æ­¤ï¼Œä»¥ä¸‹ç»“æœé€‚ç”¨äºGPT-3.5-turboå’ŒGPT-4åšå‡ºçš„53ä¸ªé¢„æµ‹ã€‚*'
- en: 'For predicting the category only, for example, â€œCoordination & Contextâ€ when
    the full category and sub-category is â€œCoordination & Context : Humanitarian Accessâ€
    â€¦'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 'æ¯”å¦‚ï¼Œä»…é¢„æµ‹ç±»åˆ«ï¼Œå¦‚â€œCoordination & Contextâ€ï¼Œå½“å®Œæ•´ç±»åˆ«å’Œå­ç±»åˆ«ä¸ºâ€œCoordination & Context : Humanitarian
    Accessâ€æ—¶â€¦â€¦'
- en: '[PRE19]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: GPT-4 was nearly always able to identify the correct category (**96%** accuracy),
    performing significantly better than GPT-3.5-turbo for the same prompts (66% accuracy).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4å‡ ä¹æ€»æ˜¯èƒ½å¤Ÿè¯†åˆ«æ­£ç¡®çš„ç±»åˆ«ï¼ˆ**96%**å‡†ç¡®ç‡ï¼‰ï¼Œåœ¨ç›¸åŒæç¤ºä¸‹è¡¨ç°æ˜¾è‘—ä¼˜äºGPT-3.5-turboï¼ˆ66%å‡†ç¡®ç‡ï¼‰ã€‚
- en: For predicting the whole category *and* sub-category together â€¦
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºåŒæ—¶é¢„æµ‹æ•´ä¸ªç±»åˆ«*å’Œ*å­ç±»åˆ«â€¦â€¦
- en: '[PRE20]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Again GPT-4 outperformed GPT-3.5 by a significant margin. **89%** accuracy is
    actually pretty good given â€¦.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡å¼ºè°ƒï¼ŒGPT-4æ¯”GPT-3.5è¡¨ç°æ˜¾è‘—ä¼˜è¶Šã€‚**89%**çš„å‡†ç¡®ç‡å®é™…ä¸Šç›¸å½“ä¸é”™ï¼Œé‰´äºâ€¦â€¦
- en: '**We *only* provided a set of text rules and didnâ€™t label data, train a classifier
    or provide any examples**.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æˆ‘ä»¬*ä»…ä»…*æä¾›äº†ä¸€ç»„æ–‡æœ¬è§„åˆ™ï¼Œæ²¡æœ‰æ ‡è®°æ•°æ®ã€è®­ç»ƒåˆ†ç±»å™¨æˆ–æä¾›ä»»ä½•ç¤ºä¾‹**ã€‚'
- en: In fact, if we look at the examples where it failed the predictions â€¦
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šï¼Œå¦‚æœæˆ‘ä»¬æŸ¥çœ‹é‚£äº›é¢„æµ‹å¤±è´¥çš„ç¤ºä¾‹â€¦â€¦
- en: '[PRE21]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We get â€¦
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¾—åˆ°â€¦â€¦
- en: '[PRE22]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: A couple of things jump out. Datasets like â€˜mozambique-attacks-on-aid-operations-education-health-and-protectionâ€™,
    have a mix of data files related to both healthcare and attacks.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å‡ ä»¶äº‹å¼•èµ·äº†æ³¨æ„ã€‚åƒâ€˜mozambique-attacks-on-aid-operations-education-health-and-protectionâ€™è¿™æ ·çš„æ•°æ®é›†ï¼ŒåŒ…å«äº†ä¸åŒ»ç–—ä¿å¥å’Œæ”»å‡»ç›¸å…³çš„æ•°æ®æ–‡ä»¶ã€‚
- en: '![](../Images/0f406a7ab9b745351ab0fb8adb6ef54a.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0f406a7ab9b745351ab0fb8adb6ef54a.png)'
- en: So assuming one category per dataset might not be the best way to frame the
    problem, datasets are reused across categories.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå‡è®¾æ¯ä¸ªæ•°æ®é›†åªæœ‰ä¸€ä¸ªç±»åˆ«å¯èƒ½ä¸æ˜¯è§£å†³é—®é¢˜çš„æœ€ä½³æ–¹å¼ï¼Œæ•°æ®é›†åœ¨ç±»åˆ«ä¹‹é—´è¢«é‡å¤ä½¿ç”¨ã€‚
- en: In about half the cases where GPT-4 was incorrect, the second-place category
    it predicted was correct. Looking at the model output for one of these cases,
    [Ukranian border crossings](https://data.humdata.org/dataset/ukraine-border-crossings)
    â€¦
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨GPT-4é”™è¯¯çš„çº¦ä¸€åŠçš„æ¡ˆä¾‹ä¸­ï¼Œå®ƒé¢„æµ‹çš„ç¬¬äºŒåç±»åˆ«æ˜¯æ­£ç¡®çš„ã€‚æŸ¥çœ‹è¿™äº›æ¡ˆä¾‹ä¸­çš„ä¸€ä¸ªæ¨¡å‹è¾“å‡ºï¼Œ[ä¹Œå…‹å…°è¾¹ç•Œç©¿è¶Š](https://data.humdata.org/dataset/ukraine-border-crossings)â€¦â€¦
- en: '[PRE23]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'What is pretty cool is its explanation of *why* it didnâ€™t choose â€˜Coordination
    & Context : Humanitarian Accessâ€™, because â€˜*â€¦it does not specifically focus on
    access constraints*â€™. Here is the category definition â€¦'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 'å¾ˆé…·çš„ä¸€ç‚¹æ˜¯å®ƒè§£é‡Šäº†*ä¸ºä»€ä¹ˆ*æ²¡æœ‰é€‰æ‹©â€˜Coordination & Context : Humanitarian Accessâ€™ï¼Œå› ä¸ºâ€˜*â€¦â€¦å®ƒå¹¶ä¸ç‰¹åˆ«å…³æ³¨è®¿é—®é™åˆ¶*â€™ã€‚è¿™æ˜¯ç±»åˆ«å®šä¹‰â€¦â€¦'
- en: 'Coordination & Context : Humanitarian Access: Tabular or vector data describing
    the location of natural hazards, permissions, active fighting, or other access
    constraints that impact the delivery of humanitarian interventions.'
  id: totrans-100
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'Coordination & Context : Humanitarian Accessï¼šè¡¨æ ¼æˆ–çŸ¢é‡æ•°æ®ï¼Œæè¿°è‡ªç„¶ç¾å®³ã€è®¸å¯ã€æ¿€çƒˆæˆ˜æ–—æˆ–å…¶ä»–å½±å“äººé“å¹²é¢„äº¤ä»˜çš„è®¿é—®é™åˆ¶çš„ä½ç½®ã€‚'
- en: So GPT-4 seems to be following the category rule to the word. There is some
    more nuance to the classification that the HDX team applies where border-crossing
    datasets are very reasonably related to humanitarian access. So perhaps one way
    to improve model prediction in this particular case would be to add additional
    text to the category definition indicating border crossing can relate to humanitarian
    access.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼ŒGPT-4ä¼¼ä¹ä¸¥æ ¼éµå¾ªç±»åˆ«è§„åˆ™ã€‚HDXå›¢é˜Ÿåº”ç”¨çš„åˆ†ç±»æœ‰ä¸€äº›æ›´ç»†è‡´çš„åŒºåˆ«ï¼Œå…¶ä¸­è·¨å¢ƒæ•°æ®é›†ä¸äººé“ä¸»ä¹‰è®¿é—®æœ‰å¾ˆåˆç†çš„å…³ç³»ã€‚å› æ­¤ï¼Œä¹Ÿè®¸æé«˜æ¨¡å‹åœ¨è¿™ç§æƒ…å†µä¸‹é¢„æµ‹çš„ä¸€ä¸ªæ–¹æ³•æ˜¯å‘ç±»åˆ«å®šä¹‰ä¸­æ·»åŠ é¢å¤–çš„æ–‡æœ¬ï¼ŒæŒ‡æ˜è¾¹ç•Œç©¿è¶Šå¯èƒ½ä¸äººé“ä¸»ä¹‰è®¿é—®ç›¸å…³ã€‚
- en: The takeaway here is that GPT-4 performed amazingly well and that the few incorrect
    predictions were due to how the problem was framed poorly by me (datasets can
    have multiple categories) and perhaps text used to define categories.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„å…³é”®æ˜¯GPT-4è¡¨ç°éå¸¸å‡ºè‰²ï¼Œè€Œå°‘æ•°ä¸æ­£ç¡®çš„é¢„æµ‹æ˜¯ç”±äºæˆ‘å¯¹é—®é¢˜çš„æ¡†å®šä¸å½“ï¼ˆæ•°æ®é›†å¯ä»¥æœ‰å¤šä¸ªç±»åˆ«ï¼‰ï¼Œä»¥åŠå®šä¹‰ç±»åˆ«çš„æ–‡æœ¬å¯èƒ½å­˜åœ¨çš„é—®é¢˜ã€‚
- en: Conclusion
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: The technique seems to be quite promising. We were able to achieve some good
    results **without any requirement to set labels, train models, or provide examples
    in prompts.** Additionally, the data summarization capabilities of models like
    GPT-4 are really impressive, helping with debugging model predictions, and might
    also be a nice way to provide quick data overviews.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æŠ€æœ¯çœ‹èµ·æ¥éå¸¸æœ‰å‰é€”ã€‚æˆ‘ä»¬èƒ½å¤Ÿè·å¾—ä¸€äº›è‰¯å¥½çš„ç»“æœï¼Œ**æ— éœ€è®¾ç½®æ ‡ç­¾ã€è®­ç»ƒæ¨¡å‹æˆ–åœ¨æç¤ºä¸­æä¾›ç¤ºä¾‹**ã€‚æ­¤å¤–ï¼Œåƒ GPT-4 è¿™æ ·çš„æ¨¡å‹çš„æ•°æ®æ€»ç»“èƒ½åŠ›ç¡®å®ä»¤äººå°è±¡æ·±åˆ»ï¼Œå¸®åŠ©è°ƒè¯•æ¨¡å‹é¢„æµ‹ï¼Œä¹Ÿå¯èƒ½æ˜¯æä¾›å¿«é€Ÿæ•°æ®æ¦‚è§ˆçš„ä¸é”™æ–¹æ³•ã€‚
- en: 'However, there are some caveats:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œå­˜åœ¨ä¸€äº›è­¦ç¤ºï¼š
- en: The amount of data used for this study was very limited due to cost and the
    fact GPT-4 is only in an early preview. Future studies would need to use more
    data of course.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”±äºæˆæœ¬å’Œ GPT-4 ä»å¤„äºæ—©æœŸé¢„è§ˆé˜¶æ®µï¼Œè¿™é¡¹ç ”ç©¶æ‰€ä½¿ç”¨çš„æ•°æ®é‡éå¸¸æœ‰é™ã€‚æœªæ¥çš„ç ”ç©¶å½“ç„¶éœ€è¦ä½¿ç”¨æ›´å¤šçš„æ•°æ®ã€‚
- en: Prompt length is currently a limiting factor, the study above only included
    datasets with less than 4 tables to avoid breaching token limits when prompting
    with table excerpts. HDX datasets can have more tables than this and having larger
    table excerpts might have been desirable in some cases. Vendors such as OpenAI
    seem to be progressively increasing token limits, so over time perhaps this becomes
    less of an issue.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›®å‰æç¤ºé•¿åº¦æ˜¯ä¸€ä¸ªé™åˆ¶å› ç´ ï¼Œä¸Šè¿°ç ”ç©¶åªåŒ…æ‹¬äº†å°‘äº4ä¸ªè¡¨çš„æ•°æ®é›†ï¼Œä»¥é¿å…åœ¨æç¤ºè¡¨æ ¼æ‘˜å½•æ—¶è¶…å‡º token é™åˆ¶ã€‚HDX æ•°æ®é›†å¯èƒ½åŒ…å«æ¯”è¿™æ›´å¤šçš„è¡¨æ ¼ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæ‹¥æœ‰æ›´å¤§çš„è¡¨æ ¼æ‘˜å½•å¯èƒ½ä¼šæ›´æœ‰ä»·å€¼ã€‚åƒ
    OpenAI è¿™æ ·çš„ä¾›åº”å•†ä¼¼ä¹åœ¨é€æ­¥å¢åŠ  token é™åˆ¶ï¼Œå› æ­¤éšç€æ—¶é—´çš„æ¨ç§»ï¼Œè¿™å¯èƒ½ä¼šå˜å¾—ä¸é‚£ä¹ˆæˆä¸ºé—®é¢˜ã€‚
- en: Likely related to being an early preview, GPT-4 model performance was very slow,
    taking 20 seconds per prompt to complete.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”±äºæ—©æœŸé¢„è§ˆçš„åŸå› ï¼ŒGPT-4 æ¨¡å‹çš„æ€§èƒ½éå¸¸æ…¢ï¼Œæ¯ä¸ªæç¤ºå®Œæˆéœ€è¦20ç§’ã€‚
- en: The framing of the problem was not ideal, for example, assuming a dataset can
    only have one category. It sufficed to illustrate the potential of Large Language
    Models for assessing data quality and summarization, but a slightly different
    approach in the future might yield better results. For example, predicting top
    dataset candidates for a given category per country for datasets on the HDX platform.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é—®é¢˜çš„æ¡†æ¶å¹¶ä¸ç†æƒ³ï¼Œä¾‹å¦‚ï¼Œå‡è®¾ä¸€ä¸ªæ•°æ®é›†åªèƒ½æœ‰ä¸€ä¸ªç±»åˆ«ã€‚è™½ç„¶è¶³ä»¥å±•ç¤ºå¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¯„ä¼°æ•°æ®è´¨é‡å’Œæ€»ç»“æ–¹é¢çš„æ½œåŠ›ï¼Œä½†æœªæ¥ç¨å¾®ä¸åŒçš„æ–¹æ³•å¯èƒ½ä¼šäº§ç”Ÿæ›´å¥½çš„ç»“æœã€‚ä¾‹å¦‚ï¼Œä¸º
    HDX å¹³å°ä¸Šçš„æ•°æ®é›†é¢„æµ‹æ¯ä¸ªå›½å®¶çš„é¡¶çº§æ•°æ®é›†å€™é€‰è€…ã€‚
- en: Being able to specify data tests and questions about data in natural language
    is still pretty cool though!
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: èƒ½å¤Ÿç”¨è‡ªç„¶è¯­è¨€æŒ‡å®šæ•°æ®æµ‹è¯•å’Œæ•°æ®é—®é¢˜ä»ç„¶å¾ˆé…·ï¼
- en: References
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[1] OCHA, [State of Open Humanitarian Data 2023](https://data.humdata.org/dataset/2048a947-5714-4220-905b-e662cbcd14c8/resource/9d4121c6-b32b-4eb8-a707-209c79241970/download/state-of-open-humanitarian-data-2023.pdf)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] OCHA, [2023å¹´å¼€æ”¾äººé“æ•°æ®çŠ¶æ€](https://data.humdata.org/dataset/2048a947-5714-4220-905b-e662cbcd14c8/resource/9d4121c6-b32b-4eb8-a707-209c79241970/download/state-of-open-humanitarian-data-2023.pdf)'
- en: '[2] Brown et al, [Language Models are Few Shot Learners](https://arxiv.org/pdf/2005.14165.pdf)
    (2020).'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Brown ç­‰äºº, [è¯­è¨€æ¨¡å‹æ˜¯å°‘æ ·æœ¬å­¦ä¹ è€…](https://arxiv.org/pdf/2005.14165.pdf)ï¼ˆ2020å¹´ï¼‰ã€‚'
- en: '[3] Kojima et al, [Large Language Models are Zero-shot reasoners](https://arxiv.org/abs/2205.11916).'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Kojima ç­‰äºº, [å¤§å‹è¯­è¨€æ¨¡å‹æ˜¯é›¶æ ·æœ¬æ¨ç†è€…](https://arxiv.org/abs/2205.11916)ã€‚'
- en: 'Schopf et al, [Evaluating Unsupervised Text Classification: Zero-Shot and similarity-based
    approaches](https://arxiv.org/abs/2211.16285)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: Schopf ç­‰äºº, [è¯„ä¼°æ— ç›‘ç£æ–‡æœ¬åˆ†ç±»ï¼šé›¶æ ·æœ¬å’ŒåŸºäºç›¸ä¼¼æ€§çš„ approaches](https://arxiv.org/abs/2211.16285)
- en: Code for this analysis can be found in [this notebook](https://github.com/datakind/gpt-3-meta-data-discovery/blob/main/gpt-4-data-quality-tests.ipynb).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªåˆ†æçš„ä»£ç å¯ä»¥åœ¨[è¿™ä¸ªç¬”è®°æœ¬](https://github.com/datakind/gpt-3-meta-data-discovery/blob/main/gpt-4-data-quality-tests.ipynb)ä¸­æ‰¾åˆ°ã€‚
