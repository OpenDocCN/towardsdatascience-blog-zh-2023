- en: Best Data Wrangling Functions in PySpark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/best-data-wrangling-functions-in-pyspark-3e903727319e?source=collection_archive---------6-----------------------#2023-12-12](https://towardsdatascience.com/best-data-wrangling-functions-in-pyspark-3e903727319e?source=collection_archive---------6-----------------------#2023-12-12)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learn the most helpful functions when wrangling Big Data with PySpark
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://gustavorsantos.medium.com/?source=post_page-----3e903727319e--------------------------------)[![Gustavo
    Santos](../Images/a19a9f4525cdeb6e7a76cd05246aa622.png)](https://gustavorsantos.medium.com/?source=post_page-----3e903727319e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3e903727319e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3e903727319e--------------------------------)
    [Gustavo Santos](https://gustavorsantos.medium.com/?source=post_page-----3e903727319e--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4429d99b1245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-data-wrangling-functions-in-pyspark-3e903727319e&user=Gustavo+Santos&userId=4429d99b1245&source=post_page-4429d99b1245----3e903727319e---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3e903727319e--------------------------------)
    ·7 min read·Dec 12, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3e903727319e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-data-wrangling-functions-in-pyspark-3e903727319e&user=Gustavo+Santos&userId=4429d99b1245&source=-----3e903727319e---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3e903727319e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-data-wrangling-functions-in-pyspark-3e903727319e&source=-----3e903727319e---------------------bookmark_footer-----------)![](../Images/fa66dae99d44fd5c8cadf67a519d043e.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Oskar Yildiz](https://unsplash.com/@oskaryil?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/turned-on-gray-laptop-computer-cOkpTiJMGzA?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I work with PySpark in Databricks on a daily basis. My work as a Data Scientist
    requires me to deal with large amounts of data in many different tables. It is
    a challenging job, many times.
  prefs: []
  type: TYPE_NORMAL
- en: 'As much as the **Extract, Transform and Load (ETL)** process sounds like something
    simple, I can tell that it is not always like that. When we work with Big Data,
    a lot of our thinking has to change for two reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: The amounts of data are way bigger than regular datasets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When working with parallel computing in clusters, we must take into account
    that the data will be split among many worker nodes to perform part of the job
    and then be brought together as a whole. And this process, many times, can become
    very time consuming if the query is too complex.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Knowing that, we must learn how to be write smart queries for Big Data. In this
    post, I will show a few of my favorite functions from the module `pyspark.sql.functions`,
    aiming to help you during your Data Wrangling in PySpark.
  prefs: []
  type: TYPE_NORMAL
- en: Best Functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now let’s move on to the content in this post.
  prefs: []
  type: TYPE_NORMAL
