- en: 'Araucana XAI: Local Explainability With Decision Trees for Healthcare'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Araucana XAI：利用决策树进行医疗保健的局部解释
- en: 原文：[https://towardsdatascience.com/araucana-xai-why-did-ai-get-this-one-wrong-8ee79dabdb1a?source=collection_archive---------14-----------------------#2023-07-14](https://towardsdatascience.com/araucana-xai-why-did-ai-get-this-one-wrong-8ee79dabdb1a?source=collection_archive---------14-----------------------#2023-07-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/araucana-xai-why-did-ai-get-this-one-wrong-8ee79dabdb1a?source=collection_archive---------14-----------------------#2023-07-14](https://towardsdatascience.com/araucana-xai-why-did-ai-get-this-one-wrong-8ee79dabdb1a?source=collection_archive---------14-----------------------#2023-07-14)
- en: Introducing a new model-agnostic, post hoc XAI approach based on CART to provide
    local explanations improving the transparency of AI-assisted decision making in
    healthcare
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍了一种基于 CART 的新型模型无关的后期 XAI 方法，以提供局部解释，从而提高 AI 辅助决策的透明度，特别是在医疗保健领域
- en: '[](https://medium.com/@detsutut?source=post_page-----8ee79dabdb1a--------------------------------)[![Tommaso
    Buonocore](../Images/c842f7d670434ba2315c63adf6fc385f.png)](https://medium.com/@detsutut?source=post_page-----8ee79dabdb1a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8ee79dabdb1a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8ee79dabdb1a--------------------------------)
    [Tommaso Buonocore](https://medium.com/@detsutut?source=post_page-----8ee79dabdb1a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@detsutut?source=post_page-----8ee79dabdb1a--------------------------------)[![Tommaso
    Buonocore](../Images/c842f7d670434ba2315c63adf6fc385f.png)](https://medium.com/@detsutut?source=post_page-----8ee79dabdb1a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8ee79dabdb1a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8ee79dabdb1a--------------------------------)
    [Tommaso Buonocore](https://medium.com/@detsutut?source=post_page-----8ee79dabdb1a--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5c63ef55f821&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faraucana-xai-why-did-ai-get-this-one-wrong-8ee79dabdb1a&user=Tommaso+Buonocore&userId=5c63ef55f821&source=post_page-5c63ef55f821----8ee79dabdb1a---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8ee79dabdb1a--------------------------------)
    ·7 min read·Jul 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8ee79dabdb1a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faraucana-xai-why-did-ai-get-this-one-wrong-8ee79dabdb1a&user=Tommaso+Buonocore&userId=5c63ef55f821&source=-----8ee79dabdb1a---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5c63ef55f821&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faraucana-xai-why-did-ai-get-this-one-wrong-8ee79dabdb1a&user=Tommaso+Buonocore&userId=5c63ef55f821&source=post_page-5c63ef55f821----8ee79dabdb1a---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8ee79dabdb1a--------------------------------)
    · 7分钟阅读 · 2023年7月14日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8ee79dabdb1a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faraucana-xai-why-did-ai-get-this-one-wrong-8ee79dabdb1a&user=Tommaso+Buonocore&userId=5c63ef55f821&source=-----8ee79dabdb1a---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8ee79dabdb1a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faraucana-xai-why-did-ai-get-this-one-wrong-8ee79dabdb1a&source=-----8ee79dabdb1a---------------------bookmark_footer-----------)![](../Images/22aec8c9f8f98b143838f8990ff864f5.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8ee79dabdb1a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faraucana-xai-why-did-ai-get-this-one-wrong-8ee79dabdb1a&source=-----8ee79dabdb1a---------------------bookmark_footer-----------)![](../Images/22aec8c9f8f98b143838f8990ff864f5.png)'
- en: The term ‘Araucana’ comes from the monkey puzzle tree pine from Chile, but is
    also the name of a beautiful breed of domestic chicken. © [MelaniMarfeld](https://pixabay.com/photos/araucana-hen-chicken-poultry-4097906/)
    from Pixabay
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: “Araucana” 这个词来源于智利的猴面包树，但它也是一种美丽的家禽品种的名称。© [MelaniMarfeld](https://pixabay.com/photos/araucana-hen-chicken-poultry-4097906/)
    取自 Pixabay
- en: Why did AI get this one wrong?
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么 AI 会出错？
- en: In the realm of artificial intelligence, there is a growing concern regarding
    the lack of transparency and understandability of complex AI systems. Recent research
    has been dedicated to addressing this issue by developing explanatory models that
    shed light on the inner workings of opaque systems like boosting, bagging, and
    deep learning techniques.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能领域，关于复杂AI系统缺乏透明性和可理解性的问题引起了越来越多的关注。最近的研究致力于通过开发解释模型来解决这一问题，这些模型揭示了像提升（boosting）、袋装（bagging）和深度学习技术这样的模糊系统的内部工作原理。
- en: Local and Global Explainability
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 局部和全局可解释性
- en: 'Explanatory models can shed light on the behavior of AI systems in two distinct
    ways:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 解释模型可以以两种不同的方式揭示AI系统的行为：
- en: '**Global explainability**. Global explainers provide a *comprehensive understanding*
    of how the AI classifier behaves as a whole. They aim to uncover overarching patterns,
    trends, biases, and other characteristics that remain consistent across various
    inputs and scenarios.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全局可解释性**。全局解释器提供了对AI分类器整体行为的*全面理解*。它们旨在揭示在各种输入和场景中始终一致的总体模式、趋势、偏差和其他特征。'
- en: '**Local explainability**. On the other hand, local explainers focus on providing
    *insights into the decision-making process* of the…'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**局部可解释性**。另一方面，局部解释器侧重于提供*对决策过程的见解*。'
