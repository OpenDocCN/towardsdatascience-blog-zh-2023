- en: 5 Lessons Learned from Testing Databricks SQL Serverless + DBT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/5-lessons-learned-from-testing-databricks-sql-serverless-dbt-1d85bc861358?source=collection_archive---------3-----------------------#2023-10-17](https://towardsdatascience.com/5-lessons-learned-from-testing-databricks-sql-serverless-dbt-1d85bc861358?source=collection_archive---------3-----------------------#2023-10-17)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We ran a $12K experiment to test the cost and performance of Serverless warehouses
    and dbt concurrent threads, and obtained unexpected results.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@jeff.b.chou?source=post_page-----1d85bc861358--------------------------------)[![Jeff
    Chou](../Images/4b5b7a7f880209faf1e81806a0f9dfba.png)](https://medium.com/@jeff.b.chou?source=post_page-----1d85bc861358--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1d85bc861358--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1d85bc861358--------------------------------)
    [Jeff Chou](https://medium.com/@jeff.b.chou?source=post_page-----1d85bc861358--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F124878bdd082&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-lessons-learned-from-testing-databricks-sql-serverless-dbt-1d85bc861358&user=Jeff+Chou&userId=124878bdd082&source=post_page-124878bdd082----1d85bc861358---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1d85bc861358--------------------------------)
    ·9 min read·Oct 17, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1d85bc861358&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-lessons-learned-from-testing-databricks-sql-serverless-dbt-1d85bc861358&user=Jeff+Chou&userId=124878bdd082&source=-----1d85bc861358---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1d85bc861358&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-lessons-learned-from-testing-databricks-sql-serverless-dbt-1d85bc861358&source=-----1d85bc861358---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: '*By: Jeff Chou,* [*Stewart Bryson*](https://medium.com/@stewartbryson)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8b40b0fb1e2e43d5fab293779781e128.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [Los Muertos Crew](https://www.pexels.com/@cristian-rojas/)
  prefs: []
  type: TYPE_NORMAL
- en: Databricks’ SQL warehouse products are a compelling offering for companies looking
    to streamline their production SQL queries and warehouses. However, as usage scales
    up, the cost and performance of these systems become crucial to analyze.
  prefs: []
  type: TYPE_NORMAL
- en: In this blog we take a technical deep dive into the cost and performance of
    their serverless SQL warehouse product by utilizing the industry standard TPC-DI
    benchmark. We hope data engineers and data platform managers can use the results
    presented here to make better decisions when it comes to their data infrastructure
    choices.
  prefs: []
  type: TYPE_NORMAL
- en: What are Databricks’ SQL warehouse offerings?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we dive into a specific product, let’s take a step back and look at
    the different options available today. Databricks currently offers [3 different
    warehouse options](https://www.databricks.com/product/pricing/databricks-sql):'
  prefs: []
  type: TYPE_NORMAL
- en: '**SQL Classic** — Most basic warehouse, runs inside customer’s cloud environment'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SQL Pro** — Improved performance and good for exploratory data science, runs
    inside customer’s cloud environment'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SQL Serverless** — “Best” performance, and the compute is fully managed by
    Databricks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From a cost perspective, both classic and pro run inside the user’s cloud environment.
    What this means is you will get 2 bills for your databricks usage — one is your
    pure Databricks cost (DBU’s) and the other is from your cloud provider (e.g. AWS
    EC2 bill).
  prefs: []
  type: TYPE_NORMAL
- en: 'To really understand the cost comparison, let’s just look at an example cost
    breakdown of running on a Small warehouse based on their [reported instance types](https://docs.databricks.com/en/sql/admin/warehouse-behavior.html):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f6c8a672940d052d1ba0fa8858f22175.png)'
  prefs: []
  type: TYPE_IMG
- en: Cost comparison of jobs compute, and the various SQL serverless options. Prices
    shown are based on on-demand list prices. [Spot prices will vary](https://aws.amazon.com/ec2/spot/pricing/)
    and were chosen based on the prices at the time of this publication. Image by
    author.
  prefs: []
  type: TYPE_NORMAL
- en: In the table above, we look at the cost comparison of on-demand vs. spot costs
    as well. You can see from the table that the serverless option has no cloud component,
    because it’s all managed by Databricks.
  prefs: []
  type: TYPE_NORMAL
- en: Serverless could be cost effective compared to pro, if you were using all on-demand
    instances. But if there are cheap spot nodes available, then Pro may be cheaper.
    Overall, the pricing for serverless is pretty reasonable in my opinion since it
    also includes the cloud costs, although it’s still a “premium” price.
  prefs: []
  type: TYPE_NORMAL
- en: We also included the equivalent jobs compute cluster, which is the cheapest
    option across the board. If cost is a concern to you, you can run SQL queries
    in jobs compute as well!
  prefs: []
  type: TYPE_NORMAL
- en: Pros and cons of Serverless
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Databricks serverless option is a fully managed compute platform. This
    is pretty much identical to how [Snowflake](https://www.snowflake.com) runs, where
    all of the compute details are hidden from users. At a high level there are pros
    and cons to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pros:**'
  prefs: []
  type: TYPE_NORMAL
- en: You don’t have to think about instances or configurations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spin up time is much less than starting up a cluster from scratch (5–10 seconds
    from our observations)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cons:**'
  prefs: []
  type: TYPE_NORMAL
- en: Enterprises may have security issues with all of the compute running inside
    of Databricks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enterprises may not be able to leverage their cloud contracts which may have
    special discounts on specific instances
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No ability to optimize the cluster, so you don’t know if the instances and configurations
    picked by Databricks are actually good for your job
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The compute is a black box — users have no idea what is going on or what changes
    Databricks is implementing underneath the hood which may make stability an issue.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Because of the inherent black box nature of serverless, we were curious to
    explore the various tunable parameters people do still have and their impact on
    performance. So let’s drive into what we explored:'
  prefs: []
  type: TYPE_NORMAL
- en: Experiment Setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We tried to take a “practical” approach to this study, and simulate what a
    real company might do when they want to run a SQL warehouse. Since [DBT](https://www.getdbt.com/)
    is such a popular tool in the modern data stack, we decided to look at 2 parameters
    to sweep and evaluate:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Warehouse size** — [‘2X-Small’, ‘X-Small’, ‘Small’, ‘Medium’, ‘Large’, ‘X-Large’,
    ‘2X-Large’, ‘3X-Large’, ‘4X-Large’]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**DBT Thread**s](https://docs.getdbt.com/docs/running-a-dbt-project/using-threads)
    — [‘4’, ‘8’, ‘16’, ‘24’, ‘32’, ‘40’, ‘48’]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The reason why we picked these two is they are both “universal” tuning parameters
    for any workload, and they both impact the compute side of the job. [DBT threads](https://docs.getdbt.com/docs/running-a-dbt-project/using-threads)
    in particular effectively tune the parallelism of your job as it runs through
    your DAG.
  prefs: []
  type: TYPE_NORMAL
- en: The workload we selected is the popular [TPC-DI](https://www.tpc.org/tpcdi/default5.asp)
    benchmark, with a scale factor of 1000\. This workload in particular is interesting
    because it’s actually an entire pipeline which mimics more real-world data workloads.
    For example, a screenshot of our DBT DAG is below, as you can see it’s quite complicated
    and changing the number of DBT threads could have an impact here.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f1e1ab47791286c4933f311b55cee5aa.png)'
  prefs: []
  type: TYPE_IMG
- en: DBT DAG from our TPC-DI Benchmark, Image by author
  prefs: []
  type: TYPE_NORMAL
- en: As a side note, Databricks has a [fantastic open source repo](https://github.com/shannon-barrow/databricks-tpc-di)
    that will help quickly set up the TPC-DI benchmark within Databricks entirely.
    (We did not use this since we are running with DBT).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: To get into the weeds of how we ran the experiment, we used [Databricks Workflows](https://docs.databricks.com/en/workflows/index.html)
    with a Task Type of dbt as the “runner” for the dbt CLI, and all the jobs were
    executed concurrently; there should be no variance due to unknown environmental
    conditions on the Databricks side.
  prefs: []
  type: TYPE_NORMAL
- en: Each job spun up a new SQL warehouse and tore it down afterwards, and ran in
    unique schemas in the same Unity Catalog. We used the [Elementary dbt package](https://docs.elementary-data.com/quickstart)
    to collect the execution results and ran a Python notebook at the end of each
    run to collect those metrics into a centralized schema.
  prefs: []
  type: TYPE_NORMAL
- en: Costs were extracted via Databricks System Tables, specifically those for Billable
    Usage.
  prefs: []
  type: TYPE_NORMAL
- en: Try this experiment yourself and clone the [Github repo here](https://github.com/synccomputingcode/databricks-tpcdi)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Below are the cost and runtime vs. warehouse size graphs. We can see below that
    the runtime stops scaling when you get the medium sized warehouses. Anything larger
    than a medium pretty much had no impact on runtime (or perhaps were worse). This
    is a typical scaling trend which shows that scaling cluster size is not infinite,
    they always have some point at which adding more compute provides diminishing
    returns.
  prefs: []
  type: TYPE_NORMAL
- en: For the CS enthusiasts out there, this is just the fundamental CS principal
    — [Amdahls Law.](https://en.wikipedia.org/wiki/Amdahl%27s_law)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: One unusual observation is that the medium warehouse outperformed the next 3
    sizes up (large to 2xlarge). We repeated this particular data point a few times,
    and obtained consistent results so it is not a strange fluke. Because of the black
    box nature of serverless, we unfortunately don’t know what’s going on under the
    hood and are unable to give an explanation.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/21006a1473f2231a3634087b518fcb73.png)'
  prefs: []
  type: TYPE_IMG
- en: Runtime in Minutes across Warehouse Sizes. Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Because scaling stops at medium, we can see in the cost graph below that the
    costs start to skyrocket after the medium warehouse size, because well basically
    you’re throwing more expensive machines while the runtime remains constant. So,
    you’re paying for extra horsepower with zero benefit.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1128d7c301950a8939daf3a79ec097e5.png)'
  prefs: []
  type: TYPE_IMG
- en: Cost in $ across Warehouse Sizes. Image by author
  prefs: []
  type: TYPE_NORMAL
- en: The graph below shows the relative change in runtime as we change the number
    of threads and warehouse size. For values greater than the zero horizontal line,
    the runtime increased (a bad thing).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/585b9cb1320cf2ec770a9e4716c5f979.png)'
  prefs: []
  type: TYPE_IMG
- en: The Percent Change in Runtime as Threads Increase. Image by author
  prefs: []
  type: TYPE_NORMAL
- en: 'The data here is a bit noisy, but there are some interesting insights based
    on the size of the warehouse:'
  prefs: []
  type: TYPE_NORMAL
- en: '**2x-small** — Increasing the number of threads usually made the job run longer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**X-small to large** — Increasing the number of threads usually helped make
    the job run about 10% faster, although the gains were pretty flat so continuing
    to increase thread count had no value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2x-large** — There was an actual optimal number of threads, which was 24,
    as seen in the clear parabolic line'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3x-large** — had a very unusual spike in runtime with a thread count of 8,
    why? No clue.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To put everything together into one comprehensive plot, we can see the plot
    below which plots the cost vs. duration of the total job. The different colors
    represent the different warehouse sizes, and the size of the bubbles are the number
    of DBT threads.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b8331017e39df72ff9b380a9c0dc67b5.png)'
  prefs: []
  type: TYPE_IMG
- en: Cost vs duration of the jobs. Size of the bubbles represents the number of threads.
    Image by author
  prefs: []
  type: TYPE_NORMAL
- en: 'In the plot above we see the typical trend that larger warehouses typically
    lead to shorter durations but higher costs. However, we do spot a few unusual
    points:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Medium is the best** — From a pure cost and runtime perspective, medium is
    the best warehouse to choose'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Impact of DBT threads** — For the smaller warehouses, changing the number
    of threads appeared to have changed the duration by about +/- 10%, but not the
    cost much. For larger warehouses, the number of threads impacted both cost and
    runtime quite significantly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In summary, our top 5 lessons learned about Databricks SQL serverless + DBT
    products are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Rules of thumbs are bad** — We cannot simply rely on “rules of thumb” about
    warehouse size or the number of dbt threads. Some expected trends do exist, but
    they are not consistent or predictable and it is entirely dependent on your workload
    and data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Huge variance —** For the exact same workloads the costs ranged from $5 —
    $45, and runtimes from 2 minutes to 90 minutes, all due to different combinations
    of number of threads and warehouse size.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Serverless scaling has limits —** Serverless warehouses do not scale infinitely
    and eventually larger warehouses will cease to provide any speedup and only end
    up causing increased costs with no benefit.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Medium is great ?**— We found the **Medium** Serverless SQL Warehouse outperformed
    many of the larger warehouse sizes on both cost and job duration for the TPC-DI
    benchmark. We have no clue why.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Jobs clusters may be cheapest** — If costs are a concern, switching to just
    standard jobs compute with notebooks may be substantially cheaper'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The results reported here reveal that the performance of black box “serverless”
    systems can result in some unusual anomalies. Since it’s all behind Databrick’s
    walls, we have no idea what is happening. Perhaps it’s all running on giant Spark
    on Kubernetes clusters, maybe they have special deals with Amazon on certain instances?
    Either way, the unpredictable nature makes controlling cost and performance tricky.
  prefs: []
  type: TYPE_NORMAL
- en: Because each workload is unique across so many dimensions, we can’t rely on
    “rules of thumb”, or costly experiments that are only true for a workload in its
    current state. The more chaotic nature of serverless system does beg the question
    if these systems need a [closed loop control system](https://medium.com/towards-data-science/why-your-data-pipelines-need-closed-loop-feedback-control-76e28e3565f)
    to keep them at bay?
  prefs: []
  type: TYPE_NORMAL
- en: 'As an introspective note — the business model of serverless is truly compelling.
    Assuming Databricks is a rational business and does not want to decrease their
    revenue, and they want to lower their costs, one must ask the question: “Is Databricks
    incentivized to improve the compute under the hood?”'
  prefs: []
  type: TYPE_NORMAL
- en: The problem is this — if they make serverless 2x faster, then all of sudden
    their revenue from serverless drops by 50% — that’s a very bad day for Databricks.
    If they could make it 2x faster, and then increase the DBU costs by 2x to counteract
    the speedup, then they would remain revenue neutral (this is what they did for
    [Photon](https://synccomputing.com/databricks-photon-and-graviton-instances-worth-it/)
    actually).
  prefs: []
  type: TYPE_NORMAL
- en: So Databricks is really incentivized to decrease their internal costs while
    keeping customer runtimes about the same. While this is great for Databricks,
    it’s difficult to pass on any serverless acceleration technology to the user that
    results in a cost reduction.
  prefs: []
  type: TYPE_NORMAL
- en: Interested in learning more about how to improve your Databricks pipelines?
    Reach out to [Jeff Chou](https://www.linkedin.com/in/jeffchoumit/) and the rest
    of the [Sync Team](https://synccomputing.com/).
  prefs: []
  type: TYPE_NORMAL
- en: Resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Try this experiment yourself and clone the Github repo here](https://github.com/synccomputingcode/databricks-tpcdi)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Related Content
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Why Your Data Pipelines Need Closed-Loop Feedback Control](https://medium.com/towards-data-science/why-your-data-pipelines-need-closed-loop-feedback-control-76e28e3565f)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Are Databricks clusters with Photon and Graviton instances worth it?](https://synccomputing.com/databricks-photon-and-graviton-instances-worth-it/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Is Databricks’s autoscaling cost efficient?](https://synccomputing.com/is-databrickss-autoscaling-cost-efficient/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introducing Gradient — Databricks optimization made easy](https://synccomputing.com/introducing-gradient-for-databricks/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
