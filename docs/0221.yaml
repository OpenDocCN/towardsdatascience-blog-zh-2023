- en: 'Context-Enriched Data: The Secret Superpower for Your Deep Learning Model'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/context-enriched-data-the-secret-superpower-for-your-deep-learning-model-549826a5fb3d?source=collection_archive---------8-----------------------#2023-01-13](https://towardsdatascience.com/context-enriched-data-the-secret-superpower-for-your-deep-learning-model-549826a5fb3d?source=collection_archive---------8-----------------------#2023-01-13)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Design better prediction models with context-aware data engineering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@christoph.oliver.moehl?source=post_page-----549826a5fb3d--------------------------------)[![Christoph
    Möhl](../Images/fa254d72929c710f11bda8f760f43453.png)](https://medium.com/@christoph.oliver.moehl?source=post_page-----549826a5fb3d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----549826a5fb3d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----549826a5fb3d--------------------------------)
    [Christoph Möhl](https://medium.com/@christoph.oliver.moehl?source=post_page-----549826a5fb3d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5bd469d8e345&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontext-enriched-data-the-secret-superpower-for-your-deep-learning-model-549826a5fb3d&user=Christoph+M%C3%B6hl&userId=5bd469d8e345&source=post_page-5bd469d8e345----549826a5fb3d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----549826a5fb3d--------------------------------)
    ·11 min read·Jan 13, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F549826a5fb3d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontext-enriched-data-the-secret-superpower-for-your-deep-learning-model-549826a5fb3d&user=Christoph+M%C3%B6hl&userId=5bd469d8e345&source=-----549826a5fb3d---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F549826a5fb3d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontext-enriched-data-the-secret-superpower-for-your-deep-learning-model-549826a5fb3d&source=-----549826a5fb3d---------------------bookmark_footer-----------)![](../Images/fdc8b0f38d333c6eb489dd22dae8bc96.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by Mateo Krössler on Unsplash
  prefs: []
  type: TYPE_NORMAL
- en: In this post, I would like to share with you my approach to optimize input data
    for deep learning models. I have successfully applied it in my work as a data
    scientist and data engineer. On the basis of practical examples you will learn
    how to enrich model input data with contextual information. This will enable you
    to design more robust and and accurate deep learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning models are so powerful, because they are very good at integrating
    contextual information. We can boost performance of neural networks by adding
    several context to dimensions to the raw data. We can achieve this with some clever
    data engineering.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'When you develop a new predictive deep learning algorithm you likely aim to
    choose a model architecture that perfectly fits your specific use case. Based
    on input data and the actual prediction task, there are plenty of recipes that
    you may have already in mind: Are you going to classify images? Then you’ll go
    most probably for convolutional neural networks. Is it about forecasting time
    series or analyzing text? LSTM networks could be a promising option, then. Normally
    the decision about the right model architecture is mainly driven by the type of
    data that flows into the model.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In that way, finding the right input data structure (i.e. defining the model’s
    input layer) is one of the most crucial steps in model design. I usually invest
    much more development time in engineering the shape of input data than in anything
    else. To be clear: We don’t we have to deal with the structure of the raw data
    as a given and just find the right model for it. The ability of neural networks
    to take care of feature engineering and feature selection internally (“end to
    end modeling”) does not free us from optimizing the structure of the input data.
    We should serve the data in a way that the model can make best sense out of it
    and take the most informed decision (i.e. the most precise prediction). The secret
    ingredient here is contextual information. We should enrich our raw data with
    as much context as possible.'
  prefs: []
  type: TYPE_NORMAL
- en: What is Context?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'But what do I mean specifically by context? Let’s take an example. Marie is
    a data scientist starting a new job to develop a sales forecasting system for
    a beverage retail company. Her task in a nutshell: Given a specific shop and a
    specific product (lemonade, orange juice, beer…), her model should predict the
    number of future sales of the product in the specific shop. Forecasting would
    be applied to thousands different products offered in hundreds of different shops.
    So far so good. On Marie’s first day, she goes to sales department, where the
    forecasting job is already performed, albeit manually by Peter, a very experienced
    sales accountant. Her goal is to understand on what basis this domain expert decides
    whether a particular product will be more or less in demand in the future. As
    a good data scientist, Marie anticipates that Peter’s years of experience will
    be very helpful in defining what data might be valuable to the model. To find
    out, Marie asks him two questions:'
  prefs: []
  type: TYPE_NORMAL
- en: '*“What data do you look at to figure out how many bottles of a particular brand
    of lemonade we will sell next month in our store in Berlin? How do you interpret
    that data?”*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Peter replies: *“We look in the first step on lemonade sales in Berlin store
    over time”.* He draws the following chart to illustrate his strategy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/88a50eabf983baa6e1bf15e986349440.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure by author
  prefs: []
  type: TYPE_NORMAL
- en: We see a continuous curve with recurring peaks in July/August (summertime in
    Berlin). It makes intuitive sense that more product is sold in the summer, when
    temperatures are high and people are more in the mood for refreshments. On a smaller
    time scale (ca one month) we see noisy up and down of sales within the range of
    ca. 10 items, which is likely due to unpredictable events (random noise).
  prefs: []
  type: TYPE_NORMAL
- en: '*Peter: “When I see a repetitive pattern with increased sales in summer and
    decreased sales in winter. I assume that this will also happen in the future and
    estimate sales accordingly.”* That sounds very plausible.'
  prefs: []
  type: TYPE_NORMAL
- en: Peter interprets sales data in the context of time, where the distance of two
    data points is defined by their time difference. If the data would not be ordered
    in time context, it would be harder to interpret. For example, if we look just
    look at sales distribution in a histogram plot, time context is lost and our best
    future sales estimate would be some aggregate such as the median of all values.
  prefs: []
  type: TYPE_NORMAL
- en: Context arises when data is ordered in some way.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It goes without saying that you should feed your sales prediction model with
    historic sales data in the right time order to preserve the context that comes
    “for free” from your database. Deep learning models are so powerful, because they
    are very good at integrating contextual information, similar to our brain (or
    Peters brain, in this case).
  prefs: []
  type: TYPE_NORMAL
- en: 'Did you ever wonder why deep learning works so well for image classification
    and image object detection? Because ordinary images come already with lots of
    “natural” context: Images are basically data points of light intensity ordered
    in two context dimensions: namely the spatial distance in *x* and the spatial
    distance in *y*. Movies (image time series) complement *time* as a third context
    dimension.'
  prefs: []
  type: TYPE_NORMAL
- en: Because context is so beneficial for prediction, we can boost our model performance
    by adding more context dimensions despite from the ones that are already included
    in the raw data. We achieve this with some clever data engineering as described
    in the next part.
  prefs: []
  type: TYPE_NORMAL
- en: We should serve the data in a way that the model can make best sense out of
    it and take the most informed decision. *I* usually invest much more development
    time in engineering the shape of input data than in anything else.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Designing Context-Enriched Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Back to the meeting with Marie and Peter. Knowing that real data in most cases
    doesn’t look as nice as in the plot above, Marie slightly modifies the chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d4d30ebbd334654657b65d110609c115.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure by author
  prefs: []
  type: TYPE_NORMAL
- en: 'Marie: *“What if the last sales data point is above the usual noise level?
    That could be a real effect. Maybe there’s a successful marketing campaign going
    on for the product. Maybe the recipe has been changed and it tastes much better
    now. In these cases, the effect is lasting, and sales will remain at the same
    high level in the future. Or maybe it is just an outlier due to a random event.
    For example, a school class visiting Berlin happened to enter the store and all
    the children bought a bottle of this lemonade brand. In this case, the increase
    is not stable, but just noise. How would you decide whether it is a real effect
    or not?”*'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see Peters scratching his head before he answers: *“In this case, I’m
    looking at the sales of stores that are similar to the one in Berlin. For example,
    our stores in Hamburg and Munich. These stores are comparable because they are
    also located in major German cities. I wouldn’t consider stores in the countryside
    because I expect different customers with different tastes and preferences there.”*'
  prefs: []
  type: TYPE_NORMAL
- en: He adds sales curves from the other stores with two potential scenarios. *“If
    I see the sales increase just in Berlin, I consider it as noise. However, if I
    see lemonade sales going up also in Hamburg and Munich I expect it to be a stable
    effect.”*
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/46b78629808f7282c6532b35a4905d20.png)![](../Images/1cb50c52d42373b03af16f227a3f4eb5.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure by author
  prefs: []
  type: TYPE_NORMAL
- en: So, in difficult situations, Peter takes more data into account to make better
    informed decisions. He adds a new data dimension in the context of different shops.
    As we learned above, context arises when the data is ordered in some way. To create
    a shop context we first have to define a distance measure to order data from different
    shops accordingly. Peter for example discriminates the shops according to the
    size of the cities where they are located.
  prefs: []
  type: TYPE_NORMAL
- en: With a some *SQL* and *Numpy* hacking, we can provide a similar context to our
    model. We first have to get population sizes of all cities where shops from our
    company are located. Then we measure the distance between all shops in terms of
    difference in population. Finally, we assemble all sales data in a 2D Matrix,
    where the first dimension is *time* and the second dimension is our *shop distance*
    measure.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ab547893b681d564a1c3ed94a912d8e1.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure by author
  prefs: []
  type: TYPE_NORMAL
- en: 'The sales matrix provides a good overview of recent lemonade sales and the
    resulting patterns can be interpreted intuitively. Look at the lower left data
    point of the sales matrix: This is the most recent sales number for Berlin. The
    bright spot is likely an outlier, as the steep sales increase is not reproduced
    in similar stores (Hamburg for example). In contrast, the sales spike in July
    is reproduced by the similar stores.'
  prefs: []
  type: TYPE_NORMAL
- en: We always need a distance measure to create context.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Translating Peters statement into mathematical terms, lemoande sales can be
    modeled as a function of population size of the cities where the product is offered.
    We always have to think very carefully about the right distance measure when adding
    new context dimensions. It depends, on what factors the entity we want to predict
    is affected. The influencing factors are totally dependent on the product and
    distance measures must be tailored accordingly. If you look at beer sales in Germany
    for example, you will see that consumers are likely to buy products from local
    breweries (You find ca. 1300 different [breweries](https://en.wikipedia.org/wiki/Beer_in_Germany)
    all across the country). People from Cologne usually drink “Kölsch” beer, but
    when you drive half an hour up north to the region of Düsseldorf, people avoid
    “Kölsch” in favor of the darker and malty “Alt” beer. So, in case of beer sales
    in Germany, it may be a reasonable option to model shop distance by their geographical
    distance. However, this will not be the case for other product categories (lemonade,
    orange juice, sports drinks…).
  prefs: []
  type: TYPE_NORMAL
- en: Because we added an additional context dimension, we created a context-enriched
    dataset in which a potential forecasting model can get an overview of lemonade
    sales over time and in different stores. This allows the model to make an informed
    decision about future sales at the Berlin store by looking at recent sales history
    and looking left and right at similar stores in other locations.
  prefs: []
  type: TYPE_NORMAL
- en: From here, we can go further and add *product type* as an additional context
    dimension. Therefore, we enrich the sales matrix with data from other products
    ranked by their similarity to lemonade (our prediction target). Again, we need
    to find a good similarity measure. Is cola more similar to lemonade than orange
    juice? Based on what data could we define a similarity ranking? In the case of
    *shop context*, we had a continuous measure, which was the population of the city.
    Now we are dealing with categories. What we really want to find are products that
    have similar sales behavior to lemonade. We can do a cross-correlation analysis
    of the time-resolved sales data for all products compared to lemonade. In this
    way, we obtain a Pearson correlation coefficient for each product that tells us
    how similar the sales patterns are. Soft drinks such as cola may have a similar
    sales pattern to lemonade, with sales increasing in the summer. Other products
    will behave completely differently. For example, Gühwein, a warm and sweet wine
    served at Christmas markets, may have a strong sales peak in December and hardly
    any sales during the rest of the year.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/65bfc907154487392b46cf8cb2fd396a.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure by author
  prefs: []
  type: TYPE_NORMAL
- en: Cross correlation analysis would reveal a low (actually negative) Pearson coefficient
    for Glühwein and a higher coefficient for cola.
  prefs: []
  type: TYPE_NORMAL
- en: 'Despite adding a third dimension to the sales matrix, we could include *product*
    context by concatenating the second dimension in the opposite direction. This
    puts the most important sales data (lemonade sales in Berlin) in the center:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b6e6bb0c911933b2f4aa372589beabba.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure by author
  prefs: []
  type: TYPE_NORMAL
- en: Adding more Features
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Although we now have a data structure that is quite rich in information, we
    only have one feature so far: The number of products sold for a particular product
    at a particular time in a particular store. This may already be sufficient for
    a robust and precise prediction, however we are free to add additional useful
    information from other data sources.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It is very likely that beverage purchasing behavior is dependent on the weather.
    For example in very hot summers, there might be an increased demand of lemonade.
    We can provide weather data (such as air temperature) as a second layer of the
    matrix. The weather data will be ordered in the same context as the sales data:
    Over *time*, *shop locations* and *products*. For different products, we will
    have identical air temperature data, however for different times and shop locations,
    we will see differences that might contribute useful information to the data.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c5af3de584bd0ec292010f2772f86111.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure by author
  prefs: []
  type: TYPE_NORMAL
- en: As a result, we have a 3-D matrix containing sales and temperature data. It
    is important to note that we do not add an additional context dimension by including
    the temperature data. As I pointed out before, context arises when data is ordered
    in some way. For our established data contexts, we ordered data with regard to
    *time*, *product similarity* and *shop similarity*. The order of the features
    (in our case along the third dimension of the matrix) however is irrelevant. Our
    data structure is comparable with an RGB color image. In the RGB image, we have
    two context dimensions (space dimensions *x* and *y*) and three color layers (*red*,
    *green*, *blue*). To interpret the image correctly, the order of color channels
    is arbitrary. You just have to keep the order once you have defined it. But there
    no distance measure as we have for data that is organized in a certain context.
  prefs: []
  type: TYPE_NORMAL
- en: The structure of your input data is not predetermined. You should expand it
    with all your creative potential and intuition.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By adding two additional contexts to the time-resolved sales data and an additional
    feature layer, we obtain a 2-D “picture” with two “channels” (sales and temperature).
    This data structure provides a comprehensive view of recent lemonade sales at
    a particular store along with sales and weather information from similar stores
    and similar products. The data structure is now very well suited to be interpreted
    by deep neural network containing, for example, multiple convolutional layers
    and LSTM units. I will not discuss how to proceed from here and design a suitable
    neural network. This could be a topic for a follow-up article.
  prefs: []
  type: TYPE_NORMAL
- en: I hope you got an idea that the structure of your input data is not predetermined,
    but that you can (should) expand it with all your creative potential and intuition.
  prefs: []
  type: TYPE_NORMAL
- en: Context enriched data structures don’t come for free. To predict various products
    for all stores of the company we will have generate thousands of context enriched
    sales profiles (one matrix for each store-product combination). You have to invest
    considerable extra work to design efficient processing and buffering steps to
    bring the data into shape and provide it for fast training and prediction cycles.
    But you will be rewarded with a model that can make accurate predictions and behave
    very robustly even with highly noisy data, because it can look “outside the box”
    and make very informed decisions.
  prefs: []
  type: TYPE_NORMAL
- en: You have questions? You need a [**freelance expert for AI, Data Science, Data
    Engineering or Python Development**](https://www.moehl-data-services.de/en)? Visit
    [my website](https://moehl-data-services.de/en) and write me a message.
  prefs: []
  type: TYPE_NORMAL
