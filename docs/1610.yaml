- en: 'iMAP: Modeling 3D Scenes in Real-Time'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/imap-modeling-3d-scenes-in-real-time-6202365d80ee?source=collection_archive---------9-----------------------#2023-05-12](https://towardsdatascience.com/imap-modeling-3d-scenes-in-real-time-6202365d80ee?source=collection_archive---------9-----------------------#2023-05-12)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learning 3D environments with handheld RGB-D cameras
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://wolfecameron.medium.com/?source=post_page-----6202365d80ee--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----6202365d80ee--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6202365d80ee--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6202365d80ee--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----6202365d80ee--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F28aa6026c553&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimap-modeling-3d-scenes-in-real-time-6202365d80ee&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=post_page-28aa6026c553----6202365d80ee---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6202365d80ee--------------------------------)
    ·15 min read·May 12, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6202365d80ee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimap-modeling-3d-scenes-in-real-time-6202365d80ee&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=-----6202365d80ee---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6202365d80ee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimap-modeling-3d-scenes-in-real-time-6202365d80ee&source=-----6202365d80ee---------------------bookmark_footer-----------)![](../Images/75c66b8fbe2eb3a7bc26faba5f1ea272.png)'
  prefs: []
  type: TYPE_NORMAL
- en: (Photo by [Brett Zeck](https://unsplash.com/@iambrettzeck?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/map?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText))
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have only seen offline approaches for modeling 3D scenes (e.g., [NeRF](https://cameronrwolfe.substack.com/p/understanding-nerfs),
    [SRNs](https://cameronrwolfe.substack.com/p/scene-representation-networks), [DeepSDF](https://cameronrwolfe.substack.com/p/3d-generative-modeling-with-deepsdf)
    [2, 3, 4]). Despite their impressive performance, these approaches require days,
    or even weeks, of computation time for the underlying neural networks to be trained.
    For example, NeRFs are trained for nearly two days for just representing a single
    scene. Plus, using the the neural net to evaluate a new scene viewpoint can be
    quite expensive too! With this in mind, we might wonder whether it’s possible
    to learn a scene representation a bit faster than this.
  prefs: []
  type: TYPE_NORMAL
- en: This question was explored in [1] with the proposal of iMAP, a real-time system
    for representing scenes and localizing (i.e., tracking the pose of) devices in
    the scene. To understand what this means, consider a camera that is moving through
    a scene and capturing the surrounding environment. The task of iMAP is to *(i)*
    take in this data, *(ii)* build a 3D representation of the scene being observed,
    and (iii) infer the location and orientation of the camera (i.e., the device)
    as it captures the scene!
  prefs: []
  type: TYPE_NORMAL
- en: 'iMAP adopts an approach that is quite similar to NeRF [2] with a few differences:'
  prefs: []
  type: TYPE_NORMAL
- en: It is based upon RGB-D data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A streaming setup is assumed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
