- en: 'iMAP: Modeling 3D Scenes in Real-Time'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: iMAP：实时建模3D场景
- en: 原文：[https://towardsdatascience.com/imap-modeling-3d-scenes-in-real-time-6202365d80ee?source=collection_archive---------9-----------------------#2023-05-12](https://towardsdatascience.com/imap-modeling-3d-scenes-in-real-time-6202365d80ee?source=collection_archive---------9-----------------------#2023-05-12)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/imap-modeling-3d-scenes-in-real-time-6202365d80ee?source=collection_archive---------9-----------------------#2023-05-12](https://towardsdatascience.com/imap-modeling-3d-scenes-in-real-time-6202365d80ee?source=collection_archive---------9-----------------------#2023-05-12)
- en: Learning 3D environments with handheld RGB-D cameras
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用手持RGB-D相机学习3D环境
- en: '[](https://wolfecameron.medium.com/?source=post_page-----6202365d80ee--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----6202365d80ee--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6202365d80ee--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6202365d80ee--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----6202365d80ee--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://wolfecameron.medium.com/?source=post_page-----6202365d80ee--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----6202365d80ee--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6202365d80ee--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6202365d80ee--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----6202365d80ee--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F28aa6026c553&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimap-modeling-3d-scenes-in-real-time-6202365d80ee&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=post_page-28aa6026c553----6202365d80ee---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6202365d80ee--------------------------------)
    ·15 min read·May 12, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6202365d80ee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimap-modeling-3d-scenes-in-real-time-6202365d80ee&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=-----6202365d80ee---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F28aa6026c553&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimap-modeling-3d-scenes-in-real-time-6202365d80ee&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=post_page-28aa6026c553----6202365d80ee---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6202365d80ee--------------------------------)
    · 15分钟阅读 · 2023年5月12日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6202365d80ee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimap-modeling-3d-scenes-in-real-time-6202365d80ee&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=-----6202365d80ee---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6202365d80ee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimap-modeling-3d-scenes-in-real-time-6202365d80ee&source=-----6202365d80ee---------------------bookmark_footer-----------)![](../Images/75c66b8fbe2eb3a7bc26faba5f1ea272.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6202365d80ee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimap-modeling-3d-scenes-in-real-time-6202365d80ee&source=-----6202365d80ee---------------------bookmark_footer-----------)![](../Images/75c66b8fbe2eb3a7bc26faba5f1ea272.png)'
- en: (Photo by [Brett Zeck](https://unsplash.com/@iambrettzeck?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/map?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText))
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: （照片由 [Brett Zeck](https://unsplash.com/@iambrettzeck?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，[Unsplash](https://unsplash.com/s/photos/map?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)）
- en: So far, we have only seen offline approaches for modeling 3D scenes (e.g., [NeRF](https://cameronrwolfe.substack.com/p/understanding-nerfs),
    [SRNs](https://cameronrwolfe.substack.com/p/scene-representation-networks), [DeepSDF](https://cameronrwolfe.substack.com/p/3d-generative-modeling-with-deepsdf)
    [2, 3, 4]). Despite their impressive performance, these approaches require days,
    or even weeks, of computation time for the underlying neural networks to be trained.
    For example, NeRFs are trained for nearly two days for just representing a single
    scene. Plus, using the the neural net to evaluate a new scene viewpoint can be
    quite expensive too! With this in mind, we might wonder whether it’s possible
    to learn a scene representation a bit faster than this.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只见过用于建模 3D 场景的离线方法（例如，[NeRF](https://cameronrwolfe.substack.com/p/understanding-nerfs)，[SRNs](https://cameronrwolfe.substack.com/p/scene-representation-networks)，[DeepSDF](https://cameronrwolfe.substack.com/p/3d-generative-modeling-with-deepsdf)
    [2, 3, 4]）。尽管这些方法表现出色，但它们需要数天甚至数周的计算时间来训练基础神经网络。例如，NeRF 需要将近两天的时间来仅仅表示一个场景。此外，使用神经网络评估新场景视点也可能相当昂贵！考虑到这一点，我们可能会想知道是否有可能比这更快地学习场景表示。
- en: This question was explored in [1] with the proposal of iMAP, a real-time system
    for representing scenes and localizing (i.e., tracking the pose of) devices in
    the scene. To understand what this means, consider a camera that is moving through
    a scene and capturing the surrounding environment. The task of iMAP is to *(i)*
    take in this data, *(ii)* build a 3D representation of the scene being observed,
    and (iii) infer the location and orientation of the camera (i.e., the device)
    as it captures the scene!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题在 [1] 中得到了探讨，提出了 iMAP，这是一种用于表示场景和定位（即，跟踪设备姿态）的实时系统。为了理解这意味着什么，请考虑一个移动穿越场景并捕捉周围环境的摄像机。iMAP
    的任务是 *(i)* 接收这些数据，*(ii)* 建立观察到的场景的 3D 表示，并 (iii) 推断摄像机（即设备）在捕捉场景时的位置和方向！
- en: 'iMAP adopts an approach that is quite similar to NeRF [2] with a few differences:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: iMAP 采用的方法与 NeRF [2] 非常相似，但有一些不同之处：
- en: It is based upon RGB-D data.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它基于 RGB-D 数据。
- en: A streaming setup is assumed.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设有一个流媒体设置。
