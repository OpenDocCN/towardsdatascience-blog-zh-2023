- en: Improving Performance and Explainability of Zero-Shot CLIP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/improving-performance-and-explainability-of-zero-shot-clip-33e579d3f4bb?source=collection_archive---------9-----------------------#2023-11-25](https://towardsdatascience.com/improving-performance-and-explainability-of-zero-shot-clip-33e579d3f4bb?source=collection_archive---------9-----------------------#2023-11-25)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Part 2 — Visual classification via description from LLMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@alexml0123?source=post_page-----33e579d3f4bb--------------------------------)[![Alexey
    Kravets](../Images/3b31f9b3c73c6c7ca709f845e6f70023.png)](https://medium.com/@alexml0123?source=post_page-----33e579d3f4bb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----33e579d3f4bb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----33e579d3f4bb--------------------------------)
    [Alexey Kravets](https://medium.com/@alexml0123?source=post_page-----33e579d3f4bb--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcf3e4a05b535&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-performance-and-explainability-of-zero-shot-clip-33e579d3f4bb&user=Alexey+Kravets&userId=cf3e4a05b535&source=post_page-cf3e4a05b535----33e579d3f4bb---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----33e579d3f4bb--------------------------------)
    ·6 min read·Nov 25, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F33e579d3f4bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-performance-and-explainability-of-zero-shot-clip-33e579d3f4bb&user=Alexey+Kravets&userId=cf3e4a05b535&source=-----33e579d3f4bb---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F33e579d3f4bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-performance-and-explainability-of-zero-shot-clip-33e579d3f4bb&source=-----33e579d3f4bb---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: This is the second part of a series on enhancing Zero-Shot CLIP performance.
    In the first part, I provided a detailed explanation of how the CLIP model operates
    and described a straightforward method to improve its performance. This involved
    extending standard prompts like *“A picture of {class}”* with customized prompts
    generated by a large language model (LLM). If you haven’t already, you can find
    part 1 [here](https://medium.com/towards-data-science/simple-way-of-improving-zero-shot-clip-performance-4eae474cb447).
    In this article we will present a relatively similar method to improve zero-shot
    CLIP performance which is additionally highly explainable.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The CLIP model is an impressive zero-shot predictor, enabling predictions on
    tasks it hasn’t explicitly been trained for. Despite its inherent capabilities,
    there exist several strategies to notably improve its performance. In the first
    article we have seen one of these strategies, however, while achieving enhanced
    performance is valuable, there are instances where we might be willing to make
    trade-offs to prioritize better explainability. In this second article of our
    series we will explore a method that not only enhances the performance of the
    zero-shot CLIP model but also ensures that its predictions are easily understandable
    and interpretable.
  prefs: []
  type: TYPE_NORMAL
- en: Explainability in Deep Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
