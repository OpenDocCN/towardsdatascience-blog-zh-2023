- en: Class Imbalance Strategies — A Visual Guide with Code
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 类别不平衡策略 — 带代码的视觉指南
- en: 原文：[https://towardsdatascience.com/class-imbalance-strategies-a-visual-guide-with-code-8bc8fae71e1a?source=collection_archive---------2-----------------------#2023-04-24](https://towardsdatascience.com/class-imbalance-strategies-a-visual-guide-with-code-8bc8fae71e1a?source=collection_archive---------2-----------------------#2023-04-24)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/class-imbalance-strategies-a-visual-guide-with-code-8bc8fae71e1a?source=collection_archive---------2-----------------------#2023-04-24](https://towardsdatascience.com/class-imbalance-strategies-a-visual-guide-with-code-8bc8fae71e1a?source=collection_archive---------2-----------------------#2023-04-24)
- en: Understand Random Undersampling, Oversampling, SMOTE, ADASYN, and Tomek Links
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解随机欠采样、过采样、SMOTE、ADASYN 和 Tomek 链接
- en: '[](https://travis-tang.medium.com/?source=post_page-----8bc8fae71e1a--------------------------------)[![Travis
    Tang](../Images/8372ea73b8cf8fe344de6274b5d9ad17.png)](https://travis-tang.medium.com/?source=post_page-----8bc8fae71e1a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8bc8fae71e1a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8bc8fae71e1a--------------------------------)
    [Travis Tang](https://travis-tang.medium.com/?source=post_page-----8bc8fae71e1a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://travis-tang.medium.com/?source=post_page-----8bc8fae71e1a--------------------------------)[![Travis
    Tang](../Images/8372ea73b8cf8fe344de6274b5d9ad17.png)](https://travis-tang.medium.com/?source=post_page-----8bc8fae71e1a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8bc8fae71e1a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8bc8fae71e1a--------------------------------)
    [Travis Tang](https://travis-tang.medium.com/?source=post_page-----8bc8fae71e1a--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F169b6a57c01e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclass-imbalance-strategies-a-visual-guide-with-code-8bc8fae71e1a&user=Travis+Tang&userId=169b6a57c01e&source=post_page-169b6a57c01e----8bc8fae71e1a---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8bc8fae71e1a--------------------------------)
    ·13 min read·Apr 24, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8bc8fae71e1a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclass-imbalance-strategies-a-visual-guide-with-code-8bc8fae71e1a&user=Travis+Tang&userId=169b6a57c01e&source=-----8bc8fae71e1a---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F169b6a57c01e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclass-imbalance-strategies-a-visual-guide-with-code-8bc8fae71e1a&user=Travis+Tang&userId=169b6a57c01e&source=post_page-169b6a57c01e----8bc8fae71e1a---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8bc8fae71e1a--------------------------------)
    ·13分钟阅读·2023年4月24日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8bc8fae71e1a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclass-imbalance-strategies-a-visual-guide-with-code-8bc8fae71e1a&user=Travis+Tang&userId=169b6a57c01e&source=-----8bc8fae71e1a---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8bc8fae71e1a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclass-imbalance-strategies-a-visual-guide-with-code-8bc8fae71e1a&source=-----8bc8fae71e1a---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8bc8fae71e1a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclass-imbalance-strategies-a-visual-guide-with-code-8bc8fae71e1a&source=-----8bc8fae71e1a---------------------bookmark_footer-----------)'
- en: Class imbalance occurs when one class in a classification problem significantly
    outweighs the other class. It’s common in many machine learning problems. Examples
    include fraud detection, anomaly detection, and medical diagnosis.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 类别不平衡发生在分类问题中一个类别显著多于另一个类别。这在许多机器学习问题中很常见。例子包括欺诈检测、异常检测和医学诊断。
- en: The Curse of Class Imbalance
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 类别不平衡的诅咒
- en: A model trained on an imbalanced dataset perform poorly on the minority class.
    At best, this can cause loss to the business in the case of a churn analysis.
    At worst, it can pervade systemic bias of a face recognition system.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在不平衡的数据集上训练的模型在少数类别上表现不佳。在最佳情况下，这可能会导致业务损失，如客户流失分析。而在最糟糕的情况下，它可能会蔓延到面部识别系统的系统性偏见中。
- en: '![](../Images/7e0577b405b22eaa703f8b6695043510.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7e0577b405b22eaa703f8b6695043510.png)'
- en: 'A balanced dataset might just be the missing ingredient (Source:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一个平衡的数据集可能就是缺少的关键（来源：
- en: Elena Mozhvilo on [Unsplash](https://unsplash.com/photos/j06gLuKK0GM))
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Elena Mozhvilo 在 [Unsplash](https://unsplash.com/photos/j06gLuKK0GM))
- en: The common approach to class imbalance is resampling. These can entail oversampling
    the majority class, undersampling the minority class, or a combination of both.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 处理类别不平衡的常见方法是重采样。这可能包括对多数类别进行过采样、对少数类别进行欠采样，或两者兼而有之。
- en: 'In this post, I use vivid visuals and code to illustrate these strategies for
    class imbalance:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我使用生动的可视化和代码来说明处理类别不平衡的策略：
- en: Random oversampling
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机过采样
- en: Random undersampling
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机欠采样
- en: Oversampling with SMOTE
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用SMOTE进行过采样
- en: Oversampling with ADASYN
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 ADASYN 进行过采样
- en: Undersampling with Tomek Link
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Tomek Link进行欠采样
- en: Oversampling with SMOTE, then undersample with TOMEK Link (SMOTE-Tomek)
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用SMOTE过采样，然后使用TOMEK Link进行欠采样（SMOTE-Tomek）
- en: I will also be using these strategies on a real-world dataset, and evaluate
    their impact on a machine learning model. Let’s go.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我还将在真实世界数据集上使用这些策略，并评估它们对机器学习模型的影响。让我们开始吧。
- en: All source code is here.
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 所有源代码都在这里。
- en: Using Imbalance-learn
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Imbalance-learn
- en: We will use the `imbalanced-learn` package in python to solve our imbalanced
    class problem. It is an open-sourced library relying on scikit-learn and provides
    tools when dealing with classification with imbalanced classes.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Python中的`imbalanced-learn`包来解决类别不平衡的问题。这是一个开源库，依赖于scikit-learn，并提供在处理不平衡类别分类时的工具。
- en: To install it, use the command.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装它，请使用以下命令。
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Dataset
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集
- en: The dataset that we are using is the [**Communities and Crime Data Set by UCI
    (CC BY 4.0)**.](https://archive.ics.uci.edu/ml/datasets/communities+and+crime)
    It contains 100 attributes of 1994 U.S. communities. We can use this to predict
    if the **crime rate is high** (defined as having **per capita violent crime**
    above 0.65). The data source is available in the UCI Machine Learning Repository
    and is created by Michael Redmond from La Salle University (Published in 2009).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的数据集是[**UCI社区与犯罪数据集（CC BY 4.0）**](https://archive.ics.uci.edu/ml/datasets/communities+and+crime)，包含1994年美国社区的100个属性。我们可以用它来预测是否**犯罪率高**（定义为**人均暴力犯罪**超过0.65）。数据来源于UCI机器学习库，由La
    Salle大学的Michael Redmond于2009年发布。
- en: The variables included in the dataset involve the community, such as the percent
    of the population considered urban, and the median family income, and involving
    law enforcement, such as per capita number of police officers, and percent of
    officers assigned to drug units.
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 数据集中包含的变量涉及社区，如被视为城市的人口比例和家庭收入中位数，以及涉及执法，如人均警官数量和分配给毒品单位的警官比例。
- en: This dataset is imbalanced. It has 12 communities with low crime rates for every
    1 community of high crime rate. This is perfect to illustrate our use case.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集存在类别不平衡。对于每一个高犯罪率社区，有12个低犯罪率社区。这非常适合我们的案例说明。
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We will convert this dictionary to a Pandas dataframe, then split it into train-test
    splits.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把这个字典转换成Pandas数据框架，然后分割成训练-测试集。
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note that we will only perform under- and over-sampling only on the train dataset.
    We will *not* change the test sets with under- and over-sampling.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们将仅对训练数据集执行欠采样和过采样。我们将*不会*对测试集进行欠采样和过采样。
- en: Preprocessing the dataset
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集预处理
- en: Our goal is to have a visualize an imbalanced dataset. In order to visualize
    the 128-dimensional dataset in a 2D graph, we do the following on the train set.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是可视化一个不平衡的数据集。为了在二维图中可视化128维的数据集，在训练集上进行以下操作。
- en: scale the dataset,
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缩放数据集，
- en: perform Principle Component Analysis (PCA) on the features to convert the 100
    features to 2 principle components,
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对特征执行主成分分析（PCA），将100个特征转换为2个主成分，
- en: visualize the data.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化数据。
- en: Here’s the data, visualized in 2D.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这是数据在2D中的可视化。
- en: '![](../Images/86931b188116c9c87693d8ef51c041c2.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/86931b188116c9c87693d8ef51c041c2.png)'
- en: Image by author
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'Code for the above graph:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图的代码：
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: With the preprocessing done, we are ready to resample our dataset.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理完成后，我们准备对数据集进行重采样。
- en: Strategy 1\. Random Oversampling
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 策略1\. 随机过采样
- en: Random oversampling duplicates existing examples from the minority class with
    replacement. Each data point in the minority class has an equal probability of
    being duplicated.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 随机过采样通过替换从少数类别中复制现有样本来增加例子。每个少数类别中的数据点有相同的复制概率。
- en: '![](../Images/ceecf5a6b76f1149935c8efbbb4780d8.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ceecf5a6b76f1149935c8efbbb4780d8.png)'
- en: Image by author
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Here’s how to we can perform oversampling on our dataset.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们如何在数据集上进行过采样的方法。
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Let’s compare the data before (left) and after (right) random oversampling.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较随机过采样前（左）和随机过采样后（右）的数据。
- en: '![](../Images/e8d5473774d60edf316cace663f86b4a.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e8d5473774d60edf316cace663f86b4a.png)'
- en: Code for plotting in Github. Image by author
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在Github上绘图的代码。图片来源：作者
- en: The only difference? After random oversampling, there are more **overlapping
    data points in the minority class**. As a result, the data points of the minority
    class appear darker.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的区别？在随机过采样之后，少数类中的**重叠数据点更多**。因此，少数类的数据点看起来更暗。
- en: '**Strategy 2\. Random Undersampling**'
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**策略2：随机欠采样**'
- en: Conversely, random undersampling removes existing samples from the majority
    class. Each data point in the majority class has an equal chance of being removed.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，随机欠采样会从多数类中移除现有样本。多数类中的每个数据点被移除的机会是相等的。
- en: '![](../Images/8eeea9953f7b07db8e240e34bbf4b009.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8eeea9953f7b07db8e240e34bbf4b009.png)'
- en: Image by author
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: We can do this with the following code.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用以下代码来实现这一点。
- en: '[PRE5]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Let’s compare the data before (left) and after (right) random undersampling.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较随机欠采样前（左）和后（右）的数据。
- en: '![](../Images/783b6e0d87a1ebec3168b582b8d21975.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/783b6e0d87a1ebec3168b582b8d21975.png)'
- en: Image by author
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: After undersampling, the overall number of data points decreased significantly.
    That’s because the data points in the majority class are removed at random until
    the classes are balanced.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 欠采样后，数据点的总体数量显著减少。这是因为在类平衡之前，随机移除多数类中的数据点。
- en: Applying machine learning to under- and over-sampled sets
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将机器学习应用于欠采样和过采样数据集
- en: Let’s compare the performance of a classification machine learning model (SVM
    model) trained on three datasets above (unmodified, under- dataset, and over-sampled
    dataset)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较在上面三个数据集（未修改数据集、欠采样数据集和过采样数据集）上训练的分类机器学习模型（SVM模型）的表现
- en: 'Here, we train three Support Vector Machine Classifiers (SVC) on three datasets:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们在三个数据集上训练了三种支持向量机分类器（SVC）：
- en: Original data
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始数据
- en: Randomly over-sampled data
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机过采样的数据
- en: randomly under-sampled data
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机欠采样的数据
- en: '[PRE6]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Then, we can visualize what each SVC has learnt from the dataset.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以可视化每个SVC从数据集中学到的内容。
- en: '![](../Images/c790f8a28ebcf0e5a45dbd055b11cc7f.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c790f8a28ebcf0e5a45dbd055b11cc7f.png)'
- en: Image by author
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: 'The graphs above summarize what the algorithms have learnt from the dataset.
    In particular, they have learned that:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图总结了算法从数据集中学到的内容。特别是，它们学到了：
- en: A new point falls that falls into the **yellow** region is predicted as a **yellow**
    point (‘*High crime rate community*’)
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个落入**黄色**区域的新点被预测为**黄色**点（‘*高犯罪率社区*’）
- en: A new point falls that falls into the **purple** region is predicted as a **purple**
    point (‘*Low crime rate community*’)
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个落入**紫色**区域的新点被预测为**紫色**点（‘*低犯罪率社区*’）
- en: 'Here are some observations:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些观察：
- en: The SVC trained on the *original* dataset is… quite useless. It essentially
    predicts all communities as purple. It learns to ignore all yellow points.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练在*原始*数据集上的SVC…相当无用。它基本上将所有社区预测为紫色。它学会忽视所有黄色点。
- en: The SVCs trained on oversampled and undersampled datasets are less biased. They
    are less likely to call misclassfy the minority class.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练在过采样和欠采样数据集上的SVC的偏差较小。它们更不容易错误分类少数类。
- en: The decision boundaries of SVCs trained on over-sampled and under-sampled dataset
    differ.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练在过采样和欠采样数据集上的SVC的决策边界有所不同。
- en: Using ROC to evaluate resampled models
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用ROC评估重采样模型
- en: To evaluate which SVC is the best, we will have to evaluate the performance
    of the SVCs on a test set. The metric that we will use is the receiver operating
    curve (ROC) to find the area under curve (AUC). Please search (Cmd+F) for “**Appendix
    1”** for an introduction to ROC.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估哪个SVC最佳，我们将评估SVC在测试集上的表现。我们将使用的指标是接收者操作特征曲线（ROC），以找到曲线下面积（AUC）。请搜索（Cmd+F）“**附录1**”以了解ROC的介绍。
- en: '![](../Images/efe1e7a50daeb633bc071de887eb0593.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/efe1e7a50daeb633bc071de887eb0593.png)'
- en: Image by author
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: '[PRE7]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The SVC trained on the original data performed poorly. It did worse than if
    we were to randomly guess the output.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在原始数据上训练的SVC表现不佳。它的表现比我们随机猜测结果还要差。
- en: The randomly oversampled dataset outperformed the under-sampled dataset. One
    possible reason is that there is a loss of information from removing data points
    from the undersampling procedure. Conversely, no information is lost from oversampling
    the data.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 随机过采样的数据集优于欠采样的数据集。一个可能的原因是，从欠采样过程中移除数据点会丧失信息。相反，过采样不会丢失信息。
- en: Now that we have an understanding of oversampling and undersampling, let’s delve
    deeper into oversampling and undersampling techniques.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对过采样和欠采样技术有了理解，让我们深入探讨过采样和欠采样。
- en: Strategy 3\. Oversampling with SMOTE
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 策略 3\. 使用SMOTE进行过采样
- en: SMOTE is a method of oversampling. Intuitively, SMOTE creates synthetic data
    points by interpolating between the minority data points that are close by to
    one another.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: SMOTE是一种过采样方法。直观地说，SMOTE通过在彼此之间插值的少数数据点之间创建合成数据点。
- en: Here’s how SMOTE works (simplified).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这是SMOTE工作的简化说明。
- en: Randomly select some data points in the minority class.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机选择少数类中的一些数据点。
- en: For every selected point, identify its *k* nearest neighbour(s).
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个选定的点，识别其*k*个最近邻居。
- en: For every neighbor, add a new point somewhere between the data point and the
    neighbor.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个邻居，添加一个新点，该点位于数据点和邻居之间的某处。
- en: Repeat steps 2 to 4 until sufficient synthetic data points are created.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤2到4，直到生成足够的合成数据点。
- en: '*Please search (Cmd+F) for “Appendix 2” for the exact algorithm of SMOTE in
    the words of its creator.*'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '*请搜索（Cmd+F）“附录2”以查找其创作者对SMOTE算法的确切描述。*'
- en: Here’s a visualization.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个可视化。
- en: Let’s oversample our dataset with SMOTE and train an SVC on it.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用SMOTE对数据集进行过采样，并在其上训练一个SVC。
- en: '[PRE8]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Here’s the result.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果。
- en: '![](../Images/93afb26c0ba1103f7dee31647bb1d0ea.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/93afb26c0ba1103f7dee31647bb1d0ea.png)'
- en: Image by author
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: Strategy 4\. Oversampling with ADASYN (+ How it’s different from SMOTE)
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 策略 4\. 使用ADASYN进行过采样（+它与SMOTE的不同之处）
- en: 'ADASYN is a cousin of SMOTE: both SMOTE and ADASYN generate new samples by
    interpolation.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ADASYN是SMOTE的一个变种：SMOTE和ADASYN都通过插值生成新样本。
- en: But there’s on critical difference. ADASYN generates samples next to the original
    samples that are wrongly classified by a KNN classifier. Conversely, SMOTE differentiates
    between samples that are correctly or wrongly classified by the KNN classifier.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 但有一个关键的区别。ADASYN会在被KNN分类器错误分类的原始样本旁边生成样本。相反，SMOTE区分了被KNN分类器正确或错误分类的样本。
- en: Here’s a visualization of how ADASYN works.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这是ADASYN工作原理的可视化。
- en: Let’s oversample our dataset with ADASYN and train an SVC on it.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用ADASYN对数据集进行过采样，并在其上训练一个SVC。
- en: '[PRE9]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Let’s compare SMOTE, ADASYN, and the original dataset.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较SMOTE、ADASYN和原始数据集。
- en: '![](../Images/b0508f63d53bdbdac8559a5ced5afb8c.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b0508f63d53bdbdac8559a5ced5afb8c.png)'
- en: Image by author
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: Here are a few observations.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几点观察。
- en: First, both over-sampling approaches cause more synthetic data points to be
    created *in between* original data points. That’s because both SMOTE and ADASYN
    use *interpolation* to create new data points.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，两种过采样方法都会在原始数据点之间创建更多的合成数据点。这是因为SMOTE和ADASYN都使用插值来创建新的数据点。
- en: Second, comparing SMOTE and ADASYN, we notice ADASYN creates data points for
    minority (*yellow*) points near the majority (*purple*) data points.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，比较SMOTE和ADASYN时，我们注意到ADASYN会在少数（*黄色*）点附近的多数（*紫色*）数据点创建数据点。
- en: Comparing the regions circled in blue above, ADASYN created *fewer* yellow data
    points in regions with only a few purple data points.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较上面用蓝色圈出的区域，ADASYN在只有少数紫色数据点的区域创建了*较少*的黄色数据点。
- en: Comparing the regions circled in brown above, ADASYN created *more* yellow data
    points in regions with more purple data points.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较上面用棕色圈出的区域，ADASYN在紫色数据点较多的区域创建了*更多*的黄色数据点。
- en: Let’s compare the ROC of all over-sampling methods we have described so far.
    In this example, they perform equally well.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较到目前为止我们描述的所有过采样方法的ROC曲线。在这个例子中，它们表现同样出色。
- en: '![](../Images/3efbe5c0f92b3f979af1a495623abe81.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3efbe5c0f92b3f979af1a495623abe81.png)'
- en: Image by author
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: Strategy 5\. Under-sampling with Tomek Links
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 策略 5\. 使用汤姆克链接进行欠采样
- en: A tomek link is a pair of points that are very close to one another but are
    of different classes. *Tomek Link’s mathematical definition can be found in the
    Appendix 3.*
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 汤姆克链接是一对非常接近但属于不同类别的点。*汤姆克链接的数学定义可以在附录3中找到。*
- en: Here’s a visualization.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个可视化。
- en: To under-sample with Tomek Links, we will identify all Tomek Links in the data
    set. For each pair of data point in the Tomek Link, we will remove the majority
    class.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用汤姆克链接进行欠采样，我们将识别数据集中所有的汤姆克链接。对于汤姆克链接中的每对数据点，我们将删除多数类别。
- en: Here’s an animation that illustrates undersampling with Tomek Link.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个动画，说明了使用汤姆克链接进行欠采样。
- en: We will apply Tomek Link undersampling to our dataset.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将对我们的数据集应用汤姆克链接欠采样。
- en: '[PRE10]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now let’s compare Tomek undersampling with random undersampling.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们比较 Tomek 欠采样和随机欠采样。
- en: '![](../Images/a0d832d1141b4bd1673e53d1bef2c71f.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a0d832d1141b4bd1673e53d1bef2c71f.png)'
- en: Image by author
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: In our particular dataset, removing Tomek Link did little to ease the class
    imbalance. This is because there are limited number of Tomek Links in the dataaset.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的数据集中，移除 Tomek Link 对缓解类别不平衡几乎没有作用。这是因为数据集中 Tomek Links 的数量有限。
- en: Let’s see how the performance of undersampling with Tomek Link differs from
    that of random undersampling.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 Tomek Link 欠采样的表现与随机欠采样有何不同。
- en: '![](../Images/b45b058004a2d9c4af8eec5d33d36a39.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b45b058004a2d9c4af8eec5d33d36a39.png)'
- en: Image by author
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: We observe that **random undersampling did better than Tomek Link undersampling.**
    This is because Tomek Link did not remove the class imbalance completely like
    random undersampling did.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们观察到**随机欠采样比 Tomek Link 欠采样效果更好。** 这是因为 Tomek Link 没有像随机欠采样那样完全消除类别不平衡。
- en: 'Strategy 6\. SMOTEK: Oversample with SMOTE, then Undersample with Tomek Links'
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 策略 6\. SMOTEK：先使用 SMOTE 过采样，然后使用 Tomek Links 欠采样
- en: Now that we have learnt about oversampling and undersampling. Can we combine
    these techniques?
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了过采样和欠采样。我们可以将这些技术结合起来吗？
- en: Of course! **SMOTE-TOMEK** is a technique that combines oversampling (SMOTE)
    with undersampling (with Tomek Links).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 当然！**SMOTE-TOMEK** 是一种结合了过采样（SMOTE）和欠采样（通过 Tomek Links）的技术。
- en: We will apply it to our dataset.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将其应用到我们的数据集上。
- en: '[PRE11]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Let’s compare SMOTE, Tomek, and SMOTE-Tomek.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较 SMOTE、Tomek 和 SMOTE-Tomek。
- en: '![](../Images/798077ce2d76cec375453ddcf4493c0a.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/798077ce2d76cec375453ddcf4493c0a.png)'
- en: Image by author
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: Comparing SMOTE-Tomek with SMOTE Only, we see the difference being circled in
    brown. SMOTE-Tomek removes the points that are close to the boundary.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 比较 SMOTE-Tomek 和仅 SMOTE，我们可以看到差异被圈出了棕色的圈。SMOTE-Tomek 移除了接近边界的点。
- en: For the grand finale, we will compare all the techniques that we have described
    above. Viola, SMOTE-TOMEK performed the best.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们将比较上述描述的所有技术。结果是，SMOTE-TOMEK 表现最佳。
- en: '![](../Images/1bf9ed2d4e34e8377859560edbbfc7c3.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1bf9ed2d4e34e8377859560edbbfc7c3.png)'
- en: Image by author
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: Closing
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结束
- en: Overall, you can use oversampling, undersampling or a combination of both to
    deal with data imbalance. If you have the computational resources, it is often
    better to use a combination of over- and under-sampling; Oversampling is a good
    strategy when you have few datapoints; while undersampling is good when there
    are potentially many similar data points.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来说，你可以使用过采样、欠采样或两者的组合来处理数据不平衡问题。如果你有计算资源，通常更好的方法是使用过采样和欠采样的组合；当数据点较少时，过采样是一种不错的策略；而当有许多类似数据点时，欠采样则表现较好。
- en: Dealing with imbalance dataset is not easy. I would encourage you to explore
    many other resampling strategies (including the different [undersampling methods](https://imbalanced-learn.org/dev/references/under_sampling.html)
    and [oversampling methods](https://imbalanced-learn.org/dev/references/over_sampling.html))
    to see which strategy performs the best on your dataset.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 处理不平衡数据集并不容易。我鼓励你探索许多其他重采样策略（包括不同的 [欠采样方法](https://imbalanced-learn.org/dev/references/under_sampling.html)
    和 [过采样方法](https://imbalanced-learn.org/dev/references/over_sampling.html)），以查看哪种策略在你的数据集上表现最好。
- en: Also, measuring the performance of imbalance dataset can be tricky. Make sure
    you use the right classification metrics. Luckily, metrics like [ROC Curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html),
    [F1 score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)
    and [geometric mean scores](https://imbalanced-learn.org/dev/references/metrics.html)
    are already available to us.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，评估不平衡数据集的性能可能会很棘手。确保使用正确的分类指标。幸运的是，[ROC 曲线](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html)、[F1
    分数](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)
    和 [几何均值分数](https://imbalanced-learn.org/dev/references/metrics.html) 等指标已经可供使用。
- en: I am Travis Tang. I post data science content on LinkedIn and Medium. Follow
    me for more :)
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我是 Travis Tang。我在 LinkedIn 和 Medium 上发布数据科学内容。关注我以获取更多内容 :)
- en: Appendix
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录
- en: Appendix 1\. Using ROC to evaluate models in class imbalance problems
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 1\. 使用 ROC 评估类别不平衡问题中的模型
- en: ROC is insensitive to class imbalance, making it a great tool to evaluate models
    with class imbalance. It does not depend on the class prevalence. This is in contrast
    to evaluation metrics such as accuracy, which can be misleading in the presence
    of class imbalance.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ROC 对类别不平衡不敏感，使其成为评估类别不平衡模型的绝佳工具。它不依赖于类别的普遍性。这与像准确率这样的评估指标形成对比，后者在类别不平衡时可能会产生误导。
- en: '![](../Images/ea7535e53d252dd13478c5d82f190260.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ea7535e53d252dd13478c5d82f190260.png)'
- en: Drawn by CMG Lee based on [http://commons.wikimedia.org/wiki/File:roc-draft-xkcd-style.svg](https://commons.wikimedia.org/wiki/File:roc-draft-xkcd-style.svg)
    .
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 由 CMG Lee 绘制，基于 [http://commons.wikimedia.org/wiki/File:roc-draft-xkcd-style.svg](https://commons.wikimedia.org/wiki/File:roc-draft-xkcd-style.svg)。
- en: An ROC curve plots the true positive rate (TPR) on the y-axis against the false
    positive rate (FPR) on the x-axis for all possible classification thresholds.
    The TPR is the proportion of positive instances that are correctly classified
    as positive, and the FPR is the proportion of negative instances that are incorrectly
    classified as positive.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ROC 曲线绘制了 y 轴上的真实正例率 (TPR) 对 x 轴上的假正例率 (FPR) 的图像，用于所有可能的分类阈值。TPR 是正确分类为正例的正例实例的比例，而
    FPR 是错误分类为正例的负例实例的比例。
- en: A model with good performance will have a ROC curve that is closer to the top-left
    corner of the plot, as this indicates a higher TPR and a lower FPR. A model makes
    completely random guesses will fall on the line with TPR = FPR.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 一个性能良好的模型将具有接近图表左上角的 ROC 曲线，因为这表示更高的 TPR 和更低的 FPR。一个完全随机猜测的模型将落在 TPR = FPR 的线条上。
- en: Appendix 2\. The exact algorithm of SMOTE algorithm
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 2\. SMOTE 算法的确切算法
- en: 'The minority class is over-sampled by taking each minority class sample and
    introducing synthetic examples along the line segments joining any/all of the
    k minority class nearest neighbors. Depending upon the amount of over-sampling
    required, neighbors from the k nearest neighbors are randomly chosen. Our implementation
    currently uses five nearest neighbors. For instance, if the amount of over-sampling
    needed is 200%, only two neighbors from the five nearest neighbors are chosen
    and one sample is generated in the direction of each. Synthetic samples are generated
    in the following way: Take the difference between the feature vector (sample)
    under consideration and its nearest neighbor. Multiply this difference by a random
    number between 0 and 1, and add it to the feature vector under consideration.
    This causes the selection of a random point along the line segment between two
    specific features. This approach effectively forces the decision region of the
    minority class to become more general. [2]'
  id: totrans-163
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 少数类通过取每个少数类样本并沿连接任意/所有 k 个少数类最近邻的线段引入合成样本来进行过采样。根据所需的过采样量，从 k 个最近邻中随机选择邻居。我们目前的实现使用五个最近邻。例如，如果所需的过采样量为
    200%，则从五个最近邻中选择两个邻居，并在每个邻居的方向上生成一个样本。合成样本的生成方式如下：取考虑中的特征向量（样本）与其最近邻之间的差异。将此差异乘以一个
    0 到 1 之间的随机数，并将其加到考虑中的特征向量上。这会在两个特定特征之间的线段上选择一个随机点。这种方法有效地使少数类的决策区域变得更一般化。 [2]
- en: Appendix 3\. Definition of **Tomek Links**
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 3\. **Tomek Links** 的定义
- en: Given two examples Ei and Ej belonging to diﬀerent classes, and d(Ei, Ej) is
    the distance between Ei and Ej. A (Ei, Ej) pair is called a Tomek link if there
    is not an example El, such that d(Ei, El)< d(Ei, Ej) or d(Ej, El)< d(Ei, Ej).
    *[1]*
  id: totrans-165
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 给定两个属于不同类别的样本 Ei 和 Ej，d(Ei, Ej) 是 Ei 和 Ej 之间的距离。如果不存在样本 El，使得 d(Ei, El) < d(Ei,
    Ej) 或 d(Ej, El) < d(Ei, Ej)，则 (Ei, Ej) 对被称为 Tomek link。*[1]*
- en: References
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Batista, Gustavo EAPA, Ronaldo C. Prati, and Maria Carolina Monard. “[A
    Study of the Behavior of Several Methods for Balancing Machine Learning Training
    Data](https://www.researchgate.net/publication/220520041_A_Study_of_the_Behavior_of_Several_Methods_for_Balancing_machine_Learning_Training_Data)”
    *ACM SIGKDD explorations newsletter* 6.1 (2004): 20–29.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Batista, Gustavo EAPA, Ronaldo C. Prati, 和 Maria Carolina Monard. “[A Study
    of the Behavior of Several Methods for Balancing Machine Learning Training Data](https://www.researchgate.net/publication/220520041_A_Study_of_the_Behavior_of_Several_Methods_for_Balancing_machine_Learning_Training_Data)”
    *ACM SIGKDD explorations newsletter* 6.1 (2004): 20–29。'
- en: '[2] Chawla, Nitesh V., et al. “[SMOTE: synthetic minority over-sampling technique.](https://dl.acm.org/doi/10.5555/1622407.1622416)”
    *Journal of artificial intelligence research* 16 (2002): 321–357.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Chawla, Nitesh V., 等. “[SMOTE: synthetic minority over-sampling technique.](https://dl.acm.org/doi/10.5555/1622407.1622416)”
    *Journal of artificial intelligence research* 16 (2002): 321–357。'
