- en: Automatically Detecting Label Errors in Datasets with CleanLab
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 CleanLab 自动检测数据集中的标签错误
- en: 原文：[https://towardsdatascience.com/automatically-detecting-label-errors-in-datasets-with-cleanlab-e0a3ea5fb345?source=collection_archive---------3-----------------------#2023-07-22](https://towardsdatascience.com/automatically-detecting-label-errors-in-datasets-with-cleanlab-e0a3ea5fb345?source=collection_archive---------3-----------------------#2023-07-22)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/automatically-detecting-label-errors-in-datasets-with-cleanlab-e0a3ea5fb345?source=collection_archive---------3-----------------------#2023-07-22](https://towardsdatascience.com/automatically-detecting-label-errors-in-datasets-with-cleanlab-e0a3ea5fb345?source=collection_archive---------3-----------------------#2023-07-22)
- en: A Tale of AI and wrongly-classified Brazilian Federal Laws
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一则关于人工智能和错误分类的巴西联邦法律的故事
- en: '[](https://joaopedro214.medium.com/?source=post_page-----e0a3ea5fb345--------------------------------)[![João
    Pedro](../Images/64a0e14527be213e5fde0a02439fbfa7.png)](https://joaopedro214.medium.com/?source=post_page-----e0a3ea5fb345--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e0a3ea5fb345--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e0a3ea5fb345--------------------------------)
    [João Pedro](https://joaopedro214.medium.com/?source=post_page-----e0a3ea5fb345--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://joaopedro214.medium.com/?source=post_page-----e0a3ea5fb345--------------------------------)[![João
    Pedro](../Images/64a0e14527be213e5fde0a02439fbfa7.png)](https://joaopedro214.medium.com/?source=post_page-----e0a3ea5fb345--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e0a3ea5fb345--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e0a3ea5fb345--------------------------------)
    [João Pedro](https://joaopedro214.medium.com/?source=post_page-----e0a3ea5fb345--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb111eee95c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomatically-detecting-label-errors-in-datasets-with-cleanlab-e0a3ea5fb345&user=Jo%C3%A3o+Pedro&userId=b111eee95c&source=post_page-b111eee95c----e0a3ea5fb345---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e0a3ea5fb345--------------------------------)
    ·10 min read·Jul 22, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe0a3ea5fb345&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomatically-detecting-label-errors-in-datasets-with-cleanlab-e0a3ea5fb345&user=Jo%C3%A3o+Pedro&userId=b111eee95c&source=-----e0a3ea5fb345---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb111eee95c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomatically-detecting-label-errors-in-datasets-with-cleanlab-e0a3ea5fb345&user=Jo%C3%A3o+Pedro&userId=b111eee95c&source=post_page-b111eee95c----e0a3ea5fb345---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e0a3ea5fb345--------------------------------)
    ·10 分钟阅读·2023年7月22日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe0a3ea5fb345&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomatically-detecting-label-errors-in-datasets-with-cleanlab-e0a3ea5fb345&user=Jo%C3%A3o+Pedro&userId=b111eee95c&source=-----e0a3ea5fb345---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe0a3ea5fb345&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomatically-detecting-label-errors-in-datasets-with-cleanlab-e0a3ea5fb345&source=-----e0a3ea5fb345---------------------bookmark_footer-----------)![](../Images/36477c5670bfa2ec58e04ee972390139.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe0a3ea5fb345&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomatically-detecting-label-errors-in-datasets-with-cleanlab-e0a3ea5fb345&source=-----e0a3ea5fb345---------------------bookmark_footer-----------)![](../Images/36477c5670bfa2ec58e04ee972390139.png)'
- en: Photo by [Gustavo Leighton](https://unsplash.com/@g_leighton?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Gustavo Leighton](https://unsplash.com/@g_leighton?utm_source=medium&utm_medium=referral)
    提供，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: A few weeks ago, while doing my usual search for datasets to develop my personal
    projects, I came across the Brazilian Chamber of Deputies Open Data Portal, which
    contains a lot of data — including the deputies' costs, parties metadata, etc
    — everything available trough a nice [API](https://dadosabertos.camara.leg.br/swagger/api.html#staticfile).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 几周前，当我在进行个人项目的数据集搜索时，我偶然发现了巴西众议院开放数据门户网站，这里包含了大量的数据——包括议员的费用、政党元数据等——所有这些数据都可以通过一个不错的
    [API](https://dadosabertos.camara.leg.br/swagger/api.html#staticfile) 获取。
- en: 'After a few hours of searching and inspecting, something very interesting caught
    my attention: The compilation of all the laws proposed by the parliamentarians
    with their ‘*ementas’* (concise summary), author, year, and, more importantly,
    their **themes** (health, security, finance, etc…) — categorized by the Chamber’s
    Documentation and Information Center (Centro de Documentação e Informação da Câmara,
    on literal translation).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 几小时的搜索和检查后，有一些非常有趣的事情引起了我的注意：所有由议员提出的法律的汇编，包括它们的‘*ementas*’（简要摘要）、作者、年份，更重要的是，它们的**主题**（健康、安全、金融等）——由议会文献和信息中心（Centro
    de Documentação e Informação da Câmara）分类。
- en: A spark shined in my brain — “*I’ll make a supervised classification pipeline
    to* ***predict the theme of a law******using its summary****, exploring some infrastructure
    aspect of Machine learning, like data versioning with DVC or something like that.*”
    I quickly wrote a script and gathered an extensive dataset comprising over 60,000
    laws, spanning the period from 1990 to 2022.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我的脑海中闪现出一个灵光——“*我将创建一个监督分类管道来* ***预测法律的主题******使用其摘要****，探索机器学习的一些基础设施方面，如使用DVC的数据版本控制或类似的东西*。”我迅速编写了一个脚本，收集了一个包含超过60,000条法律的大型数据集，时间跨度从1990年到2022年。
- en: 'I’ve already worked a little with Judiciary and Legislative data, so I had a feeling that this task would not be hard.
    But, to make things even easier, I choose to classify only whether a law proposal
    (LP) is about “*Tributes and commemorative dates*” or not (binary classification).
    In theory, it should be easy, as the texts are very simple:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经稍微涉猎过司法和立法数据，所以我有一种感觉这个任务不会很难。但是，为了更轻松些，我选择仅分类法律提案（LP）是否涉及“*纪念和纪念日期*”（二分类）。理论上，这应该很简单，因为文本非常简单：
- en: '![](../Images/a26315bf71eaec67b082f036007bfbbb.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a26315bf71eaec67b082f036007bfbbb.png)'
- en: Original summaries and a literal translation by ChatGPT - I. Image by Author.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 原始摘要和ChatGPT的字面翻译 - I。图片由作者提供。
- en: But, no matter what I tried to do, my performance did not rise above the ~0.80
    mark on the f1 score, with a relatively low recall (for the positive class) of
    0.5–0.7.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，无论我尝试了什么，我的性能在f1分数上始终未能超过~0.80，且（正类的）召回率相对较低，为0.5–0.7。
- en: Of course, my dataset is highly unbalanced, with this class representing less
    than 5% of the dataset size, but there is something more.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我的数据集高度不平衡，这一类别占数据集总量的不到5%，但还有更多因素。
- en: 'After some investigation, inspecting the data with regex-based queries, and
    looking into the wrong-classified records, I found several examples incorrectly
    labeled. With my crude approach, I’ve found ~200 false negatives, which represent
    ~7.5% of the “true” positives and 0.33% of all my dataset, without mentioning
    the false positives. See a few below:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 经过一些调查，使用基于正则表达式的查询检查数据，查看错误分类记录后，我发现了几个错误标记的例子。通过我粗略的方法，我发现了~200个假阴性，占“真实”正例的~7.5%和我数据集的0.33%，还没有提到假阳性。见下图：
- en: '![](../Images/86340626c166a22cac095a5946da6dbd.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/86340626c166a22cac095a5946da6dbd.png)'
- en: Wrongly classified examples. Image by Author.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 错误分类的例子。图片由作者提供。
- en: These examples were rotting my validation metrics — “*How many of them could
    exist? Will I have to search the errors manually?*”
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这些例子影响了我的验证指标——“*它们可能有多少个？我需要手动搜索错误吗？*”
- en: But then **Confident Learning** materialized as the **Clean Lab** python package,
    came to save me.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，**Confident Learning** 作为**Clean Lab** Python包的形式出现，来拯救我了。
- en: '![](../Images/1e88f7af7141237d5d19f6b5f3c4f018.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e88f7af7141237d5d19f6b5f3c4f018.png)'
- en: Clean Lab Logo. Image from [GitHub](https://github.com/cleanlab/cleanlab).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Clean Lab标志。图片来自[GitHub](https://github.com/cleanlab/cleanlab)。
- en: What is Confident Learning?
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是Confident Learning？
- en: Correctly labeling data is one of the most time-consuming and costly steps in
    any supervised machine-learning project. Techniques like crowdsourcing, semi-supervised
    learning, fine-tuning, and many others try to reduce the cost of collecting labels
    or the need for such labels in model training.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 正确标记数据是任何监督机器学习项目中最耗时且最昂贵的步骤之一。像众包、半监督学习、微调等技术尝试减少收集标签的成本或减少模型训练中对这些标签的需求。
- en: Fortunately, we are already a step ahead of this problem. We have labels given
    by professionals, probably government workers with adequate *know-how*. But my
    non-professional eyes with my crude regex approach could spot mistakes as soon
    as they broke my performance expectations.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们已经在这个问题上领先一步。我们有专业人士提供的标签，可能是具备足够*专业知识*的政府工作人员。但我以粗略正则表达式处理的非专业视角一旦超出我的性能预期，就能发现错误。
- en: 'The point is: How many errors are still in the data?'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 关键点是：数据中还有多少错误？
- en: It’s not reasonable to inspect every single law — An **automatic** way of detecting
    **incorrect labels** is necessary, and that’s what Confident Learning is.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 检查每一条法律是不现实的——需要一种 **自动** 检测 **错误标签** 的方法，这就是 Confident Learning 的作用。
- en: In summary, it uses statistics gathered from model probability predictions to
    estimate errors in the dataset. It can detect noise, outliers, and — the main
    subject of this post — **label errors**.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，它使用从模型概率预测中收集的统计数据来估计数据集中的错误。它可以检测噪声、离群值，以及——本篇文章的主要内容——**标签错误**。
- en: I’ll not go into the details of CL, but there is a [very nice article](/confident-learning-err-did-you-say-your-data-is-clean-ef2597903328)
    covering its main points and a [YT video](https://youtu.be/BnOTv0f9Msk) from the
    creator of **CleanLab** talking about its research on the field.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会详细介绍 CL，但有一篇[很好的文章](/confident-learning-err-did-you-say-your-data-is-clean-ef2597903328)涵盖了它的主要要点，还有一个来自
    **CleanLab** 创始人的[YT 视频](https://youtu.be/BnOTv0f9Msk)谈论它在该领域的研究。
- en: Let’s see how it works in practice.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它在实践中是如何工作的。
- en: The data
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据
- en: The data was gathered from the Brazilian Chamber of Deputies Open Data Portal,
    containing law proposals (LP) from 1990 to 2022\. The final dataset contains ~60K
    LPs.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 数据来自巴西众议院开放数据门户，包含 1990 年至 2022 年的法律提案（LP）。最终的数据集包含约 60K LPs。
- en: A single LP can have multiple themes associated with it, like Health and Finance,
    and this information is also available in the Open Data Portal. To make it easier
    to handle, I’ve encoded the theme information by binarizing each individual theme
    in a separate column.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 单个 LP 可能与多个主题相关，例如健康和金融，这些信息也可以在开放数据门户中找到。为了更方便处理，我通过将每个单独的主题二值化到单独的列中来编码主题信息。
- en: As previously mentioned, the theme used in this post is “*Tributes and commemorative
    dates*”. I choose it because its *ementas* are very short and simple, so the labels
    errors are easy to identify.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，本篇文章使用的主题是“*致敬和纪念日期*”。我选择它是因为它的 *ementas* 非常简短且简单，因此标签错误很容易识别。
- en: The data and the code are available in the [project’s GitHub repository](https://github.com/jaumpedro214/data-analysis-camara-federal-pls).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 数据和代码可以在[项目的 GitHub 仓库](https://github.com/jaumpedro214/data-analysis-camara-federal-pls)中找到。
- en: The Implementation
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现
- en: Our goal is to fix every single label error in the “*Tributes and commemorative
    dates*” automatically and finish this post with a nice and clean Dataset ready
    to be used in a Machine Learning problem.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是自动修复“*致敬和纪念日期*”中的每一个标签错误，并使这个帖子以一个干净、整洁的数据集作为结束，准备好用于机器学习问题。
- en: Setup the environment
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置环境
- en: All needed to run this project are the classical ML/Data Science Python packages
    (Pandas, Numpy & Scikit-Learn) + the CleanLab package.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这个项目所需的是经典的 ML/Data Science Python 包（Pandas, Numpy 和 Scikit-Learn）+ CleanLab
    包。
- en: '[PRE0]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Just install these requirements and we’re ready to go.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 只需安装这些要求，我们就可以开始了。
- en: Detecting Label Errors with CL
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 CL 检测标签错误
- en: The CleanLab package comes natively with the ability to identify many types
    of dataset problems, like outliers and duplicate/near-duplicate entries, but we’ll
    be only interested in the **label errors**.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: CleanLab 包自带识别许多数据集问题的能力，如离群值和重复/接近重复的条目，但我们只对 **标签错误** 感兴趣。
- en: '**CleanLab** uses probabilities generated by a Machine Learning model representing
    its confidence of an entry being a certain label. If the dataset has *n* entries
    and *m* classes, then this will be represented by an *n* by *m* matrix P, where
    P[i, j] represents the probability of row *i* being of class *j*.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**CleanLab** 使用由机器学习模型生成的概率，这些概率代表了条目被标记为某个标签的信心。如果数据集有 *n* 个条目和 *m* 个类别，那么这将由一个
    *n* x *m* 的矩阵 P 表示，其中 P[i, j] 代表第 *i* 行属于类别 *j* 的概率。'
- en: These probabilities and the “true” labels are used in the CleanLab internals
    to estimate the errors.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这些概率和“真实”标签被用在 CleanLab 的内部以估计错误。
- en: 'Let’s practice:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们练习一下：
- en: '*Importing packages*'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*导入包*'
- en: '[PRE1]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '*loading data…*'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*加载数据中…*'
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: First of all, let’s generate the probabilities.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们生成概率。
- en: 'As mentioned in the CleanLab documentation, to achieve better performance is
    crucial that the probabilities are generated [on out-of-sample records](https://docs.cleanlab.ai/stable/tutorials/pred_probs_cross_val.html#pred-probs-cross-val)
    (’non-training’ data). This is important as the models naturally tend to be over-confident
    when predicting probabilities on training data. The most usual way to generate
    out-of-sample probabilities in a dataset is to use a K-Fold strategy, as shown
    below:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 正如 CleanLab 文档中提到的，为了实现更好的性能，生成的概率必须 [基于样本外记录](https://docs.cleanlab.ai/stable/tutorials/pred_probs_cross_val.html#pred-probs-cross-val)（‘非训练’数据）。这是很重要的，因为模型在预测训练数据上的概率时，通常会过于自信。生成样本外概率的最常用方法是使用
    K-Fold 策略，如下所示：
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'NOTE: It’s important to be aware of the class distribution — Hence the StratifiedKFold
    object. The chosen class represents less than 5% of the dataset, a naive sampling
    approach could easily lead to poor-quality probabilities generated by models trained
    on wrongly balanced datasets.'
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意：重要的是要了解类别分布 —— 因此使用了 StratifiedKFold 对象。所选类别在数据集中所占比例不足 5%，一种天真的采样方法可能会导致模型在不正确平衡的数据集上生成低质量的概率。
- en: CleanLab uses a class called Datalab to handle its error-detection jobs. It
    receives the DataFrame containing our data and the label column’s name.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: CleanLab 使用一个名为 Datalab 的类来处理其错误检测任务。它接收包含我们数据的 DataFrame 和标签列的名称。
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now, we just need to pass the previously calculated probabilities to it …
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们只需将先前计算的概率传递给它……
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: … to start finding issues
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ……开始查找问题
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/18b86c0c2d30b30543c431a2c24802a7.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/18b86c0c2d30b30543c431a2c24802a7.png)'
- en: And is simple as that.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 就这么简单。
- en: The *get_issues*(”label”) function returns a DataFrame with the metrics and
    indicators calculated by CleanLab for each record. The most important columns
    are ‘*is_label_issue*’ and ‘*predicted_label*’, representing respectively if a
    record has a label issue and the possible correct label for it.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '*get_issues*(”label”) 函数返回一个 DataFrame，包含 CleanLab 为每条记录计算的指标和指标。最重要的列是 ‘*is_label_issue*’
    和 ‘*predicted_label*’，分别表示记录是否存在标签问题以及可能的正确标签。'
- en: '[PRE7]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We can merge this information in the original DataFrame to inspect which examples
    are problematic.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这些信息合并到原始 DataFrame 中，以检查哪些示例是有问题的。
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let’s check a few examples:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看几个例子：
- en: '![](../Images/3860e3258b8a00fd1fdbe455d23c18ab.png)![](../Images/78d445cc8ecdad5f1e1925259f2b4547.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3860e3258b8a00fd1fdbe455d23c18ab.png)![](../Images/78d445cc8ecdad5f1e1925259f2b4547.png)'
- en: To me, these laws are clearly associated with *Tributes and Commemorative Dates*;
    however, they are not appropriately categorized as such.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 对我来说，这些法律显然与*致敬和纪念日期*相关；然而，它们并没有被适当地分类为这些。
- en: Nice ! — CleanLab was able to find 312 label errors in our dataset, but what
    to do now?
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 很好！—— CleanLab 能够在我们的数据集中找到 312 个标签错误，但现在该怎么办？
- en: These errors could be either objects of a manual inspection for correction (in
    an active-learning manner) or instantly corrected (supposing that CleanLab did
    its job right). The former is more time-consuming but could lead to better results,
    while the latter is faster, but could lead to more errors.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这些错误可以是手动检查以进行修正的对象（以主动学习的方式）或立即修正（假设 CleanLab 做得对）。前者更耗时，但可能会导致更好的结果，而后者更快，但可能会导致更多错误。
- en: Regardless of the chosen path, CleanLab reduced the labor from 60K records to
    a few hundred — in the worst case.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 无论选择哪条路径，CleanLab 都将记录的劳动量从 60K 减少到几百条 —— 在最坏的情况下。
- en: '*But there is a catch.*'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*但有一个陷阱。*'
- en: How can we be sure that CleanLab found **all** the errors in the dataset?
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们怎么能确保 CleanLab 找到了数据集中的**所有**错误？
- en: In fact, if we run the above pipeline but with the errors fixed as ground truth,
    CleanLab will find more errors…
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，如果我们运行上述管道，但将错误修正为真实标签，CleanLab 将会发现更多错误……
- en: More errors, but *hopefully* fewer errors than the first run.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 错误更多，但*希望*比第一次运行的错误少。
- en: 'And we can repeat this logic as many times as we want: Find errors, fix errors,
    retrain the model with the new presumed better-quality labels, find errors again
    …'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以重复这个逻辑任意次数：找出错误，修正错误，用新假定的更高质量标签重新训练模型，再次找出错误……
- en: '![](../Images/10bf4f2f521ce9afa9cba9dd8aabecb2.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/10bf4f2f521ce9afa9cba9dd8aabecb2.png)'
- en: Fixing errors iteratively. Image by Author.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代修正错误。图片由作者提供。
- en: With the hope that after some interactions the number of errors will be zero.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 希望在一些交互之后，错误的数量将会是零。
- en: Iteratively fixing errors with CleanLab
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 CleanLab 迭代修正错误
- en: 'To implement this idea all that we need to do is to repeat the process above
    in a loop, the code below does just that:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现这个想法，我们只需在循环中重复上述过程，下面的代码正是这样做的：
- en: Let’s review it.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来回顾一下。
- en: 'In each iteration, the OOS probabilities are generated just as shown previously:
    using the *cross_val_predict* method with StratifiedKFold. The current set of
    probabilities (in each iteration) is used to build a new Datalab object and find
    the new label issues.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在每次迭代中，OOS 概率是按照之前展示的方式生成的：使用*cross_val_predict*方法和StratifiedKFold。当前的概率集（每次迭代中）用于构建一个新的Datalab对象并发现新的标签问题。
- en: The found issues are merged with the current dataset and fixed.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 发现的问题与当前数据集合并并修复。
- en: I choose the strategy of appending the fixed labels as a new column instead
    of replacing the original one.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我选择了将修复后的标签作为新列附加的策略，而不是替换原始列。
- en: '![](../Images/8de06e839952d37d0a01ab1a3d2f79db.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8de06e839952d37d0a01ab1a3d2f79db.png)'
- en: Appending the fixed labels. Image by Author.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 附加修复后的标签。图片由作者提供。
- en: LABEL_COLUMN_0 is the original label, LABEL_COLUMN_1 is the label column fixed
    1 time, LABEL_COLUMN_2 is the label column fixed 2 times, and so on…
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: LABEL_COLUMN_0 是原始标签，LABEL_COLUMN_1 是修复1次的标签列，LABEL_COLUMN_2 是修复2次的标签列，以此类推……
- en: In addition to this process, the usual classification metrics are also computed
    and stored for later inspection.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这个过程之外，还计算并存储了常规分类指标，以备后续检查。
- en: After 8 interactions (~16min) the process is finished.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 经过8次互动（约16分钟），过程完成了。
- en: The Results
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果
- en: The table below shows the performance metrics computed during the process.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 下表显示了在过程中的性能指标。
- en: '![](../Images/4703adfb83c3b6e815df7719203e2aef.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4703adfb83c3b6e815df7719203e2aef.png)'
- en: A total of **393 label errors** were found in the dataset in the 8 iterations.
    As expected, the number of errors found decreased with each iteration.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在8次迭代中，数据集中发现了总计**393个标签错误**。正如预期的那样，发现的错误数量随着每次迭代的增加而减少。
- en: It’s interesting to note that this process was able to “converge” to a “solution”
    with only 6 iterations — staying at 0 errors in the last 2\. This is a good indication
    that, in this case, the CleanLab implementation is robust and did not find any
    more errors by ‘accident’ that could lead to oscillations.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，这个过程在仅仅6次迭代中就能够“收敛”到一个“解决方案”——在最后2次迭代中错误数保持为0。这是一个很好的迹象，说明在这种情况下，CleanLab的实现是稳健的，并且没有发现任何可能导致振荡的‘偶然’错误。
- en: Even though the number of errors represents only 0.6% of the dataset, the f1
    score increased from 0.81 to 0.90, ~11%. This is probably due to the classes being
    highly unbalanced, as the new 322 positive labels represent a total of ~12% in
    the number of original positive examples.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管错误的数量仅占数据集的0.6%，f1分数从0.81提高到了0.90，约11%。这可能是由于类别高度不平衡，因为新的322个正标签总共占原始正样本的约12%。
- en: But was CleanLab really able to find meaningful errors? Let’s check a few examples
    to see if they make sense.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 但CleanLab真的能够发现有意义的错误吗？让我们检查几个例子看看它们是否有意义。
- en: '**False negatives fixed**'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**假阴性已修复**'
- en: '![](../Images/3cd56b85d5a050f44f03bbfaa5af56e4.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3cd56b85d5a050f44f03bbfaa5af56e4.png)'
- en: Original summaries and a literal translation by ChatGPT — II. Image by Author.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 原始总结和ChatGPT的逐字翻译 — II. 图片由作者提供。
- en: The above texts indeed resemble “tributes and commemorative dates”, suggesting
    that they should be appropriately categorized as such — Point to CleanLab
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 上述文本确实类似于“致敬和纪念日期”，这表明它们应该被适当地分类为此类 — 指向CleanLab
- en: '**False positives fixed**'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**假阳性已修复**'
- en: '![](../Images/b6e491d0925dc75bee1219f14afc62bb.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b6e491d0925dc75bee1219f14afc62bb.png)'
- en: Original summaries and a literal translation by ChatGPT — III. Image by Author.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 原始总结和ChatGPT的逐字翻译 — III. 图片由作者提供。
- en: We have a few errors in this case, the 2nd and 4th laws aren’t false positives.
    Not so good, but still ok.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下我们有一些错误，第2和第4条规则不是假阳性。虽然不是很好，但还算可以。
- en: I’ve repeated this inspection sampling new ‘fixed’ laws several times and, in
    general, CleanLab has a nearly perfect performance in detecting false negatives
    but gets a little confused with the false positives.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我重复进行了这个检查采样新‘固定’规则的操作几次，总的来说，CleanLab在检测假阴性方面表现几乎完美，但对假阳性有点困惑。
- en: Now, even though we probably don’t have a *perfectly* labeled dataset, I feel
    way more **confident** in training a machine **learning** model in it now.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，即使我们可能没有一个*完美*标记的数据集，我也更**自信**现在用它来训练机器**学习**模型了。
- en: Conclusion
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: For long the machine learning area suffered from poor quality models and lack
    of computer power, but this time is gone. Now, the real bottleneck for most ML
    applications is data. But not raw data, refined data — with good labels, well-formatted,
    without too much noise or outliers.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习领域长期以来受困于模型质量差和计算能力不足，但这种情况已经过去。现在，大多数机器学习应用的真正瓶颈是数据。不是原始数据，而是经过精炼的数据——具有良好标签、格式规范、噪音或异常值较少的数据。
- en: 'Because no matter how big and powerful a model is, how much statistics and
    maths you mix into your pipeline, any of this will save you from the most basic
    law of computer science: garbage in, garbage out.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 因为无论模型多么庞大和强大，无论你在管道中混入多少统计和数学，这些都无法拯救你免于计算机科学的最基本法则：垃圾进，垃圾出。
- en: 'And this project was a witness to this principle — I’ve tested several models,
    Deep Learning architectures, sampling techniques, and vectorization methods to,
    in the end, discover that the problem was on the basics: my data was wrong.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这个项目见证了这一原则——我测试了几个模型、深度学习架构、采样技术和向量化方法，最终发现问题出在基础上：我的数据是错误的。
- en: In such a scenario, investing in data quality techniques became a critical aspect
    to create successful ML projects.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，投资于数据质量技术成为创建成功机器学习项目的关键方面。
- en: In this post, we explored CleanLab, a package that helped us to detect and fix
    wrong labels in the dataset. It not only enabled us to significantly improve the
    quality of our dataset but it also did this in an automatic, reproducible, and
    cheap way — with no human intervention.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们探讨了 CleanLab，这个包帮助我们检测和修复数据集中的错误标签。它不仅显著提高了数据集的质量，而且以自动、可重复且廉价的方式完成——无需人工干预。
- en: I hope this project helped you in understanding a little more about Confident
    Learning and the CleanLab package. As always, I’m not an expert in any of the
    subjects addressed in this post, and I strongly recommend further reading, see
    some references below.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这个项目能帮助你更好地理解自信学习和 CleanLab 包。正如往常一样，我并不是这些主题的专家，我强烈建议你进一步阅读，以下是一些参考文献。
- en: Thank you for reading! ;)
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您的阅读！😉
- en: References
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: All the code is available in [this GitHub repository](https://github.com/jaumpedro214/data-analysis-camara-federal-pls).
  id: totrans-120
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 所有代码都可以在[这个 GitHub 仓库](https://github.com/jaumpedro214/data-analysis-camara-federal-pls)中找到。
- en: Data used — [Open Data Portal Federal Chamber](https://dadosabertos.camara.leg.br/faq/faq-home.html#r14).
    [Open-Data — Law nº 12.527]
  id: totrans-121
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用的数据 — [开放数据门户联邦议会](https://dadosabertos.camara.leg.br/faq/faq-home.html#r14).
    [开放数据 — 法律 nº 12.527]
- en: All the images are created by the Author, unless otherwise specified.
  id: totrans-122
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 除非另有说明，所有图像均由作者创建。
- en: '[1] Cleanlab. (n.d.). *GitHub — cleanlab/cleanlab: The standard data-centric
    AI package for data quality and machine learning with messy, real-world data and
    labels.* [GitHub](https://github.com/cleanlab/cleanlab).'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Cleanlab. (无日期). *GitHub — cleanlab/cleanlab: 标准的数据中心 AI 包，用于处理混乱的真实世界数据和标签的数据质量和机器学习。*
    [GitHub](https://github.com/cleanlab/cleanlab).'
- en: '[2][*Computing Out-of-Sample Predicted Probabilities with Cross-Validation*](https://docs.cleanlab.ai/stable/tutorials/pred_probs_cross_val.html#pred-probs-cross-val)
    *— cleanlab*. (n.d.).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[2][*计算样本外预测概率的交叉验证*](https://docs.cleanlab.ai/stable/tutorials/pred_probs_cross_val.html#pred-probs-cross-val)
    *— cleanlab*. (无日期).'
- en: '[3] Databricks. (2022, July 19). *CleanLab: AI to find and fix errors in ML
    datasets* [Video]. [YouTube](https://www.youtube.com/watch?v=BnOTv0f9Msk).'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Databricks. (2022年7月19日). *CleanLab: 用于发现和修复 ML 数据集中的错误的 AI* [视频]. [YouTube](https://www.youtube.com/watch?v=BnOTv0f9Msk).'
- en: '[4][*FAQ*](https://docs.cleanlab.ai/stable/tutorials/faq.html) *— cleanlab*.
    (n.d.).'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[4][*常见问题*](https://docs.cleanlab.ai/stable/tutorials/faq.html) *— cleanlab*.
    (无日期).'
- en: '[5] Mall, S. (2023, May 25). Are label errors imperative? Is confident learning
    useful? [*Medium*](/confident-learning-err-did-you-say-your-data-is-clean-ef2597903328).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Mall, S. (2023年5月25日). 标签错误是否不可避免？自信学习是否有用？[*Medium*](/confident-learning-err-did-you-say-your-data-is-clean-ef2597903328).'
- en: '[6] Northcutt, C. G. (2021). *Confident Learning: Estimating uncertainty in
    Dataset labels*. [arXiv.org](https://arxiv.org/abs/1911.00068).'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] Northcutt, C. G. (2021). *自信学习：估计数据集标签的不确定性*. [arXiv.org](https://arxiv.org/abs/1911.00068).'
