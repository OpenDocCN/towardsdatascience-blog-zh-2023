- en: Understand your Data in Real-Time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/understand-your-data-in-real-time-1f6d9f6937e5?source=collection_archive---------8-----------------------#2023-07-20](https://towardsdatascience.com/understand-your-data-in-real-time-1f6d9f6937e5?source=collection_archive---------8-----------------------#2023-07-20)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Hands-on Tutorial
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: with bytewax and ydata-profiling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@miriam.santos?source=post_page-----1f6d9f6937e5--------------------------------)[![Miriam
    Santos](../Images/decbc6528a641e7b02934a03e136284a.png)](https://medium.com/@miriam.santos?source=post_page-----1f6d9f6937e5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1f6d9f6937e5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1f6d9f6937e5--------------------------------)
    [Miriam Santos](https://medium.com/@miriam.santos?source=post_page-----1f6d9f6937e5--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F243289394aaa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-your-data-in-real-time-1f6d9f6937e5&user=Miriam+Santos&userId=243289394aaa&source=post_page-243289394aaa----1f6d9f6937e5---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1f6d9f6937e5--------------------------------)
    ·8 min read·Jul 20, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1f6d9f6937e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-your-data-in-real-time-1f6d9f6937e5&user=Miriam+Santos&userId=243289394aaa&source=-----1f6d9f6937e5---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1f6d9f6937e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-your-data-in-real-time-1f6d9f6937e5&source=-----1f6d9f6937e5---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: '*In this blog post, we will be covering how you can combine and leverage the
    open-source streaming solution,* ***bytewax****, with* ***ydata-profiling****,
    to improve the quality of your streaming flows. Buckle up!*'
  prefs: []
  type: TYPE_NORMAL
- en: Stream processing enables real-time analysis of data in-flight and before storage,
    and can be **stateful** or **stateless**.
  prefs: []
  type: TYPE_NORMAL
- en: '**Stateful stream processing** is used for *real-time* recommendations, pattern
    detection, or complex event processing, where the history of what has happened
    is required for the processing (windows, joining by a key, etc.).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Stateless stream processing** is used for *inline* transformation that doesn’t
    require knowledge of other data points in the stream like masking an email or
    converting a type.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fa739120431ffe7c214dee1b52f4a04c.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Markus Spiske](https://unsplash.com/@markusspiske?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Overall, data streams are widely used in industry and can be found applied to
    use cases such as *fraud detection*, *patient monitoring*, or *event predictive
    maintenance*.
  prefs: []
  type: TYPE_NORMAL
- en: One crucial aspect that all data streams must consider is the quality of the
    data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unlike traditional models where data quality is usually assessed during the
    creation of the data warehouse or dashboard solution, *streaming data requires
    continuous monitoring*.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is essential to maintain data quality throughout the entire process, from
    collection to feeding downstream applications. After all, the cost of bad data
    quality can be high for organizations:'
  prefs: []
  type: TYPE_NORMAL
- en: “The cost of bad data is an astonishing 15% to 25% of revenue for most companies.
    (…) Two-thirds of these costs can be eliminated by getting in front on data quality.”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**— Thomas C. Redman, author of “Getting in Front on Data Quality”**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Throughout this article, we will show you how you can combine `bytewax`with
    `ydata-profiling` to profile and improve the quality of your streaming flows!
  prefs: []
  type: TYPE_NORMAL
- en: Stream processing for data professionals with Bytewax
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Bytewax](https://github.com/bytewax/bytewax) is an OSS stream processing framework
    designed specifically for Python developers.'
  prefs: []
  type: TYPE_NORMAL
- en: It allows users to **build streaming data pipelines and real-time applications**
    with capabilities similar to Flink, Spark, and Kafka Streams, while providing
    a friendly and familiar interface and **100% compatibility with the Python ecosystem.**
  prefs: []
  type: TYPE_NORMAL
- en: Using built-in [connectors](https://bytewax.io/blog/custom-input-connector)
    or existing Python libraries, **you can connect to real-time and streaming data
    sources** (Kafka, RedPanda, WebSocket, etc.) and **write transformed data** out
    to various downstream systems (Kafka, parquet files, data lakes, etc.).
  prefs: []
  type: TYPE_NORMAL
- en: For the transformations, Bytewax **facilitates stateful and stateless transformations**
    with *map*, *windowing*, and *aggregation* methods and comes with familiar features
    such as recovery and scalability.
  prefs: []
  type: TYPE_NORMAL
- en: Bytewax [facilitates a Python first and data-centric experience to data streams](https://bytewax.io/blog/whywax)
    and is p**urposely built for data engineers and data scientists**. It allows users
    to **build streaming data pipelines and real-time applications** and create customizations
    necessary to meet their needs without having to learn and maintain JVM-based streaming
    platforms like Spark or Flink.
  prefs: []
  type: TYPE_NORMAL
- en: Bytewax is well suited for many use cases, namely [Embedding Pipelines For Generative
    AI](https://bytewax.io/blog/embedding-pipelines-for-generative-ai), [Handling
    Missing Values in Data Streams](https://bytewax.io/guides/handling-missing-values),
    [Using Language Models in a Streaming Context to Understand Financial Markets](https://bytewax.io/blog/LLM-in-streaming),
    and more. For use case inspiration and more information like documentation, tutorials,
    and guides, feel free to check [the bytewax website](https://bytewax.io/).
  prefs: []
  type: TYPE_NORMAL
- en: Why Data Profiling for Data Streams?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Data Profiling is key to a successful start of any machine learning task**,
    and refers to the step of [thoroughly understanding our data](/a-data-scientists-essential-guide-to-exploratory-data-analysis-25637eee0cf6):
    its structure, behavior, and quality.'
  prefs: []
  type: TYPE_NORMAL
- en: In a nutshell, [data profiling](/awesome-data-science-tools-to-master-in-2023-data-profiling-edition-29d29310f779)
    involves analyzing aspects related to the data’s format and basic descriptors
    (e.g., number of samples, number/types of features, duplicate values), its [intrinsic
    characteristics](/data-quality-issues-that-kill-your-machine-learning-models-961591340b40)
    (such as the presence of missing data or imbalanced features), and other complicating
    factors that may arise during data collection or processing (e.g., erroneous values
    or inconsistent features).
  prefs: []
  type: TYPE_NORMAL
- en: '**Ensuring high data quality standards is crucial for all domains and organizations,
    but is especially relevant for domains operating with domains outputting continuous
    data**, where circumstances might change fast and may require immediate action
    (e.g., healthcare monitoring, stock values, air quality policies).'
  prefs: []
  type: TYPE_NORMAL
- en: For many domains, data profiling is used from an exploratory data analysis lens,
    considering historical data stored in databases. On the contrary, for data streams,
    **data profiling becomes essential for validation and quality control continuously
    along the stream**, where data needs to be checked at different time frames or
    stages of the process.
  prefs: []
  type: TYPE_NORMAL
- en: By embedding an **automated profiling into our data flows**, we can *immediately
    get feedback* on the current state of our data and be alerted for any potentially
    critical issues — whether they are related to **data consistency and integrity**
    (e.g., corrupted values or changing formats), or to **events happening in short
    periods of time** (e.g., data drifts, deviation from business rules and outcomes).
  prefs: []
  type: TYPE_NORMAL
- en: In real-world domains — *where you just know Murphy’s law is bound to strike
    and “everything can definitely go wrong”* — automated profiling might save us
    from multiple brain puzzles and systems needing to be taken out of production!
  prefs: []
  type: TYPE_NORMAL
- en: In what concerns data profiling, `ydata-profiling` has consistently been a [crowd
    favorite](https://medium.com/ydata-ai/auditing-data-quality-with-pandas-profiling-b1bf1919f856),
    either for [tabular](https://ydata-profiling.ydata.ai/docs/master/pages/getting_started/examples.html)
    or [time-series](https://medium.com/towards-data-science/how-to-do-an-eda-for-time-series-cbb92b3b1913)
    data. And no wonder why — **it’s one line of code for an extensive set of analysis
    and insights.**
  prefs: []
  type: TYPE_NORMAL
- en: 'Complex and time-draining operations are done under the hood: ydata-profiling
    **automatically detects the feature types comprised in the data** and depending
    on the feature types (either numeric or categorical) it **adjusts the summary
    statistics and visualizations** that are shown in the profiling report.'
  prefs: []
  type: TYPE_NORMAL
- en: Fostering a *data-centric analysis*, the package also **highlights the existing
    relationships between features**, focusing on their pairwise **interactions**
    and **correlations**, and provides a thorough **evaluation of data quality alerts**,
    from *duplicate* or *constant* values to *skewed* and *imbalanced* features.
  prefs: []
  type: TYPE_NORMAL
- en: It’s really a *360º view of the quality of our data* — with minimal effort.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9c2f2ccd6d2fdc260da9563be1e4caab.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Profiling Report: Highlighting potential data qualtity issues. Image by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Putting all together: bytewax and ydata-profiling'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before starting the project, we need to first set our python dependencies and
    configure our data source.
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s install the `bytewax` and `ydata-profiling` packages (*You might
    want to use a virtual environment for this —* [*check these instructions*](https://github.com/Data-Centric-AI-Community/nist-crc-2023#%EF%B8%8F-installation-instructions)
    *if you need some extra guidance!)*
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we’ll upload the [Environmental Sensor Telemetry Dataset](https://www.kaggle.com/datasets/garystafford/environmental-sensor-data-132k)
    (License — CC0: Public Domain), which contains several measurements of **temperature,
    humidity, carbon monoxide liquid petroleum gas, smoke, light, and motion** from
    different IoT devices:'
  prefs: []
  type: TYPE_NORMAL
- en: '**In a production environment, these measurements would be continuously generated
    by each device**, and the input would look like what we expect in a streaming
    platform [such as Kafka](https://bytewax.io/guides/enriching-streaming-data).
    In this article, **to simulate the context we would find with streaming data,
    we will read the data from the CSV file one line at a time** and create a dataflow
    using bytewax.'
  prefs: []
  type: TYPE_NORMAL
- en: '*(As a quick side note, a dataflow is essentially a data pipeline that can
    be described as a directed acyclic graph — DAG)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s make some **necessary imports**:'
  prefs: []
  type: TYPE_NORMAL
- en: Then, we define our dataflow object. Afterwards, we will use a stateless map
    method where we pass in a function to convert the string to a datetime object
    and restructure the data to the format (device_id, data).
  prefs: []
  type: TYPE_NORMAL
- en: The map method will make the change to each data point in a stateless way. The
    reason we have modified the shape of our data is so that we can easily group the
    data in the next steps to profile data for each device separately rather than
    for all of the devices simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: Now we will take advantage of the stateful capabilities of `bytewax` to gather
    data for each device over a duration of time that we have defined. `ydata-profiling`
    expects a snapshot of the data over time, which makes the window operator the
    perfect method to use to do this.
  prefs: []
  type: TYPE_NORMAL
- en: 'In `ydata-profiling`, we are able to produce summarizing statistics for a dataframe
    which is specified for a particular context. For instance, in our example, we
    can produce snapshots of data referring to each IoT device or to particular time
    frames:'
  prefs: []
  type: TYPE_NORMAL
- en: 'After the snapshots are defined, leveraging `ydata-profiling` is as simple
    as calling the `ProfileReport` for each of the dataframes we would like to analyze:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example we are writing the images out to local files as part of a function
    in a map method. These could be reported out via a messaging tool or we could
    save them to some remote storage in the future. Once the profile is complete,
    the dataflow expects some output so we can use the built-in `StdOutput` to print
    the device that was profiled and the time it was profiled at that was passed out
    of the profile function in the map step:'
  prefs: []
  type: TYPE_NORMAL
- en: There are multiple ways to execute Bytewax dataflows. In this example, we use
    the same local machine, but Bytewax can also run on multiple Python processes,
    across multiple hosts, in a [Docker container](https://bytewax.io/docs/deployment/container),
    using a [Kubernetes cluster](https://bytewax.io/docs/deployment/k8s-ecosystem),
    and [more](https://bytewax.io/docs/getting-started/execution#multiple-workers-manual-cluster).
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we’ll continue with a local setup, but we encourage you to
    check our helper tool [waxctl](https://bytewax.io/docs/deployment/waxctl) which
    manages Kubernetes dataflow deployments once your pipeline is ready to transition
    to production.
  prefs: []
  type: TYPE_NORMAL
- en: 'Assuming we are in the same directory as the file with the dataflow definition,
    we can run it using:'
  prefs: []
  type: TYPE_NORMAL
- en: We can then use the profiling reports to validate the data quality, check for
    changes in schemas or data formats, and **compare the data characteristics between
    different devices or time windows**.
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, we can leverage the [**comparison report functionality**](https://pub.towardsai.net/how-to-compare-2-dataset-with-pandas-profiling-2ae3a9d7695e)
    that highlights the differences between two data profiles in a straightforward
    manner, making it easier for us to detect important patterns that need to be investigated
    or issues that have to be addressed:'
  prefs: []
  type: TYPE_NORMAL
- en: Ready to explore your own data streams?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Validating data streams is crucial to identify issues in data quality in
    a continuous manner and compare the state of data across distinct periods of time.**'
  prefs: []
  type: TYPE_NORMAL
- en: For organizations in *healthcare*, *energy*, *manufacturing*, and *entertainment*
    — all working with continuous streams of data — a**utomated profiling is key to
    establishing data governance best practices**, from quality assessment to data
    privacy.
  prefs: []
  type: TYPE_NORMAL
- en: This requires the analysis of snapshots of data which, as showcased in this
    article, can be achieved in a seamless way by combining `bytewax` and `ydata-profiling`.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bytewax** takes care of all the processes necessary to handle and structure
    data streams into snapshots, which can then be summarized and compared with **ydata-profiling**
    through a comprehensive report of data characteristics.'
  prefs: []
  type: TYPE_NORMAL
- en: Being able to appropriately process and profile incoming data opens up a plethora
    of use cases across different domains, from the **correction of errors in data
    schemas and formats** to the highlighting and mitigation of additional issues
    that derive from real-world activities, such as **anomaly detection** (e.g., fraud
    or intrusion/threats detection), **equipment malfunction**, and other events that
    deviate from the expectations (e.g., data drifts or misalignment with business
    rules).
  prefs: []
  type: TYPE_NORMAL
- en: Now you’re all set to start exploring your data streams! Let us know what other
    use cases you find and as always, feel free to drop us a line in the comments,
    or find us at the [Data-Centric AI Community](https://tiny.ydata.ai/dcai-medium)
    for further questions and suggestions! *See you there!*
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*This article was written with the support of Fabiana Clemente (CDO @* [*YData*](https://ydata.ai)*)
    developing* [*ydata-profiling*](https://github.com/ydataai/ydata-profiling)*,
    and Zander Matheson (*CEO & Founder @ [Bytewax](https://bytewax.io)*) and Oli
    Makhasoeva (Developer Relations @* [*Byetwax*](https://bytewax.io)*), both developing*
    [*bytewax*](https://github.com/bytewax/bytewax)*. You may find additional information
    about the OSS packages in the respective documentations:* [*ydata-profiling docs*](https://ydata-profiling.ydata.ai/docs/master/index.html)
    *&* [*bytewax docs*](https://bytewax.io/docs/)*.*'
  prefs: []
  type: TYPE_NORMAL
