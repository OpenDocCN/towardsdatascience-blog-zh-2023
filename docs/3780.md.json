["```py\n## Load the required Python packages\n\n### For dataframe operations\nimport numpy as np\nimport pandas as pd\n\n### For PCA\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n### For Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n### For Validation\nfrom scipy.stats import pearsonr\n```", "```py\n## Load data\n\nfile1 = 'data/standardised_variables_seifa_2021.xlsx'\n\n### Reading from Table 1, from row 5 onwards, for column A to AT\ndata1 = pd.read_excel(file1, sheet_name = 'Table 1', header = 5,\n                      usecols = 'A:AT') \n```", "```py\n## Remove rows with missing value (113 out of 60k rows)\n\ndata1_dropna = data1.dropna()\n```", "```py\n## Standardise data for PCA\n\n### Take all but the first column which is merely a location indicator\ndata_final = data1_dropna.iloc[:,1:]\n\n### Perform standardisation of data\nsc = StandardScaler()\nsc.fit(data_final)\n\n### Standardised data\ndata_final = sc.transform(data_final)\n```", "```py\n## Perform PCA\n\npca = PCA()\npca.fit_transform(data_final)\n```", "```py\n ## Create visualization for variations explained by each PC\n\nexp_var_pca = pca.explained_variance_ratio_\nplt.bar(range(1, len(exp_var_pca) + 1), exp_var_pca, alpha = 0.7,\n            label = '% of Variation Explained',color = 'darkseagreen')\n\nplt.ylabel('Explained Variation')\nplt.xlabel('Principal Component')\nplt.legend(loc = 'best')\nplt.show()\n```", "```py\n## Show and compare loadings for PC1 and PC2\n\n### Using df_plot dataframe per Image 1\n\nsns.heatmap(df_plot, annot = False, fmt = \".1f\", cmap = 'summer') \nplt.show()\n```", "```py\n ## Obtain raw score based on PC1\n\n### Perform sum product of standardised feature and PC1 loading\npca.fit_transform(data_final)\n\n### Reverse the sign of the sum product above to make output more interpretable\npca_data_transformed = -1.0*pca.fit_transform(data_final)\n\n### Convert to Pandas dataframe, and join raw score with SA1 column\npca1 = pd.DataFrame(pca_data_transformed[:,0], columns = ['Score_Raw'])\nscore_SA1 = pd.concat([data1_dropna['SA1_2021'].reset_index(drop = True), pca1]\n                    , axis = 1)\n\n### Inspect the raw score\nscore_SA1.head()\n```", "```py\n## Standardise raw scores\n\nscore_SA1['IER_recreated'] = \n          (score_SA1['Score_Raw']/score_SA1['Score_Raw'].std())*100 + 1000 \n```", "```py\n## Read in ABS published IER scores\n## similarly to how we read in the standardised portion of the features\n\nfile2 = 'data/Statistical Area Level 1, Indexes, SEIFA 2021.xlsx'\n\ndata2 = pd.read_excel(file2, sheet_name = 'Table 4', header = 5,\n                      usecols = 'A:C')\n\ndata2.rename(columns =  {'2021 Statistical Area Level 1 (SA1)': 'SA1_2021', 'Score': 'IER_2021'}, inplace = True)\n\ncol_select = ['SA1_2021', 'IER_2021']\ndata2 = data2[col_select]\n\nABS_IER_dropna = data2.dropna().reset_index(drop = True)\n```", "```py\n## Check distribution of scores\n\nscore_SA1.hist(column = 'IER_recreated', bins = 100, color = 'darkseagreen')\nplt.title('Distribution of recreated IER scores')\n\nABS_IER_dropna.hist(column = 'IER_2021', bins = 100, color = 'lightskyblue')\nplt.title('Distribution of ABS IER scores')\n\nplt.show()\n```", "```py\n ## Join the two scores by SA1 for comparison\nIER_join = pd.merge(ABS_IER_dropna, score_SA1, how = 'left', on = 'SA1_2021')\n\n## Plot scores on x-y axis. \n## If scores are identical, it should show a straight line.\n\nplt.scatter('IER_recreated', 'IER_2021', data = IER_join, color = 'darkseagreen')\nplt.title('Comparison of recreated and ABS IER scores')\nplt.xlabel('Recreated IER score')\nplt.ylabel('ABS IER score')\n\nplt.show()\n```"]