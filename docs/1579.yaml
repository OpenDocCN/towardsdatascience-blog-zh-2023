- en: Exploring the Vulnerability of Language Models to Poisoning Attacks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/exploring-the-vulnerability-of-language-models-to-poisoning-attacks-d6d03bcc5ecb?source=collection_archive---------5-----------------------#2023-05-10](https://towardsdatascience.com/exploring-the-vulnerability-of-language-models-to-poisoning-attacks-d6d03bcc5ecb?source=collection_archive---------5-----------------------#2023-05-10)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Can the strengths of Language Models be turned into their weaknesses?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://pandeyparul.medium.com/?source=post_page-----d6d03bcc5ecb--------------------------------)[![Parul
    Pandey](../Images/760b72a4feacfad6fc4224835c2e1f19.png)](https://pandeyparul.medium.com/?source=post_page-----d6d03bcc5ecb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d6d03bcc5ecb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d6d03bcc5ecb--------------------------------)
    [Parul Pandey](https://pandeyparul.medium.com/?source=post_page-----d6d03bcc5ecb--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7053de462a28&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-the-vulnerability-of-language-models-to-poisoning-attacks-d6d03bcc5ecb&user=Parul+Pandey&userId=7053de462a28&source=post_page-7053de462a28----d6d03bcc5ecb---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d6d03bcc5ecb--------------------------------)
    ·9 min read·May 10, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd6d03bcc5ecb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-the-vulnerability-of-language-models-to-poisoning-attacks-d6d03bcc5ecb&user=Parul+Pandey&userId=7053de462a28&source=-----d6d03bcc5ecb---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd6d03bcc5ecb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-the-vulnerability-of-language-models-to-poisoning-attacks-d6d03bcc5ecb&source=-----d6d03bcc5ecb---------------------bookmark_footer-----------)![](../Images/e2f0cf785260a35cc986628ea62f3e8c.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [FLY:D](https://unsplash.com/@flyd2069?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: In 2016, Microsoft experienced a [significant incident with their chatbot, Tay](https://en.wikipedia.org/wiki/Tay_(chatbot)),
    highlighting the potential dangers of data poisoning. Tay was designed as an advanced
    chatbot created by some of the best minds at Microsoft Research to interact with
    users on Twitter and promote awareness about artificial intelligence. Unfortunately,
    just 16 hours after its debut, Tay exhibited highly inappropriate and offensive
    behavior, forcing Microsoft to shut it down.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://en.wikipedia.org/wiki/Tay_%28chatbot%29?source=post_page-----d6d03bcc5ecb--------------------------------)
    [## Tay (chatbot) - Wikipedia'
  prefs: []
  type: TYPE_NORMAL
- en: Tay was an artificial intelligence chatbot that was originally released by Microsoft
    Corporation via Twitter on March…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: en.wikipedia.org](https://en.wikipedia.org/wiki/Tay_%28chatbot%29?source=post_page-----d6d03bcc5ecb--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: So what exactly happened here?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The incident transpired because users took advantage of Tay's adaptive learning
    system by deliberately providing it with racist and explicit content. This manipulation
    caused the chatbot to incorporate inappropriate material into its training data,
    subsequently leading Tay to generate offensive outputs in its interactions.
  prefs: []
  type: TYPE_NORMAL
