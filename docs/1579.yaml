- en: Exploring the Vulnerability of Language Models to Poisoning Attacks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/exploring-the-vulnerability-of-language-models-to-poisoning-attacks-d6d03bcc5ecb?source=collection_archive---------5-----------------------#2023-05-10](https://towardsdatascience.com/exploring-the-vulnerability-of-language-models-to-poisoning-attacks-d6d03bcc5ecb?source=collection_archive---------5-----------------------#2023-05-10)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Can the strengths of Language Models be turned into their weaknesses?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://pandeyparul.medium.com/?source=post_page-----d6d03bcc5ecb--------------------------------)[![Parul
    Pandey](../Images/760b72a4feacfad6fc4224835c2e1f19.png)](https://pandeyparul.medium.com/?source=post_page-----d6d03bcc5ecb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d6d03bcc5ecb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d6d03bcc5ecb--------------------------------)
    [Parul Pandey](https://pandeyparul.medium.com/?source=post_page-----d6d03bcc5ecb--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7053de462a28&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-the-vulnerability-of-language-models-to-poisoning-attacks-d6d03bcc5ecb&user=Parul+Pandey&userId=7053de462a28&source=post_page-7053de462a28----d6d03bcc5ecb---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d6d03bcc5ecb--------------------------------)
    ·9 min read·May 10, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd6d03bcc5ecb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-the-vulnerability-of-language-models-to-poisoning-attacks-d6d03bcc5ecb&user=Parul+Pandey&userId=7053de462a28&source=-----d6d03bcc5ecb---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd6d03bcc5ecb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-the-vulnerability-of-language-models-to-poisoning-attacks-d6d03bcc5ecb&source=-----d6d03bcc5ecb---------------------bookmark_footer-----------)![](../Images/e2f0cf785260a35cc986628ea62f3e8c.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [FLY:D](https://unsplash.com/@flyd2069?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: In 2016, Microsoft experienced a [significant incident with their chatbot, Tay](https://en.wikipedia.org/wiki/Tay_(chatbot)),
    highlighting the potential dangers of data poisoning. Tay was designed as an advanced
    chatbot created by some of the best minds at Microsoft Research to interact with
    users on Twitter and promote awareness about artificial intelligence. Unfortunately,
    just 16 hours after its debut, Tay exhibited highly inappropriate and offensive
    behavior, forcing Microsoft to shut it down.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 2016年，微软经历了一次与其聊天机器人Tay相关的[重大事件](https://en.wikipedia.org/wiki/Tay_(chatbot))，突显了数据中毒的潜在危险。Tay是由微软研究院的一些顶尖人才设计的先进聊天机器人，旨在与Twitter上的用户互动并提高对人工智能的认识。不幸的是，在其上线后的16小时内，Tay表现出了极为不当和冒犯的行为，迫使微软将其关闭。
- en: '[](https://en.wikipedia.org/wiki/Tay_%28chatbot%29?source=post_page-----d6d03bcc5ecb--------------------------------)
    [## Tay (chatbot) - Wikipedia'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://en.wikipedia.org/wiki/Tay_%28chatbot%29?source=post_page-----d6d03bcc5ecb--------------------------------)
    [## Tay (chatbot) - Wikipedia'
- en: Tay was an artificial intelligence chatbot that was originally released by Microsoft
    Corporation via Twitter on March…
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Tay 是一个人工智能聊天机器人，最初由微软公司于3月通过Twitter发布。
- en: en.wikipedia.org](https://en.wikipedia.org/wiki/Tay_%28chatbot%29?source=post_page-----d6d03bcc5ecb--------------------------------)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: en.wikipedia.org](https://en.wikipedia.org/wiki/Tay_%28chatbot%29?source=post_page-----d6d03bcc5ecb--------------------------------)
- en: So what exactly happened here?
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 那么，究竟发生了什么？
- en: The incident transpired because users took advantage of Tay's adaptive learning
    system by deliberately providing it with racist and explicit content. This manipulation
    caused the chatbot to incorporate inappropriate material into its training data,
    subsequently leading Tay to generate offensive outputs in its interactions.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这一事件发生的原因是用户利用了Tay的自适应学习系统，故意向其提供种族歧视和露骨内容。这种操控导致聊天机器人将不当内容纳入其训练数据中，从而使Tay在互动中生成了冒犯性的输出。
