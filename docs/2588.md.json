["```py\n# Load Packages\nimport numpy as np\nimport statsmodels.api as sm\nfrom imblearn.over_sampling import SMOTE, RandomOverSampler\n\n# Set seed\nnp.random.seed(1)\n# Create Simulation Datasets\nx = np.random.normal(size = 10000)\ny = (2.5 + x + np.random.logistic(size = 10000)) > 0\n# Bias term is set to 2.5 and coefficient of x to 1\n\n# The size of class 1 is 9005\nprint(sum(y == 1))\n# The size of class 0 is 995\nprint(sum(y == 0))\n\n# We want to match the size of class 0 to that of class 1\n# Method 0 Don't do anything\nx0 = x\ny0 = y\nmethod0 = sm.Logit(y0, sm.add_constant(x0)).fit()\nprint(method0.summary())  # 2.54 bias term and 0.97 x3 coefficient\n\n# Method 1 Simple Oversampling\nx1 = np.concatenate((x, np.repeat(x[y == 0], 8)))\ny1 = np.concatenate((y, np.array([0] * (len(x1) - len(x)))))\nmethod1 = sm.Logit(y1, sm.add_constant(x1)).fit()\nprint(method1.summary())  # 0.35 bias term and 0.98 x3 coefficient\n\n# Method 2 SMOTE\nsmote = SMOTE(random_state = 1)\nx2, y2 = smote.fit_resample(x[:, np.newaxis], y)\nmethod2 = sm.Logit(y2, sm.add_constant(x2)).fit()\nprint(method2.summary())  # 0.35 bias term and 1 x3 coefficient\n\n# Method 3 Random Sampling\nrandom_sampler = RandomOverSampler(random_state=1)\nx3, y3 = random_sampler.fit_resample(x[:, np.newaxis], y)\nmethod3 = sm.Logit(y3, sm.add_constant(x3)).fit()\nprint(method3.summary()) # 0.35 bias term and 0.99 x3 coefficient\n```", "```py\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE, RandomOverSampler\n\n# Load and preprocess the dataset\ndf = pd.read_csv(\"/kaggle/input/playground-series-s3e4/train.csv\")\ny, x = df.Class, df[df.columns[1:-1]]\nx = (x - x.min()) / (x.max() - x.min())\nx_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.3, random_state=1)\nbatch_size = 256\ntrain_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size=1024).batch(batch_size)\nvalid_dataset = tf.data.Dataset.from_tensor_slices((x_valid, y_valid)).batch(batch_size)\n```", "```py\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Normalization(),\n    tf.keras.layers.Dense(32, activation='swish'),\n    tf.keras.layers.Dense(32, activation='swish'),\n    tf.keras.layers.Dense(1)\n])\noptimizer = tf.keras.optimizers.Adam()\nloss = tf.keras.losses.BinaryCrossentropy()\nval_metric = tf.keras.metrics.AUC()\n```", "```py\n# Define Training Step function\n@tf.function\ndef train_step(x, y):\n    delta0, delta1 = tf.constant(0, dtype = tf.float32), tf.constant(0, dtype = tf.float32)\n    with tf.GradientTape() as tape:\n        logits = model(x, training=True)\n        y_pred = tf.keras.activations.sigmoid(logits)\n        loss_value = loss(y, y_pred)\n        # Calculate new bias term for addressing imbalance class\n        if len(logits[y == 1]) == 0:\n            delta0 -= (tf.reduce_sum(logits[y == 0]))\n        elif len(logits[y == 0]) == 0:\n            delta1 -= (tf.reduce_sum(logits[y == 1]))\n        else:\n            delta0 -= (tf.reduce_sum(logits[y == 0]))\n            delta1 -= (tf.reduce_sum(logits[y == 1]))\n    grads = tape.gradient(loss_value, model.trainable_weights)\n    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n    return loss_value, delta0, delta1\n```", "```py\n@tf.function\ndef test_step(x, y, delta):\n    logits = model(x, training=False)\n    y_pred = tf.keras.activations.sigmoid(logits + delta)  # Adjust predictions with delta\n    val_metric.update_state(y, y_pred)\n```", "```py\nE = 1000\nP = 10\nB = len(train_dataset)\nN_class0, N_class1 = sum(y_train == 0), sum(y_train == 1)\nearly_stopping_patience = 0\nbest_metric = 0\nfor epoch in range(E):\n    # init delta\n    delta0, delta1 = tf.constant(0, dtype = tf.float32), tf.constant(0, dtype = tf.float32)\n    print(\"\\nStart of epoch %d\" % (epoch,))\n    # Iterate over the batches of the dataset.\n    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n        loss_value, step_delta0, step_delta1 = train_step(x_batch_train, y_batch_train)\n\n        # Update delta\n        delta0 += step_delta0\n        delta1 += step_delta1\n\n    # Take average of all delta values\n    delta = (delta0/N_class0 + delta1/N_class1)/2\n\n    # Run a validation loop at the end of each epoch.\n    for x_batch_val, y_batch_val in valid_dataset:\n        test_step(x_batch_val, y_batch_val, delta)\n\n    val_auc = val_metric.result()\n    val_metric.reset_states()\n    print(\"Validation AUC: %.4f\" % (float(val_auc),))\n    if val_auc > best_metric:\n        best_metric = val_auc\n        early_stopping_patience = 0\n    else:\n        early_stopping_patience += 1\n\n    if early_stopping_patience > P:\n        print(\"Reach Early Stopping Patience. Training Finished at Validation AUC: %.4f\" % (float(best_metric),))\n        break;\n```"]