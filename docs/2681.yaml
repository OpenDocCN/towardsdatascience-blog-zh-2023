- en: RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7?source=collection_archive---------0-----------------------#2023-08-24](https://towardsdatascience.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7?source=collection_archive---------0-----------------------#2023-08-24)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The definitive guide for choosing the right method for your use case
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://heiko-hotz.medium.com/?source=post_page-----94654b1eaba7--------------------------------)[![Heiko
    Hotz](../Images/d08394d46d41d5cd9e76557a463be95e.png)](https://heiko-hotz.medium.com/?source=post_page-----94654b1eaba7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----94654b1eaba7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----94654b1eaba7--------------------------------)
    [Heiko Hotz](https://heiko-hotz.medium.com/?source=post_page-----94654b1eaba7--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F993c21f1b30f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7&user=Heiko+Hotz&userId=993c21f1b30f&source=post_page-993c21f1b30f----94654b1eaba7---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----94654b1eaba7--------------------------------)
    ·19 min read·Aug 24, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F94654b1eaba7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7&user=Heiko+Hotz&userId=993c21f1b30f&source=-----94654b1eaba7---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F94654b1eaba7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7&source=-----94654b1eaba7---------------------bookmark_footer-----------)![](../Images/f87aad7c078e00a5f9db9a00ad4debad.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Prologue
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As the wave of interest in Large Language Models (LLMs) surges, many developers
    and organisations are busy building applications harnessing their power. However,
    when the pre-trained LLMs out of the box don’t perform as expected or hoped, the
    question on how to improve the performance of the LLM application. And eventually
    we get to the point of where we ask ourselves: Should we use [Retrieval-Augmented
    Generation](https://arxiv.org/abs/2005.11401) (RAG) or model finetuning to improve
    the results?'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before diving deeper, let’s demystify these two methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '**RAG**: This approach integrates the power of retrieval (or searching) into
    LLM text generation. It combines a retriever system, which fetches relevant document
    snippets from a large corpus, and an LLM, which produces answers using the information
    from those snippets. In essence, RAG helps the model to “look up” external information
    to improve its responses.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/37f3ba773a6c401ffdd3eead8bdf76b7.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
