- en: 'A Primer on Linear Algebra: Part 2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/a-primer-on-linear-algebra-part-2-eba53c564a90?source=collection_archive---------20-----------------------#2023-04-25](https://towardsdatascience.com/a-primer-on-linear-algebra-part-2-eba53c564a90?source=collection_archive---------20-----------------------#2023-04-25)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A gentle refresher on essential concepts and operations for data science
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@dataforyou?source=post_page-----eba53c564a90--------------------------------)[![Rob
    Taylor, PhD](../Images/5e4e86da7b77404ed42d00a60ea5eacf.png)](https://medium.com/@dataforyou?source=post_page-----eba53c564a90--------------------------------)[](https://towardsdatascience.com/?source=post_page-----eba53c564a90--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----eba53c564a90--------------------------------)
    [Rob Taylor, PhD](https://medium.com/@dataforyou?source=post_page-----eba53c564a90--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F98de080592fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-primer-on-linear-algebra-part-2-eba53c564a90&user=Rob+Taylor%2C+PhD&userId=98de080592fc&source=post_page-98de080592fc----eba53c564a90---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----eba53c564a90--------------------------------)
    ·6 min read·Apr 25, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Feba53c564a90&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-primer-on-linear-algebra-part-2-eba53c564a90&user=Rob+Taylor%2C+PhD&userId=98de080592fc&source=-----eba53c564a90---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feba53c564a90&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-primer-on-linear-algebra-part-2-eba53c564a90&source=-----eba53c564a90---------------------bookmark_footer-----------)![](../Images/7d24980120b3e252016f552354d93c84.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Viktor Forgacs](https://unsplash.com/@sonance?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In my previous [post](https://medium.com/@dataforyou/a-primer-on-linear-algebra-414111d195ca),
    I introduced some of the operations and concepts that are fundamental to linear
    algebra. This included vectors and matrices, as well as the transpose, dot product,
    and matrix multiplication operators. In this post, I’ll introduce some additional
    concepts that complement those discussed previously. If you haven’t already seen
    my primer on linear algebra you can check it out [here](https://medium.com/@dataforyou/a-primer-on-linear-algebra-414111d195ca).
  prefs: []
  type: TYPE_NORMAL
- en: Linear Independence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we can define linear *independence* we first need to define linear *dependence*.
    Simply put, a sequence of vectors is linearly dependent if at least one can be
    written as a linear combination of the others. Specifically, suppose we have a
    sequence of *n* vectors **v**₁, **v**₂, ⋯, **v**ₙ that comprise the columns of
    a matrix *V*. Linear dependence holds if and only if there exists *n* scalars
    *a₁*, *a₂*, ⋯,*aₙ* such that:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b4ef04b634d5350653f4bf61f0660d33.png)'
  prefs: []
  type: TYPE_IMG
- en: Condition for linear dependence (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: where **0** denotes the *zero vector* and at least one of the *aᵢ* is *not equal
    to zero*.
  prefs: []
  type: TYPE_NORMAL
- en: 'This requirement is important because without it you could just set all *a*
    to zero and obtain the result*.* The definition oflinear independence, then, is
    just the converse case; that is, the case where the sequence of vectors is *not*
    linearly dependent. This implies that the following condition holds:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/57dadb68457242cc0437ce62adda4535.png)'
  prefs: []
  type: TYPE_IMG
- en: Condition for linear independence (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: and therefore requires that *all* scalars are zero. Under these conditions,
    no vector in the sequence can be represented as a linear combination of any of
    the remaining vectors.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, suppose we have two vectors **v**₁ and **v**₂, each of which is
    ℝ². For linear independence to hold we require a set of coefficients such that:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4bcec5c3903aff6ba2b2de02919d381c.png)'
  prefs: []
  type: TYPE_IMG
- en: Example showing linear independence for a 2 x 2 matrix (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: where both *a*₁ and *a*₂ equal zero.
  prefs: []
  type: TYPE_NORMAL
- en: Determinant
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The *determinant* is a scalar value that is a function of the elements in a
    square matrix. If the dimensionality of the matrix is small the determinant is
    fairly straightforward to compute by hand. For example, let *A* be a 2 *×* 2 matrix;
    in this case, the determinant is simply:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/615eacf5bc7e5102bd3d0b039127feea.png)'
  prefs: []
  type: TYPE_IMG
- en: The determinant of a 2 x 2 matrix (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also compute the determinant for a 3 *× 3* matrix, though this time
    the process is a little more involved. I won''t delve into details here, but the
    solution for this case is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cf7ade7b78e77aa08ab9eff957b29973.png)'
  prefs: []
  type: TYPE_IMG
- en: The determinant of a 3 x 3 matrix (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: 'This solution is called the *Leibniz formula* for the determinant and generalizes
    to higher dimensions. Again, I won’t dive into the details here but will provide
    the general formula, which is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5e91cda35e9b73094c6c5ed7e8d8a2ef.png)'
  prefs: []
  type: TYPE_IMG
- en: The determinant of a 3 x 3 matrix (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: where *sgn* is the sign function of the permutations contained in the group
    *Sₙ,* and *σ* denotes a function that reorders — or *permutes —* the set of integers.
  prefs: []
  type: TYPE_NORMAL
- en: While the formula for the determinant is not particularly intuitive, the information
    it provides *is*. The determinant is inherently geometric and tells us how an
    image changes under transformation. Thinking again about a simple 2 *×* 2 matrix,
    the determinant is actually the area of a parallelogram, which itself represents
    the image of the unit square under the transformation given in the matrix.
  prefs: []
  type: TYPE_NORMAL
- en: This also works for higher dimensions, too, though now the determinant corresponds
    to a volume, not an area. For example, the determinant of a 3 *× 3* matrix is
    the volume of a parallelepiped, whereas the determinant of any *n* *× n* matrix
    is the hypervolume of an *n*-dimensional parallelogram.
  prefs: []
  type: TYPE_NORMAL
- en: Rank
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Definitionally, the *rank* of a matrix determines the maximal number of *linearly
    independent* columns; though more formally, it corresponds to the dimensionality
    of the vector space spanned by its columns. Typically, we want matrices to have
    *full rank* because this condition implies there is no redundancy between column
    vectors. Any matrix where lineardependencies exist between columns will not have
    full rank and is referred to as *rank-deficient.*
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate, consider a square *n* *×* *n* matrix *A.* If all columns in this
    matrix are linearly independent, then the matrix is said to have *full column
    rank* which will be equal to *n*. Now, because the matrix is square, we could
    also consider whether its rows are linearly independent. If so, then the matrix
    also has *full row rank,* which will also equal *n.* Because these are equivalent
    a square matrix is considered to have full rank if all rows and columns are linearly
    independent, which is denoted as rank(*A*) = *n*.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, for square matrices, full rank is possible if and only if its determinant
    is non-zero. Therefore, we can actually use the determinant to test for linear
    independence in square matrices.
  prefs: []
  type: TYPE_NORMAL
- en: But, what if the matrix is not square? Well, in this case, full rank is defined
    a little differently. Suppose we have a non-square matrix *B* with *m* rows and
    *n* columns, then full rank is defined as the highest row or column rank possible
    given the shape of the matrix. Counterintuitively, this will equal whichever dimension
    is the *smallest*.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if *B* has a greater number of rows relative to its columns (i.e.,
    *m* > *n)* then full rank requires that *B* has full column rank, and so rank(*B*)
    = *n*. Conversely, if the number of rows is less than the number of columns (i.e.,
    *m < n),* then *B* must have full row rank, and so rank(*B*) = *m*. This is true
    because if a matrix is non-square then either its rows or columns must be linearly
    dependent.
  prefs: []
  type: TYPE_NORMAL
- en: Matrix Inversion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Definitionally, an *n* × *n* square matrix *A* is considered *invertible* if
    there exists another square *n* × *n* matrix *B* that ensures the following holds:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6a845c04b13e0f9540be32cbc3ce0519.png)'
  prefs: []
  type: TYPE_IMG
- en: Condition for matrix invertibility (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: This states that invertibility holds if the matrix product of *A* and *B* is
    the *identity matrix*. If this is indeed true, then *B* is uniquely determined
    by *A* and we say that matrix *B* is the *multiplicative inverse* of *A*, which
    we write as *A*⁻¹. *Matrix inversion* is then the task of trying to find a matrix
    *B* that satisfies the invertibility condition. I won’t get into the details here
    on the numerical methods used in matrix inversion, however.
  prefs: []
  type: TYPE_NORMAL
- en: Note that a matrix can only be inverted if it has *full rank*, which implies
    that the columns of *A* are linearly independent. Any matrix that cannot be inverted
    is then said to be *degenerate*, or *singular.*
  prefs: []
  type: TYPE_NORMAL
- en: Final Remarks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This post provides a lighter touch on some essential concepts in linear algebra.
    Like any topic, you can really delve into the details, so this piece is not entirely
    comprehensive, and only just scratches the surface. That being said, the concepts
    discussed here are essential when building mathematical models so are important
    for data scientists to be aware of. In a later post, we’ll see how these concepts,
    along with those introduced in my earlier primer, are applied when building linear
    regression models. So stay tuned!
  prefs: []
  type: TYPE_NORMAL
- en: Related Articles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[A Primer of Linear Algebra](https://medium.com/@dataforyou/a-primer-on-linear-algebra-414111d195ca)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thanks for reading!
  prefs: []
  type: TYPE_NORMAL
- en: If you enjoyed this post and would like to stay up to date then please consider
    [following me on Medium.](https://medium.com/@dataforyou) This will ensure you
    don’t miss out on any new content.
  prefs: []
  type: TYPE_NORMAL
- en: To get unlimited access to all content consider signing up for a [Medium subscription](https://medium.com/membership).
  prefs: []
  type: TYPE_NORMAL
- en: You can also follow me on [Twitter](https://twitter.com/dataforyounz), [LinkedIn](https://www.linkedin.com/in/dataforyou/),
    or check out my [GitHub](https://github.com/dataforyounz) if that’s more your
    thing 😉
  prefs: []
  type: TYPE_NORMAL
