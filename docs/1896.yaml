- en: Using enums and functools to Upgrade Your Pandas Data Pipelines
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/using-enums-and-functools-to-upgrade-your-pandas-data-pipelines-d51ca1418fe2?source=collection_archive---------4-----------------------#2023-06-09](https://towardsdatascience.com/using-enums-and-functools-to-upgrade-your-pandas-data-pipelines-d51ca1418fe2?source=collection_archive---------4-----------------------#2023-06-09)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: PROGRAMMING
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A look at more efficient programming for your data processing with two step-by-step
    examples
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://byrondolon.medium.com/?source=post_page-----d51ca1418fe2--------------------------------)[![Byron
    Dolon](../Images/9ff32138c7b1913be24cc7ab971752b0.png)](https://byrondolon.medium.com/?source=post_page-----d51ca1418fe2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d51ca1418fe2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d51ca1418fe2--------------------------------)
    [Byron Dolon](https://byrondolon.medium.com/?source=post_page-----d51ca1418fe2--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6b5d063df5dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-enums-and-functools-to-upgrade-your-pandas-data-pipelines-d51ca1418fe2&user=Byron+Dolon&userId=6b5d063df5dd&source=post_page-6b5d063df5dd----d51ca1418fe2---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d51ca1418fe2--------------------------------)
    ·12 min read·Jun 9, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd51ca1418fe2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-enums-and-functools-to-upgrade-your-pandas-data-pipelines-d51ca1418fe2&user=Byron+Dolon&userId=6b5d063df5dd&source=-----d51ca1418fe2---------------------clap_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd51ca1418fe2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-enums-and-functools-to-upgrade-your-pandas-data-pipelines-d51ca1418fe2&source=-----d51ca1418fe2---------------------bookmark_footer-----------)![](../Images/4628e4600a99a70c1aab75fbd4986ddd.png)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Image used with permission by my talented sister [ohmintyartz](https://www.instagram.com/ohmintyartz/)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: You’ve likely worked with Pandas before when creating a pipeline to process
    your raw data. Writing code to filter, group, and perform calculations on your
    data is just the first step in building data pipelines and ETL processes.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Working with data at scale means that in addition to this, we should write code
    that’s **functional** and **easy to read and maintain**.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: There are a lot of different things you can do to improve your existing data
    pipelines like [adding efficient logging](/why-you-need-to-write-dry-code-with-decorators-in-python-3930ea23f569),
    [including data validation](/how-to-do-data-validation-on-your-data-on-pandas-with-pytest-d5dda51ad0e4),
    and even by using new libraries besides Pandas like PySpark and Polars.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多不同的方法可以改善你现有的数据管道，例如[添加高效的日志记录](/why-you-need-to-write-dry-code-with-decorators-in-python-3930ea23f569)、[包括数据验证](/how-to-do-data-validation-on-your-data-on-pandas-with-pytest-d5dda51ad0e4)，甚至使用除了
    Pandas 之外的新库，比如 PySpark 和 Polars。
- en: In addition, you can also structure the actual code you use for processing data
    differently. This means not doing something to necessarily improve the performance
    of your pipelines, but rather focusing on writing code that is easy to modify
    and iterate on over time.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你还可以以不同的方式结构化你实际用于数据处理的代码。这意味着不是为了提高管道的性能，而是关注编写易于修改和迭代的代码。
- en: In this piece, let’s take a look at how you can do just that with two simple
    examples using some native Python, specifically by using **enums** and **functools.**
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，让我们看看如何通过使用一些原生 Python 的两个简单示例来做到这一点，特别是通过使用**枚举**和**functools**。
