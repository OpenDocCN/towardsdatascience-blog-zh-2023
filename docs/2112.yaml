- en: How I Coded My Own Private French Tutor Out of ChatGPT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/how-i-coded-my-own-private-french-tutor-out-of-chatgpt-16b3e15007bb?source=collection_archive---------1-----------------------#2023-06-30](https://towardsdatascience.com/how-i-coded-my-own-private-french-tutor-out-of-chatgpt-16b3e15007bb?source=collection_archive---------1-----------------------#2023-06-30)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Step-by-step guide to how I used the latest AI services to teach me a new language,
    from architecture to prompt engineering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://shakedzy.medium.com/?source=post_page-----16b3e15007bb--------------------------------)[![Shaked
    Zychlinski üéóÔ∏è](../Images/4d050b916bccab64df3c02236b3129eb.png)](https://shakedzy.medium.com/?source=post_page-----16b3e15007bb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----16b3e15007bb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----16b3e15007bb--------------------------------)
    [Shaked Zychlinski üéóÔ∏è](https://shakedzy.medium.com/?source=post_page-----16b3e15007bb--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F43218078e688&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-coded-my-own-private-french-tutor-out-of-chatgpt-16b3e15007bb&user=Shaked+Zychlinski+%F0%9F%8E%97%EF%B8%8F&userId=43218078e688&source=post_page-43218078e688----16b3e15007bb---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----16b3e15007bb--------------------------------)
    ¬∑10 min read¬∑Jun 30, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F16b3e15007bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-coded-my-own-private-french-tutor-out-of-chatgpt-16b3e15007bb&user=Shaked+Zychlinski+%F0%9F%8E%97%EF%B8%8F&userId=43218078e688&source=-----16b3e15007bb---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F16b3e15007bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-coded-my-own-private-french-tutor-out-of-chatgpt-16b3e15007bb&source=-----16b3e15007bb---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Code of the discussed foreign-language tutor can be found in the* `[companion](https://github.com/shakedzy/companion)`
    [*repo on my GitHub page*](https://github.com/shakedzy/companion)*, and you can
    use it freely for any non-commercial use.*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/77c41f40c1d0441c96b20495c9f79836.png)'
  prefs: []
  type: TYPE_IMG
- en: Made with Dall-E
  prefs: []
  type: TYPE_NORMAL
- en: So after postponing it for quite some time, I made a choice to resume my French
    studies. As I signed up for the class, this thought struck me ‚Äî *what if I could
    program ChatGPT to be my personal French tutor? What if I could* ***speak*** *to
    it, and it would speak back to me?* Being a Data Scientist working with LLMs,
    this seemed like something worth building. I mean, yes, I can just speak to my
    wife, who‚Äôs French, but that‚Äôs not as cool as designing my own personal tutor
    out of ChatGPT. Love you, honey ‚ù§Ô∏è.
  prefs: []
  type: TYPE_NORMAL
- en: 'But seriously now, this project is a little more than just ‚Äúanother cool code-toy‚Äù.
    Generative AI is headed to every field in our lives, and Large Language Models
    (LLMs) seem to take the lead here. The possibilities of what a single person can
    do these days with access to these models is jaw-dropping, and I decided this
    project is worth my time ‚Äî and yours, too, I believe ‚Äî for two main reason:'
  prefs: []
  type: TYPE_NORMAL
- en: Using ChatGPT as the well-known online tool is powerful, but integrating an
    LLM into your code is a whole different thing. LLMs are still somewhat unpredictable,
    and when your product relies on an LLM ‚Äî or any other GenAI model ‚Äî for the core
    product, you need to learn how to really control GenAI. And it‚Äôs not as easy as
    it sounds.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting a first working version took only a few workdays. Before GenAI and LLMs,
    this would take months, and would probably require more than a single person.
    The power of using these tools to create powerful applications fast is something
    you really have to try yourself ‚Äî that‚Äôs the future, as far as I see it. We‚Äôre
    not going back.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plus, this project can actually do good. My mom really wants someone she can
    practice her English with. Now she can, and it costs less than $3 a month. My
    wife‚Äôs mom wants to kick off Korean studying. Same thing, same cost. And of course
    I use it too! This project really helps people, and it costs less than a small
    cup of coffee. That‚Äôs the real GenAI revolution, if you ask me.
  prefs: []
  type: TYPE_NORMAL
- en: Starting from Scratch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Looking at this project from a high-level perspective, what I needed were 4
    elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Speech-to-text**, to transcribe my own voice to words'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Large-Language Model**, preferably a Chat-LLM, which I can ask questions
    and get responses from'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text-to-speech**, to turn the LLM‚Äôs answers to voice'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Translation**, to convert any French text I do not fully understand to English
    (or Hebrew, my native language)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Luckily, it‚Äôs 2023, and all of the above are very *very* accessible. I‚Äôve also
    chosen to use managed services and APIs rather than running any of these locally,
    as inference will be much faster this way. Also, the low prices of these APIs
    for personal use made this decision a no-brainer.
  prefs: []
  type: TYPE_NORMAL
- en: After playing around with several alternatives, I‚Äôve chosen OpenAI‚Äôs Whisper
    and ChatGPT as my Speech-to-text and LLM, and Google‚Äôs Text-to-speech and Translate
    as the remaining modules. Creating API keys and setting these services up was
    super-simple, and I was able to communicate with all of them through their native
    Python libraries in a matter of minutes.
  prefs: []
  type: TYPE_NORMAL
- en: What really struck me after testing all these services, is that the tutor I‚Äôm
    constructing is not a just an English-to-French teacher; as Whisper, ChatGPT,
    and Google Translate & TTS support dozens of languages, this can be used to learn
    pretty much *any language* while speaking *any other language*. That‚Äôs insane!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8bbea41fc4b9ccef5a4b39f60266e911.png)'
  prefs: []
  type: TYPE_IMG
- en: Made with Dall-E
  prefs: []
  type: TYPE_NORMAL
- en: Architecture and Threading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let‚Äôs first make sure the overall flow is well understood: **(1)** We begin
    by recording the user‚Äôs voice, which is **(2)** sent to Whisper API, and returns
    as text. **(3)** The text is added to the chat history and sent to ChatGPT, which
    **(4)** returns a written response. Its response is **(5)** sent to Google Text-to-speech,
    which returns a sound file that will be **(6)** played as audio.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d796016494a36f4692161e52032412a3.png)'
  prefs: []
  type: TYPE_IMG
- en: High-level architecture
  prefs: []
  type: TYPE_NORMAL
- en: My first practical step was to break this down to components and design the
    overall architecture. I knew I‚Äôll need a UI, preferably a Web UI as it‚Äôs just
    easier to launch apps through the browser these days then having a standalone
    executable. I‚Äôll also need a ‚Äúbackend‚Äù, which will be the actual Python code,
    communicating with all the different services. But in order to provide a real-time
    flowing experience, I realized I‚Äôll need to break it to different threads.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main thread will run the majority of the code: it‚Äôll transcribe my recording
    to text (via Whisper), display this text on the screen as part of the chat, and
    then display the tutor‚Äôs written response on the chat screen as well (as received
    by ChatGPT). But I‚Äôll have to move the tutor‚Äôs text-to-speech to a separate thread
    ‚Äî otherwise, what we‚Äôll have is:'
  prefs: []
  type: TYPE_NORMAL
- en: the tutor‚Äôs voice will only be heard once the entire message will be received
    from ChatGPT, and its response might be long
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: it‚Äôll block the user from responding while the tutor speaks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: that‚Äôs not the ‚Äúflowing‚Äù behavior I‚Äôd like to have; I‚Äôd like the tutor to begin
    speaking as its message is being written on the screen, and to certainly not block
    the user and prevent it from responding just because audio is still playing.
  prefs: []
  type: TYPE_NORMAL
- en: To do that, the text-to-speech part of the project was split to *two* additional
    threads. As the tutor‚Äôs response was being received from ChatGPT token-by-token,
    every full sentence created was passed to another thread, from which it was sent
    to the text-to-speech service, converting it to sound files. I‚Äôd like to emphasize
    the word *files* here ‚Äî as I‚Äôm sending text to the TTS service sentence-by-sentence,
    I also have multiple audio files, one per each sentence, which need to be played
    in the correct order. These sound files are then played from another thread, making
    sure audio playback does not block the rest of the program from running.
  prefs: []
  type: TYPE_NORMAL
- en: Making all this work, along with several other issues originating from UI-server
    interactions, were *the* complicated part of this project. Surprising, huh ‚Äî software
    engineering is where things get hard.
  prefs: []
  type: TYPE_NORMAL
- en: Designing the UI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/f6755d93b567e854ae6f1373a6eec390.png)'
  prefs: []
  type: TYPE_IMG
- en: Project‚Äôs UI
  prefs: []
  type: TYPE_NORMAL
- en: 'Well, a UI was something I knew I‚Äôll need, and I also knew pretty much how
    I‚Äôd like it to look ‚Äî but coding a UI is beyond my knowledge. So I decided to
    try a novel approach: I asked ChatGPT to write my UI for me.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For this I used the actual ChatGPT service (not the API), and used GPT-4 (yes,
    I‚Äôm a proud paying customer!). Surprisingly, my initial prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: delivered an amazing first result, ending up with a Python-Flask backend, jQuery
    code, HTML and matching CSS. But that was only about 80% of all the functionality
    I was hoping to get, so I spent roughly 10 hours going back-and-forth with GPT-4,
    optimizing and upgrading my UI, one request at a time.
  prefs: []
  type: TYPE_NORMAL
- en: 'If I made it look simple,I won‚Äôt to clearly say that it wasn‚Äôt. The more requests
    I added, the more GPT-4 got confused and delivered malfunctioning code, which
    at some point was easier to correct manually than asking it to fix it. And I had
    a lot of requests:'
  prefs: []
  type: TYPE_NORMAL
- en: Add a profile picture next to each message
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add a button for every message re-playing the its audio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add a button to every French message that will add its translation below the
    original text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add a save-session and a load-session buttons
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add a dark-mode option, make it choose the right mode automatically
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add a ‚Äúworking‚Äù icon whenever a respond from a service is waited for
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And many many more‚Ä¶
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Still, even though usually GPT‚Äôs code never worked out of the box, considering
    the fact I have very little knowledge in the fields of front-end, the results
    are amazing ‚Äî and far beyond anything I could have done myself just by Googling
    and StackOverflowing. I‚Äôve also made a lot of progress in learning how to craft
    better prompts. Thinking about it, perhaps I should write another blogpost just
    on the lessons-learned from literally building a product from the ground up alongside
    an LLM‚Ä¶ (*well,* [*I did*](https://shakedzy.medium.com/7-lessons-learned-on-creating-a-complete-product-using-chatgpt-462038856c85)).
  prefs: []
  type: TYPE_NORMAL
- en: Prompt Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*For this part of the post, I will assume you have some basic knowledge of
    how communication with a Chat LLM (like ChatGPT) works via API. If you don‚Äôt,
    you might get a little lost.*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c540817f73169cb754ea28c5f3936d12.png)'
  prefs: []
  type: TYPE_IMG
- en: Made with Dall-E
  prefs: []
  type: TYPE_NORMAL
- en: Last but most-certainly not least ‚Äî I had to make GPT take the role of a private
    tutor.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a starting point, I added a *System Prompt* to the beginning of the chat.
    As the chat with an LLM is basically a list of messages sent by the user and the
    bot to each other, a System Prompt is usually the first message of the chat, which
    describes to the bot how it should behave and what is expected of it. Mine looked
    something like this (parameters encapsulated by curly-braces are replaced by run-time
    values):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This was actually yielding pretty good results, but it seemed like the effectiveness
    of the behavioral instructions I gave the bot (‚Äúcorrect me when I‚Äôm wrong‚Äù, ‚Äúalways
    respond in French‚Äù), decayed as the chat went on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Trying to fight this vanishing behavior, I came up with an interesting solution;
    I manipulated the user messages before sending them over to GPT. Whatever the
    user‚Äôs message was, I added additional text to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Adding these at the end of every user‚Äôs message made sure the LLM responds exactly
    the way I wanted it to. It is worth mentioning that the long suffix I added is
    written in English, while the user‚Äôs message might not. This is why I added an
    explicit separator between the original message and my addition (the `---`), ending
    the context of the original message and starting a new context. Also note that
    as this suffix is added to the user‚Äôs message, it is written in first-person (‚ÄúI‚Äù,
    ‚Äúme‚Äù, etc..). This little trick improved results and behavior dramatically. While
    it might goes without saying, it might be worth emphasizing that this suffix is
    not displayed in the chat UI and the user has no idea it is added to their messages.
    It is inserted behind the scenes, right before being sent with the rest of the
    chat history to ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: One more behavior I wanted to have was making the tutor speak first, meaning
    ChatGPT will send the first message as the session begins, without waiting for
    the user to initiate the session. That is, apparently, not something ChatGPT was
    designed to do.
  prefs: []
  type: TYPE_NORMAL
- en: What I found out when attempting to make ChatGPT reply on a messages-history
    that contained only the System Prompt, is that ChatGPT ‚Äúlost it‚Äù, and began creating
    a chat with itself, playing both the user and the bot. No matter what I tried,
    I wasn‚Äôt able to make it properly initiate the session without the user saying
    something first.
  prefs: []
  type: TYPE_NORMAL
- en: 'And then I had an idea. When the session initialized, I send ChatGPT the following
    message on behalf of the user:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This request was designed to make GPT‚Äôs response look exactly how I thought
    a proper initialization of the session by the bot should be like. I then removed
    my message from the chat, and made it seem as if the bot kicked off the session
    by itself.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/bccd020fb50ed849a1d0f71945c66286.png)'
  prefs: []
  type: TYPE_IMG
- en: Made with Dall-E, edited
  prefs: []
  type: TYPE_NORMAL
- en: What kicked-off as a funny little whim became reality in literally no-time,
    done completely during spare-time of only one quite-busy man. The fact that tasks
    such as these are now so simple to create does not cease to amaze me. Just one
    year ago, having something as ChatGPT available was sci-fi, and now I can shape
    it from my own personal laptop.
  prefs: []
  type: TYPE_NORMAL
- en: This is the beginning of the future, and whatever is to come ‚Äî at least I know
    I‚Äôll be ready for it with one more foreign language. *Au revoir!*
  prefs: []
  type: TYPE_NORMAL
