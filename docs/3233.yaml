- en: Constrained Optimization and the KKT Conditions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: çº¦æŸä¼˜åŒ–ä¸ KKT æ¡ä»¶
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/constrained-optimization-and-the-kkt-conditions-a3541d57a994?source=collection_archive---------2-----------------------#2023-10-28](https://towardsdatascience.com/constrained-optimization-and-the-kkt-conditions-a3541d57a994?source=collection_archive---------2-----------------------#2023-10-28)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/constrained-optimization-and-the-kkt-conditions-a3541d57a994?source=collection_archive---------2-----------------------#2023-10-28](https://towardsdatascience.com/constrained-optimization-and-the-kkt-conditions-a3541d57a994?source=collection_archive---------2-----------------------#2023-10-28)
- en: an insight into the Lagrangian function
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯¹æ‹‰æ ¼æœ—æ—¥å‡½æ•°çš„è§è§£
- en: '[](https://paribeshregmi.medium.com/?source=post_page-----a3541d57a994--------------------------------)[![Paribesh
    Regmi](../Images/7580cbd23a1269a1540d53acc54f5ebc.png)](https://paribeshregmi.medium.com/?source=post_page-----a3541d57a994--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a3541d57a994--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a3541d57a994--------------------------------)
    [Paribesh Regmi](https://paribeshregmi.medium.com/?source=post_page-----a3541d57a994--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://paribeshregmi.medium.com/?source=post_page-----a3541d57a994--------------------------------)[![Paribesh
    Regmi](../Images/7580cbd23a1269a1540d53acc54f5ebc.png)](https://paribeshregmi.medium.com/?source=post_page-----a3541d57a994--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a3541d57a994--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a3541d57a994--------------------------------)
    [Paribesh Regmi](https://paribeshregmi.medium.com/?source=post_page-----a3541d57a994--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe15368282264&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconstrained-optimization-and-the-kkt-conditions-a3541d57a994&user=Paribesh+Regmi&userId=e15368282264&source=post_page-e15368282264----a3541d57a994---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a3541d57a994--------------------------------)
    Â·8 min readÂ·Oct 28, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa3541d57a994&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconstrained-optimization-and-the-kkt-conditions-a3541d57a994&user=Paribesh+Regmi&userId=e15368282264&source=-----a3541d57a994---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe15368282264&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconstrained-optimization-and-the-kkt-conditions-a3541d57a994&user=Paribesh+Regmi&userId=e15368282264&source=post_page-e15368282264----a3541d57a994---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a3541d57a994--------------------------------)
    Â· 8 åˆ†é’Ÿé˜…è¯» Â· 2023å¹´10æœˆ28æ—¥ [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa3541d57a994&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconstrained-optimization-and-the-kkt-conditions-a3541d57a994&user=Paribesh+Regmi&userId=e15368282264&source=-----a3541d57a994---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa3541d57a994&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconstrained-optimization-and-the-kkt-conditions-a3541d57a994&source=-----a3541d57a994---------------------bookmark_footer-----------)![](../Images/a66337b86cce4b5a7cb921d37dff75a2.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa3541d57a994&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconstrained-optimization-and-the-kkt-conditions-a3541d57a994&source=-----a3541d57a994---------------------bookmark_footer-----------)![](../Images/a66337b86cce4b5a7cb921d37dff75a2.png)'
- en: (Image by author, using math3d.org)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆä½œè€…æä¾›çš„å›¾ç‰‡ï¼Œä½¿ç”¨ math3d.orgï¼‰
- en: Optimization is ubiquitous in the realms of computer science, physics, mathematics,
    and economics. It stands as an essential tool for AI and machine learning (ML)
    professionals, applicable in diverse domains including decision-making, route
    planning, and learning parameters in ML models, such as Support Vector Machines
    (SVM) and neural networks. The most general form of optimization is finding a
    minimum/maximum of a function with respect to its independent variables, which
    can be achieved by applying basic concepts of differential calculus. Mathematically,
    at these extremities, the slope (first derivative) of a function is zero, referred
    to as **stationary points**. Determining whether such a point represents a maxima
    or a minima is done by evaluating the curvature (second derivative).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼˜åŒ–åœ¨è®¡ç®—æœºç§‘å­¦ã€ç‰©ç†å­¦ã€æ•°å­¦å’Œç»æµå­¦é¢†åŸŸä¸­æ— å¤„ä¸åœ¨ã€‚å®ƒæ˜¯äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ ï¼ˆMLï¼‰ä¸“ä¸šäººå‘˜çš„åŸºæœ¬å·¥å…·ï¼Œé€‚ç”¨äºå†³ç­–ã€è·¯çº¿è§„åˆ’ä»¥åŠMLæ¨¡å‹ä¸­çš„å­¦ä¹ å‚æ•°ï¼Œå¦‚æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰å’Œç¥ç»ç½‘ç»œã€‚ä¼˜åŒ–çš„æœ€ä¸€èˆ¬å½¢å¼æ˜¯æ±‚å‡½æ•°å…³äºå…¶ç‹¬ç«‹å˜é‡çš„æœ€å°å€¼/æœ€å¤§å€¼ï¼Œè¿™å¯ä»¥é€šè¿‡åº”ç”¨å¾®ç§¯åˆ†çš„åŸºæœ¬æ¦‚å¿µæ¥å®ç°ã€‚ä»æ•°å­¦ä¸Šè®²ï¼Œåœ¨è¿™äº›æå€¼ç‚¹ä¸Šï¼Œå‡½æ•°çš„æ–œç‡ï¼ˆç¬¬ä¸€å¯¼æ•°ï¼‰ä¸ºé›¶ï¼Œç§°ä¸º**é©»ç‚¹**ã€‚é€šè¿‡è¯„ä¼°æ›²ç‡ï¼ˆç¬¬äºŒå¯¼æ•°ï¼‰æ¥ç¡®å®šè¿™äº›ç‚¹æ˜¯æœ€å¤§å€¼è¿˜æ˜¯æœ€å°å€¼ã€‚
- en: Taking this a step further, we can add constraints to the optimization problem
    that define a specific domain in space where the function is to be optimized.
    Consequently, instead of determining the maximum and minimum of a function in
    all of real (or complex) space, the optimization is now confined to this specific
    domain. The conventional approach of calculating stationary points is no longer
    a solution, as these points may fall outside the boundary set by the constraints.
    In the coming sections, we will analyze the intricacies of constrained optimization
    problems and explore strategies for their resolution.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´è¿›ä¸€æ­¥ï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºä¼˜åŒ–é—®é¢˜æ·»åŠ çº¦æŸï¼Œä»¥å®šä¹‰ä¸€ä¸ªåœ¨ç©ºé—´ä¸­éœ€è¦ä¼˜åŒ–çš„ç‰¹å®šåŸŸã€‚å› æ­¤ï¼Œä¼˜åŒ–ä¸å†æ˜¯ç¡®å®šæ•´ä¸ªå®æ•°ï¼ˆæˆ–å¤æ•°ï¼‰ç©ºé—´ä¸­å‡½æ•°çš„æœ€å¤§å€¼å’Œæœ€å°å€¼ï¼Œè€Œæ˜¯é™å®šåœ¨è¿™ä¸ªç‰¹å®šçš„åŸŸä¸­ã€‚ä¼ ç»Ÿçš„è®¡ç®—é©»ç‚¹çš„æ–¹æ³•ä¸å†é€‚ç”¨ï¼Œå› ä¸ºè¿™äº›ç‚¹å¯èƒ½è½åœ¨çº¦æŸè®¾å®šçš„è¾¹ç•Œä¹‹å¤–ã€‚åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†åˆ†æçº¦æŸä¼˜åŒ–é—®é¢˜çš„å¤æ‚æ€§ï¼Œå¹¶æ¢ç´¢è§£å†³è¿™äº›é—®é¢˜çš„ç­–ç•¥ã€‚
- en: Equality Constraints
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç­‰å¼çº¦æŸ
- en: Optimization problems with equality constraints are of the form
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å¸¦æœ‰ç­‰å¼çº¦æŸçš„ä¼˜åŒ–é—®é¢˜çš„å½¢å¼ä¸º
- en: '![](../Images/be3d18155635f94c7943f64fc8f75302.png)![](../Images/39cd92a7560c84ee0f809668b10ffb8d.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/be3d18155635f94c7943f64fc8f75302.png)![](../Images/39cd92a7560c84ee0f809668b10ffb8d.png)'
- en: (Image by author)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰
- en: where ***f(x)*** is the function that we seek to minimize, and the constraint
    ***g(x) = 0***defines the domain within which the minimization is to be carried
    out. In these instances, the focus of minimization is inherently confined to the
    specific domain defined by the constraint. Nonetheless, as previously noted, the
    conventional application of differential calculus to determine stationary points
    does not account for the constraint, necessitating an alternative approach.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­***f(x)***æ˜¯æˆ‘ä»¬è¦æœ€å°åŒ–çš„å‡½æ•°ï¼Œçº¦æŸæ¡ä»¶***g(x) = 0***å®šä¹‰äº†æœ€å°åŒ–åº”è¿›è¡Œçš„åŸŸã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œæœ€å°åŒ–çš„é‡ç‚¹æœ¬è´¨ä¸Šé™äºç”±çº¦æŸå®šä¹‰çš„ç‰¹å®šåŸŸã€‚ç„¶è€Œï¼Œå¦‚å‰æ‰€è¿°ï¼Œä¼ ç»Ÿçš„å¾®ç§¯åˆ†åº”ç”¨äºç¡®å®šé©»ç‚¹çš„æ–¹æ³•æ²¡æœ‰è€ƒè™‘çº¦æŸï¼Œå› æ­¤éœ€è¦ä¸€ç§æ›¿ä»£æ–¹æ³•ã€‚
- en: Lagrangian function
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ‹‰æ ¼æœ—æ—¥å‡½æ•°
- en: 'Given that this is a minimization problem, one approach to adapt to the conventional
    method is to assign a value of infinity to the function outside the specified
    domain. To achieve this, we introduce a new function ***fâ€™(x)*** characterized
    by the following expression:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: é‰´äºè¿™æ˜¯ä¸€ä¸ªæœ€å°åŒ–é—®é¢˜ï¼Œä¸€ç§é€‚åº”ä¼ ç»Ÿæ–¹æ³•çš„æ–¹æ³•æ˜¯å°†å‡½æ•°åœ¨æŒ‡å®šåŸŸå¤–çš„å€¼è®¾ä¸ºæ— ç©·å¤§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥ä¸€ä¸ªæ–°çš„å‡½æ•°***fâ€™(x)***ï¼Œå…¶ç‰¹å¾å¦‚ä¸‹ï¼š
- en: '![](../Images/b22426dece319578bcb88fab60ecbeba.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b22426dece319578bcb88fab60ecbeba.png)'
- en: Such modification eliminates the possibility of minima occurring outside the
    domain, thereby ensuring that the optimal point occurs within it. Consequently,
    we can now reformulate the constrained optimization into an unconstrained optimization
    problem.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§ä¿®æ”¹æ¶ˆé™¤äº†åœ¨åŸŸå¤–å‡ºç°æœ€å°å€¼çš„å¯èƒ½æ€§ï¼Œä»è€Œç¡®ä¿æœ€ä¼˜ç‚¹å‘ç”Ÿåœ¨åŸŸå†…ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥å°†çº¦æŸä¼˜åŒ–é—®é¢˜é‡æ–°è¡¨è¿°ä¸ºæ— çº¦æŸä¼˜åŒ–é—®é¢˜ã€‚
- en: '![](../Images/c9b8158a8acdfb48e099bda35fdf1787.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c9b8158a8acdfb48e099bda35fdf1787.png)'
- en: However, there is a challenge that comes with this approach. Using differential
    calculus to optimize the above problem is not possible, since the function ***fâ€™(x)***
    is not differentiable due to a sudden discontinuity at the at the boundary of
    the domain. Here is where Lagrangian comes into play. Rather than defining the
    function ***fâ€™(x)*** as in (2), we formulate it as a maximization problem.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•å­˜åœ¨æŒ‘æˆ˜ã€‚ç”±äº***fâ€™(x)***åœ¨é¢†åŸŸè¾¹ç•Œçš„çªç„¶é—´æ–­ï¼Œä½¿ç”¨å¾®åˆ†è®¡ç®—æ¥ä¼˜åŒ–ä¸Šè¿°é—®é¢˜æ˜¯ä¸å¯èƒ½çš„ã€‚åœ¨è¿™é‡Œï¼Œæ‹‰æ ¼æœ—æ—¥æ–¹æ³•å‘æŒ¥äº†ä½œç”¨ã€‚æˆ‘ä»¬ä¸æ˜¯åƒï¼ˆ2ï¼‰ä¸­é‚£æ ·å®šä¹‰å‡½æ•°***fâ€™(x)***ï¼Œè€Œæ˜¯å°†å…¶è¡¨è¿°ä¸ºä¸€ä¸ªæœ€å¤§åŒ–é—®é¢˜ã€‚
- en: '![](../Images/019d487cce97c2bec7684cf3531e86e4.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/019d487cce97c2bec7684cf3531e86e4.png)'
- en: The expression on the RHS is called the **Lagrangian function** and the new
    variable ğ´ is the **Lagrange multiplier**. It is evident from (4) that that at
    regions where **{*g(x)<0, g(x)>0*}**, ğ´ can take the values **{-âˆ, âˆ}** to maximize
    the expression to **âˆ**.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: RHSä¸Šçš„è¡¨è¾¾å¼ç§°ä¸º**æ‹‰æ ¼æœ—æ—¥å‡½æ•°**ï¼Œæ–°å˜é‡ğ´æ˜¯**æ‹‰æ ¼æœ—æ—¥ä¹˜å­**ã€‚ä»ï¼ˆ4ï¼‰å¯ä»¥æ˜æ˜¾çœ‹å‡ºï¼Œåœ¨**{*g(x)<0, g(x)>0*}**åŒºåŸŸï¼Œğ´å¯ä»¥å–**{-âˆ,
    âˆ}**çš„å€¼ï¼Œä»¥æœ€å¤§åŒ–è¯¥è¡¨è¾¾å¼è‡³**âˆ**ã€‚
- en: As a result, the optimization in (3) takes the following form.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæ–¹ç¨‹ï¼ˆ3ï¼‰ä¸­çš„ä¼˜åŒ–é—®é¢˜å‘ˆç°å¦‚ä¸‹å½¢å¼ã€‚
- en: '![](../Images/6203dcec8513faf805b7d41fcfe94d9a.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6203dcec8513faf805b7d41fcfe94d9a.png)'
- en: Itâ€™s worth noting that the problem of non-differentiability still exists as
    the inner maximization results in the same discontinuous function. However, with
    the Lagrangian representation, we can use the max-min inequality to convert the
    max-min problem to the min-max problem to get over this issue.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œéå¯å¾®æ€§é—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œå› ä¸ºå†…éƒ¨æœ€å¤§åŒ–ä¼šå¯¼è‡´ç›¸åŒçš„é—´æ–­å‡½æ•°ã€‚ç„¶è€Œï¼Œé€šè¿‡æ‹‰æ ¼æœ—æ—¥è¡¨ç¤ºæ³•ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨æå¤§æå°ä¸ç­‰å¼å°†æå¤§æå°é—®é¢˜è½¬æ¢ä¸ºæå°æå¤§é—®é¢˜ï¼Œä»è€Œè§£å†³è¿™ä¸ªé—®é¢˜ã€‚
- en: '![](../Images/eccf3a2e7de206ad9e303b9de5f657a1.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eccf3a2e7de206ad9e303b9de5f657a1.png)'
- en: Here, we first optimize with respect to the independent variable **x** and then
    with respect to the Lagrange multiplier ğ´.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é¦–å…ˆç›¸å¯¹äºç‹¬ç«‹å˜é‡**x**è¿›è¡Œä¼˜åŒ–ï¼Œç„¶åç›¸å¯¹äºæ‹‰æ ¼æœ—æ—¥ä¹˜å­ğ´è¿›è¡Œä¼˜åŒ–ã€‚
- en: Inequality Constraints
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸ç­‰å¼çº¦æŸ
- en: '![](../Images/7796e3a469b422e11f83a9349e47363e.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7796e3a469b422e11f83a9349e47363e.png)'
- en: (Image by author)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆä½œè€…æä¾›çš„å›¾ç‰‡ï¼‰
- en: 'Weâ€™ll now analyze the scenarios when the constraint is not an equation but
    an inequality. Such optimizations are of the form:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å°†åˆ†æçº¦æŸä¸æ˜¯æ–¹ç¨‹è€Œæ˜¯ä¸ç­‰å¼æ—¶çš„æƒ…å½¢ã€‚è¿™ç±»ä¼˜åŒ–é—®é¢˜çš„å½¢å¼ä¸ºï¼š
- en: '![](../Images/4831bd2ddfa59da35234f95667b35a15.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4831bd2ddfa59da35234f95667b35a15.png)'
- en: 'We can solve this using a similar approach: we define ***fâ€™(x)*** to be the
    same as ***f(x)*** within the domain defined by the constraints and infinite elsewhere:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç±»ä¼¼çš„æ–¹æ³•æ¥è§£å†³ï¼šæˆ‘ä»¬å°†***fâ€™(x)***å®šä¹‰ä¸ºåœ¨ç”±çº¦æŸå®šä¹‰çš„é¢†åŸŸå†…ä¸***f(x)***ç›¸åŒï¼Œè€Œåœ¨å…¶ä»–åœ°æ–¹ä¸ºæ— é™ï¼š
- en: '![](../Images/46ce5189dfaf941bedee284bcb3e0d65.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/46ce5189dfaf941bedee284bcb3e0d65.png)'
- en: 'Correspondingly, the Lagrangian function is defined as:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ç›¸åº”åœ°ï¼Œæ‹‰æ ¼æœ—æ—¥å‡½æ•°å®šä¹‰ä¸ºï¼š
- en: '![](../Images/38a60c9d79adefa382829f487f307979.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/38a60c9d79adefa382829f487f307979.png)'
- en: The Lagrange multipliers corresponding to inequality constraints are denoted
    by *ğ»*. Equation (9) is different in that it also has constraints on the Lagrange
    multipliers, which was not in (4). Now the optimization problem in (7) takes the
    form
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ä¸ç­‰å¼çº¦æŸå¯¹åº”çš„æ‹‰æ ¼æœ—æ—¥ä¹˜å­ç”¨*ğ»*è¡¨ç¤ºã€‚æ–¹ç¨‹ï¼ˆ9ï¼‰ä¸ï¼ˆ4ï¼‰ä¸åŒï¼Œå› ä¸ºå®ƒè¿˜å¯¹æ‹‰æ ¼æœ—æ—¥ä¹˜å­æœ‰çº¦æŸã€‚ç°åœ¨ï¼Œæ–¹ç¨‹ï¼ˆ7ï¼‰ä¸­çš„ä¼˜åŒ–é—®é¢˜å‘ˆç°å¦‚ä¸‹å½¢å¼
- en: '![](../Images/109ad31ca255673bd62ff14059b457a8.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/109ad31ca255673bd62ff14059b457a8.png)'
- en: Applying min-max inequality,
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: åº”ç”¨æå°æå¤§ä¸ç­‰å¼ï¼Œ
- en: '![](../Images/e71552a27a584fc1b3a01c304bd84e0e.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e71552a27a584fc1b3a01c304bd84e0e.png)'
- en: Interpretation of the Lagrange multiplier ***ğ»***
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ‹‰æ ¼æœ—æ—¥ä¹˜å­***ğ»***çš„è§£é‡Š
- en: 'When calculating the stationary point of (11) with respect to ***x***, we get
    the following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å½“è®¡ç®—ï¼ˆ11ï¼‰çš„é©»ç‚¹æ—¶ï¼Œç›¸å¯¹äº***x***ï¼Œæˆ‘ä»¬å¾—åˆ°å¦‚ä¸‹ç»“æœï¼š
- en: '![](../Images/aec23980b036a3e6d3d1b36ed02e2c20.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aec23980b036a3e6d3d1b36ed02e2c20.png)'
- en: The Lagrange multiplier *ğ»* is the ratio of the slope of ***f(x)*** to the constraint
    ***g(x).*** This essentially represents the sensitivity of the optimal value of
    ***f(x)*** concerning the constraint ***g(x).*** In other words, the value of
    the Lagrange multiplier quantifies the impact of the constraint on the optimality
    of ***f(x);*** a value of *ğ» = 0* would imply that the constraint has no influence
    on the optimality***.*** Further elaboration on this concept is presented in the
    subsequent discussion on KKT conditions.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æ‹‰æ ¼æœ—æ—¥ä¹˜å­ *ğ»* æ˜¯ ***f(x)*** çš„æ–œç‡ä¸çº¦æŸ ***g(x)*** ä¹‹é—´çš„æ¯”ç‡ã€‚è¿™æœ¬è´¨ä¸Šè¡¨ç¤ºäº† ***f(x)*** æœ€ä¼˜å€¼å¯¹çº¦æŸ ***g(x)***
    çš„æ•æ„Ÿæ€§ã€‚æ¢å¥è¯è¯´ï¼Œæ‹‰æ ¼æœ—æ—¥ä¹˜å­çš„å€¼é‡åŒ–äº†çº¦æŸå¯¹ ***f(x)*** æœ€ä¼˜æ€§çš„å½±å“ï¼›å¦‚æœ *ğ» = 0*ï¼Œåˆ™è¡¨ç¤ºçº¦æŸå¯¹æœ€ä¼˜æ€§æ²¡æœ‰å½±å“ã€‚å¯¹æ­¤æ¦‚å¿µçš„è¿›ä¸€æ­¥é˜è¿°å°†åœ¨åç»­å¯¹
    KKT æ¡ä»¶çš„è®¨è®ºä¸­è¿›è¡Œã€‚
- en: KKT (Karush-Kuhn-Tucker) conditions
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KKTï¼ˆKarush-Kuhn-Tuckerï¼‰æ¡ä»¶
- en: 'The optimization in (10) is called the primal version and (11) is its dual
    version. According to min-max inequality, the dual version lower bounds the primal
    version, suggesting that the two versions are not necessarily equal. However,
    there are conditions where the primal and dual versions are equal, which is called
    the **regularity condition**. Assuming regularity, for (***x*,*** *ğ»********)to
    be the solution point it has to satisfy the following **KKT conditions**:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆ10ï¼‰ä¸­çš„ä¼˜åŒ–é—®é¢˜ç§°ä¸ºåŸå§‹ç‰ˆæœ¬ï¼Œè€Œï¼ˆ11ï¼‰æ˜¯å…¶å¯¹å¶ç‰ˆæœ¬ã€‚æ ¹æ®æå°æå¤§ä¸ç­‰å¼ï¼Œå¯¹å¶ç‰ˆæœ¬å¯¹åŸå§‹ç‰ˆæœ¬è¿›è¡Œä¸‹ç•Œä¼°è®¡ï¼Œè¡¨æ˜è¿™ä¸¤ä¸ªç‰ˆæœ¬ä¸ä¸€å®šç›¸ç­‰ã€‚ç„¶è€Œï¼Œåœ¨æŸäº›æ¡ä»¶ä¸‹ï¼ŒåŸå§‹ç‰ˆæœ¬å’Œå¯¹å¶ç‰ˆæœ¬æ˜¯ç›¸ç­‰çš„ï¼Œè¿™è¢«ç§°ä¸º**æ­£åˆ™æ€§æ¡ä»¶**ã€‚åœ¨å‡è®¾æ­£åˆ™æ€§çš„æƒ…å†µä¸‹ï¼Œä¸ºäº†ä½¿ï¼ˆ***x*,***
    *ğ»********ï¼‰æˆä¸ºè§£ç‚¹ï¼Œå®ƒå¿…é¡»æ»¡è¶³ä»¥ä¸‹ **KKT æ¡ä»¶**ï¼š
- en: '**Primal Feasibility**'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**åŸå§‹å¯è¡Œæ€§**'
- en: '![](../Images/caa5bd299b67243130ee2e8d5f138dcd.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/caa5bd299b67243130ee2e8d5f138dcd.png)'
- en: It follows from the problem definition.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä»é—®é¢˜å®šä¹‰ä¸­å¾—å‡ºã€‚
- en: '**2\. Dual Feasibility**'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. å¯¹å¶å¯è¡Œæ€§**'
- en: '![](../Images/55996cbdf99904b677f11cb6a3c105df.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/55996cbdf99904b677f11cb6a3c105df.png)'
- en: The dual feasibility follows from (9).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹å¶å¯è¡Œæ€§ä»ï¼ˆ9ï¼‰ä¸­å¾—å‡ºã€‚
- en: '**3\. Stationarity**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. å¹³ç¨³æ€§**'
- en: '![](../Images/8eeaafe5e1bda2d60579cbd57838f17f.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8eeaafe5e1bda2d60579cbd57838f17f.png)'
- en: 'This is an interesting property. Since ğ»* is a zero or a positive, the stationarity
    condition implies that at the optimal point, the gradients of ***f(x)*** and ***g(x)***
    must be oriented in opposite directions. The rationale behind this is as follows:
    if the gradients of ***f(x)*** and***g(x)***were aligned in the same direction
    at the point ***x = x****, then both ***f(x)*** and ***g(x)*** would simultaneously
    decrease in a direction opposite to their gradients. This scenario would permit
    ***f(x)*** to continue decreasing beyond the value ***f(x*)*** without violating
    the constraint, in which case ***x**** no longer qualifies as the optimal point.
    Therefore for a point to be the optimum, the stationarity property must hold.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªæœ‰è¶£çš„æ€§è´¨ã€‚ç”±äº *ğ»* æ˜¯é›¶æˆ–æ­£æ•°ï¼Œå¹³ç¨³æ€§æ¡ä»¶æ„å‘³ç€åœ¨æœ€ä¼˜ç‚¹ä¸Šï¼Œ***f(x)*** å’Œ ***g(x)*** çš„æ¢¯åº¦å¿…é¡»æœç›¸åæ–¹å‘æ’åˆ—ã€‚å…¶åŸç†å¦‚ä¸‹ï¼šå¦‚æœåœ¨ç‚¹
    ***x = x**** ä¸Šï¼Œ***f(x)*** å’Œ ***g(x)*** çš„æ¢¯åº¦æ–¹å‘ç›¸åŒï¼Œé‚£ä¹ˆ ***f(x)*** å’Œ ***g(x)*** ä¼šåœ¨ä¸å…¶æ¢¯åº¦æ–¹å‘ç›¸åçš„æ–¹å‘ä¸ŠåŒæ—¶å‡å°‘ã€‚è¿™ç§æƒ…å†µä¼šå…è®¸
    ***f(x)*** ç»§ç»­å‡å°è¶…å‡ºå€¼ ***f(x*)*** è€Œä¸è¿åçº¦æŸï¼Œæ­¤æ—¶ ***x**** ä¸å†ç¬¦åˆæœ€ä¼˜ç‚¹ã€‚å› æ­¤ï¼Œä¸ºäº†ä½¿ä¸€ä¸ªç‚¹æˆä¸ºæœ€ä¼˜ç‚¹ï¼Œå¿…é¡»æ»¡è¶³å¹³ç¨³æ€§å±æ€§ã€‚
- en: '**4\. Complementary Slackness**'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**4\. äº’è¡¥æ¾å¼›æ€§**'
- en: '![](../Images/9be1045e3e15f10153bf7197e910e968.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9be1045e3e15f10153bf7197e910e968.png)'
- en: 'This is another interesting property that directly follows from equation (9).
    When the constraint ***g(x*) < 0***, the Lagrange multiplier ğ»* must equal to
    zero. Since the Lagrange multiplier also indicates how sensitive our solution
    is to the associated constraint, a value of ğ»* = 0 signifies that the associated
    constraint has no influence on determining the solution. In other words, whether
    we consider the solution with or without the constraint, the outcome remains unaltered.
    One straightforward example is when ***f(x)*** has a global minimum in the domain
    where ***g(x) â‰¤ 0***. For the other example, consider the minimization of the
    function ***f(x)*** subject to two constraints: ***gÂ¹(x) < 5*** and ***gÂ²(x) <
    -1***. In this case, the Lagrange multiplier ğ»Â¹***** corresponding to the constraint
    ***gÂ¹*** is zero, as ***gÂ²*** already implies the conditions of ***gÂ¹***, rendering
    ***gÂ¹*** insignificant as a constraint.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¦ä¸€ä¸ªç›´æ¥æ¥è‡ªæ–¹ç¨‹ï¼ˆ9ï¼‰çš„æœ‰è¶£æ€§è´¨ã€‚å½“çº¦æŸ***g(x*) < 0***æ—¶ï¼Œæ‹‰æ ¼æœ—æ—¥ä¹˜å­ğ»*å¿…é¡»ç­‰äºé›¶ã€‚ç”±äºæ‹‰æ ¼æœ—æ—¥ä¹˜å­è¿˜è¡¨ç¤ºæˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆå¯¹ç›¸å…³çº¦æŸçš„æ•æ„Ÿåº¦ï¼Œğ»*
    = 0è¡¨ç¤ºç›¸å…³çº¦æŸå¯¹ç¡®å®šè§£å†³æ–¹æ¡ˆæ²¡æœ‰å½±å“ã€‚æ¢å¥è¯è¯´ï¼Œæ— è®ºæˆ‘ä»¬æ˜¯å¦è€ƒè™‘çº¦æŸï¼Œç»“æœä¿æŒä¸å˜ã€‚ä¸€ä¸ªç®€å•çš„ä¾‹å­æ˜¯å½“***f(x)***åœ¨***g(x) â‰¤ 0***çš„èŒƒå›´å†…æœ‰å…¨å±€æœ€å°å€¼ã€‚å¦ä¸€ä¸ªä¾‹å­æ˜¯è€ƒè™‘åœ¨ä¸¤ä¸ªçº¦æŸä¸‹æœ€å°åŒ–å‡½æ•°***f(x)***ï¼š***gÂ¹(x)
    < 5***å’Œ***gÂ²(x) < -1***ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‹‰æ ¼æœ—æ—¥ä¹˜å­ğ»Â¹*****å¯¹åº”äºçº¦æŸ***gÂ¹***æ˜¯é›¶ï¼Œå› ä¸º***gÂ²***å·²ç»éšå«äº†***gÂ¹***çš„æ¡ä»¶ï¼Œä½¿å¾—***gÂ¹***ä½œä¸ºçº¦æŸä¸é‡è¦ã€‚
- en: 'Application: Support Vector Machine (SVM)'
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åº”ç”¨ï¼šæ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰
- en: 'An example of constrained optimization with inequality constraints in machine
    learning is the Support Vector Machine (SVM). When given a dataset of data points
    **{(*xÂ¹, yÂ¹*), (*xÂ², yÂ²*), â€¦}** with ***y âˆˆ* {*-1, 1*}** representing the two
    classes, the objective is to identify a classifier that maximizes the margin between
    the classes. Specifically, we formulate SVM as the following minimization problem:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ ä¸­å¸¦æœ‰ä¸ç­‰å¼çº¦æŸçš„ä¼˜åŒ–é—®é¢˜çš„ä¸€ä¸ªä¾‹å­æ˜¯æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰ã€‚ç»™å®šæ•°æ®ç‚¹**{(*xÂ¹, yÂ¹*), (*xÂ², yÂ²*), â€¦}**çš„ä¸€ä¸ªæ•°æ®é›†ï¼Œå…¶ä¸­***y
    âˆˆ* {*-1, 1*}**è¡¨ç¤ºä¸¤ä¸ªç±»åˆ«ï¼Œç›®æ ‡æ˜¯è¯†åˆ«ä¸€ä¸ªæœ€å¤§åŒ–ç±»åˆ«ä¹‹é—´é—´éš”çš„åˆ†ç±»å™¨ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†SVMå½¢å¼åŒ–ä¸ºä»¥ä¸‹æœ€å°åŒ–é—®é¢˜ï¼š
- en: '![](../Images/41e51eabb50c4437e7a21eeeb38d93a7.png)![](../Images/97d0afa5a091924522bfb33811228aa4.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/41e51eabb50c4437e7a21eeeb38d93a7.png)![](../Images/97d0afa5a091924522bfb33811228aa4.png)'
- en: (Image by author)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆä½œè€…æä¾›çš„å›¾ç‰‡ï¼‰
- en: 'The term ***||w||*** in the equation represents the inverse of the margin.
    Itâ€™s evident that there are numerous inequality constraints: in fact, we have
    a constraint tied to each data point. However, in practice, the solution is only
    guided by a few data points that lie in proximity to the classifier boundary;
    these are referred to as **support vectors**. As we discussed in complementary
    slackness, only the Lagrange multipliers corresponding to the constraints linked
    to the support vectors possess non-zero values. For all other data points, their
    associated constraints bear Lagrange multiplier values of zero, rendering them
    insignificant in determining the classifier boundary.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹ä¸­çš„***||w||***è¡¨ç¤ºé—´éš”çš„å€’æ•°ã€‚æ˜¾ç„¶ï¼Œæœ‰å¤§é‡çš„ä¸ç­‰å¼çº¦æŸï¼šå®é™…ä¸Šï¼Œæˆ‘ä»¬å¯¹æ¯ä¸ªæ•°æ®ç‚¹éƒ½æœ‰ä¸€ä¸ªçº¦æŸã€‚ç„¶è€Œï¼Œå®é™…ä¸Šï¼Œè§£å†³æ–¹æ¡ˆåªå—åˆ°å°‘æ•°æ¥è¿‘åˆ†ç±»è¾¹ç•Œçš„æ•°æ®ç‚¹çš„æŒ‡å¯¼ï¼›è¿™äº›ç‚¹ç§°ä¸º**æ”¯æŒå‘é‡**ã€‚æ­£å¦‚æˆ‘ä»¬åœ¨äº’è¡¥æ¾å¼›æ¡ä»¶ä¸­è®¨è®ºçš„ï¼Œåªæœ‰ä¸æ”¯æŒå‘é‡ç›¸å…³çš„çº¦æŸçš„æ‹‰æ ¼æœ—æ—¥ä¹˜å­å…·æœ‰éé›¶å€¼ã€‚å¯¹äºæ‰€æœ‰å…¶ä»–æ•°æ®ç‚¹ï¼Œå…¶ç›¸å…³çº¦æŸçš„æ‹‰æ ¼æœ—æ—¥ä¹˜å­å€¼ä¸ºé›¶ï¼Œä½¿å¾—å®ƒä»¬åœ¨ç¡®å®šåˆ†ç±»è¾¹ç•Œæ—¶æ— å…³ç´§è¦ã€‚
- en: Conclusion
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: To summarize things in the article, we started with a brief introduction to
    the unconstrained optimization problem and gradually expanded it to incorporate
    the equality and inequality constraints. Moreover, we discussed how the Lagrangian
    function solves the challenges introduced by the constraints. Delving into the
    optimality of the Lagrangian, we gained insights into the KKT conditions. Lastly,
    we provided a succinct overview of how SVM is formulated as a constrained optimization
    problem and briefly discussed its solution.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ç»“ä¸€ä¸‹æ–‡ç« ä¸­çš„å†…å®¹ï¼Œæˆ‘ä»¬ä»å¯¹æ— çº¦æŸä¼˜åŒ–é—®é¢˜çš„ç®€è¦ä»‹ç»å¼€å§‹ï¼Œé€æ¸æ‰©å±•åˆ°åŒ…å«ç­‰å¼å’Œä¸ç­‰å¼çº¦æŸã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¨è®ºäº†æ‹‰æ ¼æœ—æ—¥å‡½æ•°å¦‚ä½•è§£å†³çº¦æŸå¼•å…¥çš„æŒ‘æˆ˜ã€‚æ·±å…¥æ¢è®¨æ‹‰æ ¼æœ—æ—¥å‡½æ•°çš„æœ€ä¼˜æ€§ï¼Œæˆ‘ä»¬è·å¾—äº†å¯¹KKTæ¡ä»¶çš„è§è§£ã€‚æœ€åï¼Œæˆ‘ä»¬ç®€è¦æ¦‚è¿°äº†å¦‚ä½•å°†SVMå½¢å¼åŒ–ä¸ºä¸€ä¸ªçº¦æŸä¼˜åŒ–é—®é¢˜ï¼Œå¹¶ç®€è¦è®¨è®ºäº†å…¶è§£å†³æ–¹æ¡ˆã€‚
