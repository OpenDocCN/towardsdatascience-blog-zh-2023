["```py\nimport pandas as pd\ndf = pd.read_excel(filename)\ndf = df.fillna(\"\")\ndisplay(df)\n```", "```py\ndf = pd.read_excel('sample.xlsx', sheet_name='Sheet1')\ndf = df.fillna(\"\")\nprint(df.to_csv())\n```", "```py\n,Unnamed: 0,Unnamed: 1,Unnamed: 2,Unnamed: 3,Unnamed: 4,Unnamed: 5,Unnamed: 6,Unnamed: 7,Unnamed: 8,Unnamed: 9,Unnamed: 10,Unnamed: 11\n0,Table 3: Number of acreage under irrigation,,,,,,,,,,,\n1,,,OVERALL,,Sub county,,,,,,,\n2,,,,,Chepalungu,,,,Bomet Central,,,\n3,,,,,Male,,Female,,Male,,Female,\n4,,,N,%,N,%,N,%,N,%,N,%\n5,What is the average size of land you own that is currently under irrigation?,0 - 2 acres,22,2.8%,4,2.2%,10,3.8%,3,1.7%,5,2.9%\n6,,2 - 5 acres,6,.8%,2,1.1%,2,.8%,0,0.0%,2,1.2%\n7,,5 - 10 acres,1,.1%,0,0.0%,0,0.0%,0,0.0%,1,.6%\n8,,More than 10 acres,0,0.0%,0,0.0%,0,0.0%,0,0.0%,0,0.0%\n9,,None,760,96.3%,176,96.7%,251,95.4%,170,98.3%,163,95.3%\n10,,Total,789,100.0%,182,100.0%,263,100.0%,173,100.0%,171,100.0%\n```", "```py\nimport openai as ai\n\n# Open AI API key should be put into this file\nai.api_key_path = \"./api_key.txt\"\n\ncsv_as_str = df.to_csv()\n\nprompt = (\n    \"Reformat this table to be a simpler markdown table with \"\n    + \"no hierarchical columns, no pivoting, values and percentages in different columns, \"\n    + \"and no blank cells\\n\\n\"\n    + csv_as_str\n)\n\ncompletions = ai.Completion.create(\n    engine=\"text-davinci-003\",\n    temperature=0.0,\n    prompt=prompt,\n    max_tokens=999,\n    n=1,\n    stop=None,\n)\n\nMarkdown(completions.choices[0].text)\n```", "```py\nprompt = (\n    \"Reformat this table to be a simpler markdown table with \"\n    + \"no hierarchical columns, no pivoting, values and percentages in different columns, \"\n    + \"and no blank cells\\n\\n\"\n    + csv_as_str\n)\n\ncompletions = ai.Completion.create(\n    engine=\"text-davinci-003\",\n    temperature=1.0,\n    prompt=prompt,\n    max_tokens=999,\n    n=1,\n    stop=None,\n)\n\nMarkdown(completions.choices[0].text)\n```", "```py\ncompletions = ai.Completion.create(\n    engine=\"text-davinci-003\",\n    temperature=1.0,\n    prompt=prompt,\n    max_tokens=999,\n    n=1,\n    stop=None,\n)\n\nMarkdown(completions.choices[0].text)\n```", "```py\n1,,,OVERALL,,Sub county,,,,,,,\n2,,,,,Chepalungu,,,,Bomet Central,,,\n3,,,,,Male,,Female,,Male,,Female,\n4,,,N,%,N,%,N,%,N,%,N,%\n```", "```py\ndef pad_merged_cells(sheet):\n    \"\"\"\n    Unmerge merged cells and fill with merged value.\n\n    Input Parameters\n    ----------------\n    sheet: Obj\n        Openpyxl sheet object\n\n    Output Parameters\n    -----------------\n    df: Dataframe\n        Pandas dataframe of the table\n    \"\"\"\n\n    dd = pd.DataFrame(sheet.values)\n\n    # Scan for maxn rows\n    maxn = 10\n\n    hasmerged = False\n    if len(sheet.merged_cells.ranges) > 0:\n        hasmerged = True\n\n    if hasmerged:\n        merge_list = []\n        for merge in sheet.merged_cells.ranges:\n            merge_list.append(merge)\n\n        for cell_group in merge_list:\n            min_col, min_row, max_col, max_row = range_boundaries(\n                str(cell_group))\n            top_left_cell_value = sheet.cell(row=min_row, column=min_col).value\n            sheet.unmerge_cells(str(cell_group))\n            for row in sheet.iter_rows(\n                min_col=min_col, min_row=min_row, max_col=max_col, max_row=max_row\n            ):\n                for cell in row:\n                    cell.value = top_left_cell_value\n\n    # Extract data and save to dataframe\n    data = []\n    for row in sheet.iter_rows(min_row=1):\n        row_data = []\n        for cell in row:\n            if cell.value is None:\n                row_data.append(None)\n            else:\n                row_data.append(cell.value)\n        if any(row_data):\n            data.append(row_data)\n\n    df = pd.DataFrame(data)\n\n    # Remove duplicate columns\n    df = df.T.drop_duplicates().T\n\n    # Remove duplicate rows\n    df = df.drop_duplicates()\n\n    # Fill NaN with blank string for easier viewing\n    df = df.fillna(\"\")\n\n    return df, sheet, hasmerged\n\nwb = openpyxl.load_workbook(filename)\nsheet = wb['Sheet1']\nmerged_table, sheet, hasmerged = pad_merged_cells(sheet)\n\ndisplay(merged_table)\n```", "```py\n,Table 3: Number of acreage under irrigation,,,,,,,,,,,\n1,,,OVERALL,OVERALL,Sub county,Sub county,Sub county,Sub county,Sub county,Sub county,Sub county,Sub county\n2,,,OVERALL,OVERALL,Chepalungu,Chepalungu,Chepalungu,Chepalungu,Bomet Central,Bomet Central,Bomet Central,Bomet Central\n3,,,OVERALL,OVERALL,Male,Male,Female,Female,Male,Male,Female,Female\n4,,,N,%,N,%,N,%,N,%,N,%\n5,What is the average size of land you own that is currently under irrigation?,0 - 2 acres,22,2.8%,4,2.2%,10,3.8%,3,1.7%,5,2.9%\n6,What is the average size of land you own that is currently under irrigation?,2 - 5 acres,6,.8%,2,1.1%,2,.8%,0,0.0%,2,1.2%\n7,What is the average size of land you own that is currently under irrigation?,5 - 10 acres,1,.1%,0,0.0%,0,0.0%,0,0.0%,1,.6%\n8,What is the average size of land you own that is currently under irrigation?,More than 10 acres,0,0.0%,0,0.0%,0,0.0%,0,0.0%,0,0.0%\n9,What is the average size of land you own that is currently under irrigation?,None,760,96.3%,176,96.7%,251,95.4%,170,98.3%,163,95.3%\n10,What is the average size of land you own that is currently under irrigation?,Total,789,100.0%,182,100.0%,263,100.0%,173,100.0%,171,100.0%\n```", "```py\ncsv_as_str_merged = merged_table.to_csv()\n\nprompt = (\n    \"Reformat this table to be a simpler markdown table with \"\n    + \"no hierarchical columns, no pivoting, values and percentages in different columns, \"\n    + \"and no blank cells\\n\\n\"\n    + csv_as_str_merged\n)\n\ncompletions = ai.Completion.create(\n    engine=\"text-davinci-003\",\n    temperature=0.0,\n    prompt=prompt,\n    max_tokens=999,\n    n=1,\n    stop=None,\n)\n\nMarkdown(completions.choices[0].text)\n```", "```py\nfrom io import StringIO\n\nwb = openpyxl.load_workbook(prompt_sample_table1, data_only=True)\nsheet = wb[\"Sheet1\"]\nexample_before, sheet, hasmerged = pad_merged_cells(sheet)\nexample_before_csv = example_before.to_csv()\nexample_after, hasmerged, report = parse_excel_sheet(sheet)\nexample_after_markdown = example_after.to_markdown()\nexample_after_csv = example_after.to_csv()\n\nexample_before_csv = \"\"\"\n ,0,1,2,3,4,5,6,7\n0,Table 16: % of infants on Minimum Dietary Diversity,,,,,,,\n1,,,OVERALL,OVERALL,Sub county,Sub county,Sub county,Sub county\n2,,,OVERALL,OVERALL,Chepalungu,Chepalungu,Bomet Central,Bomet Central\n3,,,N,%,n,%,n,%\n4,Infants         on Dietary Diversity,Infants  on  Minimum  Dietary Diversity,37,17.5%,24,17.9%,13,16.7%\n5,Infants         on Dietary Diversity,Infants not on Dietary Diversity,175,82.5%,110,82.1%,65,83.3%\n6,Infants         on Dietary Diversity,Total,212,100.0%,134,100.0%,78,100.0%\n\"\"\"\n\nexample_after_markdown = (\n    \"\"\"\n |    |                                      |                                         |   OVERALL - N | OVERALL - %   |   Sub county - Chepalungu | Sub county - Chepalungu - %   |   Sub county - Bomet Central | Sub county - Bomet Central - %   |\n|---:|:-------------------------------------|:----------------------------------------|--------------:|:--------------|--------------------------:|:------------------------------|-----------------------------:|:---------------------------------|\n|  1 | Infants         on Dietary Diversity | Infants  on  Minimum  Dietary Diversity |            37 | 17.5%         |                        24 | 17.9%                         |                           13 | 16.7%                            |\n|  2 | Infants         on Dietary Diversity | Infants not on Dietary Diversity        |           175 | 82.5%         |                       110 | 82.1%                         |                           65 | 83.3%                            |\n|  3 | Infants         on Dietary Diversity | Total                                   |           212 | 100.0%        |                       134 | 100.0%                        |                           78 | 100.0%                           |\n\"\"\".replace(\n        \":|\", \"|\"\n    )\n    .replace(\"|:\", \"|\")\n    .replace(\"\\n\", \"\\n<RETURN>\")\n)\n\nexample_after_csv = \"\"\"\n , , ,OVERALL - N,OVERALL - %,Sub county - Chepalungu,Sub county - Chepalungu - %,Sub county - Bomet Central,Sub county - Bomet Central - %\n1,Infants         on Dietary Diversity,Infants  on  Minimum  Dietary Diversity,37,17.5%,24,17.9%,13,16.7%\n2,Infants         on Dietary Diversity,Infants not on Dietary Diversity,175,82.5%,110,82.1%,65,83.3%\n3,Infants         on Dietary Diversity,Total,212,100.0%,134,100.0%,78,100.0%\n\"\"\"\n\ntable_to_parse_padded = \"\"\"\n,0,1,2,3,4,5,6,7,8,9,10,11\n0,Table 3: Number of acreage under irrigation,,,,,,,,,,,\n1,,,OVERALL,OVERALL,Sub county,Sub county,Sub county,Sub county,Sub county,Sub county,Sub county,Sub county\n2,,,OVERALL,OVERALL,Chepalungu,Chepalungu,Chepalungu,Chepalungu,Bomet Central,Bomet Central,Bomet Central,Bomet Central\n3,,,OVERALL,OVERALL,Male,Male,Female,Female,Male,Male,Female,Female\n4,,,N,%,N,%,N,%,N,%,N,%\n5,What is the average size of land you own that is currently under irrigation?,0 - 2 acres,22,2.8%,4,2.2%,10,3.8%,3,1.7%,5,2.9%\n6,What is the average size of land you own that is currently under irrigation?,2 - 5 acres,6,.8%,2,1.1%,2,.8%,0,0.0%,2,1.2%\n7,What is the average size of land you own that is currently under irrigation?,5 - 10 acres,1,.1%,0,0.0%,0,0.0%,0,0.0%,1,.6%\n8,What is the average size of land you own that is currently under irrigation?,More than 10 acres,0,0.0%,0,0.0%,0,0.0%,0,0.0%,0,0.0%\n9,What is the average size of land you own that is currently under irrigation?,None,760,96.3%,176,96.7%,251,95.4%,170,98.3%,163,95.3%\n10,What is the average size of land you own that is currently under irrigation?,Total,789,100.0%,182,100.0%,263,100.0%,173,100.0%,171,100.0%\n\"\"\"\n\nprompt = (\n    \"Reformat this table to only have a single header row: \\n\\n\"\n    + example_before_csv\n    + \"\\n\\n\"\n    + \"Result: \\n\\n\"\n    + example_after_csv\n    + \"\\n\\n\"\n    + \"Reformat this table to only have a single header row: \\n\\n\"\n    + table_to_parse_padded\n    + \"\\n\\n\"\n    + \"Result: \\n\\n\"\n)\n\nprint(\"\\n\\n\", prompt, \"\\n\\n\")\n\ncompletions = ai.Completion.create(\n    engine=\"text-davinci-003\",\n    temperature=0.0,\n    prompt=prompt,\n    n=1,\n    stop=None,\n    max_tokens=2068,\n    top_p=1,\n    frequency_penalty=0,\n    presence_penalty=0,\n)\n\nprint(\"\\n========== Model prediction:\\n\")\n\ndisplay(pd.read_csv(StringIO(completions.choices[0].text)))\n```", "```py\nReformat this table to only have a single header row: \n\n ,0,1,2,3,4,5,6,7\n0,Table 16: % of infants on Minimum Dietary Diversity,,,,,,,\n1,,,OVERALL,OVERALL,Sub county,Sub county,Sub county,Sub county\n2,,,OVERALL,OVERALL,Chepalungu,Chepalungu,Bomet Central,Bomet Central\n3,,,N,%,n,%,n,%\n4,Infants         on Dietary Diversity,Infants  on  Minimum  Dietary Diversity,37,17.5%,24,17.9%,13,16.7%\n5,Infants         on Dietary Diversity,Infants not on Dietary Diversity,175,82.5%,110,82.1%,65,83.3%\n6,Infants         on Dietary Diversity,Total,212,100.0%,134,100.0%,78,100.0%\n\nResult: \n\n , , ,OVERALL - N,OVERALL - %,Sub county - Chepalungu,Sub county - Chepalungu - %,Sub county - Bomet Central,Sub county - Bomet Central - %\n1,Infants         on Dietary Diversity,Infants  on  Minimum  Dietary Diversity,37,17.5%,24,17.9%,13,16.7%\n2,Infants         on Dietary Diversity,Infants not on Dietary Diversity,175,82.5%,110,82.1%,65,83.3%\n3,Infants         on Dietary Diversity,Total,212,100.0%,134,100.0%,78,100.0%\n\nReformat this table to only have a single header row: \n\n,0,1,2,3,4,5,6,7,8,9,10,11\n0,Table 3: Number of acreage under irrigation,,,,,,,,,,,\n1,,,OVERALL,OVERALL,Sub county,Sub county,Sub county,Sub county,Sub county,Sub county,Sub county,Sub county\n2,,,OVERALL,OVERALL,Chepalungu,Chepalungu,Chepalungu,Chepalungu,Bomet Central,Bomet Central,Bomet Central,Bomet Central\n3,,,OVERALL,OVERALL,Male,Male,Female,Female,Male,Male,Female,Female\n4,,,N,%,N,%,N,%,N,%,N,%\n5,What is the average size of land you own that is currently under irrigation?,0 - 2 acres,22,2.8%,4,2.2%,10,3.8%,3,1.7%,5,2.9%\n6,What is the average size of land you own that is currently under irrigation?,2 - 5 acres,6,.8%,2,1.1%,2,.8%,0,0.0%,2,1.2%\n7,What is the average size of land you own that is currently under irrigation?,5 - 10 acres,1,.1%,0,0.0%,0,0.0%,0,0.0%,1,.6%\n8,What is the average size of land you own that is currently under irrigation?,More than 10 acres,0,0.0%,0,0.0%,0,0.0%,0,0.0%,0,0.0%\n9,What is the average size of land you own that is currently under irrigation?,None,760,96.3%,176,96.7%,251,95.4%,170,98.3%,163,95.3%\n10,What is the average size of land you own that is currently under irrigation?,Total,789,100.0%,182,100.0%,263,100.0%,173,100.0%,171,100.0%\n\nResult: \n```", "```py\nprompt = (\n    \"We need to reformat this table to only have a single header row: \\n\\n\"\n    + example_before_csv\n    + \"\\n\"\n    + \"Let's think step by step \\n\"\n    + \"Row 1 is just an index row, it has no text or data \\n\"\n    + \"Row 2 contains just label text \\n\"\n    + \"Rows 3 to 5 contain column headers \\n\"\n    + \"Rows 6 onwards contain data \\n\"\n    + \"Columns are separated by commas, there should be 7 commas on each row \\n\"\n    + \"If we combine each colummn of rows 3 to 5 by concatenating vertically, we get \\n\"\n    + example_after_csv\n    + \"\\n\\n\"\n    + \"We need to reformat this table to only have a single header row: \\n\\n\"\n    + table_to_parse_padded\n    + \"\\n\\n\"\n    + \"Let's think step by step \\n\\n\"\n)\n```", "```py\nWe need to reformat this table to only have a single header row: \n\n ,0,1,2,3,4,5,6,7\n0,Table 16: % of infants on Minimum Dietary Diversity,,,,,,,\n1,,,OVERALL,OVERALL,Sub county,Sub county,Sub county,Sub county\n2,,,OVERALL,OVERALL,Chepalungu,Chepalungu,Bomet Central,Bomet Central\n3,,,N,%,n,%,n,%\n4,Infants         on Dietary Diversity,Infants  on  Minimum  Dietary Diversity,37,17.5%,24,17.9%,13,16.7%\n5,Infants         on Dietary Diversity,Infants not on Dietary Diversity,175,82.5%,110,82.1%,65,83.3%\n6,Infants         on Dietary Diversity,Total,212,100.0%,134,100.0%,78,100.0%\n\nLet's think step by step \nRow 1 is just an index row, it has no text or data \nRow 2 contains just label text \nRows 3 to 5 contain column headers \nRows 6 onwards contain data \nColumns are separated by commas, there should be 7 commas on each row \nIf we combine each colummn of rows 3 to 5 by concatenating vertically, we get \n\n , , ,OVERALL - N,OVERALL - %,Sub county - Chepalungu - N,Sub county - Chepalungu - %,Sub county - Bomet Central - N,Sub county - Bomet Central - %\n1,Infants         on Dietary Diversity,Infants  on  Minimum  Dietary Diversity,37,17.5%,24,17.9%,13,16.7%\n2,Infants         on Dietary Diversity,Infants not on Dietary Diversity,175,82.5%,110,82.1%,65,83.3%\n3,Infants         on Dietary Diversity,Total,212,100.0%,134,100.0%,78,100.0%\n\nWe need to reformat this table to only have a single header row: \n\n,0,1,2,3,4,5\n0,Random text here,,,,,\n1,,Cows,Cows,Cowboy Hats,Cowboy Hats,Cowboy Hats\n2,,TOT,Farm,Small ,Medium,Large\n3,,97,6666,0.65,,0.13\n4,,93,Bar M,,0.2,\n5,,140,Daisy,0.3,0.89,\n6,,,Plew,0.2,0.5,0.1\n7,,119,Birdie,0.2,0.1,\n8,,29,Kit Kat,,0.55,\n\nLet's think step by step \n```", "```py\nRow 1 is just an index row, it has no text or data \nRow 2 contains just label text \nRows 3 to 8 contain column headers \nRows 9 onwards contain data \nColumns are separated by commas, there should be 6 commas on each row \nIf we combine each colummn of rows 3 to 8 by concatenating vertically, we get \n\n , ,Cows - TOT,Cows - Farm,Cowboy Hats - Small ,Cowboy Hats - Medium,Cowboy Hats - Large\n1,,97,6666,0.65,,0.13\n2,,93,Bar M,,0.2,\n3,,140,Daisy,0.3,0.89,\n4,,,Plew,0.2,0.5,0.1\n5,,119,Birdie,0.2,0.1,\n6,,29,Kit Kat,,0.55,\n```", "```py\nimport openpyxl\n\ndef get_sheet_attributes(sheet, maxn):\n    \"\"\"\n    Returns a set of table attributes for a given sheet\n\n    Input Parameters:\n        sheet: Obj\n            Openpyxl sheet object\n        maxn: int\n            Number of rows to scan at start of sheet\n\n    Returns:\n        null_cells_in_rows: list of ints\n            Count of NULL records in forst maxn rows\n        float_cells_in_rows: list of ints\n            Count of numeric records in first maxn rows\n        unique_vals_in_rows: list of ints\n            Count of unique values in first maxn rows\n        year_vals_in_rows: list of ints\n            Count of year values in first maxn rows\n        hxl_row: int\n            Row number of HXL header row\n        first_float_row: int\n            Row number of row with most numeric records\n        first_not_null_row: int\n            Row number of row with most non-null records\n\n    \"\"\"\n    dd = pd.DataFrame(sheet.values)\n\n    null_cells_in_rows = list(\n        dd[0:maxn].apply(lambda x: x.isnull().sum(), axis=\"columns\")\n    )\n    float_cells_in_rows = []\n    unique_vals_in_rows = []\n    year_vals_in_rows = []\n    report_json = {}\n    hxl_row = None\n    for index, row in dd[0:maxn].iterrows():\n        unique_vals = list(row.unique())\n        unique_vals = [i for i in unique_vals if i is not None and str(i) != \"nan\"]\n        unique_vals_in_rows.append(len(unique_vals))\n        float_count = 0\n        year_count = 0\n        if check_hdx_header(list(row)):\n            hxl_row = index\n        for col in dd.columns:\n            val = row[col]\n            # Handle numbers that come through as strings\n            if isinstance(val, str):\n                val = val.replace(\",\", \"\").replace(\" \", \"\")\n                if val.isnumeric():\n                    val = int(val)\n            # Check for year values\n            if (\n                ((isinstance(val, int) or isinstance(val, float)) and val % 1 == 0)\n                and val > 1900\n                and val < 2100\n            ):\n                year_count += 1\n                continue\n            # Check for HXL tags\n            if isinstance(val, float) or isinstance(val, int) or \"^=\" in str(row[col]):\n                float_count += 1\n        float_cells_in_rows.append(float_count)\n        year_vals_in_rows.append(year_count)\n\n    max_floats = max(float_cells_in_rows)\n    min_nulls = min(null_cells_in_rows)\n    first_float_row = 0\n    if sum(float_cells_in_rows) > 0:\n        for i in range(1, len(float_cells_in_rows)):\n            # Use a ratio or special case where we go from zero to some\n            if float_cells_in_rows[i] / max_floats > 0.5 or (\n                float_cells_in_rows[i] > 0 and float_cells_in_rows[i - 1] == 0\n            ):\n                first_float_row = i\n                break\n    first_not_null_row = np.argmin(null_cells_in_rows)\n\n    report = f\"Nulls in first {maxn} rows: {str(null_cells_in_rows)}\\n\"\n    report += f\"Numeric first {maxn} rows: {str(float_cells_in_rows)}\\n\"\n    report += f\"Unique values in first {maxn} rows: {str(unique_vals_in_rows)}\\n\"\n    report += f\"Year values in first {maxn} rows: {str(year_vals_in_rows)}\\n\"\n    report += f\"HXL row: {str(hxl_row)}\\n\"\n\n    report += f\"\\nFirst reduced nulls row: {str(first_not_null_row)}\\n\"\n    report += f\"First increased numeric row (excluding years): {str(first_float_row)}\\n\"\n\n    report_json = {\n        \"null_cells_in_rows\": null_cells_in_rows,\n        \"float_cells_in_rows\": float_cells_in_rows,\n        \"unique_vals_in_rows\": unique_vals_in_rows,\n        \"year_vals_in_rows\": year_vals_in_rows,\n        \"hxl_row\": hxl_row,\n        \"first_float_row\": first_float_row,\n        \"first_not_null_row\": first_not_null_row,\n    }\n\n    return report, report_json\n\nwb = openpyxl.load_workbook(filename, data_only=True)\nfor s in wb.sheetnames:\n    sheet = wb[s]\n    report, report_json = get_sheet_attributes(sheet, maxn)\n    print(report) \n```", "```py\nNulls in first 10 rows: [12, 11, 10, 10, 8, 2, 0, 1, 1, 1]\nNumeric first 10 rows: [0, 0, 0, 0, 0, 0, 5, 5, 5, 5]\nUnique values in first 10 rows: [0, 1, 2, 2, 2, 2, 12, 8, 6, 3]\nYear values in first 10 rows: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nHXL row: None\n\nFirst reduced nulls row: 6\nFirst increased numeric row (excluding years): 6\n```", "```py\n# Make a guess at which row is the data row\ndatarow = max_not_null_row\n# Sometimes we have header rows where none are null, in this case we want to use the row with the most floats\nif max_float_row > datarow:\n    datarow = max_float_row\n# HXL row is always the row before the data row\nif hxl_row is not None:\n    datarow = hxl_row\n# If we a row with a lot of year values below datarow, use that\nif year_vals_in_rows[datarow] > 3:\n    datarow = datarow + 1\n```", "```py\n{\"prompt\": \"Nulls in first 15 rows: [9, 8, 7, 7, 3, 1, 2, 2, 2, 2, 2]\\nNumeric first 15 rows: [0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3]\\nUnique values in first 15 rows: [0, 1, 2, 2, 3, 8, 7, 7, 6, 6, 5]\\nYear values in first 15 rows: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\\nHXL row: None\\nFirst reduced nulls row: 5\\nFirst increased numeric row (excluding years): 5\", \"completion\": \"Data starts at row: 5\\n\", \"meta_data\": \"./data/Kenya/kenya-hand-washing-statistics-in-bomet-county_118ea93f-83ce-4b86-b1c4-ca54ea9acc8a/Hand_washing_practices_xlsx_efc74f32_ac23_463a_924b_d53c3656b406/Hand washing practices.xlsx\"}\n{\"prompt\": \"Nulls in first 15 rows: [2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1]\\nNumeric first 15 rows: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\\nUnique values in first 15 rows: [0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1]\\nYear values in first 15 rows: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\\nHXL row: None\\nFirst reduced nulls row: 1\\nFirst increased numeric row (excluding years): 0\", \"completion\": \"Data starts at row: 1\\n\", \"meta_data\": \"./data/Kenya/shcchealthcare-dataset_02995168-3644-4b78-92be-cdf67275b39d/2018_SHCC_Overview_Data_xlsx_d053b42a_7d31_41b5_a6d9_c8b0a424241c/2018 SHCC Overview Data.xlsx\"}\n{\"prompt\": \"Nulls in first 15 rows: [6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 7, 6, 3]\\nNumeric first 15 rows: [0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 0, 0, 0]\\nUnique values in first 15 rows: [1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 0, 1, 4]\\nYear values in first 15 rows: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\\nHXL row: None\\nFirst reduced nulls row: 1\\nFirst increased numeric row (excluding years): 2\", \"completion\": \"Data starts at row: 2\\n\", \"meta_data\": \"./data/Kenya/eastern-southern-africa-refugees-and-idps-situation-and-response-dec2019_e1f9f55e-08db-4166-a787-c7ea9969dc4d/UNICEF_ESARO_Regional_refugee_and_idp_db_2019_November_27_2019_xlsx_0696b7f3_6368_403e_bcb7_eccdc617961f/UNICEF ESARO Regional refugee and idp db 2019 November 27.2019.xlsx\"}\n```", "```py\n ai.api_key_path=\"./api_key.txt\"\n\ntrain_file = './prompts.json'\n\nprint(\"Uploading training file ...\")\ntraining_id = cli.FineTune._get_or_upload(train_file, True)\n\nprint(\"Fine-tuning model ...\")\ncreate_args = {\n    \"training_file\": training_id,\n    \"model\": \"davinci\"\n}\nresp = ai.FineTune.create(**create_args)\njob_id = resp[\"id\"]\nstatus = resp[\"status\"]\n\nprint(f'Fine-tunning model with jobID: {job_id}.')\n```", "```py\nai.api_key_path=\"./api_key.txt\"\nresult = ai.FineTune.retrieve(id=job_id)\n\nprint(result['status'])\n```", "```py\nmodel = result[\"fine_tuned_model\"]\n```", "```py\n def make_gpt3_prediction(prompt, model, temperature=0.99, max_tokens=13):\n    \"\"\"\n    Wrapper to call GPT-3 to make a prediction (completion) on a single prompt.\n    Also calls post_process() to clean up the prediction.\n\n    Parameters\n    ----------\n    prompt : str\n        Prompt to use for prediction\n    model : str\n        GPT-3 model to use\n    temperature : float\n        Temperature to use for sampling\n    max_tokens : int\n        Maximum number of tokens to use for sampling\n\n    Returns\n    -------\n    result : dict\n        Dictionary with prompt, predicted, predicted_post_processed\n    \"\"\"\n    result = {}\n    result[\"prompt\"] = prompt\n    model_result = ai.Completion.create(\n        engine=model,\n        prompt=prompt,\n        temperature=temperature,\n        max_tokens=max_tokens,\n        top_p=1,\n        frequency_penalty=0,\n        presence_penalty=0,\n        stop=[\"\\n\"],\n        logprobs=1,\n    )\n    result[\"predicted\"] = model_result[\"choices\"][0][\"text\"].replace(\" \", \"\")\n    result[\"logprobs\"] = model_result[\"choices\"][0][\"logprobs\"][\"top_logprobs\"]\n    return result\n\ndef output_prediction_metrics(results, prediction_field=\"predicted_post_processed\"):\n    \"\"\"\n    Prints out model performance report if provided results in the format:\n\n    [\n        {\n            'prompt': ' \\'ISO3\\' | \"[\\'RWA\\', \\'RWA\\', \\'RWA\\', \\'RWA\\', \\'RWA\\', \\'RWA\\', \\'RWA\\', \\'RWA\\']\"',\n            'predicted': ' #country+code+iso3+v_iso3+',\n            'expected': '#country+code'\n        },\n        ... etc ...\n    ]\n\n    Parameters\n    ----------\n    results : list\n        See above for format\n    prediction_field : str\n        Field name of element with prediction. Handy for comparing raw and post-processed predictions.\n    \"\"\"\n    y_test = []\n    y_pred = []\n    for r in results:\n        if \"expected\" not in r:\n            print(\"Provided results do not contain expected values.\")\n            sys.exit()\n        y_pred.append(r[prediction_field])\n        y_test.append(r[\"expected\"])\n\n    print(f\"There were {len(y_test)} predictions made.\")\n    print(f\"\\nPrediction using field {prediction_field} ...\\n\")\n    print(f\"Accuracy: {round(accuracy_score(y_test, y_pred),2)}\")\n    print(\n        f\"Precision: {round(precision_score(y_test, y_pred, average='weighted', zero_division=0),2)}\"\n    )\n    print(\n        f\"Recall: {round(recall_score(y_test, y_pred, average='weighted', zero_division=0),2)}\"\n    )\n    print(\n        f\"F1: {round(f1_score(y_test, y_pred, average='weighted', zero_division=0),2)}\"\n    )\n\n# File generated by downloading and processing HDX files. See this blog post\n# for more details: https://medium.com/towards-data-science/predicting-metadata-for-humanitarian-datasets-using-gpt-3-b104be17716d\ncountry='Kenya'\nresources = pd.read_pickle(hdx_resources_pkl_file)\n\ndf = resources[(resources[\"resource_format\"]=='XLSX')][[\"resource_format\",\"file\",\"sheet\",\"dataset_name\",\"dataset_org_title\"]]\ndf.drop_duplicates(inplace=True)\norgs = df[\"dataset_org_title\"].unique()\n\n# Number of rows to use when calculating table row parameters\nmaxn = 15\n\n# Determine test/train split, 0:10 used for training, 11:len(orgs) for test\ndataset_orgs_cutoff = 10\n\nfor dataset_org in orgs[dataset_orgs_cutoff: len(orgs)]:\n    rows = df.loc[df['dataset_org_title']== dataset_org]\n    row = rows.iloc[0]  # Take one sheet from each org to get more variation\n    filename = row[\"file\"]\n    sheetname = row[\"sheet\"]\n\n    wb = openpyxl.load_workbook(filename, data_only=True)\n    for s in wb.sheetnames:\n        sheet = wb[s]\n\n        # Extract table attributes \n        report = get_sheet_attributes(sheet, maxn)\n\n        report_elements = report.split('\\n\\n')\n        prompt = report_elements[0] + report_elements[1]\n        completion = report_elements[2]\n\n        # Make our GPT-3 prediction\n        res = make_gpt3_prediction(prompt, model, temperature=0.0)\n\n        predicted = res[\"predicted\"].split(':')[1].strip()\n        actual = completion.split(':')[1].strip()\n\n        results.append({\n            \"prompt\": prompt,\n            \"predicted\": predicted,\n            \"expected\": actual\n        })\n\noutput_prediction_metrics(results, prediction_field=\"predicted\")\n```", "```py\nPrediction using field predicted ...\n\nAccuracy: 0.97\nPrecision: 1.0\nRecall: 0.97\nF1: 0.99\n```", "```py\nNulls in first 10 rows: [20, 20, 20, 21, 10, 8, 19, 9, 21, 0]\nNumeric first 10 rows: [0, 0, 0, 0, 0, 0, 0, 0, 0, 14]\nUnique values in first 10 rows: [1, 1, 1, 0, 11, 13, 2, 4, 0, 21]\nYear values in first 10 rows: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\nHXL row: None\n\nFirst reduced nulls row: 9\nFirst increased numeric row (excluding years): 9\n```", "```py\nGPT-3 prediction: 9\n```"]