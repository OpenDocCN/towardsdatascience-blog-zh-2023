- en: Build low-latency and scalable ML model prediction pipelines using Spark Structured
    Streaming and MLflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/build-low-latency-and-scalable-ml-model-prediction-pipelines-using-spark-structured-streaming-and-535ae5244877?source=collection_archive---------23-----------------------#2023-01-10](https://towardsdatascience.com/build-low-latency-and-scalable-ml-model-prediction-pipelines-using-spark-structured-streaming-and-535ae5244877?source=collection_archive---------23-----------------------#2023-01-10)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: MLOps in practice series — sharing design and implementation patterns of critical
    MLOps component. The focus of today’s article is on building model prediction
    pipelines.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@weiyunna91?source=post_page-----535ae5244877--------------------------------)[![YUNNA
    WEI](../Images/ffd0dd5c697dd2b4640ade49274d2bf9.png)](https://medium.com/@weiyunna91?source=post_page-----535ae5244877--------------------------------)[](https://towardsdatascience.com/?source=post_page-----535ae5244877--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----535ae5244877--------------------------------)
    [YUNNA WEI](https://medium.com/@weiyunna91?source=post_page-----535ae5244877--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4b47aa84fc4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-low-latency-and-scalable-ml-model-prediction-pipelines-using-spark-structured-streaming-and-535ae5244877&user=YUNNA+WEI&userId=4b47aa84fc4&source=post_page-4b47aa84fc4----535ae5244877---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----535ae5244877--------------------------------)
    ·8 min read·Jan 10, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F535ae5244877&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-low-latency-and-scalable-ml-model-prediction-pipelines-using-spark-structured-streaming-and-535ae5244877&user=YUNNA+WEI&userId=4b47aa84fc4&source=-----535ae5244877---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F535ae5244877&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-low-latency-and-scalable-ml-model-prediction-pipelines-using-spark-structured-streaming-and-535ae5244877&source=-----535ae5244877---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: 'To make ML models work in a real production environment, one of the most critical
    steps is to deploy the trained models for predictions. Model deployment (release)
    is a process that enables you to integrate trained ML models into production to
    make decisions on real-world data. When it comes to model deployment, there are
    generally two types:'
  prefs: []
  type: TYPE_NORMAL
- en: One is batch prediction where the trained models are called and fed with a batch
    of data at a certain interval (such as once per day or once per week depending
    on how the models are used in certain business contexts), to periodically generate
    predictions for use.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The other is online prediction where a trained model is packaged as a REST API
    or a containerized microservice, and the model returns prediction results (generally
    in JSON format) by responding to an API request. With online prediction, the model
    makes predictions in real-time, meaning, as soon as the API is called, a model
    prediction result will be returned. Additionally the model REST API is generally
    integrated as part of a web application for end users or downstream applications
    to interact with.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
