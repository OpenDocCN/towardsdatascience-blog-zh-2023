- en: 'Linear programming: Theory and applications'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/linear-programming-theory-and-applications-c67600591612?source=collection_archive---------3-----------------------#2023-04-05](https://towardsdatascience.com/linear-programming-theory-and-applications-c67600591612?source=collection_archive---------3-----------------------#2023-04-05)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Linear optimization main concepts and implementation in Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@bruscalia12?source=post_page-----c67600591612--------------------------------)[![Bruno
    Scalia C. F. Leite](../Images/1042cd04be047c0811fef79ecd04e69c.png)](https://medium.com/@bruscalia12?source=post_page-----c67600591612--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c67600591612--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c67600591612--------------------------------)
    [Bruno Scalia C. F. Leite](https://medium.com/@bruscalia12?source=post_page-----c67600591612--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3ce9b7482ef0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-programming-theory-and-applications-c67600591612&user=Bruno+Scalia+C.+F.+Leite&userId=3ce9b7482ef0&source=post_page-3ce9b7482ef0----c67600591612---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c67600591612--------------------------------)
    ·13 min read·Apr 5, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc67600591612&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-programming-theory-and-applications-c67600591612&user=Bruno+Scalia+C.+F.+Leite&userId=3ce9b7482ef0&source=-----c67600591612---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc67600591612&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-programming-theory-and-applications-c67600591612&source=-----c67600591612---------------------bookmark_footer-----------)![](../Images/fffd9350e61f068983fceb5a4c5e2a3d.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Patrick Fore](https://unsplash.com/@patrickian4?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'Numerical optimization is a fundamental tool in quantitative decision-making
    processes. To optimize a given goal, one must select values for interrelated decision
    variables under some prescribed set of circumstances. The format of the mathematical
    equations that describe the objective and the constraints of the problem is used
    to distinguish optimization problems between two major categories: *Linear* and
    *Nonlinear Programming*.'
  prefs: []
  type: TYPE_NORMAL
- en: Management sciences and operations research make extensive use of linear models,
    whereas nonlinear programming problems tend to arise naturally in the physical
    sciences and engineering (Nocedal & Wright, 2006). In linear problems, as the
    name suggests, the objective(s) and constraints are described by linear functions
    only, which will be the focus of the current article.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this article, some of the main theoretical aspects of linear programming
    will be covered, besides applications in classical problems using Python. To do
    this, we will use the libraries *scipy* and *pyomo* (Bynum et al., 2021).
  prefs: []
  type: TYPE_NORMAL
- en: 'You may find here a short summary of the remainder of this text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Problem statement](#d73a)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Feasible space and solution techniques](#d77c)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The product mix problem](#71af)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The transportation problem](#0f73)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Further reading](#0b54)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Conclusions](#cd50)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[References](#30f1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can find the complete code in this [GIT repository](https://github.com/bruscalia/optimization-demo-files/tree/main/convex/linear).
    Now enjoy the ride!
  prefs: []
  type: TYPE_NORMAL
- en: Problem statement
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When formulating an optimization problem, one must define an objective that
    is a function of a vector decision variables ***x*** and might be subject to some
    equality and inequality constraints, which are functions of ***x*** as well. The
    objective can be defined either in a *minimization* or *maximization* sense although
    the former is the most usual. Notice that by simply multiplying the coefficients
    *cᵢ* of a *maximization* objective, it can be re-formulated in a *minimization*
    sense.
  prefs: []
  type: TYPE_NORMAL
- en: In linear problems, the decision variable space must be limited somehow. Otherwise,
    decision variables would converge to positive or negative infinity values according
    to the objective function. Constraints might be formulated by either equality
    or inequality relationships. They are usually stated as rows in the problem matrix.
    Let us distinguish the matrix of equality constraints ***A****_eq* from the matrix
    of inequality constraints ***A****_ub*.
  prefs: []
  type: TYPE_NORMAL
- en: Lower and upper boundaries for each component of ***x*** might be explicit in
    the formulation, which reduces the search space. As a convention, due to solution
    techniques, usually lower bounds for decision variables are by default equal to
    zero. This leads to a general problem formulation such as the following.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/780119ebdaf4f617198f9c3b300f7ccb.png)'
  prefs: []
  type: TYPE_IMG
- en: Linear problem in generic formulation. (Image by the author).
  prefs: []
  type: TYPE_NORMAL
- en: Inequality constraints might be re-formulated as equality constraints by adding
    non-negative slack variables. If this occurs and all decision variables are stated
    non-negative, we say the linear program is in the *standard form*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b628705c02b1b81c3f0b719f6c064edf.png)'
  prefs: []
  type: TYPE_IMG
- en: Inequality constraint re-formulated as equality by including a nonnegative slack
    variable. (Image by the author).
  prefs: []
  type: TYPE_NORMAL
- en: And can then be stated as the following.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a6ea008be2f3e2dbeea03875d61bc0fd.png)'
  prefs: []
  type: TYPE_IMG
- en: Linear programming problem in standard form. (Image by the author).
  prefs: []
  type: TYPE_NORMAL
- en: Notice that inequalities work as equalities if their corresponding slack variables
    are equal to zero. We will dive deeper into that in the next section when discussing
    the feasible space and solution techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Feasible space and solution techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let us introduce a simple example to explore the concepts of this section.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f647840cb04341e3bb3f37cf65744ff3.png)'
  prefs: []
  type: TYPE_IMG
- en: Example problem. (Image by the author).
  prefs: []
  type: TYPE_NORMAL
- en: Which can be represented in a two-dimensional space as the following.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4589a4e4dc4d3088bd99ea5debd6fdbc.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice that in each vertice of the feasible region (colored), a subset of constraints
    is active. Moreover, observe that the optimal solution in this example lies in
    a vertice. Recall that, when inequalities are active, their corresponding slack
    variables for the problem in the *standard form* are equal to zero. In linear
    problems, we will be interested in finding which constraints are active in a vertice
    that contains the optimal solution.
  prefs: []
  type: TYPE_NORMAL
- en: A generalization for higher dimensional problems is that, if an optimal solution
    exists, the set of optimal points can be a single vertice (unique solution), an
    edge or face, or even the entire feasible set (multiple solutions). The problem
    has no solution if the feasible set is empty (the infeasible case) or if the objective
    function is unbounded on the feasible region (the unbounded case).
  prefs: []
  type: TYPE_NORMAL
- en: In a formal definition, suppose the matrix ***A*** of the problem in its *standard
    form* has full row rank. In practice, preprocessing usually is applied to remove
    some redundancies. Reformulation by adding slack, surplus, and artificial variables
    is also used to force ***A*** to satisfy this condition (Nocedal & Wright, 2006).
    If we can identify a feasible point ***x*** with at most *m* nonzero components
    and the corresponding matrix ***B*** (*m* × *m*) of the columns from ***A*** matching
    nonzero indices in ***x*** is nonsingular, ***x*** is called a *basic feasible
    point* or a *basic feasible solution*. The variables set to zero are denoted *nonbasic*
    variables, while the remaining are denoted *basic* variables.
  prefs: []
  type: TYPE_NORMAL
- en: Back to the feasible region… The feasible set defined by the linear constraints
    is a polytope (in the two-variable example provided it is a polygon). Algebraically,
    all its vertices correspond to *basic feasible points* previously described. We
    can, therefore, make a connection between the algebraic and geometric viewpoints
    of the problem and gain insight into understanding how the *simplex* method works.
  prefs: []
  type: TYPE_NORMAL
- en: 'Variants of the *simplex* method are probably the most widely used solution
    techniques of linear programming. They explore the fundamental theorem of linear
    programming (Luenberger & Ye, 2008):'
  prefs: []
  type: TYPE_NORMAL
- en: If there is a *feasible solution*, there is a *basic feasible solution*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If there is an *optimal feasible solution*, there is an *optimal basic feasible
    solution*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Thus, if an optimal solution exists, there is a vertice that contains an optimal
    solution. Aiming to find such a vertice, steps in the simplex method explore adjacent
    vertices, for which the set of basic indices differs in exactly one component
    until no further improvement is achieved. The reader interested in understanding
    better how to obtain a starting feasible point, prove the optimality of a solution,
    and how to iterate between two consecutive vertices might refer to Nocedal & Wright
    (2006) or Winston & Goldberg (2004).
  prefs: []
  type: TYPE_NORMAL
- en: Interior point methods are also widely used, especially for large linear programs.
    Interior-point methods share common features that distinguish them from the simplex
    method. Each interior-point iteration is expensive to compute and can make significant
    progress toward the solution, while the simplex method usually requires a larger
    number of inexpensive iterations (Nocedal & Wright, 2006). Some optimization solvers
    might also use variants of the simplex method to refine solutions obtained by
    interior point methods.
  prefs: []
  type: TYPE_NORMAL
- en: Both the *simplex* and *interior point* methods are represented in the figure
    below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e6d4a18764a72ed98721583ecae7ea57.png)'
  prefs: []
  type: TYPE_IMG
- en: Graphical representation of the simplex method (left) and an interior point
    method (right). (Image by the author).
  prefs: []
  type: TYPE_NORMAL
- en: Now done with some important theoretical aspects, in the next section, we will
    implement our first problem using Python. To solve it, we will first use the Python
    package *scipy* which has wrappers for the open-source solver HiGHS. Furthermore,
    we will implement the same problem using *pyomo* (Bynum et al., 2021) and solve
    it with the CBC solver. Both solvers will make use of variants of the simplex
    method to obtain their solutions.
  prefs: []
  type: TYPE_NORMAL
- en: The product mix problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the product mix problem, we must allocate limited *I* resources to produce
    *J* products maximizing expected returns. Each product *j* has a known unitary
    profit margin *cⱼ* and requires a known amount of each resource *fᵢⱼ*. Consider
    the availability of each resource *bᵢ*. Our decision variables represent how much
    of each product should be produced *xⱼ*. We can formulate the problem as the following.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fc6f2d68458a5e3fddd97a099dd637f0.png)'
  prefs: []
  type: TYPE_IMG
- en: Product mix problem. (Image by the author).
  prefs: []
  type: TYPE_NORMAL
- en: From this structure, we can easily convert the problem to a matrix form, in
    which the matrix *A_ub* has elements *fᵢⱼ* in row *i* and column *j*.
  prefs: []
  type: TYPE_NORMAL
- en: Consider an example in which we have three reactants {A, B, C} used to produce
    three products {D, E, F}. The availability of each reactant is respectively 8000,
    3000, and 2000\. The profit margin of each product is respectively 2.15, 1.34,
    1.72\. The proportions are given in the table below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Let us start implementing this problem by importing useful libraries.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: And let us instantiate *numpy* arrays to represent our parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We are almost done now. All we need to do next is to call the *scipy* function
    *linprog* to solve the problem.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: And it should return a solution with properties *fun* (the objective function)
    and *x* (the vector of decision variables).
  prefs: []
  type: TYPE_NORMAL
- en: This problem is more intuitive to formulate using matrix notation than others
    might be. For more complex problems, algebraic modeling languages (AML) can be
    very helpful. An amazing open-source alternative available in Python is *pyomo*
    (Bynum et al., 2021). So let us apply it to the product mix problem.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'There are two approaches for modeling a problem in *pyomo*: *Abstract* and
    *Concrete* models. In the first approach, the algebraic expressions of the problem
    are defined before some data values are supplied, whereas, in the second, the
    model instance is created immediately as its elements are defined. You can find
    more about these approaches in the [library documentation](https://pyomo.readthedocs.io/en/stable/pyomo_overview/abstract_concrete.html)
    or in the book by Bynum et al. (2021). Throughout this article, we will adopt
    the *Concrete* model formulation.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'In this problem there are two sets:'
  prefs: []
  type: TYPE_NORMAL
- en: Resources *I*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Products *J*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When using *pyomo* we can create these sets as modeling components, which has
    some benefits of set operations implemented. It goes as the following.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: As we are using the *ConcreteModel* approach, we must provide values for each
    component immediately when instantiating it. For sets, this is done via the *initialize*
    keyword argument.
  prefs: []
  type: TYPE_NORMAL
- en: Now let us create the fixed parameters of our model. In *pyomo,* we can use
    the *Param* class to store parameters. Parameters can be defined over sets. In
    this case, we must pass the given sets as the first arguments in the definition.
    As for other *pyomo* components, multiple sets can be passed in this statement
    if the element defined (variable, parameter, expression, or constraint) is indexed
    by more than one set. This definition is in the Python **args* style.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Now, let us instantiate the decision variables and constraints. This is done
    using the *Var* and *Constraint* components respectively. Notice that I specified
    the domain of *x* as nonnegative reals. This can be done in *pyomo* via the *within*
    keyword argument.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Observe that the constraint was instantiated passing the *rule* keyword argument.
    The rule must be a callable that receives the model as the first argument followed
    by indices of its corresponding domain.
  prefs: []
  type: TYPE_NORMAL
- en: We are almost done! Let us define the objective function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: At last, let us instantiate a solver and use it to solve our model. In this
    example, I used the open-source solver CBC. You can download CBC binaries from
    [this link](https://www.coin-or.org/download/binary/Cbc/). You can also find an
    installation tutorial [here](https://github.com/coin-or/Cbc). As the CBC executable
    is included in the PATH variable of my system, I can instantiate the solver without
    specifying the path to an executable file. If yours is not, parse the keyword
    argument “executable” with the path to your executable file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: And we are done! Now you can access any modeling component and check its values
    by using the *print* or *display* methods. As expected, the solution using *pyomo*
    and CBC returned exactly the same values as the previous one using *scipy*.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following section, let us solve another problem slightly more complex:
    the transportation problem.'
  prefs: []
  type: TYPE_NORMAL
- en: The transportation problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the transportation problem, we must match suppliers *I* of limited capacity
    *bᵢ* to a set of customers *J* to meet their known demands *dⱼ*. Each pair (*i*,
    *j*) has a known supply cost *cᵢⱼ*. Our goal is to minimize the total cost by
    defining how much of each demand is supplied by each supplier. We, therefore,
    consider decision variables *xᵢⱼ* to represent those quantities. If we consider
    conditions such that the total supply capacity meets total demand, we can formulate
    the problem as the following.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bf95121652cdd7505efabfa5f004e954.png)'
  prefs: []
  type: TYPE_IMG
- en: Transportation problem. (Image by the author).
  prefs: []
  type: TYPE_NORMAL
- en: Let us consider an example with four customers {A, B, C, D} and three suppliers
    {1, 2, 3}. The demand of each customer is respectively 5, 15, 13, and 17\. The
    capacity of each supplier is respectively 14, 26, and 11\. Now consider the following
    costs matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Let us instantiate these parameters as Python objects.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: And let us start implementing our *pyomo* model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Once again we have two sets:'
  prefs: []
  type: TYPE_NORMAL
- en: Suppliers *I*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customers *J*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And the corresponding syntax should be quite similar to the previous example.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Let us instantiate our parameters as *pyomo* components.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Our decision variables…
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: And this time we should have both equality and inequality constraints as each
    demand must be met (equality) while respecting suppliers' capacities (inequality).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Let us define the objective function and once again use CBC to solve the problem.
    Notice that this time, I defined the objective using the *expr* keyword argument,
    which receives directly a *pyomo* expression.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: And in this example, I will export my results to a *pandas* DataFrame for better
    visualization.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Which should return something like this.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: And in this scenario, all customers would be served with minimum total cost.
    But what if we had less availability of suppliers than total demand? The problem
    would then be infeasible and we would need to define which constraints should
    be violated to return some optimization result. In this problem, a simple suggestion
    would be to introduce artificial variables to meet the demands with unitary costs
    greater than those of attending from any of the original suppliers. Remember that
    the best strategy should be unique for each scenario discussed in real-world problems
    though.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For a deeper understanding of the theoretical aspects of Linear Programming,
    I strongly advise reading the related chapters in the books by Luenberger & Ye
    (2008) and Nocedal & Wright (2006). The concept of *duality* can be especially
    useful due to sensitivity analysis, an economic interpretation of the problem,
    and solution techniques (just to mention a few applications).
  prefs: []
  type: TYPE_NORMAL
- en: Operations Research makes extensive use of numerical optimization. The book
    by Winston & Goldberg (2004) can be very helpful for those interested in more
    applications of optimization besides some related sciences.
  prefs: []
  type: TYPE_NORMAL
- en: Some real-world problems include discrete variables, to formulate disjunctive
    problem aspects and integrality. I wrote a few medium articles on the subject,
    which might be helpful. See here an [introduction to branch & bound](/a-gentle-introduction-to-branch-bound-d00a4ee1cad),
    the classical [knapsack problem](https://medium.com/towards-data-science/an-introduction-to-mixed-integer-linear-programming-the-knapsack-problem-1445452a9fe9),
    and the [job-shop scheduling problem](https://medium.com/towards-data-science/the-job-shop-scheduling-problem-mixed-integer-programming-models-4bbee83d16ab).
  prefs: []
  type: TYPE_NORMAL
- en: 'Some problems also include *nonlinear* functions in either the objective or
    constraints. If that’s the case, you might want to check this other article:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/nonlinear-programming-theory-and-applications-cfe127b6060c?source=post_page-----c67600591612--------------------------------)
    [## Nonlinear programming: Theory and applications'
  prefs: []
  type: TYPE_NORMAL
- en: Gradient-based line search optimization algorithms explained in detail and implemented
    from scratch in Python
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/nonlinear-programming-theory-and-applications-cfe127b6060c?source=post_page-----c67600591612--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Throughout this article, some of the most relevant theoretical aspects of linear
    optimization have been explained in detail and illustrated with two practical
    implementation examples: the product mix and the transportation problems. The
    Python library *scipy* was used to solve the product-mix problem using matrix
    notation and both problems were modeled using the Python AML *pyomo* and solved
    using open-source solvers. The code used is entirely available for readers in
    this [GIT repository](https://github.com/bruscalia/optimization-demo-files/tree/main/convex/linear).'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Bynum, M. L. et al., 2021\. *Pyomo-optimization modeling in python.* Springer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Luenberger, D. G. & Ye, Y., 2008\. *Linear and Nonlinear Programming.* 3rd
    ed. Stanford: Springer.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Nocedal, J. & Wright, S. J., 2006\. *Numerical Optimization.* 2nd ed. New York:
    Springer New York.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Winston, W. L. & Goldberg, J. B., 2004\. *Operations research: applications
    and algorithms.* 4th ed. Belmont, CA: Thomson Brooks/Cole Belmont.'
  prefs: []
  type: TYPE_NORMAL
