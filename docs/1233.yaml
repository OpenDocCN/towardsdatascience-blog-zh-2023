- en: The Magic of LLMs — Prompt Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-magic-of-llms-prompt-engineering-9c3e46130131?source=collection_archive---------1-----------------------#2023-04-08](https://towardsdatascience.com/the-magic-of-llms-prompt-engineering-9c3e46130131?source=collection_archive---------1-----------------------#2023-04-08)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Garbage in, garbage out has never been more true.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://franklyai.medium.com/?source=post_page-----9c3e46130131--------------------------------)[![Frank
    Neugebauer](../Images/0da70d082d0f9c7ad8ccf574ed215df2.png)](https://franklyai.medium.com/?source=post_page-----9c3e46130131--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9c3e46130131--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9c3e46130131--------------------------------)
    [Frank Neugebauer](https://franklyai.medium.com/?source=post_page-----9c3e46130131--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F29e3b5503cd1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-magic-of-llms-prompt-engineering-9c3e46130131&user=Frank+Neugebauer&userId=29e3b5503cd1&source=post_page-29e3b5503cd1----9c3e46130131---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9c3e46130131--------------------------------)
    ·6 min read·Apr 8, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9c3e46130131&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-magic-of-llms-prompt-engineering-9c3e46130131&user=Frank+Neugebauer&userId=29e3b5503cd1&source=-----9c3e46130131---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c3e46130131&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-magic-of-llms-prompt-engineering-9c3e46130131&source=-----9c3e46130131---------------------bookmark_footer-----------)![](../Images/8c28b5ab704518e11aef83823349fb09.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Gary Chan](https://unsplash.com/es/@gary_at_unsplash?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Rise of the Machines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Large language models (LLMs) are able to conversationally provide an unprecedented
    level of ML-generated information when *asked the right question*. For example,
    LLMs can generate articles (no, an LLM didn’t generate this text), poetry, song
    lyrics, have a conversation with someone about a topic, interpret some types of
    documents / forms, and more. However, a seldom talked about problem with LLMs
    is that it’s not always easy to know the **right question** and without that critical
    part, LLMs can be overly accurate (i.e., too much information), inaccurate, or
    far too variable for many commercial applications.
  prefs: []
  type: TYPE_NORMAL
- en: The art of asking the right question, or **prompt engineering**, is how we overcome
    this limitation (for at least the near term) and is *the magic behind the magic*
    of LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: Shifting the Problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Without providing an overview of LLMs (written by an LLM), I want to jump right
    into an important characteristic of LLMs — they are non-deterministic; you won’t
    necessarily get the same answer to the same question every time. For example,
    if I ask Google Bard a simple question such as “What is 1 + 1”, multiple times
    in a row, here’s the unedited result:'
  prefs: []
  type: TYPE_NORMAL
