- en: Designing Conversational Agents for Multi-party Interactions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计多方交互的对话代理
- en: 原文：[https://towardsdatascience.com/designing-conversational-agents-for-multi-party-interactions-523b05ea8834?source=collection_archive---------15-----------------------#2023-04-06](https://towardsdatascience.com/designing-conversational-agents-for-multi-party-interactions-523b05ea8834?source=collection_archive---------15-----------------------#2023-04-06)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/designing-conversational-agents-for-multi-party-interactions-523b05ea8834?source=collection_archive---------15-----------------------#2023-04-06](https://towardsdatascience.com/designing-conversational-agents-for-multi-party-interactions-523b05ea8834?source=collection_archive---------15-----------------------#2023-04-06)
- en: How does one extra person impact a conversation?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多一个人如何影响对话？
- en: '[](https://addlesee.medium.com/?source=post_page-----523b05ea8834--------------------------------)[![Angus
    Addlesee](../Images/0a6a016590ca622cc3c8cae24e188f6e.png)](https://addlesee.medium.com/?source=post_page-----523b05ea8834--------------------------------)[](https://towardsdatascience.com/?source=post_page-----523b05ea8834--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----523b05ea8834--------------------------------)
    [Angus Addlesee](https://addlesee.medium.com/?source=post_page-----523b05ea8834--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://addlesee.medium.com/?source=post_page-----523b05ea8834--------------------------------)[![Angus
    Addlesee](../Images/0a6a016590ca622cc3c8cae24e188f6e.png)](https://addlesee.medium.com/?source=post_page-----523b05ea8834--------------------------------)[](https://towardsdatascience.com/?source=post_page-----523b05ea8834--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----523b05ea8834--------------------------------)
    [Angus Addlesee](https://addlesee.medium.com/?source=post_page-----523b05ea8834--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7f06284203ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-conversational-agents-for-multi-party-interactions-523b05ea8834&user=Angus+Addlesee&userId=7f06284203ea&source=post_page-7f06284203ea----523b05ea8834---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----523b05ea8834--------------------------------)
    ·10 min read·Apr 6, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F523b05ea8834&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-conversational-agents-for-multi-party-interactions-523b05ea8834&user=Angus+Addlesee&userId=7f06284203ea&source=-----523b05ea8834---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7f06284203ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-conversational-agents-for-multi-party-interactions-523b05ea8834&user=Angus+Addlesee&userId=7f06284203ea&source=post_page-7f06284203ea----523b05ea8834---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----523b05ea8834--------------------------------)
    ·10分钟阅读·2023年4月6日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F523b05ea8834&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-conversational-agents-for-multi-party-interactions-523b05ea8834&user=Angus+Addlesee&userId=7f06284203ea&source=-----523b05ea8834---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F523b05ea8834&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-conversational-agents-for-multi-party-interactions-523b05ea8834&source=-----523b05ea8834---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F523b05ea8834&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-conversational-agents-for-multi-party-interactions-523b05ea8834&source=-----523b05ea8834---------------------bookmark_footer-----------)'
- en: '*This is an abridgement of a paper published at* [*IWSDS 2023*](https://sites.google.com/view/iwsds2023/home)*.*
    [*I*](http://addlesee.co.uk/) *co-authored it with the Heriot-Watt University*
    [*SPRING*](https://spring-h2020.eu/) *team detailed below. If you would like to
    cite anything discussed in this article, please cite the paper titled “*[*Data
    Collection for Multi-party Task-based Dialogue in Social Robotic*](https://drive.google.com/file/d/1gUsMOlYHDzreB17CYNFxDOu-dWCtBQ4M/view)*s”:*'
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*这是对在* [*IWSDS 2023*](https://sites.google.com/view/iwsds2023/home)*上发表的一篇论文的缩写。*
    [*我*](http://addlesee.co.uk/) *与赫瑞瓦特大学的* [*SPRING*](https://spring-h2020.eu/)
    *团队共同撰写了这篇论文，详细信息如下。如果您想引用本文中讨论的内容，请引用标题为“*[*面向社交机器人多方任务对话的数据收集*](https://drive.google.com/file/d/1gUsMOlYHDzreB17CYNFxDOu-dWCtBQ4M/view)*s”的论文：*'
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Consider an interaction with a conversational agent, maybe with Siri on your
    phone, Amazon Alexa in your home, or a virtual customer service agent on a website.
    These interactions are ‘dyadic’, that is, they involve just one person (yourself)
    and one agent. This is typical for all voice assistants and chat-based agents.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑与对话代理的互动，也许是你手机上的Siri、家中的Amazon Alexa，或者网站上的虚拟客户服务代理。这些互动是‘双方面的’，即它们只涉及一个人（你自己）和一个代理。这对于所有语音助手和基于聊天的代理来说都是典型的。
- en: '*Conversational agents are designed for one-to-one interactions.*'
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*对话代理被设计用于一对一的互动。*'
- en: '![](../Images/4c0694faaace149f2cceef1041d53b33.png)![](../Images/0f738c94a4a7fbbca2d5e9105ef6eba9.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4c0694faaace149f2cceef1041d53b33.png)![](../Images/0f738c94a4a7fbbca2d5e9105ef6eba9.png)'
- en: Both of these photos show two-party (dyadic) interactions. One with a phone
    voice assistant instead of a person (left [source](https://unsplash.com/photos/tugh5n8r8JQ)),
    (right [source](https://unsplash.com/photos/_4qmlxHbX6I)).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这两张照片展示了双方（对话式）互动。一张是有一个电话语音助手而不是一个人（左 [source](https://unsplash.com/photos/tugh5n8r8JQ)），另一张是（右
    [source](https://unsplash.com/photos/_4qmlxHbX6I)）。
- en: We are social creatures however, and people can naturally handle conversations
    with more than just one other person. Consider coffee with a few friends, family
    dinner conversations, or even work meetings with the entire team. These are called
    ‘multi-party’ conversations, and today’s conversational agents are not designed
    for this type of interaction.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们是社交动物，人们自然能够处理与不止一个其他人的对话。考虑与几个朋友一起喝咖啡、家庭晚餐对话，甚至是全体团队的工作会议。这些被称为‘多方’对话，而如今的对话代理并不为这种互动类型设计。
- en: '*Do conversational agents ever need to work in a multi-party setting? Do multi-party
    conversations add new challenges? What next steps do we need to do to progress?
    I will answer these three questions in this article.*'
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*对话代理是否需要在多方设置中工作？多方对话是否带来了新的挑战？我们需要采取什么下一步措施来推进？我将在本文中回答这三个问题。*'
- en: '![](../Images/ecbb28d99d5b8c24163e335f2e702709.png)![](../Images/c75125b099b1dfdc99294a2c7c69f3ba.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ecbb28d99d5b8c24163e335f2e702709.png)![](../Images/c75125b099b1dfdc99294a2c7c69f3ba.png)'
- en: Multi-party interactions. Consider how these conversations differ from the dyadic
    ones above (left [source](https://unsplash.com/photos/WY5kuE0R4-k)), (right [source](https://unsplash.com/photos/34GZCgaVksk)).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 多方互动。考虑这些对话与上述的双方对话有什么不同（左 [source](https://unsplash.com/photos/WY5kuE0R4-k)），（右
    [source](https://unsplash.com/photos/34GZCgaVksk)）。
- en: Conversational agents in a multi-party setting
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多方设置中的对话代理
- en: Today’s systems have been designed to handle dyadic interactions for a reason
    of course, that is typically how we interact with them. Siri does not passively
    listen to your conversation with a friend and interject where needed - it listens
    to your single request when activated. Google Assistant and Alexa are very similar,
    listening for their wake-word and one utterance. Arguably, these voice assistants
    could benefit from multi-party understanding in a family home for example, but
    this is not pressing.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如今的系统被设计用于处理双方互动，当然这是因为通常情况下我们就是这样与它们互动的。Siri不会被动地听你与朋友的对话并在需要时插话——它会在激活时听取你的单一请求。Google
    Assistant和Alexa也非常相似，监听它们的唤醒词和一个发言。可以说，这些语音助手在家庭环境中可能会从多方理解中受益，但这并不紧迫。
- en: '*Conversational agents are being embedded within virtual agents and social
    robots in public spaces like museums, airports, shopping centres, and hospitals,
    etc… People go to these locations with family members, friends, and carers - so
    these agents must be able to handle multi-party interaction.*'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*对话代理正在被嵌入到虚拟代理和公共场所如博物馆、机场、购物中心和医院的社交机器人中等……人们与家人、朋友和看护者一起去这些地方——所以这些代理必须能够处理多方互动。*'
- en: I will use many examples in this article to illustrate points, so it is best
    to set the context. Let’s imagine a robot assistant in a hospital memory clinic
    waiting room. The robot is called ARI, and patients come to their appointments
    with a companion. The pair may need directions, coffee, hospital information,
    or just some entertainment. This is coincidentally the setting of the EU [SPRING](https://spring-h2020.eu/)
    project, and all examples will fit this setting.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我将在本文中使用许多示例来说明观点，因此最好设定一下背景。让我们想象在医院记忆诊所候诊室中的一个机器人助手。这个机器人叫做ARI，患者带着伴侣来进行预约。这个配对可能需要指引、咖啡、医院信息或只是一些娱乐。这正好是EU
    [SPRING](https://spring-h2020.eu/) 项目的背景，所有示例都将符合这个背景。
- en: '![](../Images/bd5b88c97f36ce901d85fb376fbaa981.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bd5b88c97f36ce901d85fb376fbaa981.png)'
- en: The ARI robot in a multi-party setting. Copyright [PAL Robotics](https://pal-robotics.com/)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 多方设置中的ARI机器人。版权 [PAL Robotics](https://pal-robotics.com/)
- en: Are Multi-party Conversations so Different?
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多方对话真的如此不同吗？
- en: 'Considering the hospital setting above, we have only one additional person
    in an interaction. So instead of the robot only interacting with the patient,
    the robot must interact with both the patient and companion together. Does this
    change a conversation? Spoiler: Yes, a lot!'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到上述医院环境，我们的互动中只有一个额外的人。所以，机器人不仅要与患者互动，还必须同时与患者和陪伴者互动。这会改变对话吗？剧透：会的，变化很大！
- en: Speaker Recognition
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 说话人识别
- en: In a two-person dyadic interaction, the agent does not need to identify the
    speaker. It is trivial, the speaker is the only other person in the conversation.
    Alexa has a neat feature which only allows me to purchase items if it recognises
    the voice as mine - but this is not the type of speaker recognition that I mean.
    It does not matter whether an utterance is tagged as speaker 1, speaker 2, or
    speaker xyz - the response from conversational agents will be the same.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在两人对话中，代理不需要识别说话者。这是微不足道的，因为说话者是对话中唯一的其他人。Alexa有一个很棒的功能，只有在它识别到我的声音时才允许我购买物品——但这不是我所说的说话人识别。这是否标记为说话者1、说话者2还是说话者xyz都无关紧要——对话代理的回应将是一样的。
- en: 'Identifying the speaker is critical to understanding a multi-party conversation
    however. Let’s imagine that the patient and companion want to play a quiz with
    the robot. The robot asks “What is the capital of Germany?” and this is the following
    interaction:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，识别说话者对于理解多方对话至关重要。让我们假设患者和陪伴者想与机器人玩一个测验。机器人问“德国的首都是什么？”然后是以下互动：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Without speaker recognition, we cannot determine whether these two people have
    agreed or not. There are multiple options, let’s look at two (where P = Patient
    and C = Companion):'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 没有说话者识别，我们无法确定这两个人是否达成了一致。有多个选项，让我们看看其中两个（P = 患者，C = 陪伴者）：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In this PPC case, the patient and companion have come to an agreement that
    the answer is Munich. The robot could then let them know that they are incorrect,
    tell them the right answer, and continue with the next question. Alternatively:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个PPC案例中，患者和陪伴者已经达成一致，答案是慕尼黑。然后机器人可以告诉他们答案是错误的，告知他们正确答案，并继续下一个问题。或者：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In this PCC case, the patient proposed the correct answer, and the companion
    suggests a second incorrect option. The companion then reaffirms their certainty,
    but importantly, the patient has **not** agreed. If the robot took Munich as the
    final answer in this case, the patient would be very frustrated as they proposed
    the correct answer but was then ignored.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个PCC案例中，患者提出了正确答案，而陪伴者则建议了第二个错误选项。陪伴者随后再次确认他们的确定性，但重要的是，患者**没有**同意。如果机器人在这种情况下将慕尼黑作为最终答案，患者会非常沮丧，因为他们提出了正确答案却被忽视了。
- en: Hopefully this example is clear. In the PPC (or PCP) case, agreement is reached
    and continuing the quiz is the correct action. In the PCC case, the robot should
    stay silent and wait for the patients response.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这个例子很清楚。在PPC（或PCP）案例中，一致意见已经达成，继续测验是正确的行动。在PCC案例中，机器人应该保持沉默，等待患者的回应。
- en: '*The conversational agent can only know which action is correct if the speakers
    are recognised. This is not true in dyadic interactions.*'
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*对话代理只有在识别到说话者时才能知道哪个行动是正确的。这在两人对话中并不成立。*'
- en: Addressee Recognition
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 收件人识别
- en: 'Similar to speaker recognition, figuring out who is being spoken to is trivial
    in a dyadic interaction. The speaker is obviously speaking to the second person/agent.
    Again, however, this is not the case in a multi-party interaction. The speaker
    may be addressing one individual, the other individual, or both of them together.
    To illustrate this, consider (where R = Robot and P = Patient):'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 与说话人识别类似，弄清楚谁在被说话者讲述在两人对话中也很简单。说话者显然是在对第二个人/代理讲话。然而，这在多方对话中并非如此。说话者可能在对一个个体、另一个个体或两者同时讲话。为了说明这一点，请考虑（其中R
    = 机器人，P = 患者）：
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In this example, the patient originally addressed the robot in turn 1\. The
    robot then responded correctly. In turn 3 however, the patient turned to their
    companion and repeated the same question. As the robot has no addressee recognition
    capability, it responded again with the same response, frustrating the patient.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，病人在第1回合时最初向机器人提问。机器人随后作出了正确的回应。然而，在第3回合时，病人转向他们的伴侣并重复了相同的问题。由于机器人没有地址识别能力，它再次做出了相同的回应，这让病人感到沮丧。
- en: '![](../Images/f1d65e20f92b6b6b0e73aeb72657d82c.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f1d65e20f92b6b6b0e73aeb72657d82c.png)'
- en: The ARI robot being tested for SPRING in Heriot-Watt University
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在赫瑞瓦特大学测试的用于SPRING的ARI机器人
- en: Response Selection or Generation
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回应选择或生成
- en: 'It is difficult to decide what a virtual agent should say in response to a
    user, and this is true for both dyadic and multi-party conversations (unlike the
    last two tasks). It is additionally challenging in a multi-party setting due to
    the fact that your agent has to decide who to address. The robot’s response will
    be different if it is addressing an individual or everyone for example. Once again,
    I will illustrate this:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 决定虚拟代理应该如何回应用户是很困难的，这对二人对话和多方对话都是如此（不同于最后两个任务）。在多方环境中尤为具有挑战性，因为你的代理必须决定向谁发言。例如，机器人的回应会因其面对的是个人还是所有人而有所不同。我将再次说明这一点：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The robot may decide to address the patient first as they asked for assistance
    before the companion. The robot may decide to prioritise the companion due to
    urgency however. What the robot says next is dependent on who it decides to address.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 机器人可能会决定首先向病人发言，因为他们在伴侣之前请求了帮助。然而，由于紧急情况，机器人也可能决定优先考虑伴侣。接下来机器人说什么取决于它决定向谁发言。
- en: '*The three tasks above (speaker recognition, addressee recognition, and response
    selection/generation) are collectively known in the literature as “Who says what
    to whom?”. This is what current research focuses on. In our paper, we highlight
    two other important tasks for multi-party agents.*'
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*上述三个任务（说话人识别、收件人识别和回应选择/生成）在文献中统称为“谁对谁说了什么？”。这是当前研究的重点。在我们的论文中，我们强调了多方代理的另外两个重要任务。*'
- en: Dialogue State Tracking
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对话状态跟踪
- en: It is important to understand what the point of each user’s utterance is in
    the context of a conversation. Dialogue State Tracking (DST) aims to do exactly
    this with popular challenges like DSTC and MultiWoZ. Many research institutes
    and companies allocate resources to this task, but all of the datasets are dyadic.
    Once again, DST differs when in a multi-party context.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在对话的上下文中理解每个用户发言的要点是很重要的。对话状态跟踪（DST）正是要做到这一点，并面临如DSTC和MultiWoZ这样的挑战。许多研究机构和公司为此任务分配了资源，但所有的数据集都是二人对话的。再次强调，DST在多方环境中有所不同。
- en: 'Current DST models can output that a user is requesting certain information,
    affirming something, providing information, etc… but they cannot detect agreement
    or determine that a request was fulfilled, as that does not happen in dyadic interactions.
    For example:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的DST模型可以输出用户请求特定信息、确认某事、提供信息等……但它们不能检测到同意或确定请求是否已被满足，因为这在二人对话中不会发生。例如：
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This would never occur in a dyadic interaction. It makes no sense for a person
    to ask a question and then instantly answer it to themselves. Utterance 2 could
    be said by the companion however, and the robot would have to track that the companion
    provided information to the patient.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况在二人对话中永远不会发生。一个人问一个问题然后立刻自己回答是不合逻辑的。然而，发言2可能由伴侣说出，机器人必须跟踪伴侣向病人提供了信息。
- en: Goal Tracking
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目标跟踪
- en: Finally, tracking people’s goals is also more difficult in the multi-party setting.
    Similar to the DST difference, people can answer each others goals which does
    not happen in a dyadic interaction. The agent must be able to determine if a user
    goal has been *accurately* satisfied to not repeat what the person answering just
    said. If the person’s answer was incorrect however, the robot is still required
    to answer as the goal is not complete.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在多方环境中跟踪人们的目标也更加困难。类似于DST的差异，人们可以回答彼此的目标，而这种情况在二人对话中不会发生。代理必须能够确定用户目标是否被*准确*满足，以免重复刚刚回答者所说的内容。然而，如果回答者的回答是不正确的，机器人仍然需要回应，因为目标尚未完成。
- en: Another major goal tracking difference is something that we humans are very
    good at - determining when people have a shared goal. If two people enter a cafe
    to order coffee, the barista will interact differently depending on whether it
    is two seperate people ordering coffee, or two people ordering coffees together.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个主要的目标跟踪差异是我们人类非常擅长的——确定人们是否有共同的目标。如果两个人进咖啡馆点咖啡，咖啡师的互动方式会根据这是否是两个人分别点咖啡还是两个人一起点咖啡而有所不同。
- en: '![](../Images/ec16f985c858169c1431d6d1eb73ab6c.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ec16f985c858169c1431d6d1eb73ab6c.png)'
- en: Two people ordering coffee ([source](https://unsplash.com/photos/f7zm5TDOi4g))
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 两个人点咖啡 ([来源](https://unsplash.com/photos/f7zm5TDOi4g))
- en: In the above image, the two people may be ordering separately or together. In
    the latter case, the barista may say “are you paying together?”, but this would
    be odd if the two people do not know each other.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在上图中，这两个人可能是分开点餐或一起点餐。在后一种情况下，咖啡师可能会说“你们一起付款吗？”，但如果这两个人互不相识，这会显得很奇怪。
- en: 'People can indicate shared goals very explicitly (e.g. “We would like…”, “my
    son needs…”, or “me too”). But we hypothesise that goals are shared when people
    finish each other’s sentences (split-utterances). For example:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 人们可以非常明确地表明共同目标（例如，“我们想要……”，“我儿子需要……”，或“我也是”）。但我们假设当人们接续彼此的句子（分裂话语）时，目标是共享的。例如：
- en: '[PRE7]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: From the above two utterances, we can assume that the two people have a shared
    goal. This does not occur in dyadic interactions.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 从上述两个话语中，我们可以推测这两个人有共同的目标。这在双人互动中不会发生。
- en: '*I hope I have convinced you that multi-party interactions are very different
    to dyadic ones, and they contain a number of extra challenges that must be solved
    if we are to have naturally interactive agents in public spaces.*'
  id: totrans-62
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*我希望我已经说服了你们，多方互动与双人互动有很大的不同，它们包含了许多额外的挑战，如果我们要在公共空间中拥有自然互动的代理，必须解决这些问题。*'
- en: How do we Progress?
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们如何进展？
- en: As the majority of research in this field has focused on dyadic interactions,
    suitable data is very limited, and none exists with DST or goal tracking annotations.
    In order to train systems to do the above tasks in a multi-party setting, we must
    collect data. We - the SPRING project - are collecting multi-party conversations
    in a hospital memory clinic with the ARI robot.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 由于该领域的大多数研究集中在双人互动上，适合的数据非常有限，且没有具有DST或目标跟踪注释的数据。为了在多方环境中训练系统执行上述任务，我们必须收集数据。我们——SPRING项目——正在医院记忆诊所中使用ARI机器人收集多方对话。
- en: '![](../Images/6ea20838326ee7aff1c7cbe94cf12458.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6ea20838326ee7aff1c7cbe94cf12458.png)'
- en: I presented this [paper](https://drive.google.com/file/d/1gUsMOlYHDzreB17CYNFxDOu-dWCtBQ4M/view)
    at [IWSDS 2023](https://sites.google.com/view/iwsds2023/home) in LA, showing the
    ARI robot we are using for data collection.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我在[论文](https://drive.google.com/file/d/1gUsMOlYHDzreB17CYNFxDOu-dWCtBQ4M/view)中展示了我们在洛杉矶[IWSDS
    2023](https://sites.google.com/view/iwsds2023/home)会议上使用的ARI机器人用于数据收集的情况。
- en: People that are visiting the hospital memory clinic with their companions are
    given role-play scenarios with varying goals. In order to collect conversations
    with the varying challenges described above, we designed six conditions. The third
    round of data collection is ongoing as I write this!
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 访问医院记忆诊所的患者及其陪同者会被提供带有不同目标的角色扮演场景。为了收集具有上述各种挑战的对话，我们设计了六种条件。我写这篇文章时，第三轮数据收集正在进行中！
- en: 'I provide more detail in the [paper](https://drive.google.com/file/d/1gUsMOlYHDzreB17CYNFxDOu-dWCtBQ4M/view),
    but the six conditions are as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我在[论文](https://drive.google.com/file/d/1gUsMOlYHDzreB17CYNFxDOu-dWCtBQ4M/view)中提供了更多细节，但六种条件如下：
- en: Helpful Companion
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有帮助的陪同者
- en: The patient is given a goal, but the companion is simply told to assist the
    patient. They have to interact with the robot to complete these goals (e.g. get
    coffee, find out when the cafe closes, etc…).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '患者有一个目标，但陪同者只是被告知要协助患者。他们必须与机器人互动以完成这些目标（例如，获取咖啡，了解咖啡馆何时关门等）。 '
- en: This condition is what we expect a typical interaction to be like. The patient
    may need something, but the companion has no goal themself.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这个条件是我们期望的典型互动方式。患者可能需要某些东西，但陪同者自己没有目标。
- en: Shared Goals
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 共享目标
- en: As discussed in the goal tracking section above, sometimes people have shared
    goals. In this case, both the patient and companion are given the same goal, so
    they both may want lunch for example. This is only slightly different from the
    “helpful companion” condition, but initial observations suggest that more split
    utterances occur in this condition.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如上节的目标跟踪部分所讨论的，有时人们有共同的目标。在这种情况下，病人和陪同者会被分配相同的目标，例如，他们都可能想吃午餐。这与“有帮助的陪同者”条件仅有些微不同，但初步观察表明在这种条件下会出现更多的分裂性话语。
- en: Reluctant Patient
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不情愿的病人
- en: People visiting the hospital may be too shy (or even too apprehensive) to talk
    to the robot directly. In this case, the patient has a goal, but they do not talk
    directly with the robot. The companion must therefore act as an intermediary between
    the patient and robot to complete the patient’s goal.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 访问医院的人可能会因为过于害羞（或甚至过于担忧）而不直接与机器人对话。在这种情况下，病人有一个目标，但他们不会直接与机器人交谈。因此，陪同者必须作为病人和机器人之间的中介，以完成病人的目标。
- en: Different Goals
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不同的目标
- en: People do not always have the same goal. For example, the patient may want a
    coffee while the companion need the bathroom. In this condition, the patient and
    companion are given separate goals.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 人们并不总是有相同的目标。例如，病人可能想要一杯咖啡，而陪同者则需要使用洗手间。在这种情况下，病人和陪同者会被分配不同的目标。
- en: Missing Info
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缺失信息
- en: 'As alluded to earlier, the robot cannot always answer questions due to privacy.
    The robot cannot ethically disclose why the patient is visiting the hospital for
    example. Additionally, the robot cannot run face recognition on patients to identify
    them. In this case, the companion is given some missing information that the robot
    cannot know. The companion must provide this information to the robot in order
    to achieve the patient’s goal. As this is difficult to explain, here is an example:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，机器人由于隐私原因不能总是回答问题。例如，机器人不能从伦理上透露病人为什么来医院。此外，机器人不能对病人进行面部识别以确认身份。在这种情况下，陪同者会得到一些机器人无法知道的缺失信息。陪同者必须向机器人提供这些信息，以实现病人的目标。由于这很难解释，这里举个例子：
- en: '[PRE8]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As you can see, the patient’s goal is to find their appointment location. The
    companion is given extra info about which doctor the appointment is with.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，病人的目标是找到他们的预约地点。陪同者被提供了有关预约医生的额外信息。
- en: 'Disagreement:'
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不一致：
- en: Finally, multi-party interactions can involve disagreements. If the robot provides
    the location of the coffee machine, the companion may disagree. In this case,
    the patient is given a goal and the companion is given extra information that
    contradicts with the robot. The robot should be able to identify the conflict,
    re-supply the correct information, and reassure the participants that the information
    is correct.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，多方互动可能涉及分歧。如果机器人提供了咖啡机的位置，陪同者可能会不同意。在这种情况下，病人会有一个目标，而陪同者则拥有与机器人信息相矛盾的额外信息。机器人应该能够识别冲突，重新提供正确的信息，并向参与者保证信息是正确的。
- en: You can find the full paper with citations [here](https://drive.google.com/file/d/1gUsMOlYHDzreB17CYNFxDOu-dWCtBQ4M/view),
    and you can reach [me](http://addlesee.co.uk/) on [Medium](https://medium.com/@addlesee),
    on [Twitter](https://twitter.com/Addlesee_AI), or on [LinkedIn](https://www.linkedin.com/in/angusaddlesee/).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[这里](https://drive.google.com/file/d/1gUsMOlYHDzreB17CYNFxDOu-dWCtBQ4M/view)找到带有引文的完整论文，你可以通过[Medium](https://medium.com/@addlesee)、[Twitter](https://twitter.com/Addlesee_AI)或[LinkedIn](https://www.linkedin.com/in/angusaddlesee/)联系[我](http://addlesee.co.uk/)。
