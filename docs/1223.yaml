- en: Designing Conversational Agents for Multi-party Interactions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/designing-conversational-agents-for-multi-party-interactions-523b05ea8834?source=collection_archive---------15-----------------------#2023-04-06](https://towardsdatascience.com/designing-conversational-agents-for-multi-party-interactions-523b05ea8834?source=collection_archive---------15-----------------------#2023-04-06)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How does one extra person impact a conversation?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://addlesee.medium.com/?source=post_page-----523b05ea8834--------------------------------)[![Angus
    Addlesee](../Images/0a6a016590ca622cc3c8cae24e188f6e.png)](https://addlesee.medium.com/?source=post_page-----523b05ea8834--------------------------------)[](https://towardsdatascience.com/?source=post_page-----523b05ea8834--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----523b05ea8834--------------------------------)
    [Angus Addlesee](https://addlesee.medium.com/?source=post_page-----523b05ea8834--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7f06284203ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-conversational-agents-for-multi-party-interactions-523b05ea8834&user=Angus+Addlesee&userId=7f06284203ea&source=post_page-7f06284203ea----523b05ea8834---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----523b05ea8834--------------------------------)
    ·10 min read·Apr 6, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F523b05ea8834&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-conversational-agents-for-multi-party-interactions-523b05ea8834&user=Angus+Addlesee&userId=7f06284203ea&source=-----523b05ea8834---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F523b05ea8834&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-conversational-agents-for-multi-party-interactions-523b05ea8834&source=-----523b05ea8834---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: '*This is an abridgement of a paper published at* [*IWSDS 2023*](https://sites.google.com/view/iwsds2023/home)*.*
    [*I*](http://addlesee.co.uk/) *co-authored it with the Heriot-Watt University*
    [*SPRING*](https://spring-h2020.eu/) *team detailed below. If you would like to
    cite anything discussed in this article, please cite the paper titled “*[*Data
    Collection for Multi-party Task-based Dialogue in Social Robotic*](https://drive.google.com/file/d/1gUsMOlYHDzreB17CYNFxDOu-dWCtBQ4M/view)*s”:*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Consider an interaction with a conversational agent, maybe with Siri on your
    phone, Amazon Alexa in your home, or a virtual customer service agent on a website.
    These interactions are ‘dyadic’, that is, they involve just one person (yourself)
    and one agent. This is typical for all voice assistants and chat-based agents.
  prefs: []
  type: TYPE_NORMAL
- en: '*Conversational agents are designed for one-to-one interactions.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/4c0694faaace149f2cceef1041d53b33.png)![](../Images/0f738c94a4a7fbbca2d5e9105ef6eba9.png)'
  prefs: []
  type: TYPE_IMG
- en: Both of these photos show two-party (dyadic) interactions. One with a phone
    voice assistant instead of a person (left [source](https://unsplash.com/photos/tugh5n8r8JQ)),
    (right [source](https://unsplash.com/photos/_4qmlxHbX6I)).
  prefs: []
  type: TYPE_NORMAL
- en: We are social creatures however, and people can naturally handle conversations
    with more than just one other person. Consider coffee with a few friends, family
    dinner conversations, or even work meetings with the entire team. These are called
    ‘multi-party’ conversations, and today’s conversational agents are not designed
    for this type of interaction.
  prefs: []
  type: TYPE_NORMAL
- en: '*Do conversational agents ever need to work in a multi-party setting? Do multi-party
    conversations add new challenges? What next steps do we need to do to progress?
    I will answer these three questions in this article.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/ecbb28d99d5b8c24163e335f2e702709.png)![](../Images/c75125b099b1dfdc99294a2c7c69f3ba.png)'
  prefs: []
  type: TYPE_IMG
- en: Multi-party interactions. Consider how these conversations differ from the dyadic
    ones above (left [source](https://unsplash.com/photos/WY5kuE0R4-k)), (right [source](https://unsplash.com/photos/34GZCgaVksk)).
  prefs: []
  type: TYPE_NORMAL
- en: Conversational agents in a multi-party setting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Today’s systems have been designed to handle dyadic interactions for a reason
    of course, that is typically how we interact with them. Siri does not passively
    listen to your conversation with a friend and interject where needed - it listens
    to your single request when activated. Google Assistant and Alexa are very similar,
    listening for their wake-word and one utterance. Arguably, these voice assistants
    could benefit from multi-party understanding in a family home for example, but
    this is not pressing.
  prefs: []
  type: TYPE_NORMAL
- en: '*Conversational agents are being embedded within virtual agents and social
    robots in public spaces like museums, airports, shopping centres, and hospitals,
    etc… People go to these locations with family members, friends, and carers - so
    these agents must be able to handle multi-party interaction.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I will use many examples in this article to illustrate points, so it is best
    to set the context. Let’s imagine a robot assistant in a hospital memory clinic
    waiting room. The robot is called ARI, and patients come to their appointments
    with a companion. The pair may need directions, coffee, hospital information,
    or just some entertainment. This is coincidentally the setting of the EU [SPRING](https://spring-h2020.eu/)
    project, and all examples will fit this setting.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bd5b88c97f36ce901d85fb376fbaa981.png)'
  prefs: []
  type: TYPE_IMG
- en: The ARI robot in a multi-party setting. Copyright [PAL Robotics](https://pal-robotics.com/)
  prefs: []
  type: TYPE_NORMAL
- en: Are Multi-party Conversations so Different?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Considering the hospital setting above, we have only one additional person
    in an interaction. So instead of the robot only interacting with the patient,
    the robot must interact with both the patient and companion together. Does this
    change a conversation? Spoiler: Yes, a lot!'
  prefs: []
  type: TYPE_NORMAL
- en: Speaker Recognition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In a two-person dyadic interaction, the agent does not need to identify the
    speaker. It is trivial, the speaker is the only other person in the conversation.
    Alexa has a neat feature which only allows me to purchase items if it recognises
    the voice as mine - but this is not the type of speaker recognition that I mean.
    It does not matter whether an utterance is tagged as speaker 1, speaker 2, or
    speaker xyz - the response from conversational agents will be the same.
  prefs: []
  type: TYPE_NORMAL
- en: 'Identifying the speaker is critical to understanding a multi-party conversation
    however. Let’s imagine that the patient and companion want to play a quiz with
    the robot. The robot asks “What is the capital of Germany?” and this is the following
    interaction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Without speaker recognition, we cannot determine whether these two people have
    agreed or not. There are multiple options, let’s look at two (where P = Patient
    and C = Companion):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In this PPC case, the patient and companion have come to an agreement that
    the answer is Munich. The robot could then let them know that they are incorrect,
    tell them the right answer, and continue with the next question. Alternatively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In this PCC case, the patient proposed the correct answer, and the companion
    suggests a second incorrect option. The companion then reaffirms their certainty,
    but importantly, the patient has **not** agreed. If the robot took Munich as the
    final answer in this case, the patient would be very frustrated as they proposed
    the correct answer but was then ignored.
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully this example is clear. In the PPC (or PCP) case, agreement is reached
    and continuing the quiz is the correct action. In the PCC case, the robot should
    stay silent and wait for the patients response.
  prefs: []
  type: TYPE_NORMAL
- en: '*The conversational agent can only know which action is correct if the speakers
    are recognised. This is not true in dyadic interactions.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Addressee Recognition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Similar to speaker recognition, figuring out who is being spoken to is trivial
    in a dyadic interaction. The speaker is obviously speaking to the second person/agent.
    Again, however, this is not the case in a multi-party interaction. The speaker
    may be addressing one individual, the other individual, or both of them together.
    To illustrate this, consider (where R = Robot and P = Patient):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the patient originally addressed the robot in turn 1\. The
    robot then responded correctly. In turn 3 however, the patient turned to their
    companion and repeated the same question. As the robot has no addressee recognition
    capability, it responded again with the same response, frustrating the patient.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f1d65e20f92b6b6b0e73aeb72657d82c.png)'
  prefs: []
  type: TYPE_IMG
- en: The ARI robot being tested for SPRING in Heriot-Watt University
  prefs: []
  type: TYPE_NORMAL
- en: Response Selection or Generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It is difficult to decide what a virtual agent should say in response to a
    user, and this is true for both dyadic and multi-party conversations (unlike the
    last two tasks). It is additionally challenging in a multi-party setting due to
    the fact that your agent has to decide who to address. The robot’s response will
    be different if it is addressing an individual or everyone for example. Once again,
    I will illustrate this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The robot may decide to address the patient first as they asked for assistance
    before the companion. The robot may decide to prioritise the companion due to
    urgency however. What the robot says next is dependent on who it decides to address.
  prefs: []
  type: TYPE_NORMAL
- en: '*The three tasks above (speaker recognition, addressee recognition, and response
    selection/generation) are collectively known in the literature as “Who says what
    to whom?”. This is what current research focuses on. In our paper, we highlight
    two other important tasks for multi-party agents.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Dialogue State Tracking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is important to understand what the point of each user’s utterance is in
    the context of a conversation. Dialogue State Tracking (DST) aims to do exactly
    this with popular challenges like DSTC and MultiWoZ. Many research institutes
    and companies allocate resources to this task, but all of the datasets are dyadic.
    Once again, DST differs when in a multi-party context.
  prefs: []
  type: TYPE_NORMAL
- en: 'Current DST models can output that a user is requesting certain information,
    affirming something, providing information, etc… but they cannot detect agreement
    or determine that a request was fulfilled, as that does not happen in dyadic interactions.
    For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This would never occur in a dyadic interaction. It makes no sense for a person
    to ask a question and then instantly answer it to themselves. Utterance 2 could
    be said by the companion however, and the robot would have to track that the companion
    provided information to the patient.
  prefs: []
  type: TYPE_NORMAL
- en: Goal Tracking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finally, tracking people’s goals is also more difficult in the multi-party setting.
    Similar to the DST difference, people can answer each others goals which does
    not happen in a dyadic interaction. The agent must be able to determine if a user
    goal has been *accurately* satisfied to not repeat what the person answering just
    said. If the person’s answer was incorrect however, the robot is still required
    to answer as the goal is not complete.
  prefs: []
  type: TYPE_NORMAL
- en: Another major goal tracking difference is something that we humans are very
    good at - determining when people have a shared goal. If two people enter a cafe
    to order coffee, the barista will interact differently depending on whether it
    is two seperate people ordering coffee, or two people ordering coffees together.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ec16f985c858169c1431d6d1eb73ab6c.png)'
  prefs: []
  type: TYPE_IMG
- en: Two people ordering coffee ([source](https://unsplash.com/photos/f7zm5TDOi4g))
  prefs: []
  type: TYPE_NORMAL
- en: In the above image, the two people may be ordering separately or together. In
    the latter case, the barista may say “are you paying together?”, but this would
    be odd if the two people do not know each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'People can indicate shared goals very explicitly (e.g. “We would like…”, “my
    son needs…”, or “me too”). But we hypothesise that goals are shared when people
    finish each other’s sentences (split-utterances). For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: From the above two utterances, we can assume that the two people have a shared
    goal. This does not occur in dyadic interactions.
  prefs: []
  type: TYPE_NORMAL
- en: '*I hope I have convinced you that multi-party interactions are very different
    to dyadic ones, and they contain a number of extra challenges that must be solved
    if we are to have naturally interactive agents in public spaces.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How do we Progress?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As the majority of research in this field has focused on dyadic interactions,
    suitable data is very limited, and none exists with DST or goal tracking annotations.
    In order to train systems to do the above tasks in a multi-party setting, we must
    collect data. We - the SPRING project - are collecting multi-party conversations
    in a hospital memory clinic with the ARI robot.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6ea20838326ee7aff1c7cbe94cf12458.png)'
  prefs: []
  type: TYPE_IMG
- en: I presented this [paper](https://drive.google.com/file/d/1gUsMOlYHDzreB17CYNFxDOu-dWCtBQ4M/view)
    at [IWSDS 2023](https://sites.google.com/view/iwsds2023/home) in LA, showing the
    ARI robot we are using for data collection.
  prefs: []
  type: TYPE_NORMAL
- en: People that are visiting the hospital memory clinic with their companions are
    given role-play scenarios with varying goals. In order to collect conversations
    with the varying challenges described above, we designed six conditions. The third
    round of data collection is ongoing as I write this!
  prefs: []
  type: TYPE_NORMAL
- en: 'I provide more detail in the [paper](https://drive.google.com/file/d/1gUsMOlYHDzreB17CYNFxDOu-dWCtBQ4M/view),
    but the six conditions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Helpful Companion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The patient is given a goal, but the companion is simply told to assist the
    patient. They have to interact with the robot to complete these goals (e.g. get
    coffee, find out when the cafe closes, etc…).
  prefs: []
  type: TYPE_NORMAL
- en: This condition is what we expect a typical interaction to be like. The patient
    may need something, but the companion has no goal themself.
  prefs: []
  type: TYPE_NORMAL
- en: Shared Goals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As discussed in the goal tracking section above, sometimes people have shared
    goals. In this case, both the patient and companion are given the same goal, so
    they both may want lunch for example. This is only slightly different from the
    “helpful companion” condition, but initial observations suggest that more split
    utterances occur in this condition.
  prefs: []
  type: TYPE_NORMAL
- en: Reluctant Patient
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: People visiting the hospital may be too shy (or even too apprehensive) to talk
    to the robot directly. In this case, the patient has a goal, but they do not talk
    directly with the robot. The companion must therefore act as an intermediary between
    the patient and robot to complete the patient’s goal.
  prefs: []
  type: TYPE_NORMAL
- en: Different Goals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: People do not always have the same goal. For example, the patient may want a
    coffee while the companion need the bathroom. In this condition, the patient and
    companion are given separate goals.
  prefs: []
  type: TYPE_NORMAL
- en: Missing Info
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As alluded to earlier, the robot cannot always answer questions due to privacy.
    The robot cannot ethically disclose why the patient is visiting the hospital for
    example. Additionally, the robot cannot run face recognition on patients to identify
    them. In this case, the companion is given some missing information that the robot
    cannot know. The companion must provide this information to the robot in order
    to achieve the patient’s goal. As this is difficult to explain, here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the patient’s goal is to find their appointment location. The
    companion is given extra info about which doctor the appointment is with.
  prefs: []
  type: TYPE_NORMAL
- en: 'Disagreement:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finally, multi-party interactions can involve disagreements. If the robot provides
    the location of the coffee machine, the companion may disagree. In this case,
    the patient is given a goal and the companion is given extra information that
    contradicts with the robot. The robot should be able to identify the conflict,
    re-supply the correct information, and reassure the participants that the information
    is correct.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the full paper with citations [here](https://drive.google.com/file/d/1gUsMOlYHDzreB17CYNFxDOu-dWCtBQ4M/view),
    and you can reach [me](http://addlesee.co.uk/) on [Medium](https://medium.com/@addlesee),
    on [Twitter](https://twitter.com/Addlesee_AI), or on [LinkedIn](https://www.linkedin.com/in/angusaddlesee/).
  prefs: []
  type: TYPE_NORMAL
