["```py\nfrom sentence_transformers import SentenceTransformer \n\nmodel = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2') \n\nembedding = model.encode(text_field)\n```", "```py\n{ \n   \"products\":{ \n      \"mappings\":{ \n         \"properties\":{ \n            \"asin\":{ \n               \"type\":\"keyword\" \n            }, \n            \"description_vector\":{ \n               \"type\":\"knn_vector\", \n               \"dimension\":384 \n            }, \n            \"item_image\":{ \n               \"type\":\"keyword\" \n            }, \n            \"text_field\":{ \n               \"type\":\"text\", \n               \"fields\":{ \n                  \"keyword_field\":{ \n                     \"type\":\"keyword\" \n                  } \n               }, \n               \"analyzer\":\"standard\" \n            } \n         } \n      } \n   } \n} \n```", "```py\ndef store_index(index_name: str, data: np.array, metadata: list, os_client: OpenSearch): \n    documents = [] \n    for index_num, vector in enumerate(data): \n        metadata_line = metadata[index_num] \n        text_field = metadata_line[\"title\"] \n        embedding = model.encode(text_field) \n        norm_text_vector_np = normalize_data(embedding) \n        document = { \n            \"_index\": index_name, \n            \"_id\": index_num, \n            \"asin\": metadata_line[\"asin\"], \n            \"description_vector\": norm_text_vector_np.tolist(), \n            \"item_image\": metadata_line[\"imgUrl\"], \n            \"text_field\": text_field \n        } \n        documents.append(document) \n        if index_num % 1000 == 0 or index_num == len(data): \n            helpers.bulk(os_client, documents, request_timeout=1800) \n            documents = [] \n            print(f\"bulk {index_num} indexed successfully\") \n            os_client.indices.refresh(INDEX_NAME) \n\n    os_client.indices.refresh(INDEX_NAME) \n```", "```py\nbm25_query = {\n    \"size\": 20,\n    \"query\": {\n        \"match\": {\n            \"text_field\": query\n        }\n    },\n    \"_source\": [\"asin\", \"text_field\", \"item_image\"],\n}\n```", "```py\ndef normalize_bm25_formula(score, max_score):\n    return score / max_score\n```", "```py\ncpu_request_body = {\n    \"size\": 20,\n    \"query\": {\n        \"script_score\": {\n            \"query\": {\n                \"match_all\": {}\n            },\n            \"script\": {\n                \"source\": \"knn_score\",\n                \"lang\": \"knn\",\n                \"params\": {\n                    \"field\": \"description_vector\",\n                    \"query_value\": get_vector_sentence_transformers(query).tolist(),\n                    \"space_type\": \"cosinesimil\"\n                }\n            }\n        }\n    },\n    \"_source\": [\"asin\", \"text_field\", \"item_image\"],\n}\n```", "```py\ndef interpolate_results(vector_hits, bm25_hits):\n    # gather all product ids\n    bm25_ids_list = []\n    vector_ids_list = []\n    for hit in bm25_hits:\n        bm25_ids_list.append(hit[\"_source\"][\"asin\"])\n    for hit in vector_hits:\n        vector_ids_list.append(hit[\"_source\"][\"asin\"])\n    # find common product ids\n    common_results = set(bm25_ids_list) & set(vector_ids_list)\n    results_dictionary = dict((key, []) for key in common_results)\n    for common_result in common_results:\n        for index, vector_hit in enumerate(vector_hits):\n            if vector_hit[\"_source\"][\"asin\"] == common_result:\n                results_dictionary[common_result].append(vector_hit[\"_score\"])\n        for index, BM_hit in enumerate(bm25_hits):\n            if BM_hit[\"_source\"][\"asin\"] == common_result:\n                results_dictionary[common_result].append(BM_hit[\"_score\"])\n    min_value = get_min_score(common_results, results_dictionary)\n    # assign minimum value scores for all unique results\n    for vector_hit in vector_hits:\n        if vector_hit[\"_source\"][\"asin\"] not in common_results:\n            new_scored_element_id = vector_hit[\"_source\"][\"asin\"]\n            results_dictionary[new_scored_element_id] = [min_value]\n    for BM_hit in bm25_hits:\n        if BM_hit[\"_source\"][\"asin\"] not in common_results:\n            new_scored_element_id = BM_hit[\"_source\"][\"asin\"]\n            results_dictionary[new_scored_element_id] = [min_value]\n\n    return results_dictionary\n```", "```py\ndef apply_boost(combined_results, vector_boost_level, bm25_boost_level):\n    for element in combined_results:\n        if len(combined_results[element]) == 1:\n            combined_results[element] = combined_results[element][0] * vector_boost_level + \\\n                                        combined_results[element][0] * bm25_boost_level\n        else:\n            combined_results[element] = combined_results[element][0] * vector_boost_level + \\\n                                        combined_results[element][1] * bm25_boost_level\n    #sort the results based on the new scores\n    sorted_results = [k for k, v in sorted(combined_results.items(), key=lambda item: item[1], reverse=True)]\n    return sorted_results\n```", "```py\napu_request_body = {\n    \"size\": 20,\n    \"query\": {\n        \"gsi_knn\": {\n            \"field\": \"description_vector\",\n            \"vector\": get_vector_sentence_transformers(query).tolist(),\n        }\n    },\n    \"_source\": [\"asin\", \"text_field\", \"item_image\"],\n} \n```"]