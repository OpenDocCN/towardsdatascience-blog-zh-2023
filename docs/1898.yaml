- en: Training a Machine Learning Model on a Kafka Stream
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/training-a-machine-learning-model-on-a-kafka-stream-a5079f543e98?source=collection_archive---------6-----------------------#2023-06-09](https://towardsdatascience.com/training-a-machine-learning-model-on-a-kafka-stream-a5079f543e98?source=collection_archive---------6-----------------------#2023-06-09)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Updating a machine learning model online and in near real-time using training
    data generated by a Kafka producer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@kylegallatin?source=post_page-----a5079f543e98--------------------------------)[![Kyle
    Gallatin](../Images/ee2796ba575412e9caf6034a65d741e5.png)](https://medium.com/@kylegallatin?source=post_page-----a5079f543e98--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a5079f543e98--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a5079f543e98--------------------------------)
    [Kyle Gallatin](https://medium.com/@kylegallatin?source=post_page-----a5079f543e98--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F51ff4b76ebf4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-a-machine-learning-model-on-a-kafka-stream-a5079f543e98&user=Kyle+Gallatin&userId=51ff4b76ebf4&source=post_page-51ff4b76ebf4----a5079f543e98---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a5079f543e98--------------------------------)
    ·5 min read·Jun 9, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa5079f543e98&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-a-machine-learning-model-on-a-kafka-stream-a5079f543e98&user=Kyle+Gallatin&userId=51ff4b76ebf4&source=-----a5079f543e98---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa5079f543e98&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-a-machine-learning-model-on-a-kafka-stream-a5079f543e98&source=-----a5079f543e98---------------------bookmark_footer-----------)![](../Images/d379c69615c47a586b2e92f500891d1f.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Jonathan Borba](https://unsplash.com/@jonathanborba?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Lately, I’ve become increasingly interested in *online machine learning* — the
    ability to update an ML model’s weights in a production setting. Besides the the
    topic providing [fun architectural challenges](/thoughts-on-stateful-ml-online-learning-and-intelligent-ml-model-retraining-4e583728e8a1?sk=d5650f2c6be6af8ef512d9c109da3a65)
    for me, the approach boasts massive potential gains. This [study from Grubhub
    in 2021](https://arxiv.org/abs/2107.07106) demonstrated a +20% with metrics increase
    *and* 45x cost savings by leveraging online learning, and I’m all about saving
    money to make money.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d74d07e0c17ed88c29b53dfce38d84a2.png)'
  prefs: []
  type: TYPE_IMG
- en: Stateful retraining — Image by Chip Huyen with permission
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/941f78afa2549ce3c1b4779620b3d705.png)'
  prefs: []
  type: TYPE_IMG
- en: Online learning — Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'From a practical perspective, however, working with data streams and streaming
    architecture is still pretty new to ML practitioners. Creating a real-time stream
    of training data aside, there are fairly few resources on consuming such a data
    source to update a model in an online setting. In this article, I’ll demonstrate:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a Kafka instance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a producer that generates training data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a consumer that uses that training data to update an ML model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running Kafka with Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: My preferred method of working with Kafka locally is via `docker-compose`. If
    not already installed in your environment, you can follow instructions [here](https://docs.docker.com/compose/install/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Shuyi Yang’s [article on the topic](/kafka-docker-python-408baf0e1088) provides
    a high-level overview of this approach, and we can use a similar `docker-compose.yaml`
    file that creates local Kafka and Zookeeper instances and exposes Kafka on port
    9092:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'It also creates a Kafka topic called `ml_training_data` that we’ll use later.
    You can run the file by changing in the directory with the file above and running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: A Kafka producer for training data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, let’s install the Python libraries we’ll need to use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to create an artificial source of training data that’s written
    to our Kafka topic. For this, we’ll use the [River Python library](https://riverml.xyz/0.15.0/),
    which has easy-to-use APIs for streaming data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The code above uses the toy [River Phishing dataset](https://riverml.xyz/0.15.0/api/datasets/Phishing/)
    ([CC BY 4.0](http://archive.ics.uci.edu/dataset/379/website+phishing)), and sends
    labeled data observations to our Kafka topic one-at-a-time. This dataset contains
    features from web pages that are classified as phishing or not. The samples in
    the dataset are tuples that look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'First, run the producer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Then you should see the following in the console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: A Kafka consumer for training an ML model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Writing a simple Kafka consumer will let us read the data we’ve been pushing
    from the stream as it comes in, and use it to update the weights on our model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The code above initializes a simple ML model using River’s `LogisticRegression`
    class. Then, we continuously process events and use them to update our ML model
    — printing the ROCAUC metric for each sample added.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start training, run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: You should see something like the following in the console as the model learns
    observation by observation!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Both continuous training and online learning have *huge* potential in areas
    where real-time or near real-time labeled data can be made available to models
    making real-time decisions. All code and instructions are available in [this Github
    repo](https://github.com/kylegallatin/kafka-ml-training). More to come soon!
  prefs: []
  type: TYPE_NORMAL
