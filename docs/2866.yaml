- en: A Quick Guide on Normalization for Your NLP Model
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于 NLP 模型的归一化快速指南
- en: 原文：[https://towardsdatascience.com/a-quick-guide-on-normalization-for-your-nlp-model-2dbd7d2d42a7?source=collection_archive---------5-----------------------#2023-09-14](https://towardsdatascience.com/a-quick-guide-on-normalization-for-your-nlp-model-2dbd7d2d42a7?source=collection_archive---------5-----------------------#2023-09-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-quick-guide-on-normalization-for-your-nlp-model-2dbd7d2d42a7?source=collection_archive---------5-----------------------#2023-09-14](https://towardsdatascience.com/a-quick-guide-on-normalization-for-your-nlp-model-2dbd7d2d42a7?source=collection_archive---------5-----------------------#2023-09-14)
- en: Accelerate your model convergence and stabilize the training process with normalization
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过归一化加速模型收敛并稳定训练过程
- en: '[](https://medium.com/@vuphuongthao9611?source=post_page-----2dbd7d2d42a7--------------------------------)[![Thao
    Vu](../Images/9d44a2f199cdc9c29da72d9dc4971561.png)](https://medium.com/@vuphuongthao9611?source=post_page-----2dbd7d2d42a7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2dbd7d2d42a7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2dbd7d2d42a7--------------------------------)
    [Thao Vu](https://medium.com/@vuphuongthao9611?source=post_page-----2dbd7d2d42a7--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@vuphuongthao9611?source=post_page-----2dbd7d2d42a7--------------------------------)[![Thao
    Vu](../Images/9d44a2f199cdc9c29da72d9dc4971561.png)](https://medium.com/@vuphuongthao9611?source=post_page-----2dbd7d2d42a7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2dbd7d2d42a7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2dbd7d2d42a7--------------------------------)
    [Thao Vu](https://medium.com/@vuphuongthao9611?source=post_page-----2dbd7d2d42a7--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa836aac352ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quick-guide-on-normalization-for-your-nlp-model-2dbd7d2d42a7&user=Thao+Vu&userId=a836aac352ca&source=post_page-a836aac352ca----2dbd7d2d42a7---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2dbd7d2d42a7--------------------------------)
    ·7 min read·Sep 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2dbd7d2d42a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quick-guide-on-normalization-for-your-nlp-model-2dbd7d2d42a7&user=Thao+Vu&userId=a836aac352ca&source=-----2dbd7d2d42a7---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa836aac352ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quick-guide-on-normalization-for-your-nlp-model-2dbd7d2d42a7&user=Thao+Vu&userId=a836aac352ca&source=post_page-a836aac352ca----2dbd7d2d42a7---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2dbd7d2d42a7--------------------------------)
    ·7 min 阅读·2023年9月14日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2dbd7d2d42a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quick-guide-on-normalization-for-your-nlp-model-2dbd7d2d42a7&user=Thao+Vu&userId=a836aac352ca&source=-----2dbd7d2d42a7---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2dbd7d2d42a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quick-guide-on-normalization-for-your-nlp-model-2dbd7d2d42a7&source=-----2dbd7d2d42a7---------------------bookmark_footer-----------)![](../Images/664add61750b752d6992bc44d3645704.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2dbd7d2d42a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quick-guide-on-normalization-for-your-nlp-model-2dbd7d2d42a7&source=-----2dbd7d2d42a7---------------------bookmark_footer-----------)![](../Images/664add61750b752d6992bc44d3645704.png)'
- en: Photo by [Mattia Bericchia](https://unsplash.com/@mattiabericchia?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Mattia Bericchia](https://unsplash.com/@mattiabericchia?utm_source=medium&utm_medium=referral)
    提供，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Efficiently training deep learning models is challenging. The problem becomes
    more difficult with the recent growth of NLP models’ size and architecture complexity.
    To handle billions of parameters, more optimizations are proposed for faster convergence
    and stable training. One of the most remarkable techniques is normalization.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 高效地训练深度学习模型是具有挑战性的。随着 NLP 模型规模和架构复杂性的增长，问题变得更加困难。为了处理数十亿个参数，提出了更多优化方法，以实现更快的收敛和稳定的训练。其中一种最显著的技术是归一化。
- en: In this article, we will learn about some normalization techniques, how they
    work, and how they can be used for NLP deep models.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将学习一些归一化技术，它们的工作原理以及如何将它们用于 NLP 深度模型。
- en: Why not BatchNorm?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么不用 BatchNorm？
- en: BatchNorm [2] is an early normalization technique proposed to solve internal
    covariate shifts.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: BatchNorm [2] 是一种早期提出的归一化技术，旨在解决内部协变量偏移问题。
- en: To explain in simple terms, an internal covariate shift occurs when there is
    a change in the layer’s input data distribution. When the neural networks are
    forced to fit different data distributions, the gradient update changes dramatically
    between batches. Therefore, the models take longer to adjust, learn the correct
    weights and converge. The problem gets worse as the model size grows.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，当层的输入数据分布发生变化时，会出现内部协变量偏移。当神经网络被迫适应不同的数据分布时，梯度更新在不同批次之间会发生剧烈变化。因此，模型调整、学习正确权重和收敛所需的时间更长。随着模型规模的增长，这个问题会变得更严重。
- en: Initial solutions include using a small learning rate (so the impact of data…
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 初步解决方案包括使用较小的学习率（以便数据的影响...
