- en: 'RLHF: Reinforcement Learning from Human Feedback'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/rlhf-reinforcement-learning-from-human-feedback-faa5ff4761d1?source=collection_archive---------0-----------------------#2023-10-11](https://towardsdatascience.com/rlhf-reinforcement-learning-from-human-feedback-faa5ff4761d1?source=collection_archive---------0-----------------------#2023-10-11)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'ChatGPT’s success ingredient: The Instruction Data.'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://automata88.medium.com/?source=post_page-----faa5ff4761d1--------------------------------)[![Ms
    Aerin](../Images/21335c7f04e64fa34585950f038f96d0.png)](https://automata88.medium.com/?source=post_page-----faa5ff4761d1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----faa5ff4761d1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----faa5ff4761d1--------------------------------)
    [Ms Aerin](https://automata88.medium.com/?source=post_page-----faa5ff4761d1--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1d8994ad0efc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frlhf-reinforcement-learning-from-human-feedback-faa5ff4761d1&user=Ms+Aerin&userId=1d8994ad0efc&source=post_page-1d8994ad0efc----faa5ff4761d1---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----faa5ff4761d1--------------------------------)
    ·24 min read·Oct 11, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffaa5ff4761d1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frlhf-reinforcement-learning-from-human-feedback-faa5ff4761d1&user=Ms+Aerin&userId=1d8994ad0efc&source=-----faa5ff4761d1---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffaa5ff4761d1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frlhf-reinforcement-learning-from-human-feedback-faa5ff4761d1&source=-----faa5ff4761d1---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT has captivated the world with its impressive capabilities. But how did
    it get so smart?
  prefs: []
  type: TYPE_NORMAL
- en: I recently spoke to one of my former coworkers, a software engineer I respect
    a lot, and I noticed that he believes ChatGPT is a manifestation of AGI, pointing
    to its ability to simplify complex topics to a six-year-old’s level of understanding
    as evidence. While I don’t entirely disagree with him on its unreasonable intelligence,
    I felt compelled to put down my thoughts. In this article, I’d like to emphasize
    that the magic of ChatGPT is heavily reliant on its training data.
  prefs: []
  type: TYPE_NORMAL
- en: Carefully curated instruction data is the key to ChatGPT’s human-like abilities.
    Things like explaining concepts to a 6-year-old, turning a resume into a LinkedIn
    profile, brainstorming ideas with you, etc., didn’t just emerge—they were deliberately
    encoded into the model in the form of training data.
  prefs: []
  type: TYPE_NORMAL
- en: Like everyone else, this is the first time I am experiencing closed research.
    Since I was in college, all frontier research has been open and peer-reviewed,
    until recently. And I believe openness ultimately advances science more than…
  prefs: []
  type: TYPE_NORMAL
