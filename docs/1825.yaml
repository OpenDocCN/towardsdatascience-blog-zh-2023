- en: Large Language Models in Molecular Biology
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大型语言模型在分子生物学中的应用
- en: 原文：[https://towardsdatascience.com/large-language-models-in-molecular-biology-9eb6b65d8a30?source=collection_archive---------0-----------------------#2023-06-02](https://towardsdatascience.com/large-language-models-in-molecular-biology-9eb6b65d8a30?source=collection_archive---------0-----------------------#2023-06-02)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/large-language-models-in-molecular-biology-9eb6b65d8a30?source=collection_archive---------0-----------------------#2023-06-02](https://towardsdatascience.com/large-language-models-in-molecular-biology-9eb6b65d8a30?source=collection_archive---------0-----------------------#2023-06-02)
- en: Deciphering the language of biology, from DNA to cells to human health
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 破解生物学的语言，从DNA到细胞再到人类健康
- en: '[](https://medium.com/@serafimbatzoglou?source=post_page-----9eb6b65d8a30--------------------------------)[![Serafim
    Batzoglou](../Images/8abba787ae344663a196cfce707a8718.png)](https://medium.com/@serafimbatzoglou?source=post_page-----9eb6b65d8a30--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9eb6b65d8a30--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9eb6b65d8a30--------------------------------)
    [Serafim Batzoglou](https://medium.com/@serafimbatzoglou?source=post_page-----9eb6b65d8a30--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@serafimbatzoglou?source=post_page-----9eb6b65d8a30--------------------------------)[![Serafim
    Batzoglou](../Images/8abba787ae344663a196cfce707a8718.png)](https://medium.com/@serafimbatzoglou?source=post_page-----9eb6b65d8a30--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9eb6b65d8a30--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9eb6b65d8a30--------------------------------)
    [Serafim Batzoglou](https://medium.com/@serafimbatzoglou?source=post_page-----9eb6b65d8a30--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fccf342949c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flarge-language-models-in-molecular-biology-9eb6b65d8a30&user=Serafim+Batzoglou&userId=ccf342949c4&source=post_page-ccf342949c4----9eb6b65d8a30---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9eb6b65d8a30--------------------------------)
    ·40 min read·Jun 2, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9eb6b65d8a30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flarge-language-models-in-molecular-biology-9eb6b65d8a30&user=Serafim+Batzoglou&userId=ccf342949c4&source=-----9eb6b65d8a30---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fccf342949c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flarge-language-models-in-molecular-biology-9eb6b65d8a30&user=Serafim+Batzoglou&userId=ccf342949c4&source=post_page-ccf342949c4----9eb6b65d8a30---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9eb6b65d8a30--------------------------------)
    · 40分钟阅读 · 2023年6月2日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9eb6b65d8a30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flarge-language-models-in-molecular-biology-9eb6b65d8a30&user=Serafim+Batzoglou&userId=ccf342949c4&source=-----9eb6b65d8a30---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9eb6b65d8a30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flarge-language-models-in-molecular-biology-9eb6b65d8a30&source=-----9eb6b65d8a30---------------------bookmark_footer-----------)![](../Images/bdf1de98f9a4a97280c1fe604bfe3c5e.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9eb6b65d8a30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flarge-language-models-in-molecular-biology-9eb6b65d8a30&source=-----9eb6b65d8a30---------------------bookmark_footer-----------)![](../Images/bdf1de98f9a4a97280c1fe604bfe3c5e.png)'
- en: '**Image by author, created by Midjourney prompted with “DNA”.**'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者提供的图像，使用Midjourney生成，提示为“DNA”。**'
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: Will we ever decipher the language of molecular biology? Here, I argue that
    we are just a few years away from having accurate in silico models of the primary
    biomolecular information highway — from DNA to gene expression to proteins — that
    rival experimental accuracy and can be used in medicine and pharmaceutical discovery.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们是否能破解分子生物学的语言？在这里，我认为我们距离拥有准确的计算模型，模拟从DNA到基因表达再到蛋白质的主要生物分子信息通道只有几年时间，这些模型能与实验准确度相媲美，并可用于医学和药物发现。
- en: Since I started my PhD in 1996, the computational biology community had embraced
    the mantra, “biology is becoming a computational science.” Our ultimate ambition
    has been to predict the activity of biomolecules within cells, and cells within
    our bodies, with precision and reproducibility akin to engineering disciplines.
    We have aimed to create computational models of biological systems, enabling accurate
    biomolecular experimentation in silico. The recent strides made in deep learning
    and particularly large language models (LLMs), in conjunction with affordable
    and large-scale data generation, are propelling this aspiration closer to reality.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: LLMs, already proven masters at modeling human language, have demonstrated extraordinary
    feats like passing the bar exam, writing code, crafting poetry in diverse styles,
    and arguably rendering the Turing test obsolete. However, their potential for
    modeling biomolecular systems may even surpass their proficiency in modeling human
    language. Human language mirrors human thought providing us with an inherent advantage,
    while molecular biology is intricate, messy, and counterintuitive. Biomolecular
    systems, despite their messy constitution, are robust and reproducible, comprising
    millions of components interacting in ways that have evolved over billions of
    years. The resulting systems are marvelously complex, beyond human comprehension.
    Biologists often resort to simplistic rules that work only 60% or 80% of the time,
    resulting in digestible but incomplete narratives. Our capacity to generate colossal
    biomolecular data currently outstrips our ability to understand the underlying
    systems.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: This article will provide an overview of some recent breakthroughs of deep learning-based
    language models in molecular biology. We will discuss how these advances will
    converge with the direct training of LLMs on large-scale biomolecular and population
    health data in the coming years and propel the field forward. Given that LLMs
    and deep learning are familiar to a broader audience than is molecular biology,
    we begin with a brief overview of LLMs, continue with a more detailed introduction
    to molecular biology, then proceed to describe a few recent LLM advances in molecular
    biology, and finally glance at the future.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: 'At the core of our discussion is an ongoing paradigm shift in biology. Despite
    the often overused term “paradigm shift,” it is genuinely fitting here. Traditionally,
    biology has been hypothesis-driven: researchers identify patterns, formulating
    hypotheses, designing experiments or studies to test these hypotheses, and adjusting
    their theories based on the results. This approach is progressively being replaced
    by a data-driven modeling methodology. In this emerging paradigm, researchers
    start with hypothesis-free, large-scale data generation, then train a model such
    as an LLM or incorporate the data into an existing LLM. Once the LLM can accurately
    model the system, approaching the fidelity seen between experimental replicates,
    researchers can interrogate the LLM to extract insights about the system and discern
    the underlying biological principles. This shift will be increasingly pronounced
    and allow accurate modeling of biomolecular systems at a granularity that goes
    well beyond human capacity.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Large Language Models
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/9d230a0fc0ea121c00c7ecb542663f46.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
- en: '**Image by author, created with Midjourney.**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: A Large Language Model (LLM) is a type of neural network that acquires the ability
    to generate text mirroring human language by scrutinizing vast amounts of textual
    data. It operates on the principle of “self-supervision,” where the model learns
    to predict the subsequent word in a sentence based on the preceding words. This
    process allows the LLM to identify patterns, relationships, and context within
    the text, equipping it to respond to queries, generate novel content, and even
    formulate predictions. LLMs can be viewed as an advanced form of autocomplete,
    predicting the next word you are likely to type but with a surprising ability
    to behave like they have a solid comprehension of language, context, and meaning.
    This enables them to generate coherent and knowledgeable responses across diverse
    topics.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: 'The evolution of language models has seen each new generation boasting enhanced
    modeling capabilities. Let’s briefly traverse the primary types of language models
    and their unique features:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '**Word grams:** These rudimentary models predict the next word in a sentence
    based on the frequency of word pairs or word bags (unordered sets of words) in
    the training data. They disregard context or word order, leading to less coherent
    predictions. Generating text using these models results in incoherent sentences
    that have little resemblance to human text.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**CNNs (Convolutional Neural Networks):** These models analyze text data by
    considering relationships between adjacent words in a fixed window. The window
    can be quite wide, using techniques like dilation. While CNNs excel at identifying
    local patterns, they fall short in capturing long-range dependencies or comprehending
    complex sentence structures.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**LSTMs (Long Short-Term Memory networks):** These are a variant of Recurrent
    Neural Networks (RNN) capable of storing and processing information from earlier
    parts of a text. LSTMs outperform CNNs in understanding context and managing long-range
    dependencies, but they still falter with complex sentences and long text.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**LSTM（长短期记忆网络）：** 这些是能够存储和处理来自文本早期部分信息的递归神经网络（RNN）的变体。LSTM 在理解上下文和处理长距离依赖方面优于
    CNN，但在复杂句子和长文本方面仍然存在不足。'
- en: '**Attention Mechanisms** enable models to concentrate on pertinent parts of
    the input when making predictions. A number of attention “heads” allow the model
    to focus on different parts of the previous text when predicting the next word.
    They function similarly to how you would revisit key points or details in a lengthy
    article, allowing the model to refer back to relevant parts of the text and incorporate
    that information into the current context. Transformers are a class of language
    models that implement attention mechanisms.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**注意力机制** 使模型在进行预测时能够集中于输入的相关部分。一些注意力“头”允许模型在预测下一个词时关注前面文本的不同部分。它们的功能类似于你在长篇文章中重新访问关键点或细节的方式，使模型能够回顾文本中的相关部分，并将这些信息融入当前的上下文中。变换器是一类实现注意力机制的语言模型。'
- en: '**Large Language Models (LLMs):** models such as GPT-3 are transformers that
    leverage attention mechanisms and are trained on vast amounts of data. Their considerable
    size facilitates the learning of intricate patterns, relationships, and context
    within the text. LLMs represent the most advanced language models presently available,
    capable of generating remarkably accurate and coherent responses across a broad
    spectrum of topics.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**大型语言模型（LLMs）：** 如 GPT-3 这样的模型是利用注意力机制的变换器，并在大量数据上进行训练。它们的巨大规模使得学习文本中的复杂模式、关系和上下文成为可能。LLMs
    代表了当前最先进的语言模型，能够在广泛的主题上生成非常准确和连贯的回应。'
- en: 'Two LLMs that use the transformer architecture and which introduced major breakthroughs
    in the field deserve special mention: BERT and the GPT series.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个使用变换器架构并在该领域引入重大突破的 LLM 值得特别提及：BERT 和 GPT 系列。
- en: '**BERT (Bidirectional Encoder Representations from Transformers)** (Devlin
    et al. 2018) is a series of LLMs introduced by Google in 2018 and open sourced,
    with the code available on GitHub and a number of pre-trained models released.
    BERT is trained using **masked language modeling**. The idea is to hide or “mask”
    some percentage of the input tokens at random, and then predict those masked tokens.
    This forces the model to understand the context from both the left and the right
    sides of the input (hence “bidirectional”). BERT training also uses a next sentence
    prediction task. During training, the model is given pairs of sentences and has
    to predict whether the second sentence in the pair is the next sentence in the
    original document.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**BERT（双向编码器表示从变换器）**（Devlin 等，2018）是谷歌在 2018 年推出的一系列 LLM，并开源，代码可在 GitHub 上获取，并发布了多个预训练模型。BERT
    使用 **掩蔽语言建模** 进行训练。其思想是随机隐藏或“掩蔽”输入标记的某些百分比，然后预测这些被掩蔽的标记。这迫使模型从输入的左右两侧理解上下文（因此称为“双向”）。BERT
    训练还使用了下一句预测任务。在训练过程中，模型会接收到一对句子，并必须预测该对句子中的第二个句子是否是原始文档中的下一句。'
- en: '**GPT (Generative Pretrained Transformer)** is a series of LLMs introduced
    by OpenAI. Unlike BERT, GPT is trained using the traditional language modeling
    task of autocomplete: predict the next word in a sentence. Unlike BERT, GPT only
    attends to the left context (or previous tokens) during training, hence it is
    unidirectional. GPT is a generative model that is particularly strong in tasks
    involving text generation, such as writing essays, generating poetry, or completing
    sentences. The latest generation of GPT, GPT-4, has shown remarkable performance
    across a variety of tasks in multiple domains, leading to the characterization
    of it as exhibiting some sparks of general intelligence (Bubeck et al. 2023).
    It should be noted that not everyone agrees that GPT and similar LLMs show signs
    of general intelligence. To quote Rodney Brooks, “stop confusing performance with
    competence” ([https://spectrum.ieee.org/amp/gpt-4-calm-down-2660261157](https://spectrum.ieee.org/amp/gpt-4-calm-down-2660261157)).
    However, as we will see in this article, this is not a limitation for their effective
    application in molecular biology.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**GPT（生成预训练变换器）** 是由OpenAI推出的一系列LLM。与BERT不同，GPT使用传统的语言建模任务——自动补全进行训练：预测句子中的下一个词。与BERT不同，GPT在训练过程中只关注左侧上下文（或先前的标记），因此它是单向的。GPT是一个生成模型，在涉及文本生成的任务中表现特别强大，如写作、生成诗歌或完成句子。最新一代GPT，即GPT-4，在多个领域的各种任务中表现出色，导致它被描述为展现出一些通用智能的火花（Bubeck等，2023）。值得注意的是，并不是每个人都认为GPT和类似的LLM表现出通用智能。引用Rodney
    Brooks的话，“不要把表现与能力混淆” ([https://spectrum.ieee.org/amp/gpt-4-calm-down-2660261157](https://spectrum.ieee.org/amp/gpt-4-calm-down-2660261157))。然而，正如我们将在本文中看到的，这并不是它们在分子生物学中有效应用的限制。'
- en: The Genetic Dogma
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 遗传法则
- en: 'The biological trajectory of a human or any other organism, from embryonic
    development to the entirety of their lifespan, is a complex interplay between
    genetics and environment: a dialogue between an individual’s DNA and the environment
    the individual is exposed to (Figure 1).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 人类或其他任何生物的生物轨迹，从胚胎发育到其整个生命周期，是遗传与环境之间复杂的相互作用：个体的DNA与个体所暴露的环境之间的对话（图1）。
- en: '![](../Images/77b9c2729288937c905867147eb77dee.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/77b9c2729288937c905867147eb77dee.png)'
- en: '**Figure 1\. Genotype-Phenotype-Environment.** The phenotypes of an individual
    are a dialogue between the individual’s DNA and the environment. Image by author.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**图1\. 基因型-表型-环境。** 个体的表型是个体的DNA与环境之间的对话。图像由作者提供。'
- en: 'The central dogma of molecular biology describes the flow of genetic information
    within living organisms. The source of this genetic information is our DNA, an
    exact replica of which is harbored in the nucleus of every cell in our body. Human
    DNA comprises about 3 billion nucleotides arranged in 23 chromosomes, with 22
    being autosomes and one being the sex chromosome, either X or Y. Each individual
    possesses two nearly identical copies of the human genome: one inherited by their
    mother and one by their father. Every one of the approximately 30 trillion cells
    in our body retains within the nucleus a nearly identical copy of our maternal
    and paternal genome.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 分子生物学的中心法则描述了遗传信息在生物体内的流动。这些遗传信息的来源是我们的DNA，它在我们体内每个细胞的核内都有一个精确的副本。人类DNA由约30亿个核苷酸组成，排列在23条染色体上，其中22条是常染色体，1条是性染色体，分别为X或Y。每个人拥有两个几乎相同的人类基因组副本：一个由母亲遗传，一个由父亲遗传。我们体内大约30万亿个细胞中的每一个都在其细胞核内保留了一个几乎相同的母系和父系基因组副本。
- en: '![](../Images/498b5e952af7806d55ba5bbc9177c6ff.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/498b5e952af7806d55ba5bbc9177c6ff.png)'
- en: '**Figure 2\. A human chromosome.** The chromatin is tightly packed in hierarchical
    coil structures. At the bottom level, 146 nucleotide pairs are wrapped around
    a histone, resembling a bead. Histones are then coiled and supercoiled to form
    a compact chromosome that fits within the nucleus of a cell. Image from VectorMine,
    iStock Content License Agreement.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**图2\. 人类染色体。** 染色质以层级螺旋结构紧密包装。在底层，146对核苷酸缠绕在组蛋白上，类似于珠子。组蛋白然后被螺旋状缠绕并超螺旋形成一个紧凑的染色体，这个染色体适合于细胞核内。图像来源于VectorMine，iStock内容许可协议。'
- en: Within the genome lie around 20,000 genes, which are DNA segments accountable
    for protein synthesis. Approximately 1% of the genome codes for proteins, while
    the remainder comprises regions controlling gene expression, regions within genes
    that don’t code for proteins, regions contributing to DNA structure, and “junk”
    regions of selfish DNA that have “learned” to self-replicate.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 基因组中包含大约20,000个基因，这些基因是负责蛋白质合成的DNA片段。基因组中约有1%编码蛋白质，其余部分包括控制基因表达的区域、基因内部不编码蛋白质的区域、对DNA结构有贡献的区域，以及“垃圾”区域，这些自私的DNA“学会”了自我复制。
- en: The central dogma of molecular biology maps out the molecular information flow
    from the genome to the expression of genes and the subsequent production of proteins,
    which are fundamental building blocks of life.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 分子生物学的中心法则描述了从基因组到基因表达以及随后的蛋白质生产的分子信息流，这是生命的基本构件。
- en: '![](../Images/07c93465bafcd44f5add48dad168ed08.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/07c93465bafcd44f5add48dad168ed08.png)'
- en: '**Figure 3\. The central dogma of molecular biology.** Our DNA is composed
    of about 20,000 genes and intergenic regions. Genes are expressed within cells
    by a process of **transcription**, which copies the gene into a single-stranded
    molecule, the mRNA, and **translation**, which translates the mRNA sequence into
    a protein sequence composed of amino acids. Thereby, the 4-letter nucleotide code
    of the DNA segment is translated into a 20-amino acid code of the protein sequence.
    The protein sequence then folds in 3D to form a functional protein structure.
    Image by author.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**图3. 分子生物学的中心法则。** 我们的DNA由大约20,000个基因和基因间区域组成。基因在细胞内通过**转录**过程被表达，将基因复制成单链分子mRNA，以及**翻译**过程，将mRNA序列翻译成由氨基酸组成的蛋白质序列。因此，DNA片段的4个字母的核苷酸代码被翻译成蛋白质序列的20种氨基酸代码。然后，蛋白质序列在三维空间中折叠成功能性蛋白质结构。图片由作者提供。'
- en: 'Protein synthesis encompasses three primary steps: **transcription** (Figure
    3), **splicing** (Figure 4), and **translation**. During transcription, a DNA
    segment corresponding to a gene serves as a template that is replicated into a
    molecule known as messenger RNA (mRNA). The mRNA molecule undergoes splicing,
    a process wherein certain segments of the molecule are excised, or spliced out,
    and the remaining segments are joined together to form the mature mRNA. The excised
    regions are known as **introns**, and the kept regions, the **exons**, constitute
    the protein-coding part of the mRNA. Each mature mRNA is assembled from an average
    of 7 exons, although the count varies in humans from 1 to 79 for the human dystrophin
    gene. Splicing is vital in higher organisms because a single gene can yield multiple
    different proteins by assembling different exon combinations during splicing.
    The 20,000 genes give rise to approximately 70,000 known standard splice forms
    and a substantially larger number of rare or aberrant splice forms. The expression
    timing of each protein variant is part of a cell’s molecular control toolkit.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 蛋白质合成包括三个主要步骤：**转录**（图3）、**剪接**（图4）和**翻译**。在转录过程中，与基因对应的DNA片段作为模板被复制成名为信使RNA（mRNA）的分子。mRNA分子经过剪接，这一过程将某些片段剪切掉或剪接出来，其余片段被连接在一起形成成熟的mRNA。被剪切的区域称为**内含子**，而保留的区域，即**外显子**，构成了mRNA的蛋白质编码部分。每个成熟的mRNA由平均7个外显子组装而成，尽管在人体内的数量从1到79不等，例如人类的肌营养不良蛋白基因。剪接在高级生物中至关重要，因为一个基因可以通过在剪接过程中组装不同的外显子组合，产生多种不同的蛋白质。20,000个基因产生了大约70,000种已知的标准剪接形式，以及大量的稀有或异常剪接形式。每种蛋白质变体的表达时机是细胞分子控制工具包的一部分。
- en: '![](../Images/c368887b663be0f122bd16f593741ebe.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c368887b663be0f122bd16f593741ebe.png)'
- en: '**Figure 4\. Splicing of mRNA.** In humans and other eukaryotic organisms,
    an important process between transcription and translation is splicing. Certain
    regions of the mRNA are cut out, called the introns, and the rest are glued together
    in order, called the exons. The same gene can be spliced in multiple ways, leading
    to alternative splicing forms of the resulting protein, and contributing to the
    diversity of proteins. Image by author.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**图4. mRNA的剪接。** 在人类和其他真核生物中，转录与翻译之间的一个重要过程是剪接。mRNA的某些区域被切除，这些区域称为内含子，其余部分则按顺序粘合在一起，称为外显子。相同的基因可以以多种方式进行剪接，从而产生不同的剪接形式，增加了蛋白质的多样性。图片由作者提供。'
- en: Following transcription, the mRNA is transported to the cell’s protein-synthesizing
    machinery, the **ribosome**, where translation takes place. During translation,
    the mRNA sequence is decoded in groups of three nucleotides, known as codons.
    Each codon corresponds to exactly one of the 20 amino acids that form the building
    blocks of proteins. These amino acids are linked together in a chain to form a
    protein sequence, which subsequently folds into a functional, three-dimensional
    protein structure.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 转录后，mRNA被运送到细胞的蛋白质合成机制，即**核糖体**，在那里发生翻译。在翻译过程中，mRNA序列按三核苷酸一组进行解码，这些组称为密码子。每个密码子对应于20种氨基酸中的一种，这些氨基酸是蛋白质的基本构建块。这些氨基酸被链接在一起形成蛋白质序列，随后折叠成一个功能性三维蛋白质结构。
- en: Proteins are the building blocks of life, playing pivotal roles in virtually
    every biological process. They provide the structural components of cells, act
    as enzymes to catalyze chemical reactions, and facilitate communication and transportation
    within cells.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 蛋白质是生命的基本构件，在几乎所有生物过程中的作用都至关重要。它们提供了细胞的结构组件，作为酶催化化学反应，并在细胞内部促进沟通和运输。
- en: '**Gene regulation** (Figure 5) pertains to the intricate processes that dictate
    when, where, and in what quantity genes are expressed within a cell. This ensures
    the timely production of the right proteins in the right quantities. Gene regulation
    takes place at various levels, including the structuring of chromatin, chemical
    modifications, and through the action of specific proteins known as transcription
    factors.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**基因调控**（图5）涉及决定基因在细胞内何时、何地以及以何种数量表达的复杂过程。这确保了正确的蛋白质在正确的数量上及时生产。基因调控发生在不同的层次上，包括染色质的结构化、化学修饰以及特定蛋白质（称为转录因子）的作用。'
- en: '![](../Images/1fdcf591db6937930e4bf1bb5e9fb86c.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1fdcf591db6937930e4bf1bb5e9fb86c.png)'
- en: '**Figure 5\. Gene Regulation.** The promoter of a gene, the region upstream
    (to the left) of the gene start contains control elements including motifs that
    bind certain proteins called transcription factors. Those play a role in recruiting
    the RNA polymerase and controlling when, where, and to what amount the gene will
    be expressed. Open chromatin is required for transcription to take place. Image
    adapted from a presentation by Anshul Kundaje, including here with permission.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**图5. 基因调控。** 基因的启动子区域，即基因起始点的上游（左侧）区域，包含包括与某些称为转录因子的蛋白质结合的基序在内的控制元素。这些转录因子在招募RNA聚合酶和控制基因的表达时间、位置和数量方面发挥作用。开放的染色质是转录发生所必需的。图片改编自Anshul
    Kundaje的演示文稿，并在此处获得许可。'
- en: '**Transcription factors (TFs)** are proteins that are instrumental in gene
    regulation. They bind to distinct DNA sequences near or within genes, known as
    transcription factor binding sites, thereby influencing the recruitment of RNA
    polymerase, the enzyme tasked with mRNA synthesis. Consequently, transcription
    factors modulate the expression of target genes, guaranteeing the appropriate
    gene expression in response to diverse cellular signals and environmental conditions.
    Transcription factors are themselves modulated by transcription factors, forming
    complex gene regulatory pathways.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**转录因子（TFs）** 是在基因调控中发挥重要作用的蛋白质。它们结合到基因附近或基因内的特定DNA序列上，这些序列被称为转录因子结合位点，从而影响RNA聚合酶的招募，RNA聚合酶是负责mRNA合成的酶。因此，转录因子调节目标基因的表达，确保基因在响应不同细胞信号和环境条件下的适当表达。转录因子本身也受到转录因子的调节，形成复杂的基因调控途径。'
- en: '**Promoters and enhancers** are DNA regions that play a role in gene expression
    control. Promoters are located adjacent to the start of a gene (upstream, or to
    the left of the gene start, in the chemical direction of DNA), while enhancers
    are more distant regulatory elements situated within introns or between genes.
    Both promoters and enhancers harbor several transcription factor binding sites.
    With the assistance of transcription factors, a gene’s promoter and enhancers
    form three-dimensional structures that recruit and regulate the RNA polymerase
    responsible for mRNA synthesis.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**启动子和增强子** 是在基因表达调控中发挥作用的DNA区域。启动子位于基因起始点的邻近区域（在化学方向上位于基因起始点的上游或左侧），而增强子则是较远的调控元件，位于内含子内或基因间。启动子和增强子都含有多个转录因子结合位点。在转录因子的协助下，基因的启动子和增强子形成三维结构，招募并调控负责mRNA合成的RNA聚合酶。'
- en: '**Chromatin structure** (Figure 2) is an amalgamation of DNA and proteins (histones)
    that constitute our chromosomes. To fit compactly within each cell’s nucleus,
    DNA is wound around proteins known as histones. Histones are tetramers, structures
    formed by assembling four copies of the histone protein. Each such structure wraps
    around 146 nucleotide pairs of DNA, creating a rosary bead-like structure that
    subsequently folds into a higher-order helical structure, the chromatin. Chromatin
    organization determines which DNA regions are accessible for gene expression.
    For gene expression to occur, chromatin must be unfolded. Conversely, tightly
    packed chromatin prevents gene expression.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**染色质结构**（图 2）是DNA和蛋白质（组蛋白）的混合物，组成了我们的染色体。为了紧凑地容纳在每个细胞的细胞核中，DNA绕着被称为组蛋白的蛋白质缠绕。组蛋白是由四个组蛋白蛋白质副本组装成的四聚体结构。每个这样的结构绕着146对核苷酸的DNA缠绕，形成一种念珠状的结构，随后折叠成更高阶的螺旋结构，即染色质。染色质的组织决定了哪些DNA区域对基因表达是可及的。要发生基因表达，染色质必须展开。相反，紧密打包的染色质则阻止基因表达。'
- en: '**Histone modifications** refer to chemical modifications, such as acetylation
    or methylation, that can affect the histone beads, thereby influencing chromatin
    structure and gene accessibility. These modifications can either promote or inhibit
    gene expression, contingent upon the type and location of the modification. They
    are also part of the histone code, a sort of epigenetic code, i.e., an additional
    layer of code superimposed on the genetic code inscribed in the DNA. (“epi-” is
    a Greek root signifying “on top of”.)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**组蛋白修饰** 是指一些化学修饰，例如乙酰化或甲基化，这些修饰可以影响组蛋白珠子，从而影响染色质结构和基因可及性。这些修饰可以促进或抑制基因表达，具体取决于修饰的类型和位置。它们也是组蛋白密码的一部分，组蛋白密码是一种表观遗传密码，即在DNA遗传密码上叠加的额外编码层。（“epi-”是一个希腊词根，意为“在……之上”。）'
- en: '**DNA methylation** is a chemical modification where a methyl group is added
    to the DNA molecule, often at specific cytosine bases. Methylation can influence
    gene expression by affecting the binding of transcription factors or changing
    the chromatin structure, making it more compact and less accessible for transcription.
    Methylation and other DNA chemical modifications are also part of the epigenetic
    code. Gene regulation is a dynamic process specific to each cell type. Different
    cells within our body exhibit unique gene expression profiles, enabling them to
    perform specialized functions. Through precise control of gene expression, cells
    can respond to environmental stimuli, sustain homeostasis, and execute the complex
    processes essential for life.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**DNA甲基化** 是一种化学修饰，其中一个甲基基团被添加到DNA分子上，通常在特定的胞嘧啶碱基处。甲基化可以通过影响转录因子的结合或改变染色质结构来影响基因表达，使其更加紧凑，减少转录的可及性。甲基化和其他DNA化学修饰也是表观遗传密码的一部分。基因调控是一个动态过程，特定于每种细胞类型。我们身体内的不同细胞展示了独特的基因表达谱，使它们能够执行特化的功能。通过精确控制基因表达，细胞可以响应环境刺激，维持稳态，并执行生命所需的复杂过程。'
- en: '**Bidirectional flow of information.** Traditionally, the central dogma is
    described as a unidirectional flow of information: DNA to RNA to protein. However,
    there are exceptions to this and our knowledge of the underlying mechanisms is
    still evolving, a topic that is beyond the scope of this brief review. It is worth
    mentioning some exceptions. (1) The discovery of reverse transcription, a process
    where RNA is converted back into DNA, challenged the unidirectionality of the
    central dogma. This process is facilitated by the enzyme reverse transcriptase
    and is common in retroviruses, such as HIV. (2) DNA can also be transcribed into
    RNA molecules other than mRNA, such as transfer RNA (tRNA), ribosomal RNA (rRNA),
    and other types of non-coding RNA, adding another level of complexity to the flow
    of genetic information. (3) Finally, there’s a growing body of evidence about
    the role of epigenetics by mechanisms such as DNA methylation and histone modification,
    and research into the extent to which epigenetic changes can be inherited.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Variation in our DNA
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every individual is biologically shaped by the complex interplay between their
    DNA and environmental influences throughout their lifetime, from conception to
    the present moment. Our DNA, coupled with the human female reproductive system,
    ensures we are born as humans rather than, for instance, chimpanzees, whose DNA
    is 98.8% identical to ours. Any two humans share more than 99.9% identical DNA.
    Yet, our DNA variants account for the heritability of all our traits, including
    the genetic contribution to health and disease.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '**Origins of DNA variants.** The primary mechanism for introducing DNA variants
    is through mutations between the genomes of two parents and the germline genomes
    that both parents contribute to the offspring’s genome. In humans, a child’s DNA
    contains approximately 50–100 mutations compared to the parents’ DNA; the majority
    of these are contributed by the father, with a correlation to the father’s age
    (Kong et al. 2012). Germline mutations primarily drive genetic variation, accounting
    for our differences from species such as chimpanzees and squirrels. Most of these
    new variants are benign, either having no effect on the phenotype or some impact
    that is neither advantageous nor disadvantageous. A smaller fraction can be deleterious,
    particularly if they damage a functional region, which could be protein-coding,
    regulatory, or even related to chromatin structure. An even smaller fraction might
    be beneficial, such as a variant that fortuitously improves a functional element.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '**Selection.** Deleterious variants, or harmful genetic alterations, often
    render an organism less “fit” in evolutionary terms, with fitness defined as the
    expected number of surviving offspring. Over time, harmful variants tend to be
    statistically eliminated from the population. Consequently, genetic variations
    common in humans — those found in at least 1% of the population — are either benign
    or contribute to diseases that manifest later in life, beyond the reach of natural
    selection. This is also why rare variants are generally more likely to be harmful
    than common ones.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**选择。** 有害变异，或有害的基因突变，通常使一个有机体在进化上“适应性”降低，适应性定义为预期的存活后代数量。随着时间的推移，有害变异倾向于从种群中被统计学上淘汰。因此，在人类中常见的遗传变异——那些在至少1%的人群中发现的变异——要么是良性的，要么是导致晚年才表现出来的疾病，这些变异超出了自然选择的范围。这也是为什么稀有变异通常比常见变异更可能是有害的原因。'
- en: '**Coalescence and DNA sequence conservation.** Across longer evolutionary times,
    such as those separating humans and chimpanzees or dogs, the effects of selection
    on DNA are highly informative. Take any two individuals today. For example, me
    and my dog, Murzik (a maltipoo). Take any DNA region that is shared, such as any
    of the majority of human genes, which we share with dogs. Take my maternal copy
    of that gene, and Murzik’s (say) paternal copy of that gene. They have a similarity
    of about 84%. Now if we trace this region back in history (my mother inherited
    it from her mother (say), she inherited it from her father, and so on; Murzik’s
    father inherited it from his mother (say), she inherited it from her mother, and
    so on), eventually the two regions **coalesce**: there is an ancestor mammalian
    individual that had two kids that both inherited the precise same DNA piece: one
    of these kids led to me, and another one led to Murzik. The 16% sequence differences
    reflect all the germline mutations that took place across millions of generations
    that separate us from this common ancestral great grandparent. Importantly, mutations
    that took place in important parts of the gene tended to make individuals less
    fit, and are less likely to have led to me or to Murzik today. Therefore, the
    more conserved parts of the DNA region are more likely to be functionally important,
    and the less conserved parts are more likely to be tolerant of mutations.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**共alescence和DNA序列保守性。** 在较长的进化时间跨度中，如人类与黑猩猩或狗之间的时间，选择对DNA的影响非常有意义。以今天的任何两个人为例。例如，我和我的狗Murzik（一只马尔济斯和贵宾犬混种）。取任何共享的DNA区域，例如我们与狗共享的大多数人类基因。取我母系的那一个基因副本，以及Murzik（假设）的父系那一个基因副本。它们的相似度约为84%。现在如果我们追溯这个区域的历史（我母亲从她的母亲那里继承了它，她又从她的父亲那里继承，以此类推；Murzik的父亲从他的母亲那里继承了它，她又从她的母亲那里继承，以此类推），最终这两个区域会**融合**：存在一个祖先哺乳动物个体，他有两个孩子都继承了完全相同的DNA片段：其中一个孩子导致了我，另一个孩子导致了Murzik。16%的序列差异反映了数百万代之间发生的所有生殖系突变，这些突变使我们与这个共同的祖先曾祖父分离。重要的是，发生在基因重要部分的突变往往使个体适应性降低，因此不太可能导致今天的我或Murzik。因此，DNA区域中更保守的部分更可能具有功能重要性，而不那么保守的部分更可能耐受突变。'
- en: '![](../Images/05e7c79b466d86a650c891d2d38fe12b.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05e7c79b466d86a650c891d2d38fe12b.png)'
- en: '**Figure 6\. Cost of human genome seequencing.** The plot does not include
    the last two years, where additional major drops in cost took place. The cost
    today with the newest instruments is as low as $200\. Wetterstrand KA. DNA Sequencing
    Costs: Data from the NHGRI Genome Sequencing Program (GSP) Available at: [**www.genome.gov/sequencingcostsdata**](https://www.genome.gov/sequencingcostsdata).
    Accessed 5/25/2023.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**图6\. 人类基因组测序的成本。** 图中不包括过去两年，期间成本大幅下降。使用最新仪器的成本今天低至$200。Wetterstrand KA.
    DNA测序成本：来自NHGRI基因组测序计划（GSP）的数据。可访问： [**www.genome.gov/sequencingcostsdata**](https://www.genome.gov/sequencingcostsdata)。访问时间：2023年5月25日。'
- en: '**Data generation.** Since the initiation of the Human Genome Project over
    30 years ago, numerous DNA sequencing technologies have been developed, allowing
    for the rapid and cost-effective generation of DNA data. Today, an entire human
    genome can be fully sequenced for as little as $200 (Figure 6). Remarkably, the
    same technology used for sequencing our whole genome can also generate data on
    a multitude of molecular functions, such as those implicated in the central dogma
    of molecular biology. For instance, by integrating DNA sequencing with single-cell
    microfluidic technologies, researchers can measure the transcription level of
    every gene in thousands of individual cells within a biological sample. Sequencing-based
    methods can expose the structure of chromatin, histone modifications, transcription
    factor binding to DNA, and other crucial molecular information. A comprehensive
    explanation of how this is achieved is beyond the scope of this text, but in brief,
    short DNA segments with a specific property of interest — such as binding a certain
    transcription factor or being part of the open, accessible chromatin — are isolated
    in an experiment and sequenced.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据生成。** 自30多年前启动人类基因组计划以来，已经开发了大量DNA测序技术，使得DNA数据的生成既快速又具成本效益。如今，一个完整的人类基因组的测序费用低至200美元（图6）。值得注意的是，用于测序整个基因组的技术也能生成关于多种分子功能的数据，例如涉及分子生物学核心教义的功能。例如，通过将DNA测序与单细胞微流控技术结合，研究人员可以测量生物样本中数千个单独细胞内每个基因的转录水平。基于测序的方法可以揭示染色质结构、组蛋白修饰、转录因子与DNA的结合以及其他关键的分子信息。如何实现这些超出了本文的范围，但简而言之，具有特定兴趣属性的短DNA片段——例如结合某种转录因子或是开放的可及染色质的一部分——会在实验中被分离并测序。'
- en: In addition to DNA sequencing, other technologies like mass spectrometry (MS)
    and affinity-based proteomics can measure the levels of all proteins in a biological
    sample. X-ray crystallography, albeit lower in throughput, provides high-resolution
    3D structures of proteins.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 除了DNA测序，其他技术如质谱（MS）和基于亲和力的蛋白质组学也能测量生物样本中所有蛋白质的水平。虽然X射线晶体学的通量较低，但它提供了蛋白质的高分辨率3D结构。
- en: Over the past 20–30 years, our capacity to measure molecular function has drastically
    exceeded the pace of Moore’s law, primarily because of advances in DNA sequencing
    technology that also enable a large variety of molecular readouts such as gene
    expression, chromatin accessibility and histone modifications to be performed
    by sequencing-based assays. This swift advancement in data generation allows scientists
    to measure most genetic aspects within biological samples, often with single-cell
    or spatial precision.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的20至30年里，我们测量分子功能的能力已经显著超越了摩尔定律的进展，主要是因为DNA测序技术的进步，这些技术还使得各种分子读取方法得以实现，如基因表达、染色质可及性和组蛋白修饰。这种数据生成的迅速进展使科学家能够在生物样本中测量大多数遗传学方面，通常具备单细胞或空间精度。
- en: '![](../Images/efbf7a798fa5a52ab2c87ccc8917e7c5.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/efbf7a798fa5a52ab2c87ccc8917e7c5.png)'
- en: '**Figure 7\. The Genome Wide Association Studies Catalog.** The latest version
    of the iconic diagram that depicts the summary of all the associations known to
    date between locations in the 23 chromosomes and phenotypes. Source: [https://www.ebi.ac.uk/gwas/](https://www.ebi.ac.uk/gwas/).
    The diagram can be browsed live, and the associations are publicly available.
    Diagram available under CC0: [https://www.ebi.ac.uk/gwas/docs/about](https://www.ebi.ac.uk/gwas/docs/about).'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**图7\. 全基因组关联研究目录。** 最新版本的标志性图示总结了迄今为止已知的23条染色体上的位点与表型之间的所有关联。来源：[https://www.ebi.ac.uk/gwas/](https://www.ebi.ac.uk/gwas/)。图示可以实时浏览，关联信息是公开可用的。图示在CC0下提供：[https://www.ebi.ac.uk/gwas/docs/about](https://www.ebi.ac.uk/gwas/docs/about)。'
- en: '**Linking variation to function.** For over two decades, researchers have endeavored
    to elucidate gene functions and the molecular mechanisms of diseases by correlating
    genetic variants across numerous individuals’ genomes with specific phenotypes,
    such as the presence or absence of a particular disease. These investigations,
    termed genome-wide association studies (GWAS), identify statistically significant
    associations of certain genome locations, which could be genes or regulatory regions,
    with the phenotypes under study. The GWAS Catalog (https://www.ebi.ac.uk/gwas/),
    a public resource, currently contains more than 6,300 publications and 515,000
    such associations (Figure 7). When the measured phenotype isn’t binary but a quantifiable
    entity, such as height, a regression can be performed between the genomic variation
    and the phenotype, with the identified genetic loci termed quantitative trait
    loci. Besides macroscopic phenotypes like disease status, height, or hair color,
    genetic variation can be associated with molecular phenotypes such as gene expression
    levels (leading to expression quantitative trait loci, or eQTLs), protein abundance
    (resulting in protein quantitative trait loci, or pQTLs), and virtually every
    other molecular measurement. These analyses offer valuable insights into the molecular
    mechanisms governing cell function and human physiology. However, as we will discuss
    below, these traditional association analyses are likely to be surpassed by the
    application of LLMs.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**将变异与功能关联起来**。二十多年来，研究人员一直致力于通过将个体基因组中的遗传变异与特定表型（如某种疾病的存在或缺失）进行关联，以阐明基因功能和疾病的分子机制。这些研究被称为全基因组关联研究（GWAS），通过识别与研究表型显著相关的基因组位置（可能是基因或调控区域）来进行。GWAS目录（https://www.ebi.ac.uk/gwas/），一个公共资源，目前包含了超过6,300篇出版物和515,000个这样的关联（见图7）。当测量的表型不是二元的，而是可以量化的实体，如身高时，可以在基因组变异与表型之间进行回归分析，所识别的遗传位点称为定量性状位点。除了像疾病状态、身高或发色等宏观表型，遗传变异还可以与分子表型相关，如基因表达水平（导致表达定量性状位点或eQTLs）、蛋白质丰度（结果为蛋白质定量性状位点或pQTLs）以及几乎所有其他分子测量。这些分析提供了对调控细胞功能和人体生理的分子机制的宝贵见解。然而，正如我们将要讨论的，这些传统的关联分析可能会被LLMs的应用所超越。'
- en: Language Models in Molecular Biology
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分子生物学中的语言模型
- en: 'Over the past few years, remarkable progress has been made in modeling each
    step of the central dogma of molecular biology. While we haven’t yet fully transformed
    molecular biology into a computational science or made medicine and human health
    into an engineering discipline, the current momentum suggests that only a wealth
    of additional data and some further development stand between us and this vision.
    This progress is somewhat distinct from other areas of AI application. Personally,
    I believe that artificial general intelligence (AGI), even at the level of a small
    mammal, is still beyond the horizon. Additionally, combinatorics, discrete algorithms
    and mathematical reasoning aren’t the strong suits of LLMs. This is expected by
    the fact that these models are feed-forward architectures that do not include
    loops, other than the implicit loop created by taking the text generated so far,
    and feeding it back to the LLM as input. As explained in Stephen Wolfram’s excellent
    overview, computational irreducibility guarantees that these models can’t do certain
    things (Wolfram 2023). (It is worth mentioning that sparks of such abilities are
    starting to emerge in systems such as GPT-4 as described by Bubek et al, 2023.)
    However, modeling molecular biology does not need AGI: it doesn’t require high-level
    planning, agency, or goals, and only has a limited need for combinatorics and
    algorithmic reasoning. Instead, modeling molecular biology requires what LLMs
    excel at: learning the statistical properties of intricate, noisy sequential data
    to best predict such data from lossy representations.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中，我们在建模分子生物学中心法则的每一步方面取得了显著进展。虽然我们尚未完全将分子生物学转变为计算科学，也未将医学和人类健康变为工程学科，但目前的势头表明，仅仅需要大量额外的数据和进一步的发展，我们就能实现这一愿景。这一进展在某种程度上与其他AI应用领域有所不同。个人而言，我认为人工通用智能（AGI），即使是小型哺乳动物水平的AGI，仍然在视野之外。此外，组合学、离散算法和
- en: To illustrate this point, let us examine a few recent deep learning breakthroughs
    in different stages of the central dogma of molecular biology.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这一点，让我们审视一些最近在分子生物学中心法则不同阶段的深度学习突破。
- en: '*Note: I am coauthor in some of the work below, in particular the SpliceAI
    and PrimateAI-3D methods. As such my exposition could be biased.*'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：我在以下一些工作中是合著者，特别是SpliceAI和PrimateAI-3D方法。因此，我的阐述可能存在偏见。*'
- en: Predicting gene structure
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测基因结构
- en: According to the fundamental dogma of molecular biology, the primary function
    of DNA is to encode genes that are transcribed and translated into proteins. The
    specific segments of each gene that are translated into proteins are determined
    by the splicing mechanism; these segments are well-annotated for the vast majority
    of genes in the genome. However, mutations can disrupt the precise boundaries
    of splicing, known as splice sites. Rare mutations that disrupt splicing can significantly
    impact the resulting protein function, as they usually produce a completely different
    protein sequence. Consequently, they account for about 10% of rare genetic diseases
    (Jaganathan et al. 2019). Predicting splice sites and deducing gene structure
    is therefore a fundamental computational task with implications for diagnosing
    genetic diseases. In fact, this was one of the first problems I explored during
    my PhD and have continued to publish on it throughout my career. The literature
    on splice site prediction is extensive. However, until around 2018, the problem
    remained a significant challenge, with the best methods achieving accuracy of
    about 30%, a level not sufficiently predictive for applications such as genetic
    diagnosis.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8a2fa5094c3830176064791591698c63.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
- en: '**Figure 8\. SpliceAI model.** Image created by Kishore Jaganathan, included
    with permission.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: 'In 2019, SpliceAI was introduced by the Illumina AI laboratory (Jaganathan
    et al. 2019). SpliceAI doesn’t utilize transformer technology or function as an
    LLM; instead, it employs earlier techniques for language modeling, wherein the
    language is DNA sequences. It is a deep residual CNN, utilizing dilated convolutions
    to efficiently expand the window size it can handle. It accepts 10,000 nucleotide
    windows of the human genome as input and predicts the exact locations of the intron-exon
    boundaries, the so-called donor and acceptor sites — the exon-intron and intron-exon
    borders, respectively. In terms of precision-recall area under the curve (PR-AUC),
    SpliceAI achieved a score of 0.98 across the human genome, compared to the previous
    best of 0.23\. Importantly, SpliceAI is accurate enough to perform mutational
    analysis in silico: it can artificially alter any position of the DNA and determine
    whether this change introduces or eliminates a splice site within 10,000 nucleotides
    of the alteration. As a result, it can be utilized to aid genetic diagnosis: given
    a patient with a genetic disease, such as a young individual with a pediatric
    disorder, all variants in the individual not present in the parents can be compiled,
    and each variant can be input into SpliceAI to ask if it is likely to alter the
    splicing of nearby genes, thereby disrupting the function of a gene. To date,
    it has solved hundreds of previously unresolved cases of rare undiagnosed pediatric
    disease, in the context of the Genomics England 100,000 genomes project (Farh
    K, personal communication).'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: 'How did SpliceAI achieve high accuracy? In brief, it learned complex biomolecular
    properties of the DNA sequence that reliably guide the splicing machinery to the
    splice sites. These properties were previously unknown or only imprecisely known;
    SpliceAI’s deep residual network has enough capacity to capture them accurately.
    This raises an interesting question about the interpretation of deep neural networks:
    how can we extract the biomolecular rules that SpliceAI learned, to gain insight
    into the underlying biomolecular mechanisms? Generally, neural networks are black
    boxes that don’t explain how they make a prediction. However, techniques exist
    for probing the network and extracting the features to which it pays attention.
    The SpliceAI team performed such analysis and describe a plethora of learned features
    (Jaganathan et al. 2019).'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: SpliceAI 是如何实现高准确性的？简而言之，它学习了 DNA 序列的复杂生物分子特性，这些特性可靠地引导剪接机械到剪接位点。这些特性之前未知或仅不精确地了解；SpliceAI
    的深度残差网络具有足够的容量来准确捕捉这些特性。这提出了一个有趣的问题：如何提取 SpliceAI 学到的生物分子规则，以深入了解其潜在的生物分子机制？一般来说，神经网络是黑箱，不解释如何做出预测。然而，存在用于探测网络和提取其关注特征的技术。SpliceAI
    团队进行了这样的分析，并描述了大量学到的特征（Jaganathan et al. 2019）。
- en: Predicting protein structure
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测蛋白质结构
- en: The central dogma of molecular biology tells the story of how information in
    our DNA gives rise to proteins, which are the fundamental building blocks of life.
    Protein sequences are directly translated from spliced mRNA sequences according
    to the genetic code, and then fold into functional 3D shapes — protein structures.
    Predicting protein structure from the protein sequence, known as the protein folding
    problem, has long been regarded as the Holy Grail of molecular biology, due to
    its immense importance and seemingly insurmountable difficulty. The gold standard
    for protein structures is experimental data from X-ray crystallography, which
    is challenging to obtain due to difficulties in producing high-quality protein
    crystals and the complex data processing required to derive the protein structure.
    Computational prediction has been a focus of research for decades, despite structure
    prediction methods not coming close to the accuracy of X-ray crystallography.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 分子生物学的中心法则讲述了我们的 DNA 中的信息如何产生蛋白质，这些蛋白质是生命的基本构建块。蛋白质序列直接从拼接的 mRNA 序列中根据遗传密码翻译出来，然后折叠成功能性
    3D 形状——蛋白质结构。根据蛋白质序列预测蛋白质结构，被称为蛋白质折叠问题，长期以来被认为是分子生物学的**圣杯**，因其重要性极大且难度似乎难以逾越。蛋白质结构的黄金标准是
    X 射线晶体学的实验数据，由于生产高质量蛋白质晶体的困难和衍生蛋白质结构所需的复杂数据处理，这些数据难以获得。尽管结构预测方法的准确性未能接近 X 射线晶体学，计算预测仍然是研究的重点。
- en: '![](../Images/b1abd3c27ea781dc72d2242b08e31eb6.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b1abd3c27ea781dc72d2242b08e31eb6.png)'
- en: '**Figure 9\. Accuracy results in the CASP competition for protein structure
    prediction.** Each method is scored in a number of proteins whose structures are
    previously unknown, and experimentally determined by the time of the competition’s
    conclusion. The score reflects the percentage of amino acids that match the experimentally
    determined structure almost perfectly. Whereas for many years methods hovered
    around 40% or less, AlphaFold 2 has achieved accuracy of 89%, which comes close
    to experimental-level accuracy. Image by author.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 9\. CASP 竞赛中蛋白质结构预测的准确性结果。** 每种方法都在结构此前未知且在竞赛结束时通过实验确定的多种蛋白质中进行评分。评分反映了氨基酸的百分比，这些氨基酸几乎完美地匹配实验确定的结构。尽管许多年来方法的准确率徘徊在
    40% 或更低，AlphaFold 2 已实现 89% 的准确率，这接近实验级别的准确度。图像来源于作者。'
- en: The biannual competition, CASP (Critical Assessment of protein Structure Prediction),
    has been tracking progress in this field. In the 2019 competition, the AlphaFold
    method by DeepMind made a huge leap in accuracy compared to previous benchmarks.
    In 2021, AlphaFold 2 (Jumper et al. 2021) made another significant leap, nearly
    matching the accuracy of X-ray crystallography. Subsequently, in collaboration
    with the European Molecular Biology Laboratory (EMBL), DeepMind released a comprehensive
    open-source database based on AlphaFold2, called the AlphaFold Protein Structure
    Database. The database provides high-accuracy structural predictions for various
    organisms, including human proteins, model organisms, and important pathogens.
    These predicted structures are expected to expedite research and provide valuable
    insights into biological processes, drug discovery, and disease understanding.
    As of today, there are 214,683,829 protein structures in the database. In essence,
    the once Holy Grail of molecular biology is now close to a solved problem thanks
    to deep learning. AlphaFold 2 represents a major scientific advance by any measure.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: “[DeepMind’s protein-folding AI has solved a 50-year-old grand challenge of
    biology](https://www.technologyreview.com/2020/11/30/1012712/deepmind-protein-folding-ai-solved-biology-science-drugs-disease/)’’
    Will Heaven, Technology Review, 30 November 2020
  id: totrans-81
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/fff8c57b6ef3c75099b724b3e500eee6.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
- en: '**Figure 10\. Architecture of AlphaFold 2\. Image used by permission from the
    AlphaFold team (Jumper et al. 2021). (a)** Performance of AlphaFold on the CASP14
    dataset. **(b)** AlphaFold prediction of target T1049 (PDB 6Y4F, blue) compared
    with the experimental structure (green). **(c)** CASP14 target T1056 (PDB 6YJ1).
    An example of a well-predicted zinc-binding site. **(d)** CASP target T1044 (PDB
    6VR4), a 2,180-amino acid single chain, was predicted accurately. **(e)** Model
    architecture. Readers are referred to the original paper for detailed explanations.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: 'How did AlphaFold achieve such remarkable accuracy? The methodologies are worth
    summarizing (Figure 10). The techniques used in the AlphaFold paper bear a resemblance
    to an earlier method developed by Jinbo Xu and colleagues (Wang et al 2017). This
    method combines a convolutional neural network operating on protein sequences
    with a pairwise co-evolution feature. This feature identifies pairs of sequence
    positions that co-vary across related protein sequences in different species,
    to predict 2D contact maps across a protein sequence. A contact map is a score
    for every pair of positions in the sequence, indicating the likelihood of these
    two positions being in close proximity in 3D. The AlphaFold 2 method builds on
    these algorithms and is expertly engineered and trained to provide a significant
    leap in structural prediction accuracy. AlphaFold2 introduced several additional
    novel improvements: (1) It is based on the transformer LLM architecture, which
    enhances its ability to capture long-range interactions between amino acids in
    the protein sequence. (2) A novel energy-based score, the Amber energy, was introduced
    to directly optimize the 3D protein structure, allowing for an end-to-end differentiable
    approach during the structure optimization step. (3) An improved utilization of
    coevolutionary features by incorporating multiple sequence alignment (MSA) data
    boosts the model’s ability to identify conserved structural features across homologous
    protein sequences. (4) A refinement stage fine-tunes the predicted protein structures
    using a second model trained on the output of the first model, leading to more
    accurate and consistent predictions.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: AlphaFold如何实现如此显著的准确性？其方法值得总结（见图 10）。AlphaFold论文中使用的技术与徐锦波及其同事们早期开发的方法（Wang
    et al 2017）有相似之处。该方法结合了卷积神经网络对蛋白质序列的操作和成对共进化特征。该特征识别不同物种中相关蛋白质序列上共变的序列位置对，以预测蛋白质序列中的2D接触图。接触图是对序列中每对位置的评分，指示这两个位置在3D中可能相邻的可能性。AlphaFold
    2方法在这些算法基础上进行了改进，经过专业工程设计和训练，显著提高了结构预测的准确性。AlphaFold2引入了几个额外的创新改进：（1）基于Transformer
    LLM架构，增强了其捕捉蛋白质序列中长距离相互作用的能力。（2）引入了一种新的基于能量的评分，Amber能量，在结构优化步骤中直接优化3D蛋白质结构，允许在结构优化步骤中进行端到端的可微分处理。（3）通过整合多序列比对（MSA）数据，改进了共进化特征的利用，增强了模型识别同源蛋白质序列中保守结构特征的能力。（4）通过在第一个模型输出上训练的第二个模型进行的精细化阶段，调整了预测的蛋白质结构，从而实现更准确和一致的预测。
- en: '![](../Images/471c9e8218e79cc12d625923c3819b82.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/471c9e8218e79cc12d625923c3819b82.png)'
- en: '**Figure 11\. Predicted (blue) and experimentally determined (green) protein
    structures.** Image included with permission from the AlphaFold team. (Jumper
    et al. 2021, Varadi et al. 2021).'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 11\. 预测（蓝色）和实验确定的（绿色）蛋白质结构。** 图片经AlphaFold团队许可使用。（Jumper et al. 2021, Varadi
    et al. 2021）。'
- en: Since the inception of AlphaFold, progress in the application of deep learning
    to protein structural prediction, modeling, and design has progressed at blinding
    speed. ESMFold (Lin et al. 2023) is an LLM for protein structural prediction that
    provides a speedup of up to 60x without loss of accuracy. ProteinGenerator (Lyayuga
    Lisanza et al. 2023) is a sequence-space diffusion model based on the RoseTTAfold
    (Baek et al. 2021) protein structural prediction method by the same lab. ProteinGenerator
    simultaneously generates protein sequences and their accompanying structures that
    satisfy any given sequence and structural properties, as the authors demonstrate
    experimentally. RosettaFold2 (Baek et al. 2023) combines features of AlphaFold2
    and RosettaFold to provide comparable accuracy with AlphaFold2 at improved computational
    efficiency. We are at the beginning of incredible innovation in protein design,
    with upcoming groundbreaking advances in drug design and bioengineering.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 自AlphaFold问世以来，深度学习在蛋白质结构预测、建模和设计应用方面的进展突飞猛进。ESMFold（Lin et al. 2023）是一种用于蛋白质结构预测的LLM，提供高达60倍的加速而不损失准确性。ProteinGenerator（Lyayuga
    Lisanza et al. 2023）是基于RoseTTAfold（Baek et al. 2021）蛋白质结构预测方法的序列空间扩散模型，由同一实验室开发。ProteinGenerator同时生成满足任何给定序列和结构特性的蛋白质序列及其伴随结构，作者通过实验证明。RosettaFold2（Baek
    et al. 2023）结合了AlphaFold2和RosettaFold的特性，在改进计算效率的同时提供了与AlphaFold2可比的准确性。我们正处在蛋白质设计的创新之初，未来将在药物设计和生物工程方面取得突破性进展。
- en: One key takeaway is that while decades of work on first principles, including
    protein structure energy minimization and protein kinetics modeling, failed to
    yield accurate structural prediction, the complex and intricate molecular information
    of how proteins actually fold is present in the data, and LLMs were capable of
    learning it.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的结论是，尽管几十年的基础研究，包括蛋白质结构能量最小化和蛋白质动力学建模，未能提供准确的结构预测，但实际折叠的复杂分子信息存在于数据中，且LLMs能够学习这些信息。
- en: Predicting the impact of protein variants
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测蛋白质变异的影响
- en: More than 4 million positions in the genomes of any two individuals vary, with
    over 20,000 such variants located within the protein-coding regions. The majority
    of this genetic variation is benign and contributes significantly to the phenotypic
    diversity observed across humans. However, a small fraction of this genetic diversity
    is deleterious and contributes to genetic diseases. Understanding the impact of
    genetic variants and categorizing them as benign or deleterious has direct applications
    in the diagnosis of genetic diseases, identification of gene targets for drug
    development, and comprehension of the molecular mechanisms of diseases. Regrettably,
    the vast majority of variants are “variants of uncertain significance” (VUSs),
    and their impact on disease is unknown. Annotating such variants is a crucial
    unresolved problem in human genetics.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 超过400万个基因组中的位置在任何两个个体之间存在差异，其中有超过20,000个变异位点位于蛋白质编码区域。绝大多数这种遗传变异是良性的，并显著贡献于人类观察到的表型多样性。然而，这些遗传多样性中的一小部分是有害的，并导致遗传疾病。了解遗传变异的影响并将其分类为良性或有害，对于遗传疾病的诊断、药物开发的基因靶点识别以及疾病的分子机制理解都有直接应用。不幸的是，绝大多数变异是“意义不确定的变异”（VUSs），它们对疾病的影响尚不清楚。对这些变异进行注释是人类遗传学中一个关键的未解问题。
- en: '![](../Images/3e11f081207fba5f6fb164e8bda39698.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e11f081207fba5f6fb164e8bda39698.png)'
- en: '**Figure 12\. Primate Phylogeny.** Human’s closest relatives are the great
    apes. We share a common ancestor with chimpanzees and bonobos around 5–7 million
    years ago, and with gorillas a bit longer ago. Our DNA similarity is 98.8% with
    chimpanzees, 98.4% with gorillas, and 97% with orangutans. Phylogeny trees like
    the one in the picture display the evolutionary history of extant species. For
    example, the great apes consist of humans, chimpanzees and bonobos that split
    from the human lineage about 5–7 million years ago, east and west gorillas that
    split about 8 million years ago, and orangutan species that split about 15–19
    million years ago. Our next closest relatives are African and Asian monkeys. When
    comparing DNA sequences across species, the functionally important positions in
    DNA, which are likely to cause genetic disease if mutated, are more likely to
    be conserved. Conversely, positions where we observe differences between today’s
    primates and our genome are more likely to be tolerant of mutations and to not
    cause genetic disease when mutated. Image generated by Lukas Kuderna and included
    with permission.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**图12\. 灵长类动物谱系。** 人类最亲近的亲属是大猿。我们与黑猩猩和倭黑猩猩的共同祖先大约在500万到700万年前分开，与大猩猩的分开时间稍长。我们与黑猩猩的DNA相似度为98.8%，与大猩猩为98.4%，与猩猩为97%。像图中的谱系树展示了现存物种的进化历史。例如，大猿包括人类、黑猩猩和倭黑猩猩，它们大约在500万到700万年前从人类谱系分裂开来，东部和西部大猩猩大约在800万年前分裂，猩猩大约在1500万到1900万年前分裂。我们下一个最亲近的亲属是非洲和亚洲猴子。比较物种间的DNA序列时，功能重要的位置，若发生突变则可能导致遗传疾病，更可能被保守。相反，我们在今天的灵长类动物与我们基因组之间观察到差异的位置，更可能对突变有容忍性，并且在突变时不导致遗传疾病。图像由Lukas
    Kuderna生成并获得许可。'
- en: 'One important clue in determining whether a given variant is benign, or at
    least not too deleterious, comes from comparing human genetics to the genetics
    of close relatives such as chimpanzees and other primates (Figure 12). Our genome
    closely resembles the genomes of other primates: it is 98.8% similar to the genome
    of chimpanzees, 98.4% similar to the genome of gorillas, and 97% similar to the
    genome of orangutans, for instance. Proteins, which are conserved by evolution,
    are even more similar on average. Our biology is also very similar, and when a
    mutation in a human protein is lethal or causes a serious genetic disease, the
    same mutation in the corresponding primate protein is likely to also be harmful.
    Conversely, protein variants that are observed in healthy primates are likely
    to be benign in humans as well. Therefore, the more primate genomes we can access,
    the more information we can gather about the human genome: we can compile a list
    of protein variants that are frequently observed in primates and deduce that these
    variants are likely benign in humans. Hence, the search for mutations that confer
    serious genetic disease should start from mutations not on this list.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 确定给定变异是否良性，或至少不太有害的一个重要线索来自将人类遗传学与近亲如黑猩猩和其他灵长类动物的遗传学进行比较（图12）。我们的人类基因组与其他灵长类动物的基因组非常相似：例如，与黑猩猩的基因组相似度为98.8%，与大猩猩的基因组相似度为98.4%，与猩猩的基因组相似度为97%。进化上保守的蛋白质平均上更为相似。我们的生物学也非常相似，当人类蛋白质中的突变是致命的或导致严重遗传病时，相应的灵长类动物蛋白质中的相同突变也可能是有害的。相反，在健康的灵长类动物中观察到的蛋白质变异在人体中也可能是良性的。因此，我们能访问的灵长类基因组越多，我们就能获得关于人类基因组的信息：我们可以编制一个在灵长类动物中频繁观察到的蛋白质变异列表，并推测这些变异在人体中可能是良性的。因此，寻找导致严重遗传病的突变应该从不在此列表中的突变开始。
- en: 'Such a list of variants in primate proteins can never be enough to classify
    human mutations as benign or pathogenic. Simply put, there will be too many benign
    human mutations that have not had the opportunity to appear on the list of variants
    observed in primates. However, this list can be utilized in a more productive
    way: by observing the patterns within protein sequences and structures that tend
    to tolerate variants, and the patterns that tend not to tolerate variants. By
    learning to differentiate between these two classes of protein positions, we can
    gain the ability to annotate variants in proteins as likely benign and likely
    pathogenic.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 灵长类动物蛋白质中的变异列表永远无法足够用于将人类突变分类为良性或致病性。简单来说，将有太多良性人类突变没有机会出现在灵长类动物的变异列表中。然而，这份列表可以以更具生产力的方式利用：通过观察在蛋白质序列和结构中倾向于耐受变异的模式以及倾向于不耐受变异的模式。通过学习区分这两类蛋白质位置，我们可以获得注释变异为可能良性或可能致病的能力。
- en: 'The Illumina AI lab headed by Kyle Farh, which developed the SpliceAI method,
    adopted this approach to annotate variants in human proteins (Gao et al. 2023).
    Initially, in collaboration with others, they collected primate blood samples
    and sequenced the genomes of as many primates as they could access, including
    809 individuals from 233 distinct primate species. This sequencing effort is an
    important conservation initiative: some primate species are endangered, and preserving
    the wealth of genetic information in these species is crucial for basic science
    as well as for informing human genetics.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 由Kyle Farh领导的Illumina AI实验室开发了SpliceAI方法，采用这种方法对人类蛋白质中的变异进行注释（Gao等人，2023年）。最初，他们与其他团队合作，收集了灵长类动物的血液样本，并对他们能够接触到的尽可能多的灵长类动物进行了基因组测序，包括233个不同灵长类物种中的809个个体。这一测序工作是一个重要的保护举措：一些灵长类动物物种濒临灭绝，保存这些物种的遗传信息对基础科学以及人类遗传学的研究至关重要。
- en: The team identified a catalog of 4.3 million common protein variants in primates,
    with the corresponding protein also being present in humans. Then, they constructed
    a transformer that learns to distinguish between benign and pathogenic variants
    in human proteins. This was accomplished by learning the patterns of protein positions
    where primate variants tend to be present, in contrast to protein positions where
    primate variants tend to be absent. The transformer, named PrimateAI-3D, is a
    new version of a previous deep learning tool, PrimateAI (Sundaram et al. 2018),
    developed by the same laboratory. PrimateAI-3D utilizes both protein sequence
    data, as well as protein 3D models that are either experimentally reconstructed
    or computationally predicted by tools like AlphaFold and HHpred, voxelized at
    2 Angstrom resolution (Figure 13).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 团队在灵长类动物中确定了430万个常见蛋白变体的目录，对应的蛋白质也存在于人类中。然后，他们构建了一个转换器，学习区分人类蛋白质中良性和致病性变体。这是通过学习灵长类动物变体通常出现的蛋白质位置模式，与灵长类动物变体通常不出现的蛋白质位置形成对比来实现的。这个转换器名为PrimateAI-3D，是前一个深度学习工具PrimateAI（Sundaram等人，2018年）的新版本，由同一实验室开发。PrimateAI-3D利用了蛋白质序列数据以及通过AlphaFold和HHpred等工具实验重建或计算预测的蛋白质3D模型，分辨率为2埃。
    （图13）。
- en: '![](../Images/8bdc4ef3999b70254f9b71cd8c429913.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8bdc4ef3999b70254f9b71cd8c429913.png)'
- en: '**Figure 13\. Architecture of PrimateAI-3D.** Human protein structures are
    voxelized, and together with multiple sequence alignments are passed as input
    to a 3D convolutional neural network that predicts pathogenicity of all possible
    point mutations of a target residue. The network is trained using a loss function
    with three components: (1) a language model predicting a missing human or primate
    amino acid using the surrounding multiple alignment as input; (2) a 3D convolutional
    “fill-in-the-blank” model predicting a missing amino acid in the 3D structure;
    a language model score trained on classifying between observed variants and random
    variants with matching statistical properties. Figure created by Tobias Hemp and
    included with permission.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**图13\. PrimateAI-3D的架构。** 人类蛋白质结构被体素化，与多序列比对一起作为输入传递给三维卷积神经网络，预测目标残基的所有可能点突变的致病性。该网络使用三个组成部分的损失函数进行训练：（1）语言模型使用周围多序列比对预测缺失的人类或灵长类动物氨基酸；（2）三维卷积“填空”模型预测3D结构中缺失的氨基酸；（3）基于分类观察变异与具有匹配统计特性的随机变异之间的语言模型分数进行训练。图由Tobias
    Hemp创建，并获得授权包含。'
- en: In the ClinVar data set of human-annotated variants and their effects, PrimateAI-3D
    achieved 87.3% recall and 80.2% precision, with an AUC of 0.843, which was best
    across state-of-the-art methods, even though unlike other methods, it was not
    trained on ClinVar. Moreover, examining corrections to ClinVar across its versions
    hints to some proportion of the variants where PrimateAI-3D and ClinVar disagree,
    could be correctly called by PrimateAI-3D.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在人类注释变异及其影响的ClinVar数据集中，PrimateAI-3D实现了87.3%的召回率和80.2%的精确度，AUC为0.843，这在最先进的方法中表现最佳，尽管与其他方法不同，它并未在ClinVar上进行训练。此外，检查ClinVar各个版本的更正暗示了PrimateAI-3D和ClinVar存在分歧的一些变异中，PrimateAI-3D的召回可能是正确的。
- en: 'PrimateAI-3D can be applied to diagnosis of rare disease, where it can prioritize
    variants that are likely deleterious, and filter out likely benign variants. Another
    application is the discovery of genes associated with complex diseases: in a cohort
    of patients of a given disease, one can look for variants that are likely deleterious
    according to PrimateAI-3D, and then look for an abundance of such variants within
    a specific gene across the cohort. Genes that exhibit this pattern of being hit
    by many likely deleterious variants in patients of a given disease, are said to
    have a genetic “burden” that is a signal of playing a role in the disease. Gao
    and colleagues from the PrimateAI-3D team studied several genetic diseases with
    this methodology and discovered many genes previously not known to be associated
    with these diseases. Using PrimateAI-3D, Fiziev et al (2023) developed improved
    rare variant polygenic risk score (PRS) models to identify individuals at high
    disease risk. They also integrated PrimateAI-3D into rare variant burden tests
    within UK Biobank and identified promising novel drug target candidates.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: PrimateAI-3D 可用于罕见疾病的诊断，它能够优先考虑可能有害的变异，并筛选出可能无害的变异。另一个应用是发现与复杂疾病相关的基因：在某一特定疾病的患者队列中，可以寻找根据
    PrimateAI-3D 预测可能有害的变异，然后在队列中的特定基因中寻找这些变异的丰度。表现出这种模式的基因，即在某一特定疾病患者中受到许多可能有害的变异影响的基因，被认为有一种遗传“负担”，这是一种可能在疾病中发挥作用的信号。Gao
    和 PrimateAI-3D 团队的同事们采用这一方法研究了几种遗传疾病，发现了许多之前未被认识到与这些疾病相关的基因。利用 PrimateAI-3D，Fiziev
    等人（2023）开发了改进的罕见变异多基因风险评分（PRS）模型，以识别高风险个体。他们还将 PrimateAI-3D 整合到 UK Biobank 的罕见变异负担测试中，识别出了有前景的新药物靶点候选者。
- en: Modeling gene regulation
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基因调控建模
- en: 'As outlined earlier, the intricate process of gene regulation encompasses many
    interacting molecular components: the DNA chromatin structure, the chemical alterations
    within histones that DNA wraps around, the attachment of transcription factors
    to promoters and enhancers, the establishment of 3D DNA structure involving promoters,
    enhancers, bound transcription factors, and the recruitment of RNA polymerase.
    Theoretically, the precise DNA sequence in the vicinity of a gene carries all
    the information needed for this machinery to be triggered at the correct time,
    in the right amount, and in the appropriate cell type. In practice, predicting
    gene expression from the DNA sequence alone is a formidable task. Yet, language
    models have recently achieved significant progress in this area.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，基因调控的复杂过程涉及许多相互作用的分子组件：DNA 染色质结构、DNA 包绕的组蛋白中的化学修饰、转录因子与启动子和增强子结合、涉及启动子、增强子、结合的转录因子以及
    RNA 聚合酶招募的 3D DNA 结构的建立。从理论上讲，基因附近的精确 DNA 序列携带了触发这一机制所需的所有信息，以确保在正确的时间、适量的情况下，在适当的细胞类型中启动。实际上，仅凭
    DNA 序列预测基因表达是一项艰巨的任务。然而，语言模型最近在这一领域取得了重大进展。
- en: '**Data generation informative of gene regulation.** Over the past two decades,
    genomic researchers have undertaken monumental efforts to produce the appropriate
    types of large-scale molecular data for understanding gene regulation. Hundreds
    of different assays have been developed that inform various aspects of the central
    dogma, too numerous to detail here. Here are some examples of the information
    obtained, always related to a human cell line or tissue type (the former often
    being immortalized cell lines, and the latter often sourced from deceased donors):
    (1) Identifying the precise locations across the entire genome that have open
    chromatin and those that have tightly packed chromatin. Two relevant assays for
    this are DNAse-seq and ATAC-seq. (2) Pinpointing all locations in the genome where
    a specific transcription factor is bound. (3) Identifying all locations in the
    genome where a specific histone chemical modification has occurred. (4) Determining
    the level of mRNA available for a given gene, i.e., the expression level of a
    particular gene. This type of data has been obtained for hundreds of human and
    mouse cell lines from numerous individuals. In total, several thousand such experiments
    have already been collected under multi-year international projects like ENCODE,
    modENCODE, Roadmap Epigenomics, Human Cell Atlas, and others. Each experiment,
    in turn, has tens to hundreds of thousands of data points across the entire human
    or model organism genome.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**基因调控信息的数据生成。** 在过去二十年中，基因组研究人员付出了巨大的努力，生产适合理解基因调控的大规模分子数据。已经开发了数百种不同的检测方法，用于揭示中心法则的各个方面，这里无法一一列举。以下是获得的一些信息示例，均与人类细胞系或组织类型相关（前者通常是永生化细胞系，后者通常来源于已故捐赠者）：（1）识别整个基因组中具有开放染色质的精确位置和具有紧密堆积染色质的位置。与此相关的两种检测方法是DNAse-seq和ATAC-seq。（2）准确定位基因组中一个特定转录因子结合的所有位置。（3）识别基因组中一个特定组蛋白化学修饰发生的所有位置。（4）确定特定基因的mRNA水平，即特定基因的表达水平。这种数据已经从众多人类和小鼠细胞系中获得。总的来说，已经在多年的国际项目如ENCODE、modENCODE、Roadmap
    Epigenomics、Human Cell Atlas等中收集了几千次这样的实验。每个实验在整个基因组中都有数万到数十万个数据点。'
- en: 'A lineage of language models, culminating in the transformer-based Enformer
    tool (Avsek et al. 2021), have been developed to accept the DNA sequence near
    a gene as input and output the cell type-specific expression level of this gene
    for any gene in the genome. Enformer is trained on the following task: given a
    genome region of 100,000 nucleotides and a specific cell type, it is trained to
    predict each of the available types of experimental data for this region, including
    the status of open or packed chromatin, the present histone modifications, the
    specific bound transcription factors, and the level of gene expression. A language
    model is ideal for this task: instead of masked language modeling, Enformer is
    trained in a supervised way, predicting all the tracks simultaneously from DNA
    sequence. By incorporating attention mechanisms, it can efficiently collate information
    from distant regions (up to 100,000 nucleotides away) to predict the status of
    a given location. In effect, Enformer learns all the intricate correlations between
    these diverse molecular entities.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 一系列语言模型，最终形成了基于变压器的Enformer工具（Avsek等人，2021），已经被开发用来接受基因附近的DNA序列作为输入，并输出基因组中任何基因的细胞类型特异性表达水平。Enformer的训练任务如下：给定一个包含100,000个核苷酸的基因组区域和一个特定细胞类型，它被训练来预测该区域的每种实验数据类型，包括开放或紧密堆积的染色质状态、当前的组蛋白修饰、特定结合的转录因子和基因表达水平。语言模型非常适合这个任务：与掩蔽语言建模不同，Enformer以监督方式进行训练，从DNA序列中同时预测所有轨迹。通过整合注意力机制，它可以有效地汇总来自远离区域的信息（最多100,000个核苷酸），以预测给定位置的状态。实际上，Enformer学习了这些多样分子实体之间的所有复杂关联。
- en: '![](../Images/f46e614156fc8f1636838d813414eb2a.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f46e614156fc8f1636838d813414eb2a.png)'
- en: '**Figure 14\. Predictions of Enformer and an earlier system, Basenji2, compared
    to experimental results.** Image included with permission from corresponding author,
    Ziga Avsec.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**图14\. Enformer与早期系统Basenji2的预测与实验结果的比较。** 图像已获得对应作者Ziga Avsec的许可。'
- en: Enformer performs reasonably well in predicting gene expression from sequence
    alone. If we measure gene expression across all genes in the same cell line using
    a specific experimental assay (for instance, the CAGE assay), two replicates of
    the same experiment typically correlate at an average of 0.94\. A computational
    method performing at this level could arguably reduce the need for collecting
    experimental data. Enformer doesn’t quite achieve this yet, correlating at a level
    of 0.85 with experimental data, which is about three times the error compared
    to two experimental replicates. However, this performance is expected to improve
    as more data are incorporated and enhancements are made to the model. Notably,
    Enformer can predict the changes in gene expression caused by mutations present
    in different individuals, as well as by mutations artificially introduced through
    CRISPR experiments. However, it still has its limitations, such as performing
    poorly in predicting the effects of distal enhancers — enhancers that are far
    from the gene start — (Karollus et al. 2023) and to correctly determine the direction
    of the effect of personal variants in gene expression (Sasse et al. 2023). Such
    shortcomings are likely due to insufficient training data. With data generation
    proceeding at an accelerated pace, it is not unreasonable to anticipate that in
    the foreseeable future we will have LLMs capable of predicting gene expression
    from sequence alone with experimental-level accuracy, and consequently models
    that accurately and comprehensively depict the complex molecular mechanisms involved
    in the central dogma of molecular biology.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: Enformer仅通过序列预测基因表达表现相当不错。如果我们使用特定实验测定（例如CAGE实验）在同一细胞系中测量所有基因的基因表达，同一实验的两次重复通常在平均0.94的相关性水平上。一个达到这一水平的计算方法可能会减少收集实验数据的需求。Enformer目前并未完全达到这一水平，其与实验数据的相关性仅为0.85，这相当于两个实验复制的误差的三倍。然而，随着数据的积累和模型的改进，这一性能有望得到改善。值得注意的是，Enformer能够预测由不同个体的突变或通过CRISPR实验引入的人为突变引起的基因表达变化。然而，它仍然存在一些局限性，例如在预测远端增强子（距离基因起始位置较远的增强子）的效果方面表现不佳（Karollus等人，2023年），以及正确确定个人变异在基因表达中的影响方向（Sasse等人，2023年）。这些缺点可能是由于训练数据不足所致。随着数据生成步伐的加快，预计在可预见的未来，我们将拥有能够以实验水平精度从序列预测基因表达的大型语言模型（LLMs），并因此准确和全面地描绘参与分子生物学中心法则的复杂分子机制的模型。
- en: As discussed above, DNA within cells is arranged in complex, hierarchical 3D
    chromatin structure, which plays a role in gene regulation because only genes
    within open chromatin are expressed. Orca (Zhou 2022) is a recent language model,
    based on a convolutional encoder-decoder architecture, that predicts 3D genome
    structure from proximity data provided by Hi-C experiments. Those are datasets
    across the entire genomes of a cell line or tissue sample, in which pairs of genomic
    positions that are close to each other are revealed as DNA fragments that glue
    a piece of DNA from each region. The Orca model is a hierarchical multi-level
    convolutional encoder, and a multilevel decoder, which predict DNA structure at
    9 levels of resolution, from 4kb (kilo base pairs) to 1024kb, for input DNA sequences
    that are as long as the longest human chromosome.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，细胞内的DNA呈复杂的分层三维染色质结构，这在基因调控中起到作用，因为只有开放染色质内的基因才会被表达。Orca（Zhou 2022）是一种最近的语言模型，基于卷积编码器-解码器架构，从Hi-C实验提供的接近数据预测3D基因组结构。这些数据集跨越细胞系或组织样本的整个基因组，在这些数据中，接近的基因组位置会被揭示为将DNA片段粘合到每个区域的DNA片段。Orca模型是一个分层多级卷积编码器和多级解码器，用于预测从4kb到1024kb分辨率的9个级别的DNA结构，适用于与最长人类染色体长度相当的输入DNA序列。
- en: Foundation Models
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基础模型
- en: Foundation models are large deep learning architectures, such as the transformer-based
    GPT models by OpenAI, that encode a vast amount of knowledge from diverse sources.
    Researchers and practitioners can fine-tune these pre-trained models for specific
    tasks, resulting in high-performance systems for a wide range of downstream applications.
    Several foundation models have begun to emerge in molecular biology. Here, we
    will briefly introduce two such models that just appeared as preprints in biorXiv.
    *(Because the papers have not been peer reviewed yet, we refrain from reporting
    on their performance compared to other state-of-the-art methods.)*
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 基础模型是大型深度学习架构，如OpenAI的基于Transformer的GPT模型，它们编码了来自多源的大量知识。研究人员和从业者可以针对特定任务对这些预训练模型进行微调，从而为各种下游应用提供高性能系统。在分子生物学中已经开始出现几种基础模型。在这里，我们将简要介绍两种刚刚作为biorXiv预印本出现的模型。*（因为这些论文尚未经同行评审，我们暂时不报告它们与其他最先进方法的比较表现。）*
- en: '**scGPT** is a foundation model designed for single-cell transcriptomics, chromatin
    accessibility, and protein abundance. This model is trained on single-cell data
    from 10 million human cells. Each cell contains expression values for a fraction
    of the approximately 20,000 human genes. The model learns embeddings of this large
    cell × gene matrix, which provide insights into the underlying cellular states
    and active biological pathways. The authors innovatively adapted the GPT methodology
    to this vastly different setting (Figure 15). Specifically, the ordering of genes
    in the genome, unlike the ordering of words in a sentence, is not as meaningful.
    Therefore, while GPT models are trained to predict the next word, the concept
    of the “next gene” is unclear in single-cell data. The authors solve this problem
    by training the model to generate data based on a gene prompt (a collection of
    known gene values) and a cell prompt. Starting from the known genes, the model
    predicts the remaining genes along with their confidence values. For K iterations,
    it divides those into K bins, and the top 1/K most confident genes are fixed as
    known genes for the next iteration. Once trained, scGPT is fine-tuned for numerous
    downstream tasks: batch correction, cell annotation (where the ground truth is
    annotated collections of different cell types), perturbation prediction (predicting
    the cell state after a given set of genes are experimentally perturbed), multiomics
    (where each layer, transcriptome, chromatin, proteome, is treated as a different
    language), prediction of biological pathways, and more.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**scGPT** 是为单细胞转录组学、染色质可及性和蛋白质丰度设计的基础模型。该模型是在来自1000万个人类细胞的单细胞数据上训练的。每个细胞包含大约20,000个人类基因的表达值。该模型学习这个大型细胞
    × 基因矩阵的嵌入，这些嵌入提供了对潜在细胞状态和活跃生物通路的洞见。作者们创新地将GPT方法论适应到这个非常不同的环境中（图15）。具体来说，在基因组中基因的顺序，不像在句子中单词的顺序那样具有意义。因此，虽然GPT模型是训练来预测下一个词，但在单细胞数据中，“下一个基因”的概念是不清楚的。作者们通过训练模型根据基因提示（已知基因值的集合）和细胞提示生成数据来解决这个问题。从已知的基因开始，模型预测剩余的基因以及它们的置信度值。对于K次迭代，将它们分成K个箱，置信度值最高的1/K个基因作为下一次迭代的已知基因。训练完成后，scGPT可以针对多个下游任务进行微调：批次校正、细胞注释（其中地面真实是各种细胞类型的注释集合）、扰动预测（预测在给定一组基因实验扰动后的细胞状态）、多组学（其中每个层次，转录组、染色质组、蛋白质组，被视为不同的语言）、生物通路预测等等。'
- en: '![](../Images/933e9001525047abf8f5bb5758517072.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/933e9001525047abf8f5bb5758517072.png)'
- en: '**Figure 15\. Overview of scGPT.** A. Workflow of scGPT. The model is trained
    on a large number of cells from cell atlas, and is then fine tuned for downstream
    applications such as clustering, batch correction, cell annotation, perturbation
    prediction and gene network inference. B. Input embeddings. There are gene tokens,
    gene expression values, and condition tokens. C. The transformer layer. Image
    provided by Bo Wang.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '-   **图15\. scGPT概述。** A. scGPT的工作流程。该模型在来自细胞图谱的大量细胞上进行训练，然后针对聚类、批次校正、细胞注释、扰动预测和基因网络推断等下游应用进行微调。B.
    输入嵌入。有基因令牌、基因表达值和条件令牌。C. Transformer层。图像由王博提供。'
- en: '**Nucleotide Transformer** is a foundational model that focuses on raw DNA
    sequences. These sequences are tokenized into words of six characters each (k-mers
    of length 6) and trained using the BERT methodology. The training data consists
    of the reference human genome, 3200 additional diverse human genomes to capture
    variations across human genomics, and the genomes of 850 other species. The Nucleotide
    Transformer is then applied to 18 downstream tasks that encompass many of the
    previously discussed ones: promoter prediction, splice site donor and acceptor
    prediction, histone modifications, and more. Predictions are made either through
    probing, wherein embeddings at different layers are used as features for simple
    classifiers (such as logistic regression or perceptrons), or through light, computationally
    inexpensive fine-tuning.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**核苷酸变换器**是一个基础模型，专注于原始DNA序列。这些序列被分割成每个六个字符的词（长度为6的k-mer），并使用BERT方法进行训练。训练数据包括参考人类基因组、3200个额外的多样化人类基因组以捕捉人类基因组学中的变异，以及850个其他物种的基因组。然后将核苷酸变换器应用于18个下游任务，这些任务包括许多之前讨论的任务：启动子预测、剪接位点供体和受体预测、组蛋白修饰等。预测通过探测完成，其中不同层的嵌入作为简单分类器（如逻辑回归或感知器）的特征，或者通过轻量、计算上不昂贵的微调来实现。'
- en: Looking Forward
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 展望未来
- en: Deciphering the biomolecular code that connects our genomes to the intricate
    biomolecular pathways in our body’s various cells, and subsequently to our physiology
    in combination with environmental interactions, doesn’t require AGI. While there
    are numerous AI tasks that may or may not be on the horizon, I argue that understanding
    molecular biology and linking it to human health isn’t one of them. LLMs are already
    proving adequate for this general aspiration.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 解读连接我们基因组与体内各种细胞中的复杂生物分子途径的生物分子代码，并随后与环境互动结合到我们的生理功能，并不需要AGI。虽然有许多AI任务可能会出现在未来，但我认为理解分子生物学并将其与人类健康联系起来并不是其中之一。LLMs已经足够满足这一总体目标。
- en: 'Here are some tasks that we are not asking the AI to do. We aren’t asking it
    to generate new content; rather, we’re asking it to learn the complex statistical
    properties of existing biological systems. We aren’t requesting it to navigate
    intricate environments in a goal-oriented manner, maintain an internal state,
    form goals and subgoals, or learn through interaction with the environment. We
    aren’t asking it to solve mathematical problems or to develop deep counterfactual
    reasoning. We do, however, expect it to learn one-step causality relationships:
    if a certain mutation occurs, a specific gene malfunctions. If this gene is under-expressed,
    other genes in the cascade increase or decrease. Through simple one-step causal
    relationships, which can be learned from triangulating between correlations across
    modalities such as DNA variation, protein abundance and phenotype (a technique
    known as Mendelian randomization) and large-scale perturbation experiments that
    are becoming increasingly common, LLMs will effectively model cellular states.
    This connection extends from the genome at one end to the phenotype at the other.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些我们没有要求AI做的任务。我们并没有要求它生成新内容；而是要求它学习现有生物系统的复杂统计特性。我们没有要求它以目标导向的方式导航复杂环境，维持内部状态，形成目标和子目标，或通过与环境的互动学习。我们没有要求它解决数学问题或发展深层反事实推理。然而，我们确实期望它学习一步因果关系：如果发生某种突变，特定基因会失效。如果这个基因表达不足，级联中的其他基因会增加或减少。通过简单的一步因果关系，这些关系可以通过在不同模态（如DNA变异、蛋白质丰度和表型）之间的相关性进行三角测量（这是一种称为孟德尔随机化的技术）以及越来越普遍的大规模扰动实验来学习，LLMs将有效地建模细胞状态。这一联系从基因组一端延伸到表型另一端。
- en: In summary, today’s LLMs are sufficiently advanced to model molecular biology.
    Further methodological improvements are always welcome. However, the barrier is
    no longer deep learning methodology; the more significant gatekeeper is data.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，今天的LLMs已经足够先进，能够对分子生物学进行建模。进一步的方法学改进始终受欢迎。然而，障碍不再是深度学习方法；更重要的障碍是数据。
- en: Fortunately, data is becoming both cheaper and richer. Advances in DNA sequencing
    technology have reduced the cost of sequencing a human genome from $3Bn billion
    for the first genome, to roughly $1000 a few years back, and now to as low as
    $200 today. The same cost reductions apply to all molecular assays that use DNA
    sequencing as their primary readout. This includes assays for quantifying gene
    expression, chromatin structure, histone modifications, transcription factor binding,
    and hundreds of other ingenious assays developed over the past 10–20 years. Further
    innovations in single-cell technologies, as well as in proteomics, metabolomics,
    lipidomics, and other -omic assays, allow for increasingly detailed and efficient
    measurements of the various molecular layers between DNA and human physiology.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f332e5e1d608fd41a45ff7298759190f.png)![](../Images/32e26abcc26d7824c5d9f8bbb431d45c.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
- en: '**Figure 16\. UK Biobank.** The UK Biobank is a large-scale biomedical database
    and research resource, containing in-depth genetic and health information from
    around 500,000 UK volunteers. The participants were all between the ages of 40–69
    years when they were recruited from 2006–2010\. The data collected includes blood,
    urine and saliva samples, detailed information about the participants’ backgrounds,
    lifestyle and health, and subsequent medical histories accessed through health
    records. For a subset of participants, imaging data (brain, heart, abdomen, bones
    and joints) have also been collected. The exomes of 470,000 individuals were released
    in June 2022, and the entire genomes of all individuals are coming up by the end
    of 2023\. Images provided by UK Biobank and included with permission.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: So, how can all this be put together? A key type of data initiative is one that
    brings together a large group of volunteer participants for deep exploration of
    their -omic data, phenotypes, and health records. A leading example of this is
    the **UK Biobank Project (UKB)**, a large-scale biobank, biomedical database and
    research resource containing comprehensive genetic and health information from
    half a million UK participants (Figure 16). Participant biosamples have been collected
    with broad consent, and a wealth of data is continuously being generated. The
    exomes (protein-coding parts of the genome) of almost all participants have been
    released, with whole genomes to follow. In addition, various types of data are
    available including COVID-19 antibody data, metabolomic, telomere, imaging, genotype,
    clinical measurements, primary care, pain questionnaires, and more. Additional
    data types are continuously added. UKB data are available to anyone for research
    purposes. All Of Us is a similar initiative in the US, which to date has sequenced
    the genomes of 250,000 participants. FinnGen (Finnland Genomics) aims to create
    a similar biobank of 500,000 Finnish participants, which is incredibly valuable
    because genetic studies turn out to be much easier in a cohort that is genetically
    more homogeneous. deCODE Genetics leads a similar effort in Iceland, with more
    than two-thirds of the adult population in Iceland participating in the effort.
    Additional cohorts of sequenced participants exist, including millions of exomes
    sequenced by Regeneron Pharmaceuticals (a private initiative), and many national
    initiatives worldwide.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Cancer in particular is a disease of the genome, and many companies are building
    a wealth of genomic information on cancer patients and cancer samples, and additional
    clinical information. Covering this field is beyond the scope, but it is worth
    mentioning Tempus, an AI-based precision medicine company with a large and growing
    library of clinical and molecular data on cancer, Foundation Medicine, a molecular
    information company that offers comprehensive genomic profiling assays to identify
    the molecular alterations in a patient’s cancer and match them with relevant targeted
    therapies, immunotherapies, and clinical trials, and GRAIL and Guardant Helth,
    two pioneering diagnostic companies that focus on early tumor detection from “liquid
    biopsies” or analysis of the genomic content of patient blood samples, which often
    contain molecular shedding of cancer cells. Each of these companies has data on
    large and growing cohorts of patients.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: In addition to these cohort initiatives, there are numerous other large-scale
    data initiatives. Notably, the Human Cell Atlas project has already produced gene
    expression data for 42 million human cells from 6,300 donor individuals. The ENCODE
    Project, a vast functional genomic dataset on hundreds of human cell lines and
    various molecular quantities, has generated data on gene expression, chromatin
    accessibility, transcription factor binding, histone marks, DNA methylation, and
    more.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些队列倡议，还有许多其他大规模的数据倡议。值得注意的是，人类细胞图谱项目已经为来自 6,300 名捐献者的 4200 万个人类细胞生成了基因表达数据。ENCODE
    项目，作为一个庞大的功能基因组数据集，涵盖了数百个人类细胞系和各种分子量，生成了关于基因表达、染色质可及性、转录因子结合、组蛋白标记、DNA 甲基化等的数据。
- en: 'LLMs are perfectly suited to integrate these data. Looking to the future, we
    could envision a mammoth LLM integrating across all such datasets. So, what might
    the architecture and training of such a model look like? Let’s engage in a thought
    experiment and try to piece it together:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 完美适用于整合这些数据。展望未来，我们可以设想一个庞大的 LLM 跨越所有这些数据集进行整合。那么，这样一个模型的架构和训练可能会是什么样的呢？让我们进行一个思想实验，尝试拼凑出它的全貌：
- en: Genes in the genome, including important variants like different isoforms of
    the resulting proteins, are tokenized.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基因组中的基因，包括像不同异构体这样的重要变异，进行标记化处理。
- en: Different types of cells and tissues are tokenized.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同类型的细胞和组织被进行标记化处理。
- en: Human phenotypes, such as disease states, clinical indications, and adherence
    to drug regimens, are also tokenized.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人类表型，如疾病状态、临床指征和药物治疗依从性，也被进行标记化处理。
- en: DNA sequences are tokenized at a fixed-length nucleotide level.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DNA 序列在固定长度的核苷酸水平上进行标记化处理。
- en: Positional information in the genome connects genes with nucleotide content.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基因组中的位置性信息将基因与核苷酸内容连接起来。
- en: Protein sequences are tokenized using the amino acid alphabet.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蛋白质序列使用氨基酸字母表进行标记化处理。
- en: Data from the Human Cell Atlas and other single-cell datasets train the LLM
    in an autoregressive manner akin to GPT, or with masked language modeling akin
    to BERT, highlighting cell-type specific and cell-state specific gene pathways.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自人类细胞图谱和其他单细胞数据集的数据以类似 GPT 的自回归方式或类似 BERT 的掩码语言建模方式训练 LLM，突出细胞类型特异性和细胞状态特异性的基因通路。
- en: ENCODE and similar data teach the LLM to associate different molecular information
    layers like raw DNA sequence and its variants, gene expression, methylation, histone
    modifications, chromatin accessibility, etc., in a cell-type specific manner.
    Each layer is a distinct “language,” with varying richness and vocabulary, providing
    unique information. The LLM learns to translate between these languages.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ENCODE 和类似的数据教会 LLM 将不同的分子信息层如原始 DNA 序列及其变异、基因表达、甲基化、组蛋白修饰、染色质可及性等以细胞类型特异的方式关联起来。每一层都是一种独特的“语言”，具有不同的丰富性和词汇量，提供独特的信息。LLM
    学会在这些语言之间进行翻译。
- en: Projects like the PrimateAI-3D’s primate genomics initiative and other species
    sequencing efforts instruct the LLM about the potential benign or harmful effects
    of mutations in the human genome.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PrimateAI-3D 的非人类灵长类基因组学倡议以及其他物种测序工作等项目为 LLM 提供了关于人类基因组中突变潜在良性或有害效应的知识。
- en: The entire proteomes including protein variants are enriched with protein 3D
    structural information that is either experimentally obtained or predicted by
    AlphaFold, RoseTTAfold and other structural prediction methods.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 整个蛋白质组，包括蛋白质变异，丰富了蛋白质的 3D 结构信息，这些信息要么是实验获得的，要么是由 AlphaFold、RoseTTAfold 和其他结构预测方法预测的。
- en: Datasets from the UK Biobank (UKB) and other cohorts allow the LLM to associate
    genomic variant information and other molecular data with human health information.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自英国生物库（UKB）及其他队列的数据使 LLM 能够将基因组变异信息和其他分子数据与人类健康信息相关联。
- en: The LLM leverages the complete clinical records of participants to understand
    common practice and its effects, and connect this with other “languages” across
    all datasets.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM 利用参与者的完整临床记录来理解常规实践及其效果，并将其与所有数据集中的其他“语言”关联起来。
- en: The LLM harnesses the vast existing literature on basic biology, genetics, molecular
    science, and clinical practice, including all known associations of genes and
    phenotypes.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM 利用基础生物学、遗传学、分子科学和临床实践的广泛现有文献，包括所有已知的基因与表型的关联。
- en: 'Developing such an LLM presents a significant challenge, which is of different
    kind than the GPT line of LLMs. It requires technical innovation to represent
    and integrate the various information layers, as well scaling up the number of
    tokens processed by the model. Potential applications of such an LLM are vast.
    To list a few:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 开发这样的 LLM 是一项重大的挑战，与 GPT 系列的 LLM 不同。这需要技术创新来表示和整合各种信息层，并扩大模型处理的 token 数量。这样的
    LLM 具有广泛的潜在应用。列举几项：
- en: '**Clinical diagnosis.** It could leverage all available patient information,
    including their genome, other measurements, entire clinical history, and family
    health information, aiding doctors in making precise diagnoses, even for rare
    conditions. It could be particularly useful in diagnosing rare diseases and subtyping
    cancers.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**临床诊断。** 它可以利用所有可用的患者信息，包括其基因组、其他测量、完整的临床历史和家庭健康信息，帮助医生做出准确的诊断，即使是对罕见疾病。它在诊断罕见疾病和癌症亚型时尤其有用。'
- en: '**Drug development.** The LLM could help identify promising gene and pathway
    targets for different clinical indications, individuals likely to respond to certain
    drugs, and those unlikely to benefit, thereby increasing the success of clinical
    trials. It could also assist in drug molecule development and drug repurposing.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**药物开发。** LLM 可以帮助识别不同临床指示的有前景的基因和通路靶点，预测对某些药物可能有反应的个体，以及那些不太可能受益的个体，从而提高临床试验的成功率。它还可以协助药物分子开发和药物重新定位。'
- en: '**Basic molecular biology.** Each of the layers of molecular information will
    be connected to other layers in a manner similar to language translation, and
    the LLM will be probed for features that provide substantial predictive power.
    Whereas interpretation of deep learning models is a challenge, impressive advances
    are continuusly made by a research community that is eager to make AI interpretable.
    In the latest such advance by OpenAI4 , GPT-4 has just been deployed to explain
    the behavior of each of the neurons of GPT-2\. *(https://openai.com/research/language-models-can-explain-neurons-in-language-models)*'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基础分子生物学。** 每个分子信息层将以类似语言翻译的方式与其他层连接，LLM 将被探测以提供显著的预测能力。虽然深度学习模型的解释是一个挑战，但研究社区不断取得令人印象深刻的进展，致力于使
    AI 可解释。在 OpenAI4 的最新进展中，GPT-4 刚刚被部署来解释 GPT-2 的每个神经元的行为。*(https://openai.com/research/language-models-can-explain-neurons-in-language-models)*'
- en: '**Suggestions of additional experiments.** The model can be leveraged to identify
    the “gaps’’ in the training data, in the form of cell types, or molecular layers,
    or even individuals of specific genetic background or disease indications, which
    are predicted with poor confidence levels from other data.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**额外实验的建议。** 该模型可以用于识别训练数据中的“空白”，例如细胞类型、分子层次，或特定遗传背景或疾病指示的个体，这些在其他数据中预测的置信度较低。'
- en: While developing these technologies, it’s essential to consider potential risks,
    including those related to **patient privacy** and clinical practice. Patient
    privacy remains a significant concern. This is especially true for LLMs, because
    depending on the capacity of the model, in principle the data of participants
    that were used to train the model is retrievable through a prompt that includes
    part of that data or other information that hones in to a specific patient. Therefore,
    it is especially important when training LLMs with participant data to have proper
    informed consent for the intended use of and access to these models.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发这些技术时，必须考虑潜在的风险，包括与**患者隐私**和临床实践相关的风险。患者隐私仍然是一个重大关注点。这对于 LLM 尤其如此，因为根据模型的能力，原则上可以通过包含部分数据的提示或其他信息来检索用于训练模型的参与者数据。因此，在用参与者数据训练
    LLM 时，特别重要的是要获得针对这些模型预期用途和访问的适当知情同意。
- en: However, many individuals, exemplified by the participants in the UK Biobank
    cohort, are motivated to share their data and biosamples generously, providing
    immense benefits for research and society. As for clinical practice, it’s unclear
    if LLMs can independently be used for diagnosis and treatment recommendations.
    The primary purpose of these models is not to replace, but to assist healthcare
    professionals, offering powerful tools that doctors can use to verify and audit
    medical information. To quote Isaac Kohane, “trust, but verify” (Lee, Goldberg,
    Kohane 2023).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: 'So, what are the hurdles to fully implement an LLM to bridge genetics, molecular
    biology, and human health? The main obstacle is data availability. The production
    of functional genomic data, such as those from ENCODE and the Human Cell Atlas,
    needs to be accelerated. Fortunately, the cost of generating such data is rapidly
    decreasing. Simultaneously, multiomic cohort and clinical data must be produced
    and made publicly accessible. This process requires participants’ consent, taking
    into account legitimate privacy concerns. However, alongside the inalienable right
    to privacy, there’s an equally important right to participant data transparency:
    many people *want* to contribute by sharing their data. This is especially true
    for patients of rare genetic diseases and cancer, who want to help other patients
    by contributing to the study of the disease and development of treatments. The
    success of the UK Biobank is a testament to participants’ generosity in data sharing,
    aiming to make a positive impact on human health.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Molecular biology is not a set of neat concepts and clear principles, but a
    collection of trillions of little facts assembled over eons of trial and error.
    Human biologists excel in storytelling, putting these facts into descriptions
    and stories that help with intuition and experimental planning. However, making
    biology into a computational science requires a combination of massive data acquisition
    and computational models of the right capacity to distill the trillions of biological
    facts from data. With LLMs and the accelerating pace of data acquisition, we are
    indeed a few years away from having accurate in silico predictive models of the
    primary biomolecular information highway, to connect our DNA, cellular biology,
    and health. We can reasonably expect that over the next 5-10 years a wealth of
    biomedical diagnostic, drug discovery, and health span companies and initiatives
    will bring these models to application in human health and medicine, with enormous
    impact. We will also likely witness the development of open foundation models
    that integrate across data spanning from genomes all the way to medical information.
    Such models will vastly accelerate research and innovation, and foster precision
    medicine.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgments
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I thank Eric Schadt and Bo Wang for numerous suggestions and edits to the document.
    I thank Anshul Kundaje, Bo Wang and Kyle Farh for providing thoughts, comments
    and figures. I thank Lukas Kuderna for creating the Primate Phylogeny figure for
    this manuscript. I am an employee of Seer, Inc, however all opinions expressed
    here are my own.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '**References**'
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Avsek Z et al. Effective gene expression prediction from sequence by integrating
    long-range interactions. Nature Methods 2021.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Baek M et al. Accurate prediction of protein structures and interactions using
    a three-track neural network. Science 2021.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: 'Baek M et al. Efficient and accurate prediction of protein structure using
    RoseTTAFold2\. biorXiv doi: [https://doi.org/10.1101/2023.05.24.542179](https://doi.org/10.1101/2023.05.24.542179),
    2023.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: 'Bubeck S et al. Sparks of Artificial General Intelligence: Early experiments
    with GPT-4\. [arXiv:2303.12712](https://arxiv.org/abs/2303.12712), 2023.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: 'Cui et al. scGPT: Towards Building a Foundation Model for Single-Cell Multi-omics
    Using Generative AI. biorXiv [https://doi.org/10.1101/2023.04.30.538439](https://doi.org/10.1101/2023.04.30.538439),
    2023.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: 'Dalla-Torre H et al. The Nucleotide Transformer: Building and Evaluating Robust
    Foundation Models for Human Genomics. biorXiv [https://doi.org/10.1101/2023.01.11.523679](https://doi.org/10.1101/2023.01.11.523679),
    2023.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: 'Devlin J et al. BERT: Pre-training of Deep Bidirectional Transformers for Language
    Understanding. [arXiv:1810.04805](https://arxiv.org/abs/1810.04805), 2018.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Fiziev P et al. Rare penetrant mutations confer severe risk of common diseases.
    Science 2023.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Gao et al. The landscape of tolerated genetic variation in humans and primates.
    Science 2023.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Jaganathan et al. Predicting splicing from primary sequence with deep learning.
    Cell 2019.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Jumper, J., Evans, R., Pritzel, A. *et al.* Highly accurate protein structure
    prediction with AlphaFold. *Nature* **596**, 583–589, 2021.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Karollus et al. Current sequence-based models capture gene expression determinants
    in promoters but mostly ignore distal enhancers. Genome Biology 2023.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: Kong et al. Rate of de novo mutations and the importance of father’s age to
    disease risk. Nature 2012.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: 'Lee P, Goldberg C, Kohane I. The AI Revolution in Medicine: GPT-4 and Beyond.
    Pearson, 2023.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: Lin Z et al. Evolutionary-scale prediction of atomic-level protein structure
    with a language model. Science 2023.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: Lyayuga Lisanza S et al. Joint generation of protein sequence and structure
    with RoseTTAFold sequence space diffusion. biorXiv [https://doi.org/10.1101/2023.05.08.539766](https://doi.org/10.1101/2023.05.08.539766),
    2023.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: Sasse et al. How far are we from personalized gene expression prediction using
    sequence-to-expression deep neural networks? biorXiv [https://doi.org/10.1101/2023.03.16.532969](https://doi.org/10.1101/2023.03.16.532969),
    2023.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Sundaram et al. Predicting the clinical impact of human mutation with deep neural
    networks. Nature Genetics 2018.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: 'Varadi M et al. AlphaFold Protein Structure Database: massively expanding the
    structural coverage of protein-sequence space with high-accuracy models. Nucleic
    Acids Research, 2021.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Wang S et al. Accurate De Novo Prediction of Protein Contact Map by Ultra-Deep
    Learning Model. PLoS Computational Biology 2017.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: Wolfram S. What is ChatGPT doing… and why does it work? Wolfram Media, Inc.
    2023.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Zhou J. Sequence-based modeling of three-dimensional genome architecture from
    kilobase to chromosome scale. Nature Genetics 2022.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
