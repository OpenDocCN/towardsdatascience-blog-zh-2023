["```py\ndef signal0(samples_per_signal, noise_amplitude):\n    x = np.linspace(0, 4.0, samples_per_signal)\n    y = np.sin(x * np.pi * 0.5)\n    n = np.random.randn(samples_per_signal) * noise_amplitude\n\n    s = y + n\n\n    shift = np.random.randint(low=0, high=int(samples_per_signal / 2))\n    s = np.concatenate([s[shift:], s[:shift]])\n\n    return np.asarray(s, dtype=np.float32)\n\ndef signal1(samples_per_signal, noise_amplitude):\n    x = np.linspace(0, 4.0, samples_per_signal)\n    y = np.sin(x * np.pi)\n    n = np.random.randn(samples_per_signal) * noise_amplitude\n\n    s = y + n\n\n    shift = np.random.randint(low=0, high=int(samples_per_signal / 2))\n    s = np.concatenate([s[shift:], s[:shift]])\n\n    return np.asarray(s, dtype=np.float32) \n```", "```py\nclass Network(nn.Module):\n\n    def __init__(self, signal_size):\n\n        c = int(signal_size / 10)\n        if c < 3:\n            c = 3\n\n        super().__init__()\n        self.cnn = nn.Sequential(\n            nn.Conv1d(1, 8, c),\n            nn.ReLU(),\n            nn.AvgPool1d(2),\n            nn.Conv1d(8, 16, c),\n            nn.ReLU(),\n            nn.AvgPool1d(2),\n            nn.ReLU(),\n            nn.Flatten()\n        )\n\n        l = 0\n        with torch.no_grad():\n            s = torch.randn((1,1,SAMPLES_PER_SIGNAL))\n            o = self.cnn(s)\n            l = o.shape[1]\n\n        self.head = nn.Sequential(\n            nn.Linear(l, 2 * l),\n            nn.ReLU(),\n            nn.Linear(2 * l, 2),\n            nn.ReLU(),\n            nn.Softmax(dim=1)\n        )\n\n    def forward(self, x):\n\n        x = self.cnn(x)\n        x = self.head(x)\n\n        return x\n```", "```py\nSAMPLES_PER_SIGNAL = 100\nSIGNALS_IN_DATASET = 20\nNOISE_AMPLITUDE = 0.1\nREPEAT_EXPERIMENT = 10\n\nX, Y = [], []\n\nstop = int(SIGNALS_IN_DATASET / 2)\nfor i in range(SIGNALS_IN_DATASET):\n\n    if i < stop:\n        x = signal0(SAMPLES_PER_SIGNAL, NOISE_AMPLITUDE)\n        y = 0\n    else:\n        x = signal1(SAMPLES_PER_SIGNAL, NOISE_AMPLITUDE)\n        y = 1\n\n    X.append(x.reshape(1,-1))\n    Y.append(y)\n\nX = np.concatenate(X)\nY = np.array(Y, dtype=np.int64)\n\ntrain_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.1)\n\naccs = []\ntrain_accs = []\n\nfor i in range(REPEAT_EXPERIMENT):\n\n    net = NeuralNetClassifier(\n        lambda: Network(SAMPLES_PER_SIGNAL),\n        max_epochs=200,\n        criterion=nn.CrossEntropyLoss(),\n        lr=0.1,\n        callbacks=[\n            #('lr_scheduler', LRScheduler(policy=ReduceLROnPlateau, monitor=\"valid_acc\", mode=\"min\", verbose=True)),\n            ('lr_scheduler', LRScheduler(policy=CyclicLR, base_lr=0.0001, max_lr=0.01, step_size_up=10)),\n        ],\n        verbose=False,\n        batch_size=128\n    )\n\n    net = net.fit(train_x.reshape(train_x.shape[0], 1, SAMPLES_PER_SIGNAL), train_y)\n    pred = net.predict(test_x.reshape(test_x.shape[0], 1, SAMPLES_PER_SIGNAL))\n    acc = accuracy_score(test_y, pred)\n\n    print(f\"{i} - {acc}\")\n\n    accs.append(acc)\n\n    pred_train = net.predict(train_x.reshape(train_x.shape[0], 1, SAMPLES_PER_SIGNAL))\n    train_acc = accuracy_score(train_y, pred_train)\n    train_accs.append(train_acc)\n\n    print(f\"Train Acc: {train_acc}, Test Acc: {acc}\")\n\naccs = np.array(accs)\ntrain_accs = np.array(train_accs)\n\nprint(f\"Average acc: {accs.mean()}\")\nprint(f\"Average train acc: {train_accs.mean()}\")\nprint(f\"Average acc where training was successful: {accs[train_accs > 0.6].mean()}\")\nprint(f\"Training success rate: {(train_accs > 0.6).mean()}\")\n```", "```py\nX, Y = [], []\n\nstop = int(SIGNALS_IN_DATASET / 2)\nfor i in range(SIGNALS_IN_DATASET):\n\n    if i < stop:\n        x = signal0(SAMPLES_PER_SIGNAL, NOISE_AMPLITUDE)\n        y = 0\n    else:\n        x = signal1(SAMPLES_PER_SIGNAL, NOISE_AMPLITUDE)\n        y = 1\n\n    # Transforming signal into spectrum\n    x = np.abs(fft(x[:int(SAMPLES_PER_SIGNAL /2 )]))    \n\n    X.append(x.reshape(1,-1))\n    Y.append(y)\n\nX = np.concatenate(X)\nY = np.array(Y, dtype=np.int64)\n\ntrain_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.1)\n\naccs = []\ntrain_accs = []\n\nfor i in range(REPEAT_EXPERIMENT):\n    model = RandomForestClassifier()\n    model.fit(train_x, train_y)\n\n    pred = model.predict(test_x)\n    acc = accuracy_score(test_y, pred)\n\n    print(f\"{i} - {acc}\")\n\n    accs.append(acc)\n\n    pred_train = model.predict(train_x)\n    train_acc = accuracy_score(train_y, pred_train)\n    train_accs.append(train_acc)\n\n    print(f\"Train Acc: {train_acc}, Test Acc: {acc}\")\n\naccs = np.array(accs)\ntrain_accs = np.array(train_accs)\n\nprint(f\"Average acc: {accs.mean()}\")\nprint(f\"Average train acc: {train_accs.mean()}\")\nprint(f\"Average acc where training was successful: {accs[train_accs > 0.6].mean()}\")\nprint(f\"Training success rate: {(train_accs > 0.6).mean()}\")\n```"]