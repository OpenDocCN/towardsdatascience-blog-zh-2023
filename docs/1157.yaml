- en: No More OOM-Exceptions During Hyperparameter Searches in TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/no-more-oom-exceptions-during-hyperparameter-searches-in-tensorflow-26e6e3069bc9?source=collection_archive---------3-----------------------#2023-04-01](https://towardsdatascience.com/no-more-oom-exceptions-during-hyperparameter-searches-in-tensorflow-26e6e3069bc9?source=collection_archive---------3-----------------------#2023-04-01)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Use wrapper functions to avoid OOM-exceptions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://pascaljanetzky.medium.com/?source=post_page-----26e6e3069bc9--------------------------------)[![Pascal
    Janetzky](../Images/43d68509b63c5f9b3fc9cef3cbfc1a88.png)](https://pascaljanetzky.medium.com/?source=post_page-----26e6e3069bc9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----26e6e3069bc9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----26e6e3069bc9--------------------------------)
    [Pascal Janetzky](https://pascaljanetzky.medium.com/?source=post_page-----26e6e3069bc9--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F672b95fdf976&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fno-more-oom-exceptions-during-hyperparameter-searches-in-tensorflow-26e6e3069bc9&user=Pascal+Janetzky&userId=672b95fdf976&source=post_page-672b95fdf976----26e6e3069bc9---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----26e6e3069bc9--------------------------------)
    ·8 min read·Apr 1, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F26e6e3069bc9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fno-more-oom-exceptions-during-hyperparameter-searches-in-tensorflow-26e6e3069bc9&user=Pascal+Janetzky&userId=672b95fdf976&source=-----26e6e3069bc9---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F26e6e3069bc9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fno-more-oom-exceptions-during-hyperparameter-searches-in-tensorflow-26e6e3069bc9&source=-----26e6e3069bc9---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: It’s the year 2023\. Machine learning is no longer hype but at the core of everyday
    products. Ever faster hardware makes it possible to train ever larger machine
    learning models — in shorter times, too. With around 100 papers submitted per
    day on machine learning or related domains to [arXiv](https://arxiv.org/list/cs.LG/pastweek?skip=0&show=635),
    chances are high that at least one-third of them have leveraged the hardware’s
    capabilities to do hyperparameter searches to optimize their used model. And that’s
    straightforward, is it not? Just pick a framework — [Optuna](https://optuna.org),
    [wandb](https://wandb.ai/site), whatever — plug in your normal training loop,
    and…
  prefs: []
  type: TYPE_NORMAL
- en: OOM error.
  prefs: []
  type: TYPE_NORMAL
- en: At least, that’s what frequently happens with TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b3e570b3e786fedc8cb8fa13c920d878.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [İsmail Enes Ayhan](https://unsplash.com/@ismailenesayhan?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: The current state
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The lack of a function to properly free GPU memory has spurred many discussions
    and questions in Q&A forums like StackOverflow or GitHub ([1](https://stackoverflow.com/questions/39758094/clearing-tensorflow-gpu-memory-after-model-execution),
    [2](https://github.com/tensorflow/tensorflow/issues/36465), [3](https://stackoverflow.com/questions/69296496/clear-the-graph-and-free-the-gpu-memory-in-tensorflow-2),
    [4](https://discuss.tensorflow.org/t/clear-the-graph-and-free-the-gpu-memory-in-tensorflow-2/4731),
    [5](https://github.com/keras-team/keras/issues/12625), [6](https://stackoverflow.com/questions/75644097/is-there-a-way-to-clear-gpu-memory-after-training-the-tf2-model)).
    For each question, a similar set of workarounds is proposed:'
  prefs: []
  type: TYPE_NORMAL
- en: '- Limit GPU memory growth'
  prefs: []
  type: TYPE_NORMAL
- en: '- Use the numba library to clear the GPU'
  prefs: []
  type: TYPE_NORMAL
- en: '- Use native TF functions that *should* do that'
  prefs: []
  type: TYPE_NORMAL
- en: '- Switch to PyTorch'
  prefs: []
  type: TYPE_NORMAL
