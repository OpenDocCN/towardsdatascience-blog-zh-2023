- en: 'TiDE: the ‘embarrassingly’ simple MLP that beats Transformers'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/tide-the-embarrassingly-simple-mlp-that-beats-transformers-7db77d588079?source=collection_archive---------1-----------------------#2023-12-08](https://towardsdatascience.com/tide-the-embarrassingly-simple-mlp-that-beats-transformers-7db77d588079?source=collection_archive---------1-----------------------#2023-12-08)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A deep exploration of TiDE, its implementation using Darts and a real life use
    case comparison with DeepAR and TFT (a Transformer architecture)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@rjguedes?source=post_page-----7db77d588079--------------------------------)[![Rafael
    Guedes](../Images/b3d000b3bce0113d2b2727e84db04870.png)](https://medium.com/@rjguedes?source=post_page-----7db77d588079--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7db77d588079--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7db77d588079--------------------------------)
    [Rafael Guedes](https://medium.com/@rjguedes?source=post_page-----7db77d588079--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2789d1da9c75&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftide-the-embarrassingly-simple-mlp-that-beats-transformers-7db77d588079&user=Rafael+Guedes&userId=2789d1da9c75&source=post_page-2789d1da9c75----7db77d588079---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7db77d588079--------------------------------)
    ·9 min read·Dec 8, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7db77d588079&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftide-the-embarrassingly-simple-mlp-that-beats-transformers-7db77d588079&user=Rafael+Guedes&userId=2789d1da9c75&source=-----7db77d588079---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7db77d588079&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftide-the-embarrassingly-simple-mlp-that-beats-transformers-7db77d588079&source=-----7db77d588079---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: As industries continue to evolve, the importance of an accurate forecasting
    becomes a non-negotiable asset whether you work in e-commerce, healthcare, retail
    or even in agriculture. The importance of being able to foresee what comes next
    and plan accordingly to overcome future challenges is what can make you ahead
    of competition and thrive in an economy where margins are tight and the customers
    are more demanding than ever.
  prefs: []
  type: TYPE_NORMAL
- en: Transformer architectures have been the hot topic in AI for the past few years,
    specially due to their success in Natural Language Processing (NLP) being one
    of the most successful use cases the chatGPT that took the attention of everyone
    regardless if you were an AI enthusiastic or not. But NLP is not the only subject
    where Transformers have been shown to outperform the state-of-the-art solutions,
    in Computer Vision as well with Stable Diffusion and its variants.
  prefs: []
  type: TYPE_NORMAL
- en: But can Transformers outperform state-of-the-art models in time series? Although
    many efforts have been made to develop Transformers for time series forecasting,
    it seems that for long term horizons, simple linear models can outperform several
    Transformer based approaches.
  prefs: []
  type: TYPE_NORMAL
