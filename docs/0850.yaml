- en: Geometric Deep Learning on Groups
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¾¤ä½“ä¸Šçš„å‡ ä½•æ·±åº¦å­¦ä¹ 
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/geometric-deep-learning-on-groups-cec82eb9366?source=collection_archive---------17-----------------------#2023-03-06](https://towardsdatascience.com/geometric-deep-learning-on-groups-cec82eb9366?source=collection_archive---------17-----------------------#2023-03-06)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/geometric-deep-learning-on-groups-cec82eb9366?source=collection_archive---------17-----------------------#2023-03-06](https://towardsdatascience.com/geometric-deep-learning-on-groups-cec82eb9366?source=collection_archive---------17-----------------------#2023-03-06)
- en: Continuous vs discrete approaches on the sphere
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Continuous vs discrete approaches on the sphere
- en: '[](https://jasonmcewen.medium.com/?source=post_page-----cec82eb9366--------------------------------)[![Jason
    McEwen](../Images/794e7e6546ed049860dab5e294535880.png)](https://jasonmcewen.medium.com/?source=post_page-----cec82eb9366--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cec82eb9366--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cec82eb9366--------------------------------)
    [Jason McEwen](https://jasonmcewen.medium.com/?source=post_page-----cec82eb9366--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://jasonmcewen.medium.com/?source=post_page-----cec82eb9366--------------------------------)[![Jason
    McEwen](../Images/794e7e6546ed049860dab5e294535880.png)](https://jasonmcewen.medium.com/?source=post_page-----cec82eb9366--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cec82eb9366--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cec82eb9366--------------------------------)
    [Jason McEwen](https://jasonmcewen.medium.com/?source=post_page-----cec82eb9366--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fea87e920245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeometric-deep-learning-on-groups-cec82eb9366&user=Jason+McEwen&userId=ea87e920245&source=post_page-ea87e920245----cec82eb9366---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cec82eb9366--------------------------------)
    Â·6 min readÂ·Mar 6, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcec82eb9366&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeometric-deep-learning-on-groups-cec82eb9366&user=Jason+McEwen&userId=ea87e920245&source=-----cec82eb9366---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fea87e920245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeometric-deep-learning-on-groups-cec82eb9366&user=Jason+McEwen&userId=ea87e920245&source=post_page-ea87e920245----cec82eb9366---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cec82eb9366--------------------------------)
    Â·6 min readÂ·Mar 6, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcec82eb9366&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeometric-deep-learning-on-groups-cec82eb9366&user=Jason+McEwen&userId=ea87e920245&source=-----cec82eb9366---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcec82eb9366&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeometric-deep-learning-on-groups-cec82eb9366&source=-----cec82eb9366---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcec82eb9366&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeometric-deep-learning-on-groups-cec82eb9366&source=-----cec82eb9366---------------------bookmark_footer-----------)'
- en: '*Ideally geometric deep learning techniques on groups would encode equivariance
    to group transformations, to provide well-behaved representation spaces and excellent
    performance, while also being computationally efficient. However, no single approach
    provides both of these desirable properties. Continuous approaches offer excellent
    equivariance but with a very large computational cost. Discrete approaches are
    typically relatively computationally efficient but sacrifice equivariance. We
    point towards future techniques that achieve the best of both worlds.*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*ç†æƒ³æƒ…å†µä¸‹ï¼Œç¾¤ä½“ä¸Šçš„å‡ ä½•æ·±åº¦å­¦ä¹ æŠ€æœ¯åº”è¯¥èƒ½å¤Ÿç¼–ç å¯¹ç¾¤ä½“å˜æ¢çš„ç­‰å˜æ€§ï¼Œä»¥æä¾›è‰¯å¥½çš„è¡¨ç¤ºç©ºé—´å’Œå‡ºè‰²çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¹Ÿè¦å…·å¤‡è®¡ç®—æ•ˆç‡ã€‚ç„¶è€Œï¼Œæ²¡æœ‰ä¸€ç§æ–¹æ³•èƒ½å¤ŸåŒæ—¶æä¾›è¿™ä¸¤ç§ç†æƒ³çš„å±æ€§ã€‚è¿ç»­çš„æ–¹æ³•æä¾›äº†ä¼˜ç§€çš„ç­‰å˜æ€§ï¼Œä½†è®¡ç®—æˆæœ¬éå¸¸é«˜ã€‚ç¦»æ•£çš„æ–¹æ³•é€šå¸¸è®¡ç®—æ•ˆç‡ç›¸å¯¹è¾ƒé«˜ï¼Œä½†ç‰ºç‰²äº†ç­‰å˜æ€§ã€‚æˆ‘ä»¬æŒ‡å‡ºäº†æœªæ¥èƒ½å¤Ÿå…¼å…·è¿™ä¸¤è€…ä¼˜ç‚¹çš„æŠ€æœ¯ã€‚*'
- en: '![](../Images/b7a2db73eea2c07103c581afc144a2ff.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b7a2db73eea2c07103c581afc144a2ff.png)'
- en: Photo by [Serg Antonov](https://unsplash.com/@antonov?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ç…§ç‰‡ç”± [Serg Antonov](https://unsplash.com/@antonov?utm_source=medium&utm_medium=referral)
    æä¾›ï¼Œå‘å¸ƒåœ¨ [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Deep learning on groups is a rapidly growing area of geometric deep learning
    (see our recent TDS article on [*A Brief Introduction to Geometric Deep Learning*](/a-brief-introduction-to-geometric-deep-learning-dae114923ddb)).
    [Groups](https://en.wikipedia.org/wiki/Group_theory) include homogenous spaces
    with global symmetries, with the archetypical example being the sphere.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ç¾¤ä½“ä¸Šçš„æ·±åº¦å­¦ä¹ æ˜¯å‡ ä½•æ·±åº¦å­¦ä¹ ä¸€ä¸ªå¿«é€Ÿå¢é•¿çš„é¢†åŸŸï¼ˆå‚è§æˆ‘ä»¬æœ€è¿‘çš„ TDS æ–‡ç«  [*å‡ ä½•æ·±åº¦å­¦ä¹ ç®€è¦ä»‹ç»*](/a-brief-introduction-to-geometric-deep-learning-dae114923ddb)ï¼‰ã€‚[ç¾¤ä½“](https://en.wikipedia.org/wiki/Group_theory)åŒ…æ‹¬å…·æœ‰å…¨å±€å¯¹ç§°æ€§çš„åŒè´¨ç©ºé—´ï¼Œå…¶ä¸­æœ€å…¸å‹çš„ä¾‹å­æ˜¯çƒé¢ã€‚
- en: Practical applications on geometric deep learning on groups are prevalent, particularly
    for the sphere. For example, spherical data arise in myrad applications, not only
    when data is acquired directly on the sphere (such as over the Earth or by 360Â°
    cameras that capture panoramic photos and videos), but also when considering spherical
    symmetries (such as in molecular chemistry or magnetic resonance imaging).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å‡ ä½•æ·±åº¦å­¦ä¹ åœ¨ç¾¤ä½“ä¸Šçš„å®é™…åº”ç”¨å¾ˆæ™®éï¼Œå°¤å…¶æ˜¯åœ¨çƒé¢ä¸Šã€‚ä¾‹å¦‚ï¼Œçƒå½¢æ•°æ®åœ¨è®¸å¤šåº”ç”¨ä¸­å‡ºç°ï¼Œä¸ä»…åœ¨æ•°æ®ç›´æ¥è·å–è‡ªçƒé¢æ—¶ï¼ˆä¾‹å¦‚åœ°çƒä¸Šçš„æ•°æ®æˆ–é€šè¿‡ 360Â° ç›¸æœºæ•æ‰å…¨æ™¯ç…§ç‰‡å’Œè§†é¢‘æ—¶ï¼‰ï¼Œè¿˜åŒ…æ‹¬è€ƒè™‘çƒé¢å¯¹ç§°æ€§æ—¶ï¼ˆä¾‹å¦‚åˆ†å­åŒ–å­¦æˆ–ç£å…±æŒ¯æˆåƒï¼‰ã€‚
- en: We need deep learning techniques on groups that are both highly effective and
    scalable to huge datasets of high-resolution data. In general this problem remains
    unsolved.
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦åœ¨ç¾¤ä½“ä¸Šæ—¢é«˜æ•ˆåˆå¯æ‰©å±•åˆ°å¤§è§„æ¨¡é«˜åˆ†è¾¨ç‡æ•°æ®é›†çš„æ·±åº¦å­¦ä¹ æŠ€æœ¯ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œè¿™ä¸ªé—®é¢˜ä»ç„¶æ²¡æœ‰è§£å†³ã€‚
- en: '![](../Images/3875a12177434d39615895de8cbdece3.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3875a12177434d39615895de8cbdece3.png)'
- en: An example of spherical data. [Photo by [NASA](https://unsplash.com/@nasa?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)]
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªçƒå½¢æ•°æ®çš„ä¾‹å­ã€‚[ç…§ç‰‡ç”± [NASA](https://unsplash.com/@nasa?utm_source=medium&utm_medium=referral)
    æä¾›ï¼Œæ¥è‡ª [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)]
- en: Goals
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç›®æ ‡
- en: One of the reasons deep learning techniques have been so effective is due to
    the inductive biases encoded in modern architectures.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æ·±åº¦å­¦ä¹ æŠ€æœ¯ä¹‹æ‰€ä»¥å¦‚æ­¤æœ‰æ•ˆï¼Œéƒ¨åˆ†åŸå› æ˜¯ç°ä»£æ¶æ„ä¸­ç¼–ç çš„å½’çº³åå·®ã€‚
- en: One particularly powerful inductive bias is to encode symmetries that the data
    are known to satisfy (as elaborated in our TDS article [*What Einstein Can Teach
    Us About Machine Learning*](/what-einstein-can-teach-us-about-machine-learning-1661e26bef2c)*).*
    Convolutional neural networks (CNNs), for example, encode translational symmetry
    or, more precisely, translational equivariance, as illustrated in the diagram
    below.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªç‰¹åˆ«å¼ºå¤§çš„å½’çº³åå·®æ˜¯ç¼–ç æ•°æ®å·²çŸ¥æ»¡è¶³çš„å¯¹ç§°æ€§ï¼ˆå¦‚æˆ‘ä»¬ TDS æ–‡ç«  [*çˆ±å› æ–¯å¦å¯ä»¥æ•™æˆ‘ä»¬ä»€ä¹ˆå…³äºæœºå™¨å­¦ä¹ *](/what-einstein-can-teach-us-about-machine-learning-1661e26bef2c)*ï¼‰æ‰€é˜è¿°çš„ï¼‰ã€‚ä¾‹å¦‚ï¼Œå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNsï¼‰ç¼–ç äº†å¹³ç§»å¯¹ç§°æ€§ï¼Œæˆ–æ›´ç¡®åˆ‡åœ°è¯´ï¼Œå¹³ç§»ç­‰å˜æ€§ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚
- en: '![](../Images/dfaac1eb43106dd1ca19d77ccbeeb762.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dfaac1eb43106dd1ca19d77ccbeeb762.png)'
- en: llustration of translational equivariance. Given an image (top left), applying
    a convolutional kernel (ğ’œ) to obtain a feature map (top right) and then translating
    (ğ’¯) the feature map (bottom right) is equivalent to first translating the image
    (bottom left) and then applying the convolution kernel (bottom right). [Original
    figure created by authors.]
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å¹³ç§»ç­‰å˜æ€§çš„è¯´æ˜ã€‚ç»™å®šä¸€å¼ å›¾åƒï¼ˆå·¦ä¸Šï¼‰ï¼Œåº”ç”¨å·ç§¯æ ¸ï¼ˆğ’œï¼‰ä»¥è·å¾—ç‰¹å¾å›¾ï¼ˆå³ä¸Šï¼‰ï¼Œç„¶åå¹³ç§»ï¼ˆğ’¯ï¼‰ç‰¹å¾å›¾ï¼ˆå³ä¸‹ï¼‰ï¼Œç­‰åŒäºé¦–å…ˆå¹³ç§»å›¾åƒï¼ˆå·¦ä¸‹ï¼‰ï¼Œç„¶ååº”ç”¨å·ç§¯æ ¸ï¼ˆå³ä¸‹ï¼‰ã€‚[åŸå§‹å›¾å½¢ç”±ä½œè€…åˆ›å»ºã€‚]
- en: Encoding equivariance in deep learning architectures results in well-behaved
    feature spaces where learning can be performed very effectively.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ·±åº¦å­¦ä¹ æ¶æ„ä¸­ç¼–ç ç­‰å˜æ€§ä¼šäº§ç”Ÿè¡Œä¸ºè‰¯å¥½çš„ç‰¹å¾ç©ºé—´ï¼Œä½¿å¾—å­¦ä¹ å¯ä»¥éå¸¸æœ‰æ•ˆåœ°è¿›è¡Œã€‚
- en: For geometric deep learning on groups we would therefore like to encode equivariance
    to various group transformations, which typically results in very good performance.
    However, in the general group setting this becomes highly computational demanding
    â€” prohibitively so in many cases.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå¯¹äºç¾¤ä½“ä¸Šçš„å‡ ä½•æ·±åº¦å­¦ä¹ ï¼Œæˆ‘ä»¬å¸Œæœ›ç¼–ç å¯¹å„ç§ç¾¤ä½“å˜æ¢çš„ç­‰å˜æ€§ï¼Œè¿™é€šå¸¸ä¼šå¸¦æ¥éå¸¸å¥½çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œåœ¨ä¸€èˆ¬çš„ç¾¤ä½“è®¾ç½®ä¸­ï¼Œè¿™å˜å¾—éå¸¸è®¡ç®—å¯†é›†â€”â€”åœ¨è®¸å¤šæƒ…å†µä¸‹æ˜¯ä¸å¯è¡Œçš„ã€‚
- en: How to encode equivariance in deep learning architectures on groups in a computationally
    scalable manner is an active area of research.
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å¦‚ä½•åœ¨æ·±åº¦å­¦ä¹ æ¶æ„ä¸­ä»¥è®¡ç®—ä¸Šå¯æ‰©å±•çš„æ–¹å¼ç¼–ç ç­‰å˜æ€§æ˜¯ä¸€ä¸ªæ´»è·ƒçš„ç ”ç©¶é¢†åŸŸã€‚
- en: Group convolution
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¾¤ä½“å·ç§¯
- en: The notion of convolution, which is responsible for the huge success of CNN
    architectures for planar images, naturally encodes equivariance and can be generalised
    to the group setting.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å·ç§¯çš„æ¦‚å¿µï¼Œè´Ÿè´£ CNN æ¶æ„åœ¨å¹³é¢å›¾åƒä¸Šçš„å·¨å¤§æˆåŠŸï¼Œè‡ªç„¶åœ°ç¼–ç äº†ç­‰å˜æ€§ï¼Œå¹¶ä¸”å¯ä»¥æ¨å¹¿åˆ°ç¾¤ä½“è®¾ç½®ã€‚
- en: The group convolution of a signal (i.e. data, feature map) *f* defined over
    the group, with a filter *ğ­*, is given by
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ç¾¤ä¸Šä¿¡å·ï¼ˆå³æ•°æ®ã€ç‰¹å¾å›¾ï¼‰*f* ä¸æ»¤æ³¢å™¨ *ğ­* çš„ç¾¤å·ç§¯è¡¨ç¤ºä¸º
- en: '![](../Images/709f954b8e725411af8150a6d441f80d.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/709f954b8e725411af8150a6d441f80d.png)'
- en: where *g* is an element of the group *G* and d*Âµ(u)* is the (Haar) measure of
    integration. The above expression is entirely analogous to convolution in the
    more common planar setting. We apply a transformation to the filter (a translation
    for planar CNNs), take the product with the signal of interest, and then sum,
    i.e. integrate.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ *g* æ˜¯ç¾¤ *G* çš„ä¸€ä¸ªå…ƒç´ ï¼Œè€Œ d*Âµ(u)* æ˜¯ç§¯åˆ†çš„ï¼ˆHaarï¼‰æµ‹åº¦ã€‚ä¸Šè¿°è¡¨è¾¾å¼ä¸æ›´å¸¸è§çš„å¹³é¢è®¾ç½®ä¸­çš„å·ç§¯å®Œå…¨ç±»ä¼¼ã€‚æˆ‘ä»¬å¯¹æ»¤æ³¢å™¨è¿›è¡Œå˜æ¢ï¼ˆå¯¹äºå¹³é¢
    CNN æ¥è¯´æ˜¯å¹³ç§»ï¼‰ï¼Œä¸æ„Ÿå…´è¶£çš„ä¿¡å·ç›¸ä¹˜ï¼Œç„¶åæ±‚å’Œï¼Œå³ç§¯åˆ†ã€‚
- en: On the sphere we consider transformations given by 3D rotations and so the convolution
    of a signal on the sphere reads
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨çƒé¢ä¸Šï¼Œæˆ‘ä»¬è€ƒè™‘ç”± 3D æ—‹è½¬ç»™å‡ºçš„å˜æ¢ï¼Œå› æ­¤çƒé¢ä¸Šçš„ä¿¡å·å·ç§¯è¡¨ç¤ºä¸º
- en: '![](../Images/34b7b3b493003ea983d69ea818088ff6.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/34b7b3b493003ea983d69ea818088ff6.png)'
- en: where *R* denotes a rotation and *Ï‰* spherical coordinates.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ *R* è¡¨ç¤ºæ—‹è½¬ï¼Œ*Ï‰* ä¸ºçƒé¢åæ ‡ã€‚
- en: Once a convolution on the group is defined, we can then construct a CNN on the
    group in a manner analogous to standard planar CNNs. That is, by composing convolutions
    and pointwise non-linear activations (also with pooling and normalisation layers,
    appropriately constructed on the group).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦å®šä¹‰äº†ç¾¤ä¸Šçš„å·ç§¯ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä»¥ç±»ä¼¼äºæ ‡å‡†å¹³é¢ CNN çš„æ–¹å¼åœ¨ç¾¤ä¸Šæ„å»º CNNã€‚å³ï¼Œé€šè¿‡ç»„åˆå·ç§¯å’Œé€ç‚¹éçº¿æ€§æ¿€æ´»ï¼ˆè¿˜åŒ…æ‹¬é€‚å½“åœ°æ„å»ºåœ¨ç¾¤ä¸Šçš„æ± åŒ–å’Œå½’ä¸€åŒ–å±‚ï¼‰ã€‚
- en: 'The question then remains: how do we compute the group convolution in practice?'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: é—®é¢˜ä»ç„¶æ˜¯ï¼šæˆ‘ä»¬å¦‚ä½•åœ¨å®è·µä¸­è®¡ç®—ç¾¤å·ç§¯ï¼Ÿ
- en: On one hand, weâ€™d like the implementation to accurately capture the equivariance
    properties on the convolution. While on the other hand, weâ€™d like the implementation
    to be highly computationally efficient. As we will see, existing approaches typically
    capture one of these requirements but not both simultaneously.
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬å¸Œæœ›å®ç°èƒ½å¤Ÿå‡†ç¡®æ•æ‰å·ç§¯ä¸Šçš„ç­‰å˜æ€§ç‰¹æ€§ã€‚å¦ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬å¸Œæœ›å®ç°å…·æœ‰é«˜è®¡ç®—æ•ˆç‡ã€‚å¦‚æˆ‘ä»¬å°†çœ‹åˆ°çš„ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸åªèƒ½æ•æ‰è¿™äº›è¦æ±‚ä¸­çš„ä¸€ä¸ªï¼Œè€Œä¸èƒ½åŒæ—¶æ»¡è¶³ä¸¤ä¸ªè¦æ±‚ã€‚
- en: Discrete spherical CNN approaches
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¦»æ•£çƒé¢ CNN æ–¹æ³•
- en: Existing approaches can be broadly categorised in discrete and continuous approaches.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ç°æœ‰çš„æ–¹æ³•å¯ä»¥å¤§è‡´åˆ†ä¸ºç¦»æ•£å’Œè¿ç»­æ–¹æ³•ã€‚
- en: Discrete approaches work with a discrete version of the data, typically either
    pixels or a graph representation, which can often be highly computationally efficient.
    However, in general regular discretizations do not exist.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ç¦»æ•£æ–¹æ³•å¤„ç†æ•°æ®çš„ç¦»æ•£ç‰ˆæœ¬ï¼Œé€šå¸¸æ˜¯åƒç´ æˆ–å›¾å½¢è¡¨ç¤ºï¼Œè¿™é€šå¸¸å…·æœ‰å¾ˆé«˜çš„è®¡ç®—æ•ˆç‡ã€‚ç„¶è€Œï¼Œé€šå¸¸ä¸å­˜åœ¨è§„åˆ™çš„ç¦»æ•£åŒ–ã€‚
- en: Taking the sphere as an example, it is well known that a regular discretization
    of the sphere does not exist. Consequently, there is no way to discretise the
    sphere in a manner that is invariant to rotations, as illustrated in the diagram
    below.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥çƒé¢ä¸ºä¾‹ï¼Œä¼—æ‰€å‘¨çŸ¥ï¼Œçƒé¢çš„è§„åˆ™ç¦»æ•£åŒ–å¹¶ä¸å­˜åœ¨ã€‚å› æ­¤ï¼Œæ²¡æœ‰æ–¹æ³•å¯ä»¥ä»¥ä¸å˜äºæ—‹è½¬çš„æ–¹å¼å¯¹çƒé¢è¿›è¡Œç¦»æ•£åŒ–ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚
- en: '![](../Images/c0fcfa6c76dcce8dd5b460409d7b84a4.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c0fcfa6c76dcce8dd5b460409d7b84a4.png)'
- en: Rotating a set of pixels on the sphere results in a set on pixels that cannot
    be overlayed with the existing set. This is true for all samplings of the sphere.
    [Original figure created by authors.]
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨çƒé¢ä¸Šæ—‹è½¬ä¸€ç»„åƒç´ ä¼šå¾—åˆ°ä¸€ç»„ä¸èƒ½ä¸ç°æœ‰é›†åˆé‡å çš„åƒç´ ã€‚è¿™åœ¨çƒé¢çš„æ‰€æœ‰é‡‡æ ·ä¸­éƒ½æ˜¯æ­£ç¡®çš„ã€‚[åŸå§‹å›¾å½¢ç”±ä½œè€…åˆ›å»ºã€‚]
- en: Capturing strict equivariance with operations defined directly on the discretized
    space is simply not possible.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¦»æ•£ç©ºé—´ä¸Šç›´æ¥å®šä¹‰çš„æ“ä½œæ— æ³•ä¸¥æ ¼æ•æ‰ç­‰å˜æ€§ã€‚
- en: Discrete approaches therefore over favourable computational performance but
    at the cost of equivariance.
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œç¦»æ•£æ–¹æ³•åœ¨è®¡ç®—æ€§èƒ½ä¸Šå…·æœ‰ä¼˜åŠ¿ï¼Œä½†ä»£ä»·æ˜¯ç­‰å˜æ€§ã€‚
- en: Continuous spherical CNN approaches
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è¿ç»­çƒé¢ CNN æ–¹æ³•
- en: As an alternative to the discrete approaches discussed above, a continuous representation
    of the underlying signal can also be considered.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºä¸Šè¿°ç¦»æ•£æ–¹æ³•çš„æ›¿ä»£æ–¹æ¡ˆï¼Œä¹Ÿå¯ä»¥è€ƒè™‘ä¿¡å·çš„è¿ç»­è¡¨ç¤ºã€‚
- en: Functions on the sphere can be represented by an expansion in terms of spherical
    harmonics (illustrated below). For a bandlimited signal, it is posible to capture
    all of the signalâ€™s information content in a finite set of samples, from which
    spherical harmonic coefficients can be computed exactly [1]. This is the analog
    of the well-known [Nyquist-Shannon sampling theorem](https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem)
    extended to the sphere.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: çƒé¢ä¸Šçš„å‡½æ•°å¯ä»¥é€šè¿‡çƒé¢è°æ³¢çš„å±•å¼€è¡¨ç¤ºï¼ˆå¦‚ä¸‹å›¾æ‰€ç¤ºï¼‰ã€‚å¯¹äºå¸¦é™ä¿¡å·ï¼Œå¯ä»¥åœ¨æœ‰é™çš„æ ·æœ¬é›†åˆä¸­æ•æ‰åˆ°ä¿¡å·çš„æ‰€æœ‰ä¿¡æ¯å†…å®¹ï¼Œä»ä¸­å¯ä»¥å‡†ç¡®åœ°è®¡ç®—çƒé¢è°æ³¢ç³»æ•°[1]ã€‚è¿™ç±»ä¼¼äºè‘—åçš„[å¥ˆå¥æ–¯ç‰¹-é¦™å†œé‡‡æ ·å®šç†](https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem)æ‰©å±•åˆ°çƒé¢ã€‚
- en: '![](../Images/d363eb6335ceb277a928b5ee435d5ad8.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d363eb6335ceb277a928b5ee435d5ad8.png)'
- en: Spherical harmoinc functions. [Image sourced from [Wikimedia Commons](https://en.wikipedia.org/wiki/Spherical_harmonics#/media/File:Spherical_Harmonics.png).]
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: çƒé¢è°æ³¢å‡½æ•°ã€‚[å›¾åƒæ¥æºäº [Wikimedia Commons](https://en.wikipedia.org/wiki/Spherical_harmonics#/media/File:Spherical_Harmonics.png)ã€‚]
- en: Since the sphere is a compact manifold, its harmonic space is discrete. By working
    with a finite spherical harmonic space representation it is therefore possible
    to access the underlying continuous signal.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºçƒé¢æ˜¯ä¸€ä¸ªç´§è‡´æµå½¢ï¼Œå…¶è°æ³¢ç©ºé—´æ˜¯ç¦»æ•£çš„ã€‚å› æ­¤ï¼Œé€šè¿‡ä½¿ç”¨æœ‰é™çš„çƒé¢è°æ³¢ç©ºé—´è¡¨ç¤ºï¼Œå¯ä»¥è®¿é—®åº•å±‚çš„è¿ç»­ä¿¡å·ã€‚
- en: Various spherical CNN architecutres have been constructed where convolutions
    are computed through their harmonic representation [2â€“6]. By accessing the underlying
    continuous signal, these approaches achieve execellent equivariance properties.
    However, they involve repeatedly performing spherical harmonic transforms, which
    is computationally costly.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: å„ç§çƒé¢ CNN æ¶æ„å·²ç»è¢«æ„å»ºï¼Œå…¶ä¸­å·ç§¯é€šè¿‡å…¶è°æ³¢è¡¨ç¤ºæ¥è®¡ç®—[2â€“6]ã€‚é€šè¿‡è®¿é—®åº•å±‚çš„è¿ç»­ä¿¡å·ï¼Œè¿™äº›æ–¹æ³•å®ç°äº†å“è¶Šçš„ç­‰å˜æ€§ã€‚ç„¶è€Œï¼Œå®ƒä»¬æ¶‰åŠåå¤æ‰§è¡Œçƒé¢è°æ³¢å˜æ¢ï¼Œè¿™åœ¨è®¡ç®—ä¸Šæ˜¯æ˜‚è´µçš„ã€‚
- en: Continuous appraoches capture rotational equivariance acurately but are computationally
    demanding.
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¿ç»­æ–¹æ³•å‡†ç¡®æ•æ‰æ—‹è½¬ç­‰å˜æ€§ï¼Œä½†è®¡ç®—è¦æ±‚é«˜ã€‚
- en: 'Dichotomy: discrete vs continuous approaches'
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: äºŒåˆ†æ³•ï¼šç¦»æ•£ vs è¿ç»­æ–¹æ³•
- en: As we have seen above, a dichotomy exists between discrete and continous approaches,
    as illustrated in the diagram below. Ideally weâ€™d like techniques that are both
    equivariant and computationally scalable.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä¸Šæ‰€ç¤ºï¼Œç¦»æ•£å’Œè¿ç»­æ–¹æ³•ä¹‹é—´å­˜åœ¨ä¸€ç§äºŒåˆ†æ³•ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚ç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›æŠ€æœ¯æ—¢å…·æœ‰ç­‰å˜æ€§åˆå…·æœ‰è®¡ç®—å¯æ‰©å±•æ€§ã€‚
- en: However, continuous approaches offer equivariance but with a large computational
    cost. Discrete approaches, on the other hand, are typically relatively computationally
    efficient but sacrifice equivariance.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¿ç»­æ–¹æ³•æä¾›ç­‰å˜æ€§ï¼Œä½†è®¡ç®—æˆæœ¬å¾ˆé«˜ã€‚å¦ä¸€æ–¹é¢ï¼Œç¦»æ•£æ–¹æ³•é€šå¸¸è®¡ç®—æ•ˆç‡è¾ƒé«˜ï¼Œä½†ç‰ºç‰²äº†ç­‰å˜æ€§ã€‚
- en: '![](../Images/191b1b697f3daf4718c598e3bb5585cc.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/191b1b697f3daf4718c598e3bb5585cc.png)'
- en: Dichotomy between continuous and discrete geometric deep learning techniques
    on groups. [Original figure created by authors.]
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ç»­å’Œç¦»æ•£å‡ ä½•æ·±åº¦å­¦ä¹ æŠ€æœ¯åœ¨ç¾¤ä½“ä¸Šçš„äºŒåˆ†æ³•ã€‚[åŸå§‹å›¾ç”±ä½œè€…åˆ›å»ºã€‚]
- en: Breaking the dichotomy
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç ´é™¤äºŒåˆ†æ³•
- en: We desire geometric deep learning techniques on groups that provide equivariance
    (which typically translates to well-behaved representation spaces and excellent
    performance) and are also computationally scalable.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœŸæœ›åœ¨ç¾¤ä½“ä¸Šè¿›è¡Œå‡ ä½•æ·±åº¦å­¦ä¹ çš„æŠ€æœ¯èƒ½å¤Ÿæä¾›ç­‰å˜æ€§ï¼ˆè¿™é€šå¸¸è½¬åŒ–ä¸ºè‰¯å¥½çš„è¡¨ç¤ºç©ºé—´å’Œå“è¶Šçš„æ€§èƒ½ï¼‰ï¼ŒåŒæ—¶ä¹Ÿå…·æœ‰è®¡ç®—å¯æ‰©å±•æ€§ã€‚
- en: In our next post we will describe a new hyrbid discrete-continuous (DISCO) approach,
    recently accepted for ICLR, that achieves precisely these goals [7]. By keeping
    some components of the representation continuous we achieve excellent equivariance
    properties, while other components are discretized to provide highly efficient
    scalable computation.
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æè¿°ä¸€ç§æ–°çš„æ··åˆç¦»æ•£-è¿ç»­ï¼ˆDISCOï¼‰æ–¹æ³•ï¼Œæœ€è¿‘è¢« ICLR æ¥å—ï¼Œè¿™ç§æ–¹æ³•æ­£å¥½å®ç°äº†è¿™äº›ç›®æ ‡[7]ã€‚é€šè¿‡ä¿æŒè¡¨ç¤ºçš„ä¸€äº›ç»„ä»¶ä¸ºè¿ç»­çš„ï¼Œæˆ‘ä»¬å®ç°äº†å“è¶Šçš„ç­‰å˜æ€§ï¼Œè€Œå…¶ä»–ç»„ä»¶åˆ™è¢«ç¦»æ•£åŒ–ä»¥æä¾›é«˜æ•ˆçš„å¯æ‰©å±•è®¡ç®—ã€‚
- en: References
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[1] McEwen & Wiaux, *A novel sampling theorem on the sphere*, IEEE TSP (2012),
    [arXiv:1110.6298](https://arxiv.org/abs/1110.6298)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] McEwen & Wiaux, *A novel sampling theorem on the sphere*, IEEE TSP (2012),
    [arXiv:1110.6298](https://arxiv.org/abs/1110.6298)'
- en: '[2] Cohen, Geiger, Koehler, Welling, *Spherical CNNs*, ICLR (2018), [arxiv:1801.10130](https://arxiv.org/abs/1801.10130).'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Cohen, Geiger, Koehler, Welling, *Spherical CNNs*, ICLR (2018), [arxiv:1801.10130](https://arxiv.org/abs/1801.10130)ã€‚'
- en: '[3] Esteves, Allen-Blanchette, Makadia, Daniilidis, *Learning SO(3) Equivariant
    Representations with Spherical CNNs*, ECCV (2018), [arXiv:1711.06721](https://arxiv.org/abs/1711.06721).'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Esteves, Allen-Blanchette, Makadia, Daniilidis, *å­¦ä¹ SO(3)ç­‰å˜è¡¨ç¤ºçš„çƒé¢å·ç§¯ç¥ç»ç½‘ç»œ*ï¼ŒECCVï¼ˆ2018ï¼‰ï¼Œ[arXiv:1711.06721](https://arxiv.org/abs/1711.06721)ã€‚'
- en: '[4] Kondor, Lin, Trivedi, *Clebsch-Gordan Nets: a Fully Fourier Space Spherical
    Convolutional Neural Network*, NeurIPS (2018), [arXiv:1806.09231](https://arxiv.org/abs/1806.09231)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Kondor, Lin, Trivedi, *Clebsch-Gordan ç½‘ç»œï¼šä¸€ç§å®Œå…¨å‚…é‡Œå¶ç©ºé—´çš„çƒé¢å·ç§¯ç¥ç»ç½‘ç»œ*ï¼ŒNeurIPSï¼ˆ2018ï¼‰ï¼Œ[arXiv:1806.09231](https://arxiv.org/abs/1806.09231)'
- en: '[5] Cobb, Wallis, Mavor-Parker, Marignier, Price, dâ€™Avezac, McEwen, *Efficient
    Generalised Spherical CNNs*, ICLR (2021), [arXiv:2010.11661](https://arxiv.org/abs/2010.11661#)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Cobb, Wallis, Mavor-Parker, Marignier, Price, dâ€™Avezac, McEwen, *é«˜æ•ˆçš„å¹¿ä¹‰çƒé¢å·ç§¯ç¥ç»ç½‘ç»œ*ï¼ŒICLRï¼ˆ2021ï¼‰ï¼Œ[arXiv:2010.11661](https://arxiv.org/abs/2010.11661#)'
- en: '[6] McEwen, Wallis, Mavor-Parker*, Scattering Networks on the Sphere for Scalable
    and Rotationally Equivariant Spherical CNNs*, ICLR (2022), [arXiv:2102.02828](https://arxiv.org/abs/2102.02828)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] McEwen, Wallis, Mavor-Parker*ï¼Œ*çƒé¢ä¸Šçš„æ•£å°„ç½‘ç»œï¼šç”¨äºå¯æ‰©å±•å’Œæ—‹è½¬ç­‰å˜çš„çƒé¢å·ç§¯ç¥ç»ç½‘ç»œ*ï¼ŒICLRï¼ˆ2022ï¼‰ï¼Œ[arXiv:2102.02828](https://arxiv.org/abs/2102.02828)'
- en: '[7] Ocampo, Price, McEwen, *Scalable and equivariant spherical CNNs by discrete-continuous
    (DISCO) convolutions*, ICLR (2023), [arXiv:2209.13603](https://arxiv.org/abs/2209.13603)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] Ocampo, Price, McEwen, *é€šè¿‡ç¦»æ•£-è¿ç»­ï¼ˆDISCOï¼‰å·ç§¯å®ç°å¯æ‰©å±•å’Œç­‰å˜çš„çƒé¢å·ç§¯ç¥ç»ç½‘ç»œ*ï¼ŒICLRï¼ˆ2023ï¼‰ï¼Œ[arXiv:2209.13603](https://arxiv.org/abs/2209.13603)'
