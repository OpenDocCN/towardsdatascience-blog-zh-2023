- en: How to Speed Up Data Science Deliveries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-speed-up-data-science-deliveries-cbacc5a710af?source=collection_archive---------13-----------------------#2023-01-09](https://towardsdatascience.com/how-to-speed-up-data-science-deliveries-cbacc5a710af?source=collection_archive---------13-----------------------#2023-01-09)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Bringing agile to data science and reestablishing the stakeholders’ trust in
    the team
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://bahbbc.medium.com/?source=post_page-----cbacc5a710af--------------------------------)[![Bárbara
    Barbosa](../Images/7faf5e8d7a24d9b7973c0773f58bdadf.png)](https://bahbbc.medium.com/?source=post_page-----cbacc5a710af--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cbacc5a710af--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cbacc5a710af--------------------------------)
    [Bárbara Barbosa](https://bahbbc.medium.com/?source=post_page-----cbacc5a710af--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1d7b885b5695&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-speed-up-data-science-deliveries-cbacc5a710af&user=B%C3%A1rbara+Barbosa&userId=1d7b885b5695&source=post_page-1d7b885b5695----cbacc5a710af---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cbacc5a710af--------------------------------)
    ·10 min read·Jan 9, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcbacc5a710af&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-speed-up-data-science-deliveries-cbacc5a710af&user=B%C3%A1rbara+Barbosa&userId=1d7b885b5695&source=-----cbacc5a710af---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcbacc5a710af&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-speed-up-data-science-deliveries-cbacc5a710af&source=-----cbacc5a710af---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: When we start to work with data science, other people expect us to be as agile
    as the developers, but can we use the same techniques and rituals that they use
    to be agile?
  prefs: []
  type: TYPE_NORMAL
- en: I scaled a Data Science team from 1 to around 10 people over some years, and
    I want to share my experience with the multiple strategies that I used as a manager
    to be agile in a very uncertain area as is Data Science. If you are a tenured
    data scientist, it [could happen that many of your projects sometimes don't go
    to production](https://venturebeat.com/ai/why-do-87-of-data-science-projects-never-make-it-into-production/).
    At the beginning of the project, the uncertainty is high and you don't know if
    it will make it to production. If this is your case, I want to share some of my
    strategies to mitigate the uncertainty at the beginning of a project.
  prefs: []
  type: TYPE_NORMAL
- en: At the beginning of the team, everything was nice. We used a single [Kanban](https://www.atlassian.com/agile/kanban)
    because the team was pretty small and we were capable to manage everything with
    it. The problem started when the team grew and we were acting in multiple domains
    across the company. The stakeholders wanted to know the deadlines and what we
    were going to do to finish the projects. I talked to many companies back then
    and decided that we should try to move to [Scrum](https://www.scrum.org/resources/what-is-scrum).
  prefs: []
  type: TYPE_NORMAL
- en: 'We used Scrum for some years, but with time I realized that the team was unhappy.
    We had multiple problems:'
  prefs: []
  type: TYPE_NORMAL
- en: the open Pull Requests took forever to be revised, even in a very small story;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: never (or almost never) the scientists were capable of finishing the sprint;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the refining meetings took too long, and after some alignment, with the stakeholders,
    everything always change and the whole refining meeting was pointless;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the team was always superestimating the time and size of stories and, with that,
    stakeholders stopped trusting our deadlines and we had a reputation of being a
    slow team;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: it was super hard to bet on the size of an exploratory story (being an EDA —
    Exploratory Data Analysis, or even the discovery of the data itself), and after
    that step, if the data was not good, it could end in a bad model or an analysis
    that wasn't what we actually need to improve the model performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let me explain in more detail how the team worked at that time. The team
    was a [Chapter](https://productschool.com/blog/product-management-2/spotify-model-scaling-agile/),
    so we were inside some Tribes and we worked together with other teams to reach
    the goals of that Tribes. A data scientist normally would lead a project inside
    the Tribe and the other people on the Data Science team would help her, giving
    ideas during daily meetings or other ceremonies. Some projects would have two
    data scientists, but most of the time, we had one person per project and this
    person could count with the support from the Data Science chapter.
  prefs: []
  type: TYPE_NORMAL
- en: At that time, I thought that we were agile because we used an agile framework.
    In fact, being agile is actually [responding to change over following a plan](https://agilemanifesto.org/),
    and the problems that I listed made us look for a new way to manage the projects
    of the Data Science team.
  prefs: []
  type: TYPE_NORMAL
- en: We identified that one of our biggest problems was trying to solve everything
    with the first launch of a product. This created a long feedback loop that generated
    a massive amount of code (between Jupyter notebooks and Python code), which jeopardizes
    reviews. That was especially harmful when there was a problem with the logic at
    the beginning of the project that would create a cascade event of change (and
    a project being completely invalidated sometimes).
  prefs: []
  type: TYPE_NORMAL
- en: 'So we stopped. We started working to validate **a single hypothesis** and with
    that in mind, we started creating **production-ready** **versions** for every
    hypothesis that we validated. The main changes were:'
  prefs: []
  type: TYPE_NORMAL
- en: Work with **small versions** that could go to production at the end of the iteration.
    The versions are prioritized based on the biggest problem the stakeholders are
    facing at the moment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start using **soft deadlines** to increase the creativity of the team and bring
    more visibility to the stakeholders.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The **research review** is super important, but it was one of the biggest time
    drainers of the project. We moved this step to the end.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'I will detail those steps below:'
  prefs: []
  type: TYPE_NORMAL
- en: Small versions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first version of the project is the MVP and after that new versions are
    developed. The MVP is the baseline version, and this nomenclature helps the data
    scientists to think about how to work on the smallest iteration possible of a
    project and also with the stakeholders' expectations since they will also help
    with the stakeholder's expectations and the data scientists to do the smallest
    iteration possible of a project that helps to solve the problem.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ec6d56fca3ee487953330f2d085fdfef.png)'
  prefs: []
  type: TYPE_IMG
- en: We start to face a Data Science project as something that has multiple iterations,
    bearing in mind that the first iteration is not final. All iterations follow the
    full data science process (explained further), generating small deliverables.
    In the image, we have the iterations partitioned by the data available at the
    moment. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: One of the first things that we do is *Understand the Problem*, or to match
    the above image, the *Business Understanding,* and to make this step easier, we
    use the [Machine Learning Canvas](https://www.ownml.co/machine-learning-canvas)
    (ML Canvas). I also usually call this step Discovery, because here we actually
    understand if this is actually a Data Science problem and if we need data scientists
    to solve this issue. The canvas helps to assess that because we can align the
    main goals of the project with everyone impacted by it.
  prefs: []
  type: TYPE_NORMAL
- en: During the canvas section, we understand the stakeholder's problems, and the
    main data we need and we can already define an MVP and reach an agreement on what
    we will deliver on the next versions. Although this seems pretty straightforward,
    during the MVP everything can change, and this is okay, because uncertainty is
    part of a data science project, and without having your hands dirty with data
    it is hard to know what to expect next and what the next steps will be.
  prefs: []
  type: TYPE_NORMAL
- en: In a full remote or hybrid environment you can use Miro or another similar tool
    to make brainstorm with everyone and this initial alignment allows us to understand
    different aspects of the project before the data team actually starts working
    on it.
  prefs: []
  type: TYPE_NORMAL
- en: For the next steps and versions, it is imperative to have someone that is an
    expert in the area the data scientist will be working on as a partner. This person
    should be available to have brainstorming sessions and help the data scientist
    acquire the business knowledge they need for the problem, help with a hypothesis,
    and version prioritization. This person, whom we named Business Partner, will
    help the data scientist to be more in touch with the daily problems the area is
    facing and will make sure that the deliveries of the data scientist are solving
    their problems. A weekly meeting with a Business Partner can do wonders for a
    project, making sure the data scientist is down to earth with the business and
    the business understand what is being done by the data scientist.
  prefs: []
  type: TYPE_NORMAL
- en: Soft deadlines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We used a Kanban with the phases from [CRISP-DM](https://www.datascience-pm.com/crisp-dm-2/),
    which has 6 steps. Some steps are grouped and they have a soft deadline and an
    alignment meeting with the project stakeholders to wrap it up. This enhanced the
    credibility that we had with the stakeholders as without it, we didn't have a
    specific agenda, and sometimes the results were not enough consolidated or validated.
    Having some time to wrap the results up creates a more productive meeting and
    we can focus on the points that we want to discuss, not on finding possible errors
    for the analysis, enhancing the business value of that specific deliverable.
  prefs: []
  type: TYPE_NORMAL
- en: Often when I talk about this step the question of why it is "soft" commonly
    comes to people's minds. I believe this is because everyone is used to the way
    that Software Development is made and Data Science is not Software Engineer and
    has much uncertainty at some steps of the project. So the word *soft* brings this
    idea of something that has a high degree of uncertainty, as an EDA (*Exploratory
    Data Analysis*) can be hard to actually measure without the business logic. After
    the Discovery and initial data preparation and exploration, it is already possible
    for the data scientist to schedule an alignment meeting and also define the next
    soft deadlines for the project.
  prefs: []
  type: TYPE_NORMAL
- en: 'The soft deadline also brings flexibility for the data scientist: she can do
    all that she thinks/wants it is necessary to solve the problem until that date
    and, in case of a planning error, she still has material to present at the checkpoint
    and collect feedback (assuming that she focused first on the simpler version and
    scaled from there with the rest of her time). This will allow her to realize different
    experiments, having in mind the deadline.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2d0b4fe4ede2e641e37e14cc18a7c037.png)'
  prefs: []
  type: TYPE_IMG
- en: Each step of the process group with its soft deadlines. Literature revision
    + Data analysis sum up to 2 to 3 weeks; algorithm development + Result analysis
    + Review sum up 2 to 3 weeks; Deploy could take around 1 to 2 weeks but that is
    more dependent on your DataOps infrastructure and strategy. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: The image has an example of what was doable in a second/third version of a project
    (so a lot of the uncertainty about data, deploy, usage, etc. was already removed)
    and in a team that was already very familiar with the speed of their members.
    For MVP projects this might be totally different as the data preparation can be
    very complex. Projects that are beyond the first phase normally are much faster
    using this approach as most of the risk is already known and the stakeholders
    are already familiar with the way of working.
  prefs: []
  type: TYPE_NORMAL
- en: Having the alignment meeting with the stakeholders after the EDA is finished
    can guarantee that we are well aligned on the next steps and also increase the
    visibility of the Data Science team for them.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/58330edb3ffcfa4aa13feb38a903bcf6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Before the new process: Data Scientist shows up to talk with the stakeholders
    after 1 or 2 months of working on a project that everyone already forgot about.
    Photo by [Daniel Jensen](https://unsplash.com/@dallehj?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/waving-hello?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)'
  prefs: []
  type: TYPE_NORMAL
- en: Review at the end
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As stated at the beginning, one of our major problems was the research review
    time, and this was then moved to the end of the project. In a code sense, this
    is quite bad as it is not some atomic part that will create a quick code review,
    and in the code sense, this is perfectly correct, but for research, you don't
    want just to see a single piece of code that trains a model, you want to also
    see the evaluation to understand what kind of things you can do to improve this
    model (is it data? hyperparameters? just looking at the train code is impossible
    to know). This allows the reviewer to understand the business problem and suggest
    modifications that were more relevant to the problem. Before that, one person
    could be reviewing the EDA and after 2 weeks start to review the model evaluation,
    or worse than that, different people would review each part, losing the context.
    In Data Science the code is just part of the whole picture, there are Jupyter
    notebooks with insights, graphics, and data. Seeing the model evaluation and missing
    the EDA did not allow the review to be complete, and reviewing the whole iteration
    also helps the data scientist be mindful that the iteration should be small.
  prefs: []
  type: TYPE_NORMAL
- en: Because this step takes quite some time, just one data scientist reviews each
    other's research and it is optional for other people on the team to revise it.
    It is very important that after the Evaluation someone is responsible for the
    review task and there is also a deadline for it, otherwise, the revision will
    be a problem again and this step can block the entire project.
  prefs: []
  type: TYPE_NORMAL
- en: This step increases the team's knowledge and also eases the transition of people
    to another area. If you want to know more about how to do Pull requests using
    Github, take a look at [this article](https://medium.com/analytics-vidhya/creating-pull-requests-with-jupyter-notebooks-912520ee328f)
    I wrote a while ago.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges and other learnings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Because the review step is only the last one, the data scientists can have a
    hard time collaborating and asking questions. This can be solved by working with
    a [feature branch](https://www.optimizely.com/optimization-glossary/feature-branch/#:~:text=What%20is%20a%20feature%20branch,for%20how%20individuals%20work%20together.),
    where the data scientist can still deliver small pieces of code and get help on
    small chunks, but the team still keeps the context analysis when the feature branch
    goes to production. This also reduces the review time for the project in the end,
    because minor issues were already addressed. This can help to create asynchronous
    conversations with the team about a specific question to be asked.
  prefs: []
  type: TYPE_NORMAL
- en: Keeping the retrospectives was very important at that time and it is a good
    opportunity for the team discusses what is working or not in a project and exchange
    the experience with the rest of the team. This allows the Chapter to be in continuous
    improvement, even if there are no deliveries in the period, I recommend scheduling
    the meeting with a good frequency, like every 15 days.
  prefs: []
  type: TYPE_NORMAL
- en: This methodology is my adaptation of what is presented in [this article](/data-science-agile-cycles-my-method-for-managing-data-science-projects-in-the-hi-tech-industry-b289e8a72818).
    In it, the author presents an approach that uses Kanban and a checklist with the
    next steps. The soft deadline forces the data scientist to think about the steps
    that she needs to follow and this creates a more structured work, but I never
    used a predefined checklist, the data scientist thought about what was important
    and discussed the tasks with the team (almost as a refining ceremony, if you like
    to think like that). The implementation of the approach that I explain here was
    a success. It brought flexibility and ownership for the data scientist and more
    visibility and transparency with the stakeholders. This approach works better
    in a team that can be more focused on a single project at a time, but of course,
    all teams will have their own particularities and will adapt better to different
    frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: I hope this article brings some light to questions you might be having and if
    you tested it, please share your experience with me, I will be glad to hear about
    it.
  prefs: []
  type: TYPE_NORMAL
- en: This is a translated and revised version of [my original article in Portuguese](https://medium.com/creditas-tech/como-dar-mais-agilidade-nas-entregas-do-time-de-data-science-9003a1e6c898).
  prefs: []
  type: TYPE_NORMAL
