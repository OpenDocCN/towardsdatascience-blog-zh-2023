["```py\nglobal variables: numRows, lineSize, numClusters\ndef hostKMeans:\n    inputData = initializeInputData(numRows, lineSize)\n    outputCentroids = createEmptyArray(numRows, numClusters)\n    outputLabels = createEmptyArray(numRows, lineSize)\n\n    sendToDevice(inputData, outputCentroids, outputLabels)\n    cuda_kmeans[blockDimensions, threadDimensions](inputData, outputCentroids, outputLabels)\n    waitForKernelCompletion()\n    copyFromDevice(outputCentroids, outputLabels)\n```", "```py\ndef KMeansKernel(data, outputCentroids, outputLabels)\n    row = currentBlock()\n    seed = currentThread()\n\n    sharedInputRow = sharedArray(shape=(lineSize))\n    sharedInertia = sharedArray(shape=(numSeeds))\n    sharedCentroids = sharedArray(shape=(numSeeds, numClusters))\n    sharedLabels = sharedArray(shape=(numSeeds, lineSize))\n\n    sharedInputRow = data[row]\n\n    synchronizeThreads()\n    if seed == 0\n        centroids = initializeCentroids(data)\n    synchronizeThreads()\n\n    KMeansAlgorithm(sharedInputRow, sharedCentroids, sharedLabels)\n\n    sharedInertia[Seed] = calculateInertia(sharedInputRow, sharedCentroids, sharedLabels)\n\n    synchronizeThreads()\n    if seed == 0\n        minInertiaIndex = findMin(Inertia)\n    sharedOutputCentroids = centroids[minInertiaIndex]\n    sharedOutputLabels = labels[minInertiaIndex]\n```", "```py\ndef KMeansDevice(dataRow, centroids, labels)\n    seed = currentThread()\n    centroidsRow = centroids[seed]\n    labelsRow = labels[seed]\n\n    centroidsRow = sort(centroidsRow)\n    yardStick = computeYardstick(sortedCentroids)\n\n    oldCentroids = localArray(shape=(numSeeds, numClusters))\n\n    for iteration in range(100):\n        if converged(oldCentroids, centroidsRow)\n            break\n        oldCentroids = copy(centroidsRow)\n        assignLabels(dataRow, centroidsRow, labelsRow)\n        updateCentroids(dataRow, centroidsRow, labelsRow)\n```", "```py\ncuda_kmeans[(NUM_ROWS,), (NUM_SEEDS,)](input_rows, output_labels, output_centroids, random_states)\n```", "```py\n@cuda.jit()\ndef cuda_kmeans(input, output_labels, output_centroids, random_states):\n    row = cuda.blockIdx.x\n    seed = cuda.threadIdx.x\n    shared_input_row = cuda.shared.array(shape=(LINE_SIZE), dtype=np.float32)\n    shared_inertia = cuda.shared.array(shape=(NUM_SEEDS), dtype=np.float32)\n    shared_centroids = cuda.shared.array(shape=(NUM_SEEDS, NUM_CLUSTERS), dtype=np.float32)\n    shared_labels = cuda.shared.array(shape=(NUM_SEEDS, LINE_SIZE), dtype=np.int32)\n    if seed == 0:\n        get_initial_centroids(shared_input_row, shared_centroids, random_states)\n    cuda.syncthreads()\n\n    ...\n\n    kmeans(shared_input_row, shared_labels, shared_centroids)\n```", "```py\n@cuda.jit(device=True)\ndef kmeans(data_row, output_labels, output_centroids): \n    seed = cuda.threadIdx.x\n    labels_row = output_labels[seed]\n    centroids_row = output_centroids[seed]\n\n    ...\n\n    old_centroids = cuda.local.array(shape=(NUM_CLUSTERS), dtype=np.float32)\n\n    for iteration in range(NUM_ITERATIONS):\n            if iteration > 0:\n                if converged(centroids_row, old_centroids, yard_stick * EPSILON_PERCENT, iteration):\n                    break\n      # Assign labels and update centroids\n```", "```py\nint var = 100; // declare type\nint *ptr = &var; // use of a pointer and reference\nint **double_ptr = &ptr; // example of double pointer\nprintf(“Dereference double_ptr and ptr: %d %d \\n:”, **double_ptr, *ptr)\nint *ptr = 100; // initialize pointer to int type\n```", "```py\n#define NUM_ROWS 00000        // y dimension of our data set, number of blocks\n#define LINE_SIZE 100         // x dimension of our data set\n#define NUM_ITERATIONS 100    // max number of iterations\n#define NUM_CLUSTERS 3        // We are running k = 3\n#define MAX_INPUT_VALUE 100   // Upper bound on data\n#define NUM_SEEDS 32          // Number of seeds/threads is 1/3 of LINE_SIZE\n#define EPSILON_PERCENT 0.02  // Condition for convergence\n\nvoid initInputData(float** input) {\n    srand(1); \n    // allocate memory for the data\n\n    ... // initialize data using malloc and rand\n    // allocate memory on GPU\n    cudaMalloc(input, NUM_ROWS * LINE_SIZE * sizeof(float)); \n    // copy memory from CPU sample_data to GPU memory\n    cudaMemcpy(*input, sample_data, NUM_ROWS * LINE_SIZE * sizeof(float), cudaMemcpyHostToDevice);\n    free(sample_data);\n}\n\nint main() {\n    float* inputData; // initialize input data, dimensions will by NUM_ROWS x LINE SIZE\n    initInputData(&inputData); // dereference and pass to function\n    // initialize output labels and centroids\n    cudaExtent labelsExtent = make_cudaExtent(sizeof(int), LINE_SIZE, NUM_ROWS);\n    cudaPitchedPtr outputLabels; // create the pointer needed for the next call\n    cudaMalloc3D(&outputLabels, labelsExtent); // allocate memory on GPU\n\n    cudaExtent centroidsExtent = make_cudaExtent(sizeof(float), NUM_CLUSTERS, NUM_ROWS);\n    cudaPitchedPtr outputCentroids; // create the pointer needed for the next call\n    cudaMalloc3D(&outputCentroids, centroidsExtent); // allocate memory on GPU\n    cuda_kmeans <<<NUM_ROWS, NUM_SEEDS>>> (inputData, outputLabels, outputCentroids);\n    cudaDeviceSynchronize();\n\n    ... // copy output from device to back to host\n}\n```", "```py\ncuda_kmeans <<<NUM_ROWS, NUM_SEEDS>>> (inputData, outputLabels, outputCentroids);\n```", "```py\n__global__ void cuda_kmeans(float* input, cudaPitchedPtr outputLabels, cudaPitchedPtr outputCentroids) {\n    int row = blockIdx.x;\n    int seed = threadIdx.x;\n\n    // shared memory is shared between threads in blocks\n    __shared__ float input_shm[LINE_SIZE];\n    __shared__ float error_shm[NUM_SEEDS];\n    __shared__ float seed_centroids[NUM_SEEDS][NUM_CLUSTERS];\n    __shared__ int seed_labels[NUM_SEEDS][LINE_SIZE];\n\n    ... // get a single row of data\n    ... // populate input_shm\n    ... // populating the struct core_params\n    // the actual k-means function\n    kmeans(core_params);\n\n    // find seed with smallest error\n    calcError(core_params);\n    __syncthreads();\n    if (seed == 0) {\n        int* labels_line = LABELS_LINE(outputLabels, row);\n        float* centroids_line = CENTROIDS_LINE(outputCentroids, row);\n        labels_line[threadIdx.x] = seed_labels[seed][threadIdx.x];\n        centroids_line[threadIdx.x] = seed_centroids[seed][threadIdx.x];\n    }\n}\n```", "```py\n__device__ void kmeans(core_params_t& core_params) {\n    DECLARE_CORE_PARAMS(core_params);\n    getInitialCentroids(core_params);\n    sort_centroids(centroids, num_clusters);\n    float yard_stick = findYardStick(core_params);\n    float* oldCentroids = (float*)malloc(NUM_CLUSTERS * sizeof(float));\n    struct work_params_t work_params;\n    work_params.min = find_min(line, LINE_SIZE);\n    work_params.max = find_max(line, LINE_SIZE);\n    work_params.aux_buf1 = (int*)malloc(NUM_CLUSTERS * sizeof(int));\n    work_params.aux_buf2 = (int*)malloc(NUM_CLUSTERS * sizeof(int));\n    work_params.aux_buf3 = (float*)malloc(NUM_CLUSTERS * sizeof(float));\n    for (int iterations = 0; true; iterations++) {\n        bool stop = (iterations > 100) || (iterations > 0 && (converged(core_params, oldCentroids, yard_stick * EPSILON_PERCENT)));\n        if (stop)\n            break;\n        memcpy(oldCentroids, core_params.centroids, NUM_CLUSTERS * sizeof(float));\n        getLabels(core_params);\n        getCentroids(core_params, work_params);\n    }\n    free(work_params.aux_buf1);\n    free(work_params.aux_buf2);\n    free(work_params.aux_buf3);\n    free(oldCentroids);\n}\n```"]