- en: Scene Representation Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 场景表示网络
- en: 原文：[https://towardsdatascience.com/scene-representation-networks-bae6186d00d9?source=collection_archive---------14-----------------------#2023-02-22](https://towardsdatascience.com/scene-representation-networks-bae6186d00d9?source=collection_archive---------14-----------------------#2023-02-22)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/scene-representation-networks-bae6186d00d9?source=collection_archive---------14-----------------------#2023-02-22](https://towardsdatascience.com/scene-representation-networks-bae6186d00d9?source=collection_archive---------14-----------------------#2023-02-22)
- en: Modeling complex 3D scenes at infinite resolution
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在无限分辨率下建模复杂的3D场景
- en: '[](https://wolfecameron.medium.com/?source=post_page-----bae6186d00d9--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----bae6186d00d9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bae6186d00d9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bae6186d00d9--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----bae6186d00d9--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://wolfecameron.medium.com/?source=post_page-----bae6186d00d9--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----bae6186d00d9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bae6186d00d9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bae6186d00d9--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----bae6186d00d9--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F28aa6026c553&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscene-representation-networks-bae6186d00d9&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=post_page-28aa6026c553----bae6186d00d9---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bae6186d00d9--------------------------------)
    ·12 min read·Feb 22, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbae6186d00d9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscene-representation-networks-bae6186d00d9&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=-----bae6186d00d9---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F28aa6026c553&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscene-representation-networks-bae6186d00d9&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=post_page-28aa6026c553----bae6186d00d9---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bae6186d00d9--------------------------------)
    ·12分钟阅读·2023年2月22日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbae6186d00d9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscene-representation-networks-bae6186d00d9&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=-----bae6186d00d9---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbae6186d00d9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscene-representation-networks-bae6186d00d9&source=-----bae6186d00d9---------------------bookmark_footer-----------)![](../Images/b9e69450b3fa7f9dc92eb4c50cf7c7bc.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbae6186d00d9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscene-representation-networks-bae6186d00d9&source=-----bae6186d00d9---------------------bookmark_footer-----------)![](../Images/b9e69450b3fa7f9dc92eb4c50cf7c7bc.png)'
- en: (Photo by [Alexandra Gorn](https://unsplash.com/@alexagorn?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/living-room?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText))
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: （图片由 [Alexandra Gorn](https://unsplash.com/@alexagorn?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，来源于 [Unsplash](https://unsplash.com/s/photos/living-room?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)）
- en: We have seen recently (e.g., with [DeepSDF](https://cameronrwolfe.substack.com/p/3d-generative-modeling-with-deepsdf)
    and [ONets](https://cameronrwolfe.substack.com/p/shape-reconstruction-with-onets)
    [3, 5]) how 3D geometries can be represented with a neural net. But, these approaches
    have some limitations, such as requiring access to ground truth, 3D geometries
    for training and inference. Plus, *what if we want to represent an entire scene
    and not just an object or geometry*? This requires modeling both geometry and
    appearance; see below for an example. Luckily, neural nets are more than capable
    of modeling 3D scenes in this way given the correct approach.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最近已经看到（例如，[DeepSDF](https://cameronrwolfe.substack.com/p/3d-generative-modeling-with-deepsdf)和[ONets](https://cameronrwolfe.substack.com/p/shape-reconstruction-with-onets)
    [3, 5]）如何通过神经网络来表示3D几何体。但这些方法存在一些限制，例如需要真实的3D几何体进行训练和推断。此外，*如果我们想表示整个场景而不仅仅是一个物体或几何体*，该如何处理？这需要同时建模几何体和外观；下面有一个示例。幸运的是，只要方法正确，神经网络完全能够以这种方式建模3D场景。
- en: '![](../Images/0c7b3bc733de45910ed93862eab0bc9f.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0c7b3bc733de45910ed93862eab0bc9f.png)'
- en: (from [1] and [3])
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [1] 和 [3]）
- en: One approach for modeling 3D scenes is via Scene Representation Networks (SRNs)
    [1]. SRNs model scenes as a continuous function that maps each 3D coordinate to
    a representation that describes the object’s shape and appearance at that location.
    This function is learned with a feed-forward neural network. Then, SRNs use a
    learnable rendering algorithm to produce novel viewpoints (i.e., just 2D images)
    of the underlying 3D scene. Both the feed-forward network and the rendering algorithm
    can be trained end-to-end using only 2D images of scenes for supervision.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一种建模3D场景的方法是通过场景表示网络（SRNs）[1]。SRNs将场景建模为一个连续函数，该函数将每个3D坐标映射到一个描述该位置物体形状和外观的表示。这个函数是通过前馈神经网络学习的。然后，SRNs使用一个可学习的渲染算法生成底层3D场景的新视角（即，仅2D图像）。前馈网络和渲染算法都可以仅使用2D场景图像进行端到端训练。
