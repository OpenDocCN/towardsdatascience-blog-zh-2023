- en: 'Safeguarding Your RAG Pipelines: A Step-by-Step Guide to Implementing Llama
    Guard with LlamaIndex'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保护您的 RAG 管道：实施 Llama Guard 和 LlamaIndex 的逐步指南
- en: 原文：[https://towardsdatascience.com/safeguarding-your-rag-pipelines-a-step-by-step-guide-to-implementing-llama-guard-with-llamaindex-6f80a2e07756?source=collection_archive---------2-----------------------#2023-12-27](https://towardsdatascience.com/safeguarding-your-rag-pipelines-a-step-by-step-guide-to-implementing-llama-guard-with-llamaindex-6f80a2e07756?source=collection_archive---------2-----------------------#2023-12-27)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/safeguarding-your-rag-pipelines-a-step-by-step-guide-to-implementing-llama-guard-with-llamaindex-6f80a2e07756?source=collection_archive---------2-----------------------#2023-12-27](https://towardsdatascience.com/safeguarding-your-rag-pipelines-a-step-by-step-guide-to-implementing-llama-guard-with-llamaindex-6f80a2e07756?source=collection_archive---------2-----------------------#2023-12-27)
- en: How to add Llama Guard to your RAG pipelines to moderate LLM inputs and outputs
    and combat prompt injection
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何将 Llama Guard 添加到您的 RAG 管道中，以调节 LLM 输入和输出，并防止提示注入
- en: '[](https://medium.com/@wenqiglantz?source=post_page-----6f80a2e07756--------------------------------)[![Wenqi
    Glantz](../Images/65b518863e01aaa48ecc6b8ac6d1be60.png)](https://medium.com/@wenqiglantz?source=post_page-----6f80a2e07756--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6f80a2e07756--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6f80a2e07756--------------------------------)
    [Wenqi Glantz](https://medium.com/@wenqiglantz?source=post_page-----6f80a2e07756--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@wenqiglantz?source=post_page-----6f80a2e07756--------------------------------)[![Wenqi
    Glantz](../Images/65b518863e01aaa48ecc6b8ac6d1be60.png)](https://medium.com/@wenqiglantz?source=post_page-----6f80a2e07756--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6f80a2e07756--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6f80a2e07756--------------------------------)
    [Wenqi Glantz](https://medium.com/@wenqiglantz?source=post_page-----6f80a2e07756--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fce7cd5b8b74a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsafeguarding-your-rag-pipelines-a-step-by-step-guide-to-implementing-llama-guard-with-llamaindex-6f80a2e07756&user=Wenqi+Glantz&userId=ce7cd5b8b74a&source=post_page-ce7cd5b8b74a----6f80a2e07756---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6f80a2e07756--------------------------------)
    ·15 min read·Dec 27, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f80a2e07756&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsafeguarding-your-rag-pipelines-a-step-by-step-guide-to-implementing-llama-guard-with-llamaindex-6f80a2e07756&user=Wenqi+Glantz&userId=ce7cd5b8b74a&source=-----6f80a2e07756---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fce7cd5b8b74a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsafeguarding-your-rag-pipelines-a-step-by-step-guide-to-implementing-llama-guard-with-llamaindex-6f80a2e07756&user=Wenqi+Glantz&userId=ce7cd5b8b74a&source=post_page-ce7cd5b8b74a----6f80a2e07756---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6f80a2e07756--------------------------------)
    ·15 分钟阅读·2023年12月27日'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f80a2e07756&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsafeguarding-your-rag-pipelines-a-step-by-step-guide-to-implementing-llama-guard-with-llamaindex-6f80a2e07756&source=-----6f80a2e07756---------------------bookmark_footer-----------)![](../Images/50c09645ace0257d68c3faa039b9ec07.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f80a2e07756&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsafeguarding-your-rag-pipelines-a-step-by-step-guide-to-implementing-llama-guard-with-llamaindex-6f80a2e07756&source=-----6f80a2e07756---------------------bookmark_footer-----------)![](../Images/50c09645ace0257d68c3faa039b9ec07.png)'
- en: Image generated by DALL-E 3 by the author
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图像由作者使用 DALL-E 3 生成
- en: LLM security is an area that we all know deserves ample attention. Organizations
    eager to adopt Generative AI, from big to small, face a huge challenge in securing
    their LLM apps. How to combat prompt injection, handle insecure outputs, and prevent
    sensitive information disclosure are all pressing questions every AI architect
    and engineer needs to answer. Enterprise production grade LLM apps cannot survive
    in the wild without solid solutions to address LLM security.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: LLM安全是我们都知道值得充分关注的领域。渴望采用生成性AI的组织，无论大小，都面临着确保LLM应用安全的巨大挑战。如何对抗提示注入、处理不安全的输出以及防止敏感信息泄露，都是每个AI架构师和工程师需要解决的紧迫问题。企业级生产环境的LLM应用如果没有坚实的解决方案来解决LLM安全问题，将无法在实际环境中生存。
- en: Llama Guard, open-sourced by Meta on December 7th, 2023, offers a viable solution
    to address the LLM input-output vulnerabilities and combat prompt injection. Llama
    Guard falls under the umbrella project [Purple Llama](https://about.fb.com/news/2023/12/purple-llama-safe-responsible-ai-development/),
    “featuring open trust and safety tools and evaluations meant to level the playing
    field for developers to deploy generative AI models responsibly.”[1]
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Llama Guard，由Meta于2023年12月7日开源，提供了一种有效的解决方案来应对LLM输入输出漏洞和对抗提示注入。Llama Guard 属于[紫色Llama](https://about.fb.com/news/2023/12/purple-llama-safe-responsible-ai-development/)项目，“提供开放的信任和安全工具及评估，旨在为开发者负责任地部署生成性AI模型提供公平竞争环境。”[1]
- en: 'We explored [the OWASP top 10 for LLM applications](https://medium.com/gitconnected/security-driven-development-with-owasp-top-10-for-llm-applications-588406f40d4c?sk=dde699f26d74e8bcfb1ea2c4488b62e5)
    a month ago. With Llama Guard, we now have a pretty reasonable solution to start
    addressing some of those top 10 vulnerabilities, namely:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一个月前探讨了[OWASP LLM应用的十大漏洞](https://medium.com/gitconnected/security-driven-development-with-owasp-top-10-for-llm-applications-588406f40d4c?sk=dde699f26d74e8bcfb1ea2c4488b62e5)。有了Llama
    Guard，我们现在有了一个相当合理的解决方案来开始解决这些十大漏洞中的一些，具体包括：
