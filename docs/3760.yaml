- en: 'Safeguarding Your RAG Pipelines: A Step-by-Step Guide to Implementing Llama
    Guard with LlamaIndex'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/safeguarding-your-rag-pipelines-a-step-by-step-guide-to-implementing-llama-guard-with-llamaindex-6f80a2e07756?source=collection_archive---------2-----------------------#2023-12-27](https://towardsdatascience.com/safeguarding-your-rag-pipelines-a-step-by-step-guide-to-implementing-llama-guard-with-llamaindex-6f80a2e07756?source=collection_archive---------2-----------------------#2023-12-27)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How to add Llama Guard to your RAG pipelines to moderate LLM inputs and outputs
    and combat prompt injection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@wenqiglantz?source=post_page-----6f80a2e07756--------------------------------)[![Wenqi
    Glantz](../Images/65b518863e01aaa48ecc6b8ac6d1be60.png)](https://medium.com/@wenqiglantz?source=post_page-----6f80a2e07756--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6f80a2e07756--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6f80a2e07756--------------------------------)
    [Wenqi Glantz](https://medium.com/@wenqiglantz?source=post_page-----6f80a2e07756--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fce7cd5b8b74a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsafeguarding-your-rag-pipelines-a-step-by-step-guide-to-implementing-llama-guard-with-llamaindex-6f80a2e07756&user=Wenqi+Glantz&userId=ce7cd5b8b74a&source=post_page-ce7cd5b8b74a----6f80a2e07756---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6f80a2e07756--------------------------------)
    ·15 min read·Dec 27, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f80a2e07756&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsafeguarding-your-rag-pipelines-a-step-by-step-guide-to-implementing-llama-guard-with-llamaindex-6f80a2e07756&user=Wenqi+Glantz&userId=ce7cd5b8b74a&source=-----6f80a2e07756---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f80a2e07756&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsafeguarding-your-rag-pipelines-a-step-by-step-guide-to-implementing-llama-guard-with-llamaindex-6f80a2e07756&source=-----6f80a2e07756---------------------bookmark_footer-----------)![](../Images/50c09645ace0257d68c3faa039b9ec07.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image generated by DALL-E 3 by the author
  prefs: []
  type: TYPE_NORMAL
- en: LLM security is an area that we all know deserves ample attention. Organizations
    eager to adopt Generative AI, from big to small, face a huge challenge in securing
    their LLM apps. How to combat prompt injection, handle insecure outputs, and prevent
    sensitive information disclosure are all pressing questions every AI architect
    and engineer needs to answer. Enterprise production grade LLM apps cannot survive
    in the wild without solid solutions to address LLM security.
  prefs: []
  type: TYPE_NORMAL
- en: Llama Guard, open-sourced by Meta on December 7th, 2023, offers a viable solution
    to address the LLM input-output vulnerabilities and combat prompt injection. Llama
    Guard falls under the umbrella project [Purple Llama](https://about.fb.com/news/2023/12/purple-llama-safe-responsible-ai-development/),
    “featuring open trust and safety tools and evaluations meant to level the playing
    field for developers to deploy generative AI models responsibly.”[1]
  prefs: []
  type: TYPE_NORMAL
- en: 'We explored [the OWASP top 10 for LLM applications](https://medium.com/gitconnected/security-driven-development-with-owasp-top-10-for-llm-applications-588406f40d4c?sk=dde699f26d74e8bcfb1ea2c4488b62e5)
    a month ago. With Llama Guard, we now have a pretty reasonable solution to start
    addressing some of those top 10 vulnerabilities, namely:'
  prefs: []
  type: TYPE_NORMAL
