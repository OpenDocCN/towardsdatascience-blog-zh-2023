- en: Gradient Boosting from Theory to Practice (Part 1)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/gradient-boosting-from-theory-to-practice-part-1-940b2c9d8050?source=collection_archive---------4-----------------------#2023-07-11](https://towardsdatascience.com/gradient-boosting-from-theory-to-practice-part-1-940b2c9d8050?source=collection_archive---------4-----------------------#2023-07-11)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Understand the math behind the popular gradient boosting algorithm and how to
    use it in practice
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@roiyeho?source=post_page-----940b2c9d8050--------------------------------)[![Dr.
    Roi Yehoshua](../Images/905a512ffc8879069403a87dbcbeb4db.png)](https://medium.com/@roiyeho?source=post_page-----940b2c9d8050--------------------------------)[](https://towardsdatascience.com/?source=post_page-----940b2c9d8050--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----940b2c9d8050--------------------------------)
    [Dr. Roi Yehoshua](https://medium.com/@roiyeho?source=post_page-----940b2c9d8050--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3886620c5cf9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgradient-boosting-from-theory-to-practice-part-1-940b2c9d8050&user=Dr.+Roi+Yehoshua&userId=3886620c5cf9&source=post_page-3886620c5cf9----940b2c9d8050---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----940b2c9d8050--------------------------------)
    ·19 min read·Jul 11, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F940b2c9d8050&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgradient-boosting-from-theory-to-practice-part-1-940b2c9d8050&user=Dr.+Roi+Yehoshua&userId=3886620c5cf9&source=-----940b2c9d8050---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F940b2c9d8050&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgradient-boosting-from-theory-to-practice-part-1-940b2c9d8050&source=-----940b2c9d8050---------------------bookmark_footer-----------)![](../Images/24fe276d9c34eff1399a9e28bbbe6c98.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Jens Lelie](https://unsplash.com/@madebyjens?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/u0vgcIOQG08?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: Gradient boosting is a widely used machine learning technique that is based
    on a combination of **boosting** and **gradient descent**.
  prefs: []
  type: TYPE_NORMAL
- en: Boosting is an [ensemble method](https://medium.com/towards-artificial-intelligence/introduction-to-ensemble-methods-226a5a421687)
    that combines multiple weak learners (or base learners) to create a strong predictive
    model. The base models are trained sequentially, where each model focuses on correcting
    the errors made by the previous models.
  prefs: []
  type: TYPE_NORMAL
- en: In **gradient boosting**, each base model is trained to predict the negative
    gradients of the loss function with respect to the predictions of the previous
    models. As a result, adding the newly trained base learner to the ensemble makes
    a step in the steepest descent direction towards the minimum of the loss. This
    process is similar to gradient descent, but it operates in the function space
    rather than the parameter space. Therefore, it is known as **functional gradient
    descent.**
  prefs: []
  type: TYPE_NORMAL
- en: When the weak learners are [decision trees](https://medium.com/@roiyeho/decision-trees-part-1-da4e613d2369),
    the resulting method is known as **gradient-boosted decision trees** (GBDT) or
    **gradient boosting machine** (GBM).
  prefs: []
  type: TYPE_NORMAL
- en: Gradient boosting is one of the best algorithms that exist today for dealing
    with structured (tabular) data, and…
  prefs: []
  type: TYPE_NORMAL
