- en: Stress-Test Your NLP Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 给你的 NLP 模型做压力测试
- en: 原文：[https://towardsdatascience.com/stress-test-for-your-nlp-models-94dba45b6d83?source=collection_archive---------14-----------------------#2023-01-30](https://towardsdatascience.com/stress-test-for-your-nlp-models-94dba45b6d83?source=collection_archive---------14-----------------------#2023-01-30)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/stress-test-for-your-nlp-models-94dba45b6d83?source=collection_archive---------14-----------------------#2023-01-30](https://towardsdatascience.com/stress-test-for-your-nlp-models-94dba45b6d83?source=collection_archive---------14-----------------------#2023-01-30)
- en: Metrics don’t show the actual performance of NLP models. Learn how to thoroughly
    test your models and fix the annotation artifacts.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指标并未显示 NLP 模型的实际表现。了解如何彻底测试你的模型并修复标注伪影。
- en: '[](https://prosperous-silver-alpaca.medium.com/?source=post_page-----94dba45b6d83--------------------------------)[![Alexander
    Biryukov](../Images/ad35544b7be340297c1676df19436416.png)](https://prosperous-silver-alpaca.medium.com/?source=post_page-----94dba45b6d83--------------------------------)[](https://towardsdatascience.com/?source=post_page-----94dba45b6d83--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----94dba45b6d83--------------------------------)
    [Alexander Biryukov](https://prosperous-silver-alpaca.medium.com/?source=post_page-----94dba45b6d83--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://prosperous-silver-alpaca.medium.com/?source=post_page-----94dba45b6d83--------------------------------)[![Alexander
    Biryukov](../Images/ad35544b7be340297c1676df19436416.png)](https://prosperous-silver-alpaca.medium.com/?source=post_page-----94dba45b6d83--------------------------------)[](https://towardsdatascience.com/?source=post_page-----94dba45b6d83--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----94dba45b6d83--------------------------------)
    [Alexander Biryukov](https://prosperous-silver-alpaca.medium.com/?source=post_page-----94dba45b6d83--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa6325a625339&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstress-test-for-your-nlp-models-94dba45b6d83&user=Alexander+Biryukov&userId=a6325a625339&source=post_page-a6325a625339----94dba45b6d83---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----94dba45b6d83--------------------------------)
    ·9 min read·Jan 30, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F94dba45b6d83&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstress-test-for-your-nlp-models-94dba45b6d83&user=Alexander+Biryukov&userId=a6325a625339&source=-----94dba45b6d83---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa6325a625339&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstress-test-for-your-nlp-models-94dba45b6d83&user=Alexander+Biryukov&userId=a6325a625339&source=post_page-a6325a625339----94dba45b6d83---------------------post_header-----------)
    在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----94dba45b6d83--------------------------------)
    发布 · 9分钟阅读 · 2023年1月30日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F94dba45b6d83&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstress-test-for-your-nlp-models-94dba45b6d83&user=Alexander+Biryukov&userId=a6325a625339&source=-----94dba45b6d83---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F94dba45b6d83&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstress-test-for-your-nlp-models-94dba45b6d83&source=-----94dba45b6d83---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F94dba45b6d83&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstress-test-for-your-nlp-models-94dba45b6d83&source=-----94dba45b6d83---------------------bookmark_footer-----------)'
- en: Dataset artifacts are one of the problems in Natural Language Processing (NLP)
    that affect models’ performance in the real world. Even though pre-trained models
    can perform well on benchmark datasets, they show poor performance in other settings.
    *Those failures are due to dataset artifacts or annotation artifacts* — *spurious
    correlations, which a language model learns during training*[1]*.*
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集伪影是自然语言处理（NLP）中影响模型在实际世界中表现的问题之一。尽管预训练模型在基准数据集上表现良好，但在其他设置中表现却很差。 *这些失败是由于数据集伪影或标注伪影*
    —— *即语言模型在训练过程中学到的虚假关联*[1]*。
- en: '![](../Images/63a1dfef8ca9af14ff29d43f75aaff89.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63a1dfef8ca9af14ff29d43f75aaff89.png)'
- en: Photo by [Nathan Dumlao](https://unsplash.com/ko/@nate_dumlao?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Nathan Dumlao](https://unsplash.com/ko/@nate_dumlao?utm_source=medium&utm_medium=referral)
    于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: It turns out there is a whole bunch of artifacts your model can absorb while
    being trained thanks to the dataset peculiarities and the biases brought in by
    annotators. Why are artifacts bad? Basically, they are providing your model with
    shortcuts to memorize some causalities which are actually false instead of learning
    correct “reasoning”. For example, if a dataset consists of many examples where
    a male character is a doctor, then a model will give more probability to men rather
    than women to be doctors while conducting inference. It is also possible to construct
    some adversarial examples where the model achieves surprisingly low performance.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示，由于数据集的特殊性和标注者带来的偏差，你的模型在训练过程中可能会吸收大量的伪影。伪影为什么不好？基本上，它们为你的模型提供了记住一些实际上是错误的因果关系的捷径，而不是学习正确的“推理”。例如，如果一个数据集中包含许多男性角色是医生的例子，那么在进行推断时，模型会给男性成为医生的概率更高而非女性。也有可能构造一些对抗性示例，使模型表现出令人惊讶的低性能。
- en: Your job as a data scientist is to eliminate as many artifacts as possible and
    to increase the overall…
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家的你的工作是尽可能消除这些伪影，并提高整体…
