- en: A pipeline for fast experimentation on Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/a-pipeline-for-fast-experimentation-on-kubernetes-3258389120a1?source=collection_archive---------26-----------------------#2023-01-31](https://towardsdatascience.com/a-pipeline-for-fast-experimentation-on-kubernetes-3258389120a1?source=collection_archive---------26-----------------------#2023-01-31)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Using native Python packages only
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://pascaljanetzky.medium.com/?source=post_page-----3258389120a1--------------------------------)[![Pascal
    Janetzky](../Images/43d68509b63c5f9b3fc9cef3cbfc1a88.png)](https://pascaljanetzky.medium.com/?source=post_page-----3258389120a1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3258389120a1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3258389120a1--------------------------------)
    [Pascal Janetzky](https://pascaljanetzky.medium.com/?source=post_page-----3258389120a1--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F672b95fdf976&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-pipeline-for-fast-experimentation-on-kubernetes-3258389120a1&user=Pascal+Janetzky&userId=672b95fdf976&source=post_page-672b95fdf976----3258389120a1---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3258389120a1--------------------------------)
    ·6 min read·Jan 31, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3258389120a1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-pipeline-for-fast-experimentation-on-kubernetes-3258389120a1&user=Pascal+Janetzky&userId=672b95fdf976&source=-----3258389120a1---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3258389120a1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-pipeline-for-fast-experimentation-on-kubernetes-3258389120a1&source=-----3258389120a1---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: Manually creating a novel configuration file for every new experiment is a tedious
    process. Especially if you want to rapidly deploy a vast number of jobs on a Kubernetes
    cluster, an automated setup is a must. With python, it’s straightforward to build
    a simple scheduling script that reads an experiment’s configuration, such as the
    batch size, writes it into the YAML file, and creates a new job. In this post,
    we’ll discuss the how. The best is that we require no additional packages!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/042919420529caa70761f3408d3c6ec9.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'The pipeline consists of four files: Two bash scripts (one for creating and
    one for deleting Kubernetes jobs), one python script, and one .yaml-file template.
    Let’s cover them in more detail, beginning with the python script. You can find
    the complete code in [this GitHub repository](https://github.com/phrasenmaeher/kubernetes_yaml_pipeline).'
  prefs: []
  type: TYPE_NORMAL
- en: The python script
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The python code is structured into two methods. The first method yields experiment
    configurations; they are populated with exemplary values. The second method does
    the actual scheduling, which includes parsing the .yaml-file and communicating
    with Kubernetes. Let’s start with the first, more straightforward function:'
  prefs: []
  type: TYPE_NORMAL
