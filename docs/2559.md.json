["```py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim\nimport torch.profiler\nimport torch.utils.data\nfrom torch import Tensor\n\nclass Net(nn.Module):\n    def __init__(self, num_hidden=10, num_classes=10):\n        super().__init__()\n        self.conv_in = nn.Conv2d(3, 10, 3, padding='same')\n        hidden = []\n        for i in range(num_hidden):\n            hidden.append(nn.Conv2d(10, 10, 3, padding='same'))\n            hidden.append(nn.ReLU())\n\n        self.hidden = nn.Sequential(*hidden)\n        self.conv_out = nn.Conv2d(10, num_classes, 3, padding='same')\n\n    def forward(self, x):\n        x = F.relu(self.conv_in(x))\n        x = self.hidden(x)\n        x = self.conv_out(x)\n        return x\n```", "```py\nclass MaskedLoss(nn.Module):\n    def __init__(self, ignore_val=-1, num_classes=10):\n        super().__init__()\n        self.ignore_val = ignore_val\n        self.num_classes = num_classes\n        self.loss = torch.nn.CrossEntropyLoss()\n\n    def cross_entropy(self, pred: Tensor, target: Tensor) -> Tensor:\n\n        # create a boolean mask of valid labels\n        with torch.profiler.record_function('create mask'):\n            mask = target != self.ignore_val\n\n        # permute the logits in preparation for masking\n        with torch.profiler.record_function('permute'):\n            permuted_pred = torch.permute(pred, [0, 2, 3, 1])\n\n        # apply the boolean mask to the targets and logits\n        with torch.profiler.record_function('mask'):\n            masked_target = target[mask]\n            masked_pred = permuted_pred[mask.unsqueeze(-1).expand(-1, -1, -1,\n                                                             self.num_classes)]\n            masked_pred = masked_pred.reshape(-1, self.num_classes)\n\n        # calculate the cross-entropy loss\n        with torch.profiler.record_function('calc loss'):\n            loss = self.loss(masked_pred, masked_target)\n        return loss\n\n    def ignore_background(self, target: Tensor) -> Tensor:\n\n        # discover all indices where target label is \"background\"\n        with torch.profiler.record_function('non_zero'):\n            inds = torch.nonzero(target == self.num_classes - 1, as_tuple=True)\n\n        # reset all \"background\" labels to the ignore index\n        with torch.profiler.record_function('index assignment'):\n            target[inds] = self.ignore_val\n        return target\n\n    def forward(self, pred: Tensor, target: Tensor) -> Tensor:\n\n        # ignore background labels\n        target = self.ignore_background(target)\n\n        # retrieve a list of unique elements in target\n        with torch.profiler.record_function('unique'):\n            unique = torch.unique(target)\n\n        # check if the number of unique items pass the threshold\n        with torch.profiler.record_function('numel'):\n            ignore_loss = torch.numel(unique) < 2\n\n        # calculate the cross-entropy loss\n        loss = self.cross_entropy(pred, target)\n\n        # zero the loss in the case that the number of unique elements\n        # is below the threshold\n        if ignore_loss:\n            loss = 0\\. * loss\n\n        return loss\n```", "```py\nfrom torch.utils.data import Dataset\n\n# A dataset with random images and label maps\nclass FakeDataset(Dataset):\n    def __init__(self, num_classes=10):\n        super().__init__()\n        self.num_classes = num_classes\n        self.img_size = [256, 256]\n\n    def __len__(self):\n        return 1000000\n\n    def __getitem__(self, index):\n        rand_image = torch.randn([3]+self.img_size, dtype=torch.float32)\n        rand_label = torch.randint(low=-1, high=self.num_classes, \n                                                 size=self.img_size)\n        return rand_image, rand_label\n\ntrain_set = FakeDataset()\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=256, \n                              shuffle=True, num_workers=8, pin_memory=True)\n```", "```py\ndevice = torch.device(\"cuda:0\")\nmodel = Net().cuda(device)\ncriterion = MaskedLoss().cuda(device)\n\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\nmodel.train()\n\n# training loop wrapped with profiler object\nwith torch.profiler.profile(\n        schedule=torch.profiler.schedule(wait=1, warmup=4, active=3, repeat=1),\n        on_trace_ready=torch.profiler.tensorboard_trace_handler('/tmp/prof'),\n        record_shapes=True,\n        profile_memory=True,\n        with_stack=True\n) as prof:\n    for step, data in enumerate(train_loader):\n        inputs = data[0].to(device=device, non_blocking=True)\n        labels = data[1].to(device=device, non_blocking=True)\n        if step >= (1 + 4 + 3) * 1:\n            break\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        optimizer.zero_grad(set_to_none=True)\n        loss.backward()\n        optimizer.step()\n        prof.step()\n```", "```py\ndef ignore_background(self, target: Tensor) -> Tensor:\n    with torch.profiler.record_function('update background'):\n        target = torch.where(target==self.num_classes-1, \n                                     -1*torch.ones_like(target),target)\n    return target\n```", "```py\n def forward(self, pred: Tensor, target: Tensor) -> Tensor:\n\n        # ignore background labels\n        target = self.ignore_background(target)\n\n        # sort the list of labels\n        with torch.profiler.record_function('sort'):\n            sorted,_ = torch.sort(target.flatten())\n\n        # indentify the steps of the resultant step function\n        with torch.profiler.record_function('deriv'):\n            deriv = sorted[1:]-sorted[:-1]\n\n        # count the number of steps\n        with torch.profiler.record_function('count_nonzero'):\n            num_unique = torch.count_nonzero(deriv)+1\n\n        # calculate the cross-entropy loss\n        loss = self.cross_entropy(pred, target)\n\n        # zero the loss in the case that the number of unique elements\n        # is below the threshold\n        with torch.profiler.record_function('where'):\n            loss = torch.where(num_unique<2, 0.*loss, loss)\n\n        return loss\n```", "```py\nclass MaskedLoss(nn.Module):\n    def __init__(self, ignore_val=-1, num_classes=10):\n        super().__init__()\n        self.ignore_val = ignore_val\n        self.num_classes = num_classes\n        self.loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n\n    def forward(self, pred: Tensor, target: Tensor) -> Tensor:\n        with torch.profiler.record_function('calc loss'):\n            loss = self.loss(pred, target)\n        return loss\n```"]