- en: Multi-regional source of truth
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多区域数据源
- en: 原文：[https://towardsdatascience.com/multi-regional-source-of-truth-d43e1cc9e098?source=collection_archive---------17-----------------------#2023-03-14](https://towardsdatascience.com/multi-regional-source-of-truth-d43e1cc9e098?source=collection_archive---------17-----------------------#2023-03-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/multi-regional-source-of-truth-d43e1cc9e098?source=collection_archive---------17-----------------------#2023-03-14](https://towardsdatascience.com/multi-regional-source-of-truth-d43e1cc9e098?source=collection_archive---------17-----------------------#2023-03-14)
- en: Multi-regional BI solution with BigQuery as DWH
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 以 BigQuery 作为数据仓库的多区域 BI 解决方案
- en: '[](https://medium.com/@andrey.shalitkin_96428?source=post_page-----d43e1cc9e098--------------------------------)[![Andrey
    Shalitkin](../Images/07d6267bb2e39c6ac306dbd56e00a470.png)](https://medium.com/@andrey.shalitkin_96428?source=post_page-----d43e1cc9e098--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d43e1cc9e098--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d43e1cc9e098--------------------------------)
    [Andrey Shalitkin](https://medium.com/@andrey.shalitkin_96428?source=post_page-----d43e1cc9e098--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@andrey.shalitkin_96428?source=post_page-----d43e1cc9e098--------------------------------)[![Andrey
    Shalitkin](../Images/07d6267bb2e39c6ac306dbd56e00a470.png)](https://medium.com/@andrey.shalitkin_96428?source=post_page-----d43e1cc9e098--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d43e1cc9e098--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d43e1cc9e098--------------------------------)
    [Andrey Shalitkin](https://medium.com/@andrey.shalitkin_96428?source=post_page-----d43e1cc9e098--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4657f2001666&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-regional-source-of-truth-d43e1cc9e098&user=Andrey+Shalitkin&userId=4657f2001666&source=post_page-4657f2001666----d43e1cc9e098---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d43e1cc9e098--------------------------------)
    ·8 min read·Mar 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd43e1cc9e098&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-regional-source-of-truth-d43e1cc9e098&user=Andrey+Shalitkin&userId=4657f2001666&source=-----d43e1cc9e098---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4657f2001666&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-regional-source-of-truth-d43e1cc9e098&user=Andrey+Shalitkin&userId=4657f2001666&source=post_page-4657f2001666----d43e1cc9e098---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d43e1cc9e098--------------------------------)
    · 8 分钟阅读 · 2023年3月14日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd43e1cc9e098&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-regional-source-of-truth-d43e1cc9e098&user=Andrey+Shalitkin&userId=4657f2001666&source=-----d43e1cc9e098---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd43e1cc9e098&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-regional-source-of-truth-d43e1cc9e098&source=-----d43e1cc9e098---------------------bookmark_footer-----------)![](../Images/42968a7b091c74dfaa9535ffb32908ed.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd43e1cc9e098&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-regional-source-of-truth-d43e1cc9e098&source=-----d43e1cc9e098---------------------bookmark_footer-----------)![](../Images/42968a7b091c74dfaa9535ffb32908ed.png)'
- en: Image by [Lars Kienle](https://unsplash.com/@larskienle) on [Unsplash](https://unsplash.com/)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Lars Kienle](https://unsplash.com/@larskienle) 提供，来源于 [Unsplash](https://unsplash.com/)
- en: I created a [post](https://medium.com/towards-data-science/from-postgres-to-snowflake-f4b403548066)
    a year ago about migration from Postgres to Snowflake, and here is another case
    of migration. This time I’m going to concentrate on the business case, architecture,
    and design rather than the technical aspects but I’ll also try to share some tips
    that might be helpful.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我在一年前创建了一篇关于从 Postgres 迁移到 Snowflake 的[文章](https://medium.com/towards-data-science/from-postgres-to-snowflake-f4b403548066)，现在这里有另一个迁移案例。这一次我将集中于业务案例、架构和设计，而不是技术方面，但我也会尝试分享一些可能有用的技巧。
- en: The business case
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 业务案例
- en: 'It’s a B2B (Business to Business) business. The company is an AaaS (Application
    as a Service) provider. It has its software product available as an online service
    for customers in multiple countries across the globe. It requires a BI (Business
    Intelligence) system mostly to give customers access to the data. Here are the
    most interesting requirements:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个B2B（企业对企业）业务。公司是一个AaaS（应用即服务）提供商。它的软件下载作为在线服务，供全球多个国家的客户使用。它主要需要一个BI（商业智能）系统来为客户提供数据访问。以下是最有趣的要求：
- en: Some customers need access to ready-to-use dashboards and visualizations, and
    some want to pull the data into their DWH.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些客户需要访问现成的仪表板和可视化，而有些客户希望将数据提取到他们的DWH中。
- en: Since the customers operate in different countries, the data should stay in
    the region it was initially created in
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于客户在不同国家运营，数据应保持在最初创建的区域内。
- en: The customers should see only their information. For the same region, the data
    is stored within the same database and the same tables, so row-level security
    must be applied
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户应该只能看到他们的信息。对于相同的区域，数据存储在同一数据库和相同表中，因此必须应用行级安全。
- en: In the majority of cases, the customers want real-time data.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在大多数情况下，客户希望实时数据。
- en: 'Let me start with what the existing architecture looked like:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我先介绍一下现有架构的样子：
- en: '![](../Images/ec35a451a03a0e19db61f8ec82aa554f.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ec35a451a03a0e19db61f8ec82aa554f.png)'
- en: Diagram by author
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图表
- en: The key characteristics are read-only replicas to pull the data, no DWH, and
    Looker on top of it. The obvious advantage of the solution is that it’s the quickest
    one to set up. Replica, in general, has real-time data. Looker takes care of transformations,
    semantic layer, and visualizations. The row-level security is also implemented
    in Looker using different filters. Unfortunately, that’s probably the only advantage,
    and it has a lot of drawbacks.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 关键特性是读取只读副本以提取数据，没有DWH，并且在其上使用Looker。显而易见的优点是这是设置最快的解决方案。副本通常具有实时数据。Looker负责数据转换、语义层和可视化。Looker还通过不同的过滤器实现行级安全。不幸的是，这可能是唯一的优点，它还有许多缺点。
- en: Very limited ability to apply any modern data engineering techniques. We can’t
    save the transformed data, we can’t use proper tools to do the transformation,
    implement pipelines, auto-tests, etc. Basically, the only available instrument
    is a Looker Derived Tables functionality.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用任何现代数据工程技术的能力非常有限。我们不能保存转换后的数据，不能使用适当的工具进行转换、实现管道、自动测试等。基本上，唯一可用的工具是Looker
    Derived Tables功能。
- en: As there is no DWH, it’s impossible to pull data from other sources like CRM,
    mix the data from different services, or upload any static dictionary. The BI
    is limited to the data that is saved there by one particular software product.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于没有DWH，无法从其他来源（如CRM）提取数据，也无法混合来自不同服务的数据或上传任何静态字典。BI系统仅限于由特定软件产品保存的数据。
- en: As I’ve mentioned earlier, some customers need to pull the data and they’d like
    to have as low-level and raw data as possible. Looker does a great job delivering
    the reports but it works on top of its semantic layer which already has some joins,
    not all the fields are available and each Looker explore is designed for a specific
    business process. The structure is not optimized for export.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如我之前提到的，一些客户需要提取数据，并希望获得尽可能低级和原始的数据。Looker在提供报告方面做得很好，但它在其语义层之上工作，语义层已经有一些联接，并且并非所有字段都可用，每个Looker探查都是为特定业务流程设计的。结构并未针对导出进行优化。
- en: Performance. This is probably the biggest problem as the OLTP database is not
    designed for analytical purposes and we don’t have control over indexes as we
    work with read-only replicas. It leads not only to initial slow performance but
    also to performance degradation as without the indexes the more data we have the
    slower the queries are.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能。这可能是最大的问题，因为OLTP数据库不适合分析用途，并且由于我们使用的是只读副本，无法控制索引。这不仅导致初始性能缓慢，还会导致性能下降，因为没有索引时，数据越多查询速度越慢。
- en: The solution
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'The most straightforward way to address those drawbacks was to introduce a
    DWH layer which we did. The new design looked like this:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这些缺点的最直接方法是引入DWH层，我们确实这样做了。新的设计如下所示：
- en: '![](../Images/83eda77d9e064e6783c2ad9cb17a746b.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/83eda77d9e064e6783c2ad9cb17a746b.png)'
- en: Diagram by author
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图表
- en: Streaming data
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流数据
- en: There are various providers on the market to do the streaming, we’ve chosen
    Fivetran but one can have a look at Stitch, Airbyte, or any open-source framework
    like Meltano or poor Singer. We’ve also considered Google Storage Transfer Service,
    but it was in the raw state and didn’t have enough flexibility.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 市场上有多种流媒体提供商可供选择，我们选择了 Fivetran，但也可以看看 Stitch、Airbyte 或其他开源框架，如 Meltano 或 Singer。我们也考虑过
    Google Storage Transfer Service，但它还处于原始状态，灵活性不足。
- en: 'The whole process of the streaming setup wasn’t without issues, of course.
    Here are some of them:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 流媒体设置的整个过程当然不是没有问题的。以下是其中一些问题：
- en: The OLTP database didn’t have public access so a VPN had to be set up for Fivetran
    to pull the data. It involved some network configuration and required additional
    back and forth to decide on the solution that worked for both Fivetran and us
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OLTP 数据库没有公共访问权限，因此必须为 Fivetran 设置 VPN 以拉取数据。这涉及一些网络配置，并需要反复讨论以决定既适用于 Fivetran
    又适用于我们的解决方案。
- en: Fivetran adds to the database load, so we had to setup additional monitoring,
    and make sure that the stream doesn’t affect the main functionality
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fivetran 增加了数据库的负载，因此我们必须设置额外的监控，确保流媒体不会影响主要功能。
- en: The initial plan was to sync data every 5 minutes but it was causing connections
    to time out and was throwing errors in logs due to the big volume of changes.
    Fivetran was able to recover so it was no data loss but it was generating a mess
    that was making it difficult to distinguish between real errors and these overload
    errors. There was no straightforward solution but to relax requirements related
    to having real-time data and start pulling the data less frequently.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最初的计划是每 5 分钟同步一次数据，但由于更改量巨大，导致连接超时并在日志中抛出错误。Fivetran 能够恢复，因此没有数据丢失，但生成了混乱，使得很难区分实际错误和这些过载错误。没有简单的解决方案，只能放宽对实时数据的要求，减少数据拉取的频率。
- en: Transforming data
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转换数据
- en: The BigQuery was chosen mainly because it satisfies all the requirements we
    had and the majority of the existing infrastructure is also in Google cloud so
    the transition was supposed to be smooth.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 选择 BigQuery 主要是因为它满足了我们所有的要求，并且大多数现有基础设施也在 Google 云中，因此过渡本应顺利。
- en: Since we now have DWH, which is not read-only, we were able to utilize the [DBT](https://www.getdbt.com/)
    tool to perform data transformation and mix data from different sources, but even
    without any transformations, with Looker querying the same data as before but
    from BigQuery, the performance has improved dramatically, sometimes more than
    **100 times** for the heavy tables.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们现在有了可读写的 DWH，我们能够利用 [DBT](https://www.getdbt.com/) 工具进行数据转换，并将来自不同来源的数据混合在一起。即使没有任何转换，通过
    Looker 查询之前相同的数据，但从 BigQuery 中获取，性能也有了显著提高，有时对重表的提升超过了**100倍**。
- en: I won’t stop on the data preparation for the Looker as it’s very domain specific.
    What’s more interesting is how we solved the data export problem. In general,
    it’s very simple, we’ve just given customers direct access to BigQuery but the
    devil is in the details so let me share some of it.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会详细讨论 Looker 的数据准备，因为它非常领域特定。更有趣的是我们如何解决数据导出问题。总的来说，这很简单，我们只是给了客户对 BigQuery
    的直接访问权限，但细节中的问题需要关注，所以让我分享一些细节。
- en: The easiest requirement to implement was keeping data in different regions.
    Fortunately, the region for each Dataset in BigQuery is configurable. Fivetran
    streams data into different datasets and DBT models are run against these datasets
    separately so the data from different regions don’t get mixed at all.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 实现的最简单要求是将数据保存在不同的区域。幸运的是，BigQuery 中每个数据集的区域是可配置的。Fivetran 将数据流入不同的数据集，而 DBT
    模型则针对这些数据集分别运行，因此来自不同区域的数据完全不会混合。
- en: It was a bit more complicated to implement row-level security to make sure that
    the customers have access to their data only. BigQuery supports row-level security,
    but since we use DBT we’ve chosen a different approach to have better control
    over the exposing data and more options to automate the process.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 实现行级安全性以确保客户仅能访问他们的数据要复杂一些。BigQuery 支持行级安全性，但由于我们使用 DBT，因此选择了不同的方法，以更好地控制数据暴露和更多自动化选项。
- en: 'We’ve created a set of DBT models that apply security in SQL code based on
    the information about the currently connected user and create views in BigQuery.
    More precisely:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一组 DBT 模型，这些模型根据当前连接用户的信息在 SQL 代码中应用安全性，并在 BigQuery 中创建视图。更准确地说：
- en: Each customer who needs access is provided with the user/service account. The
    IAM role has general access to BigQuery, but there is no access to any specific
    dataset, so, initially, a new user can’t query the data
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要访问的每个客户都提供用户/服务帐户。IAM角色具有对BigQuery的通用访问权限，但没有对任何特定数据集的访问权限，因此，初始状态下，新用户无法查询数据
- en: The new user email is added to the DBT seed files along with the identification
    of the customer. Files for different regions are kept separately. It gives a user-customer
    mapping as well as information on what dataset the user should have access to.
    The seed files are stored in GitHub and therefore, we can run a GitHub action
    on every change in this file
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新用户电子邮件与客户识别信息一起添加到DBT种子文件中。不同地区的文件分别保存。这提供了用户-客户映射以及用户应该访问的数据集的信息。种子文件存储在GitHub中，因此我们可以在此文件的每次更改时运行GitHub操作
- en: The GitHub Action runs the parametrized DBT project against different regions.
    The regions and data are different but the structure is the same so we needed
    to write SQL code just once per each view. The DBT uploads seed files, creates
    views, and as a final step gives individual users read-only access to the needed
    dataset
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GitHub Action在不同地区运行参数化的DBT项目。地区和数据不同，但结构相同，因此我们只需为每个视图编写一次SQL代码。DBT上传种子文件，创建视图，最后一步是为各个用户提供对所需数据集的只读访问权限
- en: The views identify a currently logged-in user email using the `session_user()`
    function, join it with the user-customer mapping, and filter out everything which
    is not related to the customer from the mapping.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视图通过`session_user()`函数识别当前登录的用户电子邮件，将其与用户-客户映射连接，并筛选出与客户无关的所有内容。
- en: 'One very specific case over here that I wanted to share is giving access to
    oAuth users. In Google IAM there are two types of users: service account and oAuth
    user. It’s easy to work with the first one but not all the downstream systems
    support this type of access. E.g., Tableau online can’t work with the service
    account. The second type is a way a normal user logs into the Google account.
    It’s very poorly documented how to make sure that such a user has access to the
    specific datasets only, so here are the tips:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个我想分享的非常具体的情况，即授予oAuth用户访问权限。在Google IAM中有两种类型的用户：服务帐户和oAuth用户。处理第一种用户比较简单，但并非所有下游系统都支持这种访问方式。例如，Tableau
    online无法使用服务帐户。第二种类型是普通用户登录Google帐户的方式。有关如何确保这种用户仅访问特定数据集的文档非常有限，因此这里是一些提示：
- en: A user should have all the permissions of the `BigQuery Job` user and a `bigquery.jobs.create`
    permission additionally
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户应该拥有`BigQuery Job`用户的所有权限，并额外具有`bigquery.jobs.create`权限
- en: The dataset-level permission can be granted then the same way it works for the
    service account, e.g. with the SQL GRANT command
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集级权限可以像服务帐户一样授予，例如使用SQL GRANT命令
- en: A user doesn’t necessarily need to be created by the same Google account. E.G.
    people from other organizations can get access provided their IAM permissions
    are configured correctly in our project
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户不一定需要由相同的Google帐户创建。例如，来自其他组织的人可以获得访问权限，只要他们的IAM权限在我们的项目中配置正确
- en: Be careful with the group emails. Everything works about the access on the dataset
    level, but the `session_user()` returns the user's individual email so the row-level
    security won’t work with the group email
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小心组电子邮件。虽然数据集级别的访问权限正常工作，但`session_user()`返回的是用户的个人电子邮件，因此行级安全性无法与组电子邮件一起使用
- en: Last but not least tip to mention is that since we the clients have access to
    the views, not the tables, the views should be able to query the data from other
    data sets without exposing the raw data to the client. BigQuery has such an ability,
    one can allow all the views from one dataset to query the data from the other
    dataset regardless of the end user permissions.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个要提到的提示是，由于我们客户端只能访问视图而不能访问表格，因此视图应该能够从其他数据集查询数据，而无需将原始数据暴露给客户端。BigQuery具备这样的能力，可以允许一个数据集中的所有视图查询另一个数据集中的数据，而不受最终用户权限的限制。
- en: BigQuery monitoring
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BigQuery监控
- en: Since the customers have direct access to the DWH it’s important to know how
    much each of the customers utilizes the functionality. Since each customer is
    tied to the user the monitoring on the user level should be able to answer this
    question. I’ve come across an [interesting article on how to do it](/monitoring-your-bigquery-costs-and-reports-usage-with-data-studio-b77819ffd9fa)
    and we’ve just re-implemented the same approach in Looker.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 由于客户可以直接访问DWH，因此了解每个客户如何使用这些功能非常重要。由于每个客户都与用户绑定，因此在用户级别的监控应该能够回答这个问题。我遇到了一篇[关于如何做到这一点的有趣文章](/monitoring-your-bigquery-costs-and-reports-usage-with-data-studio-b77819ffd9fa)，我们刚刚在Looker中重新实现了相同的方法。
- en: The other part of the infrastructure is Github, more precisely GitHub actions.
    This functionality allows to create an execution workflow and set up a schedule
    for it. There are existing open-source actions like [this](https://github.com/marketplace/actions/dbt-action)
    that can help implement it, and the only thing to pay for is the GitHub minutes.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 基础设施的另一个部分是Github，更准确地说是GitHub Actions。此功能允许创建执行工作流并设置计划。像[这个](https://github.com/marketplace/actions/dbt-action)这样的开源操作可以帮助实现这一点，唯一需要支付的就是GitHub的使用时间。
- en: Single source of truth
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单一真实数据源
- en: The last thing I’d like to mention is the solution's flexibility. I’ve described
    the main and the most interesting case but the company has other services and
    with the current solution we were able to move the analytics of all these services
    into our DWH system and use it as a source of truth for the downstream systems.
    In other words, it also serves as a data feed. DBT is used to produce the views
    and tables for all the business cases and the Dataset level access allows separation
    of the downstream systems and users on the data level.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我最后要提到的是解决方案的灵活性。我已经描述了主要和最有趣的案例，但公司还有其他服务，凭借当前的解决方案，我们能够将所有这些服务的分析转移到我们的DWH系统中，并将其用作下游系统的真实数据源。换句话说，它也作为数据馈送存在。DBT被用来为所有业务案例生成视图和表格，而数据集级别的访问允许在数据级别分离下游系统和用户。
- en: The DBT flexibility allows creating models for different downstream systems
    within one project which is automated by means of GitHub as I mentioned earlier.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: DBT的灵活性允许在一个项目中为不同的下游系统创建模型，这一过程通过前面提到的GitHub实现自动化。
