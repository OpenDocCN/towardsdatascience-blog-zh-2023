- en: TensorFlow Model Training Using GradientTape
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/tensorflow-model-training-using-gradienttape-f2093646ab13?source=collection_archive---------10-----------------------#2023-10-17](https://towardsdatascience.com/tensorflow-model-training-using-gradienttape-f2093646ab13?source=collection_archive---------10-----------------------#2023-10-17)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/fbe16d8537174389bce863e509126468.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Sivani Bandaru](https://unsplash.com/@agni11?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Use of GradientTape to Update the Weights
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://rashida00.medium.com/?source=post_page-----f2093646ab13--------------------------------)[![Rashida
    Nasrin Sucky](../Images/42bd057e8eca255907c43c29a498f2ca.png)](https://rashida00.medium.com/?source=post_page-----f2093646ab13--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f2093646ab13--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f2093646ab13--------------------------------)
    [Rashida Nasrin Sucky](https://rashida00.medium.com/?source=post_page-----f2093646ab13--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8a36b941a136&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftensorflow-model-training-using-gradienttape-f2093646ab13&user=Rashida+Nasrin+Sucky&userId=8a36b941a136&source=post_page-8a36b941a136----f2093646ab13---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f2093646ab13--------------------------------)
    ·7 min read·Oct 17, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff2093646ab13&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftensorflow-model-training-using-gradienttape-f2093646ab13&user=Rashida+Nasrin+Sucky&userId=8a36b941a136&source=-----f2093646ab13---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff2093646ab13&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftensorflow-model-training-using-gradienttape-f2093646ab13&source=-----f2093646ab13---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow is arguably the most popular library for deep learning. I wrote so
    many tutorials on TensorFlow before and still continuing. TensorFlow is very well
    organized and easy to use package where you do not need to worry about model development
    and model training too much. Pretty much most of the stuff is taken care of by
    the package itself. That is probably the reason why it has gotten so popular in
    the industry. But at the same time, sometimes it is nice to have control over
    the behind-the-scenes functionalities. It gives you a lot of power to experiment
    with the models. If you are job seeker, some extra knowledge may give you an edge.
  prefs: []
  type: TYPE_NORMAL
- en: Previously, I wrote an article on [how to develop custom activation functions,
    layers, and loss functions](/how-to-define-custom-layer-activation-function-and-loss-function-in-tensorflow-bdd7e78eb67).
    In this article, we will see how you can train the model manually and update the
    weights yourself. But don’t worry. You don’t have to remember the differential
    calculus all over again. We have GradientTape() method available in TensorFlow
    itself to take care of that part.
  prefs: []
  type: TYPE_NORMAL
- en: 'If GradientTape() is totally new to you, please feel free to check this exercises
    on GradientTape() that shows you, how GradientTape() works: [Introduction to GradientTape
    in TensorFlow — Regenerative (regenerativetoday.com)](https://regenerativetoday.com/introduction-to-gradienttape-in-tensorflow/)'
  prefs: []
  type: TYPE_NORMAL
