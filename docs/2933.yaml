- en: Quantifying GPT-4’s Hidden Regressions Over Time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/quantifying-gpt-4s-hidden-regressions-over-time-368d3a16dca?source=collection_archive---------7-----------------------#2023-09-22](https://towardsdatascience.com/quantifying-gpt-4s-hidden-regressions-over-time-368d3a16dca?source=collection_archive---------7-----------------------#2023-09-22)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Part 3 of a study on generative AI usage and testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://markopolocheno.medium.com/?source=post_page-----368d3a16dca--------------------------------)[![Mark
    Chen](../Images/2d51d4e7ab451b55733a018a3d10a0a7.png)](https://markopolocheno.medium.com/?source=post_page-----368d3a16dca--------------------------------)[](https://towardsdatascience.com/?source=post_page-----368d3a16dca--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----368d3a16dca--------------------------------)
    [Mark Chen](https://markopolocheno.medium.com/?source=post_page-----368d3a16dca--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F377682c0f342&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fquantifying-gpt-4s-hidden-regressions-over-time-368d3a16dca&user=Mark+Chen&userId=377682c0f342&source=post_page-377682c0f342----368d3a16dca---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----368d3a16dca--------------------------------)
    ·5 min read·Sep 22, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F368d3a16dca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fquantifying-gpt-4s-hidden-regressions-over-time-368d3a16dca&user=Mark+Chen&userId=377682c0f342&source=-----368d3a16dca---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F368d3a16dca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fquantifying-gpt-4s-hidden-regressions-over-time-368d3a16dca&source=-----368d3a16dca---------------------bookmark_footer-----------)![](../Images/071dde74efb851e67523d42b93c503db.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Randy Fath](https://unsplash.com/@randyfath?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: GPT-4 is bigger and better than GPT-3\. GPT-4 can draft up eloquent speeches,
    [pass standardized exams](https://openai.com/research/gpt-4#:~:text=among%20test%20takers)-,Exam%20results,-(ordered%20by%20GPT),
    and even [interpret images](https://openai.com/research/gpt-4#:~:text=Visual%20inputs%3A%20VGA%20charger).
    Since its release on March 14, 2023, OpenAI continues to iterate and update GPT-4
    to improve its performance for the millions of queries it receives each day. However,
    **is the latest version of GPT-4 in OpenAI’s API, called “gpt-4”, actually better
    than the initial version** from March, called “gpt-4–0314”?
  prefs: []
  type: TYPE_NORMAL
- en: From the perspective of a machine learning engineer at [Kolena](https://www.kolena.io/),
    this article is a [continuation in a series of discussions highlighting a testing
    paradigm for LLMs](/how-to-validate-openai-gpt-model-performance-with-text-summarization-298978fea764),
    comparing the performance of GPT models under different scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: While the overall behavior of “gpt-4” might be better than “gpt-4–0314” through
    the results of various testing benchmarks and metrics, the word “better” is a
    relative term. Users have shared online that they **experienced a recent** [**regression
    in GPT-4 model performance**](https://arxiv.org/pdf/2307.09009.pdf) **in a variety
    of contexts**. One viral instance of GPT-4’s regression over time is that it could
    not figure out that 17077 was a prime number as well as it could before.
  prefs: []
  type: TYPE_NORMAL
- en: Naturally, using the most up-to-date model when it continually declines in subjective
    and objective performance is problematic. **What other regressions might secretly
    exist?**
  prefs: []
  type: TYPE_NORMAL
- en: 'We can test for hidden regressions of GPT-4 by using the CoQA ([Conversational
    Question Answering](https://stanfordnlp.github.io/coqa/))** dataset. The CoQA
    dataset contains multiple articles, each having a series of corresponding questions,
    where understanding question *n* is necessary for answering question *n+1*. Given
    an article on sport history as an example, here are some potential questions:'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Who is the most decorated Olympian?
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Which country are they from?
  prefs: []
  type: TYPE_NORMAL
- en: 3\. How many gold medals do they have?
  prefs: []
  type: TYPE_NORMAL
- en: It’s impossible to individually answer these questions because we would not
    know the person of interest without answering the first question.
  prefs: []
  type: TYPE_NORMAL
- en: Findings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'At a high level, **GPT-4 performs better than GPT-3 significantly**, but it’s
    still not perfect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '*Note: “gpt-3” is the latest Turbo model of the GPT-3.5 series, and n_correct
    is the count of questions where the average of its* [*BERT_F1*](https://huggingface.co/spaces/evaluate-metric/bertscore)
    *and* [*ROUGE_1*](https://huggingface.co/spaces/evaluate-metric/rouge) *is greater
    than 0.75*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: From the above, how come **“gpt-4–0314” is worse by metric** (BERT_F1 and ROUGE_1)
    **yet has more correctly answered questions than “gpt-4”**? Maybe both models
    incorrectly answer the same questions, but there is no guarantee that the failure
    sets of “gpt-4” and “gpt-4–0314” are homogeneous. Under the assumption that a
    newer model should be more performant, the reason for this difference or regression
    is not explainable when we observe the metrics. We can dig deeper into understanding
    the potential root causes of failure when we logically break down the data into
    smaller groups.
  prefs: []
  type: TYPE_NORMAL
- en: When we stratify the CoQA dataset with respect to the data source of each article,
    we will find that the question-answer **data pertaining to Wikipedia articles
    performed better in the newest GPT-4 model** but worse overall and in every other
    data source.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0bcb9c86a241236d376533458b45d1c1.png)'
  prefs: []
  type: TYPE_IMG
- en: A comparison of “gpt-4” and “gpt-4–0314” by BERT_F1, ROUGE_1, and the count
    of correct answers, taken from [Kolena](https://www.kolena.io/)
  prefs: []
  type: TYPE_NORMAL
- en: The image above shows a comparison between “gpt-4–0314” as a benchmark and “gpt-4”,
    highlighting the differences in the number of correct answers generated with respect
    to an improvement or decline among different data sources. **In terms of the number
    of correct answers, GPT-4's only improvement is from Wikipedia’s datapoints, and
    it declines in performance everywhere else.**
  prefs: []
  type: TYPE_NORMAL
- en: Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Does this reveal that “gpt-4” is a fine-tuned version of “gpt-4–0314” on
    Wikipedia articles?** Unfortunately, we don’t know.'
  prefs: []
  type: TYPE_NORMAL
- en: Can we then say that GPT-4 has become worse? By this measure, not necessarily.
    While academia considers Wikipedia to be an unreliable source of information,
    many people still regularly use it for quick and accessible information. If OpenAI
    wants GPT to answer any question in any domain, having **a complete comprehension
    of Wikipedia is more valuable than understanding news articles when users make
    millions of random queries each day**. News articles tend to have common themes
    anyway, and the average person might not ask GPT questions pertaining to news
    articles on topics absent within Wikipedia.
  prefs: []
  type: TYPE_NORMAL
- en: Prior to stratifying the dataset by the different data sources, there was no
    concrete explanation for why “gpt-4–0314” obtained a greater number of correct
    results compared to “gpt-4”. With just one stratification, we gain one plausible
    explanation as to why and how the models are different.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Over time, GPT-4 has regressed in conversational question answering for multiple
    data sources, but improved in performance for queries involving Wikipedia articles.**'
  prefs: []
  type: TYPE_NORMAL
- en: Being able to identify hidden regressions should be a priority for all engineers
    before deploying models to production. Finding hidden regressions for LLMs is
    not trivial, but it becomes easier with the right approach. **The best model is
    not necessarily the one with the best overall performance but the one with the
    best results under the scenarios that matter most.**
  prefs: []
  type: TYPE_NORMAL
- en: We’ll dig deeper into more stratifications of CoQA to further understand how
    GPT-4 has changed over time in a future blog post. Stay tuned!
  prefs: []
  type: TYPE_NORMAL
- en: '**The [CoQA dataset contains data from seven different datasets](https://stanfordnlp.github.io/coqa/#:~:text=Submission%20Tutorial-,License,-CoQA%20contains%20passages)
    having different licenses. In this article, we do not reveal any data within the
    dataset, and only used the data for testing and analysis from these commercially
    available data sources: Gutenberg, CNN, MCTest, and Wikipedia, with a [CC BY-SA
    4.0](https://creativecommons.org/licenses/by-sa/4.0/), [MSR-LA](https://github.com/mcobzarenco/mctest/blob/master/data/MCTest/LICENSE.pdf),
    or [Apache](https://github.com/deepmind/rc-data/blob/master/LICENSE) license.'
  prefs: []
  type: TYPE_NORMAL
