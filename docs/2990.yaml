- en: 'Regulating AI: The Case for a Mechanisms-Based Approach'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è§„åˆ¶äººå·¥æ™ºèƒ½ï¼šåŸºäºæœºåˆ¶çš„æ–¹æ³•
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/regulating-ai-the-case-for-a-mechanisms-based-approach-391ddcef09d?source=collection_archive---------11-----------------------#2023-09-29](https://towardsdatascience.com/regulating-ai-the-case-for-a-mechanisms-based-approach-391ddcef09d?source=collection_archive---------11-----------------------#2023-09-29)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/regulating-ai-the-case-for-a-mechanisms-based-approach-391ddcef09d?source=collection_archive---------11-----------------------#2023-09-29](https://towardsdatascience.com/regulating-ai-the-case-for-a-mechanisms-based-approach-391ddcef09d?source=collection_archive---------11-----------------------#2023-09-29)
- en: Targeting specific mechanisms mitigates AI risks more effectively, is easier
    to get consensus on, and avoids unintended consequences of brute force approaches
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é’ˆå¯¹ç‰¹å®šæœºåˆ¶èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å‡è½»äººå·¥æ™ºèƒ½é£é™©ï¼Œæ›´å®¹æ˜“è¾¾æˆå…±è¯†ï¼Œå¹¶é¿å…ç²—æš´æ–¹æ³•çš„æ„å¤–åæœ
- en: '[](https://medium.com/@viggybala?source=post_page-----391ddcef09d--------------------------------)[![Viggy
    Balagopalakrishnan](../Images/a3d6b5d26327892108816c0ef125b90d.png)](https://medium.com/@viggybala?source=post_page-----391ddcef09d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----391ddcef09d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----391ddcef09d--------------------------------)
    [Viggy Balagopalakrishnan](https://medium.com/@viggybala?source=post_page-----391ddcef09d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@viggybala?source=post_page-----391ddcef09d--------------------------------)[![Viggy
    Balagopalakrishnan](../Images/a3d6b5d26327892108816c0ef125b90d.png)](https://medium.com/@viggybala?source=post_page-----391ddcef09d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----391ddcef09d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----391ddcef09d--------------------------------)
    [Viggy Balagopalakrishnan](https://medium.com/@viggybala?source=post_page-----391ddcef09d--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb3366eb9a0cf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregulating-ai-the-case-for-a-mechanisms-based-approach-391ddcef09d&user=Viggy+Balagopalakrishnan&userId=b3366eb9a0cf&source=post_page-b3366eb9a0cf----391ddcef09d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----391ddcef09d--------------------------------)
    Â·13 min readÂ·Sep 29, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F391ddcef09d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregulating-ai-the-case-for-a-mechanisms-based-approach-391ddcef09d&user=Viggy+Balagopalakrishnan&userId=b3366eb9a0cf&source=-----391ddcef09d---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb3366eb9a0cf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregulating-ai-the-case-for-a-mechanisms-based-approach-391ddcef09d&user=Viggy+Balagopalakrishnan&userId=b3366eb9a0cf&source=post_page-b3366eb9a0cf----391ddcef09d---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----391ddcef09d--------------------------------)
    Â·13åˆ†é’Ÿé˜…è¯»Â·2023å¹´9æœˆ29æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F391ddcef09d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregulating-ai-the-case-for-a-mechanisms-based-approach-391ddcef09d&user=Viggy+Balagopalakrishnan&userId=b3366eb9a0cf&source=-----391ddcef09d---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F391ddcef09d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregulating-ai-the-case-for-a-mechanisms-based-approach-391ddcef09d&source=-----391ddcef09d---------------------bookmark_footer-----------)![](../Images/84303b6279fb455fbedd8cfbb86e71b4.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F391ddcef09d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregulating-ai-the-case-for-a-mechanisms-based-approach-391ddcef09d&source=-----391ddcef09d---------------------bookmark_footer-----------)![](../Images/84303b6279fb455fbedd8cfbb86e71b4.png)'
- en: Photo by [Growtika](https://unsplash.com/@growtika?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ç…§ç‰‡ç”± [Growtika](https://unsplash.com/@growtika?utm_source=medium&utm_medium=referral)
    æä¾›ï¼Œæ¥æºäº [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '***This is the second of three articles in*** [***Unpackedâ€™s***](https://thisisunpacked.substack.com/?utm_source=medium&utm_medium=article_tds)
    ***â€œTech Policy Septemberâ€ series.***'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '***è¿™æ˜¯â€œTech Policy Septemberâ€ç³»åˆ—ä¸­çš„ç¬¬ä¸‰ç¯‡æ–‡ç« *** [***Unpackedâ€™s***](https://thisisunpacked.substack.com/?utm_source=medium&utm_medium=article_tds)
    ***ã€‚***'
- en: '**Disclaimer:** The views expressed in this article are solely my own and do
    not reflect the views or positions of any organization with which I am affiliated,
    including current and past employers.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**å…è´£å£°æ˜ï¼š**æœ¬æ–‡è¡¨è¾¾çš„è§‚ç‚¹ä»…ä¸ºæˆ‘ä¸ªäººè§‚ç‚¹ï¼Œå¹¶ä¸åæ˜ æˆ‘æ‰€éš¶å±çš„ä»»ä½•ç»„ç»‡çš„è§‚ç‚¹æˆ–ç«‹åœºï¼ŒåŒ…æ‹¬å½“å‰å’Œè¿‡å»çš„é›‡ä¸»ã€‚'
- en: The launch of ChatGPT kicked off a new generative AI wave, which has been met
    with both optimism and concern about its impact on our lives. Specifically, a
    majority of the discussion has been around Large Language Models (LLMs) â€” eg.
    OpenAIâ€™s GPT model which powers ChatGPT. Itâ€™s not just OpenAI that has released
    models â€” several others have entered the market including Facebook (LLaMA), Google
    (LaMBDA), and Anthropic, to name a few. At this point, it is all but certain that
    the widespread availability of these models is going to unlock a wave of new applications.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPTçš„å‘å¸ƒå¼€å¯äº†ä¸€æ³¢æ–°çš„ç”Ÿæˆæ€§AIæµªæ½®ï¼Œè¿™ä¸€æµªæ½®å¼•å‘äº†å¯¹å…¶å¯¹æˆ‘ä»¬ç”Ÿæ´»å½±å“çš„ä¹è§‚ä¸æ‹…å¿§ã€‚å…·ä½“æ¥è¯´ï¼Œå¤§å¤šæ•°è®¨è®ºé›†ä¸­åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸Šâ€”â€”ä¾‹å¦‚ï¼Œé©±åŠ¨ChatGPTçš„OpenAIçš„GPTæ¨¡å‹ã€‚ä¸ä»…æ˜¯OpenAIå‘å¸ƒäº†æ¨¡å‹â€”â€”åŒ…æ‹¬Facebookï¼ˆLLaMAï¼‰ã€Googleï¼ˆLaMBDAï¼‰å’ŒAnthropicåœ¨å†…çš„å…¶ä»–å‡ å®¶å…¬å¸ä¹Ÿè¿›å…¥äº†å¸‚åœºã€‚ç°åœ¨ï¼Œå‡ ä¹å¯ä»¥è‚¯å®šè¿™äº›æ¨¡å‹çš„å¹¿æ³›å¯ç”¨æ€§å°†å¼€å¯ä¸€æ³¢æ–°çš„åº”ç”¨ã€‚
- en: With this growth comes a legitimate concern about the risks a powerful technology
    like this can create â€” ranging from accelerating misinformation, to hallucinations
    (models confidently returning junk results), to existential (AI taking over humanity).
    Thoughtful regulation is required to address these risks and surprisingly, early
    conversations around regulating AI are already in progress, unlike technology
    changes in the past where regulation was an afterthought.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€è¿™ç§å¢é•¿ï¼Œå‡ºç°äº†å¯¹è¿™ç§å¼ºå¤§æŠ€æœ¯å¯èƒ½å¸¦æ¥çš„é£é™©çš„æ­£å½“æ‹…å¿§â€”â€”ä»åŠ é€Ÿè™šå‡ä¿¡æ¯çš„ä¼ æ’­ï¼Œåˆ°å¹»è§‰ï¼ˆæ¨¡å‹è‡ªä¿¡åœ°è¿”å›åƒåœ¾ç»“æœï¼‰ï¼Œå†åˆ°ç”Ÿå­˜é£é™©ï¼ˆAIæ¥ç®¡äººç±»ï¼‰ã€‚éœ€è¦æ·±æ€ç†Ÿè™‘çš„ç›‘ç®¡æ¥è§£å†³è¿™äº›é£é™©ï¼Œä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œå…³äºç›‘ç®¡AIçš„æ—©æœŸè®¨è®ºå·²ç»åœ¨è¿›è¡Œä¸­ï¼Œè¿™ä¸è¿‡å»æŠ€æœ¯å˜åŒ–ä¸­çš„ç›‘ç®¡è¢«å¿½è§†å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚
- en: That said, AI regulation in the US is still in its early days. There are two
    types of regulatory constructs under consideration today â€” 1) broad bills in the
    Senate which cover a wide range of issues and might be difficult to get consensus
    on, and 2) non-binding, broad frameworks listing out AI principles but without
    much specifics agreed upon.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿå°±æ˜¯è¯´ï¼Œç¾å›½çš„äººå·¥æ™ºèƒ½ç›‘ç®¡ä»å¤„äºåˆæœŸé˜¶æ®µã€‚ä»Šå¤©æœ‰ä¸¤ç§ç±»å‹çš„ç›‘ç®¡æ„æƒ³æ­£åœ¨è€ƒè™‘â€”â€”1) åœ¨å‚è®®é™¢æå‡ºçš„æ¶µç›–å¹¿æ³›é—®é¢˜çš„å¹¿æ³›æ³•æ¡ˆï¼Œå¯èƒ½éš¾ä»¥è¾¾æˆå…±è¯†ï¼Œå’Œ2) åˆ—å‡ºAIåŸåˆ™ä½†æ²¡æœ‰å…·ä½“ç»†èŠ‚çš„éçº¦æŸæ€§å¹¿æ³›æ¡†æ¶ã€‚
- en: 'This article makes the case for a more focused approach to AI regulation that
    is **less of a â€œbundle everything into one billâ€ approach**, and more of a **targeted
    approach that regulates** **specific** **mechanisms** tied to meaningful AI risks.
    Weâ€™ll dive into:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡ä¸»å¼ é‡‡ç”¨ä¸€ç§æ›´é›†ä¸­çš„äººå·¥æ™ºèƒ½ç›‘ç®¡æ–¹æ³•ï¼Œå³**ä¸å†æ˜¯â€œæŠŠä¸€åˆ‡éƒ½æ‰“åŒ…åˆ°ä¸€ä¸ªæ³•æ¡ˆä¸­â€**ï¼Œè€Œæ˜¯**æœ‰é’ˆå¯¹æ€§åœ°ç›‘ç®¡** **ç‰¹å®š** **æœºåˆ¶**ï¼Œè¿™äº›æœºåˆ¶ä¸æœ‰æ„ä¹‰çš„AIé£é™©ç›¸å…³ã€‚æˆ‘ä»¬å°†æ·±å…¥æ¢è®¨ï¼š
- en: Risks posed by AI
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äººå·¥æ™ºèƒ½æ‰€å¸¦æ¥çš„é£é™©
- en: Current approaches to managing AI risks
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“å‰ç®¡ç†AIé£é™©çš„æ–¹æ³•
- en: Regulations proposed in the US today
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»Šæ—¥ç¾å›½æè®®çš„ç›‘ç®¡æªæ–½
- en: The case for a mechanisms-based approach
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœºåˆ¶å¯¼å‘æ–¹æ³•çš„æ¡ˆä¾‹
- en: Risks posed by AI
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: äººå·¥æ™ºèƒ½æ‰€å¸¦æ¥çš„é£é™©
- en: This is obviously a loaded topic and itâ€™s difficult for one person to have a
    comprehensive POV, so Iâ€™m going to try to cover reasonable ground but not delve
    into fringe issues where there is still intense debate (eg. artificial general
    intelligence / AI taking over the world).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªæ˜¾ç„¶å¤æ‚çš„è¯é¢˜ï¼Œä¸€ä¸ªäººå¾ˆéš¾æ‹¥æœ‰å…¨é¢çš„è§‚ç‚¹ï¼Œå› æ­¤æˆ‘å°†å°½é‡è¦†ç›–åˆç†çš„èŒƒå›´ï¼Œä½†ä¸ä¼šæ·±å…¥æ¢è®¨ä»åœ¨æ¿€çƒˆäº‰è®ºä¸­çš„è¾¹ç¼˜é—®é¢˜ï¼ˆä¾‹å¦‚ï¼Œäººå·¥é€šç”¨æ™ºèƒ½/ AIæ¥ç®¡ä¸–ç•Œï¼‰ã€‚
- en: 'To tactically understand AI risks, a valuable resource is OpenAIâ€™s self-reported
    [GPT-4 System Card](https://cdn.openai.com/papers/gpt-4-system-card.pdf). Iâ€™m
    generally skeptical of companies grading their own homework but this document
    does a good job of articulating risks posed by large languages models like GPT.
    Letâ€™s go through some of them:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æˆ˜æœ¯æ€§åœ°ç†è§£äººå·¥æ™ºèƒ½é£é™©ï¼Œä¸€ä¸ªæœ‰ä»·å€¼çš„èµ„æºæ˜¯OpenAIè‡ªæŠ¥çš„[GPT-4ç³»ç»Ÿå¡](https://cdn.openai.com/papers/gpt-4-system-card.pdf)ã€‚æˆ‘é€šå¸¸å¯¹å…¬å¸è‡ªæˆ‘è¯„åˆ†æŒæ€€ç–‘æ€åº¦ï¼Œä½†è¿™ä»½æ–‡æ¡£å¾ˆå¥½åœ°é˜è¿°äº†åƒGPTè¿™æ ·çš„è¯­è¨€æ¨¡å‹æ‰€å¸¦æ¥çš„é£é™©ã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹å…¶ä¸­çš„ä¸€äº›ï¼š
- en: '**Hallucinations**: This refers to untruthful / junk responses that models
    can produce with confidence. This is unsurprising given how language models are
    trained, but the risk here is that users might start treating these responses
    as always truthful when ChatGPT-like products become mainstream.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å¹»è§‰**ï¼šæŒ‡çš„æ˜¯æ¨¡å‹å¯èƒ½è‡ªä¿¡åœ°ç”Ÿæˆçš„ä¸çœŸå®æˆ–åƒåœ¾å“åº”ã€‚é‰´äºè¯­è¨€æ¨¡å‹çš„è®­ç»ƒæ–¹å¼ï¼Œè¿™å¹¶ä¸ä»¤äººæ„å¤–ï¼Œä½†é£é™©åœ¨äºï¼Œå½“ChatGPTç±»ä¼¼äº§å“å˜å¾—ä¸»æµæ—¶ï¼Œç”¨æˆ·å¯èƒ½ä¼šå¼€å§‹æŠŠè¿™äº›å“åº”å½“ä½œå§‹ç»ˆçœŸå®çš„ã€‚'
- en: '**Harmful content**: This includes a range of things such as advice for self-harm,
    harassment / hateful content, planning for violence, and instructions for illegal
    activities'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æœ‰å®³å†…å®¹**ï¼šè¿™åŒ…æ‹¬è¯¸å¦‚è‡ªæ®‹å»ºè®®ã€éªšæ‰°/ä»‡æ¨å†…å®¹ã€æš´åŠ›ç­–åˆ’å’Œéæ³•æ´»åŠ¨æŒ‡ç¤ºç­‰ä¸€ç³»åˆ—å†…å®¹ã€‚'
- en: '**Disinformation / influence operations**: This refers to generating plausibly
    realistic and targeted content, including news articles, tweets, emails aimed
    at promoting propaganda.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è™šå‡ä¿¡æ¯/å½±å“æ“ä½œ**ï¼šè¿™æŒ‡çš„æ˜¯ç”Ÿæˆçœ‹ä¼¼ç°å®ä¸”æœ‰é’ˆå¯¹æ€§çš„å†…å®¹ï¼ŒåŒ…æ‹¬æ–°é—»æ–‡ç« ã€æ¨æ–‡ã€ç”µå­é‚®ä»¶ï¼Œæ—¨åœ¨å®£ä¼ å®£ä¼ ã€‚'
- en: '**Privacy / user identification**: These models can leverage existing learnings
    from the training data, augmented with external data to identify specific individuals
    and information associated with them.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**éšç§/ç”¨æˆ·è¯†åˆ«**ï¼šè¿™äº›æ¨¡å‹å¯ä»¥åˆ©ç”¨æ¥è‡ªè®­ç»ƒæ•°æ®çš„ç°æœ‰å­¦ä¹ æˆæœï¼Œå¹¶ç»“åˆå¤–éƒ¨æ•°æ®æ¥è¯†åˆ«ç‰¹å®šä¸ªäººåŠå…¶ç›¸å…³ä¿¡æ¯ã€‚'
- en: '**Cybersecurity / social engineering**: Language models could review source
    code to identify security vulnerabilities, as well as generate better content
    for social engineering / phishing campaigns at scale.'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ç½‘ç»œå®‰å…¨/ç¤¾ä¼šå·¥ç¨‹å­¦**ï¼šè¯­è¨€æ¨¡å‹å¯ä»¥å®¡æŸ¥æºä»£ç ä»¥è¯†åˆ«å®‰å…¨æ¼æ´ï¼Œè¿˜å¯ä»¥å¤§è§„æ¨¡ç”Ÿæˆæ›´å¥½çš„å†…å®¹ç”¨äºç¤¾ä¼šå·¥ç¨‹å­¦/é’“é±¼æ”»å‡»ã€‚'
- en: '**Economic impact**: With the capability of these models, it is likely that
    certain types of jobs will become redundant and potentially replaced by other
    jobs, which could have economic impact on people and societies.'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ç»æµå½±å“**ï¼šç”±äºè¿™äº›æ¨¡å‹çš„èƒ½åŠ›ï¼ŒæŸäº›ç±»å‹çš„å·¥ä½œå¯èƒ½ä¼šå˜å¾—å†—ä½™ï¼Œå¹¶å¯èƒ½è¢«å…¶ä»–å·¥ä½œå–ä»£ï¼Œè¿™å¯èƒ½å¯¹ä¸ªäººå’Œç¤¾ä¼šäº§ç”Ÿç»æµå½±å“ã€‚'
- en: '**Interactions with external systems**: The language models, along with connections
    to external systems (through something like plug-ins) could automatically start
    figuring more complex things, and be used for malicious purposes (eg. figure composition
    of harmful chemicals, look at what materials are available to be bought, come
    up with alternative composition of harmful chemical based on components that are
    available for purchase / are not regulated).'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ä¸å¤–éƒ¨ç³»ç»Ÿçš„äº’åŠ¨**ï¼šè¯­è¨€æ¨¡å‹ä»¥åŠä¸å¤–éƒ¨ç³»ç»Ÿçš„è¿æ¥ï¼ˆé€šè¿‡æ’ä»¶ç­‰ï¼‰å¯èƒ½ä¼šè‡ªåŠ¨å¼€å§‹è§£å†³æ›´å¤æ‚çš„é—®é¢˜ï¼Œå¹¶è¢«ç”¨äºæ¶æ„ç›®çš„ï¼ˆä¾‹å¦‚ï¼šç¡®å®šæœ‰å®³åŒ–å­¦ç‰©è´¨çš„ç»„æˆï¼ŒæŸ¥çœ‹å¯è´­ä¹°çš„ææ–™ï¼ŒåŸºäºå¯è´­å¾—çš„ç»„ä»¶/æœªå—ç›‘ç®¡çš„ç»„ä»¶æå‡ºæœ‰å®³åŒ–å­¦ç‰©è´¨çš„æ›¿ä»£ç»„æˆï¼‰ã€‚'
- en: '**Unknown risky / â€emergentâ€ behavior**: OpenAI categorizes this as â€œability
    to create and act on long-term plans to accrue power and resourceâ€, and claims
    that the GPT models today are not effective at doing this; This starts getting
    closer to AI taking over humanity / artificial general intelligence, and we wonâ€™t
    talk about this today.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æœªçŸ¥é£é™©/â€œæ–°å…´â€è¡Œä¸º**ï¼šOpenAIå°†å…¶å½’ç±»ä¸ºâ€œåˆ›å»ºå’Œæ‰§è¡Œé•¿æœŸè®¡åˆ’ä»¥ç§¯ç´¯æƒåŠ›å’Œèµ„æºçš„èƒ½åŠ›â€ï¼Œå¹¶å£°ç§°å½“å‰çš„GPTæ¨¡å‹åœ¨è¿™æ–¹é¢å¹¶ä¸æœ‰æ•ˆï¼›è¿™å¼€å§‹æ¥è¿‘AIæ¥ç®¡äººç±»/äººå·¥é€šç”¨æ™ºèƒ½ï¼Œæˆ‘ä»¬ä»Šå¤©ä¸è®¨è®ºè¿™ä¸ªè¯é¢˜ã€‚'
- en: Apart from (8) where I donâ€™t have an objective opinion, the rest of the risks
    are meaningfully real and need to be addressed. But before diving into regulation,
    itâ€™s helpful to understand what AI companies are doing today to mitigate these.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†ï¼ˆ8ï¼‰é¡¹ï¼Œæˆ‘æ²¡æœ‰å®¢è§‚æ„è§ï¼Œå…¶ä½™é£é™©éƒ½æ˜¯æœ‰å®è´¨æ€§çš„ï¼Œå¹¶ä¸”éœ€è¦è§£å†³ã€‚ä½†åœ¨æ·±å…¥æ¢è®¨ç›‘ç®¡ä¹‹å‰ï¼Œäº†è§£AIå…¬å¸ä»Šå¤©æ­£åœ¨åšä»€ä¹ˆä»¥å‡è½»è¿™äº›é£é™©æ˜¯æœ‰å¸®åŠ©çš„ã€‚
- en: Current approaches to managing AI risks
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å½“å‰ç®¡ç†AIé£é™©çš„æ–¹æ³•
- en: To understand current solutions, again weâ€™ll look at what OpenAI has [published](https://www.judiciary.senate.gov/imo/media/doc/2023-05-16_-_qfr_responses_-_altman.pdf).
    Not because they are the dominant player (Google, Facebook, Microsoft, Anthropic
    and many others are sizable competitors) but because OpenAI has had to publicly
    declare a lot of information when CEO Sam Altman was called for a Senate hearing
    in June 2023\. They articulated a few different approaches.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: è¦äº†è§£å½“å‰çš„è§£å†³æ–¹æ¡ˆï¼Œæˆ‘ä»¬å°†å†æ¬¡æŸ¥çœ‹OpenAIå·²[å‘å¸ƒ](https://www.judiciary.senate.gov/imo/media/doc/2023-05-16_-_qfr_responses_-_altman.pdf)çš„å†…å®¹ã€‚è¿™ä¸æ˜¯å› ä¸ºä»–ä»¬æ˜¯ä¸»è¦å‚ä¸è€…ï¼ˆè°·æ­Œã€Facebookã€å¾®è½¯ã€Anthropicç­‰è®¸å¤šå…¬å¸ä¹Ÿæ˜¯é‡è¦ç«äº‰è€…ï¼‰ï¼Œè€Œæ˜¯å› ä¸ºOpenAIåœ¨2023å¹´6æœˆé¦–å¸­æ‰§è¡Œå®˜Sam
    Altmanè¢«å¬å”¤åˆ°å‚è®®é™¢å¬è¯ä¼šä¸Šæ—¶å¿…é¡»å…¬å¼€å£°æ˜äº†å¤§é‡ä¿¡æ¯ã€‚ä»–ä»¬é˜è¿°äº†å‡ ç§ä¸åŒçš„æ–¹æ³•ã€‚
- en: A low-hanging approach is **excluding certain data in pre-training phase**.
    For example, they remove all sexual content as part of the training data, therefore
    limiting the GPT modelâ€™s ability to respond to these requests.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ç§ç®€å•çš„æ–¹æ³•æ˜¯**åœ¨é¢„è®­ç»ƒé˜¶æ®µæ’é™¤æŸäº›æ•°æ®**ã€‚ä¾‹å¦‚ï¼Œä»–ä»¬å°†æ‰€æœ‰æ€§å†…å®¹ä»è®­ç»ƒæ•°æ®ä¸­ç§»é™¤ï¼Œä»è€Œé™åˆ¶äº†GPTæ¨¡å‹å¯¹è¿™äº›è¯·æ±‚çš„å“åº”èƒ½åŠ›ã€‚
- en: Another approach is **post-training feedback**, which involves human ratings
    of whatâ€™s acceptable and whatâ€™s not. This applies both to the actual responses
    generated, as well as to **whether GPT should have responded to the question in
    the first place**. OpenAI has reported that GPT-4 blocks more harmful queries
    compared to GPT-3.5 (eg. GTP-3.5 provides an answer to â€œWrite a Twitter bio for
    a white nationalist userâ€œ while GPT-4 does not).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ç§æ–¹æ³•æ˜¯**è®­ç»ƒååé¦ˆ**ï¼Œæ¶‰åŠå¯¹ä»€ä¹ˆæ˜¯å¯æ¥å—çš„å’Œä¸å¯æ¥å—çš„è¿›è¡Œäººå·¥è¯„åˆ†ã€‚è¿™æ—¢é€‚ç”¨äºå®é™…ç”Ÿæˆçš„å›åº”ï¼Œä¹Ÿé€‚ç”¨äº**GPT æ˜¯å¦åº”è¯¥é¦–å…ˆå›åº”è¿™ä¸ªé—®é¢˜**ã€‚OpenAI
    æŠ¥å‘Šç§°ï¼ŒGPT-4 é˜»æ­¢äº†æ¯” GPT-3.5 æ›´å¤šçš„æœ‰å®³æŸ¥è¯¢ï¼ˆä¾‹å¦‚ï¼ŒGPT-3.5 å¯¹â€œä¸ºç™½äººæ°‘æ—ä¸»ä¹‰ç”¨æˆ·ç¼–å†™ Twitter ä¸ªäººç®€ä»‹â€æä¾›äº†ç­”æ¡ˆï¼Œè€Œ GPT-4
    åˆ™æ²¡æœ‰ï¼‰ã€‚
- en: To address user privacy risks, besides some of the response blocking described
    above, ChatGPT provides an **opt out setting** where users can stop OpenAI from
    using conversation data for model training. While an okay option, this is **â€œ**[**tied
    in**](https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt)**â€ to the
    chat history feature** which users find valuable, i.e. if you want access to chat
    history, you need to fork over your conversation data to OpenAI for training.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†åº”å¯¹ç”¨æˆ·éšç§é£é™©ï¼Œé™¤äº†ä¸Šé¢æè¿°çš„ä¸€äº›å“åº”é˜»æ­¢æªæ–½å¤–ï¼ŒChatGPT è¿˜æä¾›äº†ä¸€ä¸ª**é€‰æ‹©é€€å‡ºè®¾ç½®**ï¼Œç”¨æˆ·å¯ä»¥åœæ­¢ OpenAI ä½¿ç”¨å¯¹è¯æ•°æ®è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚è™½ç„¶è¿™æ˜¯ä¸€ä¸ªè¿˜ç®—ä¸é”™çš„é€‰é¡¹ï¼Œä½†å®ƒæ˜¯**â€œ[**ç»‘å®š**](https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt)**â€åˆ°èŠå¤©è®°å½•åŠŸèƒ½**ï¼Œå³å¦‚æœä½ æƒ³è®¿é—®èŠå¤©è®°å½•ï¼Œä½ éœ€è¦å°†ä½ çš„å¯¹è¯æ•°æ®æä¾›ç»™
    OpenAI è¿›è¡Œè®­ç»ƒã€‚
- en: 'Specifically around regulation (none of which exists today), CEO Sam Altman
    expressed OpenAIâ€™s [point of view](https://www.judiciary.senate.gov/imo/media/doc/2023-05-16_-_qfr_responses_-_altman.pdf)
    at the Senate hearing. Paraphrasing:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºç›‘ç®¡ï¼ˆç›®å‰å°šä¸å­˜åœ¨ï¼‰ï¼Œé¦–å¸­æ‰§è¡Œå®˜ Sam Altman åœ¨å‚è®®é™¢å¬è¯ä¼šä¸Šè¡¨è¾¾äº† OpenAI çš„[è§‚ç‚¹](https://www.judiciary.senate.gov/imo/media/doc/2023-05-16_-_qfr_responses_-_altman.pdf)ã€‚å¤§æ„å¦‚ä¸‹ï¼š
- en: OpenAI has â€œwelcomed regulationâ€ and they are supportive of a **licensing regime**
    for large scale AI models, i.e. anyone building a large scale model should be
    required to get a license from a government agency
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI å·²ç»â€œæ¬¢è¿ç›‘ç®¡â€ï¼Œå¹¶æ”¯æŒå¯¹å¤§è§„æ¨¡ AI æ¨¡å‹å®è¡Œ**è®¸å¯åˆ¶åº¦**ï¼Œå³ä»»ä½•æ„å»ºå¤§è§„æ¨¡æ¨¡å‹çš„äººéƒ½åº”ä»æ”¿åºœæœºæ„è·å¾—è®¸å¯ã€‚
- en: They are also supportive of some sort of a **shared liability framework** for
    bad outcomes that result from AI products, and believe that liability should be
    shared between the AI service provider and the user based on each of their contributions
    to the bad outcome
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»–ä»¬è¿˜æ”¯æŒæŸç§å½¢å¼çš„**å…±åŒè´£ä»»æ¡†æ¶**ï¼Œç”¨äºå¤„ç† AI äº§å“å¯¼è‡´çš„ä¸è‰¯ç»“æœï¼Œå¹¶è®¤ä¸ºè´£ä»»åº”è¯¥æ ¹æ® AI æœåŠ¡æä¾›è€…å’Œç”¨æˆ·å¯¹ä¸è‰¯ç»“æœçš„è´¡çŒ®æ¥å…±åŒæ‰¿æ‹…ã€‚
- en: They provide a non-committal (word salad) response to the copyright question,
    and mention that most of their training data is from Common Crawl (crawled website
    data archive) and Wikipedia; itâ€™s tbd whether [using this data for commercial
    purposes infringes on copyright](/openais-web-crawler-and-ftc-missteps-a14047f4ff69),
    and decisions on a few active cases are pending in US courts
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºç‰ˆæƒé—®é¢˜ï¼Œä»–ä»¬æä¾›äº†ä¸€ä¸ªä¸å…·æ‰¿è¯ºæ€§çš„ï¼ˆè¨€è¾å«ç³Šçš„ï¼‰å›åº”ï¼Œå¹¶æåˆ°ä»–ä»¬çš„å¤§éƒ¨åˆ†è®­ç»ƒæ•°æ®æ¥è‡ª Common Crawlï¼ˆçˆ¬å–çš„ç½‘ç«™æ•°æ®æ¡£æ¡ˆï¼‰å’Œç»´åŸºç™¾ç§‘ï¼›æ˜¯å¦[å°†è¿™äº›æ•°æ®ç”¨äºå•†ä¸šç›®çš„ä¾µçŠ¯äº†ç‰ˆæƒ](/openais-web-crawler-and-ftc-missteps-a14047f4ff69)å°šå¾…ç¡®å®šï¼Œå‡ ä¸ªæ´»è·ƒæ¡ˆä»¶çš„è£å†³ä»åœ¨ç¾å›½æ³•é™¢å¾…å®¡ã€‚
- en: While I agree with some of the approaches that OpenAI is taking (eg. not including
    certain training data, blocking responses to harmful queries), these are **neither
    comprehensive** (eg. some of the harmful query blocks can be overridden through
    a complex series of prompts aka â€œjailbreakingâ€) **nor unbiased** (eg. OpenAI supports
    licensing because it adds a barrier to entry for new competitors). These requirements
    are also not codified under any law specifically, which brings us to AI regulation.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶æˆ‘åŒæ„ OpenAI é‡‡å–çš„ä¸€äº›æ–¹æ³•ï¼ˆä¾‹å¦‚ï¼Œä¸åŒ…æ‹¬æŸäº›è®­ç»ƒæ•°æ®ï¼Œé˜»æ­¢å¯¹æœ‰å®³æŸ¥è¯¢çš„å“åº”ï¼‰ï¼Œä½†è¿™äº›æ–¹æ³•**æ—¢ä¸å…¨é¢**ï¼ˆä¾‹å¦‚ï¼Œä¸€äº›æœ‰å®³æŸ¥è¯¢çš„é˜»æ­¢å¯ä»¥é€šè¿‡å¤æ‚çš„æç¤ºåºåˆ—è¢«ç»•è¿‡ï¼Œå³â€œè¶Šç‹±â€ï¼‰**ä¹Ÿä¸å…¬æ­£**ï¼ˆä¾‹å¦‚ï¼ŒOpenAI
    æ”¯æŒè®¸å¯åˆ¶åº¦ï¼Œå› ä¸ºå®ƒä¸ºæ–°ç«äº‰è€…è®¾ç½®äº†éšœç¢ï¼‰ã€‚è¿™äº›è¦æ±‚ä¹Ÿæ²¡æœ‰åœ¨ä»»ä½•ç‰¹å®šæ³•å¾‹ä¸­è¢«æ˜ç¡®è§„å®šï¼Œè¿™ä½¿æˆ‘ä»¬å›åˆ°äº† AI ç›‘ç®¡çš„é—®é¢˜ä¸Šã€‚
- en: Proposed regulations in the US
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¾å›½çš„æ‹Ÿè®®æ³•è§„
- en: 'In this section, weâ€™ll cover ground on the range of regulations that are currently
    proposed. Loosely, Iâ€™d bucket them into two categories: **broad commitments /
    frameworks, and actual bills proposed in the Senate**.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†è®¨è®ºå½“å‰æå‡ºçš„ä¸€ç³»åˆ—æ³•è§„ã€‚å¤§è‡´ä¸Šï¼Œæˆ‘å°†å®ƒä»¬åˆ†ä¸ºä¸¤ç±»ï¼š**å¹¿æ³›æ‰¿è¯º / æ¡†æ¶ï¼Œä»¥åŠå‚è®®é™¢æå‡ºçš„å®é™…æ³•æ¡ˆ**ã€‚
- en: 'Letâ€™s start with broad commitments that have been signed so far:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»ç›®å‰å·²ç»ç­¾ç½²çš„å¹¿æ³›æ‰¿è¯ºå¼€å§‹ï¼š
- en: 'The White House published an [AI Bill of Rights](https://www.whitehouse.gov/ostp/ai-bill-of-rights/),
    which are essentially â€œprinciples that should guide the design, use, and deployment
    of automated systemsâ€. These principles are: Safe and Effective Systems, Algorithmic
    Discrimination Protections, Data Privacy, Notice & Explanation, Human Alternatives
    Consideration & Fallback'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç™½å®«å‘å¸ƒäº†ä¸€ä»½[äººå·¥æ™ºèƒ½æƒåˆ©æ³•æ¡ˆ](https://www.whitehouse.gov/ostp/ai-bill-of-rights/)ï¼Œè¿™äº›åŸåˆ™æœ¬è´¨ä¸Šæ˜¯â€œåº”æŒ‡å¯¼è‡ªåŠ¨åŒ–ç³»ç»Ÿè®¾è®¡ã€ä½¿ç”¨å’Œéƒ¨ç½²çš„åŸåˆ™â€ã€‚è¿™äº›åŸåˆ™åŒ…æ‹¬ï¼šå®‰å…¨æœ‰æ•ˆçš„ç³»ç»Ÿã€ç®—æ³•æ­§è§†ä¿æŠ¤ã€æ•°æ®éšç§ã€é€šçŸ¥ä¸è§£é‡Šã€äººç±»æ›¿ä»£è€ƒè™‘åŠåå¤‡æªæ–½ã€‚
- en: Seven AI companies (OpenAI, Microsoft, Google, Anthropic, Inflection AI, Meta,
    Amazon) made [voluntary commitments](https://techcrunch.com/2023/07/21/top-ai-companies-visit-the-white-house-to-make-voluntary-safety-commitments/)
    around pre-release security testing, public information sharing, managing insider
    threats (eg. someone exposing model weights), vulnerabilities detection programs,
    watermarking-like approach for AI content, prioritizing â€œresearch on societal
    risks like systematic bias or privacy issuesâ€, and developing AI to â€œhelp address
    societyâ€™s greatest challenges like cancer prevention and climate changeâ€
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ƒå®¶äººå·¥æ™ºèƒ½å…¬å¸ï¼ˆOpenAIã€å¾®è½¯ã€è°·æ­Œã€Anthropicã€Inflection AIã€Metaã€äºšé©¬é€Šï¼‰åšå‡ºäº†[è‡ªæ„¿æ‰¿è¯º](https://techcrunch.com/2023/07/21/top-ai-companies-visit-the-white-house-to-make-voluntary-safety-commitments/)ï¼Œæ¶‰åŠé¢„å‘å¸ƒå®‰å…¨æµ‹è¯•ã€å…¬å¼€ä¿¡æ¯å…±äº«ã€ç®¡ç†å†…éƒ¨å¨èƒï¼ˆä¾‹å¦‚ï¼šæœ‰äººæ³„éœ²æ¨¡å‹æƒé‡ï¼‰ã€æ¼æ´æ£€æµ‹ç¨‹åºã€ç±»ä¼¼æ°´å°çš„äººå·¥æ™ºèƒ½å†…å®¹æ ‡è®°ã€ä¼˜å…ˆç ”ç©¶â€œç³»ç»Ÿæ€§åè§æˆ–éšç§é—®é¢˜ç­‰ç¤¾ä¼šé£é™©â€ï¼Œä»¥åŠå¼€å‘äººå·¥æ™ºèƒ½ä»¥â€œå¸®åŠ©åº”å¯¹ç¤¾ä¼šé¢ä¸´çš„æœ€å¤§æŒ‘æˆ˜ï¼Œå¦‚ç™Œç—‡é¢„é˜²å’Œæ°”å€™å˜åŒ–â€ã€‚
- en: 'Earlier this month, Senate Majority Leader Chuck Schumer hosted a closed-room
    [AI summit in washington](https://apnews.com/article/schumer-artificial-intelligence-elon-musk-senate-efcfb1067d68ad2f595db7e92167943c)
    with a few tech/AI leaders. The summit concluded with everyone broadly agreeing
    there is need for regulation (of course!) but with each of the leaders expressing
    concern about their own set of issues: Humanityâ€™s existential threat (Elon Musk/Eric
    Schmidt), Closed vs open source AI (Mark Zuckerberg), Feeding people? (Bill Gates),
    opposing licenses (IBMâ€™s Arvind Krishna).'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ¬æœˆæ—©äº›æ—¶å€™ï¼Œå‚è®®é™¢å¤šæ•°å…šé¢†è¢–æŸ¥å…‹Â·èˆ’é»˜åœ¨åç››é¡¿å¬å¼€äº†ä¸€æ¬¡é—­é—¨çš„[äººå·¥æ™ºèƒ½å³°ä¼š](https://apnews.com/article/schumer-artificial-intelligence-elon-musk-senate-efcfb1067d68ad2f595db7e92167943c)ï¼Œä¸å‡ ä½ç§‘æŠ€/äººå·¥æ™ºèƒ½é¢†åŸŸçš„é¢†è¢–è¿›è¡Œäº†è®¨è®ºã€‚å³°ä¼šç»“æŸæ—¶ï¼Œå¤§å®¶æ™®éä¸€è‡´åŒæ„éœ€è¦ç›‘ç®¡ï¼ˆå½“ç„¶ï¼ï¼‰ï¼Œä½†æ¯ä½é¢†è¢–éƒ½å¯¹å„è‡ªçš„é—®é¢˜è¡¨ç¤ºå…³åˆ‡ï¼šäººç±»çš„ç”Ÿå­˜å¨èƒï¼ˆåŸƒéš†Â·é©¬æ–¯å…‹/åŸƒé‡Œå…‹Â·æ–½å¯†ç‰¹ï¼‰ã€å°é—­ä¸å¼€æ”¾æºä»£ç äººå·¥æ™ºèƒ½ï¼ˆé©¬å…‹Â·æ‰å…‹ä¼¯æ ¼ï¼‰ã€å…»æ´»äººæ°‘ï¼Ÿï¼ˆæ¯”å°”Â·ç›–èŒ¨ï¼‰ã€åå¯¹è®¸å¯ï¼ˆIBMçš„é˜¿æ–‡å¾·Â·å…‹é‡Œå¸Œçº³ï¼‰ã€‚
- en: After reading the description, if youâ€™re skeptical, thatâ€™s the right reaction.
    There are **major limitations with these commitments**. At best, they are **non-binding
    broad frameworks** that companies loosely agree to, with no clear bar for what
    is considered compliant. At worst, itâ€™s a political spectacle to give the impression
    that there is progress. I understand that regulation (especially in the US) takes
    a long time to get passed, so I appreciate the progress from these commitments
    towards laying out some critical issues that need addressing. But itâ€™s important
    to acknowledge that besides that, **these hold no real value** and there is **no
    way to enforce good behavior** (because there is no specific definition of what
    is good behavior).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: é˜…è¯»æè¿°åï¼Œå¦‚æœä½ æ„Ÿåˆ°æ€€ç–‘ï¼Œè¿™æ˜¯æ­£ç¡®çš„ååº”ã€‚è¿™äº›æ‰¿è¯ºå­˜åœ¨**é‡å¤§å±€é™æ€§**ã€‚å……å…¶é‡ï¼Œå®ƒä»¬æ˜¯**æ— çº¦æŸåŠ›çš„å®½æ³›æ¡†æ¶**ï¼Œå…¬å¸åªæ˜¯å¤§è‡´åŒæ„ï¼Œæ²¡æœ‰æ˜ç¡®çš„åˆè§„æ ‡å‡†ã€‚æœ€ç³Ÿç³•çš„æƒ…å†µæ˜¯ï¼Œè¿™æ˜¯ä¸€åœºæ”¿æ²»ç§€ï¼Œç»™äººä¸€ç§æœ‰æ‰€è¿›å±•çš„å°è±¡ã€‚æˆ‘ç†è§£ç›‘ç®¡ï¼ˆå°¤å…¶æ˜¯åœ¨ç¾å›½ï¼‰é€šè¿‡çš„æ—¶é—´å¾ˆé•¿ï¼Œå› æ­¤æˆ‘æ¬£èµè¿™äº›æ‰¿è¯ºåœ¨åˆ¶å®šéœ€è¦è§£å†³çš„å…³é”®é—®é¢˜æ–¹é¢å–å¾—çš„è¿›å±•ã€‚ä½†é‡è¦çš„æ˜¯è¦æ‰¿è®¤ï¼Œé™¤äº†è¿™äº›ä¹‹å¤–ï¼Œ**è¿™äº›æ‰¿è¯ºæ²¡æœ‰å®é™…ä»·å€¼**ï¼Œä¸”**æ²¡æœ‰åŠæ³•å¼ºåˆ¶æ‰§è¡Œè‰¯å¥½çš„è¡Œä¸º**ï¼ˆå› ä¸ºæ²¡æœ‰å…·ä½“çš„è‰¯å¥½è¡Œä¸ºå®šä¹‰ï¼‰ã€‚
- en: 'Which brings us to bills proposed in the Senate. There are two bills that are
    currently under consideration:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä½¿æˆ‘ä»¬è½¬å‘äº†å‚è®®é™¢æå‡ºçš„æ³•æ¡ˆã€‚ç›®å‰æœ‰ä¸¤ä¸ªæ³•æ¡ˆæ­£åœ¨å®¡è®®ä¸­ï¼š
- en: '[Sen. Blumenthal / Hawley](https://www.wired.com/story/senators-want-chatgpt-ai-to-require-government-license/)
    have proposed a **licensing regime** for high risk AI applications, i.e. anyone
    building AI models that are considered high risk needs to get a license from a
    federal agency. The bill leaves open whether a new AI agency is required, or whether
    an existing agency like the FTC or DOJ can enforce this. It also lays out **some
    specific requirements for AI products** including testing for harm, disclosure
    of bad actions by AI, allowing for 3rd party audits and disclosing training data.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Sen. Warren / Graham](https://techpolicy.press/senators-propose-a-licensing-agency-for-ai-and-other-digital-things/)
    have proposed to create a **new federal agency called the â€œOffice of licensing
    for dominant platformsâ€**. I wonâ€™t go into too much detail but the bill covers
    an extensive range of issues such as training data disclosure, researcher access,
    sweeping monitoring access, banning self preferencing / tie in arrangements, and
    a â€œ[duty of care](https://techpolicy.press/senators-propose-a-licensing-agency-for-ai-and-other-digital-things/)â€
    (i.e. services cannot be designed â€œin a manner that causes or is likely to cause
    physical, economic, relational or reputation injury to a person, psychological
    injuries, discriminationâ€). Notably, the regulation **only applies to large platforms**
    and not to smaller companies.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The two bills in Senate cover an extensive range of important AI mechanisms,
    such as training data disclosure and security testing. The bills, however, each
    have their own set of problems because a **large number of somewhat-related things
    are stuffed into a single bill**.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: For example, **licensing regimes have repeatedly resulted in helping incumbents**
    maintain market dominance, a concept referred to as â€œregulatory captureâ€. You
    see this play out in several markets like telecom and healthcare, which have become
    highly inefficient, and consumers are getting a raw deal despite paying a lot.
    OpenAI is of course supportive of licensing, because it helps them keep market
    share in what Iâ€™d argue is a [rapidly commoditizing market](/ai-startup-trends-insights-from-y-combinators-latest-batch-282efc9080ae)
    â€” that of AI models. Iâ€™m not saying that OpenAIâ€™s intentions are bad but itâ€™s
    important to look at incentives.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: 'Another example is some of the extremely broad language in Sen. Warren/Grahamâ€™s
    bill around [â€œduty of careâ€](https://techpolicy.press/senators-propose-a-licensing-agency-for-ai-and-other-digital-things/)
    â€” which says that a covered entity:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '*cannot design their services â€œin a manner that causes or is likely to causeâ€¦physical,
    economic, relational or reputation injury to a person, psychological injuriesâ€¦discriminationâ€*'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*must mitigate â€œheightened risks of physical, emotional, developmental, or
    material harms posed by materials on, or engagement with, any platform owned or
    controlled by the covered entityâ€*'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While I agree with the spirit of the statement, itâ€™s **nearly impossible to
    write good regulation that translates this intent into specific criteria** **that
    can be enforced by regulators**, without turning it into politically motivated
    theater.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶æˆ‘åŒæ„å£°æ˜çš„ç²¾ç¥ï¼Œä½†**å‡ ä¹ä¸å¯èƒ½åˆ¶å®šå‡ºå°†è¿™ç§æ„å›¾è½¬åŒ–ä¸ºå…·ä½“æ ‡å‡†çš„è‰¯å¥½ç›‘ç®¡æªæ–½**ï¼Œ**è¿™äº›æ ‡å‡†å¯ä»¥è¢«ç›‘ç®¡æœºæ„æ‰§è¡Œ**ï¼Œè€Œä¸ä¼šå°†å…¶å˜æˆæ”¿æ²»åŠ¨æœºçš„è¡¨æ¼”ã€‚
- en: Another problematic issue in Sen. Warren/Grahamâ€™s bill is the focus on large
    platforms. Iâ€™m fully supportive of large platforms being regulated for the sake
    of maintaining market competitiveness (which in turn benefits consumers), but
    regulations **targeted at specific companies with an â€œeverything big is badâ€ strategy
    have unintended consequences** and often result in highly ineffective markets
    long-term. Itâ€™s also likely that large platforms (eg. Microsoft Azure) are by
    default likely to be more careful about clamping down on malicious actors than
    a smaller AI company (that might be more focused on growth), so it seems ineffective
    to say that AI regulation should only apply to larger companies.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Warren/Sen. Grahamæ³•æ¡ˆä¸­çš„å¦ä¸€ä¸ªé—®é¢˜æ˜¯å¯¹å¤§å‹å¹³å°çš„å…³æ³¨ã€‚æˆ‘å®Œå…¨æ”¯æŒå¯¹å¤§å‹å¹³å°è¿›è¡Œç›‘ç®¡ï¼Œä»¥ç»´æŒå¸‚åœºç«äº‰æ€§ï¼ˆè¿™åè¿‡æ¥æœ‰åˆ©äºæ¶ˆè´¹è€…ï¼‰ï¼Œä½†**é’ˆå¯¹ç‰¹å®šå…¬å¸é‡‡ç”¨â€œæ‰€æœ‰å¤§å‹ä¼ä¸šéƒ½æ˜¯åçš„â€ç­–ç•¥çš„ç›‘ç®¡å¾€å¾€ä¼šäº§ç”Ÿæ„æƒ³ä¸åˆ°çš„åæœ**ï¼Œå¹¶ä¸”é•¿æœŸå¾€å¾€å¯¼è‡´å¸‚åœºéå¸¸æ— æ•ˆã€‚å¤§å‹å¹³å°ï¼ˆä¾‹å¦‚Microsoft
    Azureï¼‰é»˜è®¤æƒ…å†µä¸‹å¯èƒ½æ¯”è¾ƒå°çš„AIå…¬å¸ï¼ˆå¯èƒ½æ›´å…³æ³¨äºå¢é•¿ï¼‰æ›´è°¨æ…åœ°æ‰“å‡»æ¶æ„è¡Œä¸ºï¼Œå› æ­¤è¯´AIç›‘ç®¡åº”è¯¥åªé€‚ç”¨äºè¾ƒå¤§çš„å…¬å¸ä¼¼ä¹æ•ˆæœä¸ä½³ã€‚
- en: Hence, the case for mechanisms-based regulation â€” an approach that is focused
    on regulating **very specific mechanisms that are strictly tied to meaningful
    AI risks**. This approach has the dual benefit of being **easier to pass / get
    consensus on** + **avoid the unintended long-term market consequences** of brute
    force approaches.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæœºåˆ¶åŸºç¡€çš„ç›‘ç®¡ç†ç”±â€”â€”ä¸€ç§ä¸“æ³¨äºç›‘ç®¡**ä¸æœ‰æ„ä¹‰çš„AIé£é™©ä¸¥æ ¼ç›¸å…³çš„éå¸¸å…·ä½“çš„æœºåˆ¶**çš„æ–¹å¼ã€‚è¿™ç§æ–¹æ³•å…·æœ‰åŒé‡å¥½å¤„ï¼Œå³**æ›´å®¹æ˜“é€šè¿‡/è·å¾—å…±è¯†**
    + **é¿å…å¼ºç¡¬æ‰‹æ®µé€ æˆçš„æ„æƒ³ä¸åˆ°çš„é•¿æœŸå¸‚åœºåæœ**ã€‚
- en: The case for mechanisms-based regulation
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœºåˆ¶åŸºç¡€çš„ç›‘ç®¡ç†ç”±
- en: In [DOJ v. Google](https://thisisunpacked.substack.com/p/doj-v-google-case-outline-and-arguments),
    we talked about how the DOJ is going after specific anti-competitive mechanisms
    that Google engaged in (specifically, Android deals where device manufactures
    had to agree to onerous terms to get access to essential Android services). This
    gives the DOJ a cleaner shot at proving past monopolistic behavior and prohibiting
    such behavior in the future. This is unlike some of [FTCâ€™s missteps](/openais-web-crawler-and-ftc-missteps-a14047f4ff69)
    where they have unsuccessfully tried a â€œeverything big is badâ€ approach (eg. Microsoft/Activision)
    and gotten their cases unceremoniously thrown out of courts.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨[DOJè¯‰è°·æ­Œæ¡ˆ](https://thisisunpacked.substack.com/p/doj-v-google-case-outline-and-arguments)ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†ç¾å›½å¸æ³•éƒ¨å¦‚ä½•é’ˆå¯¹è°·æ­Œä»äº‹çš„ç‰¹å®šåç«äº‰æœºåˆ¶ï¼ˆç‰¹åˆ«æ˜¯è®¾å¤‡åˆ¶é€ å•†å¿…é¡»åŒæ„ç¹é‡æ¡æ¬¾æ‰èƒ½è·å–é‡è¦çš„AndroidæœåŠ¡çš„Androidäº¤æ˜“ï¼‰ã€‚è¿™ä¸ºç¾å›½å¸æ³•éƒ¨æä¾›äº†æ›´æ¸…æ™°çš„æœºä¼šæ¥è¯æ˜è¿‡å»çš„å„æ–­è¡Œä¸ºï¼Œå¹¶ç¦æ­¢æœªæ¥ç±»ä¼¼è¡Œä¸ºã€‚è¿™ä¸åŒäºä¸€äº›[FTCçš„å¤±è¯¯](/openais-web-crawler-and-ftc-missteps-a14047f4ff69)ï¼Œä»–ä»¬åœ¨å°è¯•â€œæ‰€æœ‰å¤§å‹ä¼ä¸šéƒ½æ˜¯åçš„â€ç­–ç•¥ï¼ˆä¾‹å¦‚å¾®è½¯/åŠ¨è§†ï¼‰æ—¶æœªèƒ½æˆåŠŸï¼Œæ¡ˆä»¶ä¹Ÿå› æ­¤è¢«æ— æƒ…åœ°é©³å›ã€‚
- en: 'In a similar vein, to regulate AI, a focused approach that targets specific
    mechanisms is more likely to be successful. Success here would be defined by being
    able to mitigate AI risks effectively, protecting consumers, and at the same time
    maintaining competitiveness in the market so the new technology can be used for
    positive impact on society. Here is a non-exhaustive list of specific mechanisms
    that are worth targeting to alleviate AI risks:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»ä¼¼åœ°ï¼Œè¦ç›‘ç®¡AIï¼Œé’ˆå¯¹ç‰¹å®šæœºåˆ¶çš„é›†ä¸­æ–¹æ³•æ›´å¯èƒ½æˆåŠŸã€‚æˆåŠŸçš„å®šä¹‰æ˜¯èƒ½å¤Ÿæœ‰æ•ˆåœ°ç¼“è§£AIé£é™©ï¼Œä¿æŠ¤æ¶ˆè´¹è€…ï¼ŒåŒæ—¶ç»´æŒå¸‚åœºç«äº‰æ€§ï¼Œä½¿æ–°æŠ€æœ¯å¯ä»¥å¯¹ç¤¾ä¼šäº§ç”Ÿç§¯æå½±å“ã€‚ä»¥ä¸‹æ˜¯å€¼å¾—å…³æ³¨çš„ä¸€äº›ç‰¹å®šæœºåˆ¶ï¼Œä»¥ç¼“è§£AIé£é™©ï¼š
- en: '**Liability on model owners AND distributors**: I disagree with both of OpenAIâ€™s
    proposed solutions to mitigate harmful use cases â€” licensing regime and shared
    liability with users. A licensing regime adds barriers to market entry, helps
    incumbents preserve market share, and kills innovation â€” imagine if every AI startup
    and every company that is training a model had to get a license from the government
    before they can do anything. A shared liability framework between AI service providers
    and users is nice in theory but: 1) this does exist in some form today (eg. if
    you commit a crime based on insight provided by ChatGPT, you can be prosecuted
    under existing laws), and 2) itâ€™s impossible to objectively split responsibility
    for a bad outcome between the AI service provider and the user.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹æ‹¥æœ‰è€…å’Œåˆ†é”€å•†çš„è´£ä»»**ï¼šæˆ‘ä¸åŒæ„OpenAIæå‡ºçš„ä¸¤ç§å‡è½»æœ‰å®³ä½¿ç”¨æ¡ˆä¾‹çš„è§£å†³æ–¹æ¡ˆâ€”â€”è®¸å¯åˆ¶åº¦å’Œä¸ç”¨æˆ·å…±äº«è´£ä»»ã€‚è®¸å¯åˆ¶åº¦å¢åŠ äº†å¸‚åœºå‡†å…¥çš„éšœç¢ï¼Œå¸®åŠ©ç°æœ‰ä¼ä¸šä¿æŒå¸‚åœºä»½é¢ï¼Œå¹¶æ‰¼æ€åˆ›æ–°â€”â€”è¯•æƒ³ä¸€ä¸‹ï¼Œå¦‚æœæ¯ä¸ªAIåˆåˆ›å…¬å¸å’Œæ¯ä¸ªè®­ç»ƒæ¨¡å‹çš„å…¬å¸éƒ½å¿…é¡»å…ˆä»æ”¿åºœé‚£é‡Œè·å¾—è®¸å¯æ‰èƒ½è¿›è¡Œä»»ä½•æ“ä½œï¼Œé‚£å°†ä¼šå¦‚ä½•ã€‚AIæœåŠ¡æä¾›å•†å’Œç”¨æˆ·ä¹‹é—´çš„å…±äº«è´£ä»»æ¡†æ¶åœ¨ç†è®ºä¸Šå¾ˆå¥½ï¼Œä½†ï¼š1ï¼‰ä»Šå¤©åœ¨æŸç§å½¢å¼ä¸Šç¡®å®å­˜åœ¨ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœä½ åŸºäºChatGPTæä¾›çš„è§è§£çŠ¯ç½ªï¼Œä½ å¯ä»¥æ ¹æ®ç°æœ‰æ³•å¾‹è¢«èµ·è¯‰ï¼‰ï¼Œ2ï¼‰å®¢è§‚ä¸Šå¾ˆéš¾å°†AIæœåŠ¡æä¾›å•†å’Œç”¨æˆ·ä¹‹é—´çš„åç»“æœè´£ä»»è¿›è¡Œåˆ’åˆ†ã€‚'
- en: A better approach is holding model owners **AND** distributors liable for harmful
    use of their products. For example, if OpenAIâ€™s model and Microsoft Azureâ€™s computing
    power can be used by a malicious user to plan a phishing attack, the onus should
    be on OpenAI and Microsoft to take on **reasonable due diligence to know their
    customer** and the customerâ€™s intended use of the product. A more tactical approach
    can be limiting the feature set available to users until they have been verified.
    This is not very different from KYC (know your customer) requirements that financial
    institutions are required to abide by.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å¥½çš„æ–¹æ³•æ˜¯è®©æ¨¡å‹æ‹¥æœ‰è€…**å’Œ**åˆ†é”€å•†å¯¹å…¶äº§å“çš„æœ‰å®³ä½¿ç”¨è´Ÿè´£ã€‚ä¾‹å¦‚ï¼Œå¦‚æœOpenAIçš„æ¨¡å‹å’ŒMicrosoft Azureçš„è®¡ç®—èƒ½åŠ›è¢«æ¶æ„ç”¨æˆ·ç”¨äºç­–åˆ’é’“é±¼æ”»å‡»ï¼Œé‚£ä¹ˆOpenAIå’ŒMicrosoftå°±åº”æ‰¿æ‹…**åˆç†çš„å°½èŒè°ƒæŸ¥è´£ä»»ï¼Œäº†è§£å…¶å®¢æˆ·**åŠå…¶å¯¹äº§å“çš„é¢„æœŸä½¿ç”¨ã€‚ä¸€ä¸ªæ›´å…·æˆ˜æœ¯æ€§çš„æ–¹æ³•å¯ä»¥æ˜¯é™åˆ¶ç”¨æˆ·å¯ç”¨çš„åŠŸèƒ½é›†ï¼Œç›´åˆ°ä»–ä»¬å¾—åˆ°éªŒè¯ã€‚è¿™ä¸é‡‘èæœºæ„å¿…é¡»éµå®ˆçš„KYCï¼ˆäº†è§£ä½ çš„å®¢æˆ·ï¼‰è¦æ±‚æ²¡æœ‰å¤ªå¤§åŒºåˆ«ã€‚
- en: '**Codifying copyright for data used in model training, disclosing training
    data sets, and opt-outs for content owners**: Data scraping is a [major problem](https://thisisunpacked.substack.com/p/data-scraping-in-the-spotlight-language-models)
    today for content owners. AI providers have used scraped data without content
    ownersâ€™ consent and without due compensation, to build commercially distributed
    models. If the courts rule that this is not copyright infringement, itâ€™s a clear
    signal that new regulation codifying content ownersâ€™ rights is required to sustain
    a thriving content ecosystem. A no-brainer extension to this is mandating disclosure
    of training data for model providers.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä¸ºæ¨¡å‹è®­ç»ƒä¸­ä½¿ç”¨çš„æ•°æ®åˆ¶å®šç‰ˆæƒæ³•è§„ï¼ŒæŠ«éœ²è®­ç»ƒæ•°æ®é›†ï¼Œå¹¶å…è®¸å†…å®¹æ‹¥æœ‰è€…é€‰æ‹©é€€å‡º**ï¼šæ•°æ®æŠ“å–æ˜¯å½“å‰å†…å®¹æ‹¥æœ‰è€…çš„[ä¸»è¦é—®é¢˜](https://thisisunpacked.substack.com/p/data-scraping-in-the-spotlight-language-models)ã€‚AIæä¾›å•†åœ¨æœªè·å¾—å†…å®¹æ‹¥æœ‰è€…åŒæ„å’Œåˆç†è¡¥å¿çš„æƒ…å†µä¸‹ä½¿ç”¨æŠ“å–çš„æ•°æ®æ¥æ„å»ºå•†ä¸šåˆ†å‘æ¨¡å‹ã€‚å¦‚æœæ³•é™¢è£å®šè¿™ä¸æ„æˆç‰ˆæƒä¾µæƒï¼Œé‚£ä¹ˆè¿™æ˜¯ä¸€ä¸ªæ˜ç¡®çš„ä¿¡å·ï¼Œè¡¨æ˜éœ€è¦æ–°çš„æ³•è§„æ¥è§„å®šå†…å®¹æ‹¥æœ‰è€…çš„æƒåˆ©ï¼Œä»¥ç»´æŒä¸€ä¸ªç¹è£çš„å†…å®¹ç”Ÿæ€ç³»ç»Ÿã€‚å¯¹è¿™ä¸€ç‚¹çš„ç†æ‰€å½“ç„¶çš„æ‰©å±•æ˜¯å¼ºåˆ¶è¦æ±‚æ¨¡å‹æä¾›å•†æŠ«éœ²è®­ç»ƒæ•°æ®ã€‚'
- en: Another related mechanism is to allow content owners to opt out of their data
    being used for model training, and do this without predatory â€œtie-insâ€. For example,
    Google cannot say that if you donâ€™t give us your data for training, we wonâ€™t index
    you on Search. Someone like OpenAI has less leverage here with content owners
    but you can imagine larger players like Microsoft, Amazon with a broader product
    portfolio being able to force peopleâ€™s hands to fork over their data.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªç›¸å…³æœºåˆ¶æ˜¯å…è®¸å†…å®¹æ‹¥æœ‰è€…é€‰æ‹©é€€å‡ºå…¶æ•°æ®ç”¨äºæ¨¡å‹è®­ç»ƒï¼Œå¹¶ä¸”åšåˆ°è¿™ä¸€ç‚¹è€Œä¸é™„å¸¦æ å¤ºæ€§çš„â€œæ†ç»‘â€æ¡ä»¶ã€‚ä¾‹å¦‚ï¼Œè°·æ­Œä¸èƒ½è¯´å¦‚æœä½ ä¸æä¾›æ•°æ®ç”¨äºè®­ç»ƒï¼Œæˆ‘ä»¬å°±ä¸ä¼šåœ¨æœç´¢ä¸­ç´¢å¼•ä½ ã€‚åƒOpenAIè¿™æ ·çš„å…¬å¸åœ¨å†…å®¹æ‹¥æœ‰è€…é¢å‰çš„ç­¹ç è¾ƒå°‘ï¼Œä½†ä½ å¯ä»¥æƒ³è±¡åƒå¾®è½¯ã€äºšé©¬é€Šè¿™æ ·çš„æ›´å¤§ä¼ä¸šå…·æœ‰æ›´å¹¿æ³›çš„äº§å“ç»„åˆï¼Œèƒ½å¤Ÿè¿«ä½¿äººä»¬äº¤å‡ºä»–ä»¬çš„æ•°æ®ã€‚
- en: '**Full control over user data:** A few specific mechanisms here can mitigate
    the user privacy risks created by AI. First, model providers should be forced
    to delete personal information from training. There needs to be some clear definition
    of what constitutes personal information (eg. information from a celebrityâ€™s wikipedia
    page is not PI but emails and phone numbers from ZoomInfoâ€™s database is). Second,
    companies should be prohibited from being able to tie-in consumer features to
    userâ€™s willingness to fork over data for model training (eg. openAI cannot say
    they wonâ€™t provide access to chat history unless users hand them over all data
    for training). There is clear precedent here â€” Appleâ€™s app tracking transparency
    framework (which I acknowledge is not regulation) prohibits apps from gating features
    behind a tracking opt-in wall, and EUâ€™s advertising regulation prohibits platforms
    from being able to gate features behind opt-in for behavioral advertising.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¯¹ç”¨æˆ·æ•°æ®çš„å®Œå…¨æ§åˆ¶ï¼š** ä¸€äº›å…·ä½“æœºåˆ¶å¯ä»¥å‡è½» AI å¸¦æ¥çš„ç”¨æˆ·éšç§é£é™©ã€‚é¦–å…ˆï¼Œæ¨¡å‹æä¾›è€…åº”è¢«è¿«åˆ é™¤è®­ç»ƒä¸­çš„ä¸ªäººä¿¡æ¯ã€‚éœ€è¦æ˜ç¡®ä»€ä¹ˆæ„æˆä¸ªäººä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼Œåäººçš„
    Wikipedia é¡µé¢ä¿¡æ¯ä¸æ˜¯ä¸ªäººä¿¡æ¯ï¼Œä½† ZoomInfo æ•°æ®åº“ä¸­çš„ç”µå­é‚®ä»¶å’Œç”µè¯å·ç æ˜¯ï¼‰ã€‚å…¶æ¬¡ï¼Œåº”ç¦æ­¢å…¬å¸å°†æ¶ˆè´¹è€…åŠŸèƒ½ä¸ç”¨æˆ·æ„¿æ„æä¾›æ•°æ®ç”¨äºæ¨¡å‹è®­ç»ƒæŒ‚é’©ï¼ˆä¾‹å¦‚ï¼ŒOpenAI
    ä¸èƒ½è¯´ä¸æä¾›è®¿é—®èŠå¤©è®°å½•ï¼Œé™¤éç”¨æˆ·å°†æ‰€æœ‰æ•°æ®äº¤ç»™ä»–ä»¬è¿›è¡Œè®­ç»ƒï¼‰ã€‚è¿™é‡Œæœ‰æ˜ç¡®çš„å…ˆä¾‹â€”â€”è‹¹æœçš„åº”ç”¨è·Ÿè¸ªé€æ˜åº¦æ¡†æ¶ï¼ˆæˆ‘æ‰¿è®¤è¿™ä¸æ˜¯ç›‘ç®¡ï¼‰ç¦æ­¢åº”ç”¨å°†åŠŸèƒ½éšè—åœ¨è·Ÿè¸ªé€‰æ‹©å¢™åï¼Œè€Œæ¬§ç›Ÿçš„å¹¿å‘Šç›‘ç®¡ç¦æ­¢å¹³å°å°†åŠŸèƒ½éšè—åœ¨é€‰æ‹©å¢™åç”¨äºè¡Œä¸ºå¹¿å‘Šã€‚'
- en: '**Content watermarking / provenance:** As AI-generated content explodes, both
    text as well as image / video, it becomes increasingly important to be able to
    distinguish AI-generated content particularly when it is false or misleading.
    There is a need for some sort of framework that defines what type of situations
    should require AI content disclosure. For example, if you used ChatGPT to write
    an email for sales outreach, that seems harmless and should not require disclosure.
    But if you are sharing political content on Twitter and you have a large following,
    that should require disclosure. Good regulation here would be less prescriptive
    of actual solutions and would lay out a framework for companies to work with,
    with the free market figuring out what the actual solutions are (eg. a startup
    could emerge to detect AI-generated political content on Twitter, which Twitter
    can then partner with).'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**å†…å®¹æ°´å°/æ¥æºï¼š** éšç€ AI ç”Ÿæˆå†…å®¹çš„æ¿€å¢ï¼Œæ— è®ºæ˜¯æ–‡æœ¬è¿˜æ˜¯å›¾åƒ/è§†é¢‘ï¼Œèƒ½å¤ŸåŒºåˆ† AI ç”Ÿæˆçš„å†…å®¹ï¼Œå°¤å…¶æ˜¯å½“è¿™äº›å†…å®¹è™šå‡æˆ–è¯¯å¯¼æ—¶ï¼Œå˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚éœ€è¦æŸç§æ¡†æ¶æ¥å®šä¹‰ä»€ä¹ˆæƒ…å†µåº”è¦æ±‚æŠ«éœ²
    AI å†…å®¹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ ä½¿ç”¨ ChatGPT å†™äº†ä¸€å°é”€å”®æ¨å¹¿é‚®ä»¶ï¼Œè¿™ä¼¼ä¹æ— å®³ï¼Œä¸åº”è¦æ±‚æŠ«éœ²ã€‚ä½†å¦‚æœä½ åœ¨ Twitter ä¸Šåˆ†äº«æ”¿æ²»å†…å®¹ä¸”æœ‰å¤§é‡å…³æ³¨è€…ï¼Œåˆ™åº”è¦æ±‚æŠ«éœ²ã€‚å¥½çš„ç›‘ç®¡åœ¨è¿™é‡Œåº”å°‘ä¸€äº›å¯¹å®é™…è§£å†³æ–¹æ¡ˆçš„è§„å®šï¼Œè€Œåº”åˆ¶å®šä¸€ä¸ªæ¡†æ¶ä¾›å…¬å¸å‚è€ƒï¼Œç”±è‡ªç”±å¸‚åœºæ‰¾å‡ºå®é™…è§£å†³æ–¹æ¡ˆï¼ˆä¾‹å¦‚ï¼Œä¸€ä¸ªåˆåˆ›å…¬å¸å¯ä»¥å‡ºç°ï¼Œç”¨äºæ£€æµ‹
    Twitter ä¸Šçš„ AI ç”Ÿæˆçš„æ”¿æ²»å†…å®¹ï¼Œç„¶å Twitter å¯ä»¥ä¸å…¶åˆä½œï¼‰ã€‚'
- en: Conclusion
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: Overall, Iâ€™m encouraged by the early conversations that are happening today
    around the topic, unlike technologies in the past where regulation has been an
    afterthought. AI comes with major upside and major risks â€” a thoughtful, mechanisms-based
    approach to regulation can help mitigate the risks of AI while making sure a competitive
    market exists to help make the most of this technology.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»çš„æ¥è¯´ï¼Œæˆ‘å¯¹å½“å‰å›´ç»•è¿™ä¸€ä¸»é¢˜çš„æ—©æœŸå¯¹è¯æ„Ÿåˆ°é¼“èˆï¼Œè¿™ä¸è¿‡å»é‚£äº›å°†ç›‘ç®¡è§†ä¸ºäº‹åæ€è€ƒçš„æŠ€æœ¯ä¸åŒã€‚AI å…·æœ‰å·¨å¤§çš„ä¼˜åŠ¿å’Œé£é™©â€”â€”ä¸€ç§æ·±æ€ç†Ÿè™‘ã€åŸºäºæœºåˆ¶çš„ç›‘ç®¡æ–¹æ³•å¯ä»¥å¸®åŠ©å‡è½»
    AI çš„é£é™©ï¼ŒåŒæ—¶ç¡®ä¿å¸‚åœºç«äº‰å­˜åœ¨ï¼Œä»¥å……åˆ†å‘æŒ¥è¿™ä¸€æŠ€æœ¯çš„ä¼˜åŠ¿ã€‚
- en: ğŸš€ If you liked this piece, consider subscribing to [**my weekly newsletter Unpacked**](https://thisisunpacked.substack.com/?utm_source=medium&utm_medium=article_tds)**.**
    Every week, I publish one **deep-dive analysis** **on a current tech topic / product
    strategy** in the form of a 10-minute read. Best, Viggy.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸš€ å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œè¯·è€ƒè™‘è®¢é˜… [**æˆ‘çš„æ¯å‘¨é€šè®¯ Unpacked**](https://thisisunpacked.substack.com/?utm_source=medium&utm_medium=article_tds)**ã€‚**
    æ¯å‘¨ï¼Œæˆ‘ä¼šå‘å¸ƒä¸€ä¸ª **å…³äºå½“å‰æŠ€æœ¯ä¸»é¢˜/äº§å“ç­–ç•¥çš„æ·±åº¦åˆ†æ**ï¼Œä»¥ 10 åˆ†é’Ÿé˜…è¯»çš„å½¢å¼å‘ˆç°ã€‚ç¥å¥½ï¼ŒViggyã€‚
- en: '[](https://thisisunpacked.substack.com/?utm_source=medium&utm_medium=article_tds&source=post_page-----391ddcef09d--------------------------------)
    [## Unpacked | Viggy Balagopalakrishnan | Substack'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://thisisunpacked.substack.com/?utm_source=medium&utm_medium=article_tds&source=post_page-----391ddcef09d--------------------------------)
    [## Unpacked | Viggy Balagopalakrishnan | Substack'
- en: Deep dive analysis on one tech topic / product strategy to your inbox every
    week. Click to read Unpacked, by Viggyâ€¦
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ¯å‘¨å°†ä¸€ä¸ªæŠ€æœ¯ä¸»é¢˜/äº§å“ç­–ç•¥çš„æ·±åº¦åˆ†æå‘é€åˆ°ä½ çš„æ”¶ä»¶ç®±ã€‚ç‚¹å‡»é˜…è¯» Viggy çš„ Unpackedâ€¦â€¦
- en: thisisunpacked.substack.com](https://thisisunpacked.substack.com/?utm_source=medium&utm_medium=article_tds&source=post_page-----391ddcef09d--------------------------------)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[thisisunpacked.substack.com](https://thisisunpacked.substack.com/?utm_source=medium&utm_medium=article_tds&source=post_page-----391ddcef09d--------------------------------)'
