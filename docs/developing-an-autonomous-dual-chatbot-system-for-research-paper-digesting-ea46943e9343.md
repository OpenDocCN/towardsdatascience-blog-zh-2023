# ä¸ºç ”ç©¶è®ºæ–‡æ¶ˆåŒ–å¼€å‘çš„è‡ªä¸»åŒèŠå¤©æœºå™¨äººç³»ç»Ÿ

> åŸæ–‡ï¼š[`towardsdatascience.com/developing-an-autonomous-dual-chatbot-system-for-research-paper-digesting-ea46943e9343`](https://towardsdatascience.com/developing-an-autonomous-dual-chatbot-system-for-research-paper-digesting-ea46943e9343)

## å…³äºæ¦‚å¿µã€å®æ–½å’Œæ¼”ç¤ºçš„é¡¹ç›®æ¼”ç»ƒ

[](https://shuaiguo.medium.com/?source=post_page-----ea46943e9343--------------------------------)![Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----ea46943e9343--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ea46943e9343--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----ea46943e9343--------------------------------) [å¸…æœ](https://shuaiguo.medium.com/?source=post_page-----ea46943e9343--------------------------------)

Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page-----ea46943e9343--------------------------------) Â·é˜…è¯»æ—¶é•¿ 28 åˆ†é’ŸÂ·2023 å¹´ 8 æœˆ 14 æ—¥

--

![](img/ccf2282defca7f209f1bce829d03c604.png)

å›¾ç‰‡ç”±[Aaron Burden](https://unsplash.com/@aaronburden?utm_source=medium&utm_medium=referral)æä¾›ï¼Œæ¥è‡ª[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

ä½œä¸ºä¸€åç ”ç©¶äººå‘˜ï¼Œé˜…è¯»å’Œç†è§£ç§‘å­¦è®ºæ–‡ä¸€ç›´æ˜¯æˆ‘æ—¥å¸¸å·¥ä½œçš„é‡è¦éƒ¨åˆ†ã€‚æˆ‘ä»ç„¶è®°å¾—åœ¨ç ”ç©¶ç”Ÿé˜¶æ®µå­¦åˆ°çš„å¦‚ä½•é«˜æ•ˆæ¶ˆåŒ–è®ºæ–‡çš„æŠ€å·§ã€‚ç„¶è€Œï¼Œç”±äºæ¯å¤©éƒ½æœ‰æ— æ•°çš„ç ”ç©¶è®ºæ–‡å‘è¡¨ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆéš¾è·Ÿä¸Šæœ€æ–°çš„ç ”ç©¶è¶‹åŠ¿å’Œè§è§£ã€‚æ—§æœ‰çš„æŠ€å·§å¸®åŠ©æœ‰é™ã€‚

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æœ€æ–°å‘å±•ï¼Œæƒ…å†µå¼€å§‹å‘ç”Ÿå˜åŒ–ã€‚å¾—ç›Šäºå…¶å‡ºè‰²çš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ï¼ŒLLMs å¯ä»¥ç›¸å½“å‡†ç¡®åœ°ä»ç”¨æˆ·æä¾›çš„æ–‡æ¡£ä¸­è¯†åˆ«ç›¸å…³ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„ç­”æ¡ˆä»¥å›åº”ç”¨æˆ·å…³äºæ–‡æ¡£çš„é—®é¢˜ã€‚åŸºäºè¿™ä¸€æ€æƒ³ï¼Œå·²ç»å¼€å‘äº†å¤§é‡çš„æ–‡æ¡£é—®ç­”å·¥å…·ï¼Œæœ‰äº›å·¥å…·ä¸“é—¨è®¾è®¡ç”¨äºå¸®åŠ©ç ”ç©¶äººå‘˜åœ¨ç›¸å¯¹è¾ƒçŸ­çš„æ—¶é—´å†…ç†è§£å¤æ‚çš„è®ºæ–‡ã€‚

è™½ç„¶è¿™æ— ç–‘æ˜¯ä¸€ä¸ªè¿›æ­¥ï¼Œä½†åœ¨ä½¿ç”¨è¿™äº›å·¥å…·æ—¶æˆ‘æ³¨æ„åˆ°äº†ä¸€äº›æ‘©æ“¦ç‚¹ã€‚æˆ‘é¢ä¸´çš„ä¸»è¦é—®é¢˜ä¹‹ä¸€æ˜¯æç¤ºå·¥ç¨‹ã€‚ç”±äº LLM çš„å›ç­”è´¨é‡åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºæˆ‘çš„é—®é¢˜è´¨é‡ï¼Œæˆ‘å¸¸å¸¸å‘ç°è‡ªå·±èŠ±è´¹ç›¸å½“å¤šçš„æ—¶é—´æ¥åˆ¶å®šâ€œå®Œç¾â€çš„é—®é¢˜ã€‚å½“é˜…è¯»ä¸ç†Ÿæ‚‰çš„ç ”ç©¶é¢†åŸŸçš„è®ºæ–‡æ—¶ï¼Œè¿™å°¤å…¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼šæˆ‘ç»å¸¸ä¸çŸ¥é“è¯¥é—®ä»€ä¹ˆé—®é¢˜ã€‚

è¿™ä¸ªç»å†è®©æˆ‘æ€è€ƒï¼šæ˜¯å¦å¯ä»¥å¼€å‘ä¸€ä¸ªç³»ç»Ÿæ¥è‡ªåŠ¨åŒ–å¤„ç†ç ”ç©¶è®ºæ–‡çš„é—®ç­”è¿‡ç¨‹ï¼Ÿä¸€ä¸ªèƒ½å¤Ÿæ›´é«˜æ•ˆä¸”è‡ªä¸»åœ°æç‚¼è®ºæ–‡å…³é”®ç‚¹çš„ç³»ç»Ÿï¼Ÿ

ä¹‹å‰ï¼Œæˆ‘æ›¾åšè¿‡ [ä¸€ä¸ªæˆ‘ä¸ºè¯­è¨€å­¦ä¹ å¼€å‘åŒèŠå¤©æœºå™¨äººç³»ç»Ÿçš„é¡¹ç›®](https://medium.com/towards-data-science/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd)ã€‚é‚£é‡Œçš„æ¦‚å¿µç®€å•è€Œæœ‰æ•ˆï¼šé€šè¿‡è®©ä¸¤ä¸ªèŠå¤©æœºå™¨äººç”¨ç”¨æˆ·æŒ‡å®šçš„å¤–è¯­èŠå¤©ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡è§‚å¯Ÿå¯¹è¯æ¥å­¦ä¹ è¯­è¨€çš„å®é™…ä½¿ç”¨ã€‚è¿™ä¸ªé¡¹ç›®çš„æˆåŠŸè®©æˆ‘äº§ç”Ÿäº†ä¸€ä¸ªæœ‰è¶£çš„æƒ³æ³•ï¼šç±»ä¼¼çš„åŒèŠå¤©æœºå™¨äººç³»ç»Ÿæ˜¯å¦ä¹Ÿæœ‰åŠ©äºç†è§£ç ”ç©¶è®ºæ–‡å‘¢ï¼Ÿ

å› æ­¤ï¼Œåœ¨è¿™ç¯‡åšå®¢ä¸­ï¼Œæˆ‘ä»¬å°†æŠŠè¿™ä¸ªæƒ³æ³•å˜ä¸ºç°å®ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†æ¼”ç¤ºå¼€å‘ä¸€ä¸ªå¯ä»¥è‡ªä¸»å¤„ç†ç ”ç©¶è®ºæ–‡çš„åŒèŠå¤©æœºå™¨äººç³»ç»Ÿçš„è¿‡ç¨‹ã€‚

ä¸ºäº†è®©è¿™æ¬¡æ—…ç¨‹å˜å¾—æœ‰è¶£ï¼Œæˆ‘ä»¬å°†å…¶è§†ä¸ºä¸€ä¸ªè½¯ä»¶é¡¹ç›®å¹¶è¿›è¡Œä¸€ä¸ª Sprintï¼šæˆ‘ä»¬å°†ä»â€œåˆ›æ„é˜¶æ®µâ€å¼€å§‹ï¼Œä»‹ç»åˆ©ç”¨åŒèŠå¤©æœºå™¨äººç³»ç»Ÿæ¥è§£å†³æˆ‘ä»¬çš„é—®é¢˜çš„æ¦‚å¿µã€‚æ¥ä¸‹æ¥æ˜¯â€œSprint æ‰§è¡Œé˜¶æ®µâ€ï¼Œåœ¨æ­¤æœŸé—´ï¼Œæˆ‘ä»¬å°†é€æ­¥æ„å»ºè®¾è®¡çš„åŠŸèƒ½ã€‚æœ€åï¼Œæˆ‘ä»¬å°†åœ¨â€œSprint å›é¡¾é˜¶æ®µâ€å±•ç¤ºæˆ‘ä»¬çš„æ¼”ç¤ºï¼Œå¹¶åœ¨â€œSprint åæ€é˜¶æ®µâ€ä¸­åæ€æ‰€å­¦åˆ°çš„å†…å®¹å’Œæœªæ¥çš„æœºä¼šã€‚

å‡†å¤‡å¥½è¿›è¡Œ Sprint äº†å—ï¼Ÿè®©æˆ‘ä»¬å¼€å§‹å§ï¼

> è¿™æ˜¯æˆ‘ç³»åˆ— LLM é¡¹ç›®çš„ç¬¬äºŒç¯‡åšå®¢ã€‚ç¬¬ä¸€ç¯‡æ˜¯ æ„å»ºä¸€ä¸ª AI é©±åŠ¨çš„è¯­è¨€å­¦ä¹ åº”ç”¨ï¼Œç¬¬ä¸‰ç¯‡æ˜¯ é€šè¿‡çœŸå®æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®ç§‘å­¦è½¯æŠ€èƒ½ã€‚æ¬¢è¿æŸ¥çœ‹ï¼

## **ç›®å½•**

**Â·** **1\. æ¦‚å¿µï¼šåŒèŠå¤©æœºå™¨äººç³»ç»Ÿ** **Â·** **2\. Sprint è®¡åˆ’ï¼šæˆ‘ä»¬æƒ³è¦æ„å»ºä»€ä¹ˆ** **Â·** **3\. åŠŸèƒ½ 1ï¼šæ–‡æ¡£åµŒå…¥å¼•æ“** **Â·** **4\. åŠŸèƒ½ 2ï¼šåŒèŠå¤©æœºå™¨äººç³»ç»Ÿ**

âˆ˜ 4.1 æŠ½è±¡èŠå¤©æœºå™¨äººç±»

âˆ˜ 4.2 è®°è€…èŠå¤©æœºå™¨äººç±»

âˆ˜ 4.3 ä½œè€…æœºå™¨äººç±»

âˆ˜ 4.4 å¿«é€Ÿæµ‹è¯•ï¼šé¢è¯•

**Â·** **5\. åŠŸèƒ½ 3ï¼šç”¨æˆ·äº¤äº’**

âˆ˜ 5.1 åˆ›å»ºèŠå¤©ç¯å¢ƒï¼ˆåœ¨ Jupyter Notebook ä¸­ï¼‰

âˆ˜ 5.2 å®ç° PDF é«˜äº®åŠŸèƒ½

âˆ˜ 5.3 å…è®¸ç”¨æˆ·è¾“å…¥é—®é¢˜

âˆ˜ 5.4 å…è®¸ä¸‹è½½ç”Ÿæˆçš„è„šæœ¬

**Â·** **6\. Sprint å›é¡¾ï¼šå±•ç¤ºæ¼”ç¤ºï¼** **Â·** **7\. Sprint åæ€**

# 1\. æ¦‚å¿µï¼šåŒèŠå¤©æœºå™¨äººç³»ç»Ÿ

æˆ‘ä»¬è§£å†³æ–¹æ¡ˆçš„åŸºç¡€åœ¨äºåŒæœºå™¨äººç³»ç»Ÿçš„æ¦‚å¿µã€‚é¡¾åæ€ä¹‰ï¼Œè¿™ä¸ªç³»ç»Ÿæ¶‰åŠä¸¤ä¸ªç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„èŠå¤©æœºå™¨äººè¿›è¡Œè‡ªä¸»å¯¹è¯ã€‚é€šè¿‡æŒ‡å®šä¸€ä¸ªé«˜çº§ä»»åŠ¡æè¿°å¹¶åˆ†é…ç›¸å…³è§’è‰²ç»™èŠå¤©æœºå™¨äººï¼Œç”¨æˆ·å¯ä»¥å¼•å¯¼å¯¹è¯æœç€ä»–ä»¬æœŸæœ›çš„æ–¹å‘å‘å±•ã€‚

ä¸¾ä¸€ä¸ªå…·ä½“çš„ä¾‹å­ï¼š[åœ¨æˆ‘ä¹‹å‰çš„é¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªåŒæœºå™¨äººç³»ç»Ÿæ¥è¾…åŠ©è¯­è¨€å­¦ä¹ ](https://medium.com/towards-data-science/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd)ï¼Œå­¦ä¹ è€…ï¼ˆç”¨æˆ·ï¼‰å¯ä»¥æŒ‡å®šä¸€ä¸ªç°å®ç”Ÿæ´»åœºæ™¯ï¼ˆä¾‹å¦‚ï¼Œåœ¨é¤å…ç”¨é¤ï¼‰ï¼Œå¹¶ä¸ºèŠå¤©æœºå™¨äººåˆ†é…è§’è‰²ï¼ˆä¾‹å¦‚ï¼Œæœºå™¨äºº 1 ä½œä¸ºæœåŠ¡å‘˜ï¼Œæœºå™¨äºº 2 ä½œä¸ºé¡¾å®¢ï¼‰ï¼Œç„¶åä¸¤ä¸ªæœºå™¨äººä¼šæ¨¡æ‹Ÿç”¨æˆ·é€‰æ‹©çš„å¤–è¯­å¯¹è¯ï¼Œæ¨¡ä»¿åœ¨ç»™å®šåœºæ™¯ä¸­åˆ†é…è§’è‰²ä¹‹é—´çš„äº’åŠ¨ã€‚è¿™å…è®¸æŒ‰éœ€ç”Ÿæˆæ–°é²œã€ç‰¹å®šåœºæ™¯çš„è¯­è¨€å­¦ä¹ ææ–™ï¼Œä»è€Œå¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ç†è§£ç°å®ç”Ÿæ´»ä¸­çš„è¯­è¨€ä½¿ç”¨ã€‚

é‚£ä¹ˆï¼Œæˆ‘ä»¬å¦‚ä½•å°†è¿™ä¸ªæ¦‚å¿µé€‚åº”äºç ”ç©¶è®ºæ–‡çš„è‡ªåŠ¨æ¶ˆåŒ–å‘¢ï¼Ÿ

å…³é”®åœ¨äº**è§’è‰²åˆ†é…**ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œä¸€ä¸ªæœºå™¨äººå¯ä»¥æ‹…ä»»â€œ**è®°è€…**â€çš„è§’è‰²ï¼Œå…¶ä¸»è¦ä»»åŠ¡æ˜¯è¿›è¡Œé‡‡è®¿ä»¥ç†è§£å’Œæå–ç ”ç©¶è®ºæ–‡ä¸­çš„å…³é”®è§è§£ã€‚ä¸æ­¤åŒæ—¶ï¼Œå¦ä¸€ä¸ªæœºå™¨äººå¯ä»¥æ‰®æ¼”â€œ**ä½œè€…**â€çš„è§’è‰²ï¼Œæ‹¥æœ‰å¯¹ç ”ç©¶è®ºæ–‡çš„å…¨é¢è®¿é—®æƒï¼Œè´Ÿè´£å›ç­”â€œè®°è€…â€æœºå™¨äººçš„æé—®ã€‚

å½“è°ˆåˆ°äº’åŠ¨æ—¶ï¼Œè®°è€…æœºå™¨äººå°†å¯åŠ¨å¯¹è¯å¹¶å¼€å§‹é‡‡è®¿è¿‡ç¨‹ã€‚ç„¶åï¼Œä½œè€…æœºå™¨äººå°†ä½œä¸ºä¼ ç»Ÿçš„æ–‡æ¡£é—®ç­”å¼•æ“ï¼Œæ ¹æ®ç ”ç©¶è®ºæ–‡çš„ç›¸å…³èƒŒæ™¯å›ç­”è®°è€…çš„é—®é¢˜ã€‚è®°è€…æœºå™¨äººéšåä¼šæå‡ºæ›´å¤šé—®é¢˜ä»¥è¿›ä¸€æ­¥æ¾„æ¸…ã€‚é€šè¿‡è¿™ç§åå¤é—®ç­”çš„è¿‡ç¨‹ï¼Œç ”ç©¶è®ºæ–‡çš„å…³é”®è´¡çŒ®ã€æ–¹æ³•è®ºå’Œå‘ç°å¯ä»¥è¢«è‡ªåŠ¨æå–ã€‚

![](img/5bb2d4d17a40f755bd0509a680ddc114.png)

åŒæœºå™¨äººç³»ç»Ÿçš„å·¥ä½œæµç¨‹ç¤ºæ„å›¾ã€‚ï¼ˆå›¾ç‰‡æ¥æºï¼šä½œè€…ï¼‰

ä¸Šè¿°åŒæœºå™¨äººç³»ç»Ÿå¼•å…¥äº†ä¸€ç§ä»ä¼ ç»Ÿç”¨æˆ·-èŠå¤©æœºå™¨äººäº’åŠ¨çš„è½¬å˜ï¼šç”¨æˆ·ä¸å†éœ€è¦æ€è€ƒå‘ LLM æ¨¡å‹æå‡ºçš„æ­£ç¡®é—®é¢˜ï¼Œä»‹ç»çš„â€œè®°è€…â€æœºå™¨äººå°†è‡ªåŠ¨ä¸ºç”¨æˆ·æå‡ºåˆé€‚çš„é—®é¢˜ã€‚è¿™ç§æ–¹æ³•å¯ä»¥ç»•è¿‡ç”¨æˆ·è®¾è®¡é€‚å½“æç¤ºçš„éœ€è¦ï¼Œä»è€Œæ˜¾è‘—é™ä½ç”¨æˆ·çš„è®¤çŸ¥è´Ÿæ‹…ã€‚è¿™åœ¨*æ·±å…¥ä¸ç†Ÿæ‚‰çš„ç ”ç©¶é¢†åŸŸ*æ—¶å°¤å…¶æœ‰ç”¨ã€‚æ€»ä½“è€Œè¨€ï¼ŒåŒæœºå™¨äººç³»ç»Ÿå¯èƒ½æ„æˆä¸€ç§æ›´ç”¨æˆ·å‹å¥½ã€é«˜æ•ˆä¸”å¼•äººå…¥èƒœçš„æ–¹æ³•ï¼Œç”¨äºæç‚¼å¤æ‚çš„ç§‘å­¦ç ”ç©¶è®ºæ–‡ã€‚

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬è¿›è¡Œ Sprint è§„åˆ’ï¼Œå¹¶å®šä¹‰æˆ‘ä»¬å¸Œæœ›åœ¨è¿™ä¸ªé¡¹ç›®ä¸­è§£å†³çš„å‡ ä¸ªç”¨æˆ·æ•…äº‹ã€‚

# 2\. å†²åˆºè§„åˆ’ï¼šæˆ‘ä»¬æƒ³è¦æ„å»ºçš„å†…å®¹

ç¡®å®šæ¦‚å¿µåï¼Œæ¥ä¸‹æ¥æ˜¯è§„åˆ’æˆ‘ä»¬å½“å‰çš„å†²åˆºã€‚æ ¹æ®æ•æ·å¼€å‘çš„å¸¸è§„åšæ³•ï¼Œæˆ‘ä»¬çš„å†²åˆºè§„åˆ’å°†å›´ç»•ç”¨æˆ·æ•…äº‹å±•å¼€ã€‚

> åœ¨æ•æ·å¼€å‘ä¸­ï¼Œ**ç”¨æˆ·æ•…äº‹**æ˜¯ä»æœ€ç»ˆç”¨æˆ·çš„è§’åº¦å¯¹åŠŸèƒ½æˆ–ç‰¹æ€§çš„ç®€æ´ã€éæ­£å¼å’Œç®€å•çš„æè¿°ã€‚è¿™æ˜¯ä¸€ç§åœ¨æ•æ·å¼€å‘ä¸­å¸¸ç”¨çš„åšæ³•ï¼Œç”¨äºä»¥ä¸€ç§å¯ç†è§£å’Œå¯æ“ä½œçš„æ–¹å¼å®šä¹‰å’Œä¼ è¾¾éœ€æ±‚ã€‚

+   ğŸ¯ **ç”¨æˆ·æ•…äº‹ 1: æ–‡æ¡£åµŒå…¥**

> â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›å°† PDF æ ¼å¼çš„ç ”ç©¶è®ºæ–‡è¾“å…¥ç³»ç»Ÿï¼Œå¹¶å¸Œæœ›ç³»ç»Ÿå°†æˆ‘çš„è¾“å…¥è®ºæ–‡è½¬æ¢æˆ**æœºå™¨å¯è¯»æ ¼å¼**ï¼Œä»¥ä¾¿åŒæœºå™¨äººç³»ç»Ÿèƒ½å¤Ÿé«˜æ•ˆåœ°ç†è§£å’Œåˆ†æå®ƒã€‚â€ï¼ˆç”± GPT-4 ç”Ÿæˆï¼‰

è¿™ä¸ªç”¨æˆ·æ•…äº‹é›†ä¸­åœ¨æ•°æ®æ‘„å–ä¸Šã€‚æœ¬è´¨ä¸Šï¼Œæˆ‘ä»¬éœ€è¦æ„å»ºä¸€ä¸ªæ•°æ®å¤„ç†ç®¡é“ï¼ŒåŒ…æ‹¬æ–‡æ¡£åŠ è½½ã€æ‹†åˆ†ã€åµŒå…¥åˆ›å»ºå’ŒåµŒå…¥å­˜å‚¨ã€‚

åœ¨è¿™é‡Œï¼Œâ€œåµŒå…¥â€æŒ‡çš„æ˜¯æ–‡æœ¬æ•°æ®çš„æ•°å€¼è¡¨ç¤ºã€‚é€šè¿‡åˆ›å»ºç ”ç©¶è®ºæ–‡æ¯éƒ¨åˆ†çš„æ•°å€¼è¡¨ç¤ºï¼Œä½œè€…æœºå™¨äººå¯ä»¥æ›´å¥½åœ°ç†è§£ç ”ç©¶è®ºæ–‡çš„è¯­ä¹‰å«ä¹‰ï¼Œå¹¶èƒ½å¤Ÿå‡†ç¡®å›ç­”è®°è€…æœºå™¨äººçš„é—®é¢˜ã€‚

æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä¸€ä¸ªæ•°æ®åº“æ¥å­˜å‚¨ç ”ç©¶è®ºæ–‡è®¡ç®—å‡ºçš„åµŒå…¥ã€‚è¿™ä¸€æ•°æ®åº“éœ€è¦èƒ½å¤Ÿè¢«ä½œè€…æœºå™¨äººå¿«é€Ÿè®¿é—®ï¼Œä»¥ä¾¿ç”Ÿæˆå¿«é€Ÿè€Œå‡†ç¡®çš„å›ç­”ã€‚

åœ¨ç¬¬ä¸‰éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†åˆ©ç”¨**OpenAI Embeddings API**å’Œ Meta çš„**FAISS å‘é‡å­˜å‚¨**æ¥è§£å†³è¿™ä¸ªç”¨æˆ·æ•…äº‹ã€‚

+   ğŸ¯ **ç”¨æˆ·æ•…äº‹ 2: åŒæœºå™¨äºº**

> â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›è§‚å¯Ÿä¸¤ä¸ªèŠå¤©æœºå™¨äººä¹‹é—´çš„è‡ªä¸»å¯¹è¯â€”â€”ä¸€ä¸ªæ‰®æ¼”â€˜è®°è€…â€™è§’è‰²æé—®ï¼Œå¦ä¸€ä¸ªæ‰®æ¼”â€˜ä½œè€…â€™è§’è‰²å›ç­”ï¼Œè¿™äº›å¯¹è¯æ¥æºäºç ”ç©¶è®ºæ–‡çš„å†…å®¹ã€‚è¿™å°†å¸®åŠ©æˆ‘ç†è§£è®ºæ–‡çš„å…³é”®ç‚¹ï¼Œè€Œæ— éœ€å®Œæ•´é˜…è¯»æˆ–è‡ªå·±æå‡ºé—®é¢˜ã€‚â€ï¼ˆç”± GPT-4 ç”Ÿæˆï¼‰

è¿™ä¸ªç”¨æˆ·æ•…äº‹ä»£è¡¨äº†æˆ‘ä»¬é¡¹ç›®çš„åŸºçŸ³ï¼šåŒæœºå™¨äººç³»ç»Ÿçš„å¼€å‘ã€‚å¦‚â€œæ¦‚å¿µâ€éƒ¨åˆ†æ‰€è¿°ï¼Œæˆ‘ä»¬éœ€è¦æ„å»ºä¸¤ç§ç±»å‹çš„èŠå¤©æœºå™¨äººç±»ï¼šä¸€ç§èƒ½å¤Ÿæå‡ºä¸€ç³»åˆ—é—®é¢˜æ¥æŸ¥è¯¢è®ºæ–‡çš„è¯¦ç»†ä¿¡æ¯ï¼ˆå³è®°è€…æœºå™¨äººï¼‰ï¼Œå¦ä¸€ç§èƒ½å¤Ÿåˆ©ç”¨æ–‡æ¡£åµŒå…¥ç”Ÿæˆå¯¹è¿™äº›é—®é¢˜çš„å…¨é¢å›ç­”ï¼ˆå³ä½œè€…æœºå™¨äººï¼‰ã€‚

åœ¨ç¬¬å››éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä½¿ç”¨**LangChain**æ¡†æ¶æ¥è§£å†³è¿™ä¸ªç”¨æˆ·æ•…äº‹ã€‚

+   ğŸ¯ **ç”¨æˆ·æ•…äº‹ 3: èŠå¤©ç¯å¢ƒ**

> â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›æœ‰ä¸€ä¸ªç›´è§‚çš„èŠå¤©ç•Œé¢ï¼Œåœ¨è¿™é‡Œæˆ‘å¯ä»¥å®æ—¶è§‚å¯ŸèŠå¤©æœºå™¨äººçš„å¯¹è¯å±•å¼€ã€‚â€ï¼ˆç”± GPT-4 ç”Ÿæˆï¼‰

è¿™ä¸ªç”¨æˆ·æ•…äº‹çš„ç›®æ ‡æ˜¯æ„å»ºä¸€ä¸ªèŠå¤©ç¯å¢ƒï¼Œç”¨æˆ·å¯ä»¥æŸ¥çœ‹è®°è€…å’Œä½œè€…æœºå™¨äººä¹‹é—´ç”Ÿæˆçš„å¯¹è¯ã€‚ä¸ºäº†ç¬¦åˆ MVPï¼ˆæœ€ç®€å¯è¡Œäº§å“ï¼‰çš„ç²¾ç¥ï¼Œæˆ‘ä»¬å°†åœ¨ 5.1 èŠ‚ä½¿ç”¨ç®€å•çš„**Jupyter å°éƒ¨ä»¶**æ¥æ¼”ç¤ºèŠå¤©ç¯å¢ƒã€‚

+   ğŸ¯ **ç”¨æˆ·æ•…äº‹ 4: PDF é«˜äº®**

> â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿæ ¹æ®èŠå¤©æœºå™¨äººçš„è®¨è®ºåœ¨åŸç ”ç©¶è®ºæ–‡ä¸­çªå‡ºæ˜¾ç¤ºç›¸å…³éƒ¨åˆ†ã€‚è¿™å°†å¸®åŠ©æˆ‘å¿«é€Ÿæ‰¾åˆ°å¯¹è¯ä¸­è®¨è®ºçš„ä¿¡æ¯çš„æ¥æºã€‚â€ï¼ˆç”± GPT-4 ç”Ÿæˆï¼‰

è¿™ä¸ªç”¨æˆ·æ•…äº‹ç€é‡äºä¸ºç”¨æˆ·æä¾›é—®ç­”çš„å¯è¿½æº¯æ€§ã€‚å¯¹äºæ¯ä¸€ä¸ªç”±ä½œè€…æœºå™¨äººç”Ÿæˆçš„å›ç­”ï¼Œç”¨æˆ·å¯ä»¥è‡ªç„¶åœ°ç†è§£è®¨è®ºçš„ä¿¡æ¯æºè‡ªç ”ç©¶è®ºæ–‡çš„ç¡®åˆ‡ä½ç½®ã€‚è¿™ä¸ªåŠŸèƒ½ä¸ä»…æå‡äº†æˆ‘ä»¬åŒèŠå¤©æœºå™¨äººç³»ç»Ÿçš„é€æ˜åº¦ï¼Œè¿˜ä½¿å¾—ç”¨æˆ·ä½“éªŒæ›´åŠ äº’åŠ¨å’Œå¼•äººå…¥èƒœã€‚

åœ¨ 5.2 èŠ‚ï¼Œæˆ‘ä»¬å°†åˆ©ç”¨ LangChain çš„**å¯¹è¯æ£€ç´¢é“¾**æ¥è¿”å›ä½œè€…æœºå™¨äººç”¨äºç”Ÿæˆå›ç­”çš„æ¥æºï¼Œå¹¶ä½¿ç”¨**PyMuPDF**åº“æ¥çªå‡ºæ˜¾ç¤ºåŸ PDF ä¸­çš„ç›¸å…³æ–‡æœ¬ã€‚

+   ğŸ¯ **ç”¨æˆ·æ•…äº‹ 5: ç”¨æˆ·è¾“å…¥**

> â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿåœ¨èŠå¤©æœºå™¨äººçš„å¯¹è¯è¿‡ç¨‹ä¸­è¿›è¡Œå¹²é¢„å¹¶æå‡ºè‡ªå·±çš„é—®é¢˜ï¼Œè¿™æ ·æˆ‘å¯ä»¥å¼•å¯¼å¯¹è¯å¹¶ä»è®ºæ–‡ä¸­æå–æˆ‘éœ€è¦çš„ä¿¡æ¯ã€‚â€ï¼ˆç”± GPT-4 ç”Ÿæˆï¼‰

è¿™ä¸ªç”¨æˆ·æ•…äº‹å…³æ³¨äºç”¨æˆ·å‚ä¸çš„éœ€æ±‚ã€‚è™½ç„¶æˆ‘ä»¬çš„ç›®æ ‡åŒèŠå¤©æœºå™¨äººç³»ç»Ÿæ—¨åœ¨è‡ªä¸»è¿ä½œï¼Œä½†æˆ‘ä»¬ä»éœ€æä¾›ç”¨æˆ·æå‡ºè‡ªå·±é—®é¢˜çš„é€‰é¡¹ã€‚è¿™ä¸ªåŠŸèƒ½ç¡®ä¿äº†å¯¹è¯ä¸ä¼šä»…ä»…æŒ‰ç…§æœºå™¨äººçš„è®¾å®šæ–¹å‘è¿›è¡Œï¼Œè€Œæ˜¯å¯ä»¥ç”±ç”¨æˆ·çš„å¥½å¥‡å¿ƒå’Œå…´è¶£æ¥å¼•å¯¼ã€‚æ­¤å¤–ï¼Œç”¨æˆ·å¯èƒ½ä¼šå—åˆ°ç¬¬ä¸€æ¬¡å¯¹è¯çš„å¯å‘ï¼Œæƒ³è¦æå‡ºåç»­é—®é¢˜æˆ–æ·±å…¥æŒ–æ˜ä»–ä»¬ç‰¹åˆ«æ„Ÿå…´è¶£çš„æŸäº›æ–¹é¢ã€‚è¿™äº›éƒ½å¼ºè°ƒäº†ç”¨æˆ·å¹²é¢„çš„é‡è¦æ€§ã€‚

åœ¨ 5.3 èŠ‚ï¼Œæˆ‘ä»¬å°†é€šè¿‡å‡çº§ Jupyter Notebook ä¸­çš„ç”¨æˆ·ç•Œé¢æ¥å¤„ç†è¿™ä¸ªç”¨æˆ·æ•…äº‹ã€‚

+   ğŸ¯ **ç”¨æˆ·æ•…äº‹ 6: ä¸‹è½½è„šæœ¬**

> â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿä¸‹è½½èŠå¤©æœºå™¨äººå¯¹è¯çš„è®°å½•ã€‚è¿™å°†å…è®¸æˆ‘ç¦»çº¿æŸ¥çœ‹è¦ç‚¹æˆ–ä¸æˆ‘çš„åŒäº‹åˆ†äº«ä¿¡æ¯ã€‚â€ï¼ˆç”± GPT-4 ç”Ÿæˆï¼‰

è¿™ä¸ªç”¨æˆ·æ•…äº‹å…³æ³¨äºç”Ÿæˆå†…å®¹çš„å¯è®¿é—®æ€§å’Œå¯åˆ†äº«æ€§ã€‚è™½ç„¶ç”¨æˆ·å¯ä»¥åœ¨ä¸“ç”¨çš„èŠå¤©ç¯å¢ƒä¸­æŸ¥çœ‹å¯¹è¯ï¼Œä½†æä¾›ä¸€ä¸ªå¯ä»¥ä¾›ç”¨æˆ·åç»­æŸ¥çœ‹å’Œåˆ†äº«çš„è®¨è®ºè®°å½•æ˜¯å¾ˆæœ‰ç›Šçš„ã€‚

åœ¨ 5.4 èŠ‚ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨**PDFDocument**åº“å°†ç”Ÿæˆçš„è„šæœ¬è½¬æ¢ä¸º PDF æ–‡ä»¶ï¼Œä»¥ä¾›ç”¨æˆ·ä¸‹è½½ã€‚

è§„åˆ’åˆ°æ­¤ä¸ºæ­¢ï¼Œç°åœ¨æ˜¯æ—¶å€™å¼€å§‹å·¥ä½œäº†ï¼

![](img/1aa4c455b93f11b7eb1154eaf4fd48c5.png)

æˆ‘ä»¬è§„åˆ’çš„ç”¨æˆ·æ•…äº‹ã€‚ï¼ˆä½œè€…æä¾›çš„å›¾ç‰‡ï¼‰

# 3\. ç‰¹æ€§ 1ï¼šæ–‡æ¡£åµŒå…¥å¼•æ“

è®©æˆ‘ä»¬å®ç°æˆ‘ä»¬è®ºæ–‡æ¶ˆåŒ–åº”ç”¨çš„ç¬¬ä¸€ä¸ªåŠŸèƒ½ï¼šæ–‡æ¡£åµŒå…¥å¼•æ“ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªæ•°æ®å¤„ç†ç±»ï¼Œå…·å¤‡æ–‡æ¡£åŠ è½½ã€æ‹†åˆ†ã€åµŒå…¥åˆ›å»ºå’Œå­˜å‚¨çš„åŠŸèƒ½ã€‚è¿™è§£å†³äº†æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªç”¨æˆ·æ•…äº‹ï¼š

> â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›å°† PDF æ ¼å¼çš„ç ”ç©¶è®ºæ–‡è¾“å…¥ç³»ç»Ÿï¼Œå¹¶å¸Œæœ›ç³»ç»Ÿå°†æˆ‘çš„è¾“å…¥è®ºæ–‡è½¬æ¢ä¸º**æœºå™¨å¯è¯»æ ¼å¼**ï¼Œä»¥ä¾¿åŒé‡èŠå¤©æœºå™¨äººç³»ç»Ÿèƒ½å¤Ÿæœ‰æ•ˆç†è§£å’Œåˆ†æã€‚â€ï¼ˆç”± GPT-4 ç”Ÿæˆï¼‰

æˆ‘ä»¬é¦–å…ˆåˆ›å»ºä¸€ä¸ª `embedding_engine.py` æ–‡ä»¶ï¼Œå¹¶å¯¼å…¥å¿…è¦çš„åº“ï¼š

```py
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.document_loaders import PyMuPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.chains.summarize import load_summarize_chain
from langchain.chat_models import ChatOpenAI
from langchain.utilities import ArxivAPIWrapper
import os
```

ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ OpenAI åµŒå…¥ API å®ä¾‹åŒ–äº†ä¸€ä¸ªåµŒå…¥æ¨¡å‹ï¼š

```py
class Embedder:
    """Embedding engine to create doc embeddings."""

    def __init__(self, engine='OpenAI'):
        """Specify embedding model.

        Args:
        --------------
        engine: the embedding model. 
                For a complete list of supported embedding models in LangChain, 
                see https://python.langchain.com/docs/integrations/text_embedding/
        """
        if engine == 'OpenAI':
            # Reminder: need to set up openAI API key 
            # (e.g., via environment variable OPENAI_API_KEY)
            self.embeddings = OpenAIEmbeddings()

        else:
            raise KeyError("Currently unsupported chat model type!")
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å®šä¹‰äº†åŠ è½½å’Œå¤„ç† PDF æ–‡ä»¶çš„å‡½æ•°ï¼š

```py
def load_n_process_document(self, path):
    """Load and process PDF document.

    Args:
    --------------
    path: path of the paper.
    """

    # Load PDF
    loader = PyMuPDFLoader(path)
    documents = loader.load()

    # Process PDF
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    self.documents = text_splitter.split_documents(documents)
```

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨äº† `PyMuPDFLoader` æ¥åŠ è½½ PDF æ–‡ä»¶ï¼Œè¯¥å·¥å…·åœ¨åº•å±‚åˆ©ç”¨ PyMuPDF åº“è§£æ PDF æ–‡ä»¶ã€‚è¿”å›çš„ `documents` å˜é‡æ˜¯ LangChain `Document()` å¯¹è±¡çš„åˆ—è¡¨ã€‚æ¯ä¸ª `Document()` å¯¹è±¡å¯¹åº”åŸå§‹ PDF çš„ä¸€é¡µï¼Œé¡µé¢å†…å®¹å­˜å‚¨åœ¨ `page_content` é”®ä¸­ï¼Œç›¸å…³çš„å…ƒæ•°æ®ï¼ˆä¾‹å¦‚ï¼Œé¡µç ç­‰ï¼‰å­˜å‚¨åœ¨ `metadata` é”®ä¸­ã€‚

è§£æåŠ è½½çš„ PDF åï¼Œæˆ‘ä»¬ä½¿ç”¨äº† LangChain çš„ `RecursiveCharacterTextSplitter` å°†åŸå§‹ PDF æ‹†åˆ†æˆå¤šä¸ªè¾ƒå°çš„å—ã€‚ç”±äºä½œè€…æœºå™¨äººç¨åå°†ä½¿ç”¨ PDF ä¸­çš„ç›¸å…³æ–‡æœ¬æ¥å›ç­”é—®é¢˜ï¼Œåˆ›å»ºå°å—æ–‡æœ¬ä¸ä»…å¯ä»¥å¸®åŠ©ä½œè€…æœºå™¨äººä¸“æ³¨äºå…·ä½“ç»†èŠ‚ä»¥å›ç­”é—®é¢˜ï¼Œè¿˜å¯ä»¥ç¡®ä¿æä¾›ç»™ä½œè€…æœºå™¨äººçš„ä¸Šä¸‹æ–‡ä¸ä¼šè¶…å‡ºæ‰€ç”¨ LLM çš„ä»¤ç‰Œé™åˆ¶ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è®¾ç½®å‘é‡å­˜å‚¨ä»¥ç®¡ç†æ–‡æœ¬åµŒå…¥å‘é‡ï¼š

```py
def create_vectorstore(self, store_path):
    """Create vector store for doc Q&A.
       For a complete list of vector stores supported by LangChain,
       see: https://python.langchain.com/docs/integrations/vectorstores/

    Args:
    --------------
    store_path: path of the vector store.

    Outputs:
    --------------
    vectorstore: the created vector store for holding embeddings
    """
    if not os.path.exists(store_path):
        print("Embeddings not found! Creating new ones")
        self.vectorstore = FAISS.from_documents(self.documents, self.embeddings)
        self.vectorstore.save_local(store_path)

    else:
        print("Embeddings found! Loaded the computed ones")
        self.vectorstore = FAISS.load_local(store_path, self.embeddings)

    return self.vectorstore
```

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨äº† Facebook AI ç›¸ä¼¼åº¦æœç´¢ï¼ˆFAISSï¼‰åº“ä½œä¸ºæˆ‘ä»¬çš„å‘é‡å­˜å‚¨ï¼Œå®ƒæ¥å—åŠ è½½çš„ PDF å’ŒåµŒå…¥å¼•æ“ä½œä¸ºæ„é€ å‡½æ•°çš„è¾“å…¥ã€‚åˆ›å»ºçš„ `self.vectorstore` å­˜å‚¨äº†æˆ‘ä»¬ä¹‹å‰åˆ›å»ºçš„æ¯ä¸ª PDF å—çš„åµŒå…¥å‘é‡ã€‚åœ¨æŸ¥è¯¢æ—¶ï¼Œå®ƒå°†è°ƒç”¨åµŒå…¥å¼•æ“æ¥åµŒå…¥é—®é¢˜ï¼Œç„¶åæ£€ç´¢ä¸åµŒå…¥æŸ¥è¯¢â€œæœ€ç›¸ä¼¼â€çš„åµŒå…¥å‘é‡ã€‚ä¸æœ€ç›¸ä¼¼åµŒå…¥å‘é‡å¯¹åº”çš„æ–‡æœ¬å°†ä½œä¸ºä¸Šä¸‹æ–‡è¾“å…¥åˆ°ä½œè€…æœºå™¨äººï¼Œä»¥å¸®åŠ©ç”Ÿæˆç­”æ¡ˆã€‚è¿™ä¸ªè¿‡ç¨‹è¢«ç§°ä¸º**å‘é‡æœç´¢**ï¼Œæ˜¯æ–‡æ¡£é—®ç­”çš„æ ¸å¿ƒã€‚

æœ€åï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªè¾…åŠ©å‡½æ•°æ¥ç”Ÿæˆè®ºæ–‡çš„ç®€çŸ­æ‘˜è¦ã€‚è¿™å°†åœ¨ç¨åä¸ºè®°è€…æœºå™¨äººè®¾å®šåœºæ™¯æ—¶éå¸¸æœ‰ç”¨ã€‚

```py
def create_summary(self, llm_engine=None):
    """Create paper summary. 
    The summary is created by using LangChain's summarize_chain.

    Args:
    --------------
    llm_engine: backbone large language model.

    Outputs:
    --------------
    summary: the summary of the paper
    """

    if llm_engine is None:
        raise KeyError("please specify a LLM engine to perform summarization.")

    elif llm_engine == 'OpenAI':
        # Reminder: need to set up openAI API key 
        # (e.g., via environment variable OPENAI_API_KEY)
        llm = ChatOpenAI(
            model_name="gpt-3.5-turbo",
            temperature=0.8
        )

    else:
        raise KeyError("Currently unsupported chat model type!")

    # Use LLM to summarize the paper
    chain = load_summarize_chain(llm, chain_type="stuff")
    summary = chain.run(self.documents[:20])

    return summary
```

æˆ‘ä»¬æ±‚åŠ©äº LLM æ¥åˆ›å»ºæ‘˜è¦ã€‚ä»æŠ€æœ¯ä¸Šè®²ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨ LangChain çš„ `load_summarize_chain` æ¥å®ç°è¿™ä¸€ç›®æ ‡ï¼Œè¯¥æ–¹æ³•æ¥å— LLM æ¨¡å‹å’Œæ€»ç»“æ–¹æ³•ä½œä¸ºè¾“å…¥ã€‚

åœ¨æ‘˜è¦æ–¹æ³•æ–¹é¢ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†**stuff**æ–¹æ³•ï¼Œå®ƒç®€å•åœ°å°†æ‰€æœ‰æ–‡æ¡£â€œå¡«å……â€åˆ°ä¸€ä¸ªä¸Šä¸‹æ–‡ä¸­ï¼Œå¹¶æç¤º LLM ç”Ÿæˆæ‘˜è¦ã€‚æœ‰å…³å…¶ä»–æ›´é«˜çº§çš„æ–¹æ³•ï¼Œè¯·å‚é˜… LangChain çš„[å®˜æ–¹é¡µé¢](https://python.langchain.com/docs/use_cases/summarization)ã€‚

å¤ªæ£’äº†ï¼ç°åœ¨æˆ‘ä»¬å·²ç»å¼€å‘äº†`Embedder`ç±»æ¥å¤„ç†æ–‡æ¡£åŠ è½½ã€æ‹†åˆ†ä»¥åŠåµŒå…¥åˆ›å»ºå’Œå­˜å‚¨ï¼Œæˆ‘ä»¬å¯ä»¥è½¬åˆ°æˆ‘ä»¬åº”ç”¨çš„æ ¸å¿ƒéƒ¨åˆ†ï¼šåŒèŠå¤©æœºå™¨äººç³»ç»Ÿã€‚

# 4. åŠŸèƒ½ 2ï¼šåŒèŠå¤©æœºå™¨äººç³»ç»Ÿ

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å¤„ç†æˆ‘ä»¬çš„ç¬¬äºŒä¸ªç”¨æˆ·æ•…äº‹ï¼š

> â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘æƒ³è§‚å¯Ÿä¸¤ä¸ªèŠå¤©æœºå™¨äººä¹‹é—´çš„è‡ªä¸»å¯¹è¯â€”â€”ä¸€ä¸ªæ‰®æ¼”â€˜è®°è€…â€™æé—®ï¼Œå¦ä¸€ä¸ªæ‰®æ¼”â€˜ä½œè€…â€™å›ç­”ï¼Œé—®é¢˜å’Œå›ç­”éƒ½æ¥è‡ªç ”ç©¶è®ºæ–‡çš„å†…å®¹ã€‚è¿™å°†å¸®åŠ©æˆ‘ç†è§£è®ºæ–‡çš„å…³é”®ç‚¹ï¼Œè€Œæ— éœ€å®Œæ•´é˜…è¯»è®ºæ–‡æˆ–è‡ªå·±æå‡ºé—®é¢˜ã€‚â€ï¼ˆç”± GPT-4 ç”Ÿæˆï¼‰

æˆ‘ä»¬å°†é¦–å…ˆåˆ›å»ºä¸€ä¸ªæŠ½è±¡åŸºç±»ï¼Œç”¨äºå®šä¹‰èŠå¤©æœºå™¨äººçš„å…±åŒè¡Œä¸ºã€‚ä¹‹åï¼Œæˆ‘ä»¬å°†å¼€å‘ç»§æ‰¿è‡ªèŠå¤©æœºå™¨äººåŸºç±»çš„è®°è€…æœºå™¨äººå’Œä½œè€…æœºå™¨äººã€‚æˆ‘ä»¬å°†æ‰€æœ‰ç±»å®šä¹‰æ”¾åœ¨`chatbot.py`ä¸­ã€‚

## 4.1 æŠ½è±¡èŠå¤©æœºå™¨äººç±»

ç”±äºæˆ‘ä»¬çš„è®°è€…æœºå™¨äººå’Œä½œè€…æœºå™¨äººæœ‰å¾ˆå¤šç›¸ä¼¼ä¹‹å¤„ï¼ˆå› ä¸ºå®ƒä»¬éƒ½æ˜¯è§’è‰²æ‰®æ¼”æœºå™¨äººï¼‰ï¼Œå°†å®ƒä»¬å…±äº«çš„è¡Œä¸ºå®šä¹‰å°è£…åœ¨ä¸€ä¸ªæŠ½è±¡åŸºç±»ä¸­æ˜¯ä¸€ä¸ªå¥½ä¹ æƒ¯ï¼š

```py
from abc import ABC, abstractmethod
from langchain.chat_models import ChatOpenAI

class Chatbot(ABC):
    """Class definition for a single chatbot with memory, created with LangChain."""

    def __init__(self, engine):
        """Initialize the large language model and its associated memory.
        The memory can be an LangChain emory object, or a list of chat history.

        Args:
        --------------
        engine: the backbone llm-based chat model.
        """

        # Instantiate llm
        if engine == 'OpenAI':
            # Reminder: need to set up openAI API key 
            # (e.g., via environment variable OPENAI_API_KEY)
            self.llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.8)

        else:
            raise KeyError("Currently unsupported chat model type!")

    @abstractmethod
    def instruct(self):
        """Determine the context of chatbot interaction. 
        """
        pass

    @abstractmethod
    def step(self):
        """Action produced by the chatbot. 
        """
        pass

    @abstractmethod
    def _specify_system_message(self):
        """Prompt engineering for chatbot.
        """       
        pass
```

æˆ‘ä»¬å®šä¹‰äº†ä¸‰ä¸ªå¸¸ç”¨æ–¹æ³•ï¼š

+   `instruct`ï¼šè¿™ä¸ªæ–¹æ³•ç”¨äºè®¾ç½®èŠå¤©æœºå™¨äººå¹¶å°†å†…å­˜é™„åŠ åˆ°å®ƒä¸Šé¢ã€‚

+   `step`ï¼šè¿™ä¸ªæ–¹æ³•ç”¨äºå‘èŠå¤©æœºå™¨äººæä¾›è¾“å…¥å¹¶æ¥æ”¶æœºå™¨äººçš„å›åº”ã€‚

+   `specify_system_message`ï¼šè¿™ä¸ªæ–¹æ³•ç”¨äºç»™èŠå¤©æœºå™¨äººæä¾›å…·ä½“çš„æŒ‡ä»¤ï¼Œè¯´æ˜å®ƒåœ¨å¯¹è¯ä¸­åº”è¯¥å¦‚ä½•è¡Œä¸ºã€‚

æœ‰äº†èŠå¤©æœºå™¨äººæ¨¡æ¿ï¼Œæˆ‘ä»¬å‡†å¤‡åˆ›å»ºä¸¤ä¸ªå…·ä½“çš„èŠå¤©æœºå™¨äººè§’è‰²ï¼Œå³è®°è€…æœºå™¨äººå’Œä½œè€…æœºå™¨äººã€‚

## 4.2 è®°è€…èŠå¤©æœºå™¨äººç±»

è®°è€…æœºå™¨äººçš„è§’è‰²æ˜¯é‡‡è®¿ä½œè€…æœºå™¨äººå¹¶ä»ç ”ç©¶è®ºæ–‡ä¸­æå–å…³é”®è§è§£ã€‚è€ƒè™‘åˆ°è¿™ä¸€ç‚¹ï¼Œè®©æˆ‘ä»¬ç”¨å…·ä½“çš„ä»£ç å¡«å……æ¨¡æ¿æ–¹æ³•ã€‚

```py
from langchain.memory import ConversationBufferMemory

class JournalistBot(Chatbot):
    """Class definition for the journalist bot, created with LangChain."""

    def __init__(self, engine):
        """Setup journalist bot.

        Args:
        --------------
        engine: the backbone llm-based chat model.
        """

        # Instantiate llm
        super().__init__(engine)

        # Instantiate memory
        self.memory = ConversationBufferMemory(return_messages=True)
```

åœ¨æ„é€ å‡½æ•°æ–¹æ³•ä¸­ï¼Œé™¤äº†æŒ‡å®šä¸€ä¸ªä¸»å¹² LLMï¼Œè®°è€…æœºå™¨äººå¦ä¸€ä¸ªé‡è¦çš„ç»„ä»¶æ˜¯å†…å­˜å¯¹è±¡ã€‚å†…å­˜è·Ÿè¸ªå¯¹è¯å†å²ï¼Œå¹¶å¸®åŠ©è®°è€…æœºå™¨äººé¿å…é‡å¤æˆ–æ— å…³çš„é—®é¢˜ï¼Œå¹¶ç”Ÿæˆæœ‰æ„ä¹‰çš„åç»­é—®é¢˜ã€‚ä»æŠ€æœ¯ä¸Šè®²ï¼Œæˆ‘ä»¬é€šè¿‡ä½¿ç”¨ LangChain æä¾›çš„`ConversationBufferMemory`æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œå®ƒç®€å•åœ°å°†æœ€åå‡ æ¬¡è¾“å…¥/è¾“å‡ºé™„åŠ åˆ°èŠå¤©æœºå™¨äººçš„å½“å‰è¾“å…¥ä¸­ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬é€šè¿‡åˆ›å»ºä¸€ä¸ª `ConversationChain` æ¥è®¾ç½®è®°è€…èŠå¤©æœºå™¨äººï¼Œä½¿ç”¨ä¹‹å‰å®šä¹‰çš„éª¨å¹² LLMã€å†…å­˜å¯¹è±¡ä»¥åŠèŠå¤©æœºå™¨äººçš„æç¤ºã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬è¿˜æŒ‡å®šäº† `topic`ï¼ˆè®ºæ–‡ä¸»é¢˜ï¼‰å’Œ `abstract`ï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰ï¼Œè¿™äº›å°†åœ¨ç¨åç”¨äºå‘è®°è€…æœºå™¨äººæä¾›è®ºæ–‡çš„èƒŒæ™¯ä¿¡æ¯ã€‚

```py
from langchain.chains import ConversationChain
from langchain.prompts import (
    ChatPromptTemplate, 
    MessagesPlaceholder, 
    SystemMessagePromptTemplate, 
    HumanMessagePromptTemplate
)

def instruct(self, topic, abstract):
    """Determine the context of journalist chatbot. 

    Args:
    ------
    topic: the topic of the paper
    abstract: the abstract of the paper
    """

    self.topic = topic
    self.abstract = abstract

    # Define prompt template
    prompt = ChatPromptTemplate.from_messages([
        SystemMessagePromptTemplate.from_template(self._specify_system_message()),
        MessagesPlaceholder(variable_name="history"),
        HumanMessagePromptTemplate.from_template("""{input}""")
    ])

    # Create conversation chain
    self.conversation = ConversationChain(memory=self.memory, prompt=prompt, 
                                          llm=self.llm, verbose=False)
```

åœ¨ LangChain ä¸­ï¼Œç”¨äºæŒ‡ç¤ºèŠå¤©æœºå™¨äººçš„æç¤ºç”Ÿæˆå’Œæ¥æ”¶æ˜¯é€šè¿‡ä¸åŒçš„æç¤ºæ¨¡æ¿å¤„ç†çš„ã€‚å¯¹äºæˆ‘ä»¬å½“å‰çš„åº”ç”¨ç¨‹åºï¼Œæœ€å…³é”®çš„éƒ¨åˆ†æ˜¯è®¾ç½® `SystemMessagePromptTemplate`ï¼Œå› ä¸ºå®ƒå…è®¸æˆ‘ä»¬ç»™è®°è€…æœºå™¨äººæä¾› *é«˜çº§ç›®çš„*ï¼Œå¹¶å®šä¹‰å…¶æœŸæœ›çš„è¡Œä¸ºã€‚

ä»¥ä¸‹æ˜¯æŒ‡ä»¤çš„è¯¦ç»†ä¿¡æ¯ã€‚è¯·æ³¨æ„ï¼ŒæŒ‡ä»¤/æç¤ºæ˜¯é€šè¿‡ ChatGPT (GPT-4) ç”Ÿæˆå’Œä¼˜åŒ–çš„ã€‚è¿™æ˜¯æœ‰åˆ©çš„ï¼Œå› ä¸ºåœ¨å½“å‰æƒ…å†µä¸‹ï¼ŒLLM ç”Ÿæˆçš„æç¤ºå¾€å¾€æ¯”äººå·¥ç¼–å†™çš„æç¤ºè€ƒè™‘æ›´å¤šç»†èŠ‚ã€‚æ­¤å¤–ï¼Œä½¿ç”¨ LLM ç”Ÿæˆé«˜çº§æŒ‡ä»¤ä»£è¡¨äº†ä¸€ç§æ›´å…·å¯æ‰©å±•æ€§çš„è§£å†³æ–¹æ¡ˆï¼Œå¯ä»¥å°†ç³»ç»Ÿé€‚åº”åˆ°â€œè®°è€…-ä½œè€…â€äº’åŠ¨ä¹‹å¤–çš„å…¶ä»–æƒ…å¢ƒã€‚

```py
def _specify_system_message(self):
    """Specify the behavior of the journalist chatbot.
    The prompt is generated and optimized with GPT-4.

    Outputs:
    --------
    prompt: instructions for the chatbot.
    """       

    prompt = f"""You are a technical journalist interested in {self.topic}, 
    Your task is to distill a recently published scientific paper on this topic through
    an interview with the author, which is played by another chatbot.
    Your objective is to ask comprehensive and technical questions 
    so that anyone who reads the interview can understand the paper's main ideas and contributions, 
    even without reading the paper itself. 
    You're provided with the paper's summary to guide your initial questions.
    You must keep the following guidelines in mind:
    - Focus exclusive on the technical content of the paper.
    - Avoid general questions about {self.topic}, focusing instead on specifics related to the paper.
    - Only ask one question at a time.
    - Feel free to ask about the study's purpose, methods, results, and significance, 
    and clarify any technical terms or complex concepts. 
    - Your goal is to lead the conversation towards a clear and engaging summary.
    - Do not include any prefixed labels like "Interviewer:" or "Question:" in your question.

    [Abstract]: {self.abstract}"""

    return prompt
```

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¸ºè®°è€…æœºå™¨äººæä¾›äº†è®ºæ–‡çš„ç ”ç©¶é¢†åŸŸå’Œæ‘˜è¦ï¼Œä½œä¸ºåˆå§‹é—®é¢˜çš„åŸºç¡€ã€‚è¿™åæ˜ äº†ç°å®ä¸–ç•Œä¸­è®°è€…æœ€åˆå¯¹è®ºæ–‡äº†è§£ä¸å¤šï¼Œéœ€è¦é€šè¿‡æé—®æ¥è·å–æ›´å¤šä¿¡æ¯çš„æƒ…å¢ƒã€‚

æœ€åï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ª `step` æ–¹æ³•æ¥ä¸è®°è€…æœºå™¨äººäº’åŠ¨ï¼š

```py
def step(self, prompt):
    """Journalist chatbot asks question. 

    Args:
    ------
    prompt: Previos answer provided by the author bot.
    """
    response = self.conversation.predict(input=prompt)

    return response
```

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¾“å…¥æç¤ºå°†æ˜¯ä½œè€…æœºå™¨äººå¯¹è®°è€…æœºå™¨äººä¸Šä¸€ä¸ªé—®é¢˜çš„å›ç­”ã€‚å¦‚æœå¯¹è¯å°šæœªå¼€å§‹ï¼Œè¾“å…¥æç¤ºå°†ç®€å•ä¸ºâ€œå¼€å§‹å¯¹è¯â€ï¼Œä»¥æç¤ºè®°è€…æœºå™¨äººå¯åŠ¨é‡‡è®¿ã€‚

è¿™å°±æ˜¯è®°è€…æœºå™¨äººçš„å…¨éƒ¨å†…å®¹ã€‚ç°åœ¨è®©æˆ‘ä»¬è½¬å‘ä½œè€…æœºå™¨äººã€‚

## 4.3 ä½œè€…æœºå™¨äººç±»

ä½œè€…æœºå™¨äººçš„è§’è‰²æ˜¯æ ¹æ®ç ”ç©¶è®ºæ–‡å›ç­”è®°è€…æœºå™¨äººæå‡ºçš„é—®é¢˜ã€‚ä»¥ä¸‹æ˜¯ä½œè€…æœºå™¨äººçš„æ„é€ æ–¹æ³•ï¼š

```py
class AuthorBot(Chatbot):
    """Class definition for the author bot, created with LangChain."""

    def __init__(self, engine, vectorstore, debug=False):
        """Select backbone large language model, as well as instantiate 
        the memory for creating language chain in LangChain.

        Args:
        --------------
        engine: the backbone llm-based chat model.
        vectorstore: embedding vectors of the paper.
        """

        # Instantiate llm
        super().__init__(engine)

        # Instantiate memory
        self.chat_history = []

        # Instantiate embedding index
        self.vectorstore = vectorstore

        self.debug = debug
```

è¿™é‡Œæœ‰ä¸¤ç‚¹å˜åŒ–ï¼šé¦–å…ˆï¼Œä¸è®°è€…æœºå™¨äººä¸åŒï¼Œä½œè€…æœºå™¨äººåº”è¯¥èƒ½å¤Ÿè®¿é—®å®Œæ•´çš„è®ºæ–‡ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä¹‹å‰åˆ›å»ºçš„å‘é‡å­˜å‚¨éœ€è¦æä¾›ç»™æ„é€ å‡½æ•°ã€‚å¦å¤–ï¼Œè¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä¸å†ä½¿ç”¨å†…å­˜å¯¹è±¡ï¼ˆä¾‹å¦‚`ConversationBufferMemory`ï¼‰æ¥è·Ÿè¸ªèŠå¤©è®°å½•ã€‚ç›¸åï¼Œæˆ‘ä»¬å°†ç®€å•åœ°ä½¿ç”¨ä¸€ä¸ªåˆ—è¡¨æ¥å­˜å‚¨å†å²è®°å½•ï¼Œå¹¶åœ¨ä¹‹åæ˜ç¡®ä¼ é€’ç»™ä½œè€…æœºå™¨äººã€‚åˆ—è¡¨çš„æ¯ä¸ªå…ƒç´ å°†æ˜¯ä¸€ä¸ª (query, answer) çš„å…ƒç»„ã€‚åœ¨ LangChain ä¸­ï¼Œä¸¤ç§ç»´æŠ¤å¯¹è¯å†å²çš„æ–¹æ³•éƒ½è¢«æ”¯æŒã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä¸ºä½œè€…æœºå™¨äººè®¾ç½®å¯¹è¯é“¾ã€‚

```py
from langchain.chains import ConversationalRetrievalChain

def instruct(self, topic):
    """Determine the context of author chatbot. 

    Args:
    -------
    topic: the topic of the paper.
    """

    # Specify topic
    self.topic = topic

    # Define prompt template
    qa_prompt = ChatPromptTemplate.from_messages([
        SystemMessagePromptTemplate.from_template(self._specify_system_message()),
        HumanMessagePromptTemplate.from_template("{question}")
    ])

    # Create conversation chain
    self.conversation_qa = ConversationalRetrievalChain.from_llm(llm=self.llm, verbose=self.debug,
                                                                 retriever=self.vectorstore.as_retriever(
                                                                     search_kwargs={"k": 5}),
                                                                 return_source_documents=True,
                                                                combine_docs_chain_kwargs={'prompt': qa_prompt})
```

ç”±äºä½œè€…æœºå™¨äººéœ€è¦é€šè¿‡é¦–å…ˆæ£€ç´¢ç›¸å…³èƒŒæ™¯æ¥å›ç­”é—®é¢˜ï¼Œæˆ‘ä»¬é‡‡ç”¨äº† `ConversationalRetrievalChain`ã€‚å¼•ç”¨ LangChain çš„å®˜æ–¹æ–‡æ¡£ï¼š

> **å¯¹è¯æ£€ç´¢é“¾**é¦–å…ˆå°†èŠå¤©è®°å½•ï¼ˆæ— è®ºæ˜¯æ˜ç¡®ä¼ é€’çš„è¿˜æ˜¯ä»æä¾›çš„è®°å¿†ä¸­æ£€ç´¢åˆ°çš„ï¼‰å’ŒæŸ¥è¯¢åˆå¹¶æˆä¸€ä¸ªç‹¬ç«‹çš„é—®é¢˜ï¼Œç„¶åä»æ£€ç´¢å™¨ä¸­æŸ¥æ‰¾ç›¸å…³æ–‡æ¡£ï¼Œæœ€åå°†è¿™äº›æ–‡æ¡£å’ŒæŸ¥è¯¢ä¼ é€’ç»™é—®é¢˜å›ç­”é“¾ä»¥è¿”å›å“åº”ã€‚

å› æ­¤ï¼Œé™¤äº†åŸºç¡€ LLMï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä¸ºé“¾æä¾›ä¸€ä¸ªå‘é‡å­˜å‚¨ã€‚è¯·æ³¨æ„ï¼Œè¿™é‡Œæˆ‘ä»¬é€šè¿‡`search_kwargs`æŒ‡å®šäº†è¿”å›çš„ç›¸å…³æ–‡æ¡£ï¼ˆPDF å—ï¼‰çš„æ•°é‡ã€‚é€šå¸¸ï¼Œé€‰æ‹©æ­£ç¡®çš„æ•°é‡ä¸æ˜¯ä¸€é¡¹ç®€å•çš„ä»»åŠ¡ï¼Œéœ€è¦ä»”ç»†è€ƒè™‘å‡†ç¡®æ€§ã€ç›¸å…³æ€§ã€å…¨é¢æ€§å’Œè®¡ç®—èµ„æºçš„å¹³è¡¡ã€‚æœ€åï¼Œæˆ‘ä»¬å°†`return_source_documents`è®¾ç½®ä¸º Trueï¼Œè¿™å¯¹ç¡®ä¿é—®ç­”è¿‡ç¨‹ä¸­çš„é€æ˜æ€§å’Œå¯è¿½æº¯æ€§éå¸¸é‡è¦ã€‚

è¦ä¸ä½œè€…æœºå™¨äººäº’åŠ¨ï¼š

```py
def step(self, prompt):
    """Author chatbot answers question. 

    Args:
    ------
    prompt: question raised by journalist bot.

    Outputs:
    ------
    answer: the author bot's answer
    source_documents: documents that author bot used to answer questions
    """
    response = self.conversation_qa({"question": prompt, "chat_history": self.chat_history})
    self.chat_history.append((prompt, response["answer"]))

    return response["answer"], response["source_documents"]
```

å¦‚å‰æ‰€è¿°ï¼Œæˆ‘ä»¬æ˜ç¡®å°†èŠå¤©è®°å½•ï¼ˆä»¥å‰çš„æŸ¥è¯¢-å›ç­”å…ƒç»„åˆ—è¡¨ï¼‰æä¾›ç»™å¯¹è¯é“¾ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è¿˜éœ€è¦æ‰‹åŠ¨å°†æ–°è·å¾—çš„æŸ¥è¯¢-å›ç­”å…ƒç»„é™„åŠ åˆ°èŠå¤©è®°å½•ä¸­ã€‚å¯¹äºå“åº”ï¼Œæˆ‘ä»¬ä¸ä»…å¾—åˆ°ç­”æ¡ˆï¼Œè¿˜å¾—åˆ°ä½œè€…æœºå™¨äººç”¨äºç”Ÿæˆç­”æ¡ˆçš„æºæ–‡æ¡£ï¼ˆPDF å—ï¼‰ï¼Œè¿™äº›æ–‡æ¡£å°†åœ¨ç¨åç”¨äºçªå‡ºæ˜¾ç¤º PDF ä¸­çš„ç›¸åº”æ–‡æœ¬ã€‚

æœ€åï¼Œæˆ‘ä»¬å‘ŠçŸ¥ä½œè€…æœºå™¨äººè§’è‰²å¹¶æŒ‡å®šè¯¦ç»†çš„æŒ‡ä»¤ã€‚ä¸è®°è€…æœºå™¨äººä¸€æ ·ï¼Œä½œè€…æœºå™¨äººçš„æŒ‡ä»¤/æç¤ºä¹Ÿç”± ChatGPTï¼ˆGPT-4ï¼‰ç”Ÿæˆå’Œä¼˜åŒ–ã€‚

```py
def _specify_system_message(self):
    """Specify the behavior of the author chatbot.
    The prompt is generated and optimized by GPT-4.

    Outputs:
    --------
    prompt: instructions for the chatbot.
    """       

    prompt = f"""You are the author of a recently published scientific paper on {self.topic}.
    You are being interviewed by a technical journalist who is played by another chatbot and
    looking to write an article to summarize your paper.
    Your task is to provide comprehensive, clear, and accurate answers to the journalist's questions.
    Please keep the following guidelines in mind:
    - Try to explain complex concepts and technical terms in an understandable way, without sacrificing accuracy.
    - Your responses should primarily come from the relevant content of this paper, 
    which will be provided to you in the following, but you can also use your broad knowledge in {self.topic} to 
    provide context or clarify complex topics. 
    - Remember to differentiate when you are providing information directly from the paper versus 
    when you're giving additional context or interpretation. Use phrases like 'According to the paper...' for direct information, 
    and 'Based on general knowledge in the field...' when you're providing additional context.
    - Only answer one question at a time. Ensure that each answer is complete before moving on to the next question.
    - Do not include any prefixed labels like "Author:", "Interviewee:", Respond:", or "Answer:" in your answer.
    """

    prompt += """Given the following context, please answer the question.

    {context}"""

    return prompt
```

è¿™å°±æ˜¯æ„å»ºä½œè€…æœºå™¨äººçš„å…¨éƒ¨å†…å®¹ã€‚

## 4.4 å¿«é€Ÿæµ‹è¯•ï¼šé‡‡è®¿

è¯¥æ˜¯æ—¶å€™å¸¦ä¸¤ä¸ªæœºå™¨äººâ€œè¯•é©¾â€ä¸€ä¸‹äº†ï¼

ä¸ºäº†æ£€éªŒå¼€å‘çš„è®°è€…æœºå™¨äººå’Œä½œè€…æœºå™¨äººæ˜¯å¦èƒ½è¿›è¡Œæœ‰æ„ä¹‰çš„å¯¹è¯ä»¥è¾¾åˆ°æ¶ˆåŒ–è®ºæ–‡çš„ç›®çš„ï¼Œæˆ‘ä»¬é€‰æ‹©äº†ä¸€ç¯‡æ ·æœ¬ç§‘å­¦ç ”ç©¶è®ºæ–‡å¹¶è¿›è¡Œæµ‹è¯•ã€‚

æœ€è¿‘åœ¨ç ”ç©¶ç‰©ç†ä¿¡æ¯æœºå™¨å­¦ä¹ æ—¶ï¼Œæˆ‘é€‰æ‹©äº†ä¸€ç¯‡åä¸ºâ€œ[**æ”¹è¿›ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œçš„æ¨¡å‹é›†æˆè®­ç»ƒ**](https://arxiv.org/abs/2204.05108)**â€**ï¼ˆCC BY 4.0 è®¸å¯ï¼‰çš„ arXiv è®ºæ–‡è¿›è¡Œæµ‹è¯•ã€‚

```py
paper = 'Improved Training of Physics-Informed Neural Networks with Model Ensembles'

# Create embeddings
embedding = Embedder(engine='OpenAI')
embedding.load_n_process_document("../Papers/"+paper+".pdf")

# Set up vectorstore
vectorstore = embedding.create_vectorstore(store_path=paper)

# Fetch paper summary
paper_summary = embedding.create_summary(llm_engine='OpenAI')

# Instantiate journalist and author bot
journalist = JournalistBot('OpenAI')
author = AuthorBot('OpenAI', vectorstore)

# Provide instruction
journalist.instruct(topic='physics-informed machine learning', abstract=paper_summary)
author.instruct('physics-informed machine learning')

# Start conversation
for i in range(4):
    if i == 0:
        question = journalist.step('Start the conversation')
    else:
        question = journalist.step(answer)
    print("ğŸ‘¨â€ğŸ« Journalist: " + question)

    answer, source = author.step(question)
    print("ğŸ‘©â€ğŸ“ Author: " + answer)
```

ç”Ÿæˆçš„å¯¹è¯è„šæœ¬å¦‚ä¸‹æ‰€ç¤ºã€‚è¯·æ³¨æ„ï¼Œä¸ºäº†èŠ‚çœç©ºé—´ï¼Œä¸€äº›ä½œè€…æœºå™¨äººçš„å›ç­”æœªå®Œå…¨æ˜¾ç¤ºï¼š

![](img/a6e2d39406c7e6052ecb73d4b7f171fe.png)

å¼€å‘çš„è®°è€…æœºå™¨äººå’Œä½œè€…æœºå™¨äººçš„é‡‡è®¿ã€‚ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰

ç”±äºä½œè€…æœºå™¨äººä»…è¢«åŠ¨å›ç­”é—®é¢˜ï¼ˆå³ä¼ ç»Ÿçš„é—®ç­”ä»£ç†ï¼‰ï¼Œæˆ‘ä»¬å°†é‡ç‚¹æ”¾åœ¨è®°è€…æœºå™¨äººçš„è¡Œä¸ºä¸Šï¼Œä»¥è¯„ä¼°å®ƒæ˜¯å¦èƒ½å¤Ÿæœ‰æ•ˆå¼•å¯¼é‡‡è®¿ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è®°è€…æœºå™¨äººé¦–å…ˆæå‡ºäº†ä¸€ä¸ªå…³äºè®ºæ–‡çš„ä¸€èˆ¬æ€§é—®é¢˜ï¼ˆåŠ¨æœºï¼‰ï¼Œç„¶åè°ƒæ•´é—®é¢˜ä»¥æ·±å…¥æ¢è®¨æè®®ç­–ç•¥çš„æ–¹æ³•ã€‚æ€»ä½“è€Œè¨€ï¼Œå¼€å‘çš„è®°è€…æœºå™¨äººçš„è¡Œä¸ºç¬¦åˆæˆ‘ä»¬çš„é¢„æœŸï¼Œèƒ½å¤Ÿè¿›è¡Œé‡‡è®¿ä»¥æç‚¼å‡ºè®ºæ–‡çš„å…³é”®ç‚¹ã€‚è¡¨ç°ä¸é”™ğŸ˜ƒ

# 5\. ç‰¹æ€§ 3ï¼šç”¨æˆ·äº’åŠ¨

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä¹‹å‰çš„å®éªŒå°è£…åˆ°ä¸€ä¸ªåˆé€‚çš„ç”¨æˆ·ç•Œé¢ä¸­ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†è§£å†³ä¸‰ä¸ªç”¨æˆ·æ•…äº‹ï¼Œä»¥é€æ­¥æ„å»ºæ‰€éœ€çš„åŠŸèƒ½ã€‚

## 5.1 åˆ›å»ºèŠå¤©ç¯å¢ƒï¼ˆåœ¨ Jupyter Notebook ä¸­ï¼‰

æˆ‘ä»¬ä»ç¬¬ 3 ä¸ªç”¨æˆ·æ•…äº‹å¼€å§‹ï¼š

> â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›æœ‰ä¸€ä¸ªç›´è§‚çš„èŠå¤©ç•Œé¢ï¼Œå¯ä»¥å®æ—¶è§‚çœ‹èŠå¤©æœºå™¨äººçš„å¯¹è¯å±•å¼€ã€‚â€ï¼ˆç”± GPT-4 ç”Ÿæˆï¼‰

ä¸ºäº†ä¿æŒç®€å•ï¼Œæˆ‘ä»¬é€‰æ‹© Jupyter å°éƒ¨ä»¶ï¼Œå› ä¸ºå®ƒä»¬å…è®¸åœ¨ Jupyter Notebook ä¸­å¿«é€Ÿæ„å»ºæ•´ä¸ªèŠå¤©ç¯å¢ƒã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬è®¾ç½®æ˜¾ç¤ºå¯¹è¯çš„å¸ƒå±€ï¼š

```py
import ipywidgets as widgets
from IPython.display import display

# Create button
bot_ask = widgets.Button(description="Journalist Bot ask")

# Chat history
chat_log = widgets.HTML(
    value='',
    placeholder='',
    description='',
)

# Attach callbacks
bot_ask.on_click(bot_ask_clicked)

# Arrange widgets layout
first_row = widgets.HBox([bot_ask])

# Display the UI
display(chat_log, widgets.VBox([first_row]))
```

æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªæŒ‰é’®ï¼ˆ`bot_ask`ï¼‰ï¼Œå½“ç”¨æˆ·ç‚¹å‡»å®ƒæ—¶ï¼Œä¼šè°ƒç”¨ä¸€ä¸ªå›è°ƒå‡½æ•°`bot_ask_clicked`ï¼Œå¹¶ç”Ÿæˆä¸€è½®è®°è€…å’Œä½œè€…æœºå™¨äººä¹‹é—´çš„å¯¹è¯ã€‚ä¹‹åï¼Œæˆ‘ä»¬ä½¿ç”¨ HTML å°éƒ¨ä»¶åœ¨ç¬”è®°æœ¬ä¸­ä»¥ HTML å†…å®¹çš„å½¢å¼æ˜¾ç¤ºå¯¹è¯ã€‚

å›è°ƒå‡½æ•°`bot_ask_clicked`å®šä¹‰å¦‚ä¸‹ã€‚é™¤äº†æ˜¾ç¤ºè®°è€…æœºå™¨äººçš„é—®é¢˜å’Œä½œè€…æœºå™¨äººçš„å›ç­”å¤–ï¼Œæˆ‘ä»¬è¿˜æŒ‡æ˜äº†ç›¸å…³æºæ–‡æœ¬çš„ä½ç½®ï¼ˆå³é¡µé¢ç¼–å·ï¼‰ã€‚è¿™æ˜¯å¯èƒ½çš„ï¼Œå› ä¸ºä½œè€…æœºå™¨äººçš„`step()`æ–¹æ³•è¿˜è¿”å›`source`å˜é‡ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«é¡µé¢å†…å®¹åŠå…¶ç›¸å…³å…ƒæ•°æ®çš„ LangChain `Document`å¯¹è±¡åˆ—è¡¨ã€‚

```py
def bot_ask_clicked(b):

    if chat_log.value == '':
        # Starting conversation 
        bot_question = journalist.step("Start the conversation")
        line_breaker = ""

    else:
        # Ongoing conversation
        bot_question = journalist.step(chat_log.value.split("<br><br>")[-1])
        line_breaker = "<br><br>"

    # Journalist question
    chat_log.value += line_breaker + "<b style='color:blue'>ğŸ‘¨â€ğŸ« Journalist Bot:</b> " + bot_question      

    # Author bot answers
    response, source = author.step(bot_question)  

    # Author answer with source
    page_numbers = [str(src.metadata['page']+1) for src in source]
    unique_page_numbers = list(set(page_numbers))
    chat_log.value += "<br><b style='color:green'>ğŸ‘©â€ğŸ“ Author Bot:</b> " + response + "<br>"
    chat_log.value += "(For details, please check the highlighted text on page(s): " + ', '.join(unique_page_numbers) + ")"
```

ç»¼åˆè€ƒè™‘ï¼Œæˆ‘ä»¬å¾—åˆ°äº†ä»¥ä¸‹ç•Œé¢ï¼š

![](img/c229c6cb979f88ccfa584285bad8c376.png)

èŠå¤©ç•Œé¢ã€‚ï¼ˆä½œè€…æä¾›çš„å›¾ç‰‡ï¼‰

## 5.2 å®ç° PDF é«˜äº®åŠŸèƒ½

åœ¨æˆ‘ä»¬å½“å‰çš„ UI ä¸­ï¼Œæˆ‘ä»¬ä»…æŒ‡æ˜äº†ä½œè€…æœºå™¨äººæŸ¥æ‰¾è®°è€…æœºå™¨äººé—®é¢˜ç­”æ¡ˆçš„é¡µé¢ã€‚ç†æƒ³æƒ…å†µä¸‹ï¼Œç”¨æˆ·å¸Œæœ›åœ¨åŸå§‹ PDF ä¸­çªå‡ºæ˜¾ç¤ºç›¸å…³æ–‡æœ¬ï¼Œä»¥ä¾¿å¿«é€Ÿå‚è€ƒã€‚è¿™æ˜¯ç¬¬ 4 ä¸ªç”¨æˆ·æ•…äº‹çš„åŠ¨æœºï¼š

> â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›æ ¹æ®èŠå¤©æœºå™¨äººçš„è®¨è®ºï¼Œåœ¨åŸå§‹ç ”ç©¶è®ºæ–‡ä¸­çªå‡ºæ˜¾ç¤ºç›¸åº”çš„éƒ¨åˆ†ã€‚è¿™å°†å¸®åŠ©æˆ‘å¿«é€Ÿå®šä½åœ¨å¯¹è¯è¿‡ç¨‹ä¸­è®¨è®ºçš„ä¿¡æ¯æ¥æºã€‚â€ï¼ˆç”± GPT-4 ç”Ÿæˆï¼‰

ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† PyMuPDF åº“æ¥æœç´¢ç›¸å…³æ–‡æœ¬å¹¶æ‰§è¡Œæ–‡æœ¬é«˜äº®ï¼š

```py
import fitz

def highlight_PDF(file_path, phrases, output_path):
    """Search and highlight given texts in PDF.

    Args:
    --------
    file_path: PDF file path
    phrases: a list of texts (in string)
    output_path: save and output PDF
    """

    # Open PDF
    doc = fitz.open(file_path)

    # Search the doc
    for page in doc:
        for phrase in phrases:            
            text_instances = page.search_for(phrase)

            # Highlight texts
            for inst in text_instances:
                highlight = page.add_highlight_annot(inst)

    # Output PDF
    doc.save(output_path, garbage=4)
```

åœ¨ä¸Šè¿°ä»£ç ä¸­ï¼Œ`phrases`æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨ï¼Œæ¯ä¸ªå­—ç¬¦ä¸²è¡¨ç¤ºä½œè€…æœºå™¨äººç”¨æ¥ç”Ÿæˆå›ç­”çš„æºæ–‡æœ¬ä¹‹ä¸€ã€‚ä¸ºäº†é«˜äº®æ–‡æœ¬ï¼Œä»£ç é¦–å…ˆéå† PDF çš„æ¯ä¸€é¡µï¼ŒæŸ¥æ‰¾è¯¥é¡µæ˜¯å¦åŒ…å«`phrase`ã€‚ä¸€æ—¦æ‰¾åˆ°çŸ­è¯­ï¼Œå®ƒå°†åœ¨åŸå§‹ PDF ä¸­è¿›è¡Œé«˜äº®æ˜¾ç¤ºã€‚

ä¸ºäº†å°†æ­¤é«˜äº®åŠŸèƒ½é›†æˆåˆ°æˆ‘ä»¬ä¹‹å‰å¼€å‘çš„èŠå¤© UI ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦æ›´æ–°å›è°ƒå‡½æ•°ï¼š

```py
def create_bot_ask_callback(title):

    def bot_ask_clicked(b):

        if chat_log.value == '':
            # Starting conversation 
            bot_question = journalist.step("Start the conversation")
            line_breaker = ""

        else:
            # Ongoing conversation
            bot_question = journalist.step(chat_log.value.split("<br><br>")[-1])
            line_breaker = "<br><br>"

        chat_log.value += line_breaker + "<b style='color:blue'>ğŸ‘¨â€ğŸ« Journalist Bot:</b> " + bot_question      

        # Author bot answers
        response, source = author.step(bot_question)  

        ##### NEW: Highlight relevant text in PDF
        phrases = [src.page_content for src in source]
        paper_path = "../Papers/"+title+".pdf"
        highlight_PDF(paper_path, phrases, 'highlighted.pdf')
        ##### NEW

        page_numbers = [str(src.metadata['page']+1) for src in source]
        unique_page_numbers = list(set(page_numbers))
        chat_log.value += "<br><b style='color:green'>ğŸ‘©â€ğŸ“ Author Bot:</b> " + response + "<br>"
        chat_log.value += "(For details, please check the highlighted text on page(s): " + ', '.join(unique_page_numbers) + ")"

    return bot_ask_clicked
```

å°½ç®¡æˆ‘ä»¬çš„ UI å¤–è§‚ä¿æŒä¸å˜ï¼š

![](img/e8b533bd5592b34a12daba5bd0529daa.png)

åœ¨åº•å±‚ï¼Œæˆ‘ä»¬å°†æœ‰ä¸€ä¸ªæ–°çš„ PDF æ–‡ä»¶ï¼Œå…¶ä¸­ç›¸å…³æ–‡æœ¬ï¼ˆåœ¨ç¬¬ 1 å’Œç¬¬ 10 é¡µï¼‰è¢«é€‚å½“åœ°é«˜äº®æ˜¾ç¤ºï¼š

![](img/99ac9965f679532207a325f2837beb8c.png)

## 5.3 å…è®¸ç”¨æˆ·è¾“å…¥é—®é¢˜

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œè¿™ä¸¤ä¸ªæœºå™¨äººçš„å¯¹è¯éƒ½æ˜¯è‡ªä¸»çš„ã€‚ç†æƒ³æƒ…å†µä¸‹ï¼Œå¦‚æœç”¨æˆ·è§‰å¾—åˆé€‚ï¼Œä¹Ÿåº”è¯¥èƒ½å¤Ÿæå‡ºè‡ªå·±çš„é—®é¢˜ã€‚è¿™æ­£æ˜¯æˆ‘ä»¬è¦è§£å†³çš„ç¬¬ 5 ä¸ªç”¨æˆ·æ•…äº‹ï¼š

> â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿåœ¨èŠå¤©æœºå™¨äººçš„å¯¹è¯ä¸­è¿›è¡Œå¹²é¢„å¹¶æå‡ºè‡ªå·±çš„é—®é¢˜ï¼Œè¿™æ ·æˆ‘å¯ä»¥å¼•å¯¼å¯¹è¯å¹¶ä»è®ºæ–‡ä¸­æå–æˆ‘éœ€è¦çš„ä¿¡æ¯ã€‚â€ï¼ˆç”± GPT-4 ç”Ÿæˆï¼‰

ä¸ºäº†å®ç°è¿™ä¸ªç›®æ ‡ï¼Œæˆ‘ä»¬å¯ä»¥æ·»åŠ å¦ä¸€ä¸ªæŒ‰é’®ï¼Œè®©ç”¨æˆ·å†³å®šæ˜¯å¦ç”±è®°è€…æœºå™¨äººæˆ–ç”¨æˆ·å‘èµ·æ–°ä¸€è½®çš„äº¤æµï¼š

```py
# Create "user ask" button
user_ask = widgets.Button(description="User ask")

# Define callback
def create_user_ask_callback(title):

    def user_ask_clicked(b):

        chat_log.value += "<br><br><b style='color:purple'>ğŸ™‹â€â™‚ï¸You:</b> " + user_input.value

        # Author bot answers
        response, source = author.step(user_input.value)

        # Highlight relevant text in PDF
        phrases = [src.page_content for src in source]
        paper_path = "../Papers/"+title+".pdf"
        highlight_PDF(paper_path, phrases, 'highlighted.pdf')

        page_numbers = [str(src.metadata['page']+1) for src in source]
        unique_page_numbers = list(set(page_numbers))
        chat_log.value += "<br><b style='color:green'>ğŸ‘©â€ğŸ“ Author Bot:</b> " + response + "<br>"
        chat_log.value += "(For details, please check the highlighted text on page(s): " + ', '.join(unique_page_numbers) + ")"

        # Inform journalist bot about the asked questions 
        journalist.memory.chat_memory.add_user_message(user_input.value)

        # Clear user input
        user_input.value = ""

    return user_ask_clicked
```

ä¸Šè¿°å›è°ƒå‡½æ•°æœ¬è´¨ä¸Šä¸å®šä¹‰è®°è€…-ä½œè€…äº’åŠ¨çš„å›è°ƒå‡½æ•°ç›¸åŒã€‚å”¯ä¸€çš„åŒºåˆ«æ˜¯â€œé—®é¢˜â€å°†ç”±ç”¨æˆ·ç›´æ¥è¾“å…¥ã€‚æ­¤å¤–ï¼Œä¸ºäº†ä¿æŒé‡‡è®¿é€»è¾‘çš„ä¸€è‡´æ€§ï¼Œæˆ‘ä»¬å°†ç”¨æˆ·é—®é¢˜é™„åŠ åˆ°è®°è€…æœºå™¨äººçš„è®°å¿†ä¸­ï¼Œå°±åƒç”¨æˆ·æå‡ºçš„é—®é¢˜æ˜¯ç”±è®°è€…æœºå™¨äººæå‡ºçš„ä¸€æ ·ã€‚

æˆ‘ä»¬ç›¸åº”åœ°æ›´æ–°äº†ä¸»è¦çš„ç”¨æˆ·ç•Œé¢é€»è¾‘ï¼š

```py
# Chat history
chat_log = widgets.HTML(
    value='',
    placeholder='',
    description='',
)

# User input question
user_input = widgets.Text(
    value='',
    placeholder='Question',
    description='',
    disabled=False,
    layout=widgets.Layout(width="60%")
)

# Attach callbacks
bot_ask.on_click(create_bot_ask_callback(paper))
user_ask.on_click(create_user_ask_callback(paper))

# Arrange the widgets
first_row = widgets.HBox([bot_ask])
second_row = widgets.HBox([user_ask, user_input])

# Display the UI
display(chat_log, widgets.VBox([first_row, second_row]))
```

è¿™æ˜¯æˆ‘ä»¬å¾—åˆ°çš„ç»“æœï¼Œç”¨æˆ·å¯ä»¥è¾“å…¥è‡ªå·±çš„é—®é¢˜ï¼Œå¹¶ç”±ä½œè€…æœºå™¨äººè¿›è¡Œå›ç­”ï¼š

![](img/37cd0f3b65a6b848749b8cd02a2b9a99.png)

é™¤äº†è®©è®°è€…æœºå™¨äººæé—®å¤–ï¼Œç”¨æˆ·è¿˜æœ‰æœºä¼šæå‡ºè‡ªå·±çš„é—®é¢˜ã€‚ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰

## 5.4 å…è®¸ä¸‹è½½ç”Ÿæˆçš„è„šæœ¬

ä¸€åˆ‡é¡ºåˆ©ï¼ä½œä¸ºæœ€åä¸€ä¸ªè¦å®ç°çš„åŠŸèƒ½ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿå°†å¯¹è¯å†å²ä¿å­˜åˆ°ç£ç›˜ä»¥ä¾›ä»¥åå‚è€ƒã€‚è¿™æ˜¯ç¬¬ 6 ä¸ªç”¨æˆ·æ•…äº‹çš„ç›®æ ‡ï¼š

> â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿä¸‹è½½èŠå¤©æœºå™¨äººå¯¹è¯çš„è®°å½•ã€‚è¿™å°†è®©æˆ‘ç¦»çº¿æŸ¥çœ‹å…³é”®ç‚¹æˆ–ä¸åŒäº‹åˆ†äº«ä¿¡æ¯ã€‚â€ï¼ˆç”± GPT-4 ç”Ÿæˆï¼‰

ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªæ–°çš„ä¸‹è½½è„šæœ¬æŒ‰é’®ï¼Œå¹¶å°†å›è°ƒå‡½æ•°é™„åŠ åˆ°è¯¥æŒ‰é’®ã€‚åœ¨è¿™ä¸ªå›è°ƒå‡½æ•°ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† PDFDocument å°†å¯¹è¯è„šæœ¬è½¬æ¢ä¸º PDF æ–‡ä»¶ï¼š

```py
from pdfdocument.document import PDFDocument

download = widgets.Button(description="Download paper summary",
                         layout=widgets.Layout(width='auto'))

def create_download_callback(title):

    def download_clicked(b):
        pdf = PDFDocument('paper_summary.pdf')
        pdf.init_report()

        # Remove HTML tags
        chat_history = re.sub('<.*?>', '', chat_log.value)  

        # Remove emojis
        chat_history = chat_history.replace('ğŸ‘¨â€ğŸ«', '')
        chat_history = chat_history.replace('ğŸ‘©â€ğŸ“', '')
        chat_history = chat_history.replace('ğŸ™‹â€â™‚ï¸', '')

        # Add line breaks
        chat_history = chat_history.replace('Journalist Bot:', '\n\n\nJournalist: ')
        chat_history = chat_history.replace('Author Bot:', '\n\nAuthor: ')
        chat_history = chat_history.replace('You:', '\n\n\nYou: ')

        pdf.h2("Paper Summary: " + title)
        pdf.p(chat_history)
        pdf.generate()

        # Download PDF
        print('PDF generated successfully in the local folder!')

    return download_clicked
```

æˆ‘ä»¬ç›¸åº”åœ°æ›´æ–°äº†ä¸»è¦çš„ç”¨æˆ·ç•Œé¢é€»è¾‘ï¼š

```py
# Chat history
chat_log = widgets.HTML(
    value='',
    placeholder='',
    description='',
)

# User input question
user_input = widgets.Text(
    value='',
    placeholder='Question',
    description='',
    disabled=False,
    layout=widgets.Layout(width="60%")
)

# Attach callbacks
bot_ask.on_click(create_bot_ask_callback(paper))
user_ask.on_click(create_user_ask_callback(paper))
download.on_click(create_download_callback(paper))

# Arrange the widgets
first_row = widgets.HBox([bot_ask])
second_row = widgets.HBox([user_ask, user_input])
third_row = widgets.HBox([download])

# Display the UI
display(chat_log, widgets.VBox([first_row, second_row, third_row]))
```

ç°åœ¨ï¼Œç”¨æˆ·ç•Œé¢ä¸­å‡ºç°äº†ä¸€ä¸ªä¸‹è½½æŒ‰é’®ã€‚å½“ç”¨æˆ·ç‚¹å‡»å®ƒæ—¶ï¼Œä¼šè‡ªåŠ¨ç”Ÿæˆå¹¶ä¸‹è½½ä¸€ä»½è®ºæ–‡æ€»ç»“çš„ PDF æ–‡ä»¶åˆ°æœ¬åœ°æ–‡ä»¶å¤¹ï¼š

![](img/fd7da4e202f776400d99d8d260d01c21.png)

ç”¨æˆ·ç°åœ¨å¯ä»¥é€‰æ‹©ä¸‹è½½ç”Ÿæˆå¯¹è¯çš„è„šæœ¬ã€‚ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰

# 6\. å†²åˆºè¯„å®¡ï¼šå±•ç¤ºæ¼”ç¤ºï¼

ç°åœ¨æ˜¯æ—¶å€™å±•ç¤ºæˆ‘ä»¬çš„è¾›å‹¤å·¥ä½œğŸ’ª

åœ¨è¿™ä¸ªæ¼”ç¤ºä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†æˆ‘ä»¬å¼€å‘çš„åŒèŠå¤©æœºå™¨äººç³»ç»Ÿçš„å…¨éƒ¨åŠŸèƒ½ï¼š

+   è¿™ä¸¤ä¸ªæœºå™¨äººå¯ä»¥è‡ªä¸»è¿›è¡Œé‡‡è®¿ï¼Œç›®çš„æ˜¯æ¶ˆåŒ–è®ºæ–‡çš„ä¸»è¦è§‚ç‚¹ã€‚

+   ç”¨æˆ·ä¹Ÿå¯ä»¥è¿›å…¥å¯¹è¯å¹¶æå‡ºæ„Ÿå…´è¶£çš„é—®é¢˜ã€‚

+   ç”Ÿæˆçš„ç­”æ¡ˆçš„ç›¸å…³æ–‡æœ¬ä¼šåœ¨åŸå§‹ PDF ä¸­è‡ªåŠ¨é«˜äº®æ˜¾ç¤ºã€‚

+   å¯¹è¯å†å²å¯ä»¥ä¸‹è½½åˆ°æœ¬åœ°æ–‡ä»¶å¤¹ã€‚

æˆ‘ä»¬æˆåŠŸè§£å†³äº†æ‰€æœ‰ç”¨æˆ·æ•…äº‹ï¼Œå¹²å¾—å¥½ğŸ‰ ç°åœ¨å†²åˆºè¯„å®¡å·²ç»ç»“æŸï¼Œæ˜¯æ—¶å€™è¿›è¡Œä¸€äº›å›é¡¾äº†ã€‚

# 7\. å†²åˆºå›é¡¾

åœ¨è¿™ä¸ªé¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬ä¸“æ³¨äºè§£å†³é«˜æ•ˆæ¶ˆåŒ–å¤æ‚ç ”ç©¶è®ºæ–‡çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªåŒèŠå¤©æœºå™¨äººç³»ç»Ÿï¼Œå…¶ä¸­ä¸€ä¸ªæœºå™¨äººæ‰®æ¼”â€œè®°è€…â€ï¼Œå¦ä¸€ä¸ªæœºå™¨äººæ‰®æ¼”â€œä½œè€…â€ï¼Œä¸¤ä¸ªæœºå™¨äººè¿›è¡Œé‡‡è®¿ã€‚è¿™æ ·ï¼Œè®°è€…æœºå™¨äººå¯ä»¥ä»£è¡¨ç”¨æˆ·æŸ¥è¯¢è®ºæ–‡çš„å…³é”®ç‚¹ã€‚è¿™æ˜¯æœ‰ç›Šçš„ï¼Œå› ä¸ºå®ƒæ¶ˆé™¤äº†ç”¨æˆ·è‡ªè¡Œè®¾è®¡é—®é¢˜çš„éœ€æ±‚â€”â€”è¿™ä¸€æ´»åŠ¨åœ¨å¤„ç†ä¸ç†Ÿæ‚‰çš„ä¸»é¢˜æ—¶å¯èƒ½æ—¢å…·æœ‰æŒ‘æˆ˜æ€§åˆè€—æ—¶ã€‚

è®¾è®¡çš„åŒèŠå¤©æœºå™¨äººæ–¹æ³•çš„æˆåŠŸå…³é”®åœ¨äºè®°è€…æœºå™¨äººå¼•å¯¼é‡‡è®¿å¹¶ç”Ÿæˆæœ‰è§åœ°ä¸”ç›¸å…³çš„é—®é¢˜çš„èƒ½åŠ›ã€‚åœ¨å½“å‰çš„å®ç°ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† GPT-3.5-Turbo ä½œä¸ºä¸»è¦çš„è¯­è¨€æ¨¡å‹ã€‚ä¸ºäº†è¿›ä¸€æ­¥æå‡ç”¨æˆ·ä½“éªŒï¼Œå¯èƒ½éœ€è¦ä½¿ç”¨ GPT-4 æ¥å¢å¼ºè®°è€…æœºå™¨äººçš„æ¨ç†èƒ½åŠ›ã€‚

å¦å¤–é‡è¦çš„æ˜¯ï¼Œè®°è€…æœºå™¨äººéœ€è¦èƒ½å¤Ÿè§£é‡Šå’Œç†è§£åœ¨ç›¸å…³ç ”ç©¶é¢†åŸŸä¸­ä½¿ç”¨çš„æŠ€æœ¯æœ¯è¯­å’Œæ¦‚å¿µã€‚é™¤äº†ä½¿ç”¨å…ˆè¿›çš„è¯­è¨€æ¨¡å‹ï¼Œé’ˆå¯¹ç›®æ ‡é¢†åŸŸçš„ç ”ç©¶è®ºæ–‡å¯¹ç°æœ‰è¯­è¨€æ¨¡å‹è¿›è¡Œå¾®è°ƒå¯èƒ½æ˜¯ä¸€ç§æœ‰å‰æ™¯çš„ç­–ç•¥ã€‚

å±•æœ›æœªæ¥ï¼Œæˆ‘ä»¬å¯ä»¥æ‰©å±•æˆ‘ä»¬å½“å‰çš„é¡¹ç›®ï¼Œæœ‰å‡ ç§å¯èƒ½æ€§ï¼š

+   **æ›´å¥½çš„ UI è®¾è®¡ã€‚** ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† Jupyter Notebook æ¥å±•ç¤ºåŒèŠå¤©æœºå™¨äººç³»ç»Ÿçš„ä¸»è¦ç†å¿µã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„åº“ï¼ˆä¾‹å¦‚ Streamlitï¼‰æ¥æ„å»ºæ›´ç”¨æˆ·å‹å¥½ã€äº’åŠ¨æ€§æ›´å¼ºçš„ UIã€‚

+   **å¤šæ¨¡æ€èƒ½åŠ›ã€‚** ä¾‹å¦‚ï¼Œå¯ä»¥ä½¿ç”¨æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æŠ€æœ¯ä¸ºç”Ÿæˆçš„è„šæœ¬åˆ›å»ºéŸ³é¢‘ã€‚è¿™å¯¹ç”¨æˆ·å¾ˆæœ‰å¸®åŠ©ï¼Œå› ä¸ºä»–ä»¬å¯ä»¥åœ¨é€šå‹¤ã€é”»ç‚¼æˆ–å…¶ä»–é˜…è¯»ä¸ä¾¿çš„æ´»åŠ¨ä¸­ç»§ç»­æ¶ˆè€—å†…å®¹ã€‚

+   **è®¿é—®å¤–éƒ¨æ•°æ®åº“ã€‚** å¦‚æœåŒèŠå¤©æœºå™¨äººç³»ç»Ÿèƒ½å¤Ÿè®¿é—®æ›´å¤§çš„å¤–éƒ¨ç ”ç©¶è®ºæ–‡åº“ï¼Œé‚£å°†æ˜¯éå¸¸æ£’çš„ï¼Œè¿™æ ·ä½œè€…æœºå™¨äººå¯ä»¥æä¾›ä¸é¢†åŸŸå†…æœ€æ–°å‘å±•çš„æ¯”è¾ƒåˆ†æï¼Œä»è€Œç»¼åˆå¤šä¸ªè®ºæ–‡çš„è§è§£ã€‚

+   **ç”Ÿæˆæ–‡çŒ®ç»¼è¿°ã€‚** ç”±äºç”Ÿæˆçš„è®¿è°ˆè„šæœ¬å¯ä»¥ä½œä¸ºæ¯”è®ºæ–‡æ‘˜è¦æ›´ä¸°å¯Œçš„è®ºæ–‡ç²¾åï¼Œæˆ‘ä»¬å¯ä»¥é¦–å…ˆæ”¶é›†ç‰¹å®šç ”ç©¶é¢†åŸŸä¸­å„ç§è®ºæ–‡çš„è„šæœ¬ï¼Œç„¶åè¯·æ±‚ä¸€ä¸ªå•ç‹¬çš„è¯­è¨€æ¨¡å‹åŸºäºåˆ†æè¿™äº›ç§¯ç´¯çš„è®¿è°ˆè„šæœ¬ç”Ÿæˆè¯¥é¢†åŸŸçš„ç»¼åˆè¯„è¿°ã€‚è¿™ä¸€åŠŸèƒ½å¯¹äºç ”ç©¶äººå‘˜åœ¨å¯åŠ¨æ–°çš„ç ”ç©¶é¡¹ç›®æˆ–æ–‡çŒ®ç»¼è¿°è®ºæ–‡æ—¶å°¤å…¶æœ‰ä»·å€¼ã€‚

æˆ‘ä»¬çš„å†²åˆºçœŸæ˜¯å¯Œæœ‰æˆæ•ˆï¼å¦‚æœä½ è§‰å¾—æˆ‘çš„å†…å®¹æœ‰ç”¨ï¼Œå¯ä»¥åœ¨[è¿™é‡Œ](https://www.buymeacoffee.com/Shuaiguo09f)è¯·æˆ‘å–æ¯å’–å•¡ğŸ¤— éå¸¸æ„Ÿè°¢ä½ çš„æ”¯æŒï¼å’Œå¾€å¸¸ä¸€æ ·ï¼Œä½ å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/ShuaiGuo16/research_paper_digesting_with_dual_chatbot)æ‰¾åˆ°åŒ…å«å®Œæ•´ä»£ç çš„é…å¥—ç¬”è®°æœ¬ğŸ’» æœŸå¾…ä¸ä½ åˆ†äº«æ›´å¤šä»¤äººå…´å¥‹çš„ LLM é¡¹ç›®ã€‚æ•¬è¯·å…³æ³¨ï¼
