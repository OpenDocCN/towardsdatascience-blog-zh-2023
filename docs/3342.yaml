- en: 'Unlocking the Power of Big Data: The Fascinating World of Graph Learning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/unlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c?source=collection_archive---------8-----------------------#2023-11-09](https://towardsdatascience.com/unlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c?source=collection_archive---------8-----------------------#2023-11-09)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Harnessing Deep Learning to Transform Untapped Data into a Strategic Asset for
    Long-Term Competitiveness.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@mathieulaversin3?source=post_page-----c0a2ddf4043c--------------------------------)[![Mathieu
    Laversin](../Images/9ca7f2528f9fe655e2aa18e382e560f9.png)](https://medium.com/@mathieulaversin3?source=post_page-----c0a2ddf4043c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c0a2ddf4043c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c0a2ddf4043c--------------------------------)
    [Mathieu Laversin](https://medium.com/@mathieulaversin3?source=post_page-----c0a2ddf4043c--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd6ebca0f38b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c&user=Mathieu+Laversin&userId=d6ebca0f38b4&source=post_page-d6ebca0f38b4----c0a2ddf4043c---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c0a2ddf4043c--------------------------------)
    ·12 min read·Nov 9, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc0a2ddf4043c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c&user=Mathieu+Laversin&userId=d6ebca0f38b4&source=-----c0a2ddf4043c---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc0a2ddf4043c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c&source=-----c0a2ddf4043c---------------------bookmark_footer-----------)![](../Images/a392b226af14c62e715a11a498e32b34.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Nathan Anderson](https://unsplash.com/@nathananderson?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/night-sky?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: Large companies generate and collect vast amounts of data, as an example and
    90% of this data has been created in recent years. Yet, **73% of these data remain
    unused [1]**. However, as you may know, data is a goldmine for companies working
    with Big Data.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning is constantly evolving, and today, the challenge is to adapt these
    new solutions to specific goals to stand out and enhance long-term competitiveness.
  prefs: []
  type: TYPE_NORMAL
- en: My previous manager had a good intuition that these two events could come together,
    and together facilitate access, requests, and above all stop wasting time and
    money.
  prefs: []
  type: TYPE_NORMAL
- en: '**Why is this data left unused?**'
  prefs: []
  type: TYPE_NORMAL
- en: Accessing it takes too long, rights verification, and especially content checks
    are necessary before granting access to users.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/90c71b29e47c2a19feb1d4229fd0a774.png)'
  prefs: []
  type: TYPE_IMG
- en: Visualize reasons for data being unused. (generated by Bing Image Creator)
  prefs: []
  type: TYPE_NORMAL
- en: '**Is there a solution to automatically document new data?**'
  prefs: []
  type: TYPE_NORMAL
- en: If you’re not familiar with large enterprises, no problem — I wasn’t either.
    An interesting concept in such environments is the use of Big Data, particularly
    **HDFS** (Hadoop Distributed File System), which is a cluster designed to consolidate
    all of the company’s data. Within this vast pool of data, you can find structured
    data, and within that structured data, Hive columns are referenced. Some of these
    columns are used to create additional tables and likely serve as sources for various
    datasets. Companies keep the informations between some table by the lineage.
  prefs: []
  type: TYPE_NORMAL
- en: These columns also have various characteristics (domain, type, name, date, owner…).
    The goal of the project was to document the data known as physical data with business
    data.
  prefs: []
  type: TYPE_NORMAL
- en: '**Distinguishing between physical and business data:**'
  prefs: []
  type: TYPE_NORMAL
- en: To put it simply, physical data is a column name in a table, and business data
    is the usage of that column.
  prefs: []
  type: TYPE_NORMAL
- en: 'For exemple: Table named Friends contains columns (character, salary, address).
    Our **physical data** are character, salary, and address. **Our business data**
    are for example,'
  prefs: []
  type: TYPE_NORMAL
- en: For “Character” -> Name of the Character
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For “Salary” -> Amount of the salary
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For “Address” -> Location of the person
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Those business data would help in accessing data because you would directly
    have the information you needed. You would know that this is the dataset you want
    for your project, the **information** you’re looking for **is in this table**.
    So you’d just have to ask and find your happiness, go early without losing your
    time and money.
  prefs: []
  type: TYPE_NORMAL
- en: '*“During my final internship, I, along with my team of* ***interns****, implemented
    a Big Data / Graph Learning solution to document these data.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*The idea was to create a graph to structure our data and at the end predict
    business data based on features. In other word from data stored on the company’s
    environnement, document each dataset to associate an use and in the future reduce
    the search cost and be more data-driven.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*We had 830 labels to classify and not so many rows. Hopefully the power of
    graph learning come into play. I’m letting you read… “*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Article Objectives:** This article aims to provide an understanding of Big
    Data concepts, Graph Learning, the algorithm used, and the results. It also covers
    deployment considerations and how to successfully develop a model.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To help you understand my journey, the outline of this article contain :'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Acquisition: Sourcing the Essential Data for Graph Creation**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Graph-based Modeling with GSage**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Effective Deployment Strategies**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data Acquisition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As I mentioned earlier, data is often stored in Hive columns. If you didn’t
    already know, these data are stored in large containers. We extract, transform,
    and load this data through techniques known as ETL.
  prefs: []
  type: TYPE_NORMAL
- en: What type of data did I need?
  prefs: []
  type: TYPE_NORMAL
- en: '**Physical data** and their **characteristics** (domain, name, data type).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lineage** (the relationships between physical data, if they have undergone
    common transformations).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **mapping** of ‘some physical data related to business data’ to then “let”
    the algorithm perform on its own.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**1\. Characteristics/ Features** are obtained directly when we store the data;
    they are mandatory as soon as we store data. For example (depends on your case)
    :'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0c8c2d149fa04420ea7b0029121e641c.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Exemple of main feature**s, (made by the author)'
  prefs: []
  type: TYPE_NORMAL
- en: For the features, based on empirical experience, we decided to use a feature
    hasher on three columns.
  prefs: []
  type: TYPE_NORMAL
- en: '**Feature Hasher:** technique used in machine learning to convert high-dimensional
    categorical data, such as text or categorical variables, into a lower-dimensional
    numerical representation to reduce memory and computational requirements while
    preserving meaningful information.'
  prefs: []
  type: TYPE_NORMAL
- en: You could have the choice with **One Hot Encoding** technique if you have similar
    patterns. *If you want to deliver your model, my advice would be to use Feature
    Hasher.*
  prefs: []
  type: TYPE_NORMAL
- en: '**2.** **Lineage** is a bit more complex but not impossible to understand.
    Lineage is like a **history of physical data,** where we have a rough idea of
    what transformations have been applied and where the data is stored elsewhere.'
  prefs: []
  type: TYPE_NORMAL
- en: Imagine big data in your mind and all these data. In some projects, we use data
    from a table and apply a transformation through a job (Spark).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8f2312f07cc5597c8426f1474c11ff3b.png)'
  prefs: []
  type: TYPE_IMG
- en: Atlas Lineage visualized, from Atlas Website, [LINK](https://atlas.apache.org/1.2.0/ClassificationPropagation.html)
  prefs: []
  type: TYPE_NORMAL
- en: We gather the informations of all physical data we have to create connections
    in our graph, or at least one of the connections.
  prefs: []
  type: TYPE_NORMAL
- en: '**3\. The mapping** is the foundation that adds value to our project. It’s
    where we associate our business data with our physical data. This provides the
    algorithm with verified information so that it can classify the new incoming data
    in the end. This mapping had to be done by someone who understands the process
    of the company, and has the skills to recognize difficult patterns without asking.'
  prefs: []
  type: TYPE_NORMAL
- en: 'ML advice, from my own experience :'
  prefs: []
  type: TYPE_NORMAL
- en: '*Quoting Mr. Andrew NG, in classical machine learning, there’s something called
    the algorithm lifecycle. We often think about the algorithm, making it complicated,
    and not just using a good old Linear Regression (I’ve tried; it doesn’t work).
    In this lifecycle, there are all the stages of preprocessing, modeling and monitoring…
    but most importantly, there is data focusing.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**This is a mistake we often make;** we take it for granted and start doing
    data analysis. We draw conclusions from the dataset without sometimes **questioning
    its relevance**. **Don’t forget data focusing, my friends; it can boost your performance
    or even lead to a change of project :)**'
  prefs: []
  type: TYPE_NORMAL
- en: Returning to our article, after obtaining the data, we can finally **create
    our graph**.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0618769c8a8310b5805d1aaf12701ac6.png)'
  prefs: []
  type: TYPE_IMG
- en: Plot ([networkx](https://networkx.org/)) of **the distribution of our dataset,
    in a graph**. (made by the author)
  prefs: []
  type: TYPE_NORMAL
- en: This plot considers a batch of 2000 rows, so 2000 columns in datasets and tables.
    You can find in the center the business data and off-centered the physical data.
  prefs: []
  type: TYPE_NORMAL
- en: In mathematics, we denote a graph as G, **G(N, V, f)**. N represents the nodes,
    V stands for vertices (edges), and f represents the features. Let’s assume all
    three are non-empty sets.
  prefs: []
  type: TYPE_NORMAL
- en: For the nodes (we have the business data IDs in the mapping table) and also
    the physical data to trace them with lineage.
  prefs: []
  type: TYPE_NORMAL
- en: '**Speaking of lineage**, it partly serves as edges with the links we already
    have through the mapping and the IDs. We had to extract it through an ETL process
    using the **Apache Atlas APIs.**'
  prefs: []
  type: TYPE_NORMAL
- en: You can see how a big data problem, after laying the foundations, can become
    easy to understand but more challenging to implement, especially for a young intern…
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fdd4ca2d0fd9ef6663ce673842638bd9.png)'
  prefs: []
  type: TYPE_IMG
- en: “Ninja cartoon on a computer” (generated by Dall.E 3)
  prefs: []
  type: TYPE_NORMAL
- en: '**Graph-based Modeling with GSage**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Basics of Graph Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section will be dedicated to explaining GSage and why it was chosen both
    mathematically and empirically.
  prefs: []
  type: TYPE_NORMAL
- en: Before this internship, I was not accustomed to working with graphs. That’s
    why I purchased the book **[2]**, which I’ve included in the description, as it
    greatly assisted me in understanding the principles.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.amazon.fr/Graph-Machine-Learning-techniques-algorithms/dp/1800204493/ref=asc_df_1800204493/?tag=googshopfr-21&linkCode=df0&hvadid=506880135571&hvpos=&hvnetw=g&hvrand=13866138887051738726&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9055317&hvtargid=pla-1503184391952&psc=1&mcid=ad38156d270633babacde02db431d62c&source=post_page-----c0a2ddf4043c--------------------------------)
    [## Graph Machine Learning: Take graph data to the next level by applying machine
    learning techniques…'
  prefs: []
  type: TYPE_NORMAL
- en: 'Noté /5\. Retrouvez Graph Machine Learning: Take graph data to the next level
    by applying machine learning techniques…'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.amazon.fr](https://www.amazon.fr/Graph-Machine-Learning-techniques-algorithms/dp/1800204493/ref=asc_df_1800204493/?tag=googshopfr-21&linkCode=df0&hvadid=506880135571&hvpos=&hvnetw=g&hvrand=13866138887051738726&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9055317&hvtargid=pla-1503184391952&psc=1&mcid=ad38156d270633babacde02db431d62c&source=post_page-----c0a2ddf4043c--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'The principle is simple: when we talk about graph learning, we will inevitably
    discuss embedding. **In this context, nodes and their proximity are mathematically
    translated into coefficients that reduce the dimensionality of the original dataset**,
    making it more efficient for calculations. During the reduction, one of the key
    principles of the decoder **is to preserve the proximities between nodes that
    were initially close**.'
  prefs: []
  type: TYPE_NORMAL
- en: Another source of inspiration was [Maxime Labonne](https://medium.com/u/dc89da634938?source=post_page-----c0a2ddf4043c--------------------------------)
    **[3]** for his explanations of GraphSages and Graph Convolutional Networks. He
    demonstrated great pedagogy and provided clear and comprehensible examples, making
    these concepts accessible to those who wish to go into them.
  prefs: []
  type: TYPE_NORMAL
- en: '***GraphSage’s model***'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If this term doesn’t ring a bell, rest assured, just a few months ago, I was
    in your shoes. Architectures like Attention networks and Graph Convolutional Networks
    gave me quite a few nightmares and, more importantly, *kept me awake at night*.
  prefs: []
  type: TYPE_NORMAL
- en: But to save you from taking up your entire day and, especially, your commute
    time, I’m going to simplify the algorithm for you.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have the embeddings in place, that’s when the magic can happen. But
    how does it all work, you ask?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c31b2b4e40887261f7f86918c039e19d.png)'
  prefs: []
  type: TYPE_IMG
- en: Schema based on the Scooby-Doo Universe to explain GSage (made by the author).
  prefs: []
  type: TYPE_NORMAL
- en: “**You are known by the company you keep**” is the sentence, you must remember.
  prefs: []
  type: TYPE_NORMAL
- en: Because one of the fundamental assumptions underlying GraphSAGE is that nodes
    residing in the **same neighborhood should exhibit similar embeddings**. To achieve
    this, GraphSAGE employs **aggregation functions** that take a neighborhood as
    input and combine each neighbor’s embedding with specific weights. That’s why
    the mystery company embeddings would be in scooby’s neighborhood.
  prefs: []
  type: TYPE_NORMAL
- en: In essence, it gathers information from the neighborhood, with the weights being
    either learned or fixed depending on the loss function.
  prefs: []
  type: TYPE_NORMAL
- en: The true strength of GraphSAGE becomes evident when the aggregator weights are
    learned. At this point, the architecture can generate embeddings for unseen nodes
    using their features and neighborhood, making it a powerful tool for various applications
    in graph-based machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3999bbbf4baf9b568d5cd3679b6efe4a.png)'
  prefs: []
  type: TYPE_IMG
- en: Difference in training time between architecture, Maxime Labonne’s Article,
    [Link](https://mlabonne.github.io/blog/posts/2022-04-06-GraphSAGE.html)
  prefs: []
  type: TYPE_NORMAL
- en: As you saw on this graph, training time decrease when we’re taking the same
    dataset on GraphSage architecture. GAT (Graph Attention Network) and GCN (Graph
    Convolutional Network) are also really interesting graphs architectures. I really
    encourage you to look forward !
  prefs: []
  type: TYPE_NORMAL
- en: '*At the first compute, I was shocked, shocked to see 25 seconds to train 1000
    batches on thousands of rows.*'
  prefs: []
  type: TYPE_NORMAL
- en: I know at this point you’re interested in Graph Learning and you want to learn
    more, my advice would be to read this guy. Great examples, great advice).
  prefs: []
  type: TYPE_NORMAL
- en: '[](/introduction-to-graphsage-in-python-a9e7f9ecf9d7?source=post_page-----c0a2ddf4043c--------------------------------)
    [## GraphSAGE: Scaling up Graph Neural Networks'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to GraphSAGE with PyTorch Geometric
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/introduction-to-graphsage-in-python-a9e7f9ecf9d7?source=post_page-----c0a2ddf4043c--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: As I’m a reader of Medium, I’m curious to read code when I’m looking at a new
    article, and for you, we can implement a GraphSAGE architecture in PyTorch Geometric
    with the `SAGEConv` layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a network with two `SAGEConv` layers:'
  prefs: []
  type: TYPE_NORMAL
- en: The first one uses *ReLU* as the activation function and a **dropout layer**;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second one directly outputs the **node embeddings**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In our multi-class classification task, we’ve chosen to employ the cross-entropy
    loss as our primary loss function. This choice is driven by its suitability for
    classification problems with multiple classes. Additionally, we’ve incorporated
    L2 regularization with a strength of 0.0005.
  prefs: []
  type: TYPE_NORMAL
- en: '**This regularization technique helps prevent overfitting** and promotes model
    generalization by penalizing large parameter values. It’s a well-rounded approach
    to ensure model stability and predictive accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Deployment of the model :'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the development and deployment of our project, we harnessed the power of
    three key technologies, each serving a distinct and integral purpose:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7a4dae7fadcc90f34fa31346cfeea253.png)'
  prefs: []
  type: TYPE_IMG
- en: Three logos from [Google](https://www.google.com/)
  prefs: []
  type: TYPE_NORMAL
- en: '**Airflow :** To efficiently manage and schedule our project’s complex data
    workflows, we utilized the Airflow Orchestrator. Airflow is a **widely adopted
    tool for orchestrating tasks**, automating processes, and ensuring that our data
    pipelines ran smoothly and on schedule.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mirantis:** Our project’s infrastructure was built and hosted on the Mirantis
    cloud platform. Mirantis is renowned for providing **robust, scalable, and reliable
    cloud solutions**, offering a solid foundation for our **deployment**.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Jenkins:** To streamline our development and deployment processes, we relied
    on Jenkins, a trusted name in the world of continuous integration and **continuous
    delivery (CI/CD)**. Jenkins automated the **building, testing, and deployment
    of our project**, ensuring **efficiency** and **reliability** throughout our development
    cycle.'
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we stored our machine learning code in the company’s Artifactory.
    **But what exactly is an Artifactory?**
  prefs: []
  type: TYPE_NORMAL
- en: '**Artifactory:** An Artifactory is a centralized repository manager for storing,
    managing, and distributing various artifacts, such as code, libraries, and dependencies.
    It serves as a **secure** and organized storage space, ensuring that all team
    members have easy access to the necessary assets. This enables seamless **collaboration
    and simplifies the deployment of applications and projects**, making it a valuable
    asset for efficient development and deployment workflows.'
  prefs: []
  type: TYPE_NORMAL
- en: By housing our machine learning code in the Artifactory, we ensured that our
    models and data were **readily available to support our deployment via Jenkins.**
  prefs: []
  type: TYPE_NORMAL
- en: ET VOILA ! The solution was deployed.
  prefs: []
  type: TYPE_NORMAL
- en: I talked a lot about the infrastrucute but not so much about the Machine Learning
    and the results we had.
  prefs: []
  type: TYPE_NORMAL
- en: 'Results :'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The trust of the predictions :'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For each physical data, we’re taking in consideration 2 predictions, because
    of the model performances.
  prefs: []
  type: TYPE_NORMAL
- en: How’s that possible?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: First I used a softmax to make the outputs comparable, and after I used a function
    named [torch.topk](https://pytorch.org/docs/stable/generated/torch.topk.html).
    It returns the `k` largest elements of the given `input` tensor along a given
    dimension.
  prefs: []
  type: TYPE_NORMAL
- en: So, back to the first prediction, here was our distribution after training.
    Let me tell you boys and girls, that’s great!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fa18b82584a0d1ee6f8deab16a1d02ef.png)'
  prefs: []
  type: TYPE_IMG
- en: Plot (from matplotlib) of the **probabilities of the model outputs**, First
    prediction (made by the author)
  prefs: []
  type: TYPE_NORMAL
- en: Accuracies, Losses on Train / Test / Validation.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I won’t teached you what’s accuracies and losses in ML, I presumed you are all
    pros… (ask to chatgpt if you’re not sure, no shame). On the training, by different
    scale, you can see convergences on the curves, which is great and show a stable
    learning.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/38e9591e0e39237f97c80f277014c1d7.png)'
  prefs: []
  type: TYPE_IMG
- en: Plot (matplotlib) of **accuracies and losses.** (made by the author)
  prefs: []
  type: TYPE_NORMAL
- en: 't-SNE :'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: t-SNE (t-Distributed Stochastic Neighbor Embedding) is a dimensionality reduction
    technique used for visualizing and exploring high-dimensional data by preserving
    the pairwise similarities between data points in a lower-dimensional space.
  prefs: []
  type: TYPE_NORMAL
- en: 'In other words, imagine a random distribution before training :'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/17dff6aca2e38a337b1ab1a1ed626493.png)'
  prefs: []
  type: TYPE_IMG
- en: Data Distribution **before training,** (made by the author)
  prefs: []
  type: TYPE_NORMAL
- en: Remember we are doing multi-classification, so here’s the distribution after
    the training. The aggregations of features seem to have done a satisfactory work.
    Clusters are formed and physical data seem to have joined groups, demonstrating
    that the training went well.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/70933a0ca1c2018e23c7f3afb006d35f.png)'
  prefs: []
  type: TYPE_IMG
- en: Data distribution **after training,** (made by the author)
  prefs: []
  type: TYPE_NORMAL
- en: 'Conclusion :'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our goal was to predict business data based on physical data (and we did it).
    I am pleased to inform you that the algorithm is now in production and is onboarding
    new users for the future.
  prefs: []
  type: TYPE_NORMAL
- en: While I cannot provide the entire solution due to proprietary reasons, I believe
    you have all the necessary details or are well-equipped to implement it on your
    own.
  prefs: []
  type: TYPE_NORMAL
- en: My last piece of advice, I swear, have a great team, not only people who work
    well but people who make you laugh each day.
  prefs: []
  type: TYPE_NORMAL
- en: If you have any questions, please don’t hesitate to reach out to me. *Feel free
    to connect with me, and we can have a detailed discussion about it.*
  prefs: []
  type: TYPE_NORMAL
- en: '**In case I don’t see ya, good afternoon, good evening and goodnight !**'
  prefs: []
  type: TYPE_NORMAL
- en: Have you grasped everything ?
  prefs: []
  type: TYPE_NORMAL
- en: 'As **Chandler Bing** would have said :'
  prefs: []
  type: TYPE_NORMAL
- en: '**“It’s always better to lie, than to have the complicated discussion”**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Don’t forget to like and share!
  prefs: []
  type: TYPE_NORMAL
- en: References and Resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**[1]** [Inc](https://www.inc.com/jeff-barrett/misusing-data-could-be-costing-your-business-heres-how.html)
    (2018), Web Article from Inc'
  prefs: []
  type: TYPE_NORMAL
- en: '**[2]** [Graph Machine Learning: Take graph data to the next level by applying
    machine learning techniques and algorithms](https://www.amazon.fr/Graph-Machine-Learning-techniques-algorithms/dp/1800204493/ref=asc_df_1800204493/?tag=googshopfr-21&linkCode=df0&hvadid=506880135571&hvpos=&hvnetw=g&hvrand=7038120787362687179&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9055317&hvtargid=pla-1503184391952&psc=1&mcid=ad38156d270633babacde02db431d62c)
    (2021), Claudio Stamile'
  prefs: []
  type: TYPE_NORMAL
- en: '**[3]** [GSage, Scaling up the Graph Neural Network](/introduction-to-graphsage-in-python-a9e7f9ecf9d7),
    (2021), Maxime Labonne'
  prefs: []
  type: TYPE_NORMAL
- en: Image Credits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Photo by [Nathan Anderson](https://unsplash.com/@nathananderson?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/night-sky?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GSage difference of time,from Maxime Labonne’s article, [link](https://mlabonne.github.io/blog/posts/2022-04-06-GraphSAGE.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Atlas Lineage visualized, from Atlas Website, [LINK](https://atlas.apache.org/1.2.0/ClassificationPropagation.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Three logos taken [Google](https://www.google.com/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
