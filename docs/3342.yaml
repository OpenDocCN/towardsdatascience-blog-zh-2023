- en: 'Unlocking the Power of Big Data: The Fascinating World of Graph Learning'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解锁大数据的力量：图学习的迷人世界
- en: 原文：[https://towardsdatascience.com/unlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c?source=collection_archive---------8-----------------------#2023-11-09](https://towardsdatascience.com/unlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c?source=collection_archive---------8-----------------------#2023-11-09)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/unlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c?source=collection_archive---------8-----------------------#2023-11-09](https://towardsdatascience.com/unlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c?source=collection_archive---------8-----------------------#2023-11-09)
- en: Harnessing Deep Learning to Transform Untapped Data into a Strategic Asset for
    Long-Term Competitiveness.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用深度学习将未开发的数据转变为长期竞争力的战略资产。
- en: '[](https://medium.com/@mathieulaversin3?source=post_page-----c0a2ddf4043c--------------------------------)[![Mathieu
    Laversin](../Images/9ca7f2528f9fe655e2aa18e382e560f9.png)](https://medium.com/@mathieulaversin3?source=post_page-----c0a2ddf4043c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c0a2ddf4043c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c0a2ddf4043c--------------------------------)
    [Mathieu Laversin](https://medium.com/@mathieulaversin3?source=post_page-----c0a2ddf4043c--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Mathieu Laversin](../Images/9ca7f2528f9fe655e2aa18e382e560f9.png)](https://medium.com/@mathieulaversin3?source=post_page-----c0a2ddf4043c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c0a2ddf4043c--------------------------------)
    [Mathieu Laversin](https://medium.com/@mathieulaversin3?source=post_page-----c0a2ddf4043c--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd6ebca0f38b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c&user=Mathieu+Laversin&userId=d6ebca0f38b4&source=post_page-d6ebca0f38b4----c0a2ddf4043c---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c0a2ddf4043c--------------------------------)
    ·12 min read·Nov 9, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc0a2ddf4043c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c&user=Mathieu+Laversin&userId=d6ebca0f38b4&source=-----c0a2ddf4043c---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd6ebca0f38b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c&user=Mathieu+Laversin&userId=d6ebca0f38b4&source=post_page-d6ebca0f38b4----c0a2ddf4043c---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c0a2ddf4043c--------------------------------)
    ·12分钟阅读·2023年11月9日'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc0a2ddf4043c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c&source=-----c0a2ddf4043c---------------------bookmark_footer-----------)![](../Images/a392b226af14c62e715a11a498e32b34.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/a392b226af14c62e715a11a498e32b34.png)'
- en: Photo by [Nathan Anderson](https://unsplash.com/@nathananderson?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/night-sky?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Nathan Anderson](https://unsplash.com/@nathananderson?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，[Unsplash](https://unsplash.com/s/photos/night-sky?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    上的照片
- en: Large companies generate and collect vast amounts of data, as an example and
    90% of this data has been created in recent years. Yet, **73% of these data remain
    unused [1]**. However, as you may know, data is a goldmine for companies working
    with Big Data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 大公司生成和收集大量数据，以一个例子来说，90% 的数据是在最近几年创建的。然而，**73% 的这些数据仍然未被使用 [1]**。然而，正如你可能知道的那样，数据是从事大数据工作的公司的金矿。
- en: Deep learning is constantly evolving, and today, the challenge is to adapt these
    new solutions to specific goals to stand out and enhance long-term competitiveness.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习不断发展，今天的挑战是将这些新解决方案调整到特定目标，以突出表现并增强长期竞争力。
- en: My previous manager had a good intuition that these two events could come together,
    and together facilitate access, requests, and above all stop wasting time and
    money.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我以前的经理很有直觉，认为这两个事件可以结合在一起，共同促进访问、请求，最重要的是避免浪费时间和金钱。
- en: '**Why is this data left unused?**'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**为什么这些数据被闲置？**'
- en: Accessing it takes too long, rights verification, and especially content checks
    are necessary before granting access to users.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 访问这些数据需要很长时间，权利验证，特别是内容检查在授予用户访问权限之前是必需的。
- en: '![](../Images/90c71b29e47c2a19feb1d4229fd0a774.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/90c71b29e47c2a19feb1d4229fd0a774.png)'
- en: Visualize reasons for data being unused. (generated by Bing Image Creator)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化数据未被使用的原因。（由 Bing Image Creator 生成）
- en: '**Is there a solution to automatically document new data?**'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**有没有自动记录新数据的解决方案？**'
- en: If you’re not familiar with large enterprises, no problem — I wasn’t either.
    An interesting concept in such environments is the use of Big Data, particularly
    **HDFS** (Hadoop Distributed File System), which is a cluster designed to consolidate
    all of the company’s data. Within this vast pool of data, you can find structured
    data, and within that structured data, Hive columns are referenced. Some of these
    columns are used to create additional tables and likely serve as sources for various
    datasets. Companies keep the informations between some table by the lineage.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对大型企业不太熟悉，也没关系——我也是。这样环境中的一个有趣概念是使用大数据，特别是**HDFS**（Hadoop 分布式文件系统），它是一个旨在整合公司所有数据的集群。在这庞大的数据池中，你可以找到结构化数据，而在这些结构化数据中，Hive
    列被引用。这些列中的一些用于创建附加表，并可能作为各种数据集的来源。公司通过数据血缘保持表与表之间的信息。
- en: These columns also have various characteristics (domain, type, name, date, owner…).
    The goal of the project was to document the data known as physical data with business
    data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这些列还具有各种特征（领域、类型、名称、日期、所有者等）。项目的目标是用业务数据来记录被称为物理数据的数据。
- en: '**Distinguishing between physical and business data:**'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**区分物理数据和业务数据：**'
- en: To put it simply, physical data is a column name in a table, and business data
    is the usage of that column.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，物理数据是表格中的列名，而业务数据则是该列的使用方式。
- en: 'For exemple: Table named Friends contains columns (character, salary, address).
    Our **physical data** are character, salary, and address. **Our business data**
    are for example,'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：名为 Friends 的表格包含列（角色、薪资、地址）。我们的**物理数据**是角色、薪资和地址。**我们的业务数据**例如，
- en: For “Character” -> Name of the Character
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于“Character” -> 角色的名称
- en: For “Salary” -> Amount of the salary
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于“Salary” -> 薪资金额
- en: For “Address” -> Location of the person
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于“Address” -> 人的地址
- en: Those business data would help in accessing data because you would directly
    have the information you needed. You would know that this is the dataset you want
    for your project, the **information** you’re looking for **is in this table**.
    So you’d just have to ask and find your happiness, go early without losing your
    time and money.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这些业务数据将帮助访问数据，因为你可以直接获得所需的信息。你会知道这是你项目所需的数据集，**你寻找的信息** **在这个表格中**。所以你只需请求并找到你的幸福，提前去而不浪费时间和金钱。
- en: '*“During my final internship, I, along with my team of* ***interns****, implemented
    a Big Data / Graph Learning solution to document these data.*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*“在我的最后一次实习中，我和我的团队* ***实习生****，实现了一个大数据/图学习解决方案来记录这些数据。*'
- en: '*The idea was to create a graph to structure our data and at the end predict
    business data based on features. In other word from data stored on the company’s
    environnement, document each dataset to associate an use and in the future reduce
    the search cost and be more data-driven.*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*这个想法是创建一个图来结构化我们的数据，并最终根据特征预测业务数据。换句话说，从存储在公司环境中的数据中，记录每个数据集以关联用途，将来减少搜索成本，并更具数据驱动。*'
- en: '*We had 830 labels to classify and not so many rows. Hopefully the power of
    graph learning come into play. I’m letting you read… “*'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '**Article Objectives:** This article aims to provide an understanding of Big
    Data concepts, Graph Learning, the algorithm used, and the results. It also covers
    deployment considerations and how to successfully develop a model.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: 'To help you understand my journey, the outline of this article contain :'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Acquisition: Sourcing the Essential Data for Graph Creation**'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Graph-based Modeling with GSage**'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Effective Deployment Strategies**'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data Acquisition
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As I mentioned earlier, data is often stored in Hive columns. If you didn’t
    already know, these data are stored in large containers. We extract, transform,
    and load this data through techniques known as ETL.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: What type of data did I need?
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '**Physical data** and their **characteristics** (domain, name, data type).'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lineage** (the relationships between physical data, if they have undergone
    common transformations).'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **mapping** of ‘some physical data related to business data’ to then “let”
    the algorithm perform on its own.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**1\. Characteristics/ Features** are obtained directly when we store the data;
    they are mandatory as soon as we store data. For example (depends on your case)
    :'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0c8c2d149fa04420ea7b0029121e641c.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
- en: '**Exemple of main feature**s, (made by the author)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: For the features, based on empirical experience, we decided to use a feature
    hasher on three columns.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '**Feature Hasher:** technique used in machine learning to convert high-dimensional
    categorical data, such as text or categorical variables, into a lower-dimensional
    numerical representation to reduce memory and computational requirements while
    preserving meaningful information.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: You could have the choice with **One Hot Encoding** technique if you have similar
    patterns. *If you want to deliver your model, my advice would be to use Feature
    Hasher.*
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '**2.** **Lineage** is a bit more complex but not impossible to understand.
    Lineage is like a **history of physical data,** where we have a rough idea of
    what transformations have been applied and where the data is stored elsewhere.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: Imagine big data in your mind and all these data. In some projects, we use data
    from a table and apply a transformation through a job (Spark).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8f2312f07cc5597c8426f1474c11ff3b.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
- en: Atlas Lineage visualized, from Atlas Website, [LINK](https://atlas.apache.org/1.2.0/ClassificationPropagation.html)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: We gather the informations of all physical data we have to create connections
    in our graph, or at least one of the connections.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '**3\. The mapping** is the foundation that adds value to our project. It’s
    where we associate our business data with our physical data. This provides the
    algorithm with verified information so that it can classify the new incoming data
    in the end. This mapping had to be done by someone who understands the process
    of the company, and has the skills to recognize difficult patterns without asking.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: 'ML advice, from my own experience :'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ML建议，基于我自己的经验：
- en: '*Quoting Mr. Andrew NG, in classical machine learning, there’s something called
    the algorithm lifecycle. We often think about the algorithm, making it complicated,
    and not just using a good old Linear Regression (I’ve tried; it doesn’t work).
    In this lifecycle, there are all the stages of preprocessing, modeling and monitoring…
    but most importantly, there is data focusing.*'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '*引用Andrew NG先生的话，在经典机器学习中，有一种叫做算法生命周期的东西。我们常常考虑算法，使其复杂，而不只是使用一个老式的线性回归（我尝试过；它不起作用）。在这个生命周期中，包括所有的预处理、建模和监控阶段……但最重要的是，数据聚焦。*'
- en: '**This is a mistake we often make;** we take it for granted and start doing
    data analysis. We draw conclusions from the dataset without sometimes **questioning
    its relevance**. **Don’t forget data focusing, my friends; it can boost your performance
    or even lead to a change of project :)**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**这是我们经常犯的错误；** 我们理所当然地开始进行数据分析。我们从数据集中得出结论，而有时却**没有质疑其相关性**。**不要忘记数据聚焦，我的朋友们；它可以提升你的表现，甚至导致项目的改变
    :)**'
- en: Returning to our article, after obtaining the data, we can finally **create
    our graph**.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的文章，获取数据后，我们最终可以**创建我们的图**。
- en: '![](../Images/0618769c8a8310b5805d1aaf12701ac6.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0618769c8a8310b5805d1aaf12701ac6.png)'
- en: Plot ([networkx](https://networkx.org/)) of **the distribution of our dataset,
    in a graph**. (made by the author)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们数据集的分布图**的绘图（使用[networkx](https://networkx.org/)制作）。(由作者制作)'
- en: This plot considers a batch of 2000 rows, so 2000 columns in datasets and tables.
    You can find in the center the business data and off-centered the physical data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 该图考虑了一批2000行的数据，因此在数据集和表格中有2000列。你可以在中心找到业务数据，而偏离中心的是物理数据。
- en: In mathematics, we denote a graph as G, **G(N, V, f)**. N represents the nodes,
    V stands for vertices (edges), and f represents the features. Let’s assume all
    three are non-empty sets.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学中，我们将图表示为G，**G(N, V, f)**。N代表节点，V代表顶点（边），f代表特征。假设这三者都是非空集合。
- en: For the nodes (we have the business data IDs in the mapping table) and also
    the physical data to trace them with lineage.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于节点（我们在映射表中有业务数据ID）以及物理数据，以便通过谱系追踪它们。
- en: '**Speaking of lineage**, it partly serves as edges with the links we already
    have through the mapping and the IDs. We had to extract it through an ETL process
    using the **Apache Atlas APIs.**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**谈到谱系**，它部分作为边，通过映射和ID链接我们已有的链接。我们必须通过使用**Apache Atlas API**的ETL过程来提取它。'
- en: You can see how a big data problem, after laying the foundations, can become
    easy to understand but more challenging to implement, especially for a young intern…
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，在奠定基础之后，大数据问题可以变得容易理解，但实施起来却更具挑战性，尤其对于一名年轻的实习生来说……
- en: '![](../Images/fdd4ca2d0fd9ef6663ce673842638bd9.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fdd4ca2d0fd9ef6663ce673842638bd9.png)'
- en: “Ninja cartoon on a computer” (generated by Dall.E 3)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: “计算机上的忍者卡通”（由Dall.E 3生成）
- en: '**Graph-based Modeling with GSage**'
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**基于图的建模与GSage**'
- en: Basics of Graph Learning
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图学习基础
- en: This section will be dedicated to explaining GSage and why it was chosen both
    mathematically and empirically.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将致力于解释GSage以及为何在数学和经验上都选择了它。
- en: Before this internship, I was not accustomed to working with graphs. That’s
    why I purchased the book **[2]**, which I’ve included in the description, as it
    greatly assisted me in understanding the principles.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次实习之前，我不习惯使用图形。这就是为什么我购买了书籍**[2]**，我在描述中包含了它，因为它大大帮助我理解了原理。
- en: '[](https://www.amazon.fr/Graph-Machine-Learning-techniques-algorithms/dp/1800204493/ref=asc_df_1800204493/?tag=googshopfr-21&linkCode=df0&hvadid=506880135571&hvpos=&hvnetw=g&hvrand=13866138887051738726&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9055317&hvtargid=pla-1503184391952&psc=1&mcid=ad38156d270633babacde02db431d62c&source=post_page-----c0a2ddf4043c--------------------------------)
    [## Graph Machine Learning: Take graph data to the next level by applying machine
    learning techniques…'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.amazon.fr/Graph-Machine-Learning-techniques-algorithms/dp/1800204493/ref=asc_df_1800204493/?tag=googshopfr-21&linkCode=df0&hvadid=506880135571&hvpos=&hvnetw=g&hvrand=13866138887051738726&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9055317&hvtargid=pla-1503184391952&psc=1&mcid=ad38156d270633babacde02db431d62c&source=post_page-----c0a2ddf4043c--------------------------------)
    [## 图机器学习：通过应用机器学习技术将图数据提升到一个新的水平……'
- en: 'Noté /5\. Retrouvez Graph Machine Learning: Take graph data to the next level
    by applying machine learning techniques…'
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意 /5。请查阅《图机器学习：通过应用机器学习技术将图数据提升到一个新的水平》……
- en: www.amazon.fr](https://www.amazon.fr/Graph-Machine-Learning-techniques-algorithms/dp/1800204493/ref=asc_df_1800204493/?tag=googshopfr-21&linkCode=df0&hvadid=506880135571&hvpos=&hvnetw=g&hvrand=13866138887051738726&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9055317&hvtargid=pla-1503184391952&psc=1&mcid=ad38156d270633babacde02db431d62c&source=post_page-----c0a2ddf4043c--------------------------------)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.amazon.fr](https://www.amazon.fr/Graph-Machine-Learning-techniques-algorithms/dp/1800204493/ref=asc_df_1800204493/?tag=googshopfr-21&linkCode=df0&hvadid=506880135571&hvpos=&hvnetw=g&hvrand=13866138887051738726&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9055317&hvtargid=pla-1503184391952&psc=1&mcid=ad38156d270633babacde02db431d62c&source=post_page-----c0a2ddf4043c--------------------------------)'
- en: 'The principle is simple: when we talk about graph learning, we will inevitably
    discuss embedding. **In this context, nodes and their proximity are mathematically
    translated into coefficients that reduce the dimensionality of the original dataset**,
    making it more efficient for calculations. During the reduction, one of the key
    principles of the decoder **is to preserve the proximities between nodes that
    were initially close**.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 原理很简单：当我们谈论图学习时，我们必然会讨论嵌入。**在这个背景下，节点及其邻近关系在数学上被转换为减少原始数据集维度的系数**，使计算更加高效。在降维过程中，解码器的一个关键原则**是保持初始接近的节点之间的邻近关系**。
- en: Another source of inspiration was [Maxime Labonne](https://medium.com/u/dc89da634938?source=post_page-----c0a2ddf4043c--------------------------------)
    **[3]** for his explanations of GraphSages and Graph Convolutional Networks. He
    demonstrated great pedagogy and provided clear and comprehensible examples, making
    these concepts accessible to those who wish to go into them.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个灵感来源是 [Maxime Labonne](https://medium.com/u/dc89da634938?source=post_page-----c0a2ddf4043c--------------------------------)
    **[3]**，他对 GraphSages 和图卷积网络的解释展示了极佳的教学法，提供了清晰易懂的例子，使这些概念对希望深入了解的人变得更加易于理解。
- en: '***GraphSage’s model***'
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '***GraphSage 的模型***'
- en: If this term doesn’t ring a bell, rest assured, just a few months ago, I was
    in your shoes. Architectures like Attention networks and Graph Convolutional Networks
    gave me quite a few nightmares and, more importantly, *kept me awake at night*.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这个术语对你来说不熟悉，请放心，几个月前我也在你的位置。像注意力网络和图卷积网络这样的架构曾让我经历了不少噩梦，更重要的是，它们*让我夜不能寐*。
- en: But to save you from taking up your entire day and, especially, your commute
    time, I’m going to simplify the algorithm for you.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 为了节省你整天的时间，尤其是你的通勤时间，我将为你简化算法。
- en: Once you have the embeddings in place, that’s when the magic can happen. But
    how does it all work, you ask?
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了嵌入，这时候魔法才会发生。但你问一切是如何运作的？
- en: '![](../Images/c31b2b4e40887261f7f86918c039e19d.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c31b2b4e40887261f7f86918c039e19d.png)'
- en: Schema based on the Scooby-Doo Universe to explain GSage (made by the author).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 基于《史酷比宇宙》的图解来解释 GSage（由作者制作）。
- en: “**You are known by the company you keep**” is the sentence, you must remember.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: “**你以交友闻名**”这句话，你必须记住。
- en: Because one of the fundamental assumptions underlying GraphSAGE is that nodes
    residing in the **same neighborhood should exhibit similar embeddings**. To achieve
    this, GraphSAGE employs **aggregation functions** that take a neighborhood as
    input and combine each neighbor’s embedding with specific weights. That’s why
    the mystery company embeddings would be in scooby’s neighborhood.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 GraphSAGE 的一个基本假设是**同一邻域中的节点应该表现出类似的嵌入**。为实现这一点，GraphSAGE 使用**聚合函数**，将邻域作为输入，并结合每个邻居的嵌入及特定权重。这就是为什么神秘公司嵌入会出现在
    Scooby 的邻域中的原因。
- en: In essence, it gathers information from the neighborhood, with the weights being
    either learned or fixed depending on the loss function.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，它从邻域收集信息，权重可以是学习得出的，也可以是固定的，具体取决于损失函数。
- en: The true strength of GraphSAGE becomes evident when the aggregator weights are
    learned. At this point, the architecture can generate embeddings for unseen nodes
    using their features and neighborhood, making it a powerful tool for various applications
    in graph-based machine learning.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 当聚合器权重被学习时，GraphSAGE 的真正实力便会显现。此时，该架构可以利用节点的特征和邻域为未见节点生成嵌入，使其成为图基机器学习中各种应用的强大工具。
- en: '![](../Images/3999bbbf4baf9b568d5cd3679b6efe4a.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3999bbbf4baf9b568d5cd3679b6efe4a.png)'
- en: Difference in training time between architecture, Maxime Labonne’s Article,
    [Link](https://mlabonne.github.io/blog/posts/2022-04-06-GraphSAGE.html)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 架构训练时间的差异，Maxime Labonne 的文章，[链接](https://mlabonne.github.io/blog/posts/2022-04-06-GraphSAGE.html)
- en: As you saw on this graph, training time decrease when we’re taking the same
    dataset on GraphSage architecture. GAT (Graph Attention Network) and GCN (Graph
    Convolutional Network) are also really interesting graphs architectures. I really
    encourage you to look forward !
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '*At the first compute, I was shocked, shocked to see 25 seconds to train 1000
    batches on thousands of rows.*'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: I know at this point you’re interested in Graph Learning and you want to learn
    more, my advice would be to read this guy. Great examples, great advice).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '[](/introduction-to-graphsage-in-python-a9e7f9ecf9d7?source=post_page-----c0a2ddf4043c--------------------------------)
    [## GraphSAGE: Scaling up Graph Neural Networks'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to GraphSAGE with PyTorch Geometric
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/introduction-to-graphsage-in-python-a9e7f9ecf9d7?source=post_page-----c0a2ddf4043c--------------------------------)
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: As I’m a reader of Medium, I’m curious to read code when I’m looking at a new
    article, and for you, we can implement a GraphSAGE architecture in PyTorch Geometric
    with the `SAGEConv` layer.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a network with two `SAGEConv` layers:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: The first one uses *ReLU* as the activation function and a **dropout layer**;
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second one directly outputs the **node embeddings**.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In our multi-class classification task, we’ve chosen to employ the cross-entropy
    loss as our primary loss function. This choice is driven by its suitability for
    classification problems with multiple classes. Additionally, we’ve incorporated
    L2 regularization with a strength of 0.0005.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '**This regularization technique helps prevent overfitting** and promotes model
    generalization by penalizing large parameter values. It’s a well-rounded approach
    to ensure model stability and predictive accuracy.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Deployment of the model :'
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the development and deployment of our project, we harnessed the power of
    three key technologies, each serving a distinct and integral purpose:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7a4dae7fadcc90f34fa31346cfeea253.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
- en: Three logos from [Google](https://www.google.com/)
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '**Airflow :** To efficiently manage and schedule our project’s complex data
    workflows, we utilized the Airflow Orchestrator. Airflow is a **widely adopted
    tool for orchestrating tasks**, automating processes, and ensuring that our data
    pipelines ran smoothly and on schedule.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '**Mirantis:** Our project’s infrastructure was built and hosted on the Mirantis
    cloud platform. Mirantis is renowned for providing **robust, scalable, and reliable
    cloud solutions**, offering a solid foundation for our **deployment**.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '**Jenkins:** To streamline our development and deployment processes, we relied
    on Jenkins, a trusted name in the world of continuous integration and **continuous
    delivery (CI/CD)**. Jenkins automated the **building, testing, and deployment
    of our project**, ensuring **efficiency** and **reliability** throughout our development
    cycle.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we stored our machine learning code in the company’s Artifactory.
    **But what exactly is an Artifactory?**
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '**Artifactory:** An Artifactory is a centralized repository manager for storing,
    managing, and distributing various artifacts, such as code, libraries, and dependencies.
    It serves as a **secure** and organized storage space, ensuring that all team
    members have easy access to the necessary assets. This enables seamless **collaboration
    and simplifies the deployment of applications and projects**, making it a valuable
    asset for efficient development and deployment workflows.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: By housing our machine learning code in the Artifactory, we ensured that our
    models and data were **readily available to support our deployment via Jenkins.**
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: ET VOILA ! The solution was deployed.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: I talked a lot about the infrastrucute but not so much about the Machine Learning
    and the results we had.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: 'Results :'
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The trust of the predictions :'
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For each physical data, we’re taking in consideration 2 predictions, because
    of the model performances.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: How’s that possible?
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: First I used a softmax to make the outputs comparable, and after I used a function
    named [torch.topk](https://pytorch.org/docs/stable/generated/torch.topk.html).
    It returns the `k` largest elements of the given `input` tensor along a given
    dimension.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: So, back to the first prediction, here was our distribution after training.
    Let me tell you boys and girls, that’s great!
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fa18b82584a0d1ee6f8deab16a1d02ef.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
- en: Plot (from matplotlib) of the **probabilities of the model outputs**, First
    prediction (made by the author)
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Accuracies, Losses on Train / Test / Validation.
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I won’t teached you what’s accuracies and losses in ML, I presumed you are all
    pros… (ask to chatgpt if you’re not sure, no shame). On the training, by different
    scale, you can see convergences on the curves, which is great and show a stable
    learning.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/38e9591e0e39237f97c80f277014c1d7.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
- en: Plot (matplotlib) of **accuracies and losses.** (made by the author)
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: 't-SNE :'
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: t-SNE (t-Distributed Stochastic Neighbor Embedding) is a dimensionality reduction
    technique used for visualizing and exploring high-dimensional data by preserving
    the pairwise similarities between data points in a lower-dimensional space.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: 'In other words, imagine a random distribution before training :'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/17dff6aca2e38a337b1ab1a1ed626493.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
- en: Data Distribution **before training,** (made by the author)
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: Remember we are doing multi-classification, so here’s the distribution after
    the training. The aggregations of features seem to have done a satisfactory work.
    Clusters are formed and physical data seem to have joined groups, demonstrating
    that the training went well.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/70933a0ca1c2018e23c7f3afb006d35f.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
- en: Data distribution **after training,** (made by the author)
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: 'Conclusion :'
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our goal was to predict business data based on physical data (and we did it).
    I am pleased to inform you that the algorithm is now in production and is onboarding
    new users for the future.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是基于物理数据预测业务数据（而且我们做到了）。我很高兴地通知你，该算法现在已投入生产，并正在为未来的用户进行接入。
- en: While I cannot provide the entire solution due to proprietary reasons, I believe
    you have all the necessary details or are well-equipped to implement it on your
    own.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然由于专有原因我不能提供完整的解决方案，但我相信你已经掌握了所有必要的细节，或者你完全有能力自行实施。
- en: My last piece of advice, I swear, have a great team, not only people who work
    well but people who make you laugh each day.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我最后的一条建议，我发誓，拥有一个出色的团队，不仅是那些工作出色的人，还有那些每天让你开心的人。
- en: If you have any questions, please don’t hesitate to reach out to me. *Feel free
    to connect with me, and we can have a detailed discussion about it.*
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有任何问题，请随时联系我。*随时与我联系，我们可以详细讨论。*
- en: '**In case I don’t see ya, good afternoon, good evening and goodnight !**'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果我没见到你，下午好，晚上好，晚安！**'
- en: Have you grasped everything ?
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 你掌握了吗？
- en: 'As **Chandler Bing** would have said :'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 正如**钱德勒·宾**可能会说：
- en: '**“It’s always better to lie, than to have the complicated discussion”**'
  id: totrans-140
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**“说谎总比进行复杂的讨论要好”**'
- en: Don’t forget to like and share!
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 别忘了点赞和分享！
- en: References and Resources
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料和资源
- en: '**[1]** [Inc](https://www.inc.com/jeff-barrett/misusing-data-could-be-costing-your-business-heres-how.html)
    (2018), Web Article from Inc'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**[1]** [Inc](https://www.inc.com/jeff-barrett/misusing-data-could-be-costing-your-business-heres-how.html)（2018），来自Inc的网络文章'
- en: '**[2]** [Graph Machine Learning: Take graph data to the next level by applying
    machine learning techniques and algorithms](https://www.amazon.fr/Graph-Machine-Learning-techniques-algorithms/dp/1800204493/ref=asc_df_1800204493/?tag=googshopfr-21&linkCode=df0&hvadid=506880135571&hvpos=&hvnetw=g&hvrand=7038120787362687179&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9055317&hvtargid=pla-1503184391952&psc=1&mcid=ad38156d270633babacde02db431d62c)
    (2021), Claudio Stamile'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**[2]** [图机器学习：通过应用机器学习技术和算法将图数据提升到一个新水平](https://www.amazon.fr/Graph-Machine-Learning-techniques-algorithms/dp/1800204493/ref=asc_df_1800204493/?tag=googshopfr-21&linkCode=df0&hvadid=506880135571&hvpos=&hvnetw=g&hvrand=7038120787362687179&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9055317&hvtargid=pla-1503184391952&psc=1&mcid=ad38156d270633babacde02db431d62c)（2021），Claudio
    Stamile'
- en: '**[3]** [GSage, Scaling up the Graph Neural Network](/introduction-to-graphsage-in-python-a9e7f9ecf9d7),
    (2021), Maxime Labonne'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**[3]** [GraphSAGE，扩展图神经网络](/introduction-to-graphsage-in-python-a9e7f9ecf9d7)，（2021），Maxime
    Labonne'
- en: Image Credits
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图片来源
- en: Photo by [Nathan Anderson](https://unsplash.com/@nathananderson?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/night-sky?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Nathan Anderson](https://unsplash.com/@nathananderson?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)的照片，来源于[Unsplash](https://unsplash.com/s/photos/night-sky?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)'
- en: GSage difference of time,from Maxime Labonne’s article, [link](https://mlabonne.github.io/blog/posts/2022-04-06-GraphSAGE.html)
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GraphSAGE时间差，来自Maxime Labonne的文章，[链接](https://mlabonne.github.io/blog/posts/2022-04-06-GraphSAGE.html)
- en: Atlas Lineage visualized, from Atlas Website, [LINK](https://atlas.apache.org/1.2.0/ClassificationPropagation.html)
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Atlas Lineage可视化，来自Atlas网站，[链接](https://atlas.apache.org/1.2.0/ClassificationPropagation.html)
- en: Three logos taken [Google](https://www.google.com/)
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三个标志来自[Google](https://www.google.com/)
