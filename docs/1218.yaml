- en: Effective Data Augmentation for OCR
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有效的数据增强用于OCR
- en: 原文：[https://towardsdatascience.com/effective-data-augmentation-for-ocr-8013080aa9fa?source=collection_archive---------10-----------------------#2023-04-06](https://towardsdatascience.com/effective-data-augmentation-for-ocr-8013080aa9fa?source=collection_archive---------10-----------------------#2023-04-06)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/effective-data-augmentation-for-ocr-8013080aa9fa?source=collection_archive---------10-----------------------#2023-04-06](https://towardsdatascience.com/effective-data-augmentation-for-ocr-8013080aa9fa?source=collection_archive---------10-----------------------#2023-04-06)
- en: My recipe to reach those last percents of (ac)cu(re)teness
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我实现最后几个百分点的（ac）cu(re)teness的秘诀
- en: '[](https://toon-beerten.medium.com/?source=post_page-----8013080aa9fa--------------------------------)[![Toon
    Beerten](../Images/f169eaa8cefa00f17176955596972d57.png)](https://toon-beerten.medium.com/?source=post_page-----8013080aa9fa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8013080aa9fa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8013080aa9fa--------------------------------)
    [Toon Beerten](https://toon-beerten.medium.com/?source=post_page-----8013080aa9fa--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://toon-beerten.medium.com/?source=post_page-----8013080aa9fa--------------------------------)[![Toon
    Beerten](../Images/f169eaa8cefa00f17176955596972d57.png)](https://toon-beerten.medium.com/?source=post_page-----8013080aa9fa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8013080aa9fa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8013080aa9fa--------------------------------)
    [Toon Beerten](https://toon-beerten.medium.com/?source=post_page-----8013080aa9fa--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3aef462e13b5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffective-data-augmentation-for-ocr-8013080aa9fa&user=Toon+Beerten&userId=3aef462e13b5&source=post_page-3aef462e13b5----8013080aa9fa---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8013080aa9fa--------------------------------)
    ·7 min read·Apr 6, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8013080aa9fa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffective-data-augmentation-for-ocr-8013080aa9fa&user=Toon+Beerten&userId=3aef462e13b5&source=-----8013080aa9fa---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3aef462e13b5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffective-data-augmentation-for-ocr-8013080aa9fa&user=Toon+Beerten&userId=3aef462e13b5&source=post_page-3aef462e13b5----8013080aa9fa---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8013080aa9fa--------------------------------)
    ·7 min read·2023年4月6日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8013080aa9fa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffective-data-augmentation-for-ocr-8013080aa9fa&user=Toon+Beerten&userId=3aef462e13b5&source=-----8013080aa9fa---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8013080aa9fa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffective-data-augmentation-for-ocr-8013080aa9fa&source=-----8013080aa9fa---------------------bookmark_footer-----------)![](../Images/e6dd122357975bca3efc671c05bae100.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8013080aa9fa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffective-data-augmentation-for-ocr-8013080aa9fa&source=-----8013080aa9fa---------------------bookmark_footer-----------)![](../Images/e6dd122357975bca3efc671c05bae100.png)'
- en: Image by author (generated [with](https://huggingface.co/spaces/albarji/mixture-of-diffusers))
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图片（生成的 [with](https://huggingface.co/spaces/albarji/mixture-of-diffusers)）
- en: '**Background**'
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**背景**'
- en: I faced a challenge of handwritten amounts that needed to be recognized as precise
    as possible. The difficulty lies in keeping the false positives below 0.01% .
    The amount of samples in the dataset was fixed, so data augmentation is the logical
    go-to. A quick search revealed no of-the-shelf method for Optical Character Recognition
    (OCR). So I pulled up my sleeves and created a data augmentation routine myself.
    It was used during training and helped my model reach the objective. Read on to
    know how.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我面临了一个挑战，即手写金额需要尽可能精确地识别。困难在于将误报率保持在0.01%以下。数据集中的样本数量是固定的，所以数据增强是合逻辑的选择。快速搜索发现没有现成的光学字符识别（OCR）方法。因此，我卷起袖子自己创建了一个数据增强程序。这个程序在训练期间被使用，帮助我的模型达到了目标。继续阅读以了解详细情况。
- en: By introducing small changes each time an image is trained, the model is less
    likely to overfit and generalize better. I used it in conjunction with TROCR,
    but any other model should benefit as well.
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 通过在每次训练图像时引入小的变化，模型不容易过拟合，从而更好地进行泛化。我将其与TROCR结合使用，但任何其他模型也应受益。
- en: '**Test setup**'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**测试设置**'
- en: Since I can’t share images from my proprietary dataset, I wanted to use samples
    from the [IAM Handwriting Database](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database),
    but I didn’t get a reply to my request for permission to use it in this article.
    So I created some of my own examples for demonstrating.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我不能分享我专有数据集中的图像，我想使用[IAM手写数据库](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database)中的样本，但我没有收到使用这些图像的许可回复。因此，我创建了一些自己的示例来进行演示。
- en: 'I will make use of O[penCV](https://opencv.org/) and the [albumentations](https://albumentations.ai/)
    library, for three kinds of alterations: morphological, noise and transformations.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用O[penCV](https://opencv.org/)和[albumentations](https://albumentations.ai/)库，进行三种类型的变换：形态学、噪声和变换。
- en: OpenCV is a well known computer vision library. Albumentations is a relatively
    new Python library for easy yet powerful image augmentations.
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: OpenCV是一个知名的计算机视觉库。Albumentations是一个相对较新的Python库，提供了简单而强大的图像增强功能。
- en: There is also a nice [demo website](https://demo.albumentations.ai/) where you
    can try what albumentations can do. It is however limited because you can’t use
    your own image to test on. So, I created a Jupyter [notebook](https://github.com/Toon-nooT/notebooks)
    that I used to render all augmented images in this article. Feel free to open
    it in [colab](https://colab.research.google.com/github/Toon-nooT/notebooks/blob/main/OCR_data_augmentations.ipynb)
    and experiment.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个很棒的[演示网站](https://demo.albumentations.ai/)，你可以试试albumentations能做什么。然而它有一定的限制，因为你不能使用自己的图像进行测试。因此，我创建了一个Jupyter
    [笔记本](https://github.com/Toon-nooT/notebooks)，用于渲染本文中的所有增强图像。你可以在[colab](https://colab.research.google.com/github/Toon-nooT/notebooks/blob/main/OCR_data_augmentations.ipynb)中打开并进行实验。
- en: I will first show the alterations by itself with some explanation and then i
    will discuss my technique to combine all of them. I will suppose that all images
    are grayscale and will have undergone already contrast enhancement (eg. CLAHE).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我将首先展示这些变换及其一些解释，然后讨论我将它们结合在一起的技术。我假设所有图像都是灰度图像，并且已经进行了对比度增强（例如CLAHE）。
- en: '1st augmentation technique: **morphological** alterations'
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一种增强技术：**形态学**变换
- en: 'These relate to the form of structure. To put it in simpler terms: they can
    be used to make the text lines appear to be written with a finer or thicker pen.
    *Erosion* and *dilation* they are called. Unfortunately these are not (yet?) part
    of the albumentations library, so i have to resort to opencv for this.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这些与结构形式有关。简单来说：它们可以用来使文本线条看起来像是用更细或更粗的笔书写的。它们被称为*腐蚀*和*膨胀*。不幸的是，这些还不是（还？）albumentations库的一部分，因此我必须借助opencv来实现。
- en: 'To create the effect that somebody used a pen with a fatter line width, we
    can **dilate** the original:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创造出某人使用了更粗线宽的笔的效果，我们可以对原图进行**膨胀**处理：
- en: '![](../Images/4b9a2f4972ba437ab7beb639d560dceb.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b9a2f4972ba437ab7beb639d560dceb.png)'
- en: original vs dilated (*Image by author*)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 原始图像与膨胀效果 (*图片由作者提供*)
- en: '**Erosion** on the other hand (pun intended) simulates that the text has been
    written with a finer pen:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，**腐蚀**（有意的双关）模拟了文本是用更细的笔书写的效果：
- en: '![](../Images/518656273e4ca8bd9851b3e271c01fec.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/518656273e4ca8bd9851b3e271c01fec.png)'
- en: original vs erosion (*Image by author*)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 原始图像与腐蚀效果 (*图片由作者提供*)
- en: Be careful here that the last parameter — which is the number of iterations
    — is not set too high (here it was set to 3), otherwise you end up with the handwriting
    completely removed.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里要小心，最后一个参数——即迭代次数——不要设置得太高（这里设置为3），否则你最终会得到完全去除的手写字。
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: For my dataset I could only set it to 1, so this really depends on your data.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我的数据集，我只能设置为1，因此这确实取决于你的数据。
- en: '2nd augmentation technique: **noise introduction**'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第二种增强技术：**噪声引入**
- en: 'We can either remove black pixels or add white pixels to the image. there are
    several methods to that. I have experimented with many of them, but here is my
    shortlist:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以选择从图像中去除黑色像素或添加白色像素。对此有几种方法。我尝试了许多方法，但这是我的简短清单：
- en: '**RandomRain** with **black** drop color is very damaging. Even for me it’s
    hard to still read the text. That’s why i opt to set the chance of this happening
    very low:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**随机降雨**与**黑色**滴水颜色非常具有破坏性。即使对我来说也很难阅读文本。因此，我选择将这种情况发生的概率设置得非常低：'
- en: '![](../Images/0204f3ade1e653b39a087303d12f0e66.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0204f3ade1e653b39a087303d12f0e66.png)'
- en: RandomRain examples (*Image by author*)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: RandomRain 示例（*图片来源：作者*）
- en: '**RandomShadow** will smudge the text with lines of varying intensity:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**RandomShadow** 将用不同强度的线条涂抹文本：'
- en: '![](../Images/e1ac0e10469d87375b5f5e2a4dffb45b.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e1ac0e10469d87375b5f5e2a4dffb45b.png)'
- en: RandomShadow (*Image by author*)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: RandomShadow（*图片来源：作者*）
- en: '**PixelDropout** gently turns random pixels into black:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**PixelDropout** 轻轻将随机像素变为黑色：'
- en: '![](../Images/be81c47bd860ec1f9fb3693e1dbc18d9.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/be81c47bd860ec1f9fb3693e1dbc18d9.png)'
- en: black pixels with PixelDropout (*Image by author*)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 PixelDropout 的黑色像素（*图片来源：作者*）
- en: Unlike with black color drops, **RandomRain** with **white** drop color disintegrates
    the writing, which hardens the training. Much like the bad quality you see when
    a photocopy of a xerox of a fax was taken. The probability of this transform happening
    can be set much higher.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 与黑色滴落不同，**RandomRain** 使用 **白色** 滴落颜色会使书写变得支离破碎，这使得训练变得更加困难。就像你在复印传真复印件时看到的那种劣质效果一样。这种变换发生的概率可以设得更高。
- en: '![](../Images/5755ce839ed7e7fc6508076eef3793cd.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5755ce839ed7e7fc6508076eef3793cd.png)'
- en: RandomRain — white version (*Image by author*)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: RandomRain — 白色版本（*图片来源：作者*）
- en: 'In a lesser extent **PixelDropout** to **white** does the same. But it results
    more in a more general faded image:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在较小程度上，**PixelDropout** 对 **白色** 的处理也是如此。但它更多地导致了一种更普遍的褪色图像：
- en: '![](../Images/32ba83dfe76e12fea60af4a02368b9a4.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/32ba83dfe76e12fea60af4a02368b9a4.png)'
- en: PixelDropout with white pixels (*Image by author*)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 PixelDropout 的白色像素（*图片来源：作者*）
- en: '3rd augmentation technique: transformations'
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第三种增强技术：变换
- en: '**ShiftScaleRotate**: be careful here with the parameters. Try to avoid that
    some text is cut off and falls outside the original dimensions. There is both
    a zoom and rotation going on. Be sure to not overdo it with too big parameters.
    Otherwise you’ll have more chance that the 1st sample will happen. You can see
    it actually moves text outside of the image. This can be prevented by choosing
    a larger bounding box — so effectively adding more whitespace around the text.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**ShiftScaleRotate**：在这里需要注意参数。尽量避免文本被切割并超出原始尺寸。这里有缩放和旋转。请确保不要过度使用过大的参数。否则，你会有更大的机会让第一个样本发生。你可以看到它实际上将文本移动到图像之外。这可以通过选择更大的边界框来防止——从而有效地在文本周围添加更多的空白。'
- en: '![](../Images/0363993a0a4467f8609d17c980a84961.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0363993a0a4467f8609d17c980a84961.png)'
- en: zoomed and rotated (*Image by author*)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 放大和旋转（*图片来源：作者*）
- en: '**Blur**. The old (but gold) reliable. Will be performed in different intensities.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**模糊**。这个旧而可靠的方法，将以不同的强度执行。'
- en: '![](../Images/7775913f3b1f7790b6ebd6e838e0b9cc.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7775913f3b1f7790b6ebd6e838e0b9cc.png)'
- en: blurred handwritten text (*Image by author*)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 模糊的手写文本（*图片来源：作者*）
- en: '**The big finale: combining them all together:**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**大结局：将它们全部结合起来：**'
- en: 'This is where the power lies. We can randomly combine these effects to create
    unique images to include in each training epoch. Careful consideration needs to
    be taken that you don’t do too many methods of the same type. We can do this with
    the function in albumentation *OneOf* . *OneOf* contains a list of possible transformations
    and like the name implies, will only execute one of these with possibility P.
    So it makes sense to group transformations that do more or less the same, to avoid
    overdoing it. Here is the function:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是力量所在。我们可以随机组合这些效果来创建独特的图像，以包含在每个训练周期中。需要仔细考虑的是，避免使用太多相同类型的方法。我们可以使用 albumentation
    中的 *OneOf* 函数来做到这一点。*OneOf* 包含一个可能的变换列表，正如名字所示，它只会以概率 P 执行其中之一。因此，将做得更多或更少相同的变换组合在一起是有意义的，以避免过度使用。以下是该函数：
- en: '[PRE1]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: P stands for the chance of something happening. It’s a value between 0 and 1,
    where 1 means it always happens and 0 never.
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: P 代表某事发生的概率。它是一个介于 0 和 1 之间的值，其中 1 表示它总是发生，0 表示它从不发生。
- en: 'So, let’s see it in action:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们看看它的实际效果：
- en: '![](../Images/e99d22b622bdf6f7bbcae9fbc5a7bb59.png)![](../Images/598a475fa77f1eefe28a95e47e1162d2.png)![](../Images/375968cfdc0a6ec7874d0b48ee5ea3e9.png)![](../Images/d57b638661a531d581e0a8b3fdcd60ea.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e99d22b622bdf6f7bbcae9fbc5a7bb59.png)![](../Images/598a475fa77f1eefe28a95e47e1162d2.png)![](../Images/375968cfdc0a6ec7874d0b48ee5ea3e9.png)![](../Images/d57b638661a531d581e0a8b3fdcd60ea.png)'
- en: augmented text (*Images by author*)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 增强的文本（*图片来源：作者*）
- en: Looks pretty neat, no?
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来相当不错，不是吗？
- en: '**alternative approach:** 🌮'
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**另一种方法：** 🌮'
- en: In the [EASTER 2.0](https://arxiv.org/abs/2205.14879) paper, they came up with
    the [TACo](https://github.com/kartikgill/taco-box) technique. It stand for Tiling
    and Corruption. (🌮 haha)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [EASTER 2.0](https://arxiv.org/abs/2205.14879) 论文中，他们提出了 [TACo](https://github.com/kartikgill/taco-box)
    技术。它代表了 Tiling 和 Corruption。（🌮 哈哈）
- en: 'It is capable of this:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 它能够做到这一点：
- en: '![](../Images/a280195c5c28677c2534bf0d9d10eddd.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a280195c5c28677c2534bf0d9d10eddd.png)'
- en: figure by [Kartik Chaudhary / Raghav Bali](https://github.com/kartikgill/taco-box)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图像来源：[Kartik Chaudhary / Raghav Bali](https://github.com/kartikgill/taco-box)
- en: I have not tried this out because my intuition tells me too much is destroyed
    from the original. In my opinion, if i can’t read it, a computer can neither.
    I might be wrong however, when you consider that as a human, you could guess it
    is ‘TACO’, if you see ‘TA█O’. We would look at the surrounding letters. and taco
    is a common word. But a computer with a dictionary behind it might make it ‘TAMO’,
    which happens to be an english word for ‘japanese ash’*.*
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我还没有尝试过，因为我的直觉告诉我原始数据被破坏得太多。依我看，如果我读不出来，计算机也读不出来。不过，当你考虑到作为人类，你可以猜测‘TACO’，如果你看到‘TA█O’时，我们会查看周围的字母。而‘taco’是一个常见的词。但是背后有字典的计算机可能会将其识别为‘TAMO’，这恰好是‘japanese
    ash’的英文词。*。
- en: Conclusion
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: We’ve discussed many image manipulations and how they would be good for the
    task of OCR. I hope this could proof to be useful for you or at least gave you
    some inspiration to try it out yourselves. You can use my recipe as a baseline,
    but you’ll probably need to finetune a few parameters for it to be perfect for
    your dataset. Let me know how much your models have increased in accuracy!
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了许多图像处理方法以及它们如何对 OCR 任务有用。我希望这对你有帮助，或者至少能给你一些灵感，让你自己尝试。你可以使用我的配方作为基础，但你可能需要对一些参数进行微调，以使其对你的数据集完美。让我知道你的模型准确度提高了多少！
- en: I made the technique publicly available in this Jupyter [notebook](https://github.com/Toon-nooT/notebooks/blob/main/OCR_data_augmentations.ipynb).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这个 Jupyter [notebook](https://github.com/Toon-nooT/notebooks/blob/main/OCR_data_augmentations.ipynb)
    中公开了该技术。
- en: 'You may also like:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还喜欢：
- en: '[](https://toon-beerten.medium.com/hands-on-document-data-extraction-with-transformer-7130df3b6132?source=post_page-----8013080aa9fa--------------------------------)
    [## Hands-on: document data extraction with 🍩 transformer'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://toon-beerten.medium.com/hands-on-document-data-extraction-with-transformer-7130df3b6132?source=post_page-----8013080aa9fa--------------------------------)
    [## 实操：使用🍩 transformer 进行文档数据提取'
- en: My experience using donut transformers model to extract invoice indexes.
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我使用 donut transformers 模型提取发票索引的经历。
- en: toon-beerten.medium.com](https://toon-beerten.medium.com/hands-on-document-data-extraction-with-transformer-7130df3b6132?source=post_page-----8013080aa9fa--------------------------------)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: toon-beerten.medium.com](https://toon-beerten.medium.com/hands-on-document-data-extraction-with-transformer-7130df3b6132?source=post_page-----8013080aa9fa--------------------------------)
- en: 'References:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 参考资料：
- en: '[](https://opencv.org/?source=post_page-----8013080aa9fa--------------------------------)
    [## Home - OpenCV'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://opencv.org/?source=post_page-----8013080aa9fa--------------------------------)
    [## 主页 - OpenCV'
- en: OpenCV provides a real-time optimized Computer Vision library, tools, and hardware.
    It also supports model execution…
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenCV 提供了一个实时优化的计算机视觉库、工具和硬件。它还支持模型执行…
- en: opencv.org](https://opencv.org/?source=post_page-----8013080aa9fa--------------------------------)
    [](https://albumentations.ai/?source=post_page-----8013080aa9fa--------------------------------)
    [## Albumentations
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: opencv.org](https://opencv.org/?source=post_page-----8013080aa9fa--------------------------------)
    [](https://albumentations.ai/?source=post_page-----8013080aa9fa--------------------------------)
    [## Albumentations
- en: Why Albumentations Albumentations is a Python library for fast and flexible
    image augmentations. Albumentations…
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么选择 Albumentations？Albumentations 是一个用于快速和灵活图像增强的 Python 库。Albumentations…
- en: albumentations.ai](https://albumentations.ai/?source=post_page-----8013080aa9fa--------------------------------)
    [](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database?source=post_page-----8013080aa9fa--------------------------------)
    [## Research Group on Computer Vision and Artificial Intelligence - Computer Vision
    and Artificial…
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: albumentations.ai](https://albumentations.ai/?source=post_page-----8013080aa9fa--------------------------------)
    [](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database?source=post_page-----8013080aa9fa--------------------------------)
    [## 计算机视觉与人工智能研究组 - 计算机视觉与人工智能…
- en: The IAM Handwriting Database contains forms of handwritten English text which
    can be used to train and test handwritten…
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IAM 手写数据库包含可以用于训练和测试手写文本的英语手写表单…
- en: 'fki.tic.heia-fr.ch](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database?source=post_page-----8013080aa9fa--------------------------------)
    [](https://arxiv.org/abs/2205.14879?source=post_page-----8013080aa9fa--------------------------------)
    [## Easter2.0: Improving convolutional models for handwritten text recognition'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[Easter2.0：提高手写文本识别的卷积模型](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database?source=post_page-----8013080aa9fa--------------------------------) '
- en: Convolutional Neural Networks (CNN) have shown promising results for the task
    of Handwritten Text Recognition (HTR) but…
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）在手写文本识别（HTR）任务中已显示出有前景的结果，但…
- en: arxiv.org](https://arxiv.org/abs/2205.14879?source=post_page-----8013080aa9fa--------------------------------)
    [](https://github.com/Toon-nooT/notebooks?source=post_page-----8013080aa9fa--------------------------------)
    [## GitHub - Toon-nooT/notebooks
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[arxiv.org](https://arxiv.org/abs/2205.14879?source=post_page-----8013080aa9fa--------------------------------)'
- en: You can't perform that action at this time. You signed in with another tab or
    window. You signed out in another tab or…
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你现在无法执行该操作。你已在另一个标签或窗口中登录。你在另一个标签或窗口中已退出…
- en: github.com](https://github.com/Toon-nooT/notebooks?source=post_page-----8013080aa9fa--------------------------------)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[GitHub - Toon-nooT/notebooks](https://github.com/Toon-nooT/notebooks?source=post_page-----8013080aa9fa--------------------------------)'
