- en: Time Series Augmentations
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列增强
- en: 原文：[https://towardsdatascience.com/time-series-augmentations-16237134b29b?source=collection_archive---------0-----------------------#2023-10-19](https://towardsdatascience.com/time-series-augmentations-16237134b29b?source=collection_archive---------0-----------------------#2023-10-19)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/time-series-augmentations-16237134b29b?source=collection_archive---------0-----------------------#2023-10-19](https://towardsdatascience.com/time-series-augmentations-16237134b29b?source=collection_archive---------0-----------------------#2023-10-19)
- en: A simple yet effective way to increase the amount of time series data
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一种简单但有效的增加时间序列数据量的方法
- en: '[](https://medium.com/@an231?source=post_page-----16237134b29b--------------------------------)[![Alexander
    Nikitin](../Images/decc36cddc4c7a23952569e293e7d209.png)](https://medium.com/@an231?source=post_page-----16237134b29b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----16237134b29b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----16237134b29b--------------------------------)
    [Alexander Nikitin](https://medium.com/@an231?source=post_page-----16237134b29b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@an231?source=post_page-----16237134b29b--------------------------------)[![亚历山大·尼基廷](../Images/decc36cddc4c7a23952569e293e7d209.png)](https://medium.com/@an231?source=post_page-----16237134b29b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----16237134b29b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----16237134b29b--------------------------------)
    [亚历山大·尼基廷](https://medium.com/@an231?source=post_page-----16237134b29b--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5afaa29ee25a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-augmentations-16237134b29b&user=Alexander+Nikitin&userId=5afaa29ee25a&source=post_page-5afaa29ee25a----16237134b29b---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----16237134b29b--------------------------------)
    ·8 min read·Oct 19, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F16237134b29b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-augmentations-16237134b29b&user=Alexander+Nikitin&userId=5afaa29ee25a&source=-----16237134b29b---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5afaa29ee25a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-augmentations-16237134b29b&user=Alexander+Nikitin&userId=5afaa29ee25a&source=post_page-5afaa29ee25a----16237134b29b---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----16237134b29b--------------------------------)
    ·8 min read·2023年10月19日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F16237134b29b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-augmentations-16237134b29b&user=Alexander+Nikitin&userId=5afaa29ee25a&source=-----16237134b29b---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F16237134b29b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-augmentations-16237134b29b&source=-----16237134b29b---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F16237134b29b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-augmentations-16237134b29b&source=-----16237134b29b---------------------bookmark_footer-----------)'
- en: '*This blog post is available as a* [*jupyter notebook on GitHub*](https://github.com/AlexanderVNikitin/tsgm/blob/main/tutorials/augmentations.ipynb)*.*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*这篇博客文章可以在* [*GitHub上的jupyter notebook*](https://github.com/AlexanderVNikitin/tsgm/blob/main/tutorials/augmentations.ipynb)*找到。*'
- en: Augmentations have become an indispensable component in the realm of computer
    vision pipelines. However, their popularity hasn’t reached the same heights in
    other domains, such as time series. In this tutorial, I will delve into the world
    of time series augmentations, shedding light on their significance and providing
    concrete examples of their application using the powerful generative time series
    modeling library, TSGM [5].
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 增强已成为计算机视觉管道中不可或缺的组成部分。然而，它们在其他领域如时间序列中的受欢迎程度却没有达到相同的高度。在本教程中，我将**深入探讨**时间序列增强的世界，阐明其重要性，并提供使用强大的生成时间序列建模库TSGM
    [5]的实际应用示例。
- en: Our starting point is a dataset denoted (𝐗, 𝐲). Here, 𝐱ᵢ ∈ 𝐗 are multivariate
    (meaning, each time point is a multiple dimensional feature vector) time series,
    and y are labels. Predicting labels y is called a downstream task. Our goal is
    to use (𝐗, 𝐲) to produce additional samples (𝐗*, 𝐲*), which could help us solve
    the downstream task more effectively (in terms of predictive performance or robustness).
    For simplicity, we won’t work with labels in this tutorial, but the methods we
    describe here are straightforward to generalize to the case with labels, and the
    software implementations we use are easily extended to the supervised case by
    adding additional parameters to the `.generate` method (see examples below).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的起点是一个标记为（𝐗，𝐲）的数据集。在这里，𝐱ᵢ ∈ 𝐗 是多变量的（意味着每个时间点是一个多维特征向量）时间序列，而y是标签。预测标签y被称为下游任务。我们的目标是使用（𝐗，𝐲）生成额外的样本（𝐗*，𝐲*），这可以帮助我们更有效地解决下游任务（在预测性能或鲁棒性方面）。为了简化起见，我们在本教程中不会处理标签，但我们在这里描述的方法可以很容易地推广到有标签的情况，并且我们使用的软件实现可以通过向`.generate`方法添加额外参数来轻松扩展到监督情况（见下例）。
- en: Without further ado, let’s consider time series augmentations one by one.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 事不宜迟，让我们逐一考虑时间序列增强。
- en: In TSGM, all augmentations are neatly organized in `tsgm.models.augmentations`,
    and you can check out the comprehensive documentation available at [TSGM documentation](https://tsgm.readthedocs.io/en/latest/guides/introduction.html#augmentations).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在TSGM中，所有的增强方法都整齐地组织在`tsgm.models.augmentations`中，你可以查看 [TSGM documentation](https://tsgm.readthedocs.io/en/latest/guides/introduction.html#augmentations)
    提供的全面文档。
- en: 'Now, let’s kickstart coding examples by installing tsgm:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过安装tsgm来启动编码示例：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Moving forward, we import tsgm, and load an exemplary dataset. A tensor `X`
    now contains 100 sine time series of length 64, with 2 features each. With random
    shift, frequencies, and amplitudes (maximum amplitude is 20).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们导入tsgm，并加载一个示例数据集。一个张量`X`现在包含100个长度为64的正弦时间序列，每个序列有2个特征。具有随机的偏移、频率和振幅（最大振幅为20）。
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Jittering / Gaussian noise
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 抖动 / Gaussian噪声
- en: As the first augmentation we consider jittering.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一个增强方法，我们考虑抖动。
- en: Time series data are augmented with random Gaussian noise ([Wikipedia](https://en.wikipedia.org/wiki/Gaussian_noise)))
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列数据通过随机Gaussian噪声进行增强 ([Wikipedia](https://en.wikipedia.org/wiki/Gaussian_noise)))
- en: '![](../Images/44c18aa6fd22c7037051e5a7cefa7519.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/44c18aa6fd22c7037051e5a7cefa7519.png)'
- en: 'In tsgm, Gaussian noise augmentation can be applied as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在tsgm中，Gaussian噪声增强可以如下应用：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The idea behind Gaussian noise augmentation is that adding a small amount of
    jittering to time series probably will not change it significantly but will increase
    the amount of such noisy samples in our dataset. It often makes the downstream
    models more robust to noisy samples or improves predictive performance.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Gaussian噪声增强的理念是，向时间序列中添加少量的抖动可能不会显著改变它，但会增加数据集中这种噪声样本的数量。这通常使下游模型对噪声样本更具鲁棒性或提高预测性能。
- en: The hyperparameters of Gaussian noise and the way of adding the noise (e.g.,
    Gaussian noise can increase towards the end of a time series) is a difficult question
    and depends on a particular dataset and downstream problem. It is often worth
    experimenting and seeing how those parameters affect the performance of the target
    model.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Gaussian噪声的超参数及其添加方式（例如，Gaussian噪声可能会在时间序列的末尾增加）是一个困难的问题，并且取决于特定的数据集和下游问题。通常值得进行实验，看看这些参数如何影响目标模型的性能。
- en: Here, we provide a visualization of samples from the original sine dataset and
    augmented samples.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们提供了原始正弦数据集样本和增强样本的可视化。
- en: '![](../Images/bc5f06309b37e786f90ecfeff2727c18.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bc5f06309b37e786f90ecfeff2727c18.png)'
- en: Original time series and synthetic data generated via Jittering.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 原始时间序列和通过抖动生成的合成数据。
- en: Shuffle Features
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 打乱特征
- en: Another approach to time series augmentation is simply shuffle the features.
    This approach is suitable only for particular multivariate time series, where
    they are invariant to all or particular permutations of features. For instance,
    it can be applied to time series where each feature represents same independent
    measurements from various sensors.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种时间序列增强的方法是简单地打乱特征。这种方法仅适用于特定的多变量时间序列，其中这些序列对所有或特定特征的排列是不变的。例如，它可以应用于每个特征表示来自各种传感器的相同独立测量的时间序列。
- en: To explain this approach, let’s take the example of five identical sensors,
    labeled as S_1, S_2, S_3, S_4, and S_5\. For the sake of illustration, let’s assume
    that sensors 1–4 are probably exchangeable with respect to rotations. Then it
    makes sense to try augmenting data with feature rotations with respect to rotations
    of S_1, …, S_5 sensors.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解释这种方法，假设有五个相同的传感器，标记为 S_1, S_2, S_3, S_4 和 S_5。为了说明，假设传感器 1 到 4 在旋转方面是可以互换的。那么，尝试在
    S_1，…，S_5 传感器的旋转角度上进行特征旋转的数据增强是有意义的。
- en: '![](../Images/33ef023a670f580bf559f0e92d317013.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/33ef023a670f580bf559f0e92d317013.png)'
- en: In this example, five sensors are present, and measurements from those sensors
    generate five-dimensional time series data. Sensors 1 to 4 can be arbitrarily
    rotated to generate new synthetic samples (e.g., 1->2, 2->3, 3->4, 4->1). Thus,
    by applying such transformations to original data, one can generate novel synthetic
    samples.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，有五个传感器，来自这些传感器的测量生成了五维时间序列数据。传感器 1 到 4 可以被任意旋转以生成新的合成样本（例如，1->2，2->3，3->4，4->1）。因此，通过对原始数据应用这些变换，可以生成新的合成样本。
- en: 'Similarly to the previous example, the augmentation can work as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的例子类似，增强可以如下进行：
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here, we show one sample from a timeseries with 5 features, and an augmented
    sample, analogously to the image above.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们展示了一个具有 5 个特征的时间序列样本，以及一个增强样本，类似于上面的图像。
- en: '![](../Images/5c82f025b90a71ba39c5d85fa4431094.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5c82f025b90a71ba39c5d85fa4431094.png)'
- en: Original time series and synthetic data generated via shuffling features.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 原始时间序列和通过特征洗牌生成的合成数据。
- en: Slice and Shuffle
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 切片和洗牌
- en: 'Slice and shuffle augmentation [3] cuts a time series into slices and shuffles
    those pieces. This augmentation can be performed for time series that exhibit
    some form of invariance over time. For instance, imagine a time series measured
    from wearable devices for several days. The good strategy for this case is to
    slice time series by days and, by shuffling those days, get additional samples.
    Slice and shuffle augmentation is visualized in the following image:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 切片和洗牌增强 [3] 将时间序列切成片段并洗牌这些片段。对于在时间上表现出某种形式的不变性的时间序列，可以执行这种增强。例如，假设从可穿戴设备上测量的时间序列持续了几天。在这种情况下，一个好的策略是按天切割时间序列，并通过洗牌这些天来获得额外的样本。切片和洗牌增强在以下图像中可视化：
- en: '![](../Images/fb2647d33c5989842439315ba9b28271.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fb2647d33c5989842439315ba9b28271.png)'
- en: Slice and Shuffle schematic visualization.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 切片和洗牌示意图。
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Let’s view augmented and original samples:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看增强样本和原始样本：
- en: '![](../Images/49b868a4660f4f006921f821a774773b.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/49b868a4660f4f006921f821a774773b.png)'
- en: Original time series and synthetic data generated via slice and shuffle.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 原始时间序列和通过切片和洗牌生成的合成数据。
- en: Magnitude Warping
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 幅度扭曲
- en: Magnitude warping [3] changes the magnitude of each sample in a time series
    dataset by multiplication of the original time series with a cubic spline curve.
    This process scales the magnitude of time series, which can be beneficial in many
    cases, such as our synthetic example with sines `n_knots` number of knots at random
    magnitudes distributed as *N(1, σ^2*) where *σ* is set by a parameter `sigma`
    in function `.generate`.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 幅度扭曲 [3] 通过将原始时间序列与立方样条曲线相乘来改变时间序列数据集中每个样本的幅度。这个过程会缩放时间序列的幅度，这在许多情况下是有益的，例如我们用正弦波
    `n_knots` 数量的结点在随机幅度下分布的合成例子，其中 *σ* 由函数 `.generate` 中的参数 `sigma` 设置。
- en: '[PRE6]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Here is an example of original data and augmented samples generated with `MagnitudeWarping`.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个原始数据和通过 `MagnitudeWarping` 生成的增强样本的例子。
- en: '![](../Images/0e3f871956ba908f9ed5e0b9726b5e43.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0e3f871956ba908f9ed5e0b9726b5e43.png)'
- en: Original time series and synthetic data generated via magnitude warping.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 原始时间序列和通过幅度扭曲生成的合成数据。
- en: Window Warping
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 窗口扭曲
- en: 'In this technique [4], the selected windows in time series data are either
    speeding up or down. Then, the whole resulting time series is scaled back to the
    original size in order to keep the timesteps at the original length. See an example
    of such augmentation below:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种技术 [4] 中，时间序列数据中的选定窗口要么加速，要么减速。然后，将整个结果时间序列缩放回原始大小，以保持时间步长在原始长度。请参见下面的这种增强的例子：
- en: '![](../Images/bb3e8162230f88cfb55b95b90b7bb6e7.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bb3e8162230f88cfb55b95b90b7bb6e7.png)'
- en: Such augmentation can be beneficial, e.g., in modeling equipment. In such applications,
    sensor measurements can change the speed of change depending on how those pieces
    of equipment are used.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这种增强可能是有益的，例如，在设备建模中。在这种应用中，传感器测量可以根据设备的使用方式改变变化速度。
- en: In tsgm, as always, the generation can be done via
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在tsgm中，与往常一样，可以通过以下方式进行生成：
- en: '[PRE7]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: An example of a generated time series can be found below.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 下面可以找到一个生成的时间序列示例。
- en: '![](../Images/f125afd7137a500f20d74a2099619531.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f125afd7137a500f20d74a2099619531.png)'
- en: Original time series and synthetic data generated via window warping.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 原始时间序列和通过窗口规整生成的合成数据。
- en: Dynamic Time Warping Barycentric Average (DTWBA)
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动态时间规整重心平均（DTWBA）
- en: Dynamic Time Warping Barycentric Average (DTWBA)[2] is an augmentation method
    that is based on Dynamic Time Warping (DTW). DTW is a method of measuring similarity
    between time series. The idea is to “sync” those time series, as it is demonstrated
    in the following picture.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 动态时间规整重心平均（DTWBA）[2]是一种基于动态时间规整（DTW）的扩增方法。DTW是一种测量时间序列相似性的方法。其思想是“同步”这些时间序列，如下图所示。
- en: '![](../Images/6a525a2c686cff6601fbd76b6414d4b0.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a525a2c686cff6601fbd76b6414d4b0.png)'
- en: DTW is measured for two time series signals sin(x) and sin(2x). DTW measurement
    is shown with the white line. Also, a cross-similarity matrix is visualized.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: DTW用于测量两个时间序列信号sin(x)和sin(2x)的相似性。DTW测量通过白色线条显示。此外，还可视化了交叉相似性矩阵。
- en: More details on DTW computation are available at [https://rtavenar.github.io/blog/dtw.html](https://rtavenar.github.io/blog/dtw.html).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 关于DTW计算的更多细节可以在[https://rtavenar.github.io/blog/dtw.html](https://rtavenar.github.io/blog/dtw.html)中找到。
- en: 'DTWBA goes like this:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: DTWBA的过程如下：
- en: 1\. The algorithm picks one time series to initialize the DTWBA result. This
    time series can either be given explicitly or can be chosen randomly from the
    dataset
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 算法选择一个时间序列来初始化DTWBA结果。这个时间序列可以明确给出，也可以从数据集中随机选择。
- en: 2\. For each of the `N` time series, the algorithm computes DTW distance and
    the path (the path is the mapping that minimizes the distance)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 对于每一个`N`个时间序列，算法计算DTW距离和路径（路径是最小化距离的映射）。
- en: 3\. After computing all `N` DTW distances, the algorithm updates the DTWBA result
    by doing the average with respect to all the paths found above
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 在计算所有`N`个DTW距离后，算法通过对所有找到的路径进行平均来更新DTWBA结果。
- en: 4\. The algorithm repeats steps (2) and (3) until the DTWBA result converges
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 算法重复步骤（2）和（3），直到DTWBA结果收敛。
- en: A reference implementation can be found in [tslearn](https://github.com/tslearn-team/tslearn/blob/main/tslearn/barycenters/dba.py#L60),
    and a description can be found in [2].
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 参考实现可以在[tslearn](https://github.com/tslearn-team/tslearn/blob/main/tslearn/barycenters/dba.py#L60)中找到，描述可以在[2]中找到。
- en: In tsgm, the samples can be generated as follows
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在tsgm中，可以通过以下方式生成样本：
- en: '[PRE8]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/5f90e46a8f02f3b1b3b87f23a54fec58.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5f90e46a8f02f3b1b3b87f23a54fec58.png)'
- en: Original time series and synthetic data generated via DTWBA.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 原始时间序列和通过DTWBA生成的合成数据。
- en: Augmentation with Generative Machine Learning Models
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用生成机器学习模型进行扩增
- en: Another approach to augmentation is to train a machine learning model on historical
    data and train it to generate novel synthetic samples. It is a blackbox method
    because it is hard to interpret how new samples were generated. Several methods
    can be applied in the case of time series; in particular, tsgm has VAE, GANs,
    and Gaussian processes. An example of the generation of synthetic time series
    with VAEs is
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种扩增方法是训练一个机器学习模型在历史数据上，并训练它生成新颖的合成样本。这是一种黑箱方法，因为很难解释新样本是如何生成的。在时间序列的情况下，可以应用几种方法；特别是，tsgm拥有VAE、GANs和高斯过程。以下是使用VAE生成合成时间序列的示例：
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Conclusion
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: We explored several methods for synthetic time series generation. Many of them
    introduce inductive biases into the model and are useful in practical settings.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探索了几种合成时间序列生成方法。许多方法将归纳偏差引入模型，并在实际应用中非常有用。
- en: How to choose? First, analyze whether your problem contains invariances. Is
    it invariant to random noise? Is it invariant to feature shuffling?
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如何选择？首先，分析你的问题是否包含不变性。它对随机噪声不变吗？对特征洗牌不变吗？
- en: Next, choose a broad set of methods and verify whether any of the selected methods
    improve the performance of your downstream problem (tsgm has [downstream performance
    metric](https://tsgm.readthedocs.io/en/latest/autoapi/tsgm/metrics/index.html#tsgm.metrics.DownstreamPerformanceMetric)).
    Then, select the set of augmentation methods that gives the largest performance
    boost.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，选择一组广泛的方法，并验证这些方法中的任何一种是否提高了下游问题的性能（tsgm有[下游性能指标](https://tsgm.readthedocs.io/en/latest/autoapi/tsgm/metrics/index.html#tsgm.metrics.DownstreamPerformanceMetric)）。然后，选择那些提供最大性能提升的扩增方法。
- en: '*Last, but not least, I thank Letizia Iannucci and Georgy Gritsenko for help
    and useful discussions about writing of this post. Unless otherwise noted, all
    images are by the author.*'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*最后但同样重要的是，我感谢 Letizia Iannucci 和 Georgy Gritsenko 对于这篇文章写作的帮助和有益讨论。除非另有说明，所有图片均由作者提供。*'
- en: 'This blog post is a part of the project TSGM, in which we are creating a tool
    for enhancing time series pipelines via augmentation and synthetic data generation.
    If you found it helpful, take a look at [our repo](https://github.com/AlexanderVNikitin/tsgm)
    and consider citing [the paper about TSGM](https://arxiv.org/abs/2305.11567):'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇博客文章是 TSGM 项目的一部分，我们正在创建一个工具，通过增强和合成数据生成来提升时间序列管道。如果你觉得它有帮助，可以查看 [我们的仓库](https://github.com/AlexanderVNikitin/tsgm)
    并考虑引用 [关于 TSGM 的论文](https://arxiv.org/abs/2305.11567)：
- en: '[PRE11]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: References
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] H. Sakoe and S. Chiba, “Dynamic programming algorithm optimization for
    spoken word recognition”. IEEE Transactions on Acoustics, Speech, and Signal Processing,
    26(1), 43–49 (1978).'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] H. Sakoe 和 S. Chiba, “用于口语词汇识别的动态规划算法优化”。IEEE 声学、语音与信号处理学报, 26(1), 43–49
    (1978)。'
- en: '[2] F. Petitjean, A. Ketterlin & P. Gancarski. A global averaging method for
    dynamic time warping, with applications to clustering. Pattern Recognition, Elsevier,
    2011, Vol. 44, Num. 3, pp. 678–693'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] F. Petitjean, A. Ketterlin & P. Gancarski. 动态时间规整的全局平均方法及其在聚类中的应用。模式识别，Elsevier，2011，第
    44 卷，第 3 期，第 678–693 页。'
- en: '[3] Um TT, Pfister FM, Pichler D, Endo S, Lang M, Hirche S,'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Um TT, Pfister FM, Pichler D, Endo S, Lang M, Hirche S,'
- en: 'Fietzek U, Kulic´ D (2017) Data augmentation of wearable sensor data for parkinson’s
    disease monitoring using convolutional neural networks. In: Proceedings of the
    19th ACM international conference on multimodal interaction, pp. 216–220'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Fietzek U, Kulic´ D (2017) 使用卷积神经网络对可穿戴传感器数据进行数据增强以监测帕金森病。发表于第 19 届 ACM 国际多模态交互会议论文集，第
    216–220 页。
- en: '[4] Rashid, K.M. and Louis, J., 2019\. Window-warping: a time series data augmentation
    of IMU data for construction equipment activity identification. In ISARC. Proceedings
    of the international symposium on automation and robotics in construction (Vol.
    36, pp. 651–657). IAARC Publications.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Rashid, K.M. 和 Louis, J., 2019\. Window-warping: 一种用于施工设备活动识别的 IMU 数据时间序列数据增强方法。发表于
    ISARC. 国际自动化与施工机器人学会国际研讨会论文集（第 36 卷，第 651–657 页）。IAARC 出版社。'
- en: '[5] Nikitin, A., Iannucci, L. and Kaski, S., 2023\. TSGM: A Flexible Framework
    for Generative Modeling of Synthetic Time Series. *arXiv preprint arXiv:2305.11567*.
    [Arxiv link](https://arxiv.org/abs/2305.11567).'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Nikitin, A., Iannucci, L. 和 Kaski, S., 2023\. TSGM: 一种用于合成时间序列生成建模的灵活框架。*arXiv
    预印本 arXiv:2305.11567*。 [Arxiv 链接](https://arxiv.org/abs/2305.11567)。'
