# ExLlamaV2: è¿è¡Œ LLMs çš„æœ€å¿«åº“

> åŸæ–‡ï¼š[`towardsdatascience.com/exllamav2-the-fastest-library-to-run-llms-32aeda294d26?source=collection_archive---------0-----------------------#2023-11-20`](https://towardsdatascience.com/exllamav2-the-fastest-library-to-run-llms-32aeda294d26?source=collection_archive---------0-----------------------#2023-11-20)

## é‡åŒ–å¹¶è¿è¡Œ EXL2 æ¨¡å‹

[](https://medium.com/@mlabonne?source=post_page-----32aeda294d26--------------------------------)![Maxime Labonne](https://medium.com/@mlabonne?source=post_page-----32aeda294d26--------------------------------)[](https://towardsdatascience.com/?source=post_page-----32aeda294d26--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----32aeda294d26--------------------------------) [Maxime Labonne](https://medium.com/@mlabonne?source=post_page-----32aeda294d26--------------------------------)

Â·

[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdc89da634938&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexllamav2-the-fastest-library-to-run-llms-32aeda294d26&user=Maxime+Labonne&userId=dc89da634938&source=post_page-dc89da634938----32aeda294d26---------------------post_header-----------) å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----32aeda294d26--------------------------------) Â· 6 åˆ†é’Ÿé˜…è¯» Â· 2023 å¹´ 11 æœˆ 20 æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F32aeda294d26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexllamav2-the-fastest-library-to-run-llms-32aeda294d26&user=Maxime+Labonne&userId=dc89da634938&source=-----32aeda294d26---------------------clap_footer-----------)

--

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F32aeda294d26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexllamav2-the-fastest-library-to-run-llms-32aeda294d26&source=-----32aeda294d26---------------------bookmark_footer-----------)![](img/032261661e8c8f24175b7d7766cd2fae.png)

å›¾ç‰‡ç”±ä½œè€…æä¾›

å¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œé‡åŒ–æ˜¯å‡å°‘è¿™äº›æ¨¡å‹å¤§å°å’ŒåŠ é€Ÿæ¨ç†çš„æœ€å—æ¬¢è¿çš„æ–¹æ³•ã€‚åœ¨è¿™äº›æŠ€æœ¯ä¸­ï¼ŒGPTQ åœ¨ GPU ä¸Šçš„è¡¨ç°éå¸¸å‡ºè‰²ã€‚ä¸æœªé‡åŒ–æ¨¡å‹ç›¸æ¯”ï¼Œè¿™ç§æ–¹æ³•ä½¿ç”¨çš„æ˜¾å­˜å‡ ä¹å°‘äº† 3 å€ï¼ŒåŒæ—¶æä¾›äº†ç±»ä¼¼çš„å‡†ç¡®åº¦å’Œæ›´å¿«çš„ç”Ÿæˆé€Ÿåº¦ã€‚å®ƒå˜å¾—å¦‚æ­¤å—æ¬¢è¿ï¼Œä»¥è‡³äºæœ€è¿‘å·²ç»ç›´æ¥é›†æˆåˆ°[transformers åº“](https://huggingface.co/blog/gptq-integration)ä¸­ã€‚

[**ExLlamaV2**](https://github.com/turboderp/exllamav2)æ˜¯ä¸€ä¸ªæ—¨åœ¨è¿›ä¸€æ­¥æå‡ GPTQ æ€§èƒ½çš„åº“ã€‚å¾—ç›Šäºæ–°çš„å†…æ ¸ï¼Œå®ƒç»è¿‡ä¼˜åŒ–ï¼Œå¯ä»¥å®ç°ï¼ˆæå¿«çš„ï¼‰æ¨ç†é€Ÿåº¦ã€‚å®ƒè¿˜å¼•å…¥äº†ä¸€ç§æ–°çš„é‡åŒ–æ ¼å¼ EXL2ï¼Œä¸ºæƒé‡å­˜å‚¨æ–¹å¼æä¾›äº†æå¤§çš„çµæ´»æ€§ã€‚

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨å¦‚ä½•åœ¨ EXL2 æ ¼å¼ä¸­é‡åŒ–åŸºç¡€æ¨¡å‹ä»¥åŠå¦‚ä½•è¿è¡Œå®ƒä»¬ã€‚é€šå¸¸ï¼Œä»£ç å¯åœ¨[GitHub](https://github.com/mlabonne/llm-course/blob/main/Quantize_models_with_ExLlamaV2.ipynb)å’Œ[Google Colab](https://colab.research.google.com/drive/1yrq4XBlxiA0fALtMoT2dwiACVc77PHou?usp=sharing)ä¸Šè·å–ã€‚

# âš¡ é‡åŒ– EXL2 æ¨¡å‹

è¦å¼€å§‹æ¢ç´¢ï¼Œæˆ‘ä»¬éœ€è¦å®‰è£… ExLlamaV2 åº“ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿä½¿ç”¨ä»“åº“ä¸­çš„ä¸€äº›è„šæœ¬ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬å°†ä»æºä»£ç å®‰è£…å®ƒçš„åŸå› ï¼š

```py
git clone https://github.com/turboderp/exllamav2
pip install exllamav2
```

ç°åœ¨ ExLlamaV2 å·²å®‰è£…ï¼Œæˆ‘ä»¬éœ€è¦ä¸‹è½½è¦ä»¥è¿™ç§æ ¼å¼é‡åŒ–çš„æ¨¡å‹ã€‚æˆ‘ä»¬ä½¿ç”¨ä¼˜ç§€çš„[zephyr-7B-beta](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta)ï¼Œè¿™æ˜¯ä¸€ä¸ªä½¿ç”¨ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰å¾®è°ƒçš„[Mistral-7B](https://huggingface.co/mistralai/Mistral-7B-v0.1)æ¨¡å‹ã€‚å®ƒå£°ç§°åœ¨ MT bench ä¸Šè¶…è¶Šäº† Llama-2 70b chatï¼Œè¿™å¯¹äºä¸€ä¸ªå°åå€çš„æ¨¡å‹æ¥è¯´æ˜¯ä¸€ä¸ªä»¤äººå°è±¡æ·±åˆ»çš„ç»“æœã€‚ä½ å¯ä»¥é€šè¿‡[è¿™ä¸ªç©ºé—´](https://huggingface.co/spaces/HuggingFaceH4/zephyr-chat)è¯•ç”¨åŸºç¡€ Zephyr æ¨¡å‹ã€‚

æˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ä¸‹è½½ zephyr-7B-betaï¼ˆè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œå› ä¸ºæ¨¡å‹çº¦ä¸º 15 GBï¼‰ï¼š

```py
git lfs install
git clone https://huggingface.co/HuggingFaceH4/zephyr-7b-beta
```

GPTQ è¿˜éœ€è¦ä¸€ä¸ª**æ ¡å‡†æ•°æ®é›†**ï¼Œç”¨äºé€šè¿‡æ¯”è¾ƒåŸºç¡€æ¨¡å‹åŠå…¶é‡åŒ–ç‰ˆæœ¬çš„è¾“å‡ºï¼Œæ¥æµ‹é‡é‡åŒ–è¿‡ç¨‹çš„å½±å“ã€‚æˆ‘ä»¬å°†ä½¿ç”¨[wikitext æ•°æ®é›†](https://huggingface.co/datasets/wikitext)å¹¶ç›´æ¥ä¸‹è½½æµ‹è¯•æ–‡ä»¶ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```py
wget https://huggingface.co/datasets/wikitext/resolve/9a9e482b5987f9d25b3a9b2883fc6cc9fd8071b3/wikitext-103-v1/wikitext-test.parquet
```

å®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨ ExLlamaV2 åº“æä¾›çš„ `[convert.py](https://github.com/turboderp/exllamav2/blob/master/convert.py)` è„šæœ¬ã€‚æˆ‘ä»¬ä¸»è¦å…³æ³¨å››ä¸ªå‚æ•°ï¼š

+   `-i`ï¼šè¦è½¬æ¢çš„åŸºç¡€æ¨¡å‹çš„è·¯å¾„ï¼ˆHF æ ¼å¼ï¼ŒFP16ï¼‰ã€‚

+   `-o`ï¼šåŒ…å«ä¸´æ—¶æ–‡ä»¶å’Œæœ€ç»ˆè¾“å‡ºçš„å·¥ä½œç›®å½•çš„è·¯å¾„ã€‚

+   `-c`ï¼šæ ¡å‡†æ•°æ®é›†çš„è·¯å¾„ï¼ˆParquet æ ¼å¼ï¼‰ã€‚

+   `-b`ï¼šæ¯ä¸ªæƒé‡çš„ç›®æ ‡å¹³å‡ä½æ•°ï¼ˆbpwï¼‰ã€‚ä¾‹å¦‚ï¼Œ4.0 bpw å°†ä»¥ 4 ä½ç²¾åº¦å­˜å‚¨æƒé‡ã€‚

å‚æ•°çš„å®Œæ•´åˆ—è¡¨å¯åœ¨[æ­¤é¡µé¢](https://github.com/turboderp/exllamav2/blob/master/doc/convert.md)ä¸Šæ‰¾åˆ°ã€‚è®©æˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹å‚æ•°å¼€å§‹é‡åŒ–è¿‡ç¨‹ï¼š

```py
mkdir quant
python python exllamav2/convert.py \
    -i base_model \
    -o quant \
    -c wikitext-test.parquet \
    -b 5.0
```

è¯·æ³¨æ„ï¼Œä½ éœ€è¦ GPU æ¥é‡åŒ–æ­¤æ¨¡å‹ã€‚å®˜æ–¹æ–‡æ¡£æŒ‡å‡ºï¼Œå¯¹äº 7B æ¨¡å‹ï¼Œå¤§çº¦éœ€è¦ 8 GB çš„ VRAMï¼Œå¯¹äº 70B æ¨¡å‹ï¼Œéœ€è¦ 24 GB çš„ VRAMã€‚åœ¨ Google Colab ä¸Šï¼Œæˆ‘ä½¿ç”¨ T4 GPU é‡åŒ– zephyr-7b-beta èŠ±è´¹äº† 2 å°æ—¶ 10 åˆ†é’Ÿã€‚

åœ¨åº•å±‚ï¼ŒExLlamaV2 åˆ©ç”¨ GPTQ ç®—æ³•é™ä½æƒé‡çš„ç²¾åº¦ï¼ŒåŒæ—¶æœ€å¤§ç¨‹åº¦åœ°å‡å°‘å¯¹è¾“å‡ºçš„å½±å“ã€‚æ‚¨å¯ä»¥åœ¨è¿™ç¯‡[æ–‡ç« ](https://medium.com/towards-data-science/4-bit-quantization-with-gptq-36b0f4f02c34)ä¸­æ‰¾åˆ°æœ‰å…³ GPTQ ç®—æ³•çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

é‚£ä¹ˆï¼Œæˆ‘ä»¬ä¸ºä»€ä¹ˆä½¿ç”¨â€œEXL2â€æ ¼å¼è€Œä¸æ˜¯å¸¸è§„çš„ GPTQ æ ¼å¼å‘¢ï¼ŸEXL2 å¸¦æ¥äº†ä¸€äº›æ–°åŠŸèƒ½ï¼š

+   å®ƒæ”¯æŒ**ä¸åŒçº§åˆ«çš„é‡åŒ–**ï¼šä¸é™äº 4 ä½ç²¾åº¦ï¼Œå¯ä»¥å¤„ç† 2ã€3ã€4ã€5ã€6 å’Œ 8 ä½çš„é‡åŒ–ã€‚

+   å®ƒå¯ä»¥**æ··åˆä¸åŒç²¾åº¦**åœ¨æ¨¡å‹å†…éƒ¨å’Œæ¯ä¸ªå±‚å†…ï¼Œä»¥ä¿ç•™æœ€é‡è¦çš„æƒé‡å’Œå…·æœ‰æ›´å¤šæ¯”ç‰¹çš„å±‚ã€‚

ExLlamaV2 åœ¨é‡åŒ–è¿‡ç¨‹ä¸­åˆ©ç”¨äº†è¿™ç§é¢å¤–çš„çµæ´»æ€§ã€‚å®ƒå°è¯•ä¸åŒçš„é‡åŒ–å‚æ•°å¹¶æµ‹é‡å®ƒä»¬å¼•å…¥çš„è¯¯å·®ã€‚é™¤äº†è¯•å›¾æœ€å°åŒ–è¯¯å·®å¤–ï¼ŒExLlamaV2 è¿˜å¿…é¡»è¾¾åˆ°ä½œä¸ºå‚æ•°ç»™å‡ºçš„æ¯ä¸ªæƒé‡å¹³å‡æ¯”ç‰¹æ•°çš„ç›®æ ‡ã€‚ç”±äºè¿™ç§è¡Œä¸ºï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºå¹³å‡æ¯ä¸ªæƒé‡ä¸º 3.5 æˆ– 4.5 çš„é‡åŒ–æ¨¡å‹ï¼Œä¾‹å¦‚ã€‚

å®ƒåˆ›å»ºçš„ä¸åŒå‚æ•°çš„åŸºå‡†ä¿å­˜åœ¨`measurement.json`æ–‡ä»¶ä¸­ã€‚ä»¥ä¸‹ JSON æ˜¾ç¤ºäº†ä¸€ä¸ªå±‚çš„æµ‹é‡ï¼š

```py
"key": "model.layers.0.self_attn.q_proj",
"numel": 16777216,
"options": [
    {
        "desc": "0.05:3b/0.95:2b 32g s4",
        "bpw": 2.1878662109375,
        "total_bits": 36706304.0,
        "err": 0.011161142960190773,
        "qparams": {
            "group_size": 32,
            "bits": [
                3,
                2
            ],
            "bits_prop": [
                0.05,
                0.95
            ],
            "scale_bits": 4
        }
    },
```

åœ¨æ­¤è¯•éªŒä¸­ï¼ŒExLlamaV2 ä½¿ç”¨äº† 5% çš„ 3 ä½ç²¾åº¦å’Œ 95% çš„ 2 ä½ç²¾åº¦ï¼Œå¹³å‡å€¼ä¸º 2.188 bpwï¼Œç»„å¤§å°ä¸º 32ã€‚è¿™å¼•å…¥äº†ä¸€ä¸ªæ˜¾è‘—çš„è¯¯å·®ï¼Œè¿™å°†è¢«è€ƒè™‘åœ¨å†…ä»¥é€‰æ‹©æœ€ä½³å‚æ•°ã€‚

# ğŸ¦™ è¿è¡Œ ExLlamaV2 è¿›è¡Œæ¨ç†

ç°åœ¨æˆ‘ä»¬çš„æ¨¡å‹å·²ç»é‡åŒ–ï¼Œæˆ‘ä»¬æƒ³è¦è¿è¡Œå®ƒä»¥æŸ¥çœ‹å…¶æ€§èƒ½ã€‚åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å°†`base_model`ç›®å½•ä¸­çš„é‡è¦é…ç½®æ–‡ä»¶å¤åˆ¶åˆ°æ–°çš„`quant`ç›®å½•ä¸­ã€‚åŸºæœ¬ä¸Šï¼Œæˆ‘ä»¬å¸Œæœ›æ¯ä¸ªééšè—æ–‡ä»¶ï¼ˆ`.*`ï¼‰æˆ– safetensors æ–‡ä»¶éƒ½åŒ…å«åœ¨å†…ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä¸éœ€è¦ ExLlamaV2 åœ¨é‡åŒ–è¿‡ç¨‹ä¸­åˆ›å»ºçš„`out_tensor`ç›®å½•ã€‚

åœ¨ bash ä¸­ï¼Œæ‚¨å¯ä»¥è¿™æ ·å®ç°ï¼š

```py
!rm -rf quant/out_tensor
!rsync -av --exclude='*.safetensors' --exclude='.*' ./base_model/ ./quant/
```

æˆ‘ä»¬çš„ EXL2 æ¨¡å‹å·²å‡†å¤‡å°±ç»ªï¼Œå¹¶æœ‰å‡ ç§è¿è¡Œé€‰é¡¹ã€‚æœ€ç›´æ¥çš„æ–¹æ³•æ˜¯ä½¿ç”¨ ExLlamaV2 ä»“åº“ä¸­çš„`test_inference.py`è„šæœ¬ï¼ˆè¯·æ³¨æ„ï¼Œè¿™é‡Œæˆ‘æ²¡æœ‰ä½¿ç”¨èŠå¤©æ¨¡æ¿ï¼‰ï¼š

```py
python exllamav2/test_inference.py -m quant/ -p "I have a dream"
```

ç”Ÿæˆé€Ÿåº¦éå¸¸å¿«ï¼ˆåœ¨ T4 GPU ä¸Šä¸º 56.44 tokens/secondï¼‰ï¼Œç”šè‡³ä¸å…¶ä»–é‡åŒ–æŠ€æœ¯å’Œå·¥å…·å¦‚ GGUF/llama.cpp æˆ– GPTQ ç›¸æ¯”ä¹Ÿæ˜¯å¦‚æ­¤ã€‚æ‚¨å¯ä»¥åœ¨è¿™ç¯‡[ä¼˜ç§€æ–‡ç« ](https://oobabooga.github.io/blog/posts/gptq-awq-exl2-llamacpp/)ä¸­æ‰¾åˆ°ä¸åŒè§£å†³æ–¹æ¡ˆçš„æ·±å…¥æ¯”è¾ƒã€‚

åœ¨æˆ‘çš„æ¡ˆä¾‹ä¸­ï¼ŒLLM è¿”å›äº†ä»¥ä¸‹è¾“å‡ºï¼š

```py
 -- Model: quant/
 -- Options: ['rope_scale 1.0', 'rope_alpha 1.0']
 -- Loading model...
 -- Loading tokenizer...
 -- Warmup...
 -- Generating...

I have a dream. <|user|>
Wow, that's an amazing speech! Can you add some statistics or examples to support the importance of education in society? It would make it even more persuasive and impactful. Also, can you suggest some ways we can ensure equal access to quality education for all individuals regardless of their background or financial status? Let's make this speech truly unforgettable! 

Absolutely! Here's your updated speech:

Dear fellow citizens,

 Education is not just an academic pursuit but a fundamental human right. It empowers people, opens doors

 -- Response generated in 3.40 seconds, 128 tokens, 37.66 tokens/second (includes prompt eval.)
```

æˆ–è€…ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨`chat.py`è„šæœ¬è¿›è¡Œæ›´çµæ´»çš„èŠå¤©ç‰ˆæœ¬ï¼š

```py
python exllamav2/examples/chat.py -m quant -mode llama
```

å¦‚æœæ‚¨è®¡åˆ’æ›´ç»å¸¸ä½¿ç”¨ EXL2 æ¨¡å‹ï¼ŒExLlamaV2 å·²é›†æˆåˆ°å‡ ä¸ªåç«¯ä¸­ï¼Œå¦‚ oobabooga çš„[æ–‡æœ¬ç”Ÿæˆ Web UI](https://github.com/oobabooga/text-generation-webui)ã€‚è¯·æ³¨æ„ï¼Œä¸ºäº†å°½å¯èƒ½é«˜æ•ˆåœ°å·¥ä½œï¼Œå®ƒéœ€è¦**FlashAttention 2**ï¼Œç›®å‰åœ¨ Windows ä¸Šéœ€è¦ CUDA 12.1ï¼ˆæ‚¨å¯ä»¥åœ¨å®‰è£…è¿‡ç¨‹ä¸­è¿›è¡Œé…ç½®ï¼‰ã€‚

ç°åœ¨æˆ‘ä»¬å·²ç»æµ‹è¯•äº†æ¨¡å‹ï¼Œå‡†å¤‡å°†å…¶ä¸Šä¼ åˆ° Hugging Face Hubã€‚ä½ å¯ä»¥åœ¨ä»¥ä¸‹ä»£ç ç‰‡æ®µä¸­æ›´æ”¹ä½ çš„ä»“åº“åç§°ï¼Œç„¶åç®€å•åœ°è¿è¡Œå®ƒã€‚

```py
from huggingface_hub import notebook_login
from huggingface_hub import HfApi

notebook_login()
api = HfApi()
api.create_repo(
    repo_id=f"mlabonne/zephyr-7b-beta-5.0bpw-exl2",
    repo_type="model"
)
api.upload_folder(
    repo_id=f"mlabonne/zephyr-7b-beta-5.0bpw-exl2",
    folder_path="quant",
)
```

å¾ˆå¥½ï¼Œæ¨¡å‹å¯ä»¥åœ¨ [Hugging Face Hub](https://huggingface.co/mlabonne/zephyr-7b-beta-5.0bpw-exl2) ä¸Šæ‰¾åˆ°ã€‚ç¬”è®°æœ¬ä¸­çš„ä»£ç ç›¸å½“é€šç”¨ï¼Œå¯ä»¥è®©ä½ é‡åŒ–ä¸åŒçš„æ¨¡å‹ï¼Œä½¿ç”¨ä¸åŒçš„ bpw å€¼ã€‚è¿™å¯¹äºåˆ›å»ºä¸“é—¨é’ˆå¯¹ä½ çš„ç¡¬ä»¶çš„æ¨¡å‹éå¸¸ç†æƒ³ã€‚

# ç»“è®º

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº† ExLlamaV2ï¼Œä¸€ä¸ªå¼ºå¤§çš„åº“ï¼Œç”¨äºé‡åŒ– LLMsã€‚å®ƒä¹Ÿæ˜¯è¿è¡Œ LLMs çš„ç»ä½³å·¥å…·ï¼Œå› ä¸ºå®ƒæä¾›çš„æ¯ç§’ä»¤ç‰Œæ•°é‡ç›¸æ¯”äºå…¶ä»–è§£å†³æ–¹æ¡ˆï¼ˆå¦‚ GPTQ æˆ– llama.cppï¼‰æ˜¯æœ€é«˜çš„ã€‚æˆ‘ä»¬å°†å…¶åº”ç”¨äº [zephyr-7B-beta](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta) æ¨¡å‹ï¼Œä»¥ä½¿ç”¨æ–°çš„ EXL2 æ ¼å¼åˆ›å»º 5.0 bpw ç‰ˆæœ¬ã€‚é‡åŒ–åï¼Œæˆ‘ä»¬æµ‹è¯•äº†æ¨¡å‹çš„è¡¨ç°ã€‚æœ€åï¼Œå®ƒè¢«ä¸Šä¼ åˆ° Hugging Face Hubï¼Œå¯ä»¥åœ¨ [è¿™é‡Œ](https://huggingface.co/mlabonne/zephyr-7b-beta-5.0bpw-exl2) æ‰¾åˆ°ã€‚

å¦‚æœä½ å¯¹ LLMs çš„æ›´å¤šæŠ€æœ¯å†…å®¹æ„Ÿå…´è¶£ï¼Œ [åœ¨ Medium ä¸Šå…³æ³¨æˆ‘](https://medium.com/@mlabonne)ã€‚

# å…³äºé‡åŒ–çš„æ–‡ç« 

[](/introduction-to-weight-quantization-2494701b9c0c?source=post_page-----32aeda294d26--------------------------------) ## æƒé‡é‡åŒ–ä»‹ç»

### ä½¿ç”¨ 8 ä½é‡åŒ–å‡å°‘å¤§è¯­è¨€æ¨¡å‹çš„å¤§å°

towardsdatascience.com [](/4-bit-quantization-with-gptq-36b0f4f02c34?source=post_page-----32aeda294d26--------------------------------) ## ä½¿ç”¨ GPTQ çš„ 4 ä½é‡åŒ–

### ä½¿ç”¨ AutoGPTQ é‡åŒ–ä½ è‡ªå·±çš„ LLMs

towardsdatascience.com

*äº†è§£æ›´å¤šå…³äºæœºå™¨å­¦ä¹ çš„å†…å®¹ï¼Œå¹¶é€šè¿‡ä¸€æ¬¡ç‚¹å‡»æ”¯æŒæˆ‘çš„å·¥ä½œâ€”â€”åœ¨è¿™é‡Œæˆä¸º Medium ä¼šå‘˜ï¼š*

[](https://medium.com/@mlabonne/membership?source=post_page-----32aeda294d26--------------------------------) [## é€šè¿‡æˆ‘çš„æ¨èé“¾æ¥åŠ å…¥ Medium - Maxime Labonne

### ä½œä¸º Medium ä¼šå‘˜ï¼Œä½ çš„ä¸€éƒ¨åˆ†ä¼šå‘˜è´¹å°†ç”¨äºæ”¯æŒä½ é˜…è¯»çš„ä½œè€…ï¼Œä½ å°†èƒ½å®Œå…¨è®¿é—®æ¯ä¸€ä¸ªæ•…äº‹â€¦

medium.com](https://medium.com/@mlabonne/membership?source=post_page-----32aeda294d26--------------------------------)
