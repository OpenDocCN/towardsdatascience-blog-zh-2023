- en: Efficient semantic search over unstructured text in Neo4j
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Neo4j中高效的语义搜索
- en: 原文：[https://towardsdatascience.com/efficient-semantic-search-over-unstructured-text-in-neo4j-8179ad7ff451?source=collection_archive---------1-----------------------#2023-08-23](https://towardsdatascience.com/efficient-semantic-search-over-unstructured-text-in-neo4j-8179ad7ff451?source=collection_archive---------1-----------------------#2023-08-23)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/efficient-semantic-search-over-unstructured-text-in-neo4j-8179ad7ff451?source=collection_archive---------1-----------------------#2023-08-23](https://towardsdatascience.com/efficient-semantic-search-over-unstructured-text-in-neo4j-8179ad7ff451?source=collection_archive---------1-----------------------#2023-08-23)
- en: Integrate the newly added vector index into LangChain to enhance your RAG applications
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将新添加的向量索引集成到LangChain中，以提升你的RAG应用程序
- en: '[](https://bratanic-tomaz.medium.com/?source=post_page-----8179ad7ff451--------------------------------)[![Tomaz
    Bratanic](../Images/d5821aa70918fcb3fc1ff0013497b3d5.png)](https://bratanic-tomaz.medium.com/?source=post_page-----8179ad7ff451--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8179ad7ff451--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8179ad7ff451--------------------------------)
    [Tomaz Bratanic](https://bratanic-tomaz.medium.com/?source=post_page-----8179ad7ff451--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://bratanic-tomaz.medium.com/?source=post_page-----8179ad7ff451--------------------------------)[![Tomaz
    Bratanic](../Images/d5821aa70918fcb3fc1ff0013497b3d5.png)](https://bratanic-tomaz.medium.com/?source=post_page-----8179ad7ff451--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8179ad7ff451--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8179ad7ff451--------------------------------)
    [Tomaz Bratanic](https://bratanic-tomaz.medium.com/?source=post_page-----8179ad7ff451--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F57f13c0ea39a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fefficient-semantic-search-over-unstructured-text-in-neo4j-8179ad7ff451&user=Tomaz+Bratanic&userId=57f13c0ea39a&source=post_page-57f13c0ea39a----8179ad7ff451---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8179ad7ff451--------------------------------)
    ·7 min read·Aug 23, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8179ad7ff451&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fefficient-semantic-search-over-unstructured-text-in-neo4j-8179ad7ff451&user=Tomaz+Bratanic&userId=57f13c0ea39a&source=-----8179ad7ff451---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F57f13c0ea39a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fefficient-semantic-search-over-unstructured-text-in-neo4j-8179ad7ff451&user=Tomaz+Bratanic&userId=57f13c0ea39a&source=post_page-57f13c0ea39a----8179ad7ff451---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8179ad7ff451--------------------------------)
    ·7分钟阅读·2023年8月23日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8179ad7ff451&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fefficient-semantic-search-over-unstructured-text-in-neo4j-8179ad7ff451&user=Tomaz+Bratanic&userId=57f13c0ea39a&source=-----8179ad7ff451---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8179ad7ff451&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fefficient-semantic-search-over-unstructured-text-in-neo4j-8179ad7ff451&source=-----8179ad7ff451---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8179ad7ff451&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fefficient-semantic-search-over-unstructured-text-in-neo4j-8179ad7ff451&source=-----8179ad7ff451---------------------bookmark_footer-----------)'
- en: Since the advent of ChatGPT six months ago, the technology landscape has undergone
    a transformative shift. ChatGPT’s exceptional capacity for generalization has
    diminished the requirement for specialized deep learning teams and extensive training
    datasets to create custom NLP models. This has democratized access to a range
    of NLP tasks, such as summarization and information extraction, making them more
    readily available than ever before. However, we soon realized the [limitations
    of ChatGPT-like models](https://medium.com/neo4j/knowledge-graphs-llms-fine-tuning-vs-retrieval-augmented-generation-30e875d63a35),
    such as knowledge date cutoff and not having access to private information. In
    my opinion, what followed was the second wave of generative AI transformation
    with the rise of Retrieval Augmented Generation (RAG) applications, where you
    feed relevant information to the model at query time to construct better and more
    accurate answers.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 自从六个月前ChatGPT问世以来，技术领域经历了变革性的转变。ChatGPT出色的概括能力减少了对专业深度学习团队和大量训练数据集的需求，从而使得创建定制的NLP模型变得更加容易。这使得诸如摘要和信息提取等NLP任务的获取变得比以往任何时候都更加容易。然而，我们很快意识到[类似ChatGPT模型的局限性](https://medium.com/neo4j/knowledge-graphs-llms-fine-tuning-vs-retrieval-augmented-generation-30e875d63a35)，如知识截止日期和无法访问私人信息。在我看来，紧接着出现的是生成性AI转型的第二波浪潮，即检索增强生成（RAG）应用的兴起，你可以在查询时向模型提供相关信息，以构建更好、更准确的答案。
- en: '![](../Images/83f907ab327cbc66de48a587422a5183.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/83f907ab327cbc66de48a587422a5183.png)'
- en: RAG application flow. Image by the author. Icons from [https://www.flaticon.com/](https://www.flaticon.com/)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: RAG应用流程。图像由作者提供。图标来自[https://www.flaticon.com/](https://www.flaticon.com/)
- en: As mentioned, the RAG applications require a smart search tool that is able
    to retrieve additional information based on the user input, which allows the LLMs
    to produce more accurate and up-to-date answers. At first, the focus was mostly
    on retrieving information from unstructured text using semantic search. However,
    it soon became evident that a combination of structured and unstructured data
    is the best approach to RAG applications if you want to [move beyond “Chat with
    your PDF” applications](https://medium.com/neo4j/knowledge-graphs-llms-real-time-graph-analytics-89b392eaaa95).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，RAG应用程序需要一个智能搜索工具，能够根据用户输入检索额外信息，这使得LLMs能够生成更准确和最新的答案。最初，重点主要是使用语义搜索从非结构化文本中检索信息。然而，很快就明显看出，结构化和非结构化数据的组合是RAG应用程序的最佳方法，如果你想要[超越“与PDF对话”应用](https://medium.com/neo4j/knowledge-graphs-llms-real-time-graph-analytics-89b392eaaa95)。
- en: Neo4j was and is an excellent fit for handling structured information, but it
    struggled a bit with semantic search due to its brute-force approach. However,
    the struggle is in the past as Neo4j has [introduced a new vector index in version
    5.11](https://neo4j.com/blog/vector-search-deeper-insights/) designed to efficiently
    perform semantic search over unstructured text or other embedded data modalities.
    The newly added vector index makes Neo4j a great fit for most RAG applications
    as it now works great with both structured and unstructured data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Neo4j曾经并且现在仍然非常适合处理结构化信息，但由于其粗暴的方法，它在语义搜索方面有些吃力。然而，这种困难已经成为过去，因为Neo4j已经在[5.11版本中引入了新的向量索引](https://neo4j.com/blog/vector-search-deeper-insights/)，旨在高效地对非结构化文本或其他嵌入数据模式执行语义搜索。新添加的向量索引使Neo4j非常适合大多数RAG应用，因为它现在可以很好地处理结构化和非结构化数据。
- en: In this blog post I will show you how to setup a vector index in Neo4j and integrate
    it into the [LangChain ecosystem](https://www.langchain.com/). The code is available
    on [GitHub](https://github.com/tomasonjo/blogs/blob/master/llm/Neo4j_vector_index_%26_Langchain.ipynb).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我将向你展示如何在Neo4j中设置向量索引，并将其集成到[LangChain生态系统](https://www.langchain.com/)中。代码可以在[GitHub](https://github.com/tomasonjo/blogs/blob/master/llm/Neo4j_vector_index_%26_Langchain.ipynb)上找到。
- en: Neo4j Environment setup
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Neo4j环境设置
- en: You need to setup a Neo4j 5.11 or greater to follow along with the examples
    in this blog post. The easiest way is to start a free instance on [Neo4j Aura](https://neo4j.com/cloud/platform/aura-graph-database/),
    which offers cloud instances of Neo4j database. Alternatively, you can also setup
    a local instance of the Neo4j database by downloading the [Neo4j Desktop](https://neo4j.com/download/)
    application and creating a local database instance.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要设置Neo4j 5.11或更高版本，以跟随本博客中的示例。最简单的方法是启动一个免费的[Neo4j Aura](https://neo4j.com/cloud/platform/aura-graph-database/)实例，该平台提供Neo4j数据库的云实例。或者，你也可以通过下载[Neo4j
    Desktop](https://neo4j.com/download/)应用程序并创建一个本地数据库实例，来设置Neo4j数据库的本地实例。
- en: After you have instantiated the Neo4j database, you can use the LangChain library
    to connect to it.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化 Neo4j 数据库后，你可以使用 LangChain 库连接到它。
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Setting up the Vector Index
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置向量索引
- en: '[Neo4j vector index is powered by Lucene](https://neo4j.com/docs/cypher-manual/current/indexes-for-vector-search/),
    where Lucene implements a Hierarchical Navigable Small World (HNSW) Graph to perform
    a approximate nearest neighbors (ANN) query over the vector space.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[Neo4j 向量索引由 Lucene 提供支持](https://neo4j.com/docs/cypher-manual/current/indexes-for-vector-search/)，其中
    Lucene 实现了一个层次导航的小世界 (HNSW) 图，以在向量空间上执行近似最近邻 (ANN) 查询。'
- en: Neo4j’s implementation of the vector index is designed to index a single node
    property of a node label. For example, if you wanted to index nodes with the label
    `Chunk` on their node property `embedding` , you would use the following Cypher
    procedure.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Neo4j 对向量索引的实现旨在索引节点标签的单个节点属性。例如，如果你想要对标签为 `Chunk` 的节点的 `embedding` 属性进行索引，你可以使用以下
    Cypher 程序。
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Along with the index name, node label, and property, you must specify the vector
    size (embedding dimension), and the similarity metric. We will be using OpenAI’s
    text-embedding-ada-002 embedding model, which uses vector size **1536** to represent
    text in the embedding space. At the moment, only the **cosine** and **Euclidean**
    similarity metrics are available. OpenAI suggests using the cosine similarity
    metric when using their embedding model.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 除了索引名称、节点标签和属性外，你还必须指定向量大小（嵌入维度）和相似度度量。我们将使用 OpenAI 的 text-embedding-ada-002
    嵌入模型，该模型使用向量大小 **1536** 来表示嵌入空间中的文本。目前，仅提供 **余弦** 和 **欧几里得** 相似度度量。OpenAI 建议在使用其嵌入模型时使用余弦相似度度量。
- en: Populating the Vector index
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 填充向量索引
- en: Neo4j is schema-less by design, which means it doesn’t enforce any restrictions
    what goes into a node property. For example, the `embedding` property of the `Chunk`
    node could store integers, list of integers or even strings. Let’s try this out.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Neo4j 的设计是无模式的，这意味着它不强制对节点属性中的内容施加任何限制。例如，`embedding`属性可以存储整数、整数列表甚至字符串。我们来尝试一下。
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This query creates a `Chunk`node for each element in the list and uses the element
    as the `embedding`property value. For example, the first `Chunk` node will have
    the `embedding` property value **1**, the second node **[1,2,3]**, and so on.
    Neo4j doesn’t enforce any rules on what you can store under node properties. However,
    the vector index has clear instructions about the type of values and their embedding
    dimension it should index.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这个查询为列表中的每个元素创建一个 `Chunk` 节点，并将元素用作 `embedding` 属性值。例如，第一个 `Chunk` 节点的 `embedding`
    属性值为 **1**，第二个节点为 **[1,2,3]**，依此类推。Neo4j 对节点属性下可以存储的内容没有强制规则。然而，向量索引对它应该索引的值类型和嵌入维度有明确的指示。
- en: We can test which values were indexed by performing a vector index search.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过执行向量索引搜索来测试哪些值已被索引。
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If you run this query, you will get only a single node returned, even though
    you requested the top **3** neighbors to be returned. Why is that so? The vector
    index only indexes property values, where the value is a list of floats with the
    specified size. In this example, only one `embedding`property value had the list
    of floats type with the selected length 1536.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行这个查询，你将只返回一个单独的节点，即使你请求返回前 **3** 个邻居。这是为什么呢？向量索引仅索引属性值，其中值是具有指定大小的浮点数列表。在这个示例中，只有一个
    `embedding` 属性值具有浮点数列表类型，并且长度为 1536。
- en: 'A node is indexed by the vector index if all the following are true:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果满足以下所有条件，则节点会按向量索引进行索引：
- en: The node contains the configured label.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点包含配置的标签。
- en: The node contains the configured property key.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点包含配置的属性键。
- en: The respective property value is of type `LIST<FLOAT>`.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相应的属性值类型为 `LIST<FLOAT>`。
- en: The `[size()](https://neo4j.com/docs/cypher-manual/current/functions/scalar/#functions-size)`
    of the respective value is the same as the configured dimensionality.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相应值的 `[size()](https://neo4j.com/docs/cypher-manual/current/functions/scalar/#functions-size)`
    与配置的维度是相同的。
- en: The value is a valid vector for the configured similarity function.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该值是配置的相似度函数的有效向量。
- en: Integrating the vector index into the LangChain ecosystem
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将向量索引集成到 LangChain 生态系统中
- en: Now we will implement a simple custom LangChain class that will use the Neo4j
    Vector index to retrieve relevant information to generate accurate and up-to-date
    answers. But first, we have to populate the vector index.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将实现一个简单的自定义 LangChain 类，该类将使用 Neo4j 向量索引来检索相关信息，以生成准确和最新的答案。但首先，我们必须填充向量索引。
- en: '![](../Images/c74118be178b79f9f3609665c6658ed2.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c74118be178b79f9f3609665c6658ed2.png)'
- en: Data flow using the Neo4j vector index in RAG applications. Image by the author.
    Icons from flaticons.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Neo4j向量索引在RAG应用中的数据流。图像由作者提供。图标来自flaticons。
- en: 'The task will consist of the following steps:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 任务将包括以下步骤：
- en: Retrieve a Wikipedia article
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检索一篇维基百科文章
- en: Chunk the text
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 切分文本
- en: Store the text along with its vector representation in Neo4j
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Neo4j中存储文本及其向量表示
- en: Implement a custom LangChain class to support RAG applications
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现一个自定义LangChain类以支持RAG应用
- en: In this example, we will fetch only a single Wikipedia article. I have decided
    to use [Baldur’s Gate 3 page](https://en.wikipedia.org/wiki/Baldur%27s_Gate_3).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将只获取一篇维基百科文章。我决定使用[Baldur’s Gate 3页面](https://en.wikipedia.org/wiki/Baldur%27s_Gate_3)。
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Next, we need to chunk and embed the text. We will split the text by section
    using the double newline delimiter and then use OpenAI’s embedding model to represent
    each section with an appropriate vector.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要对文本进行切分和嵌入。我们将通过双换行符分隔符按部分切分文本，然后使用OpenAI的嵌入模型为每个部分表示一个合适的向量。
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Before we move on to the LangChain class, we need to import the text chunks
    into Neo4j.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续讲解LangChain类之前，需要将文本块导入Neo4j。
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: One thing you can notice is that I used the `db.create.setVectorProperty` procedure
    to store the vectors to Neo4j. This procedure is used to verify that the property
    value is indeed a list of floats. Additionally, it has the added benefit of reducing
    the storage space of vector property by approximately 50%. Therefore, it is recommended
    always to use this procedure to store vectors to Neo4j.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 有一点值得注意的是，我使用了`db.create.setVectorProperty`过程来将向量存储到Neo4j中。此过程用于验证属性值确实是浮点数列表。此外，它还有助于将向量属性的存储空间减少约50%。因此，建议始终使用此过程将向量存储到Neo4j中。
- en: Now we can go and implement the custom LangChain class used to retrieve information
    from Neo4j vector index and use it to generate answers. First, we will define
    the Cypher statement used to retrieve information.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以实现自定义的LangChain类，用于从Neo4j向量索引中检索信息，并用它生成答案。首先，我们将定义用于检索信息的Cypher语句。
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: As you can see, I have hardcoded the index name. You can make this dynamic by
    adding appropriate parameters if you wish.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我已硬编码了索引名称。如果您愿意，可以通过添加适当的参数使其动态化。
- en: The custom LangChain class is implemented pretty straightforward.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义的LangChain类实现得非常直接。
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'I have omitted some boilerplate code to make it more readable. Essentially,
    when you can call the Neo4jVectorChain, the following steps are executed:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我省略了一些模板代码以使其更易读。实质上，当您调用Neo4jVectorChain时，会执行以下步骤：
- en: Embed the question using the relevant embedding model
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用相关的嵌入模型对问题进行嵌入
- en: Use the text embedding value to retrieve most similar content from the vector
    index
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用文本嵌入值从向量索引中检索最相似的内容
- en: Use the provided context from similar content to generate the answer
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用类似内容提供的上下文生成答案
- en: We can now test our implementation.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以测试我们的实现。
- en: '[PRE9]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '*Response*'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '*响应*'
- en: '![](../Images/21517a69c90aea570d61228bfebc4243.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/21517a69c90aea570d61228bfebc4243.png)'
- en: Generated response. Image by the author.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的响应。图像由作者提供。
- en: By using the `verbose` option, you can also evaluate the retrieved context from
    the vector index that was used to generate the answer.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用`verbose`选项，您还可以评估从向量索引中检索的上下文，这些上下文用于生成答案。
- en: Summary
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: Leveraging Neo4j’s new vector indexing capabilities, you can create a unified
    data source that powers Retrieval Augmented Generation applications effectively.
    This allows you to not only implement “Chat with your PDF or documentation” solutions
    but also to conduct real-time analytics, all from a single, robust data source.
    This multi-purpose utility can streamline your operations and enhances data synergy,
    making Neo4j a great solution for managing both structured and unstructured data.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 利用Neo4j的新向量索引功能，您可以创建一个统一的数据源，有效支持检索增强生成应用。这不仅使您能够实现“与PDF或文档聊天”解决方案，还能进行实时分析，所有这些都来自一个强大的数据源。这种多用途的实用工具可以简化您的操作并增强数据协同，使Neo4j成为管理结构化和非结构化数据的绝佳解决方案。
- en: As always, the code is available on [GitHub](https://github.com/tomasonjo/blogs/blob/master/llm/Neo4j_vector_index_%26_Langchain.ipynb).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，代码可在[GitHub](https://github.com/tomasonjo/blogs/blob/master/llm/Neo4j_vector_index_%26_Langchain.ipynb)上找到。
