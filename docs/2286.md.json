["```py\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n\n# Variables to set the number of epochs and samples\nnum_epochs = 10\nnum_samples = 100  # set this to -1 to use all data\n```", "```py\n# Step 1: Load dataset and model tokenizer\ndataset = load_dataset('imdb')\ntokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n```", "```py\n# Data Exploration\ntrain_df = pd.DataFrame(dataset[\"train\"])\nsns.countplot(x='label', data=train_df)\nplt.title('Class distribution')\nplt.show()\n```", "```py\n# Step 2: Preprocess the dataset\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n```", "```py\nif num_samples == -1:\n    small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42)\n    small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42)\nelse:\n    small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(num_samples)) \n    small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(num_samples)) \n```", "```py\n# Step 3: Load pre-trained model\nmodel = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n```", "```py\n# Step 4: Define training arguments\ntraining_args = TrainingArguments(\"test_trainer\", evaluation_strategy=\"epoch\", no_cuda=True, num_train_epochs=num_epochs)\n\n# Step 5: Create Trainer instance and train\ntrainer = Trainer(\n    model=model, args=training_args, train_dataset=small_train_dataset, eval_dataset=small_eval_dataset\n)\n\ntrainer.train()\n```", "```py\n# Step 6: Evaluation\npredictions = trainer.predict(small_eval_dataset)\n\n# Confusion matrix\ncm = confusion_matrix(small_eval_dataset['label'], predictions.predictions.argmax(-1))\nsns.heatmap(cm, annot=True, fmt='d')\nplt.title('Confusion Matrix')\nplt.show()\n\n# ROC Curve\nfpr, tpr, _ = roc_curve(small_eval_dataset['label'], predictions.predictions[:, 1])\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(1.618 * 5, 5))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()\n```", "```py\n# Step 7: Inference on a new sample\nsample_text = \"This is a fantastic movie. I really enjoyed it.\"\nsample_inputs = tokenizer(sample_text, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n\n# Move inputs to device (if GPU available)\nsample_inputs.to(training_args.device)\n\n# Make prediction\npredictions = model(**sample_inputs)\npredicted_class = predictions.logits.argmax(-1).item()\n\nif predicted_class == 1:\n    print(\"Positive sentiment\")\nelse:\n    print(\"Negative sentiment\")\n```"]