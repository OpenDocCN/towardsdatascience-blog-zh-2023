- en: A gentle introduction to Steerable Neural Networks (part 2)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€Šå¯æ“æ§ç¥ç»ç½‘ç»œç®€ä»‹ï¼ˆç¬¬2éƒ¨åˆ†ï¼‰ã€‹
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/a-gentle-introduction-to-steerable-neural-networks-part-2-56dfc256b690?source=collection_archive---------9-----------------------#2023-11-21](https://towardsdatascience.com/a-gentle-introduction-to-steerable-neural-networks-part-2-56dfc256b690?source=collection_archive---------9-----------------------#2023-11-21)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/a-gentle-introduction-to-steerable-neural-networks-part-2-56dfc256b690?source=collection_archive---------9-----------------------#2023-11-21](https://towardsdatascience.com/a-gentle-introduction-to-steerable-neural-networks-part-2-56dfc256b690?source=collection_archive---------9-----------------------#2023-11-21)
- en: How to build a Steerable Filter and a steerable CNN
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¦‚ä½•æ„å»ºå¯æ“æ§æ»¤æ³¢å™¨å’Œå¯æ“æ§CNN
- en: '[](https://medium.com/@mat.cip43?source=post_page-----56dfc256b690--------------------------------)[![Matteo
    Ciprian](../Images/61dab88069d99263e941a0e549473bdf.png)](https://medium.com/@mat.cip43?source=post_page-----56dfc256b690--------------------------------)[](https://towardsdatascience.com/?source=post_page-----56dfc256b690--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----56dfc256b690--------------------------------)
    [Matteo Ciprian](https://medium.com/@mat.cip43?source=post_page-----56dfc256b690--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mat.cip43?source=post_page-----56dfc256b690--------------------------------)[![Matteo
    Ciprian](../Images/61dab88069d99263e941a0e549473bdf.png)](https://medium.com/@mat.cip43?source=post_page-----56dfc256b690--------------------------------)[](https://towardsdatascience.com/?source=post_page-----56dfc256b690--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----56dfc256b690--------------------------------)
    [Matteo Ciprian](https://medium.com/@mat.cip43?source=post_page-----56dfc256b690--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F975b976da56a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-steerable-neural-networks-part-2-56dfc256b690&user=Matteo+Ciprian&userId=975b976da56a&source=post_page-975b976da56a----56dfc256b690---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----56dfc256b690--------------------------------)
    Â·10 min readÂ·Nov 21, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F56dfc256b690&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-steerable-neural-networks-part-2-56dfc256b690&user=Matteo+Ciprian&userId=975b976da56a&source=-----56dfc256b690---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F975b976da56a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-steerable-neural-networks-part-2-56dfc256b690&user=Matteo+Ciprian&userId=975b976da56a&source=post_page-975b976da56a----56dfc256b690---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----56dfc256b690--------------------------------)
    Â· 10åˆ†é’Ÿé˜…è¯» Â· 2023å¹´11æœˆ21æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F56dfc256b690&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-steerable-neural-networks-part-2-56dfc256b690&user=Matteo+Ciprian&userId=975b976da56a&source=-----56dfc256b690---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F56dfc256b690&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-steerable-neural-networks-part-2-56dfc256b690&source=-----56dfc256b690---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F56dfc256b690&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-steerable-neural-networks-part-2-56dfc256b690&source=-----56dfc256b690---------------------bookmark_footer-----------)'
- en: 1) Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1) ä»‹ç»
- en: This article is the second and last part of the tutorial **â€œA gentle introduction
    to Steerable Neural Networksâ€**. It follows the article number one ([here](https://medium.com/@mat.cip43/a-gentle-introduction-to-steerable-neural-networks-part-1-32323d95b03f)).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡æ˜¯**ã€Šå¯æ“æ§ç¥ç»ç½‘ç»œç®€ä»‹ã€‹**æ•™ç¨‹çš„ç¬¬äºŒéƒ¨åˆ†ï¼Œä¹Ÿæ˜¯æœ€åä¸€éƒ¨åˆ†ã€‚å®ƒæ¥ç»­äº†ç¬¬ä¸€éƒ¨åˆ†çš„å†…å®¹ï¼ˆ[åœ¨è¿™é‡Œ](https://medium.com/@mat.cip43/a-gentle-introduction-to-steerable-neural-networks-part-1-32323d95b03f)ï¼‰ã€‚
- en: The first article offers an accessible overview of Steerable Neural Networks
    (S-CNNs), explaining their purpose and applications. It also delves into the underlying
    formalism and key concepts, including the definition of **equivariance** and **steerable
    filters**. Although a quick recap of the formalism will be given in the next paragraph,
    we would recommend you read the first article for a complete understanding.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ç¯‡æ–‡ç« æä¾›äº†Steerableç¥ç»ç½‘ç»œï¼ˆS-CNNsï¼‰çš„ç®€æ˜æ¦‚è¿°ï¼Œè§£é‡Šäº†å®ƒä»¬çš„ç›®çš„å’Œåº”ç”¨ã€‚å®ƒè¿˜æ·±å…¥æ¢è®¨äº†åŸºç¡€å½¢å¼ä¸»ä¹‰å’Œå…³é”®æ¦‚å¿µï¼ŒåŒ…æ‹¬ç­‰å˜æ€§å’ŒSteerableæ»¤æ³¢å™¨çš„å®šä¹‰ã€‚å°½ç®¡ä¸‹ä¸€æ®µè½å°†å¯¹å½¢å¼ä¸»ä¹‰è¿›è¡Œå¿«é€Ÿå›é¡¾ï¼Œä½†æˆ‘ä»¬å»ºè®®æ‚¨é˜…è¯»ç¬¬ä¸€ç¯‡æ–‡ç« ä»¥å…¨é¢äº†è§£ã€‚
- en: '*In this last part of the tutorial, we want to provide a guide on how to build
    a* ***Steerable Filter*** *and at the end , how to compose a Steerable Neural
    Network.*'
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*åœ¨æœ¬æ•™ç¨‹çš„æœ€åéƒ¨åˆ†ï¼Œæˆ‘ä»¬å¸Œæœ›æä¾›ä¸€ä¸ªå…³äºå¦‚ä½•æ„å»º* ***Steerable Filter*** *çš„æŒ‡å—ï¼Œå¹¶åœ¨æœ€åï¼Œä»‹ç»å¦‚ä½•ç»„åˆä¸€ä¸ªSteerableç¥ç»ç½‘ç»œã€‚*'
- en: 'Quick recap of nomenclature:'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¿«é€Ÿå›é¡¾æœ¯è¯­ï¼š
- en: '![](../Images/0d083f156172448f1c8b6b6eb607045a.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0d083f156172448f1c8b6b6eb607045a.png)'
- en: 'Fig 3A: Representation of a neural network following the formalism.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾3Aï¼šæŒ‰ç…§å½¢å¼ä¸»ä¹‰è¡¨ç¤ºçš„ç¥ç»ç½‘ç»œã€‚
- en: '**S** : input domain space. Space where the objects exists (usually â„Â³ or â„Â²).'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**S**ï¼šè¾“å…¥åŸŸç©ºé—´ã€‚å¯¹è±¡å­˜åœ¨çš„ç©ºé—´ï¼ˆé€šå¸¸ä¸ºâ„Â³æˆ–â„Â²ï¼‰ã€‚'
- en: '***f*** *â‚™****:*** a map/function , *f â‚™:* S â†’ â„ Í¨ Ê¿*â¿* Ê¾ ( F*â‚™*) *,* which
    describes the n-th feature map of the NN . Note that the *f* â° is the function
    describing the input (input layer), while *fâ‚™, with n>0,* describe the *n-th*
    feature map.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***f***â‚™****:*** ä¸€ä¸ªæ˜ å°„/å‡½æ•°ï¼Œ*f*â‚™:* S â†’ â„ Í¨ Ê¿*â¿* Ê¾ï¼ˆFâ‚™ï¼‰*ï¼Œ*æè¿°äº†NNçš„ç¬¬nä¸ªç‰¹å¾æ˜ å°„ã€‚è¯·æ³¨æ„ï¼Œfâ°æ˜¯æè¿°è¾“å…¥ï¼ˆè¾“å…¥å±‚ï¼‰çš„å‡½æ•°ï¼Œè€Œå¯¹äºn>0ï¼Œfâ‚™æè¿°äº†ç¬¬nä¸ªç‰¹å¾æ˜ å°„ã€‚'
- en: '**F***â‚™***= â„ Í¨ Ê¿*â¿* Ê¾**, it is codomain of the map *f â‚™.*'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**F***â‚™***= â„ Í¨ Ê¿*â¿* Ê¾**ï¼Œå®ƒæ˜¯æè¿°*f*â‚™*çš„å€¼åŸŸã€‚'
- en: '**Î¦***â‚™***: F***â‚™****â†’ F*** *â‚™â‚Šâ‚****,*** *n-th* Í‘filterof the NN characterizable
    by the kernel function *k****â¿*** *: S â†’* â„ Í¨ Ê¿*â¿* Ê¾ ËŸ Í¨ Ê¿*â¿âº Â¹* Ê¾ . The definition
    of convolution can be seen in the second equation above.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Î¦***â‚™***: F***â‚™****â†’ F*** *â‚™â‚Šâ‚****,* ç¬¬*n* ä¸ªNNçš„æ»¤æ³¢å™¨å¯ç”±æ ¸å‡½æ•°*k****â¿***: S â†’* â„
    Í¨ Ê¿*â¿* Ê¾ ËŸ Í¨ Ê¿*â¿âº Â¹* Ê¾ *æ¥æè¿°ã€‚å·ç§¯çš„å®šä¹‰å¦‚ä¸Šç¬¬äºŒä¸ªæ–¹ç¨‹å¼æ‰€ç¤ºã€‚'
- en: '**G**: group of transformations ( single element *g).*'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**G**ï¼šå˜æ¢çš„ç»„ï¼ˆå•ä¸€å…ƒç´ *g*ï¼‰ã€‚'
- en: 'Considering all these concepts we have been able to define convolution as following:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ç»¼åˆè€ƒè™‘æ‰€æœ‰è¿™äº›æ¦‚å¿µï¼Œæˆ‘ä»¬å·²ç»èƒ½å¤Ÿå®šä¹‰å¦‚ä¸‹å·ç§¯ï¼š
- en: '![](../Images/a6e4eece3326f205c8b544d4ec5627b4.png)![](../Images/1fc9a17c9ca2c61643ca20e9da05e064.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a6e4eece3326f205c8b544d4ec5627b4.png)![](../Images/1fc9a17c9ca2c61643ca20e9da05e064.png)'
- en: 2) Design of a Steerable CNN filter
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2) Steerable CNN æ»¤æ³¢å™¨çš„è®¾è®¡
- en: '![](../Images/b7c3c0dab47626529d9cbdd3d2a6c5ce.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b7c3c0dab47626529d9cbdd3d2a6c5ce.png)'
- en: 'Fig3A: Visual example of equivariant CNN filter. Given the transformation g
    acting on S and the consequent rotation of the input signal f given by Î â‚€(g),
    f1 is rotated by Î 1(g).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾3Aï¼šç­‰å˜CNNæ»¤æ³¢å™¨çš„è§†è§‰ç¤ºä¾‹ã€‚ç»™å®šå¯¹Sçš„å˜æ¢gåŠç”±Î â‚€(g)ç»™å®šçš„è¾“å…¥ä¿¡å·fçš„æ—‹è½¬ï¼Œfâ‚ç”±Î â‚(g)æ—‹è½¬ã€‚
- en: 2.1 Formalization of the problem
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 é—®é¢˜çš„å½¢å¼åŒ–
- en: 'We can state that a CNN of n layers is equivariant with respect to a group
    of transformations G if, for every *g in G,0*: *when an input function f â‚€ is
    transformed to Î â‚€(g), then the output function of the n-th layer is transformed
    to a transformation Î n(g).*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å£°æ˜ï¼Œå¦‚æœå¯¹äºæ¯ä¸ª*gåœ¨G,0*ï¼Œå½“è¾“å…¥å‡½æ•°fâ‚€å˜æ¢ä¸ºÎ â‚€(g)æ—¶ï¼Œé‚£ä¹ˆç¬¬nå±‚çš„è¾“å‡ºå‡½æ•°å°†å˜æ¢ä¸ºÎ n(g)ï¼Œåˆ™nå±‚çš„CNNå¯¹äºä¸€ç»„å˜æ¢Gæ˜¯ç­‰å˜çš„ã€‚
- en: 'A sufficient condition to make this statement true is that each contiguous
    layer is equivariant to transformations on itâ€™s immediate inputs (see fig 3A).
    The equivariance of the network comes by induction. Following the definitions
    given in the second article, a filter Î¦ is equivariant if it satisfies the following
    condition:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿è¿™ä¸ªé™ˆè¿°æˆç«‹çš„ä¸€ä¸ªå……åˆ†æ¡ä»¶æ˜¯æ¯ä¸ªè¿ç»­çš„å±‚å¯¹å…¶ç›´æ¥è¾“å…¥çš„å˜æ¢å…·æœ‰ç­‰å˜æ€§ï¼ˆè§å›¾3Aï¼‰ã€‚ç½‘ç»œçš„ç­‰å˜æ€§æ˜¯é€šè¿‡å½’çº³æ¥å®ç°çš„ã€‚æ ¹æ®ç¬¬äºŒç¯‡æ–‡ç« ä¸­ç»™å‡ºçš„å®šä¹‰ï¼Œå¦‚æœæ»¤æ³¢å™¨Î¦æ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼Œåˆ™Î¦æ˜¯ç­‰å˜çš„ï¼š
- en: '![](../Images/d5c3b29e939626aaa18c1f6770b5e3f7.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d5c3b29e939626aaa18c1f6770b5e3f7.png)'
- en: 'Eq.0: Definition of equivariance'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹0ï¼šç­‰å˜æ€§çš„å®šä¹‰
- en: It is now possible to claim the **main result** of the steerable neural network
    theory.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨å¯ä»¥å®£ç§°steerableç¥ç»ç½‘ç»œç†è®ºçš„**ä¸»è¦ç»“æœ**ã€‚
- en: '*Be* ***k*** *the kernel connecting the layer* f *â‚™with* f *such that* fâ‚™â‚Šâ‚
    = k* f â‚™*.*'
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*è®¾*k*è¿æ¥å±‚*f*â‚™å’Œ*f*çš„æ ¸å¿ƒå‡½æ•°ï¼Œä½¿å¾—*f*â‚™â‚Šâ‚ = k* f â‚™*.*'
- en: ''
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*The convolution* k* f â‚™*is equivariant with respect to a transformation g,
    if and only if :*'
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*å·ç§¯*k* f â‚™*å¯¹äºå˜æ¢gæ˜¯ç­‰å˜çš„ï¼Œå½“ä¸”ä»…å½“ï¼š*'
- en: '![](../Images/702fd59bbe89895caaf8f03ed705cb3a.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/702fd59bbe89895caaf8f03ed705cb3a.png)'
- en: '*or simpler*'
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*æˆ–æ›´ç®€å•*'
- en: '![](../Images/82a6e1a92a10f1b410b49216cc6989f4.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/82a6e1a92a10f1b410b49216cc6989f4.png)'
- en: 'Eq.1: Necessary and Sufficient condition for equivariance of a kernel with
    respect to a transformation g.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq.1: å…³äºå˜æ¢gçš„æ ¸ç­‰å˜æ€§çš„å¿…è¦ä¸”å……åˆ†æ¡ä»¶ã€‚'
- en: 'In the broader literature [2,3] kernels that adhere to this constraint are
    calledg-steerablekernels. As the kernel constraint operates in a linear manner,
    the solutions it generates constitute a linear subspace within the vector space
    of unconstrained kernels typically utilized in standard CNN. *Upon closer examination,
    this definition closely aligns with the concept of steerable filters introduced
    in paragraph 2 of the last article* [*here*](https://medium.com/@mat.cip43/a-gentle-introduction-to-steerable-neural-networks-part-2-a17b4139aa5f).
    In practical terms, to get this work we need a basis for this kernel subspace,
    denoted as {k_1, â€¦k_D} , which adheres to Eq.1 . The size of this basis, denoted
    as D, can be calculated as D = cÊ¿â¿ Ê¾ ËŸ cÊ¿â¿âºÂ¹Ê¾.The kernel *k(x)* is subsequently
    derived through a linear combination of this basis, with the network learning
    the weights in the process:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ›´å¹¿æ³›çš„æ–‡çŒ®ä¸­[2,3]ï¼Œéµå¾ªæ­¤çº¦æŸçš„æ ¸è¢«ç§°ä¸ºg-å¯å¯¼æ ¸ã€‚ç”±äºæ ¸çº¦æŸä»¥çº¿æ€§æ–¹å¼æ“ä½œï¼Œå®ƒç”Ÿæˆçš„è§£æ„æˆäº†æ ‡å‡†CNNä¸­é€šå¸¸ä½¿ç”¨çš„æ— çº¦æŸæ ¸çš„å‘é‡ç©ºé—´ä¸­çš„ä¸€ä¸ªçº¿æ€§å­ç©ºé—´ã€‚*ç»è¿‡æ›´ä»”ç»†çš„å®¡æŸ¥ï¼Œè¿™ä¸€å®šä¹‰ä¸æœ€åä¸€ç¯‡æ–‡ç« ç¬¬2æ®µä¸­ä»‹ç»çš„å¯å¯¼æ»¤æ³¢å™¨çš„æ¦‚å¿µéå¸¸å¥‘åˆ*
    [*è¿™é‡Œ*](https://medium.com/@mat.cip43/a-gentle-introduction-to-steerable-neural-networks-part-2-a17b4139aa5f)ã€‚åœ¨å®é™…æ“ä½œä¸­ï¼Œä¸ºäº†è·å¾—æ­¤å·¥ä½œï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ­¤æ ¸å­ç©ºé—´çš„åŸºï¼Œè®°ä½œ{k_1,
    â€¦k_D}ï¼Œå®ƒç¬¦åˆæ–¹ç¨‹ï¼ˆ1ï¼‰ã€‚è¿™ä¸ªåŸºçš„å¤§å°ï¼Œè®°ä½œDï¼Œå¯ä»¥è®¡ç®—ä¸ºD = cÊ¿â¿ Ê¾ ËŸ cÊ¿â¿âºÂ¹Ê¾ã€‚æ ¸*k(x)*éšåé€šè¿‡è¿™ä¸ªåŸºçš„çº¿æ€§ç»„åˆå¾—å‡ºï¼Œç½‘ç»œåœ¨è¿‡ç¨‹ä¸­å­¦ä¹ æƒé‡ï¼š
- en: '![](../Images/e8b0ba730141ddb8e89c464338a011ac.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e8b0ba730141ddb8e89c464338a011ac.png)'
- en: 'Eq.2: The linearity of Eq(1) makes the solution be equal to the following linear
    combination.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq.2: æ–¹ç¨‹ï¼ˆ1ï¼‰çš„çº¿æ€§ä½¿å¾—è§£ç­‰äºä»¥ä¸‹çº¿æ€§ç»„åˆã€‚'
- en: In a training scenario, our approach involves setting the sizes of both the
    input and output layers to specific values, namely cÊ¿â¿ Ê¾ and cÊ¿â¿âºÂ¹. Then, based
    on the transformations we seek equivariance to, we solve the equation and determine
    a kernel basis. Subsequently, during the training process, we learn the weights
    associated with these kernels.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è®­ç»ƒåœºæ™¯ä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ¶‰åŠå°†è¾“å…¥å±‚å’Œè¾“å‡ºå±‚çš„å¤§å°è®¾ç½®ä¸ºç‰¹å®šçš„å€¼ï¼Œå³cÊ¿â¿ Ê¾å’ŒcÊ¿â¿âºÂ¹ã€‚ç„¶åï¼Œæ ¹æ®æˆ‘ä»¬å¯»æ±‚ç­‰å˜çš„å˜æ¢ï¼Œè§£å†³æ–¹ç¨‹å¹¶ç¡®å®šä¸€ä¸ªæ ¸åŸºã€‚éšåï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ ä¸è¿™äº›æ ¸ç›¸å…³çš„æƒé‡ã€‚
- en: 2.2 Solving the equation
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 è§£æ–¹ç¨‹
- en: 'The solution of the constrain presented in Eq.1 is from being trivial. It depends
    on three main elements:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹ï¼ˆ1ï¼‰ä¸­å‘ˆç°çš„çº¦æŸçš„è§£è¿œéç®€å•ã€‚å®ƒä¾èµ–äºä¸‰ä¸ªä¸»è¦å…ƒç´ ï¼š
- en: the space S, whether it is S= â„Â³ or S= â„Â².
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç©ºé—´Sï¼Œæ— è®ºæ˜¯S= â„Â³è¿˜æ˜¯S= â„Â²ã€‚
- en: The group *G.*
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¾¤ä½“ *G*ã€‚
- en: 'The input out dimension of the layers: cÊ¿*â¿* Ê¾ and cÊ¿*â¿âº Â¹* Ê¾*.*'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å±‚çš„è¾“å…¥è¾“å‡ºç»´åº¦ï¼šcÊ¿*â¿* Ê¾ å’Œ cÊ¿*â¿âº Â¹* Ê¾*ã€‚
- en: 'More specifically we can say that the choice of the group G defines the type
    of the network. Specifically we are mainly interested on the following type of
    networks:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å…·ä½“åœ°è¯´ï¼Œæˆ‘ä»¬å¯ä»¥è¯´ç¾¤Gçš„é€‰æ‹©å®šä¹‰äº†ç½‘ç»œçš„ç±»å‹ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä¸»è¦å¯¹ä»¥ä¸‹ç±»å‹çš„ç½‘ç»œæ„Ÿå…´è¶£ï¼š
- en: 'SO Networks: Equivariant to rotations in the Special Orthogonal Group (SO).'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SO ç½‘ç»œï¼šå¯¹ç‰¹æ®Šæ­£äº¤ç¾¤ï¼ˆSOï¼‰ä¸­çš„æ—‹è½¬å…·æœ‰ç­‰å˜æ€§ã€‚
- en: 'SE Networks: Equivariant to rotations and translations within the Special Euclidean
    Group (SE).'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SE ç½‘ç»œï¼šå¯¹ç‰¹æ®Šæ¬§å‡ é‡Œå¾—ç¾¤ï¼ˆSEï¼‰ä¸­çš„æ—‹è½¬å’Œå¹³ç§»å…·æœ‰ç­‰å˜æ€§ã€‚
- en: 'E Networks: Equivariant to rotations, translations, and reflections in the
    Euclidean Group (E).'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: E ç½‘ç»œï¼šå¯¹æ¬§å‡ é‡Œå¾—ç¾¤ï¼ˆEï¼‰ä¸­çš„æ—‹è½¬ã€å¹³ç§»å’Œåå°„å…·æœ‰ç­‰å˜æ€§ã€‚
- en: If we operate in a 2D input domain, we have SO(2), SE(2), and E(2) networks
    [[4]](https://arxiv.org/abs/1911.08251). Conversely, with a 3D input domain, we
    work with SO(3), SE(3), and E(3) networks[[1](http://link)], and indeed this can
    be extended to any E(n) space [[6]](https://openreview.net/pdf?id=WE4qe9xlnQw).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬åœ¨2Dè¾“å…¥åŸŸä¸­æ“ä½œï¼Œæˆ‘ä»¬æœ‰SO(2)ï¼ŒSE(2)å’ŒE(2)ç½‘ç»œ [[4]](https://arxiv.org/abs/1911.08251)ã€‚ç›¸åï¼Œå¯¹äº3Dè¾“å…¥åŸŸï¼Œæˆ‘ä»¬ä½¿ç”¨SO(3)ï¼ŒSE(3)å’ŒE(3)ç½‘ç»œ[[1](http://link)]ï¼Œå¹¶ä¸”è¿™å¯ä»¥æ‰©å±•åˆ°ä»»ä½•E(n)ç©ºé—´
    [[6]](https://openreview.net/pdf?id=WE4qe9xlnQw)ã€‚
- en: Extending this work into other spaces and symmetries is an area of ongoing research,
    an interested reader is encouraged to investigate the fields of mathematical study
    known as Hilbert spaces and Greenâ€™s functions, a discussion of which here is out
    of the scope of this article.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å°†è¿™é¡¹å·¥ä½œæ‰©å±•åˆ°å…¶ä»–ç©ºé—´å’Œå¯¹ç§°æ€§æ˜¯ä¸€ä¸ªæŒç»­çš„ç ”ç©¶é¢†åŸŸï¼Œæ„Ÿå…´è¶£çš„è¯»è€…å¯ä»¥è°ƒæŸ¥è¢«ç§°ä¸ºHilbertç©ºé—´å’ŒGreenå‡½æ•°çš„æ•°å­¦ç ”ç©¶é¢†åŸŸï¼Œè¿™é‡Œä¸åœ¨æœ¬æ–‡è®¨è®ºèŒƒå›´ä¹‹å†…ã€‚
- en: However it is possible to see that in case of SE(n) networks the general solution
    of Eq.1 is a harmonic basis function in S= â„*â¿*. In the image above (Fig 3B) it
    is possible the harmonic functions in â„Â² on the left and harmonic functions in
    â„Â³.
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œå¯ä»¥çœ‹åˆ°åœ¨ SE(n) ç½‘ç»œçš„æƒ…å†µä¸‹ï¼Œæ–¹ç¨‹å¼1çš„ä¸€èˆ¬è§£æ˜¯S=â„*â¿*ä¸­çš„ä¸€ä¸ªè°æ³¢åŸºå‡½æ•°ã€‚åœ¨ä¸Šé¢çš„å›¾åƒä¸­ï¼ˆå›¾3Bï¼‰ï¼Œå¯ä»¥çœ‹åˆ°â„Â²å·¦ä¾§çš„è°æ³¢å‡½æ•°å’Œâ„Â³ä¸­çš„è°æ³¢å‡½æ•°ã€‚
- en: '![](../Images/643be215a340fa4459acfae5cf9f293d.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/643be215a340fa4459acfae5cf9f293d.png)'
- en: 'Fig 3B: Basis of harmonic functions in 2D (left) and in 3D (right). This basis
    constitutes a basis of steerable equivariant filters in SE(2) and SE(3) networks
    respectively.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 3Bï¼šäºŒç»´ï¼ˆå·¦ï¼‰å’Œä¸‰ç»´ï¼ˆå³ï¼‰ä¸­çš„è°æ³¢å‡½æ•°åŸºã€‚è¿™äº›åŸºåˆ†åˆ«æ„æˆ SE(2) å’Œ SE(3) ç½‘ç»œä¸­å¯æ“æ§ç­‰å˜æ»¤æ³¢å™¨çš„åŸºã€‚
- en: 'Considering a more filter design scenario, in the image Fig 3C below, we see
    for example how an SO2 steerable equivariant kernel is built for a input layer
    *f â‚€*: â„Â²->â„Â³ and an output layer of *fâ‚*:â„Â²->â„Â².'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 'è€ƒè™‘ä¸€ä¸ªæ›´å…·æ»¤æ³¢å™¨è®¾è®¡åœºæ™¯çš„æƒ…å†µï¼Œåœ¨ä¸‹å›¾ Fig 3C ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å¦‚ä½•ä¸ºè¾“å…¥å±‚ *f â‚€*: â„Â²->â„Â³ å’Œè¾“å‡ºå±‚ *fâ‚*: â„Â²->â„Â²
    æ„å»ºä¸€ä¸ª SO2 å¯æ“æ§ç­‰å˜æ ¸ã€‚'
- en: 'The kernel is a function *k*: â„Â²->â„Â³Ë£Â². Each single element of the matrix is
    obtained from a function resulting from the linear weighted combination of the
    D basis sampled at the position *(xâ‚,xâ‚‚)* . We see the example above for position
    *x=(1,2)*.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 'æ ¸æ˜¯ä¸€ä¸ªå‡½æ•° *k*: â„Â²->â„Â³Ë£Â²ã€‚çŸ©é˜µçš„æ¯ä¸ªå•ç‹¬å…ƒç´ æ˜¯é€šè¿‡å¯¹åœ¨ä½ç½®*(xâ‚,xâ‚‚)*é‡‡æ ·çš„DåŸºçš„çº¿æ€§åŠ æƒç»„åˆå¾—åˆ°çš„å‡½æ•°ã€‚æˆ‘ä»¬å¯ä»¥æŸ¥çœ‹ä¸Šé¢çš„ç¤ºä¾‹ä½ç½®
    *x=(1,2)*ã€‚'
- en: As follows we will show some simple solutions of this equation considering ,
    S=â„Â² and G as group of rotation transformations impling SO2 networks.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å±•ç¤ºä¸€äº›è¿™ä¸ªæ–¹ç¨‹çš„ç®€å•è§£ï¼Œè€ƒè™‘ S=â„Â² å’Œ G ä½œä¸ºæ—‹è½¬å˜æ¢çš„ç¾¤ä½“ï¼ŒåŒ…å« SO2 ç½‘ç»œã€‚
- en: '![](../Images/3ae0f08c22bf149cea91fecb975c2883.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3ae0f08c22bf149cea91fecb975c2883.png)'
- en: 'Fig 3C: Visualization representation of a steerable kernel 3x2 is built using
    a basis of 6 harmonic functions.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 3Cï¼šä½¿ç”¨ 6 ä¸ªè°æ³¢å‡½æ•°çš„åŸºæ„å»ºçš„ 3x2 å¯æ“æ§æ ¸çš„å¯è§†åŒ–è¡¨ç¤ºã€‚
- en: 2.3 Practical solutions
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 å®é™…è§£å†³æ–¹æ¡ˆ
- en: '- Case1A: SO2 networks , k: S=â„Â² â†’ â„'
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '- Case1A: SO2 ç½‘ç»œï¼Œk: S=â„Â² â†’ â„'
- en: Letâ€™s imagine the practical case of having a greyscale image as input and we
    want to build a steerable filter to process it. First of all, we have to decide
    the dimension of the output layer (number of features). Letâ€™s take for simplicity
    dimension 1.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾å®é™…æƒ…å†µä¸‹è¾“å…¥ä¸ºç°åº¦å›¾åƒï¼Œæˆ‘ä»¬æƒ³è¦æ„å»ºä¸€ä¸ªå¯æ“æ§æ»¤æ³¢å™¨æ¥å¤„ç†å®ƒã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¿…é¡»å†³å®šè¾“å‡ºå±‚çš„ç»´åº¦ï¼ˆç‰¹å¾æ•°é‡ï¼‰ã€‚ä¸ºäº†ç®€ä¾¿èµ·è§ï¼Œå‡è®¾ç»´åº¦ä¸º 1ã€‚
- en: 'In this setup, we have an input function *f*: â„Â²-> â„ and a similar output function
    *fâ‚*: â„Â²-> â„. Therefore the kernel function is *k*: â„Â² -> â„. We want our CNN layer
    to be equivariant to a group of transformations, G, which represents rotations
    by angle theta within [0,2Ï€) (SO network). For this problem, the kernel functionâ€™s
    basis requires using Eq.1\. Given that both f and fÂ¹ are scalar, Pi_out = 1 and
    Pi_in = 1\. This results *k[****g_****Î¸(x)] = k[x]* as written in Eq.3 .'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 'åœ¨è¿™ä¸ªè®¾ç½®ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªè¾“å…¥å‡½æ•° *f*: â„Â²-> â„ å’Œä¸€ä¸ªç±»ä¼¼çš„è¾“å‡ºå‡½æ•° *fâ‚*: â„Â²-> â„ã€‚å› æ­¤ï¼Œæ ¸å‡½æ•°æ˜¯ *k*: â„Â² -> â„ã€‚æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„
    CNN å±‚å¯¹ä¸€ä¸ªå˜æ¢ç¾¤ä½“ G æ˜¯ç­‰å˜çš„ï¼ŒG ä»£è¡¨äº†è§’åº¦ theta åœ¨ [0,2Ï€) èŒƒå›´å†…çš„æ—‹è½¬ï¼ˆSO ç½‘ç»œï¼‰ã€‚å¯¹äºè¿™ä¸ªé—®é¢˜ï¼Œæ ¸å‡½æ•°çš„åŸºéœ€è¦ä½¿ç”¨æ–¹ç¨‹å¼1ã€‚ç”±äº
    f å’Œ fÂ¹ éƒ½æ˜¯æ ‡é‡ï¼ŒPi_out = 1 å’Œ Pi_in = 1ã€‚ç»“æœæ˜¯ *k[****g_****Î¸(x)] = k[x]*ï¼Œå¦‚æ–¹ç¨‹å¼3ä¸­æ‰€å†™ã€‚'
- en: If *x = (xâ‚, xâ‚‚)* is in â„Â², g(theta) aligns with the 2D Euler matrix.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ *x = (xâ‚, xâ‚‚)* åœ¨ â„Â² ä¸­ï¼Œg(theta) ä¸ 2D æ¬§æ‹‰çŸ©é˜µå¯¹é½ã€‚
- en: '![](../Images/23227fb2d9498574821a1a0809d776c2.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/23227fb2d9498574821a1a0809d776c2.png)'
- en: 'Eq.3: Rewriting Eq.(1) in case of k: S=â„Â² â†’ â„'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 'æ–¹ç¨‹å¼3ï¼šåœ¨ k: S=â„Â² â†’ â„ çš„æƒ…å†µä¸‹é‡å†™æ–¹ç¨‹å¼ï¼ˆ1ï¼‰'
- en: It is trivial to see that this is solved by each isotropic function in (*xâ‚,
    xâ‚‚*) . Specifically this resolves with a one dimensional basis of isotropic (rotation
    invariant) kernels. (i.e. *k(xâ‚, xâ‚‚)* = *xâ‚*Â² +*xâ‚‚*Â²)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå®¹æ˜“çœ‹å‡ºï¼Œè¿™å¯ä»¥é€šè¿‡åœ¨(*xâ‚, xâ‚‚*)ä¸­çš„æ¯ä¸ªå„å‘åŒæ€§å‡½æ•°æ¥è§£å†³ã€‚å…·ä½“æ¥è¯´ï¼Œè¿™å¯ä»¥é€šè¿‡ä¸€ç»´çš„å„å‘åŒæ€§ï¼ˆæ—‹è½¬ä¸å˜ï¼‰æ ¸æ¥è§£å†³ã€‚ï¼ˆå³ *k(xâ‚, xâ‚‚)*
    = *xâ‚*Â² + *xâ‚‚*Â²ï¼‰
- en: 'Case 2: SO2 filter , k: â„Â² â†’ â„Â²'
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'Case 2: SO2 æ»¤æ³¢å™¨ï¼Œk: â„Â² â†’ â„Â²'
- en: 'Letâ€™s take now a more complex case. The input function is *f:* â„Â² â†’ â„Â² and
    the output layer is a function *f â‚:* â„Â² â†’ â„Â². The kernel can be therefore written
    as function *k: S=* â„Â² *â†’* â„Â² Ë£ Â²; in other words for each position x in â„Â² we
    have a bi-dimensional matrix 2x2 (see equation below). We want to build S02 filter
    so the group of transformations to consider is again G={g(*Î¸*)} ={r(*Î¸*)} , *Î¸*
    âˆˆ *[0,2Î [*. Being â„Â² the codomain of *f* and *f â‚, Î _out=Î _Î¸* and *Î _in=Î _Î¸ ,*
    where Î _Î¸ is the Euler matrix in â„Â². Considering all these conditions we can rewrite
    Eq.1 above in the following way:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 'ç°åœ¨è€ƒè™‘ä¸€ä¸ªæ›´å¤æ‚çš„æƒ…å†µã€‚è¾“å…¥å‡½æ•°ä¸º*f:* â„Â² â†’ â„Â²ï¼Œè¾“å‡ºå±‚ä¸ºå‡½æ•°*f â‚:* â„Â² â†’ â„Â²ã€‚å› æ­¤ï¼Œå†…æ ¸å¯ä»¥å†™ä¸ºå‡½æ•°*k: S=* â„Â² *â†’*
    â„Â² Ë£ Â²; æ¢å¥è¯è¯´ï¼Œå¯¹äºâ„Â²ä¸­çš„æ¯ä¸ªä½ç½®xï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªäºŒç»´çŸ©é˜µ2x2ï¼ˆè§ä¸‹æ–¹æ–¹ç¨‹ï¼‰ã€‚æˆ‘ä»¬æƒ³è¦æ„å»ºS02æ»¤æ³¢å™¨ï¼Œå› æ­¤éœ€è¦è€ƒè™‘çš„å˜æ¢ç¾¤å†æ¬¡æ˜¯G={g(*Î¸*)}
    ={r(*Î¸*)}ï¼Œ*Î¸* âˆˆ *[0,2Î [*. ç”±äºâ„Â²æ˜¯*f*å’Œ*f â‚*çš„å€¼åŸŸï¼ŒÎ _out=Î _Î¸* å’Œ *Î _in=Î _Î¸*ï¼Œå…¶ä¸­Î _Î¸æ˜¯â„Â²ä¸­çš„æ¬§æ‹‰çŸ©é˜µã€‚è€ƒè™‘åˆ°æ‰€æœ‰è¿™äº›æ¡ä»¶ï¼Œæˆ‘ä»¬å¯ä»¥ä»¥ä¸‹è¿°æ–¹å¼é‡å†™Eq.1ï¼š'
- en: '![](../Images/9c16aa56e4b18daebd5ae7451eff30cc.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9c16aa56e4b18daebd5ae7451eff30cc.png)'
- en: 'Eq.(4): kernel function considering *k: S=* â„Â² *â†’* â„Â² Ë£ Â²'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq.(4): è€ƒè™‘åˆ°çš„å†…æ ¸å‡½æ•°*k: S=* â„Â² *â†’* â„Â² Ë£ Â²'
- en: '![](../Images/234b4cbcbdd561e26738e4c75aac7564.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/234b4cbcbdd561e26738e4c75aac7564.png)'
- en: 'Eq.(5): Rewriting Eq.(1) for a SO2 kernel k: S=â„Â² â†’ â„Â².'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq.(5): ä¸ºSO2å†…æ ¸ké‡å†™Eq.(1): S=â„Â² â†’ â„Â²ã€‚'
- en: For a more comprehensive understanding of the solution to this equation and
    additional insights, please refer to the appendix section in the paper [4].
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: æ¬²æ›´å…¨é¢åœ°ç†è§£è¯¥æ–¹ç¨‹çš„è§£åŠæ›´å¤šè§è§£ï¼Œè¯·å‚è€ƒè®ºæ–‡[4]ä¸­çš„é™„å½•éƒ¨åˆ†ã€‚
- en: 2.4 Network non-linearities
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4 ç½‘ç»œéçº¿æ€§
- en: So far we have only considered equivariance with respect to the convolution
    operation, not considering the non-linear part given by the function Ïƒ*(f(x)):*
    **â„=**â„ Í¨â†’â„ Í¨â€™. In session 4.3 of paper [1] and 2.6 session of paper [4] this
    is widely treated.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä»…è€ƒè™‘äº†ç›¸å¯¹äºå·ç§¯æ“ä½œçš„ç­‰å˜æ€§ï¼Œè€Œæ²¡æœ‰è€ƒè™‘ç”±å‡½æ•°Ïƒ*(f(x)):* **â„=**â„ Í¨â†’â„ Í¨â€™ç»™å‡ºçš„éçº¿æ€§éƒ¨åˆ†ã€‚è®ºæ–‡[1]çš„ç¬¬4.3èŠ‚å’Œè®ºæ–‡[4]çš„ç¬¬2.6èŠ‚å¯¹æ­¤è¿›è¡Œäº†å¹¿æ³›è®¨è®ºã€‚
- en: 'Given the function f(x) the condition of equivariance can be summarized as
    following :'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ç»™å®šå‡½æ•°f(x)ï¼Œç­‰å˜æ€§æ¡ä»¶å¯ä»¥æ€»ç»“å¦‚ä¸‹ï¼š
- en: '![](../Images/af2dadd3f7be62964669f540ae651f03.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/af2dadd3f7be62964669f540ae651f03.png)'
- en: 'Eq.(5) : Condition of equivariance for the activation function.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq.(5): æ¿€æ´»å‡½æ•°çš„ç­‰å˜æ€§æ¡ä»¶ã€‚'
- en: 'As also mentioned in a related YouTube lecture [here](https://www.youtube.com/watch?v=b8K6adf_zY0),
    itâ€™s possible to create an activation function that meets this criterion by utilizing
    whatâ€™s known as a norm-based activation function like **Ïƒ*(u) =* Ïƒ*(||u||)***.
    The motivation for this is that a scalar norm is transparently invariant and so
    the application of any nonlinear function to it will result in an invariant output.
    To prove this, when we apply this formula to the aforementioned condition to Eq.(5)
    we obtain the following equation:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ç›¸å…³çš„YouTubeè®²åº§ä¸­æ‰€æåˆ°çš„[è¿™é‡Œ](https://www.youtube.com/watch?v=b8K6adf_zY0)ï¼Œå¯ä»¥é€šè¿‡åˆ©ç”¨æ‰€è°“çš„åŸºäºèŒƒæ•°çš„æ¿€æ´»å‡½æ•°ï¼Œå¦‚**Ïƒ*(u)
    =* Ïƒ*(||u||)***ï¼Œæ¥åˆ›å»ºæ»¡è¶³è¯¥æ ‡å‡†çš„æ¿€æ´»å‡½æ•°ã€‚å…¶åŠ¨æœºåœ¨äºæ ‡é‡èŒƒæ•°æ˜¯é€æ˜ä¸å˜çš„ï¼Œå› æ­¤å¯¹å…¶åº”ç”¨ä»»ä½•éçº¿æ€§å‡½æ•°å°†äº§ç”Ÿä¸å˜çš„è¾“å‡ºã€‚ä¸ºäº†è¯æ˜è¿™ä¸€ç‚¹ï¼Œå½“æˆ‘ä»¬å°†æ­¤å…¬å¼åº”ç”¨äºä¸Šè¿°æ¡ä»¶æ—¶ï¼Œä¼šå¾—åˆ°ä»¥ä¸‹æ–¹ç¨‹ï¼š
- en: '![](../Images/16f45464bf676098d1c8a548920ba2a2.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/16f45464bf676098d1c8a548920ba2a2.png)'
- en: 'Eq.(6): Rewriting Eq.(5) as norm-based functions.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq.(6): å°†Eq.(5)é‡å†™ä¸ºåŸºäºèŒƒæ•°çš„å‡½æ•°ã€‚'
- en: If â€˜gâ€™ belongs to the group of E transformations, the norm remains constant.
    Consequently, the equation is universally valid when Î â€™(g) equals the Identity.
    This implies that the specially designed activation function is consistently rotation
    invariant. An example of this , *Norm-ReLUs*, defined by *Î·(|f(x)|) = ReLU(|f(x)|
    âˆ’ b)*
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœâ€˜gâ€™å±äºEå˜æ¢ç¾¤ï¼Œåˆ™èŒƒæ•°ä¿æŒä¸å˜ã€‚å› æ­¤ï¼Œå½“Î â€™(g)ç­‰äºå•ä½çŸ©é˜µæ—¶ï¼Œè¯¥æ–¹ç¨‹åœ¨æ™®éæƒ…å†µä¸‹æ˜¯æœ‰æ•ˆçš„ã€‚è¿™æ„å‘³ç€ç‰¹åˆ«è®¾è®¡çš„æ¿€æ´»å‡½æ•°å§‹ç»ˆå…·æœ‰æ—‹è½¬ä¸å˜æ€§ã€‚ä¾‹å¦‚ï¼Œ*Norm-ReLUs*ï¼Œå…¶å®šä¹‰ä¸º*Î·(|f(x)|)
    = ReLU(|f(x)| âˆ’ b)*
- en: Additional nonlinear activation functions have been suggested in the research
    papers and the lecture, such as non-gated activation functions. We refer the reader
    to these sources for further explanation.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ç ”ç©¶è®ºæ–‡å’Œè®²åº§ä¸­æå‡ºäº†é¢å¤–çš„éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œå¦‚éé—¨æ§æ¿€æ´»å‡½æ•°ã€‚æˆ‘ä»¬å»ºè®®è¯»è€…æŸ¥é˜…è¿™äº›æ¥æºä»¥è·å–è¿›ä¸€æ­¥çš„è§£é‡Šã€‚
- en: '**3) Design a steerable CNN**'
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**3) è®¾è®¡ä¸€ä¸ªå¯æ“æ§çš„CNN**'
- en: '![](../Images/4c4ab19a773efc0fc05e8dda9e506ba6.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4c4ab19a773efc0fc05e8dda9e506ba6.png)'
- en: 'Fig 3D: The architecture of a steerable CNN as described in [[3]](https://arxiv.org/abs/1711.07289).
    Notice the use of the steerable filters in layer 2 coupled together with a G-convolution.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 'å›¾3D: å¯æ“æ§CNNçš„æ¶æ„ï¼Œå¦‚[[3]](https://arxiv.org/abs/1711.07289)ä¸­æ‰€è¿°ã€‚æ³¨æ„ç¬¬2å±‚ä¸­ä½¿ç”¨çš„å¯æ“æ§æ»¤æ³¢å™¨ä¸Gå·ç§¯çš„ç»“åˆã€‚'
- en: In the previous session, we grasped the fundamentals of constructing a single
    steerable filter. In this concluding segment, we will delve into the methodology
    of integrating these filters cohesively to establish a fully-functional steerable
    neural network.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬æŒæ¡äº†æ„å»ºå•ä¸ªå¯å¼•å¯¼æ»¤æ³¢å™¨çš„åŸºç¡€çŸ¥è¯†ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨å¦‚ä½•å°†è¿™äº›æ»¤æ³¢å™¨æœ‰æ•ˆåœ°æ•´åˆä»¥å»ºç«‹ä¸€ä¸ªåŠŸèƒ½å…¨é¢çš„å¯å¼•å¯¼ç¥ç»ç½‘ç»œã€‚
- en: In the picture above we can see an example taken by the paper [[3]](https://arxiv.org/abs/1711.07289).
    We are particularly interested in layer 2 where the steerable filters are used.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šå›¾ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸€ç¯‡è®ºæ–‡ä¸­çš„ç¤ºä¾‹[[3]](https://arxiv.org/abs/1711.07289)ã€‚æˆ‘ä»¬ç‰¹åˆ«å…³æ³¨ç¬¬2å±‚ï¼Œå…¶ä¸­ä½¿ç”¨äº†å¯å¼•å¯¼æ»¤æ³¢å™¨ã€‚
- en: Here, each horizontal representation is a steerable filter â€” a composite of
    weighted harmonic functions â€” that yields a distinct output, denoted as single
    fâ¿. Observing the structure, itâ€™s apparent that while harmonic functions remain
    consistent across the filters, their orientations vary from one to the next. This
    is emblematic of the G-convolution technique, a sophisticated method that contributes
    to the construction of networks invariant to transformation (you can find more
    information on this technique [here](https://chat.openai.com/c/64d8f147-a86f-497f-be18-2e09cb13da96#)).
    The network harnesses the power of max-pooling to funnel only the most robust
    responses from the array of steerable filters into the subsequent layer. This
    principle of selective transmission ensures that the strongest features are preserved
    and enhanced as they progress through the network. This approach mirrors the methodologies
    implemented in other works, such as in reference [5], which successfully crafted
    a scale-invariant steerable network. The architecture of such a steerable CNN
    benefits from this technique, as it naturally incorporates scale and rotation
    invariance, thereby enriching the networkâ€™s ability to recognize patterns and
    features in a more abstract yet robust manner.In any case, it is possible to see
    from the picture that the final result is a network equivariant to rotations.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæ¯ä¸ªæ°´å¹³è¡¨ç¤ºéƒ½æ˜¯ä¸€ä¸ªå¯å¼•å¯¼æ»¤æ³¢å™¨â€”â€”ç”±åŠ æƒè°æ³¢å‡½æ•°ç»„æˆâ€”â€”å®ƒäº§ç”Ÿä¸€ä¸ªä¸åŒçš„è¾“å‡ºï¼Œè¡¨ç¤ºä¸ºå•ä¸ª fâ¿ã€‚è§‚å¯Ÿå…¶ç»“æ„ï¼Œå¾ˆæ˜æ˜¾è™½ç„¶è°æ³¢å‡½æ•°åœ¨å„ä¸ªæ»¤æ³¢å™¨ä¸­ä¿æŒä¸€è‡´ï¼Œä½†å®ƒä»¬çš„æ–¹å‘åœ¨æ¯ä¸ªæ»¤æ³¢å™¨ä¹‹é—´æœ‰æ‰€å˜åŒ–ã€‚è¿™æ˜¯
    G-å·ç§¯æŠ€æœ¯çš„ä¸€ä¸ªå…¸å‹ç‰¹å¾ï¼Œè¿™æ˜¯ä¸€ç§å¤æ‚çš„æ–¹æ³•ï¼Œæœ‰åŠ©äºæ„å»ºå¯¹å˜æ¢ä¸å˜çš„ç½‘ç»œï¼ˆä½ å¯ä»¥åœ¨[è¿™é‡Œ](https://chat.openai.com/c/64d8f147-a86f-497f-be18-2e09cb13da96#)æ‰¾åˆ°æ›´å¤šå…³äºè¯¥æŠ€æœ¯çš„ä¿¡æ¯ï¼‰ã€‚è¯¥ç½‘ç»œåˆ©ç”¨æœ€å¤§æ± åŒ–çš„å¼ºå¤§åŠŸèƒ½ï¼Œå°†æ¥è‡ªå¯å¼•å¯¼æ»¤æ³¢å™¨é˜µåˆ—ä¸­çš„æœ€å¼ºå“åº”ä¼ é€’åˆ°ä¸‹ä¸€å±‚ã€‚è¿™ç§é€‰æ‹©æ€§ä¼ è¾“çš„åŸåˆ™ç¡®ä¿äº†æœ€å¼ºçš„ç‰¹å¾åœ¨ç½‘ç»œä¸­ä¼ é€’å’Œå¢å¼ºã€‚è¿™ç§æ–¹æ³•ä¸å…¶ä»–å·¥ä½œä¸­å®ç°çš„æ–¹æ³•ç±»ä¼¼ï¼Œä¾‹å¦‚å‚è€ƒæ–‡çŒ®[5]æˆåŠŸæ„å»ºäº†ä¸€ä¸ªå°ºåº¦ä¸å˜çš„å¯å¼•å¯¼ç½‘ç»œã€‚è¿™ç§å¯å¼•å¯¼
    CNN çš„æ¶æ„å—ç›Šäºè¿™ç§æŠ€æœ¯ï¼Œå› ä¸ºå®ƒè‡ªç„¶åœ°ç»“åˆäº†å°ºåº¦å’Œæ—‹è½¬ä¸å˜æ€§ï¼Œä»è€Œå¢å¼ºäº†ç½‘ç»œä»¥æ›´æŠ½è±¡ä½†æ›´å¼ºå¤§çš„æ–¹å¼è¯†åˆ«æ¨¡å¼å’Œç‰¹å¾çš„èƒ½åŠ›ã€‚æ— è®ºå¦‚ä½•ï¼Œä»å›¾ç‰‡ä¸­å¯ä»¥çœ‹å‡ºï¼Œæœ€ç»ˆç»“æœæ˜¯ä¸€ä¸ªå¯¹æ—‹è½¬ä¸å˜çš„ç½‘ç»œã€‚
- en: '![](../Images/206e02a4aa42a18b1aba73b7faab5f60.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/206e02a4aa42a18b1aba73b7faab5f60.png)'
- en: 'Fig 3E: A visual example of the application of a 2D steerable filter on a rotated
    image (original can be found [here](https://github.com/QUVA-Lab/e2cnn))'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 3Eï¼šåœ¨æ—‹è½¬å›¾åƒä¸Šåº”ç”¨2Då¯å¼•å¯¼æ»¤æ³¢å™¨çš„è§†è§‰ç¤ºä¾‹ï¼ˆåŸå§‹å›¾åƒå¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/QUVA-Lab/e2cnn)æ‰¾åˆ°ï¼‰
- en: An excellent step-by-step explanation about the design of a steerable neural
    network can be found at this [link](https://github.com/QUVA-Lab/e2cnn/blob/master/examples/introduction.ipynb),
    included in the Github repo *â€œe2cnâ€ (*[link](https://github.com/QUVA-Lab/e2cnn)).
    In this repo, it is possible to find the PyTorch code for designing an SE2 steerable
    network. Useful code for the development of SE3 networks can be found instead
    at this [link](https://github.com/mariogeiger/se3cnn), while a quick course on
    3D equivariant networks has been published [here](http://www.ipam.ucla.edu/abstract/?tid=16346&pcode=MLPWS1).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºå¯å¼•å¯¼ç¥ç»ç½‘ç»œè®¾è®¡çš„ä¼˜ç§€é€æ­¥è§£é‡Šå¯ä»¥åœ¨æ­¤[é“¾æ¥](https://github.com/QUVA-Lab/e2cnn/blob/master/examples/introduction.ipynb)ä¸­æ‰¾åˆ°ï¼Œè¯¥é“¾æ¥åŒ…å«åœ¨Githubåº“*â€œe2cnâ€*ï¼ˆ*[link](https://github.com/QUVA-Lab/e2cnn)ï¼‰ã€‚åœ¨è¯¥åº“ä¸­ï¼Œå¯ä»¥æ‰¾åˆ°è®¾è®¡
    SE2 å¯å¼•å¯¼ç½‘ç»œçš„ PyTorch ä»£ç ã€‚å…³äº SE3 ç½‘ç»œçš„æœ‰ç”¨ä»£ç å¯ä»¥åœ¨æ­¤[é“¾æ¥](https://github.com/mariogeiger/se3cnn)ä¸­æ‰¾åˆ°ï¼Œè€Œå…³äº3D
    ç­‰å˜ç½‘ç»œçš„å¿«é€Ÿè¯¾ç¨‹å·²åœ¨[è¿™é‡Œ](http://www.ipam.ucla.edu/abstract/?tid=16346&pcode=MLPWS1)å‘å¸ƒã€‚
- en: 'LITERATURE:'
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ–‡çŒ®ï¼š
- en: '[1] â€œ3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric
    Dataâ€, Weilier et al., ([link](https://arxiv.org/abs/1807.02547));'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] â€œ3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric
    Dataâ€ï¼ŒWeilier et al.ï¼Œ([link](https://arxiv.org/abs/1807.02547));'
- en: '[2] â€œSteerable CNNsâ€, Cohen et al. [( link](https://arxiv.org/abs/1612.08498));'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] â€œSteerable CNNsâ€ï¼ŒCohen et al. [( link](https://arxiv.org/abs/1612.08498));'
- en: '[3] â€œLearning Steerable Filters for Rotation Equivariant CNNsâ€,Weilier et al.,
    ([link](https://arxiv.org/abs/1711.07289))'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] â€œå­¦ä¹ æ—‹è½¬ç­‰å˜CNNçš„å¯è°ƒèŠ‚æ»¤æ³¢å™¨â€ï¼ŒWeilierç­‰äºº ([link](https://arxiv.org/abs/1711.07289))'
- en: '[4] â€œGeneral E(2)-Equivariant Steerable CNNsâ€ Weilier et al., ([link](https://arxiv.org/abs/1911.08251))'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] â€œé€šç”¨E(2)-ç­‰å˜å¯è°ƒèŠ‚CNNâ€ï¼ŒWeilierç­‰äºº ([link](https://arxiv.org/abs/1911.08251))'
- en: '[5] â€œScale Steerable Filters for the Locally Scale-Invariant Convolutional
    Neural Networkâ€, Ghosh et al. ([link](https://www.researchgate.net/publication/334480982_Scale_Steerable_Filters_for_the_Locally_Scale-Invariant_Convolutional_Neural_Network?enrichId=rgreq-7fc8b3654779eb94d36221a6e5fab2ff-XXX&enrichSource=Y292ZXJQYWdlOzMzNDQ4MDk4MjtBUzo3ODEyNTQ4ODI1MDg4MDBAMTU2MzI3NzA4NzY1NA%25253D%25253D&el=1_x_3&_esc=publicationCoverPdf))'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] â€œé€‚ç”¨äºå±€éƒ¨å°ºåº¦ä¸å˜å·ç§¯ç¥ç»ç½‘ç»œçš„å°ºåº¦å¯è°ƒèŠ‚æ»¤æ³¢å™¨â€ï¼ŒGhoshç­‰äºº ([link](https://www.researchgate.net/publication/334480982_Scale_Steerable_Filters_for_the_Locally_Scale-Invariant_Convolutional_Neural_Network?enrichId=rgreq-7fc8b3654779eb94d36221a6e5fab2ff-XXX&enrichSource=Y292ZXJQYWdlOzMzNDQ4MDk4MjtBUzo3ODEyNTQ4ODI1MDg4MDBAMTU2MzI3NzA4NzY1NA%25253D%25253D&el=1_x_3&_esc=publicationCoverPdf))'
- en: '[6] â€œA program to build E(n)-equivariant steerable CNNs.â€ Cesa et al. ([link](https://openreview.net/pdf?id=WE4qe9xlnQw))'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] â€œæ„å»ºE(n)-ç­‰å˜å¯è°ƒèŠ‚CNNçš„ç¨‹åºã€‚â€ Cesaç­‰äºº ([link](https://openreview.net/pdf?id=WE4qe9xlnQw))'
- en: 'âœï¸ ğŸ“„. About the authors:'
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: âœï¸ ğŸ“„. å…³äºä½œè€…ï¼š
- en: '***1ï¸âƒ£ Matteo Ciprian*,** Machine Learning Engineer/Researcher'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '***1ï¸âƒ£ Matteo Ciprian***ï¼Œæœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆ/ç ”ç©¶å‘˜'
- en: MSc in Telecommunications Engineering at University of Padua. Currently working
    in the field of Sensor Fusion, Signal Processing and applied AI. Experience in
    projects related to AI applications in eHealth and wearable technologies (academic
    research and corporate domains). Specialized in developing Anomaly Detection algorithms,
    as well as advancing techniques in Deep Learning and Sensor Fusion.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¡•å£«å­¦ä½ï¼Œç”µä¿¡å·¥ç¨‹ï¼Œå¸•å¤šç“¦å¤§å­¦ã€‚å½“å‰åœ¨ä¼ æ„Ÿå™¨èåˆã€ä¿¡å·å¤„ç†å’Œåº”ç”¨äººå·¥æ™ºèƒ½é¢†åŸŸå·¥ä½œã€‚å‚ä¸ä¸äººå·¥æ™ºèƒ½åœ¨ç”µå­å¥åº·å’Œå¯ç©¿æˆ´æŠ€æœ¯ä¸­çš„åº”ç”¨ç›¸å…³çš„é¡¹ç›®ï¼ˆå­¦æœ¯ç ”ç©¶å’Œä¼ä¸šé¢†åŸŸï¼‰ã€‚ä¸“æ³¨äºå¼€å‘å¼‚å¸¸æ£€æµ‹ç®—æ³•ï¼Œä»¥åŠæ¨è¿›æ·±åº¦å­¦ä¹ å’Œä¼ æ„Ÿå™¨èåˆæŠ€æœ¯ã€‚
- en: Passionate about Philosophy. Content creator in Youtube.
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯¹å“²å­¦å……æ»¡çƒ­æƒ…ã€‚YouTube å†…å®¹åˆ›ä½œè€…ã€‚
- en: '**ğŸ”— Links:** ğŸ’¼ [Linkedin](https://www.linkedin.com/in/matteo-ciprian-ba30ab122/)'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**ğŸ”— é“¾æ¥ï¼š** ğŸ’¼ [Linkedin](https://www.linkedin.com/in/matteo-ciprian-ba30ab122/)'
- en: ğŸ“¹ [Youtube](https://www.youtube.com/channel/UCF--7G3kkCmEsdPLm8wyPow)
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ğŸ“¹ [Youtube](https://www.youtube.com/channel/UCF--7G3kkCmEsdPLm8wyPow)
- en: ğŸ‘¨â€ğŸ’»[Instagram](https://www.instagram.com/cip_mat/)
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ğŸ‘¨â€ğŸ’» [Instagram](https://www.instagram.com/cip_mat/)
- en: 2ï¸âƒ£ ***Robert Schoonmaker*,** Signal Processing/Machine Learning Researcher
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 2ï¸âƒ£ ***Robert Schoonmaker***ï¼Œä¿¡å·å¤„ç†/æœºå™¨å­¦ä¹ ç ”ç©¶å‘˜
- en: PhD in Computational Condensed Matter Physics from Durham University. Specializes
    in applied machine learning and nonlinear statistics, currently investigating
    the uses of GPU compute methods on synthetic aperture radar and similar systems.
    Experience includes developing symmetric ML methods for use in sensor fusion and
    positioning techniques.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åšå£«å­¦ä½ï¼Œè®¡ç®—å‡èšæ€ç‰©ç†ï¼Œæœä¼¦å¤§å­¦ã€‚ä¸“æ³¨äºåº”ç”¨æœºå™¨å­¦ä¹ å’Œéçº¿æ€§ç»Ÿè®¡å­¦ï¼Œç›®å‰æ­£åœ¨ç ”ç©¶GPUè®¡ç®—æ–¹æ³•åœ¨åˆæˆå­”å¾„é›·è¾¾åŠç±»ä¼¼ç³»ç»Ÿä¸­çš„åº”ç”¨ã€‚ç»éªŒåŒ…æ‹¬å¼€å‘ç”¨äºä¼ æ„Ÿå™¨èåˆå’Œå®šä½æŠ€æœ¯çš„å¯¹ç§°æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚
- en: '**ğŸ”— Links:** ğŸ’¼ [Linkedin](https://www.linkedin.com/in/robert-schoonmaker-951221b/)'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**ğŸ”— é“¾æ¥ï¼š** ğŸ’¼ [Linkedin](https://www.linkedin.com/in/robert-schoonmaker-951221b/)'
