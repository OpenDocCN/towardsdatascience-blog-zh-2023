- en: Building a Streaming Data Pipeline with Redshift Serverless and Kinesis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://towardsdatascience.com/building-a-streaming-data-pipeline-with-redshift-serverless-and-kinesis-04e09d7e85b2?source=collection_archive---------7-----------------------#2023-10-06](https://towardsdatascience.com/building-a-streaming-data-pipeline-with-redshift-serverless-and-kinesis-04e09d7e85b2?source=collection_archive---------7-----------------------#2023-10-06)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An End-To-End Tutorial for Beginners
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://mshakhomirov.medium.com/?source=post_page-----04e09d7e85b2--------------------------------)[![ðŸ’¡Mike
    Shakhomirov](../Images/bc6895c7face3244d488feb97ba0f68e.png)](https://mshakhomirov.medium.com/?source=post_page-----04e09d7e85b2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----04e09d7e85b2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----04e09d7e85b2--------------------------------)
    [ðŸ’¡Mike Shakhomirov](https://mshakhomirov.medium.com/?source=post_page-----04e09d7e85b2--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Â·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe06a48b3dd48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-streaming-data-pipeline-with-redshift-serverless-and-kinesis-04e09d7e85b2&user=%F0%9F%92%A1Mike+Shakhomirov&userId=e06a48b3dd48&source=post_page-e06a48b3dd48----04e09d7e85b2---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----04e09d7e85b2--------------------------------)
    Â·9 min readÂ·Oct 6, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F04e09d7e85b2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-streaming-data-pipeline-with-redshift-serverless-and-kinesis-04e09d7e85b2&user=%F0%9F%92%A1Mike+Shakhomirov&userId=e06a48b3dd48&source=-----04e09d7e85b2---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F04e09d7e85b2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-streaming-data-pipeline-with-redshift-serverless-and-kinesis-04e09d7e85b2&source=-----04e09d7e85b2---------------------bookmark_footer-----------)![](../Images/d1700c0485714244a17aec09305461e6.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Sebastian Pandelache](https://unsplash.com/@pandelache?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I will talk about one of the most popular data pipeline design
    patterns â€” event streaming. Among other benefits, it enables lightning-fast data
    analytics and we can create reporting dashboards that update results in real-time.
    I will demonstrate how it can be achieved by building a streaming data pipeline
    with AWS Kinesis and Redshift which can be deployed with just a few clicks using
    infrastructure as code. We will use AWS CloudFormation to describe our data platform
    architecture and simplify deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine that as a data engineer, you are tasked to create a data pipeline that
    connects server event streams with a data warehouse solution (Redshift) to transform
    the data and create an analytics dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/19d9e86d0773049b03bcd3c4ea66b9ab.png)'
  prefs: []
  type: TYPE_IMG
- en: Pipeline Infrastructure. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: What is a data pipeline?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It is a sequence of data processing steps. Due to ***logical data flow connections***
    between these stages, each stage generates an **output** that serves as an **input**
    for the following stage.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
