- en: A beginner‚Äôs guide to building a Retrieval Augmented Generation (RAG) application
    from scratch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/a-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d?source=collection_archive---------1-----------------------#2023-11-02](https://towardsdatascience.com/a-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d?source=collection_archive---------1-----------------------#2023-11-02)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learn critical knowledge for building AI apps, in plain english
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)[![Bill
    Chambers](../Images/d04ba934f4cbfdf5fcb42f0b65ac0352.png)](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)
    [Bill Chambers](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9627ead2f75f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&user=Bill+Chambers&userId=9627ead2f75f&source=post_page-9627ead2f75f----e52921953a5d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)
    ¬∑10 min read¬∑Nov 2, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe52921953a5d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&user=Bill+Chambers&userId=9627ead2f75f&source=-----e52921953a5d---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe52921953a5d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&source=-----e52921953a5d---------------------bookmark_footer-----------)![](../Images/937f7d4c1dde1fb4928a29cd60f74320.png)'
  prefs: []
  type: TYPE_NORMAL
- en: A beginner‚Äôs guide to building a Retrieval Augmented Generation (RAG) application
    from scratch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Retrieval Augmented Generation, or RAG, is all the rage these days because it
    introduces some serious capabilities to large language models like OpenAI‚Äôs GPT-4
    ‚Äî and that‚Äôs the ability to use and leverage their own data.
  prefs: []
  type: TYPE_NORMAL
- en: This post will teach you the fundamental intuition behind RAG while providing
    a simple tutorial to help you get started.
  prefs: []
  type: TYPE_NORMAL
- en: The problem with learning in a fast moving space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There‚Äôs so much noise in the AI space and in particular about RAG. Vendors are
    trying to overcomplicate it. They‚Äôre trying to inject their tools, their ecosystems,
    their vision.
  prefs: []
  type: TYPE_NORMAL
- en: It‚Äôs making RAG way more complicated than it needs to be. This tutorial is designed
    to help beginners learn how to build RAG applications from scratch. No fluff,
    no (ok, minimal) jargon, no libraries, just a simple step by step RAG application.
  prefs: []
  type: TYPE_NORMAL
- en: '[Jerry from LlamaIndex advocates for building things from scratch to really
    understand the pieces](https://twitter.com/jerryjliu0/status/1716122650836439478).
    Once you do, using a library like LlamaIndex makes more sense.'
  prefs: []
  type: TYPE_NORMAL
- en: Build from scratch to learn, then build with libraries to scale.
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs get started!
  prefs: []
  type: TYPE_NORMAL
- en: 'Introducing our concept: Retrieval Augmented Generation'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You may or may not have heard of Retrieval Augmented Generation or RAG.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here‚Äôs the definition from [the blog post introducing the concept from Facebook](https://ai.meta.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/):'
  prefs: []
  type: TYPE_NORMAL
- en: '*Building a model that researches and contextualizes is more challenging, but
    it‚Äôs essential for future advancements. We recently made substantial progress
    in this realm with our Retrieval Augmented Generation (RAG) architecture, an end-to-end
    differentiable model that combines an information retrieval component (Facebook
    AI‚Äôs dense-passage retrieval system) with a seq2seq generator (our Bidirectional
    and Auto-Regressive Transformers [BART] model). RAG can be fine-tuned on knowledge-intensive
    downstream tasks to achieve state-of-the-art results compared with even the largest
    pretrained seq2seq language models. And unlike these pretrained models, RAG‚Äôs
    internal knowledge can be easily altered or even supplemented on the fly, enabling
    researchers and engineers to control what RAG knows and doesn‚Äôt know without wasting
    time or compute power retraining the entire model.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Wow, that‚Äôs a mouthful.
  prefs: []
  type: TYPE_NORMAL
- en: 'In simplifying the technique for beginners, we can state that the essence of
    RAG involves adding your own data (via a retrieval tool) to the prompt that you
    pass into a large language model. As a result, you get an output. That gives you
    several benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: You can include facts in the prompt to help the LLM avoid hallucinations
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can (manually) refer to sources of truth when responding to a user query,
    helping to double check any potential issues.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can leverage data that the LLM might not have been trained on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The High Level Components of our RAG System
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: a collection of documents (formally called a corpus)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An input from the user
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a similarity measure between the collection of documents and the user input
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Yes, it‚Äôs that simple.
  prefs: []
  type: TYPE_NORMAL
- en: To start learning and understanding RAG based systems, you don‚Äôt need a vector
    store, you don‚Äôt even *need* an LLM (at least to learn and understand conceptually).
  prefs: []
  type: TYPE_NORMAL
- en: While it is often portrayed as complicated, it doesn‚Äôt have to be.
  prefs: []
  type: TYPE_NORMAL
- en: The ordered steps of a querying RAG system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We‚Äôll perform the following steps in sequence.
  prefs: []
  type: TYPE_NORMAL
- en: Receive a user input
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform our similarity measure
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Post-process the user input and the fetched document(s).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The post-processing is done with an LLM.
  prefs: []
  type: TYPE_NORMAL
- en: A note from the paper itself
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[The actual RAG paper](https://arxiv.org/abs/2005.11401) is obviously *the*
    resource. The problem is that it assumes a LOT of context. It‚Äôs more complicated
    than we need it to be.'
  prefs: []
  type: TYPE_NORMAL
- en: For instance, here‚Äôs the overview of the RAG system as proposed in the paper.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2d54f5c723763e7d78ae93c9f91bcc2c.png)'
  prefs: []
  type: TYPE_IMG
- en: '[An overview of RAG from the RAG paper](https://arxiv.org/abs/2005.11401) by
    Lewis, et al'
  prefs: []
  type: TYPE_NORMAL
- en: That‚Äôs dense.
  prefs: []
  type: TYPE_NORMAL
- en: It‚Äôs great for researchers but for the rest of us, it‚Äôs going to be a lot easier
    to learn step by step by building the system ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: Working through an example ‚Äî the simplest RAG system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let‚Äôs get back to building RAG from scratch, step by step. Here‚Äôs the simplified
    steps that we‚Äôll be working through. While this isn‚Äôt technically ‚ÄúRAG‚Äù it‚Äôs a
    good simplified model to learn with and allow us to progress to more complicated
    variations.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c3aaa700afa3ff0bf86304cef50bac2b.png)'
  prefs: []
  type: TYPE_IMG
- en: Getting a collection of documents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Below you can see that we‚Äôve got a simple corpus of ‚Äòdocuments‚Äô (please be generous
    üòâ).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Defining and performing the similarity measure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now we need a way of measuring the similarity between the **user input** we‚Äôre
    going to receive and the **collection** of documents that we organized. Arguably
    the simplest similarity measure is [jaccard similarity](https://en.wikipedia.org/wiki/Jaccard_index).
    I‚Äôve written about that in the past (see [this post](https://billchambers.me/posts/tf-idf-explained-in-python)
    but the short answer is that the **jaccard similarity** is the intersection divided
    by the union of the ‚Äúsets‚Äù of words.
  prefs: []
  type: TYPE_NORMAL
- en: This allows us to compare our user input with the source documents.
  prefs: []
  type: TYPE_NORMAL
- en: 'Side note: preprocessing'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A challenge is that if we have a plain string like `"Take a leisurely walk in
    the park and enjoy the fresh air.",`, we're going to have to pre-process that
    into a set, so that we can perform these comparisons. We're going to do this in
    the simplest way possible, lower case and split by `" "`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Now we need to define a function that takes in the exact query and our corpus
    and selects the ‚Äòbest‚Äô document to return to the user.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now we can run it, we‚Äôll start with a simple prompt.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: And a simple user input‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Now we can return our response.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Congratulations, you‚Äôve built a basic RAG application.
  prefs: []
  type: TYPE_NORMAL
- en: I got 99 problems and bad similarity is one
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now we‚Äôve opted for a simple similarity measure for learning. But this is going
    to be problematic because it‚Äôs so simple. It has no notion of **semantics**. It‚Äôs
    just looks at what words are in both documents. That means that if we provide
    a negative example, we‚Äôre going to get the same ‚Äúresult‚Äù because that‚Äôs the closest
    document.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f6905b126532fe949de9729a803c563f.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This is a topic that‚Äôs going to come up a lot with ‚ÄúRAG‚Äù, but for now, rest
    assured that we‚Äôll address this problem later.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we have not done any post-processing of the ‚Äúdocument‚Äù to which
    we are responding. So far, we‚Äôve implemented only the ‚Äúretrieval‚Äù part of ‚ÄúRetrieval-Augmented
    Generation‚Äù. The next step is to augment generation by incorporating a large language
    model (LLM).
  prefs: []
  type: TYPE_NORMAL
- en: Adding in a LLM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To do this, we‚Äôre going to use [ollama](https://ollama.ai/) to get up and running
    with an open source LLM on our local machine. We could just as easily use OpenAI‚Äôs
    gpt-4 or Anthropic‚Äôs Claude but for now, we‚Äôll start with the open source llama2
    from [Meta AI](https://ai.meta.com/llama/).
  prefs: []
  type: TYPE_NORMAL
- en: '[ollama installation instructions are here](https://ollama.ai/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This post is going to assume some basic knowledge of large language models,
    so let‚Äôs get right to querying this model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: First we‚Äôre going to define the inputs. To work with this model, we‚Äôre going
    to take
  prefs: []
  type: TYPE_NORMAL
- en: user input,
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: fetch the most similar document (as measured by our similarity measure),
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: pass that into a prompt to the language model,
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*then* return the result to the user'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That introduces a new term, the **prompt**. In short, it‚Äôs the instructions
    that you provide to the LLM.
  prefs: []
  type: TYPE_NORMAL
- en: When you run this code, you‚Äôll see the streaming result. Streaming is important
    for user experience.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Having defined that, let‚Äôs now make the API call to ollama (and llama2). an
    important step is to make sure that ollama‚Äôs running already on your local machine
    by running `ollama serve`.
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: this might be slow on your machine, it‚Äôs certainly slow on mine. Be
    patient, young grasshopper.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This gives us a complete RAG Application, from scratch, no providers, no services.
    You know all of the components in a Retrieval-Augmented Generation application.
    Visually, here‚Äôs what we‚Äôve built.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8a2da66e8db36d3cef1c6db81b0b6a9a.png)'
  prefs: []
  type: TYPE_IMG
- en: The LLM (if you‚Äôre lucky) will handle the user input that goes against the recommended
    document. We can see that below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Areas for improvement
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If we go back to our diagream of the RAG application and think about what we‚Äôve
    just built, we‚Äôll see various opportunities for improvement. These opportunities
    are where tools like vector stores, embeddings, and prompt ‚Äòengineering‚Äô gets
    involved.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are ten potential areas where we could improve the current setup:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The number of documents** üëâ more documents might mean more recommendations.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The depth/size of documents** üëâ higher quality content and longer documents
    with more information might be better.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The number of documents we give to the LLM** üëâ Right now, we‚Äôre only giving
    the LLM one document. We could feed in several as ‚Äòcontext‚Äô and allow the model
    to provide a more personalized recommendation based on the user input.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The parts of documents that we give to the LLM** üëâ If we have bigger or more
    thorough documents, we might just want to add in parts of those documents, parts
    of various documents, or some variation there of. In the lexicon, this is called
    chunking.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Our document storage tool** üëâ We might store our documents in a different
    way or different database. In particular, if we have a lot of documents, we might
    explore storing them in a data lake or a vector store.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The similarity measure** üëâ How we measure similarity is of consequence, we
    might need to trade off performance and thoroughness (e.g., looking at every individual
    document).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The pre-processing of the documents & user input** üëâ We might perform some
    extra preprocessing or augmentation of the user input before we pass it into the
    similarity measure. For instance, we might use an embedding to convert that input
    to a vector.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The similarity measure** üëâ We can change the similarity measure to fetch
    better or more relevant documents.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The model** üëâ We can change the final model that we use. We‚Äôre using llama2
    above, but we could just as easily use an Anthropic or Claude Model.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The prompt** üëâ We could use a different prompt into the LLM/Model and tune
    it according to the output we want to get the output we want.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**If you‚Äôre worried about harmful or toxic output** üëâ We could implement a
    ‚Äúcircuit breaker‚Äù of sorts that runs the user input to see if there‚Äôs toxic, harmful,
    or dangerous discussions. For instance, in a healthcare context you could see
    if the information contained unsafe languages and respond accordingly ‚Äî outside
    of the typical flow.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The scope for improvements isn‚Äôt limited to these points; the possibilities
    are vast, and we‚Äôll delve into them in future tutorials. Until then, don‚Äôt hesitate
    to [reach out on Twitter](https://twitter.com/bllchmbrs) if you have any questions.
    Happy RAGING :).
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Jerry Liu on Twitter advocating for users to build RAG from scratch](https://twitter.com/jerryjliu0/status/1716122650836439478)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[This post was originally posted on learnbybuilding.ai](https://learnbybuilding.ai/tutorials/rag-from-scratch).
    **I‚Äôm running a course on How to Build Generative AI Products for Product Managers
    in the coming months,** [**sign up here**](https://maven.com/forms/90684f)**.**'
  prefs: []
  type: TYPE_NORMAL
