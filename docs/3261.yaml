- en: A beginnerâ€™s guide to building a Retrieval Augmented Generation (RAG) application
    from scratch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/a-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d?source=collection_archive---------1-----------------------#2023-11-02](https://towardsdatascience.com/a-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d?source=collection_archive---------1-----------------------#2023-11-02)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learn critical knowledge for building AI apps, in plain english
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)[![Bill
    Chambers](../Images/d04ba934f4cbfdf5fcb42f0b65ac0352.png)](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)
    [Bill Chambers](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9627ead2f75f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&user=Bill+Chambers&userId=9627ead2f75f&source=post_page-9627ead2f75f----e52921953a5d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)
    Â·10 min readÂ·Nov 2, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe52921953a5d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&user=Bill+Chambers&userId=9627ead2f75f&source=-----e52921953a5d---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe52921953a5d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&source=-----e52921953a5d---------------------bookmark_footer-----------)![](../Images/937f7d4c1dde1fb4928a29cd60f74320.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: A beginnerâ€™s guide to building a Retrieval Augmented Generation (RAG) application
    from scratch
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Retrieval Augmented Generation, or RAG, is all the rage these days because it
    introduces some serious capabilities to large language models like OpenAIâ€™s GPT-4
    â€” and thatâ€™s the ability to use and leverage their own data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: This post will teach you the fundamental intuition behind RAG while providing
    a simple tutorial to help you get started.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: The problem with learning in a fast moving space
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thereâ€™s so much noise in the AI space and in particular about RAG. Vendors are
    trying to overcomplicate it. Theyâ€™re trying to inject their tools, their ecosystems,
    their vision.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Itâ€™s making RAG way more complicated than it needs to be. This tutorial is designed
    to help beginners learn how to build RAG applications from scratch. No fluff,
    no (ok, minimal) jargon, no libraries, just a simple step by step RAG application.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '[Jerry from LlamaIndex advocates for building things from scratch to really
    understand the pieces](https://twitter.com/jerryjliu0/status/1716122650836439478).
    Once you do, using a library like LlamaIndex makes more sense.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Build from scratch to learn, then build with libraries to scale.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Letâ€™s get started!
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: 'Introducing our concept: Retrieval Augmented Generation'
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You may or may not have heard of Retrieval Augmented Generation or RAG.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: 'Hereâ€™s the definition from [the blog post introducing the concept from Facebook](https://ai.meta.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/):'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '*Building a model that researches and contextualizes is more challenging, but
    itâ€™s essential for future advancements. We recently made substantial progress
    in this realm with our Retrieval Augmented Generation (RAG) architecture, an end-to-end
    differentiable model that combines an information retrieval component (Facebook
    AIâ€™s dense-passage retrieval system) with a seq2seq generator (our Bidirectional
    and Auto-Regressive Transformers [BART] model). RAG can be fine-tuned on knowledge-intensive
    downstream tasks to achieve state-of-the-art results compared with even the largest
    pretrained seq2seq language models. And unlike these pretrained models, RAGâ€™s
    internal knowledge can be easily altered or even supplemented on the fly, enabling
    researchers and engineers to control what RAG knows and doesnâ€™t know without wasting
    time or compute power retraining the entire model.*'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Wow, thatâ€™s a mouthful.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: 'In simplifying the technique for beginners, we can state that the essence of
    RAG involves adding your own data (via a retrieval tool) to the prompt that you
    pass into a large language model. As a result, you get an output. That gives you
    several benefits:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: You can include facts in the prompt to help the LLM avoid hallucinations
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can (manually) refer to sources of truth when responding to a user query,
    helping to double check any potential issues.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can leverage data that the LLM might not have been trained on.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The High Level Components of our RAG System
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: a collection of documents (formally called a corpus)
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An input from the user
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a similarity measure between the collection of documents and the user input
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Yes, itâ€™s that simple.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: To start learning and understanding RAG based systems, you donâ€™t need a vector
    store, you donâ€™t even *need* an LLM (at least to learn and understand conceptually).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: While it is often portrayed as complicated, it doesnâ€™t have to be.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: The ordered steps of a querying RAG system
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Weâ€™ll perform the following steps in sequence.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: Receive a user input
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform our similarity measure
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Post-process the user input and the fetched document(s).
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The post-processing is done with an LLM.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: A note from the paper itself
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[The actual RAG paper](https://arxiv.org/abs/2005.11401) is obviously *the*
    resource. The problem is that it assumes a LOT of context. Itâ€™s more complicated
    than we need it to be.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: For instance, hereâ€™s the overview of the RAG system as proposed in the paper.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2d54f5c723763e7d78ae93c9f91bcc2c.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
- en: '[An overview of RAG from the RAG paper](https://arxiv.org/abs/2005.11401) by
    Lewis, et al'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Thatâ€™s dense.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Itâ€™s great for researchers but for the rest of us, itâ€™s going to be a lot easier
    to learn step by step by building the system ourselves.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Working through an example â€” the simplest RAG system
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Letâ€™s get back to building RAG from scratch, step by step. Hereâ€™s the simplified
    steps that weâ€™ll be working through. While this isnâ€™t technically â€œRAGâ€ itâ€™s a
    good simplified model to learn with and allow us to progress to more complicated
    variations.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c3aaa700afa3ff0bf86304cef50bac2b.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
- en: Getting a collection of documents
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Below you can see that weâ€™ve got a simple corpus of â€˜documentsâ€™ (please be generous
    ğŸ˜‰).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Defining and performing the similarity measure
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now we need a way of measuring the similarity between the **user input** weâ€™re
    going to receive and the **collection** of documents that we organized. Arguably
    the simplest similarity measure is [jaccard similarity](https://en.wikipedia.org/wiki/Jaccard_index).
    Iâ€™ve written about that in the past (see [this post](https://billchambers.me/posts/tf-idf-explained-in-python)
    but the short answer is that the **jaccard similarity** is the intersection divided
    by the union of the â€œsetsâ€ of words.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: This allows us to compare our user input with the source documents.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: 'Side note: preprocessing'
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A challenge is that if we have a plain string like `"Take a leisurely walk in
    the park and enjoy the fresh air.",`, we're going to have to pre-process that
    into a set, so that we can perform these comparisons. We're going to do this in
    the simplest way possible, lower case and split by `" "`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now we need to define a function that takes in the exact query and our corpus
    and selects the â€˜bestâ€™ document to return to the user.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now we can run it, weâ€™ll start with a simple prompt.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: And a simple user inputâ€¦
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now we can return our response.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Congratulations, youâ€™ve built a basic RAG application.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: I got 99 problems and bad similarity is one
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now weâ€™ve opted for a simple similarity measure for learning. But this is going
    to be problematic because itâ€™s so simple. It has no notion of **semantics**. Itâ€™s
    just looks at what words are in both documents. That means that if we provide
    a negative example, weâ€™re going to get the same â€œresultâ€ because thatâ€™s the closest
    document.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬é€‰æ‹©äº†ä¸€ä¸ªç®€å•çš„ç›¸ä¼¼æ€§åº¦é‡è¿›è¡Œå­¦ä¹ ã€‚ä½†è¿™ä¼šæœ‰é—®é¢˜ï¼Œå› ä¸ºå®ƒè¿‡äºç®€å•ã€‚å®ƒæ²¡æœ‰**è¯­ä¹‰**çš„æ¦‚å¿µã€‚å®ƒåªæ˜¯æŸ¥çœ‹ä¸¤ä¸ªæ–‡æ¡£ä¸­åŒ…å«äº†å“ªäº›è¯ã€‚è¿™æ„å‘³ç€å¦‚æœæˆ‘ä»¬æä¾›ä¸€ä¸ªè´Ÿé¢ä¾‹å­ï¼Œæˆ‘ä»¬å°†å¾—åˆ°ç›¸åŒçš„â€œç»“æœâ€ï¼Œå› ä¸ºè¿™æ˜¯æœ€æ¥è¿‘çš„æ–‡æ¡£ã€‚
- en: '![](../Images/f6905b126532fe949de9729a803c563f.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f6905b126532fe949de9729a803c563f.png)'
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This is a topic thatâ€™s going to come up a lot with â€œRAGâ€, but for now, rest
    assured that weâ€™ll address this problem later.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªåœ¨â€œRAGâ€ä¸­ç»å¸¸å‡ºç°çš„è¯é¢˜ï¼Œä½†ç›®å‰è¯·æ”¾å¿ƒï¼Œæˆ‘ä»¬ä¼šåœ¨åé¢è§£å†³è¿™ä¸ªé—®é¢˜ã€‚
- en: At this point, we have not done any post-processing of the â€œdocumentâ€ to which
    we are responding. So far, weâ€™ve implemented only the â€œretrievalâ€ part of â€œRetrieval-Augmented
    Generationâ€. The next step is to augment generation by incorporating a large language
    model (LLM).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬è¿˜æ²¡æœ‰å¯¹å“åº”çš„â€œæ–‡æ¡£â€è¿›è¡Œä»»ä½•åå¤„ç†ã€‚åˆ°ç°åœ¨ä¸ºæ­¢ï¼Œæˆ‘ä»¬åªå®ç°äº†â€œæ£€ç´¢å¢å¼ºç”Ÿæˆâ€çš„â€œæ£€ç´¢â€éƒ¨åˆ†ã€‚ä¸‹ä¸€æ­¥æ˜¯é€šè¿‡å¼•å…¥å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥å¢å¼ºç”Ÿæˆã€‚
- en: Adding in a LLM
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ·»åŠ LLM
- en: To do this, weâ€™re going to use [ollama](https://ollama.ai/) to get up and running
    with an open source LLM on our local machine. We could just as easily use OpenAIâ€™s
    gpt-4 or Anthropicâ€™s Claude but for now, weâ€™ll start with the open source llama2
    from [Meta AI](https://ai.meta.com/llama/).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨[ollama](https://ollama.ai/)æ¥å¯åŠ¨å¹¶è¿è¡Œæœ¬åœ°æœºå™¨ä¸Šçš„å¼€æºLLMã€‚æˆ‘ä»¬åŒæ ·å¯ä»¥ä½¿ç”¨OpenAIçš„gpt-4æˆ–Anthropicçš„Claudeï¼Œä½†ç°åœ¨æˆ‘ä»¬å°†ä»[Meta
    AI](https://ai.meta.com/llama/)çš„å¼€æºllama2å¼€å§‹ã€‚
- en: '[ollama installation instructions are here](https://ollama.ai/)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ollamaå®‰è£…è¯´æ˜åœ¨è¿™é‡Œ](https://ollama.ai/)'
- en: This post is going to assume some basic knowledge of large language models,
    so letâ€™s get right to querying this model.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡å‡è®¾ä½ å¯¹å¤§å‹è¯­è¨€æ¨¡å‹æœ‰ä¸€äº›åŸºæœ¬äº†è§£ï¼Œæ‰€ä»¥æˆ‘ä»¬ç›´æ¥å¼€å§‹æŸ¥è¯¢è¿™ä¸ªæ¨¡å‹å§ã€‚
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: First weâ€™re going to define the inputs. To work with this model, weâ€™re going
    to take
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬å°†å®šä¹‰è¾“å…¥ã€‚ä¸ºäº†ä½¿ç”¨è¿™ä¸ªæ¨¡å‹ï¼Œæˆ‘ä»¬å°†é‡‡å–
- en: user input,
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”¨æˆ·è¾“å…¥ï¼Œ
- en: fetch the most similar document (as measured by our similarity measure),
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è·å–æœ€ç›¸ä¼¼çš„æ–‡æ¡£ï¼ˆæŒ‰æˆ‘ä»¬çš„ç›¸ä¼¼æ€§åº¦é‡æ¥è¡¡é‡ï¼‰ï¼Œ
- en: pass that into a prompt to the language model,
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†å…¶ä¼ é€’ç»™è¯­è¨€æ¨¡å‹çš„æç¤ºï¼Œ
- en: '*then* return the result to the user'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ç„¶å* å°†ç»“æœè¿”å›ç»™ç”¨æˆ·'
- en: That introduces a new term, the **prompt**. In short, itâ€™s the instructions
    that you provide to the LLM.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¼•å…¥äº†ä¸€ä¸ªæ–°æœ¯è¯­ï¼Œå³**æç¤º**ã€‚ç®€è€Œè¨€ä¹‹ï¼Œå®ƒå°±æ˜¯ä½ ç»™LLMçš„æŒ‡ä»¤ã€‚
- en: When you run this code, youâ€™ll see the streaming result. Streaming is important
    for user experience.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ è¿è¡Œè¿™æ®µä»£ç æ—¶ï¼Œä½ ä¼šçœ‹åˆ°æµå¼ç»“æœã€‚æµå¼å¤„ç†å¯¹ç”¨æˆ·ä½“éªŒå¾ˆé‡è¦ã€‚
- en: '[PRE11]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Having defined that, letâ€™s now make the API call to ollama (and llama2). an
    important step is to make sure that ollamaâ€™s running already on your local machine
    by running `ollama serve`.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡®å®šäº†è¿™ä¸€ç‚¹ä¹‹åï¼Œç°åœ¨è®©æˆ‘ä»¬è°ƒç”¨ollamaï¼ˆå’Œllama2ï¼‰çš„APIã€‚ä¸€ä¸ªé‡è¦çš„æ­¥éª¤æ˜¯ç¡®ä¿ollamaå·²ç»åœ¨ä½ çš„æœ¬åœ°æœºå™¨ä¸Šè¿è¡Œï¼Œé€šè¿‡è¿è¡Œ`ollama
    serve`ã€‚
- en: '*Note: this might be slow on your machine, itâ€™s certainly slow on mine. Be
    patient, young grasshopper.*'
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*æ³¨æ„ï¼šè¿™åœ¨ä½ çš„æœºå™¨ä¸Šå¯èƒ½å¾ˆæ…¢ï¼Œåœ¨æˆ‘çš„æœºå™¨ä¸Šè‚¯å®šå¾ˆæ…¢ã€‚è¯·è€å¿ƒç‚¹ï¼Œå°è‰hopperã€‚*'
- en: '[PRE13]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This gives us a complete RAG Application, from scratch, no providers, no services.
    You know all of the components in a Retrieval-Augmented Generation application.
    Visually, hereâ€™s what weâ€™ve built.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç»™äº†æˆ‘ä»¬ä¸€ä¸ªå®Œæ•´çš„RAGåº”ç”¨ï¼Œä»é›¶å¼€å§‹ï¼Œæ²¡æœ‰æä¾›è€…ï¼Œæ²¡æœ‰æœåŠ¡ã€‚ä½ äº†è§£äº†æ£€ç´¢å¢å¼ºç”Ÿæˆåº”ç”¨ä¸­çš„æ‰€æœ‰ç»„ä»¶ã€‚è§†è§‰ä¸Šï¼Œè¿™æ˜¯æˆ‘ä»¬æ„å»ºçš„å†…å®¹ã€‚
- en: '![](../Images/8a2da66e8db36d3cef1c6db81b0b6a9a.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8a2da66e8db36d3cef1c6db81b0b6a9a.png)'
- en: The LLM (if youâ€™re lucky) will handle the user input that goes against the recommended
    document. We can see that below.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å¹¸è¿çš„è¯ï¼ŒLLMå°†å¤„ç†ä¸æ¨èæ–‡æ¡£ä¸ç¬¦çš„ç”¨æˆ·è¾“å…¥ã€‚æˆ‘ä»¬å¯ä»¥åœ¨ä¸‹é¢çœ‹åˆ°ã€‚
- en: '[PRE16]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Areas for improvement
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ”¹è¿›é¢†åŸŸ
- en: If we go back to our diagream of the RAG application and think about what weâ€™ve
    just built, weâ€™ll see various opportunities for improvement. These opportunities
    are where tools like vector stores, embeddings, and prompt â€˜engineeringâ€™ gets
    involved.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å›åˆ°RAGåº”ç”¨çš„å›¾ç¤ºï¼Œè€ƒè™‘ä¸€ä¸‹æˆ‘ä»¬åˆšåˆšæ„å»ºçš„å†…å®¹ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°å„ç§æ”¹è¿›çš„æœºä¼šã€‚è¿™äº›æœºä¼šæ˜¯å·¥å…·å¦‚å‘é‡å­˜å‚¨ã€åµŒå…¥å’Œæç¤ºâ€œå·¥ç¨‹â€ä»‹å…¥çš„åœ°æ–¹ã€‚
- en: 'Here are ten potential areas where we could improve the current setup:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰åä¸ªæ½œåœ¨çš„æ”¹è¿›é¢†åŸŸï¼š
- en: '**The number of documents** ğŸ‘‰ more documents might mean more recommendations.'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ–‡æ¡£çš„æ•°é‡** ğŸ‘‰ æ›´å¤šæ–‡æ¡£å¯èƒ½æ„å‘³ç€æ›´å¤šçš„æ¨èã€‚'
- en: '**The depth/size of documents** ğŸ‘‰ higher quality content and longer documents
    with more information might be better.'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ–‡æ¡£çš„æ·±åº¦/å¤§å°** ğŸ‘‰ æ›´é«˜è´¨é‡çš„å†…å®¹å’Œä¿¡æ¯æ›´å¤šçš„é•¿æ–‡æ¡£å¯èƒ½æ›´å¥½ã€‚'
- en: '**The number of documents we give to the LLM** ğŸ‘‰ Right now, weâ€™re only giving
    the LLM one document. We could feed in several as â€˜contextâ€™ and allow the model
    to provide a more personalized recommendation based on the user input.'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The parts of documents that we give to the LLM** ğŸ‘‰ If we have bigger or more
    thorough documents, we might just want to add in parts of those documents, parts
    of various documents, or some variation there of. In the lexicon, this is called
    chunking.'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Our document storage tool** ğŸ‘‰ We might store our documents in a different
    way or different database. In particular, if we have a lot of documents, we might
    explore storing them in a data lake or a vector store.'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The similarity measure** ğŸ‘‰ How we measure similarity is of consequence, we
    might need to trade off performance and thoroughness (e.g., looking at every individual
    document).'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The pre-processing of the documents & user input** ğŸ‘‰ We might perform some
    extra preprocessing or augmentation of the user input before we pass it into the
    similarity measure. For instance, we might use an embedding to convert that input
    to a vector.'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The similarity measure** ğŸ‘‰ We can change the similarity measure to fetch
    better or more relevant documents.'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The model** ğŸ‘‰ We can change the final model that we use. Weâ€™re using llama2
    above, but we could just as easily use an Anthropic or Claude Model.'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The prompt** ğŸ‘‰ We could use a different prompt into the LLM/Model and tune
    it according to the output we want to get the output we want.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**If youâ€™re worried about harmful or toxic output** ğŸ‘‰ We could implement a
    â€œcircuit breakerâ€ of sorts that runs the user input to see if thereâ€™s toxic, harmful,
    or dangerous discussions. For instance, in a healthcare context you could see
    if the information contained unsafe languages and respond accordingly â€” outside
    of the typical flow.'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The scope for improvements isnâ€™t limited to these points; the possibilities
    are vast, and weâ€™ll delve into them in future tutorials. Until then, donâ€™t hesitate
    to [reach out on Twitter](https://twitter.com/bllchmbrs) if you have any questions.
    Happy RAGING :).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Jerry Liu on Twitter advocating for users to build RAG from scratch](https://twitter.com/jerryjliu0/status/1716122650836439478)'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[This post was originally posted on learnbybuilding.ai](https://learnbybuilding.ai/tutorials/rag-from-scratch).
    **Iâ€™m running a course on How to Build Generative AI Products for Product Managers
    in the coming months,** [**sign up here**](https://maven.com/forms/90684f)**.**'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
