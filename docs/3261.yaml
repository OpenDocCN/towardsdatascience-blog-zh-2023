- en: A beginner’s guide to building a Retrieval Augmented Generation (RAG) application
    from scratch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从零开始构建检索增强生成（RAG）应用程序的初学者指南
- en: 原文：[https://towardsdatascience.com/a-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d?source=collection_archive---------1-----------------------#2023-11-02](https://towardsdatascience.com/a-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d?source=collection_archive---------1-----------------------#2023-11-02)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d?source=collection_archive---------1-----------------------#2023-11-02](https://towardsdatascience.com/a-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d?source=collection_archive---------1-----------------------#2023-11-02)
- en: Learn critical knowledge for building AI apps, in plain english
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用简单易懂的语言学习构建AI应用程序的关键知识
- en: '[](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)[![Bill
    Chambers](../Images/d04ba934f4cbfdf5fcb42f0b65ac0352.png)](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)
    [Bill Chambers](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)[![Bill
    Chambers](../Images/d04ba934f4cbfdf5fcb42f0b65ac0352.png)](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)
    [Bill Chambers](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9627ead2f75f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&user=Bill+Chambers&userId=9627ead2f75f&source=post_page-9627ead2f75f----e52921953a5d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)
    ·10 min read·Nov 2, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe52921953a5d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&user=Bill+Chambers&userId=9627ead2f75f&source=-----e52921953a5d---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9627ead2f75f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&user=Bill+Chambers&userId=9627ead2f75f&source=post_page-9627ead2f75f----e52921953a5d---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)
    ·10分钟阅读·2023年11月2日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe52921953a5d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&user=Bill+Chambers&userId=9627ead2f75f&source=-----e52921953a5d---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe52921953a5d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&source=-----e52921953a5d---------------------bookmark_footer-----------)![](../Images/937f7d4c1dde1fb4928a29cd60f74320.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe52921953a5d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&source=-----e52921953a5d---------------------bookmark_footer-----------)![](../Images/937f7d4c1dde1fb4928a29cd60f74320.png)'
- en: A beginner’s guide to building a Retrieval Augmented Generation (RAG) application
    from scratch
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从零开始构建检索增强生成（RAG）应用程序的初学者指南
- en: Retrieval Augmented Generation, or RAG, is all the rage these days because it
    introduces some serious capabilities to large language models like OpenAI’s GPT-4
    — and that’s the ability to use and leverage their own data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）目前非常流行，因为它为像OpenAI的GPT-4这样的语言模型引入了一些强大的功能——即利用和利用自身数据的能力。
- en: This post will teach you the fundamental intuition behind RAG while providing
    a simple tutorial to help you get started.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本文将教你RAG的基本直觉，并提供一个简单的教程帮助你入门。
- en: The problem with learning in a fast moving space
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在快速变化的领域中学习的问题
- en: There’s so much noise in the AI space and in particular about RAG. Vendors are
    trying to overcomplicate it. They’re trying to inject their tools, their ecosystems,
    their vision.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: AI领域有太多噪音，特别是关于RAG的噪音。供应商们试图使其过于复杂。他们试图注入他们的工具、生态系统和愿景。
- en: It’s making RAG way more complicated than it needs to be. This tutorial is designed
    to help beginners learn how to build RAG applications from scratch. No fluff,
    no (ok, minimal) jargon, no libraries, just a simple step by step RAG application.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得RAG变得比实际需要的复杂得多。这个教程旨在帮助初学者从零开始学习如何构建RAG应用程序。不包含冗余内容，不使用术语（好吧，尽量少用），不依赖库，只是一个简单的逐步RAG应用程序。
- en: '[Jerry from LlamaIndex advocates for building things from scratch to really
    understand the pieces](https://twitter.com/jerryjliu0/status/1716122650836439478).
    Once you do, using a library like LlamaIndex makes more sense.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[LlamaIndex的Jerry提倡从零开始构建事物以真正理解各个部分](https://twitter.com/jerryjliu0/status/1716122650836439478)。一旦你做到这一点，使用像LlamaIndex这样的库就更有意义了。'
- en: Build from scratch to learn, then build with libraries to scale.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 从零开始学习，然后用库进行扩展。
- en: Let’s get started!
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: 'Introducing our concept: Retrieval Augmented Generation'
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍我们的概念：检索增强生成
- en: You may or may not have heard of Retrieval Augmented Generation or RAG.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能听说过检索增强生成（RAG），也可能没有。
- en: 'Here’s the definition from [the blog post introducing the concept from Facebook](https://ai.meta.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/):'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这是[Facebook介绍这个概念的博客文章](https://ai.meta.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/)中的定义：
- en: '*Building a model that researches and contextualizes is more challenging, but
    it’s essential for future advancements. We recently made substantial progress
    in this realm with our Retrieval Augmented Generation (RAG) architecture, an end-to-end
    differentiable model that combines an information retrieval component (Facebook
    AI’s dense-passage retrieval system) with a seq2seq generator (our Bidirectional
    and Auto-Regressive Transformers [BART] model). RAG can be fine-tuned on knowledge-intensive
    downstream tasks to achieve state-of-the-art results compared with even the largest
    pretrained seq2seq language models. And unlike these pretrained models, RAG’s
    internal knowledge can be easily altered or even supplemented on the fly, enabling
    researchers and engineers to control what RAG knows and doesn’t know without wasting
    time or compute power retraining the entire model.*'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*构建一个能够研究和上下文化的模型更具挑战性，但这是未来发展的关键。我们最近在这一领域取得了重大进展，推出了我们的检索增强生成（RAG）架构，这是一种端到端的可微模型，将信息检索组件（Facebook
    AI的密集段落检索系统）与seq2seq生成器（我们的双向自回归变换器[BART]模型）相结合。RAG可以在知识密集型的下游任务上进行微调，与即使是最大的预训练seq2seq语言模型相比，能够达到最先进的结果。而且，与这些预训练模型不同，RAG的内部知识可以随时轻松更改或补充，使研究人员和工程师能够控制RAG知道和不知道的内容，而无需浪费时间或计算能力重新训练整个模型。*'
- en: Wow, that’s a mouthful.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 哇，真是太复杂了。
- en: 'In simplifying the technique for beginners, we can state that the essence of
    RAG involves adding your own data (via a retrieval tool) to the prompt that you
    pass into a large language model. As a result, you get an output. That gives you
    several benefits:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化技术对初学者，我们可以说RAG的本质是将你自己的数据（通过检索工具）添加到你传递给大型语言模型的提示中。这样，你将获得一个输出。这带来了几个好处：
- en: You can include facts in the prompt to help the LLM avoid hallucinations
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以在提示中包含事实，以帮助LLM避免产生幻觉。
- en: You can (manually) refer to sources of truth when responding to a user query,
    helping to double check any potential issues.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以（手动）参考权威来源来回应用户查询，帮助检查潜在问题。
- en: You can leverage data that the LLM might not have been trained on.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以利用LLM可能未曾训练过的数据。
- en: The High Level Components of our RAG System
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们RAG系统的高级组件
- en: a collection of documents (formally called a corpus)
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一组文档（正式称为语料库）
- en: An input from the user
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户输入
- en: a similarity measure between the collection of documents and the user input
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文档集合与用户输入之间的相似性测量
- en: Yes, it’s that simple.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，就是这么简单。
- en: To start learning and understanding RAG based systems, you don’t need a vector
    store, you don’t even *need* an LLM (at least to learn and understand conceptually).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始学习和理解基于RAG的系统，你不需要一个向量存储，甚至*不需要*LLM（至少在概念学习和理解方面）。
- en: While it is often portrayed as complicated, it doesn’t have to be.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然它经常被描绘得很复杂，但其实不一定如此。
- en: The ordered steps of a querying RAG system
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查询RAG系统的有序步骤
- en: We’ll perform the following steps in sequence.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按顺序执行以下步骤。
- en: Receive a user input
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接收用户输入
- en: Perform our similarity measure
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行我们的相似度度量
- en: Post-process the user input and the fetched document(s).
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对用户输入和获取的文档进行后处理。
- en: The post-processing is done with an LLM.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 后处理是通过LLM完成的。
- en: A note from the paper itself
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 论文本身的备注
- en: '[The actual RAG paper](https://arxiv.org/abs/2005.11401) is obviously *the*
    resource. The problem is that it assumes a LOT of context. It’s more complicated
    than we need it to be.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[实际的RAG论文](https://arxiv.org/abs/2005.11401)显然是*最重要的*资源。问题在于它假设了大量的上下文。这比我们需要的要复杂得多。'
- en: For instance, here’s the overview of the RAG system as proposed in the paper.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，下面是论文中提出的RAG系统概述。
- en: '![](../Images/2d54f5c723763e7d78ae93c9f91bcc2c.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2d54f5c723763e7d78ae93c9f91bcc2c.png)'
- en: '[An overview of RAG from the RAG paper](https://arxiv.org/abs/2005.11401) by
    Lewis, et al'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[来自RAG论文的RAG概述](https://arxiv.org/abs/2005.11401) 由Lewis等人提供'
- en: That’s dense.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这很密集。
- en: It’s great for researchers but for the rest of us, it’s going to be a lot easier
    to learn step by step by building the system ourselves.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对于研究人员来说，这很棒，但对于我们其他人来说，通过自己构建系统逐步学习将会容易得多。
- en: Working through an example — the simplest RAG system
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过一个示例进行工作——最简单的RAG系统
- en: Let’s get back to building RAG from scratch, step by step. Here’s the simplified
    steps that we’ll be working through. While this isn’t technically “RAG” it’s a
    good simplified model to learn with and allow us to progress to more complicated
    variations.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到从头开始构建RAG，逐步进行。这里是我们将要经历的简化步骤。虽然这不严格是“RAG”，但它是一个好的简化模型，有助于学习并使我们能够进步到更复杂的变体。
- en: '![](../Images/c3aaa700afa3ff0bf86304cef50bac2b.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c3aaa700afa3ff0bf86304cef50bac2b.png)'
- en: Getting a collection of documents
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取文档集合
- en: Below you can see that we’ve got a simple corpus of ‘documents’ (please be generous
    😉).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 下面你可以看到我们有一个简单的‘文档’语料库（请宽容一点😉）。
- en: '[PRE0]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Defining and performing the similarity measure
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义和执行相似度度量
- en: Now we need a way of measuring the similarity between the **user input** we’re
    going to receive and the **collection** of documents that we organized. Arguably
    the simplest similarity measure is [jaccard similarity](https://en.wikipedia.org/wiki/Jaccard_index).
    I’ve written about that in the past (see [this post](https://billchambers.me/posts/tf-idf-explained-in-python)
    but the short answer is that the **jaccard similarity** is the intersection divided
    by the union of the “sets” of words.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要一种方法来衡量我们将要接收的**用户输入**和我们组织的**文档集合**之间的相似度。可以说，最简单的相似度度量是[杰卡德相似度](https://en.wikipedia.org/wiki/Jaccard_index)。我在过去写过这方面的内容（参见[这篇文章](https://billchambers.me/posts/tf-idf-explained-in-python)），但简短的回答是**杰卡德相似度**是“词集”的交集除以并集。
- en: This allows us to compare our user input with the source documents.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够将用户输入与源文档进行比较。
- en: 'Side note: preprocessing'
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附注：预处理
- en: A challenge is that if we have a plain string like `"Take a leisurely walk in
    the park and enjoy the fresh air.",`, we're going to have to pre-process that
    into a set, so that we can perform these comparisons. We're going to do this in
    the simplest way possible, lower case and split by `" "`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 一个挑战是，如果我们有一个简单的字符串像`"Take a leisurely walk in the park and enjoy the fresh
    air."`，我们需要将其预处理为一个集合，以便进行这些比较。我们将以最简单的方式进行处理，转为小写并按`" "`分割。
- en: '[PRE1]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now we need to define a function that takes in the exact query and our corpus
    and selects the ‘best’ document to return to the user.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要定义一个函数，该函数接收精确的查询和我们的语料库，并选择‘最佳’文档返回给用户。
- en: '[PRE2]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now we can run it, we’ll start with a simple prompt.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以运行它了，我们将从一个简单的提示开始。
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: And a simple user input…
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个简单的用户输入…
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now we can return our response.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以返回响应。
- en: '[PRE5]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Congratulations, you’ve built a basic RAG application.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜，你已经构建了一个基本的RAG应用程序。
- en: I got 99 problems and bad similarity is one
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我有99个问题，糟糕的相似度是其中之一
- en: Now we’ve opted for a simple similarity measure for learning. But this is going
    to be problematic because it’s so simple. It has no notion of **semantics**. It’s
    just looks at what words are in both documents. That means that if we provide
    a negative example, we’re going to get the same “result” because that’s the closest
    document.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们选择了一个简单的相似性度量进行学习。但这会有问题，因为它过于简单。它没有**语义**的概念。它只是查看两个文档中包含了哪些词。这意味着如果我们提供一个负面例子，我们将得到相同的“结果”，因为这是最接近的文档。
- en: '![](../Images/f6905b126532fe949de9729a803c563f.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f6905b126532fe949de9729a803c563f.png)'
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This is a topic that’s going to come up a lot with “RAG”, but for now, rest
    assured that we’ll address this problem later.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个在“RAG”中经常出现的话题，但目前请放心，我们会在后面解决这个问题。
- en: At this point, we have not done any post-processing of the “document” to which
    we are responding. So far, we’ve implemented only the “retrieval” part of “Retrieval-Augmented
    Generation”. The next step is to augment generation by incorporating a large language
    model (LLM).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 目前为止，我们还没有对响应的“文档”进行任何后处理。到现在为止，我们只实现了“检索增强生成”的“检索”部分。下一步是通过引入大型语言模型（LLM）来增强生成。
- en: Adding in a LLM
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加LLM
- en: To do this, we’re going to use [ollama](https://ollama.ai/) to get up and running
    with an open source LLM on our local machine. We could just as easily use OpenAI’s
    gpt-4 or Anthropic’s Claude but for now, we’ll start with the open source llama2
    from [Meta AI](https://ai.meta.com/llama/).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们将使用[ollama](https://ollama.ai/)来启动并运行本地机器上的开源LLM。我们同样可以使用OpenAI的gpt-4或Anthropic的Claude，但现在我们将从[Meta
    AI](https://ai.meta.com/llama/)的开源llama2开始。
- en: '[ollama installation instructions are here](https://ollama.ai/)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ollama安装说明在这里](https://ollama.ai/)'
- en: This post is going to assume some basic knowledge of large language models,
    so let’s get right to querying this model.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 本文假设你对大型语言模型有一些基本了解，所以我们直接开始查询这个模型吧。
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: First we’re going to define the inputs. To work with this model, we’re going
    to take
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将定义输入。为了使用这个模型，我们将采取
- en: user input,
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户输入，
- en: fetch the most similar document (as measured by our similarity measure),
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取最相似的文档（按我们的相似性度量来衡量），
- en: pass that into a prompt to the language model,
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将其传递给语言模型的提示，
- en: '*then* return the result to the user'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*然后* 将结果返回给用户'
- en: That introduces a new term, the **prompt**. In short, it’s the instructions
    that you provide to the LLM.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这引入了一个新术语，即**提示**。简而言之，它就是你给LLM的指令。
- en: When you run this code, you’ll see the streaming result. Streaming is important
    for user experience.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行这段代码时，你会看到流式结果。流式处理对用户体验很重要。
- en: '[PRE11]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Having defined that, let’s now make the API call to ollama (and llama2). an
    important step is to make sure that ollama’s running already on your local machine
    by running `ollama serve`.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 确定了这一点之后，现在让我们调用ollama（和llama2）的API。一个重要的步骤是确保ollama已经在你的本地机器上运行，通过运行`ollama
    serve`。
- en: '*Note: this might be slow on your machine, it’s certainly slow on mine. Be
    patient, young grasshopper.*'
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*注意：这在你的机器上可能很慢，在我的机器上肯定很慢。请耐心点，小草hopper。*'
- en: '[PRE13]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This gives us a complete RAG Application, from scratch, no providers, no services.
    You know all of the components in a Retrieval-Augmented Generation application.
    Visually, here’s what we’ve built.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这给了我们一个完整的RAG应用，从零开始，没有提供者，没有服务。你了解了检索增强生成应用中的所有组件。视觉上，这是我们构建的内容。
- en: '![](../Images/8a2da66e8db36d3cef1c6db81b0b6a9a.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8a2da66e8db36d3cef1c6db81b0b6a9a.png)'
- en: The LLM (if you’re lucky) will handle the user input that goes against the recommended
    document. We can see that below.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你幸运的话，LLM将处理与推荐文档不符的用户输入。我们可以在下面看到。
- en: '[PRE16]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Areas for improvement
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进领域
- en: If we go back to our diagream of the RAG application and think about what we’ve
    just built, we’ll see various opportunities for improvement. These opportunities
    are where tools like vector stores, embeddings, and prompt ‘engineering’ gets
    involved.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们回到RAG应用的图示，考虑一下我们刚刚构建的内容，我们会看到各种改进的机会。这些机会是工具如向量存储、嵌入和提示“工程”介入的地方。
- en: 'Here are ten potential areas where we could improve the current setup:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有十个潜在的改进领域：
- en: '**The number of documents** 👉 more documents might mean more recommendations.'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**文档的数量** 👉 更多文档可能意味着更多的推荐。'
- en: '**The depth/size of documents** 👉 higher quality content and longer documents
    with more information might be better.'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**文档的深度/大小** 👉 更高质量的内容和信息更多的长文档可能更好。'
- en: '**The number of documents we give to the LLM** 👉 Right now, we’re only giving
    the LLM one document. We could feed in several as ‘context’ and allow the model
    to provide a more personalized recommendation based on the user input.'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**我们提供给 LLM 的文档数量** 👉 目前，我们只给 LLM 一个文档。我们可以将几个文档作为“上下文”输入，并允许模型根据用户输入提供更个性化的推荐。'
- en: '**The parts of documents that we give to the LLM** 👉 If we have bigger or more
    thorough documents, we might just want to add in parts of those documents, parts
    of various documents, or some variation there of. In the lexicon, this is called
    chunking.'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**我们提供给 LLM 的文档部分** 👉 如果我们有较大或更全面的文档，我们可能只想添加这些文档的部分、各个文档的部分，或其某种变体。在词汇中，这被称为分块（chunking）。'
- en: '**Our document storage tool** 👉 We might store our documents in a different
    way or different database. In particular, if we have a lot of documents, we might
    explore storing them in a data lake or a vector store.'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**我们的文档存储工具** 👉 我们可能以不同的方式或不同的数据库存储文档。特别是，如果我们有大量文档，我们可能会探索将它们存储在数据湖或向量存储中。'
- en: '**The similarity measure** 👉 How we measure similarity is of consequence, we
    might need to trade off performance and thoroughness (e.g., looking at every individual
    document).'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**相似度度量** 👉 我们如何度量相似度是重要的，我们可能需要在性能和全面性之间进行权衡（例如，查看每一个单独的文档）。'
- en: '**The pre-processing of the documents & user input** 👉 We might perform some
    extra preprocessing or augmentation of the user input before we pass it into the
    similarity measure. For instance, we might use an embedding to convert that input
    to a vector.'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**文档及用户输入的预处理** 👉 我们可能在将用户输入传递到相似度度量之前，进行一些额外的预处理或增强。例如，我们可能会使用嵌入将输入转换为向量。'
- en: '**The similarity measure** 👉 We can change the similarity measure to fetch
    better or more relevant documents.'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**相似度度量** 👉 我们可以更改相似度度量，以获取更好或更相关的文档。'
- en: '**The model** 👉 We can change the final model that we use. We’re using llama2
    above, but we could just as easily use an Anthropic or Claude Model.'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型** 👉 我们可以更改我们使用的最终模型。我们上面使用的是 llama2，但我们也可以轻松使用 Anthropic 或 Claude 模型。'
- en: '**The prompt** 👉 We could use a different prompt into the LLM/Model and tune
    it according to the output we want to get the output we want.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**提示** 👉 我们可以使用不同的提示输入 LLM/模型，并根据我们希望得到的输出进行调整。'
- en: '**If you’re worried about harmful or toxic output** 👉 We could implement a
    “circuit breaker” of sorts that runs the user input to see if there’s toxic, harmful,
    or dangerous discussions. For instance, in a healthcare context you could see
    if the information contained unsafe languages and respond accordingly — outside
    of the typical flow.'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**如果你担心有害或有毒的输出** 👉 我们可以实现一种“断路器”，运行用户输入以检查是否存在有毒、有害或危险的讨论。例如，在医疗保健背景中，你可以检查信息是否包含不安全的语言，并相应地做出回应——超出典型流程之外。'
- en: The scope for improvements isn’t limited to these points; the possibilities
    are vast, and we’ll delve into them in future tutorials. Until then, don’t hesitate
    to [reach out on Twitter](https://twitter.com/bllchmbrs) if you have any questions.
    Happy RAGING :).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 改进的范围不仅限于这些点；可能性广泛，我们将在未来的教程中深入探讨。在此之前，如果你有任何问题，请随时 [在 Twitter 上联系我](https://twitter.com/bllchmbrs)。祝你
    RAGING 愉快 :)。
- en: References
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[检索增强生成（RAG）用于知识密集型 NLP 任务](https://arxiv.org/abs/2005.11401)'
- en: '[Jerry Liu on Twitter advocating for users to build RAG from scratch](https://twitter.com/jerryjliu0/status/1716122650836439478)'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Jerry Liu 在 Twitter 上倡导用户从零开始构建 RAG](https://twitter.com/jerryjliu0/status/1716122650836439478)'
- en: '[This post was originally posted on learnbybuilding.ai](https://learnbybuilding.ai/tutorials/rag-from-scratch).
    **I’m running a course on How to Build Generative AI Products for Product Managers
    in the coming months,** [**sign up here**](https://maven.com/forms/90684f)**.**'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[这篇文章最初发布在 learnbybuilding.ai](https://learnbybuilding.ai/tutorials/rag-from-scratch)。**我将在未来几个月举办一个关于如何为产品经理构建生成式
    AI 产品的课程，** [**点击这里报名**](https://maven.com/forms/90684f)**。**'
