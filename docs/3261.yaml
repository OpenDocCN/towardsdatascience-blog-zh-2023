- en: A beginner’s guide to building a Retrieval Augmented Generation (RAG) application
    from scratch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/a-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d?source=collection_archive---------1-----------------------#2023-11-02](https://towardsdatascience.com/a-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d?source=collection_archive---------1-----------------------#2023-11-02)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learn critical knowledge for building AI apps, in plain english
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)[![Bill
    Chambers](../Images/d04ba934f4cbfdf5fcb42f0b65ac0352.png)](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)
    [Bill Chambers](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9627ead2f75f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&user=Bill+Chambers&userId=9627ead2f75f&source=post_page-9627ead2f75f----e52921953a5d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)
    ·10 min read·Nov 2, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe52921953a5d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&user=Bill+Chambers&userId=9627ead2f75f&source=-----e52921953a5d---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe52921953a5d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&source=-----e52921953a5d---------------------bookmark_footer-----------)![](../Images/937f7d4c1dde1fb4928a29cd60f74320.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: A beginner’s guide to building a Retrieval Augmented Generation (RAG) application
    from scratch
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Retrieval Augmented Generation, or RAG, is all the rage these days because it
    introduces some serious capabilities to large language models like OpenAI’s GPT-4
    — and that’s the ability to use and leverage their own data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: This post will teach you the fundamental intuition behind RAG while providing
    a simple tutorial to help you get started.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: The problem with learning in a fast moving space
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There’s so much noise in the AI space and in particular about RAG. Vendors are
    trying to overcomplicate it. They’re trying to inject their tools, their ecosystems,
    their vision.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: It’s making RAG way more complicated than it needs to be. This tutorial is designed
    to help beginners learn how to build RAG applications from scratch. No fluff,
    no (ok, minimal) jargon, no libraries, just a simple step by step RAG application.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '[Jerry from LlamaIndex advocates for building things from scratch to really
    understand the pieces](https://twitter.com/jerryjliu0/status/1716122650836439478).
    Once you do, using a library like LlamaIndex makes more sense.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Build from scratch to learn, then build with libraries to scale.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get started!
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: 'Introducing our concept: Retrieval Augmented Generation'
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You may or may not have heard of Retrieval Augmented Generation or RAG.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the definition from [the blog post introducing the concept from Facebook](https://ai.meta.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/):'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '*Building a model that researches and contextualizes is more challenging, but
    it’s essential for future advancements. We recently made substantial progress
    in this realm with our Retrieval Augmented Generation (RAG) architecture, an end-to-end
    differentiable model that combines an information retrieval component (Facebook
    AI’s dense-passage retrieval system) with a seq2seq generator (our Bidirectional
    and Auto-Regressive Transformers [BART] model). RAG can be fine-tuned on knowledge-intensive
    downstream tasks to achieve state-of-the-art results compared with even the largest
    pretrained seq2seq language models. And unlike these pretrained models, RAG’s
    internal knowledge can be easily altered or even supplemented on the fly, enabling
    researchers and engineers to control what RAG knows and doesn’t know without wasting
    time or compute power retraining the entire model.*'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Wow, that’s a mouthful.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: 'In simplifying the technique for beginners, we can state that the essence of
    RAG involves adding your own data (via a retrieval tool) to the prompt that you
    pass into a large language model. As a result, you get an output. That gives you
    several benefits:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: You can include facts in the prompt to help the LLM avoid hallucinations
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can (manually) refer to sources of truth when responding to a user query,
    helping to double check any potential issues.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can leverage data that the LLM might not have been trained on.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The High Level Components of our RAG System
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: a collection of documents (formally called a corpus)
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An input from the user
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a similarity measure between the collection of documents and the user input
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Yes, it’s that simple.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: To start learning and understanding RAG based systems, you don’t need a vector
    store, you don’t even *need* an LLM (at least to learn and understand conceptually).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: While it is often portrayed as complicated, it doesn’t have to be.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: The ordered steps of a querying RAG system
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ll perform the following steps in sequence.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: Receive a user input
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform our similarity measure
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Post-process the user input and the fetched document(s).
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The post-processing is done with an LLM.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: A note from the paper itself
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[The actual RAG paper](https://arxiv.org/abs/2005.11401) is obviously *the*
    resource. The problem is that it assumes a LOT of context. It’s more complicated
    than we need it to be.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: For instance, here’s the overview of the RAG system as proposed in the paper.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2d54f5c723763e7d78ae93c9f91bcc2c.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
- en: '[An overview of RAG from the RAG paper](https://arxiv.org/abs/2005.11401) by
    Lewis, et al'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: That’s dense.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: It’s great for researchers but for the rest of us, it’s going to be a lot easier
    to learn step by step by building the system ourselves.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Working through an example — the simplest RAG system
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s get back to building RAG from scratch, step by step. Here’s the simplified
    steps that we’ll be working through. While this isn’t technically “RAG” it’s a
    good simplified model to learn with and allow us to progress to more complicated
    variations.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c3aaa700afa3ff0bf86304cef50bac2b.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
- en: Getting a collection of documents
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Below you can see that we’ve got a simple corpus of ‘documents’ (please be generous
    😉).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Defining and performing the similarity measure
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now we need a way of measuring the similarity between the **user input** we’re
    going to receive and the **collection** of documents that we organized. Arguably
    the simplest similarity measure is [jaccard similarity](https://en.wikipedia.org/wiki/Jaccard_index).
    I’ve written about that in the past (see [this post](https://billchambers.me/posts/tf-idf-explained-in-python)
    but the short answer is that the **jaccard similarity** is the intersection divided
    by the union of the “sets” of words.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: This allows us to compare our user input with the source documents.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: 'Side note: preprocessing'
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A challenge is that if we have a plain string like `"Take a leisurely walk in
    the park and enjoy the fresh air.",`, we're going to have to pre-process that
    into a set, so that we can perform these comparisons. We're going to do this in
    the simplest way possible, lower case and split by `" "`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now we need to define a function that takes in the exact query and our corpus
    and selects the ‘best’ document to return to the user.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now we can run it, we’ll start with a simple prompt.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: And a simple user input…
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now we can return our response.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Congratulations, you’ve built a basic RAG application.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: I got 99 problems and bad similarity is one
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now we’ve opted for a simple similarity measure for learning. But this is going
    to be problematic because it’s so simple. It has no notion of **semantics**. It’s
    just looks at what words are in both documents. That means that if we provide
    a negative example, we’re going to get the same “result” because that’s the closest
    document.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们选择了一个简单的相似性度量进行学习。但这会有问题，因为它过于简单。它没有**语义**的概念。它只是查看两个文档中包含了哪些词。这意味着如果我们提供一个负面例子，我们将得到相同的“结果”，因为这是最接近的文档。
- en: '![](../Images/f6905b126532fe949de9729a803c563f.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f6905b126532fe949de9729a803c563f.png)'
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This is a topic that’s going to come up a lot with “RAG”, but for now, rest
    assured that we’ll address this problem later.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个在“RAG”中经常出现的话题，但目前请放心，我们会在后面解决这个问题。
- en: At this point, we have not done any post-processing of the “document” to which
    we are responding. So far, we’ve implemented only the “retrieval” part of “Retrieval-Augmented
    Generation”. The next step is to augment generation by incorporating a large language
    model (LLM).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 目前为止，我们还没有对响应的“文档”进行任何后处理。到现在为止，我们只实现了“检索增强生成”的“检索”部分。下一步是通过引入大型语言模型（LLM）来增强生成。
- en: Adding in a LLM
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加LLM
- en: To do this, we’re going to use [ollama](https://ollama.ai/) to get up and running
    with an open source LLM on our local machine. We could just as easily use OpenAI’s
    gpt-4 or Anthropic’s Claude but for now, we’ll start with the open source llama2
    from [Meta AI](https://ai.meta.com/llama/).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们将使用[ollama](https://ollama.ai/)来启动并运行本地机器上的开源LLM。我们同样可以使用OpenAI的gpt-4或Anthropic的Claude，但现在我们将从[Meta
    AI](https://ai.meta.com/llama/)的开源llama2开始。
- en: '[ollama installation instructions are here](https://ollama.ai/)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ollama安装说明在这里](https://ollama.ai/)'
- en: This post is going to assume some basic knowledge of large language models,
    so let’s get right to querying this model.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 本文假设你对大型语言模型有一些基本了解，所以我们直接开始查询这个模型吧。
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: First we’re going to define the inputs. To work with this model, we’re going
    to take
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将定义输入。为了使用这个模型，我们将采取
- en: user input,
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户输入，
- en: fetch the most similar document (as measured by our similarity measure),
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取最相似的文档（按我们的相似性度量来衡量），
- en: pass that into a prompt to the language model,
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将其传递给语言模型的提示，
- en: '*then* return the result to the user'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*然后* 将结果返回给用户'
- en: That introduces a new term, the **prompt**. In short, it’s the instructions
    that you provide to the LLM.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这引入了一个新术语，即**提示**。简而言之，它就是你给LLM的指令。
- en: When you run this code, you’ll see the streaming result. Streaming is important
    for user experience.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行这段代码时，你会看到流式结果。流式处理对用户体验很重要。
- en: '[PRE11]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Having defined that, let’s now make the API call to ollama (and llama2). an
    important step is to make sure that ollama’s running already on your local machine
    by running `ollama serve`.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 确定了这一点之后，现在让我们调用ollama（和llama2）的API。一个重要的步骤是确保ollama已经在你的本地机器上运行，通过运行`ollama
    serve`。
- en: '*Note: this might be slow on your machine, it’s certainly slow on mine. Be
    patient, young grasshopper.*'
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*注意：这在你的机器上可能很慢，在我的机器上肯定很慢。请耐心点，小草hopper。*'
- en: '[PRE13]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This gives us a complete RAG Application, from scratch, no providers, no services.
    You know all of the components in a Retrieval-Augmented Generation application.
    Visually, here’s what we’ve built.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这给了我们一个完整的RAG应用，从零开始，没有提供者，没有服务。你了解了检索增强生成应用中的所有组件。视觉上，这是我们构建的内容。
- en: '![](../Images/8a2da66e8db36d3cef1c6db81b0b6a9a.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8a2da66e8db36d3cef1c6db81b0b6a9a.png)'
- en: The LLM (if you’re lucky) will handle the user input that goes against the recommended
    document. We can see that below.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你幸运的话，LLM将处理与推荐文档不符的用户输入。我们可以在下面看到。
- en: '[PRE16]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Areas for improvement
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进领域
- en: If we go back to our diagream of the RAG application and think about what we’ve
    just built, we’ll see various opportunities for improvement. These opportunities
    are where tools like vector stores, embeddings, and prompt ‘engineering’ gets
    involved.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们回到RAG应用的图示，考虑一下我们刚刚构建的内容，我们会看到各种改进的机会。这些机会是工具如向量存储、嵌入和提示“工程”介入的地方。
- en: 'Here are ten potential areas where we could improve the current setup:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有十个潜在的改进领域：
- en: '**The number of documents** 👉 more documents might mean more recommendations.'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**文档的数量** 👉 更多文档可能意味着更多的推荐。'
- en: '**The depth/size of documents** 👉 higher quality content and longer documents
    with more information might be better.'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**文档的深度/大小** 👉 更高质量的内容和信息更多的长文档可能更好。'
- en: '**The number of documents we give to the LLM** 👉 Right now, we’re only giving
    the LLM one document. We could feed in several as ‘context’ and allow the model
    to provide a more personalized recommendation based on the user input.'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The parts of documents that we give to the LLM** 👉 If we have bigger or more
    thorough documents, we might just want to add in parts of those documents, parts
    of various documents, or some variation there of. In the lexicon, this is called
    chunking.'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Our document storage tool** 👉 We might store our documents in a different
    way or different database. In particular, if we have a lot of documents, we might
    explore storing them in a data lake or a vector store.'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The similarity measure** 👉 How we measure similarity is of consequence, we
    might need to trade off performance and thoroughness (e.g., looking at every individual
    document).'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The pre-processing of the documents & user input** 👉 We might perform some
    extra preprocessing or augmentation of the user input before we pass it into the
    similarity measure. For instance, we might use an embedding to convert that input
    to a vector.'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The similarity measure** 👉 We can change the similarity measure to fetch
    better or more relevant documents.'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The model** 👉 We can change the final model that we use. We’re using llama2
    above, but we could just as easily use an Anthropic or Claude Model.'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The prompt** 👉 We could use a different prompt into the LLM/Model and tune
    it according to the output we want to get the output we want.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**If you’re worried about harmful or toxic output** 👉 We could implement a
    “circuit breaker” of sorts that runs the user input to see if there’s toxic, harmful,
    or dangerous discussions. For instance, in a healthcare context you could see
    if the information contained unsafe languages and respond accordingly — outside
    of the typical flow.'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The scope for improvements isn’t limited to these points; the possibilities
    are vast, and we’ll delve into them in future tutorials. Until then, don’t hesitate
    to [reach out on Twitter](https://twitter.com/bllchmbrs) if you have any questions.
    Happy RAGING :).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Jerry Liu on Twitter advocating for users to build RAG from scratch](https://twitter.com/jerryjliu0/status/1716122650836439478)'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[This post was originally posted on learnbybuilding.ai](https://learnbybuilding.ai/tutorials/rag-from-scratch).
    **I’m running a course on How to Build Generative AI Products for Product Managers
    in the coming months,** [**sign up here**](https://maven.com/forms/90684f)**.**'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
