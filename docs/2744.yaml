- en: A Beginnerâ€™s Guide to LLM Fine-Tuning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://towardsdatascience.com/a-beginners-guide-to-llm-fine-tuning-4bae7d4da672?source=collection_archive---------1-----------------------#2023-08-30](https://towardsdatascience.com/a-beginners-guide-to-llm-fine-tuning-4bae7d4da672?source=collection_archive---------1-----------------------#2023-08-30)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How to fine-tune Llama and other LLMs with one tool
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@mlabonne?source=post_page-----4bae7d4da672--------------------------------)[![Maxime
    Labonne](../Images/a7efdd305e3cc77d5509bbb1076d57d8.png)](https://medium.com/@mlabonne?source=post_page-----4bae7d4da672--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4bae7d4da672--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4bae7d4da672--------------------------------)
    [Maxime Labonne](https://medium.com/@mlabonne?source=post_page-----4bae7d4da672--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Â·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdc89da634938&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-llm-fine-tuning-4bae7d4da672&user=Maxime+Labonne&userId=dc89da634938&source=post_page-dc89da634938----4bae7d4da672---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4bae7d4da672--------------------------------)
    Â·8 min readÂ·Aug 30, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4bae7d4da672&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-llm-fine-tuning-4bae7d4da672&user=Maxime+Labonne&userId=dc89da634938&source=-----4bae7d4da672---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4bae7d4da672&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-llm-fine-tuning-4bae7d4da672&source=-----4bae7d4da672---------------------bookmark_footer-----------)![](../Images/3cd56f68c14e07ab9ae3eb624bd064ed.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: The growing interest in Large Language Models (LLMs) has led to a surge in **tools
    and wrappers designed to streamline their training process**.
  prefs: []
  type: TYPE_NORMAL
- en: Popular options include [FastChat](https://github.com/lm-sys/FastChat) from
    LMSYS (used to train [Vicuna](https://huggingface.co/lmsys/vicuna-13b-v1.5)) and
    Hugging Faceâ€™s [transformers](https://github.com/huggingface/transformers)/[trl](https://github.com/huggingface/trl)
    libraries (used in [my previous article](/fine-tune-your-own-llama-2-model-in-a-colab-notebook-df9823a04a32)).
    In addition, each big LLM project, like [WizardLM](https://github.com/nlpxucan/WizardLM/tree/main),
    tends to have its own training script, inspired by the original [Alpaca](https://github.com/tatsu-lab/stanford_alpaca)
    implementation.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we will use [**Axolotl**](https://github.com/OpenAccess-AI-Collective/axolotl),
    a tool created by the OpenAccess AI Collective. We will use it to fine-tune a
    [**Code Llama 7b**](https://github.com/OpenAccess-AI-Collective/axolotl/blob/main/examples/llama-2/qlora.yml)
    model on an evol-instruct dataset comprised of 1,000 samples of Python code.
  prefs: []
  type: TYPE_NORMAL
- en: ðŸ¤” Why Axolotl?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The main appeal of Axolotl is that it provides a one-stop solution, which includes
    numerous features, model architectures, and an active community. Hereâ€™s a quick
    list of my favorite things about it:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Configuration**: All parameters used to train an LLM are neatly stored in
    a yaml config file. This makes it convenient for sharing and reproducing models.
    You can see an example for Llama 2 [here](https://github.com/OpenAccess-AI-Collective/axolotl/tree/main/examples/llama-2).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dataset Flexibility**: Axolotl allows the specification of multiple datasets
    with varied prompt formats such asâ€¦'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
