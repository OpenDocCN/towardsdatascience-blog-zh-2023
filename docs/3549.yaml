- en: Combine Multiple LoRA Adapters for Llama 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/combine-multiple-lora-adapters-for-llama-2-ea0bef9025cf?source=collection_archive---------4-----------------------#2023-11-30](https://towardsdatascience.com/combine-multiple-lora-adapters-for-llama-2-ea0bef9025cf?source=collection_archive---------4-----------------------#2023-11-30)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Add skills to your LLM without fine-tuning new adapters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@bnjmn_marie?source=post_page-----ea0bef9025cf--------------------------------)[![Benjamin
    Marie](../Images/3ea1ad230cb1e67610418a8e36a5e5dd.png)](https://medium.com/@bnjmn_marie?source=post_page-----ea0bef9025cf--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ea0bef9025cf--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ea0bef9025cf--------------------------------)
    [Benjamin Marie](https://medium.com/@bnjmn_marie?source=post_page-----ea0bef9025cf--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fad2a414578b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcombine-multiple-lora-adapters-for-llama-2-ea0bef9025cf&user=Benjamin+Marie&userId=ad2a414578b3&source=post_page-ad2a414578b3----ea0bef9025cf---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ea0bef9025cf--------------------------------)
    ·12 min read·Nov 30, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fea0bef9025cf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcombine-multiple-lora-adapters-for-llama-2-ea0bef9025cf&user=Benjamin+Marie&userId=ad2a414578b3&source=-----ea0bef9025cf---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fea0bef9025cf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcombine-multiple-lora-adapters-for-llama-2-ea0bef9025cf&source=-----ea0bef9025cf---------------------bookmark_footer-----------)![](../Images/6c4a40091827bce0f2a546522f563d4a.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image by the author — Made with an image from [Pixabay](https://pixabay.com/vectors/llama-alpaca-animal-mammal-zoo-297668/)
  prefs: []
  type: TYPE_NORMAL
- en: Fully fine-tuning a pre-trained large language model (LLM) for different tasks
    is very costly. Instead, we can freeze the parameters of the LLM while only fine-tuning
    a few million trainable parameters added through a LoRA adapter.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, we only need to fine-tune an adapter to get the model to perform
    a target task. For instance, if we want to turn a pre-trained LLM into a translation
    model, we would fine-tune an adapter for translation. We can fine-tune one adapter
    for each ask that we want the LLM to perform.
  prefs: []
  type: TYPE_NORMAL
- en: '*But can we combine several adapters to get one single multi-task adapter?*'
  prefs: []
  type: TYPE_NORMAL
- en: For instance, if we have one adapter for translation and one adapter for summarization,
    can we combine both of them so that the LLM can do translation and summarization?
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I show how to combine multiple LoRA adapters into a single
    multi-task adapter. We will see that it is very simple and that the resulting
    adapter can be as good as the adapters used for the combination.
  prefs: []
  type: TYPE_NORMAL
- en: Using Llama 2 7B, we will see how to combine an adapter fine-tuned for translation
    with another adapter fine-tuned for chat. With the resulting adapter, we will
    be able to make a…
  prefs: []
  type: TYPE_NORMAL
