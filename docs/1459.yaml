- en: 'Multi-Task Machine Learning: Solving Multiple Problems Simultaneously'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/multi-task-learning-4531eb32d77b?source=collection_archive---------10-----------------------#2023-04-27](https://towardsdatascience.com/multi-task-learning-4531eb32d77b?source=collection_archive---------10-----------------------#2023-04-27)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Some supervised, some unsupervised, some self-supervised, in NLP and computer
    vision
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://jagota-arun.medium.com/?source=post_page-----4531eb32d77b--------------------------------)[![Arun
    Jagota](../Images/3c3eb142f671b5fb933c2826d8ed78d9.png)](https://jagota-arun.medium.com/?source=post_page-----4531eb32d77b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4531eb32d77b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4531eb32d77b--------------------------------)
    [Arun Jagota](https://jagota-arun.medium.com/?source=post_page-----4531eb32d77b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fef9ed921edad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-task-learning-4531eb32d77b&user=Arun+Jagota&userId=ef9ed921edad&source=post_page-ef9ed921edad----4531eb32d77b---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4531eb32d77b--------------------------------)
    ·11 min read·Apr 27, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4531eb32d77b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-task-learning-4531eb32d77b&user=Arun+Jagota&userId=ef9ed921edad&source=-----4531eb32d77b---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4531eb32d77b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-task-learning-4531eb32d77b&source=-----4531eb32d77b---------------------bookmark_footer-----------)![](../Images/f245371498b59c216924e720580c26fd.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Image by [Gerd Altmann](https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3685928)
    From [Pixabay](https://pixabay.com/)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '*Single-task learning* is the process of learning to predict a single outcome
    (binary, multi-class, or continuous) from a labeled data set.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: By contrast, *multi-task learning* is the process of jointly learning to predict
    multiple outcomes on inputs of the same modality. Such as images or text.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: The obvious question to ask is, why learn *jointly*? Why not independently learn
    single-task models to predict the various outcomes?
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: The answer is that joint learning can learn features that generalize better
    across tasks. Those that form good predictors for multiple tasks are favored over
    those that don’t. The learned features may even generalize to new prediction tasks
    in the same domain.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是，联合学习可以学习那些在任务之间具有更好泛化能力的特征。那些能成为多个任务的良好预测器的特征会比那些不能的特征更受青睐。所学到的特征甚至可能对同一领域的新预测任务具有泛化能力。
- en: '**Adding Unsupervised Learning To The Mix**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**将无监督学习加入到混合中**'
- en: To this point, we have supposed that all the chosen tasks in the multi-task
    setting are supervised in nature. Let’s relax this to allow some of the tasks
    to be unsupervised.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们假设在多任务设置中选择的所有任务都是有监督的。让我们放宽这一假设，允许一些任务是无监督的。
- en: Why? Because we may have a lot more data to train on. Some labeled for the various
    outcomes, and a lot unlabeled. Adding unsupervised tasks to the joint…
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么？因为我们可能有更多的数据来进行训练。其中一些数据是标注的，针对不同的结果，还有很多是未标注的。将无监督任务加入到联合学习中……
