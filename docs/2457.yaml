- en: How I Built A Cascading Data Pipeline Based on AWS (Part 1)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我如何构建基于 AWS 的级联数据管道（第 1 部分）
- en: 原文：[https://towardsdatascience.com/how-i-built-a-cascading-data-pipeline-based-on-aws-997b212a84d2?source=collection_archive---------7-----------------------#2023-07-31](https://towardsdatascience.com/how-i-built-a-cascading-data-pipeline-based-on-aws-997b212a84d2?source=collection_archive---------7-----------------------#2023-07-31)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-i-built-a-cascading-data-pipeline-based-on-aws-997b212a84d2?source=collection_archive---------7-----------------------#2023-07-31](https://towardsdatascience.com/how-i-built-a-cascading-data-pipeline-based-on-aws-997b212a84d2?source=collection_archive---------7-----------------------#2023-07-31)
- en: Automatic, scalable, and powerful
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动化、可扩展且强大
- en: '[](https://anzhemeng.medium.com/?source=post_page-----997b212a84d2--------------------------------)[![Memphis
    Meng](../Images/5a2b214eb5d5ab884b18224c471662c0.png)](https://anzhemeng.medium.com/?source=post_page-----997b212a84d2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----997b212a84d2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----997b212a84d2--------------------------------)
    [Memphis Meng](https://anzhemeng.medium.com/?source=post_page-----997b212a84d2--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://anzhemeng.medium.com/?source=post_page-----997b212a84d2--------------------------------)[![Memphis
    Meng](../Images/5a2b214eb5d5ab884b18224c471662c0.png)](https://anzhemeng.medium.com/?source=post_page-----997b212a84d2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----997b212a84d2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----997b212a84d2--------------------------------)
    [Memphis Meng](https://anzhemeng.medium.com/?source=post_page-----997b212a84d2--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F85370dce2b14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-built-a-cascading-data-pipeline-based-on-aws-997b212a84d2&user=Memphis+Meng&userId=85370dce2b14&source=post_page-85370dce2b14----997b212a84d2---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----997b212a84d2--------------------------------)
    ·14 min read·Jul 31, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F997b212a84d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-built-a-cascading-data-pipeline-based-on-aws-997b212a84d2&user=Memphis+Meng&userId=85370dce2b14&source=-----997b212a84d2---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F85370dce2b14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-built-a-cascading-data-pipeline-based-on-aws-997b212a84d2&user=Memphis+Meng&userId=85370dce2b14&source=post_page-85370dce2b14----997b212a84d2---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----997b212a84d2--------------------------------)
    ·14 min read·Jul 31, 2023 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F997b212a84d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-built-a-cascading-data-pipeline-based-on-aws-997b212a84d2&user=Memphis+Meng&userId=85370dce2b14&source=-----997b212a84d2---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F997b212a84d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-built-a-cascading-data-pipeline-based-on-aws-997b212a84d2&source=-----997b212a84d2---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F997b212a84d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-built-a-cascading-data-pipeline-based-on-aws-997b212a84d2&source=-----997b212a84d2---------------------bookmark_footer-----------)'
- en: Today I’m going to share some experience of building a data engineering project
    that I always take pride in. You are going to learn the reasons behind why I used
    the tools and AWS components, and how I designed the architecture.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 今天我将分享一些关于构建我一直引以为傲的数据工程项目的经验。你将了解我使用这些工具和 AWS 组件的原因，以及我如何设计架构。
- en: '![](../Images/4f95b8b2918bb62a2337706df55ff6e3.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f95b8b2918bb62a2337706df55ff6e3.png)'
- en: Image by Author
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: '**Disclaimer**: The content of this text is inspired by my experience with
    an unnamed entity. However, certain critical commercial interests and details
    have intentionally been replaced with fictional data/codes or omitted, for the
    purpose of maintaining confidentiality and privacy. Therefore, the full and accurate
    extent of the actual commercial interests involved is reserved.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**免责声明**：本文内容源于我与一个未透露名称的实体的经验。然而，为了维护保密性和隐私，某些关键的商业利益和细节被故意用虚构的数据/代码替代或省略。因此，实际涉及的商业利益的完整和准确范围被保留。'
- en: Prerequisites
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前提条件
- en: Knowledge of Python
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Python 知识
- en: Understanding of AWS components, such as DynamoDB, Lambda serverless, SQS and
    CloudWatch
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 理解AWS组件，例如DynamoDB、Lambda无服务器、SQS和CloudWatch
- en: Comfortable coding experience with [YAML](https://en.wikipedia.org/wiki/YAML)
    & [SAM CLI](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/install-sam-cli.html)
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 舒适的编码体验，使用[YAML](https://en.wikipedia.org/wiki/YAML)和[SAM CLI](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/install-sam-cli.html)
- en: Background
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 背景
- en: Let’s say you are a data engineer and you need to constantly update the data
    in the warehouse. For example, you are responsible to sync up with the sales records
    of [Dunder Mifflin Paper Co.](https://dundermifflinpaper.com) on a regular basis.
    (I understand this is not a realistic scenario but have fun :) !) The data is
    sent to you via a vendor’s API and…
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你是数据工程师，需要不断更新数据仓库。例如，你负责定期与[Dunder Mifflin Paper Co.](https://dundermifflinpaper.com)的销售记录同步。（我明白这不是一个现实的场景，但还是要玩得开心
    :)！）数据通过供应商的API发送给你，…
