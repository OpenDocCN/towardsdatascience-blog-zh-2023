- en: 'Unveiling the Power of Bias Adjustment: Enhancing Predictive Precision in Imbalanced
    Datasets'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/unveiling-the-power-of-bias-adjustment-enhancing-predictive-precision-in-imbalanced-datasets-ecad1836fc58?source=collection_archive---------2-----------------------#2023-08-13](https://towardsdatascience.com/unveiling-the-power-of-bias-adjustment-enhancing-predictive-precision-in-imbalanced-datasets-ecad1836fc58?source=collection_archive---------2-----------------------#2023-08-13)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://sirano1004.medium.com/?source=post_page-----ecad1836fc58--------------------------------)[![Hyung
    Gyu Rho](../Images/ce0248c75a21e0871d8e0b9fdf3c55b6.png)](https://sirano1004.medium.com/?source=post_page-----ecad1836fc58--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ecad1836fc58--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ecad1836fc58--------------------------------)
    [Hyung Gyu Rho](https://sirano1004.medium.com/?source=post_page-----ecad1836fc58--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F89f7d2237f82&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funveiling-the-power-of-bias-adjustment-enhancing-predictive-precision-in-imbalanced-datasets-ecad1836fc58&user=Hyung+Gyu+Rho&userId=89f7d2237f82&source=post_page-89f7d2237f82----ecad1836fc58---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ecad1836fc58--------------------------------)
    ·11 min read·Aug 13, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fecad1836fc58&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funveiling-the-power-of-bias-adjustment-enhancing-predictive-precision-in-imbalanced-datasets-ecad1836fc58&user=Hyung+Gyu+Rho&userId=89f7d2237f82&source=-----ecad1836fc58---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fecad1836fc58&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funveiling-the-power-of-bias-adjustment-enhancing-predictive-precision-in-imbalanced-datasets-ecad1836fc58&source=-----ecad1836fc58---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: Addressing class imbalance is crucial for accurate predictions in data science.
    This article introduces Bias Adjustment to enhance model accuracy amidst class
    imbalance. Explore how Bias Adjustment optimizes predictions and overcomes this
    challenge.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Introduction**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the realm of data science, effectively managing imbalanced datasets is crucial
    for precise predictions. Imbalanced datasets, characterized by significant class
    disparities, can lead to biased models favoring the majority class and delivering
    subpar performance for the minority class, especially in critical contexts like
    fraud detection and disease diagnosis.
  prefs: []
  type: TYPE_NORMAL
- en: This article introduces a pragmatic remedy known as Bias Adjustment. By fine-tuning
    the bias term within the model, it counteracts class imbalance, bolstering the
    model’s aptitude for accurate predictions across both majority and minority classes.
    The article outlines algorithms catering to binary and multi-class classification,
    followed by an exploration of their underlying principles. Notably, the Algorithm
    Explanation and Underlying Principles section rigorously establishes a theoretical
    link between my algorithm, oversampling, and adjusting class weights, enhancing
    the reader’s understanding.
  prefs: []
  type: TYPE_NORMAL
- en: To substantiate the efficacy and rationale, a simulation study scrutinizes the
    relationship between Bias Adjustment and oversampling. Further, a practical application
    is employed to illustrate the implementation and tangible benefits of Bias Adjustment
    in credit card fraud detection.
  prefs: []
  type: TYPE_NORMAL
- en: Bias Adjustment offers a direct and impactful avenue for refining predictive
    modeling results in the face of class imbalance. This article provides a comprehensive
    grasp of the mechanism, principles, and real-world implications of Bias Adjustment,
    making it an invaluable tool for data scientists seeking to enhance model performance
    amidst imbalanced datasets.
  prefs: []
  type: TYPE_NORMAL
- en: '**Algorithm**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Bias Adjustment algorithm introduces a methodology to address class imbalance
    in binary and multi-class classification tasks. By recalibrating the bias term
    at each epoch, the algorithm enhances the model’s capacity to handle imbalanced
    datasets effectively. Through adjusting the bias term, the algorithm sensitizes
    the model to minority class instances, thereby improving classification accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Model f(x) and its Role in Predictions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At the core of our bias adjustment algorithm is the concept of *f*(*x*) — a
    crucial factor that guides our approach to dealing with class imbalance. *f*(*x*)
    serves as a link between input features *x* and the final predictions. In binary
    classification, it acts as a mapping that transforms inputs into real values,
    aligned with the sigmoid activation for probability interpretation. In multi-class
    classification, *f*(*x*) transforms into a set of functions, *f_k*​(*x*), where
    each class *k* has its own function, working in sync with the softmax activation.
    This distinction is instrumental in our bias adjustment algorithm, where we use
    *f*(*x*) to adjust bias term(s) and fine-tune sensitivity to class imbalance.
  prefs: []
  type: TYPE_NORMAL
- en: Brief Overview of the Algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The algorithm’s concept is straightforward: calculate the average of *f_k*​(*x*)
    for each class *k* and represent this average as *δk*​. By subtracting *δk*​ from
    *f_k*​(*x*), we ensure that the expected value of *f_k*​(*x*) − *δk*​ becomes
    0 for every class *k*. Consequently, the model predicts that each class is equally
    likely to occur. While this provides a concise glimpse into the algorithm’s rationale,
    it’s important to note that this approach is substantiated by theoretical and
    mathematical foundations, which will be explored further in subsequent sections
    of this article.'
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm for Binary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/e6293ba872ad3b540f9cd23197189f24.png)'
  prefs: []
  type: TYPE_IMG
- en: Created by Author
  prefs: []
  type: TYPE_NORMAL
- en: '**Utilization for Prediction**: For making predictions, apply the last calculated
    **δ** value from the algorithm. This **δ** value reflects cumulative adjustments
    made during training and serves as a basis for the final bias term in the sigmoid
    activation function during prediction.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a4a52dfc7014e6b66e345a243c864b93.png)'
  prefs: []
  type: TYPE_IMG
- en: Algorithm for Multi-Class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/1799b9446e951ce30b308f0a72cd0f2b.png)'
  prefs: []
  type: TYPE_IMG
- en: Created by Author
  prefs: []
  type: TYPE_NORMAL
- en: '**Utilization for Prediction**: The culmination of our algorithm’s training
    process yields a crucial element — the last calculated δk value. This δk value
    encapsulates the cumulative bias term adjustments that have been meticulously
    orchestrated during training. Its significance lies in its role as a foundational
    parameter for the final bias term in the softmax activation function during prediction.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4d4e7537ab3c519e04fbfa2dfd3eb397.png)'
  prefs: []
  type: TYPE_IMG
- en: Created by Author
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm Explanation and Underlying Principles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From oversampling to adjusting class weight, From adjusting class weight to
    the new algorithm
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In this section, we embark on an exploration of the Algorithm’s Explanation
    and Underlying Principles. Our aim is to elucidate the mechanics and rationale
    behind the algorithm’s operations, providing insights into its effectiveness in
    addressing class imbalance in classification tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Loss Function and Imbalance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We commence our journey by delving into the heart of the algorithm, the loss
    function. For our initial exposition, we will examine the loss function without
    directly addressing the issue of class imbalance. Let us consider a binary classification
    problem, where Class 1 comprises 90% of the observations and Class 0 constitutes
    the remaining 10%. Denoting the set of observations from Class 1 as C1 and from
    Class 0 as C0, we take this as our starting point.
  prefs: []
  type: TYPE_NORMAL
- en: 'The loss function, in the absence of addressing class imbalance, takes the
    form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b02fec09ab7ad330f7e894557d973f43.png)'
  prefs: []
  type: TYPE_IMG
- en: Created by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'In the pursuit of model estimation, we endeavor to minimize this loss function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/62429da598d38fdc82aa3a41f804fed5.png)'
  prefs: []
  type: TYPE_IMG
- en: Created by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'Mitigating Imbalance: Oversampling and Adjusting Class Weights'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: However, the crux of our endeavor lies in addressing the class imbalance predicament.
    To surmount this challenge, we venture into employing oversampling techniques.
    While various oversampling methods exist — encompassing simple oversampling, random
    oversampling, SMOTE, and others — our focus, for presentational clarity, narrows
    onto simple oversampling, with a glimpse into random oversampling.
  prefs: []
  type: TYPE_NORMAL
- en: '**Simple Oversampling:** A fundamental approach in our arsenal is simple oversampling,
    a technique where we duplicate instances of the minority class by a factor of
    eight to match the size of the majority class. In our illustrative example, where
    the minority class constitutes 10% and the majority class the remaining 90%, we
    duplicate the minority class observations eightfold, effectively equalizing class
    distribution. Denoting the set of duplicated observations as D0, this step transforms
    our loss function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4993b018b94f60b98c45f133295481f6.png)'
  prefs: []
  type: TYPE_IMG
- en: Created by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'This reveals a profound insight: the core principle of simple oversampling
    seamlessly corresponds to the notion of adjusting class weights. Duplicating the
    minority class eightfold effectively equates to augmenting the weight of the minority
    class to ninefold. Significantly, the technique of oversampling mirrors the mechanism
    of weight adjustment.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Random Oversampling:** A brief contemplation on random oversampling underscores
    a parallel observation. Random oversampling, akin to its simpler counterpart,
    serves as an equivalent to random adjustment of observation weights.'
  prefs: []
  type: TYPE_NORMAL
- en: '**From Adjusting Class Weights to Adjusting Bias**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A key revelation underscores the core of our approach: the essential equivalence
    between bias adjustment, oversampling, and weight adjustment. This insight emanates
    from'
  prefs: []
  type: TYPE_NORMAL
- en: “Prentice and Pyke (1979) … have shown that, when the model contains a constant
    (intercept) term for each category, these constant terms are the only coefficient
    affected by the unequal selection probability of the Y” Scott & Wild (1986) [2].
    Also, Manski and Lerman (1977) show the same result in softmax setting [1].
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Unveiling the Significance:** Translating this insight into the realm of
    machine learning, the constant (intercept) term is the bias term. This fundamental
    observation reveals that when we recalibrate class weights or observation weights,
    the resulting changes primarily manifest as adjustments to the bias term. Put
    simply, the bias term acts as the linchpin connecting our strategy to address
    class imbalance.'
  prefs: []
  type: TYPE_NORMAL
- en: A Unified Perspective
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This understanding provides a straightforward explanation of how our algorithm,
    oversampling, and weight adjustment are, in essence, interchangeable and substitutable.
    This unification simplifies our approach while maintaining its potency in mitigating
    class imbalance challenges.
  prefs: []
  type: TYPE_NORMAL
- en: 'Simulation Study: Verifying the Bias Term Influence through Oversampling'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To solidify our assertion that oversampling predominantly affects the bias term
    while keeping the model’s functional core intact, we delve into a targeted simulation
    study. Our aim is to demonstrate empirically how oversampling techniques solely
    impact the bias term, leaving the model’s essence unaltered.
  prefs: []
  type: TYPE_NORMAL
- en: The Simulation Setup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this illustrative purpose, we focus on a simplified scenario: logistic
    regression with a single feature. Our model is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/90ab09648be9ab0c4594e647a59c1e96.png)'
  prefs: []
  type: TYPE_IMG
- en: Created by Author
  prefs: []
  type: TYPE_NORMAL
- en: where **1**(.) denotes the indicator function, x_i is drawn from a standard
    normal distribution, and *e_i*​ follows a logistic distribution. In this context,
    we set *f*(*x*)=*x*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running the Simulation:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using this setup, we meticulously examine the impact of oversampling techniques
    on the bias term while keeping the model’s core constant. We proceed with three
    oversampling methods: simple oversampling, SMOTE, and random sampling. Each method
    is meticulously applied, and the results are carefully recorded.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Python code snippet below outlines the simulation process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Results:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/cf669eaba6a84a8ca92c2ddd8dcffbff.png)'
  prefs: []
  type: TYPE_IMG
- en: Simulation Results; Created by Author
  prefs: []
  type: TYPE_NORMAL
- en: Key Observations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The outcomes of our simulation study succinctly validate our proposition. Despite
    the application of various oversampling methods, the core model function *f*(*x*)=*x*
    remains unaltered. The crucial insight lies in the remarkable consistency of the
    model component across all oversampling techniques. Instead, the bias term exhibits
    noticeable variations, corroborating our claim that oversampling primarily impacts
    the bias term without affecting the underlying model structure.
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcing the Core Concept
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our simulation study undeniably underscores the fundamental equivalence between
    oversampling, weight adjustment, and bias term modification. By showcasing that
    oversampling exclusively alters the bias term, we fortify the principle that these
    strategies are interchangeable tools in the arsenal against class imbalance.
  prefs: []
  type: TYPE_NORMAL
- en: Applying the Bias Adjustment Algorithm to Credit Card Fraud Detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To demonstrate the effectiveness of our bias adjustment algorithm in addressing
    class imbalance, we employ a real-world dataset from a [Kaggle competition](https://www.kaggle.com/competitions/playground-series-s3e4/overview)
    focused on credit card fraud detection. In this scenario, the challenge lies in
    predicting whether a credit card transaction is fraudulent (labeled as 1) or not
    (labeled as 0), given the inherent rarity of fraud cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by loading essential packages and preparing the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We then define a simple deep learning model for binary classification and set
    up the optimizer, loss function, and evaluation metric. I follow the competition
    evaluation and choose AUC as evaluation metric. Furthermore, the model is intentionally
    simplified as the focus of this article is to show how to implement the bias adjustment
    algorithm, not to ace in prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Within the core of our bias adjustment algorithm lies the training and validation
    steps, where we meticulously address class imbalance. To elucidate this process,
    we delve into the intricate mechanisms that balance the model’s predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Training Step with Accumulating Delta Values
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the training step, we embark on the journey of enhancing model sensitivity
    to class imbalance. Here, we calculate and accumulate the sum of model outputs
    for two distinct clusters: `delta0` and `delta1`. These clusters hold significant
    importance, representing the predicted values associated with classes 0 and 1,
    respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Validation Step: Imbalance Resolution with Delta'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The normalized delta values, derived from the training process, take center
    stage in the validation step. Armed with these refined indicators of class imbalance,
    we align the model’s predictions more accurately with the true distribution of
    classes. The `test_step` function integrates these delta values to adaptively
    adjust predictions, ultimately leading to a refined evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Utilizing Delta Values for Imbalance Correction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As training progresses, we collect valuable insights encapsulated within the
    `delta0` and `delta1` cluster sums. These cumulative values emerge as indicators
    of the bias inherent in our model's predictions. At the conclusion of each epoch,
    we execute a vital transformation. By dividing the accumulated cluster sums by
    the corresponding number of observations from each class, we derive normalized
    delta values. This normalization acts as a crucial equalizer, encapsulating the
    essence of our bias adjustment approach.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The Outcome
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In our application to credit card fraud detection, the enhanced efficacy of
    our algorithm shines through. With bias adjustment seamlessly integrated into
    the training process, we achieve an impressive AUC score of 0.77\. This starkly
    contrasts with the AUC score of 0.71 attained without the guiding hand of bias
    adjustment. The profound improvement in predictive performance stands as a testament
    to the algorithm’s ability to navigate the intricacies of class imbalance, charting
    a course towards more accurate and reliable predictions.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] Manski, C. F., & Lerman, S. R. (1977). [The estimation of choice probabilities
    from choice based samples](https://www.jstor.org/stable/1914121). *Econometrica:
    Journal of the Econometric Society*, 1977–1988.'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] Scott, A. J., & Wild, C. J. (1986). [Fitting logistic models under case-control
    or choice based sampling](https://www.jstor.org/stable/2345712). *Journal of the
    Royal Statistical Society Series B: Statistical Methodology*, *48*(2), 170–182.'
  prefs: []
  type: TYPE_NORMAL
