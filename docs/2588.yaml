- en: 'Unveiling the Power of Bias Adjustment: Enhancing Predictive Precision in Imbalanced
    Datasets'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 揭示偏差调整的力量：在类别不平衡数据集中提升预测精度
- en: 原文：[https://towardsdatascience.com/unveiling-the-power-of-bias-adjustment-enhancing-predictive-precision-in-imbalanced-datasets-ecad1836fc58?source=collection_archive---------2-----------------------#2023-08-13](https://towardsdatascience.com/unveiling-the-power-of-bias-adjustment-enhancing-predictive-precision-in-imbalanced-datasets-ecad1836fc58?source=collection_archive---------2-----------------------#2023-08-13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/unveiling-the-power-of-bias-adjustment-enhancing-predictive-precision-in-imbalanced-datasets-ecad1836fc58?source=collection_archive---------2-----------------------#2023-08-13](https://towardsdatascience.com/unveiling-the-power-of-bias-adjustment-enhancing-predictive-precision-in-imbalanced-datasets-ecad1836fc58?source=collection_archive---------2-----------------------#2023-08-13)
- en: '[](https://sirano1004.medium.com/?source=post_page-----ecad1836fc58--------------------------------)[![Hyung
    Gyu Rho](../Images/ce0248c75a21e0871d8e0b9fdf3c55b6.png)](https://sirano1004.medium.com/?source=post_page-----ecad1836fc58--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ecad1836fc58--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ecad1836fc58--------------------------------)
    [Hyung Gyu Rho](https://sirano1004.medium.com/?source=post_page-----ecad1836fc58--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://sirano1004.medium.com/?source=post_page-----ecad1836fc58--------------------------------)[![Hyung
    Gyu Rho](../Images/ce0248c75a21e0871d8e0b9fdf3c55b6.png)](https://sirano1004.medium.com/?source=post_page-----ecad1836fc58--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ecad1836fc58--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ecad1836fc58--------------------------------)
    [Hyung Gyu Rho](https://sirano1004.medium.com/?source=post_page-----ecad1836fc58--------------------------------)'
- en: ·
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F89f7d2237f82&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funveiling-the-power-of-bias-adjustment-enhancing-predictive-precision-in-imbalanced-datasets-ecad1836fc58&user=Hyung+Gyu+Rho&userId=89f7d2237f82&source=post_page-89f7d2237f82----ecad1836fc58---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ecad1836fc58--------------------------------)
    ·11 min read·Aug 13, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fecad1836fc58&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funveiling-the-power-of-bias-adjustment-enhancing-predictive-precision-in-imbalanced-datasets-ecad1836fc58&user=Hyung+Gyu+Rho&userId=89f7d2237f82&source=-----ecad1836fc58---------------------clap_footer-----------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F89f7d2237f82&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funveiling-the-power-of-bias-adjustment-enhancing-predictive-precision-in-imbalanced-datasets-ecad1836fc58&user=Hyung+Gyu+Rho&userId=89f7d2237f82&source=post_page-89f7d2237f82----ecad1836fc58---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ecad1836fc58--------------------------------)
    ·11 分钟阅读·2023年8月13日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fecad1836fc58&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funveiling-the-power-of-bias-adjustment-enhancing-predictive-precision-in-imbalanced-datasets-ecad1836fc58&user=Hyung+Gyu+Rho&userId=89f7d2237f82&source=-----ecad1836fc58---------------------clap_footer-----------)'
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fecad1836fc58&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funveiling-the-power-of-bias-adjustment-enhancing-predictive-precision-in-imbalanced-datasets-ecad1836fc58&source=-----ecad1836fc58---------------------bookmark_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fecad1836fc58&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funveiling-the-power-of-bias-adjustment-enhancing-predictive-precision-in-imbalanced-datasets-ecad1836fc58&source=-----ecad1836fc58---------------------bookmark_footer-----------)'
- en: Addressing class imbalance is crucial for accurate predictions in data science.
    This article introduces Bias Adjustment to enhance model accuracy amidst class
    imbalance. Explore how Bias Adjustment optimizes predictions and overcomes this
    challenge.
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 解决类别不平衡问题对于数据科学中的准确预测至关重要。本文介绍了偏差调整，以提高模型在类别不平衡情况下的准确性。探索偏差调整如何优化预测并克服这一挑战。
- en: '**Introduction**'
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**介绍**'
- en: In the realm of data science, effectively managing imbalanced datasets is crucial
    for precise predictions. Imbalanced datasets, characterized by significant class
    disparities, can lead to biased models favoring the majority class and delivering
    subpar performance for the minority class, especially in critical contexts like
    fraud detection and disease diagnosis.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学领域，有效管理不平衡数据集对于准确预测至关重要。不平衡的数据集以显著的类别差异为特征，可能导致模型偏向多数类，并对少数类的表现不佳，尤其是在诸如欺诈检测和疾病诊断等关键领域。
- en: This article introduces a pragmatic remedy known as Bias Adjustment. By fine-tuning
    the bias term within the model, it counteracts class imbalance, bolstering the
    model’s aptitude for accurate predictions across both majority and minority classes.
    The article outlines algorithms catering to binary and multi-class classification,
    followed by an exploration of their underlying principles. Notably, the Algorithm
    Explanation and Underlying Principles section rigorously establishes a theoretical
    link between my algorithm, oversampling, and adjusting class weights, enhancing
    the reader’s understanding.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本文介绍了一种实用的解决方案，称为偏差调整。通过微调模型中的偏差项，它可以对抗类别不平衡，增强模型对多数类和少数类的准确预测能力。文章概述了针对二分类和多分类的算法，并探讨了它们的基本原理。值得注意的是，算法解释和基本原理部分严格建立了我的算法、过采样和调整类别权重之间的理论联系，从而加深了读者的理解。
- en: To substantiate the efficacy and rationale, a simulation study scrutinizes the
    relationship between Bias Adjustment and oversampling. Further, a practical application
    is employed to illustrate the implementation and tangible benefits of Bias Adjustment
    in credit card fraud detection.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了证明其有效性和合理性，一项模拟研究考察了偏差调整与过采样之间的关系。此外，还通过实际应用展示了在信用卡欺诈检测中实现偏差调整的实施过程和实际效益。
- en: Bias Adjustment offers a direct and impactful avenue for refining predictive
    modeling results in the face of class imbalance. This article provides a comprehensive
    grasp of the mechanism, principles, and real-world implications of Bias Adjustment,
    making it an invaluable tool for data scientists seeking to enhance model performance
    amidst imbalanced datasets.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差调整为在面对类别不平衡时优化预测建模结果提供了直接且有影响力的途径。本文提供了对偏差调整机制、原理及实际应用的全面理解，使其成为数据科学家在不平衡数据集中提升模型性能的重要工具。
- en: '**Algorithm**'
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**算法**'
- en: The Bias Adjustment algorithm introduces a methodology to address class imbalance
    in binary and multi-class classification tasks. By recalibrating the bias term
    at each epoch, the algorithm enhances the model’s capacity to handle imbalanced
    datasets effectively. Through adjusting the bias term, the algorithm sensitizes
    the model to minority class instances, thereby improving classification accuracy.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差调整算法引入了一种方法来解决二分类和多分类任务中的类别不平衡问题。通过在每个训练周期重新校准偏差项，该算法提高了模型处理不平衡数据集的能力。通过调整偏差项，该算法使模型对少数类实例更加敏感，从而提高分类准确性。
- en: Model f(x) and its Role in Predictions
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型 f(x) 及其在预测中的作用
- en: At the core of our bias adjustment algorithm is the concept of *f*(*x*) — a
    crucial factor that guides our approach to dealing with class imbalance. *f*(*x*)
    serves as a link between input features *x* and the final predictions. In binary
    classification, it acts as a mapping that transforms inputs into real values,
    aligned with the sigmoid activation for probability interpretation. In multi-class
    classification, *f*(*x*) transforms into a set of functions, *f_k*​(*x*), where
    each class *k* has its own function, working in sync with the softmax activation.
    This distinction is instrumental in our bias adjustment algorithm, where we use
    *f*(*x*) to adjust bias term(s) and fine-tune sensitivity to class imbalance.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的偏差调整算法的核心概念是*f*(*x*) —— 这是指导我们处理类别不平衡问题的关键因素。*f*(*x*) 作为输入特征*x*和最终预测之间的连接。在二分类中，它作为一种映射，将输入转换为实际值，并与用于概率解释的
    sigmoid 激活函数对齐。在多分类中，*f*(*x*) 变成一组函数，*f_k*​(*x*)，其中每个类别*k*都有自己的函数，与 softmax 激活函数同步工作。这种区别在我们的偏差调整算法中至关重要，我们使用*f*(*x*)
    来调整偏差项并微调对类别不平衡的敏感性。
- en: Brief Overview of the Algorithm
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 算法概述
- en: 'The algorithm’s concept is straightforward: calculate the average of *f_k*​(*x*)
    for each class *k* and represent this average as *δk*​. By subtracting *δk*​ from
    *f_k*​(*x*), we ensure that the expected value of *f_k*​(*x*) − *δk*​ becomes
    0 for every class *k*. Consequently, the model predicts that each class is equally
    likely to occur. While this provides a concise glimpse into the algorithm’s rationale,
    it’s important to note that this approach is substantiated by theoretical and
    mathematical foundations, which will be explored further in subsequent sections
    of this article.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的概念很简单：计算每个类别 *k* 的 *f_k*​(*x*) 的平均值，并将该平均值表示为 *δk*​。通过从 *f_k*​(*x*) 中减去 *δk*​，我们确保
    *f_k*​(*x*) − *δk*​ 的期望值对于每个类别 *k* 都变为0。因此，模型预测每个类别发生的概率是相同的。虽然这提供了对算法原理的简要了解，但重要的是要注意，这种方法有理论和数学基础支撑，后续章节将进一步探讨。
- en: Algorithm for Binary
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 二分类算法
- en: '![](../Images/e6293ba872ad3b540f9cd23197189f24.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e6293ba872ad3b540f9cd23197189f24.png)'
- en: Created by Author
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 作者创作
- en: '**Utilization for Prediction**: For making predictions, apply the last calculated
    **δ** value from the algorithm. This **δ** value reflects cumulative adjustments
    made during training and serves as a basis for the final bias term in the sigmoid
    activation function during prediction.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**预测的利用**：在进行预测时，应用算法中最后计算的 **δ** 值。该 **δ** 值反映了在训练过程中所做的累计调整，并作为预测时 sigmoid
    激活函数中最终偏差项的基础。'
- en: '![](../Images/a4a52dfc7014e6b66e345a243c864b93.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a4a52dfc7014e6b66e345a243c864b93.png)'
- en: Algorithm for Multi-Class
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多类别算法
- en: '![](../Images/1799b9446e951ce30b308f0a72cd0f2b.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1799b9446e951ce30b308f0a72cd0f2b.png)'
- en: Created by Author
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 作者创作
- en: '**Utilization for Prediction**: The culmination of our algorithm’s training
    process yields a crucial element — the last calculated δk value. This δk value
    encapsulates the cumulative bias term adjustments that have been meticulously
    orchestrated during training. Its significance lies in its role as a foundational
    parameter for the final bias term in the softmax activation function during prediction.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**预测的利用**：我们算法训练过程的最终结果是一个关键元素——最后计算的 δk 值。该 δk 值封装了在训练过程中精心调整的累计偏差项。它的重要性在于，它作为预测时
    softmax 激活函数中最终偏差项的基础参数。'
- en: '![](../Images/4d4e7537ab3c519e04fbfa2dfd3eb397.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4d4e7537ab3c519e04fbfa2dfd3eb397.png)'
- en: Created by Author
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 作者创作
- en: Algorithm Explanation and Underlying Principles
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 算法解释与基本原理
- en: From oversampling to adjusting class weight, From adjusting class weight to
    the new algorithm
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 从过采样到调整类别权重，从调整类别权重到新算法
- en: In this section, we embark on an exploration of the Algorithm’s Explanation
    and Underlying Principles. Our aim is to elucidate the mechanics and rationale
    behind the algorithm’s operations, providing insights into its effectiveness in
    addressing class imbalance in classification tasks.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将深入探讨算法的解释和基本原理。我们的目标是阐明算法操作的机制和原理，提供关于其在分类任务中解决类别不平衡问题的有效性的见解。
- en: Loss Function and Imbalance
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 损失函数与不平衡
- en: We commence our journey by delving into the heart of the algorithm, the loss
    function. For our initial exposition, we will examine the loss function without
    directly addressing the issue of class imbalance. Let us consider a binary classification
    problem, where Class 1 comprises 90% of the observations and Class 0 constitutes
    the remaining 10%. Denoting the set of observations from Class 1 as C1 and from
    Class 0 as C0, we take this as our starting point.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从深入探讨算法的核心——损失函数开始。对于初步阐述，我们将研究未直接解决类别不平衡问题的损失函数。假设一个二分类问题，其中类别1占90%的观察值，类别0占剩余的10%。我们将类别1的观察值集合表示为
    C1，将类别0的观察值集合表示为 C0，以此作为起点。
- en: 'The loss function, in the absence of addressing class imbalance, takes the
    form:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在未解决类别不平衡问题的情况下，损失函数的形式为：
- en: '![](../Images/b02fec09ab7ad330f7e894557d973f43.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b02fec09ab7ad330f7e894557d973f43.png)'
- en: Created by Author
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 作者创作
- en: 'In the pursuit of model estimation, we endeavor to minimize this loss function:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型估计过程中，我们努力最小化这个损失函数：
- en: '![](../Images/62429da598d38fdc82aa3a41f804fed5.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/62429da598d38fdc82aa3a41f804fed5.png)'
- en: Created by Author
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 作者创作
- en: 'Mitigating Imbalance: Oversampling and Adjusting Class Weights'
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缓解不平衡：过采样和调整类别权重
- en: However, the crux of our endeavor lies in addressing the class imbalance predicament.
    To surmount this challenge, we venture into employing oversampling techniques.
    While various oversampling methods exist — encompassing simple oversampling, random
    oversampling, SMOTE, and others — our focus, for presentational clarity, narrows
    onto simple oversampling, with a glimpse into random oversampling.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们工作的核心在于解决类别不平衡问题。为了克服这一挑战，我们探讨了过采样技术。虽然存在各种过采样方法——包括简单过采样、随机过采样、SMOTE等——为了展示的清晰性，我们目前关注简单过采样，并稍微涉及随机过采样。
- en: '**Simple Oversampling:** A fundamental approach in our arsenal is simple oversampling,
    a technique where we duplicate instances of the minority class by a factor of
    eight to match the size of the majority class. In our illustrative example, where
    the minority class constitutes 10% and the majority class the remaining 90%, we
    duplicate the minority class observations eightfold, effectively equalizing class
    distribution. Denoting the set of duplicated observations as D0, this step transforms
    our loss function as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**简单过采样：** 我们工具箱中的一种基本方法是简单过采样，这是一种将少数类别的实例按八倍因子复制以匹配多数类别大小的技术。在我们的示例中，少数类别占10%，多数类别占90%，我们将少数类别的观察值复制八倍，从而有效地平衡类别分布。将复制的观察值集合记为D0，这一步骤将我们的损失函数转化如下：'
- en: '![](../Images/4993b018b94f60b98c45f133295481f6.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4993b018b94f60b98c45f133295481f6.png)'
- en: Created by Author
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 作者创建
- en: 'This reveals a profound insight: the core principle of simple oversampling
    seamlessly corresponds to the notion of adjusting class weights. Duplicating the
    minority class eightfold effectively equates to augmenting the weight of the minority
    class to ninefold. Significantly, the technique of oversampling mirrors the mechanism
    of weight adjustment.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这揭示了一个深刻的见解：简单过采样的核心原则与调整类别权重的概念无缝对应。将少数类别复制八倍有效地等同于将少数类别的权重增加到九倍。显著的是，过采样技术与权重调整的机制相似。
- en: '**Random Oversampling:** A brief contemplation on random oversampling underscores
    a parallel observation. Random oversampling, akin to its simpler counterpart,
    serves as an equivalent to random adjustment of observation weights.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**随机过采样：** 对随机过采样的简单思考突显了一个相似的观察。随机过采样，与其更简单的对应方法类似，充当了观察权重随机调整的等效方法。'
- en: '**From Adjusting Class Weights to Adjusting Bias**'
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**从调整类别权重到调整偏差**'
- en: 'A key revelation underscores the core of our approach: the essential equivalence
    between bias adjustment, oversampling, and weight adjustment. This insight emanates
    from'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一个关键的启示强调了我们方法的核心：偏差调整、过采样和权重调整之间的本质等价性。这一洞察来源于
- en: “Prentice and Pyke (1979) … have shown that, when the model contains a constant
    (intercept) term for each category, these constant terms are the only coefficient
    affected by the unequal selection probability of the Y” Scott & Wild (1986) [2].
    Also, Manski and Lerman (1977) show the same result in softmax setting [1].
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “Prentice和Pyke（1979）……已经表明，当模型包含每个类别的常数（截距）项时，这些常数项是唯一受Y的不平等选择概率影响的系数” Scott
    & Wild (1986) [2]。此外，Manski和Lerman（1977）在softmax设置中也显示了相同的结果 [1]。
- en: '**Unveiling the Significance:** Translating this insight into the realm of
    machine learning, the constant (intercept) term is the bias term. This fundamental
    observation reveals that when we recalibrate class weights or observation weights,
    the resulting changes primarily manifest as adjustments to the bias term. Put
    simply, the bias term acts as the linchpin connecting our strategy to address
    class imbalance.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**揭示重要性：** 将这一洞察转化为机器学习领域，常数（截距）项就是偏差项。这一基本观察揭示了，当我们重新校准类别权重或观察权重时，结果变化主要表现为对偏差项的调整。简而言之，偏差项是将我们的策略与解决类别不平衡问题的关键连接起来的枢纽。'
- en: A Unified Perspective
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 统一视角
- en: This understanding provides a straightforward explanation of how our algorithm,
    oversampling, and weight adjustment are, in essence, interchangeable and substitutable.
    This unification simplifies our approach while maintaining its potency in mitigating
    class imbalance challenges.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这种理解提供了一个直接的解释，说明我们的算法、过采样和权重调整在本质上是可互换和替代的。这种统一性简化了我们的方法，同时保持了其在缓解类别不平衡问题上的有效性。
- en: 'Simulation Study: Verifying the Bias Term Influence through Oversampling'
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模拟研究：通过过采样验证偏差项的影响
- en: To solidify our assertion that oversampling predominantly affects the bias term
    while keeping the model’s functional core intact, we delve into a targeted simulation
    study. Our aim is to demonstrate empirically how oversampling techniques solely
    impact the bias term, leaving the model’s essence unaltered.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为了巩固我们的主张，即过采样主要影响偏置项，同时保持模型的功能核心不变，我们深入进行了一项针对性的模拟研究。我们的目标是实证演示过采样技术如何仅影响偏置项，而不改变模型的本质。
- en: The Simulation Setup
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模拟设置
- en: 'For this illustrative purpose, we focus on a simplified scenario: logistic
    regression with a single feature. Our model is defined as:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这一目的，我们关注一个简化的场景：具有单一特征的逻辑回归。我们的模型定义为：
- en: '![](../Images/90ab09648be9ab0c4594e647a59c1e96.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/90ab09648be9ab0c4594e647a59c1e96.png)'
- en: Created by Author
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 作者创建
- en: where **1**(.) denotes the indicator function, x_i is drawn from a standard
    normal distribution, and *e_i*​ follows a logistic distribution. In this context,
    we set *f*(*x*)=*x*.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 **1**(.) 表示指示函数，x_i 从标准正态分布中抽取，*e_i* 服从逻辑斯蒂分布。在这种情况下，我们设定 *f*(*x*)=*x*。
- en: 'Running the Simulation:'
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行模拟：
- en: 'Using this setup, we meticulously examine the impact of oversampling techniques
    on the bias term while keeping the model’s core constant. We proceed with three
    oversampling methods: simple oversampling, SMOTE, and random sampling. Each method
    is meticulously applied, and the results are carefully recorded.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此设置，我们仔细检查了过采样技术对偏置项的影响，同时保持模型的核心不变。我们进行了三种过采样方法：简单过采样、SMOTE 和随机采样。每种方法都经过仔细应用，结果也被仔细记录。
- en: 'The Python code snippet below outlines the simulation process:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的 Python 代码片段概述了模拟过程：
- en: '[PRE0]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Results:'
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/cf669eaba6a84a8ca92c2ddd8dcffbff.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cf669eaba6a84a8ca92c2ddd8dcffbff.png)'
- en: Simulation Results; Created by Author
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟结果；作者创建
- en: Key Observations
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主要观察
- en: The outcomes of our simulation study succinctly validate our proposition. Despite
    the application of various oversampling methods, the core model function *f*(*x*)=*x*
    remains unaltered. The crucial insight lies in the remarkable consistency of the
    model component across all oversampling techniques. Instead, the bias term exhibits
    noticeable variations, corroborating our claim that oversampling primarily impacts
    the bias term without affecting the underlying model structure.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模拟研究结果简洁地验证了我们的主张。尽管应用了各种过采样方法，但核心模型函数 *f*(*x*)=*x* 保持不变。关键见解在于模型组件在所有过采样技术中保持了显著的一致性。相反，偏置项表现出明显的变化，证实了我们的观点，即过采样主要影响偏置项，而不改变模型的基本结构。
- en: Reinforcing the Core Concept
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加强核心概念
- en: Our simulation study undeniably underscores the fundamental equivalence between
    oversampling, weight adjustment, and bias term modification. By showcasing that
    oversampling exclusively alters the bias term, we fortify the principle that these
    strategies are interchangeable tools in the arsenal against class imbalance.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模拟研究无疑强调了过采样、权重调整和偏置项修改之间的基本等价性。通过展示过采样仅改变偏置项，我们强化了这些策略作为对抗类别不平衡的可互换工具的原则。
- en: Applying the Bias Adjustment Algorithm to Credit Card Fraud Detection
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将偏置调整算法应用于信用卡欺诈检测
- en: To demonstrate the effectiveness of our bias adjustment algorithm in addressing
    class imbalance, we employ a real-world dataset from a [Kaggle competition](https://www.kaggle.com/competitions/playground-series-s3e4/overview)
    focused on credit card fraud detection. In this scenario, the challenge lies in
    predicting whether a credit card transaction is fraudulent (labeled as 1) or not
    (labeled as 0), given the inherent rarity of fraud cases.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示我们偏置调整算法在解决类别不平衡问题上的有效性，我们使用了一个来自 [Kaggle 竞赛](https://www.kaggle.com/competitions/playground-series-s3e4/overview)
    的真实数据集，专注于信用卡欺诈检测。在这种情况下，挑战在于预测一笔信用卡交易是否欺诈（标记为 1）或非欺诈（标记为 0），考虑到欺诈案件的固有稀少性。
- en: 'We start by loading essential packages and preparing the dataset:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先加载必要的包并准备数据集：
- en: '[PRE1]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We then define a simple deep learning model for binary classification and set
    up the optimizer, loss function, and evaluation metric. I follow the competition
    evaluation and choose AUC as evaluation metric. Furthermore, the model is intentionally
    simplified as the focus of this article is to show how to implement the bias adjustment
    algorithm, not to ace in prediction:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们定义了一个简单的深度学习模型用于二分类，并设置了优化器、损失函数和评估指标。我遵循了竞赛评估并选择了AUC作为评估指标。此外，模型故意被简化，因为本文的重点是展示如何实现偏差调整算法，而不是在预测中取得最佳成绩。
- en: '[PRE2]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Within the core of our bias adjustment algorithm lies the training and validation
    steps, where we meticulously address class imbalance. To elucidate this process,
    we delve into the intricate mechanisms that balance the model’s predictions.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的偏差调整算法的核心中，训练和验证步骤中，我们细致地解决了类别不平衡问题。为了阐明这个过程，我们深入探讨了平衡模型预测的复杂机制。
- en: Training Step with Accumulating Delta Values
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用累积Delta值的训练步骤
- en: 'In the training step, we embark on the journey of enhancing model sensitivity
    to class imbalance. Here, we calculate and accumulate the sum of model outputs
    for two distinct clusters: `delta0` and `delta1`. These clusters hold significant
    importance, representing the predicted values associated with classes 0 and 1,
    respectively.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练步骤中，我们开始了提升模型对类别不平衡敏感性的旅程。在这里，我们计算并累积了两个不同集群的模型输出之和：`delta0`和`delta1`。这两个集群具有重要意义，分别代表了与类别0和类别1相关的预测值。
- en: '[PRE3]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Validation Step: Imbalance Resolution with Delta'
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 验证步骤：使用Delta解决不平衡问题
- en: The normalized delta values, derived from the training process, take center
    stage in the validation step. Armed with these refined indicators of class imbalance,
    we align the model’s predictions more accurately with the true distribution of
    classes. The `test_step` function integrates these delta values to adaptively
    adjust predictions, ultimately leading to a refined evaluation.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 从训练过程中得出的归一化Delta值在验证步骤中发挥了核心作用。凭借这些精细化的类别不平衡指标，我们将模型的预测与真实的类别分布更准确地对齐。`test_step`函数将这些Delta值集成到自适应调整预测中，最终导致更精细的评估。
- en: '[PRE4]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Utilizing Delta Values for Imbalance Correction
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用Delta值进行不平衡修正
- en: As training progresses, we collect valuable insights encapsulated within the
    `delta0` and `delta1` cluster sums. These cumulative values emerge as indicators
    of the bias inherent in our model's predictions. At the conclusion of each epoch,
    we execute a vital transformation. By dividing the accumulated cluster sums by
    the corresponding number of observations from each class, we derive normalized
    delta values. This normalization acts as a crucial equalizer, encapsulating the
    essence of our bias adjustment approach.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 随着训练的进行，我们收集了 encapsulated 在`delta0`和`delta1`集群总和中的宝贵见解。这些累积值成为我们模型预测中固有偏差的指示器。在每个训练周期结束时，我们执行了一个重要的转换。通过将累积的集群总和除以每个类别的相应观察数，我们得到归一化的Delta值。这种归一化作为关键的平衡器，概括了我们偏差调整方法的本质。
- en: '[PRE5]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The Outcome
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果
- en: In our application to credit card fraud detection, the enhanced efficacy of
    our algorithm shines through. With bias adjustment seamlessly integrated into
    the training process, we achieve an impressive AUC score of 0.77\. This starkly
    contrasts with the AUC score of 0.71 attained without the guiding hand of bias
    adjustment. The profound improvement in predictive performance stands as a testament
    to the algorithm’s ability to navigate the intricacies of class imbalance, charting
    a course towards more accurate and reliable predictions.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们应用于信用卡欺诈检测的过程中，我们算法的增强效果得到了体现。通过将偏差调整无缝集成到训练过程中，我们获得了令人印象深刻的AUC得分0.77。这与未进行偏差调整时获得的0.71的AUC得分形成了鲜明对比。预测性能的显著改善证明了该算法在处理类别不平衡的复杂性方面的能力，为更准确和可靠的预测铺平了道路。
- en: References
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Manski, C. F., & Lerman, S. R. (1977). [The estimation of choice probabilities
    from choice based samples](https://www.jstor.org/stable/1914121). *Econometrica:
    Journal of the Econometric Society*, 1977–1988.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Manski, C. F., & Lerman, S. R. (1977). [从基于选择的样本中估计选择概率](https://www.jstor.org/stable/1914121).
    *Econometrica: Journal of the Econometric Society*, 1977–1988.'
- en: '[2] Scott, A. J., & Wild, C. J. (1986). [Fitting logistic models under case-control
    or choice based sampling](https://www.jstor.org/stable/2345712). *Journal of the
    Royal Statistical Society Series B: Statistical Methodology*, *48*(2), 170–182.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Scott, A. J., & Wild, C. J. (1986). [在病例对照或选择性抽样下拟合逻辑模型](https://www.jstor.org/stable/2345712)。*《皇家统计学会B系列：统计方法》*，*48*(2)，170–182。'
