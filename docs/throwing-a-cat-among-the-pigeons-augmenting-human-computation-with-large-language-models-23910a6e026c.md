# 抛出一只猫到鸽子中间？用大型语言模型增强人类计算能力

> 原文：[https://towardsdatascience.com/throwing-a-cat-among-the-pigeons-augmenting-human-computation-with-large-language-models-23910a6e026c?source=collection_archive---------19-----------------------#2023-07-21](https://towardsdatascience.com/throwing-a-cat-among-the-pigeons-augmenting-human-computation-with-large-language-models-23910a6e026c?source=collection_archive---------19-----------------------#2023-07-21)

## 生成性人工智能的时代提供了改善群体工作机会的可能性，而不一定是取代它

[](https://medium.com/@ujwal07?source=post_page-----23910a6e026c--------------------------------)[![Ujwal Gadiraju](../Images/ee7345cf2e7fbf6ee29866659b60b18e.png)](https://medium.com/@ujwal07?source=post_page-----23910a6e026c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----23910a6e026c--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----23910a6e026c--------------------------------) [Ujwal Gadiraju](https://medium.com/@ujwal07?source=post_page-----23910a6e026c--------------------------------)

·

[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc529f92bfe0d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthrowing-a-cat-among-the-pigeons-augmenting-human-computation-with-large-language-models-23910a6e026c&user=Ujwal+Gadiraju&userId=c529f92bfe0d&source=post_page-c529f92bfe0d----23910a6e026c---------------------post_header-----------) 发表在[Towards Data Science](https://towardsdatascience.com/?source=post_page-----23910a6e026c--------------------------------) ·12分钟阅读·2023年7月21日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F23910a6e026c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthrowing-a-cat-among-the-pigeons-augmenting-human-computation-with-large-language-models-23910a6e026c&user=Ujwal+Gadiraju&userId=c529f92bfe0d&source=-----23910a6e026c---------------------clap_footer-----------)

--

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F23910a6e026c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthrowing-a-cat-among-the-pigeons-augmenting-human-computation-with-large-language-models-23910a6e026c&source=-----23910a6e026c---------------------bookmark_footer-----------)![](../Images/ef56b511577de8d7bd8679a862770161.png)

照片由[Steve Johnson](https://unsplash.com/@steve_j?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)拍摄，来源于[Unsplash](https://unsplash.com/photos/_0iV9LmPDn0?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

我一直对词源学充满兴趣。通常，单词和短语如何获得我们熟悉的意义背后有一个引人入胜的故事。随着时代的变迁，词汇也在不断演变。*机械土耳其人*是18世纪匈牙利作家和发明家沃尔夫冈·冯·肯佩伦制造的一个下棋类人形机器。传说*机械土耳其人*在欧洲巡演，并在传说中的棋局中击败了拿破仑·波拿巴和本杰明·富兰克林等显赫人物。直到后来，真正的秘密才被揭示出来，原来是一个隐藏在地板下的真实人类棋手，在那里操控着机械人形的走棋。

这个故事启发了2005年推出的亚马逊机械土耳其人众包平台的命名。该平台旨在解决当时的替代方案无法解决的任务，并需要人工输入或智能。在这种背景下，“*人工人工智能*”的概念形成了，人类在机器能力之外提供智能。我们已经从那里走了很长一段路，达到了全新的“*人工人工人工智能*”概念的边缘。没错，你没看错，三个人工。在你试图用额头破解这个难题之前，让我们快速回顾一些记忆。

## **众包的早期日子**

在他2004年出版的《群体的智慧》一书中，詹姆斯·苏罗维基探讨并综合了形成明智群体所需的特征——这种群体通常能比单一个体做出更好的决策。他指出，意见的多样性、判断的独立性和知识的分散性是实现这一目标的重要属性。2006年，杰夫·豪在为《连线》杂志撰写的关于《众包的兴起》的文章中创造了*众包*这个词，它是“crowds”和“outsourcing”的合成词。他讨论了企业如何通过公开征集的方式，开始利用分布式在线社区的集体能力来完成某些任务。

亚马逊机械土耳其人在首次推出后蓬勃发展，几年内，全球数十万人通过在平台上完成任务找到了谋生的机会。这激发了全球范围内众包平台的增长，铸造并巩固了在线微任务众包工作的全新经济。研究人员和从业者开始依赖众包平台来完成各种任务，并证明了即使是高度复杂的任务也可以分解并众包。提出了系统和工具，以支持众包工作者有效完成任务。一些当代众包平台的显著例子包括 [Toloka AI](https://toloka.ai)（“一个支持快速和可扩展AI发展的数据中心环境”）。

借助人类洞察力”) 和 [Prolific](https://www.prolific.co)（一个“进行研究或训练下一代人工智能”的平台）。

2009年，ImageNet的发布推动了整个机器学习领域。该数据集包含超过320万张图像，分为12个子树，并具有超过五千个同义词集，这是通过亚马逊机械土耳其工人众包进行的巨大数据收集努力[1]。这为多个计算机视觉任务提供了前所未有的进步机会，包括对象识别和图像分类。

我们不要忘记，这一进展伴随着一系列的试炼和磨难。许多人感受到了依赖易受认知和系统性偏见影响的人类生成数据所带来的危险的震颤。在2013年，一群在众包社区中著名的研究者写了一篇名为《众包工作的未来》的论文，反思了这一范式的现状以及需要立即解决的一系列挑战[2]。尽管取得了显著进展，但许多这些挑战在10年后的今天仍未得到解决。关于数据质量（例如，偏见传播）、平台上的权力不对称、低劣的小时工资、不公平的工作拒绝、隐形劳动、不健康的工作环境等问题已有充分记录。尽管有些人认为这是一个破碎的工作范式的脆弱之处，历史上却点缀着显著的成果，众包的力量无疑推动了技术进步的速度，只有少数人会预见到。

## **生成性人工智能的迷人时代**

目前全球主流媒体陷入了关于生成性人工智能和大型语言模型民主化的广泛叙事中。许多生活将继续以预期和意想不到的方式受到人工智能的影响。而正是幕后辛勤工作的人工推动了这场人工智能革命。如果我们“审视人工智能的阴影，我们将发现推动它的人类”，正如玛丽·格雷和西德·苏里在《幽灵工作》中*难以忘怀*地指出的那样[3]。

夸大的预测和引人注目的标题将这一时代中人类的角色比作焦虑的鸽子，并将大型语言模型比作大胆的猫——隐喻中的猫打乱了队伍，使它们四散离去。但这个生成性人工智能新时代的开始对人类输入究竟意味着什么？在塑造未来技术方面，人类输入的需求是否已经在很大程度上被消除了？在本文的其余部分，我将论证答案是否定的，我们应预期的主要变化是在继续需要的人类输入的性质上。

我最近共同撰写了一篇研讨会论文，探讨了人类计算工作流程如何适应生成式AI模型的出现[4]。这项工作在今年早些时候于汉堡举办的顶级HCI会议ACM CHI 2023上的生成式AI研讨会上进行了展示。我们强调了大型语言模型（LLMs）在增强现有众包工作流程中可能发挥的作用，并讨论了如何对这些工作流程进行实证评估。

## **众包工作流程入门**

众包工作流程是管理大规模任务如何被分解成较小任务以供众包工人完成的不同模式。众包驱动的文字处理器Soylent运用了**Find-Fix-Verify**工作流程，通过将任务分成生成和审查文本的阶段来生产高质量的文本。这使得“作家可以调用Mechanical Turk工人根据需要缩短、校对和编辑他们文档的部分[5]。” **Iterate-and-Vote**工作流程已被用于创建图像描述，在这个过程中，工人首先被要求写出图像的描述（例如，最终目的是帮助盲人）。随后，通过投票任务来确定最佳描述[6]。**Map-Reduce**工作流程则被提议用于“将工作分成可以并行完成的任务，映射任务到工人，并管理它们之间的依赖关系[7]。” 具有相同本质的工具，如**CrowdWeaver**，被提议用于管理复杂的工作流程，支持任务之间的数据共享，并提供监控工具和实时任务调整能力[8]。

## **利用LLMs提升众包工作流程**

语言模型的出现不太可能使这些工作流程、框架和工具变得完全平凡。相反，众包社区独特地能够通过利用几十年的有效工作流程、人机交互方法和构建混合人类-人工智能系统的知识，来迎接LLMs带来的好处。

以人为本的技术开发视角专注于增强人们日常生活中的体验和提高人的能力。如果大语言模型（LLMs）确实可以帮助众包工人完成任务，它们应该以一种能够让工人更准确、更迅速地完成任务的方式被接纳和整合，或以某种方式改善他们的整体体验。

信息检索领域的研究者（这是我在过去十年中参与的一个社区）最近考虑了LLMs的普及对人类注释员在相关性判断中的角色意味着什么[9]。他们提出了一个人类与LLMs之间合作的谱系，以生成相关性判断（从人类判断到完全自动评估，类似于流行的*自动化水平*）。作者探讨了在辅助注释任务中引入LLMs的潜在好处，并将其与这样做的风险进行了权衡。显然，LLMs可以降低创建评估集合的注释成本。然而，尚不清楚这些集合是否会系统性地与由人类创建的集合不同，以及这些文献会如何影响信息检索系统的评估，从而影响未来这些系统的设计。

除了在工作流程中支持个体写作或分类任务外，研究者们还在探索LLMs在辅助众包工作者中的应用。刘等人将GPT-3的生成能力与人类的评估能力结合，创建了一个新的自然语言推理数据集，该数据集在用作训练集时能产生更有效的模型[10]。类似地，其他人引入了一个‘*生成注释助手*’，以帮助生成动态对抗数据集合，显著提高了收集速率[11]。然而，关于LLMs如何提高众包工作流程的有效性以及如何全面评估这些工作流程，还有一些尚未完全理解的开放性问题。

## **前方有许多障碍吗？**

与人类类似，LLMs也可能受到偏见和不公平的影响。一方面，先前的研究表明，人类注释员在完成注释任务时容易受自身意见的影响，从而导致系统性偏见渗入结果数据集合[12]。其他研究者提出了用于对抗或报告注释过程中可能出现的认知偏见的检查清单[13]。另一方面，最近的研究揭示了LLMs中存在的歧视性立场和刻板印象偏见[14, 15]。

人类计算与众包研究社区（HCOMP）设计了多种有效的方法、接口、衡量标准和工具，以确保从众包工作者那里收集到高质量的数据。我们集体弄清楚如何在决策管道中集成LLMs的同时，提供这些质量相关的保证只是时间问题。

表面上，将大型语言模型（LLMs）整合进众包工作流程似乎相当简单。正如许多复杂系统解决方案的提议一样，说起来容易做起来难。众包涉及许多不同的利益相关者：希望收集大规模注释的任务请求者，愿意提供帮助以获得报酬的众包工人，提供基础设施并充当这些交易市场的平台，以及在下游开发或建设中间接使用产品或技术的最终用户。将LLMs纳入工作流程的影响可能以不同方式影响每个利益相关者。

如果众包工人能够通过在智能工作流程中利用LLMs变得更加高效，那么有可能在不增加成本的情况下完成更多工作。然而，还需要进一步的工作来更好地理解将LLMs纳入众包工作流程所带来的风险和奖励。考虑到可能需要的责任追究，谁将负责设计、开发和将LLMs整合到这些工作流程中呢？

历史上，众包工人通常被留给自己来提高生产力以及改善他们工作的环境和条件。难道现在不应该由众包平台和任务请求者共同负责，更好地理解如何配备基于LLMs的解决方案，以帮助工人成功完成任务，并提升和增强他们的工作体验吗？

## **人工人工人工智能与可期的未来**

一项近期案例研究探讨了“人类”在文本总结任务中生成的众包数据在多大程度上确实是由人类生成的。作者发现证据表明，在他们对Amazon Mechanical Turk的研究中，超过30%的众包工人已经开始依赖LLMs [16]。尽管该研究仅报告了44名工人的这些见解，数字需谨慎对待，但这确实反映了越来越多的众包工人可能转向LLM-based解决方案的不可否认的前景，这些解决方案可以帮助他们提高生产力、最大化收入，并改善他们在众包市场中的时间。这就是“**人工**人工人工智能”概念的来源——众包工人可能利用AI（LLMs的帮助）提供所谓的“人类”输入。

![](../Images/7894a2491d6265d08d018a575594a1d8.png)

**图**：一张插图描绘了“人工人工人工智能”这一术语的出现，该术语源于[29]的AI（1）到AAI（2），最终到AAAI（3）。**来源**：作者提供的图像。

需要进一步考虑LLMs的透明度和可解释性，与从人类那里获得的相比。当众包工人完成注释或其他需要决策的任务时，任务请求者可以通过后续问题提取有意义的理由。众包工人具备在需要时提供这些见解的能力。目前LLMs尚无法实现这一点。是的，存在模型可解释性的方法，但没有一种显示出与人类在沟通两端所能实现的效果相当的有效性。这种对LLMs的“黑箱”感知可能会对任务请求者和众包平台的采纳形成障碍，同时也阻碍了众包工人对这些工具的适当依赖。

人类与LLMs？无限的可能性和一片引人入胜的问题海洋，只有少数闪烁的答案。利用这一技术进步来改善众包工作，更像是捕捉到风帆上的一阵风，而不是搅动一个黄蜂窝。让我们忙起来，因为当我们能够让人类居于中心舞台时，一个美好的未来在等待着我们。

## **参考文献**

1.  Deng, J., Dong, W., Socher, R., Li, L. J., Li, K., & Fei-Fei, L. (2009年6月)。Imagenet：大规模层次图像数据库。*发表于2009年IEEE计算机视觉与模式识别会议论文集*（第248–255页）。IEEE。

1.  Kittur, A., Nickerson, J.V., Bernstein, M., Gerber, E., Shaw, A., Zimmerman, J., Lease, M. 和 Horton, J., 2013年2月。众包工作的未来。*发表于2013年计算机支持协作工作会议论文集*（第1301–1318页）。

1.  Gray, M. L., & Suri, S. (2019)。*幽灵工作：如何阻止硅谷建立一个新的全球底层阶级*。Eamon Dolan Books。

1.  Allen, G., He, G., Gadiraju, U. 提升！生成模型能为人类计算工作流程做些什么？*发表于ACM国际计算系统人因会议（CHI 2023）的生成AI研讨会论文集*。

1.  Bernstein, Michael S., Greg Little, Robert C. Miller, Björn Hartmann, Mark S. Ackerman, David R. Karger, David Crowell, 和 Katrina Panovich. “Soylent：一个内部含有众包的文字处理器。” *发表于第23届年度ACM用户界面软件与技术研讨会论文集*，第313–322页。2010年。

1.  Little, G., Chilton, L. B., Goldman, M., & Miller, R. C. (2009年6月)。Turkit：机械土耳其上迭代任务的工具。*发表于ACM SIGKDD人类计算研讨会论文集*（第29–30页）。

1.  Kittur, A., Smus, B., Khamkar, S., & Kraut, R. E. (2011年10月)。Crowdforge：众包复杂工作。*发表于第24届年度ACM用户界面软件与技术研讨会论文集*（第43–52页）。

1.  Kittur, A., Khamkar, S., André, P. 和 Kraut, R., 2012年2月。CrowdWeaver：可视化管理复杂的众包工作。*发表于ACM 2012年计算机支持协作工作会议论文集*（第1033–1036页）。

1.  Faggioli, G., Dietz, L., Clarke, C., Demartini, G., Hagen, M., Hauff, C., Kando, N., Kanoulas, E., Potthast, M., Stein, B. 和 Wachsmuth, H., 2023\. 《对大型语言模型在相关性判断中的视角》。*arXiv 预印本 arXiv:2304.09161*。

1.  Liu, Z., Roberts, R.A., Lal-Nag, M., Chen, X., Huang, R. 和 Tong, W., 2021\. 《基于AI的语言模型在药物发现与开发中的应用》。*Drug Discovery Today*, *26*(11), 第2593–2607页。

1.  Bartolo, M., Thrush, T., Riedel, S., Stenetorp, P., Jia, R. 和 Kiela, D., 2021\. 《模型在循环中：利用生成式注释助手辅助众包工作者》。*arXiv 预印本 arXiv:2112.09062*。

1.  Hube, C., Fetahu, B. 和 Gadiraju, U., 2019年5月。《理解和减轻众包收集主观判断中的工作者偏见》。见于 *2019年CHI计算机系统人因会议论文集*（第1–12页）。

1.  Draws, T., Rieger, A., Inel, O., Gadiraju, U., 和 Tintarev, N. (2021年10月)。 《应对众包中的认知偏见检查表》。见于 *AAAI人类计算与众包会议论文集*（第9卷，第48–59页）。

1.  Abid, A., Farooqi, M. 和 Zou, J., 2021年7月。《大型语言模型中的持久反穆斯林偏见》。见于 *2021年AAAI/ACM人工智能、伦理与社会会议论文集*（第298–306页）。

1.  Nadeem, M., Bethke, A. 和 Reddy, S., 2020\. 《StereoSet：测量预训练语言模型中的刻板偏见》。*arXiv 预印本 arXiv:2004.09456*。

1.  Veselovsky, V., Ribeiro, M. H., 和 West, R. (2023)。 《人工人工人工智能：众包工作者广泛使用大型语言模型进行文本生成任务》。*arXiv 预印本 arXiv:2306.07899*。
