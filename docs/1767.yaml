- en: Summarising Best Practices for Prompt Engineering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结最佳实践以进行提示工程
- en: 原文：[https://towardsdatascience.com/summarising-best-practices-for-prompt-engineering-c5e86c483af4?source=collection_archive---------0-----------------------#2023-05-29](https://towardsdatascience.com/summarising-best-practices-for-prompt-engineering-c5e86c483af4?source=collection_archive---------0-----------------------#2023-05-29)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/summarising-best-practices-for-prompt-engineering-c5e86c483af4?source=collection_archive---------0-----------------------#2023-05-29](https://towardsdatascience.com/summarising-best-practices-for-prompt-engineering-c5e86c483af4?source=collection_archive---------0-----------------------#2023-05-29)
- en: How to build your own LLM-based application using OpenAI API
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何使用 OpenAI API 构建自己的基于 LLM 的应用
- en: '[](https://medium.com/@andimid?source=post_page-----c5e86c483af4--------------------------------)[![Dmytro
    Nikolaiev (Dimid)](../Images/4121156b9c08ed20e7aa620712a391d9.png)](https://medium.com/@andimid?source=post_page-----c5e86c483af4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c5e86c483af4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c5e86c483af4--------------------------------)
    [Dmytro Nikolaiev (Dimid)](https://medium.com/@andimid?source=post_page-----c5e86c483af4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@andimid?source=post_page-----c5e86c483af4--------------------------------)[![Dmytro
    Nikolaiev (Dimid)](../Images/4121156b9c08ed20e7aa620712a391d9.png)](https://medium.com/@andimid?source=post_page-----c5e86c483af4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c5e86c483af4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c5e86c483af4--------------------------------)
    [Dmytro Nikolaiev (Dimid)](https://medium.com/@andimid?source=post_page-----c5e86c483af4--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F97b5279dad26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummarising-best-practices-for-prompt-engineering-c5e86c483af4&user=Dmytro+Nikolaiev+%28Dimid%29&userId=97b5279dad26&source=post_page-97b5279dad26----c5e86c483af4---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c5e86c483af4--------------------------------)
    ·13 min read·May 29, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc5e86c483af4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummarising-best-practices-for-prompt-engineering-c5e86c483af4&user=Dmytro+Nikolaiev+%28Dimid%29&userId=97b5279dad26&source=-----c5e86c483af4---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F97b5279dad26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummarising-best-practices-for-prompt-engineering-c5e86c483af4&user=Dmytro+Nikolaiev+%28Dimid%29&userId=97b5279dad26&source=post_page-97b5279dad26----c5e86c483af4---------------------post_header-----------)
    发表在[Towards Data Science](https://towardsdatascience.com/?source=post_page-----c5e86c483af4--------------------------------)
    · 13分钟阅读 · 2023年5月29日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc5e86c483af4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummarising-best-practices-for-prompt-engineering-c5e86c483af4&user=Dmytro+Nikolaiev+%28Dimid%29&userId=97b5279dad26&source=-----c5e86c483af4---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc5e86c483af4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummarising-best-practices-for-prompt-engineering-c5e86c483af4&source=-----c5e86c483af4---------------------bookmark_footer-----------)![](../Images/29f7df4f533997ab03fde5e13ffcb7b5.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc5e86c483af4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummarising-best-practices-for-prompt-engineering-c5e86c483af4&source=-----c5e86c483af4---------------------bookmark_footer-----------)![](../Images/29f7df4f533997ab03fde5e13ffcb7b5.png)'
- en: Photo by [Glenn Carstens-Peters](https://unsplash.com/@glenncarstenspeters?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/RLw-UC03Gwc?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Glenn Carstens-Peters](https://unsplash.com/@glenncarstenspeters?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)拍摄，来源于[Unsplash](https://unsplash.com/photos/RLw-UC03Gwc?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)。
- en: Prompt engineering refers to the process of creating instructions called *prompts*
    for Large Language Models (LLMs), such as OpenAI’s ChatGPT. With the immense potential
    of LLMs to solve a wide range of tasks, leveraging prompt engineering can empower
    us to save significant time and facilitate the development of impressive applications.
    It holds the key to **unleashing the full capabilities** of these huge models,
    transforming how we interact and benefit from them.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程指的是为大型语言模型（LLMs），如OpenAI的ChatGPT，创建称为*提示*的指令的过程。利用LLMs解决各种任务的巨大潜力，借助提示工程可以节省大量时间，并促进令人印象深刻的应用程序的开发。它是**释放这些大型模型全部能力**的关键，改变我们与这些模型的互动方式及其带来的好处。
- en: 'In this article, I tried to summarize the best practices of prompt engineering
    to help you build LLM-based applications faster. While the field is developing
    very rapidly, the following “time-tested” :) techniques tend to work well and
    allow you to achieve fantastic results. In particular, we will cover:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我尝试总结提示工程的最佳实践，以帮助你更快地构建基于LLM的应用程序。虽然这个领域发展迅速，但以下这些“经过时间考验”的:) 技术往往效果很好，并能让你取得出色的成果。特别是，我们将涵盖：
- en: The concept of **iterative prompt development**, using separators and structural
    output;
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**迭代提示开发**的概念，使用分隔符和结构化输出；'
- en: '**Chain-of-Thoughts** reasoning;'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**思维链**推理；'
- en: '**Few-shot learning**.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**少样本学习**。'
- en: Together with intuitive explanations, I’ll share both hands-on examples and
    resources for future investigation.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 结合直观的解释，我将分享实际的示例和未来调查的资源。
- en: Then we’ll explore how you can build a simple LLM-based application for local
    use using [OpenAI API](https://platform.openai.com/docs/introduction) for free.
    We will use Python to describe the logic and [Streamlit library](https://streamlit.io/)
    to build the web interface.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将探索如何使用[OpenAI API](https://platform.openai.com/docs/introduction)免费构建一个简单的基于LLM的本地应用程序。我们将使用Python来描述逻辑，使用[Streamlit库](https://streamlit.io/)来构建网页界面。
- en: Let’s start!
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Best Practices for Prompt Engineering
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示工程的最佳实践
- en: In this article, I will interact with ChatGPT through both the web interface
    and API. The `gpt-3.5-turbo` model I’ll use is the one behind ChatGPT, so you
    can experiment with your prompts right in the browser.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将通过网页界面和API与ChatGPT互动。我将使用的`gpt-3.5-turbo`模型是ChatGPT背后的模型，因此你可以直接在浏览器中实验你的提示。
- en: One important thing to note here is that ChatGPT is not only LLM; as you probably
    know, it’s also a SFT (Supervised Fine-Tuning) model that was further finetuned
    with [Reinforcement Learning from Human Feedback (RLHF)](https://huyenchip.com/2023/05/02/rlhf.html).
    While many developers currently utilize OpenAI’s models for experimental projects
    and personal exploration, there are other models that may be more appropriate
    for deployment in production settings within large corporations due to privacy
    and other reasons.
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这里一个重要的点是，ChatGPT不仅仅是大型语言模型（LLM）；如你所知，它还是一个SFT（监督微调）模型，经过了[来自人类反馈的强化学习（RLHF）](https://huyenchip.com/2023/05/02/rlhf.html)的进一步微调。虽然许多开发者目前利用OpenAI的模型进行实验项目和个人探索，但由于隐私和其他原因，其他模型可能更适合在大型企业的生产环境中部署。
- en: ''
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If you want to know why base models (such as [GPT-3](https://en.wikipedia.org/wiki/GPT-3),
    [Chinchilla](https://arxiv.org/abs/2203.15556), [LLaMA](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/))
    do not function in the same way as fine-tuned and RLHF-trained assistants (e.g.,
    [ChatGPT](https://openai.com/blog/chatgpt), [Koala](https://bair.berkeley.edu/blog/2023/04/03/koala/),
    [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html)), there is [a talk
    by Andrej Karpathy about training and using GPT-like models](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2).
    I highly recommend checking it out for a deeper understanding, and it is just
    40 minutes long. For a summary, take a look at [this Twitter thread](https://threadreaderapp.com/thread/1661236778458832896.html).
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你想知道为什么基础模型（如[GPT-3](https://en.wikipedia.org/wiki/GPT-3)，[Chinchilla](https://arxiv.org/abs/2203.15556)，[LLaMA](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)）的功能与微调和RLHF训练的助手（如[ChatGPT](https://openai.com/blog/chatgpt)，[Koala](https://bair.berkeley.edu/blog/2023/04/03/koala/)，[Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html)）不同，可以参考[Andrej
    Karpathy关于训练和使用类似GPT模型的讲座](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2)。我强烈推荐查看这个讲座以获得更深入的理解，时间只有40分钟。总结可以参考[这个Twitter线程](https://threadreaderapp.com/thread/1661236778458832896.html)。
- en: Now let’s dive into best practices for prompting instruction-tuned LLMs!
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们深入探讨针对指令调优LLMs的最佳实践！
- en: Iterative Prompt Development
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Just as any machine learning model is built through an *iterative process*,
    effective prompts are also constructed through a similar iterative approach. Even
    the most talented developer may not create the perfect prompt on their first attempt,
    so be prepared for the reality that you may need *dozens* of attempts to achieve
    the desired goal.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4083d7c372cb4ac15b64bd8af2107112.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
- en: Building data-based applications is always an iterative process. [Public domain](https://commons.wikimedia.org/wiki/File:CRISP-DM_Process_Diagram.png)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: It’s always better to understand things through examples. Let’s start building
    a **system to extract information from a job description**. The sample job description
    we’ll be using in the examples is the following Machine Learning Engineer job
    posting from LinkedIn.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2d4285bb3456098a7f92e0604ba754c5.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
- en: Sample job description. Screenshot of the [LinkedIn job page](https://www.linkedin.com/jobs/)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: The initial prompt can be as simple as asking the model to extract specific
    information. Additionally, I’ll use delimiters (you can learn more about it in
    the [ChatGPT Prompt Engineering for Developers course](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)
    I will mention later). While it’s unlikely that a local application would be susceptible
    to [prompt injection attacks](https://learnprompting.org/docs/prompt_hacking/injection),
    it’s just good practice.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3f70008e054894ce2493fe290b9c3ad0.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
- en: Output for a prompt v1\. Image by Author created using [ChatGPT](https://chat.openai.com/chat)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Hmm, that’s not very helpful. We need to be more specific about what we want
    from the model. Let’s ask it to extract the job title, company name, key skills
    required, and a summarized job description.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember that this is just an example, and you can design your prompts to extract
    as much information as you want: degree, years of experience required, location,
    etc.'
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/f9638fb4a5327f81e5a5cf32ff957ffb.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
- en: Output for a prompt v2\. Image by Author created using [ChatGPT](https://chat.openai.com/chat)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Looking better! To make the output more compact and concise, let’s ask the model
    to output skills as a list and a more brief summary of the job description.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c77323df87ea345febfaa32f5f4bf160.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
- en: Output for a prompt v3\. Image by Author created using [ChatGPT](https://chat.openai.com/chat)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: It’s a significant improvement from our initial attempt, isn’t it? And we accomplish
    this in just two iterations! So, don’t lose hope when things don’t go smoothly
    initially. Keep guiding the model, experiment, and you’ll certainly achieve success.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Asking for a Structural Output
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The second point I would like to discuss is asking the model to output results
    in some expected structural format. While it may not be as critical for interacting
    with LLM through the web interface (e.g. as we do with ChatGPT), it becomes **extremely
    useful for LLM-based applications** since the process of parsing the results is
    much easier.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我想讨论的第二点是要求模型以某种预期的结构化格式输出结果。虽然这对通过网页界面与 LLM 交互（例如我们与 ChatGPT 的方式）可能不是那么关键，但对于基于
    LLM 的应用程序来说是**极其有用的**，因为解析结果的过程要容易得多。
- en: One common practice is to use formats like JSON or XML and define specific keys
    to organize output data. Let’s modify our prompt to show the model expected JSON
    structure.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的做法是使用 JSON 或 XML 等格式，并定义特定的键来组织输出数据。让我们修改提示以展示模型预期的 JSON 结构。
- en: '![](../Images/7ec32d518783fe76a5e156fe8e630909.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7ec32d518783fe76a5e156fe8e630909.png)'
- en: Output for a prompt v4, asking for JSON output. Image by Author created using
    [ChatGPT](https://chat.openai.com/chat)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对于提示 v4 的输出，要求 JSON 输出。由 [ChatGPT](https://chat.openai.com/chat) 创作的作者提供的图像
- en: Such output is much easier to parse and process in the following logic of your
    application.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的输出更容易在应用程序的后续逻辑中解析和处理。
- en: It’s worth saying a few words about the development of this direction. Some
    tools are aiming to strictly fit the model’s output into a given format, which
    can be extremely useful for some tasks. Just look at the examples below!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 值得提及的是这个方向的发展。一些工具旨在严格将模型的输出适配到给定的格式，这对某些任务非常有用。只需看看下面的示例！
- en: One of the possible applications is the generation of a large amount of content
    in a specific format (e.g. game characters information using [guidance](https://github.com/microsoft/guidance)).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个可能的应用是生成特定格式的大量内容（例如，使用 [guidance](https://github.com/microsoft/guidance)
    的游戏角色信息）。
- en: '![](../Images/947eb4216ade29b99b26d82cb16f0ca2.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/947eb4216ade29b99b26d82cb16f0ca2.png)'
- en: Generating game character info in JSON. Gif from [guidance GitHub repo](https://github.com/microsoft/guidance)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 生成 JSON 格式的游戏角色信息。来自 [guidance GitHub 仓库](https://github.com/microsoft/guidance)
    的 gif
- en: Languages like [LMQL](https://lmql.ai/) bring a programming-like approach to
    prompting language models. As these tools continue to evolve and improve, they
    have the potential to revolutionize how we interact with LLMs, resulting in more
    accurate and structured responses.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 像 [LMQL](https://lmql.ai/) 这样的语言为提示语言模型引入了类似编程的方法。随着这些工具的不断发展和改进，它们有可能彻底改变我们与
    LLM 的互动方式，从而提供更准确和结构化的响应。
- en: '![](../Images/5fe7d232aafae7011bd6de1799076779.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5fe7d232aafae7011bd6de1799076779.png)'
- en: LMQL query example. Screenshot of the [LMQL webpage, see more examples here](https://lmql.ai/)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: LMQL 查询示例。请参阅 [LMQL 网页，更多示例请见此处](https://lmql.ai/) 的截图
- en: Chain-of-Thought Reasoning
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Chain-of-Thought 推理
- en: Chain-of-Thought (CoT) reasoning was discovered to be very helpful for tasks
    that require… well, reasoning. So if you have the opportunity to solve the task
    by breaking it into multiple simpler steps that can be a great approach for LLM.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Chain-of-Thought (CoT) 推理被发现对于需要……好吧，推理的任务非常有帮助。因此，如果你有机会通过将任务分解成多个更简单的步骤来解决问题，这对于
    LLM 来说可能是一个很好的方法。
- en: Take a look at the example from the original paper. By splitting the problem
    into smaller steps and providing explicit instructions, we can assist the model
    in producing correct outputs.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 看看原始论文中的示例。通过将问题拆分成更小的步骤并提供明确的指示，我们可以帮助模型生成正确的输出。
- en: '![](../Images/8ed7855cdb779bf6d4e88425bf2cbcfe.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8ed7855cdb779bf6d4e88425bf2cbcfe.png)'
- en: Introducing CoT prompting. Figure 1 from the [Chain-of-Thought Prompting Elicits
    Reasoning in LLMs paper](https://arxiv.org/pdf/2201.11903.pdf)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍 CoT 提示。来自 [Chain-of-Thought Prompting Elicits Reasoning in LLMs 论文](https://arxiv.org/pdf/2201.11903.pdf)
    的图 1
- en: Interestingly, it emerges later that appending a straightforward and *magic*
    **“let’s think step by step”** at the end of a prompt can improve results — this
    technique is known as *zero-shot CoT*. So, compose prompts that allow the model
    to “think out loud” since it does not have any other ability to express thoughts
    other than generate tokens.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，后来发现，在提示的末尾附加一个简单的且*神奇的* **“让我们一步一步思考”** 可以改善结果——这种技巧被称为 *零-shot CoT*。因此，构建允许模型“思考过程”的提示是很有帮助的，因为模型没有其他表达思想的能力，除了生成标记。
- en: The best zero-shot CoT prompt so far is “**Let’s work this out in a step by
    step way to be sure we have the right answer**”.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 目前最佳的零-shot CoT 提示是“**让我们一步一步地解决这个问题，以确保我们得到正确的答案**”。
- en: '![](../Images/d9ad914d665075aee6752b6276e50124.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9ad914d665075aee6752b6276e50124.png)'
- en: Best zero-shot prompts. Table 7 from the [LLMs Are Human-Level Prompt Engineers
    paper](https://arxiv.org/pdf/2211.01910.pdf)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳零样本提示。来自[LLMs 是人类水平的提示工程师论文](https://arxiv.org/pdf/2211.01910.pdf)的表7
- en: 'More sophisticated approaches to solving even more complex tasks are now being
    actively developed. While they significantly outperform in some scenarios, their
    practical usage remains somewhat limited. I will mention two such techniques:
    *self-consistency* and the *Tree of Thoughts*.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 更复杂的解决方案正在积极开发中。虽然它们在某些场景中显著超越其他方法，但其实际应用仍然有限。我将提到两种这样的技术：*自一致性*和*思维树*。
- en: The authors of the [self-consistency paper](https://arxiv.org/pdf/2203.11171.pdf)
    offered the following approach. Instead of just relying on the initial model output,
    they suggested sampling multiple times and aggregating the results through majority
    voting. By relying on both intuition and the success of [ensembles](https://en.wikipedia.org/wiki/Ensemble_learning)
    in classical machine learning, this technique enhances the model’s robustness.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[自一致性论文](https://arxiv.org/pdf/2203.11171.pdf)的作者提出了以下方法。他们建议不要仅仅依赖于初始模型输出，而是通过多次采样并通过多数投票来聚合结果。通过依赖直觉和[集成方法](https://en.wikipedia.org/wiki/Ensemble_learning)在经典机器学习中的成功，这种技术增强了模型的鲁棒性。'
- en: '![](../Images/c7c6be883fb384c6a33edc479af020de.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c7c6be883fb384c6a33edc479af020de.png)'
- en: Self-consistency. Figure 1 from the [Self-Consistency Improves CoT Reasoning
    in Language Models paper](https://arxiv.org/pdf/2203.11171.pdf)
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 自一致性。来自[自一致性改进语言模型中的链式推理论文](https://arxiv.org/pdf/2203.11171.pdf)的图1
- en: You can also apply self-consistency without implementing the aggregation step.
    For tasks with short outputs ask the model to **suggest several options** and
    choose the best one.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在不实施聚合步骤的情况下应用自一致性。对于短输出的任务，要求模型**建议几个选项**并选择最佳选项。
- en: Tree of Thoughts (ToT) takes this concept a stride further. It puts forward
    the idea of applying tree-search algorithms for the model’s “reasoning thoughts”,
    essentially backtracking when it stumbles upon poor assumptions.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 思维树（ToT）将这一概念进一步扩展。它提出了为模型的“推理思维”应用树搜索算法的想法，当模型遇到不良假设时，实际上是回溯。
- en: '![](../Images/a0fb05671b6dee06c9e97bfb2c687e18.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a0fb05671b6dee06c9e97bfb2c687e18.png)'
- en: 'Tree of Thoughts. Figure 1 from the [Tree of Thoughts: Deliberate Problem Solving
    with LLMs paper](https://arxiv.org/pdf/2305.10601.pdf)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 思维树。来自[思维树：使用LLMs进行深思熟虑问题解决论文](https://arxiv.org/pdf/2305.10601.pdf)的图1
- en: If you are interested, check out [Yannic Kilcher’s video with a ToT paper review](https://www.youtube.com/watch?v=ut5kp56wW_4).
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你感兴趣，可以查看[Yannic Kilcher的ToT论文评论视频](https://www.youtube.com/watch?v=ut5kp56wW_4)。
- en: For our particular scenario, utilizing Chain-of-Thought reasoning is not necessary,
    yet we can prompt the model to tackle the summarization task in two phases. Initially,
    it can condense the entire job description, and then summarize the derived summary
    with a focus on job responsibilities.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的具体场景，利用链式思维推理并非必要，但我们可以将模型的总结任务分为两个阶段。最初，它可以概括整个职位描述，然后再对得出的总结进行集中于职位职责的总结。
- en: '![](../Images/8c95872561a59e8ab6fde59c6ae006c2.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8c95872561a59e8ab6fde59c6ae006c2.png)'
- en: Output for a prompt v5, containing step-by-step instructions. Image by Author
    created using [ChatGPT](https://chat.openai.com/chat)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 带有逐步指令的提示v5的输出。由[ChatGPT](https://chat.openai.com/chat)创建的作者图像
- en: In this particular example, the results did not show significant changes, but
    this approach works very well for most tasks.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个特定的例子中，结果没有显示出显著的变化，但这种方法对大多数任务非常有效。
- en: Few-shot Learning
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 少样本学习
- en: The last technique we will cover is called *few-shot learning*, also known as
    *in-context learning*. It’s as simple as incorporating several examples into your
    prompt to provide the model with a clearer picture of your task.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将介绍的最后一种技术叫做*少样本学习*，也称为*上下文学习*。它的简单之处在于将几个示例纳入提示中，以便为模型提供更清晰的任务描述。
- en: These examples should not only be **relevant** to your task but also **diverse**
    to encapsulate the variety in your data. “Labeling” data for few-shot learning
    might be a bit more challenging when you’re using CoT, particularly if your pipeline
    has many steps or your inputs are long. However, typically, the results make it
    worth the effort. Also, keep in mind that labeling a few examples is far less
    expensive than labeling an entire training/testing set as in traditional ML model
    development.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例不仅要**与任务相关**，还要**多样化**，以涵盖数据的多样性。对于少量样本学习，使用 CoT 可能会有些挑战，特别是当你的流程有很多步骤或输入较长时。然而，通常来说，结果是值得这些努力的。另外，请记住，标记少量示例的成本远低于在传统机器学习模型开发中标记整个训练/测试集的成本。
- en: If we add an example to our prompt, it will understand the requirements even
    better. For instance, if we demonstrate that we’d prefer the final summary in
    bullet-point format, the model will mirror our template.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在提示中添加一个示例，它将更好地理解要求。例如，如果我们表明我们希望最终总结以要点形式呈现，模型将会按照我们的模板进行回应。
- en: 'This prompt is quite overwhelming, but don’t be afraid: it is just a previous
    prompt (v5) and one labeled example with another job description in the `For example:
    ''input description'' -> ''output JSON''` format.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '这个提示可能会让人感到有些压倒，但不要害怕：它只是一个以前的提示（v5）和一个标记的示例，采用 `For example: ''input description''
    -> ''output JSON''` 格式。'
- en: '![](../Images/2be54202a408a5d5282c61effc8f4fe8.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2be54202a408a5d5282c61effc8f4fe8.png)'
- en: Output for a prompt v6, containing an example. Image by Author created using
    [ChatGPT](https://chat.openai.com/chat)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 包含一个示例的提示 v6 输出。图像由作者使用[ChatGPT](https://chat.openai.com/chat)创建
- en: Summarizing Best Practices
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结最佳实践
- en: 'To summarize the best practices for prompt engineering, consider the following:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 总结提示工程的最佳实践，请考虑以下几点：
- en: '**Don’t be afraid to experiment**. Try different approaches and iterate gradually,
    correcting the model and taking small steps at a time;'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不要害怕实验**。尝试不同的方法，逐步迭代，纠正模型并一次进行小的步骤；'
- en: '**Use separators** in input (e.g. <>) and ask for a **structured output** (e.g.
    JSON);'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在输入中**使用分隔符**（例如 <>），并要求**结构化输出**（例如 JSON）；
- en: '**Provide a list of actions to complete the task**. Whenever feasible, offer
    the model a set of actions and let it output its “internal thoughts”;'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提供完成任务的行动列表**。尽可能地，向模型提供一组行动，并让它输出“内部想法”；'
- en: In case of short outputs **ask for multiple suggestions**;
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果输出较短，**请求多个建议**；
- en: '**Provide examples**. If possible, show the model several diverse examples
    that represent your data with the desired output.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提供示例**。如果可能，向模型展示几个代表数据的多样化示例，并显示期望的输出。'
- en: I would say that this framework offers a sufficient basis for automating a wide
    range of day-to-day tasks, like information extraction, summarization, text generation
    such as emails, etc. However, in a production environment, it is still possible
    to further optimize models by [fine-tuning them](https://magazine.sebastianraschka.com/p/finetuning-large-language-models)
    on specific datasets to further enhance performance. Additionally, there is rapid
    development in the [plugins](https://openai.com/blog/chatgpt-plugins) and [agents](https://www.pinecone.io/learn/langchain-agents/),
    but that’s a whole different story altogether.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这个框架为自动化各种日常任务提供了足够的基础，例如信息提取、总结、文本生成（如电子邮件）等。然而，在生产环境中，仍然可以通过在特定数据集上[微调模型](https://magazine.sebastianraschka.com/p/finetuning-large-language-models)来进一步优化性能。此外，[插件](https://openai.com/blog/chatgpt-plugins)和[代理](https://www.pinecone.io/learn/langchain-agents/)的快速发展也值得关注，但那是完全不同的话题。
- en: Prompt Engineering Course by DeepLearning.AI and OpenAI
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DeepLearning.AI 和 OpenAI 的提示工程课程
- en: Along with the earlier-mentioned [talk by Andrej Karpathy](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2),
    this blog post draws its inspiration from the [ChatGPT Prompt Engineering for
    Developers course by DeepLearning.AI and OpenAI](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/).
    It’s absolutely free, takes just a couple of hours to complete, and, my personal
    favorite, it enables you to experiment with the OpenAI API without even signing
    up!
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 除了之前提到的[Andrej Karpathy 的讲座](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2)，这篇博客文章还从[DeepLearning.AI
    和 OpenAI 的 ChatGPT 提示工程课程](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)中汲取了灵感。该课程完全免费，完成仅需几小时，并且我个人非常喜欢的一点是，它允许你在无需注册的情况下实验
    OpenAI API！
- en: That’s a great playground for experimenting, so definitely check it out.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个很好的实验场地，所以一定要去看看。
- en: Building the LLM-based Application with OpenAI API and Streamlit
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 OpenAI API 和 Streamlit 构建基于 LLM 的应用程序
- en: Wow, we covered quite a lot of information! Now, let’s move forward and start
    building the application using the knowledge we have gained.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 哇，我们涵盖了很多信息！现在，让我们继续前进，开始使用我们获得的知识构建应用程序吧。
- en: Generating OpenAI Key
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成 OpenAI 密钥
- en: To get started, you’ll need to register an OpenAI account and create your API
    key. [OpenAI currently offers **$5 of free credit for 3 months**](https://openai.com/pricing#:~:text=Simple%20and%20flexible-,Start%20for%20free,-Start%20experimenting%20with)
    to every individual. Follow the [introduction to the OpenAI API](https://platform.openai.com/docs/api-reference/introduction)
    page to register your account and [generate your API key](https://platform.openai.com/docs/api-reference/introduction).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用，你需要注册一个 OpenAI 账户并创建你的 API 密钥。[OpenAI 目前为每个人提供**3 个月的 $5 免费信用额**](https://openai.com/pricing#:~:text=Simple%20and%20flexible-,Start%20for%20free,-Start%20experimenting%20with)。请参考[OpenAI
    API 入门介绍](https://platform.openai.com/docs/api-reference/introduction)页面来注册你的账户和[生成你的
    API 密钥](https://platform.openai.com/docs/api-reference/introduction)。
- en: Once you have a key, create an `OPENAI_API_KEY` [environment variable](https://www.twilio.com/blog/how-to-set-environment-variables-html)
    to access it in the code with `os.getenv('OPENAI_API_KEY')`.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了密钥，创建一个`OPENAI_API_KEY` [环境变量](https://www.twilio.com/blog/how-to-set-environment-variables-html)以便通过`os.getenv('OPENAI_API_KEY')`在代码中访问它。
- en: Estimating the Costs with Tokenizer Playground
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用标记器实验室估算成本
- en: At this stage, you might be curious about how much you can do with just a free
    trial and what options are available after the initial three months. It’s a pretty
    good question to ask, especially when you consider that [LLMs cost millions of
    dollars](https://medium.com/towards-data-science/behind-the-millions-estimating-the-scale-of-large-language-models-97bd7287fb6b)!
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，你可能会好奇仅凭免费试用可以做多少事情，以及初始三个月后有哪些选项。这是个很好的问题，特别是当你考虑到[LLMs 需要花费数百万美元](https://medium.com/towards-data-science/behind-the-millions-estimating-the-scale-of-large-language-models-97bd7287fb6b)！
- en: Of course, these millions are about training. It turns out that the inference
    requests are quite affordable. While GPT-4 may be perceived as expensive (although
    the price is likely to decrease), `gpt-3.5-turbo` (the model behind default ChatGPT)
    is still sufficient for the majority of tasks. In fact, OpenAI has done an incredible
    engineering job, given how inexpensive and fast these models are now, considering
    their original size in billions of parameters.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这些数百万是关于训练的。事实证明，推理请求非常实惠。虽然 GPT-4 可能被认为比较贵（尽管价格可能会下降），但`gpt-3.5-turbo`（默认
    ChatGPT 背后的模型）仍然足以应对大多数任务。实际上，考虑到这些模型的原始参数量以亿计，OpenAI 做了一个令人难以置信的工程工作，因为这些模型现在既便宜又快速。
- en: The `gpt-3.5-turbo` model comes at a cost of $0.002 per 1,000 tokens.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '`gpt-3.5-turbo` 模型的费用是每 1,000 个标记 $0.002。'
- en: But how much is it? Let’s see. First, we need to know what is a token. In simple
    terms, a token refers to a part of a word. In the context of the English language,
    you can expect **around 14 tokens for every 10 words**.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，具体多少钱呢？让我们看看。首先，我们需要了解什么是标记。简单来说，标记指的是单词的一部分。在英语中，你可以预期**每 10 个单词大约有 14 个标记**。
- en: To get a more accurate estimation of the number of tokens for your specific
    task and prompt, the best approach is to give it a try! Luckily, OpenAI provides
    a [tokenizer playground](https://platform.openai.com/tokenizer) that can help
    you with this.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更准确地估算你特定任务和提示的标记数量，最好的方法是亲自尝试！幸运的是，OpenAI 提供了一个[标记器实验室](https://platform.openai.com/tokenizer)来帮助你。
- en: 'Side note: Tokenization for Different Languages'
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附注：不同语言的标记化
- en: Due to the widespread use of English on the Internet, this language benefits
    from the most optimal tokenization. As highlighted in the [“All languages are
    not tokenized equal”](https://blog.yenniejun.com/p/all-languages-are-not-created-tokenized)
    blog post, tokenization is not a uniform process across languages, and certain
    languages may require a greater number of tokens for representation. Keep this
    in mind if you want to build an application that involves prompts in multiple
    languages, e.g. for translation.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 由于英语在互联网的广泛使用，这种语言的标记化效果最好。正如在[“所有语言的标记化并不相等”](https://blog.yenniejun.com/p/all-languages-are-not-created-tokenized)博客文章中强调的那样，标记化在不同语言中并不统一，某些语言可能需要更多的标记来表示。如果你想构建一个涉及多语言提示的应用程序，比如翻译，请记住这一点。
- en: To illustrate this point, let’s take a look at the tokenization of [pangrams](https://clagnut.com/blog/2380)
    in different languages. In this toy example, English required 9 tokens, French
    — 12, Bulgarian — 59, Japanese — 72, and Russian — 73.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这一点，我们来看看不同语言中 [全句](https://clagnut.com/blog/2380) 的分词情况。在这个玩具示例中，英语需要 9
    个标记，法语 — 12，保加利亚语 — 59，日语 — 72，俄语 — 73。
- en: '![](../Images/ff25f16bfa9d4e539d0b727755bced5c.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ff25f16bfa9d4e539d0b727755bced5c.png)'
- en: Tokenization for different languages. Screenshot of the [OpenAI tokenizer playground](https://platform.openai.com/tokenizer)
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 不同语言的分词。截图来自 [OpenAI 分词器游乐场](https://platform.openai.com/tokenizer)
- en: Cost vs Performance
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 成本与性能
- en: As you may have noticed, prompts can become quite lengthy, especially when incorporating
    examples. By increasing the length of the prompt, we potentially enhance the quality,
    but the cost grows at the same time as we use more tokens.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能注意到的那样，提示可能会变得相当长，尤其是在包含示例时。通过增加提示的长度，我们可能会提高质量，但同时随着使用更多标记，成本也会增加。
- en: Our latest prompt (v6) consists of approximately 1.5k tokens.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最新的提示（v6）大约由 1.5k 个标记组成。
- en: '![](../Images/0d86ff60b17ea35cb57608a7b0e76e0a.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0d86ff60b17ea35cb57608a7b0e76e0a.png)'
- en: Tokenization of the prompt v6\. Screenshot of the [OpenAI tokenizer playground](https://platform.openai.com/tokenizer)
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 提示的分词 v6。截图来自 [OpenAI 分词器游乐场](https://platform.openai.com/tokenizer)
- en: Considering that the output length is typically the same range as the input
    length, we can estimate an average of around 3k tokens per request (*input tokens
    + output tokens*). By multiplying this number by the initial cost, we find that
    **each request is about $0.006 or 0.6 cents**, which is quite affordable.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到输出长度通常与输入长度相同，我们可以估计每次请求的平均标记数约为 3k 个（*输入标记 + 输出标记*）。通过将这个数字乘以初始费用，我们发现**每次请求约为
    0.006 美元或 0.6 美分**，这相当实惠。
- en: Even if we consider a slightly higher cost of 1 cent per request (equivalent
    to roughly 5k tokens), you would still be able to make **100 requests for just
    $1**. Additionally, OpenAI offers the flexibility [to set both soft and hard limits](https://openai.com/pricing#:~:text=How%20can%20I%20manage%20my%20spending%3F).
    With soft limits, you receive notifications when you approach your defined limit,
    while hard limits restrict you from exceeding the specified threshold.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们考虑到每次请求稍高的费用为1美分（相当于大约5k个标记），你仍然可以以**仅需1美元进行100次请求**。此外，OpenAI 提供了[设置软限制和硬限制](https://openai.com/pricing#:~:text=How%20can%20I%20manage%20my%20spending%3F)的灵活性。软限制会在你接近定义的限制时发出通知，而硬限制则会限制你超出指定阈值。
- en: For local use of your LLM application, you can comfortably configure a hard
    limit of $1 per month, ensuring that you remain within budget while enjoying the
    benefits of the model.
  id: totrans-117
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于本地使用的 LLM 应用程序，你可以舒适地配置每月 1 美元的硬限制，确保在预算范围内享受模型的好处。
- en: Streamlit App Template
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Streamlit 应用模板
- en: Now, let’s build a web interface to interact with the model programmatically
    eliminating the need to manually copy prompts each time. We will do this with
    [Streamlit](https://streamlit.io/).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们构建一个网页界面，以编程方式与模型互动，消除每次手动复制提示的需要。我们将使用 [Streamlit](https://streamlit.io/)
    来完成这一任务。
- en: Streamlit is a Python library that allows you to create simple web interfaces
    without the need for HTML, CSS, and JavaScript. It is beginner-friendly and enables
    the creation of browser-based applications using minimal Python knowledge. Let’s
    now create a simple template for our LLM-based application.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: Streamlit 是一个 Python 库，它允许你创建简单的网页界面，无需使用 HTML、CSS 和 JavaScript。它对初学者友好，并允许使用最少的
    Python 知识创建基于浏览器的应用程序。现在我们来创建一个简单的模板，用于基于 LLM 的应用程序。
- en: Firstly, we need the logic that will handle the communication with the OpenAI
    API. In the example below, I consider `generate_prompt()`function to be defined
    and return the prompt for a given input text (e.g. similar to what you saw before).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要处理与 OpenAI API 通信的逻辑。在下面的示例中，我假设 `generate_prompt()` 函数已定义并返回给定输入文本的提示（例如，类似于你之前看到的）。
- en: And that’s it! Know more about different parameters in [OpenAI’s documentation](https://platform.openai.com/docs/api-reference/chat/create#:~:text=given%20chat%20conversation.-,Request%20body,-model),
    but things work well just out of the box.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！了解更多关于不同参数的信息，请参考 [OpenAI 的文档](https://platform.openai.com/docs/api-reference/chat/create#:~:text=given%20chat%20conversation.-,Request%20body,-model)，但默认设置已经很好。
- en: Having this code, we can design a simple web app. We need a field to enter some
    text, a button to process it, and a couple of output widgets. I prefer to have
    access to both the full model prompt and output for debugging and exploring reasons.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些代码，我们可以设计一个简单的网页应用程序。我们需要一个输入文本的字段，一个处理文本的按钮，以及几个输出小部件。我更倾向于访问完整的模型提示和输出，以便进行调试和探索原因。
- en: The code for the entire application will look something like this and can be
    found in [this GitHub repository](https://github.com/Winston-503/streamlit_app_template).
    I have added a placeholder function called `toy_ask_chatgpt()` since sharing the
    OpenAI key is not a good idea. Currently, this application simply copies the prompt
    into the output.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 整个应用程序的代码大致如下，可以在[这个 GitHub 仓库](https://github.com/Winston-503/streamlit_app_template)中找到。由于共享
    OpenAI 密钥不是一个好主意，我添加了一个名为`toy_ask_chatgpt()`的占位符函数。目前，这个应用程序只是将提示复制到输出中。
- en: Without defining functions and placeholders, it is only about 50 lines of code!
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不定义函数和占位符，这只有大约50行代码！
- en: And thanks to a [recent update in Streamlit it now allows embed it](https://docs.streamlit.io/streamlit-community-cloud/get-started/embed-your-app)
    right in this article! So you should be able to see it right below.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 幸好[Streamlit 最近的更新现在允许嵌入它](https://docs.streamlit.io/streamlit-community-cloud/get-started/embed-your-app)到这篇文章中！所以你应该能够在下方看到它。
- en: Now you see how easy it is. If you wish, you can [deploy your app with Streamlit
    Cloud](https://docs.streamlit.io/streamlit-community-cloud/get-started/deploy-an-app).
    But be careful, since every request costs you money if you put your API key there!
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以看到这有多么简单。如果你愿意，你可以[使用 Streamlit Cloud 部署你的应用程序](https://docs.streamlit.io/streamlit-community-cloud/get-started/deploy-an-app)。但要小心，因为如果你在其中放置你的
    API 密钥，每个请求都会花费你金钱！
- en: Conclusion
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this blog post, I listed several best practices for prompt engineering. We
    discussed iterative prompt development, the use of separators, requesting structural
    output, Chain-of-Thought reasoning, and few-shot learning. I also provided you
    with a template to build a simple web app using Streamlit in under 100 lines of
    code. Now, it’s your turn to come up with an exciting project idea and turn it
    into reality!
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我列出了几种提示工程的最佳实践。我们讨论了迭代提示开发、使用分隔符、请求结构化输出、思维链推理以及少量示例学习。我还提供了一个模板，用于在不到100行代码的情况下使用
    Streamlit 构建一个简单的网页应用程序。现在，轮到你来提出一个令人兴奋的项目创意并将其变为现实了！
- en: It’s truly amazing how modern tools allow us to create complex applications
    in just a few hours. Even without extensive programming knowledge, proficiency
    in Python, or a deep understanding of machine learning, you can quickly build
    something useful and automate some tasks.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现代工具允许我们在仅仅几小时内创建复杂的应用程序，这真是令人惊叹。即使没有丰富的编程知识、Python 熟练度或对机器学习的深刻理解，你也可以快速构建一些有用的东西并自动化一些任务。
- en: Don’t hesitate to ask me questions if you’re a beginner and want to create a
    similar project. I’ll be more than happy to assist you and respond as soon as
    possible. Best of luck with your projects!
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是初学者并且想创建类似的项目，请随时向我提问。我将非常乐意协助你，并尽快回复。祝你的项目好运！
- en: Resources
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源
- en: 'Here are my other articles about LLMs that may be useful to you. I have already
    covered:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我关于 LLM 的其他文章，希望对你有所帮助。我已经涵盖了：
- en: '[Estimating the Scale of Large Language Models](/behind-the-millions-estimating-the-scale-of-large-language-models-97bd7287fb6b):
    what are LLMs, how are they trained, and how much data and compute do they need;'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[估算大语言模型的规模](/behind-the-millions-estimating-the-scale-of-large-language-models-97bd7287fb6b)：LLM
    是什么，如何训练，它们需要多少数据和计算资源；'
- en: '[Using ChatGPT for Debugging](/using-chatgpt-for-efficient-debugging-fc9e065b7856#da94-27cac6b3f550):
    how to use LLMs for debugging and code generation.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 ChatGPT 进行调试](/using-chatgpt-for-efficient-debugging-fc9e065b7856#da94-27cac6b3f550)：如何使用
    LLM 进行调试和代码生成。'
- en: 'You can be also interested in:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还会对以下内容感兴趣：
- en: Free [Learn Prompting course](https://learnprompting.org/) to gain a deeper
    understanding of prompting and various techniques associated with it;
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 免费的[Learn Prompting 课程](https://learnprompting.org/)，以深入了解提示和相关技术；
- en: Recently released [short courses by DeepLearning.AI](https://www.deeplearning.ai/short-courses/)
    to build applications with OpenAI API
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最近发布的[DeepLearning.AI 短期课程](https://www.deeplearning.ai/short-courses/)，用于构建
    OpenAI API 应用程序
- en: Thank you for reading!
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 感谢阅读！
- en: I hope these materials were useful to you. [Follow me on Medium](https://medium.com/@andimid)
    to get more articles like this.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 希望这些材料对你有所帮助。[在 Medium 上关注我](https://medium.com/@andimid)，以获取更多类似的文章。
- en: If you have any questions or comments, I will be glad to get any feedback. Ask
    me in the comments, or connect via [LinkedIn](https://www.linkedin.com/in/andimid/)
    or [Twitter](https://twitter.com/dimid_ml).
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你有任何问题或评论，我会很高兴收到任何反馈。可以在评论中问我，或通过[LinkedIn](https://www.linkedin.com/in/andimid/)或[Twitter](https://twitter.com/dimid_ml)联系我。
- en: To support me as a writer and to get access to thousands of other Medium articles,
    get Medium membership using [my referral link](https://medium.com/@andimid/membership)
    (no extra charge for you).
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持我作为作者并访问其他成千上万篇Medium文章，请通过[我的推荐链接](https://medium.com/@andimid/membership)获取Medium会员（对你没有额外费用）。
