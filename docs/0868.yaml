- en: Why are Randomized Experiments the Gold Standard in Causal Inference?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/why-are-randomized-experiments-the-gold-standard-in-causal-inference-f3fa240a1d02?source=collection_archive---------14-----------------------#2023-03-07](https://towardsdatascience.com/why-are-randomized-experiments-the-gold-standard-in-causal-inference-f3fa240a1d02?source=collection_archive---------14-----------------------#2023-03-07)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Understanding the identifying assumptions in experiments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@murat.unal?source=post_page-----f3fa240a1d02--------------------------------)[![Murat
    Unal](../Images/9f00db7597d7ece01213a6b0589c87d8.png)](https://medium.com/@murat.unal?source=post_page-----f3fa240a1d02--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f3fa240a1d02--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f3fa240a1d02--------------------------------)
    [Murat Unal](https://medium.com/@murat.unal?source=post_page-----f3fa240a1d02--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F15a64c9fc55d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-are-randomized-experiments-the-gold-standard-in-causal-inference-f3fa240a1d02&user=Murat+Unal&userId=15a64c9fc55d&source=post_page-15a64c9fc55d----f3fa240a1d02---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f3fa240a1d02--------------------------------)
    ·7 min read·Mar 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff3fa240a1d02&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-are-randomized-experiments-the-gold-standard-in-causal-inference-f3fa240a1d02&user=Murat+Unal&userId=15a64c9fc55d&source=-----f3fa240a1d02---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3fa240a1d02&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-are-randomized-experiments-the-gold-standard-in-causal-inference-f3fa240a1d02&source=-----f3fa240a1d02---------------------bookmark_footer-----------)![](../Images/b84e56591feb7ece2a967855fe86a5e9.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [takaharu SAWA](https://unsplash.com/@haru88?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Causal inference without assumptions is impossible. Every available method requires
    untestable assumptions to establish causality from observed associations in the
    data. As such, stating the identifying assumptions and defending them is the most
    critical aspect of causal inference, yet it is also the most neglected one.
  prefs: []
  type: TYPE_NORMAL
- en: In my previous article we kicked off the discussion around this topic by describing
    what identification is and why it takes precedence over estimation in causal inference.
    As a reminder, identification, essentially consists of clearly stating the assumptions
    required for statistical estimates obtained from the data to be given a causal
    interpretation as well as advocating for them in our causal analysis. In what
    follows we discuss identification in randomized experiments a.k.a. the gold standard
    among all the identification strategies in causal inference.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/identification-the-key-to-credible-causal-inference-c3023143349e?source=post_page-----f3fa240a1d02--------------------------------)
    [## Identification: The Key to Credible Causal Inference'
  prefs: []
  type: TYPE_NORMAL
- en: Improve your causal IQ and build trust in your causal inference by mastering
    identification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/identification-the-key-to-credible-causal-inference-c3023143349e?source=post_page-----f3fa240a1d02--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: What gives experiments a special status among other identification strategies?
    It is two things. First, well-conducted experiments require the minimum set of
    identifying assumptions to establish causality. Second, these assumptions are
    much more plausible than those required by other methods. The combination of these
    two facts increase the credibility of the causal inference in randomized experiments.
  prefs: []
  type: TYPE_NORMAL
- en: 'To aid in discussion, let’s again consider a simple case with two treatment
    conditions described by a binary random variable, *Ti=[0,1]*, and denoting the
    outcome by *Yi.* We are interested in finding the average treatment effect (ATE),
    which is the difference between the expected values:'
  prefs: []
  type: TYPE_NORMAL
- en: where *Yi1* denote the potential outcome for subject *i* if they are treated
    and *Yi0* denote the potential outcome for subject *i* if they are not*.* If it
    is not clear what potential outcomes means, I highly suggest you read the article
    linked above. You will see a concrete example and it will help you follow the
    rest of this article.
  prefs: []
  type: TYPE_NORMAL
- en: Because we only have access to a sample from the population, we only observe
    the conditional expectations *E[Yi|Ti=1]* and *E[Yi|Ti=0]*, which are the expected
    outcomes among the treated and the control, respectively, we see in our data.
  prefs: []
  type: TYPE_NORMAL
- en: Now, to claim what we obtain by taking the differences of the conditional expectations
    is the ATE, our causal estimand, we need to show they are equivalent to the unconditional
    expectations. The way to do this is by making assumptions and convincing our audience
    about their plausibility in our specific context.
  prefs: []
  type: TYPE_NORMAL
- en: 'Identification Part 1: Stating the Assumptions'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In randomized experiments the identifying assumptions are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. Independence:** the potential outcomes are independent from treatment
    status.'
  prefs: []
  type: TYPE_NORMAL
- en: 2\. **SUTVA (Stable Unit Treatment Value Assumption):** (1) No interaction effects,
    meaning treatments received by one unit do not affect outcomes for another unit.
    (2) No hidden variations of treatment, only the level of the treatment applied
    to the specific subject potentially affects outcomes for that subject.
  prefs: []
  type: TYPE_NORMAL
- en: Technically, in addition to the two identifying assumptions, we also assume
    no systematic attrition among experiment subjects and absence of noncompliance.
  prefs: []
  type: TYPE_NORMAL
- en: 'With these assumptions we can write the expectations of the observed outcomes
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'This allows us to use the outcomes of the treated and control in our data to
    obtain the ATE:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another way to see these assumptions in action is to look at the following
    decomposition:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0eaf986824d3d5bdb5274c943cfecef1.png)'
  prefs: []
  type: TYPE_IMG
- en: The independence assumption effectively eliminates the Bias term and we are
    left with the ATT (average treatment effect on the treated), which amounts to
    the ATE.
  prefs: []
  type: TYPE_NORMAL
- en: 'Identification Part 2: Defending the Assumptions'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A direct consequence of this identification strategy is that it allows us to
  prefs: []
  type: TYPE_NORMAL
- en: assert that the treated and control groups will be identical in all aspects,
    observable and unobservable, except for the differences in treatment assignments.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, if we have a well-conducted experiment with no systematic attrition
    among subjects then convincing our audience about the validity of the identifying
    assumptions will be much easier.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make things concrete, let’s describe the relationship between the outcomes,
    *Yi*, the treatment *Ti*, and covariates *Xi* using a model and for simplicity
    let’s assume it is linear:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The *P* covariates, which may be very large, include observed or unobserved
    other linear effects on the outcome and *Bi* is the individual treatment effect,
    which is the difference between the two potential outcomes, *Yi1 — Yi0*. We don’t
    observe this effect, but subtracting the average outcomes among the controls from
    the average outcomes among the treatments gives us this:'
  prefs: []
  type: TYPE_NORMAL
- en: which shows that we get what we want through the difference in means when the
    means of all the other effects on the outcomes
  prefs: []
  type: TYPE_NORMAL
- en: are identical in the two groups.
  prefs: []
  type: TYPE_NORMAL
- en: This is the case of **perfect balance** and randomization guarantees it by construction,
    because it provides orthogonality of the treatment to the other *P* causes represented
    in our causal model. In other words, we know nothing was used in determining treatment
    assignments except a coin flip.
  prefs: []
  type: TYPE_NORMAL
- en: Still, there are threats to the **internal validity** of the experiments, which
    can undermine our causal inference. First, violation of SUTVA whereby subjects
    in the two groups interact with each other can happen in many social and economic
    applications. If that happens the comparisons we make would no longer between
    treated and control, but between treated and partially treated.
  prefs: []
  type: TYPE_NORMAL
- en: Second, ruling out confounding due to common causes is guaranteed in expectation,
    which means the probability that treatment and control only differ in treatment
    assignment and nothing else gets arbitrarily higher as the sample size increases.
    In a given sample, especially if it is small, the net effects of other causes
    might not be zero, and this can bias the ATE.
  prefs: []
  type: TYPE_NORMAL
- en: 'As such, it is always good practice to examine the balances in observables
    between treated and control in our sample before analyzing the experiment. Typically
    this is done by computing the normalized differences as a scale-free measure of
    the difference in distributions instead of the t-statistic. Specifically, for
    each covariate, we report the difference in averages by treatment status, scaled
    by the square root of the sum of the variances:'
  prefs: []
  type: TYPE_NORMAL
- en: where S1², S0² is the sample variance of the treated and control, respectively.
    As a rule of thumb, differences larger than 0.10, might indicate imbalance, which
    would call for covariate adjustment in the analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Notice, however, we have no way to test whether common unobservable causes are
    eliminated in our experiment. We simply assume if balance is achieved in observables
    it is plausible that it will hold in unobservables as well. But, this might not
    be the case, especially in small samples.
  prefs: []
  type: TYPE_NORMAL
- en: We also need to be mindful about the generalizability of experiment findings,
    i.e. their **external validity**. It is important to recognize that experiments
    allow us to identify the treatment effect within the population used in the study.
    Also, unless the experiment is designed for measuring long-term effects, the estimated
    ATE usually applies for the short-term. It is common to treat the estimates from
    an experiment as if it were the truth, not just in the study sample but more generally,
    but this might not be valid.
  prefs: []
  type: TYPE_NORMAL
- en: There are many cases where businesses decided to scale operations based on experiment
    findings in one market, sample or time period, and failed because those findings
    had not been proven to be generalizable. In general, to ensure valid extrapolation,
    we either need random sampling in addition to randomization of treatment or additional
    assumptions. For example, if we have an online experiment, to ensure that findings
    are generalizable to all users within a predetermined location, we need to eliminate
    day of the week and time of the day effects by sampling visitors randomly throughout
    the day as well as the week.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Causal inference is difficult due to its inherent uncertainty, and progress
    can be made so long we improve our understanding of the most critical part: identification.
    Randomized experiments require fewer identifying assumptions than any other identification
    strategy. What is more, these assumptions are much more plausible in experiments.
    These two traits together have earned experiments the gold standard status in
    causal inference. Nevertheless, experiments can still lack internal validity if
    they are not conducted properly, and generalizing experiment findings is challenging
    in its own ways.'
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading! I hope you felt it was worth your time.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I strive to write high quality and useful articles for practitioners on methods
    and applications in causal inference as well as marketing data science.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If you’re interested in these areas consider following me, and feel invited
    to share your comments/suggestions.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] L. Keele, [The Statistics of Causal Inference: A View from Political Methodology.](https://www.cambridge.org/core/journals/political-analysis/article/abs/statistics-of-causal-inference-a-view-from-political-methodology/314EFF877ECB1B90A1452D10D4E24BB3)
    (2015), *Political Analysis.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] A. Lewbel, [The Identification Zoo — Meanings of Identification in Econometrics.](https://www.aeaweb.org/articles?id=10.1257%2Fjel.20181361)
    (2019), *Journal of Economic Literature.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] G. W. Imbens and J. M. Wooldridge, [Recent Developments in the Econometrics
    of Program Evaluation](https://www.aeaweb.org/articles?id=10.1257%2Fjel.47.1.5),
    (2009), *Journal of Economic Literature.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] J. List, The Voltage Effect: How to Make Good Ideas Great and Great Ideas
    Scale, (2022).'
  prefs: []
  type: TYPE_NORMAL
