- en: 'XGBoost: The Definitive Guide (Part 1)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/xgboost-the-definitive-guide-part-1-cc24d2dcd87a?source=collection_archive---------4-----------------------#2023-08-09](https://towardsdatascience.com/xgboost-the-definitive-guide-part-1-cc24d2dcd87a?source=collection_archive---------4-----------------------#2023-08-09)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A step-by-step derivation of the popular XGBoost algorithm including a detailed
    numerical illustration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@roiyeho?source=post_page-----cc24d2dcd87a--------------------------------)[![Dr.
    Roi Yehoshua](../Images/905a512ffc8879069403a87dbcbeb4db.png)](https://medium.com/@roiyeho?source=post_page-----cc24d2dcd87a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cc24d2dcd87a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cc24d2dcd87a--------------------------------)
    [Dr. Roi Yehoshua](https://medium.com/@roiyeho?source=post_page-----cc24d2dcd87a--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3886620c5cf9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fxgboost-the-definitive-guide-part-1-cc24d2dcd87a&user=Dr.+Roi+Yehoshua&userId=3886620c5cf9&source=post_page-3886620c5cf9----cc24d2dcd87a---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cc24d2dcd87a--------------------------------)
    ·15 min read·Aug 9, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcc24d2dcd87a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fxgboost-the-definitive-guide-part-1-cc24d2dcd87a&user=Dr.+Roi+Yehoshua&userId=3886620c5cf9&source=-----cc24d2dcd87a---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcc24d2dcd87a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fxgboost-the-definitive-guide-part-1-cc24d2dcd87a&source=-----cc24d2dcd87a---------------------bookmark_footer-----------)![](../Images/6146a3f112054a1a9ea8ef91d58e7b4e.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Sam Battaglieri](https://unsplash.com/@st_b?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/_PXtCCQ4Dj0?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: XGBoost (short for eXtreme Gradient Boosting) is an open-source library that
    provides an optimized and scalable implementation of gradient boosted decision
    trees. It incorporates various software and hardware optimization techniques that
    allow it to deal with huge amounts of data.
  prefs: []
  type: TYPE_NORMAL
- en: Originally developed as a research project by Tianqi Chen and Carlos Guestrin
    in 2016 [1], XGBoost has become the go-to solution for solving supervised learning
    tasks on structured (tabular) data. It provides state-of-the-art results on many
    standard regression and classification tasks, and many Kaggle competition winners
    have used XGBoost as part of their winning solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Although significant progress has been made using deep neural networks for tabular
    data, they are still outperformed by XGBoost and other tree-based models on many
    standard benchmarks [2, 3]. In addition, XGBoost requires much less tuning than
    deep models.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main innovations of XGBoost with respect to other gradient boosting algorithms
    include:'
  prefs: []
  type: TYPE_NORMAL
- en: Clever regularization of the decision trees.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using second-order approximation to optimize…
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
