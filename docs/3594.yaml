- en: On Why Machines Can Think
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于机器为何能够思考
- en: 原文：[https://towardsdatascience.com/on-why-machines-can-think-40edafce293d?source=collection_archive---------2-----------------------#2023-12-06](https://towardsdatascience.com/on-why-machines-can-think-40edafce293d?source=collection_archive---------2-----------------------#2023-12-06)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/on-why-machines-can-think-40edafce293d?source=collection_archive---------2-----------------------#2023-12-06](https://towardsdatascience.com/on-why-machines-can-think-40edafce293d?source=collection_archive---------2-----------------------#2023-12-06)
- en: How can we think about **thinking** in the simplest way possible?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们如何以最简单的方式思考**思维**呢？
- en: '[](https://medium.com/@niya.stoimenova?source=post_page-----40edafce293d--------------------------------)[![Niya
    Stoimenova](../Images/122b1debc4ae3af4fdf4d78e36071b68.png)](https://medium.com/@niya.stoimenova?source=post_page-----40edafce293d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----40edafce293d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----40edafce293d--------------------------------)
    [Niya Stoimenova](https://medium.com/@niya.stoimenova?source=post_page-----40edafce293d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@niya.stoimenova?source=post_page-----40edafce293d--------------------------------)[![Niya
    Stoimenova](../Images/122b1debc4ae3af4fdf4d78e36071b68.png)](https://medium.com/@niya.stoimenova?source=post_page-----40edafce293d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----40edafce293d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----40edafce293d--------------------------------)
    [Niya Stoimenova](https://medium.com/@niya.stoimenova?source=post_page-----40edafce293d--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbacf8cf8265e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-why-machines-can-think-40edafce293d&user=Niya+Stoimenova&userId=bacf8cf8265e&source=post_page-bacf8cf8265e----40edafce293d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----40edafce293d--------------------------------)
    ·15 min read·Dec 6, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F40edafce293d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-why-machines-can-think-40edafce293d&user=Niya+Stoimenova&userId=bacf8cf8265e&source=-----40edafce293d---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbacf8cf8265e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-why-machines-can-think-40edafce293d&user=Niya+Stoimenova&userId=bacf8cf8265e&source=post_page-bacf8cf8265e----40edafce293d---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----40edafce293d--------------------------------)
    ·15分钟阅读·2023年12月6日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F40edafce293d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-why-machines-can-think-40edafce293d&user=Niya+Stoimenova&userId=bacf8cf8265e&source=-----40edafce293d---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F40edafce293d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-why-machines-can-think-40edafce293d&source=-----40edafce293d---------------------bookmark_footer-----------)![](../Images/9a5aaabda3a088a8883480eaf3a3056d.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F40edafce293d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-why-machines-can-think-40edafce293d&source=-----40edafce293d---------------------bookmark_footer-----------)![](../Images/9a5aaabda3a088a8883480eaf3a3056d.png)'
- en: Opening Pandora’s box (image by author)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 打开潘多拉的盒子（图片来源：作者）
- en: In the 17th century, [René Descartes introduced](https://en.wikipedia.org/wiki/Ren%C3%A9_Descartes)
    a relatively new idea — the dictum “**cogito ergo sum**” (“I think, therefore
    I am”). This simple formulation served as the basis of Western philosophy and
    defined for centuries our ideas on what constitutes the essence of being a human.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在17世纪，[勒内·笛卡尔](https://en.wikipedia.org/wiki/Ren%C3%A9_Descartes)提出了一个相对较新的思想——“**我思故我在**”。这一简单的表述成为了西方哲学的基础，并定义了几个世纪以来我们对人类本质的理解。
- en: Since then, our understanding of what it means to be a human evolved. Yet, for
    all intents and purposes, many still consider one’s capability to think as one
    of the most important hallmarks of humanity.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 从那时起，我们对作为人类的意义的理解发生了变化。然而，实际上，许多人仍然认为思考的能力是人性的最重要标志之一。
- en: So, it comes as no surprise that the moment ChatGPT (and similar models) was
    released, we started being bombarded with articles discussing “whether it can
    think”.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，ChatGPT（及类似模型）发布的瞬间，我们开始被大量讨论“它是否能够思考”的文章轰炸。
- en: For example, the New Yorker mused “[What kind of mind does ChatGPT have?](https://www.newyorker.com/science/annals-of-artificial-intelligence/what-kind-of-mind-does-chatgpt-have)”;
    the Washington Post proclaimed “[ChatGPT can ace logic tests. But don’t ask it
    to be creative](https://www.washingtonpost.com/technology/2023/03/18/gpt4-review/).”;
    and the Atlantic concluded that [“ChatGPT is dumber than you think”](https://www.theatlantic.com/technology/archive/2022/12/chatgpt-openai-artificial-intelligence-writing-ethics/672386/).
    A personal favourite of mine is this [video of a comedian](https://www.tiktok.com/@dragoscomedy/video/7229402346680339717)
    trying to explain what ChatGPT is to someone who’s working in HR.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: As with any other complex topic that lends itself well to speculation, people
    are both over-exaggerating and under-representing the thinking capabilities of
    AI models. So, let’s unpack this.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: To think is to reason
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thinking is a complex construct that has come to represent many different things.
    So, for simplicity sake, let’s presume that thinking is more or less synonymous
    with reasoning.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '**Reasoning** is a much better defined concept that is, coincidentally, being
    [increasingly thrown around as the **future of AI**](https://www.deeplearning.ai/the-batch/yoshua-bengio-wants-neural-nets-that-reason/?utm_campaign=The+Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-865CMxeXG2eIMWb7rFgGbKVMVqV6u6UWP8TInA4WfSYvPjc6yOsNPeTNfS_m_et5Atfjyw).
    It’s also what Descartes (largely) meant when he was talking about thinking.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: So instead of asking “Can AI think?”, let’s ask “Can AI reason?”.
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The short answer is **yes**. The long answer — it can reason, but only in some
    ways.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Reasoning is not a monolithic concept. There are multiple ways, in which one
    reasons, depending on the type of tasks she’s trying to accomplish. So, in this
    post, we’ll first go through a brief primer on the three key reasoning types and
    examine how machines measure up. Then, we’ll explore why machines cannot perform
    common-sense reasoning and what question we need to answer before they can.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Primer on reasoning
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Generally, there are three main types of reasoning we employ when “thinking”:
    **deduction**, **induction**, and **abduction**.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Deduction
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Simply put, deduction is the ability to reach a conclusion from a given rule
    and a case that are assumed to be true.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: 'Picture this: you fill a pan with water, turn on the stove, and pop in a thermometer.
    Because of things you’ve learned in school, you know that water (usually) boils
    at 100 °C. So, when someone tells you that the temperature has reached 100 °C,
    you can safely deduce that the water is boiling (you don’t actually have to see
    it with your own eyes to be “pretty sure” that it happens).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Here’s a useful structure to keep in mind.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '***1.* Rule:** water boils when it reaches 100 °C'
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '***2.* Case:** the temperature of the water is 100 °C'
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '***3.* Result:** the water in the pan is boiling'
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Thus, you reason from **rule** and **case** to a **result**.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你从**规则**和**案例**推理到**结果**。
- en: '![](../Images/2f15238c136a44f7ddb3a0ea2aca6886.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2f15238c136a44f7ddb3a0ea2aca6886.png)'
- en: 'Deduction: reasoning from rule and case to a result (image by author)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 推理：从规则和案例推理到结果（图片由作者提供）
- en: Deduction is fundamental for our ability to do science. It’s also the type of
    reasoning that’s the easiest to reproduce by a machine.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 推理对我们进行科学研究至关重要。它也是机器最容易重现的推理类型。
- en: By design, almost every machine carries out some form of deduction. Your simple
    non-glamorous calculator deduces answers every time you ask it how much 3+5 is.
    And it has zero AI in it.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 按设计，几乎每台机器都执行某种形式的推理。你的简单的、毫不起眼的计算器每次你问3+5是多少时都会推导出答案。而它其中没有任何人工智能。
- en: 'If we put it in the same structure as the water example above, we get:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们把它放在和上述水的例子相同的结构中，我们得到：
- en: '**Rule:** The calculator has been “provided” with the rule that **1+1 = 2**'
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**规则：** 计算器已经“提供”了规则**1+1 = 2**'
- en: ''
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Case:** You’ve asked the question **3+5 = ?**'
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**案例：** 你问了问题**3+5 = ?**'
- en: ''
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Result:** Based on the rule, it can calculate/deduce that **3+5 = 8**'
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**结果：** 根据规则，它可以计算/推导出**3+5 = 8**'
- en: Simple.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 简单。
- en: Induction
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 归纳
- en: Induction is the ability to generalise rules from a given set of observations.
    It’s central for our ability to do science since it allows us to *quantitatively*
    identify new patterns/rules.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 归纳是从给定的观察集合中概括规则的能力。它对我们进行科学研究至关重要，因为它使我们能够*定量*地识别新的模式/规则。
- en: 'Let’s stick to the water-boiling example. Imagine you have never been told
    that water boils at 100 °C. So, every time you bring a pan of water to a boil,
    you put a thermometer in and measure the temperature — 100, 1.000, 10.000 times.
    Then, your friends do the same — and no matter how many times you do it, the temperature
    is always 100 °C. So, you can **induce** the rule: “*water boils at 100 °C*”.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们坚持水的沸腾例子。假设你从未被告知水在100°C沸腾。因此，每次你将一锅水加热到沸腾时，你都放入一个温度计并测量温度——100次，1,000次，10,000次。然后，你的朋友们也做同样的事——无论你做多少次，温度总是100°C。因此，你可以**归纳**出规则：“*水在100°C沸腾*”。
- en: '1\. **Result**: water is boiling'
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 1\. **结果：** 水在沸腾
- en: ''
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '2\. **Case**: whenever you put the thermometer in, it always shows 100 °C.'
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 2\. **案例：** 每当你放入温度计时，它总是显示100°C。
- en: ''
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 3\. **Rule:** water boils at 100 °C.
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 3\. **规则：** 水在100°C沸腾。
- en: '![](../Images/173ec6860028897d9e780b6e479a84d3.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/173ec6860028897d9e780b6e479a84d3.png)'
- en: 'Induction: reasoning from result and case to a rule (image by author)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 归纳：从结果和案例推理到规则（图片由作者提供）
- en: And voila, you’ve identified quantitatively a new rule based on the pattern
    you observed. To do that, you reason from **result** and **case** to a **rule**.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你就根据你观察到的模式定量地识别出了一个新的规则。为此，你从**结果**和**案例**推理到**规则**。
- en: This type of reasoning is not always correct, of course. Famously, Europeans
    thought all swans were white until they sailed to Australia. Also, we know that
    water doesn’t always boil at 100 °C (the atmospheric pressure plays a role, too).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这种推理类型当然并不总是正确的。著名的是，欧洲人曾认为所有天鹅都是白色的，直到他们航行到了澳大利亚。我们也知道水的沸点并不总是100°C（大气压力也起作用）。
- en: Just because something happens to be correct 10.000 times, it doesn’t mean it
    will always be correct. Still, 10.000 times tends to be a safe bet.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅因为某件事发生了10,000次并不意味着它总是正确的。但10,000次通常是一个安全的选择。
- en: 'Induction is much more challenging for machines. Your calculator, of course,
    cannot perform it. Machine learning models, however, can. In fact, that’s their
    primary objective: generalise from a set of given results.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 归纳对机器来说要困难得多。你的计算器当然无法执行归纳。然而，机器学习模型可以。实际上，这正是它们的主要目标：从一组给定的结果中进行概括。
- en: Let’s take a simple example. Say, we have a supervised classification model
    that we’ll use for spam detection. First, we have the labelled training dataset
    — *spam* or *not spam* (a.k.a. the **result**). Within that dataset, we’ve compiled
    multiple **cases** for each result. Based on these, the model induces its own
    **rules** that can, later on, be applied to a case it has never seen before.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们举一个简单的例子。假设我们有一个监督分类模型，将用于垃圾邮件检测。首先，我们有标记的训练数据集——*垃圾邮件*或*非垃圾邮件*（即**结果**）。在这个数据集中，我们为每个结果编制了多个**案例**。基于这些案例，模型会归纳出自己的**规则**，这些规则可以在以后应用于一个它从未见过的案例。
- en: 1. **Result:** spam or not spam
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 1. **结果：** 垃圾邮件或非垃圾邮件
- en: ''
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 2\. **Case:** large samples for both spam and not spam examples
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 2\. **案例：** 大样本，包括垃圾邮件和非垃圾邮件示例
- en: ''
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '3\. **Rule**: emails with “these patterns and words” are likely to be spam
    (within a certain degree of probability)'
  id: totrans-62
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '3. **规则**: 包含“这些模式和词语”的邮件很可能是垃圾邮件（在一定的概率范围内）'
- en: Likewise, when dealing with unsupervised models such as recommendation systems,
    the process follows a similar beat. We first provide the model with a dataset
    about what people tend to buy when they go to the supermarket (**result**). Once
    we start with the model training, we’ll expect it to first cluster repeating patterns
    (**cases**) and then, induce its own **rules** that can be later on applied to
    *similar* contexts.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，当处理无监督模型如推荐系统时，过程也类似。我们首先向模型提供一个数据集，关于人们在超市购物时的倾向（**结果**）。一旦开始模型训练，我们会期望它首先聚类重复的模式（**案例**），然后引导出自己的**规则**，这些规则可以在*类似*的背景中应用。
- en: 1. **Result:** the unlabelled data about people’s purchases
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '1. **结果**: 关于人们购买的未标记数据'
- en: ''
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 2\. **Case:** the similar purchases the model found in the dataset (e.g., everyone
    who bought eggs also bought bacon).
  id: totrans-66
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '2. **案例**: 模型在数据集中发现的类似购买（例如，每个人买鸡蛋的人也会买培根）。'
- en: ''
  id: totrans-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '3\. **Rule**: people who buy eggs buy bacon, too (within a certain degree of
    probability)'
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '3. **规则**: 买鸡蛋的人也会买培根（在一定的概率范围内）'
- en: In both cases, these rules aren’t necessarily intelligible by humans. As in,
    we know that a computer vision model “*pays attention*” to a certain part of an
    image, but we rarely know **why**. In fact, the more complex the model is, the
    lower our chances are of knowing what rules it uses.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，这些规则不一定对人类是可理解的。也就是说，我们知道计算机视觉模型“*关注*”图像的某个部分，但我们很少知道**为什么**。实际上，模型越复杂，我们了解其使用规则的机会就越小。
- en: So, here we go — machines can perform both induction and deduction.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，这里我们可以看到——机器可以同时执行归纳和演绎推理。
- en: Deduction and induction — the bedrock of science
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 演绎推理和归纳推理——科学的基石
- en: It is a widely-held belief that the combination of *induction* and *deduction*
    is the driving force behind our ability to reason. And, as our examples show,
    contemporary ML models, even the simple ones, can already perform both.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 广泛认为，*归纳*和*演绎*的结合是我们推理能力的驱动力。正如我们的例子所示，当代的机器学习模型，即使是简单的模型，也能执行这两种操作。
- en: They first utilise inductive reasoning to generate rules from a given dataset.
    Then, they apply these rules to new **cases**. For example, once we present a
    model with *a previously unseen photo*, it leverages its **rules** to deduce specific
    **results** (e.g., *it can tell us that the photo we provided is upside down*).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 它们首先利用归纳推理从给定的数据集中生成规则。然后，它们将这些规则应用于新的**案例**。例如，一旦我们向模型提供*一张以前未见过的照片*，它会利用其**规则**来推断出具体的**结果**（例如，*它可以告诉我们提供的照片是倒置的*）。
- en: Still, the majority of data scientists will agree that even the most advanced
    ML models cannot reason. Why?
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 尽管如此，大多数数据科学家会同意，即使是最先进的机器学习模型也无法进行推理。为什么？
- en: The water-boiling example can serve as a simple illustration on why relying
    solely on deduction and induction doesn’t quite cut it. True, we need them to
    generate a **rule** (*“water boils at 100 °C”*) and then falsify it in a diverse
    set of cases. However, this combination falls short in explaining how we guessed
    that the **result** of *boiling* has something to do with *temperature*.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 水煮沸的例子可以简单地说明为什么仅依靠演绎推理和归纳推理并不足够。确实，我们需要它们来生成**规则**（*“水在100°C时沸腾”*），然后在各种案例中进行验证。然而，这种结合不足以解释我们是如何猜测到*煮沸*的**结果**与*温度*有关的。
- en: Beyond that, additional limitations of induction and deduction also become apparent
    — they are somewhat constrained by a specific context and lack the capacity to
    fully encapsulate the human ability to transfer knowledge across domains. This
    is precisely where **abduction** comes in, offering a more comprehensive perspective
    on the cognitive processes that enable us to make intuitive leaps and connect
    insights across different realms.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，归纳和演绎推理的额外局限性也变得显而易见——它们在特定的上下文中有所限制，缺乏在不同领域之间转移知识的能力。这正是**演绎推理**发挥作用的地方，它提供了一个更全面的视角，展示了使我们能够进行直觉跃迁并将洞察力连接到不同领域的认知过程。
- en: Abduction
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 演绎推理
- en: Abduction is the ability to generate new hypotheses from a single surprising
    observation (i.e., **result**). We do that every time we rely on our experiences
    to come to an explanation of sorts.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 演绎推理是从单一惊讶的观察（即**结果**）中生成新假设的能力。我们每次依赖经验来解释某些事物时，都会这样做。
- en: We go out and we see a wet street. We explain it away with the guess that it
    might’ve rained the night before. We don’t need to have seen 10.000 wet streets
    to know that when it rains, the street gets wet. Technically, we don’t even need
    to have encountered a wet street before — it’s enough for us to know that when
    water touches objects, it makes them wet.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们出去看到一条湿街。我们用之前可能下过雨的猜测来解释。我们不需要看到1万条湿街就知道下雨时街道会变湿。从技术上讲，我们甚至不需要以前遇到过湿街——我们只需知道当水接触物体时，会使物体变湿。
- en: 'This means that if we’re to go back to our water-boiling example, we’ll have
    a different way to reason:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，如果我们回到水煮沸的例子，我们将有不同的推理方式：
- en: '1\. **Result**: the water is boiling'
  id: totrans-81
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 1\. **结果**：水在煮沸
- en: ''
  id: totrans-82
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '2\. **Rule**: water boils at 100 °C'
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 2\. **规则**：水在100°C时煮沸
- en: ''
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '3\. **Case**: the temperature of the water must be 100 °C'
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 3\. **案例**：水的温度必须是100°C
- en: '![](../Images/b29d170924efec4a6c41bb81e04ad0c8.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b29d170924efec4a6c41bb81e04ad0c8.png)'
- en: 'Abduction: reasoning from rule and result to a case (image by author)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 溯因推理：从规则和结果推断到一个案例（作者插图）
- en: We start from the **result** (as we do with induction), but we combine it with
    a **rule** we already know (based on our world knowledge and experience). The
    combination of the two allows us to come up with a **case** (i.e., *the water
    is boiling because of changes in its temperature*).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从**结果**开始（就像我们进行归纳推理时一样），但我们将其与我们已知的**规则**结合（基于我们的世界知识和经验）。这两者的结合使我们能够得出一个**案例**（即，*水因温度变化而煮沸*）。
- en: Abduction is the least reliable of the reasoning types. Chances are that the
    hypothesis you reached through abduction is not correct. For instance, the result
    of “wet street” might have had nothing to do with the rain — perhaps a pipe had
    bursted somewhere on the street during the night, or someone diligently sprayed
    the street with water. The rain, however, seems like a plausible explanation.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 溯因推理是所有推理类型中最不可靠的。通过溯因推理得出的假设很可能是不正确的。例如，“湿街”的结果可能与雨无关——也许某个地方的管道在夜间破裂，或者有人认真地用水喷洒了街道。然而，雨似乎是一个合理的解释。
- en: As such, abductive reasoning allows us to move through everyday situations without
    being stuck. As in, we don’t need 10.000 tries to make a simple decision.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，溯因推理允许我们在日常情况中顺利前行，而不会陷入困境。也就是说，我们不需要尝试1万次来做出简单的决策。
- en: To my knowledge, no AI model/algorithm to date has been able to perform abductive
    reasoning. Not in the ways I just described.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 据我了解，目前没有任何AI模型/算法能够进行**溯因推理**。不是以我刚刚描述的方式。
- en: Those of you familiar with rule-based systems from the 1960s and 1970s, of course,
    can point at [MYCIN](https://en.wikipedia.org/wiki/Mycin), [XCON](https://en.wikipedia.org/wiki/Xcon)
    and [SHRDLU](https://en.wikipedia.org/wiki/SHRDLU) and claim that they’re capable
    of abduction. Others might bring up the examples of abduction cited by the Stanford
    AI index in [2022](https://aiindex.stanford.edu/wp-content/uploads/2022/03/2022-AI-Index-Report_Master.pdf)
    and [2023](https://aiindex.stanford.edu/wp-content/uploads/2023/04/HAI_AI-Index-Report_2023.pdf)
    as one of the most promising areas for future research (i.e., *abductive natural
    language inference*).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 那些对1960年代和1970年代基于规则的系统熟悉的人，当然可以提到[MYCIN](https://en.wikipedia.org/wiki/Mycin)、[XCON](https://en.wikipedia.org/wiki/Xcon)和[SHRDLU](https://en.wikipedia.org/wiki/SHRDLU)，并声称它们能够进行溯因推理。其他人可能会提到斯坦福AI指数在[2022](https://aiindex.stanford.edu/wp-content/uploads/2022/03/2022-AI-Index-Report_Master.pdf)和[2023](https://aiindex.stanford.edu/wp-content/uploads/2023/04/HAI_AI-Index-Report_2023.pdf)中引用的溯因推理例子，认为这是未来研究中最有前景的领域之一（即，*溯因自然语言推理*）。
- en: So, if machines were able to do “abduction” in the 1970s, why are they still
    not able to do what I claimed abduction can do (i.e., common sense reasoning)?
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，如果机器在1970年代能够进行“溯因推理”，为什么它们仍然不能做我所称的溯因推理（即常识推理）？
- en: Why abduction continues to be elusive
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么溯因推理仍然难以捉摸
- en: 'There are two high-level reasons why even state-of-the-art models can’t perform
    abduction: **conflation** and **architecture**.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是最先进的模型也无法进行溯因推理的原因有两个：**混淆**和**架构**。
- en: 'Conflation: abduction is not the same as Inference to the best explanation
    (IBE)'
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混淆：溯因推理与最佳解释推理（IBE）不同
- en: Historically, in computer science, many have used the terms IBE and abduction
    interchangeably. Even ChatGPT will tell you that the two are the same, or that
    abduction is a sub-set of IBE (depending on how you ask it). The [Stanford Encyclopedia
    of Philosophy](https://plato.stanford.edu/index.html) echoes this sentiment, too.
    In fact, almost every paper in the larger field of computer science you’ll read
    about abduction, will tell you that it’s the same as IBE.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 历史上，在计算机科学领域，许多人将IBE和推断这两个术语互换使用。即使是ChatGPT也会告诉你这两者是相同的，或者推断是IBE的一个子集（取决于你如何提问）。[斯坦福哲学百科全书](https://plato.stanford.edu/index.html)也反映了这种观点。实际上，你在计算机科学的相关领域阅读的几乎每一篇关于推断的论文，都告诉你它与IBE相同。
- en: Yet, these are two *very* *different* constructs.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这两者是*非常* *不同* 的构建。
- en: Generally, abduction covers the act of generating a novel case (*where learnings
    can be transferred from one context to another*). IBE, on the other hand, is a
    very special and more context-specific form of induction that doesn’t necessarily
    require you to identify patterns quantitatively (i.e., you don’t need to observe
    a pattern 10.000 times to formulate a rule). The exact ways in which these are
    different is a rather complicated philosophical discussion. If you want a deep-dive
    into that, I recommend [this paper](https://www.jstor.org/stable/10.2979/trancharpeirsoc.51.3.300).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，**推断**涵盖了生成新案例的行为（*将学习转移到不同的背景中*）。另一方面，IBE是一种非常特殊且更具背景特定性的归纳形式，它不一定要求你定量地识别模式（即，你不需要观察一个模式10,000次来制定规则）。这些之间的具体区别是一个相当复杂的哲学讨论。如果你想深入了解这一点，我推荐[这篇论文](https://www.jstor.org/stable/10.2979/trancharpeirsoc.51.3.300)。
- en: For the purposes of this post, however, what will help us is to think about
    them within the **rule**, **case** and **result** structure and use specific examples
    like MYCIN and the abductive natural language inference model the Stanford AI
    Index cites.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，就本文而言，帮助我们的是将其放在**规则**、**案例**和**结果**结构中进行思考，并使用像MYCIN和斯坦福AI指数引用的推断自然语言模型这样的具体例子。
- en: MYCIN was an early expert system developed in the 1970s at Stanford to assist
    doctors in diagnosing infectious diseases. It relied on a knowledge base where
    each **rule** was expressed in terms of condition (IF — i.e., the **case**) and
    a conclusion (THEN — i.e., the **result**). It then utilised a [*backward chaining*](https://en.wikipedia.org/wiki/Backward_chaining)inference
    mechanism, which allowed it to take a set of symptoms and patient data (**result**
    and **case,** respectively), and work backwards to identify and assign *a heuristic
    certainty score from 0 to 1* to the **rules** that might explain the situation
    best. Namely, it reasoned from result and case to a rule (i.e., the pattern that
    inductive reasoning follows).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: MYCIN是20世纪70年代在斯坦福开发的早期专家系统，旨在帮助医生诊断传染病。它依赖于一个知识库，其中每个**规则**都以条件（IF——即**案例**）和结论（THEN——即**结果**）的形式表达。然后它利用了[*逆向推理*](https://en.wikipedia.org/wiki/Backward_chaining)机制，使其能够从一组症状和病人数据（分别是**结果**和**案例**）中，向后推理以识别和分配*从0到1的启发式确定性评分*给那些可能最好地解释情况的**规则**。即，它从结果和案例推理到规则（即，归纳推理遵循的模式）。
- en: The work the Stanford AI index cites as an [example](https://arxiv.org/abs/1908.05739)
    of *abductive natural language inference* (either when generating a hypothesis
    or selecting the most plausible one) is a bit trickier. Still, it is not abduction.
    In fact, I’d argue, it resembles IBE, but it follows the same pattern as the other
    ML models we discussed thus far — induction, followed by deduction.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 斯坦福AI指数引用的作为*推断自然语言推理*的[例子](https://arxiv.org/abs/1908.05739)（无论是生成假设还是选择最合理的假设）有点棘手。但这仍然不是推断。事实上，我会说，它类似于IBE，但它遵循与我们迄今讨论的其他机器学习模型相同的模式——归纳，接着是演绎。
- en: Some background; in 2020, Bhagavatula and colleagues*, trained a transformer
    model conditioned on a dataset they call ART (containing ∼20K narrative contexts
    defined by pairs of observations (O1, O2) and 200K explanatory hypotheses). After
    training, they provided the model with a set of two observations and asked it
    to generate a plausible hypothesis to match (see Figure 4).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 背景：在2020年，Bhagavatula及其同事*，对一个他们称之为ART的数据集（包含约20K由观察对（O1, O2）定义的叙事背景和200K解释性假设）训练了一个变换器模型。训练后，他们给模型提供了一组观察数据，并要求它生成一个合理的假设以匹配（见图4）。
- en: '![](../Images/722ffbdc9331a51b34baf58481db839e.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/722ffbdc9331a51b34baf58481db839e.png)'
- en: 'Figure 4: Abductive natural language inference (the figure is taken from [arXiv:1908.05739](https://arxiv.org/abs/1908.05739))'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：推测自然语言推理（该图取自 [arXiv:1908.05739](https://arxiv.org/abs/1908.05739)）
- en: As you can see from the figure, when a transformer model (GPT-2+COMeT embeddings)
    is presented with O1 (e.g., “*Junior is the name of a 20****+*** *year old turtle*”),
    and O2 (e.g., *“Junior is still going strong”*), it can generate a plausible hypothesis
    (e.g., *“Junior has been swimming in the pool with her friends”*) that might explain
    why we think Junior is still going strong.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如图所示，当一个变压器模型（GPT-2+COMeT 嵌入）面对 O1（例如，*“Junior 是一只 20****+*** *岁的老海龟*”）和 O2（例如，*“Junior
    仍然很强壮”*）时，它可以生成一个合理的假设（例如，*“Junior 一直在池塘里和她的朋友们一起游泳”*），这可能解释了为什么我们认为 Junior 仍然很强壮。
- en: Why is this IBE and not abduction?
  id: totrans-107
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为什么这是 IBE 而不是推测？
- en: 'Let’s abstract ourselves from the underlying ML model for a bit and think about
    how a human might perform such reasoning task. First, we’re provided with a **result**:
    *Junior is still going strong*, and we’re told what the **case** is (i.e., *Junior
    is a relatively old turtle*). Then, from these, what we’d do is to try and find
    a potential (context-dependent) **rule** that can explain the case and the result.
    For example, we can induce that *an old turtle that’s still going strong*'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们暂时从基础的 ML 模型中抽象出来，考虑一下人类如何执行这样的推理任务。首先，我们得到一个**结果**：*Junior 仍然很强壮*，并且我们被告知**案例**是什么（即，*Junior
    是一只相对年长的海龟*）。然后，从这些中，我们会尝试找出一个潜在的（上下文相关的）**规则**，以解释这个案例和结果。例如，我们可以推导出*一只年老却仍然强壮的海龟*
- en: tends to play with its friends OR
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 趋向于和朋友们玩耍 或
- en: has a healthy appetite OR
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有良好的食欲 或
- en: has good vitals
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 具有良好的生命体征
- en: and so on.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 依此类推。
- en: We can then choose the most plausible (to us) rule and apply it to our case
    of “an old turtle”. This will allow us to hypothesise that Junior could *have
    been swimming with her friends.*
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以选择最符合我们判断的规则，并将其应用于“一个老海龟”的情况。这将允许我们假设 Junior *可能一直在和她的朋友们一起游泳*。
- en: As already explained, the identifying of the potential rules from a limited
    set of observations is indicative of IBE and the act of drawing conclusions from
    these, tends to be a weak form of deduction.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，从有限的观察中识别潜在规则表明了 IBE，而从这些规则中得出的结论则倾向于是一种较弱的推演形式。
- en: We *as humans* understand that when one ages (be it a turtle or a human), their
    vitality tends to go down (arguably). This allows us to generate rules that are
    relatively ‘imbued with meaning”. A transformer model cannot do that. What it
    can do, however, is improve its predictions on the most probable combination of
    words that can follow the provided case and result (by applying induction and
    then deduction). The model has no underlying understanding that when Junior is
    having fun, she’s still going strong.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们*作为人类*理解到，当一个生物变老（无论是海龟还是人类）时，它们的活力往往会下降（可以说是）。这使我们能够生成相对“充满意义”的规则。然而，变压器模型无法做到这一点。它能做的，是通过归纳和推演来改善对最可能的单词组合的预测。模型没有基本理解，当
    Junior 玩得开心时，她仍然很强壮。
- en: In fact, one might even go as far as to say that the work on *abductive natural
    language inference* is reminiscent of [chain-of-thought](https://arxiv.org/abs/2201.11903)
    prompting. Granted, the instructions are presented to the transformer in a different
    manner.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，有人甚至可以说*推测自然语言推理*的工作类似于 [链式思维](https://arxiv.org/abs/2201.11903) 提示。尽管如此，指令是以不同的方式呈现给变压器的。
- en: What all these instances highlight, hopefully, is that what computer science
    labels as abduction isn’t abduction after all. Instead, it appears to be a context-specific
    variant of induction.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 希望所有这些例子突显出计算机科学所称的推测其实并不是推测。相反，它似乎是一种特定上下文的归纳变体。
- en: 'Architecture: contemporary ML models are bound by induction'
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 架构：当代 ML 模型受限于归纳
- en: The second reason behind state-of-art models’ inability to carry out abduction
    lies in their architecture. By definition, ML models are an induction-generating
    machines. This inclination is further strengthen by their so-called **inductive
    bias**.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 状态最先进模型无法进行推测的第二个原因在于它们的架构。根据定义，机器学习模型是一个生成归纳的机器。这种倾向被它们所谓的**归纳偏差**进一步加强。
- en: Inductive bias is an integral concept in ML referring to the inherent assumptions
    or preferences a model possesses regarding the types of functions it should learn.
    The bias helps guide the learning process by restricting the set of possible hypotheses,
    making learning more efficient and accurate.
  id: totrans-120
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: For example, *decision trees* focus on hierarchical structures and simple decision
    boundaries. *Support Vector Machines* aim to find wide margins between classes.
    *Convolutional Neural Networks* emphasise translation invariance and hierarchical
    feature learning in images. *Recurrent Neural Networks* are biased towards sequential
    patterns, *Bayesian Networks* model probabilistic relationships, *regularised
    linear models* prefer simpler models by penalising large coefficients, and general
    *transformers* like GPT-4 are characterised by their ability to capture sequential
    dependencies and relationships in data. These biases shape the models’ behaviour
    and suitability for different tasks. They also make it difficult to transfer learnings
    from one context to another.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: What we still need
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OK, by now we discussed a primer on reasoning and we saw that machines can indeed
    reason. They perform both deduction and induction. However, what we tend to intuitively
    term as “thinking” is facilitated by abduction, which continues to be elusive
    due to conflation and architecture.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: So, what do we need then?
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: How do we go about building something that can perform abductive reasoning?
  id: totrans-125
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Well, first of all, we need to be able to properly define what abduction is
    and describe how it works. Sadly, not much work has been done in this regard.
    Especially, when it comes to identifying how abduction relates to induction and
    deduction. Or how it can be operationalised by machines. The only thing scholars
    tend to agree on is that abduction comes first, followed by induction and deduction.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '**So, what is abduction?**'
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Abduction is not a monolithic construct. I’ve personally came across around
    10 different types, depending on the scientific field to which they pertain. Even
    the philosopher who introduced the notion of *abduction*, Charles Peirce, doesn’t
    refer to it in a consistent manner.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: However, there are three main types that can describe the fundamental functions
    abduction serves. The exact functions and how they came to be are too complex
    to cover in this post. So, here are the cliff notes.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: First, we have the most straightforward abduction type — *explanatory*. The
    one we discussed thus far. To employ it, we start with an observation (**result**)
    and a **rule** that is easy to identify. The combination of the two then enables
    us to make a conjecture about the **case**. This is well-illustrated in the water-boiling
    example.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Then, we have *innovative abduction —* a type of abduction which allows us to
    reason from a (desired) **result** to a pair of a **case** and a **rule.** Namely,
    we only know what result we want to create and then we need to gradually define
    a **case-rule** pairing that will allow us to achieve said result. This type of
    abduction is usually used to generate novel ideas.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们有了*创新性推断*——一种允许我们从一个（期望的）**结果**推理到一对**案例**和**规则**的推断。也就是说，我们只知道我们想要创造什么结果，然后我们需要逐步定义一个**案例-规则**配对，这样才能实现所述结果。这种类型的推断通常用于生成新颖的想法。
- en: Finally, we have, I think, one of the most interesting types of abduction —
    *manipulative*. We use it in situations where the only thing we know is parts
    of the **result** (desired or otherwise). Furthermore, the context in which this
    result “lives” is defined by multiple hidden interdependencies. So, it’s not possible
    to start looking for/generating a suitable **case-rule** pair right away. Instead,
    we need to better understand the result and how it relates to its environment,
    so that we can reduce the level of uncertainty.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我认为我们有了最有趣的一种推断——*操控性推断*。我们在唯一知道**结果**（期望的或其他）部分的情况下使用它。此外，这个结果“存在”的背景由多个隐藏的相互依赖关系定义。因此，不能立刻开始寻找/生成合适的**案例-规则**配对。相反，我们需要更好地理解结果以及它与环境的关系，以便减少不确定性。
- en: That’s where the so-called *thinking device/epistemic mediator* comes in. This
    could take the form of e.g., a basic sketch, prototype, or 3D model, serving as
    a means to enhance our understanding of the problem. By manipulating this *mediator*
    within the target environment, we gain a deeper understanding of the context.
    Consequently, we become better equipped to explore potential combinations of **rules**
    and **cases**. Additionally, it allows us to establish associations that aid the
    transferring of knowledge from one domain to another. A simplified version of
    this kind of thinking is commonly applied in stereometry, for instance.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是所谓的*思维装置/认识中介*发挥作用的地方。这可以采取例如基本草图、原型或3D模型的形式，用于增强我们对问题的理解。通过在目标环境中操控这个*中介*，我们能更深入地理解背景。因此，我们能够更好地探索**规则**和**案例**的潜在组合。此外，它还使我们能够建立关联，帮助将知识从一个领域转移到另一个领域。这种思维的简化版本通常在立体几何中应用。
- en: As I said, much work still needs to be done in explaining the relationships
    among these abduction types and their relatedness with other reasoning approaches.
    This endeavour is becoming increasingly critical, however, as it holds the potential
    to offer valuable insights into the transferability of insights across different
    domains. Especially, in light of the renewed interest in reasoning we see in the
    field — be it via IBE, “reasoning through simulation and examples”, or System-1
    and System-2 thinking.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我所说，仍需要做大量工作来解释这些推断类型之间的关系及其与其他推理方法的相关性。然而，这项工作变得越来越关键，因为它有可能为不同领域之间的洞察力转移提供宝贵的见解。特别是在我们看到该领域对推理的新兴趣的背景下——无论是通过
    IBE、“通过模拟和例子进行推理”，还是系统1和系统2思维。
- en: Amidst all that, it seems pertinent to understand how not to conflate the different
    types of reasoning that can be performed by a machine. Because, yes, machines
    can reason. They simply cannot perform the full reasoning spectrum.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些情况中，理解如何区分机器可以进行的不同类型的推理似乎尤为重要。因为，确实，机器是可以进行推理的。它们只是无法进行全方位的推理。
- en: '*Other interesting work on IBE can be found in [this paper (they do equate
    abduction with IBE, however).](https://arxiv.org/abs/2305.14618)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '*关于 IBE 的其他有趣工作可以在[这篇论文中找到（他们确实将推断等同于 IBE）。](https://arxiv.org/abs/2305.14618)*'
