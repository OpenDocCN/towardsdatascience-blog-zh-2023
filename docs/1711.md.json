["```py\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\n```", "```py\nmodel = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Dense(1, activation=\"sigmoid\", input_shape=(1,)))\nmodel.summary()\n```", "```py\n@tf.function()\ndef action_selection(model):\n    with tf.GradientTape() as tape:\n        output = model(np.array([[0.0]]))  # [0 ... 1]\n        action = (tf.random.uniform((1, 1)) < output)  # [0 or 1]\n\n        loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(action, output))\n\n    grads = tape.gradient(loss, model.trainable_variables)\n    return output, action, loss, grads\n```", "```py\nSTEPS = 1000\nLR = 0.5\n```", "```py\nfor step in range(STEPS):\n\n    output, action, loss, grads = action_selection(model)\n    if action == False:  # Action A\n        reward = float(np.random.random() < 0.3)\n\n    if action == True:  # Action B\n        reward = float(np.random.random() < 0.4)\n\n    grads_adjusted = []\n    for var_index in range(len(model.trainable_variables)):\n        grads_adjusted.append((reward-0.5)*2 * grads[var_index])\n\n    model.trainable_variables[0].assign(model.trainable_variables[0]-LR*grads_adjusted[0])\n    model.trainable_variables[1].assign(model.trainable_variables[1]-LR*grads_adjusted[1])\n```"]