- en: A Framework for Analyzing Churn
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析流失的框架
- en: 原文：[https://towardsdatascience.com/a-framework-for-analyzing-churn-370d2283b75c?source=collection_archive---------4-----------------------#2023-01-13](https://towardsdatascience.com/a-framework-for-analyzing-churn-370d2283b75c?source=collection_archive---------4-----------------------#2023-01-13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-framework-for-analyzing-churn-370d2283b75c?source=collection_archive---------4-----------------------#2023-01-13](https://towardsdatascience.com/a-framework-for-analyzing-churn-370d2283b75c?source=collection_archive---------4-----------------------#2023-01-13)
- en: A step-by-step guide to performing a customer churn analysis, using a simulated
    dataset
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用模拟数据集进行客户流失分析的逐步指南
- en: '[](https://gabri-albini.medium.com/?source=post_page-----370d2283b75c--------------------------------)[![Gabriele
    Albini](../Images/153b88c71ea4e5e221a90de3caa71cdb.png)](https://gabri-albini.medium.com/?source=post_page-----370d2283b75c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----370d2283b75c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----370d2283b75c--------------------------------)
    [Gabriele Albini](https://gabri-albini.medium.com/?source=post_page-----370d2283b75c--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://gabri-albini.medium.com/?source=post_page-----370d2283b75c--------------------------------)[![Gabriele
    Albini](../Images/153b88c71ea4e5e221a90de3caa71cdb.png)](https://gabri-albini.medium.com/?source=post_page-----370d2283b75c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----370d2283b75c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----370d2283b75c--------------------------------)
    [Gabriele Albini](https://gabri-albini.medium.com/?source=post_page-----370d2283b75c--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F93c18fcb4ee6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-framework-for-analyzing-churn-370d2283b75c&user=Gabriele+Albini&userId=93c18fcb4ee6&source=post_page-93c18fcb4ee6----370d2283b75c---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----370d2283b75c--------------------------------)
    ·14 min read·Jan 13, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F370d2283b75c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-framework-for-analyzing-churn-370d2283b75c&user=Gabriele+Albini&userId=93c18fcb4ee6&source=-----370d2283b75c---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[阅读](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F93c18fcb4ee6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-framework-for-analyzing-churn-370d2283b75c&user=Gabriele+Albini&userId=93c18fcb4ee6&source=post_page-93c18fcb4ee6----370d2283b75c---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----370d2283b75c--------------------------------)
    ·14分钟阅读·2023年1月13日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F370d2283b75c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-framework-for-analyzing-churn-370d2283b75c&user=Gabriele+Albini&userId=93c18fcb4ee6&source=-----370d2283b75c---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F370d2283b75c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-framework-for-analyzing-churn-370d2283b75c&source=-----370d2283b75c---------------------bookmark_footer-----------)![](../Images/62f0f24f3727ca4e6109e0031b5222d6.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F370d2283b75c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-framework-for-analyzing-churn-370d2283b75c&source=-----370d2283b75c---------------------bookmark_footer-----------)![](../Images/62f0f24f3727ca4e6109e0031b5222d6.png)'
- en: Photo by [JESHOOTS.COM](https://unsplash.com/@jeshoots?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[JESHOOTS.COM](https://unsplash.com/@jeshoots?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '“*Churn*” has become a common business word that refers to the concept of churn
    rate, defined by Wikipedia as the:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: “*客户流失*”已经成为一个常见的商业词汇，它指的是流失率的概念，维基百科定义为：
- en: “proportion of contractual customers or subscribers who leave a supplier during
    a given time period”
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “在给定时间段内离开供应商的合同客户或订阅者的比例”
- en: 'When analyzing churn from a data perspective, we usually mean to use the available
    tools to extract information about the existing customer base, specifically: quantify
    the current churn rate and understand what could influence/prevent future churn.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据角度分析流失时，我们通常意味着使用现有工具提取有关现有客户群的信息，具体来说：量化当前的流失率并了解可能影响/预防未来流失的因素。
- en: 'So, when we develop a “churn model”, we should use existing data with two objectives
    in mind:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当我们开发“流失模型”时，应该考虑使用现有数据并且要有两个目标：
- en: Predict churn for our existing active customers
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为现有活跃客户预测流失
- en: Make some hypotheses about what influenced the customers’ churn decision, identifying
    some potential actions that could reduce churn
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对影响客户流失决策的因素进行一些假设，识别出可能减少流失的潜在措施。
- en: 'Predicting churn requires a lot of work and it is not an easy task but, more
    importantly, it is not even the ultimate goal: it is the starting point to design
    and implement a customer “*retention*” strategy!'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 预测流失需要大量工作，这不是一项容易的任务，但更重要的是，它甚至不是*最终*目标：这是设计和实施客户“*留存*”策略的起点！
- en: 'This article will focus on the implementation of a churn analysis framework,
    inspired by the book: [1]*“Fighting Churn with Data” by Carl S. Gold*. This is
    a great book that I recommend to anybody who is working with churn data: the book
    goes into lots of details and examples (with explained code!) showing a churn
    analysis end-to-end. From all the suggested steps, I’ve taken what has been most
    relevant and successful in my experience and adapted it to the context and dataset
    I am familiar with. In this article, the framework has been applied to a simulated
    data set, inspired by a real business case ([link to the Github repository](https://github.com/gabri-al/churn_analysis)).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本文将重点介绍流失分析框架的实现，灵感来源于书籍：[1]*《用数据对抗流失》*，作者是卡尔·S·戈德。这是一本推荐给所有处理流失数据的人的优秀书籍：书中详细介绍了流失分析的全过程，提供了很多细节和示例（包括解释代码！）。在所有建议的步骤中，我提取了在我的经验中最相关和成功的部分，并将其调整为我熟悉的背景和数据集。本文将该框架应用于一个模拟数据集，灵感来源于一个真实的商业案例（[Github
    仓库链接](https://github.com/gabri-al/churn_analysis)）。
- en: 'Table of Content:'
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目录：
- en: 1- [The Data](#5487)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 1- [数据](#5487)
- en: 1.1- [What data should be considered when developing a churn model?](#d95f)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 1.1- [开发流失模型时应考虑哪些数据？](#d95f)
- en: 1.2- [The raw data](#d95f)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 1.2- [原始数据](#d95f)
- en: '2- [Data preprocessing: churn metrics](#c74a)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 2- [数据预处理：流失指标](#c74a)
- en: 2.1- [Creating customer metrics](#652c)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 2.1- [创建客户指标](#652c)
- en: 2.2- [Analysing churn metrics](#048e)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 2.2- [分析流失指标](#048e)
- en: 3- [Churn prediction with Machine Learning](#179c)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 3- [使用机器学习进行流失预测](#179c)
- en: 3.1- [Logistic Regression](#179c)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 3.1- [逻辑回归](#179c)
- en: 3.2- [Random Forest](#ba22)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 3.2- [随机森林](#ba22)
- en: 3.3- [XGBoost](#481c)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 3.3- [XGBoost](#481c)
- en: 4- [Generating churn predictions](#bd49)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 4- [生成流失预测](#bd49)
- en: 5- [Next steps](#f279)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 5- [下一步](#f279)
- en: '[References](#f062)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[参考文献](#f062)'
- en: 1\. The Data
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1. 数据
- en: 1.1 What data should be considered when developing a churn model?
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 开发流失模型时应考虑哪些数据？
- en: 'This is not a trivial question! A lot of different information may be related
    to churn and setting up general rules would never cover all possible businesses,
    systems, contexts, etc. For example, when thinking about churn-related information,
    we may consider:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是一个简单的问题！很多不同的信息可能与流失相关，制定通用规则永远无法涵盖所有可能的业务、系统、背景等。例如，在考虑流失相关信息时，我们可能会考虑：
- en: 'Demographic information about the clients (or accounts): gender, location,
    age, tenure, …'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于客户（或账户）的基本信息：性别、位置、年龄、任期等
- en: 'Subscriptions related information: the products customers have subscribed to,
    adds-on activated, activation and cancellation dates …'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与订阅相关的信息：客户订阅的产品、激活的附加功能、激活和取消日期等
- en: 'Payment information: How much do clients pay? What payment method do they use?
    Are they paying regularly? …'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支付信息：客户支付了多少？他们使用什么支付方式？他们是否定期付款？
- en: 'Product usage information: login information, clicks information, minutes of
    interaction with the product, …'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品使用信息：登录信息、点击信息、与产品的互动分钟数等
- en: 'Information related to the interaction with customer support: chats or calls
    made by clients, rating of support services, claims details, …'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与客户支持互动相关的信息：客户进行的聊天或电话、支持服务的评分、投诉细节等
- en: …
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: …
- en: Translated into systems, this data would need to come from various transactional
    systems (CRMs, ERPs, billing, …) and should be properly organized into some DataLake
    / Data Warehouse (ideally taking frequent snapshots covering several months).
    Given that this is happening, a lot of know-how should then be available to understand
    what field is representing what information, and, usually, lots of approvals are
    needed to access this data, especially if some external consultant would like
    to use it.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 翻译成系统后，这些数据需要来自各种事务系统（CRM、ERP、计费等），并应适当地组织到某些数据湖/数据仓库中（理想情况下，频繁地拍摄覆盖几个月）。考虑到这一点，需要有大量的专业知识来了解哪些字段代表了哪些信息，通常，访问这些数据需要大量的批准，特别是如果外部顾问想要使用这些数据的话。
- en: From my experience, all this data (and the related considerable history) is
    ***rarely available***. Usually, what’s available and organized, is the data that
    companies are *required* to store and use, due to financial or legal regulations
    or simply because the data is needed to run the daily business. This data must
    be available *somewhere*.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我的经验，所有这些数据（以及相关的历史记录）***很少可用***。通常，可用且已组织的数据是公司因财务或法律法规要求或仅因运行日常业务所需的数据。这些数据必须在*某处*可用。
- en: 'For instance: suppose we’re a company offering on-demand video training, we
    have to know what client has what subscription and how much they’re paying to
    offer our services and produce our balance sheet. However, we don’t necessarily
    need to store the information about the minute that client XYZ paused a specific
    video before finishing it.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：假设我们是一家提供按需视频培训的公司，我们需要知道客户拥有哪些订阅以及他们支付了多少，以提供我们的服务并制作财务报表。然而，我们不一定需要存储客户
    XYZ 在完成特定视频之前暂停视频的具体时间。
- en: For all these reasons, in order to keep the article simple and realistic, I’ll
    focus on a “small” dataset, ideally coming from the data that should be available
    in any CRM.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于所有这些原因，为了保持文章简洁和现实，我将重点关注一个“较小”的数据集，理想情况下这些数据应来自任何 CRM 中应有的数据。
- en: 1.2 The raw data
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 原始数据
- en: 'Let’s imagine we’re a B2C (business to consumer) company offering online video
    courses through our website. Our business works in this way:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们假设我们是一家通过网站提供在线视频课程的 B2C（商业对消费者）公司。我们的业务运作方式如下：
- en: 'A new user could subscribe to courses on two domains: machine learning (domain
    A) and guitar (domain B). They can purchase several subscriptions which allow
    them to have different user logging in at the same time. Additionally, they may
    opt to include an “add-on” which consists in receiving weekly live sessions with
    a specialist from the chosen domain.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新用户可以订阅两个领域的课程：机器学习（领域 A）和吉他（领域 B）。他们可以购买多个订阅，从而允许不同用户同时登录。此外，他们还可以选择包含“附加服务”的选项，该服务包括每周与所选领域的专家进行在线直播。
- en: Once subscribed, a user has a monthly payment and may or may not have discounts.
    They can cancel their subscription anytime, meaning that the subscription won’t
    be renewed at the end of the month.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦订阅，用户将每月支付费用，并可能有或没有折扣。他们可以随时取消订阅，这意味着订阅将在月底不会续订。
- en: Users can open a live chat and contact a support team for any issue.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户可以打开实时聊天并联系支持团队解决任何问题。
- en: 'The raw data would look like the following:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据将如下所示：
- en: '![](../Images/6a32434a393847910e9f5f5026ede0a6.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a32434a393847910e9f5f5026ede0a6.png)'
- en: Dummy raw data | Image by author
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟原始数据 | 图片来源作者
- en: 'This business context is quite common and should apply to any B2C business
    with monthly subscriptions and the option to include an add-on to a base offer
    (e.g. businesses like: on-demand media content, telco, utility, e-commerce, insurance,
    and premium software).'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这种商业背景非常常见，适用于任何具有每月订阅和将附加服务添加到基本报价的 B2C 业务（例如：按需媒体内容、电信、公用事业、电子商务、保险和高级软件等企业）。
- en: '2\. Data preprocessing: churn metrics'
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2. 数据预处理：流失指标
- en: Starting from the raw data, we will have to predict if a client is going to
    churn. We will consider clients as a whole, regardless of how many subscriptions
    they have.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 从原始数据开始，我们需要预测客户是否会流失。我们将把客户视为一个整体，无论他们有多少个订阅。
- en: Since our goal is to predict churn to develop a retention strategy, we need
    to know, in advance, if a client will be churning, so that we can do something
    to influence this decision.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的目标是预测流失以制定留存策略，我们需要提前知道客户是否会流失，以便我们可以采取措施影响这一决定。
- en: 2.1 Creating customer metrics
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 创建客户指标
- en: 'What KPIs can we produce considering the raw data above? Here are some ideas
    (that are the columns of our [dataset](https://github.com/gabri-al/churn_analysis)):'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到以上原始数据，我们可以生成哪些KPI？以下是一些想法（它们是我们[数据集](https://github.com/gabri-al/churn_analysis)的列）：
- en: '“mrr_ratio” = this is the monthly recurrent revenue by subscription. So, for
    every client: we sum([monthly fee — discount]) for every active subscription,
    we count the nr of active subscriptions and we divide the two.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “mrr_ratio” = 这是按订阅计算的每月经常性收入。因此，对于每个客户：我们对每个有效订阅求和([每月费用 — 折扣])，然后计算有效订阅的数量，并将两者相除。
- en: “mrr_ratio_A” and “mrr_ratio_B” = these are the monthly recurrent revenues by
    domain (A is machine learning; B is guitar), considering the mrr and the nr of
    active subscriptions by domain.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “mrr_ratio_A”和“mrr_ratio_B” = 这些是按领域计算的每月经常性收入（A是机器学习；B是吉他），考虑领域内的mrr和活跃订阅数量。
- en: “subs_A” and “subs_B” = active subscription count by domain
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “subs_A”和“subs_B” = 按领域的活跃订阅数量
- en: '“discount_ratio” = discount % that the client has, obtained as: 1 — ([monthly
    fee — discount] / [monthly fee])'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “discount_ratio” = 客户的折扣百分比，计算方法为：1 — ([每月费用 — 折扣] / [每月费用])
- en: “has_addon” = a flag indicating if the client has at least one subscription
    with an add on
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “has_addon” = 一个标志，指示客户是否有至少一个带附加组件的订阅
- en: “support_chats” = count of chats initiated by the client in a period
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “support_chats” = 客户在一个期间内发起的聊天次数
- en: “is_churn” = a flag indicating if the client is going to churn (1) or not (0)
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “is_churn” = 一个标志，指示客户是否将要流失（1）或不流失（0）
- en: 'The best method to use our historic raw data to calculate these KPIs is, in
    my opinion, to:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为使用我们历史原始数据来计算这些KPI的最佳方法是：
- en: Identify some fixed observation period (e.g. the 20th of every month), leaving
    some reasonable time from our renewal (which we suppose to occur on the 30th of
    every month).
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定一些固定的观察期（例如每月20号），留出一些合理的时间从我们的续订（我们假设每月30号发生）。
- en: Create a table “A” in which, for every “lost” client, we include their past
    churn dates.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个表“A”，在其中，对于每一个“流失”的客户，我们包括他们过去的流失日期。
- en: Create another table “B” in which, for every client, on the 20th of the month,
    we calculate the KPIs based on the past 30 days’ data. In other words, we take
    monthly screenshots of the client metrics, but we do it on the 20th of every month.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建另一个表“B”，其中，对于每个客户，在每月20号，我们根据过去30天的数据计算KPI。换句话说，我们每月20号对客户指标进行月度快照。
- en: We join the tables “A” and “B” on client ID and flag all rows that will end
    up in a churn by the next observation date.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将表“A”和“B”按客户ID连接，并标记所有将在下一个观察日期流失的行。
- en: 'These observation periods and KPIs are normally calculated on the data warehouse
    and then exported into Python. The data that I simulated for the project represents
    exactly this scenario. Suppose we just obtained the following dataset from our
    data warehouse:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这些观察期和KPI通常在数据仓库中计算，然后导出到Python。我为项目模拟的数据正好代表了这种情况。假设我们刚刚从数据仓库中获得了以下数据集：
- en: '![](../Images/d22561b15385296e33661df0a17cb897.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d22561b15385296e33661df0a17cb897.png)'
- en: Dummy churn metrics | Image by author
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟流失指标 | 图片由作者提供
- en: '(*Note: this is a simulated dataset. All the continuous metrics have been drawn
    from a multivariate Gaussian distribution that approximates the real data. This
    is why we have negative values and decimal values on KPIs that shouldn’t be negative
    or decimals. Additionally, each row should correspond to a client ID, but this
    information is not relevant*).'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: (*注意：这是一个模拟数据集。所有连续指标都从一个多变量高斯分布中提取，近似真实数据。这就是为什么我们有负值和应不为负值或小数的KPI的原因。此外，每一行应对应一个客户ID，但此信息并不相关*)。
- en: 2.2 Analysing churn metrics
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 分析流失指标
- en: Once we have some metrics, we can finally start checking what’s their relationship
    with churn.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们拥有一些指标，我们可以开始检查它们与流失的关系。
- en: The most intuitive way to investigate this relationship is via a **cohort analysis**.
    Usually, 10 cohorts are generated by splitting each metric data into 10 equal-size
    buckets, depending on their values. We then relate each metric with the “is_churn”
    flag by calculating the churn rate in each cohort. If a metric is not continuous
    and has less than 10 categorical values, then we just consider one cohort per
    category.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 最直观的方式来调查这种关系是通过**队列分析**。通常，通过将每个指标数据拆分成10个相等大小的桶来生成10个队列，具体取决于它们的值。然后，我们通过计算每个队列中的流失率，将每个指标与“is_churn”标志相关联。如果指标不是连续的且具有少于10个分类值，那么我们只考虑每个类别一个队列。
- en: 'On the left chart, we can see that the clients who have a higher mrr_ratio,
    on average, churn more, as they are paying more per subscription:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在左侧图表中，我们可以看到，平均而言，拥有更高mrr_ratio的客户流失更多，因为他们每个订阅支付更多：
- en: '![](../Images/635ff9d13ee409337f67d4cb586b2783.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/635ff9d13ee409337f67d4cb586b2783.png)'
- en: Churn metric cohorts | Image by author
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 流失指标队列 | 作者提供的图像
- en: Whenever we see such behavior, which makes logical sense and where, depending
    on the metric value, we see a considerable difference in churn, then we can expect
    the metric to be relevant in our analysis.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们看到这样的行为，具有逻辑意义，并且根据指标值，我们看到流失有显著差异时，我们可以期望该指标在我们的分析中是相关的。
- en: On the contrary, if we see metrics where, regardless of the cohort average value,
    there’s no impact on churn (e.g. horizontal line), then we may consider excluding
    the metric from the model.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，如果我们看到指标中，无论队列的平均值如何，对流失没有影响（例如水平线），那么我们可能会考虑将该指标从模型中排除。
- en: 3\. Churn prediction with Machine Learning
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 机器学习中的流失预测
- en: We will now use the dataset to predict churn.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将使用数据集来预测流失。
- en: 'Note that churn is *not simple* to predict. Deciding to churn is subjective
    and it may not always be a logical choice: one client may churn because of costs-related
    issues and others may churn because of quality. Additionally, bad customer service
    or a perceived negative feeling about the product/brand may trigger the decision
    to churn subjectively.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，流失的预测是*不简单*的。决定流失是主观的，而且可能并不总是一个逻辑选择：一个客户可能因为费用问题而流失，其他客户可能因为质量问题而流失。此外，糟糕的客户服务或对产品/品牌的负面感受也可能主观地引发流失决定。
- en: For these reasons, model performances won’t be as high as in other ML tasks.
    According to Carl S. Gold [1], a healthy churn prediction model would perform
    with an AUC score between 0.6 and 0.8.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这些原因，模型的表现不会像其他机器学习任务那样高。根据Carl S. Gold [1]的说法，一个健康的流失预测模型的AUC得分应在0.6到0.8之间。
- en: 'Some considerations to take into account:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 需要考虑的一些因素：
- en: 'Churn is a binary classification task: the model would learn to predict if
    a record belongs to class 1 (churned client) or class 0 (not churn). However,
    we will be interested in the ***probability that each record belongs to each class***.
    Keep this in mind when selecting a model.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流失是一个二分类任务：模型将学习预测记录是否属于类1（流失客户）或类0（未流失）。然而，我们将关注***每条记录属于每个类别的概率***。在选择模型时，请记住这一点。
- en: 'Model performances cannot be measured using accuracy score. Usually, a low
    minority of clients churn and therefore our dataset is unbalanced: only approx.
    10% of the dummy data belongs to class 1 (churned clients). Any model that always
    predicts class 0, will have a 90% accuracy but such model wouldn’t help at all.
    Instead, we will use the ***roc_auc score*** to measure performances.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型表现不能通过准确率来衡量。通常，少数客户流失，因此我们的数据集是不平衡的：仅约10%的虚拟数据属于类1（流失客户）。任何总是预测类0的模型将具有90%的准确率，但这样的模型完全没有帮助。相反，我们将使用***roc_auc得分***来衡量性能。
- en: We will be using cross-validation to tune models’ hyperparameters. Since we’re
    working with a timed dataset, we cannot simply use a random record assignment
    to each fold. We need to train our model to use present or past data and never
    use future data. So, the best practice suggests using a ***Time Series Split***
    (from [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html)
    [2]), which works on any time-sorted dataset.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将使用交叉验证来调整模型的超参数。由于我们处理的是时间序列数据集，我们不能简单地使用随机记录分配到每个折叠。我们需要训练我们的模型使用当前或过去的数据，而不是未来的数据。因此，最佳实践建议使用***时间序列分割***（来自[sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html)
    [2]），它适用于任何按时间排序的数据集。
- en: '*(Note: in cross-validation, 10 splits are normally used. Here, 3 were used
    due to the limited data size and very unbalanced data towards class 0).*'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '*(注意：在交叉验证中，通常使用10个拆分。这里由于数据量有限和数据对类0极度不平衡，使用了3个拆分)。*'
- en: Let’s now compare three classification models.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们比较三种分类模型。
- en: 3.1 Logistic Regression
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.1 逻辑回归
- en: Logistic regression is a generalized linear regression model, which is a very
    common classification technique, especially used for binary classification. Since
    it’s a regression model, many hypotheses should be verified beforehand; for instance,
    we should not violate the “no multicollinearity” assumption, meaning that we should
    ensure that no features are correlated, i.e. each feature should provide unique
    and independent information.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是一个广义的线性回归模型，这是一种非常常见的分类技术，尤其用于二分类问题。由于它是一个回归模型，许多假设需要事先验证；例如，我们不应违反“无多重共线性”假设，这意味着我们需要确保没有特征是相关的，即每个特征应提供独特且独立的信息。
- en: Although this would be easy to verify, I can anticipate that logistic regression
    won’t be the most performing model, so we won’t be using any invalid results we
    may obtain.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这很容易验证，我可以预见逻辑回归不会是性能最好的模型，因此我们不会使用我们可能获得的任何无效结果。
- en: '![](../Images/ddf9b140349ae80c8918d589f967f132.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ddf9b140349ae80c8918d589f967f132.png)'
- en: Logisitc Regression | Image by author
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归 | 作者插图
- en: 3.2 Random Forest
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.2 随机森林
- en: Random Forest is an ensemble tree-based method.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是一种基于树的集成方法。
- en: '**Tree-based methods** are very powerful classification (or regression) algorithms
    that consist in splitting our train data according to several decision nodes.
    Each decision node performs a “split” with a True / False decision, based on a
    specific feature. The split decision is determined so that, on the next level
    of the tree, the “entropy” of our dataset is reduced the most. Entropy is a measure
    of the disorder of the data and it is linked to the “information gain” that we
    can get, in our classification/regression task.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于树的方法** 是非常强大的分类（或回归）算法，它们通过根据多个决策节点来划分我们的训练数据。每个决策节点根据特定特征执行一次“划分”，做出 True
    / False 决策。划分决策的确定方式是为了在树的下一层尽可能减少我们的数据集的“熵”。熵是数据无序程度的度量，它与我们在分类/回归任务中可以获得的“信息增益”相关。'
- en: For instance, in a binary classification problem, if we notice that by splitting
    data according to a feature, we get — for each True/False resulting branch — 95%
    percent of the data belonging to one class and 5% belonging to the opposite class,
    then we managed to gain more information from our data, reducing its level of
    disorder or “entropy”.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 例如，在一个二分类问题中，如果我们注意到通过根据一个特征来划分数据，我们得到的每个 True/False 结果分支中——95% 的数据属于一个类别，5%
    的数据属于另一个类别，那么我们就成功地从数据中获得了更多的信息，降低了数据的无序程度或“熵”。
- en: '**Random Forest (RF)** builds several different trees and then takes the average/most
    frequent result to make a final prediction. RF ensures that each tree is built
    differently from the others thanks to two methods:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**随机森林（RF）** 构建了多个不同的树，然后取这些树的平均值或最频繁的结果来做最终预测。RF 确保每棵树与其他树的构建方式不同，这得益于两种方法：'
- en: '*Bagging (bootstrap aggregating)*: each tree is trained by using a sample of
    the entire training set, so, each tree is built using different data.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Bagging（自助聚合）*：每棵树都是通过使用整个训练集的样本进行训练的，因此每棵树都是使用不同的数据构建的。'
- en: '*Feature randomness*: each tree is built by limiting the available features,
    using a subset of all the available features.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*特征随机性*：每棵树都是通过限制可用特征来构建的，使用所有可用特征的一个子集。'
- en: 'Let’s now tune RF hyperparameters on our dataset, select the best model and
    show the most “important” features (i.e. the frequency representing how often
    each feature is used to generate a decision split):'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们在数据集上调整 RF 的超参数，选择最佳模型，并展示最“重要”的特征（即每个特征用于生成决策分裂的频率）：
- en: '![](../Images/7740711313d8cd5ad8592673f7393a6e.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7740711313d8cd5ad8592673f7393a6e.png)'
- en: Random Forest | Image by author
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林 | 作者插图
- en: 3.3 XGBoost
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.3 XGBoost
- en: '**XGBoost** stands for Extreme Gradient Boosting and it is another tree-based
    ensemble technique that, similarly to RF, allows to combine the predictions made
    by several decision trees.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**XGBoost** 代表极端梯度提升，它是另一种基于树的集成技术，与 RF 类似，允许将多个决策树的预测结果进行结合。'
- en: XGBoost is an evolution (“Extreme”) of the “*Gradient boosting*” methodology.
    So, to illustrate XGBoost, let’s examine these two aspects separately.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost 是“*梯度提升*”方法的一个进化（“极端”）版本。因此，为了说明 XGBoost，让我们分别考察这两个方面。
- en: 'In “**gradient boosting**” methods, differently from RF, the trees that are
    built are very much related. Predictions are made by “weak learners” (i.e. simple
    trees) that are improved over and over. Typically, the initial prediction is the
    average target value, and it is then refined by creating new trees. Each new tree
    is built from the previous trees’ errors: so, starting from the residuals/wrong
    predictions of the previous “weak learners”, a new tree is built, minimizing a
    cost function and assigning more weights to the attributes that generated the
    errors. Finally, results are combined by weighting the results from each tree.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在“**梯度提升**”方法中，与随机森林（RF）不同，构建的树之间有很大关联。预测是由“弱学习者”（即简单树）做出的，这些树会不断改进。通常，初始预测是目标值的平均值，然后通过创建新树进行精炼。每棵新树是基于前一棵树的错误构建的：因此，从前一轮“弱学习者”的残差/错误预测开始，建立新树，最小化成本函数，并对产生错误的属性分配更多权重。最后，通过加权每棵树的结果来组合结果。
- en: 'Starting from “gradient boosting”, “**Extreme Gradient Boosting**” is a complete
    algorithm that includes several improvements to the gradient boosting method,
    such as: performance optimizations and a regularization parameter (which allows
    to avoid overfitting). Most importantly, thanks to these additional elements,
    XGBoost can run on simple machines like normal laptops.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从“梯度提升”开始，“**极端梯度提升**”是一个完整的算法，包括对梯度提升方法的几项改进，如性能优化和正则化参数（可以避免过拟合）。最重要的是，得益于这些附加元素，XGBoost
    可以在像普通笔记本电脑这样的简单机器上运行。
- en: '![](../Images/96ab1b8c02fcb003325095f5156fd0db.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/96ab1b8c02fcb003325095f5156fd0db.png)'
- en: 4\. Generating churn predictions
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 生成流失预测
- en: The top-performing model is XGBoost and we will now use it to predict the churn
    probabilities of a [test set](https://github.com/gabri-al/churn_analysis) (containing
    new records not used in the training phase).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 表现最好的模型是 XGBoost，我们将使用它来预测 [测试集](https://github.com/gabri-al/churn_analysis)（包含在训练阶段未使用的新记录）的流失概率。
- en: 'After importing the test set, we calculate, for each record, the model’s predicted
    probabilities of belonging to class 1 (churned clients) and plot the ROC_AUC score:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在导入测试集后，我们计算每条记录属于类别 1（流失客户）的模型预测概率，并绘制 ROC_AUC 分数：
- en: '![](../Images/4d6614cfc76923e1c41fea03710f7904.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4d6614cfc76923e1c41fea03710f7904.png)'
- en: Test set AUC score | Image by author
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 测试集 AUC 分数 | 图片由作者提供
- en: 'Let’s add the predicted class to the original data. By default, all records
    with a predicted probability ≥ .5 will be assigned to class 1\. We can lower this
    threshold and compare the resulting confusion matrices:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将预测的类别添加到原始数据中。默认情况下，所有预测概率 ≥ .5 的记录将被分配到类别 1。我们可以降低这个阈值，并比较结果的混淆矩阵：
- en: '![](../Images/73e0e8b5c3e031a17c9c1ba91e67bca9.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/73e0e8b5c3e031a17c9c1ba91e67bca9.png)'
- en: Confusion Matrices | Image by author
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵 | 图片由作者提供
- en: By lowering the threshold, we can identify more churning clients (true positives
    and false positives) but there is still a considerable number of clients that
    will churn but we fail to identify (false negatives), despite the good performances
    of our xgboost model.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 通过降低阈值，我们可以识别更多的流失客户（真正的正例和假阳性），但仍有相当数量的客户会流失但我们未能识别（假阴性），尽管我们的 xgboost 模型表现良好。
- en: 'We could try to find a better model, but predicting churn is generally hard.
    So, instead of using a simple churn vs non-churn distinction, an idea is to use
    our predicted probabilities to define some different retention strategies:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以尝试找到更好的模型，但预测流失通常很困难。因此，除了使用简单的流失与非流失区分外，一个想法是利用我们预测的概率来定义一些不同的留存策略：
- en: For clients with a predicted_proba > .75 = high risk of churning, we can design
    a “strong” retention strategy. Since we expect few false positives, we can afford
    to invest in these clients with higher confidence.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于预测概率大于 .75 的客户 = 高风险流失，我们可以设计一种“强力”的留存策略。由于我们预期的假阳性很少，因此我们可以更有信心地对这些客户进行投资。
- en: Clients with predicted_proba between .5 and .75 = moderate risk of churning
    and “moderate” retention strategy.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测概率在 .5 和 .75 之间的客户 = 中等流失风险和“中等”留存策略。
- en: Clients with predicted_proba between .25 and .5 = low risk of churning and “weak”
    retention strategy.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测概率在 .25 和 .5 之间的客户 = 低风险流失和“弱”留存策略。
- en: 5\. Next steps
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. 下一步
- en: At this stage, we should have a working model which can assign a “probability
    of churn” to any new data.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们应该有一个能够为任何新数据分配“流失概率”的工作模型。
- en: 'The next step of our analysis is to further define the retention strategies
    mentioned before. Our strategy should address: (a) actions to take which could
    lead to a churn reduction; (b) how to measure the success of our actions; (c)
    finally, a rollout plan.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们分析的下一步是进一步定义前面提到的保留策略。我们的策略应包括：（a）可能导致流失减少的行动；（b）如何衡量我们行动的成功；（c）最后，推广计划。
- en: 'Here are some ideas to address these points:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些解决这些问题的想法：
- en: 'Identifying actions that lead to a churn reduction:'
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确定导致流失减少的行动：
- en: 'Let’s combine the importance of the features seen above, together with our
    predictions. For instance, both tree-based models ranked “**subs_B**” as the most
    used feature in the trees. We would need to dig more into it and understand what
    churn and non-churn clients look like with respect to subs_B. The cohort analysis
    seen earlier would help here:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们结合上面看到的特征重要性与我们的预测。例如，两个基于树的模型将“**subs_B**”列为树中使用最多的特征。我们需要深入了解流失和非流失客户在subs_B方面的情况。之前看到的群体分析将有助于这里：
- en: '![](../Images/1da13d54c6f5d5cd0201a9bd691951a4.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1da13d54c6f5d5cd0201a9bd691951a4.png)'
- en: Cohort Analysis on train data | Image by author
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练数据上进行群体分析 | 作者图像
- en: 'It seems that clients with high churn have the minimum value (i.e. 0 subscriptions,
    the data has been transformed so the x-axis values are not much interpretable
    here), or a too high number of “subs_B”. We have to be careful to draw some causal
    conclusions between “subs_B” and “is_churn”, as this analysis is not proving any
    sort of causal relationship. However, we could test some hypotheses:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来高流失的客户有最低值（即0订阅，数据已经被转换，因此x轴值在这里不太易于解释），或者“subs_B”的数量过多。我们必须小心地得出“subs_B”和“is_churn”之间的因果结论，因为此分析并未证明任何因果关系。然而，我们可以测试一些假设：
- en: It seems that clients are satisfied with our B product, could it help to cross-sell
    “B” to clients having only the A product, to reduce churn?
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 看起来客户对我们的B产品感到满意，将“B”产品交叉销售给仅拥有A产品的客户，是否有助于减少流失？
- en: We should also understand what is the business reason behind clients with so
    many “B” subscriptions. We may educate them to use our products more efficiently
    and reduce B subscriptions.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们还应该了解客户拥有这么多“B”订阅背后的业务原因。我们可以教育他们更有效地使用我们的产品，从而减少B订阅。
- en: '**How to measure the success of our actions**:'
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**如何衡量我们行动的成功**：'
- en: Once we identified some actions that we would like to suggest, we can plan our
    measurement methodology.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们确定了一些建议的行动，我们可以规划我们的测量方法。
- en: 'A/B tests are a very common way to do that:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: A/B 测试是一种非常常见的方式：
- en: We create two comparable samples from clients with similar predicted churn probabilities.
    One sample will represent our treatment group and will be exposed to our churn
    reduction strategy, the other sample will represent our control group and won’t
    be exposed to any retention action.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们从具有类似预测流失概率的客户中创建两个可比样本。一个样本将代表我们的处理组，并将暴露于我们的流失减少策略，另一个样本将代表我们的对照组，不会暴露于任何保留行动。
- en: We would hope to prove that the churn rate of our treatment group is significantly
    lower than the one of the control group.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们希望证明我们的处理组的流失率显著低于对照组。
- en: '**The rollout plan:**'
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**推广计划：**'
- en: 'When suggesting retention actions, we shouldn’t forget to take other contextual
    aspects into account. To name a few: how much churn is a concern? (i.e. are there
    a lot of new clients acquired to compensate for churn?) what’s the budget to address
    the problem? how long should we wait to see the results? can we use any other
    data to improve our models? what has been done already?'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在建议保留行动时，我们不应忘记考虑其他背景因素。举几个例子：流失的担忧程度如何？（即是否有大量新客户以弥补流失？）解决问题的预算是多少？我们应该等多久才能看到结果？我们可以使用其他数据来改善模型吗？已经做了哪些工作？
- en: This will help us understand if what we’re suggesting is feasible.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这将帮助我们了解我们建议的可行性。
- en: Thank you for reading!!
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 谢谢阅读！！
- en: References
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Carl S. Gold — “Fighting Churn with Data: The science and strategy of customer
    retention”, 2020'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Carl S. Gold — “用数据对抗流失：客户保留的科学与策略”，2020年'
- en: '[2] [Scikit-learn: Machine Learning in Python](https://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html),
    Pedregosa *et al.*, JMLR 12, pp. 2825–2830, 2011'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [Scikit-learn: Python中的机器学习](https://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html)，Pedregosa
    *等*，JMLR 12，第2825–2830页，2011年'
