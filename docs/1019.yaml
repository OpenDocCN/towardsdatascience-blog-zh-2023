- en: Train your ML models on GPU changing just one line of code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/train-your-ml-models-on-gpu-changing-just-one-line-of-code-5f8ff96a91ba?source=collection_archive---------12-----------------------#2023-03-20](https://towardsdatascience.com/train-your-ml-models-on-gpu-changing-just-one-line-of-code-5f8ff96a91ba?source=collection_archive---------12-----------------------#2023-03-20)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Utilize cuML and ATOM to make your machine learning pipelines blazingly fast
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://tvdboom.medium.com/?source=post_page-----5f8ff96a91ba--------------------------------)[![Marco
    vd Boom](../Images/3fc053efda1c23dd84a6418ded2603ca.png)](https://tvdboom.medium.com/?source=post_page-----5f8ff96a91ba--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5f8ff96a91ba--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5f8ff96a91ba--------------------------------)
    [Marco vd Boom](https://tvdboom.medium.com/?source=post_page-----5f8ff96a91ba--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe2091b627921&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-your-ml-models-on-gpu-changing-just-one-line-of-code-5f8ff96a91ba&user=Marco+vd+Boom&userId=e2091b627921&source=post_page-e2091b627921----5f8ff96a91ba---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5f8ff96a91ba--------------------------------)
    ·5 min read·Mar 20, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5f8ff96a91ba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-your-ml-models-on-gpu-changing-just-one-line-of-code-5f8ff96a91ba&user=Marco+vd+Boom&userId=e2091b627921&source=-----5f8ff96a91ba---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5f8ff96a91ba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-your-ml-models-on-gpu-changing-just-one-line-of-code-5f8ff96a91ba&source=-----5f8ff96a91ba---------------------bookmark_footer-----------)![](../Images/47cda21ca8cd9c5fe8ecf85bd2b81072.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Thomas Foster](https://unsplash.com/de/@thomasfos?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Graphics Processing Units (GPUs) can significantly accelerate calculations for
    preprocessing steps or training machine learning models. Training models typically
    involves compute-intensive matrix multiplications and other operations that can
    take advantage of a GPU’s massively parallel architecture. Training on large datasets
    can take hours to run on a single processor. However, if you offload those tasks
    to a GPU, you can reduce training time to minutes instead.
  prefs: []
  type: TYPE_NORMAL
- en: In this story, we’ll show you how to use the [ATOM](https://github.com/tvdboom/ATOM)
    library to easily train your machine learning pipeline on a GPU. ATOM is an open-source
    Python package designed to help data scientists fasten the exploration of machine
    learning pipelines. Read [this story](/atom-a-python-package-for-fast-exploration-of-machine-learning-pipelines-653956a16e7b)
    if you want a gentle introduction to the library.
  prefs: []
  type: TYPE_NORMAL
- en: Set up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ATOM uses [cuML](https://github.com/rapidsai/cuml) as backend library for GPU
    training. cuML is a suite of fast, GPU-accelerated machine learning algorithms
    designed for data science and analytical tasks. Unfortunately, cuML can not be
    installed through pip, and is therefore not installed as a dependency of ATOM.
    Read [here](https://docs.rapids.ai/install) how to install it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Requirements for cuML to take into account:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Operating System: Ubuntu 18.04/20.04 or CentOS 7/8 with gcc/++ 9.0+ or Windows
    10+ with WSL2'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GPU: NVIDIA Pascal™ or better with [Compute capability](https://developer.nvidia.com/cuda-gpus)
    6.0+'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Drivers: CUDA & NVIDIA Drivers of versions 11.0, 11.2, 11.4 or 11.5'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tip:** See [this repo](https://github.com/rapidsai-community/rapids-smsl)
    to install cuML on [SageMaker Studio Lab](https://studiolab.sagemaker.aws/).'
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Training transformers and models in atom using a GPU is as easy as
  prefs: []
  type: TYPE_NORMAL
- en: 'initializing *atom* with parameter `device="gpu"`. The `device` parameter accepts
    any string that follows the [SYCL_DEVICE_FILTER](https://github.com/intel/llvm/blob/sycl/sycl/doc/EnvironmentVariables.md#sycl_device_filter)
    filter selector. Examples are:'
  prefs: []
  type: TYPE_NORMAL
- en: device=”cpu” (use CPU)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: device=”gpu” (use default GPU)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: device=”gpu:0" (use first GPU)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: device=”gpu:1" (use second GPU)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Note:** ATOM does not support multi-GPU training. If there is more than one'
  prefs: []
  type: TYPE_NORMAL
- en: GPU on the machine and the `device` parameter does not specify which
  prefs: []
  type: TYPE_NORMAL
- en: one to use, the first one is used by default.
  prefs: []
  type: TYPE_NORMAL
- en: Use the `engine` parameter to choose between the cuML and sklearnex execution
    engines. In this story, we will focus on cuML. The [XGBoost](https://tvdboom.github.io/ATOM/v5.1/API/models/xgb/),
    [LightGBM](https://tvdboom.github.io/ATOM/v5.1/API/models/lgb/) and [CatBoost](https://tvdboom.github.io/ATOM/v5.1/API/models/catb/)
    models come with their own GPU engine. Setting device=”gpu” is sufficient to accelerate
    them with GPU, regardless of the engine parameter. Click [here](https://tvdboom.github.io/ATOM/v5.1/user_guide/accelerating/#supported-estimators_1)
    for an overview of the transformers and models that support GPU acceleration.
  prefs: []
  type: TYPE_NORMAL
- en: '**Tip:** If you don’t have access to a GPU, you can use online cloud services
    like [Google Colab](https://colab.research.google.com/) or [Sagemaker Studio Lab](https://studiolab.sagemaker.aws/)
    to try it out. Make sure to choose the GPU compute type. See [this notebook](https://studiolab.sagemaker.aws/import/github/tvdboom/ATOM/blob/master/examples/accelerating_cuml.ipynb)
    to get you started.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get started with the example.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/55acf33fb5b7d0954041f4858c0ca1db.png)'
  prefs: []
  type: TYPE_IMG
- en: Not only models, but also transformers can benefit from GPU acceleration. For
    example, to scale the features to mean=0 and std=1.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/8c063e8ed093c866d452bc5a70af3b9b.png)'
  prefs: []
  type: TYPE_IMG
- en: Since we stated that we want to use the cuML engine, ATOM automatically selects
    the transformer from that library whenever available.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/c9ddb00955323c040c092a1c234a8b0f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let’s train three models: the [Random Forest](https://tvdboom.github.io/ATOM/v5.1/API/models/rf/)
    is available in cuML, the [Stochastig Gradient Descent](https://tvdboom.github.io/ATOM/v5.1/API/models/sgd/)
    is not, and [XGBoost](https://tvdboom.github.io/ATOM/v5.1/API/models/xgb/) has
    its own GPU implementation.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/33a1e0871c3a4ffb7d8b45b5e06c1e5f.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/c33a9703e165fc7293d750a134ff0b51.png)'
  prefs: []
  type: TYPE_IMG
- en: Note the massive difference in training time between the models!
  prefs: []
  type: TYPE_NORMAL
- en: If we check the underlying estimators, we’ll see that the the RF model was indeed
    trained on GPU, the SGD wasn’t (since it’s not available on cuML, ATOM falls back
    to the default sklearn implementation), and the XGB model did train on GPU using
    its native module.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/361899e33da3925a1afae09cd6ebc382.png)'
  prefs: []
  type: TYPE_IMG
- en: Lastly, analyzing the results is as easy as always.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/02f1c905f80dca2a6d6bc8c29145edf8.png)'
  prefs: []
  type: TYPE_IMG
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have shown how to use the ATOM package to train your machine learning pipelines
    on GPU. ATOM is also capable of acceleration on CPU. Read [this story](https://medium.com/towards-data-science/make-your-sklearn-models-up-to-100-times-faster-563bb682665e)
    to learn how.
  prefs: []
  type: TYPE_NORMAL
- en: For further information about ATOM, have a look at the package’s [documentation](https://tvdboom.github.io/ATOM/).
    For bugs or feature requests, don’t hesitate to open an issue on [GitHub](https://github.com/tvdboom/ATOM)
    or send me an email.
  prefs: []
  type: TYPE_NORMAL
- en: 'References:'
  prefs: []
  type: TYPE_NORMAL
- en: All plots and images (except the featured image) are created by the author.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Related stories:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/atom-a-python-package-for-fast-exploration-of-machine-learning-pipelines-653956a16e7b?source=post_page-----5f8ff96a91ba--------------------------------)
    [## ATOM: A Python package for fast exploration of machine learning pipelines'
  prefs: []
  type: TYPE_NORMAL
- en: Automated Tool for Optimized Modelling (ATOM) is an open-source Python package
    designed to help data scientists perform…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/atom-a-python-package-for-fast-exploration-of-machine-learning-pipelines-653956a16e7b?source=post_page-----5f8ff96a91ba--------------------------------)
    [](/exploration-of-deep-learning-pipelines-made-easy-e1cf649892bc?source=post_page-----5f8ff96a91ba--------------------------------)
    [## Exploration of Deep Learning pipelines made easy
  prefs: []
  type: TYPE_NORMAL
- en: A simple guide on how to use the right package to perform fast DL experimentations
    in Python
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/exploration-of-deep-learning-pipelines-made-easy-e1cf649892bc?source=post_page-----5f8ff96a91ba--------------------------------)
    [](/make-your-sklearn-models-up-to-100-times-faster-563bb682665e?source=post_page-----5f8ff96a91ba--------------------------------)
    [## Make your sklearn models up to 100 times faster
  prefs: []
  type: TYPE_NORMAL
- en: How to considerable reduce training time changing only 1 line of code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/make-your-sklearn-models-up-to-100-times-faster-563bb682665e?source=post_page-----5f8ff96a91ba--------------------------------)
  prefs: []
  type: TYPE_NORMAL
