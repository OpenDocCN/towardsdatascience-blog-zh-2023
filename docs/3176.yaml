- en: From Data Platform to ML Platform
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/from-data-platform-to-ml-platform-4a8192edab5d?source=collection_archive---------0-----------------------#2023-10-22](https://towardsdatascience.com/from-data-platform-to-ml-platform-4a8192edab5d?source=collection_archive---------0-----------------------#2023-10-22)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How Data/ML platforms evolve and support complex MLOps practices
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@ming.gao.gm?source=post_page-----4a8192edab5d--------------------------------)[![ming
    gao](../Images/4eeb08e6f2f47f789801694b82fe3057.png)](https://medium.com/@ming.gao.gm?source=post_page-----4a8192edab5d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4a8192edab5d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4a8192edab5d--------------------------------)
    [ming gao](https://medium.com/@ming.gao.gm?source=post_page-----4a8192edab5d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F56b61a38427c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-data-platform-to-ml-platform-4a8192edab5d&user=ming+gao&userId=56b61a38427c&source=post_page-56b61a38427c----4a8192edab5d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4a8192edab5d--------------------------------)
    ·9 min read·Oct 22, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4a8192edab5d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-data-platform-to-ml-platform-4a8192edab5d&user=ming+gao&userId=56b61a38427c&source=-----4a8192edab5d---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4a8192edab5d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-data-platform-to-ml-platform-4a8192edab5d&source=-----4a8192edab5d---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Data/ML has been the most popular topic in our tech landscape. I want to share
    my understanding of Data/ML Platform and how would those platforms evolve from
    basic to complex. At last, I try my best to cover MLOps, a principle for managing
    ML projects.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: About who-I-am, here is [my LinkedIn](https://www.linkedin.com/in/ming-gao-57509a101/).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: 'Starting of the Journey: Online Service + OLTP + OLAP'
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the starts, data infrastructures could be fairly simple. Analytical queries
    might be sent to the read replica of a online [OLTP database](https://en.wikipedia.org/wiki/Online_transaction_processing)
    or setting up a OLAP database serve as data warehouse.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the infrastructure might look like:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/91b189e685127aef067dfd947f9df224.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: There is nothing wrong with those systems as long as it fulfil business requirements.
    All systems that fulfil our business need are good systems. If there are simple,
    it is even better.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 只要系统能够满足业务需求，就没有问题。满足我们业务需求的所有系统都是好的系统。如果它们简单，那就更好。
- en: 'At this stage, there are multiple ways of doing data analysis:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，有多种数据分析方法：
- en: Simply submit queries to OLTP database’s replica node. (Not recommended).
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仅向 OLTP 数据库的副本节点提交查询。（不推荐）
- en: Enabling CDC(Change Data Capture) of OLTP databse and ingest those data to OLAP
    database. Come to the option of ingestion service for CDC logs, you can choose
    based on the OLAP database you have selected. For example, [Flink data streaming
    with CDC connectors](https://github.com/ververica/flink-cdc-connectors) is a way
    to handle this. Many enterprise services come with their own suggested solution,
    e.g. [Snowpipe](https://quickstarts.snowflake.com/guide/CDC_SnowpipeStreaming_DynamicTables/index.html?index=..%2F..index#0)
    for Snowflake. It is also recommended to load data from replica node to preserve
    the CPU/IO bandwidth of master node for online traffic.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启用 OLTP 数据库的 CDC（变更数据捕捉）并将这些数据导入到 OLAP 数据库。关于 CDC 日志的导入服务选项，你可以根据所选择的 OLAP 数据库来选择。例如，[Flink
    数据流与 CDC 连接器](https://github.com/ververica/flink-cdc-connectors) 是处理此问题的一种方式。许多企业服务提供自己的建议解决方案，例如
    [Snowpipe](https://quickstarts.snowflake.com/guide/CDC_SnowpipeStreaming_DynamicTables/index.html?index=..%2F..index#0)
    适用于 Snowflake。也建议从副本节点加载数据，以保持主节点的 CPU/IO 带宽用于在线流量。
- en: In this stage, ML workloads might be running in your local environment. You
    can set up a [Jupyter](https://jupyter.org/install) notebook locally, and load
    structured data from OLAP Database, then train your ML model locally.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，ML 任务可能在本地环境中运行。你可以在本地设置一个 [Jupyter](https://jupyter.org/install) 笔记本，从
    OLAP 数据库加载结构化数据，然后在本地训练 ML 模型。
- en: 'The potential challenges of this architecture are but not limited to:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这种架构的潜在挑战包括但不限于：
- en: It is hard to manage unstructured or semi-structured data with OLAP database.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 OLAP 数据库管理非结构化或半结构化数据是困难的。
- en: OLAP might have performance regression when come to massive data processing.
    (more than TB data required for a single ETL task)
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当处理海量数据时，OLAP 可能会出现性能回退。（单个 ETL 任务需要 TB 以上的数据）
- en: Lack of supporting for various compute engines, e.g. Spark or Presto. Most of
    compute engine do support connecting to OLAP with JDBC endpoint, but the parallel
    processing will be badly limited by the IO bottleneck of JDBC endpoint itself.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对各种计算引擎的支持不足，例如 Spark 或 Presto。大多数计算引擎确实支持通过 JDBC 端点连接到 OLAP，但并行处理会受到 JDBC 端点自身的
    IO 瓶颈严重限制。
- en: The cost of storing massive data in OLAP database is high.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储海量数据在 OLAP 数据库中的成本很高。
- en: You might know the direction to solve this already. Build a Data lake! Bringing
    in Data lake do not necessary mean you need to completely sunset OLAP Database.
    It is still common to see company having two systems co-exist for different use-cases.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经知道解决此问题的方向。建立一个数据湖！引入数据湖并不一定意味着你需要完全淘汰 OLAP 数据库。公司中有两种系统共存以满足不同用例仍然很常见。
- en: 'Data lake: Storage-Compute Separation + Schema on Write'
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据湖：存储计算分离 + 写时模式
- en: A data lake allows you to persist unstructured and semi-structure data, and
    performs schema-on-read. It allows you reduce cost by storing large data volume
    with specialised storage solution and spun up compute cluster based on your demand.
    It further allows you to manage TB/PB dataset effortlessly by scaling up the compute
    clusters.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据湖允许你持久化非结构化和半结构化数据，并执行按需模式。它允许你通过使用专门的存储解决方案存储大量数据来降低成本，并根据需求启动计算集群。它还允许你通过扩展计算集群轻松管理
    TB/PB 数据集。
- en: 'There is how your infrastructure might look like:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 你的基础设施可能如下所示：
- en: '![](../Images/c23044e4526d4ac5dee67ac3bd0cf016.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c23044e4526d4ac5dee67ac3bd0cf016.png)'
- en: Image by the author
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: This is an oversimplified graph indeed. The actually implementation of a data
    lake can be much more complicated.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这确实是一个过于简化的图示。数据湖的实际实现可能要复杂得多。
- en: Many cloud provider now have quite established store solution for Data lake,
    e.g. AWS S3 and Azure ADLS. There is still a lot of tasks need to be done on top
    of those storage solutions. For example, there should be a Hive metastore to manage
    your table metadata and a [Datahub](https://github.com/datahub-project/datahub)
    to provide data visibility. There are also challenging topics like *fine-grain
    permission control in data lake* and *data lineage analysis(e.g.* [spline](https://absaoss.github.io/spline/)*)*.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在许多云服务提供商已经有相当成熟的数据湖存储解决方案，例如 AWS S3 和 Azure ADLS。在这些存储解决方案之上仍然需要完成许多任务。例如，应该有一个
    Hive metastore 来管理你的表元数据，以及一个 [Datahub](https://github.com/datahub-project/datahub)
    提供数据可视性。还有一些具有挑战性的话题，如 *数据湖中的精细权限控制* 和 *数据血缘分析（例如* [spline](https://absaoss.github.io/spline/)*)*。
- en: To maximum the value and efficiency of your data lake, we should carefully choose
    file format and average file sizes for each layers of your data lake.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最大化你的数据湖的价值和效率，我们应该仔细选择每个数据湖层的文件格式和平均文件大小。
- en: '![](../Images/b7f14745cfb589ea9bac421913334c57.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b7f14745cfb589ea9bac421913334c57.png)'
- en: Image by the author
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'The general tips are:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一般建议包括：
- en: 'Avoid small files: Small files are one of major causes for high storage cost
    and poor performance in Data lake.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免小文件：小文件是数据湖中高存储成本和性能差的主要原因之一。
- en: 'Balance between *latency*, *compress* *ratio* and *performance*: A low latency
    Data lake table with file format like [Hudi](https://hudi.apache.org/blog/2021/07/21/streaming-data-lake-platform/)
    might not give you the best compress ratio, and large ORC files with high compress
    ratio might give your performance nightmare. You might want to choose file format
    wisely based on the usage pattern of the table, latency requirement and table
    sizes.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 *延迟*、*压缩* *比率* 和 *性能* 之间的平衡：具有文件格式如 [Hudi](https://hudi.apache.org/blog/2021/07/21/streaming-data-lake-platform/)
    的低延迟数据湖表可能不会给你最佳的压缩比，而大容量的 ORC 文件高压缩比可能会带来性能噩梦。你可能需要根据表的使用模式、延迟要求和表大小来明智地选择文件格式。
- en: There are some quite established SaaS/PaaS provider like [Databricks](https://www.databricks.com/)
    which provide a decent Data lake(or LakeHouse now) solution. You also can explore
    [ByteHouse](https://bytehouse.cloud/) to have a unified experience of big data
    analysis.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一些成熟的 SaaS/PaaS 提供商如 [Databricks](https://www.databricks.com/) 提供了相当不错的数据湖（或现在的
    LakeHouse）解决方案。你也可以探索 [ByteHouse](https://bytehouse.cloud/) 以获得统一的大数据分析体验。
- en: On the ML side, team might start exploring well established ML framework like
    Tensenflow and Pytorch in remote environment. Furthermore, trained ML models could
    been deployed to production environment for online model inferrence. Both Tensorflow
    and Pytorch come with serving solution, e.g. TensorFlow Serving and Pytorch Serving.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习方面，团队可能会开始在远程环境中探索成熟的机器学习框架，如 Tensorflow 和 Pytorch。此外，训练好的机器学习模型可以部署到生产环境中进行在线模型推理。Tensorflow
    和 Pytorch 都提供了服务解决方案，例如 TensorFlow Serving 和 Pytorch Serving。
- en: 'However, our journey will not stop here. We might have following challenges
    now:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们的旅程不会就此停止。我们现在可能面临以下挑战：
- en: Lack of realtime metric and features management which are critical for online
    ML model serving.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏实时指标和特征管理，这对在线机器学习模型服务至关重要。
- en: Lack of model performance monitoring.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏模型性能监控。
- en: Let’s level up our game further.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进一步提升我们的游戏水平。
- en: 'Realtime Data/ML Infra: Data River + Data Streaming + Feature Store + Metric
    Server'
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实时数据/机器学习基础设施：数据流 + 数据流媒体 + 特征存储 + 指标服务器
- en: It usually a joint effort from multiple departments of companies to build realtime
    data infra. The initial rationale of building Data River usually is not for data/ML
    system but allowing micro-services to further scale up by removing synchronised
    call. Instead, micro-services will gain efficiency by communicating with a message
    broker like [Kafka](https://kafka.apache.org/) (at the cost of lower consistency
    level).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，构建实时数据基础设施是公司多个部门的共同努力。构建数据流的初衷通常不是为了数据/机器学习系统，而是通过消除同步调用来允许微服务进一步扩展。相反，微服务将通过与像
    [Kafka](https://kafka.apache.org/) 这样的消息中间件进行通信而提高效率（代价是较低的一致性水平）。
- en: The overall architecture might look like this.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 整体架构可能如下所示。
- en: '![](../Images/11709d7d8e95a361f21cc6d4ff616520.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/11709d7d8e95a361f21cc6d4ff616520.png)'
- en: Image by the author
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: With data available in Data River (e.g. [Kafka](https://kafka.apache.org/)),
    we can build data streaming pipeline to process realtime data. Those data can
    be used directly in online feature store or sync to an metric server like [Pinot](https://github.com/apache/pinot).
    Metric server can further process/aggregate those metric point to more useful
    model performance metrics and business metrics. You can also adopt streaming database
    like [RisingWave](https://www.risingwave.com/) which can joining/aggregating streaming
    data with SQL syntax.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 有了在数据河流（例如[Kafka](https://kafka.apache.org/)）中的数据，我们可以构建数据流管道来处理实时数据。这些数据可以直接用于在线特征存储或同步到像[Pinot](https://github.com/apache/pinot)这样的度量服务器。度量服务器可以进一步处理/聚合这些度量点，形成更有用的模型性能度量和业务度量。你也可以采用像[RisingWave](https://www.risingwave.com/)这样的流数据库，它可以用SQL语法对流数据进行连接/聚合。
- en: For building data streaming itself, [Flink](https://flink.apache.org/) is quite
    popular. You can also use [Flink with CDC connector](https://ververica.github.io/flink-cdc-connectors/release-2.1/content/about.html)
    to extract data from OLTP database and sink data to message brokers and data lake.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据流构建，[Flink](https://flink.apache.org/)相当受欢迎。你也可以使用[带有CDC连接器的Flink](https://ververica.github.io/flink-cdc-connectors/release-2.1/content/about.html)从OLTP数据库提取数据，并将数据发送到消息中间件和数据湖。
- en: There should be a online feature store backed by key-value database like [ScyllaDB](https://www.scylladb.com/)
    or AWS Dynamo DB. Online feature store can help you enrich the the request sent
    to Model Serving service with a feature vector associated with certain reference
    ID (user-id, product uuid). It can greatly de-couple the dependency between backend
    service team who build micro-services and ML engineer team who build ML models.
    It allow ML engineers rollout new ML feature with new ML model independently (*Your
    model serving API signature expose to micro-services will remain the same when
    you update feature vector).*
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 应该有一个在线特征存储，支持如[ScyllaDB](https://www.scylladb.com/)或AWS Dynamo DB等键值数据库。在线特征存储可以帮助你用与特定参考ID（用户ID、产品UUID）相关联的特征向量丰富发送给模型服务的请求。这可以极大地解耦构建微服务的后台服务团队与构建ML模型的ML工程师团队之间的依赖关系。它允许ML工程师独立推出新的ML特征与新ML模型（*当你更新特征向量时，你的模型服务API签名对微服务的暴露将保持不变*）。
- en: '![](../Images/630bcf3480c7796bd8d4878d436ad999.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/630bcf3480c7796bd8d4878d436ad999.png)'
- en: Image by the author
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: In the book, [Designing Machine Learning System](https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/),
    it has shared about Model Stacking ([Jen Wadkin’s](https://threnjen.medium.com/)
    [medium post](/simple-model-stacking-explained-and-automated-1b54e4357916) about
    model stacking). It is quite common for people to use model stacking in model
    serving as well. An orchestrator is required when you want to to stack hererogenous
    models together, e.g. stacking pytorch and tensorflow model together. You potential
    can make your orchestrator even more complicated by having a dynamic weightage
    based on model performance when routing request to different models.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在书中，[设计机器学习系统](https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/)提到了模型堆叠（[Jen
    Wadkin的](https://threnjen.medium.com/) [medium帖子](/simple-model-stacking-explained-and-automated-1b54e4357916)关于模型堆叠）。在模型服务中使用模型堆叠是相当常见的。当你想将异构模型堆叠在一起时，例如将pytorch和tensorflow模型堆叠在一起时，需要一个协调器。你还可以通过在路由请求到不同模型时根据模型性能动态调整权重，使你的协调器变得更加复杂。
- en: 'Now we have a complicated system. It looks pretty cool but it carry new challenges:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个复杂的系统。它看起来很酷，但带来了新的挑战：
- en: Debt of the system will soaring high if leave it unmanage.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果不加以管理，系统的债务将迅速增加。
- en: High cognitive load for ML engineers.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对ML工程师而言认知负担很重。
- en: That’s probably when you need to thinking how MLOps can help you.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这时你可能需要思考MLOps如何帮助你。
- en: 'MLOps: Abstraction, Observability and Scalability'
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLOps：抽象、可观察性和可扩展性
- en: 'MLOps is never a specific solution. It is more like a set of principles for
    managing ML system. Different with a typical software project. ML systems are
    greatly affected by data shifting, and data dependency management is not a easy
    task. Paper [Hidden Technical Debt in Machine Learning Systems](https://proceedings.neurips.cc/paper_files/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf)
    has described those challenges in details. Therefore, a MLOps driven ML platform
    must able to:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps从来不是一个具体的解决方案。它更像是一组用于管理ML系统的原则。与典型的软件项目不同，ML系统受数据变化的影响很大，数据依赖管理并非易事。论文[机器学习系统中的隐性技术债务](https://proceedings.neurips.cc/paper_files/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf)详细描述了这些挑战。因此，一个由MLOps驱动的ML平台必须能够：
- en: Data change monitoring & data quality monitoring.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据变化监控和数据质量监控。
- en: Manage ML features across offline and online environment.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理离线和在线环境中的ML特征。
- en: Reproducible ML Pipeline which fulfil experimental-operational symmetry.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可重复的ML管道，满足实验-操作对称性。
- en: Concise ML pipeline configuration which can abstract away infra details.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简洁的ML管道配置，可以抽象出基础设施的细节。
- en: 'This article, [MLOps: Continuous delivery and automation pipelines in machine
    learning](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning),
    highlighted the importance of [experimental-operational symmetric](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#characteristics_2).
    It also described MLOps automation level from level-0, level-1 to finally level-2\.
    I really like the graph from this doc and will just borrow it to explain what
    level-1 MLOps looks like.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '本文，[MLOps: 机器学习中的持续交付和自动化管道](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)，强调了[实验-操作对称性](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#characteristics_2)的重要性。它还描述了MLOps的自动化级别，从level-0、level-1到最终的level-2。我非常喜欢这份文档中的图表，将借用它来解释level-1
    MLOps的样子。'
- en: '![](../Images/995a8cd1a179f9c0570df09ceb34025e.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/995a8cd1a179f9c0570df09ceb34025e.png)'
- en: 'Image by Author. Describing MLOps Level-1 in [MLOps: Continuous delivery and
    automation pipelines in machine learning](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '作者提供的图像。描述了[MLOps: 机器学习中的持续交付和自动化管道](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)中的MLOps
    Level-1。'
- en: To scale such MLOps practise in your organisation, you need to provide concise
    ML pipeline configuration which can abstract infrastructure implementation details
    away for ML Engineers. By doing this, platform engineers also gain flexibility
    for upgrading ML platform without causing too much disruption to platform users.
    You can consider using configuration files like yaml to describe ML pipelines
    and rely on your ML Pipeline controllers to translate them to actual workload.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在您的组织中扩展这种MLOps实践，您需要提供简洁的ML管道配置，以便为ML工程师抽象出基础设施实现细节。这样，平台工程师也能在不对平台用户造成过多干扰的情况下灵活地升级ML平台。您可以考虑使用像yaml这样的配置文件来描述ML管道，并依靠您的ML管道控制器将其转换为实际的工作负载。
- en: So let’s re-organised realtime data/ML infra with following graph to highlight
    how MLOps shapes our platforms.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们通过以下图表重新组织实时数据/ML基础设施，以突出MLOps如何塑造我们的平台。
- en: '![](../Images/3e97f33cbd4aabce938a02c91af58155.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e97f33cbd4aabce938a02c91af58155.png)'
- en: Image by the author
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: To give you a better ideal of what the ML pipelines might look like. Here are
    the possible abstraction examples for each stage in ML pipeline. The following
    graph only help your to further understand what is the configuration might look
    like. It does not represent any actual implementation. It does not cover all aspects
    required neither.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 为了给您更好的了解ML管道可能的样子，这里是每个阶段的可能抽象示例。以下图表仅帮助您进一步理解配置的可能样子，并不代表任何实际实现，也不涵盖所有所需的方面。
- en: '![](../Images/1de18b307f8c4b3a05838f7fbba7a76f.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1de18b307f8c4b3a05838f7fbba7a76f.png)'
- en: A general idea of configurations in ML pipeline. Image by the author
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ML管道配置的一般概念。作者提供的图像
- en: Kubernetes is a popular solution to orchestrate ML workload(or maybe all workload
    nowadays). You can use CRDs to provide concise interfaces between users and platforms.
    In article [My thinking of Kubebuilder](https://towardsdev.com/my-thinking-about-kubebuilder-443a9d45f1e),
    I have shared some of my thinking when I build CRD with kubebuilder.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是一种流行的解决方案，用于编排机器学习工作负载（或如今的所有工作负载）。你可以使用 CRD 提供用户与平台之间的简洁接口。在文章[我对
    Kubebuilder 的思考](https://towardsdev.com/my-thinking-about-kubebuilder-443a9d45f1e)中，我分享了在使用
    kubebuilder 构建 CRD 时的一些想法。
- en: '![](../Images/816be3f43007666345b98180577530a5.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/816be3f43007666345b98180577530a5.png)'
- en: Image by the author
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: 'Of course, I didn’t cover many important sub-topics which include but not limited
    to:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我没有涵盖许多重要的子主题，包括但不限于：
- en: Hyperparameter Optimization
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超参数优化
- en: Distributed Training architecture
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式训练架构
- en: What Next
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 接下来做什么
- en: You can see ***MLOps only give a known mission a proper name***. It is far from
    a job done. What I shared is a opinionated strategy for implement ML Ops platform.
    Even with that, the bar of creating high quality ML product is still high, and
    the effort of collecting, processing, mining data is still heavy.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到***MLOps只是给已知任务一个合适的名称***。这远不是任务完成。我分享的是一个有观点的机器学习操作平台实施策略。即便如此，创建高质量机器学习产品的门槛仍然很高，收集、处理和挖掘数据的工作量仍然很大。
- en: Besides those challenges remains, I also want to share the trends in ML landscape
    I have observed. It is surely not a completed list given how fast this domain
    evolves.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些挑战之外，我还想分享我观察到的机器学习领域的趋势。鉴于这个领域发展的如此快速，这绝对不是一个完整的列表。
- en: 'Serviceless: We have put ML’s value too far behind because the foundation a
    ML platform is usually a Data platform. It is like forcing users to buy computers
    to engage on social media platforms when we are already in mobile time. Serviceless
    data services and data engine are addressing this challenge. Many service providers
    explore their own ***serveless*** solution to lower the bar of adoption, e.g.
    [Databricks](https://docs.databricks.com/en/serverless-compute/index.html), Snowflake
    , Bytehouse. Companies can start building their ML products after bootstrapping
    data warehouses, or data lakes, or lakehouses.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无服务：我们将机器学习的价值抛在了很远的后面，因为机器学习平台通常建立在数据平台的基础上。这就像在移动时代强迫用户购买计算机来参与社交媒体平台一样。无服务的数据服务和数据引擎正在应对这个挑战。许多服务提供商探索自己的***无服务***解决方案，以降低采用门槛，例如[Databricks](https://docs.databricks.com/en/serverless-compute/index.html)、Snowflake、Bytehouse。公司可以在启动数据仓库、数据湖或湖仓后开始构建他们的机器学习产品。
- en: 'AI driven feature engineering: Well, AI can do everything now, can’t it?'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI 驱动的特征工程：好吧，AI 现在可以做一切，对吗？
- en: 'MaaS trends: More powerful Model-as-a-Service will pop up. Companies can directly
    leverage on ML power without even building their own ML service to enjoy a great
    lifting to their business.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MaaS 趋势：更强大的模型即服务（Model-as-a-Service）将会出现。公司可以直接利用机器学习的力量，而无需自己构建机器学习服务，从而极大地提升他们的业务。
- en: As we all have noticed, ML space evolves so fast. At this very moment, when
    I am typing this, this article might already been expired. More ideas had already
    popped up and been translated to reality. Please do let me know what do you think
    about of ML Ops, or where should I further my learning. Let’s keep up the pace
    together!
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们都注意到的，机器学习领域发展如此迅速。在我打字的此刻，这篇文章可能已经过时。更多的想法已经出现并转化为现实。请告诉我你对机器学习操作的看法，或者我应该在哪些方面进一步学习。让我们一起保持进度！
