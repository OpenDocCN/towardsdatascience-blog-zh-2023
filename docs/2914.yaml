- en: 'LLM Output Parsing: Function Calling vs. LangChain'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM输出解析：函数调用与LangChain
- en: 原文：[https://towardsdatascience.com/llm-output-parsing-function-calling-vs-langchain-63b80545b3a7?source=collection_archive---------2-----------------------#2023-09-21](https://towardsdatascience.com/llm-output-parsing-function-calling-vs-langchain-63b80545b3a7?source=collection_archive---------2-----------------------#2023-09-21)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/llm-output-parsing-function-calling-vs-langchain-63b80545b3a7?source=collection_archive---------2-----------------------#2023-09-21](https://towardsdatascience.com/llm-output-parsing-function-calling-vs-langchain-63b80545b3a7?source=collection_archive---------2-----------------------#2023-09-21)
- en: 'How to consistently parse outputs from LLMs using Open AI API and LangChain
    function calling: evaluating the methods’ advantages and disadvantages'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何使用Open AI API和LangChain函数调用一致地解析LLM的输出：评估这些方法的优缺点
- en: '[](https://gabrielcassimiro17.medium.com/?source=post_page-----63b80545b3a7--------------------------------)[![Gabriel
    Cassimiro](../Images/2cf8a09a706236059c46c7f0f20d4365.png)](https://gabrielcassimiro17.medium.com/?source=post_page-----63b80545b3a7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----63b80545b3a7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----63b80545b3a7--------------------------------)
    [Gabriel Cassimiro](https://gabrielcassimiro17.medium.com/?source=post_page-----63b80545b3a7--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://gabrielcassimiro17.medium.com/?source=post_page-----63b80545b3a7--------------------------------)[![Gabriel
    Cassimiro](../Images/2cf8a09a706236059c46c7f0f20d4365.png)](https://gabrielcassimiro17.medium.com/?source=post_page-----63b80545b3a7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----63b80545b3a7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----63b80545b3a7--------------------------------)
    [Gabriel Cassimiro](https://gabrielcassimiro17.medium.com/?source=post_page-----63b80545b3a7--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3692fb93d7e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fllm-output-parsing-function-calling-vs-langchain-63b80545b3a7&user=Gabriel+Cassimiro&userId=3692fb93d7e5&source=post_page-3692fb93d7e5----63b80545b3a7---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----63b80545b3a7--------------------------------)
    ·11 min read·Sep 21, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F63b80545b3a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fllm-output-parsing-function-calling-vs-langchain-63b80545b3a7&user=Gabriel+Cassimiro&userId=3692fb93d7e5&source=-----63b80545b3a7---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3692fb93d7e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fllm-output-parsing-function-calling-vs-langchain-63b80545b3a7&user=Gabriel+Cassimiro&userId=3692fb93d7e5&source=post_page-3692fb93d7e5----63b80545b3a7---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----63b80545b3a7--------------------------------)
    ·11分钟阅读·2023年9月21日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F63b80545b3a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fllm-output-parsing-function-calling-vs-langchain-63b80545b3a7&user=Gabriel+Cassimiro&userId=3692fb93d7e5&source=-----63b80545b3a7---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F63b80545b3a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fllm-output-parsing-function-calling-vs-langchain-63b80545b3a7&source=-----63b80545b3a7---------------------bookmark_footer-----------)![](../Images/affa0a341f50bd362761ff3898004072.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F63b80545b3a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fllm-output-parsing-function-calling-vs-langchain-63b80545b3a7&source=-----63b80545b3a7---------------------bookmark_footer-----------)![](../Images/affa0a341f50bd362761ff3898004072.png)'
- en: Image by [Victor Barrios](https://unsplash.com/pt-br/@thevictorbarrios?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    at [Unsplash](https://unsplash.com/pt-br/fotografias/yjygDnvRuaI?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Victor Barrios](https://unsplash.com/pt-br/@thevictorbarrios?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，来源于 [Unsplash](https://unsplash.com/pt-br/fotografias/yjygDnvRuaI?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: Creating tools with LLMs requires multiple components, such as vector databases,
    chains, agents, document splitters, and many other new tools.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LLMs创建工具需要多个组件，例如向量数据库、链、代理、文档分割器和许多其他新工具。
- en: However, one of the most crucial components is the LLM output parsing. If you
    cannot receive structured responses from your LLM, you will have a hard time working
    with the generations. This becomes even more evident when we want a single call
    to the LLM to output more than one piece of information.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，最关键的组件之一是 LLM 输出解析。如果你不能从 LLM 接收到结构化的响应，你将很难处理生成的内容。当我们希望一次调用 LLM 输出多个信息时，这一点变得尤为明显。
- en: 'Let’s illustrate the problem with a hypothetical scenario:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个假设的场景来说明这个问题：
- en: We want the LLM to output from a single call the **ingredients** and the **steps**
    to make a certain recipe. But we want to have both of these items separately to
    use in two different parts of our system.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望 LLM 从一次调用中输出 **ingredients** 和 **steps** 来制作特定的食谱。但我们希望将这两项内容分别用于系统的两个不同部分。
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This returns the following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回如下内容：
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This is a huge string and parsing it would be hard because the LLM can return
    slightly different structures breaking whatever code you write. You could argue
    that asking in the prompt to always return “Ingredients:” and “Steps:” could resolve
    and you are not wrong. This could work, however you would still need to process
    the string manually and be open to eventual variations and hallucinations.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个庞大的字符串，解析起来会很困难，因为 LLM 可能会返回稍有不同的结构，从而破坏你编写的代码。你可以争辩说，在提示中始终要求返回“Ingredients:”
    和 “Steps:” 可以解决问题，你说得没错。这可能有效，但你仍然需要手动处理字符串，并且要应对可能的变化和虚构。
- en: Solution
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'There are a couple of ways we could solve this problem. One was mentioned above,
    but there are a couple of tested ways that might be better. In this article, I
    will show two options:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用几种方法解决这个问题。上述提到了一种，但还有几种经过测试的方法可能更好。在本文中，我将展示两个选项：
- en: Open AI Function calling;
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Open AI 函数调用；
- en: LangChain Output Parser.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LangChain 输出解析器。
- en: Open AI Function calling
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Open AI 函数调用
- en: This is a method that I have been trying and is giving the most consistent results.
    We use the Function Calling capability of the Open AI API so that the model returns
    the response as a structured JSON.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我尝试过的一种方法，并且给出了最一致的结果。我们利用 Open AI API 的函数调用能力，以便模型将响应作为结构化的 JSON 返回。
- en: This functionality has the objective of providing the LLM the ability to call
    an external function by providing the inputs as a JSON. The models were fine-tuned
    to understand when they need to use a given function. An example of this is a
    function for current weather. If you ask GPT for the current weather, it won’t
    be able to tell you, but you can provide a function that does this and pass it
    to GPT so it will know that it can be accessed given some input.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这个功能的目标是提供给 LLM 通过 JSON 输入调用外部函数的能力。模型经过微调，以理解何时需要使用特定函数。一个例子是当前天气的函数。如果你问 GPT
    当前的天气，它不能告诉你，但你可以提供一个做这件事的函数并传递给 GPT，这样它就会知道可以根据输入访问它。
- en: If you want to dive deeper into this functionality here is the [announcement
    from Open AI](https://openai.com/blog/function-calling-and-other-api-updates)
    and here is a [great article](/how-to-use-openais-function-calling-e35bdac88ae7).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想深入了解这个功能，可以查看 [Open AI 的公告](https://openai.com/blog/function-calling-and-other-api-updates)，以及一篇
    [很棒的文章](/how-to-use-openais-function-calling-e35bdac88ae7)。
- en: 'So let’s look in the code at what this would look like given our problem at
    hand. Let’s break down the code:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 那么让我们在代码中看看这个在我们面临的问题下会是什么样子。让我们分解一下代码：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The first thing we need to do is declare the functions that will be available
    to the LLM. We have to give it a name and a description so that the model understands
    when it should use the function. Here we tell it the this function is used to
    return the recipe asked.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事是声明将对 LLM 可用的函数。我们必须给它一个名称和描述，以便模型理解何时应使用该函数。在这里，我们告诉它这个函数是用来返回请求的食谱的。
- en: Then we go into the parameters. First, we say that it is of type object and
    the properties it can use are ingredients and steps. Both of these also have a
    description and a type to guide the LLM on the output. Finally, we specify which
    of those properties are required to call the function (this means we could have
    optional fields that the LLM would judge if it wanted to use them).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们进入参数设置。首先，我们说明它的类型为对象，其可以使用的属性有“ingredients”和“steps”。这两个属性也都有一个描述和一个类型，以指导
    LLM 输出。最后，我们指定哪些属性是调用函数时必需的（这意味着我们可以有可选字段，LLM 可以决定是否使用它们）。
- en: 'Let’s use that now in a call to the LLM:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们在一次调用 LLM 中使用这个：
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Here we start by creating our query to the API by formatting a base prompt with
    what could be a variable input (recipe). Then, we declare our API call using “gpt-3.5-turbo-0613”,
    we pass our query in the messages argument, and now we pass our functions.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们开始通过格式化一个可能是变量输入（食谱）的基础提示来创建对API的查询。然后，我们使用“gpt-3.5-turbo-0613”声明我们的API调用，我们将查询传递到messages参数中，然后传递我们的函数。
- en: 'There are two arguments regarding our functions. The first one we pass the
    list of objects in the format shown above with the functions the model has access
    to. And the second argument “function_call” we specify how the model should use
    those functions. There are three options:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 关于我们的函数有两个参数。第一个是我们传递的对象列表，格式如上所示，包含模型可以访问的函数。第二个参数“function_call”我们指定模型应该如何使用这些函数。有三种选项：
- en: “Auto” -> the model decides between user response or function calling;
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “Auto” -> 模型在用户响应或函数调用之间进行决定；
- en: “none” -> the model does not call the function and returns the user response;
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “none” -> 模型不调用函数，而是返回用户响应；
- en: '{“name”: “my_function_name”} -> specifying a function name forces the model
    to use it.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '{“name”: “my_function_name”} -> 指定一个函数名称强制模型使用它。'
- en: You can find the official documentation [here](https://platform.openai.com/docs/api-reference/chat/create).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[这里](https://platform.openai.com/docs/api-reference/chat/create)找到官方文档。
- en: 'In our case and for using as output parsing we used the latter:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，作为输出解析我们使用了后者：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'So now we can look at our responses. The response we get (after this filter
    [“choices”][0][“message”]) is:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以查看我们的响应。我们得到的响应（在此过滤器[“choices”][0][“message”]之后）是：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If we parse it further into the “function_call” we can see our intended structured
    response:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们进一步解析到“function_call”，我们可以看到我们预期的结构化响应：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Conclusion for function calling
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 函数调用的结论
- en: It is possible to use the feature of function calling straight from the Open
    AI API. This allows us to have a dictionary format response with the same keys
    every time the LLM is called.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 可以直接从Open AI API使用函数调用的功能。这允许我们每次调用LLM时都得到具有相同键的字典格式响应。
- en: To use it is pretty straightforward, you just have to declare the functions
    object specifying the name, description, and properties focused on your task but
    specifying (in the description) that this should be the response of the model.
    Also, when calling the API we can force the model to use our function, making
    it even more consistent.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 使用起来相当直接，你只需声明函数对象，指定名称、描述和关注于你的任务的属性，同时在描述中指定这应该是模型的响应。此外，当调用API时，我们可以强制模型使用我们的函数，从而使其更加一致。
- en: The main downside of this method is that it is not supported by all LLM models
    and APIs. So if we wanted to use Google PaLM API we would have to use another
    method.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的主要缺点是并不是所有的LLM模型和API都支持。所以，如果我们想使用Google PaLM API，我们将不得不使用另一种方法。
- en: LangChain Output Parsers
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LangChain 输出解析器
- en: One alternative we have that is model-agnostic is using LangChain.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以选择一个与模型无关的替代方案，就是使用LangChain。
- en: First, what is LangChain?
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，什么是LangChain？
- en: LangChain is a framework for developing applications powered by language models.
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: LangChain是一个用于开发由语言模型驱动的应用程序的框架。
- en: That is the official definition of LangChain. This framework was created recently
    and is already used as the industry standard for building tools powered by LLMs.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这是LangChain的官方定义。这个框架最近创建，并已经作为构建由LLM驱动的工具的行业标准。
- en: It has a functionality that is great for our use case called “Output Parsers”.
    In this module, there are multiple objects that can be created to return and parse
    different types of formats from LLM calls. It achieves this, by first declaring
    what the format is and passing it in the prompt to the LLM. Then it uses the object
    created previously to parse the response.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 它有一个非常适合我们用例的功能，称为“输出解析器”。在这个模块中，可以创建多个对象来返回和解析来自LLM调用的不同类型的格式。实现的方式是，首先声明格式，并将其传递到LLM的提示中。然后，使用之前创建的对象来解析响应。
- en: 'Let’s break down the code:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分解代码：
- en: '[PRE7]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The first thing we do here is create our Response Schema that will be the input
    for our parser. We create one for the ingredients and one for the steps, each
    containing a name that will be the key of the dictionary and a description that
    will guide the LLM on the response.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先要做的是创建我们的响应模式，这将作为解析器的输入。我们为成分和步骤各创建一个，每个都包含一个名称，这将是字典的键，以及一个描述，这将指导LLM如何回应。
- en: Then we create our StructuredOutputParser from those response schemas. There
    are multiple ways to do this, with different styles of parsers. Look [here](https://python.langchain.com/docs/modules/model_io/output_parsers/)
    to learn more about them.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们从这些响应模式中创建我们的结构化输出解析器。有多种方法可以做到这一点，使用不同风格的解析器。了解更多信息，请查看[这里](https://python.langchain.com/docs/modules/model_io/output_parsers/)。
- en: 'Lastly, we get our format instructions and define our prompt that will have
    the recipe name and the format instructions as inputs. The format instructions
    are these:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们获取我们的格式说明，并定义我们的提示，将食谱名称和格式说明作为输入。格式说明如下：
- en: '[PRE8]json" and "[PRE9]json'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE8]json" 和 "[PRE9]json'
- en: '{'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '{'
- en: '"ingredients": string  // The ingredients from recipe, as a unique string.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '"ingredients": string  // 食谱中的成分，作为一个独特的字符串。'
- en: '"steps": string  // The steps to prepare the recipe, as a unique string.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '"steps": string  // 准备食谱的步骤，作为一个独特的字符串。'
- en: '}'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: '"""'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: '[PRE10]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: llm_openai = OpenAI()
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: llm_openai = OpenAI()
- en: llm_palm = GooglePalm()
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: llm_palm = GooglePalm()
- en: recipe = 'Fish and chips'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: recipe = '炸鱼薯条'
- en: formated_prompt = prompt.format(**{"recipe":recipe, "format_instructions":output_parser.get_format_instructions()})
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: formated_prompt = prompt.format(**{"recipe":recipe, "format_instructions":output_parser.get_format_instructions()})
- en: response_palm = llm_palm(formated_prompt)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: response_palm = llm_palm(formated_prompt)
- en: response_openai = llm_openai(formated_prompt)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: response_openai = llm_openai(formated_prompt)
- en: print("PaLM:")
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: print("PaLM:")
- en: print(response_palm)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: print(response_palm)
- en: print(output_parser.parse(response_palm))
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: print(output_parser.parse(response_palm))
- en: print("Open AI:")
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: print("Open AI:")
- en: print(response_openai)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: print(response_openai)
- en: print(output_parser.parse(response_openai))
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: print(output_parser.parse(response_openai))
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'PaLM:'
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'PaLM:'
- en: '{'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '{'
- en: '''ingredients'': ''''''- 1 cup all-purpose flour\n'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '''ingredients'': ''''''- 1 杯通用面粉\n'
- en: '- 1 teaspoon baking powder\n'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '- 1 茶匙发酵粉\n'
- en: '- 1/2 teaspoon salt\n'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '- 1/2 茶匙盐\n'
- en: '- 1/2 cup cold water\n'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '- 1/2 杯冷水\n'
- en: '- 1 egg\n'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '- 1 个鸡蛋\n'
- en: '- 1 pound white fish fillets, such as cod or haddock\n'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '- 1 磅白鱼片，如鳕鱼或鳕鱼\n'
- en: '- Vegetable oil for frying\n- 1 cup tartar sauce\n'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '- 用于炸制的植物油\n- 1 杯塔塔酱\n'
- en: '- 1/2 cup malt vinegar\n- Lemon wedges'''''','
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '- 1/2 杯麦芽醋\n- 柠檬角'''''','
- en: '''steps'': ''''''1\. In a large bowl, whisk together the flour, baking powder,
    and salt.\n'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '''steps'': ''''''1\. 在一个大碗中，搅拌面粉、发酵粉和盐。\n'
- en: 2\. In a separate bowl, whisk together the egg and water.\n
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 在另一个碗中，搅拌鸡蛋和水。\n
- en: 3\. Dip the fish fillets into the egg mixture, then coat them in the flour mixture.\n
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 将鱼片浸入鸡蛋混合物中，然后在面粉混合物中裹上。\n
- en: 4\. Heat the oil in a deep fryer or large skillet to 375 degrees F (190 degrees
    C).\n
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 在深炸锅或大煎锅中加热油至 375 华氏度（190 摄氏度）。\n
- en: 5\. Fry the fish fillets for 3-5 minutes per side, or until golden brown and
    cooked through.\n
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. 将鱼片两面煎 3-5 分钟，直到金黄酥脆并完全熟透。\n
- en: 6\. Drain the fish fillets on paper towels.\n
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 6\. 在纸巾上沥干鱼片。\n
- en: 7\. Serve the fish fillets immediately with tartar sauce, malt vinegar, and
    lemon wedges.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 7\. 立即将鱼片与塔塔酱、麦芽醋和柠檬角一起上桌。
- en: ''''''''
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ''''''''
- en: '}'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: Open AI
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Open AI
- en: '{'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '{'
- en: '''ingredients'': ''1 ½ pounds cod fillet, cut into 4 pieces,'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '''ingredients'': ''1 ½ 磅鳕鱼片，切成 4 块，'
- en: 2 cups all-purpose flour,
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 2 杯通用面粉，
- en: 2 teaspoons baking powder,
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 2 茶匙发酵粉，
- en: 1 teaspoon salt,
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 1 茶匙盐，
- en: 1 teaspoon freshly ground black pepper,
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 1 茶匙新鲜磨碎的黑胡椒，
- en: ½ teaspoon garlic powder,
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ½ 茶匙大蒜粉，
- en: 1 cup beer (or water),
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 1 杯啤酒（或水），
- en: vegetable oil, for frying,
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 用于炸制的植物油，
- en: Tartar sauce, for serving',
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 塔塔酱，用于搭配',
- en: '''steps'': ''1\. Preheat the oven to 400°F (200°C) and line a baking sheet
    with parchment paper.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '''steps'': ''1\. 预热烤箱至 400°F (200°C)，并在烤盘上铺上烘焙纸。'
- en: 2\. In a medium bowl, mix together the flour, baking powder, salt, pepper and
    garlic powder.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 在一个中等大小的碗中，将面粉、发酵粉、盐、胡椒粉和大蒜粉混合在一起。
- en: 3\. Pour in the beer and whisk until a thick batter forms.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 倒入啤酒，搅拌至形成浓稠的面糊。
- en: 4\. Dip the cod in the batter, coating it on all sides.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 将鳕鱼浸入面糊中，确保四面都裹上。
- en: 5\. Heat about 2 inches (5 cm) of oil in a large pot or skillet over medium-high
    heat.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. 在一个大锅或煎锅中加热约 2 英寸（5 厘米）的油，火力中高。
- en: 6\. Fry the cod for 3 to 4 minutes per side, or until golden brown.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 6\. 将鳕鱼两面煎 3 到 4 分钟，直到金黄酥脆。
- en: 7\. Transfer the cod to the prepared baking sheet and bake for 5 to 7 minutes.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 7\. 将鳕鱼转移到准备好的烤盘上，烘烤 5 到 7 分钟。
- en: 8\. Serve warm with tartar sauce.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 8\. 热食，配以塔塔酱。'
- en: '}'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: '```'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '```'
- en: 'Conclusion: LangChain Output parsing'
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论：LangChain 输出解析
- en: This method is really good as well and has as its main characteristic flexibility.
    We create a couple of structures such as Response Schema, Output Parser, and Prompt
    Templates that can be pieced together easily and used with different models. Another
    good advantage of this is the support for multiple output formats.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法也非常好，其主要特点是灵活性。我们创建了一些结构，如响应模式、输出解析器和提示模板，这些结构可以轻松组合在一起，并与不同的模型一起使用。另一个好处是支持多种输出格式。
- en: The main disadvantage comes from passing the format instructions via the prompt.
    This allows for random errors and hallucinations. One real example was from this
    specific case where I had to specify “ as a unique string” in the description
    of the response schema. If I did not specify this, the model was returning a list
    of strings with the steps and instructions and this caused an error of parsing
    in the Output Parser.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的缺点来自通过提示传递格式指令。这可能会导致随机错误和幻觉。一个真实的例子是，在这个具体的案例中，我需要在响应模式的描述中指定“作为唯一字符串”。如果我没有这样指定，模型会返回一个包含步骤和指令的字符串列表，这会导致输出解析器的解析错误。
- en: Conclusion
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'There are multiple ways of using an output parser for your LLM-powered application.
    However, your choice may change depending on the problem at hand. For myself,
    I like to follow this idea:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 使用输出解析器来处理 LLM 驱动的应用有多种方法。然而，根据问题的不同，你的选择可能会有所变化。对我而言，我喜欢遵循这个思路：
- en: I always use an output parser, even if I have only one output from the LLM.
    This allows me to control and specify my outputs. If I am working with Open AI,
    Function Calling is my choice because it has the most control and will avoid random
    errors in a production application. However, if I am using a different LLM or
    need a different output format, my choice is LangChain, but with a lot of testing
    on the outputs, in order to craft the prompt with the least mistakes.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我总是使用输出解析器，即使我只有一个来自 LLM 的输出。这使我能够控制和指定我的输出。如果我使用的是 Open AI，Function Calling
    是我的选择，因为它具有最好的控制能力，并能避免生产应用中的随机错误。然而，如果我使用的是不同的 LLM 或需要不同的输出格式，我的选择是 LangChain，但需要对输出进行大量测试，以便构建最少错误的提示。
- en: Thanks for reading.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读。
- en: The full code can be found [here](https://github.com/gabrielcassimiro17/llm-output-parsing).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的代码可以在 [这里](https://github.com/gabrielcassimiro17/llm-output-parsing) 找到。
- en: 'If you like the content and want to support me, you can buy me a coffee:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这些内容并想要支持我，可以请我喝杯咖啡：
- en: '[](https://www.buymeacoffee.com/cassimiro?source=post_page-----63b80545b3a7--------------------------------)
    [## Gabriel Cassimiro is a Data Scientist sharing free content to the community'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.buymeacoffee.com/cassimiro?source=post_page-----63b80545b3a7--------------------------------)
    [## 加布里埃尔·卡西米罗是一个数据科学家，向社区分享免费内容'
- en: I love supporting creators!
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我喜欢支持创作者！
- en: www.buymeacoffee.com](https://www.buymeacoffee.com/cassimiro?source=post_page-----63b80545b3a7--------------------------------)
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: www.buymeacoffee.com](https://www.buymeacoffee.com/cassimiro?source=post_page-----63b80545b3a7--------------------------------)
- en: 'Here are a few other articles you might be interested in:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些你可能感兴趣的其他文章：
- en: '[](/async-calls-for-chains-with-langchain-3818c16062ed?source=post_page-----63b80545b3a7--------------------------------)
    [## Async calls for Chains with Langchain'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/async-calls-for-chains-with-langchain-3818c16062ed?source=post_page-----63b80545b3a7--------------------------------)
    [## 使用 Langchain 进行链条的异步调用'
- en: How to make Langchain chains work with Async calls to LLMs, speeding up the
    time it takes to run a sequential long…
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何使 Langchain 链条与异步调用 LLM 一起工作，从而加快运行顺序长时间任务的速度…
- en: towardsdatascience.com](/async-calls-for-chains-with-langchain-3818c16062ed?source=post_page-----63b80545b3a7--------------------------------)
    [](/solving-unity-environment-with-deep-reinforcement-learning-836dc181ee3b?source=post_page-----63b80545b3a7--------------------------------)
    [## Solving Unity Environment with Deep Reinforcement Learning
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/async-calls-for-chains-with-langchain-3818c16062ed?source=post_page-----63b80545b3a7--------------------------------)
    [](/solving-unity-environment-with-deep-reinforcement-learning-836dc181ee3b?source=post_page-----63b80545b3a7--------------------------------)
    [## 使用深度强化学习解决 Unity 环境问题
- en: End to End Project with code of a PyTorch implementation of Deep Reinforcement
    Learning Agent.
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 PyTorch 实现深度强化学习代理的端到端项目代码。
- en: towardsdatascience.com](/solving-unity-environment-with-deep-reinforcement-learning-836dc181ee3b?source=post_page-----63b80545b3a7--------------------------------)
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/solving-unity-environment-with-deep-reinforcement-learning-836dc181ee3b?source=post_page-----63b80545b3a7--------------------------------)
