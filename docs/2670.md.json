["```py\nfrom langchain.graphs import Neo4jGraph\n\nNEO4J_URI=\"neo4j+s://1234.databases.neo4j.io\"\nNEO4J_USERNAME=\"neo4j\"\nNEO4J_PASSWORD=\"-\"\n\ngraph = Neo4jGraph(\n    url=NEO4J_URI,\n    username=NEO4J_USERNAME,\n    password=NEO4J_PASSWORD\n)\n```", "```py\nCALL db.index.vector.createNodeIndex(\n  'wikipedia', // index name\n  'Chunk',     // node label\n  'embedding', // node property\n   1536,       // vector size\n   'cosine'    // similarity metric\n)\n```", "```py\nWITH [1, [1,2,3], [\"2\",\"5\"], [x in range(0, 1535) | toFloat(x)]] AS exampleValues\nUNWIND range(0, size(exampleValues) - 1) as index\nCREATE (:Chunk {embedding: exampleValues[index], index: index})\n```", "```py\nCALL db.index.vector.queryNodes(\n  'wikipedia', // index name\n   3, // topK neighbors to return\n   [x in range(0,1535) | toFloat(x) / 2] // input vector\n)\nYIELD node, score\nRETURN node.index AS index, score\n```", "```py\nimport wikipedia\nbg3 = wikipedia.page(pageid=60979422)\n```", "```py\nimport os\nfrom langchain.embeddings import OpenAIEmbeddings\n\nos.environ[\"OPENAI_API_KEY\"] = \"API_KEY\"\n\nembeddings = OpenAIEmbeddings()\n\nchunks = [{'text':el, 'embedding': embeddings.embed_query(el)} for\n                  el in bg3.content.split(\"\\n\\n\") if len(el) > 50]\n```", "```py\ngraph.query(\"\"\"\nUNWIND $data AS row\nCREATE (c:Chunk {text: row.text})\nWITH c, row\nCALL db.create.setVectorProperty(c, 'embedding', row.embedding)\nYIELD node\nRETURN distinct 'done'\n\"\"\", {'data': chunks})\n```", "```py\nvector_search = \"\"\"\nWITH $embedding AS e\nCALL db.index.vector.queryNodes('wikipedia',$k, e) yield node, score\nRETURN node.text AS result\n\"\"\"\n```", "```py\nclass Neo4jVectorChain(Chain):\n    \"\"\"Chain for question-answering against a Neo4j vector index.\"\"\"\n\n    graph: Neo4jGraph = Field(exclude=True)\n    input_key: str = \"query\"  #: :meta private:\n    output_key: str = \"result\"  #: :meta private:\n    embeddings: OpenAIEmbeddings = OpenAIEmbeddings()\n    qa_chain: LLMChain = LLMChain(llm=ChatOpenAI(temperature=0), prompt=CHAT_PROMPT)\n\n    def _call(self, inputs: Dict[str, str], run_manager, k=3) -> Dict[str, Any]:\n        \"\"\"Embed a question and do vector search.\"\"\"\n        question = inputs[self.input_key]\n\n        # Embed the question\n        embedding = self.embeddings.embed_query(question)\n\n        # Retrieve relevant information from the vector index\n        context = self.graph.query(\n            vector_search, {'embedding': embedding, 'k': 3})\n        context = [el['result'] for el in context]\n\n        # Generate the answer\n        result = self.qa_chain(\n            {\"question\": question, \"context\": context},\n        )\n        final_result = result[self.qa_chain.output_key]\n        return {self.output_key: final_result}\n```", "```py\nvector_qa = Neo4jVectorChain(graph=graph, embeddings=embeddings, verbose=True)\nvector_qa.run(\"What is the gameplay of Baldur's Gate 3 like?\")\n```"]