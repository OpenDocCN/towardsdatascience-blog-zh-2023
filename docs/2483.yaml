- en: User Feedback — The Missing Piece of the ML Monitoring Stack
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/user-feedback-the-missing-piece-of-your-ml-monitoring-stack-46b2bbf0b5e4?source=collection_archive---------7-----------------------#2023-08-02](https://towardsdatascience.com/user-feedback-the-missing-piece-of-your-ml-monitoring-stack-46b2bbf0b5e4?source=collection_archive---------7-----------------------#2023-08-02)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A complete guide to building user-centric AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@joel.hodgson1996?source=post_page-----46b2bbf0b5e4--------------------------------)[![Joel
    Hodgson](../Images/86c6a256d618c159407139e389cf30e4.png)](https://medium.com/@joel.hodgson1996?source=post_page-----46b2bbf0b5e4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----46b2bbf0b5e4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----46b2bbf0b5e4--------------------------------)
    [Joel Hodgson](https://medium.com/@joel.hodgson1996?source=post_page-----46b2bbf0b5e4--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc1af09f6c90f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fuser-feedback-the-missing-piece-of-your-ml-monitoring-stack-46b2bbf0b5e4&user=Joel+Hodgson&userId=c1af09f6c90f&source=post_page-c1af09f6c90f----46b2bbf0b5e4---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----46b2bbf0b5e4--------------------------------)
    ·8 min read·Aug 2, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F46b2bbf0b5e4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fuser-feedback-the-missing-piece-of-your-ml-monitoring-stack-46b2bbf0b5e4&user=Joel+Hodgson&userId=c1af09f6c90f&source=-----46b2bbf0b5e4---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F46b2bbf0b5e4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fuser-feedback-the-missing-piece-of-your-ml-monitoring-stack-46b2bbf0b5e4&source=-----46b2bbf0b5e4---------------------bookmark_footer-----------)![](../Images/7ab7564a2ff994d8022b5650e5bd9fbc.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image from [Unsplash](https://unsplash.com/photos/x21KgBfOd_4)
  prefs: []
  type: TYPE_NORMAL
- en: The misalignment of AI models and users
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Have you ever spent months, and who knows how much $$$, implementing an AI model,
    to find no one uses it? Even if you do overcome the challenges of adoption, how
    do you know if the model outputs are truly adding value to the user’s decisions,
    queries, professional or daily activities?
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning performance metrics and real-time monitoring tools are an excellent
    way to calculate the performance of a model, and identify when things may be going
    wrong ***from a technical point of view***. But without understanding user engagement
    or satisfaction, it is difficult to know if the model is being used for its intended
    purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, listening to the users of AI models may uncover incorrectly predicted
    edge cases; explainability algorithms that don’t explain things quite as clearly
    as we hoped; or user experience flaws that impact how users engage with a model.
  prefs: []
  type: TYPE_NORMAL
- en: The remainder of this article will cover the importance of understanding user
    feedback on AI models, the different types of user feedback, and how user feedback
    can be collected to improve model performance, increase user adoption, and ultimately
    align AI models to users.
  prefs: []
  type: TYPE_NORMAL
- en: Contents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The misalignment of AI models and users
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is user feedback for AI?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why is user feedback for AI important?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the different types of feedback?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A guide to collecting user feedback
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wrapping up
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is user feedback for AI?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we refer to user feedback, the user in question depends on the use case
    you are implementing. For example, this might be an internal business user or
    stakeholder of an internal ML-based demand forecasting application; it may be
    an external domain expert, such as a medical oncologist, leveraging a MedTech
    product assisting with detecting tumours in medical scans; Or, it may be the end
    user of an external facing job application assistant, leveraging generative AI
    to help write and refine resumes.
  prefs: []
  type: TYPE_NORMAL
- en: The concepts, methods and benefits outlined in this article apply to all of
    these different use cases. However, some benefits may apply more or less depending
    on the use case itself, and should be taken into consideration on a case by case
    basis.
  prefs: []
  type: TYPE_NORMAL
- en: '***For the purpose of this article, we will use the resume assistant, described
    above, to illustrate the benefits of user feedback for this application.***'
  prefs: []
  type: TYPE_NORMAL
- en: A second important point, when referring to user feedback, is that we don’t
    just mean relabelling incorrect predictions, or a feedback loop for automated
    model retraining. User feedback involves any information given by users, providing
    an understanding of the usefulness and adoption of the AI application. In our
    resume assistant example, user feedback could include user satisfaction scores,
    providing insights into how happy users are with the generated resumes, or written
    comments to highlight specific issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'This type of feedback should not always be pushed directly into an automated
    retraining pipeline for several reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: User feedback is typically unstructured, and highlights issues outside of incorrect
    predictions, so can’t always be used to directly retrain a model. For example,
    a user highlighting that the resume assistant is using overly formal language
    may require more examples of less formal text in the training data, opposed to
    directly retraining with this feedback.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Focusing solely on correct/incorrect predictions overlooks valuable information
    provided by users. Understanding user feedback allows AI teams to improve the
    application based on user experiences and usage patterns.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Training strategies such as reinforcement learning with human feedback (RLHF)
    work very well within a controlled environment. However, real-world user feedback
    can be noisy and potentially harmful. For example, blindly incorporating user
    feedback into the training data can lead to [data poisoning](https://datascientest.com/en/data-poisoning-a-threat-to-machine-learning-models),
    where malicious users intentionally mislead the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Therefore, AI teams should review user feedback to extract the different insights
    and determine the next best course of action to improve the overall AI application.
  prefs: []
  type: TYPE_NORMAL
- en: Why is user feedback for AI important?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Enabling Model Evaluation**'
  prefs: []
  type: TYPE_NORMAL
- en: Many AI models lack a ground truth. This makes evaluation on a test dataset
    difficult, as it is usually based on a proxy metric that often only tells part
    of the story. This is especially true for generative models, where understanding
    whether users are satisfied with model predictions is usually the most important
    metric.
  prefs: []
  type: TYPE_NORMAL
- en: '**Increasing Model Performance:**'
  prefs: []
  type: TYPE_NORMAL
- en: User feedback can be used to continuously improve the performance of AI models.
    Users can hold good domain knowledge required to build a robust model. Additionally,
    monitoring user engagement can help identify if a model has poor performance due
    to the train/test set being a poor representation of the real-world.
  prefs: []
  type: TYPE_NORMAL
- en: '**Increasing User Alignment:**'
  prefs: []
  type: TYPE_NORMAL
- en: User feedback provides insight into what aspects of the model work well and
    what causes friction. This enables the AI team to enhance user experience, making
    the model more intuitive and user-friendly. Additionally, AI teams can ensure
    the models are aligned to all users, and not just smaller sub groups. For example,
    ensuring the resume assistant maintains quality across all languages, not just
    English.
  prefs: []
  type: TYPE_NORMAL
- en: As users feel their voices are heard, they are more likely to trust the AI model
    and remain engaged, leading to increased user alignment and adoption.
  prefs: []
  type: TYPE_NORMAL
- en: '**Increasing AI responsibility:**'
  prefs: []
  type: TYPE_NORMAL
- en: Through user feedback, AI teams can identify and address concerns related to
    safety, bias, or other ethical considerations. This proactive approach results
    in the development of safer and more responsible AI models. By seeking and responding
    to user feedback, AI teams demonstrate their accountability and commitment to
    creating high-quality and reliable AI solutions. Feedback may also reveal the
    need for additional educational resources and documentation, which AI teams can
    provide to ensure users have a clear understanding of the model’s capabilities
    and promote best practices.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, leveraging user insights allows AI teams to refine models, optimise
    user experience, and address ethical concerns, leading to higher user satisfaction
    and trust.
  prefs: []
  type: TYPE_NORMAL
- en: Now we have clarified what user feedback is and its benefits, let’s cover the
    different types of feedback and what they are used for.
  prefs: []
  type: TYPE_NORMAL
- en: What are the different types of feedback?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are two main categories of user feedback, explicit and implicit. This
    can be explained and illustrated nicely by our new best friend, ChatGPT (in the
    image below).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a5b9397bba6d961859c9eaf208cbb18a.png)'
  prefs: []
  type: TYPE_IMG
- en: ChatGPT illustrating the difference between explicit and implicit feedback.
    Screenshot taken from ChatGPT by OpenAI, and edited by author.
  prefs: []
  type: TYPE_NORMAL
- en: Explicit user feedback refers to direct, intentional, and consciously provided
    input from users regarding their experiences, opinions or preferences. As you
    would’ve seen in the ChatGPT interface, the thumbs up/down feedback is an example
    of explicit feedback.
  prefs: []
  type: TYPE_NORMAL
- en: Explicit feedback can be broken down further into quantitative and qualitative.
    Quantitative feedback includes measurable scales, such as thumbs up/down, user
    satisfaction (also known as the 5-point Likert scale), or any custom scale that
    best fits what you are trying to understand from your users.
  prefs: []
  type: TYPE_NORMAL
- en: Qualitative feedback typically involves an open textbox to allow users to provide
    written feedback. Combining a quantitative measure with qualitative feedback,
    enables the AI team to understand the “why” behind the user’s comment, and uncover
    details such as AI bugs, domain knowledge, or user preferences.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/71d7b014b2434d88c7f289a30fb4a892.png)'
  prefs: []
  type: TYPE_IMG
- en: Submitting qualitative feedback, after selecting a negative quantitative response.
    Screenshot taken from ChatGPT by OpenAI.
  prefs: []
  type: TYPE_NORMAL
- en: Implicit user feedback refers to indirect, unintentional, and unconsciously
    provided data based on users behaviours, actions or patterns. Looking again at
    the ChatGPT UI, the ‘copy to clipboard’ button is an example of how OpenAI collects
    implicit feedback. For the resume assistant example, implicit user feedback also
    could be taken by tracking any edits the user makes to the generated output.
  prefs: []
  type: TYPE_NORMAL
- en: Consideration needs to be made when choosing the types of feedback to implement.
    Explicit feedback provides a much clearer understanding of the user’s feedback
    and thoughts. However, for external use cases, the end users may not always provide
    explicit feedback, as they may not understand how they will benefit (or feel they
    don’t have time!). In this case, implicit feedback can also give a good understanding
    of how the AI application is being used, without relying on the user to take direct
    action.
  prefs: []
  type: TYPE_NORMAL
- en: Based on the application, and the challenges you currently face, you should
    also consider what measures you want to implement. For example, if you are focused
    on increasing the model performance, then a thumbs up/down measure with a comment
    can help identify model issues. But if you are more focused on increasing adoption,
    then perhaps a user satisfaction score would be better.
  prefs: []
  type: TYPE_NORMAL
- en: A guide to collecting user feedback
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we walk through four key steps for collecting user feedback,
    and integrating the user insights back into the ML monitoring system (as shown
    below).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/841a8c873bee0a48146e481cb44dd8ba.png)'
  prefs: []
  type: TYPE_IMG
- en: System diagram outlining a high-level architecture for collecting user feedback,
    and integrating the user insights back into the ML monitoring system. Image by
    author.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1: Design & build feedback components within your AI app**'
  prefs: []
  type: TYPE_NORMAL
- en: After defining your goals on why you are collecting user feedback, you can determine
    what type of feedback best fits your requirements. User feedback is typically
    implemented after a model output has been generated. However, you may wish to
    collect feedback throughout your application, to gain feedback on certain features
    of the application.
  prefs: []
  type: TYPE_NORMAL
- en: AI model metadata should be captured along with all feedback submitted through
    the component. This includes things such as the model version, prompts or requests,
    the model outputs, and user demographics (such as user ID and location).
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 2: Develop analytics capabilities to understand user feedback**'
  prefs: []
  type: TYPE_NORMAL
- en: For quantitative feedback this might include plots such as user satisfaction
    (CSAT/NPS) or the average positive/negative response over time, with the ability
    to compare these metrics for different model versions, users or other metadata.
  prefs: []
  type: TYPE_NORMAL
- en: For qualitative feedback, use ML to analyse the sentiment in user comments and
    to classify feedback into various categories. This allows monitoring the different
    sentiment / satisfaction metrics over the different categories of comments.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 3: Identify AI issues**'
  prefs: []
  type: TYPE_NORMAL
- en: Using the analytics capabilities, recurring topics and themes in the feedback
    can be identified to categorise areas for improvements. AI issues can then be
    raised and prioritised to be solved by the AI team.
  prefs: []
  type: TYPE_NORMAL
- en: The role of the AI team at this stage is to identify model issues as well as
    user issues, and determine the best course of action to resolve them.
  prefs: []
  type: TYPE_NORMAL
- en: For a reminder of the types of insights the AI team may find within the user
    feedback, have a look back at the “What is user feedback for AI?” section.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 4 — Integrate user feedback back into your ML monitoring system**'
  prefs: []
  type: TYPE_NORMAL
- en: Integrating user feedback into your current ML monitoring system will allow
    you to set up alerting (similar to performance monitoring, or drift detection).
    For example if the global user satisfaction score drops below a certain threshold,
    an alert can be triggered to notify the AI team to take action.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, summaries and daily reporting can be sent to the AI team or stakeholders,
    providing an overview of the user feedback.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To summarise, user feedback enables AI teams to identify bugs, fine tune models
    and align models to users.
  prefs: []
  type: TYPE_NORMAL
- en: The above can also be achieved with ML monitoring systems. However, by assessing
    the model from a different perspective, i.e. from the user’s point of view, we
    can identify additional information that would have been missed by the traditional
    ML monitoring systems.
  prefs: []
  type: TYPE_NORMAL
- en: I hope this article has sparked your interest, and provided you with initial
    ideas on how you can start listening to your users and enhancing your AI applications.
  prefs: []
  type: TYPE_NORMAL
- en: '*If you would like to learn more about user feedback for AI, or share and discuss
    your ideas around this topic, please feel free to get in touch via* [*Linkedin*](https://www.linkedin.com/in/joel-hodgson-6459ab151/)
    *or* [*email*](mailto:joel.hodgson@trubrics.com)*.*'
  prefs: []
  type: TYPE_NORMAL
