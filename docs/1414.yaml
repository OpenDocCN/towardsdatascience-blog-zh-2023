- en: Can ChatGPT Compete with Domain-Specific Sentiment Analysis Machine Learning
    Models?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/can-chatgpt-compete-with-domain-specific-sentiment-analysis-machine-learning-models-cdcd9937b460?source=collection_archive---------4-----------------------#2023-04-25](https://towardsdatascience.com/can-chatgpt-compete-with-domain-specific-sentiment-analysis-machine-learning-models-cdcd9937b460?source=collection_archive---------4-----------------------#2023-04-25)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A hands-on comparison using ChatGPT and Domain-Specific Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@francisco.paiva?source=post_page-----cdcd9937b460--------------------------------)[![Francisco
    Caio Lima Paiva](../Images/4cfbed5b2ec5944e593d2eec9ec7bf3d.png)](https://medium.com/@francisco.paiva?source=post_page-----cdcd9937b460--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cdcd9937b460--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cdcd9937b460--------------------------------)
    [Francisco Caio Lima Paiva](https://medium.com/@francisco.paiva?source=post_page-----cdcd9937b460--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb20176e45fd4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-chatgpt-compete-with-domain-specific-sentiment-analysis-machine-learning-models-cdcd9937b460&user=Francisco+Caio+Lima+Paiva&userId=b20176e45fd4&source=post_page-b20176e45fd4----cdcd9937b460---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cdcd9937b460--------------------------------)
    ·15 min read·Apr 25, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcdcd9937b460&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-chatgpt-compete-with-domain-specific-sentiment-analysis-machine-learning-models-cdcd9937b460&user=Francisco+Caio+Lima+Paiva&userId=b20176e45fd4&source=-----cdcd9937b460---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcdcd9937b460&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-chatgpt-compete-with-domain-specific-sentiment-analysis-machine-learning-models-cdcd9937b460&source=-----cdcd9937b460---------------------bookmark_footer-----------)![](../Images/78d74b03be2070788f3ee96a1287eb02.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [K. Mitch Hodge](https://unsplash.com/@kmitchhodge?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT is a GPT (**G**enerative **P**re-trained **T**ransformer) machine learning
    (ML) tool that has surprised the world. Its breathtaking capabilities impress
    casual users, professionals, researchers, and even its [own creators](https://twitter.com/janleike/status/1625207251630960640?t=wHDHT50I-UYEbL7kRDsgfw&s=08).
    Moreover, its capacity to be an ML model trained for general tasks and perform
    very well in domain-specific situations is impressive. I am a researcher, and
    its ability to do sentiment analysis (SA) interests me.
  prefs: []
  type: TYPE_NORMAL
- en: SA is a very widespread Natural Language Processing (NLP). It has several applications
    and thus can be used in several domains (e.g., finance, entertainment, psychology).
    However, some fields adopt specific terms and jargon (e.g., [finance](https://doi.org/10.1111/j.1540-6261.2010.01625.x)).
    Hence, [whether general domain ML models can be as capable as domain-specific](https://aclanthology.org/D16-1057/)
    models is still an [open research question in NLP](http://dx.doi.org/10.1016/j.eswa.2014.06.009).
  prefs: []
  type: TYPE_NORMAL
- en: If you ask the ChatGPT this research question — which is this article’s title
    — it will give you a humble answer (go on, try it). But, oh, my dear reader, I
    usually wouldn’t spoil this for you, but you have no idea how surprisingly modest
    this ChatGPT answer was…
  prefs: []
  type: TYPE_NORMAL
- en: Still, as an AI researcher, industry professional, and hobbyist, I am used to
    fine-tuning general domain NLP machine learning tools (e.g., GloVe) for usage
    in domain-specific tasks. This is the case because it was uncommon for most domains
    to find an out-of-the-box solution that could do well enough without some fine-tuning.
    I will show you how this could no longer be the case.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this text, I compare ChatGPT to a domain-specific ML model by discussing
    the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: SemEval 2017 Task 5 — A domain-specific challenge
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using ChatGPT API to label a dataset with code examples
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Verdict and results of the comparison with reproducibility details
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Conclusion and Results Discussion
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'BONUS: How this comparison can be done in an applied scenario'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Note 1**: *This is just a simple hands-on experiment that sheds some light
    on the subject,* ***NOT*** *an exhaustive scientific investigation.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Note 2**: *All images unless otherwise noted are by the author.*'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. SemEval 2017 Task 5 — A domain-specific challenge
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[SemEval (**Sem**antic **Eval**uation)](https://semeval.github.io/) is a renowned
    NLP workshop where research teams compete scientifically in sentiment analysis,
    text similarity, and question-answering tasks. The organizers provide textual
    data and gold-standard datasets created by annotators (domain specialists) and
    linguists to evaluate state-of-the-art solutions for each task.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In particular, SemEval’s [Task 5 of the 2017 edition](https://aclanthology.org/S17-2089/)
    asked researchers to score financial microblogs and news headlines for sentiment
    analysis on a -1 (most negative) to 1 (most positive) scale. We’ll use the gold-standard
    dataset from that year’s SemEval to test ChatGPT’s performance in a domain-specific
    task. Subtask 2 dataset (news headlines) had two sets of sentences (maximum of
    30 words each): the training (1,142 sentences) and the testing (491 sentences)
    sets.'
  prefs: []
  type: TYPE_NORMAL
- en: Considering these sets, the data distribution of sentiment scores and text sentences
    is displayed below. The plot below shows bimodal distributions in both training
    and testing sets. Moreover, the graph indicates more positive than negative sentences
    in the dataset. This will be a piece of handy information in the evaluation section.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/984d1518ff6754bef42d870bc3dfcd3d.png)'
  prefs: []
  type: TYPE_IMG
- en: SemEval 2017 Task 5 Subtask 2 (news headlines) data distribution sentiment score
    considering the training (left — 1,142 sentences) and testing (right — 491 sentences)
    sets.
  prefs: []
  type: TYPE_NORMAL
- en: For this subtask, the winning research team (i.e., which ranked best on the
    test set) named their ML architecture [Fortia-FBK](https://aclanthology.org/S17-2138/).
    Inspired by this competition’s discoveries, some colleagues and I made a research
    article ([Assessing Regression-Based Sentiment Analysis Techniques in Financial
    Texts](https://doi.org/10.5753/eniac.2019.9329)) where we implemented our version
    of Fortia-FBK and evaluated ways to improve this architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Also, we investigated the factors that made this architecture the winning one.
    Thus, our implementation ([code is here](https://bit.ly/3kzau8G)) of this winning
    architecture (i.e., Fortia-FBK) will be used for comparison with ChatGPT. The
    architecture (CNN+GloVe+Vader) employed is the one shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7dfd1ae2e006d8b16f27985fde3cf5bf.png)'
  prefs: []
  type: TYPE_IMG
- en: Domain-specific sentiment analysis ML model for financial news domain. Architecture
    developed for the research article “[Assessing Regression-Based Sentiment Analysis
    Techniques in Financial Texts](https://doi.org/10.5753/eniac.2019.9329)”. **Source:**
    Author Master’s dissertation (Lima Paiva, F.C. in “Assimilating sentiment analysis
    in reinforcement learning for intelligent trading”).
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Using ChatGPT API to label a dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using ChatGPT API has already been discussed here on Medium [for synthesizing
    data](/hands-on-sentiment-analysis-on-hotels-reviews-using-artificial-intelligence-and-open-ais-chatgpt-d1939850c79e).
    Also, you can find sentiment labeling examples in the [ChatGPT API code samples
    section](https://platform.openai.com/playground/p/default-adv-tweet-classifier?model=text-davinci-003)
    (Notice that using the API is not free). For this code example, consider SemEval’s
    2017 Task gold-standard dataset that you can [get here](https://bitbucket.org/ssix-project/semeval-2017-task-5-subtask-2/src/master/).
  prefs: []
  type: TYPE_NORMAL
- en: Then, to use the API for labeling several sentences at once, use a code as such,
    where I prepare a full prompt with sentences from a dataframe with the Gold-Standard
    dataset with the sentence to be labeled and the target company to which the sentiment
    refers.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Then, call the API for the *text-davinci-003* *engine* (GPT-3 version). Here
    I made some adjustments to the code to account for the max number of total characters
    in the prompt plus the answer, which must be at most 4097 characters.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Ultimately, doing that for a total of 1633 (training + testing sets) sentences
    in the gold-standard dataset and you get the following results with ChatGPT API
    labels.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0d9d998311830d06e8d4ac8b053962de.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of SemEval 2017 Task 5 Subtask 2 (news headlines) Gold-Standard dataset
    with sentiment labeled using the ChatGPT API.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1\. Issues with ChatGPT and its API at scale
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As with any other API, there are some typical requirements
  prefs: []
  type: TYPE_NORMAL
- en: Requests rate limit that requires throttling adjustments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Request limit of 25000 tokens (i.e., sub-word unit or a byte-pair encoding)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maximum length of 4096 tokens per request (prompt + response included)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cost of $0.0200 / 1K tokens (Note: I never spent more than U$ 2 after everything
    I did)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, these are just the typical requirements when dealing with most APIs.
    Moreover, remember that in this domain-specific problem, there is a target entity
    (i.e., company) for each sentence for the sentiment. So I had to play around until
    I designed a prompt pattern that made it possible to label the sentiment of several
    sentences at once and make it easy to process the results afterward. Furthermore,
    that are other limitations that impacted the prompt and code that I showed previously.
    Specifically, I found issues using this text API for several sentences (>1000).
  prefs: []
  type: TYPE_NORMAL
- en: '**Reproducibility:** ChatGPT’s sentiment assessments on sentiment can change
    significantly with very few changes to the prompt (e..g, adding or removing a
    comma or a dot of the sentence).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consistency:** If you do not clearly specify the pattern response, ChatGPT
    will get creative (even if you select a very low randomness parameter), making
    it hard to process results. Moreover, even when you specify the pattern, it can
    output inconsistent output formats.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mismatches:** Even though it can very precisely identify the target entity
    (e.g., company) you want to have the sentiment assessed in a sentence, it can
    mix up results when doing this at scale. For example, suppose you pass on 10 sentences
    each with a target company. Still, some of the companies appear in other sentences
    or are repeated. In that case, ChatGPT can mismatch the targets and sentence sentiments,
    change the order of the sentiment labels or provide fewer than 10 labels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bias:** Currently, the [issue of ChatGPT bias is well known](https://hbswk.hbs.edu/item/chatgpt-did-big-tech-set-up-the-world-for-ai-bias-disaster).
    And there are [ideas on how to improve this problem](https://www.technologyreview.com/2023/02/21/1068893/how-openai-is-trying-to-make-chatgpt-safer-and-less-biased/).
    However, until then, beware that you are learning to use a Biased API.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of these issues imply a learning curve to properly use the (biased) API.
    It required some fine-tuning to get what I needed. Sometimes I had to do many
    trials until I reached the desired outcome with minimal consistency.
  prefs: []
  type: TYPE_NORMAL
- en: You should send as many sentences as possible at once in an ideal situation
    for two reasons. First, you want to get your labels as fast as possible. Second,
    the prompt counts as tokens in the cost, so fewer requests mean less cost. Yet,
    we have a limit of 4096 tokens per request. Also, given the issues I mentioned,
    another notable API limitation exists. Passing too many sentences at once increases
    the chance of mismatches and inconsistencies. Thus, it is up to you to keep increasing
    and decreasing the number of sentences until you find your sweet spot for consistency
    and cost. If you do not do that properly, you will suffer in the post-processing
    results phase.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, if you have thousands of sentences to process, start with a batch
    of a few half-dozen sentences and no more than 10 prompts to check on the reliability
    of the responses. Then, slowly increase the number to verify capacity and quality
    until you find the optimal prompt and rate that fits your task.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Verdict and results of the comparison
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 3.1\. Details of the comparison
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ChatGPT, in its GPT-3 version, cannot attribute sentiment to text sentences
    using numeric values (no matter how much I tried). However, specialists attributed
    numeric scores to sentence sentiments in this particular Gold-Standard dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, to make a viable comparison, I had to:'
  prefs: []
  type: TYPE_NORMAL
- en: Categorize the dataset scores into *Positive*, *Neutral*, or *Negative* labels.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Do the same to the scores produced from the domain-specific ML model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define a range of possible thresholds (with steps of 0.001) for determining
    where one category begins and ends. Then, given the threshold *TH*,scores above
    +*TH* are considered *Positive* sentiment, below -*TH* is *Negat*ive, and between
    are *Neutral*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Iterate over the range of thresholds and evaluate both models’ accuracy at each
    point.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Investigate their performance by sets (i.e., training or testing), given that
    the domain-specific model would have an unfair advantage in the training set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The code for step 3 is below. And the complete code for replicating the whole
    comparison [is here](https://drive.google.com/drive/folders/1_FpNvcGjnl8N2Z_Az3FGGWQ4QxmutmgG?usp=share_link).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '3.2\. Verdict: Yes, ChatGPT can not only win but shatter the competition'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The final result is displayed in the plot below, which shows how the accuracy
    (y-axis) changes for both models when categorizing the numeric Gold-Standard dataset,
    as the threshold (x-axis) is adjusted. Also, the training and testing sets are
    on the left and right sides, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7df2607c6c8bce7123a2fa61934611bd.png)'
  prefs: []
  type: TYPE_IMG
- en: Comparison between ChatGPT and the Domain-specific ML model that considers the
    training (left side) and testing (right side) set separately. This evaluation
    assesses how the accuracy (y-axis) changes regarding the threshold (x-axis) for
    categorizing the numeric Gold-Standard dataset for both models.
  prefs: []
  type: TYPE_NORMAL
- en: First, I must be honest. I was not expecting this smashing result. Consequently,
    to not be unfair with ChatGPT, I replicated the original SemEval 2017 competition
    setup, where the Domain-Specific ML model would be built with the training set.
    Then the actual ranking and comparison would only occur over the test set.
  prefs: []
  type: TYPE_NORMAL
- en: However, even in the training set, with the most favorable scenario — threshold
    of 0.066 vs. 0.014 for ChatGPT — the Domain-Specific ML model achieved at most
    an accuracy 2pp worse than ChatGPT’s best accuracy (0.73 vs. 0.75). Moreover,
    ChatGPT showed a superior accuracy across all thresholds than the Domain-Specific
    model in both training and testing sets.
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, the best threshold for both models (0.038 and 0.037) was close
    in the test set. And at this threshold, ChatGPT achieved an 11pp better accuracy
    than the Domain-Specific model (0.66 vs. 077). Also, ChatGPT showed a much better
    consistency across threshold changes than the Domain-Specific Model. Thus, it
    is visible that ChatGPT’s accuracy decreased much less steeply.
  prefs: []
  type: TYPE_NORMAL
- en: In resume, ChatGPT vastly outperformed the Domain-Specific ML model in accuracy.
    Also, the idea is that ChatGPT could be fine-tuned to specific tasks. Hence, imagine
    how much better ChatGPT could become.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3\. Investigating ChatGPT sentiment labeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I always intended to do a more micro investigation by taking examples where
    ChatGPT was inaccurate and comparing it to the Domain-Specific Model. However,
    as ChatGPT went much better than anticipated, I moved on to investigate only the
    cases where it missed the correct sentiment.
  prefs: []
  type: TYPE_NORMAL
- en: Initially, I performed a similar evaluation as before, but now using the complete
    Gold-Standard dataset at once. Next, I selected the threshold (0.016) for converting
    the Gold-Standard numeric values into the Positive, Neutral, and Negative labels
    that incurred ChatGPT’s best accuracy (0.75). Then, I made a confusion matrix.
    The plots are below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/426659a3ea372555089dfe2778fa693e.png)'
  prefs: []
  type: TYPE_IMG
- en: On the left side, a line plot for assessing how the ChatGPT’s accuracy (y-axis)
    changes regarding the threshold (x-axis) for categorizing the numeric Gold-Standard
    complete dataset. The confusion matrix for the positive, neutral, and negative
    labels is on the right side, given that the threshold leading to maximum ChatGPT
    performance is 0.016\. Also, the confusion matrix contains the percentage of ChatGPT’s
    hits and misses according to the converted labels.
  prefs: []
  type: TYPE_NORMAL
- en: Recall that I showed a distribution of data sentences with more positive scores
    than negative sentences in a previous section. Here in the confusion matrix, observe
    that considering the threshold of 0.016, there are 922 (56.39%) positive sentences,
    649 (39.69%) negative, and 64 (3.91%) neutral.
  prefs: []
  type: TYPE_NORMAL
- en: Also, notice that ChatGPT is less accurate with neutral labels. This is expected,
    as these are the labels that are more prone to be affected by the limits of the
    threshold. Interestingly, ChatGPT tended to categorize most of these neutral sentences
    as positive. However, since fewer sentences are considered neutral, this phenomenon
    may be related to greater positive sentiment scores in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, when considering the other labels, ChatGPT showed the capacity
    to identify correctly 6pp more positive categories than negative (78.52% vs. 72.11%).
    In this case, I am not sure this is related to each score spectrum’s number of
    sentences. First, because there are much more sentences of each category type.
    Second, observe the number of ChatGPT’s misses that went to labels in the opposite
    direction (positive to negative or vice-versa). Again, ChatGPT makes more such
    mistakes with the negative category, which is much less numerous. Thus, ChatGPT
    seems more troubled with negative sentences than with positive ones.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4\. Some specific cases and comparison to Human Specialists
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I selected a few sentences with the most noticeable particularities between
    the Gold-Standard (human scores) and ChatGPT. Then, I used the same threshold
    established previously to convert the numerical scores into sentiment labels (0.016).
    Moreover, [ChatGPT has already been reported to outperform humans](https://arxiv.org/abs/2303.15056).
    Thus, I investigated the discrepancies and gave my ruling, to which either Humans
    or the Chatgpt I found was more precise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, since at least 2018, the American agency [DARPA has delved into the significance
    of bringing explainability to AI decisions](https://www.darpa.mil/program/explainable-artificial-intelligence).
    Outstandingly, ChatPGT presents such a capacity: it can explain its decisions.
    This capability helped me to give my ruling. The table below displays this examination.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f47bcdc041dd08bfd889a25b8321db1e.png)'
  prefs: []
  type: TYPE_IMG
- en: The table shows examples of sentences with mismatches between the Gold-Standard
    labels (converted from human specialists’ scores using the 0.016 thresholds) and
    ChatGPT. Moreover, I gave my ruling on which I agreed best.
  prefs: []
  type: TYPE_NORMAL
- en: 'Starting with the cases where I ruled in favor of human specialists. In the
    cases of sentences 3 and 4, ChatGPT should have realized that getting back payouts
    and company alliances are generally considered beneficial in the finance domain.
    However, in the case of sentence 7, I asked it to explain its decision, and here
    is what ChatGPT replied:'
  prefs: []
  type: TYPE_NORMAL
- en: The positive sentiment towards Barclays is conveyed by the word “record,” which
    implies a significant accomplishment for the company in successfully resolving
    legal issues with regulatory bodies.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In the case of this sentence, ChatGPT did not comprehend that, although striking
    a record deal may generally be good, the SEC is a regulatory body. Hence, striking
    a record deal with the SEC means that Barclays and Credit Suisse had to pay a
    record value in fines.
  prefs: []
  type: TYPE_NORMAL
- en: Moving on to sentences 5 and 8, these were very tough calls. Let me be clear,
    humans were correct in their assessments. However, it is just the case that ChatGPT
    just couldn’t have guessed those ones. In sentence 5, it required knowledge of
    the situation at that moment in time to understand that the sentence represented
    a good outcome. And for sentence 8, knowledge is needed that an oil price drop
    correlates to a stock price drop for that specific target company.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, for sentence 6, the most neutral a sentence can get with a zero sentiment
    score, ChatGPT explained its decision as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The sentence is positive as it is announcing the appointment of a new Chief
    Operating Officer of Investment Bank, which is a good news for the company.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: However, this was a generic and not very insightful response and did not justify
    why ChatGPT thinks the appointment of this particular executive was good. Thus,
    I agreed with the human specialists in this case.
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, I ruled favorably in sentences 1, 2, 9, and 10 for ChatGPT. Moreover,
    looking carefully, human specialists should have paid more attention to the target
    company or the overall message. This is particularly emblematic in sentence 1,
    where specialists should have recognized that although the sentiment was positive
    for Glencore, the target company was Barclays, which just wrote the report. In
    this sense, ChatGPT did better discerning the sentiment target and meaning in
    these sentences.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Conclusion and Results Discussion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As seen in the table below, achieving such a performance required lots of financial
    and human resources.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/21adc02dbe9932ffa050d45c2473ef8f.png)'
  prefs: []
  type: TYPE_IMG
- en: A comparison of aspects of models such as the number of parameters, word embedding
    size used, cost, the number of researchers to build it, best accuracy in the test
    set, and whether its decision is explainable.
  prefs: []
  type: TYPE_NORMAL
- en: In this sense, even though ChatGPT outperformed the domain-specific model, the
    ultimate comparison would need fine-tuning ChatGPT for a domain-specific task.
    Doing so would help address if the gains in performance of fine-tuning outweigh
    the effort costs.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, [one of the most essential factors in a textual model is the size
    of the word embeddings](https://doi.org/10.5753/eniac.2019.9329). This technology
    has evolved since the SemEval 2017 edition. Thus, some updates in this part could
    significantly increase the results of the domain-specific model.
  prefs: []
  type: TYPE_NORMAL
- en: On another note, with the popularity of generative text models and LLMs, some
    [open-source versions](https://www.kdnuggets.com/2023/04/8-opensource-alternative-chatgpt-bard.html)
    could help assemble an interesting future comparison. Moreover, the capacity of
    LLMs such as ChatGPT to explain their decisions is an outstanding, arguably unexpected
    accomplishment that can revolutionize the field.
  prefs: []
  type: TYPE_NORMAL
- en: '5\. BONUS: How this comparison can be done in an applied scenario'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sentiment analysis in different domains is a stand-alone scientific endeavor
    on its own. Still, applying the results of sentiment analysis in an appropriate
    scenario can be another scientific problem. Also, as we are considering sentences
    from the financial domain, it would be convenient to experiment with adding sentiment
    features to an applied intelligent system. This is precisely what some researchers
    have been doing, and I am experimenting with that, also.
  prefs: []
  type: TYPE_NORMAL
- en: In 2021 I and some colleagues published a [research article on how to employ
    sentiment analysis on a applied scenario](https://doi.org/10.1145/3490354.3494445).
    In this article — presented at the Second ACM International Conference on AI in
    Finance (ICAIF’21) — we proposed an efficient way to incorporate market sentiment
    into a reinforcement learning architecture. The source code for the implementation
    of this architecture is [available here](https://github.com/xicocaio/its-sentarl),
    and a part of it’s overall design is displayed below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/94e44b2161b2b5b156194d6a9e398531.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A part of an architecture example of how to incorporate market sentiment into
    a reinforcement learning architecture for applied situations. **Source:** *Intelligent
    Trading Systems: A Sentiment-Aware Reinforcement Learning Approach. Proceedings
    of the Second ACM International Conference on AI in Finance (ICAIF ‘21).* ***Lima
    Paiva, F. C.****; Felizardo, L. K.; Bianchi, R. A. d. C. B.; Costa, A. H. R.*'
  prefs: []
  type: TYPE_NORMAL
- en: This architecture was designed to work with numerical sentiment scores like
    those in the Gold-Standard dataset. Still, there are techniques (e.g., [Bullishnex
    index](https://doi.org/10.1111/j.1540-6261.2004.00662.x)) for converting categorical
    sentiment, as generated by ChatGPT in appropriate numerical values. Applying such
    a conversion makes it possible to use ChatGPT-labeled sentiment in such an architecture.
    Moreover, this is an example of what you can do in such a situation and is what
    I intend to do in a future analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1\. Other articles in my line of research (NLP, RL)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '***Lima Paiva, F. C.****; Felizardo, L. K.; Bianchi, R. A. d. C. B.; Costa,
    A. H. R.* [*Intelligent Trading Systems: A Sentiment-Aware Reinforcement Learning
    Approach*](https://doi.org/10.1145/3490354.3494445). Proceedings of the Second
    ACM International Conference on AI in Finance (ICAIF ‘21).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Felizardo, L. K.; **Lima Paiva, F. C.**; de Vita Graves, C.; Matsumoto, E.
    Y.; Costa, A. H. R.; Del-Moral-Hernandez, E.; Brandimarte, P. [*Outperforming
    algorithmic trading reinforcement learning systems: A supervised approach to the
    cryptocurrency market*](https://doi.org/10.1016/j.eswa.2022.117259). Expert Systems
    with Applications (2022), v. 202, p. 117259.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Felizardo, L. K.; **Lima Paiva, F. C.**; Costa, A. H. R.; Del-Moral-Hernandez,
    E. [*Reinforcement Learning Applied to Trading Systems: A Survey*](https://arxiv.org/abs/2212.06064)*.*
    arXiv, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Resources Used Here
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Comparison Jupyter notebook](https://drive.google.com/drive/folders/1_FpNvcGjnl8N2Z_Az3FGGWQ4QxmutmgG?usp=sharing)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Domain-specific machine learning model](https://bit.ly/3kzau8G)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Gold-Standard Dataset](https://bitbucket.org/ssix-project/semeval-2017-task-5-subtask-2/src/master/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Code for applied sentiment analsyis scenario (ITS-SentARL)](https://github.com/xicocaio/its-sentarl)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Main References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Khadjeh Nassirtoussi, A., Aghabozorgi, S., Ying Wah, T., and Ngo, D. C. L.
    [Text mining for market prediction: A systematic review](http://dx.doi.org/10.1016/j.eswa.2014.06.009).
    Expert Systems with Applications (2014), 41(16):7653–7670.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loughran, T. and Mcdonald, B. [When Is a Liability Not a Liability ? Textual
    Analysis , Dictionaries , and 10-Ks](https://doi.org/10.1111/j.1540-6261.2010.01625.x).
    Journal of Finance (2011), 66(1):35–65.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hamilton, W. L., Clark, K., Leskovec, J., and Jurafsky, D. [Inducing domain-specific
    sentiment lexicons from unlabeled corpora.](https://aclanthology.org/D16-1057/)
    Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,
    pages 595–605.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cortis, K.; Freitas, A.; Daudert, T.; Huerlimann, M.; Zarrouk, M.; Handschuh,
    S.; Davis, B. [*SemEval-2017 Task 5: Fine-Grained Sentiment Analysis on Financial
    Microblogs and News*](https://aclanthology.org/S17-2089/). Proceedings of the
    11th International Workshop on Semantic Evaluation (SemEval-2017).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Davis, B., Cortis, K., Vasiliu, L., Koumpis, A., Mcdermott, R., and Handschuh,
    S. [Social Sentiment Indices Powered by X-Scores](https://www.thinkmind.org/index.php?view=article&articleid=alldata_2016_1_40_90041).
    ALLDATA, The Second Inter-national Conference on Big Data, Small Data, Linked
    Data and Open Data (2016).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ferreira, Taynan; **Lima Paiva, F. C.**; Silva, Roberto da; Paula, Angel de;
    Costa, Anna; Cugnasca, Carlos. [*Assessing Regression-Based Sentiment Analysis
    Techniques in Financial Texts*](https://doi.org/10.5753/eniac.2019.9329). 16th
    National Meeting on Artificial and Computational Intelligence (ENIAC), 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reaching Out
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Linkedin](https://www.linkedin.com/in/xicocaio/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Website](https://sites.google.com/alumni.usp.br/francisco-paiva)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Research Gate](https://www.researchgate.net/profile/Francisco-Lima-Paiva)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
