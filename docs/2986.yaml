- en: 'Exploring GEMBA: A New LLM-Based Metric for Translation Quality Assessment'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索 GEMBA：一种基于 LLM 的翻译质量评估新指标
- en: 原文：[https://towardsdatascience.com/exploring-gemba-a-new-llm-based-metric-for-translation-quality-assessment-3a3383de6d1f?source=collection_archive---------7-----------------------#2023-09-29](https://towardsdatascience.com/exploring-gemba-a-new-llm-based-metric-for-translation-quality-assessment-3a3383de6d1f?source=collection_archive---------7-----------------------#2023-09-29)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/exploring-gemba-a-new-llm-based-metric-for-translation-quality-assessment-3a3383de6d1f?source=collection_archive---------7-----------------------#2023-09-29](https://towardsdatascience.com/exploring-gemba-a-new-llm-based-metric-for-translation-quality-assessment-3a3383de6d1f?source=collection_archive---------7-----------------------#2023-09-29)
- en: '#GEN-AI RESEARCH PAPERS'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '#GEN-AI 研究论文'
- en: Using LLMs for evaluating translation quality
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 LLM 评估翻译质量
- en: '[](https://varshitasher.medium.com/?source=post_page-----3a3383de6d1f--------------------------------)[![Dr.
    Varshita Sher](../Images/a3f2e9bf1dc1d8cbe018e54f9341f608.png)](https://varshitasher.medium.com/?source=post_page-----3a3383de6d1f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3a3383de6d1f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3a3383de6d1f--------------------------------)
    [Dr. Varshita Sher](https://varshitasher.medium.com/?source=post_page-----3a3383de6d1f--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://varshitasher.medium.com/?source=post_page-----3a3383de6d1f--------------------------------)[![Dr.
    Varshita Sher](../Images/a3f2e9bf1dc1d8cbe018e54f9341f608.png)](https://varshitasher.medium.com/?source=post_page-----3a3383de6d1f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3a3383de6d1f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3a3383de6d1f--------------------------------)
    [Dr. Varshita Sher](https://varshitasher.medium.com/?source=post_page-----3a3383de6d1f--------------------------------)'
- en: ·
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff8ca36def59&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-gemba-a-new-llm-based-metric-for-translation-quality-assessment-3a3383de6d1f&user=Dr.+Varshita+Sher&userId=f8ca36def59&source=post_page-f8ca36def59----3a3383de6d1f---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3a3383de6d1f--------------------------------)
    ·9 min read·Sep 29, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3a3383de6d1f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-gemba-a-new-llm-based-metric-for-translation-quality-assessment-3a3383de6d1f&user=Dr.+Varshita+Sher&userId=f8ca36def59&source=-----3a3383de6d1f---------------------clap_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff8ca36def59&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-gemba-a-new-llm-based-metric-for-translation-quality-assessment-3a3383de6d1f&user=Dr.+Varshita+Sher&userId=f8ca36def59&source=post_page-f8ca36def59----3a3383de6d1f---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3a3383de6d1f--------------------------------)
    · 9 分钟阅读 · 2023年9月29日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3a3383de6d1f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-gemba-a-new-llm-based-metric-for-translation-quality-assessment-3a3383de6d1f&user=Dr.+Varshita+Sher&userId=f8ca36def59&source=-----3a3383de6d1f---------------------clap_footer-----------)'
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3a3383de6d1f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-gemba-a-new-llm-based-metric-for-translation-quality-assessment-3a3383de6d1f&source=-----3a3383de6d1f---------------------bookmark_footer-----------)![](../Images/dfe2aa68fdf75319c195035d9fe70462.png)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3a3383de6d1f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-gemba-a-new-llm-based-metric-for-translation-quality-assessment-3a3383de6d1f&source=-----3a3383de6d1f---------------------bookmark_footer-----------)![](../Images/dfe2aa68fdf75319c195035d9fe70462.png)'
- en: Image generated by Author using [DALL.E 2](https://openai.com/product/dall-e-2)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图像由作者使用 [DALL.E 2](https://openai.com/product/dall-e-2) 生成
- en: Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: I recently read an intriguing [paper from the Microsoft](https://arxiv.org/pdf/2302.14520.pdf)¹
    team (published in May 2023) that caught my attention. The paper delves into the
    world of translation evaluation, shedding light on an innovative metric called
    GEMBA (**G**PT **E**stimation **M**etric **B**ased **A**ssessment). In this blog
    post, we’ll dissect the paper and provide insights into this exciting development.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我最近读到了一篇有趣的[微软论文](https://arxiv.org/pdf/2302.14520.pdf)¹（发表于2023年5月），引起了我的注意。论文深入探讨了翻译评估领域，揭示了一种名为GEMBA（**G**PT
    **E**stimation **M**etric **B**ased **A**ssessment）的创新度量标准。在这篇博客文章中，我们将剖析论文并提供对这一令人兴奋的发展的一些见解。
- en: 'Premise: Exploring the motivation behind the paper'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前提：探索论文背后的动机。
- en: 'Research Questions and Hypotheses: Exploring the paper’s primary research question
    and hypotheses.'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 研究问题和假设：探讨论文的主要研究问题和假设。
- en: 'Metrics for Assessing Translation Quality: Shallow-dive into existing metrics,
    including BLEU, COMET, and METEOR.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 翻译质量评估度量标准：浅入现有度量标准，包括BLEU、COMET和METEOR。
- en: 'Introduce GEMBA: Deep dive into the novel GEMBA metric.'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 介绍GEMBA：深入了解新颖的GEMBA度量标准。
- en: 'Experiment Details: Insights into the experiments conducted'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实验细节：对所进行实验的洞见。
- en: 'Key findings: Highlighting the main results from the paper'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 主要发现：突出论文的主要结果。
- en: 'Limitations: Discussing things to look out for before implementing GEMBA in
    production'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 限制：讨论在生产环境中实施GEMBA前需要注意的事项。
- en: 1\. Premise
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 前提
- en: LLMs, although not initially designed for translation tasks, have demonstrated
    impressive precision in this domain. This realization led authors to the exploration
    of using LLMs as evaluation tools for translations. The paper’s central idea is
    quite straightforward- positioning LLMs (Large Language Models) as tools for evaluating
    translations, not just for performing them. The authors propose a new metric called
    GEMBA, which outperforms existing state-of-the-art metrics for translation quality
    assessment.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管LLMs最初并未设计用于翻译任务，但它们在这一领域展现了令人印象深刻的精准度。这一认识促使作者探索使用LLMs作为翻译评估工具。论文的核心思想相当简单——将LLMs（大型语言模型）定位为评估翻译的工具，而不仅仅是执行翻译。作者提出了一种新的度量标准叫做GEMBA，它在翻译质量评估方面超越了现有的最先进度量标准。
- en: 2\. Research Question
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 研究问题
- en: '*Can LLMs be used for quality assessment of translations?*'
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*LLMs能否用于翻译质量评估？*'
- en: 3\. Translation Quality Assessment Metrics
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 翻译质量评估度量标准
- en: Before delving into GEMBA, let’s take a quick look at the existing metrics used
    to evaluate the quality of machine-generated translations, such as BLEU, COMET,
    METEOR, etc. These metrics have their own strengths and are suited to different
    use cases, depending on the specific aspects of translation quality that are most
    important for the evaluation.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解GEMBA之前，让我们快速回顾一下用于评估机器生成翻译质量的现有度量标准，如BLEU、COMET、METEOR等。这些度量标准各有其优点，适用于不同的使用案例，取决于翻译质量中最重要的特定方面。
- en: For instance, BLEU (Bilingual Evaluation Understudy) primarily focuses on n-gram
    precision, which means it measures how many n-word sequences in the machine translation
    overlap with n-word sequences in one or more reference translations. It rewards
    the presence of specific word sequences and does not explicitly consider word
    order, stemming, or synonymy. METEOR (Metric for Evaluation of Translation with
    Explicit ORdering), on the other hand, goes beyond basic n-gram matching and takes
    a more holistic approach to translation evaluation. It considers multiple aspects
    of translation quality, including word stemming, synonymy, word order, exact word
    matches, and even penalties for untranslated words. Similarly, COMET (Content-based
    Machine Translation Evaluation) uses a slightly different approach by focusing
    on content-based evaluation and calculating the semantic similarity between a
    machine translation output and a reference translation using embeddings. In simpler
    words, it evaluates how well the content and meaning of the machine translation
    match the reference, regardless of the specific linguistic variations or word
    choices.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，BLEU（双语评估替代指标）主要关注n-gram精确度，这意味着它测量机器翻译中的n-词序列与一个或多个参考翻译中的n-词序列的重叠情况。它奖励特定词序列的存在，而没有明确考虑词序、词干提取或同义词关系。另一方面，METEOR（显式排序翻译评估指标）超越了基本的n-gram匹配，采取了更全面的翻译评估方法。它考虑了翻译质量的多个方面，包括词干提取、同义词关系、词序、精确的词匹配，甚至对未翻译词的惩罚。同样，COMET（基于内容的机器翻译评估）使用了一种略微不同的方法，专注于基于内容的评估，并通过嵌入计算机器翻译输出与参考翻译之间的语义相似度。简而言之，它评估机器翻译的内容和意义与参考翻译的匹配程度，而不考虑具体的语言变异或词汇选择。
- en: You can learn about other evaluation metrics such as YiSi, chrF, BERTScore,
    etc [here](https://machinetranslate.org/metrics).
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你可以在[这里](https://machinetranslate.org/metrics)了解其他评估指标，如YiSi、chrF、BERTScore等。
- en: Given the plethora of metrics we discussed just now, you may ask — *Why do we
    need a new metric like GEMBA?* The answer lies in its unique approach — prompting
    LLMs to assess translations based on their own judgment. Unlike traditional metrics,
    GEMBA seeks to align with human assessment of translations by scoring them on
    a scale (say 0 to 100), focusing on both meaning and grammar.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于我们刚才讨论的众多指标，你可能会问——*为什么我们需要像GEMBA这样的新指标？* 答案在于其独特的方法——促使大型语言模型根据自身判断评估翻译。与传统指标不同，GEMBA旨在通过对翻译进行评分（例如0到100），关注意义和语法，与人类评估翻译对齐。
- en: 4\. Introducing GEMBA
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 介绍GEMBA
- en: As mentioned previously, GEMBA is a GPT-based metric for the assessment of translation
    quality, which works both with a reference translation and without.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，GEMBA是一种基于GPT的翻译质量评估指标，它可以在有参考翻译和没有参考翻译的情况下工作。
- en: 'In essence, GEMBA is a really well-engineered prompt for the evaluation task
    and consists of:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，GEMBA是一个经过精心设计的评估任务prompt，包含：
- en: prompt variant (from a pre-defined set of four variants)
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: prompt变体（来自预定义的四种变体集合）
- en: source language name, e.g., “Chinese”
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 源语言名称，例如“中文”
- en: target language name, e.g., “English”
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标语言名称，例如“英语”
- en: source segments i.e. the sentence that needs to be translated
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 源片段，即需要翻译的句子
- en: candidate translations i.e. the translated sentence
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 候选翻译，即翻译的句子
- en: '[optional] reference translations i.e. the baseline translation that can be
    used as ground truth'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可选] 参考翻译，即可以作为基准翻译的翻译'
- en: 'Here’s an example of one of the prompt variants: GEMBA-DA (Direct Assessment)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这是其中一种prompt变体的示例：GEMBA-DA（直接评估）
- en: '![](../Images/c2fe2c3dc576ad0398dafd70e9e68bc5.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c2fe2c3dc576ad0398dafd70e9e68bc5.png)'
- en: GEMBA-DA prompt. Image taken from original paper
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: GEMBA-DA prompt。图像来源于原始论文
- en: '*P.S. In case you are interested in the other three variants, here is detailed
    information on all prompt variants introduced by the paper:*'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*附注：如果你对其他三种变体感兴趣，以下是论文中介绍的所有prompt变体的详细信息：*'
- en: '![](../Images/b80872de907f5f5ad1a3c2fd7bb50616.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b80872de907f5f5ad1a3c2fd7bb50616.png)'
- en: GEMBA prompt variants. Image taken from original paper
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: GEMBA prompt变体。图像来源于原始论文
- en: 5\. Experimentation and Evaluation
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 实验和评估
- en: 'The authors tested the efficiency of the GEMBA metric using the widely popular
    MQM 2022 dataset (Multidimensional Quality Metrics) as an evaluation set. This
    dataset includes a diverse range of (100K+) sentences from various domains such
    as news, social, e-commerce, etc., and covers three translation directions: English
    to Russian, English to German, and Chinese to English.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 作者使用广泛流行的 MQM 2022 数据集（多维质量指标）测试了 GEMBA 指标的效率。该数据集包括来自新闻、社交、电商等各种领域的多样化句子（100K+），涵盖三个翻译方向：英语到俄语、英语到德语和中文到英语。
- en: Additionally, to find the best GPT model for implementing GEMBA, the authors
    tested each of the prompt variants with seven models from the GPT family ranging
    from GPT 2 up to the latest GPT-4 model.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了找到实施 GEMBA 的最佳 GPT 模型，作者测试了 GPT 系列中从 GPT 2 到最新 GPT-4 模型的七个模型的每个提示变体。
- en: '![](../Images/113060dec377b610ab5deb56ace40c0b.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/113060dec377b610ab5deb56ace40c0b.png)'
- en: 7 GPT models used for evaluating GEMBA. Image taken from original paper
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 用于评估 GEMBA 的 7 个 GPT 模型。图像来自原始论文
- en: Having set the stage for experimentation of the GEMBA metric, the next obvious
    question is —
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在为 GEMBA 指标实验设定了舞台后，接下来的明显问题是 —
- en: 'Q: How do we tell if GEMBA is performing better than conventional metrics such
    as BLEU and COMET?'
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 问：我们如何判断 GEMBA 是否比传统指标如 BLEU 和 COMET 表现更好？
- en: 'A: If GEMBA scores corresponds closely with what a human thinks of the translation,
    we have a winner!'
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'A: 如果 GEMBA 得分与人类对翻译的看法紧密相关，那么我们就找到了赢家！'
- en: To operationalize that answer, there are two metrics (Kendall’s Tau and Accuracy
    (*accuracy*, [Kocmi et al., 2021](https://aclanthology.org/2021.wmt-1.57/))) that
    need to be calculated, depending on whether we are undertaking *segment-level*
    evaluation or *system-level* evaluation. But first, what are they?
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一答案，需要根据我们是进行 *段级* 评估还是 *系统级* 评估来计算两个指标（Kendall’s Tau 和准确度 (*accuracy*,
    [Kocmi et al., 2021](https://aclanthology.org/2021.wmt-1.57/)))。但首先，它们是什么？
- en: '**System level evaluation** assesses the **overall performance** of a machine
    translation system as a whole. It looks at the quality of translations generated
    by the system across a wide range of text or content.'
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**系统级评估** 评估机器翻译系统的 **整体性能**。它查看系统生成的翻译在广泛文本或内容中的质量。'
- en: ''
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Segment level evaluation** focuses on assessing the quality of translations
    on a per-segment basis (typically a **sentence** or a smaller unit of text)'
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**段级评估** 侧重于评估逐段翻译的质量（通常是 **句子** 或更小的文本单元）'
- en: 'Generally speaking:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言：
- en: Kendall’s Tau is used for segment-level evaluations
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kendall’s Tau 用于段级评估
- en: Accuracy is used for system-level evaluations
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确度用于系统级评估
- en: 'Let’s take a deep dive into their formulas for clarity using simple examples:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了清晰起见，我们来深入了解它们的公式，使用简单的示例：
- en: '**A. Kendall’s Tau**'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**A. Kendall’s Tau**'
- en: '**(Kendall’s Tau** tells if there is a correlation between 2 rankings)'
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**（Kendall’s Tau** 用于判断两个排名之间是否存在相关性）'
- en: Suppose you have three translations (A, B, and C) of a given sentence, and you
    want to assess the correlation between rankings produced by a metric (e.g., LLM,
    BLEU, METEOR scores) and human judgments of translation quality.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个给定句子的三种翻译（A、B 和 C），你想评估指标（如 LLM、BLEU、METEOR 分数）产生的排名与人类翻译质量判断之间的相关性。
- en: '**Reference** (Human): “The quick brown fox jumps over the lazy dog.”'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考**（人类）： “快速的棕色狐狸跳过了懒狗。”'
- en: '**Translation A**: “The fast brown fox jumps over the lazy dog.”'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**翻译 A**: “迅速的棕色狐狸跳过了懒狗。”'
- en: '**Translation B**: “The quick red fox jumps over the lazy dog.”'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**翻译 B**: “快速的红色狐狸跳过了懒狗。”'
- en: '**Translation C**: “The lazy dog is jumped over by the quick brown fox.”'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**翻译 C**: “懒狗被快速的棕色狐狸跳过。”'
- en: '**Human Ranking:** A > B > C (i.e., they prefer Translation A the most, then
    B, and lastly C)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**人类排序:** A > B > C（即，他们最喜欢翻译 A，然后是 B，最后是 C）'
- en: '**Metric scores for these translations:** LLM(A) = 0.85'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**这些翻译的指标分数:** LLM(A) = 0.85'
- en: LLM(B) = 0.75
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: LLM(B) = 0.75
- en: LLM(C) = 0.60
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: LLM(C) = 0.60
- en: 'With all information, we can calculate Kendall’s Tau as follows:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 综合所有信息，我们可以按如下方式计算 Kendall’s Tau：
- en: '![](../Images/9758b4a89fc855185d542b615a69bbd7.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9758b4a89fc855185d542b615a69bbd7.png)'
- en: 'Next, let’s calculate concordant and discordant pairs:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们计算一致对和不一致对：
- en: '**Pair 1: (A, B)** Human Ranking: A > B'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**对 1: (A, B)** 人工排序：A > B'
- en: 'LLM Scores: LLM(A) = 0.85 > LLM(B) = 0.75'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 分数：LLM(A) = 0.85 > LLM(B) = 0.75
- en: 'Result: **Concordant pair** (both human and metric prefer A over B).'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '结果: **一致对**（人类和指标都更喜欢 A 而不是 B）。'
- en: '**Pair 2: (A, C)** Human Ranking: A > C'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**对 2: (A, C)** 人工排序：A > C'
- en: 'LLM Scores: LLM(A) = 0.85 > LLM(C) = 0.60'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: LLM分数：LLM(A) = 0.85 > LLM(C) = 0.60
- en: 'Result: **Concordant pair** (both human and metric prefer A over C).'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：**一致对**（人工和度量都更喜欢A而不是C）。
- en: '**Pair 3: (B, C)** Human Ranking: B > C'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**对3： (B, C)** 人工排名：B > C'
- en: 'LLM Scores: LLM(B) = 0.75 > LLM(C) = 0.60'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: LLM分数：LLM(B) = 0.75 > LLM(C) = 0.60
- en: 'Result: **Concordant pair** (both human and metric prefer B over C).'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：**一致对**（人工和度量都更喜欢B而不是C）。
- en: 'Plugging these into the formula we get:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些值代入公式中，我们得到：
- en: '![](../Images/0e0807f463e9c7e7b2433b8c21800542.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0e0807f463e9c7e7b2433b8c21800542.png)'
- en: Kendall’s Tau
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Kendall’s Tau
- en: In other words, *τ* = 1 suggests a perfect agreement between the metric and
    human judgment and is hence a high-quality metric that can be used for automating
    the quality of translations.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，*τ* = 1表示度量和人工判断之间完全一致，因此这是一个可以用于自动化翻译质量的高质量度量。
- en: '**B. Accuracy**'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**B. 准确率**'
- en: Kendall’s Tau assesses the similarity or agreement between rankings, whereas
    accuracy measures the correctness of rankings.
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Kendall’s Tau评估排名之间的相似性或一致性，而准确率衡量排名的正确性。
- en: 'To illustrate calculations of accuracy, take the same setup as above i.e. Reference
    (Human), Translation A, Translation B, Translation C, Human Ranking but let’s
    update the metric scores a bit so that B is marked as a better translation than
    C according to Bleu:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明准确率的计算，我们采用与上面相同的设置，即参考（人工）、翻译A、翻译B、翻译C、人工排名，但让我们稍微更新度量分数，以便根据Bleu将B标记为比C更好的翻译：
- en: 'Metric Scores (BLEU):'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 度量分数（BLEU）：
- en: BLEU(A) = 0.80
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: BLEU(A) = 0.80
- en: BLEU(B) = 0.70
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: BLEU(B) = 0.70
- en: BLEU(C) = 0.75
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: BLEU(C) = 0.75
- en: 'With all the information, here’s how to calculate accuracy:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 结合所有信息，这里是如何计算准确率的方法：
- en: '![](../Images/b6c0c4a022e73e9b05d6f5fe78701d82.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b6c0c4a022e73e9b05d6f5fe78701d82.png)'
- en: Let’s calculate metric Δ (which is nothing but the difference in metric values
    for a pair of translations) and human Δ (which is the difference in the human
    scores for a pair of translations). If you look at the formula closely, you will
    notice we are not interested in the actual value of the Δ but the sign of the
    Δ. Put simply, a high accuracy can only be achieved if the sign of both Δs are
    the same i.e. human and metric are in alignment about a translation.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算度量Δ（这只是成对翻译的度量值差异）和人工Δ（这是假设的翻译对的人工评分差异）。如果你仔细查看公式，你会注意到我们并不关心Δ的实际值，而是Δ的符号。简单来说，只有当两个Δ的符号相同，即人工和度量对翻译的看法一致时，才能实现高准确率。
- en: '**Pair 1: (A, B)** Metric∆ = BLEU(A) — BLEU(B) = 0.80–0.70 = 0.10'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**对1： (A, B)** 度量Δ = BLEU(A) — BLEU(B) = 0.80–0.70 = 0.10'
- en: Human∆ = 1 (A is ranked higher than B)
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 人工Δ = 1（A的排名高于B）
- en: 'Result: Metric∆ and Human∆ have the same sign (both positive). This is a rank
    agreement.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：度量Δ和人工Δ具有相同的符号（都是正的）。这是一个排名一致性。
- en: '**Pair 2: (A, C)** Metric∆ = BLEU(A) — BLEU(C) = 0.80–0.75 = 0.05'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**对2： (A, C)** 度量Δ = BLEU(A) — BLEU(C) = 0.80–0.75 = 0.05'
- en: Human∆ = 2 (A is ranked higher than C)
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 人工Δ = 2（A的排名高于C）
- en: 'Result: Metric∆ and Human∆ have the same sign (both positive). This is a rank
    agreement.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：度量Δ和人工Δ具有相同的符号（都是正的）。这是一个排名一致性。
- en: '**Pair 3: (B, C)** Metric∆ = BLEU(B) — BLEU(C) = 0.70–0.75 = -0.05'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**对3： (B, C)** 度量Δ = BLEU(B) — BLEU(C) = 0.70–0.75 = -0.05'
- en: Human∆ = 1 (B is ranked higher than C)
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 人工Δ = 1（B的排名高于C）
- en: 'Result: Metric∆ and Human∆ have different signs (metric is negative, human
    is positive). This is a rank disagreement.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：度量Δ和人工Δ具有不同的符号（度量为负，人工为正）。这是一个排名不一致。
- en: 'Plugging these into the formula we get:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些值代入公式中，我们得到：
- en: Accuracy(Bleu) = (2/3)*100 = 67%, meaning the BLEU metric accurately ranks 2
    out of 3 pairs of translations as per human judgment. Whether or not this percentage
    is good enough to automate evaluation with Bleu, I will leave that to the reader’s
    discretion!
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率（Bleu）= (2/3)*100 = 67%，这意味着BLEU度量准确地将3对翻译中的2对按照人工判断进行了排名。是否这个百分比足够好以自动化Bleu的评估，我留给读者自行判断！
- en: '*Note: The examples used to demonstrate the calculation of Kendall’s Tau and
    Accuracy were simplified for demonstration purposes. In reality, the formulas
    get more complicated if ties need to be handled i.e. if a human/metric gives the
    same ranking to two or more translations. You can read more about them* [*here*](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient#Accounting_for_ties)*.*'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：用于演示Kendall’s Tau和准确率计算的示例已简化以进行演示。在实际情况下，如果需要处理平局，即如果人工/度量对两个或更多翻译给出相同的排名，则公式会变得更复杂。你可以阅读更多有关内容*
    [*这里*](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient#Accounting_for_ties)*。*'
- en: '6\. Key Results: System vs. Segment Level Evaluation'
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关键结果：系统与片段级别评估
- en: The paper reports that GEMBA excels in system-level evaluations, surpassing
    existing metrics.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 论文报告称GEMBA在系统级评估中表现优异，超越了现有的评估指标。
- en: '![](../Images/616f4c4e0fe739d69ca0110e1a2625ee.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/616f4c4e0fe739d69ca0110e1a2625ee.png)'
- en: Results from system-level evaluations. Image taken from original paper
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 系统级评估结果。图片取自原始论文
- en: However, in segment-level evaluations, there is room for improvement. Ties in
    rankings between LLMs and humans at this level may account for this discrepancy
    as Kendall’s Tau penalizes ties. Since the Gemba-DA metric returns a discrete
    value between 0–100, there is a high probability that two translations will obtain
    an equal score.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在分段级评估中还有改进的空间。LLM与人类在这一层级上的排名平局可能解释了这一差异，因为Kendall’s Tau会惩罚平局。由于Gemba-DA指标返回0-100之间的离散值，两种翻译得到相等分数的概率很高。
- en: '![](../Images/a91e9b41382d139357bfadceead09239.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a91e9b41382d139357bfadceead09239.png)'
- en: Results from segment-level evaluations (P.S. the first column Accuracy is the
    same one from the previous table). Image taken from original paper
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 分段级评估结果（P.S. 第一列的准确率与前面的表格相同）。图片取自原始论文
- en: The results also stress the importance of choosing the right LLM for implementing
    GEMBA. Among the seven models from the GPT family tested any model beyond 3.5
    showed promising results. GPT-4 stood out as the top performer, but models like
    Davinci, ChatGPT Turbo, and GPT-3.5 also performed well.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 结果还强调了选择合适LLM以实施GEMBA的重要性。在测试的GPT家族的七种模型中，任何超过3.5的模型都表现出色。GPT-4表现尤为突出，但Davinci、ChatGPT
    Turbo和GPT-3.5也表现良好。
- en: '![](../Images/7a2b32be8d7943a777023d7225f40647.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a2b32be8d7943a777023d7225f40647.png)'
- en: GEMBA implementation with various models from the GPT family. Image taken from
    original paper
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 各种GPT家族模型的GEMBA实施。图片取自原始论文
- en: '**7\. Limitations and Considerations**'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**7\. 限制和考虑事项**'
- en: The paper highlights certain limitations to address GEMBA’s broader applicability.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 论文突出了GEMBA在更广泛应用中的某些限制。
- en: There is a need for evaluation of GEMBA with low-resource languages since the
    paper only considers English, Chinese, Russian, and German.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于论文仅考虑了英语、中文、俄语和德语，因此需要对低资源语言进行GEMBA的评估。
- en: There could be potential data leakage concerns as it is uncertain whether the
    test data was included in Open AI’s training (the secret sauce hasn’t been released
    by Open AI at the time of writing). Having said that, the likelihood is very low
    as GPT models claim to have a knowledge cutoff date of Sep 2021, and the MQM dataset
    was released in Dec 2022.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能存在数据泄漏的风险，因为尚不清楚测试数据是否包含在Open AI的训练中（撰写时Open AI尚未发布秘密配方）。尽管如此，可能性非常低，因为GPT模型声称知识截止日期为2021年9月，而MQM数据集于2022年12月发布。
- en: 'There could be occasional invalid responses from LLMs:'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM可能会偶尔出现无效回应：
- en: ►textual answer instead of score → handled by increasing `temperature` until
    a numeric score is outputted.
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ►文本回答而非分数→通过提高`temperature`直到输出数字分数来处理。
- en: ►“2”, “two”, “**”, “★★”, “two stars”, or “2 stars” → handled in post-processing
    to maintain uniformity.
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ►“2”，“two”，“**”，“★★”，“two stars”或“2 stars”→在后处理中处理以保持一致性。
- en: ►authors excluded outputs from LLM in the non-English target language ( such
    as 星 or 五) from analysis.
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ►作者排除了非英语目标语言（如星或五）的LLM输出。
- en: '![](../Images/265cb17581d9e1baa8d3129dcbdb9e02.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/265cb17581d9e1baa8d3129dcbdb9e02.png)'
- en: Number of invalid responses. Image taken from original paper.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 无效回应的数量。图片取自原始论文。
- en: Conclusion
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Keeping in mind the ease of implementing GEMBA with a simple prompt, it definitely
    stands out as a groundbreaking metric for translation quality assessment. Its
    alignment with human judgment and adaptability to various LLM models make it a
    compelling addition to the field of NLP and translation evaluation. As we continue
    to explore and refine GEMBA (perhaps with few-shot prompting), it holds promise
    as a valuable tool for ensuring high-quality translations in diverse language
    contexts.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 牢记使用简单提示实现GEMBA的便利性，它无疑是翻译质量评估的突破性指标。它与人类判断的一致性以及对各种LLM模型的适应性，使其成为NLP和翻译评估领域的有力补充。随着我们继续探索和完善GEMBA（也许通过少量提示），它作为确保在多种语言环境中高质量翻译的有价值工具，具有很大的潜力。
- en: '*[1] Kocmi, T., & Federmann, C. (2023). Large language models are state-of-the-art
    evaluators of translation quality. arXiv preprint arXiv:2302.14520.*'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '*[1] Kocmi, T., & Federmann, C. (2023). 大型语言模型是翻译质量的最先进评估工具。arXiv预印本arXiv:2302.14520。*'
