# 将 LLM 应用于企业数据：概念、关注点和热点观点

> 原文：[`towardsdatascience.com/applying-llms-to-enterprise-data-concepts-concerns-and-hot-takes-e19ded4bde88?source=collection_archive---------0-----------------------#2023-05-28`](https://towardsdatascience.com/applying-llms-to-enterprise-data-concepts-concerns-and-hot-takes-e19ded4bde88?source=collection_archive---------0-----------------------#2023-05-28)

[](https://medium.com/@sjstone1987?source=post_page-----e19ded4bde88--------------------------------)![Sam Stone](https://medium.com/@sjstone1987?source=post_page-----e19ded4bde88--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e19ded4bde88--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----e19ded4bde88--------------------------------) [Sam Stone](https://medium.com/@sjstone1987?source=post_page-----e19ded4bde88--------------------------------)

·

[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcbfd810ae7b5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapplying-llms-to-enterprise-data-concepts-concerns-and-hot-takes-e19ded4bde88&user=Sam+Stone&userId=cbfd810ae7b5&source=post_page-cbfd810ae7b5----e19ded4bde88---------------------post_header-----------) 发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e19ded4bde88--------------------------------) ·11 分钟阅读·2023 年 5 月 28 日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe19ded4bde88&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapplying-llms-to-enterprise-data-concepts-concerns-and-hot-takes-e19ded4bde88&user=Sam+Stone&userId=cbfd810ae7b5&source=-----e19ded4bde88---------------------clap_footer-----------)

--

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe19ded4bde88&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapplying-llms-to-enterprise-data-concepts-concerns-and-hot-takes-e19ded4bde88&source=-----e19ded4bde88---------------------bookmark_footer-----------)![](img/e5099f80b99f02339e08046a067ee45c.png)

来源：[DreamStudio](https://beta.dreamstudio.ai/)（由作者生成）

让 GPT-4 证明有无限个素数——而且要押韵——[它可以做到](https://arxiv.org/pdf/2303.12712.pdf)。但让它回答你的团队上季度的表现如何，它将惨败。这说明了大型语言模型（“LLMs”）的一个根本性挑战：它们对一般的、公开的知识（如素数理论）有很好的理解，但对专有的、非公开的信息（例如你团队上季度的表现）完全不了解。[1] 专有信息对于绝大多数企业使用工作流至关重要。一个理解公共互联网的模型虽然有趣，但对于大多数组织在原始形式下作用不大。

在过去的一年里，我有幸与多个组织合作，将大型语言模型（LLMs）应用于企业案例。本文详细介绍了任何开始此类旅程的人应该了解的关键概念和关注点，以及对 LLMs 如何演变及其对机器学习产品策略的影响的一些见解。它面向产品经理、设计师、工程师以及其他对 LLMs“底层”工作原理了解有限或没有了解，但有兴趣学习这些概念而无需深入技术细节的读者。

# 四个概念

## 检索增强生成（RAG）：上下文窗口和嵌入

让 LLM 对专有数据进行推理的最简单方法是将专有数据提供给模型的提示。大多数 LLM 可以正确回答以下问题：“我们有 2 个客户，A 和 B，分别花费了$100K 和$200K。谁是我们最大的客户，他们花了多少钱？”我们只是通过将查询（第二句话）与上下文（第一句话）预先添加来进行了基本的提示工程。

但在现实世界中，我们可能有成千上万或数百万的客户。我们如何决定哪些信息应该进入上下文——考虑到每个包含在上下文中的单词都需要付费？这就是嵌入的作用。嵌入是一种将文本转换为数值向量的方法，相似的文本生成相似的向量（在 N 维空间中“接近”的向量）。[2] 我们可能会嵌入网站文本、文档，甚至是来自 SharePoint、Google Docs 或 Notion 的整个语料库。然后，对于每个用户提示，我们将其嵌入，并找到与我们的提示向量最相似的文本语料库中的向量。

例如，如果我们嵌入了有关动物的维基百科页面，当用户询问有关野生动物园的问题时，我们的搜索将高度排名有关狮子、斑马和长颈鹿的维基百科文章。这使我们能够识别与提示最相似的文本块——因此最有可能回答问题的文本块。[3] 我们将这些最相似的文本块包含在预先添加到提示中的上下文中，以便提示中包含 LLM 回答问题所需的所有信息。

## **微调**

嵌入的一个缺点是每次调用 LLM 都需要将所有上下文与提示一起传递。LLM 没有对最基本的企业特定概念的“记忆”。而且由于大多数基于云的 LLM 提供商按提示令牌收费，这可能会很快变得昂贵。[4]

微调使 LLM 能够理解特定企业的概念，而无需在每个提示中包含这些概念。我们取一个基础模型，该模型已经通过数十亿个学习参数编码了一般知识，并调整这些参数以反映特定企业知识，同时仍保留底层的一般知识。[5] 当我们使用新的微调模型生成推断时，我们可以“免费”获得这些企业知识。

与嵌入/提示工程不同，后者的底层模型是第三方黑箱，微调更接近经典机器学习，机器学习团队从零开始创建自己的模型。微调需要一个带有标记观察的数据集；微调后的模型对训练数据的质量和数量非常敏感。我们还需要做出配置决策（如轮次、学习率等），协调长期训练任务，并跟踪模型版本。一些基础模型提供商提供了抽象化这种复杂性的 API，但有些则没有。

尽管微调模型的推断可能更便宜，但这可能会被昂贵的训练任务所抵消。[6] 一些基础模型提供商（如 OpenAI）仅支持落后模型的微调（所以[不包括 ChatGPT 或 GPT-4](https://platform.openai.com/docs/guides/fine-tuning)）。

## **Evals**

LLMs 带来了一个新颖且重要的挑战，即衡量复杂输出的质量。经典的机器学习团队有经过验证的方法来衡量简单输出的准确性，如数值预测或分类。但大多数企业使用 LLM 的场景涉及生成数十到数千个单词的响应。概念复杂到需要超过十个单词时，通常可以用多种方式表达。因此，即使我们有一个经过人工验证的“专家”响应，对模型响应与专家响应进行精确字符串匹配也是过于严格的测试，会低估模型响应的质量。

[Evals](https://github.com/openai/evals)框架，由 OpenAI 开源，是应对这一问题的一种方法。该框架需要一个标记的测试集（其中提示与“专家”响应匹配），但它允许对模型和专家响应进行广泛的比较。例如，模型生成的答案是否是专家答案的子集或超集；是否在事实上一致；比专家答案更简洁或不如专家答案简洁？警告是 Evals 使用 LLM 来进行这些检查。如果“检查者”LLM 存在缺陷，评估结果本身可能也会不准确。

## **对抗样本**

如果你在生产环境中使用 LLM，你需要确信它能够安全地处理误导性或恶意的用户输入。对于大多数企业来说，起点是确保模型不会传播虚假信息。这意味着系统需要知道自己的局限性以及何时说“不知道”。这里有许多战术方法。可以通过提示工程来实现，例如使用提示语言“如果无法用上述上下文回答问题，请回答‘我不知道’”。也可以通过微调来实现，提供超出范围的训练示例，其中专家的回答是“我不知道”。

企业还需要防范恶意用户输入，例如[提示黑客攻击](https://learnprompting.org/docs/category/-prompt-hacking)。限制系统可接受的输入和输出的格式及长度可以是一个简单而有效的起点。如果你只是为内部用户服务，采取预防措施是一个好主意；如果你为外部用户服务，这些预防措施则是必不可少的。

# 三个关注点

## **偏见延续**

最受欢迎的 LLM（OpenAI / GPT-4、Google / Bard）的开发者们已经费尽心力地将他们的模型与人类偏好对齐，并部署了复杂的调节层。如果你让 GPT-4 或 Bard 讲一个种族歧视或厌女的笑话，它们会礼貌地拒绝。[7]

这是个好消息。不过坏消息是，这种针对社会偏见的调节措施，并不一定能防止机构偏见。设想我们的客户支持团队对某一特定类型的客户有粗鲁的历史。如果历史的客户支持对话被天真地用于构建一个新的 AI 系统（例如，通过微调），这个系统可能会复制这种偏见。

如果你使用过去的数据来训练一个 AI 模型（无论是经典模型还是生成模型），需要仔细审视你希望将哪些过去的情况延续到未来，哪些则不希望。 有时，制定原则并以此为基础工作（例如，通过提示工程），而不是直接使用过去的数据，会更为简便。

## **模型锁定**

除非你一直生活在石头下，否则你应该知道生成型 AI 模型正在迅速进步。考虑到企业使用场景，今天最好的 LLM 可能在六个月后就不是最佳解决方案，六年后几乎肯定不会是最佳解决方案。聪明的机器学习团队知道，他们会在某个时候需要更换模型。

但还有另外两个主要原因需要轻松“替换” LLMs。首先，许多基础模型提供者在支持指数增长的用户量方面遇到了困难，导致了[停机和服务质量下降](https://isdown.app/integrations/openai)。在你的系统中构建一个备份基础模型是一个好主意。其次，在你的系统中测试多个基础模型（“赛马”）来了解哪个表现最好是非常有用的。根据上面的评估部分，分析地衡量模型质量通常很困难，因此有时你只想运行两个模型并进行定性比较。

## **数据泄露**

阅读你考虑使用的任何基础模型的条款和条件。如果模型提供者有权使用用户输入进行未来的模型训练，那是令人担忧的。LLMs 体积如此庞大，以至于特定用户的查询/响应可能会直接编码到未来的模型版本中，并可能对该版本的任何用户开放。想象一下你组织中的用户查询“我如何清理这段做 XYZ 的代码？ [你的专有机密代码在这里]”。如果这个查询被模型提供者用来重新训练他们的 LLM，那么新版本的 LLM 可能会学习到你的专有代码是解决 XYZ 用例的好方法。如果一个竞争对手询问如何做 XYZ，这个 LLM 可能会“泄露”你的源代码，或者类似的内容。

OpenAI 现在[允许用户选择不让他们的数据用于训练模型](https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt)，这设立了一个良好的先例，但并不是所有模型提供者都遵循了他们的例子。一些组织也在探索在自己的虚拟私有云中运行 LLMs；这也是对开源 LLMs 感兴趣的一个主要原因。

# 两个热点问题

## **提示工程将主导微调**

当我首次开始为企业使用调整大型语言模型（LLMs）时，我对微调（fine tuning）的兴趣远大于提示工程（prompt engineering）。微调感觉更符合我所熟悉的经典机器学习系统的原则：处理一些数据，生成训练/测试数据集，启动训练任务，等待一段时间，评估结果与某些指标。

但我逐渐相信，对于大多数企业用例来说，提示工程（配合嵌入）是一种更好的方法。首先，提示工程的迭代周期比微调要快得多，因为没有模型训练，而模型训练可能需要数小时或数天。改变提示并生成新的响应可以在几分钟内完成。相反，微调在模型训练方面是不可逆的；如果使用了不正确的训练数据或出现了更好的基础模型，你需要重新开始微调任务。其次，提示工程需要的 ML 概念知识远少于神经网络超参数优化、训练任务协调或数据整理等。微调通常需要经验丰富的 ML 工程师，而提示工程通常可以由没有 ML 经验的软件工程师完成。第三，提示工程对于快速增长的[模型链](https://python.langchain.com/en/latest/index.html)策略效果更佳，在这种策略中，复杂的请求被分解为更小的组成请求，每个请求可以分配给不同的 LLM。有时，最好的“组成模型”是经过微调的模型。[8] 但对企业而言，大多数增值工作在于（i）找出如何拆解问题，（ii）为每个组成部分编写提示，以及（iii）为每个部分确定最佳的现成模型；而不是创建自己的微调模型。

随着时间的推移，提示工程的优势可能会不断扩大。如今，提示工程需要长而昂贵的提示（因为每个提示必须包含上下文）。但我敢打赌，随着模型提供商领域的竞争加剧以及提供商们找到更便宜的 LLM 训练方法，每个 token 的成本会迅速下降。提示工程目前也受限于最大提示大小——不过，OpenAI 已经接受 GPT-4 每个提示 32K tokens（约 40 页的平均英文文本），而[Anthropic 的 Claude 接受 100K tokens](https://www.anthropic.com/index/100k-context-windows)（约 15 页）。我也敢打赌，未来会出现更大的上下文窗口。

*[2023 年 8 月更新] 这篇文章很棒* [*解释了你可能不需要微调的原因。*](https://www.tidepool.so/2023/08/17/why-you-probably-dont-need-to-fine-tune-an-llm/)

## **数据不会像以前那样成为护城河**

随着 LLMs 在生成可人类解释的推理方面变得越来越好，考虑人类如何使用数据进行推理以及这对 LLMs 意味着什么是很有用的。[9] 人类实际上并不使用很多数据！大多数时候，我们做的是“零样本学习”，这意味着我们回答问题时不需要提供一组示例问答对。提问者只提供问题，我们根据逻辑、原则、启发式、偏见等来回答。

这与几年前的 LLMs 有所不同，当时它们只能进行少量学习，你需要在提示中包含少量示例问答对。这与经典的机器学习有很大不同，后者需要对数百、数千或数百万个问答对进行训练。

我坚信，LLM 使用案例中占主导地位的将会是“零样本”使用。LLMs 将能够在没有任何用户提供示例的情况下回答大多数问题。它们将需要提示工程，以指令、政策、假设等形式存在。例如，[这篇文章](https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411)使用 GPT-4 审查代码中的安全漏洞；这种方法不需要关于过去易受攻击代码的数据。清晰的指令、政策和假设将变得越来越重要——但拥有大量高质量、标记好的专有数据将变得不那么重要。

如果你正在积极地将 LLMs 应用于你的企业数据中，我很想听听你发现了什么有效，什么无效。请留下评论！

# 脚注

[1] 直到最近，LLMs 对最新的公开知识也不了解——例如，GPT-4 是在 2021 年 9 月之前收集的信息上进行训练的。然而，现在 GPT-4 和 Bard 的消费者接口可以查询开放互联网，并收集有关近期事件的信息。因此，时效性正迅速消退，成为 LLMs 的知识限制。

[2] 嵌入可以处理各种数据结构，而不仅仅是文本。

[3] 整个嵌入工作流程发生在调用 LLM 之前。例如，OpenAI 推荐使用其 ada-002 模型进行嵌入，这比任何前沿的 GPT 模型都更便宜、更快。

[4] 令牌是词语或词语的一部分。[这是一个很好的解释，说明为什么语言模型使用令牌而不是词语。](https://blog.quickchat.ai/post/tokens-entropy-question/#:~:text=Why%20tokens%3F,up%20on%20features%20that%20matter.)

[5] 学习到的参数数量可以从百万到万亿不等。目前大多数广泛使用的 LLM 具有数十亿个参数。

[6] 更便宜的推理并非理所当然；[OpenAI 收费](https://docs.google.com/document/d/1iJRm5vmT3Udv2mGTD4LsLobYaHEj2OaBywIzI83WdQo/edit#) 每 1 千个令牌$0.03–0.06，适用于具有 8K 上下文窗口的 GPT-4（具体取决于令牌是输入还是输出）。针对经过微调的 Davinci 模型，它的收费为每 1 千个令牌$0.12，该模型已相对滞后。

[7] 当然，这些人类是由 OpenAI 和 Google 雇佣的。由于许多人不同意这些组织的价值观，他们也不同意这些审查政策。

[8] 例如，[GOAT](https://huggingface.co/papers/2305.14201) 是一个针对算术进行了微调的开源模型 LLaMA 的版本。它在许多算术基准测试中超越了 GPT-4。大多数企业的工作流程都需要进行算术运算；在链式处理方法下，涉及算术的工作流程部分会被识别并路由到 GOAT。对于这样的企业来说，投资于良好的路由和与 GOAT 的集成是有意义的，但在我看来，不值得自己微调算术 LLM。

[9] 关于今天的语言模型（LLMs）是否能够真正进行推理，以及真正的推理到底意味着什么（是否需要意识？自我意识？主动性？）存在很多争论。绕过这个哲学上的而非实证性的争论，值得注意的是，LLMs 在产生符合广泛认同的良好推理观念的解释方面确实在不断进步；[这篇论文](https://arxiv.org/pdf/2303.12712.pdf)中有许多很好的例子。
