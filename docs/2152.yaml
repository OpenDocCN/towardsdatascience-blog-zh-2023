- en: Basics of Anomaly Detection with Multivariate Gaussian Distribution
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-basics-of-anomaly-detection-65aff59949b7?source=collection_archive---------2-----------------------#2023-07-05](https://towardsdatascience.com/the-basics-of-anomaly-detection-65aff59949b7?source=collection_archive---------2-----------------------#2023-07-05)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Overview of anomaly detection, review of multivariate Gaussian distribution,
    and implementation of basic anomaly detection algorithm in Python with two examples
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://viyaleta.medium.com/?source=post_page-----65aff59949b7--------------------------------)[![Viyaleta
    Apgar](../Images/8d8fd8e4817bc4d1dbeb16a2ec1ae1f1.png)](https://viyaleta.medium.com/?source=post_page-----65aff59949b7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----65aff59949b7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----65aff59949b7--------------------------------)
    [Viyaleta Apgar](https://viyaleta.medium.com/?source=post_page-----65aff59949b7--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fccae8864d5a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-of-anomaly-detection-65aff59949b7&user=Viyaleta+Apgar&userId=ccae8864d5a4&source=post_page-ccae8864d5a4----65aff59949b7---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----65aff59949b7--------------------------------)
    ·11 min read·Jul 5, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F65aff59949b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-of-anomaly-detection-65aff59949b7&user=Viyaleta+Apgar&userId=ccae8864d5a4&source=-----65aff59949b7---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F65aff59949b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-of-anomaly-detection-65aff59949b7&source=-----65aff59949b7---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Our innate ability to recognize patters allows us to use this skill in filling-in
    gaps or predicting what is going to happen next. Occasionally, however, something
    happens that does not fit our expectation and does not fall into our perception
    of a pattern. We call such occurrences anomalies. If we are trying to predict
    something, we may want to exclude anomalies from our training data. Or perhaps
    we want to identify anomalies to help make our life better. In either case, anomaly
    detection techniques can prove to be useful and applicable in most industries
    and subject areas.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: This article will guide you through the basics of anomaly detection and implementation
    of statistical anomaly detection model.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本文将引导你了解异常检测的基础知识以及统计异常检测模型的实现。
- en: What is anomaly detection?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是异常检测？
- en: In general terms, anomaly detection refers to the process of identifying phenomena
    that is out of ordinary. The goal of anomaly detection is to identify events,
    occurrences, data points, or outcomes that are not in line with our expectations
    and do not fit some underlying pattern. Hence, the key to implementing anomaly
    detection is to understand the underlying pattern of expected events. If we know
    the pattern of the expected, we can use it to map the never-before-seen data points;
    if our mapping is not successful and our new data point falls outside of our expected
    pattern, it’s probable that we have found our anomaly.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，异常检测是指识别异常现象的过程。异常检测的目标是识别那些与我们的期望不符的事件、发生情况、数据点或结果。因此，实施异常检测的关键是理解预期事件的基本模式。如果我们知道预期的模式，我们可以用它来映射前所未见的数据点；如果我们的映射不成功，而我们的新数据点落在预期模式之外，那么很可能我们发现了异常。
- en: There are three types of anomalies that typically occur. First type includes
    individual instances which are considered anomalous with respect to the entire
    dataset (e.g., an individual car driving at very low speed on a highway is anomalous
    compared to all highway traffic). Second type includes instances which are anomalies
    within a specific context (e.g., credit card transactions which appear OK when
    compared to all credit card transactions but are anomalous for the specific individual’s
    spending pattern). Third type of anomalies is collective — a set of instances
    may be considered anomalous even though each instance on its own follows a certain
    expectation (e.g., a single fraudulent credit card transaction on Amazon may not
    seem out of ordinary but a set of transactions that take place back to back in
    a short amount of time is suspicious) [1].
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 通常有三种类型的异常情况。第一种类型包括相对于整个数据集被认为异常的单独实例（例如，一辆汽车在高速公路上以非常低的速度行驶，相比于所有高速公路交通，这种情况被认为是异常的）。第二种类型包括在特定背景下的异常实例（例如，相比于所有信用卡交易，看似正常的信用卡交易在特定个人的消费模式中却是异常的）。第三种异常类型是集体性的——即使每个实例本身都符合一定的期望，一组实例也可能被认为是异常的（例如，一次单独的欺诈性信用卡交易在亚马逊上可能不显得特别，但在短时间内连续发生的一组交易则很可疑）[1]。
- en: 'Anomaly detection techniques fall into three categories:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 异常检测技术分为三类：
- en: '**Supervised detection** requires positive and anomalous labels in the dataset.
    Supervised learning algorithms like neural networks or boosted forests can be
    applied to categorize data points into expected/anomaly classes. Unfortunately,
    anomaly datasets tend to be very imbalanced and generally do not have enough training
    samples to allow up or downsampling techniques to aid the supervised learning.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**监督检测**需要数据集中有正标签和异常标签。可以应用诸如神经网络或提升森林等监督学习算法，将数据点分类为预期类别/异常类别。不幸的是，异常数据集往往非常不平衡，通常没有足够的训练样本来使上采样或下采样技术帮助监督学习。'
- en: '**Semi-supervised detection** deals with data that is partially labeled. Semi-supervised
    techniques assume that the input data only contains positive instances and that
    the input data follows an expected pattern. These techniques attempt to learn
    the distribution of positive cases in order to be able to generate positive instances.
    During testing, the algorithm will evaluate the likelihood that the anomalous
    instance could have been generated by the model and uses this probability to predict
    anomalous cases. [2]'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**半监督检测**处理部分标记的数据。半监督技术假设输入数据仅包含正实例，并且输入数据遵循预期模式。这些技术试图学习正案例的分布，以便能够生成正实例。在测试过程中，算法将评估异常实例可能是由模型生成的概率，并使用这一概率来预测异常情况。[2]'
- en: '**Unsupervised detection** uses completely unlabeled data in order to create
    a boundary of expectation and anything that falls outside of this boundary is
    considered to be anomalous.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**无监督检测**使用完全未标记的数据来创建期望的边界，任何落在此边界之外的都被认为是异常的。'
- en: Anomaly detection techniques can be applied to any data and data format impacts
    which algorithm will be most useful. Types of data include **series** (time series,
    linked list, language, sound), **tabular** (e.g., engine sensor data), **image**
    (e.g., X-ray images), and **graph** (e.g., workflow or process).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4de9612835019d778d1b3b5b103b76c9.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
- en: Example of anomaly detection in chest X-ray images [[4]](https://doi.org/10.1007/s10278-020-00413-2)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: 'Given the variety of problems and techniques, anomaly detection is actually
    a vast area of data science with many applications. Some of these applications
    include: fraud detection, cybersecurity applications, analysis of sales or transactional
    data, identification of rare diseases, monitoring of manufacturing processes,
    exoplanet search, machine learning preprocessing, and many more. Therefore, access
    to powerful and performant algorithms has the potential to make significant impact
    in many fields.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a look how at the most basic algorithm that can be used to detect
    anomalies.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Gaussian Distribution for Anomaly Detection
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the basic anomaly detection techniques employs the power of Gaussian
    (i.e. Normal) distribution in order to identify outliers.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Discovered by Carl Friedrich Gauss, Gaussian distribution models many natural
    phenomena and is, therefore, a popular choice for modeling features in a dataset.
    This distribution’s probability density function is a bell curve centered at the
    arithmetic mean and the width of the curve is defined by the variance of the dataset.
    With the majority of the cases being at or near the center, the probability density
    function features two elongated tails on each end. The more rare the instance
    — the further it is from the center — the more likely it is to be an outlier or
    an anomaly. Eureka!— we can use this concept to model anomalies in our dataset.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: The probability density function, defined as f(x), measures the probability
    of some outcome x in our dataset. Formally,
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/132e4dae7fd023a5a97330b388f36f9c.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
- en: Let’s assume that our dataset had only one feature and that feature followed
    a normal distribution, then we can model our anomaly detection algorithm using
    f(x) from above. We can then set some threshold epsilon which will determine if
    a case is anomalous or not. Epsilon should be set heuristically and its value
    will depend on the use case and the preferred sensitivity for anomalies.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f9ba04d873bd8758283bccee5d6dcae6.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
- en: Graph depicting Normal Distribution [[5]](https://github.com/viyaleta/Anomaly-Detection/blob/main/Examples/1%20Anomaly%20Detection%20with%20Guassian%20Distribution.ipynb)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: In a normal distribution, 2.5% of instances occur two standard deviations below
    the mean value. So if we set our threshold to 0.054, then about 2.5% of events
    in our dataset will be classified as anomalies (CDF of 2 standard deviations below
    the mean is 2.5 and PDF at -2 is 0.054). Lower thresholds will yield fewer classified
    anomalies and higher thresholds will be less sensitive.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: In real world, there is likely to be a tradeoff as some of positive cases may
    fall below the threshold and some of the anomalies may hide above the threshold.
    It will be necessary to understand the use case and test different epsilon values
    before settling on the one that is best suited.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: An example with a single feature is trivial — what do we do if we have more
    than one feature? If our features are completely independent, we can actually
    take the product of the feature probability density function in order to classify
    anomalies.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/44aa3c666d6764da479b385114e930a4.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
- en: For a two uncorrelated feature case, this becomes
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/db09df24bd5a74f1cf1babd3389893b2.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
- en: Essentially, the product of probabilities of features can ensure that if at
    least one feature has an outlier, we can detect an anomaly (given that our epsilon
    is high enough); if our instance exhibits an outlier value in several features,
    our probability will be even smaller (since our total probability value is a product
    of fractions) and a value is even more likely to be an anomaly.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: However, *we cannot assume that our features are independent*. And this is where
    a multivariate probability density function comes it. In the multivariate case,
    we build a covariance matrix (denoted by a Σ) in order to capture how the features
    are related to each other. Then, we can use the covariance matrix to avoid “double-counting”
    of feature relations (this is a very rudimentary way of phrasing what is actually
    happening). The formula for multivariate distribution probability density function
    is shown below and [these slides from Duke](https://www2.stat.duke.edu/courses/Spring12/sta104.1/Lectures/Lec22.pdf)
    do a good job and deriving the formula.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4ee3cd2aef8c7c7487f88fc87c54d509.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
- en: Here, x is an input vector, μ is a vector of feature means and Σ is a covariance
    matrix between the features.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: 'To make our life easier, we can use scipy library to implement this function:
    scipy.stats.multivariate_normal takes as input a vector of feature means and standard
    deviations and has a .pdf method for returning probability density given a set
    of points.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try this implementation on an actual example.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Two-feature Model Implementation in Python
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, let’s observe a two-feature example which will allow us to visualize
    anomalies in Eucledian space. For this example, I generated two features with
    100 samples drawn from the Normal distribution (these are the positive samples).
    I calculated feature means and standard deviations and fit a multivariate normal
    model from the scipy.stats library with the distribution information. **Of note:**
    I fit my model with positive samples only. In real-world data, we want to clean
    our dataset to ensure that the features follow normal distribution and do not
    contain outliers or odd values — this will improve models ability to locate anomalies
    (especially since it will help ensure the feature Normal distribution requirement).
    Finally, I added 5 anomalous samples to my dataset and use the .pdf method to
    report the probabilities.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: 'The following scatterplot shows the result: x1 feature is plotted on the x-axis,
    x2 feature is plotted on the y-axis, anomalies are annotated, and the color represents
    the probability from the multivariate probability density function.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c3574a946504c99dbc4d629bd0c81d95.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: Scatterplot showing positive and anomalous points [[5]](https://github.com/viyaleta/Anomaly-Detection/blob/main/Examples/1%20Anomaly%20Detection%20with%20Guassian%20Distribution.ipynb)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: Once we set our threshold *low enough*, we will be able to distinguish the anomalies
    from the expected values. Two charts below compare epsilon values between 1x10^-7
    and 1x10^-9\. Epsilon value of 1x10^-9 tends to capture our intended outliers
    better while 1x10^-7 identifies some positive samples as outliers.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cdb42a428657fe549c0caaa84b045b05.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
- en: Scatterplot comparison of identified anomalies at higher and lower epsilon [[5]](https://github.com/viyaleta/Anomaly-Detection/blob/main/Examples/1%20Anomaly%20Detection%20with%20Guassian%20Distribution.ipynb)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: In this example, it is easy to identify the epsilon because we can visually
    depict and identify anomalies and analyze our results. Let’s see how this changes
    in an example with a few more features.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: Multivariate Model Implementation with Python
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this example, I will use [the wine dataset](http://odds.cs.stonybrook.edu/wine-dataset/)
    from ODDS library [3]. This dataset contains 13 numerical features and 129 instances.
    The features capture information about the wine and the original dataset was used
    for classification tasks based on wine analysis. For the purpose of anomaly detection,
    one of the target classes was downsampled and is presented as an outlier. There
    are total of 10 anomalies among 129 instances (~8%). We are working with a fairly
    clean dataset with no missing values.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: The very first thing we must do is ensure that our features follow a Gaussian
    distribution. Where possible, we should remove outliers and normalize the distribution
    using one of normalization tactics. In this dataset, 4 features already follow
    a normal distribution (alcohol, ash, alcalinity of ash, and non-flavanoid phenols)
    and 4 features can be normalized by taking their log (total phenols, proanthocyanins,
    color intensity, and hue). While better strategies exist for the remaining features,
    for the purpose of this exercise I simply dropped them from our training dataset.
    Finally, I removed the outliers by excluding all rows that contain at least one
    feature value that is above or below 2 standard deviations from the mean. The
    remainder of the code is the same as in the example above.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Unlike the two-feature example from the section above, it is no longer feasible
    to visualize the results on a 2-dimensional plane but we can use confusion matrix
    metrics (including recall and precision) and ROC area under the curve to help
    us find the correct epsilon for the use-case.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: As there is usually a tradeoff between precision and recall, the setting of
    epsilon depends on the sensitivity requirement of our use case. For this example,
    I looked for an epsilon that maximizes the area under the curve. Some use cases
    may call for trying to find as many anomalies as possible (at the cost of including
    positive values) while other use-cases may call for only detecting anomalies if
    we are absolutely sure (at the cost of missing some anomalies from our final report).
    I calculated evaluation metrics for several different epsilon values.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/db00e59bb482f0674f681affbde78dd6.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
- en: Lineplot comparison of evaluation metrics by epsilon value [[5]](https://github.com/viyaleta/Anomaly-Detection/blob/main/Examples/1%20Anomaly%20Detection%20with%20Guassian%20Distribution.ipynb)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: As epsilon increases, recall increases. Precision is fairly low throughout the
    proposed epsilon values but tends to peak around 0.0035 and 0.0065\. The AUC attempts
    to strike the balance between precision and recall and has a peak around 0.0065\.
    Let’s take a look at the confusion matrix.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/676e53e6d1ff455b6c95918e4e6acc36.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
- en: Table depicting confusion matrix [[5]](https://github.com/viyaleta/Anomaly-Detection/blob/main/Examples/1%20Anomaly%20Detection%20with%20Guassian%20Distribution.ipynb)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: Our model does quite well at finding all of the anomalies and only misses one.
    This is a fantastic result given that I excluded a third of the features. Unfortunately,
    our model also shows 40 positive instances as anomalies which means that if we
    use the model for anomaly detection, we would have to manually check half of positive
    instances to see if they were actually anomalous.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: To improve this model we can further engineer the remaining features and find
    an epsilon values that may be a bit less sensitive to outliers. The rest of this
    problem is trivial and is left as an exercise for the reader (iykyk). You can
    find the [source code here](https://github.com/viyaleta/Anomaly-Detection/blob/main/Examples/1%20Anomaly%20Detection%20with%20Guassian%20Distribution.ipynb).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: Potential Drawbacks with Gaussian Anomaly Detection
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multivariate Gaussian distribution is a great model for anomaly detection —
    it is simple, fast, and easy to execute. However, its drawbacks can prevent its
    utilization for numerous use cases.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '**First**, multivariate distribution can produce fairly low probability density
    values. Generally, this is not a problem for modern computers. But there may be
    instances where the values are too low to be effectively handled by a computer.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '**Second**, we must ensure that our features follow a normal distribution.
    This may not be too much of an issue if time and effort is dedicated to perform
    proper feature engineering and data manipulation but putting effort is risky since
    we won’t know the payout until we do the work.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '**Third**, this model does not handle categorical features and if our dataset
    includes categorical features, we must create a separate model per each combination
    of categorical features (which can turn out to be a lot of work).'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '**Finally**, the model assumes that all features are equally relevant and there
    is no complex relationship between the features. One option to deal with this
    is to implement the multivariate distribution probability density function from
    scratch and include some parameter to help with feature importance. To resolve
    the issue with feature relationships, we could do further feature engineering
    and create new features but this process can be difficult, time-consuming, and
    risky (in terms of payout).'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Nonetheless, the use of multivariate Gaussian distribution for anomaly detection
    is a great first step for tabular anomaly detection problems. It can be used to
    set a benchmark or can prove to be a perfect tool for catching anomalies in a
    dataset and provides for us an intuitive way to understand anomaly detection.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading! In the near future I hope to do a full series on anomaly
    detection so if this topic is interesting to you, stay tuned.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: 'Sources:'
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/code/matheusfacure/semi-supervised-anomaly-detection-survey](https://www.kaggle.com/code/matheusfacure/semi-supervised-anomaly-detection-survey)'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://ai.googleblog.com/2023/02/unsupervised-and-semi-supervised.html](https://ai.googleblog.com/2023/02/unsupervised-and-semi-supervised.html)'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Saket Sathe and Charu C. Aggarwal. [LODES: Local Density meets Spectral Outlier
    Detection.](http://saketsathe.net/papers/lodes.pdf) SIAM Conference on Data Mining,
    2016.'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Nakao, T., Hanaoka, S., Nomura, Y. *et al.* Unsupervised Deep Anomaly Detection
    in Chest Radiographs. *J Digit Imaging* **34**, 418–427 (2021). [https://doi.org/10.1007/s10278-020-00413-2](https://doi.org/10.1007/s10278-020-00413-2)
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Nakao, T., Hanaoka, S., Nomura, Y. *等*。《胸部放射图中的无监督深度异常检测》。*J Digit Imaging*
    **34**，418–427（2021）。 [https://doi.org/10.1007/s10278-020-00413-2](https://doi.org/10.1007/s10278-020-00413-2)
- en: '[https://github.com/viyaleta/Anomaly-Detection/blob/main/Examples/1%20Anomaly%20Detection%20with%20Guassian%20Distribution.ipynb](https://github.com/viyaleta/Anomaly-Detection/blob/main/Examples/1%20Anomaly%20Detection%20with%20Guassian%20Distribution.ipynb)'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://github.com/viyaleta/Anomaly-Detection/blob/main/Examples/1%20Anomaly%20Detection%20with%20Guassian%20Distribution.ipynb](https://github.com/viyaleta/Anomaly-Detection/blob/main/Examples/1%20Anomaly%20Detection%20with%20Guassian%20Distribution.ipynb)'
- en: Math typesetting courtesy of [Codecogs online LaTeX editor](https://latex.codecogs.com/eqneditor/editor.php).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 数学排版由 [Codecogs 在线 LaTeX 编辑器](https://latex.codecogs.com/eqneditor/editor.php)
    提供。
- en: Jupyter Notebook with examples [can be found here](https://github.com/viyaleta/Anomaly-Detection/blob/main/Examples/1%20Anomaly%20Detection%20with%20Guassian%20Distribution.ipynb).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 带有示例的 Jupyter Notebook [可以在这里找到](https://github.com/viyaleta/Anomaly-Detection/blob/main/Examples/1%20Anomaly%20Detection%20with%20Guassian%20Distribution.ipynb)。
