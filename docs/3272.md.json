["```py\nlibrary(kernlab)\nlibrary(drf)\nlibrary(Matrix)\nlibrary(DescTools)\nlibrary(mice)\nlibrary(sobolMDA)\nsource(\"compute_drf_vimp.R\") ##Contents of this file can be found below\nsource(\"evaluation.R\") ##Contents of this file can be found below\n```", "```py\n##Simulate Data that experiences both a mean as well as sd shift\n\n# Simulate from X\nx1 <- runif(n,-1,1)\nx2 <- runif(n,-1,1)\nX0 <- matrix(runif(7*n,-1,1), nrow=n, ncol=7)\nx3 <- x1+ runif(n,-1,1)\nX <- cbind(x1,x2, x3, X0)\n\n# Simulate dependent variable Y\nY <- as.matrix(rnorm(n,mean = 0.8*(x1 > 0), sd = 1 + 1*(x2 > 0)))\ncolnames(X)<-paste0(\"X\", 1:10)\n\nhead(cbind(Y,X)) \n```", "```py\n## Variable importance for conditional Expectation Estimation\n\nXY <- as.data.frame(cbind(Xfull, Y))\ncolnames(XY) <- c(paste('X', 1:(ncol(XY)-1), sep=''), 'Y')\nnum.trees <- 500\nforest <- sobolMDA::ranger(Y ~., data = XY, num.trees = num.trees, importance = 'sobolMDA')\nsobolMDA <- forest$variable.importance\nnames(sobolMDA) <- colnames(X)\n\nsort(sobolMDA, decreasing = T)\n\n          X1           X8           X7           X6           X5           X9 \n 0.062220958  0.021946135  0.016818860  0.016777223 -0.001290326 -0.001540919 \n          X3          X10           X4           X2 \n-0.001578540 -0.007400854 -0.008299478 -0.020334150 \n```", "```py\nforest <- sobolMDA::ranger(Y ~., data = XY, num.trees = num.trees, importance = 'permutation')\nMDA <- forest$variable.importance\nnames(MDA) <- colnames(X)\n\nsort(MDA, decreasing = T)\n\n          X1           X3           X6           X7           X8           X2 \n 0.464516976  0.118147061  0.063969310  0.032741521  0.029004312 -0.004494380 \n          X4           X9          X10           X5 \n-0.009977733 -0.011030996 -0.014281844 -0.018062544 \n```", "```py\nMMDVimp <- compute_drf_vimp(X=X,Y=Y)\nsort(MMDVimp, decreasing = T)\n\n         X2          X1         X10          X6          X8          X3 \n0.683315006 0.318517259 0.014066410 0.009904518 0.006859128 0.005529749 \n         X7          X9          X4          X5 \n0.003476256 0.003290550 0.002417677 0.002036174 \n```", "```py\n# Load data (https://github.com/lorismichel/drf/blob/master/applications/wage_data/data/datasets/wage_benchmark.Rdata)\nload(\"wage_benchmark.Rdata\")\n\n##Define the training data\n\nn<-1000\n\nXtrain<-X[1:n,] \nYtrain<-Y[1:n,]\nXtrain<-cbind(Xtrain,Ytrain[,\"male\"])\ncolnames(Xtrain)[ncol(Xtrain)]<-\"male\"\nYtrain<-Ytrain[,1, drop=F]\n\n##Define the test data\nntest<-2000\nXtest<-X[(n+1):(n+ntest),]  \nYtest<-Y[(n+1):(n+ntest),]\nXtest<-cbind(Xtest,Ytest[,\"male\"])\ncolnames(Xtest)[ncol(Xtest)]<-\"male\"\nYtest<-Ytest[,1, drop=F]\n```", "```py\n# Calculate variable importance for both measures\n# 1\\. Sobol-MDA\nXY <- as.data.frame(cbind(Xtrain, Ytrain))\ncolnames(XY) <- c(paste('X', 1:(ncol(XY)-1), sep=''), 'Y')\nnum.trees <- 500\nforest <- sobolMDA::ranger(Y ~., data = XY, num.trees = num.trees, importance = 'sobolMDA')\nSobolMDA <- forest$variable.importance\nnames(SobolMDA) <- colnames(Xtrain)\n\n# 2\\. MMD-MDA\nMMDVimp <- compute_drf_vimp(X=Xtrain,Y=Ytrain,silent=T)\n\nprint(\"Top 10 most important variables for conditional Expectation estimation\")\nsort(SobolMDA, decreasing = T)[1:10]\nprint(\"Top 5 most important variables for conditional Distribution estimation\")\nsort(MMDVimp, decreasing = T)[1:10]\n```", "```py\nSobol-MDA:\n\neducation_level                   age                  male \n          0.073506769           0.027079349           0.013722756 \n        occupation_11         occupation_43           industry_54 \n          0.013550320           0.010025332           0.007744589 \n          industry_44         occupation_23         occupation_15 \n          0.006657918           0.005772662           0.004610835 \nmarital_never married \n          0.004545964 \n```", "```py\nMMD-MDA:\n\neducation_level                   age                  male \n          0.420316085           0.109212519           0.027356393 \n        occupation_43         occupation_11 marital_never married \n          0.016861954           0.014122583           0.003449910 \n        occupation_29       marital_married           industry_81 \n          0.002272629           0.002085207           0.001152210 \n          industry_72 \n          0.000984725\n```", "```py\n# Remove variables one-by-one accoring to the importance values saved in SobolMDA\n# and MMDVimp.\nevallistSobol<-evalall(SobolMDA, X=Xtrain ,Y=Ytrain ,Xtest, Ytest, metrics=c(\"MSE\"), num.trees )\nevallistMMD<-evalall(MMDVimp, X=Xtrain ,Y=Ytrain ,Xtest, Ytest, metrics=c(\"MMD\"), num.trees )\n\nplot(evallistSobol$evalMSE, type=\"l\", lwd=2, cex=0.8, col=\"darkgreen\", main=\"MSE loss\" , xlab=\"Number of Variables removed\", ylab=\"Values\")\nplot(evallistMMD$evalMMD, type=\"l\", lwd=2, cex=0.8, col=\"darkgreen\", main=\"MMD loss\" , xlab=\"Number of Variables removed\", ylab=\"Values\")\n```", "```py\n #### Contents of compute_drf_vimp.R ######\n\n#' Variable importance for Distributional Random Forests\n#'\n#' @param X Matrix with input training data.\n#' @param Y Matrix with output training data.\n#' @param X_test Matrix with input testing data. If NULL, out-of-bag estimates are used.\n#' @param num.trees Number of trees to fit DRF. Default value is 500 trees.\n#' @param silent If FALSE, print variable iteration number, otherwise nothing is print. Default is FALSE.\n#'\n#' @return The list of importance values for all input variables.\n#' @export\n#'\n#' @examples\ncompute_drf_vimp <- function(X, Y, X_test = NULL, num.trees = 500, silent = FALSE){\n\n  # fit initial DRF\n  bandwidth_Y <- drf:::medianHeuristic(Y)\n  k_Y <- rbfdot(sigma = bandwidth_Y)\n  K <- kernelMatrix(k_Y, Y, Y)\n  DRF <- drf(X, Y, num.trees = num.trees)\n  wall <- predict(DRF, X_test)$weights\n\n  # compute normalization constant\n  wbar <- colMeans(wall)\n  wall_wbar <- sweep(wall, 2, wbar, \"-\")\n  I0 <- as.numeric(sum(diag(wall_wbar %*% K %*% t(wall_wbar))))\n\n  # compute drf importance dropping variables one by one\n  I <- sapply(1:ncol(X), function(j) {\n    if (!silent){print(paste0('Running importance for variable X', j, '...'))}\n    DRFj <- drf(X = X[, -j, drop=F], Y = Y, num.trees = num.trees) \n    DRFpredj <- predict(DRFj, X_test[, -j])\n    wj <- DRFpredj$weights\n    Ij <- sum(diag((wj - wall) %*% K %*% t(wj - wall)))/I0\n    return(Ij)\n  })\n\n  # compute retraining bias\n  DRF0 <- drf(X = X, Y = Y, num.trees = num.trees)\n  DRFpred0 = predict(DRF0, X_test)\n  w0 <- DRFpred0$weights\n  vimp0 <- sum(diag((w0 - wall) %*% K %*% t(w0 - wall)))/I0\n\n  # compute final importance (remove bias & truncate negative values)\n  vimp <- sapply(I - vimp0, function(x){max(0,x)})\n\n  names(vimp)<-colnames(X)\n\n  return(vimp)\n\n} \n```", "```py\n#### Contents of evaluation.R ######\n\ncompute_mmd_loss <- function(Y_train, Y_test, weights){\n  # Y_train <- scale(Y_train)\n  # Y_test <- scale(Y_test)\n  bandwidth_Y <- (1/drf:::medianHeuristic(Y_train))^2\n  k_Y <- rbfdot(sigma = bandwidth_Y)\n  K_train <- matrix(kernelMatrix(k_Y, Y_train, Y_train), ncol = nrow(Y_train))\n  K_cross <- matrix(kernelMatrix(k_Y, Y_test, Y_train), ncol = nrow(Y_train))\n  weights <- matrix(weights, ncol = ncol(weights))\n  t1 <- diag(weights%*%K_train%*%t(weights))\n  t2 <- diag(K_cross%*%t(weights))\n  mmd_loss <- mean(t1) - 2*mean(t2)\n  mmd_loss\n}\n\nevalall <- function(Vimp, X ,Y ,Xtest, Ytest, metrics=c(\"MMD\",\"MSE\"), num.trees ){\n\n  if (ncol(Ytest) > 1 & \"MSE\" %in% metrics){\n    metrics <- metrics[!( metrics %in% \"MSE\") ]\n  }\n\n  # Sort for increasing importance, such that the least important variables are removed first\n  Vimp<-sort(Vimp)\n\n  if ( is.null(names(Vimp)) ){\n    stop(\"Need names for later\")  \n  }\n\n  evalMMD<-matrix(0, nrow=ncol(X))\n  evalMSE<-matrix(0, nrow=ncol(X))\n\n  ###Idea: Create a function that takes a variable importance measure and does this loop!!\n\n  for (j in 1:ncol(X)){\n\n    if (j==1){\n\n      if (\"MMD\" %in% metrics){\n\n        DRFred<- drf(X=X,Y=Y)\n        weights<- predict(DRFred, newdata=Xtest)$weights\n        evalMMD[j]<-compute_mmd_loss(Y_train=Y, Y_test=Ytest, weights)\n\n      }\n\n      if (\"MSE\" %in% metrics){\n\n        XY <- as.data.frame(cbind(X, Y))\n        colnames(XY) <- c(paste('X', 1:(ncol(XY)-1), sep=''), 'Y')\n        RFfull <- sobolMDA::ranger(Y ~., data = XY, num.trees = num.trees)\n        XtestRF<-Xtest\n        colnames(XtestRF) <- paste('X', 1:ncol(XtestRF), sep='')\n        predRF<-predict(RFfull, data=XtestRF)\n        evalMSE[j] <- mean((Ytest - predRF$predictions)^2)\n\n      }\n\n    }else{\n\n      if (\"MMD\" %in% metrics){\n\n        DRFred<- drf(X=X[,!(colnames(X) %in% names(Vimp[1:(j-1)])), drop=F],Y=Y)\n        weights<- predict(DRFred, newdata=Xtest[,!(colnames(Xtest) %in% names(Vimp[1:(j-1)])), drop=F])$weights\n        evalMMD[j]<-compute_mmd_loss(Y_train=Y, Y_test=Ytest, weights)\n\n      }\n\n      if (\"MSE\" %in% metrics){\n\n        XY <- as.data.frame(cbind(X[,!(colnames(X) %in% names(Vimp[1:(j-1)])), drop=F], Y))\n        colnames(XY) <- c(paste('X', 1:(ncol(XY)-1), sep=''), 'Y')\n        RFfull <- sobolMDA::ranger(Y ~., data = XY, num.trees = num.trees)\n        XtestRF<-Xtest[,!(colnames(Xtest) %in% names(Vimp[1:(j-1)])), drop=F]\n        colnames(XtestRF) <- paste('X', 1:ncol(XtestRF), sep='')\n        predRF<-predict(RFfull, data=XtestRF)\n        evalMSE[j] <- mean((Ytest - predRF$predictions)^2)\n\n        # DRFall <- drf(X=X[,!(colnames(X) %in% names(Vimp[1:(j-1)])), drop=F], Y=Y, num.trees=num.trees)\n        # quantpredictall<-predict(DRFall, newdata=Xtest[,!(colnames(Xtest) %in% names(Vimp[1:(j-1)])), drop=F], functional=\"quantile\",quantiles=c(0.5))\n        # evalMAD[j] <- mean(sapply(1:nrow(Xtest), function(j)  abs(Ytest[j] - quantpredictall$quantile[,,\"q=0.5\"][j]) ))\n      }\n\n    }\n\n  }\n\n  return(list(Vimp=Vimp, evalMMD=evalMMD, evalMSE=evalMSE ))\n\n} \n```"]