["```py\nimport arviz as az\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pymc as pm\nfrom arviz.labels import MapLabeller\n\nfrom IPython.display import Image\nfrom pymc_marketing import clv\n```", "```py\nimport requests\nimport zipfile\nimport os\n\n# Download the zip file\nurl = \"https://archive.ics.uci.edu/static/public/352/online+retail.zip\"\nresponse = requests.get(url)\nfilename = \"online_retail.zip\"\n\nwith open(filename, 'wb') as file:\n    file.write(response.content)\n\n# Unzip the file\nwith zipfile.ZipFile(filename, 'r') as zip_ref:\n    zip_ref.extractall(\"online_retail_data\")\n\n# Finding the Excel file name\nfor file in os.listdir(\"online_retail_data\"):\n    if file.endswith(\".xlsx\"):\n        excel_file = os.path.join(\"online_retail_data\", file)\n        break\n\n# Convert from Excel to CSV\ndata_raw = pd.read_excel(excel_file)\n\ndata_raw.head()\n```", "```py\n# Handling Return Orders\n# Extracting rows where InvoiceNo starts with \"C\"\ncancelled_orders = data_raw[data_raw['InvoiceNo'].astype(str).str.startswith(\"C\")]\n\n# Create a temporary DataFrame with the columns we want to match on, and also negate the 'Quantity' column\ncancelled_orders['Quantity'] = -cancelled_orders['Quantity']\n\n# Merge the original DataFrame with the temporary DataFrame on the columns we want to match\nmerged_data = pd.merge(data_raw, cancelled_orders[['CustomerID', 'StockCode', 'Quantity', 'UnitPrice']], \n                       on=['CustomerID', 'StockCode', 'Quantity', 'UnitPrice'], \n                       how='left', indicator=True)\n\n# Filter out rows where the merge found a match, and also filter out the original return orders\ndata_raw = merged_data[(merged_data['_merge'] == 'left_only') & (~merged_data['InvoiceNo'].astype(str).str.startswith(\"C\"))]\n\n# Drop the indicator column\ndata_raw = data_raw.drop(columns=['_merge'])\n\n# Selecting relevant features and calculating total sales\nfeatures = ['CustomerID', 'InvoiceNo', 'InvoiceDate', 'Quantity', 'UnitPrice', 'Country']\ndata = data_raw[features]\ndata['TotalSales'] = data['Quantity'].multiply(data['UnitPrice'])\n\n# Removing transactions with missing customer IDs as they don't contribute to individual customer behavior\ndata = data[data['CustomerID'].notna()]\ndata['CustomerID'] = data['CustomerID'].astype(int).astype(str)\ndata.head()\n```", "```py\ndata_summary_rfm = clv.utils.clv_summary(data, 'CustomerID', 'InvoiceDate', 'TotalSales')\ndata_summary_rfm = data_summary_rfm.rename(columns={'CustomerID': 'customer_id'})\ndata_summary_rfm.index = data_summary_rfm['customer_id']\ndata_summary_rfm.head()\n```", "```py\nbgm = clv.BetaGeoModel(\n    data = data_summary_rfm,\n)\nbgm.build_model()\n\nbgm.fit()\nbgm.fit_summary()\n```", "```py\nclv.plot_probability_alive_matrix(bgm);\n```", "```py\nnum_purchases = bgm.expected_num_purchases(\n    customer_id=data_summary_rfm[\"customer_id\"],\n    t=365,\n    frequency=data_summary_rfm[\"frequency\"],\n    recency=data_summary_rfm[\"recency\"],\n    T=data_summary_rfm[\"T\"]\n)\n\nsdata = data_summary_rfm.copy()\nsdata[\"expected_purchases\"] = num_purchases.mean((\"chain\", \"draw\")).values\nsdata.sort_values(by=\"expected_purchases\").tail(4)\n```", "```py\nnonzero_data = data_summary_rfm.query(\"frequency>0\")\ndataset = pd.DataFrame({\n    'customer_id': nonzero_data.customer_id,\n    'mean_transaction_value': nonzero_data[\"monetary_value\"],\n    'frequency': nonzero_data[\"frequency\"],\n})\ngg = clv.GammaGammaModel(\n    data = dataset\n)\ngg.build_model()\ngg.fit();\n\nexpected_spend = gg.expected_customer_spend(\n    customer_id=data_summary_rfm[\"customer_id\"],\n    mean_transaction_value=data_summary_rfm[\"monetary_value\"],\n    frequency=data_summary_rfm[\"frequency\"],\n)\n```", "```py\nlabeller = MapLabeller(var_name_map={\"x\": \"customer\"})\naz.plot_forest(expected_spend.isel(customer_id=(range(5))), combined=True, labeller=labeller)\nplt.xlabel(\"Expected average order value\");\n```", "```py\nclv_estimate = gg.expected_customer_lifetime_value(\n    transaction_model=bgm,\n    customer_id=data_summary_rfm['customer_id'],\n    mean_transaction_value=data_summary_rfm[\"monetary_value\"],\n    frequency=data_summary_rfm[\"frequency\"],\n    recency=data_summary_rfm[\"recency\"],\n    T=data_summary_rfm[\"T\"],\n    time=120, # 120 months = 10 years\n    discount_rate=0.01,\n    freq=\"D\",\n)\n\nclv_df = az.summary(clv_estimate, kind=\"stats\").reset_index()\n\nclv_df['customer_id'] = clv_df['index'].str.extract('(\\d+)')[0]\n\nclv_df = clv_df[['customer_id', 'mean', 'hdi_3%', 'hdi_97%']]\nclv_df.rename(columns={'mean' : 'clv_estimate', 'hdi_3%': 'clv_estimate_hdi_3%', 'hdi_97%': 'clv_estimate_hdi_97%'}, inplace=True)\n\n# monetary_values = data_summary_rfm.loc[clv_df['customer_id'], 'monetary_value']\nmonetary_values = data_summary_rfm.set_index('customer_id').loc[clv_df['customer_id'], 'monetary_value']\nclv_df['monetary_value'] = monetary_values.values\nclv_df.to_csv('clv_estimates_output.csv', index=False)\n```", "```py\n# Calculating total sales per transaction\ndata['TotalSales'] = data['Quantity'] * data['UnitPrice']\ncustomer_sales = data.groupby('CustomerID').agg({\n    'TotalSales': sum,\n    'Country': 'first'  # Assuming a customer is associated with only one country\n})\n\ncustomer_countries = customer_sales.reset_index()[['CustomerID', 'Country']]\n\nclv_with_country = pd.merge(clv_df, customer_countries, left_on='customer_id', right_on='CustomerID', how='left')\n\naverage_clv_by_country = clv_with_country.groupby('Country')['clv_estimate'].mean()\n\ncustomer_count_by_country = data.groupby('Country')['CustomerID'].nunique()\n\ncountry_clv_summary = pd.DataFrame({\n    'AverageCLV': average_clv_by_country,\n    'CustomerCount': customer_count_by_country,\n})\n# Calculate the average lower and upper bounds of the CLV estimates by country\naverage_clv_lower_by_country = clv_with_country.groupby('Country')['clv_estimate_hdi_3%'].mean()\naverage_clv_upper_by_country = clv_with_country.groupby('Country')['clv_estimate_hdi_97%'].mean()\n\n# Add these averages to the country_clv_summary dataframe\ncountry_clv_summary['AverageCLVLower'] = average_clv_lower_by_country\ncountry_clv_summary['AverageCLVUpper'] = average_clv_upper_by_country\n\n# Filtering countries with more than 20 customers\nfiltered_countries = country_clv_summary[country_clv_summary['CustomerCount'] >= 20]\n\n# Sorting in descending order by CustomerCount\nsorted_countries = filtered_countries.sort_values(by='AverageCLV', ascending=False)\n\n# Prepare the data for error bars\nlower_error = sorted_countries['AverageCLV'] - sorted_countries['AverageCLVLower']\nupper_error = sorted_countries['AverageCLVUpper'] - sorted_countries['AverageCLV']\nasymmetric_error = [lower_error, upper_error]\n\n# Create a new figure with a specified size\nplt.figure(figsize=(12,8))\n\n# Create a plot representing the average CLV with error bars indicating the confidence intervals\n# We convert the index to a regular list to avoid issues with matplotlib's handling of pandas Index objects\nplt.errorbar(x=sorted_countries['AverageCLV'], y=sorted_countries.index.tolist(), \n             xerr=asymmetric_error, fmt='o', color='black', ecolor='lightgray', capsize=5, markeredgewidth=2)\n\n# Set labels and title\nplt.xlabel('Average CLV')  # x-axis label\nplt.ylabel('Country')  # y-axis label\nplt.title('Average Customer Lifetime Value (CLV) by Country with Confidence Intervals')  # chart title\n\n# Adjust the y-axis to display countries from top down\nplt.gca().invert_yaxis()\n\n# Show the grid lines\nplt.grid(True, linestyle='--', alpha=0.7)\n\n# Display the plot\nplt.show()\n```"]