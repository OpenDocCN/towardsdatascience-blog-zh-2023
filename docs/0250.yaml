- en: Clear, Visual Explanation of K-Means for Image Compression with GIFs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/clear-and-visual-explanation-of-the-k-means-algorithm-applied-to-image-compression-b7fdc547e410?source=collection_archive---------8-----------------------#2023-01-16](https://towardsdatascience.com/clear-and-visual-explanation-of-the-k-means-algorithm-applied-to-image-compression-b7fdc547e410?source=collection_archive---------8-----------------------#2023-01-16)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@sebastian.charmot?source=post_page-----b7fdc547e410--------------------------------)[![Sebastian
    Charmot](../Images/c848c48d186b536c83e34e3a06332e8c.png)](https://medium.com/@sebastian.charmot?source=post_page-----b7fdc547e410--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b7fdc547e410--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b7fdc547e410--------------------------------)
    [Sebastian Charmot](https://medium.com/@sebastian.charmot?source=post_page-----b7fdc547e410--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8d18b9c9ebb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclear-and-visual-explanation-of-the-k-means-algorithm-applied-to-image-compression-b7fdc547e410&user=Sebastian+Charmot&userId=8d18b9c9ebb&source=post_page-8d18b9c9ebb----b7fdc547e410---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b7fdc547e410--------------------------------)
    ·11 min read·Jan 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb7fdc547e410&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclear-and-visual-explanation-of-the-k-means-algorithm-applied-to-image-compression-b7fdc547e410&user=Sebastian+Charmot&userId=8d18b9c9ebb&source=-----b7fdc547e410---------------------clap_footer-----------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb7fdc547e410&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclear-and-visual-explanation-of-the-k-means-algorithm-applied-to-image-compression-b7fdc547e410&source=-----b7fdc547e410---------------------bookmark_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: How K-Means can be used to significantly reduce the file size of an image.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: In this guide, I describe and implement the k-means algorithm from scratch and
    apply it to image compression. I use different visualizations to help the reader
    develop a stronger understanding of the k-means algorithm and how it can be used
    for image compression. I also discuss various advantages and limitations of this
    approach towards the end.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: All images unless otherwise noted are by the author, available [here](https://www.sebastiancharmot.com/).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eb4a8971c44c824c68e531b2b3d3a2f1.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
- en: Using K-means to compress the original image on the left by a factor of 6
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4a8d4863efed1d27cfda9ddad80ef5b7.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
- en: How the k-means algorithm iteratively creates the compressed image
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: What is the K-Means Algorithm?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The k-means algorithm is an *unsupervised* algorithm that *partitions* a dataset
    into *k* distinct clusters. It is unsupervised, meaning there are no labels for
    the data points. In other words, we don’t have prior knowledge of how the dataset
    should be clustered. We simply provide the dataset as is, and use k-means to partition
    it into *k* clusters.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Big Picture Idea
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: K-means seeks to divide a dataset into k clusters where members of each cluster
    share characteristics and are different from other clusters. Therefore, the goal
    is for k-means to divide the dataset *meaningfully* into k different clusters.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Applications
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cluster analysis groups similar data together by abstracting the underlying
    structure of a dataset, which can provide meaningful insight. “Clustering has
    been effectively applied in a variety of engineering and scientific disciplines
    such as psychology, biology, medicine, computer vision, communications, and remote
    sensing” [[1](https://www.researchgate.net/profile/M-Murty-3/publication/5600582_Genetic_K-Means_Algorithm/links/541aaa280cf25ebee988b52d/Genetic-K-Means-Algorithm.pdf)].
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: How the K-Means Algorithm Works
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The K-means algorithm is broken into several steps:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Initializing a set of cluster centroids
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assigning observations to clusters
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Updating the clusters
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Steps 2 and 3 are repeated for either a set number of iterations or until convergence,
    which occurs when the cluster centroids no longer change.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Let us dive deeper into each of these steps.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Initializing the set of cluster centroids
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first step to initializing the set of cluster centroids is choosing how
    many centroids we want to use, which we refer to as *k*.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Once, we have chosen the number of clusters, we choose *k* samples randomly
    from the training examples, and set the cluster centroids to be equal to the values
    of the selected *k* examples. Alternatively, we can randomly sample *k* different
    points in the solution space to initialize the cluster centroids.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: We refer to the *j*-th centroid as μⱼ, because it represents the mean of the
    values assigned to cluster *j*. This is where the name k-means arises from. In
    the figure below, we set *k*=3 and randomly sample 3 points in the sample space
    (represented by green, blue, and red ‘x’) to initialize the cluster centroids.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8e3b17968729d91228e949780d813930.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
- en: On the left, the data is shown on a scatter-plot. On the right, we add the 3
    initial cluster centroids denoted in green, blue, and red ‘x’
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Assigning Observations to Clusters
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have our *k* centroids, we assign each observation (data point)
    to the centroid closest to it. Typically, we calculate “closeness” using the euclidean
    distance. In the figure below, we illustrate the process of assigning the observations
    to the 3 centroids above.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/72fb7317b23deed421ebf31cee0adbe4.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
- en: On the left, we show the 3 initial centroids. On the right, we see assign observations
    to the nearest centroid.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Updating the Centroids
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once all of the observations have been assigned to a cluster, we shift the centroid
    of each cluster to the mean of its assigned observations. We illustrate this process
    below.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0bdbb48c250b2b9218762b42f1fa7d16.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: On the left, we assign observations to clusters. On the right, we update the
    cluster centroids to the mean of the assigned observations. Notice how the centroids
    shift.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Repeat till convergence or for a certain number of iterations
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Each iteration of the k-means algorithm consists of two parts: Step 2 (Assigning
    Observations to Clusters) and Step 3 (Updating the Clusters). This process is
    repeated for either a set number of iterations or until convergence. Convergence
    occurs when the cluster centroids no longer change. This is equivalent to saying
    that the assignments of the observations do not change anymore.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: The *k* means algorithm will always converge within a finite number of iterations
    [[2](https://stats.stackexchange.com/questions/188087/proof-of-convergence-of-k-means)]
    but it is susceptible to local minima [[3](https://cs229.stanford.edu/notes2022fall/main_notes.pdf)].
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: In the example below, the *k* means algorithm converges at iteration 4\. This
    is because the cluster centroids no longer change after iteration 4.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c0ff935f399427c39ccf6b402a3fa913.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: K-means iterating until convergence
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: K-Means for Image Compression
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The goal of image compression is to reduce the file size of an image. We can
    use K-means to select *k* colors to represent an entire image. This allows us
    to represent an image using only *k* colors, instead of the entire RGB space.
    This process is also referred to as *image quantization*.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Why K-means is useful for image compression
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The purpose of using k-means for image compression is to select *k* colors to
    represent a target image with the least approximation error. In other words, we
    will be using k-means to find the **best** *k* colors to represent a target image
    with.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: How K-means provides compression
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The color pixels in an image are represented by their RGB values, which each
    range from 0 to 255\. Since each color band has 256=2⁸ settings, there are a total
    of 256 **⋅** 256 **⋅** 256 = 256³ = 2²⁴ ~ 17 million colors. To represent each
    of these colors for any pixel, computers need log₂(2²⁴) = 24 bits of storage space.
    If we use K-means to select 16 colors that we represent an entire image with,
    we only need log₂(16) = 4 bits. Therefore, by using K-means with *k*=16, we can
    compress the image size by a factor of 6!
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand the theory, let us dive into some code and visualizations.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4a8d4863efed1d27cfda9ddad80ef5b7.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
- en: How the centroids and resultant compressed image change as the number of iterations
    increases
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: Reading in the Image and Initializing the Centroids
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the context of image compression, the centroids are the colors we are using
    to represent the compressed image. Therefore, our first step is to read in the
    image and select *k* random colors from the image to initialize our centroids.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: In line 7, we read in the image using numpy. This produces a 2 dimensional array
    where each element is a list of length 3 that represents the RGB values of that
    pixel. Remember to modify `image_path` to your own.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Starting on line 9, we define the function to initialize our centroids. We select
    a random pixel from the image and add its corresponding RGB value to the `centroids_init`
    array. We do this *k =* `num_clusters` times. Thus, `centroids_init` is an array
    of *k* colors sampled randomly from our image.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: Assigning and Updating Centroids
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To iteratively update our centroids, we repeat the process of assigning observations
    to cluster centroids and updating the centroids to be the mean of the assigned
    observations.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: In the context of image compression, this means assigning each pixel of the
    target image to the centroid color that is nearest to it.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: In lines 11–17, we are creating the dictionary `centroid_rgbs` . Each key corresponds
    to an index of the centroids and the values are a single numpy array that contain
    all of the colors assigned to the corresponding centroid.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: The assignment of each pixel to a centroid is done on line 13 using `linalg.norm`to
    calculate the euclidean distance to each centroid and then using `argmin`to find
    the index of the nearest centroid.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Creating the Compressed Image
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have the finalized centroids, we can create the compressed image.
    We simply iterate through each pixel and change its color to the nearest centroid.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: Putting Everything Together
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the following snippet and the function definitions above, all the pieces
    to running k-means for image compression are complete.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: To generate the GIF’s, I used `plt.savefig` at various stages of the algorithm.
    My github repository contains the code for that process, and how to convert those
    frames to a GIF [[4](https://github.com/SebastianCharmot/kmeans_image_compression)].
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0eda8ce59d0ce400d13f7813feba0ac3.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
- en: Progression of k=64 on an image of a cuttelfish.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: In the GIF above, we see how the centroids, which are the colors we choose to
    represent the image, change over time as the k-means algorithm iterates.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: Analysis of K-Means for Image Compression
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, we analyze some details regarding the use of k-means for image compression.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Outliers
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Often, images will contain outlier colors relative to the main color palette
    of the image. For example, the target image below contains two small clown-fish
    that are bright orange. Their color contrasts strongly from the dark background
    and sea anemone, which draws the viewers attention to them (hopefully in an aesthetically
    pleasing way).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e81c4a1c2e10e75d58418ac0149e9ca7.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
- en: My original image is on the left. The image on the right is compressed using
    k-means where *k*=16
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: The GIF below illustrates what happens when we apply k-means to this image for
    *k*=16\. Although the clown-fish’s bright orange is selected as an initial cluster,
    it is eventually ‘washed out’ by the darker colors as the algorithm iterates.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6a188e4b1d530eca5ef332d709d9a4e3.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
- en: K-means iterating over the picture of the sea anemone. Notice how the bright
    orange is lost over time.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Although the overall quality of the compressed image increases as the number
    of iterations increases, the accuracy of the outlier color decreases.
  id: totrans-82
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Some literature suggests creating clusters specifically for outliers (calculated
    using a distance metric) to improve overall clustering accuracy [[5](https://www2.math.uconn.edu/~gan/ggpaper/gan2017kmor.pdf)].
    The authors’ use of numerical experiments on both synthetic data and real data
    are provided to demonstrate the effectiveness and efficiency of their proposed
    algorithm. I suspect that implementing this algorithm could help with image compression
    using k-means, especially with images that contain outlier colors.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Selecting “*k”*
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The choice of *k* determines the amount of compression, and is up to the user
    to set. A higher value of *k* will provide for a more faithful representation
    of the target image, but comes at the cost of lower compression. In the graphic
    below, we illustrate compressed images with increasing values of *k*. The compression
    factors for *k*=16, *k*=32, *k*=64, and *k*=128 are **6**, **4.8**, **4**, and
    **3.4** respectively.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6564a7b2dd9de3b720be80bd9827265d.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
- en: Compressed images for k=16, 32, 64, and 128
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: In the example above, we see that choosing a *k* value greater than 32 is critical
    in mitigating the outlier issue mentioned in the previous section. Since k is
    large enough, at least one centroid is able to be assigned to the bright orange
    color. In the figure below, we plot the centroid colors after 30 iterations for
    both k=64 and k=256.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/12b366855481307378f49784f06dd806.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
- en: Centroids for k=64 and k=256 after 30 iterations
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: After 30 iterations, *k*=64 has one centroid that is assigned to orange. For
    *k*=256, there are approximately 4 shades of orange.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: This visualization also portrays the compression amount vs. detail trade-off
    for different k-values. Clearly for larger values of k, we have more colors and
    retention of detail, however we require more data to represent those colors.
  id: totrans-92
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It is likely worth experimenting with different values of *k* depending on the
    target image and use case.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Lossy Compression
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using the k-means algorithm to compress an image is a form of *lossy compresion*.
    Lossy compression is a class of data compression that uses approximations and
    partial data loss of a target image [[6](https://www.khanacademy.org/computing/computers-and-internet/xcae6f4a7ff015e7d:digital-information/xcae6f4a7ff015e7d:data-compression/a/lossy-compression)].
    When we use k-means for image compression, we are approximating each pixel’s color
    using the nearest centroid. Since we are losing information in this process, we
    cannot revert the compressed image back to the original. This is why lossy compression
    is also refered to as *irreversible compression*.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, lossless data compression does not lose information. Instead,
    it uses techniques to represent the original information using less data [[7](https://ieeexplore.ieee.org/abstract/document/1594297)].
    However, the amount of compression that is possible using lossless data compression
    is much lower than that of lossy compression.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Although k-means is a form of lossy compression, the loss of detail can be almost
    in-perceivable to the human eye for certain values of *k*.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a1747ee458e6e2d72db6f8b3d0a402f4.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
- en: Target image on left and compressed image on right using k=256
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Can you notice many differences between the two images above? Using *k*=256,
    the compressed image on the right requires only 1/3 the amount of data compared
    to the full image on the right!
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: Randomness in Centroid Initialization
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Holding everything in regards to k-means constant, each run will differ slightly
    as a result of the randomness inherent in the centroid initialization process.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e414737c395a110e1f65221ad82c8551.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
- en: Notice the slight variations in the compressed images for 3 separate runs of
    k=16
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: This means that the compressed images given the same parameters will output
    slightly different variations. However, for larger values of k, this effect is
    not as apparent to the human eye.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9ec819a4610d939fa74cb6866e1348bb.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
- en: The differences in the compressed images for 3 separate runs of k=1256 are almost
    indistribguishable
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and Disadvantages
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have completed a thorough analysis of the k-means algorithm in regards
    to image compression, we will explicitly discuss its advantages and disadvantages.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Advantages
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Efficiency: The k-means algorithm is computationally efficient (linear time
    complexity), making it suitable for real-time image compression applications [[8](https://ieeexplore.ieee.org/document/8101601)].
    This also means it can handle large images.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Simplicity: The k-means algorithm is relatively simple and easy to understand.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Great for certain types of images: k-means performs well on images with distinct
    clusters of similar colors.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disadvantages
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Lossy Compression Algorithm: K-means is a form of lossy compression that represents
    an entire image based on clusters of pixels, therefore it loses some color information
    and may not preserve fine details in an image.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sensitivity to initialization: The performance of the k-means algorithm can
    be sensitive to the initial positions of the centroids, which can lead to sub-optimal
    or inconsistent results. This is less of a problem with larger values of *k*.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Not suitable for certain types of images: k-means algorithm perform poorly
    on images with smooth color gradients and images with high noise.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Overall, k-means can be a good choice for lossy image compression, especially
    for images with distinct clusters of similar colors. However, it may not be the
    best choice for all types of images and other techniques such as vector quantization
    or fractal compression may produce better results.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: The user has a critical decision to make when selecting the value of *k*, and
    must keep in mind the ‘compression amount vs. detail trade-off’ discussed in the
    “Selecting ‘k’” section. The optimal k value will likely vary according to the
    user’s needs.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully the different visualizations were able to help develop a stronger
    understanding of the k-means algorithm, and how it can perform image compression.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Krishna, K., and M. Narasimha Murty. “Genetic K-Means Algorithm.” *IEEE
    Transactions on Systems, Man and Cybernetics, Part B (Cybernetics)*, vol. 29,
    no. 3, 1999, pp. 433–439., [https://doi.org/10.1109/3477.764879.](https://doi.org/10.1109/3477.764879.)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[2] [https://stats.stackexchange.com/questions/188087/proof-of-convergence-of-k-means](https://stats.stackexchange.com/questions/188087/proof-of-convergence-of-k-means)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '[3] Ng, Andrew. “CS229 Lecture Notes.” [https://cs229.stanford.edu/notes2022fall/main_notes.pdf](https://cs229.stanford.edu/notes2022fall/main_notes.pdf)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[4] My Github Repository with the code for this project. [https://github.com/SebastianCharmot/kmeans_image_compression](https://github.com/SebastianCharmot/kmeans_image_compression)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '[5] Gan, Guojun, and Michael Kwok-Po Ng. “K -Means Clustering with Outlier
    Removal.” *Pattern Recognition Letters*, vol. 90, 2017, pp. 8–14., [https://doi.org/10.1016/j.patrec.2017.03.008.](https://doi.org/10.1016/j.patrec.2017.03.008.)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '[6] “Lossy Compression (Article).” *Khan Academy*, Khan Academy, [https://www.khanacademy.org/computing/computers-and-internet/xcae6f4a7ff015e7d:digital-information/xcae6f4a7ff015e7d:data-compression/a/lossy-compression.](https://www.khanacademy.org/computing/computers-and-internet/xcae6f4a7ff015e7d:digital-information/xcae6f4a7ff015e7d:data-compression/a/lossy-compression.)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[7] Ming Yang, and N. Bourbakis. “An Overview of Lossless Digital Image Compression
    Techniques.” *48th Midwest Symposium on Circuits and Systems, 2005.*, 2005, [https://doi.org/10.1109/mwscas.2005.1594297.](https://doi.org/10.1109/mwscas.2005.1594297.)'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '[8] Chiou, Paul T., et al. “A Complexity Analysis of the JPEG Image Compression
    Algorithm.” *2017 9th Computer Science and Electronic Engineering (CEEC)*, 2017,
    [https://doi.org/10.1109/ceec.2017.8101601.](https://doi.org/10.1109/ceec.2017.8101601.)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] Chiou, Paul T., 等. “JPEG图像压缩算法的复杂性分析。” *2017年第九届计算机科学与电子工程会议 (CEEC)*, 2017,
    [https://doi.org/10.1109/ceec.2017.8101601.](https://doi.org/10.1109/ceec.2017.8101601.)'
