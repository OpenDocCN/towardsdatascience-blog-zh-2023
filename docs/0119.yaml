- en: Stereo Vision System for 3D Tracking
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3D跟踪的立体视觉系统
- en: 原文：[https://towardsdatascience.com/stereo-vision-system-for-3d-tracking-ce8eaca3a40a?source=collection_archive---------1-----------------------#2023-01-08](https://towardsdatascience.com/stereo-vision-system-for-3d-tracking-ce8eaca3a40a?source=collection_archive---------1-----------------------#2023-01-08)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/stereo-vision-system-for-3d-tracking-ce8eaca3a40a?source=collection_archive---------1-----------------------#2023-01-08](https://towardsdatascience.com/stereo-vision-system-for-3d-tracking-ce8eaca3a40a?source=collection_archive---------1-----------------------#2023-01-08)
- en: Two eyes are all you need
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你只需要两只眼睛
- en: '[](https://sebastiengilbert.medium.com/?source=post_page-----ce8eaca3a40a--------------------------------)[![Sébastien
    Gilbert](../Images/380f6588c3ef718947bcf82061f190eb.png)](https://sebastiengilbert.medium.com/?source=post_page-----ce8eaca3a40a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ce8eaca3a40a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ce8eaca3a40a--------------------------------)
    [Sébastien Gilbert](https://sebastiengilbert.medium.com/?source=post_page-----ce8eaca3a40a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://sebastiengilbert.medium.com/?source=post_page-----ce8eaca3a40a--------------------------------)[![Sébastien
    Gilbert](../Images/380f6588c3ef718947bcf82061f190eb.png)](https://sebastiengilbert.medium.com/?source=post_page-----ce8eaca3a40a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ce8eaca3a40a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ce8eaca3a40a--------------------------------)
    [Sébastien Gilbert](https://sebastiengilbert.medium.com/?source=post_page-----ce8eaca3a40a--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F975aef8c496a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstereo-vision-system-for-3d-tracking-ce8eaca3a40a&user=S%C3%A9bastien+Gilbert&userId=975aef8c496a&source=post_page-975aef8c496a----ce8eaca3a40a---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ce8eaca3a40a--------------------------------)
    ·6 min read·Jan 8, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fce8eaca3a40a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstereo-vision-system-for-3d-tracking-ce8eaca3a40a&user=S%C3%A9bastien+Gilbert&userId=975aef8c496a&source=-----ce8eaca3a40a---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F975aef8c496a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstereo-vision-system-for-3d-tracking-ce8eaca3a40a&user=S%C3%A9bastien+Gilbert&userId=975aef8c496a&source=post_page-975aef8c496a----ce8eaca3a40a---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ce8eaca3a40a--------------------------------)
    ·6分钟阅读·2023年1月8日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fce8eaca3a40a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstereo-vision-system-for-3d-tracking-ce8eaca3a40a&user=S%C3%A9bastien+Gilbert&userId=975aef8c496a&source=-----ce8eaca3a40a---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fce8eaca3a40a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstereo-vision-system-for-3d-tracking-ce8eaca3a40a&source=-----ce8eaca3a40a---------------------bookmark_footer-----------)![](../Images/729c84682441f3dacaf348fbf88094b2.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fce8eaca3a40a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstereo-vision-system-for-3d-tracking-ce8eaca3a40a&source=-----ce8eaca3a40a---------------------bookmark_footer-----------)![](../Images/729c84682441f3dacaf348fbf88094b2.png)'
- en: Photo by [Adriano Pinto](https://unsplash.com/@adrianopintofotografia?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Adriano Pinto](https://unsplash.com/@adrianopintofotografia?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Like the vast majority of sighted animals on this planet, we have two eyes.
    This marvelous feature of our evolution allows us to see the environment in three
    dimensions.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 就像地球上绝大多数有视力的动物一样，我们有两只眼睛。我们进化中的这一奇妙特性使我们能够以三维的方式看待环境。
- en: To obtain 3D information from a scene, we can mimic binocular vision with at
    least two cameras working together. Such a setup is called a *stereo vision system*.
    When properly calibrated, each camera supplies a constraint on the 3D coordinates
    of a given feature point. With at least two calibrated cameras, it is possible
    to calculate the 3D coordinates of the feature point.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要从场景中获取3D信息，我们可以通过至少两台相机协同工作来模拟双眼视觉。这种设置被称为*立体视觉系统*。当相机经过正确校准后，每台相机都会对特定特征点的3D坐标提供约束。通过至少两台经过校准的相机，可以计算特征点的3D坐标。
- en: In this article, we’ll calibrate a pair of cameras, and use this calibration
    to compute the 3D coordinates of a feature point tracked in a series of images.
    You can find the corresponding code [in this repository](https://github.com/sebastiengilbert73/tutorial_calibrate_stereo_vision).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将校准一对相机，并使用此校准来计算在一系列图像中跟踪的特征点的3D坐标。你可以在[这个仓库](https://github.com/sebastiengilbert73/tutorial_calibrate_stereo_vision)找到相应的代码。
- en: Stereo Vision System
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 立体视觉系统
- en: 'Figure 1 shows the stereo vision system that I have been using. As you can
    see, nothing fancy: a pair of webcams, rigidly held together with 3D printed parts,
    tie wraps, and hot glue.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图1显示了我使用的立体视觉系统。如你所见，没有什么花哨的：一对通过3D打印部件、绑带和热熔胶固定在一起的网络摄像头。
- en: '![](../Images/4b1399212d3f0a0942471c8ec2d90d44.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b1399212d3f0a0942471c8ec2d90d44.png)'
- en: 'Figure 1: The stereo vision system. Image by the author.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：立体视觉系统。作者提供的图像。
- en: It just happened that I had two webcams of the same model lying around in a
    drawer, but it is not necessary to have identical cameras. Since the cameras get
    calibrated independently, they can have different intrinsic parameters and still
    play their role in a stereo vision system.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 正好我有两台相同型号的网络摄像头闲置在抽屉里，但并不一定需要完全相同的相机。由于相机是独立校准的，它们可以具有不同的内在参数，并且仍然在立体视觉系统中发挥作用。
- en: Calibration of the Cameras
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相机的校准
- en: The Projection Matrix
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 投影矩阵
- en: The calibration of the cameras boils down to computing their *projection matrix*.
    The projection matrix of a pinhole camera model is a 3x4 matrix that allows one
    to calculate the pixel coordinates of a feature point from its 3D coordinates
    in a world reference frame.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 相机的校准归结为计算它们的*投影矩阵*。针孔相机模型的投影矩阵是一个3x4矩阵，它允许从世界参考框架中的3D坐标计算特征点的像素坐标。
- en: '![](../Images/585d80834287ff068b7fcf88e8bf8f85.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/585d80834287ff068b7fcf88e8bf8f85.png)'
- en: In equation (1), *i* refers to the camera index. In a system of two cameras,
    *i* belongs to {1, 2}.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在公式(1)中，*i* 指代相机索引。在一个由两台相机组成的系统中，*i* 属于{1, 2}。
- en: Pᵢ is the 3x4 projection matrix of camera *i*.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Pᵢ 是相机 *i* 的3x4投影矩阵。
- en: (uᵢ, vᵢ) are the pixel coordinates of the feature point, as seen from camera
    *i*. (X, Y, Z) are the feature point 3D coordinates.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: (uᵢ, vᵢ) 是特征点的像素坐标，从相机 *i* 看到的情况。 (X, Y, Z) 是特征点的3D坐标。
- en: The scalar λᵢ is the scaling factor that preserves the equation homogeneity
    (i.e. the last element of the vectors on both sides is 1). Its presence comes
    from the loss of information that happens when a 3D point is projected on a 2D
    plane (the camera sensor), as multiple 3D points map to the same 2D point.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 标量 λᵢ 是保持方程同质性的缩放因子（即，两边向量的最后一个元素是1）。它的存在来自于将3D点投影到2D平面（相机传感器）时信息的丧失，因为多个3D点映射到同一个2D点。
- en: Assuming we know the projection matrix of the cameras and we have the pixel
    coordinates of a feature point, our goal is to isolate (X, Y, Z).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们知道相机的投影矩阵，并且我们有一个特征点的像素坐标，我们的目标是隔离(X, Y, Z)。
- en: '![](../Images/9fa9e7c101aea9e4ace8db3af43626e6.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9fa9e7c101aea9e4ace8db3af43626e6.png)'
- en: 'Inserting (3) into the first two rows of (2):'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 将(3)代入(2)的前两行：
- en: '![](../Images/72b8b49fffbc2ddccd9b62922d9fc254.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/72b8b49fffbc2ddccd9b62922d9fc254.png)'
- en: Equation (6) shows that each camera view supplies us with two linear equations
    in 3 unknowns (X, Y, Z). If we have at least two camera views of the same 3D point,
    we can compute the 3D coordinates by solving an overdetermined system of linear
    equations.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 公式(6) 表明，每个相机视图为我们提供两个未知数(X, Y, Z)的线性方程。如果我们至少有两个相机视图的相同3D点，我们可以通过求解一个过定的线性方程组来计算3D坐标。
- en: Great! But how do we compute the projection matrices?
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 太棒了！但我们如何计算投影矩阵呢？
- en: Computation of the Projection Matrix
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 投影矩阵的计算
- en: To compute the projection matrix of a camera, we need a large number of known
    3D points and their corresponding pixel coordinates. We use a checkerboard calibration
    pattern placed as precisely as possible at measured distances from the stereo
    rig.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算相机的投影矩阵，我们需要大量已知的3D点及其对应的像素坐标。我们使用一个棋盘格标定图案，尽可能精确地放置在测量距离上的立体设备前。
- en: '![](../Images/b8fe2ea5058b6c7391ff242ad89134ce.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b8fe2ea5058b6c7391ff242ad89134ce.png)'
- en: 'Figure 2: The checkerboard calibration pattern at a known location. Image by
    the author.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：在已知位置的棋盘格标定图案。作者提供的图像。
- en: The [repository includes the calibration pattern images](https://github.com/sebastiengilbert73/tutorial_calibrate_stereo_vision/tree/main/calibration_images),
    for both cameras.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[该仓库包括标定模式图像](https://github.com/sebastiengilbert73/tutorial_calibrate_stereo_vision/tree/main/calibration_images)，适用于两台相机。'
- en: '![](../Images/990076df5538be05eec67d75df4db8cc.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/990076df5538be05eec67d75df4db8cc.png)'
- en: 'Figure 3: Images of the checkerboard calibration pattern, at 60 cm from the
    cameras. Image by the author.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：60 cm 距离摄像头的棋盘格标定模式图像。图片由作者提供。
- en: You can run the whole calibration procedure with [this python program](https://github.com/sebastiengilbert73/tutorial_calibrate_stereo_vision/blob/main/calibrate_stereo.py).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用[这个 Python 程序](https://github.com/sebastiengilbert73/tutorial_calibrate_stereo_vision/blob/main/calibrate_stereo.py)运行整个标定过程。
- en: The square intersections in each calibration image get detected with an instance
    of the class CheckerboardIntersections, which we introduced in [my previous article](https://medium.com/towards-data-science/camera-radial-distortion-compensation-with-gradient-descent-22728487acb1).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 每个标定图像中的方形交点通过 CheckerboardIntersections 类的一个实例进行检测，该类在[我之前的文章](https://medium.com/towards-data-science/camera-radial-distortion-compensation-with-gradient-descent-22728487acb1)中介绍过。
- en: In this case, we set the intersection detector parameters to be relatively sensitive,
    such that all the real intersections are detected, plus a manageable amount of
    false positives (in other words, perfect recall, reasonable precision). Since
    the calibration is a process that we’ll only do once, we can afford the work of
    manually removing the false positives. The [program](https://github.com/sebastiengilbert73/tutorial_calibrate_stereo_vision/blob/main/calibrate_stereo.py)
    iterates over the calibration pattern images and asks the user to select the false
    positives.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将交点检测器的参数设置得相对灵敏，以便检测所有真实交点，并且有一定量的假阳性（换句话说，完美的召回，合理的精度）。由于标定是一次性的过程，我们可以承受手动去除假阳性的工作。[程序](https://github.com/sebastiengilbert73/tutorial_calibrate_stereo_vision/blob/main/calibrate_stereo.py)会遍历标定模式图像并要求用户选择假阳性。
- en: '![](../Images/86b556356698bc4af90e7ed329d0a251.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/86b556356698bc4af90e7ed329d0a251.png)'
- en: 'Figure 4: Found intersection points, before and after the manual removal of
    false positives. Image by the author.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：找到的交点，手动去除假阳性前后的情况。图片由作者提供。
- en: As we saw in [my article about the compensation of camera radial distortion](https://medium.com/towards-data-science/camera-radial-distortion-compensation-with-gradient-descent-22728487acb1),
    the raw intersection coordinates must be undistorted. The radial distortion model
    was previously computed for both cameras, and [the corresponding files are already
    in the repository](https://github.com/sebastiengilbert73/tutorial_calibrate_stereo_vision/tree/main/radial_distortion).
    The undistorted coordinates are the ones that we’ll use to build the projection
    matrix of a pinhole camera model.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[我关于相机径向失真的补偿文章](https://medium.com/towards-data-science/camera-radial-distortion-compensation-with-gradient-descent-22728487acb1)中看到的，原始交点坐标必须是未失真的。径向失真模型之前已经为两台相机计算，[相应的文件已在仓库中](https://github.com/sebastiengilbert73/tutorial_calibrate_stereo_vision/tree/main/radial_distortion)。未失真的坐标是我们用来构建针孔相机模型的投影矩阵的坐标。
- en: At this point, we have 7 (captures at different distances) x 6 x 6 (square intersection
    points) = 252 correspondences between a 3D point and pixel coordinates for each
    camera.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们有 7（不同距离的拍摄）x 6 x 6（方形交点）= 252 对应于每台相机的 3D 点和像素坐标。
- en: 'To compute the entries of the projection matrix, we’ll start again with equation
    (1), but this time assuming we know (u, v)ₖ and (X, Y, Z)ₖ, and we want to solve
    for the entries of P. The subscript k refers to the index of the pair (pixel_coords,
    XYZ_world). The scalars λₖ (one for each point) are also unknown. We can eliminate
    the λₖ from the system of linear equations with a bit of manipulation:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算投影矩阵的条目，我们将重新开始使用方程（1），但这次假设我们知道（u, v）ₖ 和（X, Y, Z）ₖ，并且我们要解决 P 的条目。下标 k 指的是（pixel_coords,
    XYZ_world）对的索引。标量 λₖ（每个点一个）也是未知的。我们可以通过一些操作将 λₖ 从线性方程组中消除：
- en: '![](../Images/ee0b9873ccf2aee89a90c47ef0184a24.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ee0b9873ccf2aee89a90c47ef0184a24.png)'
- en: 'Equations (8) and (9) can get written in the form Ap = 0:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 方程（8）和（9）可以写成 Ap = 0 的形式：
- en: '![](../Images/3ce5bc073f325cafb6148b39d12132a0.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3ce5bc073f325cafb6148b39d12132a0.png)'
- en: Equation (10) shows that each correspondence supplies two homogeneous linear
    equations in 12 unknowns. At least 6 correspondences are necessary to solve for
    the entries of P. We also need our 3D points to be non-coplanar. With 252 correspondences
    from 7 planes, we are safe.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 方程 (10) 显示每个对应关系提供了12个未知数中的两个齐次线性方程。至少需要6个对应关系来解出P的条目。我们还需要我们的3D点是非共面的。通过7个平面中的252个对应关系，我们是安全的。
- en: After execution of the calibration program, we can verify that the projection
    matrices correctly project the known 3D points back to their undistorted pixel
    coordinates.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行校准程序后，我们可以验证投影矩阵是否正确地将已知的3D点投影回其未畸变的像素坐标。
- en: '![](../Images/f17937b96be652b55561e8d60969356e.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f17937b96be652b55561e8d60969356e.png)'
- en: 'Figure 5: Projection of the checkerboard 3D points in the images. Image by
    the author.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：图像中棋盘格3D点的投影。图像由作者提供。
- en: In Figure 5, the blue dots are the points found by the intersection detector,
    after compensating for the radial distortion. The yellow circles are the projections
    of the 3D points in the image. We can see that the projection matrices of both
    cameras do a good job. Note that the excentric annotated points do not coincide
    with the checkerboard intersections, due to the radial distortion compensation.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在图5中，蓝色点是经过径向畸变补偿后由交点检测器找到的点。黄色圆圈是图像中3D点的投影。我们可以看到，两台摄像头的投影矩阵表现良好。请注意，偏离标注点与棋盘格交点不重合，这是由于径向畸变补偿造成的。
- en: 3D Tracking
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3D 跟踪
- en: We can now use our calibrated stereo system to compute the 3D location of a
    feature point. To demonstrate that, we’ll track an easy-to-detect feature point
    (the center of a red square) in a series of images.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用校准后的立体系统来计算特征点的3D位置。为了演示这一点，我们将跟踪一个易于检测的特征点（一个红色方块的中心）在一系列图像中的位置。
- en: You can find the tracking program [here](https://github.com/sebastiengilbert73/tutorial_calibrate_stereo_vision/blob/main/track_red_square.py).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[这里](https://github.com/sebastiengilbert73/tutorial_calibrate_stereo_vision/blob/main/track_red_square.py)找到跟踪程序。
- en: '![](../Images/b33e6e53aba1d639ffe4249adee0a68f.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b33e6e53aba1d639ffe4249adee0a68f.png)'
- en: 'Figure 6: Left: An image of the tracked red square. Right: The detected blob.
    Image by the author.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：左：跟踪的红色方块的图像。右：检测到的斑点。图像由作者提供。
- en: Figure 6 shows an example of the detection of the tracked red square. In a few
    words, the square is tracked by first identifying the regions of the images where
    the blue component is dominant since the area around the red square is blue. A
    region where the red component dominates, within the blue-dominated area, is then
    found. For the details, please refer to [the code](https://github.com/sebastiengilbert73/tutorial_calibrate_stereo_vision/blob/main/utilities/red_square.py).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图6展示了跟踪红色方块的检测示例。简而言之，方块是通过首先识别图像中蓝色成分占主导的区域来跟踪的，因为红色方块周围的区域是蓝色的。然后，在蓝色主导区域内找到红色成分占主导的区域。详细信息请参阅[代码](https://github.com/sebastiengilbert73/tutorial_calibrate_stereo_vision/blob/main/utilities/red_square.py)。
- en: '![](../Images/6c6d694dc3406e8bb5a50b50e6b03fd6.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6c6d694dc3406e8bb5a50b50e6b03fd6.png)'
- en: 'Figure 7: The center of the red square gets tracked in 3D. The coordinates
    are in cm. Animation by the author.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：红色方块的中心在3D中被跟踪。坐标单位为厘米。动画由作者提供。
- en: Using the undistorted pixel coordinates from both cameras, and their corresponding
    projection matrices, the 3D location of the feature point can be computed for
    each image in the series, as displayed in the animation above.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 使用两台摄像头的未畸变像素坐标及其对应的投影矩阵，可以计算出每张图像中特征点的3D位置，如上面的动画所示。
- en: Conclusion
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: We built a simple stereo vision system with a pair of webcams. We calibrated
    both cameras by compensating for their radial distortion and computing their projection
    matrices. We could use our calibrated system to track the 3D location of a feature
    point in a series of images.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用一对网络摄像头构建了一个简单的立体视觉系统。我们通过补偿径向畸变并计算投影矩阵来校准这两台摄像头。我们可以使用经过校准的系统来跟踪一系列图像中一个特征点的3D位置。
- en: Please feel free to experiment with [the code](https://github.com/sebastiengilbert73/tutorial_calibrate_stereo_vision).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 请随意尝试[代码](https://github.com/sebastiengilbert73/tutorial_calibrate_stereo_vision)。
- en: '**If you have an application of stereo vision in mind, let me know, I would
    be very interested to hear about it!**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果你有立体视觉的应用想法，请告诉我，我会非常感兴趣了解！**'
