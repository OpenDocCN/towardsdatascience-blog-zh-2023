- en: Deep Dive into PFI for Model Interpretability
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入探讨模型可解释性的PFI
- en: 原文：[https://towardsdatascience.com/deep-dive-into-pfi-for-model-interpretability-f12f0c64226c?source=collection_archive---------11-----------------------#2023-07-20](https://towardsdatascience.com/deep-dive-into-pfi-for-model-interpretability-f12f0c64226c?source=collection_archive---------11-----------------------#2023-07-20)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/deep-dive-into-pfi-for-model-interpretability-f12f0c64226c?source=collection_archive---------11-----------------------#2023-07-20](https://towardsdatascience.com/deep-dive-into-pfi-for-model-interpretability-f12f0c64226c?source=collection_archive---------11-----------------------#2023-07-20)
- en: Another interpretability tool for your toolbox
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另一个可供选择的可解释性工具
- en: '[](https://medium.com/@tiagotoledojr?source=post_page-----f12f0c64226c--------------------------------)[![Tiago
    Toledo Jr.](../Images/577748ae15ec9eb7ead9355f94287a9d.png)](https://medium.com/@tiagotoledojr?source=post_page-----f12f0c64226c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f12f0c64226c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f12f0c64226c--------------------------------)
    [Tiago Toledo Jr.](https://medium.com/@tiagotoledojr?source=post_page-----f12f0c64226c--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@tiagotoledojr?source=post_page-----f12f0c64226c--------------------------------)[![Tiago
    Toledo Jr.](../Images/577748ae15ec9eb7ead9355f94287a9d.png)](https://medium.com/@tiagotoledojr?source=post_page-----f12f0c64226c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f12f0c64226c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f12f0c64226c--------------------------------)
    [Tiago Toledo Jr.](https://medium.com/@tiagotoledojr?source=post_page-----f12f0c64226c--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff4eeaf479b0c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-pfi-for-model-interpretability-f12f0c64226c&user=Tiago+Toledo+Jr.&userId=f4eeaf479b0c&source=post_page-f4eeaf479b0c----f12f0c64226c---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f12f0c64226c--------------------------------)
    ·6 min read·Jul 20, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff12f0c64226c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-pfi-for-model-interpretability-f12f0c64226c&user=Tiago+Toledo+Jr.&userId=f4eeaf479b0c&source=-----f12f0c64226c---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff4eeaf479b0c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-pfi-for-model-interpretability-f12f0c64226c&user=Tiago+Toledo+Jr.&userId=f4eeaf479b0c&source=post_page-f4eeaf479b0c----f12f0c64226c---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f12f0c64226c--------------------------------)
    ·6分钟阅读·2023年7月20日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff12f0c64226c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-pfi-for-model-interpretability-f12f0c64226c&user=Tiago+Toledo+Jr.&userId=f4eeaf479b0c&source=-----f12f0c64226c---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff12f0c64226c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-pfi-for-model-interpretability-f12f0c64226c&source=-----f12f0c64226c---------------------bookmark_footer-----------)![](../Images/7eb50e79f4113ff3f3d5a63159eb633f.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff12f0c64226c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-pfi-for-model-interpretability-f12f0c64226c&source=-----f12f0c64226c---------------------bookmark_footer-----------)![](../Images/7eb50e79f4113ff3f3d5a63159eb633f.png)'
- en: Photo by [fabio](https://unsplash.com/@fabioha?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [fabio](https://unsplash.com/@fabioha?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Knowing how to assess your model is essential for your work as a data scientist.
    No one will sign off on your solution if you’re not able to fully understand and
    communicate it to your stakeholders. This is why knowing interpretability methods
    is so important.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 了解如何评估你的模型对于数据科学家的工作至关重要。如果你不能完全理解并向利益相关者传达你的解决方案，没有人会批准它。这就是为什么了解可解释性方法如此重要的原因。
- en: The lack of interpretability can kill a very good model. I haven’t developed
    a model where my stakeholders weren’t interested in understanding how the predictions
    were made. Therefore, knowing how to interpret a model and communicate it to the
    business is an essential ability for a data scientist.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 缺乏可解释性可能会毁掉一个非常好的模型。我还没有开发过一个我的利益相关者不关心理解预测如何产生的模型。因此，知道如何解释模型并将其传达给业务是数据科学家的核心能力。
- en: In this post, we’re going to explore the Permutation Feature Importance (PFI),
    an model agnostic methodology that can help us identify what are the most important
    features of our model, and therefore, communicate better what the model is considering
    when doing its predictions.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将深入探讨置换特征重要性（PFI），这是一种与模型无关的方法，可以帮助我们识别模型中最重要的特征，从而更好地沟通模型在进行预测时的考虑因素。
- en: What is the Permutation Feature Importance
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 置换特征重要性是什么
- en: The PFI method tries to estimate how important a feature is for model results
    based on what happens to the model when we change the feature connected to the
    target variable.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: PFI 方法尝试估计一个特征对模型结果的重要性，基于我们改变与目标变量相关的特征时模型的表现。
- en: To do that, for each feature, we want to analyze the importance, we random shuffle
    it while keeping all the other features and target the same way.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，对于每个特征，我们要分析其重要性，我们将其随机打乱，同时保持其他特征和目标不变。
- en: This makes the feature useless to predict the target since we broke the relationship
    between them by changing their joint distribution.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得特征在预测目标时变得无用，因为我们通过改变它们的联合分布打破了它们之间的关系。
- en: Then, we can use our model to predict our shuffled dataset. The amount of performance
    reduction in our model will indicate how important that feature is.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用模型来预测我们打乱的数据集。模型性能的减少量将指示该特征的重要性。
- en: 'The algorithm then looks something like this:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 算法大致如下：
- en: We train a model in a training dataset and then assess its performance on both
    the training and the testing dataset
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在训练数据集上训练一个模型，然后在训练集和测试集上评估其表现。
- en: For each feature, we create a new dataset where the feature is shuffled
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个特征，我们创建一个新的数据集，其中该特征被打乱。
- en: We then use the trained model to predict the output of the new dataset
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后我们使用训练好的模型来预测新数据集的输出。
- en: The quotient of the new performance metric by the old one gives us the importance
    of the feature
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新的性能指标与旧指标的比值给出了特征的重要性。
- en: Notice that if a feature is not important, the performance of the model should
    not vary a lot. If it is, then the performance must suffer a lot.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果一个特征不重要，模型的表现不应有太大变化。如果它重要，那么表现应该会有很大变化。
- en: Interpreting the PFI
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释 PFI
- en: Now that we know how to calculate the PFI, how do we interpret it?
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道如何计算 PFI，我们如何解释它呢？
- en: 'It depends on which fold we are applying the PFI to. We usually have two options:
    applying it to the training or the test dataset.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这取决于我们将 PFI 应用到哪个折叠。我们通常有两个选项：将其应用于训练数据集或测试数据集。
- en: Training Interpretation
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练解释
- en: During training, our model learns the patterns of the data and tries to represent
    it. Of course, during training, we have no idea of how well our model generalizes
    to unseen data.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，我们的模型学习数据的模式并尝试表示它。当然，在训练过程中，我们无法知道我们的模型对未见数据的泛化效果如何。
- en: Therefore, by applying the PFI to the training dataset we are going to see which
    features were the most relevant for the learning of the representation of the
    data by the model.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过将 PFI 应用于训练数据集，我们将看到哪些特征对模型学习数据表示最为相关。
- en: In business terms, this indicates which features were the most important for
    the model construction.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 从业务角度来看，这表明哪些特征对模型构建最为重要。
- en: Test Interpretation
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试解释
- en: Now, if we apply the method to the test dataset, we are going to see the feature
    impact on the generalization of the model.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们将方法应用于测试数据集，我们将看到特征对模型泛化的影响。
- en: Let’s think about it. If we see the performance of the model go down in the
    test set after we shuffled a feature, it means that that feature was important
    for the performance on that set. Since the test set is what we use to test generalization
    (if you’re doing everything right), then we can say that it is important for generalization.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一下。如果我们在打乱某个特征后看到模型在测试集上的表现下降，这意味着该特征对该数据集的表现很重要。由于测试集是我们用来测试泛化的（如果你做得对的话），那么我们可以说它对泛化很重要。
- en: The problems with PFI
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PFI 的问题
- en: The PFI analyzes the effect of a feature in your model performance, therefore,
    it does not state anything about the raw data. If your model performance is poor,
    then any relation you find with PFI will be meaningless.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: This is true for both sets, if your model is underfitting (low prediction power
    on the training set) or overfitting (low prediction power on the test set) then
    you cannot take insights from this method.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Also, when two features are highly correlated the PFI can mislead your interpretation.
    If you shuffle one feature but the required information is encoded into another
    one, then the performance may not suffer at all, which would make you think the
    feature is useless, which may not be the case.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the PFI in Python
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To implement the PFI in Python we must first import our required libraries.
    For this, we are going to use mainly the libraries numpy, pandas, tqdm, and sklearn:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now, we must load our dataset, which is going to be the Iris dataset. Then,
    we’re going to fit a Random Forest to the data.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'With our model fitted, let’s analyze its performance to see if we can safely
    apply the PFI to see how the features impact our model:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can see we achieved a 99% accuracy on the training set and a 95.5% accuracy
    on the test set. Looks good for now. Let’s get the original error scores for a
    later comparison:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now let’s calculate the permutation scores. For that, it is usual to run the
    shuffle for each feature several times to achieve a statistic of the feature scores
    to avoid any coincidences. In our case, let’s do 10 repetitions for each feature:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now we have a dictionary with the performance for each shuffle we did. Now,
    let’s generate a table that has, for each feature in each fold, the average and
    the standard deviation of the performance when compared to the original performance
    of our model:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We will end up with something like this:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: We can see that feature 2 seems to be the most important feature in our dataset
    for both folds, followed by feature 3\. Since we’re not fixing the random seed
    for the shuffle function from numpy we can expect this number to vary.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: 'We can then plot the importance in a graph to have a better visualization of
    the importance:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The PFI is a simple methodology that can help you quickly identify the most
    important features. Go ahead and try to apply it to some model you’re developing
    to see how it is behaving.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: But also be aware of the limitations of the method. Not knowing where a method
    falls short will end up making you do an incorrect interpretation.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: Also, notices that the PFI shows the importance of the feature but does not
    states in which direction it is influencing the model output.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: So, tell me, how are you going to use this in your next models?
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Stay tuned for more posts about interpretability methods that can improve your
    overall understanding of a model.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
