- en: 'The Ultimate Guide to Training BERT from Scratch: Final Act'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从零开始训练 BERT 的终极指南：最终篇
- en: 原文：[https://towardsdatascience.com/the-ultimate-guide-to-training-bert-from-scratch-final-act-eab78b0657bb?source=collection_archive---------5-----------------------#2023-12-18](https://towardsdatascience.com/the-ultimate-guide-to-training-bert-from-scratch-final-act-eab78b0657bb?source=collection_archive---------5-----------------------#2023-12-18)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-ultimate-guide-to-training-bert-from-scratch-final-act-eab78b0657bb?source=collection_archive---------5-----------------------#2023-12-18](https://towardsdatascience.com/the-ultimate-guide-to-training-bert-from-scratch-final-act-eab78b0657bb?source=collection_archive---------5-----------------------#2023-12-18)
- en: 'The Final Frontier: Building and Training Your BERT Model'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最终前沿：构建和训练你的 BERT 模型
- en: '[](https://dpoulopoulos.medium.com/?source=post_page-----eab78b0657bb--------------------------------)[![Dimitris
    Poulopoulos](../Images/ce535a1679779f5a2ec8b024e6691e50.png)](https://dpoulopoulos.medium.com/?source=post_page-----eab78b0657bb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----eab78b0657bb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----eab78b0657bb--------------------------------)
    [Dimitris Poulopoulos](https://dpoulopoulos.medium.com/?source=post_page-----eab78b0657bb--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dpoulopoulos.medium.com/?source=post_page-----eab78b0657bb--------------------------------)[![Dimitris
    Poulopoulos](../Images/ce535a1679779f5a2ec8b024e6691e50.png)](https://dpoulopoulos.medium.com/?source=post_page-----eab78b0657bb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----eab78b0657bb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----eab78b0657bb--------------------------------)
    [Dimitris Poulopoulos](https://dpoulopoulos.medium.com/?source=post_page-----eab78b0657bb--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7cc87df5b1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-guide-to-training-bert-from-scratch-final-act-eab78b0657bb&user=Dimitris+Poulopoulos&userId=7cc87df5b1&source=post_page-7cc87df5b1----eab78b0657bb---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----eab78b0657bb--------------------------------)
    ·7 min read·Dec 18, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Feab78b0657bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-guide-to-training-bert-from-scratch-final-act-eab78b0657bb&user=Dimitris+Poulopoulos&userId=7cc87df5b1&source=-----eab78b0657bb---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7cc87df5b1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-guide-to-training-bert-from-scratch-final-act-eab78b0657bb&user=Dimitris+Poulopoulos&userId=7cc87df5b1&source=post_page-7cc87df5b1----eab78b0657bb---------------------post_header-----------)
    发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----eab78b0657bb--------------------------------)
    · 7分钟阅读 · 2023年12月18日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Feab78b0657bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-guide-to-training-bert-from-scratch-final-act-eab78b0657bb&user=Dimitris+Poulopoulos&userId=7cc87df5b1&source=-----eab78b0657bb---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feab78b0657bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-guide-to-training-bert-from-scratch-final-act-eab78b0657bb&source=-----eab78b0657bb---------------------bookmark_footer-----------)![](../Images/548c617f9d3d11635cc30ccc45e1d106.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feab78b0657bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-guide-to-training-bert-from-scratch-final-act-eab78b0657bb&source=-----eab78b0657bb---------------------bookmark_footer-----------)![](../Images/548c617f9d3d11635cc30ccc45e1d106.png)'
- en: Photo by [Rob Laughter](https://unsplash.com/@roblaughter?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Rob Laughter](https://unsplash.com/@roblaughter?utm_source=medium&utm_medium=referral)
    于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: This blog post concludes our series on training BERT from scratch. For context
    and a complete understanding, please refer to [Part I](/the-ultimate-guide-to-training-bert-from-scratch-introduction-b048682c795f),
    [Part II](/the-ultimate-guide-to-training-bert-from-scratch-the-tokenizer-ddf30f124822),
    and [Part III](/the-ultimate-guide-to-training-bert-from-scratch-prepare-the-dataset-beaae6febfd5)
    of the series.
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本博客文章结束了我们关于从零开始训练 BERT 的系列。如果需要背景信息和完整理解，请参考系列的 [第一部分](/the-ultimate-guide-to-training-bert-from-scratch-introduction-b048682c795f)、[第二部分](/the-ultimate-guide-to-training-bert-from-scratch-the-tokenizer-ddf30f124822)
    和 [第三部分](/the-ultimate-guide-to-training-bert-from-scratch-prepare-the-dataset-beaae6febfd5)。
- en: When BERT burst onto the scene in 2018, it triggered a tsunami in the world
    of Natural Language Processing (NLP). Many consider this as the NLP’s own ImageNet
    moment, drawing parallels to the shift deep neural networks brought to computer
    vision and the broader field of machine learning back in 2012.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当 BERT 在 2018 年登上舞台时，它在自然语言处理（NLP）领域引发了巨大的波澜。许多人将这一时刻视为 NLP 自身的 ImageNet 时刻，类似于
    2012 年深度神经网络对计算机视觉和更广泛的机器学习领域带来的变革。
- en: Five years down the line, the prophecy holds true. Transformer-based Large Language
    Models (LLMs) aren’t just the shiny new toy; they’re reshaping the landscape.
    From transforming how we work to revolutionizing how we access information, these
    models are core technology behind countless emerging startups aiming to harness
    their untapped potential.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 五年过去了，这一预言依然成立。基于 Transformer 的大型语言模型（LLMs）不仅仅是炫目的新玩具，它们正在重塑整个领域。这些模型正在改变我们的工作方式，并彻底革新我们获取信息的方式，它们是无数新兴初创公司背后的核心技术，这些公司旨在挖掘其尚未开发的潜力。
- en: This is the reason I decided to write this series of blog posts, diving into
    the world of BERT and how can you train your own model from scratch. The point
    isn’t just to get the job done — after all, you can easily find pre-trained BERT
    models on the Hugging Face Hub. The real magic lies in understanding the inner
    workings of this groundbreaking model and applying…
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我决定写这一系列博客文章的原因，深入探讨 BERT 的世界以及如何从零开始训练自己的模型。关键不仅仅是完成任务——毕竟，你可以轻松地在 Hugging
    Face Hub 上找到预训练的 BERT 模型。真正的魔力在于理解这个突破性模型的内部工作原理并应用……
