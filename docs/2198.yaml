- en: 'Mastering Model Interpretability: A Comprehensive Look at Partial Dependence
    Plots'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/mastering-model-interpretability-a-comprehensive-look-at-partial-dependence-plots-d5e78e86051a?source=collection_archive---------14-----------------------#2023-07-07](https://towardsdatascience.com/mastering-model-interpretability-a-comprehensive-look-at-partial-dependence-plots-d5e78e86051a?source=collection_archive---------14-----------------------#2023-07-07)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Starting your journey in the interpretable AI world.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@tiagotoledojr?source=post_page-----d5e78e86051a--------------------------------)[![Tiago
    Toledo Jr.](../Images/577748ae15ec9eb7ead9355f94287a9d.png)](https://medium.com/@tiagotoledojr?source=post_page-----d5e78e86051a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d5e78e86051a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d5e78e86051a--------------------------------)
    [Tiago Toledo Jr.](https://medium.com/@tiagotoledojr?source=post_page-----d5e78e86051a--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff4eeaf479b0c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-model-interpretability-a-comprehensive-look-at-partial-dependence-plots-d5e78e86051a&user=Tiago+Toledo+Jr.&userId=f4eeaf479b0c&source=post_page-f4eeaf479b0c----d5e78e86051a---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d5e78e86051a--------------------------------)
    ·7 min read·Jul 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd5e78e86051a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-model-interpretability-a-comprehensive-look-at-partial-dependence-plots-d5e78e86051a&user=Tiago+Toledo+Jr.&userId=f4eeaf479b0c&source=-----d5e78e86051a---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd5e78e86051a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-model-interpretability-a-comprehensive-look-at-partial-dependence-plots-d5e78e86051a&source=-----d5e78e86051a---------------------bookmark_footer-----------)![](../Images/f605a8b589d514ca9f8aca161c4d675a.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [David Pupăză](https://unsplash.com/@davfts?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Knowing how to interpret your model is essential to understand if it is not
    doing weird stuff. The more you know your model, the less likely you are to be
    surprised by its behavior when it goes to production.
  prefs: []
  type: TYPE_NORMAL
- en: Also, the more domain you have over your model, the better you’re going to be
    able to sell it to your business unit. The worst thing that can happen is for
    them to realize you’re actually not sure of what you’re selling them.
  prefs: []
  type: TYPE_NORMAL
- en: I’ve never developed a model in which I wasn’t required to explain how the predictions
    were made given the input variables. At the very least, stating to the business
    which features contributed positively or negatively was essential.
  prefs: []
  type: TYPE_NORMAL
- en: One tool you can use to understand how your model works is the Partial Dependence
    Plot (PDP), which we will explore in this post.
  prefs: []
  type: TYPE_NORMAL
- en: What is the PDP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The PDP is a global interpretability method that focuses on showing you how
    the feature values of your model are related to the output of your model.
  prefs: []
  type: TYPE_NORMAL
- en: It is not a method to understand your data, it only generates insights for your
    model, so no causal relationship between the target and features can be inferred
    from this method. It can, however, allow you to make causal inferences about your
    model.
  prefs: []
  type: TYPE_NORMAL
- en: This is because the method probes your model, so you can see exactly what the
    model does when the feature variable changes.
  prefs: []
  type: TYPE_NORMAL
- en: How it works
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First of all, the PDP allows us to investigate only one or two features at a
    time. In this post, we are going to focus on the single feature analysis case.
  prefs: []
  type: TYPE_NORMAL
- en: 'After your model is trained, we generate a probing dataset. This dataset is
    created following the algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: We select each unique value for the feature we are interested in
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For each unique value, we make a copy of your entire dataset, setting the feature
    value to that unique value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we use our model to make the predictions for this new dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we average the predictions of the model for each unique value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s make an example. Let’s say we have the following dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2db5862e15add1cf4952cf3d1f895135.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, if we want to apply the PDP to Feature 0, we will repeat the dataset for
    each unique value of the feature, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/618c3d56e22e67fac47025e30905cc16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, after applying our model we will have something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/49281fb530c5d0d5ae15bbf9eece114f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, we calculate the average output for each value, ending up with the following
    dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9b7d1b62a620559bb2d52a7ba95490a7.png)'
  prefs: []
  type: TYPE_IMG
- en: Then it is just a matter of plotting this data with a line plot.
  prefs: []
  type: TYPE_NORMAL
- en: For regression problems, it is straightforward to calculate the average output
    for each feature value. For classification methods, we can use the predicted probability
    for each class and then average those values. In this case, we will have a PDP
    for each feature and class pair in our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematical Interpretation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The interpretation of the PDP is that we are marginalizing one or two features
    to assess their marginal effect on the predicted output of the model. This is
    given by the formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5e121619c3a2fafb87fad2084cb7bdf5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Where $f$ is the machine learning model, $x_S$ is the set of features we are
    interested in analyzing and $x_C$ is the set of other features we are going to
    average over. The above function can be calculated using the following approximation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/47887c4183fb43a36ea4b995ce532135.png)'
  prefs: []
  type: TYPE_IMG
- en: Problems with the PDP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PDP has some limitations we must be aware of. First of all, since we average
    the outputs over each feature value, we will end up with a plot that goes over
    every value in the dataset, even if that value happens only once.
  prefs: []
  type: TYPE_NORMAL
- en: Because of that, you may end up seeing some behavior for a very few populated
    areas of your dataset that may be not representative of what would happen if that
    value was more frequent. Therefore it is helpful to always look at the distribution
    of a feature when seeing its PDP to know which values are more likely to happen.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another problem happens when you can have a feature with values canceling each
    out. For example, if your feature has the following distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/25c53b5861af9646f5490f4743458aaa.png)'
  prefs: []
  type: TYPE_IMG
- en: 'When calculating the PDP for this feature, we will end up with something like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7176ed7a7773ebc6cc1f2b8897ee94c0.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice that the impact of the feature is by no means zero, but it is zero on
    average. This may mislead you into believing that the feature is useless when
    in fact it is not.
  prefs: []
  type: TYPE_NORMAL
- en: Another problem with this approach is when the feature we are analyzing is correlated
    with the features we are averaging over. This is because if we have correlated
    features if we force every value of the dataset to have each value for the feature
    of interest, we are going to create unrealistic points.
  prefs: []
  type: TYPE_NORMAL
- en: Think about a dataset with the amount of rain and the amount of clouds in the
    sky. When we average the values for the amount of rain, we are going to have points
    saying that there was rain without clouds in the sky, which is an unfeasible point.
  prefs: []
  type: TYPE_NORMAL
- en: Interpreting PDP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s see how to analyze a Partial Dependence Plot. Look at the image below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/71598657893794801e31a18c01af3358.png)'
  prefs: []
  type: TYPE_IMG
- en: In the x-axis, we have the values of feature 0, in the y-axis we have the average
    output of the model for each feature value. Notice that for values smaller than
    -0.10, the model outputs very low target predictions, after that the predictions
    go up and then start varying around 150 until the feature value goes over 0.09,
    in which the predictions start to go up dramatically.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we can say that there is a positive correlation between the feature
    and the target prediction, however, this correlation is not linear.
  prefs: []
  type: TYPE_NORMAL
- en: ICE Plots
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The ICE plots try to solve the problem of the feature values canceling each
    other out. Basically, in an ICE plot, we plot each individual prediction the model
    made for each value, not only its average value.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the PDP in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s implement the PDP in Python. For that, we are first going to import the
    required libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We are going to use the diabetes dataset from sklearn. The tqdm library will
    be used to make progress bars for our loops.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we are going to load the dataset and fit a Random Forest Regressor to
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, for each feature in our dataset, we will calculate the average prediction
    of the model for the dataset with that feature fixed for that value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we plot the PDP for each feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'For example, the plot for Feature 3 is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d6ee9c6136c8fe6609437b9dcc2d8dbf.png)'
  prefs: []
  type: TYPE_IMG
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now you have another tool in your toolbox to use to make your work better and
    help the business unit understand what is happening with that black-box model
    you’re showing them.
  prefs: []
  type: TYPE_NORMAL
- en: But don’t let the theory vanish. Grab a model you’re currently developing and
    apply the PDP visualization to it. Understand what the model is doing, and be
    more precise in your hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: Also, this is not the only interpretability method out there. In fact, we have
    other methods that work better with correlated features. Stay tuned for my next
    posts where these methods will be covered.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[https://ethen8181.github.io/machine-learning/model_selection/partial_dependence/partial_dependence.html](https://ethen8181.github.io/machine-learning/model_selection/partial_dependence/partial_dependence.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://scikit-learn.org/stable/modules/partial_dependence.html](https://scikit-learn.org/stable/modules/partial_dependence.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://christophm.github.io/interpretable-ml-book/pdp.html](https://christophm.github.io/interpretable-ml-book/pdp.html)'
  prefs: []
  type: TYPE_NORMAL
