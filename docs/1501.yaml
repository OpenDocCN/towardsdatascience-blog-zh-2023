- en: Automatically Managing Data Pipeline Infrastructures With Terraform
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Terraform 自动管理数据管道基础设施
- en: 原文：[https://towardsdatascience.com/automatically-managing-data-pipeline-infrastructures-with-terraform-323fd1808a47?source=collection_archive---------9-----------------------#2023-05-02](https://towardsdatascience.com/automatically-managing-data-pipeline-infrastructures-with-terraform-323fd1808a47?source=collection_archive---------9-----------------------#2023-05-02)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/automatically-managing-data-pipeline-infrastructures-with-terraform-323fd1808a47?source=collection_archive---------9-----------------------#2023-05-02](https://towardsdatascience.com/automatically-managing-data-pipeline-infrastructures-with-terraform-323fd1808a47?source=collection_archive---------9-----------------------#2023-05-02)
- en: '*I know the manual work you did last summer*'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*我知道你去年夏天做的手动工作*'
- en: '[](https://joaopedro214.medium.com/?source=post_page-----323fd1808a47--------------------------------)[![João
    Pedro](../Images/64a0e14527be213e5fde0a02439fbfa7.png)](https://joaopedro214.medium.com/?source=post_page-----323fd1808a47--------------------------------)[](https://towardsdatascience.com/?source=post_page-----323fd1808a47--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----323fd1808a47--------------------------------)
    [João Pedro](https://joaopedro214.medium.com/?source=post_page-----323fd1808a47--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://joaopedro214.medium.com/?source=post_page-----323fd1808a47--------------------------------)[![João
    Pedro](../Images/64a0e14527be213e5fde0a02439fbfa7.png)](https://joaopedro214.medium.com/?source=post_page-----323fd1808a47--------------------------------)[](https://towardsdatascience.com/?source=post_page-----323fd1808a47--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----323fd1808a47--------------------------------)
    [João Pedro](https://joaopedro214.medium.com/?source=post_page-----323fd1808a47--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb111eee95c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomatically-managing-data-pipeline-infrastructures-with-terraform-323fd1808a47&user=Jo%C3%A3o+Pedro&userId=b111eee95c&source=post_page-b111eee95c----323fd1808a47---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----323fd1808a47--------------------------------)
    ·15 min read·May 2, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F323fd1808a47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomatically-managing-data-pipeline-infrastructures-with-terraform-323fd1808a47&user=Jo%C3%A3o+Pedro&userId=b111eee95c&source=-----323fd1808a47---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb111eee95c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomatically-managing-data-pipeline-infrastructures-with-terraform-323fd1808a47&user=Jo%C3%A3o+Pedro&userId=b111eee95c&source=post_page-b111eee95c----323fd1808a47---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----323fd1808a47--------------------------------)
    ·15 分钟阅读·2023年5月2日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F323fd1808a47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomatically-managing-data-pipeline-infrastructures-with-terraform-323fd1808a47&user=Jo%C3%A3o+Pedro&userId=b111eee95c&source=-----323fd1808a47---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F323fd1808a47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomatically-managing-data-pipeline-infrastructures-with-terraform-323fd1808a47&source=-----323fd1808a47---------------------bookmark_footer-----------)![](../Images/62fc203322b755adb5210f9bf185c849.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F323fd1808a47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomatically-managing-data-pipeline-infrastructures-with-terraform-323fd1808a47&source=-----323fd1808a47---------------------bookmark_footer-----------)![](../Images/62fc203322b755adb5210f9bf185c849.png)'
- en: Photo by [EJ Yao](https://unsplash.com/fr/@hojipago?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [EJ Yao](https://unsplash.com/fr/@hojipago?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: A few weeks ago, I wrote a post about [developing a data pipeline using both
    on-premise and AWS tools](https://medium.com/towards-data-science/data-pipeline-with-airflow-and-aws-tools-s3-lambda-glue-18585d269761).
    This post is part of my recent effort in bringing more cloud-oriented data engineering
    posts.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 几周前，我写了一篇关于 [使用本地和AWS工具开发数据管道](https://medium.com/towards-data-science/data-pipeline-with-airflow-and-aws-tools-s3-lambda-glue-18585d269761)
    的文章。这篇文章是我最近努力推出更多云导向数据工程文章的一部分。
- en: 'However, when mentally reviewing this post, I noticed a big problem: **the
    manual work**.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当我在脑海中回顾这篇文章时，我注意到一个大问题：**手动工作**。
- en: Whenever I develop a new project, whether real or fictional, I always try to
    reduce the friction of configuring the environment (install dependencies, configure
    folders, obtain credentials, etc) and that’s why I always use Docker. With it,
    I just pass you a docker-compose.yaml file + a few Dockerfiles and you are capable
    of creating exactly the same environment as me with just one command — docker
    compose up.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我开发一个新项目，无论是真实的还是虚构的，我总是试图减少配置环境的摩擦（安装依赖项、配置文件夹、获取凭据等），这就是为什么我总是使用 Docker
    的原因。通过 Docker，我只需传递一个 docker-compose.yaml 文件 + 几个 Dockerfile，您就能够通过一个命令创建与我完全相同的环境
    —— docker compose up。
- en: 'However, when we want to develop a new data project with cloud tools (S3, Lambda,
    Glue, EMR, etc) Docker can’t help us, as the components need to be instantiated
    in the providers’ infrastructure, and there are two main ways of doing this: Manually
    on the UI or programmatically through service APIs.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当我们想要使用云工具（如 S3、Lambda、Glue、EMR 等）开发新的数据项目时，Docker 无法帮助我们，因为组件需要在提供商的基础设施中实例化，并且有两种主要的方法可以实现这一点：在
    UI 上手动操作或通过服务 API 进行编程。
- en: For example, you can access the AWS UI on your browser, search for S3 and create
    a new bucket manually, or write a code in Python to create this same instance
    making a request on the AWS API.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，您可以在浏览器上访问 AWS UI，搜索 S3 并手动创建一个新的存储桶，或者编写 Python 代码通过 AWS API 创建相同的实例。
- en: '![](../Images/556cd3cc054a57f1b8dce90fba077454.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/556cd3cc054a57f1b8dce90fba077454.png)'
- en: In the post mentioned earlier, I described step-by-step how to create the needed
    components **MANUALLY** through the AWS web interface. The result? Even trying
    to summarize as much as possible (and even omitting parts!), the post ended up
    with 17 min, 7 min more than I usually do, full of PRINTS of which screen you
    should access, where you should click, and which settings to choose.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面提到的帖子中，我详细描述了如何通过 AWS Web 界面**手动**创建所需的组件的步骤。结果如何？即使尽可能简化（甚至省略部分内容！），帖子也耗时
    17 分钟，比我通常所需的多了 7 分钟，充满了说明应访问哪个屏幕，点击哪里以及选择哪些设置的截图。
- en: In addition to being a costly, confusing, and time-consuming process, it is
    still susceptible to human errors, which ends up bringing more headaches and possibly
    even bad surprises in the monthly bill. Definitely an unpleasant process.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 除了成本高、混乱且耗时外，这仍然容易出现人为错误，这可能会在每月账单中带来更多麻烦甚至不愉快的惊喜。绝对是一个令人不愉快的过程。
- en: And this is the exactly kind of problem that **Terraform** comes to solve.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是 **Terraform** 要解决的问题类型。
- en: not sponsored.
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 不是赞助内容。
- en: What is Terraform?
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Terraform 是什么？
- en: '**Terraform is an IaC (Infrastructure as Code) tool** that manages infrastructure
    in cloud providers in an automatic and programmatically manner.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**Terraform 是一种基础设施即代码（IaC）工具**，以自动化和编程方式管理云提供商中的基础设施。'
- en: In Terraform, the desired infrastructures is described using a declarative language
    called HCL (HashiCorp Configuration Language), where the components are specified,
    *e.g.* a S3 bucket named “my-bucket” and an EC2 server with Ubuntu 22 in the us-east-1
    zone.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Terraform 中，期望的基础设施是通过一种称为 HCL（HashiCorp 配置语言）的声明性语言来描述的，其中指定了组件，*例如*一个名为“my-bucket”的
    S3 存储桶以及一个位于 us-east-1 区域、运行 Ubuntu 22 的 EC2 服务器。
- en: The described resources are materialized by Terraform through calls in the cloud
    provider’s service APIs. Beyond creation, it is also capable of destroying and
    updating the infrastructure, adding/removing only the resources needed to move
    from the actual state to the desired state, *e.g.* if 4 instances of EC2 are requested,
    it will create only 2 new instances if 2 others already exist. This behavior is
    achieved because Terraform stores the actual state of the infrastructure in state
    files.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Terraform 通过调用云提供商的服务 API 将描述的资源实现。除了创建之外，它还能够销毁和更新基础设施，仅添加/删除从当前状态转移到期望状态所需的资源，*例如*如果请求创建
    4 个 EC2 实例，则如果已存在 2 个实例，则仅创建 2 个新实例。这种行为是通过 Terraform 将基础设施的实际状态存储在状态文件中来实现的。
- en: Because of this, it's possible to manage a project’s infrastructure in a much
    more agile and secure way, as it removes the manual work needed of configuring
    each individual resource.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，可以更加敏捷和安全地管理项目的基础设施，因为它消除了配置每个单独资源所需的手动工作。
- en: Terraform’s proposal is to be a cloud-agnostic IaC tool, so it uses a standardized
    language to mediate the interaction with the cloud providers’ APIs, removing the
    need of learning how to interact with them directly. Still in this line, HCL language
    also supports variables manipulation and a certain degree of ‘flux control’ (if-statements
    and loops), allowing the use of conditionals and loops in resource creation, e.g.
    create 100 EC2 instances.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Terraform的目标是成为一个与云平台无关的基础设施即代码（IaC）工具，因此它使用标准化的语言来调解与云提供商API的交互，从而不需要学习如何直接与它们交互。在这一点上，HCL语言还支持变量操作和一定程度的‘流控制’（条件语句和循环），允许在资源创建中使用条件和循环，例如，创建100个EC2实例。
- en: Last but not least, Terraform also allows infrastructure versioning, as its
    plain-text files can be easily manipulated by git.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，Terraform还允许基础设施版本控制，因为它的纯文本文件可以被git轻松操作。
- en: The implementation
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施
- en: As mentioned earlier, this post seeks to automate the process of infrastructure
    creation of my previous post.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，本文旨在自动化我之前文章中的基础设施创建过程。
- en: '![](../Images/9e4978df123ccfc0325b619453122674.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9e4978df123ccfc0325b619453122674.png)'
- en: To recap, the project developed aimed at creating a data pipeline to extract
    questions from the Brazillian ENEM (National Exam of High School, on literal translation)
    tests using the PDFs available on the MEC (Ministry of Education) [website](https://www.gov.br/inep/pt-br/areas-de-atuacao/avaliacao-e-exames-educacionais/enem/provas-e-gabaritos).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，开发的项目旨在创建一个数据管道，从巴西的ENEM（国家高中考试，直译）测试中提取问题，使用MEC（教育部）[网站](https://www.gov.br/inep/pt-br/areas-de-atuacao/avaliacao-e-exames-educacionais/enem/provas-e-gabaritos)上提供的PDF。
- en: The process involved three steps, controlled by a local Airflow instance. These
    steps included downloading and uploading the PDF file to S3 storage, extracting
    texts from the PDFs using a Lambda function, and segmenting the extracted text
    into questions using a Glue Job.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程涉及三个步骤，由本地Airflow实例控制。这些步骤包括将PDF文件下载和上传到S3存储，通过Lambda函数从PDF中提取文本，以及使用Glue
    Job将提取的文本分割成问题。
- en: Note that, for this pipeline to work, many AWS components have to be created
    and correctly configured.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，为了使这个管道正常工作，需要创建并正确配置许多AWS组件。
- en: 0\. Setting up the environment
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 0\. 设置环境
- en: All the code used in this project is available in this [GitHub Repository](https://github.com/jaumpedro214/posts).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目中使用的所有代码都可以在这个[GitHub仓库](https://github.com/jaumpedro214/posts)中找到。
- en: You’ll need a machine with Docker and an AWS account.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要一台安装了Docker的机器和一个AWS账户。
- en: The first step is configuring a new AWS IAM user for Terraform, this will be
    the only step executed in the AWS web console.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是为Terraform配置一个新的AWS IAM用户，这将是唯一在AWS网页控制台中执行的步骤。
- en: '**Create a new IAM user with FullAccess to S3, Glue, Lambda, and IAM and generate
    code credentials for it.**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**创建一个对S3、Glue、Lambda和IAM具有完全访问权限的新IAM用户，并为其生成代码凭证。**'
- en: '![](../Images/32738de4887661967fc6bd33ddd06e0e.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/32738de4887661967fc6bd33ddd06e0e.png)'
- en: This is a lot of permission for a single user, so keep the credentials safe.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对一个用户来说大量的权限，所以请妥善保管凭证。
- en: I’m using FullAccess permissions because I wanna make things easier for now,
    but always consider the ‘least privileged’ approach when dealing with credentials.
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我使用了完全访问权限，因为我现在想让事情更简单，但在处理凭证时总是考虑‘最小权限’的原则。
- en: Now, back to the local environment.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，回到本地环境。
- en: '**On the same path** as the *docker-compose.yaml* file, create a *.env* file
    and write your credentials:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在与*docker-compose.yaml*文件相同的路径下，创建一个*.env*文件并写入你的凭证：
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: These variables will be passed to the docker-compose file to be used by Terraform.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这些变量将传递给docker-compose文件供Terraform使用。
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 1\. Create the Terraform file
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 创建Terraform文件
- en: Still on the same folder create a new directory called **terraform**. Inside
    it, create a new file **main.tf**, this will be our main Terraform file.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一个文件夹中，创建一个名为**terraform**的新目录。在其中，创建一个新的文件**main.tf**，这将是我们的主要Terraform文件。
- en: This folder will be mapped inside the container when it runs, so the internal
    Terraform will be able to see this file.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当容器运行时，这个文件夹将被映射到容器内部，这样内部的Terraform就能看到这个文件。
- en: 2\. Configure the AWS Provider
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 配置AWS提供商
- en: The first thing we need to do is to configure the cloud provider used.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事是配置所使用的云提供商。
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This is what a Terraform configuration file looks like — a set of blocks with
    different types, each one with a specific function.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是一个Terraform配置文件的样子——一组具有不同类型的块，每个块都有特定的功能。
- en: The **terraform** block fixes the versions for Terraform itself and for the
    AWS provider.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**terraform** 块固定了 Terraform 本身和 AWS 提供程序的版本。'
- en: A **variable** is exactly what the name suggests — a value assigned to a name
    that can be referenced throughout the code.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**变量** 正如名称所示——一个分配给名称的值，可以在代码中引用。'
- en: As you probably already noticed, our variables don’t have a value assigned to
    them, so what’s going on? The answer is back in the docker-compose.yaml file,
    the value of these variables was set using environment variables in the system.
    When a variable value is not defined, Terraform will look at the value of the
    environment variable TF_VAR_<var_name> and use its value. I’ve opted for this
    approach to avoid hard-coding the keys.
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 正如你可能已经注意到的，我们的变量没有分配值，那么发生了什么？答案在 docker-compose.yaml 文件中，这些变量的值是通过系统中的环境变量设置的。当变量值未定义时，Terraform
    会查看环境变量 TF_VAR_<var_name> 的值并使用它。我选择了这种方法来避免硬编码密钥。
- en: The **provider** block is also self-explanatory — It references the cloud provider
    we’re using and configures its credentials. We set the provider’s arguments (access_key,
    secret_key, and region) with the variables defined earlier, referenced with the
    **var.<var_name>** notation.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**provider** 块也是显而易见的——它引用了我们使用的云提供商并配置了其凭据。我们用之前定义的变量设置提供程序的参数（access_key、secret_key
    和 region），并用 **var.<var_name>** 符号引用这些变量。'
- en: 'With this block defined, run:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 定义好这个块之后，运行：
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: To set up Terraform.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置 Terraform。
- en: '3\. Creating our first resource: The S3 bucket'
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 创建我们的第一个资源：S3 存储桶
- en: Terraform uses the **resource** block to reference infrastructure components
    such as S3 buckets and EC2 instances, as well as actions like granting permissions
    to users or uploading files to a bucket.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Terraform 使用 **resource** 块来引用基础设施组件，如 S3 存储桶和 EC2 实例，以及授予用户权限或将文件上传到存储桶等操作。
- en: The code below creates a new S3 bucket for our project.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码为我们的项目创建一个新的 S3 存储桶。
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'A **resource** definition follows the syntax:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**resource** 定义遵循以下语法：'
- en: '[PRE5]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In the case above, “*aws_s3_bucket*” is the resource type, “*enem-bucket-terraform-jobs*”
    is the resource name, used to reference this resource in the file (it is not the
    bucket name in the AWS infrastructure). The argument *bucket=“enem-bucket-terraform-jobs”*
    assigns a name to our bucket.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述情况下，“*aws_s3_bucket*”是资源类型，“*enem-bucket-terraform-jobs*”是资源名称，用于在文件中引用此资源（它不是
    AWS 基础设施中的存储桶名称）。参数 *bucket=“enem-bucket-terraform-jobs”* 为我们的存储桶分配了一个名称。
- en: 'Now, with the command:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用以下命令：
- en: '[PRE6]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Terraform will compare the current state of the infrastructure and infer what
    needs to be done to achieve the desired state described in the *main.tf* file.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Terraform 将比较当前的基础设施状态，并推断出需要做什么以实现 *main.tf* 文件中描述的期望状态。
- en: '![](../Images/ae83b2fbae13c9abd3147dc8b37bfa58.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ae83b2fbae13c9abd3147dc8b37bfa58.png)'
- en: Because this bucket still does not exist, Terraform will plan to create it.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这个存储桶还不存在，所以 Terraform 会计划创建它。
- en: To apply Terraform’s plan, run
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 要应用 Terraform 的计划，运行
- en: '[PRE7]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/1d873cde7308f28ae0a43ff09f80950e.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1d873cde7308f28ae0a43ff09f80950e.png)'
- en: And, with only these few commands, our bucket is already created.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 仅凭这几条命令，我们的存储桶已经创建好了。
- en: '![](../Images/87b7aa95c4c7680037fd00ca21c7931e.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/87b7aa95c4c7680037fd00ca21c7931e.png)'
- en: Easy, right?
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 很简单，对吧？
- en: 'To destroy the bucket, just type:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 要销毁存储桶，只需输入：
- en: '[PRE8]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/26f46fc9e91c4fd0764cf47b9e65bbe2.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/26f46fc9e91c4fd0764cf47b9e65bbe2.png)'
- en: And Terraform takes care of the rest.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 然后 Terraform 会处理其余的部分。
- en: 'These are the basic commands that will follow us until the end of the post:
    **plan**, **apply**, **destroy**. From now on, all that we’re going to do is configure
    the *main.tf* file, adding the resources needed to materialize our data pipeline.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是将伴随我们直到帖子结束的基本命令：**plan**、**apply**、**destroy**。从现在开始，我们要做的就是配置 *main.tf*
    文件，添加实现我们数据管道所需的资源。
- en: '4\. Configuring the Lambda Function part I: Roles and permissions'
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 配置 Lambda 函数第一部分：角色和权限
- en: Now on the Lambda Function definition.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在进入 Lambda 函数定义部分。
- en: This was one of the trickiest parts of my previous post because, by default,
    Lambda functions already need a set of basic permissions and, on top of that,
    we had also to give it read and write permissions to the S3 bucket previously
    created.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我之前帖子中最棘手的部分之一，因为默认情况下，Lambda 函数已经需要一组基本权限，此外，我们还必须给它对之前创建的 S3 存储桶的读写权限。
- en: First of all, we must create a new IAM role.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们必须创建一个新的 IAM 角色。
- en: '[PRE9]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: When developing these things, I strongly suggest that you first ask what you
    want in ChatGPT, GitHub Copilot, or any other LLM friend and then check the provider’s
    documentation on how this type of resource works.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发这些东西时，我强烈建议你首先在ChatGPT、GitHub Copilot或其他LLM朋友中询问你需要什么，然后查看提供商的文档，了解这种类型的资源如何工作。
- en: The code above creates a new IAM role and allows AWS Lambda Functions to assume
    it. The next step is to attach the Lambda Basic Execution policy to this role
    to allow the Lambda Function to execute without errors.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码创建了一个新的IAM角色，并允许AWS Lambda函数假设它。下一步是将Lambda Basic Execution策略附加到该角色，以允许Lambda函数无错误地执行。
- en: '[PRE10]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The nice thing to note in the code above is that we can **reference resource
    attributes** **and pass them as arguments in the creation of new resources**.
    In the case above, instead of hard-coding the ‘*role’* argument with the name
    of the previously created role ‘*lambda_execution_role_terraform*’, we can reference
    this attribute using the syntax:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 上面代码中值得注意的一点是，我们可以**引用资源属性**并**将它们作为参数传递到新资源的创建中**。在上述案例中，我们可以使用以下语法引用属性，而不是将‘*role’*参数硬编码为之前创建的角色‘*lambda_execution_role_terraform*’的名称：
- en: <*resource_type*>.<*resource_name*>.<*attribute>*
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: <*resource_type*>.<*resource_name*>.<*attribute>*
- en: If you take some time to look into the Terraform documentation of a resource,
    you’ll note that it has *arguments* and *attributes*. **Arguments** are what you
    pass in order to create/configure a new resource and **attributes** are read-only
    properties about this resource available after its creation.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你花时间查看资源的Terraform文档，你会注意到它有*arguments*和*attributes*。**Arguments**是你用来创建/配置新资源的参数，**attributes**是关于资源的只读属性，在资源创建后可用。
- en: Because of this, attributes are used by Terraform to implicitly manage dependencies
    between resources, establishing the appropriate order of their creation.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，attributes被Terraform用来隐式管理资源之间的依赖关系，建立它们创建的适当顺序。
- en: The code below creates a new access policy for our S3 bucket, allowing basic
    CRUD operations on it.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码为我们的S3桶创建一个新的访问策略，允许对其进行基本的CRUD操作。
- en: '[PRE11]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Again, instead of hard-coding the bucket’s ARN, we can reference this attribute
    using *aws_s3_bucket.enem-data-bucket.arn.*
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们可以使用*aws_s3_bucket.enem-data-bucket.arn*引用这个属性，而不是硬编码桶的ARN。
- en: With the Lambda role correctly configured, we can finally create the function
    itself.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在正确配置Lambda角色之后，我们终于可以创建函数本身。
- en: '[PRE12]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The *lambda_function.zip* file is a compressed folder that must have a *lambda_function.py*
    file with a *lambda_handler(event, context)* function inside. It must be on the
    same path as the main.tf file.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '*lambda_function.zip*文件是一个压缩文件夹，其中必须包含一个*lambda_function.py*文件，文件内有一个*lambda_handler(event,
    context)*函数。它必须与main.tf文件在同一路径上。'
- en: '![](../Images/55218ad3da8f5fd729ad85c35abc6893.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/55218ad3da8f5fd729ad85c35abc6893.png)'
- en: '[PRE13]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '5\. Configuring the Lambda Function part II: Attaching a trigger'
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 配置Lambda函数第II部分：附加触发器
- en: 'Now, we need to configure a trigger for the Lambda Function: It must execute
    every time a new PDF is uploaded to the bucket.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要为Lambda函数配置触发器：它必须在每次新PDF上传到桶时执行。
- en: '[PRE14]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This is a case where we must specify an **explicit dependency between resources**,
    as the “*bucket_notification*” resource needs to be created after the “*allow_bucket_execution*”.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个需要指定**资源之间显式依赖关系**的情况，因为“*bucket_notification*”资源需要在“*allow_bucket_execution*”之后创建。
- en: This can be easily achieved by using the *depends_on* argument.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过使用*depends_on*参数轻松实现。
- en: 'And we’re done with the lambda function, just run:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了lambda函数的设置，只需运行：
- en: '[PRE15]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: And the Lambda Function will be created.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda函数将被创建。
- en: '![](../Images/e8fce41371bbdd862c956c35f59f362e.png)![](../Images/1f2ebfd3ddd742f95516c69670a8bcbb.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e8fce41371bbdd862c956c35f59f362e.png)![](../Images/1f2ebfd3ddd742f95516c69670a8bcbb.png)'
- en: 6\. Adding a module to the Glue job
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 向Glue作业添加模块
- en: Our *main.tf* file is getting pretty big, and remember that this is just a simple
    data pipeline. To enhance the organization and reduce its size, we can use the
    concept of **modules**.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的*main.tf*文件变得相当庞大，而且记住这只是一个简单的数据管道。为了增强组织性并减少其大小，我们可以使用**模块**的概念。
- en: A **module** is a set of resources grouped in a separate file that can be referenced
    and reused by other configuration files. Modules enable us to abstract complex
    parts of the infrastructure to make our code more manageable, reusable, organized,
    and *modular.*
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 一个**模块**是一组在单独文件中分组的资源，可以被其他配置文件引用和重用。模块使我们能够抽象复杂的基础设施部分，使我们的代码更加可管理、可重用、组织良好，并且*模块化*。
- en: So, instead of coding all the resources needed to create our Glue job in the
    *main.tf* file, we’ll put them inside a **module.**
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们不会在 *main.tf* 文件中编写创建 Glue 作业所需的所有资源，而是将它们放在一个 **模块** 中。
- en: In the ./*terraform* folder, create a new folder ‘*glue*’ with a *glue.tf* file
    inside it.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在 ./*terraform* 文件夹中，创建一个名为 ‘*glue*’ 的新文件夹，其中包含一个 *glue.tf* 文件。
- en: '![](../Images/3375413fdca889e5377830c6a4b95a74.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3375413fdca889e5377830c6a4b95a74.png)'
- en: 'Then add a new S3 bucket resource in the file:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 然后在文件中添加一个新的 S3 存储桶资源：
- en: '[PRE16]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Back in *main.tf*, just reference this module with:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 回到 *main.tf*，只需引用这个模块：
- en: '[PRE17]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'And reinitialize terraform:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 并重新初始化 terraform：
- en: '[PRE18]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Terraform will restart its backend and initialize the module with it.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Terraform 将重新启动其后端并用它初始化模块。
- en: '![](../Images/ee2d3d65250fa77aff8cd9899da16247.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ee2d3d65250fa77aff8cd9899da16247.png)'
- en: 'Now, if we run terraform plan, it should include this new bucket in the creation
    list:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们运行 terraform plan，它应该将这个新的存储桶包含在创建列表中：
- en: '![](../Images/92f1e71972ce18c1a8dfea2c35acfb96.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/92f1e71972ce18c1a8dfea2c35acfb96.png)'
- en: Using this **module**, we’ll be able to encapsulate all the logic of creating
    the job in a single external file.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个 **模块**，我们可以将创建作业的所有逻辑封装在一个单独的外部文件中。
- en: A requirement of AWS Glue jobs is that their job files are stored in an S3 bucket,
    and that’s why we created “*enem-bucket-terraform-jobs*”. Now, we must upload
    the job’s file itself.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Glue 作业的一个要求是它们的作业文件存储在 S3 存储桶中，这就是为什么我们创建了“*enem-bucket-terraform-jobs*”。现在，我们必须上传作业文件本身。
- en: '![](../Images/cb3a6357ab4ecd7c13ac4410833e8fa5.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cb3a6357ab4ecd7c13ac4410833e8fa5.png)'
- en: 'In the *terraform* path*,* I’d included a *myjob.py* file, it is just an empty
    file used to simulate this behavior. To upload a new object to a bucket, just
    use the “aws_s3_object” resource:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *terraform* 路径*，*我包含了一个 *myjob.py* 文件，这只是一个用于模拟此行为的空文件。要向存储桶上传新对象，只需使用“aws_s3_object”资源：
- en: '[PRE19]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: From now on, it is just a matter of implementing the Glue role and creating
    the job itself.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在开始，只需实现 Glue 角色并创建作业本身。
- en: '[PRE20]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '**Not so fast**. We must assure that this job has the same read and write permissions
    to the bucket “*enem-data-bucket*” as the Lambda Function, *i.e.* we need to attach
    the *aws_iam_policy.s3_access_policy* to its role*.*'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '**不要那么快**。我们必须确保这个作业对“*enem-data-bucket*”桶具有与 Lambda 函数相同的读写权限，*即*，我们需要将 *aws_iam_policy.s3_access_policy*
    附加到其角色*。*'
- en: But, because this policy was defined in the main file, **we cannot reference
    it directly in our module**.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，由于该策略是在主文件中定义的，**我们不能直接在我们的模块中引用它**。
- en: '[PRE21]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In order to achieve this behavior, we must pass the *access policy arn* as an
    **argument** to the **module**, and that’s pretty simple.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这种行为，我们必须将 *access policy arn* 作为 **参数** 传递给 **模块**，这非常简单。
- en: First, in the *glue.tf* file, create a new variable to receive the value.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在 *glue.tf* 文件中，创建一个新的变量来接收这个值。
- en: '[PRE22]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Go back to the main file and, in the module reference, pass a value to this
    variable.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 返回主文件，在模块引用中传递一个值给这个变量。
- en: '[PRE23]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Finally, in the glue file, use the value of the variable in the resource.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在 glue 文件中，使用变量的值在资源中。
- en: '[PRE24]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Now, take a minute to think about the power of what we had just done. With **modules**
    and **arguments**, we can create **fully parametrized** **complex infrastructures**.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，花点时间思考我们刚刚完成的事情的威力。通过 **模块** 和 **参数**，我们可以创建**完全参数化的复杂基础设施**。
- en: The code above doesn’t just create a specific job for our pipeline. By just
    changing the value of the *enem-data-bucket-access-policy-arn* variable, we can
    create a new job to process data from an entirely different bucket.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码不仅仅是为我们的流水线创建了一个特定的作业。只需更改 *enem-data-bucket-access-policy-arn* 变量的值，我们就可以创建一个新的作业来处理来自完全不同存储桶的数据。
- en: And that logic applies to **anything** you want. It’s possible, for example,
    to simultaneously create a complete infrastructure for a project for the development,
    testing, and production environments, using just variables to alternate between
    them.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这种逻辑适用于你想要的 **任何** 东西。例如，可以使用变量同时为开发、测试和生产环境创建一个完整的项目基础设施。
- en: 'Without further talking, all that rests is to create the Glue job itself, and
    there is no novelty in that:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 没有多言，剩下的就是创建 Glue 作业本身，这并不是什么新鲜事：
- en: '[PRE25]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: And our infrastructure is done. Run **terraform apply** to create the remaining
    resources.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的基础设施就完成了。运行 **terraform apply** 创建剩余的资源。
- en: '[PRE26]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![](../Images/8758e74ee515b58b4122caba119e4357.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8758e74ee515b58b4122caba119e4357.png)'
- en: And **terraform destroy** to get rid of everything.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 并且 **terraform destroy** 来清除所有内容。
- en: '[PRE27]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![](../Images/14cc69bea1ee680d9227381852cf0921.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/14cc69bea1ee680d9227381852cf0921.png)'
- en: Conclusion
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: I met Terraform a few days after publishing my 2nd post about creating data
    pipelines using cloud providers, and it blew my mind. I instantly thought about
    all the manual work that I did to set up the project, all the prints captured
    to showcase the process and all the undocumented details that will haunt my nightmares
    when I need to reproduce the process.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我在发布有关使用云服务提供商创建数据管道的第二篇文章几天后，认识了**Terraform**，它彻底改变了我的想法。我立刻想到了为了设置项目所做的所有手动工作，展示过程的所有截图以及在需要重新生成过程时会困扰我梦魇的所有未记录细节。
- en: Terraform solves all these problems. It is simple, easy to set up, and easy
    to use, all it needs are a few .*tf* files along with the providers’ credentials
    and we’re ready to go.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: Terraform 解决了所有这些问题。它简单易用，设置也简便，只需要一些 .*tf* 文件和提供者的凭据，我们就可以立即开始。
- en: Terraform tackles that kind of problem that people usually don’t are so *excited*
    to think about. When developing data products, we all think about performance,
    optimization, delay, quality, accuracy, and other data-specific or domain-specific
    aspects of our product.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: Terraform 解决了人们通常不太*激动*去思考的那种问题。在开发数据产品时，我们都关注性能、优化、延迟、质量、准确性以及产品的其他数据特定或领域特定方面。
- en: Don’t get me wrong, we all study to apply our better mathematical and computational
    knowledge to solve these problems, but we also need to think about critical aspects
    of the *development process* of our product, like reproducibility, maintainability,
    documentation, versioning, integration, modularization, and so on.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 不要误会，我们都学习应用我们更好的数学和计算知识来解决这些问题，但我们也需要考虑我们产品*开发过程*的关键方面，如可复现性、可维护性、文档化、版本控制、集成、模块化等等。
- en: These are aspects that our *software engineer* colleagues have been concerned
    about for a long time, so we don’t have to reinvent the wheel, just learn one
    thing or two from their best practices.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我们*软件工程师*同事长期关注的方面，因此我们不必重复造轮子，只需从他们的最佳实践中学习一两件事情即可。
- en: That’s why I always use Docker in my projects and that’s also why I will probably
    add Terraform in my basic toolset.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么我在我的项目中始终使用 Docker，并且这也是为什么我可能会将 Terraform 添加到我的基本工具集中的原因。
- en: I hope this post helped you in understanding this tool — Terraform — including
    its objectives, basic functionalities, and practical benefits. As always, I’m
    not an expert in any of the subjects addressed in this post, and I strongly recommend
    further reading, see some references below.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 希望本文帮助您理解这个工具 — Terraform — 包括其目标、基本功能和实际好处。与往常一样，我对本文提到的任何主题都不是专家，并强烈推荐进一步阅读，请参考以下参考资料。
- en: Thank you for reading! ;)
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 谢谢你的阅读！ ;)
- en: References
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: All the code is available in [this GitHub repository](https://github.com/jaumpedro214/posts).
  id: totrans-166
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 所有代码都可以在[此 GitHub 仓库](https://github.com/jaumpedro214/posts)中找到。
- en: Data used — [ENEM PDFs](https://www.gov.br/inep/pt-br/areas-de-atuacao/avaliacao-e-exames-educacionais/enem/provas-e-gabaritos),
    [CC BY-ND 3.0], MEC-Brazilian Gov.
  id: totrans-167
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用的数据 — [ENEM PDFs](https://www.gov.br/inep/pt-br/areas-de-atuacao/avaliacao-e-exames-educacionais/enem/provas-e-gabaritos)，[CC
    BY-ND 3.0]，巴西政府教育部。
- en: All the images are created by the Author, unless otherwise specified.
  id: totrans-168
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 所有图片由作者创建，除非另有说明。
- en: '[1] *Add trigger to AWS Lambda functions via Terraform*. Stack Overflow. [Link](https://stackoverflow.com/questions/68245765/add-trigger-to-aws-lambda-functions-via-terraform).'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] *通过 Terraform 为 AWS Lambda 函数添加触发器*。Stack Overflow。[链接](https://stackoverflow.com/questions/68245765/add-trigger-to-aws-lambda-functions-via-terraform)。'
- en: '[2] *AWSLambdaBasicExecutionRole — AWS Managed Policy*. [Link](https://docs.aws.amazon.com/aws-managed-policy/latest/reference/AWSLambdaBasicExecutionRole.html).'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] *AWSLambdaBasicExecutionRole — AWS 管理策略*。[链接](https://docs.aws.amazon.com/aws-managed-policy/latest/reference/AWSLambdaBasicExecutionRole.html)。'
- en: '[3] Brikman, Y. (2022, October 11). Terraform tips & tricks: loops, if-statements,
    and gotchas. [*Medium*](https://blog.gruntwork.io/terraform-tips-tricks-loops-if-statements-and-gotchas-f739bbae55f9)*.*
    [4] *Create Resource Dependencies | Terraform | HashiCorp Developer*. [Link](https://developer.hashicorp.com/terraform/tutorials/configuration-language/dependencies).'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Brikman, Y. (2022年10月11日)。Terraform 技巧与窍门：循环、条件语句和陷阱。[*Medium*](https://blog.gruntwork.io/terraform-tips-tricks-loops-if-statements-and-gotchas-f739bbae55f9)*。*[4]
    *创建资源依赖关系 | Terraform | HashiCorp Developer*。[链接](https://developer.hashicorp.com/terraform/tutorials/configuration-language/dependencies)。'
- en: '[5] TechWorld with Nana. (2020, July 4). *Terraform explained in 15 mins |
    Terraform Tutorial for Beginners* [Video]. [YouTube](https://www.youtube.com/watch?v=l5k1ai_GBDE).'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] TechWorld with Nana. (2020年7月4日)。*在15分钟内解释 Terraform | Terraform初学者教程*
    [视频]。[YouTube](https://www.youtube.com/watch?v=l5k1ai_GBDE)。'
- en: '[6] *Terraform Registry*. AWS provider. [Link](https://registry.terraform.io/providers/hashicorp/aws/latest).'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] *Terraform Registry*。AWS 提供者。 [Link](https://registry.terraform.io/providers/hashicorp/aws/latest)。'
