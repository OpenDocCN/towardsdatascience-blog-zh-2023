- en: An Introduction to Covariance and Correlation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/an-introduction-to-covariance-and-correlation-52d613a0ceb4?source=collection_archive---------0-----------------------#2023-03-25](https://towardsdatascience.com/an-introduction-to-covariance-and-correlation-52d613a0ceb4?source=collection_archive---------0-----------------------#2023-03-25)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A gentle introduction to some very common measures of association
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@dataforyou?source=post_page-----52d613a0ceb4--------------------------------)[![Rob
    Taylor, PhD](../Images/5e4e86da7b77404ed42d00a60ea5eacf.png)](https://medium.com/@dataforyou?source=post_page-----52d613a0ceb4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----52d613a0ceb4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----52d613a0ceb4--------------------------------)
    [Rob Taylor, PhD](https://medium.com/@dataforyou?source=post_page-----52d613a0ceb4--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F98de080592fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-covariance-and-correlation-52d613a0ceb4&user=Rob+Taylor%2C+PhD&userId=98de080592fc&source=post_page-98de080592fc----52d613a0ceb4---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----52d613a0ceb4--------------------------------)
    ·6 min read·Mar 25, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F52d613a0ceb4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-covariance-and-correlation-52d613a0ceb4&user=Rob+Taylor%2C+PhD&userId=98de080592fc&source=-----52d613a0ceb4---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F52d613a0ceb4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-covariance-and-correlation-52d613a0ceb4&source=-----52d613a0ceb4---------------------bookmark_footer-----------)![](../Images/315d5f3a5cac77efb3e1c1e1b233675e.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Richard Horvath](https://unsplash.com/@orwhat?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Understanding associations between variables is crucial for building accurate
    models and making informed decisions. Statistics can be a messy business; full
    of noise and random variation. Yet, by identifying the patterns and connections
    between variables, we can draw insights into how varying features influence each
    other. For the data scientist and data analyst, such associations are exceedingly
    useful, particularly when it comes to analysis and model building.
  prefs: []
  type: TYPE_NORMAL
- en: With this in mind, covariance and correlation are two fundamental statistical
    concepts that describe the relationship between variables. Though they are similar
    in nature, they do differ in how each characterizes associations. But, as we’ll
    discover shortly, these differences are more cosmetic than they are substantive,
    and they're really just different sides of the same coin. So today we’ll explore
    what covariance and correlation are, how they are calculated, and what they mean.
  prefs: []
  type: TYPE_NORMAL
- en: Covariance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To motivate this discussion, suppose we have two random variables *X* and *Y*
    that we’re particularly interested in. I’m not going to make any specific assumptions
    about *how* they’re distributed except to say they are jointly distributed according
    to some function *f*(*x*, *y*). In such cases, it’s interesting to consider the
    extent to which *X* and *Y* vary together, and this is precisely what *covariance*
    measures: it is a measure of the *joint variability* of two random variables.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we treat *X* and *Y* as continuous random variables then the covariance
    may be expressed as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c8105cc862bf0c462b003a505c3572bd.png)'
  prefs: []
  type: TYPE_IMG
- en: Definition of covariance (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: 'The integrals here make this equation look more intimidating than it actually
    is, and all that’s happening here is that an average is being computed over the
    joint space. This fact can be made clearer by using the expected value operator,
    **E**[⋅], which produces a more palatable mathematical expression for covariance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02c35935bbc7b3ddd47c93f7748f9dc8.png)'
  prefs: []
  type: TYPE_IMG
- en: Definition for covariance using expectation operator (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: 'So, what we can see here is that covariance is an expectation (or average)
    taken over the product of the mean-centered *X* and *Y* variables. In fact, this
    can be simplified even further because expectations have rather nice linearity
    properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c13b23277c410c99ab1feb64825ecd11.png)'
  prefs: []
  type: TYPE_IMG
- en: Using linearity of expectations to further simplify the definition of covariance
    (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now see that the covariance is just the mean of the product of the variables
    minus the product of their means. Also, here’s a fun fact: the *variance* is a
    special case of covariance and is simply the covariance of a variable with itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eb0e83a0a709d7c156966309082bc930.png)'
  prefs: []
  type: TYPE_IMG
- en: The covariance of a variable with itself is just the variance (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: 'Fundamentally, covariance is a property of any joint probability distribution
    and is a population parameter in its own right. This means that if we only have
    a sample of *X* and *Y*, we could compute the sample covariance using the following
    formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e8346267a57e2e6ddb211f104f6b710e.png)'
  prefs: []
  type: TYPE_IMG
- en: Sample covariance (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: Okay, but what does covariance mean, in practice?
  prefs: []
  type: TYPE_NORMAL
- en: 'Simply, covariance measures the extent to which the values of one variable
    are related to the values of another variable, which can either be positive or
    negative. A *positive* covariance indicates that the two variables tend to move
    in the same direction. For example, if large values of *X* tend to coincide with
    the large values of *Y*, then the covariance is positive. The same applies if
    lower values coincide, too. However, a *negative* covariance indicates that values
    tend to move in opposite directions: this would occur if large values of *X* correspond
    with low values of *Y*, for example.'
  prefs: []
  type: TYPE_NORMAL
- en: A useful property of covariance is that its sign describes the tendency of the
    *linear relationship* between *X* and *Y.* That being said, the actual units it’s
    expressed in are somewhat less useful. Recall that we’re taking products between
    *X* and *Y* so the measure itself is also in units of *X* × *Y.* This can make
    comparisons between data difficult because the scale of measurement matters.
  prefs: []
  type: TYPE_NORMAL
- en: Correlation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'What we most often refer to as *correlation* is measured using Pearson’s product-moment
    correlation coefficient, which is conventionally denoted using *ρ*. Now, if you
    were thinking that covariance sounds a lot like correlation, you’re not wrong.
    And that’s because the correlation coefficient is just a *normalized* version
    of the covariance, where the normalizing factor is the product of the standard
    deviations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f3aeb215df8353cd811984e6425fa05f.png)'
  prefs: []
  type: TYPE_IMG
- en: Pearson’s product moment correlation coefficient (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also estimate the correlation coefficient from data using the following
    formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3ba8bd89465d029d2a7f432cfac4e1c3.png)'
  prefs: []
  type: TYPE_IMG
- en: Sample correlation coefficient (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: The upshot of this normalization is that the correlation coefficient can only
    take on values between -1 and 1, with -1 indicating a perfect negative correlation,
    1 indicating a perfect positive correlation, and 0 denoting no correlation. In
    this way, it measures both the strength and direction of the relationship between
    two variables. What’s nice about this is that the correlation coefficient is a
    *standardized measure*, which means that it is agnostic about the scale of the
    variables involved. This solves an intrinsic issue with covariance, making it
    much easier to compare correlations between different sets of variables.
  prefs: []
  type: TYPE_NORMAL
- en: However, while the correlation coefficient estimates the strength of a relationship,
    it cannot fully characterize the data. Anscombe’s quartet provides a very good
    example of this, showing how different patterns in data yield identical correlation
    coefficients. Ultimately, Pearson’s correlation coefficient only provides a full
    characterization if the data are multivariate normal. If this is not true, then
    the correlation coefficient is only indicative and needs to be considered along
    with a visual inspection of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Covariance, Correlation, & Independence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s suppose that the random variables *X* and *Y* are statistically independent.
    Under the independence assumption, it follows that the expected value of *X* and
    *Y* is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6639cad2183ea41650c9cbefaa783007.png)'
  prefs: []
  type: TYPE_IMG
- en: The expectation of two independent random variables (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: If we plug this into the expression for the covariance we find that
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4c6838cac37318ca39e46159044c9948.png)'
  prefs: []
  type: TYPE_IMG
- en: Covariance of independent random variables (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, random variables that are independent have zero covariance, which
    further implies that these variables are *uncorrelated*. However, if we find that
    two variables are uncorrelated — i.e., they have a correlation coefficient of
    zero — we cannot necessarily assume that they are independent. Fundamentally,
    covariance and correlation measure *linear* dependency, so all we can say is that
    the variables are not *linearly* related. It’s entirely possible that the variables
    are non-linearly related, but covariance and correlation cannot detect these types
    of relationships.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate this fact we can lean on a classic counterexample that goes as
    follows. Suppose *X* is a random variable that has some distribution *f*(*x*)
    that is symmetric around zero. This implies that for all *x* we have that *f*(*-x*)
    = *f*(*x*) which further implies the following is true:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5b9f4cb3b96759f55e500f3bd098f816.png)'
  prefs: []
  type: TYPE_IMG
- en: The symmetry condition (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: 'Given this symmetry condition, the expectation of *X* is therefore:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/07bd6ada549e038350a4fd463f49b489.png)'
  prefs: []
  type: TYPE_IMG
- en: The expectation for a symmetric distribution (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: 'If we now create a dependency between *X* and *Y* such that *Y* = *X²* then
    we know what *Y* must be for any given value of *X*. However, if we examine the
    covariance between *X* and *Y* we find that:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bcacd4b7f2c0c6bedf07b4d8279828d4.png)'
  prefs: []
  type: TYPE_IMG
- en: Covariance of two variables that are non-linearly related (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: What this demonstrates is that, while *X* and *Y* are clearly dependent, the
    covariance is zero because the relationship is non-linear. There is one special
    case that you should be aware of, though. If *X* and *Y* are each normally distributed
    variables then a correlation coefficient of zero *does* imply independence.
  prefs: []
  type: TYPE_NORMAL
- en: Related Content
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Multicollinearity: Problem, or Not?](https://medium.com/towards-data-science/multicollinearity-problem-or-not-d4bd7a9cfb91)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thanks for reading!
  prefs: []
  type: TYPE_NORMAL
- en: If you enjoyed this post and would like to stay up to date then please consider
    [following me on Medium.](https://medium.com/@dataforyou) This will ensure you
    don’t miss out on any new content.
  prefs: []
  type: TYPE_NORMAL
- en: To get unlimited access to all content consider signing up for a [Medium subscription](https://medium.com/membership).
  prefs: []
  type: TYPE_NORMAL
- en: You can also follow me on [Twitter](https://twitter.com/dataforyounz), [LinkedIn](https://www.linkedin.com/in/dataforyou/),
    or check out my [GitHub](https://github.com/dataforyounz) if that’s more your
    thing 😉
  prefs: []
  type: TYPE_NORMAL
