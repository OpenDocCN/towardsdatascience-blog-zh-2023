# 生成式人工智能负责任使用的紧迫性

> 原文：[`towardsdatascience.com/the-urgent-need-for-responsible-use-of-generative-ai-d3134605267f`](https://towardsdatascience.com/the-urgent-need-for-responsible-use-of-generative-ai-d3134605267f)

## 为什么规模、个性化、来源不明和生成内容的传播要求我们立即行动

[](https://heiko-hotz.medium.com/?source=post_page-----d3134605267f--------------------------------)![Heiko Hotz](https://heiko-hotz.medium.com/?source=post_page-----d3134605267f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d3134605267f--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----d3134605267f--------------------------------) [Heiko Hotz](https://heiko-hotz.medium.com/?source=post_page-----d3134605267f--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d3134605267f--------------------------------) ·阅读时间 6 分钟·2023 年 8 月 7 日

--

![](img/f73c65500922a3b7db0293a32e36c03e.png)

照片由 [Google DeepMind](https://unsplash.com/@googledeepmind?utm_source=medium&utm_medium=referral) 提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

# 这是什么内容？

“你认为负责任的生成式人工智能（GenAI）为什么重要且紧迫？”这是政策制定者、研究人员、记者和关注的公民们今天提出的问题。生成式人工智能的快速进展吸引了公众的想象力，但也提出了紧迫的伦理问题。像 ChatGPT、Bard 和 Stable Diffusion 这样的模型展示了技术的创造潜力——但在错误的手中，这些相同的能力可能会在前所未有的规模上滋生虚假信息和操控。与以往的技术不同，生成式人工智能使得创造高度个性化、特定背景的合成媒体成为可能，这些媒体很难被验证为虚假。这带来了新的社会风险和复杂的治理挑战。

在这篇博客文章中，我将深入探讨四个方面（规模与速度、个性化、来源不明、传播）来区分这个新纪元的生成式人工智能（GenAI）与以往的时代，并强调为什么现在是关注人工智能伦理和负责任使用的正确时机。在这篇文章中，我旨在通过突出关键方面来回答“为什么是现在？”这个问题。潜在的解决方案将在随后的文章中探讨。

# 为什么这很重要？

负责任的 GenAI 不仅仅是一个与技术专家相关的假设性问题。这是一个影响我们所有公民的问题，我们在日益复杂的信息生态系统中航行。我们如何在一个我们的眼睛和耳朵可能被欺骗的世界中保持信任和联系？如果任何人都可以制作引人注目却完全虚假的现实，社会如何达成共享的真理？如果不加以控制，GenAI 的滥用将威胁到诚信、同情和人类尊严等基础价值观。但如果我们迅速而集体地实施伦理 AI 设计，我们可以实现生成技术在创造力、联系和社会公益方面的巨大潜力。通过发声和传播意识，我们可以影响 AI 的发展方向。

# 规模和速度

生成模型使得以惊人的规模、前所未有的速度和简易性创建逼真的虚假内容成为可能。一个人只需简单的提示和点击即可生成无尽的定制音频、视频、图像和文本。这引入了制造操控内容的全新效率和产量水平。人类团队无法与全天候生成无尽定制虚假内容的 AI 系统竞争。只要有足够的计算能力，恶意行为者就可以通过纯粹的人工虚假量淹没社交网络，完全主导真实的声音。随着生成模型变得更易获得和更具说服力，组织大规模虚假信息活动不再需要太多专业知识或资源。

这当然不是一个新现象。例如，Twitter 机器人已经存在相当长时间，它们大约占所有推文的[25%](https://www.businessinsider.com/twitter-bots-comprise-less-than-5-but-tweet-more-2022-9)，即[每天约 2.15 亿条推文](https://www.businessdit.com/number-of-tweets-per-day/)。但随着 GenAI 的进步，区分机器人生成内容和人类内容将变得越来越具有挑战性。

# 个性化

GenAI 可以制作精准利用个体脆弱性和经历的内容。这使得心理操控比泛泛的虚假信息更为强大。设计得极具个人背景共鸣的虚假信息通过破坏共享的真理和现实观念来颠覆人类话语。当任何人都可以被灌输自己独特的一套 AI 制造的“事实”时，社会如何达成共识？这种个性化风险会导致两极化和部落主义，侵蚀群体之间的同情心和联系。

这当然是在即将到来的 2024 年美国大选背景下的热门话题。例如，在 2023 年 5 月，[特朗普在他的社交媒体平台 Truth Social 上分享了一段伪造的视频](https://news.yahoo.com/trump-shares-fake-video-anderson-145621081.html)，该视频中是 CNN 主播安德森·库珀。路透社深刻地[指出](https://www.reuters.com/article/usa-election-ai-idCAKBN2XL0IS)：

> 欢迎来到美国 2024 年总统竞选，这里的现实似乎变得难以把握。

# 来源

与早期的 Photoshop 等技术不同，通过法医分析验证生成伪造品极为困难。模糊的来源使恶意行为者获得了似是而非的辩解权和侵蚀客观真理的自由。即使是尽职尽责的人也难以实际验证他们遇到的所有生成内容的来源。这种不对称性使得即使生成内容在仔细检查时不够逼真，也能传播虚假信息。

在 2022 年，[一段深度伪造的视频](https://www.npr.org/2022/03/16/1087062648/deepfake-video-zelenskyy-experts-war-manipulation-ukraine-russia)被制作出来，似乎显示了乌克兰总统泽连斯基向俄罗斯军队投降。这段视频在社交媒体上广泛传播，导致一些人相信泽连斯基实际上已经投降。视频模糊的来源使得判断其真实性变得困难，即使是尽职尽责的人也很难验证其来源。视频来源的模糊性使得它能够广泛传播，即使有些人可能会在详细查看时质疑其真实性。

# 扩散

一旦由生成模型制作的高度逼真的伪造品出现，它们可以通过社交网络、消息应用和其他数字平台迅速传播。

尽管这与“规模与速度”部分相关，但从不同角度看这个问题至关重要：深度伪造通常设计得很具情感吸引力。它们可能展示令人震惊、丑闻性的或其他引人注目的内容。这使得它们更容易在社交媒体上被分享，在那里，人们不断寻找新的有趣内容。看到深度伪造的人越多，越有可能有人相信它是真的。即使每个单独的伪造品可能无法欺骗仔细的审查，但大规模传播的数量会压倒追踪和反击虚假信息的努力。病毒式传播赋予生成伪造品一种难以控制的传播范围和影响力。一旦它们“在野外”传播，平台已经难以处理更简单的虚假信息——由生成 AI 创建的内容则更高难度。

举一个具体的例子：在 2023 年 3 月，一张 AI 生成的教皇方济各的照片在社交媒体上病毒式传播，[一条推文](https://twitter.com/singareddynm/status/1639655045875507201)获得了近 2100 万次观看——它甚至获得了[“巴伦西亚教皇”](https://www.forbes.com/sites/danidiplacido/2023/03/27/why-did-balenciaga-pope-go-viral/)的昵称。根据[纽约邮报](https://nypost.com/2023/05/11/google-to-label-ai-generated-images-as-viral-trump-deepfake/)的报道，创作该图像的艺术家对这些关注并不感兴趣，恰恰相反：

> 被指生成该图片的 AI 艺术家 Pablo Xavier 表示，他“并不希望[这些图片]如此轰动”，并承认“人们在不加质疑的情况下认为它是真的，这确实令人害怕。”

# 结论

这些前所未有的能力——规模与速度、个性化、模糊来源和扩散——从根本上改变了虚假信息的性质，迫切需要辩论。我们如何应对一种能够大规模操控人们并摧毁共识现实的技术？需要什么治理措施才能在在线话语中保持信任和真相？我们能否遏制生成 AI 的有害应用，同时培养有益的应用？没有简单的答案，但现在进行诚恳的讨论对将这项技术引向伦理结果至关重要。

在一个由人工智能驱动的世界中，维护人类自主权、尊严和我们共享的现实是至关重要的。随着生成模型变得越来越强大和易于获得，我们需要伦理性护栏和智能治理，以防止反乌托邦的结果。必须迅速而深思熟虑地采取行动——在假设性风险通过自动化和人工智能操控扩散成现实之前。现在是塑造生成 AI 未来的最佳时机，以实现公正和有益的方向。

# Heiko Hotz

👋 在[Medium](https://heiko-hotz.medium.com/)和[LinkedIn](https://www.linkedin.com/in/heikohotz/)关注我，阅读更多关于生成 AI、机器学习和自然语言处理的内容。

👥 如果你在伦敦，请加入我们的[NLP London Meetups](https://www.meetup.com/nlp_london/)。

📔 我对 AI 新闻的看法在[😇 Naughty Neural](https://naughtyneural.net/)。

![](img/33b1525d9317ce4918a46789999f97ee.png)

作者提供的图片
