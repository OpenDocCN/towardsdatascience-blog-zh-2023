# ä½¿ç”¨ Redshift Serverless å’Œ Kinesis æ„å»ºæµæ•°æ®ç®¡é“

> åŸæ–‡ï¼š[`towardsdatascience.com/building-a-streaming-data-pipeline-with-redshift-serverless-and-kinesis-04e09d7e85b2`](https://towardsdatascience.com/building-a-streaming-data-pipeline-with-redshift-serverless-and-kinesis-04e09d7e85b2)

## é¢å‘åˆå­¦è€…çš„å®Œæ•´æ•™ç¨‹

[](https://mshakhomirov.medium.com/?source=post_page-----04e09d7e85b2--------------------------------)![ğŸ’¡Mike Shakhomirov](https://mshakhomirov.medium.com/?source=post_page-----04e09d7e85b2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----04e09d7e85b2--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----04e09d7e85b2--------------------------------) [ğŸ’¡Mike Shakhomirov](https://mshakhomirov.medium.com/?source=post_page-----04e09d7e85b2--------------------------------)

Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page-----04e09d7e85b2--------------------------------) Â·é˜…è¯»æ—¶é—´ 9 åˆ†é’ŸÂ·2023 å¹´ 10 æœˆ 6 æ—¥

--

![](img/d1700c0485714244a17aec09305461e6.png)

å›¾ç‰‡ç”±[Sebastian Pandelache](https://unsplash.com/@pandelache?utm_source=medium&utm_medium=referral)æ‹æ‘„ï¼Œæ¥æºäº[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å°†è®¨è®ºæœ€å—æ¬¢è¿çš„æ•°æ®ç®¡é“è®¾è®¡æ¨¡å¼ä¹‹ä¸€â€”â€”äº‹ä»¶æµã€‚é™¤äº†å…¶ä»–å¥½å¤„ï¼Œå®ƒè¿˜æ”¯æŒè¶…å¿«çš„æ•°æ®åˆ†æï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºå®æ—¶æ›´æ–°ç»“æœçš„æŠ¥å‘Šä»ªè¡¨ç›˜ã€‚æˆ‘å°†æ¼”ç¤ºå¦‚ä½•é€šè¿‡æ„å»ºä¸€ä¸ªä½¿ç”¨ AWS Kinesis å’Œ Redshift çš„æµæ•°æ®ç®¡é“æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡å‡ æ¬¡ç‚¹å‡»ä½¿ç”¨åŸºç¡€è®¾æ–½å³ä»£ç è¿›è¡Œéƒ¨ç½²ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ AWS CloudFormation æ¥æè¿°æˆ‘ä»¬çš„æ•°æ®å¹³å°æ¶æ„å¹¶ç®€åŒ–éƒ¨ç½²è¿‡ç¨‹ã€‚

æƒ³è±¡ä¸€ä¸‹ï¼Œä½œä¸ºæ•°æ®å·¥ç¨‹å¸ˆï¼Œä½ çš„ä»»åŠ¡æ˜¯åˆ›å»ºä¸€ä¸ªå°†æœåŠ¡å™¨äº‹ä»¶æµä¸æ•°æ®ä»“åº“è§£å†³æ–¹æ¡ˆï¼ˆRedshiftï¼‰è¿æ¥èµ·æ¥çš„æ•°æ®ç®¡é“ï¼Œä»¥ä¾¿è½¬æ¢æ•°æ®å¹¶åˆ›å»ºåˆ†æä»ªè¡¨ç›˜ã€‚

![](img/19d9e86d0773049b03bcd3c4ea66b9ab.png)

ç®¡é“åŸºç¡€è®¾æ–½ã€‚å›¾ç‰‡æ¥æºï¼šä½œè€…ã€‚

> ä»€ä¹ˆæ˜¯æ•°æ®ç®¡é“ï¼Ÿ
> 
> å®ƒæ˜¯ä¸€ä¸ªæ•°æ®å¤„ç†æ­¥éª¤çš„åºåˆ—ã€‚ç”±äºè¿™äº›é˜¶æ®µä¹‹é—´çš„***é€»è¾‘æ•°æ®æµè¿æ¥***ï¼Œæ¯ä¸ªé˜¶æ®µç”Ÿæˆä¸€ä¸ª**è¾“å‡º**ï¼Œä½œä¸ºä¸‹ä¸€ä¸ªé˜¶æ®µçš„**è¾“å…¥**ã€‚

æˆ‘ä¹‹å‰åœ¨è¿™ç¯‡æ–‡ç« ä¸­å†™è¿‡ç›¸å…³å†…å®¹ï¼š

[](/data-pipeline-design-patterns-100afa4b93e3?source=post_page-----04e09d7e85b2--------------------------------) ## æ•°æ®ç®¡é“è®¾è®¡æ¨¡å¼

### é€‰æ‹©åˆé€‚çš„æ¶æ„åŠç¤ºä¾‹

towardsdatascience.com

ä¾‹å¦‚ï¼Œäº‹ä»¶æ•°æ®å¯ä»¥ç”±åç«¯çš„æºåˆ›å»ºï¼Œä½¿ç”¨ Kinesis Firehose æˆ– Kafka æµæ„å»ºäº‹ä»¶æµã€‚ç„¶åå®ƒå¯ä»¥é¦ˆé€åˆ°å¤šä¸ªä¸åŒçš„æ¶ˆè´¹è€…æˆ–ç›®çš„åœ°ã€‚

æµå¼å¤„ç†æ˜¯ä¼ä¸šæ•°æ®çš„â€œå¿…å¤‡â€è§£å†³æ–¹æ¡ˆï¼Œå› å…¶æµæ•°æ®å¤„ç†èƒ½åŠ›ã€‚å®ƒèƒ½å¤Ÿå®ç°å®æ—¶æ•°æ®åˆ†æã€‚

åœ¨æˆ‘ä»¬çš„ç”¨ä¾‹åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è®¾ç½®ä¸€ä¸ª**ELT æµå¼**æ•°æ®ç®¡é“åˆ° AWS Redshiftã€‚AWS Firehose æµå¯ä»¥æä¾›è¿™ç§æ— ç¼é›†æˆï¼Œå½“æ•°æ®æµè¢«ç›´æ¥ä¸Šä¼ åˆ°æ•°æ®ä»“åº“è¡¨æ—¶ã€‚ç„¶åï¼Œæ•°æ®å¯ä»¥è¢«è½¬æ¢ä»¥ä½¿ç”¨ AWS Quicksight ä½œä¸º BI å·¥å…·æ¥åˆ›å»ºæŠ¥å‘Šï¼Œä¾‹å¦‚ã€‚

![](img/90a8cb4b073924f3113fce5df13ab20c.png)

æ·»åŠ äº† BI ç»„ä»¶ã€‚å›¾ç‰‡æ¥æºäºä½œè€…ã€‚

> æœ¬æ•™ç¨‹å‡è®¾å­¦ä¹ è€…ç†Ÿæ‚‰ AWS CLI å¹¶ä¸”å…·æœ‰åŸºæœ¬çš„ Python çŸ¥è¯†ã€‚

## å·¥ä½œæµç¨‹

1\. é¦–å…ˆï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ AWS CloudFormation åˆ›å»º Kinesis æ•°æ®æµã€‚

2\. æˆ‘ä»¬å°†ä½¿ç”¨ AWS Lambda å‘æ­¤äº‹ä»¶æµå‘é€ç¤ºä¾‹æ•°æ®äº‹ä»¶ã€‚

3\. æœ€åï¼Œæˆ‘ä»¬å°†é…ç½® AWS Redshift é›†ç¾¤å¹¶æµ‹è¯•æˆ‘ä»¬çš„æµå¼ç®¡é“ã€‚

## åˆ›å»º AWS Kinesis æ•°æ®æµ

AWS Kinesis Data Streams æ˜¯ä¸€ä¸ª Amazon Kinesis å®æ—¶æ•°æ®æµè§£å†³æ–¹æ¡ˆã€‚å®ƒæä¾›äº†å‡ºè‰²çš„å¯æ‰©å±•æ€§å’Œè€ç”¨æ€§ï¼Œæ•°æ®æµå¯ä»¥è¢«ä»»ä½•æ¶ˆè´¹è€…è®¿é—®ã€‚

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ CloudFormation æ¨¡æ¿æ¥åˆ›å»ºå®ƒã€‚ä¸‹é¢çš„å‘½ä»¤è¡Œè„šæœ¬å°†è§¦å‘ AWS CLI å‘½ä»¤è¿›è¡Œéƒ¨ç½²ï¼š

```py
KINESIS_STACK=YourRedshiftDataStream
ENV=staging
aws \
cloudformation deploy \
--template-file kinesis-data-stream.yaml \
--stack-name $KINESIS_STACK \
--capabilities CAPABILITY_IAM \
--parameter-overrides \
"Environment"=$ENV
```

å¹¶ä¸”æ¨¡æ¿ kinesis-data-stream.yaml å°†å¦‚ä¸‹æ‰€ç¤ºï¼š

```py
AWSTemplateFormatVersion: 2010-09-09
Description: >
  Firehose resources relating to statistics generation.
  Repository - https://github.com/your_repository.

Parameters:
  Environment:
    AllowedValues:
      - staging
      - production
    Description: Target environment
    Type: String
    Default: 'staging'

Resources:
  MyKinesisStream:
    Type: AWS::Kinesis::Stream
    Properties: 
      Name: !Sub 'your-data-stream-${Environment}'
      RetentionPeriodHours: 24 
      StreamModeDetails:
        StreamMode: ON_DEMAND
      # ShardCount: 1
      Tags: 
        -
          Key: Environment
          Value: Production
```

éå¸¸ç®€å•ã€‚å¦‚æœä¸€åˆ‡é¡ºåˆ©ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°æˆ‘ä»¬çš„ Kinesis æµè¢«éƒ¨ç½²ï¼š

![](img/0f33f2db4f4b45e501787735db96cb76.png)

æµå·²åˆ›å»ºã€‚å›¾ç‰‡æ¥æºäºä½œè€…ã€‚

## 2\. åˆ›å»º AWS Lambda å‡½æ•°ä»¥æ¨¡æ‹Ÿäº‹ä»¶æµ

ç°åœ¨æˆ‘ä»¬å¸Œæœ›å°†ä¸€äº›äº‹ä»¶å‘é€åˆ°æˆ‘ä»¬çš„ Kinesis æ•°æ®æµã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªæ— æœåŠ¡å™¨åº”ç”¨ç¨‹åºï¼Œä¾‹å¦‚ AWS Lambdaã€‚æˆ‘ä»¬å°†ä½¿ç”¨`boto3`åº“ï¼ˆAWS çš„ Python SDKï¼‰æ¥æ„å»ºä¸€ä¸ªæ•°æ®è¿æ¥å™¨ä¸ AWS Kinesis è¿›è¡Œæ•°æ®æºè¿æ¥ã€‚

![](img/611621ecd4f8ba97807a73dcbfff5e82.png)

æœ¬åœ°è¿è¡Œåº”ç”¨ä»¥æ¨¡æ‹Ÿäº‹ä»¶æµã€‚å›¾ç‰‡æ¥æºäºä½œè€…ã€‚

æˆ‘ä»¬çš„åº”ç”¨ç¨‹åºæ–‡ä»¶å¤¹ç»“æ„å¯ä»¥å¦‚ä¸‹æ‰€ç¤ºï¼š

```py
.
â”œâ”€â”€ app.py
â”œâ”€â”€ config
â”‚   â””â”€â”€ staging.yaml
â”œâ”€â”€ env.json
â””â”€â”€ requirements.txt
```

æˆ‘ä»¬çš„`app.py`å¿…é¡»èƒ½å¤Ÿå‘ Kinesis æ•°æ®æµå‘é€äº‹ä»¶ï¼š

```py
# Make sure boto3 is installed locally, i.e. pip install boto3
import json
import random
import boto3

kinesis_client = boto3.client('kinesis', region_name='eu-west-1')
# Constants:
STREAM_NAME = "your-data-stream-staging"

def lambda_handler(event, context):
    processed = 0
    print(STREAM_NAME)
    try:
        print('Trying to send events to Kinesis...')
        for i in range(0, 5):
            data = get_data()
            print(i, " : ", data)
            kinesis_client.put_record(
                StreamName=STREAM_NAME,

                Data=json.dumps(data),
                PartitionKey="partitionkey")
            processed += 1
    except Exception as e:
        print(e)
    message = 'Successfully processed {} events.'.format(processed)
    return {
        'statusCode': 200,
        'body': { 'lambdaResult': message }
    }

```

æˆ‘ä»¬å¸Œæœ›æ·»åŠ ä¸€ä¸ªå¸®åŠ©å‡½æ•°æ¥ç”Ÿæˆä¸€äº›éšæœºäº‹ä»¶æ•°æ®ã€‚ä¾‹å¦‚ï¼š

```pypython
# Helpers:
def get_data():
    return {
        'event_time': datetime.now().isoformat(),
        'event_name': random.choice(['JOIN', 'LEAVE', 'OPEN_CHAT', 'SUBSCRIBE', 'SEND_MESSAGE']),
        'user': round(random.random() * 100)}
```

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`python-lambda-local`åº“æœ¬åœ°è¿è¡Œå’Œæµ‹è¯• AWS Lambdaï¼Œæ–¹æ³•å¦‚ä¸‹ï¼š

```py
pip install python-lambda-local
cd stack
python-lambda-local -e events_connector/env.json -f lambda_handler events_connector/app.py event.json --timeout 10000
# -e is for environment variables if you choose to use them.
#  event.json - sample JSON event to invoke our Lambda with.
```

`env.json` åªæ˜¯ä¸€ä¸ªäº‹ä»¶è´Ÿè½½ï¼Œç”¨äºæœ¬åœ°è¿è¡Œ Lambdaã€‚

`config/staging.yaml` å¯ä»¥åŒ…å«æˆ‘ä»¬åº”ç”¨ç¨‹åºæœªæ¥å¯èƒ½éœ€è¦çš„ä»»ä½•ç¯å¢ƒç‰¹å®šè®¾ç½®ã€‚ä¾‹å¦‚ï¼š

```py
# staging.yaml
Kinesis:
  DataStreamNsme: your-data-stream-staging
```

å¦‚æœä½ éœ€è¦ä½¿ç”¨`requirements.txt`ï¼Œå®ƒå¯ä»¥å¦‚ä¸‹æ‰€ç¤ºï¼š

```py
requests==2.28.1
pyyaml==6.0
boto3==boto3-1.26.90
python-lambda-local==0.1.13
```

åœ¨ä½ çš„å‘½ä»¤è¡Œä¸­è¿è¡Œè¿™ä¸ªï¼š

```py
 cd stack
pip install -r events_connector/requirements.txt
```

è¿™ç§æ–¹æ³•å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºæˆ‘ä»¬å¯èƒ½å¸Œæœ›å°†æ— æœåŠ¡å™¨åº”ç”¨ç¨‹åºéƒ¨ç½²åˆ°äº‘ä¸­å¹¶è¿›è¡Œè°ƒåº¦ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ CloudFormation æ¨¡æ¿æ¥å®ç°è¿™ä¸€ç‚¹ã€‚æˆ‘ä¹‹å‰åœ¨è¿™é‡Œå†™è¿‡ï¼š

[## Infrastructure as Code for Beginners](https://levelup.gitconnected.com/infrastructure-as-code-for-beginners-a4e36c805316?source=post_page-----04e09d7e85b2--------------------------------)

### ä½¿ç”¨è¿™äº›æ¨¡æ¿åƒä¸“ä¸šäººå£«ä¸€æ ·éƒ¨ç½²æ•°æ®ç®¡é“

[levelup.gitconnected.com](https://levelup.gitconnected.com/infrastructure-as-code-for-beginners-a4e36c805316?source=post_page-----04e09d7e85b2--------------------------------)

å½“æˆ‘ä»¬ä½¿ç”¨ CloudFormation æ¨¡æ¿æ—¶ï¼Œåº”ç”¨ç¨‹åºå¯ä»¥é€šè¿‡ç±»ä¼¼çš„ shell è„šæœ¬è¿›è¡Œéƒ¨ç½²ï¼š

```py
PROFILE=your-aws-profile
STACK_NAME=YourStackNameLive
LAMBDA_BUCKET=your-lambdas-bucket.aws # Make sure it exists

date

TIME=`date +"%Y%m%d%H%M%S"`

base=${PWD##*/}
zp=$base".zip"
echo $zp

rm -f $zp

pip install --target ./package -r requirements.txt

cd package
zip -r ../${base}.zip .

cd $OLDPWD

zip -r $zp ./events_connector -x __pycache__ 

aws --profile $PROFILE s3 cp ./${base}.zip s3://${LAMBDA_BUCKET}/events_connector/${base}${TIME}.zip

aws --profile $PROFILE \
cloudformation deploy \
--template-file stack.yaml \
--stack-name $STACK_NAME \
--capabilities CAPABILITY_IAM \
--parameter-overrides \
"StackPackageS3Key"="events_connector/${base}${TIME}.zip" \
"Environment"="staging" \
"Testing"="false"
```

è¿™æ˜¯ä¸€ä¸ªçµæ´»çš„è®¾ç½®ï¼Œå…è®¸æˆ‘ä»¬åˆ›å»ºå¼ºå¤§çš„ CI/CD ç®¡é“ã€‚æˆ‘è®°å¾—æˆ‘åœ¨ä¸‹é¢çš„å¸–å­ä¸­åˆ›å»ºäº†ä¸€ä¸ªã€‚

## Continuous Integration and Deployment for Data Platforms

### æ•°æ®å·¥ç¨‹å¸ˆå’Œ ML Ops çš„ CI/CD

[towardsdatascience.com

## åˆ›å»º Redshift Serverless èµ„æº

ç°åœ¨æˆ‘ä»¬éœ€è¦ä¸ºæˆ‘ä»¬çš„æµæ•°æ®ç®¡é“åˆ›å»º Redshift Serverless é›†ç¾¤ã€‚æˆ‘ä»¬å¯ä»¥æ‰‹åŠ¨æˆ–ä½¿ç”¨ CloudFormation æ¨¡æ¿é…ç½® Redshift Workgroupã€åˆ›å»º Namespace å’Œå…¶ä»–æ‰€éœ€èµ„æºã€‚

Redshift Serverless ä»…ä»…æ˜¯ä¸€ä¸ªæ•°æ®ä»“åº“è§£å†³æ–¹æ¡ˆã€‚å®ƒå¯ä»¥æ‰§è¡Œä»»ä½•è§„æ¨¡çš„åˆ†æå·¥ä½œè´Ÿè½½ï¼Œæ— éœ€æ•°æ®ä»“åº“åŸºç¡€è®¾æ–½ç®¡ç†ã€‚Redshift è¿è¡Œè¿…é€Ÿï¼Œå¹¶èƒ½åœ¨å‡ ç§’é’Ÿå†…ä»å·¨é‡æ•°æ®ä¸­ç”Ÿæˆæ´å¯Ÿã€‚å®ƒä¼šè‡ªåŠ¨æ‰©å±•ï¼Œä¸ºå³ä½¿æ˜¯æœ€è‹›åˆ»çš„åº”ç”¨ç¨‹åºæä¾›å¿«é€Ÿæ€§èƒ½ã€‚

![](img/9e11cbe2d920bab18ad3e3c56a7a0a94.png)

ä¾‹å­è§†å›¾æ˜¾ç¤ºäº†æˆ‘ä»¬åº”ç”¨ç¨‹åºçš„äº‹ä»¶ã€‚å›¾åƒæ¥æºäºä½œè€…ã€‚

åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ CloudFormation æ¨¡æ¿å®šä¹‰æ¥éƒ¨ç½² Redshift èµ„æºã€‚

```py
AWSTemplateFormatVersion: 2010-09-09
Parameters:
  DatabaseName:
    Description: The name of the first database in the Amazon Redshift Serverless environment.
    Type: String
    Default: dev
    MaxLength: 127
    AllowedPattern: '[a-zA-Z][a-zA-Z_0-9+.@-]*'
  AdminUsername:
    Description: The administrator's user name for Redshift Serverless Namespace being created.
    Type: String
    Default: admin
    AllowedPattern: '[a-zA-Z][a-zA-Z_0-9+.@-]*'
  AdminUserPassword:
    Description: The password associated with admin user.
    Type: String
    NoEcho: 'true'
    Default: Admin123
    MinLength: 8
    MaxLength: 64
    # AllowedPattern: '^(?=.*[a-z])(?=.*[A-Z])(?=.*\d)[^\x00-\x20\x22\x27\x2f\x40\x5c\x7f-\uffff]+'
  NamespaceName:
    Description: A unique identifier that defines the Namespace.
    Default: rswg
    Type: String
    MinLength: 3
    MaxLength: 64
    AllowedPattern: '^[a-z0-9-]+$'
  WorkgroupName:
    Description: A unique identifier that defines the Workspace.
    Default: redshiftworkgroup
    Type: String
    MinLength: 3
    MaxLength: 64
    AllowedPattern: '^[a-z0-9-]*$'
  BaseRPU:
    Description: Base RPU for Redshift Serverless Workgroup.
    Type: Number
    MinValue: 8
    MaxValue: 512
    Default: 8
    AllowedValues: [8,16,32,40,48,56,64,72,80,88,96,104,112,120,128,136,144,152,160,168,176,184,192,200,208,216,224,232,240,248,256,264,272,280,288,296,304,312,320,328,336,344,352,360,368,376,384,392,400,408,416,424,432,440,448,456,464,472,480,488,496,504,512]
  PubliclyAccessible:
    Description: Redshift Serverless instance to be publicly accessible.
    Type: String
    Default: true
    AllowedValues:
      - true
      - false

  SubnetId:
    Description: You must have at least three subnets, and they must span across three Availability Zones
    Type: List<AWS::EC2::Subnet::Id>
  SecurityGroupIds:
    Description: The list of SecurityGroupIds in your Virtual Private Cloud (VPC).
    Type: List<AWS::EC2::SecurityGroup::Id>
  LogExportsList:
    Description: Provide comma seperate values from list "userlog","connectionlog","useractivitylog".  E.g userlog,connectionlog,useractivitylog.  If left blank, LogExport is turned off.
    Type: CommaDelimitedList 
    Default: userlog,connectionlog,useractivitylog
  EnhancedVpcRouting:
    Description: The value that specifies whether to enable enhanced virtual private cloud (VPC) routing, which forces Amazon Redshift Serverless to route traffic through your VPC.
    Type: String
    AllowedValues:
      - true
      - false
    Default: false    
Metadata:
  'AWS::CloudFormation::Interface':
    ParameterGroups:
      - Label:
          default: Namespace parameters
        Parameters:
          - NamespaceName
          - DatabaseName
          - AdminUsername
          - AdminUserPassword
          - IAMRole
          - LogExportsList          
      - Label:
          default: Workgroup parameters
        Parameters:
            - WorkgroupName
            - BaseRPU
            - PubliclyAccessible
            - SubnetId
            - SecurityGroupIds
            - EnhancedVpcRouting            
    ParameterLabels:
      DatabaseName:
        default: "Database Name"
      AdminUsername:
        default: "Admin User Name"
      AdminUserPassword:
        default: "Admin User Password"
      NamespaceName:
        default: "Namespace"
      WorkgroupName:
        default: "Workgroup"
      BaseRPU:
        default: "Base RPU"
      PubliclyAccessible:
        default: "Publicly accessible"
      SubnetId:
        default: "Subnet Ids (Select 3 Subnet Ids spanning 3 AZs)"
      SecurityGroupIds:
        default: "Security Group Id"
      IAMRole:
        default: "Associate IAM Role"
      EnhancedVpcRouting:
        default: "Enhanced VPC Routing"  
      LogExportsList:
        default: "Log Export List"
Resources:
  RedshiftAccessRole:
    Type: AWS::IAM::Role
    Properties:
      ManagedPolicyArns: 
          - arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole
          - arn:aws:iam::aws:policy/AmazonRedshiftAllCommandsFullAccess

      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          -
            Effect: Allow
            Principal:
              Service:
                - redshift.amazonaws.com
            Action:
              - sts:AssumeRole
  RedshiftRolePolicy:
    Type: AWS::IAM::Policy
    Properties:
      PolicyName: RedshiftRolePolicy
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          -
            Effect: Allow
            Action: s3:ListAllMyBuckets
            Resource: arn:aws:s3:::*
          -
            Effect: Allow
            Action:
              - 's3:Get*'
              - 's3:List*'
            Resource: '*'
          -
            Effect: Allow
            Action: cloudwatch:*
            Resource: "*"
          -
            Effect: Allow
            Action: kinesis:*
            Resource: "*"
      Roles:
        - !Ref RedshiftAccessRole
  RedshiftServerlessNamespace:
    DependsOn: RedshiftAccessRole
    Type: 'AWS::RedshiftServerless::Namespace'
    Properties:
      AdminUsername:
        Ref: AdminUsername
      AdminUserPassword:
        Ref: AdminUserPassword
      DbName:
        Ref: DatabaseName
      NamespaceName:
        Ref: NamespaceName
      IamRoles:
        - !GetAtt [ RedshiftAccessRole, Arn ]
      LogExports:
        Ref: LogExportsList        
  RedshiftServerlessWorkgroup:
    Type: 'AWS::RedshiftServerless::Workgroup'
    Properties:
      WorkgroupName:
        Ref: WorkgroupName
      NamespaceName:
        Ref: NamespaceName
      BaseCapacity:
        Ref: BaseRPU
      PubliclyAccessible:
        Ref: PubliclyAccessible
      SubnetIds:
        Ref: SubnetId
      SecurityGroupIds:
        Ref: SecurityGroupIds
      EnhancedVpcRouting:
        Ref: EnhancedVpcRouting        
    DependsOn:
      - RedshiftServerlessNamespace
Outputs:
  ServerlessNamespace:
    Description: Name of the namespace
    Value: !Ref NamespaceName
  ServerlessWorkgroup:
    Description: Name of the workgroup
    Value: !Ref WorkgroupName
```

æ‰€ä»¥å¦‚æœæˆ‘ä»¬åœ¨å‘½ä»¤è¡Œä¸­è¿è¡Œè¿™æ®µä»£ç ï¼Œå®ƒå°†éƒ¨ç½²è¿™ä¸ªå †æ ˆï¼š

```py
STACK=YourRedshiftServerless
SUBNETID=subnet-1,subnet-2,subnet-3
SECURITYGROUPIDS=sg-your-security-group
aws \
cloudformation deploy \
--template-file redshift-serverless.yaml \
--stack-name $STACK \
--capabilities CAPABILITY_IAM \
--parameter-overrides \
"SubnetId"=$SUBNETID \
"SecurityGroupIds"=$SECURITYGROUPIDS
```

é€šå¸¸ï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨ç§æœ‰å­ç½‘ä¸­éƒ¨ç½²æ•°æ®åº“ã€‚ç„¶è€Œï¼Œåœ¨å¼€å‘çš„æ—©æœŸé˜¶æ®µï¼Œä½ å¯èƒ½å¸Œæœ›ä»å¼€å‘æœºå™¨ç›´æ¥è®¿é—® Redshiftã€‚

> è¿™ä¸æ¨èç”¨äºç”Ÿäº§ç¯å¢ƒï¼Œä½†åœ¨è¿™ç§å¼€å‘æƒ…å†µä¸‹ï¼Œä½ å¯ä»¥å…ˆå°† Redshift æ”¾å…¥æˆ‘ä»¬çš„ `default` VPC å­ç½‘ã€‚
> 
> ç°åœ¨ï¼Œå½“æ‰€æœ‰æ‰€éœ€çš„ç®¡é“èµ„æºæˆåŠŸé…ç½®åï¼Œæˆ‘ä»¬å¯ä»¥è¿æ¥æˆ‘ä»¬çš„ Kinesis æµå’Œ Redshift æ•°æ®ä»“åº“ã€‚

ç„¶åæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ SQL è¯­å¥åœ¨ Redshift ä¸­åˆ›å»º `kinesis_data` æ¨¡å¼ï¼š

```py
CREATE EXTERNAL SCHEMA kinesis_data
FROM KINESIS
IAM_ROLE 'arn:aws:iam::123456789:role/rs3-RedshiftAccessRole-1TU31HQNXM0EK';
;
CREATE MATERIALIZED VIEW "your-stream-view" AUTO REFRESH YES AS
    SELECT approximate_arrival_timestamp,
           partition_key,
           shard_id,
           sequence_number,
           refresh_time,
           JSON_PARSE(kinesis_data) as payload
      FROM kinesis_data."your-data-stream-staging";
;
```

è¿™æ®µ SQL çš„ç¬¬ä¸€éƒ¨åˆ†å°†è®¾ç½® AWS Kinesis ä½œä¸ºæ•°æ®æºã€‚ç¬¬äºŒéƒ¨åˆ†å°†åˆ›å»ºä¸€ä¸ªåŒ…å«æˆ‘ä»¬åº”ç”¨ç¨‹åºäº‹ä»¶æ•°æ®çš„è§†å›¾ã€‚

ç¡®ä¿åˆ›å»ºä¸€ä¸ªå…·æœ‰ `AmazonRedshiftAllCommandsFullAccess` AWS ç®¡ç†ç­–ç•¥çš„ AWS Redshift è§’è‰²ã€‚

```py
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Action": "s3:ListAllMyBuckets",
            "Resource": "arn:aws:s3:::*",
            "Effect": "Allow"
        },
        {
            "Action": [
                "s3:Get*",
                "s3:List*"
            ],
            "Resource": "*",
            "Effect": "Allow"
        },
        {
            "Action": "cloudwatch:*",
            "Resource": "*",
            "Effect": "Allow"
        },
        {
            "Action": "kinesis:*",
            "Resource": "*",
            "Effect": "Allow"
        }
    ]
}
```

å°±è¿™æ ·ã€‚ä¸€åˆ‡å‡†å¤‡å¥½è¿è¡Œåº”ç”¨ç¨‹åºä»¥æ¨¡æ‹Ÿäº‹ä»¶æ•°æ®æµã€‚è¿™äº›äº‹ä»¶ä¼šç«‹å³å‡ºç°åœ¨æˆ‘ä»¬åˆšåˆšåˆ›å»ºçš„ Redshift è§†å›¾ä¸­ï¼š

![](img/611621ecd4f8ba97807a73dcbfff5e82.png)

åº”ç”¨ç¨‹åºåœ¨æœ¬åœ°è¿è¡Œã€‚å›¾åƒæ¥æºäºä½œè€…ã€‚

![](img/9e11cbe2d920bab18ad3e3c56a7a0a94.png)

ç¤ºä¾‹è§†å›¾æ˜¾ç¤ºäº†æ¥è‡ªæˆ‘ä»¬åº”ç”¨ç¨‹åºçš„äº‹ä»¶ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚

# ç»“è®º

æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªç®€å•è€Œå¯é çš„æµæ•°æ®ç®¡é“ï¼Œä»ä½¿ç”¨ AWS Lambda åˆ›å»ºçš„æ— æœåŠ¡å™¨åº”ç”¨ç¨‹åºåˆ° AWS Redshift æ•°æ®ä»“åº“ï¼Œåœ¨é‚£é‡Œæ•°æ®å®æ—¶è½¬åŒ–å’Œæ‘„å–ã€‚å®ƒèƒ½å¤Ÿè½»æ¾æ•è·ã€å¤„ç†å’Œå­˜å‚¨ä»»ä½•è§„æ¨¡çš„æ•°æ®æµã€‚å¯¹äºä»»ä½•æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰ç®¡é“éƒ½éå¸¸é€‚ç”¨ï¼Œå…¶ä¸­æ¨¡å‹ç”¨äºæ£€æŸ¥æ•°æ®å¹¶é¢„æµ‹æ¨ç†ç«¯ç‚¹ï¼Œå› ä¸ºæ•°æ®æµå‘å…¶ç›®æ ‡ã€‚

æˆ‘ä»¬ä½¿ç”¨åŸºç¡€è®¾æ–½å³ä»£ç æ¥éƒ¨ç½²æ•°æ®ç®¡é“èµ„æºã€‚è¿™æ˜¯éƒ¨ç½²ä¸åŒæ•°æ®ç¯å¢ƒä¸­èµ„æºçš„é¦–é€‰æ–¹æ³•ã€‚

# æ¨èé˜…è¯»

/continuous-integration-and-deployment-for-data-platforms-817bf1b6bed1?source=post_page-----04e09d7e85b2--------------------------------) [## æ•°æ®å¹³å°çš„æŒç»­é›†æˆå’Œéƒ¨ç½²

### æ•°æ®å·¥ç¨‹å¸ˆå’Œ ML è¿ç»´çš„ CI/CD

[Towards Data Science /data-platform-architecture-types-f255ac6e0b7?source=post_page-----04e09d7e85b2--------------------------------) [## æ•°æ®å¹³å°æ¶æ„ç±»å‹

### å®ƒèƒ½å¤šå¤§ç¨‹åº¦ä¸Šæ»¡è¶³ä½ çš„ä¸šåŠ¡éœ€æ±‚ï¼Ÿé€‰æ‹©çš„å›°å¢ƒã€‚

[Towards Data Science [`levelup.gitconnected.com/infrastructure-as-code-for-beginners-a4e36c805316?source=post_page-----04e09d7e85b2--------------------------------) [## åˆå­¦è€…çš„åŸºç¡€è®¾æ–½å³ä»£ç 

### ä½¿ç”¨è¿™äº›æ¨¡æ¿åƒä¸“ä¸šäººå£«ä¸€æ ·éƒ¨ç½²æ•°æ®ç®¡é“

[LevelUp`](https://levelup.gitconnected.com/infrastructure-as-code-for-beginners-a4e36c805316?source=post_page-----04e09d7e85b2--------------------------------)
