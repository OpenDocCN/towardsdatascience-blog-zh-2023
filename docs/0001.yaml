- en: 'Graph ML in 2023: The State of Affairs'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图形机器学习在2023年的现状
- en: 原文：[https://towardsdatascience.com/graph-ml-in-2023-the-state-of-affairs-1ba920cb9232?source=collection_archive---------0-----------------------#2023-01-01](https://towardsdatascience.com/graph-ml-in-2023-the-state-of-affairs-1ba920cb9232?source=collection_archive---------0-----------------------#2023-01-01)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/graph-ml-in-2023-the-state-of-affairs-1ba920cb9232?source=collection_archive---------0-----------------------#2023-01-01](https://towardsdatascience.com/graph-ml-in-2023-the-state-of-affairs-1ba920cb9232?source=collection_archive---------0-----------------------#2023-01-01)
- en: STATE OF THE ART DIGEST
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最前沿动态
- en: Hot trends and major advancements
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 热点趋势和重大进展
- en: '[](https://mgalkin.medium.com/?source=post_page-----1ba920cb9232--------------------------------)[![Michael
    Galkin](../Images/c5eb13334712ca0462d8a5df4a268ad0.png)](https://mgalkin.medium.com/?source=post_page-----1ba920cb9232--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1ba920cb9232--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1ba920cb9232--------------------------------)
    [Michael Galkin](https://mgalkin.medium.com/?source=post_page-----1ba920cb9232--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://mgalkin.medium.com/?source=post_page-----1ba920cb9232--------------------------------)[![Michael
    Galkin](../Images/c5eb13334712ca0462d8a5df4a268ad0.png)](https://mgalkin.medium.com/?source=post_page-----1ba920cb9232--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1ba920cb9232--------------------------------)[![数据科学前沿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1ba920cb9232--------------------------------)
    [Michael Galkin](https://mgalkin.medium.com/?source=post_page-----1ba920cb9232--------------------------------)'
- en: ·
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4d4f8ddd1e68&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgraph-ml-in-2023-the-state-of-affairs-1ba920cb9232&user=Michael+Galkin&userId=4d4f8ddd1e68&source=post_page-4d4f8ddd1e68----1ba920cb9232---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1ba920cb9232--------------------------------)
    ·26 min read·Jan 1, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1ba920cb9232&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgraph-ml-in-2023-the-state-of-affairs-1ba920cb9232&user=Michael+Galkin&userId=4d4f8ddd1e68&source=-----1ba920cb9232---------------------clap_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4d4f8ddd1e68&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgraph-ml-in-2023-the-state-of-affairs-1ba920cb9232&user=Michael+Galkin&userId=4d4f8ddd1e68&source=post_page-4d4f8ddd1e68----1ba920cb9232---------------------post_header-----------)
    发布在 [数据科学前沿](https://towardsdatascience.com/?source=post_page-----1ba920cb9232--------------------------------)
    · 26分钟阅读 · 2023年1月1日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1ba920cb9232&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgraph-ml-in-2023-the-state-of-affairs-1ba920cb9232&user=Michael+Galkin&userId=4d4f8ddd1e68&source=-----1ba920cb9232---------------------clap_footer-----------)'
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1ba920cb9232&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgraph-ml-in-2023-the-state-of-affairs-1ba920cb9232&source=-----1ba920cb9232---------------------bookmark_footer-----------)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1ba920cb9232&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgraph-ml-in-2023-the-state-of-affairs-1ba920cb9232&source=-----1ba920cb9232---------------------bookmark_footer-----------)'
- en: 2022 comes to an end and it is about time to sit down and reflect upon the achievements
    made in Graph ML as well as to hypothesize about possible breakthroughs in 2023\.
    Tune in 🎄☕
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 2022年已经结束，是时候坐下来回顾一下在图形机器学习（Graph ML）方面取得的成就，并对2023年的可能突破进行假设了。敬请关注 🎄☕
- en: '![](../Images/f8888b219ca9e135881455e3596c98d7.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f8888b219ca9e135881455e3596c98d7.png)'
- en: Background image generated by [DALL-E 2](https://openai.com/dall-e-2/), text
    added by Author.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 背景图像由 [DALL-E 2](https://openai.com/dall-e-2/) 生成，文本由作者添加。
- en: '*The article is written together with* [*Hongyu Ren*](http://hyren.me/) *(Stanford
    University),* [*Zhaocheng Zhu*](https://kiddozhu.github.io/) *(Mila & University
    of Montreal). We thank* [*Christopher Morris*](https://chrsmrrs.github.io/) *and*
    [*Johannes Brandstetter*](https://www.microsoft.com/en-us/research/people/johannesb/)
    *for the feedback and helping with the Theory and PDE sections, respectively.
    Follow* [*Michael*](https://twitter.com/michael_galkin)*,* [*Hongyu*](https://twitter.com/ren_hongyu)*,*
    [*Zhaocheng*](https://twitter.com/zhu_zhaocheng), [*Christopher*](https://twitter.com/chrsmrrs)*,
    and* [*Johannes*](https://twitter.com/jo_brandstetter) *here on Medium and Twitter
    for more graph ml-related discussions.*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*这篇文章由* [*Hongyu Ren*](http://hyren.me/) *(斯坦福大学)、* [*Zhaocheng Zhu*](https://kiddozhu.github.io/)
    *(Mila 和蒙特利尔大学)共同撰写。我们感谢* [*Christopher Morris*](https://chrsmrrs.github.io/)
    *和* [*Johannes Brandstetter*](https://www.microsoft.com/en-us/research/people/johannesb/)
    *在理论和偏微分方程部分的反馈和帮助。请关注* [*Michael*](https://twitter.com/michael_galkin)*、* [*Hongyu*](https://twitter.com/ren_hongyu)*、*
    [*Zhaocheng*](https://twitter.com/zhu_zhaocheng)、* [*Christopher*](https://twitter.com/chrsmrrs)*和*
    [*Johannes*](https://twitter.com/jo_brandstetter) *在Medium和Twitter上，以获取更多与图机器学习相关的讨论。*'
- en: '**Table of Contents:**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**目录：**'
- en: '[Generative Models: Denoising Diffusion for Molecules and Proteins](#48f6)'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[生成模型：分子和蛋白质的去噪扩散模型](#48f6)'
- en: '[DFTs, ML Force Fields, Materials, and Weather Simulations](#d2e8)'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[DFTs、机器学习力场、材料和天气模拟](#d2e8)'
- en: '[Geometry & Topology & PDEs](#6d20)'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[几何学与拓扑学与偏微分方程](#6d20)'
- en: '[Graph Transformers](#8e6c)'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[图变换器](#8e6c)'
- en: '[BIG Graphs](#ca19)'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[大型图](#ca19)'
- en: '[GNN Theory: Weisfeiler and Leman Go Places, Subgraph GNNs](#7986)'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[GNN理论：Weisfeiler和Leman的前景，子图GNN](#7986)'
- en: '[Knowledge Graphs: Inductive Reasoning Takes Over](#e5e6)'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[知识图谱：归纳推理接管](#e5e6)'
- en: '[Algorithmic Reasoning and Alignment](#b2f5)'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[算法推理和对齐](#b2f5)'
- en: '[Cool GNN Applications](#0de4)'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[酷炫的GNN应用](#0de4)'
- en: '[Hardware: IPUs and Graphcore win OGB LSC 2022](#b813)'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[硬件：IPU和Graphcore赢得OGB LSC 2022](#b813)'
- en: '[New Conferences: LoG and Molecular ML](#9b59)'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[新的会议：LoG 和分子机器学习](#9b59)'
- en: '[Courses and Educational Materials](#41dc)'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[课程和教育材料](#41dc)'
- en: '[New Datasets, Benchmarks, and Challenges](#3e6d)'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[新的数据集、基准和挑战](#3e6d)'
- en: '[Software Libraries and Open Source](#463f)'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[软件库和开源](#463f)'
- en: '[Join the Community](#1b30)'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[加入社区](#1b30)'
- en: '[The Meme of 2022](#7593)'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2022年的网络迷因](#7593)'
- en: 'Generative Models: Denoising Diffusion for Molecules and Proteins'
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成模型：分子和蛋白质的去噪扩散模型
- en: Generative diffusion models in the vision-language domain were the headline
    topic in the Deep Learning world in 2022\. While generating images and videos
    is definitely a cool playground to try out different models and sampling techniques,
    we’d argue that
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 生成扩散模型在视觉语言领域是2022年深度学习世界的头条话题。尽管生成图像和视频无疑是尝试不同模型和采样技术的酷炫领域，我们认为
- en: the most *useful* applications of diffusion models in 2022 were actually created
    in the Geometric Deep Learning area focusing on molecules and proteins
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在2022年，扩散模型最*有用*的应用实际上是在几何深度学习领域中创建的，重点关注分子和蛋白质
- en: In our recent article, we were pondering whether [“Denoising Diffusion Is All
    You Need?”](/denoising-diffusion-generative-models-in-graph-ml-c496af5811c5).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们最近的文章中，我们在思考是否 [“去噪扩散模型就是你所需的一切？”](/denoising-diffusion-generative-models-in-graph-ml-c496af5811c5)。
- en: '[](/denoising-diffusion-generative-models-in-graph-ml-c496af5811c5?source=post_page-----1ba920cb9232--------------------------------)
    [## Denoising Diffusion Generative Models in Graph ML'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/denoising-diffusion-generative-models-in-graph-ml-c496af5811c5?source=post_page-----1ba920cb9232--------------------------------)
    [## 去噪扩散生成模型在图机器学习中的应用'
- en: Is Denoising Diffusion all you need?
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 去噪扩散模型就是你所需的一切吗？
- en: towardsdatascience.com](/denoising-diffusion-generative-models-in-graph-ml-c496af5811c5?source=post_page-----1ba920cb9232--------------------------------)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/denoising-diffusion-generative-models-in-graph-ml-c496af5811c5?source=post_page-----1ba920cb9232--------------------------------)
- en: 'There, we reviewed newest generative models for *graph generation* (DiGress),
    *molecular conformer generation* (EDM, GeoDiff, Torsional Diffusion), *molecular
    docking* (DiffDock), *molecular linking* (DiffLinker), and *ligand generation*
    (DiffSBDD). As soon as the post went public, several amazing protein generation
    models were released:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在那里，我们回顾了最新的生成模型用于*图生成*（DiGress）、*分子构象生成*（EDM、GeoDiff、Torsional Diffusion）、*分子对接*（DiffDock）、*分子连接*（DiffLinker）和*配体生成*（DiffSBDD）。一旦帖子公开，几种令人惊叹的蛋白质生成模型也随之发布：
- en: '[**Chroma**](https://www.generatebiomedicines.com/chroma) from Generate Biomedicines
    allows to impose functional and geometric constraints, and even use natural language
    queries like “Generate a protein with CHAD domain” thanks to a small GPT-Neo trained
    on protein captioning;'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[**Chroma**](https://www.generatebiomedicines.com/chroma)来自Generate Biomedicines，允许施加功能性和几何约束，甚至可以使用自然语言查询，比如“生成一个具有CHAD结构域的蛋白质”，这要归功于一个小型的GPT-Neo，经过蛋白质标注的训练；'
- en: '![](../Images/7e24c508e8b597a6205035e92bd02e6d.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7e24c508e8b597a6205035e92bd02e6d.png)'
- en: '*Chroma protein generation. Source:* [*Generate Biomedicines*](https://www.generatebiomedicines.com/chroma)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*Chroma蛋白质生成。来源：* [*Generate Biomedicines*](https://www.generatebiomedicines.com/chroma)'
- en: '[**RoseTTaFold Diffusion**](https://www.bakerlab.org/2022/11/30/diffusion-model-for-protein-design/)
    (RF Diffusion) from the Baker Lab and MIT is packed with the similar functionality
    also allowing for text prompts like “Generate a protein that binds to X” as well
    as being capable of functional motif scaffolding, scaffolding enzyme active sites,
    and *de novo* protein design. Strong point: 1000 designs generated with RF Diffusion
    were experimentally [synthesized and tested](https://twitter.com/DaveJuergens/status/1601675072175239170)
    in the lab!'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[**RoseTTaFold Diffusion**](https://www.bakerlab.org/2022/11/30/diffusion-model-for-protein-design/)（RF
    Diffusion）来自Baker Lab和MIT，具有类似功能，还支持文本提示，如“生成一个能够结合X的蛋白质”，并且能够进行功能性基序支架、酶活性位点支架和*de
    novo*蛋白质设计。强项：用RF Diffusion生成的1000种设计在实验室中[被合成和测试](https://twitter.com/DaveJuergens/status/1601675072175239170)！'
- en: '![](../Images/d6ce018a9c6d17df43d48a15da42dce6.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d6ce018a9c6d17df43d48a15da42dce6.png)'
- en: '*RF Diffusion. Source:* [*Watson et al.*](https://www.biorxiv.org/content/10.1101/2022.12.09.519842v1)
    *BakerLab*'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*RF Diffusion。来源：* [*Watson等*](https://www.biorxiv.org/content/10.1101/2022.12.09.519842v1)
    *BakerLab*'
- en: 'The Meta AI FAIR team made amazing progress in protein design purely with language
    models: mid-2022, [**ESM-2**](https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1)
    was released, a protein LM trained solely on protein sequences that outperforms
    ESM-1 and other baselines by a huge margin. Moreover, it was then shown that encoded
    LM representations are a very good starting point for obtaining the actual geometric
    configuration of a protein without the need for Multiple Sequence Alignments (MSAs)
    — this is done via [**ESMFold**](https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1).
    A big shoutout to Meta AI and FAIR for publishing the model and the weights: it
    is available in the [official GitHub repo](https://github.com/facebookresearch/esm)
    and [on HuggingFace](https://huggingface.co/models?other=esm) as well!'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Meta AI FAIR团队在蛋白质设计领域通过语言模型取得了惊人的进展：2022年中，[**ESM-2**](https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1)发布了，这是一种仅在蛋白质序列上训练的蛋白质语言模型，远超ESM-1及其他基准模型。而且，后来显示编码的语言模型表示是获得蛋白质实际几何结构的非常好的起点，而无需多重序列比对（MSAs）——这可以通过[**ESMFold**](https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1)实现。特别感谢Meta
    AI和FAIR发布了该模型及其权重：它在[官方GitHub仓库](https://github.com/facebookresearch/esm)和[HuggingFace](https://huggingface.co/models?other=esm)上也可以找到！
- en: '![](../Images/6d7f2f02320b2b61008ce8bb1973205d.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6d7f2f02320b2b61008ce8bb1973205d.png)'
- en: 'Scaling ESM-2 leads to better folding prediction. Source: [Lin, Akin, Rao,
    Hie et al](https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展ESM-2可以获得更好的折叠预测。来源：[Lin, Akin, Rao, Hie等](https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1)
- en: '🍭 Later on, even more goodies arrived from the ESM team: [Verkuil et al.](https://www.biorxiv.org/content/10.1101/2022.12.21.521521v1)
    find that ESM-2 can generate *de novo* protein sequences that can actually be
    synthesized in the lab and, more importantly, do not have any match among known
    natural proteins. [Hie et al.](https://www.biorxiv.org/content/10.1101/2022.12.21.521526v1)
    propose pretty much a new programming language for protein designers (think of
    it as a query language for ESMFold) — production rules organized in a syntax tree
    with constraint functions. Then, each program is “compiled” into an energy function
    that governs the generative process. Meta AI also released the biggest [Metagenomic
    Atlas](https://esmatlas.com/), but more on that in the **Datasets** section of
    this article.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 🍭 随后，来自ESM团队的更多好消息传来：[Verkuil等](https://www.biorxiv.org/content/10.1101/2022.12.21.521521v1)发现ESM-2可以生成*de
    novo*蛋白质序列，这些序列实际上可以在实验室中合成，并且更重要的是，它们在已知的自然蛋白质中没有任何匹配。[Hie等](https://www.biorxiv.org/content/10.1101/2022.12.21.521526v1)提出了一种全新的蛋白质设计编程语言（可以把它看作是ESMFold的查询语言）——生产规则以约束函数的语法树形式组织。然后，每个程序被“编译”为一个控制生成过程的能量函数。Meta
    AI还发布了最大的[Metagenomic Atlas](https://esmatlas.com/)，但更多内容请参见本文的**数据集**部分。
- en: In the antibody design area, a similar LM-based approach is taken by **IgLM**
    by [Shuai, Ruffolo, and Gray](https://www.biorxiv.org/content/10.1101/2021.12.13.472419v2).
    IGLM generates antibody sequences conditioned on chain and species id tags.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在抗体设计领域，**IgLM** 采用了类似的基于 LM 的方法，如 [Shuai、Ruffolo 和 Gray](https://www.biorxiv.org/content/10.1101/2021.12.13.472419v2)
    所述。IGLM 生成基于链和物种 ID 标签的抗体序列。
- en: 'Finally, we’d highlight a few works from Jian Tang’s lab at Mila. **MoleculeSTM**
    by [Liu et al.](https://arxiv.org/abs/2212.10789) is a CLIP-like text-to-molecule
    model (plus a new large pre-training dataset). MoleculeSTM can do 2 impressive
    things: (1) retrieve molecules by text description like “triazole derivatives”
    and retrieve text description from a given molecule in SMILES, (2) molecule editing
    from text prompts like “make the molecule soluble in water with low permeability”
    — and the model edits the molecular graph according to the description, mindblowing
    🤯'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们要特别提到 Jian Tang 实验室在 Mila 的一些工作。由 [Liu 等人](https://arxiv.org/abs/2212.10789)
    提出的 **MoleculeSTM** 是一个类似 CLIP 的文本到分子模型（以及一个新的大型预训练数据集）。MoleculeSTM 能做到两件令人印象深刻的事情：（1）通过文本描述如“噻唑衍生物”检索分子，并从给定的
    SMILES 分子中检索文本描述；（2）根据文本提示进行分子编辑，如“使分子在水中溶解且渗透性低”——模型根据描述编辑分子图谱，令人瞠目结舌 🤯
- en: Then, **ProtSEED** by [Shi et al.](https://arxiv.org/abs/2210.08761) is a generative
    model for protein sequence *and* structure simultaneously (for example, most existing
    diffusion models for proteins can do only one of those at a time). ProtSEED can
    be conditioned on residue features or pairs of residues. Model-wise, it is an
    equivariant iterative model with improved triangular attention. ProtSEED was evaluated
    on Antibody CDR co-design, Protein sequence-structure co-design, and Fixed backbone
    sequence design.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，[Shi 等人](https://arxiv.org/abs/2210.08761) 提出的 **ProtSEED** 是一个同时生成蛋白质序列
    *和* 结构的模型（例如，大多数现有的蛋白质扩散模型一次只能处理其中之一）。ProtSEED 可以基于残基特征或残基对进行条件设置。从模型的角度看，它是一个具有改进的三角注意力的对称迭代模型。ProtSEED
    在抗体 CDR 共同设计、蛋白质序列-结构共同设计和固定骨架序列设计中进行了评估。
- en: '![](../Images/e54ef61a84ca2aeca7a1b707387881e2.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e54ef61a84ca2aeca7a1b707387881e2.png)'
- en: 'Molecule editing from text inputs. Source: [Liu et al.](https://arxiv.org/abs/2212.10789)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 从文本输入中进行分子编辑。来源：[Liu 等人](https://arxiv.org/abs/2212.10789)
- en: Besides generating the protein structures, there are also some works for generating
    protein sequences from structures, known as inverse folding. Don’t forget to check
    out the [ESM-IF1](https://www.biorxiv.org/content/10.1101/2022.04.10.487779v2)
    from Meta and the [ProteinMPNN](https://www.science.org/doi/full/10.1126/science.add2187)
    from the Baker Lab.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 除了生成蛋白质结构外，还有一些工作致力于从结构生成蛋白质序列，这被称为逆折叠。不要忘记查看 Meta 的 [ESM-IF1](https://www.biorxiv.org/content/10.1101/2022.04.10.487779v2)
    和 Baker 实验室的 [ProteinMPNN](https://www.science.org/doi/full/10.1126/science.add2187)。
- en: '**What to expect in 2023**: (1) performance improvements of diffusion models
    such as faster sampling and more efficient solvers; (2) more powerful conditional
    protein generation models; (3) more successful applications of [Generative Flow
    Networks](https://arxiv.org/abs/2111.09266) (GFlowNets, check out the [tutorial](https://milayb.notion.site/The-GFlowNet-Tutorial-95434ef0e2d94c24aab90e69b30be9b3))
    to molecules and proteins.'
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**2023 年的预期**：（1）扩散模型的性能改进，例如更快的采样和更高效的求解器；（2）更强大的条件蛋白质生成模型；（3）对 [生成流网络](https://arxiv.org/abs/2111.09266)（GFlowNets，查看
    [教程](https://milayb.notion.site/The-GFlowNet-Tutorial-95434ef0e2d94c24aab90e69b30be9b3)）在分子和蛋白质中的更成功应用。'
- en: '**DFTs, ML Force Fields, Materials, and Weather Simulations**'
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**DFTs、ML 力场、材料和天气模拟**'
- en: AI4Science becomes the frontier of equivariant GNN research and its applications.
    Pairing GNNs with PDEs, we can now tackle much more complex prediction tasks.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: AI4Science 成为对称 GNN 研究及其应用的前沿。通过将 GNN 与 PDEs 配对，我们现在可以处理更复杂的预测任务。
- en: In 2022, this frontier expanded to ML-based **Density Functional Theory** (DFT)
    and **Force fields** approximations used for **molecular dynamics** and **material
    discovery.** The other growing field is **Weather simulations**.
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 2022 年，这一前沿领域扩展到了用于 **分子动力学** 和 **材料发现** 的基于 ML 的 **密度泛函理论**（DFT）和 **力场** 近似。另一个不断增长的领域是
    **天气模拟**。
- en: We would recommend the [talk](https://www.youtube.com/watch?v=t7q_ZNrBghY) by
    Max Welling for a broader overview of AI4Science and what is now enabled by using
    Deep Learning in science.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们推荐 Max Welling 的 [讲座](https://www.youtube.com/watch?v=t7q_ZNrBghY)，以获得关于 AI4Science
    的更广泛概述，以及深度学习在科学中的应用现状。
- en: Starting with models, 2022 has seen a surge in equivariant GNNs for molecular
    dynamics and simulations, e.g., building upon [NequIP](https://arxiv.org/abs/2101.03164),
    **Allegro** by [Musaelian, Batzner, et al.](https://arxiv.org/abs/2204.05249)
    or **MACE** by [Batatia et al.](https://arxiv.org/abs/2206.07697) The design space
    for such models is very large, so refer to the recent survey by [Batatia, Batzner,
    et al.](https://arxiv.org/abs/2205.06643) for an overview. A crucial component
    for most of them is the [**e3nn**](https://github.com/e3nn/e3nn) library (paper
    by [Geiger and Smidt](https://arxiv.org/abs/2207.09453)) and the notion of tensor
    product. We highly recommend a great [new course](https://uvagedl.github.io/)
    by Erik Bekkers on Group Equivariant Deep Learning to understand the mathematical
    foundations and catch up with the recent papers.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 从模型开始，2022年见证了等变GNN在分子动力学和模拟中的激增，例如，基于[NequIP](https://arxiv.org/abs/2101.03164)、由[Musaelian、Batzner等人](https://arxiv.org/abs/2204.05249)提出的**Allegro**或由[Batatia
    et al.](https://arxiv.org/abs/2206.07697)提出的**MACE**。这些模型的设计空间非常大，因此可以参考[Batatia、Batzner等人](https://arxiv.org/abs/2205.06643)的最新综述以获得概述。对于大多数模型来说，一个关键组件是[**e3nn**](https://github.com/e3nn/e3nn)库（[Geiger和Smidt](https://arxiv.org/abs/2207.09453)的论文）和张量积的概念。我们强烈推荐Erik
    Bekkers提供的一个出色的[新课程](https://uvagedl.github.io/)，以理解数学基础并跟上最新论文。
- en: ⚛️ **Density Functional Theory** (DFT) calculations are one of the main workhorses
    of molecular dynamics (and account for a great deal of computing time in big clusters).
    DFT is O(n³) to the input size though, so can ML help here? In *Learned Force
    Fields Are Ready For Ground State Catalyst Discovery,* [Schaarschmidt et al.](https://arxiv.org/abs/2209.12466)
    present the experimental study of models of learned potentials — turns out GNNs
    can do a very good job in linear O(n) time! The **Easy Potentials** approach (trained
    on Open Catalyst data) turns out to be quite a good predictor especially when
    paired with a postprocessing step. Model-wise, it is an MPNN with the [Noisy Nodes](https://arxiv.org/abs/2106.07971)
    self-supervised objective.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ⚛️ **密度泛函理论**（DFT）计算是分子动力学的主要工具之一（并且在大型集群中占据了大量计算时间）。然而，DFT的时间复杂度是O(n³)，那么机器学习能否有所帮助呢？在*学习到的力场已准备好用于基态催化剂发现*中，[Schaarschmidt
    et al.](https://arxiv.org/abs/2209.12466)展示了学习势能模型的实验研究——结果表明GNNs在O(n)线性时间内可以表现得非常好！**Easy
    Potentials**方法（基于Open Catalyst数据训练）证明是一个非常好的预测器，特别是与后处理步骤配合时。模型方面，它是一个带有[Noisy
    Nodes](https://arxiv.org/abs/2106.07971)自监督目标的MPNN。
- en: In **Forces are not Enough**, [Fu et al.](https://arxiv.org/abs/2210.07237)
    introduce a new benchmark for molecular dynamics — in addition to MD17, the authors
    add datasets on modeling liquids (Water), peptides (Alanine dipeptide), and solid-state
    materials (LiPS). More importantly, the authors consider a wide range of physical
    properties like stability of simulations, diffusivity, and radial distribution
    functions. Most SOTA molecular dynamics models were probed including SchNet, ForceNet,
    DimeNet, GemNet (-T and -dT), and NequIP.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在**《力量不足》**中，[Fu et al.](https://arxiv.org/abs/2210.07237)提出了一个新的分子动力学基准——除了MD17，作者们还添加了液体（水）、肽（丙氨酸二肽）和固态材料（LiPS）的数据集。更重要的是，作者们考虑了广泛的物理属性，如模拟的稳定性、扩散性和径向分布函数。包括SchNet、ForceNet、DimeNet、GemNet（-T和-dT）以及NequIP在内的大多数SOTA分子动力学模型都被探讨了。
- en: '![](../Images/b1ffbec28f6b6c061b8f5f66ff7fdc9e.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b1ffbec28f6b6c061b8f5f66ff7fdc9e.png)'
- en: 'Source: [Fu et al.](https://arxiv.org/abs/2210.07237)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [Fu et al.](https://arxiv.org/abs/2210.07237)'
- en: In crystal structure modeling, we’d highlight **Equivariant Crystal Networks**
    by [Kaba and Ravanbakhsh](https://openreview.net/forum?id=0Dh8dz4snu) — a neat
    way to build representations of periodic structures with crystalline symmetries.
    Crystals can be described with *lattices* and *unit cells* with basis vectors
    that are subject to group transformations. Conceptually, ECN creates edge index
    masks corresponding to symmetry groups, performs message passing over this masked
    index, and aggregates the results of many symmetry groups.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在晶体结构建模中，我们要特别提到由[Kaba和Ravanbakhsh](https://openreview.net/forum?id=0Dh8dz4snu)提出的**等变晶体网络**——一种用来构建具有晶体对称性的周期性结构表示的巧妙方法。晶体可以用*晶格*和*单位胞*来描述，基向量可以进行群变换。概念上，ECN创建了与对称群对应的边索引掩码，对这些掩码索引进行消息传递，并聚合多个对称群的结果。
- en: '![](../Images/e6422b43252d3ad7ca97e55de20b9931.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e6422b43252d3ad7ca97e55de20b9931.png)'
- en: 'Source: [Kaba and Ravanbakhsh](https://openreview.net/forum?id=0Dh8dz4snu)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [Kaba和Ravanbakhsh](https://openreview.net/forum?id=0Dh8dz4snu)'
- en: Even more news on material discovery can found in the proceedings of the recent
    [AI4Mat NeurIPS workshop](https://sites.google.com/view/ai4mat)!
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 关于材料发现的更多消息可以在最近的 [AI4Mat NeurIPS workshop](https://sites.google.com/view/ai4mat)
    会议记录中找到！
- en: ☂️ ML-based weather forecasting made a huge progress as well. In particular,
    [**GraphCast**](https://arxiv.org/abs/2212.12794) by DeepMind and [**Pangu-Weather**](https://arxiv.org/abs/2211.02556)
    by Huawei demonstrated exceptionally good results outperforming traditional models
    by a large margin. While Pangu-Weather leverages 3D/visual inputs and Visual Transformers,
    GraphCast employs a mesh MPNN where Earth is split into several hierarchy levels
    of meshes. The deepest level has about 40K nodes with 474 input features and the
    model outputs 227 predicted variables. The MPNN follows the “encoder-processor-decoder”
    and has 16 layers. GraphCast is autoregressive model w.r.t. the next timestep
    prediction, that is, it takes previous two states and predicts the next one. GraphCast
    can build a 10-day forecast in <60 seconds on a single TPUv4 and is much more
    accurate than non-ML forecasting models. 👏
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ☂️ 基于机器学习的天气预报也取得了巨大的进展。特别是，DeepMind 的 [**GraphCast**](https://arxiv.org/abs/2212.12794)
    和华为的 [**Pangu-Weather**](https://arxiv.org/abs/2211.02556) 展示了出色的结果，大大超越了传统模型。虽然
    Pangu-Weather 利用 3D/视觉输入和视觉变换器，GraphCast 则采用了网格 MPNN，其中地球被分割为多个层级的网格。最深层有大约 40K
    节点，具有 474 个输入特征，模型输出 227 个预测变量。MPNN 遵循“编码器-处理器-解码器”结构，并具有 16 层。GraphCast 是一个自回归模型，相对于下一个时间步预测，即它利用前两个状态预测下一个状态。GraphCast
    可以在单个 TPUv4 上在 <60 秒内建立 10 天的预测，并且比非机器学习预测模型准确得多。👏
- en: '![](../Images/642385acd4eeb71b13131b45b29d0697.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/642385acd4eeb71b13131b45b29d0697.png)'
- en: 'Encoder-Processor-Decoder mesh MPNN in GraphCast. Source: [Lam, Sanchez-Gonzalez,
    Willson, Wirnsberger, Fortunato, Pritzel, et al.](https://arxiv.org/abs/2212.12794)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: GraphCast 中的编码器-处理器-解码器网格 MPNN。来源：[Lam, Sanchez-Gonzalez, Willson, Wirnsberger,
    Fortunato, Pritzel 等](https://arxiv.org/abs/2212.12794)
- en: '**What to expect in 2023**: We expect to see a lot more focus on computational
    efficiency and scalability of GNNs. Current GNN-based force-fields are obtaining
    remarkable accuracy, but are still 2–3 orders of magnitude slower than classical
    force-fields and are typically only deployed on a few hundred atoms. For GNNs
    to truly have a transformative impact on materials science and drug discovery,
    we will see many folks tackling this issue, be it through architectural advances
    or smarter sampling.'
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**2023年的期待**：我们期望看到更多关注 GNN 的计算效率和可扩展性。目前基于 GNN 的力场取得了显著的准确性，但仍比经典力场慢 2-3 个数量级，并且通常只部署在几百个原子上。为了使
    GNN 在材料科学和药物发现中真正发挥变革性影响，我们将看到许多人致力于解决这个问题，无论是通过架构进步还是更智能的采样方法。'
- en: Geometry & Topology & PDEs
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 几何学 & 拓扑学 & PDEs
- en: In 2022, 1️⃣ we got a better understanding of oversmoothing and oversquashing
    phenomena in GNNs and their connections to algebraic topology; 2️⃣ using GNNs
    for PDE modeling is now mainstream.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在 2022 年，1️⃣ 我们对 GNN 中的过度平滑和过度压缩现象及其与代数拓扑的关系有了更好的理解；2️⃣ 使用 GNN 进行 PDE 建模现在已经成为主流。
- en: 1️⃣ Michael Bronstein’s lab made huge contributions to this problem — check
    those excellent posts on Neural Sheaf Diffusion and framing GNNs as gradient flows
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 1️⃣ Michael Bronstein 的实验室对这个问题做出了巨大贡献 —— 查看那些关于神经切片扩散和将 GNN 视为梯度流的优秀帖子。
- en: '[](/neural-sheaf-diffusion-for-deep-learning-on-graphs-bfa200e6afa6?source=post_page-----1ba920cb9232--------------------------------)
    [## Neural Sheaf Diffusion for deep learning on graphs'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/neural-sheaf-diffusion-for-deep-learning-on-graphs-bfa200e6afa6?source=post_page-----1ba920cb9232--------------------------------)
    [## 神经切片扩散在图上的深度学习'
- en: Cellular sheaf theory, a branch of algebraic topology, provides new insights
    into how Graph Neural Networks work and…
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 细胞切片理论，作为代数拓扑的一个分支，为图神经网络的工作原理提供了新的见解…
- en: towardsdatascience.com](/neural-sheaf-diffusion-for-deep-learning-on-graphs-bfa200e6afa6?source=post_page-----1ba920cb9232--------------------------------)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/neural-sheaf-diffusion-for-deep-learning-on-graphs-bfa200e6afa6?source=post_page-----1ba920cb9232--------------------------------)'
- en: 'And on GNNs as gradient flows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 以及关于 GNN 作为梯度流的内容：
- en: '[](/graph-neural-networks-as-gradient-flows-4dae41fb2e8a?source=post_page-----1ba920cb9232--------------------------------)
    [## Graph Neural Networks as gradient flows'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/graph-neural-networks-as-gradient-flows-4dae41fb2e8a?source=post_page-----1ba920cb9232--------------------------------)
    [## 图神经网络作为梯度流'
- en: GNNs derived as gradient flows minimising a learnable energy that describes
    attractive and repulsive forces between…
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GNN 作为梯度流的衍生物，通过最小化描述吸引力和排斥力的可学习能量来优化…
- en: towardsdatascience.com](/graph-neural-networks-as-gradient-flows-4dae41fb2e8a?source=post_page-----1ba920cb9232--------------------------------)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/graph-neural-networks-as-gradient-flows-4dae41fb2e8a?source=post_page-----1ba920cb9232--------------------------------)'
- en: 2️⃣ Using GNNs for PDE modeling became a mainstream topic. Some papers require
    the 🤯 **math alert** 🤯 warning, but if you are familiar with the basics of ODEs
    and PDEs it should be much easier.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 2️⃣ 使用 GNNs 进行 PDE 建模已成为主流话题。一些论文需要 🤯 **数学警报** 🤯 提示，但如果你对 ODEs 和 PDEs 的基础知识很熟悉，这应该会更容易。
- en: '*Message Passing Neural PDE Solvers* by [Brandstetter, Worrall, and Welling](https://openreview.net/forum?id=vSix3HPYKSU)
    describe how message passing can help solving PDEs, generalize better, and get
    rid of manual heuristics. Furthermore, MP-PDEs representationally contain classic
    solvers like finite differences.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '*消息传递神经 PDE 求解器* 由 [Brandstetter, Worrall, 和 Welling](https://openreview.net/forum?id=vSix3HPYKSU)
    描述了消息传递如何帮助解决 PDE，具有更好的泛化能力，并摆脱手动启发式。此外，MP-PDEs 在表示上包含经典求解器，如有限差分。'
- en: '![](../Images/4e9be60b522337c75d2f485d5e19ed8d.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4e9be60b522337c75d2f485d5e19ed8d.png)'
- en: 'Source: [Brandstetter, Worrall, and Welling](https://openreview.net/forum?id=vSix3HPYKSU)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [Brandstetter, Worrall, 和 Welling](https://openreview.net/forum?id=vSix3HPYKSU)'
- en: The topic was developed further by many recent works including continuous forecasting
    with implicit neural representations ([Yin et al.](https://arxiv.org/abs/2209.14855)),
    supporting mixed boundary conditions ([Horie and Mitsume](https://openreview.net/forum?id=B3TOg-YCtzo)),
    or latent evolution of PDEs ([Wu et al.](https://arxiv.org/abs/2206.07681))
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 该主题通过许多近期工作得到了进一步发展，包括使用隐式神经表示进行连续预测 ([Yin et al.](https://arxiv.org/abs/2209.14855))、支持混合边界条件
    ([Horie and Mitsume](https://openreview.net/forum?id=B3TOg-YCtzo))，或 PDE 的潜在演变
    ([Wu et al.](https://arxiv.org/abs/2206.07681))
- en: '**What to expect in 2023**: Neural PDEs and their applications are likely to
    expand to more physics-related AI4Science subfields, where especially computational
    fluid dynamics (CFD) will potentially be influenced by GNN based surrogates in
    the coming months. Classical CFD is applied to a wide range of research and engineering
    problems in many fields of study, including aerodynamics, hypersonic and environmental
    engineering, fluid flows, visual effects in video games, or weather simulations
    as discussed above. GNN based surrogates might augment/replace traditional well-tried
    techniques such as finite element methods ([Lienen et al.](https://arxiv.org/abs/2203.08852)),
    remeshing algorithms ([Song et al.](https://arxiv.org/abs/2204.11188)), boundary
    value problems ([Loetsch et al.](https://arxiv.org/abs/2206.14092)), or interactions
    with triangularized boundary geometries ([Mayr et al.](https://arxiv.org/abs/2106.11299)).'
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**2023 年的期待**：神经 PDE 及其应用有可能扩展到更多与物理相关的 AI4Science 子领域，特别是计算流体动力学（CFD）在未来几个月可能会受到基于
    GNN 的替代品的影响。经典的 CFD 被广泛应用于多个领域的研究和工程问题，包括空气动力学、高超声速和环境工程、流体流动、视频游戏中的视觉效果，或上述天气模拟。基于
    GNN 的替代品可能会增强/替代传统的经过验证的技术，如有限元方法 ([Lienen et al.](https://arxiv.org/abs/2203.08852))、重网格算法
    ([Song et al.](https://arxiv.org/abs/2204.11188))、边值问题 ([Loetsch et al.](https://arxiv.org/abs/2206.14092))，或与三角化边界几何的交互
    ([Mayr et al.](https://arxiv.org/abs/2106.11299))。'
- en: ''
  id: totrans-88
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The neural PDE community is starting to build strong and commonly used baselines
    and frameworks, which will in return help to accelerate the progress, e.g. **PDEBench**
    ([Takamoto et al.](https://arxiv.org/abs/2210.07182)) or **PDEArena** ([Gupta
    et al.](https://arxiv.org/abs/2209.15616))
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 神经 PDE 社区正在开始建立强大且常用的基准和框架，这将反过来帮助加速进展，例如 **PDEBench** ([Takamoto et al.](https://arxiv.org/abs/2210.07182))
    或 **PDEArena** ([Gupta et al.](https://arxiv.org/abs/2209.15616))
- en: Graph Transformers
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图神经网络变换器
- en: 'Definitely one of the main community drivers in 2022, **graph transformers**
    (GTs) evolved a lot towards higher effectiveness and better scalability. Several
    outstanding models published in 2022:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 绝对是 2022 年的主要社区推动力之一，**图神经网络变换器**（GTs）在有效性和可扩展性方面有了很大进展。2022 年发布了几个杰出的模型：
- en: '**👑 GraphGPS** by [Rampášek et al.](https://arxiv.org/abs/2205.12454) takes
    the title of **“GT of 2022”** thanks to combining local message passing, global
    attention (optionally, linear for higher efficiency), and positional encodings
    that led to setting a new SOTA on ZINC and many other benchmarks. Check out a
    dedicated article on GraphGPS'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**👑 GraphGPS** 由 [Rampášek et al.](https://arxiv.org/abs/2205.12454) 提出的，因其结合了局部消息传递、全局注意力（可选地，线性以提高效率）和位置编码，最终在
    ZINC 和许多其他基准上设立了新的 SOTA 标杆，被誉为 **“2022 年的 GT”**。查看有关 GraphGPS 的专门文章'
- en: '[](/graphgps-navigating-graph-transformers-c2cc223a051c?source=post_page-----1ba920cb9232--------------------------------)
    [## GraphGPS: Navigating Graph Transformers'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/graphgps-navigating-graph-transformers-c2cc223a051c?source=post_page-----1ba920cb9232--------------------------------)
    [## GraphGPS: 导航图形变换器'
- en: Recipes for cooking the best graph transformers
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最佳图形变换器的烹饪秘诀
- en: towardsdatascience.com](/graphgps-navigating-graph-transformers-c2cc223a051c?source=post_page-----1ba920cb9232--------------------------------)
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/graphgps-navigating-graph-transformers-c2cc223a051c?source=post_page-----1ba920cb9232--------------------------------)
- en: GraphGPS served as a backbone of **GPS++,** the [winning](https://ogb.stanford.edu/neurips2022/results/#winners_pcqm4mv2)
    OGB Large Scale Challenge 2022 model on PCQM4M v2 (graph regression). **GPS++**,
    [created by](https://arxiv.org/abs/2212.02229) Graphcore, Valence Discovery, and
    Mila, incorporates more features including 3D coordinates and leverages sparse-optimized
    IPU hardware (more on that in the following section). GPS++ weights are already
    [available](https://github.com/graphcore/ogb-lsc-pcqm4mv2) on GitHub!
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: GraphGPS 作为 **GPS++** 的核心，[获胜](https://ogb.stanford.edu/neurips2022/results/#winners_pcqm4mv2)
    OGB 大规模挑战赛 2022 模型在 PCQM4M v2（图回归）上表现突出。**GPS++**，[由](https://arxiv.org/abs/2212.02229)
    Graphcore、Valence Discovery 和 Mila 创建，整合了更多特性，包括 3D 坐标，并利用了稀疏优化的 IPU 硬件（更多信息见下一节）。GPS++
    权重已在 GitHub 上[可用](https://github.com/graphcore/ogb-lsc-pcqm4mv2)！
- en: '![](../Images/030d6d10617c7e1782ce0d078c915c21.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/030d6d10617c7e1782ce0d078c915c21.png)'
- en: 'GraphGPS intuition. Source: [Rampášek et al](https://arxiv.org/abs/2205.12454)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: GraphGPS 直观理解。来源：[Rampášek et al](https://arxiv.org/abs/2205.12454)
- en: '**Transformer-M** by [Luo et al.](https://arxiv.org/abs/2210.01765) inspired
    many top OGB LSC models as well. Transformer-M adds 3D coordinates to the neat
    mix of joint 2D-3D pre-training. At inference time, when 3D info is not known,
    the model would infer a glimpse of 3D knowledge which improves the performance
    on PCQM4Mv2 by a good margin. Code is [available](https://github.com/lsj2408/Transformer-M)
    either.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**Transformer-M** 由 [Luo et al.](https://arxiv.org/abs/2210.01765) 提出的方法也启发了许多顶级
    OGB LSC 模型。Transformer-M 将 3D 坐标添加到整洁的 2D-3D 预训练混合中。在推理时，当 3D 信息未知时，该模型将推断出一部分
    3D 知识，从而显著提高 PCQM4Mv2 的性能。代码[可用](https://github.com/lsj2408/Transformer-M)。'
- en: '![](../Images/2b5d5841cfa0a2d34817e2a1d077b999.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2b5d5841cfa0a2d34817e2a1d077b999.png)'
- en: '*Transformer-M joint 2D-3D pre-training scheme. Source:* [*Luo et al.*](https://arxiv.org/abs/2210.01765)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*Transformer-M 2D-3D 预训练方案。来源：* [*Luo et al.*](https://arxiv.org/abs/2210.01765)'
- en: '**TokenGT** by [Kim et al](https://arxiv.org/abs/2207.02505) goes even more
    explicit and adds all edges of the input graph (in addition to all nodes) to the
    sequence fed to the Transformer. With those inputs, encoder needs additional token
    types to distinguish nodes from edges. The authors prove several nice theoretical
    properties (although at the cost of higher computational complexity O((V+E)²)
    that can get to the 4th power in the worst case of a fully-connected graph). Code
    is [available](https://github.com/jw9730/tokengt).'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**TokenGT** 由 [Kim et al](https://arxiv.org/abs/2207.02505) 提出的方法更加明确，并将输入图的所有边（除了所有节点）添加到喂给
    Transformer 的序列中。使用这些输入，编码器需要额外的标记类型来区分节点和边。作者证明了几个很好的理论性质（尽管代价是较高的计算复杂度 O((V+E)²)，在完全连接图的最坏情况下可能达到四次方）。代码[可用](https://github.com/jw9730/tokengt)。'
- en: '![](../Images/362b38baa863661789419ac3384b6568.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/362b38baa863661789419ac3384b6568.png)'
- en: 'TokenGT adds both nodes and edges to the input sequence. Source: [Kim et al](https://arxiv.org/abs/2207.02505)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: TokenGT 将节点和边都添加到输入序列中。来源：[Kim et al](https://arxiv.org/abs/2207.02505)
- en: '**What to expect in 2023**: for the coming year, we’d expect 1️⃣ GTs to scale
    up along the axes of both data and model parameters, from molecules of <50 nodes
    to graphs of millions of nodes, in order to witness the emergent behavior as in
    text & vision foundation models 2️⃣ similar to [BLOOM](https://huggingface.co/bigscience/bloom)
    by the BigScience Initiative, a big open-source pre-trained equivariant GT for
    molecular data, perhaps within the [Open Drug Discovery](https://m2d2.io/opendrugdiscovery/)
    project.'
  id: totrans-105
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**2023 年的预期**：在来年，我们预计 1️⃣ GTs 在数据和模型参数两个维度上扩展，从小于 50 节点的分子到数百万节点的图，以见证如文本和视觉基础模型中的突现行为
    2️⃣ 类似于 [BLOOM](https://huggingface.co/bigscience/bloom) 由 BigScience Initiative
    提供的用于分子数据的大型开源预训练等变 GT，也许在 [Open Drug Discovery](https://m2d2.io/opendrugdiscovery/)
    项目中。'
- en: BIG Graphs
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大图
- en: 🔥 One of our favorites in 2022 is *“Graph Neural Networks for Link Prediction
    with Subgraph Sketching*” by [Chamberlain, Shirobokov et al.](https://arxiv.org/abs/2209.15486)
    — this is a neat combination of algorithms + ML techniques. It is known that [SEAL](https://arxiv.org/pdf/2010.16103.pdf)-like
    labeling tricks dramatically improve link prediction performance compared to standard
    GNN encoders but suffer from big computation/memory overhead. In this work, the
    authors find that obtaining distances from two nodes of a query edge can be efficiently
    done with hashing ([MinHashing](https://en.wikipedia.org/wiki/MinHash)) and cardinality
    estimation ([HyperLogLog](https://en.wikipedia.org/wiki/HyperLogLog)) algorithms.
    Essentially, message passing is done over *minhashing* and *hyperloglog* initial
    sketches of single nodes (*min* aggregation for minhash, *max* for hyperloglog
    sketches) — this is the core of the **ELPH** link prediction model (with a simple
    MLP decoder). The authors then design a more scalable **BUDDY** model where k-hop
    hash propagation can be precomputed before training. Experimentally, ELPH and
    BUDDY scale to large graphs that were previously way too large or resource hungry
    for labeling trick approaches. Great work and definitely a solid baseline for
    all future link prediction models! 👏
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 🔥 我们在 2022 年最喜欢的一篇是[Chamberlain, Shirobokov 等](https://arxiv.org/abs/2209.15486)的
    *“基于子图草图的链接预测图神经网络*”——这是算法与 ML 技术的巧妙结合。众所周知，[SEAL](https://arxiv.org/pdf/2010.16103.pdf)
    类的标记技巧相比于标准 GNN 编码器可以显著提升链接预测性能，但却面临巨大的计算/内存开销。在这项工作中，作者发现利用哈希 ([MinHashing](https://en.wikipedia.org/wiki/MinHash))
    和基数估计 ([HyperLogLog](https://en.wikipedia.org/wiki/HyperLogLog)) 算法，可以高效地获取查询边两个节点之间的距离。本质上，消息传递是在
    *minhashing* 和 *hyperloglog* 单节点的初步草图（*min* 聚合用于 minhash，*max* 用于 hyperloglog
    草图）上进行的——这就是**ELPH** 链接预测模型的核心（带有简单的 MLP 解码器）。然后，作者设计了一个更具可扩展性的 **BUDDY** 模型，其中
    k-hop 哈希传播可以在训练前预计算。实验表明，ELPH 和 BUDDY 可以扩展到以前过于庞大或资源消耗过大的图中。出色的工作，绝对是未来所有链接预测模型的坚实基线！👏
- en: '![](../Images/0a1e1985708d039dbfd156a1aef9ac06.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0a1e1985708d039dbfd156a1aef9ac06.png)'
- en: 'The motivation behind computing subgraph hashes to estimate cardinalities of
    neighborhoods and intersections. Source: [Chamberlain, Shirobokov et al.](https://arxiv.org/abs/2209.15486)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 计算子图哈希以估计邻域和交集基数的动机。来源：[Chamberlain, Shirobokov 等](https://arxiv.org/abs/2209.15486)
- en: On the graph sampling and minibatching side, [Gasteiger, Qian, and Günnemann](https://openreview.net/forum?id=b9g0vxzYa_)
    design [**Influence-based Mini-Batching (IBMB)**](https://github.com/tum-daml/ibmb),
    a good example how Personalized PageRank (PPR) can solve even graph batching!
    IBMB aims at creating the smallest minibatches whose nodes have the maximum influence
    on the node classification task. In fact, the influence score is equivalent to
    PPR. Practically, given a set of target nodes, IBMB (1) partitions the graph into
    permanent clusters, (2) runs PPR within each batch to select top-PPR nodes that
    would form a final subgraph minibatch. The resulting minibatches can be sent to
    any GNN encoder. IBMB is pretty much **constant** O(1) to the graph size where
    partitioning and PPRs can be precomputed at the pre-processing stage.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在图采样和迷你批处理方面，[Gasteiger, Qian, 和 Günnemann](https://openreview.net/forum?id=b9g0vxzYa_)
    设计了[**基于影响力的迷你批处理 (IBMB)**](https://github.com/tum-daml/ibmb)，这是个很好的例子，说明个性化PageRank
    (PPR) 如何解决图批处理问题！IBMB 旨在创建对节点分类任务影响最大的最小迷你批次。实际上，影响力分数等同于 PPR。实际上，给定一组目标节点，IBMB
    (1) 将图划分为永久集群，(2) 在每个批次内运行 PPR，选择 top-PPR 节点以形成最终的子图迷你批次。生成的迷你批次可以发送到任何 GNN 编码器。IBMB
    对图的大小几乎是**常数** O(1)，因为分区和 PPR 可以在预处理阶段预计算。
- en: Although the resulting batches are fixed and do not change over training (not
    stochastic enough), the authors design momentum-like optimization terms to mitigate
    this non-stochasticity. IBMB can be used both in training and inference with massive
    speedups — up to 17x and 130x, respectively 🚀
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管生成的批次是固定的，并且在训练过程中不会改变（不够随机），但作者设计了类似动量的优化项来缓解这种非随机性。IBMB 可以在训练和推理中使用，速度提升可达
    17 倍和 130 倍 🚀
- en: '![](../Images/79a47281579302493940b6b733e1b1c3.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/79a47281579302493940b6b733e1b1c3.png)'
- en: 'Influence-based mini-batching. Source: [Gasteiger, Qian, and Günnemann](https://openreview.net/forum?id=b9g0vxzYa_)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 基于影响力的迷你批处理。来源：[Gasteiger, Qian, 和 Günnemann](https://openreview.net/forum?id=b9g0vxzYa_)
- en: The subtitle of this subsection could be “*brought to you by Google*” since
    the majority of the papers have authors from Google ;)
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 本小节的副标题可以是“*由谷歌提供*”，因为大多数论文的作者都来自谷歌 ;)
- en: '[Carey et al.](https://openreview.net/pdf?id=q5h7Ywx-sS) created ***Stars***,
    a method for building sparse similarity graphs at the scale of **tens of trillions**
    of edges 🤯. Pairwise N² comparisons would obviously not work here — Stars employs
    two-hop [spanner graphs](https://en.wikipedia.org/wiki/Geometric_spanner) (those
    are the graphs where similar points are connected with at most two hops) and [SortingLSH](http://infolab.stanford.edu/~bawa/Pub/similarity.pdf)
    that together enable almost linear time complexity and high sparsity.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[Carey等](https://openreview.net/pdf?id=q5h7Ywx-sS) 创建了***Stars***，一种在**数十万亿**边的规模下构建稀疏相似性图的方法🤯。成对的N²比较显然不可行——Stars使用了两个跳数的[spanner图](https://en.wikipedia.org/wiki/Geometric_spanner)（这些图中相似的点通过最多两个跳数连接）和[SortingLSH](http://infolab.stanford.edu/~bawa/Pub/similarity.pdf)，两者结合使得接近线性的时间复杂度和高稀疏性成为可能。'
- en: '[Dhulipala et al.](https://openreview.net/pdf?id=LpgG0C6Y75) created **ParHAC**,
    an approximate (1+𝝐) parallel algorithm for hierarchical agglomerative clustering
    (HAC) on very large graphs and extensive theoretical foundations of the algorithm.
    ParHAC has O(V+E) complexity and poly-log depth and runs up to 60x faster than
    baselines on graphs with **hundreds of billions** of edges (here it is the Hyperlink
    graph with 1.7B nodes and 125B edges).'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[Dhulipala等](https://openreview.net/pdf?id=LpgG0C6Y75) 创建了**ParHAC**，一种用于非常大图的近似（1+𝝐）并行层次聚类（HAC）算法及其广泛的理论基础。ParHAC具有O(V+E)复杂度和多对数深度，在具有**数百亿**边的图上运行速度比基线快高达60倍（这里是具有1.7B节点和125B边的超链接图）。'
- en: '[Devvrit et al.](https://openreview.net/pdf?id=ldl2V3vLZ5) created **S³GC**,
    a scalable self-supervised graph clustering algorithm with one-layer GNN and constrastive
    training objective. S³GC uses both graph structure and node features and scales
    to graphs of up to 1.6B edges.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[Devvrit等](https://openreview.net/pdf?id=ldl2V3vLZ5) 创建了**S³GC**，一种可扩展的自监督图聚类算法，使用单层GNN和对比训练目标。S³GC使用图结构和节点特征，能够扩展到高达1.6B边的图。'
- en: Finally, [Epasto et al.](https://openreview.net/forum?id=Fhty8PgFkDo) created
    a differentially-private modification of PageRank!
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，[Epasto等](https://openreview.net/forum?id=Fhty8PgFkDo) 创建了PageRank的差分隐私修改版本！
- en: 'LoG 2022 featured two tutorials on large-scale GNNs: [Scaling GNNs in Production](https://www.youtube.com/watch?v=HRC4hZKiUWU)
    by Da Zheng, Vassilis N. Ioannidis, and Soji Adeshina and [Parallel and Distributed
    GNNs](https://www.youtube.com/watch?v=e2jJU7u7si0) by Torsten Hoefler and Maciej
    Besta.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: LoG 2022包含了两个关于大规模GNN的教程：[生产中GNN的扩展](https://www.youtube.com/watch?v=HRC4hZKiUWU)由Da
    Zheng、Vassilis N. Ioannidis和Soji Adeshina主讲，以及[并行和分布式GNN](https://www.youtube.com/watch?v=e2jJU7u7si0)由Torsten
    Hoefler和Maciej Besta主讲。
- en: '**What to expect in 2023**: further reduction in compute costs and inference
    time for very large graphs. Perhaps models for OGB LSC graphs could run on commodity
    machines instead of huge clusters?'
  id: totrans-120
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**2023年值得期待**：进一步降低计算成本和推理时间，以应对非常大的图。也许OGB LSC图的模型可以在普通机器上运行，而不是在大型集群上？'
- en: 'GNN Theory: Weisfeiler and Leman Go Places, Subgraph GNNs'
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GNN理论：Weisfeiler和Leman的足迹，子图GNN
- en: '![](../Images/b7121cd3156f09a0fadc730188d2124d.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b7121cd3156f09a0fadc730188d2124d.png)'
- en: 'Tourists of the year! Source of the original portraits: [Towards Geometric
    Deep Learning IV: Chemical Precursors of GNNs](/towards-geometric-deep-learning-iv-chemical-precursors-of-gnns-11273d74125)
    by Michael Bronstein'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 年度游客！原始肖像来源：[几何深度学习IV：GNN的化学前体](/towards-geometric-deep-learning-iv-chemical-precursors-of-gnns-11273d74125)
    由Michael Bronstein主讲
- en: '🏖 🌄 Weisfeiler and Leman, grandfathers of Graph ML and GNN theory, had a very
    prolific traveling year! After visiting [Neural](https://ojs.aaai.org/index.php/AAAI/article/view/4384),
    [Sparse](https://proceedings.neurips.cc/paper/2020/file/f81dee42585b3814de199b2e88757f5c-Paper.pdf),
    [Topological](http://proceedings.mlr.press/v139/bodnar21a/bodnar21a.pdf), and
    [Cellular](https://proceedings.neurips.cc/paper/2021/file/157792e4abb490f99dbd738483e0d2d4-Paper.pdf)
    places in previous years, in 2022 we have seen them in several new places:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 🏖 🌄 Weisfeiler和Leman，图ML和GNN理论的奠基人，度过了非常多产的一年！继之前访问过[Neural](https://ojs.aaai.org/index.php/AAAI/article/view/4384)、[Sparse](https://proceedings.neurips.cc/paper/2020/file/f81dee42585b3814de199b2e88757f5c-Paper.pdf)、[Topological](http://proceedings.mlr.press/v139/bodnar21a/bodnar21a.pdf)和[Cellular](https://proceedings.neurips.cc/paper/2021/file/157792e4abb490f99dbd738483e0d2d4-Paper.pdf)场所后，2022年我们在几个新地方见到了他们：
- en: WL Go **Machine Learning** — a comprehensive survey by [Morris et al](https://arxiv.org/abs/2112.09992)
    on the basics of the WL test, terminology, and various applications;
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WL Go **机器学习** — [Morris等](https://arxiv.org/abs/2112.09992) 对WL测试的基础知识、术语及各种应用的综合调查；
- en: WL Go **Relational** — the first attempt by [Barcelo et al](https://arxiv.org/abs/2211.17113)
    to study expressiveness of relational GNNs used in multi-relational graphs and
    KGs. Turns out R-GCN and CompGCN are equally expressive and are bounded by the
    Relational 1-WL test, and the most expressive message function (aggregating entity-relation
    representations) is a Hadamard product;
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WL Go **关系** —— [Barcelo et al](https://arxiv.org/abs/2211.17113) 首次尝试研究在多关系图和知识图中使用的关系
    GNNs 的表现力。结果表明，R-GCN 和 CompGCN 的表现力相同，且受限于关系 1-WL 测试，最具表现力的消息函数（聚合实体-关系表示）是 Hadamard
    乘积；
- en: '[WL Go Walking by Niels M. Kriege](https://arxiv.org/abs/2205.10914) studies
    expressiveness of random walk kernels and finds that the RW kernel (with a small
    modification) is as expressive as a WL subtree kernel;'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[WL Go Walking by Niels M. Kriege](https://arxiv.org/abs/2205.10914) 研究了随机游走核的表现力，发现
    RW 核（经过小的修改）与 WL 子树核一样具表现力。'
- en: 'WL Go **Geometric**: [Joshi, Bodnar et al](https://openreview.net/forum?id=kXe4Y0c4VqT)
    propose Geometric WL test (GWL) to study expressiveness of equivariant and invariant
    GNNs (to ceratin symmetries: translation, rotation, reflection, permutation).
    Turns out, equivariant GNNs (such as [E-GNN](https://arxiv.org/abs/2102.09844),
    [NequIP](https://arxiv.org/abs/2101.03164) or [MACE](https://arxiv.org/abs/2206.07697))
    are provably more powerful than invariant GNNs (such as [SchNet](https://proceedings.neurips.cc/paper/2017/file/303ed4c69846ab36c2904d3ba8573050-Paper.pdf)
    or [DimeNet](https://arxiv.org/abs/2011.14115));'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WL Go **几何**：[Joshi, Bodnar et al](https://openreview.net/forum?id=kXe4Y0c4VqT)
    提出了几何 WL 测试（GWL）来研究等变和不变 GNNs（对于某些对称性：平移、旋转、反射、排列）的表现力。结果表明，等变 GNNs（例如 [E-GNN](https://arxiv.org/abs/2102.09844)、[NequIP](https://arxiv.org/abs/2101.03164)
    或 [MACE](https://arxiv.org/abs/2206.07697)）在理论上比不变 GNNs（例如 [SchNet](https://proceedings.neurips.cc/paper/2017/file/303ed4c69846ab36c2904d3ba8573050-Paper.pdf)
    或 [DimeNet](https://arxiv.org/abs/2011.14115)）更强大。
- en: 'WL Go **Temporal**: [Souza et al](https://openreview.net/pdf?id=MwSXgQSxL5s)
    propose Temporal WL test to study expressiveness of temporal GNNs. The authors
    then propose a novel injective aggregation function (and the PINT model) that
    should be most expressive;'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WL Go **时间**：[Souza et al](https://openreview.net/pdf?id=MwSXgQSxL5s) 提出了时间
    WL 测试来研究时间 GNNs 的表现力。作者随后提出了一种新型的单射聚合函数（以及 PINT 模型），这应该是最具表现力的；
- en: 'WL Go **Gradual**: [Bause and Kriege](https://openreview.net/forum?id=fe1DEN1nds)
    propose to modify the original WL color refinement with a non-injective function
    where different multi-sets *might* get assigned the same color (under certain
    conditions). It thus enables more gradual color refinement and slower convergence
    to stable coloring that eventually retains expressiveness of 1-WL but gets a few
    distinguishing properties on the way.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WL Go **渐进**：[Bause 和 Kriege](https://openreview.net/forum?id=fe1DEN1nds) 提议用非单射函数修改原始
    WL 颜色细化，其中不同的多重集合*可能*被分配相同的颜色（在某些条件下）。因此，它使得颜色细化过程更加渐进，并且收敛到稳定着色的速度更慢，最终保留了 1-WL
    的表现力，但在过程中获得了一些区分特性。
- en: 'WL Go **Infinite**: [Feldman et al](https://arxiv.org/abs/2201.13410) propose
    to change the initial node coloring with spectral features derived from the heat
    kernel of the Laplacian or with k-smallest eigenvectors of the Laplacian (for
    large graphs) which is quite close to Laplacian Positional Encodings (LPEs).'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WL Go **无限**：[Feldman et al](https://arxiv.org/abs/2201.13410) 提议用从拉普拉斯的热核衍生的谱特征或拉普拉斯的
    k 最小特征向量（对于大图）来改变初始节点着色，这与拉普拉斯位置编码（LPEs）非常接近。
- en: 'WL Go **Hyperbolic**: [Nikolentzos et al](https://arxiv.org/abs/2211.02501)
    note that the color refinement procedure of the WL test produces a tree hierarchy
    of colors. In order to preserve relative distances of nodes encoded by those colors,
    the authors propose to map output states of each layer/iteration into a hyperbolic
    space and update it after each next layer. The final embeddings are supposed to
    retain the notion of node distances.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WL Go **双曲**：[Nikolentzos et al](https://arxiv.org/abs/2211.02501) 指出 WL 测试的颜色细化过程会产生颜色的树状层次结构。为了保持这些颜色所编码的节点相对距离，作者建议将每层/迭代的输出状态映射到双曲空间，并在每次更新后调整。最终的嵌入应该保留节点距离的概念。
- en: '📈 In the realm of more expressive (than 1-WL) architectures, subgraph GNNs
    are the biggest trend. Among those, three approaches stand out: 1️⃣ **Subgraph
    Union Networks** (SUN) by [Frasca, Bevilacqua, et al.](https://arxiv.org/abs/2206.11140)
    that provide a comprehensive analysis of subgraph GNNs design space and expressiveness
    showing they are bounded by 3-WL; 2️⃣ **Ordered Subgraph Aggregation Networks**
    (OSAN) by [Qian, Rattan, et al](https://arxiv.org/abs/2206.11168) devise a hierarchy
    of subgraph-enhanced GNNs (k-OSAN) and find that k-OSAN are incomparable to k-WL
    but are strictly limited by (k+1)-WL. One particularly cool part of OSAN is using
    [Implicit MLE](https://arxiv.org/abs/2106.01798) (NeurIPS’21), a differentiable
    discrete sampling technique, for sampling ordered subgraphs. **️3️⃣ SpeqNets**
    by [Morris et al.](https://arxiv.org/abs/2203.13913) devise a permutation-equivariant
    hierarchy of graph networks that balances between scalability and expressivity.
    4️⃣ **GraphSNN** by [Wijesinghe and Wang](https://openreview.net/pdf?id=uxgg9o7bI_3)
    derives expressive models based on the overlap of *subgraph* isomorphisms and
    *subtree* isomorpishms.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 📈 在比1-WL更具表达力的架构领域中，子图GNNs是最大的趋势。其中有三种方法脱颖而出：1️⃣ **子图联合网络**（SUN），由[Frasca, Bevilacqua等](https://arxiv.org/abs/2206.11140)提出，提供了子图GNNs设计空间和表达力的全面分析，显示它们受限于3-WL；2️⃣
    **有序子图聚合网络**（OSAN），由[Qian, Rattan等](https://arxiv.org/abs/2206.11168)提出，设计了一种子图增强GNNs（k-OSAN）的层次结构，并发现k-OSAN与k-WL不可比，但严格受限于（k+1）-WL。OSAN的一个特别酷的部分是使用[隐式MLE](https://arxiv.org/abs/2106.01798)（NeurIPS’21），这是一种可微分的离散采样技术，用于采样有序子图。**️3️⃣
    SpeqNets** 由[Morris等](https://arxiv.org/abs/2203.13913)提出，设计了一种图网络的置换等变层次结构，平衡了可扩展性和表达力。4️⃣
    **GraphSNN** 由[Wijesinghe和Wang](https://openreview.net/pdf?id=uxgg9o7bI_3)提出，基于*子图*同构和*子树*同构的重叠推导出表达性模型。
- en: 🤔 A few works rethink the WL framework as a general means for GNN expressiveness.
    [Geerts and Reutter](https://openreview.net/pdf?id=wIzUeM3TAU) define **k-order
    MPNNs** that can be characterized with Tensor Languages (with a mapping between
    WL and **Tensor Languages**). A new [anonymous ICLR’23 submission](https://openreview.net/forum?id=r9hNv76KoT3)
    proposes to leverage [graph biconnectivity](https://en.wikipedia.org/wiki/Biconnected_component)
    and defines a **Generalized Distance WL** algorithm.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 🤔 一些研究重新审视WL框架作为GNN表达力的一种通用手段。[Geerts和Reutter](https://openreview.net/pdf?id=wIzUeM3TAU)定义了**k阶MPNNs**，可以通过张量语言（WL与**张量语言**之间的映射）进行表征。一个新的[匿名ICLR’23提交](https://openreview.net/forum?id=r9hNv76KoT3)提出利用[图的双连通性](https://en.wikipedia.org/wiki/Biconnected_component)并定义了**广义距离WL**算法。
- en: If you’d like to study the topic even deeper, check out a wonderful [LOG 2022
    tutorial](https://www.youtube.com/watch?v=ASQYjbUBYzs&list=PL2iNJC54likoqgKwpFnbBik8Im1sZ27Hm&index=7)
    by Fabrizio Frasca, Beatrice Bevilacqua, and Haggai Maron with practical examples!
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想更深入地研究这个主题，查看Fabrizio Frasca、Beatrice Bevilacqua和Haggai Maron的精彩[LOG 2022教程](https://www.youtube.com/watch?v=ASQYjbUBYzs&list=PL2iNJC54likoqgKwpFnbBik8Im1sZ27Hm&index=7)及其实际例子吧！
- en: '**What to expect in 2023**: *1️⃣* More efforts on creating time- and memory-efficient
    subgraph GNNs. *2️⃣* Better understanding of generalization of GNNs. *3️⃣* Weisfeiler
    and Leman visit 10 new places!'
  id: totrans-136
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**2023年的期待**：*1️⃣* 更多致力于创建时间和内存高效的子图GNNs。*2️⃣* 更好地理解GNNs的泛化能力。*3️⃣* Weisfeiler和Leman访问10个新地方！'
- en: 'Knowledge Graphs: Inductive Reasoning Takes Over'
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 知识图谱：归纳推理占据主导地位
- en: 'Last year, we observed a major shift in KG representation learning: transductive-only
    approaches are being actively retired in favor of inductive models that can build
    meaningful representation for new, unseen nodes and perform node classification
    and link prediction.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 去年，我们观察到了KG表示学习的重大转变：传导性方法正被积极淘汰，取而代之的是归纳模型，这些模型可以为新的、未见过的节点构建有意义的表示，并执行节点分类和链接预测。
- en: 'In 2022, the field was expanding along two main axes: 1️⃣ inductive link prediction
    (LP) 2️⃣ and inductive (multi-hop) query answering that extends link prediction
    to much more complex prediction tasks.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在2022年，该领域沿着两个主要轴线扩展：1️⃣ 归纳链接预测（LP）2️⃣ 和归纳（多跳）查询回答，将链接预测扩展到更复杂的预测任务。
- en: 1️⃣ In link prediction, the majority of inductive models (like [**NBFNet**](https://arxiv.org/abs/2106.06935)
    or [**NodePiece**](https://arxiv.org/abs/2106.12144)) transfer to unseen nodes
    at inference by assuming that the set of relation types is fixed during training
    and does not change over time so they can learn relation embeddings. What happens
    when the set of relations changes as well? In the hardest case, we’d want to transfer
    to KGs with completely different nodes **and** relation types.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 1️⃣ 在链路预测中，大多数归纳模型（如[**NBFNet**](https://arxiv.org/abs/2106.06935)或[**NodePiece**](https://arxiv.org/abs/2106.12144)）通过假设关系类型的集合在训练期间是固定的且不会随时间变化，从而转移到未见节点，并学习关系嵌入。当关系集合也发生变化时会发生什么？在最困难的情况下，我们希望能够转移到具有完全不同节点**和**关系类型的知识图谱。
- en: So far, all such models supporting unseen relations resort to meta-learning
    which is slow and resource-hungry. In 2022, for the first time, [Huang, Ren, and
    Leskovec](https://openreview.net/forum?id=LvW71lgly25) proposed the Connected
    Subgraph Reasoner (**CSR**) framework that is inductive along **both** entities
    and relation types **and** does not need any meta-learning! 👀 Generally, for new
    relations at inference, models see at least *k* example triples with this relation
    (hence, a k-shot learning scenario). Conceptually, CSR extracts subgraphs around
    each example trying to learn common relational patterns (i.e., optimizing edge
    masks) and then apply the mask to the query subgraph (with the missing target
    link to predict).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，所有支持未见关系的模型都依赖于元学习，这种方法既慢又消耗资源。在2022年，[黄，任和莱斯科维奇](https://openreview.net/forum?id=LvW71lgly25)首次提出了**CSR**（连接子图推理器）框架，它在**实体**和**关系类型**上都是归纳的**且**不需要任何元学习！👀
    通常，在推理时，对于新关系，模型至少看到*k*个示例三元组（因此是k-shot学习场景）。从概念上讲，CSR提取每个示例周围的子图，试图学习共同的关系模式（即优化边缘掩码），然后将掩码应用于查询子图（预测缺失的目标链路）。
- en: '![](../Images/495777bb4fc9ea6eae90cb434332ab5a.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/495777bb4fc9ea6eae90cb434332ab5a.png)'
- en: 'Inductive CSR that supports KGs with unseen entities and relation types. Source:
    [Huang, Ren, and Leskovec](https://openreview.net/forum?id=LvW71lgly25)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 支持具有未见实体和关系类型的知识图谱的**归纳CSR**。来源：[黄，任和莱斯科维奇](https://openreview.net/forum?id=LvW71lgly25)
- en: '**ReFactor GNNs** by [Chen et al.](https://openreview.net/forum?id=81LQV4k7a7X)
    is another insightful work on inductive qualities of shallow KG embedding models
    — particularly, the authors find that shallow factorization models like DistMult
    resemble infinitely deep GNNs when looking through the lens of backpropagation
    and how nodes update their representations from neighboring and non-neighboring
    nodes. Turns out that, theoretically, any factorization model can be turned into
    an inductive model!'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '[Chen等人](https://openreview.net/forum?id=81LQV4k7a7X)的**ReFactor GNNs**是另一项有关浅层KG嵌入模型归纳特性的有洞察力的工作——特别是，作者发现浅层因子分解模型如DistMult在反向传播的视角下，与无限深度的GNNs类似，节点如何从邻近节点和非邻近节点更新其表示。理论上，任何因子分解模型都可以转变为归纳模型！'
- en: 2️⃣ Inductive representation learning arrived in the area of complex logical
    query answering as well. (shameless plug) In fact, it was one of the focuses of
    our team this year 😊 First, in [Zhu et al.](https://arxiv.org/abs/2205.10128),
    we found that Neural Bellman-Ford nets generalize well from simple link prediction
    to complex query answering tasks in a new [**GNN Query Executor**](https://github.com/DeepGraphLearning/GNN-QE)
    (GNN-QE) model where a GNN based on NBF-Net performs relation projections while
    other logical operators are performed via fuzzy logic [t-norms](https://en.wikipedia.org/wiki/T-norm).
    Then, in [Inductive Logical Query Answering in Knowledge Graphs](https://openreview.net/forum?id=-vXEN5rIABY)
    we studied ⚗️ *the essence of inductiveness* ⚗️ and proposed two ways to answer
    logical queries over unseen entities at inference time, that is, via (1) inductive
    node representations obtained with NodePiece encoder paired with the inference-only
    decoder (less performant but scalable) or via (2) inductive relational structure
    representations akin to the one in GNN-QE (better quality but more resource-hungry
    and hard to scale). Overall we are able to scale to an inductive query setting
    on graphs **with millions of nodes and 500k unseen nodes and 5m unseen edges**
    during inference.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 2️⃣ 从归纳表征学习也开始涉及到复杂的逻辑查询回答。 （厚颜无耻的插入广告）事实上，这是我们团队今年的重点之一 😊 首先，在[Zhu等人](https://arxiv.org/abs/2205.10128)的研究中，我们发现神经贝尔曼-福特网络从简单的链接预测成功地推广到了复杂的查询任务，这是在一个新的[**GNN查询执行器**](https://github.com/DeepGraphLearning/GNN-QE)（GNN-QE）模型中，其中一个基于NBF-Net的GNN进行了关系投影，而其他逻辑运算通过模糊逻辑[t-范数](https://en.wikipedia.org/wiki/T-norms)来实现。
    然后，在[知识图中的归纳逻辑查询回答](https://openreview.net/forum?id=-vXEN5rIABY)中，我们研究了⚗️ *归纳性的本质*
    ⚗️并提出了两种解决方案，以在推理时回答关于未知实体的逻辑查询，即通过（1）与仅用于推理的解码器配对的归纳节点表示（性能较差但可扩展），或通过（2）类似于GNN-QE中的归纳关系结构表示（质量更高但需要更多资源并且难以扩展）。
    总的来说，我们能够在推理时处理**拥有数百万节点和500k个未见节点以及5m未见边缘**的图中进行归纳查询设置。
- en: '![](../Images/063be3295d889aafc4b3b1c292e3e88b.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/063be3295d889aafc4b3b1c292e3e88b.png)'
- en: 'Inductive logical query answering approaches: via node representations (NodePiece-QE)
    and relational structure representations (GNN-QE). Source: [Galkin et al.](https://arxiv.org/abs/2210.08008)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 透过节点表示（NodePiece-QE）和关系结构表示（GNN-QE）进行归纳逻辑查询回答。 来源：[Galkin等人](https://arxiv.org/abs/2210.08008)
- en: The other cool work in the area is [**SMORE**](https://github.com/google-research/smore)by
    [Ren, Dai, et al.](https://arxiv.org/abs/2110.14890) — it is a large-scale (transductive-only
    yet) system for complex query answering over very large graphs scaling up to the
    full Freebase with about 90M nodes and 300M edges 👀. In addition to CUDA, training,
    and pipeline optimizations, SMORE implements a bidirectional query sampler such
    that training queries can be generated on-the-fly right in the data loader instead
    of creating and storing huge datasets. Don’t forget to check out a [fresh hands-on
    tutorial](https://www.youtube.com/watch?v=kzWV57qJmiA&list=PL2iNJC54likoqgKwpFnbBik8Im1sZ27Hm&index=1)
    on large-scale graph reasoning from LOG 2022!
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这个领域中的另一项重要工作是[**SMORE**](https://github.com/google-research/smore)来自[任、戴等人](https://arxiv.org/abs/2110.14890)
    — 这是一个大规模（仅限传导）的系统，可对大约90M个节点和300M条边缘的完整Freebase进行复杂查询回答👀。 除了CUDA、训练和管道优化，SMORE还实现了一个双向查询采样器，使得训练查询可以在数据加载器中即时生成，而无需创建和存储大量数据集。
    不要忘记从LOG 2022中查看关于大规模图推理的[全新实践教程](https://www.youtube.com/watch?v=kzWV57qJmiA&list=PL2iNJC54likoqgKwpFnbBik8Im1sZ27Hm&index=1)!
- en: Last but not the least, [Yang, Lin and Zhang](https://arxiv.org/pdf/2209.08858.pdf)
    brought up an interesting paper rethinking the evaluation of knowledge graph completion.
    They point out knowledge graphs tend to be open-world (i.e., there are facts not
    encoded by the knowledge graph) rather close-world assumed by most works. As a
    result, metrics observed under the close-world assumption exhibit a log trend
    w.r.t. the true metric — this means if you get 0.4 MRR for your model, chances
    are that the test knowledge graph is incomplete and your model has already done
    a good job👍. Maybe we can design some new dataset and evaluation to mitigate such
    an issue?
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但并非最不重要，[杨、林和张](https://arxiv.org/pdf/2209.08858.pdf)提出了一篇有趣的论文，重新思考了知识图完成的评估。
    他们指出知识图倾向于是开放世界的（即，有些事实并未被知识图编码），而不是大部分作品所假设的闭世界。 因此，在闭世界假设下观察到的指标对真实指标呈现出了对数趋势——这意味着如果你的模型得到了0.4的MRR，那么测试知识图很可能是不完整的，而你的模型已经做得相当不错👍。也许我们可以设计一些新的数据集和评估来缓解这个问题？
- en: '**What to expect in 2023**: an inductive model fully transferable to different
    KGs with new sets of entities and relations, e.g., training on Wikidata, and running
    inference on DBpedia or Freebase.'
  id: totrans-150
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**2023 年的预期**：一个可以完全迁移到不同知识图谱的新集合的归纳模型，例如在 Wikidata 上进行训练，并在 DBpedia 或 Freebase
    上运行推理。'
- en: Algorithmic Reasoning and Alignment
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 算法推理与对齐
- en: 2022 was a year of major breakthroughs and milestones for algorithmic reasoning.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 2022 年是算法推理领域取得重大突破和里程碑的一年。
- en: 1️⃣ First, the [**CLRS benchmark**](https://github.com/deepmind/clrs) by [Veličković
    et al.](https://arxiv.org/abs/2205.15659) is now available as the main playground
    to design and benchmark algorithmic reasoning models and tasks. CLRS already includes
    30 tasks (such as classical sorting algorithms, string algorithms, and graph algorithms)
    but still allows you to bring your own formulations or modify existing ones.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 1️⃣ 首先，[**CLRS 基准测试**](https://github.com/deepmind/clrs)由 [Veličković 等人](https://arxiv.org/abs/2205.15659)
    提供，现在可以作为设计和评估算法推理模型和任务的主要平台。CLRS 已经包括了 30 个任务（如经典排序算法、字符串算法和图算法），但仍然允许你带入自己的公式或修改现有公式。
- en: 2️⃣ Then, a **Generalist Neural Algorithmic Learner** by [Ibarz et al.](https://openreview.net/forum?id=FebadKZf6Gd)
    and DeepMind has shown that it is possible to train a *single* processor network
    that can be trained in the multi-task mode on different algorithms — previously,
    you’d train a single model for a single task repeating that for all 30 CLRS problems.
    The paper also describes several modifications and tricks to the model architecture
    side and training procedure to let the model generalize better and prevent forgetting,
    e.g., triplet reasoning similar to triangular attention (common for molecular
    models) and [edge transformers](https://arxiv.org/abs/2112.00578). Overall, a
    new model brings a massive 25% absolute gain over baselines and solves 24 out
    of 30 CLRS tasks with 60%+ micro-F1.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 2️⃣ 然后，[Ibarz 等人](https://openreview.net/forum?id=FebadKZf6Gd) 和 DeepMind 的**通用神经算法学习器**表明，可以训练一个*单一*的处理器网络，在不同算法上以多任务模式进行训练——以前，你需要为每个
    CLRS 问题训练一个单独的模型。论文还描述了模型架构和训练过程中的若干修改和技巧，以使模型更好地进行泛化并防止遗忘，例如，类似于三角注意力的三元组推理（在分子模型中常见）和
    [边变换器](https://arxiv.org/abs/2112.00578)。总体而言，新模型带来了比基线高出 25% 的绝对增益，并且以 60%+ 的微观
    F1 分数解决了 30 个 CLRS 任务中的 24 个。
- en: '![](../Images/b4f7d36cd5ab8040d258a815d1dca4dc.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b4f7d36cd5ab8040d258a815d1dca4dc.png)'
- en: 'Source: [Ibarz et al.](https://openreview.net/forum?id=FebadKZf6Gd)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[Ibarz 等人](https://openreview.net/forum?id=FebadKZf6Gd)
- en: 3️⃣ Last year, we [discussed](/graph-ml-in-2022-where-are-we-now-f7f8242599e0#72d1)
    the works on algorithmic alignment and saw the signs that GNNs can probably align
    well with dynamic programming. In 2022, [Dudzik and Veličković](https://openreview.net/forum?id=wu1Za9dY1GY)
    prove that **GNNs are Dynamic Programmers** using category theory, abstract algebra,
    and notion of *pushforward* and *pullback* operations. This is a wonderful example
    of applying category theory that many people consider “abstract nonsense” 😉. Category
    theory is likely to have more impact in GNN theory and Graph ML in general, so
    check out a fresh course [Cats4AI](https://cats.for.ai/) for a gentle introduction
    to the field.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 3️⃣ 去年，我们[讨论了](https://graph-ml-in-2022-where-are-we-now-f7f8242599e0#72d1)关于算法对齐的工作，并看到
    GNNs 可能与动态规划良好对齐的迹象。在 2022 年，[Dudzik 和 Veličković](https://openreview.net/forum?id=wu1Za9dY1GY)
    通过范畴论、抽象代数以及*推前*和*拉回*操作的概念证明了**GNNs 是动态规划器**。这是应用范畴论的一个绝妙例子，许多人认为这是“抽象无聊”的😉。范畴论可能会在
    GNN 理论和图 ML 中产生更大的影响，因此可以查看新的课程 [Cats4AI](https://cats.for.ai/) 以获得对该领域的温和介绍。
- en: 4️⃣ Finally, the work of [Beurer-Kellner et al.](https://openreview.net/forum?id=AiY6XvomZV4)
    is one of the first practical application of the neural algorithmic reasoning
    framework, here it is applied to configuring computer networks, i.e., routing
    protocols like BGP that are at the core of the internet. There, the authors show
    that representing a routing config as a graph allows to frame the routing problem
    as node property prediction. This approach brings whopping 👀 **490x** 👀 speedups
    compared to traditional rule-based routing methods and stil maintain 90+% specification
    consistency.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 4️⃣ 最后，[Beurer-Kellner 等人](https://openreview.net/forum?id=AiY6XvomZV4) 的工作是神经算法推理框架的首批实际应用之一，这里将其应用于配置计算机网络，即互联网核心的路由协议如
    BGP。在这项工作中，作者展示了将路由配置表示为图形，可以将路由问题框架化为节点属性预测。这种方法相比传统的基于规则的路由方法带来了惊人的👀 **490x**
    👀加速，并且仍然保持90%以上的规范一致性。
- en: '![](../Images/9045a1b7fb0c1e4f9b6f05c353eaaea9.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9045a1b7fb0c1e4f9b6f05c353eaaea9.png)'
- en: 'Source: [Beurer-Kellner et al.](https://openreview.net/forum?id=AiY6XvomZV4)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[Beurer-Kellner 等](https://openreview.net/forum?id=AiY6XvomZV4)
- en: If you want to follow algorithmic reasoning more closely, don’t miss a fresh
    [LoG 2022 tutorial](https://algo-reasoning.github.io/) by ​​Petar Veličković,
    Andreea Deac and Andrew Dudzik.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想更深入地了解算法推理，不要错过 Petar Veličković、Andreea Deac 和 Andrew Dudzik 最新的 [LoG 2022
    教程](https://algo-reasoning.github.io/)。
- en: '**What to expect in 2023: *1️⃣*** Algorithmic reasoning tasks are likely to
    scale to graphs of thousands of nodes and practical applications like in code
    analysis or databases, *2️⃣* even more algorithms in the benchmark, *3️⃣* most
    unlikely — there will appear a model capable of solving quickselect *😅*'
  id: totrans-162
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**2023 年的展望： *1️⃣*** 算法推理任务可能会扩展到成千上万个节点的图，以及代码分析或数据库等实际应用， *2️⃣* 更多的基准算法，
    *3️⃣* 最不可能——会出现一个能够解决 quickselect 的模型 *😅*'
- en: Cool GNN Applications
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 酷炫的 GNN 应用
- en: 👃 **Learning to Smell with GNNs.** Back in 2019, Google AI started a [project](https://ai.googleblog.com/2019/10/learning-to-smell-using-deep-learning.html)
    on learning representations of smells. From basic chemistry we know that aromaticity
    depends on the molecular structure, e.g., cyclic compounds. In fact, the whole
    group of ”aromatic hydrocarbons” was named *aromatic* because they actually has
    some smell (compared to many non-organic molecules). If we have a molecular structure,
    we can employ a GNN on top of it and learn some representations!
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 👃 **使用 GNN 学习嗅觉。** 早在2019年，Google AI 开始了一个关于嗅觉表示学习的 [项目](https://ai.googleblog.com/2019/10/learning-to-smell-using-deep-learning.html)。从基础化学知识我们知道，芳香性取决于分子结构，例如环状化合物。事实上，整个“芳香烃”组被命名为
    *芳香的* 是因为它们实际上有一些气味（与许多无机分子相比）。如果我们有一个分子结构，我们可以在其基础上使用 GNN 来学习一些表示！
- en: 'Recently, Google AI released [a new blogpost](https://ai.googleblog.com/2022/09/digitizing-smell-using-molecular-maps.html)
    and paper by [Qian et al.](https://www.biorxiv.org/content/10.1101/2022.07.21.500995v3)
    describing the next phase of the project — the **Principal Odor Map** that is
    able to group molecules in “odor clusters”. The authors conducted 3 cool experiments:
    classifying 400 new molecules never smelled before and comparison to the averaged
    rating of a group of human panelists; linking odor quality to fundamental biology;
    and probing aromatic molecules on their mosquito repelling qualities. The GNN-based
    model shows very good results — now we can finally claim that GNNs can smell!
    Looking forward for GNNs transforming the perfume industry.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，Google AI 发布了 [一篇新博客文章](https://ai.googleblog.com/2022/09/digitizing-smell-using-molecular-maps.html)
    和 [Qian 等人](https://www.biorxiv.org/content/10.1101/2022.07.21.500995v3) 的论文，描述了项目的下一阶段——**主要气味地图**，能够将分子分组为“气味簇”。作者进行了三项有趣的实验：对400种之前从未闻过的新分子进行分类，并与一组人类评审员的平均评分进行比较；将气味质量与基础生物学关联；以及探测芳香分子的驱蚊特性。基于
    GNN 的模型表现非常出色——现在我们可以自信地说 GNN 可以嗅觉！期待 GNN 在香水行业的变革。
- en: '![](../Images/676191b7f09085ed9d141bae32bae385.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/676191b7f09085ed9d141bae32bae385.png)'
- en: 'Embedding of odors. Source: [Google AI blog](https://ai.googleblog.com/2022/09/digitizing-smell-using-molecular-maps.html)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 气味的嵌入。来源：[Google AI 博客](https://ai.googleblog.com/2022/09/digitizing-smell-using-molecular-maps.html)
- en: '⚽ **GNNs + Football.** If you thought that sophisticated GNNs for modelling
    trajectories are only used for molecular dynamics and arcane quantum simulations,
    fear not! Here is a cool practical application with a very high potential outreach:
    **Graph Imputer** by [Omidshafiei et al.](https://www.nature.com/articles/s41598-022-12547-0.epdf?sharing_token=HmyoHCAtNdoDfjlObtCiltRgN0jAjWel9jnR3ZoTv0NzQifNnvllGA8o7uZB3n1gdCaC-3jfBQwxpTCJNR7isTeW2uWhYUL8hz8MmWvyYQLogAFNcVp5ZZuTr_O-slFsi4f4-5pz3J2Th9rSxCJV-s63f-q5fojV0FBGNWKYlRQ%3D),
    DeepMind, and FC Liverpool predicts trajectories of football players (and the
    ball). Each game graph consists of 23 nodes, gets updated with a standard message
    passing encoder and a special time-dependent LSTM. The dataset is quite novel,
    too — it consists of 105 English Premier League matches (avg 90 min each), all
    players and the ball were tracked at 25 fps, and the resulting training trajectory
    sequences encode about 9.6 seconds of gameplay.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ⚽ **GNNs + 足球。** 如果你认为用于建模轨迹的复杂GNN仅用于分子动力学和深奥的量子模拟，那就不要担心！这里有一个非常有潜力的实际应用：**Graph
    Imputer** 由 [Omidshafiei 等](https://www.nature.com/articles/s41598-022-12547-0.epdf?sharing_token=HmyoHCAtNdoDfjlObtCiltRgN0jAjWel9jnR3ZoTv0NzQifNnvllGA8o7uZB3n1gdCaC-3jfBQwxpTCJNR7isTeW2uWhYUL8hz8MmWvyYQLogAFNcVp5ZZuTr_O-slFsi4f4-5pz3J2Th9rSxCJV-s63f-q5fojV0FBGNWKYlRQ%3D)
    提出的，DeepMind 和利物浦足球俱乐部预测足球运动员（以及足球）的轨迹。每场比赛图包含23个节点，通过标准消息传递编码器和特殊的时间依赖LSTM进行更新。数据集也非常新颖——它包含了105场英超比赛（每场比赛平均90分钟），所有球员和足球的运动被以25帧每秒的速度跟踪，得到的训练轨迹序列编码了大约9.6秒的比赛过程。
- en: The paper is easy to read and has numerous football illustrations, check it
    out! Sports tech is actively growing those days, and football analysts now could
    go even deeper in studying their competitors. Will EPL clubs compete for GNN researchers
    in the upcoming transfer windows? Time to create transfermarkt for GNN researchers
    😉
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇论文易于阅读，并有大量的足球插图，快去看看吧！体育技术在这些年里迅速发展，足球分析师现在可以更深入地研究他们的对手。英超俱乐部会在即将到来的转会窗口中竞争GNN研究人员吗？是时候为GNN研究人员创建一个transfermarkt了😉
- en: '![](../Images/4636afc466b88dba1d5146bab2df8221.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4636afc466b88dba1d5146bab2df8221.png)'
- en: 'Football match simulation is like molecular dynamics simulation! Source: [DeepMind](https://twitter.com/deepmind/status/1529444212864843777?lang=en)'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 足球比赛模拟就像分子动力学模拟一样！来源：[DeepMind](https://twitter.com/deepmind/status/1529444212864843777?lang=en)
- en: '🪐 **Galaxies and Astrophysics.** For astrophysics aficionados: **Mangrove**
    by [Jespersen et al.](https://arxiv.org/abs/2210.13473) applies GraphSAGE to merger
    trees of dark matter to predict a variety of galactic properties like stellar
    mass, cold gas mass, star formation rate, and even black hole mass. The paper
    is a bit heavy on the terminology of astrophysics but pretty easy in terms of
    GNN parameterization and training. Mangrove works 4–9 orders of magnitude faster
    than standard models. Experimental charts are pieces of art that you can hang
    on a wall 🖼️.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 🪐 **银河系与天体物理学。** 对天体物理学爱好者而言：**Mangrove** 由 [Jespersen 等](https://arxiv.org/abs/2210.13473)
    提出的应用GraphSAGE于暗物质的合并树，以预测各种银河属性，如恒星质量、冷气体质量、星形成率，甚至黑洞质量。尽管这篇论文在天体物理学术语上有些复杂，但在GNN参数化和训练方面相对简单。Mangrove的速度比标准模型快4到9个数量级。实验图表就像艺术品一样，可以挂在墙上
    🖼️。
- en: '![](../Images/77efdaa485947c23151de37ec221a2cb.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/77efdaa485947c23151de37ec221a2cb.png)'
- en: 'Mangrove approach to present dark matter halos as merger trees and graphs.
    Source: [Jespersen et al.](https://arxiv.org/abs/2210.13473)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: Mangrove将暗物质晕呈现为合并树和图。来源：[Jespersen 等](https://arxiv.org/abs/2210.13473)
- en: '🤖 **GNNs for code**. Code generation models like AlphaCode and Codex have mindblowing
    capabilities. Although LLMs are at the core of those models, GNNs do help in a
    few neat ways: **Instruction Pointer Attention GNNs** (IPA-GNNs) first proposed
    by [Bieber et al](https://arxiv.org/abs/2010.12621) have been used to [predict
    runtime errors](https://arxiv.org/abs/2203.03771) in competitive programming tasks
    — so it is almost like a virtual code interpreter! **CodeTrek** by [Pashakhanloo
    et al.](https://openreview.net/forum?id=WQc075jmBmf) proposes to model a program
    as a relational graph and embed it via random walks and Transformer encoder. Downstream
    applications include variable misuse, prediction exceptions, predicting shadowed
    variables.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 🤖 **GNNs用于代码**。像AlphaCode和Codex这样的代码生成模型具有令人惊叹的能力。虽然LLMs是这些模型的核心，但GNNs在几个巧妙的方面确实有帮助：**指令指针注意力GNNs**（IPA-GNNs）首次由[Bieber
    et al](https://arxiv.org/abs/2010.12621)提出，用于[预测运行时错误](https://arxiv.org/abs/2203.03771)在竞赛编程任务中——这几乎就像一个虚拟的代码解释器！由[Pashakhanloo
    et al.](https://openreview.net/forum?id=WQc075jmBmf)提出的**CodeTrek**建议将程序建模为关系图，并通过随机游走和Transformer编码器进行嵌入。下游应用包括变量误用、预测异常和预测被遮蔽的变量。
- en: '![](../Images/ab5c9d787662778c2d57153876512efe.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ab5c9d787662778c2d57153876512efe.png)'
- en: 'Source: [Pashakhanloo et al.](https://openreview.net/forum?id=WQc075jmBmf)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[Pashakhanloo et al.](https://openreview.net/forum?id=WQc075jmBmf)
- en: 'Hardware: IPUs and Graphcore Win OGB Large-Scale Challenge 2022'
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 硬件：IPUs和Graphcore赢得OGB大规模挑战赛2022
- en: 🥇 2022 brought a huge success to [Graphcore](https://www.graphcore.ai/) and
    [IPUs](https://www.graphcore.ai/bow-processors) — the hardware optimized for sparse
    operations that are so needed when working with graphs. The first success story
    was optimizing Temporal Graph Nets (TGN) for IPUs with massive performance gains
    (check the [article](/accelerating-and-scaling-temporal-graph-networks-on-the-graphcore-ipu-c15ac309b765)
    in Michael Bronstein’s blog).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 🥇 2022年为[Graphcore](https://www.graphcore.ai/)和[IPUs](https://www.graphcore.ai/bow-processors)带来了巨大的成功——这些硬件专门优化了处理图形时非常需要的稀疏操作。第一个成功故事是优化了IPUs上的Temporal
    Graph Nets (TGN)，取得了巨大的性能提升（查看Michael Bronstein博客中的[文章](/accelerating-and-scaling-temporal-graph-networks-on-the-graphcore-ipu-c15ac309b765)）。
- en: '[](/accelerating-and-scaling-temporal-graph-networks-on-the-graphcore-ipu-c15ac309b765?source=post_page-----1ba920cb9232--------------------------------)
    [## Accelerating and scaling Temporal Graph Networks on the Graphcore IPU'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 加速和扩展在Graphcore IPU上的Temporal Graph Networks](/accelerating-and-scaling-temporal-graph-networks-on-the-graphcore-ipu-c15ac309b765?source=post_page-----1ba920cb9232--------------------------------)'
- en: Is GPU the best hardware choice for GNNs? Together with Graphcore, we explore
    the advantages of the new IPU…
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GPU是GNNs的最佳硬件选择吗？与Graphcore一起，我们探讨了新IPU的优势……
- en: towardsdatascience.com](/accelerating-and-scaling-temporal-graph-networks-on-the-graphcore-ipu-c15ac309b765?source=post_page-----1ba920cb9232--------------------------------)
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/accelerating-and-scaling-temporal-graph-networks-on-the-graphcore-ipu-c15ac309b765?source=post_page-----1ba920cb9232--------------------------------)'
- en: 'Later on, Graphcore [stormed the leaderboards](https://www.graphcore.ai/posts/graphcore-claims-double-win-in-open-graph-benchmark-challenge)
    of OGB LSC’22 by winning 2 out of 3 tracks: link prediction on the **WikiKG90M
    v2** knowledge graph and graph regression on the **PCQM4M v2** molecular dataset.
    In addition to the sheer compute power, the authors took several clever model
    decisions: for link prediction it was [Balanced Entity Sampling and Sharing (BESS)](https://arxiv.org/abs/2211.12281)
    for training an ensemble of shallow LP models (check the [blog post](/large-scale-knowledge-graph-completion-on-ipu-4cf386dfa826)
    by Daniel Justus for more details), and GPS++ for the graph regression task (we
    covered GPS++ above in the GT section). You can [try out](https://ipu.dev/3FwVoLD)
    the pre-trained models using IPUs-powered virtual machines on Paperspace. Congratulations
    to Graphcore and their team! 👏'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 此后，Graphcore在OGB LSC’22的排行榜上[大放异彩](https://www.graphcore.ai/posts/graphcore-claims-double-win-in-open-graph-benchmark-challenge)，在3个赛道中赢得了2个：**WikiKG90M
    v2**知识图谱上的链接预测和**PCQM4M v2**分子数据集上的图回归。除了强大的计算能力外，作者还做出了一些巧妙的模型决策：对于链接预测，采用了[平衡实体采样和共享
    (BESS)](https://arxiv.org/abs/2211.12281)来训练一个浅层LP模型的集合（查看Daniel Justus的[博客文章](/large-scale-knowledge-graph-completion-on-ipu-4cf386dfa826)了解更多细节），对于图回归任务采用了GPS++（我们在GT部分中讨论了GPS++）。你可以[尝试](https://ipu.dev/3FwVoLD)在Paperspace上使用IPUs支持的虚拟机来使用预训练模型。祝贺Graphcore及其团队！👏
- en: PyG partnered with NVIDIA ([post](https://pyg.org/ns-newsarticle-accelerating-pyg-on-nvidia-gpus))
    and Intel ([post](https://pyg.org/news/accelerating-pyg-on-intel-cpus)) to increase
    the performance of core operations on GPUs and CPUs, respectively. Similarly,
    DGL [incorporated](https://www.dgl.ai/release/2022/07/25/release.html) new GPU
    optimizations in the recent 0.9 version. Massive gains for sparse matmuls and
    sampling procedures, so we’d encourage you to update your environments with the
    most recent versions!.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: PyG 与 NVIDIA ([post](https://pyg.org/ns-newsarticle-accelerating-pyg-on-nvidia-gpus))
    和 Intel ([post](https://pyg.org/news/accelerating-pyg-on-intel-cpus)) 合作，分别提高了
    GPU 和 CPU 上核心操作的性能。类似地，DGL [纳入](https://www.dgl.ai/release/2022/07/25/release.html)
    了最近 0.9 版本中的新 GPU 优化。对于稀疏矩阵乘法和采样程序都有大幅提升，因此我们建议你更新到最新版本的环境！
- en: '**What to expect in 2023**: major GNN libraries are likely to increase the
    breadth of supported hardware backends such as IPUs or upcoming Intel Max Series
    GPUs.'
  id: totrans-185
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**2023 年的期望：** 主要 GNN 库可能会扩展对硬件后端的支持，如 IPU 或即将推出的 Intel Max 系列 GPU。'
- en: 'New Conferences: Learning of Graphs (LoG) and Molecular ML (MoML)'
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 新会议：学习图形（LoG）和分子 ML（MoML）
- en: 'This year we witnessed the inauguration of two graph and geometric ML conferences:
    the [Learning on Graphs Conference (LoG)](https://logconference.org/#hero) and
    the [Molecular ML Conference](https://www.moml22.mit.edu/) (MoML).'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 今年我们见证了两个图形和几何 ML 会议的启动：[学习图形会议（LoG）](https://logconference.org/#hero) 和 [分子
    ML 会议](https://www.moml22.mit.edu/)（MoML）。
- en: LoG is a more general all-around GraphML venue (held virtually this year) while
    MoML (held at MIT) has a broader mission and influence over the AI4Science community
    where graphs and geometry still plays a major role. Both conferences were received
    extremely well. MoML attracted 7 top speakers and 38 posters, LoG had ~3000 registrations,
    266 submissions, 71 posters, 12 orals, and 7 awesome tutorials (all recordings
    of oral talks and tutorials are [already on YouTube](https://www.youtube.com/@learningongraphs)).
    Besides, LoG introduced a great monetary incentive for reviewers, resulting in
    a well-recognized improvement of the review quality! From our point of view, quality
    of LoG reviews was often better than those at NeurIPS or ICML.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: LoG 是一个更通用的全方位 GraphML 会议（今年以虚拟形式举行），而 MoML（在 MIT 举办）具有更广泛的使命和对 AI4Science 社区的影响，其中图和几何仍然扮演着重要角色。这两个会议都得到了极好的反响。MoML
    吸引了 7 位顶级讲者和 38 个海报，LoG 有大约 3000 个注册、266 个投稿、71 个海报、12 个口头报告和 7 个精彩的教程（所有口头报告和教程的录音[已在
    YouTube](https://www.youtube.com/@learningongraphs) 上）。此外，LoG 为评审引入了丰厚的奖金激励，显著提高了评审质量！在我们看来，LoG
    的评审质量通常优于 NeurIPS 或 ICML 的评审。
- en: This is a huge win and carnival for the graph ML community, and congrats to
    everyone working in the field of graph and geometric machine learning with a new
    “home” venue!
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这是图形 ML 社区的一次巨大胜利和庆典，祝贺所有在图形和几何机器学习领域工作的人员，拥有了一个新的“家”会议！
- en: '**What to expect in 2023:** LOG and MoML become main Graph ML venues to include
    into your submission calendar along with ICLR / NeurIPS / ICML'
  id: totrans-190
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**2023 年的期望：** LOG 和 MoML 将成为包括在提交日历中的主要 Graph ML 会议，此外还有 ICLR / NeurIPS /
    ICML。'
- en: Courses and Educational Materials
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 课程和教育材料
- en: Geometric Deep Learning Course — [Second Edition](https://www.youtube.com/playlist?list=PLn2-dEmQeTfSLXW8yXP4q_Ii58wFdxb3C)
    (2022) is already on YouTube. The main entry point to the field.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 几何深度学习课程 — [第二版](https://www.youtube.com/playlist?list=PLn2-dEmQeTfSLXW8yXP4q_Ii58wFdxb3C)（2022
    年）已在 YouTube 上。该领域的主要入门点。
- en: '[An Introduction to Group Equivariant Deep Learning](https://uvagedl.github.io/)
    by Erik Bekkers — one of the best new courses about equivariance and equivariant
    models!'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[群体等变深度学习介绍](https://uvagedl.github.io/) 由 Erik Bekkers 提供 — 这是关于等变性和等变模型的最佳新课程之一！'
- en: '[Cats4AI](https://cats.for.ai/) — a new course by Andrew Dudzik, Bruno Gavranović,
    João Guilherme Araújo, Petar Veličković, and Pim de Haan is the best place to
    learn about category theory and its connections to Geometric DL.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Cats4AI](https://cats.for.ai/) — 由 Andrew Dudzik、Bruno Gavranović、João Guilherme
    Araújo、Petar Veličković 和 Pim de Haan 开设的新课程，是了解范畴理论及其与几何深度学习连接的最佳场所。'
- en: 'Summer School proceedings: [Italian Summer School on Geometric DL](https://www.sci.unich.it/geodeep2022/#home),
    London Geometry and Machine Learning ([LOGML](https://www.logml.ai/home-2022))
    Summer School, [BIRS Workshop on Topological Representation Learning](https://www.birs.ca/events/2022/5-day-workshops/22w5125).'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 夏季学校成果：[意大利几何深度学习夏季学校](https://www.sci.unich.it/geodeep2022/#home)、伦敦几何与机器学习（[LOGML](https://www.logml.ai/home-2022)）夏季学校、[BIRS
    顶点表示学习研讨会](https://www.birs.ca/events/2022/5-day-workshops/22w5125)。
- en: '[Stanford Graph Learning Workshop 2022](https://snap.stanford.edu/graphlearning-workshop-2022/)
    — latest news from PyG developers and partners and Stanford researchers.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[斯坦福图学习研讨会 2022](https://snap.stanford.edu/graphlearning-workshop-2022/) —
    PyG开发者、合作伙伴和斯坦福研究人员的最新消息。'
- en: New Datasets, Benchmarks, and Challenges
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 新数据集、基准和挑战
- en: '[OGB Large-Scale Challenge 2022](https://ogb.stanford.edu/neurips2022/): The
    second large scale challenge held at NeurIPS2022 with large and realistic graph
    ML tasks covering node-, edge-, graph-level predictions.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OGB大规模挑战 2022](https://ogb.stanford.edu/neurips2022/): 第二届大规模挑战，在NeurIPS2022上举办，涵盖节点、边、图级预测的大规模和现实图机器学习任务。'
- en: '[Open Catalyst 2022 Challenge](https://opencatalystproject.org/challenge.html):
    the second edition of the challenge held at NeurIPS2022 with the task to design
    new machine learning models to predict the outcome of catalyst simulations used
    to understand activity'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[开放催化剂 2022 挑战](https://opencatalystproject.org/challenge.html): 第二届挑战，在NeurIPS2022上举办，任务是设计新的机器学习模型，以预测催化剂模拟的结果，以了解其活性。'
- en: '[CASP 15](https://predictioncenter.org/casp15/index.cgi): the protein structure
    prediction challenge disrupted by AlphaFold a few years ago at CASP 14\. Detailed
    analysis is yet to come, but it seems that MSAs strike back and best performing
    models still rely on MSAs.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CASP 15](https://predictioncenter.org/casp15/index.cgi): 由AlphaFold在CASP 14中引发的蛋白质结构预测挑战。详细分析尚待公布，但似乎MSAs卷土重来，表现最好的模型仍然依赖于MSAs。'
- en: '[Long Range Graph Benchmark](https://arxiv.org/abs/2206.08164): for measuring
    GNNs and GTs capabilities of capturing long range interactions in graphs.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[长距离图基准](https://arxiv.org/abs/2206.08164): 用于测量GNNs和GTs在图中捕捉长距离交互的能力。'
- en: '[Taxonomy of Graph Benchmarks](https://arxiv.org/abs/2206.07729), [Graph Learning
    Indexer](https://github.com/Graph-Learning-Benchmarks/gli): deeper studies of
    the dataset landscape in Graph ML outlining open challenges in benchmarking and
    trustworthiness of results.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[图基准分类](https://arxiv.org/abs/2206.07729)，[图学习索引器](https://github.com/Graph-Learning-Benchmarks/gli):
    对图机器学习数据集景观的深入研究，概述了基准测试和结果可信度中的开放挑战。'
- en: '[GraphWorld](https://ai.googleblog.com/2022/05/graphworld-advances-in-graph.html):
    a framework for analyzing the performance of GNN architectures on millions of
    synthetic benchmark datasets'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GraphWorld](https://ai.googleblog.com/2022/05/graphworld-advances-in-graph.html):
    一个框架，用于分析GNN架构在数百万个合成基准数据集上的表现。'
- en: '[Chartalist](https://openreview.net/forum?id=10iA3OowAV3) — a collection of
    blockchain graph datasets'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Chartalist](https://openreview.net/forum?id=10iA3OowAV3) — 一系列区块链图数据集。'
- en: '[PEER protein learning benchmark](https://github.com/DeepGraphLearning/PEER_Benchmark):
    a multi-task benchmark for protein sequence understanding with 17 tasks of protein
    understanding lying in 5 task categories.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PEER蛋白质学习基准](https://github.com/DeepGraphLearning/PEER_Benchmark): 一个多任务蛋白质序列理解基准，包括17个蛋白质理解任务，分为5个任务类别。'
- en: '[ESM Metagenomic Atlas](https://esmatlas.com/): acomprehensive database of
    over 600 million predicted protein structures with nice visualizations and search
    UI.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ESM宏基因组图谱](https://esmatlas.com/): 一个综合性数据库，包含超过6亿个预测蛋白质结构，提供了漂亮的可视化和搜索界面。'
- en: Software Libraries and Open Source
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 软件库和开源
- en: 'Mainstream graph ML libraries: [PyG 2.2](https://www.pyg.org/) (PyTorch), [DGL
    0.9](https://www.dgl.ai/) (PyTorch, TensorFlow, MXNet), [TF GNN](https://github.com/tensorflow/gnn)
    (TensorFlow) and [Jraph](https://github.com/deepmind/jraph) (Jax)'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主流图机器学习库：[PyG 2.2](https://www.pyg.org/)（PyTorch），[DGL 0.9](https://www.dgl.ai/)（PyTorch、TensorFlow、MXNet），[TF
    GNN](https://github.com/tensorflow/gnn)（TensorFlow）和 [Jraph](https://github.com/deepmind/jraph)（Jax）
- en: '[TorchDrug](https://torchdrug.ai/) and [TorchProtein](https://torchprotein.ai/):
    machine learning library for drug discovery and protein science'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TorchDrug](https://torchdrug.ai/) 和 [TorchProtein](https://torchprotein.ai/):
    用于药物发现和蛋白质科学的机器学习库。'
- en: '[PyKEEN](https://github.com/pykeen/pykeen): the best platform for training
    and evaluating knowledge graph embeddings'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyKEEN](https://github.com/pykeen/pykeen): 用于训练和评估知识图谱嵌入的最佳平台。'
- en: '[Graphein](https://graphein.ai/): a package that provides a number of types
    of graph-based representations of proteins'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Graphein](https://graphein.ai/): 提供多种基于图的蛋白质表示的包。'
- en: '[GRAPE](https://github.com/AnacletoLAB/grape) and [Marius](https://marius-project.org/):
    scalable graph processing and embedding libraries over billion-scale graphs'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GRAPE](https://github.com/AnacletoLAB/grape) 和 [Marius](https://marius-project.org/):
    可扩展的图处理和嵌入库，处理超大规模图。'
- en: '[MatSci ML Toolkit](https://github.com/IntelLabs/matsciml): a flexible framework
    for deep learning on the opencatalyst dataset'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MatSci ML工具包](https://github.com/IntelLabs/matsciml): 用于在opencatalyst数据集上进行深度学习的灵活框架。'
- en: '[E3nn](https://github.com/e3nn/e3nn): the go-to library for E(3) equivariant
    neural networks'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[E3nn](https://github.com/e3nn/e3nn)：用于 E(3) 等变神经网络的首选库'
- en: Join the Community
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入社区
- en: 'Reading Groups: [Learning on Graphs and Geometry](https://m2d2.io/talks/log2/about/)
    (LOG2) reading group, [Molecular Modeling & Drug Discovery](https://m2d2.io/talks/m2d2/about/)
    (M2D2) reading group, and their Slack communities'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读小组：[图学习与几何](https://m2d2.io/talks/log2/about/)（LOG2）阅读小组，[分子建模与药物发现](https://m2d2.io/talks/m2d2/about/)（M2D2）阅读小组及其
    Slack 社区
- en: Learning of Graphs (LoG) [Slack community](https://logconference.org/)
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图学习（LoG）[Slack 社区](https://logconference.org/)
- en: '[Michael Bronstein’s blog on Medium](https://michael-bronstein.medium.com/)'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Michael Bronstein 的 Medium 博客](https://michael-bronstein.medium.com/)'
- en: '[PyG medium](https://medium.com/@pytorch_geometric), [blog posts](https://pyg.org/blogs-and-tutorials),
    and newsletter'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyG medium](https://medium.com/@pytorch_geometric)、[博客文章](https://pyg.org/blogs-and-tutorials)和通讯'
- en: '[GraphML Telegram channel](https://t.me/graphML)'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GraphML Telegram 频道](https://t.me/graphML)'
- en: The Meme of 2022 🪓
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2022 年的流行文化现象 🪓
- en: '![](../Images/8b5892b801b9e71ad5914d29b86184f8.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8b5892b801b9e71ad5914d29b86184f8.png)'
- en: Created by Michael Galkin and Michael Bronstein
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 由 Michael Galkin 和 Michael Bronstein 创建
