- en: 'Advanced RAG 01: Small-to-Big Retrieval'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级 RAG 01：从小到大的检索
- en: 原文：[https://towardsdatascience.com/advanced-rag-01-small-to-big-retrieval-172181b396d4?source=collection_archive---------0-----------------------#2023-11-04](https://towardsdatascience.com/advanced-rag-01-small-to-big-retrieval-172181b396d4?source=collection_archive---------0-----------------------#2023-11-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/advanced-rag-01-small-to-big-retrieval-172181b396d4?source=collection_archive---------0-----------------------#2023-11-04](https://towardsdatascience.com/advanced-rag-01-small-to-big-retrieval-172181b396d4?source=collection_archive---------0-----------------------#2023-11-04)
- en: Child-Parent RecursiveRetriever and Sentence Window Retrieval with LlamaIndex
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Child-Parent 递归检索器和 LlamaIndex 的句子窗口检索
- en: '[](https://sophiamyang.medium.com/?source=post_page-----172181b396d4--------------------------------)[![Sophia
    Yang, Ph.D.](../Images/c133f918245ea4857dc46df3a07fc2b1.png)](https://sophiamyang.medium.com/?source=post_page-----172181b396d4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----172181b396d4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----172181b396d4--------------------------------)
    [Sophia Yang, Ph.D.](https://sophiamyang.medium.com/?source=post_page-----172181b396d4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://sophiamyang.medium.com/?source=post_page-----172181b396d4--------------------------------)[![Sophia
    Yang, Ph.D.](../Images/c133f918245ea4857dc46df3a07fc2b1.png)](https://sophiamyang.medium.com/?source=post_page-----172181b396d4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----172181b396d4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----172181b396d4--------------------------------)
    [Sophia Yang, Ph.D.](https://sophiamyang.medium.com/?source=post_page-----172181b396d4--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fae9cae9cbcd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-rag-01-small-to-big-retrieval-172181b396d4&user=Sophia+Yang%2C+Ph.D.&userId=ae9cae9cbcd2&source=post_page-ae9cae9cbcd2----172181b396d4---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----172181b396d4--------------------------------)
    ·7 min read·Nov 4, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F172181b396d4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-rag-01-small-to-big-retrieval-172181b396d4&user=Sophia+Yang%2C+Ph.D.&userId=ae9cae9cbcd2&source=-----172181b396d4---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fae9cae9cbcd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-rag-01-small-to-big-retrieval-172181b396d4&user=Sophia+Yang%2C+Ph.D.&userId=ae9cae9cbcd2&source=post_page-ae9cae9cbcd2----172181b396d4---------------------post_header-----------)
    发布在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----172181b396d4--------------------------------)
    ·7分钟阅读·2023年11月4日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F172181b396d4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-rag-01-small-to-big-retrieval-172181b396d4&user=Sophia+Yang%2C+Ph.D.&userId=ae9cae9cbcd2&source=-----172181b396d4---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F172181b396d4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-rag-01-small-to-big-retrieval-172181b396d4&source=-----172181b396d4---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F172181b396d4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-rag-01-small-to-big-retrieval-172181b396d4&source=-----172181b396d4---------------------bookmark_footer-----------)'
- en: RAG (Retrieval-Augmented Generation) systems retrieve relevant information from
    a given knowledge base, thereby allowing it to generate factual, contextually
    relevant, and domain-specific information. However, RAG faces a lot of challenges
    when it comes to effectively retrieving relevant information and generating high-quality
    responses. In this series of blog posts/videos, I will walk through advanced RAG
    techniques aiming at optimizing the RAG workflow and addressing the challenges
    in naive RAG systems.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: RAG（检索增强生成）系统从给定的知识库中检索相关信息，从而生成事实性、语境相关且领域特定的信息。然而，RAG 在有效检索相关信息和生成高质量响应方面面临许多挑战。在这一系列的博客文章/视频中，我将介绍高级
    RAG 技术，旨在优化 RAG 工作流并解决原始 RAG 系统中的挑战。
- en: The first technique is called **small-to-big retrieval**. In basic RAG pipelines,
    we embed a big text chunk for retrieval, and this exact same text chunk is used
    for synthesis. But sometimes embedding/retrieving big text chunks can feel suboptimal.
    There might be a lot of filler text in a big text chunk that hides the semantic
    representation, leading to worse retrieval. What if we could embed/retrieve based
    on smaller, more targeted chunks, but still have enough context for the LLM to
    synthesize a response? Specifically, decoupling text chunks used for retrieval
    vs. the text chunks used for synthesis could be advantageous. Using smaller text
    chunks enhances the accuracy of retrieval, while larger text chunks offer more
    contextual information. The concept behind small-to-big retrieval is to use smaller
    text chunks during the retrieval process and subsequently provide the larger text
    chunk to which the retrieved text belongs to the large language model.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个技术称为 **小到大的检索**。在基本的 RAG 流水线中，我们对大的文本块进行嵌入以进行检索，并且这个相同的文本块用于合成。但有时对大文本块进行嵌入/检索可能效果不佳。大的文本块中可能包含大量的填充文本，这些文本掩盖了语义表示，导致检索效果较差。如果我们可以基于较小的、更多针对性的块进行嵌入/检索，同时仍然提供足够的上下文供
    LLM 合成响应，那将会怎样？具体来说，将用于检索的文本块与用于合成的文本块解耦可能是有利的。使用较小的文本块可以提高检索的准确性，而较大的文本块则提供了更多的上下文信息。小到大检索的概念是在检索过程中使用较小的文本块，然后将包含检索文本的大文本块提供给大语言模型。
- en: 'There are two primary techniques:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 主要有两种技术：
- en: '**Smaller Child Chunks Referring to Bigger Parent Chunks**: Fetch smaller chunks
    during retrieval first, then reference the parent IDs, and return the bigger chunks.'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**较小的子块引用较大的父块**：在检索过程中首先获取较小的块，然后引用父块的 ID，最后返回较大的块。'
- en: '**Sentence Window Retrieval:** Fetch a single sentence during retrieval and
    return a window of text around the sentence.'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**句子窗口检索**：在检索过程中获取单个句子，并返回该句子周围的一段文本。'
- en: In this blog post, we will dive into the implementations of these two methods
    in LlamaIndex. Why am I not doing it in LangChain? Because there are already lots
    of resources out there on advanced RAG with LangChain. I’d rather not duplicate
    the effort. Also, I use both LangChain and LlamaIndex. It’s best to understand
    more tools and use them flexibly.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我们将深入探讨这两种方法在 LlamaIndex 中的实现。为什么我不在 LangChain 中进行？因为在 LangChain 中已有大量关于高级
    RAG 的资源。我宁愿不重复劳动。另外，我同时使用 LangChain 和 LlamaIndex。了解更多工具并灵活使用是最好的。
- en: You can find all the code in this [notebook](https://colab.research.google.com/github/sophiamyang/demos/blob/main/advanced_rag_small_to_big.ipynb).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这个 [notebook](https://colab.research.google.com/github/sophiamyang/demos/blob/main/advanced_rag_small_to_big.ipynb)
    中找到所有代码。
- en: Basic RAG Review
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本 RAG 复习
- en: 'Let’s start with a basic RAG implementation with 4 simple steps:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个基本的 RAG 实现开始，分为 4 个简单步骤：
- en: '**Step 1\. Loading Documents**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 1\. 加载文档**'
- en: We use a PDFReader to load a PDF file, and combine each page of the document
    into one Document object.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 PDFReader 加载 PDF 文件，并将文档的每一页合并为一个 Document 对象。
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Step 2\. Parsing Documents into Text Chunks (Nodes)**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 2\. 将文档解析成文本块（节点）**'
- en: Then we split the document into text chunks, which are called “Nodes” in LlamaIndex,
    where we define the chuck size as 1024\. The default node IDs are random text
    strings, we can then format our node ID to follow a certain format.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将文档拆分成文本块，这些块在 LlamaIndex 中称为“节点”，我们将块大小定义为 1024。默认的节点 ID 是随机文本字符串，我们可以将节点
    ID 格式化为某种格式。
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Step 3\. Select Embedding Model and LLM**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 3\. 选择嵌入模型和 LLM**'
- en: 'We need to define two models:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要定义两个模型：
- en: The embedding model is used to create vector embeddings for each of the text
    chunks. Here we are calling the [FlagEmbedding](https://huggingface.co/BAAI/bge-small-en)
    model from Hugging Face.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 嵌入模型用于为每个文本块创建向量嵌入。这里我们调用了 [FlagEmbedding](https://huggingface.co/BAAI/bge-small-en)
    模型来自 Hugging Face。
- en: 'LLM: user query and the relevant text chunks are fed into the LLM so that it
    can generate answers with relevant context.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM：用户查询和相关文本块被输入到 LLM 中，以便它可以生成带有相关上下文的答案。
- en: We can bundle these two models together in the ServiceContext and use them later
    in the indexing and querying steps.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这两个模型捆绑在 ServiceContext 中，然后在索引和查询步骤中使用它们。
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Step 4\. Create Index, retriever, and query engine**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 4\. 创建索引、检索器和查询引擎**'
- en: 'Index, retriever, and query engine are three basic components for asking questions
    about your data or documents:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 索引、检索器和查询引擎是三个基本组件，用于询问有关数据或文档的问题：
- en: Index is a data structure that allows us to retrieve relevant information quickly
    for a user query from external documents. The Vector Store Index takes the text
    chunks/Nodes and then creates vector embeddings of the text of every node, ready
    to be queried by an LLM.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索引是一种数据结构，允许我们快速检索用户查询的相关信息。向量存储索引将文本块/节点转换为向量嵌入，准备好供 LLM 查询。
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Retriever is used for fetching and retrieving relevant information given user
    query.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Retriever 用于根据用户查询提取和检索相关信息。
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Query engine is built on top of the index and retriever providing a generic
    interface to ask questions about your data.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询引擎建立在索引和检索器之上，提供一个通用接口来提问关于数据的问题。
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/9b2a0ffe21724a1924606ac62e2c7e20.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9b2a0ffe21724a1924606ac62e2c7e20.png)'
- en: 'Advanced Method 1: Smaller Child Chunks Referring to Bigger Parent Chunks'
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级方法 1：较小的子块引用更大的父块
- en: 'In the previous section, we used a fixed chunk size of 1024 for both retrieval
    and synthesis. In this section, we are going to explore how to use smaller child
    chunks for retrieval and refer to bigger parent chunks for synthesis. The first
    step is to create smaller child chunks:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一部分中，我们使用了固定大小为 1024 的块进行检索和合成。在这一部分中，我们将探讨如何使用较小的子块进行检索，并引用较大的父块进行合成。第一步是创建较小的子块：
- en: '**Step 1: Create Smaller Child Chunks**'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 1：创建更小的子块**'
- en: 'For each of the text chunks with chunk size 1024, we create even smaller text
    chunks:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个大小为 1024 的文本块，我们创建更小的文本块：
- en: 8 text chunks of size 128
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 8 个大小为 128 的文本块
- en: 4 text chunks of size 256
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 4 个大小为 256 的文本块
- en: 2 text chunks of size 512
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 个大小为 512 的文本块
- en: We append the original text chunk of size 1024 to the list of text chunks.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将原始大小为 1024 的文本块附加到文本块列表中。
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: When we take a look at all the text chunks `all_nodes_dict`, we can see many
    smaller chunks are associated with each of the original text chunks for example
    `node-0`. In fact, all of the smaller chunks reference to the large chunk in the
    metadata with index_id pointing to the index ID of the larger chunk.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们查看所有的文本块`all_nodes_dict`时，我们可以看到许多更小的块与每个原始文本块相关联，例如`node-0`。实际上，所有更小的块在元数据中引用大块，索引
    ID 指向较大块的索引 ID。
- en: '![](../Images/ecafaa8666c5f4d709895e6509f251af.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ecafaa8666c5f4d709895e6509f251af.png)'
- en: '**Step 2: Create Index, retriever, and query engine**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 2：创建索引、检索器和查询引擎**'
- en: 'Index: Create vector embeddings of all the text chunks.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索引：创建所有文本块的向量嵌入。
- en: '[PRE7]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Retriever: the key here is to use a **RecursiveRetriever** to traverse node
    relationships and fetch nodes based on “references”. This retriever will recursively
    explore links from nodes to other retrievers/query engines. For any retrieved
    nodes, if any of the nodes are IndexNodes, then it will explore the linked retriever/query
    engine and query that.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Retriever：关键在于使用**RecursiveRetriever**来遍历节点关系，并根据“引用”提取节点。这个检索器将递归地探索从节点到其他检索器/查询引擎的链接。对于任何检索到的节点，如果任何节点是
    IndexNodes，那么它将探索链接的检索器/查询引擎并进行查询。
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: When we ask a question and retrieve the most relevant text chunks, it will actually
    retrieve the text chunk with the node id pointing to the parent chunk and thus
    retrieve the parent chunk.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们提出一个问题并检索最相关的文本块时，它实际上会检索指向父块的节点 ID 的文本块，从而检索到父块。
- en: '![](../Images/745e9d631b07b5bcb9c452f36573e737.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/745e9d631b07b5bcb9c452f36573e737.png)'
- en: Now with the same steps as before, we can create a query engine as a generic
    interface to ask questions about our data.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在，按照之前的步骤，我们可以创建一个查询引擎作为通用接口来提问关于我们数据的问题。
- en: '[PRE9]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/b650da5b25213cf97602caf2808e003a.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b650da5b25213cf97602caf2808e003a.png)'
- en: 'Advanced Method 2: Sentence Window Retrieval'
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级方法 2：句子窗口检索
- en: To achieve an even more fine-grained retrieval, instead of using smaller child
    chunks, we can parse the documents into a single sentence per chunk.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现更细粒度的检索，我们可以将文档解析为每个块一个单独的句子，而不是使用更小的子块。
- en: In this case, single sentences will be similar to the “child” chunk concept
    we mentioned in method 1\. The sentence “window” (5 sentences on either side of
    the original sentence) will be similar to the “parent” chunk concept. In other
    words, we use the single sentences during retrieval and pass the retrieved sentence
    with the sentence window to the LLM.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，单句子将类似于我们在方法 1 中提到的“子块”概念。句子“窗口”（原句子两侧的 5 个句子）将类似于“父块”概念。换句话说，我们在检索过程中使用单句子，并将检索到的句子与句子窗口一起传递给
    LLM。
- en: '**Step 1: Create sentence window node parser**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 1：创建句子窗口节点解析器**'
- en: '[PRE10]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '**Step 2: Create query engine**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: When we create the query engine, we can replace the sentence with the sentence
    window using the MetadataReplacementPostProcessor, so that the window of the sentences
    get sent to the LLM.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The Sentence Window Retrieval was able to answer the question “Can you tell
    me about the key concepts for safety finetuning”:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4ab8ad213fe4335b4aa98bcea6f7159f.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
- en: Here you can see the actual sentence retrieved and the window of the sentence,
    which provides more context and details.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a837434f74e6571a46044db2ca09ac23.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
- en: '**Conclusion**'
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this blog, we explored how to use small-to-big retrieval to improve RAG,
    focusing on the Child-Parent RecursiveRetriever and Sentence Window Retrieval
    with LlamaIndex. In future blog posts, we will dive deeper into other tricks and
    tips. Stay tuned for more on this exciting journey into advanced RAG techniques!
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: 'References:'
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[https://docs.llamaindex.ai/en/latest/examples/node_postprocessor/MetadataReplacementDemo.html](https://docs.llamaindex.ai/en/latest/examples/node_postprocessor/MetadataReplacementDemo.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://docs.llamaindex.ai/en/stable/examples/retrievers/recursive_retriever_nodes.html](https://docs.llamaindex.ai/en/stable/examples/retrievers/recursive_retriever_nodes.html)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/5deefebaf7043e111b40052de0e361dc.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
- en: . . .
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: By [Sophia Yang](https://www.linkedin.com/in/sophiamyang/) on November 4, 2023
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Connect with me on [LinkedIn](https://www.linkedin.com/in/sophiamyang/), [Twitter](https://twitter.com/sophiamyang),
    and [YouTube](https://www.youtube.com/SophiaYangDS) and join the DS/ML [Book Club](https://dsbookclub.github.io/)
    ❤️
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
