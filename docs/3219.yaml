- en: Entropy-Regularized Reinforcement Learning Explained
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/entropy-regularized-reinforcement-learning-explained-2ba959c92aad?source=collection_archive---------11-----------------------#2023-10-26](https://towardsdatascience.com/entropy-regularized-reinforcement-learning-explained-2ba959c92aad?source=collection_archive---------11-----------------------#2023-10-26)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learn more reliable, robust, and transferable policies by adding entropy bonuses
    to your algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://wvheeswijk.medium.com/?source=post_page-----2ba959c92aad--------------------------------)[![Wouter
    van Heeswijk, PhD](../Images/9c996bccd6fdfb6d9aa8b50b93338eb9.png)](https://wvheeswijk.medium.com/?source=post_page-----2ba959c92aad--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2ba959c92aad--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2ba959c92aad--------------------------------)
    [Wouter van Heeswijk, PhD](https://wvheeswijk.medium.com/?source=post_page-----2ba959c92aad--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F33f45c9ab481&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fentropy-regularized-reinforcement-learning-explained-2ba959c92aad&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=post_page-33f45c9ab481----2ba959c92aad---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2ba959c92aad--------------------------------)
    ·8 min read·Oct 26, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2ba959c92aad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fentropy-regularized-reinforcement-learning-explained-2ba959c92aad&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=-----2ba959c92aad---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2ba959c92aad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fentropy-regularized-reinforcement-learning-explained-2ba959c92aad&source=-----2ba959c92aad---------------------bookmark_footer-----------)![](../Images/2fce76a87f64dcb27147a0868dc84b72.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Jeremy Thomas](https://unsplash.com/@jeremythomasphoto?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '*Entropy* is a concept associated with a state of disorder, randomness, or
    uncertainty. It can be considered as a **measure of information for random variables**.
    Traditionally, it is associated with fields such as thermodynamics, but the term
    found its way to many other domains.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In 1948, Claude Shannon introduced the notion of entropy in information theory.
    In this context, an event is considered to offer more information if it has a
    lower probability of happening; the **information of an event is inversely correlated
    to its probability of occurrence**. Intuitively: we learn more from rare events.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The notion of entropy can be formalized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: In Reinforcement Learning (RL), the notion of entropy has been deployed as well,
    with the purpose of encouraging exploration. In this context, entropy is a **measure
    of predictability of actions** returned by a stochastic policy.
  prefs: []
  type: TYPE_NORMAL
- en: Concretely, **RL takes the entropy of the policy (i.e., probability distribution
    of actions) as a bonus and embeds it as a reward component**. This article addresses
    the basic case, but entropy bonuses are an integral part of many…
  prefs: []
  type: TYPE_NORMAL
