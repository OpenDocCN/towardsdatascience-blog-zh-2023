["```py\nimport requests\n\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n}\n\nresponse_json = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json={\n    \"model\": \"gpt-3.5-turbo\",\n    \"messages\": [{\"role\": \"user\", \"content\": \"ping\"}],\n    \"temperature\": 0\n}).json()\n\nprint(response_json[\"choices\"][0][\"message\"][\"content\"])\n```", "```py\nPong!\n```", "```py\n# Sync call\n\nimport time\n\ndef delay_print(msg):\n    print(msg, end=\" \")\n    time.sleep(1)\n\ndef sync_print():\n    for i in range(10):\n        delay_print(i)\n\nstart_time = time.time()\nsync_print()\nprint(\"\\n\", time.time() - start_time, \"seconds.\")\n```", "```py\n0 1 2 3 4 5 6 7 8 9 \n 10.019574642181396 seconds.\n```", "```py\n#Async Call\n\nimport asyncio\n\nasync def delay_print_async(msg):\n    print(msg, end=\" \")\n    await asyncio.sleep(1)\n\nasync def async_print():\n    asyncio.gather(*[delay_print_async(i) for i in range(10)])\n\nstart_time = time.time()\nawait async_print()\nprint(\"\\n\", time.time() - start_time, \"seconds.\")\n```", "```py\n0.0002448558807373047 seconds.\n0 1 2 3 4 5 6 7 8 9 \n```", "```py\nimport aiohttp\n\nasync def get_completion(content):\n    async with aiohttp.ClientSession() as session:\n        async with session.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json={\n            \"model\": \"gpt-3.5-turbo\",\n            \"messages\": [{\"role\": \"user\", \"content\": content}],\n            \"temperature\": 0\n        }) as resp:\n\n            response_json = await resp.json()\n            return response_json[\"choices\"][0]['message'][\"content\"]\n\nawait get_completion(\"Ping\")\n```", "```py\nPong!\n```", "```py\nasync def get_completion_list(content_list):\n    return await asyncio.gather(*[get_completion(content) for content in content_list])\n\nawait get_completion_list([\"ping\", \"pong\"]*5)\n```", "```py\n['Pong!',\n 'Ping!',\n 'Pong!',\n 'Ping!',\n 'Pong!',\n 'Ping!',\n 'Pong!',\n 'Ping!',\n 'Pong!',\n 'Ping!']\n```", "```py\nasync def get_completion(content, session):\n    async with session.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json={\n        \"model\": \"gpt-3.5-turbo\",\n        \"messages\": [{\"role\": \"user\", \"content\": content}],\n        \"temperature\": 0\n    }) as resp:\n\n        response_json = await resp.json()\n        return response_json[\"choices\"][0]['message'][\"content\"]\n\nasync def get_completion_list(content_list):\n    async with aiohttp.ClientSession() as session:\n        return await asyncio.gather(*[get_completion(content, session) for content in content_list])\n\nawait get_completion_list([\"ping\", \"pong\"]*5)\n```", "```py\nasync def get_completion(content, session, semaphore):\n    async with semaphore:\n\n        await asyncio.sleep(1)\n\n        async with session.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json={\n            \"model\": \"gpt-3.5-turbo\",\n            \"messages\": [{\"role\": \"user\", \"content\": content}],\n            \"temperature\": 0\n        }) as resp:\n\n            response_json = await resp.json()\n            return response_json[\"choices\"][0]['message'][\"content\"]\n\nasync def get_completion_list(content_list, max_parallel_calls):\n    semaphore = asyncio.Semaphore(value=max_parallel_calls)\n\n    async with aiohttp.ClientSession() as session:\n        return await asyncio.gather(*[get_completion(content, session, semaphore) for content in content_list])\n\nstart_time = time.perf_counter()\ncompletion_list = await get_completion_list([\"ping\", \"pong\"]*5, 100)\nprint(\"Time elapsed: \", time.perf_counter() - start_time, \"seconds.\")\nprint(completion_list)\n```", "```py\nTime elapsed:  1.8094507199984946 seconds.\n['Pong!', 'Ping!', 'Pong!', 'Ping!', 'Pong!', 'Ping!', 'Pong!', 'Ping!', 'Pong!', 'Ping!']\n```", "```py\nclass ProgressLog:\n    def __init__(self, total):\n        self.total = total\n        self.done = 0\n\n    def increment(self):\n        self.done = self.done + 1\n\n    def __repr__(self):\n        return f\"Done runs {self.done}/{self.total}.\"\n\nasync def get_completion(content, session, semaphore, progress_log):\n    async with semaphore:\n\n        await asyncio.sleep(1)\n\n        async with session.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json={\n            \"model\": \"gpt-3.5-turbo\",\n            \"messages\": [{\"role\": \"user\", \"content\": content}],\n            \"temperature\": 0\n        }) as resp:\n\n            response_json = await resp.json()\n\n            progress_log.increment()\n            print(progress_log)\n\n            return response_json[\"choices\"][0]['message'][\"content\"]\n\nasync def get_completion_list(content_list, max_parallel_calls):\n    semaphore = asyncio.Semaphore(value=max_parallel_calls)\n    progress_log = ProgressLog(len(content_list))\n\n    async with aiohttp.ClientSession() as session:\n        return await asyncio.gather(*[get_completion(content, session, semaphore, progress_log) for content in content_list])\n\nstart_time = time.perf_counter()\ncompletion_list = await get_completion_list([\"ping\", \"pong\"]*5, 100)\nprint(\"Time elapsed: \", time.perf_counter() - start_time, \"seconds.\")\nprint(completion_list)\n```", "```py\nDone runs 1/10.\nDone runs 2/10.\nDone runs 3/10.\nDone runs 4/10.\nDone runs 5/10.\nDone runs 6/10.\nDone runs 7/10.\nDone runs 8/10.\nDone runs 9/10.\nDone runs 10/10.\nTime elapsed:  1.755018908999773 seconds.\n['Pong!', 'Ping!', 'Pong!', 'Ping!', 'Pong!', 'Ping!', 'Pong!', 'Ping!', 'Pong!', 'Ping!']\n```", "```py\nfrom tenacity import (\n    retry,\n    stop_after_attempt,\n    wait_random_exponential,\n)\n```", "```py\nimport random\n\nclass ProgressLog:\n    def __init__(self, total):\n        self.total = total\n        self.done = 0\n\n    def increment(self):\n        self.done = self.done + 1\n\n    def __repr__(self):\n        return f\"Done runs {self.done}/{self.total}.\"\n\n@retry(wait=wait_random_exponential(min=1, max=60), before_sleep=print)\nasync def get_completion(content, session, semaphore, progress_log):\n    async with semaphore:\n\n        #await asyncio.sleep(1)\n        if random.random() < 0.2:\n            raise Exception(\"Random exception\")\n\n        async with session.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json={\n            \"model\": \"gpt-3.5-turbo\",\n            \"messages\": [{\"role\": \"user\", \"content\": content}],\n            \"temperature\": 0\n        }) as resp:\n\n            response_json = await resp.json()\n\n            progress_log.increment()\n            print(progress_log)\n\n            return response_json[\"choices\"][0]['message'][\"content\"]\n\nasync def get_completion_list(content_list, max_parallel_calls):\n    semaphore = asyncio.Semaphore(value=max_parallel_calls)\n    progress_log = ProgressLog(len(content_list))\n\n    async with aiohttp.ClientSession() as session:\n        return await asyncio.gather(*[get_completion(content, session, semaphore, progress_log) for content in content_list])\n\nstart_time = time.perf_counter()\ncompletion_list = await get_completion_list([\"ping\", \"pong\"]*5, 100)\nprint(\"Time elapsed: \", time.perf_counter() - start_time, \"seconds.\")\nprint(completion_list)\n```", "```py\n<RetryCallState 133364377433616: attempt #1; slept for 0.74; last result: failed (Exception Random exception)>\n<RetryCallState 133364377424496: attempt #1; slept for 0.79; last result: failed (Exception Random exception)>\nDone runs 1/10.\nDone runs 2/10.\nDone runs 3/10.\nDone runs 4/10.\nDone runs 5/10.\nDone runs 6/10.\nDone runs 7/10.\nDone runs 8/10.\nDone runs 9/10.\nDone runs 10/10.\nTime elapsed:  1.1305301820011664 seconds.\n['Pong!', 'Ping!', 'Pong!', 'Ping!', 'Pong!', 'Ping!', 'Pong!', 'Ping!', 'Pong!', 'Ping!']\n```", "```py\nimport random\n\nclass ProgressLog:\n    def __init__(self, total):\n        self.total = total\n        self.done = 0\n\n    def increment(self):\n        self.done = self.done + 1\n\n    def __repr__(self):\n        return f\"Done runs {self.done}/{self.total}.\"\n\n@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(2), before_sleep=print)\nasync def get_completion(content, session, semaphore, progress_log):\n    async with semaphore:\n\n        #await asyncio.sleep(1)\n        if random.random() < 0.9:\n            raise Exception(\"Random exception\")\n\n        async with session.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json={\n            \"model\": \"gpt-3.5-turbo\",\n            \"messages\": [{\"role\": \"user\", \"content\": content}],\n            \"temperature\": 0\n        }) as resp:\n\n            response_json = await resp.json()\n\n            progress_log.increment()\n            print(progress_log)\n\n            return response_json[\"choices\"][0]['message'][\"content\"]\n\nasync def get_completion_list(content_list, max_parallel_calls):\n    semaphore = asyncio.Semaphore(value=max_parallel_calls)\n    progress_log = ProgressLog(len(content_list))\n\n    async with aiohttp.ClientSession() as session:\n        return await asyncio.gather(*[get_completion(content, session, semaphore, progress_log) for content in content_list])\n\nstart_time = time.perf_counter()\ncompletion_list = await get_completion_list([\"ping\", \"pong\"]*5, 100)\nprint(\"Time elapsed: \", time.perf_counter() - start_time, \"seconds.\")\nprint(completion_list)\n```", "```py\n<RetryCallState 133364608660048: attempt #1; slept for 0.1; last result: failed (Exception Random exception)>\n<RetryCallState 133364377435680: attempt #1; slept for 0.71; last result: failed (Exception Random exception)>\n<RetryCallState 133364377421472: attempt #1; slept for 0.17; last result: failed (Exception Random exception)>\n<RetryCallState 133364377424256: attempt #1; slept for 0.37; last result: failed (Exception Random exception)>\n<RetryCallState 133364377430928: attempt #1; slept for 0.87; last result: failed (Exception Random exception)>\n<RetryCallState 133364377420752: attempt #1; slept for 0.42; last result: failed (Exception Random exception)>\n<RetryCallState 133364377422576: attempt #1; slept for 0.47; last result: failed (Exception Random exception)>\n<RetryCallState 133364377431312: attempt #1; slept for 0.11; last result: failed (Exception Random exception)>\n<RetryCallState 133364377425840: attempt #1; slept for 0.69; last result: failed (Exception Random exception)>\n<RetryCallState 133364377424592: attempt #1; slept for 0.89; last result: failed (Exception Random exception)>\n---------------------------------------------------------------------------\nException                                 Traceback (most recent call last)\n/usr/local/lib/python3.10/dist-packages/tenacity/_asyncio.py in __call__(self, fn, *args, **kwargs)\n     49                 try:\n---> 50                     result = await fn(*args, **kwargs)\n     51                 except BaseException:  # noqa: B902\n\n5 frames\nException: Random exception\n\nThe above exception was the direct cause of the following exception:\n\nRetryError                                Traceback (most recent call last)\n/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py in iter(self, retry_state)\n    324             if self.reraise:\n    325                 raise retry_exc.reraise()\n--> 326             raise retry_exc from fut.exception()\n    327 \n    328         if self.wait:\n\nRetryError: RetryError[<Future at 0x794b5057a590 state=finished raised Exception>]\n```", "```py\nimport random\n\nclass ProgressLog:\n    def __init__(self, total):\n        self.total = total\n        self.done = 0\n\n    def increment(self):\n        self.done = self.done + 1\n\n    def __repr__(self):\n        return f\"Done runs {self.done}/{self.total}.\"\n\n@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(2), before_sleep=print, retry_error_callback=lambda _: None)\nasync def get_completion(content, session, semaphore, progress_log):\n    async with semaphore:\n\n        #await asyncio.sleep(1)\n        if random.random() < 0.7:\n            raise Exception(\"Random exception\")\n\n        async with session.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json={\n            \"model\": \"gpt-3.5-turbo\",\n            \"messages\": [{\"role\": \"user\", \"content\": content}],\n            \"temperature\": 0\n        }) as resp:\n\n            response_json = await resp.json()\n\n            progress_log.increment()\n            print(progress_log)\n\n            return response_json[\"choices\"][0]['message'][\"content\"]\n\nasync def get_completion_list(content_list, max_parallel_calls):\n    semaphore = asyncio.Semaphore(value=max_parallel_calls)\n    progress_log = ProgressLog(len(content_list))\n\n    async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(1)) as session:\n        return await asyncio.gather(*[get_completion(content, session, semaphore, progress_log) for content in content_list])\n\nstart_time = time.perf_counter()\ncompletion_list = await get_completion_list([\"ping\", \"pong\"]*5, 100)\nprint(\"Time elapsed: \", time.perf_counter() - start_time, \"seconds.\")\nprint(completion_list)\n```", "```py\n<RetryCallState 133364377805024: attempt #1; slept for 0.22; last result: failed (Exception Random exception)>\n<RetryCallState 133364377799456: attempt #1; slept for 0.53; last result: failed (Exception Random exception)>\n<RetryCallState 133364377801328: attempt #1; slept for 0.24; last result: failed (Exception Random exception)>\n<RetryCallState 133364377810208: attempt #1; slept for 0.38; last result: failed (Exception Random exception)>\n<RetryCallState 133364377801616: attempt #1; slept for 0.54; last result: failed (Exception Random exception)>\n<RetryCallState 133364377422096: attempt #1; slept for 0.59; last result: failed (Exception Random exception)>\n<RetryCallState 133364377430592: attempt #1; slept for 0.07; last result: failed (Exception Random exception)>\n<RetryCallState 133364377425648: attempt #1; slept for 0.05; last result: failed (Exception Random exception)>\nDone runs 1/10.\nDone runs 2/10.\nDone runs 3/10.\nTime elapsed:  2.6409040250000544 seconds.\n['Pong!', 'Ping!', None, None, None, None, None, 'Ping!', None, None]\n```", "```py\nclass ProgressLog:\n    def __init__(self, total):\n        self.total = total\n        self.done = 0\n\n    def increment(self):\n        self.done = self.done + 1\n\n    def __repr__(self):\n        return f\"Done runs {self.done}/{self.total}.\"\n\n@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(20), before_sleep=print, retry_error_callback=lambda _: None)\nasync def get_completion(content, session, semaphore, progress_log):\n    async with semaphore:\n\n        async with session.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json={\n            \"model\": \"gpt-3.5-turbo\",\n            \"messages\": [{\"role\": \"user\", \"content\": content}],\n            \"temperature\": 0\n        }) as resp:\n\n            response_json = await resp.json()\n\n            progress_log.increment()\n            print(progress_log)\n\n            return response_json[\"choices\"][0]['message'][\"content\"]\n\nasync def get_completion_list(content_list, max_parallel_calls):\n    semaphore = asyncio.Semaphore(value=max_parallel_calls)\n    progress_log = ProgressLog(len(content_list))\n\n    async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(10)) as session:\n        return await asyncio.gather(*[get_completion(content, session, semaphore, progress_log) for content in content_list])\n\nstart_time = time.perf_counter()\ncompletion_list = await get_completion_list([\"ping\", \"pong\"]*100, 100)\nprint(\"Time elapsed: \", time.perf_counter() - start_time, \"seconds.\")\n```", "```py\n<RetryCallState 133364375201936: attempt #1; slept for 0.57; last result: failed (TimeoutError )>\nTime elapsed:  12.705538211999738 seconds.\n```", "```py\nimport asyncio\nimport aiohttp\nfrom tenacity import (\n    retry,\n    stop_after_attempt,\n    wait_random_exponential,\n)\n\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n}\n\nclass ProgressLog:\n    def __init__(self, total):\n        self.total = total\n        self.done = 0\n\n    def increment(self):\n        self.done = self.done + 1\n\n    def __repr__(self):\n        return f\"Done runs {self.done}/{self.total}.\"\n\n@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(20), before_sleep=print, retry_error_callback=lambda _: None)\nasync def get_completion(content, session, semaphore, progress_log):\n    async with semaphore:\n\n        async with session.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json={\n            \"model\": \"gpt-3.5-turbo\",\n            \"messages\": [{\"role\": \"user\", \"content\": content}],\n            \"temperature\": 0\n        }) as resp:\n\n            response_json = await resp.json()\n\n            progress_log.increment()\n            print(progress_log)\n\n            return response_json[\"choices\"][0]['message'][\"content\"]\n\nasync def get_completion_list(content_list, max_parallel_calls, timeout):\n    semaphore = asyncio.Semaphore(value=max_parallel_calls)\n    progress_log = ProgressLog(len(content_list))\n\n    async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(timeout)) as session:\n        return await asyncio.gather(*[get_completion(content, session, semaphore, progress_log) for content in content_list])\n```"]