["```py\nimport cv2\nface_cascade = cv2.CascadeClassifier('./configs/haarcascade_frontalface_default.xml')\n\ndef haar(image):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n    print(len(faces) + \" total faces detected.\")\n    for (x, y, w, h) in faces:\n        print(f\"Face detected in the box {x} {y} {x+w} {y+h}\")\n```", "```py\nimport cv2\nfrom mtcnn import MTCNN\ndetector = MTCNN()\n\ndef mtcnn_detector(image):\n    faces = detector.detect_faces(image)\n    print(len(faces) + \" total faces detected.\")\n    for face in faces:\n        x, y, w, h = face['box']\n        print(f\"Face detected in the box {x} {y} {x+w} {y+h}\")\n```", "```py\nimport cv2\nfrom yoloface import face_analysis\nface=face_analysis()\n\ndef yolo_face_detection(image):\n    img,box,conf=face.face_detection(image, model='tiny')\n    print(len(box) + \" total faces detected.\")\n    for i in range(len(box)):\n        x, y, h, w = box[i]\n        print(f\"Face detected in the box {x} {y} {x+w} {y+h}\")\n```", "```py\nf = image[y:y + h, x:x + w]\nblurred_face = cv2.GaussianBlur(f, (99, 99), 15)  # You can adjust blur parameters\nimage[y:y + h, x:x + w] = blurred_face\n```", "```py\nf = image[y:y + h, x:x + w]\nf = cv2.resize(f, (10, 10), interpolation=cv2.INTER_NEAREST)\nimage[y:y + h, x:x + w] = cv2.resize(f, (w, h), interpolation=cv2.INTER_NEAREST)\n```", "```py\nimport cv2\nfrom yoloface import face_analysis\nface=face_analysis()\n\ndef yolo_face_detection_video(video_path, output_path, pixelate):\n    cap = cv2.VideoCapture(video_path)\n    if not cap.isOpened():\n        raise ValueError(\"Could not open video file\")\n\n    # Get video properties\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n    # Define the codec and create a VideoWriter object for the output video\n    fourcc = cv2.VideoWriter_fourcc(*'H264')\n    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        tm = time.time()\n        img, box, conf = face.face_detection(frame_arr=frame, frame_status=True, model='tiny')\n        print(pixelate)\n\n        for i in range(len(box)):\n            x, y, h, w = box[i]\n            if pixelate:\n                f = img[y:y + h, x:x + w]\n                f = cv2.resize(f, (10, 10), interpolation=cv2.INTER_NEAREST)\n                img[y:y + h, x:x + w] = cv2.resize(f, (w, h), interpolation=cv2.INTER_NEAREST)\n            else:\n                blurred_face = cv2.GaussianBlur(img[y:y + h, x:x + w], (99, 99), 30)  # You can adjust blur parameters\n                img[y:y + h, x:x + w] = blurred_face\n\n        print(time.time() - tm)\n        out.write(img)\n\n    cap.release()\n    out.release()\n    cv2.destroyAllWindows()\n```"]