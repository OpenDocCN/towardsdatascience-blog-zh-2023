# ç°ä»£æ•°æ®ä»“åº“

> åŸæ–‡ï¼š[`towardsdatascience.com/modern-data-warehousing-2b1b0486ce4a`](https://towardsdatascience.com/modern-data-warehousing-2b1b0486ce4a)

## å…ˆè¿›çš„æ•°æ®å¹³å°è®¾è®¡

[](https://mshakhomirov.medium.com/?source=post_page-----2b1b0486ce4a--------------------------------)![ğŸ’¡Mike Shakhomirov](https://mshakhomirov.medium.com/?source=post_page-----2b1b0486ce4a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2b1b0486ce4a--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----2b1b0486ce4a--------------------------------) [ğŸ’¡Mike Shakhomirov](https://mshakhomirov.medium.com/?source=post_page-----2b1b0486ce4a--------------------------------)

Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2b1b0486ce4a--------------------------------) Â·12 åˆ†é’Ÿé˜…è¯»Â·2023 å¹´ 12 æœˆ 16 æ—¥

--

![](img/61b0eba3203a5c89ddf3b0bd67553f9a.png)

å›¾ç‰‡ç”± [Nubelson Fernandes](https://unsplash.com/@nublson?utm_source=medium&utm_medium=referral) æä¾›ï¼Œæ¥æºäº [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

åœ¨è¿™ä¸ªæ•…äº‹ä¸­ï¼Œæˆ‘å°†å°è¯•é˜æ˜ç°ä»£æ•°æ®ä»“åº“è§£å†³æ–¹æ¡ˆï¼ˆDWHï¼‰ç›¸å¯¹äºå…¶ä»–æ•°æ®å¹³å°æ¶æ„ç±»å‹çš„å¥½å¤„ã€‚æˆ‘æ•¢è¯´ï¼Œç›®å‰ DWH æ˜¯æ•°æ®å·¥ç¨‹å¸ˆä¸­æœ€å—æ¬¢è¿çš„å¹³å°ã€‚ä¸å…¶ä»–è§£å†³æ–¹æ¡ˆç±»å‹ç›¸æ¯”ï¼Œå®ƒæä¾›äº†å®è´µçš„å¥½å¤„ï¼Œä½†ä¹Ÿæœ‰ä¸€äº›ä¼—æ‰€å‘¨çŸ¥çš„å±€é™æ€§ã€‚æƒ³å­¦ä¹ æ•°æ®å·¥ç¨‹å—ï¼Ÿè¿™ä¸ªæ•…äº‹æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ï¼Œå› ä¸ºå®ƒè§£é‡Šäº†æ•°æ®å·¥ç¨‹çš„æ ¸å¿ƒâ€”â€”æ¶æ„å›¾ä¸­å¿ƒçš„ DWH è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬å°†çœ‹çœ‹å¸‚åœºä¸Šä¸åŒ DWH çš„æ•°æ®å¦‚ä½•è¢«æ‘„å–å’Œè½¬æ¢ã€‚

æˆ‘ä¹Ÿå¸Œæœ›èƒ½ä¸ç»éªŒä¸°å¯Œçš„ç”¨æˆ·å±•å¼€è®¨è®ºã€‚äº†è§£ä½ çš„æ„è§å¹¶å¬å¬ä½ å¯¹æ­¤è¯é¢˜çš„çœ‹æ³•å°†éå¸¸æ£’ã€‚

## æ•°æ®ä»“åº“çš„å…³é”®ç‰¹æ€§

æ— æœåŠ¡å™¨çš„åˆ†å¸ƒå¼ SQL å¼•æ“ï¼ˆBigQueryã€Snowflakeã€Redshiftã€Microsoft Azure Synapseã€Teradataï¼‰å°±æ˜¯æˆ‘ä»¬æ‰€ç§°çš„ç°ä»£æ•°æ®ä»“åº“ï¼ˆDWHï¼‰ã€‚è¿™æ˜¯ä¸€ç§ä»¥ SQL ä¸ºä¸»çš„æ•°æ®æ¶æ„ [1]ï¼Œæ•°æ®å­˜å‚¨åœ¨æ•°æ®ä»“åº“ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨éè§„èŒƒåŒ–æ˜Ÿå‹æ¨¡å¼ [2] æ•°æ®é›†çš„æ‰€æœ‰ä¼˜ç‚¹ï¼Œå› ä¸ºå¤§å¤šæ•°ç°ä»£æ•°æ®ä»“åº“éƒ½æ˜¯åˆ†å¸ƒå¼çš„ï¼Œæ‰©å±•æ€§è‰¯å¥½ï¼Œè¿™æ„å‘³ç€æ— éœ€æ‹…å¿ƒè¡¨çš„é”®å’Œç´¢å¼•ã€‚å®ƒéå¸¸é€‚åˆå¯¹å¤§æ•°æ®è¿›è¡Œå³å¸­åˆ†ææŸ¥è¯¢ã€‚

[](/data-platform-architecture-types-f255ac6e0b7?source=post_page-----2b1b0486ce4a--------------------------------) ## æ•°æ®å¹³å°æ¶æ„ç±»å‹

### å®ƒåœ¨å¤šå¤§ç¨‹åº¦ä¸Šæ»¡è¶³äº†ä½ çš„ä¸šåŠ¡éœ€æ±‚ï¼Ÿé€‰æ‹©çš„å›°å¢ƒã€‚

towardsdatascience.com

å¤§å¤šæ•°ç°ä»£æ•°æ®ä»“åº“è§£å†³æ–¹æ¡ˆå¯ä»¥å¤„ç†ç»“æ„åŒ–å’Œéç»“æ„åŒ–æ•°æ®ï¼Œå¹¶ä¸”å¯¹æ‹¥æœ‰è‰¯å¥½ SQL æŠ€èƒ½çš„æ•°æ®åˆ†æå¸ˆéå¸¸æ–¹ä¾¿ã€‚

![](img/cc3e052dadb4fa0eb1d7d46cfd146875.png)

DWH æ•°æ®ç”Ÿå‘½å‘¨æœŸã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚

ç°ä»£æ•°æ®ä»“åº“å¯ä»¥è½»æ¾ä¸å•†ä¸šæ™ºèƒ½è§£å†³æ–¹æ¡ˆé›†æˆï¼Œå¦‚ Lookerã€Tableauã€Sisense å’Œ Modeï¼Œå®ƒä»¬ä½¿ç”¨ ANSI-SQL å¤„ç†æ•°æ®ã€‚åœ¨ä¸‹é¢çš„å›¾ç¤ºä¸­ï¼Œæˆ‘è¯•å›¾æ˜ å°„ä¸€ä¸ªå¸¸è§çš„æ•°æ®è½¬æ¢è¿‡ç¨‹åŠä½¿ç”¨çš„å·¥å…·ï¼ˆå½“ç„¶è¿™ä¸æ˜¯å®Œæ•´çš„åˆ—è¡¨ï¼‰ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ° DWH åœ¨ä¸­é—´ã€‚

![](img/18cc03801d2c651426977bc6c4f2c68a.png)

å…¸å‹çš„æ•°æ®æ—…ç¨‹åŠä½¿ç”¨çš„å·¥å…·ã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚

> æ•°æ®ä»“åº“*å¹¶ä¸è®¾è®¡*ç”¨äºå­˜å‚¨éç»“æ„åŒ–æ•°æ®ï¼Œå¦‚å›¾åƒã€è§†é¢‘æˆ–æ–‡æ¡£ã€‚

ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä¼šå¸Œæœ›ä½¿ç”¨æ•°æ®æ¹–ã€‚

## æ•°æ®ä»“åº“ä¸æ•°æ®åº“ï¼šæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

æ•°æ®ä»“åº“å…·æœ‰åˆ—å¼æ•°æ®ç»“æ„ï¼Œä¸è®¸å¤š RDS ç›¸åŒï¼Œå®ƒæ˜¯å…³ç³»å‹çš„ã€‚æ•°æ®è¢«ç»„ç»‡æˆè¡¨æ ¼ã€è¡Œå’Œåˆ—ã€‚ç„¶è€Œï¼Œåœ¨ RDS ä¸­ï¼Œæ•°æ®æ˜¯æŒ‰è¡Œç»„ç»‡å’Œå­˜å‚¨çš„ï¼Œè€Œæ•°æ®ä»“åº“ä¸­çš„æ•°æ®åˆ™æ˜¯æŒ‰åˆ—å­˜å‚¨çš„ã€‚åè€…æ›´å¥½åœ°æ”¯æŒåœ¨çº¿åˆ†æå¤„ç†ï¼ˆOLAPï¼‰ï¼Œè€Œ RDS åªèƒ½æä¾›åœ¨çº¿äº‹åŠ¡å¤„ç†ï¼ˆOLTPï¼‰ã€‚RDS ç¡®å®æ›´åŠ é¢å‘äº‹åŠ¡ã€‚ä¸€äº›ç°ä»£çš„æ•°æ®ä»“åº“è§£å†³æ–¹æ¡ˆå¯ä»¥åŒæ—¶æä¾›è¿™ä¸¤ç§æ•°æ®å¤„ç†æ–¹æ³•ã€‚ä¾‹å¦‚ï¼ŒAWS Redshift æ”¯æŒæ•°æ®ä»“åº“å’Œæ•°æ®æ¹–æ–¹æ³•ï¼Œä½¿å…¶èƒ½å¤Ÿè®¿é—®å’Œåˆ†æå¤§é‡æ•°æ®ã€‚

å…³ç³»å‹æ•°æ®åº“ï¼ˆ**RDS**ï¼‰å°†æ•°æ®å­˜å‚¨åœ¨ä¸€ä¸ªåŸºäºè¡Œçš„è¡¨æ ¼ä¸­ï¼Œåˆ—è¿æ¥ç›¸å…³çš„æ•°æ®å…ƒç´ ã€‚å®ƒçš„è®¾è®¡å’Œä¼˜åŒ–æ˜¯ä¸ºäº†å¿«é€Ÿæå–å½“å‰æ•°æ®ã€‚æµè¡Œçš„å…³ç³»å‹æ•°æ®åº“æœ‰***PostgreSQLã€MySQLã€Microsoft SQL Server å’Œ Oracleã€‚*** RDBMS æ˜¯ä¸€ä¸ªå…³ç³»å‹æ•°æ®åº“ç®¡ç†ç³»ç»Ÿï¼Œå¸®åŠ©ç®¡ç†æ•°æ®åº“ã€‚

**NoSQL** æ•°æ®åº“æ”¯æŒ**ä»…ç®€å•äº‹åŠ¡**ï¼Œè€Œå…³ç³»å‹æ•°æ®åº“è¿˜æ”¯æŒå¤æ‚äº‹åŠ¡åŠè¿æ¥æ“ä½œã€‚NoSQL æ•°æ®åº“ç”¨äºå¤„ç†é«˜é€Ÿåˆ°è¾¾çš„æ•°æ®ã€‚æµè¡Œçš„ NoSQL æ•°æ®åº“æœ‰ MongoDB å’Œ CouchDBï¼ˆæ–‡æ¡£æ•°æ®åº“ï¼‰ï¼ŒRedis å’Œ DynamoDBï¼ˆé”®å€¼æ•°æ®åº“ï¼‰ã€‚

æ•°æ®ä»“åº“ä¸»è¦ç”¨äºæ•°æ®åˆ†æï¼ŒåŒ…æ‹¬å¤§é‡çš„å†å²æ•°æ®ã€‚ä½¿ç”¨æ•°æ®ä»“åº“éœ€è¦ç”¨æˆ·**æå‰**åˆ›å»ºä¸€ä¸ªé¢„å®šä¹‰çš„ã€å›ºå®šçš„æ¨¡å¼ï¼Œè¿™æœ‰åŠ©äºæ•°æ®åˆ†æã€‚åœ¨å¤„ç†æ•°æ®ä»“åº“æ—¶ï¼Œè¡¨æ ¼å¿…é¡»ç®€å•ï¼ˆå»è§„èŒƒåŒ–ï¼‰ï¼Œä»¥ä¾¿è®¡ç®—å¤§é‡æ•°æ®ã€‚ç”±äº RDS æ•°æ®åº“è¡¨å’Œè¿æ¥æ˜¯è§„èŒƒåŒ–çš„ï¼Œæ‰€ä»¥å®ƒä»¬æ¯”è¾ƒå¤æ‚ã€‚å› æ­¤ï¼Œä¼ ç»Ÿæ•°æ®åº“å’Œæ•°æ®ä»“åº“ä¹‹é—´çš„ä¸»è¦åŒºåˆ«åœ¨äºï¼Œä¼ ç»Ÿæ•°æ®åº“çš„è®¾è®¡å’Œä¼˜åŒ–æ˜¯ä¸ºäº†è®°å½•æ•°æ®ï¼Œè€Œæ•°æ®ä»“åº“çš„è®¾è®¡å’Œä¼˜åŒ–åˆ™æ˜¯ä¸ºäº†å“åº”åˆ†æéœ€æ±‚ã€‚

RDS å­˜å‚¨åº”ç”¨ç¨‹åºæ‰€éœ€çš„å½“å‰æ•°æ®ã€‚åœ¨è¿è¡Œåº”ç”¨ç¨‹åºæ—¶ï¼Œå½“éœ€è¦å¿«é€Ÿè·å–ä¸€äº›å½“å‰æ•°æ®æ—¶ï¼Œå®ƒéå¸¸æœ‰ç”¨ã€‚

## æ•°æ®ä»“åº“ä¸æ•°æ®æ¹–

æ•°æ®æ¹–æ˜¯å­˜å‚¨å¤§é‡éç»“æ„åŒ–æ•°æ®ï¼ˆå¦‚å›¾åƒã€è§†é¢‘å’Œæ–‡æ¡£ï¼‰ä»¥åŠç»“æ„åŒ–æ•°æ®ï¼ˆå¦‚ JSONã€CSVã€PARQUET å’Œ AVRO [3]ï¼‰çš„ç†æƒ³å­˜å‚¨è§£å†³æ–¹æ¡ˆã€‚

## å¤§æ•°æ®æ–‡ä»¶æ ¼å¼è§£æ

### Parquet vs ORC vs AVRO vs JSONã€‚é€‰æ‹©å“ªä¸ªä»¥åŠå¦‚ä½•ä½¿ç”¨å®ƒä»¬ï¼Ÿ

[towardsdatascience.com

ç„¶è€Œï¼Œä»æ•°æ®æ¹–ä¸­æå–æ´å¯Ÿ**é€šå¸¸éœ€è¦ç¼–ç æŠ€èƒ½**ï¼Œå› ä¸ºæ•°æ®æ¹–æ²¡æœ‰åƒæ•°æ®ä»“åº“é‚£æ ·å†…ç½®çš„åˆ†ææˆ–æŸ¥è¯¢èƒ½åŠ›ã€‚ç”¨æˆ·éœ€è¦åˆ©ç”¨ç¼–ç¨‹è¯­è¨€å¦‚ Pythonã€JAVAã€Scala æˆ– PySpark æ¥è®¿é—®ã€å¤„ç†å’Œåˆ†æå­˜å‚¨åœ¨æ•°æ®æ¹–ä¸­çš„æ•°æ®ã€‚

> å½“æ•°æ®æ¹–ç”¨æˆ·æ‹¥æœ‰è‰¯å¥½çš„ç¼–ç æŠ€èƒ½æ—¶ï¼Œä¼šå‡ºç°æƒŠäººçš„å¥½å¤„

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ•°æ®æ¹–æ¶æ„å¯ä»¥æä¾›æ•°æ®å¤„ç†çš„æœ€é«˜çµæ´»æ€§ã€‚ç”¨æˆ·åªéœ€äº†è§£å¦‚ä½•ç¼–ç å³å¯åº”ç”¨ç›¸å…³çš„æ•°æ®è½¬æ¢ã€‚

> ç„¶è€Œï¼Œé€šå¸¸æƒ…å†µä¸‹ï¼ŒSQL ä¼˜å…ˆçš„è§£å†³æ–¹æ¡ˆå˜å¾—æ›´æœ‰ç”¨ã€‚

## æ•°æ®ä»“åº“çš„ä¸»è¦ä¼˜ç‚¹

ä½œä¸ºç”¨äº SQL æŸ¥è¯¢å’ŒæŠ¥å‘Šçš„é›†ä¸­æ•°æ®ä»“åº“ï¼Œæ•°æ®ä»“åº“å…·æœ‰è®¸å¤šç±»ä¼¼äºä¼ ç»Ÿå…³ç³»æ•°æ®åº“è§£å†³æ–¹æ¡ˆçš„ç‰¹å¾ã€‚æ•°æ®ä»“åº“çš„ä¸€äº›ä¸»è¦ä¼˜ç‚¹åŒ…æ‹¬æ›´å¥½çš„å¯æ‰©å±•æ€§ï¼ˆç›¸æ¯”äº RDSï¼‰ã€æ›´å¥½çš„æ•°æ®æ²»ç†ï¼ˆç›¸æ¯”äºæ•°æ®æ¹–å’Œæ•°æ®ç½‘æ ¼æ¶æ„ï¼‰ã€å¢å¼ºçš„å•†ä¸šæ™ºèƒ½å’Œæ”¹å–„çš„æ•°æ®è´¨é‡ [4]

## è‡ªåŠ¨åŒ–é‚®ä»¶å’Œæ•°æ®è´¨é‡æ£€æŸ¥

### æ•°æ®ä»“åº“æŒ‡å—ï¼Œå¸®åŠ©é€šè¿‡å®šæœŸé‚®ä»¶è·å¾—æ›´å¥½ã€æ›´æ¸…æ´çš„æ•°æ®

[towardsdatascience.com

**æ›´å¥½çš„æ•°æ®æ²»ç†ï¼š**å¸‚åœºä¸Šçš„è®¸å¤šæ•°æ®ä»“åº“è§£å†³æ–¹æ¡ˆæä¾›äº†åˆ—çº§è®¿é—®æ§åˆ¶å’Œè¡Œçº§è®¿é—®æ§åˆ¶ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥ä¸ºç”¨æˆ·å®šä¹‰ç»†ç²’åº¦çš„æ§åˆ¶ã€‚ä¾‹å¦‚ï¼Œåœ¨ BigQuery ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥é™åˆ¶è®¿é—®æˆ–é®è”½ä»»ä½•å¯¹ä¸šåŠ¡æˆ–ä¸ªäººæ•æ„Ÿçš„åˆ— [5]ï¼š

![](img/0e68e73ee8db6b61e7d7920a691167f1.png)

ä½¿ç”¨ç­–ç•¥æ ‡ç­¾çš„æ•°æ®é®è”½ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨åŸºç¡€è®¾æ–½å³ä»£ç ï¼ˆIaCï¼‰æ¥å®šä¹‰è¿™äº›ç­–ç•¥ï¼Œè¿™ç±»ä¼¼äºæˆ‘ä»¬åœ¨éƒ¨ç½²åŸºç¡€è®¾æ–½èµ„æºæ—¶æ‰€åšçš„ [6]ã€‚åœ¨ä¸‹é¢çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸å¹³å°æ— å…³çš„ Terraform æ¥å®šä¹‰æ•°æ®é›†è®¿é—®æƒé™ï¼š

```py
resource "google_bigquery_dataset_access" "access" {
  dataset_id    = google_bigquery_dataset.dataset.dataset_id
  role          = "OWNER"
  user_by_email = google_service_account.bqowner.email
}

resource "google_bigquery_dataset" "dataset" {
  dataset_id = "my_dataset"
}

resource "google_service_account" "bqowner" {
  account_id = "bqowner"
} 
```

**æ›´å¥½çš„åä½œï¼š** ç°ä»£æ•°æ®ä»“åº“è§£å†³æ–¹æ¡ˆæä¾›åä½œåŠŸèƒ½ã€‚æœ‰æ•ˆçš„å†³ç­–é€šå¸¸éœ€è¦ç»„ç»‡å†…éƒ¨å¤šä¸ªäººå‘˜ï¼ˆå¦‚æ•°æ®åˆ†æå¸ˆã€å¸‚åœºè¥é”€å›¢é˜Ÿã€ç®¡ç†å±‚ç­‰ï¼‰çš„è¾“å…¥ï¼Œä»¥åŠå¤šä¸ªæ•°æ®æ¥æºã€‚ç¡®å®ï¼Œ**å°†æ•æ·æ–¹æ³•åº”ç”¨äºä»»ä½•** **æ•°æ®è½¬æ¢å¼€å‘** æ˜¯è‡³å…³é‡è¦çš„ã€‚æˆ‘ç§°ä¹‹ä¸ºæœ€ä½³å®è·µã€‚

> åä½œæ˜¯å…³é”®

æ•°æ®ä»“åº“è§£å†³æ–¹æ¡ˆè®¾è®¡ä½¿å¾—é€šè¿‡å°†å¤§å‹æ•°æ®é¡¹ç›®æ‹†åˆ†æˆæ›´å°çš„éƒ¨åˆ†æ¥äº¤ä»˜è¿™äº›é¡¹ç›®å˜å¾—æ›´å®¹æ˜“ã€‚ä»æˆ‘æ‰€çœ‹åˆ°çš„ï¼Œç»„ç»‡å€¾å‘äºæ‘†è„±æ•°æ®é¡¹ç›®è®¾è®¡å’Œäº¤ä»˜ä¸­ç¹ççš„ç€‘å¸ƒå¼æ–¹æ³•ã€‚ç°åœ¨æˆ‘ä»¬æ‹¥æœ‰ç°ä»£æ•°æ®ä»“åº“è§£å†³æ–¹æ¡ˆæä¾›çš„å•ä¸€æ•°æ®é›†æˆå±‚ï¼Œè¿™æœ‰åŠ©äºæ›´å¿«åœ°éƒ¨ç½²å¢é‡æ¨¡å‹æ›´æ–°ï¼Œå¹¶æ›´é¢‘ç¹åœ°æä¾›ä¸šåŠ¡æ´å¯Ÿã€‚

**å¯æ‰©å±•æ€§**ï¼šæ•°æ®ä»“åº“è¢«è®¾è®¡ä¸ºèƒ½å¤Ÿå¾ˆå¥½åœ°æ‰©å±•ï¼Œä»¥å¤„ç†å¤§é‡æ•°æ®ã€‚åœ¨å¿…è¦æ—¶æ‰©å±•æ•°æ®ç®¡é“ä»¥æ»¡è¶³ä¸æ–­å¢é•¿çš„ä¸šåŠ¡éœ€æ±‚è‡³å…³é‡è¦ã€‚å®ƒè¿˜å¿…é¡»èƒ½å¤Ÿåœ¨å•ä¸€ç³»ç»Ÿä¸­ä»¥è§„æ¨¡åŒ–æ–¹å¼è¿è¡Œå¹¶å‘å·¥ä½œè´Ÿè½½ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªéå¸¸å¸¸è§çš„æ•°æ®ä»“åº“ç—›ç‚¹æ˜¯ç”¨æˆ·æŸ¥è¯¢çš„å¹¶å‘æ€§ã€‚å½“æ•°æ®ä»“åº“è§£å†³æ–¹æ¡ˆåªå…è®¸ä¸€å®šæ•°é‡çš„å¹¶å‘ç”¨æˆ·æŸ¥è¯¢ï¼ˆé€šå¸¸ä¸è¶…è¿‡ 50ï¼‰æ—¶ï¼Œå°±ä¼šå‡ºç°è¿™ç§æƒ…å†µã€‚è®¸å¤šç°ä»£æ•°æ®ä»“åº“å¯ä»¥æä¾›å¸¦æœ‰åˆ†å¸ƒå¼ç‰©ç†èŠ‚ç‚¹çš„è™šæ‹Ÿé›†ç¾¤æ¥è§£å†³è¿™ä¸ªé—®é¢˜[11]ã€‚

> ç¡®å®ï¼Œåœ¨è®¸å¤šåœºæ™¯ä¸­ï¼Œå…·æœ‰è‡ªåŠ¨æ‰©å±•çš„åˆ†å¸ƒå¼è®¡ç®—é›†ç¾¤å¸®åŠ©å¾ˆå¤§ã€‚

ä¾‹å¦‚ï¼Œè€ƒè™‘ä»¥ä¸‹ Snowflake çš„ SQL å¤šé›†ç¾¤è®¾ç½®ï¼š

![](img/2e8e059c087780bbd9a5f28743f45632.png)

ä½¿ç”¨ Snowflake çš„å¤šé›†ç¾¤æ•°æ®ä»“åº“ã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚

**æ”¹è¿›çš„æ•°æ®åŠ è½½ï¼š** æ•°æ®ä»“åº“è§£å†³æ–¹æ¡ˆå„ä¸ç›¸åŒã€‚å¯¹äºå…¶ä¸­ä¸€äº›ï¼Œæ•°æ®æ‘„å–æ˜¯ä¸€ä¸ªå¾®ä¸è¶³é“çš„ä»»åŠ¡ï¼ˆå¦‚ Snowflakeï¼‰ï¼Œè€Œå…¶ä»–çš„åˆ™åœ¨å¤„ç†åˆ†åŒºæ—¶æä¾›äº†æ›´å¤§çš„çµæ´»æ€§ï¼ˆå¦‚ BigQueryï¼‰ã€‚è€ƒè™‘ä¸‹é¢çš„ Snowflake æ•°æ®ä»“åº“ä¸­çš„æ•°æ®åŠ è½½ç¤ºä¾‹ã€‚æˆ‘ä»¬å‡è®¾æ‰€æœ‰æ•°æ®æ–‡ä»¶éƒ½å­˜å‚¨åœ¨ AWS S3 å­˜å‚¨æ¡¶ä¸­ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```py
[{

      "id": 1,
      "price": "75836"
},
{
     "id": 2,
      "price": "92567"
}
{
     "id": 3,
      "price": "89921"
}]
```

ç°åœ¨æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ SQL æ¥åŠ è½½å®ƒï¼

```py
/* Create a JSON file format that strips the outer array. */

CREATE OR REPLACE FILE FORMAT json_format
  TYPE = 'JSON'
  STRIP_OUTER_ARRAY = TRUE;

/* Create a target table for the JSON data. */

CREATE OR REPLACE TABLE sales (src VARIANT);

/* Copy the JSON data into the target table. */

COPY INTO sales
  FROM s3://mybucket/data/files
  CREDENTIALS=(AWS_KEY_ID='$AWS_ACCESS_KEY_ID' AWS_SECRET_KEY='$AWS_SECRET_ACCESS_KEY')
  ENCRYPTION=(MASTER_KEY = 'eSx...')
  FILE_FORMAT = (FORMAT_NAME = my_csv_format);

SELECT * FROM sales;
```

> è¿™å°±æ˜¯ä¸ºä»€ä¹ˆ Snowflake åœ¨æ•°æ®åˆ†æå¸ˆå’Œæ— ä»£ç ç”¨æˆ·ä¸­å¦‚æ­¤å—æ¬¢è¿çš„åŸå› ã€‚

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæ•°æ®ä»“åº“çš„æ•°æ®æ‘„å–ä¾‹ç¨‹å¤„ç†äº†æ‰€æœ‰å†…å®¹ï¼ŒåŒ…æ‹¬é€šè¿‡å»é™¤å¤–éƒ¨æ•°ç»„æ¥å¤„ç†æ•°æ®æ ¼å¼ï¼Œå³ [{},{},{}] -> {},{},{}ã€‚

ä¾‹å¦‚ï¼Œåœ¨ BigQuery ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šæƒ³åˆ›å»ºä¸€ä¸ªæ•°æ®åŠ è½½åº”ç”¨ç¨‹åºæ¥åšåŒæ ·çš„äº‹æƒ…ã€‚è€ƒè™‘ä¸‹é¢çš„ Python ä»£ç [14]ï¼š

```py
import io
import json

def etl(item):
    return json.dumps(item)

# Text file loaded as a blob
blob = """
        [
{"id":"1","first_name":"John"},
{"id":"2","first_name":"Mary"}
]
"""
json_data = json.loads(blob)
data_str = u"\n".join(etl(item) for item in json_data)

print(data_str)
data_file = io.BytesIO(data_str.encode())

# This data file is ready for BigQuery as Newline delimited JSON
print(data_file)
```

[](/python-for-data-engineers-f3d5db59b6dd?source=post_page-----2b1b0486ce4a--------------------------------) ## Python for Data Engineers

### é¢å‘åˆå­¦è€…çš„é«˜çº§ ETL æŠ€æœ¯

towardsdatascience.com

åœ¨ç”¨æˆ·çš„ç¼–ç¨‹æŠ€èƒ½æ–¹é¢ï¼ŒBigQuery çœ‹èµ·æ¥ç¨æ˜¾è¦æ±‚è¾ƒé«˜ã€‚

> å¯ä»¥åˆç†åœ°è®¤ä¸ºï¼Œäº†è§£åº•å±‚å·¥ä½œåŸç†å¾€å¾€åœ¨é•¿æœŸå†…æ›´å…·æˆæœ¬æ•ˆç›Šã€‚

ç¡®å®ï¼ŒBigQuery æä¾›äº†æ›´ç²¾ç»†çš„åˆ†åŒºæ§åˆ¶ï¼Œè¿™å¯èƒ½åœ¨å¤„ç† DWH ä¸­çš„æ•°æ®æ—¶å¸¦æ¥æ›´å¤§çš„èŠ‚çœã€‚è€ƒè™‘è¿™ä¸ªæ•°æ®åŠ è½½çš„ä¾‹å­ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰åˆ†åŒºï¼ˆDAYã€MONTHã€RANGEï¼‰ï¼š

```py
"""
This function will check if a table exists, otherwise create it.
Will also check if tableSchema contains partition_field and
if exists will use it to create a table.
"""
def _check_if_table_exists(tableData):
    # get table_id reference
    tableName = tableData.get('name')
    tableSchema = tableData.get('schema')
    tableDataset = tableData.get('dataset_id')

    # Check if dataset exists, if not then create
    _check_if_dataset_exists(tableDataset)

    table_id = client.dataset(tableDataset).table(tableName)
    # check if table exists, otherwise create
    try:
        client.get_table(table_id)
    except Exception:
        logging.warn('Creating table: %s' % (tableName))
        schema = create_schema_from_yaml(tableSchema)
        table = bigquery.Table(table_id, schema=schema)
        # Check if partition_field exists in schema definition and if so use it to create the table:
        if (tableData.get('partition_field')):
            table.time_partitioning = bigquery.TimePartitioning(
                type_=bigquery.TimePartitioningType.DAY,
                field=tableData.get('partition_field'), #"date",  # name of column to use for partitioning

            )  # 90 days
        else:
            table.time_partitioning = bigquery.TimePartitioning(
                type_=bigquery.TimePartitioningType.DAY,
            )
        table = client.create_table(table)
        print("Created table {}.{}.{}".format(table.project, table.dataset_id, table.table_id))

# Creates schema definition in BigQuery format using schemas.yaml
# - name: test_table_json
#   alt_name: test_table_json
#   load_method: _load_table_from_json
#   dataset_id: source
#   size: small
#   format: SRC
#   schema:
#     - name: "src"
#       type: "STRING"
#       mode: "NULLABLE"
#   disabled: False
def create_schema_from_yaml(table_schema):
    schema = []
    for column in table_schema:

        schemaField = bigquery.SchemaField(column['name'], column['type'], column['mode'])

        schema.append(schemaField)

        if column['type'] == 'RECORD':
            schemaField._fields = create_schema_from_yaml(column['fields'])
    return schema
```

> å½“æˆ‘ä»¬æœ‰ä¸€ä¸ªå¸¦æœ‰æ—¥æœŸ/æœˆä»½ç»´åº¦çš„æ•°æ®æ¨¡å‹æ—¶ï¼Œè¿™å˜å¾—éå¸¸æœ‰ç”¨ï¼Œå¹¶ä¸”é€šå¸¸èƒ½èŠ‚çœå¾ˆå¤šé’±ã€‚

è¿™è¿™æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡æ•°æ®åŠ è½½çš„ä¾‹å­ã€‚**å¦å¤–**ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªæ•°æ®ç®¡é“ï¼Œä½¿æ•°æ®æŒç»­è¢«æ‘„å–ã€‚è¿™è¢«ç§°ä¸ºæ•°æ®æµ [12]ã€‚

[](/streaming-in-data-engineering-2bb2b9b3b603?source=post_page-----2b1b0486ce4a--------------------------------) ## æ•°æ®å·¥ç¨‹ä¸­çš„æµå¼å¤„ç†

### æµå¼æ•°æ®ç®¡é“å’Œå®æ—¶åˆ†æ

towardsdatascience.com

Snowflake æœ‰ä¸€ä¸ªæ–¹ä¾¿çš„ Kafka è¿æ¥å™¨ [13]ï¼Œç®€åŒ–äº†æµå¼æ•°æ®ç®¡é“ï¼Œå¹¶è¿æ¥åˆ° Kafka æœåŠ¡å™¨ï¼Œä»¥ä»ä¸»é¢˜ä¸­æŒç»­æ‹‰å–æ•°æ®ã€‚

**æ”¹è¿›çš„å•†ä¸šæ™ºèƒ½**ï¼šè®¸å¤šå…¬å¸ä»å„ç§æ¥æºï¼ˆä¾‹å¦‚å¤©æ°”ã€æ”¶å…¥ã€æ”¯ä»˜ã€å®¢æˆ·ä¿¡æ¯ã€è¶‹åŠ¿ã€ä¾›åº”å•†ä¿¡æ¯ç­‰ï¼‰æ”¶é›†å¤§é‡æ•°æ®ã€‚æ•°æ®é‡åºå¤§å¯èƒ½æ˜¯æ— ç”¨çš„ã€‚å°†è¿™äº›æ•°æ®å­˜å‚¨åœ¨å¤šä¸ªå¹³å°ä¸Šä¹Ÿå¯èƒ½å¾ˆæ˜‚è´µã€‚å› æ­¤ï¼ŒDWH ä½œä¸ºå•ä¸€çœŸå®æ¥æºä¼¼ä¹æ˜¯ BI ç®¡é“çš„é—®é¢˜è§£å†³è€…ï¼Œæ¯ä¸ªäººéƒ½å¯ä»¥è½»æ¾ç”Ÿæˆæ•°æ®æ´å¯Ÿã€‚è¯·å‚é˜…ä¸‹é¢çš„ Google Looker Studio é›†æˆã€‚å®ƒé€‚ç”¨äºç°ä»£ DWH è§£å†³æ–¹æ¡ˆï¼Œè€Œä¸”è¿™äº›è§£å†³æ–¹æ¡ˆåŸºæœ¬ä¸Šéƒ½æ˜¯å¸‚åœºé¢†å¯¼è€…ã€‚

![](img/550d5f58c60aba1d313b40f1952cd9db.png)

Snowflake æ•°æ®è¿æ¥å™¨ã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚

![](img/e9e59e9fe9ed618e339bc331e23b826c.png)

AWS Redshift è¿æ¥å™¨ç”¨äº Looker Studioã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚

ä¾æ­¤ç±»æ¨â€¦â€¦ä¸€ä¸ªå…è´¹çš„ç¤¾åŒºå•†ä¸šæ™ºèƒ½ï¼ˆBIï¼‰å·¥å…·è¿æ¥äº†å¸‚åœºä¸Šæ‰€æœ‰ä¸»è¦çš„æ•°æ®ä»“åº“è§£å†³æ–¹æ¡ˆï¼Œå³ Redshiftã€Snowflakeã€BigQueryã€Databricks [7]ã€Galaxy [8] ç­‰ã€‚

![](img/679dc8acbc096112a6f794c1fe61bbcd.png)

Looker Studio æ•°æ®è¿æ¥å™¨ã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚

æ•°æ®ä»“åº“ä¸ºå•†ä¸šæ™ºèƒ½å·¥å…·å’Œåº”ç”¨ç¨‹åºæä¾›äº†ä¸€ä¸ªå¹³å°ï¼Œä»¥è®¿é—®å’Œåˆ†ææ•°æ®ã€‚è¿™ä½¿å¾—ä¼ä¸šå¯ä»¥æ ¹æ®æ•°æ®é©±åŠ¨çš„è§è§£åšå‡ºæ˜æ™ºçš„å†³ç­–ã€‚

**æ›´å¥½çš„äº§å“é›†æˆå’Œ DevOps ç”Ÿå‘½å‘¨æœŸ**ï¼šä¸€äº›äº§å“åœ¨æ•°æ®ç®¡é“çš„è®¾è®¡å’Œéƒ¨ç½²æ–¹é¢æ›´è¿›ä¸€æ­¥ã€‚å¯¹äº BI å¼€å‘è€…å’Œæ•°æ®å·¥ç¨‹å¸ˆæ¥è¯´ï¼Œå°†æ‰€æœ‰å†…å®¹ä¿å­˜åœ¨ Git ä¸­éå¸¸é‡è¦ã€‚å¯ç”¨è¿™ä¸€åŠŸèƒ½å¯¹æŒç»­é›†æˆè‡³å…³é‡è¦ [9]ã€‚æˆ‘ä¹‹å‰å†™è¿‡å…³äºå¦‚ä½•ä½¿ç”¨ IaC å·¥å…·å¦‚ AWS CloudFormation å’Œ Terraform éƒ¨ç½²æ•°æ®ç®¡é“èµ„æºçš„æ–‡ç« ï¼š

[](/continuous-integration-and-deployment-for-data-platforms-817bf1b6bed1?source=post_page-----2b1b0486ce4a--------------------------------) ## æ•°æ®å¹³å°çš„æŒç»­é›†æˆå’Œéƒ¨ç½²

### æ•°æ®å·¥ç¨‹å¸ˆå’Œ ML Ops çš„ CI/CD

towardsdatascience.com

> æƒ³è±¡ä¸€ä¸‹æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ CI/CD å·¥å…·éƒ¨ç½²æŠ¥å‘Šã€‚æ˜¯çš„ï¼Œæ²¡é”™ã€‚ä¸ä»…ä»…æ˜¯æ•°æ®ç®¡é“èµ„æºï¼Œè¿˜æœ‰ BI ä»ªè¡¨æ¿ã€‚

è¯·å‚é˜…ä¸‹é¢çš„ AWS CloudFormation æ¨¡æ¿ã€‚å®ƒéƒ¨ç½² AWS Quicksight æ•°æ®é›†å’ŒæŠ¥å‘Šåˆ†æï¼š

```py
AWSTemplateFormatVersion: 2010-09-09
Description: 'Automated deployment of QuickSight Assets.'

...

Resources:
...

 QSCFBuildQSDataSource:
    Type: Custom::QSCFBuildQSDataSource
    Properties:
      ServiceToken: !GetAtt QSCFBuildQuickSightResourcesLambdaCreator.Arn
      Name: !Join
        - ''
        - - QSCFBuildQSDataSource
          - !Ref Suffix
      CommandFile: QSCF-DataSource
      ResourceType: DataSource
      ResourceId: QSCF-DataSource

  QSCFBuildQSTheme:
    Type: Custom::QSCFBuildQSTheme
    Properties:
      ServiceToken: !GetAtt QSCFBuildQuickSightResourcesLambdaCreator.Arn
      Name: !Join
        - ''
        - - QSCFBuildQSTheme
          - !Ref Suffix
      CommandFile: QSCF-Theme
      ResourceType: Theme
      ResourceId: QSCF-Theme

  QSCFBuildQSDataSet:
    Type: Custom::QSCFBuildQSDataSet
    DependsOn: QSCFBuildQSDataSource
    Properties:
      ServiceToken: !GetAtt QSCFBuildQuickSightResourcesLambdaCreator.Arn
      Name: !Join
        - ''
        - - QSCFBuildQSDataSet
          - !Ref Suffix
      CommandFile: QSCF-DataSet
      ResourceType: DataSet
      ResourceId: QSCF-DataSet

  QSCFBuildQSDashboard:
    Type: Custom::QSCFBuildQSDashboard
    DependsOn:
      - QSCFBuildQSDataSet
      - QSCFBuildQSTheme
    Properties:
      ServiceToken: !GetAtt QSCFBuildQuickSightResourcesLambdaCreator.Arn
      Name: !Join
        - ''
        - - QSCFBuildQSDashboard
          - !Ref Suffix
      CommandFile: QSCF-Dashboard
      ResourceType: Dashboard
      ResourceId: QSCF-Dashboard

  QSCFBuildQSTemplate:
    Type: Custom::QSCFBuildQSTemplate
    Properties:
      ServiceToken: !GetAtt QSCFBuildQuickSightResourcesLambdaCreator.Arn
      Name: !Join
        - ''
        - - QSCFBuildQSTemplate
          - !Ref Suffix
      CommandFile: QSCF-Template
      ResourceType: Template
      ResourceId: QSCF-Template

  QSCFBuildQSAnalysis:
    Type: Custom::QSCFBuildQSAnalysis
    DependsOn:
      - QSCFBuildQSDataSet
      - QSCFBuildQSTheme
      - QSCFBuildQSTemplate
    Properties:
      ServiceToken: !GetAtt QSCFBuildQuickSightResourcesLambdaCreator.Arn
      Name: !Join
        - ''
        - - QSCFBuildQSAnalysis
          - !Ref Suffix
      CommandFile: QSCF-Analysis
      ResourceType: Analysis
      ResourceId: QSCF-Analysis
```

æˆ‘ä¹‹å‰å†™äº†ä¸€ç¯‡æ•™ç¨‹[10]ï¼Œè®²è¿°äº†å¦‚ä½•ä½¿ç”¨ AWS CloudFormation éƒ¨ç½²æµæ•°æ®ç®¡é“ã€‚åœ¨æˆ‘çœ‹æ¥ï¼Œå°† BI åŠŸèƒ½æ·»åŠ åˆ°å…¶ä¸­ä¼šä½¿å…¶æ›´å¥½ã€‚

[](/building-a-streaming-data-pipeline-with-redshift-serverless-and-kinesis-04e09d7e85b2?source=post_page-----2b1b0486ce4a--------------------------------) ## ä½¿ç”¨ Redshift Serverless å’Œ Kinesis æ„å»ºæµæ•°æ®ç®¡é“

### åˆå­¦è€…çš„ç«¯åˆ°ç«¯æ•™ç¨‹

towardsdatascience.com

## ç»“è®º

æ€»çš„æ¥è¯´ï¼Œæ•°æ®ä»“åº“æ˜¯æœ€å—æ¬¢è¿çš„æ•°æ®å¹³å°ä¹‹ä¸€ï¼Œå¯ä»¥å¸®åŠ©å…¬å¸ï¼ˆç‰¹åˆ«æ˜¯åœ¨ä¼ä¸šçº§åˆ«ï¼‰é€šè¿‡æä¾›å•ä¸€çš„çœŸå®æ•°æ®æºæ¥è·å¾—ç«äº‰ä¼˜åŠ¿ï¼Œä»è€Œè¿›è¡Œæ•°æ®é©±åŠ¨çš„å†³ç­–ã€‚ç°ä»£æ•°æ®ä»“åº“è§£å†³æ–¹æ¡ˆæœ‰åŠ©äºæ›´å¿«åœ°æä¾›æ•°æ®æ´å¯Ÿã€‚åœ¨å¿«é€Ÿå˜åŒ–çš„å•†ä¸šç¯å¢ƒä¸­ï¼Œå…¬å¸å¯ä»¥é€šè¿‡è‡ªåŠ¨åŒ–æŠ€æœ¯æ¿€æ´»è¿™äº›è§£å†³æ–¹æ¡ˆï¼Œä¸ºä¸šåŠ¡åˆ©ç›Šç›¸å…³è€…åˆ›é€ æ›´å¤§çš„ä»·å€¼ã€‚æ¯ç§è§£å†³æ–¹æ¡ˆéƒ½æä¾›äº†ä½¿å…¶ç‹¬ç‰¹çš„åŠŸèƒ½ã€‚ç„¶è€Œï¼Œå‡ ä¹æ¯ç§æƒ…å†µä¸‹éƒ½éœ€è¦è€ƒè™‘ä¸€äº›å› ç´ ã€‚æˆæœ¬æ•ˆç›Šã€æ•°æ®åˆ†åŒºã€æŸ¥è¯¢ç”¨æˆ·å¹¶å‘ã€æ•°æ®æ¹–å­˜å‚¨åŠç›¸å…³æˆæœ¬â€”â€”è¿™äº›ç—›ç‚¹éƒ½æ˜¯æœ‰æ•ˆçš„ã€‚æœ‰æ—¶ï¼Œå°†å†å²æ•°æ®å¸è½½åˆ°äº‘å­˜å‚¨æ¡£æ¡ˆä¸­ä»¥ä¼˜åŒ–æˆæœ¬å¯èƒ½æ˜¯æœ‰ç”¨çš„[15]ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä½¿ç”¨ Apache Iceberg è¡¨å¯èƒ½æœ‰åŠ©äºè§£å†³ç”¨æˆ·æŸ¥è¯¢å¹¶å‘é—®é¢˜[16]ã€‚

[](/introduction-to-apache-iceberg-tables-a791f1758009?source=post_page-----2b1b0486ce4a--------------------------------) ## Apache Iceberg è¡¨ä»‹ç»

### é€‰æ‹© Apache Iceberg ä½œä¸ºæ•°æ®æ¹–çš„å‡ ä¸ªä»¤äººä¿¡æœçš„ç†ç”±

towardsdatascience.com

åœ¨è®¾è®¡å’Œæ„å»ºå®Œç¾çš„æ•°æ®å¹³å°æ—¶ï¼Œæœ‰å‡ ä¸ªäº‹é¡¹éœ€è¦è€ƒè™‘ã€‚ä¸€äº›ç”¨æˆ·å¯èƒ½è®¤ä¸ºæœ€ä½³çš„æ•°æ®ä»“åº“æ˜¯æ¹–ä»“ï¼ˆDatabricksï¼‰ï¼Œä½†æœ€ç»ˆè¿™å–å†³äºæ•°æ®çš„å­˜å‚¨æ–¹å¼ä»¥åŠä½ å¯¹å†å²è®°å½•çš„ä¸šåŠ¡éœ€æ±‚ã€‚åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œä½œä¸ºæ‰€æœ‰åˆ©ç›Šç›¸å…³è€…çš„å•ä¸€çœŸå®æ•°æ®æºçš„æ•°æ®ä»“åº“è§£å†³æ–¹æ¡ˆå¯èƒ½æˆä¸ºæœ€ä½³é€‰æ‹©ã€‚ç»“åˆåˆé€‚çš„æ•°æ®å»ºæ¨¡å·¥å…·ï¼Œä½ å°†è·å¾—é€‚ç”¨äºå¤–éƒ¨æ•°æ®åˆ° BI æ•°æ®ç®¡é“çš„æ­£ç¡®å·¥å…·ã€‚

æˆ‘å¸Œæœ›ä½ è§‰å¾—è¿™äº›æƒ³æ³•æœ‰ç”¨ã€‚å®ƒä»¬åŸºäºæˆ‘ä¸ªäººçš„ç»éªŒå’Œè§‚å¯Ÿã€‚

## æ¨èé˜…è¯»

[1] [`medium.com/towards-data-science/data-platform-architecture-types-f255ac6e0b7`](https://medium.com/towards-data-science/data-platform-architecture-types-f255ac6e0b7)

[2] `towardsdatascience.com/data-modelling-for-data-engineers-93d058efa302`

[3] [`medium.com/towards-data-science/big-data-file-formats-explained-275876dc1fc9`](https://medium.com/towards-data-science/big-data-file-formats-explained-275876dc1fc9)

[4] `towardsdatascience.com/automated-emails-and-data-quality-checks-for-your-data-1de86ed47cf0`

[5] [`cloud.google.com/bigquery/docs/column-level-security-intro`](https://cloud.google.com/bigquery/docs/column-level-security-intro)

[6] [`registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_dataset_access`](https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_dataset_access)

[7] [`docs.databricks.com/en/partners/bi/looker.html`](https://docs.databricks.com/en/partners/bi/looker.html)

[8] [`docs.starburst.io/clients/looker.html`](https://docs.starburst.io/clients/looker.html)

[9] `towardsdatascience.com/continuous-integration-and-deployment-for-data-platforms-817bf1b6bed1`

[10] [`medium.com/towards-data-science/building-a-streaming-data-pipeline-with-redshift-serverless-and-kinesis-04e09d7e85b2`](https://medium.com/towards-data-science/building-a-streaming-data-pipeline-with-redshift-serverless-and-kinesis-04e09d7e85b2)

[11] [`www.snowflake.com/blog/auto-scale-snowflake-major-leap-forward-massively-concurrent-enterprise-applications/`](https://www.snowflake.com/blog/auto-scale-snowflake-major-leap-forward-massively-concurrent-enterprise-applications/)

[12] [`medium.com/towards-data-science/streaming-in-data-engineering-2bb2b9b3b603`](https://medium.com/towards-data-science/streaming-in-data-engineering-2bb2b9b3b603)

[13] [`docs.snowflake.com/en/user-guide/kafka-connector`](https://docs.snowflake.com/en/user-guide/kafka-connector)

[14] `towardsdatascience.com/python-for-data-engineers-f3d5db59b6dd`

[15] [`medium.com/towards-artificial-intelligence/supercharge-your-data-engineering-skills-with-this-machine-learning-pipeline-b69d159780b7`](https://medium.com/towards-artificial-intelligence/supercharge-your-data-engineering-skills-with-this-machine-learning-pipeline-b69d159780b7)

[16] [`medium.com/towards-data-science/introduction-to-apache-iceberg-tables-a791f1758009`](https://medium.com/towards-data-science/introduction-to-apache-iceberg-tables-a791f1758009)
