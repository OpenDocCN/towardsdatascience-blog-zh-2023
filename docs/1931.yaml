- en: Controllable Medical Image Generation with ControlNets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/controllable-medical-image-generation-with-controlnets-48ef33dde652?source=collection_archive---------6-----------------------#2023-06-13](https://towardsdatascience.com/controllable-medical-image-generation-with-controlnets-48ef33dde652?source=collection_archive---------6-----------------------#2023-06-13)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Guide on using ControlNets to control the generation process of Latent Diffusion
    Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@walhugolp?source=post_page-----48ef33dde652--------------------------------)[![Walter
    Hugo Lopez Pinaya](../Images/0c132d0d1321790b0cea880800d231e0.png)](https://medium.com/@walhugolp?source=post_page-----48ef33dde652--------------------------------)[](https://towardsdatascience.com/?source=post_page-----48ef33dde652--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----48ef33dde652--------------------------------)
    [Walter Hugo Lopez Pinaya](https://medium.com/@walhugolp?source=post_page-----48ef33dde652--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa1dadbc02295&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontrollable-medical-image-generation-with-controlnets-48ef33dde652&user=Walter+Hugo+Lopez+Pinaya&userId=a1dadbc02295&source=post_page-a1dadbc02295----48ef33dde652---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----48ef33dde652--------------------------------)
    ·9 min read·Jun 13, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F48ef33dde652&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontrollable-medical-image-generation-with-controlnets-48ef33dde652&user=Walter+Hugo+Lopez+Pinaya&userId=a1dadbc02295&source=-----48ef33dde652---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F48ef33dde652&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontrollable-medical-image-generation-with-controlnets-48ef33dde652&source=-----48ef33dde652---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: In this post, we will present a guide on training a **ControlNet** to empower
    users with precise control over the generation process of a **Latent Diffusion
    Model** **(like Stable Diffusion!)**. Our aim is to showcase the remarkable capabilities
    of these models in translating brain images across various contrasts. To achieve
    this, we will leverage the power of the recently introduced **open-source extension
    for MONAI,** [**MONAI Generative Models**](https://github.com/Project-MONAI/GenerativeModels)**!**
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/802d4dc3c60ef6342ff0aa9478c0bad4.png)'
  prefs: []
  type: TYPE_IMG
- en: Generating T1-weighted brain images (right) from FLAIR images (left) using ControlNet
  prefs: []
  type: TYPE_NORMAL
- en: '***Our project code is available in this public repository*** [***https://github.com/Warvito/generative_brain_controlnet***](https://github.com/Warvito/generative_brain_controlnet)'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In recent years, text-to-image diffusion models have witnessed remarkable advancements,
    enabling the generation of highly realistic images based on open-domain text descriptions.
    These generated images have rich details, well-defined outlines, coherent structures,
    and meaningful contextual representation. However, despite the significant achievements
    of diffusion models, there remains a challenge in achieving precise control over
    the generative process. **Even with lengthy and intricate text descriptions, accurately
    capturing the user’s desired ideas can be a struggle.**
  prefs: []
  type: TYPE_NORMAL
