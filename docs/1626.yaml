- en: The Power of the Dot Product in Artificial Intelligence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-power-of-the-dot-product-in-artificial-intelligence-c002331e1829?source=collection_archive---------7-----------------------#2023-05-15](https://towardsdatascience.com/the-power-of-the-dot-product-in-artificial-intelligence-c002331e1829?source=collection_archive---------7-----------------------#2023-05-15)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How a simple tool gives rise to astonishing complexity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://manuel-brenner.medium.com/?source=post_page-----c002331e1829--------------------------------)[![Manuel
    Brenner](../Images/f62843c79a9b378494cb83caf3ddc792.png)](https://manuel-brenner.medium.com/?source=post_page-----c002331e1829--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c002331e1829--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c002331e1829--------------------------------)
    [Manuel Brenner](https://manuel-brenner.medium.com/?source=post_page-----c002331e1829--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1fde95441432&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-power-of-the-dot-product-in-artificial-intelligence-c002331e1829&user=Manuel+Brenner&userId=1fde95441432&source=post_page-1fde95441432----c002331e1829---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c002331e1829--------------------------------)
    ·9 min read·May 15, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc002331e1829&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-power-of-the-dot-product-in-artificial-intelligence-c002331e1829&user=Manuel+Brenner&userId=1fde95441432&source=-----c002331e1829---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc002331e1829&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-power-of-the-dot-product-in-artificial-intelligence-c002331e1829&source=-----c002331e1829---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: Taking something simple and scaling it up to achieve something more complex
    is a powerful idea, laying the foundation of [life](https://manuel-brenner.medium.com/the-importance-of-noise-327fcab7c4fb),
    computers (based on the simplicity of the [Turing machine](https://medium.com/discourse/a-non-technical-guide-to-turing-machines-f8c6da9596e5)),
    and deep learning techniques (based on the idea of the neurons in a neural network).
  prefs: []
  type: TYPE_NORMAL
- en: '[More is frequently different](https://manuel-brenner.medium.com/more-is-different-a49e833260b3),
    which we continue observing as state-of-the-art architectures are increasingly
    scaled (with large language models like [GPT](https://arxiv.org/abs/2005.14165)
    changing the world as we speak), leading to better generalization and impressive
    results.'
  prefs: []
  type: TYPE_NORMAL
- en: Researchers claim that large language models showcase [emergent abilities](https://openreview.net/pdf?id=yzkSU5zdwD)
    that are achieved without too much architectural innovation, but (arguably) mostly
    from an increase of computational resources and the repetition of simple operations
    at scale (for a caveat, see [this article](https://arxiv.org/abs/2304.15004)).
  prefs: []
  type: TYPE_NORMAL
- en: Although training deep learning models requires ingenuity and techniques that
    the community has built up over years, the fundamental building blocks of most
    deep learning approaches remain quite simple, being composed of only a small number
    of mathematical operations.
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps the most important one is the dot product. In the rest of this article,
    I want to explore what the dot product does, why it is so important, and why scaling
    it up has achieved levels of AI that astonish everyone that comes into closer
    contact with it.
  prefs: []
  type: TYPE_NORMAL
