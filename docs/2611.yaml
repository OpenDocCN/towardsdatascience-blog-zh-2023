- en: Introduction to Ranking Algorithms
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 排名算法介绍
- en: 原文：[https://towardsdatascience.com/introduction-to-ranking-algorithms-4e4639d65b8?source=collection_archive---------0-----------------------#2023-08-16](https://towardsdatascience.com/introduction-to-ranking-algorithms-4e4639d65b8?source=collection_archive---------0-----------------------#2023-08-16)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/introduction-to-ranking-algorithms-4e4639d65b8?source=collection_archive---------0-----------------------#2023-08-16](https://towardsdatascience.com/introduction-to-ranking-algorithms-4e4639d65b8?source=collection_archive---------0-----------------------#2023-08-16)
- en: Learn about main ranking algorithms for sorting search results
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解排序搜索结果的主要排名算法
- en: '[](https://medium.com/@slavahead?source=post_page-----4e4639d65b8--------------------------------)[![Vyacheslav
    Efimov](../Images/db4b02e75d257063e8e9d3f1f75d9d6d.png)](https://medium.com/@slavahead?source=post_page-----4e4639d65b8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4e4639d65b8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4e4639d65b8--------------------------------)
    [Vyacheslav Efimov](https://medium.com/@slavahead?source=post_page-----4e4639d65b8--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@slavahead?source=post_page-----4e4639d65b8--------------------------------)[![Vyacheslav
    Efimov](../Images/db4b02e75d257063e8e9d3f1f75d9d6d.png)](https://medium.com/@slavahead?source=post_page-----4e4639d65b8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4e4639d65b8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4e4639d65b8--------------------------------)
    [Vyacheslav Efimov](https://medium.com/@slavahead?source=post_page-----4e4639d65b8--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc8a0ca9d85d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-ranking-algorithms-4e4639d65b8&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=post_page-c8a0ca9d85d8----4e4639d65b8---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4e4639d65b8--------------------------------)
    ·12 min read·Aug 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4e4639d65b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-ranking-algorithms-4e4639d65b8&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=-----4e4639d65b8---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc8a0ca9d85d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-ranking-algorithms-4e4639d65b8&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=post_page-c8a0ca9d85d8----4e4639d65b8---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4e4639d65b8--------------------------------)
    · 12 分钟阅读 · 2023年8月16日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4e4639d65b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-ranking-algorithms-4e4639d65b8&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=-----4e4639d65b8---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e4639d65b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-ranking-algorithms-4e4639d65b8&source=-----4e4639d65b8---------------------bookmark_footer-----------)![](../Images/f8dc54f04406b2e33771a6097cc38bff.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e4639d65b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-ranking-algorithms-4e4639d65b8&source=-----4e4639d65b8---------------------bookmark_footer-----------)![](../Images/f8dc54f04406b2e33771a6097cc38bff.png)'
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '**Learning to rank** (LTR) is a class of supervised machine learning algorithms
    aiming to sort a list of items in terms of their relevance to a query. In classical
    machine learning in problems like classification and regression, the goal is to
    predict a single value based on a feature vector. LTR algorithms operate on a
    set of feature vectors and predict the optimal order of items.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**学习排序**（LTR）是一类监督式机器学习算法，旨在根据与查询的相关性对一组项目进行排序。在经典机器学习中，如分类和回归问题，目标是根据特征向量预测单一值。LTR算法在一组特征向量上操作，并预测项目的最佳排序。'
- en: 'LTR has many different applications. Here are some of them:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: LTR有许多不同的应用。以下是其中的一些：
- en: '*Search engines*. A user types a query into a browser search bar. The search
    engine should rank the web pages in a way that the most relevant results appear
    in top positions.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*搜索引擎*。用户在浏览器搜索栏中输入查询。搜索引擎应该以一种方式对网页进行排名，使得最相关的结果出现在最上面的位置。'
- en: '*Recommender systems*. A movie recommender system choosing which film should
    be recommended to a user based on an input query.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*推荐系统*。一个电影推荐系统，根据输入查询选择应该推荐给用户的电影。'
- en: 'Let us formally define the ranking problem:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们正式定义排序问题：
- en: Given an *n*-dimensional feature vector storing the information about a query
    and a document, the objective of ranking is to find such a function *f* which
    produces a real number indicating the relevance of the query to the document.
    Additionally, if object *i* is ranked higher than object *j* (*i ▷ j*), then *f(i)*
    should be greater than *f(j)*.
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 给定一个存储查询和文档信息的 *n* 维特征向量，排序的目标是找到一个函数 *f*，该函数产生一个实数，表示查询与文档的相关性。此外，如果对象 *i*
    排名高于对象 *j*（*i ▷ j*），则 *f(i)* 应该大于 *f(j)*。
- en: ''
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Note. i ▷ j means that document i is ranked higher than document j.
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意。i ▷ j 表示文档 i 排名高于文档 j。
- en: Data
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据。
- en: Feature vectors
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征向量。
- en: 'Feature vectors consist of three types of features:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 特征向量包括三种类型的特征：
- en: Features derived only from a document (e.g., document length, number of links
    in a document).
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅从文档中派生的特征（例如，文档长度，文档中的链接数量）。
- en: Features derived only from a query (e.g., query length, frequency of a query).
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅从查询中派生的特征（例如，查询长度，查询的频率）。
- en: Features derived from a combination of a document and query (e.g., TF-IDF, BM25,
    BERT, number of common words in a document and query)
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从文档和查询的组合中派生的特征（例如，TF-IDF，BM25，BERT，文档和查询中共同出现的单词数量）。
- en: Training data
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练数据。
- en: In order to train a model, we need training data that will be fed into the model.
    There are two possible approaches based on how the training data is collected.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练模型，我们需要将训练数据输入到模型中。根据训练数据的收集方式，有两种可能的方法。
- en: '**Offline LTR**. Data is manually annotated by a human. The human rates the
    relevance of pairs (query, document) for different queries and documents. This
    approach is expensive and time-consuming but provides high-quality annotations.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**离线LTR**。数据由人工手动注释。人工对不同查询和文档的对（查询，文档）相关性进行评分。这种方法成本高且耗时，但提供高质量的注释。'
- en: '**Online LTR**. Data is implicitly collected from user interactions with query
    results (e.g., number of clicks on ranked items, time spent on a web page). In
    this case, it is simple to obtain training data but user interactions are not
    easy-interpretable.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在线LTR**。数据是通过用户与查询结果的互动（例如，对排序项目的点击次数，网页上的停留时间）隐式收集的。在这种情况下，获得训练数据是简单的，但用户互动的解释并不容易。'
- en: After that, we have features vectors and labels corresponding to them. This
    is everything we need for training a model. The next step is to choose the most
    suited machine learning algorithm for a problem.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们有了特征向量及其对应的标签。这就是训练模型所需的一切。下一步是选择最适合问题的机器学习算法。
- en: Ranking types
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 排序类型。
- en: 'From the high level, the majority of LTR algorithms use stochastic gradient
    descent to find the most optimal ranking. Depending on how an algorithm chooses
    and compares ranks of items at each iteration, there exist three principal methods:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，大多数 LTR 算法使用随机梯度下降来找到最优的排序。根据算法在每次迭代中如何选择和比较项目的排名，存在三种主要方法：
- en: Pointwise ranking.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点对点排序。
- en: Pairwise ranking.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成对排序。
- en: Listwise ranking.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列表排序。
- en: All of these methods transform ranking task to a classification or regression
    problem. In the following sections, we will see how they operate under the hood.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些方法都将排序任务转化为分类或回归问题。在接下来的部分，我们将看到它们如何在幕后运作。
- en: Pointwise ranking
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 点对点排序。
- en: In the pointwise approach, scores are predicted individually for each feature
    vector. Ultimately, the predicted scores are sorted. It does not matter which
    type of model (decision tree, neural network, etc.) is used for prediction.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在点对点方法中，为每个特征向量单独预测分数。最终，预测的分数被排序。使用哪种类型的模型（决策树，神经网络等）进行预测并不重要。
- en: This type of ranking transforms the ranking problem to the regression task where
    a regression model tries to predict correct relevance with respect to a chosen
    loss function (e.g., MSE).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的排序将排序问题转化为回归任务，其中回归模型试图根据选择的损失函数（例如，MSE）预测正确的相关性。
- en: Another valid approach is to transform ground truth rankings into one-hot representations
    and feed this data to the model. In this case, it is possible to use either a
    regression or classification model (with cross-entropy loss).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种有效的方法是将真实排名转化为独热编码表示，并将这些数据输入模型。在这种情况下，可以使用回归模型或分类模型（带有交叉熵损失）。
- en: '![](../Images/19ffa80ba5d625d00d9d6881dc00c920.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/19ffa80ba5d625d00d9d6881dc00c920.png)'
- en: Pointwise model architecture. As the input, the model accepts a query and a
    feature vector.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 逐点模型架构。作为输入，模型接受一个查询和一个特征向量。
- en: Despite the method being very simple, it has some issues listed below.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这种方法非常简单，但它存在以下列出的一些问题。
- en: '**Class imbalance**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**类别不平衡**'
- en: A common issue when using the pointwise method is class imbalance. If a random
    query is taken in real life, then it is very likely that only a tiny part of all
    documents in the collection will be relevant to it. Thus there is a high disbalance
    between relative and irrelative documents to a query in training data.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 使用逐点方法时的一个常见问题是类别不平衡。如果在现实生活中随机选择一个查询，那么很可能只有集合中的一小部分文档与之相关。因此，在训练数据中，相对文档与查询之间存在很高的不平衡。
- en: While it is possible to overcome this issue but there is a much more serious
    problem to consider.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然可以克服这个问题，但还有一个更严重的问题需要考虑。
- en: '**Bad optimisation metric**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**糟糕的优化指标**'
- en: 'Pointwise ranking has a major fundamental problem with its optimisation objective:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 逐点排名在优化目标上存在一个主要的基本问题：
- en: Pointwise ranking optimises document scores independently and does not take
    into account relative scores between different documents. Therefore, it does not
    directly optimise the ranking quality.
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 逐点排名独立地优化文档得分，而没有考虑不同文档之间的相对得分。因此，它没有直接优化排名质量。
- en: Consider an example below where a pointwise algorithm made predictions for two
    sets of documents. Let us assume that MSE loss is optimised during training.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 请看下面的例子，其中一个逐点算法对两组文档进行了预测。我们假设在训练过程中优化了均方误差（MSE）损失。
- en: '![](../Images/ab96312857422fddf4b78d2abfbdc2fb.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ab96312857422fddf4b78d2abfbdc2fb.png)'
- en: Collection contains 5 documents where 1 document is relevant and the other 4
    are irrelevant. For the relevant document, the predicted relevance is 0.7 while
    for others is 0.5.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 集合包含5个文档，其中1个文档是相关的，其他4个是无关的。对于相关文档，预测相关性为0.7，而对于其他文档为0.5。
- en: '![](../Images/b3b1559a7b5e01bf22d113b59ee8a45b.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b3b1559a7b5e01bf22d113b59ee8a45b.png)'
- en: Collection contains 5 documents where 1 document is relevant and the other 4
    are irrelevant. For the relevant document, the predict relevance is 0.1 while
    for others is 0.2.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 集合包含5个文档，其中1个文档是相关的，其他4个是无关的。对于相关文档，预测相关性为0.1，而对于其他文档为0.2。
- en: Given two ranking results, we can see that from the algorithm’s point of view,
    the second ranking is better because the corresponding MSE value is lower. However,
    choosing the second ranking means that the user will be shown all irrelevant results
    at first. By the way, in the first example, the relevant result is shown at first
    which is much better from the user experience. Normally, a user does not put much
    attention on what is recommended after.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 给定两个排名结果，我们可以看到从算法的角度来看，第二个排名更好，因为对应的MSE值较低。然而，选择第二个排名意味着用户会首先看到所有无关的结果。顺便提一下，在第一个例子中，相关结果首先显示，这在用户体验上要好得多。通常，用户不会太关注之后的推荐内容。
- en: This example shows that in real life we are concerned more about showing relevant
    results at first as well as about the relative order of the items. With independent
    processing of documents, pointwise does not guarantee these aspects. A lower loss
    is not the equivalent of a better ranking.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子表明，在现实生活中，我们更关心的是首先展示相关结果以及项目的相对顺序。通过独立处理文档，逐点模型无法保证这些方面。较低的损失并不等同于更好的排名。
- en: Pairwise ranking
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对输入对排名
- en: Pairwise models work with a pair of documents at each iteration. Depending on
    the input format there are two types of pairwise models.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 对输入对模型在每次迭代中处理一对文档。根据输入格式的不同，有两种类型的对输入对模型。
- en: Pair-input models
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对输入对模型
- en: The input to the model is two feature vectors. The model output is the probability
    that the first document is ranked higher than the second. During training, these
    probabilities are calculated for different pairs of feature vectors. The weights
    of the model are adjusted through gradient descent based on ground truth ranks.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的输入是两个特征向量。模型输出是第一个文档排名高于第二个文档的概率。在训练过程中，这些概率是为不同的特征向量对计算的。模型的权重通过基于真实排名的梯度下降进行调整。
- en: '![](../Images/e43a1c5459c83f5e495b0dc047b00b41.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e43a1c5459c83f5e495b0dc047b00b41.png)'
- en: Pair input model architecture. As an input, the model accepts a query and two
    concatenated feature vectors.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对输入对模型架构。作为输入，模型接受一个查询和两个连接的特征向量。
- en: 'This method has two major disadvantages during inference:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法在推理过程中有两个主要缺点：
- en: In order to rank *n* documents for a given query during inference, each pair
    of these documents needs to be processed by the model to get all pairwise probabilities.
    The total number of pairs is quadratic (exactly equal to *n * (n — 1) / 2)* which
    is very inefficient.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了在推理过程中对给定查询的*n*个文档进行排名，每对这些文档都需要由模型处理以获得所有成对概率。总对数是平方的（准确等于*n * (n — 1) /
    2*），这非常低效。
- en: 'Even by having pairwise probabilities of all documents, it is not obvious how
    to finally rank them, especially in paradoxical situations like *vicious circles*
    when there are triplets of documents *(x, y, z)* that are ranked by the model
    in a way that: *x ▷ y, y ▷ z* and *z ▷ x*.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使拥有所有文档的成对概率，也不明显如何最终排名，尤其是在像*恶性循环*这样的矛盾情况下，其中有三元组文档*(x, y, z)*，模型以如下方式对其进行排名：*x
    ▷ y, y ▷ z* 和 *z ▷ x*。
- en: '![](../Images/ae4c5599cbc9f028db64eb237e835fdd.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ae4c5599cbc9f028db64eb237e835fdd.png)'
- en: Vicious circle problem
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 恶性循环问题
- en: Because of these downsides, pair-input models are rarely used in practice and
    single-input models are preferred over them.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些缺点，成对输入模型在实践中很少使用，单输入模型被优先考虑。
- en: Single-input models
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单输入模型
- en: The model accepts a single feature vector as an input. During training, each
    document in a pair is independently fed into the model to receive its own score.
    Then both scores are compared and the model is adjusted through gradient descent
    based on ground truth ranks.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 模型接受一个单一的特征向量作为输入。在训练过程中，成对中的每个文档都独立地输入到模型中以接收其分数。然后比较这两个分数，并通过基于真实排名的梯度下降来调整模型。
- en: '![](../Images/1a6716a53b044b36d4b440a6bd07286e.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1a6716a53b044b36d4b440a6bd07286e.png)'
- en: Single input model architecture. As an input, the model takes a query and a
    single feature vector representing a document. The ranking prediction is calculated
    after the model independently assigned scores to two feature vectors.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 单输入模型架构。作为输入，该模型接收一个查询和一个表示文档的特征向量。在模型对两个特征向量独立分配分数后，计算排名预测。
- en: During inference, each document receives a score by being passed to the model.
    The scores are then sorted to obtain the final ranking.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在推理过程中，每个文档通过传递到模型中来接收一个分数。然后对这些分数进行排序，以获得最终排名。
- en: For those who are familiar with Siamese networks (FaceNet, SBERT, e.t.c), single
    input models can be thought of Siamese networks.
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于熟悉Siamese网络（FaceNet，SBERT等）的人来说，单输入模型可以被认为是Siamese网络。
- en: Pairwise loss functions
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 成对损失函数
- en: During each training iteration, the model predicts scores for a pair of documents.
    Therefore, the loss function should be pairwise and consider the scores of both
    documents.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在每次训练迭代中，模型对一对文档预测分数。因此，损失函数应为成对的，并考虑两个文档的分数。
- en: 'In general, pairwise loss takes as its argument *z* the difference between
    two scores *s[i] — s[j]* multiplied by a constant σ. Depending on the algorithm,
    the loss function can have one of the following forms:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，成对损失函数以*z*为其参数，其中*z*是两个分数*s[i] — s[j]*的差异乘以一个常数σ。根据算法的不同，损失函数可以具有以下形式之一：
- en: '![](../Images/48d6a711a440dcab40f232a805397db4.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/48d6a711a440dcab40f232a805397db4.png)'
- en: Different loss functions for pairwise ranking
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 成对排名的不同损失函数
- en: Sometimes the score difference *z* can be multiplied by a constant.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 有时分数差异*z*可以乘以一个常数。
- en: '**RankNet** is one of the most popular pairwise ranking algorithms. We are
    going to look through the details of its implementation in the next section.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**RankNet**是最流行的成对排名算法之一。我们将在下一部分详细了解其实现细节。'
- en: RankNet
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RankNet
- en: 'After obtaining scores for documents *i* and *j*, RankNet uses the softmax
    function to normalise them. By doing so, RankNet obtains the probability *P[i][j]
    = P(i ▷ j)* that the document *i* is ranked higher than document *j*. Inversely,
    we can calculate the probability *P̃[j][i] = P(j ▷ i) = 1 — P(i ▷ j)*. For simplicity,
    let us suppose that in reality i is ranked higher j, so *P̃[i][j] = 1* and *P̃[j][i]
    = 0*. For model weights’ update, RankNet uses cross-entropy loss which is simplified
    in the following way:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在获得文档*i*和*j*的分数后，RankNet使用softmax函数进行归一化。通过这样做，RankNet获得文档*i*比文档*j*排名更高的概率*P[i][j]
    = P(i ▷ j)*。反之，我们可以计算概率*P̃[j][i] = P(j ▷ i) = 1 — P(i ▷ j)*。为了简便起见，假设实际情况是i的排名高于j，所以*P̃[i][j]
    = 1*和*P̃[j][i] = 0*。对于模型权重的更新，RankNet使用交叉熵损失，其简化如下：
- en: '![](../Images/6c4dea9ee17904829712d2ba51356f67.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6c4dea9ee17904829712d2ba51356f67.png)'
- en: RankNet loss function
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: RankNet损失函数
- en: The weights of the model are adjusted by the gradient descent. The next time
    the model gets the same pair of documents i and j, the document i will be likely
    to get a higher score than before and the document j will probably be pushed down.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的权重通过梯度下降进行调整。下次模型遇到相同的文档对 i 和 j 时，文档 i 的得分可能会比之前更高，而文档 j 可能会被推得更低。
- en: '**RankNet factorisation**'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**RankNet 分解**'
- en: 'For simplicity, we are not going to dive deeply into the mathematics but there
    was an interesting research result presented in the original paper where authors
    found a way to simplify the training process. This is done by introducing the
    variable *S[i][j]* which takes one of three possible values:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化，我们不会深入探讨数学内容，但原始论文中提出了一个有趣的研究结果，作者找到了一种简化训练过程的方法。这是通过引入变量 *S[i][j]* 来实现的，该变量可以取三个可能的值之一：
- en: '![](../Images/21d81de7d6a67bb40d5efe8f3ed70b5a.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/21d81de7d6a67bb40d5efe8f3ed70b5a.png)'
- en: 'After some mathematical tricks, the derivative of cross-entropy loss factorised
    as:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 经过一些数学技巧，交叉熵损失的导数被分解为：
- en: '![](../Images/207459fd1c021ca1a311c1c0de0af13a.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/207459fd1c021ca1a311c1c0de0af13a.png)'
- en: The lambda value in the formula is a constant that can be relatively fast calculated
    for all the pairs of documents. By taking positive or negative values, these lambdas
    act as forces pushing documents up or down.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 公式中的 λ 值是一个常数，可以相对快速地计算所有文档对的 λ 值。通过取正值或负值，这些 λ 值充当了推动文档上升或下降的力量。
- en: We can sum up all the pairwise lambdas for a single document *i*. This sum results
    in the total force applied to the document *i* in the ranking.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以对单个文档 *i* 汇总所有成对的 λ 值。这个总和表示在排名中应用于文档 *i* 的总力量。
- en: '![](../Images/25abcfc6b9f24834aed4f62ca59d95e0.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/25abcfc6b9f24834aed4f62ca59d95e0.png)'
- en: Summing up lambdas for finding the total force applied to a document
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 对于找到应用于文档的总力量的 λ 值的汇总
- en: Working with lambdas directly results in a faster training time and better interpretation
    of results.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 直接使用 λ 函数可以得到更快的训练时间和更好的结果解释。
- en: Though pairwise algorithms perform better than pointwise approaches, they have
    two downsides.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管成对算法比逐点方法表现更好，但它们有两个缺点。
- en: '**Not interpretable probabilities**'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**不可解释的概率**'
- en: The output probabilities of the model just show how confident the model is that
    a certain object *i* is ranked higher than object *j*. However, these probabilities
    are not real and sometimes can be roughly approximated by the model, so it is
    not a good idea to always use them for interpretation, especially in confusing
    cases with vicious circles we saw earlier.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 模型输出的概率只是显示模型对某个对象 *i* 排在对象 *j* 之上的信心。然而，这些概率并不真实，有时模型可以粗略地近似这些概率，因此不应该总是用它们来进行解释，尤其是在之前看到的有恶性循环的混乱情况下。
- en: '**Minimisation of inversions is not optimal**'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**最小化倒置不是最优解**'
- en: This issue is much more critical than the previous one. The fundamental problem
    with most pairwise algorithms and RankNet in particular as well is that they minimise
    the number of rank inversions. Though it might appear natural to optimise the
    number of inversions, this is not what in reality most end users want. Consider
    the following example with two rankings. Which ranking is better, in your opinion?
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题比之前的问题更为严重。大多数成对算法，特别是 RankNet 的根本问题在于它们最小化排名倒置的数量。虽然优化倒置数量可能看起来很自然，但这并不是大多数最终用户真正想要的。考虑以下两个排名。你认为哪个排名更好？
- en: '![](../Images/fa57343c1cf76dc55727e424755beff0.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fa57343c1cf76dc55727e424755beff0.png)'
- en: Two relevant documents are located at the beginning and at the end of the list.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 两个相关的文档分别位于列表的开头和结尾。
- en: '![](../Images/6ef13f674a8c9dd2ce78e90f20f2b64a.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6ef13f674a8c9dd2ce78e90f20f2b64a.png)'
- en: Two relevant documents are located to the left side of the middle of the list.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 两个相关的文档位于列表的中间偏左位置。
- en: Though the second ranking has fewer inversions which is the priority for the
    algorithm, a normal user would still prefer the first ranking because there is
    at least one relevant result at the top. This means that the user does not have
    to scroll through a lot of documents to find the first relevant result. In the
    same way, it would be better to use such user-oriented metrics as *nDCG* or *ERR*
    which put more emphasis on top results rather than the number of inversions.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管第二个排名的倒排数较少，这是算法的优先考虑，但普通用户仍然会更喜欢第一个排名，因为顶部至少有一个相关结果。这意味着用户不需要滚动大量文档才能找到第一个相关结果。同样，使用如*nDCG*或*ERR*这样的用户导向指标会更好，因为这些指标更注重顶部结果而非倒排数量。
- en: As a consequence, we can see that **not all document pairs are equally important**.
    The algorithm needs to be adjusted in a way that would put much more importance
    on getting correct ranking on the top rather than on the bottom.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示，**并非所有文档对都同样重要**。算法需要调整，以更重视正确的顶部排名，而不是底部排名。
- en: 'Researchers of the paper present a well-illustrated example of how optimising
    ranking with RankNet can lead to not optimal results:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 论文的研究人员提供了一个很好的例子，说明如何通过RankNet优化排名可能导致非最优结果：
- en: '![](../Images/3f95efbadb4b904721e05be414cc4e41.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3f95efbadb4b904721e05be414cc4e41.png)'
- en: 'We can see that the document in the 1-st position was pushed to the 4-th and
    the 15-th document to the 10-th, so the total number of inversions has decreased
    by 2\. Nevertheless, from the user experience, the new ranking became worse. The
    core issue lies in the fact that RankNet assigns larger gradients to documents
    at worse positions. However, for optimising user-oriented metrics this should
    work inversely: documents at better positions should be pushed further up than
    those at worse positions. This way, user-oriented metrics like *nDCG* will be
    higher.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，第1位的文档被推到了第4位，第15位的文档被推到了第10位，所以总的倒排数减少了2。然而，从用户体验来看，新排名变得更糟。核心问题在于RankNet为排名较差的文档分配了更大的梯度。然而，为了优化用户导向的指标，这应该是反向的：排名较好的文档应被进一步推高，而不是排名较差的文档。这样，像*nDCG*这样的用户导向指标将会更高。
- en: Listwise ranking
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 列表排名
- en: Listwise algorithms optimise ranking metrics explicitly. To optimise a certain
    metric with gradient descent, a derivative needs to be calculated for that metric.
    Unfortunately, most of the ranking metrics like *nDCG* or *precision* are non-continuous
    and non-differentiable, so other advanced techniques are invented.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 列表算法明确优化排名指标。为了使用梯度下降优化某个指标，需要为该指标计算导数。不幸的是，大多数排名指标如*nDCG*或*precision*是非连续且不可微的，因此发明了其他高级技术。
- en: Unlike pointwise or pairwise ranking, listwise methods take as an input a whole
    list of documents at a single time. Sometimes this leads to big computations but
    also gives more robustness since the algorithm is provided with more information
    at each iteration.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 与点对点或对对排名方法不同，列表方法一次处理整个文档列表。这有时会导致大量计算，但也提供了更强的鲁棒性，因为算法在每次迭代时获得了更多的信息。
- en: '![](../Images/fecd781fb044ed36d9f94774ff070e1a.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fecd781fb044ed36d9f94774ff070e1a.png)'
- en: Listwise model architecture. As an input, the model takes a query and feature
    vectors of all documents.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 列表模型架构。作为输入，模型接收一个查询和所有文档的特征向量。
- en: LambdaRank
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LambdaRank
- en: Depending on the implementation, LambdaRank can be considered as a pairwise
    or listwise method.
  id: totrans-114
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 根据实现的不同，LambdaRank可以被认为是点对点或列表方法。
- en: When focusing on *nDCG*, it seems optimal to assign larger gradients to pairs
    of documents whose position swap results in higher *nDCG*. This core idea lies
    in **LambdaRank**.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 当关注*nDCG*时，似乎最优的做法是为那些位置交换结果能提高*nDCG*的文档对分配更大的梯度。这一核心思想在于**LambdaRank**。
- en: The “lambda” in the name of the algorithm hints that LambdaRank also uses lambdas
    described in RankNet for optimisation.
  id: totrans-116
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 算法名称中的“lambda”暗示LambdaRank还使用了RankNet中描述的lambda进行优化。
- en: 'Researchers produced an amazing result and proved that if the loss value in
    RankNet is multiplied by *|nDCG|*, then the algorithm tends to directly optimize
    *nDCG*! That is said, the LambdaRank algorithm is very similar to RankNet except
    for the fact that this time lambdas are multiplied by *nDCG* change:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员取得了惊人的成果，并证明如果RankNet中的损失值乘以*|nDCG|*，则算法倾向于直接优化*nDCG*！也就是说，LambdaRank算法与RankNet非常相似，只是这次lambda被乘以*nDCG*的变化：
- en: '![](../Images/464e7586c3a73e13a471d9209b253874.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/464e7586c3a73e13a471d9209b253874.png)'
- en: Formula for nDCG optimisation
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: nDCG优化公式
- en: What is also incredible about the research is the fact that this trick works
    not only for *nDCG* but for other information retrieval metrics as well! Similarly,
    if lambdas are multiplied by the precision change, then *precision* will be optimised.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 研究中另一个令人惊讶的事实是，这种技巧不仅对 *nDCG* 有效，而且对其他信息检索度量也有效！类似地，如果将 λ 乘以精度变化，那么 *precision*
    将得到优化。
- en: Recently, it was theoretically proven that LambdaRank optimizes a lower bound
    on certain information retrieval metrics.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，理论上已经证明 LambdaRank 可以优化某些信息检索度量的下界。
- en: Other Methods
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他方法
- en: We will not be discussing in detail how other listwise methods work but still
    provide the main idea behind its implementations of two honourable algorithms.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会详细讨论其他基于列表的方法如何工作，但仍会提供两个优秀算法的主要实现思想。
- en: '**LambdaMart** is a famous implementation of a listwise approach that uses
    gradient boosting trees with a loss function derived from LambdaRank. In practice,
    it performs better than LambdaRank.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**LambdaMart** 是一种著名的基于列表的方法实现，它使用从 LambdaRank 派生的损失函数的梯度提升树。在实际应用中，它比 LambdaRank
    表现更好。'
- en: '[**SoftRank**](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/SoftRankWsdm08Submitted.pdf)
    addresses the problem of derivative existence for *nDCG*. It creates a new metric
    called “*SoftNDCG*” which smoothly represents and approximates *nDCG* making it
    possible to find a corresponding derivative and update the model’s weights through
    gradient descent. In fact, this approach can be equally applied to other metrics
    as well.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[**SoftRank**](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/SoftRankWsdm08Submitted.pdf)
    解决了 *nDCG* 的导数存在问题。它创建了一种新的度量标准——“*SoftNDCG*”，它平滑地表示并近似 *nDCG*，使得可以找到相应的导数，并通过梯度下降更新模型的权重。事实上，这种方法也可以同样应用于其他度量标准。'
- en: Conclusion
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: We have covered ranking — an important task in machine learning for sorting
    a set of objects in the relevant order. Pointwise and pairwise approaches are
    not used that often while listwise methods are most robust. Obviously, we have
    discussed only a small part of ranking algorithms but this information is essential
    for understanding more complex techniques like ListNet or ListMLE. An extensive
    list of listwise algorithms can be found [here](https://en.wikipedia.org/wiki/Learning_to_rank#Listwise_approach).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了排名——这是机器学习中的一项重要任务，用于将一组对象按相关顺序排序。点对点和对对对方法不常使用，而基于列表的方法最为稳健。显然，我们只讨论了排名算法的一个小部分，但这些信息对于理解更复杂的技术如
    ListNet 或 ListMLE 是必不可少的。可以在 [这里](https://en.wikipedia.org/wiki/Learning_to_rank#Listwise_approach)
    找到一个详细的列表方法算法。
- en: It is worth noting that LambdaRank is currently one of the state-of-the-art
    ranking algorithms which gives a lot of flexibility for optimising a particular
    metric.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，LambdaRank 目前是最先进的排名算法之一，为优化特定度量提供了很大的灵活性。
- en: If you would like to find more information about ranking metrics, I highly recommend
    you go through my other article on this topic.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于排名度量的信息，我强烈建议你阅读我关于这个话题的另一篇文章。
- en: '[](/comprehensive-guide-to-ranking-evaluation-metrics-7d10382c1025?source=post_page-----4e4639d65b8--------------------------------)
    [## Comprehensive Guide to Ranking Evaluation Metrics'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/comprehensive-guide-to-ranking-evaluation-metrics-7d10382c1025?source=post_page-----4e4639d65b8--------------------------------)
    [## 排名评估度量的全面指南'
- en: Explore an abundant choice of metrics and find the best one for your problem
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 探索丰富的度量选择，找到最适合你问题的度量
- en: towardsdatascience.com](/comprehensive-guide-to-ranking-evaluation-metrics-7d10382c1025?source=post_page-----4e4639d65b8--------------------------------)
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/comprehensive-guide-to-ranking-evaluation-metrics-7d10382c1025?source=post_page-----4e4639d65b8--------------------------------)
- en: Resources
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源
- en: '[From RankNet to LambdaRank to LambdaMART: An Overview](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf)'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从 RankNet 到 LambdaRank 再到 LambdaMART：概述](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf)'
- en: '[Learning to Rank using Gradient Descent](https://icml.cc/2015/wp-content/uploads/2015/06/icml_ranking.pdf)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用梯度下降的学习排序](https://icml.cc/2015/wp-content/uploads/2015/06/icml_ranking.pdf)'
- en: '[Information Retrieval | Learning to Rank | Harrie Oosterhuis](https://drive.google.com/drive/folders/19OfEsLME1IR7bGPzVo8Dh31emcPNiaP_)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[信息检索 | 学习排序 | 哈里·奥斯特豪斯](https://drive.google.com/drive/folders/19OfEsLME1IR7bGPzVo8Dh31emcPNiaP_)'
- en: '[Learning to Rank | Wikipedia](https://en.wikipedia.org/wiki/Learning_to_rank)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习排序 | 维基百科](https://en.wikipedia.org/wiki/Learning_to_rank)'
- en: '[SoftRank: Optimising Non-Smooth Rank Metrics](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/SoftRankWsdm08Submitted.pdf)'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*All images unless otherwise noted are by the author*'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
