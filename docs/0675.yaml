- en: Explainable AI with TCAV from Google AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/explainable-ai-with-tcav-from-google-ai-5408adf905e?source=collection_archive---------7-----------------------#2023-02-18](https://towardsdatascience.com/explainable-ai-with-tcav-from-google-ai-5408adf905e?source=collection_archive---------7-----------------------#2023-02-18)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Explain deep neural networks using concept-based explanations
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://adib0073.medium.com/?source=post_page-----5408adf905e--------------------------------)[![Aditya
    Bhattacharya](../Images/d0f79ad4a85330c58327aea499b7eea0.png)](https://adib0073.medium.com/?source=post_page-----5408adf905e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5408adf905e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5408adf905e--------------------------------)
    [Aditya Bhattacharya](https://adib0073.medium.com/?source=post_page-----5408adf905e--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4bb294d0fe6b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplainable-ai-with-tcav-from-google-ai-5408adf905e&user=Aditya+Bhattacharya&userId=4bb294d0fe6b&source=post_page-4bb294d0fe6b----5408adf905e---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5408adf905e--------------------------------)
    ·13 min read·Feb 18, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5408adf905e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplainable-ai-with-tcav-from-google-ai-5408adf905e&user=Aditya+Bhattacharya&userId=4bb294d0fe6b&source=-----5408adf905e---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5408adf905e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplainable-ai-with-tcav-from-google-ai-5408adf905e&source=-----5408adf905e---------------------bookmark_footer-----------)![](../Images/08876ebee32ea4c27b44a794161d9bab.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: 'Image Source: [Pixabay](https://pixabay.com/illustrations/tick-tock-tiktok-network-computer-7730760/)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '[**Explainable AI (XAI)**](https://amzn.to/3cY4c2h) is a subfield of artificial
    intelligence (AI) that aims to develop AI systems that can provide clear and understandable
    explanations of their decision-making processes to humans. The goal of XAI is
    to make AI more transparent, trustworthy, responsible, and ethical. XAI is an
    important element in increasing AI adoption, especially for high stake domains
    such as healthcare, finance, and law enforcement. In these domains, it is crucial
    to understand how an AI system arrived at a particular decision or recommendation.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: There are various techniques used in XAI, including model transparency, rule-based
    systems, and model-agnostic methods such as LIME and SHAP. XAI approaches can
    vary depending on the type of AI system, the application domain, and the level
    of explainability required. Overall, XAI is an essential field for developing
    AI systems that can be trusted and used ethically and effectively in real-world
    applications.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: XAI中使用了各种技术，包括模型透明性、基于规则的系统以及模型无关的方法，如LIME和SHAP。XAI的方法可以根据AI系统的类型、应用领域和所需的解释性水平而有所不同。总体而言，XAI是开发可被信任并在实际应用中以道德和有效方式使用的AI系统的一个重要领域。
- en: 'If you want a brief introduction to XAI in a short 45 mins video, then you
    can watch one of my past sessions on XAI delivered at the **AI Accelerator Festival
    APAC, 2021**:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在短短45分钟的视频中获得对XAI的简要介绍，你可以观看我在**AI Accelerator Festival APAC, 2021**上关于XAI的其中一个过去的演讲：
