- en: Researching a Multilingual FEMA Disaster Bot Using LangChain and GPT-4
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ LangChain å’Œ GPT-4 ç ”ç©¶å¤šè¯­è¨€ FEMA ç¾éš¾æœºå™¨äºº
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/researching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd?source=collection_archive---------5-----------------------#2023-08-17](https://towardsdatascience.com/researching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd?source=collection_archive---------5-----------------------#2023-08-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/researching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd?source=collection_archive---------5-----------------------#2023-08-17](https://towardsdatascience.com/researching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd?source=collection_archive---------5-----------------------#2023-08-17)
- en: Some pros and cons of Retrieval-Augmented Generation (RAG) for high-risk chat
    applications
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é«˜é£é™©èŠå¤©åº”ç”¨ç¨‹åºä¸­æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰çš„ä¼˜ç¼ºç‚¹
- en: '[](https://medium.com/@astrobagel?source=post_page-----4591f26d8dcd--------------------------------)[![Matthew
    Harris](../Images/4fa3264bb8a028633cd8d37093c16214.png)](https://medium.com/@astrobagel?source=post_page-----4591f26d8dcd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4591f26d8dcd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4591f26d8dcd--------------------------------)
    [Matthew Harris](https://medium.com/@astrobagel?source=post_page-----4591f26d8dcd--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@astrobagel?source=post_page-----4591f26d8dcd--------------------------------)[![Matthew
    Harris](../Images/4fa3264bb8a028633cd8d37093c16214.png)](https://medium.com/@astrobagel?source=post_page-----4591f26d8dcd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4591f26d8dcd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4591f26d8dcd--------------------------------)
    [Matthew Harris](https://medium.com/@astrobagel?source=post_page-----4591f26d8dcd--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4a2cd25b8ff9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresearching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd&user=Matthew+Harris&userId=4a2cd25b8ff9&source=post_page-4a2cd25b8ff9----4591f26d8dcd---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4591f26d8dcd--------------------------------)
    Â·54 min readÂ·Aug 17, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4591f26d8dcd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresearching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd&user=Matthew+Harris&userId=4a2cd25b8ff9&source=-----4591f26d8dcd---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4a2cd25b8ff9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresearching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd&user=Matthew+Harris&userId=4a2cd25b8ff9&source=post_page-4a2cd25b8ff9----4591f26d8dcd---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4591f26d8dcd--------------------------------)
    Â·54åˆ†é’Ÿé˜…è¯»Â·2023å¹´8æœˆ17æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4591f26d8dcd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresearching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd&user=Matthew+Harris&userId=4a2cd25b8ff9&source=-----4591f26d8dcd---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4591f26d8dcd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresearching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd&source=-----4591f26d8dcd---------------------bookmark_footer-----------)![](../Images/37138d88da2ef33806c505f6c3bcb47e.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4591f26d8dcd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresearching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd&source=-----4591f26d8dcd---------------------bookmark_footer-----------)![](../Images/37138d88da2ef33806c505f6c3bcb47e.png)'
- en: Image generated by [DALL-E2](https://openai.com/dall-e-2) using prompt â€œA photo
    of a raging river flooding around a robotâ€
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”± [DALL-E2](https://openai.com/dall-e-2) ä½¿ç”¨æç¤ºâ€œä¸€ä¸ªæ¿€æµå›´ç»•ä¸€ä¸ªæœºå™¨äººæ³›æ»¥çš„ç…§ç‰‡â€ç”Ÿæˆ
- en: '*TL;DR*'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*ç®€è¦æ¦‚è¿°*'
- en: '*In this article, we explore how to build a multilingual* [*US Federal Emergency
    Management Agency (FEMA)*](https://www.fema.gov/about) *disaster chatbot to help
    people prepare for and survive disasters such as floods, tornados, wildfires,
    earthquakes, and winter storms. A chat interface was created from 34 FEMA PDF
    documents using LangChain and GPT-4\. As amazing as this popular pattern is, care
    is needed with high-risk applications such as disaster response bots. Though Large
    Language Model (LLM) hallucinations are minimized, common issues with semantic
    search of documents can lead to critical information being excluded in chat responses.
    We tested a few simple techniques to improve performance for this specific analysis,
    such as incorporating document metadata into embeddings, enriching user questions
    with LLM zero-shot context classification, and automatic language detection and
    translation using Google Translate to better support languages like Swahili. The
    techniques applied were pretty basic, but the ability of the prototype bot to
    surface information efficiently from FEMA PDF documents shows promise. Obviously,
    testing and validation would be needed if using this technique for high-risk situations,
    ideally using automated LLM techniques to create question-and-answer validation
    data.*'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ¢è®¨äº†å¦‚ä½•æ„å»ºä¸€ä¸ªå¤šè¯­è¨€çš„* [*ç¾å›½è”é‚¦åº”æ€¥ç®¡ç†å±€ (FEMA)*](https://www.fema.gov/about) *ç¾éš¾èŠå¤©æœºå™¨äººï¼Œä»¥å¸®åŠ©äººä»¬å‡†å¤‡å’Œåº”å¯¹è¯¸å¦‚æ´ªæ°´ã€é¾™å·é£ã€é‡ç«ã€åœ°éœ‡å’Œå†¬å­£é£æš´ç­‰ç¾éš¾ã€‚æˆ‘ä»¬ä½¿ç”¨
    LangChain å’Œ GPT-4 ä» 34 ä¸ª FEMA PDF æ–‡æ¡£ä¸­åˆ›å»ºäº†ä¸€ä¸ªèŠå¤©ç•Œé¢ã€‚å°½ç®¡è¿™ç§æµè¡Œæ¨¡å¼éå¸¸ä»¤äººæƒŠå¹ï¼Œä½†åœ¨é«˜é£é™©åº”ç”¨å¦‚ç¾éš¾å“åº”æœºå™¨äººä¸­ä»éœ€è°¨æ…ã€‚è™½ç„¶å¤§è¯­è¨€æ¨¡å‹
    (LLM) çš„å¹»è§‰ç°è±¡å·²è¢«æœ€å°åŒ–ï¼Œä½†æ–‡æ¡£çš„è¯­ä¹‰æœç´¢å¸¸è§é—®é¢˜å¯èƒ½å¯¼è‡´èŠå¤©å“åº”ä¸­é—æ¼å…³é”®ä¿¡æ¯ã€‚æˆ‘ä»¬æµ‹è¯•äº†ä¸€äº›ç®€å•çš„æŠ€æœ¯æ¥æé«˜è¿™ç§ç‰¹å®šåˆ†æçš„æ€§èƒ½ï¼Œæ¯”å¦‚å°†æ–‡æ¡£å…ƒæ•°æ®çº³å…¥åµŒå…¥ã€é€šè¿‡
    LLM é›¶æ ·æœ¬ä¸Šä¸‹æ–‡åˆ†ç±»ä¸°å¯Œç”¨æˆ·é—®é¢˜ï¼Œä»¥åŠä½¿ç”¨è°·æ­Œç¿»è¯‘è¿›è¡Œè‡ªåŠ¨è¯­è¨€æ£€æµ‹å’Œç¿»è¯‘ï¼Œä»¥æ›´å¥½åœ°æ”¯æŒåƒæ–¯ç“¦å¸Œé‡Œè¯­è¿™æ ·çš„è¯­è¨€ã€‚åº”ç”¨çš„æŠ€æœ¯éå¸¸åŸºç¡€ï¼Œä½†åŸå‹æœºå™¨äººçš„ä¿¡æ¯æå–èƒ½åŠ›ä»
    FEMA PDF æ–‡æ¡£ä¸­æ˜¾ç¤ºäº†å¸Œæœ›ã€‚æ˜¾ç„¶ï¼Œå¦‚æœå°†è¿™ç§æŠ€æœ¯ç”¨äºé«˜é£é™©æƒ…å†µï¼Œéœ€è¿›è¡Œæµ‹è¯•å’ŒéªŒè¯ï¼Œç†æƒ³æƒ…å†µä¸‹ä½¿ç”¨è‡ªåŠ¨åŒ–çš„ LLM æŠ€æœ¯åˆ›å»ºé—®ç­”éªŒè¯æ•°æ®ã€‚*'
- en: A few weeks ago we had a major flooding event in Vermont. The small brook that
    gurgles cheerfully past our house turned into a raging monster hellbent on destruction.
    Luckily we werenâ€™t damaged badly, but sadly, many lost property and livelihoods.
    At one point during the flood, it looked like we might have to evacuate so I started
    checking the [US Federal Emergency Management Agency (FEMA)](https://www.fema.gov/about)
    website for advice. I had already prepared somewhat, but when trouble arrived
    I wanted to reconfirm a few things. FEMA has really excellent, concise resources
    in PDF documents and web pages which I started searching, but I wondered ...
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å‡ å‘¨å‰ï¼Œæˆ‘ä»¬åœ¨ä½›è’™ç‰¹å·ç»å†äº†ä¸€æ¬¡ä¸¥é‡çš„æ´ªæ°´äº‹ä»¶ã€‚æµç»æˆ‘ä»¬æˆ¿å­çš„é‚£æ¡å°æºªå˜æˆäº†ä¸€ä¸ªæ„¤æ€’çš„æ€ªç‰©ï¼Œç‹‚æš´åœ°ç ´åä¸€åˆ‡ã€‚å¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä»¬æ²¡æœ‰å—åˆ°ä¸¥é‡æŸå®³ï¼Œä½†é—æ†¾çš„æ˜¯ï¼Œè®¸å¤šäººå¤±å»äº†è´¢äº§å’Œç”Ÿè®¡ã€‚åœ¨æ´ªæ°´çš„æŸä¸ªæ—¶åˆ»ï¼Œçœ‹èµ·æ¥æˆ‘ä»¬å¯èƒ½éœ€è¦æ’¤ç¦»ï¼Œäºæ˜¯æˆ‘å¼€å§‹æŸ¥çœ‹
    [ç¾å›½è”é‚¦åº”æ€¥ç®¡ç†å±€ (FEMA)](https://www.fema.gov/about) ç½‘ç«™ä¸Šçš„å»ºè®®ã€‚æˆ‘å·²ç»æœ‰äº†ä¸€äº›å‡†å¤‡ï¼Œä½†å½“éº»çƒ¦æ¥ä¸´æ—¶ï¼Œæˆ‘æƒ³é‡æ–°ç¡®è®¤ä¸€äº›äº‹æƒ…ã€‚FEMA
    çš„ PDF æ–‡æ¡£å’Œç½‘é¡µèµ„æºéå¸¸ä¼˜ç§€ä¸”ç®€æ˜ï¼Œæˆ‘å¼€å§‹æœç´¢ï¼Œä½†æˆ‘åœ¨æƒ³â€¦â€¦
- en: '***In an emergency, is there a faster way to get helpful information that doesnâ€™t
    require searching and reading multiple documents?***'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***åœ¨ç´§æ€¥æƒ…å†µä¸‹ï¼Œæœ‰æ²¡æœ‰æ¯”æœç´¢å’Œé˜…è¯»å¤šä¸ªæ–‡æ¡£æ›´å¿«çš„æ–¹æ³•æ¥è·å–æœ‰ç”¨ä¿¡æ¯ï¼Ÿ***'
- en: One obvious solution might be to ask a chatbot. I think chatbots can get a bit
    overused at times, but this does seem like a solid use case as a conversational
    interface can be more efficient when time is of the essence.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæ˜æ˜¾çš„è§£å†³æ–¹æ¡ˆå¯èƒ½æ˜¯è¯¢é—®èŠå¤©æœºå™¨äººã€‚æˆ‘è®¤ä¸ºèŠå¤©æœºå™¨äººæœ‰æ—¶å¯èƒ½ä¼šè¢«è¿‡åº¦ä½¿ç”¨ï¼Œä½†åœ¨æ—¶é—´ç´§è¿«çš„æƒ…å†µä¸‹ï¼Œè¿™ç¡®å®æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„åº”ç”¨åœºæ™¯ï¼Œå› ä¸ºå¯¹è¯ç•Œé¢å¯èƒ½æ›´ä¸ºé«˜æ•ˆã€‚
- en: It is not a new idea, organisations such as the American Red Cross have developed
    bots like [Clara](https://www.redcross.org/get-help/disaster-relief-and-recovery-services/meet-clara.html)
    for disaster response. However, a promising new pattern has recently emerged to
    use Generative AI Large Language Models (LLMs) such as [OpenAIâ€™s GPT-4](https://openai.com/research/gpt-4),
    [Metaâ€™s LLAMA 2](https://ai.meta.com/llama/), and a growing plethora of models
    on [HuggingFace](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard).
    These models can be used to index a specified set of documents and interact with
    them conversationally. [Called Retrieval-Augmented Generation (RAG)](https://huggingface.co/blog/ray-rag),
    there are hundreds of tutorials on the web demonstrating it with the amazing [LangChain](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa)
    Python package and I fully expect this technique to appear soon in software we
    use every day. Whatâ€™s interesting is that it restricts responses to the provided
    content and so is less prone to hallucinations which can prevent using LLMs in
    critical situations such as disaster response.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¹¶ä¸æ˜¯ä¸€ä¸ªæ–°æƒ³æ³•ï¼Œåƒç¾å›½çº¢åå­—ä¼šè¿™æ ·çš„ç»„ç»‡å·²ç»å¼€å‘äº†ç±»ä¼¼äº[Clara](https://www.redcross.org/get-help/disaster-relief-and-recovery-services/meet-clara.html)çš„ç¾å®³å“åº”æœºå™¨äººã€‚ç„¶è€Œï¼Œæœ€è¿‘å‡ºç°äº†ä¸€ç§æœ‰å‰æ™¯çš„æ–°æ¨¡å¼ï¼Œåˆ©ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œå¦‚[OpenAIçš„GPT-4](https://openai.com/research/gpt-4)ã€[Metaçš„LLAMA
    2](https://ai.meta.com/llama/)ä»¥åŠåœ¨[HuggingFace](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)ä¸Šä¸æ–­å¢é•¿çš„ä¼—å¤šæ¨¡å‹ã€‚è¿™äº›æ¨¡å‹å¯ä»¥ç”¨æ¥ç´¢å¼•æŒ‡å®šçš„æ–‡æ¡£é›†ï¼Œå¹¶ä¸å…¶è¿›è¡Œå¯¹è¯ã€‚[è¿™ç§æ–¹æ³•ç§°ä¸ºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰](https://huggingface.co/blog/ray-rag)ï¼Œç½‘ä¸Šæœ‰æ•°ç™¾ä¸ªæ•™ç¨‹å±•ç¤ºäº†ä½¿ç”¨ä»¤äººæƒŠå¹çš„[LangChain](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa)
    Python åŒ…ï¼Œæˆ‘å®Œå…¨é¢„æœŸè¿™ç§æŠ€æœ¯å¾ˆå¿«ä¼šå‡ºç°åœ¨æˆ‘ä»¬æ¯å¤©ä½¿ç”¨çš„è½¯ä»¶ä¸­ã€‚æœ‰è¶£çš„æ˜¯ï¼Œå®ƒå°†å“åº”é™åˆ¶åœ¨æä¾›çš„å†…å®¹èŒƒå›´å†…ï¼Œä»è€Œå‡å°‘äº†å¹»è§‰çš„å‘ç”Ÿï¼Œè¿™æœ‰åŠ©äºåœ¨ç¾å®³å“åº”ç­‰å…³é”®æƒ…å†µä¸‹ä½¿ç”¨LLMsã€‚
- en: But how safe is it in cases where the information retrieved might save lives?
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†åœ¨ä¿¡æ¯æ£€ç´¢å¯èƒ½æ‹¯æ•‘ç”Ÿå‘½çš„æƒ…å†µä¸‹ï¼Œè¿™ç§æ–¹æ³•çš„å®‰å…¨æ€§å¦‚ä½•å‘¢ï¼Ÿ
- en: In this article, I briefly explore creating a LangChain GPT-4 chat interface
    for asking questions about disaster safety based on a set of documents from the
    [US Federal Emergency Management Agency (FEMA)](https://www.fema.gov/about). We
    will encounter some of the limitations that need to be considered if using this
    technique in high-risk situations.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ç®€è¦æ¢è®¨äº†åˆ›å»ºä¸€ä¸ªLangChain GPT-4èŠå¤©ç•Œé¢ï¼Œç”¨äºåŸºäº[ç¾å›½è”é‚¦åº”æ€¥ç®¡ç†ç½²ï¼ˆFEMAï¼‰](https://www.fema.gov/about)çš„ä¸€ç»„æ–‡æ¡£è¯¢é—®æœ‰å…³ç¾å®³å®‰å…¨çš„é—®é¢˜ã€‚æˆ‘ä»¬å°†é‡åˆ°ä¸€äº›éœ€è¦è€ƒè™‘çš„é™åˆ¶ï¼Œå¦‚æœåœ¨é«˜é£é™©æƒ…å†µä¸‹ä½¿ç”¨è¿™ç§æŠ€æœ¯çš„è¯ã€‚
- en: FEMA Disaster Preparation and Safety PDF Documents
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: FEMAç¾å®³å‡†å¤‡å’Œå®‰å…¨PDFæ–‡æ¡£
- en: For this study, I downloaded 34 PDFs from FEMA (listed [here](https://github.com/datakind/stay_safe_bot/blob/main/docs_data/fema_docs.csv))
    which cover a wide range of disaster-related topics for preparing and reacting
    to emergencies such as wildfires, tornadoes, floods, earthquakes, and winter storms.
    This isnâ€™t the full set of amazing resources FEMA offer, but should suffice to
    test our chat interface.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¿™é¡¹ç ”ç©¶ï¼Œæˆ‘ä»FEMAä¸‹è½½äº†34ä¸ªPDFæ–‡ä»¶ï¼ˆ[åˆ—è¡¨åœ¨è¿™é‡Œ](https://github.com/datakind/stay_safe_bot/blob/main/docs_data/fema_docs.csv)ï¼‰ï¼Œè¿™äº›æ–‡ä»¶æ¶µç›–äº†å¹¿æ³›çš„ç¾å®³ç›¸å…³è¯é¢˜ï¼ŒåŒ…æ‹¬å¦‚ä½•å‡†å¤‡å’Œåº”å¯¹é‡ç«ã€é¾™å·é£ã€æ´ªæ°´ã€åœ°éœ‡å’Œå†¬å­£é£æš´ã€‚è¿™ä¸æ˜¯FEMAæä¾›çš„æ‰€æœ‰æƒŠäººèµ„æºï¼Œä½†åº”è¯¥è¶³å¤Ÿæµ‹è¯•æˆ‘ä»¬çš„èŠå¤©ç•Œé¢ã€‚
- en: Indexing Documents For Information Retrieval
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç´¢å¼•æ–‡æ¡£ä»¥è¿›è¡Œä¿¡æ¯æ£€ç´¢
- en: Once downloaded, we can use LangChain to read the PDF documents. Documents are
    split into chunks of text, and each is given a fingerprint (embeddings) using
    an embedding model. In this analysis, we will use [OpenAIâ€™s embeddings](https://platform.openai.com/docs/guides/embeddings),
    but LangChain supports [many others](https://python.langchain.com/docs/integrations/text_embedding/).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹è½½åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨LangChainè¯»å–PDFæ–‡æ¡£ã€‚æ–‡æ¡£è¢«åˆ†å‰²æˆæ–‡æœ¬å—ï¼Œå¹¶ä½¿ç”¨åµŒå…¥æ¨¡å‹ç»™æ¯ä¸ªå—åˆ†é…ä¸€ä¸ªæŒ‡çº¹ï¼ˆåµŒå…¥ï¼‰ã€‚åœ¨è¿™é¡¹åˆ†æä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨[OpenAIçš„åµŒå…¥](https://platform.openai.com/docs/guides/embeddings)ï¼Œä½†LangChainæ”¯æŒ[è®¸å¤šå…¶ä»–æ¨¡å‹](https://python.langchain.com/docs/integrations/text_embedding/)ã€‚
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Looking at data extracted for one document [https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf](https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf)
    â€¦
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹ä¸ºä¸€ä¸ªæ–‡æ¡£æå–çš„æ•°æ®[https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf](https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf)
    â€¦
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We can see that it has split the document by page. As it happens this is not
    an unreasonable approach for the FEMA documents we are processing, which are very
    concise guides where each page is a discrete topic, but for other applications,
    it is usually better to split text at a more granular level using [LangChainâ€™s
    text_splitter](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒæŒ‰é¡µé¢æ‹†åˆ†äº†æ–‡æ¡£ã€‚å®é™…ä¸Šï¼Œè¿™å¯¹äºæˆ‘ä»¬æ­£åœ¨å¤„ç†çš„ FEMA æ–‡æ¡£å¹¶éä¸åˆç†ï¼Œè¿™äº›æ–‡æ¡£éå¸¸ç®€æ´ï¼Œæ¯é¡µéƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ä¸»é¢˜ï¼Œä½†å¯¹äºå…¶ä»–åº”ç”¨ï¼Œé€šå¸¸æ›´å¥½çš„æ˜¯åœ¨æ›´ç»†çš„çº§åˆ«æ‹†åˆ†æ–‡æœ¬ï¼Œä½¿ç”¨[LangChain
    çš„ text_splitter](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa)ã€‚
- en: We can now use our text excerpts to create a database of embeddings â€¦
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å¯ä»¥ä½¿ç”¨æˆ‘ä»¬çš„æ–‡æœ¬æ‘˜å½•æ¥åˆ›å»ºåµŒå…¥æ•°æ®åº“...
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We have chosen a simple option to persist the embeddings to the file system,
    but itâ€™s worth noting that [Chroma supports more options](https://python.langchain.com/docs/integrations/vectorstores/chroma)
    should you have a large number of documents, where performance may be an issue.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€‰æ‹©äº†ä¸€ä¸ªç®€å•çš„é€‰é¡¹å°†åµŒå…¥æŒä¹…åŒ–åˆ°æ–‡ä»¶ç³»ç»Ÿï¼Œä½†å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œ[Chroma æ”¯æŒæ›´å¤šé€‰é¡¹](https://python.langchain.com/docs/integrations/vectorstores/chroma)ï¼Œå¦‚æœä½ æœ‰å¤§é‡æ–‡æ¡£ï¼Œæ€§èƒ½å¯èƒ½æ˜¯ä¸€ä¸ªé—®é¢˜ã€‚
- en: Setting up our conversational interface
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è®¾ç½®æˆ‘ä»¬çš„å¯¹è¯ç•Œé¢
- en: We will use just one PDF to start with so itâ€™s easier to verify results â€¦
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†é¦–å…ˆä½¿ç”¨ä¸€ä¸ª PDFï¼Œè¿™æ ·æ›´å®¹æ˜“éªŒè¯ç»“æœ...
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In the above, we have chosen GPT-4 for the chat model where the API key was
    defined in a `.env` file with variable `OPENAI_API_KEY.` LangChain offers support
    for [many other](https://python.langchain.com/docs/integrations/chat/) models
    also.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šè¿°å†…å®¹ä¸­ï¼Œæˆ‘ä»¬é€‰æ‹©äº† GPT-4 ä½œä¸ºèŠå¤©æ¨¡å‹ï¼Œå…¶ä¸­ API å¯†é’¥åœ¨ `.env` æ–‡ä»¶ä¸­å®šä¹‰ï¼Œå˜é‡ä¸º `OPENAI_API_KEY`ã€‚LangChain
    è¿˜æ”¯æŒ[è®¸å¤šå…¶ä»–](https://python.langchain.com/docs/integrations/chat/)æ¨¡å‹ã€‚
- en: With just a few lines of code, we have set up a conversational interface onto
    a set of documents, which includes all the power of LLMs. I have developed chatbots
    over the years and can say that this concise pattern reduces a LOT of complexity.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: åªéœ€å‡ è¡Œä»£ç ï¼Œæˆ‘ä»¬å°±å»ºç«‹äº†ä¸€ä¸ªå¯¹æ–‡æ¡£çš„å¯¹è¯ç•Œé¢ï¼Œè¿™åŒ…æ‹¬äº† LLM çš„æ‰€æœ‰åŠŸèƒ½ã€‚æˆ‘å¤šå¹´æ¥å¼€å‘äº†èŠå¤©æœºå™¨äººï¼Œå¯ä»¥è¯´è¿™ç§ç®€æ´çš„æ¨¡å¼å¤§å¤§å‡å°‘äº†å¤æ‚æ€§ã€‚
- en: Kudos to the amazing LangChain package!
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹å‡ºè‰²çš„ LangChain åŒ…è‡´ä»¥èµèª‰ï¼
- en: Asking our first question
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æå‡ºæˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªé—®é¢˜
- en: Since we would also like to see the documents referenced in order to validate
    chat responses, we need to make a slight adjustment to a LangChain method in order
    to account for an issue when retrieving matched documents when also using chat
    memory (The solution was suggested [here](https://github.com/langchain-ai/langchain/issues/2256#issuecomment-1665188576))
    ...
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬è¿˜å¸Œæœ›æŸ¥çœ‹å¼•ç”¨çš„æ–‡æ¡£ä»¥éªŒè¯èŠå¤©å“åº”ï¼Œæˆ‘ä»¬éœ€è¦å¯¹ LangChain æ–¹æ³•è¿›è¡Œä¸€äº›è°ƒæ•´ï¼Œä»¥è§£å†³åœ¨ä½¿ç”¨èŠå¤©è®°å¿†æ—¶æ£€ç´¢åŒ¹é…æ–‡æ¡£æ—¶å‡ºç°çš„é—®é¢˜ï¼ˆè§£å†³æ–¹æ¡ˆå·²åœ¨[è¿™é‡Œ](https://github.com/langchain-ai/langchain/issues/2256#issuecomment-1665188576)å»ºè®®ï¼‰...
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: OK, now we are ready to ask a question about our one PDF document!
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œç°åœ¨æˆ‘ä»¬å‡†å¤‡å¥½å¯¹æˆ‘ä»¬çš„ä¸€ä¸ª PDF æ–‡æ¡£æé—®äº†ï¼
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: That seems very reasonable, letâ€™s see what content was used to generate this
    summary â€¦
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼¼ä¹å¾ˆåˆç†ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ç”¨äºç”Ÿæˆæ­¤æ‘˜è¦çš„å†…å®¹...
- en: '[PRE9]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The answer *looks* great and has summarized brilliantly the excerpts that were
    matched. However, it seems to have missed a page in the [source document](https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf).
    This PDF is a short document where **everything** in it is relevant to flood preparation,
    so losing pages is actually significant.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆ*çœ‹èµ·æ¥*å¾ˆæ£’ï¼Œå¹¶ä¸”å‡ºè‰²åœ°æ€»ç»“äº†åŒ¹é…çš„æ‘˜å½•ã€‚ç„¶è€Œï¼Œå®ƒä¼¼ä¹é—æ¼äº† [æºæ–‡æ¡£](https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf)ä¸­çš„ä¸€é¡µã€‚è¿™ä¸ª
    PDF æ˜¯ä¸€ä¸ªç®€çŸ­çš„æ–‡æ¡£ï¼Œå…¶ä¸­**æ‰€æœ‰å†…å®¹**éƒ½ä¸æ´ªæ°´å‡†å¤‡æœ‰å…³ï¼Œå› æ­¤é—æ¼é¡µé¢å®é™…ä¸Šæ˜¯å¾ˆé‡è¦çš„ã€‚
- en: It goes to show that blindly accepting LLM patterns on the web may give amazing-looking
    results, but work is needed to make them truly useful.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è¡¨æ˜ï¼Œç›²ç›®æ¥å—ç½‘ç»œä¸Šçš„ LLM æ¨¡å¼å¯èƒ½ä¼šå¾—åˆ°çœ‹èµ·æ¥å¾ˆæ£’çš„ç»“æœï¼Œä½†éœ€è¦è¿›è¡Œå·¥ä½œæ‰èƒ½ä½¿å…¶çœŸæ­£æœ‰ç”¨ã€‚
- en: Document Context (Metadata) Can Be Important
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ–‡æ¡£ä¸Šä¸‹æ–‡ï¼ˆå…ƒæ•°æ®ï¼‰å¯èƒ½å¾ˆé‡è¦
- en: For this scenario, we have a document that relates to one topic, flooding, even
    if individual text sections might not mention it explicitly. We might get better
    results if we provide some context with each text excerpt, ie some document metadata.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªä¸ä¸€ä¸ªä¸»é¢˜ç›¸å…³çš„æ–‡æ¡£ï¼Œå³æ´ªæ°´ï¼Œå³ä½¿ä¸ªåˆ«æ–‡æœ¬éƒ¨åˆ†å¯èƒ½æ²¡æœ‰æ˜ç¡®æåˆ°å®ƒã€‚å¦‚æœæˆ‘ä»¬åœ¨æ¯ä¸ªæ–‡æœ¬æ‘˜å½•ä¸­æä¾›ä¸€äº›ä¸Šä¸‹æ–‡ï¼Œå³ä¸€äº›æ–‡æ¡£å…ƒæ•°æ®ï¼Œå¯èƒ½ä¼šè·å¾—æ›´å¥½çš„ç»“æœã€‚
- en: For our simple test, letâ€™s try prefixing all text excerpts with the filename
    (fema-protect-your-home-flooding.pdf) with punctuation and suffix removed, plus
    a text saying â€œThis snippet relates toâ€. The final prefix will be â€œThis snippet
    relates to fema protect your home flooding:â€, which provides the LLM a bit more
    context â€¦
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæˆ‘ä»¬çš„ç®€å•æµ‹è¯•ï¼Œè¯•ç€å°†æ‰€æœ‰æ–‡æœ¬æ‘˜å½•å‰ç¼€åŠ ä¸Šæ–‡ä»¶åï¼ˆfema-protect-your-home-flooding.pdfï¼‰ï¼Œå»æ‰æ ‡ç‚¹å’Œåç¼€ï¼Œå†åŠ ä¸Šâ€œæ­¤æ‘˜å½•ç›¸å…³äºâ€è¿™æ®µæ–‡å­—ã€‚æœ€ç»ˆå‰ç¼€å°†æ˜¯â€œæ­¤æ‘˜å½•ç›¸å…³äº
    fema protect your home flooding:â€ï¼Œè¿™ä¸ºLLMæä¾›äº†æ›´å¤šçš„èƒŒæ™¯ä¿¡æ¯â€¦â€¦
- en: '[PRE10]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Bingo! That does now seem to have captured the important pages from the PDF
    and summarized them nicely. Obviously, a very crude approach, a more formal method
    using metadata instead of just the filename would be better. It might also be
    more elegant to [use a template](https://github.com/langchain-ai/langchain/issues/1136)
    rather than just prefixing, but it does illustrate how a little context like this
    can help.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: æˆåŠŸäº†ï¼è¿™ä¼¼ä¹ç¡®å®æ•è·äº†PDFä¸­çš„é‡è¦é¡µé¢ï¼Œå¹¶å¾ˆå¥½åœ°æ€»ç»“äº†å®ƒä»¬ã€‚æ˜¾ç„¶ï¼Œè¿™æ˜¯ä¸€ç§éå¸¸ç²—ç•¥çš„æ–¹æ³•ï¼Œä½¿ç”¨å…ƒæ•°æ®è€Œä¸ä»…ä»…æ˜¯æ–‡ä»¶åçš„æ›´æ­£å¼æ–¹æ³•ä¼šæ›´å¥½ã€‚ä½¿ç”¨[æ¨¡æ¿](https://github.com/langchain-ai/langchain/issues/1136)å¯èƒ½ä¹Ÿæ›´ä¼˜é›…ï¼Œè€Œä¸ä»…ä»…æ˜¯å‰ç¼€ï¼Œä½†å®ƒç¡®å®å±•ç¤ºäº†è¿™æ ·ä¸€ç‚¹èƒŒæ™¯å¦‚ä½•å¸®åŠ©ã€‚
- en: What about if we now use all documents in our set â€¦
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆå¦‚æœæˆ‘ä»¬ç°åœ¨ä½¿ç”¨æ‰€æœ‰æ–‡æ¡£é›†ä¸­çš„æ–‡æ¡£å‘¢â€¦â€¦
- en: '[PRE12]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Thatâ€™s done a great job, it surfaced information from our key articles in [https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf](https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf),
    plus an article from [https://www.fema.gov/sites/default/files/documents/fema_protect-your-property-storm-surge.pdf](https://www.fema.gov/sites/default/files/documents/fema_protect-your-property-storm-surge.pdf),
    the only other document in the set which mentions flooding.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: åšå¾—å¾ˆå¥½ï¼Œå®ƒä»[https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf](https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf)ä¸­çš„å…³é”®æ–‡ç« æå–äº†ä¿¡æ¯ï¼Œè¿˜åŒ…æ‹¬[https://www.fema.gov/sites/default/files/documents/fema_protect-your-property-storm-surge.pdf](https://www.fema.gov/sites/default/files/documents/fema_protect-your-property-storm-surge.pdf)ä¸­çš„ä¸€ç¯‡æ–‡ç« ï¼Œè¿™æ˜¯æ–‡æ¡£é›†ä¸­å”¯ä¸€æåˆ°æ´ªæ°´çš„å…¶ä»–æ–‡æ¡£ã€‚
- en: Retrieval Prompt Length
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ£€ç´¢æç¤ºé•¿åº¦
- en: At this point, itâ€™s worth noting that the final summarization prompt which turns
    document excerpts into a nice answer can be quite long depending on the size and
    number of excerpts. A continual battle with LLMs is to achieve our goals without
    breaching token limits. Though it hasnâ€™t had a significant effect for our use
    case, other scenarios might need to employ [contextual compression methods](https://blog.langchain.dev/improving-document-retrieval-with-contextual-compression/).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æ—¶ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæœ€ç»ˆçš„æ€»ç»“æç¤ºå°†æ–‡æ¡£æ‘˜å½•è½¬åŒ–ä¸ºæ¼‚äº®çš„ç­”æ¡ˆå¯èƒ½ä¼šç›¸å½“é•¿ï¼Œå…·ä½“å–å†³äºæ‘˜å½•çš„å¤§å°å’Œæ•°é‡ã€‚ä¸LLMçš„æŒç»­æˆ˜æ–—æ˜¯å®ç°æˆ‘ä»¬çš„ç›®æ ‡è€Œä¸è¶…å‡ºä»¤ç‰Œé™åˆ¶ã€‚å°½ç®¡å¯¹æˆ‘ä»¬çš„ç”¨ä¾‹æ²¡æœ‰é‡å¤§å½±å“ï¼Œä½†å…¶ä»–åœºæ™¯å¯èƒ½éœ€è¦é‡‡ç”¨[ä¸Šä¸‹æ–‡å‹ç¼©æ–¹æ³•](https://blog.langchain.dev/improving-document-retrieval-with-contextual-compression/)ã€‚
- en: Question Context Can Be Important
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é—®é¢˜èƒŒæ™¯å¯èƒ½å¾ˆé‡è¦
- en: We intentionally mixed documents related to (i) **planning** for disasters,
    and (ii) **reacting immediately** to dangerous events. This can result in confusing
    responses that mix both contexts â€¦
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ•…æ„æ··åˆäº†ä¸ï¼ˆiï¼‰**ç¾å®³è§„åˆ’**å’Œï¼ˆiiï¼‰**ç«‹å³ååº”**ç›¸å…³çš„æ–‡æ¡£ã€‚è¿™å¯èƒ½ä¼šå¯¼è‡´æ··æ·†çš„å“åº”ï¼Œå°†ä¸¤ç§èƒŒæ™¯æ··åˆåœ¨ä¸€èµ·â€¦â€¦
- en: '[PRE14]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The answer is now a bit of a mixed bag, with some points relating to immediate
    action â€œMove your car to higher groundâ€ and some to preparation â€œPurchase flood
    insuranceâ€. When people are stressed during an emergency, they probably arenâ€™t
    thinking of prompt engineering and so we can expect slightly ambiguous inputs.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨çš„ç­”æ¡ˆæœ‰ç‚¹æ··ä¹±ï¼Œæœ‰äº›ç‚¹æ¶‰åŠç«‹å³è¡ŒåŠ¨â€œå°†ä½ çš„è½¦ç§»åˆ°é«˜åœ°â€ï¼Œæœ‰äº›ç‚¹æ¶‰åŠå‡†å¤‡â€œè´­ä¹°æ´ªæ°´ä¿é™©â€ã€‚å½“äººä»¬åœ¨ç´§æ€¥æƒ…å†µä¸‹æ„Ÿåˆ°å‹åŠ›æ—¶ï¼Œä»–ä»¬å¯èƒ½ä¸ä¼šè€ƒè™‘å³æ—¶å·¥ç¨‹ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥æœŸå¾…ç¨å¾®æ¨¡ç³Šçš„è¾“å…¥ã€‚
- en: We could of course solve this problem by using more document metadata to split
    into sub-groups, but this requires work if that metadata is not available. Another
    option is to provide more context to the question to indicate if the user is interested
    in disaster preparation, or needs help immediately. We could build a classifier
    for this, but in these days of powerful LLMs letâ€™s use zero-shot classification
    with GPT-4 â€¦
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨æ›´å¤šçš„æ–‡æ¡£å…ƒæ•°æ®æ¥å°†å…¶æ‹†åˆ†ä¸ºå­ç»„æ¥è§£å†³æ­¤é—®é¢˜ï¼Œä½†å¦‚æœæ²¡æœ‰è¿™äº›å…ƒæ•°æ®ï¼Œåˆ™éœ€è¦å·¥ä½œã€‚å¦ä¸€ç§é€‰æ‹©æ˜¯å‘é—®é¢˜æä¾›æ›´å¤šèƒŒæ™¯ï¼Œä»¥æŒ‡ç¤ºç”¨æˆ·æ˜¯å¦å¯¹ç¾å®³å‡†å¤‡æ„Ÿå…´è¶£ï¼Œæˆ–éœ€è¦ç«‹å³å¸®åŠ©ã€‚æˆ‘ä»¬å¯ä»¥ä¸ºæ­¤å»ºç«‹ä¸€ä¸ªåˆ†ç±»å™¨ï¼Œä½†åœ¨è¿™äº›å¼ºå¤§çš„LLMæ—¶ä»£ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨GPT-4çš„é›¶æ ·æœ¬åˆ†ç±»â€¦â€¦
- en: '[PRE16]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Nice! With very minimal effort, we can easily determine whether a question relates
    to planning or taking immediate action.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå¥½ï¼åªéœ€å¾ˆå°‘çš„åŠªåŠ›ï¼Œæˆ‘ä»¬å°±å¯ä»¥è½»æ¾ç¡®å®šé—®é¢˜æ˜¯æ¶‰åŠè§„åˆ’è¿˜æ˜¯ç«‹å³è¡ŒåŠ¨ã€‚
- en: We can now prefix the user question with this â€¦
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥ç”¨è¿™ä¸ªå‰ç¼€æ¥å‰ç½®ç”¨æˆ·é—®é¢˜â€¦â€¦
- en: '[PRE18]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Which gives â€¦
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç»™â€¦â€¦
- en: '[PRE19]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Great, worked nicely and didnâ€™t try to sell us any insurance, it gave advice
    that could be acted upon immediately.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå¥½ï¼Œæ•ˆæœå¾ˆå¥½ï¼Œæ²¡æœ‰è¯•å›¾æ¨é”€ä»»ä½•ä¿é™©ï¼Œç»™å‡ºçš„å»ºè®®å¯ä»¥ç«‹å³ä»˜è¯¸å®è·µã€‚
- en: Letâ€™s test the converse â€¦
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æµ‹è¯•ä¸€ä¸‹åå‘æƒ…å†µâ€¦
- en: '[PRE20]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Perfect, it provided forest fire preparation information.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: å®Œç¾ï¼Œå®ƒæä¾›äº†æ£®æ—ç«ç¾å‡†å¤‡ä¿¡æ¯ã€‚
- en: Obviously, this would need a lot of testing for anything high-risk that could
    be used in a real emergency, but it illustrates one way we can enhance performance
    by enriching the userâ€™s prompt.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¾ç„¶ï¼Œè¿™éœ€è¦å¯¹ä»»ä½•é«˜é£é™©çš„çœŸå®ç´§æ€¥æƒ…å†µè¿›è¡Œå¤§é‡æµ‹è¯•ï¼Œä½†å®ƒè¯´æ˜äº†æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸°å¯Œç”¨æˆ·çš„æç¤ºæ¥æå‡æ€§èƒ½çš„ä¸€ç§æ–¹æ³•ã€‚
- en: Making Sure Answers Only Come from the Provided Documents
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¡®ä¿ç­”æ¡ˆä»…æ¥è‡ªæä¾›çš„æ–‡æ¡£
- en: For an application where the information can affect safety, itâ€™s important that
    the information presented *only* comes from the documents provided. Hallucinations
    containing incorrect information could have some really dire effects.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä¸€ä¸ªä¿¡æ¯å¯èƒ½å½±å“å®‰å…¨æ€§çš„åº”ç”¨ç¨‹åºï¼Œç¡®ä¿æä¾›çš„ä¿¡æ¯*ä»…*æ¥è‡ªæä¾›çš„æ–‡æ¡£æ˜¯éå¸¸é‡è¦çš„ã€‚åŒ…å«é”™è¯¯ä¿¡æ¯çš„å¹»è§‰å¯èƒ½ä¼šäº§ç”Ÿéå¸¸ä¸¥é‡çš„åæœã€‚
- en: Letâ€™s try asking something totally unrelated to disasters â€¦
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å°è¯•é—®ä¸€äº›ä¸ç¾éš¾å®Œå…¨æ— å…³çš„é—®é¢˜â€¦
- en: '[PRE22]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Which gives â€¦
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼šæä¾›â€¦
- en: '[PRE23]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Though I am a bit sad not finding out how to make some yummy cake, LangChain
    took care of this scenario nicely and determines that the question does not relate
    to the information in the PDF guides provided.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶æˆ‘æœ‰ç‚¹é—æ†¾æ²¡èƒ½æ‰¾åˆ°å¦‚ä½•åšä¸€äº›ç¾å‘³çš„è›‹ç³•ï¼Œä½† LangChain å¾ˆå¥½åœ°å¤„ç†äº†è¿™ä¸ªåœºæ™¯ï¼Œå¹¶åˆ¤æ–­å‡ºé—®é¢˜ä¸æä¾›çš„ PDF æŒ‡å—ä¸­çš„ä¿¡æ¯æ— å…³ã€‚
- en: Thatâ€™s good, no major hallucinations! The last thing Iâ€™d want in a disaster
    is to be told to make a sponge cake and fly a spaceship or something. ğŸ˜Š
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå¥½ï¼Œæ²¡æœ‰é‡å¤§å¹»è§‰ï¼åœ¨ç¾éš¾ä¸­ï¼Œæˆ‘æœ€ä¸å¸Œæœ›çš„å°±æ˜¯è¢«å‘ŠçŸ¥å»åšæµ·ç»µè›‹ç³•æˆ–é£å®‡å®™é£èˆ¹ä¹‹ç±»çš„äº‹ã€‚ğŸ˜Š
- en: Conversation History
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¯¹è¯å†å²
- en: One great feature of LangChain is that it seamlessly takes care of conversation
    history. With one line of code, the model can pick up on previous questions â€¦
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain çš„ä¸€ä¸ªå¾ˆæ£’çš„åŠŸèƒ½æ˜¯å®ƒæ— ç¼åœ°å¤„ç†å¯¹è¯å†å²ã€‚åªéœ€ä¸€è¡Œä»£ç ï¼Œæ¨¡å‹å°±èƒ½æ‹¾èµ·ä¹‹å‰çš„é—®é¢˜â€¦
- en: '[PRE24]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Then ask it a question referring to â€˜Itâ€™ (the hurricane) â€¦
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åé—®å®ƒä¸€ä¸ªæŒ‡å‘â€œå®ƒâ€ï¼ˆé£“é£ï¼‰çš„æé—®â€¦
- en: '[PRE25]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Perfect, it maintains a history and knows what Iâ€™m referring to. Under pressure,
    one might expect a user to ask follow-up questions, so this ability â€” implemented
    with 2 lines of code! â€” is very important.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: å®Œç¾ï¼Œå®ƒä¿æŒäº†å†å²è®°å½•ï¼Œå¹¶çŸ¥é“æˆ‘åœ¨æŒ‡ä»€ä¹ˆã€‚åœ¨å‹åŠ›ä¸‹ï¼Œç”¨æˆ·å¯èƒ½ä¼šæå‡ºåç»­é—®é¢˜ï¼Œå› æ­¤è¿™ç§èƒ½åŠ›â€”â€”ç”¨ 2 è¡Œä»£ç å®ç°ï¼â€”â€”æ˜¯éå¸¸é‡è¦çš„ã€‚
- en: Translation
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¿»è¯‘
- en: To make the chatbot more versatile, we can explore multilingual support. Many
    major LLMs such as [GPT-4 offer native support for top languages](https://openai.com/research/gpt-4),
    but performance can vary depending on the language.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä½¿èŠå¤©æœºå™¨äººæ›´åŠ å¤šåŠŸèƒ½ï¼Œæˆ‘ä»¬å¯ä»¥æ¢ç´¢å¤šè¯­è¨€æ”¯æŒã€‚è®¸å¤šä¸»è¦çš„ LLMï¼Œå¦‚ [GPT-4 æä¾›äº†å¯¹ä¸»è¦è¯­è¨€çš„æœ¬åœ°æ”¯æŒ](https://openai.com/research/gpt-4)ï¼Œä½†æ€§èƒ½å¯èƒ½ä¼šå› è¯­è¨€è€Œå¼‚ã€‚
- en: Letâ€™s start with Portuguese â€¦
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»è‘¡è„ç‰™è¯­å¼€å§‹â€¦
- en: '[PRE26]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Which is the right information. However, with Swahili â€¦
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: å“ªä¸ªä¿¡æ¯æ˜¯æ­£ç¡®çš„ã€‚ç„¶è€Œï¼Œå¯¹äºæ–¯ç“¦å¸Œé‡Œè¯­â€¦
- en: '[PRE28]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The results *look* very plausible but are missing important information. Text
    excerpts matched are missing some key flood sections and we also have snippets
    related to wildfires when we asked about floods. Basically, using embeddings created
    from English documents with Swahili questions doesnâ€™t perform well. Not unreasonable,
    though it did work well for a Latin language Portuguese.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœ*çœ‹èµ·æ¥*éå¸¸å¯ä¿¡ï¼Œä½†ç¼ºå°‘é‡è¦ä¿¡æ¯ã€‚åŒ¹é…çš„æ–‡æœ¬æ‘˜å½•ç¼ºå°‘ä¸€äº›å…³é”®çš„æ´ªæ°´éƒ¨åˆ†ï¼Œå½“æˆ‘ä»¬è¯¢é—®æ´ªæ°´æ—¶ï¼Œè¿˜å¾—åˆ°äº†ä¸é‡ç«ç›¸å…³çš„ç‰‡æ®µã€‚åŸºæœ¬ä¸Šï¼Œä½¿ç”¨ä»è‹±è¯­æ–‡æ¡£åˆ›å»ºçš„åµŒå…¥æ¥å¤„ç†æ–¯ç“¦å¸Œé‡Œè¯­é—®é¢˜æ•ˆæœä¸å¥½ã€‚ä¸è¿‡ï¼Œä½¿ç”¨æ‹‰ä¸è¯­è¨€çš„è‘¡è„ç‰™è¯­æ•ˆæœå¾ˆå¥½ï¼Œè¿™å¹¶ä¸ä»¤äººæ„å¤–ã€‚
- en: Perhaps a more robust approach would be to first detect language and translate
    it into English with [Google Translate](https://translate.google.com/), then convert
    the response back into the prompt language.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿè®¸æ›´ç¨³å¥çš„æ–¹æ³•æ˜¯å…ˆæ£€æµ‹è¯­è¨€ï¼Œå†ç”¨ [Google Translate](https://translate.google.com/) å°†å…¶ç¿»è¯‘æˆè‹±è¯­ï¼Œç„¶åå°†å“åº”è½¬æ¢å›æç¤ºè¯­è¨€ã€‚
- en: Letâ€™s add this to our chat interface â€¦
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å°†è¿™ä¸ªæ·»åŠ åˆ°æˆ‘ä»¬çš„èŠå¤©ç•Œé¢ä¸­â€¦
- en: '[PRE30]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Much better, using Google Translate to translate Swahili automatically to English
    and then translating the answer back to Swahili gives us all the required information
    from our set of PDFs. For a risk-critical use-case like disaster response, this
    would need a LOT of testing with native speakers to ensure safety of course, but
    it shows promise towards being multilingual.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å¥½ï¼Œä½¿ç”¨ Google Translate å°†æ–¯ç“¦å¸Œé‡Œè¯­è‡ªåŠ¨ç¿»è¯‘æˆè‹±è¯­ï¼Œç„¶åå°†å›ç­”ç¿»è¯‘å›æ–¯ç“¦å¸Œé‡Œè¯­ï¼Œèƒ½ä»æˆ‘ä»¬çš„ PDF æ–‡ä»¶é›†ä¸­è·å¾—æ‰€æœ‰æ‰€éœ€çš„ä¿¡æ¯ã€‚å¯¹äºç¾éš¾å“åº”ç­‰é£é™©å…³é”®çš„ç”¨ä¾‹ï¼Œå½“ç„¶éœ€è¦ä¸æ¯è¯­è€…è¿›è¡Œå¤§é‡æµ‹è¯•ä»¥ç¡®ä¿å®‰å…¨ï¼Œä½†è¿™åœ¨å¤šè¯­è¨€æ”¯æŒæ–¹é¢æ˜¾ç¤ºå‡ºäº†å‰æ™¯ã€‚
- en: Asking a Wider Set of Questions
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æå‡ºæ›´å¹¿æ³›çš„é—®é¢˜
- en: OK, letâ€™s take the final version for a spin and ask more disaster-related questions
    â€¦
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œè®©æˆ‘ä»¬è¯•ç”¨ä¸€ä¸‹æœ€ç»ˆç‰ˆæœ¬ï¼Œæå‡ºæ›´å¤šä¸ç¾éš¾ç›¸å…³çš„é—®é¢˜â€¦â€¦
- en: '[PRE32]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: I think those are pretty amazing, spot checking a few and they seem to capture
    key content in the PDF documents used.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºè¿™äº›éå¸¸æƒŠäººï¼ŒæŠ½æŸ¥äº†ä¸€äº›ï¼Œå®ƒä»¬ä¼¼ä¹èƒ½å¤Ÿæ•æ‰åˆ°æ‰€ç”¨PDFæ–‡æ¡£ä¸­çš„å…³é”®ä¿¡æ¯ã€‚
- en: '[ Based on the above, my disaster kit now has Ear plugs! ]'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[åŸºäºä¸Šè¿°å†…å®¹ï¼Œæˆ‘çš„ç¾éš¾åŒ…ç°åœ¨æœ‰è€³å¡äº†ï¼]'
- en: Evaluating Performance
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ€§èƒ½è¯„ä¼°
- en: In this analysis, we have only spot-checked how well our chat interface is returning
    critical information for a small set of FEMA PDF documents. This is good to illustrate
    some concepts, but for a production application, we would need something better
    than spot-checking. Luckily, LangChain has provided a set of [evaluators](https://python.langchain.com/docs/guides/evaluation/),
    and of particular interest is a [Streamlit application](https://blog.langchain.dev/auto-eval-of-question-answering-tasks/)
    that generates question-answer pairs automatically and then uses these to evaluate
    retrieval chains, allowing developers to experiment with some of the parameters
    involved. I havenâ€™t yet tried this yet, but the idea of generating evaluation
    data automatically using LLMs seems a great way to build scaffolding for a more
    systematic approach for testing our FEMA disaster bot.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é¡¹åˆ†æä¸­ï¼Œæˆ‘ä»¬ä»…ä»…å¯¹æˆ‘ä»¬çš„èŠå¤©ç•Œé¢åœ¨è¿”å›ä¸€å°éƒ¨åˆ†FEMA PDFæ–‡æ¡£çš„å…³é”®ä¿¡æ¯æ–¹é¢è¿›è¡Œäº†æŠ½æŸ¥ã€‚è¿™å¯¹äºè¯´æ˜ä¸€äº›æ¦‚å¿µæ˜¯æœ‰å¸®åŠ©çš„ï¼Œä½†å¯¹äºç”Ÿäº§åº”ç”¨ç¨‹åºï¼Œæˆ‘ä»¬éœ€è¦æ¯”æŠ½æŸ¥æ›´å¥½çš„æ–¹æ³•ã€‚å¹¸è¿çš„æ˜¯ï¼ŒLangChain
    æä¾›äº†ä¸€ç»„[è¯„ä¼°å·¥å…·](https://python.langchain.com/docs/guides/evaluation/)ï¼Œç‰¹åˆ«å€¼å¾—å…³æ³¨çš„æ˜¯ä¸€ä¸ª[Streamlit
    åº”ç”¨](https://blog.langchain.dev/auto-eval-of-question-answering-tasks/)ï¼Œå®ƒå¯ä»¥è‡ªåŠ¨ç”Ÿæˆé—®ç­”å¯¹ï¼Œç„¶ååˆ©ç”¨è¿™äº›æ•°æ®æ¥è¯„ä¼°æ£€ç´¢é“¾ï¼Œä»è€Œå…è®¸å¼€å‘è€…å®éªŒä¸€äº›ç›¸å…³çš„å‚æ•°ã€‚æˆ‘è¿˜æ²¡æœ‰å°è¯•è¿‡ï¼Œä½†ä½¿ç”¨LLMè‡ªåŠ¨ç”Ÿæˆè¯„ä¼°æ•°æ®çš„æƒ³æ³•ä¼¼ä¹æ˜¯ä¸ºæµ‹è¯•æˆ‘ä»¬çš„FEMAç¾éš¾æœºå™¨äººæ„å»ºæ›´ç³»ç»ŸåŒ–æ–¹æ³•çš„å¥½åŠæ³•ã€‚
- en: Conclusions
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: Using a set of 34 PDF documents on the FEMA website, we were easily able to
    build a multilingual conversational interface using LangChain and GPT-4 that was
    able to answer a wide range of questions related to disaster preparedness and
    safety protocols. However, using this common document retrieval LangChain pattern
    for a high-risk safety critical chatbot faces the same challenges as found with
    semantic search. Even with advanced LLM embeddings capturing more nuance in natural
    language, itâ€™s still quite easy to *lose* important content.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨FEMAç½‘ç«™ä¸Šçš„34ä»½PDFæ–‡æ¡£ï¼Œæˆ‘ä»¬èƒ½å¤Ÿè½»æ¾åœ°æ„å»ºä¸€ä¸ªå¤šè¯­è¨€å¯¹è¯ç•Œé¢ï¼Œä½¿ç”¨LangChainå’ŒGPT-4ï¼Œèƒ½å¤Ÿå›ç­”å¹¿æ³›çš„ç¾éš¾å‡†å¤‡å’Œå®‰å…¨åè®®ç›¸å…³çš„é—®é¢˜ã€‚ç„¶è€Œï¼Œå¯¹äºé«˜é£é™©å®‰å…¨å…³é”®çš„èŠå¤©æœºå™¨äººï¼Œä½¿ç”¨è¿™ç§é€šç”¨æ–‡æ¡£æ£€ç´¢çš„LangChainæ¨¡å¼é¢ä¸´ç€ä¸è¯­ä¹‰æœç´¢ç›¸åŒçš„æŒ‘æˆ˜ã€‚å³ä½¿ä½¿ç”¨å…ˆè¿›çš„LLMåµŒå…¥æ•æ‰è‡ªç„¶è¯­è¨€ä¸­çš„æ›´å¤šç»†å¾®å·®åˆ«ï¼Œä»ç„¶å¾ˆå®¹æ˜“*ä¸¢å¤±*é‡è¦å†…å®¹ã€‚
- en: 'For our FEMA disaster bot use case, this was due to:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæˆ‘ä»¬çš„FEMAç¾éš¾æœºå™¨äººç”¨ä¾‹ï¼Œè¿™ç§æƒ…å†µæ˜¯ç”±äºï¼š
- en: '**Mixed context documents** â€” Without including document metadata, responses
    mixed information from different contexts. Simply prefixing document names improved
    performance for our scenario, and more sophisticated metadata strategies could
    be applied. Also, adding a zero-shot LLM classifier to enrich the user question
    was helpful.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ··åˆä¸Šä¸‹æ–‡æ–‡æ¡£** â€” åœ¨æ²¡æœ‰åŒ…å«æ–‡æ¡£å…ƒæ•°æ®çš„æƒ…å†µä¸‹ï¼Œå“åº”æ··åˆäº†æ¥è‡ªä¸åŒä¸Šä¸‹æ–‡çš„ä¿¡æ¯ã€‚ç®€å•åœ°åœ¨æ–‡æ¡£åç§°å‰åŠ å‰ç¼€æé«˜äº†æˆ‘ä»¬åœºæ™¯ä¸­çš„æ€§èƒ½ï¼Œå¹¶ä¸”å¯ä»¥åº”ç”¨æ›´å¤æ‚çš„å…ƒæ•°æ®ç­–ç•¥ã€‚æ­¤å¤–ï¼Œæ·»åŠ ä¸€ä¸ªé›¶æ ·æœ¬LLMåˆ†ç±»å™¨æ¥ä¸°å¯Œç”¨æˆ·é—®é¢˜ä¹Ÿæ˜¯æœ‰å¸®åŠ©çš„ã€‚'
- en: '**Underrepresented languages in LLMs** â€”Relying on LLM translation can result
    in poor performance for less well-represented languages such as Swahili. Adding
    automatic Google translation improved performance for our use case.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LLMsä¸­çš„ä½ä»£è¡¨æ€§è¯­è¨€** â€” ä¾èµ–LLMç¿»è¯‘å¯èƒ½ä¼šå¯¼è‡´å¯¹äºä»£è¡¨æ€§è¾ƒå°‘çš„è¯­è¨€ï¼ˆå¦‚æ–¯ç“¦å¸Œé‡Œè¯­ï¼‰æ€§èƒ½è¾ƒå·®ã€‚æ·»åŠ è‡ªåŠ¨Googleç¿»è¯‘æé«˜äº†æˆ‘ä»¬ç”¨ä¾‹ä¸­çš„æ€§èƒ½ã€‚'
- en: We explored crude methods to address the above issues, but for a production
    chatbot, more advanced techniques and other mitigation found through testing and
    validation would be required.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ¢ç´¢äº†ç²—ç•¥çš„æ–¹æ³•æ¥è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½†å¯¹äºç”Ÿäº§èŠå¤©æœºå™¨äººï¼Œéœ€è¦é€šè¿‡æµ‹è¯•å’ŒéªŒè¯æ‰¾åˆ°æ›´å…ˆè¿›çš„æŠ€æœ¯å’Œå…¶ä»–ç¼“è§£æªæ–½ã€‚
- en: Still though, pretty amazing what LLMs can do these days!
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡å¦‚æ­¤ï¼ŒLLMç°åœ¨èƒ½åšçš„äº‹æƒ…ç¡®å®ä»¤äººæƒŠå¹ï¼
- en: '**References**'
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**å‚è€ƒèµ„æ–™**'
- en: You can find a notebook with all code [here](https://github.com/datakind/stay_safe_bot).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/datakind/stay_safe_bot)æ‰¾åˆ°åŒ…å«æ‰€æœ‰ä»£ç çš„ç¬”è®°æœ¬ã€‚
