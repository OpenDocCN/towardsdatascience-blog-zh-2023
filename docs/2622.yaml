- en: Researching a Multilingual FEMA Disaster Bot Using LangChain and GPT-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/researching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd?source=collection_archive---------5-----------------------#2023-08-17](https://towardsdatascience.com/researching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd?source=collection_archive---------5-----------------------#2023-08-17)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Some pros and cons of Retrieval-Augmented Generation (RAG) for high-risk chat
    applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@astrobagel?source=post_page-----4591f26d8dcd--------------------------------)[![Matthew
    Harris](../Images/4fa3264bb8a028633cd8d37093c16214.png)](https://medium.com/@astrobagel?source=post_page-----4591f26d8dcd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4591f26d8dcd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4591f26d8dcd--------------------------------)
    [Matthew Harris](https://medium.com/@astrobagel?source=post_page-----4591f26d8dcd--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4a2cd25b8ff9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresearching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd&user=Matthew+Harris&userId=4a2cd25b8ff9&source=post_page-4a2cd25b8ff9----4591f26d8dcd---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4591f26d8dcd--------------------------------)
    ·54 min read·Aug 17, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4591f26d8dcd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresearching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd&user=Matthew+Harris&userId=4a2cd25b8ff9&source=-----4591f26d8dcd---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4591f26d8dcd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresearching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd&source=-----4591f26d8dcd---------------------bookmark_footer-----------)![](../Images/37138d88da2ef33806c505f6c3bcb47e.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image generated by [DALL-E2](https://openai.com/dall-e-2) using prompt “A photo
    of a raging river flooding around a robot”
  prefs: []
  type: TYPE_NORMAL
- en: '*TL;DR*'
  prefs: []
  type: TYPE_NORMAL
- en: '*In this article, we explore how to build a multilingual* [*US Federal Emergency
    Management Agency (FEMA)*](https://www.fema.gov/about) *disaster chatbot to help
    people prepare for and survive disasters such as floods, tornados, wildfires,
    earthquakes, and winter storms. A chat interface was created from 34 FEMA PDF
    documents using LangChain and GPT-4\. As amazing as this popular pattern is, care
    is needed with high-risk applications such as disaster response bots. Though Large
    Language Model (LLM) hallucinations are minimized, common issues with semantic
    search of documents can lead to critical information being excluded in chat responses.
    We tested a few simple techniques to improve performance for this specific analysis,
    such as incorporating document metadata into embeddings, enriching user questions
    with LLM zero-shot context classification, and automatic language detection and
    translation using Google Translate to better support languages like Swahili. The
    techniques applied were pretty basic, but the ability of the prototype bot to
    surface information efficiently from FEMA PDF documents shows promise. Obviously,
    testing and validation would be needed if using this technique for high-risk situations,
    ideally using automated LLM techniques to create question-and-answer validation
    data.*'
  prefs: []
  type: TYPE_NORMAL
- en: A few weeks ago we had a major flooding event in Vermont. The small brook that
    gurgles cheerfully past our house turned into a raging monster hellbent on destruction.
    Luckily we weren’t damaged badly, but sadly, many lost property and livelihoods.
    At one point during the flood, it looked like we might have to evacuate so I started
    checking the [US Federal Emergency Management Agency (FEMA)](https://www.fema.gov/about)
    website for advice. I had already prepared somewhat, but when trouble arrived
    I wanted to reconfirm a few things. FEMA has really excellent, concise resources
    in PDF documents and web pages which I started searching, but I wondered ...
  prefs: []
  type: TYPE_NORMAL
- en: '***In an emergency, is there a faster way to get helpful information that doesn’t
    require searching and reading multiple documents?***'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One obvious solution might be to ask a chatbot. I think chatbots can get a bit
    overused at times, but this does seem like a solid use case as a conversational
    interface can be more efficient when time is of the essence.
  prefs: []
  type: TYPE_NORMAL
- en: It is not a new idea, organisations such as the American Red Cross have developed
    bots like [Clara](https://www.redcross.org/get-help/disaster-relief-and-recovery-services/meet-clara.html)
    for disaster response. However, a promising new pattern has recently emerged to
    use Generative AI Large Language Models (LLMs) such as [OpenAI’s GPT-4](https://openai.com/research/gpt-4),
    [Meta’s LLAMA 2](https://ai.meta.com/llama/), and a growing plethora of models
    on [HuggingFace](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard).
    These models can be used to index a specified set of documents and interact with
    them conversationally. [Called Retrieval-Augmented Generation (RAG)](https://huggingface.co/blog/ray-rag),
    there are hundreds of tutorials on the web demonstrating it with the amazing [LangChain](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa)
    Python package and I fully expect this technique to appear soon in software we
    use every day. What’s interesting is that it restricts responses to the provided
    content and so is less prone to hallucinations which can prevent using LLMs in
    critical situations such as disaster response.
  prefs: []
  type: TYPE_NORMAL
- en: But how safe is it in cases where the information retrieved might save lives?
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I briefly explore creating a LangChain GPT-4 chat interface
    for asking questions about disaster safety based on a set of documents from the
    [US Federal Emergency Management Agency (FEMA)](https://www.fema.gov/about). We
    will encounter some of the limitations that need to be considered if using this
    technique in high-risk situations.
  prefs: []
  type: TYPE_NORMAL
- en: FEMA Disaster Preparation and Safety PDF Documents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this study, I downloaded 34 PDFs from FEMA (listed [here](https://github.com/datakind/stay_safe_bot/blob/main/docs_data/fema_docs.csv))
    which cover a wide range of disaster-related topics for preparing and reacting
    to emergencies such as wildfires, tornadoes, floods, earthquakes, and winter storms.
    This isn’t the full set of amazing resources FEMA offer, but should suffice to
    test our chat interface.
  prefs: []
  type: TYPE_NORMAL
- en: Indexing Documents For Information Retrieval
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once downloaded, we can use LangChain to read the PDF documents. Documents are
    split into chunks of text, and each is given a fingerprint (embeddings) using
    an embedding model. In this analysis, we will use [OpenAI’s embeddings](https://platform.openai.com/docs/guides/embeddings),
    but LangChain supports [many others](https://python.langchain.com/docs/integrations/text_embedding/).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Looking at data extracted for one document [https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf](https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf)
    …
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We can see that it has split the document by page. As it happens this is not
    an unreasonable approach for the FEMA documents we are processing, which are very
    concise guides where each page is a discrete topic, but for other applications,
    it is usually better to split text at a more granular level using [LangChain’s
    text_splitter](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa).
  prefs: []
  type: TYPE_NORMAL
- en: We can now use our text excerpts to create a database of embeddings …
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We have chosen a simple option to persist the embeddings to the file system,
    but it’s worth noting that [Chroma supports more options](https://python.langchain.com/docs/integrations/vectorstores/chroma)
    should you have a large number of documents, where performance may be an issue.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up our conversational interface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will use just one PDF to start with so it’s easier to verify results …
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In the above, we have chosen GPT-4 for the chat model where the API key was
    defined in a `.env` file with variable `OPENAI_API_KEY.` LangChain offers support
    for [many other](https://python.langchain.com/docs/integrations/chat/) models
    also.
  prefs: []
  type: TYPE_NORMAL
- en: With just a few lines of code, we have set up a conversational interface onto
    a set of documents, which includes all the power of LLMs. I have developed chatbots
    over the years and can say that this concise pattern reduces a LOT of complexity.
  prefs: []
  type: TYPE_NORMAL
- en: Kudos to the amazing LangChain package!
  prefs: []
  type: TYPE_NORMAL
- en: Asking our first question
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since we would also like to see the documents referenced in order to validate
    chat responses, we need to make a slight adjustment to a LangChain method in order
    to account for an issue when retrieving matched documents when also using chat
    memory (The solution was suggested [here](https://github.com/langchain-ai/langchain/issues/2256#issuecomment-1665188576))
    ...
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: OK, now we are ready to ask a question about our one PDF document!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: That seems very reasonable, let’s see what content was used to generate this
    summary …
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The answer *looks* great and has summarized brilliantly the excerpts that were
    matched. However, it seems to have missed a page in the [source document](https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf).
    This PDF is a short document where **everything** in it is relevant to flood preparation,
    so losing pages is actually significant.
  prefs: []
  type: TYPE_NORMAL
- en: It goes to show that blindly accepting LLM patterns on the web may give amazing-looking
    results, but work is needed to make them truly useful.
  prefs: []
  type: TYPE_NORMAL
- en: Document Context (Metadata) Can Be Important
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this scenario, we have a document that relates to one topic, flooding, even
    if individual text sections might not mention it explicitly. We might get better
    results if we provide some context with each text excerpt, ie some document metadata.
  prefs: []
  type: TYPE_NORMAL
- en: For our simple test, let’s try prefixing all text excerpts with the filename
    (fema-protect-your-home-flooding.pdf) with punctuation and suffix removed, plus
    a text saying “This snippet relates to”. The final prefix will be “This snippet
    relates to fema protect your home flooding:”, which provides the LLM a bit more
    context …
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Bingo! That does now seem to have captured the important pages from the PDF
    and summarized them nicely. Obviously, a very crude approach, a more formal method
    using metadata instead of just the filename would be better. It might also be
    more elegant to [use a template](https://github.com/langchain-ai/langchain/issues/1136)
    rather than just prefixing, but it does illustrate how a little context like this
    can help.
  prefs: []
  type: TYPE_NORMAL
- en: What about if we now use all documents in our set …
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: That’s done a great job, it surfaced information from our key articles in [https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf](https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf),
    plus an article from [https://www.fema.gov/sites/default/files/documents/fema_protect-your-property-storm-surge.pdf](https://www.fema.gov/sites/default/files/documents/fema_protect-your-property-storm-surge.pdf),
    the only other document in the set which mentions flooding.
  prefs: []
  type: TYPE_NORMAL
- en: Retrieval Prompt Length
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point, it’s worth noting that the final summarization prompt which turns
    document excerpts into a nice answer can be quite long depending on the size and
    number of excerpts. A continual battle with LLMs is to achieve our goals without
    breaching token limits. Though it hasn’t had a significant effect for our use
    case, other scenarios might need to employ [contextual compression methods](https://blog.langchain.dev/improving-document-retrieval-with-contextual-compression/).
  prefs: []
  type: TYPE_NORMAL
- en: Question Context Can Be Important
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We intentionally mixed documents related to (i) **planning** for disasters,
    and (ii) **reacting immediately** to dangerous events. This can result in confusing
    responses that mix both contexts …
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The answer is now a bit of a mixed bag, with some points relating to immediate
    action “Move your car to higher ground” and some to preparation “Purchase flood
    insurance”. When people are stressed during an emergency, they probably aren’t
    thinking of prompt engineering and so we can expect slightly ambiguous inputs.
  prefs: []
  type: TYPE_NORMAL
- en: We could of course solve this problem by using more document metadata to split
    into sub-groups, but this requires work if that metadata is not available. Another
    option is to provide more context to the question to indicate if the user is interested
    in disaster preparation, or needs help immediately. We could build a classifier
    for this, but in these days of powerful LLMs let’s use zero-shot classification
    with GPT-4 …
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Nice! With very minimal effort, we can easily determine whether a question relates
    to planning or taking immediate action.
  prefs: []
  type: TYPE_NORMAL
- en: We can now prefix the user question with this …
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Which gives …
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Great, worked nicely and didn’t try to sell us any insurance, it gave advice
    that could be acted upon immediately.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s test the converse …
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Perfect, it provided forest fire preparation information.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, this would need a lot of testing for anything high-risk that could
    be used in a real emergency, but it illustrates one way we can enhance performance
    by enriching the user’s prompt.
  prefs: []
  type: TYPE_NORMAL
- en: Making Sure Answers Only Come from the Provided Documents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For an application where the information can affect safety, it’s important that
    the information presented *only* comes from the documents provided. Hallucinations
    containing incorrect information could have some really dire effects.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try asking something totally unrelated to disasters …
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Which gives …
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Though I am a bit sad not finding out how to make some yummy cake, LangChain
    took care of this scenario nicely and determines that the question does not relate
    to the information in the PDF guides provided.
  prefs: []
  type: TYPE_NORMAL
- en: That’s good, no major hallucinations! The last thing I’d want in a disaster
    is to be told to make a sponge cake and fly a spaceship or something. 😊
  prefs: []
  type: TYPE_NORMAL
- en: Conversation History
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One great feature of LangChain is that it seamlessly takes care of conversation
    history. With one line of code, the model can pick up on previous questions …
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Then ask it a question referring to ‘It’ (the hurricane) …
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Perfect, it maintains a history and knows what I’m referring to. Under pressure,
    one might expect a user to ask follow-up questions, so this ability — implemented
    with 2 lines of code! — is very important.
  prefs: []
  type: TYPE_NORMAL
- en: Translation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To make the chatbot more versatile, we can explore multilingual support. Many
    major LLMs such as [GPT-4 offer native support for top languages](https://openai.com/research/gpt-4),
    but performance can vary depending on the language.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with Portuguese …
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Which is the right information. However, with Swahili …
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The results *look* very plausible but are missing important information. Text
    excerpts matched are missing some key flood sections and we also have snippets
    related to wildfires when we asked about floods. Basically, using embeddings created
    from English documents with Swahili questions doesn’t perform well. Not unreasonable,
    though it did work well for a Latin language Portuguese.
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps a more robust approach would be to first detect language and translate
    it into English with [Google Translate](https://translate.google.com/), then convert
    the response back into the prompt language.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s add this to our chat interface …
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Much better, using Google Translate to translate Swahili automatically to English
    and then translating the answer back to Swahili gives us all the required information
    from our set of PDFs. For a risk-critical use-case like disaster response, this
    would need a LOT of testing with native speakers to ensure safety of course, but
    it shows promise towards being multilingual.
  prefs: []
  type: TYPE_NORMAL
- en: Asking a Wider Set of Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OK, let’s take the final version for a spin and ask more disaster-related questions
    …
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: I think those are pretty amazing, spot checking a few and they seem to capture
    key content in the PDF documents used.
  prefs: []
  type: TYPE_NORMAL
- en: '[ Based on the above, my disaster kit now has Ear plugs! ]'
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating Performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this analysis, we have only spot-checked how well our chat interface is returning
    critical information for a small set of FEMA PDF documents. This is good to illustrate
    some concepts, but for a production application, we would need something better
    than spot-checking. Luckily, LangChain has provided a set of [evaluators](https://python.langchain.com/docs/guides/evaluation/),
    and of particular interest is a [Streamlit application](https://blog.langchain.dev/auto-eval-of-question-answering-tasks/)
    that generates question-answer pairs automatically and then uses these to evaluate
    retrieval chains, allowing developers to experiment with some of the parameters
    involved. I haven’t yet tried this yet, but the idea of generating evaluation
    data automatically using LLMs seems a great way to build scaffolding for a more
    systematic approach for testing our FEMA disaster bot.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using a set of 34 PDF documents on the FEMA website, we were easily able to
    build a multilingual conversational interface using LangChain and GPT-4 that was
    able to answer a wide range of questions related to disaster preparedness and
    safety protocols. However, using this common document retrieval LangChain pattern
    for a high-risk safety critical chatbot faces the same challenges as found with
    semantic search. Even with advanced LLM embeddings capturing more nuance in natural
    language, it’s still quite easy to *lose* important content.
  prefs: []
  type: TYPE_NORMAL
- en: 'For our FEMA disaster bot use case, this was due to:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mixed context documents** — Without including document metadata, responses
    mixed information from different contexts. Simply prefixing document names improved
    performance for our scenario, and more sophisticated metadata strategies could
    be applied. Also, adding a zero-shot LLM classifier to enrich the user question
    was helpful.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Underrepresented languages in LLMs** —Relying on LLM translation can result
    in poor performance for less well-represented languages such as Swahili. Adding
    automatic Google translation improved performance for our use case.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We explored crude methods to address the above issues, but for a production
    chatbot, more advanced techniques and other mitigation found through testing and
    validation would be required.
  prefs: []
  type: TYPE_NORMAL
- en: Still though, pretty amazing what LLMs can do these days!
  prefs: []
  type: TYPE_NORMAL
- en: '**References**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can find a notebook with all code [here](https://github.com/datakind/stay_safe_bot).
  prefs: []
  type: TYPE_NORMAL
