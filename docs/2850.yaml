- en: Which Features Are Harmful For Your Classification Model?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/which-features-are-harmful-for-your-classification-model-6227859a44a6?source=collection_archive---------2-----------------------#2023-09-12](https://towardsdatascience.com/which-features-are-harmful-for-your-classification-model-6227859a44a6?source=collection_archive---------2-----------------------#2023-09-12)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How to calculate the Error Contribution of the features of a classifier, with
    the goal of understanding and improving the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@mazzanti.sam?source=post_page-----6227859a44a6--------------------------------)[![Samuele
    Mazzanti](../Images/432477d6418a3f79bf25dec42755d364.png)](https://medium.com/@mazzanti.sam?source=post_page-----6227859a44a6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6227859a44a6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6227859a44a6--------------------------------)
    [Samuele Mazzanti](https://medium.com/@mazzanti.sam?source=post_page-----6227859a44a6--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe16f3bb86e03&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-features-are-harmful-for-your-classification-model-6227859a44a6&user=Samuele+Mazzanti&userId=e16f3bb86e03&source=post_page-e16f3bb86e03----6227859a44a6---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6227859a44a6--------------------------------)
    ·14 min read·Sep 12, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6227859a44a6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-features-are-harmful-for-your-classification-model-6227859a44a6&user=Samuele+Mazzanti&userId=e16f3bb86e03&source=-----6227859a44a6---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6227859a44a6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-features-are-harmful-for-your-classification-model-6227859a44a6&source=-----6227859a44a6---------------------bookmark_footer-----------)![](../Images/76d978549f4c414fe424adb41c37db80.png)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Image by Author]'
  prefs: []
  type: TYPE_NORMAL
- en: Feature importance is the most common tool for explaining a machine learning
    model. It is so popular that many data scientists end up believing that feature
    importance equals feature goodness.
  prefs: []
  type: TYPE_NORMAL
- en: It is not so.
  prefs: []
  type: TYPE_NORMAL
- en: '**When a feature is important, it simply means that the model found it useful
    in the training set. However, this doesn’t say anything about the ability of the
    feature to generalize on new data!**'
  prefs: []
  type: TYPE_NORMAL
- en: 'To account for that, we need to make a distinction between two concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Prediction Contribution**: the weight that a variable has in the predictions
    made by the model. This is determined by the patterns that the model found on
    the training set. This is equivalent to feature importance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Error Contribution**: the weight that a variable has in the errors made by
    the model on a holdout dataset. This is a better proxy of the feature performance
    on new data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this article, I will explain the logic behind the calculation of these two
    quantities on a classification model. I will also show an example in…
  prefs: []
  type: TYPE_NORMAL
