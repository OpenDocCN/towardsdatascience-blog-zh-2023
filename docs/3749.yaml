- en: 'Illuminating Insights: GPT Extracts Meaning from Charts and Tables'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/illuminating-insights-gpt-extracts-meaning-from-charts-and-tables-a0b71c991d34?source=collection_archive---------1-----------------------#2023-12-24](https://towardsdatascience.com/illuminating-insights-gpt-extracts-meaning-from-charts-and-tables-a0b71c991d34?source=collection_archive---------1-----------------------#2023-12-24)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Using GPT Vision to interpret and aggregate image data.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@ilia.teimouri?source=post_page-----a0b71c991d34--------------------------------)[![Ilia
    Teimouri PhD](../Images/0eb948c4d3f81c116cd16fa4d5016629.png)](https://medium.com/@ilia.teimouri?source=post_page-----a0b71c991d34--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a0b71c991d34--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a0b71c991d34--------------------------------)
    [Ilia Teimouri PhD](https://medium.com/@ilia.teimouri?source=post_page-----a0b71c991d34--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbf9b9036159&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Filluminating-insights-gpt-extracts-meaning-from-charts-and-tables-a0b71c991d34&user=Ilia+Teimouri+PhD&userId=bf9b9036159&source=post_page-bf9b9036159----a0b71c991d34---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a0b71c991d34--------------------------------)
    ·7 min read·Dec 24, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa0b71c991d34&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Filluminating-insights-gpt-extracts-meaning-from-charts-and-tables-a0b71c991d34&user=Ilia+Teimouri+PhD&userId=bf9b9036159&source=-----a0b71c991d34---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa0b71c991d34&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Filluminating-insights-gpt-extracts-meaning-from-charts-and-tables-a0b71c991d34&source=-----a0b71c991d34---------------------bookmark_footer-----------)![](../Images/6f4c9df91feb7c242dca20cf31c52358.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [David Travis](https://unsplash.com/@dtravisphd) on [Unsplash](https://unsplash.com).
  prefs: []
  type: TYPE_NORMAL
- en: Integrating visual inputs like images alongside text and speech into large language
    models (LLMs) is considered an important new direction in AI research by many
    experts in the field. By augmenting these models to handle multiple modes of data
    beyond just language, there is potential to significantly broaden the scope of
    applications they can be utilised for as well as enhance their overall intelligence
    and performance on existing NLP tasks.
  prefs: []
  type: TYPE_NORMAL
- en: The promise of multimodal AI spans from more engaging user experiences like
    conversational agents that can see their surroundings and refer to objects around
    them, to robots that can fluidly translate commands into physical actions using
    combined knowledge of language and vision. By uniting historically separate areas
    of AI around a unified model architecture, multimodality may accelerate progress
    in tasks relying on multiple skills like visual question answering or image captioning.
    The synergies between learning algorithms, data types, and model designs across
    fields could lead to rapid advancement.
  prefs: []
  type: TYPE_NORMAL
- en: 'Many companies have already embraced multimodality in various forms: [OpenAI](https://chat.openai.com),
    [Anthropic](http://claude.ai), Google ([Bard](https://bard.google.com) and [Gemini](https://deepmind.google/technologies/gemini/#introduction))
    allow you to upload your own image or…'
  prefs: []
  type: TYPE_NORMAL
