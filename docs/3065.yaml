- en: 'Class Imbalance: Exploring Undersampling Techniques'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/class-imbalance-exploring-undersampling-techniques-24009f55b255?source=collection_archive---------10-----------------------#2023-10-07](https://towardsdatascience.com/class-imbalance-exploring-undersampling-techniques-24009f55b255?source=collection_archive---------10-----------------------#2023-10-07)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let’s learn about undersampling and how it helps solve class imbalance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://essamwissam.medium.com/?source=post_page-----24009f55b255--------------------------------)[![Essam
    Wisam](../Images/6320ce88ba2e5d56d70ce3e0f97ceb1d.png)](https://essamwissam.medium.com/?source=post_page-----24009f55b255--------------------------------)[](https://towardsdatascience.com/?source=post_page-----24009f55b255--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----24009f55b255--------------------------------)
    [Essam Wisam](https://essamwissam.medium.com/?source=post_page-----24009f55b255--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fccb82b9f3b87&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclass-imbalance-exploring-undersampling-techniques-24009f55b255&user=Essam+Wisam&userId=ccb82b9f3b87&source=post_page-ccb82b9f3b87----24009f55b255---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----24009f55b255--------------------------------)
    ·5 min read·Oct 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F24009f55b255&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclass-imbalance-exploring-undersampling-techniques-24009f55b255&user=Essam+Wisam&userId=ccb82b9f3b87&source=-----24009f55b255---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F24009f55b255&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclass-imbalance-exploring-undersampling-techniques-24009f55b255&source=-----24009f55b255---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: We have formally explained [earlier](https://essamwissam.medium.com/class-imbalance-and-oversampling-a-formal-introduction-c77b918e586d)
    the effect of class imbalance and its causes and we also explained several oversampling
    techniques that get around this issue such as random oversampling, ROSE, RWO,
    SMOTE, BorderlineSMOTE1, SMOTE-NC, and SMOTE-N. In this story, we will attempt
    to make a similar tour over undersampling techniques while assuming that it’s
    obvious how undersampling would help solve the imbalance issue given our earlier
    explanation.
  prefs: []
  type: TYPE_NORMAL
- en: Table of Contents
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ∘ [Introduction](#86fd)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Naive Random Undersampling](#3667)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [K-Means Undersampling](#42ea)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Tomek Links Undersampling](#1967)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Edited Nearest Neighbors Undersampling](#f69a)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Undersampling techniques generally fall into two main categories: controlled
    and uncontrolled. In controlled techniques, the algorithm receives a number that
    indicates how many samples there should be in the final dataset; meanwhile, in
    uncontrolled techniques undersampling is usually performed by simply removing
    points that meet some condition. It’s unknown a priori how many points will meet
    such condition and obviously it can’t be controlled. In this story, we will cover
    two controlled undersampling techniques (random and k-means undersampling) and
    two uncontrolled undersampling techniques (Tomek Links and Edited Nearest Neighbors).'
  prefs: []
  type: TYPE_NORMAL
- en: Naive Random Undersampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this technique, if it’s given that *N_k* points should be removed from class
    *k*, then *N_k* points are randomly chosen from that class for deletion (also
    possible to randomly choose the points to keep such that *N_k* points are removed).
  prefs: []
  type: TYPE_NORMAL
- en: The following shows an example of undersampling the two majority classes in
    data with three classes 0, 1, and 2.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f371e62e5265461af19aec389093eb71.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure by the author using the Imbalance.jl package in Julia
  prefs: []
  type: TYPE_NORMAL
- en: The following is an animation that shows the output at different degrees of
    undersampling
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b306cbc84ead4662b94625913ee41ae9.png)'
  prefs: []
  type: TYPE_IMG
- en: Animation by the author using the Imbalance.jl package in Julia
  prefs: []
  type: TYPE_NORMAL
- en: Notice how this is entirely a random process; no specific choice is made regarding
    which points to keep. The distribution of the data may be severely altered due
    to this.
  prefs: []
  type: TYPE_NORMAL
- en: K-Means Undersampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can preserve the distribution of the data by being more careful about which
    points to remove (or to keep). In K-means undersampling, if it is required to
    have *N_k* points for class k, then K-means is performed with *K=N_k* leading
    to *N_k* final centroids. K-means undersampling let’s those centers (or the nearest
    neighbor of each of them; this is a hyperparameter) be the final *N_k* points
    to return. Because the centers themselves preserve the distribution of the data,
    this results in a smaller set of points that preserve it as well.
  prefs: []
  type: TYPE_NORMAL
- en: The following shows an example of undersampling the two majority classes in
    data with three classes 0, 1, and 2.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/425a287df6bfd8bb15bfa0a504d221b5.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure by the author using the Imbalance.jl package in Julia
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice how it’s more careful in terms of preserving the structure of the data
    than random undersampling which would be even more evident with more undersampling.
    Let’s further illustrate this with an animation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a08a5d2c19a54be9f15ab1ec0bcc83bf.png)'
  prefs: []
  type: TYPE_IMG
- en: Animation by the author using the Imbalance.jl package in Julia
  prefs: []
  type: TYPE_NORMAL
- en: Note that the centers depend on the initialization which typically involves
    randomness.
  prefs: []
  type: TYPE_NORMAL
- en: Tomek Links Undersampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is an uncontrolled undersampling technique where a point can be removed
    if it is part of a Tomek link. Two points form a Tomek link if:'
  prefs: []
  type: TYPE_NORMAL
- en: They belong to different classes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of the two points is the nearest neighbor of the other point
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The rationale here is that such points don’t help make the decision boundary
    better (e.g., may make overfitting easier) and that they maybe noise. The following
    is an example for applying Tomek Links:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/944b071a947c077d41ce2bcb3031a2c4.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure by the author using the Imbalance.jl package in Julia
  prefs: []
  type: TYPE_NORMAL
- en: Notice how after undersampling it’s more easier to find a more linear decision
    boundary besides that this brings the data to better balance as well. In this,
    we skipped undersampling the minority class in green and stopped undersampling
    for a class once it had about as much points.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see this in action more closely, where all classes are eventually undersampled,
    consider the following animation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2ad59401e111a8c0347accb48b982d67.png)'
  prefs: []
  type: TYPE_IMG
- en: Animation by the author using the Imbalance.jl package in Julia
  prefs: []
  type: TYPE_NORMAL
- en: Edited Nearest Neighbors Undersampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although Tomek links are mostly points that don’t help form a better decision
    boundary or are noise, not all noisy points will form Tomek links. If a noisy
    point from class *k_1* exists in a dense region in class *k_2* then it can be
    normal for the nearest neighbor of the noisy point to have a nearest point that
    is not the noisy point which implies that it shall remain for not forming a Tomek
    link. Instead of this condition, edited nearest neighbors undersampling by default
    keeps a point iff the majority of its neighbors are from the same class. There
    is also the option to keep only if all of them are from the same class or for
    minimal undersampling to keep any point iff there exists a neighbor from the same
    class.
  prefs: []
  type: TYPE_NORMAL
- en: 'This animation portrays the algorithm in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d70c87c8af65cfb5033eb6a0cc0592ad.png)'
  prefs: []
  type: TYPE_IMG
- en: Animation by the author using the Imbalance.jl package in Julia
  prefs: []
  type: TYPE_NORMAL
- en: Notice how it cleans out more points that would not be helpful to the decision
    boundary or are noise. Even more cleaning out can be done if the number of neighbors
    k or the keep condition is altered in the right way. This is another animation
    that illustrates the effect.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/837b337e4d2de73c33609370c1bf3d86.png)'
  prefs: []
  type: TYPE_IMG
- en: Animation by the author using the Imbalance.jl package in Julia
  prefs: []
  type: TYPE_NORMAL
- en: The difference between the “mode” and “only mode” conditions is that the former
    keeps a point iff its class is one of the most common among the neighbors; meanwhile,
    the latter keeps a point iff its class is the only most common class.
  prefs: []
  type: TYPE_NORMAL
- en: This wraps up our tour over some interesting undersampling algorithms. Hope
    this has helped you learn more about both controlled and uncontrolled undersampling.
    Till next time, au revoir.
  prefs: []
  type: TYPE_NORMAL
- en: '**References:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[1] Wei-Chao, L., Chih-Fong, T., Ya-Han, H., & Jing-Shang, J. (2017). Clustering-based
    undersampling in class-imbalanced data. Information Sciences, 409–410, 17–26.'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] Ivan Tomek. Two modifications of cnn. IEEE Trans. Systems, Man and Cybernetics,
    6:769–772, 1976.'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] Dennis L Wilson. Asymptotic properties of nearest neighbor rules using
    edited data. IEEE Transactions on Systems, Man, and Cybernetics, pages 408–421,
    1972.'
  prefs: []
  type: TYPE_NORMAL
