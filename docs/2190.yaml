- en: Real-Time Crowdedness Predictions for Train Travelers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实时火车乘客拥挤度预测
- en: 原文：[https://towardsdatascience.com/real-time-crowdedness-predictions-for-train-travelers-a5a5d2858bed?source=collection_archive---------6-----------------------#2023-07-07](https://towardsdatascience.com/real-time-crowdedness-predictions-for-train-travelers-a5a5d2858bed?source=collection_archive---------6-----------------------#2023-07-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/real-time-crowdedness-predictions-for-train-travelers-a5a5d2858bed?source=collection_archive---------6-----------------------#2023-07-07](https://towardsdatascience.com/real-time-crowdedness-predictions-for-train-travelers-a5a5d2858bed?source=collection_archive---------6-----------------------#2023-07-07)
- en: Using serverless Azure technology to provide streaming predictions to our travel
    planner app
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用无服务器的 Azure 技术为我们的旅行规划应用提供流式预测
- en: '[](https://rikjongerius.medium.com/?source=post_page-----a5a5d2858bed--------------------------------)[![Rik
    Jongerius](../Images/8a5d60736fe5693d633bcfff78ebca71.png)](https://rikjongerius.medium.com/?source=post_page-----a5a5d2858bed--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a5a5d2858bed--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a5a5d2858bed--------------------------------)
    [Rik Jongerius](https://rikjongerius.medium.com/?source=post_page-----a5a5d2858bed--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://rikjongerius.medium.com/?source=post_page-----a5a5d2858bed--------------------------------)[![Rik
    Jongerius](../Images/8a5d60736fe5693d633bcfff78ebca71.png)](https://rikjongerius.medium.com/?source=post_page-----a5a5d2858bed--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a5a5d2858bed--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a5a5d2858bed--------------------------------)
    [Rik Jongerius](https://rikjongerius.medium.com/?source=post_page-----a5a5d2858bed--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8d3b69256f17&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freal-time-crowdedness-predictions-for-train-travelers-a5a5d2858bed&user=Rik+Jongerius&userId=8d3b69256f17&source=post_page-8d3b69256f17----a5a5d2858bed---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a5a5d2858bed--------------------------------)
    ·11 min read·Jul 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa5a5d2858bed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freal-time-crowdedness-predictions-for-train-travelers-a5a5d2858bed&user=Rik+Jongerius&userId=8d3b69256f17&source=-----a5a5d2858bed---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8d3b69256f17&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freal-time-crowdedness-predictions-for-train-travelers-a5a5d2858bed&user=Rik+Jongerius&userId=8d3b69256f17&source=post_page-8d3b69256f17----a5a5d2858bed---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a5a5d2858bed--------------------------------)
    ·11 分钟阅读·2023年7月7日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa5a5d2858bed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freal-time-crowdedness-predictions-for-train-travelers-a5a5d2858bed&user=Rik+Jongerius&userId=8d3b69256f17&source=-----a5a5d2858bed---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa5a5d2858bed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freal-time-crowdedness-predictions-for-train-travelers-a5a5d2858bed&source=-----a5a5d2858bed---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa5a5d2858bed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freal-time-crowdedness-predictions-for-train-travelers-a5a5d2858bed&source=-----a5a5d2858bed---------------------bookmark_footer-----------)'
- en: With [Wessel Radstok](https://medium.com/@wradstok)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 与 [Wessel Radstok](https://medium.com/@wradstok)
- en: '![](../Images/467683cd95344dc3cf7146719c2aeb44.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/467683cd95344dc3cf7146719c2aeb44.png)'
- en: '[Image by vecstock](https://www.freepik.com/free-photo/transportation-speed-blurred-railroad-track-generative-ai_40965146.htm#query=train&position=4&from_view=search&track=sph)
    on Freepik'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[图像来源：vecstock](https://www.freepik.com/free-photo/transportation-speed-blurred-railroad-track-generative-ai_40965146.htm#query=train&position=4&from_view=search&track=sph)
    于 Freepik'
- en: 'Travelers on the Dutch Railways can use the app from the Dutch railway agency
    to plan their trip. While planning the trip, the app shows a prediction for the
    crowdedness of the train in question. This is shown as three categories: low occupation,
    medium, or high. The traveler can use this information to decide if they wish
    to take a different train that might be a bit less crowded.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/508c238b1404e1ff56b17a500e9ca36b.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1: Travel app with the predicted passenger crowdedness (indicated using
    1, 2, or 3 persons). Image by author.*'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: These predictions are performed using a batch process. A machine learning model
    is trained regularly on historic data and each morning a process runs to predict
    the crowdedness of trains in the coming days. This is done by predicting how many
    passengers are expected and combining it with the capacity of the train planned
    for the route.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: However, during the day incidents may happen that will cause trains to be cancelled,
    be diverted, or it might be that a double-decker train is planned but only a single-deck
    train is available. As a result, the traveler will see outdated crowdedness information.
    Around 20% of departing trains change capacity on the day of travel, and often
    shortly before departing.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: In this blog, we explain how we built a streaming pipeline that takes real-time
    information on the length and type of train that is planned for a route and updates
    the expected crowdedness in the app. We follow a Lambda architecture where our
    nightly predictions implement the batch layer, and the update process implements
    the streaming layer. This pipeline is currently running in production, providing
    all train travelers in the Netherlands using our app with a more real-time view
    on the expected crowdedness of their trip.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7544de84e23e133d03816dc61c778d9f.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
- en: '*Figure 2: Simplified view of our application architecture using a Lambda architecture.
    Image created using draw.io.*'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: We describe the approach we took to implement this architecture. Our first implementation
    was done using Spark Structured Streaming, which didn’t work out as we expected.
    Based on our experience, which we will discuss, we decided to take a different
    approach using serverless resources in the Azure cloud.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: 'First attempt: Spark Structured Streaming'
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our daily crowdedness predictions run on Databricks using Spark for data processing.
    As Spark has support for streaming data processing, it seems a logical fit to
    implement the real-time updates of our predictions in Spark Structured Streaming.
    This decision gave us the advantage that the platform was already available and
    we could implement the logic using the DataFrame paradigm which we already had
    experience with.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: We started the implementation with a batch version of the model we wanted to
    run in a streaming version and converted this to a pure Spark Structured Streaming
    implementation. We ended up with a small notebook to bootstrap the streaming job
    and a custom python package containing the logic we needed.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: During the development process we learned a few things about programming using
    Structured Streaming. First, the programming interface of SQL DataFrames and Structured
    Streaming DataFrames is not the same. Structured Streaming is a lot more limited
    in terms of what can be done, which meant we couldn’t implement the batch model
    one-to-one in a streaming fashion and we had to revise the algorithm a few times
    to make it work. The limited expressiveness of the Structured Streaming interface
    led to code that turned unreadable and was therefore difficult to maintain.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple example of this is that we wanted to perform an outer join on two
    streams of data based on a time window. However, Spark Structured Streaming requires
    having an equality in the join condition and we did not have two columns with
    the same data. We tried adding two literal fields with the same value to the two
    streams for the equality, but Spark is not that easily fooled. We ended up creating
    a “millennium” field as our time stamps are all in the 3th millennium: that works
    but we essentially created a “Y3K” bug.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, we had to split the algorithm in separate steps because we had
    different time constraints on different parts of the model which we couldn’t implement
    in a single Structured Streaming job. We chose to split the model into several
    parts, coupled together using Azure Event Hubs as a persistent storage layer in
    between. This had the advantage that each part of the processing had a clear goal
    and could be tested individually.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/77164311ef064682032c62d8031a61d4.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
- en: '*Figure 3: Overview of streaming processing of train capacity updates using
    Spark Structured Streaming. Image created using draw.io.*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: We tested our flow in two ways. For the unit tests, we would simply take the
    streaming logic and fed it with hand-crafted batch Spark SQL DataFrames for testing.
    This means we could test parts of the streaming flow without actually starting
    a streaming job. This approach captures a lot of the functional requirements,
    but wouldn’t capture any timing issues. The second testing step used Spark Structured
    Streaming memory sinks to run the query in streaming mode to capture some timing
    effects as well.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: 'Eventually, we deployed our code and we saw our cloud bill increase dramatically.
    We identified two reasons for this: First, Databricks is a great solution for
    batch analytics jobs, but it is expensive to keep running continuously for streaming
    jobs. Secondly, the information security policy of our employer requires us to
    log data access. As the state store of Structured Streaming may contain data,
    we had to log this as well. However, the state store is updated very often and
    contains many small files which lead to an enormous set of logs that is expensive
    to capture.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Eventually, we decided to abandon this approach. Our cloud costs were too high
    for the problem we tried to tackle. Combined with the fact that the model implementation
    was very difficult to understand and maintain due to the limited expressiveness
    of Spark Structured Streaming led us to the conclusion that we didn’t want to
    invest further to improve on this approach but to see if we could tackle this
    in a different way.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Redesign using serverless technologies
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Noting that many parts of the flow do not require state, we landed on a system
    which used Azure Functions as a compute platform such that each message can be
    handled separately. Where state is necessary we use Stream Analytics. This allows
    us to compare messages, replay messages, or join them with another stream. To
    allow fast access to auxiliary data we use a Cosmos Database. We still use Azure
    Event Hubs to tie all parts together.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3410471c9905e65088de9140f4005f2a.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4: Final architecture using serverless technologies. Image created
    using draw.io.*'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: Azure Functions
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Azure Functions are an easy method to apply operations to a stream of events.
    They are invoked separately for each event in the stream which makes it easy to
    reason about the business logic. They have native support for Python, making it
    easy to write maintainable operations. Because the platform manages all of the
    cloud connectivity boilerplate, they can easily be developed and tested locally.
    We use them in various parts of the flow:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Some functions simply filter incoming messages, reducing the compute load of
    subsequent steps and thus reducing capacity and cost;
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Several functions enrich messages by joining them with other data sources available
    in for example Cosmos DB;
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other functions transforms the message from one format to e.g. the final output
    format;
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we use Azure Functions to ingest data from the batch layer into the
    streaming layer.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filtering, enriching, and transformations
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The functions performing these steps are straightforward Python code. As an
    example, the main part of the filtering function is just a few lines:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*Listing 1: Example Azure Function code which filters and transforms messages.*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Here, we take each message, filter only the messages related to trains our company
    operates, and remove keys (data fields) from the message we are not interested
    in. Finally, we add a build ID metadata to the message such that we have some
    tracing information for debugging purposes. For the interested reader, the JSON
    string is encoded as a Bytes object using *str.encode()*. If regular string is
    sent to the Event Hub, it is being pretty-printed automatically which introduces
    a lot of white space in the message. A Bytes object is sent unchanged.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们处理每条消息，过滤出与我们公司运营的列车相关的消息，并从消息中移除我们不感兴趣的键（数据字段）。最后，我们向消息中添加构建 ID 元数据，以便我们在调试时有一些追踪信息。对于感兴趣的读者，JSON
    字符串使用 *str.encode()* 编码为 Bytes 对象。如果将普通字符串发送到 Event Hub，它会自动被美化显示，这会在消息中引入大量空白。Bytes
    对象则不会发生任何更改。
- en: Data ingestion into a fast Cosmos Database
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据摄取到快速 Cosmos 数据库
- en: In order to recompute the train crowdedness, quick access to the predicted number
    of travelers in the train, the capacity of the new rolling stock and the boundaries
    for low, medium and high classification are required. This data is generated daily
    as part of our batch process and written to our data lake in parquet format. Loading
    this data from the data lake for every recompute action is too slow. We leverage
    Azure Cosmos Database key-value store to make required static data available with
    low latency for the Azure Functions recomputing train crowdedness.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了重新计算列车拥挤度，需要快速访问预测的乘客数量、新的滚动库存的容量以及低、中和高分类的边界。这些数据是我们批处理流程的一部分，每天生成，并以 parquet
    格式写入到我们的数据湖中。每次重新计算时从数据湖加载这些数据太慢。我们利用 Azure Cosmos 数据库的键值存储，以低延迟提供所需的静态数据，用于 Azure
    Functions 重新计算列车拥挤度。
- en: The ideal scenario is that we trigger the ingestion from our nightly batch process
    and can also receive whether the ingestion succeeded or failed. The ingestion
    process also needs to be able to read parquet files with complex types, which
    dropped support for an Azure Data Factory copy activity. Our solution was to leverage
    Azure Durable Functions. This is an extension to the standard Azure Functions
    platform which enables stateful, long-running functions. Specifically, durable
    functions support webhooks which allows us to communicate back whether ingestion
    succeeded to the orchestrator.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 理想的情况是，我们从每晚的批处理流程中触发数据摄取，并且能够接收到摄取是否成功或失败的反馈。摄取过程还需要能够读取包含复杂类型的 parquet 文件，这些文件在
    Azure 数据工厂复制活动中不再受支持。我们的解决方案是利用 Azure Durable Functions。这是标准 Azure Functions 平台的扩展，支持有状态的长期运行函数。具体而言，Durable
    Functions 支持 webhooks，这使我们能够向协调器反馈摄取是否成功。
- en: Ingestion then works as follows. Our nightly batch process triggers a durable
    function. This durable functions selects the correct Activity Function for the
    data source that needs to be ingested and triggers this Activity for each parquet
    file available. We then use pandas to read each file, perform some simple transformations
    and bulk-insert the records into the Cosmos database. The durable function automatically
    keeps track of any failures and will retry that function.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 数据摄取的工作流程如下。我们的每晚批处理流程触发一个 Durable Function。该 Durable Function 选择正确的 Activity
    Function 以处理需要摄取的数据源，并针对每个可用的 parquet 文件触发该 Activity。然后，我们使用 pandas 读取每个文件，执行一些简单的转换，并将记录批量插入到
    Cosmos 数据库中。Durable Function 会自动跟踪任何失败情况，并重新尝试该函数。
- en: Azure Stream Analytics
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Azure Stream Analytics
- en: Some operations we cannot easily perform with Azure Functions. This is primarily
    true for stateful operations, or for operations that combine messages over time
    windows.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 有些操作我们无法通过 Azure Functions 轻松完成。这主要适用于有状态的操作，或涉及在时间窗口内合并消息的操作。
- en: 'Our daily crowdedness predictions are done in a batch process that does not
    compute the predictions instantaneously. It takes time, time during which new
    updates on train capacity may occur. If that happens, we wish to update the crowdedness
    twice: first on the most recent previous prediction, and next on the new predictions
    when they becomes available. We use Azure Stream Analytics here to keep state
    of update messages and replay them from a certain timestamp when a new batch prediction
    is available.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的每日拥挤度预测是在一个批处理流程中完成的，该流程不会立即计算预测结果。这个过程需要时间，在这段时间内可能会有新的列车容量更新。如果发生这种情况，我们希望更新拥挤度两次：首先是在最新的上一个预测上，然后是在新的预测结果变得可用时。我们在这里使用
    Azure Stream Analytics 来保持更新消息的状态，并在新批次预测可用时从特定时间戳重新播放这些消息。
- en: Azure Stream Analytics queries are written in a SQL dialect. It is relatively
    straight-forward to implement transformations. However, some care need to be taken
    when the message throughput needs to be high. In our case, a straightforward implementation
    couldn’t keep up with the input stream and we had to make sure that the stream
    analytics query was able to run in an embarrassingly parallel manner.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Embarrassingly parallel queries have some requirements and limitations. They
    need to process partitioned data, and they need to perform stateful operations
    (e.g. joins) contained within a partition. This means that when joining two Event
    Hub streams, they must have the same number of partitions, and data from partition
    1 on the first Event Hub may only be joined to data from partition 1 on the second.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: In order to solve this, we duplicate some of our data on several Event Hub partitions
    and essentially implement a broadcast join operation. We illustrate this in the
    following query. Here, each of our crowdedness predictions is given a batch ID
    and a batch start time which is used to decide which train capacity update message
    is applicable to which prediction. A message can be applicable to multiple predictions
    if the message arrives during the calculation of a new set of predictions). In
    this case multiple message are output. Each batch ID is duplicated over multiple
    Event Hub partitions.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '*Listing 2: Example Azure Stream Analytics query adding the corresponding batch
    ID for the prediction to each message.*'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: End-to-end integration testing
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: From the initial commit on the project we decided to perform automated end-to-end
    integration testing on the streaming flow. This testing took the form of seeding
    the entry Event Hubs with sample messages that we generate, and then validating
    the messages created at the output Event Hubs. We also included the Cosmos database
    ingestion in this integration test flow. Making these tests part of our continuous
    deployment gave us great confidence when making changes as the number of components
    in the flow increased and the complexity increased with it.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/862c9e638336e2c6445752a5a0b1d962.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
- en: '*Figure 5: Overview of the CI/CD pipeline steps used for integration testing
    of the streaming flow. We delete any stray data from earlier tests if needed,
    upload new data and start the data ingest functions for three data sources. Then,
    we feed the system with event messages on the Event Hub and check if they properly
    come out of the other end. Finally, we perform an extra check on the Cosmos Database
    ingestion. Image by author.*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions and key learnings
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our quest to give our train travelers the most recent insights into passenger
    crowdedness, even in situations where changes in train service occur, we embraced
    a lambda architecture to update our prognoses when train capacity changes.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Our initial implementation using Spark Structured Streaming didn’t perform as
    expected and we switched to a serverless architecture using Azure Event Hubs,
    Azure Functions, Azure Stream Analytics and Azure Cosmos DB.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最初使用 Spark Structured Streaming 的实现未能达到预期效果，因此我们转向了使用 Azure Event Hubs、Azure
    Functions、Azure Stream Analytics 和 Azure Cosmos DB 的无服务器架构。
- en: 'The key benefits of this approach include:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的关键好处包括：
- en: 'As the developer, you are in control: it is clear which parts under perform
    and which parts incur the highest costs;'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为开发者，你掌控全局：哪些部分性能不佳，哪些部分产生最高成本都很清楚；
- en: In contrast to Spark Structured Streaming, pure Python code in Azure Functions
    is readable, maintainable and expressive;
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与 Spark Structured Streaming 相比，Azure Functions 中的纯 Python 代码可读性强、可维护性好且表达力丰富；
- en: Azure Functions are cheap for stateless operations;
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于无状态操作，Azure Functions 成本低廉；
- en: Azure Streaming Analytics is the most expensive part, and must only be used
    where it matters (stateful or time window operations);
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure 流分析是最昂贵的部分，只能在重要的地方使用（有状态或时间窗口操作）；
- en: The new solution reduced cloud infra costs significantly.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新解决方案显著降低了云基础设施成本。
- en: 'The key downsides:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 关键的缺点：
- en: The use of decoupled components such as Azure Functions and Azure Cosmos DB
    may lead to race conditions if the design is not considered very well;
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用解耦组件如 Azure Functions 和 Azure Cosmos DB 可能导致竞争条件，前提是设计不够完善；
- en: 'There are many bits of infrastructure and small piece of code to manage: logic
    is not concentrated in a single place and requires more extensive testing.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要管理许多基础设施和小块代码：逻辑没有集中在一个地方，需要更多的测试。
