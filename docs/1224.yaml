- en: 'Model employment: The inference comes after training, not during'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型使用：推理发生在训练之后，而不是训练期间
- en: 原文：[https://towardsdatascience.com/model-employment-the-inference-comes-after-training-not-during-6129efdf8e90?source=collection_archive---------16-----------------------#2023-04-06](https://towardsdatascience.com/model-employment-the-inference-comes-after-training-not-during-6129efdf8e90?source=collection_archive---------16-----------------------#2023-04-06)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/model-employment-the-inference-comes-after-training-not-during-6129efdf8e90?source=collection_archive---------16-----------------------#2023-04-06](https://towardsdatascience.com/model-employment-the-inference-comes-after-training-not-during-6129efdf8e90?source=collection_archive---------16-----------------------#2023-04-06)
- en: Training and using models are two separate phases
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练和使用模型是两个独立的阶段
- en: '[](https://medium.com/@valefonsecadiaz?source=post_page-----6129efdf8e90--------------------------------)[![Valeria
    Fonseca Diaz](../Images/880222be555e8fa7df660f9dd1233818.png)](https://medium.com/@valefonsecadiaz?source=post_page-----6129efdf8e90--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6129efdf8e90--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6129efdf8e90--------------------------------)
    [Valeria Fonseca Diaz](https://medium.com/@valefonsecadiaz?source=post_page-----6129efdf8e90--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@valefonsecadiaz?source=post_page-----6129efdf8e90--------------------------------)[![Valeria
    Fonseca Diaz](../Images/880222be555e8fa7df660f9dd1233818.png)](https://medium.com/@valefonsecadiaz?source=post_page-----6129efdf8e90--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6129efdf8e90--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6129efdf8e90--------------------------------)
    [Valeria Fonseca Diaz](https://medium.com/@valefonsecadiaz?source=post_page-----6129efdf8e90--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6e363caf1c79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-employment-the-inference-comes-after-training-not-during-6129efdf8e90&user=Valeria+Fonseca+Diaz&userId=6e363caf1c79&source=post_page-6e363caf1c79----6129efdf8e90---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6129efdf8e90--------------------------------)
    ·5 min read·Apr 6, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6129efdf8e90&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-employment-the-inference-comes-after-training-not-during-6129efdf8e90&user=Valeria+Fonseca+Diaz&userId=6e363caf1c79&source=-----6129efdf8e90---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6e363caf1c79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-employment-the-inference-comes-after-training-not-during-6129efdf8e90&user=Valeria+Fonseca+Diaz&userId=6e363caf1c79&source=post_page-6e363caf1c79----6129efdf8e90---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6129efdf8e90--------------------------------)
    ·5分钟阅读·2023年4月6日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6129efdf8e90&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-employment-the-inference-comes-after-training-not-during-6129efdf8e90&user=Valeria+Fonseca+Diaz&userId=6e363caf1c79&source=-----6129efdf8e90---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6129efdf8e90&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-employment-the-inference-comes-after-training-not-during-6129efdf8e90&source=-----6129efdf8e90---------------------bookmark_footer-----------)![](../Images/266a5d9950575df712e50ee2a143a083.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6129efdf8e90&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-employment-the-inference-comes-after-training-not-during-6129efdf8e90&source=-----6129efdf8e90---------------------bookmark_footer-----------)![](../Images/266a5d9950575df712e50ee2a143a083.png)'
- en: (Image by author) Building models vs. Using models
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: （图像由作者提供）构建模型与使用模型
- en: After finishing the training phase of our models, new stages of the whole modeling
    pipeline get activated. The most common one within the machine-learning community
    is model deployment. For those who are not familiar with the concept, this basically
    refers to placing the model somewhere. If you’ve [read these posts](/is-interpreting-ml-models-a-dead-end-f5b9dd78ba77)
    about general machine-learning topics, you may remember the analogy of models
    with cars. When a car is built and assembled, “deployment” may be, for example,
    bringing it to car dealers’ shops. Another stage in this whole pipeline is model
    employment.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成模型训练阶段后，整个建模流程的新阶段会被激活。机器学习社区中最常见的一个阶段是模型部署。对于那些不熟悉这一概念的人来说，这基本上指的是将模型放置在某个地方。如果你曾[阅读这些帖子](/is-interpreting-ml-models-a-dead-end-f5b9dd78ba77)关于一般的机器学习话题，你可能会记得将模型比作汽车的类比。当一辆车被制造和组装完成后，“部署”可能例如是将其送到汽车经销商店。这个整个流程中的另一个阶段是模型应用。
- en: “Model employment”? Yes. This simply refers to everything that happens regarding
    the **utility** of our models. That includes making predictions, determining significant
    parameters, interpreting features, and the like. While this is a way of defining
    the practical uses of a model, the technical term for all of these is *inference*.
    Model employment may not necessarily follow its deployment. It will always depend
    on what use of the model is needed. However, it must and should always take place
    **after** model training, not during. While model deployment by definition requires
    placing the model somewhere, it hardly collapses or is confounded with training
    steps. This, unfortunately, is not always the case for model employment compromising
    correct inference.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: “模型应用”？是的。这仅指与我们模型的**实用性**相关的一切。这包括进行预测、确定重要参数、解释特征等。虽然这是一种定义模型实际用途的方式，但所有这些的技术术语是*推论*。模型应用可能不一定紧随其后。它始终取决于模型的实际用途。然而，它必须且应当总是发生在**模型训练之后**，而不是训练过程中。尽管模型部署按定义要求将模型放置在某处，但它几乎不会与训练步骤混淆。这不幸的是，模型应用有时会影响正确的推论。
- en: '**The machine-learning community approach**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习社区的方法**'
- en: A few decades ago, when the machine-learning community took a more solid shape,
    these concepts were very well digested and easily put into practice by those who
    were diving into the practices of training models and using them to predict different
    things. To this day, not only do we have infinite types of models around the world
    serving us in different ways, but the level of their complexity has increased
    so much that we’re very close to building that machine that will evolve our species
    like our friend ChatGPT. This level of complexity does not leave room for machine-learning
    pipelines to mix steps and for the people in charge not to differentiate the different
    stages. Thanks to that well-organized separation of stages, we’re able to make
    more accurate predictions and trust the acquired inference from our models.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 几十年前，当机器学习社区逐渐成型时，这些概念被很好地消化，并且很容易被那些投入模型训练和预测实践的人应用到实际中。直到今天，我们不仅在全球范围内拥有无限类型的模型为我们提供不同的服务，而且这些模型的复杂程度已经增加到我们非常接近构建那种像我们的朋友ChatGPT一样进化我们物种的机器。这种复杂程度不允许机器学习流程混合步骤，也不允许负责人混淆不同阶段。多亏了这些井然有序的阶段划分，我们能够做出更准确的预测，并信任我们模型得出的推论。
- en: '**The classical statistics community approach**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**经典统计学社区的方法**'
- en: If you have taken any classical statistics course, you have dealt with estimating
    (training) many different types of models for the purpose of testing some hypotheses
    and finding the so-called significant differences of the features involved for
    a particular response variable. This was the legacy of the [classical statistical
    paradigm by Fisher](https://nautil.us/how-eugenics-shaped-statistics-238014/).
    In this type of practice, the model training phase has been completely confounded
    with the model employment phase. Yes, we do things like choosing the input features
    (training) based on their significance level (employment) both with the same data.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你曾修过任何经典统计学课程，你就会处理许多不同类型的模型，以测试一些假设并找出某个响应变量相关特征的所谓显著差异。这是[费舍尔经典统计范式](https://nautil.us/how-eugenics-shaped-statistics-238014/)的遗产。在这种实践中，模型训练阶段完全与模型应用阶段混淆在一起。是的，我们确实会根据输入特征的显著性水平（应用）来选择这些特征（训练），而且都是使用相同的数据。
- en: '![](../Images/ba7a7561e89a1192896879d481c6bad1.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ba7a7561e89a1192896879d481c6bad1.png)'
- en: (Image by author) A spectrum of complexity and structure
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: (Image by author) 复杂性和结构的范围
- en: '**The whole spectrum in-between**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**整个范围的中间部分**'
- en: As the level of complexity gets simpler, reality has shown us that the separation
    between model training and employment becomes blurrier. Many data scientists out
    there deal with different levels of complexity when it comes to training and using
    models. Some models may be very simple to train and hard to employ, or vice-versa.
    If we were to audit machine-learning projects of low levels of complexity, it
    might well be the case that there’s no single object saving the model, no clear
    environment of deployment, and definitely no unique stage of employment particularly
    for interpretation or significance testing. We might find many models that live
    in forgotten folders as multiple lines of code that no one can easily understand
    with scattered pieces reporting figures of interest. Well, how problematic could
    this be?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 随着复杂性水平的简化，现实已经向我们展示了模型训练与使用之间的分离变得越来越模糊。许多数据科学家在训练和使用模型时面对不同的复杂性水平。有些模型可能非常容易训练但难以使用，反之亦然。如果我们审计低复杂度的机器学习项目，可能会发现没有单一对象保存模型，没有明确的部署环境，并且没有特别用于解释或显著性测试的独特阶段。我们可能会发现许多模型被遗忘在文件夹中，作为多行代码散落着报告感兴趣的数字。那么，这会有多大问题呢？
- en: '![](../Images/ce0d5164d23a79448e334e5b3534ff53.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ce0d5164d23a79448e334e5b3534ff53.png)'
- en: (Image by author) A tool for writing, the finished product vs. the scattered
    pieces
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: (Image by author) 一种写作工具，完成品与散落的零件
- en: '**Our models need to be assembled tools**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们的模型需要成为完整的工具**'
- en: Yes, like a simple pencil or a complex device. Statistical models, from simple
    linear regressions to deep learning models, are tools. We build those tools for
    a purpose. That purpose may vary from field to field or application to application,
    but ultimately, they are meant to be employed for that purpose. When the employment
    phase is not detached from the training, we end up with models that look like
    scattered pieces that haven’t been assembled. When we report the employment or
    inference of our model based on a disassembled tool, the risk of misleading inference
    is rather high. It would be the same as writing with a disassembled pencil or
    driving a disassembled car. What sense could that make and why take the risk?
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，就像一支简单的铅笔或一个复杂的设备。统计模型，从简单的线性回归到深度学习模型，都是工具。我们构建这些工具是有目的的。这个目的可能因领域或应用而异，但**最终**，它们是为了那个目的而被使用的。当使用阶段没有与训练分开时，我们最终得到的模型就像是尚未组装的散落零件。当我们基于一个未组装的工具报告模型的使用或推断时，误导性推断的风险相当高。这就像用拆开的铅笔写字或开拆开的车一样。这有什么意义？为什么要冒这个风险？
- en: '**Smooth transition to a proper model employment**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**顺畅过渡到适当的模型使用**'
- en: 'Successful model employment generally depends on having at least some form
    of [model persistence](https://scikit-learn.org/stable/model_persistence.html).
    Even if your model is to live only locally, there will always be at least one
    user of that model: The researcher/data scientist or whoever will use the model
    to report the findings. Because there’s already at least one user, it is necessary
    to at least [save the model](https://machinelearningmastery.com/finalize-machine-learning-models-in-r/)
    in some available format. Once the save button is pressed or the save function
    is run, voilà! Your model now exists as an assembled tool.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 成功的模型使用通常取决于至少某种形式的 [模型持久性](https://scikit-learn.org/stable/model_persistence.html)。即使你的模型仅在本地使用，也总会有至少一个用户：研究人员/数据科学家或任何将使用模型报告结果的人。因为已经有至少一个用户，所以必须至少
    [保存模型](https://machinelearningmastery.com/finalize-machine-learning-models-in-r/)
    为某种可用格式。一旦按下保存按钮或运行保存功能，瞧！你的模型现在作为一个完整的工具存在。
- en: 'Not any moment before you are ready to **employ** your model. When you are,
    here are a few beneficial/necessary practices:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在你准备好**使用**模型之前的任何时刻都不应进行。当你准备好时，这里有一些有益的/必要的实践：
- en: '***Separate the scripts for model training and model employment***. A significance
    test to report inference should live in a separate script or software file from
    the estimation of the model.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***将模型训练和模型使用的脚本分开***。显著性测试报告应与模型估计分开存在于不同的脚本或软件文件中。'
- en: '***Methods for model employment should not be used for model training.*** Just
    as the prediction performance in the test set is not used to tune the model parameters,
    a significance test should not be used to select the input features if run on
    the same training data.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***模型使用的方法不应用于模型训练。*** 就像测试集中的预测性能不用于调整模型参数一样，显著性测试也不应在同一训练数据上用于选择输入特征。'
- en: '***Report the model training results separately from the model employment results.***
    Because they are different stages, when we are to publish or report the results,
    the stages should also be reported separately.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***将模型训练结果与模型使用结果分别报告。*** 因为它们是不同的阶段，所以在发布或报告结果时，这些阶段也应该分别报告。'
- en: '**Better model employment for all levels**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**为所有级别提供更好的模型使用**'
- en: I asked ChatGPT about model employment coming after model training and it said
    it was correct, generally. So, isn’t it always the case? Well, the robot had a
    very good point. In online learning, the employment of the model produces feedback
    to update the model in time, so the tasks interact continuously. “That’s right!”.
    But wait, being connected through feedback is not the same as being confounded.
    The particular model training and employment interrelation in online learning
    is in itself a whole modeling scheme. Even there, there are clear definitions
    and approaches when it comes to the updating phase, the prediction phase, and
    the feedback flow. So, the conceptual separation remains valid.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我向ChatGPT询问了模型训练后的模型使用情况，它表示通常来说这是正确的。那么，这难道不是一成不变的事实吗？其实，机器人提出了一个很好的观点。在在线学习中，模型的使用会产生反馈来及时更新模型，因此任务会持续互动。“没错！”但请注意，通过反馈连接并不等同于被混淆。在在线学习中，特定的模型训练和使用的相互关系本身就是一个完整的建模方案。即使在这里，更新阶段、预测阶段和反馈流程都有明确的定义和方法。因此，概念上的分离仍然是有效的。
- en: Looking at our models and the practices around them when it comes to model training
    vs. model employment, it all boils down to organization and structure rather than
    modeling skills. Once we’re able to separate the stages of the modeling pipeline,
    our models should be able to persist as well as provide solid inference. Isn’t
    that our ultimate goal?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 看待我们的模型及其相关实践时，模型训练与模型使用的区别归结为组织和结构，而非建模技能。一旦我们能够分离建模流程的各个阶段，我们的模型就应该能够持续存在并提供可靠的推断。这难道不是我们的终极目标吗？
- en: '*Let’s keep it up with a good structure!*'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*让我们保持良好的结构！*'
