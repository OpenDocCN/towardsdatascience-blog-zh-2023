- en: 'Cleaning Up Confluence Chaos: A Python and BERTopic Quest'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/cleaning-up-confluence-chaos-a-python-and-bertopic-quest-d3aafc2ed736?source=collection_archive---------1-----------------------#2023-04-29](https://towardsdatascience.com/cleaning-up-confluence-chaos-a-python-and-bertopic-quest-d3aafc2ed736?source=collection_archive---------1-----------------------#2023-04-29)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A tale of taming unruly documents to create the ultimate GPT-based chatbot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@massi.costacurta?source=post_page-----d3aafc2ed736--------------------------------)[![Massimiliano
    Costacurta](../Images/599c3469021c53f116cc67c390db6695.png)](https://medium.com/@massi.costacurta?source=post_page-----d3aafc2ed736--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d3aafc2ed736--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d3aafc2ed736--------------------------------)
    [Massimiliano Costacurta](https://medium.com/@massi.costacurta?source=post_page-----d3aafc2ed736--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F233cb43234c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcleaning-up-confluence-chaos-a-python-and-bertopic-quest-d3aafc2ed736&user=Massimiliano+Costacurta&userId=233cb43234c3&source=post_page-233cb43234c3----d3aafc2ed736---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d3aafc2ed736--------------------------------)
    ·8 min read·Apr 29, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd3aafc2ed736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcleaning-up-confluence-chaos-a-python-and-bertopic-quest-d3aafc2ed736&user=Massimiliano+Costacurta&userId=233cb43234c3&source=-----d3aafc2ed736---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd3aafc2ed736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcleaning-up-confluence-chaos-a-python-and-bertopic-quest-d3aafc2ed736&source=-----d3aafc2ed736---------------------bookmark_footer-----------)![](../Images/b1dec38e9c54230b6b25f899c6b43db0.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Rick Mason](https://unsplash.com/@egnaro?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'Introduction:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Picture this: you’re at a rapidly growing tech company, and you’ve been given
    the mission to create a state-of-the-art chatbot using the mind-blowing GPT technology.
    This chatbot is destined to become the company’s crown jewel, a virtual oracle
    that’ll answer questions based on the treasure trove of knowledge stored in your
    Confluence spaces. Sounds like a dream job, right?'
  prefs: []
  type: TYPE_NORMAL
- en: But, as you take a closer look at the Confluence knowledge base, reality hits.
    It’s a wild jungle of empty/incomplete pages, irrelevant documents and duplicate
    content. It’s like someone dumped a thousand jigsaw puzzles into a giant blender
    and pressed “start.” And now, it’s your job to clean up this mess before you can
    even think about building that amazing chatbot.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily for you, in this article, we’ll embark on a thrilling journey to conquer
    the Confluence chaos, using the power of Python and BERTopic to identify and eliminate
    those annoying outliers. So, buckle up and get ready to transform your knowledge
    base into the perfect training ground for your cutting-edge GPT-based chatbot.
  prefs: []
  type: TYPE_NORMAL
- en: The Manual Approach and the Heuristic Temptation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you face the daunting task of cleaning up your Confluence knowledge base,
    you might consider diving in manually, sorting through each document one by one.
    However, the manual approach is slow, labor-intensive, and error-prone. After
    all, even the most meticulous employee can overlook important details or misjudge
    the relevance of a document.
  prefs: []
  type: TYPE_NORMAL
- en: With your knowledge of Python, you might be tempted to create a heuristic-based
    solution, using a set of predefined rules to identify and eliminate outliers.
    While this approach is faster than manual cleanup, it has its limitations. Heuristics
    can be rigid and struggle to adapt to the complex and ever-evolving nature of
    your Confluence spaces, often leading to suboptimal results.
  prefs: []
  type: TYPE_NORMAL
- en: Python and BERTopic — The Powerful Duo for Confluence Cleanup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Enter Python and BERTopic, a powerful combination that can help you tackle the
    challenge of cleaning up your Confluence knowledge base more effectively. Python
    is a versatile programming language, while BERTopic is an advanced topic modeling
    library that can analyze your documents and group them based on their underlying
    topics.
  prefs: []
  type: TYPE_NORMAL
- en: In the next paragraphs, we’ll explore how Python and BERTopic can work together
    to automate the process of identifying and eliminating outliers in your Confluence
    spaces. By harnessing their combined powers, you’ll save time and resources while
    increasing the accuracy and effectiveness of your cleanup efforts.
  prefs: []
  type: TYPE_NORMAL
- en: The Python-BERTopic Project — A Step-by-Step Guide
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Alright, from this point on, I’ll walk you through the process of creating
    a Python script using BERTopic to identify and eliminate outliers in your Confluence
    knowledge base. The goal is to generate a ranked list of documents based on their
    “unrelatedness” score (which we’ll define later). The final output will consist
    of the document’s title, a preview of the text (first 100 characters), and the
    unrelatedness score. The final output will appear as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '(Title: “AI in Healthcare”, Preview: “Artificial intelligence is transforming…”,
    Unrelatedness: 0.95)'
  prefs: []
  type: TYPE_NORMAL
- en: '(Title: “Office Birthday Party Guidelines”, Preview: “To ensure a fun and safe…”,
    Unrelatedness: 0.8)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The essential steps in this process include:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Connect to Confluence and download documents: establish a connection to your
    Confluence account and fetch the documents for processing. This section provides
    guidance on setting up the connection, authenticating, and downloading the necessary
    data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'HTML processing and text extraction using Beautiful Soup: use Beautiful Soup,
    a powerful Python library, to manage HTML content and extract the text from Confluence
    documents. This step involves cleaning up the extracted text, removing unwanted
    elements, and preparing the data for analysis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Apply BERTopic and create the ranking: with the cleaned-up text in hand, apply
    BERTopic to analyze and group the documents based on their underlying topics.
    After obtaining the topic representations, calculate the “unrelatedness” measure
    for each document and create a ranking to identify and eliminate outliers in your
    Confluence knowledge base.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Confluence Connection and Documents Download
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Finally the code. Here, we’ll start downloading documents from a Confluence
    space, we’ll then process the HTML content, and we’ll extract the text for the
    next phase (BERTopic!).
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to connect to Confluence via API. Thanks to the atlassian-python-api
    library, that can be done with a few lines of code. If you don’t have an API token
    for Atlassian, read [this guide](https://support.atlassian.com/atlassian-account/docs/manage-api-tokens-for-your-atlassian-account/)
    to set that up.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'After fetching the pages, we’ll create a directory for the text files, extract
    the pages’ content and save the text content to individual files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The function `process_html_document` carries out all the necessary cleaning
    tasks to extract the text from the downloaded pages while maintaining a coherent
    format. The extent to which you want to refine this process depends on your specific
    requirements. In this case, we focus on handling tables and lists to ensure that
    the resulting text document retains a format similar to the original layout.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Identifying Outliers with BERTopic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this final chapter, we’ll finally leverage BERTopic, a powerful topic modeling
    technique that utilizes BERT embeddings. You can learn more about BERTopic in
    their [GitHub repository](https://github.com/MaartenGr/BERTopic) and their [documentation](https://maartengr.github.io/BERTopic/).
  prefs: []
  type: TYPE_NORMAL
- en: Our approach to finding outliers consists of running BERTopic with different
    values for the number of topics. In each iteration, we’ll collect all documents
    that fall into the Outlier cluster (-1). The more frequently a document appears
    in the -1 cluster, the more likely it is to be considered an outlier. This frequency
    forms the first component of our unrelatedness score. BERTopic also provides a
    probability value for documents in the -1 cluster. We’ll calculate the average
    of these probabilities for each document over all the iterations. This average
    represents the second component of our unrelatedness score. Finally, we’ll determine
    the overall unrelatedness score for each document by computing the average of
    the two scores (frequency and probability). This combined score will help us identify
    the most unrelated documents in our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the initial code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In this code block, we set up the necessary tools for BERTopic by importing
    the required libraries and initializing the models. We define 3 models that will
    be used by BERTopic:'
  prefs: []
  type: TYPE_NORMAL
- en: '`vectorizer_model`: the `CountVectorizer` model tokenizes the documents and
    creates a document-term matrix where each entry represents the count of a term
    in a document. It also removes English stop words from the documents to improve
    topic modeling performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`representation_model`: the `MaximalMarginalRelevance` (MMR) model diversifies
    the extracted topics by considering both the relevance and diversity of topics.
    The `diversity` parameter controls the trade-off between these two aspects, with
    higher values leading to more diverse topics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ctfidf_model`: the `ClassTfidfTransformer` model adjusts the term frequency-inverse
    document frequency (TF-IDF) scores of the document-term matrix to better represent
    topics. It reduces the impact of frequently occurring words across topics and
    enhances the distinction between topics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We then collect the text and filenames of the documents from the ‘txt_files’
    directory to process them with BERTopic in the next step.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In the above section, we use BERTopic to identify outlier documents by iterating
    through a range of topic counts from a specified minimum to a maximum. For each
    topic count, BERTopic extracts the topics and their corresponding probabilities.
    It then identifies the outlier topic and updates the `outlier_counts` and `outlier_probs`
    for documents assigned to this outlier topic. This process iteratively accumulates
    counts and probabilities, providing a measure of how often and how ‘strongly’
    documents are classified as outliers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can compute our unrelatedness score and print the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: And that’s it! Here you will have your list of outliers documents ranked by
    unrelatedness. By cleaning up your Confluence spaces and removing irrelevant content,
    you can pave the way for creating a more efficient and valuable chatbot that leverages
    your organization’s knowledge. Happy cleaning!
  prefs: []
  type: TYPE_NORMAL
- en: Did you enjoy this article? Want to stay updated on future content like this?
    Don’t forget to follow me on Medium to get notified about my latest articles and
    insights in AI, machine learning, and more. Let’s continue our learning journey
    together!
  prefs: []
  type: TYPE_NORMAL
