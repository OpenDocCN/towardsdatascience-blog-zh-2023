- en: Building a Lego Technic sorter with Real-Time Advanced Object Recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/enhancing-nullspace-robotics-capabilities-building-a-lego-sorter-with-advanced-object-recognition-7ba5d70c9902?source=collection_archive---------5-----------------------#2023-11-02](https://towardsdatascience.com/enhancing-nullspace-robotics-capabilities-building-a-lego-sorter-with-advanced-object-recognition-7ba5d70c9902?source=collection_archive---------5-----------------------#2023-11-02)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@aveekgoswami?source=post_page-----7ba5d70c9902--------------------------------)[![Aveek
    Goswami](../Images/605b68f373d08d4d82223f9478417177.png)](https://medium.com/@aveekgoswami?source=post_page-----7ba5d70c9902--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7ba5d70c9902--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7ba5d70c9902--------------------------------)
    [Aveek Goswami](https://medium.com/@aveekgoswami?source=post_page-----7ba5d70c9902--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fff6c39b7b31a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fenhancing-nullspace-robotics-capabilities-building-a-lego-sorter-with-advanced-object-recognition-7ba5d70c9902&user=Aveek+Goswami&userId=ff6c39b7b31a&source=post_page-ff6c39b7b31a----7ba5d70c9902---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7ba5d70c9902--------------------------------)
    ·9 min read·Nov 2, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7ba5d70c9902&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fenhancing-nullspace-robotics-capabilities-building-a-lego-sorter-with-advanced-object-recognition-7ba5d70c9902&user=Aveek+Goswami&userId=ff6c39b7b31a&source=-----7ba5d70c9902---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7ba5d70c9902&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fenhancing-nullspace-robotics-capabilities-building-a-lego-sorter-with-advanced-object-recognition-7ba5d70c9902&source=-----7ba5d70c9902---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: '**During my internship at** [**Nullspace Robotics**](https://sg.nullspace.co)**,
    I had the privilege of diving into a project that would enhance the company’s
    capabilities. We integrated object detection and machine learning image recognition
    to develop a machine that classifies lego technic pieces in real time.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**In this blog post, I’ll guide you through the challenges encountered and
    how we successfully brought this project to fruition.**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a5719e3ed885a8b80b02d537557a7715.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Amos Koh and I spent our summer ’22 teaching students programming and robotics
    while working on this project for Nullspace. You can find us at the links below
    the article.*'
  prefs: []
  type: TYPE_NORMAL
- en: Nullspace Robotics is Singapore’s leading provider of robotics and programming
    education for primary and secondary school students. A large part of their operations
    involve building robots with lego technic parts which are sorted into specific
    trays. You can imagine it’s a nightmarish task asking an 8 year old with boundless
    energy to help put the pieces back into the tray when all they want to do is build
    more things.
  prefs: []
  type: TYPE_NORMAL
- en: Nullspace tasked us with making a machine that can sort the lego technic pieces
    into specific categories with minimal human intervention to solve one of the key
    efficiency challenges when conducting a robotics lesson
  prefs: []
  type: TYPE_NORMAL
- en: Defining the Challenge
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The project involved 3 main parts: real-time object and motion detection, image
    recognition and building the hardware of the machine. Due to the time constraints
    of the internship, we primarily focused on the first two items which involved
    the software aspects of the project.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A key challenge was to recognise moving parts and identify them within the
    same frame. We contemplated two approaches: integrating machine learning image
    recognition into the object detection camera or keeping the processes separate.'
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, we decided on separating object detection and recognition. This
    approach involved first capturing a suitable picture after detecting the object
    and then running a model to clasify the image. Integrating the processes together
    would require running the model on practically every frame to classify every object
    detected. Separating them eliminated the need for the model to be in a constant
    processing mode, ensuring a smoother and more computationally efficient operation.
  prefs: []
  type: TYPE_NORMAL
- en: '**Object Detection**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We used ideas from the projects cited below the article to implement our object/motion
    detection program and customise it to lego pieces
  prefs: []
  type: TYPE_NORMAL
- en: In our case, we used similar motion detection concepts because our machine would
    involve a conveyor belt system of uniform colour, so any motion detected would
    be due to a lego piece moving on the belt.
  prefs: []
  type: TYPE_NORMAL
- en: 'We applied gaussian blurring as well as other image processing techniques to
    all frames and compared it with previous frames. Further processing was done to
    isolate (draw bounding boxes around) the items causing motion as shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: To ensure the motion was actually caused by a lego piece, the stability of the
    motion detection was assessed using a motion counter, which checked that motion
    was detected for a certain number of frames before concluding that the motion
    was actually due to a lego piece and not miscellaneous noise. The final image
    is then saved and fed into our CNN to classify it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Creating the Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Building the dataset**'
  prefs: []
  type: TYPE_NORMAL
- en: We created the dataset of images ourselves rather than using images of lego
    technic pieces found online because we wanted to replicate the conditions under
    which the model would be detecting and classifying the pieces eventually. We hence
    designed a simple conveyor belt system using none other than lego technic pieces
    themselves! We then hooked it up to an lego spike prime motor to keep the conveyor
    belt moving.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2e2e1ef3fe6d6b3949357d1d2bcb5a94.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Designing the model architecture**'
  prefs: []
  type: TYPE_NORMAL
- en: To address the heart of the challenge, I adapted a machine learning model I
    found on Aladdinpersson’s GitHub repository. This model featured convolutional
    layers with a sequence from 128 to 64 to 32 to 16, an architectural choice designed
    to improve image recognition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of using a pre-trained model, we designed our own convolutional neural
    network because:'
  prefs: []
  type: TYPE_NORMAL
- en: We did not require particularly deep feature extraction for our images
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We wanted to keep the model small and reduce its complexity, at the same time
    reducing the computational cost of running the model. This would enable to run
    the CNN as a tflite model more efficiently on the Pi.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Data normalization was a crucial step to ensure consistent training accuracy,
    especially given the variation in the range of values captured by different images
    due to lighting differences.
  prefs: []
  type: TYPE_NORMAL
- en: In this model, various layers such as ReLU, dense, softmax, and flatten played
    pivotal roles. ReLU activation, for example, was essential for image classification
    as it mitigated the issue of vanishing gradients in image recognition. Dense layers,
    on the other hand, are standard in Tensorflow models, facilitating densely connected
    neural networks. Softmax activation was used to calculate probabilities for each
    category in our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: For loss functions, we employed Keras’ Sparse Categorical Cross Entropy, a fitting
    choice for multi-class classification tasks. The Keras Adam optimizer, renowned
    for its efficiency, was used to fine-tune the model.
  prefs: []
  type: TYPE_NORMAL
- en: '**Training and Optimization**'
  prefs: []
  type: TYPE_NORMAL
- en: Epochs were carefully selected to strike a balance between training and overfitting,
    with a preference for a number below 200 to ensure optimal model performance.
    For accelerated model training, we harnessed Google Colab, which provided access
    to GPU resources, ensuring significantly faster training speeds compared to our
    own laptops.
  prefs: []
  type: TYPE_NORMAL
- en: 'The full model architecture is shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Choosing the architecture**'
  prefs: []
  type: TYPE_NORMAL
- en: In most common CNN architectures, the number of filters increases to try and
    capture more complex features at higher layers. However, for distinguishing between
    our Lego pieces, there was a high degree of similarity among classes, and we need
    our network to look for specific features such as bends and holes. I felt that
    a smaller number of filters in deeper layers might help in focusing on these fewer
    subtle differences, rather than looking at multiple features which may not help
    in discriminating the pieces.
  prefs: []
  type: TYPE_NORMAL
- en: We tested both architectures out, with decreasing filters and increasing filters,
    and the decreasing filter model performed significantly better. It hence seems
    that by reducing the number of filters, we can get the network focus on what is
    essential, reducing noise from complex feature maps.
  prefs: []
  type: TYPE_NORMAL
- en: '*Of course, it depends on your use case and the distinguishing features present
    in your dataset. Something like facial recognition for example would need a more
    complex feature map, so the increasing filter approach may work better.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Model results**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The model was trained with 6000 images spanning 7 categories of lego technic
    blocks. It achieved a final validation accuracy of **93%**. Diagrams showing the
    progression of training as well as a confusion matrix to assess performance are
    shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8da60f1fe85e0e69ae73b076c5da5cd6.png)'
  prefs: []
  type: TYPE_IMG
- en: Implementing the model on the Raspberry Pi
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The most efficient way to run a neural network on a pi is as a tflite (tensorflow
    lite) model. We saved the model locally and then loaded it onto the Pi.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Continuing from the motion counter for loop above, the suitable images were
    then fed into the neural network to be classified:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Flexibility was a key consideration. The motion counter could be adjusted for
    the process of either capturing images to build the dataset or set the threshold
    for when the image should be captured for classification, enhancing the system’s
    versatility.
  prefs: []
  type: TYPE_NORMAL
- en: Demonstration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The culmination of our efforts was a showcase of the system’s overall accuracy,
    supported by photos and videos capturing its operation. The conveyor belt setup
    (above) was an essential part of this demonstration:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a7725099423eb08137c26cfafb1f89f7.png)![](../Images/2428c86acf96a1fbd484b8396e3bf7e2.png)'
  prefs: []
  type: TYPE_IMG
- en: Future Work and Areas for improvement
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Software: A future extension would also be to include a quality checker model
    in the operation to ensure that the images used to classify the pieces are suitable.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Hardware: The model would undoubtedly benefit from a superior camera for higher
    quality images. Moreover, the conveyor belt system built temporarily for our testing
    and demonstration will need to be scaled up to accommodate more pieces. A method
    will also need to be devised and implemented to separate multiple lego pieces
    and ensure only one piece is visible in the camera’s frame at the time. There
    are similar projects available online which go into detail on possible methods.'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: My journey at Nullspace Robotics was my first foray into building my own neural
    network for practical purposes. Having designed models as part of training courses
    in the past, it’s a wholly different experience creating one intended for actual
    production, where we need to account for factors such as resources, use purposes,
    and figuring out how to tailor our dataset and model to fit out purposes. I look
    forward to continuing my journey in machine learning and leveraging the latest
    AI technologies to build more innovative solutions.
  prefs: []
  type: TYPE_NORMAL
- en: I would like to thank Nullspace for the opportunity to work on this project
    and am excited to see what’s next for the company as it pushes the boundaries
    of robotics education.
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the full repository on Github or HuggingFace for the code, access
    to the dataset images and more information about the project:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Github: [https://github.com/magichampz/lego-sorting-machine-ag-ak/](https://github.com/magichampz/lego-sorting-machine-ag-ak/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'HuggingFace: [https://huggingface.co/magichampz](https://huggingface.co/magichampz)'
  prefs: []
  type: TYPE_NORMAL
- en: Meet the developers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Aveek: [https://www.linkedin.com/in/aveekg00/](https://www.linkedin.com/in/aveekg00/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Amos: [https://www.linkedin.com/in/ak726/](https://www.linkedin.com/in/ak726/)'
  prefs: []
  type: TYPE_NORMAL
- en: Check out [Nullspace Robotics](https://sg.nullspace.co)
  prefs: []
  type: TYPE_NORMAL
- en: 'References:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[](https://pyimagesearch.com/2015/05/25/basic-motion-detection-and-tracking-with-python-and-opencv/?source=post_page-----7ba5d70c9902--------------------------------)
    [## Basic motion detection and tracking with Python and OpenCV — PyImageSearch'
  prefs: []
  type: TYPE_NORMAL
- en: In this tutorial, I’ll show you how to use Python and OpenCV to perform basic
    motion detection and tracking. Learn how…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: pyimagesearch.com](https://pyimagesearch.com/2015/05/25/basic-motion-detection-and-tracking-with-python-and-opencv/?source=post_page-----7ba5d70c9902--------------------------------)
    [](/image-analysis-for-beginners-creating-a-motion-detector-with-opencv-4ca6faba4b42?source=post_page-----7ba5d70c9902--------------------------------)
    [## Detecting motion with OpenCV — image analysis for beginners
  prefs: []
  type: TYPE_NORMAL
- en: How to detect and analyze moving objects with OpenCV
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/image-analysis-for-beginners-creating-a-motion-detector-with-opencv-4ca6faba4b42?source=post_page-----7ba5d70c9902--------------------------------)
    [](https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/TensorFlow/Basics/tutorial15-customizing-modelfit.py?source=post_page-----7ba5d70c9902--------------------------------)
    [## Machine-Learning-Collection/ML/TensorFlow/Basics/tutorial15-customizing-modelfit.py
    at master ·…
  prefs: []
  type: TYPE_NORMAL
- en: A resource for learning about Machine learning & Deep Learning …
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/TensorFlow/Basics/tutorial15-customizing-modelfit.py?source=post_page-----7ba5d70c9902--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Outtakes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/4ffed3f50aa90501db4c8d22d2657f79.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Unless otherwise noted, all images are by the author*'
  prefs: []
  type: TYPE_NORMAL
