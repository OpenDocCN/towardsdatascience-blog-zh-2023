- en: Finding Needles in a Haystack — Search Indexes for Jaccard Similarity
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在干草堆中找针 — Jaccard 相似度的搜索索引
- en: 原文：[https://towardsdatascience.com/finding-needles-in-a-haystack-search-indexes-for-jaccard-similarity-db1ccdaa8d17?source=collection_archive---------4-----------------------#2023-08-18](https://towardsdatascience.com/finding-needles-in-a-haystack-search-indexes-for-jaccard-similarity-db1ccdaa8d17?source=collection_archive---------4-----------------------#2023-08-18)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/finding-needles-in-a-haystack-search-indexes-for-jaccard-similarity-db1ccdaa8d17?source=collection_archive---------4-----------------------#2023-08-18](https://towardsdatascience.com/finding-needles-in-a-haystack-search-indexes-for-jaccard-similarity-db1ccdaa8d17?source=collection_archive---------4-----------------------#2023-08-18)
- en: From basic concepts to exact and approximate indexes
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从基础概念到精确和近似索引
- en: '[](https://ekzhu.medium.com/?source=post_page-----db1ccdaa8d17--------------------------------)[![Eric
    Zhù](../Images/d1e5938b5ebeec307a01d717e09f3b30.png)](https://ekzhu.medium.com/?source=post_page-----db1ccdaa8d17--------------------------------)[](https://towardsdatascience.com/?source=post_page-----db1ccdaa8d17--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----db1ccdaa8d17--------------------------------)
    [Eric Zhù](https://ekzhu.medium.com/?source=post_page-----db1ccdaa8d17--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ekzhu.medium.com/?source=post_page-----db1ccdaa8d17--------------------------------)[![Eric
    Zhù](../Images/d1e5938b5ebeec307a01d717e09f3b30.png)](https://ekzhu.medium.com/?source=post_page-----db1ccdaa8d17--------------------------------)[](https://towardsdatascience.com/?source=post_page-----db1ccdaa8d17--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----db1ccdaa8d17--------------------------------)
    [Eric Zhù](https://ekzhu.medium.com/?source=post_page-----db1ccdaa8d17--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5b549f62ef70&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffinding-needles-in-a-haystack-search-indexes-for-jaccard-similarity-db1ccdaa8d17&user=Eric+Zh%C3%B9&userId=5b549f62ef70&source=post_page-5b549f62ef70----db1ccdaa8d17---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----db1ccdaa8d17--------------------------------)
    ·15 min read·Aug 18, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdb1ccdaa8d17&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffinding-needles-in-a-haystack-search-indexes-for-jaccard-similarity-db1ccdaa8d17&user=Eric+Zh%C3%B9&userId=5b549f62ef70&source=-----db1ccdaa8d17---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5b549f62ef70&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffinding-needles-in-a-haystack-search-indexes-for-jaccard-similarity-db1ccdaa8d17&user=Eric+Zh%C3%B9&userId=5b549f62ef70&source=post_page-5b549f62ef70----db1ccdaa8d17---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----db1ccdaa8d17--------------------------------)
    · 15 分钟阅读 · 2023年8月18日'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdb1ccdaa8d17&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffinding-needles-in-a-haystack-search-indexes-for-jaccard-similarity-db1ccdaa8d17&source=-----db1ccdaa8d17---------------------bookmark_footer-----------)![](../Images/b908929fab9e1511d3be9e9741d26730.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdb1ccdaa8d17&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffinding-needles-in-a-haystack-search-indexes-for-jaccard-similarity-db1ccdaa8d17&source=-----db1ccdaa8d17---------------------bookmark_footer-----------)![](../Images/b908929fab9e1511d3be9e9741d26730.png)'
- en: Finding Needles in a Haystack. Image by the author using Midjourney.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在干草堆中找针。图像由作者使用 Midjourney 制作。
- en: Vector databases are in the news for being the external memory of large language
    models (LLMs). The vector databases today are new systems built on decade-old
    research called approximate nearest neighbor (ANN) indexes. These indexing algorithms
    takes many high-dimensional vectors (e.g., `float32[]`), and built a data structure
    that supports finding the approximate neighbors of a query vector in the high-dimensional
    space. It is like Google Map finds your neighbors’ houses given your house’s latitude
    and longitude, except the ANN indexes operate in a much higher dimensional space.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 向量数据库因作为大型语言模型（LLMs）的外部记忆而成为新闻话题。如今的向量数据库是建立在十年前的近似最近邻（ANN）索引研究基础上的新系统。这些索引算法处理许多高维向量（例如`float32[]`），并构建一个数据结构，支持在高维空间中找到查询向量的近似邻居。这就像Google地图根据你家的纬度和经度找到你邻居的房子一样，只不过ANN索引在更高维空间中操作。
- en: This line of research has a history that dates back decades. In the late 90s,
    ML researchers were hand-crafting numerical features for multimedia data such
    as image and audio. Similarity search based on these feature vectors became a
    natural problem. For a while, researchers crowded this area. This academic bubble
    broke when a seminal paper, [*When is “Nearest Neighbor” Meaningful?*](https://faculty.ist.psu.edu/vhonavar/Courses/ds310/WhenIsNearestNeighborMeaningful.pdf),
    basically told everyone stop wasting time because nearest neighbor in high-dimensional
    space of hand-crafted features is *mostly* not meaningful — an interesting topic
    for another post. Still to this day, I keep seeing research papers and [vector
    database benchmarks](https://github.com/erikbern/ann-benchmarks) publishing performance
    numbers on the SIFT-128 dataset, which consists of exactly the hand-crafted feature
    vectors with meaningless similarity.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这项研究有着几十年的历史。90年代末，机器学习研究人员手工制作多媒体数据（如图像和音频）的数值特征。基于这些特征向量的相似性搜索成为一个自然的问题。一段时间内，研究人员涌入这一领域。这一学术泡沫在一篇开创性论文[*When
    is “Nearest Neighbor” Meaningful?*](https://faculty.ist.psu.edu/vhonavar/Courses/ds310/WhenIsNearestNeighborMeaningful.pdf)
    发表后破裂，基本告诉大家不要浪费时间，因为在手工制作特征的高维空间中的最近邻*大多*是不具有意义的——这是另一个话题。即便如此，我仍然看到研究论文和[向量数据库基准测试](https://github.com/erikbern/ann-benchmarks)发布关于SIFT-128数据集的性能数据，该数据集由具有无意义相似性的手工制作特征向量组成。
- en: 'Despite the noise around hand-crafted features, there has been a fruitful line
    of research focusing on one high-dimensional data type with meaningful similarity:
    ***set*** and ***Jaccard***.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管手工制作特征存在噪声，但研究中有一条富有成果的方向专注于一种具有意义的高维数据类型：***集合***和***Jaccard***。
- en: In this post I cover search indexes for Jaccard similarity over sets. I will
    start with the basic concepts, and then move on to exact and approximate indexes.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将介绍集合上Jaccard相似性的搜索索引。我将从基本概念开始，然后转向精确和近似索引。
- en: Set and Jaccard
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集合和Jaccard
- en: A set is just a collection of distinct elements. The songs you liked on Spotify
    is a set; the tweets your retweeted last week is a set; and the distinct tokens
    extracted from this blog post also form a set. Set is a natural way to represent
    data points in application scenarios like music recommendation, social network,
    and plagiarism detection.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 集合只是不同元素的集合。你在Spotify上喜欢的歌曲是一个集合；你上周转发的推文是一个集合；从这篇博客文章中提取的不同令牌也形成一个集合。集合是表示数据点的一种自然方式，适用于音乐推荐、社交网络和剽窃检测等应用场景。
- en: 'Let’s say on Spotify, I follow these artists:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 假设在Spotify上，我关注了这些艺术家：
- en: '`[the weekend, taylor swift, wasia project]`'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '`[the weekend, taylor swift, wasia project]`'
- en: 'and my daughter follows these artists:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我的女儿关注了这些艺术家：
- en: '`[the weekend, miley cyrus, sza]`'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '`[the weekend, miley cyrus, sza]`'
- en: A reasonable way to measure the similarity of our music tastes is to see how
    many artists we both follow — the intersection size. In this case we both follow
    `the weekend`, so the intersection size is 1.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 衡量我们音乐品味相似性的一个合理方法是看我们共同关注了多少艺术家——即交集大小。在这种情况下，我们都关注了`the weekend`，所以交集大小为1。
- en: '![](../Images/d00f4cc116700727294fa5a4fd4940a5.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d00f4cc116700727294fa5a4fd4940a5.png)'
- en: Each set represents a user’s following list. The intersection shows the common
    followings shared by both users. Image by the author.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 每个集合代表一个用户的关注列表。交集显示了两个用户共享的共同关注。图片由作者提供。
- en: However, you could imagine another pair of users each follows 100 artists, and
    the intersection size is also 1, but the similarity in their tastes should be
    much smaller than the similarity between my daughter’s and mine. To make the measurement
    comparable across different pairs of users, we normalize the intersection size
    with the union size. This way, the similarity between my daughter’s and my followings
    is `1 / 5 = 0.2`, and the similarity between the other pair of users’ followings
    is `1 / 199 ~= 0.005`. This is called Jaccard similarity.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，你可以想象另一对用户每人关注100位艺术家，它们的交集大小仍然是1，但他们的品味相似度应该远低于我女儿和我之间的相似度。为了使不同用户对之间的测量具有可比性，我们用并集大小来归一化交集大小。这样，我女儿和我关注的相似度为`1
    / 5 = 0.2`，而另一对用户关注的相似度为`1 / 199 ~= 0.005`。这被称为Jaccard相似度。
- en: 'For a set `A` and a set `B`, the formula for Jaccard similarity is:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对于集合`A`和集合`B`，Jaccard相似度的公式是：
- en: '![](../Images/952c0040f88159f0452076f2a213b264.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/952c0040f88159f0452076f2a213b264.png)'
- en: Jaccard similarity formula for set A and B.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 集合A和B的Jaccard相似度公式。
- en: 'Why is set a high-dimensional data type? A set can be encoded as a “one-hot”
    vector, whose dimensions 1-to-1 map to all possible elements (e.g., all artists
    on Spotify). A dimension in this vector has a value of 1 if the set contains the
    element corresponding to this dimension, and 0 otherwise. So, the vectorized set
    of my followed artists look like the following:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么集合是高维数据类型？集合可以编码为“one-hot”向量，其维度1对1映射到所有可能的元素（例如，Spotify上的所有艺术家）。如果集合包含对应于该维度的元素，则该维度的值为1，否则为0。因此，我关注的艺术家的向量化集合如下所示：
- en: '![](../Images/d15e8385c01a2ba371ac1326433d9454.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d15e8385c01a2ba371ac1326433d9454.png)'
- en: High-dimensional vector representation of the set of followings. Image by the
    author.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 高维向量表示关注集合。图像由作者提供。
- en: where the second, third, and the third from the last dimensions are `the weekend`,
    `taylor swift`, and `wasia project`. There are over 10 million artists on Spotify,
    so a vector like this is extremely high dimensional and very sparse — most dimensions
    are 0s.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 其中第二、第三和倒数第三个维度分别是`the weekend`、`taylor swift`和`wasia project`。Spotify上有超过1000万的艺术家，因此这样的向量维度极高且非常稀疏——大多数维度为0。
- en: Inverted Indexes for Jaccard Search
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Jaccard搜索的反向索引
- en: People want to find things quickly, so computer scientists invented data structures
    called indexes to make search performance satisfactory for software applications.
    Specifically, a Jaccard search index is built on a collection of sets, given a
    query set, it returns `k` sets that have the highest Jaccard with the query set.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 人们希望快速找到事物，因此计算机科学家发明了被称为索引的数据结构，以使搜索性能对软件应用程序满意。具体来说，Jaccard搜索索引是建立在一组集合上的，给定一个查询集合，它返回与查询集合具有最高Jaccard相似度的`k`个集合。
- en: 'Search index for Jaccard is based on a data structure called inverted index.
    An inverted index has an extremely simple interface: input a set element, say
    `the weekend`, it returns a list of IDs of sets that contain the input element,
    e.g., `[ 32, 231, 432, 1322, ...]`. The inverted index is essentially a lookup
    table whose keys are all possible set elements, and values are lists of set IDs.
    In this example, each list in the inverted index represents the IDs of the followers
    of an artist.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Jaccard的搜索索引基于一种称为反向索引的数据结构。反向索引具有极其简单的接口：输入一个集合元素，比如`the weekend`，它返回包含输入元素的集合ID列表，例如`[
    32, 231, 432, 1322, ...]`。反向索引本质上是一个查找表，其键是所有可能的集合元素，值是集合ID列表。在这个例子中，反向索引中的每个列表表示一个艺术家的关注者ID。
- en: '![](../Images/e35f6d3782a0eef367f83e38a706f6e2.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e35f6d3782a0eef367f83e38a706f6e2.png)'
- en: Inverted index contains lists of set IDs matching the query set. Image by the
    author.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 反向索引包含与查询集合匹配的集合ID列表。图像由作者提供。
- en: '![](../Images/c7d321e010b7d33cd3e21f2838a58265.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c7d321e010b7d33cd3e21f2838a58265.png)'
- en: Original sets are stored in a separate table for lookup by their set IDs. Image
    by the author.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 原始集合存储在一个单独的表中，以便通过其集合ID进行查找。图像由作者提供。
- en: 'You can see the reason why this is called “inverted index”: it allows you to
    go from a set element to find sets that contain the element.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到这为什么被称为“反向索引”：它允许你从一个集合元素找到包含该元素的集合。
- en: Exact Search Algorithm
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 精确搜索算法
- en: Inverted index is incredibly powerful data structure for speeding up search.
    Using inverted index, when search, instead of going through all the sets and compare
    each with the query set — very expensive if you have millions of sets, you only
    need to process the IDs of the sets that share at least one element with the query
    set. You can obtain the set IDs directly from the inverted index lists.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 倒排索引是加速搜索的极其强大的数据结构。使用倒排索引时，在搜索时，你不需要遍历所有集合并与查询集合进行比较——如果你有数百万个集合，这会非常昂贵，你只需要处理与查询集合共享至少一个元素的集合
    ID。你可以直接从倒排索引列表中获取集合 ID。
- en: 'This idea is implemented by the following search algorithm:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法是通过以下搜索算法实现的：
- en: '[PRE0]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In plain English, the algorithm walks through every inverted index list matched
    by elements in the query set and uses a candidate table to keep track of the number
    of times each set ID appears. If a set ID appears `n` times, the indexed set has
    `n` overlapping elements with the query set. In the end, the algorithm uses all
    the information in the candidate table to calculate Jaccard similarities, and
    then returns the IDs of the top-k most similar sets.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 用通俗的语言来说，该算法遍历查询集合中元素匹配的每个倒排索引列表，并使用候选表跟踪每个集合 ID 出现的次数。如果一个集合 ID 出现了`n`次，则索引集合与查询集合有`n`个重叠元素。最后，算法使用候选表中的所有信息来计算
    Jaccard 相似度，然后返回最相似的前 k 个集合的 ID。
- en: '![](../Images/092291d3e27e5e73587c9a307a19cd96.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/092291d3e27e5e73587c9a307a19cd96.png)'
- en: The candidate table in the **search_top_k_merge_list** algorithm is used to
    keep track of the overlap counts of indexed sets found through the inverted index.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**search_top_k_merge_list**算法中的候选表用于跟踪通过倒排索引找到的索引集合的重叠计数。'
- en: 'The `search_top_k_merge_list` algorithm can be fast when: (1) the number of
    elements in the query set is small and (2) the number of IDs in the inverted index
    lists for the query elements are small. In the Spotify scenario, this could be
    the case if most people follow a few artists (likely true) and all artists have
    more-or-less the same number of followers (not true). We all know it is a fact
    that a few top artists are followed by most people and most artists have few followers.
    After all, the music industry follows the [Pareto Distribution](https://en.wikipedia.org/wiki/Pareto_distribution).'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当以下情况发生时，`search_top_k_merge_list`算法可以很快：(1) 查询集合中的元素数量较小，以及 (2) 查询元素的倒排索引列表中的
    ID 数量较少。在 Spotify 场景中，如果大多数人关注的艺术家不多（可能是这样），并且所有艺术家拥有的粉丝数量大致相同（不准确）。我们都知道，少数顶级艺术家受到大多数人的关注，而大多数艺术家的粉丝很少。毕竟，音乐产业遵循[帕累托分布](https://en.wikipedia.org/wiki/Pareto_distribution)。
- en: Taylor Swift has 78 million followers on Spotify, and The Weekend has 67 million.
    Having them on my following list means the `search_top_k_merge_list` algorithm
    will need to walk through at least 145 million set IDs and the candidate table
    `candidates` will grow to this astronomical size. Despite the fact that computers
    today are fast and powerful, on my Intel i7 machine, creating a table of this
    size still takes at least 30 seconds (Python) and dynamically allocates 2.5 GB
    of memory.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 泰勒·斯威夫特在 Spotify 上有 7800 万粉丝，而周末（The Weekend）有 6700 万粉丝。将他们添加到我的关注列表中意味着`search_top_k_merge_list`算法需要遍历至少
    1.45 亿个集合 ID，并且候选表`candidates`将增长到这个天文数字的规模。尽管今天的计算机速度快且强大，在我的 Intel i7 机器上，创建这样一个表仍然需要至少
    30 秒（Python），并动态分配 2.5 GB 的内存。
- en: Most people follow some of these super star artists. So, if you use this algorithm
    in your search application, you will for sure get a gargantuan cloud hosting bill
    for large resource usage and terrible user experience for high search latency.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数人关注一些超级明星艺术家。因此，如果你在搜索应用中使用这个算法，你肯定会因为大规模资源使用而获得一笔巨额的云托管账单，并且由于搜索延迟高，用户体验将会很差。
- en: Branch and Bound Optimization
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分支限界优化
- en: Intuitively, the previous algorithm `search_top_k_merge_list` processes all
    potential candidates in a breadth-first fashion because it only uses the inverted
    index to compute intersection. This algorithm performs poorly due to super star
    artists with millions of followers.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 从直观上看，之前的算法`search_top_k_merge_list`以广度优先的方式处理所有潜在候选，因为它仅使用倒排索引来计算交集。由于超级明星艺术家拥有数百万粉丝，这个算法表现不佳。
- en: Another approach is to be more selective about potential candidates. Imagine
    interviewing candidates for a job and you are the hiring manager. You cannot afford
    to interview all potential candidates who send you CVs, so you sort the candidates
    into buckets based on your job criteria and start interviewing candidates who
    hit the criteria your care about the most. As you are interviewing them one by
    one you evaluate whether each one actually hit all or most of your criteria and
    stop interviewing when you found someone.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是对潜在候选更加挑剔。假设你在面试候选人，你是招聘经理。你无法面试所有给你发送简历的潜在候选人，因此你根据招聘标准将候选人分到不同的类别中，并开始面试那些符合你最关心标准的候选人。随着你逐个面试，你评估每个人是否符合所有或大部分标准，当找到符合要求的人时停止面试。
- en: This approach also works when it comes to finding similar sets of followed artists.
    The idea is that you want to start from the artist with the **least number of
    followers** in your query set. Why? Simply because those artists give you fewer
    candidate sets to work with, so that you can process less lists of artists from
    the inverted index and find your best `k` candidates more quickly. In my Spotify’s
    following list, `wasian project` only has 1 million followers — way less than
    `taylor swift`. Those much smaller number of people that follows `wasian project`
    has the same potential to be in the best `k` candidates than those much larger
    number of people that follow `taylor swift`.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '这种方法在寻找类似的关注艺术家集合时也适用。这个想法是你希望从查询集中关注 **最少粉丝数** 的艺术家开始。为什么？因为这些艺术家提供的候选集较少，这样你可以处理更少的倒排索引列表，更快找到你最佳的
    `k` 个候选。在我的 Spotify 关注列表中，`wasian project` 只有 100 万粉丝——远少于 `taylor swift`。那些关注
    `wasian project` 的粉丝数量远少于关注 `taylor swift` 的粉丝，但他们有同样的潜力成为最佳 `k` 个候选。 '
- en: The key insight here is that we do not want to process all potential candidate
    lists but stop when we processed enough. The tricky part is to know when to stop.
    The following is a modified version of the previous algorithm that implements
    the idea.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的关键洞察是我们不希望处理所有潜在候选列表，而是在处理到足够数量时停止。棘手的部分是知道何时停止。以下是一个修改版的算法，实现了这个思想。
- en: '[PRE1]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `search_top_k_probe_set` algorithm computes Jaccard similarity for every
    new candidate it found. It keeps track of the current best `k` candidates at all
    times, and it stops when the upper bound Jaccard of any new candidate is no greater
    than the minimum Jaccard of the current best `k` candidates.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`search_top_k_probe_set` 算法为它找到的每个新候选计算 Jaccard 相似度。它始终跟踪当前最佳的 `k` 个候选，并在任何新候选的上界
    Jaccard 相似度不大于当前最佳 `k` 个候选的最小 Jaccard 相似度时停止。'
- en: '![](../Images/ea42c9db8d21b9c284d5c1f7e8ce6b02.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ea42c9db8d21b9c284d5c1f7e8ce6b02.png)'
- en: The **search_top_k_probe_set** algorithm walks through the inverted index lists
    and computes the Jaccard similarity for every candidate set it encounters and
    keeps track of the current top-k candidate sets. It stops when the maximum Jaccard
    similarity of any set in the unseen lists is no greater than the minimum similarity
    of the current top-k candidates. Image by the author.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**search_top_k_probe_set** 算法遍历倒排索引列表，为每个遇到的候选集计算 Jaccard 相似度，并跟踪当前的 top-k
    候选集。当未处理列表中任何集合的最大 Jaccard 相似度不大于当前 top-k 候选集的最小相似度时，它就会停止。图片由作者提供。'
- en: 'How to compute the upper bound Jaccard? After processing `n` lists of candidates,
    for any unseen candidate, their maximum intersection with the query set is at
    most equal to the number of remaining unprocessed lists: `|Q|-n`. We are giving
    it the most benefit of doubt by saying that such candidate may show up in every
    single one of the `|Q|-n` remaining lists. Now we can use simple math to derive
    the upper bound Jaccard of such candidate `X`.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如何计算 Jaccard 相似度的上界？在处理了 `n` 个候选列表之后，对于任何未见候选，其与查询集的最大交集最多等于剩余未处理列表的数量：`|Q|-n`。我们给予它最大的怀疑，以便认为该候选可能出现在每一个剩余的
    `|Q|-n` 列表中。现在我们可以使用简单的数学推导该候选 `X` 的上界 Jaccard 相似度。
- en: '![](../Images/149d53d26af727515829448b9532d6c1.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/149d53d26af727515829448b9532d6c1.png)'
- en: The formula for calculating the upper bound of Jaccard similarity between an
    unseen candidate indexed set X and query set Q, after walking through n lists
    of candidates.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 计算一个未见候选索引集 X 和查询集 Q 之间 Jaccard 相似度的上界的公式，经过处理了 n 个候选列表之后。
- en: This clever technique is called *Prefix Filter* in set similarity search research
    literature. I wrote [a paper](https://dl.acm.org/doi/pdf/10.1145/3299869.3300065)
    about it that goes into much more details and further algorithmic optimizations.
    I also created a Python library [SetSimilaritySearch](https://github.com/ekzhu/SetSimilaritySearch)
    that implements a much more optimized version of the the `search_top_k_probe_set`
    algorithm that also supports cosine and containment similarity measures.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这个巧妙的技术在集合相似性搜索研究文献中被称为*前缀过滤器*。我写了一篇[论文](https://dl.acm.org/doi/pdf/10.1145/3299869.3300065)，详细讲述了这一点以及进一步的算法优化。我还创建了一个
    Python 库[SetSimilaritySearch](https://github.com/ekzhu/SetSimilaritySearch)，实现了一个更优化的
    `search_top_k_probe_set` 算法版本，并支持余弦和包含相似性度量。
- en: Approximate Index for Jaccard Search
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Jaccard 搜索的近似索引
- en: In the last section, I explained two search algorithms that work on inverted
    index. These algorithms are **exact**, meaning that the `k` best candidates they
    return are the true `k` best candidates. Sounds trite? Well, this is a question
    we should ask ourselves whenever we design search algorithms on large-scale data,
    because in many scenarios it is not necessary to get the true `k` best candidates.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一部分，我解释了两种基于倒排索引的搜索算法。这些算法是**精确的**，意味着它们返回的 `k` 个最佳候选项确实是最好的 `k` 个候选项。听起来老生常谈？其实，这是我们在设计大规模数据上的搜索算法时应该问自己的问题，因为在许多情况下，获取真实的
    `k` 个最佳候选项并非必要。
- en: 'Think about the Spotify example again: do you really care if the result of
    a search may miss a few people with similar taste as yours? Most people understand
    that in everyday applications (Google, Spotify, Twitter, etc.), the search is
    never exhaustive or exact. These applications are not mission critical enough
    to justify exact search. This is why the most widely used search algorithms are
    all approximate.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 再考虑一下 Spotify 的例子：你真的在乎搜索结果可能会遗漏一些与您品味相似的人吗？大多数人都明白，在日常应用程序（如 Google、Spotify、Twitter
    等）中，搜索从来不会是详尽无遗或完全准确的。这些应用程序的任务并不足以证明精确搜索的必要性。这就是为什么最广泛使用的搜索算法都是近似的。
- en: 'There are mainly two benefits of using approximate search algorithms:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 使用近似搜索算法主要有两个好处：
- en: Faster. You can cut many corners if you no longer need exact results.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更快。如果你不再需要精确的结果，你可以省去许多步骤。
- en: Predicable resource consumption. This one is less obvious, but for several approximate
    algorithms, their resource usage (e.g., memory) can be configured *a priori* independent
    of data distribution.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可预测的资源消耗。这一点不那么明显，但对于几种近似算法，它们的资源使用（例如内存）可以在*事先*配置，与数据分布无关。
- en: 'In this post, I write about the most widely used approximate index for Jaccard:
    Minwise Locality Sensitive Hashing (MinHash LSH).'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将讨论 Jaccard 最常用的近似索引：最小化局部敏感哈希（MinHash LSH）。
- en: What is LSH?
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是 LSH？
- en: Locality Sensitive Hashing indexes are true wonders in computer science. They
    are algorithmic magic powered by number theory. In machine learning literature,
    they are k-NN models, but unlike typical machine learning models, LSH indexes
    are data-agnostic so their accuracy conditioned on similarity can be determined
    *a priori* before ingesting new data points or changing data distribution. So,
    they are more similar to inverted indexes than a model.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 局部敏感哈希索引在计算机科学中确实是奇迹。它们是由数论驱动的算法魔法。在机器学习文献中，它们被称为 k-NN 模型，但与典型的机器学习模型不同，LSH
    索引对数据无关，因此它们在相似性条件下的准确性可以在*事先*确定，而不需要在摄取新数据点或更改数据分布之前进行调整。因此，它们更类似于倒排索引而不是模型。
- en: An LSH index is essentially a set of hash tables each with a different hash
    function. Just like a typical hash table, an LSH index’s hash function takes a
    data point (e.g., a set, a feature vector, or an embedding vector) as input, and
    outputs a binary hash key. Except for this, they cannot be more different.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: LSH 索引本质上是一组具有不同哈希函数的哈希表。就像典型的哈希表一样，LSH 索引的哈希函数将一个数据点（例如，一个集合、特征向量或嵌入向量）作为输入，并输出一个二进制哈希键。除此之外，它们没有更多的相似之处。
- en: A typical hash function outputs keys that are pseudo-randomly and uniformly
    distributed over the entire key space for any input data. For example, MurmurHash
    is a well-known hash function that outputs near-uniformly and randomly over a
    32-bit key space. This means that for any two inputs, such as `abcdefg` and `abcefg`,
    as long as they are different, their MurmurHash keys should not be correlated
    and should have the same probability to be any one of the keys in the entire 32-bit
    key space. This is a desired property of a hash function, because you want even
    distribution of keys over hash buckets to avoid chaining or constantly resizing
    your hash table.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的哈希函数输出的键在整个键空间中是伪随机且均匀分布的。比如，MurmurHash 是一个著名的哈希函数，它在 32 位键空间中输出近乎均匀且随机的哈希值。这意味着对于任何两个输入，例如
    `abcdefg` 和 `abcefg`，只要它们不同，它们的 MurmurHash 键就不应有相关性，并且在整个 32 位键空间中出现的概率应相同。这是哈希函数的一个期望特性，因为你希望键在哈希桶中均匀分布，以避免链表或不断调整哈希表的大小。
- en: 'An LSH’s hash function does something opposite: for a pair of similar inputs,
    with similarity defined through some metric space measure, their hash keys should
    be more likely to be equal, than another pair of hash keys of dis-similar inputs.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: LSH 的哈希函数执行的是相反的操作：对于一对相似的输入，定义相似度的度量空间中，它们的哈希键更有可能相等，而不是另一对不相似输入的哈希键。
- en: What does this mean? It means that an LSH hash function has higher probability
    of hash key collision for data points that are more similar. Effectively, we are
    utilizing this higher collision probability for similarity-based retrieval.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着什么？这意味着 LSH 哈希函数对更相似的数据点具有更高的哈希键冲突概率。实际上，我们利用这一较高的冲突概率来进行基于相似度的检索。
- en: '**MinHash LSH**'
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**MinHash LSH**'
- en: For every similarity/distance metric, there is an LSH hash function. For Jaccard,
    the function is called *Minwise Hash Function*, or *MinHash function*. Given an
    input set, a MinHash function consumes all elements with a random hash function
    and keeps track of the minimum hash value observed. You can build an LSH index
    using a single MinHash function. See the diagram below.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每一个相似度/距离度量，有一个 LSH 哈希函数。对于 Jaccard，这个函数被称为 *Minwise Hash Function* 或 *MinHash
    function*。给定一个输入集合，MinHash 函数使用随机哈希函数处理所有元素，并跟踪观察到的最小哈希值。你可以使用单个 MinHash 函数构建一个
    LSH 索引。请参见下图。
- en: '![](../Images/3339dcd8002b6e5e406823b1a84c18ad.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3339dcd8002b6e5e406823b1a84c18ad.png)'
- en: A MinHash LSH index with a single random hash function. Image by the author.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 使用单个随机哈希函数的 MinHash LSH 索引。图片来源于作者。
- en: The mathematical theory behind MinHash function states that the probability
    of two sets having the same minimum hash value (i.e., hash key collision) is the
    same as their Jaccard.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: MinHash 函数背后的数学理论指出，两个集合具有相同最小哈希值（即哈希键冲突）的概率与它们的 Jaccard 相同。
- en: '![](../Images/7ab93444444bf7a11030ccfd10bbd501.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7ab93444444bf7a11030ccfd10bbd501.png)'
- en: h(A) is the hash values of all elements in A by random hash function h.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: h(A) 是通过随机哈希函数 h 对 A 中所有元素的哈希值。
- en: min(h(A)) is the minimum hash value of all elements in A.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: min(h(A)) 是 A 中所有元素的最小哈希值。
- en: It is a magical result, but the [proof](https://cs.stackexchange.com/questions/11256/proving-calculating-minhash)
    is quite simple.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个神奇的结果，但[证明](https://cs.stackexchange.com/questions/11256/proving-calculating-minhash)却相当简单。
- en: A MinHash LSH index with a single MinHash function does not give you satisfactory
    accuracy because the collision probability is linearly proportional to the Jaccard.
    See the following plot to understand why.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 使用单个 MinHash 函数的 MinHash LSH 索引不能提供令人满意的准确性，因为碰撞概率与 Jaccard 成线性关系。请参见下面的图表以理解原因。
- en: '![](../Images/b0fdfc8e67178d1960da592910366887.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b0fdfc8e67178d1960da592910366887.png)'
- en: Collision probability of a single MinHash function over Jaccard between query
    set and indexed set. The Y-axis is the collision probability and the X-axis is
    the Jaccard between the query set and an indexed set. For example, an indexed
    set having Jaccard = 0.8 with the query set has 80% probability to be retrieved
    by the index; another indexed set having Jaccard 0.2 with the query set has 20%
    probability to be retrieved. Image by the author.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 单个 MinHash 函数在查询集合和索引集合之间的 Jaccard 上的碰撞概率。Y 轴是碰撞概率，X 轴是查询集合和索引集合之间的 Jaccard。例如，Jaccard
    = 0.8 的索引集合与查询集合有 80% 的概率通过索引被检索到；而 Jaccard 为 0.2 的另一个索引集合与查询集合有 20% 的概率被检索到。图片来源于作者。
- en: 'Imagine we draw a threshold at Jaccard = 0.9: results with higher Jaccard than
    0.9 with the query set is relevant, wheres results with lower than 0.9 Jaccard
    are irrelevant. In the context of search, the notion of “false positive” means
    that irrelevant results are returned, wheres the notion of “false negative” means
    that relevant results are not returned. Based on the plot above and looking at
    the area corresponding to false positive: if the index only uses a single MinHash
    function, it is going to produce false positives at a very high probability.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 设想我们在Jaccard = 0.9处画一条阈值线：与查询集合Jaccard值高于0.9的结果是相关的，而Jaccard值低于0.9的结果是无关的。在搜索的背景下，“假阳性”意味着返回了无关的结果，而“假阴性”意味着没有返回相关的结果。根据上面的图，并查看假阳性对应的区域：如果索引只使用一个MinHash函数，它将产生非常高概率的假阳性。
- en: '**Boosting the Accuracy of MinHash LSH**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**提升MinHash LSH的准确性**'
- en: 'This why we need another LSH magic: a process called *boosting.* We can boost
    the index to be much more attuned to the relevancy threshold specified.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么我们需要另一个LSH魔法：一个叫做*增强*的过程。我们可以将索引提升到更符合指定的相关性阈值。
- en: Instead of only one, we use `m` MinHash functions generated through a process
    called [*Universal Hashing*](https://en.wikipedia.org/wiki/Universal_hashing)
    *—* basically `m` random permutations of the same hash function of 32-bit or 64-bit
    integer. For every indexed set, we generate `m` minimum hash values using universal
    hashing.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`m`个MinHash函数，这些函数通过称为[*Universal Hashing*](https://en.wikipedia.org/wiki/Universal_hashing)
    *的过程生成*——基本上是32位或64位整数相同哈希函数的`m`个随机排列。对于每个被索引的集合，我们使用通用哈希生成`m`个最小哈希值。
- en: Imagine you list the `m` minimum hash values for an indexed set. We group every
    `r` number of hash values into a band of hash values, and we make `b` such bands.
    This requires `m = b * r`.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 设想你列出了一个索引集合的`m`个最小哈希值。我们将每`r`个哈希值分组到一个哈希值带中，我们创建`b`个这样的带。这需要`m = b * r`。
- en: '![](../Images/bd82df942ac0ca697f4bec44ec66d8fa.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bd82df942ac0ca697f4bec44ec66d8fa.png)'
- en: Minimum hash values of an indexed set in MinHash LSH with m= 16, b = 4 and r=
    4\. Image by the author.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在MinHash LSH中，具有m= 16，b = 4和r= 4的索引集合的最小哈希值。图片由作者提供。
- en: The probability that two sets having “band collision” — all the hash values
    in a band collide between two sets, or `r` contiguous hash collisions, is `Jaccard(A,
    B)^r`. That’s a lot smaller than a single hash value. However, the probability
    of having at least one “band collision” between two sets is `1 — (1-Jaccard(A,
    B)^r)^b`.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 两个集合具有“带碰撞”的概率——两个集合中的所有哈希值在一个带中碰撞，或`r`个连续的哈希碰撞，是`Jaccard(A, B)^r`。这比单个哈希值小得多。然而，两个集合之间至少有一个“带碰撞”的概率是`1
    — (1-Jaccard(A, B)^r)^b`。
- en: 'Why do we care about `1 — (1-Jaccard(A, B)^r)^b`? Because this function has
    a special shape:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为什么关心`1 — (1-Jaccard(A, B)^r)^b`？因为这个函数有一个特殊的形状：
- en: '![](../Images/7a54154a0bb345a3050b88640e266687.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a54154a0bb345a3050b88640e266687.png)'
- en: Boosted probability function for retrieval over Jaccard for MinHash LSH Index
    using b = 32 and r = 32\. Image by the author.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 使用b = 32和r = 32的MinHash LSH索引的Jaccard检索增强概率函数。图片由作者提供。
- en: In the plot above, you can see by using `m` MinHash functions, the “at-least-one
    band collision” probability is an S-curve function with a steep rise around Jaccard
    = 0.9\. Assuming the relevancy threshold is 0.9, the false positive probability
    of this index is much smaller than the index that uses only one random hash function.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的图中，你可以看到使用`m`个MinHash函数时，“至少一个带碰撞”概率是一个S型曲线函数，在Jaccard = 0.9附近急剧上升。假设相关性阈值为0.9，则该索引的假阳性概率远小于仅使用一个随机哈希函数的索引。
- en: Because of this, an LSH index always uses `b` bands of `r` MinHash functions
    to boost accuracy. Each band is a hash table storing pointers to indexed sets.
    During search, any indexed set collides with the query set on any band is returned.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，LSH索引总是使用`b`个`r`个MinHash函数的带来提升准确性。每个带是一个存储指向索引集合的指针的哈希表。在搜索过程中，任何与查询集合在任何带中碰撞的索引集合都会被返回。
- en: '![](../Images/9fe2d7543be0e5790c3983e78e155cd6.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9fe2d7543be0e5790c3983e78e155cd6.png)'
- en: A MinHash LSH Index using b = 4 and r = 4\. Each band is a hash table whose
    hash key is a concatenation of minimum hash values from 4 MinHash functions. Image
    by the author.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一个使用b = 4和r = 4的MinHash LSH索引。每个带是一个哈希表，其哈希键是4个MinHash函数的最小哈希值的连接。图片由作者提供。
- en: To build an MinHash LSH index, we can specify *a prior* a relevancy threshold
    and acceptable false positive and negative probabilities conditioned on Jaccard
    similarity, and [calculate](https://github.com/ekzhu/datasketch/blob/4676353c1374b2e0b33b0da2dd6596fa47fdd4c8/datasketch/lsh.py#L22)
    the optimal `m`, `b` and `r`, before indexing any data points. This is a great
    advantage of using LSH over other approximate indexes.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建MinHash LSH索引，我们可以指定*一个先验*的相关性阈值以及基于Jaccard相似度的可接受的假阳性和假阴性概率，并在索引任何数据点之前，[计算](https://github.com/ekzhu/datasketch/blob/4676353c1374b2e0b33b0da2dd6596fa47fdd4c8/datasketch/lsh.py#L22)最优的`m`、`b`和`r`。这是使用LSH相对于其他近似索引的一个巨大优势。
- en: You can find my implementation of MinHash LSH in the Python package [datasketch](https://github.com/ekzhu/datasketch).
    It also has other MinHash-related algorithms like LSH Forest and Weighted MinHash.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在Python包[datasketch](https://github.com/ekzhu/datasketch)中找到我的MinHash LSH实现。它还包括其他与MinHash相关的算法，如LSH森林和加权MinHash。
- en: Final Thoughts
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最终思考
- en: 'I have covered a lot of topics in this post, but I barely scratched the surface
    of search indexes for Jaccard similarity. If you are interested in reading more
    about these topics, I have a list of further readings for you:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这篇文章中涵盖了很多主题，但我只是浅尝辄止地探讨了Jaccard相似度搜索索引。如果你有兴趣阅读更多这些主题，我为你准备了进一步阅读的列表：
- en: '[Mining of Massive Datasets](http://mmds.org/) by Jure Leskovec, Anand Rajaraman
    and Jeff Ullman. The 3rd chapter goes into detail about MinHash and LSH. I think
    it is a great chapter for gaining the intuition of MinHash. Be aware the application
    described in the chapter is focused on n-gram based text matching.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[《大规模数据集挖掘》(Mining of Massive Datasets)](http://mmds.org/)由Jure Leskovec、Anand
    Rajaraman和Jeff Ullman撰写。第3章详细介绍了MinHash和LSH。我认为这是一个很好的章节，用于获得对MinHash的直观理解。请注意，章节中描述的应用侧重于基于n-gram的文本匹配。'
- en: '[JOSIE: Overlap Set Similarity Search for Finding Joinable Tables in Data Lakes.](https://dl.acm.org/doi/10.1145/3299869.3300065)
    The preliminary section of this paper explains the intuitation behind the `search_top_k_merge_list`
    and `search_top_k_probe_set` algorithms. The main section explains how to take
    cost into consideration when input sets are large, such as a table column.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[JOSIE：用于在数据湖中查找可连接表的重叠集合相似度搜索](https://dl.acm.org/doi/10.1145/3299869.3300065)。本文的初步部分解释了`search_top_k_merge_list`和`search_top_k_probe_set`算法的直观。主要部分解释了在输入集合很大时（例如表列），如何考虑成本。'
- en: '[Datasketch](https://github.com/ekzhu/datasketch) and [SetSimilaritySearch](https://github.com/ekzhu/SetSimilaritySearch/)
    libraries respectively implement the state-of-the-art approximate and exact Jaccard
    similarity search indexes. The [issues list of the datasketch project](https://github.com/ekzhu/datasketch/issues)
    is a treasure trove of application scenarios and practical considerations when
    applying MinHash LSH.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Datasketch](https://github.com/ekzhu/datasketch) 和 [SetSimilaritySearch](https://github.com/ekzhu/SetSimilaritySearch/)
    库分别实现了最先进的近似和精确Jaccard相似度搜索索引。[datasketch项目的问题列表](https://github.com/ekzhu/datasketch/issues)是应用场景和实际考虑的宝贵资源，尤其是在应用MinHash
    LSH时。'
- en: What about Embeddings?
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 那么嵌入呢？
- en: 'In recent years, due to breakthroughs in representation learning using deep
    neural networks like Transformers, similarity between learned embedding vectors
    is meaningful when the input data is part of the same domain that the embedding
    model trained on. The main differences between that scenario and the search scenario
    described in this post are:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，由于使用像Transformers这样的深度神经网络在表示学习上的突破，当输入数据属于嵌入模型训练的相同领域时，学习到的嵌入向量之间的相似度是有意义的。与本文描述的搜索场景相比，这种情况的主要区别在于：
- en: 'Embedding vectors are dense vectors with typically 60 to 700 dimensions. Every
    dimension is non-zero. In contrast, sets, when represented as one-hot vectors
    are sparse: 10k to millions of dimensions, but most dimensions are zeros.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 嵌入向量是通常具有60到700维的稠密向量。每一维都是非零的。相比之下，集合在表示为独热编码向量时是稀疏的：10k到数百万维，但大多数维度为零。
- en: Cosine similarity (or dot-product on normalized vectors) is typically used for
    embedding vectors. For sets we use Jaccard similarity.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 余弦相似度（或标准化向量上的点积）通常用于嵌入向量。对于集合，我们使用Jaccard相似度。
- en: It is hard to specify a relevancy threshold on similarity between embedding
    vectors, because the vectors are learned black-box representations of the original
    data such as image or text. On the other hand, Jaccard similarity threshold for
    sets is much easier to specify because **sets are the original data**.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很难为嵌入向量之间的相似性指定一个相关性阈值，因为这些向量是对原始数据（如图像或文本）的黑箱表示。另一方面，集合的Jaccard相似度阈值要容易得多，因为**集合是原始数据**。
- en: Due to the above differences, it is not straightforward to compare embeddings
    and sets because they are distinctively different data types, even though you
    could classify both of them as high-dimensional. They are suitable for different
    application scenarios.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 由于上述差异，比较嵌入和集合并不是直接的，因为它们是明显不同的数据类型，即使你可以将它们都归类为高维数据。它们适用于不同的应用场景。
