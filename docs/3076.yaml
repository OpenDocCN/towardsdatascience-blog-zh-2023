- en: Your Own Personal LLaMa
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你自己的个人 LLaMa
- en: 原文：[https://towardsdatascience.com/your-own-personal-llama-8cf24a9237cb?source=collection_archive---------2-----------------------#2023-10-09](https://towardsdatascience.com/your-own-personal-llama-8cf24a9237cb?source=collection_archive---------2-----------------------#2023-10-09)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/your-own-personal-llama-8cf24a9237cb?source=collection_archive---------2-----------------------#2023-10-09](https://towardsdatascience.com/your-own-personal-llama-8cf24a9237cb?source=collection_archive---------2-----------------------#2023-10-09)
- en: How you can find, retrieve, and feed your custom data into LLaMa 2 to improve
    responses
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何找到、检索和输入你的自定义数据到 LLaMa 2，以提升响应效果
- en: '[](https://robgon.medium.com/?source=post_page-----8cf24a9237cb--------------------------------)[![Robert
    A. Gonsalves](../Images/96b4da0f602a1cd9d1e1d2917868cbee.png)](https://robgon.medium.com/?source=post_page-----8cf24a9237cb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8cf24a9237cb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8cf24a9237cb--------------------------------)
    [Robert A. Gonsalves](https://robgon.medium.com/?source=post_page-----8cf24a9237cb--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://robgon.medium.com/?source=post_page-----8cf24a9237cb--------------------------------)[![Robert
    A. Gonsalves](../Images/96b4da0f602a1cd9d1e1d2917868cbee.png)](https://robgon.medium.com/?source=post_page-----8cf24a9237cb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8cf24a9237cb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8cf24a9237cb--------------------------------)
    [Robert A. Gonsalves](https://robgon.medium.com/?source=post_page-----8cf24a9237cb--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc97e6c73c13c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-own-personal-llama-8cf24a9237cb&user=Robert+A.+Gonsalves&userId=c97e6c73c13c&source=post_page-c97e6c73c13c----8cf24a9237cb---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8cf24a9237cb--------------------------------)
    ·12 min read·Oct 9, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8cf24a9237cb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-own-personal-llama-8cf24a9237cb&user=Robert+A.+Gonsalves&userId=c97e6c73c13c&source=-----8cf24a9237cb---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc97e6c73c13c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-own-personal-llama-8cf24a9237cb&user=Robert+A.+Gonsalves&userId=c97e6c73c13c&source=post_page-c97e6c73c13c----8cf24a9237cb---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8cf24a9237cb--------------------------------)
    ·12 分钟阅读·2023年10月9日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8cf24a9237cb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-own-personal-llama-8cf24a9237cb&user=Robert+A.+Gonsalves&userId=c97e6c73c13c&source=-----8cf24a9237cb---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8cf24a9237cb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-own-personal-llama-8cf24a9237cb&source=-----8cf24a9237cb---------------------bookmark_footer-----------)![](../Images/1b4813b49c3698de27945718255e006d.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8cf24a9237cb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-own-personal-llama-8cf24a9237cb&source=-----8cf24a9237cb---------------------bookmark_footer-----------)![](../Images/1b4813b49c3698de27945718255e006d.png)'
- en: '**“a minimalist painting of a cute llama standing in an art class,”** I*mage
    created using an AI image creation program,* Midjourney, and edited by the author'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**“一幅描绘可爱小羊驼在艺术课堂上站立的极简主义画作，”** 我*使用 AI 图像创作程序* Midjourney 创建，并由作者编辑'
- en: In my [last article](https://medium.com/p/cb0512091e3f), I showed how I could
    fine-tune OpenAI’s ChatGPT to improve the results of performing tasks like formatting
    text documents. Although fine-tuning helped the Large Language Model (LLM) better
    perform the formatting task, the model didn’t seem to absorb much of the knowledge
    in the training data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在我[上一篇文章](https://medium.com/p/cb0512091e3f)中，我展示了如何微调 OpenAI 的 ChatGPT 来提升文本格式化等任务的结果。虽然微调帮助大型语言模型（LLM）更好地完成格式化任务，但该模型似乎并未充分吸收训练数据中的知识。
- en: For this article, I explored using an open-source LLM, Meta’s LLaMa 2 [1], and
    a technique called Retrieval Augmented Generation (RAG) [2] to automatically find
    relevant reference text that helped the model answer questions. I used the text
    from 36 of my articles on Medium as reference material to see if I could create
    a private, custom chatbot that could answer questions about my writings.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我探讨了使用开源 LLM、Meta 的 LLaMa 2 [1] 和一种叫做检索增强生成（RAG）[2] 的技术，以自动查找相关的参考文本，帮助模型回答问题。我使用了我在
    Medium 上的 36 篇文章中的文本作为参考材料，看看是否能创建一个私人定制的聊天机器人，回答有关我写作的问题。
- en: For example, without providing any reference text, here’s how LLaMa 2 responded
    to a question about [one of my articles](/muybridge-derby-bringing-animal-locomotion-photographs-to-life-with-ai-b1918e6622ec).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在没有提供任何参考文本的情况下，LLaMa 2 对一个关于 [我其中一篇文章](/muybridge-derby-bringing-animal-locomotion-photographs-to-life-with-ai-b1918e6622ec)
    的问题作出了如下回应。
- en: '***RobG:*** *What is Muybridge Derby?*'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***RobG:*** *什么是 Muybridge Derby？*'
- en: ''
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**LLaMa 2:** Thank you for asking! I’m here to help you with your question.
    However, I must inform you that “Muybridge Derby” is not a real or recognized
    term in any context. It’s possible that it may be a misspelling or a made-up'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**LLaMa 2:** 感谢你的提问！我在这里帮助你解决你的问题。然而，我必须告诉你，“Muybridge Derby”在任何背景下都不是一个真实或公认的术语。它可能是拼写错误或虚构的。'
- en: term, and I cannot provide information on something that does not exist.
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 术语，我不能提供关于不存在的事物的信息。
- en: If you could…
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你能…
