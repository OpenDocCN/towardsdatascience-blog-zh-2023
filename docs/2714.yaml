- en: Monte Carlo Methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/monte-carlo-methods-b2504976c415?source=collection_archive---------4-----------------------#2023-08-26](https://towardsdatascience.com/monte-carlo-methods-b2504976c415?source=collection_archive---------4-----------------------#2023-08-26)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[A Baby Robot’s Guide To Reinforcement Learning](https://towardsdatascience.com/tagged/baby-robot-guide)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'An Introduction to Reinforcement Learning: Part 4'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@tinkertytonk?source=post_page-----b2504976c415--------------------------------)[![Steve
    Roberts](../Images/14384b0516dfd3dc792972b221d787ec.png)](https://medium.com/@tinkertytonk?source=post_page-----b2504976c415--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b2504976c415--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b2504976c415--------------------------------)
    [Steve Roberts](https://medium.com/@tinkertytonk?source=post_page-----b2504976c415--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6b6735266652&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-methods-b2504976c415&user=Steve+Roberts&userId=6b6735266652&source=post_page-6b6735266652----b2504976c415---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b2504976c415--------------------------------)
    ·26 min read·Aug 26, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb2504976c415&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-methods-b2504976c415&user=Steve+Roberts&userId=6b6735266652&source=-----b2504976c415---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb2504976c415&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-methods-b2504976c415&source=-----b2504976c415---------------------bookmark_footer-----------)![](../Images/2bce2525d4bd8752cf2f67f728bf7e67.png)'
  prefs: []
  type: TYPE_NORMAL
- en: All images by author
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once again we’re off to the casino, and this time it’s situated in sunny Monte
    Carlo, made famous by its appearance in the classic movie [*Madagascar 3: Europe’s
    Most Wanted*](https://en.wikipedia.org/wiki/Madagascar_3:_Europe%27s_Most_Wanted)(although
    there’s a slight chance that it was already famous).'
  prefs: []
  type: TYPE_NORMAL
- en: In our last visit to a casino we looked at the [***multi-armed bandit***](https://medium.com/towards-data-science/multi-armed-bandits-part-1-b8d33ab80697)and
    used this as a way to visualise the problem of how to choose the best action when
    confronted with many possible actions.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of ***Reinforcement Learning*** the bandit problem can be thought of
    as representing a single state and the actions available within that state. *Monte
    Carlo* methods extend this idea to cover multiple, interrelated, states.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, in the previous problems we’ve looked at, we’ve always been given
    a full model of the environment. This model defines both the transition probabilities,
    that describe the chances of moving from one state to the next, and the reward
    received for making this transition.
  prefs: []
  type: TYPE_NORMAL
- en: In *Monte Carlo* methods this isn’t the case. No model is given and instead
    the agent must discover the properties of the environment through exploration…
  prefs: []
  type: TYPE_NORMAL
