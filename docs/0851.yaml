- en: 'Introducing Quix Streams: an open-source Python library for Kafka'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/introducing-quix-streams-an-open-source-python-library-for-kafka-9ab694c683c4?source=collection_archive---------18-----------------------#2023-03-06](https://towardsdatascience.com/introducing-quix-streams-an-open-source-python-library-for-kafka-9ab694c683c4?source=collection_archive---------18-----------------------#2023-03-06)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Easily produce and consume time-series data streams with a Pandas-like interface
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@tomasatquix?source=post_page-----9ab694c683c4--------------------------------)[![Tomáš
    Neubauer](../Images/5eb14b73cfe100ef9a43148db6abd3a9.png)](https://medium.com/@tomasatquix?source=post_page-----9ab694c683c4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9ab694c683c4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9ab694c683c4--------------------------------)
    [Tomáš Neubauer](https://medium.com/@tomasatquix?source=post_page-----9ab694c683c4--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd620afda25db&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-quix-streams-an-open-source-python-library-for-kafka-9ab694c683c4&user=Tom%C3%A1%C5%A1+Neubauer&userId=d620afda25db&source=post_page-d620afda25db----9ab694c683c4---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9ab694c683c4--------------------------------)
    ·7 min read·Mar 6, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9ab694c683c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-quix-streams-an-open-source-python-library-for-kafka-9ab694c683c4&user=Tom%C3%A1%C5%A1+Neubauer&userId=d620afda25db&source=-----9ab694c683c4---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9ab694c683c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-quix-streams-an-open-source-python-library-for-kafka-9ab694c683c4&source=-----9ab694c683c4---------------------bookmark_footer-----------)![](../Images/d943b1dd736dd40843ce1917803e06f4.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: You might be wondering why the world needs another Python framework for Kafka.
    After all, there are a lot of existing libraries and frameworks to choose from,
    such as [kafka-python](https://kafka-python.readthedocs.io/en/master/), [Faust](https://faust.readthedocs.io/en/latest/),
    [PySpark](https://spark.apache.org/docs/latest/api/python/), and so on.
  prefs: []
  type: TYPE_NORMAL
- en: The focus of [Quix Streams](https://github.com/quixio/quix-streams) however
    is time-series and telemetry data, so the features are optimized for telemetry-related
    use cases. This could be device telemetry (it was originally road-testing on sensor
    data from Formula 1 racing cars) or other types of telemetry data such as metrics,
    logs, and traces.
  prefs: []
  type: TYPE_NORMAL
- en: It’s also designed to help you get the best out Apache Kafka’s horizontal scaling
    capabilities. This is especially important if you need to process a large firehose
    of data (e.g. 60,000 data points a second).
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, you don’t have to be doing real-time ML on Formula 1 telemetry
    to find Quix Streams useful— my hope is that its simplicity and performance will
    make many of you more productive and I’m excited to see what other use cases you
    find for it.
  prefs: []
  type: TYPE_NORMAL
- en: What you can do with Quix Streams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To help you learn more about what you can do with this library, here’s a list
    of core features with simplified code samples to demonstrate how they work:'
  prefs: []
  type: TYPE_NORMAL
- en: Use Pandas DataFrames to produce data more efficiently
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Time-series parameters are emitted at the same time, so they share one timestamp.
    Handling this data independently is wasteful. The library uses a tabular system
    that can work for instance with Pandas DataFrames natively. Each row has a timestamp
    and user-defined tags as indexes
  prefs: []
  type: TYPE_NORMAL
- en: For a complete, runnable example of how to use the library with Pandas to stream
    data directly from a CSV, see [this gist](https://gist.github.com/merlin-quix/e42594da530432cbd050bd83db97c857).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Produce time-series data without worrying about serialization or deserialization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Quix Streams serializes and deserializes time-series data using different codecs
    and optimizations to minimize payloads in order to increase throughput and reduce
    latency.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example shows data being appended to as stream with the `add_value`
    method:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leverage built-in buffers to optimize processing operations for windows of time-series
    data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you’re sending data at high frequency, processing each message can be costly.
    The library provides built-in time-series buffers for producing and consuming,
    allowing several configurations for balancing between latency and cost.
  prefs: []
  type: TYPE_NORMAL
- en: For example, you can configure the library to release a packet from the buffer
    whenever 100 items of timestamped data are collected or when a certain number
    of milliseconds in data have elapsed (using timestamps in the data rather the
    consumer machine’s clock).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You can then read from the buffer and process it with the `on_read` function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Produce and consume different types of mixed data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This library allows you to produce and consume different types of mixed data
    in the same timestamp, like numbers, strings or binary data.
  prefs: []
  type: TYPE_NORMAL
- en: For example, you can produce both time-series data and large binary blobs together.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Often, you’ll want to combine time series data with binary data. In the following
    example, we combine bus’s onboard camera with telemetry from its ECU unit so we
    can analyze the onboard camera feed with context.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can also produce events that include payloads:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example, you might need to listen for changes in time-series or binary
    streams and produce an event (such as “speed limit exceeded”). These might require
    some kind of document to send along with the event message (e.g. transaction invoices,
    or a speeding ticket with photographic proof). Here’s an example for a speeding
    camera:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use stream contexts for horizontal scaling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Stream contexts allow you to bundle data from one data source into the same
    scope with supplementary metadata — which enables workloads to be horizontally
    scaled with multiple replicas.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following sample, the `create_stream` function is used to create a stream
    called **bus-123AAAV** which gets assigned to one particular consumer and will
    receive messages in the correct order:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leverage built-in stateful processing for greater resiliency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The library includes an easy-to-use state store combining blob storage and Kubernetes
    persistence volumes that ensures quick recovery from any outages or disruptions.
  prefs: []
  type: TYPE_NORMAL
- en: To use it, you can create an instance of `LocalFileStorage` or use one of our
    helper classes to manage the state such as `InMemoryStorage`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of a stateful operation sum for a selected column in data:'
  prefs: []
  type: TYPE_NORMAL
- en: Other performance and usability enhancements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The library also includes a number of other enhancements that are designed
    to simplify the process of managing configuration and performance when interacting
    with Kafka:'
  prefs: []
  type: TYPE_NORMAL
- en: '**No schema registry required**: The library doesn’t need a schema registry
    to send different sets of types or parameters, this is handled internally by the
    protocol. This means that you can send more than one schema per topic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Message splitting**: Quix Streams automatically handles large messages on
    the producer side, splitting them up if required. You no longer need to worry
    about Kafka message limits. On the consumer side, those messages are automatically
    merged back.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Message Broker configuration**: Many configuration settings are needed to
    use Kafka at its best, and the ideal configuration takes time. The library takes
    care of Kafka configuration by default but also supports custom configurations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Checkpointing**: The library supports manual or automatic checkpointing when
    you consume data from a Kafka Topic. This enables you to inform the message broker
    that you have already processed messages up to one point (and not process the
    same messages again in case of an unplanned restart).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Horizontal scaling**: Quix Streams handles horizontal scaling using the streaming
    context feature. You can scale the processing services, from one replica to many
    and back to one, and the library ensures that the data load is always shared between
    your replicas reliably.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a detailed overview of features, see the [library documentation](https://quix.io/docs/sdk-intro.html).
  prefs: []
  type: TYPE_NORMAL
- en: Getting Started
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To quickly try out Quix Streams, you just need to install the library and set
    up a local Kafka instance.
  prefs: []
  type: TYPE_NORMAL
- en: Install Quix Streams
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Install Quix streams with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To install Quix Streams on Macs with M1 or M2 chips, see this special installation
    guide: [Installing on Quix Streams on a M1/M2 Mac](https://github.com/quixio/quix-streams/blob/main/mac-m1-m2-install.md).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Install Kafka locally
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This library needs to utilize a message broker to send and receive data. To
    install and test Kafka locally:'
  prefs: []
  type: TYPE_NORMAL
- en: Download the Apache Kafka binary from the [Apache Kafka Download](https://kafka.apache.org/downloads)
    page.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Extract the contents of the file to a convenient location (i.e. `kafka_dir`),
    and start the Kafka services with the following commands:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Linux / macOS**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Windows**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: You can find more detailed instructions in Apache Kafka’s [official documentation](https://kafka.apache.org/quickstart)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can also find a comprehensive [Quick Start guide](https://quix.io/docs/sdk/quickstart.html)
    for Quix Streams in the official documentation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following examples will give you a basic idea of how to produce and consume
    data with Quix Streams.:'
  prefs: []
  type: TYPE_NORMAL
- en: Producing time-series data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here’s an example of how to produce time-series data into a Kafka Topic with
    Python.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Consuming time-series data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here’s an example of how to consume time-series data from a Kafka Topic with
    Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: For full documentation of how to [consume](https://www.quix.io/docs/sdk/subscribe.html)
    and [produce](https://www.quix.io/docs/sdk/publish.html) time-series and event
    data with Quix Streams, [see the docs](https://www.quix.io/docs/sdk/introduction.html).
  prefs: []
  type: TYPE_NORMAL
- en: What’s Next
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is the first iteration of Quix Streams, and the next release is already
    in the works.
  prefs: []
  type: TYPE_NORMAL
- en: The main highlight is a new feature called “**streaming data frames**” that
    simplifies stateful stream processing for users coming from a batch processing
    environment. It eliminates the need for users to manage state in memory, update
    rolling windows, deal with checkpointing and state persistence, and manage state
    recovery after a service unexpectedly restarts.
  prefs: []
  type: TYPE_NORMAL
- en: By introducing a familiar interface to Pandas DataFrames, my collaborators and
    I hope to make stream processing even more accessible to data professionals who
    are new to streaming data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example shows how you would perform rolling window calculation
    on a streaming data frame:'
  prefs: []
  type: TYPE_NORMAL
- en: Note that this is exactly how you would do the same calculation on static data
    in Jupyter notebook — so will be easy to learn for those of you who are used to
    batch processing.
  prefs: []
  type: TYPE_NORMAL
- en: There’s also no need to grapple with the complexity of stateful processing on
    streaming data — this will all be managed by the library. Moreover, although it
    will still feel like Pandas, it will use binary tables under the hood — which
    adds a significant performance boost compared to traditional Pandas DataFrames.
  prefs: []
  type: TYPE_NORMAL
- en: To find out when the next version is ready, make sure you watch the [Quix Streams
    GitHub repo](https://github.com/quixio/quix-streams).
  prefs: []
  type: TYPE_NORMAL
- en: 'The roadmap should also be shaped by feedback and contributions from the wider
    data community:'
  prefs: []
  type: TYPE_NORMAL
- en: If you find a bug or want to request an enhancement, feel free to [log a GitHub
    issue](https://github.com/quixio/quix-streams/issues).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you have questions, need help, or simply want to find out more about the
    library, try posting a message in the Slack community “[The Stream](https://quix.io/slack-invite)”
    (which I help to moderate) or check out the [documentation](https://quix.io/docs/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you want to improve the library, see the [contribution guidelines](https://github.com/quixio/quix-streams/blob/main/CONTRIBUTING.md).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
