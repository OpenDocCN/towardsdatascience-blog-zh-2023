- en: 10 Confusing XGBoost Hyperparameters and How to Tune Them Like a Pro in 2023
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/10-confusing-xgboost-hyperparameters-and-how-to-tune-them-like-a-pro-in-2023-e305057f546?source=collection_archive---------0-----------------------#2023-06-11](https://towardsdatascience.com/10-confusing-xgboost-hyperparameters-and-how-to-tune-them-like-a-pro-in-2023-e305057f546?source=collection_archive---------0-----------------------#2023-06-11)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: XGBoost hyperparameters done with style and visuals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://ibexorigin.medium.com/?source=post_page-----e305057f546--------------------------------)[![Bex
    T.](../Images/516496f32596e8ad56bf07f178a643c6.png)](https://ibexorigin.medium.com/?source=post_page-----e305057f546--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e305057f546--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e305057f546--------------------------------)
    [Bex T.](https://ibexorigin.medium.com/?source=post_page-----e305057f546--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F39db050c2ac2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F10-confusing-xgboost-hyperparameters-and-how-to-tune-them-like-a-pro-in-2023-e305057f546&user=Bex+T.&userId=39db050c2ac2&source=post_page-39db050c2ac2----e305057f546---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e305057f546--------------------------------)
    ·9 min read·Jun 11, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe305057f546&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F10-confusing-xgboost-hyperparameters-and-how-to-tune-them-like-a-pro-in-2023-e305057f546&user=Bex+T.&userId=39db050c2ac2&source=-----e305057f546---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe305057f546&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F10-confusing-xgboost-hyperparameters-and-how-to-tune-them-like-a-pro-in-2023-e305057f546&source=-----e305057f546---------------------bookmark_footer-----------)![](../Images/4e9f3c8752e76146b330a1b3b4bdf911.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image by me with Midjourney
  prefs: []
  type: TYPE_NORMAL
- en: Intro
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Today, I am going to show you how to squeeze XGBoost so hard that both ‘o’s
    pop out. We will achieve this by fine-tuning its hyperparameters to such an extent
    that it will no longer be able to *bst* after giving us all the performance it
    can.
  prefs: []
  type: TYPE_NORMAL
- en: This will not be a mere hyperparameter checklist post. Oh no. I will provide
    a detailed explanation of each of the ten hyperparameters, functionalities, accepted
    value ranges, best practices, and how to use Optuna for hyperparameter tuning.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s dive in!
  prefs: []
  type: TYPE_NORMAL
- en: What we wanted all along…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A dumb underfit XGBoost model is virtually unheard of. Even with default parameter
    values, it performs reasonably well on many tabular tasks. However, its biggest
    problem lies in over-effing-fitting.
  prefs: []
  type: TYPE_NORMAL
- en: To address this issue, most of the XGBoost hyperparameters are put there to
    tame the underlying beast so that it doesn’t just swallow up the training set
    and burp up the bones during testing.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, through hyperparameter tuning, our goal is to strike the optimal
    balance between a complex model that overfits and a…
  prefs: []
  type: TYPE_NORMAL
