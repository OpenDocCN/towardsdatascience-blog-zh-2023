- en: One Hot Encoding
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: One Hot 编码
- en: 原文：[https://towardsdatascience.com/one-hot-encoding-scikit-vs-pandas-2133775567b8?source=collection_archive---------2-----------------------#2023-03-13](https://towardsdatascience.com/one-hot-encoding-scikit-vs-pandas-2133775567b8?source=collection_archive---------2-----------------------#2023-03-13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/one-hot-encoding-scikit-vs-pandas-2133775567b8?source=collection_archive---------2-----------------------#2023-03-13](https://towardsdatascience.com/one-hot-encoding-scikit-vs-pandas-2133775567b8?source=collection_archive---------2-----------------------#2023-03-13)
- en: Scikit Learn or Pandas?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Scikit Learn 还是 Pandas？
- en: '[](https://medium.com/@andras.gefferth?source=post_page-----2133775567b8--------------------------------)[![Andras
    Gefferth](../Images/e9ded538e9106b9c8d0211d1cca3aa99.png)](https://medium.com/@andras.gefferth?source=post_page-----2133775567b8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2133775567b8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2133775567b8--------------------------------)
    [Andras Gefferth](https://medium.com/@andras.gefferth?source=post_page-----2133775567b8--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@andras.gefferth?source=post_page-----2133775567b8--------------------------------)[![安德拉斯·盖费斯](../Images/e9ded538e9106b9c8d0211d1cca3aa99.png)](https://medium.com/@andras.gefferth?source=post_page-----2133775567b8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2133775567b8--------------------------------)[![数据科学趋势](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2133775567b8--------------------------------)
    [安德拉斯·盖费斯](https://medium.com/@andras.gefferth?source=post_page-----2133775567b8--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa9dc9dafd198&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fone-hot-encoding-scikit-vs-pandas-2133775567b8&user=Andras+Gefferth&userId=a9dc9dafd198&source=post_page-a9dc9dafd198----2133775567b8---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2133775567b8--------------------------------)
    ·8 min read·Mar 13, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2133775567b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fone-hot-encoding-scikit-vs-pandas-2133775567b8&user=Andras+Gefferth&userId=a9dc9dafd198&source=-----2133775567b8---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa9dc9dafd198&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fone-hot-encoding-scikit-vs-pandas-2133775567b8&user=Andras+Gefferth&userId=a9dc9dafd198&source=post_page-a9dc9dafd198----2133775567b8---------------------post_header-----------)
    发布于 [数据科学趋势](https://towardsdatascience.com/?source=post_page-----2133775567b8--------------------------------)
    ·8分钟阅读·2023年3月13日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2133775567b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fone-hot-encoding-scikit-vs-pandas-2133775567b8&user=Andras+Gefferth&userId=a9dc9dafd198&source=-----2133775567b8---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2133775567b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fone-hot-encoding-scikit-vs-pandas-2133775567b8&source=-----2133775567b8---------------------bookmark_footer-----------)![](../Images/d2f9889de233a8661b5cae9ac767f88a.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2133775567b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fone-hot-encoding-scikit-vs-pandas-2133775567b8&source=-----2133775567b8---------------------bookmark_footer-----------)![](../Images/d2f9889de233a8661b5cae9ac767f88a.png)'
- en: One hot encoding is a popular method to represent categorical data (All images
    by author)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: One hot 编码是一种流行的表示分类数据的方法（所有图片均由作者提供）
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Both [sklearn.preprocessing.OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)
    and [pandas.get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)
    are popular choices (well, practically the only choices unless you want want to
    implement it yourself) to perform One Hot Encoding. Most scientist recommend scikit,
    as using its fit/transform paradigm it provides a built-in mechanism to learn
    all the possible categories from the training set and apply them to the validation
    or real input data. Therefore this approach will prevent the errors arising when
    the validation or real input data does not contain all categories, or the categories
    do not appear in the same order.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[sklearn.preprocessing.OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)和[pandas.get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)都是流行的选择（实际上是唯一的选择，除非你想自己实现）来执行**独热编码**。大多数科学家推荐使用`scikit`，因为它使用其fit/transform范式，提供了一种内置机制来学习训练集中的所有可能类别，并将其应用于验证或实际输入数据。因此，这种方法将防止在验证或实际输入数据中不包含所有类别或类别顺序不同引发的错误。'
- en: In this article I will argue, that there is no clear winner of this competition.
    For data scientists who use pandas DataFrame, using the native pandas get_dummies
    function has clear benefits and there is a very straightforward way to avoid the
    above mentioned issue.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我将争论，这场竞争没有明确的赢家。对于使用`pandas` DataFrame的数据科学家来说，使用原生的`pandas get_dummies`函数有明显的好处，而且有一种非常简单的方法可以避免上述提到的问题。
- en: Introduction
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: What is One Hot Encoding?
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是**独热编码**？
- en: You can safely skip this section if you already know.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经知道这些内容，可以安全地跳过这一部分。
- en: One Hot Encoding (OHE from now) is a technique to encode categorical data to
    numerical ones. It is mainly used in machine learning applications. Consider,
    for example, you are building a model to predict the weight of animals. One of
    your inputs is going to be the type of animal, ie. cat/dog/parrot. This is a string
    value, and therefore models like a linear regressor are not able to deal with
    it.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**独热编码**（以下简称**OHE**）是一种将分类数据编码为数值数据的技术。它主要用于机器学习应用。例如，假设你正在构建一个预测动物体重的模型。你的一个输入将是动物的类型，即猫/狗/鹦鹉。这是一个字符串值，因此像线性回归这样的模型无法处理它。'
- en: 'The approach, which first comes to mind is to give integer labels to the animals
    and replace each string with the corresponding integer representation. But, if
    you do this, you introduce some artificial ordering of the animals (e.g. a parrot
    will have three times more impact for the “animal” weight than a cat). Instead,
    OHE creates a new input variable (ie. column) for each of the animals and sets
    this variable to 1 or 0 depending on whether the animal is the selected one. Example:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个想到的方法是给动物赋予整数标签，并用相应的整数表示替换每个字符串。但是，如果这样做，你会引入一些人为的排序（例如，鹦鹉对“动物”权重的影响是猫的三倍）。相反，OHE为每种动物创建一个新的输入变量（即列），并根据动物是否是选定的那个，将该变量设置为1或0。示例：
- en: '![](../Images/14897c9b2c3b33067854f4c1ed164985.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/14897c9b2c3b33067854f4c1ed164985.png)'
- en: One Hot Encoding (All images by author)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**独热编码**（所有图片由作者提供）'
- en: After this separation, your linear model can assign weights to these new columns
    independently of the others. In practice, actually, you don’t really need 3 columns
    to represent the 3 animals. You can choose any one of them to drop. In other words
    if it is not a dog and not a cat, it can’t be anything else than a parrot.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种分离之后，你的线性模型可以独立地为这些新列分配权重。实际上，你并不需要3列来表示这3种动物。你可以选择其中任何一列来丢弃。换句话说，如果它既不是狗也不是猫，那它就只能是鹦鹉。
- en: Scikit vs Pandas
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**Scikit**与**Pandas**'
- en: Both scikit-learn and pandas provide methods to perform this operation and there
    is a debate with long history among data scientists which one to use. You can
    find quite a few articles on the topic if you search. The reason I revisit the
    topic is because both of these libraries evolve and there are new features which
    are worth taking into account when deciding.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit-learn`和`pandas`都提供了执行此操作的方法，数据科学家之间关于使用哪个方法的争论已经有很长的历史。如果你搜索一下，会找到很多相关文章。我重新讨论这个话题的原因是这两个库都在不断发展，有一些新的功能在决策时值得考虑。'
- en: Article scope
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文章范围
- en: 'There are several options one may specify when encoding, such as whether to
    use sparse or dense data representation or whether to keep all new columns or
    drop one of them. Both libraries support many of such features, but in this article
    I will not focus on them. The main focus of this article is the handling of the
    categories as explaind below:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在编码时，可以指定几个选项，比如是否使用稀疏或密集的数据表示，或者是否保留所有新列或删除其中之一。这两个库都支持许多这样的功能，但在这篇文章中我不会关注它们。本文的重点是类别的处理，如下所述：
- en: If you do a train/test split (either manually or automated using sklearn.model_selection.train_test_split)
    it may easily happen that your train dataset will not contain any parrots. It’s
    not necessarily an issue from theoretical point of view, if some categories are
    missing you can still make a prediction, probably less accurate. But your code
    will break if it is not prepared for this difference as the columns in the fitted
    data do not agree with the columns of the data used for prediction.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你进行训练/测试拆分（无论是手动还是使用`sklearn.model_selection.train_test_split`自动化），可能会出现训练数据集中不包含任何鹦鹉的情况。从理论上讲，这不一定是一个问题，如果某些类别缺失，你仍然可以进行预测，只是预测可能不够准确。但如果你的代码没有为这种差异做好准备，那么由于拟合数据中的列与用于预测的数据的列不一致，你的代码会出错。
- en: 'In this article I will focus on the following points:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将关注以下几点：
- en: How do you tell the OHE the set of all categories and how do you make sure the
    encoding is applied consistently to train/test/validation/real data?
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何告诉OHE所有类别的集合，并确保编码一致地应用于训练/测试/验证/实际数据？
- en: How to apply the encoding to a pandas DataFrame?
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将编码应用于pandas DataFrame？
- en: How to incorporate the encoder in a scikit pipeline?
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在scikit管道中集成编码器？
- en: Scikit-learn
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Scikit-learn
- en: The usual wisdom is to use sklearn.preprocessing.OneHotEncoder for this purpose,
    because using its fit/transform paradigm you can use the training dataset to “teach”
    categories and apply it to your real-world input data.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 通常的做法是使用`sklearn.preprocessing.OneHotEncoder`，因为通过其fit/transform范式，你可以使用训练数据集来“教会”类别，并将其应用于你的实际输入数据。
- en: 'The main steps are the followings:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 主要步骤如下：
- en: where X_train is your training input data and real_input is your real input
    data (what a surprise!) which you want to apply the model to.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 其中X_train是你的训练输入数据，real_input是你希望应用模型的真实输入数据（真是个惊喜！）。
- en: If you are “lucky”, then all possible categories will appear in X_train, the
    encoder object learns these categories and the corresponding mappings, and will
    produce the right columns in the right column order for the real input. We have
    to note, that sklearn.preprocessing.OneHotEncoder produces a numpy array so the
    order of the columns is important.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你“幸运”，那么所有可能的类别都会出现在X_train中，编码器对象学习这些类别及其对应的映射，并会为真实输入生成正确的列和正确的列顺序。我们需要注意的是，`sklearn.preprocessing.OneHotEncoder`产生的是一个numpy数组，所以列的顺序很重要。
- en: But you should not assume you will always be lucky. For example, if you use
    cross-validation to randomly and repeatedly split your data into train and test
    parts you may easily end up in a situation where your actual training data is
    missing some of the categories. This leads to error as you won’t be able to transform
    the data in test set.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 但你不应该假设自己总是会幸运。例如，如果你使用交叉验证来随机重复地将数据拆分为训练和测试部分，你可能会发现实际的训练数据缺少一些类别。这会导致错误，因为你无法转换测试集中的数据。
- en: 'The solution provided by sklearn for this case is to explicitly provide the
    possible categories to the OneHotEncoder object as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: sklearn为这种情况提供的解决方案是明确地向OneHotEncoder对象提供可能的类别，如下所示：
- en: You need to provide a list of lists in the categories parameter in order to
    specify the categories for each of the input columns.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要在类别参数中提供一个列表的列表，以便为每个输入列指定类别。
- en: Another common step, when using scikit is to do the conversion between raw numpy
    arrays and pandas DataFrames. You can either use sklearn.compose.make_column_transformer
    for this, or implement it manually, using the .get_feature_names_out() method
    of OneHotEncoder to give you the column names for the new features. Let’s see
    examples for both of these. I will add another column, Color, in order to make
    the examples more informative.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 使用scikit的另一个常见步骤是进行原始numpy数组和pandas DataFrame之间的转换。你可以使用`sklearn.compose.make_column_transformer`来实现，或者手动实现，使用OneHotEncoder的`.get_feature_names_out()`方法来获取新特征的列名。让我们来看一下这两种方法的示例。我将添加另一列，Color，以使示例更加信息丰富。
- en: Specifying inputs and encoder
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指定输入和编码器
- en: '![](../Images/70c91ca71450d91a0d7f0931da171785.png)![](../Images/fb9684dd5f41de7d56167c297eaed9ae.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/70c91ca71450d91a0d7f0931da171785.png)![](../Images/fb9684dd5f41de7d56167c297eaed9ae.png)'
- en: Column transformer approach
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 列转换器方法
- en: '![](../Images/61791f3991a1bb6481173c1e9e39d969.png)![](../Images/ef68010416160a735642951ca20904e4.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61791f3991a1bb6481173c1e9e39d969.png)![](../Images/ef68010416160a735642951ca20904e4.png)'
- en: We can see that the column converter does part of the job, but we still need
    to do additional work if we want to use DataFrames. Also I don’t really like these
    column names, but there’s no way to tune them, other than manual post processing.
    Note, that columns are created for all possible categories not only those which
    appear in the input.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到列转换器完成了部分工作，但如果我们想使用 DataFrames，还需要做额外的工作。我也不太喜欢这些列名，但除了手动后处理，没有其他方法可以调整它们。注意，列是为所有可能的类别创建的，而不仅仅是那些出现在输入中的类别。
- en: Manual approach
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 手动方法
- en: I call it manual, as we use the OneHotEncoder object directly and deal with
    selecting, and appending the columns ourselves.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我称之为手动方法，因为我们直接使用 OneHotEncoder 对象，并自己处理选择和追加列的操作。
- en: '![](../Images/0d1749798e8b1fcccf3ded14f9d15934.png)![](../Images/9e5c6b060d1f8b990a63e86e6ecc07ee.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0d1749798e8b1fcccf3ded14f9d15934.png)![](../Images/9e5c6b060d1f8b990a63e86e6ecc07ee.png)'
- en: We had to do a bit more of manual work, but the column names are much more friendly.
    Besides, in newer versions of scikit (1.3 and above) we can fine-tune these names.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不得不做一点额外的手动工作，但列名更友好。此外，在较新的 scikit 版本（1.3 及以上）中，我们可以微调这些名称。
- en: Pipelines
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管道
- en: A [scikit pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)
    is a convenient way to sequentially apply a list of transforms. You can use it
    to assemble several steps that can be cross-validated together while setting different
    parameters.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 [scikit 管道](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)
    是一种方便的方式来顺序应用一系列转换。你可以使用它来组装几个步骤，这些步骤可以一起进行交叉验证，同时设置不同的参数。
- en: The manual/raw approach is generally not suited to be included in a pipeline
    because of the additional steps needed to select and add the columns. The column
    transformer approach, on the other hand, is suited for pipelines. The additional
    steps we made were only required to transform the numpy array to DataFrame, which
    is not a requirement for a pipeline.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 手动/原始方法通常不适合包含在管道中，因为需要额外的步骤来选择和添加列。而列转换器方法则适用于管道。我们所做的额外步骤仅仅是将 numpy 数组转换为
    DataFrame，这对管道来说不是必需的。
- en: Pandas
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Pandas
- en: The pandas.get_dummies function does not follow the fit/transform model, neither
    does it have an explicit input parameter specifying the available categories.
    One could therefore conclude, that it is is inappropriate for the job. This conclusion,
    however, is not correct.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: pandas.get_dummies 函数不遵循 fit/transform 模型，也没有明确的输入参数来指定可用的类别。因此，可以得出结论，它不适合这个任务。然而，这个结论并不正确。
- en: Pandas inherently supports the handling of categorical data through [pandas.CategoricalDtype](https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.html).
    You need to do your homework, and set up the column categories properly. Once
    that is done consistently, you no longer need the fitting step.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 本身支持通过 [pandas.CategoricalDtype](https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.html)
    处理分类数据。你需要做好功课，并正确设置列的类别。一旦一致完成这些操作，你就不再需要拟合步骤了。
- en: 'Using the categorical type has additional benefits, like reduced storage space,
    or checking for typos. Let’s see how this is done:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 使用分类类型有额外的好处，例如减少存储空间或检查拼写错误。让我们看看这是如何做到的：
- en: Now all we need to do is to call the get_dummies function.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要做的就是调用 get_dummies 函数。
- en: '![](../Images/a9a6b0a503f3702dec63e9c226f35fe8.png)![](../Images/1017ba1bb0d8e5118cabc84e2e0a7f2f.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a9a6b0a503f3702dec63e9c226f35fe8.png)![](../Images/1017ba1bb0d8e5118cabc84e2e0a7f2f.png)'
- en: 'As we can see, after the categories are properly set, there is no additional
    work needed to have a nice DataFrame. Actually, I did a bit of cheating above:
    by default, get_dummies converts all columns with object, string, or category
    dtype. If this isn’t what we want, we can explicitly specify the list of columns
    to convert, using the columns parameter of get_dummies:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，在类别正确设置之后，不需要额外的工作就可以获得一个漂亮的 DataFrame。实际上，我在上面有点作弊：默认情况下，get_dummies
    会转换所有具有对象、字符串或类别数据类型的列。如果这不是我们想要的，我们可以通过使用 get_dummies 的 columns 参数显式指定要转换的列列表：
- en: '![](../Images/fde6e02007b4109ea7826d3c978cdae7.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fde6e02007b4109ea7826d3c978cdae7.png)'
- en: 'We have mentioned scikit pipelines above. In order for a transformer to be
    eligible for a pipeline it has to implement the fit and transform methods, which
    the get_dummies function clearly does not do. Fortunately, it is super easy to
    create a custom transformer for this task:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上面提到了 scikit 管道。为了使变换器适用于管道，它必须实现 fit 和 transform 方法，而 get_dummies 函数显然没有做到这一点。幸运的是，为此任务创建一个自定义变换器非常简单：
- en: Now we can use our new class as any other scikit transformer, we can even embed
    it in a pipeline.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以像使用其他 scikit 变换器一样使用我们新的类，我们甚至可以将其嵌入到管道中。
- en: '![](../Images/fde6e02007b4109ea7826d3c978cdae7.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fde6e02007b4109ea7826d3c978cdae7.png)'
- en: When writing this transformer we assumed that the relevant columns already have
    categorical dtypes. But it is very simple to add a few lines of code to GetDummiesTransformer
    to allow the specification of the columns in the __init__ function.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写这个变换器时，我们假设相关列已经具有分类数据类型。但是，只需添加几行代码到 GetDummiesTransformer 中即可在 __init__
    函数中允许指定列。
- en: Conclusion
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'As we have seen it is possible and very much suggested to explicitly specify
    the available categories for both the scikit OneHotEncoder and the pandas get_dummies
    approaches. (Remember: explicit is better than implicit!). This means, that **both
    of these approaches are well suited for the task** so it is a personal preference
    which one to choose. For scikit the explicit category setting was achieved by
    passing a parameter to the constructor of the OneHotEncoder class, while for pandas
    we had to setup the categorical datatype.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，明确指定 scikit OneHotEncoder 和 pandas get_dummies 方法的可用类别是可能的，也非常推荐。（记住：明确优于隐含！）这意味着**这两种方法都非常适合这个任务**，所以选择哪个方法是个人偏好。对于
    scikit，明确的类别设置是通过将参数传递给 OneHotEncoder 类的构造函数实现的，而对于 pandas，我们必须设置分类数据类型。
- en: Using the **“raw” version of OneHotEncoder** (ie. without a column transformer)
    needs the most manual adjustment, and I see only very rare cases where I would
    use this approach in practice.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**“原始”版本的 OneHotEncoder**（即没有列变换器）需要最多的手动调整，我在实际中仅在非常少见的情况下会使用这种方法。
- en: If your process relies on scikit pipelines (which has many advantages) then
    using scikit **OneHotEncoder with a column transformer seems** to be the most
    natural choice to me.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的过程依赖于 scikit 管道（这有许多优点），那么使用 scikit **OneHotEncoder 和列变换器似乎**是最自然的选择。
- en: If you like to process the data step-by-step, going from DataFrame to DataFrame
    (which can be a good choice in the exploration phase) then I would definitely
    take the **pandas.get_dummies** approach.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你喜欢逐步处理数据，从一个 DataFrame 到另一个 DataFrame（这在探索阶段可能是一个不错的选择），那么我一定会选择**pandas.get_dummies**方法。
- en: 'That’s it folks. I hope you learned something from my post. And as always:
    like, subscribe, share, comment!'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样，希望你从我的帖子中学到了东西。像往常一样：点赞、订阅、分享、评论！
