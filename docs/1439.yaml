- en: Multivariate Process Control by Principal Component Analysis Using T² and Q
    errors
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/multivariate-process-control-by-principal-component-analysis-using-t%C2%B2-and-q-errors-c94908d14b04?source=collection_archive---------8-----------------------#2023-04-26](https://towardsdatascience.com/multivariate-process-control-by-principal-component-analysis-using-t%C2%B2-and-q-errors-c94908d14b04?source=collection_archive---------8-----------------------#2023-04-26)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Using and interpreting Hotelling’s T² and Squared Prediction Error Q in anomaly
    detection systems
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@davide.massidda?source=post_page-----c94908d14b04--------------------------------)[![Davide
    Massidda](../Images/b5cf1dc0201041ff5cad76ee13ee2df1.png)](https://medium.com/@davide.massidda?source=post_page-----c94908d14b04--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c94908d14b04--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c94908d14b04--------------------------------)
    [Davide Massidda](https://medium.com/@davide.massidda?source=post_page-----c94908d14b04--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F433251ece79d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultivariate-process-control-by-principal-component-analysis-using-t%C2%B2-and-q-errors-c94908d14b04&user=Davide+Massidda&userId=433251ece79d&source=post_page-433251ece79d----c94908d14b04---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c94908d14b04--------------------------------)
    ·12 min read·Apr 26, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc94908d14b04&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultivariate-process-control-by-principal-component-analysis-using-t%25C2%25B2-and-q-errors-c94908d14b04&user=Davide+Massidda&userId=433251ece79d&source=-----c94908d14b04---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc94908d14b04&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultivariate-process-control-by-principal-component-analysis-using-t%25C2%25B2-and-q-errors-c94908d14b04&source=-----c94908d14b04---------------------bookmark_footer-----------)![](../Images/054e0f77d6a401cd71794ce2aa09c550.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Image from [geralt](https://pixabay.com/users/geralt-9301/) on [Pixabay](https://pixabay.com/illustrations/geometry-mathematics-volume-surface-1044090/)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: A substantial part of my job as a data scientist consists in building anomaly
    detection systems for process control in manufacturing, and the Principal Component
    Analysis (from now PCA) has an essential role in my toolbox.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家的工作中，构建制造过程控制的异常检测系统是一个重要部分，主成分分析（以下简称PCA）在我的工具箱中扮演着关键角色。
- en: 'The scientific literature suggests two measures to trace anomalies through
    the PCA: **Hotelling’s T²** and Squared Prediction Error, aka **Q error**. Although
    their calculation is not complicated, the base software packages often ignore
    them, and their meaning remains quite enigmatic.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 科学文献建议使用两种度量来追踪PCA中的异常：**Hotelling的T²**和平方预测误差，也称为**Q误差**。尽管它们的计算并不复杂，但基础软件包通常忽略它们，其含义仍然相当神秘。
- en: There are hundreds of good tutorials about PCA on the web. However, despite
    this large amount of information, some questions about the usage of PCA in production
    environments still need to be adequately addressed. In this tutorial, I’ll avoid
    repeating what hundreds of people said before me, going straight to the point.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 网络上有数百个关于PCA的优秀教程。然而，尽管信息量很大，一些关于PCA在生产环境中使用的问题仍然需要得到充分解决。在本教程中，我将避免重复之前已有的内容，直截了当地切入主题。
- en: This tutorial
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 本教程
- en: 'After a quick introduction to PCA — just enough to emphasize some points —
    in this tutorial, we’ll deep dive into the usage of T² and Q errors, disassembling
    their formulas to understand what they can tell us. Here you will not find the
    whole story about PCA and its usage in anomaly detection, but I will focus on
    the meaning of T² and Q measures: from where they rise and how to interpret them.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在对PCA进行快速介绍后——仅仅强调一些要点——在本教程中，我们将深入探讨T²和Q误差的使用，拆解它们的公式以理解它们能告诉我们什么。这里你不会找到有关PCA及其在异常检测中使用的全部故事，但我将重点讲解T²和Q度量的含义：它们从何而来以及如何解读。
- en: I will use basic Python code, directly leveraging the SVD algorithm implemented
    in `numpy`. I will propose only the necessary code to obtain the described results,
    cutting the one to generate the graphs (you can find it [here](https://github.com/DavideMassidda/MPC-by-PCA)).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用基础的Python代码，直接利用`numpy`中实现的SVD算法。我只会提供获得所描述结果所需的代码，省略生成图表的代码（你可以在 [这里](https://github.com/DavideMassidda/MPC-by-PCA)
    找到）。
- en: Read on if you have at least a shallow knowledge of PCA as a data reduction
    technique. If you don’t know what a principal component is, I suggest you move
    to a general dissertation about PCA, then next, return here.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你至少对PCA有一个浅显的了解，请继续阅读。如果你不知道什么是主成分，建议你先阅读关于PCA的一般论文，然后再回来这里。
- en: Table of contents
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目录
- en: '**Process control data**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**过程控制数据**'
- en: – *Centering and scaling data* **Process control by PCA**
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: – *数据中心化和缩放* **通过PCA进行过程控制**
- en: – *An encoding-decoding system*
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: – *编码-解码系统*
- en: – *Distillation* **Anomaly detection by PCA**
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: – *蒸馏* **通过PCA进行异常检测**
- en: – *Squared Prediction Error Q*
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: – *平方预测误差 Q*
- en: – *Hotelling’s T²* **Anomaly detection in practice** – *From data to PCs… and
    back*
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: – *Hotelling的T²* **实际中的异常检测** – *从数据到主成分…再回来*
- en: – *Q contributions*
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: – *Q贡献*
- en: – *T² contributions* **Concluding remarks**
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: – *T²贡献* **总结性意见**
- en: Process control data
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过程控制数据
- en: For this tutorial, I generated some ad-hoc data, simulating a straightforward
    process control in an industrial plant. In [this repository](https://github.com/DavideMassidda/MPC-by-PCA),
    you can find the data and a notebook, including the complete code used to run
    the analyses.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我生成了一些特定的数据，模拟了工业工厂中的一个简单过程控制。在 [这个仓库](https://github.com/DavideMassidda/MPC-by-PCA)
    中，你可以找到数据和一个笔记本，其中包括用于运行分析的完整代码。
- en: Let’s start reading the data and briefly exploring it.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始读取数据并简要探索它。
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The table includes a column “group” splitting observations in a *train* set
    (100 records) and a *test* set (30 records). Five variables are recorded.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 表格包括一个“group”列，将观察分为*训练*集（100条记录）和*测试*集（30条记录）。记录了五个变量。
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Each variable is monitored over time.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 每个变量在时间上被监控。
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The correlation matrix shows good relations between the whole set of variables.
    No “isolated communities” of variables or redundant measures appear.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 相关矩阵显示了变量集之间的良好关系。没有出现“孤立社区”或冗余测量。
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Centering and scaling data
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据的中心化和缩放
- en: Since data have different scales, we need to center and scale values before
    running the PCA, obtaining a training set where each variable has a mean of 0
    and a standard deviation of 1.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据具有不同的尺度，我们需要在运行PCA之前对值进行中心化和缩放，得到一个训练集，其中每个变量的均值为0，标准差为1。
- en: To rescale future data, I train a “scaler” object storing the center and scale
    parameters, so I transform the training data. I call “X” the raw observed data
    and “Z” the scaled data.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了重新缩放未来数据，我训练一个“缩放器”对象来存储中心和尺度参数，以便我可以转换训练数据。我将原始观察数据称为“X”，将缩放后的数据称为“Z”。
- en: '[PRE8]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Finally, let’s see the time series of records for each autoscaled variable.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，看看每个自动缩放变量的时间序列记录。
- en: '![](../Images/9bb9203266640708a70d3e8322ed59eb.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9bb9203266640708a70d3e8322ed59eb.png)'
- en: Figure 1\. Times series of autoscaled variables — Image from the author, license
    CC0.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图1\. 自动缩放变量的时间序列 — 图片来源于作者，许可证CC0。
- en: Process control by PCA
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过PCA进行过程控制
- en: A way to view PCA is as an encoding-decoding system trained on a data set representing
    a process in control. During the training, the system learns the rules for relating
    the variables to monitor. Subsequently, laying on these rules, the system can
    evaluate new data, establishing whether a process is in control.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 观察PCA的一种方式是将其视为一个经过训练的编码-解码系统，该数据集表示一个受控过程。在训练过程中，系统学习监控变量之间的关系规则。随后，依赖于这些规则，系统可以评估新数据，确定过程是否在控制之中。
- en: 'PCA takes the observed variables as an ensemble and **redistributes their variability**,
    building new **orthogonal** variables: the Principal Components (PCs). Starting
    from *k* variables, PCA allows obtaining *k* PCs. The algorithm estimates the
    coefficients (*loadings*) to multiply with observed variables (Z) to get PCs.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: PCA将观察到的变量视作一个整体，并**重新分配它们的变异性**，构建新的**正交**变量：主成分（PCs）。从* k *个变量开始，PCA可以得到*
    k *个PCs。该算法估计系数（*loadings*），用于与观察变量（Z）相乘以获得PCs。
- en: '![](../Images/cf94358b68cc321cd5bb4a72ef0f8e7d.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cf94358b68cc321cd5bb4a72ef0f8e7d.png)'
- en: Figure 2\. Relations between the data space and the components space in PCA
    — Image from the author, license CC0.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图2\. PCA中数据空间与成分空间之间的关系 — 图片来源于作者，许可证CC0。
- en: In practice, PCA finds the rules (i.e., the loadings) to **project** data from
    the space of observed data to the space of principal components, obtaining the
    PC scores. This projection can be reverted by multiplying the PC scores by the
    transposed loadings matrix (see Figure 2).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，PCA找到规则（即系数）来**将**数据从观察数据空间投影到主成分空间，从而获得PC得分。这种投影可以通过将PC得分与转置的系数矩阵相乘来恢复（见图2）。
- en: I use the Singular Value Decomposition algorithm in the following code block
    to estimate loadings for our plant data.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我在以下代码块中使用奇异值分解算法来估计我们植物数据的系数。
- en: '[PRE9]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The loadings array reports variables on the rows and PCs on the columns. This
    is the usual orientation of the matrix, but software packages can differ in their
    disposition.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 系数数组报告变量在行上，PCs在列上。这是矩阵的常规方向，但软件包的排列方式可能会有所不同。
- en: We can obtain the PC scores by multiplying the observed data matrix by the loadings
    matrix.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将观察数据矩阵乘以系数矩阵来获得PC得分。
- en: '[PRE11]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: An encoding-decoding system
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编码-解码系统
- en: A key concept of PCA is that each PC is fed by all the variables (although with
    varying degrees depending on the loading value). Then, when we inspect the scores
    of a single PC, we inspect all the variables at once (yes, it is!).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: PCA的一个关键概念是每个PC都由所有变量提供（尽管根据系数值的不同，程度有所不同）。因此，当我们检查单个PC的得分时，我们实际上是在一次性检查所有变量（是的，就是这样！）。
- en: However, the overall data variability isn’t equally distributed between PCs
    because PCs are ranked from the one accounting for the greatest variability (PC_1)
    to the one accounting for the lesser variability (PC_k). Realistically, the first
    PCs account for the “signal” present in data, while the latest for the noise.
    So, we can drop the PCs not conveying a significant amount of variability, separating
    the signal from the noise.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，总的数据变异性在PCs之间并不均等分配，因为PCs是从最大变异性（PC_1）到较少变异性（PC_k）进行排序的。实际上，前面的PCs代表数据中的“信号”，而后面的PCs代表噪声。因此，我们可以丢弃那些没有显著变异性的PCs，将信号与噪声分开。
- en: The figure below shows the time series PC scores on our data. It’s evident the
    decrement in variability when increasing the rank of the component (in particular,
    jumping from the first to the second component).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图展示了我们数据的时间序列PC得分。显然，随着成分排名的增加（特别是从第一个成分跳到第二个成分），变异性减少。
- en: '![](../Images/1128f44e5a1a16488cf6c14495a3e9c8.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1128f44e5a1a16488cf6c14495a3e9c8.png)'
- en: Figure 3\. Time series of principal component scores — Image from the author,
    license CC0.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图3\. 主成分得分的时间序列 — 图片来源于作者，许可证CC0。
- en: Distillation
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 蒸馏
- en: In the image below, I exploded Figure 2\. I represented all the retained PCs
    in the gray node named *distilled data*, while with the other gray node, I represented
    all the dropped PCs. I used the term “distilled” because each component is an
    amalgamated essence of many variables.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2b190cb219fc2564ac841b2d74d18d42.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
- en: Figure 4\. PCA as an encoding-decoding system — Image from the author, license
    CC0.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: We can calculate the amount of variance assimilated by each component by squaring
    the singular values from SVD and dividing them by the degrees of freedom.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Let’s look at the results.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The first component accounts for 69% of the total variance of data. Adding up
    the second component, we can explain the 80%. Two components can be enough to
    resume the whole data if we assume the remaining 20% is noise.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Using only two of five components is like performing a data compression with
    losing information. However, since the lost part theoretically is noise, we are
    gaining an advantage by dropping the last components.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Let’s isolate the loadings and variances on our system.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: When new data arrive at a trained PCA, they are projected into the component
    space (encoding). Afterward, they are rebuilt to revert the process, using just
    the firsts PCs (decoding).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly detection by PCA
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, we deep dive into detecting anomalies by Q and T² error measures. First
    of all, let’s understand what they represent. We will see the formulas directly
    applied to the data later.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Squared Prediction Error Q
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since we dropped the noise in the encoding step, the rebuilt data cannot be
    exactly equal to the observed data. This difference generates the error Q.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: 'When the process control system returns an anomaly of type Q, **something has
    broken the correlation structure**: one or more variables are no longer variating
    in harmony with the others (where the concept of “in harmony” is defined by the
    correlation matrix).'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: We can distinguish two extreme scenarios.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: A variable takes an unexpected value (not necessarily out of range) and is no
    longer “predictable” from the others. If a certain type of correlation is expected
    from two variables, and suddenly the direction of one changes, their expected
    relation isn’t observed more, generating an alarm.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The variable has a normal behavior, but all the others deviate from expectations.
    If previous information says that when the other variables deviate, our variable
    should deviate too, and it does not, the process has an anomaly.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The second scenario can appear paradoxical. For this reason, we need to consider
    another type of error: Hotelling’s T².'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Hotelling’s T²
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Unlike Q, T² is more **linked to the metric of the observed data**: values
    out of the expected range generate extremes T².'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: The T² statistic is strictly related to the [Mahalanobis distance](https://en.wikipedia.org/wiki/Mahalanobis_distance).
    We can conceive T² as a multivariate version of an anomaly detection system based
    on thresholds imposed on observed data but with some relevant differences.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: Observed data are denoised from the encoding system.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Anomalies are searched at the PC level, and only later they will be decoded
    at the observed data level.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The second point is interesting because PCs synthesize the entire group of variables.
    Using T², we do not search anomalies variable-by-variable in a univariate perspective,
    but we analyze data all at once.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: During the training process, we stored the variances of the PCs. Now, we can
    use this information to compare the observed variance of PCs against the expected
    one, calculating an “anomaly score” for each PC. Afterward, we can decode this
    anomaly score to return to the data space, obtaining the contribution of each
    variable to the variation of the PCs.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly detection in practice
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Previously we built our PCA system. Now, let’s start to use it, projecting new
    data in the PC space. We start centering and scaling data, next visualizing the
    time series of variables.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: In the image below, the time series of each variable for the new data is represented.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5b264beb537ff0a6617c08b3fd51ea5b.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
- en: Figure 5\. Time series of centered and scaled test data — Image from the author,
    license CC0.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Insane data, isn’t it? As you can see, **I simulated a going crazy process**.
    Four variables strongly drift from the expected mean to high values, and a fifth
    variable, after an initial drift, gradually returns to normal values.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: From data to PCs… and back
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can **encode** data calculating the PC scores:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Thereafter, we can **decode** the PCs calculating the expected data:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now, let’s visualize the time series of rebuilt data:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/46a1faf68a46450b5ad31ffc1f4a9e06.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
- en: Figure 6\. Times series of expected data built using a subset of PCs — Image
    from the author, license CC0.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Well, here we finally reveal a fundamental issue of multivariate process control.
    If you look closely at the chart above, you’ll notice that the rebuilt data show
    two main defects compared to the observed data (Figure 5).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: The observed data of the first four variables peak and settle on a plateau.
    Differently, their expected values, after peaking, gradually decrease.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The observed data of the fifth variable climb to the peak and quickly decrease.
    Differently, its expected values show a slight decrease after peaking. Essentially,
    its trend is similar to one of the other variables.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The reconstruction of the first four variables has been influenced by what happens
    in the fifth, while the reconstruction of the fifth variable has been influenced
    by what happens in the first four. Then, each rebuilt variable is a mix of the
    entire dataset.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: This inaccuracy is happening **because we are decoding by dropping the last
    PCs**. According to our PCA, the “madness” of new data is noise, so it’s absorbed
    from the last PCs, which absorb the “singularities” of new data absent in training
    data.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: 'In production environments, Q and T² errors can be used to monitor these anomalies
    and understand their origin. For both statistics, we can calculate the following
    values:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: the contribution of each variable to each measure of error;
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the squared cumulated contributions for each measure of error, generating the
    Q and T² properly said.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can find details with good math explanations [here](https://wiki.eigenvector.com/index.php?title=T-Squared_Q_residuals_and_Contributions).
    In this post, I’ll focus on the contributions since the main interest in data
    monitoring is locating the source of the anomaly.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Q contributions
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The contribution of each variable to the Q error is the distance between observed
    scaled data and their expected (rebuilt) values.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: In the image below, you can visualize the time series of Q contributions of
    new data.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d59e0bca5f013d27591efda947055e22.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
- en: Figure 7\. Times series of Q contributions — Image from the author, license
    CC0.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: Roughly speaking, Q contributions are near zero for all the variables since
    half of the monitoring period. In the second part of the period, Q contributions
    drift from zero for all the variables, especially for the fifth.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: This shouldn’t surprise us. As we have seen, up to the middle of the period,
    the variables are anomalous but anomalous **in a synchronous way** (coherently
    with correlations observed in the training set). In the second part of the period,
    the fifth variable returns towards the mean, going to “normal” values (near the
    ones of the training set) but **breaking** the correlation structure.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: T² contributions
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The formula to obtain T² contributions is similar to the formula to decode
    PCs to the data level but with an important difference: the **scaling factor**.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: PCs are all mean-centered, so the expected value for all the PCs is zero. However,
    since each PC absorbs a different amount of data variance (see Figure 3), each
    PC has its scale. The same score may represent a small variation on one PC but
    a large variation on another!
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, before decoding, each PC is scaled by dividing it by its standard
    deviation. In this way, PCs are put on the same scale before decoding.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The image below shows the time series of T² contributions.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5f6918975916ca544256ea9ac21057ce.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
- en: Figure 8\. Time series of T² contributions — Image from the author, license
    CC0.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Concluding remarks
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The process control using PCA considers the monitored variables as a system
    that should move in unison, expecting its elements to vary consistently (Q statistic)
    and within certain ranges (T² statistic).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'The main difference between Q and T² anomalies is where these originate: the
    first at the **data level** and the second at the **PC level**.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Q warns us that the encoding-decoding system isn’t working as expected on new
    data because of the observed relations between the variables. So, the Q contributions
    allow us to identify the unpredictable variables given the observed data.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Q 警告我们编码解码系统在新数据上由于变量间的观察关系未按预期工作。因此，Q 贡献使我们能够根据观察数据识别不可预测的变量。
- en: T² warns us that the encoding system is getting PC scores too distant from the
    center of the whole data. The T² contributions decode the errors, “back-propagating”
    them to the data level, allowing us to identify the variables with anomalous observations.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: T² 警告我们编码系统的 PC 分数与整个数据中心的距离过远。T² 贡献解码错误，“反向传播”到数据层级，允许我们识别具有异常观测值的变量。
- en: The core idea is that each data record consists of a signal and a noise. The
    PCA removes the noise and evaluates the signal, alarming if the signal of a variable
    is too distant from as expected (T²) and if it’s overwhelmed by the noise (Q).
    One does not necessarily imply the other, although they can occur together.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 核心思想是每条数据记录由信号和噪声组成。PCA 去除噪声并评估信号，如果变量的信号与预期（T²）过远或被噪声压倒（Q），则发出警报。尽管它们可以同时发生，但一个并不一定意味着另一个。
