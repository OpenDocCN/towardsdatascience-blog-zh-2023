- en: 'The Dreaded Antagonist: Data Leakage in Machine Learning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-dreaded-antagonist-data-leakage-in-machine-learning-5f08679852cc?source=collection_archive---------6-----------------------#2023-05-19](https://towardsdatascience.com/the-dreaded-antagonist-data-leakage-in-machine-learning-5f08679852cc?source=collection_archive---------6-----------------------#2023-05-19)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Probably one of the most underappreciated concepts in Machine Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@andreas030503?source=post_page-----5f08679852cc--------------------------------)[![Andreas
    Lukita](../Images/8660ca1fea5da34ce3475281c1f52152.png)](https://medium.com/@andreas030503?source=post_page-----5f08679852cc--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5f08679852cc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5f08679852cc--------------------------------)
    [Andreas Lukita](https://medium.com/@andreas030503?source=post_page-----5f08679852cc--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F955ef38ea7b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-dreaded-antagonist-data-leakage-in-machine-learning-5f08679852cc&user=Andreas+Lukita&userId=955ef38ea7b&source=post_page-955ef38ea7b----5f08679852cc---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5f08679852cc--------------------------------)
    ·13 min read·May 19, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5f08679852cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-dreaded-antagonist-data-leakage-in-machine-learning-5f08679852cc&user=Andreas+Lukita&userId=955ef38ea7b&source=-----5f08679852cc---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5f08679852cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-dreaded-antagonist-data-leakage-in-machine-learning-5f08679852cc&source=-----5f08679852cc---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: I have attended more than 5 Business Analytics and Machine Learning courses,
    both in-person and online. Surprisingly, only one has scratched the surface of
    data leakage, briefly.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/27869387f3796925a3534d992a08e29b.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Luis Tosta](https://unsplash.com/@luis_tosta?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: When talking about data leakage without the context of machine learning, oftentimes
    we refer to it as the scenario when confidential information is transferred to
    a third party without proper security measures or permission, leading to a breach
    of privacy and security[¹](#21ca).
  prefs: []
  type: TYPE_NORMAL
- en: 'While the concept is somewhat similar, this is not quite the explanation in
    the context of machine learning. Here’s what it means in the world of machine
    learning:'
  prefs: []
  type: TYPE_NORMAL
- en: Data leakage occurs when information from the test dataset is mistakenly included
    in the training dataset.[²](#0b31)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**The result?** Unrealistically good performance metrics during training, but
    poor performance when the model is actually put to use.'
  prefs: []
  type: TYPE_NORMAL
- en: '**In simpler terms,** the model memorized information that it should not have
    access to, leading to artificially inflated performance metrics during training.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Still can’t wrap your head around it?** Well, picture this. You are studying
    for your upcoming math exam. You do lots of practice questions to get better each
    day. Then, you find out that the exam questions have been accidentally leaked
    online. You have access to this critical information and decide to practice on
    this paper (You train yourself on this dataset that is not supposed to be known
    before the exam, and thus, you “memorize” the pattern of the question). The result?
    You become overly familiar with the test question and you get unrealistically
    good performance metrics for that piece of paper, but when you are actually put
    to use in the real world… (let’s not touch on that).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Table of Contents**'
  prefs: []
  type: TYPE_NORMAL
- en: Types of Data Leakage in Machine Learning ([**Target Leakage**](#9db8), [**Train-Test
    Contamination, Leakage during Data Preprocessing**](#501a))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Consequences of Data Leakage in Machine Learning**](#91a0)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preventing Data Leakage in Machine Learning ([**Manual Review**](#29c5), **Data
    cleaning and preprocessing**, [**Using pipeline**](#fde0), [**Proper validation
    techniques**](#7dbc))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Real-world Dataset Examples: The Titanic Dataset**](#7912)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Data Leakage 1st illustration: Including target survived as feature**](#35b6)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Data Leakage 2nd illustration: Mixing up records of training and testing
    data**](#b38e)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Data Leakage 3rd illustration: Wrong data preprocessing steps**](#c37d)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Data Leakage 4th illustration: Including the feature cabin as part of the
    feature in the model**](#eb28)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Target Leakage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As for **Target Leakage**, it might not be so easy and straightforward to recognize.
    Picture this: you are building a model to predict whether your customers will
    cancel their monthly subscriptions to your service (i.e., churn out). At first
    glance, including the **“number of customer service calls”** made by the customeras
    a feature in our model does not seem problematic at all, as you may reason out
    that more customer service calls are linked to a higher probability of churning
    out.'
  prefs: []
  type: TYPE_NORMAL
- en: However, upon closer inspection, it is found that the **“number of customer
    service calls“** is the result of customers churning out, instead of a contributing
    feature. Customers who have already decided to churn out merely call to settle
    any outstanding issues before eventually canceling their subscriptions. Hence,
    this information would not be available to us at the time of predicting whether
    a customer would churn out (In other words, we only know this information for
    customers that have already decided to churn out).
  prefs: []
  type: TYPE_NORMAL
- en: '**Including Target Variable as part of Feature Variables, or any proxy that
    is directly or indirectly derived from the Target Variable, could lead to data
    leakage.**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Train-Test Contamination and Leakage during Data Preprocessing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: These situations refer to the case when the same preprocessing steps are applied
    to both train and test datasets. For instance, when we do data preprocessing steps
    such as feature scaling, estimating missing values, and removing outliers, we
    should ensure that we do not **“learn”** from the test dataset as shown below[³](#f24a).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Here, we separate our dataset into training and testing early before the preprocessing
    steps such that we are able to **fit** only the training dataset. Note that we
    **should not** **fit** on the entire dataset (both train and test) as this would
    result in data leakage (our model learns what it is not supposed to learn, in
    other words, this information about the testing dataset is not known at the time
    of prediction).
  prefs: []
  type: TYPE_NORMAL
- en: '**Fit on training data, transform on both training and testing data.**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Consequences of Data Leakage in Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The consequences of not detecting the presence of data leakage in a machine-learning
    project are immense — they give false hope. Ever experience when your training
    performance is ridiculously high whereas your testing dataset performs very poorly?
    Data leakage might be the culprit. The keywords here are overfitting and the inability
    to generalize. This is because the model has learned to memorize noise and irrelevant
    information, resulting in poor performance when faced with a real test dataset[²](#0b31).
  prefs: []
  type: TYPE_NORMAL
- en: The eventual outcome?
  prefs: []
  type: TYPE_NORMAL
- en: '**You make an inaccurate model evaluation and unreliable predictions. What
    a waste of resources!**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Preventing Data Leakage: Manual Review'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Yes, we all get it. Manual review is inefficient and can be very time-consuming.
    However, putting in the time to study the relationship between features and target
    variable is perhaps the most consistent way to detect data leakage, and hence,
    be very well worth it. When a feature has a very high correlation with the target,
    for example, we should be skeptical to investigate the relationship further. Sometimes,
    doing Exploratory Data Analysis (EDA) might help with uncovering the correlation
    between features and targets. Moreover, having a well-rounded domain knowledge
    and expertise can help to determine whether or not a feature should or should
    not be included in the model. Remember, when in doubt, always ask yourself this
    guiding question
  prefs: []
  type: TYPE_NORMAL
- en: '**“Does this feature contain information that would not be available at the
    time of prediction?”**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If the answer to the above question is a “yes”, then including that feature
    could result in data leakage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Preventing Data Leakage: Pipeline is King'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: None of the Business Analytics and Machine Learning courses that I attended
    before has any mention of building a Machine Learning Preprocessing Pipeline.
    The most common practice is to write spaghetti code all around the place without
    any standardization of workflow. While this may be familiar to many people, it
    is simply not the best practice — one reason being the possibility of introducing
    data leakage into the model. The first time I was exposed to the idea of leveraging
    a pipeline came from the book *Data Cleaning and Exploration with Machine Learning*[⁴](#0654).
    The way of writing the code by embedding each preprocessing step as variable arguments
    into the `make_pipeline` method and separating the steps for numerical, categorical,
    and binary variables respectively are some key lessons I picked up from the book.
  prefs: []
  type: TYPE_NORMAL
- en: Simply put, a pipeline is a set of linear sequences of data preprocessing steps,
    executed one after another. Pipelines offer a clear and orderly chaining process
    for automating a machine learning project’s workflow. We can leverage the scikit-learn
    Pipeline class[⁵](#60b9), which takes a list of tuples as input, where each tuple
    represents a single step in the pipeline. The first element of each tuple is a
    string that represents the name of the step, and the second element is an instance
    of a scikit-learn transformer or estimator object. Of course, there is an alternative
    shorthand to this, which is `**make_pipeline**` which does not require us to name
    the estimators (We are all lazy creatures). Remember, the estimators need to have
    both `**fit**` and `**transform**` method.
  prefs: []
  type: TYPE_NORMAL
- en: '**Why bother with Pipeline?**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pipeline handles all the data processing processes automatically. It also
    makes sure that each step is only fitted on the training data, which prevents
    data leakage and guarantees that the stages are carried out in the proper order.**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Here’s an example: we want to do data preprocessing for different data types
    in our dataset, namely numerical, categorical, and binary features, each with
    different steps. We can leverage on `**make_pipeline**` to lay out the process
    in an orderly manner, and let the Pipeline takes care of all the jobs behind the
    scene. This would return a `**Pipeline**` object which has several attributes
    and methods we can call. For example, we could call `**fit**(X_train, y_train)`
    and `**score**(X_test, y_test)` to fit and evaluate the model respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Preventing Data Leakage: Cross-Validation'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section is inspired by the book *Data Cleaning and Exploration with Machine
    Learning*[⁴](#0654). Another thing I picked up from the book is marrying the concept
    of Pipeline and Cross-Validation. Yes, they are not exclusive! The selection of
    train and test datasets is very critical and could lead to data leakage if not
    done correctly. When we do not perform cross-validation to evaluate our model,
    we run the risk of overfitting the training data and getting poor performance
    on new, unseen data. It could be by chance that the once-off train test split
    that we performed resulted in our model learning a specific feature exclusive
    to that split, which might not be generalizable.
  prefs: []
  type: TYPE_NORMAL
- en: '**Why bother with Cross-Validation?**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cross-validation allows us to obtain a more precise prediction of how well
    our model will perform on brand-new, untested data. By using cross-validation,
    we can test the effectiveness of our model on more than one subset of the data.**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We can leverage **scikit-learn** K-fold CV to achieve this.
  prefs: []
  type: TYPE_NORMAL
- en: How does K-fold CV work in short? The data is first divided into **k** equal-sized
    folds, after which the model is trained on **k-1** folds before being tested on
    the last fold. Each fold serves as the testing set once during the course of this
    operation, which is repeated k times. At the end of the iteration, an estimate
    of the model’s performance is generated by averaging the outcomes of the k iterations.
    When k is set to 1, this means we are falling back to the usual train test split.
    We train our model on the entire dataset and test it on a separate dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The good news is, we can pick up from where we left off in the Pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Real-World Dataset Example: The Titanic Dataset'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Titanic. Classic. The Titanic dataset is a classic machine learning problem,
    where we’re given a set of features for each passenger, such as their age, gender,
    ticket class, place of embarkation, and whether they had family members on board[⁶](#d470).
    Using these features, the goal is to train a machine-learning model to predict
    whether a passenger `**survived**` or not. Here is a short and quick version of
    the prediction without delving into hyperparameter tuning and feature selection.
  prefs: []
  type: TYPE_NORMAL
- en: '***Using the following code to clean up the raw dataset.***'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Let me explain the idea behind the preprocessing steps I have implemented:'
  prefs: []
  type: TYPE_NORMAL
- en: Impute the missing data from `Embarked` column with the most frequent entries
    using `SimpleImputer` class from scikit-learn.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Impute the missing data from `Age` column with a list of mean values based on
    the conditions of whether the person has family members onboard. (i.e. if the
    person has no family member onboard, then we impute the mean that is calculated
    based on the other passengers who also have no family members onboard)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Engineered a feature `IsAlone` to denote whether the passenger has any family
    members onboard
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Engineered a feature `Title` to denote the title of the passenger
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Engineered a feature `AgeGroup` to categorize 5 different age group generations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Data Leakage 1st illustration: Including target** `**survived**` **as feature**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: As you might have expected, including the target variable `survived` as a feature
    effectively make our model useless as it now has an accuracy of 100.0% on the
    validation data. There is no point in doing any prediction. This mistake is easy
    to spot and less common.
  prefs: []
  type: TYPE_NORMAL
- en: 'Data Leakage 2nd illustration: Mixing up records of training and testing data'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If testing data is accidentally included in the training set, the model may
    be trained on this leaked information and thus perform unrealistically well on
    the test set. The following is an ***intentionally made-up example*** of including
    part of the test set into the training set.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Data Leakage 3rd illustration: Wrong data preprocessing steps'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here, we are supposed to separate the dataset into training and testing dataset
    before the preprocessing steps. If we do the preprocessing steps before splitting
    the dataset, we might accidentally learn from the testing dataset, leading to
    overly inflated model performance.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The correct step is to `fit_transform` on the training dataset, and `transform`
    on the testing dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Data Leakage 4th illustration: Including the feature cabin as part of the feature
    in the model'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This data leakage problem is not easy to spot and perhaps needs some domain
    knowledge to understand. The main question to ask is **“Does this feature contain
    information that would not be available at the time of prediction?”** If the answer
    to this question is a yes, then high chance there could be data leakage in play.
  prefs: []
  type: TYPE_NORMAL
- en: In the context of this, the “prediction” is being done after the passengers
    have already boarded the ship and the event has occurred. The goal is to predict
    whether a passenger would have survived or not based on the available data (i.e.
    passenger class, age, etc.) after the event has already taken place. At the time
    of prediction, cabin number information is not available since it was only assigned
    to passengers after they boarded the ship.
  prefs: []
  type: TYPE_NORMAL
- en: Not every passenger had their cabin number recorded in the dataset, in fact,
    we have a large number of missing data. The cabin number may not be accurate or
    complete even for those that do have the record. Thus, we cannot utilize cabin
    number as a predictor when developing a model to estimate survival because it
    could not be correct or available for all passengers.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine that we decide to use the cabin number as one of the predictors in the
    model. While training the model, it uses the cabin number to make predictions
    and gets really good at it. But when we try to use the model in the real world,
    we may not have the cabin number for all passengers, or the cabin number we have
    might be wrong. This means that even if the model was very accurate during training,
    it may not do well in a real-world deployment case.
  prefs: []
  type: TYPE_NORMAL
- en: One possible solution is to drop this feature and exclude it from the model
    building.
  prefs: []
  type: TYPE_NORMAL
- en: Afterword
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Preventing data leakage is indeed a challenging task. Studying the relationship
    between features and target variable is key to uncovering this problem. Next time
    when you see an insanely high performance from your model, maybe it’s better to
    learn to sit back and observe, cause not everything needs a reaction.
  prefs: []
  type: TYPE_NORMAL
- en: Thank you for reading, and happy modeling!
  prefs: []
  type: TYPE_NORMAL
- en: If you pick up something useful from this article, do consider giving me a [***Follow***](https://medium.com/@andreas030503)
    on Medium. Easy, 1 article a week to keep yourself updated and stay ahead of the
    curve!
  prefs: []
  type: TYPE_NORMAL
- en: '***You can connect with me on LinkedIn:*** [***https://www.linkedin.com/in/andreaslukita7/***](https://www.linkedin.com/in/andreaslukita7/)'
  prefs: []
  type: TYPE_NORMAL
- en: '***References:***'
  prefs: []
  type: TYPE_NORMAL
- en: Forcepoint. *What is Data Leakage? Data Leakage Defined, Explained, and Explored*.
    [https://www.forcepoint.com/cyber-edu/data-leakage](https://www.forcepoint.com/cyber-edu/data-leakage)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Analytics Vidhya. *Data Leakage And Its Effect On The Performance of An ML Model*.
    [https://www.analyticsvidhya.com/blog/2021/07/data-leakage-and-its-effect-on-the-performance-of-an-ml-model/](https://www.analyticsvidhya.com/blog/2021/07/data-leakage-and-its-effect-on-the-performance-of-an-ml-model/)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: JFrog. *Be Careful from Data Leakage — Potential Pitfalls in your Machine Learning
    Model*. [https://jfrog.com/community/data-science/be-careful-from-data-leakage-2/](https://jfrog.com/community/data-science/be-careful-from-data-leakage-2/)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Data Cleaning and Exploration with Machine Learning by Michael Walker: [https://www.packtpub.com/product/data-cleaning-and-exploration-with-machine-learning/9781803241678](https://www.packtpub.com/product/data-cleaning-and-exploration-with-machine-learning/9781803241678)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Scikit-learn Pipeline. [https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Titanic Dataset. [https://www.openml.org/search?type=data&status=active&id=40945&sort=runs](https://www.openml.org/search?type=data&status=active&id=40945&sort=runs)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://github.com/datasciencedojo/datasets/blob/master/titanic.csv](https://github.com/datasciencedojo/datasets/blob/master/titanic.csv)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
