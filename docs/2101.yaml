- en: Running Python Wheel Tasks in Custom Docker Containers in Databricks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Databricks中运行自定义Docker容器中的Python Wheel任务
- en: 原文：[https://towardsdatascience.com/running-python-wheel-tasks-in-custom-docker-containers-in-databricks-de3ff20f5c79?source=collection_archive---------8-----------------------#2023-06-29](https://towardsdatascience.com/running-python-wheel-tasks-in-custom-docker-containers-in-databricks-de3ff20f5c79?source=collection_archive---------8-----------------------#2023-06-29)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/running-python-wheel-tasks-in-custom-docker-containers-in-databricks-de3ff20f5c79?source=collection_archive---------8-----------------------#2023-06-29](https://towardsdatascience.com/running-python-wheel-tasks-in-custom-docker-containers-in-databricks-de3ff20f5c79?source=collection_archive---------8-----------------------#2023-06-29)
- en: A step-by-step tutorial to build and run Python Wheel Tasks on custom Docker
    images in Databricks (feat. Poetry and Typer CLI)
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一步步教程，教你如何在Databricks的自定义Docker镜像中构建和运行Python Wheel任务（包括Poetry和Typer CLI）
- en: '[](https://johschmidt42.medium.com/?source=post_page-----de3ff20f5c79--------------------------------)[![Johannes
    Schmidt](../Images/e0cacf7ff37f339a9bf8bd33c7c83a4d.png)](https://johschmidt42.medium.com/?source=post_page-----de3ff20f5c79--------------------------------)[](https://towardsdatascience.com/?source=post_page-----de3ff20f5c79--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----de3ff20f5c79--------------------------------)
    [Johannes Schmidt](https://johschmidt42.medium.com/?source=post_page-----de3ff20f5c79--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://johschmidt42.medium.com/?source=post_page-----de3ff20f5c79--------------------------------)[![Johannes
    Schmidt](../Images/e0cacf7ff37f339a9bf8bd33c7c83a4d.png)](https://johschmidt42.medium.com/?source=post_page-----de3ff20f5c79--------------------------------)[](https://towardsdatascience.com/?source=post_page-----de3ff20f5c79--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----de3ff20f5c79--------------------------------)
    [Johannes Schmidt](https://johschmidt42.medium.com/?source=post_page-----de3ff20f5c79--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb5022ff2e428&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frunning-python-wheel-tasks-in-custom-docker-containers-in-databricks-de3ff20f5c79&user=Johannes+Schmidt&userId=b5022ff2e428&source=post_page-b5022ff2e428----de3ff20f5c79---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----de3ff20f5c79--------------------------------)
    ·13 min read·Jun 29, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fde3ff20f5c79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frunning-python-wheel-tasks-in-custom-docker-containers-in-databricks-de3ff20f5c79&user=Johannes+Schmidt&userId=b5022ff2e428&source=-----de3ff20f5c79---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb5022ff2e428&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frunning-python-wheel-tasks-in-custom-docker-containers-in-databricks-de3ff20f5c79&user=Johannes+Schmidt&userId=b5022ff2e428&source=post_page-b5022ff2e428----de3ff20f5c79---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----de3ff20f5c79--------------------------------)
    ·13分钟阅读·2023年6月29日'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fde3ff20f5c79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frunning-python-wheel-tasks-in-custom-docker-containers-in-databricks-de3ff20f5c79&source=-----de3ff20f5c79---------------------bookmark_footer-----------)![](../Images/fb9e8f76720dd5326d06b7b8b62a10ad.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fde3ff20f5c79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frunning-python-wheel-tasks-in-custom-docker-containers-in-databricks-de3ff20f5c79&source=-----de3ff20f5c79---------------------bookmark_footer-----------)![](../Images/fb9e8f76720dd5326d06b7b8b62a10ad.png)'
- en: Photo by [Lluvia Morales](https://unsplash.com/@hi_lluvia?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Lluvia Morales](https://unsplash.com/@hi_lluvia?utm_source=medium&utm_medium=referral)
    提供，发布于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'Data engineers design and build pipelines to run ETL workloads so that data
    can be used downstream to solve business problems. In Databricks, for such a pipeline,
    you usually start off by creating a **cluster**, a **notebook/script**, and write
    some **Spark** code. Once you have a working prototype, you make it production-ready
    so that your code can be executed as a Databricks job, for example using the REST
    API. For Databricks, this means that there usually needs to be a Python notebook/script
    on the Databricks file system already OR a remote Git repository is connected
    to the workspace*. But what if you don’t want to do either of those? There is
    another way to run a Python script as a Databricks job without uploading any file
    to the Databricks workspace or [connecting to a remote Git repository](https://docs.databricks.com/repos/index.html):
    **Python wheel tasks** with declared entrypoints and **Databricks Container Services**
    allow you to start job runs that will use Docker images from a container registry.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程师设计和构建流水线来运行 ETL 工作负载，以便数据可以在下游用于解决业务问题。在 Databricks 中，对于这样的流水线，通常是通过创建一个**集群**、一个**笔记本/脚本**，并编写一些**Spark**代码来开始。一旦有了工作原型，就使其可以投入生产，这样你的代码可以作为
    Databricks 作业执行，例如使用 REST API。对于 Databricks 而言，这意味着通常需要在 Databricks 文件系统上有一个 Python
    笔记本/脚本，或者连接到工作区的远程 Git 存储库。但如果你不想执行以上任何操作呢？在不将任何文件上传到 Databricks 工作区或[连接到远程 Git
    存储库](https://docs.databricks.com/repos/index.html)的情况下，还有另一种在 Databricks 中运行 Python
    脚本作为作业的方式：利用声明入口点的**Python wheel 任务**和**Databricks 容器服务**，可以启动使用容器注册表中 Docker
    镜像的作业运行。
- en: 'Hence, this tutorial will show you how to do exactly that: run **Python jobs**
    (Python wheel tasks) in **custom Docker images** in Databricks.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，本教程将向您展示如何做到这一点：在 Databricks 中运行**Python 作业**（Python wheel 任务）并使用**自定义 Docker
    镜像**。
