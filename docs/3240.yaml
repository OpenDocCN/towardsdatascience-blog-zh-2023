- en: Topic Modelling in production
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生产中的主题建模
- en: 原文：[https://towardsdatascience.com/topic-modelling-in-production-e3b3e99e4fca?source=collection_archive---------0-----------------------#2023-10-30](https://towardsdatascience.com/topic-modelling-in-production-e3b3e99e4fca?source=collection_archive---------0-----------------------#2023-10-30)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/topic-modelling-in-production-e3b3e99e4fca?source=collection_archive---------0-----------------------#2023-10-30](https://towardsdatascience.com/topic-modelling-in-production-e3b3e99e4fca?source=collection_archive---------0-----------------------#2023-10-30)
- en: Leveraging LangChain to move from ad-hoc Jupyter Notebooks to production modular
    service
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用 LangChain 从临时的 Jupyter Notebook 迁移到生产模块化服务
- en: '[](https://miptgirl.medium.com/?source=post_page-----e3b3e99e4fca--------------------------------)[![Mariya
    Mansurova](../Images/b1dd377b0a1887db900cc5108bca8ea8.png)](https://miptgirl.medium.com/?source=post_page-----e3b3e99e4fca--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e3b3e99e4fca--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e3b3e99e4fca--------------------------------)
    [Mariya Mansurova](https://miptgirl.medium.com/?source=post_page-----e3b3e99e4fca--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://miptgirl.medium.com/?source=post_page-----e3b3e99e4fca--------------------------------)[![Mariya
    Mansurova](../Images/b1dd377b0a1887db900cc5108bca8ea8.png)](https://miptgirl.medium.com/?source=post_page-----e3b3e99e4fca--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e3b3e99e4fca--------------------------------)[![数据科学前沿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e3b3e99e4fca--------------------------------)
    [Mariya Mansurova](https://miptgirl.medium.com/?source=post_page-----e3b3e99e4fca--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F15a29a4fc6ad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftopic-modelling-in-production-e3b3e99e4fca&user=Mariya+Mansurova&userId=15a29a4fc6ad&source=post_page-15a29a4fc6ad----e3b3e99e4fca---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e3b3e99e4fca--------------------------------)
    ·22 min read·Oct 30, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe3b3e99e4fca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftopic-modelling-in-production-e3b3e99e4fca&user=Mariya+Mansurova&userId=15a29a4fc6ad&source=-----e3b3e99e4fca---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F15a29a4fc6ad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftopic-modelling-in-production-e3b3e99e4fca&user=Mariya+Mansurova&userId=15a29a4fc6ad&source=post_page-15a29a4fc6ad----e3b3e99e4fca---------------------post_header-----------)
    发表在 [数据科学前沿](https://towardsdatascience.com/?source=post_page-----e3b3e99e4fca--------------------------------)
    ·22分钟阅读·2023年10月30日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe3b3e99e4fca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftopic-modelling-in-production-e3b3e99e4fca&user=Mariya+Mansurova&userId=15a29a4fc6ad&source=-----e3b3e99e4fca---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe3b3e99e4fca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftopic-modelling-in-production-e3b3e99e4fca&source=-----e3b3e99e4fca---------------------bookmark_footer-----------)![](../Images/afdbbe895f01c14cdde29dadbd785120.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe3b3e99e4fca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftopic-modelling-in-production-e3b3e99e4fca&source=-----e3b3e99e4fca---------------------bookmark_footer-----------)![](../Images/afdbbe895f01c14cdde29dadbd785120.png)'
- en: Image by DALL-E 3
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 DALL-E 3 制作
- en: In [the previous article](/topic-modelling-using-chatgpt-api-8775b0891d16),
    we discussed how to do Topic Modelling using ChatGPT and got excellent results.
    The task was to look at customer reviews for hotel chains and define the main
    topics mentioned in the reviews.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [上一篇文章](/topic-modelling-using-chatgpt-api-8775b0891d16) 中，我们讨论了如何使用 ChatGPT
    进行主题建模，并取得了出色的结果。任务是查看酒店连锁的客户评价，并定义评论中提到的主要主题。
- en: In the previous iteration, we used standard [ChatGPT completions API](https://platform.openai.com/docs/guides/gpt/chat-completions-api)
    and sent raw prompts ourselves. Such an approach works well when we are doing
    some ad-hoc analytical research.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的迭代中，我们使用了标准的 [ChatGPT 完成 API](https://platform.openai.com/docs/guides/gpt/chat-completions-api)
    并且自己发送了原始提示。这种方法在我们进行一些临时分析研究时效果很好。
- en: However, if your team is actively using and monitoring customer reviews, it’s
    worth considering some automatisation. A good automatisation will not only help
    you build an autonomous pipeline, but it will also be more convenient (even team
    members unfamiliar with LLMs and coding will be able to access this data) and
    more cost-effective (you will send all texts to LLM and pay only once).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你的团队正在积极使用和监控客户评论，值得考虑一些自动化。良好的自动化不仅会帮助你构建一个自主的管道，还会更加方便（即使是不熟悉 LLM 和编码的团队成员也能访问这些数据）和更具成本效益（你只需将所有文本发送给
    LLM，并只需支付一次费用）。
- en: Suppose we are building a sustainable production-ready service. In that case,
    it’s worth leveraging existing frameworks to reduce the amount of glue code and
    have a more modular solution (so that we could easily switch, for example, from
    one LLM to another).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们正在构建一个可持续的生产就绪服务。在这种情况下，值得利用现有框架来减少胶水代码的数量，并拥有一个更模块化的解决方案（例如，我们可以轻松地从一个
    LLM 切换到另一个）。
- en: In this article, I would like to tell you about one of the most popular frameworks
    for LLM applications — [LangChain](https://www.langchain.com). Also, we will understand
    in detail how to evaluate your model’s performance since it’s a crucial step for
    business applications.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我想告诉你一个最受欢迎的 LLM 应用框架之一——[LangChain](https://www.langchain.com)。此外，我们将详细了解如何评估你模型的性能，因为这是商业应用中的关键步骤。
- en: Nuances of production process
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生产过程的细节
- en: Revising initial approach
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 修订初始方法
- en: First, let’s revise our previous approach for ad-hoc Topic Modelling with ChatGPT.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们回顾一下之前使用 ChatGPT 进行的即席话题建模方法。
- en: '**Step 1: Get a representative sample.**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 1：获取代表性样本。**'
- en: We want to determine the list of topics we will use for our markup. The most
    straightforward way is to send all reviews and ask LLM to define the list of 20–30
    topics mentioned in our reviews. Unfortunately, we won’t be able to do it since
    it won’t fit the context size. We could use a map-reduce approach, but it could
    be costly. That’s why we would like to define a representative sample.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想确定将用于标记的话题列表。最直接的方法是发送所有评论，并要求 LLM 定义我们评论中提到的 20–30 个话题列表。不幸的是，我们不能做到这一点，因为这不符合上下文大小。我们可以使用
    map-reduce 方法，但这可能会很昂贵。因此，我们希望定义一个代表性样本。
- en: For this, we [built](/topic-modelling-using-chatgpt-api-8775b0891d16) a [BERTopic](https://maartengr.github.io/BERTopic/getting_started/quickstart/quickstart.html)
    topic model and got the most representative reviews for each topic.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们[构建了](/topic-modelling-using-chatgpt-api-8775b0891d16)一个[BERTopic](https://maartengr.github.io/BERTopic/getting_started/quickstart/quickstart.html)
    话题模型，并获得了每个话题中最具代表性的评论。
- en: '**Step 2: Determine the list of topics we will use for markup.**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 2：确定我们将用于标记的话题列表。**'
- en: The next step is to pass all the selected texts to ChatGPT and ask it to define
    a list of topics mentioned in these reviews. Then, we can use these topics for
    later markup.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是将所有选定的文本传递给 ChatGPT，并要求它定义这些评论中提到的话题列表。然后，我们可以使用这些话题进行后续标记。
- en: '**Step 3: Doing topics’ markup in batches.**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 3：批量进行话题标记。**'
- en: The last step is the most straightforward — we can send customer reviews in
    batches that fit the context size and ask LLM to return topics for each customer
    review.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是最直接的——我们可以将符合上下文大小的客户评论分批发送，并要求 LLM 返回每个客户评论的话题。
- en: Finally, with these three steps, we could determine the list of relevant topics
    for our texts and classify them all.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过这三步，我们可以确定我们文本的相关话题列表并对其进行分类。
- en: It works perfectly for one-time research. However, we are missing some bits
    for an excellent production-ready solution.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这在一次性研究中效果很好。然而，我们还缺少一些要素来实现一个出色的生产就绪解决方案。
- en: From ad-hoc to production
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从即席到生产
- en: Let’s discuss what improvements we could make to our initial ad-hoc approach.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一下我们可以对最初的即席方法进行哪些改进。
- en: In the previous approach, we have a static list of topics. But in real-life
    examples, new topics might arise over time, for example, if you launch a new feature.
    So, we need a feedback loop to update the list of topics we are using. The easiest
    way to do it is to capture the list of reviews without any assigned topics and
    regularly run topic modelling on them.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在之前的方法中，我们有一个静态的话题列表。但在实际情况中，新的话题可能会随着时间出现，例如，如果你推出了新功能。因此，我们需要一个反馈循环来更新我们使用的话题列表。最简单的方法是捕捉没有分配话题的评论列表，并定期对其进行话题建模。
- en: If we are doing one-time research, we can validate the results of the topics’
    assignments manually. But for the process that is running in production, we need
    to think about a continuous evaluation.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们进行一次性研究，我们可以手动验证主题分配的结果。但对于在生产环境中运行的过程，我们需要考虑持续评估。
- en: If we are building a pipeline for customer review analysis, we should consider
    more potential use cases and store other related information we might need. For
    example, it’s helpful to store translated versions of customer reviews so that
    our colleagues don’t have to use Google Translate all the time. Also, sentiment
    and other features (for example, products mentioned in the customer review) might
    be valuable for analysis and filtering.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们正在构建一个客户评论分析的管道，我们应该考虑更多潜在的用例，并存储我们可能需要的其他相关信息。例如，存储客户评论的翻译版本是有帮助的，这样我们的同事就不必一直使用Google翻译。此外，情感和其他特征（例如客户评论中提到的产品）可能对分析和过滤很有价值。
- en: The LLM industry is progressing quite quickly right now, and everything is changing
    all the time. It’s worth considering a modular approach where we can quickly iterate
    and try new approaches over time without rewriting the whole service from scratch.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目前LLM行业进展迅速，一切都在不断变化。值得考虑一种模块化的方法，我们可以在不从头开始重写整个服务的情况下，快速迭代并尝试新的方法。
- en: '![](../Images/3a85e2f56aeca48465378a421f27fb2f.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3a85e2f56aeca48465378a421f27fb2f.png)'
- en: Scheme of the service by author
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的服务方案
- en: 'We have a lot of ideas on what to do with our topic modelling service. But
    let’s focus on the main parts: modular approach instead of API calls and evaluation.
    The LangChain framework will help us with both topics, so let’s learn more about
    it.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有很多关于如何使用主题建模服务的想法。但让我们专注于主要部分：模块化方法而非API调用和评估。LangChain框架将帮助我们解决这两个问题，所以让我们深入了解一下它。
- en: LangChain Basics
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LangChain基础知识
- en: '[LangChain](https://python.langchain.com/docs/get_started/introduction) is
    a framework for building applications powered by Language Models. Here are the
    main [components](https://docs.langchain.com/docs/category/components) of LangChain:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[LangChain](https://python.langchain.com/docs/get_started/introduction)是一个用于构建由语言模型驱动的应用程序的框架。以下是LangChain的主要[组件](https://docs.langchain.com/docs/category/components)：'
- en: '**Schema** is the most basic classes like Documents, Chat Messages and Texts.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Schema**是最基本的类，如文档、聊天消息和文本。'
- en: '**Models**. LangChain provides access to LLMs, Chat Models and Text Embedding
    models that you could easily use in your applications and switch between them
    if needed. It goes without saying it supports such popular models like ChatGPT,
    Anthropic and Llama.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Models**。LangChain提供对LLMs、聊天模型和文本嵌入模型的访问，您可以轻松地在应用程序中使用这些模型，并根据需要在它们之间切换。不用说，它支持像ChatGPT、Anthropic和Llama这样的流行模型。'
- en: '**Prompts** is a functionality to help work with prompts, including prompt
    templates, output parsers and example selectors for few-shot prompting.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prompts**是一种帮助处理提示的功能，包括提示模板、输出解析器和少样本提示的示例选择器。'
- en: '**Chains** are the core of LangChain (as you might guess by the name). Chains
    help you to build a sequence of blocks that will be executed. You can truly appreciate
    this functionality if you’re building a complex application.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Chains**是LangChain的核心（正如你从名字中可以猜到的）。Chains帮助您构建一系列将被执行的块。如果您正在构建复杂的应用程序，您会真正欣赏到这个功能。'
- en: '**Indexes**: document loaders, text splitters, vector stores and retrievers.
    This module provides tools that help LLMs to interact with your documents. This
    functionality would be valuable if you’re building a Q&A use case. We won’t be
    using this functionality much in our example today.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Indexes**：文档加载器、文本分割器、向量存储和检索器。此模块提供了帮助LLMs与您的文档交互的工具。如果您正在构建问答用例，这些功能会很有价值。我们今天的示例中不会使用这些功能。'
- en: LangChain provides a whole set of methods to manage and limit **memory**. This
    functionality is primarily needed for ChatBot scenarios.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangChain提供了一整套管理和限制**内存**的方法。这些功能主要用于聊天机器人场景。
- en: One of the latest and most powerful features is **agents**. If you are a heavy
    ChatGPT user, you must have heard about the plugins. It’s the same idea that you
    can empower LLM with a set of custom or predefined tools (like Google Search or
    Wikipedia), and then the agent can use them while answering your questions. In
    this setup, LLM is acting like a reasoning agent and decides what it needs to
    do to achieve the result and when it gets the final answer that it could share.
    It’s exciting functionality, so it’s definitely worth a separate discussion.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最新和最强大的功能之一是**代理**。如果您是ChatGPT的重度用户，您一定听说过插件。这与您可以为LLM配置一组自定义或预定义工具（如Google搜索或维基百科）的想法相同，然后代理可以在回答您的问题时使用它们。在这种设置下，LLM就像一个推理代理，决定为实现结果需要做什么以及何时获得最终答案以分享。这是一个令人兴奋的功能，因此绝对值得单独讨论。
- en: So, LangChain can help us build modular applications and be able to switch between
    different components (for example, from ChatGPT to Anthropic or from CSV as data
    input to Snowflake DB). LangChain has more than [190 integrations](https://python.langchain.com/docs/integrations/providers),
    so that it can save you quite a lot of time.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，LangChain 可以帮助我们构建模块化应用程序，并能够在不同组件之间切换（例如，从ChatGPT到Anthropic，或者从CSV作为数据输入到Snowflake
    DB）。LangChain 拥有超过[190个集成](https://python.langchain.com/docs/integrations/providers)，因此可以帮助您节省大量时间。
- en: Also, we could reuse ready-made chains for [some use cases](https://python.langchain.com/docs/use_cases)
    instead of starting from scratch.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以重用现成的链式结构来处理[某些用例](https://python.langchain.com/docs/use_cases)，而不是从头开始。
- en: When calling ChatGPT API manually, we have to manage quite a lot of Python glue
    code to make it work. It’s not a problem when you’re working on a small, straightforward
    task, but it might become unmanageable when you need to build something more complex
    and convoluted. In such cases, LangChain may help you eliminate this glue code
    and create more easy-to-maintain modular code.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在手动调用ChatGPT API时，我们必须管理大量的Python胶水代码来使其正常工作。当您处理一个小型、简单的任务时，这并不是问题，但是当您需要构建更复杂和复杂的东西时，可能会变得难以管理。在这种情况下，LangChain
    可能会帮助您消除这些胶水代码，并创建更易于维护的模块化代码。
- en: 'However, LangChain has its own limitations:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，LangChain 也有其局限性：
- en: It’s primarily focused on OpenAI models, so it might not work so smoothly with
    on-premise open-source models.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它主要集中在OpenAI模型上，因此可能与本地开源模型不太兼容。
- en: The flip side of convenience is that it’s not easy to understand what’s going
    on under the hood and when and how the ChatGPT API you’re paying for is executed.
    You can use debug mode, but you need to specify it and go through the complete
    logs for a clearer view.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 便利的反面是，不容易理解底层发生了什么，以及何时以及如何执行您支付的ChatGPT API。您可以使用调试模式，但需要指定并查看完整日志，以获得更清晰的视角。
- en: Despite pretty good documentation, I struggle from time to time to find answers
    to my questions. There are not so many other tutorials and resources on the internet
    apart from the official documentation, quite frequently you can see only official
    pages in Google.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管有相当好的文档，我偶尔还是会在寻找答案时遇到困难。除了官方文档外，互联网上几乎没有其他教程和资源，通常只能看到Google的官方页面。
- en: The Langchain library is progressing a lot, and the team constantly ship new
    features. So, the library is not mature, and you might have to switch from the
    functionality you’re using. For example, the `SequentialChain` class is considered
    legacy now and might be deprecated in the future since they’ve introduced [LCEL](https://python.langchain.com/docs/expression_language/)
    — we will talk about it in more detail later on.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Langchain 库正在取得很大进展，团队不断发布新功能。因此，这个库还不够成熟，您可能需要从您正在使用的功能切换。例如，`SequentialChain`类现在被认为是遗留的，并且可能会在未来被弃用，因为他们已经引入了[LCEL](https://python.langchain.com/docs/expression_language/)
    — 我们稍后将更详细地讨论它。
- en: We’ve gotten a birds-eye overview of LangChain functionality, but practice makes
    perfect. Let’s start using LangChain.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经对LangChain功能有了总体的了解，但实践出真知。让我们开始使用LangChain。
- en: Enhancing topics’ assignment
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 增强主题分配
- en: Let’s refactor the topic assignment since it will be the most common operation
    in our regular process, and it will help us understand how to use LangChain in
    practice.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重构主题分配，因为它将是我们日常流程中最常见的操作，并且将帮助我们了解如何在实践中使用LangChain。
- en: First of all, we need to install the package.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要安装这个包。
- en: '[PRE0]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Loading documents
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载文档
- en: To work with the customers’ reviews, we first need to load them. For that, we
    could use [Document Loaders](https://python.langchain.com/docs/modules/data_connection/document_loaders/).
    In our case, customer reviews are stored as a set of .txt files in a Directory,
    but you can effortlessly load docs from third-party tools. For example, there’s
    an [integration](https://python.langchain.com/docs/integrations/document_loaders/snowflake)
    with Snowflake.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 要处理客户的评论，我们首先需要加载它们。为此，我们可以使用 [文档加载器](https://python.langchain.com/docs/modules/data_connection/document_loaders/)。在我们的案例中，客户评论被存储在一个目录中的一组
    .txt 文件中，但你可以轻松地从第三方工具加载文档。例如，还有一个与 Snowflake 的 [集成](https://python.langchain.com/docs/integrations/document_loaders/snowflake)。
- en: We will use `DirectoryLoader` to load all files in the directory since we have
    separate files from hotels. For each file, we will specify `TextLoader` as a loader
    (by default, a loader for unstructured documents is used). Our files are encoded
    in `ISO-8859–1`, so the default call returns an error. However, LangChain can
    automatically detect used encoding. With such a setup, it works ok.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `DirectoryLoader` 加载目录中的所有文件，因为我们有来自不同酒店的单独文件。对于每个文件，我们将指定 `TextLoader`
    作为加载器（默认情况下，使用用于非结构化文档的加载器）。我们的文件使用 `ISO-8859–1` 编码，因此默认调用会返回错误。然而，LangChain 可以自动检测使用的编码。使用这样的设置，它工作得很好。
- en: '[PRE1]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Splitting documents
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文档分割
- en: Now, we would like to split our documents. We know that each file consists of
    a set of customer comments delimited by `\n`. Since our case is very straightforward,
    we will use the most basic `CharacterTextSplitter` that splits documents by character.
    When working with real documents (whole long texts instead of independent short
    comments), it’s better to use [Recursive split by character](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter)
    since it allows you to split documents into chunks smarter.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们希望分割我们的文档。我们知道每个文件由一组以 `\n` 分隔的客户评论组成。由于我们的案例非常简单，我们将使用最基本的 `CharacterTextSplitter`，按字符分割文档。当处理实际文档（而不是独立的短评论）时，最好使用
    [按字符递归分割](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter)，因为它允许你更智能地将文档分割成块。
- en: However, LangChain is more suited for fuzzy text splitting. So, I had to hack
    it a bit to make it work the way I wanted.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，LangChain 更适合模糊文本分割。因此，我不得不稍微修改它，使其按我想要的方式工作。
- en: 'How it works:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 它是如何工作的：
- en: You specify `chunk_size` and `chunk_overlap`, and it tries to make the minimal
    number of splits so that each chunk is smaller than `chunk_size`. If it fails
    to create a small enough chunk, it prints a message to the Jupyter Notebook output.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你指定 `chunk_size` 和 `chunk_overlap`，它会尽量减少分割次数，以使每个块小于 `chunk_size`。如果无法创建足够小的块，它会在
    Jupyter Notebook 输出中打印一条消息。
- en: If you specify too big `chunk_size`, not all comments will be separated.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你指定的 `chunk_size` 太大，一些评论将不会被分开。
- en: If you specify too small `chunk_size`, you will have print statements for each
    comment in your output, leading to the Notebook reloading. Unfortunately, I couldn’t
    find any parameters to switch it off.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你指定的 `chunk_size` 太小，你的输出中会为每个评论打印语句，导致 Notebook 重新加载。不幸的是，我找不到任何参数来关闭这个功能。
- en: To overcome this problem, I specified `length_function` as a constant equal
    to `chunk_size`. Then I got just a standard split by character. LangChain provides
    enough flexibility to do what you want, but only in a somewhat hacky way.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我将 `length_function` 指定为等于 `chunk_size` 的常量。然后我得到了标准的按字符分割。LangChain
    提供了足够的灵活性来实现你的需求，但只有以一种有点 hacky 的方式。
- en: '[PRE2]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Also, let’s add the document ID to the metadata — we will use it later.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，让我们将文档 ID 添加到元数据中——我们稍后会用到它。
- en: '[PRE3]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The advantage of using Documents is that we now have automatic data sources
    and can filter data by it. For example, we can filter only comments related to
    Travelodge Hotel.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 使用文档的优点在于我们现在拥有了自动数据源，并且可以根据它来过滤数据。例如，我们可以仅过滤与 Travelodge Hotel 相关的评论。
- en: '[PRE4]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Next, we need a model. As we discussed earlier in LangChain, there are LLMs
    and Chat Models. The main difference is that LLMs take texts and return texts,
    while Chat Models are more suitable for conversational use cases and can get a
    set of messages as input. In our case, we will use the ChatModel for OpenAI since
    we would like to pass system messages as well.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要一个模型。正如我们之前在 LangChain 中讨论的那样，有 LLMs 和聊天模型。主要区别在于 LLMs 接受文本并返回文本，而聊天模型更适合对话式用例，可以将一组消息作为输入。在我们的案例中，我们将使用
    OpenAI 的 ChatModel，因为我们也希望传递系统消息。
- en: '[PRE5]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Prompts
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示
- en: Let’s move on to the most important part — our prompt. In LangChain, there’s
    a concept of Prompt Templates. They help to reuse prompts parametrised by variables.
    It’s helpful since, in real-life applications, prompts might be very detailed
    and sophisticated. So, prompt templates can be a useful high-level abstraction
    that would help you to manage your code effectively.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进入最重要的部分——我们的提示。在LangChain中，有一个提示模板的概念。它们帮助重复使用由变量参数化的提示。这很有帮助，因为在实际应用中，提示可能非常详细和复杂。因此，提示模板可以成为一种有用的高级抽象，帮助你有效地管理代码。
- en: Since we are going to use the Chat Model, we will need [ChatPromptTemplate.](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/#chatprompttemplate)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将使用聊天模型，我们需要[ChatPromptTemplate.](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/#chatprompttemplate)
- en: But before jumping into prompts, let’s briefly discuss a helpful feature — an
    output parser. Surprisingly, they can help us to create an effective prompt. We
    can define the desired output, generate an output parser and then use the parser
    to create instructions for the prompt.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 但在深入探讨提示之前，让我们简要讨论一个有用的功能——输出解析器。令人惊讶的是，它们可以帮助我们创建一个有效的提示。我们可以定义所需的输出，生成一个输出解析器，然后使用该解析器为提示创建指令。
- en: 'Let’s define what we would like to see in the output. First, we would like
    to be able to pass a list of customer reviews to the prompt to process them in
    batches, so in the result, we would like to get a list with the following parameters:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一下我们希望在输出中看到的内容。首先，我们希望能够将客户评论的列表传递给提示，以批量处理它们，因此在结果中，我们希望得到一个具有以下参数的列表：
- en: id to identify documents,
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于识别文档的ID，
- en: list of topics from the predefined list (we will be using the list from our
    previous iteration),
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从预定义列表中获取主题列表（我们将使用我们上一个迭代中的列表），
- en: sentiment (negative, neutral or positive).
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 情感（负面、中性或正面）。
- en: Let’s specify our output parser. Since we need a pretty complex JSON structure,
    we will use [Pydantic Output Parser](https://python.langchain.com/docs/modules/model_io/output_parsers/pydantic)
    instead of the most commonly used [Structured Output Parser](https://python.langchain.com/docs/modules/model_io/output_parsers/structured).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们指定我们的输出解析器。由于我们需要一个相当复杂的JSON结构，我们将使用[Pydantic Output Parser](https://python.langchain.com/docs/modules/model_io/output_parsers/pydantic)而不是最常用的[Structured
    Output Parser](https://python.langchain.com/docs/modules/model_io/output_parsers/structured)。
- en: For that, we need to create a class inherited from `BaseModel` and specify all
    fields we need with names and descriptions (so that LLM could understand what
    we expect in the response).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们需要创建一个继承自`BaseModel`的类，并指定我们所需的所有字段及其名称和描述（以便LLM可以理解我们对响应的期望）。
- en: '[PRE6]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now, we could use this parser to generate formatting instructions for our prompt.
    That’s a fantastic case when you could use prompting best practices and spend
    less time on prompt engineering.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用这个解析器为我们的提示生成格式化指令。这是一个绝佳的例子，展示了如何使用提示最佳实践，从而减少提示工程的时间。
- en: '[PRE7]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/223f83dd83f0e516f1a09c0acbc47478.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/223f83dd83f0e516f1a09c0acbc47478.png)'
- en: 'Then, it’s time to move on to our prompt. We took a batch of comments and formatted
    them into the expected format. Then, we created a prompt message with a bunch
    of variables: `topics_descr_list`, `format_instructions` and `input_data`. After
    that, we created chat prompt messages consisting of a constant system message
    and a prompt message. The last step is to format chat prompt messages with actual
    values.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，进入我们的提示部分。我们取了一批评论并将其格式化为预期格式。接着，我们创建了一个包含多个变量的提示消息：`topics_descr_list`、`format_instructions`和`input_data`。之后，我们创建了由一个常量系统消息和一个提示消息组成的聊天提示消息。最后一步是用实际值格式化聊天提示消息。
- en: '[PRE8]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '{input_data}'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '{input_data}'
- en: '[PRE9]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now, we can pass these formatted messages to LLM and see a response.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以将这些格式化的消息传递给LLM，并查看响应。
- en: '[PRE10]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](../Images/19c75f5b1930416d6db2123198a6c974.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/19c75f5b1930416d6db2123198a6c974.png)'
- en: We got the response as a string object, but we could leverage our parser and
    get the list of `CustomerCommentData` class objects as a result.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了一个字符串对象的响应，但我们可以利用我们的解析器，将其结果转换为一组`CustomerCommentData`类对象。
- en: '[PRE11]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/39bbe90b0978935dfefd2f9ffe552981.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/39bbe90b0978935dfefd2f9ffe552981.png)'
- en: So, we’ve leveraged LangChain and some of its features and have already built
    a bit smarter solution that could assign topics to the comments in batches (it
    would save us some costs) and started to define not only topics but also sentiment.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们利用了LangChain及其一些功能，已经构建了一个更智能的解决方案，可以将主题分配给批量评论（这将节省我们的成本），并开始定义不仅仅是主题，还有情感。
- en: Adding more logic
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加更多逻辑
- en: So far, we’ve built only single LLM calls without any relations and sequencing.
    However, in real life, we often want to split our tasks into multiple steps. For
    that, we can use Chains. Chain is the fundamental building block for LangChain.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只构建了没有任何关系和顺序的单一LLM调用。然而，在现实生活中，我们通常希望将任务拆分成多个步骤。为此，我们可以使用链。链是LangChain的基本构建块。
- en: LLMChain
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLMChain
- en: The most basic type of chain is an LLMChain. It is a combination of LLM and
    prompt.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 最基本的链类型是LLMChain。它是LLM和提示的组合。
- en: So we can rewrite our logic into a chain. This code will give us absolutely
    the same result as before, but it’s pretty convenient to have one method that
    defines it all.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们可以将我们的逻辑重写成一个链。这段代码将给我们与之前完全相同的结果，但拥有一个定义所有内容的方法是非常方便的。
- en: '[PRE12]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Sequential Chains
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 顺序链
- en: LLM chain is very basic. The power of chains is in building more complex logic.
    Let’s try to create something more advanced.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: LLM链非常基础。链的力量在于构建更复杂的逻辑。让我们尝试创建一些更高级的东西。
- en: The idea of [sequential chains](https://python.langchain.com/docs/modules/chains/foundational/sequential_chains)
    is to use the output of one chain as the input for another.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[顺序链](https://python.langchain.com/docs/modules/chains/foundational/sequential_chains)的理念是将一个链的输出用作另一个链的输入。'
- en: For defining chains, we will be using [LCEL](https://python.langchain.com/docs/expression_language)
    (LangChain Expression Language). This new language was introduced just a couple
    of months ago, and now all the old approaches with `SimpleSequentialChain` or
    `SequentialChain` are considered legacy. So, it’s worth spending some time understanding
    the LCEL concept.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义链时，我们将使用[LCEL](https://python.langchain.com/docs/expression_language)（LangChain表达语言）。这种新语言刚刚推出几个月，现在所有旧的`SimpleSequentialChain`或`SequentialChain`方法都被视为遗留方法。因此，花时间了解LCEL的概念是值得的。
- en: Let’s rewrite the previous chain in LCEL.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用LCEL重写之前的链。
- en: '[PRE13]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: If you want to learn it first-hand, I suggest you watch [this video](https://www.youtube.com/watch?v=9M8x485j_lU)
    about LCEL from the LangChain team.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想亲身体验，建议你观看[这个视频](https://www.youtube.com/watch?v=9M8x485j_lU)，了解LangChain团队讲解的LCEL。
- en: Using sequential chains
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用顺序链
- en: In some cases, it might be helpful to have [several sequential calls](https://python.langchain.com/docs/expression_language/cookbook/multiple_chains)
    so that the output of one chain is used in the other ones.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，拥有[多个顺序调用](https://python.langchain.com/docs/expression_language/cookbook/multiple_chains)可能会很有帮助，以便将一个链的输出用作其他链的输入。
- en: In our case, we can first translate reviews into English and then do topic modelling
    and sentiment analysis.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，我们可以先将评论翻译成英语，然后进行主题建模和情感分析。
- en: '![](../Images/685f59a665a81ef918b94ae53fa56394.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/685f59a665a81ef918b94ae53fa56394.png)'
- en: '[PRE14]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '{input_data}'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '{input_data}'
- en: '[PRE15]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '{translated_data}'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '{translated_data}'
- en: '[PRE16]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We similarly defined prompt templates for translation and topic assignment.
    Then, we determined the translation chain. The only new thing here is the usage
    of `StrOutputParser()`, which converts response objects into strings (no rocket
    science).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们类似地为翻译和主题分配定义了提示模板。然后，我们确定了翻译链。这里唯一的新事物是`StrOutputParser()`的使用，它将响应对象转换为字符串（没什么高深的技术）。
- en: Then, we defined the full chain, specifying the input parameters, prompt template
    and LLM. For input parameters, we took `translated_data` from the output of `translate_chain`
    while other parameters from the invoke input using the `itemgetter` function.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们定义了完整的链，指定了输入参数、提示模板和LLM。对于输入参数，我们从`translate_chain`的输出中获取`translated_data`，而其他参数则使用`itemgetter`函数从调用输入中提取。
- en: However, in our case, such an approach with a combined chain might not be so
    convenient since we would like to save the output of the first chain as well to
    have translated values.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在我们的情况下，使用组合链可能不是那么方便，因为我们还希望保存第一个链的输出以获得翻译值。
- en: With chains, everything becomes a bit more convoluted so that we might need
    some debugging capabilities. There are two options for debugging.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 使用链时，一切变得有些复杂，我们可能需要一些调试功能。调试有两个选项。
- en: The first one is that you can switch on debugging locally.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个选项是你可以在本地启用调试。
- en: '[PRE17]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The other option is to use the LangChain platform — [LangSmith](https://blog.langchain.dev/announcing-langsmith/).
    However, it’s still in beta-tester mode, so you might need to wait to get access.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选择是使用LangChain平台 — [LangSmith](https://blog.langchain.dev/announcing-langsmith/)。不过，它仍处于测试阶段，所以你可能需要等待才能获得访问权限。
- en: Routing
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 路由
- en: 'One of the most complex cases of chains is [routing](https://python.langchain.com/docs/expression_language/how_to/routing)
    when you use different prompts for different use cases. For example, we could
    save different customer review parameters depending on the sentiment:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 链中最复杂的案例之一是[路由](https://python.langchain.com/docs/expression_language/how_to/routing)，当你为不同的用例使用不同的提示时。例如，我们可以根据情感保存不同的客户评论参数：
- en: If the comment is negative, we will store the list of problems mentioned by
    the customer.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果评论是负面的，我们将存储客户提到的问题列表。
- en: Otherwise, we will get the list of good points from the review.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 否则，我们将从评论中获得好点的列表。
- en: To use a routing chain, we will need to pass comments one by one instead of
    batching them as we did before.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用路由链，我们需要逐个传递评论，而不是像以前那样批量处理。
- en: So our chain on a high level will look like this.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们高层的链将会是这样的。
- en: '![](../Images/99a869839ba12e1e401eca16ab094b04.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/99a869839ba12e1e401eca16ab094b04.png)'
- en: First, we need to define the main chain that determines the sentiment. This
    chain consists of prompt, LLM and already familiar `StrOutputParser()`.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要定义主要的链来确定情感。这条链由提示、LLM和已经熟悉的`StrOutputParser()`组成。
- en: '[PRE18]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '{input_data}'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '{input_data}'
- en: '[PRE19]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: For positive reviews, we will ask the model to extract good points, while for
    negative ones — problems. So, we will need two different chains.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 对于正面评论，我们将要求模型提取好点，而对于负面评论 — 问题。所以，我们将需要两个不同的链。
- en: We will use the same Pydantic output parsers as before to specify the intended
    output format and generate instructions.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与以前相同的Pydantic输出解析器来指定预期的输出格式并生成指令。
- en: We used `partial_variables` on top of the general topic assignment prompt message
    to specify different format instructions for positive and negative cases.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在通用主题分配提示消息上使用了`partial_variables`来为正面和负面案例指定不同的格式说明。
- en: '[PRE20].'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE20].'
- en: Please, analyse the provided review and identify the main topics and sentiment.
    Include only topics from the provided below list.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 请分析提供的评论，并识别主要主题和情感。仅包括下列列表中的主题。
- en: 'List of topics with descriptions (delimited with ":"):'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 带有描述的主题列表（用“:”分隔）：
- en: '{topics_descr_list}'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '{topics_descr_list}'
- en: 'Output format:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 输出格式：
- en: '{format_instructions}'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '{format_instructions}'
- en: 'Customer reviews:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 客户评论：
- en: '[PRE21]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: ''''''''
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: ''''''''
- en: defining prompt templates
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义提示模板
- en: positive_topic_assignment_template = ChatPromptTemplate(
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: positive_topic_assignment_template = ChatPromptTemplate(
- en: messages=[
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: messages=[
- en: SystemMessagePromptTemplate.from_template("You're a helpful assistant. Your
    task is to analyse hotel reviews."),
  id: totrans-156
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: SystemMessagePromptTemplate.from_template("你是一个有帮助的助手。你的任务是分析酒店评论。"),
- en: HumanMessagePromptTemplate.from_template(general_topic_assignment_msg)
  id: totrans-157
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: HumanMessagePromptTemplate.from_template(general_topic_assignment_msg)
- en: '],'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '],'
- en: input_variables=["topics_descr_list", "input_data"],
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: input_variables=["topics_descr_list", "input_data"],
- en: 'partial_variables={"format_instructions": positive_format_instructions} )'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'partial_variables={"format_instructions": positive_format_instructions} )'
- en: negative_topic_assignment_template = ChatPromptTemplate(
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: negative_topic_assignment_template = ChatPromptTemplate(
- en: messages=[
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: messages=[
- en: SystemMessagePromptTemplate.from_template("You're a helpful assistant. Your
    task is to analyse hotel reviews."),
  id: totrans-163
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: SystemMessagePromptTemplate.from_template("你是一个有帮助的助手。你的任务是分析酒店评论。"),
- en: HumanMessagePromptTemplate.from_template(general_topic_assignment_msg)
  id: totrans-164
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: HumanMessagePromptTemplate.from_template(general_topic_assignment_msg)
- en: '],'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '],'
- en: input_variables=["topics_descr_list", "input_data"],
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: input_variables=["topics_descr_list", "input_data"],
- en: 'partial_variables={"format_instructions": negative_format_instructions} )'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'partial_variables={"format_instructions": negative_format_instructions} )'
- en: '[PRE22]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: from langchain.schema.runnable import RunnableBranch
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain.schema.runnable import RunnableBranch
- en: branch = RunnableBranch(
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: branch = RunnableBranch(
- en: '(lambda x: "negative" in x["sentiment"].lower(), negative_chain),'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '(lambda x: "negative" in x["sentiment"].lower(), negative_chain),'
- en: positive_chain
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: positive_chain
- en: )
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: full_route_chain = {
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: full_route_chain = {
- en: '"sentiment": sentiment_chain,'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"sentiment": sentiment_chain,'
- en: '"input_data": lambda x: x["input_data"],'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"input_data": lambda x: x["input_data"],'
- en: '"topics_descr_list": lambda x: x["topics_descr_list"]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"topics_descr_list": lambda x: x["topics_descr_list"]'
- en: '} | branch'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '} | branch'
- en: 'full_route_chain.invoke({''input_data'': review,'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 'full_route_chain.invoke({''input_data'': review,'
- en: '''topics_descr_list'': topics_list})'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '''topics_descr_list'': topics_list})'
- en: '[PRE23]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: from langchain.evaluation import ExactMatchStringEvaluator
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain.evaluation import ExactMatchStringEvaluator
- en: evaluator = ExactMatchStringEvaluator(
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: evaluator = ExactMatchStringEvaluator(
- en: ignore_case=True,
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ignore_case=True,
- en: ignore_numbers=True,
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ignore_numbers=True,
- en: ignore_punctuation=True,
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ignore_punctuation=True,
- en: )
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: evaluator.evaluate_strings(
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: evaluator.evaluate_strings(
- en: prediction="positive.",
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: prediction="positive.",
- en: reference="Positive"
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: reference="Positive"
- en: )
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: '{''score'': 1}'
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '{''score'': 1}'
- en: evaluator.evaluate_strings(
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: evaluator.evaluate_strings(
- en: prediction="negative",
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: prediction="negative",
- en: reference="Positive"
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: reference="Positive"
- en: )
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: '{''score'': 0}'
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '{''score'': 0}'
- en: '[PRE24]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: from langchain.evaluation import load_evaluator
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain.evaluation import load_evaluator
- en: from langchain.evaluation import EmbeddingDistance
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain.evaluation import EmbeddingDistance
- en: evaluator = load_evaluator(
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: evaluator = load_evaluator(
- en: '"embedding_distance", distance_metric=EmbeddingDistance.EUCLIDEAN'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"embedding_distance", distance_metric=EmbeddingDistance.EUCLIDEAN'
- en: )
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: evaluator.evaluate_strings(
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: evaluator.evaluate_strings(
- en: prediction="well designed rooms, clean, great location",
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: prediction="设计良好的房间，干净，位置优越",
- en: reference="well designed rooms, clean, great location, good atmosphere"
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: reference="设计良好的房间，干净，位置优越，氛围很好"
- en: )
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: '{''score'': 0.20732719121627757}'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '{''score'': 0.20732719121627757}'
- en: '[PRE25]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: from langchain.evaluation import Criteria
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain.evaluation import Criteria
- en: list(Criteria)
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: list(Criteria)
- en: '[<Criteria.CONCISENESS: ''conciseness''>,'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '[<Criteria.CONCISENESS: ''简洁性''>,'
- en: '<Criteria.RELEVANCE: ''relevance''>,'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '<Criteria.RELEVANCE: ''相关性''>,'
- en: '<Criteria.CORRECTNESS: ''correctness''>,'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '<Criteria.CORRECTNESS: ''正确性''>,'
- en: '<Criteria.COHERENCE: ''coherence''>,'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '<Criteria.COHERENCE: ''连贯性''>,'
- en: '<Criteria.HARMFULNESS: ''harmfulness''>,'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '<Criteria.HARMFULNESS: ''有害性''>,'
- en: '<Criteria.MALICIOUSNESS: ''maliciousness''>,'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '<Criteria.MALICIOUSNESS: ''恶意''>,'
- en: '<Criteria.HELPFULNESS: ''helpfulness''>,'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '<Criteria.HELPFULNESS: ''有用性''>,'
- en: '<Criteria.CONTROVERSIALITY: ''controversiality''>,'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '<Criteria.CONTROVERSIALITY: ''争议性''>,'
- en: '<Criteria.MISOGYNY: ''misogyny''>,'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '<Criteria.MISOGYNY: ''厌女''>,'
- en: '<Criteria.CRIMINALITY: ''criminality''>,'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '<Criteria.CRIMINALITY: ''犯罪性''>,'
- en: '<Criteria.INSENSITIVITY: ''insensitivity''>,'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '<Criteria.INSENSITIVITY: ''不敏感性''>,'
- en: '<Criteria.DEPTH: ''depth''>,'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '<Criteria.DEPTH: ''深度''>,'
- en: '<Criteria.CREATIVITY: ''creativity''>,'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '<Criteria.CREATIVITY: ''创造力''>,'
- en: '<Criteria.DETAIL: ''detail''>]'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '<Criteria.DETAIL: ''细节''>]'
- en: '[PRE26]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: evaluator = load_evaluator("criteria", criteria="conciseness")
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: evaluator = load_evaluator("criteria", criteria="简洁性")
- en: eval_result = evaluator.evaluate_strings(
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: eval_result = evaluator.evaluate_strings(
- en: prediction="well designed rooms, clean, great location",
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: prediction="设计良好的房间，干净，位置优越",
- en: input="List the good points that customer mentioned",
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: input="列出客户提到的优点",
- en: )
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: '[PRE27]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: evaluator = load_evaluator("labeled_criteria", criteria="correctness")
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: evaluator = load_evaluator("labeled_criteria", criteria="正确性")
- en: eval_result = evaluator.evaluate_strings(
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: eval_result = evaluator.evaluate_strings(
- en: prediction="well designed rooms, clean, great location",
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: prediction="设计良好的房间，干净，位置优越",
- en: input="List the good points that customer mentioned",
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: input="列出客户提到的优点",
- en: reference="well designed rooms, clean, great location, good atmosphere",
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: reference="设计良好的房间，干净，位置优越，氛围很好",
- en: )
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: '[PRE28]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'custom_criterion = {"multiple": "Does the output contain multiple points?"}'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 'custom_criterion = {"multiple": "输出是否包含多个点？"}'
- en: evaluator = load_evaluator("criteria", criteria=custom_criterion)
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: evaluator = load_evaluator("criteria", criteria=custom_criterion)
- en: eval_result = evaluator.evaluate_strings(
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: eval_result = evaluator.evaluate_strings(
- en: prediction="well designed rooms, clean, great location",
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: prediction="设计良好的房间，干净，位置优越",
- en: input="List the good points that customer mentioned",
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: input="列出客户提到的优点",
- en: )
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: '[PRE29]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: from langchain.chat_models import ChatOpenAI
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain.chat_models import ChatOpenAI
- en: accuracy_criteria = {
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: accuracy_criteria = {
- en: '"accuracy": """'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"accuracy": """'
- en: 'Score 1: The answer doesn''t mention any relevant points.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '分数 1: 答案没有提到任何相关点。'
- en: 'Score 3: The answer mentions only few of relevant points but have major inaccuracies
    or includes several not relevant options.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '分数 3: 答案只提到了一些相关点，但有重大不准确或包含几个不相关选项。'
- en: 'Score 5: The answer has moderate quantity of relevant options but might have
    inaccuracies or wrong points.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '分数 5: 答案有适量相关选项，但可能存在不准确或错误的点。'
- en: 'Score 7: The answer aligns with the reference and shows most of relevant points
    and don''t have completely wrong options mentioned.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '分数 7: 答案与参考一致，展示了大部分相关点，并且没有完全错误的选项。'
- en: 'Score 10: The answer is completely accurate and aligns perfectly with the reference."""'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '分数 10: 答案完全准确，并与参考完全一致。'
- en: '}'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: evaluator = load_evaluator(
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: evaluator = load_evaluator(
- en: '"labeled_score_string",'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"labeled_score_string",'
- en: criteria=accuracy_criteria,
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: criteria=accuracy_criteria,
- en: llm=ChatOpenAI(model="gpt-4"),
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: llm=ChatOpenAI(model="gpt-4"),
- en: )
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: eval_result = evaluator.evaluate_strings(
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: eval_result = evaluator.evaluate_strings(
- en: prediction="well designed rooms, clean, great location",
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: prediction="设计良好的房间，干净，位置优越",
- en: input="""Below is a customer review delimited by [PRE30]
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: input="""以下是由[PRE30]限定的客户评论
- en: Small but well designed rooms, clean, great location, good atmosphere. I would
    stay there again. Continental breakfast is weak but ok.
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 小而设计良好的房间，干净，位置优越，氛围很好。我会再次入住。欧式早餐一般但可以接受。
- en: '[PRE31]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '![](../Images/9a85f3ea6a6ec65b20ef73b036dec829.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9a85f3ea6a6ec65b20ef73b036dec829.png)'
- en: We got seven as a score, which looks pretty valid. Let’s look at the actual
    prompt used.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了七分，这看起来很有效。让我们看看实际使用的提示。
- en: '![](../Images/95be175868f753919929dd772eed5abe.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/95be175868f753919929dd772eed5abe.png)'
- en: However, I would treat scores from LLMs with a pinch of salt. Remember, it’s
    not a regression function, and scores might be pretty subjective.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，我会对 LLM 的分数持保留态度。记住，这不是一个回归函数，分数可能相当主观。
- en: We’ve been using the scoring model with the reference. But in many cases, we
    might not have the correct answers, or it could be expensive for us to get them.
    You can use the scoring evaluator even without reference scores asking the model
    to assess the answer. It’s worth using GPT-4 to be more confident in the results.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一直在使用带有参考的评分模型。但在许多情况下，我们可能没有正确的答案，或者获取答案的成本可能很高。即使没有参考评分，你也可以使用评分评估器让模型评估答案。使用
    GPT-4 以获得更有信心的结果是值得的。
- en: '[PRE32]. Provide the list the good points that customer mentioned in the customer
    review.'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE32]。提供客户在评价中提到的优点列表。'
- en: 'Customer review:'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 客户评价：
- en: '[PRE33]'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '"""'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"""'
- en: )
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: '```'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '```'
- en: '![](../Images/1afcfe80ddb39f4c0a6255e0ef3a574a.png)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1afcfe80ddb39f4c0a6255e0ef3a574a.png)'
- en: We got a pretty close score to the previous one.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了与之前相当接近的分数。
- en: We’ve looked at quite a lot of possible ways to validate your output, so I hope
    you are now ready to test your models’ results.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探讨了很多可能的方式来验证你的输出，所以希望你现在已经准备好测试你的模型结果。
- en: Summary
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this article, we’ve discussed some nuances we need to take into account if
    we want to use LLMs for production processes.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们讨论了一些如果我们想要将 LLM 用于生产过程时需要考虑的细微差别。
- en: We’ve looked at the use of the LangChain framework to make our solution more
    modular so that we could easily iterate and use new approaches (for example, switching
    from one LLM to another). Also, frameworks usually help to make our code easier
    to maintain.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们探讨了使用 LangChain 框架使我们的解决方案更加模块化，以便我们可以轻松地迭代并使用新方法（例如，从一种 LLM 切换到另一种）。此外，框架通常有助于使我们的代码更易于维护。
- en: The other big topic we’ve discussed is the different tools we have to assess
    the model’s performance. If we are using LLMs in production, we need to have some
    constant monitoring in place to ensure the quality of our service, and it’s worth
    spending some time to create an evaluation pipeline based on LLMs or human-in-the-loop.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们讨论的另一个重要话题是评估模型性能的不同工具。如果我们在生产中使用 LLM，我们需要进行一些持续监控，以确保服务质量，并且值得花些时间基于 LLM
    或人机协作创建评估流程。
- en: Thank you a lot for reading this article. I hope it was insightful to you. If
    you have any follow-up questions or comments, please leave them in the comments
    section.
  id: totrans-284
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 非常感谢你阅读本文。希望它对你有启发。如果你有任何后续问题或评论，请在评论区留言。
- en: Dataset
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集
- en: '*Ganesan, Kavita and Zhai, ChengXiang. (2011). OpinRank Review Dataset.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '*Ganesan, Kavita 和 Zhai, ChengXiang. (2011). OpinRank 评价数据集。'
- en: UCI Machine Learning Repository.* [*https://doi.org/10.24432/C5QW4W*](https://doi.org/10.24432/C5QW4W.)
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: UCI 机器学习库。*[https://doi.org/10.24432/C5QW4W](https://doi.org/10.24432/C5QW4W)*
- en: Reference
  id: totrans-288
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考
- en: This article is based on information from the course [“LangChain for LLM Application
    Development”](https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/)
    by DeepLearning.AI and LangChain.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 本文基于 DeepLearning.AI 和 LangChain 的课程 [“LangChain for LLM Application Development”](https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/)。
