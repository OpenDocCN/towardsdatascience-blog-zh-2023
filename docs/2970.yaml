- en: Redefining Conversational AI with Large Language Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过大型语言模型重新定义对话式人工智能
- en: 原文：[https://towardsdatascience.com/redefining-conversational-ai-with-large-language-models-1ded152c3398?source=collection_archive---------1-----------------------#2023-09-28](https://towardsdatascience.com/redefining-conversational-ai-with-large-language-models-1ded152c3398?source=collection_archive---------1-----------------------#2023-09-28)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/redefining-conversational-ai-with-large-language-models-1ded152c3398?source=collection_archive---------1-----------------------#2023-09-28](https://towardsdatascience.com/redefining-conversational-ai-with-large-language-models-1ded152c3398?source=collection_archive---------1-----------------------#2023-09-28)
- en: A guide to implementing conversational AI for a unified user experience
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现对话式人工智能以提供统一用户体验的指南
- en: '[](https://medium.com/@janna.lipenkova_52659?source=post_page-----1ded152c3398--------------------------------)[![Dr.
    Janna Lipenkova](../Images/112fe9a8c5936869243f2a43fde6dfee.png)](https://medium.com/@janna.lipenkova_52659?source=post_page-----1ded152c3398--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1ded152c3398--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1ded152c3398--------------------------------)
    [Dr. Janna Lipenkova](https://medium.com/@janna.lipenkova_52659?source=post_page-----1ded152c3398--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@janna.lipenkova_52659?source=post_page-----1ded152c3398--------------------------------)[![Dr.
    Janna Lipenkova](../Images/112fe9a8c5936869243f2a43fde6dfee.png)](https://medium.com/@janna.lipenkova_52659?source=post_page-----1ded152c3398--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1ded152c3398--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1ded152c3398--------------------------------)
    [Dr. Janna Lipenkova](https://medium.com/@janna.lipenkova_52659?source=post_page-----1ded152c3398--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff215f8e427a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fredefining-conversational-ai-with-large-language-models-1ded152c3398&user=Dr.+Janna+Lipenkova&userId=f215f8e427a2&source=post_page-f215f8e427a2----1ded152c3398---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1ded152c3398--------------------------------)
    ·21 min read·Sep 28, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1ded152c3398&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fredefining-conversational-ai-with-large-language-models-1ded152c3398&user=Dr.+Janna+Lipenkova&userId=f215f8e427a2&source=-----1ded152c3398---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff215f8e427a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fredefining-conversational-ai-with-large-language-models-1ded152c3398&user=Dr.+Janna+Lipenkova&userId=f215f8e427a2&source=post_page-f215f8e427a2----1ded152c3398---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1ded152c3398--------------------------------)
    · 21分钟阅读 · 2023年9月28日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1ded152c3398&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fredefining-conversational-ai-with-large-language-models-1ded152c3398&user=Dr.+Janna+Lipenkova&userId=f215f8e427a2&source=-----1ded152c3398---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1ded152c3398&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fredefining-conversational-ai-with-large-language-models-1ded152c3398&source=-----1ded152c3398---------------------bookmark_footer-----------)![](../Images/32544267351219a9d654d0c06f717155.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1ded152c3398&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fredefining-conversational-ai-with-large-language-models-1ded152c3398&source=-----1ded152c3398---------------------bookmark_footer-----------)![](../Images/32544267351219a9d654d0c06f717155.png)'
- en: 'Source: [rawpixel.com](https://www.rawpixel.com/image/7665902/robert-delaunay-rythme-joie-vivre)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [rawpixel.com](https://www.rawpixel.com/image/7665902/robert-delaunay-rythme-joie-vivre)'
- en: Conversational AI is an application of LLMs that has triggered a lot of buzz
    and attention due to its scalability across many industries and use cases. While
    conversational systems have existed for decades, LLMs have brought the quality
    push that was needed for their large-scale adoption. In this article, we will
    use the mental model shown in Figure 1 to dissect conversational AI applications
    (cf. [**Building AI products with a holistic mental model**](https://medium.com/towards-data-science/building-ai-products-with-a-holistic-mental-model-33f8729e3ad9)for
    an introduction to the mental model). After considering the market opportunities
    and the business value of conversational AI systems, we will explain the additional
    “machinery” in terms of data, LLM fine-tuning, and conversational design that
    needs to be set up to make conversations not only possible but also useful and
    enjoyable.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对话式人工智能是大型语言模型（LLMs）的一种应用，因其在多个行业和用例中的可扩展性而引发了大量关注。尽管对话式系统已经存在了几十年，但LLMs带来了大规模应用所需的质量提升。在本文中，我们将使用图
    1 所示的心理模型来剖析对话式人工智能应用（参见 [**用整体心理模型构建 AI 产品**](https://medium.com/towards-data-science/building-ai-products-with-a-holistic-mental-model-33f8729e3ad9)以了解心理模型）。在考虑了对话式人工智能系统的市场机会和商业价值之后，我们将解释需要设置的额外“机制”，包括数据、LLM
    微调和对话设计，以使对话不仅成为可能，而且有用和愉悦。
- en: '![](../Images/4a49a8b61f07d46f32988551caf4e98b.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4a49a8b61f07d46f32988551caf4e98b.png)'
- en: 'Figure 1: Mental model of an AI system (cf. [**Building AI products with a
    holistic mental model**](https://medium.com/towards-data-science/building-ai-products-with-a-holistic-mental-model-33f8729e3ad9)**)**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：AI 系统的心理模型（参见 [**用整体心理模型构建 AI 产品**](https://medium.com/towards-data-science/building-ai-products-with-a-holistic-mental-model-33f8729e3ad9)**)**
- en: 1\. Opportunity, value, and limitations
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 机会、价值和局限
- en: Traditional UX design is built around a multitude of artificial UX elements,
    swipes, taps, and clicks, requiring a learning curve for each new app. Using conversational
    AI, we can do away with this busyness, substituting it with the elegant experience
    of a naturally flowing conversation in which we can forget about the transitions
    between different apps, windows, and devices. We use language, our universal and
    familiar protocol for communication, to interact with different virtual assistants
    (VAs) and accomplish our tasks.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的用户体验（UX）设计围绕着大量的人工UX元素、滑动、点击和触碰展开，这要求每个新应用都有一个学习曲线。通过使用对话式人工智能，我们可以摆脱这些繁琐的操作，代之以自然流畅对话的优雅体验，这样我们可以忘记不同应用、窗口和设备之间的过渡。我们使用语言——我们通用且熟悉的沟通协议——与不同的虚拟助手（VAs）互动并完成任务。
- en: Conversational UIs are not exactly the new hot stuff. Interactive voice response
    systems (IVRs) and chatbots have been around since the 1990s, and major advances
    in NLP have been closely followed by waves of hope and development for voice and
    chat interfaces. However, before the time of LLMs, most of the systems were implemented
    in the symbolic paradigm, relying on rules, keywords, and conversational patterns.
    They were also limited to a specific, pre-defined domain of “competence”, and
    users venturing outside of these would soon hit a dead end. All in all, these
    systems were mined with potential points of failure, and after a couple of frustrating
    attempts, many users never came back to them. The following figure illustrates
    an example dialogue. A user who wants to order tickets for a specific concert
    patiently goes through a detailed interrogation flow, only to find out at the
    end that the concert is sold out.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 对话式用户界面（UI）并不是全新的热门事物。交互式语音响应系统（IVRs）和聊天机器人自1990年代以来就已经存在，而自然语言处理（NLP）的重大进展也一直伴随着语音和聊天界面的希望和发展浪潮。然而，在大型语言模型（LLMs）出现之前，大多数系统都是以符号范式实现的，依赖于规则、关键字和对话模式。它们还局限于特定的、预定义的“能力”领域，用户如果超出这些领域很快就会陷入困境。总的来说，这些系统充满了潜在的失败点，在经历了几次令人沮丧的尝试后，许多用户再也没有回到这些系统中。下图展示了一个对话示例。一个希望为特定音乐会订票的用户耐心地经过了一系列详细的询问流程，结果在最后发现音乐会已经售罄。
- en: '![](../Images/d549f3bdf0f405df910d27b880d715c4.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d549f3bdf0f405df910d27b880d715c4.png)'
- en: 'Figure 2: Example of a poor conversation flow'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：糟糕对话流程的示例
- en: 'As an enabling technology, LLMs can take conversational interfaces to new levels
    of quality and user satisfaction. Conversational systems can now display much
    broader world knowledge, linguistic competence, and conversational ability. Leveraging
    pre-trained models, they can also be developed in much shorter timespans since
    the tedious work of compiling rules, keywords, and dialogue flows is now replaced
    by the statistical knowledge of the LLM. Let’s look at two prominent applications
    where conversational AI can provide value at scale:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种赋能技术，LLMs 可以将对话界面提升到新的质量和用户满意度水平。对话系统现在能够展示更广泛的世界知识、语言能力和对话能力。利用预训练模型，它们也可以在更短的时间内开发完成，因为编写规则、关键词和对话流程的繁琐工作现在被LLM的统计知识所取代。让我们来看看两个对话式
    AI 可以大规模提供价值的突出的应用场景：
- en: '**Customer support** and, more generally, applications that are used by a large
    number of users who often make similar requests. Here, the company providing the
    customer support has a clear information advantage over the user and can leverage
    this to create a more intuitive and enjoyable user experience. Consider the case
    of rebooking a flight. For myself, a rather frequent flyer, this is something
    that happens 1–2 times per year. In-between, I tend to forget the details of the
    process, not to speak of the user interface of a specific airline. By contrast,
    the customer support of the airline has rebooking requests at the front and center
    of their operations. Instead of exposing the rebooking process via a complex graphical
    interface, its logic can be “hidden” from customers who contact the support, and
    they can use language as a natural channel to make their rebooking. Of course,
    there will still remain a “long tail” of less familiar requests. For example,
    imagine a spontaneous mood swing that pushes a business customer to add her beloved
    dog as excess baggage to a booked flight. These more individual requests can be
    passed on to human agents or covered via an internal knowledge management system
    connected to the virtual assistant.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户支持**，更一般来说，是那些由大量用户使用的应用，这些用户经常提出类似的请求。在这里，提供客户支持的公司在信息上相对于用户具有明显的优势，可以利用这一点创造出更直观和愉悦的用户体验。以重新预订航班为例。对于我这样一个经常乘坐飞机的人来说，这是一年中会发生1到2次的事情。在这段时间内，我往往会忘记过程的细节，更不用说特定航空公司的用户界面了。相比之下，航空公司的客户支持将重新预订请求置于其操作的核心。与其通过复杂的图形界面展示重新预订过程，不如将其逻辑“隐藏”在联系支持的客户面前，他们可以使用自然语言作为通道来完成重新预订。当然，仍然会有一些较少见的请求。例如，想象一下一个突发的情绪波动使得一位商务客户决定将她心爱的狗作为超额行李添加到已预订的航班中。这些更具个性化的请求可以交给人工客服处理，或通过连接到虚拟助手的内部知识管理系统来解决。'
- en: '**Knowledge management** which is grounded in a large quantity of data. For
    many modern companies, the internal knowledge they accumulate over years of operating,
    iterating, and learning is a core asset and differentiator — if it is stored,
    managed, and accessed in an efficient way. Sitting on a wealth of data that is
    hidden in collaboration tools, internal wikis, knowledge bases, etc., they often
    fail to transform it into actionable knowledge. As employees leave, new employees
    are onboarded, and you never come to finalize that documentation page you started
    three months ago, valuable knowledge falls victim to entropy. It becomes more
    and more difficult to find a way through the internal data labyrinth and get your
    hands on the bits of information required in a specific business situation. This
    leads to huge efficiency losses for knowledge workers. To address this issue,
    we can augment LLMs with semantic search on internal data sources. LLMs allow
    to use natural-language questions instead of complex formal queries to ask questions
    against this database. Users can thus focus on their information needs rather
    than on the structure of the knowledge base or the syntax of a query language
    such as SQL. Being text-based, these systems work with data in a rich semantic
    space, making meaningful connections “under the hood”.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**知识管理**依赖于大量的数据。对于许多现代公司而言，他们在运营、迭代和学习过程中积累的内部知识是一项核心资产和差异化因素——前提是这些知识以高效的方式存储、管理和访问。虽然公司拥有隐藏在协作工具、内部维基、知识库等中的大量数据，但他们常常未能将其转化为可操作的知识。随着员工离职、新员工加入，以及你永远无法完成三个月前开始的文档页面，有价值的知识会受到熵的影响。找到内部数据迷宫中的出路并获取特定业务情境所需的信息变得越来越困难。这导致了知识工作者的巨大效率损失。为了解决这个问题，我们可以通过在内部数据源上增强LLM的语义搜索功能来应对。LLM允许使用自然语言问题而不是复杂的正式查询来对数据库进行提问。这样，用户可以专注于他们的信息需求，而不是知识库的结构或查询语言（如SQL）的语法。由于这些系统是基于文本的，它们在丰富的语义空间中处理数据，在“幕后”进行有意义的连接。'
- en: Beyond these major application areas, there are numerous other applications,
    such as telehealth, mental health assistants, and educational chatbots, that can
    streamline UX and bring value to their users in a faster and more efficient way.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些主要的应用领域，还有许多其他应用，例如远程医疗、心理健康助手和教育聊天机器人，它们可以以更快、更高效的方式优化用户体验并为用户带来价值。
- en: 2\. Data
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 数据
- en: LLMs are originally not trained to engage in fluent small talk or more substantial
    conversations. Rather, they learn to generate the following token at each inference
    step, eventually resulting in a coherent text. This low-level objective is different
    from the challenge of human conversation. Conversation is incredibly intuitive
    for humans, but it gets incredibly complex and nuanced when you want to teach
    a machine to do it. For example, let’s look at the fundamental notion of intents.
    When we use language, we do so for a specific purpose, which is our communicative
    intent — it could be to convey information, socialize, or ask someone to do something.
    While the first two are rather straightforward for an LLM (as long as it has seen
    the required information in the data), the latter is already more challenging.
    Not only does the LLM need to combine and structure the related information in
    a coherent way, but it also needs to set the right emotional tone in terms of
    soft criteria such as formality, creativity, humor, etc. This is a challenge for
    conversational design (cf. section 5), which is closely intertwined with the task
    of creating fine-tuning data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）最初并不是为了进行流畅的小谈话或更深入的对话而训练的。相反，它们在每一步推理中学习生成下一个标记，最终形成连贯的文本。这种低级别的目标与人类对话的挑战不同。对人类来说，对话非常直观，但当你想教会机器做到这一点时，它就变得极其复杂和微妙。例如，让我们来看一下意图的基本概念。当我们使用语言时，我们是为了特定的目的，这就是我们的沟通意图——可能是传达信息、社交或要求别人做某事。前两种目的对LLM来说相对直接（只要它在数据中见过所需的信息），而后者则更具挑战性。LLM不仅需要以连贯的方式组合和组织相关信息，还需要在正式性、创造力、幽默感等软性标准方面设定正确的情感基调。这是对话设计（参见第5节）的挑战，与创建微调数据的任务紧密相关。
- en: Making the transition from classical language generation to recognizing and
    responding to specific communicative intents is an important step toward better
    usability and acceptance of conversational systems. As for all fine-tuning endeavors,
    this starts with the compilation of an appropriate dataset.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 从传统语言生成转向识别和响应特定的交流意图是提升对话系统可用性和接受度的重要步骤。与所有微调工作一样，这从编制适当的数据集开始。
- en: 'The fine-tuning data should come as close as possible to the (future) real-world
    data distribution. First, it should be conversational (dialogue) data. Second,
    if your virtual assistant will be specialized in a specific domain, you should
    try to assemble fine-tuning data that reflects the necessary domain knowledge.
    Third, if there are typical flows and requests that will be recurring frequently
    in your application, as in the case of customer support, try to incorporate varied
    examples of these in your training data. The following table shows a sample of
    conversational fine-tuning data from the [**3K Conversations Dataset for ChatBot**](https://www.kaggle.com/datasets/kreeshrajani/3k-conversations-dataset-for-chatbot),
    which is freely available on Kaggle:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 微调数据应尽可能接近（未来的）实际数据分布。首先，它应该是对话（对话）数据。其次，如果你的虚拟助手将专注于特定领域，你应该尝试组装反映必要领域知识的微调数据。第三，如果你的应用程序中有典型的流程和请求会频繁出现，例如客户支持中的情况，请尽量将这些的多样化示例纳入你的训练数据中。下表显示了来自[**3K
    Conversations Dataset for ChatBot**](https://www.kaggle.com/datasets/kreeshrajani/3k-conversations-dataset-for-chatbot)的对话微调数据示例，该数据集在Kaggle上免费提供：
- en: '![](../Images/894be395f0faa667e41ee18dd2275a0e.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/894be395f0faa667e41ee18dd2275a0e.png)'
- en: 'Table 1: Sample of conversational fine-tuning data from the [3K Conversations
    Dataset for ChatBot](https://www.kaggle.com/datasets/kreeshrajani/3k-conversations-dataset-for-chatbot)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：来自[**3K Conversations Dataset for ChatBot**](https://www.kaggle.com/datasets/kreeshrajani/3k-conversations-dataset-for-chatbot)的对话微调数据示例
- en: Manually creating conversational data can become an expensive undertaking —
    crowdsourcing and using LLMs to help you generate data are two ways to scale up.
    Once the dialogue data is collected, the conversations need to be assessed and
    annotated. This allows you to show both positive and negative examples to your
    model and nudge it towards picking up the characteristics of the “right” conversations.
    The assessment can happen either with absolute scores or a ranking of different
    options between each other. The latter approach leads to more accurate fine-tuning
    data because humans are normally better at ranking multiple options than evaluating
    them in isolation.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 手动创建对话数据可能是一项昂贵的工作——众包和使用LLMs来帮助生成数据是扩展的两种方式。一旦对话数据收集完成，就需要对对话进行评估和注释。这使你能够向模型展示正面和负面的示例，并推动其捕捉到“正确”对话的特征。评估可以通过绝对分数或不同选项之间的排名来进行。后一种方法能够提供更准确的微调数据，因为人类通常更擅长对多个选项进行排名，而不是单独评估它们。
- en: With your data in place, you are ready to fine-tune your model and enrich it
    with additional capabilities. In the next section, we will look at fine-tuning,
    integrating additional information from memory and semantic search, and connecting
    agents to your conversational system to empower it to execute specific tasks.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据就绪后，你可以对模型进行微调，并为其增添额外的功能。在下一节中，我们将探讨微调、从记忆和语义搜索中集成额外信息，以及将代理连接到你的对话系统以使其能够执行特定任务。
- en: 3\. Assembling the conversational system
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 组装对话系统
- en: A typical conversational system is built with a conversational agent that orchestrates
    and coordinates the components and capabilities of the system, such as the LLM,
    the memory, and external data sources. The development of conversational AI systems
    is a highly experimental and empirical task, and your developers will be in a
    constant back-and-forth between optimizing your data, improving the fine-tuning
    strategy, playing with additional components and enhancements, and testing the
    results. Non-technical team members, including product managers and UX designers,
    will also be continuously testing the product. Based on their customer discovery
    activities, they are in a great position to anticipate future users' conversation
    style and content and should be actively contributing this knowledge.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的对话系统由一个协调和组织系统组件和能力的对话代理构建，例如 LLM、内存和外部数据源。对话 AI 系统的开发是一个高度实验性和经验性的任务，你的开发人员将不断在优化数据、改进微调策略、尝试额外组件和增强功能以及测试结果之间反复进行。非技术团队成员，包括产品经理和用户体验设计师，也将持续测试产品。根据他们的客户发现活动，他们能够很好地预测未来用户的对话风格和内容，并应积极贡献这一知识。
- en: 3.1 Teaching conversation skills to your LLM
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3.1 教授你的 LLM 对话技能
- en: For fine-tuning, you need your fine-tuning data (cf. section 2) and a pre-trained
    LLM. LLMs already know a lot about language and the world, and our challenge is
    to teach them the principles of conversation. In fine-tuning, the target outputs
    are texts, and the model will be optimized to generate texts that are as similar
    as possible to the targets. For supervised fine-tuning, you first need to clearly
    define the conversational AI task you want the model to perform, gather the data,
    and run and iterate over the fine-tuning process.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于微调，你需要你的微调数据（参见第 2 节）和一个预训练的 LLM。LLM 已经对语言和世界有很多了解，我们的挑战是教会它们对话的原则。在微调中，目标输出是文本，模型将被优化以生成尽可能与目标相似的文本。对于监督微调，你首先需要清晰定义你希望模型执行的对话
    AI 任务，收集数据，然后运行和迭代微调过程。
- en: With the hype around LLMs, a variety of fine-tuning methods have emerged. For
    a rather traditional example of fine-tuning for conversation, you can refer to
    the description of the LaMDA model.[1] LaMDA was fine-tuned in two steps. First,
    dialogue data is used to teach the model conversational skills (“generative” fine-tuning).
    Then, the labels produced by annotators during the assessment of the data are
    used to train classifiers that can assess the model’s outputs along desired attributes,
    which include sensibleness, specificity, interestingness, and safety (“discriminative”
    fine-tuning). These classifiers are then used to steer the behavior of the model
    towards these attributes.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 随着对 LLM 的炒作，各种微调方法应运而生。对于一个相对传统的对话微调示例，你可以参考 LaMDA 模型的描述。[1] LaMDA 通过两个步骤进行微调。首先，使用对话数据教会模型对话技能（“生成”微调）。然后，使用评估数据时由注释员产生的标签来训练分类器，这些分类器可以评估模型在所需属性（包括合理性、具体性、趣味性和安全性）上的输出。这些分类器随后用于引导模型的行为朝向这些属性。
- en: '![](../Images/0156ee512968f01f0a085c0212aea211.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0156ee512968f01f0a085c0212aea211.png)'
- en: 'Figure 3: LaMDA is fine-tuned in two steps'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：LaMDA 通过两个步骤进行微调
- en: Additionally, factual groundedness — the ability to ground their outputs in
    credible external information — is an important attribute of LLMs. To ensure factual
    groundedness and minimize hallucination, LaMDA was fine-tuned with a dataset that
    involves calls to an external information retrieval system whenever external knowledge
    is required. Thus, the model learned to first retrieve factual information whenever
    the user made a query that required new knowledge.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，事实基础性——将其输出建立在可靠的外部信息上的能力——是 LLM 的一个重要属性。为了确保事实基础性并最小化幻觉，LaMDA 通过一个数据集进行了微调，该数据集涉及在需要外部知识时调用外部信息检索系统。因此，模型学会了在用户提出需要新知识的查询时，首先检索事实信息。
- en: Another popular fine-tuning technique is Reinforcement Learning from Human Feedback
    (RLHF)[2]. RLHF “redirects” the learning process of the LLM from the straightforward
    but artificial next-token prediction task towards learning human preferences in
    a given communicative situation. These human preferences are directly encoded
    in the training data. During the annotation process, humans are presented with
    prompts and either write the desired response or rank a series of existing responses.
    The behavior of the LLM is then optimized to reflect the human preference.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种流行的微调技术是来自人类反馈的强化学习（RLHF）[2]。RLHF “重定向”了大型语言模型（LLM）的学习过程，从简单但人为的下一个词预测任务转向在特定交流情境中学习人类偏好。这些人类偏好直接编码在训练数据中。在标注过程中，人类会收到提示，或者写下期望的回应，或者对一系列现有回应进行排序。然后，LLM
    的行为被优化以反映人类的偏好。
- en: 3.2 Adding external data and semantic search
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3.2 添加外部数据和语义搜索
- en: Beyond compiling conversations for fine-tuning the model, you might want to
    enhance your system with specialized data that can be leveraged during the conversation.
    For example, your system might need access to external data, such as patents or
    scientific papers, or internal data, such as customer profiles or your technical
    documentation. This is normally done via semantic search (also known as retrieval-augmented
    generation, or RAG)[3]. The additional data is saved in a database in the form
    of semantic embeddings (cf. [this article](https://jannalipenkova.com/tpost/7ln0d1jhin-word-embeddings-your-secret-weapon-for-i)
    for an explanation of embeddings and further references). When the user request
    comes in, it is preprocessed and transformed into a semantic embedding. The semantic
    search then identifies the documents that are most relevant to the request and
    uses them as context for the prompt. By integrating additional data with semantic
    search, you can reduce hallucination and provide more useful, factually grounded
    responses. By continuously updating the embedding database, you can also keep
    the knowledge and responses of your system up-to-date without constantly rerunning
    your fine-tuning process.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 除了编译对话用于微调模型之外，你可能还想用可以在对话中利用的专门数据来增强你的系统。例如，你的系统可能需要访问外部数据，如专利或科学论文，或内部数据，如客户档案或你的技术文档。这通常通过语义搜索（也称为检索增强生成，或
    RAG）[3] 完成。额外的数据以语义嵌入的形式保存在数据库中（参见[这篇文章](https://jannalipenkova.com/tpost/7ln0d1jhin-word-embeddings-your-secret-weapon-for-i)以了解嵌入的解释和进一步参考）。当用户请求到来时，它会被预处理并转换为语义嵌入。语义搜索然后识别与请求最相关的文档，并将其作为提示的上下文。通过将额外数据与语义搜索结合，你可以减少幻觉并提供更有用、基于事实的回应。通过不断更新嵌入数据库，你还可以保持系统的知识和回应的最新状态，而不需要不断重新运行微调过程。
- en: 3.3 Memory and context awareness
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3.3 记忆与上下文意识
- en: 'Imagine going to a party and meeting Peter, a lawyer. You get excited and start
    pitching the legal chatbot you are currently planning to build. Peter looks interested,
    leans towards you, uhms and nods. At some point, you want his opinion on whether
    he would like to use your app. Instead of an informative statement that would
    compensate for your eloquence, you hear: “Uhm… what was this app doing again?”'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下你去参加一个派对，遇到了彼得，一位律师。你很兴奋，开始介绍你正在计划构建的法律聊天机器人。彼得看起来很感兴趣，朝你倾斜身体，嗯嗯作声并点头。在某个时刻，你想知道他是否愿意使用你的应用程序。你听到的不是一个能弥补你口才的有信息性的声明，而是：“嗯……这个应用程序来做什么的？”
- en: The unwritten contract of communication among humans presupposes that we are
    listening to our conversation partners and building our own speech acts on the
    context we are co-creating during the interaction. In social settings, the emergence
    of this joint understanding characterizes a fruitful, enriching conversation.
    In more mundane settings like reserving a restaurant table or buying a train ticket,
    it is an absolute necessity in order to accomplish the task and provide the expected
    value to the user. This requires your assistant to know the history of the current
    conversation, but also of past conversations — for example, it should not be asking
    for the name and other personal details of a user over and over whenever they
    initiate a conversation.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 人类之间的未书面沟通契约假定我们在倾听对话伙伴，并在我们共同创建的上下文基础上构建自己的言语行为。在社交环境中，这种共同理解的出现标志着一次富有成效、充实的对话。在更平凡的场景中，比如预订餐厅桌位或购买火车票，这是完成任务并向用户提供期望价值的绝对必要条件。这要求您的助理了解当前对话的历史，也包括过去对话的历史——例如，它不应该在用户每次发起对话时重复询问用户的姓名和其他个人信息。
- en: 'One of the challenges of maintaining context awareness is coreference resolution,
    i.e. understanding which objects are referred to by pronouns. Humans intuitively
    use a lot of contextual cues when they interpret language — for example, you can
    ask a young child, “Please get the green ball out of the red box and bring it
    to me,” and the child will know you mean the ball, not the box. For virtual assistants,
    this task can be rather challenging, as illustrated by the following dialogue:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 维护上下文意识的挑战之一是共指消解，即理解代词指代的对象。人类在解释语言时直观地使用了很多上下文线索——例如，您可以问一个小孩：“请把红色盒子里的绿球拿出来给我，”孩子会知道您指的是球，而不是盒子。对于虚拟助手来说，这项任务可能相当具有挑战性，如以下对话所示：
- en: 'Assistant: *Thanks, I will now book your flight. Would you also like to order
    a meal for your flight?*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 助理：*谢谢，我现在将为您预订航班。您是否还想为航班订餐？*
- en: 'User: *Uhm… can I decide later whether I want it?*'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 用户：*嗯……我可以稍后决定是否需要吗？*
- en: 'Assistant: *Sorry, this flight cannot be changed or canceled later.*'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 助理：*抱歉，这个航班不能更改或取消。*
- en: Here, the assistant fails to recognize that the pronoun *it* from the user refers
    not to the flight, but to the meal, thus requiring another iteration to fix this
    misunderstanding.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，助理未能识别用户的代词*it*指的不是航班，而是餐食，因此需要进行另一次迭代以纠正这一误解。
- en: 3.4 Additional guardrails
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3.4 附加保护措施
- en: Every now and then, even the best LLM will misbehave and hallucinate. In many
    cases, hallucinations are plain accuracy issues — and, well, you need to accept
    that no AI is 100% accurate. Compared to other AI systems, the “distance” between
    the user and the AI is rather small between the user and the AI. A plain accuracy
    issue can quickly turn into something that is perceived as toxic, discriminative,
    or generally harmful. Additionally, since LLMs don’t have an inherent understanding
    of privacy, they can also reveal sensitive data such as personally identifiable
    information (PII). You can work against these behaviors by using additional guardrails.
    Tools such as Guardrails AI, Rebuff, NeMo Guardrails, and Microsoft Guidance allow
    you to de-risk your system by formulating additional requirements on LLM outputs
    and blocking undesired outputs.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是最好的 LLM，也会偶尔出现行为不当和幻觉。在许多情况下，幻觉只是简单的准确性问题——而且，您需要接受没有任何 AI 是 100% 准确的。与其他
    AI 系统相比，用户与 AI 之间的“距离”相对较小。简单的准确性问题很快会转变为被认为是有害的、歧视性的或一般性的有害内容。此外，由于 LLM 对隐私没有固有的理解，它们还可能泄露诸如个人身份信息（PII）之类的敏感数据。您可以通过使用额外的保护措施来抵制这些行为。工具如
    Guardrails AI、Rebuff、NeMo Guardrails 和 Microsoft Guidance 允许您通过对 LLM 输出制定额外要求并阻止不良输出来降低系统的风险。
- en: Multiple architectures are possible in conversational AI. The following schema
    shows a simple example of how the fine-tuned LLM, external data, and memory can
    be integrated by a conversational agent, which is also responsible for the prompt
    construction and the guardrails.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对话 AI 中可能有多种架构。以下示例展示了如何通过对话代理将微调的 LLM、外部数据和记忆集成在一起，代理还负责提示构建和保护措施。
- en: '![](../Images/aca149a7e873e8d9a7393d94b991b0fe.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aca149a7e873e8d9a7393d94b991b0fe.png)'
- en: 'Figure 4: Schema of a conversational AI system including a fine-tuned LLM,
    a database for semantic search, and a memory component'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：包含微调 LLM、语义搜索数据库和记忆组件的对话 AI 系统示意图
- en: 4\. User experience and conversational design
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 用户体验与对话设计
- en: The charm of conversational interfaces lies in their simplicity and uniformity
    across different applications. If the future of user interfaces is that all apps
    look more or less the same, is the job of the UX designer doomed? Definitely not
    — conversation is an art to be taught to your LLM so it can conduct conversations
    that are helpful, natural, and comfortable for your users. Good conversational
    design emerges when we combine our knowledge of human psychology, linguistics,
    and UX design. In the following, we will first consider two basic choices when
    building a conversational system, namely whether you will use voice and/or chat,
    as well as the larger context of your system. Then, we will look at the conversations
    themselves, and see how you can design the personality of your assistant while
    teaching it to engage in helpful and cooperative conversations.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对话界面的魅力在于它们在不同应用程序中保持的简单性和一致性。如果用户界面的未来是所有应用看起来或多或少都一样，那么UX设计师的工作就注定要失败了吗？绝对不是——对话是一门艺术，需要教给你的LLM，以便它能够进行对用户有帮助、自然且舒适的对话。良好的对话设计是在结合我们对人类心理学、语言学和UX设计的知识时产生的。接下来，我们将首先考虑在构建对话系统时的两个基本选择，即你是否会使用语音和/或聊天，以及你系统的更大背景。然后，我们将看看对话本身，并了解如何设计你的助手的个性，同时教会它进行有帮助和合作的对话。
- en: 4.1 Voice versus chat
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4.1 语音与聊天
- en: Conversational interfaces can be implemented using chat or voice. In a nutshell,
    voice is faster while chat allows users to stay private and to benefit from enriched
    UI functionality. Let’s dive a bit deeper into the two options since this is one
    of the first and most important decisions you will face when building a conversational
    app.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对话界面可以通过聊天或语音实现。简而言之，语音更快，而聊天允许用户保持隐私，并受益于丰富的UI功能。让我们深入了解这两种选项，因为这是构建对话应用时你将面临的第一个也是最重要的决策之一。
- en: To pick between the two alternatives, start by considering the physical setting
    in which your app will be used. For example, why are almost all conversational
    systems in cars, such as those offered by Nuance Communications, based on voice?
    Because the hands of the driver are already busy and they cannot constantly switch
    between the steering wheel and a keyboard. This also applies to other activities
    like cooking, where users want to stay in the flow of their activity while using
    your app. Cars and kitchens are mostly private settings, so users can experience
    the joy of voice interaction without worrying about privacy or about bothering
    others. By contrast, if your app is to be used in a public setting like the office,
    a library, or a train station, voice might not be your first choice.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 要在这两种选择之间做出决定，首先要考虑你的应用将使用的物理环境。例如，为什么几乎所有汽车中的对话系统，如Nuance Communications提供的那些，都是基于语音的？因为司机的双手已经忙碌，他们不能不断在方向盘和键盘之间切换。这同样适用于其他活动，如烹饪，在这些活动中，用户希望在使用你的应用时保持活动的流畅。汽车和厨房通常是私人环境，因此用户可以享受语音交互的乐趣，而无需担心隐私问题或打扰他人。相比之下，如果你的应用将在办公室、图书馆或火车站等公共场所使用，语音可能不是你的首选。
- en: After understanding the physical setting, consider the emotional side. Voice
    can be used intentionally to transmit tone, mood, and personality — does this
    add value in your context? If you are building your app for leisure, voice might
    increase the fun factor, while an assistant for mental health could accommodate
    more empathy and allow a potentially troubled user a larger diapason of expression.
    By contrast, if your app will assist users in a professional setting like trading
    or customer service, a more anonymous, text-based interaction might contribute
    to more objective decisions and spare you the hassle of designing an overly emotional
    experience.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解了物理环境后，考虑情感方面。语音可以有意地传达语调、情绪和个性——这在你的背景中是否增添了价值？如果你为休闲目的构建应用，语音可能会增加趣味性，而一个用于心理健康的助手可以更具同情心，并允许潜在的困扰用户有更大的表达范围。相比之下，如果你的应用将帮助用户在专业环境中，如交易或客户服务，基于文本的更匿名交互可能有助于做出更客观的决策，并免去设计过于情感化体验的麻烦。
- en: As a next step, think about the functionality. The text-based interface allows
    you to enrich the conversations with other media like images and graphical UI
    elements such as buttons. For example, in an e-commerce assistant, an app that
    suggests products by posting their pictures and structured descriptions will be
    way more user-friendly than one that describes products via voice and potentially
    provides their identifiers.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步，考虑功能性。基于文本的界面允许你通过其他媒体（如图片）和图形用户界面元素（如按钮）来丰富对话。例如，在一个电子商务助手中，通过展示产品图片和结构化描述来推荐产品的应用程序将比通过语音描述产品并可能提供其标识符的应用程序更具用户友好性。
- en: 'Finally, let’s talk about the additional design and development challenges
    of building a voice UI:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们谈谈构建语音用户界面的额外设计和开发挑战：
- en: There is an additional step of speech recognition that happens before user inputs
    can be processed with LLMs and Natural Language Processing (NLP).
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在用户输入可以通过 LLM 和自然语言处理（NLP）处理之前，还有一个额外的语音识别步骤。
- en: Voice is a more personal and emotional medium of communication — thus, the requirements
    for designing a consistent, appropriate, and enjoyable persona behind your virtual
    assistant are higher, and you will need to take into account additional factors
    of “voice design” such as timbre, stress, tone, and speaking speed.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音是一种更具个人化和情感化的沟通媒介——因此，为虚拟助手设计一致、合适且愉快的个性化要求更高，你需要考虑“语音设计”的额外因素，如音色、重音、语调和语速。
- en: Users expect your voice conversation to proceed at the same speed as a human
    conversation. To offer a natural interaction via voice, you need a much shorter
    latency than for chat. In human conversations, the typical gap between turns is
    200 milliseconds — This prompt response is possible because we start constructing
    our turns while listening to our partner’s speech. Your voice assistant will need
    to match up with this degree of fluency in the interaction. By contrast, for chatbots,
    you compete with time spans of seconds, and some developers even introduce an
    additional delay to make the conversation feel like a typed chat between humans.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户期望你的语音对话速度与人类对话速度相同。为了通过语音提供自然的互动，你需要比聊天更短的延迟。在人类对话中，转折之间的典型间隔为 200 毫秒——这种快速响应是可能的，因为我们在听对方讲话时开始构建我们的发言。你的语音助手需要达到这种流畅度。相比之下，对于聊天机器人，你需要与几秒钟的时间跨度竞争，一些开发者甚至引入额外的延迟，使对话感觉像是人类之间的输入聊天。
- en: Communication via voice is a linear, one-off enterprise — if your user didn’t
    get what you said, you are in for a tedious, error-prone clarification loop. Thus,
    your turns need to be as concise, clear, and informative as possible.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音沟通是线性的、一发即成的事业——如果用户没有听懂你说的话，你将进入一个冗长且容易出错的澄清循环。因此，你的发言需要尽可能简洁、清晰和信息丰富。
- en: If you go for the voice solution, make sure that you not only clearly understand
    the advantages as compared to chat, but also have the skills and resources to
    address these additional challenges.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你选择语音解决方案，确保你不仅清楚了解相对于聊天的优势，还具备应对这些额外挑战的技能和资源。
- en: 4.2 Where will your conversational AI live?
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4.2 你的对话 AI 将生活在哪里？
- en: Now, let’s consider the larger context in which you can integrate conversational
    AI. All of us are familiar with chatbots on company websites — those widgets on
    the right of your screen that pop up when we open the website of a business. Personally,
    more often than not, my intuitive reaction is to look for the Close button. Why
    is that? Through initial attempts to “converse” with these bots, I have learned
    that they cannot satisfy more specific information requirements, and in the end,
    I still need to comb through the website. The moral of the story? Don’t build
    a chatbot because it’s cool and trendy — rather, build it because you are sure
    it can create additional value for your users.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们考虑你可以集成对话 AI 的更大背景。我们都熟悉公司网站上的聊天机器人——当我们打开商业网站时，屏幕右侧弹出的那些小部件。就我个人而言，更多时候，我的直觉反应是寻找“关闭”按钮。这是为什么呢？通过最初尝试“与这些机器人对话”，我了解到它们无法满足更具体的信息需求，最终我仍然需要浏览网站。故事的寓意？不要因为聊天机器人很酷和时尚而构建它——而是因为你确定它能为用户创造额外的价值。
- en: 'Beyond the controversial widget on a company website, there are several exciting
    contexts to integrate those more general chatbots that have become possible with
    LLMs:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 除了公司网站上有争议的小部件，还有几个令人兴奋的背景，可以集成那些随着 LLMs 变得可能的更通用的聊天机器人：
- en: '**Copilots**: These assistants guide and advise you through specific processes
    and tasks, like GitHub CoPilot for programming. Normally, copilots are “tied”
    to a specific application (or a small suite of related applications).'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**副驾驶**：这些助手在特定的流程和任务中为你提供指导和建议，比如用于编程的 GitHub CoPilot。通常，副驾驶是“绑定”到特定应用程序（或一小套相关应用程序）的。'
- en: '**Synthetic humans** (also digital humans): These creatures “emulate” real
    humans in the digital world. They look, act, and talk like humans and thus also
    need rich conversational abilities. Synthetic humans are often used in immersive
    applications such as gaming, and augmented and virtual reality.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合成人物**（也称数字人物）：这些生物在数字世界中“模仿”真实人类。它们看起来、行动和说话都像人类，因此也需要丰富的对话能力。合成人物通常用于沉浸式应用，如游戏、增强现实和虚拟现实。'
- en: '**Digital twins**: Digital twins are digital “copies” of real-world processes
    and objects, such as factories, cars, or engines. They are used to simulate, analyze,
    and optimize the design and behavior of the real object. Natural language interactions
    with digital twins allow for smoother and more versatile access to the data and
    models.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数字双胞胎**：数字双胞胎是现实世界过程和物体的数字“副本”，例如工厂、汽车或引擎。它们用于模拟、分析和优化真实物体的设计和行为。与数字双胞胎的自然语言交互使得对数据和模型的访问更加顺畅和多样化。'
- en: '**Databases**: Nowadays, data is available on any topic, be it investment recommendations,
    code snippets, or educational materials. What is often hard is to find the very
    specific data that users need in a specific situation. Graphical interfaces to
    databases are either too coarse-grained or covered with endless search and filter
    widgets. Versatile query languages such as SQL and GraphQL are only accessible
    to users with the corresponding skills. Conversational solutions allow users to
    query the data in natural language, while the LLM that processes the requests
    automatically converts them into the corresponding query language (cf. [this article](https://medium.com/towards-data-science/enabling-the-data-driven-organisation-with-text2sql-f8e07089dd0c)
    for an explanation of Text2SQL).'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据库**：如今，任何主题的数据都是可用的，无论是投资建议、代码片段还是教育材料。通常难的是找到用户在特定情况下需要的非常具体的数据。图形界面的数据库要么过于粗糙，要么布满了无尽的搜索和过滤小部件。诸如
    SQL 和 GraphQL 等多功能查询语言仅对具备相应技能的用户开放。对话式解决方案允许用户以自然语言查询数据，而处理请求的 LLM 会自动将其转换为相应的查询语言（参见[这篇文章](https://medium.com/towards-data-science/enabling-the-data-driven-organisation-with-text2sql-f8e07089dd0c)以了解
    Text2SQL 的解释）。'
- en: 4.3 Imprinting a personality on your assistant
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4.3 在你的助手上印刻个性
- en: As humans, we are wired to anthropomorphize, i.e. to inflict additional human
    traits when we see something that vaguely resembles a human. Language is one of
    humankind's most unique and fascinating abilities, and conversational products
    will automatically be associated with humans. People will imagine a person behind
    their screen or device — and it is good practice to not leave this specific person
    to the chance of your users’ imaginations, but rather lend it a consistent personality
    that is aligned with your product and brand. This process is called “persona design”.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 作为人类，我们天生倾向于拟人化，即在看到某些与人类略微相似的事物时附加额外的人类特征。语言是人类最独特和迷人的能力之一，对话产品将自动与人类相关联。人们会想象屏幕或设备背后有一个人——而且最好不要让这个特定的人物依赖于用户的想象，而是赋予其与您的产品和品牌一致的个性。这个过程被称为“角色设计”。
- en: The first step of persona design is understanding the character traits you would
    like your persona to display. Ideally, this is already done at the level of the
    training data — for example, when using RLHF, you can ask your annotators to rank
    the data according to traits like helpfulness, politeness, fun, etc., in order
    to bias the model towards the desired characteristics. These characteristics can
    be matched with your brand attributes to create a consistent image that continuously
    promotes your branding via the product experience.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 角色设计的第一步是理解你希望角色展示的特质。理想情况下，这应该在训练数据层面上完成——例如，在使用 RLHF 时，你可以要求标注者根据有用性、礼貌性、趣味性等特质对数据进行排名，从而使模型偏向于所需的特征。这些特征可以与您的品牌属性相匹配，以创建一个一致的形象，通过产品体验不断地促进品牌建设。
- en: Beyond general characteristics, you should also think about how your virtual
    assistant will deal with specific situations beyond the “happy path”. For example,
    how will it respond to user requests that are beyond its scope, reply to questions
    about itself, and deal with abusive or vulgar language?
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 除了一般特征外，你还应该考虑你的虚拟助手如何处理“幸福路径”之外的特定情况。例如，它将如何回应超出其范围的用户请求，回答关于自身的问题，以及处理辱骂或粗俗的语言？
- en: It is important to develop explicit internal guidelines on your persona that
    can be used by data annotators and conversation designers. This will allow you
    to design your persona in a purposeful way and keep it consistent across your
    team and over time, as your application undergoes multiple iterations and refinements.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要制定明确的内部指南，以供数据标注员和对话设计师使用。这将使你能够以有目的的方式设计你的角色，并在团队内及随着应用程序经过多个迭代和优化的过程中保持一致性。
- en: 4.4 Making conversations helpful with the “principle of cooperation”
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4.4 使用“合作原则”使对话更有帮助
- en: Have you ever had the impression of talking to a brick wall when you were actually
    speaking with a human? Sometimes, we find our conversation partners are just not
    interested in leading the conversation to success. Fortunately, in most cases,
    things are smoother, and humans will intuitively follow the “principle of cooperation”
    that was introduced by the language philosopher Paul Grice. According to this
    principle, humans who successfully communicate with each other follow four maxims,
    namely quantity, quality, relevance, and manner.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否曾经有过和砖墙对话的感觉，即便你实际上是在和一个人交谈？有时，我们发现我们的对话伙伴根本不愿意将对话引向成功。幸运的是，在大多数情况下，事情会更顺利，人们会直观地遵循由语言哲学家保罗·格赖斯提出的“合作原则”。根据这一原则，成功沟通的人遵循四个准则，即量、质量、相关性和方式。
- en: '**Maxim of quantity**'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**量的准则**'
- en: 'The maxim of quantity asks the speaker to be informative and make their contribution
    as informative as required. On the side of the virtual assistant, this also means
    actively moving the conversation forward. For example, consider this snippet from
    an e-commerce fashion app:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 量的准则要求说话者提供信息，并使他们的贡献尽可能有信息量。在虚拟助手的角度，这也意味着积极推动对话。例如，请考虑这个来自电子商务时尚应用的片段：
- en: 'Assistant: *What kind of clothing items are you looking for?*'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 助理：*你在寻找什么类型的衣物？*
- en: 'User: *I am looking for a dress in orange.*'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 用户：*我在找一件橙色的连衣裙。*
- en: 'Assistant: Don’t: *Sorry, we don’t have orange dresses at the moment.*'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 助理：不要：*对不起，我们目前没有橙色的连衣裙。*
- en: '*Do: Sorry, we don’t have dresses in orange, but we have this great and very
    comfortable dress in yellow: …*'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*做：对不起，我们没有橙色的连衣裙，但我们有这件很棒且非常舒适的黄色连衣裙：…*'
- en: The user hopes to leave your app with a suitable item. Stopping the conversation
    because you don’t have items that would fit the exact description kills off the
    possibility of success. However, if your app makes suggestions about alternative
    items, it will appear more helpful and leave the option of a successful interaction
    open.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 用户希望从你的应用中找到合适的物品。由于没有符合确切描述的物品而停止对话会使成功的可能性丧失。然而，如果你的应用能提出替代物品的建议，它会显得更有帮助，并留住成功互动的可能性。
- en: Especially in voice interactions, it is important to find the right balance
    between providing all the information the user might need for success while not
    overwhelming them with unnecessary information which might cloud the interaction.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是在语音交互中，找到提供用户可能需要的所有信息与不使他们被不必要的信息淹没之间的正确平衡非常重要，以免干扰对话。
- en: '**Maxim of quality**'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**质量的准则**'
- en: The maxim of quality asks speakers to be truthful and not say things they believe
    are false or for which they lack adequate evidence. There is a lot of subjectivity
    and personal belief involved here — thus, this maxim cannot be directly projected
    onto LLMs. As we have seen, LLMs tend to hallucinate, and this risk is especially
    high when the conversation drifts off into less familiar territories. Additional
    guardrails can be used in order to avoid misleading statements and bring the conversation
    back on track.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 质量的准则要求说话者要真实，不说他们认为是虚假的或缺乏充分证据的事物。在这里涉及大量主观性和个人信念——因此，这一准则不能直接投射到大型语言模型上。正如我们所见，大型语言模型倾向于产生虚假信息，这种风险在对话进入不熟悉的领域时尤其高。可以使用额外的保护措施来避免误导性陈述，并将对话引回正轨。
- en: '**Maxim of relevance**'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关性准则**'
- en: 'The maxim of relevance asks us to be — well, relevant. As a precondition, the
    virtual assistant has to understand the true intent of the user. Here is an example
    of an airline assistant that violates this rule:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 相关原则要求我们要——确切地说，要相关。作为前提，虚拟助理必须理解用户的真实意图。以下是一个违反这一原则的航空公司助理的例子：
- en: 'User: *I need a flight from Berlin to Zurich tomorrow morning.*'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 用户：*我需要一张明天早上从柏林到苏黎世的航班。*
- en: 'Assistant: *OK, I found the following flights from Berlin to Zurich for tomorrow
    morning. Flight BZ36294 leaves Berlin at 6.30am and arrives in Zurich at 8am.
    Flight BZ96294 leaves Berlin at 8am and arrives at 9.30am. Flight BZ96294 leaves
    Berlin at 8am and arrives in Zurich at 9.30am. Flight BZ95614 leaves Berlin at
    11am and arrives in Zurich at 12.30pm. There is also the possibility of a connecting
    flight, in which case you would leave Berlin at 11.45am and arrive in Zurich at
    3pm.*'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 助理：*好的，我找到了一些明天早上从柏林到苏黎世的航班。航班 BZ36294 在早上6:30从柏林起飞，8点到达苏黎世。航班 BZ96294 在早上8点从柏林起飞，9:30到达。航班
    BZ96294 在早上8点从柏林起飞，9:30到达苏黎世。航班 BZ95614 在早上11点从柏林起飞，12:30到达苏黎世。此外，还有一个中转航班的可能性，即你将在11:45离开柏林，3点到达苏黎世。*
- en: 'User: *Sorry… could you repeat this again?*'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 用户：*对不起……你能再重复一遍吗？*
- en: 'The assistant is overwhelming the user with detailed information that might
    not be relevant. By breaking this up and guiding the user to limit their search
    space, the dialogue becomes much easier to digest:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 助理用大量可能不相关的详细信息让用户感到不知所措。通过将这些信息分解并引导用户缩小搜索范围，对话会变得更易于理解：
- en: 'User: *I need a flight from Berlin to Zurich tomorrow morning.*'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 用户：*我需要一张明天早上从柏林到苏黎世的航班。*
- en: 'Assistant: *Ok, I found flights leaving at 6.30, 8, and 11am. Which time would
    you like to leave?*'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 助理：*好的，我找到了一些明天早上从柏林出发的航班，分别是6:30、8点和11点。你想选择哪个时间出发？*
- en: 'User: *I need to be in Zurich before 9am.*'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 用户：*我需要在早上9点前到达苏黎世。*
- en: 'Assistant: *OK, so you can take the flight BZ36294\. It leaves at 6.30 and
    arrives at 8am. Should I buy the ticket for you?*'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 助理：*好的，你可以选择航班 BZ36294。它在6:30出发，8点到达。我要为你购买机票吗？*
- en: 'User: *Yes, thanks.*'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 用户：*是的，谢谢。*
- en: '**Maxim of manner**'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**表述原则**'
- en: Finally, the maxim of manner states that our speech acts should be clear, concise
    and orderly, avoiding ambiguity and obscurity of expression. Your virtual assistant
    should avoid technical or internal jargon, and favour simple, universally understandable
    formulations.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，表述原则指出我们的言语行为应当清晰、简洁、有序，避免歧义和模糊表达。你的虚拟助理应避免技术或内部术语，倾向于使用简单、普遍易懂的表述。
- en: While Grice’s principles are valid for all conversations independently of a
    specific domain, LLMs not trained specifically for conversation often fail to
    fulfill them. Thus, when compiling your training data, it is important to have
    enough dialogue samples that allow your model to learn these principles.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然格赖斯的原则适用于所有对话，无论具体领域如何，但没有专门针对对话进行训练的LLMs往往无法满足这些原则。因此，在编制训练数据时，重要的是要有足够的对话样本，以便模型能够学习这些原则。
- en: The domain of conversational design is developing rather quickly. Whether you
    are already building AI products or thinking about your career path in AI, I encourage
    you to dig deeper into this topic (cf. the excellent introductions in [5] and
    [6]). As AI is turning into a commodity, good design together with a defensible
    data strategy will become two important differentiators for AI products.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 对话设计领域发展迅速。无论你是已经在构建人工智能产品还是考虑在人工智能领域的职业道路，我鼓励你深入探讨这个话题（参见[5]和[6]中的优秀介绍）。随着人工智能逐渐成为一种商品，良好的设计和可辩护的数据策略将成为人工智能产品的重要差异化因素。
- en: Summary
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Let’s summarize the key takeaways from the article. Additionally, figure 5 offers
    a “cheat sheet” with the main points that you can download as a reference.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一下文章的要点。此外，图5提供了一个“备忘单”，其中包含主要内容，你可以下载作为参考。
- en: 'LLMs enhance conversational AI: Large Language Models (LLMs) have significantly
    improved the quality and scalability of conversational AI applications across
    various industries and use cases.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）提升了对话型人工智能的质量和可扩展性：大型语言模型（LLMs）显著提高了各个行业和应用场景中对话型人工智能应用的质量和可扩展性。
- en: Conversational AI can add a lot of value to applications with lots of similar
    user requests (e.g., customer service) or that need to access a large quantity
    of unstructured data (e.g. knowledge management).
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对话型人工智能可以为处理大量类似用户请求（例如客服）或需要访问大量非结构化数据（例如知识管理）的应用增加很多价值。
- en: 'Data: Fine-tuning LLMs for conversational tasks requires high-quality conversational
    data that closely mirrors real-world interactions. Crowdsourcing and LLM-generated
    data can be valuable resources for scaling data collection.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据：为对话任务微调 LLMs 需要高质量的对话数据，这些数据应尽可能贴近现实世界的互动。众包和 LLM 生成的数据可以是扩大数据收集的宝贵资源。
- en: 'Putting the system together: Developing conversational AI systems is an iterative
    and experimental process involving constant optimization of data, fine-tuning
    strategies, and component integration.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组建系统：开发对话型 AI 系统是一个迭代和实验的过程，涉及对数据、微调策略和组件集成的持续优化。
- en: 'Teaching conversation skills to LLMs: Fine-tuning LLMs involves training them
    to recognize and respond to specific communicative intents and situations.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 教授对话技巧给 LLMs：微调 LLMs 涉及训练它们识别和响应特定的交流意图和情境。
- en: 'Adding external data with semantic search: Integrating external and internal
    data sources using semantic search enhances the AI’s responses by providing more
    contextually relevant information.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用语义搜索添加外部数据：通过使用语义搜索整合外部和内部数据源，可以通过提供更多上下文相关的信息来增强 AI 的响应。
- en: 'Memory and context awareness: Effective conversational systems must maintain
    context awareness, including tracking the history of the current conversation
    and past interactions, to provide meaningful and coherent responses.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记忆和上下文意识：有效的对话系统必须保持上下文意识，包括跟踪当前对话和过去互动的历史，以提供有意义和连贯的回应。
- en: 'Setting guardrails: To ensure responsible behavior, conversational AI systems
    should employ guardrails to prevent inaccuracies, hallucinations, and breaches
    of privacy.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置保护措施：为了确保负责任的行为，对话型 AI 系统应采用保护措施，以防止不准确、虚假信息和隐私泄露。
- en: 'Persona design: Designing a consistent persona for your conversational assistant
    is essential to creating a cohesive and branded user experience. Persona characteristics
    should align with your product and brand attributes.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人物设定：为你的对话助手设计一个一致的人物设定对创建连贯且具有品牌特色的用户体验至关重要。人物特征应与产品和品牌属性相一致。
- en: 'Voice vs. chat: Choosing between voice and chat interfaces depends on factors
    like the physical setting, emotional context, functionality, and design challenges.
    Consider these factors when deciding on the interface for your conversational
    AI.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音与聊天：选择语音还是聊天界面取决于物理环境、情感背景、功能和设计挑战等因素。在决定对话型 AI 的界面时，请考虑这些因素。
- en: 'Integration in various contexts: Conversational AI can be integrated in different
    contexts, including copilots, synthetic humans, digital twins, and databases,
    each with specific use cases and requirements.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在各种环境中的集成：对话型 AI 可以在不同的环境中集成，包括副驾驶、合成人物、数字双胞胎和数据库，每种情况都有特定的应用场景和需求。
- en: 'Observing the Principle of Cooperation: Following the principles of quantity,
    quality, relevance, and manner in conversations can make interactions with conversational
    AI more helpful and user-friendly.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察合作原则：遵循对话中的数量、质量、相关性和方式原则可以使与对话型 AI 的互动更加有帮助和用户友好。
- en: '![](../Images/71700b472407119594816219f785a1cc.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/71700b472407119594816219f785a1cc.png)'
- en: 'Figure 5: Key takeaways and best practices for conversational AI'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：对话型 AI 的关键要点和最佳实践
- en: References
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Heng-Tze Chen et al. 2022\. [LaMDA: Towards Safe, Grounded, and High-Quality
    Dialog Models for Everything](https://blog.research.google/2022/01/lamda-towards-safe-grounded-and-high.html).'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Heng-Tze Chen 等. 2022\. [LaMDA: 迈向安全、扎根且高质量的对话模型](https://blog.research.google/2022/01/lamda-towards-safe-grounded-and-high.html)。'
- en: '[2] OpenAI. 2022\. ChatGPT: [Optimizing Language Models for Dialogue](https://openai.com/blog/chatgpt).
    Retrieved on January 13, 2022.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] OpenAI. 2022\. ChatGPT: [优化对话模型](https://openai.com/blog/chatgpt)。2022年1月13日检索。'
- en: '[3] Patrick Lewis et al. 2020\. [Retrieval-Augmented Generation for Knowledge-Intensive
    NLP Tasks](https://arxiv.org/abs/2005.11401).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Patrick Lewis 等. 2020\. [检索增强生成用于知识密集型 NLP 任务](https://arxiv.org/abs/2005.11401)。'
- en: '[4] Paul Grice. 1989\. Studies in the Way of Words.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Paul Grice. 1989\. 《言语的方式研究》。'
- en: '[5] Cathy Pearl. 2016\. Designing Voice User Interfaces.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Cathy Pearl. 2016\. 《语音用户界面设计》。'
- en: '[6] Michael Cohen et al. 2004\. Voice User Interface Design.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] Michael Cohen 等. 2004\. 《语音用户界面设计》。'
- en: '*Note: All images are by the author, except noted otherwise.*'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：除非另有说明，所有图片均由作者提供。*'
