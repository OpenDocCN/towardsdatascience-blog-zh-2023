- en: Building a maintainable and modular LLM application stack with Hamilton in 13
    minutes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç”¨ Hamilton åœ¨ 13 åˆ†é’Ÿå†…æ„å»ºä¸€ä¸ªå¯ç»´æŠ¤ä¸”æ¨¡å—åŒ–çš„ LLM åº”ç”¨å †æ ˆ
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/building-a-maintainable-and-modular-llm-application-stack-with-hamilton-baa68e55e8cd?source=collection_archive---------10-----------------------#2023-07-13](https://towardsdatascience.com/building-a-maintainable-and-modular-llm-application-stack-with-hamilton-baa68e55e8cd?source=collection_archive---------10-----------------------#2023-07-13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/building-a-maintainable-and-modular-llm-application-stack-with-hamilton-baa68e55e8cd?source=collection_archive---------10-----------------------#2023-07-13](https://towardsdatascience.com/building-a-maintainable-and-modular-llm-application-stack-with-hamilton-baa68e55e8cd?source=collection_archive---------10-----------------------#2023-07-13)
- en: LLM Applications are dataflows, use a tool specifically designed to express
    them
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM åº”ç”¨æ˜¯æ•°æ®æµï¼Œä½¿ç”¨ä¸“é—¨è®¾è®¡çš„å·¥å…·æ¥è¡¨è¾¾å®ƒä»¬
- en: '[](https://medium.com/@stefan.krawczyk?source=post_page-----baa68e55e8cd--------------------------------)[![Stefan
    Krawczyk](../Images/150405abaad9590e1dc2589168ed2fa3.png)](https://medium.com/@stefan.krawczyk?source=post_page-----baa68e55e8cd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----baa68e55e8cd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----baa68e55e8cd--------------------------------)
    [Stefan Krawczyk](https://medium.com/@stefan.krawczyk?source=post_page-----baa68e55e8cd--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@stefan.krawczyk?source=post_page-----baa68e55e8cd--------------------------------)[![Stefan
    Krawczyk](../Images/150405abaad9590e1dc2589168ed2fa3.png)](https://medium.com/@stefan.krawczyk?source=post_page-----baa68e55e8cd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----baa68e55e8cd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----baa68e55e8cd--------------------------------)
    [Stefan Krawczyk](https://medium.com/@stefan.krawczyk?source=post_page-----baa68e55e8cd--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F193628e26f00&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-maintainable-and-modular-llm-application-stack-with-hamilton-baa68e55e8cd&user=Stefan+Krawczyk&userId=193628e26f00&source=post_page-193628e26f00----baa68e55e8cd---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----baa68e55e8cd--------------------------------)
    Â·13 min readÂ·Jul 13, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbaa68e55e8cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-maintainable-and-modular-llm-application-stack-with-hamilton-baa68e55e8cd&user=Stefan+Krawczyk&userId=193628e26f00&source=-----baa68e55e8cd---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F193628e26f00&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-maintainable-and-modular-llm-application-stack-with-hamilton-baa68e55e8cd&user=Stefan+Krawczyk&userId=193628e26f00&source=post_page-193628e26f00----baa68e55e8cd---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----baa68e55e8cd--------------------------------)
    Â·13 åˆ†é’Ÿé˜…è¯»Â·2023å¹´7æœˆ13æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbaa68e55e8cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-maintainable-and-modular-llm-application-stack-with-hamilton-baa68e55e8cd&user=Stefan+Krawczyk&userId=193628e26f00&source=-----baa68e55e8cd---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbaa68e55e8cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-maintainable-and-modular-llm-application-stack-with-hamilton-baa68e55e8cd&source=-----baa68e55e8cd---------------------bookmark_footer-----------)![](../Images/84bcb5f1c47c2c34ce7c753f621da5a8.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbaa68e55e8cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-maintainable-and-modular-llm-application-stack-with-hamilton-baa68e55e8cd&source=-----baa68e55e8cd---------------------bookmark_footer-----------)![](../Images/84bcb5f1c47c2c34ce7c753f621da5a8.png)'
- en: LLM stacks. Using the right tool, like Hamilton, can sure your stack doesnâ€™t
    become a pain to maintain and manage. Image from [pixabay](https://pixabay.com/photos/books-stack-book-store-1163695/).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: LLM å †æ ˆã€‚ä½¿ç”¨åˆé€‚çš„å·¥å…·ï¼Œå¦‚ Hamiltonï¼Œå¯ä»¥ç¡®ä¿ä½ çš„å †æ ˆä¸ä¼šå˜å¾—éš¾ä»¥ç»´æŠ¤å’Œç®¡ç†ã€‚å›¾ç‰‡æ¥æºäº [pixabay](https://pixabay.com/photos/books-stack-book-store-1163695/)ã€‚
- en: '*This post is written in collaboration with* [*Thierry Jean*](https://medium.com/u/cf12dc7f8440)
    *and originally appeared* [*here*](https://blog.dagworks.io/p/building-a-maintainable-and-modular)*.*'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ­¤æ–‡ç« ä¸* [*Thierry Jean*](https://medium.com/u/cf12dc7f8440) *åˆä½œæ’°å†™ï¼Œæœ€åˆå‘å¸ƒäº* [*æ­¤å¤„*](https://blog.dagworks.io/p/building-a-maintainable-and-modular)ã€‚'
- en: 'In this post, weâ€™re going to share how [Hamilton](https://github.com/dagWorks-Inc/hamilton),
    an open source framework, can help you write modular and maintainable code for
    your large language model (LLM) application stack. Hamilton is great for describing
    any type of [dataflow](https://en.wikipedia.org/wiki/Dataflow), which is exactly
    what youâ€™re doing when building an LLM powered application. With Hamilton you
    get strong [software maintenance ergonomics](https://ceur-ws.org/Vol-3306/paper5.pdf),
    with the added benefit of being able to easily swap and evaluate different providers/implementations
    for components of your application. Disclaimer: Iâ€™m one of the authors of the
    Hamilton package.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†åˆ†äº«å¦‚ä½•ä½¿ç”¨[Hamilton](https://github.com/dagWorks-Inc/hamilton)è¿™ä¸€å¼€æºæ¡†æ¶æ¥ç¼–å†™æ¨¡å—åŒ–å’Œå¯ç»´æŠ¤çš„ä»£ç ï¼Œä»¥æ”¯æŒä½ çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åº”ç”¨ç¨‹åºå †æ ˆã€‚Hamilton
    éå¸¸é€‚åˆæè¿°ä»»ä½•ç±»å‹çš„[æ•°æ®æµ](https://en.wikipedia.org/wiki/Dataflow)ï¼Œè¿™æ­£æ˜¯ä½ åœ¨æ„å»º LLM é©±åŠ¨åº”ç”¨ç¨‹åºæ—¶æ‰€åšçš„ã€‚é€šè¿‡
    Hamiltonï¼Œä½ å¯ä»¥è·å¾—å¼ºå¤§çš„[è½¯ä»¶ç»´æŠ¤äººæœºå·¥ç¨‹å­¦](https://ceur-ws.org/Vol-3306/paper5.pdf)ï¼ŒåŒæ—¶è¿˜èƒ½è½»æ¾åœ°äº¤æ¢å’Œè¯„ä¼°åº”ç”¨ç¨‹åºç»„ä»¶çš„ä¸åŒæä¾›è€…/å®ç°ã€‚å…è´£å£°æ˜ï¼šæˆ‘æ˜¯
    Hamilton åŒ…çš„ä½œè€…ä¹‹ä¸€ã€‚
- en: The example weâ€™ll walk you through will mirror a typical LLM application workflow
    youâ€™d run to populate a vector database with some text knowledge. Specifically,
    weâ€™ll cover pulling data from the web, creating text embeddings (vectors) and
    pushing them to a vector store.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æ¼”ç¤ºçš„ç¤ºä¾‹å°†é•œåƒä½ ç”¨äºå¡«å……å‘é‡æ•°æ®åº“çš„å…¸å‹ LLM åº”ç”¨ç¨‹åºå·¥ä½œæµç¨‹ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†æ¶µç›–ä»ç½‘ç»œä¸­æå–æ•°æ®ã€åˆ›å»ºæ–‡æœ¬åµŒå…¥ï¼ˆå‘é‡ï¼‰å¹¶å°†å…¶æ¨é€åˆ°å‘é‡å­˜å‚¨ä¸­ã€‚
- en: '![](../Images/3af6ce8a4bc5b6f967b1e28e6085bcc0.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3af6ce8a4bc5b6f967b1e28e6085bcc0.png)'
- en: Stack overview. Image by authors.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å †æ ˆæ¦‚è¿°ã€‚ä½œè€…æä¾›çš„å›¾åƒã€‚
- en: The LLM application dataflow
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM åº”ç”¨ç¨‹åºæ•°æ®æµ
- en: To start, letâ€™s describe what a typical LLM dataflow consists of. The application
    will receive a small data input (e.g., a text, a command) and act within a larger
    context (e.g., chat history, documents, state). This data will move through different
    services (LLM, vector database, document store, etc.) to perform operations, generate
    new data artifacts, and return final results. Most use cases repeat this flow
    multiple times while iterating over different inputs.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œè®©æˆ‘ä»¬æè¿°ä¸€ä¸‹å…¸å‹çš„ LLM æ•°æ®æµçš„ç»„æˆã€‚åº”ç”¨ç¨‹åºå°†æ¥æ”¶ä¸€ä¸ªå°çš„æ•°æ®è¾“å…¥ï¼ˆä¾‹å¦‚æ–‡æœ¬ã€å‘½ä»¤ï¼‰ï¼Œå¹¶åœ¨æ›´å¤§çš„ä¸Šä¸‹æ–‡ä¸­è¿›è¡Œæ“ä½œï¼ˆä¾‹å¦‚èŠå¤©è®°å½•ã€æ–‡æ¡£ã€çŠ¶æ€ï¼‰ã€‚è¿™äº›æ•°æ®å°†é€šè¿‡ä¸åŒçš„æœåŠ¡ï¼ˆLLMã€å‘é‡æ•°æ®åº“ã€æ–‡æ¡£å­˜å‚¨ç­‰ï¼‰è¿›è¡Œæ“ä½œã€ç”Ÿæˆæ–°çš„æ•°æ®å·¥ä»¶ï¼Œå¹¶è¿”å›æœ€ç»ˆç»“æœã€‚å¤§å¤šæ•°ç”¨ä¾‹ä¼šåœ¨è¿­ä»£ä¸åŒè¾“å…¥çš„è¿‡ç¨‹ä¸­é‡å¤è¿™ä¸€æµç¨‹å¤šæ¬¡ã€‚
- en: 'Some common operations include:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›å¸¸è§çš„æ“ä½œåŒ…æ‹¬ï¼š
- en: Convert text to embeddings
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ–‡æœ¬è½¬æ¢ä¸ºåµŒå…¥
- en: Store / search / retrieve embeddings
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­˜å‚¨ / æœç´¢ / æ£€ç´¢åµŒå…¥
- en: Find nearest neighbors to an embedding
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æŸ¥æ‰¾åµŒå…¥çš„æœ€è¿‘é‚»
- en: Retrieve text for an embedding
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ£€ç´¢ç”¨äºåµŒå…¥çš„æ–‡æœ¬
- en: Determine context required to pass into a prompt
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¡®å®šä¼ é€’åˆ°æç¤ºä¸­çš„ä¸Šä¸‹æ–‡
- en: Prompt models with context from relevant text
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ç›¸å…³æ–‡æœ¬ä¸­çš„ä¸Šä¸‹æ–‡æç¤ºæ¨¡å‹
- en: Send results to another service (API, database, etc.)
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†ç»“æœå‘é€åˆ°å…¶ä»–æœåŠ¡ï¼ˆAPIã€æ•°æ®åº“ç­‰ï¼‰
- en: â€¦
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¦
- en: and chaining them together!
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¹¶å°†å®ƒä»¬ä¸²è”èµ·æ¥ï¼
- en: Now, letâ€™s think about the above in a production context, and imagine a user
    is unsatisfied with the outputs of your application and you want to find the root
    cause of the issue. Your application logged both the prompt and the results. Your
    code allows you to figure out the sequence of operations. Yet, you have no clue
    where things went wrong and the system produced undesirable outputâ€¦ To mitigate
    this, weâ€™d argue itâ€™s critical then to have lineage of data artifacts and the
    code that produces them, so you can debug situations such as these quickly.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æ·±å…¥æ¢è®¨ä¸Šè¿°å†…å®¹ï¼Œå‡è®¾ç”¨æˆ·å¯¹ä½ çš„åº”ç”¨ç¨‹åºçš„è¾“å‡ºä¸æ»¡æ„ï¼Œå¹¶ä¸”ä½ æƒ³æ‰¾åˆ°é—®é¢˜çš„æ ¹æºã€‚ä½ çš„åº”ç”¨ç¨‹åºè®°å½•äº†æç¤ºå’Œç»“æœã€‚ä½ çš„ä»£ç å…è®¸ä½ æ‰¾å‡ºæ“ä½œçš„é¡ºåºã€‚ç„¶è€Œï¼Œä½ ä¸çŸ¥é“é—®é¢˜å‡ºåœ¨å“ªé‡Œï¼Œç³»ç»Ÿäº§ç”Ÿäº†ä¸ç†æƒ³çš„è¾“å‡ºâ€¦â€¦ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬è®¤ä¸ºè·Ÿè¸ªæ•°æ®å·¥ä»¶åŠç”Ÿæˆå®ƒä»¬çš„ä»£ç æ˜¯å…³é”®ï¼Œè¿™æ ·ä½ æ‰èƒ½å¿«é€Ÿè°ƒè¯•ç±»ä¼¼çš„æƒ…å†µã€‚
- en: To add to the complexity of your LLM application dataflow, many operations are
    non-deterministic, meaning you canâ€™t rerun or reverse engineer the operation to
    reproduce intermediate results. For example, an API call to generate a text or
    image response will likely be non-reproducible even if you have access to the
    same input and configuration (you *can* *mitigate some of this* with options such
    as [temperature](https://platform.openai.com/docs/api-reference/chat/create#chat/create-temperature)).
    This also extends to certain vector database operations like â€œfind nearestâ€ where
    the result depends on the objects currently stored in the database. In production
    settings, it is prohibitive to near impossible to snapshot DB states to make calls
    reproducible.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºè®¸å¤šæ“ä½œæ˜¯éç¡®å®šæ€§çš„ï¼Œè¿™å¢åŠ äº†ä½ çš„LLMåº”ç”¨ç¨‹åºæ•°æ®æµçš„å¤æ‚æ€§ï¼Œè¿™æ„å‘³ç€ä½ ä¸èƒ½é‡æ–°è¿è¡Œæˆ–é€†å‘å·¥ç¨‹æ“ä½œä»¥é‡ç°ä¸­é—´ç»“æœã€‚ä¾‹å¦‚ï¼Œå³ä½¿ä½ æ‹¥æœ‰ç›¸åŒçš„è¾“å…¥å’Œé…ç½®ï¼Œç”Ÿæˆæ–‡æœ¬æˆ–å›¾åƒå“åº”çš„APIè°ƒç”¨å¯èƒ½ä¹Ÿæ˜¯ä¸å¯é‡å¤çš„ï¼ˆä½ *å¯ä»¥*é€šè¿‡å¦‚[temperature](https://platform.openai.com/docs/api-reference/chat/create#chat/create-temperature)è¿™æ ·çš„é€‰é¡¹*ç¼“è§£éƒ¨åˆ†é—®é¢˜*ï¼‰ã€‚è¿™ä¹Ÿæ‰©å±•åˆ°æŸäº›å‘é‡æ•°æ®åº“æ“ä½œï¼Œå¦‚â€œæŸ¥æ‰¾æœ€è¿‘â€â€”â€”å…¶ç»“æœå–å†³äºæ•°æ®åº“ä¸­å½“å‰å­˜å‚¨çš„å¯¹è±¡ã€‚åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå¿«ç…§æ•°æ®åº“çŠ¶æ€ä»¥ä½¿è°ƒç”¨å¯é‡å¤å‡ ä¹æ˜¯ä¸ç°å®çš„ã€‚
- en: 'For these reasons, it is important to adopt flexible tooling to create robust
    dataflows that allow you to:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºè¿™äº›åŸå› ï¼Œé‡‡ç”¨çµæ´»çš„å·¥å…·ä»¥åˆ›å»ºç¨³å¥çš„æ•°æ®æµå¾ˆé‡è¦ï¼Œè¿™æ ·å¯ä»¥è®©ä½ ï¼š
- en: plugin in various components easily.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è½»æ¾åœ°æ’å…¥å„ç§ç»„ä»¶ã€‚
- en: see how components connect to each other.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: äº†è§£ç»„ä»¶ä¹‹é—´å¦‚ä½•è¿æ¥ã€‚
- en: add and customize common production needs like caching, validation, and observability.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ·»åŠ å’Œå®šåˆ¶å¸¸è§çš„ç”Ÿäº§éœ€æ±‚ï¼Œå¦‚ç¼“å­˜ã€éªŒè¯å’Œå¯è§‚å¯Ÿæ€§ã€‚
- en: adjust the flow structure to your needs without requiring a strong engineering
    skill set
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ ¹æ®ä½ çš„éœ€æ±‚è°ƒæ•´æµç»“æ„ï¼Œè€Œä¸éœ€è¦å¼ºå¤§çš„å·¥ç¨‹æŠ€èƒ½
- en: plug into the traditional data processing and machine learning ecosystem.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ’ä»¶é›†æˆåˆ°ä¼ ç»Ÿçš„æ•°æ®å¤„ç†å’Œæœºå™¨å­¦ä¹ ç”Ÿæ€ç³»ç»Ÿä¸­ã€‚
- en: In this post weâ€™ll give an overview of how Hamilton fulfills points 1, 2, &
    4\. We refer you to our [documentation](https://hamilton.dagworks.io/en/latest/)
    for points 3 & 5.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¦‚è¿°Hamiltonå¦‚ä½•æ»¡è¶³ç¬¬1ã€2å’Œ4ç‚¹ã€‚æœ‰å…³ç¬¬3å’Œ5ç‚¹çš„ä¿¡æ¯ï¼Œè¯·å‚é˜…æˆ‘ä»¬çš„[æ–‡æ¡£](https://hamilton.dagworks.io/en/latest/)ã€‚
- en: Current LLM application development tooling
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å½“å‰çš„LLMåº”ç”¨ç¨‹åºå¼€å‘å·¥å…·
- en: The LLM space is still in its infancy, and the usage patterns and tooling are
    rapidly evolving. While LLM frameworks can get you started, current options are
    not production tested; to our knowledge, no established tech companies are using
    the current popular LLM frameworks in production.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: LLMé¢†åŸŸä»å¤„äºèµ·æ­¥é˜¶æ®µï¼Œä½¿ç”¨æ¨¡å¼å’Œå·¥å…·æ­£åœ¨å¿«é€Ÿæ¼”å˜ã€‚è™½ç„¶LLMæ¡†æ¶å¯ä»¥è®©ä½ å…¥é—¨ï¼Œä½†å½“å‰çš„é€‰é¡¹å¹¶æœªç»è¿‡ç”Ÿäº§ç¯å¢ƒæµ‹è¯•ï¼›æ®æˆ‘ä»¬äº†è§£ï¼Œç›®å‰æ²¡æœ‰æˆç†Ÿçš„ç§‘æŠ€å…¬å¸åœ¨ç”Ÿäº§ä¸­ä½¿ç”¨å½“å‰æµè¡Œçš„LLMæ¡†æ¶ã€‚
- en: 'Donâ€™t get us wrong, some of the tooling out there is great for getting a quick
    proof of concept up and running! However, we feel they fall short in two specific
    areas:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ«è¯¯è§£æˆ‘ä»¬çš„æ„æ€ï¼Œæœ‰äº›å·¥å…·ç¡®å®éå¸¸é€‚åˆå¿«é€Ÿå»ºç«‹æ¦‚å¿µéªŒè¯ï¼ç„¶è€Œï¼Œæˆ‘ä»¬è®¤ä¸ºå®ƒä»¬åœ¨ä¸¤ä¸ªç‰¹å®šé¢†åŸŸå­˜åœ¨ä¸è¶³ï¼š
- en: '**1\. How to model the LLM applicationâ€™s dataflow.** We strongly believe that
    the dataflow of â€œactionsâ€ is better modeled as functions, rather than through
    object oriented classes and lifecycles. Functions are much simpler to reason about,
    test, and change. Object oriented classes can become quite opaque and impose more
    mental burden.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**1\. å¦‚ä½•å»ºæ¨¡LLMåº”ç”¨ç¨‹åºçš„æ•°æ®æµã€‚** æˆ‘ä»¬å¼ºçƒˆè®¤ä¸ºâ€œåŠ¨ä½œâ€çš„æ•°æ®æµå»ºæ¨¡æ›´é€‚åˆç”¨å‡½æ•°æ¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯é€šè¿‡é¢å‘å¯¹è±¡çš„ç±»å’Œç”Ÿå‘½å‘¨æœŸã€‚å‡½æ•°æ›´å®¹æ˜“æ¨ç†ã€æµ‹è¯•å’Œæ›´æ”¹ã€‚é¢å‘å¯¹è±¡çš„ç±»å¯èƒ½å˜å¾—ç›¸å½“æ™¦æ¶©ï¼Œå¹¶å¸¦æ¥æ›´å¤šçš„æ€ç»´è´Ÿæ‹…ã€‚'
- en: When something errors, object-oriented frameworks require you to drill into
    the objectsâ€™ source code to understand it. Whereas with Hamilton functions, a
    clear dependency lineage tells you where to look and helps you reason about what
    happened (more on this below)!
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å½“å‡ºç°é”™è¯¯æ—¶ï¼Œé¢å‘å¯¹è±¡çš„æ¡†æ¶éœ€è¦ä½ æ·±å…¥åˆ°å¯¹è±¡çš„æºä»£ç ä¸­ä»¥ç†è§£å®ƒã€‚è€Œä½¿ç”¨Hamiltonå‡½æ•°æ—¶ï¼Œæ¸…æ™°çš„ä¾èµ–å…³ç³»è°±èƒ½å‘Šè¯‰ä½ åœ¨å“ªé‡ŒæŸ¥æ‰¾ï¼Œå¹¶å¸®åŠ©ä½ æ¨ç†å‘ç”Ÿäº†ä»€ä¹ˆï¼ˆæ›´å¤šä¿¡æ¯è¯·è§ä¸‹æ–‡ï¼‰ï¼
- en: '**2\. Customization/extensions.** Unfortunately you need a strong software
    engineering skill set to modify the current frameworks once you step outside the
    bounds of what they make â€œeasyâ€ to do. If thatâ€™s not an option, this means you
    can end up stepping outside the framework for a particular piece of custom business
    logic, which can inadvertently lead you to maintaining more code surface area
    than if you didnâ€™t use the framework in the first place.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. å®šåˆ¶/æ‰©å±•ã€‚** ä¸å¹¸çš„æ˜¯ï¼Œä¸€æ—¦ä½ è¶…å‡ºæ¡†æ¶æä¾›çš„â€œç®€å•â€åŠŸèƒ½ï¼Œä½ éœ€è¦å¼ºå¤§çš„è½¯ä»¶å·¥ç¨‹æŠ€èƒ½æ¥ä¿®æ”¹å½“å‰æ¡†æ¶ã€‚å¦‚æœè¿™ä¸æ˜¯ä¸€ä¸ªé€‰é¡¹ï¼Œè¿™æ„å‘³ç€ä½ å¯èƒ½ä¼šåœ¨ç‰¹å®šçš„è‡ªå®šä¹‰ä¸šåŠ¡é€»è¾‘ä¸Šè„±ç¦»æ¡†æ¶ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´ä½ ç»´æŠ¤æ›´å¤šçš„ä»£ç é¢ç§¯ï¼Œè€Œä¸æ˜¯å¦‚æœä½ ä¸€å¼€å§‹å°±ä¸ä½¿ç”¨æ¡†æ¶çš„è¯ã€‚'
- en: For more on these two points we point you to threads such as these two ([hacker
    news](https://news.ycombinator.com/item?id=36645575#36647985), [reddit](https://old.reddit.com/r/LangChain/comments/13fcw36/langchain_is_pointless/))
    that have users speak in more detail.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: While Hamilton is not a complete replacement for current LLM frameworks (e.g.
    there is no â€œagentâ€ component), it *does* have all the building blocks to meet
    your LLM application needs and both can work in conjunction. If you want a clean,
    clear, and customizable way to write production code, integrate several LLM stack
    components, and gain observability over your app, then letâ€™s move onto the next
    few sections!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Building with Hamilton
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hamilton is a declarative micro-framework to describe [dataflows](https://en.wikipedia.org/wiki/Dataflow)
    in Python. Itâ€™s not a new framework (3.5+ years old), and has been used for years
    in production modeling data & machine learning dataflows. Its strength is expressing
    the flow of data & computation in a way that is straightforward to create and
    maintain (much like DBT does for SQL), which lends itself very well to support
    modeling the data & computational needs of LLM applications.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ac83c0914a4533f8f7429b752d511120.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: The Hamilton paradigm in a picture. Instead of procedural assignment, you instead
    model it as a function. The function name is an â€œoutputâ€ you can get, while the
    function input arguments declare dependencies on whatâ€™s required to be computed.
    Image by author.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: 'The basics of Hamilton are simple, and it can be extended in quite a few ways;
    you don''t have to know Hamilton to get value out of this post, but if you''re
    interested, check out:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '[tryhamilton.dev](https://www.tryhamilton.dev/) â€“ an interactive tutorial in
    your browser!'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Pandas data transformations in Hamilton in 5 minutes](/how-to-use-hamilton-with-pandas-in-5-minutes-89f63e5af8f5)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Lineage + Hamilton in 10 minutes](https://blog.dagworks.io/p/lineage-hamilton-in-10-minutes-c2b8a944e2e6)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hamilton + Airflow for production](https://blog.dagworks.io/publish/post/130538397)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Onto our example
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To help set some mental context, picture this. Youâ€™re a small data team that
    is tasked with creating an LLM application to â€œchatâ€ with your organizationâ€™s
    document. You believe itâ€™s important to evaluate candidate architectures in terms
    of features, performance profile, licenses, infrastructure requirements, and costs.
    Ultimately, you know your organizationâ€™s primary concern is providing the most
    relevant results and a great user experience. The best way to assess this is to
    build a prototype, test different stacks and compare their characteristics and
    outputs. Then when you transition to production, youâ€™ll want confidence that the
    system can be maintained and introspected easily, to consistently provide a great
    user experience.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: 'With that in mind, in this example, we will implement part of an LLM application,
    specifically the data ingestion step to index a knowledge base, where we convert
    text to embeddings and store them in a vector database. We implement this in a
    modular with a few different services/technologies. The broad steps are:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Load the [SQuAD dataset](https://huggingface.co/datasets/squad) from the HuggingFace
    Hub. You would swap this out for your corpus of preprocessed documents.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Embed text entries using the [Cohere API](https://docs.cohere.com/reference/embed),
    the [OpenAI API](https://platform.openai.com/docs/api-reference/embeddings), or
    the [SentenceTransformer library](https://www.sbert.net/examples/applications/computing-embeddings/README.html).
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Store embeddings in a vector database, either [LanceDB](https://lancedb.github.io/lancedb/),
    [Pinecone](https://docs.pinecone.io/docs/overview), or [Weaviate](https://weaviate.io/developers/weaviate).
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you need to know more about embeddings & search, we direct readers to the
    following links:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '[Text embeddings explained - Weaviate](https://weaviate.io/blog/vector-embeddings-explained)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How-to conduct semantic search with Pinecone](https://docs.pinecone.io/docs/semantic-text-search)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As weâ€™re walking through this example, it would be useful for you to think
    about/keep in mind the following:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '**Compare what we show you with what youâ€™re doing now.** See how Hamilton enables
    you to curate and structure a project without needing an explicit LLM-centric
    framework.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Project and application structure.** Understand how Hamilton enforces a structure
    that enables you to build and maintain a modular stack.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Confidence in iteration & project longevity.** Combining the above two points,
    Hamilton enables you to more easily maintain an LLM application in production,
    no matter who authored it.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Letâ€™s start with a visualization to give you an overview of what weâ€™re talking
    about:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/149c01e23dbcb8ef11df1a74517ca8f3.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
- en: Hamilton DAG visualization of Pinecone + Sentence transformer stack. Image by
    author.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: Hereâ€™s what the LLM Application dataflow would look like when using pinecone
    with sentence transformers. With Hamilton to understand how things connect is
    just as simple as `display_all_functions()` call on the [Hamilton driver object](https://hamilton.dagworks.io/en/latest/reference/drivers/Driver/#hamilton.driver.Driver.display_all_functions).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Modular Code
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Letâ€™s explain the two main ways to implement modular code with Hamilton using
    our example for context.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '@config.when'
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hamiltonâ€™s focus is on readability. Without explaining what `@config.when` does,
    you can probably tell that this is a conditional statement, and only included
    *when* the predicate is satisfied. Below you will find the implementation for
    converting text to embeddings with the OpenAI and the Cohere API.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: Hamilton will recognize two functions as alternative implementations because
    of the `@config.when` decorator and the same function name `embeddings` preceding
    the double underscore (`__cohere`, `__openai`). Their function signatures need
    not be entirely the same, which means it's easy and clear to adopt different implementations.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Hamilton å°†è¯†åˆ«ä¸¤ä¸ªå‡½æ•°ä½œä¸ºæ›¿ä»£å®ç°ï¼Œå› ä¸º`@config.when`è£…é¥°å™¨å’Œç›¸åŒçš„å‡½æ•°åç§°`embeddings`ä½äºåŒä¸‹åˆ’çº¿ï¼ˆ`__cohere`ã€`__openai`ï¼‰ä¹‹å‰ã€‚å®ƒä»¬çš„å‡½æ•°ç­¾åä¸å¿…å®Œå…¨ç›¸åŒï¼Œè¿™æ„å‘³ç€é‡‡çº³ä¸åŒå®ç°æ˜¯ç®€å•ä¸”æ¸…æ™°çš„ã€‚
- en: embedding_module.py
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: embedding_module.py
- en: For this project, it made sense to have all embedding services implemented in
    the same file with the `@config.when` decorator since there are only 3 functions
    per service. However, as the project grows in complexity, functions could be moved
    to separate modules too, and the next sectionâ€™s modularity pattern employed instead.
    Another point to note is that each of these functions is independently unit-testable.
    Should you have specific needs, itâ€™s straightforward to encapsulate it in the
    function and test it.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¿™ä¸ªé¡¹ç›®ï¼Œå°†æ‰€æœ‰åµŒå…¥æœåŠ¡å®ç°æ”¾åœ¨åŒä¸€ä¸ªæ–‡ä»¶ä¸­å¹¶ä½¿ç”¨`@config.when`è£…é¥°å™¨æ˜¯åˆç†çš„ï¼Œå› ä¸ºæ¯ä¸ªæœåŠ¡åªæœ‰ 3 ä¸ªå‡½æ•°ã€‚ç„¶è€Œï¼Œéšç€é¡¹ç›®å¤æ‚æ€§çš„å¢é•¿ï¼Œå‡½æ•°ä¹Ÿå¯ä»¥ç§»åŠ¨åˆ°å•ç‹¬çš„æ¨¡å—ä¸­ï¼Œå¹¶é‡‡ç”¨ä¸‹ä¸€èŠ‚çš„æ¨¡å—åŒ–æ¨¡å¼ã€‚å¦ä¸€ä¸ªè¦ç‚¹æ˜¯è¿™äº›å‡½æ•°éƒ½æ˜¯ç‹¬ç«‹å¯å•å…ƒæµ‹è¯•çš„ã€‚å¦‚æœä½ æœ‰ç‰¹å®šçš„éœ€æ±‚ï¼Œå°†å…¶å°è£…åˆ°å‡½æ•°ä¸­å¹¶è¿›è¡Œæµ‹è¯•æ˜¯å¾ˆç®€å•çš„ã€‚
- en: Switching out python modules
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ›´æ¢ Python æ¨¡å—
- en: Below you will find the implementation of vector database operations for Pinecone
    and Weaviate. Note that the snippets are from `pinecone_module.py` and `weaviate_module.py`
    and notice how function signatures resemble and differ.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢ä½ å°†çœ‹åˆ° Pinecone å’Œ Weaviate çš„å‘é‡æ•°æ®åº“æ“ä½œå®ç°ã€‚è¯·æ³¨æ„ï¼Œè¿™äº›ä»£ç ç‰‡æ®µæ¥è‡ª`pinecone_module.py`å’Œ`weaviate_module.py`ï¼Œå¹¶è§‚å¯Ÿå‡½æ•°ç­¾åçš„ç›¸ä¼¼ä¹‹å¤„å’Œä¸åŒä¹‹å¤„ã€‚
- en: pinecone_module.py and weaviate_module.py
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: pinecone_module.py å’Œ weaviate_module.py
- en: With Hamilton, the dataflow is stitched together using function names and function
    input arguments. Therefore by sharing function names for similar operations, the
    two modules are easily interchangeable. Since the LanceDB, Pinecone, and Weaviate
    implementations reside in separate modules, it reduces the number of dependencies
    per file and makes them shorter, improving both readability and maintainability.
    The logic for each implementation is clearly encapsulated in these named functions,
    so unit testing is straightforward to implement for each respective module. The
    separate modules reinforce the idea that they shouldnâ€™t be loaded simultaneously.
    The Hamilton driver will actually throw an error when multiple functions with
    the same name are found that helps enforce this concept.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Hamilton æ—¶ï¼Œæ•°æ®æµé€šè¿‡å‡½æ•°åç§°å’Œå‡½æ•°è¾“å…¥å‚æ•°è¿æ¥åœ¨ä¸€èµ·ã€‚å› æ­¤ï¼Œé€šè¿‡å…±äº«ç±»ä¼¼æ“ä½œçš„å‡½æ•°åç§°ï¼Œè¿™ä¸¤ä¸ªæ¨¡å—å¯ä»¥è½»æ¾äº’æ¢ã€‚ç”±äº LanceDBã€Pinecone
    å’Œ Weaviate å®ç°åˆ†åˆ«å­˜åœ¨äºä¸åŒçš„æ¨¡å—ä¸­ï¼Œè¿™å‡å°‘äº†æ¯ä¸ªæ–‡ä»¶çš„ä¾èµ–æ•°é‡ï¼Œä½¿æ–‡ä»¶æ›´çŸ­ï¼Œä»è€Œæé«˜äº†å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚æ¯ä¸ªå®ç°çš„é€»è¾‘éƒ½æ¸…æ™°åœ°å°è£…åœ¨è¿™äº›å‘½åå‡½æ•°ä¸­ï¼Œå› æ­¤é’ˆå¯¹æ¯ä¸ªæ¨¡å—è¿›è¡Œå•å…ƒæµ‹è¯•æ˜¯ç›´æ¥å¯è¡Œçš„ã€‚åˆ†ç¦»çš„æ¨¡å—å¼ºåŒ–äº†å®ƒä»¬ä¸åº”åŒæ—¶åŠ è½½çš„æ¦‚å¿µã€‚å½“å‘ç°å¤šä¸ªç›¸åŒåç§°çš„å‡½æ•°æ—¶ï¼ŒHamilton
    é©±åŠ¨ç¨‹åºå®é™…ä¸Šä¼šæŠ›å‡ºé”™è¯¯ï¼Œè¿™æœ‰åŠ©äºåŠ å¼ºè¿™ä¸€æ¦‚å¿µã€‚
- en: Driver implications
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é©±åŠ¨ç¨‹åºçš„å½±å“
- en: 'The key part for running Hamilton code is the `Driver` object found in `run.py`.
    Excluding the code for the CLI and some argument parsing, we get:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: è¿è¡Œ Hamilton ä»£ç çš„å…³é”®éƒ¨åˆ†æ˜¯`Driver`å¯¹è±¡ï¼Œå®ƒåœ¨`run.py`ä¸­æ‰¾åˆ°ã€‚æ’é™¤ CLI å’Œä¸€äº›å‚æ•°è§£æçš„ä»£ç ï¼Œæˆ‘ä»¬å¾—åˆ°ï¼š
- en: Snippet of run.py
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: run.py çš„ä»£ç ç‰‡æ®µ
- en: 'The Hamilton Driver, which orchestrates execution and is what you manipulate
    your dataflow through, allows modularity through three mechanisms as seen in the
    above code snippet:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Hamilton é©±åŠ¨ç¨‹åºè´Ÿè´£åè°ƒæ‰§è¡Œï¼Œå¹¶ä¸”æ˜¯ä½ é€šè¿‡å®ƒæ“æ§æ•°æ®æµçš„å·¥å…·ï¼Œé€šè¿‡ä¸Šè¿°ä»£ç ç‰‡æ®µä¸­çœ‹åˆ°çš„ä¸‰ç§æœºåˆ¶å®ç°äº†æ¨¡å—åŒ–ï¼š
- en: '**Driver configuration.** this is a dictionary the driver receives at instantiation
    containing information that should remain constant, such as which API to use,
    or the embedding service API key. This integrates well with a command plane that
    can pass JSON or strings (e.g., a Docker container, [Airflow](https://blog.dagworks.io/publish/posts/detail/130538397),
    [Metaflow](https://outerbounds.com/blog/developing-scalable-feature-engineering-dags/),
    etc.). Concretely this is where weâ€™d specify swapping out what embedding API to
    use.'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Driver é…ç½®ã€‚** è¿™æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œé©±åŠ¨ç¨‹åºåœ¨å®ä¾‹åŒ–æ—¶æ¥æ”¶è¯¥å­—å…¸ï¼ŒåŒ…å«åº”è¯¥ä¿æŒä¸å˜çš„ä¿¡æ¯ï¼Œä¾‹å¦‚ä½¿ç”¨å“ªä¸ª API æˆ–åµŒå…¥æœåŠ¡ API å¯†é’¥ã€‚è¿™ä¸å¯ä»¥ä¼ é€’
    JSON æˆ–å­—ç¬¦ä¸²çš„å‘½ä»¤å¹³é¢ï¼ˆä¾‹å¦‚ Docker å®¹å™¨ã€[Airflow](https://blog.dagworks.io/publish/posts/detail/130538397)ã€[Metaflow](https://outerbounds.com/blog/developing-scalable-feature-engineering-dags/)
    ç­‰ï¼‰å¾ˆå¥½åœ°é›†æˆã€‚å…·ä½“æ¥è¯´ï¼Œè¿™é‡Œæ˜¯æˆ‘ä»¬æŒ‡å®šè¦æ›´æ¢å“ªä¸ªåµŒå…¥ API çš„åœ°æ–¹ã€‚'
- en: '**Driver modules.** the driver can receive an arbitrary number of independent
    Python modules to build the dataflow from. Here, the `vector_db_module` can be
    swapped in for the desired vector database implementation weâ€™re connecting to.
    One can also import modules dynamically through [importlib](https://docs.python.org/3/library/importlib.html#importlib.import_module),
    which can be useful for development vs production contexts, and also enable a
    configuration driven way to changing the dataflow implementation.'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**é©±åŠ¨ç¨‹åºæ¨¡å—ã€‚** é©±åŠ¨ç¨‹åºå¯ä»¥æ¥æ”¶ä»»æ„æ•°é‡çš„ç‹¬ç«‹ Python æ¨¡å—æ¥æ„å»ºæ•°æ®æµã€‚åœ¨è¿™é‡Œï¼Œ`vector_db_module` å¯ä»¥æ›¿æ¢ä¸ºæˆ‘ä»¬è¿æ¥çš„æ‰€éœ€å‘é‡æ•°æ®åº“å®ç°ã€‚è¿˜å¯ä»¥é€šè¿‡
    [importlib](https://docs.python.org/3/library/importlib.html#importlib.import_module)
    åŠ¨æ€å¯¼å…¥æ¨¡å—ï¼Œè¿™åœ¨å¼€å‘ä¸ç”Ÿäº§ç¯å¢ƒä¸­å¯èƒ½å¾ˆæœ‰ç”¨ï¼ŒåŒæ—¶ä¹Ÿèƒ½å®ç°é€šè¿‡é…ç½®é©±åŠ¨çš„æ–¹å¼æ¥æ”¹å˜æ•°æ®æµå®ç°ã€‚'
- en: '**Driver execution.** The `final_vars` parameter determines what output should
    be returned. You do not need to restructure your code to change what output you
    want to get. Letâ€™s take the case of wanting to debug something within our dataflow,
    it is possible to request the output of any function by adding its name to `final_vars`.
    For example, if you have some intermediate output to debug, itâ€™s easy to request
    it, or stop execution at that spot entirely. Note, the driver can receive `inputs`
    and `overrides` values when calling `execute()`; in the code above, the `class_name`
    is an execution time `input` that indicates the embedding object we want to create
    and where to store it in our vector database.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**é©±åŠ¨ç¨‹åºæ‰§è¡Œã€‚** `final_vars` å‚æ•°å†³å®šäº†åº”è¯¥è¿”å›ä»€ä¹ˆè¾“å‡ºã€‚ä½ æ— éœ€é‡æ„ä»£ç æ¥æ”¹å˜æƒ³è¦è·å¾—çš„è¾“å‡ºã€‚ä¸¾ä¸ªä¾‹å­ï¼Œå¦‚æœä½ æƒ³è°ƒè¯•æ•°æ®æµä¸­çš„æŸäº›å†…å®¹ï¼Œå¯ä»¥é€šè¿‡å°†å‡½æ•°çš„åç§°æ·»åŠ åˆ°
    `final_vars` æ¥è¯·æ±‚ä»»ä½•å‡½æ•°çš„è¾“å‡ºã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ æœ‰ä¸€äº›ä¸­é—´è¾“å‡ºéœ€è¦è°ƒè¯•ï¼Œå¯ä»¥å¾ˆå®¹æ˜“åœ°è¯·æ±‚å®ƒï¼Œæˆ–è€…å®Œå…¨åœ¨é‚£ä¸ªç‚¹åœæ­¢æ‰§è¡Œã€‚è¯·æ³¨æ„ï¼Œé©±åŠ¨ç¨‹åºåœ¨è°ƒç”¨ `execute()`
    æ—¶å¯ä»¥æ¥æ”¶ `inputs` å’Œ `overrides` å€¼ï¼›åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œ`class_name` æ˜¯ä¸€ä¸ªæ‰§è¡Œæ—¶çš„ `input`ï¼ŒæŒ‡ç¤ºæˆ‘ä»¬è¦åˆ›å»ºçš„åµŒå…¥å¯¹è±¡ä»¥åŠå°†å…¶å­˜å‚¨åœ¨å‘é‡æ•°æ®åº“ä¸­çš„ä½ç½®ã€‚'
- en: Modularity Summary
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¨¡å—åŒ–æ€»ç»“
- en: 'In Hamilton, the key to enable swappable components is to:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ Hamilton ä¸­ï¼Œä½¿ç»„ä»¶å¯äº’æ¢çš„å…³é”®æ˜¯ï¼š
- en: define functions with effectively the same name and then,
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å®šä¹‰å…·æœ‰ç›¸åŒåç§°çš„å‡½æ•°ï¼Œç„¶åï¼Œ
- en: annotate them with `@config.when` and choose which one to use via configuration
    passed to the driver, or,
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ `@config.when` å¯¹å®ƒä»¬è¿›è¡Œæ³¨è§£ï¼Œå¹¶é€šè¿‡ä¼ é€’ç»™é©±åŠ¨ç¨‹åºçš„é…ç½®é€‰æ‹©ä½¿ç”¨å“ªä¸€ä¸ªï¼Œæˆ–è€…ï¼Œ
- en: put them in separate python modules and pass in the desired module to the driver.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†å®ƒä»¬æ”¾åœ¨ä¸åŒçš„ Python æ¨¡å—ä¸­ï¼Œå¹¶å°†æ‰€éœ€çš„æ¨¡å—ä¼ é€’ç»™é©±åŠ¨ç¨‹åºã€‚
- en: So weâ€™ve just shown how you can plugin, swap, and call various LLM components
    with Hamilton. We didnâ€™t need to explain what an object oriented hierarchy is,
    nor require you to have extensive software engineering experience to follow (we
    hope!). To accomplish this, we just had to match function names, and their output
    types. We think this way of writing and modularizing code is therefore more accessible
    than current LLM frameworks permit.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬åˆšåˆšå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ Hamilton æ’ä»¶ã€äº¤æ¢å’Œè°ƒç”¨å„ç§ LLM ç»„ä»¶ã€‚æˆ‘ä»¬æ— éœ€è§£é‡Šä»€ä¹ˆæ˜¯é¢å‘å¯¹è±¡çš„å±‚æ¬¡ç»“æ„ï¼Œä¹Ÿä¸è¦æ±‚ä½ å…·å¤‡å¹¿æ³›çš„è½¯ä»¶å·¥ç¨‹ç»éªŒï¼ˆæˆ‘ä»¬å¸Œæœ›å¦‚æ­¤ï¼ï¼‰ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬åªéœ€åŒ¹é…å‡½æ•°åç§°åŠå…¶è¾“å‡ºç±»å‹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è®¤ä¸ºè¿™ç§ç¼–å†™å’Œæ¨¡å—åŒ–ä»£ç çš„æ–¹å¼æ¯”å½“å‰
    LLM æ¡†æ¶æ‰€å…è®¸çš„æ›´åŠ å¯è®¿é—®ã€‚
- en: Hamilton code in practice
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hamilton ä»£ç çš„å®é™…åº”ç”¨
- en: 'To add to our claims, here a few practical implications of writing Hamilton
    code for LLM workflows that weâ€™ve observed:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ”¯æŒæˆ‘ä»¬çš„ä¸»å¼ ï¼Œè¿™é‡Œæœ‰ä¸€äº›æˆ‘ä»¬è§‚å¯Ÿåˆ°çš„å°† Hamilton ä»£ç åº”ç”¨äº LLM å·¥ä½œæµçš„å®é™…å½±å“ï¼š
- en: CI/CD
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CI/CD
- en: This ability to swap out modules/`@config.when` also means that integration
    testing in a CI system is straightforward to think about, since you have the flexibility
    and freedom to swap/isolate parts of the dataflow as desired.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å—/`@config.when` çš„å¯äº’æ¢æ€§ä¹Ÿæ„å‘³ç€åœ¨ CI ç³»ç»Ÿä¸­çš„é›†æˆæµ‹è¯•éå¸¸å®¹æ˜“æ€è€ƒï¼Œå› ä¸ºä½ å¯ä»¥æ ¹æ®éœ€è¦çµæ´»åœ°äº¤æ¢æˆ–éš”ç¦»æ•°æ®æµçš„éƒ¨åˆ†ã€‚
- en: Collaboration
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åä½œ
- en: The modularity Hamilton enables can allow one to mirror cross team boundaries
    easily. The function names & their output types become a contract, which ensures
    one can make surgical changes and be confident in the change, as well as have
    the visibility into downstream dependencies with Hamiltonâ€™s [visualization and
    lineage features](https://blog.dagworks.io/p/lineage-hamilton-in-10-minutes-c2b8a944e2e6)
    (like the initial visualization we saw). For example, itâ€™s clear how to interact
    and consume from the vector database.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Hamilton å®ç°çš„æ¨¡å—åŒ–å¯ä»¥è½»æ¾è·¨å›¢é˜Ÿè¾¹ç•Œé•œåƒã€‚å‡½æ•°åç§°åŠå…¶è¾“å‡ºç±»å‹æˆä¸ºåˆåŒï¼Œç¡®ä¿å¯ä»¥è¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„æ›´æ”¹å¹¶å¯¹æ›´æ”¹å……æ»¡ä¿¡å¿ƒï¼Œè¿˜å¯ä»¥é€šè¿‡ Hamilton
    çš„ [å¯è§†åŒ–å’Œè¡€ç»ŸåŠŸèƒ½](https://blog.dagworks.io/p/lineage-hamilton-in-10-minutes-c2b8a944e2e6)
    äº†è§£ä¸‹æ¸¸ä¾èµ–å…³ç³»ï¼ˆå°±åƒæˆ‘ä»¬çœ‹åˆ°çš„åˆå§‹å¯è§†åŒ–ä¸€æ ·ï¼‰ã€‚ä¾‹å¦‚ï¼Œå¦‚ä½•ä¸å‘é‡æ•°æ®åº“äº¤äº’å¹¶è¿›è¡Œæ¶ˆè´¹å°±éå¸¸æ¸…æ™°ã€‚
- en: Code changes are simpler to review, because the flow is defined by declarative
    functions. The changes are self-contained; because there is no object oriented
    hierarchy to learn, just a function to modify. Anything â€œcustomâ€ is de facto supported
    by Hamilton.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä»£ç æ›´æ”¹æ›´æ˜“äºå®¡æŸ¥ï¼Œå› ä¸ºæµç¨‹ç”±å£°æ˜å¼å‡½æ•°å®šä¹‰ã€‚æ›´æ”¹æ˜¯è‡ªåŒ…å«çš„ï¼›ç”±äºæ²¡æœ‰é¢å‘å¯¹è±¡çš„å±‚æ¬¡ç»“æ„éœ€è¦å­¦ä¹ ï¼Œåªéœ€ä¿®æ”¹ä¸€ä¸ªå‡½æ•°ã€‚ä»»ä½•â€œè‡ªå®šä¹‰â€çš„å†…å®¹éƒ½è¢«Hamiltoné»˜è®¤æ”¯æŒã€‚
- en: Debugging
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è°ƒè¯•
- en: When there is an error with Hamilton, itâ€™s clear as to what the code it maps
    to is, and because of how the function is defined, one knows where to place it
    within the dataflow.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: å½“Hamiltonå‡ºç°é”™è¯¯æ—¶ï¼Œå¾ˆæ¸…æ¥šå®ƒæ˜ å°„åˆ°çš„ä»£ç æ˜¯ä»€ä¹ˆï¼Œå¹¶ä¸”ç”±äºå‡½æ•°çš„å®šä¹‰ï¼Œä½ çŸ¥é“å®ƒåœ¨æ•°æ®æµä¸­çš„ä½ç½®ã€‚
- en: Take the simple example of the embeddings function using cohere. If there was
    a time out, or error in parsing the response it would be clear that it maps to
    this code, and from the function definition youâ€™d know where in the flow it fits.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä½¿ç”¨cohereçš„embeddingså‡½æ•°ä¸ºç®€å•ç¤ºä¾‹ã€‚å¦‚æœå‘ç”Ÿè¶…æ—¶æˆ–è§£æå“åº”æ—¶å‡ºé”™ï¼Œå°†æ¸…æ¥šåœ°æ˜ å°„åˆ°è¿™æ®µä»£ç ï¼Œå¹¶ä¸”é€šè¿‡å‡½æ•°å®šä¹‰ä½ ä¼šçŸ¥é“å®ƒåœ¨æµç¨‹ä¸­çš„ä½ç½®ã€‚
- en: '[PRE0]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/ed4bd30c315330f5fcec9bd4984202c4.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ed4bd30c315330f5fcec9bd4984202c4.png)'
- en: Visualization showing where `embeddings` fits in the dataflow. Image by author.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: å¯è§†åŒ–æ˜¾ç¤º`embeddings`åœ¨æ•°æ®æµä¸­çš„ä½ç½®ã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚
- en: Tips for creating a modular LLM stack
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åˆ›å»ºæ¨¡å—åŒ–LLMå †æ ˆçš„æŠ€å·§
- en: Before we finish, here are some ideas to guide you through building your application.
    Some decisions might not have an obvious best choice, but having the right approach
    to modularity will allow you to efficiently iterate as requirements evolve.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç»“æŸä¹‹å‰ï¼Œè¿™é‡Œæœ‰ä¸€äº›æƒ³æ³•æ¥æŒ‡å¯¼ä½ æ„å»ºåº”ç”¨ç¨‹åºã€‚æŸäº›å†³ç­–å¯èƒ½æ²¡æœ‰æ˜æ˜¾çš„æœ€ä½³é€‰æ‹©ï¼Œä½†æ­£ç¡®çš„æ¨¡å—åŒ–æ–¹æ³•å°†ä½¿ä½ èƒ½å¤Ÿéšç€éœ€æ±‚çš„å˜åŒ–é«˜æ•ˆè¿­ä»£ã€‚
- en: Before writing any code, draw a DAG of the logical steps of your workflow. This
    sets the basis for defining common steps and interfaces that are not service-specific.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨ç¼–å†™ä»»ä½•ä»£ç ä¹‹å‰ï¼Œç»˜åˆ¶ä½ çš„å·¥ä½œæµçš„DAGã€‚è¿™ä¸ºå®šä¹‰é€šç”¨æ­¥éª¤å’Œæ¥å£å¥ å®šäº†åŸºç¡€ï¼Œè¿™äº›æ­¥éª¤å’Œæ¥å£ä¸æ˜¯ç‰¹å®šäºæœåŠ¡çš„ã€‚
- en: Identify steps that could be swapped. By being purposeful with configuration
    points, you will reduce risks of [speculative generality](https://refactoring.guru/smells/speculative-generality).
    Concretely, this would result in functions with less arguments, default values,
    and grouped into thematic modules.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç¡®å®šå¯ä»¥äº¤æ¢çš„æ­¥éª¤ã€‚é€šè¿‡æœ‰ç›®çš„åœ°è®¾ç½®é…ç½®ç‚¹ï¼Œä½ å°†å‡å°‘[æŠ•æœºæ³›åŒ–](https://refactoring.guru/smells/speculative-generality)çš„é£é™©ã€‚å…·ä½“æ¥è¯´ï¼Œè¿™å°†å¯¼è‡´å…·æœ‰è¾ƒå°‘å‚æ•°ã€é»˜è®¤å€¼ä¸”æŒ‰ä¸»é¢˜æ¨¡å—åˆ†ç»„çš„å‡½æ•°ã€‚
- en: Chunk parts of your dataflow into modules with few dependencies, if relevant.
    This will lead to shorter Python files with fewer package dependencies, improved
    readability and maintainability. Hamilton is indifferent and can build its DAG
    from multiple modules.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†æ•°æ®æµçš„éƒ¨åˆ†åˆ‡åˆ†æˆä¾èµ–è¾ƒå°‘çš„æ¨¡å—ï¼ˆå¦‚æœ‰ç›¸å…³ï¼‰ã€‚è¿™å°†å¯¼è‡´æ›´çŸ­çš„Pythonæ–‡ä»¶ï¼Œå‡å°‘åŒ…ä¾èµ–ï¼Œæé«˜å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚Hamiltonå¯¹æ­¤ä¸åœ¨æ„ï¼Œå¯ä»¥ä»å¤šä¸ªæ¨¡å—æ„å»ºå…¶DAGã€‚
- en: To close & future directions
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®ºä¸æœªæ¥æ–¹å‘
- en: 'Thanks for getting this far. We believe that Hamilton has a part to play in
    helping everyone express their dataflows, and LLM applications are just one use
    case! To summarize our messaging in this post can be boiled down to:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢ä½ é˜…è¯»åˆ°è¿™é‡Œã€‚æˆ‘ä»¬ç›¸ä¿¡Hamiltonåœ¨å¸®åŠ©æ¯ä¸ªäººè¡¨è¾¾ä»–ä»¬çš„æ•°æ®æµæ–¹é¢æœ‰ä¸€å®šä½œç”¨ï¼Œè€ŒLLMåº”ç”¨ç¨‹åºåªæ˜¯å…¶ä¸­ä¸€ä¸ªç”¨ä¾‹ï¼æ€»ç»“æˆ‘ä»¬åœ¨è¿™ç¯‡æ–‡ç« ä¸­çš„ä¿¡æ¯ï¼Œå¯ä»¥å½’çº³ä¸ºï¼š
- en: It is useful to conceive of LLM applications as dataflows, and are therefore
    a great fit for using Hamilton.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†LLMåº”ç”¨ç¨‹åºè§†ä¸ºæ•°æ®æµæ˜¯æœ‰ç”¨çš„ï¼Œå› æ­¤éå¸¸é€‚åˆä½¿ç”¨Hamiltonã€‚
- en: Object-centric LLM frameworks can be opaque and hard to extend and maintain
    for your production needs. Instead, one should write their own integrations with
    Hamiltonâ€™s straightforward declarative style. Doing so will improve your codeâ€™s
    transparency and maintainability, with clear testable functions, clear mapping
    of runtime errors to functions, and built-in visualization of your dataflow.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é¢å‘å¯¹è±¡çš„LLMæ¡†æ¶å¯èƒ½ä¸é€æ˜ä¸”éš¾ä»¥æ‰©å±•å’Œç»´æŠ¤ä»¥æ»¡è¶³ç”Ÿäº§éœ€æ±‚ã€‚ç›¸åï¼Œåº”è¯¥ä½¿ç”¨Hamiltonç®€å•çš„å£°æ˜å¼é£æ ¼ç¼–å†™è‡ªå·±çš„é›†æˆã€‚è¿™æ ·å¯ä»¥æé«˜ä»£ç çš„é€æ˜åº¦å’Œå¯ç»´æŠ¤æ€§ï¼Œå…·æœ‰æ¸…æ™°çš„å¯æµ‹è¯•å‡½æ•°ã€æ˜ç¡®çš„è¿è¡Œæ—¶é”™è¯¯æ˜ å°„åˆ°å‡½æ•°çš„æ–¹å¼ï¼Œä»¥åŠå†…ç½®çš„æ•°æ®æµå¯è§†åŒ–ã€‚
- en: The modularity prescribed by using Hamilton will make collaboration more efficient
    and provide you with the requisite flexibility to modify and change your LLM workflows
    at the speed at which the field is moving.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Hamiltonæ‰€è§„å®šçš„æ¨¡å—åŒ–å°†ä½¿åä½œæ›´é«˜æ•ˆï¼Œå¹¶ä¸ºä½ æä¾›å¿…è¦çš„çµæ´»æ€§ï¼Œä»¥ä¾¿æŒ‰ç…§è¯¥é¢†åŸŸçš„è¿›å±•é€Ÿåº¦ä¿®æ”¹å’Œæ›´æ”¹LLMå·¥ä½œæµã€‚
- en: 'We now invite you to play around with, try, and modify the full example for
    yourselves [here](https://github.com/DAGWorks-Inc/hamilton/tree/main/examples/LLM_Workflows/modular_llm_stack).
    There is a `README` that will explain the commands to run and get started. Otherwise,
    we are working on making the Hamilton + LLM Application experience even better
    by thinking about the following:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨é‚€è¯·ä½ åœ¨[è¿™é‡Œ](https://github.com/DAGWorks-Inc/hamilton/tree/main/examples/LLM_Workflows/modular_llm_stack)ç©è½¬ã€å°è¯•å’Œä¿®æ”¹å®Œæ•´çš„ç¤ºä¾‹ã€‚è¿™é‡Œæœ‰ä¸€ä¸ª`README`æ–‡ä»¶ä¼šè§£é‡Šå¦‚ä½•è¿è¡Œå‘½ä»¤å’Œå¼€å§‹ä½¿ç”¨ã€‚å¦åˆ™ï¼Œæˆ‘ä»¬æ­£åœ¨æ€è€ƒä»¥ä¸‹å†…å®¹æ¥æå‡
    Hamilton + LLM åº”ç”¨ä½“éªŒï¼š
- en: '**Agents.** Can we provide the same level of visibility to agents that we have
    for regular Hamilton dataflows?'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ä»£ç†ã€‚** æˆ‘ä»¬èƒ½å¦ä¸ºä»£ç†æä¾›ä¸å¸¸è§„ Hamilton æ•°æ®æµç›¸åŒçš„å¯è§†æ€§ï¼Ÿ'
- en: '**Parallelization.** How can we make it simpler to express running a dataflow
    over a list of documents for example. See this [work in progress PR](https://github.com/DAGWorks-Inc/hamilton/pull/216)
    for what we mean.'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å¹¶è¡ŒåŒ–ã€‚** æˆ‘ä»¬å¦‚ä½•ç®€åŒ–åœ¨æ–‡æ¡£åˆ—è¡¨ä¸Šè¿è¡Œæ•°æ®æµçš„è¡¨è¾¾æ–¹å¼ã€‚è¯·å‚è§è¿™ä¸ª[è¿›è¡Œä¸­çš„ PR](https://github.com/DAGWorks-Inc/hamilton/pull/216)äº†è§£æˆ‘ä»¬çš„æ„æ€ã€‚'
- en: '**Plugins for caching and observability.** One can already implement a custom
    caching and observability solution on top of Hamilton. Weâ€™re working on providing
    more standard options out of the box for common components, e.g. redis.'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ç¼“å­˜å’Œå¯è§‚å¯Ÿæ€§çš„æ’ä»¶ã€‚** ç›®å‰å·²ç»å¯ä»¥åœ¨ Hamilton ä¸Šå®ç°è‡ªå®šä¹‰çš„ç¼“å­˜å’Œå¯è§‚å¯Ÿæ€§è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬æ­£åœ¨è‡´åŠ›äºä¸ºå¸¸è§ç»„ä»¶æä¾›æ›´å¤šçš„æ ‡å‡†é€‰é¡¹ï¼Œä¾‹å¦‚
    redisã€‚'
- en: '**A user contributed dataflows section.** We see the possibility to standardize
    on common names for specific LLM application use cases. In which case we can start
    to aggregate Hamilton dataflows, and allow people to pull them down for their
    needs.'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ç”¨æˆ·è´¡çŒ®çš„æ•°æ®æµéƒ¨åˆ†ã€‚** æˆ‘ä»¬çœ‹åˆ°å¯ä»¥åœ¨ç‰¹å®š LLM åº”ç”¨ç”¨ä¾‹ä¸Šæ ‡å‡†åŒ–å¸¸è§åç§°çš„å¯èƒ½æ€§ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹èšåˆ Hamilton æ•°æ®æµï¼Œå¹¶å…è®¸äººä»¬æ ¹æ®è‡ªå·±çš„éœ€æ±‚ä¸‹è½½ã€‚'
- en: We want to hear from you!
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æƒ³å¬å¬ä½ çš„æ„è§ï¼
- en: 'If youâ€™re excited by any of this, or have strong opinions, drop by our Slack
    channel / or leave some comments here! Some resources to get you help:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å¯¹è¿™äº›å†…å®¹æ„Ÿåˆ°å…´å¥‹ï¼Œæˆ–æœ‰å¼ºçƒˆçš„çœ‹æ³•ï¼Œæ¬¢è¿è®¿é—®æˆ‘ä»¬çš„ Slack é¢‘é“æˆ–åœ¨è¿™é‡Œç•™ä¸‹è¯„è®ºï¼ä¸€äº›å¯ä»¥å¸®åŠ©ä½ çš„èµ„æºï¼š
- en: ğŸ“£ join our community on [Slack](https://hamilton-opensource.slack.com/join/shared_invite/zt-1bjs72asx-wcUTgH7q7QX1igiQ5bbdcg#/shared-invite/email)
    â€” weâ€™re more than happy to help answer questions you might have or get you started.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ“£ åŠ å…¥æˆ‘ä»¬çš„[Slack](https://hamilton-opensource.slack.com/join/shared_invite/zt-1bjs72asx-wcUTgH7q7QX1igiQ5bbdcg#/shared-invite/email)ç¤¾åŒº
    â€” æˆ‘ä»¬å¾ˆä¹æ„å¸®åŠ©è§£ç­”ä½ å¯èƒ½é‡åˆ°çš„é—®é¢˜æˆ–å¸®åŠ©ä½ å…¥é—¨ã€‚
- en: â­ï¸ us on [GitHub](https://github.com/DAGWorks-Inc/hamilton)
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: â­ï¸ åœ¨[GitHub](https://github.com/DAGWorks-Inc/hamilton)ä¸Šç»™æˆ‘ä»¬ç‚¹èµ
- en: ğŸ“ leave us an [issue](https://github.com/DAGWorks-Inc/hamilton/issues) if you
    find something
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ“ å¦‚æœä½ å‘ç°äº†é—®é¢˜ï¼Œè¯·ç»™æˆ‘ä»¬ç•™ä¸‹ä¸€ä¸ª[issue](https://github.com/DAGWorks-Inc/hamilton/issues)
- en: 'Other Hamilton posts you might be interested in:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½æ„Ÿå…´è¶£çš„å…¶ä»– Hamilton æ–‡ç« ï¼š
- en: '[tryhamilton.dev](https://www.tryhamilton.dev/) â€“ an interactive tutorial in
    your browser!'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[tryhamilton.dev](https://www.tryhamilton.dev/) â€“ ä¸€ä¸ªåœ¨æµè§ˆå™¨ä¸­è¿›è¡Œäº¤äº’å¼æ•™ç¨‹çš„å¹³å°ï¼'
- en: '[Pandas data transformations in Hamilton in 5 minutes](https://blog.dagworks.io/p/how-to-use-hamilton-with-pandas-in-5-minutes-89f63e5af8f5)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5åˆ†é’Ÿå†…åœ¨ Hamilton ä¸­è¿›è¡Œ Pandas æ•°æ®è½¬æ¢](https://blog.dagworks.io/p/how-to-use-hamilton-with-pandas-in-5-minutes-89f63e5af8f5)'
- en: '[Lineage + Hamilton in 10 minutes](https://blog.dagworks.io/p/lineage-hamilton-in-10-minutes-c2b8a944e2e6)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10åˆ†é’Ÿå†…äº†è§£ Lineage + Hamilton](https://blog.dagworks.io/p/lineage-hamilton-in-10-minutes-c2b8a944e2e6)'
- en: '[Hamilton + Airflow for production](https://blog.dagworks.io/publish/post/130538397)'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Hamilton + Airflow ç”Ÿäº§ç¯å¢ƒ](https://blog.dagworks.io/publish/post/130538397)'
