- en: Building a maintainable and modular LLM application stack with Hamilton in 13
    minutes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用 Hamilton 在 13 分钟内构建一个可维护且模块化的 LLM 应用堆栈
- en: 原文：[https://towardsdatascience.com/building-a-maintainable-and-modular-llm-application-stack-with-hamilton-baa68e55e8cd?source=collection_archive---------10-----------------------#2023-07-13](https://towardsdatascience.com/building-a-maintainable-and-modular-llm-application-stack-with-hamilton-baa68e55e8cd?source=collection_archive---------10-----------------------#2023-07-13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/building-a-maintainable-and-modular-llm-application-stack-with-hamilton-baa68e55e8cd?source=collection_archive---------10-----------------------#2023-07-13](https://towardsdatascience.com/building-a-maintainable-and-modular-llm-application-stack-with-hamilton-baa68e55e8cd?source=collection_archive---------10-----------------------#2023-07-13)
- en: LLM Applications are dataflows, use a tool specifically designed to express
    them
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM 应用是数据流，使用专门设计的工具来表达它们
- en: '[](https://medium.com/@stefan.krawczyk?source=post_page-----baa68e55e8cd--------------------------------)[![Stefan
    Krawczyk](../Images/150405abaad9590e1dc2589168ed2fa3.png)](https://medium.com/@stefan.krawczyk?source=post_page-----baa68e55e8cd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----baa68e55e8cd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----baa68e55e8cd--------------------------------)
    [Stefan Krawczyk](https://medium.com/@stefan.krawczyk?source=post_page-----baa68e55e8cd--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@stefan.krawczyk?source=post_page-----baa68e55e8cd--------------------------------)[![Stefan
    Krawczyk](../Images/150405abaad9590e1dc2589168ed2fa3.png)](https://medium.com/@stefan.krawczyk?source=post_page-----baa68e55e8cd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----baa68e55e8cd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----baa68e55e8cd--------------------------------)
    [Stefan Krawczyk](https://medium.com/@stefan.krawczyk?source=post_page-----baa68e55e8cd--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F193628e26f00&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-maintainable-and-modular-llm-application-stack-with-hamilton-baa68e55e8cd&user=Stefan+Krawczyk&userId=193628e26f00&source=post_page-193628e26f00----baa68e55e8cd---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----baa68e55e8cd--------------------------------)
    ·13 min read·Jul 13, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbaa68e55e8cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-maintainable-and-modular-llm-application-stack-with-hamilton-baa68e55e8cd&user=Stefan+Krawczyk&userId=193628e26f00&source=-----baa68e55e8cd---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F193628e26f00&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-maintainable-and-modular-llm-application-stack-with-hamilton-baa68e55e8cd&user=Stefan+Krawczyk&userId=193628e26f00&source=post_page-193628e26f00----baa68e55e8cd---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----baa68e55e8cd--------------------------------)
    ·13 分钟阅读·2023年7月13日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbaa68e55e8cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-maintainable-and-modular-llm-application-stack-with-hamilton-baa68e55e8cd&user=Stefan+Krawczyk&userId=193628e26f00&source=-----baa68e55e8cd---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbaa68e55e8cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-maintainable-and-modular-llm-application-stack-with-hamilton-baa68e55e8cd&source=-----baa68e55e8cd---------------------bookmark_footer-----------)![](../Images/84bcb5f1c47c2c34ce7c753f621da5a8.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbaa68e55e8cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-maintainable-and-modular-llm-application-stack-with-hamilton-baa68e55e8cd&source=-----baa68e55e8cd---------------------bookmark_footer-----------)![](../Images/84bcb5f1c47c2c34ce7c753f621da5a8.png)'
- en: LLM stacks. Using the right tool, like Hamilton, can sure your stack doesn’t
    become a pain to maintain and manage. Image from [pixabay](https://pixabay.com/photos/books-stack-book-store-1163695/).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 堆栈。使用合适的工具，如 Hamilton，可以确保你的堆栈不会变得难以维护和管理。图片来源于 [pixabay](https://pixabay.com/photos/books-stack-book-store-1163695/)。
- en: '*This post is written in collaboration with* [*Thierry Jean*](https://medium.com/u/cf12dc7f8440)
    *and originally appeared* [*here*](https://blog.dagworks.io/p/building-a-maintainable-and-modular)*.*'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*此文章与* [*Thierry Jean*](https://medium.com/u/cf12dc7f8440) *合作撰写，最初发布于* [*此处*](https://blog.dagworks.io/p/building-a-maintainable-and-modular)。'
- en: 'In this post, we’re going to share how [Hamilton](https://github.com/dagWorks-Inc/hamilton),
    an open source framework, can help you write modular and maintainable code for
    your large language model (LLM) application stack. Hamilton is great for describing
    any type of [dataflow](https://en.wikipedia.org/wiki/Dataflow), which is exactly
    what you’re doing when building an LLM powered application. With Hamilton you
    get strong [software maintenance ergonomics](https://ceur-ws.org/Vol-3306/paper5.pdf),
    with the added benefit of being able to easily swap and evaluate different providers/implementations
    for components of your application. Disclaimer: I’m one of the authors of the
    Hamilton package.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将分享如何使用[Hamilton](https://github.com/dagWorks-Inc/hamilton)这一开源框架来编写模块化和可维护的代码，以支持你的大型语言模型（LLM）应用程序堆栈。Hamilton
    非常适合描述任何类型的[数据流](https://en.wikipedia.org/wiki/Dataflow)，这正是你在构建 LLM 驱动应用程序时所做的。通过
    Hamilton，你可以获得强大的[软件维护人机工程学](https://ceur-ws.org/Vol-3306/paper5.pdf)，同时还能轻松地交换和评估应用程序组件的不同提供者/实现。免责声明：我是
    Hamilton 包的作者之一。
- en: The example we’ll walk you through will mirror a typical LLM application workflow
    you’d run to populate a vector database with some text knowledge. Specifically,
    we’ll cover pulling data from the web, creating text embeddings (vectors) and
    pushing them to a vector store.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将演示的示例将镜像你用于填充向量数据库的典型 LLM 应用程序工作流程。具体来说，我们将涵盖从网络中提取数据、创建文本嵌入（向量）并将其推送到向量存储中。
- en: '![](../Images/3af6ce8a4bc5b6f967b1e28e6085bcc0.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3af6ce8a4bc5b6f967b1e28e6085bcc0.png)'
- en: Stack overview. Image by authors.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 堆栈概述。作者提供的图像。
- en: The LLM application dataflow
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM 应用程序数据流
- en: To start, let’s describe what a typical LLM dataflow consists of. The application
    will receive a small data input (e.g., a text, a command) and act within a larger
    context (e.g., chat history, documents, state). This data will move through different
    services (LLM, vector database, document store, etc.) to perform operations, generate
    new data artifacts, and return final results. Most use cases repeat this flow
    multiple times while iterating over different inputs.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们描述一下典型的 LLM 数据流的组成。应用程序将接收一个小的数据输入（例如文本、命令），并在更大的上下文中进行操作（例如聊天记录、文档、状态）。这些数据将通过不同的服务（LLM、向量数据库、文档存储等）进行操作、生成新的数据工件，并返回最终结果。大多数用例会在迭代不同输入的过程中重复这一流程多次。
- en: 'Some common operations include:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 一些常见的操作包括：
- en: Convert text to embeddings
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将文本转换为嵌入
- en: Store / search / retrieve embeddings
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储 / 搜索 / 检索嵌入
- en: Find nearest neighbors to an embedding
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查找嵌入的最近邻
- en: Retrieve text for an embedding
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检索用于嵌入的文本
- en: Determine context required to pass into a prompt
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定传递到提示中的上下文
- en: Prompt models with context from relevant text
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用相关文本中的上下文提示模型
- en: Send results to another service (API, database, etc.)
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将结果发送到其他服务（API、数据库等）
- en: …
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: …
- en: and chaining them together!
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并将它们串联起来！
- en: Now, let’s think about the above in a production context, and imagine a user
    is unsatisfied with the outputs of your application and you want to find the root
    cause of the issue. Your application logged both the prompt and the results. Your
    code allows you to figure out the sequence of operations. Yet, you have no clue
    where things went wrong and the system produced undesirable output… To mitigate
    this, we’d argue it’s critical then to have lineage of data artifacts and the
    code that produces them, so you can debug situations such as these quickly.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在生产环境中深入探讨上述内容，假设用户对你的应用程序的输出不满意，并且你想找到问题的根源。你的应用程序记录了提示和结果。你的代码允许你找出操作的顺序。然而，你不知道问题出在哪里，系统产生了不理想的输出……为了解决这个问题，我们认为跟踪数据工件及生成它们的代码是关键，这样你才能快速调试类似的情况。
- en: To add to the complexity of your LLM application dataflow, many operations are
    non-deterministic, meaning you can’t rerun or reverse engineer the operation to
    reproduce intermediate results. For example, an API call to generate a text or
    image response will likely be non-reproducible even if you have access to the
    same input and configuration (you *can* *mitigate some of this* with options such
    as [temperature](https://platform.openai.com/docs/api-reference/chat/create#chat/create-temperature)).
    This also extends to certain vector database operations like “find nearest” where
    the result depends on the objects currently stored in the database. In production
    settings, it is prohibitive to near impossible to snapshot DB states to make calls
    reproducible.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 由于许多操作是非确定性的，这增加了你的LLM应用程序数据流的复杂性，这意味着你不能重新运行或逆向工程操作以重现中间结果。例如，即使你拥有相同的输入和配置，生成文本或图像响应的API调用可能也是不可重复的（你*可以*通过如[temperature](https://platform.openai.com/docs/api-reference/chat/create#chat/create-temperature)这样的选项*缓解部分问题*）。这也扩展到某些向量数据库操作，如“查找最近”——其结果取决于数据库中当前存储的对象。在生产环境中，快照数据库状态以使调用可重复几乎是不现实的。
- en: 'For these reasons, it is important to adopt flexible tooling to create robust
    dataflows that allow you to:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这些原因，采用灵活的工具以创建稳健的数据流很重要，这样可以让你：
- en: plugin in various components easily.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 轻松地插入各种组件。
- en: see how components connect to each other.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 了解组件之间如何连接。
- en: add and customize common production needs like caching, validation, and observability.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加和定制常见的生产需求，如缓存、验证和可观察性。
- en: adjust the flow structure to your needs without requiring a strong engineering
    skill set
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据你的需求调整流结构，而不需要强大的工程技能
- en: plug into the traditional data processing and machine learning ecosystem.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 插件集成到传统的数据处理和机器学习生态系统中。
- en: In this post we’ll give an overview of how Hamilton fulfills points 1, 2, &
    4\. We refer you to our [documentation](https://hamilton.dagworks.io/en/latest/)
    for points 3 & 5.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将概述Hamilton如何满足第1、2和4点。有关第3和5点的信息，请参阅我们的[文档](https://hamilton.dagworks.io/en/latest/)。
- en: Current LLM application development tooling
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当前的LLM应用程序开发工具
- en: The LLM space is still in its infancy, and the usage patterns and tooling are
    rapidly evolving. While LLM frameworks can get you started, current options are
    not production tested; to our knowledge, no established tech companies are using
    the current popular LLM frameworks in production.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: LLM领域仍处于起步阶段，使用模式和工具正在快速演变。虽然LLM框架可以让你入门，但当前的选项并未经过生产环境测试；据我们了解，目前没有成熟的科技公司在生产中使用当前流行的LLM框架。
- en: 'Don’t get us wrong, some of the tooling out there is great for getting a quick
    proof of concept up and running! However, we feel they fall short in two specific
    areas:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 别误解我们的意思，有些工具确实非常适合快速建立概念验证！然而，我们认为它们在两个特定领域存在不足：
- en: '**1\. How to model the LLM application’s dataflow.** We strongly believe that
    the dataflow of “actions” is better modeled as functions, rather than through
    object oriented classes and lifecycles. Functions are much simpler to reason about,
    test, and change. Object oriented classes can become quite opaque and impose more
    mental burden.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**1\. 如何建模LLM应用程序的数据流。** 我们强烈认为“动作”的数据流建模更适合用函数来表示，而不是通过面向对象的类和生命周期。函数更容易推理、测试和更改。面向对象的类可能变得相当晦涩，并带来更多的思维负担。'
- en: When something errors, object-oriented frameworks require you to drill into
    the objects’ source code to understand it. Whereas with Hamilton functions, a
    clear dependency lineage tells you where to look and helps you reason about what
    happened (more on this below)!
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当出现错误时，面向对象的框架需要你深入到对象的源代码中以理解它。而使用Hamilton函数时，清晰的依赖关系谱能告诉你在哪里查找，并帮助你推理发生了什么（更多信息请见下文）！
- en: '**2\. Customization/extensions.** Unfortunately you need a strong software
    engineering skill set to modify the current frameworks once you step outside the
    bounds of what they make “easy” to do. If that’s not an option, this means you
    can end up stepping outside the framework for a particular piece of custom business
    logic, which can inadvertently lead you to maintaining more code surface area
    than if you didn’t use the framework in the first place.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 定制/扩展。** 不幸的是，一旦你超出框架提供的“简单”功能，你需要强大的软件工程技能来修改当前框架。如果这不是一个选项，这意味着你可能会在特定的自定义业务逻辑上脱离框架，这可能会导致你维护更多的代码面积，而不是如果你一开始就不使用框架的话。'
- en: For more on these two points we point you to threads such as these two ([hacker
    news](https://news.ycombinator.com/item?id=36645575#36647985), [reddit](https://old.reddit.com/r/LangChain/comments/13fcw36/langchain_is_pointless/))
    that have users speak in more detail.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: While Hamilton is not a complete replacement for current LLM frameworks (e.g.
    there is no “agent” component), it *does* have all the building blocks to meet
    your LLM application needs and both can work in conjunction. If you want a clean,
    clear, and customizable way to write production code, integrate several LLM stack
    components, and gain observability over your app, then let’s move onto the next
    few sections!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Building with Hamilton
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hamilton is a declarative micro-framework to describe [dataflows](https://en.wikipedia.org/wiki/Dataflow)
    in Python. It’s not a new framework (3.5+ years old), and has been used for years
    in production modeling data & machine learning dataflows. Its strength is expressing
    the flow of data & computation in a way that is straightforward to create and
    maintain (much like DBT does for SQL), which lends itself very well to support
    modeling the data & computational needs of LLM applications.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ac83c0914a4533f8f7429b752d511120.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: The Hamilton paradigm in a picture. Instead of procedural assignment, you instead
    model it as a function. The function name is an “output” you can get, while the
    function input arguments declare dependencies on what’s required to be computed.
    Image by author.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: 'The basics of Hamilton are simple, and it can be extended in quite a few ways;
    you don''t have to know Hamilton to get value out of this post, but if you''re
    interested, check out:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '[tryhamilton.dev](https://www.tryhamilton.dev/) – an interactive tutorial in
    your browser!'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Pandas data transformations in Hamilton in 5 minutes](/how-to-use-hamilton-with-pandas-in-5-minutes-89f63e5af8f5)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Lineage + Hamilton in 10 minutes](https://blog.dagworks.io/p/lineage-hamilton-in-10-minutes-c2b8a944e2e6)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hamilton + Airflow for production](https://blog.dagworks.io/publish/post/130538397)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Onto our example
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To help set some mental context, picture this. You’re a small data team that
    is tasked with creating an LLM application to “chat” with your organization’s
    document. You believe it’s important to evaluate candidate architectures in terms
    of features, performance profile, licenses, infrastructure requirements, and costs.
    Ultimately, you know your organization’s primary concern is providing the most
    relevant results and a great user experience. The best way to assess this is to
    build a prototype, test different stacks and compare their characteristics and
    outputs. Then when you transition to production, you’ll want confidence that the
    system can be maintained and introspected easily, to consistently provide a great
    user experience.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: 'With that in mind, in this example, we will implement part of an LLM application,
    specifically the data ingestion step to index a knowledge base, where we convert
    text to embeddings and store them in a vector database. We implement this in a
    modular with a few different services/technologies. The broad steps are:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Load the [SQuAD dataset](https://huggingface.co/datasets/squad) from the HuggingFace
    Hub. You would swap this out for your corpus of preprocessed documents.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Embed text entries using the [Cohere API](https://docs.cohere.com/reference/embed),
    the [OpenAI API](https://platform.openai.com/docs/api-reference/embeddings), or
    the [SentenceTransformer library](https://www.sbert.net/examples/applications/computing-embeddings/README.html).
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Store embeddings in a vector database, either [LanceDB](https://lancedb.github.io/lancedb/),
    [Pinecone](https://docs.pinecone.io/docs/overview), or [Weaviate](https://weaviate.io/developers/weaviate).
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you need to know more about embeddings & search, we direct readers to the
    following links:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '[Text embeddings explained - Weaviate](https://weaviate.io/blog/vector-embeddings-explained)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How-to conduct semantic search with Pinecone](https://docs.pinecone.io/docs/semantic-text-search)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As we’re walking through this example, it would be useful for you to think
    about/keep in mind the following:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '**Compare what we show you with what you’re doing now.** See how Hamilton enables
    you to curate and structure a project without needing an explicit LLM-centric
    framework.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Project and application structure.** Understand how Hamilton enforces a structure
    that enables you to build and maintain a modular stack.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Confidence in iteration & project longevity.** Combining the above two points,
    Hamilton enables you to more easily maintain an LLM application in production,
    no matter who authored it.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s start with a visualization to give you an overview of what we’re talking
    about:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/149c01e23dbcb8ef11df1a74517ca8f3.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
- en: Hamilton DAG visualization of Pinecone + Sentence transformer stack. Image by
    author.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: Here’s what the LLM Application dataflow would look like when using pinecone
    with sentence transformers. With Hamilton to understand how things connect is
    just as simple as `display_all_functions()` call on the [Hamilton driver object](https://hamilton.dagworks.io/en/latest/reference/drivers/Driver/#hamilton.driver.Driver.display_all_functions).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Modular Code
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s explain the two main ways to implement modular code with Hamilton using
    our example for context.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '@config.when'
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hamilton’s focus is on readability. Without explaining what `@config.when` does,
    you can probably tell that this is a conditional statement, and only included
    *when* the predicate is satisfied. Below you will find the implementation for
    converting text to embeddings with the OpenAI and the Cohere API.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: Hamilton will recognize two functions as alternative implementations because
    of the `@config.when` decorator and the same function name `embeddings` preceding
    the double underscore (`__cohere`, `__openai`). Their function signatures need
    not be entirely the same, which means it's easy and clear to adopt different implementations.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Hamilton 将识别两个函数作为替代实现，因为`@config.when`装饰器和相同的函数名称`embeddings`位于双下划线（`__cohere`、`__openai`）之前。它们的函数签名不必完全相同，这意味着采纳不同实现是简单且清晰的。
- en: embedding_module.py
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: embedding_module.py
- en: For this project, it made sense to have all embedding services implemented in
    the same file with the `@config.when` decorator since there are only 3 functions
    per service. However, as the project grows in complexity, functions could be moved
    to separate modules too, and the next section’s modularity pattern employed instead.
    Another point to note is that each of these functions is independently unit-testable.
    Should you have specific needs, it’s straightforward to encapsulate it in the
    function and test it.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个项目，将所有嵌入服务实现放在同一个文件中并使用`@config.when`装饰器是合理的，因为每个服务只有 3 个函数。然而，随着项目复杂性的增长，函数也可以移动到单独的模块中，并采用下一节的模块化模式。另一个要点是这些函数都是独立可单元测试的。如果你有特定的需求，将其封装到函数中并进行测试是很简单的。
- en: Switching out python modules
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更换 Python 模块
- en: Below you will find the implementation of vector database operations for Pinecone
    and Weaviate. Note that the snippets are from `pinecone_module.py` and `weaviate_module.py`
    and notice how function signatures resemble and differ.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 下面你将看到 Pinecone 和 Weaviate 的向量数据库操作实现。请注意，这些代码片段来自`pinecone_module.py`和`weaviate_module.py`，并观察函数签名的相似之处和不同之处。
- en: pinecone_module.py and weaviate_module.py
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: pinecone_module.py 和 weaviate_module.py
- en: With Hamilton, the dataflow is stitched together using function names and function
    input arguments. Therefore by sharing function names for similar operations, the
    two modules are easily interchangeable. Since the LanceDB, Pinecone, and Weaviate
    implementations reside in separate modules, it reduces the number of dependencies
    per file and makes them shorter, improving both readability and maintainability.
    The logic for each implementation is clearly encapsulated in these named functions,
    so unit testing is straightforward to implement for each respective module. The
    separate modules reinforce the idea that they shouldn’t be loaded simultaneously.
    The Hamilton driver will actually throw an error when multiple functions with
    the same name are found that helps enforce this concept.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Hamilton 时，数据流通过函数名称和函数输入参数连接在一起。因此，通过共享类似操作的函数名称，这两个模块可以轻松互换。由于 LanceDB、Pinecone
    和 Weaviate 实现分别存在于不同的模块中，这减少了每个文件的依赖数量，使文件更短，从而提高了可读性和可维护性。每个实现的逻辑都清晰地封装在这些命名函数中，因此针对每个模块进行单元测试是直接可行的。分离的模块强化了它们不应同时加载的概念。当发现多个相同名称的函数时，Hamilton
    驱动程序实际上会抛出错误，这有助于加强这一概念。
- en: Driver implications
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 驱动程序的影响
- en: 'The key part for running Hamilton code is the `Driver` object found in `run.py`.
    Excluding the code for the CLI and some argument parsing, we get:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 Hamilton 代码的关键部分是`Driver`对象，它在`run.py`中找到。排除 CLI 和一些参数解析的代码，我们得到：
- en: Snippet of run.py
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: run.py 的代码片段
- en: 'The Hamilton Driver, which orchestrates execution and is what you manipulate
    your dataflow through, allows modularity through three mechanisms as seen in the
    above code snippet:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Hamilton 驱动程序负责协调执行，并且是你通过它操控数据流的工具，通过上述代码片段中看到的三种机制实现了模块化：
- en: '**Driver configuration.** this is a dictionary the driver receives at instantiation
    containing information that should remain constant, such as which API to use,
    or the embedding service API key. This integrates well with a command plane that
    can pass JSON or strings (e.g., a Docker container, [Airflow](https://blog.dagworks.io/publish/posts/detail/130538397),
    [Metaflow](https://outerbounds.com/blog/developing-scalable-feature-engineering-dags/),
    etc.). Concretely this is where we’d specify swapping out what embedding API to
    use.'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Driver 配置。** 这是一个字典，驱动程序在实例化时接收该字典，包含应该保持不变的信息，例如使用哪个 API 或嵌入服务 API 密钥。这与可以传递
    JSON 或字符串的命令平面（例如 Docker 容器、[Airflow](https://blog.dagworks.io/publish/posts/detail/130538397)、[Metaflow](https://outerbounds.com/blog/developing-scalable-feature-engineering-dags/)
    等）很好地集成。具体来说，这里是我们指定要更换哪个嵌入 API 的地方。'
- en: '**Driver modules.** the driver can receive an arbitrary number of independent
    Python modules to build the dataflow from. Here, the `vector_db_module` can be
    swapped in for the desired vector database implementation we’re connecting to.
    One can also import modules dynamically through [importlib](https://docs.python.org/3/library/importlib.html#importlib.import_module),
    which can be useful for development vs production contexts, and also enable a
    configuration driven way to changing the dataflow implementation.'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**驱动程序模块。** 驱动程序可以接收任意数量的独立 Python 模块来构建数据流。在这里，`vector_db_module` 可以替换为我们连接的所需向量数据库实现。还可以通过
    [importlib](https://docs.python.org/3/library/importlib.html#importlib.import_module)
    动态导入模块，这在开发与生产环境中可能很有用，同时也能实现通过配置驱动的方式来改变数据流实现。'
- en: '**Driver execution.** The `final_vars` parameter determines what output should
    be returned. You do not need to restructure your code to change what output you
    want to get. Let’s take the case of wanting to debug something within our dataflow,
    it is possible to request the output of any function by adding its name to `final_vars`.
    For example, if you have some intermediate output to debug, it’s easy to request
    it, or stop execution at that spot entirely. Note, the driver can receive `inputs`
    and `overrides` values when calling `execute()`; in the code above, the `class_name`
    is an execution time `input` that indicates the embedding object we want to create
    and where to store it in our vector database.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**驱动程序执行。** `final_vars` 参数决定了应该返回什么输出。你无需重构代码来改变想要获得的输出。举个例子，如果你想调试数据流中的某些内容，可以通过将函数的名称添加到
    `final_vars` 来请求任何函数的输出。例如，如果你有一些中间输出需要调试，可以很容易地请求它，或者完全在那个点停止执行。请注意，驱动程序在调用 `execute()`
    时可以接收 `inputs` 和 `overrides` 值；在上面的代码中，`class_name` 是一个执行时的 `input`，指示我们要创建的嵌入对象以及将其存储在向量数据库中的位置。'
- en: Modularity Summary
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模块化总结
- en: 'In Hamilton, the key to enable swappable components is to:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Hamilton 中，使组件可互换的关键是：
- en: define functions with effectively the same name and then,
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义具有相同名称的函数，然后，
- en: annotate them with `@config.when` and choose which one to use via configuration
    passed to the driver, or,
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `@config.when` 对它们进行注解，并通过传递给驱动程序的配置选择使用哪一个，或者，
- en: put them in separate python modules and pass in the desired module to the driver.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将它们放在不同的 Python 模块中，并将所需的模块传递给驱动程序。
- en: So we’ve just shown how you can plugin, swap, and call various LLM components
    with Hamilton. We didn’t need to explain what an object oriented hierarchy is,
    nor require you to have extensive software engineering experience to follow (we
    hope!). To accomplish this, we just had to match function names, and their output
    types. We think this way of writing and modularizing code is therefore more accessible
    than current LLM frameworks permit.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们刚刚展示了如何使用 Hamilton 插件、交换和调用各种 LLM 组件。我们无需解释什么是面向对象的层次结构，也不要求你具备广泛的软件工程经验（我们希望如此！）。为了实现这一点，我们只需匹配函数名称及其输出类型。因此，我们认为这种编写和模块化代码的方式比当前
    LLM 框架所允许的更加可访问。
- en: Hamilton code in practice
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hamilton 代码的实际应用
- en: 'To add to our claims, here a few practical implications of writing Hamilton
    code for LLM workflows that we’ve observed:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 为了支持我们的主张，这里有一些我们观察到的将 Hamilton 代码应用于 LLM 工作流的实际影响：
- en: CI/CD
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CI/CD
- en: This ability to swap out modules/`@config.when` also means that integration
    testing in a CI system is straightforward to think about, since you have the flexibility
    and freedom to swap/isolate parts of the dataflow as desired.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 模块/`@config.when` 的可互换性也意味着在 CI 系统中的集成测试非常容易思考，因为你可以根据需要灵活地交换或隔离数据流的部分。
- en: Collaboration
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 协作
- en: The modularity Hamilton enables can allow one to mirror cross team boundaries
    easily. The function names & their output types become a contract, which ensures
    one can make surgical changes and be confident in the change, as well as have
    the visibility into downstream dependencies with Hamilton’s [visualization and
    lineage features](https://blog.dagworks.io/p/lineage-hamilton-in-10-minutes-c2b8a944e2e6)
    (like the initial visualization we saw). For example, it’s clear how to interact
    and consume from the vector database.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Hamilton 实现的模块化可以轻松跨团队边界镜像。函数名称及其输出类型成为合同，确保可以进行有针对性的更改并对更改充满信心，还可以通过 Hamilton
    的 [可视化和血统功能](https://blog.dagworks.io/p/lineage-hamilton-in-10-minutes-c2b8a944e2e6)
    了解下游依赖关系（就像我们看到的初始可视化一样）。例如，如何与向量数据库交互并进行消费就非常清晰。
- en: Code changes are simpler to review, because the flow is defined by declarative
    functions. The changes are self-contained; because there is no object oriented
    hierarchy to learn, just a function to modify. Anything “custom” is de facto supported
    by Hamilton.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代码更改更易于审查，因为流程由声明式函数定义。更改是自包含的；由于没有面向对象的层次结构需要学习，只需修改一个函数。任何“自定义”的内容都被Hamilton默认支持。
- en: Debugging
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调试
- en: When there is an error with Hamilton, it’s clear as to what the code it maps
    to is, and because of how the function is defined, one knows where to place it
    within the dataflow.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当Hamilton出现错误时，很清楚它映射到的代码是什么，并且由于函数的定义，你知道它在数据流中的位置。
- en: Take the simple example of the embeddings function using cohere. If there was
    a time out, or error in parsing the response it would be clear that it maps to
    this code, and from the function definition you’d know where in the flow it fits.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 以使用cohere的embeddings函数为简单示例。如果发生超时或解析响应时出错，将清楚地映射到这段代码，并且通过函数定义你会知道它在流程中的位置。
- en: '[PRE0]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/ed4bd30c315330f5fcec9bd4984202c4.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ed4bd30c315330f5fcec9bd4984202c4.png)'
- en: Visualization showing where `embeddings` fits in the dataflow. Image by author.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化显示`embeddings`在数据流中的位置。图像由作者提供。
- en: Tips for creating a modular LLM stack
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建模块化LLM堆栈的技巧
- en: Before we finish, here are some ideas to guide you through building your application.
    Some decisions might not have an obvious best choice, but having the right approach
    to modularity will allow you to efficiently iterate as requirements evolve.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束之前，这里有一些想法来指导你构建应用程序。某些决策可能没有明显的最佳选择，但正确的模块化方法将使你能够随着需求的变化高效迭代。
- en: Before writing any code, draw a DAG of the logical steps of your workflow. This
    sets the basis for defining common steps and interfaces that are not service-specific.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在编写任何代码之前，绘制你的工作流的DAG。这为定义通用步骤和接口奠定了基础，这些步骤和接口不是特定于服务的。
- en: Identify steps that could be swapped. By being purposeful with configuration
    points, you will reduce risks of [speculative generality](https://refactoring.guru/smells/speculative-generality).
    Concretely, this would result in functions with less arguments, default values,
    and grouped into thematic modules.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定可以交换的步骤。通过有目的地设置配置点，你将减少[投机泛化](https://refactoring.guru/smells/speculative-generality)的风险。具体来说，这将导致具有较少参数、默认值且按主题模块分组的函数。
- en: Chunk parts of your dataflow into modules with few dependencies, if relevant.
    This will lead to shorter Python files with fewer package dependencies, improved
    readability and maintainability. Hamilton is indifferent and can build its DAG
    from multiple modules.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据流的部分切分成依赖较少的模块（如有相关）。这将导致更短的Python文件，减少包依赖，提高可读性和可维护性。Hamilton对此不在意，可以从多个模块构建其DAG。
- en: To close & future directions
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论与未来方向
- en: 'Thanks for getting this far. We believe that Hamilton has a part to play in
    helping everyone express their dataflows, and LLM applications are just one use
    case! To summarize our messaging in this post can be boiled down to:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢你阅读到这里。我们相信Hamilton在帮助每个人表达他们的数据流方面有一定作用，而LLM应用程序只是其中一个用例！总结我们在这篇文章中的信息，可以归纳为：
- en: It is useful to conceive of LLM applications as dataflows, and are therefore
    a great fit for using Hamilton.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将LLM应用程序视为数据流是有用的，因此非常适合使用Hamilton。
- en: Object-centric LLM frameworks can be opaque and hard to extend and maintain
    for your production needs. Instead, one should write their own integrations with
    Hamilton’s straightforward declarative style. Doing so will improve your code’s
    transparency and maintainability, with clear testable functions, clear mapping
    of runtime errors to functions, and built-in visualization of your dataflow.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 面向对象的LLM框架可能不透明且难以扩展和维护以满足生产需求。相反，应该使用Hamilton简单的声明式风格编写自己的集成。这样可以提高代码的透明度和可维护性，具有清晰的可测试函数、明确的运行时错误映射到函数的方式，以及内置的数据流可视化。
- en: The modularity prescribed by using Hamilton will make collaboration more efficient
    and provide you with the requisite flexibility to modify and change your LLM workflows
    at the speed at which the field is moving.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Hamilton所规定的模块化将使协作更高效，并为你提供必要的灵活性，以便按照该领域的进展速度修改和更改LLM工作流。
- en: 'We now invite you to play around with, try, and modify the full example for
    yourselves [here](https://github.com/DAGWorks-Inc/hamilton/tree/main/examples/LLM_Workflows/modular_llm_stack).
    There is a `README` that will explain the commands to run and get started. Otherwise,
    we are working on making the Hamilton + LLM Application experience even better
    by thinking about the following:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在邀请你在[这里](https://github.com/DAGWorks-Inc/hamilton/tree/main/examples/LLM_Workflows/modular_llm_stack)玩转、尝试和修改完整的示例。这里有一个`README`文件会解释如何运行命令和开始使用。否则，我们正在思考以下内容来提升
    Hamilton + LLM 应用体验：
- en: '**Agents.** Can we provide the same level of visibility to agents that we have
    for regular Hamilton dataflows?'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**代理。** 我们能否为代理提供与常规 Hamilton 数据流相同的可视性？'
- en: '**Parallelization.** How can we make it simpler to express running a dataflow
    over a list of documents for example. See this [work in progress PR](https://github.com/DAGWorks-Inc/hamilton/pull/216)
    for what we mean.'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**并行化。** 我们如何简化在文档列表上运行数据流的表达方式。请参见这个[进行中的 PR](https://github.com/DAGWorks-Inc/hamilton/pull/216)了解我们的意思。'
- en: '**Plugins for caching and observability.** One can already implement a custom
    caching and observability solution on top of Hamilton. We’re working on providing
    more standard options out of the box for common components, e.g. redis.'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**缓存和可观察性的插件。** 目前已经可以在 Hamilton 上实现自定义的缓存和可观察性解决方案。我们正在致力于为常见组件提供更多的标准选项，例如
    redis。'
- en: '**A user contributed dataflows section.** We see the possibility to standardize
    on common names for specific LLM application use cases. In which case we can start
    to aggregate Hamilton dataflows, and allow people to pull them down for their
    needs.'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**用户贡献的数据流部分。** 我们看到可以在特定 LLM 应用用例上标准化常见名称的可能性。在这种情况下，我们可以开始聚合 Hamilton 数据流，并允许人们根据自己的需求下载。'
- en: We want to hear from you!
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们想听听你的意见！
- en: 'If you’re excited by any of this, or have strong opinions, drop by our Slack
    channel / or leave some comments here! Some resources to get you help:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对这些内容感到兴奋，或有强烈的看法，欢迎访问我们的 Slack 频道或在这里留下评论！一些可以帮助你的资源：
- en: 📣 join our community on [Slack](https://hamilton-opensource.slack.com/join/shared_invite/zt-1bjs72asx-wcUTgH7q7QX1igiQ5bbdcg#/shared-invite/email)
    — we’re more than happy to help answer questions you might have or get you started.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 📣 加入我们的[Slack](https://hamilton-opensource.slack.com/join/shared_invite/zt-1bjs72asx-wcUTgH7q7QX1igiQ5bbdcg#/shared-invite/email)社区
    — 我们很乐意帮助解答你可能遇到的问题或帮助你入门。
- en: ⭐️ us on [GitHub](https://github.com/DAGWorks-Inc/hamilton)
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ⭐️ 在[GitHub](https://github.com/DAGWorks-Inc/hamilton)上给我们点赞
- en: 📝 leave us an [issue](https://github.com/DAGWorks-Inc/hamilton/issues) if you
    find something
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 📝 如果你发现了问题，请给我们留下一个[issue](https://github.com/DAGWorks-Inc/hamilton/issues)
- en: 'Other Hamilton posts you might be interested in:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能感兴趣的其他 Hamilton 文章：
- en: '[tryhamilton.dev](https://www.tryhamilton.dev/) – an interactive tutorial in
    your browser!'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[tryhamilton.dev](https://www.tryhamilton.dev/) – 一个在浏览器中进行交互式教程的平台！'
- en: '[Pandas data transformations in Hamilton in 5 minutes](https://blog.dagworks.io/p/how-to-use-hamilton-with-pandas-in-5-minutes-89f63e5af8f5)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5分钟内在 Hamilton 中进行 Pandas 数据转换](https://blog.dagworks.io/p/how-to-use-hamilton-with-pandas-in-5-minutes-89f63e5af8f5)'
- en: '[Lineage + Hamilton in 10 minutes](https://blog.dagworks.io/p/lineage-hamilton-in-10-minutes-c2b8a944e2e6)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10分钟内了解 Lineage + Hamilton](https://blog.dagworks.io/p/lineage-hamilton-in-10-minutes-c2b8a944e2e6)'
- en: '[Hamilton + Airflow for production](https://blog.dagworks.io/publish/post/130538397)'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Hamilton + Airflow 生产环境](https://blog.dagworks.io/publish/post/130538397)'
