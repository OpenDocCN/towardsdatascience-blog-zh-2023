- en: Elegant prompt versioning and LLM model configuration with spacy-llm
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 spacy-llm 进行优雅的提示版本管理和 LLM 模型配置
- en: 原文：[https://towardsdatascience.com/elegant-prompt-versioning-and-llm-model-configuration-with-spacy-llm-126b836daad1?source=collection_archive---------3-----------------------#2023-07-26](https://towardsdatascience.com/elegant-prompt-versioning-and-llm-model-configuration-with-spacy-llm-126b836daad1?source=collection_archive---------3-----------------------#2023-07-26)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/elegant-prompt-versioning-and-llm-model-configuration-with-spacy-llm-126b836daad1?source=collection_archive---------3-----------------------#2023-07-26](https://towardsdatascience.com/elegant-prompt-versioning-and-llm-model-configuration-with-spacy-llm-126b836daad1?source=collection_archive---------3-----------------------#2023-07-26)
- en: Using spacy-llm to simplify prompt management and create tasks for data extraction
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 spacy-llm 简化提示管理并创建数据提取任务
- en: '[](https://medium.com/@dehhmesquita?source=post_page-----126b836daad1--------------------------------)[![Déborah
    Mesquita](../Images/3b77b7eb569e24f2679875429173daf1.png)](https://medium.com/@dehhmesquita?source=post_page-----126b836daad1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----126b836daad1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----126b836daad1--------------------------------)
    [Déborah Mesquita](https://medium.com/@dehhmesquita?source=post_page-----126b836daad1--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@dehhmesquita?source=post_page-----126b836daad1--------------------------------)[![Déborah
    Mesquita](../Images/3b77b7eb569e24f2679875429173daf1.png)](https://medium.com/@dehhmesquita?source=post_page-----126b836daad1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----126b836daad1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----126b836daad1--------------------------------)
    [Déborah Mesquita](https://medium.com/@dehhmesquita?source=post_page-----126b836daad1--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdd9e06a0a640&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Felegant-prompt-versioning-and-llm-model-configuration-with-spacy-llm-126b836daad1&user=D%C3%A9borah+Mesquita&userId=dd9e06a0a640&source=post_page-dd9e06a0a640----126b836daad1---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----126b836daad1--------------------------------)
    ·5 min read·Jul 26, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F126b836daad1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Felegant-prompt-versioning-and-llm-model-configuration-with-spacy-llm-126b836daad1&user=D%C3%A9borah+Mesquita&userId=dd9e06a0a640&source=-----126b836daad1---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdd9e06a0a640&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Felegant-prompt-versioning-and-llm-model-configuration-with-spacy-llm-126b836daad1&user=D%C3%A9borah+Mesquita&userId=dd9e06a0a640&source=post_page-dd9e06a0a640----126b836daad1---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----126b836daad1--------------------------------)
    ·5分钟阅读·2023年7月26日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F126b836daad1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Felegant-prompt-versioning-and-llm-model-configuration-with-spacy-llm-126b836daad1&user=D%C3%A9borah+Mesquita&userId=dd9e06a0a640&source=-----126b836daad1---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F126b836daad1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Felegant-prompt-versioning-and-llm-model-configuration-with-spacy-llm-126b836daad1&source=-----126b836daad1---------------------bookmark_footer-----------)![](../Images/64fa1ffb2743af291cb93acc5f61d321.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F126b836daad1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Felegant-prompt-versioning-and-llm-model-configuration-with-spacy-llm-126b836daad1&source=-----126b836daad1---------------------bookmark_footer-----------)![](../Images/64fa1ffb2743af291cb93acc5f61d321.png)'
- en: A [tidy desk](https://unsplash.com/pt-br/fotografias/zCQsBI7ZltQ), how you code
    will look like if you use spacy-llm haha
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 一张 [整洁的桌子](https://unsplash.com/pt-br/fotografias/zCQsBI7ZltQ)，如果你使用 spacy-llm，你的代码将会像这样哈哈
- en: Managing prompts and handling OpenAI request failures can be a challenging task.
    Fortunately, spaCy released [spacy-llm](https://github.com/explosion/spacy-llm),
    a powerful tool that simplifies prompt management and eliminates the need to create
    a custom solution from scratch.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 管理提示和处理 OpenAI 请求失败可能是一个具有挑战性的任务。幸运的是，spaCy 发布了 [spacy-llm](https://github.com/explosion/spacy-llm)，这是一个强大的工具，可以简化提示管理，并消除了从头创建自定义解决方案的需求。
- en: In this article, you will learn how to leverage spacy-llm to create a task that
    extracts data from text using a prompt. We will dive into the basics of spacy
    and explore some of the features of spacy-llm.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，你将学习如何利用 spacy-llm 创建一个从文本中提取数据的任务。我们将深入了解 spaCy 的基础知识，并探索一些 spacy-llm
    的功能。
- en: spaCy and spacy-llm 101
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: spaCy 和 spacy-llm 101
- en: spaCy is a library for advanced NLP in Python and Cython. When dealing with
    text data, several processing steps are typically required, such as tokenization
    and POS tagging. In order to execute these steps, spaCy provides the `nlp` method,
    which invokes a processing pipeline.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: spaCy 是一个用于 Python 和 Cython 的高级 NLP 库。在处理文本数据时，通常需要几个处理步骤，例如分词和词性标注。为了执行这些步骤，spaCy
    提供了 `nlp` 方法，它会调用一个处理管道。
- en: spaCy v3.0 introduces `config.cfg`, a file where we can include detailed settings
    of these pipelines.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: spaCy v3.0 引入了 `config.cfg`，这是一个我们可以在其中包括这些管道详细设置的文件。
- en: '`config.cfg` uses [confection](https://github.com/explosion/confection), a
    config system which allows the creation of arbitrary object trees. For instance,
    confection parsers the following `config.cfg`:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '`config.cfg` 使用了 [confection](https://github.com/explosion/confection)，这是一个允许创建任意对象树的配置系统。例如，confection
    解析以下 `config.cfg`：'
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'into:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 进入：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Each pipeline use components, and spacy-llm stores the pipeline components
    into registries using [catalogue](https://github.com/explosion/catalogue). This
    library, also from Explosion, introduces function registries that allow for efficient
    management of the components. A `llm`component is defined into [two main settings](https://github.com/explosion/spacy-llm/tree/a3ee82eae366d101d37afd055606c9ead0186251#-api):'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 每个管道使用组件，spacy-llm 将管道组件存储到使用 [catalogue](https://github.com/explosion/catalogue)
    的注册表中。这个库，同样来自 Explosion，引入了函数注册表，以便高效地管理组件。`llm` 组件被定义在 [两个主要设置](https://github.com/explosion/spacy-llm/tree/a3ee82eae366d101d37afd055606c9ead0186251#-api)
    中：
- en: A [**task**](https://github.com/explosion/spacy-llm/tree/a3ee82eae366d101d37afd055606c9ead0186251#tasks),
    defining the prompt to send to the LLM as well as the functionality to parse the
    resulting response
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 [**任务**](https://github.com/explosion/spacy-llm/tree/a3ee82eae366d101d37afd055606c9ead0186251#tasks)，定义要发送到
    LLM 的提示以及解析生成响应的功能
- en: A [**model**](https://github.com/explosion/spacy-llm/tree/a3ee82eae366d101d37afd055606c9ead0186251#models),
    defining the model and how to connect to it
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 [**模型**](https://github.com/explosion/spacy-llm/tree/a3ee82eae366d101d37afd055606c9ead0186251#models)，定义模型及其连接方式
- en: To include a component that uses a LLM in our pipeline, we need to follow a
    few steps. First, we need to create a task and register it into the registry.
    Next, we can use a model to execute the prompt and retrieve the responses. Now
    it’s time to do all that so we can run the pipeline
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要在我们的管道中包含一个使用 LLM 的组件，我们需要遵循几个步骤。首先，我们需要创建一个任务并将其注册到注册表中。接下来，我们可以使用模型来执行提示并检索响应。现在是时候完成这些操作，以便我们可以运行管道了
- en: Creating a task to extract data from text
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个从文本中提取数据的任务
- en: We will use quotes from [https://dummyjson.com/](https://dummyjson.com/quotes)
    and create a task to extract the context from every quote. We will create the
    prompt, register the task and finally create the config file.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 [https://dummyjson.com/](https://dummyjson.com/quotes) 上的引用，并创建一个任务来从每个引用中提取上下文。我们将创建提示、注册任务，并最终创建配置文件。
- en: '**1\. The prompt**'
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**1\. 提示**'
- en: 'spacy-llm uses Jinja templates to define the instructions and examples. The
    `{{ text }}` will be replaced by the quote we will provide. This is our prompt:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: spacy-llm 使用 Jinja 模板来定义指令和示例。 `{{ text }}` 将被我们提供的引用所替换。这是我们的提示：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**2\. The task class**'
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**2\. 任务类**'
- en: 'Now let’s create the class for the task. The class should implement two functions:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们创建任务的类。这个类应该实现两个函数：
- en: '`**generate_prompts(docs: Iterable[Doc]) -> Iterable[str]**`: a function that
    takes in a list of spaCy `[Doc](https://spacy.io/api/doc)` objects and transforms
    them into a list of prompts'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`**generate_prompts(docs: Iterable[Doc]) -> Iterable[str]**`：一个函数，它接受一个 spaCy
    `[Doc](https://spacy.io/api/doc)` 对象的列表，并将其转换为一个提示的列表'
- en: '`**parse_responses(docs: Iterable[Doc], responses: Iterable[str]) -> Iterable[Doc]**`:
    a function for parsing the LLM''s outputs into spaCy `[Doc](https://spacy.io/api/doc)`
    objects'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`**parse_responses(docs: Iterable[Doc], responses: Iterable[str]) -> Iterable[Doc]**`：一个将
    LLM 输出解析为 spaCy `[Doc](https://spacy.io/api/doc)` 对象的函数'
- en: '`**generate_prompts**` will use our Jinja template and `**parse_responses**`
    will add the attribute context to our Doc. This is the `QuoteContextExtractTask`
    class:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '`**generate_prompts**` 将使用我们的 Jinja 模板，而 `**parse_responses**` 将为我们的 Doc 添加上下文属性。这是
    `QuoteContextExtractTask` 类：'
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now we just need to add the task to the spacy-llm `llm_tasks` register:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们只需将任务添加到 spacy-llm 的 `llm_tasks` 注册表中：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**3\. The config.cfg file**'
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**3. config.cfg 文件**'
- en: 'We’ll use the GPT-3.5 model from OpenAI. spacy-llm has a model for that so
    we just need to make sure the secret key is available as an environmental variable:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 OpenAI 的 GPT-3.5 模型。spacy-llm 为此提供了一个模型，所以我们只需确保秘密密钥作为环境变量可用：
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'To build the `nlp` method that runs the pipeline we’ll use the `assemble` method
    from spacy-llm. This methods reads from a `.cfg` file. The file should reference
    the GPT-3.5 model (it’s already in he registry) and the task we’ve created:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建运行管道的 `nlp` 方法，我们将使用 spacy-llm 的 `assemble` 方法。该方法从 `.cfg` 文件中读取。文件应引用 GPT-3.5
    模型（它已在注册表中）和我们创建的任务：
- en: '[PRE6]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**4\. Running the pipeline**'
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**4. 运行管道**'
- en: 'Now we just need to put everything together and run the code:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们只需将所有内容组合在一起并运行代码：
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'And run:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然后运行：
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: If you want to change the prompt, just create another Jinja file and create
    a `my_namespace.QuoteContextExtractTask.v2` task the same way we’ve created the
    first one. If you want to change the temperature, just change the parameter on
    the `config.cfg` file. Nice, right?
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想更改提示，只需创建另一个 Jinja 文件，并以与第一次创建相同的方式创建 `my_namespace.QuoteContextExtractTask.v2`
    任务。如果你想更改温度，只需在 `config.cfg` 文件中更改参数。不错，对吧？
- en: Final thoughts
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后的思考
- en: The ability to handle OpenAI REST requests and its straightforward approach
    to storing and versioning prompts are my favorite things about spacy-llm. Additionally,
    the library offers a Cache for caching prompts and responses per document, a method
    for providing examples for few-shot prompts, and a logging feature, among other
    things.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 处理 OpenAI REST 请求的能力及其直接存储和版本控制提示的方法是我最喜欢 spacy-llm 的地方。此外，该库提供了一个用于缓存每个文档的提示和响应的缓存功能，一个为少量示例提示提供示例的方法，以及日志记录功能等。
- en: 'You can take a look at the entire code from today here: [https://github.com/dmesquita/spacy-llm-elegant-prompt-versioning](https://github.com/dmesquita/spacy-llm-elegant-prompt-versioning).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里查看今天的完整代码：[https://github.com/dmesquita/spacy-llm-elegant-prompt-versioning](https://github.com/dmesquita/spacy-llm-elegant-prompt-versioning)。
- en: As always, thank you for reading!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，谢谢你的阅读！
