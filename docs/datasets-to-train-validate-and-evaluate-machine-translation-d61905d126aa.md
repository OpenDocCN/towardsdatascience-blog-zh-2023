# 训练、验证和评估机器翻译的数据集

> 原文：[https://towardsdatascience.com/datasets-to-train-validate-and-evaluate-machine-translation-d61905d126aa?source=collection_archive---------2-----------------------#2023-02-04](https://towardsdatascience.com/datasets-to-train-validate-and-evaluate-machine-translation-d61905d126aa?source=collection_archive---------2-----------------------#2023-02-04)

## 选择、检查和拆分

[](https://medium.com/@bnjmn_marie?source=post_page-----d61905d126aa--------------------------------)[![Benjamin Marie](../Images/3ea1ad230cb1e67610418a8e36a5e5dd.png)](https://medium.com/@bnjmn_marie?source=post_page-----d61905d126aa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d61905d126aa--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d61905d126aa--------------------------------) [Benjamin Marie](https://medium.com/@bnjmn_marie?source=post_page-----d61905d126aa--------------------------------)

·

[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fad2a414578b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdatasets-to-train-validate-and-evaluate-machine-translation-d61905d126aa&user=Benjamin+Marie&userId=ad2a414578b3&source=post_page-ad2a414578b3----d61905d126aa---------------------post_header-----------) 发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d61905d126aa--------------------------------) ·13 min 阅读·2023年2月4日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd61905d126aa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdatasets-to-train-validate-and-evaluate-machine-translation-d61905d126aa&user=Benjamin+Marie&userId=ad2a414578b3&source=-----d61905d126aa---------------------clap_footer-----------)

--

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd61905d126aa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdatasets-to-train-validate-and-evaluate-machine-translation-d61905d126aa&source=-----d61905d126aa---------------------bookmark_footer-----------)![](../Images/b19a0e5aa70cbc0a6adef86313a71daf.png)

图片来源于 [Pixabay](https://pixabay.com/illustrations/translate-translation-web-service-3324171/)

对于大多数自然语言处理（NLP）任务，一个重要的步骤是选择用于训练、验证和评估系统的数据集。机器翻译也不例外，但由于任务的多语言特性，它有一些特定的要求。

在这篇文章中，我解释了如何选择、检查和拆分数据集，以构建一个机器翻译系统。我通过实例展示了数据集中最重要的属性，并根据机器翻译系统的目标如何在数据的质量和数量之间进行权衡。

# 训练、验证和评估

要构建一个机器翻译系统，我们需要尽可能多的数据：

+   **训练**：机器翻译系统必须经过训练才能学习如何翻译。如果我们计划使用神经模型，这一步骤在数据和计算资源方面是最昂贵的。

+   **验证**：可以在训练过程中使用验证数据集来监控模型的表现。例如，如果表现一段时间后没有改善，我们可以决定提前停止训练。然后，如果我们在不同训练步骤保存了模型，我们可以选择在验证数据上表现最佳的模型，并用这个模型进行评估。

+   **评估**：这一步骤自动生成我们选择的模型在尽可能接近我们系统实际部署后将要翻译的文本的数据集上的表现。如果表现令人满意，那么我们可以部署我们的模型。如果不满意，我们需要用不同的超参数或训练数据重新训练模型。

[](/watch-out-for-your-beam-search-hyperparameters-9c4daf6668d6?source=post_page-----d61905d126aa--------------------------------) [## 注意你的束搜索超参数

### 默认值永远不是最优的。

towardsdatascience.com](/watch-out-for-your-beam-search-hyperparameters-9c4daf6668d6?source=post_page-----d61905d126aa--------------------------------)

所有这些数据集都是**平行语料库**，包括**源语言**和**目标语言**，并且理想情况下是**目标领域**的。

这句中包含了很多关键词。让我们逐一解释它们。

+   **源语言**：这是将由我们的机器翻译系统翻译的文本的语言。

+   **目标语言**：这是机器翻译系统生成的翻译的语言。

+   **目标领域**：这个概念更复杂。假设用于构建我们系统的数据应尽可能接近系统部署后将要翻译的数据，例如**相同的风格、体裁和主题**。如果我们希望系统翻译推文，那么用推文训练模型比用科学摘要训练要好得多。这可能显而易见，但通常找到一个大型目标领域数据集是具有挑战性的，因此我们必须尽量接近它。

+   **平行语料库**：这通常以源语言中的句子或**段落**形式出现，并与其在目标语言中的翻译配对。我们使用平行数据来教系统如何翻译。这类数据还有许多其他名称：平行数据、双语语料库、双语文本等。“平行数据”可能是最常见的名称。

例如，以下数据集是平行的：

![](../Images/e7b0aea558f481a2f2e339fc8e20bb06.png)

从 Paracrawl 英荷平行语料库中提取（[CC0](https://www.paracrawl.eu/)）。作者截图。

# 质量

为了获得最佳的机器翻译系统，我们需要一个大规模的平行语料库来训练系统。但我们**不应为数量而牺牲质量**。

无论我们讨论的是训练数据还是验证/评估数据，所使用数据的质量会产生不同的影响。

但首先，让我们定义一下构建系统所需的高质量平行数据的最重要特征。

## 正确

平行数据中的翻译**应当正确且自然**。理想情况下，这意味着翻译应该由专业翻译人员从零开始制作（即未后期编辑）并经过独立检查。平行语料库常常通过非专业翻译人员众包制作。数据也可以直接从网络上爬取并自动配对，这对于只有少量数据的领域和语言对而言绝对不完美。即便这类数据集的质量远非理想，我们可能也不得不在它们是唯一资源时使用它们。

## 对齐

平行数据中的段落或文档**应当正确对齐**。如果段落配对不正确，系统在训练时将学到错误的翻译。

## 原始

平行数据的源语言部分**不应是其他语言的翻译**。这一点可能稍微复杂一些。我们希望我们的系统学习如何翻译源语言中的文本。然而，如果在训练时，我们提供的文本不是原本的源语言文本，即已经是从其他语言翻译过来的文本，那么系统将更擅长翻译翻译文本而非原始文本。下面我会详细说明为什么这一点很重要。

## 领域内

数据**应当在目标领域内**。这是一个有争议的理想情境。我们可以在非目标领域的数据集上训练一个非常好的系统，然后在目标领域的较小数据集上进行微调。

## 原始

数据**应该接近原始状态**。使用已经预处理过的数据集通常是个坏主意。这里的预处理指的是任何改变了原始文本的过程。这可以是分词、大小写还原、标点规范化等。很常见的是，所有这些预处理步骤都没有明确说明，这导致我们无法在我们的系统实际翻译的文本上准确重现它们。定义我们自己的预处理步骤要安全得多，有时也更快捷。

要大致了解数据集的质量，我们**应该始终知道数据的来源及其创建方式**。我会在下面详细介绍。

在训练时，机器翻译系统将学习平行数据的属性。神经模型对噪声相对较为鲁棒，但如果我们的训练数据非常嘈杂，即对齐不准确或有许多翻译错误，系统将学习生成带有错误的翻译。

在验证/评估时，使用的平行数据的质量更加关键。如果我们的数据集质量较差，评估步骤将仅告诉我们系统在翻译不佳方面的表现。换句话说，这将是一次无用的评估，但可能会让我们误以为可以部署一个训练不充分的机器翻译系统。

# 数量

除了质量，数据的数量也至关重要。

“数量”通常指的是平行语料库中平行段落的数量。我在这里将使用这个定义。

对于训练来说，**尽可能使用更多的数据是一个好的经验法则**，前提是数据的质量合理。我将训练场景分为3类：

+   **低资源**：训练数据包含少于100,000个平行段落（或称为句子）

+   **中等资源**：训练数据包含100,000到1,000,000个平行段落

+   **高资源**：训练数据包含超过1,000,000个平行段落

对于验证和评估，使用大量数据可能看似是获取我们模型准确评估的正确选择，但通常我们更倾向于**将更多的数据用于训练而不是验证和评估**。

如果你查看研究和开发中的最佳实践，你会发现机器翻译的验证和评估数据集通常包含1,000到3,000个平行段落。请记住，这些数据集的质量比数量重要得多，与训练数据集不同。我们希望评估数据集的翻译尽可能完美，并且尽可能接近我们的系统将要翻译的文本。

# 单语数据

单语数据，与我之前描述的平行数据不同，是指单一语言的文本。可以是源语言或目标语言。

由于这些数据是单语的，因此比平行数据更容易以**非常大**的数量进行收集。

它通常被用于生成合成平行数据，然后用来增强训练平行数据。

生成合成数据有许多策略，如回译和正向翻译。如果处理不当，它们可能会对训练产生负面影响。

我将在另一篇博客文章中详细讨论这些策略。敬请关注！

# 数据泄漏预防

如果你对机器学习有所了解，你可能已经知道什么是数据泄漏。

我们希望训练数据与验证和评估数据尽可能接近，但**没有任何重叠**。

如果存在重叠，我们就谈论数据泄漏。

这意味着我们的系统部分地在用于验证/评估的数据上进行训练。这是一个关键问题，因为它人为地提高了验证/评估结果。系统确实会特别擅长翻译其验证/评估数据，因为它在训练时已经见过这些数据，而一旦投入生产，系统很可能会面临未见过的文本进行翻译。

预防数据泄漏比听起来要困难得多，并且使问题更加复杂的是，数据泄漏有许多不同的层次。

最明显的数据泄漏情况是评估数据中的段落或文档也出现在训练数据中。这些段落应该被排除。

另一种数据泄漏的形式是当训练和评估数据来自相同的文档时。例如，将数据集的段落顺序打乱，然后选择前95%用于训练，最后5%用于验证/评估，可能会导致数据泄漏。在这种情况下，我们可能在训练和验证/评估数据中使用了原本来自同一文档的段落对，这些文档可能由同一译者创建。也有可能训练数据中的段落直接用于创建验证/评估数据段落的翻译。因此，验证/评估数据在翻译时人为变得更容易。

为了防止数据泄漏，总是要了解数据的来源，以及数据是如何制作和划分为训练/验证/评估数据集的。

# 关于翻译腔

平行语料库有两个方面。理想情况下，源语言端是由源语言母语者编写的**原始文本**，而目标语言端是由目标语言母语者生产的翻译。

目标端不是原始文本：它是翻译。翻译可能包含错误。研究还表明，翻译在词汇上不如原文多样，在句法上也比原文简单。这些**翻译伪影**定义了“翻译腔”。

*为什么在机器翻译中这很重要？*

假设你有一个平行语料库，原始源语言为西班牙语，翻译为英语。这对于一个西班牙语到英语的机器翻译系统来说是完美的。

但如果你想要一个英语到西班牙语的系统，你可能会想直接交换平行语料库的两边：原文在目标语言侧，翻译在源语言侧。

然后，你的系统将学习翻译……翻译！由于翻译比原文更容易翻译，神经网络学习任务要简单得多。但然后，机器翻译系统在翻译用户输入的原文时会表现不佳。

底线是：**检查数据的来源**，以确保至少你不会在源语言中找到翻译内容。

注意，有时这种情况是不可避免的，特别是在处理低资源语言时。

# 平行语料库的来源

幸运的是，网上有许多领域和语言的平行语料库。

我主要使用以下网站获取所需的内容：

+   [OPUS](https://opus.nlpl.eu/)：这可能是最广泛的平行语料库来源。为 300 多种语言提供了数十种语料库。它们可以以纯文本格式（2 个文件：1 个用于源语言，1 个用于目标语言）或 TMX 格式下载，TMX 是翻译行业中常用的 XML 格式。每个语料库的大小和长度（以段落和标记数量计）也会给出。

+   [Hugging Face 的数据集](https://huggingface.co/datasets)：这个数据集并不是专门针对机器翻译资源，但你可以通过选择“translation”标签找到许多平行语料库。OPUS 和 Dataset 的交集非常大，但你会发现一些 OPUS 上没有的平行语料库。

这是目前最大的两个平行语料库来源。如果你知道其他来源，请在评论中指出。

请注意，你会发现的大多数平行语料库只能用于研究和学术目的，而不能用于商业目的。OPUS 不会显示每个数据集的许可信息。如果你需要知道，请直接检查数据集的原始来源或联系创建者。

# 示例

现在，让我们更实际地操作一些数据集。我创建了两个需要平行数据的任务：

+   任务 1：一个通用的机器翻译系统，将西班牙语翻译成英语（Es→En）

+   任务 2：一个专门的机器翻译系统，将 COVID-19 相关内容从斯瓦希里语翻译成英语（Sw→En）

我们将首先专注于*任务 1*。

我们可以开始在 OPUS 上搜索，看是否有针对这个任务的平行语料库。

幸运的是，西班牙语到英语（Es→En）是一个高资源任务。在各种领域有大量平行语料库。例如，从 OPUS，我们可以获得：

![](../Images/ccad4f1ad23139ba0371f719defe4caf.png)

来自[OPUS](https://opus.nlpl.eu)的截图。

第一个，“ParaCrawl v9”是最大的之一。它是自动创建的，但足够好以训练机器翻译系统。我们应该始终检查许可证，以确保我们可以将其用于目标应用程序。如上所述，OPUS没有提供许可证信息，但一旦点击，它会提供数据集的来源。有关许可证信息，我们必须检查数据的原始来源：[https://www.paracrawl.eu/](https://www.paracrawl.eu/)。该语料库在[CC0许可证](https://creativecommons.org/share-your-work/public-domain/cc0/)下提供。允许学术和商业用途。

这是一个包含264M对段的大型语料库。这个数据量足够将其拆分为训练/验证/评估数据集。我会这样拆分数据以避免数据泄露：

![](../Images/8645063b165ced63106b235166e7b22c.png)

作者插图。

由于段对数量很多，我们可以将数据拆分为连续的10M段对。我会提取一个段，对例如最后一个段进行重新拆分成更小的连续段对1M。最后，我会从第一个较小段提取3,000个段用于验证，从最后一个较小段提取另外3,000个段用于评估。

训练、验证和评估数据集之间的距离足够。这是一种非常简单的方法，但远非最佳。如果语料库中的段对已经被打乱，它不会防止数据泄露。

还有其他方法，我在这里不讨论，以更好地保证在提取每个数据集最有用的段对时数据不会泄露。

对于训练，你可以从例如前两个10M段开始。如果对翻译质量不满意，你可以将更多的段加入训练数据中。

如果翻译质量没有太大改善，说明你可能不需要使用剩余的200M+段对。

*任务2* 要困难得多。

我们想要翻译斯瓦希里语。非洲语言通常资源较少。此外，我们针对的是一个相对较新的领域——COVID-19，因此我们可以预期这个任务可用的数据会非常少。

正如预期的那样，在OPUS上可用的数据集要少得多：

![](../Images/a5918577f225704639f73c1990b50506.png)

来自[OPUS](https://opus.nlpl.eu)的截图。

一个好的点是，Paracrawl也提供Sw→En的资源，但其10万个段对相对较小。然而，这是一个最大的CC0许可证资源之一。我会用它进行训练，然后尝试添加其他数据源（如CCMatrix或CCAligned）以观察性能如何改进。

*但如何评估一个专门用于翻译COVID-19内容的机器翻译系统？*

在 COVID-19 爆发后，研究社区致力于制作多语言的翻译资源。 [TICO-19](https://tico-19.github.io/) 语料库就是其中之一，并且提供了 CC0 许可。它可以在 OPUS 上获取。虽然它很小，但提供了 3,100 段斯瓦希里语和英语的翻译。这足以制作验证/评估数据集。在这里，我会选择 1,000 段用于验证，其余段落用于评估。然后，你将了解你的系统在 Paracrawl 上训练后在翻译 COVID-19 内容方面的表现。

请注意，我没有讨论这两个任务中的翻译腔。Paracrawl 很可能在其源语言侧有非原始的西班牙语和斯瓦希里语。TICO-19 语料库是从英语创建的。斯瓦希里语侧是非原始的。换句话说，我们不能避免这两个任务中的翻译腔。

# 结论

在这篇文章中，我描述了如何选择和拆分你的数据集，以创建你自己的机器翻译系统。

总结来说，我认为最重要的点是找到质量与数量之间的最佳折中点，特别是当你针对低资源语言时。此外，深入了解你的数据集也至关重要。如果不加以检查，你可能会得到一个完全偏离目标且存在偏见和不公正的系统。

在下一篇文章中，我将展示如何预处理这些数据集以改进它们，并促进机器翻译的训练。

我所有的文章都发布在我的新闻通讯《The Kaitchup》中。订阅以接收每周有关运行大型语言模型和机器翻译系统的新闻、技巧和教程。

[](https://kaitchup.substack.com/?source=post_page-----d61905d126aa--------------------------------) [## The Kaitchup - AI on a Budget | Benjamin Marie, PhD | Substack

### 订阅每周 AI 新闻、技巧和有关调优、大型语言模型运行和服务的教程…

kaitchup.substack.com](https://kaitchup.substack.com/?source=post_page-----d61905d126aa--------------------------------)
