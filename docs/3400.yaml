- en: The World’s Smallest Data Pipeline Framework
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-worlds-smallest-data-pipeline-framework-408eaf1a4ce4?source=collection_archive---------0-----------------------#2023-11-16](https://towardsdatascience.com/the-worlds-smallest-data-pipeline-framework-408eaf1a4ce4?source=collection_archive---------0-----------------------#2023-11-16)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A simple and fast data pipeline foundation with sophisticated functionality.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@doug.blank?source=post_page-----408eaf1a4ce4--------------------------------)[![Douglas
    Blank, PhD](../Images/b2fa86b9fe63a8bcb4f218ef5a6791e9.png)](https://medium.com/@doug.blank?source=post_page-----408eaf1a4ce4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----408eaf1a4ce4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----408eaf1a4ce4--------------------------------)
    [Douglas Blank, PhD](https://medium.com/@doug.blank?source=post_page-----408eaf1a4ce4--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F66e2bac7e7d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-worlds-smallest-data-pipeline-framework-408eaf1a4ce4&user=Douglas+Blank%2C+PhD&userId=66e2bac7e7d8&source=post_page-66e2bac7e7d8----408eaf1a4ce4---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----408eaf1a4ce4--------------------------------)
    ·7 min read·Nov 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F408eaf1a4ce4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-worlds-smallest-data-pipeline-framework-408eaf1a4ce4&user=Douglas+Blank%2C+PhD&userId=66e2bac7e7d8&source=-----408eaf1a4ce4---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F408eaf1a4ce4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-worlds-smallest-data-pipeline-framework-408eaf1a4ce4&source=-----408eaf1a4ce4---------------------bookmark_footer-----------)![](../Images/99ca52ffe5163ed83984a01c7a33d07c.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Ana Lucia Cottone](https://unsplash.com/@fromanalucia?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Data wrangling is perhaps the job that occupies the most time from Data Scientists.
    Data wrangling includes cleaning, transforming, and generally manipulating data
    from its raw state into something useful. Like many activities, the wrangling
    process often needs to be refined over time. So it is important to keep track
    of how a dataset is wrangled so that your team can manage and reproduce the process
    over time. Data wrangling, although not always fun, may be the most important
    activity at any modern company.
  prefs: []
  type: TYPE_NORMAL
- en: There are some companies that specialize in data pipelines, and they can be
    complex and very sophisticated. But for this exploration, let’s consider the task
    of turning a text file into a set of words or “tokens”, throwing out texts that
    are not useful to us. Let’s start simple, and work our way up.
  prefs: []
  type: TYPE_NORMAL
- en: 'Initially, lets define a series of steps to perform wrangling functions on
    words in a text. We’ll use the Python **text.translate()** function to do some
    of the work for us. Consider these 4 functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**step1** is a function that removes all of the punctuation from a word, and
    removes newlines. **step2** turns a word into lowercase. **step3** again uses
    **text.translate()** to remove digits. And **step4** will be used as a filter
    to filter out words that contain non-ASCII letters. You can imagine additional
    steps, such as stemming.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As these are simple functions, if we apply **step1** to a word, we’ll get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Indeed, it has removed the punctuation from the text. We can apply all three
    functions by wrapping them Russian-doll style around the word:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Here we see that functions **step1**, **step2**, and **step3** have been applied
    leaving only the letters “testing”. Note that we will define our functions to
    work in a particular order. That is, **step1** should be done before **step2**,
    etc.
  prefs: []
  type: TYPE_NORMAL
- en: This function-based process is simple to create and simple to use. Of course,
    we could do all of the functions at once. But as the “pipeline” of functions get
    longer and more complex, breaking up the process into discrete steps will make
    the process more manageable. In fact, each step might become so complex as to
    have different teams working on them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Okay, so far, so good. But of course, we don’t want to manually apply the function
    pipeline onto each word. Instead we want to apply it to every word in a list.
    To do this, we make a very simple function **apply()**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can use the same functions on entire lists of words:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Ah, yes, we need to remove empty words. **step4** designed exactly for that,
    but is a bit more complex to use. It would look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'That is, because **step4** is a filter function returning True to keep it and
    False to remove it, it is applied like so: **filter(step4, data)**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few problems with this simple approach:'
  prefs: []
  type: TYPE_NORMAL
- en: The steps are applied from the inside out. That is, the first step, **step1,**
    is the innermost function, while **step3** is on the outside. Not very intuitive.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It is very wordy in that we have to repeat the **apply()** function for each
    step function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Filters (like **step4**) can’t be used like the other functions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'With these issues in mind, can we abstract the main functionality into a generalized
    pipeline? I’m imagining a two-step approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'How could we define **my_pipeline**? It turns out to be fairly straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: That is, **my_pipeline** is a function that takes a series of step functions,
    and returns a function that takes a list of words, applies each step in the series,
    and returns the processed list of words.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try it out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: It works — we got exactly what we got before! What about the **step4** filter
    function? Let’s leave that for the moment and try out this system on “real” data.
    Well, it will be real fake data. For these experiments, we’ll create 10,000 documents,
    each consisting of 10 paragraphs. We’ll use the **DocumentGenerator()** from the
    Python package **essential_generators**.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This will take about 30 seconds to generate all of the data. To continue with
    our simple code, we need to introduce one more step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This step will take a filename, open the file, and split the text on spaces.
    And we need to make a slight adjustment to our **apply()** function to handle
    lists of words, instead of words:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'I also made one other slight adjustment to **apply**: it now returns a *generator
    expression* rather than a *list comprehension* by using the surrounding parentheses
    rather than square brackets. This will delay processing until needed (sometimes
    called “lazy evaluation”).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can build a near-complete pipeline system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that it takes a list of filenames as input. Nice and simple. But there
    are a few things that I’d still like to see:'
  prefs: []
  type: TYPE_NORMAL
- en: ability to handle filters in a simple way
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ability to run the pipeline in parallel to process datasets quickly
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ability to visualize the pipeline
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For these three additions, I’ll refer you to the **picopipe** project that
    I developed based on the ideas above. You can pip install it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'and run it with the same step functions from above:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Here, **pfilter** stands for pipeline-filter, and you simply wrap it around
    the **step4** function. I’m pretty happy with the design. But let’s see how fast
    it will run.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s get all of the document filenames. An easy way to do that is to
    use **glob**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'And now we can process all of the documents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: That takes about 21 seconds on my laptop to process all 10,000 documents. Short
    and sweet! Can we make that run faster?
  prefs: []
  type: TYPE_NORMAL
- en: Yes! There is now also an **n_jobs** parameter to the pipe that indicates the
    number of jobs you can run in parallel. Here is a little bit of code that will
    process the dataset multiple times using 0 to 9 threads. How much faster do you
    think it will it run using 9 threads in parallel?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'That will take a couple of minutes. Plotting the result time versus threads
    shows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9adcf33bc1b49428d2ac99c18d791632.png)'
  prefs: []
  type: TYPE_IMG
- en: Plot showing the running time of splitting the processing into a number of parallel
    jobs. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Interesting: the chart levels off rather than continuing to decrease with additional
    threads. That is, using 9 threads is not 9 times faster than using 1 thread. Why
    not? Unfortunately, you can’t break the law. And there is a law: [Amdahl’s Law](https://en.wikipedia.org/wiki/Amdahl%27s_law).
    It basically says that you’ll never get N times faster because there is an overhead
    cost that can’t be reduced. In this case, I can reduce the time from about 21
    seconds down to 8 seconds using 4 threads. Still, not bad!'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, I’d like to visualize the pipeline. For this part of the project I
    chose to try out the [Mermaid Diagram format](https://mermaid.js.org/). It has
    gained a lot of support lately, including in github’s repositories. The format
    is very simple, and easy to create. For github rendering, simply name the file
    with a .mmd extension. Here is how to generate a mermaid script using **picopipe**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'And here is is shown in github’s rendering:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5ab0ba92cedff16f7180c27157973786.png)'
  prefs: []
  type: TYPE_IMG
- en: Github.com supports Mermaid document files directly. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, github doesn’t show the mouseover functionality (defined in
    CSS). However, if you can set your own CSS, then it works to not only visualize
    the pipeline, but can show the step code when you mouseover a step box:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/acc16cb6c6ee57db0eb49f60136a6ade.png)'
  prefs: []
  type: TYPE_IMG
- en: A Mermaid diagram as shown in Comet’s custom panels. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: 'The above Mermaid chart with mousover support was created using Comet’s custom
    panel system (free for all users). It was very easy to create a custom panel that
    displays Mermaid files. Here is a demo of the above Mermaid chart rendered live:
    [comet.com/dsblank/picopipe/a4c044c1657b464087ec44f67ae22709](https://www.comet.com/dsblank/picopipe/a4c044c1657b464087ec44f67ae22709?experiment-tab=panels&showOutliers=true&smoothing=0&viewId=QXG0miglwPD2bCyWHGheKEF4j&xAxis=step)'
  prefs: []
  type: TYPE_NORMAL
- en: 'That completes our exploration of developing the World’s Smallest Data Pipeline
    Framework, and exploring its parallelization and visualization. You can find all
    of the code here: [github.com/dsblank/picopipe](https://github.com/dsblank/picopipe)
    I hope you found the ideas presented here and final module useful.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Interested in Artificial Intelligence, Machine Learning, or Data Science?
    Consider a clap and a follow. Doug is Head of Research at*** [***comet.com***](https://www.comet.com/)***,
    an ML experiment-tracking and model-monitoring company.***'
  prefs: []
  type: TYPE_NORMAL
