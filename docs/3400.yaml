- en: The World’s Smallest Data Pipeline Framework
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 世界上最小的数据管道框架
- en: 原文：[https://towardsdatascience.com/the-worlds-smallest-data-pipeline-framework-408eaf1a4ce4?source=collection_archive---------0-----------------------#2023-11-16](https://towardsdatascience.com/the-worlds-smallest-data-pipeline-framework-408eaf1a4ce4?source=collection_archive---------0-----------------------#2023-11-16)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-worlds-smallest-data-pipeline-framework-408eaf1a4ce4?source=collection_archive---------0-----------------------#2023-11-16](https://towardsdatascience.com/the-worlds-smallest-data-pipeline-framework-408eaf1a4ce4?source=collection_archive---------0-----------------------#2023-11-16)
- en: A simple and fast data pipeline foundation with sophisticated functionality.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个简单快速的数据管道基础，具备复杂的功能。
- en: '[](https://medium.com/@doug.blank?source=post_page-----408eaf1a4ce4--------------------------------)[![Douglas
    Blank, PhD](../Images/b2fa86b9fe63a8bcb4f218ef5a6791e9.png)](https://medium.com/@doug.blank?source=post_page-----408eaf1a4ce4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----408eaf1a4ce4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----408eaf1a4ce4--------------------------------)
    [Douglas Blank, PhD](https://medium.com/@doug.blank?source=post_page-----408eaf1a4ce4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@doug.blank?source=post_page-----408eaf1a4ce4--------------------------------)[![Douglas
    Blank, PhD](../Images/b2fa86b9fe63a8bcb4f218ef5a6791e9.png)](https://medium.com/@doug.blank?source=post_page-----408eaf1a4ce4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----408eaf1a4ce4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----408eaf1a4ce4--------------------------------)
    [Douglas Blank, PhD](https://medium.com/@doug.blank?source=post_page-----408eaf1a4ce4--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F66e2bac7e7d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-worlds-smallest-data-pipeline-framework-408eaf1a4ce4&user=Douglas+Blank%2C+PhD&userId=66e2bac7e7d8&source=post_page-66e2bac7e7d8----408eaf1a4ce4---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----408eaf1a4ce4--------------------------------)
    ·7 min read·Nov 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F408eaf1a4ce4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-worlds-smallest-data-pipeline-framework-408eaf1a4ce4&user=Douglas+Blank%2C+PhD&userId=66e2bac7e7d8&source=-----408eaf1a4ce4---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F66e2bac7e7d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-worlds-smallest-data-pipeline-framework-408eaf1a4ce4&user=Douglas+Blank%2C+PhD&userId=66e2bac7e7d8&source=post_page-66e2bac7e7d8----408eaf1a4ce4---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----408eaf1a4ce4--------------------------------)
    · 7分钟阅读 · 2023年11月16日'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F408eaf1a4ce4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-worlds-smallest-data-pipeline-framework-408eaf1a4ce4&source=-----408eaf1a4ce4---------------------bookmark_footer-----------)![](../Images/99ca52ffe5163ed83984a01c7a33d07c.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F408eaf1a4ce4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-worlds-smallest-data-pipeline-framework-408eaf1a4ce4&source=-----408eaf1a4ce4---------------------bookmark_footer-----------)![](../Images/99ca52ffe5163ed83984a01c7a33d07c.png)'
- en: Photo by [Ana Lucia Cottone](https://unsplash.com/@fromanalucia?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Ana Lucia Cottone](https://unsplash.com/@fromanalucia?utm_source=medium&utm_medium=referral)
    于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Data wrangling is perhaps the job that occupies the most time from Data Scientists.
    Data wrangling includes cleaning, transforming, and generally manipulating data
    from its raw state into something useful. Like many activities, the wrangling
    process often needs to be refined over time. So it is important to keep track
    of how a dataset is wrangled so that your team can manage and reproduce the process
    over time. Data wrangling, although not always fun, may be the most important
    activity at any modern company.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 数据整理可能是数据科学家花费时间最多的工作。数据整理包括清理、转换以及将原始数据处理成有用的信息。像许多活动一样，整理过程通常需要随着时间的推移进行改进。因此，跟踪数据集是如何整理的很重要，这样你的团队可以管理并重复这个过程。虽然数据整理并不总是有趣，但它可能是现代公司中最重要的活动。
- en: There are some companies that specialize in data pipelines, and they can be
    complex and very sophisticated. But for this exploration, let’s consider the task
    of turning a text file into a set of words or “tokens”, throwing out texts that
    are not useful to us. Let’s start simple, and work our way up.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 有些公司专注于数据管道，这些管道可能很复杂且非常精密。但是为了这次探索，让我们考虑将一个文本文件转化为一组单词或“标记”，并丢弃那些对我们没有用的文本。让我们从简单开始，逐步深入。
- en: 'Initially, lets define a series of steps to perform wrangling functions on
    words in a text. We’ll use the Python **text.translate()** function to do some
    of the work for us. Consider these 4 functions:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们定义一系列步骤，以对文本中的单词执行整理函数。我们将使用 Python 的 **text.translate()** 函数来完成一些工作。考虑这4个函数：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**step1** is a function that removes all of the punctuation from a word, and
    removes newlines. **step2** turns a word into lowercase. **step3** again uses
    **text.translate()** to remove digits. And **step4** will be used as a filter
    to filter out words that contain non-ASCII letters. You can imagine additional
    steps, such as stemming.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**step1** 是一个函数，用于删除单词中的所有标点符号和换行符。**step2** 将单词转换为小写。**step3** 再次使用 **text.translate()**
    来删除数字。而 **step4** 将用作过滤器，过滤掉包含非 ASCII 字符的单词。你可以想象一些额外的步骤，例如词干提取。'
- en: 'As these are simple functions, if we apply **step1** to a word, we’ll get:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些是简单函数，如果我们对一个单词应用 **step1**，我们将得到：
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Indeed, it has removed the punctuation from the text. We can apply all three
    functions by wrapping them Russian-doll style around the word:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 确实，它已经从文本中删除了标点符号。我们可以通过将所有三个函数像俄罗斯套娃一样包裹在单词周围来应用它们：
- en: '[PRE2]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here we see that functions **step1**, **step2**, and **step3** have been applied
    leaving only the letters “testing”. Note that we will define our functions to
    work in a particular order. That is, **step1** should be done before **step2**,
    etc.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们看到函数 **step1**、**step2** 和 **step3** 已被应用，只剩下字母“testing”。注意，我们将定义我们的函数按特定的顺序进行工作。也就是说，**step1**
    应该在 **step2** 之前完成，等等。
- en: This function-based process is simple to create and simple to use. Of course,
    we could do all of the functions at once. But as the “pipeline” of functions get
    longer and more complex, breaking up the process into discrete steps will make
    the process more manageable. In fact, each step might become so complex as to
    have different teams working on them.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这个基于函数的过程简单易创建，也简单易用。当然，我们可以一次性完成所有的函数。但随着“管道”函数变得越来越长且复杂，将过程分解为离散的步骤会使过程更易于管理。实际上，每一步可能会变得如此复杂，以至于需要不同的团队来处理。
- en: 'Okay, so far, so good. But of course, we don’t want to manually apply the function
    pipeline onto each word. Instead we want to apply it to every word in a list.
    To do this, we make a very simple function **apply()**:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，到目前为止，一切顺利。但当然，我们不想手动将函数管道应用到每个单词上。我们想要将它应用到列表中的每个单词。为此，我们创建了一个非常简单的函数 **apply()**：
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now we can use the same functions on entire lists of words:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以在整个单词列表上使用相同的函数：
- en: '[PRE4]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Ah, yes, we need to remove empty words. **step4** designed exactly for that,
    but is a bit more complex to use. It would look like:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 啊，是的，我们需要去除空白单词。**step4** 正是为此设计的，但使用起来有些复杂。它的样子是这样的：
- en: '[PRE5]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'That is, because **step4** is a filter function returning True to keep it and
    False to remove it, it is applied like so: **filter(step4, data)**.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，因为 **step4** 是一个过滤函数，返回 True 以保留单词，返回 False 以删除它，所以它的应用方式是：**filter(step4,
    data)**。
- en: 'There are a few problems with this simple approach:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单方法有几个问题：
- en: The steps are applied from the inside out. That is, the first step, **step1,**
    is the innermost function, while **step3** is on the outside. Not very intuitive.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 步骤是从内向外应用的。也就是说，第一个步骤 **step1** 是最内层的函数，而 **step3** 是最外层的。不是很直观。
- en: It is very wordy in that we have to repeat the **apply()** function for each
    step function.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这非常冗长，因为我们必须为每个步骤函数重复**apply()**函数。
- en: Filters (like **step4**) can’t be used like the other functions.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过滤器（如**step4**）不能像其他函数一样使用。
- en: 'With these issues in mind, can we abstract the main functionality into a generalized
    pipeline? I’m imagining a two-step approach:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些问题，我们能否将主要功能抽象成一个通用的管道？我设想了一个两步法：
- en: '[PRE6]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'How could we define **my_pipeline**? It turns out to be fairly straightforward:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何定义**my_pipeline**？事实证明，它非常简单：
- en: '[PRE7]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: That is, **my_pipeline** is a function that takes a series of step functions,
    and returns a function that takes a list of words, applies each step in the series,
    and returns the processed list of words.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，**my_pipeline**是一个函数，它接受一系列步骤函数，并返回一个函数，该函数接受一个单词列表，应用系列中的每个步骤，然后返回处理后的单词列表。
- en: 'Let’s try it out:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们试试：
- en: '[PRE8]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: It works — we got exactly what we got before! What about the **step4** filter
    function? Let’s leave that for the moment and try out this system on “real” data.
    Well, it will be real fake data. For these experiments, we’ll create 10,000 documents,
    each consisting of 10 paragraphs. We’ll use the **DocumentGenerator()** from the
    Python package **essential_generators**.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 它有效——我们得到了之前得到的完全一样的结果！**step4**过滤器函数怎么样？让我们暂时放下这个问题，试试这个系统在“真实”数据上的表现。好吧，这将是真实的假数据。对于这些实验，我们将创建10,000个文档，每个文档包含10个段落。我们将使用Python包**essential_generators**中的**DocumentGenerator()**。
- en: '[PRE9]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This will take about 30 seconds to generate all of the data. To continue with
    our simple code, we need to introduce one more step:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这将需要大约30秒来生成所有数据。要继续我们的简单代码，我们需要引入一个步骤：
- en: '[PRE10]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This step will take a filename, open the file, and split the text on spaces.
    And we need to make a slight adjustment to our **apply()** function to handle
    lists of words, instead of words:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步将接收一个文件名，打开文件，并按空格分割文本。我们还需要对我们的**apply()**函数做一个小调整，以处理单词列表，而不是单词：
- en: '[PRE11]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'I also made one other slight adjustment to **apply**: it now returns a *generator
    expression* rather than a *list comprehension* by using the surrounding parentheses
    rather than square brackets. This will delay processing until needed (sometimes
    called “lazy evaluation”).'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我还对**apply**做了一个小调整：现在它通过使用括号而不是方括号来返回一个*生成器表达式*而不是*列表推导式*。这将延迟处理直到需要时（有时称为“延迟评估”）。
- en: 'Now we can build a near-complete pipeline system:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以构建一个接近完整的管道系统：
- en: '[PRE12]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Note that it takes a list of filenames as input. Nice and simple. But there
    are a few things that I’d still like to see:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，它接受一个文件名列表作为输入。简单明了。但我仍然希望看到一些东西：
- en: ability to handle filters in a simple way
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以简单的方式处理过滤器的能力
- en: ability to run the pipeline in parallel to process datasets quickly
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以并行运行管道快速处理数据集的能力
- en: ability to visualize the pipeline
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可视化管道的能力
- en: 'For these three additions, I’ll refer you to the **picopipe** project that
    I developed based on the ideas above. You can pip install it:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这三个附加功能，我会推荐你参考我基于上述想法开发的**picopipe**项目。你可以通过pip安装它：
- en: '[PRE13]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'and run it with the same step functions from above:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 并使用上述相同的步骤函数运行它：
- en: '[PRE14]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Here, **pfilter** stands for pipeline-filter, and you simply wrap it around
    the **step4** function. I’m pretty happy with the design. But let’s see how fast
    it will run.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，**pfilter**代表管道过滤器，你只需将其包裹在**step4**函数周围。我对这个设计相当满意。但让我们看看它运行得有多快。
- en: 'First, let’s get all of the document filenames. An easy way to do that is to
    use **glob**:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们获取所有的文档文件名。一种简单的方法是使用**glob**：
- en: '[PRE15]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'And now we can process all of the documents:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以处理所有文档了：
- en: '[PRE16]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: That takes about 21 seconds on my laptop to process all 10,000 documents. Short
    and sweet! Can we make that run faster?
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的笔记本电脑上处理所有10,000个文档大约需要21秒。简短而甜美！我们能让它运行得更快吗？
- en: Yes! There is now also an **n_jobs** parameter to the pipe that indicates the
    number of jobs you can run in parallel. Here is a little bit of code that will
    process the dataset multiple times using 0 to 9 threads. How much faster do you
    think it will it run using 9 threads in parallel?
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 是的！现在管道中还有一个**n_jobs**参数，指示你可以并行运行的作业数量。这里有一小段代码，将使用0到9个线程多次处理数据集。你认为使用9个线程并行运行会快多少？
- en: '[PRE17]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'That will take a couple of minutes. Plotting the result time versus threads
    shows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这将需要几分钟。绘制结果时间与线程数的关系图显示：
- en: '![](../Images/9adcf33bc1b49428d2ac99c18d791632.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9adcf33bc1b49428d2ac99c18d791632.png)'
- en: Plot showing the running time of splitting the processing into a number of parallel
    jobs. Image by the author.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 显示将处理拆分为多个并行作业的运行时间的绘图。作者提供的图片。
- en: 'Interesting: the chart levels off rather than continuing to decrease with additional
    threads. That is, using 9 threads is not 9 times faster than using 1 thread. Why
    not? Unfortunately, you can’t break the law. And there is a law: [Amdahl’s Law](https://en.wikipedia.org/wiki/Amdahl%27s_law).
    It basically says that you’ll never get N times faster because there is an overhead
    cost that can’t be reduced. In this case, I can reduce the time from about 21
    seconds down to 8 seconds using 4 threads. Still, not bad!'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是：图表并不随着额外线程的增加而继续减少。也就是说，使用9个线程并不比使用1个线程快9倍。为什么呢？不幸的是，您不能违法。而且有一个法则：[阿姆达尔定律](https://en.wikipedia.org/wiki/Amdahl%27s_law)。它基本上说，您永远不会因为存在无法减少的开销成本而使速度快N倍。在这种情况下，我可以使用4个线程将时间从约21秒减少到8秒。还不错！
- en: 'Finally, I’d like to visualize the pipeline. For this part of the project I
    chose to try out the [Mermaid Diagram format](https://mermaid.js.org/). It has
    gained a lot of support lately, including in github’s repositories. The format
    is very simple, and easy to create. For github rendering, simply name the file
    with a .mmd extension. Here is how to generate a mermaid script using **picopipe**:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我想要可视化管道。在项目的这一部分，我选择尝试[Mermaid图表格式](https://mermaid.js.org/)。它最近得到了很多支持，包括在github的仓库中。这种格式非常简单，易于创建。对于github的渲染，只需将文件命名为.mmd扩展名即可。以下是使用**picopipe**生成Mermaid脚本的方法：
- en: '[PRE18]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'And here is is shown in github’s rendering:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 并且在github的渲染中显示如下：
- en: '![](../Images/5ab0ba92cedff16f7180c27157973786.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5ab0ba92cedff16f7180c27157973786.png)'
- en: Github.com supports Mermaid document files directly. Image by the author.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Github.com直接支持Mermaid文档文件。作者提供的图片。
- en: 'Unfortunately, github doesn’t show the mouseover functionality (defined in
    CSS). However, if you can set your own CSS, then it works to not only visualize
    the pipeline, but can show the step code when you mouseover a step box:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，github不显示鼠标悬停功能（在CSS中定义）。但是，如果您可以设置自己的CSS，则可以实现不仅可视化管道，还可以在鼠标悬停在步骤框时显示步骤代码：
- en: '![](../Images/acc16cb6c6ee57db0eb49f60136a6ade.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/acc16cb6c6ee57db0eb49f60136a6ade.png)'
- en: A Mermaid diagram as shown in Comet’s custom panels. Image by the author.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如Comet的自定义面板中所示的Mermaid图表。作者提供的图片。
- en: 'The above Mermaid chart with mousover support was created using Comet’s custom
    panel system (free for all users). It was very easy to create a custom panel that
    displays Mermaid files. Here is a demo of the above Mermaid chart rendered live:
    [comet.com/dsblank/picopipe/a4c044c1657b464087ec44f67ae22709](https://www.comet.com/dsblank/picopipe/a4c044c1657b464087ec44f67ae22709?experiment-tab=panels&showOutliers=true&smoothing=0&viewId=QXG0miglwPD2bCyWHGheKEF4j&xAxis=step)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 上述的带有鼠标悬停支持的Mermaid图表是使用Comet的自定义面板系统创建的（所有用户免费）。创建显示Mermaid文件的自定义面板非常简单。以下是上述Mermaid图表的实时演示：[comet.com/dsblank/picopipe/a4c044c1657b464087ec44f67ae22709](https://www.comet.com/dsblank/picopipe/a4c044c1657b464087ec44f67ae22709?experiment-tab=panels&showOutliers=true&smoothing=0&viewId=QXG0miglwPD2bCyWHGheKEF4j&xAxis=step)
- en: 'That completes our exploration of developing the World’s Smallest Data Pipeline
    Framework, and exploring its parallelization and visualization. You can find all
    of the code here: [github.com/dsblank/picopipe](https://github.com/dsblank/picopipe)
    I hope you found the ideas presented here and final module useful.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了我们对开发“世界上最小数据管道框架”的探索，以及对其并行化和可视化的探索。您可以在此处找到所有的代码：[github.com/dsblank/picopipe](https://github.com/dsblank/picopipe)
    我希望您觉得这里呈现的想法和最终模块有用。
- en: '***Interested in Artificial Intelligence, Machine Learning, or Data Science?
    Consider a clap and a follow. Doug is Head of Research at*** [***comet.com***](https://www.comet.com/)***,
    an ML experiment-tracking and model-monitoring company.***'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '***对人工智能、机器学习或数据科学感兴趣吗？考虑鼓掌和关注。Doug是*** [***comet.com***](https://www.comet.com/)
    ***的研究主管。***'
