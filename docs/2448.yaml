- en: Practical Prompt Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/practical-prompt-engineering-74e96130abc4?source=collection_archive---------0-----------------------#2023-07-30](https://towardsdatascience.com/practical-prompt-engineering-74e96130abc4?source=collection_archive---------0-----------------------#2023-07-30)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Tips and tricks for successful prompting with LLMs…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://wolfecameron.medium.com/?source=post_page-----74e96130abc4--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----74e96130abc4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----74e96130abc4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----74e96130abc4--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----74e96130abc4--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F28aa6026c553&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-prompt-engineering-74e96130abc4&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=post_page-28aa6026c553----74e96130abc4---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----74e96130abc4--------------------------------)
    ·15 min read·Jul 30, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F74e96130abc4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-prompt-engineering-74e96130abc4&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=-----74e96130abc4---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F74e96130abc4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-prompt-engineering-74e96130abc4&source=-----74e96130abc4---------------------bookmark_footer-----------)![](../Images/e25abf0c0a3c6577a9a7741aa923ce0d.png)'
  prefs: []
  type: TYPE_NORMAL
- en: (Photo by [Jan Kahánek](https://unsplash.com/@honza_kahanek?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/g3O5ZtRk2E4?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText))
  prefs: []
  type: TYPE_NORMAL
- en: Due to their text-to-text format, large language models (LLMs) are capable of
    solving a wide variety of tasks with a single model. Such a capability was originally
    demonstrated via zero and few-shot learning with models like [GPT-2](https://cameronrwolfe.substack.com/p/language-models-gpt-and-gpt-2)
    and [GPT-3](https://cameronrwolfe.substack.com/i/88082618/language-models-are-few-shot-learners)
    [5, 6]. When fine-tuned to align with human preferences and instructions, however,
    LLMs become even more compelling, enabling popular generative applications such
    as [coding assistants](https://cameronrwolfe.substack.com/i/93578656/evaluating-large-language-models-trained-on-code),
    [information-seeking dialogue agents](https://cameronrwolfe.substack.com/i/93578656/training-language-models-to-follow-instructions-with-human-feedback),
    and [chat-based search experiences](http://microsoft.com/en-us/bing?form=MW00X7&ef_id=_k_Cj0KCQjwgLOiBhC7ARIsAIeetVB3LkqQ31NslKZ7qj1J1Sx3PYJltfeBZs6bYulrUtPSrChf8KLmmZMaAkoKEALw_wcB_k_&OCID=AIDcmmf8m4fdss_SEM__k_Cj0KCQjwgLOiBhC7ARIsAIeetVB3LkqQ31NslKZ7qj1J1Sx3PYJltfeBZs6bYulrUtPSrChf8KLmmZMaAkoKEALw_wcB_k_&gclid=Cj0KCQjwgLOiBhC7ARIsAIeetVB3LkqQ31NslKZ7qj1J1Sx3PYJltfeBZs6bYulrUtPSrChf8KLmmZMaAkoKEALw_wcB&ch=).
  prefs: []
  type: TYPE_NORMAL
- en: 'Due to the applications that they make possible, LLMs have seen a quick rise
    to fame both in research communities and popular culture. During this rise, we
    have also witnessed the development of a new, complementary field: *prompt engineering*.
    At a high-level, LLMs operate by *i)* taking text (i.e., a prompt) as input and
    *ii)* producing textual output from which we can extract something useful (e.g.,
    a classification, summarization, translation, etc.). The flexibility of this approach
    is beneficial. At the same time, however, we must determine how to properly construct
    out input prompt such that the LLM has the best chance of generating the desired
    output.'
  prefs: []
  type: TYPE_NORMAL
- en: Prompt engineering is an empirical science that studies how different prompting
    strategies can be use to optimize LLM…
  prefs: []
  type: TYPE_NORMAL
