["```py\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\ntokenizer = AutoTokenizer.from_pretrained(\"tomasonjo/movie-generator-small\")\nmodel = AutoModelForCausalLM.from_pretrained(\"tomasonjo/movie-generator-small\").to(\n    device\n)\n\nprefix = \"\\nCreate a Cypher statement to answer the following question:\"\n\ndef generate_cypher(prompt):\n    inputs = tokenizer(\n        f\"{prefix}{prompt}<|endoftext|>\", return_tensors=\"pt\", add_special_tokens=False\n    ).to(device)\n    tokens = model.generate(\n        **inputs,\n        max_new_tokens=256,\n        temperature=0.3,\n        repetition_penalty=1.2,\n        num_beams=4,\n    )[0]\n    tokens = tokens[inputs[\"input_ids\"].shape[1] :]\n    return tokenizer.decode(tokens, skip_special_tokens=True)\n```", "```py\ngenerate_cypher(\"How many movies did Tom Hanks appear in?\")\n#MATCH (d:Person {name: 'Tom Hanks'})-[:ACTED_IN]->(m:Movie) \n#RETURN {movie: m.title} AS result\n\ngenerate_cypher(\"When was Toy Story released?\")\n#MATCH (m:Movie {title: 'When'})-[:IN_GENRE]->(g:Genre)\n#RETURN {genre: g.name} AS result\n```"]