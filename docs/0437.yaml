- en: 'Emojis Aid Social Media Sentiment Analysis: Stop Cleaning Them Out!'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è¡¨æƒ…ç¬¦å·æœ‰åŠ©äºç¤¾äº¤åª’ä½“æƒ…æ„Ÿåˆ†æï¼šä¸è¦å†æ¸…é™¤å®ƒä»¬äº†ï¼
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/emojis-aid-social-media-sentiment-analysis-stop-cleaning-them-out-bb32a1e5fc8e?source=collection_archive---------5-----------------------#2023-01-31](https://towardsdatascience.com/emojis-aid-social-media-sentiment-analysis-stop-cleaning-them-out-bb32a1e5fc8e?source=collection_archive---------5-----------------------#2023-01-31)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/emojis-aid-social-media-sentiment-analysis-stop-cleaning-them-out-bb32a1e5fc8e?source=collection_archive---------5-----------------------#2023-01-31](https://towardsdatascience.com/emojis-aid-social-media-sentiment-analysis-stop-cleaning-them-out-bb32a1e5fc8e?source=collection_archive---------5-----------------------#2023-01-31)
- en: Leverage emojis in social media sentiment analysis to improve accuracy.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åœ¨ç¤¾äº¤åª’ä½“æƒ…æ„Ÿåˆ†æä¸­åˆ©ç”¨è¡¨æƒ…ç¬¦å·æ¥æé«˜å‡†ç¡®æ€§ã€‚
- en: '[](https://medium.com/@bc3088?source=post_page-----bb32a1e5fc8e--------------------------------)[![Bale
    Chen](../Images/de6276419f1f93de346387a5ea2cc5b8.png)](https://medium.com/@bc3088?source=post_page-----bb32a1e5fc8e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bb32a1e5fc8e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bb32a1e5fc8e--------------------------------)
    [Bale Chen](https://medium.com/@bc3088?source=post_page-----bb32a1e5fc8e--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@bc3088?source=post_page-----bb32a1e5fc8e--------------------------------)[![Bale
    Chen](../Images/de6276419f1f93de346387a5ea2cc5b8.png)](https://medium.com/@bc3088?source=post_page-----bb32a1e5fc8e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bb32a1e5fc8e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bb32a1e5fc8e--------------------------------)
    [Bale Chen](https://medium.com/@bc3088?source=post_page-----bb32a1e5fc8e--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8695cd8317da&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Femojis-aid-social-media-sentiment-analysis-stop-cleaning-them-out-bb32a1e5fc8e&user=Bale+Chen&userId=8695cd8317da&source=post_page-8695cd8317da----bb32a1e5fc8e---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bb32a1e5fc8e--------------------------------)
    Â·14 min readÂ·Jan 31, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbb32a1e5fc8e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Femojis-aid-social-media-sentiment-analysis-stop-cleaning-them-out-bb32a1e5fc8e&user=Bale+Chen&userId=8695cd8317da&source=-----bb32a1e5fc8e---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8695cd8317da&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Femojis-aid-social-media-sentiment-analysis-stop-cleaning-them-out-bb32a1e5fc8e&user=Bale+Chen&userId=8695cd8317da&source=post_page-8695cd8317da----bb32a1e5fc8e---------------------post_header-----------)
    å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bb32a1e5fc8e--------------------------------)
    Â·14 åˆ†é’Ÿé˜…è¯»Â·2023å¹´1æœˆ31æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbb32a1e5fc8e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Femojis-aid-social-media-sentiment-analysis-stop-cleaning-them-out-bb32a1e5fc8e&user=Bale+Chen&userId=8695cd8317da&source=-----bb32a1e5fc8e---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbb32a1e5fc8e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Femojis-aid-social-media-sentiment-analysis-stop-cleaning-them-out-bb32a1e5fc8e&source=-----bb32a1e5fc8e---------------------bookmark_footer-----------)![](../Images/37923fbf0be08bd4aef8544f5266e515.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbb32a1e5fc8e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Femojis-aid-social-media-sentiment-analysis-stop-cleaning-them-out-bb32a1e5fc8e&source=-----bb32a1e5fc8e---------------------bookmark_footer-----------)![](../Images/37923fbf0be08bd4aef8544f5266e515.png)'
- en: Photo by [Denis Cherkashin](https://unsplash.com/@denic?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/emojis?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”± [Denis Cherkashin](https://unsplash.com/@denic?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    æä¾›ï¼Œæ¥æºäº [Unsplash](https://unsplash.com/s/photos/emojis?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: '**TL;DR:**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç®€æ˜æ‰¼è¦ï¼š**'
- en: Including emojis in the social media sentiment analysis would robustly improve
    the sentiment classification accuracy no matter what model you use or how you
    incorporate emojis in the loop
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ— è®ºä½ ä½¿ç”¨ä»€ä¹ˆæ¨¡å‹ï¼Œæˆ–å¦‚ä½•åœ¨åˆ†æä¸­çº³å…¥è¡¨æƒ…ç¬¦å·ï¼Œå°†è¡¨æƒ…ç¬¦å·åŒ…æ‹¬åœ¨ç¤¾äº¤åª’ä½“æƒ…æ„Ÿåˆ†æä¸­éƒ½èƒ½æ˜¾è‘—æé«˜æƒ…æ„Ÿåˆ†ç±»çš„å‡†ç¡®æ€§
- en: More than half of the popular BERT-based encoders donâ€™t support emojis
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¶…è¿‡ä¸€åŠçš„æµè¡Œ BERT åŸºç¡€ç¼–ç å™¨ä¸æ”¯æŒè¡¨æƒ…ç¬¦å·
- en: Twitter-RoBERTa encoder performs the best in sentiment analysis and coordinates
    well with emojis
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Twitter-RoBERTaç¼–ç å™¨åœ¨æƒ…æ„Ÿåˆ†æä¸­è¡¨ç°æœ€ä½³ï¼Œå¹¶ä¸”ä¸è¡¨æƒ…ç¬¦å·åè°ƒè‰¯å¥½
- en: Instead of cleaning emojis out, converting them to their textual description
    can help boost sentiment classification accuracy and handle the out-of-vocabulary
    issue.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸å…¶æ¸…é™¤è¡¨æƒ…ç¬¦å·ï¼Œä¸å¦‚å°†å®ƒä»¬è½¬æ¢ä¸ºæ–‡æœ¬æè¿°ï¼Œè¿™å¯ä»¥å¸®åŠ©æé«˜æƒ…æ„Ÿåˆ†ç±»çš„å‡†ç¡®æ€§å¹¶å¤„ç†è¯æ±‡è¡¨å¤–çš„é—®é¢˜ã€‚
- en: As social media has become an essential part of peopleâ€™s lives, the content
    that people share on the Internet is highly valuable to many parties. Many modern
    natural language processing (NLP) techniques were deployed to understand the general
    publicâ€™s social media posts. Sentiment Analysis is one of the most popular and
    critical NLP topics that focuses on analyzing opinions, sentiments, emotions,
    or attitudes toward entities in written texts computationally [[1](#1a95)]. Social
    media sentiment analysis (SMSA) is thus a field of understanding and learning
    representations for the sentiments expressed in short social media posts.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€ç¤¾äº¤åª’ä½“æˆä¸ºäººä»¬ç”Ÿæ´»çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œäººä»¬åœ¨äº’è”ç½‘ä¸Šåˆ†äº«çš„å†…å®¹å¯¹è®¸å¤šæ–¹é¢éƒ½æå…·ä»·å€¼ã€‚è®¸å¤šç°ä»£è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æŠ€æœ¯è¢«åº”ç”¨äºç†è§£å…¬ä¼—çš„ç¤¾äº¤åª’ä½“å¸–å­ã€‚æƒ…æ„Ÿåˆ†ææ˜¯æœ€å—æ¬¢è¿å’Œæœ€å…³é”®çš„NLPè¯é¢˜ä¹‹ä¸€ï¼Œä¾§é‡äºè®¡ç®—æ€§åœ°åˆ†æå¯¹ä¹¦é¢æ–‡æœ¬ä¸­å®ä½“çš„æ„è§ã€æƒ…æ„Ÿã€æƒ…ç»ªæˆ–æ€åº¦[[1](#1a95)]ã€‚å› æ­¤ï¼Œç¤¾äº¤åª’ä½“æƒ…æ„Ÿåˆ†æï¼ˆSMSAï¼‰æ˜¯ä¸€ä¸ªç†è§£å’Œå­¦ä¹ åœ¨çŸ­ç¤¾äº¤åª’ä½“å¸–å­ä¸­è¡¨è¾¾æƒ…æ„Ÿçš„é¢†åŸŸã€‚
- en: Another important feature of this project is the cute little in-text graphics
    â€” emojisğŸ˜„. These graphical symbols have increasingly gained ground in social media
    communications. According to [Emojipediaâ€™s statistics](https://emojipedia.org/stats/)
    in 2021, a famous emoji reference site, over one-fifth of the tweets now contains
    emojis (21.54%), while over half of the comments on Instagram include emojis.
    Emojis are handy and concise ways to express emotions and convey meanings, which
    may explain their great popularity.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªé¡¹ç›®çš„å¦ä¸€ä¸ªé‡è¦ç‰¹å¾æ˜¯å¯çˆ±çš„æ–‡å†…å›¾å½¢â€”â€”è¡¨æƒ…ç¬¦å·ğŸ˜„ã€‚è¿™äº›å›¾å½¢ç¬¦å·åœ¨ç¤¾äº¤åª’ä½“é€šè®¯ä¸­è¶Šæ¥è¶Šå—åˆ°æ¬¢è¿ã€‚æ ¹æ®[Emojipediaçš„ç»Ÿè®¡æ•°æ®](https://emojipedia.org/stats/)ï¼ˆ2021å¹´ï¼‰ï¼Œä¸€ä¸ªè‘—åçš„è¡¨æƒ…ç¬¦å·å‚è€ƒç½‘ç«™ï¼Œç°åœ¨è¶…è¿‡äº”åˆ†ä¹‹ä¸€çš„æ¨æ–‡åŒ…å«è¡¨æƒ…ç¬¦å·ï¼ˆ21.54%ï¼‰ï¼Œè€Œè¶…è¿‡ä¸€åŠçš„Instagramè¯„è®ºä¸­åŒ…å«è¡¨æƒ…ç¬¦å·ã€‚è¡¨æƒ…ç¬¦å·æ˜¯ä¸€ç§æ–¹ä¾¿ä¸”ç®€æ´çš„è¡¨è¾¾æƒ…æ„Ÿå’Œä¼ è¾¾æ„ä¹‰çš„æ–¹å¼ï¼Œè¿™å¯èƒ½è§£é‡Šäº†å®ƒä»¬çš„å·¨å¤§å—æ¬¢è¿ç¨‹åº¦ã€‚
- en: However ubiquitous emojis are in network communications, they are not favored
    by the field of NLP and SMSA. In the stage of preprocessing data, emojis are usually
    removed alongside other unstructured information like URLs, stop words, unique
    characters, and pictures [[2](#c7e8)]. While some researchers have started to
    study the potential of including emojis in SMSA in recent years, it remains a
    niche approach and awaits further research. This project aims to **examine the
    emoji-compatibility of trending BERT encoders** and **explore different methods
    of incorporating emojis in SMSA to improve accuracy**.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡è¡¨æƒ…ç¬¦å·åœ¨ç½‘ç»œé€šä¿¡ä¸­æ— å¤„ä¸åœ¨ï¼Œä½†å®ƒä»¬åœ¨NLPå’ŒSMSAé¢†åŸŸå¹¶ä¸å—é’çã€‚åœ¨æ•°æ®é¢„å¤„ç†é˜¶æ®µï¼Œè¡¨æƒ…ç¬¦å·é€šå¸¸ä¼šä¸å…¶ä»–éç»“æ„åŒ–ä¿¡æ¯å¦‚URLã€åœç”¨è¯ã€ç‰¹æ®Šå­—ç¬¦å’Œå›¾ç‰‡ä¸€èµ·è¢«åˆ é™¤[[2](#c7e8)]ã€‚è™½ç„¶ä¸€äº›ç ”ç©¶äººå‘˜è¿‘å¹´æ¥å¼€å§‹ç ”ç©¶åœ¨SMSAä¸­åŒ…å«è¡¨æƒ…ç¬¦å·çš„æ½œåŠ›ï¼Œä½†è¿™ä»ç„¶æ˜¯ä¸€ç§å°ä¼—æ–¹æ³•ï¼Œç­‰å¾…è¿›ä¸€æ­¥ç ”ç©¶ã€‚è¿™ä¸ªé¡¹ç›®æ—¨åœ¨**æ£€éªŒæµè¡Œçš„BERTç¼–ç å™¨å¯¹è¡¨æƒ…ç¬¦å·çš„å…¼å®¹æ€§**å¹¶**æ¢ç´¢å°†è¡¨æƒ…ç¬¦å·èå…¥SMSAä»¥æé«˜å‡†ç¡®æ€§çš„æ–¹æ³•**ã€‚
- en: Table of Contents
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç›®å½•
- en: '**1** [**Background Knowledge**](#776f)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**1** [**èƒŒæ™¯çŸ¥è¯†**](#776f)'
- en: 1.1 [What is SMSA exactly?](#4843)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 1.1 [SMSAç©¶ç«Ÿæ˜¯ä»€ä¹ˆï¼Ÿ](#4843)
- en: 1.2 [Development of Sentiment Analysis Methodologies](#d8db)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 1.2 [æƒ…æ„Ÿåˆ†ææ–¹æ³•çš„å‘å±•](#d8db)
- en: 2[**Experiment**](#cfe0)2.1 [Model design](#40f1)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 2[**å®éªŒ**](#cfe0)2.1 [æ¨¡å‹è®¾è®¡](#40f1)
- en: 2.2 [Lesson learned in Data Preparation Stage (A Sad Story)](#2f88)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 2.2 [æ•°æ®å‡†å¤‡é˜¶æ®µçš„ç»éªŒæ•™è®­ï¼ˆä¸€ä¸ªæ‚²ä¼¤çš„æ•…äº‹ï¼‰](#2f88)
- en: 2.3 [Emoji-compatibility Test of the BERT family](#666a)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 2.3 [BERTå®¶æ—çš„è¡¨æƒ…ç¬¦å·å…¼å®¹æ€§æµ‹è¯•](#666a)
- en: 2.4 [Experimenting Methods to Preprocess Emojis](#bc42)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 2.4 [å®éªŒæ–¹æ³•æ¥é¢„å¤„ç†è¡¨æƒ…ç¬¦å·](#bc42)
- en: '**3** [**Results Discussion**](#df89) **4** [**Conclusion**](#fa8d)[**Acknowledgments**](#5d30)[**Reference**](#e8ad)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**3** [**ç»“æœè®¨è®º**](#df89) **4** [**ç»“è®º**](#fa8d)[**è‡´è°¢**](#5d30)[**å‚è€ƒæ–‡çŒ®**](#e8ad)'
- en: 1 Background Knowledge
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 èƒŒæ™¯çŸ¥è¯†
- en: 1.1 What is SMSA exactly?
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 SMSAç©¶ç«Ÿæ˜¯ä»€ä¹ˆï¼Ÿ
- en: 'Here is some background knowledge about SMSA you might want to know before
    looking into the actual experiment. No technical background/math is required so
    far. Let me first explain the intuition of the most typical SMSA task:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯ä¸€äº›å…³äºSMSAçš„èƒŒæ™¯çŸ¥è¯†ï¼Œä½ å¯èƒ½å¸Œæœ›åœ¨æ·±å…¥å®é™…å®éªŒä¹‹å‰äº†è§£ã€‚åˆ°ç›®å‰ä¸ºæ­¢ï¼Œä¸éœ€è¦æŠ€æœ¯èƒŒæ™¯/æ•°å­¦çŸ¥è¯†ã€‚è®©æˆ‘é¦–å…ˆè§£é‡Šæœ€å…¸å‹çš„SMSAä»»åŠ¡çš„ç›´è§‰ï¼š
- en: '![](../Images/08d91363c13fa841f5deb5f015f9ded1.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08d91363c13fa841f5deb5f015f9ded1.png)'
- en: SMSA Example
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: SMSAç¤ºä¾‹
- en: As the picture above shows, given a social media post, the model (represented
    by the gray robot) will output the prediction of its sentiment label. In this
    example, the model responds that this post is 57.60% likely to express positive
    sentiment, 12.38% likely to be negative, and 30.02% likely to be neutral. Some
    studies classify posts in a binary way, i.e. positive/negative, but others consider
    â€œneutralâ€ as an option as well. This project follows the latter.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œç»™å®šä¸€ä¸ªç¤¾äº¤åª’ä½“å¸–å­ï¼Œæ¨¡å‹ï¼ˆç”±ç°è‰²æœºå™¨äººè¡¨ç¤ºï¼‰å°†è¾“å‡ºå…¶æƒ…æ„Ÿæ ‡ç­¾çš„é¢„æµ‹ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæ¨¡å‹å›åº”è¯¥å¸–å­ 57.60% å¯èƒ½è¡¨è¾¾æ­£é¢æƒ…æ„Ÿï¼Œ12.38%
    å¯èƒ½æ˜¯è´Ÿé¢ï¼Œ30.02% å¯èƒ½æ˜¯ä¸­ç«‹çš„ã€‚ä¸€äº›ç ”ç©¶å°†å¸–å­åˆ†ç±»ä¸ºäºŒå…ƒæ–¹å¼ï¼Œå³æ­£é¢/è´Ÿé¢ï¼Œä½†å…¶ä»–ç ”ç©¶ä¹Ÿè€ƒè™‘äº†â€œä¸­ç«‹â€ä½œä¸ºé€‰é¡¹ã€‚æœ¬é¡¹ç›®éµå¾ªåè€…ã€‚
- en: 1.2 Development of Sentiment Analysis Methodologies
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 æƒ…æ„Ÿåˆ†ææ–¹æ³•çš„å‘å±•
- en: To my best knowledge, the first quantitative approach to studying social media
    sentiment is using the **lexicon-based method**. The model has a predefined lexicon
    that maps each token to a sentiment score. So, given a sentence, the model consults
    the lexicon, aggregates the sentiment scores of each word, and outputs the overall
    sentiment score. Very intuitive, right?
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æ®æˆ‘äº†è§£ï¼Œç ”ç©¶ç¤¾äº¤åª’ä½“æƒ…æ„Ÿçš„é¦–ä¸ªå®šé‡æ–¹æ³•æ˜¯ä½¿ç”¨**è¯æ±‡è¡¨æ–¹æ³•**ã€‚è¯¥æ¨¡å‹æœ‰ä¸€ä¸ªé¢„å®šä¹‰çš„è¯æ±‡è¡¨ï¼Œå°†æ¯ä¸ªè¯å…ƒæ˜ å°„åˆ°æƒ…æ„Ÿåˆ†æ•°ã€‚å› æ­¤ï¼Œç»™å®šä¸€ä¸ªå¥å­ï¼Œæ¨¡å‹æŸ¥è¯¢è¯æ±‡è¡¨ï¼Œæ±‡æ€»æ¯ä¸ªè¯çš„æƒ…æ„Ÿåˆ†æ•°ï¼Œå¹¶è¾“å‡ºæ€»ä½“æƒ…æ„Ÿåˆ†æ•°ã€‚éå¸¸ç›´è§‚ï¼Œå¯¹å§ï¼Ÿ
- en: '![](../Images/a25d24f3eec39ee769107336e506031b.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a25d24f3eec39ee769107336e506031b.png)'
- en: Basic Diagram of a Lexicon-based Sentiment Analysis Model
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºè¯æ±‡è¡¨çš„æƒ…æ„Ÿåˆ†ææ¨¡å‹åŸºæœ¬å›¾
- en: '[SentiWordNet](https://github.com/aesuli/SentiWordNet) and [VADER](https://github.com/cjhutto/vaderSentiment)
    are the two paradigms of this kind that have been favored by both the industry
    and academia.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[SentiWordNet](https://github.com/aesuli/SentiWordNet) å’Œ [VADER](https://github.com/cjhutto/vaderSentiment)
    æ˜¯è¿™ç§æ–¹æ³•çš„ä¸¤ä¸ªèŒƒä¾‹ï¼Œå—åˆ°äº†ä¸šç•Œå’Œå­¦æœ¯ç•Œçš„é’çã€‚'
- en: With the development of **machine learning**, classifiers like SVM, Random Forests,
    Multi-layer Perceptron, etc., gained ground in sentiment analysis. However, textual
    input isnâ€™t valid for those models, so those classifiers are compounded with **word
    embedding models** to perform sentiment analysis tasks. Word embedding models
    convert words into numerical vectors that machines could play with. [Googleâ€™s
    word2vec](https://arxiv.org/abs/1301.3781) embedding model was a great breakthrough
    in representation learning for textual data, followed by [GloVe by Pennington
    et al.](https://nlp.stanford.edu/projects/glove/) and [fasttext by Facebook](https://fasttext.cc/).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€**æœºå™¨å­¦ä¹ **çš„å‘å±•ï¼Œåƒ SVMã€éšæœºæ£®æ—ã€å¤šå±‚æ„ŸçŸ¥å™¨ç­‰åˆ†ç±»å™¨åœ¨æƒ…æ„Ÿåˆ†æä¸­è·å¾—äº†ç«‹è¶³ä¹‹åœ°ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹ä¸é€‚ç”¨äºæ–‡æœ¬è¾“å…¥ï¼Œå› æ­¤è¿™äº›åˆ†ç±»å™¨ä¸**è¯åµŒå…¥æ¨¡å‹**ç»“åˆä»¥æ‰§è¡Œæƒ…æ„Ÿåˆ†æä»»åŠ¡ã€‚è¯åµŒå…¥æ¨¡å‹å°†è¯è¯­è½¬æ¢ä¸ºæœºå™¨å¯ä»¥æ“ä½œçš„æ•°å€¼å‘é‡ã€‚[Google
    çš„ word2vec](https://arxiv.org/abs/1301.3781) åµŒå…¥æ¨¡å‹æ˜¯æ–‡æœ¬æ•°æ®è¡¨ç¤ºå­¦ä¹ çš„é‡å¤§çªç ´ï¼Œå…¶åæ˜¯[Pennington
    ç­‰äººçš„ GloVe](https://nlp.stanford.edu/projects/glove/)å’Œ[Facebook çš„ fasttext](https://fasttext.cc/)ã€‚
- en: Due to the sequential nature of natural language and the immense popularity
    of Deep Learning, **Recurrent Neural Network (RNN)** then becomes â€œthe popular
    kid.â€ RNN decodes, or â€œreadsâ€, the sequence of word embeddings in order, preserving
    the sequential structure in the loop, which lexicon-based models and traditional
    machine learning models didnâ€™t achieve.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºè‡ªç„¶è¯­è¨€çš„é¡ºåºç‰¹æ€§å’Œæ·±åº¦å­¦ä¹ çš„æå¤§æ™®åŠï¼Œ**é€’å½’ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰** æˆä¸ºäº†â€œæµè¡Œçš„å°å­â€ã€‚RNN æŒ‰é¡ºåºè§£ç æˆ–â€œè¯»å–â€è¯åµŒå…¥åºåˆ—ï¼Œåœ¨å¾ªç¯ä¸­ä¿ç•™é¡ºåºç»“æ„ï¼Œè€Œè¯æ±‡è¡¨æ¨¡å‹å’Œä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹æœªèƒ½å®ç°è¿™ä¸€ç‚¹ã€‚
- en: '![](../Images/c4ff03168aa444fe5c62fe3842d61634.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c4ff03168aa444fe5c62fe3842d61634.png)'
- en: A Typical Workflow of SMSA Nowadays
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ç°ä»£ SMSA çš„å…¸å‹å·¥ä½œæµç¨‹
- en: The evolved workflow is explained in the diagram above. Word embeddings are
    passed into an RNN model that outputs the last hidden state(s) (If you donâ€™t know
    what the last hidden state is, itâ€™s intuitively the â€œsummaryâ€ composed by the
    RNN after â€œreadingâ€ all the text.) Lastly, we use a feed-forward fully connected
    neural network to map the high-dimensional hidden state to a sentiment label.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šå›¾è§£é‡Šäº†æ¼”å˜åçš„å·¥ä½œæµç¨‹ã€‚è¯åµŒå…¥è¢«ä¼ å…¥ RNN æ¨¡å‹ï¼Œæ¨¡å‹è¾“å‡ºæœ€åä¸€ä¸ªéšè—çŠ¶æ€ï¼ˆå¦‚æœä½ ä¸æ¸…æ¥šæœ€åçš„éšè—çŠ¶æ€æ˜¯ä»€ä¹ˆï¼Œç›´è§‚ä¸Šå®ƒæ˜¯ RNN åœ¨â€œè¯»å–â€å®Œæ‰€æœ‰æ–‡æœ¬åâ€œæ€»ç»“â€çš„å†…å®¹ï¼‰ã€‚æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨å‰é¦ˆå…¨è¿æ¥ç¥ç»ç½‘ç»œå°†é«˜ç»´éšè—çŠ¶æ€æ˜ å°„åˆ°æƒ…æ„Ÿæ ‡ç­¾ä¸Šã€‚
- en: We are almost there! The last piece of the puzzle is the **Transformer models**.
    Even if you havenâ€™t learned NLP, you still might have heard about â€œAttention is
    All You Needâ€ [[3](#1c64)]. In this paper, they proposed the self-attention technique
    and developed the Transformer Model.These models are so powerful that it transcends
    the previous models in almost every subtask of NLP. If you are not familiar with
    Transformer models, I strongly recommend you read [this introductory article](/transformers-141e32e69591)
    by Giuliano Giacaglia.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¿«å®Œæˆäº†ï¼æœ€åä¸€å—æ‹¼å›¾æ˜¯**Transformeræ¨¡å‹**ã€‚å³ä½¿ä½ è¿˜æ²¡æœ‰å­¦ä¹ NLPï¼Œä½ å¯èƒ½ä¹Ÿå¬è¯´è¿‡â€œAttention is All You Needâ€[[3](#1c64)]ã€‚åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œä»–ä»¬æå‡ºäº†è‡ªæ³¨æ„åŠ›æŠ€æœ¯ï¼Œå¹¶å¼€å‘äº†Transformeræ¨¡å‹ã€‚è¿™äº›æ¨¡å‹éå¸¸å¼ºå¤§ï¼Œä»¥è‡³äºåœ¨å‡ ä¹æ‰€æœ‰NLPçš„å­ä»»åŠ¡ä¸­è¶…è¶Šäº†ä¹‹å‰çš„æ¨¡å‹ã€‚å¦‚æœä½ ä¸ç†Ÿæ‚‰Transformeræ¨¡å‹ï¼Œæˆ‘å¼ºçƒˆæ¨èä½ é˜…è¯»Giuliano
    Giacagliaçš„[è¿™ç¯‡å…¥é—¨æ–‡ç« ](/transformers-141e32e69591)ã€‚
- en: Both industry and academia have started to use the pretrained Transformer models
    on a large scale due to their unbeatable performance. Thanks to the [Hugging Face](http://huggingface.co/models)
    *transformer* package, developers can now easily import and deploy those large
    pretrained models. BERT, aka. Bidirectional Encoder Representations for Transformer,
    is the most famous transformer-based encoder model that learns excellent representations
    for text. Later on, RoBERTa, BERTweet, DeBERTa, etc., were developed based on
    BERT.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºé¢„è®­ç»ƒTransformeræ¨¡å‹å…·æœ‰æ— ä¸ä¼¦æ¯”çš„æ€§èƒ½ï¼Œä¸šç•Œå’Œå­¦æœ¯ç•Œå·²ç»å¼€å§‹å¤§è§„æ¨¡ä½¿ç”¨è¿™äº›æ¨¡å‹ã€‚å¤šäºäº†[Hugging Face](http://huggingface.co/models)çš„*transformer*åŒ…ï¼Œå¼€å‘è€…ç°åœ¨å¯ä»¥è½»æ¾å¯¼å…¥å’Œéƒ¨ç½²è¿™äº›å¤§å‹é¢„è®­ç»ƒæ¨¡å‹ã€‚BERTï¼Œå³åŒå‘ç¼–ç å™¨è¡¨ç¤ºçš„Transformerï¼Œæ˜¯æœ€è‘—åçš„åŸºäºTransformerçš„ç¼–ç å™¨æ¨¡å‹ï¼Œå®ƒä¸ºæ–‡æœ¬å­¦ä¹ å‡ºè‰²çš„è¡¨ç¤ºã€‚ä¹‹åï¼ŒåŸºäºBERTå¼€å‘äº†RoBERTaã€BERTweetã€DeBERTaç­‰æ¨¡å‹ã€‚
- en: 2 Experiments
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2 å®éªŒ
- en: 'With all those background knowledge, we can now dive into the experiments and
    programming parts! If you do feel not confident with the mechanism of NLP, I recommend
    you to skip the technical details or go read some introductory blogs about NLP
    on Towards Data Science. Letâ€™s clarify our experiment objectives first. We want
    to know:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰äº†è¿™äº›èƒŒæ™¯çŸ¥è¯†ï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥æ·±å…¥åˆ°å®éªŒå’Œç¼–ç¨‹éƒ¨åˆ†äº†ï¼å¦‚æœä½ å¯¹NLPæœºåˆ¶æ„Ÿåˆ°ä¸è‡ªä¿¡ï¼Œæˆ‘å»ºè®®ä½ è·³è¿‡æŠ€æœ¯ç»†èŠ‚æˆ–é˜…è¯»ä¸€äº›å…³äºNLPçš„å…¥é—¨åšå®¢ï¼Œä¾‹å¦‚åœ¨Towards
    Data Scienceä¸Šã€‚é¦–å…ˆï¼Œæˆ‘ä»¬è¦æ˜ç¡®å®éªŒç›®æ ‡ã€‚æˆ‘ä»¬æƒ³çŸ¥é“ï¼š
- en: how compatible the currently trending pretrained BERT-based models are with
    emoji data.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›®å‰æµè¡Œçš„åŸºäºé¢„è®­ç»ƒBERTæ¨¡å‹çš„å…¼å®¹æ€§å¦‚ä½•ä¸emojiæ•°æ®ã€‚
- en: how the performance would be influenced if we incorporate emojis in the SMSA
    process.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬åœ¨SMSAè¿‡ç¨‹ä¸­åŠ å…¥emojiï¼Œæ€§èƒ½ä¼šå—åˆ°ä»€ä¹ˆå½±å“ã€‚
- en: what exactly we should do in the data processing stage to include the emojis.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ•°æ®å¤„ç†é˜¶æ®µï¼Œæˆ‘ä»¬åº”è¯¥å¦‚ä½•å¤„ç†ä»¥åŒ…å«emojiã€‚
- en: 2.1 Model Design
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 æ¨¡å‹è®¾è®¡
- en: 'Our model follows the aforementioned neural network paradigm that consists
    of a pretrained BERT-based encoder, a Bi-LSTM layer, and a feedforward fully connected
    network. The diagram is shown below:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„æ¨¡å‹éµå¾ªä¸Šè¿°çš„ç¥ç»ç½‘ç»œèŒƒå¼ï¼Œç”±é¢„è®­ç»ƒçš„åŸºäºBERTçš„ç¼–ç å™¨ã€Bi-LSTMå±‚å’Œå‰é¦ˆå…¨è¿æ¥ç½‘ç»œç»„æˆã€‚å›¾ç¤ºå¦‚ä¸‹ï¼š
- en: '![](../Images/1fe39eea86b8886152593fa59c468784.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1fe39eea86b8886152593fa59c468784.png)'
- en: Model diagram
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹å›¾
- en: To be clear, a preprocessed tweet is first passed through the pretrained encoder
    and becomes a sequence of representational vectors. Then, the representational
    vectors are passed through the Bi-LSTM layer. The two last hidden states of the
    two directions of LSTM will be processed by the feedforward layer to output the
    final prediction of the tweetâ€™s sentiment.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ¸…æ¥šï¼Œé¢„å¤„ç†çš„æ¨æ–‡é¦–å…ˆé€šè¿‡é¢„è®­ç»ƒç¼–ç å™¨ï¼Œå˜æˆä¸€ä¸ªè¡¨ç¤ºå‘é‡åºåˆ—ã€‚ç„¶åï¼Œè¡¨ç¤ºå‘é‡é€šè¿‡Bi-LSTMå±‚ã€‚LSTMçš„ä¸¤ä¸ªæ–¹å‘çš„ä¸¤ä¸ªæœ€åéšè—çŠ¶æ€å°†ç”±å‰é¦ˆå±‚å¤„ç†ï¼Œä»¥è¾“å‡ºæ¨æ–‡æƒ…æ„Ÿçš„æœ€ç»ˆé¢„æµ‹ã€‚
- en: We alter the encoder models and emoji preprocessing methods to observe the varying
    performance. The Bi-LSTM and feedforward layers are configured in the same way
    for all experiments in order to control variables. In the training process, we
    only train the Bi-LSTM and feed-forward layers. The parameters of pretrained encoder
    models are frozen.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ”¹å˜ç¼–ç å™¨æ¨¡å‹å’Œemojié¢„å¤„ç†æ–¹æ³•ï¼Œä»¥è§‚å¯Ÿæ€§èƒ½çš„å˜åŒ–ã€‚ä¸ºäº†æ§åˆ¶å˜é‡ï¼ŒBi-LSTMå’Œå‰é¦ˆå±‚åœ¨æ‰€æœ‰å®éªŒä¸­é…ç½®ç›¸åŒã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬åªè®­ç»ƒBi-LSTMå’Œå‰é¦ˆå±‚ã€‚é¢„è®­ç»ƒç¼–ç å™¨æ¨¡å‹çš„å‚æ•°è¢«å†»ç»“ã€‚
- en: The PyTorch implementation of this model and other technical details can be
    found in my [GitHub Repo](https://github.com/BaleChen/emoji-setiment-analysis).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹çš„PyTorchå®ç°åŠå…¶ä»–æŠ€æœ¯ç»†èŠ‚å¯ä»¥åœ¨æˆ‘çš„[GitHub Repo](https://github.com/BaleChen/emoji-setiment-analysis)ä¸­æ‰¾åˆ°ã€‚
- en: 2.2 Lesson Learnt in Data Preparation Stage
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 æ•°æ®å‡†å¤‡é˜¶æ®µçš„ç»éªŒæ•™è®­
- en: 'Data availability is every data science researcherâ€™s pain in the neck. At first,
    I wanted to find a benchmark Twitter sentiment analysis dataset where I can compare
    the results with the previous models, but I encountered the following setbacks:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®çš„å¯ç”¨æ€§æ˜¯æ¯ä¸ªæ•°æ®ç§‘å­¦ç ”ç©¶è€…çš„ç—›ç‚¹ã€‚èµ·åˆï¼Œæˆ‘æƒ³æ‰¾ä¸€ä¸ªåŸºå‡†çš„Twitteræƒ…æ„Ÿåˆ†ææ•°æ®é›†ï¼Œä»¥ä¾¿å°†ç»“æœä¸ä¹‹å‰çš„æ¨¡å‹è¿›è¡Œæ¯”è¾ƒï¼Œä½†æˆ‘é‡åˆ°äº†ä»¥ä¸‹éšœç¢ï¼š
- en: Most datasets only have â€œtweet IDâ€ as a query key to find the original content.
    To access the original tweet with the IDs, I need to have **Twitter API access**.
    My professor mentor and I both tried to apply for one, but neither of us was approved
    (We still donâ€™t know why).
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¤§å¤šæ•°æ•°æ®é›†åªæœ‰â€œæ¨æ–‡IDâ€ä½œä¸ºæŸ¥è¯¢é”®æ¥æŸ¥æ‰¾åŸå§‹å†…å®¹ã€‚è¦è®¿é—®å¸¦æœ‰IDçš„åŸå§‹æ¨æ–‡ï¼Œæˆ‘éœ€è¦**Twitter APIè®¿é—®æƒé™**ã€‚æˆ‘å’Œæˆ‘çš„æ•™æˆå¯¼å¸ˆéƒ½å°è¯•ç”³è¯·è¿‡ï¼Œä½†æˆ‘ä»¬éƒ½æ²¡æœ‰è·å¾—æ‰¹å‡†ï¼ˆæˆ‘ä»¬ä»ç„¶ä¸çŸ¥é“åŸå› ï¼‰ã€‚
- en: Wellâ€¦another problem is that **a large portion of the tweets already perished**!
    This means either they were deleted by the author or by the Twitter server for
    some reason.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å—¯â€¦â€¦å¦ä¸€ä¸ªé—®é¢˜æ˜¯**å¤§éƒ¨åˆ†æ¨æ–‡å·²ç»æ¶ˆå¤±**ï¼è¿™æ„å‘³ç€å®ƒä»¬è¦ä¹ˆè¢«ä½œè€…åˆ é™¤ï¼Œè¦ä¹ˆå› ä¸ºæŸç§åŸå› è¢«TwitteræœåŠ¡å™¨åˆ é™¤äº†ã€‚
- en: Even though there are few datasets that directly store tweet content, those
    stored in ***.csv or *.tsv formats are unable to preserve emojis**. Namely, the
    original tweets have emojis, but the compiled dataset that I downloaded from the
    web completely lost all emojis.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°½ç®¡æœ‰å¾ˆå°‘çš„æ•°æ®é›†ç›´æ¥å­˜å‚¨æ¨æ–‡å†…å®¹ï¼Œä½†å­˜å‚¨åœ¨***.csvæˆ–*.tsvæ ¼å¼çš„æ•°æ®é›†æ— æ³•ä¿ç•™è¡¨æƒ…ç¬¦å·**ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼ŒåŸå§‹æ¨æ–‡ä¸­æœ‰è¡¨æƒ…ç¬¦å·ï¼Œä½†æˆ‘ä»ç½‘ä¸Šä¸‹è½½çš„ç¼–è¯‘æ•°æ®é›†å®Œå…¨ä¸¢å¤±äº†æ‰€æœ‰è¡¨æƒ…ç¬¦å·ã€‚
- en: So, whenever you want to conduct Twitter sentiment analysis, make sure you first
    validate the dataset if the dataset store tweets by their Tweet ID, which require
    you to spend extra effort to retrieve the original text. Tweets can easily perish
    if the dataset is from years ago. Also, donâ€™t expect too much on applying for
    Twitter API. My mentor, who is an assistant professor at a prestigious American
    university, canâ€™t even meet their requirement (for some unknown reason). Lastly,
    to preserve the emojis, donâ€™t ever save them in csv or tsv format. Pickle, xlsx,
    or json can be your good choices.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæ— è®ºä½•æ—¶ä½ æƒ³è¿›è¡ŒTwitteræƒ…æ„Ÿåˆ†æï¼Œç¡®ä¿é¦–å…ˆéªŒè¯æ•°æ®é›†æ˜¯å¦é€šè¿‡Tweet IDå­˜å‚¨æ¨æ–‡ï¼Œè¿™éœ€è¦ä½ é¢å¤–çš„åŠªåŠ›æ¥æ£€ç´¢åŸå§‹æ–‡æœ¬ã€‚å¦‚æœæ•°æ®é›†æ˜¯å‡ å¹´å‰çš„ï¼Œæ¨æ–‡å¾ˆå®¹æ˜“æ¶ˆå¤±ã€‚æ­¤å¤–ï¼Œä¸è¦å¯¹ç”³è¯·Twitter
    APIæŠ±æœ‰å¤ªé«˜çš„æœŸæœ›ã€‚æˆ‘çš„å¯¼å¸ˆæ˜¯ä¸€ä½ç¾å›½è‘—åå¤§å­¦çš„åŠ©ç†æ•™æˆï¼Œä½†ä¹Ÿæ— æ³•æ»¡è¶³ä»–ä»¬çš„è¦æ±‚ï¼ˆåŸå› ä¸æ˜ï¼‰ã€‚æœ€åï¼Œä¸ºäº†ä¿ç•™è¡¨æƒ…ç¬¦å·ï¼Œåƒä¸‡ä¸è¦å°†å…¶ä¿å­˜ä¸ºcsvæˆ–tsvæ ¼å¼ã€‚Pickleã€xlsxæˆ–jsonå¯èƒ½æ˜¯ä½ çš„å¥½é€‰æ‹©ã€‚
- en: Anyways, to find a dataset that retains emojis, has sentiment labels, and is
    of desirable size was extremely hard for me. Eventually, I found this Novak et
    alâ€™s [dataset](https://figshare.com/articles/dataset/Emoji_Sentiment_Ranking/1600931)
    satisfies all criteria.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: æ— è®ºå¦‚ä½•ï¼Œæ‰¾åˆ°ä¸€ä¸ªä¿ç•™è¡¨æƒ…ç¬¦å·ã€å…·æœ‰æƒ…æ„Ÿæ ‡ç­¾ä¸”å¤§å°åˆé€‚çš„æ•°æ®é›†å¯¹æˆ‘æ¥è¯´éå¸¸å›°éš¾ã€‚æœ€ç»ˆï¼Œæˆ‘å‘ç°Novakç­‰äººçš„[æ•°æ®é›†](https://figshare.com/articles/dataset/Emoji_Sentiment_Ranking/1600931)ç¬¦åˆæ‰€æœ‰æ ‡å‡†ã€‚
- en: 2.3 Emoji-compatibility Test of the BERT family
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 BERTå®¶æ—çš„è¡¨æƒ…ç¬¦å·å…¼å®¹æ€§æµ‹è¯•
- en: Before implementing the BERT-based encoders, we need to know whether they are
    compatible with emojis, i.e. whether they can produce unique representations for
    emoji tokens. More specifically, before passing the tweet into an encoder, it
    will first be ***tokenized*** by a model tokenizer that is unique to the encoder
    (e.g. RoBERTa-base uses the RoBERTa-base tokenizer, while BERT-base uses the BERT-base
    tokenizer). What the tokenizer does is splitting the long strings of textual input
    into individual word tokens that are in the vocabulary (shown in the graph below).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å®ç°åŸºäºBERTçš„ç¼–ç å™¨ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦äº†è§£å®ƒä»¬æ˜¯å¦ä¸è¡¨æƒ…ç¬¦å·å…¼å®¹ï¼Œå³æ˜¯å¦èƒ½ä¸ºè¡¨æƒ…ç¬¦å·æ ‡è®°ç”Ÿæˆç‹¬ç‰¹çš„è¡¨ç¤ºã€‚æ›´å…·ä½“åœ°è¯´ï¼Œåœ¨å°†æ¨æ–‡ä¼ é€’ç»™ç¼–ç å™¨ä¹‹å‰ï¼Œå®ƒä¼šé¦–å…ˆç”±æ¨¡å‹åˆ†è¯å™¨è¿›è¡Œ***åˆ†è¯***ï¼Œè¿™ç§åˆ†è¯å™¨æ˜¯ç‰¹å®šäºç¼–ç å™¨çš„ï¼ˆä¾‹å¦‚ï¼ŒRoBERTa-baseä½¿ç”¨RoBERTa-baseåˆ†è¯å™¨ï¼Œè€ŒBERT-baseä½¿ç”¨BERT-baseåˆ†è¯å™¨ï¼‰ã€‚åˆ†è¯å™¨çš„ä½œç”¨æ˜¯å°†é•¿å­—ç¬¦ä¸²çš„æ–‡æœ¬è¾“å…¥æ‹†åˆ†ä¸ºè¯æ±‡è¡¨ä¸­çš„å•ä¸ªè¯æ ‡è®°ï¼ˆå¦‚ä¸‹å›¾æ‰€ç¤ºï¼‰ã€‚
- en: '![](../Images/46fd0a58138ad2eeca109b73da2a8f1b.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/46fd0a58138ad2eeca109b73da2a8f1b.png)'
- en: spaCyâ€™s rule-based Tokenizer ([source](https://github.com/explosion/spaCy))
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: spaCyçš„åŸºäºè§„åˆ™çš„åˆ†è¯å™¨ ([source](https://github.com/explosion/spaCy))
- en: In our case, if emojis are not in the tokenizer vocabulary, then they will all
    be tokenized into an unknown token (e.g. â€œ<UNK>â€). Encoder models will thus produce
    the same vector representation for all those unknown tokens, in which case cleaning
    or not cleaning out the emojis will technically not make any difference in the
    model performance.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œå¦‚æœè¡¨æƒ…ç¬¦å·ä¸åœ¨åˆ†è¯å™¨è¯æ±‡è¡¨ä¸­ï¼Œå®ƒä»¬å°†è¢«å…¨éƒ¨æ ‡è®°ä¸ºæœªçŸ¥æ ‡è®°ï¼ˆä¾‹å¦‚â€œ<UNK>â€ï¼‰ã€‚å› æ­¤ï¼Œç¼–ç å™¨æ¨¡å‹å°†å¯¹æ‰€æœ‰è¿™äº›æœªçŸ¥æ ‡è®°äº§ç”Ÿç›¸åŒçš„å‘é‡è¡¨ç¤ºï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¸…ç†æˆ–ä¸æ¸…ç†è¡¨æƒ…ç¬¦å·åœ¨æ¨¡å‹æ€§èƒ½ä¸ŠæŠ€æœ¯ä¸Šä¸ä¼šæœ‰ä»»ä½•åŒºåˆ«ã€‚
- en: I chose the following list of common BERT-based encoders.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘é€‰æ‹©äº†ä»¥ä¸‹å¸¸è§çš„åŸºäºBERTçš„ç¼–ç å™¨åˆ—è¡¨ã€‚
- en: ALBERT-base-v2
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ALBERT-base-v2
- en: BERT-base, BERT-large
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BERT-base, BERT-large
- en: BERTweet-base, BERTweet-large
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BERTweet-base, BERTweet-large
- en: DeBERTa-base, DeBERTa-large
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DeBERTa-base, DeBERTa-large
- en: DistilBERT
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DistilBERT
- en: RoBERTa-base, RoBERTa-large
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RoBERTa-base, RoBERTa-large
- en: Twitter-RoBERTa
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Twitter-RoBERTa
- en: XLMRoBERTa-base, XLMRoBERTa-large
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XLMRoBERTa-base, XLMRoBERTa-large
- en: 'The test can be easily done using the HuggingFace [*transformers*](https://pypi.org/project/transformers/)
    package and the [*emoji*](https://pypi.org/project/emoji/) package. We first import
    them:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ä»¥ä½¿ç”¨HuggingFaceçš„[*transformers*](https://pypi.org/project/transformers/)åŒ…å’Œ[*emoji*](https://pypi.org/project/emoji/)åŒ…è½»æ¾å®Œæˆæµ‹è¯•ã€‚æˆ‘ä»¬é¦–å…ˆå¯¼å…¥å®ƒä»¬ï¼š
- en: '[PRE0]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: AutoTokenizer is a very useful function where you can use the name of the model
    to load the corresponding tokenizer, like the following one-line code where I
    import the BERT-base tokenizer.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: AutoTokenizeræ˜¯ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„åŠŸèƒ½ï¼Œä½ å¯ä»¥ä½¿ç”¨æ¨¡å‹åç§°æ¥åŠ è½½ç›¸åº”çš„åˆ†è¯å™¨ï¼Œæ¯”å¦‚ä¸‹é¢è¿™è¡Œä»£ç ï¼Œå…¶ä¸­æˆ‘å¯¼å…¥äº†BERT-baseåˆ†è¯å™¨ã€‚
- en: '[PRE1]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Then, we use the *emoji* package to obtain the full list of emojis and use the
    encode and decode function to detect compatibility.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨*emoji*åŒ…æ¥è·å–å®Œæ•´çš„è¡¨æƒ…ç¬¦å·åˆ—è¡¨ï¼Œå¹¶ä½¿ç”¨ç¼–ç å’Œè§£ç åŠŸèƒ½æ¥æ£€æµ‹å…¼å®¹æ€§ã€‚
- en: '[PRE2]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 2.4 Experimenting Methods to Preprocess Emojis
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4 å®éªŒæ–¹æ³•æ¥é¢„å¤„ç†è¡¨æƒ…ç¬¦å·
- en: We came up with 5 ways of data preprocessing methods to make use of the emoji
    information as opposed to removing emojis (rm) from the original tweets.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æå‡ºäº†5ç§æ•°æ®é¢„å¤„ç†æ–¹æ³•ï¼Œä»¥åˆ©ç”¨è¡¨æƒ…ç¬¦å·ä¿¡æ¯ï¼Œè€Œä¸æ˜¯ä»åŸå§‹æ¨æ–‡ä¸­åˆ é™¤è¡¨æƒ…ç¬¦å· (rm)ã€‚
- en: '**Directly encode (dir)** Use the pretrained encoder models that support emojis
    to directly vectorize the emojis. In this way, emojis are treated as normal word
    tokens. This is the most straightforward method.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç›´æ¥ç¼–ç  (dir)** ä½¿ç”¨æ”¯æŒè¡¨æƒ…ç¬¦å·çš„é¢„è®­ç»ƒç¼–ç å™¨æ¨¡å‹ç›´æ¥å°†è¡¨æƒ…ç¬¦å·å‘é‡åŒ–ã€‚è¿™æ ·ï¼Œè¡¨æƒ…ç¬¦å·å°±ä¼šè¢«è§†ä¸ºæ™®é€šçš„è¯ä»¤ã€‚è¿™æ˜¯æœ€ç›´æ¥çš„æ–¹æ³•ã€‚'
- en: '**Replacing emojis with descriptions (emoji2desc)** The pretrained encoders
    are not specifically trained to create representations for emojis. Rather, they
    are trained on a vast amount of text. We conjecture that encoders might have better
    representations for words than emojis, so converting emojis to their official
    description might help better extract the semantic information. For example, â€œI
    love animals ğŸ˜â€ will become â€œI love animals smiling face with heart-eyes.â€ The
    python realization is shown below (using the *emoji* package):'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç”¨æè¿°æ›¿æ¢è¡¨æƒ…ç¬¦å· (emoji2desc)** é¢„è®­ç»ƒçš„ç¼–ç å™¨å¹¶æ²¡æœ‰ä¸“é—¨é’ˆå¯¹è¡¨æƒ…ç¬¦å·åˆ›å»ºè¡¨ç¤ºã€‚ç›¸åï¼Œå®ƒä»¬æ˜¯åœ¨å¤§é‡æ–‡æœ¬ä¸Šè¿›è¡Œè®­ç»ƒçš„ã€‚æˆ‘ä»¬æ¨æµ‹ç¼–ç å™¨å¯èƒ½å¯¹è¯è¯­çš„è¡¨ç¤ºè¦ä¼˜äºè¡¨æƒ…ç¬¦å·ï¼Œå› æ­¤å°†è¡¨æƒ…ç¬¦å·è½¬æ¢ä¸ºå…¶å®˜æ–¹æè¿°å¯èƒ½æœ‰åŠ©äºæ›´å¥½åœ°æå–è¯­ä¹‰ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œâ€œæˆ‘çˆ±åŠ¨ç‰©
    ğŸ˜â€å°†å˜æˆâ€œæˆ‘çˆ±åŠ¨ç‰© ç¬‘è„¸å¸¦å¿ƒçœ¼â€ã€‚ä¸‹é¢çš„Pythonå®ç°å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨*emoji*åŒ…ï¼š'
- en: '[PRE3]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Concatenate emojis (concat-emoji)** Essentially, we reposition the emojis
    to the end of the sentence and perform directly encode method. Since emojis donâ€™t
    belong to the grammatical structure of the sentences, we want to know if repositioning
    them would help better distinguish the textual and emoji information. For example,
    â€œThe cold weather is killing meğŸ§Š. Donâ€™t wanna work any longerğŸ˜¡ğŸ˜­. â€ becomes â€œThe
    cold weather is killing me. Donâ€™t wanna work any longer. ğŸ§ŠğŸ˜¡ğŸ˜­â€'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**è¿æ¥è¡¨æƒ…ç¬¦å· (concat-emoji)** æœ¬è´¨ä¸Šï¼Œæˆ‘ä»¬å°†è¡¨æƒ…ç¬¦å·é‡æ–°å®šä½åˆ°å¥å­çš„æœ«å°¾ï¼Œå¹¶æ‰§è¡Œç›´æ¥ç¼–ç æ–¹æ³•ã€‚ç”±äºè¡¨æƒ…ç¬¦å·ä¸å±äºå¥å­çš„è¯­æ³•ç»“æ„ï¼Œæˆ‘ä»¬æƒ³çŸ¥é“é‡æ–°å®šä½å®ƒä»¬æ˜¯å¦æœ‰åŠ©äºæ›´å¥½åœ°åŒºåˆ†æ–‡æœ¬å’Œè¡¨æƒ…ç¬¦å·ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œâ€œå¤©æ°”å¤ªå†·äº†ğŸ§Šã€‚
    ä¸æƒ³å†å·¥ä½œäº†ğŸ˜¡ğŸ˜­ã€‚â€ å˜æˆ â€œå¤©æ°”å¤ªå†·äº†ã€‚ ä¸æƒ³å†å·¥ä½œäº†ã€‚ ğŸ§ŠğŸ˜¡ğŸ˜­â€'
- en: '[PRE4]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Concatenate description (concat-desc)** Besides, we also tested replacing
    those repositioned emojis with their textual descriptions.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**è¿æ¥æè¿° (concat-desc)** æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æµ‹è¯•äº†ç”¨æ–‡æœ¬æè¿°æ›¿æ¢é‚£äº›é‡æ–°å®šä½çš„è¡¨æƒ…ç¬¦å·ã€‚'
- en: '[PRE5]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Meta-feature (meta)** Instead of treating emojis as part of the sentence,
    we can also regard them as high-level features. We use the Emoji Sentiment Ranking
    [[4](#de51)] lexicon to get the positivity, neutrality, negativity, and sentiment
    score features. Then, we concatenate those features with the emoji vector representations,
    which form the emoji meta-feature vector of the tweet. This vector harbors the
    emoji sentiment information of the tweet. Pure text will be as usual passed through
    the encoder and BiLSTM layer, then the meta-feature vector will be concatenated
    with the last hidden states from the BiLSTM layer to be the input of the feedforward
    layers. This process is essentially isolating the emojis from the sentence and
    treating them as meta-data of a tweet.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**å…ƒç‰¹å¾ï¼ˆmetaï¼‰** é™¤äº†å°†è¡¨æƒ…ç¬¦å·è§†ä¸ºå¥å­çš„ä¸€éƒ¨åˆ†å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥å°†å®ƒä»¬è§†ä¸ºé«˜çº§ç‰¹å¾ã€‚æˆ‘ä»¬ä½¿ç”¨è¡¨æƒ…ç¬¦å·æƒ…æ„Ÿæ’å [[4](#de51)] è¯å…¸æ¥è·å–ç§¯ææ€§ã€ä¸­ç«‹æ€§ã€æ¶ˆææ€§å’Œæƒ…æ„Ÿåˆ†æ•°ç‰¹å¾ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†è¿™äº›ç‰¹å¾ä¸è¡¨æƒ…ç¬¦å·çš„å‘é‡è¡¨ç¤ºè¿æ¥èµ·æ¥ï¼Œå½¢æˆæ¨æ–‡çš„è¡¨æƒ…ç¬¦å·å…ƒç‰¹å¾å‘é‡ã€‚è¿™ä¸ªå‘é‡åŒ…å«äº†æ¨æ–‡çš„è¡¨æƒ…ç¬¦å·æƒ…æ„Ÿä¿¡æ¯ã€‚çº¯æ–‡æœ¬å°†ç…§å¸¸é€šè¿‡ç¼–ç å™¨å’ŒBiLSTMå±‚ï¼Œç„¶åå°†å…ƒç‰¹å¾å‘é‡ä¸BiLSTMå±‚çš„æœ€åéšè—çŠ¶æ€è¿æ¥ï¼Œä½œä¸ºå‰é¦ˆå±‚çš„è¾“å…¥ã€‚è¿™ä¸ªè¿‡ç¨‹æœ¬è´¨ä¸Šæ˜¯å°†è¡¨æƒ…ç¬¦å·ä»å¥å­ä¸­éš”ç¦»å¼€æ¥ï¼Œå°†å®ƒä»¬è§†ä¸ºæ¨æ–‡çš„å…ƒæ•°æ®ã€‚'
- en: '**3 Results Discussion**'
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**ç»“æœè®¨è®º**'
- en: With all those technical designs, we finally arrive at the results part. First,
    letâ€™s look at the emoji-compatibility of those commonBERT-based encoder models.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ç»è¿‡æ‰€æœ‰è¿™äº›æŠ€æœ¯è®¾è®¡ï¼Œæˆ‘ä»¬æœ€ç»ˆè¿›å…¥äº†ç»“æœéƒ¨åˆ†ã€‚é¦–å…ˆï¼Œè®©æˆ‘ä»¬çœ‹çœ‹è¿™äº›å¸¸è§çš„BERTåŸºç¡€ç¼–ç å™¨æ¨¡å‹çš„è¡¨æƒ…ç¬¦å·å…¼å®¹æ€§ã€‚
- en: '![](../Images/bae1c8a4f2a8a36d4375f2199ed2ccb7.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bae1c8a4f2a8a36d4375f2199ed2ccb7.png)'
- en: Emoji-compatibility of BERT-based emoji models
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: BERTåŸºç¡€çš„è¡¨æƒ…ç¬¦å·æ¨¡å‹çš„è¡¨æƒ…ç¬¦å·å…¼å®¹æ€§
- en: '**More than half of those models canâ€™t recognize all emojis! RoBERTa** (both
    base and large versions), **DeBERTa** (both base and large versions), **BERTweet-large**,
    and **Twitter-RoBERTa** support all emojis. However, common encoders like **BERT**
    (both base and large versions), **DistilBERT**, and **ALBERT** nearly do not support
    any emoji.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**è¶…è¿‡ä¸€åŠçš„è¿™äº›æ¨¡å‹ä¸èƒ½è¯†åˆ«æ‰€æœ‰è¡¨æƒ…ç¬¦å·ï¼** RoBERTaï¼ˆåŸºç¡€ç‰ˆå’Œå¤§ç‰ˆï¼‰ã€**DeBERTa**ï¼ˆåŸºç¡€ç‰ˆå’Œå¤§ç‰ˆï¼‰ã€**BERTweet-large**
    å’Œ **Twitter-RoBERTa** æ”¯æŒæ‰€æœ‰è¡¨æƒ…ç¬¦å·ã€‚ç„¶è€Œï¼Œåƒ **BERT**ï¼ˆåŸºç¡€ç‰ˆå’Œå¤§ç‰ˆï¼‰ã€**DistilBERT** å’Œ **ALBERT**
    è¿™æ ·çš„å¸¸è§ç¼–ç å™¨å‡ ä¹ä¸æ”¯æŒä»»ä½•è¡¨æƒ…ç¬¦å·ã€‚'
- en: Now, letâ€™s compare the model performance with different emoji-compatible encoders
    and different methods to incorporate emojis. The percentage in the following graph
    indicates the sentiment classification accuracy. Each cell represents the accuracy
    of an encoder model with a certain preprocessing method.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ¯”è¾ƒä¸åŒè¡¨æƒ…ç¬¦å·å…¼å®¹ç¼–ç å™¨å’Œä¸åŒæ–¹æ³•ä¸‹çš„æ¨¡å‹æ€§èƒ½ã€‚ä¸‹å›¾ä¸­çš„ç™¾åˆ†æ¯”è¡¨ç¤ºæƒ…æ„Ÿåˆ†ç±»çš„å‡†ç¡®ç‡ã€‚æ¯ä¸ªå•å…ƒæ ¼ä»£è¡¨æŸç§é¢„å¤„ç†æ–¹æ³•ä¸‹çš„ç¼–ç å™¨æ¨¡å‹çš„å‡†ç¡®ç‡ã€‚
- en: (Note that *emoji2vec* is a baseline model that is developed in 2015\. Itâ€™s
    not BERT-based but itâ€™s a predefined emoji-embedding model that can also produce
    vector representation for emojis. It can be seen as an extension of Googleâ€™s Word2vec
    model)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆè¯·æ³¨æ„ *emoji2vec* æ˜¯ä¸€ä¸ªäº2015å¹´å¼€å‘çš„åŸºå‡†æ¨¡å‹ã€‚å®ƒä¸æ˜¯BERTåŸºç¡€çš„ï¼Œè€Œæ˜¯ä¸€ä¸ªé¢„å®šä¹‰çš„è¡¨æƒ…ç¬¦å·åµŒå…¥æ¨¡å‹ï¼Œä¹Ÿå¯ä»¥ç”Ÿæˆè¡¨æƒ…ç¬¦å·çš„å‘é‡è¡¨ç¤ºã€‚å®ƒå¯ä»¥çœ‹ä½œæ˜¯Googleçš„Word2vecæ¨¡å‹çš„æ‰©å±•ï¼‰
- en: '![](../Images/9603acca512c29461bcc59bc9041739b.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9603acca512c29461bcc59bc9041739b.png)'
- en: Sentiment Classification Accuracy
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ…æ„Ÿåˆ†ç±»å‡†ç¡®ç‡
- en: To compare different methods to incorporate emojis into the SMSA process, we
    also show the accuracy across different methods with confidence intervals.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ¯”è¾ƒå°†è¡¨æƒ…ç¬¦å·èå…¥SMSAè¿‡ç¨‹ä¸­çš„ä¸åŒæ–¹æ³•ï¼Œæˆ‘ä»¬è¿˜å±•ç¤ºäº†ä¸åŒæ–¹æ³•ä¸‹çš„å‡†ç¡®ç‡åŠç½®ä¿¡åŒºé—´ã€‚
- en: '![](../Images/564a0d218182070e34434676c064f680.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/564a0d218182070e34434676c064f680.png)'
- en: The average accuracy of each preprocessing method (with confidence interval)
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ç§é¢„å¤„ç†æ–¹æ³•çš„å¹³å‡å‡†ç¡®ç‡ï¼ˆå¸¦ç½®ä¿¡åŒºé—´ï¼‰
- en: One of the most significant insights is that **including emojis, no matter how
    you include them, enhances the performance of** SMSA **models.** Removing the
    emojis lowers the accuracy by 1.202% on average. For methods that include emojis,
    the overlapping confidence intervals indicate a relatively blurry distinction.
    Thereâ€™s no â€œgenerally bestâ€ method to utilize emojis.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªé‡è¦çš„å‘ç°æ˜¯ï¼Œ**æ— è®ºå¦‚ä½•åŒ…å«è¡¨æƒ…ç¬¦å·ï¼Œéƒ½èƒ½æå‡** SMSA **æ¨¡å‹çš„æ€§èƒ½ã€‚** ç§»é™¤è¡¨æƒ…ç¬¦å·å¹³å‡é™ä½äº†1.202%çš„å‡†ç¡®ç‡ã€‚å¯¹äºåŒ…å«è¡¨æƒ…ç¬¦å·çš„æ–¹æ³•ï¼Œé‡å çš„ç½®ä¿¡åŒºé—´è¡¨ç¤ºå‡ºç›¸å¯¹æ¨¡ç³Šçš„åŒºåˆ†ã€‚æ²¡æœ‰â€œé€šå¸¸æœ€ä½³â€çš„æ–¹æ³•æ¥åˆ©ç”¨è¡¨æƒ…ç¬¦å·ã€‚
- en: '![](../Images/9e8a528a73b2c060276b63a66e7b3861.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9e8a528a73b2c060276b63a66e7b3861.png)'
- en: The average accuracy of each encoder model (with confidence interval)
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªç¼–ç å™¨æ¨¡å‹çš„å¹³å‡å‡†ç¡®ç‡ï¼ˆå¸¦ç½®ä¿¡åŒºé—´ï¼‰
- en: For comparison among all encoder models, the results are shown in the bar chart
    above. The confidence interval is also annotated on the top of the bar chart.
    Small confidence intervals imply **high statistical confidence in the ranking**.
    **Twitter-RoBERTa performed the best** across all models, which is very likely
    caused by the **training domain**. ***emoji2vec***, which was developed in 2015
    and prior to the boom of transformer models, holds **relatively poor representations
    of emojis** under the standards of this time.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ‰€æœ‰ç¼–ç æ¨¡å‹ä¸­è¿›è¡Œæ¯”è¾ƒçš„ç»“æœå¦‚ä¸Šæ–¹æŸ±çŠ¶å›¾æ‰€ç¤ºã€‚æŸ±çŠ¶å›¾é¡¶éƒ¨ä¹Ÿæ ‡æ³¨äº†ç½®ä¿¡åŒºé—´ã€‚å°çš„ç½®ä¿¡åŒºé—´è¡¨ç¤º**å¯¹æ’åçš„ç»Ÿè®¡ä¿¡å¿ƒè¾ƒé«˜**ã€‚**Twitter-RoBERTaåœ¨æ‰€æœ‰æ¨¡å‹ä¸­è¡¨ç°æœ€ä½³**ï¼Œè¿™å¾ˆå¯èƒ½æ˜¯ç”±**è®­ç»ƒé¢†åŸŸ**é€ æˆçš„ã€‚***emoji2vec***ï¼Œè¯¥æ¨¡å‹å¼€å‘äº2015å¹´å¹¶æ—©äºå˜å‹å™¨æ¨¡å‹çš„å…´èµ·ï¼Œåœ¨å½“å‰æ ‡å‡†ä¸‹å¯¹è¡¨æƒ…ç¬¦å·çš„**è¡¨ç¤ºç›¸å¯¹è¾ƒå·®**ã€‚
- en: Now that no â€œgenerally bestâ€ method is found, we probe into how different models
    would benefit differently from various preprocessing methods. The following graph
    depicts the percentage improvement of using a certain preprocessing method compared
    with removing emojis at the beginning.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¢ç„¶æ²¡æœ‰æ‰¾åˆ°â€œæ™®éæœ€ä½³â€çš„æ–¹æ³•ï¼Œæˆ‘ä»¬æ·±å…¥æ¢è®¨ä¸åŒæ¨¡å‹å¦‚ä½•ä»å„ç§é¢„å¤„ç†æ–¹æ³•ä¸­è·å¾—ä¸åŒçš„æ”¶ç›Šã€‚ä¸‹å›¾å±•ç¤ºäº†ä½¿ç”¨æŸç§é¢„å¤„ç†æ–¹æ³•ä¸ä¸€å¼€å§‹ç§»é™¤è¡¨æƒ…ç¬¦å·ç›¸æ¯”çš„ç™¾åˆ†æ¯”æ”¹è¿›ã€‚
- en: '![](../Images/e41ec99904cff81302c9a289b4d89a1f.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e41ec99904cff81302c9a289b4d89a1f.png)'
- en: Percentage improvement heatmap
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: ç™¾åˆ†æ¯”æ”¹è¿›çƒ­å›¾
- en: Firstly, all the improvement indices are positive, which strongly justifies
    the usefulness of emojis in SMSA. Including emojis in the data would improve the
    SMSA modelâ€™s performance.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæ‰€æœ‰çš„æ”¹è¿›æŒ‡æ ‡éƒ½æ˜¯æ­£æ•°ï¼Œè¿™å¼ºæœ‰åŠ›åœ°è¯æ˜äº†è¡¨æƒ…ç¬¦å·åœ¨SMSAä¸­çš„æœ‰ç”¨æ€§ã€‚åœ¨æ•°æ®ä¸­åŒ…å«è¡¨æƒ…ç¬¦å·å°†æé«˜SMSAæ¨¡å‹çš„æ€§èƒ½ã€‚
- en: '**Generally for BERT-based models, directly encoding emojis seems to be a sufficient
    and sometimes the best method.** Surprisingly, the most straightforward methods
    work just as well as the complicated ones, if not better.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**é€šå¸¸ï¼Œå¯¹äºåŸºäºBERTçš„æ¨¡å‹ï¼Œç›´æ¥ç¼–ç è¡¨æƒ…ç¬¦å·ä¼¼ä¹æ˜¯ä¸€ç§è¶³å¤Ÿä¸”æœ‰æ—¶æ˜¯æœ€å¥½çš„æ–¹æ³•ã€‚** ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œæœ€ç®€å•çš„æ–¹æ³•æ•ˆæœä¸å¤æ‚çš„æ–¹æ³•ä¸€æ ·å¥½ï¼Œç”šè‡³æ›´å¥½ã€‚'
- en: '**Poor emoji representation learning models might benefit more from converting
    emojis to textual descriptions.** Maximal and minimal improvement both appear
    on the emoji2vec model. Itâ€™s likely that emoji2vec has relatively worse vector
    representations of emojis, but converting emojis to their textual descriptions
    would help capture the emotional meanings of a social media post.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**è¡¨æƒ…ç¬¦å·è¡¨ç¤ºå­¦ä¹ æ¨¡å‹è¾ƒå·®çš„æƒ…å†µå¯èƒ½ä¼šä»å°†è¡¨æƒ…ç¬¦å·è½¬æ¢ä¸ºæ–‡æœ¬æè¿°ä¸­å—ç›Šæ›´å¤šã€‚** emoji2vecæ¨¡å‹çš„æ”¹è¿›æ—¢å‡ºç°æœ€å¤§å€¼ä¹Ÿå‡ºç°æœ€å°å€¼ã€‚å¾ˆå¯èƒ½emoji2vecå¯¹è¡¨æƒ…ç¬¦å·çš„å‘é‡è¡¨ç¤ºè¾ƒå·®ï¼Œä½†å°†è¡¨æƒ…ç¬¦å·è½¬æ¢ä¸ºæ–‡æœ¬æè¿°æœ‰åŠ©äºæ•æ‰ç¤¾äº¤åª’ä½“å¸–å­çš„æƒ…æ„Ÿæ„ä¹‰ã€‚'
- en: '**RoBERTa-large displayed an unexpectedly small improvement regardless of preprocessing
    methods**, indicating that it doesnâ€™t benefit as much from the emojis as other
    BERT-based models. This result might be explained by the fact that RoBERTa-largeâ€™s
    architecture might be more suitable for learning representations for pure text
    than for emojis, but it still awaits a more rigorous justification.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**RoBERTa-largeæ— è®ºé¢„å¤„ç†æ–¹æ³•å¦‚ä½•æ˜¾ç¤ºå‡ºæ„å¤–çš„å°æ”¹è¿›**ï¼Œè¿™è¡¨æ˜å®ƒä¸åƒå…¶ä»–åŸºäºBERTçš„æ¨¡å‹é‚£æ ·å—ç›Šäºè¡¨æƒ…ç¬¦å·ã€‚è¿™ä¸ªç»“æœå¯èƒ½æ˜¯å› ä¸ºRoBERTa-largeçš„æ¶æ„å¯èƒ½æ›´é€‚åˆå­¦ä¹ çº¯æ–‡æœ¬çš„è¡¨ç¤ºè€Œä¸æ˜¯è¡¨æƒ…ç¬¦å·ï¼Œä½†ä»éœ€è¦æ›´ä¸¥æ ¼çš„è®ºè¯ã€‚'
- en: 4 Conclusion
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 ç»“è®º
- en: From this project, the key takeaway is that **including emojis in the loop of
    SMSA would improve the sentiment classification accuracy no matter what model
    or preprocessing method you use. So, THINK TWICE about cleaning them out when
    you face a social media sentiment analysis task!**
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è¿™ä¸ªé¡¹ç›®ä¸­ï¼Œå…³é”®çš„æ”¶è·æ˜¯**æ— è®ºä½ ä½¿ç”¨ä»€ä¹ˆæ¨¡å‹æˆ–é¢„å¤„ç†æ–¹æ³•ï¼Œåœ¨SMSAè¿‡ç¨‹ä¸­åŒ…å«è¡¨æƒ…ç¬¦å·éƒ½ä¼šæé«˜æƒ…æ„Ÿåˆ†ç±»çš„å‡†ç¡®æ€§ã€‚å› æ­¤ï¼Œå½“ä½ é¢å¯¹ç¤¾äº¤åª’ä½“æƒ…æ„Ÿåˆ†æä»»åŠ¡æ—¶ï¼Œ*ä¸€å®šè¦ä»”ç»†è€ƒè™‘*æ˜¯å¦æ¸…é™¤å®ƒä»¬ï¼**
- en: The best model to handle SMSA tasks and coordinate with emojis is the [Twitter-RoBERTa](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment)
    encoder! Please use it if you are dealing with Twitter data and analyzing tweet
    sentiment.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: å¤„ç†SMSAä»»åŠ¡å¹¶åè°ƒè¡¨æƒ…ç¬¦å·çš„æœ€ä½³æ¨¡å‹æ˜¯[Twitter-RoBERTa](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment)ç¼–ç å™¨ï¼å¦‚æœä½ æ­£åœ¨å¤„ç†Twitteræ•°æ®å’Œåˆ†ææ¨æ–‡æƒ…æ„Ÿï¼Œè¯·ä½¿ç”¨å®ƒã€‚
- en: Regarding how to incorporate the emojis specifically, the methods didnâ€™t show
    a significant difference, so a straightforward way â€” directly treating the emojis
    as regular word tokens â€” would do the job perfectly. Yet, considering that half
    of the common BERT-based encoders in our study donâ€™t support emojis, we recommend
    using the [emoji2desc](#ff68) method. That means converting emojis to their official
    textual description using [a simple line of code](#57b7) I mentioned before, which
    can easily handle the out-of-vocabulary emoji tokens.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºå¦‚ä½•å…·ä½“èå…¥è¡¨æƒ…ç¬¦å·ï¼Œæ–¹æ³•ä¹‹é—´å¹¶æ²¡æœ‰æ˜¾è‘—å·®å¼‚ï¼Œå› æ­¤ä¸€ç§ç›´æ¥çš„æ–¹æ³•â€”â€”å°†è¡¨æƒ…ç¬¦å·ç›´æ¥è§†ä¸ºæ™®é€šå•è¯æ ‡è®°â€”â€”å¯ä»¥å®Œç¾è§£å†³é—®é¢˜ã€‚ç„¶è€Œï¼Œè€ƒè™‘åˆ°æˆ‘ä»¬ç ”ç©¶ä¸­ä¸€åŠçš„å¸¸è§BERTç¼–ç å™¨ä¸æ”¯æŒè¡¨æƒ…ç¬¦å·ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨[emoji2desc](#ff68)æ–¹æ³•ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä½¿ç”¨ä¹‹å‰æåˆ°çš„[ä¸€è¡Œç®€å•ä»£ç ](#57b7)å°†è¡¨æƒ…ç¬¦å·è½¬æ¢ä¸ºå…¶å®˜æ–¹æ–‡æœ¬æè¿°ï¼Œè¿™å¯ä»¥è½»æ¾å¤„ç†è¯æ±‡è¡¨å¤–çš„è¡¨æƒ…ç¬¦å·æ ‡è®°ã€‚
- en: If you are using traditional word embeddings like *word2vec* and you also donâ€™t
    want to waste the cute emojis, consider using the [emoji2desc](#ff68) or [concat-emoji](#afb8)
    method instead of using *emoji2vec* model.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä½¿ç”¨ä¼ ç»Ÿçš„è¯åµŒå…¥å¦‚ *word2vec*ï¼Œè€Œä¸”ä½ ä¹Ÿä¸æƒ³æµªè´¹å¯çˆ±çš„è¡¨æƒ…ç¬¦å·ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨[emoji2desc](#ff68)æˆ–[concat-emoji](#afb8)æ–¹æ³•ï¼Œè€Œä¸æ˜¯ä½¿ç”¨
    *emoji2vec* æ¨¡å‹ã€‚
- en: Hope our project can guide SMSA researchers and industry workers on how to include
    emojis in the process. More importantly, this project offers a new perspective
    on improving SMSA accuracy. Diving into the technical bits is not necessarily
    the only way to make progress, and for example, these simple but powerful emojis
    can help as well.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›æˆ‘ä»¬çš„é¡¹ç›®èƒ½å¤ŸæŒ‡å¯¼SMSAç ”ç©¶äººå‘˜å’Œè¡Œä¸šå·¥ä½œè€…å¦‚ä½•åœ¨è¿‡ç¨‹ä¸­åŒ…å«è¡¨æƒ…ç¬¦å·ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œè¿™ä¸ªé¡¹ç›®æä¾›äº†ä¸€ç§æé«˜SMSAå‡†ç¡®æ€§çš„å…¨æ–°è§†è§’ã€‚æ·±å…¥ç ”ç©¶æŠ€æœ¯ç»†èŠ‚å¹¶ä¸æ˜¯å”¯ä¸€çš„è¿›å±•æ–¹å¼ï¼Œä¾‹å¦‚ï¼Œè¿™äº›ç®€å•å´å¼ºå¤§çš„è¡¨æƒ…ç¬¦å·ä¹Ÿå¯ä»¥æä¾›å¸®åŠ©ã€‚
- en: Scripts, an academic report, and more can be found in my [GitHub Repo](https://github.com/BaleChen/emoji-setiment-analysis).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: è„šæœ¬ã€å­¦æœ¯æŠ¥å‘ŠåŠæ›´å¤šå†…å®¹å¯ä»¥åœ¨æˆ‘çš„[GitHub Repo](https://github.com/BaleChen/emoji-setiment-analysis)ä¸­æ‰¾åˆ°ã€‚
- en: Regarding images in the post, all unless otherwise noted are by the author.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºæ–‡ç« ä¸­çš„å›¾ç‰‡ï¼Œé™¤éå¦æœ‰è¯´æ˜ï¼Œå¦åˆ™å‡ä¸ºä½œè€…æä¾›ã€‚
- en: '**Acknowledgments**'
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**è‡´è°¢**'
- en: I would like to extend my warmest gratitude to my research supervisor and mentor
    Professor [Mathieu LauriÃ¨re](https://mlauriere.github.io/). He provides me with
    insightful advice and guides me through this summer research. It is my great honor
    and pleasure to finish this study with him and receive his email greeting on my
    birthday.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è¡·å¿ƒæ„Ÿè°¢æˆ‘çš„ç ”ç©¶å¯¼å¸ˆå’ŒæŒ‡å¯¼æ•™æˆ[é©¬ä¿®Â·åŠ³é‡ŒåŸƒ](https://mlauriere.github.io/)ã€‚ä»–ä¸ºæˆ‘æä¾›äº†æ·±åˆ»çš„å»ºè®®ï¼Œå¹¶åœ¨è¿™ä¸ªå¤å­£ç ”ç©¶è¿‡ç¨‹ä¸­ç»™äºˆæŒ‡å¯¼ã€‚èƒ½ä¸ä»–ä¸€èµ·å®Œæˆè¿™é¡¹ç ”ç©¶ï¼Œå¹¶åœ¨æˆ‘ç”Ÿæ—¥æ—¶æ”¶åˆ°ä»–çš„é‚®ä»¶é—®å€™ï¼Œæˆ‘æ„Ÿåˆ°éå¸¸è£å¹¸å’Œé«˜å…´ã€‚
- en: This work was also supported in part through the NYU IT High Performance Computing
    resources, services, and staff expertise.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬å·¥ä½œè¿˜éƒ¨åˆ†å¾—åˆ°äº†çº½çº¦å¤§å­¦ITé«˜æ€§èƒ½è®¡ç®—èµ„æºã€æœåŠ¡å’Œå‘˜å·¥ä¸“ä¸šçŸ¥è¯†çš„æ”¯æŒã€‚
- en: Besides, I genuinely appreciate NYU and NYU Shanghai for offering me the [DURF](https://shanghai.nyu.edu/academics/undergraduate-research)
    research opportunity.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæˆ‘çœŸè¯šåœ°æ„Ÿè°¢çº½çº¦å¤§å­¦åŠçº½çº¦å¤§å­¦ä¸Šæµ·æ ¡åŒºæä¾›çš„[DURF](https://shanghai.nyu.edu/academics/undergraduate-research)ç ”ç©¶æœºä¼šã€‚
- en: Thanks to all my friends and family who helped me throughout this summer. The
    research would not have been possible without any of you.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢æ‰€æœ‰åœ¨è¿™ä¸ªå¤å¤©å¸®åŠ©æˆ‘çš„æœ‹å‹å’Œå®¶äººã€‚æ²¡æœ‰ä½ ä»¬çš„æ”¯æŒï¼Œè¿™é¡¹ç ”ç©¶æ˜¯ä¸å¯èƒ½å®Œæˆçš„ã€‚
- en: Reference
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[1] Liu, B. [Sentiment Analysis: Mining Opinions, Sentiments, and Emotions.](https://doi.org/10.1017/CBO9781139084789)
    (2015), Cambridge University Press, Cambridge.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Liu, B. [Sentiment Analysis: Mining Opinions, Sentiments, and Emotions.](https://doi.org/10.1017/CBO9781139084789)
    (2015)ï¼Œå‰‘æ¡¥å¤§å­¦å‡ºç‰ˆç¤¾ï¼Œå‰‘æ¡¥ã€‚'
- en: '[2] Chakriswaran, P., Vincent, D. R., Srinivasan, K., Sharma, V., Chang, C.-Y.,
    and Reina, D. G. [Emotion AI-Driven Sentiment Analysis: A Survey, Future Research
    Directions, and Open Issues.](https://doi.org/10.3390/app9245462) (2019), Applied
    Sciences.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Chakriswaran, P., Vincent, D. R., Srinivasan, K., Sharma, V., Chang, C.-Y.,
    å’Œ Reina, D. G. [Emotion AI-Driven Sentiment Analysis: A Survey, Future Research
    Directions, and Open Issues.](https://doi.org/10.3390/app9245462) (2019)ï¼Œåº”ç”¨ç§‘å­¦ã€‚'
- en: '[3] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez,
    A., Kaiser, u., & Polosukhin, I. [Attention is All you Need.](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
    (2017), In *Advances in Neural Information Processing Systems*. Curran Associates,
    Inc.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez,
    A., Kaiser, u., & Polosukhin, I. [Attention is All you Need.](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
    (2017), åœ¨ *Advances in Neural Information Processing Systems* ä¸­ã€‚Curran Associates,
    Inc.'
- en: '[4] Kralj Novak, P., SmailoviÄ‡, J., Sluban, B., & MozetiÄ, I. [Sentiment of
    Emojis.](https://doi.org/10.1371/journal.pone.0144296) (2015), *PLOS ONE*, *10*(12),
    e0144296.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Kralj Novak, P., SmailoviÄ‡, J., Sluban, B., & MozetiÄ, I. [Sentiment of
    Emojis.](https://doi.org/10.1371/journal.pone.0144296) (2015)ï¼Œ*PLOS ONE*ï¼Œ*10*(12)ï¼Œe0144296ã€‚'
