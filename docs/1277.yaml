- en: A Gentle Introduction to GPT Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/a-gentle-introduction-to-gpt-models-e02b093a495b?source=collection_archive---------1-----------------------#2023-04-12](https://towardsdatascience.com/a-gentle-introduction-to-gpt-models-e02b093a495b?source=collection_archive---------1-----------------------#2023-04-12)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Welcome to the new world of token generators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@bnjmn_marie?source=post_page-----e02b093a495b--------------------------------)[![Benjamin
    Marie](../Images/3ea1ad230cb1e67610418a8e36a5e5dd.png)](https://medium.com/@bnjmn_marie?source=post_page-----e02b093a495b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e02b093a495b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e02b093a495b--------------------------------)
    [Benjamin Marie](https://medium.com/@bnjmn_marie?source=post_page-----e02b093a495b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fad2a414578b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-gpt-models-e02b093a495b&user=Benjamin+Marie&userId=ad2a414578b3&source=post_page-ad2a414578b3----e02b093a495b---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e02b093a495b--------------------------------)
    ·9 min read·Apr 12, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe02b093a495b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-gpt-models-e02b093a495b&user=Benjamin+Marie&userId=ad2a414578b3&source=-----e02b093a495b---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe02b093a495b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-gpt-models-e02b093a495b&source=-----e02b093a495b---------------------bookmark_footer-----------)![](../Images/db0b10a3b127c9e3fba8e78be613555e.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image from [Pixabay](https://pixabay.com/illustrations/dinosaur-t-rex-animal-dino-5631999/)
    — Modified by author
  prefs: []
  type: TYPE_NORMAL
- en: With the recent releases of ChatGPT and GPT-4, GPT models have drawn a lot of
    interest from the scientific community. These new versions of OpenAI’s GPT models
    are so powerful and versatile that it may take a lot of time before we can exploit
    their full potential.
  prefs: []
  type: TYPE_NORMAL
- en: Even though they are impressive, what you may not know is that the main ideas
    and algorithms behind GPT models are far from new.
  prefs: []
  type: TYPE_NORMAL
- en: Whether you are a seasoned data scientist or just someone curious about GPT,
    knowing how GPT models evolved is particularly insightful on the impact of data
    and what to expect for the coming years.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I explain how GPT models became what they are today. I’ll mainly
    focus on how OpenAI scaled GPT models over the years. I’ll also give some pointers
    if you want to get started using GPT models.
  prefs: []
  type: TYPE_NORMAL
- en: Generative pre-trained language models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GPT models are language models.
  prefs: []
  type: TYPE_NORMAL
- en: Language models have existed for [more than 50 years](https://web.stanford.edu/~jurafsky/slp3/3.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: The first generation of language models was “*n*-gram based”. They modeled the
    probability of a word given some previous words.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, if you have the sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '*The cat sleeps in the kitchen.*'
  prefs: []
  type: TYPE_NORMAL
- en: With *n*=3, you can get from a 3-gram language model the probability of having
    “*in*” following “*cat sleeps*”.
  prefs: []
  type: TYPE_NORMAL
- en: '*n*-gram models remained useful in many natural language and speech processing
    tasks until the beginning of the 2010s.'
  prefs: []
  type: TYPE_NORMAL
- en: They suffer several limitations. The computational complexity dramatically increases
    with a higher *n*. So these models were often limited to *n*=5 or lower.
  prefs: []
  type: TYPE_NORMAL
- en: Then, thanks to neural networks and the use of more powerful machines, this
    main limitation was alleviated and it became possible to compute the probability
    for much longer n-grams, for instance for *n*=20 or higher.
  prefs: []
  type: TYPE_NORMAL
- en: Generating text with these models was also possible but their outputs were of
    a so poor quality that they were rarely used for this purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Then, in 2018, [OpenAI proposed the first GPT model](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: GPT stands for “generative pre-trained”. “Pre-trained” means that the model
    was simply trained on a large amount of text to model probabilities without any
    other purpose than language modeling. GPT models can then be fine-tuned, i.e.,
    further trained, to perform more specific tasks.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, you can use a small dataset of news summaries to obtain a GPT
    model very good at news summarization. Or fine-tune it on French-English translations
    to obtain a machine translation system capable of translating from French to English.
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: The term “pre-training” suggests that the models are not fully trained
    and that another step is needed. With recent models, the need for fine-tuning
    tends to disappear. The pre-trained models are now directly used in applications.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'GPT models are now very good in almost all natural language processing tasks.
    I particularly studied their ability to do machine translation, as you can read
    in the following article:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/translate-with-gpt-3-9903c4a6f385?source=post_page-----e02b093a495b--------------------------------)
    [## Translate with GPT-3'
  prefs: []
  type: TYPE_NORMAL
- en: Machine translation but without a machine translation system
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/translate-with-gpt-3-9903c4a6f385?source=post_page-----e02b093a495b--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: The scale of the training, and the Transformer neural network architecture that
    they exploit, are the main reasons why they can generate fluent text.
  prefs: []
  type: TYPE_NORMAL
- en: Since 2018 and the first GPT, several versions and subversions of GPT followed.
  prefs: []
  type: TYPE_NORMAL
- en: 4 versions and many more subversions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GPT and GPT-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[GPT-2 came out only a few months after the first GPT](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
    was announced. *Note: The term “GPT” was never mentioned in the scientific paper
    describing the first GPT. Arguably, we could say that “GPT-1” never existed. To
    the best of my knowledge, it was also never released.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*What is the difference between GPT and GPT-2?*'
  prefs: []
  type: TYPE_NORMAL
- en: The scale. GPT-2 is much larger than GPT.
  prefs: []
  type: TYPE_NORMAL
- en: GPT was trained on the BookCorpus which contains 7,000 books. The model has
    120 million parameters.
  prefs: []
  type: TYPE_NORMAL
- en: What’s a parameter?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A parameter is a variable learned during the model training. Typically, a model
    with more parameters is bigger and better.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 120 million was a huge number in 2018.
  prefs: []
  type: TYPE_NORMAL
- en: With GPT-2, OpenAI proposed an even bigger model containing 1.5 billion parameters.
  prefs: []
  type: TYPE_NORMAL
- en: It was trained on an undisclosed corpus called WebText. This corpus is 10 times
    larger than BookCorpus ([according to the paper describing GPT-2](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)).
  prefs: []
  type: TYPE_NORMAL
- en: 'OpenAI gradually released 4 versions of GPT-2:'
  prefs: []
  type: TYPE_NORMAL
- en: 'small: 124 million parameters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'medium: 355 million parameters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'large: 774 million parameters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'xl: 1.5 billion parameters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They are [all publicly available](https://openai.com/research/gpt-2-1-5b-release)
    and can be used in commercial products.
  prefs: []
  type: TYPE_NORMAL
- en: While GPT-2-XL excels at generating fluent text in the wild, i.e., without any
    particular instructions or fine-tuning, it remains far less powerful than more
    recent GPT models for specific tasks.
  prefs: []
  type: TYPE_NORMAL
- en: The release of GPT-2-XL was the last open release of a GPT model by OpenAI.
    GPT-3 and GPT-4 can only be used through OpenAI’s API.
  prefs: []
  type: TYPE_NORMAL
- en: GPT-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: GPT-3 was announced in 2020\. With its 175 billion parameters, it was an even
    bigger jump from GPT-2 than GPT-2 from the first GPT.
  prefs: []
  type: TYPE_NORMAL
- en: '[This is also from GPT-3 that OpenAI stopped to disclose precise training information
    about GPT models.](https://arxiv.org/pdf/2005.14165.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: Today, there are 7 GPT-3 models available through OpenAI’s API but we only know
    little about them.
  prefs: []
  type: TYPE_NORMAL
- en: With GPT-3, OpenAI demonstrated that GPT models can be extremely good for specific
    language generation tasks if the users provide a few examples of the task they
    want the model to achieve.
  prefs: []
  type: TYPE_NORMAL
- en: GPT-3.5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the GPT-3 models running in the API and attracting more and more users,
    OpenAI could collect a very large dataset of user inputs.
  prefs: []
  type: TYPE_NORMAL
- en: They exploited these inputs to further improve their models.
  prefs: []
  type: TYPE_NORMAL
- en: They used a technique called [reinforcement learning from human feedback (RLHF)](https://openai.com/blog/deep-reinforcement-learning-from-human-preferences/).
    I won’t explain the details here but you can find them in [a blog post](https://openai.com/research/instruction-following)
    published by OpenAI.
  prefs: []
  type: TYPE_NORMAL
- en: In a nutshell, thanks to RLHF, GPT-3.5 is much better at following user instructions
    than GPT-3\. OpenAI denotes this class of GPT models as “instructGPT”.
  prefs: []
  type: TYPE_NORMAL
- en: With GPT-3.5, you can “prompt” the model to perform a specific task without
    the need to give it examples of the task. You just have to write the “right” prompt
    to get the best result. This is where “prompt engineering” becomes important and
    why skilled [prompt engineers are receiving incredible job offers](https://www.businessinsider.com/ai-prompt-engineer-jobs-pay-salary-requirements-no-tech-background-2023-3).
  prefs: []
  type: TYPE_NORMAL
- en: GPT-3.5 is the current model used to power ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: GPT-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: GPT-4 has been released in March 2023.
  prefs: []
  type: TYPE_NORMAL
- en: We know almost nothing about its training.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main difference with GPT-3/GPT-3.5 is that GPT-4 is bimodal: It can take
    as input images and text.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It can generate text but won’t directly generate images. *Note: GPT-4 can generate
    the code that can generate an image, or retrieve one from the Web.*'
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing these lines, GPT-4 is still in a “limited beta”.
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ChatGPT is just a user interface with chat functionalities. When you write something
    with ChatGPT, it’s a GPT-3.5 model that generates the answer.
  prefs: []
  type: TYPE_NORMAL
- en: 'A particularity of ChatGPT is that it’s not just taking as input the current
    query of the user as an out-of-the-box GPT model would do. To properly work as
    a chat engine, ChatGPT must keep track of the conversation: What has been said,
    what is the user goal, etc.'
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI didn’t disclose how it does that. Given that GPT models can only accept
    a prompt of a limited length (I’ll explain this later), ChatGPT can’t just concatenate
    all the dialogue turns together to put them in the same prompt. This kind of prompt
    could be way too large to be handled by GPT-3.5.
  prefs: []
  type: TYPE_NORMAL
- en: How to use GPT models?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can easily get GPT-2 models online and use them on your computer. If you
    want to run large language models on your machine, you may be interested in reading
    my tutorial:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://pub.towardsai.net/run-very-large-language-models-on-your-computer-390dd33838bb?source=post_page-----e02b093a495b--------------------------------)
    [## Run Very Large Language Models on Your Computer'
  prefs: []
  type: TYPE_NORMAL
- en: With PyTorch and Hugging Face’s device_map
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: pub.towardsai.net](https://pub.towardsai.net/run-very-large-language-models-on-your-computer-390dd33838bb?source=post_page-----e02b093a495b--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: For GPT-3 and GPT-3.5, we have no other choice than to use OpenAI’s API. You
    will first need to create an OpenAI account on [their website](https://openai.com/).
  prefs: []
  type: TYPE_NORMAL
- en: Once you have an account, you can start playing with the models inside the “playground”
    which is a sandbox that OpenAI proposes to experiment with the models. You can
    access it only when you are logged in.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to directly use the models in your application, OpenAI and the open-source
    community offer libraries in many languages, such as [Python, Node.js, and PHP,](https://platform.openai.com/docs/libraries)
    to call the models using OpenAI API.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can create and get your OpenAI API key in your OpenAI account. *Note: Keep
    this key secret. Anyone who has it can consume your OpenAI credits.*'
  prefs: []
  type: TYPE_NORMAL
- en: Each model has different settings that you can adjust. Be aware that GPT models
    are *non-deterministic.* If you prompt a model twice with the same prompt there
    is a high chance that you will have two close but different answers.
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: If you want to reduce the variations between answers given the same
    prompt, you can set to 0 the “temperature” parameter of the model. As a side effect,
    it will also significantly decrease the diversity of the answers, in other words,
    the generated text may be more redundant.*'
  prefs: []
  type: TYPE_NORMAL
- en: You will also have to care about the “maximum content length”. This is the length
    of your prompt in addition to the length of the answer generated by GPT. For instance,
    GPT-3.5-turbo has a “maximum content length” of 4,096 *tokens*.
  prefs: []
  type: TYPE_NORMAL
- en: '**A token is not a word.**'
  prefs: []
  type: TYPE_NORMAL
- en: A token is the minimal unit of text used by the GPT models to generate text.
    Yes, GPT models are not exactly word generators but rather token generators. A
    token can be a character, a piece of word, a word, or even a sequence of words
    for some languages.
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI gives an example in the [API documentation](https://platform.openai.com/docs/guides/chat/introduction).
  prefs: []
  type: TYPE_NORMAL
- en: '`*"ChatGPT is great!"*` *is encoded into six tokens:* `*["Chat", "G", "PT",
    " is", " great", "!"]*`*.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As a rule of thumb, count that 750 English words yield 1,000 tokens.
  prefs: []
  type: TYPE_NORMAL
- en: In my opinion, managing the “maximum content length” is the most tedious part
    of working with the OpenAI API. First, there is no straightforward way to know
    how many tokens your prompt contains. Then, you can’t know in advance how many
    tokens will be in the answer of the model.
  prefs: []
  type: TYPE_NORMAL
- en: You have to guess. And you can only guess right if you have some experience
    with the models. I recommend experimenting a lot with them to better gauge how
    long can be the answers given your prompts.
  prefs: []
  type: TYPE_NORMAL
- en: If your prompt is too long, the answer will be cut-off.
  prefs: []
  type: TYPE_NORMAL
- en: I won’t give more details about the API here as it can become quite technical.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations of GPT models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GPT models are only token generators trained on the Web. They are biased by
    the content they were trained on and thus cannot be considered fully safe.
  prefs: []
  type: TYPE_NORMAL
- en: Since GPT-3.5, OpenAI has trained its model to avoid answering harmful content.
    To achieve this, they used machine learning techniques and consequently this “self-moderation”
    of the model can’t be 100% trusted.
  prefs: []
  type: TYPE_NORMAL
- en: This self-moderation may work for a given prompt, but may then completely fail
    after just changing one word in this prompt.
  prefs: []
  type: TYPE_NORMAL
- en: I also recommend reading the [Terms of Use](https://openai.com/policies/terms-of-use)
    of OpenAI products. In this document, the limitations of GPT models appear more
    clearly in my opinion.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you plan to build your application with the API, you should particularly
    pay attention to this point:'
  prefs: []
  type: TYPE_NORMAL
- en: You must be at least 13 years old to use the Services. If you are under 18 you
    must have your parent or legal guardian’s permission to use the Services. If you
    use the Services on behalf of another person or entity, you must have the authority
    to accept the Terms on their behalf. You must provide accurate and complete information
    to register for an account. You may not make your access credentials or account
    available to others outside your organization, and you are responsible for all
    activities that occur using your credentials.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Italy temporarily banned ChatGPT because it may generate inappropriate answers
    for people under 18, among other reasons.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/@bnjmn_marie/italy-bans-chatgpt-europe-may-follow-c7222112f97e?source=post_page-----e02b093a495b--------------------------------)
    [## Italy Bans ChatGPT, Europe May Follow'
  prefs: []
  type: TYPE_NORMAL
- en: Towards a boom of ChatGPT wrappers “Ready for Italy”
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@bnjmn_marie/italy-bans-chatgpt-europe-may-follow-c7222112f97e?source=post_page-----e02b093a495b--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: If you are a developer building an application on top of OpenAI API, you must
    check the age of your users.
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI also published a list of [usage policies pointing out all the prohibited
    usage of the models](https://openai.com/policies/usage-policies).
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GPT models are very simple models and their architecture didn’t evolve much
    since 2018\. But when you train a simple model at a large scale on the right data
    and with the right hyperparameters, you can get extremely powerful AI models such
    as GPT-3 and GPT-4.
  prefs: []
  type: TYPE_NORMAL
- en: They are so powerful that we have not nearly explored all their potential.
  prefs: []
  type: TYPE_NORMAL
- en: While recent GPT models are not open-source, they remain easy to use with OpenAI’s
    API. You can also play with them through [ChatGPT](https://chat.openai.com/chat).
  prefs: []
  type: TYPE_NORMAL
