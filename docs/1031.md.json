["```py\nimport os\nimport openai\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\nopenai.Edit.create(\n  model=\"text-davinci-edit-001\",\n  input=\"It was so great to meet you .... \",\n  instruction=\"Summarize the text below in the form of an email that is 5 sentences or less.\"\n)\n```", "```py\nfrom langchain.prompts.few_shot import FewShotPromptTemplate\n\nexamples = [\n  {\n    \"question\": \"Who lived longer, Muhammad Ali or Alan Turing?\",\n    \"answer\": \n\"\"\"\nAre follow up questions needed here: Yes.\nFollow up: How old was Muhammad Ali when he died?\nIntermediate answer: Muhammad Ali was 74 years old when he died.\nFollow up: How old was Alan Turing when he died?\nIntermediate answer: Alan Turing was 41 years old when he died.\nSo the final answer is: Muhammad Ali\n\"\"\"\n  },\n  {\n    \"question\": \"When was the founder of craigslist born?\",\n    \"answer\": \n\"\"\"\nAre follow up questions needed here: Yes.\nFollow up: Who was the founder of craigslist?\nIntermediate answer: Craigslist was founded by Craig Newmark.\nFollow up: When was Craig Newmark born?\nIntermediate answer: Craig Newmark was born on December 6, 1952.\nSo the final answer is: December 6, 1952\n\"\"\"\n...\n]\n\nexample_prompt = PromptTemplate(input_variables=[\"question\", \"answer\"], \n                                template=\"Question: {question}\\n{answer}\")\n\nprompt = FewShotPromptTemplate(\n    examples=examples, \n    example_prompt=example_prompt, \n    suffix=\"Question: {input}\", \n    input_variables=[\"input\"]\n)\n\nprint(prompt.format(input=\"Who was the father of Mary Ball Washington?\"))\n```", "```py\nfrom transformers import AutoTokenizer\n\nmodel_checkpoint = \"google/flan-t5-small\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n...\nexamples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\nexamples[\"context\"] = [c.lstrip() for c in examples[\"context\"]]\ntokenized_examples = tokenizer(\n        examples[\"question\"],\n        examples[\"context\"],\n        ...\n)\n...\n```", "```py\nfrom transformers import TFAutoModelForQuestionAnswering\nimport tensorflow as tf\nfrom tensorflow import keras\n\nmodel = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\noptimizer = keras.optimizers.Adam(learning_rate=5e-5)\nmodel.compile(optimizer=optimizer)\nmodel.fit(train_set, validation_data=validation_set, epochs=1)\n```", "```py\ninputs = tokenizer([context], [question], return_tensors=\"np\")\noutputs = model(inputs)\nstart_position = tf.argmax(outputs.start_logits, axis=1)\nend_position = tf.argmax(outputs.end_logits, axis=1)\n```"]