["```py\nimport time, os\nimport torch\nfrom torch.utils.data import Dataset\nfrom timm.models.vision_transformer import VisionTransformer\n\nuse_amp = True # toggle to enable/disable amp\nuse_compile = True # toggle to use eager/graph execution mode\n\n# use a fake dataset (random data)\nclass FakeDataset(Dataset):\n  def __len__(self):\n    return 1000000\n\n  def __getitem__(self, index):\n    rand_image = torch.randn([3, 224, 224], dtype=torch.float32)\n    label = torch.tensor(data=[index % 1000], dtype=torch.int64)\n    return rand_image, label\n\ndef train():\n  device = torch.cuda.current_device()\n  dataset = FakeDataset()\n  batch_size = 64\n\n  # define an image classification model with a ViT backbone\n  model = VisionTransformer()\n\n  if use_compile:\n    model = torch.compile(model)\n\n  model.to(device)\n\n  optimizer = torch.optim.Adam(model.parameters())\n  data_loader = torch.utils.data.DataLoader(dataset,\n                          batch_size=batch_size, num_workers=4)\n  loss_function = torch.nn.CrossEntropyLoss()\n\n  t0 = time.perf_counter()\n  summ = 0\n  count = 0\n\n  for idx, (inputs, target) in enumerate(data_loader, start=1):\n    inputs = inputs.to(device)\n    targets = torch.squeeze(target.to(device), -1)\n\n    optimizer.zero_grad()\n\n    with torch.cuda.amp.autocast(\n      enabled=use_amp,\n      dtype=torch.bfloat16\n    ):\n      outputs = model(inputs)\n      loss = loss_function(outputs, targets)\n\n    loss.backward()\n    optimizer.step()\n\n    batch_time = time.perf_counter() - t0\n\n    if idx > 10:  # skip first few steps\n      summ += batch_time\n      count += 1\n    t0 = time.perf_counter()\n    if idx > 500:\n      break\n\n  print(f'average step time: {summ/count}')\n\nif __name__ == '__main__':\n  train()\n```", "```py\ndef compile(model: Optional[Callable] = None, *,\n            fullgraph: builtins.bool = False,\n            dynamic: builtins.bool = False,\n            backend: Union[str, Callable] = \"inductor\",\n            mode: Union[str, None] = None,\n            options: Optional[Dict[str, Union[str, builtins.int, builtins.bool]]] = None,\n            disable: builtins.bool = False) -> Callable:\n    \"\"\"\n    Optimizes given model/function using TorchDynamo and specified backend.\n\n    Args:\n       model (Callable): Module/function to optimize\n       fullgraph (bool): Whether it is ok to break model into several subgraphs\n       dynamic (bool): Use dynamic shape tracing\n       backend (str or Callable): backend to be used\n       mode (str): Can be either \"default\", \"reduce-overhead\" or \"max-autotune\"\n       options (dict): A dictionary of options to pass to the backend.\n       disable (bool): Turn torch.compile() into a no-op for testing\n    \"\"\"\n```", "```py\nfrom torch import _dynamo\nprint(_dynamo.list_backends())\n```", "```py\n out_path = os.path.join(os.environ.get('SM_MODEL_DIR','/tmp'),'profile')\n  from torch.profiler import profile, ProfilerActivity\n  with profile(\n          activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n          schedule=torch.profiler.schedule(\n            wait=20,\n            warmup=5,\n            active=10,\n            repeat=1),\n          on_trace_ready=torch.profiler.tensorboard_trace_handler(\n                                                dir_name=out_path)\n\n  ) as p:\n    for idx, (inputs, target) in enumerate(data_loader, start=1):\n      inputs = inputs.to(device)\n      targets = torch.squeeze(target.to(device), -1)\n      optimizer.zero_grad()\n\n      with torch.cuda.amp.autocast(\n        enabled=use_amp,\n        dtype=torch.bfloat16\n      ):\n        outputs = model(inputs)\n        loss = loss_function(outputs, targets)\n      loss.backward()\n      optimizer.step()\n      p.step()\n```", "```py\nimport os, logging\nimport torch\nfrom torch import _dynamo\n\n# enable debug prints\ntorch._dynamo.config.log_level = logging.INFO\ntorch._dynamo.config.verbose=True\n\n# uncomment to run minifier\n# torch._dynamo.config.repro_after=\"aot\"\n\ndef build_model():\n  import torch.nn as nn\n  import torch.nn.functional as F\n\n  class DumbNet(nn.Module):\n    def __init__(self):\n      super().__init__()\n      self.conv1 = nn.Conv2d(3, 6, 5)\n      self.pool = nn.MaxPool2d(2, 2)\n      self.fc1 = nn.Linear(1176, 10)\n\n    def forward(self, x):\n      x = self.pool(F.relu(self.conv1(x)))\n      x = torch.flatten(x, 1)\n      x = self.fc1(x)\n      with torch.no_grad():\n        sum_vals = torch.sum(x,0)\n        # this is the problematic line of code\n        torch.distributed.all_reduce(sum_vals)\n      # add noise\n      x = x + 0.1*sum_vals\n      return x\n\n  net = DumbNet()\n  return net\n\ndef train():\n  os.environ['MASTER_ADDR'] = os.environ.get('MASTER_ADDR',\n                                             'localhost')\n  os.environ['MASTER_PORT'] = os.environ.get('MASTER_PORT',\n                                             str(2222))\n  torch.distributed.init_process_group('nccl', rank=0,\n                                         world_size=1)\n  torch.cuda.set_device(0)\n  device = torch.cuda.current_device()\n\n  model = build_model()\n\n  model = torch.compile(model)\n\n  # replace with this to verfiy that error is not in TorchDynamo\n  # model = torch.compile(model, 'eager')\n  # replace with this to verfiy that error is not in AOTAutograd\n  # model = torch.compile(model, 'aot_eager')\n\n  model.to(device)\n\n  rand_image = torch.randn([4, 3, 32, 32], dtype=torch.float32).to(device)\n\n  model(rand_image)\n\nif __name__ == '__main__':\n  train()\n```", "```py\nimport torch\nfrom torch import _dynamo\nimport numpy as np\n\ndef build_model():\n  import torch.nn as nn\n  import torch.nn.functional as F\n\n  class DumbNet(nn.Module):\n    def __init__(self):\n      super().__init__()\n      self.conv1 = nn.Conv2d(3, 6, 5)\n      self.pool = nn.MaxPool2d(2, 2)\n      self.fc1 = nn.Linear(1176, 10)\n      self.fc2 = nn.Linear(10, 10)\n      self.fc3 = nn.Linear(10, 10)\n      self.fc4 = nn.Linear(10, 10)\n      self.d = {}\n\n    def forward(self, x):\n      x = self.pool(F.relu(self.conv1(x)))\n      x = torch.flatten(x, 1)\n      assert torch.all(x >= 0) # graph break\n      x = self.fc1(x)\n      self.d['fc1-out'] = x.sum().item() # graph break\n      x = self.fc2(x)\n      for k in np.arange(1): # graph break\n        x = self.fc3(x)\n      print(x)  # graph break\n      x = self.fc4(x)\n      return x\n\n  net = DumbNet()\n  return net\n\ndef train():\n  model = build_model()\n  rand_image = torch.randn([4, 3, 32, 32], dtype=torch.float32)\n  explanation = torch._dynamo.explain(model, rand_image)\n  print(explanation)\n\nif __name__ == '__main__':\n  train()\n```", "```py\nimport torch\nfrom timm.models.vision_transformer import VisionTransformer\n\nclass ExpensiveLoss(torch.nn.Module):\n  def __init__(self):\n    super(ExpensiveLoss, self).__init__()\n    self.expert_model = VisionTransformer(depth=24)\n    if torch.cuda.is_available():\n      self.expert_model.to(torch.cuda.current_device())\n    self.mse_loss = torch.nn.MSELoss()\n\n  def forward(self, input, outputs):\n    expert_output = self.expert_model(input)\n    return self.mse_loss(outputs, expert_output)\n```", "```py\nloss_function = ExpensiveLoss()\ncompiled_loss = torch.compile(loss_function)\n```", "```py\nimport time, os\nimport torch\nfrom torch.utils.data import Dataset\nfrom torch import nn\nfrom timm.models.vision_transformer import VisionTransformer\n\n# use a fake dataset (random data)\nclass FakeDataset(Dataset):\n  def __len__(self):\n    return 1000000\n\n  def __getitem__(self, index):\n    rand_image = torch.randn([3, 224, 224], dtype=torch.float32)\n    label = torch.tensor(data=[index % 1000], dtype=torch.int64)\n    return rand_image, label\n\n# create a wrapper model for the ViT model and loss\nclass SuperModel(torch.nn.Module):\n  def __init__(self):\n    super(SuperModel, self).__init__()\n    self.model = VisionTransformer()\n    self.expert_model = VisionTransformer(depth=24 if torch.cuda.is_available() else 2)\n    self.mse_loss = torch.nn.MSELoss()\n\n  def forward(self, inputs):\n    outputs = self.model(inputs)\n    with torch.no_grad():\n      expert_output = self.expert_model(inputs)\n    return self.mse_loss(outputs, expert_output)\n\n# a loss that simply passes through the model output\nclass PassthroughLoss(nn.Module):\n  def __call__(self, model_output):\n    return model_output\n\ndef train():\n  device = torch.cuda.current_device()\n  dataset = FakeDataset()\n  batch_size = 64\n\n  # create and compile the model\n  model = SuperModel()\n  model = torch.compile(model)\n\n  model.to(device)\n\n  optimizer = torch.optim.Adam(model.parameters())\n  data_loader = torch.utils.data.DataLoader(dataset,\n                          batch_size=batch_size, num_workers=4)\n\n  loss_function = PassthroughLoss()\n\n  t0 = time.perf_counter()\n  summ = 0\n  count = 0\n\n  for idx, (inputs, target) in enumerate(data_loader, start=1):\n    inputs = inputs.to(device)\n    targets = torch.squeeze(target.to(device), -1)\n\n    optimizer.zero_grad()\n\n    with torch.cuda.amp.autocast(\n      enabled=True,\n      dtype=torch.bfloat16\n    ):\n      outputs = model(inputs)\n      loss = loss_function(outputs)\n\n    loss.backward()\n    optimizer.step()\n\n    batch_time = time.perf_counter() - t0\n\n    if idx > 10:  # skip first few steps\n      summ += batch_time\n      count += 1\n    t0 = time.perf_counter()\n    if idx > 500:\n      break\n\n  print(f'average step time: {summ/count}')\n\nif __name__ == '__main__':\n  train()\n```"]