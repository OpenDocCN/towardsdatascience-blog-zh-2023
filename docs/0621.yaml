- en: Semantic Textual Similarity with BERT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/semantic-textual-similarity-with-bert-fc800656e7a3?source=collection_archive---------1-----------------------#2023-02-15](https://towardsdatascience.com/semantic-textual-similarity-with-bert-fc800656e7a3?source=collection_archive---------1-----------------------#2023-02-15)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How to use BERT to calculate the semantic similarity between two texts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@marcellusruben?source=post_page-----fc800656e7a3--------------------------------)[![Ruben
    Winastwan](../Images/15ad0dd03bf5892510abdf166a1e91e1.png)](https://medium.com/@marcellusruben?source=post_page-----fc800656e7a3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fc800656e7a3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fc800656e7a3--------------------------------)
    [Ruben Winastwan](https://medium.com/@marcellusruben?source=post_page-----fc800656e7a3--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5dae9da73c9b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-textual-similarity-with-bert-fc800656e7a3&user=Ruben+Winastwan&userId=5dae9da73c9b&source=post_page-5dae9da73c9b----fc800656e7a3---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fc800656e7a3--------------------------------)
    ·11 min read·Feb 15, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffc800656e7a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-textual-similarity-with-bert-fc800656e7a3&user=Ruben+Winastwan&userId=5dae9da73c9b&source=-----fc800656e7a3---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc800656e7a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-textual-similarity-with-bert-fc800656e7a3&source=-----fc800656e7a3---------------------bookmark_footer-----------)![](../Images/618fe6986fde72b9eaae6d126ce78716.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Photo by Leeloo Thefirst: [https://www.pexels.com/photo/brown-wooden-ruler-and-colored-pencils-on-papers-8970296/](https://www.pexels.com/photo/brown-wooden-ruler-and-colored-pencils-on-papers-8970296/)'
  prefs: []
  type: TYPE_NORMAL
- en: Ever since its inception in 2017 by Google Brain team, Transformers have rapidly
    become the state-of-the-art model for various use cases within the fields of Computer
    Vision and NLP. Its superior performance led to the development of several state-of-the-art
    models such as BERT and its variants like distilBERT and RoBERTa.
  prefs: []
  type: TYPE_NORMAL
- en: BERT outperformed old recurrent models in various NLP tasks such as text classification,
    Named Entity Recognition (NER), question answering, and even the task that we’re
    going to focus on in this article, which is semantic textual similarity (STS).
  prefs: []
  type: TYPE_NORMAL
- en: Thus, in this article, we’re going to see how we can train a BERT model for
    STS task with the help of Sentence Transformers library. Next, we’re going to
    use the trained model to predict unknown data. But as a starter, we need to know
    first what STS task actually is and the dataset that we will use for this task.
  prefs: []
  type: TYPE_NORMAL
- en: Semantic Textual Similarity and the Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Semantic textual similarity (STS) refers to a task in which we compare the similarity
    between one text to another.
  prefs: []
  type: TYPE_NORMAL
