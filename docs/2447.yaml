- en: The Necessity of a Gradient of Explainability in AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI 解释性梯度的必要性
- en: 原文：[https://towardsdatascience.com/the-necessity-of-a-gradient-of-explainability-in-ai-743ee0bcb848?source=collection_archive---------3-----------------------#2023-07-29](https://towardsdatascience.com/the-necessity-of-a-gradient-of-explainability-in-ai-743ee0bcb848?source=collection_archive---------3-----------------------#2023-07-29)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-necessity-of-a-gradient-of-explainability-in-ai-743ee0bcb848?source=collection_archive---------3-----------------------#2023-07-29](https://towardsdatascience.com/the-necessity-of-a-gradient-of-explainability-in-ai-743ee0bcb848?source=collection_archive---------3-----------------------#2023-07-29)
- en: Too much detail can be overwhelming, yet insufficient detail can be misleading.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 细节过多可能会令人不知所措，而细节不足则可能会引导误解。
- en: '[](https://medium.com/@kevin.berlemont?source=post_page-----743ee0bcb848--------------------------------)[![Kevin
    Berlemont, PhD](../Images/18697f38b76f1fb04870f565cfb04b4c.png)](https://medium.com/@kevin.berlemont?source=post_page-----743ee0bcb848--------------------------------)[](https://towardsdatascience.com/?source=post_page-----743ee0bcb848--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----743ee0bcb848--------------------------------)
    [Kevin Berlemont, PhD](https://medium.com/@kevin.berlemont?source=post_page-----743ee0bcb848--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@kevin.berlemont?source=post_page-----743ee0bcb848--------------------------------)[![Kevin
    Berlemont, PhD](../Images/18697f38b76f1fb04870f565cfb04b4c.png)](https://medium.com/@kevin.berlemont?source=post_page-----743ee0bcb848--------------------------------)[](https://towardsdatascience.com/?source=post_page-----743ee0bcb848--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----743ee0bcb848--------------------------------)
    [Kevin Berlemont, PhD](https://medium.com/@kevin.berlemont?source=post_page-----743ee0bcb848--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3dea771eb493&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-necessity-of-a-gradient-of-explainability-in-ai-743ee0bcb848&user=Kevin+Berlemont%2C+PhD&userId=3dea771eb493&source=post_page-3dea771eb493----743ee0bcb848---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----743ee0bcb848--------------------------------)
    ·4 min read·Jul 29, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F743ee0bcb848&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-necessity-of-a-gradient-of-explainability-in-ai-743ee0bcb848&user=Kevin+Berlemont%2C+PhD&userId=3dea771eb493&source=-----743ee0bcb848---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3dea771eb493&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-necessity-of-a-gradient-of-explainability-in-ai-743ee0bcb848&user=Kevin+Berlemont%2C+PhD&userId=3dea771eb493&source=post_page-3dea771eb493----743ee0bcb848---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----743ee0bcb848--------------------------------)
    ·4 分钟阅读·2023年7月29日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F743ee0bcb848&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-necessity-of-a-gradient-of-explainability-in-ai-743ee0bcb848&user=Kevin+Berlemont%2C+PhD&userId=3dea771eb493&source=-----743ee0bcb848---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F743ee0bcb848&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-necessity-of-a-gradient-of-explainability-in-ai-743ee0bcb848&source=-----743ee0bcb848---------------------bookmark_footer-----------)![](../Images/053eb6288d97c8586d780c90ace9e905.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F743ee0bcb848&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-necessity-of-a-gradient-of-explainability-in-ai-743ee0bcb848&source=-----743ee0bcb848---------------------bookmark_footer-----------)![](../Images/053eb6288d97c8586d780c90ace9e905.png)'
- en: Photo by [No Revisions](https://unsplash.com/@norevisions?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [No Revisions](https://unsplash.com/@norevisions?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: “*Any sufficiently advanced technology is indistinguishable from magic*” — **Arthur
    C. Clarke**
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: “*任何足够先进的技术都与魔法无异*” — **阿瑟·克拉克**
- en: With the advances in self-driving cars, computer vision, and more recently,
    large language models, science can sometimes feel like magic! Models are becoming
    more and more complex every day, and it can be tempting to wave your hands in
    the air and mumble something about backpropagation and neural networks when trying
    to explain complex models to a new audience. However, it is necessary to describe
    an AI model, its expected impact, and potential biases, and that’s where Explainable
    AI comes in.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 随着自动驾驶汽车、计算机视觉的进步，以及最近的大型语言模型，科学有时会让人感觉像魔法一样！模型变得越来越复杂，每天都在进步，当尝试向新受众解释复杂模型时，可能会不自觉地挥手并喃喃自语一些关于反向传播和神经网络的术语。然而，有必要描述AI模型、其预期影响和潜在偏见，这就是**可解释AI**发挥作用的地方。
- en: With the explosion of AI methods over the past decade, users have come to accept
    the answers they are given without question. The whole algorithm process is often
    described as a black box, and it is not always straightforward or even possible
    to understand how the model arrived at a specific result, even for the researchers
    who developed it. To build trust and confidence in its users, companies must characterize
    the fairness, transparency, and underlying decision-making processes of the different
    systems they employ. This approach not only leads to a responsible approach towards
    AI systems, but…
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去十年中，随着AI方法的爆炸性发展，用户已经开始接受他们所得到的答案而不加质疑。整个算法过程通常被描述为一个黑匣子，即使是开发该模型的研究人员，也不总是能够直接或完全理解模型是如何得出具体结果的。为了建立用户的信任和信心，公司必须描述他们所使用的不同系统的公平性、透明度和基本决策过程。这种方法不仅导致对AI系统的负责任态度，而且…
