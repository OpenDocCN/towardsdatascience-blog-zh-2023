- en: The Necessity of a Gradient of Explainability in AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-necessity-of-a-gradient-of-explainability-in-ai-743ee0bcb848?source=collection_archive---------3-----------------------#2023-07-29](https://towardsdatascience.com/the-necessity-of-a-gradient-of-explainability-in-ai-743ee0bcb848?source=collection_archive---------3-----------------------#2023-07-29)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Too much detail can be overwhelming, yet insufficient detail can be misleading.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@kevin.berlemont?source=post_page-----743ee0bcb848--------------------------------)[![Kevin
    Berlemont, PhD](../Images/18697f38b76f1fb04870f565cfb04b4c.png)](https://medium.com/@kevin.berlemont?source=post_page-----743ee0bcb848--------------------------------)[](https://towardsdatascience.com/?source=post_page-----743ee0bcb848--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----743ee0bcb848--------------------------------)
    [Kevin Berlemont, PhD](https://medium.com/@kevin.berlemont?source=post_page-----743ee0bcb848--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3dea771eb493&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-necessity-of-a-gradient-of-explainability-in-ai-743ee0bcb848&user=Kevin+Berlemont%2C+PhD&userId=3dea771eb493&source=post_page-3dea771eb493----743ee0bcb848---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----743ee0bcb848--------------------------------)
    ·4 min read·Jul 29, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F743ee0bcb848&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-necessity-of-a-gradient-of-explainability-in-ai-743ee0bcb848&user=Kevin+Berlemont%2C+PhD&userId=3dea771eb493&source=-----743ee0bcb848---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F743ee0bcb848&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-necessity-of-a-gradient-of-explainability-in-ai-743ee0bcb848&source=-----743ee0bcb848---------------------bookmark_footer-----------)![](../Images/053eb6288d97c8586d780c90ace9e905.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [No Revisions](https://unsplash.com/@norevisions?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: “*Any sufficiently advanced technology is indistinguishable from magic*” — **Arthur
    C. Clarke**
  prefs: []
  type: TYPE_NORMAL
- en: With the advances in self-driving cars, computer vision, and more recently,
    large language models, science can sometimes feel like magic! Models are becoming
    more and more complex every day, and it can be tempting to wave your hands in
    the air and mumble something about backpropagation and neural networks when trying
    to explain complex models to a new audience. However, it is necessary to describe
    an AI model, its expected impact, and potential biases, and that’s where Explainable
    AI comes in.
  prefs: []
  type: TYPE_NORMAL
- en: With the explosion of AI methods over the past decade, users have come to accept
    the answers they are given without question. The whole algorithm process is often
    described as a black box, and it is not always straightforward or even possible
    to understand how the model arrived at a specific result, even for the researchers
    who developed it. To build trust and confidence in its users, companies must characterize
    the fairness, transparency, and underlying decision-making processes of the different
    systems they employ. This approach not only leads to a responsible approach towards
    AI systems, but…
  prefs: []
  type: TYPE_NORMAL
