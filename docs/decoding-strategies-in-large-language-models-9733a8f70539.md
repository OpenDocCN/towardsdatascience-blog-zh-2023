# å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§£ç ç­–ç•¥

> åŸæ–‡ï¼š[https://towardsdatascience.com/decoding-strategies-in-large-language-models-9733a8f70539?source=collection_archive---------0-----------------------#2023-06-04](https://towardsdatascience.com/decoding-strategies-in-large-language-models-9733a8f70539?source=collection_archive---------0-----------------------#2023-06-04)

## ä»æŸæœç´¢åˆ°æ ¸é‡‡æ ·çš„æ–‡æœ¬ç”ŸæˆæŒ‡å—

[](https://medium.com/@mlabonne?source=post_page-----9733a8f70539--------------------------------)[![Maxime Labonne](../Images/a7efdd305e3cc77d5509bbb1076d57d8.png)](https://medium.com/@mlabonne?source=post_page-----9733a8f70539--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9733a8f70539--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9733a8f70539--------------------------------) [Maxime Labonne](https://medium.com/@mlabonne?source=post_page-----9733a8f70539--------------------------------)

Â·

[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdc89da634938&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecoding-strategies-in-large-language-models-9733a8f70539&user=Maxime+Labonne&userId=dc89da634938&source=post_page-dc89da634938----9733a8f70539---------------------post_header-----------) å‘å¸ƒåœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9733a8f70539--------------------------------) Â·15åˆ†é’Ÿé˜…è¯»Â·2023å¹´6æœˆ4æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9733a8f70539&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecoding-strategies-in-large-language-models-9733a8f70539&user=Maxime+Labonne&userId=dc89da634938&source=-----9733a8f70539---------------------clap_footer-----------)

--

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9733a8f70539&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecoding-strategies-in-large-language-models-9733a8f70539&source=-----9733a8f70539---------------------bookmark_footer-----------)![](../Images/8e3084bd4e009d7fb0c6ec5d7aef4aa6.png)

å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚

åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿·äººçš„ä¸–ç•Œä¸­ï¼Œæ¨¡å‹æ¶æ„ã€æ•°æ®å¤„ç†å’Œä¼˜åŒ–å—åˆ°å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼ŒåƒæŸæœç´¢è¿™æ ·çš„è§£ç ç­–ç•¥åœ¨æ–‡æœ¬ç”Ÿæˆä¸­æ‰®æ¼”ç€å…³é”®è§’è‰²ï¼Œä½†å¸¸è¢«å¿½è§†ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨LLMså¦‚ä½•ç”Ÿæˆæ–‡æœ¬ï¼Œé€šè¿‡å‰–æè´ªå©ªæœç´¢å’ŒæŸæœç´¢çš„æœºåˆ¶ï¼Œä»¥åŠä½¿ç”¨top-kå’Œæ ¸é‡‡æ ·çš„é‡‡æ ·æŠ€æœ¯ã€‚

åˆ°æœ¬æ–‡ç»“æŸæ—¶ï¼Œä½ å°†ä¸ä»…å½»åº•ç†è§£è¿™äº›è§£ç ç­–ç•¥ï¼Œè¿˜ä¼šç†Ÿæ‚‰å¦‚ä½•å¤„ç†æ¸©åº¦ã€num_beamsã€top_kå’Œtop_pç­‰é‡è¦è¶…å‚æ•°ã€‚

æœ¬æ–‡çš„ä»£ç å¯ä»¥åœ¨[GitHub](https://github.com/mlabonne/llm-course/blob/main/Decoding_Strategies_in_Large_Language%C2%A0Models.ipynb)å’Œ[Google Colab](https://colab.research.google.com/drive/19CJlOS5lI29g-B3dziNn93Enez1yiHk2?usp=sharing)ä¸­æ‰¾åˆ°ï¼Œä¾›å‚è€ƒå’Œè¿›ä¸€æ­¥æ¢ç´¢ã€‚

# ğŸ“š èƒŒæ™¯

ä¸ºäº†å¼€å§‹ï¼Œè®©æˆ‘ä»¬ç”¨ä¸€ä¸ªä¾‹å­æ¥è®²è§£ã€‚æˆ‘ä»¬å°†æŠŠæ–‡æœ¬â€œI have a dreamâ€è¾“å…¥åˆ°GPT-2æ¨¡å‹ä¸­ï¼Œå¹¶è¦æ±‚å®ƒç”Ÿæˆæ¥ä¸‹æ¥çš„äº”ä¸ªæ ‡è®°ï¼ˆè¯æˆ–å­è¯ï¼‰ã€‚

```py
from transformers import GPT2LMHeadModel, GPT2Tokenizer
import torch

device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = GPT2LMHeadModel.from_pretrained('gpt2').to(device)
tokenizer =â€¦
```
