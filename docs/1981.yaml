- en: Debugging SageMaker Endpoints With Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/debugging-sagemaker-endpoints-with-docker-7a703fae3a26?source=collection_archive---------11-----------------------#2023-06-16](https://towardsdatascience.com/debugging-sagemaker-endpoints-with-docker-7a703fae3a26?source=collection_archive---------11-----------------------#2023-06-16)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An Alternative To SageMaker Local Mode
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://ram-vegiraju.medium.com/?source=post_page-----7a703fae3a26--------------------------------)[![Ram
    Vegiraju](../Images/07d9334e905f710d9f3c6187cf69a1a5.png)](https://ram-vegiraju.medium.com/?source=post_page-----7a703fae3a26--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7a703fae3a26--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7a703fae3a26--------------------------------)
    [Ram Vegiraju](https://ram-vegiraju.medium.com/?source=post_page-----7a703fae3a26--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6e49569edd2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdebugging-sagemaker-endpoints-with-docker-7a703fae3a26&user=Ram+Vegiraju&userId=6e49569edd2b&source=post_page-6e49569edd2b----7a703fae3a26---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7a703fae3a26--------------------------------)
    ·6 min read·Jun 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7a703fae3a26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdebugging-sagemaker-endpoints-with-docker-7a703fae3a26&user=Ram+Vegiraju&userId=6e49569edd2b&source=-----7a703fae3a26---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7a703fae3a26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdebugging-sagemaker-endpoints-with-docker-7a703fae3a26&source=-----7a703fae3a26---------------------bookmark_footer-----------)![](../Images/0b957e3ecdec75d862d1a637b72d9fe3.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image from [Unsplash](https://unsplash.com/photos/1VW6HLOQE5A) by [**Mohammad
    Rahmani**](https://unsplash.com/@afgprogrammer)
  prefs: []
  type: TYPE_NORMAL
- en: A pain point with getting started with [SageMaker Real-Time Inference](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html)
    is that it is hard to debug at times. When creating an endpoint there are a number
    of ingredients you need to make sure are baked properly for successful deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Proper file structuring of model artifacts depending on the Model Server and
    Container that you are utilizing. Essentially the model.tar.gz you provide must
    be in a format that is compliant with the Model Server.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you have a custom inference script that implements pre and post processing
    for your model, you need to ensure that the handlers implemented are compliant
    with your model server and that there are no scripting errors at the code level
    either.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Previously we have discussed [SageMaker Local Mode](/debugging-sagemaker-endpoints-quickly-with-local-mode-2975bd55f6f7),
    but at the time of this article Local Mode does not support all hosting options
    and model servers that are available for SageMaker Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: To overcome this limitation we take a look at using [Docker](https://www.docker.com/)
    with a sample model and how we can test/debug our model artifacts and inference
    script prior to SageMaker Deployment. In this specific example we will utilize
    the [BART Model](https://huggingface.co/facebook/bart-large) that I have covered
    in my [last article](/deploying-llms-on-amazon-sagemaker-with-djl-serving-8220e3cfad0c)
    and see how we can host it with Docker.
  prefs: []
  type: TYPE_NORMAL
