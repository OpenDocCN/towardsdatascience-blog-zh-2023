- en: My (Very) Personal Data Warehouse
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æˆ‘çš„ï¼ˆéå¸¸ï¼‰ä¸ªäººæ•°æ®ä»“åº“
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/my-very-personal-data-warehouse-fitbit-activity-analysis-with-duckdb-8d1193046133?source=collection_archive---------3-----------------------#2023-05-31](https://towardsdatascience.com/my-very-personal-data-warehouse-fitbit-activity-analysis-with-duckdb-8d1193046133?source=collection_archive---------3-----------------------#2023-05-31)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/my-very-personal-data-warehouse-fitbit-activity-analysis-with-duckdb-8d1193046133?source=collection_archive---------3-----------------------#2023-05-31](https://towardsdatascience.com/my-very-personal-data-warehouse-fitbit-activity-analysis-with-duckdb-8d1193046133?source=collection_archive---------3-----------------------#2023-05-31)
- en: Fitbit activity analysis with DuckDB
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨DuckDBåˆ†æFitbitæ´»åŠ¨æ•°æ®
- en: '[](https://simon-aubury.medium.com/?source=post_page-----8d1193046133--------------------------------)[![Simon
    Aubury](../Images/fb757b7175c211450dcfa7249549c31e.png)](https://simon-aubury.medium.com/?source=post_page-----8d1193046133--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8d1193046133--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8d1193046133--------------------------------)
    [Simon Aubury](https://simon-aubury.medium.com/?source=post_page-----8d1193046133--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://simon-aubury.medium.com/?source=post_page-----8d1193046133--------------------------------)[![Simon
    Aubury](../Images/fb757b7175c211450dcfa7249549c31e.png)](https://simon-aubury.medium.com/?source=post_page-----8d1193046133--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8d1193046133--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8d1193046133--------------------------------)
    [Simon Aubury](https://simon-aubury.medium.com/?source=post_page-----8d1193046133--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb7b3bb643843&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-very-personal-data-warehouse-fitbit-activity-analysis-with-duckdb-8d1193046133&user=Simon+Aubury&userId=b7b3bb643843&source=post_page-b7b3bb643843----8d1193046133---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8d1193046133--------------------------------)
    Â·13 min readÂ·May 31, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8d1193046133&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-very-personal-data-warehouse-fitbit-activity-analysis-with-duckdb-8d1193046133&user=Simon+Aubury&userId=b7b3bb643843&source=-----8d1193046133---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb7b3bb643843&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-very-personal-data-warehouse-fitbit-activity-analysis-with-duckdb-8d1193046133&user=Simon+Aubury&userId=b7b3bb643843&source=post_page-b7b3bb643843----8d1193046133---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8d1193046133--------------------------------)
    Â· 13åˆ†é’Ÿé˜…è¯» Â· 2023å¹´5æœˆ31æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8d1193046133&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-very-personal-data-warehouse-fitbit-activity-analysis-with-duckdb-8d1193046133&user=Simon+Aubury&userId=b7b3bb643843&source=-----8d1193046133---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8d1193046133&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-very-personal-data-warehouse-fitbit-activity-analysis-with-duckdb-8d1193046133&source=-----8d1193046133---------------------bookmark_footer-----------)![](../Images/d002b45123ebfc0803be779dbe0d1fe1.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8d1193046133&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-very-personal-data-warehouse-fitbit-activity-analysis-with-duckdb-8d1193046133&source=-----8d1193046133---------------------bookmark_footer-----------)![](../Images/d002b45123ebfc0803be779dbe0d1fe1.png)'
- en: Photo by [Jake Hills](https://unsplash.com/es/@jakehills?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±[Jake Hills](https://unsplash.com/es/@jakehills?utm_source=medium&utm_medium=referral)æä¾›ï¼Œå‘å¸ƒåœ¨[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Wearable fitness trackers have become an integral part of our lives, collecting
    and tracking data about our daily activities, sleep patterns, location, heart
    rate, and much more. Iâ€™ve been using a Fitbit device for 6 years to monitor my
    health. However, I have always found the data analysis capabilities lacking â€”
    especially when I wanted to track my progress against long term fitness goals.
    What insights are buried within my archive of personal fitness activity data?
    To start exploring I needed a good approach for performing data analysis over
    thousands of poorly documented JSON and CSV files â€¦ extra points for analysis
    that doesnâ€™t require my data to leave my laptop.
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å¯ç©¿æˆ´å¥èº«è¿½è¸ªå™¨å·²æˆä¸ºæˆ‘ä»¬ç”Ÿæ´»ä¸­ä¸å¯æˆ–ç¼ºçš„ä¸€éƒ¨åˆ†ï¼Œæ”¶é›†å¹¶è·Ÿè¸ªæˆ‘ä»¬æ—¥å¸¸æ´»åŠ¨ã€ç¡çœ æ¨¡å¼ã€ä½ç½®ã€å¿ƒç‡ç­‰æ•°æ®ã€‚æˆ‘å·²ç»ä½¿ç”¨ Fitbit è®¾å¤‡ 6 å¹´æ¥ç›‘æµ‹æˆ‘çš„å¥åº·ã€‚ç„¶è€Œï¼Œæˆ‘ä¸€ç›´è§‰å¾—æ•°æ®åˆ†æåŠŸèƒ½ä¸è¶³
    â€” å°¤å…¶æ˜¯åœ¨æˆ‘æƒ³è·Ÿè¸ªé•¿æœŸå¥èº«ç›®æ ‡çš„è¿›å±•æ—¶ã€‚æˆ‘çš„ä¸ªäººå¥èº«æ´»åŠ¨æ•°æ®å­˜æ¡£ä¸­åŸ‹è—äº†å“ªäº›è§è§£ï¼Ÿè¦å¼€å§‹æ¢ç´¢ï¼Œæˆ‘éœ€è¦ä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•æ¥å¯¹æˆåƒä¸Šä¸‡çš„è®°å½•ä¸å®Œå–„çš„ JSON å’Œ
    CSV æ–‡ä»¶è¿›è¡Œæ•°æ®åˆ†æâ€¦â€¦é¢å¤–åŠ åˆ†çš„æ˜¯åˆ†æè¿‡ç¨‹ä¸­ä¸éœ€è¦å°†æˆ‘çš„æ•°æ®ä»ç¬”è®°æœ¬ç”µè„‘ä¸Šç§»èµ°ã€‚
- en: Enter [DuckDB](https://duckdb.org/why_duckdb) â€” a lightweight, free yet powerful
    analytical database designed to streamline data analysis workflows â€” that runs
    locally. In this blog post, I want to use DuckDB to explore my Fitbit data achieve
    and share the approach for analysing a variety of data formats and charting my
    health and fitness goals with the help of [Seaborn](https://seaborn.pydata.org/)
    data visualisations.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è¿›å…¥ [DuckDB](https://duckdb.org/why_duckdb) â€” ä¸€ä¸ªè½»é‡çº§ã€å…è´¹ä½†å¼ºå¤§çš„åˆ†ææ•°æ®åº“ï¼Œæ—¨åœ¨ç®€åŒ–æ•°æ®åˆ†æå·¥ä½œæµ â€”
    å®ƒåœ¨æœ¬åœ°è¿è¡Œã€‚åœ¨è¿™ç¯‡åšå®¢ä¸­ï¼Œæˆ‘æƒ³ä½¿ç”¨ DuckDB æ¥æ¢ç´¢æˆ‘çš„ Fitbit æ•°æ®ï¼Œå¹¶åˆ†äº«ä½¿ç”¨ [Seaborn](https://seaborn.pydata.org/)
    æ•°æ®å¯è§†åŒ–çš„å„ç§æ•°æ®æ ¼å¼åˆ†ææ–¹æ³•ä»¥åŠç»˜åˆ¶æˆ‘çš„å¥åº·å’Œå¥èº«ç›®æ ‡çš„é€”å¾„ã€‚
- en: Export Fitbit data archive
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¯¼å‡º Fitbit æ•°æ®å­˜æ¡£
- en: Firstly, I needed to get hold of all of my historic fitness data. Fitbit make
    it fairly easy to export your Fitbit data for the lifetime of your account by
    following the instructions at [export your account archive](https://www.fitbit.com/settings/data/export).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘éœ€è¦è·å–æˆ‘æ‰€æœ‰çš„å†å²å¥èº«æ•°æ®ã€‚é€šè¿‡éµå¾ª [å¯¼å‡ºæ‚¨çš„è´¦æˆ·å­˜æ¡£](https://www.fitbit.com/settings/data/export)
    çš„è¯´æ˜ï¼ŒFitbit ä½¿å¾—å¯¼å‡ºæ‚¨è´¦æˆ·ç”Ÿå‘½å‘¨æœŸä¸­çš„ Fitbit æ•°æ®å˜å¾—ç›¸å½“ç®€å•ã€‚
- en: '![](../Images/aa73415b842cc76279e913c0efaac903.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aa73415b842cc76279e913c0efaac903.png)'
- en: Instructions for using the export Fitbit data archive â€” Screenshot by the author.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å¯¼å‡º Fitbit æ•°æ®å­˜æ¡£çš„è¯´æ˜ â€” ä½œè€…æˆªå›¾ã€‚
- en: Youâ€™ll need to confirm your request â€¦ and be patient. My archive took over three
    days to create â€” but I finally received an email with instructions to download
    a ZIP file containing my Fitbit data. This file should contain all my personal
    fitness activity recorded by my Fitbit or associated service. Unzipping the archive
    reveals a huge collection of files â€” mine for example had 7,921 files once I unzipped
    the 79MB file.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨éœ€è¦ç¡®è®¤æ‚¨çš„è¯·æ±‚â€¦â€¦å¹¶ä¿æŒè€å¿ƒã€‚æˆ‘çš„å­˜æ¡£åˆ›å»ºäº†è¶…è¿‡ä¸‰å¤© â€” ä½†æˆ‘æœ€ç»ˆæ”¶åˆ°äº†å«æœ‰ä¸‹è½½ ZIP æ–‡ä»¶è¯´æ˜çš„ç”µå­é‚®ä»¶ã€‚è¯¥æ–‡ä»¶åº”åŒ…å«ç”±æˆ‘çš„ Fitbit æˆ–ç›¸å…³æœåŠ¡è®°å½•çš„æ‰€æœ‰ä¸ªäººå¥èº«æ´»åŠ¨ã€‚è§£å‹å­˜æ¡£åä¼šæ˜¾ç¤ºå‡ºå¤§é‡çš„æ–‡ä»¶
    â€” ä¾‹å¦‚ï¼Œæˆ‘åœ¨è§£å‹ 79MB æ–‡ä»¶åæ€»å…±æœ‰ 7,921 ä¸ªæ–‡ä»¶ã€‚
- en: '![](../Images/ce1b07a83af019cead0416c777cb7f8f.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ce1b07a83af019cead0416c777cb7f8f.png)'
- en: A small sample of the thousands of nested files â€” Screenshot by the author.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°ä»¥åƒè®¡çš„åµŒå¥—æ–‡ä»¶ä¸­çš„ä¸€å°éƒ¨åˆ† â€” ä½œè€…æˆªå›¾ã€‚
- en: Letâ€™s start looking at the variety of data available in the archive.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¼€å§‹æŸ¥çœ‹å­˜æ¡£ä¸­å¯ç”¨çš„æ•°æ®ç§ç±»ã€‚
- en: Why DuckDB?
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆé€‰æ‹© DuckDBï¼Ÿ
- en: There are many great blogs ([1](https://betterprogramming.pub/duckdb-whats-the-hype-about-5d46aaa73196),[2](https://mattpalmer.io/posts/whats-the-hype-duckdb/),[3](/a-serverless-query-engine-from-spare-parts-bd6320f10353))
    describing DuckDB â€” the [TL;DR](https://www.dictionary.com/browse/tl-dr) summary
    is DuckDB is an open-source in-process OLAP database built specifically for analytical
    queries. It runs locally, has extensive SQL support and can run queries directly
    on Pandas data, Parquet, JSON data. Extra points for its seamless integration
    with Python and R. The fact itâ€™s insanely fast and does (mostly) all processing
    in memory make it a good choice for building my personal data warehouse.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰è®¸å¤šä¼˜ç§€çš„åšå®¢ ([1](https://betterprogramming.pub/duckdb-whats-the-hype-about-5d46aaa73196),[2](https://mattpalmer.io/posts/whats-the-hype-duckdb/),[3](/a-serverless-query-engine-from-spare-parts-bd6320f10353))
    æè¿°äº† DuckDB â€” [TL;DR](https://www.dictionary.com/browse/tl-dr) æ‘˜è¦æ˜¯ DuckDB æ˜¯ä¸€ä¸ªå¼€æºçš„å†…å­˜
    OLAP æ•°æ®åº“ï¼Œä¸“ä¸ºåˆ†ææŸ¥è¯¢è€Œæ„å»ºã€‚å®ƒæœ¬åœ°è¿è¡Œï¼Œæ”¯æŒå¹¿æ³›çš„ SQLï¼Œå¹¶èƒ½ç›´æ¥åœ¨ Pandas æ•°æ®ã€Parquetã€JSON æ•°æ®ä¸Šè¿è¡ŒæŸ¥è¯¢ã€‚é¢å¤–åŠ åˆ†çš„æ˜¯å®ƒä¸
    Python å’Œ R çš„æ— ç¼é›†æˆã€‚å®ƒçš„æé€Ÿå¤„ç†èƒ½åŠ›å’Œå¤§éƒ¨åˆ†å†…å­˜å¤„ç†ä½¿å…¶æˆä¸ºæ„å»ºä¸ªäººæ•°æ®ä»“åº“çš„å¥½é€‰æ‹©ã€‚
- en: Fitbit activity data
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Fitbit æ´»åŠ¨æ•°æ®
- en: The first collection of files I looked at was activity data. Physical Activity
    and broad exercise information appears to be stored in numbered files such as
    `Physical Activity/exercise-1700.json`
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: I couldnâ€™t work out what the file numbering actually meant, my guess is they
    are just increasing integers for a collection of exercise files. In my data export
    the earliest files started at 0 and went to file number 1700 over a 6 year period.
    Inside is an array of records, each with a description of an activity. The record
    seems to change depending on the activity â€” here is an example of a â€œwalkâ€
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This physical activity data is one file of the 7,921 files now on my laptop.
    Fortunately, DuckDB can read (and auto-detect the schema) from JSON files using
    [read_json](https://duckdb.org/docs/data/json/overview.html#read_json_auto-function)
    function, allowing me to load all of the exercise files into the `physical_activity`
    table using a single SQL statement. Itâ€™s worth noting I needed to specify the
    date format mask as the Fitbit export has a very [American style date](https://en.wikipedia.org/wiki/Date_and_time_notation_in_the_United_States)
    format ğŸ˜•.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This SQL command reads the physical activity data from disk, converts the activity
    and duration and loads into a DuckDB table in memory.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: Load Physical Activity data into data frame
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I wanted to understand how I was spending my time with each month. As the activity
    data is stored at a very granular level I used the DuckDB SQL [time_bucket](https://duckdb.org/docs/sql/functions/timestamp.html)
    function to truncate the *activityTime* timestamp into monthly buckets. Loading
    the grouped physical activity data into data frame can be accomplished with this
    aggregate SQL and the query results can be directed into a Pandas dataframe with
    the << operator.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This single SQL query groups my activity data (bike, walk, run etc.,) into monthly
    buckets and allows me to honestly reflect on how much time I was devoting to physical
    activity.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Plot Monthly Activity Minutes
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I want to now explore my activity data visually â€” so letâ€™s get the Fitbit data
    and produce some statistical graphics. Iâ€™m going to use the Python [Seaborn](https://seaborn.pydata.org/)
    data visualisation library to create a bar plot of the monthly activity minutes
    directly from the *activity_df* dataframe.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Executing this against the loaded activity data creates this bar plot.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0e444629dea3ac0ca0427b4ec89659ba.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
- en: Workout activity breakdown â€” Screenshot by the author.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: It looks like my primary activity continues to be walking, and my New Years
    resolution to run more often in 2023 hasnâ€™t actually happened (yet?)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Sleep
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: About [one in three adults doesnâ€™t get enough sleep](https://www.health.harvard.edu/heart-health/are-you-getting-enough-sleep),
    so I wanted to explore my long term sleeping patterns. In my Fitbit archive sleep
    data appears to be recorded in dated files such as`Sleep/sleep-2022-12-28.json`.
    Each file holds a months worth of data, but confusingly is dated for the month
    before the event. For example, the file `sleep-2022-12-28.json` appears to have
    data for January spanning the dates 2023-01-02 to 2023-01-27\. Anyway â€” file naming
    weirdness aside we can explore the contents of the file. Within the record is
    an extended â€œlevelsâ€ block with a breakdown of sleep type (wake, light, REM, deep)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äº [ä¸‰åˆ†ä¹‹ä¸€çš„æˆå¹´äººç¡çœ ä¸è¶³](https://www.health.harvard.edu/heart-health/are-you-getting-enough-sleep)ï¼Œæ‰€ä»¥æˆ‘æƒ³æ¢ç´¢æˆ‘çš„é•¿æœŸç¡çœ æ¨¡å¼ã€‚åœ¨æˆ‘çš„Fitbitæ¡£æ¡ˆä¸­ï¼Œç¡çœ æ•°æ®ä¼¼ä¹è¢«è®°å½•åœ¨ä»¥æ—¥æœŸå‘½åçš„æ–‡ä»¶ä¸­ï¼Œä¾‹å¦‚`Sleep/sleep-2022-12-28.json`ã€‚æ¯ä¸ªæ–‡ä»¶åŒ…å«ä¸€ä¸ªæœˆçš„æ•°æ®ï¼Œä½†æ··æ·†çš„æ˜¯ï¼Œæ–‡ä»¶çš„æ—¥æœŸä¸ºäº‹ä»¶å‘ç”Ÿå‰çš„æœˆä»½ã€‚ä¾‹å¦‚ï¼Œæ–‡ä»¶`sleep-2022-12-28.json`ä¼¼ä¹åŒ…å«äº†2023å¹´1æœˆ2æ—¥è‡³2023å¹´1æœˆ27æ—¥çš„æ•°æ®ã€‚ä¸ç®¡æ€æ ·
    â€” æ–‡ä»¶å‘½åçš„å¥‡æ€ªä¹‹å¤„æš‚ä¸”ä¸æï¼Œæˆ‘ä»¬å¯ä»¥æ¢è®¨æ–‡ä»¶çš„å†…å®¹ã€‚åœ¨è®°å½•ä¸­æœ‰ä¸€ä¸ªæ‰©å±•çš„â€œlevelsâ€å—ï¼Œè¯¦ç»†æè¿°äº†ç¡çœ ç±»å‹ï¼ˆæ¸…é†’ã€æµ…ç¡ã€å¿«é€Ÿçœ¼åŠ¨ã€æ·±ç¡ï¼‰ã€‚
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: If I look at some of the older files (possibly created with my older Fitbit
    surge device) there is a different breakdown of sleep type (restless, awake, asleep).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæŸ¥çœ‹ä¸€äº›è¾ƒæ—§çš„æ–‡ä»¶ï¼ˆå¯èƒ½æ˜¯ç”¨æˆ‘ä»¥å‰çš„Fitbit Surgeè®¾å¤‡åˆ›å»ºçš„ï¼‰ï¼Œä¼šå‘ç°ç¡çœ ç±»å‹çš„åˆ†ç±»æœ‰æ‰€ä¸åŒï¼ˆèºåŠ¨ã€ä¸æ¸…é†’ã€ç¡çœ ï¼‰ã€‚
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Regardless of the schema, we can use the [DuckDB JSON](https://duckdb.org/docs/extensions/json.html)
    reader to read the records into a single table.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: æ— è®ºæ•°æ®æ¨¡å¼å¦‚ä½•ï¼Œæˆ‘ä»¬éƒ½å¯ä»¥ä½¿ç”¨ [DuckDB JSON](https://duckdb.org/docs/extensions/json.html)
    è¯»å–å™¨å°†è®°å½•è¯»å…¥ä¸€ä¸ªè¡¨æ ¼ä¸­ã€‚
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Schema changes for sleep data
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¡çœ æ•°æ®çš„æ¨¡å¼å˜åŒ–
- en: I wanted to process all of my sleep data, and handle the apparent schema change
    in the way sleep is recorded (most likely as I changed models of Fitbit devices).
    Some of the records have time recorded against `$.awake` which is similar (but
    not identical to) `$.wake`
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³å¤„ç†æˆ‘æ‰€æœ‰çš„ç¡çœ æ•°æ®ï¼Œå¹¶å¤„ç†è®°å½•ç¡çœ çš„æ¨¡å¼å˜åŒ–ï¼ˆå¾ˆå¯èƒ½æ˜¯å› ä¸ºæˆ‘æ›´æ¢äº†Fitbitè®¾å¤‡çš„å‹å·ï¼‰ã€‚ä¸€äº›è®°å½•çš„æ—¶é—´æ ‡è®°åœ¨`$.awake`ä¸Šï¼Œè¿™ä¸`$.wake`ç±»ä¼¼ï¼ˆä½†ä¸å®Œå…¨ç›¸åŒï¼‰ã€‚
- en: I used the SQL [coalesce](https://duckdb.org/docs/sql/functions/utility.html)
    function â€” which return the first expression that evaluates to a non-NULL value
    to combine similar types of sleep stage.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä½¿ç”¨äº†SQLä¸­çš„ [coalesce](https://duckdb.org/docs/sql/functions/utility.html) å‡½æ•°
    â€” å®ƒè¿”å›ç¬¬ä¸€ä¸ªè®¡ç®—ç»“æœä¸ºéNULLå€¼çš„è¡¨è¾¾å¼ï¼Œä»¥ç»“åˆç±»ä¼¼ç±»å‹çš„ç¡çœ é˜¶æ®µã€‚
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: With DuckDB I can query with [json_extract](https://duckdb.org/docs/extensions/json.html#json-extraction-functions)
    to extract the duration stages from the nested JSON to generate a *sleep_log_df*
    dataframe with all of the historic sleep stages grouped.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨DuckDBï¼Œæˆ‘å¯ä»¥é€šè¿‡ [json_extract](https://duckdb.org/docs/extensions/json.html#json-extraction-functions)
    æå–åµŒå¥—JSONä¸­çš„æ—¶é•¿é˜¶æ®µï¼Œä»¥ç”Ÿæˆä¸€ä¸ª *sleep_log_df* æ•°æ®æ¡†ï¼Œå°†æ‰€æœ‰å†å²ç¡çœ é˜¶æ®µè¿›è¡Œåˆ†ç»„ã€‚
- en: Plot sleep activity
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»˜åˆ¶ç¡çœ æ´»åŠ¨å›¾
- en: We can not take the daily sleep logs and produce a stacked bar plot showing
    the breakdown each night of being awake and in light, deep and [REM](https://en.wikipedia.org/wiki/Rapid_eye_movement_sleep)
    sleep.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å°†æ¯æ—¥ç¡çœ æ—¥å¿—åˆ¶ä½œæˆå †å æ¡å½¢å›¾ï¼Œæ˜¾ç¤ºæ¯æ™šæ¸…é†’ã€æµ…ç¡ã€æ·±ç¡å’Œ [REM](https://en.wikipedia.org/wiki/Rapid_eye_movement_sleep)
    ç¡çœ çš„åˆ†ç±»ã€‚
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Loading a month of sleep data allows me to create a broader analysis of sleep
    duration.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ è½½ä¸€ä¸ªæœˆçš„ç¡çœ æ•°æ®è®©æˆ‘èƒ½å¤Ÿè¿›è¡Œæ›´å¹¿æ³›çš„ç¡çœ æ—¶é•¿åˆ†æã€‚
- en: '![](../Images/3e9cfbb697bb69a1449463626e94ab1e.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e9cfbb697bb69a1449463626e94ab1e.png)'
- en: Sleep cycle duration each night â€” Screenshot by the author.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯æ™šçš„ç¡çœ å‘¨æœŸæ—¶é•¿ â€” ä½œè€…æˆªå›¾ã€‚
- en: The ability to graph multiple nights of sleep together on a single plot allows
    me to start understanding how days of the week and cyclic events affects the duration
    and quality of my sleep.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: å°†å¤šæ™šçš„ç¡çœ æ•°æ®ç»˜åˆ¶åœ¨ä¸€ä¸ªå›¾è¡¨ä¸Šï¼Œä½¿æˆ‘èƒ½å¤Ÿå¼€å§‹ç†è§£æ˜ŸæœŸå‡ å’Œå‘¨æœŸæ€§äº‹ä»¶å¦‚ä½•å½±å“æˆ‘çš„ç¡çœ æ—¶é•¿å’Œè´¨é‡ã€‚
- en: Heart rate
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¿ƒç‡
- en: Heart rate is captured very frequently (every 10â€“15 seconds) in files stored
    daily named like `Physical Activity/heart_rate-2023-01-26.json`. These files are
    really big â€” each day has around 70,000 lines â€” all wrapped in a single array.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: å¿ƒç‡æ•°æ®è¢«éå¸¸é¢‘ç¹åœ°æ•æ‰ï¼ˆæ¯`10â€“15ç§’`ä¸€æ¬¡ï¼‰ï¼Œå­˜å‚¨åœ¨åä¸º`Physical Activity/heart_rate-2023-01-26.json`çš„æ¯æ—¥æ–‡ä»¶ä¸­ã€‚è¿™äº›æ–‡ä»¶éå¸¸å¤§
    â€” æ¯å¤©çº¦æœ‰70,000è¡Œ â€” æ‰€æœ‰æ•°æ®éƒ½åŒ…è£…åœ¨ä¸€ä¸ªæ•°ç»„ä¸­ã€‚
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: My theory here is the file name represents the locale of the user. For example,
    in my timezone (GMT+11) named `heart_rate-2023-01-26.json` the data covers the
    day 26 00:00 (AEST) to 23:59 (AEST) - and it makes logical sense if the dates
    within the files are in GMT.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çš„ç†è®ºæ˜¯æ–‡ä»¶åè¡¨ç¤ºç”¨æˆ·çš„æ—¶åŒºã€‚ä¾‹å¦‚ï¼Œåœ¨æˆ‘çš„æ—¶åŒºï¼ˆGMT+11ï¼‰ï¼Œå‘½åä¸º`heart_rate-2023-01-26.json`çš„æ•°æ®è¦†ç›–äº†26æ—¥00:00ï¼ˆAESTï¼‰è‡³23:59ï¼ˆAESTï¼‰
    - å¦‚æœæ–‡ä»¶ä¸­çš„æ—¥æœŸä¸ºGMTï¼Œåˆ™é€»è¾‘ä¸Šæ˜¯åˆç†çš„ã€‚
- en: Transform JSON files
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è½¬æ¢JSONæ–‡ä»¶
- en: Up to now Iâ€™ve managed to process my Fitbit data as-is with included DuckDB
    functions. However, I hit a problem when trying to process these enormous heart
    rate files. DuckDB gave me this error when trying to process a large array of
    records in a JSON files
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘å·²ç»æˆåŠŸå¤„ç†äº†åŒ…å« DuckDB å‡½æ•°çš„ Fitbit æ•°æ®ã€‚ç„¶è€Œï¼Œåœ¨å¤„ç†è¿™äº›å·¨å¤§çš„å¿ƒç‡æ–‡ä»¶æ—¶ï¼Œæˆ‘é‡åˆ°äº†é—®é¢˜ã€‚å½“å°è¯•å¤„ç† JSON æ–‡ä»¶ä¸­çš„å¤§æ•°ç»„è®°å½•æ—¶ï¼ŒDuckDB
    ç»™å‡ºäº†è¿™ä¸ªé”™è¯¯ã€‚
- en: '**(duckdb.InvalidInputException) â€œINTERNAL Error: Unexpected yyjson tag in
    ValTypeToStringâ€**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**(duckdb.InvalidInputException) â€œINTERNAL Error: Unexpected yyjson tag in
    ValTypeToStringâ€**'
- en: I think this error message is an abrupt way of telling me itâ€™s unreasonable
    to expect a JSON array to have so many elements. The fix was to pre-process the
    file so it wasnâ€™t an array of JSON records, instead converted to newline-delimited
    JSON, or [ndjson](http://ndjson.org/).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºè¿™ä¸ªé”™è¯¯ä¿¡æ¯æ˜¯ä¸€ä¸ªçªå¦‚å…¶æ¥çš„æé†’ï¼Œå‘Šè¯‰æˆ‘æœŸæœ›ä¸€ä¸ª JSON æ•°ç»„æœ‰è¿™ä¹ˆå¤šå…ƒç´ æ˜¯ä¸åˆç†çš„ã€‚è§£å†³åŠæ³•æ˜¯é¢„å¤„ç†æ–‡ä»¶ï¼Œä½¿å…¶ä¸æ˜¯ JSON è®°å½•æ•°ç»„ï¼Œè€Œæ˜¯è½¬æ¢ä¸ºæ¢è¡Œç¬¦åˆ†éš”çš„
    JSON æˆ– [ndjson](http://ndjson.org/)ã€‚
- en: '[PRE10]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: To transform heart rate array_of_records into newline-delimited JSON I used
    a sneaky bit of Python to convert each file.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å°†å¿ƒç‡æ•°ç»„è®°å½•è½¬æ¢ä¸ºæ¢è¡Œç¬¦åˆ†éš”çš„ JSONï¼Œæˆ‘ä½¿ç”¨äº†ä¸€ç‚¹å°å·§çš„ Python ä»£ç æ¥è½¬æ¢æ¯ä¸ªæ–‡ä»¶ã€‚
- en: '[PRE11]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This will find each *.json* file, read converting the contents into newline-delimited
    JSON with a new file created with the file extension *.ndjson*. This converts
    an array with 70,000 records to a file with 70,000 lines â€” with each JSON record
    now stored on a new line.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†æŸ¥æ‰¾æ¯ä¸ª *.json* æ–‡ä»¶ï¼Œè¯»å–å†…å®¹å¹¶å°†å…¶è½¬æ¢ä¸ºæ¢è¡Œç¬¦åˆ†éš”çš„ JSONï¼Œå¹¶ç”¨ *.ndjson* æ–‡ä»¶æ‰©å±•ååˆ›å»ºæ–°æ–‡ä»¶ã€‚è¿™å°†ä¸€ä¸ªåŒ…å«70,000æ¡è®°å½•çš„æ•°ç»„è½¬æ¢ä¸ºä¸€ä¸ªåŒ…å«70,000è¡Œçš„æ–‡ä»¶â€”â€”æ¯æ¡
    JSON è®°å½•ç°åœ¨å­˜å‚¨åœ¨æ–°çš„ä¸€è¡Œä¸Šã€‚
- en: Load heart rate data into table
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å°†å¿ƒç‡æ•°æ®åŠ è½½åˆ°è¡¨ä¸­
- en: With the newly converted *ndjson* files, Iâ€™m now ready to load heart rate data
    into a DuckDB table. Note the use of `timestampformat='%m/%d/%y %H:%M:%S');` to
    describe the leading month in the dates (for example *"01/25/23 13:00:07"*)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ–°è½¬æ¢çš„ *ndjson* æ–‡ä»¶ï¼Œæˆ‘ç°åœ¨å‡†å¤‡å°†å¿ƒç‡æ•°æ®åŠ è½½åˆ° DuckDB è¡¨ä¸­ã€‚æ³¨æ„ä½¿ç”¨ `timestampformat='%m/%d/%y %H:%M:%S');`
    æ¥æè¿°æ—¥æœŸä¸­çš„å‰å¯¼æœˆä»½ï¼ˆä¾‹å¦‚ *"01/25/23 13:00:07"*)
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We can load all the .ndjson files by setting the format to â€™newline_delimitedâ€™.
    Note we can extract the BPM (beats per minute) with the JSON extraction and cast
    into an integer.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡å°†æ ¼å¼è®¾ç½®ä¸º â€™newline_delimitedâ€™ æ¥åŠ è½½æ‰€æœ‰ .ndjson æ–‡ä»¶ã€‚æ³¨æ„æˆ‘ä»¬å¯ä»¥é€šè¿‡ JSON æå–æ¥æå– BPMï¼ˆæ¯åˆ†é’Ÿå¿ƒè·³æ¬¡æ•°ï¼‰å¹¶å°†å…¶è½¬æ¢ä¸ºæ•´æ•°ã€‚
- en: '![](../Images/3085503bcdcd2945270d26a383b88a08.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3085503bcdcd2945270d26a383b88a08.png)'
- en: DuckDB is blazing fast at processing JSON- Screenshot by the author.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: DuckDB åœ¨å¤„ç† JSON æ—¶éå¸¸å¿«é€Ÿ â€” ä½œè€…æˆªå›¾ã€‚
- en: Itâ€™s worth highlighting here how insanely fast DuckDB is â€” it took only 2.8
    seconds to load 12 million records!
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: å€¼å¾—åœ¨è¿™é‡Œå¼ºè°ƒ DuckDB çš„é€Ÿåº¦æ˜¯å¤šä¹ˆæƒŠäººâ€”â€”åŠ è½½ 1200 ä¸‡æ¡è®°å½•ä»…ç”¨äº† 2.8 ç§’ï¼
- en: Load heart rate into data frame
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å°†å¿ƒç‡åŠ è½½åˆ°æ•°æ®æ¡†ä¸­
- en: With 12 million hear rate measurements loaded, letâ€™s load a single days worth
    of data into a data frame for the 21st of May.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åŠ è½½äº† 1200 ä¸‡æ¡å¿ƒç‡æµ‹é‡è®°å½•åï¼Œæˆ‘ä»¬å°† 5 æœˆ 21 æ—¥çš„ä¸€å¤©æ•°æ®åŠ è½½åˆ°æ•°æ®æ¡†ä¸­ã€‚
- en: '[PRE13]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This DuckDB query aggregates the variability of heart rate into time bucks of
    1 minute; banding into min, average and maximum within each period.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ª DuckDB æŸ¥è¯¢å°†å¿ƒç‡çš„å˜å¼‚æ€§èšåˆåˆ° 1 åˆ†é’Ÿçš„æ—¶é—´å—ä¸­ï¼›åœ¨æ¯ä¸ªå‘¨æœŸå†…è¿›è¡Œæœ€å°å€¼ã€å¹³å‡å€¼å’Œæœ€å¤§å€¼çš„åˆ†ç±»ã€‚
- en: Plot Heart rate
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»˜åˆ¶å¿ƒç‡å›¾
- en: I can plat the heart rate using a plot like this (and also to show off I actually
    did go for a run at 6am)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¯ä»¥ä½¿ç”¨è¿™æ ·çš„å›¾æ¥ç»˜åˆ¶å¿ƒç‡ï¼ˆé¡ºä¾¿ç‚«è€€ä¸€ä¸‹ï¼Œæˆ‘ç¡®å®åœ¨æ—©ä¸Š 6 ç‚¹å»è·‘æ­¥äº†ï¼‰
- en: '[PRE14]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/9962db0f04ea299fd471bc8b221b5da7.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9962db0f04ea299fd471bc8b221b5da7.png)'
- en: Heart rate over a day â€” Screenshot by the author.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€å¤©ä¸­çš„å¿ƒç‡ â€” ä½œè€…æˆªå›¾ã€‚
- en: Exploring heart rate with fine granularity allows me to track my fitness goals
    â€” especially if I stick with my regular running routine.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ç»†ç²’åº¦æ¢ç´¢å¿ƒç‡ä½¿æˆ‘èƒ½å¤Ÿè·Ÿè¸ªæˆ‘çš„å¥èº«ç›®æ ‡â€”â€”ç‰¹åˆ«æ˜¯å¦‚æœæˆ‘åšæŒæˆ‘çš„å¸¸è§„è·‘æ­¥è®¡åˆ’ã€‚
- en: Steps
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ­¥éª¤
- en: Steps are recorded in daily files named `Physical Activity/steps-2023-02-26.json`.
    This appears to be a fine grain count of steps during period blocks (every 5 to
    10 minutes) throughout the day
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¥éª¤è®°å½•åœ¨åä¸º `Physical Activity/steps-2023-02-26.json` çš„æ¯æ—¥æ–‡ä»¶ä¸­ã€‚è¿™ä¼¼ä¹æ˜¯å¯¹ä¸€å¤©ä¸­æ¯ä¸ªæ—¶é—´æ®µå—ï¼ˆæ¯ 5
    åˆ° 10 åˆ†é’Ÿï¼‰å†…çš„æ­¥éª¤çš„è¯¦ç»†è®¡æ•°ã€‚
- en: '[PRE15]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: To aggregate the steps into daily counts I needed to convert GMT into my local
    timezone (GMT+11)
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å°†æ­¥éª¤èšåˆä¸ºæ¯æ—¥ç»Ÿè®¡ï¼Œæˆ‘éœ€è¦å°† GMT è½¬æ¢ä¸ºæˆ‘çš„æœ¬åœ°æ—¶åŒºï¼ˆGMT+11ï¼‰ã€‚
- en: '[PRE16]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Aggregating the number of daily steps into the *steps_df* dataframe allows me
    to explore the longer term activity trends as I attempt to exceed 10,000 steps
    to realise the [increased health benefits](https://www.10000steps.org.au/articles/healthy-lifestyles/health-check-do-we-really-need-take-10000-steps-day/).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ¯æ—¥æ­¥éª¤èšåˆåˆ° *steps_df* æ•°æ®æ¡†ä¸­ï¼Œä½¿æˆ‘èƒ½å¤Ÿæ¢ç´¢é•¿æœŸçš„æ´»åŠ¨è¶‹åŠ¿ï¼Œå› ä¸ºæˆ‘åŠªåŠ›è¶…è¶Š 10,000 æ­¥ä»¥å®ç°[å¥åº·ç›Šå¤„çš„æå‡](https://www.10000steps.org.au/articles/healthy-lifestyles/health-check-do-we-really-need-take-10000-steps-day/)ã€‚
- en: Plot daily steps
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»˜åˆ¶æ¯æ—¥æ­¥éª¤
- en: We can now take dataframe and plot a daily step count
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥å°†æ•°æ®æ¡†ç»˜åˆ¶ä¸ºæ¯æ—¥æ­¥æ•°
- en: '[PRE17]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](../Images/8a95077d4b6046f60e34eef75c8ff1de.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8a95077d4b6046f60e34eef75c8ff1de.png)'
- en: Daily step count â€” Screenshot by the author.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯æ—¥æ­¥æ•°ç»Ÿè®¡â€”â€”ä½œè€…æˆªå›¾ã€‚
- en: Which shows Iâ€™ve still got to work at my daily step goal â€” another strike against
    my new years fitness resolution.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¾ç¤ºæˆ‘è¿˜éœ€è¦åŠªåŠ›è¾¾åˆ°æˆ‘çš„æ¯æ—¥æ­¥æ•°ç›®æ ‡â€”â€”è¿™å¯¹æˆ‘çš„æ–°å¹´å¥èº«å†³å¿ƒæ¥è¯´åˆæ˜¯ä¸€æ¬¡æ‰“å‡»ã€‚
- en: GPS Mapping
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPS æ˜ å°„
- en: Fitbit stores GPS logged activities as [TCX (Training Center XML)](https://en.wikipedia.org/wiki/GPS_Exchange_Format)
    files. These XML files are *not* in the downloaded ZIP, but we have a reference
    to their location in the Physical Activity files, which I can query like this.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Fitbit å°† GPS è®°å½•çš„æ´»åŠ¨å­˜å‚¨ä¸º[TCX (è®­ç»ƒä¸­å¿ƒ XML)](https://en.wikipedia.org/wiki/GPS_Exchange_Format)
    æ–‡ä»¶ã€‚è¿™äº› XML æ–‡ä»¶åœ¨ä¸‹è½½çš„ ZIP æ–‡ä»¶ä¸­*æ²¡æœ‰*ï¼Œä½†æˆ‘ä»¬åœ¨èº«ä½“æ´»åŠ¨æ–‡ä»¶ä¸­æœ‰å…¶ä½ç½®çš„å‚è€ƒï¼Œæˆ‘å¯ä»¥åƒè¿™æ ·æŸ¥è¯¢ã€‚
- en: '[PRE18]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The tcxLink field is a URL reference to their location in the Physical Activity
    files.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: tcxLink å­—æ®µæ˜¯å¯¹èº«ä½“æ´»åŠ¨æ–‡ä»¶ä¸­ä½ç½®çš„ URL å‚è€ƒã€‚
- en: '![](../Images/6037d84f1ca242c03cced5f82d2e7f4f.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6037d84f1ca242c03cced5f82d2e7f4f.png)'
- en: The URL for each TCX file â€” Screenshot by the author.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ª TCX æ–‡ä»¶çš„ URLâ€”â€”ä½œè€…æˆªå›¾ã€‚
- en: We can use this URL directly in a browser (once logged onto the Fitbit website)
    to do download the GPS XML file. Looking inside the TCX file, we find low level
    GPS locations every few seconds.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ç›´æ¥åœ¨æµè§ˆå™¨ä¸­ä½¿ç”¨è¿™ä¸ª URLï¼ˆç™»å½• Fitbit ç½‘ç«™åï¼‰æ¥ä¸‹è½½ GPS XML æ–‡ä»¶ã€‚æŸ¥çœ‹ TCX æ–‡ä»¶å†…éƒ¨ï¼Œæˆ‘ä»¬ä¼šå‘ç°æ¯éš”å‡ ç§’é’Ÿå°±æœ‰ä½çº§åˆ«çš„
    GPS ä½ç½®æ•°æ®ã€‚
- en: '![](../Images/c850bc9f8b7d837fb45767fd1fa6780c.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c850bc9f8b7d837fb45767fd1fa6780c.png)'
- en: TCX GPS XML file sample contentents - Screenshot by the author.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: TCX GPS XML æ–‡ä»¶æ ·æœ¬å†…å®¹â€”â€”ä½œè€…æˆªå›¾ã€‚
- en: The good news is this has some obvious fields like latitude, longitude and time.
    The not so good news is this is XML, so we need to pre-process these files prior
    to loading into DuckDB as presently XML isnâ€™t supported by the file reader. We
    can convert XML files into JSON files with another bit of Python code, looping
    over each *.tcx* file.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½æ¶ˆæ¯æ˜¯æ•°æ®ä¸­æœ‰ä¸€äº›æ˜æ˜¾çš„å­—æ®µï¼Œå¦‚çº¬åº¦ã€ç»åº¦å’Œæ—¶é—´ã€‚ä¸å¤ªå¥½çš„æ¶ˆæ¯æ˜¯æ•°æ®æ˜¯ XML æ ¼å¼çš„ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦åœ¨åŠ è½½åˆ° DuckDB ä¹‹å‰é¢„å¤„ç†è¿™äº›æ–‡ä»¶ï¼Œå› ä¸ºç›®å‰
    XML æ ¼å¼ä¸è¢«æ–‡ä»¶è¯»å–å™¨æ”¯æŒã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡å¦ä¸€æ®µ Python ä»£ç å°† XML æ–‡ä»¶è½¬æ¢ä¸º JSON æ–‡ä»¶ï¼Œå¾ªç¯éå†æ¯ä¸ª *.tcx* æ–‡ä»¶ã€‚
- en: There is a bit of nasty XML nesting going on here, with the location data found
    under *TrainingCenterDatabase/Activities/Activity/Lap*.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€äº›å¤æ‚çš„ XML åµŒå¥—ï¼Œä½ç½®æ•°æ®ä½äº *TrainingCenterDatabase/Activities/Activity/Lap* ä¸‹ã€‚
- en: '[PRE19]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Loading GPS Geospatial data
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ è½½ GPS åœ°ç†ç©ºé—´æ•°æ®
- en: We can load the Geospatial data like this
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥è¿™æ ·åŠ è½½åœ°ç†ç©ºé—´æ•°æ®
- en: '[PRE20]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This DuckDB query flattens the JSON, converts the latitude, longitude and time
    into the correct data types and loads into the *route_df* dataframe.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ª DuckDB æŸ¥è¯¢æ‰å¹³åŒ–äº† JSONï¼Œå°†çº¬åº¦ã€ç»åº¦å’Œæ—¶é—´è½¬æ¢ä¸ºæ­£ç¡®çš„æ•°æ®ç±»å‹ï¼Œå¹¶åŠ è½½åˆ° *route_df* æ•°æ®æ¡†ä¸­ã€‚
- en: Visualize GPS Routes with Folium
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Folium å¯è§†åŒ– GPS è·¯çº¿
- en: Having a table of location information isnâ€™t very descriptive, so I wanted to
    start plotting my running routes on an interactive map. I used this blog to help
    [Visualize routes with Folium](https://betterdatascience.com/data-science-for-cycling-how-to-visualize-gpx-strava-routes-with-python-and-folium/).
    Modifying the code helped me plot my own runs, for example this is a plot of a
    recent run while on holiday in [Canberra](https://en.wikipedia.org/wiki/Canberra).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: æ‹¥æœ‰ä¸€ä¸ªä½ç½®ä¿¡æ¯çš„è¡¨æ ¼å¹¶ä¸å¤Ÿç›´è§‚ï¼Œå› æ­¤æˆ‘æƒ³å¼€å§‹åœ¨äº¤äº’å¼åœ°å›¾ä¸Šç»˜åˆ¶æˆ‘çš„è·‘æ­¥è·¯çº¿ã€‚æˆ‘ä½¿ç”¨äº†è¿™ç¯‡åšå®¢æ¥å¸®åŠ©[ä½¿ç”¨ Folium å¯è§†åŒ–è·¯çº¿](https://betterdatascience.com/data-science-for-cycling-how-to-visualize-gpx-strava-routes-with-python-and-folium/)ã€‚ä¿®æ”¹ä»£ç å¸®åŠ©æˆ‘ç»˜åˆ¶äº†è‡ªå·±çš„è·‘æ­¥è·¯çº¿ï¼Œä¾‹å¦‚è¿™æ˜¯æˆ‘åœ¨[å ªåŸ¹æ‹‰](https://en.wikipedia.org/wiki/Canberra)åº¦å‡æ—¶çš„ä¸€æ¬¡è·‘æ­¥è·¯çº¿å›¾ã€‚
- en: '[PRE21]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![](../Images/9d1e52b607975ce6d097d1cb3e5b5d7f.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9d1e52b607975ce6d097d1cb3e5b5d7f.png)'
- en: Folium map plot of a run â€” Screenshot by the author.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: è·‘æ­¥çš„ Folium åœ°å›¾å›¾ç¤ºâ€”â€”ä½œè€…æˆªå›¾ã€‚
- en: Which generates a plot of my run using [open street map](https://openmaptiles.org/)
    tiles, giving me a great interactive detailed map of my run.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç”Ÿæˆäº†ä¸€ä¸ªä½¿ç”¨[å¼€æ”¾è¡—å›¾](https://openmaptiles.org/) ç“¦ç‰‡çš„è·‘æ­¥å›¾ï¼Œç»™æˆ‘æä¾›äº†ä¸€ä¸ªå¾ˆå¥½çš„äº¤äº’å¼è¯¦ç»†è·‘æ­¥åœ°å›¾ã€‚
- en: Data goals and fitness goal summary
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ•°æ®ç›®æ ‡å’Œå¥èº«ç›®æ ‡æ€»ç»“
- en: Did I get get closer to my goal of analysis my Fitbit device data â€” absolutely!
    DuckDB proved to be an ideal flexible lightweight analytical tool for wrangling
    my extensive and chaotic Fitbit data achieve. Blazing through literally millions
    of records in seconds with the extensive SQL support and flexible file parsing
    options locally into dataframes makes DuckDB ideal for building my own personal
    data warehouse.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ˜¯å¦æ›´æ¥è¿‘åˆ†ææˆ‘çš„ Fitbit è®¾å¤‡æ•°æ®çš„ç›®æ ‡â€”â€”ç»å¯¹æ˜¯çš„ï¼DuckDB è¯æ˜æ˜¯ä¸€ä¸ªç†æƒ³çš„çµæ´»è½»é‡çº§åˆ†æå·¥å…·ï¼Œèƒ½å¤Ÿå¿«é€Ÿå¤„ç†æˆ‘çš„å¤§é‡æ··ä¹±çš„ Fitbit
    æ•°æ®ã€‚é€šè¿‡å¹¿æ³›çš„ SQL æ”¯æŒå’Œçµæ´»çš„æ–‡ä»¶è§£æé€‰é¡¹ï¼ŒDuckDB èƒ½å¤Ÿåœ¨å‡ ç§’é’Ÿå†…å¤„ç†æ•°ç™¾ä¸‡æ¡è®°å½•ï¼Œå°†æ•°æ®æœ¬åœ°å¯¼å…¥æ•°æ®æ¡†ï¼Œè¿™ä½¿å¾— DuckDB æˆä¸ºæ„å»ºä¸ªäººæ•°æ®ä»“åº“çš„ç†æƒ³é€‰æ‹©ã€‚
- en: As for my fitness goal â€” I have some work to do. I think I should leave this
    blog now as Iâ€™m short of my step goal target for today
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: Code
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ğŸ› ï¸Code for Fitbit activity analysis with DuckDB â€” [https://github.com/saubury/duckdb-fitbit](https://github.com/saubury/duckdb-fitbit)
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
