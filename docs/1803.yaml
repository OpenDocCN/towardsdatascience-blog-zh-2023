- en: My (Very) Personal Data Warehouse
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我的（非常）个人数据仓库
- en: 原文：[https://towardsdatascience.com/my-very-personal-data-warehouse-fitbit-activity-analysis-with-duckdb-8d1193046133?source=collection_archive---------3-----------------------#2023-05-31](https://towardsdatascience.com/my-very-personal-data-warehouse-fitbit-activity-analysis-with-duckdb-8d1193046133?source=collection_archive---------3-----------------------#2023-05-31)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/my-very-personal-data-warehouse-fitbit-activity-analysis-with-duckdb-8d1193046133?source=collection_archive---------3-----------------------#2023-05-31](https://towardsdatascience.com/my-very-personal-data-warehouse-fitbit-activity-analysis-with-duckdb-8d1193046133?source=collection_archive---------3-----------------------#2023-05-31)
- en: Fitbit activity analysis with DuckDB
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用DuckDB分析Fitbit活动数据
- en: '[](https://simon-aubury.medium.com/?source=post_page-----8d1193046133--------------------------------)[![Simon
    Aubury](../Images/fb757b7175c211450dcfa7249549c31e.png)](https://simon-aubury.medium.com/?source=post_page-----8d1193046133--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8d1193046133--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8d1193046133--------------------------------)
    [Simon Aubury](https://simon-aubury.medium.com/?source=post_page-----8d1193046133--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://simon-aubury.medium.com/?source=post_page-----8d1193046133--------------------------------)[![Simon
    Aubury](../Images/fb757b7175c211450dcfa7249549c31e.png)](https://simon-aubury.medium.com/?source=post_page-----8d1193046133--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8d1193046133--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8d1193046133--------------------------------)
    [Simon Aubury](https://simon-aubury.medium.com/?source=post_page-----8d1193046133--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb7b3bb643843&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-very-personal-data-warehouse-fitbit-activity-analysis-with-duckdb-8d1193046133&user=Simon+Aubury&userId=b7b3bb643843&source=post_page-b7b3bb643843----8d1193046133---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8d1193046133--------------------------------)
    ·13 min read·May 31, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8d1193046133&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-very-personal-data-warehouse-fitbit-activity-analysis-with-duckdb-8d1193046133&user=Simon+Aubury&userId=b7b3bb643843&source=-----8d1193046133---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb7b3bb643843&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-very-personal-data-warehouse-fitbit-activity-analysis-with-duckdb-8d1193046133&user=Simon+Aubury&userId=b7b3bb643843&source=post_page-b7b3bb643843----8d1193046133---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8d1193046133--------------------------------)
    · 13分钟阅读 · 2023年5月31日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8d1193046133&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-very-personal-data-warehouse-fitbit-activity-analysis-with-duckdb-8d1193046133&user=Simon+Aubury&userId=b7b3bb643843&source=-----8d1193046133---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8d1193046133&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-very-personal-data-warehouse-fitbit-activity-analysis-with-duckdb-8d1193046133&source=-----8d1193046133---------------------bookmark_footer-----------)![](../Images/d002b45123ebfc0803be779dbe0d1fe1.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8d1193046133&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-very-personal-data-warehouse-fitbit-activity-analysis-with-duckdb-8d1193046133&source=-----8d1193046133---------------------bookmark_footer-----------)![](../Images/d002b45123ebfc0803be779dbe0d1fe1.png)'
- en: Photo by [Jake Hills](https://unsplash.com/es/@jakehills?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Jake Hills](https://unsplash.com/es/@jakehills?utm_source=medium&utm_medium=referral)提供，发布在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Wearable fitness trackers have become an integral part of our lives, collecting
    and tracking data about our daily activities, sleep patterns, location, heart
    rate, and much more. I’ve been using a Fitbit device for 6 years to monitor my
    health. However, I have always found the data analysis capabilities lacking —
    especially when I wanted to track my progress against long term fitness goals.
    What insights are buried within my archive of personal fitness activity data?
    To start exploring I needed a good approach for performing data analysis over
    thousands of poorly documented JSON and CSV files … extra points for analysis
    that doesn’t require my data to leave my laptop.
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 可穿戴健身追踪器已成为我们生活中不可或缺的一部分，收集并跟踪我们日常活动、睡眠模式、位置、心率等数据。我已经使用 Fitbit 设备 6 年来监测我的健康。然而，我一直觉得数据分析功能不足
    — 尤其是在我想跟踪长期健身目标的进展时。我的个人健身活动数据存档中埋藏了哪些见解？要开始探索，我需要一种有效的方法来对成千上万的记录不完善的 JSON 和
    CSV 文件进行数据分析……额外加分的是分析过程中不需要将我的数据从笔记本电脑上移走。
- en: Enter [DuckDB](https://duckdb.org/why_duckdb) — a lightweight, free yet powerful
    analytical database designed to streamline data analysis workflows — that runs
    locally. In this blog post, I want to use DuckDB to explore my Fitbit data achieve
    and share the approach for analysing a variety of data formats and charting my
    health and fitness goals with the help of [Seaborn](https://seaborn.pydata.org/)
    data visualisations.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 进入 [DuckDB](https://duckdb.org/why_duckdb) — 一个轻量级、免费但强大的分析数据库，旨在简化数据分析工作流 —
    它在本地运行。在这篇博客中，我想使用 DuckDB 来探索我的 Fitbit 数据，并分享使用 [Seaborn](https://seaborn.pydata.org/)
    数据可视化的各种数据格式分析方法以及绘制我的健康和健身目标的途径。
- en: Export Fitbit data archive
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导出 Fitbit 数据存档
- en: Firstly, I needed to get hold of all of my historic fitness data. Fitbit make
    it fairly easy to export your Fitbit data for the lifetime of your account by
    following the instructions at [export your account archive](https://www.fitbit.com/settings/data/export).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我需要获取我所有的历史健身数据。通过遵循 [导出您的账户存档](https://www.fitbit.com/settings/data/export)
    的说明，Fitbit 使得导出您账户生命周期中的 Fitbit 数据变得相当简单。
- en: '![](../Images/aa73415b842cc76279e913c0efaac903.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aa73415b842cc76279e913c0efaac903.png)'
- en: Instructions for using the export Fitbit data archive — Screenshot by the author.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 使用导出 Fitbit 数据存档的说明 — 作者截图。
- en: You’ll need to confirm your request … and be patient. My archive took over three
    days to create — but I finally received an email with instructions to download
    a ZIP file containing my Fitbit data. This file should contain all my personal
    fitness activity recorded by my Fitbit or associated service. Unzipping the archive
    reveals a huge collection of files — mine for example had 7,921 files once I unzipped
    the 79MB file.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要确认您的请求……并保持耐心。我的存档创建了超过三天 — 但我最终收到了含有下载 ZIP 文件说明的电子邮件。该文件应包含由我的 Fitbit 或相关服务记录的所有个人健身活动。解压存档后会显示出大量的文件
    — 例如，我在解压 79MB 文件后总共有 7,921 个文件。
- en: '![](../Images/ce1b07a83af019cead0416c777cb7f8f.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ce1b07a83af019cead0416c777cb7f8f.png)'
- en: A small sample of the thousands of nested files — Screenshot by the author.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 数以千计的嵌套文件中的一小部分 — 作者截图。
- en: Let’s start looking at the variety of data available in the archive.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始查看存档中可用的数据种类。
- en: Why DuckDB?
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么选择 DuckDB？
- en: There are many great blogs ([1](https://betterprogramming.pub/duckdb-whats-the-hype-about-5d46aaa73196),[2](https://mattpalmer.io/posts/whats-the-hype-duckdb/),[3](/a-serverless-query-engine-from-spare-parts-bd6320f10353))
    describing DuckDB — the [TL;DR](https://www.dictionary.com/browse/tl-dr) summary
    is DuckDB is an open-source in-process OLAP database built specifically for analytical
    queries. It runs locally, has extensive SQL support and can run queries directly
    on Pandas data, Parquet, JSON data. Extra points for its seamless integration
    with Python and R. The fact it’s insanely fast and does (mostly) all processing
    in memory make it a good choice for building my personal data warehouse.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多优秀的博客 ([1](https://betterprogramming.pub/duckdb-whats-the-hype-about-5d46aaa73196),[2](https://mattpalmer.io/posts/whats-the-hype-duckdb/),[3](/a-serverless-query-engine-from-spare-parts-bd6320f10353))
    描述了 DuckDB — [TL;DR](https://www.dictionary.com/browse/tl-dr) 摘要是 DuckDB 是一个开源的内存
    OLAP 数据库，专为分析查询而构建。它本地运行，支持广泛的 SQL，并能直接在 Pandas 数据、Parquet、JSON 数据上运行查询。额外加分的是它与
    Python 和 R 的无缝集成。它的极速处理能力和大部分内存处理使其成为构建个人数据仓库的好选择。
- en: Fitbit activity data
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Fitbit 活动数据
- en: The first collection of files I looked at was activity data. Physical Activity
    and broad exercise information appears to be stored in numbered files such as
    `Physical Activity/exercise-1700.json`
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: I couldn’t work out what the file numbering actually meant, my guess is they
    are just increasing integers for a collection of exercise files. In my data export
    the earliest files started at 0 and went to file number 1700 over a 6 year period.
    Inside is an array of records, each with a description of an activity. The record
    seems to change depending on the activity — here is an example of a “walk”
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This physical activity data is one file of the 7,921 files now on my laptop.
    Fortunately, DuckDB can read (and auto-detect the schema) from JSON files using
    [read_json](https://duckdb.org/docs/data/json/overview.html#read_json_auto-function)
    function, allowing me to load all of the exercise files into the `physical_activity`
    table using a single SQL statement. It’s worth noting I needed to specify the
    date format mask as the Fitbit export has a very [American style date](https://en.wikipedia.org/wiki/Date_and_time_notation_in_the_United_States)
    format 😕.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This SQL command reads the physical activity data from disk, converts the activity
    and duration and loads into a DuckDB table in memory.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: Load Physical Activity data into data frame
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I wanted to understand how I was spending my time with each month. As the activity
    data is stored at a very granular level I used the DuckDB SQL [time_bucket](https://duckdb.org/docs/sql/functions/timestamp.html)
    function to truncate the *activityTime* timestamp into monthly buckets. Loading
    the grouped physical activity data into data frame can be accomplished with this
    aggregate SQL and the query results can be directed into a Pandas dataframe with
    the << operator.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This single SQL query groups my activity data (bike, walk, run etc.,) into monthly
    buckets and allows me to honestly reflect on how much time I was devoting to physical
    activity.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Plot Monthly Activity Minutes
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I want to now explore my activity data visually — so let’s get the Fitbit data
    and produce some statistical graphics. I’m going to use the Python [Seaborn](https://seaborn.pydata.org/)
    data visualisation library to create a bar plot of the monthly activity minutes
    directly from the *activity_df* dataframe.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Executing this against the loaded activity data creates this bar plot.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0e444629dea3ac0ca0427b4ec89659ba.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
- en: Workout activity breakdown — Screenshot by the author.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: It looks like my primary activity continues to be walking, and my New Years
    resolution to run more often in 2023 hasn’t actually happened (yet?)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Sleep
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: About [one in three adults doesn’t get enough sleep](https://www.health.harvard.edu/heart-health/are-you-getting-enough-sleep),
    so I wanted to explore my long term sleeping patterns. In my Fitbit archive sleep
    data appears to be recorded in dated files such as`Sleep/sleep-2022-12-28.json`.
    Each file holds a months worth of data, but confusingly is dated for the month
    before the event. For example, the file `sleep-2022-12-28.json` appears to have
    data for January spanning the dates 2023-01-02 to 2023-01-27\. Anyway — file naming
    weirdness aside we can explore the contents of the file. Within the record is
    an extended “levels” block with a breakdown of sleep type (wake, light, REM, deep)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 [三分之一的成年人睡眠不足](https://www.health.harvard.edu/heart-health/are-you-getting-enough-sleep)，所以我想探索我的长期睡眠模式。在我的Fitbit档案中，睡眠数据似乎被记录在以日期命名的文件中，例如`Sleep/sleep-2022-12-28.json`。每个文件包含一个月的数据，但混淆的是，文件的日期为事件发生前的月份。例如，文件`sleep-2022-12-28.json`似乎包含了2023年1月2日至2023年1月27日的数据。不管怎样
    — 文件命名的奇怪之处暂且不提，我们可以探讨文件的内容。在记录中有一个扩展的“levels”块，详细描述了睡眠类型（清醒、浅睡、快速眼动、深睡）。
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: If I look at some of the older files (possibly created with my older Fitbit
    surge device) there is a different breakdown of sleep type (restless, awake, asleep).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果查看一些较旧的文件（可能是用我以前的Fitbit Surge设备创建的），会发现睡眠类型的分类有所不同（躁动、不清醒、睡眠）。
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Regardless of the schema, we can use the [DuckDB JSON](https://duckdb.org/docs/extensions/json.html)
    reader to read the records into a single table.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 无论数据模式如何，我们都可以使用 [DuckDB JSON](https://duckdb.org/docs/extensions/json.html)
    读取器将记录读入一个表格中。
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Schema changes for sleep data
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 睡眠数据的模式变化
- en: I wanted to process all of my sleep data, and handle the apparent schema change
    in the way sleep is recorded (most likely as I changed models of Fitbit devices).
    Some of the records have time recorded against `$.awake` which is similar (but
    not identical to) `$.wake`
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我想处理我所有的睡眠数据，并处理记录睡眠的模式变化（很可能是因为我更换了Fitbit设备的型号）。一些记录的时间标记在`$.awake`上，这与`$.wake`类似（但不完全相同）。
- en: I used the SQL [coalesce](https://duckdb.org/docs/sql/functions/utility.html)
    function — which return the first expression that evaluates to a non-NULL value
    to combine similar types of sleep stage.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了SQL中的 [coalesce](https://duckdb.org/docs/sql/functions/utility.html) 函数
    — 它返回第一个计算结果为非NULL值的表达式，以结合类似类型的睡眠阶段。
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: With DuckDB I can query with [json_extract](https://duckdb.org/docs/extensions/json.html#json-extraction-functions)
    to extract the duration stages from the nested JSON to generate a *sleep_log_df*
    dataframe with all of the historic sleep stages grouped.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 使用DuckDB，我可以通过 [json_extract](https://duckdb.org/docs/extensions/json.html#json-extraction-functions)
    提取嵌套JSON中的时长阶段，以生成一个 *sleep_log_df* 数据框，将所有历史睡眠阶段进行分组。
- en: Plot sleep activity
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 绘制睡眠活动图
- en: We can not take the daily sleep logs and produce a stacked bar plot showing
    the breakdown each night of being awake and in light, deep and [REM](https://en.wikipedia.org/wiki/Rapid_eye_movement_sleep)
    sleep.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将每日睡眠日志制作成堆叠条形图，显示每晚清醒、浅睡、深睡和 [REM](https://en.wikipedia.org/wiki/Rapid_eye_movement_sleep)
    睡眠的分类。
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Loading a month of sleep data allows me to create a broader analysis of sleep
    duration.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 加载一个月的睡眠数据让我能够进行更广泛的睡眠时长分析。
- en: '![](../Images/3e9cfbb697bb69a1449463626e94ab1e.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e9cfbb697bb69a1449463626e94ab1e.png)'
- en: Sleep cycle duration each night — Screenshot by the author.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 每晚的睡眠周期时长 — 作者截图。
- en: The ability to graph multiple nights of sleep together on a single plot allows
    me to start understanding how days of the week and cyclic events affects the duration
    and quality of my sleep.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 将多晚的睡眠数据绘制在一个图表上，使我能够开始理解星期几和周期性事件如何影响我的睡眠时长和质量。
- en: Heart rate
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 心率
- en: Heart rate is captured very frequently (every 10–15 seconds) in files stored
    daily named like `Physical Activity/heart_rate-2023-01-26.json`. These files are
    really big — each day has around 70,000 lines — all wrapped in a single array.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 心率数据被非常频繁地捕捉（每`10–15秒`一次），存储在名为`Physical Activity/heart_rate-2023-01-26.json`的每日文件中。这些文件非常大
    — 每天约有70,000行 — 所有数据都包装在一个数组中。
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: My theory here is the file name represents the locale of the user. For example,
    in my timezone (GMT+11) named `heart_rate-2023-01-26.json` the data covers the
    day 26 00:00 (AEST) to 23:59 (AEST) - and it makes logical sense if the dates
    within the files are in GMT.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我的理论是文件名表示用户的时区。例如，在我的时区（GMT+11），命名为`heart_rate-2023-01-26.json`的数据覆盖了26日00:00（AEST）至23:59（AEST）
    - 如果文件中的日期为GMT，则逻辑上是合理的。
- en: Transform JSON files
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转换JSON文件
- en: Up to now I’ve managed to process my Fitbit data as-is with included DuckDB
    functions. However, I hit a problem when trying to process these enormous heart
    rate files. DuckDB gave me this error when trying to process a large array of
    records in a JSON files
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我已经成功处理了包含 DuckDB 函数的 Fitbit 数据。然而，在处理这些巨大的心率文件时，我遇到了问题。当尝试处理 JSON 文件中的大数组记录时，DuckDB
    给出了这个错误。
- en: '**(duckdb.InvalidInputException) “INTERNAL Error: Unexpected yyjson tag in
    ValTypeToString”**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**(duckdb.InvalidInputException) “INTERNAL Error: Unexpected yyjson tag in
    ValTypeToString”**'
- en: I think this error message is an abrupt way of telling me it’s unreasonable
    to expect a JSON array to have so many elements. The fix was to pre-process the
    file so it wasn’t an array of JSON records, instead converted to newline-delimited
    JSON, or [ndjson](http://ndjson.org/).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这个错误信息是一个突如其来的提醒，告诉我期望一个 JSON 数组有这么多元素是不合理的。解决办法是预处理文件，使其不是 JSON 记录数组，而是转换为换行符分隔的
    JSON 或 [ndjson](http://ndjson.org/)。
- en: '[PRE10]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: To transform heart rate array_of_records into newline-delimited JSON I used
    a sneaky bit of Python to convert each file.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将心率数组记录转换为换行符分隔的 JSON，我使用了一点小巧的 Python 代码来转换每个文件。
- en: '[PRE11]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This will find each *.json* file, read converting the contents into newline-delimited
    JSON with a new file created with the file extension *.ndjson*. This converts
    an array with 70,000 records to a file with 70,000 lines — with each JSON record
    now stored on a new line.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这将查找每个 *.json* 文件，读取内容并将其转换为换行符分隔的 JSON，并用 *.ndjson* 文件扩展名创建新文件。这将一个包含70,000条记录的数组转换为一个包含70,000行的文件——每条
    JSON 记录现在存储在新的一行上。
- en: Load heart rate data into table
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将心率数据加载到表中
- en: With the newly converted *ndjson* files, I’m now ready to load heart rate data
    into a DuckDB table. Note the use of `timestampformat='%m/%d/%y %H:%M:%S');` to
    describe the leading month in the dates (for example *"01/25/23 13:00:07"*)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用新转换的 *ndjson* 文件，我现在准备将心率数据加载到 DuckDB 表中。注意使用 `timestampformat='%m/%d/%y %H:%M:%S');`
    来描述日期中的前导月份（例如 *"01/25/23 13:00:07"*)
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We can load all the .ndjson files by setting the format to ’newline_delimited’.
    Note we can extract the BPM (beats per minute) with the JSON extraction and cast
    into an integer.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将格式设置为 ’newline_delimited’ 来加载所有 .ndjson 文件。注意我们可以通过 JSON 提取来提取 BPM（每分钟心跳次数）并将其转换为整数。
- en: '![](../Images/3085503bcdcd2945270d26a383b88a08.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3085503bcdcd2945270d26a383b88a08.png)'
- en: DuckDB is blazing fast at processing JSON- Screenshot by the author.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: DuckDB 在处理 JSON 时非常快速 — 作者截图。
- en: It’s worth highlighting here how insanely fast DuckDB is — it took only 2.8
    seconds to load 12 million records!
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 值得在这里强调 DuckDB 的速度是多么惊人——加载 1200 万条记录仅用了 2.8 秒！
- en: Load heart rate into data frame
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将心率加载到数据框中
- en: With 12 million hear rate measurements loaded, let’s load a single days worth
    of data into a data frame for the 21st of May.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在加载了 1200 万条心率测量记录后，我们将 5 月 21 日的一天数据加载到数据框中。
- en: '[PRE13]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This DuckDB query aggregates the variability of heart rate into time bucks of
    1 minute; banding into min, average and maximum within each period.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 DuckDB 查询将心率的变异性聚合到 1 分钟的时间块中；在每个周期内进行最小值、平均值和最大值的分类。
- en: Plot Heart rate
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 绘制心率图
- en: I can plat the heart rate using a plot like this (and also to show off I actually
    did go for a run at 6am)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以使用这样的图来绘制心率（顺便炫耀一下，我确实在早上 6 点去跑步了）
- en: '[PRE14]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/9962db0f04ea299fd471bc8b221b5da7.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9962db0f04ea299fd471bc8b221b5da7.png)'
- en: Heart rate over a day — Screenshot by the author.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 一天中的心率 — 作者截图。
- en: Exploring heart rate with fine granularity allows me to track my fitness goals
    — especially if I stick with my regular running routine.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 以细粒度探索心率使我能够跟踪我的健身目标——特别是如果我坚持我的常规跑步计划。
- en: Steps
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤
- en: Steps are recorded in daily files named `Physical Activity/steps-2023-02-26.json`.
    This appears to be a fine grain count of steps during period blocks (every 5 to
    10 minutes) throughout the day
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤记录在名为 `Physical Activity/steps-2023-02-26.json` 的每日文件中。这似乎是对一天中每个时间段块（每 5
    到 10 分钟）内的步骤的详细计数。
- en: '[PRE15]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: To aggregate the steps into daily counts I needed to convert GMT into my local
    timezone (GMT+11)
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将步骤聚合为每日统计，我需要将 GMT 转换为我的本地时区（GMT+11）。
- en: '[PRE16]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Aggregating the number of daily steps into the *steps_df* dataframe allows me
    to explore the longer term activity trends as I attempt to exceed 10,000 steps
    to realise the [increased health benefits](https://www.10000steps.org.au/articles/healthy-lifestyles/health-check-do-we-really-need-take-10000-steps-day/).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 将每日步骤聚合到 *steps_df* 数据框中，使我能够探索长期的活动趋势，因为我努力超越 10,000 步以实现[健康益处的提升](https://www.10000steps.org.au/articles/healthy-lifestyles/health-check-do-we-really-need-take-10000-steps-day/)。
- en: Plot daily steps
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 绘制每日步骤
- en: We can now take dataframe and plot a daily step count
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将数据框绘制为每日步数
- en: '[PRE17]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](../Images/8a95077d4b6046f60e34eef75c8ff1de.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8a95077d4b6046f60e34eef75c8ff1de.png)'
- en: Daily step count — Screenshot by the author.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 每日步数统计——作者截图。
- en: Which shows I’ve still got to work at my daily step goal — another strike against
    my new years fitness resolution.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示我还需要努力达到我的每日步数目标——这对我的新年健身决心来说又是一次打击。
- en: GPS Mapping
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPS 映射
- en: Fitbit stores GPS logged activities as [TCX (Training Center XML)](https://en.wikipedia.org/wiki/GPS_Exchange_Format)
    files. These XML files are *not* in the downloaded ZIP, but we have a reference
    to their location in the Physical Activity files, which I can query like this.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Fitbit 将 GPS 记录的活动存储为[TCX (训练中心 XML)](https://en.wikipedia.org/wiki/GPS_Exchange_Format)
    文件。这些 XML 文件在下载的 ZIP 文件中*没有*，但我们在身体活动文件中有其位置的参考，我可以像这样查询。
- en: '[PRE18]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The tcxLink field is a URL reference to their location in the Physical Activity
    files.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: tcxLink 字段是对身体活动文件中位置的 URL 参考。
- en: '![](../Images/6037d84f1ca242c03cced5f82d2e7f4f.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6037d84f1ca242c03cced5f82d2e7f4f.png)'
- en: The URL for each TCX file — Screenshot by the author.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 TCX 文件的 URL——作者截图。
- en: We can use this URL directly in a browser (once logged onto the Fitbit website)
    to do download the GPS XML file. Looking inside the TCX file, we find low level
    GPS locations every few seconds.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以直接在浏览器中使用这个 URL（登录 Fitbit 网站后）来下载 GPS XML 文件。查看 TCX 文件内部，我们会发现每隔几秒钟就有低级别的
    GPS 位置数据。
- en: '![](../Images/c850bc9f8b7d837fb45767fd1fa6780c.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c850bc9f8b7d837fb45767fd1fa6780c.png)'
- en: TCX GPS XML file sample contentents - Screenshot by the author.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: TCX GPS XML 文件样本内容——作者截图。
- en: The good news is this has some obvious fields like latitude, longitude and time.
    The not so good news is this is XML, so we need to pre-process these files prior
    to loading into DuckDB as presently XML isn’t supported by the file reader. We
    can convert XML files into JSON files with another bit of Python code, looping
    over each *.tcx* file.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是数据中有一些明显的字段，如纬度、经度和时间。不太好的消息是数据是 XML 格式的，因此我们需要在加载到 DuckDB 之前预处理这些文件，因为目前
    XML 格式不被文件读取器支持。我们可以通过另一段 Python 代码将 XML 文件转换为 JSON 文件，循环遍历每个 *.tcx* 文件。
- en: There is a bit of nasty XML nesting going on here, with the location data found
    under *TrainingCenterDatabase/Activities/Activity/Lap*.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些复杂的 XML 嵌套，位置数据位于 *TrainingCenterDatabase/Activities/Activity/Lap* 下。
- en: '[PRE19]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Loading GPS Geospatial data
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载 GPS 地理空间数据
- en: We can load the Geospatial data like this
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以这样加载地理空间数据
- en: '[PRE20]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This DuckDB query flattens the JSON, converts the latitude, longitude and time
    into the correct data types and loads into the *route_df* dataframe.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 DuckDB 查询扁平化了 JSON，将纬度、经度和时间转换为正确的数据类型，并加载到 *route_df* 数据框中。
- en: Visualize GPS Routes with Folium
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Folium 可视化 GPS 路线
- en: Having a table of location information isn’t very descriptive, so I wanted to
    start plotting my running routes on an interactive map. I used this blog to help
    [Visualize routes with Folium](https://betterdatascience.com/data-science-for-cycling-how-to-visualize-gpx-strava-routes-with-python-and-folium/).
    Modifying the code helped me plot my own runs, for example this is a plot of a
    recent run while on holiday in [Canberra](https://en.wikipedia.org/wiki/Canberra).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一个位置信息的表格并不够直观，因此我想开始在交互式地图上绘制我的跑步路线。我使用了这篇博客来帮助[使用 Folium 可视化路线](https://betterdatascience.com/data-science-for-cycling-how-to-visualize-gpx-strava-routes-with-python-and-folium/)。修改代码帮助我绘制了自己的跑步路线，例如这是我在[堪培拉](https://en.wikipedia.org/wiki/Canberra)度假时的一次跑步路线图。
- en: '[PRE21]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![](../Images/9d1e52b607975ce6d097d1cb3e5b5d7f.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9d1e52b607975ce6d097d1cb3e5b5d7f.png)'
- en: Folium map plot of a run — Screenshot by the author.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 跑步的 Folium 地图图示——作者截图。
- en: Which generates a plot of my run using [open street map](https://openmaptiles.org/)
    tiles, giving me a great interactive detailed map of my run.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这生成了一个使用[开放街图](https://openmaptiles.org/) 瓦片的跑步图，给我提供了一个很好的交互式详细跑步地图。
- en: Data goals and fitness goal summary
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据目标和健身目标总结
- en: Did I get get closer to my goal of analysis my Fitbit device data — absolutely!
    DuckDB proved to be an ideal flexible lightweight analytical tool for wrangling
    my extensive and chaotic Fitbit data achieve. Blazing through literally millions
    of records in seconds with the extensive SQL support and flexible file parsing
    options locally into dataframes makes DuckDB ideal for building my own personal
    data warehouse.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我是否更接近分析我的 Fitbit 设备数据的目标——绝对是的！DuckDB 证明是一个理想的灵活轻量级分析工具，能够快速处理我的大量混乱的 Fitbit
    数据。通过广泛的 SQL 支持和灵活的文件解析选项，DuckDB 能够在几秒钟内处理数百万条记录，将数据本地导入数据框，这使得 DuckDB 成为构建个人数据仓库的理想选择。
- en: As for my fitness goal — I have some work to do. I think I should leave this
    blog now as I’m short of my step goal target for today
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: Code
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 🛠️Code for Fitbit activity analysis with DuckDB — [https://github.com/saubury/duckdb-fitbit](https://github.com/saubury/duckdb-fitbit)
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
