- en: 'GPT-4 vs. ChatGPT: An exploration of training, performance, capabilities, and
    limitations'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/gpt-4-vs-chatgpt-an-exploration-of-training-performance-capabilities-and-limitations-35c990c133c5?source=collection_archive---------0-----------------------#2023-03-17](https://towardsdatascience.com/gpt-4-vs-chatgpt-an-exploration-of-training-performance-capabilities-and-limitations-35c990c133c5?source=collection_archive---------0-----------------------#2023-03-17)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: GPT-4 is an improvement, but temper your expectations.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@mary.newhauser?source=post_page-----35c990c133c5--------------------------------)[![Mary
    Newhauser](../Images/7f0d7287f7b735bb9391858f1fc641ee.png)](https://medium.com/@mary.newhauser?source=post_page-----35c990c133c5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----35c990c133c5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----35c990c133c5--------------------------------)
    [Mary Newhauser](https://medium.com/@mary.newhauser?source=post_page-----35c990c133c5--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6b27bdb820b9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgpt-4-vs-chatgpt-an-exploration-of-training-performance-capabilities-and-limitations-35c990c133c5&user=Mary+Newhauser&userId=6b27bdb820b9&source=post_page-6b27bdb820b9----35c990c133c5---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----35c990c133c5--------------------------------)
    ·7 min read·Mar 17, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F35c990c133c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgpt-4-vs-chatgpt-an-exploration-of-training-performance-capabilities-and-limitations-35c990c133c5&user=Mary+Newhauser&userId=6b27bdb820b9&source=-----35c990c133c5---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35c990c133c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgpt-4-vs-chatgpt-an-exploration-of-training-performance-capabilities-and-limitations-35c990c133c5&source=-----35c990c133c5---------------------bookmark_footer-----------)![](../Images/8ebc0c71e1eaa32026c30fe54eb8b0d9.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI stunned the world when it dropped [ChatGPT](https://openai.com/blog/chatgpt)
    in late 2022\. The new generative language model is expected to totally transform
    entire industries, including media, education, law, and tech. In short, ChatGPT
    threatens to disrupt just about everything. And even before we had time to truly
    envision a post-ChatGPT world, OpenAI dropped [GPT-4](https://openai.com/research/gpt-4).
  prefs: []
  type: TYPE_NORMAL
- en: In recent months, the speed with which groundbreaking large language models
    have been released is astonishing. If you still don’t understand how ChatGPT differs
    from GPT-3, let alone GPT-4, I don’t blame you.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we will cover the key similarities and differences between
    ChatGPT and GPT-4, including their training methods, performance and capabilities,
    and limitations.
  prefs: []
  type: TYPE_NORMAL
- en: 'ChatGPT vs. GPT-4: Similarities & differences in training methods'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ChatGPT and GPT-4 both stand on the shoulders of giants, building on previous
    versions of GPT models while adding improvements to model architecture, employing
    more sophisticated training methods, and increasing the number of training parameters.
  prefs: []
  type: TYPE_NORMAL
