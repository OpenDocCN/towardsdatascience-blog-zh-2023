- en: Data Quality Issues that Kill Your Machine Learning Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/data-quality-issues-that-kill-your-machine-learning-models-961591340b40?source=collection_archive---------4-----------------------#2023-01-19](https://towardsdatascience.com/data-quality-issues-that-kill-your-machine-learning-models-961591340b40?source=collection_archive---------4-----------------------#2023-01-19)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Data Quality Chronicles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Navigating the complexity of imperfect data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@miriam.santos?source=post_page-----961591340b40--------------------------------)[![Miriam
    Santos](../Images/decbc6528a641e7b02934a03e136284a.png)](https://medium.com/@miriam.santos?source=post_page-----961591340b40--------------------------------)[](https://towardsdatascience.com/?source=post_page-----961591340b40--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----961591340b40--------------------------------)
    [Miriam Santos](https://medium.com/@miriam.santos?source=post_page-----961591340b40--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F243289394aaa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-quality-issues-that-kill-your-machine-learning-models-961591340b40&user=Miriam+Santos&userId=243289394aaa&source=post_page-243289394aaa----961591340b40---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----961591340b40--------------------------------)
    ·8 min read·Jan 19, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F961591340b40&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-quality-issues-that-kill-your-machine-learning-models-961591340b40&user=Miriam+Santos&userId=243289394aaa&source=-----961591340b40---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F961591340b40&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-quality-issues-that-kill-your-machine-learning-models-961591340b40&source=-----961591340b40---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: '*This is a column series that focuses on data quality for data science. This
    constitutes the first piece and focuses on Imbalanced Data, Underrepresented Data,
    and Overlapped Data.*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/896d0664fdf1aa1b80791ac60098ce60.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Sergey Sokolov](https://unsplash.com/@svsokolov?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: G***arbage in, garbage out.* That is the curse of learning from data.** In this
    piece, I’ll go over the importance of feeding high-quality data to your machine
    learning models and introduce you to killer data quality issues that, if left
    unchecked, may utterly compromise your data science projects.
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning has become a ubiquitous tool in real world domains
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*From social to medical applications, machine learning has become deeply entangled
    in our daily lives.*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/814ff3e3227790515834a98cb67e8b35.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Machine Learning in the wild: with great power, comes great responsibility.
    A reference to the “Coded Gaze” of Facial Recognition Technology and the work
    developed by Joy Buolamwini on the [Algorithmic Justice League](https://www.ajl.org/library/multimedia).
    Photo by [engin akyurt](https://unsplash.com/@enginakyurt?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)'
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps you woke up today at 7:45am because an algorithm has been analyzing
    your sleep patterns and determined that that was the best time for you to start
    your day without feeling drowsy. Then, you may have driven to work through a route
    that was recommended by another algorithm, so that you can avoid traffic.
  prefs: []
  type: TYPE_NORMAL
- en: When you opened your laptop, your email was already sorted into these so-called
    “smart” folders and the spam was automatically filtered (by yet another algorithm!)
    so that you may focus only on the messages that matter.
  prefs: []
  type: TYPE_NORMAL
- en: And at the end of this very long day, maybe you have a blind date with someone
    whose profile has hand-picked (well, *script-picked?*) for you among thousands
    of possibilities. Again, by another algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: '*When technology becomes so pervasive as machine learning currently is, we
    would be wise to* ***zero in on these models and the way they learn****, because
    although AI has a* ***great potential to serve society****, it also has a* ***great
    power for destruction and inequality****.*'
  prefs: []
  type: TYPE_NORMAL
- en: And why is that?
  prefs: []
  type: TYPE_NORMAL
- en: 'Imperfect Data: Scavenging a World of Imperfection'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*The reason is that* ***algorithms learn from what we teach them****.*'
  prefs: []
  type: TYPE_NORMAL
- en: They learn from the data we feed them and they expect that data to be “well-behaved”
    in what concerns several of its properties.
  prefs: []
  type: TYPE_NORMAL
- en: '**Ideally, that would be the case. But our world is imperfect, we are imperfect,
    and the data we generate naturally carries out those imperfections.**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Data* (or *Big Data*, a word we’ve been hearing more than often over the past
    years) is not the same as *Quality Data,* and mistaking these two may lead to
    the development of **biased and unfair models**, rather than **accurate and reliable
    models**.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dea06f1d39e853d6a474cd5381e72cc7.png)'
  prefs: []
  type: TYPE_IMG
- en: Data versus Quality Data. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: '**Traditionally, machine learning algorithms *rely on a few assumptions* regarding
    the training data, such as:**'
  prefs: []
  type: TYPE_NORMAL
- en: Existing classes are equally represented;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Existing sub-concepts in data are also equally represented;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instances from different classes occupy different regions of the input space;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is a sufficiently large number of training instances to learn the underlying
    concepts in data;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature values are consistent and instances are correctly labeled;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Features are informative and relevant for the end task;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training and test data follow the same distribution;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All feature values are available for all instances.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Naturally, in real-world domains, imperfection is always lurking and these
    *assumptions are most often broken* than not.**'
  prefs: []
  type: TYPE_NORMAL
- en: 'When they are broken, they arise as *data imperfections*, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: Imbalanced Data;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Underrepresented Data or Small Disjuncts;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Class Overlap;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Small Data, Lack of Density, or Lack of Data;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inconsistent Data;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Irrelevant Data;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Redundant Data;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Noisy Data;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset Shift;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Missing Data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If left untreated, these imperfections may jeopardize the performance of standard
    machine learning models with nefarious consequences for business applications
    and people’s lives.
  prefs: []
  type: TYPE_NORMAL
- en: An erroneous alert of credit card fraud that lead to the loss of a critical
    investment. A failed tumor detection that transformed into the hard choice between
    a painful course of treatment or an end-of-life decision. A misjudgment between
    individuals with similar face structures that mistakenly sentences one to face
    the law and sets the other one free.
  prefs: []
  type: TYPE_NORMAL
- en: '**Imperfection may cost us our money, freedom, and lives.**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Before I go on details regarding these data imperfections, I’d like to clarify
    the concept of ***Imperfect Data***.
  prefs: []
  type: TYPE_NORMAL
- en: In [my own research](https://scholar.google.com/citations?user=isaI6u8AAAAJ&hl=en),
    I have used this word as an umbrella term to describe *any data properties, idiosyncrasies*,
    or issues that are prone to bias the behavior and performance of classifiers (other
    authors describe them as *data intrinsic characteristics*, *data difficulty factors*,
    or *data irregularities*).
  prefs: []
  type: TYPE_NORMAL
- en: This means that certain “imperfections” are not to be taken in the literal sense
    of the word (which could translate to *defective data* to some extent).
  prefs: []
  type: TYPE_NORMAL
- en: Certainly, **some imperfections may arise due to errors in the data acquisition,
    transmission, and collection processes, but others are a natural product of the
    intrinsic nature of the domains.** They arise naturally, irrespectively of how
    flawless the process of data acquisition, transmission, or collection may be.
  prefs: []
  type: TYPE_NORMAL
- en: The 3 data imperfections covered here — *Imbalanced Data, Underrepresented Data,
    and Ovelapped Data* — are a fantastic example of this. They most often result
    from the nature of the domain itself rather than from any mistakes made during
    data collection or storage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Imbalanced Data: Uneven Concepts, Unequal Predictions'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Imbalanced Data generally refers to a disproportion of the number of examples
    of each class in a dataset**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In other words, classes are not equally represented in the domain, which biases
    the learning process of classifiers towards well-represented concepts, causing
    them to potentially overlook or disregard the remaining. This is problematic since
    in most applications the minority class is usually the class of interest.
  prefs: []
  type: TYPE_NORMAL
- en: '**And where do we find it?**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Well, some examples are [*disease diagnosis*](https://dl.acm.org/doi/10.1145/2988544),
    [*credit card fraud*](https://keras.io/examples/structured_data/imbalanced_classification/),
    [*sentiment analysis*](https://ieeexplore.ieee.org/abstract/document/8923218),
    and [*churn prediction*](https://www.youtube.com/watch?v=S9iuwZxNdCk).
  prefs: []
  type: TYPE_NORMAL
- en: '**An interesting twist: Class imbalance *per se* may not be the issue!**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Indeed, even in the presence of a highly imbalanced domain, a standard classifier
    might be able to obtain satisfying results *if the classification problem is of
    low complexity* (e.g., consider a linearly separable domain, for instance).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ecbde41f8bfd2acf22bfbcbb6f5e8654.png)'
  prefs: []
  type: TYPE_IMG
- en: Imbalanced Data in isolation versus combined with class overlap. Both domains
    contain the same number of points (500) and imbalance ratio (8:1). Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, although class imbalance may be easy to overcome in isolation,
    it should always be taken into account when training machine learning models,
    especially in what concerns the [design of appropriate cross-validation approaches](https://ieeexplore.ieee.org/abstract/document/8492368)
    and the choice of unbiased classification [performance measures](https://dl.acm.org/doi/abs/10.1145/2907070).
  prefs: []
  type: TYPE_NORMAL
- en: 'Underrepresented Data: The problem of Small Disjuncts'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Underrepresented data is another form of imbalanced data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Whereas in the previous case we were referring to *between-class* imbalance,
    underrepresented data is associated with a *within-class* imbalance phenomena
    and arises in the form of *small disjuncts*.
  prefs: []
  type: TYPE_NORMAL
- en: Small disjuncts are small, underrepresented sub-concepts in data, understood
    as small clusters within a class concept.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7e1f3bac485a5c6ddddef798081efc22.png)'
  prefs: []
  type: TYPE_IMG
- en: Underrepresented Data is characterised by the appearance of small sub-clusters
    in data. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly to *between-class* imbalance, small disjuncts are problematic because
    classifiers often learn by generating rules for well-represented concepts, i.e.,
    *larger disjuncts*. Thus, they become susceptible to overfit these sub-concepts,
    which leads to a poor classification performance for new examples.
  prefs: []
  type: TYPE_NORMAL
- en: '**And where to find them?**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The appearance of *small disjuncts* is very common in [healthcare data](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8611905/),
    due to the heterogeneity of some diseases (such as cancer) and the biological
    diversity among patients. Other examples are [facial and emotional recognition](https://link.springer.com/chapter/10.1007/978-3-662-48558-3_18).
  prefs: []
  type: TYPE_NORMAL
- en: A current open challenge in research nowadays is distinguishing between *core
    concepts* (even if appearing as clusters in the data space), *underrepresented
    sub-concepts or small disjuncts*, and *noisy instances*. This is not a trivial
    issue per se, and it becomes more complicated if other problems are present in
    data (and they usually are).
  prefs: []
  type: TYPE_NORMAL
- en: 'Class Overlap: Get out of my (input) space!'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Class overlap occurs when instances from different classes coexist in the same
    region of the data space
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As representatives of different concepts populate the same regions, machine
    learning classifiers have a hard time discriminating them, which leads to poor
    classification performance (especially affecting the less represented concepts
    in those regions).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0d188a7697f523cc8ff47dedf9e8c080.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Typical examples of class overlap: domains have an increasing amount of overlapping
    examples. Image by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: Over the years, researchers have been approaching this issue either by *learning
    solely from non-overlapped regions* (somewhat neglecting the problem), *treating
    the overlapped data as a new class*, or *building separate classifiers* for overlapped
    and non-overlapped regions.
  prefs: []
  type: TYPE_NORMAL
- en: Other authors try to distinguish between examples scattered throughout the entire
    input space and those that concentrate on the decision boundaries between concepts,
    applying tailored strategies to handle each type differently.
  prefs: []
  type: TYPE_NORMAL
- en: Current research is now shifting towards the idea that **class overlap is an
    heterogeneous concept, comprising multiple sources of complexity**. In preliminary
    work, I’ve particularly distinguished it between 4 main overlap representations,
    dividing it into Feature Overlap, Instance Overlap, Structural Overlap, and Multiresolution
    Overlap, each associated with distinct complexity concepts.
  prefs: []
  type: TYPE_NORMAL
- en: '**And where do we find it?**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: From [character recognition](https://link.springer.com/article/10.1007/s10032-008-0069-1),
    [software defect prediction](https://link.springer.com/article/10.1007/s11219-016-9342-6),
    and [protein and drug discovery](https://pubmed.ncbi.nlm.nih.gov/30195659/), class
    overlap is also a common data characteristic found in real-world domains.
  prefs: []
  type: TYPE_NORMAL
- en: 'Final Thoughts: Where do we go from here?'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Whereas the past decades in AI research have been dedicated to producing better
    models — a paradigm we have been calling *Model-Centric AI* — current focus has
    been shifting from model optimization and hyper parameter tuning to systematic
    identification and mitigation of data quality issues — a paradigm recently coined
    as *Data-Centric AI*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d621d07badb9e4703f3a8a6fd400b65e.png)'
  prefs: []
  type: TYPE_IMG
- en: In the “AI Tower of Babel” we currently live in, truly understanding data and
    pointing to what matters will prove more transformative than having huge amounts
    of “information”. This **pointing to** is the basis of the new Data-Centric AI
    paradigm. Photo by [Killian Cartignies](https://unsplash.com/@kikisad?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: This new approach comprehends a systematic and continuous cycle of iterations
    over the data, moving from *imperfect* to *smart and actionable* data. That naturally
    requires a deep understanding of data imperfections, their identification and
    characterization, as well as their combined effects and efficient mitigation strategies.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *Data Quality Chronicles Series* introduces the topic of data quality for
    data science, starting with 3 common data quality issues found in real-world domains:
    *Imbalanced Data*, *Underrepresented Data*, and *Overlapped Data*. The following
    parts of the series will be dedicated to characterizing other data quality issues,
    deep-diving into each one, and introducing the reader to efficient tools and strategies
    to effectively identify and measure them when handling real-world datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: About me
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ph.D., Machine Learning Researcher, Educator, Data Advocate, and overall “jack-of-all-trades”.
    Here on Medium, I write about **Data-Centric AI and Data Quality**, educating
    the Data Science & Machine Learning communities on how to move from *imperfect*
    to *intelligent* data.
  prefs: []
  type: TYPE_NORMAL
- en: '[Data-Centric AI Community](https://tiny.ydata.ai/dcai-medium) | [GitHub](https://github.com/Data-Centric-AI-Community)
    | [Google Scholar](https://scholar.google.com/citations?user=isaI6u8AAAAJ&hl=en)
    | [LinkedIn](https://www.linkedin.com/in/miriamseoanesantos/)'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'B. Krawczyk, [Learning from Imbalanced Data: Open Challenges and Future Directions](https://link.springer.com/article/10.1007/s13748-016-0094-0)
    (2016), *Progress in Artificial Intelligence*, 5(4), 221–232.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'S. Das, S. Datta, B. Chaudhuri, [Handling data irregularities in classification:
    Foundations, trends, and future challenges](https://www.sciencedirect.com/science/article/abs/pii/S0031320318300931)
    (2018), *Pattern Recognition* 81, 674–693.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. Fernández, S. García, M. Galar, M., R. Prati, B. Krawczyk, F. Herrera, [*Data
    Intrinsic Characteristics*](https://www.springerprofessional.de/en/data-intrinsic-characteristics/16217922)(2018),
    Springer International Publishing. pp. 253–277.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'I. Triguero, D. García-Gil, J. Maillo, J. Luengo, S. García, F. Herrera, [Transforming
    big data into smart data: An insight on the use of the k-nearest neighbors algorithm
    to obtain quality data](https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/widm.1289)
    (2019), Wiley Interdisciplinary Reviews: *Data Mining and Knowledge Discovery*
    9, e1289.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'M. Santos, P. Abreu, N. Japkowicz, A. Fernández, J. Santos, [A Unifying View
    of Class Overlap and Imbalance: Key concepts, multi-view panorama, and open avenues
    for research](https://www.sciencedirect.com/science/article/pii/S1566253522001099)
    (2023), *Information Fusion* 89, 228–253.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
