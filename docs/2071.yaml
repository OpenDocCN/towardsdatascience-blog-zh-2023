- en: 'Pandas 2.0: A Game-Changer for Data Scientists?'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/pandas-2-0-a-game-changer-for-data-scientists-3cd281fcc4b4?source=collection_archive---------0-----------------------#2023-06-27](https://towardsdatascience.com/pandas-2-0-a-game-changer-for-data-scientists-3cd281fcc4b4?source=collection_archive---------0-----------------------#2023-06-27)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The Top 5 Features for Efficient Data Manipulation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@miriam.santos?source=post_page-----3cd281fcc4b4--------------------------------)[![Miriam
    Santos](../Images/decbc6528a641e7b02934a03e136284a.png)](https://medium.com/@miriam.santos?source=post_page-----3cd281fcc4b4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3cd281fcc4b4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3cd281fcc4b4--------------------------------)
    [Miriam Santos](https://medium.com/@miriam.santos?source=post_page-----3cd281fcc4b4--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F243289394aaa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpandas-2-0-a-game-changer-for-data-scientists-3cd281fcc4b4&user=Miriam+Santos&userId=243289394aaa&source=post_page-243289394aaa----3cd281fcc4b4---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3cd281fcc4b4--------------------------------)
    ·7 min read·Jun 27, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3cd281fcc4b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpandas-2-0-a-game-changer-for-data-scientists-3cd281fcc4b4&user=Miriam+Santos&userId=243289394aaa&source=-----3cd281fcc4b4---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3cd281fcc4b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpandas-2-0-a-game-changer-for-data-scientists-3cd281fcc4b4&source=-----3cd281fcc4b4---------------------bookmark_footer-----------)![](../Images/7969af49055231191e3ed95318f9168d.png)'
  prefs: []
  type: TYPE_NORMAL
- en: This April, [pandas 2.0.0 was officially launched](https://github.com/pandas-dev/pandas/releases/tag/v2.0.0),
    making huge waves across the data science community. Photo by [Yancy Min](https://unsplash.com/@yancymin?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral).
  prefs: []
  type: TYPE_NORMAL
- en: '**Due to its extensive functionality and versatility,** `pandas` **has secured
    a place in every data scientist’s heart.**'
  prefs: []
  type: TYPE_NORMAL
- en: From data input/output to data cleaning and transformation, it’s nearly impossible
    to think about data manipulation without `import pandas as pd`, *right*?
  prefs: []
  type: TYPE_NORMAL
- en: '*Now, bear with me:* with such a buzz around LLMs over the past months, I have
    somehow let slide the fact that `pandas` has just undergone a major release! Yep,
    `pandas 2.0` [is out and came with guns blazing](https://pandas.pydata.org/docs/dev/whatsnew/v2.0.0.html)!'
  prefs: []
  type: TYPE_NORMAL
- en: 'Although I wasn’t aware of all the hype, the [Data-Centric AI Community](https://tiny.ydata.ai/dcai-medium)
    promptly came to the rescue:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fb154dd1a6cf10801128616a7b33ecea.png)'
  prefs: []
  type: TYPE_IMG
- en: The 2.0 release seems to have created quite an impact in the data science community,
    with a lot of users praising the modifications added in the new version. Screenshot
    by Author.
  prefs: []
  type: TYPE_NORMAL
- en: '**Fun fact:** *Were you aware this release was in the making for an astonishing
    3 years? Now that’s what I call “commitment to the community”!*'
  prefs: []
  type: TYPE_NORMAL
- en: '*So what does* `*pandas 2.0*` *bring to the table? Let’s dive right into it!*'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Performance, Speed, and Memory-Efficiency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we all know, `pandas` was built using `numpy`, which was [not intentionally
    designed as a backend](https://datapythonista.me/blog/pandas-20-and-the-arrow-revolution-part-i)
    for dataframe libraries. For that reason, one of the major limitations of `pandas`
    was handling in-memory processing for larger datasets.
  prefs: []
  type: TYPE_NORMAL
- en: '**In this release, the big change comes from the introduction of the** [**Apache
    Arrow**](https://arrow.apache.org) **backend for pandas data.**'
  prefs: []
  type: TYPE_NORMAL
- en: Essentially, Arrow is a standardized in-memory columnar data format with available
    libraries for several programming languages (C, C++, R, Python, among others).
    For Python there is [PyArrow](https://arrow.apache.org/docs/python/), which is
    based on the C++ implementation of Arrow, and therefore, *fast*!
  prefs: []
  type: TYPE_NORMAL
- en: '**So, long story short, PyArrow takes care of our previous memory constraints
    of versions 1.X and allows us to conduct faster and more memory-efficient data
    operations, especially for larger datasets.**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a **comparison between reading the data** without and with the`pyarrow`
    backend, using the [Hacker News](https://www.kaggle.com/datasets/santiagobasulto/all-hacker-news-posts-stories-askshow-hn-polls)
    dataset, which is around 650 MB (License [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)):'
  prefs: []
  type: TYPE_NORMAL
- en: 'Comparison of read_csv(): Using the pyarrow backend is 35X faster. Snippet
    by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, using the new backend makes **reading the data nearly 35x faster.**
    Other aspects worth pointing out:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Without the `pyarrow` backend, each column/feature is stored as its own unique
    data type: **numeric** features are stored as `**int64**` or `**float64**` while
    **string** values are stored as **objects**;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With `pyarrow`, all features are using the Arrow dtypes: note the `[pyarrow]`
    annotation and the different types of data: `int64` , `float64` , `string` , `timestamp`
    , and `double` :'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'df.info(): Investigating the dtypes of each DataFrame. Snippter by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Arrow Data Types and Numpy Indices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Beyond reading data, which is the simplest case, you can **expect additional
    improvements** for a series of other operations, especially [those involving string
    operations](https://medium.com/@santiagobasulto/pandas-2-0-performance-comparison-3f56b4719f58),
    since `pyarrow`’s implementation of the string datatype is quite efficient:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Comparing string operations: showcasing the efficiency of arrow’s implementation.
    Snippet by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, Arrow has more (and better support for) data types than `numpy`, which
    are needed outside the scientific (numerical) scope: **dates and times**, **duration**,
    **binary**, **decimals**, **lists**, and **maps**. Skimming through the [equivalence
    between pyarrow-backed](https://pandas.pydata.org/docs/dev/reference/arrays.html#pyarrow)
    and `numpy` data types might actually be a good exercise in case you want to learn
    how to leverage them.'
  prefs: []
  type: TYPE_NORMAL
- en: '**It is also now possible to hold more numpy numeric types in indices.** The
    traditional `int64`, `uint64`, and `float64` have opened up space for all numpy
    numeric dtypes Index values so we can, for instance, **specify their 32-bit version
    instead:**'
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging 32-bit numpy indices, making the code more memory-efficient. Snippet
    by Author.
  prefs: []
  type: TYPE_NORMAL
- en: This is a welcome change since indices are one of the most used functionalities
    in `pandas`, allowing users to filter, join, and shuffle data, among other data
    operations. **Essentially, the lighter the Index is, the more efficient those
    processes will be!**
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Easier Handling of Missing Values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Being built on top of `numpy` made it hard for `pandas` to handle missing values
    in a hassle-free, flexible way, since `**numpy**` **does not support null values
    for some data types.**
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, **integers are automatically converted to floats**, which is
    not ideal:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Missing Values: Conversion to float. Snippet by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: Note how `points` automatically changes from `int64` to `float64` after the
    introduction of a single`None` value.
  prefs: []
  type: TYPE_NORMAL
- en: '**There is nothing worst for a data flow than wrong typesets**, *especially
    within a data-centric AI paradigm.*'
  prefs: []
  type: TYPE_NORMAL
- en: Erroneous typesets directly impact data preparation decisions, cause incompatibilities
    between different chunks of data, and even when passing silently, they might compromise
    certain operations that output nonsensical results in return.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, at the [Data-Centric AI Community](https://tiny.ydata.ai/dcai-medium),
    we’re currenlty working on a project around [synthetic data for data privacy](https://github.com/Data-Centric-AI-Community/nist-crc-2023).
    One of the features, `NOC` (number of children), has missing values and therefore
    it is automatically converted to `float` when the data is loaded. The, when passing
    the data into a generative model as a `float` , we might get output values as
    decimals such as 2.5 — unless you’re a mathematician with 2 kids, a newborn, and
    a weird sense of humor, *having 2.5 children is not OK.*
  prefs: []
  type: TYPE_NORMAL
- en: '**In pandas 2.0, we can leverage** `dtype = ''numpy_nullable''`**, where missing
    values are accounted for without any dtype changes**, so we can keep our original
    data types (`int64` in this case):'
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging ‘numpy_nullable’, pandas 2.0 can handle missing values without changing
    the original data types. Snippet by Author.
  prefs: []
  type: TYPE_NORMAL
- en: '**It might seem like a subtle change**, but under the hood it means that now
    `pandas` can natively **use Arrow’s implementation of dealing with missing values**.
    This makes operations **much more efficient**, since `pandas` doesn’t have to
    implement its own version for handling null values for each data type.'
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Copy-On-Write Optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Pandas 2.0 also adds a new lazy copy mechanism that defers copying** DataFrames
    and Series objects **until they are modified**.'
  prefs: []
  type: TYPE_NORMAL
- en: This means that [certain methods](https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html#copy-on-write-optimizations)
    will return **views rather than copies** when **copy-on-write is enabled**, which
    improves memory efficiency by minimizing unnecessary data duplication.
  prefs: []
  type: TYPE_NORMAL
- en: '**It also means you need to be extra careful when using chained assignments.**'
  prefs: []
  type: TYPE_NORMAL
- en: If the copy-on-write mode is enabled, **chained assignments will not work**
    because they **point to a temporary object** that is the result of an indexing
    operation (which under copy-on-write behaves as a copy).
  prefs: []
  type: TYPE_NORMAL
- en: 'When `copy_on_write` is **disabled**, operations like slicing [**may change
    the original**](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#why-does-assignment-fail-when-using-chained-indexing)
    `df` if the new dataframe is changed:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Disabled Copy-on-Write: original dataframe is changed in chained assignments.
    Snippet by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When `copy_on_write` is **enabled**, a [copy is created at assignment](https://stackoverflow.com/questions/23296282/what-rules-does-pandas-use-to-generate-a-view-vs-a-copy),
    and therefore the **original dataframe is never changed.** Pandas 2.0 will raise
    a `ChainedAssignmentError` in these situations to avoid silent bugs:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Enabled Copy-on-Write: original dataframe is not changed in chained assignments.
    Snippet by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Optional Dependencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When using `pip`, version 2.0 gives us the flexibility to **install optional
    dependencies**, which is a plus in terms of *customization* and *optimization*
    of resources.
  prefs: []
  type: TYPE_NORMAL
- en: '**We can tailor the installation to our specific requirements, without spending
    disk space on what we don’t really need.**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Plus, it saves a lot of “dependency headaches”, **reducing the likelihood of
    compatibility issues or conflicts** with other packages we may have in our development
    environments:'
  prefs: []
  type: TYPE_NORMAL
- en: Installing optional dependencies. Snippet by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Taking it for a spin!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Yet, the question lingered: is the buzz really justified? I was curious to
    see whether `pandas 2.0` provided significant improvements with respect to some
    packages I use on a daily basis: ydata-profiling, matplotlib, seaborn, scikit-learn.'
  prefs: []
  type: TYPE_NORMAL
- en: '**From those, I decided to take** [**ydata-profiling**](https://github.com/ydataai/ydata-profiling)
    **for a spin—** it has just added support for pandas 2.0, which [seemed like a
    must-have](https://github.com/ydataai/ydata-profiling/issues/1321) for the community!
    In the new release, users can rest to sure that their pipelines won’t break if
    they’re using pandas 2.0, and that’s a major plus! *But what else?*'
  prefs: []
  type: TYPE_NORMAL
- en: Truth be told, ydata-profiling has been one of my top favorite tools for [exploratory
    data analysis](/a-data-scientists-essential-guide-to-exploratory-data-analysis-25637eee0cf6),
    and it’s a nice and quick benchmark too — **a 1-line of code on my side, but under
    the hood it is full of computations that as a data scientist I need to work out**
    — descriptive statistics, histogram plotting, analyzing correlations, *and so
    on.*
  prefs: []
  type: TYPE_NORMAL
- en: So what better way than testing the impact of the `pyarrow` engine on all of
    those at once with minimal effort?
  prefs: []
  type: TYPE_NORMAL
- en: Benchmarking with ydata-profiling. Snippet by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Again, reading the data is definitely better with the `pyarrow` engine, althought
    creating the data profile has not changed significanlty in terms of speed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Yet, differences may rely on memory efficiency, for which we’d have to run
    a different analysis. Also, we could further investigate the type of analysis
    being conducted over the data: for some operations, [the difference between 1.5.2
    and 2.0 versions seems negligible](https://medium.com/@santiagobasulto/pandas-2-0-performance-comparison-3f56b4719f58).'
  prefs: []
  type: TYPE_NORMAL
- en: '**But the main thing I noticed that might make a difference to this regard**
    is that ydata-profiling is not yet leveraging the `pyarrow` data types. This update
    [could have a great impact in both speed and memory](https://twitter.com/rasbt/status/1632090412117532672?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1632334005264580608%7Ctwgr%5E5b02b1e083a5a8172dee5c827232d185e41f54ff%7Ctwcon%5Es3_&ref_url=https%3A%2F%2Fcdn.embedly.com%2Fwidgets%2Fmedia.html%3Ftype%3Dtext2Fhtmlkey%3Da19fcc184b9711e1b4764040d3dc5c07schema%3Dtwitterurl%3Dhttps3A%2F%2Ftwitter.com%2FRitchieVink%2Fstatus%2F1632334005264580608%2Fphoto%2F1image%3Dhttps3A%2F%2Fi.embed.ly%2F1%2Fimage3Furl3Dhttps253A252F252Fabs.twimg.com252Ferrors252Flogo46x38.png26key3Da19fcc184b9711e1b4764040d3dc5c07)
    and is something I look forward in future developments!'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Verdict: Performance, Flexibility, Interoperability!'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This new `pandas 2.0` release brings a lot of flexibility and performance optimization
    with **subtle, yet crucial modifications “under the hood”.**
  prefs: []
  type: TYPE_NORMAL
- en: Maybe they are not “flashy” for newcomers into the field of data manipulation,
    but they sure as hell are like water in the desert for veteran data scientists
    that used to jump through hoops to overcome the limitations of the previous versions.
  prefs: []
  type: TYPE_NORMAL
- en: '**Wrapping it up, these are the top main advantages introduced in the new release:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Performance Optimization:** With the introduction of Apache Arrow backend,
    more numpy dtype indices, and copy-on-write mode;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Added flexibility and customization:** Allowing users to control optional
    dependencies and taking advantage of the Apache Arrow data types (including nullability
    from the get go!);'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Interoperability:** Perhaps a less “acclaimed” advantage of the new version
    but with huge impact. Since Arrow is language-independent, in-memory data can
    be transferred between programs built not only on Python, but also R, Spark, and
    others using Apache Arrow backend!'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*And there you have it, folks!* I hope this wrap up as quieted down some of
    your questions around `pandas 2.0` and its applicability on our data manipulation
    tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: I’m still curious whether you have found major differences in you daily coding
    with the introduction of `pandas 2.0` as well! If you’re up to it, come and find
    me at the [Data-Centric AI Community](https://tiny.ydata.ai/dcai-medium) and let
    me know your thoughts! *See you there?*
  prefs: []
  type: TYPE_NORMAL
- en: About me
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ph.D., Machine Learning Researcher, Educator, Data Advocate, and overall “jack-of-all-trades”.
    Here on Medium, I write about **Data-Centric AI and Data Quality**, educating
    the Data Science & Machine Learning communities on how to move from imperfect
    to intelligent data.
  prefs: []
  type: TYPE_NORMAL
- en: '[Data-Centric AI Community](https://tiny.ydata.ai/dcai-medium) | [GitHub](https://github.com/Data-Centric-AI-Community)
    | [Google Scholar](https://scholar.google.com/citations?user=isaI6u8AAAAJ&hl=en)
    | [LinkedIn](https://www.linkedin.com/in/miriamseoanesantos/)'
  prefs: []
  type: TYPE_NORMAL
