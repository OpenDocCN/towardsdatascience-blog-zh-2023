- en: A Practical Approach to Evaluating Positive-Unlabeled (PU) Classifiers in Business
    Analytics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/a-practical-approach-to-evaluating-positive-unlabeled-pu-classifiers-in-real-world-business-66e074bb192f?source=collection_archive---------4-----------------------#2023-03-31](https://towardsdatascience.com/a-practical-approach-to-evaluating-positive-unlabeled-pu-classifiers-in-real-world-business-66e074bb192f?source=collection_archive---------4-----------------------#2023-03-31)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An approach for evaluating PU models with common classification metrics adjusted
    for the prior probability of the positive class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://wldmrgml.medium.com/?source=post_page-----66e074bb192f--------------------------------)[![Volodymyr
    Holomb](../Images/ff4a34f4dc4ee397d4d30512aa8f177c.png)](https://wldmrgml.medium.com/?source=post_page-----66e074bb192f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----66e074bb192f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----66e074bb192f--------------------------------)
    [Volodymyr Holomb](https://wldmrgml.medium.com/?source=post_page-----66e074bb192f--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F95923fba037b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-practical-approach-to-evaluating-positive-unlabeled-pu-classifiers-in-real-world-business-66e074bb192f&user=Volodymyr+Holomb&userId=95923fba037b&source=post_page-95923fba037b----66e074bb192f---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----66e074bb192f--------------------------------)
    ·4 min read·Mar 31, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F66e074bb192f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-practical-approach-to-evaluating-positive-unlabeled-pu-classifiers-in-real-world-business-66e074bb192f&user=Volodymyr+Holomb&userId=95923fba037b&source=-----66e074bb192f---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F66e074bb192f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-practical-approach-to-evaluating-positive-unlabeled-pu-classifiers-in-real-world-business-66e074bb192f&source=-----66e074bb192f---------------------bookmark_footer-----------)![](../Images/8d6a7407a8e7d7a25b7036830c443aa2.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Made by DALL-E-2 according to the author’s description
  prefs: []
  type: TYPE_NORMAL
- en: As businesses increasingly employ machine learning models on collected data,
    one challenge that arises is the presence of positive-unlabeled (PU) datasets.
    These datasets contain only a small portion of labelled data, with the remaining
    samples being unlabeled. **While unlabeled samples are typically considered negative,
    some of them may be positive**. PU datasets are used in various business contexts,
    such as predicting customer churn or upsell opportunities, sales forecasting,
    and fraud detection.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating machine learning algorithms on PU datasets can be difficult because
    traditional metrics may not accurately reflect the model’s performance. For example,
    simply holding out the positive samples for testing and adding unlabeled entries
    as the negative class can result in a highly skewed confusion matrix inflated
    by false positives. This can occur when the **model detects positive samples in
    the testing set, but their corresponding labels are negative**.
  prefs: []
  type: TYPE_NORMAL
- en: The Practical Approach to Evaluating PU Classifiers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To address the issue, our team adopted a practical approach that estimates standard
    binary classification metrics on PU datasets by using information about the expected
    frequency of positive samples. **Our approach involves using the prior probability
    of the positive class (estimated during the fitting of the self-learning classifier)
    to adjust the false positives and true positives observed on the test**. This
    approach enables a more accurate evaluation of the model’s performance on PU datasets,
    even when the positive class is significantly underrepresented.
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate the efficacy of our approach and run an experiment in a controlled
    setting, we first created a synthetic binary classification dataset using sci-kit-learn’s
    *make_classification* function. The positive samples represent the minor class
    in the data, and a PU learning scenario is simulated by randomly selecting a subset
    of the positive samples and removing their labels.
  prefs: []
  type: TYPE_NORMAL
- en: In a real-world business scenario, the dataset may typically contain such a
    preset ratio of labelled / unlabelled entries. For example, the dataset used **to
    predict customer churn for the coming year** may contain labelled customers from
    the previous year who did not sign a new yearly contract, as well as current customers
    who have similar characteristics as the churned customers but have not yet churned.
    In this case, the dataset may contain up to 40% churned customers, but only half
    of them will be labelled as such (showing the annual churn rate of 20%).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a5ef4cb61b34b96594b8ded20e60fdad.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: We then split the data into training and testing sets using the *train_test_split*
    function. The features *X* and a pseudo-labelled version of the target variable
    *y_pu* are passed to the classifier for training. To evaluate the classifier’s
    performance, we compute standard machine learning metrics such as accuracy, precision,
    and recall on the unlabeled version of the testing set, and compare them further
    to the corresponding metrics computed on the original labelled version.
  prefs: []
  type: TYPE_NORMAL
- en: Code Snippet for Implementing the Approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Below we provide a code snippet that demonstrates the implementation of our
    proposed approach for evaluating classifier performance on PU datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Our *compute_confusion_matrix* function determines the size of the testing data
    and identifies the indices of positive samples in the training set. The model’s
    probability estimates of the positive samples in the training set are then obtained,
    and their mean is computed, representing the probability that a positive sample
    is labelled.
  prefs: []
  type: TYPE_NORMAL
- en: Next, the function applies the fitted [**ImPULSE model**](/an-impulse-to-action-a-practical-solution-for-positive-unlabelled-classification-cd5895128e45)
    to predict the probabilities of the positive class for the testing data and creates
    a confusion matrix using sci-kit-learn’s *confusion_matrix* function. Suppose
    the model’s prior probability of the positive class (in unlabelled samples) is
    greater than zero. In that case, the function adjusts the confusion matrix to
    account for the potential presence of unlabeled positive samples in the testing
    data. The function estimates the expected number of false positives and true positives
    due to unlabeled entries. It then adjusts the confusion matrix accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: To ensure that the resulting confusion matrix matches the size of the testing
    data, the function rounds and rescales it, adjusting the number of true negatives
    if needed.
  prefs: []
  type: TYPE_NORMAL
- en: After obtaining the adjusted confusion matrix, we can use it to calculate standard
    machine learning metrics to get more accurate, as far as possible, of the model’s
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the corresponding [demo notebook on Jovian](https://jovian.com/wldmrgml/impulse-conf-mtx-demo-git)
    and the full code in the [GitHub repo](https://github.com/woldemarg/self_training_pu.git).
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have proposed a practical approach for evaluating machine learning models
    on positive-unlabeled (PU) datasets commonly found in business scenarios. Traditional
    evaluation metrics may not accurately reflect the model’s performance on such
    datasets. The approach estimates standard binary classification metrics on PU
    datasets by using the prior probability of the positive class, enabling a more
    accurate evaluation of the model’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: Reference Reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Jain, Shantanu, et al. “Recovering True Classifier Performance in Positive-Unlabeled
    Learning.”, 2017](https://doi.org/10.48550/arXiv.1702.00518)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Bekker Jessa, and Davis Jesse. “Learning from Positive and Unlabeled Data:
    a Survey.”, 2018](https://doi.org/10.48550/arXiv.1811.04820)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Agmon, Alon. “Semi-Supervised Classification of Unlabeled Data (PU Learning).”,
    2022](/semi-supervised-classification-of-unlabeled-data-pu-learning-81f96e96f7cb)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Saunders, Jack, and Freitas, A. “Evaluating the Predictive Performance of
    Positive-Unlabelled Classifiers: a Brief Critical Review and Practical Recommendations
    for Improvement.”, 2022](https://doi.org/10.48550/arXiv.2206.02423)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Holomb, Volodymyr. “An imPULSE to Action: A Practical Solution for Positive-Unlabeled
    Classification.”, 2023](/an-impulse-to-action-a-practical-solution-for-positive-unlabelled-classification-cd5895128e45)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
