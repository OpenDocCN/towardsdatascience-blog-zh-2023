["```py\n def get_age_group(a):\n    if a < 25:\n        return '18 - 25'\n    if a < 35:\n        return '25 - 34'\n    if a < 45:\n        return '35 - 44'\n    if a < 55:\n        return '45 - 54'\n    if a < 65:\n        return '55 - 64'\n    return '65+'\n\nraw_df['age_group'] = raw_df.age.map(get_age_group)\n```", "```py\n num_metric = 'exited'\ndenom_metric = 'total'\nmax_depth = 4\n\ndef convert_filters_to_str(f):\n    lst = []\n    for k in sorted(f.keys()):\n        lst.append(str(k) + ' = ' + str(f[k]))\n\n    if len(lst) != 0:\n        return ', '.join(lst)\n    return ''\n\ndef raw_deep_dive_segments(tmp_df, filters):\n    # return segment\n    yield {\n        'filters': filters,\n        'numerator': tmp_df[num_metric].sum(),\n        'denominator': tmp_df[denom_metric].sum()\n    }\n\n    # if we haven't reached max_depth then we can dive deeper\n    if len(filters) < max_depth:\n        for dim in dimensions:\n            # check if this dimensions has already been used\n            if dim in filters:\n                continue\n\n            # deduplication of possible combinations\n            if (filters != {}) and (dim < max(filters.keys())):\n                continue\n\n            for val in tmp_df[dim].unique():\n                next_tmp_df = tmp_df[tmp_df[dim] == val]\n\n                # checking if segment size is big enough\n                if next_tmp_df[denom_metric].sum() < min_segment_size:\n                    continue\n\n                next_filters = filters.copy()\n                next_filters[dim] = val\n\n                # executing function for subsequent segment\n                for rec in raw_deep_dive_segments(next_tmp_df, next_filters):\n                    yield rec\n\n# aggregating all segments for dataframe\nsegments_df = pd.DataFrame(list(raw_deep_dive_segments(df, {})))\n```", "```py\nbaseline_churn = 0.2037\nsegments_df['churn_share'] = segments_df.churn/segments_df.total\nsegments_df['churn_est_reduction'] = (segments_df.churn_share - baseline_churn)\\\n    *segments_df.total\nsegments_df['churn_est_reduction'] = segments_df['churn_est_reduction']\\\n  .map(lambda x: int(round(x)))\n\nfilt_segments_df = segments_df[segments_df.churn_est_reduction > 0]\\\n    .sort_values('churn_est_reduction', ascending = False).set_index('segment')\n```", "```py\nimport statsmodels.stats.proportion\n\n# getting all parent - child pairs\ndef get_all_ancestors_recursive(filt):\n    if len(filt) > 1:\n        for dim in filt:\n            cfilt = filt.copy()\n            cfilt.pop(dim)\n            yield cfilt\n            for f in get_all_ancestors_recursive(cfilt):\n                yield f\n\ndef get_all_ancestors(filt):\n    tmp_data = []\n    for f in get_all_ancestors_recursive(filt):\n        tmp_data.append(convert_filters_to_str(f))\n    return list(set(tmp_data))\n\ntmp_data = []\n\nfor f in tqdm.tqdm(filt_segments_df['filters']):\n    parent_segment = convert_filters_to_str(f)\n    for af in get_all_ancestors(f):\n        tmp_data.append(\n            {\n                'parent_segment': af,\n                'ancestor_segment': parent_segment\n            }\n        )\n\nfull_ancestors_df = pd.DataFrame(tmp_data)\n\n# filter child nodes where churn rate is lower \n\nfilt_child_segments = []\n\nfor parent_segment in tqdm.tqdm(filt_segments_df.index):\n    for child_segment in full_ancestors_df[full_ancestors_df.parent_segment == parent_segment].ancestor_segment:\n        if child_segment in filt_child_segments:\n            continue\n\n        churn_diff_ci = statsmodels.stats.proportion.confint_proportions_2indep(\n            filt_segments_df.loc[parent_segment][num_metric],\n            filt_segments_df.loc[parent_segment][denom_metric],\n            filt_segments_df.loc[child_segment][num_metric],\n            filt_segments_df.loc[child_segment][denom_metric]\n        )\n\n        if churn_diff_ci[0] > -0.00:\n            filt_child_segments.append(\n                {\n                    'parent_segment': parent_segment,\n                    'child_segment': child_segment\n                }\n            )\n\nfilt_child_segments_df = pd.DataFrame(filt_child_segments)\nfilt_segments_df = filt_segments_df[~filt_segments_df.index.isin(filt_child_segments_df.child_segment.values)]\n\n# filter parent nodes where churn rate is lower \n\nfilt_parent_segments = []\n\nfor child_segment in tqdm.tqdm(filt_segments_df.index):\n    for parent_segment in full_ancestors_df[full_ancestors_df.ancestor_segment == child_segment].parent_segment:\n        if parent_segment not in filt_segments_df.index:\n            continue\n\n        churn_diff_ci = statsmodels.stats.proportion.confint_proportions_2indep(\n            filt_segments_df.loc[parent_segment][num_metric],\n            filt_segments_df.loc[parent_segment][denom_metric],\n            filt_segments_df.loc[child_segment][num_metric],\n            filt_segments_df.loc[child_segment][denom_metric]\n        )\n        child_coverage = filt_segments_df.loc[child_segment][num_metric]/filt_segments_df.loc[parent_segment][num_metric]\n\n        if (churn_diff_ci[1] < 0.00) and (child_coverage >= 0.8):\n            filt_parent_segments.append(\n                {\n                    'parent_segment': parent_segment,\n                    'child_segment': child_segment\n                }\n            )  \n\nfilt_parent_segments_df = pd.DataFrame(filt_parent_segments)\nfilt_segments_df = filt_segments_df[~filt_segments_df.index.isin(filt_parent_segments_df.parent_segment.values)]\n```", "```py\nroot_segments_df = filt_segments_df[~filt_segments_df.index.isin(\n    full_ancestors_df[full_ancestors_df.parent_segment.isin(\n        filt_segments_df.index)].ancestor_segment\n    )\n]\n```", "```py\n# pip install wise_pizza - for installation\nimport wise_pizza\n\n# building a model \nsf = wise_pizza.explain_levels(\n    df=df,\n    dims=dimensions,\n    total_name=\"exited\",\n    size_name=\"total\",\n    max_depth=4,\n    min_segments=15,\n    solver=\"lasso\"\n)\n\n# making a plot\nsf.plot(width=700, height=100, plot_is_static=False)\n```"]