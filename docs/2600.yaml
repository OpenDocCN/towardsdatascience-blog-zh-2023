- en: The Complexities of Entity Resolution Implementation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实体解析实现的复杂性
- en: 原文：[https://towardsdatascience.com/the-complexities-of-entity-resolution-implementation-a2284e54171?source=collection_archive---------11-----------------------#2023-08-14](https://towardsdatascience.com/the-complexities-of-entity-resolution-implementation-a2284e54171?source=collection_archive---------11-----------------------#2023-08-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-complexities-of-entity-resolution-implementation-a2284e54171?source=collection_archive---------11-----------------------#2023-08-14](https://towardsdatascience.com/the-complexities-of-entity-resolution-implementation-a2284e54171?source=collection_archive---------11-----------------------#2023-08-14)
- en: Hands-on example of some typical challenges when working on data matching
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于数据匹配时一些典型挑战的实用示例
- en: '[](https://medium.com/@stefan.berkner?source=post_page-----a2284e54171--------------------------------)[![Stefan
    Berkner](../Images/a84ebfb24744984c0de8f2e77c2070e6.png)](https://medium.com/@stefan.berkner?source=post_page-----a2284e54171--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a2284e54171--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a2284e54171--------------------------------)
    [Stefan Berkner](https://medium.com/@stefan.berkner?source=post_page-----a2284e54171--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@stefan.berkner?source=post_page-----a2284e54171--------------------------------)[![Stefan
    Berkner](../Images/a84ebfb24744984c0de8f2e77c2070e6.png)](https://medium.com/@stefan.berkner?source=post_page-----a2284e54171--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a2284e54171--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a2284e54171--------------------------------)
    [Stefan Berkner](https://medium.com/@stefan.berkner?source=post_page-----a2284e54171--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F704fdfc8efaa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complexities-of-entity-resolution-implementation-a2284e54171&user=Stefan+Berkner&userId=704fdfc8efaa&source=post_page-704fdfc8efaa----a2284e54171---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a2284e54171--------------------------------)
    ·11 min read·Aug 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa2284e54171&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complexities-of-entity-resolution-implementation-a2284e54171&user=Stefan+Berkner&userId=704fdfc8efaa&source=-----a2284e54171---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F704fdfc8efaa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complexities-of-entity-resolution-implementation-a2284e54171&user=Stefan+Berkner&userId=704fdfc8efaa&source=post_page-704fdfc8efaa----a2284e54171---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a2284e54171--------------------------------)
    ·11 min read·2023年8月14日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa2284e54171&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complexities-of-entity-resolution-implementation-a2284e54171&user=Stefan+Berkner&userId=704fdfc8efaa&source=-----a2284e54171---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa2284e54171&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complexities-of-entity-resolution-implementation-a2284e54171&source=-----a2284e54171---------------------bookmark_footer-----------)![](../Images/1796f00e2295895c1e15056138d13ef5.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa2284e54171&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complexities-of-entity-resolution-implementation-a2284e54171&source=-----a2284e54171---------------------bookmark_footer-----------)![](../Images/1796f00e2295895c1e15056138d13ef5.png)'
- en: Artsy Representation of an Entity (Image by the Author)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 实体的艺术表现（图像由作者提供）
- en: 'Entity resolution is the process of determining whether two or more records
    in a data set refer to the same real-world entity, often a person or a company.
    At a first glance entity resolution may look like a relatively simple task: e.g.
    given two pictures of a person, even a small child could determine if it shows
    the same person or not with a quite high accuracy. And the same is true for computers:
    comparing two records that contain attributes like names, addresses, emails etc.,
    can easily be done. However, the deeper one digs into that topic, the more challenging
    it gets: various matching algorithms need to be evaluated, handling millions or
    billions of records means quadratic complexity, not to mention real-time and data
    deletion use cases.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 实体解析是确定数据集中两个或更多记录是否指向同一现实世界实体的过程，通常是一个人或公司。乍一看，实体解析可能看起来是一个相对简单的任务：例如，给出一个人的两张照片，即使是小孩也可以以相当高的准确率确定是否显示的是同一个人。计算机也是如此：比较包含姓名、地址、电子邮件等属性的两个记录是很容易做到的。然而，越深入探讨这个主题，挑战越大：需要评估各种匹配算法，处理数百万或数十亿条记录意味着平方复杂度，更不用说实时和数据删除的使用案例了。
- en: Fuzzy Text Matching
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模糊文本匹配
- en: Let’s start with looking into comparing two records of the famous artist Vincent
    Van Gogh — or was it Van Gough?
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始比较著名艺术家 Vincent Van Gogh 的两个记录——还是 Van Gough？
- en: '![](../Images/30f4ee24c32fce80c0b5f28833b1b4df.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/30f4ee24c32fce80c0b5f28833b1b4df.png)'
- en: 'There are a few errors in the second record (beside being born a century later
    and an email address): the name is spelled incorrectly, the day of birth is mixed
    up, the postcode is missing and the email address is slightly different.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 第二条记录中有一些错误（除了出生在一个世纪之后和一个电子邮件地址）：名字拼写错误，出生日期混淆，邮政编码缺失，电子邮件地址略有不同。
- en: So how can we compare those values? If, let’s say, the names would be equal,
    then a simple string comparison of those values would be sufficient. As this is
    not the case, we need some more advanced fuzzy matching. There are many different
    algorithms available for text-based fuzzy matching and they can be roughly separated
    into three groups. Phonetic algorithms focus on how similar a text is pronounced.
    The most famous algorithms are Soundex and Metaphone, which are mostly used for
    English texts, but variations of those exist for other languages too like the
    Kölner Phonetik (Cologne Phonetic) for German. Text distance algorithms typically
    define how many characters of a text need to change to reach the other text. Levenshtein
    and Hamming distance are two well known algorithms in that group. Similarity algorithms,
    such as Cosine Similarity or the Jaccard Index, compute the structural similarity
    of texts and often represent the similarity as a percentage.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们如何比较这些值呢？如果，假设姓名相同，那么对这些值进行简单的字符串比较就足够了。由于情况并非如此，我们需要一些更先进的模糊匹配方法。文本基础的模糊匹配有许多不同的算法，大致可以分为三组。语音算法关注文本发音的相似性。最著名的算法是
    Soundex 和 Metaphone，这些算法主要用于英语文本，但也有适用于其他语言的变体，如适用于德语的 Kölner Phonetik（科隆语音）。文本距离算法通常定义了将一个文本更改为另一个文本需要改变多少个字符。Levenshtein
    和 Hamming 距离是这一组中两个知名的算法。相似性算法，如余弦相似性或 Jaccard 指数，计算文本的结构相似性，并通常以百分比表示相似性。
- en: For the purpose of this article, we will use a very simple approach, using only
    a Levenshtein distance on the name and equality on the city. This example and
    all following examples will use golang as a programming language and use existing
    libraries where possible. Converting this into python, java or any other language
    should be trivial. Also it will only perform matching on the name attribute. Adding
    more attributes or even making it configurable is not the purpose of this article.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 出于本文的目的，我们将使用一种非常简单的方法，仅对姓名使用 Levenshtein 距离，对城市进行等值比较。此示例及所有后续示例将使用 golang
    作为编程语言，并尽可能使用现有库。将其转换为 Python、Java 或任何其他语言应该是微不足道的。此外，它仅对姓名属性进行匹配。添加更多属性或使其可配置不是本文的目的。
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Try in the Go Playground: [https://go.dev/play/p/IJtanpXEdyu](https://go.dev/play/p/IJtanpXEdyu)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Go Playground 中尝试：[https://go.dev/play/p/IJtanpXEdyu](https://go.dev/play/p/IJtanpXEdyu)
- en: The Levensthein distance between the two names is exactly 3\. That is because,
    there are three additional characters (“en” in the first name and “u” in the last
    name). Note, that this works with this specific input. It is however far away
    from perfect. E.g. the names “Joe Smith” and “Amy Smith” also have a Levenshtein
    distance of three, but are obviously not the same person. Combining a distance
    algorithm with a phonetic algorithm could solve the issue, but that is out of
    scope for this article.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 两个名字之间的Levenshtein距离为3。原因是有三个额外的字符（名字中的“en”和姓氏中的“u”）。注意，这适用于这个特定输入。然而，距离仍然远未完美。例如，“Joe
    Smith”和“Amy Smith”之间的Levenshtein距离也是三，但显然不是同一个人。结合距离算法和语音算法可能解决这个问题，但超出了本文的范围。
- en: When using a rule-based approach, instead of a ML-based approach, choosing the
    right algorithms that yield the best results for your use case is the most crucial
    aspect of your business success. This is where you should be spending most of
    your time. Unfortunately, as we will discover now, there is a ton of other things
    that will distract you from optimizing those rules if you decide to develop an
    entity resolution engine yourself.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 使用基于规则的方法而不是基于机器学习的方法时，选择能够为你的用例提供最佳结果的算法是商业成功的关键方面。这是你应该花费大部分时间的地方。不幸的是，正如我们现在将发现的那样，如果你决定自己开发实体解析引擎，还有很多其他事情会让你分心，妨碍你优化这些规则。
- en: Naïve Entity Resolution
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 天真的实体解析
- en: Now that we know how to compare two records, we need to find all records that
    match with each other. The easiest approach is to simply compare each record with
    all other records. For the purpose of this example we work with randomly chosen
    names and cities. For the names we force up to three errors (replace any character
    with x).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们知道了如何比较两个记录，我们需要找到所有匹配的记录。最简单的方法是将每条记录与所有其他记录进行比较。为了这个例子，我们使用随机选择的名字和城市。对于名字，我们强制引入最多三个错误（将任何字符替换为x）。
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Try in the Go Playground: [https://go.dev/play/p/ky80W_hk4S3](https://go.dev/play/p/ky80W_hk4S3)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在Go Playground中尝试：[https://go.dev/play/p/ky80W_hk4S3](https://go.dev/play/p/ky80W_hk4S3)
- en: 'You should see some output similar like this (you may need to run it multiple
    times if you do not get any matches for the randomized data):'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到一些类似这样的输出（如果没有匹配的随机数据，你可能需要运行多次）：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If you are lucky, you will also get mismatches like “Daisy” and “Dave”. That
    is because we are using a Levenshtein distance of three, which is way to high
    as the sole fuzzy algorithm on short names. Feel free to improve this on your
    own.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运气好的话，你也会得到像“Daisy”和“Dave”这样的不匹配。这是因为我们使用了三的Levenshtein距离，而对于短名字来说，这个值太高了。欢迎你自己改进这个方法。
- en: Performance wise, the real problematic bit is the 9,900 comparisons needed to
    get to the result, because doubling the amount of the input will roughly quadruple
    the amount of needed comparisons. 39,800 comparisons are needed for 200 records.
    For the small amount of only 100,000 records that would mean almost 10 billion
    comparisons are needed. No matter how big your system is, there will be a point
    at which the system will not be able to finish this in an acceptable time as the
    amount of data grows.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 性能方面，真正的问题在于需要进行9,900次比较才能得到结果，因为输入量的增加会大约使所需的比较次数增加四倍。200条记录需要39,800次比较。对于仅有100,000条记录的小数据量，这意味着需要近100亿次比较。不管你的系统多么强大，数据量增加到一定程度时，系统将无法在可接受的时间内完成。
- en: A quick, but almost useless optimization is to not compare every combination
    twice. It should not matter if we compare A with B or B with A. However, this
    would only reduce the amount of comparisons needed by factor two, which is neglectable
    due to the quadratic growth.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一个快速但几乎无用的优化是不要将每个组合比较两次。A与B或B与A的比较结果应无差别。然而，这只能将所需比较次数减少一半，由于二次增长，这种减少微不足道。
- en: Complexity Reduction by Blocking
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过阻塞减少复杂性
- en: If we are looking at the rules we created, we easily notice that we will never
    have a match if the cities are different. All those comparisons are completely
    wasted and should be prevented. Putting records which you suspect are similar
    into a common bucket and others that are not into another one, is in entity resolution
    called blocking. As we want to use the city as our blocking key, the implementation
    is fairly simple.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看创建的规则，会很容易发现，如果城市不同，我们将永远不会有匹配。所有这些比较都是完全浪费的，应该被避免。将你怀疑相似的记录放入一个公共桶，将其他记录放入另一个桶，在实体解析中称为阻塞。由于我们希望使用城市作为阻塞键，因此实现起来相当简单。
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Try in the Go Playground: [https://go.dev/play/p/1z_j0nhX-tU](https://go.dev/play/p/1z_j0nhX-tU)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '在 Go Playground 中尝试: [https://go.dev/play/p/1z_j0nhX-tU](https://go.dev/play/p/1z_j0nhX-tU)'
- en: The result will now be the same, but we have only roughly a tenth of the comparisons
    as previously, because we have ten different cities. In a real application this
    effect would be tremendously bigger due to the much higher variance of the cities.
    Furthermore, each block can be processed independently of the others, e.g. in
    parallel on the same or on different servers.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 结果现在将是相同的，但比较次数仅为之前的十分之一，因为我们有十个不同的城市。在实际应用中，由于城市的方差更大，这一效果会更为显著。此外，每个块可以独立处理，例如，在相同或不同的服务器上并行处理。
- en: Finding the right blocking key can be a challenge on its own. Using an attribute
    like the city could result in uneven distributions, and therefore result in cases
    where one huge block (e.g. a large city) takes a lot longer than all other blocks.
    Or the city contains a tiny spelling error and is no longer considered as a valid
    match. Using multiple attributes and/or using phonetic keys or [q-grams](https://en.wikipedia.org/wiki/N-gram)
    as a blocking key can solve these issues, but increases the complexity of the
    software.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 找到合适的阻塞键本身可能是一个挑战。使用像城市这样的属性可能会导致不均匀的分布，从而导致某些巨大块（例如大城市）所需的时间比其他块要长得多。或者城市中包含一个微小的拼写错误，从而不再被视为有效匹配。使用多个属性和/或使用语音键或
    [q-grams](https://en.wikipedia.org/wiki/N-gram) 作为阻塞键可以解决这些问题，但会增加软件的复杂性。
- en: From Matches to Entity
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从匹配到实体
- en: So far all we can say about our records is, whether two of them are matching
    or not. For very basic use cases this might already be sufficient. However, in
    the majority you want to know all matches that belong to the same entity. This
    can reach from simple star-like patterns where A matches with B, C and D, over
    chain-like patterns where A matches B, B matches C and C matches D, to very complex
    graph-like patterns. This so called transitive record-linkage can easily be implemented
    using a connected component algorithm as long as all data fits in memory on a
    single server. Again, in a real world application, this is much more challenging.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只能说记录是否匹配。对于非常基本的用例，这可能已经足够。然而，大多数情况下，你会想知道属于同一实体的所有匹配。这可能从简单的星形模式（例如
    A 与 B、C 和 D 匹配），到链式模式（例如 A 与 B 匹配，B 与 C 匹配，C 与 D 匹配），再到非常复杂的图形模式。这种所谓的传递记录链接可以使用连通组件算法轻松实现，只要所有数据都适合在单台服务器的内存中。再次强调，在现实世界的应用中，这会更具挑战性。
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Try in the Go Playground: [https://go.dev/play/p/vP3tzlzJ2LN](https://go.dev/play/p/vP3tzlzJ2LN)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '在 Go Playground 中尝试: [https://go.dev/play/p/vP3tzlzJ2LN](https://go.dev/play/p/vP3tzlzJ2LN)'
- en: 'The connected components function iterates over all edges and either creates
    a new component, adds the new id to the existing component or merges two components
    into a single one. The result then looks something like that:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 连通组件函数遍历所有边，创建新的组件、将新 id 添加到现有组件中，或将两个组件合并为一个。结果看起来大致如下：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Keeping those edges gives us a few advantages. We can use them to make the resulting
    entity understandable and explainable, ideally even with a nice UI that shows
    how the records of an entity are connected. Or when working with a real-time entity
    resolution system, we can use the edges to split an entity as data was removed.
    Or you use them when constructing a [graph neural network (GNN)](https://en.wikipedia.org/wiki/Graph_neural_network),
    leading to even better ML results instead of just the records alone.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 保留这些边缘给我们带来了一些优势。我们可以利用它们使结果实体易于理解和解释，理想情况下，还能提供一个漂亮的用户界面，展示实体的记录是如何连接的。或者在使用实时实体解析系统时，我们可以利用这些边缘来拆分实体，特别是在数据被移除时。或者你可以在构建
    [图神经网络 (GNN)](https://en.wikipedia.org/wiki/Graph_neural_network) 时使用它们，从而获得比仅仅记录本身更好的机器学习结果。
- en: '![](../Images/b1a6b9d79c3aa9defb431b1244e9d2cf.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b1a6b9d79c3aa9defb431b1244e9d2cf.png)'
- en: Visual Representation of an Entity (Image by the Author)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 实体的可视化表示（图像由作者提供）
- en: One issue from the edges can arise when there are a lot of very similar records.
    If e.g. A matches with B and B matches with C, then C might also match with A
    depending on the used rules. If D, E, F and so on also match with the existing
    records, then we are back to the quadratic growth issue, soon resulting in so
    many edges that they become no longer handleable.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘的一个问题可能会出现在有大量非常相似的记录时。例如，如果 A 与 B 匹配，B 与 C 匹配，那么 C 也可能与 A 匹配，具体取决于使用的规则。如果
    D、E、F 等也与现有记录匹配，那么我们将回到平方增长的问题，很快会出现大量边缘，导致无法处理。
- en: Remember how we built the blocking buckets? Surprise! For very similar data,
    which all ends up in a few huge buckets, the performance of the computation drops
    drastically again — even if you followed the previous advice of creating buckets
    from multiple attributes.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 还记得我们如何构建阻塞桶吗？惊喜！对于非常相似的数据，最终都集中在几个巨大的桶中，计算性能会急剧下降——即使你遵循了之前创建多个属性桶的建议。
- en: A typical example for these kind of non-identical duplicates is someone ordering
    regularly in the same shop, but with guest access (sorry, no nice customer id).
    That person might be using almost always the same delivery address and is mostly
    capable of writing their own name correctly. Those records therefore should be
    treated in a special way to ensure a stable system performance, but that is a
    [topic on its own](https://www.youtube.com/watch?v=HjafHL068XM).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这种非相同重复项的典型例子是某人在同一家商店定期订购，但使用的是访客访问（抱歉，没有漂亮的客户 ID）。那个人可能几乎总是使用相同的送货地址，并且大多数情况下能够正确地写出自己的名字。因此，这些记录应该以特殊方式处理，以确保系统性能的稳定，但这是一个
    [单独的话题](https://www.youtube.com/watch?v=HjafHL068XM)。
- en: 'Before you feel too comfortable with your gained knowledge and want to start
    implementing your own solution, let me quickly crush your dreams. We have not
    yet talked about the challenges of doing any of this in real-time. Even if you
    think you will not need an always up-to-date entity (the obvious benefit), a real-time
    approach yields further value: you don’t need to do the same calculations over
    and over again, but only for the new data. On the other hand, it is much more
    complex to implement. Want to do blocking? Compare the new records with all the
    records of the bucket(s) it belongs to, but that can take a while and could be
    rather considered as incremental batch. Also until that finally finished, there
    are a ton of new records waiting already to be processed. Want to calculate the
    entities using connected components? Sure, keep the whole graph in memory and
    just add the new edges. But do not forget to keep track of the two entities that
    just have been merged together due to the new record.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在你对获得的知识感到过于自满并想开始实施自己的解决方案之前，让我迅速打破你的幻想。我们还没有谈到实时处理这些问题的挑战。即使你认为不需要始终保持最新的实体（这是明显的好处），实时方法仍然提供了额外的价值：你不需要一遍又一遍地进行相同的计算，只需对新数据进行计算。另一方面，实施起来复杂得多。想做阻塞吗？将新记录与所属桶的所有记录进行比较，但这可能需要一段时间，并且可以被视为增量批处理。直到最终完成之前，还有大量新记录等待处理。想使用连通组件计算实体？当然，将整个图保存在内存中并只添加新的边。但是不要忘记跟踪由于新记录而刚刚合并在一起的两个实体。
- en: So, you are still willing to implement this on your own. And you made the (in
    that case) wise decision, to not store edges and not support real-time. So you
    successfully ran your first entity resolution batch job with all your data. It
    took a while, but you will only do this once per month, so that is fine. It is
    probably just about then when you see your data protection officer running around
    the corner and telling you to remove that one person from your data set due to
    a GDPR complaint. So you run the whole batch job again for a single removed entity
    — yay.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，你仍然愿意自己实施这个方案。你做出了（在这种情况下）明智的决定，即不存储边缘并且不支持实时处理。于是你成功地运行了第一次实体解析批处理作业，处理了所有数据。这花了一段时间，但你每月只需执行一次，所以没问题。可能就在这个时候，你看到数据保护官从拐角处跑来，告诉你因
    GDPR 投诉而需要从数据集中删除那个人。所以你为了一个被删除的实体重新运行了整个批处理作业——太棒了。
- en: Conclusion
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: Doing entity resolution may at first look fairly simple, but it contains a lot
    of significant technical challenges. Some of these can be simplified and/or ignored,
    but others need to be solved for good performance.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 进行实体解析乍一看可能相当简单，但它包含了许多重要的技术挑战。这些挑战中的一些可以被简化和/或忽略，但其他的则需要解决以获得良好的性能。
- en: '*Originally published at* [*https://tilores.io*](https://tilores.io/content/The-Complexities-of-Entity-Resolution-Implementation)*.*'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*最初发表于* [*https://tilores.io*](https://tilores.io/content/The-Complexities-of-Entity-Resolution-Implementation)*。*'
