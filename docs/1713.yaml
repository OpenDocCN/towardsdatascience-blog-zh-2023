- en: 'Logistic Regression: Deceptively Flawed'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é€»è¾‘å›å½’ï¼šçœ‹ä¼¼æœ‰ç¼ºé™·
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/logistic-regression-deceptively-flawed-2c3e7f77eac9?source=collection_archive---------15-----------------------#2023-05-23](https://towardsdatascience.com/logistic-regression-deceptively-flawed-2c3e7f77eac9?source=collection_archive---------15-----------------------#2023-05-23)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/logistic-regression-deceptively-flawed-2c3e7f77eac9?source=collection_archive---------15-----------------------#2023-05-23](https://towardsdatascience.com/logistic-regression-deceptively-flawed-2c3e7f77eac9?source=collection_archive---------15-----------------------#2023-05-23)
- en: When can large odds ratios and perfectly separated data bite you?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¤§çš„èµ”ç‡æ¯”å’Œå®Œç¾åˆ†ç¦»çš„æ•°æ®ä»€ä¹ˆæ—¶å€™ä¼šè®©ä½ åƒäºï¼Ÿ
- en: '[](https://medium.com/@igor-s?source=post_page-----2c3e7f77eac9--------------------------------)[![Igor
    Å egota](../Images/17c592b71fef9526a0679d47937837f6.png)](https://medium.com/@igor-s?source=post_page-----2c3e7f77eac9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2c3e7f77eac9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2c3e7f77eac9--------------------------------)
    [Igor Å egota](https://medium.com/@igor-s?source=post_page-----2c3e7f77eac9--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@igor-s?source=post_page-----2c3e7f77eac9--------------------------------)[![Igor
    Å egota](../Images/17c592b71fef9526a0679d47937837f6.png)](https://medium.com/@igor-s?source=post_page-----2c3e7f77eac9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2c3e7f77eac9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2c3e7f77eac9--------------------------------)
    [Igor Å egota](https://medium.com/@igor-s?source=post_page-----2c3e7f77eac9--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe5f8ebca4ad8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-deceptively-flawed-2c3e7f77eac9&user=Igor+%C5%A0egota&userId=e5f8ebca4ad8&source=post_page-e5f8ebca4ad8----2c3e7f77eac9---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2c3e7f77eac9--------------------------------)
    Â·8 min readÂ·May 23, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2c3e7f77eac9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-deceptively-flawed-2c3e7f77eac9&user=Igor+%C5%A0egota&userId=e5f8ebca4ad8&source=-----2c3e7f77eac9---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe5f8ebca4ad8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-deceptively-flawed-2c3e7f77eac9&user=Igor+%C5%A0egota&userId=e5f8ebca4ad8&source=post_page-e5f8ebca4ad8----2c3e7f77eac9---------------------post_header-----------)
    å‘è¡¨åœ¨[Towards Data Science](https://towardsdatascience.com/?source=post_page-----2c3e7f77eac9--------------------------------)
    Â·8åˆ†é’Ÿé˜…è¯»Â·2023å¹´5æœˆ23æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2c3e7f77eac9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-deceptively-flawed-2c3e7f77eac9&user=Igor+%C5%A0egota&userId=e5f8ebca4ad8&source=-----2c3e7f77eac9---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2c3e7f77eac9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-deceptively-flawed-2c3e7f77eac9&source=-----2c3e7f77eac9---------------------bookmark_footer-----------)![](../Images/fd6846838f4d97d1fe123837c8fb36d1.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2c3e7f77eac9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-deceptively-flawed-2c3e7f77eac9&source=-----2c3e7f77eac9---------------------bookmark_footer-----------)![](../Images/fd6846838f4d97d1fe123837c8fb36d1.png)'
- en: Photo by [Alvan Nee](https://unsplash.com/es/@alvannee?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ç…§ç‰‡ç”±[Alvan Nee](https://unsplash.com/es/@alvannee?utm_source=medium&utm_medium=referral)æ‹æ‘„ï¼Œå‘å¸ƒåœ¨[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'This is a second part to a previous post on conceptual understanding of logistic
    regression:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸Šä¸€ç¯‡å…³äºé€»è¾‘å›å½’æ¦‚å¿µç†è§£çš„æ–‡ç« çš„ç¬¬äºŒéƒ¨åˆ†ï¼š
- en: '[](/logistic-regression-faceoff-67560de4f492?source=post_page-----2c3e7f77eac9--------------------------------)
    [## Logistic regression: Faceoff and Conceptual Understanding'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/logistic-regression-faceoff-67560de4f492?source=post_page-----2c3e7f77eac9--------------------------------)
    [## é€»è¾‘å›å½’ï¼šå¯¹å†³ä¸æ¦‚å¿µç†è§£'
- en: What log-losses and perfectly separated data have to do with hockey sticks?
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¯¹æ•°æŸå¤±å’Œå®Œç¾åˆ†ç¦»çš„æ•°æ®ä¸å†°çƒæ£’æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ
- en: towardsdatascience.com](/logistic-regression-faceoff-67560de4f492?source=post_page-----2c3e7f77eac9--------------------------------)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/logistic-regression-faceoff-67560de4f492?source=post_page-----2c3e7f77eac9--------------------------------)
- en: Last time we visualized and explained fitting log-losses in logistic regression.
    We also showed that this process cannot fit perfectly separated data. In other
    words, unlike linear regression with ordinary least square fit, logistic regression
    actually works better if the data is a little bit noisy!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šæ¬¡æˆ‘ä»¬å¯è§†åŒ–å¹¶è§£é‡Šäº†é€»è¾‘å›å½’ä¸­çš„å¯¹æ•°æŸå¤±æ‹Ÿåˆã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº†è¿™ä¸ªè¿‡ç¨‹æ— æ³•å®Œç¾æ‹Ÿåˆå®Œå…¨åˆ†ç¦»çš„æ•°æ®ã€‚æ¢å¥è¯è¯´ï¼Œä¸æ™®é€šæœ€å°äºŒä¹˜æ³•çš„çº¿æ€§å›å½’ä¸åŒï¼Œé€»è¾‘å›å½’å®é™…ä¸Šåœ¨æ•°æ®ç¨å¾®æœ‰äº›å™ªå£°æ—¶æ•ˆæœæ›´å¥½ï¼
- en: In practice, does this actually matter? *It depends:*
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šï¼Œè¿™æ˜¯å¦é‡è¦ï¼Ÿ*è¿™è¦çœ‹æƒ…å†µï¼š*
- en: It matters if our goal is to use the output for statistical inference. For example,
    accurately estimating model coefficients, calculating confidence intervals and
    to test hypotheses using p-values.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å°†è¾“å‡ºç”¨äºç»Ÿè®¡æ¨æ–­ï¼Œè¿™å°±å¾ˆé‡è¦ã€‚ä¾‹å¦‚ï¼Œå‡†ç¡®ä¼°è®¡æ¨¡å‹ç³»æ•°ã€è®¡ç®—ç½®ä¿¡åŒºé—´å¹¶ä½¿ç”¨ p å€¼æµ‹è¯•å‡è®¾ã€‚
- en: It does not matter much or at all, if our goal is to use the output of a logistic
    model to create a predictive classification model.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä½¿ç”¨é€»è¾‘æ¨¡å‹çš„è¾“å‡ºåˆ›å»ºä¸€ä¸ªé¢„æµ‹åˆ†ç±»æ¨¡å‹ï¼Œé‚£ä¹ˆè¿™å¹¶æ²¡æœ‰å¤ªå¤§å…³ç³»ã€‚
- en: 'Statistical inference: statsmodels'
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»Ÿè®¡æ¨æ–­ï¼šstatsmodels
- en: Sample data
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹æ•°æ®
- en: 'For this part, we will use Pythonâ€™s statsmodels library. Keep in mind that
    statsmodels and scikit-learn (used later) parametrize the probability using *Î²*s
    instead of *k* and *xâ‚€*:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Python çš„ statsmodels åº“ã€‚è¯·æ³¨æ„ï¼Œstatsmodels å’Œ scikit-learnï¼ˆç¨åä½¿ç”¨ï¼‰ä½¿ç”¨ *Î²*
    æ¥å‚æ•°åŒ–æ¦‚ç‡ï¼Œè€Œä¸æ˜¯ *k* å’Œ *xâ‚€*ï¼š
- en: '![](../Images/6b56227f9d6f2bd6640839f01a3d90a6.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6b56227f9d6f2bd6640839f01a3d90a6.png)'
- en: 'where the relationship between *k*, *xâ‚€* and *Î²â‚*, *Î²â‚€* is:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ *k*ã€*xâ‚€* å’Œ *Î²â‚*ã€*Î²â‚€* ä¹‹é—´çš„å…³ç³»æ˜¯ï¼š
- en: '![](../Images/b9226107d5bd05e8238a5d138809310b.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b9226107d5bd05e8238a5d138809310b.png)'
- en: 'We will continue with datasets we generated in the [first part on logistic
    regression](/logistic-regression-faceoff-67560de4f492), first with the â€œimperfectâ€
    data `sample_df` , using statsmodelsâ€™ formula API:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ç»§ç»­ä½¿ç”¨æˆ‘ä»¬åœ¨ [é€»è¾‘å›å½’ç¬¬ä¸€éƒ¨åˆ†](/logistic-regression-faceoff-67560de4f492) ä¸­ç”Ÿæˆçš„æ•°æ®é›†ï¼Œé¦–å…ˆä½¿ç”¨â€œéå®Œç¾â€æ•°æ®
    `sample_df` ï¼Œä½¿ç”¨ statsmodels çš„å…¬å¼ APIï¼š
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/0c76474446a04887204ce5aebabe589a.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0c76474446a04887204ce5aebabe589a.png)'
- en: 'Our model parameters are *k = 3* and *xâ‚€ = 2.5*, so those translate to *Î²â‚
    = 3* and *Î²â‚€ = -7.5\.* We can compare those with fitted parameters by reading
    them out from the `coef` column of the bottom table:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„æ¨¡å‹å‚æ•°æ˜¯ *k = 3* å’Œ *xâ‚€ = 2.5*ï¼Œå› æ­¤å®ƒä»¬å¯¹åº”äº *Î²â‚ = 3* å’Œ *Î²â‚€ = -7.5*ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»åº•éƒ¨è¡¨æ ¼çš„ `coef`
    åˆ—ä¸­è¯»å–è¿™äº›å‚æ•°ï¼Œä¸æ‹Ÿåˆçš„å‚æ•°è¿›è¡Œæ¯”è¾ƒï¼š
- en: '![](../Images/6e4bba19fadc12707c46ebbaba5aa5c7.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6e4bba19fadc12707c46ebbaba5aa5c7.png)'
- en: We have very few data points and the seed was intentionally chosen to showcase
    outliers, so the fit is a little bit off, but it is still in the right ballpark.
    The total log-loss is here reported as â€œLog-Likelihoodâ€, which is just the negative
    of total log-loss and equals -6.911.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„æ•°æ®ç‚¹éå¸¸å°‘ï¼Œè€Œä¸”ç§å­æ˜¯æ•…æ„é€‰æ‹©çš„ï¼Œä»¥å±•ç¤ºç¦»ç¾¤å€¼ï¼Œå› æ­¤æ‹Ÿåˆç•¥æœ‰åå·®ï¼Œä½†ä»åœ¨åˆç†èŒƒå›´å†…ã€‚è¿™é‡ŒæŠ¥å‘Šçš„æ€»å¯¹æ•°æŸå¤±ä¸ºâ€œå¯¹æ•°ä¼¼ç„¶â€ï¼Œå³æ€»å¯¹æ•°æŸå¤±çš„è´Ÿå€¼ï¼Œç­‰äº
    -6.911ã€‚
- en: Perfectly separated data
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å®Œå…¨åˆ†ç¦»çš„æ•°æ®
- en: What happens when we run our perfectly separated dataset in statsmodels? Again,
    it depends!
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬åœ¨ statsmodels ä¸­è¿è¡Œæˆ‘ä»¬å®Œå…¨åˆ†ç¦»çš„æ•°æ®é›†æ—¶ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿç­”æ¡ˆæ˜¯ï¼Œè¿™è¦çœ‹æƒ…å†µï¼
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In this case we got an error â€” no results are output. In other cases of perfect
    separation, we may get a warning. For example, if we use the same parameters but
    different random seed:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹æˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªé”™è¯¯â€”â€”æ²¡æœ‰è¾“å‡ºç»“æœã€‚åœ¨å…¶ä»–å®Œç¾åˆ†ç¦»çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šå¾—åˆ°ä¸€ä¸ªè­¦å‘Šã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨ç›¸åŒçš„å‚æ•°ä½†ä¸åŒçš„éšæœºç§å­ï¼š
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/29d9a85d58eaf5d3be965f408b515d2b.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/29d9a85d58eaf5d3be965f408b515d2b.png)'
- en: 'Since the second model did not converge either, we can argue that it probably
    should have also returned an error, not an innocent warning. Logistic regression
    function in R, `glm(..., family=binomial)` does the same. To quote [R Inferno](https://www.burns-stat.com/pages/Tutor/R_inferno.pdf),
    Circle 5, Consistency:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºç¬¬äºŒä¸ªæ¨¡å‹ä¹Ÿæ²¡æœ‰æ”¶æ•›ï¼Œæˆ‘ä»¬å¯ä»¥è®¤ä¸ºå®ƒå¯èƒ½ä¹Ÿåº”è¯¥è¿”å›ä¸€ä¸ªé”™è¯¯ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªæ— å®³çš„è­¦å‘Šã€‚R ä¸­çš„é€»è¾‘å›å½’å‡½æ•° `glm(..., family=binomial)`
    ä¹Ÿæ˜¯è¿™æ ·ã€‚å¼•ç”¨ [R Inferno](https://www.burns-stat.com/pages/Tutor/R_inferno.pdf) çš„ç¬¬äº”åœˆï¼Œä¸€è‡´æ€§ï¼š
- en: There is a problem with warnings. No one reads them. People have to read error
    messages because no food pellet falls into the tray after they push the button.
    With a warning the machine merely beeps at them but they still get their food
    pellet. Never mind that it might be poison.
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è­¦å‘Šçš„é—®é¢˜åœ¨äºï¼Œæ²¡æœ‰äººä¼šé˜…è¯»å®ƒä»¬ã€‚äººä»¬å¿…é¡»é˜…è¯»é”™è¯¯ä¿¡æ¯ï¼Œå› ä¸ºåœ¨æŒ‰ä¸‹æŒ‰é’®åæ²¡æœ‰é£Ÿç‰©é¢—ç²’æ‰å…¥æ‰˜ç›˜ä¸­ã€‚è€Œè­¦å‘Šåªä¼šä½¿æœºå™¨å‘å‡ºè­¦æŠ¥ï¼Œä½†ä»–ä»¬ä»ç„¶ä¼šå¾—åˆ°é£Ÿç‰©é¢—ç²’ã€‚å³ä½¿å®ƒå¯èƒ½æ˜¯æ¯’è¯ä¹Ÿæ— æ‰€è°“ã€‚
- en: Therefore, be careful when doing inference using effect sizes and p-values!
    In this case the data is perfectly separable â€” we have a perfect predictor â€” while
    the reported p-value (P > |z|) is 0.998\. Ignoring or misunderstanding these warnings
    may get you miss some obvious features in the data.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œåœ¨ä½¿ç”¨æ•ˆåº”å¤§å°å’Œ p å€¼è¿›è¡Œæ¨æ–­æ—¶è¦å°å¿ƒï¼åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ•°æ®æ˜¯å®Œå…¨å¯åˆ†çš„â€”â€”æˆ‘ä»¬æœ‰ä¸€ä¸ªå®Œç¾çš„é¢„æµ‹å™¨â€”â€”è€ŒæŠ¥å‘Šçš„ p å€¼ï¼ˆP > |z|ï¼‰ä¸º 0.998ã€‚å¿½è§†æˆ–è¯¯è§£è¿™äº›è­¦å‘Šå¯èƒ½ä¼šä½¿ä½ é”™è¿‡æ•°æ®ä¸­çš„ä¸€äº›æ˜æ˜¾ç‰¹å¾ã€‚
- en: Alternatively, consider using a different model. There is a brave new world
    outside of logistic regression! ğŸŒ
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å¦å¤–ï¼Œè€ƒè™‘ä½¿ç”¨å…¶ä»–æ¨¡å‹ã€‚é€»è¾‘å›å½’ä¹‹å¤–è¿˜æœ‰ä¸€ä¸ªå´­æ–°çš„ä¸–ç•Œï¼ğŸŒ
- en: 'Prediction: scikit-learn'
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é¢„æµ‹ï¼šscikit-learn
- en: Sample data
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ ·æœ¬æ•°æ®
- en: scikit-learn automates and abstracts much of the calculations while providing
    a simple and consistent way to run many different models. However, in doing so,
    it hides a number of things happening in the background. When it is not obvious
    what is happening under the hood, learning data science concepts from scikit-learn
    documentation can lead to misunderstanding.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn è‡ªåŠ¨åŒ–å’ŒæŠ½è±¡äº†è®¸å¤šè®¡ç®—ï¼ŒåŒæ—¶æä¾›äº†ä¸€ç§ç®€å•è€Œä¸€è‡´çš„æ–¹å¼æ¥è¿è¡Œè®¸å¤šä¸åŒçš„æ¨¡å‹ã€‚ç„¶è€Œï¼Œåœ¨è¿™æ ·åšæ—¶ï¼Œå®ƒéšè—äº†è®¸å¤šåœ¨åå°å‘ç”Ÿçš„äº‹æƒ…ã€‚å½“åå°å‘ç”Ÿçš„äº‹æƒ…ä¸æ˜æ˜¾æ—¶ï¼Œä»
    scikit-learn æ–‡æ¡£ä¸­å­¦ä¹ æ•°æ®ç§‘å­¦æ¦‚å¿µå¯èƒ½ä¼šå¯¼è‡´è¯¯è§£ã€‚
- en: 'One of these is misunderstandings is that when we run `LogisticRegression()`
    from `sklearn.linear_model` and use a `.predict()` method, it *makes it seem*
    as if we are running a classification model:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ä¸€ä¸ªè¯¯è§£æ˜¯ï¼Œå½“æˆ‘ä»¬ä» `sklearn.linear_model` è¿è¡Œ `LogisticRegression()` å¹¶ä½¿ç”¨ `.predict()`
    æ–¹æ³•æ—¶ï¼Œå®ƒ*çœ‹èµ·æ¥åƒ*æˆ‘ä»¬åœ¨è¿è¡Œä¸€ä¸ªåˆ†ç±»æ¨¡å‹ï¼š
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: However, we can verify that this is still the same old logistic regression by
    either calling its `.predict_proba()` method or by digging out the model parameters
    from the model object, which we printed out here.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è°ƒç”¨å…¶ `.predict_proba()` æ–¹æ³•æˆ–ä»æ¨¡å‹å¯¹è±¡ä¸­æŒ–æ˜æ¨¡å‹å‚æ•°æ¥éªŒè¯è¿™ä»ç„¶æ˜¯è€æ—§çš„é€»è¾‘å›å½’ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œæ‰“å°å‡ºæ¥äº†ã€‚
- en: 'Under the hood, `.predict()` predicts outcomes based on the larger of two probabilities:
    *p* or *1-p*. If *p > 1-p* then it predicts 1, otherwise it predicts 0\. It does
    not calculate confidence intervals, does not have p-values and does not do any
    kind of statistical inference or hypothesis testing. It is still a regression
    model, just with another thresholding layer on top of it.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¹•åï¼Œ`.predict()` æ ¹æ®ä¸¤ä¸ªæ¦‚ç‡ä¸­çš„è¾ƒå¤§è€…è¿›è¡Œé¢„æµ‹ï¼š*p* æˆ– *1-p*ã€‚å¦‚æœ *p > 1-p*ï¼Œåˆ™é¢„æµ‹ä¸º 1ï¼Œå¦åˆ™é¢„æµ‹ä¸º 0ã€‚å®ƒä¸ä¼šè®¡ç®—ç½®ä¿¡åŒºé—´ï¼Œä¹Ÿæ²¡æœ‰
    p å€¼ï¼Œä¹Ÿä¸ä¼šè¿›è¡Œä»»ä½•ç±»å‹çš„ç»Ÿè®¡æ¨æ–­æˆ–å‡è®¾æ£€éªŒã€‚å®ƒä»ç„¶æ˜¯ä¸€ä¸ªå›å½’æ¨¡å‹ï¼Œåªæ˜¯åœ¨å…¶ä¸Šæ–¹æœ‰ä¸€ä¸ªé¢å¤–çš„é˜ˆå€¼å±‚ã€‚
- en: 'Note: `LogisticRegression()` by default uses L2 regularization, which adds
    an extra term to the log-loss function. To make it comparable with statsmodels,
    use `LogisticRegression(penalty=None)`.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼š`LogisticRegression()` é»˜è®¤ä½¿ç”¨ L2 æ­£åˆ™åŒ–ï¼Œå®ƒåœ¨å¯¹æ•°æŸå¤±å‡½æ•°ä¸­æ·»åŠ äº†ä¸€ä¸ªé¢å¤–çš„é¡¹ã€‚ä¸ºäº†ä½¿å…¶ä¸ statsmodels å¯æ¯”ï¼Œä½¿ç”¨
    `LogisticRegression(penalty=None)`ã€‚
- en: Perfectly separable data
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å®Œå…¨å¯åˆ†çš„æ•°æ®
- en: The advantage of ignoring the accuracy of fitted coefficients is that even if
    the coefficients are not accurate, or just plain wrong, the model can still be
    good enough! As the saying goes, â€œlet not the perfect be the enemy of the goodâ€.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: å¿½ç•¥æ‹Ÿåˆç³»æ•°çš„å‡†ç¡®æ€§çš„å¥½å¤„åœ¨äºï¼Œå³ä½¿ç³»æ•°ä¸å‡†ç¡®æˆ–å®Œå…¨é”™è¯¯ï¼Œæ¨¡å‹ä»ç„¶å¯èƒ½è¶³å¤Ÿå¥½ï¼æ­£å¦‚è°šè¯­æ‰€è¯´ï¼Œâ€œä¸è¦è®©å®Œç¾æˆä¸ºä¼˜ç§€çš„æ•Œäººâ€ã€‚
- en: 'scikit-learn by default uses a different fitting method (called â€œ[lbfgs](https://en.wikipedia.org/wiki/Limited-memory_BFGS)â€)
    than statsmodels. In my very limited set of tests, lbfgs did not error out on
    perfectly separated data. To see what happens here, let us run the same two datasets
    we used previously for statsmodels:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn é»˜è®¤ä½¿ç”¨ä¸ statsmodels ä¸åŒçš„æ‹Ÿåˆæ–¹æ³•ï¼ˆç§°ä¸º â€œ[lbfgs](https://en.wikipedia.org/wiki/Limited-memory_BFGS)â€ï¼‰ã€‚åœ¨æˆ‘éå¸¸æœ‰é™çš„æµ‹è¯•ä¸­ï¼Œlbfgs
    åœ¨å®Œå…¨åˆ†ç¦»çš„æ•°æ®ä¸Šæ²¡æœ‰å‡ºç°é”™è¯¯ã€‚ä¸ºäº†æŸ¥çœ‹è¿™é‡Œå‘ç”Ÿäº†ä»€ä¹ˆï¼Œè®©æˆ‘ä»¬è¿è¡Œä¹‹å‰ç”¨äº statsmodels çš„ä¸¤ä¸ªç›¸åŒæ•°æ®é›†ï¼š
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This algorithm also stops at some point, giving finite values of *Î²â‚* (or *k*),
    without an error, but it still predicts the correct outcomes. These are perfectly
    usable model fits for classification!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥ç®—æ³•åœ¨æŸä¸ªç‚¹ä¹Ÿä¼šåœæ­¢ï¼Œç»™å‡ºæœ‰é™çš„ *Î²â‚*ï¼ˆæˆ– *k*ï¼‰å€¼ï¼Œæ²¡æœ‰é”™è¯¯ï¼Œä½†ä»ç„¶èƒ½å¤Ÿé¢„æµ‹æ­£ç¡®çš„ç»“æœã€‚è¿™äº›éƒ½æ˜¯ç”¨äºåˆ†ç±»çš„å®Œå…¨å¯ç”¨çš„æ¨¡å‹æ‹Ÿåˆï¼
- en: Log-odds and loose ends
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¯¹æ•°å‡ ç‡å’Œæœªè§£å†³çš„é—®é¢˜
- en: 'There is one last topic we did not touch too much. Coefficient *k* (or *Î²â‚*)
    which multiplies *x*, has another interpretation â€” a *log odds ratio*. Odds ratio
    describes the multiplicative change in odds, when *x* increases by 1:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰ä¸€ä¸ªæˆ‘ä»¬æ²¡æœ‰æ·±å…¥è®¨è®ºçš„è¯é¢˜ã€‚ç³»æ•° *k*ï¼ˆæˆ– *Î²â‚*ï¼‰ä¹˜ä»¥ *x*ï¼Œæœ‰å¦ä¸€ç§è§£é‡Šâ€”â€”*å¯¹æ•°å‡ ç‡æ¯”*ã€‚å‡ ç‡æ¯”æè¿°äº†å½“ *x* å¢åŠ  1 æ—¶å‡ ç‡çš„ä¹˜æ³•å˜åŒ–ï¼š
- en: '![](../Images/e8f72fc1b29d7d37a5de1eee98f6643a.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e8f72fc1b29d7d37a5de1eee98f6643a.png)'
- en: This definition states that **odds ratio is a ratio of ratios of probabilities**.
    If increasing *x* by one unit, increases the probability of *y = 1* from 0.1 (odds
    0.1 / 0.9 = 0.11) to 0.2 (odds = 0.2 / 0.8 = 0.25), that is represented by odds
    ratio of 0.25 / 0.1 = 2.27.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªå®šä¹‰è¡¨æ˜**èµ”ç‡æ¯”æ˜¯æ¦‚ç‡æ¯”çš„æ¯”ç‡**ã€‚å¦‚æœå°† *x* å¢åŠ ä¸€ä¸ªå•ä½ï¼Œä½¿å¾— *y = 1* çš„æ¦‚ç‡ä» 0.1ï¼ˆèµ”ç‡ 0.1 / 0.9 = 0.11ï¼‰å¢åŠ åˆ°
    0.2ï¼ˆèµ”ç‡ = 0.2 / 0.8 = 0.25ï¼‰ï¼Œåˆ™èµ”ç‡æ¯”ä¸º 0.25 / 0.1 = 2.27ã€‚
- en: When probabilities are small, large odds ratio does not reflect large absolute
    probabilities. If increasing *x* by one unit, increases the probability of *y
    = 1:*
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æ¦‚ç‡å¾ˆå°æ—¶ï¼Œå¤§çš„èµ”ç‡æ¯”å¹¶ä¸åæ˜ å¤§çš„ç»å¯¹æ¦‚ç‡ã€‚å¦‚æœå°† *x* å¢åŠ ä¸€ä¸ªå•ä½ï¼Œä½¿å¾— *y = 1:*
- en: from *p(x) = 0.0001* (odds = 0.0001 / (1â€“0.0001) â‰ˆ 0.0001)
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä» *p(x) = 0.0001*ï¼ˆèµ”ç‡ = 0.0001 / (1â€“0.0001) â‰ˆ 0.0001ï¼‰
- en: to *p(x + 1) = 0.001* (odds = 0.001 / (1â€“0.001) â‰ˆ 0.001)
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ° *p(x + 1) = 0.001*ï¼ˆèµ”ç‡ = 0.001 / (1â€“0.001) â‰ˆ 0.001ï¼‰
- en: 'then this gives us the odds ratio of 0.001/0.0001 = 10\. Even though the odds
    ratio is 10, the final absolute probability is still very small: 0.001\. The good
    news is that **when probability is small, odds ratio becomes easier to interpret**
    â€” it is approximately equal to a ratio of two probabilities *p(x + 1) / p(x)*.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆè¿™ç»™å‡ºäº†èµ”ç‡æ¯”ä¸º 0.001/0.0001 = 10ã€‚å³ä½¿èµ”ç‡æ¯”ä¸º 10ï¼Œæœ€ç»ˆçš„ç»å¯¹æ¦‚ç‡ä»ç„¶å¾ˆå°ï¼š0.001ã€‚å¥½æ¶ˆæ¯æ˜¯**å½“æ¦‚ç‡å¾ˆå°æ—¶ï¼Œèµ”ç‡æ¯”å˜å¾—æ›´å®¹æ˜“è§£é‡Š**â€”â€”å®ƒå¤§è‡´ç­‰äºä¸¤ä¸ªæ¦‚ç‡
    *p(x + 1) / p(x)* çš„æ¯”ç‡ã€‚
- en: 'Compare this to another example where probability increases by a substantial
    amount, say by 25% from *p(x) = 0.5* to *p(x + 1) = 0.75*: in this case odds ratio
    is only 3!'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ­¤ä¸å¦ä¸€ä¸ªä¾‹å­è¿›è¡Œæ¯”è¾ƒï¼Œå…¶ä¸­æ¦‚ç‡å¤§å¹…å¢åŠ ï¼Œä¾‹å¦‚ä» *p(x) = 0.5* å¢åŠ åˆ° *p(x + 1) = 0.75*ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹èµ”ç‡æ¯”ä»…ä¸º 3ï¼
- en: Therefore, high odds ratio needs to be used with a grain of salt when the probability
    of *y = 1* is small. There are alternatives to odds ratio, such as [relative risk](https://www.statology.org/interpret-relative-risk/)
    which are more interpretable, but may not be simple to calculate.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå½“ *y = 1* çš„æ¦‚ç‡å¾ˆå°çš„æ—¶å€™ï¼Œé«˜èµ”ç‡æ¯”éœ€è¦è°¨æ…ä½¿ç”¨ã€‚è¿˜æœ‰å…¶ä»–å¯æ›¿ä»£çš„èµ”ç‡æ¯”ï¼Œä¾‹å¦‚ [ç›¸å¯¹é£é™©](https://www.statology.org/interpret-relative-risk/)ï¼Œè¿™äº›æ–¹æ³•æ›´å…·å¯è§£é‡Šæ€§ï¼Œä½†è®¡ç®—å¯èƒ½ä¸ç®€å•ã€‚
- en: Conclusion
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: In the last two posts, we gave an intuitive explanation to logistic regression
    and show how to run regression models in Pythonâ€™s statsmodels and scikit-learn
    libraries.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å‰ä¸¤ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å¯¹é€»è¾‘å›å½’è¿›è¡Œäº†ç›´è§‚çš„è§£é‡Šï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•åœ¨ Python çš„ statsmodels å’Œ scikit-learn åº“ä¸­è¿è¡Œå›å½’æ¨¡å‹ã€‚
- en: 'Take home points:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: å…³é”®è¦ç‚¹ï¼š
- en: Logistic regression outputs a probability â€” therefore it is a regression algorithm.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€»è¾‘å›å½’è¾“å‡ºä¸€ä¸ªæ¦‚ç‡â€”â€”å› æ­¤å®ƒæ˜¯ä¸€ç§å›å½’ç®—æ³•ã€‚
- en: Logistic regression is often used for classification. For example, by predicting
    the outcome with a larger probability â€” or by setting a custom probability threshold.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€»è¾‘å›å½’é€šå¸¸ç”¨äºåˆ†ç±»ã€‚ä¾‹å¦‚ï¼Œé€šè¿‡é¢„æµ‹å…·æœ‰æ›´å¤§æ¦‚ç‡çš„ç»“æœâ€”â€”æˆ–è€…é€šè¿‡è®¾ç½®è‡ªå®šä¹‰æ¦‚ç‡é˜ˆå€¼ã€‚
- en: Parameters are estimated numerically using the difference between data and two
    **crossed hockey sticks log-loss curves that serve as a cost function**.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‚æ•°é€šè¿‡æ•°æ®ä¹‹é—´çš„å·®å¼‚å’Œä¸¤ä¸ª**äº¤å‰æ›²æ£çƒæ£’å¯¹æ•°æŸå¤±æ›²çº¿ä½œä¸ºæˆæœ¬å‡½æ•°**çš„å·®å¼‚æ¥è¿›è¡Œæ•°å€¼ä¼°è®¡ã€‚
- en: Use **statsmodels** to run a logistic regression when you are interested in
    statistical inference (care about accuracy of coefficients, hypothesis testing,
    p-values, ...).
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“ä½ å¯¹ç»Ÿè®¡æ¨æ–­æ„Ÿå…´è¶£ï¼ˆå…³æ³¨ç³»æ•°çš„å‡†ç¡®æ€§ã€å‡è®¾æ£€éªŒã€p å€¼ç­‰ï¼‰æ—¶ï¼Œä½¿ç”¨ **statsmodels** è¿›è¡Œé€»è¾‘å›å½’ã€‚
- en: Use **scikit-learn** to run a logistic regression when you just want to predict
    the outcome or when you need to run a larger model.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“ä½ åªæ˜¯æƒ³é¢„æµ‹ç»“æœæˆ–éœ€è¦è¿è¡Œæ›´å¤§æ¨¡å‹æ—¶ï¼Œä½¿ç”¨ **scikit-learn** è¿›è¡Œé€»è¾‘å›å½’ã€‚
- en: 'Perfectly separable data breaks statistical inference: best-fit coefficients
    do not exist or â€œare infiniteâ€ and p-values will be large (because of large confidence
    intervals). If we only care about using the model for classification/prediction,
    then scikit-learnâ€™s implementation works better for perfectly separated data.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®Œç¾å¯åˆ†çš„æ•°æ®ç ´åäº†ç»Ÿè®¡æ¨æ–­ï¼šæœ€ä½³æ‹Ÿåˆç³»æ•°ä¸å­˜åœ¨æˆ–â€œæ˜¯æ— é™çš„â€ï¼Œè€Œ p å€¼å°†å¾ˆå¤§ï¼ˆå› ä¸ºç½®ä¿¡åŒºé—´å¾ˆå¤§ï¼‰ã€‚å¦‚æœæˆ‘ä»¬åªå…³å¿ƒä½¿ç”¨æ¨¡å‹è¿›è¡Œåˆ†ç±»/é¢„æµ‹ï¼Œé‚£ä¹ˆ scikit-learn
    çš„å®ç°å¯¹å®Œç¾åˆ†ç¦»çš„æ•°æ®æ•ˆæœæ›´å¥½ã€‚
- en: '**Do not blindly trust large (log-)odds ratios**. Consider calculating additional
    metrics, such as absolute probabilities.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä¸è¦ç›²ç›®ç›¸ä¿¡å¤§çš„ï¼ˆå¯¹æ•°ï¼‰èµ”ç‡æ¯”**ã€‚è€ƒè™‘è®¡ç®—é¢å¤–çš„æŒ‡æ ‡ï¼Œå¦‚ç»å¯¹æ¦‚ç‡ã€‚'
- en: I hope this helps you in your data science journey!
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›è¿™å¯¹ä½ çš„æ•°æ®ç§‘å­¦ä¹‹æ—…æœ‰æ‰€å¸®åŠ©ï¼
