- en: Simplify Airflow DAG Creation and Maintenance with Hamilton in 8 minutes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/simplify-airflow-dag-creation-and-maintenance-with-hamilton-in-8-minutes-e6e48c9c2cb0?source=collection_archive---------6-----------------------#2023-07-05](https://towardsdatascience.com/simplify-airflow-dag-creation-and-maintenance-with-hamilton-in-8-minutes-e6e48c9c2cb0?source=collection_archive---------6-----------------------#2023-07-05)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How Hamilton can help you write more maintainable Airflow DAGs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@stefan.krawczyk?source=post_page-----e6e48c9c2cb0--------------------------------)[![Stefan
    Krawczyk](../Images/150405abaad9590e1dc2589168ed2fa3.png)](https://medium.com/@stefan.krawczyk?source=post_page-----e6e48c9c2cb0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e6e48c9c2cb0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e6e48c9c2cb0--------------------------------)
    [Stefan Krawczyk](https://medium.com/@stefan.krawczyk?source=post_page-----e6e48c9c2cb0--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F193628e26f00&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimplify-airflow-dag-creation-and-maintenance-with-hamilton-in-8-minutes-e6e48c9c2cb0&user=Stefan+Krawczyk&userId=193628e26f00&source=post_page-193628e26f00----e6e48c9c2cb0---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e6e48c9c2cb0--------------------------------)
    ·8 min read·Jul 5, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe6e48c9c2cb0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimplify-airflow-dag-creation-and-maintenance-with-hamilton-in-8-minutes-e6e48c9c2cb0&user=Stefan+Krawczyk&userId=193628e26f00&source=-----e6e48c9c2cb0---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe6e48c9c2cb0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimplify-airflow-dag-creation-and-maintenance-with-hamilton-in-8-minutes-e6e48c9c2cb0&source=-----e6e48c9c2cb0---------------------bookmark_footer-----------)![](../Images/2a7ff556e1e9539020d0b8b388dab73f.png)'
  prefs: []
  type: TYPE_NORMAL
- en: An abstract representation of how Airflow & Hamilton relate. Airflow helps bring
    it all together, while Hamilton helps make the innards manageable. Image from
    [Pixabay](https://pixabay.com/illustrations/abstract-lines-perspective-plan-3242256/).
  prefs: []
  type: TYPE_NORMAL
- en: '*This post is written in collaboration with* [*Thierry Jean*](https://medium.com/u/cf12dc7f8440?source=post_page-----e6e48c9c2cb0--------------------------------)
    *and originally appeared* [*here*](https://blog.dagworks.io/p/supercharge-your-airflow-dag-with)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: This post walks you through the benefits of having two open source projects,
    [Hamilton](https://github.com/dagworks-inc/hamilton) and [Airflow](https://airflow.apache.org/),
    and their [directed acyclic graphs](https://en.wikipedia.org/wiki/Directed_acyclic_graph)
    (DAGs) work in tandem. At a high level Airflow is responsible for orchestration
    (think macro) and Hamilton helps author clean and maintainable data transformations
    (think micro).
  prefs: []
  type: TYPE_NORMAL
- en: For those that are unfamiliar with Hamilton, we point you to an interactive
    overview on [tryhamilton.dev](http://www.tryhamilton.dev/), or our other posts,
    e.g. like this [one](/functions-dags-introducing-hamilton-a-microframework-for-dataframe-generation-more-8e34b84efc1d).
    Otherwise we will talk about Hamilton at a high level and point to reference documentation
    for more details. For reference I’m one of the co-creators of Hamilton.
  prefs: []
  type: TYPE_NORMAL
- en: For those still mentally trying to grasp how the two can run together, the reason
    you can run Hamilton with Airflow, is that Hamilton is just a library with a small
    dependency footprint, and so one can add Hamilton to their Airflow setup in no
    time!
  prefs: []
  type: TYPE_NORMAL
- en: 'Just to recap, Airflow is the industry standard to orchestrate data pipelines.
    It powers all sorts of data initiatives including ETL, ML pipelines and BI. Since
    its inception in 2014, Airflow users have faced certain rough edges with regards
    to authoring and maintaining data pipelines:'
  prefs: []
  type: TYPE_NORMAL
- en: Maintainably managing the evolution of workflows; what starts simple can invariably
    get complex.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Writing modular, reusable, and testable code that runs within an Airflow task.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Tracking lineage of code and data artifacts that an Airflow DAG produces.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is where we believe Hamilton can help! [Hamilton](https://github.com/dagworks-inc/hamilton)
    is a Python micro-framework for writing data transformations. In short, one writes
    python functions in a “declarative” style, which Hamilton parses and connects
    into a graph based on their names, arguments and type annotations. Specific outputs
    can be requested and Hamilton will execute the required function path to produce
    them. Because it doesn’t provide macro orchestrating capabilities, it pairs nicely
    with Airflow by helping data professionals write cleaner code and more reusable
    code for Airflow DAGs.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/946b089522c6fba64b5fc5cc216d6480.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The Hamilton Paradigm in a picture. This example shows how one would map procedural
    pandas code to Hamilton functions that define a DAG. Note: Hamilton can be used
    for any Python object types, not just Pandas. Image by author.'
  prefs: []
  type: TYPE_NORMAL
- en: Write maintainable Airflow DAGs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A common use of Airflow is to help with machine learning/data science. Running
    such workloads in production often requires complex workflows. A necessary design
    decision with Airflow is determining how to break up the workflow into Airflow
    tasks. Create too many and you increase scheduling and execution overhead (e.g.
    moving lots of data), create too few and you have monolithic tasks that can take
    a while to run, but probably is more efficient to run. The trade-off here is Airflow
    DAG complexity versus code complexity within each of the tasks. This makes debugging
    and reasoning about the workflow harder, especially if you did not author the
    initial Airflow DAG. More often than not, the initial task structure of the Airflow
    DAG becomes fixed, because refactoring the task code becomes prohibitive!
  prefs: []
  type: TYPE_NORMAL
- en: While simpler DAGs such as `A->B->C` are desirable, there is an inherent tension
    between the structure’s simplicity and the amount of code per task. The more code
    per task, the more difficult it is to identify points of failure, at the trade-off
    of potential computational efficiencies, but in the case of failures, retries
    grow in cost with the “size” of the task.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/86d7f093205e068e4d4295544e29adac.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Airflow DAG structure choices: how many tasks? how much code per task? Image
    by author.'
  prefs: []
  type: TYPE_NORMAL
- en: Instead, what if you could simultaneously wrangle the complexity within an Airflow
    task, no matter the size of code within it, and gain the flexibility to easily
    change the Airflow DAG shape with minimal effort? This is where Hamilton comes
    in.
  prefs: []
  type: TYPE_NORMAL
- en: 'With Hamilton you can replace the code within each Airflow task with a Hamilton
    DAG, where Hamilton handles the “micro” orchestration of the code within the task.
    Note: Hamilton actually enables you to logically model everything that you’d want
    an Airflow DAG to do. More on that below.'
  prefs: []
  type: TYPE_NORMAL
- en: To use Hamilton, you load a Python module that contains your Hamilton functions,
    instantiate a [Hamilton Driver](https://hamilton.dagworks.io/en/latest/concepts/driver-capabilities/)
    and execute a Hamilton DAG within an Airflow task in a few lines of code. By using
    Hamilton, you can write your data transformation at an arbitrary granularity,
    allowing you to inspect in greater details what each Airflow task is doing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically the mechanics of the code are:'
  prefs: []
  type: TYPE_NORMAL
- en: Import your function modules
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pass them to the Hamilton driver to build the DAG.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, call `Driver.execute()` with the outputs you want to execute from the
    DAG you’ve defined.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let’s look at some code that create a single node Airflow DAG but uses Hamilton
    to train and evaluate a ML model:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we didn’t show the Hamilton code here, but the benefits of this approach
    are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Unit & integration testing.** Hamilton, through its naming and type annotations
    requirements, pushes developers to write modular Python code. This results in
    Python modules well-suited for unit testing. Once your Python code is unit tested,
    you can develop integration tests to ensure it behaves properly in your Airflow
    tasks. In contrast, testing code contained in an Airflow task is less trivial,
    especially in CI/CD settings, since it requires having access to an Airflow environment.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Reuse data transformations.** This approach keeps the data transformations
    code in Python modules, separated from the Airflow DAG file. This means this code
    is also runnable *outside* of Airflow! If you come from the analytics world, it
    should feel similar to developing and testing SQL queries in an external `.sql`
    file, then loading it into your Airflow Postgres operators.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Reorganize your Airflow DAG easily.** The lift required to change your Airflow
    DAG is now much lower. If you logically model everything in Hamilton, e.g. an
    end to end machine learning pipeline, it’s just a matter of determining how much
    of this Hamilton DAG needs to be computed in each Airflow task. For example, you
    change the number of tasks from one monolithic Airflow task, to a few, or to many
    — all that would need to change is what you request from Hamilton since your Hamilton
    DAG needn’t change at all!'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Iterative development with Hamilton & Airflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In most data science projects, it would be impossible to write the DAG of the
    final system from day 1 as requirements will change. For example, the data science
    team might want to try different feature sets for their model. Until the list
    is set and finalized, it is probably undesirable to have the feature set in your
    source code and under version control; configuration files would be preferable.
  prefs: []
  type: TYPE_NORMAL
- en: Airflow supports default and runtime DAG configurations and will log these settings
    to make every DAG run reproducible. However, adding configurable behaviors will
    require committing adding conditional statements and complexity to your Airflow
    task code. This code might become obsolete during the project or only be useful
    in particular scenarios, ultimately decreasing your DAGs readability.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, Hamilton can use Airflow’s runtime configuration to execute different
    data transformations from the function graph on the fly. This layered approach
    can greatly increase the expressivity of Airflow DAGs while maintaining structural
    simplicity. Alternatively, Airflow can [dynamically generate new DAGs](https://airflow.apache.org/docs/apache-airflow/stable/howto/dynamic-dag-generation.html)
    from configurations, but this could decrease observability and some of these features
    remain experimental.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/422eabbc6ecaa3194d10d42aba2a8e52.png)'
  prefs: []
  type: TYPE_IMG
- en: Airflow UI for DAG run configuration. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: If you work in a hand-off model, this approach promotes a separation of concerns
    between the data engineers responsible for the Airflow production system and the
    data scientists in charge of developing business solutions by writing Hamilton
    code. Having this separation can also improve data consistency and reduce code
    duplication. For example, a single Airflow DAG can be reused with different Hamilton
    modules to create different models. Similarly, the same Hamilton data transformations
    can be reused across different Airflow DAGs to power dashboards, API, applications,
    etc.
  prefs: []
  type: TYPE_NORMAL
- en: Below are two pictures. The first illustrates the high-level Airflow DAG containing
    two nodes. The second displays the low-level Hamilton DAG of the Python module
    `evaluate_model` imported in the Airflow task `train_and_evaluate_model.`
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0e45dd55064d29ec14ea5cd81351a6c6.png)'
  prefs: []
  type: TYPE_IMG
- en: '1\. Airflow UI: Absenteeism Airflow DAG'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5ec58be392b5bebce940e285035ee8d6.png)'
  prefs: []
  type: TYPE_IMG
- en: '2\. Hamilton driver visualization: function graph for evaluate_model.py'
  prefs: []
  type: TYPE_NORMAL
- en: Handling data artifacts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data science projects produce a large number of data artifacts from datasets,
    performance evaluations, figures, trained models, etc. The artifacts needed will
    change over the course of the project life cycle (data exploration, model optimization,
    production debugging, etc.). This is a problem for Airflow since removing a task
    from a DAG will delete its metadata history and break the artifact lineage. In
    certain scenarios, producing unnecessary or redundant data artifacts can incur
    significant computation and storage costs.
  prefs: []
  type: TYPE_NORMAL
- en: Hamilton can provide the needed flexibility for data artifact generation through
    its [data saver API](https://hamilton.dagworks.io/en/latest/reference/decorators/save_to/#save-to).
    Functions decorated with `@save_to.*` add the possibility to store their output,
    one need only to request this functionality via `Driver.execute()`. In the code
    below, calling `validation_predictions_table` will return the table whereas calling
    the `output_name_` value of `save_validation_predictions` will return the table
    and save it to `.csv`
  prefs: []
  type: TYPE_NORMAL
- en: This added flexibility allows users to easily toggle the artifacts generated
    and it can be done directly through the Airflow runtime configuration, without
    editing the Airflow DAG or Hamilton modules.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, the fine-grained Hamilton function graph allows for precise data
    lineage & provenance. Utility functions `what_is_downstream_of()` and `what_is_upstream_of()`
    help visualize and programmatically explore data dependencies. We point interested
    readers for more detail [here](https://medium.com/towards-data-science/lineage-hamilton-in-10-minutes-c2b8a944e2e6).
  prefs: []
  type: TYPE_NORMAL
- en: To finish & an example to get started
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hopefully by now we’ve impressed on you that combing Hamilton with Airflow will
    help you with Airflow’s DAG creation & maintainability challenges. Since this
    is a short post, to wrap things up, let’s move onto the code we have in the [Hamilton
    repository](https://github.com/DAGWorks-Inc/hamilton/tree/main/examples) for you.
  prefs: []
  type: TYPE_NORMAL
- en: To help you get up and running, we have an [example](https://github.com/DAGWorks-Inc/hamilton/tree/main/examples/airflow)
    on how to use Hamilton with Airflow. It should cover all the basics that you need
    to get started. The README includes how to set up Airflow with Docker, so that
    you don’t need to worry about installing dependencies just to play with the example.
  prefs: []
  type: TYPE_NORMAL
- en: As for the code in the example, it contains two Airflow DAGs, one showcasing
    a [basic Hamilton “how-to”](https://github.com/DAGWorks-Inc/hamilton/blob/main/examples/airflow/dags/hamilton/hamilton_how_to_dag.py)
    to create “features” for training a model, and the other a more complete [machine
    learning project example](https://github.com/DAGWorks-Inc/hamilton/blob/main/examples/airflow/dags/hamilton/absenteeism_prediction_dag.py),
    that does a full end-to-end pipeline of creating features and then fitting and
    evaluating a model. For both examples, you’ll find the Hamilton code under the
    plugins folder.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b27744e2f236a1e08e0a7f94ce091547.png)'
  prefs: []
  type: TYPE_IMG
- en: What you should expect to see in the Airflow example. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: If you have questions or need help — please join our [Slack](https://hamilton-opensource.slack.com/join/shared_invite/zt-1bjs72asx-wcUTgH7q7QX1igiQ5bbdcg#/shared-invite/email).
    Otherwise, to learn more about Hamilton’s features and functionality, we refer
    you to Hamilton’s [documentation](https://hamilton.dagworks.io/).
  prefs: []
  type: TYPE_NORMAL
- en: References & Further Reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thanks for taking a look at this post. If you want to dive deeper, or want to
    learn more about Hamilton, we have the following links for you to browse!
  prefs: []
  type: TYPE_NORMAL
- en: '[Hamilton + Airflow code example](https://github.com/DAGWorks-Inc/hamilton/tree/main/examples/airflow)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hamilton Documentation](https://hamilton.dagworks.io/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[tryhamilton.dev](https://www.tryhamilton.dev/) — an interactive way to learn
    more about Hamilton.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For another orchestration system integrating with Hamilton, you can checkout
    [Hamilton + Metaflow](https://outerbounds.com/blog/developing-scalable-feature-engineering-dags/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hamilton Slack community](https://hamilton-opensource.slack.com/join/shared_invite/zt-1bjs72asx-wcUTgH7q7QX1igiQ5bbdcg#/shared-invite/email)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Lineage + Hamilton in 10 minutes](https://medium.com/towards-data-science/lineage-hamilton-in-10-minutes-c2b8a944e2e6)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introducing Hamilton](/functions-dags-introducing-hamilton-a-microframework-for-dataframe-generation-more-8e34b84efc1d)
    (backstory and introduction)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hamilton + Pandas in 5 minutes](/how-to-use-hamilton-with-pandas-in-5-minutes-89f63e5af8f5)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to use Hamilton in a Notebook environment](/how-to-iterate-with-hamilton-in-a-notebook-8ec0f85851ed)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
