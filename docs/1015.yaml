- en: Create Your Own Large Language Model Playground in SageMaker Studio
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åœ¨ SageMaker Studio ä¸­åˆ›å»ºä½ è‡ªå·±çš„å¤§è¯­è¨€æ¨¡å‹å®éªŒå®¤
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/create-your-own-large-language-model-playground-in-sagemaker-studio-1be5846c5089?source=collection_archive---------8-----------------------#2023-03-20](https://towardsdatascience.com/create-your-own-large-language-model-playground-in-sagemaker-studio-1be5846c5089?source=collection_archive---------8-----------------------#2023-03-20)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/create-your-own-large-language-model-playground-in-sagemaker-studio-1be5846c5089?source=collection_archive---------8-----------------------#2023-03-20](https://towardsdatascience.com/create-your-own-large-language-model-playground-in-sagemaker-studio-1be5846c5089?source=collection_archive---------8-----------------------#2023-03-20)
- en: Now you can deploy LLMs and experiment with them all in one place
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç°åœ¨ä½ å¯ä»¥åœ¨ä¸€ä¸ªåœ°æ–¹éƒ¨ç½²å’Œå®éªŒå¤§è¯­è¨€æ¨¡å‹
- en: '[](https://heiko-hotz.medium.com/?source=post_page-----1be5846c5089--------------------------------)[![Heiko
    Hotz](../Images/d08394d46d41d5cd9e76557a463be95e.png)](https://heiko-hotz.medium.com/?source=post_page-----1be5846c5089--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1be5846c5089--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1be5846c5089--------------------------------)
    [Heiko Hotz](https://heiko-hotz.medium.com/?source=post_page-----1be5846c5089--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://heiko-hotz.medium.com/?source=post_page-----1be5846c5089--------------------------------)[![Heiko
    Hotz](../Images/d08394d46d41d5cd9e76557a463be95e.png)](https://heiko-hotz.medium.com/?source=post_page-----1be5846c5089--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1be5846c5089--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1be5846c5089--------------------------------)
    [Heiko Hotz](https://heiko-hotz.medium.com/?source=post_page-----1be5846c5089--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F993c21f1b30f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-your-own-large-language-model-playground-in-sagemaker-studio-1be5846c5089&user=Heiko+Hotz&userId=993c21f1b30f&source=post_page-993c21f1b30f----1be5846c5089---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1be5846c5089--------------------------------)
    Â·4 min readÂ·Mar 20, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1be5846c5089&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-your-own-large-language-model-playground-in-sagemaker-studio-1be5846c5089&user=Heiko+Hotz&userId=993c21f1b30f&source=-----1be5846c5089---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F993c21f1b30f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-your-own-large-language-model-playground-in-sagemaker-studio-1be5846c5089&user=Heiko+Hotz&userId=993c21f1b30f&source=post_page-993c21f1b30f----1be5846c5089---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1be5846c5089--------------------------------)
    Â·4 min readÂ·2023å¹´3æœˆ20æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1be5846c5089&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-your-own-large-language-model-playground-in-sagemaker-studio-1be5846c5089&user=Heiko+Hotz&userId=993c21f1b30f&source=-----1be5846c5089---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1be5846c5089&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-your-own-large-language-model-playground-in-sagemaker-studio-1be5846c5089&source=-----1be5846c5089---------------------bookmark_footer-----------)![](../Images/297ddb414e85786a29359c9b3da09c2a.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1be5846c5089&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-your-own-large-language-model-playground-in-sagemaker-studio-1be5846c5089&source=-----1be5846c5089---------------------bookmark_footer-----------)![](../Images/297ddb414e85786a29359c9b3da09c2a.png)'
- en: Image by author â€” created with Midjourney
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾› â€” ä½¿ç”¨ Midjourney åˆ›å»º
- en: What is this about?
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä»€ä¹ˆå†…å®¹ï¼Ÿ
- en: Utilising large language models (LLMs) through a REST endpoint offers numerous
    benefits, but experimenting with them via API calls can be cumbersome. Below we
    can see how we can interact with a model that has been deployed to an Amazon SageMaker
    endpoint.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ REST ç«¯ç‚¹åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å…·æœ‰ä¼—å¤šä¼˜ç‚¹ï¼Œä½†é€šè¿‡ API è°ƒç”¨è¿›è¡Œå®éªŒå¯èƒ½ä¼šå¾ˆéº»çƒ¦ã€‚ä»¥ä¸‹æˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•ä¸å·²éƒ¨ç½²åˆ° Amazon SageMaker
    ç«¯ç‚¹çš„æ¨¡å‹è¿›è¡Œäº¤äº’ã€‚
- en: '![](../Images/45bb60e75133478567a98b8deb717a89.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/45bb60e75133478567a98b8deb717a89.png)'
- en: Image by author
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: To streamline this process, it would be advantageous to develop a playground
    app that allows for seamless interaction with the deployed model. In this tutorial,
    we will achieve this by using Amazon SageMaker (SM) Studio as our all-in-one IDE
    and deploy a Flan-T5-XXL model to a SageMaker endpoint and subsequently create
    a [Streamlit](https://streamlit.io/)-based playground app that can be accessed
    directly within Studio.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç®€åŒ–è¿™ä¸ªè¿‡ç¨‹ï¼Œå¼€å‘ä¸€ä¸ªå…è®¸ä¸å·²éƒ¨ç½²æ¨¡å‹æ— ç¼äº’åŠ¨çš„æ¸¸ä¹åœºåº”ç”¨å°†æ˜¯æœ‰åˆ©çš„ã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä½¿ç”¨Amazon SageMakerï¼ˆSMï¼‰Studioä½œä¸ºæˆ‘ä»¬çš„å…¨åŠŸèƒ½IDEï¼Œå¹¶å°†Flan-T5-XXLæ¨¡å‹éƒ¨ç½²åˆ°SageMakerç«¯ç‚¹ï¼Œéšååˆ›å»ºä¸€ä¸ªåŸºäº[Streamlit](https://streamlit.io/)çš„æ¸¸ä¹åœºåº”ç”¨ï¼Œç›´æ¥åœ¨Studioä¸­è®¿é—®ã€‚
- en: All of the code for this tutorial is available in this [GitHub repository](https://github.com/marshmellow77/deploy-flan-t5-sagemaker).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ•™ç¨‹çš„æ‰€æœ‰ä»£ç éƒ½å¯ä»¥åœ¨è¿™ä¸ª[GitHubä»“åº“](https://github.com/marshmellow77/deploy-flan-t5-sagemaker)ä¸­æ‰¾åˆ°ã€‚
- en: Why is it important?
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆè¿™å¾ˆé‡è¦ï¼Ÿ
- en: Assessing and contrasting different LLMs is crucial for organisations to identify
    the most fitting model for their unique requirements and to experiment quickly.
    A playground app presents the most accessible, rapid, and straightforward method
    for stakeholders (technical & non-technical) to experiment with deployed models.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: è¯„ä¼°å’Œå¯¹æ¯”ä¸åŒçš„LLMå¯¹ç»„ç»‡æ¥è¯´è‡³å…³é‡è¦ï¼Œä»¥ç¡®å®šæœ€é€‚åˆå…¶ç‹¬ç‰¹éœ€æ±‚çš„æ¨¡å‹ï¼Œå¹¶å¿«é€Ÿè¿›è¡Œå®éªŒã€‚ä¸€ä¸ªæ¸¸ä¹åœºåº”ç”¨æä¾›äº†æœ€ä¾¿æ·ã€å¿«é€Ÿå’Œç®€å•çš„æ–¹æ³•ï¼Œè®©åˆ©ç›Šç›¸å…³è€…ï¼ˆæ— è®ºæ˜¯æŠ€æœ¯äººå‘˜è¿˜æ˜¯éæŠ€æœ¯äººå‘˜ï¼‰å¯ä»¥å®éªŒå·²éƒ¨ç½²çš„æ¨¡å‹ã€‚
- en: In addition, utilising a playground app enhances comparison and promotes further
    customisation, such as incorporating feedback buttons and ranking the model output.
    These supplementary features enable users to offer feedback that enhances the
    modelâ€™s precision and overall performance. In essence, a playground app grants
    a more thorough comprehension of a modelâ€™s strengths and weaknesses, ultimately
    guiding well-informed decisions in choosing the most suitable LLM for the intended
    application.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œåˆ©ç”¨æ¸¸ä¹åœºåº”ç”¨å¯ä»¥å¢å¼ºå¯¹æ¯”ï¼Œå¹¶ä¿ƒè¿›è¿›ä¸€æ­¥çš„å®šåˆ¶ï¼Œä¾‹å¦‚åŠ å…¥åé¦ˆæŒ‰é’®å’Œå¯¹æ¨¡å‹è¾“å‡ºè¿›è¡Œæ’åã€‚è¿™äº›é™„åŠ åŠŸèƒ½ä½¿ç”¨æˆ·èƒ½å¤Ÿæä¾›åé¦ˆï¼Œæå‡æ¨¡å‹çš„ç²¾ç¡®æ€§å’Œæ•´ä½“æ€§èƒ½ã€‚å®è´¨ä¸Šï¼Œæ¸¸ä¹åœºåº”ç”¨æä¾›äº†å¯¹æ¨¡å‹ä¼˜åŠ¿å’ŒåŠ£åŠ¿çš„æ›´æ·±å…¥ç†è§£ï¼Œæœ€ç»ˆå¸®åŠ©åšå‡ºæ˜æ™ºçš„å†³å®šï¼Œä»¥é€‰æ‹©æœ€é€‚åˆåº”ç”¨çš„LLMã€‚
- en: Letâ€™s get started!
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¼€å§‹å§ï¼
- en: Deploying the Flan-T5-XXL model
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: éƒ¨ç½²Flan-T5-XXLæ¨¡å‹
- en: Before we can set up the playground we need to set up a REST API to access our
    model. Fortunately this is very straightforward in SageMaker. Similarly to what
    we have done when we [deployed the Flan-UL2 model](https://medium.com/better-programming/deploy-flan-ul2-on-a-single-gpu-1778dac605f3),
    we can write an inference script that downloads the model from the [Hugging Face
    Model Hub](https://huggingface.co/models) and deploys it to a SageMaker endpoint.
    That endpoint then provides us with a REST API that we can access within our AWS
    account without having to use API Gateway on top.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬å¯ä»¥è®¾ç½®æ¸¸ä¹åœºä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦è®¾ç½®ä¸€ä¸ªREST APIæ¥è®¿é—®æˆ‘ä»¬çš„æ¨¡å‹ã€‚å¹¸è¿çš„æ˜¯ï¼Œåœ¨SageMakerä¸­è¿™éå¸¸ç®€å•ã€‚ç±»ä¼¼äºæˆ‘ä»¬[éƒ¨ç½²Flan-UL2æ¨¡å‹](https://medium.com/better-programming/deploy-flan-ul2-on-a-single-gpu-1778dac605f3)æ—¶æ‰€åšçš„é‚£æ ·ï¼Œæˆ‘ä»¬å¯ä»¥ç¼–å†™ä¸€ä¸ªæ¨ç†è„šæœ¬ï¼Œä»[Hugging
    Face Model Hub](https://huggingface.co/models)ä¸‹è½½æ¨¡å‹ï¼Œå¹¶å°†å…¶éƒ¨ç½²åˆ°SageMakerç«¯ç‚¹ã€‚è¿™ä¸ªç«¯ç‚¹éšåä¸ºæˆ‘ä»¬æä¾›ä¸€ä¸ªREST
    APIï¼Œæˆ‘ä»¬å¯ä»¥åœ¨AWSè´¦æˆ·å†…è®¿é—®ï¼Œè€Œä¸å¿…ä½¿ç”¨API Gatewayã€‚
- en: Note that we are using the option to load the model in 8 bit which allows us
    to deploy the model onto a single GPU (G5 instance).
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†8ä½åŠ è½½æ¨¡å‹çš„é€‰é¡¹ï¼Œè¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿå°†æ¨¡å‹éƒ¨ç½²åˆ°å•ä¸ªGPUï¼ˆG5å®ä¾‹ï¼‰ä¸Šã€‚
- en: 'Once we have the inference script ready we can deploy the model with just one
    command:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æˆ‘ä»¬å‡†å¤‡å¥½æ¨ç†è„šæœ¬ï¼Œå°±å¯ä»¥é€šè¿‡ä¸€ä¸ªå‘½ä»¤éƒ¨ç½²æ¨¡å‹ï¼š
- en: For more detailed information check out the deployment notebook and my previous
    [blog post on deploying Flan-UL2](https://medium.com/better-programming/deploy-flan-ul2-on-a-single-gpu-1778dac605f3).
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ¬²äº†è§£æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹éƒ¨ç½²ç¬”è®°æœ¬å’Œæˆ‘ä¹‹å‰çš„[å…³äºéƒ¨ç½²Flan-UL2çš„åšå®¢æ–‡ç« ](https://medium.com/better-programming/deploy-flan-ul2-on-a-single-gpu-1778dac605f3)ã€‚
- en: Once the endpoint is up and running we can get to the fun part â€” setting up
    a playground app to interact with the model.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦ç«¯ç‚¹å¯åŠ¨å¹¶è¿è¡Œï¼Œæˆ‘ä»¬å°±å¯ä»¥å¼€å§‹æœ‰è¶£çš„éƒ¨åˆ†â€”â€”è®¾ç½®ä¸€ä¸ªæ¸¸ä¹åœºåº”ç”¨ä»¥ä¸æ¨¡å‹äº’åŠ¨ã€‚
- en: Playground app
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¸¸ä¹åœºåº”ç”¨
- en: We will employ Streamlit to develop a streamlined playground app. With just
    a few lines of code, it enables us to create a text box and showcase various generation
    parameters within a user-friendly interface. You are welcome to modify the app
    and exhibit an alternate set of generation parameters for even greater control
    over the text generation procedure.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨Streamlitå¼€å‘ä¸€ä¸ªç²¾ç®€çš„æ¸¸ä¹åœºåº”ç”¨ã€‚åªéœ€å‡ è¡Œä»£ç ï¼Œå®ƒå°±èƒ½è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ–‡æœ¬æ¡†ï¼Œå¹¶åœ¨ç”¨æˆ·å‹å¥½çš„ç•Œé¢ä¸­å±•ç¤ºå„ç§ç”Ÿæˆå‚æ•°ã€‚æ¬¢è¿æ‚¨ä¿®æ”¹åº”ç”¨ï¼Œå¹¶å±•ç¤ºä¸€ç»„ä¸åŒçš„ç”Ÿæˆå‚æ•°ï¼Œä»¥ä¾¿æ›´å¥½åœ°æ§åˆ¶æ–‡æœ¬ç”Ÿæˆè¿‡ç¨‹ã€‚
- en: A list of all generation parameters can be found [here](https://huggingface.co/docs/transformers/main/en/main_classes/text_generation#transformers.GenerationConfig).
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ‰€æœ‰ç”Ÿæˆå‚æ•°çš„åˆ—è¡¨å¯ä»¥åœ¨[è¿™é‡Œ](https://huggingface.co/docs/transformers/main/en/main_classes/text_generation#transformers.GenerationConfig)æ‰¾åˆ°ã€‚
- en: Note that you will have to specify the endpoint name in line 10 which you can
    retrieve from the deployment notebook of the SageMaker console.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œä½ éœ€è¦åœ¨ç¬¬10è¡ŒæŒ‡å®šç»ˆç«¯åç§°ï¼Œä½ å¯ä»¥ä»SageMakeræ§åˆ¶å°çš„éƒ¨ç½²ç¬”è®°æœ¬ä¸­è·å–ã€‚
- en: Test
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æµ‹è¯•
- en: Now itâ€™s time to deploy and test our playground app. Inspired by the documentation
    on how to use [TensorBoard in SM Studio](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-tensorboard.html),
    we can use the same mechanism to spin up our Streamlit app in SM Studio.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ˜¯æ—¶å€™éƒ¨ç½²å’Œæµ‹è¯•æˆ‘ä»¬çš„å®éªŒå¹³å°åº”ç”¨ç¨‹åºäº†ã€‚å—[TensorBoardåœ¨SM Studioä¸­çš„ä½¿ç”¨è¯´æ˜](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-tensorboard.html)çš„å¯å‘ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç›¸åŒçš„æœºåˆ¶åœ¨SM
    Studioä¸­å¯åŠ¨æˆ‘ä»¬çš„Streamlitåº”ç”¨ã€‚
- en: To do so, we can execute the command `streamlit run flan-t5-playground.py --server.port
    6006` in the terminal. After that we will be able to access the playground on
    `https://<YOUR_STUDIO_ID>.studio.<YOUR_REGION>.sagemaker.aws/jupyter/default/proxy/6006/`.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ç»ˆç«¯æ‰§è¡Œå‘½ä»¤`streamlit run flan-t5-playground.py --server.port 6006`ã€‚ä¹‹åï¼Œæˆ‘ä»¬å°†èƒ½å¤Ÿé€šè¿‡`https://<YOUR_STUDIO_ID>.studio.<YOUR_REGION>.sagemaker.aws/jupyter/default/proxy/6006/`è®¿é—®è¿™ä¸ªå®éªŒå¹³å°ã€‚
- en: '![](../Images/045aca51c07037d80dea313f5eb8e1a8.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/045aca51c07037d80dea313f5eb8e1a8.png)'
- en: Image by author
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„å›¾ç‰‡
- en: Conclusion
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: In this tutorial, we successfully deployed a cutting-edge language model and
    established a playground app within a single environment, SageMaker Studio. The
    process of initiating LLM experimentation has never been more straightforward.
    I hope you found this information valuable, and please feel free to reach out
    if you have any questions or require further assistance.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬æˆåŠŸéƒ¨ç½²äº†ä¸€ä¸ªå‰æ²¿è¯­è¨€æ¨¡å‹ï¼Œå¹¶åœ¨å•ä¸€ç¯å¢ƒSageMaker Studioä¸­å»ºç«‹äº†ä¸€ä¸ªå®éªŒå¹³å°ã€‚å¯åŠ¨LLMå®éªŒçš„è¿‡ç¨‹ä»æœªå¦‚æ­¤ç®€å•ã€‚å¸Œæœ›ä½ è§‰å¾—è¿™äº›ä¿¡æ¯æœ‰ä»·å€¼ï¼Œå¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦è¿›ä¸€æ­¥çš„å¸®åŠ©ï¼Œè¯·éšæ—¶è”ç³»æˆ‘ã€‚
- en: Heiko Hotz
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Heiko Hotz
- en: ğŸ‘‹ Follow me on [Medium](https://heiko-hotz.medium.com/) and [LinkedIn](https://www.linkedin.com/in/heikohotz/)
    to read more about Generative AI, Machine Learning, and Natural Language Processing.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ‘‹ å…³æ³¨æˆ‘åœ¨[Medium](https://heiko-hotz.medium.com/)å’Œ[LinkedIn](https://www.linkedin.com/in/heikohotz/)ä¸Šï¼Œé˜…è¯»æ›´å¤šå…³äºç”ŸæˆAIã€æœºå™¨å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€å¤„ç†çš„å†…å®¹ã€‚
- en: ğŸ‘¥ If youâ€™re based in London join one of our [NLP London Meetups](https://www.meetup.com/nlp_london/).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ‘¥ å¦‚æœä½ åœ¨ä¼¦æ•¦ï¼Œæ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„[NLP London Meetups](https://www.meetup.com/nlp_london/)ã€‚
- en: '![](../Images/e6d9bd71d244a777df727c64afaa8f1b.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e6d9bd71d244a777df727c64afaa8f1b.png)'
- en: '[https://www.linkedin.com/in/heikohotz/](https://www.linkedin.com/in/heikohotz/)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.linkedin.com/in/heikohotz/](https://www.linkedin.com/in/heikohotz/)'
