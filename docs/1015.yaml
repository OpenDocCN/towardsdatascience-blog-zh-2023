- en: Create Your Own Large Language Model Playground in SageMaker Studio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://towardsdatascience.com/create-your-own-large-language-model-playground-in-sagemaker-studio-1be5846c5089?source=collection_archive---------8-----------------------#2023-03-20](https://towardsdatascience.com/create-your-own-large-language-model-playground-in-sagemaker-studio-1be5846c5089?source=collection_archive---------8-----------------------#2023-03-20)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Now you can deploy LLMs and experiment with them all in one place
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://heiko-hotz.medium.com/?source=post_page-----1be5846c5089--------------------------------)[![Heiko
    Hotz](../Images/d08394d46d41d5cd9e76557a463be95e.png)](https://heiko-hotz.medium.com/?source=post_page-----1be5846c5089--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1be5846c5089--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1be5846c5089--------------------------------)
    [Heiko Hotz](https://heiko-hotz.medium.com/?source=post_page-----1be5846c5089--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Â·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F993c21f1b30f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-your-own-large-language-model-playground-in-sagemaker-studio-1be5846c5089&user=Heiko+Hotz&userId=993c21f1b30f&source=post_page-993c21f1b30f----1be5846c5089---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1be5846c5089--------------------------------)
    Â·4 min readÂ·Mar 20, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1be5846c5089&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-your-own-large-language-model-playground-in-sagemaker-studio-1be5846c5089&user=Heiko+Hotz&userId=993c21f1b30f&source=-----1be5846c5089---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1be5846c5089&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-your-own-large-language-model-playground-in-sagemaker-studio-1be5846c5089&source=-----1be5846c5089---------------------bookmark_footer-----------)![](../Images/297ddb414e85786a29359c9b3da09c2a.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image by author â€” created with Midjourney
  prefs: []
  type: TYPE_NORMAL
- en: What is this about?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Utilising large language models (LLMs) through a REST endpoint offers numerous
    benefits, but experimenting with them via API calls can be cumbersome. Below we
    can see how we can interact with a model that has been deployed to an Amazon SageMaker
    endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/45bb60e75133478567a98b8deb717a89.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: To streamline this process, it would be advantageous to develop a playground
    app that allows for seamless interaction with the deployed model. In this tutorial,
    we will achieve this by using Amazon SageMaker (SM) Studio as our all-in-one IDE
    and deploy a Flan-T5-XXL model to a SageMaker endpoint and subsequently create
    a [Streamlit](https://streamlit.io/)-based playground app that can be accessed
    directly within Studio.
  prefs: []
  type: TYPE_NORMAL
- en: All of the code for this tutorial is available in this [GitHub repository](https://github.com/marshmellow77/deploy-flan-t5-sagemaker).
  prefs: []
  type: TYPE_NORMAL
- en: Why is it important?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Assessing and contrasting different LLMs is crucial for organisations to identify
    the most fitting model for their unique requirements and to experiment quickly.
    A playground app presents the most accessible, rapid, and straightforward method
    for stakeholders (technical & non-technical) to experiment with deployed models.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, utilising a playground app enhances comparison and promotes further
    customisation, such as incorporating feedback buttons and ranking the model output.
    These supplementary features enable users to offer feedback that enhances the
    modelâ€™s precision and overall performance. In essence, a playground app grants
    a more thorough comprehension of a modelâ€™s strengths and weaknesses, ultimately
    guiding well-informed decisions in choosing the most suitable LLM for the intended
    application.
  prefs: []
  type: TYPE_NORMAL
- en: Letâ€™s get started!
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the Flan-T5-XXL model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we can set up the playground we need to set up a REST API to access our
    model. Fortunately this is very straightforward in SageMaker. Similarly to what
    we have done when we [deployed the Flan-UL2 model](https://medium.com/better-programming/deploy-flan-ul2-on-a-single-gpu-1778dac605f3),
    we can write an inference script that downloads the model from the [Hugging Face
    Model Hub](https://huggingface.co/models) and deploys it to a SageMaker endpoint.
    That endpoint then provides us with a REST API that we can access within our AWS
    account without having to use API Gateway on top.
  prefs: []
  type: TYPE_NORMAL
- en: Note that we are using the option to load the model in 8 bit which allows us
    to deploy the model onto a single GPU (G5 instance).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Once we have the inference script ready we can deploy the model with just one
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: For more detailed information check out the deployment notebook and my previous
    [blog post on deploying Flan-UL2](https://medium.com/better-programming/deploy-flan-ul2-on-a-single-gpu-1778dac605f3).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Once the endpoint is up and running we can get to the fun part â€” setting up
    a playground app to interact with the model.
  prefs: []
  type: TYPE_NORMAL
- en: Playground app
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will employ Streamlit to develop a streamlined playground app. With just
    a few lines of code, it enables us to create a text box and showcase various generation
    parameters within a user-friendly interface. You are welcome to modify the app
    and exhibit an alternate set of generation parameters for even greater control
    over the text generation procedure.
  prefs: []
  type: TYPE_NORMAL
- en: A list of all generation parameters can be found [here](https://huggingface.co/docs/transformers/main/en/main_classes/text_generation#transformers.GenerationConfig).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Note that you will have to specify the endpoint name in line 10 which you can
    retrieve from the deployment notebook of the SageMaker console.
  prefs: []
  type: TYPE_NORMAL
- en: Test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now itâ€™s time to deploy and test our playground app. Inspired by the documentation
    on how to use [TensorBoard in SM Studio](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-tensorboard.html),
    we can use the same mechanism to spin up our Streamlit app in SM Studio.
  prefs: []
  type: TYPE_NORMAL
- en: To do so, we can execute the command `streamlit run flan-t5-playground.py --server.port
    6006` in the terminal. After that we will be able to access the playground on
    `https://<YOUR_STUDIO_ID>.studio.<YOUR_REGION>.sagemaker.aws/jupyter/default/proxy/6006/`.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/045aca51c07037d80dea313f5eb8e1a8.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this tutorial, we successfully deployed a cutting-edge language model and
    established a playground app within a single environment, SageMaker Studio. The
    process of initiating LLM experimentation has never been more straightforward.
    I hope you found this information valuable, and please feel free to reach out
    if you have any questions or require further assistance.
  prefs: []
  type: TYPE_NORMAL
- en: Heiko Hotz
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ðŸ‘‹ Follow me on [Medium](https://heiko-hotz.medium.com/) and [LinkedIn](https://www.linkedin.com/in/heikohotz/)
    to read more about Generative AI, Machine Learning, and Natural Language Processing.
  prefs: []
  type: TYPE_NORMAL
- en: ðŸ‘¥ If youâ€™re based in London join one of our [NLP London Meetups](https://www.meetup.com/nlp_london/).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e6d9bd71d244a777df727c64afaa8f1b.png)'
  prefs: []
  type: TYPE_IMG
- en: '[https://www.linkedin.com/in/heikohotz/](https://www.linkedin.com/in/heikohotz/)'
  prefs: []
  type: TYPE_NORMAL
