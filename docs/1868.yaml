- en: 'Unbox the Cox: Intuitive Guide to Cox Regressions'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解锁Cox回归：Cox回归的直观指南
- en: 原文：[https://towardsdatascience.com/unbox-the-cox-intuitive-guide-to-cox-regressions-c485408ae15d?source=collection_archive---------11-----------------------#2023-06-06](https://towardsdatascience.com/unbox-the-cox-intuitive-guide-to-cox-regressions-c485408ae15d?source=collection_archive---------11-----------------------#2023-06-06)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/unbox-the-cox-intuitive-guide-to-cox-regressions-c485408ae15d?source=collection_archive---------11-----------------------#2023-06-06](https://towardsdatascience.com/unbox-the-cox-intuitive-guide-to-cox-regressions-c485408ae15d?source=collection_archive---------11-----------------------#2023-06-06)
- en: How do hazards and maximum likelihood estimates predict event rankings?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 风险和最大似然估计如何预测事件排名？
- en: '[](https://medium.com/@igor-s?source=post_page-----c485408ae15d--------------------------------)[![Igor
    Šegota](../Images/17c592b71fef9526a0679d47937837f6.png)](https://medium.com/@igor-s?source=post_page-----c485408ae15d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c485408ae15d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c485408ae15d--------------------------------)
    [Igor Šegota](https://medium.com/@igor-s?source=post_page-----c485408ae15d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@igor-s?source=post_page-----c485408ae15d--------------------------------)[![Igor
    Šegota](../Images/17c592b71fef9526a0679d47937837f6.png)](https://medium.com/@igor-s?source=post_page-----c485408ae15d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c485408ae15d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c485408ae15d--------------------------------)
    [Igor Šegota](https://medium.com/@igor-s?source=post_page-----c485408ae15d--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe5f8ebca4ad8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funbox-the-cox-intuitive-guide-to-cox-regressions-c485408ae15d&user=Igor+%C5%A0egota&userId=e5f8ebca4ad8&source=post_page-e5f8ebca4ad8----c485408ae15d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c485408ae15d--------------------------------)
    ·10 min read·Jun 6, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc485408ae15d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funbox-the-cox-intuitive-guide-to-cox-regressions-c485408ae15d&user=Igor+%C5%A0egota&userId=e5f8ebca4ad8&source=-----c485408ae15d---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe5f8ebca4ad8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funbox-the-cox-intuitive-guide-to-cox-regressions-c485408ae15d&user=Igor+%C5%A0egota&userId=e5f8ebca4ad8&source=post_page-e5f8ebca4ad8----c485408ae15d---------------------post_header-----------)
    发表在[Towards Data Science](https://towardsdatascience.com/?source=post_page-----c485408ae15d--------------------------------)
    ·10分钟阅读·2023年6月6日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc485408ae15d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funbox-the-cox-intuitive-guide-to-cox-regressions-c485408ae15d&user=Igor+%C5%A0egota&userId=e5f8ebca4ad8&source=-----c485408ae15d---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc485408ae15d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funbox-the-cox-intuitive-guide-to-cox-regressions-c485408ae15d&source=-----c485408ae15d---------------------bookmark_footer-----------)![](../Images/9eb4923328ea3ea068ceed2c39230ac5.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc485408ae15d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funbox-the-cox-intuitive-guide-to-cox-regressions-c485408ae15d&source=-----c485408ae15d---------------------bookmark_footer-----------)![](../Images/9eb4923328ea3ea068ceed2c39230ac5.png)'
- en: Photo by [Chris Boyer](https://unsplash.com/fr/@csgboyer?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Chris Boyer](https://unsplash.com/fr/@csgboyer?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: The goal of Cox regression is to model the relationship between predictor variables
    and the time it takes for an event to happen — like events that only happen once.
    Let’s dive into a made-up dataset with 5 subjects, labeled A to E. During the
    study, each subject either experienced an event (event = 1) or not (event = 0).
    On top of that, each subject got assigned a single predictor, let’s call it *x*,
    before the study. As a practical example, if we are tracking the death events,
    then *x* could be the dosage of a drug we are testing to see if it helps people
    live longer, by affecting the time until death.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Cox 回归的目标是建模预测变量与事件发生所需时间之间的关系——例如只发生一次的事件。我们来看一个虚构的数据集，包含5个受试者，标记为A到E。在研究期间，每个受试者要么经历了事件（事件
    = 1），要么没有（事件 = 0）。此外，每个受试者在研究前都被分配了一个预测变量，我们称之为 *x*。作为一个实际例子，如果我们跟踪死亡事件，那么 *x*
    可能是我们正在测试的药物剂量，看看它是否通过影响直到死亡的时间来帮助人们活得更久。
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/3fb26d1a5d08f6457756d77a06975e25.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3fb26d1a5d08f6457756d77a06975e25.png)'
- en: 'In this dataset, subject E did not experience anything during the study, so
    we set event = 0 and the time assigned is basically the last moment we knew about
    them. This kind of data is called “censored” because we have no clue if the event
    happened after the study ended. To make it easier to understand, a cool “lollipop”
    🍭 plot comes in handy for visualizing this type of data:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个数据集中，受试者E在研究期间没有经历任何事件，因此我们将事件设置为0，分配的时间基本上是我们最后一次知道他们的时间。这种数据被称为“删失数据”，因为我们不知道事件是否在研究结束后发生。为了更容易理解，使用一个酷炫的“棒棒糖”🍭图来可视化这种类型的数据非常有用：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/96788e4368f5a669934f3b5990c8f847.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/96788e4368f5a669934f3b5990c8f847.png)'
- en: Lines indicate the duration of time each subject experienced before an event,
    which is represented by a filled circle. Subject E does not have a circle since
    it survived the entire study.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 线条表示每个受试者在事件发生之前经历的时间，事件由填充的圆圈表示。受试者E没有圆圈，因为他在整个研究期间都存活。
- en: (️️Plotting functions available on my [Github repo](https://github.com/igor-sb/blog/blob/main/posts/cox/plots.py).)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: (️️绘制函数可以在我的 [Github 仓库](https://github.com/igor-sb/blog/blob/main/posts/cox/plots.py)
    中找到。)
- en: 'Just a heads up: I want to make the main ideas of Cox regression easier to
    grasp, so we will focus on data where only one event can happen at a given time
    (no ties).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 提个醒：我希望让Cox回归的主要思想更易于理解，因此我们将专注于在给定时间只能发生一个事件的数据（没有平局）。
- en: Hazards
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 危险度
- en: 'Hazard represents the instant rate (probability per unit time) at which an
    event can occur at a specific time — assuming the event has not occurred before
    that point. Since it is a rate at which events take place, it can have arbitrary
    units and unlike probability, hazard values can range between 0 and infinity:
    [0, ∞).'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 危险度表示事件在特定时间点发生的瞬时率（单位时间内的概率）——假设在此之前事件尚未发生。由于这是一个事件发生的速率，它可以具有任意单位，与概率不同，危险度值可以在0到无穷大之间变化：[0,
    ∞)。
- en: In Cox regression, hazard works similar to the odds in logistic regression.
    In logistic regression, odds = p/(1-p) takes probabilities from the range of [0,
    1] and transforms them to a range of [0, ∞). Then, taking the logarithm converts
    the odds to log-odds, which can have values from negative infinity to positive
    infinity (-∞, ∞). This log-odds transformation of probabilities is done to match
    the possible output values to the linear combination of predictors *β₁x₁ + β₂x₂
    + …*, which also can range (-∞, ∞).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在Cox回归中，危险度的工作方式类似于逻辑回归中的赔率。在逻辑回归中，赔率 = p/(1-p) 将概率范围 [0, 1] 转换为 [0, ∞) 的范围。然后，取对数将赔率转换为对数赔率，其值可以从负无穷到正无穷
    (-∞, ∞)。这种对数赔率的概率变换是为了将可能的输出值与预测变量 *β₁x₁ + β₂x₂ + …* 的线性组合匹配，后者的范围也可以是 (-∞, ∞)。
- en: 'Here, we start with a hazard h(t, x) that already has values ranging from 0
    to infinity [0, ∞). By applying a logarithm, we transform that range to (-∞, ∞),
    allowing it to be fitted with a linear combination of predictors:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们从一个危险度 h(t, x) 开始，它的值范围已经是从0到无穷大 [0, ∞)。通过应用对数变换，我们将该范围转变为 (-∞, ∞)，从而允许用预测变量的线性组合进行拟合：
- en: '![](../Images/fc0695bae7d071593adceb20df485e57.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fc0695bae7d071593adceb20df485e57.png)'
- en: 'In Cox regression, there’s another assumption that helps make things easier.
    It assumes that all the time dependence of the log-hazard is packed into the intercept
    term:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在Cox回归中，还有一个假设有助于简化问题。它假设对数危险度的所有时间依赖性都包含在截距项中：
- en: '![](../Images/531233308f98f878371c83f7fcb1115d.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/531233308f98f878371c83f7fcb1115d.png)'
- en: 'The motivation behind this assumption is to simplify the fitting process significantly
    (we will show how in a moment). In the literature, the intercept term *β₀(t)*
    is usually moved to the left side of this equation and expressed as a *baseline
    hazard* *log[h₀(t)]*:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这一假设的动机是为了显著简化拟合过程（我们稍后将展示具体方法）。在文献中，截距项 *β₀(t)* 通常被移到方程的左侧，并表示为 *基线风险* *log[h₀(t)]*：
- en: '![](../Images/4f5424d6048b6c1fed45d84545dadf02.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f5424d6048b6c1fed45d84545dadf02.png)'
- en: 'From this equation, we can expressed the hazard *h(t, x)*:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个方程中，我们可以表示风险 *h(t, x)*：
- en: '![](../Images/f3954fe815dc8cd628e927d940715235.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f3954fe815dc8cd628e927d940715235.png)'
- en: 'Now, here is the cool part: since the data from each subject only comes to
    hazard through predictors *x*, every subject’s hazard has the same time dependence.
    The only difference lies in the *exp(βx)* part, which makes hazards from different
    subjects proportional to each other. That’s why this model is also called a “proportional
    hazard” model.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这里是有趣的部分：由于每个被试的数据通过预测变量 *x* 仅影响风险，因此每个被试的风险具有相同的时间依赖性。唯一的区别在于 *exp(βx)*
    部分，这使得来自不同被试的风险相互成比例。这就是为什么这个模型也被称为“比例风险”模型。
- en: 'We have been drawing a lot of parallels to the logistic regression. If you
    read my previous post on logistic regression:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将很多逻辑回归的类比提及了。如果你阅读了我之前关于逻辑回归的帖子：
- en: '[](/logistic-regression-faceoff-67560de4f492?source=post_page-----c485408ae15d--------------------------------)
    [## Logistic regression: Faceoff'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/logistic-regression-faceoff-67560de4f492?source=post_page-----c485408ae15d--------------------------------)
    [## 逻辑回归：对决'
- en: What do log-losses and perfectly separated data have to do with hockey sticks?
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 对数损失和完全分离的数据与曲棍球棒有什么关系？
- en: towardsdatascience.com](/logistic-regression-faceoff-67560de4f492?source=post_page-----c485408ae15d--------------------------------)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/logistic-regression-faceoff-67560de4f492?source=post_page-----c485408ae15d--------------------------------)
- en: you may be wondering if Cox regression also suffers from predictors being “too
    good”. Stay tuned for the next post which will cover that!
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道 Cox 回归是否也会受到预测变量“过于优秀”的影响。请继续关注下一篇文章，我们将讨论这一点！
- en: Likelihoods
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可能性
- en: 'Cox models are fit using a method called Maximum Likelihood Estimation (MLE).
    Likelihoods are quite similar to probabilities: they share the same equation —
    almost like two sides of the same coin. Probabilities are functions of data *x*,
    with fixed model parameters *β*s, while likelihoods are functions of *β*s, with
    fixed *x*. It‘s like looking at the probability density of a Normal distribution,
    but instead of focusing on *x*, we focus on *μ* and *σ*.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Cox 模型使用一种称为最大似然估计（MLE）的方法进行拟合。可能性与概率非常相似：它们共享相同的方程——几乎就像是同一枚硬币的两面。概率是数据 *x*
    的函数，模型参数 *β* 固定，而可能性是 *β* 的函数，*x* 固定。这就像是查看正态分布的概率密度，但不是关注 *x*，而是关注 *μ* 和 *σ*。
- en: 'The MLE fitting process begins with a rank-order of event occurrence. In our
    made-up data this order is: A, B, D, C, with E censored. This is the only instance
    where time comes into play in Cox regression. **The actual numeric values of event
    times do not matter at all, as long as the subjects experience the events in the
    same order.**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: MLE 拟合过程始于事件发生的排序。在我们编造的数据中，这个顺序是：A、B、D、C，E 为删失。这是 Cox 回归中唯一涉及时间的情况。**事件时间的实际数值完全不重要，只要被试经历事件的顺序相同。**
- en: 'We then move on to each subject one by one and estimate the probability or
    likelihood of that subject experiencing an event compared to all the other subjects
    who are *still at risk* of having an event. For instance, take subject A who experienced
    an event at t = 1\. The likelihood of this happening is determined by the hazard
    rate at which subject A experiences the event, relative to the combined hazard
    rates of everyone else who is still at risk at t = 1 (which includes everyone):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们逐个处理每个被试，并估计该被试经历事件的概率或可能性，相对于所有其他仍处于 *风险之中的* 被试。例如，考虑被试 A，在 t = 1 时经历了事件。这一事件发生的可能性由被试
    A 经历事件的风险率决定，相对于 t = 1 时所有其他仍处于风险中的人的综合风险率（包括所有人）：
- en: '![](../Images/22bde743e454b44530da2e6409211ca6.png)![](../Images/54b824e014a5d03c06363b78f76dccc3.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/22bde743e454b44530da2e6409211ca6.png)![](../Images/54b824e014a5d03c06363b78f76dccc3.png)'
- en: As you may have noticed, we did not bother defining the baseline hazard *h₀(t)*
    because it actually cancels out completely from the likelihood calculation.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所注意到的，我们没有定义基线风险 *h₀(t)*，因为它实际上在可能性计算中完全抵消了。
- en: 'Once we substitute the values for *x* (-1.7, -0.4, 0.0, 0.9, 1.2) for each
    subject, we end up with an equation that only has *β* left:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们为每个主题代入值 *x*（-1.7、-0.4、0.0、0.9、1.2），我们会得到一个仅剩下 *β* 的方程：
- en: '![](../Images/879d7ce7c23fe47b1fa333f0162c8f52.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/879d7ce7c23fe47b1fa333f0162c8f52.png)'
- en: 'From this point on, for any time after t = 1, the hazard of subject A is considered
    zero and is not taken into account when calculating further likelihoods. For instance,
    at another time, t = 3, subject B experiences an event. So, the likelihood for
    subject B is determined relative to the hazards of subjects B through E only:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 从这一点起，在 t = 1 之后的任何时间，主题 A 的风险被认为是零，并且在计算进一步的似然值时不会考虑。例如，在另一个时间 t = 3，主题 B 发生了事件。因此，主题
    B 的似然值是相对于主题 B 到 E 的风险来确定的：
- en: '![](../Images/3faac948b82115b83c1d3cc217e6d64c.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3faac948b82115b83c1d3cc217e6d64c.png)'
- en: We could keep going and calculate the likelihoods for all subjects A through
    D, but we will cover that in the coding part in the next section. Subject E, being
    censored and not experiencing an event does not have its own likelihood. Since
    the censored data is only used in the likelihoods of uncensored subjects, the
    resulting combined likelihood is often referred to as “partial likelihood”.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以继续计算所有主题 A 到 D 的似然值，但这将在下一部分的编码中进行。由于主题 E 是被审查的且未发生事件，所以它没有自己的似然值。由于审查数据仅用于未审查主题的似然值中，因此结果组合的似然值通常被称为“部分似然”。
- en: 'To summarize this process, we can create an animated lollipop plot:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结这个过程，我们可以创建一个动画棒棒糖图：
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/5a032e3aeb7bd02f84175c9d0adcdff6.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5a032e3aeb7bd02f84175c9d0adcdff6.png)'
- en: Finding β
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查找 β
- en: 'When events occur independently of each other, the joint probability or likelihood
    of observing all events can be calculated by multiplying individual likelihoods,
    denoted as *L= L(A) L(B) L(C) L(D)*. However, multiplying exponential expressions
    can lead to numerical errors, so we often take the logarithm of this likelihood.
    By applying the logarithm, we transform the product of likelihoods into a sum
    of log-likelihoods:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当事件彼此独立发生时，观察所有事件的联合概率或似然值可以通过乘以各个似然值来计算，表示为 *L= L(A) L(B) L(C) L(D)*。然而，乘法的指数表达式可能导致数值误差，因此我们通常取该似然值的对数。通过应用对数，我们将似然值的乘积转换为对数似然值的总和：
- en: '![](../Images/d69effc0790722ed973c9fbc57e3dbf8.png)![](../Images/b1eb9b567f2776034ddfcd328389df9f.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d69effc0790722ed973c9fbc57e3dbf8.png)![](../Images/b1eb9b567f2776034ddfcd328389df9f.png)'
- en: Since the logarithm is a monotonic function, both the likelihood and the log-likelihood
    reach their maximum point at the same value of *β*. To facilitate visualization
    and enable comparison with other cost functions, we can define a cost as the negative
    log-likelihood and aim to minimize it instead.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 由于对数是单调函数，似然值和对数似然值在相同的 *β* 值下达到最大值。为了便于可视化和与其他成本函数进行比较，我们可以将成本定义为负对数似然值，并旨在最小化它。
- en: Ready, Set, Code!
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备好，开始编码！
- en: 'We can implement this algorithm in Python, step by step. First, we need to
    extract the event time and predictor *x* for each uncensored subject. This can
    be accomplished using the function `event_time_and_x_from_subject()`. Once we
    have the event time for a subject, we can subset our data frame to identify the
    rows corresponding to all subjects who are still at risk. This is achieved using
    the function `subjects_at_risk_data()`. Finally, we calculate the log-likelihood
    for each subject using the function `log_likelihood()`:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以逐步在 Python 中实现这个算法。首先，我们需要提取每个未审查主题的事件时间和预测变量 *x*。这可以通过函数 `event_time_and_x_from_subject()`
    完成。一旦我们得到主题的事件时间，我们可以对数据框进行子集处理，以识别所有仍在风险中的主题的行。这是通过函数 `subjects_at_risk_data()`
    实现的。最后，我们使用函数 `log_likelihood()` 计算每个主题的对数似然值：
- en: '[PRE3]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'For visualization purposes, we plot the cost or negative log-likelihoods. Therefore,
    we need to compute these values for each subject at a specific *β* value:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化，我们绘制成本或负对数似然值。因此，我们需要计算每个主题在特定 *β* 值下的这些值：
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To find the minimum cost, we sweep through the range of *β* values:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到最小成本，我们遍历 *β* 值的范围：
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/c8e55f4725d681c1cc1c6e001ac32640.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c8e55f4725d681c1cc1c6e001ac32640.png)'
- en: Making sense of it all
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解这一切
- en: 'Rather than aggregating the data frame by summing the log-likelihoods grouped
    by subject, we can keep it in its current form and visualize it as stacked bar
    charts. In this visualization, the total height of each bar corresponds to the
    sum of negative log-likelihoods. Each subject is represented by a different color
    within the bar, indicating their individual likelihood and contribution to the
    overall likelihood:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 与其通过按受试者分组的对数似然度求和来聚合数据框，不如保持其当前形式并将其可视化为堆叠条形图。在这个可视化中，每个条形图的总高度对应于负对数似然度的总和。每个受试者在条形图中用不同的颜色表示，指示他们的个体似然度及其对整体似然度的贡献：
- en: '[PRE6]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/80e3ddfac00be7575824dad21f243b1d.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/80e3ddfac00be7575824dad21f243b1d.png)'
- en: Each narrow vertical colored bar represents the individual negative log-likelihood.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 每个狭窄的垂直彩色条表示个体负对数似然度。
- en: Let’s understand how to interpret this plot.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来理解一下如何解读这个图。
- en: First, note that the negative log-likelihood (cost) is large when the likelihood
    and hazards are small. Think of the y-axis similar to -log(p-value); larger values
    indicate lower probability.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，注意到当似然度和危险度很小时，负对数似然度（成本）很大。可以将 y 轴视为 -log(p-value)；较大的值表示较低的概率。
- en: Second, censored subjects (like subject E) do not have their own individual
    likelihoods, so they don’t appear on the plot. However, their contribution is
    incorporated into the likelihoods of subjects A to D.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，被审查的受试者（如受试者 E）没有自己单独的似然度，因此它们没有出现在图中。然而，它们的贡献被纳入了受试者 A 到 D 的似然度中。
- en: 'Now, consider different scenarios based on the value of *β*:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，考虑基于 *β* 值的不同场景：
- en: If *β* is large and negative, subjects A, B, and C (with *x ≤ 0*) and their
    events are fitted nearly perfectly. The likelihoods of these subjects are all
    close to one. However, fitting such large negative *β* values for A, B, and C
    comes at the cost of subject D. In this range of *β*, the probability of subject
    D (with *x > 0*) having an event is very low. As a result, the total cost is dominated
    by the small likelihood of subject D.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果*β*很大且为负数，受试者 A、B 和 C（*x ≤ 0*）及其事件几乎完美拟合。这些受试者的似然度都接近于一。然而，给 A、B 和 C 拟合如此大的负
    *β* 值的代价是受试者 D。在这个 *β* 范围内，受试者 D（*x > 0*）发生事件的概率非常低。因此，总成本由受试者 D 的小似然度主导。
- en: If *β* is large and positive, the hazard of subject D (with *x > 0*) becomes
    significant compared to the other hazards. The purple section (subject D) becomes
    a small part of the total cost. However, since subjects A, B, and C all have *x
    ≤ 0*, the cost of fitting a large *β* for them is high. Consequently, these subjects
    dominate the total cost.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 *β* 很大且为正，受试者 D（*x > 0*）的危险度相较于其他危险度变得显著。紫色部分（受试者 D）成为总成本的一小部分。然而，由于受试者 A、B
    和 C 都有 *x ≤ 0*，因此给他们拟合一个大 *β* 的成本很高。因此，这些受试者主导了总成本。
- en: 'The optimal value of β, located around 2 on the plot, strikes a balance between
    assigning high probabilities to events of subjects A, B, and C versus subject
    D. This optimal value can be verified numerically:'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 位于图上约 2 的 *β* 的最佳值在为受试者 A、B 和 C 事件分配高概率与受试者 D 之间取得了平衡。这个最佳值可以通过数值方法验证：
- en: '[PRE7]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/5409dfe3fd3f2e8624ef9b997747366f.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5409dfe3fd3f2e8624ef9b997747366f.png)'
- en: Using lifelines library
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 lifelines 库
- en: 'Now that we have a better understanding of how Cox regression works, we can
    apply it to sample data using Python’s lifelines library to verify the results.
    Here is a code snippet for our made-up data:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对 Cox 回归有了更好的理解，我们可以使用 Python 的 lifelines 库将其应用于样本数据以验证结果。以下是我们虚构数据的代码片段：
- en: '[PRE8]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/80353e673eb6a541c755657f79ded4f9.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/80353e673eb6a541c755657f79ded4f9.png)'
- en: In the output, we can observe the coefficient (coef) value of -1.71, which corresponds
    to the β coefficient. Next to it, we have exp(coef), representing exp(β), as well
    as columns indicating standard errors and confidence intervals. The “partial log-likelihood”
    value is -2.64, which matches our manual result.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在输出中，我们可以观察到 -1.71 的系数（coef）值，它对应于 *β* 系数。它旁边的是 exp(coef)，表示 exp(β)，还有表示标准误差和置信区间的列。“部分对数似然度”值为
    -2.64，这与我们的手动结果相匹配。
- en: Lastly, it is important to mention that Cox regression implementations also
    offer an extension that allows the model to handle multiple events tied at the
    same event time. However, this goes beyond the scope of this discussion.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，需要提到的是，Cox 回归实现还提供了一个扩展，允许模型处理在同一事件时间发生的多个事件。然而，这超出了本讨论的范围。
- en: Conclusion
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'There was a lot to “unbox” here:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有很多需要“拆解”的内容：
- en: Cox regression models the association between predictor variables and the rank-order
    of times to an event occurrence.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cox 回归模型描述了预测变量与事件发生时间排名顺序之间的关联。
- en: Actual numeric values of event times do not matter at all, as long as the subjects
    experience the events in the same order.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件时间的实际数值完全无关紧要，只要受试者以相同的顺序经历这些事件。
- en: Hazards are probabilities per unit time and can have arbitrary units, while
    likelihoods are related the probability of events occurring.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 危险度是单位时间内的概率，可以具有任意单位，而似然度与事件发生的概率相关。
- en: Stacked bar charts can be used to provide insights into maximum likelihood estimation
    by stacking individual negative log-likelihoods and exploring how they change
    with predictors *x*.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 堆叠条形图可以用来通过堆叠单个负对数似然值提供对最大似然估计的洞察，并探索它们如何随预测变量*x*变化。
- en: By striking a balance between assigning probabilities to events for various
    subjects, MLE finds *β* for which the observed data is *most likely to happen*.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过在为各种受试者分配事件概率之间取得平衡，最大似然估计找到使观察数据*最有可能发生*的*β*。
- en: To be continued… 👀
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 敬请期待… 👀
- en: References
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Code with plots: [https://github.com/igor-sb/blog/blob/main/posts/cox/plots.py](https://github.com/igor-sb/blog/blob/main/posts/cox/plots.py)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '带图表的代码: [https://github.com/igor-sb/blog/blob/main/posts/cox/plots.py](https://github.com/igor-sb/blog/blob/main/posts/cox/plots.py)'
- en: 'Survival Data Analysis slides from Prof. Patrick Breheny: [https://myweb.uiowa.edu/pbreheny/7210/f19/index.html](https://myweb.uiowa.edu/pbreheny/7210/f19/index.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '帕特里克·布雷赫尼教授的生存数据分析幻灯片: [https://myweb.uiowa.edu/pbreheny/7210/f19/index.html](https://myweb.uiowa.edu/pbreheny/7210/f19/index.html)'
- en: ChatGPT for text cleanup and funny hallucinations
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于文本清理和有趣的虚构的ChatGPT
