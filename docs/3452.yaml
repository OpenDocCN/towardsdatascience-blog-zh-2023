- en: 'Mastering Elasticsearch: A Beginner’s Guide to Powerful Searches and Precision
    — Part 1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/mastering-elasticsearch-a-beginners-guide-to-powerful-searches-and-precision-part-1-87686fec9808?source=collection_archive---------2-----------------------#2023-11-21](https://towardsdatascience.com/mastering-elasticsearch-a-beginners-guide-to-powerful-searches-and-precision-part-1-87686fec9808?source=collection_archive---------2-----------------------#2023-11-21)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Unlock the power of Elasticsearch: dive into Elasticsearch, grasp basic search
    queries, and explore lexical search'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@sanilkhurana7?source=post_page-----87686fec9808--------------------------------)[![Sanil
    Khurana](../Images/b6aea8dd0366a0659fcf3828fc745aea.png)](https://medium.com/@sanilkhurana7?source=post_page-----87686fec9808--------------------------------)[](https://towardsdatascience.com/?source=post_page-----87686fec9808--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----87686fec9808--------------------------------)
    [Sanil Khurana](https://medium.com/@sanilkhurana7?source=post_page-----87686fec9808--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2bda56b80bb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-elasticsearch-a-beginners-guide-to-powerful-searches-and-precision-part-1-87686fec9808&user=Sanil+Khurana&userId=2bda56b80bb9&source=post_page-2bda56b80bb9----87686fec9808---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----87686fec9808--------------------------------)
    ·19 min read·Nov 21, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F87686fec9808&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-elasticsearch-a-beginners-guide-to-powerful-searches-and-precision-part-1-87686fec9808&user=Sanil+Khurana&userId=2bda56b80bb9&source=-----87686fec9808---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F87686fec9808&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-elasticsearch-a-beginners-guide-to-powerful-searches-and-precision-part-1-87686fec9808&source=-----87686fec9808---------------------bookmark_footer-----------)![](../Images/b489d34d4f65f6863cced325c6f575e0.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Contents
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: · [Introduction](#90ef)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: · [Starting where we left off, Elasticsearch](#a78d)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Sample Dataset](#67ab)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Understanding ElasticSearch Queries](#95a7)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Understanding the response](#a1e5)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [A basic search query](#1b1f)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: · [Lexical Search](#88c4)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: · [Problems in our current search query](#64f7)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Similar words return different results](#11df)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Lack of understanding of what the user wants](#3dd1)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Similar words are not returned](#bfca)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Typos are ignored](#aa13)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Different combinations of words have different meanings](#ad80)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: · [Improving our search](#21f0)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Boosting more relevant fields](#2bc3)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Boosting based on functions](#1e6e)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Fuzzy Queries](#ac5f)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: · [Conclusion](#da2c)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Ever wondered how you effortlessly find the perfect pair of shoes online or
    stumble upon a friend’s post in the vast realm of social media? It’s all thanks
    to the unsung hero of digital experiences: search systems.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Think back to your latest online purchase — whether it was a stylish pair of
    shoes or a thoughtful book for a friend. How did you stumble upon exactly what
    you were looking for? Chances are, you navigated through a sea of options using
    the search bar! That’s the magic of search systems, quietly shaping our online
    experiences and making it a breeze to discover the perfect find amidst the digital
    aisles. In a world teeming with choices, the ability to find what we seek quickly
    and effortlessly is a testament to the importance of robust and intuitive search
    systems for the products we love.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: In my recent Elasticsearch exploration ([check out my primer on its architecture
    and terminology](https://medium.com/better-programming/system-design-series-elasticsearch-architecting-for-search-5d5e61360463)),
    we uncovered the engine powering these discoveries. This post delves into search
    — navigating ElasticSearch queries, comprehending responses, and crafting a basic
    query to set the stage.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: 'Our goal: build a simple search query, find problems, and improve it with practical
    examples. Join us in acknowledging the challenges within our current search system
    and discovering a pathway to refinement in this world of digital aisles.”'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Starting where we left off, Elasticsearch
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sample Dataset
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To demonstrate different ways we can improve search, let’s set up Elasticsearch
    and load some data in it. For this post, I will use [this News dataset I found
    on Kaggle](https://www.kaggle.com/datasets/rmisra/news-category-dataset). The
    dataset is pretty simple, it contains around 210,000 news articles, with their
    headlines, short descriptions, authors, and some other fields we don’t care much
    about. We don’t really need all 210,000 documents, so I will load up around 10,000
    documents in ES and start searching.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: These are a few examples of the documents in the dataset —
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Each document represents a news article. Each article contains a `link`, `headline`,
    a `short_description`, a `category`, `authors`, `country`(random values, added
    by me), and `timestamp`(again random values, added by me).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: I added `country` and `timestamp` fields to make the examples in the following
    sections more fun, so let’s begin!
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Understanding ElasticSearch Queries
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Elasticsearch queries are written in JSON. Instead of diving deep into all the
    different syntaxes you can use to create search queries, let’s start simple and
    build from there.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: The simplest full-text query is the `match` query. The idea is simple, you write
    a query and Elasticsearch performs a full-text search against a specific field.
    For example,
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的全文查询是 `match` 查询。其思想很简单，您编写一个查询，Elasticsearch 对特定字段执行全文搜索。例如，
- en: '[PRE1]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The above query finds all articles where the word “robbery” appears in the “headline”.
    These are the results I got back -
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 上述查询找到了所有标题中出现单词“抢劫”的文章。这些是我收到的结果 -
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: But, what if you want to perform a full-text search on multiple fields? You
    can do that by a `multi_match` query,
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果您希望在多个字段上执行全文搜索，该怎么办？您可以通过 `multi_match` 查询来实现，
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This performs a similar operation, but instead of looking at a single field,
    it now looks at both `headine` and `short_description` of all the documents and
    performs a full-text search on them.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这执行了类似的操作，但不再仅限于单个字段，而是查看所有文档的 `headine` 和 `short_description`，并对它们进行全文搜索。
- en: Understanding the response
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解响应
- en: This is a sample response from our last query -
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们上次查询的一个示例响应 -
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `took` field and the `timed_out` field are pretty easy to understand, they
    simply represent the time in milliseconds it took for Elasticsearch to return
    the response, and whether the query was timed out or not.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`took` 字段和 `timed_out` 字段很容易理解，它们简单地表示 Elasticsearch 返回响应所花费的毫秒数，以及查询是否超时。'
- en: The `_shards` field tells how many shards were involved in this search operation,
    how many of them returned successfully, how many failed, and how many skipped.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`_shards` 字段告诉我们在此搜索操作中涉及了多少分片，其中多少返回成功，多少失败，以及多少被跳过。'
- en: The `hits` field contains the documents returned from the search. Each document
    is given a score based on how relevant it is to our search. The hits field also
    contains a field `total` mentioning the total number of documents returned, and
    the max score of the documents.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '`hits` 字段包含从搜索返回的文档。每个文档根据其与搜索相关性而得分。hits 字段还包含一个 `total` 字段，提到返回的文档总数，以及文档的最大分数。'
- en: Finally, in the nested field, `hits` we get all the relevant documents, along
    with their `_id`, and their `score`. The documents are sorted by their scores.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在嵌套字段 `hits` 中，我们获取所有相关文档，包括它们的 `_id` 和它们的 `score`。文档按它们的分数排序。
- en: A basic search query
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个基本的搜索查询
- en: Let’s start building our search query. We can start with a simple query and
    dissect problems in it -
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始构建我们的搜索查询。我们可以从一个简单的查询开始，并剖析其中的问题 -
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This is a pretty simple query, it just finds all the documents where the word
    “robbery” appears in any of the given fields, i.e. `headline` or `short_description`.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常简单的查询，它只是找到所有包含单词“抢劫”的文档，无论其出现在哪些字段中，即 `headline` 或 `short_description`。
- en: It returns a few results, and we can see all of them have the word “robbery”
    in it.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 它返回了一些结果，我们可以看到它们中都有单词“抢劫”。
- en: '[PRE6]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Lexical Search
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 词法搜索
- en: What we’ve engaged in thus far is referred to as ‘lexical search.’ In this type
    of search, the system seeks precise matches for a given word or phrase within
    documents. In essence, when a user inputs ‘robbery,’ our search query identifies
    all documents containing the exact term ‘robbery.’ While this method may appear
    intuitive initially, its limitations become apparent quite swiftly, as we will
    soon discover.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们所涉及的被称为“词法搜索”。在这种类型的搜索中，系统寻找文档中给定单词或短语的精确匹配。实质上，当用户输入“抢劫”时，我们的搜索查询识别出所有包含确切术语“抢劫”的文档。尽管这种方法最初可能看起来直观，但它的局限性很快就会显现出来，正如我们马上就会发现的那样。
- en: Problems in our current search query
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们当前搜索查询中的问题
- en: Similar words return different results
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相似的词语会返回不同的结果
- en: Let’s take a few examples, let’s see what we get when the user searches for
    “robbed” —
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们举几个例子，看看当用户搜索“被抢劫”时我们会得到什么 -
- en: '[PRE7]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: These are the results I get back —
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我收到的结果 -
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: To keep it simple, these are the headlines of the documents I got back —
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简单起见，这些是我收到的文档的标题 -
- en: '[PRE9]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Both of these documents contain the word “robbed” in either the headline or
    the description. But if the user had searched for “robbery”, then we would see
    a completely different set of documents in the results -
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这两篇文档中都包含“被抢劫”一词，无论是在标题还是描述中。但是如果用户搜索的是“抢劫”，那么我们将会在结果中看到完全不同的文档 -
- en: '[PRE10]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: So in short, we get different results if the user searches for “robbery” than
    if the user searches for “robbed”. This is obviously not ideal, if the user has
    searched for any of these(or anything related to “rob”), we should show all documents
    that contain different forms of the word “rob”(called [“inflected” forms)](https://en.wikipedia.org/wiki/Inflection)
    in the query.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Lack of understanding of what the user wants
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: “The goal of a designer is to listen, observe, understand, sympathize, empathize,
    synthesize, and glean insights that enable him or her to make the invisible visible.”
    — Hillman Curtis
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We are trying to retrieve documents aligning with the user’s query, a task that
    extends beyond the user’s input alone. By delving into additional parameters,
    we gain a much richer understanding of our user’s preferences and needs.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: For example, when a user searches for news, their interest likely extends beyond
    relevance alone; how recent the news article is often crucial. To enhance our
    search precision, we can fine-tune the scoring mechanism.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, we also have a `location` field in our articles. This field signifies
    the geographical origin of the news, presenting an opportunity to further refine
    our results. We can use this to boost articles from the user’s country.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Similar words are not returned
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since we are only returning articles that contain the exact match the user queried
    for, we are likely missing relevant documents that contain similar words. For
    example, if I search for “theft”, I get the following articles,
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The word “robbery” may have a different meaning than the word “theft”, but it’s
    still a relevant word, and the user may be interested in seeing articles with
    the word “robbery” as well(although at a lower relevance score than the documents
    that contain the exact word the user searched for)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: There can be many similar words to theft, each having different levels of similarity.
    For example, “theft” may be more similar to “shoplifting” and less similar to
    “burglary”. But both can be synonymous to each other in certain contexts and can
    be of some relevance, though not as relevant as the exact word in the query, i.e.
    “theft”.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Our current search doesn’t consider the similarity of words in documents and
    in the query. If a user searches for “theft”, only the articles containing the
    word “theft” are returned, whereas we should also return articles containing words
    similar to “theft”(like “burglary” or “robbery”).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Typos are ignored
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: “If the user can’t use it, it doesn’t work.” — Susan Dray
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Another issue is that any typo by a user would return empty results. We know
    that users may accidentally make typos, and we don’t want to return empty results.
    For example, searching “robbey” on Google News still returns results related to
    “robbery”.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2e1ded7685eacd2857f18ec016254422.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
- en: Different combinations of words have different meanings
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s look at an example, let’s assume the user made this query —
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: For you and me, it’s obvious the user wants to search for news related to “covid”
    or “virus” in “New Jersey”. But to our search engine, each of these words means
    the same, and it has no way to understand that the ordering of these words matters(for
    example, “New” and “Jersey” in “New Jersey”).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the top three results,
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: If you look carefully at the results above, you’ll notice that the second result,
    “New Variants Raise Worry About COVID-19 Virus Reinfections” is completely unrelated
    to New Jersey. In fact, after reading the description, it seems to be more related
    to COVID-19 infections in South Africa!
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: This is because the words “COVID”, “virus” and “New” are part of the document,
    because of this, the document gets a higher score. However, this is not at all
    relevant to the user query. Our search system does not understand that the terms
    “New” and “Jersey” should be treated as a single term.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Improving our search
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Boosting more relevant fields
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: “Words have a weight so if you are going to say something heavy, make sure to
    pick the right ones.” — Lang Leav
  id: totrans-100
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We can decide to boost certain fields or certain values which might be more
    useful in understanding what an article is about. For example, the headline of
    the article might be more meaningful than the description of the article.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take an example query. Let’s assume the user is trying to search for elections,
    this would be our Elasticsearch query —
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: These are the results we get back-
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: If you look at the second article “The 20 Funniest Tweets From Women This Week
    (Oct. 31-Nov. 6)”, you can see it doesn’t even seem to be about elections. However,
    due to the presence of the word ‘election’ in the description, Elasticsearch deemed
    it a relevant result. Perhaps, there’s room for improvement. It makes intuitive
    sense that articles with headings matching the user’s query would be more relevant.
    To achieve this, we can instruct Elasticsearch to boost the `heading` field, essentially
    assigning it greater importance than the `short_description` field in score calculations.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: This is pretty simple to do in our query-
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Notice the `heading^4` that I put in `fields`. This simply means that the field
    “heading” is boosted by 4\. Let’s look at the results now,
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We can see now that all the top results contain the word “election” in the heading
    and thus, the returned articles are more relevant.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Boosting based on functions
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While we have boosted certain fields, we also want to introduce two new types
    of boosts based on what users want when searching for news.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: We want to boost articles from the user’s country. We don’t simply want to filter
    based on country since that might lead to irrelevant results appearing at the
    top, but we also don’t want to ignore it completely. In short, we want to give
    more weight to articles from the user’s country.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We want to boost more recent news. We don’t simply want to sort based on recency
    since that also might lead to irrelevant results appearing at the top, instead,
    we want to balance recency with relevance.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let’s see how to do this.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: In Elasticsearch, we can use the `function_score` query to apply custom scoring
    functions, including boosting. The `function_score` query allows you to modify
    the score of documents based on various functions. To put it simply, we can boost
    certain documents based on conditions.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by boosting the user’s country. Let’s assume the user’s country
    is “US” and plug it into the query when sending it to Elasticsearch. To achieve
    this, we need to add a `function_score` block, which allows custom scoring functions
    to be applied to the results of a query. We can define multiple `functions` for
    a given query, specifying conditions on matching the document and the boost value.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: We can define a function to boost user’s country —
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This boosts articles by 2 where the country is “US”.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s try to boost recent news on top. We can do this by using `field_value_factor`.
    The `field_value_factor` function allows us to use a field from a document to
    influence its score which is precisely what we want. Let’s see how it looks —
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The term `factor` specifies the multiplier or factor by which the values of
    the specified field should influence the score. With this function, documents
    with more recent timestamps will be given higher scores.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Our full query becomes —
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Now recent documents and documents from the user’s country will be given a higher
    score. We can tune this balance by configuring the values for the `weight` and
    the `factor` fields.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Fuzzy Queries
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next, let’s fix typos in the search query.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: In Elasticsearch, we can perform fuzzy searches to retrieve documents that match
    a specified term even if there are slight variations in the spelling or characters.
    To do this, we can simply add a `fuzziness` field to our query. Our final query
    becomes —
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: There is a lot more to spelling correction than simply adding `fuzziness`. [Check
    out this blog post if you want to learn more](https://queryunderstanding.com/spelling-correction-471f71b19880).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this blog post, we’ve dived into the nuts and bolts of Elasticsearch, starting
    with a hands-on look at a sample dataset and the basics of crafting search queries.
    We’ve demystified Elasticsearch responses and walked through a basic search query,
    laying the foundation for effective exploration.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: As we explored lexical search, we recognized some quirks in our current search
    approach. To address these challenges, we introduced boosting and fuzziness —
    handy tools to fine-tune our searches and deal with real-world data complexities.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: As we wrap up here, consider this a pit stop on our journey toward search excellence.
    In the next part, we’ll delve into advanced strategies to overcome specific issues
    in our current search approach. Brace yourself for the fascinating world of semantic
    search, where the focus shifts from just matching keywords to understanding the
    meaning behind them, paving the way for more intuitive and context-aware search
    experiences. Get ready to take your Elasticsearch adventure to the next level!
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Enjoyed the journey through Elasticsearch? Follow me on Medium for more articles.
    For quicker bites of knowledge(tidbits about what I am reading about, cheatsheets,
    etc.), [follow me on LinkedIn](https://www.linkedin.com/in/sanil-khurana-a2503513b/)
    with regular short-form content(for example, while reading about Elasticsearch,
    I discussed how a particular scoring function, called tf-idf works in a brief
    5 minute post [here](https://www.linkedin.com/posts/sanil-khurana-a2503513b_searchengine-softwaredevelopment-data-activity-7127859782736089088-fi3H?utm_source=share&utm_medium=member_desktop)).
    Let’s stay connected on this exploration of tech and data!
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
