- en: Multi-Armed Bandits Applied to Order Allocation among Execution Algorithms
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多臂老虎机应用于执行算法中的订单分配
- en: 原文：[https://towardsdatascience.com/multi-armed-bandits-applied-to-order-allocation-among-execution-algorithms-fff21dedc927?source=collection_archive---------10-----------------------#2023-03-02](https://towardsdatascience.com/multi-armed-bandits-applied-to-order-allocation-among-execution-algorithms-fff21dedc927?source=collection_archive---------10-----------------------#2023-03-02)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/multi-armed-bandits-applied-to-order-allocation-among-execution-algorithms-fff21dedc927?source=collection_archive---------10-----------------------#2023-03-02](https://towardsdatascience.com/multi-armed-bandits-applied-to-order-allocation-among-execution-algorithms-fff21dedc927?source=collection_archive---------10-----------------------#2023-03-02)
- en: Finding the right balance between exploitation and exploration
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 找到**利用**与*探索*之间的正确平衡
- en: '[](https://medium.com/@larsterbraak?source=post_page-----fff21dedc927--------------------------------)[![Lars
    ter Braak](../Images/79a2bbfbe8706c2451826049e3e2d8e7.png)](https://medium.com/@larsterbraak?source=post_page-----fff21dedc927--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fff21dedc927--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fff21dedc927--------------------------------)
    [Lars ter Braak](https://medium.com/@larsterbraak?source=post_page-----fff21dedc927--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@larsterbraak?source=post_page-----fff21dedc927--------------------------------)[![Lars
    ter Braak](../Images/79a2bbfbe8706c2451826049e3e2d8e7.png)](https://medium.com/@larsterbraak?source=post_page-----fff21dedc927--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fff21dedc927--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fff21dedc927--------------------------------)
    [Lars ter Braak](https://medium.com/@larsterbraak?source=post_page-----fff21dedc927--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff1d3961756e7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-armed-bandits-applied-to-order-allocation-among-execution-algorithms-fff21dedc927&user=Lars+ter+Braak&userId=f1d3961756e7&source=post_page-f1d3961756e7----fff21dedc927---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fff21dedc927--------------------------------)
    ·6 min read·Mar 2, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffff21dedc927&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-armed-bandits-applied-to-order-allocation-among-execution-algorithms-fff21dedc927&user=Lars+ter+Braak&userId=f1d3961756e7&source=-----fff21dedc927---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff1d3961756e7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-armed-bandits-applied-to-order-allocation-among-execution-algorithms-fff21dedc927&user=Lars+ter+Braak&userId=f1d3961756e7&source=post_page-f1d3961756e7----fff21dedc927---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fff21dedc927--------------------------------)
    · 6 min 阅读 · 2023年3月2日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffff21dedc927&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-armed-bandits-applied-to-order-allocation-among-execution-algorithms-fff21dedc927&user=Lars+ter+Braak&userId=f1d3961756e7&source=-----fff21dedc927---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffff21dedc927&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-armed-bandits-applied-to-order-allocation-among-execution-algorithms-fff21dedc927&source=-----fff21dedc927---------------------bookmark_footer-----------)![](../Images/4aa78a1ebd02691dc382392a434cb265.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffff21dedc927&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-armed-bandits-applied-to-order-allocation-among-execution-algorithms-fff21dedc927&source=-----fff21dedc927---------------------bookmark_footer-----------)![](../Images/4aa78a1ebd02691dc382392a434cb265.png)'
- en: 'Confused robot observing three one-armed slot machines in Picasso style. Source:
    DALL-E 2.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 困惑的机器人以毕加索风格观察三台单臂老虎机。来源：DALL-E 2。
- en: Making decisions under uncertainty is a common challenge faced by professionals
    in various fields, including data science and asset management. Asset managers
    face this problem when selecting among multiple execution algorithms to carry
    out their trades. The allocation of orders among algorithms resembles the multi-armed
    bandit problem that gamblers face when deciding which slot machines to play, as
    they must determine the number of times to play each machine, the order in which
    to play them, and whether to continue with the current machine or switch to another.
    In this article, we describe how an asset manager can best distribute orders among
    available algorithms based on realized execution cost.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在不确定性下做出决策是各个领域的专业人士面临的常见挑战，包括数据科学和资产管理。资产经理在选择多个执行算法来完成交易时会遇到这个问题。算法之间的订单分配类似于赌徒面临的多臂老虎机问题，他们必须决定玩每台老虎机的次数、顺序以及是否继续当前机器或切换到另一台。在这篇文章中，我们描述了资产经理如何根据实际执行成本最佳地分配订单到可用算法中。
- en: Dummy example
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例
- en: For each order, we take an action *a* to allocate to one of *K* algorithms
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个订单，我们采取行动*a*，将其分配给*K*个算法中的一个
- en: '![](../Images/604ac3185d674ae9b4d86f32aae31c91.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/604ac3185d674ae9b4d86f32aae31c91.png)'
- en: 'Eq. 1: Set of possible actions to allocate an order to one of K algorithms.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq. 1: 分配订单到K个算法中的一个的可能行动集合。'
- en: The value of action *a* is the expected execution cost for the algorithm
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 行动*a*的价值是该算法的预期执行成本
- en: '![](../Images/81fdf713fc23730a0ac9ab393150107d.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81fdf713fc23730a0ac9ab393150107d.png)'
- en: 'Eq. 2: (Unobserved) expected execution cost for action a, i.e. choosing a certain
    algorithm.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq. 2: (未观察的) 行动a的预期执行成本，即选择某个算法。'
- en: Suppose that *K = 3* and the expected execution cost for the algorithms are
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 假设*K = 3*，并且算法的预期执行成本为
- en: '![](../Images/082e972322dab17604114dadcd127ea0.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/082e972322dab17604114dadcd127ea0.png)'
- en: 'Eq. 3: (Unobserved) expected execution cost for three algorithms.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq. 3: (未观察的) 三个算法的预期执行成本。'
- en: If you would know the action values a priori, it would be trivial to solve the
    problem. You would always select the algorithm with the lowest expected execution
    cost. Suppose now that we start allocating orders among the three algorithms as
    shown in Figure 1.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你事先知道行动值，解决问题会非常简单。你将始终选择预期执行成本最低的算法。现在假设我们开始按照图1中所示在三个算法之间分配订单。
- en: '![](../Images/99b76e27a17b4638bba7a8db92b5de80.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/99b76e27a17b4638bba7a8db92b5de80.png)'
- en: 'Figure 1: Example of order allocation among three algorithms and associated
    execution cost. Source: Author.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '图1: 在三个算法之间分配订单及其相关执行成本的示例。来源：作者。'
- en: 'We still do not know the action values with certainty, but we do have estimates
    after some time *t*:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍然不确定行动值，但在一段时间*t*后，我们有了估计：
- en: '![](../Images/b59cc23f6af13e112a07e1993daa40a7.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b59cc23f6af13e112a07e1993daa40a7.png)'
- en: 'Eq. 4: (Observed) expected execution cost for action a conditional on the information
    up until time t.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq. 4: (观察的) 基于截至时间t的信息，行动a的预期执行成本。'
- en: We can for instance construct the empirical distribution of the execution cost¹
    for each algorithm, as shown in Figure 2.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以构建每个算法的执行成本¹的经验分布，如图2所示。
- en: '![](../Images/cfc1fbe77b98e44fae885343d3740419.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cfc1fbe77b98e44fae885343d3740419.png)'
- en: 'Figure 2: Empirical distribution of execution cost per algorithm after some
    time t. Source: Author.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '图2: 一段时间t后每个算法的执行成本的经验分布。来源：作者。'
- en: 'Allocating all orders to the algorithm with the lowest expected execution cost
    may appear to be the best approach. However, doing so would prevent us from gathering
    information on the performance of the other algorithms. This illustrates the classical
    multi-armed bandit dilemma:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有订单分配给预期执行成本最低的算法可能看起来是最佳方法。然而，这样做会阻止我们收集其他算法性能的信息。这体现了经典的多臂老虎机困境：
- en: Exploit the information that has already been learned
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用已经学到的信息
- en: Explore to learn which actions give the best outcomes
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索以了解哪些行动能获得最佳结果
- en: 'The objective is to **minimize the average execution cost** after allocating
    *N* orders:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是**最小化平均执行成本**，在分配*P*个订单之后：
- en: '![](../Images/42a442d21839f39b066048d565246519.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/42a442d21839f39b066048d565246519.png)'
- en: 'Eq. 5: Objective function for order allocation problem.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq. 5: 订单分配问题的目标函数。'
- en: Solving the problem using policies
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用策略解决问题
- en: To solve the problem, we need an action selection policy that tells us how to
    allocate each order based on current information *S.* We can define a policy as
    a map from *S* to *a:*
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们需要一个动作选择策略，它告诉我们如何基于当前信息*S*分配每个订单。我们可以将策略定义为从*S*到*a*的映射：
- en: '![](../Images/b6e38cf7191513324dc8acd814c6a6ce.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b6e38cf7191513324dc8acd814c6a6ce.png)'
- en: 'Eq. 6: Definition of an action selection policy.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq. 6: 动作选择策略的定义。'
- en: 'We discuss the most well known policies² for the multi-armed bandit problem,
    which can be classified in the following categories:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了最著名的多臂赌博机问题策略²，这些策略可以分为以下几类：
- en: '**Semi-uniform strategies:** *Greedy &* *ε-greedy*'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**半均匀策略：** *贪婪 &* *ε-贪婪*'
- en: '**Probability matching strategies:** *Upper-Confidence-Bound & Thompson sampling*'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**概率匹配策略：** *上置信界限 & 汤普森采样*'
- en: '*Greedy*'
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*贪婪*'
- en: 'The *greedy approach* allocates all orders to the action with the lowest estimated
    value. This policy always exploits current knowledge to maximize immediate reward:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*贪婪方法*将所有订单分配给估计值最低的动作。该策略总是利用当前知识以最大化即时奖励：'
- en: '![](../Images/91851e1c2265209712ca67b5f37fd516.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/91851e1c2265209712ca67b5f37fd516.png)'
- en: 'Eq. 7: Action selection policy for greedy approach.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq. 7: 贪婪方法的动作选择策略。'
- en: ϵ-Greedy
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ϵ-贪婪
- en: 'The *ε-greedy approach* behaves greedily most of the time but with probability
    *ε* selects randomly among the suboptimal actions:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*ε-贪婪方法*大多数时候表现得很贪婪，但以概率*ε*随机选择次优动作：'
- en: '![](../Images/d97e34f46b3fc27bed27c9430a6c8394.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d97e34f46b3fc27bed27c9430a6c8394.png)'
- en: 'Eq. 8: Action selection policy for ϵ-greedy approach.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq. 8: ϵ-贪婪方法的动作选择策略。'
- en: An advantage of this policy is that it converges to the optimal action in the
    limit.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 该策略的一个优点是，它在极限情况下会收敛到最优动作。
- en: Upper-Confidence-Bound
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 上置信界限
- en: 'The *Upper-Confidence-Bound (UCB) approach* selects the action with the lowest
    action value *minus* a term that is inversely proportional to the number of times
    the trading algorithm is used, i.e. *Nt(a)*. The approach thus selects among the
    non-greedy actions according to their potential for actually being optimal and
    the associated uncertainties in those estimates:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*上置信界限（UCB）方法*选择具有最低动作值*减去*一个与交易算法使用次数成反比的项，即*Nt(a)*。该方法在非贪婪动作中选择，依据其实际最优潜力及这些估计的相关不确定性：'
- en: '![](../Images/302f652ce4b8def7b38188decddadaff.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/302f652ce4b8def7b38188decddadaff.png)'
- en: 'Eq. 9: Action selection policy for Upper-Confidence-Bound (UCB) approach.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq. 9: 上置信界限（UCB）方法的动作选择策略。'
- en: Thompson Sampling
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 汤普森采样
- en: 'The *Thompson Sampling approach,* as proposed by Thompson (1933), assumes a
    known initial distribution over the action values and updates the distribution
    after each order allocation³. The approach selects actions according to their
    posterior probability of being the best action:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*汤普森采样方法*，如汤普森（1933）所提，假设对动作值有一个已知的初始分布，并在每次订单分配后更新分布。该方法根据动作的后验概率选择最佳动作：'
- en: '![](../Images/2b51308774601572de67352cfe760f88.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2b51308774601572de67352cfe760f88.png)'
- en: 'Eq. 10: Action selection policy for Thompson sampling approach.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq. 10: 汤普森采样方法的动作选择策略。'
- en: Evaluating policies
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 策略评估
- en: 'In practice, policies are commonly evaluated on *regret* which is the deviation
    from the optimal solution:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际应用中，策略通常通过*遗憾*来评估，遗憾是与最优解的偏差：
- en: '![](../Images/01a002b041e58e03fd373b02962bb370.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01a002b041e58e03fd373b02962bb370.png)'
- en: 'Eq. 11: Definition of regret as a function of a sequence of actions.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq. 11: 遗憾作为一系列动作的函数的定义。'
- en: 'where *μ** is the minimal execution cost mean:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 其中*μ*是最小执行成本均值：
- en: '![](../Images/4d3cd7291df6ad7f70777c3bd3a37b0a.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4d3cd7291df6ad7f70777c3bd3a37b0a.png)'
- en: 'Eq. 12: Expected execution cost for choosing the optimal action.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq. 12: 选择最优动作的期望执行成本。'
- en: 'Actions are a direct consequence of the policy, and we can therefore also define
    regret as a function of the chosen policy:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 动作是策略的直接结果，因此我们也可以将遗憾定义为所选策略的函数：
- en: '![](../Images/9aa74ffc6a17bd11d09b049e5d37e3d8.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9aa74ffc6a17bd11d09b049e5d37e3d8.png)'
- en: 'Eq. 13: Definition of regret as a function of an action selection policy π.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq. 13: 遗憾作为动作选择策略π的函数的定义。'
- en: In Figure 3, we simulate the regret for the aforementioned policies in the dummy
    example. We observe that the *Upper-Confidence-Bound approach* and *Thompson sampling
    approach* perform best.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在图3中，我们在示例中模拟了上述策略的遗憾。我们观察到*上置信界限方法*和*汤普森采样方法*表现最佳。
- en: '![](../Images/502478bbb0858eae530f379beb661fd9.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/502478bbb0858eae530f379beb661fd9.png)'
- en: 'Figure 3: Simulated regret for different action selection policies for dummy
    order allocation problem. Source: Author.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：针对虚拟订单分配问题的不同动作选择策略的模拟遗憾。来源：作者。
- en: Allocating orders? Embrace uncertainty!
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 订单分配？拥抱不确定性！
- en: The dummy example simulation results strongly indicate that relying solely on
    a *greedy approach* may not yield optimal outcomes. It is, therefore, crucial
    to incorporate and measure the uncertainty in the execution cost estimates when
    developing an order allocation strategy.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟示例模拟结果强烈表明，单纯依赖*贪婪方法*可能无法获得最佳结果。因此，在制定订单分配策略时，融入并衡量执行成本估算的不确定性至关重要。
- en: Footnotes
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 脚注
- en: ¹ To ensure comparability of the empirical distribution of the execution cost,
    we need to either allocate similar orders or use order-agnostic cost metrics for
    evaluation.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ¹ 为确保执行成本的经验分布的可比性，我们需要分配类似的订单或使用无关订单的成本指标进行评估。
- en: ² In situation where an algorithm’s execution cost are dependent on the order
    characteristics, contextual bandits are a more suitable option. To learn more
    about this approach, we recommend Chapter 2.9 in Barto & Sutton (2018) for an
    introduction.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ² 在算法的执行成本依赖于顺序特征的情况下，上下文强盗算法是更合适的选择。要了解更多关于这种方法的信息，我们推荐 Barto & Sutton (2018)
    的第 2.9 章作为入门。
- en: ³ We strongly suggest Russo et al. (2018) as an outstanding resource to learn
    about Thompson sampling.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ³ 我们强烈建议阅读 Russo 等 (2018) 作为学习 Thompson 采样的杰出资源。
- en: Additional resources
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 额外资源
- en: The following tutorials / lectures were personally very helpful for my understanding
    of multi-armed bandit problems.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 以下教程 / 讲座对我理解多臂强盗问题非常有帮助。
- en: Industry
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 行业
- en: Research Scientist Robert Schapire @ [Microsoft](https://www.youtube.com/watch?v=N5x48g2sp8M&ab_channel=SimonsInstitute)
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 研究科学家 Robert Schapire @ [Microsoft](https://www.youtube.com/watch?v=N5x48g2sp8M&ab_channel=SimonsInstitute)
- en: Research Scientist Hado van Hasselt @ [Deepmind](https://www.youtube.com/watch?v=TCCjZe0y4Qc&ab_channel=DeepMind)
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 研究科学家 Hado van Hasselt @ [Deepmind](https://www.youtube.com/watch?v=TCCjZe0y4Qc&ab_channel=DeepMind)
- en: '**Academia**'
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**学术界**'
- en: Assistant Professor Christina Lee Yu @ [Cornell](https://www.youtube.com/watch?v=w1pRb8SGdcw&t=446s&ab_channel=SimonsInstitute)
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 助理教授 Christina Lee Yu @ [Cornell](https://www.youtube.com/watch?v=w1pRb8SGdcw&t=446s&ab_channel=SimonsInstitute)
- en: Assistant Professor Emma Brunskill @ [MIT](https://www.youtube.com/watch?v=FgzM3zpZ55o&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&ab_channel=StanfordOnline)
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 助理教授 Emma Brunskill @ [MIT](https://www.youtube.com/watch?v=FgzM3zpZ55o&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&ab_channel=StanfordOnline)
- en: References
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Sutton, R. S., & Barto, A. G. (2018). Reinforcement learning: An introduction.
    *MIT press*.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Sutton, R. S., & Barto, A. G. (2018). 强化学习：导论。*麻省理工学院出版社*。'
- en: '[2] Russo, D. J., Van Roy, B., Kazerouni, A., Osband, I., & Wen, Z. (2018).
    A tutorial on Thompson sampling. *Foundations and Trends® in Machine Learning*,
    *11*(1), 1–96.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Russo, D. J., Van Roy, B., Kazerouni, A., Osband, I., & Wen, Z. (2018).
    关于 Thompson 采样的教程。*机器学习基础与趋势®*，*11*(1)，1–96。'
- en: '[3] Thompson, W. 1933\. On the likelihood that one unknown probability exceeds
    another in view of the evidence of two samples. *Biometrika*. 25(3/4): 285–294.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Thompson, W. 1933\. 在两个样本的证据下，一个未知概率超过另一个的可能性。*生物统计学*。25(3/4): 285–294。'
- en: '[4] Thompson, W. R. 1935\. On the theory of apportionment. *American Journal
    of Mathematics*. 57(2): 450–456.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Thompson, W. R. 1935\. 关于配额理论。*美国数学杂志*。57(2): 450–456。'
- en: '[5] Eckles, D. and M. Kaptein. 2014\. Thompson sampling with the online bootstrap.
    *arXiv preprint arXiv:1410.4009*.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Eckles, D. 和 M. Kaptein. 2014\. 在线自助法的 Thompson 采样。*arXiv 预印本 arXiv:1410.4009*。'
- en: 'If you’re keen on reading more, see a selection of my articles below:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对更多内容感兴趣，可以查看我下面的一些文章：
- en: '[](https://medium.com/@larsterbraak/cost-decomposition-for-a-vwap-execution-algorithm-buy-side-perspective-1126f9eebf40?source=post_page-----fff21dedc927--------------------------------)
    [## Cost decomposition for a VWAP execution algorithm: Buy-side perspective.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@larsterbraak/cost-decomposition-for-a-vwap-execution-algorithm-buy-side-perspective-1126f9eebf40?source=post_page-----fff21dedc927--------------------------------)
    [## VWAP 执行算法的成本分解：买方视角'
- en: Linear cost decomposition for VWAP execution algorithm that allows for faster
    and more granular algorithmic trading…
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用于 VWAP 执行算法的线性成本分解，允许更快且更细致的算法交易……
- en: 'medium.com](https://medium.com/@larsterbraak/cost-decomposition-for-a-vwap-execution-algorithm-buy-side-perspective-1126f9eebf40?source=post_page-----fff21dedc927--------------------------------)
    [](/introduction-to-probabilistic-classification-a-machine-learning-perspective-b4776b469453?source=post_page-----fff21dedc927--------------------------------)
    [## Introduction to Probabilistic Classification: A Machine Learning Perspective'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[medium.com](https://medium.com/@larsterbraak/cost-decomposition-for-a-vwap-execution-algorithm-buy-side-perspective-1126f9eebf40?source=post_page-----fff21dedc927--------------------------------)
    [](/introduction-to-probabilistic-classification-a-machine-learning-perspective-b4776b469453?source=post_page-----fff21dedc927--------------------------------)
    [## 引言：概率分类的机器学习视角'
- en: Guide to go from predicting labels to predicting probabilities
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从预测标签到预测概率的指南
- en: 'towardsdatascience.com](/introduction-to-probabilistic-classification-a-machine-learning-perspective-b4776b469453?source=post_page-----fff21dedc927--------------------------------)
    [](https://medium.com/@larsterbraak/beyond-traditional-return-modelling-embracing-thick-tails-67f457dfbf6b?source=post_page-----fff21dedc927--------------------------------)
    [## Beyond traditional asset return modelling: Embracing thick tails.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/introduction-to-probabilistic-classification-a-machine-learning-perspective-b4776b469453?source=post_page-----fff21dedc927--------------------------------)
    [](https://medium.com/@larsterbraak/beyond-traditional-return-modelling-embracing-thick-tails-67f457dfbf6b?source=post_page-----fff21dedc927--------------------------------)
    [## 超越传统资产回报建模：拥抱厚尾。
- en: Guide to statistical inference for preasymptotics.
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 针对预渐近性的统计推断指南。
- en: medium.com](https://medium.com/@larsterbraak/beyond-traditional-return-modelling-embracing-thick-tails-67f457dfbf6b?source=post_page-----fff21dedc927--------------------------------)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[medium.com](https://medium.com/@larsterbraak/beyond-traditional-return-modelling-embracing-thick-tails-67f457dfbf6b?source=post_page-----fff21dedc927--------------------------------)'
