- en: When Stochastic Policies Are Better Than Deterministic Ones
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/when-stochastic-policies-are-better-than-deterministic-ones-b950cd0d60f4?source=collection_archive---------5-----------------------#2023-02-18](https://towardsdatascience.com/when-stochastic-policies-are-better-than-deterministic-ones-b950cd0d60f4?source=collection_archive---------5-----------------------#2023-02-18)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Why we let randomness dictate our action selection in Reinforcement Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://wvheeswijk.medium.com/?source=post_page-----b950cd0d60f4--------------------------------)[![Wouter
    van Heeswijk, PhD](../Images/9c996bccd6fdfb6d9aa8b50b93338eb9.png)](https://wvheeswijk.medium.com/?source=post_page-----b950cd0d60f4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b950cd0d60f4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b950cd0d60f4--------------------------------)
    [Wouter van Heeswijk, PhD](https://wvheeswijk.medium.com/?source=post_page-----b950cd0d60f4--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F33f45c9ab481&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-stochastic-policies-are-better-than-deterministic-ones-b950cd0d60f4&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=post_page-33f45c9ab481----b950cd0d60f4---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b950cd0d60f4--------------------------------)
    ·6 min read·Feb 18, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb950cd0d60f4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-stochastic-policies-are-better-than-deterministic-ones-b950cd0d60f4&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=-----b950cd0d60f4---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb950cd0d60f4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-stochastic-policies-are-better-than-deterministic-ones-b950cd0d60f4&source=-----b950cd0d60f4---------------------bookmark_footer-----------)![](../Images/8175bb620e2361f15241cbfd404190f9.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Rock-paper-scissors would be a dull affair with deterministic policies [Photo
    by [Marcus Wallis](https://unsplash.com/@marcus_wallis?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)]
  prefs: []
  type: TYPE_NORMAL
- en: If you are used to deterministic decision-making policies (e.g., as in [Deep
    Q-learning](https://medium.com/towards-data-science/deep-q-learning-for-the-cliff-walking-problem-b54835409046)),
    the need for and use of stochastic policies might elude you. After all, **deterministic
    policies** offer a convenient state-action mapping *π:s ↦ a*, ideally even the
    optimal mapping (that is, if all the Bellman equations are learned to perfection).
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, **stochastic policies —** represented by a conditional probability
    distribution over the actions in a given state, *π:P(a|s)* — seem rather inconvenient
    and imprecise. Why would we allow randomness to direct our actions, why leave
    the selection of the best known decisions to chance?
  prefs: []
  type: TYPE_NORMAL
- en: In reality, a huge number of Reinforcement Learning (RL) algorithms indeed deploys
    stochastic policies, judging by the sheer number of actor-critic algorithms out
    there. Evidently, there must be some benefit to this approach. This article discusses
    four cases in which stochastic policies are superior to their deterministic counterparts.
  prefs: []
  type: TYPE_NORMAL
