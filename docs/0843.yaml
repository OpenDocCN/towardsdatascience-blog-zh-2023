- en: Full Explanation of MLE, MAP and Bayesian Inference
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/full-explanation-of-mle-map-and-bayesian-inference-1db9a7fb1d2b?source=collection_archive---------10-----------------------#2023-03-06](https://towardsdatascience.com/full-explanation-of-mle-map-and-bayesian-inference-1db9a7fb1d2b?source=collection_archive---------10-----------------------#2023-03-06)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Introducing maximum likelihood estimation, maximum a posteriori estimation and
    Bayesian Inference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@hrmnmichaels?source=post_page-----1db9a7fb1d2b--------------------------------)[![Oliver
    S](../Images/b5ee0fa2d5fb115f62e2e9dfcb92afdd.png)](https://medium.com/@hrmnmichaels?source=post_page-----1db9a7fb1d2b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1db9a7fb1d2b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1db9a7fb1d2b--------------------------------)
    [Oliver S](https://medium.com/@hrmnmichaels?source=post_page-----1db9a7fb1d2b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff2daf6260cca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffull-explanation-of-mle-map-and-bayesian-inference-1db9a7fb1d2b&user=Oliver+S&userId=f2daf6260cca&source=post_page-f2daf6260cca----1db9a7fb1d2b---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1db9a7fb1d2b--------------------------------)
    ·13 min read·Mar 6, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1db9a7fb1d2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffull-explanation-of-mle-map-and-bayesian-inference-1db9a7fb1d2b&user=Oliver+S&userId=f2daf6260cca&source=-----1db9a7fb1d2b---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1db9a7fb1d2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffull-explanation-of-mle-map-and-bayesian-inference-1db9a7fb1d2b&source=-----1db9a7fb1d2b---------------------bookmark_footer-----------)![](../Images/ed3fd52dd4249d2f6376d0b4e133f357.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [fabio](https://unsplash.com/@fabioha?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/oyXis2kALVg?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: In this post we will introduce the concepts *MLE (maximum likelihood estimation)*,
    *MAP (maximum a posteriori estimation)* and *Bayesian inference* — which are fundamental
    to statistics, data science and machine learning, to name just a few fields. We
    will explain each method using the same example of an unfair coin toss, derive
    results analytically and numerically (for Bayesian inference) and show differences.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will learn that MLE maximises the likelihood — i.e. chooses parameters which
    maximise the likelihood of the observed data. MAP adds a prior, inducing prior
    knowledge over the parameters — thus bridging the gap from a purely Frequentist
    concept to a Bayesian one ([link](/statistics-are-you-bayesian-or-frequentist-4943f953f21b)).
    Bayesian inference eventually gives us the most information, but also is the hardest
    to execute: it involves modelling the full posterior distribution of the parameter
    given the data — as opposed to the previous methods just yielding point estimates.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s set the stage by formalising these descriptions: essentially, for any
    kind of learning problem we want to find a model / parameters which describe the
    observed data as well as possible. We can fully describe and solve this by…'
  prefs: []
  type: TYPE_NORMAL
