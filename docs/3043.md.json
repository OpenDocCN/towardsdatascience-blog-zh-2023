["```py\ndef getZippedFilePaths():\n    zip_file_names = []\n    for dirname, _, filenames in os.walk('/kaggle/input'):\n        for filename in filenames:\n            if filename.split('.')[-1] == 'zip':\n                zip_file_names.append((os.path.join(dirname, filename)))\n\n    return zip_file_names\n\nzip_file_names = getZippedFilePaths()\n\nitems_to_remove = ['/kaggle/input/carvana-image-masking-challenge/train.zip', \n                   '/kaggle/input/carvana-image-masking-challenge/test.zip']\n\nzip_file_names = [item for item in zip_file_names if item not in items_to_remove]\n\nfor zip_file_path in zip_file_names:\n    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n        zip_ref.extractall()\n```", "```py\n# Appending all path names to a sorted list\ntrain_hq_dir = '/kaggle/working/train_hq/'\ntrain_masks_dir = '/kaggle/working/train_masks/'\ntest_hq_dir = '/kaggle/working/test_hq/'\n\nX_train_id = sorted([os.path.join(train_hq_dir, filename) for filename in os.listdir(train_hq_dir)], key=lambda x: x.split('/')[-1].split('.')[0])\ny_train = sorted([os.path.join(train_masks_dir, filename) for filename in os.listdir(train_masks_dir)], key=lambda x: x.split('/')[-1].split('.')[0])\nX_test_id = sorted([os.path.join(test_hq_dir, filename) for filename in os.listdir(test_hq_dir)], key=lambda x: x.split('/')[-1].split('.')[0])\n\nX_train_id = X_train_id[:1000]\ny_train = y_train[:1000]\nX_train, X_val, y_train, y_val = train_test_split(X_train_id, y_train, test_size=0.2, random_state=42)\n\n# Create Dataset objects from the list of file paths\nX_train = tf.data.Dataset.from_tensor_slices(X_train)\ny_train = tf.data.Dataset.from_tensor_slices(y_train)\n\nX_val = tf.data.Dataset.from_tensor_slices(X_val)\ny_val = tf.data.Dataset.from_tensor_slices(y_val)\n\nX_test = tf.data.Dataset.from_tensor_slices(X_test_id)\n\nimg_height = 96\nimg_width = 128\nnum_channels = 3\n\nimg_size = (img_height, img_width)\n\n# Apply preprocessing\nX_train = X_train.map(preprocess_image)\ny_train = y_train.map(preprocess_target)\n\nX_val = X_val.map(preprocess_image)\ny_val = y_val.map(preprocess_target)\n\nX_test = X_test.map(preprocess_image)\n\n# Add labels to dataframe objects (one-hot-encoded)\ntrain_dataset = tf.data.Dataset.zip((X_train, y_train))\nval_dataset = tf.data.Dataset.zip((X_val, y_val))\n\n# Apply the batch size to the dataset\nBATCH_SIZE = 32\nbatched_train_dataset = train_dataset.batch(BATCH_SIZE)\nbatched_val_dataset = val_dataset.batch(BATCH_SIZE)\nbatched_test_dataset = X_test.batch(BATCH_SIZE)\n\n# Adding autotune for pre-fetching\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nbatched_train_dataset = batched_train_dataset.prefetch(buffer_size=AUTOTUNE)\nbatched_val_dataset = batched_val_dataset.prefetch(buffer_size=AUTOTUNE)\nbatched_test_dataset = batched_test_dataset.prefetch(buffer_size=AUTOTUNE)\n```", "```py\ndef preprocess_image(file_path):\n    # Load and decode the image\n    img = tf.io.read_file(file_path)\n    # You can adjust channels based on your images (3 for RGB)\n    img = tf.image.decode_jpeg(img, channels=3) # Returned as uint8\n    # Normalize the pixel values to [0, 1]\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    # Resize the image to your desired dimensions\n    img = tf.image.resize(img, [96, 128], method = 'nearest')\n    return img\n\ndef preprocess_target(file_path):\n    # Load and decode the image\n    mask = tf.io.read_file(file_path)\n    # Normalizing to between 0 and 1 (only two classes)\n    mask = tf.image.decode_image(mask, expand_animations=False, dtype=tf.float32)\n    # Get only one value for the 3rd channel\n    mask = tf.math.reduce_max(mask, axis=-1, keepdims=True)\n    # Resize the image to your desired dimensions\n    mask = tf.image.resize(mask, [96, 128], method = 'nearest')\n    return mask\n```", "```py\n# View images and associated labels\nfor images, masks in batched_val_dataset.take(1):\n    car_number = 0\n    for image_slot in range(16):\n        ax = plt.subplot(4, 4, image_slot + 1)\n        if image_slot % 2 == 0:\n            plt.imshow((images[car_number])) \n            class_name = 'Image'\n        else:\n            plt.imshow(masks[car_number], cmap = 'gray')\n            plt.colorbar()\n            class_name = 'Mask'\n            car_number += 1            \n        plt.title(class_name)\n        plt.axis(\"off\")\n```", "```py\ndata_augmentation = tf.keras.Sequential([\n        tfl.RandomFlip(mode=\"horizontal\", seed=42),\n        tfl.RandomRotation(factor=0.01, seed=42),\n        tfl.RandomContrast(factor=0.2, seed=42)\n])\n\ndef get_model(img_size):\n    inputs = Input(shape=img_size + (3,))\n    x = data_augmentation(inputs)\n\n    # Contracting path\n    x = tfl.Conv2D(64, 3, strides=2, activation=\"relu\", padding=\"same\", kernel_initializer='he_normal')(x) \n    x = tfl.Conv2D(64, 3, activation=\"relu\", padding=\"same\", kernel_initializer='he_normal')(x) \n    x = tfl.Conv2D(128, 3, strides=2, activation=\"relu\", padding=\"same\", kernel_initializer='he_normal')(x) \n    x = tfl.Conv2D(128, 3, activation=\"relu\", padding=\"same\", kernel_initializer='he_normal')(x) \n    x = tfl.Conv2D(256, 3, strides=2, padding=\"same\", activation=\"relu\", kernel_initializer='he_normal')(x) \n    x = tfl.Conv2D(256, 3, activation=\"relu\", padding=\"same\", kernel_initializer='he_normal')(x)\n\n    # Expanding path\n    x = tfl.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\", kernel_initializer='he_normal')(x)\n    x = tfl.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\", kernel_initializer='he_normal', strides=2)(x)\n    x = tfl.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\", kernel_initializer='he_normal')(x)\n    x = tfl.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\", kernel_initializer='he_normal', strides=2)(x)\n    x = tfl.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\", kernel_initializer='he_normal')(x)\n    x = tfl.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\", kernel_initializer='he_normal', strides=2)(x)\n\n    outputs = tfl.Conv2D(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n    model = keras.Model(inputs, outputs) \n\n    return model\n\ncustom_model = get_model(img_size=img_size)\n```", "```py\nfrom tensorflow.keras import backend as K\n\ndef dice_coef(y_true, y_pred, smooth=10e-6):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    dice = (2\\. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return dice\n\ndef dice_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n```", "```py\ncustom_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001,\n                                                        epsilon=1e-06), \n                                                        loss=[dice_loss], \n                                                        metrics=[dice_coef])\ncallbacks_list = [\n    keras.callbacks.EarlyStopping(\n        monitor=\"val_loss\",\n        patience=2,\n    ),\n    keras.callbacks.ModelCheckpoint(\n        filepath=\"best-custom-model\",\n        monitor=\"val_loss\",\n        save_best_only=True,\n    )\n]\n\nhistory = custom_model.fit(batched_train_dataset, epochs=20,\n                    callbacks=callbacks_list,\n                    validation_data=batched_val_dataset)\n```", "```py\ndef display(display_list):\n    plt.figure(figsize=(15, 15))\n\n    title = ['Input Image', 'True Mask', 'Predicted Mask']\n\n    for i in range(len(display_list)):\n        plt.subplot(1, len(display_list), i+1)\n        plt.title(title[i])\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n        plt.axis('off')\n    plt.show()\n\ndef create_mask(pred_mask):\n    mask = pred_mask[..., -1] >= 0.5\n    pred_mask[..., -1] = tf.where(mask, 1, 0)\n    # Return only first mask of batch\n    return pred_mask[0]\n\ndef show_predictions(model, dataset=None, num=1):\n    \"\"\"\n    Displays the first image of each of the num batches\n    \"\"\"\n    if dataset:\n        for image, mask in dataset.take(num):\n            pred_mask = model.predict(image)\n            display([image[0], mask[0], create_mask(pred_mask)])\n    else:\n        display([sample_image, sample_mask,\n             create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n\ncustom_model = keras.models.load_model(\"/kaggle/working/best-custom-model\", custom_objects={'dice_coef': dice_coef, 'dice_loss': dice_loss})\n\nshow_predictions(model = custom_model, dataset = batched_train_dataset, num = 6)\n```", "```py\ndef conv_block(inputs=None, n_filters=64, dropout_prob=0, max_pooling=True):\n    conv = Conv2D(n_filters,  \n                  3,   \n                  activation='relu',\n                  padding='same',\n                  kernel_initializer='he_normal')(inputs)\n    conv = Conv2D(n_filters,  \n                  3,   \n                  activation='relu',\n                  padding='same',\n                  kernel_initializer='he_normal')(conv)\n\n    if dropout_prob > 0:\n        conv = Dropout(dropout_prob)(conv)\n\n    if max_pooling:\n        next_layer = MaxPooling2D(pool_size=(2, 2))(conv)\n\n    else:\n        next_layer = conv\n\n    skip_connection = conv\n\n    return next_layer, skip_connection\n\ndef upsampling_block(expansive_input, contractive_input, n_filters=64):\n    up = Conv2DTranspose(\n        n_filters,    \n        3,    \n        strides=(2, 2),\n        padding='same',\n        kernel_initializer='he_normal')(expansive_input)\n\n    # Merge the previous output and the contractive_input\n    merge = concatenate([up, contractive_input], axis=3)\n\n    conv = Conv2D(n_filters,   \n                  3,     \n                  activation='relu',\n                  padding='same',\n                  kernel_initializer='he_normal')(merge)\n    conv = Conv2D(n_filters,   \n                  3,     \n                  activation='relu',\n                  padding='same',\n                  kernel_initializer='he_normal')(conv)\n\n    return conv\n\ndef unet_model(input_size=(96, 128, 3), n_filters=64, n_classes=1):\n    inputs = Input(input_size)\n\n    inputs = data_augmentation(inputs)\n\n    # Contracting Path (encoding)\n    cblock1 = conv_block(inputs, n_filters)\n    cblock2 = conv_block(cblock1[0], n_filters*2)\n    cblock3 = conv_block(cblock2[0], n_filters*4)\n    cblock4 = conv_block(cblock3[0], n_filters*8, dropout_prob=0.3)\n\n    # Bottleneck Layer\n    cblock5 = conv_block(cblock4[0], n_filters*16, dropout_prob=0.3, max_pooling=False)\n\n    # Expanding Path (decoding)\n    ublock6 = upsampling_block(cblock5[0], cblock4[1],  n_filters*8)\n    ublock7 = upsampling_block(ublock6, cblock3[1],  n_filters*4)\n    ublock8 = upsampling_block(ublock7, cblock2[1],  n_filters*2)\n    ublock9 = upsampling_block(ublock8, cblock1[1],  n_filters)\n\n    conv9 = Conv2D(n_filters,\n                   3,\n                   activation='relu',\n                   padding='same',\n                   kernel_initializer='he_normal')(ublock9)\n\n    conv10 = Conv2D(n_classes, 1, padding='same', activation=\"sigmoid\")(conv9)\n\n    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n\n    return model\n```", "```py\nunet = unet_model(input_size=(img_height, img_width, num_channels), n_filters=64, n_classes=1)\nunet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, epsilon=1e-06),\n             loss=[dice_loss], \n             metrics=[dice_coef])\n\ncallbacks_list = [\n    keras.callbacks.EarlyStopping(\n        monitor=\"val_loss\",\n        patience=2,\n    ),\n    keras.callbacks.ModelCheckpoint(\n        filepath=\"best-u_net-model\",\n        monitor=\"val_loss\",\n        save_best_only=True,\n    )\n]\n\nhistory = unet.fit(batched_train_dataset, epochs=20,\n                    callbacks=callbacks_list,\n                    validation_data=batched_val_dataset)\n```", "```py\nunet = keras.models.load_model(\"/kaggle/working/best-u_net-model\", custom_objects={'dice_coef': dice_coef, 'dice_loss': dice_loss})\n\nshow_predictions(model = unet, dataset = batched_train_dataset, num = 6)\n```"]