- en: Using Quantum Annealing for Feature Selection in scikit-learn
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用量子退火进行 scikit-learn 特征选择
- en: 原文：[https://towardsdatascience.com/using-quantum-annealing-for-feature-selection-in-scikit-learn-e747d056f673?source=collection_archive---------7-----------------------#2023-04-10](https://towardsdatascience.com/using-quantum-annealing-for-feature-selection-in-scikit-learn-e747d056f673?source=collection_archive---------7-----------------------#2023-04-10)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/using-quantum-annealing-for-feature-selection-in-scikit-learn-e747d056f673?source=collection_archive---------7-----------------------#2023-04-10](https://towardsdatascience.com/using-quantum-annealing-for-feature-selection-in-scikit-learn-e747d056f673?source=collection_archive---------7-----------------------#2023-04-10)
- en: Feature selection for scikit-learn models, for datasets with many features,
    using quantum processing
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对于具有大量特征的数据集，使用量子处理进行 scikit-learn 模型的特征选择
- en: '[](https://florin-andrei.medium.com/?source=post_page-----e747d056f673--------------------------------)[![Florin
    Andrei](../Images/372ac3e80dbc03cbd20295ec1df5fa6f.png)](https://florin-andrei.medium.com/?source=post_page-----e747d056f673--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e747d056f673--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e747d056f673--------------------------------)
    [Florin Andrei](https://florin-andrei.medium.com/?source=post_page-----e747d056f673--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://florin-andrei.medium.com/?source=post_page-----e747d056f673--------------------------------)[![Florin
    Andrei](../Images/372ac3e80dbc03cbd20295ec1df5fa6f.png)](https://florin-andrei.medium.com/?source=post_page-----e747d056f673--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e747d056f673--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e747d056f673--------------------------------)
    [Florin Andrei](https://florin-andrei.medium.com/?source=post_page-----e747d056f673--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Faeaeb9d7d248&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-quantum-annealing-for-feature-selection-in-scikit-learn-e747d056f673&user=Florin+Andrei&userId=aeaeb9d7d248&source=post_page-aeaeb9d7d248----e747d056f673---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e747d056f673--------------------------------)
    ·11 min read·Apr 10, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe747d056f673&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-quantum-annealing-for-feature-selection-in-scikit-learn-e747d056f673&user=Florin+Andrei&userId=aeaeb9d7d248&source=-----e747d056f673---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Faeaeb9d7d248&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-quantum-annealing-for-feature-selection-in-scikit-learn-e747d056f673&user=Florin+Andrei&userId=aeaeb9d7d248&source=post_page-aeaeb9d7d248----e747d056f673---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e747d056f673--------------------------------)
    · 11 分钟阅读 · 2023年4月10日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe747d056f673&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-quantum-annealing-for-feature-selection-in-scikit-learn-e747d056f673&user=Florin+Andrei&userId=aeaeb9d7d248&source=-----e747d056f673---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe747d056f673&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-quantum-annealing-for-feature-selection-in-scikit-learn-e747d056f673&source=-----e747d056f673---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe747d056f673&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-quantum-annealing-for-feature-selection-in-scikit-learn-e747d056f673&source=-----e747d056f673---------------------bookmark_footer-----------)'
- en: Feature selection is a vast topic in machine learning. When done correctly,
    it can help reduce overfitting, increase interpretability, reduce the computational
    burden, etc. Numerous techniques are used to perform feature selection. What they
    all have in common is that they look at the set of features and try to separate
    features that lead to good outcomes (accurate predictions, interpretable models,
    etc) from features that do not help with this goal.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 特征选择是机器学习中的一个广泛话题。正确实施时，它可以帮助减少过拟合、提高可解释性、降低计算负担等。用于特征选择的技术有很多种，它们的共同点在于它们会查看特征集，并尝试将那些能够带来良好结果（准确的预测、可解释的模型等）的特征与那些不利于此目标的特征分开。
- en: Particularly difficult are cases where the number of features is very large.
    An exhaustive exploration of all combinations of features is often computationally
    prohibitive. Algorithms such as the stepwise search by the `regsubsets()` function
    in R may try to infer promising combinations of features by adding / removing
    features and comparing the results. But ultimately, when the number of features
    is large, a trade-off remains between the degree of success of the search and
    the effort spent finding the best combination of features.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 特别困难的是特征数量非常大的情况。对所有特征组合进行穷举探索通常计算开销很大。像R中的`regsubsets()`函数那样的逐步搜索算法可能会通过添加/删除特征并比较结果来尝试推断出有前途的特征组合。但最终，当特征数量很大时，搜索成功的程度与寻找最佳特征组合所花费的努力之间仍然存在权衡。
- en: As a rule of thumb, when the best solution to a problem involves searching over
    a large number of combinations, quantum annealing might be worth investigating.
    I will show an example of feature selection for a dataset with hundreds of features
    using a scikit-learn plugin recently published by D-Wave.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，当问题的最佳解涉及到大量组合的搜索时，量子退火可能值得研究。我将展示一个使用D-Wave最近发布的scikit-learn插件进行特征选择的例子，该数据集具有数百个特征。
- en: D-Wave and scikit-learn
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: D-Wave和scikit-learn
- en: Keep in mind, this is not general-purpose, gate-model quantum computing. This
    is an algorithm that, in essence, is similar to simulated annealing, in that there
    is an objective function, and something like simulated annealing is used to find
    a combination of values that minimizes the objective. Except the annealing is
    not simulated — instead, a real system is programmed such that the physical energy
    of the system matches the objective function. The energy of the system is lowered
    until it reaches a minimum (annealing), and then the solution is simply the state
    of the system, which is read and returned to the user.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这并不是通用的门模型量子计算。这是一种算法，本质上类似于模拟退火，其中有一个目标函数，并且使用类似于模拟退火的方法来找到一个最小化目标的值组合。不同的是，这里的退火并非模拟的，而是通过编程使实际系统的物理能量与目标函数相匹配。系统的能量会降低直到达到最低点（退火），然后解就是系统的状态，这个状态会被读取并返回给用户。
- en: '[D-Wave](https://www.dwavesys.com/) builds quantum annealers that can efficiently
    solve many problems where the combinatorial complexity is high. As long as you
    can reduce the problem to a binary quadratic model (BQM), or a BQM with constraints
    (CQM), or some discrete generalization of the above (DQM), the problem can be
    submitted to the quantum solvers. More details are in [the documentation](https://docs.dwavesys.com/docs/latest/doc_getting_started.html).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[D-Wave](https://www.dwavesys.com/) 构建了量子退火器，可以有效地解决许多组合复杂度很高的问题。只要你能将问题简化为二次二进制模型（BQM），或者带约束的BQM（CQM），或者上述模型的某些离散推广（DQM），问题就可以提交给量子解算器。更多细节请参见[文档](https://docs.dwavesys.com/docs/latest/doc_getting_started.html)。'
- en: In theory, you could formulate the feature selection algorithm in terms of a
    BQM, where the presence of a feature is a binary variable of value 1, and the
    absence of a feature is a variable equal to 0, but that takes some effort. D-Wave
    provides [a scikit-learn plugin](https://github.com/dwavesystems/dwave-scikit-learn-plugin)
    that can be plugged directly into scikit-learn pipelines and simplifies the process.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，你可以将特征选择算法表述为BQM，其中特征的存在是值为1的二进制变量，而特征的缺失是值为0的变量，但这需要一些工作。D-Wave提供了一个可以直接插入到scikit-learn管道中的[scikit-learn插件](https://github.com/dwavesystems/dwave-scikit-learn-plugin)，简化了这一过程。
- en: This article will first show the entire process of explicitly formulating a
    BQM, then a CQM, sending the model out to the quantum solver, then parsing the
    results. This is the general method of solving optimization processes on the quantum
    annealer, and can be used for many problems.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本文将首先展示显式地表述BQM的整个过程，然后是CQM，将模型发送到量子解算器，然后解析结果。这是解决量子退火器上优化过程的一般方法，并且可以用于许多问题。
- en: But if all you want is to select the best features in a dataset, a simple `SelectFromQuadraticModel()`
    method call is enough. This collapses the whole algorithm into a single line of
    code. We will show that at the end.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果你只是想选择数据集中最好的特征，一个简单的`SelectFromQuadraticModel()`方法调用就足够了。这将整个算法压缩成一行代码。我们将在最后展示这一点。
- en: Problem and method
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题与方法
- en: 'Consider the [Scene Recognition Dataset](https://www.openml.org/d/312) downloaded
    from OpenML, originally created by [Boutell, M., Luo, J., Shen, X., Brown, C.
    (2004)](https://www.sciencedirect.com/science/article/abs/pii/S0031320304001074)
    and distributed under a CC BY license by its authors. It is a binary classification
    dataset with one dependent variable (Urban), and has nearly 300 features. The
    value of the response variable (binary: urban or not urban) needs to be predicted
    based on a combination of features. A simple classification model such as `RandomForestClassifier()`
    should perform well, assuming the features are chosen properly.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑从OpenML下载的[场景识别数据集](https://www.openml.org/d/312)，最初由[Boutell, M., Luo, J.,
    Shen, X., Brown, C. (2004)](https://www.sciencedirect.com/science/article/abs/pii/S0031320304001074)创建，并由其作者在CC
    BY许可证下分发。这是一个二分类数据集，具有一个依赖变量（Urban），并有近300个特征。响应变量的值（二元：城市或非城市）需要基于特征的组合进行预测。一个简单的分类模型如`RandomForestClassifier()`应该表现良好，前提是特征选择得当。
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'A method for choosing the features, described in [a paper by Milne, Rounds,
    and Goddard (2018)](https://1qbit.com/whitepaper/optimal-feature-selection-in-credit-scoring-classification-using-quantum-annealer/)
    is a good fit for the quantum annealers and can be summarized this way:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一种选择特征的方法，描述在[Milne, Rounds, 和Goddard (2018)的论文](https://1qbit.com/whitepaper/optimal-feature-selection-in-credit-scoring-classification-using-quantum-annealer/)中，适合量子退火机，并可以总结如下：
- en: Split the dataset into the matrix of features, and the response vector — the
    (X, y) tuple familiar from scikit-learn. Using these, construct a correlation
    matrix C, where Cii represent the correlations of features with the response,
    and Cij are the mutual correlations of the features. Of the features that are
    highly correlated with the response, we want to capture as many as possible. Of
    the features that are correlated with each other, we want to capture as few as
    possible, but without affecting features that are strongly correlated with the
    response. Obviously, we want to strike a balance between all these criteria.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据集拆分为特征矩阵和响应向量——即scikit-learn中熟悉的(X, y)元组。使用这些，构造一个相关矩阵C，其中Cii表示特征与响应的相关性，Cij是特征之间的相互相关性。对于与响应高度相关的特征，我们希望尽可能多地捕获。对于彼此相关的特征，我们希望尽可能少地捕获，但不影响与响应强相关的特征。显然，我们希望在所有这些标准之间取得平衡。
- en: 'Let Xi be binary variables that indicate whether feature i is chosen for the
    final dataset. If feature i is chosen, then Xi = 1, otherwise Xi = 0\. The problem
    then becomes equivalent to finding the extreme of:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 设Xi为二元变量，指示特征i是否被选择到最终数据集中。如果选择了特征i，则Xi = 1，否则Xi = 0。问题变成了等同于寻找极值：
- en: '![](../Images/ed33a2a33134634f69b8ea136b01c8f1.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ed33a2a33134634f69b8ea136b01c8f1.png)'
- en: objective function
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 目标函数
- en: The first sum of term represents the individual contributions from features
    — let’s call them linear terms. The second sum of terms could be said to contain
    quadratic interaction terms. alpha is a bias coefficient that controls the amount
    of interaction between features that we allow in the objective function; its values
    will have to be explored to find the best outcome. Finding the set of Xi that
    minimizes the objective function is equivalent to feature selection.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个项的总和表示来自特征的个别贡献——我们称之为线性项。第二个项的总和可以说包含了二次交互项。alpha是一个偏置系数，它控制目标函数中我们允许的特征之间的交互量；其值需要探索以找到最佳结果。找到最小化目标函数的Xi集合等同于特征选择。
- en: The objective function is literally a binary quadratic model — BQM. It is binary
    because Xi can be either 0 or 1\. It is quadratic because the highest order terms
    are the quadratic interactions. This can be easily solved on a quantum annealer.
    The only constraint we will need to apply is that the number of variables Xi that
    are equal to 1 cannot be greater than the total number of features we are willing
    to accept.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 目标函数实际上是一个二次二元模型——BQM。它是二元的，因为Xi可以是0或1。它是二次的，因为最高阶的项是二次交互项。这可以很容易地在量子退火机上解决。我们需要应用的唯一约束是，等于1的变量Xi的数量不能超过我们愿意接受的特征总数。
- en: Feature selection the hard way
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用困难的方法进行特征选择
- en: Let’s solve the problem. The code block below imports all the libraries we need,
    downloads the dataset, and instantiates a classifier model.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来解决这个问题。下面的代码块导入了我们需要的所有库，下载了数据集，并实例化了一个分类模型。
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We are interested in two things:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们关注两件事：
- en: the “relevance” of each feature, which is the strength of its correlation with
    the response
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个特征的“相关性”，即它与响应的相关强度
- en: the “redundancy” of features, which is just the set of non-diagonal items in
    the correlation matrix (weights of quadratic interaction terms)
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征的“冗余性”，即相关矩阵中的非对角项（二次交互项的权重）
- en: Let’s build a couple of functions to visualize relevance and redundancy, apply
    them to the entire dataset without feature selection, and then cross-validate
    (5 folds) the performance of the model on the entire dataset.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们构建几个函数来可视化相关性和冗余性，将它们应用于没有特征选择的整个数据集，然后在整个数据集上进行交叉验证（5 折）模型的性能。
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This is the result:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![](../Images/d404dc2909d215a51faa41f8e31b8544.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d404dc2909d215a51faa41f8e31b8544.png)'
- en: baseline performance
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 基线性能
- en: The accuracy of the model is 0.9082\. Features vary significantly in terms of
    relevance. There are pockets of redundancy where there seems to be strong correlation
    between features.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的准确性为 0.9082。特征在相关性方面变化显著。有一些冗余的区域，特征之间似乎存在强相关性。
- en: To minimize the objective function, let’s create a quadratic model with constraints,
    and send it to the quantum annealer. The code will be explained below.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最小化目标函数，让我们创建一个带有约束的二次模型，并将其发送到量子退火器。代码将在下面解释。
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: There’s a lot going on there. Let’s explain each step.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这里发生了很多事情。让我们解释每一步。
- en: We limit the number of features to k=30\. This is the main constraint for the
    model.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将特征数量限制为k=30。这是模型的主要限制。
- en: We deviate slightly from the objective function described in the paper. Instead
    of defining alpha directly, we use an equivalent parameter beta, which serves
    the same purpose. And then we define alpha in a way that keeps the contribution
    of interaction terms under control — if the number of features is extremely large,
    this will make sure the interaction terms do not overwhelm the linear terms in
    the objective function.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们稍微偏离了论文中描述的目标函数。我们没有直接定义 alpha，而是使用了一个等效参数 beta，它具有相同的作用。然后我们以一种保持交互项贡献受控的方式定义
    alpha——如果特征数量极大，这将确保交互项不会压倒目标函数中的线性项。
- en: We shape the correlation matrix in a way that can be used to build a BQM directly.
    We constrain the BQM with the condition that no more than k=30 features can be
    used, and so we obtain a constrained quadratic model (CQM). We send the CQM to
    the quantum annealer and collect the results.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以一种可以直接构建 BQM 的方式塑造相关矩阵。我们将 BQM 限制在不超过 k=30 个特征的条件下，因此我们获得一个受限的二次模型 (CQM)。我们将
    CQM 发送到量子退火器并收集结果。
- en: It should be noted that the run time of the quantum part of the code is about
    10 seconds. For many problems, this is a typical baseline duration, even when
    the number of variables is large. The run time tends to increase with the complexity
    of the problem, but the increase may not be as abrupt as you’d expect from classical
    solvers.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 应该注意的是，量子部分代码的运行时间约为 10 秒。对于许多问题，这是一个典型的基准时长，即使变量数量很大。运行时间往往随着问题复杂性的增加而增加，但这种增加可能不会像你从经典求解器中预期的那样急剧。
- en: 'We’re not done yet. The D-Wave hardware typically samples the solution space,
    and returns a large number of potentially feasible solutions. This is due to the
    way the hardware works: one annealing event is quick and easy to run, so it makes
    sense to run annealing repeatedly, which is what happens here automatically. If
    enough samples are generated, some of them will be the best solution.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还没有完成。D-Wave 硬件通常会对解决方案空间进行采样，并返回大量可能的可行解决方案。这是因为硬件的工作方式：一个退火事件运行迅速且容易，因此重复进行退火是有意义的，这里自动发生了。如果生成足够多的样本，其中一些将是最佳解决方案。
- en: So we need to sort the solutions and pick the best one. “Best” means — it has
    the lowest value for the objective function, which D-Wave calls “energy” because
    it really is the physical energy of the quantum processor.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们需要对解决方案进行排序并挑选最佳方案。“最佳”意味着——它在目标函数中具有最低的值，D-Wave 称之为“能量”，因为它确实是量子处理器的物理能量。
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '`features` is the array with the indices of the features picked by the quantum
    annealer. It is the solution to the feature selection process. Obviously, its
    length will be k=30.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`features` 是一个包含量子退火器选定特征索引的数组。这是特征选择过程的结果。显然，它的长度将是 k=30。'
- en: 'Let’s measure the accuracy of the model after feature selection:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在特征选择后测量模型的准确性：
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/1bdf597311e331f7e012d682fb9a9c3b.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1bdf597311e331f7e012d682fb9a9c3b.png)'
- en: explicit optimization
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 显式优化
- en: The accuracy of the model after feature selection is 0.9381\. We got exactly
    the number of features we want. Most of them have high relevance. And the correlation
    values between features are generally low. The model performs better, chances
    are it’s easier to interpret, and the time it took to select the right features
    was not too long.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 特征选择后的模型准确度为 0.9381。我们获得了确切数量的特征。大多数特征具有很高的相关性。特征之间的相关值通常较低。模型表现更好，可能更容易解释，并且选择正确特征所花费的时间并不长。
- en: But the process is long and tedious, if all you want is to select some features.
    Fortunately there is a much easier way now.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 但是这个过程很长且繁琐，如果你只想选择一些特征的话。幸运的是，现在有一种更简单的方法。
- en: Feature selection the easy way
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 轻松的特征选择方法
- en: 'If you have the D-Wave scikit-learn plugin installed, all you have to do is
    this:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你安装了 D-Wave scikit-learn 插件，你只需执行以下操作：
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'That’s literally it. Behind the scenes, the code creates the quadratic model,
    constrains it, sends it out to the quantum solver, gets the results back, parses
    them, and selects the best result to be returned in NumPy array format, the way
    scikit-learn likes it. The run time is about the same. But let’s see what the
    results look like:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是全部了。后台代码创建了二次模型，对其进行约束，发送到量子求解器，获取结果，再进行解析，最后选择最佳结果以 NumPy 数组格式返回，这是 scikit-learn
    所期望的格式。运行时间大致相同。但让我们看看结果是什么样的：
- en: '[PRE7]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/a40d30fc00a2ef4480f93234552d20a2.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a40d30fc00a2ef4480f93234552d20a2.png)'
- en: plugin optimization
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 插件优化
- en: The accuracy of the model is 0.9369, essentially the same as the performance
    we got from the explicit optimization (well within the typical fluctuation of
    various random components).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的准确度为 0.9369，本质上与我们通过显式优化获得的性能相同（在各种随机组件的典型波动范围内）。
- en: The set of features that got selected is slightly different. This may be accounted
    for by slight differences between my manual process and the automated implementation
    in the library.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 选择的特征集略有不同。这可能是由于我的手动过程和库中的自动化实现之间的微小差异造成的。
- en: In either case, we moved the performance of the model up from good to great,
    with an algorithm that does not guess heuristically, but takes into account the
    totality of the features.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何一种情况下，我们都将模型的性能从良好提升到了卓越，通过一种不进行启发式猜测的算法，而是考虑了所有特征的总和。
- en: Further topics to explore
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 待探索的进一步主题
- en: The alpha parameter will bias the feature selection algorithm towards either
    less redundancy but potentially less quality (alpha=0) or towards higher quality
    but at the price of increased redundancy (alpha=1). Which is the best value depends
    on the problem you’re trying to solve.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: alpha 参数会使特征选择算法偏向于减少冗余但可能质量较低（alpha=0），或者偏向于提高质量但代价是增加冗余（alpha=1）。最佳值取决于你要解决的问题。
- en: 'The `SelectFromQuadraticModel()` method has a parameter called `time_limit`
    which is exactly what the name says: it controls the maximum time spent on the
    solver. You pay for the time you use, so high values here might be expensive.
    On the other hand, if the quantum annealing does not seem to converge towards
    good enough solutions, higher values here might be worth exploring. The problem
    shown here is rather trivial for the quantum processor, so we just used the default
    value.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`SelectFromQuadraticModel()` 方法有一个名为 `time_limit` 的参数，正如名称所示：它控制求解器上的最大时间。你为所用的时间付费，因此这里的高值可能会很昂贵。另一方面，如果量子退火似乎未能收敛到足够好的解决方案，这里较高的值可能值得探索。这里展示的问题对量子处理器而言相当简单，所以我们仅使用了默认值。'
- en: Keep in mind the data exchange between your computer and the quantum solver
    in the cloud may be non-trivial, so the latency of your connection might be important
    in time-critical applications such as finance.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，你的计算机与云端量子求解器之间的数据交换可能并非简单，因此在时间敏感的应用程序（如金融）中，连接的延迟可能非常重要。
- en: References
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料
- en: D-Wave webinar introducing the scikit-learn plugin. [https://www.youtube.com/watch?v=VHEpe00AXPI](https://www.youtube.com/watch?v=VHEpe00AXPI)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: D-Wave 网络研讨会介绍了 scikit-learn 插件。[https://www.youtube.com/watch?v=VHEpe00AXPI](https://www.youtube.com/watch?v=VHEpe00AXPI)
- en: Milne, A., Rounds, M., & Goddard, P. (2018). *Optimal Feature Selection in Credit
    Scoring and Classification Using a Quantum Annealer*. 1QBit.com. [https://1qbit.com/whitepaper/optimal-feature-selection-in-credit-scoring-classification-using-quantum-annealer/](https://1qbit.com/whitepaper/optimal-feature-selection-in-credit-scoring-classification-using-quantum-annealer/)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Milne, A., Rounds, M., & Goddard, P. (2018). *使用量子退火器进行信用评分和分类的最佳特征选择*。1QBit.com。[1QBit.com上的白皮书](https://1qbit.com/whitepaper/optimal-feature-selection-in-credit-scoring-classification-using-quantum-annealer/)
- en: Boutell, M., Luo, J., Shen, X., Brown, C. (2004). Learning multi-label scene
    classification. The Pattern Recognition journal on ScienceDirect. [https://www.sciencedirect.com/science/article/abs/pii/S0031320304001074](https://www.sciencedirect.com/science/article/abs/pii/S0031320304001074)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Boutell, M., Luo, J., Shen, X., Brown, C. (2004). 学习多标签场景分类。《模式识别》期刊，ScienceDirect。[文章链接](https://www.sciencedirect.com/science/article/abs/pii/S0031320304001074)
- en: Getting Started with D-Wave Solvers [https://docs.dwavesys.com/docs/latest/doc_getting_started.html](https://docs.dwavesys.com/docs/latest/doc_getting_started.html)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 入门指南：[D-Wave 求解器](https://docs.dwavesys.com/docs/latest/doc_getting_started.html)
- en: D-Wave scikit-learn Plugin [https://github.com/dwavesystems/dwave-scikit-learn-plugin](https://github.com/dwavesystems/dwave-scikit-learn-plugin)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: D-Wave scikit-learn 插件：[D-Wave scikit-learn 插件](https://github.com/dwavesystems/dwave-scikit-learn-plugin)
- en: 'D-Wave Examples: Feature Selection for CQM [https://github.com/dwave-examples/feature-selection-cqm](https://github.com/dwave-examples/feature-selection-cqm)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: D-Wave 示例：CQM 特征选择：[D-Wave 示例：CQM 特征选择](https://github.com/dwave-examples/feature-selection-cqm)
- en: OpenML Scene Recognition Dataset [https://www.openml.org/d/312](https://www.openml.org/d/312)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: OpenML 场景识别数据集：[OpenML 场景识别数据集](https://www.openml.org/d/312)
- en: Code and artifacts created for this article [https://github.com/FlorinAndrei/misc/tree/master/dwave-scikit-learn-feature-selection](https://github.com/FlorinAndrei/misc/tree/master/dwave-scikit-learn-feature-selection)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 为本文创作的代码和工件：[为本文创作的代码和工件](https://github.com/FlorinAndrei/misc/tree/master/dwave-scikit-learn-feature-selection)
- en: Thanks to Dr. Matthew Boutell of the Rose-Hulman Institute of Technology for
    granting me access to the Scene Features dataset under a Creative Commons license.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢罗斯-霍尔曼科技学院的**马修·布特尔博士**授权我在创作共用许可证下访问场景特征数据集。
- en: All images were created by the author.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 所有图像均由作者创作。
