# ä»‹ç» KeyLLM â€” ä½¿ç”¨ LLM è¿›è¡Œå…³é”®è¯æå–

> åŸæ–‡ï¼š[`towardsdatascience.com/introducing-keyllm-keyword-extraction-with-llms-39924b504813`](https://towardsdatascience.com/introducing-keyllm-keyword-extraction-with-llms-39924b504813)

## ä½¿ç”¨ KeyLLMã€KeyBERT å’Œ Mistral 7B æ¥æå–å…³é”®è¯

[](https://medium.com/@maartengrootendorst?source=post_page-----39924b504813--------------------------------)![Maarten Grootendorst](https://medium.com/@maartengrootendorst?source=post_page-----39924b504813--------------------------------)[](https://towardsdatascience.com/?source=post_page-----39924b504813--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----39924b504813--------------------------------) [Maarten Grootendorst](https://medium.com/@maartengrootendorst?source=post_page-----39924b504813--------------------------------)

Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page-----39924b504813--------------------------------) Â·é˜…è¯»æ—¶é—´ 9 åˆ†é’ŸÂ·2023 å¹´ 10 æœˆ 5 æ—¥

--

![](img/47514c37ae551ce79a535285a4d4488a.png)

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å˜å¾—è¶Šæ¥è¶Šå°ã€å¿«é€Ÿä¸”é«˜æ•ˆã€‚ç›´åˆ°æˆ‘å¼€å§‹è€ƒè™‘å®ƒä»¬ç”¨äºè¿­ä»£ä»»åŠ¡ï¼Œå¦‚å…³é”®è¯æå–ã€‚

åœ¨åˆ›å»ºäº†[KeyBERT](https://github.com/MaartenGr/KeyBERT)ä¹‹åï¼Œæˆ‘è§‰å¾—æ˜¯æ—¶å€™æ‰©å±•è¯¥åŒ…ä»¥åŒ…æ‹¬ LLMs äº†ã€‚å®ƒä»¬éå¸¸å¼ºå¤§ï¼Œæˆ‘å¸Œæœ›ä¸ºå°†æ¥è¿™äº›æ¨¡å‹å¯ä»¥åœ¨æ›´å°çš„ GPU ä¸Šè¿è¡Œåšå¥½å‡†å¤‡ã€‚

ä»‹ç»`[KeyLLM](https://maartengr.github.io/KeyBERT/guides/keyllm.html)`ï¼Œè¿™æ˜¯ KeyBERT çš„ä¸€ä¸ªæ‰©å±•ï¼Œå…è®¸ä½ ä½¿ç”¨ä»»ä½• LLM æ¥æå–ã€åˆ›å»ºç”šè‡³å¾®è°ƒå…³é”®è¯ï¼

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä½¿ç”¨æœ€è¿‘å‘å¸ƒçš„ Mistral 7B æ¨¡å‹çš„`[KeyLLM](https://maartengr.github.io/KeyBERT/guides/keyllm.html)`è¿›è¡Œå…³é”®è¯æå–ã€‚

æˆ‘ä»¬å°†ä»å®‰è£…ä¸€ç³»åˆ—åœ¨æœ¬ç¤ºä¾‹ä¸­å°†è¦ä½¿ç”¨çš„åŒ…å¼€å§‹ï¼š

```py
pip install --upgrade git+https://github.com/UKPLab/sentence-transformers
pip install keybert ctransformers[cuda]
pip install --upgrade git+https://github.com/huggingface/transformers
```

æˆ‘ä»¬æ­£åœ¨ä»ä¸»åˆ†æ”¯å®‰è£…`sentence-transformers`ï¼Œå› ä¸ºå®ƒä¿®å¤äº†ç¤¾åŒºæ£€æµ‹çš„åŠŸèƒ½ï¼Œæˆ‘ä»¬å°†åœ¨æœ€åå‡ ä¸ªç”¨ä¾‹ä¸­ä½¿ç”¨ã€‚æˆ‘ä»¬å¯¹`transformers`ä¹Ÿåšäº†åŒæ ·çš„å¤„ç†ï¼Œå› ä¸ºå®ƒå°šä¸æ”¯æŒ Mistral æ¶æ„ã€‚

ä½ ä¹Ÿå¯ä»¥è·Ÿéš[**Google Colab Notebook**](https://colab.research.google.com/drive/1A1lbPnBhtxL9jR7vFcm7Z0F0aJdEl-zj?usp=sharing)ä»¥ç¡®ä¿ä¸€åˆ‡æŒ‰é¢„æœŸå·¥ä½œã€‚

# ğŸ¤– åŠ è½½æ¨¡å‹

åœ¨ä¹‹å‰çš„æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•å¯¹åŸå§‹æ¨¡å‹çš„æƒé‡è¿›è¡Œé‡åŒ–ï¼Œä»¥ä¾¿åœ¨ä¸é‡åˆ°å†…å­˜é—®é¢˜çš„æƒ…å†µä¸‹è¿è¡Œã€‚

åœ¨è¿‡å»å‡ ä¸ªæœˆé‡Œï¼Œ[TheBloke](https://huggingface.co/TheBloke)ä¸ºæˆ‘ä»¬è¾›å‹¤å·¥ä½œï¼Œå¯¹æ•°ç™¾ä¸ªæ¨¡å‹è¿›è¡Œäº†é‡åŒ–ã€‚

è¿™æ ·ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥ä¸‹è½½æ¨¡å‹ï¼Œè¿™å°†å¤§å¤§åŠ å¿«é€Ÿåº¦ã€‚

æˆ‘ä»¬å°†ä»åŠ è½½æ¨¡å‹æœ¬èº«å¼€å§‹ã€‚æˆ‘ä»¬å°†æŠŠ 50 å±‚å¸è½½åˆ° GPU ä¸Šã€‚è¿™å°†å‡å°‘ RAM ä½¿ç”¨é‡ï¼Œè€Œä½¿ç”¨ VRAMã€‚å¦‚æœä½ é‡åˆ°å†…å­˜é”™è¯¯ï¼Œå‡å°‘è¿™ä¸ªå‚æ•°ï¼ˆ`gpu_layers`ï¼‰å¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©ï¼

```py
from ctransformers import AutoModelForCausalLM

# Set gpu_layers to the number of layers to offload to GPU. 
# Set to 0 if no GPU acceleration is available on your system.
model = AutoModelForCausalLM.from_pretrained(
    "TheBloke/Mistral-7B-Instruct-v0.1-GGUF",
    model_file="mistral-7b-instruct-v0.1.Q4_K_M.gguf",
    model_type="mistral",
    gpu_layers=50,
    hf=True
)
```

åœ¨åŠ è½½äº†æ¨¡å‹æœ¬èº«åï¼Œæˆ‘ä»¬æƒ³åˆ›å»ºä¸€ä¸ªğŸ¤— Transformers ç®¡é“ã€‚

è¿™æ ·åšçš„ä¸»è¦å¥½å¤„æ˜¯ï¼Œè¿™äº›ç®¡é“åœ¨è®¸å¤šæ•™ç¨‹ä¸­éƒ½æœ‰å‡ºç°ï¼Œé€šå¸¸ä½œä¸ºåå°åœ¨è½¯ä»¶åŒ…ä¸­ä½¿ç”¨ã€‚åˆ°ç›®å‰ä¸ºæ­¢ï¼Œ`ctransformers`çš„åŸç”Ÿæ”¯æŒç¨‹åº¦è¿˜æ²¡æœ‰`transformers`é‚£ä¹ˆé«˜ã€‚

ç”±äº Mistral çš„åˆ†è¯å™¨ç›¸å¯¹è¾ƒæ–°ï¼Œå°šæ— æ³•ä½¿ç”¨`ctransformers`åŠ è½½ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨åŸå§‹ä»“åº“ä¸­çš„åˆ†è¯å™¨ã€‚

```py
from transformers import AutoTokenizer, pipeline

# Tokenizer
tokenizer = AutoTokenizer.from_pretrained("mistralai/Mistral-7B-Instruct-v0.1")

# Pipeline
generator = pipeline(
    model=model, tokenizer=tokenizer,
    task='text-generation',
    max_new_tokens=50,
    repetition_penalty=1.1
)
```

# ğŸ“„ æç¤ºå·¥ç¨‹

è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªéå¸¸åŸºç¡€çš„ç¤ºä¾‹æ¥çœ‹çœ‹è¿™æ˜¯å¦æœ‰æ•ˆï¼š

```py
>>> response = generator("What is 1+1?")
>>> print(response[0]["generated_text"])
"""
What is 1+1?
A: 2
"""
```

å®Œç¾ï¼å®ƒå¯ä»¥å¤„ç†ä¸€ä¸ªéå¸¸åŸºæœ¬çš„é—®é¢˜ã€‚ä¸ºäº†å…³é”®è¯æå–çš„ç›®çš„ï¼Œè®©æˆ‘ä»¬æ¢ç´¢ä¸€ä¸‹å®ƒæ˜¯å¦èƒ½å¤„ç†æ›´å¤šçš„å¤æ‚æ€§ã€‚

```py
prompt = """
I have the following document:
* The website mentions that it only takes a couple of days to deliver but I still have not received mine

Extract 5 keywords from that document.
"""
response = generator(prompt)
print(response[0]["generated_text"])
```

æˆ‘ä»¬å¾—åˆ°å¦‚ä¸‹è¾“å‡ºï¼š

```py
"""
I have the following document:
* The website mentions that it only takes a couple of days to deliver but I still have not received mine

Extract 5 keywords from that document.

**Answer:**
1\. Website
2\. Mentions
3\. Deliver
4\. Couple
5\. Days
"""
```

å®ƒè¡¨ç°å¾—éå¸¸å¥½ï¼ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬å¸Œæœ›è¾“å‡ºçš„ç»“æ„åœ¨è¾“å…¥æ–‡æœ¬ä¸åŒçš„æƒ…å†µä¸‹ä¿æŒä¸€è‡´ï¼Œæˆ‘ä»¬éœ€è¦ç»™ LLM ä¸€ä¸ªç¤ºä¾‹ã€‚

è¿™å°±æ˜¯æ›´é«˜çº§æç¤ºå·¥ç¨‹çš„ç”¨æ­¦ä¹‹åœ°ã€‚ä¸å¤§å¤šæ•°å¤§å‹è¯­è¨€æ¨¡å‹ä¸€æ ·ï¼ŒMistral 7B æœŸæœ›ç‰¹å®šçš„æç¤ºæ ¼å¼ã€‚å½“æˆ‘ä»¬æƒ³å±•ç¤ºâ€œæ­£ç¡®â€äº¤äº’çš„æ ·å­æ—¶ï¼Œè¿™éå¸¸æœ‰å¸®åŠ©ã€‚

æç¤ºæ¨¡æ¿å¦‚ä¸‹ï¼š

![](img/ed736ed8bd3f7f90ec3b71a5fe87d324.png)

åŸºäºè¯¥æ¨¡æ¿ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå…³é”®è¯æå–çš„æ¨¡æ¿ã€‚

å®ƒéœ€è¦æœ‰ä¸¤ä¸ªç»„ä»¶ï¼š

+   `Example prompt` - è¿™å°†ç”¨äºå‘ LLM å±•ç¤ºâ€œè‰¯å¥½â€è¾“å‡ºçš„æ ·å­

+   `Keyword prompt` - è¿™å°†ç”¨äºè¯·æ±‚ LLM æå–å…³é”®è¯

ç¬¬ä¸€ä¸ªç»„ä»¶ï¼Œ`example_prompt`ï¼Œå°†ä»…ä»…æ˜¯ä¸€ä¸ªæ­£ç¡®æå–å…³é”®è¯çš„ç¤ºä¾‹ï¼Œç¬¦åˆæˆ‘ä»¬æ„Ÿå…´è¶£çš„æ ¼å¼ã€‚

**æ ¼å¼**æ˜¯ä¸€ä¸ªå…³é”®ç»„ä»¶ï¼Œå› ä¸ºå®ƒç¡®ä¿ LLM å§‹ç»ˆä»¥æˆ‘ä»¬å¸Œæœ›çš„æ–¹å¼è¾“å‡ºå…³é”®è¯ï¼š

```py
example_prompt = """
<s>[INST]
I have the following document:
- The website mentions that it only takes a couple of days to deliver but I still have not received mine.

Please give me the keywords that are present in this document and separate them with commas.
Make sure you to only return the keywords and say nothing else. For example, don't say:
"Here are the keywords present in the document"
[/INST] meat, beef, eat, eating, emissions, steak, food, health, processed, chicken</s>"""
```

ç¬¬äºŒä¸ªç»„ä»¶ï¼Œ`keyword_prompt`ï¼Œå®é™…ä¸Šæ˜¯`example_prompt`çš„é‡å¤ï¼Œåªä¸è¿‡æœ‰ä¸¤ä¸ªå˜åŒ–ï¼š

+   å®ƒè¿˜ä¸ä¼šæœ‰è¾“å‡ºã€‚é‚£å°†ç”± LLM ç”Ÿæˆã€‚

+   æˆ‘ä»¬ä½¿ç”¨`KeyBERT`çš„**[DOCUMENT]**æ ‡ç­¾æ¥æŒ‡ç¤ºè¾“å…¥æ–‡æ¡£çš„ä½ç½®ã€‚

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨**[DOCUMENT]**å°†æ–‡æ¡£æ’å…¥åˆ°æ‚¨é€‰æ‹©çš„ä½ç½®ã€‚è¿™ä¸ªé€‰é¡¹æœ‰åŠ©äºæˆ‘ä»¬åœ¨éœ€è¦æ—¶æ›´æ”¹æç¤ºçš„ç»“æ„ï¼Œè€Œä¸å¿…å°†æç¤ºè®¾ç½®åœ¨ç‰¹å®šä½ç½®ã€‚

```py
keyword_prompt = """
[INST]
I have the following document:
- [DOCUMENT]

Please give me the keywords that are present in this document and separate them with commas.
Make sure you to only return the keywords and say nothing else. For example, don't say:
"Here are the keywords present in the document"
[/INST]
"""
```

æœ€åï¼Œæˆ‘ä»¬å°†ä¸¤ä¸ªæç¤ºåˆå¹¶ä»¥åˆ›å»ºæˆ‘ä»¬çš„æœ€ç»ˆæ¨¡æ¿ï¼š

```py
>>> prompt = example_prompt + keyword_prompt
>>> print(prompt)
"""
<s>[INST]
I have the following document:
- The website mentions that it only takes a couple of days to deliver but I still have not received mine.

Please give me the keywords that are present in this document and separate them with commas.
Make sure you to only return the keywords and say nothing else. For example, don't say: 
"Here are the keywords present in the document"
[/INST] meat, beef, eat, eating, emissions, steak, food, health, processed, chicken</s>
[INST]

I have the following document:
- [DOCUMENT]

Please give me the keywords that are present in this document and separate them with commas.
Make sure you to only return the keywords and say nothing else. For example, don't say: 
"Here are the keywords present in the document"
[/INST]
"""
```

ç°åœ¨æˆ‘ä»¬æœ‰äº†æœ€ç»ˆçš„æç¤ºæ¨¡æ¿ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹æ¢ç´¢`KeyBERT`ä¸`KeyLLM`çš„ä¸€äº›æœ‰è¶£çš„æ–°åŠŸèƒ½ã€‚æˆ‘ä»¬å°†é¦–å…ˆæ¢ç´¢ä»…ä½¿ç”¨ Mistral çš„ 7B æ¨¡å‹çš„`KeyLLM`

# ğŸ—ï¸ ä½¿ç”¨`KeyLLM`è¿›è¡Œå…³é”®è¯æå–

ä½¿ç”¨åŸç”Ÿ`KeyLLM`è¿›è¡Œå…³é”®è¯æå–æ˜¯æå…¶ç®€å•çš„ï¼›æˆ‘ä»¬åªéœ€è®©å®ƒä»æ–‡æ¡£ä¸­æå–å…³é”®è¯å³å¯ã€‚

![](img/80116740c612fd002adc807f474e5863.png)

é€šè¿‡ LLM ä»æ–‡æ¡£ä¸­æå–å…³é”®è¯çš„æƒ³æ³•å¾ˆç®€å•ï¼Œå¯ä»¥è½»æ¾æµ‹è¯•ä½ çš„ LLM åŠå…¶åŠŸèƒ½ã€‚

ä½¿ç”¨`KeyLLM`å¾ˆç®€å•ï¼Œæˆ‘ä»¬é¦–å…ˆé€šè¿‡`keybert.llm.TextGeneration`åŠ è½½æˆ‘ä»¬çš„ LLMï¼Œå¹¶ç»™å®ƒä¹‹å‰åˆ›å»ºçš„æç¤ºæ¨¡æ¿ã€‚

ğŸ”¥ **æç¤º** ğŸ”¥ï¼šå¦‚æœä½ æƒ³ä½¿ç”¨ä¸åŒçš„ LLMï¼Œå¦‚ ChatGPTï¼Œä½ å¯ä»¥åœ¨[è¿™é‡Œ](https://maartengr.github.io/KeyBERT/guides/llms.html)æŸ¥çœ‹å·²å®ç°ç®—æ³•çš„å®Œæ•´æ¦‚è¿°ã€‚

```py
from keybert.llm import TextGeneration
from keybert import KeyLLM

# Load it in KeyLLM
llm = TextGeneration(generator, prompt=prompt)
kw_model = KeyLLM(llm)
```

åœ¨å‡†å¤‡å¥½æˆ‘ä»¬çš„`KeyLLM`å®ä¾‹åï¼Œåªéœ€å¯¹ä½ çš„æ–‡æ¡£è¿è¡Œ`.extract_keywords`å³å¯ï¼š

```py
documents = [
"The website mentions that it only takes a couple of days to deliver but I still have not received mine.",
"I received my package!",
"Whereas the most powerful LLMs have generally been accessible only through limited APIs (if at all), Meta released LLaMA's model weights to the research community under a noncommercial license."
]

keywords = kw_model.extract_keywords(documents)
```

æˆ‘ä»¬å¾—åˆ°ä»¥ä¸‹å…³é”®è¯ï¼š

```py
[['deliver',
    'days',
    'website',
    'mention',
    'couple',
    'still',
    'receive',
    'mine'],
    ['package', 'received'],
    ['LLM',
    'API',
    'accessibility',
    'release',
    'license',
    'research',
    'community',
    'model',
    'weights',
    'Meta']]
```

è¿™äº›å…³é”®è¯çœ‹èµ·æ¥å¾ˆæ£’ï¼

ä½ å¯ä»¥è°ƒæ•´æç¤ºä»¥æŒ‡å®šä½ æƒ³æå–çš„å…³é”®è¯ç±»å‹ï¼Œå®ƒä»¬å¯ä»¥æœ‰å¤šé•¿ï¼Œç”šè‡³åœ¨ LLM æ˜¯å¤šè¯­è¨€çš„æƒ…å†µä¸‹è¿”å›å“ªç§è¯­è¨€ã€‚

# ğŸš€ ä½¿ç”¨`KeyLLM`è¿›è¡Œé«˜æ•ˆå…³é”®è¯æå–

å¯¹æˆåƒä¸Šä¸‡çš„æ–‡æ¡£è¿›è¡Œ LLM è¿­ä»£å¹¶ä¸æ˜¯æœ€æœ‰æ•ˆçš„æ–¹æ³•ï¼ç›¸åï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨åµŒå…¥æ¨¡å‹ä½¿å…³é”®è¯æå–æ›´é«˜æ•ˆã€‚

è¿™ä¸ªè¿‡ç¨‹å¦‚ä¸‹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†æ‰€æœ‰æ–‡æ¡£åµŒå…¥å¹¶è½¬æ¢ä¸ºæ•°å€¼è¡¨ç¤ºã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æ‰¾å‡ºå“ªäº›æ–‡æ¡£å½¼æ­¤æœ€ç›¸ä¼¼ã€‚æˆ‘ä»¬å‡è®¾é«˜åº¦ç›¸ä¼¼çš„æ–‡æ¡£å°†å…·æœ‰ç›¸åŒçš„å…³é”®è¯ï¼Œå› æ­¤ä¸éœ€è¦ä¸ºæ‰€æœ‰æ–‡æ¡£æå–å…³é”®è¯ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬åªä»æ¯ä¸ªç°‡ä¸­çš„ä¸€ä¸ªæ–‡æ¡£ä¸­æå–å…³é”®è¯ï¼Œå¹¶å°†è¿™äº›å…³é”®è¯åˆ†é…ç»™åŒä¸€ç°‡ä¸­çš„æ‰€æœ‰æ–‡æ¡£ã€‚

è¿™æ›´é«˜æ•ˆï¼Œè€Œä¸”ç›¸å½“çµæ´»ã€‚ç°‡æ˜¯çº¯ç²¹åŸºäºæ–‡æ¡£ä¹‹é—´çš„ç›¸ä¼¼æ€§ç”Ÿæˆçš„ï¼Œè€Œä¸è€ƒè™‘ç°‡ç»“æ„ã€‚æ¢å¥è¯è¯´ï¼Œå®ƒæœ¬è´¨ä¸Šæ˜¯åœ¨å¯»æ‰¾æˆ‘ä»¬é¢„æœŸå…·æœ‰ç›¸åŒå…³é”®è¯é›†åˆçš„è¿‘é‡å¤æ–‡æ¡£ã€‚

![](img/eaa53dc36d4b4e0a0d725a0870665841.png)

è¦ä½¿ç”¨`KeyLLM`å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬æå‰åµŒå…¥æ–‡æ¡£å¹¶å°†å®ƒä»¬ä¼ é€’ç»™`.extract_keywords`ã€‚é˜ˆå€¼æŒ‡ç¤ºæ–‡æ¡£éœ€è¦å¤šç›¸ä¼¼æ‰èƒ½åˆ†é…åˆ°åŒä¸€ä¸ªç°‡ã€‚

å°†æ­¤å€¼å¢åŠ åˆ°åƒ.95 è¿™æ ·çš„æ•°å­—å°†è¯†åˆ«è¿‘ä¹ç›¸åŒçš„æ–‡æ¡£ï¼Œè€Œå°†å…¶è®¾ç½®ä¸ºåƒ.5 è¿™æ ·çš„å€¼å°†è¯†åˆ«å…³äºç›¸åŒä¸»é¢˜çš„æ–‡æ¡£ã€‚

```py
from keybert import KeyLLM
from sentence_transformers import SentenceTransformer

# Extract embeddings
model = SentenceTransformer('BAAI/bge-small-en-v1.5')
embeddings = model.encode(documents, convert_to_tensor=True)

# Load it in KeyLLM
kw_model = KeyLLM(llm)

# Extract keywords
keywords = kw_model.extract_keywords(
    documents, 
    embeddings=embeddings, 
    threshold=.5
)
```

æˆ‘ä»¬å¾—åˆ°ä»¥ä¸‹å…³é”®è¯ï¼š

```py
>>> keywords
[['deliver',
    'days',
    'website',
    'mention',
    'couple',
    'still',
    'receive',
    'mine'],
    ['deliver',
    'days',
    'website',
    'mention',
    'couple',
    'still',
    'receive',
    'mine'],
    ['LLaMA',
    'model',
    'weights',
    'release',
    'noncommercial',
    'license',
    'research',
    'community',
    'powerful',
    'LLMs',
    'APIs']]
```

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å‰ä¸¤ä¸ªæ–‡æ¡£è¢«èšç±»åœ¨ä¸€èµ·å¹¶è·å¾—äº†ç›¸åŒçš„å…³é”®è¯ã€‚æˆ‘ä»¬åªä¼ é€’ä¸¤ä¸ªæ–‡æ¡£ï¼Œè€Œä¸æ˜¯ä¼ é€’æ‰€æœ‰ä¸‰ä¸ªæ–‡æ¡£ã€‚å¦‚æœä½ æœ‰æˆåƒä¸Šä¸‡çš„æ–‡æ¡£ï¼Œè¿™å¯ä»¥æ˜¾è‘—åŠ å¿«é€Ÿåº¦ã€‚

# ğŸ† ä½¿ç”¨`KeyBERT`å’Œ`KeyLLM`è¿›è¡Œé«˜æ•ˆå…³é”®è¯æå–

ä¹‹å‰ï¼Œæˆ‘ä»¬æ‰‹åŠ¨å°†åµŒå…¥ä¼ é€’ç»™`KeyLLM`ä»¥è¿›è¡Œé›¶-shot å…³é”®è¯æå–ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡åˆ©ç”¨`KeyBERT`è¿›ä¸€æ­¥æ‰©å±•è¿™ä¸ªä¾‹å­ã€‚

ç”±äº`KeyBERT`ç”Ÿæˆå…³é”®è¯å¹¶åµŒå…¥æ–‡æ¡£ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™ä¸€ç‚¹ä¸ä»…ç®€åŒ–æµç¨‹ï¼Œè¿˜å¯ä»¥å‘ LLM å»ºè®®ä¸€äº›å…³é”®è¯ã€‚

è¿™äº›å»ºè®®çš„å…³é”®å­—å¯ä»¥å¸®åŠ© LLM å†³å®šä½¿ç”¨å“ªäº›å…³é”®å­—ã€‚æ­¤å¤–ï¼Œè¿™å…è®¸`KeyBERT`ä¸­çš„æ‰€æœ‰å†…å®¹ä¸`KeyLLM`ä¸€èµ·ä½¿ç”¨ï¼

![](img/fbe7f8a1b581d44e8cc90b0aed10af87.png)

è¿™ç§é«˜æ•ˆçš„å…³é”®å­—æå–æ–¹æ³•ï¼Œä½¿ç”¨`KeyBERT`å’Œ`KeyLLM`åªéœ€è¦ä¸‰è¡Œä»£ç ï¼æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ª KeyBERT æ¨¡å‹ï¼Œå¹¶å°†ä¹‹å‰åˆ›å»ºçš„åµŒå…¥æ¨¡å‹åˆ†é…ç»™ LLMï¼š

```py
from keybert import KeyLLM, KeyBERT

# Load it in KeyLLM
kw_model = KeyBERT(llm=llm, model='BAAI/bge-small-en-v1.5')

# Extract keywords
keywords = kw_model.extract_keywords(documents, threshold=0.5)
```

æˆ‘ä»¬å¾—åˆ°ä»¥ä¸‹å…³é”®å­—ï¼š

```py
>>> keywords
[['deliver',
  'days',
  'website',
  'mention',
  'couple',
  'still',
  'receive',
  'mine'],
 ['deliver',
  'days',
  'website',
  'mention',
  'couple',
  'still',
  'receive',
  'mine'],
 ['LLaMA',
  'model',
  'weights',
  'release',
  'license',
  'research',
  'community',
  'powerful',
  'LLMs',
  'APIs',
  'accessibility']]
```

å°±è¿™æ ·ï¼ä½¿ç”¨`KeyLLM`ï¼Œä½ å¯ä»¥åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹æ¥å¸®åŠ©åˆ›å»ºæ›´å¥½çš„å…³é”®å­—ã€‚æˆ‘ä»¬å¯ä»¥é€‰æ‹©ä»æ–‡æœ¬æœ¬èº«æå–å…³é”®å­—ï¼Œæˆ–è€…è®© LLM æå‡ºå…³é”®å­—ã€‚

é€šè¿‡å°†`KeyLLM`ä¸`KeyBERT`ç»“åˆä½¿ç”¨ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€äº›è®¡ç®—å’Œå»ºè®®æ¥å¢åŠ å…¶æ½œåŠ›ã€‚

**æ›´æ–°**ï¼šæˆ‘åœ¨ YouTube ä¸Šä¸Šä¼ äº†ä¸€ä¸ªè§†é¢‘ç‰ˆæœ¬ï¼Œæ›´æ·±å…¥åœ°è®²è§£äº†å¦‚ä½•ä½¿ç”¨ KeyLLMï¼š

# æ„Ÿè°¢é˜…è¯»ï¼

å¦‚æœä½ å’Œæˆ‘ä¸€æ ·ï¼Œå¯¹ AI å’Œ/æˆ–å¿ƒç†å­¦å……æ»¡çƒ­æƒ…ï¼Œè¯·éšæ—¶åœ¨[**LinkedIn**](https://www.linkedin.com/in/mgrootendorst/)ä¸Šæ·»åŠ æˆ‘ï¼Œåœ¨[**Twitter**](https://twitter.com/MaartenGr)ä¸Šå…³æ³¨æˆ‘ï¼Œæˆ–è€…è®¢é˜…æˆ‘çš„[**Newsletter**](http://maartengrootendorst.substack.com/)ã€‚ä½ è¿˜å¯ä»¥åœ¨æˆ‘çš„[**ä¸ªäººç½‘ç«™**](https://maartengrootendorst.com/)ä¸Šæ‰¾åˆ°ä¸€äº›æˆ‘çš„å†…å®¹ã€‚

*æ‰€æœ‰æ²¡æœ‰æ¥æºä¿¡ç”¨çš„å›¾åƒéƒ½æ˜¯ä½œè€…åˆ›å»ºçš„â€”â€”ä¹Ÿå°±æ˜¯è¯´ï¼Œæ‰€æœ‰å›¾åƒéƒ½æ˜¯æˆ‘è‡ªå·±åˆ¶ä½œçš„ ;)*
