- en: Introducing PeekingDuck for Computer Vision
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 PeekingDuck 计算机视觉
- en: 原文：[https://towardsdatascience.com/introducing-peekingduck-for-computer-vision-8b0105591559?source=collection_archive---------17-----------------------#2023-01-03](https://towardsdatascience.com/introducing-peekingduck-for-computer-vision-8b0105591559?source=collection_archive---------17-----------------------#2023-01-03)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/introducing-peekingduck-for-computer-vision-8b0105591559?source=collection_archive---------17-----------------------#2023-01-03](https://towardsdatascience.com/introducing-peekingduck-for-computer-vision-8b0105591559?source=collection_archive---------17-----------------------#2023-01-03)
- en: Open-source state-of-the-art computer vision models with minimal lines of code
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开源的最先进计算机视觉模型，代码行数极少
- en: '[](https://medium.com/@natsunoyuki?source=post_page-----8b0105591559--------------------------------)[![Y.
    Natsume](../Images/a39993351a920c3a9f5bd27b6b3306aa.png)](https://medium.com/@natsunoyuki?source=post_page-----8b0105591559--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8b0105591559--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8b0105591559--------------------------------)
    [Y. Natsume](https://medium.com/@natsunoyuki?source=post_page-----8b0105591559--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@natsunoyuki?source=post_page-----8b0105591559--------------------------------)[![Y.
    Natsume](../Images/a39993351a920c3a9f5bd27b6b3306aa.png)](https://medium.com/@natsunoyuki?source=post_page-----8b0105591559--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8b0105591559--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8b0105591559--------------------------------)
    [Y. Natsume](https://medium.com/@natsunoyuki?source=post_page-----8b0105591559--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdab037034ffe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-peekingduck-for-computer-vision-8b0105591559&user=Y.+Natsume&userId=dab037034ffe&source=post_page-dab037034ffe----8b0105591559---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8b0105591559--------------------------------)
    ·4 min read·Jan 3, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8b0105591559&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-peekingduck-for-computer-vision-8b0105591559&user=Y.+Natsume&userId=dab037034ffe&source=-----8b0105591559---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdab037034ffe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-peekingduck-for-computer-vision-8b0105591559&user=Y.+Natsume&userId=dab037034ffe&source=post_page-dab037034ffe----8b0105591559---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8b0105591559--------------------------------)
    ·4 min read·2023年1月3日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8b0105591559&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-peekingduck-for-computer-vision-8b0105591559&user=Y.+Natsume&userId=dab037034ffe&source=-----8b0105591559---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8b0105591559&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-peekingduck-for-computer-vision-8b0105591559&source=-----8b0105591559---------------------bookmark_footer-----------)![](../Images/a5aec3707685a05c0409e2d70cd8f6a9.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8b0105591559&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-peekingduck-for-computer-vision-8b0105591559&source=-----8b0105591559---------------------bookmark_footer-----------)![](../Images/a5aec3707685a05c0409e2d70cd8f6a9.png)'
- en: Photo by [Vlad Tchompalov](https://unsplash.com/@tchompalov?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/wt5Y8VY_0bA?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Vlad Tchompalov](https://unsplash.com/@tchompalov?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，来源于 [Unsplash](https://unsplash.com/photos/wt5Y8VY_0bA?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)。
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Computer vision projects can be a very daunting, involving a wide variety of
    tools and packages such as [OpenCV](https://opencv.org), [TensorFlow](https://www.tensorflow.org)
    and [PyTorch](https://pytorch.org/vision/stable/index.html) just to name a few.
    Not only does one have to be familiar with the tools and APIs involved, one also
    needs to combine the various packages correctly in order for the entire computer
    vision pipeline to work properly.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: For example, OpenCV handles images in the `[H, W, C]` format with BGR channels,
    while TensorFlow does so in the same format but with RGB channels, and PyTorch
    does so in the `[C, H, W]` format with RGB channels. Due to this inconsistency
    the image format must be constantly modified as the image is passed amongst the
    various libraries. Issues like this (in addition to others!) results in plenty
    of boilerplate code which we want to avoid in general.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: 'What if we could streamline computer vision pipelines with a single unified
    pipeline which is:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Open source without restrictions such as GPL-3.0 in order to cut costs.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Modular for applicability to various use cases.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: State-of-the-art for maximum performance.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Minimal to minimize pipline complexity.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It turns out that all of these issues are resolved to some extent with [PeekingDuck](https://github.com/aisingapore/PeekingDuck)
    — a computer vision package released recently by [AI Singapore](https://github.com/aisingapore)!
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: PeekingDuck
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'PeekingDuck is a computer vision framework which is:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Open source (Apache 2.0) — no costs or restrictions.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Modular — mix and match various modules to solve different use cases.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: State-of-the-art computer vision inference —powerful deep learning models.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Minimal — literally no Python code needed!
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After installing PeekingDuck as a Python package through a package manager such
    as pip, the package can be used directly from the command line/terminal, allowing
    for easy and direct integration with other applications.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Installing PeekingDuck
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'PeekingDuck is installed as a Python package:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Nodes — PeekingDuck’s Basic Building Blocks
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With PeekingDuck, computer vision pipelines are built using basic building
    blocks called nodes. Each node handles a different set of operations, and by mixing
    various nodes different pipelines can be created. As of writing PeekingDuck has
    6 different types of nodes:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Input —feed image data into the pipeline from live camera feeds or video/image
    files.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Augment —preprocess image data.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Model —perform computer vision tasks such as object detection or pose estimation.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Dabble — post process model outputs.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw — visualize model outputs such as bounding boxes.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Output — save model outputs to disk.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Person Tracking Pipeline
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using PeekingDuck is easy! In this section we will demonstrate how to use PeekingDuck
    to create a person tracking pipeline using PeekingDuck!
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Initialize PeekingDuck
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first step is to initialize PeekingDuck within a specified directory (`person_tracking/`
    in this case).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This will create a configuration file named `pipeline_config.yml` under `person_tracking/`
    together with some other source code files. In order to get PeekingDuck to do
    what we want it to do, we have to modify `pipeline_config.yml`.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这将会在 `person_tracking/` 下创建一个名为 `pipeline_config.yml` 的配置文件以及一些其他源代码文件。为了让 PeekingDuck
    按我们希望的方式运行，我们必须修改 `pipeline_config.yml`。
- en: 'In our case, `pipeline_config.yml` should contain the following lines:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，`pipeline_config.yml` 应包含以下行：
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We use the following `nodes` for this task:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为此任务使用以下 `nodes`：
- en: '`input.visual` — specifies the file to load the image data from. We use a video
    stitched from the [Venice-2 images from the MOT15 dataset](https://motchallenge.net/data/MOT15/).'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`input.visual` — 指定加载图像数据的文件。我们使用的是一个由 [MOT15 数据集的 Venice-2 图像](https://motchallenge.net/data/MOT15/)
    拼接而成的视频。'
- en: '`model.jde` — specifies the model to use. For person tracking we use the [Joint
    Detection and Embedding (JDE)](https://github.com/Zhongdao/Towards-Realtime-MOT)
    model.'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`model.jde` — 指定要使用的模型。对于人物跟踪，我们使用 [Joint Detection and Embedding (JDE)](https://github.com/Zhongdao/Towards-Realtime-MOT)
    模型。'
- en: '`dabble.statistics` —Performs statistical calculations based on the model’s
    output. In this case we calculate the maximum number of detected IDs for each
    frame.'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`dabble.statistics` — 根据模型的输出进行统计计算。在这种情况下，我们计算每帧检测到的最大 ID 数量。'
- en: '`draw.bbox` — draws the detected bounding boxes on each frame.'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`draw.bbox` — 在每帧上绘制检测到的边界框。'
- en: '`draw.tag` — draws the corresponding tag for each bounding box.'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`draw.tag` — 为每个边界框绘制相应的标签。'
- en: '`draw.legend` — draws the cumulative maximum number of detections.'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`draw.legend` — 绘制累计检测到的最大数量。'
- en: '`output.media_writer` — outputs the model’s predictions to disk.'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`output.media_writer` — 将模型的预测结果输出到磁盘。'
- en: By mixing and matching different nodes, we can build different pipelines to
    solve different computer vision use cases. A detailed list of available nodes
    are available on [PeekingDuck’s website](https://peekingduck.readthedocs.io/en/stable/nodes/input.html).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 通过混合和匹配不同的节点，我们可以构建不同的管道来解决不同的计算机视觉应用场景。详细的节点列表可以在 [PeekingDuck 的网站](https://peekingduck.readthedocs.io/en/stable/nodes/input.html)
    上找到。
- en: Prepare the Data
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备数据
- en: The next step is to prepare the data. In our case we use OpenCV to stitch together
    the [Venice-2 images from the MOT15 dataset](https://motchallenge.net/data/MOT15/)
    into a video file named `venice-2-train.mp4` with a frame rate of `30` and a resolution
    of `[1920, 1080]`.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是准备数据。在我们的例子中，我们使用 OpenCV 将 [MOT15 数据集的 Venice-2 图像](https://motchallenge.net/data/MOT15/)
    拼接成一个名为 `venice-2-train.mp4` 的视频文件，帧率为 `30`，分辨率为 `[1920, 1080]`。
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Run PeekingDuck
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行 PeekingDuck
- en: 'After initializing both PeekingDuck as well as the data, all that is left is
    to simply run the pipeline from the command line:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在初始化了 PeekingDuck 和数据之后，剩下的就是从命令行运行管道：
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The pipeline’s output will be saved under `output/` as specified in `pipeline_config.yml`
    which can be visualized either as a video or as a `.gif` image as shown below.
    The detected bounding boxes have been overlaid onto each tracked person together
    with each corresponding tracking ID. The cumulative maximum number of tracked
    IDs is also displayed on the lower left part of each frame.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 管道的输出将保存在 `output/` 下，如 `pipeline_config.yml` 中所指定，可以以视频或 `.gif` 图像的形式进行可视化。检测到的边界框已覆盖到每个跟踪人员上，并标注了每个相应的跟踪
    ID。累计的最大跟踪 ID 数量也显示在每帧的左下角。
- en: '![](../Images/fe5f0fe49c6bcc446bfb2fe238236788.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fe5f0fe49c6bcc446bfb2fe238236788.png)'
- en: PeekingDuck person tracking output. Figure created by the author. Original images
    are the [Venice-2 images from the MOT15 dataset](https://motchallenge.net/data/MOT15/).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: PeekingDuck 人物跟踪输出。图形由作者创建。原始图像是来自 [MOT15 数据集的 Venice-2 图像](https://motchallenge.net/data/MOT15/)。
- en: Note that aside from preparing the data, we have not written a single line of
    Python code while using PeekingDuck to do person tracking!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，除了准备数据外，我们在使用 PeekingDuck 进行人物跟踪时没有编写一行 Python 代码！
- en: Conclusion
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Computer vision has come a long way, and we now have access to many fantastic
    packages such as PeekingDuck. PeekingDuck offers open-source, modular state-of-the-art
    computer vision models with minimal amounts of Python code, allowing for anyone
    to pursue computer vision projects with relative ease and simplicity!
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉已经取得了长足进展，我们现在可以使用许多出色的包，如 PeekingDuck。PeekingDuck 提供了开源的、模块化的最先进的计算机视觉模型，代码量最少，使得任何人都可以相对轻松地进行计算机视觉项目！
- en: References
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[https://peekingduck.readthedocs.io/en/stable/master.html](https://peekingduck.readthedocs.io/en/stable/master.html)'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://motchallenge.net/data/MOT15/](https://motchallenge.net/data/MOT15/)'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://github.com/Zhongdao/Towards-Realtime-MOT](https://github.com/Zhongdao/Towards-Realtime-MOT)'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
