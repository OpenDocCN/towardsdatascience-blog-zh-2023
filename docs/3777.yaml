- en: Orchestrating Efficient Reasoning Over Knowledge Graphs with LLM Compiler Frameworks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/orchestrating-efficient-reasoning-over-knowledge-graphs-with-llm-compiler-frameworks-749d36dc32b9?source=collection_archive---------3-----------------------#2023-12-29](https://towardsdatascience.com/orchestrating-efficient-reasoning-over-knowledge-graphs-with-llm-compiler-frameworks-749d36dc32b9?source=collection_archive---------3-----------------------#2023-12-29)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@alcarazanthony1?source=post_page-----749d36dc32b9--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----749d36dc32b9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----749d36dc32b9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----749d36dc32b9--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----749d36dc32b9--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F30bc9ffd2f4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Forchestrating-efficient-reasoning-over-knowledge-graphs-with-llm-compiler-frameworks-749d36dc32b9&user=Anthony+Alcaraz&userId=30bc9ffd2f4b&source=post_page-30bc9ffd2f4b----749d36dc32b9---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----749d36dc32b9--------------------------------)
    ·6 min read·Dec 29, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F749d36dc32b9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Forchestrating-efficient-reasoning-over-knowledge-graphs-with-llm-compiler-frameworks-749d36dc32b9&user=Anthony+Alcaraz&userId=30bc9ffd2f4b&source=-----749d36dc32b9---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F749d36dc32b9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Forchestrating-efficient-reasoning-over-knowledge-graphs-with-llm-compiler-frameworks-749d36dc32b9&source=-----749d36dc32b9---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Artificial intelligence software was used to enhance the grammar, flow, and
    readability of this article’s text.*'
  prefs: []
  type: TYPE_NORMAL
- en: Recent innovations in large language model (LLM) design have led to rapid advancements
    in few-shot learning and reasoning capabilities. However, despite their progress,
    LLMs still face limitations when dealing with complex real-world contexts involving
    massive amounts of interconnected knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: To address this challenge, a promising approach has emerged in *retrieval augmented
    generation* (RAG) systems. RAG combines the adaptive learning strengths of LLMs
    with scalable retrieval from external knowledge sources like knowledge graphs
    (KGs). Rather than attempting to encode all information within the model statically,
    RAG allows querying necessary context from indexed knowledge graphs on the fly
    as needed.
  prefs: []
  type: TYPE_NORMAL
- en: However, effectively orchestrating reasoning and retrieval across interconnected
    knowledge sources brings its own challenges. Naive approaches that simply retrieve
    and concatenate information in discrete steps often fail to fully capture the
    nuances within dense knowledge graphs. The interconnected nature of concepts means
    that vital contextual details can be missed if not analyzed in relation to one
    another.
  prefs: []
  type: TYPE_NORMAL
- en: Recently, an intriguing framework named LLM Compiler has demonstrated early
    successes in optimizing orchestration of multiple function calls in LLMs by automatically
    handling…
  prefs: []
  type: TYPE_NORMAL
