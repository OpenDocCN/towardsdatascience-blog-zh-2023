- en: 'The Power of Retrieval Augmented Generation: A Comparison between Base and
    RAG LLMs with Llama2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检索增强生成的力量：Base 和 RAG LLM 与 Llama2 的比较
- en: 原文：[https://towardsdatascience.com/the-power-of-retrieval-augmented-generation-a-comparison-between-base-and-rag-llms-with-llama2-368865762c0d?source=collection_archive---------0-----------------------#2023-11-29](https://towardsdatascience.com/the-power-of-retrieval-augmented-generation-a-comparison-between-base-and-rag-llms-with-llama2-368865762c0d?source=collection_archive---------0-----------------------#2023-11-29)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-power-of-retrieval-augmented-generation-a-comparison-between-base-and-rag-llms-with-llama2-368865762c0d?source=collection_archive---------0-----------------------#2023-11-29](https://towardsdatascience.com/the-power-of-retrieval-augmented-generation-a-comparison-between-base-and-rag-llms-with-llama2-368865762c0d?source=collection_archive---------0-----------------------#2023-11-29)
- en: A deep dive into tailoring pre-trained LLMs for custom use cases using a RAG
    approach, featuring LangChain and Hugging Face integration
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深入探讨如何使用 RAG 方法针对特定用例调整预训练的 LLM，包含 LangChain 和 Hugging Face 的集成
- en: '[](https://medium.com/@luisroque?source=post_page-----368865762c0d--------------------------------)[![Luís
    Roque](../Images/e281d470b403375ba3c6f521b1ccf915.png)](https://medium.com/@luisroque?source=post_page-----368865762c0d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----368865762c0d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----368865762c0d--------------------------------)
    [Luís Roque](https://medium.com/@luisroque?source=post_page-----368865762c0d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@luisroque?source=post_page-----368865762c0d--------------------------------)[![Luís
    Roque](../Images/e281d470b403375ba3c6f521b1ccf915.png)](https://medium.com/@luisroque?source=post_page-----368865762c0d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----368865762c0d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----368865762c0d--------------------------------)
    [Luís Roque](https://medium.com/@luisroque?source=post_page-----368865762c0d--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2195f049db86&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-power-of-retrieval-augmented-generation-a-comparison-between-base-and-rag-llms-with-llama2-368865762c0d&user=Lu%C3%ADs+Roque&userId=2195f049db86&source=post_page-2195f049db86----368865762c0d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----368865762c0d--------------------------------)
    ·12 min read·Nov 29, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F368865762c0d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-power-of-retrieval-augmented-generation-a-comparison-between-base-and-rag-llms-with-llama2-368865762c0d&user=Lu%C3%ADs+Roque&userId=2195f049db86&source=-----368865762c0d---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2195f049db86&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-power-of-retrieval-augmented-generation-a-comparison-between-base-and-rag-llms-with-llama2-368865762c0d&user=Lu%C3%ADs+Roque&userId=2195f049db86&source=post_page-2195f049db86----368865762c0d---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----368865762c0d--------------------------------)
    ·12 分钟阅读·2023年11月29日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F368865762c0d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-power-of-retrieval-augmented-generation-a-comparison-between-base-and-rag-llms-with-llama2-368865762c0d&user=Lu%C3%ADs+Roque&userId=2195f049db86&source=-----368865762c0d---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F368865762c0d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-power-of-retrieval-augmented-generation-a-comparison-between-base-and-rag-llms-with-llama2-368865762c0d&source=-----368865762c0d---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F368865762c0d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-power-of-retrieval-augmented-generation-a-comparison-between-base-and-rag-llms-with-llama2-368865762c0d&source=-----368865762c0d---------------------bookmark_footer-----------)'
- en: '*This post was co-authored with Rafael Guedes.*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*这篇文章由 Rafael Guedes 共同撰写。*'
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: Since the release of ChatGPT in November of 2022, Large Language Models (LLMs)
    have been the hot topic in the AI community for their capabilities in understanding
    and generating human-like text, pushing the boundaries of what was previously
    possible in natural language processing (NLP).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 自从2022年11月 ChatGPT 发布以来，大型语言模型（LLMs）因其理解和生成类人文本的能力，成为了 AI 社区的热门话题，推动了自然语言处理（NLP）领域的边界。
- en: LLMs have been shown to be versatile by tackling different use cases in various
    industries since they are not limited to a specific task. They can be adapted
    to several domains, making them attractive for organizations and the research
    community. Several applications have been explored using LLMs such as content
    generation, chatbots, code generation, creative writing, virtual assistants, and
    many more.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Another characteristic that makes LLMs so attractive is the fact that there
    are open-source options. Companies like Meta made their pre-trained LLM (Llama2
    🦙) available in repositories like Hugging Face 🤗. Are these pre-trained LLMs good
    enough for each company’s specific use case? Certainly not.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
