- en: 'The Power of Retrieval Augmented Generation: A Comparison between Base and
    RAG LLMs with Llama2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://towardsdatascience.com/the-power-of-retrieval-augmented-generation-a-comparison-between-base-and-rag-llms-with-llama2-368865762c0d?source=collection_archive---------0-----------------------#2023-11-29](https://towardsdatascience.com/the-power-of-retrieval-augmented-generation-a-comparison-between-base-and-rag-llms-with-llama2-368865762c0d?source=collection_archive---------0-----------------------#2023-11-29)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A deep dive into tailoring pre-trained LLMs for custom use cases using a RAG
    approach, featuring LangChain and Hugging Face integration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@luisroque?source=post_page-----368865762c0d--------------------------------)[![LuÃ­s
    Roque](../Images/e281d470b403375ba3c6f521b1ccf915.png)](https://medium.com/@luisroque?source=post_page-----368865762c0d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----368865762c0d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----368865762c0d--------------------------------)
    [LuÃ­s Roque](https://medium.com/@luisroque?source=post_page-----368865762c0d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Â·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2195f049db86&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-power-of-retrieval-augmented-generation-a-comparison-between-base-and-rag-llms-with-llama2-368865762c0d&user=Lu%C3%ADs+Roque&userId=2195f049db86&source=post_page-2195f049db86----368865762c0d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----368865762c0d--------------------------------)
    Â·12 min readÂ·Nov 29, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F368865762c0d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-power-of-retrieval-augmented-generation-a-comparison-between-base-and-rag-llms-with-llama2-368865762c0d&user=Lu%C3%ADs+Roque&userId=2195f049db86&source=-----368865762c0d---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F368865762c0d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-power-of-retrieval-augmented-generation-a-comparison-between-base-and-rag-llms-with-llama2-368865762c0d&source=-----368865762c0d---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: '*This post was co-authored with Rafael Guedes.*'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since the release of ChatGPT in November of 2022, Large Language Models (LLMs)
    have been the hot topic in the AI community for their capabilities in understanding
    and generating human-like text, pushing the boundaries of what was previously
    possible in natural language processing (NLP).
  prefs: []
  type: TYPE_NORMAL
- en: LLMs have been shown to be versatile by tackling different use cases in various
    industries since they are not limited to a specific task. They can be adapted
    to several domains, making them attractive for organizations and the research
    community. Several applications have been explored using LLMs such as content
    generation, chatbots, code generation, creative writing, virtual assistants, and
    many more.
  prefs: []
  type: TYPE_NORMAL
- en: Another characteristic that makes LLMs so attractive is the fact that there
    are open-source options. Companies like Meta made their pre-trained LLM (Llama2
    ðŸ¦™) available in repositories like Hugging Face ðŸ¤—. Are these pre-trained LLMs good
    enough for each companyâ€™s specific use case? Certainly not.
  prefs: []
  type: TYPE_NORMAL
