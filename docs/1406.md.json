["```py\npip install -U imbalanced-learn\n```", "```py\n>>> from imblearn.datasets import fetch_datasets\n\n>>> # Fetch dataset from imbalanced-learn library \n>>> # as a dictionary of numpy array\n>>> us_crime = fetch_datasets()['us_crime']\n>>> us_crime\n\n{'data': array([[0.19, 0.33, 0.02, ..., 0.26, 0.2 , 0.32],\n        [0\\.  , 0.16, 0.12, ..., 0.12, 0.45, 0\\.  ],\n        [0\\.  , 0.42, 0.49, ..., 0.21, 0.02, 0\\.  ],\n        ...,\n        [0.16, 0.37, 0.25, ..., 0.32, 0.18, 0.91],\n        [0.08, 0.51, 0.06, ..., 0.38, 0.33, 0.22],\n        [0.2 , 0.78, 0.14, ..., 0.3 , 0.05, 1\\.  ]]),\n 'target': array([-1,  1, -1, ..., -1, -1, -1]),\n 'DESCR': 'us_crime'}\n```", "```py\n# Convert the dictionary to a pandas dataframe\ncrime_df = pd.concat([pd.DataFrame(us_crime['data'], columns = [f'data_{i}' for i in range(us_crime.data.shape[1])]),\n           pd.DataFrame(us_crime['target'], columns = ['target'])], axis = 1)\n\n# Split data into train test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(crime_df.drop('target', axis = 1), \n                                                    crime_df['target'], \n                                                    test_size = 0.4, \n                                                    random_state = 42)\n```", "```py\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\n# Scale the dataset on both train and test sets.\n# Note that we fit MinMaxScaler on X_train only, not on the entire dataset.\n# This prevents data leakage from test set to train set.\nscaler = MinMaxScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Perform PCA Decomposition on both train and test sets\n# Note that we fit PCA on X_train only, not on the entire dataset.\n# This prevents data leakage from test set to train set.\npca = PCA(n_components=2)\npca.fit(X_train)\nX_train_pca = pca.transform(X_train)\nX_test_pca = pca.transform(X_test)\n\n# Function for plotting dataset \ndef plot_data(X,y,ax,title):\n    ax.scatter(X[:, 0], X[:, 1], c=y, alpha=0.5, s = 30, edgecolor=(0,0,0,0.5))\n    ax.set_ylabel('Principle Component 1')\n    ax.set_xlabel('Principle Component 2')\n    if title is not None:\n        ax.set_title(title)\n\n# Plot dataset\nfig,ax = plt.subplots(figsize=(5, 5))\nplot_data(X_train_pca, y_train, ax, title='Original Dataset')\n```", "```py\nfrom imblearn.over_sampling import RandomOverSampler\n\n# Perform random oversampling\nros = RandomOverSampler(random_state=0)\nX_train_ros, y_train_ros = ros.fit_resample(X_train_pca, y_train)\n```", "```py\nfrom imblearn.under_sampling import RandomUnderSampler\n\n# Perform random sampling\nrus = RandomUnderSampler(random_state=0)\nX_train_rus, y_train_rus = rus.fit_resample(X_train_pca, y_train)\n\n# Function for plotting is in Notebook.\n# Insert link here.\n```", "```py\nfrom sklearn.svm import SVC\n\n# Train SVC on original data\nclf = SVC(kernel='linear',probability=True)\nclf_ros.fit(X_train_pca, y_train)\n\n# Train SVC on randomly oversampled data\nclf_ros = SVC(kernel='linear',probability=True)\nclf_ros.fit(X_train_ros, y_train_ros)\n\n# Train SVC on randomly undersampled data\nclf_rus = SVC(kernel='linear',probability=True)\nclf_rus.fit(X_train_rus, y_train_rus)\n\n# Function for plotting is in Notebook.\n# Insert link here.\n```", "```py\nfrom sklearn.svm import SVC\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\n\n# Helper function for plotting ROC\ndef plot_roc(ax, X_train, y_train, X_test, y_test, title):\n    clf = SVC(kernel='linear',probability=True)\n    clf.fit(X_train, y_train)\n    y_test_pred = clf.predict_proba(X_test)[:,1]\n    fpr, tpr, thresh = metrics.roc_curve(y_test, y_test_pred)\n    auc = metrics.roc_auc_score(y_test, y_test_pred)\n    ax.plot(fpr,tpr,label=f\"{title} AUC={auc:.3f}\")\n\n    ax.set_title('ROC Curve')\n    ax.set_xlabel('False Positive Rate')\n    ax.set_ylabel('True Positive Rate')\n    ax.legend(loc=0)\n\n# Plot all ROC into one graph\nfig,ax = plt.subplots(1,1,figsize=(8,5))\nplot_roc(ax, X_train_pca, y_train, X_test_pca, y_test, 'Original Dataset')\nplot_roc(ax, X_train_ros, y_train_ros, X_test_pca, y_test, 'Randomly Oversampled Dataset')\nplot_roc(ax, X_train_rus, y_train_rus, X_test_pca, y_test, 'Randomly Undersampled Dataset') \n```", "```py\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.svm import LinearSVC\n\n# Perform random sampling\nsmote = SMOTE(random_state=0)\nX_train_smote, y_train_smote = smote.fit_resample(X_train_pca, y_train)\n\n# Train linear SVC\nclf_smote = SVC(kernel='linear',probability=True)\nclf_smote.fit(X_train_smote, y_train_smote)\n\n# Plot decision boundary\n# Function for plotting decision boundary is in Notebook\n# Link: \n```", "```py\nfrom imblearn.over_sampling import ADASYN\n\n# Perform random sampling\nadasyn = ADASYN(random_state=0)\nX_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train_pca, y_train)\n\n# Train linear SVC\nfrom sklearn.svm import SVC\nclf_adasyn = SVC(kernel='linear',probability=True)\nclf_adasyn.fit(X_train_adasyn, y_train_adasyn)\n\n# Plot decision boundary\n# Function for plotting decision boundary is in Notebook\n# Link:\n```", "```py\nfrom imblearn.under_sampling import TomekLinks\nfrom sklearn.svm import LinearSVC\n\n# Perform Tomek Link undersampling\ntomek = TomekLinks()\nX_train_tomek, y_train_tomek = tomek.fit_resample(X_train_pca, y_train)\n\n# Train linear SVC\nclf_tomek = SVC(kernel='linear',probability=True)\nclf_tomek.fit(X_train_tomek, y_train_tomek)\n\n# Code for plotting graph in notebook.\n# Notebook link:\n```", "```py\nfrom imblearn.combine import SMOTETomek\nfrom sklearn.svm import LinearSVC\n\n# Perform random sampling\nsmotetomek = SMOTETomek(random_state=0)\nX_train_smotetomek, y_train_smotetomek = smotetomek.fit_resample(X_train_pca, y_train)\n\n# Plot linear SVC\nclf_smotetomek = SVC(kernel='linear',probability=True)\nclf_smotetomek.fit(X_train_smotetomek, y_train_smotetomek)\n```"]