- en: 'Avoid Overfitting in Neural Networks: a Deep Dive'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/avoid-overfitting-in-neural-networks-a-deep-dive-b4615a2d9507?source=collection_archive---------3-----------------------#2023-11-30](https://towardsdatascience.com/avoid-overfitting-in-neural-networks-a-deep-dive-b4615a2d9507?source=collection_archive---------3-----------------------#2023-11-30)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learn how to implement regularization techniques to boost performances and prevent
    Neural Network overfitting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@riccardo.andreoni?source=post_page-----b4615a2d9507--------------------------------)[![Riccardo
    Andreoni](../Images/5e22581e419639b373019a809d6e65c1.png)](https://medium.com/@riccardo.andreoni?source=post_page-----b4615a2d9507--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b4615a2d9507--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b4615a2d9507--------------------------------)
    [Riccardo Andreoni](https://medium.com/@riccardo.andreoni?source=post_page-----b4615a2d9507--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F76784541161c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Favoid-overfitting-in-neural-networks-a-deep-dive-b4615a2d9507&user=Riccardo+Andreoni&userId=76784541161c&source=post_page-76784541161c----b4615a2d9507---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b4615a2d9507--------------------------------)
    ·10 min read·Nov 30, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb4615a2d9507&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Favoid-overfitting-in-neural-networks-a-deep-dive-b4615a2d9507&user=Riccardo+Andreoni&userId=76784541161c&source=-----b4615a2d9507---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb4615a2d9507&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Favoid-overfitting-in-neural-networks-a-deep-dive-b4615a2d9507&source=-----b4615a2d9507---------------------bookmark_footer-----------)![](../Images/9b99bb683b9b10973ea4a001da99621b.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Image source: [unsplash.com](https://unsplash.com/photos/multicolored-illustration-gpiKdZmDQig).'
  prefs: []
  type: TYPE_NORMAL
- en: 'When training a deep neural network, it’s often troublesome to achieve the
    same performances on **both the training and validation sets**. A considerably
    higher error on the validation set is a **clear flag for overfitting**: the network
    has become too specialized in the training data. In this article, I provide a
    comprehensive guide on how to bypass this issue.'
  prefs: []
  type: TYPE_NORMAL
- en: Overfitting Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When dealing with any machine learning application, it’s important to have a
    clear understanding of the **bias and variance of the model**. In traditional
    machine learning algorithms, we talk about the [**bias vs. variance tradeoff**](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff#:~:text=In%20statistics%20and%20machine%20learning,bias%20in%20the%20estimated%20parameters.),
    which consists of the struggle of minimizing both the **variance** and the **bias**
    of a model.
  prefs: []
  type: TYPE_NORMAL
- en: In order to reduce the bias of a model (i.e. its error from erroneous assumptions),
    we need a **more complex model**. On the contrary, reducing the model’s variance
    (the sensitivity of the model in capturing the variations of the training data),
    implies a **more simple model**. It is straightforward that the bias vs. variance
    tradeoff, in traditional machine learning, derives from the conflict of…
  prefs: []
  type: TYPE_NORMAL
