# 5 个有用的提取与加载实践，帮助获得高质量原始数据

> 原文：[https://towardsdatascience.com/5-helpful-extract-load-practices-for-high-quality-raw-data-65b9a59a8721?source=collection_archive---------8-----------------------#2023-04-04](https://towardsdatascience.com/5-helpful-extract-load-practices-for-high-quality-raw-data-65b9a59a8721?source=collection_archive---------8-----------------------#2023-04-04)

## 不可变的原始区域，未经过变换、平展或去重，直到完成你的挖掘工作

[](https://svenbalnojan.medium.com/?source=post_page-----65b9a59a8721--------------------------------)[![Sven Balnojan](../Images/3c8ba26bf656dec273cde0d93acf5576.png)](https://svenbalnojan.medium.com/?source=post_page-----65b9a59a8721--------------------------------)[](https://towardsdatascience.com/?source=post_page-----65b9a59a8721--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----65b9a59a8721--------------------------------) [Sven Balnojan](https://svenbalnojan.medium.com/?source=post_page-----65b9a59a8721--------------------------------)

·

[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F31ae15774b19&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-helpful-extract-load-practices-for-high-quality-raw-data-65b9a59a8721&user=Sven+Balnojan&userId=31ae15774b19&source=post_page-31ae15774b19----65b9a59a8721---------------------post_header-----------) 发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----65b9a59a8721--------------------------------) ·8 分钟阅读·2023年4月4日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F65b9a59a8721&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-helpful-extract-load-practices-for-high-quality-raw-data-65b9a59a8721&user=Sven+Balnojan&userId=31ae15774b19&source=-----65b9a59a8721---------------------clap_footer-----------)

--

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F65b9a59a8721&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-helpful-extract-load-practices-for-high-quality-raw-data-65b9a59a8721&source=-----65b9a59a8721---------------------bookmark_footer-----------)![](../Images/942b5c7466ce87920f0d5f97feff976f.png)

挖掘机 - 图片由 [Dmitriy Zub](https://unsplash.com/@dimitryzub?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 提供，来源于 [Unsplash](https://unsplash.com/photos/jibUsRaauLY?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)。

*这篇文章是对* [*Meltano 博客*](https://github.com/meltano/meltano)*的更新版。*

ELT 正成为数据架构的默认选择，但许多最佳实践主要关注“变换（T）”。

但数据质量在提取和加载阶段之后的转换中决定。正如谚语所说，“垃圾进，垃圾出。”

强大的 EL 管道为提供准确、及时和无误的数据奠定了基础。

幸运的是，我们有一个充满数据专家的社区，他们使用过 Meltano、Stitch、Airbyte、Fivetran 和市场上所有的大型提取和加载工具。因此，我们请他们提供他们最关键的提取和加载实践！

我们提炼了 5 个数据实践 [被社区使用和喜爱](https://meltano.slack.com/)，这些实践将提升所有数据集的质量，无论你使用什么工具。

*但等等，这些不是“最佳实践”吗？因为我们认为它们是可以选择的。如果你正在处理一个新项目或在提取和加载过程中还没有很多实践，你可以全部实施。如果你已经有了一些，补充那些有意义的实践。*

## 设置舞台：我们需要提取和加载实践，因为“复制原始数据”比听起来复杂得多。

ELT 作为一种模式的概念听起来很简单，“只需首先复制源数据，然后在自己的空间中对原始数据进行转换。”然而，“复制”和“原始数据”这两个词有隐藏的障碍。

“复制”听起来很简单。但源数据会变化，除非你知道发生了什么变化，否则“复制”比你想象的要复杂。想象一下一个包含 1.5 亿个“订单”的生产表，它有一个“时间戳”，但没有“修改”数据。是的，这样的表随处可见。那么，你怎么知道订单是否被修改了？如果是，哪些订单被修改了？例如，你怎么知道哪些订单被“取消”，这种操作通常发生在同一数据记录中并在原地“修改”它？

“原始数据”听起来很清晰。然而，提取和加载的概念隐含着通常你在两个不同的技术系统 A 和 B 之间复制数据，其中你需要调整数据以匹配系统 B。你从 REST API 中获取数据并将其放入 Snowflake，或从 Oracle 数据库中提取数据并放入 Redshift。每次更换系统时，你都需要修改“原始数据”以遵循新系统的规则。你需要进行类型转换；你需要考虑是否要“展平 JSON”或是否要向数据中添加额外的元数据。

单纯“复制原始数据”每次添加新数据源或目标时都会提出新问题。即使只是来自同一生产数据库的新表，你一直在复制的数据。

这些实践将在你使用新数据源将数据导入数据系统时为你提供指导。

## 1\. 使每次 EL 运行具有唯一标识——时间戳所有内容

我们从可能最重要的最佳实践开始：使你加载到数据系统中的每一位数据都能被识别并追溯到获取它的过程。

典型的方法是包含捕获的元数据值：

+   摄取时间：表示加载过程开始的时间戳。

+   摄取过程：表示加载过程及其实例的唯一标识符。

+   源系统：关于数据来源的元数据。

![](../Images/41b27b818ea3570f01f23d958c21a027.png)

图片由作者提供。

将这些元数据中的任何一个或全部添加到你摄取的数据的每一行/条目中。我们建议使用摄取器的开始时间作为“摄取时间”，因为这简化了过程。“摄取实例的标识符”应该明确。不要仅仅提供“Airflow-OracleDB-Ingester”作为过程，而是提供“Airflow-OracleDB-Ingester-ID1244”，其中ID1244标识特定的摄取运行。

将源系统作为元数据的一个好处是，你可以快速调试下游仪表板中的问题并识别其来源。这也是其他用例中有用的元数据。

假设你有一个遗留系统和一个新的客户注册组件。在这种情况下，你可以在仪表板中将源系统作为过滤选项，让用户仅过滤来自一个系统的客户。

![](../Images/644ef20394e1ff864642f8a183b4f584.png)

图片由作者提供。

## 2\. 在原始层级之外的层级去重数据

通常，你会遇到三种数据重复情况需要“去重”。但无论是哪种情况，都不要在原始/落地层进行去重！

第一种情况是有意的重复数据，其中源系统包含你和终端用户认为重复的内容。例如，你的CRM系统可能有两个相同客户的条目，该客户取消后重新注册。如果你在原始层级去重，这意味着要么合并两个条目，要么删除一个。这两者都会删除源系统中存在的数据。

第二种情况是无意间产生的重复数据，其中源系统可能会删除你在数据仓库中仍然存在的记录，或者源系统无意中生成了未来可能会删除的重复数据。尽管这是一个“错误”，我不建议在原始摄取区域删除这些数据，而是应该在后续阶段进一步过滤，例如在建模的下一阶段。否则，你会在摄取中添加难以跟踪的逻辑。

第三种情况是由于技术限制导致的重复。可能是你的摄取工具倾向于“至少一次交付”策略，或者可能是摄取过程中的一个bug。使用“至少一次交付”增量加载策略，你确保获取所有数据行，但可能会产生一些重复数据。再次建议在原始层级保留重复数据，并在后续阶段进行过滤。

![](../Images/ff199127920861992094eaa3637ff3f0.png)

图片由作者提供。

无论情况如何，都不要在加载时去重。加载所有数据，并保持原样。稍后在下一阶段进行去重。

## 3\. 在EL期间不要展平，推迟到一个阶段后进行

许多源系统在摄取时会返回数组、JSON或其他具有某些层级的嵌套对象，你希望将其拆解以进行进一步处理。但不是在摄取层面。将原始数据按原样导入你的数据系统，然后让一个过程进行“扁平化”。

一个很典型的例子是JSON对象。你的源数据可能包含一个大的JSON对象，而你希望将其处理成Snowflake数据库中的单独列。这种做法建议首先创建一个仅包含元数据列和一个“JSON_blob”列的原始表，其中包含JSON对象。在第二步，你可以将这些数据处理成列。

![](../Images/65ab7ad6d86159b77caaa8f6cbd89b2d.png)

图片由作者提供。

这样做的原因是，扁平化涉及业务逻辑。它涉及到你知道哪些属性是“始终存在的”。如果你在摄取时进行扁平化，你的摄取过程可能会因为一个JSON对象为空，或者一个JSON对象没有一个预期的值而中断。处理已经摄取的数据并重新运行扁平化工具总是比运行摄取和扁平化过程更容易。

*附加提示：相同的实践可以避免在摄取时进行类型转换（如果可能的话）。我们建议在摄取之后再进行类型转换。*

## 4\. 拥有一个不可变的原始层

在某个时候，你将切换到数据的增量更新。此时要记住创建一个“不可变原始层”，这是一个你**绝对不要修改或删除数据**的区域。

> “不可变原始层”：一个你**绝对不要修改或删除数据**的区域。

不去重复数据是其中的一部分（见规则2），但还有更多：在你的不可变原始层中，你不会删除上游移除的记录或修改上游修改的数据。你只是加载新数据，仅此而已。

一个我仍然痛苦记忆的例子是北极星指标仪表板。它展示了我基于过去几个月客户行为所工作的北极星指标的当前发展情况。仪表板和数字看起来都很好，呈上升趋势。产品和管理决策基于此做出。北极星指标的新记录每周广播一次。

然后突然有一天，仪表板看起来不同了。我们的北极星指标减少了10%的值，并在某个特定细分市场中减少了30%。

一位大客户离开了，记录被完全删除。

由于我们在修改原始数据，我们彻底搞砸了北极星指标，无法恢复。

从那天起，我们使用了可能会变动的所有原始数据的[快照](https://docs.getdbt.com/docs/build/snapshots)。

![](../Images/1fb22bc843ea507b419f0816c0eb7b90.png)

图片由作者提供。

为自己做个好事，让你的原始层不可变。

*注意：不可变的暂存区域实际上就是你在进行全表同步时创建的，如果你不删除数据的话。此外，出于GDPR和隐私问题，你应该在这里做一个例外。*

## 5\. 在数据摄取时不要进行任何形式的转换，即使是轻微的，除非确实必要

在摄取时即时转换数据有充分的理由，但几乎所有你能想到的案例也可以在不转换的情况下运作。法律和安全是即时转换数据的两个好理由。对于其他所有理由，你应该首先摄取数据，然后对摄取的数据进行小规模的转换。

如果你选择在摄取数据时进行“即时”转换，确保你使其防故障。尽量只添加数据或删除数据，而不是修改数据。

如果你默认要进行转换，最好先进行数据摄取。然后，你可以，例如，创建一个映射表并在那里进行连接。

![](../Images/e210cf087a2aa0289dc7d767e08bead3.png)

图片由作者提供。

你可以通过使用像“[dbt seeds](https://docs.getdbt.com/docs/build/seeds)”这样的机制或摄取由外部贡献者维护的 Google Sheets 来实现。

## 总结

我们都知道“垃圾进，垃圾出”，但我们往往未能在提取和加载的世界中认识到这一点。

这些做法侧重于在我们流程的最开始阶段减少垃圾数据。它们将帮助你更快地解决问题，并从长远来看提高数据质量。

如果你想了解所有实践的简短版本，请查看下面的图示。

![](../Images/a3e3d5dd98f02bb8fda9cbb7ae21cc98.png)

5 个有用的提取和加载实践，图片由作者提供。
