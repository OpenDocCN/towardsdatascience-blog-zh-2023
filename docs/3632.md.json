["```py\nextraction_functions = [\n    {\n        \"name\": \"extract_information\",\n        \"description\": \"extracts information\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"metric\": {\n                    \"type\": \"string\",\n                    \"description\": \"main metric we need to calculate, for example, 'number of users' or 'number of sessions'\",\n                },\n                \"filters\": {\n                    \"type\": \"string\",\n                    \"description\": \"filters to apply to the calculation (do not include filters on dates here)\",\n                },\n                \"dimensions\": {\n                    \"type\": \"string\",\n                    \"description\": \"parameters to split your metric by\",\n                },\n                \"period_start\": {\n                    \"type\": \"string\",\n                    \"description\": \"the start day of the period for a report\",\n                },\n                \"period_end\": {\n                    \"type\": \"string\",\n                    \"description\": \"the end day of the period for a report\",\n                },\n                \"output_type\": {\n                    \"type\": \"string\",\n                    \"description\": \"the desired output\",\n                    \"enum\": [\"number\", \"visualisation\"]\n                }\n            },\n            \"required\": [\"metric\"],\n        },\n    }\n]\n```", "```py\nimport openai\n\nmessages = [\n    {\n        \"role\": \"system\",\n        \"content\": \"Extract the relevant information from the provided request.\"\n    },\n    {\n        \"role\": \"user\",\n        \"content\": \"How did number of iOS users change over time?\"\n    }\n]\n\nresponse = openai.ChatCompletion.create(\n    model = \"gpt-3.5-turbo-1106\", \n    messages = messages,\n    functions = extraction_functions\n)\n\nprint(response)\n```", "```py\n{\n  \"id\": \"chatcmpl-8TqGWvGAXZ7L43gYjPyxsWdOTD2n2\",\n  \"object\": \"chat.completion\",\n  \"created\": 1702123112,\n  \"model\": \"gpt-3.5-turbo-1106\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": null,\n        \"function_call\": {\n          \"name\": \"extract_information\",\n          \"arguments\": \"{\\\"metric\\\":\\\"number of users\\\",\\\"filters\\\":\\\"platform='iOS'\\\",\\\"dimensions\\\":\\\"date\\\",\\\"period_start\\\":\\\"2021-01-01\\\",\\\"period_end\\\":\\\"2021-12-31\\\",\\\"output_type\\\":\\\"visualisation\\\"}\"\n        }\n      },\n      \"finish_reason\": \"function_call\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 159,\n    \"completion_tokens\": 53,\n    \"total_tokens\": 212\n  },\n  \"system_fingerprint\": \"fp_eeff13170a\"\n}\n```", "```py\n # always calling extract_information function\nresponse = openai.ChatCompletion.create(\n    model = \"gpt-3.5-turbo-1106\",\n    messages = messages,\n    functions = extraction_functions,\n    function_call = {\"name\": \"extract_information\"}\n)\n\n# no function calls\nresponse = openai.ChatCompletion.create(\n    model = \"gpt-3.5-turbo-1106\",\n    messages = messages,\n    functions = extraction_functions,\n    function_call = \"none\"\n)\n```", "```py\nfrom pydantic import BaseModel, Field\nfrom typing import Optional\n\nclass RequestStructure(BaseModel):\n  \"\"\"extracts information\"\"\"\n  metric: str = Field(description = \"main metric we need to calculate, for example, 'number of users' or 'number of sessions'\")\n  filters: Optional[str] = Field(description = \"filters to apply to the calculation (do not include filters on dates here)\")\n  dimensions: Optional[str] = Field(description = \"parameters to split your metric by\")\n  period_start: Optional[str] = Field(description = \"the start day of the period for a report\")\n  period_end: Optional[str] = Field(description = \"the end day of the period for a report\")\n  output_type: Optional[str] = Field(description = \"the desired output\", enum = [\"number\", \"visualisation\"])\n```", "```py\nfrom langchain.utils.openai_functions import convert_pydantic_to_openai_function\nextract_info_function = convert_pydantic_to_openai_function(RequestStructure, \n    name = 'extract_information')\n```", "```py\n{'name': 'extract_information',\n 'description': 'extracts information',\n 'parameters': {'title': 'RequestStructure',\n  'description': 'extracts information',\n  'type': 'object',\n  'properties': {'metric': {'title': 'Metric',\n    'description': \"main metric we need to calculate, for example, 'number of users' or 'number of sessions'\",\n    'type': 'string'},\n   'filters': {'title': 'Filters',\n    'description': 'filters to apply to the calculation (do not include filters on dates here)',\n    'type': 'string'},\n   'dimensions': {'title': 'Dimensions',\n    'description': 'parameters to split your metric by',\n    'type': 'string'},\n   'period_start': {'title': 'Period Start',\n    'description': 'the start day of the period for a report',\n    'type': 'string'},\n   'period_end': {'title': 'Period End',\n    'description': 'the end day of the period for a report',\n    'type': 'string'},\n   'output_type': {'title': 'Output Type',\n    'description': 'the desired output',\n    'enum': ['number', 'visualisation'],\n    'type': 'string'}},\n  'required': ['metric']}}\n```", "```py\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.chat_models import ChatOpenAI\n\nmodel = ChatOpenAI(temperature=0.1, model = 'gpt-3.5-turbo-1106')\\\n  .bind(functions = [extract_info_function])\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"Extract the relevant information from the provided request. \\\n            Extract ONLY the information presented in the initial request. \\\n            Don't add anything else. \\\n            Return partial information if something is missing.\"),\n    (\"human\", \"{request}\")\n])\n\nextraction_chain = prompt | model\n```", "```py\nextraction_chain.invoke({'request': \"How many customers visited our site on iOS in April 2023 from different countries?\"})\n```", "```py\nAIMessage(\n  content='', \n  additional_kwargs={\n    'function_call': {\n       'name': 'extract_information', \n       'arguments': '''{\n         \"metric\":\"number of customers\", \"filters\":\"device = 'iOS'\",\n         \"dimensions\":\"country\", \"period_start\":\"2023-04-01\",\n         \"period_end\":\"2023-04-30\", \"output_type\":\"number\"}\n        '''}\n  }\n)\n```", "```py\nfrom langchain.agents import tool\n\n@tool\ndef percentage_difference(metric1: float, metric2: float) -> float:\n    \"\"\"Calculates the percentage difference between metrics\"\"\"\n    return (metric2 - metric1)/metric1*100\n```", "```py\nprint(percentage_difference.name)\n# percentage_difference.name\n\nprint(percentage_difference.args)\n# {'metric1': {'title': 'Metric1', 'type': 'number'},\n# 'metric2': {'title': 'Metric2', 'type': 'number'}}\n\nprint(percentage_difference.description)\n# 'percentage_difference(metric1: float, metric2: float) -> float - Calculates the percentage difference between metrics'\n```", "```py\nfrom langchain.tools.render import format_tool_to_openai_function\nprint(format_tool_to_openai_function(percentage_difference))\n```", "```py\n{'name': 'percentage_difference',\n 'description': 'percentage_difference(metric1: float, metric2: float) -> float - Calculates the percentage difference between metrics',\n 'parameters': {'title': 'percentage_differenceSchemaSchema',\n  'type': 'object',\n  'properties': {'metric1': {'title': 'Metric1', 'type': 'number'},\n   'metric2': {'title': 'Metric2', 'type': 'number'}},\n  'required': ['metric1', 'metric2']}\n}\n```", "```py\nclass Metrics(BaseModel):\n    metric1: float = Field(description=\"Base metric value to calculate the difference\")\n    metric2: float = Field(description=\"New metric value that we compare with the baseline\")\n\n@tool(args_schema=Metrics)\ndef percentage_difference(metric1: float, metric2: float) -> float:\n    \"\"\"Calculates the percentage difference between metrics\"\"\"\n    return (metric2 - metric1)/metric1*100\n```", "```py\n{'name': 'percentage_difference',\n 'description': 'percentage_difference(metric1: float, metric2: float) -> float - Calculates the percentage difference between metrics',\n 'parameters': {'title': 'Metrics',\n  'type': 'object',\n  'properties': {'metric1': {'title': 'Metric1',\n    'description': 'Base metric value to calculate the difference',\n    'type': 'number'},\n   'metric2': {'title': 'Metric2',\n    'description': 'New metric value that we compare with the baseline',\n    'type': 'number'}},\n  'required': ['metric1', 'metric2']}}\n```", "```py\nmodel = ChatOpenAI(temperature=0.1, model = 'gpt-3.5-turbo-1106')\\\n  .bind(functions = [format_tool_to_openai_function(percentage_difference)])\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a product analyst willing to help your product team. You are very strict to the point and accurate. You use only facts, not inventing information.\"),\n    (\"user\", \"{request}\")\n])\n\nanalyst_chain = prompt | model\nanalyst_chain.invoke({'request': \"In April we had 100 users and in May only 95\\. What is difference in percent?\"})\n```", "```py\nAIMessage(content='', additional_kwargs={\n    'function_call': {\n      'name': 'percentage_difference', \n      'arguments': '{\"metric1\":100,\"metric2\":95}'}\n  }\n)\n```", "```py\nfrom langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\nanalyst_chain = prompt | model | OpenAIFunctionsAgentOutputParser()\nresult = analyst_chain.invoke({'request': \"There were 100 users in April and 110 users in May. How did the number of users changed?\"})\n```", "```py\nAgentActionMessageLog(\n   tool='percentage_difference', \n   tool_input={'metric1': 100, 'metric2': 110}, \n   log=\"\\nInvoking: `percentage_difference` with `{'metric1': 100, 'metric2': 110}`\\n\\n\\n\", \n   message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'percentage_difference', 'arguments': '{\"metric1\":100,\"metric2\":110}'}})]\n)\n```", "```py\nobservation = percentage_difference(result.tool_input)\nprint(observation)\n# 10\n```", "```py\nfrom langchain.prompts import MessagesPlaceholder\n\nmodel = ChatOpenAI(temperature=0.1, model = 'gpt-3.5-turbo-1106')\\\n  .bind(functions = [format_tool_to_openai_function(percentage_difference)])\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a product analyst willing to help your product team. You are very strict to the point and accurate. You use only facts, not inventing information.\"),\n    (\"user\", \"{request}\"),\n    MessagesPlaceholder(variable_name=\"observations\")\n])\n\nanalyst_chain = prompt | model | OpenAIFunctionsAgentOutputParser()\nresult1 = analyst_chain.invoke({\n    'request': \"There were 100 users in April and 110 users in May. How did the number of users changed?\",\n    \"observations\": []\n})\n\nobservation = percentage_difference(result1.tool_input)\nprint(observation)\n# 10\n```", "```py\nfrom langchain.agents.format_scratchpad import format_to_openai_functions\nformat_to_openai_functions([(result1, observation), ])\n```", "```py\n[AIMessage(content='', additional_kwargs={'function_call': {'name': 'percentage_difference', \n                                           'arguments': '{\"metric1\":100,\"metric2\":110}'}}),\n FunctionMessage(content='10.0', name='percentage_difference')]\n```", "```py\nresult2 = analyst_chain.invoke({\n    'request': \"There were 100 users in April and 110 users in May. How did the number of users changed?\",\n    \"observations\": format_to_openai_functions([(result1, observation)])\n})\n```", "```py\nAgentFinish(\n  return_values={'output': 'The number of users increased by 10%.'}, \n  log='The number of users increased by 10%.'\n)\n```", "```py\nSystem: You are a product analyst willing to help your product team. You are very strict to the point and accurate. You use only facts, not inventing information.\nHuman: There were 100 users in April and 110 users in May. How did the number of users changed?\nAI: {'name': 'percentage_difference', 'arguments': '{\"metric1\":100,\"metric2\":110}'}\nFunction: 10.0\n```", "```py\nimport langchain\nlangchain.debug = True\n```", "```py\nimport datetime\nimport random\n\nclass Filters(BaseModel):\n    month: str = Field(description=\"Month of customer's activity in the format %Y-%m-%d\")\n    city: Optional[str] = Field(description=\"City of residence for customers (by default no filter)\", \n                    enum = [\"London\", \"Berlin\", \"Amsterdam\", \"Paris\"])\n\n@tool(args_schema=Filters)\ndef get_monthly_active_users(month: str, city: str = None) -> int:\n    \"\"\"Returns number of active customers for the specified month\"\"\"\n    dt = datetime.datetime.strptime(month, '%Y-%m-%d')\n    total = dt.year + 10*dt.month\n    if city is None:\n        return total\n    else:\n        return int(total*random.random())\n```", "```py\nimport wikipedia\n\nclass Wikipedia(BaseModel):\n    term: str = Field(description=\"Term to search for\")\n\n@tool(args_schema=Wikipedia)\ndef get_summary(term: str) -> str:\n    \"\"\"Returns basic knowledge about the given term provided by Wikipedia\"\"\"\n    return wikipedia.summary(term)\n```", "```py\ntoolkit = {\n    'percentage_difference': percentage_difference,\n    'get_monthly_active_users': get_monthly_active_users,\n    'get_summary': get_summary\n}\n\nanalyst_functions = [format_tool_to_openai_function(f) \n  for f in toolkit.values()]\n```", "```py\nfrom langchain.prompts import MessagesPlaceholder\n\nmodel = ChatOpenAI(temperature=0.1, model = 'gpt-4-1106-preview')\\\n  .bind(functions = analyst_functions)\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a product analyst willing to help your product team. You are very strict to the point and accurate. \\\n        You use only information provided in the initial request. \\\n        If you need to determine some information i.e. what is the name of the capital, you can use Wikipedia.\"),\n    (\"user\", \"{request}\"),\n    MessagesPlaceholder(variable_name=\"observations\")\n])\n\nanalyst_chain = prompt | model | OpenAIFunctionsAgentOutputParser()\n```", "```py\nresult1 = analyst_chain.invoke({\n    'request': \"How many users were in April 2023 from Berlin?\",\n    \"observations\": []\n})\nprint(result1)\n```", "```py\nresult1 = analyst_chain.invoke({\n    'request': \"How did the number of users from the capital of Germany\\\n        change between April and May 2023?\",\n    \"observations\": []\n})\n```", "```py\nobservation1 = toolkit[result1.tool](result1.tool_input)\nprint(observation1)\n\n# The capital of Germany is the  city state of Berlin. It is the seat of \n# the President of Germany, whose official residence is Schloss Bellevue. \n# The Bundesrat (\"federal council\") is the representation of the Federal States \n# (Bundesl√§nder) of Germany and has its seat at the former Prussian Herrenhaus \n# (House of Lords). Though most of the ministries are seated in Berlin, \n# some of them, as well as some minor departments, are seated in Bonn, \n# the former capital of West Germany.\n# Although Berlin is officially the capital of the Federal Republic of Germany,\n# 8,000 out of the 18,000 total officials employed at the federal bureaucracy \n# still work in Bonn, about 600 km (370 mi) away from Berlin.\n\n# source: https://en.wikipedia.org/wiki/Capital_of_Germany \n\nresult2 = analyst_chain.invoke({\n    'request': \"How did the number of users from the capital of Germany change between April and May 2023?\",\n    \"observations\": format_to_openai_functions([(result1, observation1)])\n})\n```", "```py\nobservation2 = toolkit[result2.tool](result2.tool_input)\nprint(observation2)\n# 168\n\nresult3 = analyst_chain.invoke({\n    'request': \"How did the number of users from the capital of Germany change between April and May 2023?\",\n    \"observations\": format_to_openai_functions([(result1, observation1), (result2, observation2)])\n})\n```", "```py\nobservation3 = toolkit[result3.tool](result3.tool_input)\nprint(observation3)\n# 1046\n\nresult4 = analyst_chain.invoke({\n    'request': \"How did the number of users from the capital of Germany change between April and May 2023?\",\n    \"observations\": format_to_openai_functions(\n      [(result1, observation1), (result2, observation2), \n      (result3, observation3)])\n})\n```", "```py\nobservation4 = toolkit[result4.tool](result4.tool_input)\nprint(observation4)\n\n# 523.27\n\nresult5 = analyst_chain.invoke({\n    'request': \"How did the number of users from the capital of Germany change between April and May 2023?\",\n    \"observations\": format_to_openai_functions(\n      [(result1, observation1), (result2, observation2), \n      (result3, observation3), (result4, observation4)])\n})\n```"]