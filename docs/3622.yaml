- en: Convenient Reinforcement Learning With Stable-Baselines3
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/convenient-reinforcement-learning-with-stable-baselines3-dccf466b7585?source=collection_archive---------1-----------------------#2023-12-09](https://towardsdatascience.com/convenient-reinforcement-learning-with-stable-baselines3-dccf466b7585?source=collection_archive---------1-----------------------#2023-12-09)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Reinforcement Learning](https://medium.com/tag/reinforcement-learning)'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Reinforcement learning without the boilerplate code
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://dr-robert-kuebler.medium.com/?source=post_page-----dccf466b7585--------------------------------)[![Dr.
    Robert Kübler](../Images/3b8d8b88f76c0c43d9c305e3885e7ab9.png)](https://dr-robert-kuebler.medium.com/?source=post_page-----dccf466b7585--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dccf466b7585--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dccf466b7585--------------------------------)
    [Dr. Robert Kübler](https://dr-robert-kuebler.medium.com/?source=post_page-----dccf466b7585--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6d6b5fb431bf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconvenient-reinforcement-learning-with-stable-baselines3-dccf466b7585&user=Dr.+Robert+K%C3%BCbler&userId=6d6b5fb431bf&source=post_page-6d6b5fb431bf----dccf466b7585---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----dccf466b7585--------------------------------)
    ·10 min read·Dec 9, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdccf466b7585&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconvenient-reinforcement-learning-with-stable-baselines3-dccf466b7585&user=Dr.+Robert+K%C3%BCbler&userId=6d6b5fb431bf&source=-----dccf466b7585---------------------clap_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdccf466b7585&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconvenient-reinforcement-learning-with-stable-baselines3-dccf466b7585&source=-----dccf466b7585---------------------bookmark_footer-----------)![](../Images/b3a8b5fb8229e66fec0ddd0fbefcafc4.png)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Created by the author with Leonardo Ai**.**
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: In my previous articles about reinforcement learning, I have shown you how to
    implement (deep) Q-learning using nothing but a bit of numpy and TensorFlow. While
    this was an important step towards understanding how these algorithms work under
    the hood, the code tended to get lengthy — and I even merely implemented one of
    the most basic versions of deep Q-learning.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '[](/hands-on-deep-q-learning-9073040ce841?source=post_page-----dccf466b7585--------------------------------)
    [## Hands-On Deep Q-Learning'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/hands-on-deep-q-learning-9073040ce841?source=post_page-----dccf466b7585--------------------------------)
    [## 实践深度 Q 学习'
- en: Level up your agent to win more difficult games!
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提升你的智能体，以赢得更困难的游戏！
- en: towardsdatascience.com](/hands-on-deep-q-learning-9073040ce841?source=post_page-----dccf466b7585--------------------------------)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[前往数据科学网站](/hands-on-deep-q-learning-9073040ce841?source=post_page-----dccf466b7585--------------------------------)'
- en: Given the explanations in this article, understanding the code should be quite
    straightforward. However, if we *really* want to get things done, we should rely
    on well-documented, maintained, and optimized libraries. Just as we don’t want
    to implement linear regression over and over again, we don’t want to do the same
    for reinforcement learning.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 根据本文的解释，理解代码应该相当直接。然而，如果我们*真的*想要完成任务，我们应该依赖于文档完善、维护良好且经过优化的库。正如我们不希望一遍遍实现线性回归一样，我们也不希望在强化学习中重复做同样的事。
- en: In this article, I will show you the reinforcement library [**Stable-Baselines3**](https://stable-baselines3.readthedocs.io/)
    which is as easy to use as scikit-learn. Instead of training models to predict
    labels, though, we get trained…
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将向你展示一个名为[**Stable-Baselines3**](https://stable-baselines3.readthedocs.io/)的强化学习库，它的使用方式和
    scikit-learn 一样简单。不过，我们训练的不是用于预测标签的模型，而是…
