- en: Custom Kafka metrics using Apache Spark PrometheusServlet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/custom-kafka-streaming-metrics-using-apache-spark-prometheus-sink-9c04cf2ddaf1?source=collection_archive---------6-----------------------#2023-02-02](https://towardsdatascience.com/custom-kafka-streaming-metrics-using-apache-spark-prometheus-sink-9c04cf2ddaf1?source=collection_archive---------6-----------------------#2023-02-02)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Creating and exposing custom Kafka Consumer Streaming metrics in Apache Spark
    using PrometheusServlet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@vitorf24?source=post_page-----9c04cf2ddaf1--------------------------------)[![Vitor
    Teixeira](../Images/db450ae1e572a49357c02e9ba3eb4f9d.png)](https://medium.com/@vitorf24?source=post_page-----9c04cf2ddaf1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9c04cf2ddaf1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9c04cf2ddaf1--------------------------------)
    [Vitor Teixeira](https://medium.com/@vitorf24?source=post_page-----9c04cf2ddaf1--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6b05068b69d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcustom-kafka-streaming-metrics-using-apache-spark-prometheus-sink-9c04cf2ddaf1&user=Vitor+Teixeira&userId=6b05068b69d8&source=post_page-6b05068b69d8----9c04cf2ddaf1---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9c04cf2ddaf1--------------------------------)
    ·6 min read·Feb 2, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9c04cf2ddaf1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcustom-kafka-streaming-metrics-using-apache-spark-prometheus-sink-9c04cf2ddaf1&user=Vitor+Teixeira&userId=6b05068b69d8&source=-----9c04cf2ddaf1---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c04cf2ddaf1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcustom-kafka-streaming-metrics-using-apache-spark-prometheus-sink-9c04cf2ddaf1&source=-----9c04cf2ddaf1---------------------bookmark_footer-----------)![](../Images/6bd8f187e7f1a8a29cca8e8787e9ce8f.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Christin Hume](https://unsplash.com/@christinhumephoto?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: In this blog post, I will describe how to create and enhance current Spark Structured
    Streaming metrics with Kafka consumer metrics and expose them using the Spark
    3 PrometheusServlet that can be directly targeted by Prometheus. In previous Spark
    versions, one must set up either a JmxSink/JmxExporter, GraphiteSink/GraphiteExporter,
    or a custom sink deploying metrics to a PushGateway server. With that said, we
    couldn’t really avoid the increase in the complexity of our solutions as we must
    set up external components that interact with our applications so that they can
    be scraped by Prometheus.
  prefs: []
  type: TYPE_NORMAL
- en: Motivation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: More than ever, observability is a must when it comes to software. It allows
    us to get insights into what is happening inside the software without having to
    directly interact with the system. One way of building upon this observability
    pillar is by exposing application metrics. When built upon an observability stack,
    they allow us to detect problems either by alerts or simply looking at a dashboard
    and finding their root cause by analyzing metrics.
  prefs: []
  type: TYPE_NORMAL
