- en: Custom Kafka metrics using Apache Spark PrometheusServlet
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Apache Spark PrometheusServlet 的自定义 Kafka 指标
- en: 原文：[https://towardsdatascience.com/custom-kafka-streaming-metrics-using-apache-spark-prometheus-sink-9c04cf2ddaf1?source=collection_archive---------6-----------------------#2023-02-02](https://towardsdatascience.com/custom-kafka-streaming-metrics-using-apache-spark-prometheus-sink-9c04cf2ddaf1?source=collection_archive---------6-----------------------#2023-02-02)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/custom-kafka-streaming-metrics-using-apache-spark-prometheus-sink-9c04cf2ddaf1?source=collection_archive---------6-----------------------#2023-02-02](https://towardsdatascience.com/custom-kafka-streaming-metrics-using-apache-spark-prometheus-sink-9c04cf2ddaf1?source=collection_archive---------6-----------------------#2023-02-02)
- en: Creating and exposing custom Kafka Consumer Streaming metrics in Apache Spark
    using PrometheusServlet
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Apache Spark 中使用 PrometheusServlet 创建和暴露自定义 Kafka Consumer Streaming 指标
- en: '[](https://medium.com/@vitorf24?source=post_page-----9c04cf2ddaf1--------------------------------)[![Vitor
    Teixeira](../Images/db450ae1e572a49357c02e9ba3eb4f9d.png)](https://medium.com/@vitorf24?source=post_page-----9c04cf2ddaf1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9c04cf2ddaf1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9c04cf2ddaf1--------------------------------)
    [Vitor Teixeira](https://medium.com/@vitorf24?source=post_page-----9c04cf2ddaf1--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@vitorf24?source=post_page-----9c04cf2ddaf1--------------------------------)[![Vitor
    Teixeira](../Images/db450ae1e572a49357c02e9ba3eb4f9d.png)](https://medium.com/@vitorf24?source=post_page-----9c04cf2ddaf1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9c04cf2ddaf1--------------------------------)[![数据科学前沿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9c04cf2ddaf1--------------------------------)
    [Vitor Teixeira](https://medium.com/@vitorf24?source=post_page-----9c04cf2ddaf1--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6b05068b69d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcustom-kafka-streaming-metrics-using-apache-spark-prometheus-sink-9c04cf2ddaf1&user=Vitor+Teixeira&userId=6b05068b69d8&source=post_page-6b05068b69d8----9c04cf2ddaf1---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9c04cf2ddaf1--------------------------------)
    ·6 min read·Feb 2, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9c04cf2ddaf1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcustom-kafka-streaming-metrics-using-apache-spark-prometheus-sink-9c04cf2ddaf1&user=Vitor+Teixeira&userId=6b05068b69d8&source=-----9c04cf2ddaf1---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6b05068b69d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcustom-kafka-streaming-metrics-using-apache-spark-prometheus-sink-9c04cf2ddaf1&user=Vitor+Teixeira&userId=6b05068b69d8&source=post_page-6b05068b69d8----9c04cf2ddaf1---------------------post_header-----------)
    发布在 [数据科学前沿](https://towardsdatascience.com/?source=post_page-----9c04cf2ddaf1--------------------------------)
    ·6分钟阅读·2023年2月2日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9c04cf2ddaf1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcustom-kafka-streaming-metrics-using-apache-spark-prometheus-sink-9c04cf2ddaf1&user=Vitor+Teixeira&userId=6b05068b69d8&source=-----9c04cf2ddaf1---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c04cf2ddaf1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcustom-kafka-streaming-metrics-using-apache-spark-prometheus-sink-9c04cf2ddaf1&source=-----9c04cf2ddaf1---------------------bookmark_footer-----------)![](../Images/6bd8f187e7f1a8a29cca8e8787e9ce8f.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c04cf2ddaf1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcustom-kafka-streaming-metrics-using-apache-spark-prometheus-sink-9c04cf2ddaf1&source=-----9c04cf2ddaf1---------------------bookmark_footer-----------)![](../Images/6bd8f187e7f1a8a29cca8e8787e9ce8f.png)'
- en: Photo by [Christin Hume](https://unsplash.com/@christinhumephoto?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Christin Hume](https://unsplash.com/@christinhumephoto?utm_source=medium&utm_medium=referral)
    于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: In this blog post, I will describe how to create and enhance current Spark Structured
    Streaming metrics with Kafka consumer metrics and expose them using the Spark
    3 PrometheusServlet that can be directly targeted by Prometheus. In previous Spark
    versions, one must set up either a JmxSink/JmxExporter, GraphiteSink/GraphiteExporter,
    or a custom sink deploying metrics to a PushGateway server. With that said, we
    couldn’t really avoid the increase in the complexity of our solutions as we must
    set up external components that interact with our applications so that they can
    be scraped by Prometheus.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我将描述如何使用 Kafka 消费者指标创建和增强当前的 Spark Structured Streaming 指标，并通过 Spark
    3 的 PrometheusServlet 将其暴露出来，Prometheus 可以直接访问。之前的 Spark 版本中，必须设置 JmxSink/JmxExporter、GraphiteSink/GraphiteExporter
    或自定义 sink 将指标部署到 PushGateway 服务器。尽管如此，我们确实无法避免解决方案复杂性的增加，因为我们必须设置与我们的应用程序交互的外部组件，以便它们可以被
    Prometheus 抓取。
- en: Motivation
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 动机
- en: More than ever, observability is a must when it comes to software. It allows
    us to get insights into what is happening inside the software without having to
    directly interact with the system. One way of building upon this observability
    pillar is by exposing application metrics. When built upon an observability stack,
    they allow us to detect problems either by alerts or simply looking at a dashboard
    and finding their root cause by analyzing metrics.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 现如今，软件的可观测性比以往任何时候都更为重要。它使我们能够洞察软件内部发生的情况，而无需直接与系统互动。建立在这一可观测性支柱上的一种方式是暴露应用程序指标。当建立在可观测性栈上时，它们允许我们通过警报或仅仅查看仪表板来检测问题，并通过分析指标找到问题的根本原因。
