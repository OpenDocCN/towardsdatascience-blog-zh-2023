- en: Linear Discriminant Analysis (LDA) Can Be So Easy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性判别分析（LDA）可以如此简单
- en: 原文：[https://towardsdatascience.com/linear-discriminant-analysis-lda-can-be-so-easy-b3f46e32f982?source=collection_archive---------8-----------------------#2023-02-20](https://towardsdatascience.com/linear-discriminant-analysis-lda-can-be-so-easy-b3f46e32f982?source=collection_archive---------8-----------------------#2023-02-20)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/linear-discriminant-analysis-lda-can-be-so-easy-b3f46e32f982?source=collection_archive---------8-----------------------#2023-02-20](https://towardsdatascience.com/linear-discriminant-analysis-lda-can-be-so-easy-b3f46e32f982?source=collection_archive---------8-----------------------#2023-02-20)
- en: An Interactive Visualisation for You to Experiment With
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为你准备的互动可视化工具
- en: '[](https://medium.com/@frederikho?source=post_page-----b3f46e32f982--------------------------------)[![Frederik
    Holtel](../Images/adc1632104df83db4449ca56d0a2c2ad.png)](https://medium.com/@frederikho?source=post_page-----b3f46e32f982--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b3f46e32f982--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b3f46e32f982--------------------------------)
    [Frederik Holtel](https://medium.com/@frederikho?source=post_page-----b3f46e32f982--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@frederikho?source=post_page-----b3f46e32f982--------------------------------)[![Frederik
    Holtel](../Images/adc1632104df83db4449ca56d0a2c2ad.png)](https://medium.com/@frederikho?source=post_page-----b3f46e32f982--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b3f46e32f982--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b3f46e32f982--------------------------------)
    [Frederik Holtel](https://medium.com/@frederikho?source=post_page-----b3f46e32f982--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fde281205c742&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-discriminant-analysis-lda-can-be-so-easy-b3f46e32f982&user=Frederik+Holtel&userId=de281205c742&source=post_page-de281205c742----b3f46e32f982---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b3f46e32f982--------------------------------)
    ·7 min read·Feb 20, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb3f46e32f982&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-discriminant-analysis-lda-can-be-so-easy-b3f46e32f982&user=Frederik+Holtel&userId=de281205c742&source=-----b3f46e32f982---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fde281205c742&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-discriminant-analysis-lda-can-be-so-easy-b3f46e32f982&user=Frederik+Holtel&userId=de281205c742&source=post_page-de281205c742----b3f46e32f982---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b3f46e32f982--------------------------------)
    ·7 分钟阅读·2023年2月20日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb3f46e32f982&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-discriminant-analysis-lda-can-be-so-easy-b3f46e32f982&user=Frederik+Holtel&userId=de281205c742&source=-----b3f46e32f982---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb3f46e32f982&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-discriminant-analysis-lda-can-be-so-easy-b3f46e32f982&source=-----b3f46e32f982---------------------bookmark_footer-----------)![](../Images/5f710a7c3c6c2686a4fca1620a2c6619.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb3f46e32f982&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-discriminant-analysis-lda-can-be-so-easy-b3f46e32f982&source=-----b3f46e32f982---------------------bookmark_footer-----------)![](../Images/5f710a7c3c6c2686a4fca1620a2c6619.png)'
- en: 'Image created by Arus Nazaryan using Midjourney. Prompt: “`Drone footage of
    two flocks of sheep, bright blue and deep red, divided by a fence which separates
    the flocks in the middle, clean, realistic sheep, on green grass, photorealistic`”'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 Arus Nazaryan 使用 Midjourney 创建。提示词：“`无人机拍摄的两群羊，明亮的蓝色和深红色，被一条中间分隔群体的围栏分开，干净、逼真的羊，绿草地上，照片级真实感`”
- en: Classification is a central topic in machine learning. However, it can be challenging
    to understand how the different algorithms work. In this article, we will make
    linear discriminant analysis come alive with an interactive plot that you can
    experiment with. Get ready to dive into the world of data classification!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 分类是机器学习中的核心话题。然而，理解不同算法的工作原理可能会很具挑战性。在这篇文章中，我们将通过一个互动图表使线性判别分析变得生动，你可以进行实验。准备好深入数据分类的世界吧！
- en: '**Interactive plot** 👇🏽 Click to add and remove data points, use drag to move
    them. Change the population parameters and generate new data samples.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**交互式图** 👇🏽 点击添加和移除数据点，使用拖动来移动它们。改变人口参数并生成新的数据样本。'
- en: If you are applying or studying classification methods, you might have come
    across various methods such as Naive Bayes, K-nearest neighbours (KNN), quadratic
    discriminant analysis (QDA) and linear discriminant analysis (LDA). However, it
    is not always intuitive to understand what the different algorithms are doing.
    LDA is one of the first approaches to learn and consider and this articles demonstrates
    how the technique works.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在应用或研究分类方法，可能会遇到各种方法，如朴素贝叶斯、K最近邻（KNN）、二次判别分析（QDA）和线性判别分析（LDA）。然而，理解不同算法的工作原理并不总是直观的。LDA是最初需要学习和考虑的方法之一，本文展示了该技术的工作原理。
- en: 'Let’s start from the beginning. All classification methods are approaches to
    answer the question: Which type of class does this observation belong to?'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从头开始。所有分类方法都是为了回答这个问题：这个观测值属于哪种类型的类别？
- en: In the plot above, there are two independent variables, `x_1` on the horizontal
    axis and `x_2` on the vertical axis. Think of the independent variables as scores
    in two subjects, e.g. physics and literature (ranging from 0–20). The dependent
    value `y` is the class, in the plot represented as red or blue. Think of it as
    a binary variable we want to predict, such as whether an applicant is admitted
    to university (“yes” or “no”). A set of given observations is displayed as circles.
    Each is characterised by a `x_1` and a `x_2` value and the class.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的图中，有两个独立变量，`x_1` 在水平轴上，`x_2` 在垂直轴上。把独立变量看作是两个学科的分数，例如物理和文学（范围从0到20）。因变量
    `y` 是类别，在图中表示为红色或蓝色。将其视为我们想要预测的二元变量，例如申请人是否被大学录取（“是”或“否”）。一组给定的观测值以圆圈的形式显示。每个圆圈由
    `x_1` 和 `x_2` 值以及类别特征。
- en: Now, if a new data point is added, to which class shall it be assigned?
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果添加一个新的数据点，它应该被分配到哪个类别呢？
- en: LDA allows us to draw a boundary to divide the space in two parts (or multiple
    ones, but two in this case with two classes). For example, below in figure 1 I
    marked a new data point at `(x_1 = 4, x_2 = 14)` with a cross. As it falls on
    the “red side” of the space, this observation would be assigned to the red class.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: LDA允许我们绘制一个边界，将空间分成两部分（或者多个部分，但在这种情况下是两个类别）。例如，在下图1中，我在 `(x_1 = 4, x_2 = 14)`
    处标记了一个新的数据点。由于它落在空间的“红色侧”，这个观测值将被分配到红色类别。
- en: '![](../Images/03f247a59ed97037b70563a516d9fdc9.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03f247a59ed97037b70563a516d9fdc9.png)'
- en: 'Figure 1: The new observation at the cross (x_1=4, x_2=14) is assigned to the
    red class.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：交叉点 (x_1=4, x_2=14) 被分配到红色类别。
- en: How it works — the math behind it
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的——背后的数学
- en: So given the LDA boundary, we can make classifications. But how can we draw
    the boundary line using the LDA algorithm?
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，给定LDA边界，我们可以进行分类。但是我们如何使用LDA算法绘制边界线呢？
- en: The line divides the plot where the probability of the red class and the blue
    class is 50% each. Going to one side, the probability of red is higher, going
    to the opposite side, blue is more probable. We need to come up with a way to
    calculate how probable it is for the new observation to belong to each of the
    classes.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这条线将图形分成红色类别和蓝色类别的概率各为50%的区域。往一侧移动，红色的概率更高；往另一侧移动，蓝色的概率更高。我们需要找出一种方法来计算新观测值属于每个类别的概率。
- en: 'The probability that the new observation belongs to the red class can be written
    this way: `P(Y = red| X = (x_1 = 4, x_2 = 14))`. To make it easier to read, instead
    of `x_1 = 4, x_2 = 14`, I will in the following just write `x` which is a vector
    containing the two values.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 新观测值属于红色类别的概率可以这样写： `P(Y = red| X = (x_1 = 4, x_2 = 14))`。为了便于阅读，我将以下用 `x` 代替
    `x_1 = 4, x_2 = 14`，它是包含两个值的向量。
- en: According to the Bayes theorem, we can express conditional probabilities as
    `P(Y = red | X = x) = P(Y = red ) * P(X = x | Y = red) / P(X = x)`. So to calculate
    the probability that the new observation is “red” given its x values, we need
    to know three other probabilities.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 根据贝叶斯定理，我们可以将条件概率表示为 `P(Y = red | X = x) = P(Y = red ) * P(X = x | Y = red)
    / P(X = x)`。因此，为了计算给定x值的新观测值是“红色”的概率，我们需要知道另外三个概率。
- en: Let’s go step by step. `P(Y = red)` and `P(X = x)` are called “prior probabilities”.
    In the plot, `P(Y = red)` can be calculated simply by taking the share of all
    “red” observations of the total number of observations (27,27% in figure 1).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一步步来。`P(Y = red)` 和 `P(X = x)` 被称为“先验概率”。在图中，`P(Y = red)` 可以通过将所有“红色”观察值占总观察值数量的比例（图1中为27,27%）来简单计算。
- en: Calculating the prior probability of x, `P(X = x)`, is more difficult. We don’t
    have any observation with `x_1 = 4` and `x_2 = 14`in the initial dataset, so what
    is its probability? Zero? Not quite.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 计算 `x` 的先验概率 `P(X = x)` 更为困难。我们在初始数据集中没有 `x_1 = 4` 和 `x_2 = 14` 的观察值，那么它的概率是多少？零？不完全是。
- en: '`P(X = x)` can be understood as the sum of the joint probabilities `P(Y = red,
    X = x)` and `P(Y = blue, X = x)` (see also [here](https://stats.stackexchange.com/questions/294080/proof-of-a-modified-bayes-theorem/601390#601390)):'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`P(X = x)` 可以理解为联合概率 `P(Y = red, X = x)` 和 `P(Y = blue, X = x)` 的总和（另见 [这里](https://stats.stackexchange.com/questions/294080/proof-of-a-modified-bayes-theorem/601390#601390)）：'
- en: '![](../Images/799fcbe610da7c6556a979336e1d23ab.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/799fcbe610da7c6556a979336e1d23ab.png)'
- en: 'Each of the joint probabilities can be expressed with the Bayes theorem as:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 每个联合概率可以用贝叶斯定理表示为：
- en: '![](../Images/24085fa6839e75ef86e639e814ace775.png)![](../Images/c151ed9d4013af48cf428953eb9cf508.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/24085fa6839e75ef86e639e814ace775.png)![](../Images/c151ed9d4013af48cf428953eb9cf508.png)'
- en: You see the priors `P(red)` and `P(blue)` enter again, which we already know
    how to determine. What is left for us to do, is to find a way to calculate the
    conditional probabilities `P(X = x | Y = red)` and `P(X = x | Y = blue)`.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到先验 `P(red)` 和 `P(blue)` 再次出现，我们已经知道如何确定它们。剩下的工作是找到计算条件概率 `P(X = x | Y =
    red)` 和 `P(X = x | Y = blue)` 的方法。
- en: 'Even if we did never see any red data point at position `x` in the plot in
    our original data set, we can find a probability if we regard `x` to be drawn
    from a population of a certain form. Usually when using real world data, the population
    is not directly observable, so we don’t know the true form of the population distribution.
    What LDA does is to assume that the `x` values are normally distributed on the
    `x_1` and `x_2` axis. With real world data, this assumption can be more or less
    reasonable. As we are dealing with a generated data set here though, we don’t
    have to worry about this problem. The data originate from populations which follow
    a normal (i.e. Gaussian) distribution, characterised by two parameters (per independent
    variable): `~N(mean, variance)`.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们在原始数据集中从未看到位置 `x` 的任何红色数据点，我们也可以找到一个概率，如果我们将 `x` 看作是从某种形式的总体中抽取的。通常在使用现实世界数据时，总体是不可直接观察的，因此我们不知道总体分布的真实形式。LDA的做法是假设
    `x` 值在 `x_1` 和 `x_2` 轴上是正态分布的。对于现实世界的数据，这个假设可能或多或少是合理的。然而，由于我们处理的是生成的数据集，因此我们不必担心这个问题。这些数据来源于遵循正态（即高斯）分布的总体，其特征由两个参数（每个独立变量）：`~N(mean,
    variance)`。
- en: Using the formula for multivariate normal distributions, we can describe the
    distribution of the data belonging to class “red” as
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 使用多元正态分布的公式，我们可以将属于“红色”类别的数据的分布描述为
- en: '![](../Images/4b4031dc61db91365394f8ba1779263f.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b4031dc61db91365394f8ba1779263f.png)'
- en: where Σ denotes a covariance matrix. LDA uses only one common covariance matrix
    for all classes, meaning that it assumes that all classes have the same `variance(x_1)`,
    `variance(x_2)` and `covariance(x_1, x_2)`.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 Σ 表示协方差矩阵。LDA 仅使用一个共同的协方差矩阵，意味着它假设所有类别具有相同的 `variance(x_1)`、`variance(x_2)`
    和 `covariance(x_1, x_2)`。
- en: 'Now that we’ve got the formula for `P (X = x | Y = red)`, we can plug this
    in the equation above to get to `P (Y = red|X = x)`. This gives us a monstrous
    equation, which I’ll skip here. Luckily, it gets simpler from here. Our goal now
    is to find the dividing line that separates the red and blue zones, i.e. we want
    to find those points where the probabilities of being class red or blue are equal:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们得到了 `P (X = x | Y = red)` 的公式，我们可以将其代入上面的方程中以得到 `P (Y = red|X = x)`。这会得到一个庞大的方程，我在这里略过。幸运的是，从这里开始会更简单。我们的目标是找到分隔红色和蓝色区域的分界线，即我们要找到那些红色或蓝色的概率相等的点：
- en: '![](../Images/67b338ecddf9e092b8ae3e60bb63bd78.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/67b338ecddf9e092b8ae3e60bb63bd78.png)'
- en: 'Performing some transformations, it can be shown that minimising this is equivalent
    to minimising the following equation:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 进行一些变换后，可以证明最小化这个等价于最小化以下方程：
- en: '![](../Images/108550b5f8c0466072a963be46d35546.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/108550b5f8c0466072a963be46d35546.png)'
- en: Solving this for `x_2`, we get a line like
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 对 `x_2` 求解，我们得到一条类似于
- en: '![](../Images/100c7df1aaca3863d287b1c2f5f0ed2a.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/100c7df1aaca3863d287b1c2f5f0ed2a.png)'
- en: where `β_0` and `β_1` are the parameters depending on the means µ_red and µ_blue,
    the common covariance matrix Σ and the prior probabilities of red and blue, P(“red”)
    and P(“blue”).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 其中`β_0`和`β_1`是依赖于均值µ_red和µ_blue、共同协方差矩阵Σ以及红色和蓝色的先验概率P（“red”）和P（“blue”）的参数。
- en: Exploring the plot
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索图表
- en: Now that you know how it works, you can explore the plot using different parameters.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解它是如何工作的，你可以使用不同的参数来探索图表。
- en: When you click “create new sample”, the plot displays two boundaries. The Bayes
    boundary is calculated using the “real” population parameters. The estimated boundary
    in contrast makes estimates for the parameters based on the sample data.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 当你点击“创建新样本”时，图表会显示两个边界。贝叶斯边界是使用“真实”总体参数计算的。相对而言，估计边界则基于样本数据对参数进行估计。
- en: 'Some guiding questions for exploration:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 探索的一些指导问题：
- en: Using which parameters does the estimated boundary deviate strongly from the
    Bayes boundary? (see figure 2, left image)
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用哪些参数时，估计边界与贝叶斯边界偏差较大？（见图2，左侧图像）
- en: How sensitive is the boundary to outliers? (see figure 2, center image)
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 边界对异常值有多敏感？（见图2，中间图像）
- en: Which parameters give results you did not expect?
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些参数产生了你没有预料到的结果？
- en: '![](../Images/649cf2e543b218c92974395aae814f8b.png)![](../Images/a0465c6200f9b51fbca9d93cb6399d9f.png)![](../Images/bf0cdda45ba59b21e6f72ba1f0ecfcaf.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/649cf2e543b218c92974395aae814f8b.png)![](../Images/a0465c6200f9b51fbca9d93cb6399d9f.png)![](../Images/bf0cdda45ba59b21e6f72ba1f0ecfcaf.png)'
- en: 'Figure 2\. Left: The estimated boundary deviates strongly from the Bayes boundary.
    Center: The boundary adapts to an outlier. Right: The boundary adapts well to
    the data point moving around.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图2\. 左侧：估计边界与贝叶斯边界偏差较大。中间：边界适应异常值。右侧：边界对移动的数据点适应良好。
- en: Final remarks
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最终备注
- en: LDA is an important tool to know in the realm of machine learning classification
    methods. However, it is one thing to understand the theory behind LDA through
    equations and formulas, and another to gain a practical understanding through
    hands-on exploration. The interactive tool presented here offers a unique opportunity
    to experiment and understand LDA in a more intuitive way.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: LDA是机器学习分类方法领域中的一个重要工具。然而，了解LDA的理论通过方程和公式是一回事，而通过实践探索获得实际理解则是另一回事。这里提供的互动工具提供了一个独特的机会，可以以更直观的方式实验和理解LDA。
- en: Which other statistical methods would you like to see interactively visualised?
    Let me know in the comments!
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 你希望看到哪些其他统计方法的互动可视化？请在评论中告诉我！
- en: Don’t forget to **follow me** to stay in the loop for further articles!
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 别忘了**关注我**，以便获取更多文章的最新动态！
- en: All images, unless otherwise noted, were created by the author using Observable.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，否则所有图像均由作者使用Observable创建。
- en: 'If you want to read up on LDA, have a look into the great book “An Introduction
    to Statistical Learning” by James, Witten, Hastie and Tibshirani, which you can
    download for free on their website: [https://www.statlearning.com/](https://www.statlearning.com/)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解LDA，可以看看由James、Witten、Hastie和Tibshirani编写的精彩书籍《统计学习导论》，你可以在他们的网站上免费下载：[https://www.statlearning.com/](https://www.statlearning.com/)
