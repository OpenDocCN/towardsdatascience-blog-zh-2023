- en: Managing Deep Learning Models Easily With TOML Configurations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/managing-deep-learning-models-easily-with-toml-configurations-fb680b9deabe?source=collection_archive---------4-----------------------#2023-06-15](https://towardsdatascience.com/managing-deep-learning-models-easily-with-toml-configurations-fb680b9deabe?source=collection_archive---------4-----------------------#2023-06-15)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You may never need those long CLI args for your train.py
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://equipintelligence.medium.com/?source=post_page-----fb680b9deabe--------------------------------)[![Shubham
    Panchal](../Images/d48aecd8b1ed27ab68fc2e7ff6716606.png)](https://equipintelligence.medium.com/?source=post_page-----fb680b9deabe--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fb680b9deabe--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fb680b9deabe--------------------------------)
    [Shubham Panchal](https://equipintelligence.medium.com/?source=post_page-----fb680b9deabe--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd45a9465f044&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanaging-deep-learning-models-easily-with-toml-configurations-fb680b9deabe&user=Shubham+Panchal&userId=d45a9465f044&source=post_page-d45a9465f044----fb680b9deabe---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fb680b9deabe--------------------------------)
    ·4 min read·Jun 15, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffb680b9deabe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanaging-deep-learning-models-easily-with-toml-configurations-fb680b9deabe&user=Shubham+Panchal&userId=d45a9465f044&source=-----fb680b9deabe---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffb680b9deabe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanaging-deep-learning-models-easily-with-toml-configurations-fb680b9deabe&source=-----fb680b9deabe---------------------bookmark_footer-----------)![](../Images/e4b95ed664b346a4ed6a66901d2d0454.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Scott Graham](https://unsplash.com/@homajob?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Managing deep learning models can be difficult due to the huge number of parameters
    and settings that are needed for all modules. The training module might need parameters
    like `batch_size` or the `num_epochs` or parameters for the learning rate scheduler.
    Similarly, the data preprocessing module might need `train_test_split` or parameters
    for image augmentation.
  prefs: []
  type: TYPE_NORMAL
- en: A naive approach to manage or introduce these parameters into pipeline is to
    use them as CLI arguments while running the scripts. Command line arguments could
    be difficult to enter and managing all parameters in a single file may not be
    possible. TOML files provide a cleaner way to manage configurations and scripts
    can load necessary parts of the configuration in the form of a Python `dict` without
    needing boilerplate code to read/parse command-line args.
  prefs: []
  type: TYPE_NORMAL
- en: In this blog, we’ll explore the use of TOML in configuration files and how we
    can efficiently use them across training/deployment scripts.
  prefs: []
  type: TYPE_NORMAL
- en: What are TOML files?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TOML, stands for [*Tom’s Obvious Minimal Language*](https://toml.io/en/), is
    file-format designed specifically for configuration files. The concept of a TOML
    file is quite similar to [YAML/YML files](https://yaml.org/) which have the ability
    to store key-value pairs in a tree-like hierarchy. [An advantage of TOML over
    YAML is its readability](https://www.reddit.com/r/devops/comments/6f82nu/yaml_vs_toml/)
    which becomes important when there are multiple nested levels.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/243acf211a4cf117dd43331068b4c1c7.png)'
  prefs: []
  type: TYPE_IMG
- en: Fig.1\. The same model configurations written in TOML (left) and YAML (right).
    TOML allows us to write key-value pairs at the same indentation level regardless
    of the hierarchy.
  prefs: []
  type: TYPE_NORMAL
- en: Personally, except for enhanced readability, I find no practical reason to prefer
    TOML over YAML. Using YAML is absolutely fine, here’s a [Python package](https://pypi.org/project/PyYAML/)
    for parsing YAML.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Why do we need configurations in TOML?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two advantages of using TOML for storing model/data/deployment configuration
    for ML models:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Managing all configurations in a single file: With TOML files, we can create
    multiple groups of settings that are required for different modules. For instance,
    in figure 1, the settings related to the model’s training procedure are nested
    under the `[train]` attribute, similarly the `port` and `host` required for deploying
    the model are stored under `deploy` . We need not jump between `train.py` or `deploy.py`
    to change their parameters, instead we can globalize all settings from a single
    TOML configuration file.'
  prefs: []
  type: TYPE_NORMAL
- en: This could be super helpful if we’re training the model on a virtual machine,
    where code-editors or IDEs are not available for editing files. A single config
    file is easy to edit with `vim` or `nano` available on most VMs.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How do we read configurations from TOML?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To read the configuration from a TOML files, two Python packages can be used,
    `[toml](https://github.com/uiri/toml)` and `[munch](https://github.com/uiri/toml)`
    . `toml` will help us read the TOML file and return the contents of the file as
    a Python `dict` . `munch` will convert the contents of the `dict` to enable attribute-style
    access of elements. For instance, instead of writing, `config[ "training" ][ "num_epochs"
    ]` , we can just write `config.training.num_epochs` which enhances readability.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the following file structure,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '`project_config.toml` contains the configuration for our ML project, like,'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In `config.py` , we create a function which returns the *munchified*-version
    of this configuration, using `toml` and `munch` ,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Now, now in any of our project files, like `train.py` or `predict.py` , we can
    load this configuration,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The output of `print( toml.load( filepath ) ) )` is,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: If you’re using MLOps tools like W&B Tracking or MLFlow, maintaining configuration
    as a `dict` could be helpful as we can directly pass it as an argument.
  prefs: []
  type: TYPE_NORMAL
- en: The End
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hope you will consider using TOML configurations in your next ML project! Its
    a clean way of managing settings that are both global or local to your training
    / deployment or inference scripts.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of writing long CLI arguments, the scripts could directly load the configuration
    from the TOML file. If we wish to train two versions of a model with different
    hyperparameters, we just need to change the TOML file in `config.py` . I have
    started using TOML files in my recent projects and experimentation has become
    faster. MLOps tools can also manage versions of a model along with their configurations,
    but the simplicity of the above discussed approach is unique and required minimal
    change in existing projects.
  prefs: []
  type: TYPE_NORMAL
- en: Hope you’ve enjoyed reading. Have a nice day ahead!
  prefs: []
  type: TYPE_NORMAL
