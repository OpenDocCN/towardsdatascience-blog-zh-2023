["```py\nversion: v1\nsharing:\n  timeSlicing:\n    resources:\n    - name: nvidia.com/gpu\n      replicas: 4\n```", "```py\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: default-mig-parted-config\ndata:\n  config.yaml: |\n    version: v1\n    mig-configs:\n      all-1g.5gb:\n        - devices: all\n          mig-enabled: true\n          mig-devices:\n            \"1g.5gb\": 7\n      all-2g.10gb:\n        - devices: all\n          mig-enabled: true\n          mig-devices:\n            \"2g.10gb\": 3 \n```", "```py\nhelm install oci://ghcr.io/nebuly-ai/helm-charts/nvidia-device-plugin \\\n  --version 0.13.0 \\\n  --generate-name \\\n  -n nebuly-nvidia \\\n  --create-namespace\n```", "```py\naffinity:\n  nodeAffinity:\n    requiredDuringSchedulingIgnoredDuringExecution:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: nos.nebuly.com/gpu-partitioning\n          operator: NotIn\n          values:\n          - mps\n```", "```py\nversion: v1\nsharing:\n  mps: \n    resources:\n      - name: nvidia.com/gpu\n        rename: nvidia.com/gpu-4gb\n        memoryGB: 4\n        replicas: 2\n        devices: [\"0\"]\n```", "```py\napiVersion: v1\nkind: Pod\nmetadata:\n  name: mps-partitioning-example\nspec:\n  hostIPC: true # \n  securityContext:\n    runAsUser: 1000 # \n  containers:\n    - name: sleepy\n      image: \"busybox:latest\"\n      command: [\"sleep\", \"120\"]\n      resources:\n        limits:\n          nvidia.com/gpu-4gb: 1 #\n```", "```py\nkubectl label nodes <node-names> \"nos.nebuly.com/gpu-partitioning=mps\"\n```"]