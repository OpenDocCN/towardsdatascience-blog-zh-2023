- en: On AB tests and Carryover Effect
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/on-ab-tests-and-carryover-effect-43668dbd52e2?source=collection_archive---------11-----------------------#2023-05-23](https://towardsdatascience.com/on-ab-tests-and-carryover-effect-43668dbd52e2?source=collection_archive---------11-----------------------#2023-05-23)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/fc3f7a565f50700b922874649897f0db.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Ron Hansen](https://unsplash.com/@ron_hansen?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/@tearth?source=post_page-----43668dbd52e2--------------------------------)[![Denis
    Vorotyntsev](../Images/046fc24b4accb4ca2a60aff6c46083f3.png)](https://medium.com/@tearth?source=post_page-----43668dbd52e2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----43668dbd52e2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----43668dbd52e2--------------------------------)
    [Denis Vorotyntsev](https://medium.com/@tearth?source=post_page-----43668dbd52e2--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F12556e7f5251&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-ab-tests-and-carryover-effect-43668dbd52e2&user=Denis+Vorotyntsev&userId=12556e7f5251&source=post_page-12556e7f5251----43668dbd52e2---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----43668dbd52e2--------------------------------)
    ·7 min read·May 23, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F43668dbd52e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-ab-tests-and-carryover-effect-43668dbd52e2&user=Denis+Vorotyntsev&userId=12556e7f5251&source=-----43668dbd52e2---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F43668dbd52e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-ab-tests-and-carryover-effect-43668dbd52e2&source=-----43668dbd52e2---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: In the complex world of data-driven decision-making, A/B testing stands out
    as a powerful tool, helping businesses optimize their strategies and improve user
    experiences. But what happens when the effects of one test bleed into the next,
    muddying the waters and skewing the results?
  prefs: []
  type: TYPE_NORMAL
- en: This phenomenon, known as the “carryover effect”, can pose significant challenges
    to understanding the real impact of the changes being tested. In this article,
    we delve into the nuances of A/B testing and the carryover effect, discussing
    strategies to manage this phenomenon effectively. We’ll explore the mechanisms
    of user grouping, the technique of “bucketing”, and how to identify and address
    the carryover effect to ensure that your A/B tests deliver reliable, actionable
    results.
  prefs: []
  type: TYPE_NORMAL
- en: Users and Buckets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AB testing is a foundational method for comparing two versions of a feature,
    often used to determine which performs better. To execute these tests, we often
    group users into two cohorts — the control group and the treatment group, based
    on user-ids. For simplicity, we could assign all “even” users to control and all
    “odd” users to treatment.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/77eae2204d6cd3a1a212b0255ef966b6.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Straightforward AB test setup: all users are split into control and treatment*'
  prefs: []
  type: TYPE_NORMAL
- en: The initial step involves estimating the sample size — the number of users or
    events we need to collect based on our selected metrics, such as click-through
    rate or average revenue per user. These estimates consider the variance (based
    on historical observations of these metrics) and expected effect (based on the
    offline results of the proposed model). After gathering sufficient data, we dive
    into statistical analysis, like using a t-test to compare the average revenue
    in control and treatment groups to determine the better-performing model.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, this approach faces several hurdles:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Simultaneous Multiple Testing**: Launching multiple tests concurrently becomes
    a challenge. For instance, if a new model necessitates a test, there’s no residual
    traffic to accommodate this. The solution would be halting the current AB test
    and splitting users into three groups. But what if we don’t know the number of
    variants we’ll run in the future?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Scalability Issues**: When dealing with expansive user bases, scaling the
    analysis becomes a daunting task. Calculating statistics over the last few days
    of AB tests, even with caching results at user-level, can be taxing, especially
    when dealing with copious amounts of users.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To circumnavigate these problems, we utilize a technique called “bucketing”.
  prefs: []
  type: TYPE_NORMAL
- en: The Bucketing Method
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Bucketing groups several users into a single unit referred to as a “bucket”.
    You can consider this bucket as a “meta-user”. To determine the bucket id, we
    use this formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Here, the ***salt*** is a fixed random string, while the ***number_of_buckets***
    is a predefined parameter of the system. Depending on the system design, the bucket
    id can be calculated in real-time (when a user visits the website) or calculated
    once when a user visits a website and stored in a key-value storage.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f4a893a5de0d595cb78e6a4d1f2c21f0.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Bucketing idea: users are split into buckets using the formula above. Treatment
    is applied on the user level, but the analysis is done on the bucket level.*'
  prefs: []
  type: TYPE_NORMAL
- en: Prior to initiating the AB test, we estimate how many buckets we’ll allocate
    to control and treatment. For instance, if the total number of buckets equals
    1000, we assign users in buckets 0–99 to the control model and users in buckets
    100–199 to the treatment model. This gives us 10% of traffic for both models.
  prefs: []
  type: TYPE_NORMAL
- en: Bucketing allows us to analyze results at the bucket level rather than the user
    level, enabling us to cache metrics at the bucket level, which eliminates the
    need for heavy recalculations.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the Carryover Effect
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Imagine a scenario where you are working on a substantial e-commerce website,
    designing a new recommendation model using high-level neural networks. This model
    includes an innovative feature, an OpenAI GPT3 API call, to generate item title
    embeddings. Offline results from this model show a significant boost in performance,
    prompting the decision to test it online.
  prefs: []
  type: TYPE_NORMAL
- en: The AB test is structured to span a week, designating 10% of the website’s traffic
    for control and 10% for treatment. The objective is to compare the number of clicks
    between both groups to identify which model performs better.
  prefs: []
  type: TYPE_NORMAL
- en: However, a few hours post the launch of the AB test, there is an alarming dip
    in all metrics. A deep dive into the data reveals that the loading time of the
    pages has increased significantly due to the complex model. This was an unforeseen
    issue, not encountered during offline testing, and not accounted for during the
    online test.
  prefs: []
  type: TYPE_NORMAL
- en: In response to the slow loading times, users assigned to the treatment group
    become frustrated, leading some to reduce their usage or churn entirely. This
    unfortunate event disrupts the balance of user distribution across buckets, an
    aspect not considered in the new AB test.
  prefs: []
  type: TYPE_NORMAL
- en: This persistent disbalance, a direct fallout of the initial test, is known as
    the “carryover effect”. It occurs when the same group of users consistently experiences
    changes across multiple tests. In essence, the buckets, owing to the consistent
    salt or seed used for bucket assignment, “remember” previous AB tests, affecting
    the results of subsequent tests.
  prefs: []
  type: TYPE_NORMAL
- en: The carryover effect becomes particularly evident when users’ behavior is altered
    due to previous treatments. For instance, if a new functionality being tested
    requires a learning curve for users, the treatment group members may adapt faster
    due to their early exposure, gaining an edge over users in other groups.
  prefs: []
  type: TYPE_NORMAL
- en: In large-scale and mature systems, where a minute 1% change could signify millions
    in revenue, this effect gains significant importance. Data scientists and machine
    learning engineers often strive for even a 0.1% lift in metrics. However, even
    a minor carryover effect can invalidate multiple AB tests, potentially leading
    to a sub-optimal model being adopted or a superior model being discarded due to
    biased AB bucketing.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting the Problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To identify this problem, data scientists should periodically conduct AA tests.
    A well-designed AB test system should yield a uniform distribution of p-values
    in AA tests. A non-uniform p-value histogram in an AA test suggests an imbalance
    in buckets, potentially resulting from a myriad of factors, including the carryover
    effect.
  prefs: []
  type: TYPE_NORMAL
- en: Strategies to Counter the Problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Shuffling All Users
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The quickest and simplest solution to evade the bucket memory issue is periodically
    changing the salt. This ensures users are randomly distributed across buckets
    after every reshuffle, breaking the connection with the previous split. However,
    the method is impractical during ongoing AB tests as it disturbs the user distribution
    between control and treatment, invalidating the i.i.d. premise of AB test and
    thus invalidating the results.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1bc700fc490fbdd6a07c89a94795cae2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Simple shuffling: changing salt would lead to shuffling users across buckets'
  prefs: []
  type: TYPE_NORMAL
- en: This method also poses challenges when multiple AB tests are run simultaneously,
    coordinating the cessation of all tests can be difficult, and any delays can be
    costly. Also, long-lasting negative tests can’t be stopped without losing of AB
    test’s progress.
  prefs: []
  type: TYPE_NORMAL
- en: Shuffling Non-AB Tested Users
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An alternative is to reshuffle users not involved in any AB tests. With this
    approach, after each completed AB test, users who aren’t part of any tests are
    shuffled across available buckets.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7172bb1363805085813c3e4383904ac0.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Shuffling non-ab-tested users: after the end of Test 2, users from buckets
    2, 3, 4, and 5 were shuffled. Users in Test 1 remained untouched. After Test 1
    was stopped, users from all buckets were shuffled.*'
  prefs: []
  type: TYPE_NORMAL
- en: Although this approach doesn’t require halting all AB tests, it’s more complex
    to implement. We need to track users in experiments and store the user-id to bucket
    mapping, frequently updating it — a task that can be tricky in large systems.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Navigating the complexities of AB testing, from setting up users and buckets
    to managing the carryover effect, requires careful planning and strategic handling.
    Understanding these intricacies can help ensure your testing provides valuable,
    actionable insights and contributes positively to your ongoing development efforts.
    By adopting efficient solutions to overcome potential hurdles, you can streamline
    your testing process, improve user experiences, and ultimately optimize your product’s
    success.
  prefs: []
  type: TYPE_NORMAL
- en: Further Reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To deepen your understanding of the carryover effect and other nuances of AB
    testing, here are some valuable resources for further reading:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Controlled experiments on the web: Survey and practical guide](https://www.researchgate.net/publication/220451900_Controlled_experiments_on_the_web_Survey_and_practical_guide)
    gives a detailed look into the design of bucketing, a pivotal element in carrying
    out controlled web experiments.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Separation strategies for three pitfalls in A/B testing](https://www.ueo-workshop.com/wp-content/uploads/2014/04/Separation-strategies-for-three-pitfalls-in-AB-testing_withacknowledgments.pdf)
    gives a detailed look into the design of bucketing, a pivotal element in carrying
    out controlled web experiments.'
  prefs: []
  type: TYPE_NORMAL
- en: '[How to interpret a p-value histogram](http://varianceexplained.org/statistics/interpreting-pvalue-histogram/)
    presents an in-depth look at the interpretation of p-value histograms, a critical
    part of AA tests. It can aid in detecting the carryover effect, giving readers
    a stronger grasp of the statistical aspects of AB testing.'
  prefs: []
  type: TYPE_NORMAL
