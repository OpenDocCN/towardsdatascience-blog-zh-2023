- en: 'XGBoost: Theory and Hyperparameter Tuning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/xgboost-theory-and-hyperparameter-tuning-bc4068aba95e?source=collection_archive---------4-----------------------#2023-02-16](https://towardsdatascience.com/xgboost-theory-and-hyperparameter-tuning-bc4068aba95e?source=collection_archive---------4-----------------------#2023-02-16)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A complete guide with examples in Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://jorgemartinlasaosa.medium.com/?source=post_page-----bc4068aba95e--------------------------------)[![Jorge
    Martín Lasaosa](../Images/21b4e500b7d14204ea76f579c3e2433f.png)](https://jorgemartinlasaosa.medium.com/?source=post_page-----bc4068aba95e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bc4068aba95e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bc4068aba95e--------------------------------)
    [Jorge Martín Lasaosa](https://jorgemartinlasaosa.medium.com/?source=post_page-----bc4068aba95e--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdd62b41dbbf5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fxgboost-theory-and-hyperparameter-tuning-bc4068aba95e&user=Jorge+Mart%C3%ADn+Lasaosa&userId=dd62b41dbbf5&source=post_page-dd62b41dbbf5----bc4068aba95e---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bc4068aba95e--------------------------------)
    ·17 min read·Feb 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbc4068aba95e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fxgboost-theory-and-hyperparameter-tuning-bc4068aba95e&user=Jorge+Mart%C3%ADn+Lasaosa&userId=dd62b41dbbf5&source=-----bc4068aba95e---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbc4068aba95e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fxgboost-theory-and-hyperparameter-tuning-bc4068aba95e&source=-----bc4068aba95e---------------------bookmark_footer-----------)![](../Images/c1e8bc4dcd14576319bd1f517bfeaa2b.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Joanne Francis](https://unsplash.com/@nipawinnews?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a few months, I will have been working as a Data Scientist for 3 years. I
    know it is not a long career yet, but together with my academic experience, I
    have been able to work on several machine learning projects for different sectors
    (energy, customer experience…). All of them were fed by *tabular data,* which
    means structured data (organised in rows and columns). In contrast, there are
    projects fed by unstructured data such as images or text which are more related
    to machine learning fields such as Computer Vision or Natural Language Processing
    (NLP).
  prefs: []
  type: TYPE_NORMAL
- en: Based on my experience, XGBoost *usually* performs well with *tabular data*
    projects. Although the No Free Lunch Theorem [1] states that any two algorithms
    are equivalent when their performances are averaged across all possible problems,
    on Bojan Tunguz’s Twitter [2] you can read frequent discussions with other professionals
    about why tree-based models (and specially XGBoost) are often the best candidates
    for tackling *tabular data* projects, even with the growing research into the
    use of Deep Learning techniques for this type of data. [3]
  prefs: []
  type: TYPE_NORMAL
- en: Also, it is quite funny to see how a Kaggle Grandmaster [4] jokes about being
    an XGBoost evangelist.
  prefs: []
  type: TYPE_NORMAL
