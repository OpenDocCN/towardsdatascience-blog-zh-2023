- en: How To Prepare Your Data For Visualizations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-prepare-your-data-for-visualizations-94e33473f70b?source=collection_archive---------2-----------------------#2023-06-26](https://towardsdatascience.com/how-to-prepare-your-data-for-visualizations-94e33473f70b?source=collection_archive---------2-----------------------#2023-06-26)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Without using Tableau Prep or Alteryx
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@stephanie_lo?source=post_page-----94e33473f70b--------------------------------)[![Stephanie
    Lo](../Images/2b7787607352815394cf8b734a9f0f02.png)](https://medium.com/@stephanie_lo?source=post_page-----94e33473f70b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----94e33473f70b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----94e33473f70b--------------------------------)
    [Stephanie Lo](https://medium.com/@stephanie_lo?source=post_page-----94e33473f70b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff4309a31ceee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-prepare-your-data-for-visualizations-94e33473f70b&user=Stephanie+Lo&userId=f4309a31ceee&source=post_page-f4309a31ceee----94e33473f70b---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----94e33473f70b--------------------------------)
    ·8 min read·Jun 26, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F94e33473f70b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-prepare-your-data-for-visualizations-94e33473f70b&user=Stephanie+Lo&userId=f4309a31ceee&source=-----94e33473f70b---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F94e33473f70b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-prepare-your-data-for-visualizations-94e33473f70b&source=-----94e33473f70b---------------------bookmark_footer-----------)![](../Images/3adf0a964e9289b69e1d09c3fa24aad7.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Robert Katzki](https://unsplash.com/@ro_ka?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Want to get started on your next Data Visualization project? Start off by getting
    friendly with Data Cleaning. Data Cleaning is a vital step in any data pipeline,
    transforming raw, ‘dirty’ data inputs into those that are more reliable, relevant
    and concise. Data preparation tools such as Tableau Prep or Alteryx were created
    for this purpose, but why spend money on these services when you can accomplish
    the task with open-source programming languages like Python? This article will
    guide you through the process of getting data ready for visualization using Python
    scripts, offering a more cost-effective alternative to data preparation tools.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Throughout this article we will be focusing on getting data Tableau ready
    for data visualizations, but the main concepts equally apply to other business
    intelligence tools.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I get it. Data cleaning just seems like **another** step in the already lengthy
    process of bringing your visualizations or dashboards to life. But it’s crucial,
    and can be enjoyable. It’s how you get comfortable with your data set, by getting
    an in-depth look at the data that you have and don’t have, and the consequential
    decisions you have to take to approach your end analysis goals.
  prefs: []
  type: TYPE_NORMAL
- en: 'Whilst Tableau is a versatile data visualization tool, sometimes the route
    to get to your answer isn’t clear. This is where processing your dataset before
    loading it into Tableau may be your biggest secret helper. Let’s explore some
    key reasons why data cleaning is beneficial before integrating it with Tableau:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Eliminates irrelevant information:** Raw Data often contains unnecessary
    or repeating information that can clutter your analysis. By cleaning the data,
    you can remove the waste and concentrate your visualizations on the most relevant
    data features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Simplifies data transformation**: If you have a clear vision of the visualization
    you intend to produce, performing these pre-transformations before loading the
    data into Tableau can streamline the process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Easier transferability within teams**: When data sources are regularly updated,
    new additions can introduce inconsistencies and potentially break Tableau. With
    Python Scripts and code description (more formally known as markdown documentation),
    you can effectively share and empower others to understand your code and troubleshoot
    any programming issues that may arise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time-saving for data refreshes:** Data that needs to be refreshed regularly
    can benefit from leveraging the [Hyper API](https://tableau.github.io/hyper-db/docs/)
    — an application that produces Hyper file formats specific to Tableau and allows
    for automated data extract uploads whilst making the data refresh process more
    efficient.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we’ve covered some advantages of preparing your data, let’s put this
    into practice by creating a simple data pipeline. We’ll explore how data cleaning
    and processing can be integrated into a workflow and help make your visualizations
    easier to manage.
  prefs: []
  type: TYPE_NORMAL
- en: '**Creating a data pipeline using Python Scripts**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/af05fd654844ba80dc4efc209b3ddb1a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'The journey our data will take is a pretty simple one: Data Cleaning, Data
    Processing for Visuals and transforming them into Tableau-Ready Hyper Files for
    seamless integration.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A final note before delving into our working example is that for the Hyper
    file conversion you will need to download the `pantab` library. This library simplifies
    the conversion of Pandas Dataframes into Tableau .hyper extracts. You can can
    easily complete this by using the following code in the terminal of your chosen
    environment (For those less familiar with environments [this is a great primer
    article](/a-data-scientists-guide-to-python-virtual-environments-858841922f14)
    on what they are and how to install certain libraries):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**Tutorial: Data Preparation with Python exploring Electric Vehicles Licenses
    in Canada**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The data visualizations we will be aiming on producing focus on the popularity
    of different electric automakers and models based on Government available data
    from Statistics Canada.
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s important to note that this builds upon a dataset previously explored
    in my prior article: [Electric Vehicle Analysis with R](https://medium.com/towards-data-science/the-starter-guide-for-transitioning-your-python-projects-to-r-8de4122b04ad).
    If you’re interested in understanding the initial exploration of the data set
    and the rationale behind the decisions made, please refer to it for greater detail.
    This tutorial focuses on building out the Python scripts where at each step following
    the initial inputs, we will be saving the output of the each Python script into
    their respective folders, as outlined below:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/8d3dd5b6a797fd46c82484c68f7176b6.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: The folder process ensures that the pipeline is well organized and that we are
    able to keep a record of each output in the project. Let’s jump into building
    out our first Python script!
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Cleaning**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The initial script in our pipeline follows the fundamental steps of data cleaning,
    which for this dataset includes: keeping/renaming relevant columns, removing nulls
    and/or duplicates, and making data values consistent.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can start by specifying our input file locations and the destination for
    the output files. This step is important since it allows us to organize different
    versions of the files in the same location, in this case we are modifying the
    file outputs on a monthly basis, so each file output is separated by month as
    indicated at the end of the file name `2023_04`:'
  prefs: []
  type: TYPE_NORMAL
- en: The following code reads the original .csv inputs and defines what columns we
    want to keep. In this case, we are interested in preserving information related
    to the type of models bought and disregard columns pertaining to the car dealerships
    or any other irrelevant columns.
  prefs: []
  type: TYPE_NORMAL
- en: Now we can shorten the column names, removing leading or trailing white spaces,
    and add in underscores for easier comprehension.
  prefs: []
  type: TYPE_NORMAL
- en: Next, after having checked that there are only a few null entries in the dataset,
    we will remove the null data with the `.dropna` function. At this point, you would
    also want to remove duplicates but in the case of this particular dataset we will
    not. This is because there is a substantial amount of repeated information, and
    in the absence of row identifiers removing duplicates would result in data loss.
  prefs: []
  type: TYPE_NORMAL
- en: The last final step is to save our data as a .csv file to an appropriate folder
    location which would be placed in the `clean_data` folder of our shared directory.
  prefs: []
  type: TYPE_NORMAL
- en: Notice how we referenced the file using `__file__`, and specified the file directory
    by using bash commands where `../` indicates the previous folder. This concludes
    our data cleaning script. Now let’s proceed to the data processing phase!
  prefs: []
  type: TYPE_NORMAL
- en: Access to complete working code and assembled scripts can be found in my Github
    repository [here](https://github.com/stephrlo/Pipeline_for_Data_Visualization).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Data Processing for Visualizations**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s revisit the objectives of the visualizations we are trying to achieve,
    which aim to highlight the changes in popularity of electric vehicles registered.
    To effectively showcase this, we want our final Tableau-ready dataset to include
    the following features, which we will code out:'
  prefs: []
  type: TYPE_NORMAL
- en: Absolute counts of vehicles by year
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Proportional counts of vehicles by year
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Largest increases and decreases of vehicles registered
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ranking of vehicles registered
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Previous ranking of vehicles registered for comparison
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on the visuals you aim to produce, the creation of your ideal columns
    may be an iterative process. In my case, I included the last column after having
    built out my visualizations since I knew I wanted to provide the viewer with a
    visual comparison of ranking differences so the Python script was adjusted accordingly.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'For the following code we will focus on the model aggregated data set since
    the other dataset for brands is very similar. Let’s first define our `inputfile`
    and `outputfile` :'
  prefs: []
  type: TYPE_NORMAL
- en: Notice how we referred to the `inputfile` from the `clean_data` folder, which
    was the output of our data cleaning script.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code below reads in the data, and creates a data frame of the aggregated
    counts by `Vehicle_Make_and_Model` and `Calendar_Year` :'
  prefs: []
  type: TYPE_NORMAL
- en: The `pivot` function performs similarly to the pivot table function in Excel
    where it takes each of the values in `Calendar_Year` as the column input.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then the script uses a For Loop to create `per_1K` inputs. This calculates
    the proportions of each model to be able to compare each model on the same scale
    and creates a column for each year:'
  prefs: []
  type: TYPE_NORMAL
- en: From calculating the proportions by year we can calculate the largest increases
    and decreases of each model from the start of the dataset in 2019 until the last
    full year of data in 2022.
  prefs: []
  type: TYPE_NORMAL
- en: Here, the `melt` function is used to re-pivot the separated `per_1K` columns
    by year back into rows, so that we just have one column for `per_1K` and their
    associated values.
  prefs: []
  type: TYPE_NORMAL
- en: The below code allows us to join our absolute counts and the other calculations
    we just created.
  prefs: []
  type: TYPE_NORMAL
- en: We can now create the `rank` column using license counts and sort these values
    by `Vehicle_Make_and_Model` and `Calendar_Year`.
  prefs: []
  type: TYPE_NORMAL
- en: Last column to create is the `previous_rank` column by using the `shift` function.
  prefs: []
  type: TYPE_NORMAL
- en: Finally we are able to save the output to the `clean_model` folder path in our
    pipeline, supplying us withone visual ready data set.
  prefs: []
  type: TYPE_NORMAL
- en: As a friendly reminder, the full python script code, including that for the
    `clean_brand` processed data set can be found on my GitHub repository [here](https://github.com/stephrlo/Pipeline_for_Data_Visualization).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Transforming your final data files into .hyper file formats**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The final step in our pipeline is relatively simple since all we have left to
    do is to convert the .csv processed files we created into .hyper file formats.
    This should be relatively easy as long as you’ve downloaded the `pantab` library
    as referenced earlier.
  prefs: []
  type: TYPE_NORMAL
- en: It’s worth a mention that in Tableau, connected data can either have a live
    connection or be extracted. A live connection ensures that there is a continuous
    flow of data, with updates from the source reflected almost immediately in Tableau.
    Extracted data involves Tableau creating a local file with a .hyper file extension
    which contains a copy of the data (Detailed description of data sources can be
    found [here](https://www.flerlagetwins.com/2022/01/data-sources-1.html)). Its
    main advantage is its fast loading capability where Tableau can access and present
    the information more efficiently which is particularly beneficial with large datasets.
  prefs: []
  type: TYPE_NORMAL
- en: The code for the hyper file conversion scripts start with loading in `pandas`
    and `pantab` packages, followed by reading in the `cleaned_model` data set that
    you would need for Tableau.
  prefs: []
  type: TYPE_NORMAL
- en: The last line of code uses the `frame_to_hyper` function that produces the .hyper
    files and saves this to the `hyper` folder.
  prefs: []
  type: TYPE_NORMAL
- en: As a final step, we can easily load .hyper file formats into Tableau by opening
    a new workbook, and in the `select a file` section you can choose the file of
    your choice to load by selecting `more`. When we load in our `ev_vehicle_models.hyper`
    file it should show as a Tableau Extract such as in the screenshot below where
    your data is ready to build your visuals upon!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bc18e6c9cf681746035b80323cb5483e.png)'
  prefs: []
  type: TYPE_IMG
- en: Closing Thoughts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By incorporating thoughtful planning into your visualizations, you can simplify
    the maintenance of your dashboards through the creation of a straightforward data
    pipeline. Don’t worry if you lack the resources; open-source coding programs like
    Python offer powerful capabilities. As a final, friendly reminder, for access
    to the Python scripts please check out my GitHub repository [here](https://github.com/stephrlo/Pipeline_for_Data_Visualization).
  prefs: []
  type: TYPE_NORMAL
- en: All images unless otherwise noted are by the author.
  prefs: []
  type: TYPE_NORMAL
- en: '**References**'
  prefs: []
  type: TYPE_NORMAL
- en: Salesforce, [Tableau Hyper API](https://tableau.github.io/hyper-db/docs/), 2023
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: R.Vickery , [A Data Scientists Guide to Python Virtual Environments](/a-data-scientists-guide-to-python-virtual-environments-858841922f14),
    Jan 2021
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'K.Flerlage, [Tableau Data Sources Part 1: Data Source Types](https://www.flerlagetwins.com/2022/01/data-sources-1.html),
    Jul 2022'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
