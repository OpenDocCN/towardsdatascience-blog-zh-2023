- en: CI/CD for Multi-Model Endpoints in AWS
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CI/CD 在 AWS 的多模型端点
- en: 原文：[https://towardsdatascience.com/ci-cd-for-multi-model-endpoints-in-aws-18bf939e0a48?source=collection_archive---------7-----------------------#2023-06-22](https://towardsdatascience.com/ci-cd-for-multi-model-endpoints-in-aws-18bf939e0a48?source=collection_archive---------7-----------------------#2023-06-22)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/ci-cd-for-multi-model-endpoints-in-aws-18bf939e0a48?source=collection_archive---------7-----------------------#2023-06-22](https://towardsdatascience.com/ci-cd-for-multi-model-endpoints-in-aws-18bf939e0a48?source=collection_archive---------7-----------------------#2023-06-22)
- en: A simple, flexible alternative for sustainable ML solutions
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个简单、灵活的可持续机器学习解决方案的替代方案
- en: '[](https://medium.com/@andrewcharabin?source=post_page-----18bf939e0a48--------------------------------)[![Andrew
    Charabin](../Images/8cfe2657a9cd16c3ce30b98e3c9e9945.png)](https://medium.com/@andrewcharabin?source=post_page-----18bf939e0a48--------------------------------)[](https://towardsdatascience.com/?source=post_page-----18bf939e0a48--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----18bf939e0a48--------------------------------)
    [Andrew Charabin](https://medium.com/@andrewcharabin?source=post_page-----18bf939e0a48--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@andrewcharabin?source=post_page-----18bf939e0a48--------------------------------)[![Andrew
    Charabin](../Images/8cfe2657a9cd16c3ce30b98e3c9e9945.png)](https://medium.com/@andrewcharabin?source=post_page-----18bf939e0a48--------------------------------)[](https://towardsdatascience.com/?source=post_page-----18bf939e0a48--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----18bf939e0a48--------------------------------)
    [Andrew Charabin](https://medium.com/@andrewcharabin?source=post_page-----18bf939e0a48--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff282e085f18e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fci-cd-for-multi-model-endpoints-in-aws-18bf939e0a48&user=Andrew+Charabin&userId=f282e085f18e&source=post_page-f282e085f18e----18bf939e0a48---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----18bf939e0a48--------------------------------)
    ·14 min read·Jun 22, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F18bf939e0a48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fci-cd-for-multi-model-endpoints-in-aws-18bf939e0a48&user=Andrew+Charabin&userId=f282e085f18e&source=-----18bf939e0a48---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff282e085f18e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fci-cd-for-multi-model-endpoints-in-aws-18bf939e0a48&user=Andrew+Charabin&userId=f282e085f18e&source=post_page-f282e085f18e----18bf939e0a48---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----18bf939e0a48--------------------------------)
    ·14分钟阅读·2023年6月22日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F18bf939e0a48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fci-cd-for-multi-model-endpoints-in-aws-18bf939e0a48&user=Andrew+Charabin&userId=f282e085f18e&source=-----18bf939e0a48---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F18bf939e0a48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fci-cd-for-multi-model-endpoints-in-aws-18bf939e0a48&source=-----18bf939e0a48---------------------bookmark_footer-----------)![](../Images/c1424ad7b2588399204bb9dd6c2e504c.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F18bf939e0a48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fci-cd-for-multi-model-endpoints-in-aws-18bf939e0a48&source=-----18bf939e0a48---------------------bookmark_footer-----------)![](../Images/c1424ad7b2588399204bb9dd6c2e504c.png)'
- en: Image via VectorStock under license to Andrew Charabin
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于 VectorStock，授权给**Andrew Charabin**
- en: Automating the retraining and deployment of production machine learning solutions
    is a pivotal step to ensure models account for [covariate shift](https://www.seldon.io/what-is-covariate-shift#:~:text=It%20is%20when%20the%20distribution,issue%20encountered%20in%20machine%20learning.)
    while limiting error-prone and unnecessary human effort.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化生产机器学习解决方案的再培训和部署是确保模型考虑到[covariate shift](https://www.seldon.io/what-is-covariate-shift#:~:text=It%20is%20when%20the%20distribution,issue%20encountered%20in%20machine%20learning.)的关键步骤，同时减少出错和不必要的人力投入。
- en: For models deployed using the AWS stack and particularly SageMaker, AWS offers
    a standard CI/CD solution using [SageMaker Pipelines](https://aws.amazon.com/sagemaker/pipelines/)
    to automate retraining/deployment, and the [SageMaker Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html)
    to track lineage of a model.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用 AWS 堆栈和特别是 SageMaker 部署的模型，AWS 提供了一种标准 CI/CD 解决方案，使用 [SageMaker Pipelines](https://aws.amazon.com/sagemaker/pipelines/)
    来自动化重新训练/部署，以及 [SageMaker 模型注册表](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html)
    来跟踪模型的传承。
- en: 'While the standard solution works well for standard cases, there are several
    limitations for more intricate cases:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然标准解决方案在标准情况下效果良好，但在更复杂的情况下存在若干限制：
- en: Input data needs to be sourced from AWS s3.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入数据需要从 AWS s3 获取。
- en: Difficulty setting up dynamic warm start hyperparameter tuning.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置动态预热超参数调整的难度。
- en: Additional model training steps are required to train multiple models.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 需要额外的模型训练步骤来训练多个模型。
- en: Long bootstrapping time to execute a pipeline.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行管道的启动时间较长。
- en: Limited debugging tools.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调试工具有限。
- en: 'Fortunately, AWS has launched new functionality that can be used to build a
    CI/CD pipeline that overcomes these limitations. The following functionality can
    be accessed within [SageMaker Studio](https://aws.amazon.com/sagemaker/studio/),
    AWS’ integrated development environment for machine learning:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，AWS 推出了可以用来构建克服这些限制的 CI/CD 管道的新功能。以下功能可以在 [SageMaker Studio](https://aws.amazon.com/sagemaker/studio/)
    中访问，这是 AWS 的集成开发环境，用于机器学习：
- en: '[Use a Custom SageMaker Image](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-byoi-launch.html)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用自定义 SageMaker 图像](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-byoi-launch.html)'
- en: '[Git/SageMaker Studio Integration](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-tasks-git.html)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Git/SageMaker Studio 集成](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-tasks-git.html)'
- en: '[Warm Start Hyperparameter Tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-warm-start.html)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[预热超参数调整](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-warm-start.html)'
- en: '[SageMaker Studio Notebook Jobs](https://aws.amazon.com/blogs/machine-learning/operationalize-your-amazon-sagemaker-studio-notebooks-as-scheduled-notebook-jobs/)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SageMaker Studio 笔记本作业](https://aws.amazon.com/blogs/machine-learning/operationalize-your-amazon-sagemaker-studio-notebooks-as-scheduled-notebook-jobs/)'
- en: '[Cross-Account Model Registry](https://aws.amazon.com/blogs/machine-learning/build-a-cross-account-mlops-workflow-using-the-amazon-sagemaker-model-registry/)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[跨账户模型注册表](https://aws.amazon.com/blogs/machine-learning/build-a-cross-account-mlops-workflow-using-the-amazon-sagemaker-model-registry/)'
- en: '***The purpose of this article…***'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '***本文的目的…***'
- en: is to go over key details of an alternative CI/CD solution via the AWS cloud
    that provides more flexibility and faster speed to market.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 目的是通过 AWS 云探讨一种替代 CI/CD 解决方案的关键细节，该方案提供了更多灵活性和更快的市场速度。
- en: '***Solution Component Overview:***'
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***解决方案组件概述：***'
- en: ''
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*1\. Custom SageMaker Studio image for PostgreSQL querying*'
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*1\. 自定义 SageMaker Studio 图像用于 PostgreSQL 查询*'
- en: ''
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*2\. Dynamic warm start hyperparameter tuning*'
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*2\. 动态预热超参数调整*'
- en: ''
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*3\. Register multiple models to the Model Registry in a single interactive
    python notebook*'
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*3\. 在单个交互式 Python 笔记本中注册多个模型到模型注册表*'
- en: ''
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*4\. Refresh a multi-model endpoint with new models*'
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*4\. 用新模型刷新多模型端点*'
- en: ''
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*5\. Schedule retrain/redeploy notebooks to run on a set cadence*'
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*5\. 计划重新训练/重新部署笔记本以在设定的周期上运行*'
- en: Let’s get started.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 开始吧。
- en: 1\. Custom SageMaker Studio image *for PostgreSQL querying*
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 自定义 SageMaker Studio 图像 *用于 PostgreSQL 查询*
- en: While SageMaker pipelines allows input data from s3, what if new input data
    resides in a data warehouse like AWS Redshift or Google BigQuery? Of course, an
    [ETL](https://www.ibm.com/topics/etl) or comparable process can be used to move
    data to s3 in batches, but that simply adds unnecessary complexity/rigidity in
    comparison to querying the data directly from the data warehouse in the pipeline.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 SageMaker 管道允许从 s3 获取输入数据，但如果新输入数据位于数据仓库中，如 AWS Redshift 或 Google BigQuery
    呢？当然，可以使用 [ETL](https://www.ibm.com/topics/etl) 或类似过程将数据批量移动到 s3，但这与直接从数据仓库查询数据相比，增加了不必要的复杂性/僵化。
- en: SageMaker Studio provides several default images to initialize an environment,
    one example being ‘Data Science’ which includes common packages like numpy and
    pandas. However, to connect to a PostgreSQL database in Python, a driver or adapter
    is required. [Psycopg2](https://pypi.org/project/psycopg2/) is the most popular
    PostgreSQL database adapter for the Python programming language. Fortunately,
    custom images can be used to initialize a Studio environment although there are
    specific requirements. I’ve prepackaged a Docker image that meets these requirements
    and build on top of the Python Julia-1.5.2 image by adding the psycopg2 driver.
    The image can be found in [this](https://github.com/acharabin/SageMaker-Studio-Image-With-Psycopg2)
    git repository. The steps outlined [here](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-byoi.html)
    can then be used to make the image accessible in a Studio domain.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Studio提供了几种默认镜像来初始化环境，其中一个例子是包含常用包如numpy和pandas的‘Data Science’镜像。然而，要在Python中连接到PostgreSQL数据库，需要一个驱动程序或适配器。[Psycopg2](https://pypi.org/project/psycopg2/)是Python编程语言中最流行的PostgreSQL数据库适配器。幸运的是，可以使用自定义镜像来初始化Studio环境，尽管有特定的要求。我已经预打包了一个满足这些要求的Docker镜像，并在Python
    Julia-1.5.2镜像基础上添加了psycopg2驱动程序。该镜像可以在[这个](https://github.com/acharabin/SageMaker-Studio-Image-With-Psycopg2)git仓库中找到。然后，可以使用[这里](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-byoi.html)概述的步骤使镜像在Studio域中可用。
- en: 2\. Dynamic warm start hyperparameter tuning
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 动态预热启动超参数调优
- en: Model retraining is different in nature than initial model training. It isn’t
    practical to invest the same amount of resources to search for the best model
    hyperparameters and over the same large search space when retraining a model.
    This is especially true when only minor adjustments to the best hyperparameters
    are expected from the last production model.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 模型重新训练在性质上与初始模型训练不同。在重新训练模型时，投资相同数量的资源来搜索最佳模型超参数以及相同的大范围搜索空间是不切实际的。特别是当仅期望对上一生产模型的最佳超参数进行微调时尤其如此。
- en: 'For this reason, the hyperparameter tuning solution recommended for CI/CD in
    this article doesn’t try to blitz retuning with K fold cross-validation, warm
    pools, etc. All that can work great for an initial model training. For retraining,
    however, we want to start with what worked great in production already, and make
    small adjustments to account for newly available data. As such, using warm start
    hyperparameter tuning is the perfect solution. Going further, a dynamic warm start
    tuning system can be created that uses the latest production tuning job as the
    parent. The solution can look as follows for an example XGBoost baysian tuning
    job:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，本文推荐的CI/CD超参数调优解决方案不会尝试通过K折交叉验证、预热池等方式快速重新调优。这些方法对于初始模型训练非常有效。然而，对于重新训练，我们希望从生产中已经有效的地方开始，并对新获取的数据进行小幅调整。因此，使用动态预热启动超参数调优是完美的解决方案。进一步地，可以创建一个动态预热启动调优系统，使用最新的生产调优作业作为父作业。以下是一个示例XGBoost贝叶斯调优作业的解决方案：
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Tuning job history will be saved in a log file in the base directory, with
    example output as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 调优作业历史将保存在基础目录中的日志文件中，示例输出如下：
- en: '![](../Images/329069d473afac7188601c22592ee081.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/329069d473afac7188601c22592ee081.png)'
- en: Chart by author
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图表
- en: The date/time stamp as well as the name of the tuning job and metadata are stored
    in .csv format, with new tuning jobs being appended to the file.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 日期/时间戳、调优作业名称以及元数据以.csv格式存储，新调优作业会追加到文件中。
- en: 'The system will dynamically warm start using the latest tuning job that meets
    required conditions. In this example the conditions are noted in the following
    line of code:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 系统将动态地使用满足要求条件的最新调优作业进行预热启动。在这个例子中，条件在以下代码行中注明：
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Because we’ll want to test the pipeline works, a testing=True run option is
    available that forces only one hyperparameter tuning job. A condition is added
    to only consider jobs with more than 1 tuned model as parents, given these are
    non-testing. Furthermore, the tuning job log file can be used across different
    models, as one could in theory use a parent job across models. In this case the
    model is tracked with the ‘metric’ field, and eligible tuning jobs are filtered
    to match the metric in the current training instance.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们需要测试管道的工作情况，所以提供了`testing=True`运行选项，这将强制仅进行一个超参数调优作业。添加了一个条件，只考虑具有多个调优模型作为父模型的作业，前提是这些是非测试的。此外，调优作业日志文件可以在不同模型间使用，因为理论上可以在模型间使用父作业。在这种情况下，模型通过‘metric’字段进行跟踪，符合条件的调优作业会过滤以匹配当前训练实例中的指标。
- en: Once the retraining has been done, we’ll then append the log file with the new
    hyperparameter tuning job and write it locally as well as to s3 with [versioning](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Versioning.html)
    turned on.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦重新训练完成，我们将把新的超参数调整作业追加到日志文件中，并将其写入本地以及s3，同时启用[版本控制](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Versioning.html)。
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**3\. Register multiple models to the Model Registry in a single interactive
    python notebook**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. 在单个交互式Python笔记本中将多个模型注册到模型注册表**'
- en: Often, organizations will have multiple AWS accounts for different use cases
    (i.e. sandbox, QA, and production). You’ll need to determine which account to
    use for each for each step of the CI/CD solution, then add the cross-account permissions
    noted in [this guide](https://aws.amazon.com/blogs/machine-learning/build-a-cross-account-mlops-workflow-using-the-amazon-sagemaker-model-registry/).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，组织会有多个AWS账户用于不同的用例（即沙盒、QA和生产）。你需要确定在CI/CD解决方案的每个步骤中使用哪个账户，然后添加[本指南](https://aws.amazon.com/blogs/machine-learning/build-a-cross-account-mlops-workflow-using-the-amazon-sagemaker-model-registry/)中提到的跨账户权限。
- en: The recommendation is to perform model training and model registration in the
    same account, specifically a sandbox or testing account. So in the below chart
    the ‘Data Science’ and ‘Shared Services’ account will be the same. Within this
    account an s3 bucket will be needed to house model artifacts and track lineage
    on other files related to the pipeline. Models/endpoints will be deployed separately
    within each ‘deployment’ account (i.e. sandbox, QA, production) by referencing
    the model artifacts and the registry in the training/registration account.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐在同一账户中进行模型训练和模型注册，特别是沙盒或测试账户。因此，在下图中，‘数据科学’和‘共享服务’账户将是相同的。在该账户中，需要一个s3桶来存放模型工件并跟踪与流水线相关的其他文件的血统。模型/端点将在每个‘部署’账户（即沙盒、QA、生产）中分别部署，引用训练/注册账户中的模型工件和注册表。
- en: '![](../Images/62a4d64e3bf6d781dd23ffc4aeb9bfa0.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/62a4d64e3bf6d781dd23ffc4aeb9bfa0.png)'
- en: Chart from [AWS Documentation](https://aws.amazon.com/blogs/machine-learning/build-a-cross-account-mlops-workflow-using-the-amazon-sagemaker-model-registry/)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 来自[AWS 文档](https://aws.amazon.com/blogs/machine-learning/build-a-cross-account-mlops-workflow-using-the-amazon-sagemaker-model-registry/)
- en: Now that we’ve decided which AWS account will be used for training and to house
    the model registry, we can now build an initial model and develop the CI/CD solution.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经决定了用于训练和存放模型注册表的AWS账户，我们可以构建初始模型并开发CI/CD解决方案。
- en: When using SageMaker Pipelines, separate pipeline steps are created for data
    preprocessing, training/tuning, evaluation, registration, and any post-processing.
    While that’s fine for a single model pipeline, it creates a lot of pipeline code
    duplicity when there are multiple models required for a machine learning solution.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 使用SageMaker Pipelines时，为数据预处理、训练/调整、评估、注册以及任何后处理创建独立的管道步骤。虽然这对于单个模型管道是可以的，但当需要多个模型来解决机器学习方案时，会产生大量的管道代码重复。
- en: 'As a result, the recommended solution is instead to build and schedule three
    interactive python notebooks in SageMaker Studio. They are run in sequence and
    together accomplish the CI/CD pipeline once automated with a notebook job:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，推荐的解决方案是构建并调度三个交互式Python笔记本在SageMaker Studio中。它们按顺序运行，并通过一个自动化的笔记本作业一起完成CI/CD流水线：
- en: '***A. Data preparation***'
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***A. 数据准备***'
- en: ''
  id: totrans-62
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '***B. Model training, evaluation, and registration***'
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***B. 模型训练、评估和注册***'
- en: ''
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '***C. Endpoint refresh with the latest approved models***'
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***C. 使用最新批准的模型刷新端点***'
- en: A. Data preparation
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: A. 数据准备
- en: Here we will query and load data from the data warehouse and write it locally
    and to s3\. We can set dynamic date/time conditions using the current date and
    pass the resulting date floor and ceiling into the SQL query.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将从数据仓库查询并加载数据，然后将其写入本地和s3。我们可以使用当前日期设置动态的日期/时间条件，并将生成的日期下限和上限传递到SQL查询中。
- en: '[PRE3]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This step ends with saving the prepared data for training locally as well as
    in s3 for lineage tracking.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步骤以将准备好的训练数据保存到本地以及s3以进行血统追踪结束。
- en: B. Model training, evaluation, and registration
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: B. 模型训练、评估和注册
- en: By using an interactive python notebook in Studio, we can now complete model
    training, evaluation, and registration all in one notebook. All these steps can
    be built into a function and that is applied for additional models that need to
    be retrained. For illustrative purposes, the code has been provided without using
    a function.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在 Studio 中使用交互式 Python notebook，我们现在可以在一个 notebook 中完成模型训练、评估和注册。所有这些步骤都可以构建为一个函数，并适用于需要重新训练的其他模型。为了说明，代码未使用函数提供。
- en: Prior to proceeding, model package groups need to be created in the Registry
    (either in the console or via Python) for each model that’s part of the solution.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，需要在注册表中为解决方案中的每个模型创建模型包组（可以在控制台中创建，也可以通过 Python 创建）。
- en: '[PRE4]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: By opening the model package group in the registry, you can see all the model
    versions that have been registered, the date they were registered, and their approval
    status.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 通过打开注册表中的模型包组，您可以查看所有已注册的模型版本、注册日期和批准状态。
- en: '![](../Images/0a582302948d0320e279dda5eb3f2bb5.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0a582302948d0320e279dda5eb3f2bb5.png)'
- en: Chart from [AWS Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/modelregistryfaq.html)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 [AWS 文档](https://docs.aws.amazon.com/sagemaker/latest/dg/modelregistryfaq.html)
    的图表
- en: The supervisor of the pipeline can then review the evaluation report saved locally
    in the previous step, which contains the history of all past model evaluations,
    and determine if they’d like to approve or deny the model based on the testing
    set evaluation metrics. Later on, criteria can be set to only update production
    (or QA) endpoints with the latest model if it was approved.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 管道的主管可以查看在前一步中本地保存的评估报告，其中包含所有过去模型评估的历史记录，并根据测试集评估指标确定是否批准或拒绝该模型。稍后，可以设置条件，仅在模型获得批准后更新生产（或
    QA）端点。
- en: '**4\. Refreshing a multi-model endpoint with new models**'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**4\. 用新模型刷新多模型端点**'
- en: SageMaker has a [MultiDataModel](https://sagemaker.readthedocs.io/en/stable/api/inference/multi_data_model.html)
    class that allows deploying SageMaker endpoints that can host more than one model.
    The rationale is that multiple models can be loaded in the same compute instance,
    sharing resources and saving costs. Furthermore, it simplifies model retraining/admin
    as only one endpoint needs to be reflected with the new models and managed, vs.
    having to duplicate steps across each dedicated endpoint (which can be done as
    an alternative). The MultiDataModel class can also be used to deploy a single
    model, which could make sense if there are plans to add additional models to the
    solution in the future.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 具有一个 [MultiDataModel](https://sagemaker.readthedocs.io/en/stable/api/inference/multi_data_model.html)
    类，允许部署可以托管多个模型的 SageMaker 端点。其原理在于可以在同一个计算实例中加载多个模型，共享资源并节省成本。此外，它简化了模型的重新训练/管理，因为只需更新一个端点以反映新模型并进行管理，而不必在每个专用端点之间重复步骤（这也可以作为替代方案）。MultiDataModel
    类也可以用于部署单个模型，如果计划在未来向解决方案中添加更多模型，这可能会很有意义。
- en: We’ll need to create the model and endpoint on the first go in the training
    account. The MultiDataModel class requires a location to store model artifacts
    that can be loaded into the endpoint when they are invoked; below we’ll use the
    ‘models’ directory in the s3 bucket being used.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在首次训练账户中，我们需要创建模型和端点。MultiDataModel 类需要一个位置来存储可以在调用时加载到端点中的模型工件；下面我们将使用正在使用的
    s3 bucket 中的“models”目录。
- en: '[PRE5]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'After that, the MultiDataModel can be referenced as follows:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，可以按照以下方式引用 MultiDataModel：
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Models can be added to the MultiDataModel by copying the artifact to the {s3
    bucket}/models directory which the endpoint will use to load models. All we need
    is the model package group name and the Model Registry will provide the respective
    source artifact location and approval status.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过将工件复制到端点将使用的 {s3 bucket}/models 目录，将模型添加到 MultiDataModel 中。我们所需的只是模型包组名称，模型注册表将提供相应的源工件位置和批准状态。
- en: We can add a condition to only add the latest model if it’s approved, illustrated
    below. This condition may be omitted in the sandbox account in case an immediate
    deploy is needed for data science QA and to ultimately approve the model.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以添加一个条件，仅在模型获得批准后才添加最新模型，如下所示。如果需要立即部署进行数据科学 QA 并最终批准模型，可以在沙箱账户中省略此条件。
- en: '[PRE7]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We can then list the models that have been added with the following function:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用以下函数列出已添加的模型：
- en: '[PRE8]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: To remove a model, one can navigate to the associated s3 directory in the console
    and delete any of them; they will be gone when relisting the available models.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除模型，可以在控制台中导航到关联的 s3 目录，并删除其中的任何一个；它们会在重新列出可用模型时消失。
- en: 'A model can be invoked in the deployed endpoint once it’s been added by using
    the following code:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在部署的端点中可以通过以下代码进行调用：
- en: '[PRE9]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Upon the first invocation of a model, the endpoint will load the target model,
    resulting in additional latency. For future invocations where the model is already
    loaded, inferences will be obtained immediately. In the [multi-model endpoint
    developer guide](https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html),
    AWS notes that models which that haven’t been invoked recently will be ‘unloaded’
    when the endpoint reaches a memory utilization threshold. The models will then
    be reloaded upon their next invocation.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在首次调用模型时，端点将加载目标模型，从而导致额外的延迟。在模型已加载的未来调用中，推理将立即获得。在 [多模型端点开发指南](https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html)
    中，AWS 指出，当端点达到内存使用阈值时，最近未调用的模型将被“卸载”。模型将在下次调用时重新加载。
- en: When an existing model artifact is overwritten via mme.add_model() or in the
    s3 console, the deployed endpoint won’t be reflected immediately. To force the
    endpoint to reload the latest model artifacts upon their next invocation, we can
    use a trick of updating the endpoint with an arbitrary new endpoint configuration.
    This creates a new endpoint where models need to be loaded, and safely manages
    the transition between the old and new endpoint. Because each endpoint configuration
    requires a unique name, we can add a suffix with a date/time stamp.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 当现有模型工件通过 mme.add_model() 或在 s3 控制台中被覆盖时，部署的端点不会立即反映变化。为了强制端点在下次调用时重新加载最新的模型工件，我们可以使用一个技巧，即通过任意新的端点配置更新端点。这将创建一个新端点，需要加载模型，并安全地管理旧端点和新端点之间的过渡。由于每个端点配置需要唯一的名称，我们可以添加带有日期/时间戳的后缀。
- en: '[PRE10]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Once this code is run, you’ll see that the associated endpoint will have an
    ‘updating’ status when viewing it in the console. During this updating period,
    the previous endpoint will be available for use, and it will be swapped with the
    new endpoint once it’s ready, after which the status will adjust to ‘in service.’
    The new models added will then be loaded upon their next invocation.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码后，你会看到关联的端点在控制台中将显示“更新中”状态。在此更新期间，之前的端点将可用，且在新端点准备好后将被交换，此时状态将调整为“服务中”。新添加的模型将在下次调用时加载。
- en: We’ve now built out the three notebooks required for the CI/CD solution — data
    preparation, training/evaluation, and endpoint updating. However, these files
    are currently only in the training AWS account. We need to adapt the third notebook
    to work in any deployment AWS account where a respective endpoint will be created/updated.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经构建了 CI/CD 解决方案所需的三个笔记本 —— 数据准备、训练/评估和端点更新。然而，这些文件目前仅存在于训练 AWS 账户中。我们需要调整第三个笔记本，以便在任何部署的
    AWS 账户中工作，在这些账户中将创建/更新相应的端点。
- en: To do this we can add conditional logic based on the AWS Account ID. s3 buckets
    will also be required in the new AWS accounts to house model artifacts. Since
    s3 bucket names need to be unique across AWS, such conditional logic can be used
    for this. It can also be applied to adjust the endpoint instance type and conditions
    for adding new models (i.e. approval status).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们可以添加基于 AWS 账户 ID 的条件逻辑。新的 AWS 账户也需要 s3 存储桶来存放模型工件。由于 s3 存储桶名称在 AWS 中需要唯一，因此可以使用这种条件逻辑。此外，这也可以应用于调整端点实例类型以及添加新模型的条件（即审批状态）。
- en: '[PRE11]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The steps to initially create and deploy the MultiDataModel will need to be
    repeated in each new deployment account.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 最初创建和部署 MultiDataModel 的步骤需要在每个新的部署账户中重复进行。
- en: Now that we have one working notebook that references the AWS Account ID and
    can be run across different AWS accounts, we’ll want to set up a git repo that
    contains this notebook (and likely the other two for lineage tracking), then clone
    the repo in the SageMaker Studio domains of these accounts. Fortunately, with
    the Studio/Git integration these steps are straightforward/seamless and are outlined
    in the following [document](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-tasks-git.html).
    Based on my experience, it’s recommended to create the repo outside of SageMaker
    Studio and clone it within each AWS account domain.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个可以引用 AWS 账户 ID 并可以跨不同 AWS 账户运行的工作笔记本，我们将希望设置一个包含这个笔记本（以及可能包含其他两个用于传承追踪）的
    git 仓库，然后在这些账户的 SageMaker Studio 域中克隆该仓库。幸运的是，借助 Studio/Git 集成，这些步骤非常直接/无缝，并在以下
    [文档](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-tasks-git.html) 中进行了说明。根据我的经验，建议在
    SageMaker Studio 外部创建仓库，并在每个 AWS 账户域中克隆它。
- en: Any future changes to the notebooks can be done in the training account and
    pushed to the repo. They can then be reflected in the other deployment accounts
    by pulling in the changes. Make sure to create a .gitignore file so only the 3
    notebooks are considered vs. any of the log or other files; lineage there will
    be tracked in s3\. Furthermore, one should recognize that anytime a notebook is
    run the console output will change. To avoid conflicts when pulling the file changes
    in the other deployments accounts, any file changes since the last pull in these
    accounts should be restored prior to pulling the latest updates.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 对于笔记本的任何未来更改可以在训练账户中进行，并推送到仓库。然后，通过拉取更改，可以在其他部署账户中反映这些更改。确保创建一个 `.gitignore`
    文件，以便仅考虑这三个笔记本，而不是日志或其他文件；其传承将被追踪到 s3。进一步地，应当认识到每次运行笔记本时，控制台输出都会发生变化。为了避免在其他部署账户中拉取文件更改时发生冲突，必须在拉取最新更新之前恢复自上次拉取以来的文件更改。
- en: 5\. *Schedule retrain/redeploy notebooks to run on a set cadence*
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*安排重新训练/重新部署笔记本以按设定的节奏运行*'
- en: Finally we can schedule all three notebooks to run concurrently in the training
    account. We can use the new [SageMaker Studio notebook jobs](https://aws.amazon.com/blogs/machine-learning/operationalize-your-amazon-sagemaker-studio-notebooks-as-scheduled-notebook-jobs/)
    feature to do this. The schedules should be considered as environment/account
    dependent — i.e. in the deployment accounts we can create separate notebook jobs
    but now just to update endpoints with the latest models, and provide some lag-time
    between when newly approved models are automatically deployed in the sandbox,
    QA, and production accounts. The beauty is that the only manual part of the process
    once the solution is released becomes model approval/denying in the registry.
    And if anything goes wrong with a newly deployed model, the model can be denied/deleted
    in the registry after which the endpoint update notebook can be manually run to
    revert to the previous production model version, buying time for further investigation.
    In this case, we set the pipeline to run on set time intervals (i.e. monthly/quarterly),
    although this solution can be adapted to work upon conditions (i.e. data drift
    or declining production model accuracy).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以安排在训练账户中同时运行所有三个笔记本。我们可以使用新的 [SageMaker Studio notebook jobs](https://aws.amazon.com/blogs/machine-learning/operationalize-your-amazon-sagemaker-studio-notebooks-as-scheduled-notebook-jobs/)
    功能来实现这一点。调度应被视为环境/账户依赖的——即在部署账户中我们可以创建单独的笔记本作业，但现在只是为了用最新的模型更新端点，并在新批准的模型自动部署到沙盒、QA
    和生产账户之间提供一些滞后时间。其优点是，解决方案发布后唯一的手动部分变成了在注册表中的模型审批/拒绝。如果新部署的模型出现问题，可以在注册表中拒绝/删除该模型，然后手动运行端点更新笔记本，以恢复到之前的生产模型版本，从而争取进一步调查的时间。在这种情况下，我们将管道设置为按设定时间间隔运行（例如每月/每季度），尽管此解决方案可以调整为基于条件工作（例如数据漂移或生产模型准确度下降）。
- en: Closing remarks
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结束语
- en: CI/CD is currently hot topic in the machine learning operations space. This
    is warranted as many times less thought occurs on the continuity of a machine
    learning solution after it’s initial deployment. To ensure production machine
    learning solutions are robust to covariate drift and are sustainable over time,
    a simple and flexible CI/CD solution is required. Fortunately, AWS has released
    a host of new features within it’s SageMaker ecosystem that makes such a solution
    possible. This article shows a path to successfully accomplish this for a wide
    array of tailored ML solutions, requiring only a single manual model verification
    step.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: CI/CD 目前是机器学习运维领域的热门话题。这是合理的，因为很多时候对于机器学习解决方案在初次部署后的持续性考虑较少。为了确保生产机器学习解决方案对协变量漂移具有鲁棒性，并且能够在长时间内可持续，需要一个简单而灵活的
    CI/CD 解决方案。幸运的是，AWS 在其 SageMaker 生态系统中发布了一系列新功能，使这种解决方案成为可能。本文展示了一种成功实现这一目标的路径，适用于各种量身定制的机器学习解决方案，只需进行一次手动模型验证步骤。
- en: Thanks for reading! If you liked this article, follow me to get notified of
    my new posts. Also, feel free to share any comments/suggestions.
  id: totrans-106
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 感谢阅读！如果你喜欢这篇文章，关注我以获取我新帖的通知。同时，欢迎随时分享你的评论/建议。
