- en: The Proper Way to Make Calls to ChatGPT API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-proper-way-to-make-calls-to-chatgpt-api-52e635bea8ff?source=collection_archive---------0-----------------------#2023-07-15](https://towardsdatascience.com/the-proper-way-to-make-calls-to-chatgpt-api-52e635bea8ff?source=collection_archive---------0-----------------------#2023-07-15)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How to make reliable calls to ChatGPT API to build robust applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://lucolivi.medium.com/?source=post_page-----52e635bea8ff--------------------------------)[![Lucas
    Oliveira](../Images/e303751fcafde01db6d1182320a50797.png)](https://lucolivi.medium.com/?source=post_page-----52e635bea8ff--------------------------------)[](https://towardsdatascience.com/?source=post_page-----52e635bea8ff--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----52e635bea8ff--------------------------------)
    [Lucas Oliveira](https://lucolivi.medium.com/?source=post_page-----52e635bea8ff--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb9eafd3d6f21&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-proper-way-to-make-calls-to-chatgpt-api-52e635bea8ff&user=Lucas+Oliveira&userId=b9eafd3d6f21&source=post_page-b9eafd3d6f21----52e635bea8ff---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----52e635bea8ff--------------------------------)
    ·11 min read·Jul 15, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F52e635bea8ff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-proper-way-to-make-calls-to-chatgpt-api-52e635bea8ff&user=Lucas+Oliveira&userId=b9eafd3d6f21&source=-----52e635bea8ff---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F52e635bea8ff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-proper-way-to-make-calls-to-chatgpt-api-52e635bea8ff&source=-----52e635bea8ff---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: LLMs are everywhere now, especially ChatGPT. There are a ton of applications
    being built on top of it and if you are not, you should give it a try.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/054928a295cef1538fd969eea16d31b4.png)'
  prefs: []
  type: TYPE_IMG
- en: Created with Midjourney.
  prefs: []
  type: TYPE_NORMAL
- en: Building applications on top of ChatGPT will likely require you to make several
    parallel calls. Unfortunately, you are not the only one. With so many applications
    performing millions of requests per day (KUDOS for their engineering team by the
    way) often the API will return a “too many requests” error. So we need a good
    way to deal with such errors while making several parallel calls.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this small Python tutorial, we will cover these two important topics to
    efficiently perform calls to ChatGPT API:'
  prefs: []
  type: TYPE_NORMAL
- en: Perform several calls in parallel
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Retry calls in case they fail
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 1\. Performing several calls in parallel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The simplest way to perform a call is to perform it synchronously, that is,
    send the request and wait for the response to arrive to continue the program.
    We can do that simply as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: If we are working in a simple system it is fine, however, if we wish to perform
    several calls in parallel to an API or other resources like a database, we can
    do it asynchronously for faster responses.
  prefs: []
  type: TYPE_NORMAL
- en: Executing tasks asynchronously will trigger every action and wait for them to
    finish in parallel, which will reduce the wait time.
  prefs: []
  type: TYPE_NORMAL
- en: A basic way to do this is to create different threads to process each request,
    however, there is a better way to do it [using async calls](https://realpython.com/async-io-python/).
  prefs: []
  type: TYPE_NORMAL
- en: Doing an async call is often more efficient since you can specify the exact
    places where your application should wait whereas in traditional threading the
    system will automatically put threads to wait, which may be suboptimal.
  prefs: []
  type: TYPE_NORMAL
- en: Below we present an example showing the difference between using sync and async
    calls.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The `asyncio.gather` method will trigger all async calls passed to it and return
    their results once they are ready.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately performing async calls with the `requests` library is not possible.
    To do it you can use the `aiohttp` library. Below there is an example of how to
    perform an async call with `aiohttp`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: As said before, to perform async requests we need to make use of the `asyncio.gather`
    method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Although this works, performing calls this way is not ideal since we are recreating
    the session object for every call. We can save resources and time by reusing the
    same session object like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Simple, right? With this, you can easily perform several calls. One problem
    however is that often it is not a good practice to perform unlimited calls this
    way since you can overload a system and be penalized preventing you from performing
    additional requests for some amount of time ([trust me, you will](https://platform.openai.com/docs/guides/rate-limits)).
    So it is a good idea to limit the amount of calls you can perform at the same
    time. You can do this easily with the `asyncio.Semaphore` class.
  prefs: []
  type: TYPE_NORMAL
- en: The `Semaphore` class creates a context manager that will manage the amount
    of async calls that are currently being performed within its context. If the max
    amount is reached it will block until some of the calls finish.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'An optional thing here is to report how the progress of the calls is going.
    You can do it by creating a small class that will hold the progress and be shared
    across all calls. You can do it as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This completes this section on how to perform multiple async requests. With
    this, you can perform several async calls, limit the number of calls per time
    and report the progress. However, there are still some problems to handle.
  prefs: []
  type: TYPE_NORMAL
- en: The requests made can fail for several different reasons like server overload,
    connection interruption, bad requests, etc. These may generate exceptions or return
    unpredictable responses so we need to treat these cases and automatically retry
    failed calls.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Retry calls in case they fail
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To handle failed calls we will make use of the `tenacity` library. Tenacity
    provides function decorators that will automatically retry our function call in
    case it generates an exception.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: To provide a retry functionality to our calls we will need to place the `@retry`
    decorator. Using it without additional parameters will make the function retry
    immediately and indefinitely once it fails. This is not good for some reasons.
  prefs: []
  type: TYPE_NORMAL
- en: One is that our function call may fail due to server overload which makes it
    reasonable to wait some time before trying again. To indicate the time to wait
    we will use the approach of the exponential backoff using the parameter `wait=wait_random_exponential(min=min_value,
    max=max_value)`. This will increase the wait time the more the function fails.
  prefs: []
  type: TYPE_NORMAL
- en: One optional thing is to log messages whenever some retry occurs. We can do
    it by providing some function to the parameter `before_sleep`. Here we will use
    the `print` function, however, a better way is to use the `logging` module and
    pass a `logging.error` or `logging.debug` function to this parameter.
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate we will generate random exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This will make our function wait some time before retrying it. However, the
    reason for failure may be systematical due to a server downtime or a bad payload
    for example. In this case, we want our amount of retries to be limited. We can
    do it with the parameter `stop=stop_after_attempt(n)`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'With this parameter set a `RetryError` will raise once the amount of tries
    reaches the maximum value. However, it may be the case that we want to continue
    our running without generating an exception, just saving a `None` value to the
    call return to handle it later. To do it we can use the callback function `retry_error_callback`
    to just return the `None` value in case a `RetryError` error occurs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: With this, `None` values will be returned instead of generating errors.
  prefs: []
  type: TYPE_NORMAL
- en: One problem not handled yet is the stuck connection problem. This happens when
    we perform a request and for some reason, the host holds the connection but neither
    fails nor returns something. To handle such cases we need to place a timeout to
    return in case the call doesn’t return a value within a given period. To do it
    we can use use the `timeout` parameter from the `aiohttp` library together with
    the `aiohttp.ClientTimeout` class. In case a timeout occurs here, a `TimeoutError`
    will be raised, which will then be handled by the `retry` decorator from `tenacity`
    and automatically run the function again.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Great! Now we have a robust way to run multiple parallel requests that will
    automatically retry in case some failure occurs and return `None` values in case
    the failure is systematic. So the final code will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'In summary, we have implemented the following features:'
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous calls to reduce wait time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Logging async calls progress.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Automatically trigger retries when a call fails.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Return None values in case the fails are systematical.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Retry a call when it timeouts and doesn’t return anything.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you have any questions, found some error, or have any ideas on how to improve
    this leave a comment below!
  prefs: []
  type: TYPE_NORMAL
