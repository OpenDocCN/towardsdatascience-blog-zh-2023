- en: 'Text Classification Challenge with Extra-Small Datasets: Fine-Tuning Versus
    ChatGPT'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本分类挑战：极小数据集上的微调与ChatGPT
- en: 原文：[https://towardsdatascience.com/text-classification-challenge-with-extra-small-datasets-fine-tuning-versus-chatgpt-6348fecea357?source=collection_archive---------3-----------------------#2023-07-07](https://towardsdatascience.com/text-classification-challenge-with-extra-small-datasets-fine-tuning-versus-chatgpt-6348fecea357?source=collection_archive---------3-----------------------#2023-07-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/text-classification-challenge-with-extra-small-datasets-fine-tuning-versus-chatgpt-6348fecea357?source=collection_archive---------3-----------------------#2023-07-07](https://towardsdatascience.com/text-classification-challenge-with-extra-small-datasets-fine-tuning-versus-chatgpt-6348fecea357?source=collection_archive---------3-----------------------#2023-07-07)
- en: LLMs excel on extra-small datasets, but classical approaches shine as datasets
    grow
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM在极小数据集上表现优秀，但随着数据集的增大，传统方法则表现突出
- en: '[](https://v-zhukov.medium.com/?source=post_page-----6348fecea357--------------------------------)[![Viacheslav
    Zhukov](../Images/c08a514fd6dc82214b72e419efb81d27.png)](https://v-zhukov.medium.com/?source=post_page-----6348fecea357--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6348fecea357--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6348fecea357--------------------------------)
    [Viacheslav Zhukov](https://v-zhukov.medium.com/?source=post_page-----6348fecea357--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Viacheslav Zhukov](../Images/c08a514fd6dc82214b72e419efb81d27.png)](https://v-zhukov.medium.com/?source=post_page-----6348fecea357--------------------------------)
    [![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6348fecea357--------------------------------)
    [Viacheslav Zhukov](https://v-zhukov.medium.com/?source=post_page-----6348fecea357--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F996e241eda9b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-classification-challenge-with-extra-small-datasets-fine-tuning-versus-chatgpt-6348fecea357&user=Viacheslav+Zhukov&userId=996e241eda9b&source=post_page-996e241eda9b----6348fecea357---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6348fecea357--------------------------------)
    ·7 min read·Jul 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6348fecea357&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-classification-challenge-with-extra-small-datasets-fine-tuning-versus-chatgpt-6348fecea357&user=Viacheslav+Zhukov&userId=996e241eda9b&source=-----6348fecea357---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F996e241eda9b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-classification-challenge-with-extra-small-datasets-fine-tuning-versus-chatgpt-6348fecea357&user=Viacheslav+Zhukov&userId=996e241eda9b&source=post_page-996e241eda9b----6348fecea357---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6348fecea357--------------------------------)
    · 7分钟阅读 · 2023年7月7日'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6348fecea357&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-classification-challenge-with-extra-small-datasets-fine-tuning-versus-chatgpt-6348fecea357&source=-----6348fecea357---------------------bookmark_footer-----------)![](../Images/f25a15c69eb89ab31cc985d9ceff3b86.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/f25a15c69eb89ab31cc985d9ceff3b86.png)'
- en: Photo by [Debby Hudson](https://unsplash.com/de/@hudsoncrafted?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[Debby Hudson](https://unsplash.com/de/@hudsoncrafted?utm_source=medium&utm_medium=referral)拍摄的照片，发布于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)。'
- en: The Toloka ML team continually researches and compares different approaches
    to text classification under various conditions. Here we present another one of
    our experiments on the performance of NLP models when trained on extra-small datasets.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Toloka ML团队不断研究并比较在各种条件下的文本分类不同方法。在这里，我们展示了一个关于NLP模型在极小数据集上训练表现的实验。
- en: Previously, we provided a [brief overview of potential solutions](https://medium.com/toloka/choosing-the-best-architecture-for-your-text-classification-task-aee30ecc7870)
    and [compared classical models with large language models (LLMs)](https://www.kdnuggets.com/2023/04/best-architecture-text-classification-task-benchmarking-options.html)
    for a specific text classification task. However, those comparisons were based
    on a “regular” dataset that contained enough data points to build a reliable classifier.
    In real-world scenarios, you may encounter situations where limited data is available
    or human labeling hasn’t been carried out.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们提供了一个关于潜在解决方案的[简要概述](https://medium.com/toloka/choosing-the-best-architecture-for-your-text-classification-task-aee30ecc7870)和[将经典模型与大型语言模型（LLMs）进行比较](https://www.kdnuggets.com/2023/04/best-architecture-text-classification-task-benchmarking-options.html)的内容，针对特定的文本分类任务。然而，那些比较是基于一个包含足够数据点以建立可靠分类器的“常规”数据集。在实际应用场景中，你可能会遇到数据有限或没有进行人工标注的情况。
- en: Intuitively, LLMs such as GPT-3 or ChatGPT might outperform smaller models due
    to their extensive “knowledge”. To investigate this hypothesis, we created an
    artificially small dataset by extracting a portion of a larger one and compared
    several approaches. We fine-tuned the RoBERTa base model, employed ChatGPT for
    few-shot classification, and fine-tuned the GPT-3 Babbage model.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 直观上，像GPT-3或ChatGPT这样的LLMs可能会由于其广泛的“知识”而优于较小的模型。为了验证这一假设，我们通过提取较大数据集的一部分创建了一个人工的小数据集，并比较了几种方法。我们微调了RoBERTa基础模型，使用ChatGPT进行少量示例分类，并微调了GPT-3
    Babbage模型。
- en: The dataset
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集
- en: To evaluate the comprehension capabilities of various models, we selected a
    multiclass dataset consisting of scientific article abstracts. The task was to
    determine each article’s domain.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估各种模型的理解能力，我们选择了一个由科学文章摘要组成的多类别数据集。任务是确定每篇文章的领域。
- en: 'We opted for the [WOS-11967](https://data.mendeley.com/datasets/9rw3vkcfy4/6)
    [1] dataset, which contains 11,967 documents with 35 categories that include seven
    parent categories: medical, psychology, computer science, biochemistry, electrical
    engineering, civil sciences, and mechanical engineering. We sampled 10,000 data
    points and focused solely on the parent categories for our analysis.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了[WOS-11967](https://data.mendeley.com/datasets/9rw3vkcfy4/6) [1] 数据集，该数据集包含11,967个文档，涵盖35个类别，其中包括七个父类别：医学、心理学、计算机科学、生物化学、电气工程、土木科学和机械工程。我们抽取了10,000个数据点，仅关注父类别进行分析。
- en: While the dataset was not perfectly balanced, the class distribution was reasonably
    proportional. Therefore, satisfactory results could potentially be achieved across
    all classes. The class distribution is illustrated below.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管数据集并未完全平衡，但类别分布相当合理。因此，所有类别都可能取得令人满意的结果。类别分布如下图所示。
- en: '![](../Images/9170f11ccb793cb99aa9a0db664bbcd7.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9170f11ccb793cb99aa9a0db664bbcd7.png)'
- en: The class distribution of the sample of the [WOS-11967](https://paperswithcode.com/dataset/web-of-science-dataset)
    dataset
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[WOS-11967](https://paperswithcode.com/dataset/web-of-science-dataset)数据集的样本类别分布'
- en: Upon manual analysis, we found that determining the domain of some abstracts
    was relatively straightforward, while in other cases, the task became more challenging.
    For instance, computer science articles may discuss mathematical topics, or psychology
    articles might contain medical or biochemical terms and abbreviations, making
    it difficult to distinguish them from biochemistry or medical domains. The abstracts
    also varied significantly in length, with a mean of 274 tokens (ChatGPT tokens)
    and a standard deviation of 115 tokens.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 通过人工分析，我们发现确定一些摘要的领域相对简单，而在其他情况下，任务变得更加具有挑战性。例如，计算机科学文章可能讨论数学主题，或心理学文章可能包含医学或生化术语和缩写，使其难以与生物化学或医学领域区分开。摘要的长度也有显著差异，平均为274个token（ChatGPT
    tokens），标准差为115个token。
- en: 'To simulate scenarios involving extra-small datasets, we performed a train-test
    split on the corpora and allocated a small number of samples to the training set.
    We repeated this process three times with different training set sizes to evaluate
    any changes in performance in the models based on the available training data.
    We created three splits for our experiment: WOS-11967-s200 (200 samples in the
    training set, 9,800 samples in the test set), WOS-11967-s500 (500 / 9,500), and
    WOS-11967-s2000 (2,000 / 8,000).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟涉及超小数据集的场景，我们对语料库进行了训练-测试拆分，并将少量样本分配到训练集中。我们重复进行了三次不同训练集大小的测试，以评估模型基于可用训练数据的性能变化。我们为实验创建了三个拆分：WOS-11967-s200（训练集中200个样本，测试集中9,800个样本），WOS-11967-s500（500
    / 9,500），和WOS-11967-s2000（2,000 / 8,000）。
- en: Now, let’s take a look at the results obtained using different models to tackle
    these problems.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看使用不同模型解决这些问题所获得的结果。
- en: Regular fine-tuning with RoBERTa
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正常的 RoBERTa 微调
- en: For our baseline, we selected the [RoBERTa base](https://huggingface.co/roberta-base)
    model [2] and fine-tuned it on the three datasets mentioned earlier. We used the
    same hyperparameter configuration for each run (a batch size of 32, a learning
    rate of 3e-5, a linear scheduler with warmup, and a 256-token window), along with
    early stopping to prevent overfitting.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 作为基线，我们选择了[RoBERTa base](https://huggingface.co/roberta-base)模型，并在前面提到的三个数据集上进行了微调。我们对每次运行使用了相同的超参数配置（批量大小为32，学习率为3e-5，带热身的线性调度器，256标记窗口），并采用了早停法以防止过拟合。
- en: 'We obtained the following results:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获得了以下结果：
- en: '![](../Images/d34e0b776b929c71e86f362bbb949c6e.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d34e0b776b929c71e86f362bbb949c6e.png)'
- en: The data shows that 200 samples are insufficient when it comes to extracting
    all the necessary patterns and information required to accurately classify the
    abstracts. The lower macro-average F1 score also indicates that the model underperforms
    on under-represented classes like mechanical engineering. This suggests that it’s
    not enough to have only a few samples from a particular class.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 数据显示，200个样本不足以提取准确分类摘要所需的所有模式和信息。较低的宏平均F1得分也表明模型在机械工程等代表性不足的类别上表现不佳。这表明，仅有少量来自特定类别的样本是不够的。
- en: As expected, the model’s performance improved as the amount of available data
    increased — ultimately resulting in robust performance for multiclass classification
    across seven classes.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，随着可用数据量的增加，模型的性能得到了改善——*最终*实现了在七个类别中的多类别分类的强大性能。
- en: Few-shot with ChatGPT
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与 ChatGPT 的少样本学习
- en: The second approach we explored was few-shot classification using ChatGPT. This
    method differs significantly from traditional classification as it doesn’t involve
    training a model per se. Instead, we engineered the input prompt to achieve optimal
    performance.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探索的第二种方法是使用 ChatGPT 的少样本分类。这种方法与传统分类方法有很大不同，因为它不涉及训练模型本身。相反，我们设计了输入提示以实现最佳性能。
- en: However, it was impossible to feed all 200 samples into the model due to its
    4096-token context size limit. Given the measurements above, we could only present
    around 14 abstracts to the model. That number was further reduced when considering
    the tokens used for instructions and delimiters.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于模型的4096标记上下文大小限制，无法将所有200个样本输入模型。根据上述测量，我们只能向模型展示大约14个摘要。在考虑到用于指令和分隔符的标记时，这一数字进一步减少。
- en: Initially, we employed the “system” role for instructions and provided a single
    example per class to guide the model’s response. We simplified the class names
    to single tokens while retaining their meaning. This made it easier for the model
    to select the appropriate category and limit the output to a single token. For
    instance, “Biochemistry” became “Bio,” and “Computer Science” became “Computer.”
    Additionally, we restricted the number of tokens generated by providing a list
    of classes to choose from and instructing the model to return the “Unknown” token
    if it was unsure about the category.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，我们采用了“系统”角色来提供指令，并为每个类别提供了一个示例以指导模型的响应。我们将类别名称简化为单个标记，同时保留其含义。这使得模型更容易选择合适的类别，并将输出限制为单个标记。例如，“生物化学”变成了“Bio”，“计算机科学”变成了“Computer”。此外，我们通过提供类别列表让模型选择，并指示模型如果不确定类别则返回“Unknown”标记，从而限制了生成的标记数量。
- en: Overall, ‌performance with this method was inferior compared to the RoBERTa
    model trained on just 200 samples. We noticed that the model’s classification
    ability heavily depended on the supplied prompt. Modifying a single sentence could
    either improve or worsen the metrics. In some cases, ChatGPT missed categories
    despite explicit instructions not to do so (which could be a drawback of how we
    formulated our prompt).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，使用这种方法的性能不如仅在200个样本上训练的RoBERTa模型。我们注意到模型的分类能力严重依赖于提供的提示。修改一句话可能会改善或恶化指标。在某些情况下，尽管有明确指示，ChatGPT仍错过了类别（这可能是我们制定提示方式的一个缺陷）。
- en: In a few fringe cases, it produced categories not listed in the instructions,
    but described the article domains, such as “Math” or “Chemistry”. It’s unclear
    whether these flaws should be attributed to the model or the dataset. However,
    according to the validation set, these categories can be corrected using simple
    rules like changing all instances of “Math” to “Computer”.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在一些边缘情况下，它生成了未列在指令中的类别，但描述了文章领域，如“数学”或“化学”。尚不清楚这些缺陷应归因于模型还是数据集。然而，根据验证集，这些类别可以使用简单规则进行更正，如将所有“数学”实例改为“计算机”。
- en: 'To improve metrics, we tried to use as much data as possible. Since we still
    couldn’t feed all 200 samples into the model, we devised a two-stage process:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高指标，我们尽可能使用了更多的数据。由于我们仍无法将全部200个样本输入模型，我们设计了一个两阶段的过程：
- en: First, we asked the model to identify similarities between abstracts from a
    specific domain and generate summaries.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们要求模型识别特定领域摘要之间的相似性并生成总结。
- en: Second, we incorporated these summaries into the instructions to provide the
    model with insights about the classes and features identified by the model itself
    in the first stage.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，我们将这些总结纳入指令中，以便为模型提供关于第一阶段模型自身识别的类别和特征的见解。
- en: 'This approach allowed us to feed more training data samples into the model;
    and it worked — we boosted metrics by approximately 10%. Below is the prompt we
    used to generate these summaries:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法使我们能够将更多训练数据样本输入模型；并且有效——我们将指标提升了约10%。以下是我们用来生成这些总结的提示：
- en: '![](../Images/b4b133bdb8221b7550efaf7c2611a75d.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b4b133bdb8221b7550efaf7c2611a75d.png)'
- en: The prompt for ChatGPT used to extract meaningful information about article
    domains
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 用于提取有关文章领域的有意义信息的ChatGPT提示
- en: For each domain, we supplied seven to eight abstracts, resulting in a total
    of 63 distinct abstracts used to prepare the classification prompt (eight abstracts
    per seven classes to build summaries and seven abstracts provided as examples
    in the actual prompt).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个领域，我们提供了七到八个摘要，共使用了63个不同的摘要来准备分类提示（每七个类别八个摘要用于构建总结，七个摘要作为实际提示中的示例）。
- en: Nevertheless, we instructed the model to respond with “Unknown” if it was uncertain
    about the class. In the validation set we observed that most “Unknown” responses
    corresponded to computer science articles. We then replaced all “Unknown” instances
    with the “Computer” class.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我们指示模型在对类别不确定时回复“未知”。在验证集中，我们观察到大多数“未知”回应对应于计算机科学文章。然后我们用“计算机”类别替换了所有“未知”实例。
- en: 'The resulting classification prompt read as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的分类提示如下：
- en: '![](../Images/dc6b4f585eed094a3ab7603da457ecea.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc6b4f585eed094a3ab7603da457ecea.png)'
- en: The final prompt for ChatGPT used to classify article abstracts
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 用于分类文章摘要的最终提示
- en: 'Once again, performance was heavily influenced by the prompt and the samples
    provided. The model also generated several categories outside the target list,
    requiring manual adjustments to be made based on the validation set. This approach
    yielded the following results:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，性能受提示和提供的样本的影响很大。模型还生成了多个目标列表之外的类别，需要根据验证集进行手动调整。这种方法得出了以下结果：
- en: '![](../Images/01ddbbce428c0cb90661725195fbb622.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01ddbbce428c0cb90661725195fbb622.png)'
- en: The performance was notably better than fine-tuning a RoBERTa model on 200 samples
    — and fewer samples were required. However, as the availability of labeled data
    increased, RoBERTa began to outperform this approach, even with just 500 samples.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 性能明显优于在200个样本上微调的RoBERTa模型——并且所需样本更少。然而，随着标记数据的增加，RoBERTa开始超过这种方法，即使只有500个样本。
- en: We believe that further performance improvements are possible through proper
    prompt engineering. Some useful tips and tricks can be found in the [Prompting
    Guide](https://www.promptingguide.ai/).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们相信，通过适当的提示工程，可以进一步提升性能。一些有用的提示和技巧可以在[Prompting Guide](https://www.promptingguide.ai/)中找到。
- en: Fine-tuning a GPT-3 model
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微调 GPT-3 模型
- en: 'For our final approach, we fine-tuned the GPT-3 Babbage model on these three
    datasets. We followed the dataset preparation recommendations outlined in the
    [OpenAI guide](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset)
    and opted for the default hyperparameters without making any specific adjustments.
    The training process for each dataset took about 20 minutes, yielding the following
    results:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们最终的方法，我们在这三个数据集上对 GPT-3 Babbage 模型进行了微调。我们遵循了[OpenAI 指南](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset)中概述的数据集准备建议，并选择了默认的超参数，没有进行任何特定的调整。每个数据集的训练过程大约花费了
    20 分钟，得到以下结果：
- en: '![](../Images/c84cd45bfa9a44da632ae4ffe4272287.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c84cd45bfa9a44da632ae4ffe4272287.png)'
- en: The fine-tuned GPT-3 model delivered impressive results even on the smallest
    dataset, surpassing both RoBERTa and ChatGPT. As the amount of training data increased,
    the performance gap between RoBERTa and the tuned GPT-3 model narrowed. This raised
    questions about the resources and feasibility of using either option. We discussed
    the pros and cons of both approaches in our [previous articles](https://medium.com/toloka/choosing-the-best-architecture-for-your-text-classification-task-aee30ecc7870).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 微调后的 GPT-3 模型即使在最小的数据集上也表现出色，超越了 RoBERTa 和 ChatGPT。随着训练数据量的增加，RoBERTa 和调优后的
    GPT-3 模型之间的性能差距缩小。这引发了对使用这两种选项的资源和可行性的疑问。我们在[之前的文章](https://medium.com/toloka/choosing-the-best-architecture-for-your-text-classification-task-aee30ecc7870)中讨论了这两种方法的优缺点。
- en: Conclusion
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This experiment demonstrates that our initial hypothesis was correct — larger
    models trained on more extensive data perform significantly better on extra-small
    datasets. With proper prompt engineering and few-shot techniques, it’s possible
    to achieve favorable results.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这个实验表明，我们的初步假设是正确的——在更大数据上训练的更大模型在额外小的数据集上表现显著更好。通过适当的提示工程和少样本技术，可以取得良好的结果。
- en: However, differences in performance decrease as the dataset size increases.
    Moreover, an appropriately tailored classical model, such as a domain-adapted
    RoBERTa model, can sometimes outperform generic LLMs in classification tasks.
    It can be attributed to the model’s specialized “knowledge” of the subject matter.
    Furthermore, with the right optimizations, inference using these models can be
    significantly faster, which is crucial when developing online services.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，随着数据集大小的增加，性能差异会减少。此外，适当定制的经典模型，例如领域适配的 RoBERTa 模型，有时可以在分类任务中优于通用的 LLM。这可以归因于模型对特定主题的专门“知识”。此外，通过正确的优化，使用这些模型的推断速度可以显著提高，这在开发在线服务时至关重要。
- en: All images unless otherwise noted are by the author.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，所有图片均由作者提供。
- en: Sources
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 来源
- en: 'Kowsari K, Brown DE, Heidarysafa M, Jafari Meimandi K, Gerber MS, Barnes LE.
    HDLTex: Hierarchical Deep Learning for Text Classification. In: *Machine Learning
    and Applications (ICMLA), 2017 16th IEEE International Conference On*. IEEE; 2017.'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Kowsari K, Brown DE, Heidarysafa M, Jafari Meimandi K, Gerber MS, Barnes LE.
    HDLTex: 分层深度学习用于文本分类。载于：*机器学习与应用（ICMLA），2017 年第 16 届 IEEE 国际会议*。IEEE; 2017。'
- en: 'Liu Y, Ott M, Goyal N, et al. RoBERTa: A Robustly Optimized BERT Pretraining
    Approach. *CoRR*. 2019;abs/1907.11692\. [http://arxiv.org/abs/1907.11692](http://arxiv.org/abs/1907.11692)'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '刘 Y, Ott M, Goyal N 等. RoBERTa: 一种稳健优化的 BERT 预训练方法。*CoRR*。2019;abs/1907.11692\.
    [http://arxiv.org/abs/1907.11692](http://arxiv.org/abs/1907.11692)'
