- en: A Decade of Knowledge Graphs in Natural Language Processing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„çŸ¥è¯†å›¾è°±ï¼šåå¹´å›é¡¾
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/a-decade-of-knowledge-graphs-in-natural-language-processing-5fdb15abc2b3?source=collection_archive---------8-----------------------#2023-03-14](https://towardsdatascience.com/a-decade-of-knowledge-graphs-in-natural-language-processing-5fdb15abc2b3?source=collection_archive---------8-----------------------#2023-03-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/a-decade-of-knowledge-graphs-in-natural-language-processing-5fdb15abc2b3?source=collection_archive---------8-----------------------#2023-03-14](https://towardsdatascience.com/a-decade-of-knowledge-graphs-in-natural-language-processing-5fdb15abc2b3?source=collection_archive---------8-----------------------#2023-03-14)
- en: An overview of the research landscape combining structured and unstructured
    knowledge in NLP
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…³äºç»“åˆç»“æ„åŒ–å’Œéç»“æ„åŒ–çŸ¥è¯†åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„ç ”ç©¶ç°çŠ¶
- en: '[](https://medium.com/@tim.schopf?source=post_page-----5fdb15abc2b3--------------------------------)[![Tim
    Schopf](../Images/7d98a87af243ae6a82f837aa04ac2675.png)](https://medium.com/@tim.schopf?source=post_page-----5fdb15abc2b3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5fdb15abc2b3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5fdb15abc2b3--------------------------------)
    [Tim Schopf](https://medium.com/@tim.schopf?source=post_page-----5fdb15abc2b3--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@tim.schopf?source=post_page-----5fdb15abc2b3--------------------------------)[![Tim
    Schopf](../Images/7d98a87af243ae6a82f837aa04ac2675.png)](https://medium.com/@tim.schopf?source=post_page-----5fdb15abc2b3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5fdb15abc2b3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5fdb15abc2b3--------------------------------)
    [Tim Schopf](https://medium.com/@tim.schopf?source=post_page-----5fdb15abc2b3--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7fe3665aa3e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-decade-of-knowledge-graphs-in-natural-language-processing-5fdb15abc2b3&user=Tim+Schopf&userId=7fe3665aa3e3&source=post_page-7fe3665aa3e3----5fdb15abc2b3---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5fdb15abc2b3--------------------------------)
    Â·8 min readÂ·Mar 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5fdb15abc2b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-decade-of-knowledge-graphs-in-natural-language-processing-5fdb15abc2b3&user=Tim+Schopf&userId=7fe3665aa3e3&source=-----5fdb15abc2b3---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7fe3665aa3e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-decade-of-knowledge-graphs-in-natural-language-processing-5fdb15abc2b3&user=Tim+Schopf&userId=7fe3665aa3e3&source=post_page-7fe3665aa3e3----5fdb15abc2b3---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5fdb15abc2b3--------------------------------)
    Â·8åˆ†é’Ÿé˜…è¯»Â·2023å¹´3æœˆ14æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5fdb15abc2b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-decade-of-knowledge-graphs-in-natural-language-processing-5fdb15abc2b3&user=Tim+Schopf&userId=7fe3665aa3e3&source=-----5fdb15abc2b3---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5fdb15abc2b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-decade-of-knowledge-graphs-in-natural-language-processing-5fdb15abc2b3&source=-----5fdb15abc2b3---------------------bookmark_footer-----------)![](../Images/c288205bdd2f7682d7f07f8bcfe638d9.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5fdb15abc2b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-decade-of-knowledge-graphs-in-natural-language-processing-5fdb15abc2b3&source=-----5fdb15abc2b3---------------------bookmark_footer-----------)![](../Images/c288205bdd2f7682d7f07f8bcfe638d9.png)'
- en: Photo by [Billy Huynh](https://unsplash.com/@billy_huy?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”± [Billy Huynh](https://unsplash.com/@billy_huy?utm_source=medium&utm_medium=referral)
    æä¾›ï¼Œæ¥è‡ª [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '*This post is based on our AACL-IJCNLP 2022 paper* [*â€œA Decade of Knowledge
    Graphs in Natural Language Processing: A Surveyâ€*](https://aclanthology.org/2022.aacl-main.46/)*.
    You can read more details there.*'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*è¿™ç¯‡æ–‡ç« åŸºäºæˆ‘ä»¬åœ¨AACL-IJCNLP 2022çš„è®ºæ–‡* [*ã€Šè‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„çŸ¥è¯†å›¾è°±ï¼šåå¹´å›é¡¾ã€‹*](https://aclanthology.org/2022.aacl-main.46/)*ã€‚ä½ å¯ä»¥åœ¨é‚£é‡Œé˜…è¯»æ›´å¤šç»†èŠ‚ã€‚*'
- en: '**Knowledge Graphs (KGs) have attracted a lot of attention** in both academia
    and industry since the introduction of Googleâ€™s KG in 2012 [(Singhal, 2012)](https://blog.google/products/search/introducing-knowledge-graph-things-not/).
    As a representation of semantic relations between entities, KGs have proven to
    be **particularly relevant for natural language processing (NLP)** and have experienced
    a rapid increase in popularity in recent years, a trend that appears to be accelerating
    ğŸš€. Given the increasing amount of research work in this area, several KG-related
    approaches have been surveyed in the NLP research community. However, a comprehensive
    study that categorizes established topics and reviews the maturity of individual
    research streams remains absent to this day. Contributing to closing this gap,
    we systematically analyzed 507 papers from the literature on KGs in NLP. As a
    result, we present a structured overview of the research landscape, provide a
    taxonomy of tasks, summarize our findings, and highlight directions for future
    work.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**çŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰è‡ª2012å¹´Googleæ¨å‡ºKGä»¥æ¥åœ¨å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œéƒ½å—åˆ°äº†æå¤§å…³æ³¨**ï¼ˆ[Singhal, 2012](https://blog.google/products/search/introducing-knowledge-graph-things-not/)ï¼‰ã€‚ä½œä¸ºå®ä½“ä¹‹é—´è¯­ä¹‰å…³ç³»çš„è¡¨ç¤ºï¼ŒçŸ¥è¯†å›¾è°±å·²è¢«è¯æ˜å¯¹è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰**ç‰¹åˆ«ç›¸å…³**ï¼Œå¹¶ä¸”è¿‘å¹´æ¥åœ¨æµè¡Œåº¦ä¸Šè¿…é€Ÿå¢é•¿ï¼Œè¿™ä¸€è¶‹åŠ¿ä¼¼ä¹æ­£åœ¨åŠ é€ŸğŸš€ã€‚é‰´äºè¿™ä¸€é¢†åŸŸçš„ç ”ç©¶å·¥ä½œè¶Šæ¥è¶Šå¤šï¼ŒNLPç ”ç©¶ç¤¾åŒºä¸­å·²ç»å¯¹å‡ ç§ä¸çŸ¥è¯†å›¾è°±ç›¸å…³çš„æ–¹æ³•è¿›è¡Œäº†ç»¼è¿°ã€‚ç„¶è€Œï¼Œè¿„ä»Šä¸ºæ­¢ï¼Œä»ç¼ºä¹å¯¹å·²å»ºç«‹ä¸»é¢˜çš„ç»¼åˆç ”ç©¶ï¼Œå¹¶å¯¹ä¸ªåˆ«ç ”ç©¶æµçš„æˆç†Ÿåº¦è¿›è¡Œå›é¡¾ã€‚ä¸ºå¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬ç³»ç»Ÿåœ°åˆ†æäº†507ç¯‡å…³äºNLPä¸­çŸ¥è¯†å›¾è°±çš„æ–‡çŒ®ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å‘ˆç°äº†ç ”ç©¶é¢†åŸŸçš„ç»“æ„åŒ–æ¦‚è¿°ï¼Œæä¾›äº†ä»»åŠ¡åˆ†ç±»æ³•ï¼Œæ€»ç»“äº†æˆ‘ä»¬çš„å‘ç°ï¼Œå¹¶å¼ºè°ƒäº†æœªæ¥å·¥ä½œçš„æ–¹å‘ã€‚'
- en: What is Natural Language Processing?
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ï¼Ÿ
- en: Natural language processing (NLP) is a subfield of [linguistics](https://en.wikipedia.org/wiki/Linguistics),
    [computer science](https://en.wikipedia.org/wiki/Computer_science), and [artificial
    intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence) concerned
    with the interactions between computers and human language, in particular how
    to program computers to process and analyze large amounts of [natural language](https://en.wikipedia.org/wiki/Natural_language)
    data([Wikipedia](https://en.wikipedia.org/wiki/Natural_language_processing)).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æ˜¯[è¯­è¨€å­¦](https://en.wikipedia.org/wiki/Linguistics)ã€[è®¡ç®—æœºç§‘å­¦](https://en.wikipedia.org/wiki/Computer_science)å’Œ[äººå·¥æ™ºèƒ½](https://en.wikipedia.org/wiki/Artificial_intelligence)çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œæ¶‰åŠè®¡ç®—æœºä¸äººç±»è¯­è¨€ä¹‹é—´çš„äº’åŠ¨ï¼Œç‰¹åˆ«æ˜¯å¦‚ä½•ç¼–ç¨‹è®¡ç®—æœºä»¥å¤„ç†å’Œåˆ†æå¤§é‡çš„[è‡ªç„¶è¯­è¨€](https://en.wikipedia.org/wiki/Natural_language)æ•°æ®ï¼ˆ[Wikipedia](https://en.wikipedia.org/wiki/Natural_language_processing)ï¼‰ã€‚
- en: What are Knowledge Graphs?
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: çŸ¥è¯†å›¾è°±æ˜¯ä»€ä¹ˆï¼Ÿ
- en: KGs have emerged as an approach for semantically representing knowledge about
    real-world entities in a machine-readable format. Most works implicitly adopt
    a broad definition of KGs, wherethey are understood as *â€œ****a graph of data intended
    to accumulate and convey knowledge of the real world, whose nodes represent entities
    of interest and whose edges represent relations between these entitiesâ€*** ([Hogan
    et al., 2022](https://dl.acm.org/doi/10.1145/3447772)).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: çŸ¥è¯†å›¾è°±ä½œä¸ºä»¥æœºå™¨å¯è¯»æ ¼å¼è¯­ä¹‰åŒ–è¡¨ç¤ºç°å®ä¸–ç•Œå®ä½“çš„ä¸€ä¸ªæ–¹æ³•å·²ç»å‡ºç°ã€‚å¤§å¤šæ•°ç ”ç©¶éšå«åœ°é‡‡ç”¨äº†çŸ¥è¯†å›¾è°±çš„å¹¿æ³›å®šä¹‰ï¼Œå³*â€œä¸€ä¸ªæ—¨åœ¨ç§¯ç´¯å’Œä¼ è¾¾ç°å®ä¸–ç•ŒçŸ¥è¯†çš„å›¾è°±ï¼Œå…¶ä¸­èŠ‚ç‚¹ä»£è¡¨æ„Ÿå…´è¶£çš„å®ä½“ï¼Œè¾¹ä»£è¡¨è¿™äº›å®ä½“ä¹‹é—´çš„å…³ç³»â€*ï¼ˆ[Hogan
    et al., 2022](https://dl.acm.org/doi/10.1145/3447772)ï¼‰ã€‚
- en: '**Why do we use Knowledge Graphs in NLP?**'
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**æˆ‘ä»¬ä¸ºä»€ä¹ˆåœ¨NLPä¸­ä½¿ç”¨çŸ¥è¯†å›¾è°±ï¼Ÿ**'
- en: The underlying paradigm is that the combination of structured and unstructured
    knowledge can benefit all kinds of NLP tasks. For instance, structured knowledge
    from KGs can be injected into that of the contextual knowledge found in language
    models, which improves the performance in downstream tasks ([Colon-Hernandez et
    al., 2021](https://arxiv.org/abs/2101.12294)). Furthermore, given the current
    public discussions about Large Language Models, such as ChatGPT, we may use KGs
    to verify and, if necessary, correct hallucinated and false statements of generative
    models. Additionally, with the growing importance of KGs, there are also expanding
    efforts to construct new KGs from unstructured texts.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶åŸºæœ¬èŒƒå¼æ˜¯ç»“æ„åŒ–å’Œéç»“æ„åŒ–çŸ¥è¯†çš„ç»“åˆå¯ä»¥ä½¿æ‰€æœ‰ç±»å‹çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡å—ç›Šã€‚ä¾‹å¦‚ï¼Œå°†çŸ¥è¯†å›¾è°±ä¸­çš„ç»“æ„åŒ–çŸ¥è¯†æ³¨å…¥è¯­è¨€æ¨¡å‹ä¸­çš„ä¸Šä¸‹æ–‡çŸ¥è¯†ï¼Œå¯ä»¥æå‡ä¸‹æ¸¸ä»»åŠ¡çš„æ€§èƒ½ï¼ˆ[Colon-Hernandez
    et al., 2021](https://arxiv.org/abs/2101.12294)ï¼‰ã€‚æ­¤å¤–ï¼Œé‰´äºç›®å‰å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ChatGPTï¼‰çš„å…¬ä¼—è®¨è®ºï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨çŸ¥è¯†å›¾è°±æ¥éªŒè¯å¹¶åœ¨å¿…è¦æ—¶çº æ­£ç”Ÿæˆæ¨¡å‹ä¸­çš„è™šå‡å’Œé”™è¯¯é™ˆè¿°ã€‚éšç€çŸ¥è¯†å›¾è°±é‡è¦æ€§çš„æ—¥ç›Šå¢åŠ ï¼Œä¹Ÿæœ‰è¶Šæ¥è¶Šå¤šçš„åŠªåŠ›åœ¨ä»éç»“æ„åŒ–æ–‡æœ¬ä¸­æ„å»ºæ–°çš„çŸ¥è¯†å›¾è°±ã€‚
- en: How are Knowledge Graphs used in NLP?
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: çŸ¥è¯†å›¾è°±åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åº”ç”¨æ˜¯ä»€ä¹ˆï¼Ÿ
- en: Characteristics of the Research Landscape ğŸï¸
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç ”ç©¶é¢†åŸŸçš„ç‰¹ç‚¹ ğŸï¸
- en: The figure below shows the distribution of publications over a ten-year observation
    period.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹å›¾å±•ç¤ºäº†åå¹´è§‚å¯ŸæœŸå†…çš„å‡ºç‰ˆç‰©åˆ†å¸ƒæƒ…å†µã€‚
- en: '![](../Images/053913c7ce26b03916cfef5ffd7017a1.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/053913c7ce26b03916cfef5ffd7017a1.png)'
- en: Distribution of number of papers from 2012 to 2021 (image by author).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 2012å¹´è‡³2021å¹´çš„è®ºæ–‡æ•°é‡åˆ†å¸ƒï¼ˆå›¾åƒç”±ä½œè€…æä¾›ï¼‰ã€‚
- en: While the first publications appear in 2013, the annual publications grew slowly
    between 2013 and 2016\. From 2017 onwards, the number of publications doubled
    almost every year. Because of the significant rise in research interest within
    these years, more than 90% of all publications originate from these five years.
    Even though the growth trend seems to stop in 2021, this is likely due to the
    data export which happened in the first week of 2022, leaving out many studies
    from 2021 that were enlisted in the databases later in 2022\. Nonetheless, the
    trend clearly indicates that KGs are receiving increasing attention from the NLP
    research community.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡ç¬¬ä¸€ç¯‡å‡ºç‰ˆç‰©å‡ºç°äº2013å¹´ï¼Œä½†2013å¹´è‡³2016å¹´é—´ï¼Œå¹´åº¦å‡ºç‰ˆç‰©æ•°é‡å¢é•¿ç¼“æ…¢ã€‚ä»2017å¹´èµ·ï¼Œå‡ºç‰ˆç‰©æ•°é‡å‡ ä¹æ¯å¹´ç¿»å€ã€‚ç”±äºè¿™äº›å¹´å†…ç ”ç©¶å…´è¶£çš„æ˜¾è‘—ä¸Šå‡ï¼Œ90%ä»¥ä¸Šçš„å‡ºç‰ˆç‰©éƒ½æ¥æºäºè¿™äº”å¹´ã€‚å°½ç®¡2021å¹´çš„å¢é•¿è¶‹åŠ¿ä¼¼ä¹åœæ­¢äº†ï¼Œè¿™å¾ˆå¯èƒ½æ˜¯å› ä¸ºæ•°æ®å¯¼å‡ºå‘ç”Ÿåœ¨2022å¹´ç¬¬ä¸€å‘¨ï¼Œé—æ¼äº†è®¸å¤š2021å¹´çš„ç ”ç©¶ï¼Œè¿™äº›ç ”ç©¶åœ¨2022å¹´æ™šäº›æ—¶å€™æ‰è¢«åˆ—å…¥æ•°æ®åº“ã€‚ç„¶è€Œï¼Œè¿™ä¸€è¶‹åŠ¿æ¸…æ¥šåœ°è¡¨æ˜ï¼ŒçŸ¥è¯†å›¾è°±æ­£å—åˆ°è‡ªç„¶è¯­è¨€å¤„ç†ç ”ç©¶ç¤¾åŒºè¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚
- en: In addition, we observed that the number of domains explored in the research
    literature grew rapidly in parallel with the annual count of papers. In the figure
    below, the ten most frequent domains are displayed.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œç ”ç©¶æ–‡çŒ®ä¸­æ¢ç´¢çš„é¢†åŸŸæ•°é‡è¿…é€Ÿå¢é•¿ï¼Œä¸å¹´åº¦è®ºæ–‡æ•°é‡ç›¸åŒ¹é…ã€‚åœ¨ä¸‹å›¾ä¸­ï¼Œæ˜¾ç¤ºäº†åä¸ªæœ€é¢‘ç¹çš„é¢†åŸŸã€‚
- en: '![](../Images/621378379fd793ddc615aaa93f948828.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/621378379fd793ddc615aaa93f948828.png)'
- en: Number of papers by most popular application domains (image by author).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æŒ‰æœ€çƒ­é—¨åº”ç”¨é¢†åŸŸåˆ’åˆ†çš„è®ºæ–‡æ•°é‡ï¼ˆå›¾åƒç”±ä½œè€…æä¾›ï¼‰ã€‚
- en: It is striking that health is by far the most prominent domain. The latter appears
    more than twice as often as the scholarly domain, which ranks second. Other popular
    areas are engineering, business, social media, or law. In view of the domain diversity,
    it becomes evident that KGs are naturally applicable to many different contexts.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¾è‘—çš„æ˜¯ï¼Œå¥åº·é¢†åŸŸè¿œè¿œæ˜¯æœ€çªå‡ºçš„é¢†åŸŸã€‚å¥åº·é¢†åŸŸå‡ºç°çš„é¢‘ç‡æ˜¯å­¦æœ¯é¢†åŸŸçš„ä¸¤å€å¤šï¼Œåè€…æ’åœ¨ç¬¬äºŒä½ã€‚å…¶ä»–çƒ­é—¨é¢†åŸŸåŒ…æ‹¬å·¥ç¨‹ã€å•†ä¸šã€ç¤¾äº¤åª’ä½“æˆ–æ³•å¾‹ã€‚è€ƒè™‘åˆ°é¢†åŸŸçš„å¤šæ ·æ€§ï¼Œæ˜¾è€Œæ˜“è§ï¼ŒçŸ¥è¯†å›¾è°±è‡ªç„¶é€‚ç”¨äºè®¸å¤šä¸åŒçš„æƒ…å¢ƒã€‚
- en: Tasks in the Research Literature ğŸ“–
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç ”ç©¶æ–‡çŒ®ä¸­çš„ä»»åŠ¡ ğŸ“–
- en: Based on the tasks identified in the literature on KGs in NLP, we developed
    the empirical taxonomy shown below.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºæ–‡çŒ®ä¸­å…³äºçŸ¥è¯†å›¾è°±çš„ä»»åŠ¡ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸‹å›¾æ‰€ç¤ºçš„å®è¯åˆ†ç±»æ³•ã€‚
- en: '![](../Images/70692a9fa6f645027ae0d7db9eaa4756.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/70692a9fa6f645027ae0d7db9eaa4756.png)'
- en: Taxonomy of tasks that involve Knowledge Graphs in Natural Language Processing
    (image by author).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æ¶‰åŠè‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„çŸ¥è¯†å›¾è°±çš„ä»»åŠ¡åˆ†ç±»ï¼ˆå›¾åƒç”±ä½œè€…æä¾›ï¼‰ã€‚
- en: 'The two top-level categories consist of knowledge acquisition and knowledge
    application. **Knowledge acquisition** contains NLP tasks to construct KGs from
    unstructured text (**knowledge graph construction**) or to conduct reasoning over
    already constructed KGs (**knowledge graph reasoning**). KG construction tasks
    are further split into two subcategories: **knowledge extraction**, which is used
    to populate KGs with entities, relations, or attributes, and **knowledge integration**,
    which is used to update KGs. **Knowledge application**, being the second top-level
    concept, encompasses common NLP tasks, which are enhanced through structured knowledge
    from KGs.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸¤ä¸ªé¡¶çº§ç±»åˆ«åŒ…æ‹¬çŸ¥è¯†è·å–å’ŒçŸ¥è¯†åº”ç”¨ã€‚**çŸ¥è¯†è·å–**åŒ…å«ä»éç»“æ„åŒ–æ–‡æœ¬ä¸­æ„å»ºçŸ¥è¯†å›¾è°±çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼ˆ**çŸ¥è¯†å›¾è°±æ„å»º**ï¼‰æˆ–å¯¹å·²ç»æ„å»ºçš„çŸ¥è¯†å›¾è°±è¿›è¡Œæ¨ç†ï¼ˆ**çŸ¥è¯†å›¾è°±æ¨ç†**ï¼‰ã€‚çŸ¥è¯†å›¾è°±æ„å»ºä»»åŠ¡è¿›ä¸€æ­¥åˆ†ä¸ºä¸¤ä¸ªå­ç±»åˆ«ï¼š**çŸ¥è¯†æå–**ï¼Œç”¨äºå°†å®ä½“ã€å…³ç³»æˆ–å±æ€§å¡«å……åˆ°çŸ¥è¯†å›¾è°±ä¸­ï¼Œä»¥åŠ**çŸ¥è¯†æ•´åˆ**ï¼Œç”¨äºæ›´æ–°çŸ¥è¯†å›¾è°±ã€‚**çŸ¥è¯†åº”ç”¨**ä½œä¸ºç¬¬äºŒä¸ªé¡¶çº§æ¦‚å¿µï¼Œæ¶µç›–äº†é€šè¿‡çŸ¥è¯†å›¾è°±çš„ç»“æ„åŒ–çŸ¥è¯†æ¥å¢å¼ºçš„å¸¸è§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚
- en: '**Knowledge Graph Construction ğŸ—ï¸**'
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**çŸ¥è¯†å›¾è°±æ„å»º ğŸ—ï¸**'
- en: The task of **entity extraction** is a starting point in constructing KGs and
    is used to derive real-world entities from unstructured text. Once the relevant
    entities are singled out, relationships and interactions between them are found
    with the task of **relation extraction**. A lot of papers use both entity exraction
    and relation extraction to construct new KGs, e.g., for news events or scholarly
    research. **Entity linking** is a task of linking entities recognized in some
    text to already existing entities in KGs. Since synonymous or similar entities
    often exist in different KGs or in different languages, **entity alignment** can
    be performed to reduce redundancy and repetition in future tasks. Coming up with
    the rules and schemes of KGs, i.e., their structure and format of knowledge presented
    in it, is done with the task of **ontology construction**.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**å®ä½“æå–**çš„ä»»åŠ¡æ˜¯æ„å»ºçŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰çš„èµ·ç‚¹ï¼Œç”¨äºä»éç»“æ„åŒ–æ–‡æœ¬ä¸­æå–ç°å®ä¸–ç•Œçš„å®ä½“ã€‚ä¸€æ—¦ç›¸å…³å®ä½“è¢«è¯†åˆ«å‡ºæ¥ï¼Œå°±ä¼šé€šè¿‡**å…³ç³»æå–**ä»»åŠ¡æ‰¾å‡ºå®ƒä»¬ä¹‹é—´çš„å…³ç³»å’Œäº’åŠ¨ã€‚è®¸å¤šè®ºæ–‡ä½¿ç”¨å®ä½“æå–å’Œå…³ç³»æå–æ¥æ„å»ºæ–°çš„çŸ¥è¯†å›¾è°±ï¼Œä¾‹å¦‚ï¼Œç”¨äºæ–°é—»äº‹ä»¶æˆ–å­¦æœ¯ç ”ç©¶ã€‚**å®ä½“é“¾æ¥**æ˜¯å°†æ–‡æœ¬ä¸­è¯†åˆ«å‡ºçš„å®ä½“ä¸çŸ¥è¯†å›¾è°±ä¸­å·²å­˜åœ¨çš„å®ä½“è¿›è¡Œé“¾æ¥çš„ä»»åŠ¡ã€‚ç”±äºåŒä¹‰æˆ–ç±»ä¼¼çš„å®ä½“å¸¸å¸¸å­˜åœ¨äºä¸åŒçš„çŸ¥è¯†å›¾è°±æˆ–ä¸åŒçš„è¯­è¨€ä¸­ï¼Œ**å®ä½“å¯¹é½**å¯ä»¥è¢«æ‰§è¡Œï¼Œä»¥å‡å°‘æœªæ¥ä»»åŠ¡ä¸­çš„å†—ä½™å’Œé‡å¤ã€‚åˆ¶å®šçŸ¥è¯†å›¾è°±çš„è§„åˆ™å’Œæ–¹æ¡ˆï¼Œå³å…¶ç»“æ„å’ŒçŸ¥è¯†å±•ç¤ºçš„æ ¼å¼ï¼Œæ˜¯é€šè¿‡**æœ¬ä½“æ„å»º**ä»»åŠ¡å®Œæˆçš„ã€‚'
- en: '**Knowledge Graph Reasoning** ğŸ§ '
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**çŸ¥è¯†å›¾è°±æ¨ç†** ğŸ§ '
- en: Once constructed, KGs contain structured world knowledge and can be used to
    infer new knowledge by reasoning over them. Thereby, the task of classifying entities
    is called **entity classification**, while **link prediction** is the task of
    inferring missing links between entities in existing KGs often performed via ranking
    entities as possible answers to queries. **Knowledge graph embedding** techniques
    are used to create dense vector representations of a graph so that they can then
    be used for downstream machine learning tasks.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ„å»ºå®Œæˆï¼ŒçŸ¥è¯†å›¾è°±åŒ…å«ç»“æ„åŒ–çš„ä¸–ç•ŒçŸ¥è¯†ï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡æ¨ç†å¾—å‡ºæ–°çš„çŸ¥è¯†ã€‚å› æ­¤ï¼Œåˆ†ç±»å®ä½“çš„ä»»åŠ¡è¢«ç§°ä¸º**å®ä½“åˆ†ç±»**ï¼Œè€Œ**é“¾æ¥é¢„æµ‹**æ˜¯æ¨æ–­ç°æœ‰çŸ¥è¯†å›¾è°±ä¸­å®ä½“ä¹‹é—´ç¼ºå¤±é“¾æ¥çš„ä»»åŠ¡ï¼Œé€šå¸¸é€šè¿‡å¯¹å®ä½“è¿›è¡Œæ’åºä½œä¸ºæŸ¥è¯¢çš„å¯èƒ½ç­”æ¡ˆã€‚**çŸ¥è¯†å›¾è°±åµŒå…¥**æŠ€æœ¯ç”¨äºåˆ›å»ºå›¾çš„å¯†é›†å‘é‡è¡¨ç¤ºï¼Œä»¥ä¾¿å¯ä»¥ç”¨äºä¸‹æ¸¸çš„æœºå™¨å­¦ä¹ ä»»åŠ¡ã€‚
- en: '**Knowledge Application** ğŸ› ï¸'
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**çŸ¥è¯†åº”ç”¨** ğŸ› ï¸'
- en: Existing KGs can be used in a multitude of popular NLP tasks. Here we outline
    the most popular ones. **Question answering (QA)** was found to be the most common
    NLP task using KGs. This task is typically divided into textual QA and question
    answering over knowledge bases (KBQA). Textual QA derives answers from unstructured
    documents while KBQA does so from predefined knowledge bases. KBQA is naturally
    tied to KGs while textual QA can also be approached by using KGs as a source of
    common-sense knowledge when answering questions. This approach is desired not
    only because it is helpful for generating answers, but also because it makes answers
    more interpretable. **Semantic search** refers to â€œsearch with meaningâ€, where
    the goal is not just to search for literal matches, but to understand the search
    intent and query context as well. This label denoted studies that use KGs for
    search, recommendations, and analytics. Examples are a big semantic network of
    everyday concepts called ConceptNet and a KG of scholarly communications and the
    relationships, among them the Microsoft Academic Graph. **Conversational interfaces**
    constitute another NLP field that can benefit from world knowledge contained in
    KGs. We can utilize the knowledge from KGs to generate responses of conversational
    agents that are more informative and appropriate in a given context.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ç°æœ‰çš„çŸ¥è¯†å›¾è°±å¯ä»¥ç”¨äºå¤šç§æµè¡Œçš„è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä»»åŠ¡ã€‚è¿™é‡Œæˆ‘ä»¬æ¦‚è¿°äº†æœ€å¸¸è§çš„ä»»åŠ¡ã€‚**é—®ç­”ï¼ˆQAï¼‰**è¢«å‘ç°æ˜¯ä½¿ç”¨çŸ¥è¯†å›¾è°±çš„æœ€å¸¸è§NLPä»»åŠ¡ã€‚è¿™ä¸ªä»»åŠ¡é€šå¸¸è¢«åˆ†ä¸ºæ–‡æœ¬é—®ç­”å’ŒåŸºäºçŸ¥è¯†åº“çš„é—®ç­”ï¼ˆKBQAï¼‰ã€‚æ–‡æœ¬é—®ç­”ä»éç»“æ„åŒ–æ–‡æ¡£ä¸­æå–ç­”æ¡ˆï¼Œè€ŒKBQAåˆ™ä»é¢„å®šä¹‰çš„çŸ¥è¯†åº“ä¸­æå–ç­”æ¡ˆã€‚KBQAè‡ªç„¶ä¸çŸ¥è¯†å›¾è°±ç´§å¯†ç›¸å…³ï¼Œè€Œæ–‡æœ¬é—®ç­”ä¹Ÿå¯ä»¥é€šè¿‡ä½¿ç”¨çŸ¥è¯†å›¾è°±ä½œä¸ºå›ç­”é—®é¢˜çš„å¸¸è¯†çŸ¥è¯†æ¥æºæ¥è¿›è¡Œã€‚è¿™ç§æ–¹æ³•ä¸ä»…æœ‰åŠ©äºç”Ÿæˆç­”æ¡ˆï¼Œè¿˜ä½¿ç­”æ¡ˆæ›´åŠ å¯è§£é‡Šã€‚**è¯­ä¹‰æœç´¢**æŒ‡çš„æ˜¯â€œæœ‰æ„ä¹‰çš„æœç´¢â€ï¼Œå…¶ç›®æ ‡ä¸ä»…ä»…æ˜¯æœç´¢å­—é¢åŒ¹é…ï¼Œè¿˜è¦ç†è§£æœç´¢æ„å›¾å’ŒæŸ¥è¯¢ä¸Šä¸‹æ–‡ã€‚è¿™ä¸ªæ ‡ç­¾è¡¨ç¤ºäº†åˆ©ç”¨çŸ¥è¯†å›¾è°±è¿›è¡Œæœç´¢ã€æ¨èå’Œåˆ†æçš„ç ”ç©¶ã€‚ä¾‹å¦‚ï¼Œå¤§å‹è¯­ä¹‰ç½‘ç»œæ¦‚å¿µç½‘ï¼ˆConceptNetï¼‰å’Œå­¦æœ¯äº¤æµåŠå…¶å…³ç³»çš„çŸ¥è¯†å›¾è°±â€”â€”å¾®è½¯å­¦æœ¯å›¾è°±ï¼ˆMicrosoft
    Academic Graphï¼‰ã€‚**å¯¹è¯ç•Œé¢**æ˜¯å¦ä¸€ä¸ªå¯ä»¥å—ç›ŠäºçŸ¥è¯†å›¾è°±ä¸­ä¸–ç•ŒçŸ¥è¯†çš„NLPé¢†åŸŸã€‚æˆ‘ä»¬å¯ä»¥åˆ©ç”¨çŸ¥è¯†å›¾è°±ä¸­çš„çŸ¥è¯†æ¥ç”Ÿæˆåœ¨ç‰¹å®šä¸Šä¸‹æ–‡ä¸­æ›´å…·ä¿¡æ¯æ€§å’Œé€‚å½“æ€§çš„å¯¹è¯ä»£ç†å“åº”ã€‚
- en: '**Natural language generation (NLG)** is a subfield of NLP and computational
    linguistics that is concerned with models which generate natural language output
    from scratch. KGs are used in this subfield for producing natural language text
    from KGs, generating question-answer pairs, the multi-modal task of image captioning,
    or data augmentation in low-resource settings. **Text analysis** combines various
    analytical NLP techniques and methods that are applied to process and understand
    textual data. Exemplary tasks are sentiment detection, topic modeling, or word
    sense disambiguation. **Augmented language models** are a combination of large
    pretrained language models (PLMs) such as BERT ([Devlin et al., 2019](https://aclanthology.org/N19-1423.pdf))
    and GPT ([Radford et al., 2018](https://gwern.net/doc/www/s3-us-west-2.amazonaws.com/d73fdc5ffa8627bce44dcda2fc012da638ffb158.pdf))
    with knowledge contained in KGs. Since PLMs derive their knowledge from huge amounts
    of unstructured training data, a rising research trend is in combining them with
    structured knowledge. Knowledge from KGs can be infused into language models in
    their input, architecture, output, or some combination thereof.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**è‡ªç„¶è¯­è¨€ç”Ÿæˆï¼ˆNLGï¼‰** æ˜¯ NLP å’Œè®¡ç®—è¯­è¨€å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œå…³æ³¨äºä»å¤´ç”Ÿæˆè‡ªç„¶è¯­è¨€è¾“å‡ºçš„æ¨¡å‹ã€‚çŸ¥è¯†å›¾è°±åœ¨è¿™ä¸ªå­é¢†åŸŸä¸­ç”¨äºä»çŸ¥è¯†å›¾è°±ç”Ÿæˆè‡ªç„¶è¯­è¨€æ–‡æœ¬ã€ç”Ÿæˆé—®ç­”å¯¹ã€å¤šæ¨¡æ€ä»»åŠ¡ä¸­çš„å›¾åƒæè¿°ï¼Œæˆ–åœ¨ä½èµ„æºç¯å¢ƒä¸‹è¿›è¡Œæ•°æ®å¢å¼ºã€‚**æ–‡æœ¬åˆ†æ**
    ç»“åˆäº†å„ç§åˆ†ææ€§ NLP æŠ€æœ¯å’Œæ–¹æ³•ï¼Œç”¨äºå¤„ç†å’Œç†è§£æ–‡æœ¬æ•°æ®ã€‚å…¸å‹ä»»åŠ¡åŒ…æ‹¬æƒ…æ„Ÿæ£€æµ‹ã€ä¸»é¢˜å»ºæ¨¡æˆ–è¯ä¹‰æ¶ˆæ­§ã€‚**å¢å¼ºå‹è¯­è¨€æ¨¡å‹** æ˜¯å°†è¯¸å¦‚ BERT ([Devlin
    et al., 2019](https://aclanthology.org/N19-1423.pdf)) å’Œ GPT ([Radford et al.,
    2018](https://gwern.net/doc/www/s3-us-west-2.amazonaws.com/d73fdc5ffa8627bce44dcda2fc012da638ffb158.pdf))
    ç­‰å¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ä¸çŸ¥è¯†å›¾è°±ä¸­åŒ…å«çš„çŸ¥è¯†ç›¸ç»“åˆã€‚ç”±äºé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ä»å¤§é‡çš„éç»“æ„åŒ–è®­ç»ƒæ•°æ®ä¸­è·å–çŸ¥è¯†ï¼Œä¸€ç§ä¸Šå‡çš„ç ”ç©¶è¶‹åŠ¿æ˜¯å°†å®ƒä»¬ä¸ç»“æ„åŒ–çŸ¥è¯†ç»“åˆèµ·æ¥ã€‚çŸ¥è¯†å›¾è°±ä¸­çš„çŸ¥è¯†å¯ä»¥æ³¨å…¥åˆ°è¯­è¨€æ¨¡å‹çš„è¾“å…¥ã€æ¶æ„ã€è¾“å‡ºæˆ–å…¶ç»„åˆä¸­ã€‚'
- en: Popular Tasks using Knowledge Graphs in NLP ğŸ“ˆ
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨çŸ¥è¯†å›¾è°±åœ¨ NLP ä¸­çš„çƒ­é—¨ä»»åŠ¡ ğŸ“ˆ
- en: The figure below shows the most popular tasks using KGs in NLP.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹å›¾å±•ç¤ºäº†åœ¨ NLP ä¸­ä½¿ç”¨çŸ¥è¯†å›¾è°±çš„æœ€å—æ¬¢è¿çš„ä»»åŠ¡ã€‚
- en: '![](../Images/35a9cd61c6cb49ed237845051447d341.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/35a9cd61c6cb49ed237845051447d341.png)'
- en: Distribution of number of papers by most popular tasks from 2013 to 2021 (image
    by author).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 2013 å¹´è‡³ 2021 å¹´é—´æœ€å—æ¬¢è¿ä»»åŠ¡çš„è®ºæ–‡æ•°é‡åˆ†å¸ƒï¼ˆå›¾åƒä½œè€…æä¾›ï¼‰ã€‚
- en: We can observe, that tasks, such as relation extraction or semantic search,
    have already existed for some time and continue to grow steadily. In our study,
    we use this, among others, as an indicator to conclude that tasks such as relation
    extraction or semantic search are already reasonably mature. In contrast, augmented
    language models and knowledge graph embedding tasks can still be considered relatively
    immature. This may be a result of the fact that these tasks are still relatively
    young and less investigated. The figure above shows that the two tasks have only
    seen a sharp increase in studies from 2018 onwards and attracted a lot of interest
    since then.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥è§‚å¯Ÿåˆ°ï¼Œè¯¸å¦‚å…³ç³»æå–æˆ–è¯­ä¹‰æœç´¢ç­‰ä»»åŠ¡å·²ç»å­˜åœ¨äº†ä¸€æ®µæ—¶é—´ï¼Œå¹¶ä¸”æŒç»­ç¨³æ­¥å¢é•¿ã€‚åœ¨æˆ‘ä»¬çš„ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å°†è¿™äº›ä»»åŠ¡ä½œä¸ºæŒ‡æ ‡ä¹‹ä¸€ï¼Œä»¥å¾—å‡ºå…³ç³»æå–æˆ–è¯­ä¹‰æœç´¢ç­‰ä»»åŠ¡å·²ç»ç›¸å¯¹æˆç†Ÿçš„ç»“è®ºã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå¢å¼ºå‹è¯­è¨€æ¨¡å‹å’ŒçŸ¥è¯†å›¾è°±åµŒå…¥ä»»åŠ¡ä»ç„¶å¯ä»¥è¢«è®¤ä¸ºç›¸å¯¹ä¸æˆç†Ÿã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºè¿™äº›ä»»åŠ¡ä»ç„¶ç›¸å¯¹å¹´è½»ï¼Œä¸”ç ”ç©¶è¾ƒå°‘ã€‚ä¸Šå›¾æ˜¾ç¤ºï¼Œè¿™ä¸¤é¡¹ä»»åŠ¡ä»
    2018 å¹´å¼€å§‹ç ”ç©¶æ•°é‡æ€¥å‰§å¢åŠ ï¼Œå¹¶è‡ªé‚£æ—¶èµ·å¸å¼•äº†å¤§é‡å…´è¶£ã€‚
- en: Conclusion ğŸ’¡
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º ğŸ’¡
- en: Recent years have witnessed a rising prominence of KGs in NLP research. Since
    the first publications in 2013, researchers worldwide have paid increasing attention
    to study KGs from a NLP perspective, especially in the past five years. To provide
    an overview of this maturing research area, we performed a multifaceted survey
    about the use of KGs in NLP. Our findings show that a large number of tasks concerning
    KGs in NLP have been studied across various domains. Papers concerning KG construction
    using entity extraction and relation extraction account for the majority of all
    works. Applied NLP tasks such as QA and semantic search also have a strong research
    community. The most emergent topics in recent years have been augmented language
    models, QA, and KG embeddings.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: è¿‘å¹´æ¥ï¼ŒçŸ¥è¯†å›¾è°±åœ¨ NLP ç ”ç©¶ä¸­çš„é‡è¦æ€§æ—¥ç›Šæå‡ã€‚è‡ª 2013 å¹´é¦–æ¬¡å‘è¡¨ç›¸å…³æ–‡çŒ®ä»¥æ¥ï¼Œå…¨çƒç ”ç©¶äººå‘˜å¯¹ä» NLP è§’åº¦ç ”ç©¶çŸ¥è¯†å›¾è°±ç»™äºˆäº†è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ï¼Œç‰¹åˆ«æ˜¯åœ¨è¿‡å»äº”å¹´ä¸­ã€‚ä¸ºäº†æä¾›è¿™ä¸€æˆç†Ÿç ”ç©¶é¢†åŸŸçš„æ¦‚è¿°ï¼Œæˆ‘ä»¬å¯¹çŸ¥è¯†å›¾è°±åœ¨
    NLP ä¸­çš„åº”ç”¨è¿›è¡Œäº†å¤šæ–¹é¢çš„è°ƒæŸ¥ã€‚æˆ‘ä»¬çš„å‘ç°æ˜¾ç¤ºï¼Œå¤§é‡æ¶‰åŠçŸ¥è¯†å›¾è°±çš„ NLP ä»»åŠ¡å·²åœ¨å„ä¸ªé¢†åŸŸå¾—åˆ°äº†ç ”ç©¶ã€‚æ¶‰åŠä½¿ç”¨å®ä½“æå–å’Œå…³ç³»æå–æ„å»ºçŸ¥è¯†å›¾è°±çš„è®ºæ–‡å æ‰€æœ‰å·¥ä½œçš„ä¸»è¦éƒ¨åˆ†ã€‚åº”ç”¨çš„
    NLP ä»»åŠ¡ï¼Œå¦‚ QA å’Œè¯­ä¹‰æœç´¢ï¼Œä¹Ÿæœ‰ç€å¼ºå¤§çš„ç ”ç©¶ç¤¾åŒºã€‚è¿‘å¹´æ¥æœ€çªå‡ºçš„ä¸»é¢˜æ˜¯å¢å¼ºå‹è¯­è¨€æ¨¡å‹ã€QA å’ŒçŸ¥è¯†å›¾è°±åµŒå…¥ã€‚
- en: Some of the outlined tasks are still confined to the research community, while
    others have found practical application in many real-life contexts. We observed
    that the KG construction tasks and semantic search over KGs are the most widely
    applied ones. Of the NLP tasks, QA and conversational interfaces have been adopted
    to many real-life domains, usually in the form of digital assistants. Tasks like
    KG embedding and augmented language models are still only being researched and
    lack a widespread practical adoption in real-world scenarios. We anticipate that
    as the research areas of augmented language models and KG embedding mature, more
    methods and tools will be investigated for these tasks.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›æ¦‚è¿°çš„ä»»åŠ¡ä»ç„¶å±€é™äºç ”ç©¶é¢†åŸŸï¼Œè€Œå¦ä¸€äº›ä»»åŠ¡å·²ç»åœ¨è®¸å¤šå®é™…åº”ç”¨ä¸­æ‰¾åˆ°äº†åº”ç”¨ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼ŒçŸ¥è¯†å›¾è°±çš„æ„å»ºä»»åŠ¡å’Œå¯¹çŸ¥è¯†å›¾è°±çš„è¯­ä¹‰æœç´¢æ˜¯æœ€å¹¿æ³›åº”ç”¨çš„ä»»åŠ¡ã€‚åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­ï¼Œé—®ç­”ç³»ç»Ÿå’Œå¯¹è¯æ¥å£å·²ç»è¢«åº”ç”¨åˆ°è®¸å¤šç°å®ç”Ÿæ´»é¢†åŸŸï¼Œé€šå¸¸ä»¥æ•°å­—åŠ©æ‰‹çš„å½¢å¼å‡ºç°ã€‚åƒçŸ¥è¯†å›¾è°±åµŒå…¥å’Œå¢å¼ºè¯­è¨€æ¨¡å‹è¿™æ ·çš„ä»»åŠ¡ä»åœ¨ç ”ç©¶ä¸­ï¼Œåœ¨å®é™…åœºæ™¯ä¸­å°šæœªå¾—åˆ°å¹¿æ³›åº”ç”¨ã€‚æˆ‘ä»¬é¢„æœŸï¼Œéšç€å¢å¼ºè¯­è¨€æ¨¡å‹å’ŒçŸ¥è¯†å›¾è°±åµŒå…¥çš„ç ”ç©¶é¢†åŸŸæˆç†Ÿï¼Œå°†ä¼šæœ‰æ›´å¤šçš„æ–¹æ³•å’Œå·¥å…·è¢«ç ”ç©¶ç”¨äºè¿™äº›ä»»åŠ¡ã€‚
- en: Sources
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¥æº
- en: '[](https://aclanthology.org/2022.aacl-main.46/?source=post_page-----5fdb15abc2b3--------------------------------)
    [## A Decade of Knowledge Graphs in Natural Language Processing: A Survey'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://aclanthology.org/2022.aacl-main.46/?source=post_page-----5fdb15abc2b3--------------------------------)
    [## åå¹´çŸ¥è¯†å›¾è°±åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åº”ç”¨ï¼šä¸€é¡¹è°ƒæŸ¥'
- en: Phillip Schneider, Tim Schopf, Juraj Vladika, Mikhail Galkin, Elena Simperl,
    Florian Matthes. Proceedings of the 2ndâ€¦
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Phillip Schneider, Tim Schopf, Juraj Vladika, Mikhail Galkin, Elena Simperl,
    Florian Matthes. ç¬¬2å±Šä¼šè®®è®ºæ–‡é›†â€¦
- en: 'aclanthology.org](https://aclanthology.org/2022.aacl-main.46/?source=post_page-----5fdb15abc2b3--------------------------------)
    [](https://github.com/sebischair/KG-in-NLP-survey?source=post_page-----5fdb15abc2b3--------------------------------)
    [## GitHub - sebischair/KG-in-NLP-survey: This repository contains the annotated
    collection of 507â€¦'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[aclanthology.org](https://aclanthology.org/2022.aacl-main.46/?source=post_page-----5fdb15abc2b3--------------------------------)
    [](https://github.com/sebischair/KG-in-NLP-survey?source=post_page-----5fdb15abc2b3--------------------------------)
    [## GitHub - sebischair/KG-in-NLP-survey: æœ¬ä»“åº“åŒ…å«äº†507ç¯‡è¢«æ³¨é‡Šçš„è®ºæ–‡â€¦'
- en: 'This repository contains the annotated collection of 507 papers included in
    the study: "A Decade of Knowledge Graphs inâ€¦'
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æœ¬ä»“åº“åŒ…å«äº†507ç¯‡è¢«æ³¨é‡Šçš„è®ºæ–‡ï¼Œè¿™äº›è®ºæ–‡è¢«çº³å…¥äº†ç ”ç©¶ï¼šâ€œåå¹´çŸ¥è¯†å›¾è°±åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åº”ç”¨â€ã€‚
- en: github.com](https://github.com/sebischair/KG-in-NLP-survey?source=post_page-----5fdb15abc2b3--------------------------------)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/sebischair/KG-in-NLP-survey?source=post_page-----5fdb15abc2b3--------------------------------)'
