- en: A Decade of Knowledge Graphs in Natural Language Processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/a-decade-of-knowledge-graphs-in-natural-language-processing-5fdb15abc2b3?source=collection_archive---------8-----------------------#2023-03-14](https://towardsdatascience.com/a-decade-of-knowledge-graphs-in-natural-language-processing-5fdb15abc2b3?source=collection_archive---------8-----------------------#2023-03-14)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An overview of the research landscape combining structured and unstructured
    knowledge in NLP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@tim.schopf?source=post_page-----5fdb15abc2b3--------------------------------)[![Tim
    Schopf](../Images/7d98a87af243ae6a82f837aa04ac2675.png)](https://medium.com/@tim.schopf?source=post_page-----5fdb15abc2b3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5fdb15abc2b3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5fdb15abc2b3--------------------------------)
    [Tim Schopf](https://medium.com/@tim.schopf?source=post_page-----5fdb15abc2b3--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7fe3665aa3e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-decade-of-knowledge-graphs-in-natural-language-processing-5fdb15abc2b3&user=Tim+Schopf&userId=7fe3665aa3e3&source=post_page-7fe3665aa3e3----5fdb15abc2b3---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5fdb15abc2b3--------------------------------)
    ¬∑8 min read¬∑Mar 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5fdb15abc2b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-decade-of-knowledge-graphs-in-natural-language-processing-5fdb15abc2b3&user=Tim+Schopf&userId=7fe3665aa3e3&source=-----5fdb15abc2b3---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5fdb15abc2b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-decade-of-knowledge-graphs-in-natural-language-processing-5fdb15abc2b3&source=-----5fdb15abc2b3---------------------bookmark_footer-----------)![](../Images/c288205bdd2f7682d7f07f8bcfe638d9.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Billy Huynh](https://unsplash.com/@billy_huy?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '*This post is based on our AACL-IJCNLP 2022 paper* [*‚ÄúA Decade of Knowledge
    Graphs in Natural Language Processing: A Survey‚Äù*](https://aclanthology.org/2022.aacl-main.46/)*.
    You can read more details there.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Knowledge Graphs (KGs) have attracted a lot of attention** in both academia
    and industry since the introduction of Google‚Äôs KG in 2012 [(Singhal, 2012)](https://blog.google/products/search/introducing-knowledge-graph-things-not/).
    As a representation of semantic relations between entities, KGs have proven to
    be **particularly relevant for natural language processing (NLP)** and have experienced
    a rapid increase in popularity in recent years, a trend that appears to be accelerating
    üöÄ. Given the increasing amount of research work in this area, several KG-related
    approaches have been surveyed in the NLP research community. However, a comprehensive
    study that categorizes established topics and reviews the maturity of individual
    research streams remains absent to this day. Contributing to closing this gap,
    we systematically analyzed 507 papers from the literature on KGs in NLP. As a
    result, we present a structured overview of the research landscape, provide a
    taxonomy of tasks, summarize our findings, and highlight directions for future
    work.'
  prefs: []
  type: TYPE_NORMAL
- en: What is Natural Language Processing?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Natural language processing (NLP) is a subfield of [linguistics](https://en.wikipedia.org/wiki/Linguistics),
    [computer science](https://en.wikipedia.org/wiki/Computer_science), and [artificial
    intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence) concerned
    with the interactions between computers and human language, in particular how
    to program computers to process and analyze large amounts of [natural language](https://en.wikipedia.org/wiki/Natural_language)
    data([Wikipedia](https://en.wikipedia.org/wiki/Natural_language_processing)).
  prefs: []
  type: TYPE_NORMAL
- en: What are Knowledge Graphs?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: KGs have emerged as an approach for semantically representing knowledge about
    real-world entities in a machine-readable format. Most works implicitly adopt
    a broad definition of KGs, wherethey are understood as *‚Äú****a graph of data intended
    to accumulate and convey knowledge of the real world, whose nodes represent entities
    of interest and whose edges represent relations between these entities‚Äù*** ([Hogan
    et al., 2022](https://dl.acm.org/doi/10.1145/3447772)).
  prefs: []
  type: TYPE_NORMAL
- en: '**Why do we use Knowledge Graphs in NLP?**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The underlying paradigm is that the combination of structured and unstructured
    knowledge can benefit all kinds of NLP tasks. For instance, structured knowledge
    from KGs can be injected into that of the contextual knowledge found in language
    models, which improves the performance in downstream tasks ([Colon-Hernandez et
    al., 2021](https://arxiv.org/abs/2101.12294)). Furthermore, given the current
    public discussions about Large Language Models, such as ChatGPT, we may use KGs
    to verify and, if necessary, correct hallucinated and false statements of generative
    models. Additionally, with the growing importance of KGs, there are also expanding
    efforts to construct new KGs from unstructured texts.
  prefs: []
  type: TYPE_NORMAL
- en: How are Knowledge Graphs used in NLP?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Characteristics of the Research Landscape üèûÔ∏è
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The figure below shows the distribution of publications over a ten-year observation
    period.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/053913c7ce26b03916cfef5ffd7017a1.png)'
  prefs: []
  type: TYPE_IMG
- en: Distribution of number of papers from 2012 to 2021 (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: While the first publications appear in 2013, the annual publications grew slowly
    between 2013 and 2016\. From 2017 onwards, the number of publications doubled
    almost every year. Because of the significant rise in research interest within
    these years, more than 90% of all publications originate from these five years.
    Even though the growth trend seems to stop in 2021, this is likely due to the
    data export which happened in the first week of 2022, leaving out many studies
    from 2021 that were enlisted in the databases later in 2022\. Nonetheless, the
    trend clearly indicates that KGs are receiving increasing attention from the NLP
    research community.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, we observed that the number of domains explored in the research
    literature grew rapidly in parallel with the annual count of papers. In the figure
    below, the ten most frequent domains are displayed.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/621378379fd793ddc615aaa93f948828.png)'
  prefs: []
  type: TYPE_IMG
- en: Number of papers by most popular application domains (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: It is striking that health is by far the most prominent domain. The latter appears
    more than twice as often as the scholarly domain, which ranks second. Other popular
    areas are engineering, business, social media, or law. In view of the domain diversity,
    it becomes evident that KGs are naturally applicable to many different contexts.
  prefs: []
  type: TYPE_NORMAL
- en: Tasks in the Research Literature üìñ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Based on the tasks identified in the literature on KGs in NLP, we developed
    the empirical taxonomy shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/70692a9fa6f645027ae0d7db9eaa4756.png)'
  prefs: []
  type: TYPE_IMG
- en: Taxonomy of tasks that involve Knowledge Graphs in Natural Language Processing
    (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: 'The two top-level categories consist of knowledge acquisition and knowledge
    application. **Knowledge acquisition** contains NLP tasks to construct KGs from
    unstructured text (**knowledge graph construction**) or to conduct reasoning over
    already constructed KGs (**knowledge graph reasoning**). KG construction tasks
    are further split into two subcategories: **knowledge extraction**, which is used
    to populate KGs with entities, relations, or attributes, and **knowledge integration**,
    which is used to update KGs. **Knowledge application**, being the second top-level
    concept, encompasses common NLP tasks, which are enhanced through structured knowledge
    from KGs.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Knowledge Graph Construction üèóÔ∏è**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The task of **entity extraction** is a starting point in constructing KGs and
    is used to derive real-world entities from unstructured text. Once the relevant
    entities are singled out, relationships and interactions between them are found
    with the task of **relation extraction**. A lot of papers use both entity exraction
    and relation extraction to construct new KGs, e.g., for news events or scholarly
    research. **Entity linking** is a task of linking entities recognized in some
    text to already existing entities in KGs. Since synonymous or similar entities
    often exist in different KGs or in different languages, **entity alignment** can
    be performed to reduce redundancy and repetition in future tasks. Coming up with
    the rules and schemes of KGs, i.e., their structure and format of knowledge presented
    in it, is done with the task of **ontology construction**.
  prefs: []
  type: TYPE_NORMAL
- en: '**Knowledge Graph Reasoning** üß†'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once constructed, KGs contain structured world knowledge and can be used to
    infer new knowledge by reasoning over them. Thereby, the task of classifying entities
    is called **entity classification**, while **link prediction** is the task of
    inferring missing links between entities in existing KGs often performed via ranking
    entities as possible answers to queries. **Knowledge graph embedding** techniques
    are used to create dense vector representations of a graph so that they can then
    be used for downstream machine learning tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '**Knowledge Application** üõ†Ô∏è'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Existing KGs can be used in a multitude of popular NLP tasks. Here we outline
    the most popular ones. **Question answering (QA)** was found to be the most common
    NLP task using KGs. This task is typically divided into textual QA and question
    answering over knowledge bases (KBQA). Textual QA derives answers from unstructured
    documents while KBQA does so from predefined knowledge bases. KBQA is naturally
    tied to KGs while textual QA can also be approached by using KGs as a source of
    common-sense knowledge when answering questions. This approach is desired not
    only because it is helpful for generating answers, but also because it makes answers
    more interpretable. **Semantic search** refers to ‚Äúsearch with meaning‚Äù, where
    the goal is not just to search for literal matches, but to understand the search
    intent and query context as well. This label denoted studies that use KGs for
    search, recommendations, and analytics. Examples are a big semantic network of
    everyday concepts called ConceptNet and a KG of scholarly communications and the
    relationships, among them the Microsoft Academic Graph. **Conversational interfaces**
    constitute another NLP field that can benefit from world knowledge contained in
    KGs. We can utilize the knowledge from KGs to generate responses of conversational
    agents that are more informative and appropriate in a given context.
  prefs: []
  type: TYPE_NORMAL
- en: '**Natural language generation (NLG)** is a subfield of NLP and computational
    linguistics that is concerned with models which generate natural language output
    from scratch. KGs are used in this subfield for producing natural language text
    from KGs, generating question-answer pairs, the multi-modal task of image captioning,
    or data augmentation in low-resource settings. **Text analysis** combines various
    analytical NLP techniques and methods that are applied to process and understand
    textual data. Exemplary tasks are sentiment detection, topic modeling, or word
    sense disambiguation. **Augmented language models** are a combination of large
    pretrained language models (PLMs) such as BERT ([Devlin et al., 2019](https://aclanthology.org/N19-1423.pdf))
    and GPT ([Radford et al., 2018](https://gwern.net/doc/www/s3-us-west-2.amazonaws.com/d73fdc5ffa8627bce44dcda2fc012da638ffb158.pdf))
    with knowledge contained in KGs. Since PLMs derive their knowledge from huge amounts
    of unstructured training data, a rising research trend is in combining them with
    structured knowledge. Knowledge from KGs can be infused into language models in
    their input, architecture, output, or some combination thereof.'
  prefs: []
  type: TYPE_NORMAL
- en: Popular Tasks using Knowledge Graphs in NLP üìà
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The figure below shows the most popular tasks using KGs in NLP.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/35a9cd61c6cb49ed237845051447d341.png)'
  prefs: []
  type: TYPE_IMG
- en: Distribution of number of papers by most popular tasks from 2013 to 2021 (image
    by author).
  prefs: []
  type: TYPE_NORMAL
- en: We can observe, that tasks, such as relation extraction or semantic search,
    have already existed for some time and continue to grow steadily. In our study,
    we use this, among others, as an indicator to conclude that tasks such as relation
    extraction or semantic search are already reasonably mature. In contrast, augmented
    language models and knowledge graph embedding tasks can still be considered relatively
    immature. This may be a result of the fact that these tasks are still relatively
    young and less investigated. The figure above shows that the two tasks have only
    seen a sharp increase in studies from 2018 onwards and attracted a lot of interest
    since then.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion üí°
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recent years have witnessed a rising prominence of KGs in NLP research. Since
    the first publications in 2013, researchers worldwide have paid increasing attention
    to study KGs from a NLP perspective, especially in the past five years. To provide
    an overview of this maturing research area, we performed a multifaceted survey
    about the use of KGs in NLP. Our findings show that a large number of tasks concerning
    KGs in NLP have been studied across various domains. Papers concerning KG construction
    using entity extraction and relation extraction account for the majority of all
    works. Applied NLP tasks such as QA and semantic search also have a strong research
    community. The most emergent topics in recent years have been augmented language
    models, QA, and KG embeddings.
  prefs: []
  type: TYPE_NORMAL
- en: Some of the outlined tasks are still confined to the research community, while
    others have found practical application in many real-life contexts. We observed
    that the KG construction tasks and semantic search over KGs are the most widely
    applied ones. Of the NLP tasks, QA and conversational interfaces have been adopted
    to many real-life domains, usually in the form of digital assistants. Tasks like
    KG embedding and augmented language models are still only being researched and
    lack a widespread practical adoption in real-world scenarios. We anticipate that
    as the research areas of augmented language models and KG embedding mature, more
    methods and tools will be investigated for these tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Sources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[](https://aclanthology.org/2022.aacl-main.46/?source=post_page-----5fdb15abc2b3--------------------------------)
    [## A Decade of Knowledge Graphs in Natural Language Processing: A Survey'
  prefs: []
  type: TYPE_NORMAL
- en: Phillip Schneider, Tim Schopf, Juraj Vladika, Mikhail Galkin, Elena Simperl,
    Florian Matthes. Proceedings of the 2nd‚Ä¶
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'aclanthology.org](https://aclanthology.org/2022.aacl-main.46/?source=post_page-----5fdb15abc2b3--------------------------------)
    [](https://github.com/sebischair/KG-in-NLP-survey?source=post_page-----5fdb15abc2b3--------------------------------)
    [## GitHub - sebischair/KG-in-NLP-survey: This repository contains the annotated
    collection of 507‚Ä¶'
  prefs: []
  type: TYPE_NORMAL
- en: 'This repository contains the annotated collection of 507 papers included in
    the study: "A Decade of Knowledge Graphs in‚Ä¶'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/sebischair/KG-in-NLP-survey?source=post_page-----5fdb15abc2b3--------------------------------)
  prefs: []
  type: TYPE_NORMAL
