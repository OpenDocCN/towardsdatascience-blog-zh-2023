- en: Semantic Search with PostgreSQL and OpenAI Embeddings
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 PostgreSQL 和 OpenAI 嵌入实现语义搜索
- en: 原文：[https://towardsdatascience.com/semantic-search-with-postgresql-and-openai-embeddings-4d327236f41f?source=collection_archive---------3-----------------------#2023-11-21](https://towardsdatascience.com/semantic-search-with-postgresql-and-openai-embeddings-4d327236f41f?source=collection_archive---------3-----------------------#2023-11-21)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/semantic-search-with-postgresql-and-openai-embeddings-4d327236f41f?source=collection_archive---------3-----------------------#2023-11-21](https://towardsdatascience.com/semantic-search-with-postgresql-and-openai-embeddings-4d327236f41f?source=collection_archive---------3-----------------------#2023-11-21)
- en: '[](https://curiousdima.medium.com/?source=post_page-----4d327236f41f--------------------------------)[![Dima
    Timofeev](../Images/a11f81c67f04923c0ca454347f1fe423.png)](https://curiousdima.medium.com/?source=post_page-----4d327236f41f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4d327236f41f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4d327236f41f--------------------------------)
    [Dima Timofeev](https://curiousdima.medium.com/?source=post_page-----4d327236f41f--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://curiousdima.medium.com/?source=post_page-----4d327236f41f--------------------------------)[![Dima
    Timofeev](../Images/a11f81c67f04923c0ca454347f1fe423.png)](https://curiousdima.medium.com/?source=post_page-----4d327236f41f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4d327236f41f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4d327236f41f--------------------------------)
    [Dima Timofeev](https://curiousdima.medium.com/?source=post_page-----4d327236f41f--------------------------------)'
- en: ·
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1df0a90be7e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-search-with-postgresql-and-openai-embeddings-4d327236f41f&user=Dima+Timofeev&userId=1df0a90be7e9&source=post_page-1df0a90be7e9----4d327236f41f---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4d327236f41f--------------------------------)
    ·4 min read·Nov 21, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4d327236f41f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-search-with-postgresql-and-openai-embeddings-4d327236f41f&user=Dima+Timofeev&userId=1df0a90be7e9&source=-----4d327236f41f---------------------clap_footer-----------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1df0a90be7e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-search-with-postgresql-and-openai-embeddings-4d327236f41f&user=Dima+Timofeev&userId=1df0a90be7e9&source=post_page-1df0a90be7e9----4d327236f41f---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4d327236f41f--------------------------------)
    ·4分钟阅读·2023年11月21日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4d327236f41f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-search-with-postgresql-and-openai-embeddings-4d327236f41f&user=Dima+Timofeev&userId=1df0a90be7e9&source=-----4d327236f41f---------------------clap_footer-----------)'
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4d327236f41f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-search-with-postgresql-and-openai-embeddings-4d327236f41f&source=-----4d327236f41f---------------------bookmark_footer-----------)![](../Images/2c0f934e64c66aa85851890637f67bfa.png)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4d327236f41f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-search-with-postgresql-and-openai-embeddings-4d327236f41f&source=-----4d327236f41f---------------------bookmark_footer-----------)![](../Images/2c0f934e64c66aa85851890637f67bfa.png)'
- en: Image by [Igor Omilaev](https://unsplash.com/@omilaev) on [Unsplash](https://unsplash.com/photos/a-blue-background-with-a-bunch-of-cookies-and-a-red-object-Z2PahC-Fi08)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Igor Omilaev](https://unsplash.com/@omilaev) 提供，来源于 [Unsplash](https://unsplash.com/photos/a-blue-background-with-a-bunch-of-cookies-and-a-red-object-Z2PahC-Fi08)
- en: Implementing semantic search within corporate databases can be challenging and
    requires significant effort. However, does it have to be this way? In this article,
    I demonstrate how you can utilize PostgreSQL along with OpenAI Embeddings to implement
    semantic search on your data. If you prefer not to use OpenAI Embeddings API,
    I will provide you with links to free embedding models.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在公司数据库中实现语义搜索可能是具有挑战性的，并且需要付出大量的努力。然而，真的非得如此吗？在这篇文章中，我将展示如何利用 PostgreSQL 和 OpenAI
    嵌入技术来在你的数据上实现语义搜索。如果你不希望使用 OpenAI 嵌入 API，我还会为你提供免费的嵌入模型链接。
- en: On a very high level, vector databases with LLMs allow to do semantic search
    on available data (stored in databases, documents, etc.) Thank to the “[Efficient
    Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)”
    paper (also known as “Word2Vec Paper”) co-authored by legendary [Jeff Dean](https://en.wikipedia.org/wiki/Jeff_Dean),
    we know how to represent words as real-valued vectors. Word embeddings are dense
    vector representations of words in a vector space where words with similar meanings
    are closer to each other. Word embeddings capture semantic relationships between
    words and there are more than one technique to create them.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 从很高的层面来看，具有 LLM 的向量数据库允许对可用数据（存储在数据库、文档等中）进行语义搜索。感谢 “[Efficient Estimation of
    Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)” 论文（也称为
    “Word2Vec 论文”），由传奇 [Jeff Dean](https://en.wikipedia.org/wiki/Jeff_Dean) 共同作者，我们知道如何将单词表示为实值向量。词嵌入是单词在向量空间中的密集向量表示，其中意义相似的单词彼此接近。词嵌入捕捉了单词之间的语义关系，并且有多种技术来创建它们。
- en: '![](../Images/615281e0ab21b19949fcf1800e50fe06.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/615281e0ab21b19949fcf1800e50fe06.png)'
- en: Image by the author
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Let’s practice and use OpenAI’s [*text-embedding-ada*](https://openai.com/blog/new-and-improved-embedding-model)
    model! The choice of distance function typically doesn’t matter much. OpenAI recommends
    cosine similarity. If you don’t want to use OpenAI embeddings and prefer running
    a different model locally instead of making API calls, I suggest considering one
    of the [SentenceTransformers pretrained models](https://www.sbert.net/docs/pretrained_models.html).
    Choose your model wisely.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们实践并使用 OpenAI 的 [*text-embedding-ada*](https://openai.com/blog/new-and-improved-embedding-model)
    模型！距离函数的选择通常没那么重要。OpenAI 推荐使用余弦相似度。如果你不想使用 OpenAI 的嵌入，倾向于本地运行不同的模型而不是进行 API 调用，我建议考虑其中一种
    [SentenceTransformers 预训练模型](https://www.sbert.net/docs/pretrained_models.html)。选择你的模型时要谨慎。
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now that we have developed an understanding of what an embedding is, let’s utilize
    it to sort some reviews.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经理解了嵌入的概念，让我们利用它来排序一些评论。
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: While the absolute difference may appear small, consider a sorting function
    with thousands and thousands of reviews. In such cases, we can prioritize highlighting
    only the positive ones at the top.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然绝对差异可能看起来很小，但考虑到数以千计的评论排序函数。在这种情况下，我们可以优先突出显示顶部的正面评论。
- en: Once a word or a document has been transformed into an embedding, it can be
    stored in a database. This action, however, does not automatically classify the
    database as a vector database. It’s only when the database begins to support fast
    operations on the vector that we can rightfully label it as a vector database.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦一个单词或文档被转换为嵌入，它可以存储在数据库中。然而，这个动作并不会自动将数据库分类为向量数据库。只有当数据库开始支持对向量的快速操作时，我们才能称其为向量数据库。
- en: There are numerous commercial and open-source vector databases, making it a
    highly discussed topic. I will demonstrate the functioning of vector databases
    using a [pgvector](https://www.postgresql.org/about/news/pgvector-050-released-2700/),
    an open-source PostgreSQL extension that enables vector similarity search functionalities
    for arguably the most popular database.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 目前有许多商业和开源的向量数据库，这使得它成为一个高度讨论的话题。我将通过使用 [pgvector](https://www.postgresql.org/about/news/pgvector-050-released-2700/)，一个开源的
    PostgreSQL 扩展，来演示向量数据库的功能，它为 arguably 最受欢迎的数据库提供了向量相似性搜索功能。
- en: 'Let’s run the PostgreSQL container with pgvector:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行带有 pgvector 的 PostgreSQL 容器：
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let’s start [pgcli](https://github.com/dbcli/pgcli) to connect to the database
    (*pgcli postgres://postgres:postgres@localhost:5432*) and create a table, insert
    the embeddings we computed above, and then select similar items:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们启动 [pgcli](https://github.com/dbcli/pgcli) 以连接到数据库 (*pgcli postgres://postgres:postgres@localhost:5432*)，创建一个表，插入我们计算的嵌入，然后选择相似的项目：
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We are prepared to search for similar documents now. I have shortened the embedding
    for “good ride” again because printing 1536 dimensions is excessive.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经准备好搜索相似的文档。我再次缩短了“good ride”的嵌入，因为打印 1536 维度是多余的。
- en: '[PRE4]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Completed! As you can observe, we have computed embeddings for multiple documents,
    stored them in the database, and conducted vector similarity searches. The potential
    applications are vast, ranging from corporate searches to features in medical
    record systems for identifying patients with similar symptoms. Furthermore, this
    method is not restricted to texts; similarity can also be calculated for other
    types of data such as sound, video, and images.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 完成了！如你所见，我们已经为多个文档计算了嵌入向量，将其存储在数据库中，并进行了向量相似性搜索。这些应用的潜力巨大，涵盖了从企业搜索到医疗记录系统中的相似症状患者识别等众多领域。此外，这种方法不仅限于文本；也可以计算声音、视频和图像等其他类型数据的相似性。
- en: Enjoy!
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 享受吧！
