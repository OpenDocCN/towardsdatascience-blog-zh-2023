- en: Building a Basic Machine Learning Model in Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/building-a-basic-machine-learning-model-in-python-d7cca929ee62?source=collection_archive---------2-----------------------#2023-01-02](https://towardsdatascience.com/building-a-basic-machine-learning-model-in-python-d7cca929ee62?source=collection_archive---------2-----------------------#2023-01-02)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Extensive essay on how to pick the right problem and how to develop a basic
    classifier*'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@juras.jursenas?source=post_page-----d7cca929ee62--------------------------------)[![Juras
    Juršėnas](../Images/eb2ca720f2c8688dbf8079879c028d12.png)](https://medium.com/@juras.jursenas?source=post_page-----d7cca929ee62--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d7cca929ee62--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d7cca929ee62--------------------------------)
    [Juras Juršėnas](https://medium.com/@juras.jursenas?source=post_page-----d7cca929ee62--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3041473d9e3c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-basic-machine-learning-model-in-python-d7cca929ee62&user=Juras+Jur%C5%A1%C4%97nas&userId=3041473d9e3c&source=post_page-3041473d9e3c----d7cca929ee62---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d7cca929ee62--------------------------------)
    ·20 min read·Jan 2, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd7cca929ee62&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-basic-machine-learning-model-in-python-d7cca929ee62&user=Juras+Jur%C5%A1%C4%97nas&userId=3041473d9e3c&source=-----d7cca929ee62---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd7cca929ee62&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-basic-machine-learning-model-in-python-d7cca929ee62&source=-----d7cca929ee62---------------------bookmark_footer-----------)![](../Images/01ff8323628648cdfec674b9023fa9f2.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [charlesdeluvio](https://unsplash.com/@charlesdeluvio?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: By now, all of us have seen the results of various basic machine learning (ML)
    models. The internet is rife with images, videos, and articles showing off how
    a computer identifies, correctly or not, various animals.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: While we have moved towards more intricate machine learning models, such as
    ones that generate or upscale images, those basic ones still form the foundation
    of those efforts. Mastering the basics can become a launchpad for much greater
    future endeavors.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: So, I decided to revisit the basics myself and build a basic machine learning
    model with several caveats — it must be somewhat useful, as simplistic as possible,
    and return reasonably accurate results.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Unlike many other tutorials on the internet, however, I want to present my entire
    thought process from beginning to end. As such, the coding part will begin quite
    a bit later as problem selection in both the theoretical and practical realm is
    equally important. In the end, I believe that understanding *why* will go further
    than *how to*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Picking the correct problem for ML
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although machine learning can solve a great deal of challenges, it’s not a one-size-fits-all
    approach. Even if we were to temporarily forget about the financial, temporal,
    and other resource costs, ML models would still be great at some things and terrible
    at others.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Categorization is a great example of where machine learning may shine. Whenever
    we deal with real world data (i.e., we’re not dealing with categories created
    within the code itself), figuring out all possible rules that define a phenomenon
    is nearly impossible.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: As I’ve written previously, if we were to attempt to take a rule-based approach
    to categorize whether an object is a cat or not, we’d quickly run into issues.
    There seems to be no defining quality that makes any physical object what it is
    — there are cats without tails, fur, ears, one eye, a different number of legs,
    etc., but all of them still fall within the same category.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Enumerating all of the possible rules and exceptions to them is likely impossible,
    maybe there even isn’t some eternal list, and we make them up as we go. Machine
    learning, in some sense, mimics our thinking by eating up an enormous amount of
    data to make predictions.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: In other words, we should carefully consider the problem we’re trying to solve
    before trying to figure out which model would fit best, how much data we’ll need,
    and many other things we concern ourselves with once we start the task.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: In search of practical application
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Making models that differentiate between dogs and cats is certainly interesting
    and fun but unlikely to net any benefit, even if we scale up the operation to
    immense levels. Additionally, there have been millions of tutorials for such models
    created online.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: 'I decided to pick word categorization, as it hasn’t been as frequently written
    about, and it has some practical application. Our SEO team had an interesting
    proposition — they needed to categorize keywords according to three types:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '**Informational** — users searching for knowledge about a topic (e.g., “what
    is a proxy”)'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Transactional** — users seeking for a product or service (e.g., “best proxies”)'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Navigational** — users seeking for a specific brand or an offshoot of it
    (e.g., “Oxylabs)'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Categorizing thousands of keywords manually is a bit of a pain. Such a task
    seems (almost) perfect for machine learning, although there’s an inherent issue
    that is nearly impossible to solve, which I will expand upon later.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Finally, it made data collection and management a significantly easier task
    than it would otherwise have been. SEO specialists use a variety of tools to track
    keywords, most of which can export thousands of them into a CSV sheet. All that
    needs to be done is to assign categories to the keywords.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Building a pre-MVP
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deciding how many data points you’ll need before building a model is nearly
    impossible. There are some dependencies on the stated goal (i.e., more or less
    categories), however, calculating these with precision is a fool’s errand. Picking
    a sufficiently large number (e.g., 1000 entries) is a good starting point.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: One thing I’d caution against is working with the entire dataset first. Since
    it is likely, it’s the first time you’re developing a model, a lot of things can
    go wrong. In general, you’re better off writing the code and running it on a small
    sample (e.g., 10% of the total) just to ensure there are no semantic errors or
    any other horrors.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Once you get the desired result, start working with the entire dataset. While
    it’s unlikely that you’ll have to throw out the project entirely, you don’t want
    to end up spending hours of (boring) work and have nothing to show for.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Regardless, with some samples in hand, we can begin the development experience
    properly. I’ve chosen Python as it’s a fairly common language with decent support
    for machine learning through its numerous libraries.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Libraries
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Pandas](https://pypi.org/project/pandas/). While not strictly necessary, reading
    and exporting to CSV is going to make our lives significantly easier.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[SciKit-Learn](https://pypi.org/project/scikit-learn/). A fairly powerful and
    flexible machine learning library, which will form the foundation for our classification
    model. We’ll be using various *sklearn* features throughout the tutorial.'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[NLTK](https://pypi.org/project/nltk/) (Natural Language Toolkit). As we’ll
    be processing natural language, NLTK does the job perfectly. *Stopwords* will
    be absolutely necessary from the package.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Imports
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Line 1
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Fairly self-explanatory. *Pandas* allows us to read and write CSV and other
    spreadsheet files by creating data frames. Since we’ll be dealing with keywords,
    most SEO tools export lists of them in CSV, which will reduce the data processing
    we need to do manually.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Line 2
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: From the SciKit-Learn library, we’ll pick up several things, *TfidfVectorizer*
    being our first choice.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Vectorizers convert our strings into feature vectors, which results in two important
    changes. First, strings are converted into numerical representations. Each unique
    string is converted into an index, which is then turned into a vector (the offshoot
    of a matrix).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '**Sentence #1**: “The dog is brown.”'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '**Sentence #2**: “The dog is black.”'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: 'Vectorization would take both sentences and create an index of:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Outside of turning strings into numerical values, vectorization also optimizes
    data processing. Instead of having to go through identical strings several times,
    the same index is used akin to compressing files.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: Finally, TFIDF (term frequency-inverse document frequency) is one of the ways
    to weigh term importance across documents. In simple terms, it takes each term,
    assesses its frequency divided by the document length, and assigns a weighted
    value to it. As a result, words that repeat frequently are considered more important.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Line 3
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*LogisticRegression* is one of the ways to discover relationships between variables.
    Since our task is a classic example of classification, logistic regressions work
    perfectly as they take some input variable *x* (keyword)and assign it a value
    of *y* (informational/transactional/navigational).'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: There are other options, such as *LinearSVC,* which involves significantly more
    complicated mathematics. In extremely simplistic terms, SVC takes several clusters
    of data points and finds the values in each that are closest to the opposing cluster(s).
    These are called support vectors.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: A hyperplane (i.e., an *n-dimensional* geometrical object in an *n+1-dimensional*
    space) is drawn in such a way that the distances between it and each support vector
    is maximized.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eb722b44930e8f5e8c3e04443201fa5c.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
- en: Image by author
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '[There exists research to state that using Support Vector Machines](https://link.springer.com/chapter/10.1007/BFb0026683)
    might produce better results in text classification, however, it’s likely due
    to the significantly more complicated nature of the task. These advantages aren’t
    entirely relevant in our case as they surface when feature counts reach inordinately
    high numbers, so linear regressions should work just fine.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: Line 4
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Pipeline* is a flexible machine learning tool that lets you create an object
    that assembles several steps of the entire process into one. It has numerous benefits
    — from helping you write neater code to preventing data leakage.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Line 5
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While not entirely necessary in our case, *SelectKBest* and *chi2* help optimize
    models by improving accuracy and reducing training time. *SelectKBest* allows
    us to set a maximum number of features that are used.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '*Chi2* (or *chi-squared*) is a statistical test for the independence of variables
    that helps us select the best features (hence, *SelectKBest)* for training:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/706e58897a99f3e0263bb1a57a7447b6.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
- en: Image by author.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Expected values are calculated by accepting the null hypothesis (variables are
    independent). These are then hedged against our observed values. If observed values
    deviate a significant margin from the expected ones, we can reject the null hypothesis,
    which forces us to accept that variables are dependent.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: If variables are dependent, they are acceptable for the machine learning model
    as that’s exactly what we’re looking for — relations between objects. In turn,
    *SelectKBest* takes all *chi2* results and selects those that have the strongest
    relationships.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: In our case, since our number of features is relatively small, *SelectKBest*
    might not bring the optimization we’d be interested in, but it becomes essential
    once the numbers start rising.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: Line 6
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our final import is from NLTK, which we will only use for the *stopwords* list.
    Unfortunately, the default list isn’t suitable for our task at hand. Most such
    lists include words like “how,” “what,” “why,” and many others that, while useless
    in regular categorization, indicate search intent.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: In fact, there’s a case to be made that these words are more important than
    any remainder in keywords like “how to build a web scraper.” Since we’re interested
    in the category of the sentence rather than any other value, the *stopwords* create
    the best shot at deciding what it might be.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: As such, removing some of the entries from the stopwords list is vital. Luckily,
    NLTK stopwords are just text files which you can edit with any word processor.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '[NLTK downloads are stored in user directories by default](https://sites.pitt.edu/~naraehan/python3/faq.html#Q-where-nltk-data)
    but can be changed if necessary through the use of *download_dir=.*'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Dataframes and stopwords
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All machine learning models begin with data preparation and processing. Since
    we’re working with SEO keywords, these can be easily exported through CSV from
    popular tools that measure performance.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: There is something to be said about picking a random sample that should include
    close to equal amounts of our categories. As we’re producing a pre-MVP, that shouldn’t
    be a concern, as data can be added as we go if the model delivers the results
    we need.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Before proceeding onwards, it would be wise to select a few dozen keywords out
    of a CSV file and label them. Once we get to a working model, we can label the
    rest. Since *Pandas* creates data frames in a tabular format, the easiest way
    is to simply add a new column, “Category” or “Label,” and assign each keyword
    row with *Informational, Transactional, or Navigational.*
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Line 1 & 2
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Whenever we have a CSV of any sort, *Pandas* requires us to create a dataframe.
    First, we’ll read the keyword list supplied by SEO tools. Remember that the CSV
    files should already have some keyword categorization involved, otherwise there
    will be nothing to train the model on.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: After reading the file, we create a dataframe object from our CSV.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Line 3
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ll use NLTK to grab the stopwords file, however, we can’t use it as it is.
    NLTK’s default includes many words we consider essential for keyword categorization
    (e.g., “what,” “how,” “where,” etc.). As such, it will have to be adjusted to
    fit our purposes.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: While there are no hard and fast rules in such a case, indefinite and definite
    articles can stay (e.g., “a,” “an,” “the,” etc.) as they provide no information.
    Everything that could potentially show user intention, however, will have to be
    removed from the default file.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: I created a copy called ‘english_adjusted’ to make things easier for myself.
    Additionally, in case I need the original version for whatever reason, it will
    always be available without redownload.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you’ll likely need to run NLTK once with the regular parameter ‘english’
    to download the files, which can be done at any stage. Otherwise, you’ll receive
    an error.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the pipeline
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After all of these preparatory steps, we finally get to move on to the actual
    machine learning bit. These are the most important bits and pieces of the model.
    It’s likely that you’ll spend quite a bit of time tinkering with these parameters
    to find out the best options.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, there isn’t a lot of guidance that would apply in all cases.
    Some experimentation and reasoning will be required to reduce the amount of testing
    that’s needed, but eliminating it completely is impossible.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Some may notice that I’m not splitting the dataset into a train and test split
    through *scikit-learn*. Again, that is a luxury awarded by the nature of the problem.
    SEO tools can export thousands of (unlabeled) keywords in less than a minute,
    meaning you can procure a test set separately without much effort.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: So, due to optimization reasons, I’ll be simply using a second dataset that
    has no labels as our testing grounds. Since, however, the *train_test_split* is
    so ubiquitous, I’ll show a version of the same model using it in the addendum
    at the bottom of the article.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Line 1
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Pipeline allows us to truncate and simplify long processes into a single object,
    making it a lot easier to work with the settings of the model. It will also reduce
    the likelihood of making errors.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: We’ll start by defining our vectorizer. I’ve noted above that we’ll be using
    *TFIDFVectorizer* as it produces better results due to the way it weighs words
    found in documents. *CountVectorizer* is an option, however, you’d have to import
    it, and the results may vary.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '*Ngram_range* is an interesting reasoning challenge. To get the best results,
    you have to decide how many tokens (in our case, words) have to be counted. *Ngram_range*
    of (1, 1) would take a single word (unigram), of (1, 2) would take both a single
    word and the two nearest (bigram) in combination, of (1, 3) would take a single
    word, two, and three (trigram) in combination.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: I chose *ngram_range(1, 3)* for several reasons. First, since the model is relatively
    simple and performance is not an issue, I can afford to run a larger range of
    ngrams, so the lower bound can be set to be minimal.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, once we remove stopwords, we should think about what ngram
    upper end would be enough to glean meaning from the keywords. If possible, I find
    it easier to pick the hardest and easiest examples out of the dataset. In our
    case, the easiest examples are any question (“how to get proxies”), and the hardest
    are nouns (“web scraper”) or names (“Oxylabs”)
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Since we’ll be removing words like “to”, we get a trigram in question cases
    (“how get proxies”), which is completely clear. In fact, you could make the argument
    that a bigram (“how get”) is enough as the intention is still clear.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Hardest examples, however, will usually be shorter than a trigram as the ease
    of understanding search intent correlates with query length. Therefore, *ngram_range
    (1, 3)* should strike a decent balance for performance and accuracy.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, there’s an argument to be made for *sublinear_tf*, which is a modification
    of the regular TF-IDF calculations. If set to *True,* weight is calculated through
    a logarithmic function: *1 + log(tf)*. In other words, term frequency gains diminishing
    returns.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: With *sublinear_tf,* words that appear frequently and in many documents would
    not be weighed as heavily. Since we have a collection of somewhat random keywords,
    we never know which ones get preferential treatment, however, these could often
    be terms such as “how,” “what,” etc., which are ones we’d like to be weighed heavily.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: Throughout testing, I found that the model performed better without *sublinear_tf*,
    but I recommend tinkering a bit to see whether it would grant any benefits.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: The *Stopwords* parameter is, by now, self explanatory as we’ve discussed previously.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Line 2
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While not technically a new line, I’ll be separating these out for clarity and
    brevity purposes. We’ll be now invoking *SelectKBest*, which I’ve written fairly
    extensively about above. Our point of interest is the *k* value.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: These will be different, depending on the size of your dataset. *SelectKBest*
    is intended to optimize performance and accuracy. In my case, sending in ‘all’
    works, but you’ll usually have to pick some large enough *N* that matches your
    own dataset.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Line 3
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finally, we get to the method that will be used for the model. *LogisticRegression*
    is our choice, as mentioned previously, but there’s a lot of tinkering to be done
    with the parameters.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: “C”value is a hyperparameter, which is a parameter that tells the model the
    parameters it should pick. Hyperparameters are highly complicated parts of the
    model that have a tremendous impact on the end results.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: In extremely simple terms, the *C* value is the trust score for your training
    data. A high *C* value means that a higher weight, when fitting, will be placed
    on training data and a lower weight on penalties. Low C values place higher emphasis
    on penalties and lower weight on training data.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: There should always be some penalty in place as training will never fully represent
    real world values (due to being a small subset of it, regardless of how much you
    collect). Additionally, having outliers and not penalizing them means the model
    [will inch closer to being overfit](https://medium.com/p/7aeef64755d2).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: The *penalty* parameter is the operation that will be used for the hyperparameter.
    There are three types of penalties offered by *SciKit-Learn* — *‘l1’*, *‘l2’*,
    and *‘elasticnet’*. ‘*None*’is also an option, but it should be used sparingly,
    if ever.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: ‘*L1*’ is the absolute sum of the magnitude of all coefficients. In simple terms,
    it pulls all coefficients towards some central point. If large penalties are applied,
    some data points can become zero (i.e., be eliminated).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: ‘*L1*’ should be used in cases where there is either multicollinearity (several
    variables are correlated) or when you want to simplify the model. Since *l1* eliminates
    some data points, models nearly always become simpler. It doesn’t work as well,
    however, when you already have a relatively simple distribution of data points.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: ‘*L2*’ is a different version of a similar process. Instead of being the absolute
    sum, it’s the sum of the square of all coefficient values. As such, all coefficients
    are shrunk by an identical value, but none are eliminated. ‘*L2*’ is the default
    setting as it’s the most flexible and rarely causes issues.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: ‘*Elasticnet*’ is a combination of both of the above methods. There [has been
    quite an extensive commentary](https://stats.stackexchange.com/questions/184029/what-is-elastic-net-regularization-and-how-does-it-solve-the-drawbacks-of-ridge)
    written on whether ‘*elasticnet*’ should be the default approach, however, not
    all solvers support it. In our case, we’d need to switch to the “saga” solver,
    which is intended for large datasets.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: There would likely be little benefit to using ‘*elasticnet*’ in a tutorial-level
    machine learning model. Just keep in mind that it may be beneficial in the future.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Moving on to *‘max_iter*’, the parameter will set the maximum number of iterations
    the model will perform until convergence. In simple terms, convergence is the
    point at which further iterations are unlikely to occur and serves as the stopping
    point.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Higher values increase computational complexity but may result in better overall
    behavior. In cases where the datasets are relatively simplistic, *‘max_iter’*
    can be set to thousands and above as it won’t be too taxing on the system.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: If the values are too low and convergence fails, a warning message will be displayed.
    As such, it’s not that difficult to find the lowest possible value and to work
    up from there.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Fitting the model and outputting data
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’re nearing the end of the tutorial as we finally get to fitting the model
    and receiving the output.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Line 1–3
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Within line 1, we use our established pipeline to fit the model to the training
    data. In case some debugging or additional analysis is needed, the pipeline enables
    us to create named steps, which can be called later on.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Line 4–8
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We create another dataframe from a CSV file that holds only the keywords. We
    will be using our newly created model to predict each keyword and its category.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Since our dataframe contains only keywords, we add a new column “type” and run
    *model.predict* to provide us with an output.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Finally, all of it is moved to an output CSV file, which will be created in
    the local directory. Usually, you’d like to set some destination, but for testing
    purposes, there’s often no need to do so.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: There’s a commented-out line that I’d like to mention that calls the *score*
    function. *SciKit* provides us with numerous ways to estimate the predictive power
    of our model. These shouldn’t be understood as gospel, as predicted accuracy and
    real world accuracy can often diverge.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Scores, however, are useful as a rule of thumb and as a quick way to evaluate
    whether the parameters have had some influence on the model. While there are plenty
    of scoring methods, the basic *model.score* uses *R squared*, which is helpful
    in most cases whenever we’re tuning parameters.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Examining the results
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: My training data had a mere 1300 entries with three distinct categories, which
    I have mentioned above. Even with such a small set, the model managed to arrive
    at a decent accuracy score of about 80%.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Some of these, as one would expect, are debatable, and even Google thinks so.
    For example, “web scrape” was a keyword frequently searched for. There’s no clear
    indication of whether the query is transactional or informational. Google SERPs
    think as much as there are results for products and informational articles in
    the top 5.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: There’s one area the model struggled with — navigational keywords. If I were
    to guess, the model predicted the category correctly about 5–10% of the time.
    There are several reasons for such an occurrence.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: 'The distribution of the dataset could be blamed as it’s heavily imbalanced:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '**Transactional** — 0.457353%'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Informational** — 0.450735%'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Navigational** — 0.091912%'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While real world scenarios would present a similar distribution (due to the
    inherent rarity of Navigational keywords), the training data is too sparse for
    proper fitting. Additionally, the frequency of navigational keywords is so low
    that the model would produce greater accuracy by always assigning the other two.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: I don’t think, however, that presenting the training data with more navigational
    keywords would produce a much better result. It’s a problem that is extremely
    difficult to solve through textual analysis, whatever kind we choose.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Navigational keywords consist mostly of brand names, which are neologisms or
    other newly produced words. Nothing within them follows the natural language,
    and, as such, connections between them can only be discovered *a posteriori*.
    In other words, we’d have to first know it’s a brand name, from other data sources,
    to assign the category correctly.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: If I had to guess, Google and other search engines discover brand names through
    the way users act when they query a new word. They might look for domain matches
    or other data, but predicting that something is a navigational keyword without
    human interaction is extremely difficult.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Feature engineering would be a potential solution to the problem. We’d have
    to discover new connections between the navigational and other categories and
    implement assignments through other approaches.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: As feature engineering is a different topic entirely and one that deserves its
    own article, I’ll provide a single example. Navigational keywords will rarely
    be queried as questions (outside of “what is”) as they would otherwise make no
    sense (e.g., “how to Oxylabs,” “how to get Oxylabs.”)
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: There’s a debatable point as to whether “how to get Oxylabs proxies” would be
    considered transactional or navigational. It would definitely fit within the transactional
    category, however, so it could be considered so.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: By knowing that relatively few navigational keywords would be formed as questions,
    we could build a model that would filter out most questions, leaving us with a
    smaller subset of potential targets.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, many navigational keywords have significantly shorter query lengths,
    mostly consisting of a single word, while the other categories have the same length
    relatively rarely.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: Both of these methods and many others can be combined to improve the model’s
    accuracy when selecting navigational keywords. Getting into feature engineering,
    however, is much more complicated than a basic tutorial should cover.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: For now, word classification should be covered with an overall better understanding
    of how machine learning models work. Hopefully, the explanation of the many parameters
    and tools available will let you create a functional model from the get-go.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even if the article has been exceedingly long, you might have noticed that writing
    a machine learning model isn’t all that difficult. In fact, one may say that doing
    so is the smallest part of the project, at least in this case.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: 'Machine learning heavily relies on preparation, of which we can outline several
    parts:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '**Picking the right problem**. Some problems are simply better solved with
    other approaches. Don’t buy into the hype and try to solve everything through
    machine learning. With rule-based systems, you might be able to save time and
    resources while producing even better results.'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Preparing the data**. A model will only be as good as the data. If your data
    is labeled incorrectly, lacks veracity, or is otherwise faulty, no amount of development
    and resources build something that creates reliable outputs.'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**准备数据**。一个模型的好坏取决于数据。如果你的数据标记不正确、缺乏真实性或其他方面存在问题，那么再多的开发和资源也无法创建出可靠的输出。'
- en: '**Picking the model**. It’s easy to default to logistic regression or any other
    model because you’ve done it so many times. *Sci-Kit Learn* has other options
    such as those I haven’t even mentioned, such as *PassiveAggressiveClassifier,*
    which use different mathematical approaches. Again, I stress the importance of
    picking the right problem as it should decide what modeling method you choose.'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**选择模型**。由于你已经做过很多次，可能很容易选择逻辑回归或其他模型。*Sci-Kit Learn*还有其他选项，比如我没有提到的*PassiveAggressiveClassifier*，它们使用不同的数学方法。再次强调，选择正确的问题非常重要，因为它应该决定你选择什么建模方法。'
- en: I hope that this article will serve many newcomers to machine learning by providing
    not only the practical part, but also provide the way of thinking one should approach
    problems with.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这篇文章能为许多机器学习新手提供帮助，不仅提供实践部分，还提供处理问题的思路。
- en: 'Addendum: Original full code block'
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录：原始完整代码块
- en: '[PRE6]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Addendum II: Train_test_split'
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录 II：Train_test_split
- en: Imports
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导入
- en: '[PRE7]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: As per usual, we have to import the *train_test_split* itself (line 5).
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 按照惯例，我们需要导入*train_test_split*本身（第5行）。
- en: Setting up the split
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置拆分
- en: '[PRE8]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Line 1
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第1行
- en: As our dataset has only two features (*keyword* & *category*), we’ll need two
    variables for each. One of them will store the training data, and the other one
    will be used for testing purposes.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的数据集只有两个特征（*keyword*和*category*），我们需要为每个特征准备两个变量。其中一个用于存储训练数据，另一个用于测试目的。
- en: We’ll take the data frame created in previous steps and assign the column names
    (in my dataset, they were called “Keyword” and “Type,” as evidenced by the parameters).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用之前步骤中创建的数据框，并指定列名（在我的数据集中，它们被称为“Keyword”和“Type”，如参数所示）。
- en: Finally, *SciKit-Learn* solves data splitting problems for us by allowing automated
    divisions for both sets. The *train_test_split* takes float and integer values
    that represent percentages to be used for either the test set size or the training
    set size. If both are left as *None*, it will default to 0.25.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，*SciKit-Learn*通过允许对两个数据集进行自动分割来解决数据拆分问题。*train_test_split*接受表示测试集大小或训练集大小百分比的浮点和整数值。如果两个值都设置为*None*，默认值将为0.25。
- en: Some tinkering will be required to get the best results. I’ve tried many different
    splits, with 0.3 producing the best results. Generally, you’ll find that many
    models will work best on splits ranging from 0.2 to 0.3.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 需要进行一些调整才能获得最佳结果。我尝试了许多不同的拆分，其中0.3产生了最佳结果。一般来说，你会发现许多模型在0.2到0.3范围内的拆分效果最佳。
- en: Particular splits tend to have less effect on accuracy when data point numbers
    increase. In fact, in extremely large datasets, splitting on 0.1 might improve
    computational performance.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 特定的拆分对准确性的影响较小，当数据点数量增加时更是如此。实际上，在极大的数据集上，拆分为0.1可能会提高计算性能。
- en: Relations between statistical units are complicated, however, the abstract field
    of connections that can be made is finite, so that accuracy can be understood
    as a requirement for a flat number of data points instead of a specific ratio.
    In other words, there is some *N* where results don’t get any better, so if datasets
    are large, smaller ratios might be more optimal.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 统计单位之间的关系很复杂，但是可以建立的连接的抽象领域是有限的，因此准确性可以理解为对一定数量的数据点的要求，而不是特定的比例。换句话说，有一个*N*，在这个点上结果不会再变得更好，因此如果数据集很大，较小的比例可能更为优化。
- en: There are some [highly technical articles written about the topic](https://link.springer.com/article/10.1007/s41664-018-0068-2)
    that explain the idea in much greater depth and provide ways to calculate the
    optimal split.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些[关于这个主题的高度技术文章](https://link.springer.com/article/10.1007/s41664-018-0068-2)深入解释了这个想法，并提供了计算最佳拆分的方法。
- en: Everything else in this code block follows the same steps as in the original
    tutorial.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码块中的其他部分遵循与原始教程相同的步骤。
- en: Fitting the model and outputting data (again)
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拟合模型并输出数据（再次）
- en: '[PRE9]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Line 1
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第1行
- en: Instead of training our model on the labeled dataset directly, we’ll be training
    it on the previously split one, naming *x_train* and *y_train*. Lines 2 and 3
    remain identical.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会直接在标记数据集上训练模型，而是在之前拆分的那个数据集上进行训练，命名为*x_train*和*y_train*。第2行和第3行保持不变。
- en: Line 4
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第4行
- en: Since there is no separate dataset, we’ll be using the test part of our initial
    one for predictions. So, we create a dataframe that has the column *Keyword* in
    which we will output all of the keywords from the test dataset. In the second
    column, *Type*, we’ll use the model to predict the category of the keyword, drawing
    from the same dataset.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 由于没有单独的数据集，我们将使用初始数据集中的测试部分进行预测。因此，我们创建一个数据框，其中包含*关键词*这一列，我们将在该列中输出测试数据集中的所有关键词。在第二列*类型*中，我们将使用模型来预测关键词的类别，依然使用相同的数据集。
- en: Finally, as per the original version, all of that will be outputted into a results
    file. Printing accuracy score is also an option if one is interested in how well
    the model thinks it’s performing.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，按照原始版本，所有结果将输出到一个结果文件中。如果有人对模型的表现如何感兴趣，也可以选择打印准确率分数。
