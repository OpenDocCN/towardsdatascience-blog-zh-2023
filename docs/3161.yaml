- en: CLIP — Intuitively and Exhaustively Explained
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/clip-intuitively-and-exhaustively-explained-1d02c07dbf40?source=collection_archive---------2-----------------------#2023-10-20](https://towardsdatascience.com/clip-intuitively-and-exhaustively-explained-1d02c07dbf40?source=collection_archive---------2-----------------------#2023-10-20)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Creating strong image and language representations for general machine learning
    tasks.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@danielwarfield1?source=post_page-----1d02c07dbf40--------------------------------)[![Daniel
    Warfield](../Images/c1c8b4dd514f6813e08e401401324bca.png)](https://medium.com/@danielwarfield1?source=post_page-----1d02c07dbf40--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1d02c07dbf40--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1d02c07dbf40--------------------------------)
    [Daniel Warfield](https://medium.com/@danielwarfield1?source=post_page-----1d02c07dbf40--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbdc4072cbfdc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclip-intuitively-and-exhaustively-explained-1d02c07dbf40&user=Daniel+Warfield&userId=bdc4072cbfdc&source=post_page-bdc4072cbfdc----1d02c07dbf40---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1d02c07dbf40--------------------------------)
    ·17 min read·Oct 20, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1d02c07dbf40&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclip-intuitively-and-exhaustively-explained-1d02c07dbf40&user=Daniel+Warfield&userId=bdc4072cbfdc&source=-----1d02c07dbf40---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1d02c07dbf40&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclip-intuitively-and-exhaustively-explained-1d02c07dbf40&source=-----1d02c07dbf40---------------------bookmark_footer-----------)![](../Images/bb84737af3ff56dd6f70ef16d6a1e9ce.png)'
  prefs: []
  type: TYPE_NORMAL
- en: “Contrasting Modes” by Daniel Warfield using MidJourney. All images by the author
    unless otherwise specified.
  prefs: []
  type: TYPE_NORMAL
- en: In this post you’ll learn about “contrastive language-image pre-training” (CLIP),
    A strategy for creating vision and language representations so good they can be
    used to make highly specific and performant classifiers without any training data.
    We’ll go over the theory, how CLIP differs from more conventional methods, then
    we’ll walk through the architecture step by step.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b518de3e7bc648a9fde1be23489a9594.png)'
  prefs: []
  type: TYPE_IMG
- en: CLIP predicting highly specific labels for classification tasks it was never
    directly trained on. [Source](https://arxiv.org/pdf/2103.00020.pdf)
  prefs: []
  type: TYPE_NORMAL
- en: '**Who is this useful for?** Anyone interested in computer vision, natural language
    processing (NLP), or multimodal modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: '**How advanced is this post?** This post should be approachable to novice data
    scientists. Some of the later sections are a bit more advanced (particularly when
    we dig into the loss function).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pre-requisites:** Some cursory knowledge of computer vision and natural language
    processing.'
  prefs: []
  type: TYPE_NORMAL
- en: The Typical Image Classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When training a model to detect if an image is of a cat or a dog, a common approach
    is to present a model with images of…
  prefs: []
  type: TYPE_NORMAL
