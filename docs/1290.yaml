- en: How to Generate Real-World Synthetic Data with CTGAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-generate-real-world-synthetic-data-with-ctgan-af41b4d60fde?source=collection_archive---------2-----------------------#2023-04-13](https://towardsdatascience.com/how-to-generate-real-world-synthetic-data-with-ctgan-af41b4d60fde?source=collection_archive---------2-----------------------#2023-04-13)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Synthetic Data Generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Exploring the Streamlit App introduced in ydata-synthetic
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@miriam.santos?source=post_page-----af41b4d60fde--------------------------------)[![Miriam
    Santos](../Images/decbc6528a641e7b02934a03e136284a.png)](https://medium.com/@miriam.santos?source=post_page-----af41b4d60fde--------------------------------)[](https://towardsdatascience.com/?source=post_page-----af41b4d60fde--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----af41b4d60fde--------------------------------)
    [Miriam Santos](https://medium.com/@miriam.santos?source=post_page-----af41b4d60fde--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F243289394aaa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-generate-real-world-synthetic-data-with-ctgan-af41b4d60fde&user=Miriam+Santos&userId=243289394aaa&source=post_page-243289394aaa----af41b4d60fde---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----af41b4d60fde--------------------------------)
    ·10 min read·Apr 13, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faf41b4d60fde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-generate-real-world-synthetic-data-with-ctgan-af41b4d60fde&user=Miriam+Santos&userId=243289394aaa&source=-----af41b4d60fde---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf41b4d60fde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-generate-real-world-synthetic-data-with-ctgan-af41b4d60fde&source=-----af41b4d60fde---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: G*enerating synthetic data is increasingly becoming a fundamental task to master
    as we move towards a Data-Centric paradigm of AI development.*
  prefs: []
  type: TYPE_NORMAL
- en: '[Synthetic Data](https://medium.com/ydata-ai/synthetic-data-1cd0ba907609) truly
    has a tremendous potential, but it also comes with its own challenges, especially
    in what concerns fully capturing the complexity and intricacies of real-world
    domains, namely their heterogeneity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a596a47e4d2bddb9612433846d953718.png)'
  prefs: []
  type: TYPE_IMG
- en: Data heterogeneity is tough to handle in synthetic data generation models, especially
    for real-world domains, comprising additional (complex!) data characteristics
    and difficulty factors. Photo by [Tolga Ulkan](https://unsplash.com/@tolga__?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral).
  prefs: []
  type: TYPE_NORMAL
- en: Real-world domains are associated to [numerous aspects of complexity](/data-quality-issues-that-kill-your-machine-learning-models-961591340b40)
    (e.g., missing data, imbalanced data, noisy data), yet **one of the most common
    is encompassing heterogeneous (or “mixed”) data**, i.e., data that comprises both
    numeric and categorical features.
  prefs: []
  type: TYPE_NORMAL
- en: As each feature type may come with its own intrinsic characteristics, **heterogeneous
    data raises additional challenges** to the process of synthetic data generation.
  prefs: []
  type: TYPE_NORMAL
- en: '[CTGAN](https://arxiv.org/abs/1907.00503) (Conditional Tabular Generative Adversarial
    Network) was conceptualized to partially “capture” this heterogeneity of real-world
    data and compared to other architectures such as [WGAN and WGAN-GP](https://medium.com/ydata-ai/generating-synthetic-tabular-data-with-gans-part-1-866705a77302),
    has proven to be more robust and generalizable for a variety of datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Throughout this article, we’ll dissect the properties of this architecture
    that make it so different and performant for tabular data, and why and when you
    should leverage it.*'
  prefs: []
  type: TYPE_NORMAL
- en: Real-World Tabular Heterogeneous Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Real-world domains are often described by what we call “tabular data”,**
    i.e., data that can be structured and organized in a table-like format.'
  prefs: []
  type: TYPE_NORMAL
- en: As a standard, features (sometimes called “variables” or “attributes”) are represented
    in *columns*, whereas observations (or “records”) correspond to the *rows*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Additionally, real-world data usually comprises both numeric and categorical
    features.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Numeric** features (also called “continuous”) are those that encode quantitative
    values, whereas **categorical** (also called “discrete”) represent qualitative
    measurements.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of the [Adult Census Income](https://www.kaggle.com/datasets/uciml/adult-census-income?resource=download)
    dataset (available in [Kaggle](https://www.kaggle.com) under the [CC0: Public
    Domain](https://creativecommons.org/publicdomain/zero/1.0/) license) that we’ll
    be exploring later on: `age` and `fnlwgt` are **numeric** features, while the
    remaining are **categorical**.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d47e13ee9a35e8eda7a821bd7492bce4.png)'
  prefs: []
  type: TYPE_IMG
- en: A simple example of a tabular heterogenous dataset, containing numeric and categorical
    features. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: '**Due to the nature of each feature type, handling heterogeneous data is not
    straightforward when developing our machine learning models.**'
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the internal workings of the algorithm we need to train, the input
    data needs to be represented or preprocessed in different ways, so that their
    characteristics are properly learned by the model.
  prefs: []
  type: TYPE_NORMAL
- en: '**When it comes to generating synthetic data, this assumes an even greater
    importance.** We’re not just worried about preprocessing the data so that it can
    be consumed efficiently by the model, **we’re concerned about whether the model
    can efficiently learn the characteristics of the real data**, so that it is able
    to output synthetic data that preserves its properties.'
  prefs: []
  type: TYPE_NORMAL
- en: Why CTGAN for Heterogeneous Tabular Data?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since the original [GAN](https://arxiv.org/abs/1406.2661) formulation, research
    has been proposing modifications to the original architecture, new loss functions,
    or optimization strategies to address specific GAN limitations.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, certain architectures such as [WGAN](https://arxiv.org/abs/1701.07875)
    and [WGAN-GP](https://arxiv.org/abs/1704.00028) introduced significant improvements
    to GAN in what concerns training stability and convergence time. [PacGAN](https://arxiv.org/abs/1712.04086),
    on the other hand, was designed to alleviate mode collapse, another common shortcoming
    of traditional GAN architectures.
  prefs: []
  type: TYPE_NORMAL
- en: '**Yet, in what concerns data heterogeneity (i.e., handling both numeric and
    categorical features and their intrinsic characteristics) these architectures
    still seemed to fall short.**'
  prefs: []
  type: TYPE_NORMAL
- en: Although they have shown to be great for numeric features, they struggled to
    capture the distributions of categorical features, whose presence is a reality
    for great the majority of real-world datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, none of these architectures was conceptualized to address heterogeneous
    data comprising mixed feature types — both numeric *and* categorical.
  prefs: []
  type: TYPE_NORMAL
- en: '**On the contrary, CTGAN was specifically designed to deal with the challenges
    posed by tabular datasets, handling mixed data.**'
  prefs: []
  type: TYPE_NORMAL
- en: Building on top of the success attained by other architectures, such as WGAN-GP
    and PacGAN, **CTGAN goes one step further by considering synthetic data generation
    as a complete flow — from data preparation to the GAN architecture itself.** In
    other words, CTGAN attends to the specific characteristics of both numeric and
    categorical features and incorporates those characteristics into the generator
    model. *How?*
  prefs: []
  type: TYPE_NORMAL
- en: 'Numeric features: Non-Gaussian and Multimodal Distributions'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**CTGAN introduces Mode-Specific Normalization**'
  prefs: []
  type: TYPE_NORMAL
- en: Contrary to image data, where pixel values normally follow a Gaussian-like distribution,
    **continuous features in tabular data are often non-Gaussian.**
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, they **tend to follow multimodal distributions**, where probability
    distributions have more than one mode, i.e., they present distinct local maxima
    (or “peaks”):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c3fa694d297e1a4fb73e11d468362f5f.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of a Guassian-like versus a Skewed data distributon (Figs. a and b).
    Example of a multimodal distribution decomposed into distributions with distinct
    modes (c and d). Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'To capture these behaviors, CTGAN uses **mode-specific normalization**. Using
    a VGM (Variational Gaussian Mixture) model, each value in a continuous feature
    is represented by a one-hot vector indicating its sampled mode and a scalar that
    represents the value normalized according to that mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b83ba6bee60f36edfd5e8f095c0345e4.png)'
  prefs: []
  type: TYPE_IMG
- en: An example of mode-specific normalization. ci,j represents a value i in a feature
    j (e.g., j = “Age”), for which p3 was picked. ci,j is therefore represented by
    a vector [ai,j, 0, 0, 1]. n3 and p3 represent the mode and standard deviation
    of p3\. Image from [1].
  prefs: []
  type: TYPE_NORMAL
- en: 'Categorical features: Sparse One-Hot-Encoded Vector and High Category Imbalance'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**CTGAN introduces the Conditional Generator**'
  prefs: []
  type: TYPE_NORMAL
- en: 'CTGAN aims to address essentially two main challenges introduced by categorical
    features:'
  prefs: []
  type: TYPE_NORMAL
- en: '**One is the the sparsity of one-hot-encoded vectors in real-world data.**
    While the generator outputs the probability distributions over all possible categorical
    values, the original “real” categorical values are directly encoded in a one-hot-vector.
    These are easily distinguishable by the discriminator by comparing the distribution
    sparseness between real and synthetic data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The other is the imbalance associated to some categorical features.** If
    some categories of a feature are underrepresented, they cannot be learned adequately
    by the generator. If we were concerned with predictive modeling or classification
    tasks, data oversampling could be a solution to alleviate this issue. However,
    since the goal of synthetic data generation is to mimic the properties of the
    original data, this is not an option.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CTGAN introduces a Conditional Generator** to deal with the challenges imposed
    by imbalanced categories which usually lead to GAN’s infamous mode collapse. Nevertheless,
    there are no free lunches with conditional architectures: **the input needs to
    be prepared** so that the generator can interpret the conditions, **and the generated
    rows need to preserve an input condition**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To this end, CTGAN considers a **conditional vector** which, when used in a
    sample-by-sample training, makes a lot of difference in what concerns the use
    of CTGAN:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/731878c5e5a23c8bf49f5553f37bed42.png)'
  prefs: []
  type: TYPE_IMG
- en: Overview of the CTGAN model. With training-by-sampling, examples are conditioned
    on the possible values of categorical features, sampled according to their log-frequency.
    Image from [1].
  prefs: []
  type: TYPE_NORMAL
- en: Generating Synthetic Tabular Data with CTGAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**One of the easiest ways to get started with synthetic data is to explore
    the models available as open source software scattered through GitHub.** There
    are plenty of tools that you can experiment with: *take a look into the* [*awesome-data-centric-ai*](https://github.com/Data-Centric-AI-Community/awesome-data-centric-ai#-synthetic-data)
    *repository for a curated list of open-source tools!*'
  prefs: []
  type: TYPE_NORMAL
- en: '**When it comes to learning and experimenting with new libraries, I’m all for
    an easy and intuitive experience: if there’s a UI, even better.**'
  prefs: []
  type: TYPE_NORMAL
- en: For synthetic data generation, `ydata-synthetic` has recently introduced a Streamlit
    app that lets us conduct a complete flow from data reading to profiling the newly
    generated synthetic data. *Perfect!*
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eaee4d32a4fb7f4a3136faa9606300d6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'ydata-synthetic Streamlit app: Welcome Screen. Image by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step to get the UI running is installing `ydata-synthetic`. Don’t
    forget to add the “streamlit” extra:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, you can open up a Python file and run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: After running the above command, the console will output the URL from which
    you can access the app!
  prefs: []
  type: TYPE_NORMAL
- en: Train a Synthesizer Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Training a synthesizer is straightforward: you can access the “**Train a Synthesizer**”
    tab and upload a file (again, I’m using the Adult Census Income dataset):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9390e1b69b3494f4bcd8c71103e81b52.png)'
  prefs: []
  type: TYPE_IMG
- en: 'ydata-synthetic Streamlit app: Upload file. Screencast by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the file loads, we need to specify which features are `numeric` and `categorical`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/01f558ca1c18e02b21013ca25bb61b07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'ydata-synthetic Streamlit app: Specify numeric and categorical features. Screencast
    by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: Then, we can select our synthesizer parameters, namely the `model` we intend
    to use and its parameters, such as `batch size`, `learning rate`, and additional
    settings (e.g. `noise dimension`, `layer dimension`, and the regularization constants
    `beta`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we select the training parameters, namely the training `epochs`, and
    the training starts with a click of a button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1a7ab9fae777680654ca7b33c7513446.png)'
  prefs: []
  type: TYPE_IMG
- en: 'ydata-synthetic Streamlit app: Define synthesizer and traning parameters. Screencast
    by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that I’m naturally using CTGAN in the example, but other models are currently
    supported such as GAN, WGAN, WGANGP, CRAMER, and DRAGAN.
  prefs: []
  type: TYPE_NORMAL
- en: Generate and Profile Synthetic Data Samples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To generate new synthetic samples, we can access the “**Generate synthetic data**”
    tab, choose the number of samples to generate and specify the filename where they’ll
    be saved.
  prefs: []
  type: TYPE_NORMAL
- en: Our model is saved and loaded by default as `trained_synth.pkl` but we can load
    a previously trained model by providing its path.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a54f9970c135707eefb498543aae0cae.png)'
  prefs: []
  type: TYPE_IMG
- en: 'ydata-synthetic Streamlit app: Generate new synthetic samples. Screencast by
    Author.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, I decided to generate a data profiling report to check the overall
    characteristics of the synthetic data, so I checked the “**Generate synthetic
    data profiling**” and the synthesization process starts by clicking “**Generate
    Samples**”:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/44256306c01ea416694065cb71be96b4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'ydata-synthetic Streamlit app: New synthetic samples and data profiling. Screencast
    by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: The report is generated using the familiar `[ydata-profiling](https://github.com/ydataai/ydata-profiling)`
    package and the synthetic samples are now saved in a `synthetic_adult.csv` file.
  prefs: []
  type: TYPE_NORMAL
- en: 'By exploring the profile report of our newly generated samples, we can easily
    determine that **CTGAN has sucessfully learned the characteristics of the original
    data**, even in a complex heterogeneous scenario such as the Adult Dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: Basic feature **statistics remain consistent** for both numeric and categorical
    features (e.g., mean/standard deviation, number of categories/mode);
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **representation of categorical features is mimicked**, i.e., the frequency
    of original categories is maintained on the synthetic data;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **underlying relationships** — correlation and interaction — between features
    **are also kept**, including the original data quality alerts (i.e., the synthetic
    data shows the same quality alerts as those presented for the original data).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Naturally, depending on the specific parameters given to the model, we can improve
    our synthetic data generation results so that the new data is as close as possible
    to the original data.
  prefs: []
  type: TYPE_NORMAL
- en: '*And that’s a wrap! Painless and hassle-free generation in just a few steps!*'
  prefs: []
  type: TYPE_NORMAL
- en: Limitations and Open Challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Although CTGAN has proven to be a powerful architecture for tabular data, it
    still has some limitations and drawbacks (some common to all deep learning models,
    as expected):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Optimizing hyperparameters** for datasets with different characteristics
    is challenging and it may require a significant amount of trial and error;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Handling high-cardinality** features remains problematic since it becomes
    difficult for the model to learn and generate such a large number of unique categories;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Handling skewed distributions** or distributions with a large amount of **constant
    values** (e.g., a large amount of 0’s) are also hard to capture by this architecture;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Synthesization might be less accurate for **small datasets**, since CTGAN, as
    any other deep learning model, is data savvy;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training and convergence may require significant **computational resources and
    time**, especially for very large datasets;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overall, CTGAN can be most effective for generating synthetic data for **structured,
    tabular datasets with heterogeneous features and an adequate training size**,
    but may require a sharp eye to spot specific data characteristics and assess whether
    the model is in the best possible conditions to generate synthetic data that accurately
    incorporates the properties of the original data.
  prefs: []
  type: TYPE_NORMAL
- en: Final Thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this article, we discussed the working principles of CTGAN, focusing
    on how the architecture captures certain complex characteristics, extensively
    found in real-world domains. Additionally, we explored the `ydata-synthetic` Streamlit
    app, that allows us to get started with synthetic data and learn more about CTGAN
    and other generation models in a no-code, friendly environment. *Pretty cool,
    han?*
  prefs: []
  type: TYPE_NORMAL
- en: To be added to the UI soon is the support for time-series models, namely [TimeGAN](/synthetic-time-series-data-a-gan-approach-869a984f2239),
    more advanced settings for CTGAN, and [side-by-side comparison reports](https://pub.towardsai.net/how-to-compare-2-dataset-with-pandas-profiling-2ae3a9d7695e)
    using `ydata-profiling`. *Something to look for in future articles!*
  prefs: []
  type: TYPE_NORMAL
- en: 'As always, feedback, questions, and suggestions are always appreciated: you
    can leave me a comment, star or contribute to the repo, and even find me at the
    [Data-Centric AI Community](https://tiny.ydata.ai/dcai-medium) to discuss other
    data-related topics. *See you there?*'
  prefs: []
  type: TYPE_NORMAL
- en: About me
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ph.D., Machine Learning Researcher, Educator, Data Advocate, and overall “jack-of-all-trades”.
    Here on Medium, I write about **Data-Centric AI and Data Quality**, educating
    the Data Science & Machine Learning communities on how to move from imperfect
    to intelligent data.
  prefs: []
  type: TYPE_NORMAL
- en: '[Data-Centric AI Community](https://tiny.ydata.ai/dcai-medium) | [GitHub](https://github.com/Data-Centric-AI-Community)
    | [Google Scholar](https://scholar.google.com/citations?user=isaI6u8AAAAJ&hl=en)
    | [LinkedIn](https://www.linkedin.com/in/miriamseoanesantos/)'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Xu, L., Skoularidou, M., Cuesta-Infante, A., & Veeramachaneni, K. [Modeling
    Tabular Data Using Conditional GAN](https://arxiv.org/abs/1907.00503) (2019).
    *Advances in Neural Information Processing Systems, 32.*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Arjovsky, M., Chintala, S., & Bottou, L. [Wasserstein Generative Adversarial
    Networks](https://arxiv.org/abs/1701.07875) (2017). In *International conference
    on machine learning* (pp. 214–223).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., & Courville, A. C. [Improved
    Training of Wasserstein GANs](https://arxiv.org/abs/1704.00028) (2017). *Advances
    in neural information processing systems*, *30*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Lin, Z., Khetan, A., Fanti, G., & Oh, S. PacGAN: [The power of two samples
    in generative adversarial networks](https://arxiv.org/abs/1712.04086) (2018).
    *Advances in neural information processing systems*, *31*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
    S., Courville, A. & Bengio, Y. (2014). [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661).
    In *Advances in neural information processing systems* (pp. 2672–2680).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Adult Census Income](https://www.kaggle.com/datasets/uciml/adult-census-income)
    Dataset (obtained from [Kaggle](https://www.kaggle.com) under the [CC0: Public
    Domain](https://creativecommons.org/publicdomain/zero/1.0/) license). Kohavi R.,
    [Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid](http://robotics.stanford.edu/~ronnyk/nbtree.pdf)
    (1996), *Proceedings of the Second International Conference on Knowledge Discovery
    and Data Mining.*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
