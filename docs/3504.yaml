- en: 'Courage to Learn ML: Demystifying L1 & L2 Regularization (part 2)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/courage-to-learn-ml-unraveling-l1-l2-regularization-part-2-1bb171e43b35?source=collection_archive---------6-----------------------#2023-11-25](https://towardsdatascience.com/courage-to-learn-ml-unraveling-l1-l2-regularization-part-2-1bb171e43b35?source=collection_archive---------6-----------------------#2023-11-25)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Unlocking the Intuition Behind L1 Sparsity with Lagrange multipliers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://amyma101.medium.com/?source=post_page-----1bb171e43b35--------------------------------)[![Amy
    Ma](../Images/2edf55456a1f92724535a1441fa2bef5.png)](https://amyma101.medium.com/?source=post_page-----1bb171e43b35--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1bb171e43b35--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1bb171e43b35--------------------------------)
    [Amy Ma](https://amyma101.medium.com/?source=post_page-----1bb171e43b35--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd6d8df787b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcourage-to-learn-ml-unraveling-l1-l2-regularization-part-2-1bb171e43b35&user=Amy+Ma&userId=d6d8df787b&source=post_page-d6d8df787b----1bb171e43b35---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1bb171e43b35--------------------------------)
    ·6 min read·Nov 25, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1bb171e43b35&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcourage-to-learn-ml-unraveling-l1-l2-regularization-part-2-1bb171e43b35&user=Amy+Ma&userId=d6d8df787b&source=-----1bb171e43b35---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1bb171e43b35&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcourage-to-learn-ml-unraveling-l1-l2-regularization-part-2-1bb171e43b35&source=-----1bb171e43b35---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Welcome back to ‘[Courage to Learn ML](/towardsdatascience.com/tagged/courage-to-learn-ml):
    Demystifying L1 & L2 Regularization,’ Part Two. In [our previous discussion](https://medium.com/@yujing-ma45/understanding-l1-l2-regularization-part-1-9c7affe6f920),
    we explored the benefits of smaller coefficients and the means to attain them
    through weight penalization techniques. Now, in this follow-up, our mentor and
    learner will delve even deeper into the realm of L1 and L2 regularization.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you’ve been pondering questions like these, you’re in the right place:'
  prefs: []
  type: TYPE_NORMAL
- en: What’s the reason behind the names L1 and L2 regularization?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we interpret the classic L1 and L2 regularization graph?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are Lagrange multipliers, and how can we understand them intuitively?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying Lagrange multipliers to comprehend L1 sparsity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Your engagement — likes, comments, and follows — does more than just boost morale;
    it powers our journey of discovery! So, let’s dive in.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eb38cadf6bb97d614c0c0bc8ddd9755a.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Aarón Blanco Tejedor](https://unsplash.com/@the_meaning_of_love?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Why they call L1, l2 regularization?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The name, L1 and L2 regularization, comes from the concept of Lp norms directly.
    Lp norms represent different ways to calculate distances from a point to the…
  prefs: []
  type: TYPE_NORMAL
