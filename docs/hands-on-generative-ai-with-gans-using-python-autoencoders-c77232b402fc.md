# ä½¿ç”¨ Python å®ç°ç”Ÿæˆå¼ AIï¼šè‡ªç¼–ç å™¨

> åŸæ–‡ï¼š[`towardsdatascience.com/hands-on-generative-ai-with-gans-using-python-autoencoders-c77232b402fc`](https://towardsdatascience.com/hands-on-generative-ai-with-gans-using-python-autoencoders-c77232b402fc)

![](img/6fa218e9894ae7f7c804d4ccfef9edc1.png)

å›¾ç‰‡ç”± [GR Stocks](https://unsplash.com/@grstocks?utm_source=medium&utm_medium=referral) æä¾›ï¼Œæ¥æºäº [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

## ä»è‡ªç¼–ç å™¨å¼€å§‹ï¼Œæ›´å¥½åœ°ç†è§£ GANs

[](https://medium.com/@marcellopoliti?source=post_page-----c77232b402fc--------------------------------)![Marcello Politi](https://medium.com/@marcellopoliti?source=post_page-----c77232b402fc--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c77232b402fc--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----c77232b402fc--------------------------------) [Marcello Politi](https://medium.com/@marcellopoliti?source=post_page-----c77232b402fc--------------------------------)

Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c77232b402fc--------------------------------) Â·é˜…è¯»æ—¶é—´ 6 åˆ†é’ŸÂ·2023 å¹´ 3 æœˆ 21 æ—¥

--

## ä»‹ç»

æœ€è¿‘å‡ å¹´ï¼Œç”±äºäººå·¥æ™ºèƒ½èƒ½å¤Ÿç”Ÿæˆå‡ ä¹ä¸çœŸå®æ•°æ®éš¾ä»¥åŒºåˆ†çš„åˆæˆå®ä¾‹ï¼Œç”Ÿæˆæ¨¡å‹å˜å¾—è¶Šæ¥è¶Šå—æ¬¢è¿ã€‚ä½ å¯èƒ½å¯¹èƒ½å¤Ÿç”Ÿæˆæ–‡æœ¬çš„ç¥ç»ç½‘ç»œ Chat GPT å’Œèƒ½å¤Ÿç”Ÿæˆå®Œå…¨åŸåˆ›å›¾åƒçš„ DALLE æ¯”è¾ƒç†Ÿæ‚‰ã€‚

ç½‘ç«™ [thispersondoesnotexist.com](https://this-person-does-not-exist.com/en) æ˜¯ä¸€ä¸ªè‘—åçš„ç”Ÿæˆç½‘ç»œä¾‹å­ï¼Œæ¯æ¬¡ä½ è®¿é—®è¿™ä¸ªé“¾æ¥æ—¶ï¼Œéƒ½ä¼šæ˜¾ç¤ºä¸€ä¸ªä¸å­˜åœ¨çš„äººçš„ AI ç”Ÿæˆå›¾åƒã€‚è¿™åªæ˜¯ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æƒŠäººå¯èƒ½æ€§ä¸­çš„ä¸€ä¸ªä¾‹å­ã€‚

éšç€æ—¶é—´çš„æ¨ç§»ï¼Œç”Ÿæˆå¼äººå·¥æ™ºèƒ½å·²ç»å‘å±•ï¼Œéšç€ç ”ç©¶çš„æ¨è¿›ï¼Œå‡ºç°äº†è®¸å¤šæ¶æ„æ¥è§£å†³å„ç§åº”ç”¨åœºæ™¯ã€‚ä½†è¦å¼€å§‹å­¦ä¹ ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼Œä½ éœ€è¦ç†Ÿæ‚‰ä¸€ç§æ¶æ„ï¼šç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰ã€‚

## GANs æ¦‚è¿°

ç”Ÿæˆç½‘ç»œçš„æœ€ç»ˆ**ç›®æ ‡æ˜¯ç”Ÿæˆä¸å…¶è®­ç»ƒé›†å…·æœ‰ç›¸åŒåˆ†å¸ƒçš„æ–°æ•°æ®**ã€‚ç”Ÿæˆç½‘ç»œé€šå¸¸è¢«è§†ä¸ºæœºå™¨å­¦ä¹ ä¸­çš„æ— ç›‘ç£å­¦ä¹ çš„ä¸€éƒ¨åˆ†ï¼Œå› ä¸ºå®ƒä»¬ä¸éœ€è¦æ ‡è®°æ•°æ®ã€‚ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰æ¦‚å¿µç”± Ian Goodfellow äº 2014 å¹´æå‡ºï¼Œç›¸å…³è®ºæ–‡æ˜¯â€œ[*Generative Adversarial Nets*](https://arxiv.org/pdf/1406.2661.pdf)â€ã€‚

æœ€åˆï¼ŒGAN çš„æ¶æ„åŸºäºå…¨è¿æ¥å±‚ï¼Œæ—¨åœ¨**ç”Ÿæˆä½åˆ†è¾¨ç‡å›¾åƒ**ï¼Œå¦‚æ‰‹å†™æ•°å­—ã€‚ä»é‚£æ—¶èµ·ï¼ŒGAN ç»å†äº†ä¼—å¤šæ”¹è¿›å’Œåº”ç”¨ã€‚å®ƒä»¬å·²è¢«ç”¨äºå›¾åƒåˆ°å›¾åƒçš„è½¬æ¢ã€å›¾åƒè¶…åˆ†è¾¨ç‡å’Œå›¾åƒä¿®è¡¥ç­‰ä»»åŠ¡ï¼Œå…¶ä¸­ç½‘ç»œå­¦ä¹ é‡å»ºå›¾åƒçš„ç¼ºå¤±éƒ¨åˆ†ã€‚

GANs ä¹Ÿå¯ä»¥ç”¨äºç›‘ç£å­¦ä¹ å’ŒåŠç›‘ç£å­¦ä¹ ä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œæ¡ä»¶ GANs å¯ä»¥æ ¹æ®æŸäº›æ¡ä»¶ç”Ÿæˆæ•°æ®ï¼Œå¦‚æ ¹æ®ç”¨æˆ·è¾“å…¥ç”Ÿæˆä¸åŒåŠ¨ç‰©çš„å›¾åƒã€‚åŠç›‘ç£ GANs ä½¿ç”¨æ ‡è®°æ•°æ®æ¥æé«˜ç”Ÿæˆæ•°æ®çš„è´¨é‡ã€‚

GANs çš„åº”ç”¨è¿œä¸æ­¢äºå›¾åƒç”Ÿæˆã€‚è¿™äº›æ¨¡å‹å·²è¢«åº”ç”¨äº NLPï¼ˆè‡ªç„¶è¯­è¨€å¤„ç†ï¼‰ã€éŸ³ä¹ç”Ÿæˆç”šè‡³è¯ç‰©å‘ç°ï¼ç”Ÿæˆæ¨¡å‹çš„æ½œåŠ›å·¨å¤§ï¼Œéšç€æŠ€æœ¯çš„ä¸æ–­è¿›æ­¥ï¼Œæˆ‘ä»¬å¯ä»¥æœŸå¾…æ›´å¤šåˆ›æ–°åº”ç”¨çš„å‡ºç°ã€‚

GANs å¾ˆæœ‰å¸å¼•åŠ›ï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥ç”Ÿæˆä¸è®­ç»ƒæ•°æ®åˆ†å¸ƒç›¸åŒçš„æ•°æ®ã€‚

## è‡ªç¼–ç å™¨ä¸ GANs

è¦å®Œå…¨ç†è§£è¿™äº›ç”Ÿæˆå¯¹æŠ—ç½‘ç»œçš„å·¥ä½œåŸç†ï¼Œé¦–å…ˆäº†è§£è‡ªç¼–ç å™¨æ˜¯å¾ˆæœ‰å¸®åŠ©çš„ã€‚è‡ªç¼–ç å™¨æ˜¯ä¸€ç§å¯ä»¥å‹ç¼©å’Œè§£å‹è®­ç»ƒæ•°æ®çš„ç¥ç»ç½‘ç»œç±»å‹ï¼Œä½¿å…¶åœ¨æ•°æ®å‹ç¼©å’Œç‰¹å¾æå–æ–¹é¢éå¸¸æœ‰ç”¨ã€‚

**æ ‡å‡†è‡ªç¼–ç å™¨æ— æ³•ç”Ÿæˆæ–°æ•°æ®**ï¼Œä½†å®ƒä»¬ä½œä¸ºç†è§£ GANs çš„æœ‰ç”¨èµ·ç‚¹ã€‚è‡ªç¼–ç å™¨ç”±ä¸¤ä¸ªä¸²è”çš„ç½‘ç»œç»„æˆâ€”â€”ç¼–ç å™¨ç½‘ç»œå’Œè§£ç å™¨ç½‘ç»œã€‚ç¼–ç å™¨ç½‘ç»œæ¥æ”¶**d ç»´è¾“å…¥ç‰¹å¾ xï¼Œå¹¶å°†å…¶ç¼–ç ä¸º p ç»´å‘é‡ z**ã€‚æ¢å¥è¯è¯´ï¼Œç¼–ç å™¨çš„è§’è‰²æ˜¯å­¦ä¹ å¦‚ä½•å»ºæ¨¡å‡½æ•° z = f(X)ã€‚**å‘é‡ z ä¹Ÿç§°ä¸ºæ½œåœ¨å‘é‡**ã€‚é€šå¸¸ï¼Œæ½œåœ¨å‘é‡çš„ç»´åº¦ä½äºåŸå§‹è¾“å…¥å‘é‡ï¼Œå› æ­¤**p < d**

**è§£ç å™¨**ç½‘ç»œ**æ¥æ”¶**ç¼–ç åçš„å‘é‡**z å¹¶é‡å»ºåŸå§‹è¾“å…¥ç‰¹å¾ x**ã€‚**è‡ªç¼–ç å™¨çš„ç›®æ ‡æ˜¯æœ€å°åŒ–åŸå§‹è¾“å…¥ç‰¹å¾ä¸é‡å»ºç‰¹å¾ä¹‹é—´çš„å·®å¼‚**ã€‚é€šè¿‡è¿™æ ·åšï¼Œ**è‡ªç¼–ç å™¨å­¦ä¹ åœ¨å‹ç¼©å’Œè§£å‹è¾“å…¥æ•°æ®çš„åŒæ—¶ä¿ç•™å…¶æœ¬è´¨ç‰¹å¾**ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹ä¸€ä¸ªè¡¨ç¤ºè‡ªç¼–ç å™¨æ¶æ„çš„å›¾ç‰‡ã€‚

![](img/2870a78625634c5309e753a7607f6e4b.png)

è‡ªç¼–ç å™¨æ¶æ„ï¼ˆå›¾åƒç”±ä½œè€…æä¾›ï¼‰

**è™½ç„¶è‡ªç¼–ç å™¨å¯ä»¥ç”¨äºæ•°æ®å‹ç¼©å’Œç‰¹å¾æå–ï¼Œä½†å®ƒä»¬æ— æ³•åƒ GANs é‚£æ ·ç”Ÿæˆæ–°æ•°æ®ã€‚**

åœ¨è¿™ä¸ªç®€å•çš„ä¾‹å­ä¸­ï¼Œç¼–ç å™¨å’Œè§£ç å™¨éƒ½æ˜¯ç®€å•çš„çº¿æ€§å±‚ï¼Œç”¨äºå‹ç¼©å’Œè§£å‹ç©ºé—´ã€‚**æ›´å¤æ‚çš„æ¶æ„å¯ä»¥åŒ…å«å¤šä¸ªå±‚ï¼Œå¹¶ä¸”å¯èƒ½åŒ…å«ä¸åŒç±»å‹çš„å±‚ï¼Œä¾‹å¦‚åœ¨åº”ç”¨äºå›¾åƒæ¨¡å‹æ—¶ä½¿ç”¨å·ç§¯å±‚ã€‚**

è®©æˆ‘ä»¬çœ‹çœ‹åœ¨ PyTorch ä¸­è‡ªç¼–ç å™¨çš„ä¸€ä¸ªç®€å•å®ç°ã€‚

```py
class AutoEncoder(nn.Module):
    def __init__(self, **kwargs):
        super().__init__()
        self.encoder = nn.Linear(
          in_features=kwargs["input_shape"], out_features=128
        )
        self.decoder = nn.Linear(
            in_features=128, out_features=kwargs["input_shape"]
        )

    def forward(self, x):
        latent_vector = torch.relu(self.encoder(x))
        reconstructed = torch.relu(self.decoder(latent_vector))
        return reconstructed
```

AutoEncoder ç±»åƒå¾€å¸¸ä¸€æ ·ç»§æ‰¿ nn.Moduleï¼ŒåŒ…æ‹¬ä¸€ä¸ªç¼–ç å™¨å’Œä¸€ä¸ªè§£ç å™¨ï¼Œå®ƒä»¬éƒ½æ˜¯çº¿æ€§å±‚ï¼Œæ¥å—ä¸€ä¸ªå¤§å°ä¸º input_shapeï¼ˆä¾‹å¦‚ 784ï¼‰çš„è¾“å…¥å‘é‡ xï¼Œå°†å…¶å‡å°‘åˆ°å¤§å°ä¸º 128 çš„æ½œåœ¨ç©ºé—´ï¼Œæœ€ç»ˆé‡å»ºåŸå§‹å¤§å°çš„å‘é‡ã€‚

## å…¶ä»–ç±»å‹çš„ AutoEncoders

æˆ‘ä»¬å·²ç»çœ‹åˆ°ï¼Œé€šå¸¸æ½œåœ¨å‘é‡çš„å¤§å°å°äºè¾“å…¥å‘é‡çš„å¤§å°ï¼Œå› æ­¤å‘ç”Ÿå‹ç¼©ï¼Œå³ **p<d**ã€‚è¿™ç±» autoencoders è¢«ç§°ä¸º **undercomplete**ã€‚

ä½†æˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªæ¯”è¾“å…¥å‘é‡æ›´å¤§çš„æ½œåœ¨å‘é‡ï¼Œ**p>d**ã€‚å½“ç„¶ï¼Œ**overcomplete autoencoders**ï¼ä½†å®ƒä»¬çš„ç”¨é€”æ˜¯ä»€ä¹ˆï¼Ÿå®ƒä»¬å¯ä»¥ç”¨äº **é™å™ª**ã€‚

åœ¨è¿™äº›ç½‘ç»œçš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¾“å…¥æ•°æ®ä¸­ä¼šæ·»åŠ å™ªå£°ï¼Œä¾‹å¦‚æ¨¡ç³Šçš„å›¾åƒï¼Œç½‘ç»œå¿…é¡»èƒ½å¤Ÿé‡å»ºæ— å™ªå£°çš„å›¾åƒã€‚è¿™ç§ç‰¹å®šçš„æ¶æ„ç§°ä¸ºå»å™ª autoencoderã€‚

![](img/1c5fd6e04e9d564a956c473fa40100e1.png)

åŸºæœ¬å»å™ªæ¶æ„ï¼ˆå›¾ç‰‡ä½œè€…ï¼‰

## Autoencoder çš„å®é™…ç¤ºä¾‹

ç°åœ¨è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªå¦‚ä½•ä½¿ç”¨ PyTorch å®ç°æ›´å¤æ‚çš„ Autoencoder çš„ä¾‹å­ï¼Œè¯¥ Autoencoder ç”¨äºç”Ÿæˆç±»ä¼¼äº MNIST æ•°æ®é›†çš„åˆæˆæ•°æ®ã€‚

é¦–å…ˆï¼Œåƒå¾€å¸¸ä¸€æ ·ï¼Œæˆ‘ä»¬å®‰è£…å¹¶å¯¼å…¥æ‰€éœ€çš„åº“ã€‚

```py
!pip install torchvision
!pip install torch

from torchvision import datasets
from torchvision import transforms
import torch
import matplotlib.pyplot as plt
```

ç°åœ¨æˆ‘ä»¬åªéœ€å¯¼å…¥æ•°æ®é›†ã€‚åœ¨ Pytorch ä¸­è¿™éå¸¸ç®€å•ï¼Œå› ä¸ºåº“æä¾›äº†å¿«é€Ÿä¸‹è½½æ•°æ®é›†çš„æ–¹æ³•ã€‚æ‰€ä»¥æˆ‘ä»¬å®ä¾‹åŒ–æ•°æ®é›†ï¼Œç„¶åæ˜¯æˆ‘ä»¬éœ€è¦è®­ç»ƒç½‘ç»œçš„ dataloaderã€‚æˆ‘ä»¬è¿˜å®šä¹‰äº†ä¸€ä¸ªè½¬æ¢ï¼Œå°†å›¾åƒåœ¨è¢«ç½‘ç»œå¤„ç†æ—¶è½¬æ¢ä¸ºå¼ é‡ã€‚

```py
dataset = datasets.MNIST(root = "./data",
      train = True,
      download = True,
      transform = tensor_transform)

loader = torch.utils.data.DataLoader(dataset = dataset,
         batch_size = 64,
         shuffle = True)

tensor_transform = transforms.ToTensor()
```

ç°åœ¨æ˜¯æ—¶å€™åˆ›å»º AutoEncoder ç±»äº†ï¼Œå°±åƒä¹‹å‰ä¸€æ ·ã€‚ä½†åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç¼–ç å™¨å’Œè§£ç å™¨éƒ½ä¼šæ›´æ·±ï¼Œå› ä¸ºå®ƒä»¬å°†ç”±æ›´å¤šçš„å±‚ç»„æˆï¼Œä»¥æ›´å¥½åœ°æ•æ‰å›¾åƒç‰¹å¾ã€‚

```py
class AutoEncoder(torch.nn.Module):
 def __init__(self):
  super().__init__()

  self.encoder = torch.nn.Sequential(
   torch.nn.Linear(28 * 28, 128),
   torch.nn.ReLU(),
   torch.nn.Linear(128, 64),
   torch.nn.ReLU(),
   torch.nn.Linear(64, 36),
   torch.nn.ReLU(),
   torch.nn.Linear(36, 18),
   torch.nn.ReLU(),
   torch.nn.Linear(18, 9)
  )

  self.decoder = torch.nn.Sequential(
   torch.nn.Linear(9, 18),
   torch.nn.ReLU(),
   torch.nn.Linear(18, 36),
   torch.nn.ReLU(),
   torch.nn.Linear(36, 64),
   torch.nn.ReLU(),
   torch.nn.Linear(64, 128),
   torch.nn.ReLU(),
   torch.nn.Linear(128, 28 * 28),
   torch.nn.Sigmoid()
  )

 def forward(self, x):
  encoded = self.encoder(x)
  decoded = self.decoder(encoded)
  return decoded
```

å¦‚ä½ æ‰€è§ï¼Œå®ƒå¹¶æ²¡æœ‰æ¯”æœ€åˆçœ‹åˆ°çš„ç®€å•ä¾‹å­å¤æ‚å¤šå°‘ã€‚

æ­£å¦‚æˆ‘ä»¬è®­ç»ƒæ¨¡å‹æ—¶æ€»æ˜¯è¿™æ ·ï¼Œæˆ‘ä»¬å®ä¾‹åŒ–ç±»ï¼Œå¹¶å®šä¹‰ä¸€ä¸ªæŸå¤±å‡½æ•°å’Œä¸€ä¸ªä¼˜åŒ–å™¨ã€‚åœ¨è¿™é‡Œæ˜¯ MSELoss å’Œ Adamã€‚

```py
model = AutoEncoder()
loss_function = torch.nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(),
       lr = 1e-1,
       weight_decay = 1e-6)
```

è®­ç»ƒç½‘ç»œçš„æ—¶åˆ»æ¥äº†ã€‚æˆ‘ä»¬å¿…é¡»éå†æˆ‘ä»¬çš„ dataloaderï¼Œå¹¶è°ƒæ•´è¾“å…¥ä»¥åŒ¹é…æ¨¡å‹æ¶æ„ã€‚ç„¶åè®¡ç®—è¾“å‡ºå’Œè·å¾—çš„æŸå¤±ï¼Œå¹¶å°†æ‰€æœ‰å†…å®¹ä¿å­˜åˆ°ä¸€ä¸ªåˆ—è¡¨ä¸­ï¼Œä»¥ä¾¿åœ¨è®­ç»ƒç»“æŸæ—¶ç»˜åˆ¶ã€‚

```py
epochs = 25
losses = []
for epoch in range(epochs):
 for (image, _) in loader:

   image = image.reshape(-1, 28*28)
   reconstructed = model(image)

   loss = loss_function(reconstructed, image)
   optimizer.zero_grad()
   loss.backward()
   optimizer.step()

   losses.append(loss)

plt.style.use('fivethirtyeight')
plt.xlabel('Iteration')
plt.ylabel('MSE-Loss')
plt.plot(losses[-100:])
```

å¥½äº†ï¼Œæˆ‘ä»¬çš„ç½‘ç»œå·²ç»è®­ç»ƒå®Œæˆï¼ç°åœ¨æˆ‘ä»¬å¯ä»¥å°†åŸå§‹å›¾åƒä¸ç½‘ç»œé‡å»ºçš„å›¾åƒè¿›è¡Œå¯¹æ¯”ã€‚

```py
plt.imshow(dataset[0])
plt.imshow(model(dataset[0].reshape(-1, 28, 28))
```

![](img/9d062ed06421a4b2e062a271196a1bc9.png)

åŸå§‹ vs é‡å»ºï¼ˆæ¥æº: [`arxiv.org/pdf/2003.05991.pdf`](https://arxiv.org/pdf/2003.05991.pdf)ï¼‰

# æœ€ç»ˆæ€è€ƒ

å­¦ä¹ è‡ªç¼–ç å™¨å¯¹äºç†è§£ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰çš„å·¥ä½œåŸç†éå¸¸æœ‰å¸®åŠ©ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬äº†è§£äº†ä¸€äº›å…³äºè¿™äº›æ¶æ„çš„ç†è®ºï¼Œç„¶åçœ‹åˆ°å®ƒä»¬å¦‚ä½•ç”¨äºé‡æ„ MNIST å›¾åƒçš„è¾“å‡ºã€‚ä½¿ç”¨å®ƒä»¬éå¸¸æœ‰è¶£ï¼Œè€Œä¸”å®ƒä»¬ä¹Ÿæœ‰å„ç§ç”¨é€”ï¼Œå…¶ä¸­ä¸€äº›åŒ…æ‹¬å‹ç¼©å’Œè§£å‹è¾“å…¥æˆ–å»å™ªå›¾åƒï¼Œæ­£å¦‚æˆ‘ä»¬æ‰€è§ã€‚**åœ¨ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†è§£é‡Šè‡ªç¼–ç å™¨å¦‚ä½•ä¸ GANs ç›¸å…³ï¼Œå¹¶ä¸”æˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•å®ç°å®ƒä»¬ã€‚** å…³æ³¨æˆ‘ä»¥è·å–æœªæ¥çš„æ–‡ç« ![ğŸ˜‰](https://emojipedia.org/it/apple/ios-15.4/faccina-che-fa-l-occhiolino/)

# ç»“æŸ

*Marcello Politi*

[Linkedin](https://www.linkedin.com/in/marcello-politi/), [Twitter](https://twitter.com/_March08_), [CV](https://march-08.github.io/digital-cv/)
