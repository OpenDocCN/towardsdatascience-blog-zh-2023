- en: Please Use Streaming Workload to Benchmark Vector Databases
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 请使用流工作负载来评估向量数据库性能
- en: 原文：[https://towardsdatascience.com/please-use-streaming-workload-to-benchmark-vector-databases-bb0154480263?source=collection_archive---------12-----------------------#2023-12-01](https://towardsdatascience.com/please-use-streaming-workload-to-benchmark-vector-databases-bb0154480263?source=collection_archive---------12-----------------------#2023-12-01)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/please-use-streaming-workload-to-benchmark-vector-databases-bb0154480263?source=collection_archive---------12-----------------------#2023-12-01](https://towardsdatascience.com/please-use-streaming-workload-to-benchmark-vector-databases-bb0154480263?source=collection_archive---------12-----------------------#2023-12-01)
- en: Why static workload is insufficient and what I learned by comparing HNSWLIB
    and DiskANN using streaming workload
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为何静态工作负载不足以满足需求，以及通过比较 HNSWLIB 和 DiskANN 使用流工作负载学到了什么
- en: '[](https://ekzhu.medium.com/?source=post_page-----bb0154480263--------------------------------)[![Eric
    Zhù](../Images/d1e5938b5ebeec307a01d717e09f3b30.png)](https://ekzhu.medium.com/?source=post_page-----bb0154480263--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bb0154480263--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bb0154480263--------------------------------)
    [Eric Zhù](https://ekzhu.medium.com/?source=post_page-----bb0154480263--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ekzhu.medium.com/?source=post_page-----bb0154480263--------------------------------)[![Eric
    Zhù](../Images/d1e5938b5ebeec307a01d717e09f3b30.png)](https://ekzhu.medium.com/?source=post_page-----bb0154480263--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bb0154480263--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bb0154480263--------------------------------)
    [Eric Zhù](https://ekzhu.medium.com/?source=post_page-----bb0154480263--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5b549f62ef70&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplease-use-streaming-workload-to-benchmark-vector-databases-bb0154480263&user=Eric+Zh%C3%B9&userId=5b549f62ef70&source=post_page-5b549f62ef70----bb0154480263---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bb0154480263--------------------------------)
    ·9 min read·Dec 1, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbb0154480263&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplease-use-streaming-workload-to-benchmark-vector-databases-bb0154480263&user=Eric+Zh%C3%B9&userId=5b549f62ef70&source=-----bb0154480263---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[跟随](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5b549f62ef70&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplease-use-streaming-workload-to-benchmark-vector-databases-bb0154480263&user=Eric+Zh%C3%B9&userId=5b549f62ef70&source=post_page-5b549f62ef70----bb0154480263---------------------post_header-----------)
    在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bb0154480263--------------------------------)
    ·9 min 阅读·Dec 1, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbb0154480263&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplease-use-streaming-workload-to-benchmark-vector-databases-bb0154480263&user=Eric+Zh%C3%B9&userId=5b549f62ef70&source=-----bb0154480263---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbb0154480263&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplease-use-streaming-workload-to-benchmark-vector-databases-bb0154480263&source=-----bb0154480263---------------------bookmark_footer-----------)![](../Images/21b32f20cb6635202bec5b0bac958cac.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbb0154480263&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplease-use-streaming-workload-to-benchmark-vector-databases-bb0154480263&source=-----bb0154480263---------------------bookmark_footer-----------)![](../Images/21b32f20cb6635202bec5b0bac958cac.png)'
- en: Image by DALLE-3
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 DALLE-3 提供
- en: Vector databases are built for high-dimensional vector retrieval. Today, many
    vectors are *embeddings* generated by deep neural nets like [GPTs](https://platform.openai.com/docs/models/embeddings)
    and [CLIP](https://openai.com/research/clip) to represent data points such as
    pieces of text, images, or audio tracks. Embeddings are used in many applications
    like search engines, recommendation systems, and chatbots. You can index embeddings
    in a vector database, which uses an *Approximate Nearest Neighbor (ANN) index*
    to supports fast retrieval of top neighbors by a distance function like Cosine
    or Euclidian. Latency is 2 to 10 milliseconds for a 1 million vectors index, and
    scales sub-linearly (i.e., *O(log n)*) with respect to index size.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 向量数据库是为了高维向量检索而构建的。如今，许多向量是由深度神经网络生成的*嵌入*，如[GPTs](https://platform.openai.com/docs/models/embeddings)和[CLIP](https://openai.com/research/clip)，用于表示数据点，如文本片段、图像或音频轨道。嵌入被用于许多应用，如搜索引擎、推荐系统和聊天机器人。你可以在向量数据库中索引嵌入，数据库使用*近似最近邻（ANN）索引*，通过如余弦或欧几里得等距离函数支持快速检索最邻近的对象。对于100万向量的索引，延迟为2到10毫秒，并且随着索引大小呈亚线性扩展（即*O(log
    n)*)。
- en: 'In this post, I point to several problems with the way we currently evaluate
    ANN indexes and suggest a new type of evaluation. This post focuses on ANN indexes
    for embedding vectors, an area that is getting a lot of attention recently: vector
    database startups like [Pinecone](https://www.pinecone.io/), [Zilliz](https://zilliz.com/),
    [Qdrant](https://qdrant.tech/), and [Weaviate](https://weaviate.io/) offer embedding
    indexing and retrieval as their core service.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我指出了我们当前评估ANN索引方式的几个问题，并建议了一种新的评估类型。本文重点关注嵌入向量的ANN索引，这是一个最近受到广泛关注的领域：像[Pinecone](https://www.pinecone.io/)、[Zilliz](https://zilliz.com/)、[Qdrant](https://qdrant.tech/)和[Weaviate](https://weaviate.io/)这样的向量数据库初创公司提供嵌入索引和检索作为其核心服务。
- en: 1\. Static workload benchmark is insufficient.
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 静态负载基准测试是不够的。
- en: The standard way to evaluate ANN indexes is to use a *static workload benchmark*,
    which consists of a fixed dataset and a fixed query set.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 评估ANN索引的标准方法是使用*静态负载基准测试*，它由固定数据集和固定查询集组成。
- en: '![](../Images/272cb4fc524e7f0d76587653d6bcfc9e.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/272cb4fc524e7f0d76587653d6bcfc9e.png)'
- en: A static workload benchmark. Image by the author.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 静态负载基准测试。图片来源于作者。
- en: 'A static workload benchmark first builds the ANN index from the fixed dataset,
    and then runs the fixed query set several times with different parameter settings
    and measures the highest achievable query throughput at each minimum accuracy
    level. After performing the same procedure for each ANN index, the benchmark generates
    a plot like the one below:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 静态负载基准测试首先从固定数据集中构建ANN索引，然后以不同参数设置多次运行固定查询集，并在每个最小准确度水平下测量可达到的最高查询吞吐量。对每个ANN索引执行相同的程序后，基准测试会生成如下图所示的图表：
- en: '![](../Images/b75756a775de669d73b48dc4799be039.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b75756a775de669d73b48dc4799be039.png)'
- en: Figure from [ANN Benchmarks (11/25/2023)](https://github.com/erikbern/ann-benchmarks/tree/b8cdbdf29238e14e70c90074f1247ef0dcfdd7f2).
    [MIT Licence.](https://github.com/erikbern/ann-benchmarks/blob/main/LICENSE)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图源自[ANN Benchmarks (11/25/2023)](https://github.com/erikbern/ann-benchmarks/tree/b8cdbdf29238e14e70c90074f1247ef0dcfdd7f2)。[MIT许可。](https://github.com/erikbern/ann-benchmarks/blob/main/LICENSE)
- en: The plot above compares different ANN indexes using a static workload called
    glove-100-angular, which contains embeddings of words.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 上图比较了使用静态负载名为glove-100-angular的不同ANN索引，该负载包含词语的嵌入。
- en: This evaluation approach was popularized by the [ann-benchmarks](https://github.com/erikbern/ann-benchmarks)
    project which started 5 years ago. Many vector databases are now measuring their
    performance using this approach in their tech blogs. See the [Qdrant benchmark](https://qdrant.tech/benchmarks/)
    and [Timescale benchmark](https://www.timescale.com/blog/how-we-made-postgresql-the-best-vector-database/).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这种评估方法由[ann-benchmarks](https://github.com/erikbern/ann-benchmarks)项目推广，该项目始于5年前。许多向量数据库现在在其技术博客中使用这种方法来测量其性能。请参见[Qdrant基准](https://qdrant.tech/benchmarks/)和[Timescale基准](https://www.timescale.com/blog/how-we-made-postgresql-the-best-vector-database/)。
- en: Static workload benchmark has been useful because the result is easy to understand
    and allows us to compare the accuracy and query performance trade-off across different
    indexing algorithms using a same plot.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 静态负载基准测试是有用的，因为结果易于理解，并允许我们通过相同的图表比较不同索引算法之间的准确度和查询性能权衡。
- en: Except it is not nearly a complete evaluation of ANN indexes, and you **should
    not** choose ANN index for your project based only on this. It overly stresses
    on recall accuracy and query performance while skipping other important aspects
    like indexing performance and memory usage.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 除非这是对 ANN 索引的完整评估，否则你**不应**仅仅根据这一点选择 ANN 索引。它过分强调了召回准确性和查询性能，而忽略了其他重要方面，如索引性能和内存使用。
- en: Indexing performance should be reflected.
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 索引性能应当被反映出来。
- en: Indexing throughput measures how fast the ANN index can accept new data points.
    Similar to query throughput, it is typically inversely correlated to recall accuracy.
    For example, the plot below shows the relationship between indexing throughput
    and recall of HNSWLIB and DiskANN Vamana indexes.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 索引吞吐量衡量了 ANN 索引接受新数据点的速度。与查询吞吐量类似，它通常与召回准确性呈反比。例如，下面的图展示了 HNSWLIB 和 DiskANN
    Vamana 索引的索引吞吐量与召回之间的关系。
- en: '![](../Images/e481403afedb2918d24c7f046316afa0.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e481403afedb2918d24c7f046316afa0.png)'
- en: Recall vs. Indexing Throughput of HNSWLIB and DiskANN Vamana on OpenAI 1M. Image
    by the author.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: HNSWLIB 和 DiskANN Vamana 在 OpenAI 1M 上的召回率与索引吞吐量。图片由作者提供。
- en: This plot is similar to the previous Recall-QPS plot, but from this plot you
    can see that higher recall is also a tradeoff of index performance. However, if
    I am interested in both indexing and query performance, this plot is still insufficient
    because it does not show the margin of which the recall-performance tradeoff is
    being made, as the static benchmark segregates indexing and querying workloads.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图与之前的 Recall-QPS 图类似，但从这张图中你可以看到更高的召回率也是索引性能的权衡。如果我对索引和查询性能都感兴趣，这张图仍然不够充分，因为它没有显示出召回性能权衡的边界，因为静态基准测试将索引和查询负载分开。
- en: Many ANN indexes support bulk indexing API which can be much more optimized
    than point indexing (i.e., add vectors one at a time) and can create a more accurate
    index. For example, cluster-based ANN indexes build clusters of all vectors in
    batch. The static workload benchmark separates indexing and query workloads, so
    it encourages bulk indexing which may not be realistic.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 许多 ANN 索引支持批量索引 API，这比逐点索引（即，一次添加一个向量）优化得多，并且可以创建更准确的索引。例如，基于簇的 ANN 索引在批量中构建所有向量的簇。静态工作负载基准将索引和查询负载分开，因此它鼓励批量索引，这可能不切实际。
- en: One more issue related to indexing is product quantization (PQ). Many ANN indexes
    use PQ or other forms of vector compression to speed up compute. The static workload
    benchmark allows ANN indexes to build optimized compression codebook before the
    query phase starts, but such optimal codebook may not be achievable in practice.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个与索引相关的问题是产品量化（PQ）。许多 ANN 索引使用 PQ 或其他形式的向量压缩来加速计算。静态工作负载基准允许 ANN 索引在查询阶段开始之前构建优化的压缩代码本，但这样的最佳代码本在实践中可能无法实现。
- en: Memory usage matters.
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内存使用很重要。
- en: Most of the popular ANN indexes are in-memory, meaning their main data structure
    stays in volatile storage (DRAM) from which queries are served. Therefore, it
    is important to measure memory efficiency and its tradeoff with performance and
    recall accuracy. For example, in [this research paper](https://www.microsoft.com/en-us/research/publication/hm-ann-efficient-billion-point-nearest-neighbor-search-on-heterogeneous-memory/),
    the authors measured the memory usage of HNSW with 1 billion points to be 490
    GB, while [NSG](https://github.com/ZJULearning/nsg) is 303 GB, but on the recall
    and query performance side HNSW only slightly dominates NSG. This kind of trade-off
    should be front-and-center when it comes to benchmarking ANN indexes.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数流行的 ANN 索引都是内存中的，这意味着它们的主要数据结构保持在易失性存储（DRAM）中以供查询。因此，衡量内存效率及其与性能和召回准确性的权衡是很重要的。例如，在[这篇研究论文](https://www.microsoft.com/en-us/research/publication/hm-ann-efficient-billion-point-nearest-neighbor-search-on-heterogeneous-memory/)中，作者测量了
    HNSW 在 10 亿点下的内存使用为 490 GB，而[NSG](https://github.com/ZJULearning/nsg)为 303 GB，但在召回和查询性能方面，HNSW
    仅略微优于 NSG。进行 ANN 索引基准测试时，这种权衡应当被重点考虑。
- en: Still, it is difficult get a realistic picture of memory efficiency with only
    static benchmark for several reasons. For one, the ANN index algorithm can create
    a read-optimized index that is very compact at the expensive of subsequent indexing
    performance. For another, the workload only captures pure indexing or pure query
    but not a mix of both, which is more likely to happen in a real scenario like
    Q&A engine or chatbot when new data arrives constantly.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仅用静态基准很难获得内存效率的现实图景，原因有几个。首先，ANN索引算法可以创建一个读取优化的索引，这样虽然索引很紧凑，但会影响随后的索引性能。其次，工作负载只捕捉纯粹的索引或纯粹的查询，而不是两者的混合，这在实际场景中，如问答引擎或聊天机器人，数据不断到达时更为常见。
- en: Data distribution shifts over time.
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据分布随时间变化。
- en: In static benchmark, the data and query sets are unchanged. This is not realistic
    as data and queries are driven by end users’ interest which changes over time.
    If the data and query sets are always fixed, then the best index is a cache that
    memorizes every query result. Recently, research in ANN indexes (e.g., [FreshDiskANN](https://arxiv.org/abs/2105.09613))
    have started to measure out-of-distribution query performance — it is a right
    step forward.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在静态基准中，数据和查询集保持不变。这并不现实，因为数据和查询是由最终用户的兴趣驱动的，而这些兴趣会随着时间变化。如果数据和查询集始终固定，那么最佳的索引就是一个记住每个查询结果的缓存。最近，ANN索引的研究（例如，[FreshDiskANN](https://arxiv.org/abs/2105.09613)）开始测量分布外查询性能——这是一个正确的进步。
- en: What about deletes?
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除的情况如何？
- en: Delete API has become standard for ANN indexes, but no static benchmark is measuring
    this. Being able to handle deletes is important as the emerging AI-related application
    scenarios like chatbot are using ANN index as an operational storage that resembles
    online transaction processing (OLTP) databases, as data is constantly being added
    and modified.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 删除API已经成为ANN索引的标准，但没有静态基准在测量这一点。能够处理删除是重要的，因为新兴的AI相关应用场景如聊天机器人将ANN索引作为类似于在线事务处理（OLTP）数据库的操作存储，因为数据不断被添加和修改。
- en: 2\. Streaming workload tells you a lot more.
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 流式工作负载提供了更多信息。
- en: 'If an ANN index supports the following APIs:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个ANN索引支持以下API：
- en: Insert(ID, vector)
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 插入(ID, vector)
- en: Query(vector)
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询(vector)
- en: Delete(ID)
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除(ID)
- en: and if the usage scenario is anything but static data and queries (like, every
    scenario?), then a streaming workload benchmark can give you more insight into
    the characteristics of ANN indexes and how well they perform for your specific
    usage scenario.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用场景不仅仅是静态数据和查询（比如，所有场景？），那么流式工作负载基准可以让你更深入地了解ANN索引的特性以及它们在特定使用场景中的表现。
- en: 'A streaming workload benchmark consists of two streams: a data stream that
    corresponds to a sequence of Insert and Delete API calls, and a query stream for
    a sequence of Query API calls. It can be realized using an actual streaming system
    like Kafka, or more simply using a runbook with sequences of pointers to a data
    set and a query set similar to those used by a static benchmark.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 流式工作负载基准包括两个流：一个数据流，对应一系列的插入和删除API调用；另一个查询流，对应一系列的查询API调用。它可以通过实际的流式系统如Kafka实现，或者更简单地使用运行手册，其中包含指向数据集和查询集的序列，类似于静态基准中使用的那些。
- en: '![](../Images/8ef25c99d58a3e5a08ef908914096487.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8ef25c99d58a3e5a08ef908914096487.png)'
- en: A simple streaming workload benchmark that uses a runbook. Image by the author.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 使用运行手册的简单流式工作负载基准。图片由作者提供。
- en: 'The above diagram illustrates the streaming workload benchmark used in the
    [NeurIPS 23'' Big ANN Benchmarks](https://big-ann-benchmarks.com/). Specifically,
    each step in the runbook corresponds to a batch of vectors, so the operations
    can be executed in parallel. This approach has the following benefits:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图示展示了[NeurIPS 23' 大型ANN基准](https://big-ann-benchmarks.com/)中使用的流式工作负载基准。具体来说，运行手册中的每一步对应一批向量，因此操作可以并行执行。这种方法具有以下优点：
- en: '**Flexibility:** workload patterns and data distribution shifts can be modelled
    as different streaming workloads which then get compiled to different runbooks.'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**灵活性：** 工作负载模式和数据分布变化可以被建模为不同的流式工作负载，然后编译成不同的运行手册。'
- en: '**Realistic:** indexing and query are interleaved so the ANN index must accommodate
    future insertions. Besides, the memory profile more accurately reflects real workload.'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**现实性：** 索引和查询交替进行，因此ANN索引必须适应未来的插入。此外，内存配置更准确地反映了实际工作负载。'
- en: '**Simple analysis:** performance can be described using overall throughput
    rather than indexing vs. query throughputs, so the tradeoff between recall and
    performance can be visualized easily.'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**简单分析：** 性能可以通过整体吞吐量来描述，而不是索引与查询吞吐量，因此可以轻松地可视化召回率与性能之间的权衡。'
- en: '**Completeness:** insert and delete operations are also evaluated.'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**完整性：** 插入和删除操作也进行了评估。'
- en: In this blog post, I deep dive into (4) above and show you a new insight I discovered
    using a streaming workload benchmark.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我深入探讨了上述（4）点，并展示了我通过流式工作负载基准测试发现的新见解。
- en: 'Compare recall stability: HNSW vs. Vamana'
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较召回稳定性：HNSW与Vamana
- en: When running a streaming workload benchmark, an important metric we collect
    is the recall of each query operation. We can compare different index setups (parameters,
    algorithms, etc.) by looking at their recall stability over time, and decide which
    index is suitable for a given usage scenario.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行流式工作负载基准测试时，我们收集的一个重要指标是每个查询操作的召回率。我们可以通过查看不同索引设置（参数、算法等）的召回稳定性随时间的变化来进行比较，并决定哪个索引适用于特定的使用场景。
- en: I measured the recall stability of [DiskANN’s](https://github.com/microsoft/DiskANN)
    Vamana and various HNSW implementations under the streaming workload defined by
    the final runbook in the [NeurIPS 23' Big ANN Benchmarks](http://big-ann-benchmarks.com/neurips23.html).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我测量了[DiskANN](https://github.com/microsoft/DiskANN)的Vamana和各种HNSW实现的召回稳定性，测试是在[NeurIPS
    23' Big ANN Benchmarks](http://big-ann-benchmarks.com/neurips23.html)中定义的流式工作负载下进行的。
- en: 'Some background on Vamana and HNSW: they are both graph ANN indexes, and they
    are particularly good at handling embeddings. In a graph ANN index, each vector
    is a node, and query is executed as graph traversal. Directed edges are selectively
    constructed to limit memory usage while guaranteeing fast traversal from any node
    to any node. During in-place delete, for each in-coming neighbor node of a deleted
    node, graph ANN indexes perform edge repair to maintain the directed graph structure.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 关于Vamana和HNSW的一些背景：它们都是图形ANN索引，并且特别擅长处理嵌入。在图形ANN索引中，每个向量是一个节点，查询作为图形遍历执行。有向边被选择性地构造，以限制内存使用，同时保证从任何节点到任何节点的快速遍历。在原地删除期间，对于每个即将到来的邻居节点，图形ANN索引执行边修复以维护有向图结构。
- en: The first HNSW implementation we use is one based on [HNSWLIB](https://github.com/nmslib/hnswlib),
    with added Delete API implemented using a repair algorithm called `[repairConnectionsForUpdate](https://github.com/nmslib/hnswlib/blob/359b2ba87358224963986f709e593d799064ace6/hnswlib/hnswalg.h#L987)`,
    which is already part of HNSWLIB’s source code. The idea is to perform a "re-insert"
    of the node to be repaired and update its out-going neighbors at all levels. The
    figure blow shows the recall over time for both Vamana and HNSW.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的第一个HNSW实现是基于[HNSWLIB](https://github.com/nmslib/hnswlib)的，增加了使用名为`[repairConnectionsForUpdate](https://github.com/nmslib/hnswlib/blob/359b2ba87358224963986f709e593d799064ace6/hnswlib/hnswalg.h#L987)`的修复算法实现的删除API，该算法已是HNSWLIB源代码的一部分。其思想是对需要修复的节点执行“重新插入”，并在所有层级上更新其出度邻居。下图展示了Vamana和HNSW的召回率随时间的变化。
- en: '![](../Images/26c58cfb3d502e6ab1ffa284963901bf.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/26c58cfb3d502e6ab1ffa284963901bf.png)'
- en: Recall stability of DiskANN’s Vamana and an HNSW implementation based on HNSWLIB.
    Delete API calls are marked as “X”s. Image by the author.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: DiskANN的Vamana与基于HNSWLIB的HNSW实现的召回稳定性。删除API调用标记为“X”。图片由作者提供。
- en: Note that I set Vamana’s maximum degree parameter to 40 (`R = 40`) and HNSW’s
    base layer’s maximum degree also to 40 (`M = 20, M0 = 40`). So, they should use
    more-or-less the same memory.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我将Vamana的最大度参数设置为40（`R = 40`），将HNSW的基础层最大度也设置为40（`M = 20, M0 = 40`）。因此，它们应使用大致相同的内存。
- en: It is clear from this plot that deletes have an adverse effect on recall, as
    recall monotonically decreases during consecutive deletes. In comparison, HNSW
    is much more affected by deletes than Vamana.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 从该图中可以明显看出，删除对召回率有不利影响，因为召回率在连续删除过程中单调下降。相比之下，HNSW受删除的影响远大于Vamana。
- en: The second HNSW implementation we use replaces HNSWLIB’s edge repair algorithm
    with Vamana’s, which is quite different. The idea behind Vamana’s edge repair
    algorithm is to connect each in-coming neighbor of a deleted node to the out-going
    neighbors of the deleted node, while applying a pruning step to maintain a maximum
    degree constraint. In this case, we use HNSW’s original pruning algorithm. It
    is implemented by HNSWLIB in a function called `[getNeighborsByHeuristic2](https://github.com/nmslib/hnswlib/blob/359b2ba87358224963986f709e593d799064ace6/hnswlib/hnswalg.h#L382C16-L382C16)`.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的第二个HNSW实现将HNSWLIB的边修复算法替换为Vamana的，这两者差别很大。Vamana的边修复算法的思想是将每个被删除节点的入邻居连接到被删除节点的出邻居，同时应用修剪步骤以保持最大度约束。在这种情况下，我们使用HNSW原始的修剪算法。它由HNSWLIB在一个名为`[getNeighborsByHeuristic2](https://github.com/nmslib/hnswlib/blob/359b2ba87358224963986f709e593d799064ace6/hnswlib/hnswalg.h#L382C16-L382C16)`的函数中实现。
- en: '![](../Images/49624e6da662d3d8e04325ab4b8f3c48.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/49624e6da662d3d8e04325ab4b8f3c48.png)'
- en: Recall stability of DiskANN’s Vamana and an HNSW implementation using Vamana’s
    edge repair algorithm to handle deletion. Image by the author.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾DiskANN的Vamana和一个使用Vamana边修复算法处理删除的HNSW实现。图片由作者提供。
- en: With all parameters staying the same, changing HNSWLIB’s edge repair algorithm
    to Vamana’s immediately improved HNSW’s recall stability.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有参数保持不变的情况下，将HNSWLIB的边修复算法更改为Vamana的，HNSW的召回稳定性立即得到了改善。
- en: Let’s go an extra mile and change the HNSW’s edge pruning algorithm to Vamana’s.
    Now the HNSW index is nearly the same as Vamana’s, except that it has multiple
    layers. We call this index “Multi-layer Vamana”.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们多做一点工作，将HNSW的边修剪算法改为Vamana的。现在HNSW索引与Vamana的几乎相同，唯一的不同是它有多个层级。我们称这个索引为“多层Vamana”。
- en: '![](../Images/b9dff422ba7877a4bc1409d8191e5cf5.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b9dff422ba7877a4bc1409d8191e5cf5.png)'
- en: Recall stability of DiskANN’s Vamana and an HNSW implementation using Vamana’s
    edge repair and pruning algorithms — “multi-layer Vamana”. Image by the author.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾DiskANN的Vamana和一个使用Vamana边修复和修剪算法的HNSW实现——“多层Vamana”。图片由作者提供。
- en: You can see HNSW’s recall is now slightly higher than Vamana’s while using a
    similar amount of memory. I haven’t found this is observation in any research
    paper anywhere. Moreover, while performance is not in the figure, I noticed significant
    slowdown when switching to Vamana’s pruning algorithm.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到HNSW的召回率现在略高于Vamana的，同时使用了类似的内存。我还没有在任何研究论文中发现这一观察结果。此外，虽然图中没有性能数据，但我注意到在切换到Vamana的修剪算法时性能显著下降。
- en: In conclusion, by using the streaming workload benchmark, I was able to discover
    something new about different edge repair and pruning algorithms. A logical next
    step would be to look into the performance implications of these algorithms, and
    I can do this using the streaming workload benchmark.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，通过使用流式工作负载基准测试，我能够发现有关不同边修复和修剪算法的新信息。一个合乎逻辑的下一步是研究这些算法的性能影响，我可以通过流式工作负载基准测试来实现这一点。
- en: 3\. Conclusion
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 结论
- en: To summarize, in this blog post, I pointed out that static workload benchmarks
    are insufficient for realistic evaluation of ANN indexes, and I described streaming
    workload benchmark which I think is a better replacement. I also used a specific
    streaming workload to uncover a new comparison between HNSW and Vamana indexes.
    Kudos to the team behind the [NeurIPS 23' Big ANN Benchmarks](http://big-ann-benchmarks.com/neurips21.html)!
    They have open sourced the streaming workload I used in this blog post.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，在这篇博客文章中，我指出了静态工作负载基准测试不足以真实评估ANN索引，并描述了我认为更好的替代方案——流式工作负载基准测试。我还使用了一个特定的流式工作负载来揭示HNSW和Vamana索引之间的新对比。感谢[NeurIPS
    23' Big ANN Benchmarks](http://big-ann-benchmarks.com/neurips21.html)团队！他们已经开源了我在这篇博客文章中使用的流式工作负载。
- en: We need a TPC-C and TPC-H for vector databases.
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们需要一个用于向量数据库的TPC-C和TPC-H。
- en: There is still a lot of work to be done in benchmarking. ANN index is the core
    feature of vector databases, and they have raised [over 350 million dollars](https://www.cbinsights.com/research/generative-ai-infrastructure-vector-database/).
    Yet many of them are still measuring performance using an outdated approach that
    no longer reflect actual usage scenarios. Database systems underwent a similar
    stage in the 90s and early 2000s. Then, standard benchmarks like TPC-C and TPC-H
    were developed and are still used today. We should have something like this for
    vector databases.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在基准测试方面仍有很多工作要做。ANN 索引是向量数据库的核心特征，它们已经筹集了[超过3.5亿美元](https://www.cbinsights.com/research/generative-ai-infrastructure-vector-database/)。然而，其中许多仍在使用一种过时的方法来衡量性能，这种方法已经不能反映实际使用场景。数据库系统在90年代和2000年代初经历了类似的阶段。随后，像
    TPC-C 和 TPC-H 这样的标准基准被开发出来，并且至今仍在使用。我们应该为向量数据库也制定类似的标准。
