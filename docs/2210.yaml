- en: 'Harnessing the Power of Knowledge Graphs: Enriching an LLM with Structured
    Data'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/harnessing-the-power-of-knowledge-graphs-enriching-an-llm-with-structured-data-997fabc62386?source=collection_archive---------2-----------------------#2023-07-10](https://towardsdatascience.com/harnessing-the-power-of-knowledge-graphs-enriching-an-llm-with-structured-data-997fabc62386?source=collection_archive---------2-----------------------#2023-07-10)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/e32186b4eaa2e36dee4c8c50e5110b8f.png)'
  prefs: []
  type: TYPE_IMG
- en: A step-by-step guide to creating a knowledge graph and exploring its potential
    to enhance an LLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://stevehedden.medium.com/?source=post_page-----997fabc62386--------------------------------)[![Steve
    Hedden](../Images/af7bec4a191ab857eccd885dd89e88b4.png)](https://stevehedden.medium.com/?source=post_page-----997fabc62386--------------------------------)[](https://towardsdatascience.com/?source=post_page-----997fabc62386--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----997fabc62386--------------------------------)
    [Steve Hedden](https://stevehedden.medium.com/?source=post_page-----997fabc62386--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2c634ce75a74&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fharnessing-the-power-of-knowledge-graphs-enriching-an-llm-with-structured-data-997fabc62386&user=Steve+Hedden&userId=2c634ce75a74&source=post_page-2c634ce75a74----997fabc62386---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----997fabc62386--------------------------------)
    ·20 min read·Jul 10, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F997fabc62386&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fharnessing-the-power-of-knowledge-graphs-enriching-an-llm-with-structured-data-997fabc62386&user=Steve+Hedden&userId=2c634ce75a74&source=-----997fabc62386---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F997fabc62386&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fharnessing-the-power-of-knowledge-graphs-enriching-an-llm-with-structured-data-997fabc62386&source=-----997fabc62386---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: '*For accompanying code, see notebook* [*here.*](https://github.com/SteveHedden/kg_llm/blob/main/SDKG.ipynb)'
  prefs: []
  type: TYPE_NORMAL
- en: In recent years, [large language models](https://snorkel.ai/large-language-models-llms/)
    (LLMs), have become ubiquitous. Perhaps the most famous LLM is ChatGPT, which
    was released by OpenAI in November 2022\. ChatGPT is able to [generate ideas](https://www.linkedin.com/pulse/generate-100-content-ideas-chat-gpt-mfon-akpan/),
    [give personalized recommendations](https://bootcamp.uxdesign.cc/how-to-use-chatgpt-for-personalized-recommendations-840e01dcad89),
    [understand complicated topics](https://medium.com/101-innovation-hacks/using-chatgpt-to-explain-complex-concepts-2ea6aba97cf3),
    [act as a writing assistant](https://chatgptwriter.ai/), or [help you build a
    model to predict the Academy Awards.](https://medium.com/design-bootcamp/using-chatgpt-to-predict-the-oscars-c6d8cdb6b3a0)
    Meta has announced their own LLM called [LLaMA](https://ai.meta.com/blog/large-language-model-llama-meta-ai/),
    Google has [LaMDA](https://blog.google/technology/ai/lamda/), and there is even
    an open-source alternative, [BLOOM.](https://huggingface.co/bigscience/bloom)
  prefs: []
  type: TYPE_NORMAL
- en: 'LLMs have excelled in natural language processing (NLP) tasks like the ones
    listed above because LLMs have historically focused on [unstructured data](https://en.wikipedia.org/wiki/Unstructured_data)
    — data that does not have a pre-defined structure, and is usually text-heavy.
    I asked ChatGPT, “why have LLMs historically focused on unstructured data?” The
    reply was:'
  prefs: []
  type: TYPE_NORMAL
- en: “LLMs have historically focused on unstructured data due to its abundance, availability,
    and the challenges it poses. Unstructured data provides a vast source for training
    language models, allowing them to learn patterns, context, and semantics. LLMs
    excel in handling…
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
