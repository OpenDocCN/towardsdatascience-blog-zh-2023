- en: A Comprehensive Overview of Gaussian Splatting
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/a-comprehensive-overview-of-gaussian-splatting-e7d570081362?source=collection_archive---------0-----------------------#2023-12-23](https://towardsdatascience.com/a-comprehensive-overview-of-gaussian-splatting-e7d570081362?source=collection_archive---------0-----------------------#2023-12-23)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Everything you need to know about the new trend in the field of 3D representations
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://yurkovak.medium.com/?source=post_page-----e7d570081362--------------------------------)[![Kate
    Yurkova](../Images/c29a9d59d1b8227d189b12a8adb5bbfa.png)](https://yurkovak.medium.com/?source=post_page-----e7d570081362--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e7d570081362--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e7d570081362--------------------------------)
    [Kate Yurkova](https://yurkovak.medium.com/?source=post_page-----e7d570081362--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F16ecfab4b128&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-overview-of-gaussian-splatting-e7d570081362&user=Kate+Yurkova&userId=16ecfab4b128&source=post_page-16ecfab4b128----e7d570081362---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e7d570081362--------------------------------)
    Â·12 min readÂ·Dec 23, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe7d570081362&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-overview-of-gaussian-splatting-e7d570081362&user=Kate+Yurkova&userId=16ecfab4b128&source=-----e7d570081362---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe7d570081362&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-overview-of-gaussian-splatting-e7d570081362&source=-----e7d570081362---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Gaussian splatting is a method for representing 3D scenes and rendering novel
    views introduced in â€œ3D Gaussian Splatting for Real-Time Radiance Field Renderingâ€Â¹.
    **It can be thought of as an alternative to NeRFÂ²-like models**, and just like
    NeRF back in the day, Gaussian splatting led to [lots of new research works](https://github.com/MrNeRF/awesome-3D-gaussian-splatting)
    that chose to use it as an underlying representation of a 3D world for various
    use cases. So whatâ€™s so special about it and why is it better than NeRF? Or is
    it, even? Letâ€™s find out!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: 'Table of contents:'
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[TL;DR](#fbb7)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Representing a 3D world](#4012)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Image formation model & rendering](#9bb2)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Optimization](#6c97)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[View-dependant colors with SH](#4cd8)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[è§†å›¾ä¾èµ–é¢œè‰²ä¸SH](#4cd8)'
- en: '[Limitations](#3c15)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[é™åˆ¶](#3c15)'
- en: '[Where to play with it](#1a92)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[åœ¨å“ªé‡Œç©](#1a92)'
- en: TL;DR
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TL;DR
- en: First and foremost, the main claim to fame of this work was **the high rendering
    speed** as can be understood from the title. This is due to the representation
    itself which will be covered below and thanks to the tailored implementation of
    a rendering algorithm with custom CUDA kernels.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œè¿™é¡¹å·¥ä½œçš„ä¸»è¦äº®ç‚¹æ˜¯**é«˜æ¸²æŸ“é€Ÿåº¦**ï¼Œå¦‚æ ‡é¢˜æ‰€ç¤ºã€‚è¿™å½’åŠŸäºè¡¨ç¤ºæœ¬èº«ï¼ˆå°†åœ¨ä¸‹æ–‡ä¸­ä»‹ç»ï¼‰ä»¥åŠå®šåˆ¶çš„CUDAå†…æ ¸æ¸²æŸ“ç®—æ³•çš„å®ç°ã€‚
- en: '![](../Images/448d1c345960722b064124d7883df986.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/448d1c345960722b064124d7883df986.png)'
- en: '**Figure 1:** A side-by-side comparison of previous high-quality representations
    and Gaussian Splatting (marked as â€œOursâ€) in terms of rendering speed (fps), training
    time (min), and visual quality (Peak signal-to-noise ratio, the higher the better)
    [Source: taken from [1]]'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾1ï¼š** ä»¥æ¸²æŸ“é€Ÿåº¦ï¼ˆfpsï¼‰ã€è®­ç»ƒæ—¶é—´ï¼ˆminï¼‰å’Œè§†è§‰è´¨é‡ï¼ˆå³°å€¼ä¿¡å™ªæ¯”ï¼Œè¶Šé«˜è¶Šå¥½ï¼‰å¯¹æ¯”ä¹‹å‰çš„é«˜è´¨é‡è¡¨ç°å’Œé«˜æ–¯æº…å°„ï¼ˆæ ‡è®°ä¸ºâ€œæˆ‘ä»¬çš„â€ï¼‰[æ¥æºï¼šå–è‡ª[1]]'
- en: Additionally, Gaussian splatting **doesnâ€™t involve any neural network at all**.
    There isnâ€™t even a small MLP, nothing â€œneuralâ€, a scene is essentially just a
    set of points in space. This in itself is already an attention grabber. It is
    quite refreshing to see such a method gaining popularity in our AI-obsessed world
    with research companies chasing models comprised of more and more billions of
    parameters. Its idea stems from â€œSurface splattingâ€Â³ (2001) so it sets a cool
    example that classic computer vision approaches can still inspire relevant solutions.
    Its simple and explicit representation makes Gaussian splatting particularly **interpretable**,
    a very good reason to choose it over NeRFs for some applications.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œé«˜æ–¯æº…å°„**å®Œå…¨ä¸æ¶‰åŠä»»ä½•ç¥ç»ç½‘ç»œ**ã€‚ç”šè‡³æ²¡æœ‰ä¸€ä¸ªå°çš„MLPï¼Œå®Œå…¨æ²¡æœ‰â€œç¥ç»â€æˆåˆ†ï¼Œåœºæ™¯æœ¬è´¨ä¸Šåªæ˜¯ç©ºé—´ä¸­çš„ä¸€ç»„ç‚¹ã€‚è¿™æœ¬èº«å·²ç»éå¸¸å¸å¼•æ³¨æ„åŠ›ã€‚åœ¨æˆ‘ä»¬å¯¹AIç—´è¿·çš„ä¸–ç•Œä¸­ï¼Œçœ‹åˆ°è¿™æ ·çš„æ–¹æ³•é€æ¸æµè¡Œï¼Œä¸é‚£äº›è¿½é€åŒ…å«æ›´å¤šæ•°åäº¿å‚æ•°çš„æ¨¡å‹çš„ç ”ç©¶å…¬å¸ç›¸æ¯”ï¼Œé¢‡å…·æ¸…æ–°æ„Ÿã€‚å®ƒçš„ç†å¿µæ¥æºäºâ€œè¡¨é¢æº…å°„â€Â³ï¼ˆ2001ï¼‰ï¼Œå› æ­¤å®ƒä¸ºç»å…¸è®¡ç®—æœºè§†è§‰æ–¹æ³•ä»ç„¶å¯ä»¥æ¿€å‘ç›¸å…³è§£å†³æ–¹æ¡ˆæ ‘ç«‹äº†ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ã€‚å…¶ç®€å•è€Œæ˜ç¡®çš„è¡¨ç¤ºä½¿å¾—é«˜æ–¯æº…å°„ç‰¹åˆ«**å¯è§£é‡Š**ï¼Œè¿™æ˜¯åœ¨ä¸€äº›åº”ç”¨ä¸­é€‰æ‹©å®ƒè€Œä¸æ˜¯NeRFsçš„ä¸€ä¸ªéå¸¸å¥½çš„ç†ç”±ã€‚
- en: Representing a 3D world
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»£è¡¨ä¸€ä¸ª3Dä¸–ç•Œ
- en: As mentioned earlier, in Gaussian splatting a 3D world is represented with a
    set of 3D points, in fact, millions of them, in a ballpark of 0.5â€“5 million. Each
    point is a 3D Gaussian with its own **unique parameters that are fitted per scene**
    such that renders of this scene match closely to the known dataset images. The
    optimization and rendering processes will be discussed later so letâ€™s focus for
    a moment on the necessary parameters.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å‰æ‰€è¿°ï¼Œåœ¨é«˜æ–¯æº…å°„ä¸­ï¼Œä¸€ä¸ª3Dä¸–ç•Œæ˜¯ç”±ä¸€ç»„3Dç‚¹è¡¨ç¤ºçš„ï¼Œå®é™…ä¸Šæ˜¯æ•°ç™¾ä¸‡ä¸ªï¼Œæ•°é‡åœ¨0.5-5ç™¾ä¸‡çš„èŒƒå›´å†…ã€‚æ¯ä¸ªç‚¹æ˜¯ä¸€ä¸ª3Dé«˜æ–¯ï¼Œå…¶**å”¯ä¸€çš„å‚æ•°é’ˆå¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œæ‹Ÿåˆ**ï¼Œä½¿å¾—è¯¥åœºæ™¯çš„æ¸²æŸ“ä¸å·²çŸ¥æ•°æ®é›†å›¾åƒéå¸¸åŒ¹é…ã€‚ä¼˜åŒ–å’Œæ¸²æŸ“è¿‡ç¨‹å°†åœ¨åé¢è®¨è®ºï¼Œå› æ­¤ç°åœ¨æˆ‘ä»¬æš‚æ—¶å…³æ³¨å¿…è¦çš„å‚æ•°ã€‚
- en: '![](../Images/06cdb742a5dc51d20f3b47bbf79b848d.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/06cdb742a5dc51d20f3b47bbf79b848d.png)'
- en: '**Figure 2:** Centers of Gaussian (means) [Source: taken from Dynamic 3D Gaussiansâ´]'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾2ï¼š** é«˜æ–¯ä¸­å¿ƒï¼ˆå‡å€¼ï¼‰[æ¥æºï¼šå–è‡ªåŠ¨æ€3Dé«˜æ–¯â´]'
- en: '**Each 3D Gaussian is parametrized by:**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ¯ä¸ª3Dé«˜æ–¯ç”±ä»¥ä¸‹å‚æ•°åŒ–ï¼š**'
- en: Mean **Î¼** interpretable as location x, y, z;
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡å€¼**Î¼**å¯ä»¥è§£é‡Šä¸ºä½ç½®x, y, zï¼›
- en: Covariance **Î£**;
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åæ–¹å·®**Î£**ï¼›
- en: Opacity **Ïƒ(ğ›¼)**, a sigmoid function is applied to map the parameter to the
    [0, 1] interval;
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸é€æ˜åº¦**Ïƒ(ğ›¼)**ï¼Œåº”ç”¨äº†ä¸€ä¸ª sigmoid å‡½æ•°æ¥å°†å‚æ•°æ˜ å°„åˆ°[0, 1]åŒºé—´ï¼›
- en: '**Color parameters**, either 3 values for (R, G, B) or spherical harmonics
    (SH) coefficients.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é¢œè‰²å‚æ•°**ï¼Œå¯ä»¥æ˜¯ï¼ˆR, G, Bï¼‰çš„3ä¸ªå€¼æˆ–çƒé¢è°æ³¢ï¼ˆSHï¼‰ç³»æ•°ã€‚'
- en: 'Two groups of parameters here need further discussion, a covariance matrix
    and SH. There is a separate section dedicated to the latter. As for the covariance,
    it is chosen to be anisotropic by design, that is, not [isotropic](https://stats.stackexchange.com/questions/204595/what-is-an-isotropic-spherical-covariance-matrix).
    Practically, it means that **a 3D point can be an ellipsoid rotated and stretched
    along any direction in space**. It could have required 9 parameters, however,
    they cannot be optimized directly because a covariance matrix has a physical meaning
    only if itâ€™s [a positive semi-definite matrix](https://en.wikipedia.org/wiki/Definite_matrix).
    Using gradient descent for optimization makes it hard to pose such constraints
    on a matrix directly, that is why it is factorized instead as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸¤ç»„å‚æ•°éœ€è¦è¿›ä¸€æ­¥è®¨è®ºï¼Œä¸€ç»„æ˜¯åæ–¹å·®çŸ©é˜µï¼Œå¦ä¸€ç»„æ˜¯SHã€‚åè€…æœ‰ä¸€ä¸ªä¸“é—¨çš„ç« èŠ‚è¿›è¡Œè®¨è®ºã€‚è‡³äºåæ–¹å·®ï¼Œå®ƒè¢«è®¾è®¡ä¸ºå„å‘å¼‚æ€§çš„ï¼Œå³ä¸æ˜¯[å„å‘åŒæ€§](https://stats.stackexchange.com/questions/204595/what-is-an-isotropic-spherical-covariance-matrix)ã€‚å®é™…ä¸Šï¼Œè¿™æ„å‘³ç€**ä¸€ä¸ª3Dç‚¹å¯ä»¥æ˜¯ä¸€ä¸ªåœ¨ç©ºé—´ä¸­æ²¿ä»»æ„æ–¹å‘æ—‹è½¬å’Œæ‹‰ä¼¸çš„æ¤­çƒä½“**ã€‚å®ƒæœ¬æ¥éœ€è¦9ä¸ªå‚æ•°ï¼Œä½†ç”±äºåæ–¹å·®çŸ©é˜µåªæœ‰åœ¨å®ƒæ˜¯[åŠæ­£å®šçŸ©é˜µ](https://en.wikipedia.org/wiki/Definite_matrix)æ—¶æ‰æœ‰ç‰©ç†æ„ä¹‰ï¼Œå› æ­¤è¿™äº›å‚æ•°ä¸èƒ½ç›´æ¥ä¼˜åŒ–ã€‚ä½¿ç”¨æ¢¯åº¦ä¸‹é™è¿›è¡Œä¼˜åŒ–ä½¿å¾—ç›´æ¥å¯¹çŸ©é˜µæ–½åŠ è¿™æ ·çš„çº¦æŸå˜å¾—å›°éš¾ï¼Œå› æ­¤å®ƒè¢«åˆ†è§£å¦‚ä¸‹ï¼š
- en: '![](../Images/b7489bbf981a0b2fad6d3ca1ec4295e7.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b7489bbf981a0b2fad6d3ca1ec4295e7.png)'
- en: 'Such factorization is known as [eigendecomposition of a covariance matrix](https://www.visiondummy.com/2014/04/geometric-interpretation-covariance-matrix/#Covariance_matrix_as_a_linear_transformation)
    and can be understood as a configuration of an ellipsoid where:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§åˆ†è§£è¢«ç§°ä¸º[åæ–¹å·®çŸ©é˜µçš„ç‰¹å¾åˆ†è§£](https://www.visiondummy.com/2014/04/geometric-interpretation-covariance-matrix/#Covariance_matrix_as_a_linear_transformation)ï¼Œå¯ä»¥ç†è§£ä¸ºæ¤­çƒä½“çš„é…ç½®ï¼Œå…¶ä¸­ï¼š
- en: S is a diagonal scaling matrix with 3 parameters for scale;
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S æ˜¯ä¸€ä¸ªå…·æœ‰3ä¸ªç¼©æ”¾å‚æ•°çš„å¯¹è§’ç¼©æ”¾çŸ©é˜µï¼›
- en: R is a 3x3 rotation matrix analytically expressed with 4 quaternions.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: R æ˜¯ä¸€ä¸ªç”¨4ä¸ªå››å…ƒæ•°è§£æè¡¨ç¤ºçš„3x3æ—‹è½¬çŸ©é˜µã€‚
- en: The beauty of using Gaussians lies in the two-fold impact of each point. On
    one hand, each point effectively **represents a limited area** in space close
    to its mean, according to its covariance. On the other hand, it has a **theoretically
    infinite extent** meaning that each Gaussian is defined on the whole 3D space
    and can be evaluated for any point. This is great because during optimization
    it allows gradients to flow from long distances.â´
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒçš„ç¾åœ¨äºæ¯ä¸ªç‚¹çš„åŒé‡å½±å“ã€‚ä¸€æ–¹é¢ï¼Œæ¯ä¸ªç‚¹æ ¹æ®å…¶åæ–¹å·®æœ‰æ•ˆåœ°**è¡¨ç¤ºäº†ç©ºé—´ä¸­æ¥è¿‘å…¶å‡å€¼çš„æœ‰é™åŒºåŸŸ**ã€‚å¦ä¸€æ–¹é¢ï¼Œå®ƒå…·æœ‰**ç†è®ºä¸Šçš„æ— é™èŒƒå›´**ï¼Œè¿™æ„å‘³ç€æ¯ä¸ªé«˜æ–¯åˆ†å¸ƒåœ¨æ•´ä¸ª3Dç©ºé—´ä¸­å®šä¹‰ï¼Œå¹¶ä¸”å¯ä»¥åœ¨ä»»ä½•ç‚¹ä¸Šè¿›è¡Œè¯„ä¼°ã€‚è¿™ä¸€ç‚¹å¾ˆé‡è¦ï¼Œå› ä¸ºåœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œå®ƒå…è®¸æ¢¯åº¦ä»è¾ƒè¿œçš„è·ç¦»ä¼ æ’­ã€‚â´
- en: 'The impact of a 3D Gaussian *i* on an arbitrary 3D point *p* in 3D is defined
    as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 3Dé«˜æ–¯åˆ†å¸ƒçš„ *i* å¯¹ä»»æ„3Dç‚¹ *p* çš„å½±å“å®šä¹‰å¦‚ä¸‹ï¼š
- en: '![](../Images/7cfa4b0ef239eaf9326f095e305af6e7.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7cfa4b0ef239eaf9326f095e305af6e7.png)'
- en: '**Figure 3:** An influence of a 3D Gaussian i on a point p in 3D [Source: Image
    by the author]'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾3ï¼š** 3Dé«˜æ–¯åˆ†å¸ƒ *i* å¯¹3Dç‚¹ *p* çš„å½±å“ [æ¥æºï¼šä½œè€…æä¾›çš„å›¾åƒ]'
- en: This equation looks almost like a probability density function of the [multivariate
    normal distribution](https://en.wikipedia.org/wiki/Multivariate_normal_distribution)
    except the normalization term with a determinant of covariance is ignored and
    it is weighting by the opacity instead.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ–¹ç¨‹çœ‹èµ·æ¥å‡ ä¹åƒæ˜¯[å¤šå˜é‡æ­£æ€åˆ†å¸ƒ](https://en.wikipedia.org/wiki/Multivariate_normal_distribution)çš„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œé™¤äº†å½’ä¸€åŒ–é¡¹çš„åæ–¹å·®è¡Œåˆ—å¼è¢«å¿½ç•¥ï¼Œå–è€Œä»£ä¹‹çš„æ˜¯é€šè¿‡ä¸é€æ˜åº¦åŠ æƒã€‚
- en: '**Image formation model & r**endering'
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**å›¾åƒå½¢æˆæ¨¡å‹ä¸æ¸²æŸ“**'
- en: Image formation model
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å›¾åƒå½¢æˆæ¨¡å‹
- en: 'Given a set of 3D points, possibly, the most interesting part is to see how
    it can be used for rendering. You might be previously familiar with a point-wise
    ğ›¼-blending used in NeRF. Turns out that **NeRFs and Gaussian splatting share the
    same image formation model**. To see this, letâ€™s take a little detour and re-visit
    the volumetric rendering formula given in NeRFÂ² and many of its follow-up works
    (1). We will also rewrite it using simple transitions (2):'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ç»™å®šä¸€ç»„3Dç‚¹ï¼Œå¯èƒ½æœ€æœ‰è¶£çš„éƒ¨åˆ†æ˜¯æŸ¥çœ‹å®ƒå¦‚ä½•ç”¨äºæ¸²æŸ“ã€‚ä½ å¯èƒ½ä¹‹å‰ç†Ÿæ‚‰NeRFä¸­ä½¿ç”¨çš„ç‚¹å¯¹ç‚¹ğ›¼æ··åˆã€‚ç»“æœæ˜¯**NeRFå’Œé«˜æ–¯ç‚¹æŠ•å°„å…±äº«ç›¸åŒçš„å›¾åƒå½¢æˆæ¨¡å‹**ã€‚ä¸ºäº†äº†è§£è¿™ä¸€ç‚¹ï¼Œè®©æˆ‘ä»¬ç¨ä½œç»•é“ï¼Œé‡æ–°è®¿é—®NeRFÂ²åŠå…¶è®¸å¤šåç»­å·¥ä½œçš„ä½“ç§¯æ¸²æŸ“å…¬å¼(1)ã€‚æˆ‘ä»¬è¿˜å°†ä½¿ç”¨ç®€å•çš„è½¬æ¢(2)å¯¹å…¶è¿›è¡Œé‡å†™ï¼š
- en: '![](../Images/b5c04ce9756b8ed2d8cd7c0e13e578ce.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b5c04ce9756b8ed2d8cd7c0e13e578ce.png)'
- en: 'You can refer to the NeRF paper for the definitions of Ïƒ and Î´ but conceptually
    this can be read as follows: in NeRF, color in an image pixel *p* is approximated
    by integrating over samples (MLP predictions) along the ray going through this
    pixel. The final color is **a weighted sum of colors of 3D points sampled along
    this ray, down-weighted by transmittance**. With this in mind, letâ€™s finally look
    at the image formation model of Gaussian splatting:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1dc95bb2be718c79e04d032837b2ba01.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
- en: Indeed, formulas (2) and (3) are almost identical. **The only difference is
    how ğ›¼ is computed** between the two. In Gaussian Splatting, the aggregation for
    each pixel is conducted over the contribution of an ordered list of projected
    2D Gaussians. This small discrepancy turns out extremely significant in practice
    and results in drastically different rendering speeds. In fact, it is **the foundation
    of the real-time performance** of Gaussian splatting.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: To understand why this is the case, we need to understand what *f^{2D}* means
    and which computational demands it poses. This function is simply a projection
    of *f(p)* we saw in the previous section into 2D, i.e. onto an image plane of
    the camera that is being rendered. **Both a 3D point and its projection are multivariate
    Gaussians** so the impact of a projected 2D Gaussian on a pixel can be computed
    using the same formula as the impact of a 3D Gaussian on other points in 3D (see
    Figure 3). The only difference is that the mean Î¼ and covariance Î£ must be projected
    into 2D which is done using derivations from EWA splattingâµ.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: 'Means in 2D can be trivially obtained by projecting a vector *Î¼* in homogeneous
    coordinates (with extra 1 coordinate) into an image plane using an intrinsic camera
    matrix *K* and an extrinsic camera matrix *W=*[*R*|*t*]:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/407712e079d453a1663f3cbcbde84275.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: 'This can be also written in one line as follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a26ec4410ee5dd4848f7bb93562f5403.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
- en: Here â€œzâ€ subscript stands for z-normalization. Covariance in 2D is defined using
    a Jacobian of (4), *J:*
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ef9295f4c347b373be0d195920f39264.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
- en: The whole process remains differentiatable, and that is of course crucial for
    optimization.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: Rendering
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The formula (3) tells us how to get a color in a single pixel. To render an
    entire image, itâ€™s **still necessary to traverse through all the HxW pixels**,
    just like in NeRF, however, the process is much more lightweight because:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: For a given camera, *f(p)* of each 3D point **can be projected into 2D in advance**,
    before iterating over pixels. This way, when a Gaussian is blended for a few nearby
    pixels, we wonâ€™t need to re-project it over and over again.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is **no MLP to be inferenced** HÂ·WÂ·P times for a single image, 2D Gaussians
    are blended onto an image directly.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is **no ambiguity in which 3D point to evaluate** along the ray, no need
    to choose [a ray sampling strategy](https://docs.nerf.studio/nerfology/model_components/visualize_samplers.html).
    A set of 3D points overlapping the ray of each pixel (see *N* in (3)) is discrete
    and fixed after optimization.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ²¿å°„çº¿è¯„ä¼°å“ªä¸ª3Dç‚¹æ²¡æœ‰æ­§ä¹‰**ï¼Œæ— éœ€é€‰æ‹©[å°„çº¿é‡‡æ ·ç­–ç•¥](https://docs.nerf.studio/nerfology/model_components/visualize_samplers.html)ã€‚æ¯ä¸ªåƒç´ å°„çº¿çš„3Dç‚¹é›†ï¼ˆå‚è§(3)ä¸­çš„*N*ï¼‰æ˜¯ç¦»æ•£ä¸”åœ¨ä¼˜åŒ–åå›ºå®šçš„ã€‚'
- en: A pre-processing **sorting stage is done once per frame, on a GPU**, using a
    custom implementation of differentiable CUDA kernels.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„å¤„ç†çš„**æ’åºé˜¶æ®µåœ¨æ¯ä¸€å¸§ä¸­è¿›è¡Œä¸€æ¬¡ï¼Œä½¿ç”¨GPU**ï¼Œé€šè¿‡è‡ªå®šä¹‰çš„å¯å¾®åˆ†CUDAå†…æ ¸å®ç°ã€‚
- en: 'The conceptual difference can be seen in **Figure 4**:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: æ¦‚å¿µä¸Šçš„å·®å¼‚å¯ä»¥åœ¨**å›¾4**ä¸­çœ‹åˆ°ï¼š
- en: '![](../Images/35c2fb9154bbdb55bc710a0fb1ba8356.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/35c2fb9154bbdb55bc710a0fb1ba8356.png)'
- en: '**Figure 4:** A conceptual difference between NeRF and GS, Left: Query a **continuous**
    MLP along the ray, Right: Blend a discrete set of Gaussians relevant to the given
    ray [Source: Image by the author]'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾4ï¼š** NeRFå’ŒGSä¹‹é—´çš„æ¦‚å¿µå·®å¼‚ï¼Œå·¦ï¼šæ²¿å°„çº¿æŸ¥è¯¢**è¿ç»­**çš„MLPï¼Œå³ï¼šæ··åˆä¸ç»™å®šå°„çº¿ç›¸å…³çš„ç¦»æ•£é«˜æ–¯é›†åˆ [æ¥æºï¼šä½œè€…æä¾›çš„å›¾åƒ]'
- en: 'The sorting algorithm mentioned above is one of the contributions of the paper.
    Its purpose is to prepare for color rendering with the formula (3): sorting of
    the 3D points by depth (proximity to an image plane) and grouping them by tiles.
    The first is needed to compute transmittance, and the latter allows to limit the
    weighted sum for each pixel to Î±-blending of the relevant 3D points only (or their
    2D projections, to be more specific). The grouping is achieved using simple 16x16
    pixel tiles and is implemented such that a Gaussian can land in a few tiles if
    it overlaps more than a single view frustum. Thanks to **sorting, the rendering
    of each pixel can be reduced to Î±-blending of pre-ordered points from the tile
    the pixel belongs to.**'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šè¿°æ’åºç®—æ³•æ˜¯è®ºæ–‡çš„ä¸€ä¸ªè´¡çŒ®ã€‚å…¶ç›®çš„æ˜¯ä¸ºäº†é…åˆå…¬å¼(3)è¿›è¡Œé¢œè‰²æ¸²æŸ“ï¼šæŒ‰æ·±åº¦ï¼ˆé è¿‘å›¾åƒå¹³é¢çš„è·ç¦»ï¼‰å¯¹3Dç‚¹è¿›è¡Œæ’åºï¼Œå¹¶æŒ‰å›¾å—è¿›è¡Œåˆ†ç»„ã€‚å‰è€…ç”¨äºè®¡ç®—é€å°„ç‡ï¼Œåè€…åˆ™é™åˆ¶æ¯ä¸ªåƒç´ çš„åŠ æƒå’Œåªå¯¹ç›¸å…³çš„3Dç‚¹è¿›è¡ŒÎ±æ··åˆï¼ˆæˆ–å…¶2DæŠ•å½±ï¼Œæ›´å…·ä½“åœ°è¯´ï¼‰ã€‚åˆ†ç»„æ˜¯é€šè¿‡ç®€å•çš„16x16åƒç´ å›¾å—å®ç°çš„ï¼Œå¹¶ä¸”å®ç°æ–¹å¼ä½¿å¾—ä¸€ä¸ªé«˜æ–¯å¯ä»¥è½åœ¨å¤šä¸ªå›¾å—ä¸­ï¼Œå¦‚æœå®ƒé‡å äº†å¤šä¸ªè§†é”¥ä½“ã€‚å¾—ç›Šäº**æ’åºï¼Œæ¯ä¸ªåƒç´ çš„æ¸²æŸ“å¯ä»¥ç®€åŒ–ä¸ºä»åƒç´ æ‰€å±çš„å›¾å—ä¸­é¢„æ’åºç‚¹çš„Î±æ··åˆã€‚**
- en: '![](../Images/5e97817449a482b9581c75363e79d003.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5e97817449a482b9581c75363e79d003.png)'
- en: '**Figure 5:** View frustums, each corresponding to a 16x16 image tile. Colors
    have no special meaning. The result of the sorting algorithm is a subset of 3D
    points within each tile sorted by depth. [Source: Based on the plots from [here](https://docs.nerf.studio/nerfology/model_components/visualize_samples.html#d-frustum)]'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾5ï¼š** è§†é”¥ä½“ï¼Œæ¯ä¸ªè§†é”¥ä½“å¯¹åº”ä¸€ä¸ª16x16çš„å›¾åƒå—ã€‚é¢œè‰²æ²¡æœ‰ç‰¹æ®Šå«ä¹‰ã€‚æ’åºç®—æ³•çš„ç»“æœæ˜¯åœ¨æ¯ä¸ªå›¾å—å†…æŒ‰æ·±åº¦æ’åºçš„3Dç‚¹çš„å­é›†ã€‚[æ¥æºï¼šåŸºäº[è¿™é‡Œ](https://docs.nerf.studio/nerfology/model_components/visualize_samples.html#d-frustum)çš„å›¾]'
- en: '**Optimization**'
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**ä¼˜åŒ–**'
- en: 'A naive question might come to mind: how is it even possible to get a decent-looking
    image from a bunch of blobs in space? And well, it is true that if Gaussians arenâ€™t
    optimized properly, you will get all kinds of pointy artifacts in renders. In
    Figure 6 you can observe an example of such artifacts, they look quite literally
    like ellipsoids. The key to getting good renders is 3 components: **good initialization,
    differentiable optimization, and adaptive densification**.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: å¯èƒ½ä¼šäº§ç”Ÿä¸€ä¸ªå¹¼ç¨šçš„é—®é¢˜ï¼šå¦‚ä½•ä»ç©ºé—´ä¸­çš„ä¸€å †æ¨¡ç³Šç‰©ä½“ä¸­å¾—åˆ°ä¸€ä¸ªçœ‹èµ·æ¥ä¸é”™çš„å›¾åƒï¼Ÿçš„ç¡®ï¼Œå¦‚æœé«˜æ–¯æ²¡æœ‰è¢«å¦¥å–„ä¼˜åŒ–ï¼Œæ¸²æŸ“ç»“æœä¸­ä¼šå‡ºç°å„ç§å°–é”çš„ä¼ªå½±ã€‚åœ¨å›¾6ä¸­ï¼Œä½ å¯ä»¥è§‚å¯Ÿåˆ°è¿™ç§ä¼ªå½±çš„ä¸€ä¸ªç¤ºä¾‹ï¼Œå®ƒä»¬çœ‹èµ·æ¥ç¡®å®åƒæ¤­çƒä½“ã€‚è·å¾—è‰¯å¥½æ¸²æŸ“çš„å…³é”®åœ¨äº3ä¸ªç»„æˆéƒ¨åˆ†ï¼š**è‰¯å¥½çš„åˆå§‹åŒ–ã€å¯å¾®åˆ†ä¼˜åŒ–å’Œè‡ªé€‚åº”ç¨ å¯†åŒ–**ã€‚
- en: '![](../Images/efee6cd91739022a65625107a91c4adc.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/efee6cd91739022a65625107a91c4adc.png)'
- en: '**Figure 6:** An example of renders of an under-optimized scene [Source: Image
    by the author]'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾6ï¼š** ä¸€ä¸ªæœªä¼˜åŒ–åœºæ™¯çš„æ¸²æŸ“ç¤ºä¾‹ [æ¥æºï¼šä½œè€…æä¾›çš„å›¾åƒ]'
- en: The initialization refers to the parameters of 3D points set at the start of
    training. For point locations (means), the authors propose to use a point cloud
    produced by SfM (Structure from Motion), see Figure 7\. The logic is that for
    any 3D reconstruction, be it with GS, NeRF, or something more classic, you must
    know camera matrices so you would probably run SfM anyway to obtain those. **Since
    SfM produces a sparse point cloud as a by-product, why not use it for initialization?**
    So thatâ€™s what the paper suggests. When a point cloud is not available for whatever
    reason, a random initialization can be used instead, under the risk of a potential
    loss of the final reconstruction quality.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: åˆå§‹åŒ–æŒ‡çš„æ˜¯åœ¨è®­ç»ƒå¼€å§‹æ—¶è®¾å®šçš„ 3D ç‚¹å‚æ•°ã€‚å¯¹äºç‚¹ä½ç½®ï¼ˆå‡å€¼ï¼‰ï¼Œä½œè€…å»ºè®®ä½¿ç”¨ SfMï¼ˆç»“æ„å…‰æŸæ³•ï¼‰ç”Ÿæˆçš„ç‚¹äº‘ï¼Œè§å›¾ 7ã€‚é€»è¾‘æ˜¯ï¼Œå¯¹äºä»»ä½• 3D é‡å»ºï¼Œæ— è®ºæ˜¯
    GSã€NeRF è¿˜æ˜¯æ›´ç»å…¸çš„æ–¹æ³•ï¼Œä½ éƒ½å¿…é¡»çŸ¥é“ç›¸æœºçŸ©é˜µï¼Œå› æ­¤ä½ å¯èƒ½è¿˜æ˜¯ä¼šè¿è¡Œ SfM æ¥è·å–è¿™äº›çŸ©é˜µã€‚**ç”±äº SfM ç”Ÿæˆç¨€ç–ç‚¹äº‘ä½œä¸ºå‰¯äº§å“ï¼Œä¸ºä»€ä¹ˆä¸åˆ©ç”¨å®ƒè¿›è¡Œåˆå§‹åŒ–ï¼Ÿ**
    è¿™å°±æ˜¯è®ºæ–‡çš„å»ºè®®ã€‚å½“ç‚¹äº‘ç”±äºæŸç§åŸå› ä¸å¯ç”¨æ—¶ï¼Œå¯ä»¥ä½¿ç”¨éšæœºåˆå§‹åŒ–ï¼Œä½†æœ‰å¯èƒ½å¯¼è‡´æœ€ç»ˆé‡å»ºè´¨é‡çš„æŸå¤±ã€‚
- en: '![](../Images/5f546683705712828152da57840ffe4a.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5f546683705712828152da57840ffe4a.png)'
- en: '**Figure 7:** A sparse 3D point cloud produced by SfM, means initialization
    [Source: Taken from [here](https://speciale.ar/publication/privacypreservingsfm/)]'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 7ï¼š** ç”± SfM ç”Ÿæˆçš„ç¨€ç– 3D ç‚¹äº‘ï¼Œè¡¨ç¤ºåˆå§‹åŒ– [æ¥æºï¼šå–è‡ª [here](https://speciale.ar/publication/privacypreservingsfm/)]'
- en: Covariances are initialized to be isotropic, in other words, **3D points begin
    as spheres**. The radiuses are set based on mean distances to neighboring points
    such that the 3D world is nicely covered and has no â€œholesâ€.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: åæ–¹å·®åˆå§‹åŒ–ä¸ºå„å‘åŒæ€§ï¼Œæ¢å¥è¯è¯´ï¼Œ**3D ç‚¹æœ€åˆæ˜¯çƒå½¢**ã€‚åŠå¾„åŸºäºä¸é‚»è¿‘ç‚¹çš„å¹³å‡è·ç¦»è¿›è¡Œè®¾ç½®ï¼Œä»¥ç¡®ä¿ 3D ä¸–ç•Œè¢«å¾ˆå¥½åœ°è¦†ç›–ï¼Œå¹¶ä¸”æ²¡æœ‰â€œå­”æ´â€ã€‚
- en: After init, a simple Stochastic Gradient Descent is used to fit everything properly.
    The scene is optimized for **a loss function that is a combination of L1 and D-SSIM**
    (structural dissimilarity index measure) between a ground truth view and a current
    render.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: åˆå§‹åŒ–åï¼Œä½¿ç”¨ç®€å•çš„éšæœºæ¢¯åº¦ä¸‹é™æ³•æ¥æ­£ç¡®æ‹Ÿåˆæ‰€æœ‰å†…å®¹ã€‚åœºæ™¯ç»è¿‡ä¼˜åŒ–ä»¥**ä½¿æŸå¤±å‡½æ•°æˆä¸º L1 å’Œ D-SSIM**ï¼ˆç»“æ„ä¸ç›¸ä¼¼æ€§æŒ‡æ•°æµ‹é‡ï¼‰ä¹‹é—´çš„ç»„åˆï¼Œæ¯”è¾ƒçœŸå®è§†å›¾å’Œå½“å‰æ¸²æŸ“æ•ˆæœã€‚
- en: However, thatâ€™s not it, another crucial part remains and that is adaptive densification.
    It is launched once in a while during training, say, every 100 SGD steps and its
    purpose is to address under- and over-reconstruction. Itâ€™s important to emphasize
    that **SGD on its own can only do as much as adjust the existing points**. But
    it would struggle to find good parameters in areas that lack points altogether
    or have too many of them. Thatâ€™s where adaptive densification comes in, **splitting
    points** with large gradients (Figure 8) and **removing points** that have converged
    to very low values of Î± (if a point is that transparent, why keep it?).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¿™è¿˜ä¸æ˜¯å…¨éƒ¨ï¼Œå¦ä¸€ä¸ªå…³é”®éƒ¨åˆ†æ˜¯è‡ªé€‚åº”ç¨ å¯†åŒ–ã€‚å®ƒåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸æ—¶å¯åŠ¨ï¼Œæ¯”å¦‚æ¯`100 SGD`æ­¥ï¼Œè¿™ä¸ªè¿‡ç¨‹æ—¨åœ¨è§£å†³æ¬ é‡å»ºå’Œè¿‡åº¦é‡å»ºçš„é—®é¢˜ã€‚éœ€è¦å¼ºè°ƒçš„æ˜¯ï¼Œ**SGD
    æœ¬èº«åªèƒ½è°ƒæ•´ç°æœ‰ç‚¹**ã€‚ä½†åœ¨å®Œå…¨ç¼ºå°‘ç‚¹æˆ–ç‚¹è¿‡å¤šçš„åŒºåŸŸï¼Œå®ƒä¼šéš¾ä»¥æ‰¾åˆ°åˆé€‚çš„å‚æ•°ã€‚è¿™æ—¶ï¼Œè‡ªé€‚åº”ç¨ å¯†åŒ–å°±æ´¾ä¸Šç”¨åœºäº†ï¼Œå®ƒ**æ‹†åˆ†å¤§æ¢¯åº¦çš„ç‚¹**ï¼ˆå›¾ 8ï¼‰å¹¶**ç§»é™¤å·²æ”¶æ•›åˆ°éå¸¸ä½
    Î± å€¼çš„ç‚¹**ï¼ˆå¦‚æœä¸€ä¸ªç‚¹å¦‚æ­¤é€æ˜ï¼Œä¸ºä»€ä¹ˆè¿˜è¦ä¿ç•™å®ƒï¼Ÿï¼‰ã€‚
- en: '![](../Images/43554f1bdf17135d3873a2d1f67ed947.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/43554f1bdf17135d3873a2d1f67ed947.png)'
- en: '**Figure 8:** Adaptive densification. A toy example of fitting a bean shape
    that weâ€™d like to render with a few points. [Source: Taken from [1]]'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 8ï¼š** è‡ªé€‚åº”ç¨ å¯†åŒ–ã€‚ä¸€ä¸ªç©å…·ç¤ºä¾‹ï¼Œå±•ç¤ºäº†æˆ‘ä»¬å¸Œæœ›ç”¨å°‘é‡ç‚¹æ¥å‘ˆç°çš„è±†å½¢ã€‚[æ¥æºï¼šå–è‡ª[1]]'
- en: '**View-dependant colors with SH**'
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**è§†å›¾ä¾èµ–è‰²å½©ä¸ SH**'
- en: Spherical harmonics, SH for short, play a significant role in computer graphics
    and were first proposed as a way to learn a view-dependant color of discrete 3D
    voxels in Plenoxelsâ¶. View dependence is a nice-to-have property that **improves
    the quality of renders since it allows the model to represent non-Lambertian effects**,
    e.g. specularities of metallic surfaces. However, it is certainly not a must since
    itâ€™s possible to make a simplification, choose to represent color with 3 RGB values,
    and still use Gaussian splatting like it was done in [4]. That is why we are reviewing
    this representation detail separately after the whole method is laid out.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: çƒé¢è°æ³¢ï¼ˆç®€ç§° SHï¼‰åœ¨è®¡ç®—æœºå›¾å½¢å­¦ä¸­èµ·ç€é‡è¦ä½œç”¨ï¼Œæœ€æ—©æå‡ºä½œä¸ºä¸€ç§å­¦ä¹ ç¦»æ•£ 3D ä½“ç´ è§†å›¾ä¾èµ–è‰²å½©çš„æ–¹æ³•ï¼Œåœ¨ Plenoxelsâ¶ ä¸­å¾—åˆ°åº”ç”¨ã€‚è§†å›¾ä¾èµ–æ€§æ˜¯ä¸€ä¸ªå¯é€‰å±æ€§ï¼Œ**å®ƒæé«˜äº†æ¸²æŸ“è´¨é‡ï¼Œå› ä¸ºå®ƒå…è®¸æ¨¡å‹è¡¨ç¤ºéæœ—ä¼¯ç‰¹æ•ˆåº”**ï¼Œä¾‹å¦‚é‡‘å±è¡¨é¢çš„é«˜å…‰ã€‚ç„¶è€Œï¼Œè¿™ç»ä¸æ˜¯å¿…é¡»çš„ï¼Œå› ä¸ºå¯ä»¥ç®€åŒ–é€‰æ‹©ç”¨
    3 ä¸ª RGB å€¼è¡¨ç¤ºé¢œè‰²ï¼Œä»ç„¶ä½¿ç”¨é«˜æ–¯æ•£å°„ï¼Œå°±åƒåœ¨[4]ä¸­åšçš„é‚£æ ·ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åœ¨æ–¹æ³•å®Œæ•´æè¿°åå•ç‹¬å›é¡¾è¿™ä¸ªè¡¨ç¤ºç»†èŠ‚ã€‚
- en: 'SH are special functions defined on the surface of a sphere. In other words,
    you can evaluate such a function for any point on the sphere and get a value.
    **All of these functions are derived from this single formula** by choosing positive
    integers for *â„“* and âˆ’*â„“* â‰¤ *m* â‰¤ *â„“*, one *(â„“, m)* pair per SH:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: SH æ˜¯å®šä¹‰åœ¨çƒé¢ä¸Šçš„ç‰¹æ®Šå‡½æ•°ã€‚æ¢å¥è¯è¯´ï¼Œä½ å¯ä»¥å¯¹çƒé¢ä¸Šçš„ä»»ä½•ç‚¹è¯„ä¼°è¿™æ ·çš„å‡½æ•°å¹¶å¾—åˆ°ä¸€ä¸ªå€¼ã€‚**æ‰€æœ‰è¿™äº›å‡½æ•°éƒ½ä»è¿™ä¸ªå•ä¸€çš„å…¬å¼ä¸­æ¨å¯¼è€Œæ¥**ï¼Œé€šè¿‡é€‰æ‹©æ­£æ•´æ•°çš„*â„“*
    å’Œ - *â„“* â‰¤ *m* â‰¤ *â„“*ï¼Œæ¯ä¸ªSHä¸€ä¸ª*(â„“, m)*å¯¹ï¼š
- en: '![](../Images/ce8f701bf9ee54a8e4de80b75becda76.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ce8f701bf9ee54a8e4de80b75becda76.png)'
- en: While a bit intimidating at first, for small values of *l* this formula simplifies
    significantly. In fact, for *â„“ = 1, Y = ~0.282*, just a constant on the whole
    sphere. On the contrary, higher values of *â„“* produce more complex surfaces. The
    theory tells us that spherical harmonics form an orthonormal basis so **each function
    defined on a sphere can be expressed through SH**.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶ä¸€å¼€å§‹æœ‰ç‚¹ä»¤äººç”Ÿç•ï¼Œä½†å¯¹äºå°å€¼çš„*l*è¿™ä¸ªå…¬å¼ä¼šå¤§å¤§ç®€åŒ–ã€‚å®é™…ä¸Šï¼Œå¯¹äº*â„“ = 1, Y = ~0.282*ï¼Œåœ¨æ•´ä¸ªçƒé¢ä¸Šåªæ˜¯ä¸€ä¸ªå¸¸æ•°ã€‚ç›¸åï¼Œè¾ƒé«˜çš„*â„“*å€¼ä¼šäº§ç”Ÿæ›´å¤æ‚çš„è¡¨é¢ã€‚ç†è®ºå‘Šè¯‰æˆ‘ä»¬ï¼Œçƒé¢è°æ³¢å½¢æˆä¸€ä¸ªæ­£äº¤åŸºï¼Œå› æ­¤**åœ¨çƒé¢ä¸Šå®šä¹‰çš„æ¯ä¸ªå‡½æ•°éƒ½å¯ä»¥é€šè¿‡SHè¡¨ç¤º**ã€‚
- en: 'Thatâ€™s why the idea to express view-dependant color goes like this: letâ€™s limit
    ourselves to a certain degree of freedom *â„“_max* and say that each **color (red,
    green, and blue) is a linear combination of the first *â„“_max* SH functions**.
    For every 3D Gaussian, we want to learn the correct coefficients so that when
    we look at this 3D point from a certain direction it will convey a color the closest
    to the ground truth one. The whole process of obtaining a view-dependant color
    can be seen in Figure 9.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯ä¸ºä»€ä¹ˆè¡¨è¾¾è§†è§’ç›¸å…³é¢œè‰²çš„æƒ³æ³•æ˜¯è¿™æ ·çš„ï¼šè®©æˆ‘ä»¬å°†è‡ªç”±åº¦é™åˆ¶åœ¨ä¸€ä¸ªç‰¹å®šçš„*â„“_max*ï¼Œå¹¶å‡è®¾æ¯ç§**é¢œè‰²ï¼ˆçº¢è‰²ã€ç»¿è‰²å’Œè“è‰²ï¼‰æ˜¯å‰*â„“_max*ä¸ªSHå‡½æ•°çš„çº¿æ€§ç»„åˆ**ã€‚å¯¹äºæ¯ä¸ª3Dé«˜æ–¯ï¼Œæˆ‘ä»¬å¸Œæœ›å­¦ä¹ æ­£ç¡®çš„ç³»æ•°ï¼Œä»¥ä¾¿å½“æˆ‘ä»¬ä»æŸä¸ªæ–¹å‘æŸ¥çœ‹è¿™ä¸ª3Dç‚¹æ—¶ï¼Œå®ƒèƒ½ä¼ è¾¾å‡ºæœ€æ¥è¿‘çœŸå®é¢œè‰²çš„é¢œè‰²ã€‚è·å¾—è§†è§’ç›¸å…³é¢œè‰²çš„æ•´ä¸ªè¿‡ç¨‹å¯ä»¥å‚è§å›¾9ã€‚
- en: '![](../Images/c53b7a7d485fa4e9d0ad103b9e3a4343.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c53b7a7d485fa4e9d0ad103b9e3a4343.png)'
- en: '**Figure 9:** A process of obtaining a view-dependant color (red component)
    of a point with *â„“_max = 2 and 9 learned coefficients*. A sigmoid function maps
    the value into the [0, 1] interval. Oftentimes, clipping is used instead [Source:
    Image by the author]'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾9ï¼š** è·å–ä¸€ä¸ªç‚¹çš„è§†è§’ç›¸å…³é¢œè‰²ï¼ˆçº¢è‰²åˆ†é‡ï¼‰çš„è¿‡ç¨‹ï¼Œ*â„“_max = 2 å’Œ 9 ä¸ªå­¦ä¹ åˆ°çš„ç³»æ•°*ã€‚ä¸€ä¸ªsigmoidå‡½æ•°å°†å€¼æ˜ å°„åˆ°[0, 1]åŒºé—´ã€‚é€šå¸¸ï¼Œè£å‰ªè¢«ç”¨æ¥ä»£æ›¿
    [æ¥æºï¼šä½œè€…å›¾ç‰‡]'
- en: Limitations
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é™åˆ¶
- en: 'Despite the overall great results and the impressive rendering speed, the simplicity
    of the representation comes with a price. The most significant consideration is
    various **regularization heuristics** that are introduced during optimization
    to guard the model **against â€œbrokenâ€ Gaussians**: points that are too big, too
    long, redundant, etc. This part is crucial and the mentioned issues can be further
    amplified in tasks beyond novel view rendering.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡æ€»ä½“ç»“æœå¾ˆå‡ºè‰²ï¼Œæ¸²æŸ“é€Ÿåº¦ä¹Ÿå¾ˆå¿«ï¼Œä½†è¡¨ç¤ºçš„ç®€å•æ€§ä¹Ÿæœ‰ä»£ä»·ã€‚æœ€é‡è¦çš„è€ƒè™‘æ˜¯ä¼˜åŒ–è¿‡ç¨‹ä¸­å¼•å…¥çš„å„ç§**æ­£åˆ™åŒ–å¯å‘å¼**ï¼Œä»¥ä¿æŠ¤æ¨¡å‹**å…å—â€œç ´æŸâ€é«˜æ–¯çš„å½±å“**ï¼šè¿‡å¤§ã€è¿‡é•¿ã€å†—ä½™çš„ç‚¹ç­‰ã€‚è¿™éƒ¨åˆ†éå¸¸å…³é”®ï¼Œè¿™äº›é—®é¢˜åœ¨æ–°è§†è§’æ¸²æŸ“ä¹‹å¤–çš„ä»»åŠ¡ä¸­å¯èƒ½ä¼šè¿›ä¸€æ­¥æ”¾å¤§ã€‚
- en: The choice to step aside from a continuous representation in favor of a discrete
    one means that **the inductive bias of MLPs is lost**. In NeRFs, an MLP performs
    an implicit interpolation and smoothes out possible inconsistencies between given
    views, while 3D Gaussians are more sensitive, leading back to the problem described
    above.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: é€‰æ‹©æ”¾å¼ƒè¿ç»­è¡¨ç¤ºè€Œè½¬å‘ç¦»æ•£è¡¨ç¤ºæ„å‘³ç€**MLPçš„å½’çº³åå·®ä¸¢å¤±**ã€‚åœ¨NeRFä¸­ï¼ŒMLPæ‰§è¡Œéšå¼æ’å€¼ï¼Œå¹¶å¹³æ»‘ç»™å®šè§†å›¾ä¹‹é—´å¯èƒ½çš„ä¸ä¸€è‡´ï¼Œè€Œ3Dé«˜æ–¯åˆ™æ›´æ•æ„Ÿï¼Œè¿™ä¼šå¯¼è‡´å›åˆ°ä¸Šè¿°é—®é¢˜ã€‚
- en: 'Furthermore, Gaussian splatting is not free from some well-known **artifacts
    present in NeRFs** which they both inherit from the shared image formation model:
    lower quality in less seen or unseen regions, floaters close to an image plane,
    etc.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œé«˜æ–¯å–·æº…ä¹Ÿä¸å…å—åˆ°ä¸€äº›åœ¨NeRFä¸­å­˜åœ¨çš„**å·²çŸ¥ä¼ªå½±**çš„å½±å“ï¼Œè¿™äº›ä¼ªå½±éƒ½æ¥æºäºå…±äº«çš„å›¾åƒå½¢æˆæ¨¡å‹ï¼šåœ¨å°‘è§æˆ–æœªè§åŒºåŸŸçš„è´¨é‡è¾ƒä½ã€æ¥è¿‘å›¾åƒå¹³é¢çš„æµ®åŠ¨ç‚¹ç­‰ã€‚
- en: The file size of a checkpoint is another property to take into account, even
    though novel view rendering is far from being deployed to edge devices. Considering
    the ballpark number of 3D points and the MLP architectures of popular NeRFs, both
    take **the same order of magnitude of disk space**, with GS being just a few times
    heavier on average.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: æ£€æŸ¥ç‚¹çš„æ–‡ä»¶å¤§å°æ˜¯å¦ä¸€ä¸ªéœ€è¦è€ƒè™‘çš„å±æ€§ï¼Œå³ä½¿æ–°è§†è§’æ¸²æŸ“è·ç¦»è¾¹ç¼˜è®¾å¤‡çš„éƒ¨ç½²è¿˜å¾ˆè¿œã€‚è€ƒè™‘åˆ°3Dç‚¹çš„å¤§è‡´æ•°é‡å’Œæµè¡ŒNeRFçš„MLPæ¶æ„ï¼Œä¸¤è€…**ç£ç›˜ç©ºé—´çš„é‡çº§ç›¸åŒ**ï¼Œå…¶ä¸­GSå¹³å‡é‡é‡ä»…é‡å‡ å€ã€‚
- en: Where to play with it
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç©å®ƒçš„åœ°æ–¹
- en: 'No blog post can do justice to a method as well as just running it and seeing
    the results for yourself. Here is where you can play around:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: æ²¡æœ‰å“ªä¸ªåšå®¢æ–‡ç« èƒ½æ¯”ç›´æ¥è¿è¡Œæ–¹æ³•å¹¶äº²è‡ªæŸ¥çœ‹ç»“æœæ›´èƒ½ä½“ç°å…¶ä»·å€¼ã€‚ä½ å¯ä»¥åœ¨è¿™é‡Œå°è¯•ï¼š
- en: '[gaussian-splatting](https://github.com/graphdeco-inria/gaussian-splatting)
    â€” the official implementation with custom CUDA kernels;'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[gaussian-splatting](https://github.com/graphdeco-inria/gaussian-splatting)
    â€” å¸¦æœ‰è‡ªå®šä¹‰CUDAå†…æ ¸çš„å®˜æ–¹å®ç°ï¼›'
- en: '[nerfstudio](https://github.com/nerfstudio-project/nerfstudio) â€”yes, Gaussian
    splatting in **nerf**studio. This is a framework originally dedicated to NeRF-like
    models but since December, â€˜23, it also supports GS;'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[nerfstudio](https://github.com/nerfstudio-project/nerfstudio) â€” æ˜¯çš„ï¼Œ**nerf**studioä¸­çš„é«˜æ–¯æº…å°„ã€‚è¿™æ˜¯ä¸€ä¸ªæœ€åˆä¸“æ³¨äºNeRFç±»ä¼¼æ¨¡å‹çš„æ¡†æ¶ï¼Œä½†ä»2023å¹´12æœˆå¼€å§‹ï¼Œå®ƒä¹Ÿæ”¯æŒGSï¼›'
- en: '[threestudio-3dgs](https://github.com/DSaurus/threestudio-3dgs) â€” an extension
    for threestudio, another cross-model framework. You should use this one if you
    are interested in generating 3D models from a prompt rather than learning an existing
    set of images;'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[threestudio-3dgs](https://github.com/DSaurus/threestudio-3dgs) â€” ä¸€ä¸ªç”¨äºthreestudioçš„æ‰©å±•ï¼Œå¦ä¸€ä¸ªè·¨æ¨¡å‹æ¡†æ¶ã€‚å¦‚æœä½ å¯¹ä»æç¤ºç”Ÿæˆ3Dæ¨¡å‹æ„Ÿå…´è¶£ï¼Œè€Œä¸æ˜¯å­¦ä¹ ç°æœ‰çš„å›¾åƒé›†ï¼Œä½ åº”è¯¥ä½¿ç”¨è¿™ä¸ªï¼›'
- en: '[UnityGaussianSplatting](https://github.com/aras-p/UnityGaussianSplatting)
    â€” if Unity is your thing, you can port a trained model into this plugin for visualization;'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UnityGaussianSplatting](https://github.com/aras-p/UnityGaussianSplatting)
    â€” å¦‚æœä½ å¯¹Unityæ„Ÿå…´è¶£ï¼Œä½ å¯ä»¥å°†è®­ç»ƒå¥½çš„æ¨¡å‹ç§»æ¤åˆ°è¿™ä¸ªæ’ä»¶ä¸­è¿›è¡Œå¯è§†åŒ–ï¼›'
- en: '[gsplat](https://github.com/nerfstudio-project/gsplat) â€” a library for CUDA-accelerated
    rasterization of Gaussians that branched out of nerfstudio. It can be used for
    independent torch-based projects as a differentiatable module for splatting.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[gsplat](https://github.com/nerfstudio-project/gsplat) â€” ä¸€ä¸ªç”¨äºé«˜æ–¯ä½“ç´ CUDAåŠ é€Ÿå…‰æ …åŒ–çš„åº“ï¼Œæºè‡ªnerfstudioã€‚å®ƒå¯ä»¥ä½œä¸ºå¯åŒºåˆ†çš„æº…å°„æ¨¡å—ç”¨äºç‹¬ç«‹çš„åŸºäºtorchçš„é¡¹ç›®ã€‚'
- en: Have fun!
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ç©å¾—å¼€å¿ƒï¼
- en: Acknowledgments
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è‡´è°¢
- en: This blog post is based on a group meeting in the lab of Dr. Tali Dekel. Special
    thanks go to [Michal Geyer](https://medium.com/u/74c8897cdd08?source=post_page-----e7d570081362--------------------------------)
    for the discussions of the paper, to the authors of [4] for a coherent summary
    of Gaussian splatting, and to [Yuliang Guo](https://medium.com/u/0170f53deb62?source=post_page-----e7d570081362--------------------------------)
    for the suggested improvements.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬åšå®¢æ–‡ç« åŸºäºDr. Tali Dekelå®éªŒå®¤çš„ä¸€ä¸ªå°ç»„ä¼šè®®ã€‚ç‰¹åˆ«æ„Ÿè°¢[Michal Geyer](https://medium.com/u/74c8897cdd08?source=post_page-----e7d570081362--------------------------------)å¯¹è®ºæ–‡è®¨è®ºçš„è´¡çŒ®ï¼Œæ„Ÿè°¢[4]çš„ä½œè€…å¯¹é«˜æ–¯æº…å°„çš„è¿è´¯æ€»ç»“ï¼Œä»¥åŠ[Yuliang
    Guo](https://medium.com/u/0170f53deb62?source=post_page-----e7d570081362--------------------------------)å¯¹æ”¹è¿›å»ºè®®çš„æä¾›ã€‚
- en: References
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: Kerbl, B., Kopanas, G., LeimkÃ¼hler, T., & Drettakis, G. (2023). [3D Gaussian
    Splatting for Real-Time Radiance Field Rendering.](https://arxiv.org/abs/2308.04079)
    SIGGRAPH 2023.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kerbl, B., Kopanas, G., LeimkÃ¼hler, T., & Drettakis, G. (2023). [ç”¨äºå®æ—¶è¾å°„åœºæ¸²æŸ“çš„3Dé«˜æ–¯æº…å°„ã€‚](https://arxiv.org/abs/2308.04079)
    SIGGRAPH 2023ã€‚
- en: 'Mildenhall, B., Srinivasan, P. P., Tancik, M., Barron, J. T., Ramamoorthi,
    R., & Ng, R. (2020). [NeRF: Representing Scenes as Neural Radiance Fields for
    View Synthesis.](https://arxiv.org/abs/2003.08934) ECCV 2020.'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Mildenhall, B., Srinivasan, P. P., Tancik, M., Barron, J. T., Ramamoorthi,
    R., & Ng, R. (2020). [NeRF: å°†åœºæ™¯è¡¨ç¤ºä¸ºç¥ç»è¾å°„åœºä»¥å®ç°è§†å›¾åˆæˆã€‚](https://arxiv.org/abs/2003.08934)
    ECCV 2020ã€‚'
- en: Zwicker, M., Pfister, H., van Baar, J., & Gross, M. (2001). [Surface Splatting.](https://www.cs.umd.edu/~zwicker/publications/SurfaceSplatting-SIG01.pdf)
    SIGGRAPH 2001
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Zwicker, M., Pfister, H., van Baar, J., & Gross, M. (2001). [è¡¨é¢æº…å°„ã€‚](https://www.cs.umd.edu/~zwicker/publications/SurfaceSplatting-SIG01.pdf)
    SIGGRAPH 2001ã€‚
- en: 'Luiten, J., Kopanas, G., Leibe, B., & Ramanan, D. (2023). [Dynamic 3D Gaussians:
    Tracking by Persistent Dynamic View Synthesis.](https://arxiv.org/abs/2308.09713)
    International Conference on 3D Vision.'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Luiten, J., Kopanas, G., Leibe, B., & Ramanan, D. (2023). [åŠ¨æ€3Dé«˜æ–¯ï¼šé€šè¿‡æŒä¹…åŠ¨æ€è§†å›¾åˆæˆè¿›è¡Œè·Ÿè¸ªã€‚](https://arxiv.org/abs/2308.09713)
    å›½é™…3Dè§†è§‰ä¼šè®®ã€‚
- en: Zwicker, M., Pfister, H., van Baar, J., & Gross, M. (2001). [EWA Volume Splatting.](https://www.cs.umd.edu/~zwicker/publications/EWAVolumeSplatting-VIS01.pdf)
    IEEE Visualization 2001.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Zwicker, M., Pfister, H., van Baar, J., & Gross, M. (2001). [EWAä½“ç§¯æº…å°„ã€‚](https://www.cs.umd.edu/~zwicker/publications/EWAVolumeSplatting-VIS01.pdf)
    IEEE Visualization 2001ã€‚
- en: 'Yu, A., Fridovich-Keil, S., Tancik, M., Chen, Q., Recht, B., & Kanazawa, A.
    (2023). [Plenoxels: Radiance Fields without Neural Networks.](https://arxiv.org/abs/2112.05131)
    CVPR 2022.'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Yu, A., Fridovich-Keil, S., Tancik, M., Chen, Q., Recht, B., & Kanazawa, A.
    (2023). [Plenoxels: æ— éœ€ç¥ç»ç½‘ç»œçš„è¾å°„åœºã€‚](https://arxiv.org/abs/2112.05131) CVPR 2022ã€‚'
