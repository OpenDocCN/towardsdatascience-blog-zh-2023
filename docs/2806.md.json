["```py\nimport numpy as np\nimport pandas as pd\nfrom sklearn import metrics\nfrom sklearn.metrics import f1_score, precision_score, recall_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom lightgbm import LGBMClassifier\n\n# Convert target variable to numeric\ndf['Credit_Score'] = df['Credit_Score'].str.replace('Good', '3', n=-1)\ndf['Credit_Score'] = df['Credit_Score'].str.replace('Standard', '2', n=-1)\ndf['Credit_Score'] = df['Credit_Score'].str.replace('Poor', '1', n=-1)\ndf['Credit_Score'] = df[['Credit_Score']].apply(pd.to_numeric)\n\n# Split the dataset\nX=df.loc[:, df.columns != 'Credit_Score']\nY=df['Credit_Score']\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)\n\n# Train the LightGBM model\nlgbm = LGBMClassifier()\nlgbm.fit(x_train, y_train)\ny_pred = lgbm.predict(x_test)\n\n# Print performance metrics\nprint('F1 score: %.3f' % f1_score(y_test, y_pred, average='weighted'))\nprint('Precision: %.3f' % precision_score(y_test, y_pred, average='weighted'))\nprint('Recall: %.3f' % recall_score(y_test, y_pred, average='weighted'))\n```", "```py\nfrom scipy import stats\n\n# Create new datasets with different no. of samples\noriginal_df = x_train[['Credit_History_Age', 'Payment_Behaviour']].reset_index(drop=True)\nnew_df = x_train[['Credit_History_Age', 'Payment_Behaviour']].reset_index(drop=True)\nnew_df1 = new_df.sample(n = 1000).reset_index(drop=True)\nnew_df2 = new_df.sample(n = 5000).reset_index(drop=True)\nnew_df3 = new_df.sample(n = len(x_train)).reset_index(drop=True)\n\n# Prepare drifted data for numeric feature\ndef drift_numeric_col(df, numeric_col, drift_range):\n    df[numeric_col] = df[numeric_col] + np.random.uniform(0, drift_range, size=(df.shape[0], ))\n\ndrift_numeric_col(new_df1, 'Credit_History_Age', 2)\ndrift_numeric_col(new_df2, 'Credit_History_Age', 2)\ndrift_numeric_col(new_df3, 'Credit_History_Age', 2)\n\n# K-S Test\ndef ks_test(original_df, new_df, numeric_col):\n    test = stats.ks_2samp(original_df[numeric_col], new_df[numeric_col])\n    print(\"Column : %s , p-value : %1.3f\" % (numeric_col, test[1]))\n\n# Conduct K-S Test for numeric feature\nks_test(original_df, new_df1, 'Credit_History_Age')\nks_test(original_df, new_df2, 'Credit_History_Age')\nks_test(original_df, new_df3, 'Credit_History_Age')\n```", "```py\n# Prepare drifted data for categorical column\ndef drift_cat_col(df, cat_col, drift_ratio):\n    no_of_drift = round(len(df)*drift_ratio)\n    random_numbers = [random.randint(0, 1) for _ in range(no_of_drift)]\n    indices = random.sample(range(len(df[cat_col])), no_of_drift)\n    df.loc[indices, cat_col] = random_numbers\n\ndrift_cat_col(new_df1, 'Payment_Behaviour', 0.8)\ndrift_cat_col(new_df2, 'Payment_Behaviour', 0.8)\ndrift_cat_col(new_df3, 'Payment_Behaviour', 0.8)\n```", "```py\ndef psi(data_base, data_new, num_bins = 10):\n    # Sort the data\n    data_base = sorted(data_base)\n    data_new = sorted(data_new)\n\n    # Prepare the bins\n    min_val = min(data_base[0], data_new[0])\n    max_val = max(data_base[-1], data_new[-1])\n    bins = [min_val + (max_val - min_val)*(i)/num_bins for i in range(num_bins+1)]\n    bins[0] = min_val - 0.0001\n    bins[-1] = max_val + 0.0001\n\n    # Bucketize the baseline data and count the samples\n    bins_base = pd.cut(data_base, bins = bins, labels = range(1,num_bins+1))\n    df_base = pd.DataFrame({'base': data_base, 'bin': bins_base})\n    grp_base = df_base.groupby('bin').count()\n    grp_base['percent_base'] = grp_base['base'] / grp_base['base'].sum() \n\n    # Bucketize the new data and count the samples\n    bins_new = pd.cut(data_new, bins = bins, labels = range(1,num_bins+1))\n    df_new = pd.DataFrame({'new': data_new, 'bin': bins_new})\n    grp_new = df_new.groupby('bin').count()\n    grp_new['percent_new'] = grp_new['new'] / grp_new['new'].sum()\n\n    # Compare the bins\n    psi_df = grp_base.join(grp_new, on = \"bin\", how = \"inner\")\n\n    # Calculate the PSI\n    psi_df['percent_base'] = psi_df['percent_base'].replace(0, 0.0001)\n    psi_df['percent_new'] = psi_df['percent_new'].replace(0, 0.0001)\n    psi_df['psi'] = (psi_df['percent_base'] - psi_df['percent_new']) * np.log(psi_df['percent_base'] / psi_df['percent_new'])\n\n    # Return the total PSI value\n    return np.sum(psi_df['psi'].values)\n\n# Conduct K-S Test for numeric feature\npsi(original_df['Credit_History_Age'], new_df1['Credit_History_Age'])\npsi(original_df['Credit_History_Age'], new_df2['Credit_History_Age'])\npsi(original_df['Credit_History_Age'], new_df3['Credit_History_Age'])\n\n# Conduct K-S Test for categorical feature\npsi(original_df['Payment_Behaviour'], new_df1['Payment_Behaviour'])\npsi(original_df['Payment_Behaviour'], new_df2['Payment_Behaviour'])\npsi(original_df['Payment_Behaviour'], new_df3['Payment_Behaviour'])\n```", "```py\nfrom skmultiflow.drift_detection import ADWIN\n\nadwin = ADWIN()\ndata_stream=[]\ndata_stream = np.concatenate((original_df['Credit_History_Age'],new_df3['Credit_History_Age']))\n\n# Add stream elements to ADWIN and verify if drift occurred\nfor i in range(len(data_stream)):\n  adwin.add_element(data_stream[i])\n  if adwin.detected_change():\n  print('Change detected at index {}'.format(i))\n  adwin.reset()\n```"]