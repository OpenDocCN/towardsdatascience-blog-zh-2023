- en: Intuitive Explanation of Exponential Moving Average
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/intuitive-explanation-of-exponential-moving-average-2eb9693ea4dc?source=collection_archive---------2-----------------------#2023-12-16](https://towardsdatascience.com/intuitive-explanation-of-exponential-moving-average-2eb9693ea4dc?source=collection_archive---------2-----------------------#2023-12-16)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Understand the logic behind the fundamental algorithm used inside the gradient
    descent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@slavahead?source=post_page-----2eb9693ea4dc--------------------------------)[![Vyacheslav
    Efimov](../Images/db4b02e75d257063e8e9d3f1f75d9d6d.png)](https://medium.com/@slavahead?source=post_page-----2eb9693ea4dc--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2eb9693ea4dc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2eb9693ea4dc--------------------------------)
    [Vyacheslav Efimov](https://medium.com/@slavahead?source=post_page-----2eb9693ea4dc--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc8a0ca9d85d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintuitive-explanation-of-exponential-moving-average-2eb9693ea4dc&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=post_page-c8a0ca9d85d8----2eb9693ea4dc---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2eb9693ea4dc--------------------------------)
    ·6 min read·Dec 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2eb9693ea4dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintuitive-explanation-of-exponential-moving-average-2eb9693ea4dc&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=-----2eb9693ea4dc---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2eb9693ea4dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintuitive-explanation-of-exponential-moving-average-2eb9693ea4dc&source=-----2eb9693ea4dc---------------------bookmark_footer-----------)![](../Images/f65b757753e90cbe70d7ae2c04608e84.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In time series analysis, there is often a need to understand the trend direction
    of a sequence by taking into account previous values. Approximation of the next
    values in a sequence can be performed in several ways, including the usage of
    simple baselines or the construction of advanced machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: An **exponential (weighted) moving average** is a robust trade-off between these
    two methods. Having a simple recursive method under the hood makes it possible
    to efficiently implement the algorithm. At the same time, it is very flexible
    and can be successfully adapted for most types of sequences.
  prefs: []
  type: TYPE_NORMAL
- en: This article covers the motivation behind the method, a description of its workflow
    and bias correction — an effective technique to overcome a bias obstacle in approximation.
  prefs: []
  type: TYPE_NORMAL
- en: Motivation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Imagine a problem of approximating a given parameter that changes in time. On
    every iteration, we are aware of all of its previous values. The objective is
    to predict the next value which depends on the previous values.
  prefs: []
  type: TYPE_NORMAL
- en: One of the naive strategies is to simply take the average of the last several
    values. This might work in certain cases but it is not very suitable for scenarios
    when a parameter is more dependent on the most recent values.
  prefs: []
  type: TYPE_NORMAL
- en: One of the possible ways to overcome this issue is to distribute higher weights
    to more recent values and assign fewer weights to prior values. The exponential
    moving average is exactly a strategy that follows this principle. **It is based
    on the assumption that more recent values of a variable contribute more to the
    formation of the next value than precedent values**.
  prefs: []
  type: TYPE_NORMAL
- en: Formula
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To understand how the exponential moving average works, let us look at its
    recursive equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1ee395f76a578feac3fbfb7250c75d0f.png)'
  prefs: []
  type: TYPE_IMG
- en: Exponential moving average formula
  prefs: []
  type: TYPE_NORMAL
- en: vₜ is a time series that approximates a given variable. Its index t corresponds
    to the timestamp t. Since this formula is recursive, the value v₀ for the initial
    timestamp t = 0 is needed. In practice, v₀ is usually taken as 0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: θ is the observation on the current iteration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: β is a hyperparameter between 0 and 1 which defines how weight importance should
    be distributed between a previous average value vₜ-₁ and the current observation
    θ
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let us write this formula for first several parameter values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1ded5cd1e0b8e9dfc5d8637a452907e7.png)'
  prefs: []
  type: TYPE_IMG
- en: Obtaining formula for the t-th timestamp
  prefs: []
  type: TYPE_NORMAL
- en: 'As a result, the final formula looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2520ba4bbbbd0aa1c25fe694d2ce7d6e.png)'
  prefs: []
  type: TYPE_IMG
- en: Exponential moving average for the t-th timestamp
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the most recent observation θ has a weight of 1, the second
    last observation — β, the third last — β², etc. Since 0 < β < 1, the multiplication
    term βᵏ goes exponentially down with the increase of k, *so the older the observations,
    the less important they are*. Finally, every sum term is multiplied by (1 —β).
  prefs: []
  type: TYPE_NORMAL
- en: In practice, the value for β is usually chosen close to 0.9.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/946afdcedcea1cae3b14897b927bb2e1.png)'
  prefs: []
  type: TYPE_IMG
- en: Weight distribution for different timestamps (β = 0.9)
  prefs: []
  type: TYPE_NORMAL
- en: Mathematical interpretation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using the famous second wonderful limit from mathematical analysis, it is possible
    to prove the following limit:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/088ede23a815fe975357a0f9c57e7506.png)'
  prefs: []
  type: TYPE_IMG
- en: The second wonderful limit
  prefs: []
  type: TYPE_NORMAL
- en: 'By making a substitution β = 1 - *x*, we can rewrite it in the form below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e648d093856d49a1a829473a3bc8008f.png)'
  prefs: []
  type: TYPE_IMG
- en: The second wonderful limit in another form
  prefs: []
  type: TYPE_NORMAL
- en: 'We also know that in the equation for the exponential moving average, every
    observation value is multiplied by a term βᵗ where t indicates how many timestamps
    ago the observation was computed. Since the base β is equal in both cases, we
    can equate the exponents of both formulas:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7bedd715d3f938568c452996e6e00451.png)'
  prefs: []
  type: TYPE_IMG
- en: By using this equation, for a chosen value of β, we can compute an approximate
    number of timestamps t it takes for weight terms to reach the value of 1 / e ≈
    0.368). It means that observations computed within last t iterations have a weight
    term greater than 1 / e and those more precedent calculated out of last t timestamp
    range come up with weights lower than 1 / e having a much less significance.
  prefs: []
  type: TYPE_NORMAL
- en: In reality, weights lower than 1 / e make a tiny impact on the exponentially
    weighted average. That is why it is said that **for a given value of β, the exponential
    weighted average takes into consideration the last t = 1 / (1 - β) observations**.
  prefs: []
  type: TYPE_NORMAL
- en: To get a better sense of the formula, let us plug in different values for β**:**
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/de06a335b31a2fbeb4c261e9c312f732.png)'
  prefs: []
  type: TYPE_IMG
- en: For instance, taking β= 0.9 indicates that approximately in t = 10 iterations,
    the weight decays to 1 / e, compared to the weight of the current observation.
    In other words, the exponential weighted average mostly depends only on the last
    t = 10 observations.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Bias correction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The common problem with using exponential weighted average is that in most
    problems it cannot approximate well the first series values. It occurs due to
    the absence of a sufficient amount of data on the first iterations. For example,
    imagine we are given the following time series sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9d079e18b99a43f4c6e4aada6d25daa4.png)'
  prefs: []
  type: TYPE_IMG
- en: The goal is to approximate it with the exponential weighted average. However,
    if we use the normal formula, then the first several values will put a large weight
    on v₀ which is 0 whereas most of the points on the scatterplot are above 20\.
    As a consequence, a sequence of first weighted averages will be too low to precisely
    approximate the original sequence.
  prefs: []
  type: TYPE_NORMAL
- en: One of the naive solutions is to take a value for v₀ being close to the first
    observation θ₁. Though this approach works well in some situations, it is still
    not perfect, especially in cases when a given sequence is volatile. For example,
    if θ₂ differs too much from θ₁, then while calculating the second value v₂, the
    weighted average will normally put much more importance on the previous trend
    v₁ than the current observation θ₂. As a result, the approximation will be very
    poor.
  prefs: []
  type: TYPE_NORMAL
- en: A much more flexible solution is to use a technique called “**bias correction**”.
    Instead of simply using computed values vₖ, they are divided by (1 —βᵏ). Assuming
    that β is chosen close to 0.9–1, this expression tends to be close to 0 for first
    iterations where k is small. Thus, instead of slowly accumulating the first several
    values where v₀ = 0, they are now divided by a relatively small number scaling
    them into larger values.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ed809abff8a65e5f605c4394dfdbec49.png)'
  prefs: []
  type: TYPE_IMG
- en: Exponential moving average computation example with and without bias correction
  prefs: []
  type: TYPE_NORMAL
- en: In general, this scaling works very well and precisely adapts the first several
    terms. When k becomes larger, the denominator gradually approaches 1, thus gradually
    omitting the effect of this scaling which is no longer needed, because starting
    from a certain iteration, the algorithm can rely with a high confidence on its
    recent values without any additional scaling.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a505a4b5dbc0326cb86660f06e5f0fb9.png)'
  prefs: []
  type: TYPE_IMG
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article, we have covered an extremely useful technique for approximating
    a time series sequence. The robustness of the exponential weighted average algorithm
    is primarily achieved by its hyperparameter β which can be adapted for a particular
    type of sequence. Apart from it, the introduced bias correction mechanism makes
    it possible to efficiently approximate data even on early timestamps when there
    is too little information.
  prefs: []
  type: TYPE_NORMAL
- en: Exponential weighted average has a wide application scope in time series analysis.
    Additionally, it used in variations of gradient descent algorithm for convergence
    acceleration. One of the most popular of them is the Momentum optimizer in deep
    learning which removes unnecessary oscillations of an optimized function aligning
    it more precisely towards a local minimum.
  prefs: []
  type: TYPE_NORMAL
- en: '*All images unless otherwise noted are by the author*'
  prefs: []
  type: TYPE_NORMAL
