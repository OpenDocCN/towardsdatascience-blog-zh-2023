- en: Topic Modelling using ChatGPT API
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用ChatGPT API进行主题建模
- en: 原文：[https://towardsdatascience.com/topic-modelling-using-chatgpt-api-8775b0891d16?source=collection_archive---------0-----------------------#2023-10-04](https://towardsdatascience.com/topic-modelling-using-chatgpt-api-8775b0891d16?source=collection_archive---------0-----------------------#2023-10-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/topic-modelling-using-chatgpt-api-8775b0891d16?source=collection_archive---------0-----------------------#2023-10-04](https://towardsdatascience.com/topic-modelling-using-chatgpt-api-8775b0891d16?source=collection_archive---------0-----------------------#2023-10-04)
- en: Comprehensive guide to ChatGPT API for newbies
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 针对新手的ChatGPT API综合指南
- en: '[](https://miptgirl.medium.com/?source=post_page-----8775b0891d16--------------------------------)[![Mariya
    Mansurova](../Images/b1dd377b0a1887db900cc5108bca8ea8.png)](https://miptgirl.medium.com/?source=post_page-----8775b0891d16--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8775b0891d16--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8775b0891d16--------------------------------)
    [Mariya Mansurova](https://miptgirl.medium.com/?source=post_page-----8775b0891d16--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://miptgirl.medium.com/?source=post_page-----8775b0891d16--------------------------------)[![Mariya
    Mansurova](../Images/b1dd377b0a1887db900cc5108bca8ea8.png)](https://miptgirl.medium.com/?source=post_page-----8775b0891d16--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8775b0891d16--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8775b0891d16--------------------------------)
    [Mariya Mansurova](https://miptgirl.medium.com/?source=post_page-----8775b0891d16--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F15a29a4fc6ad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftopic-modelling-using-chatgpt-api-8775b0891d16&user=Mariya+Mansurova&userId=15a29a4fc6ad&source=post_page-15a29a4fc6ad----8775b0891d16---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8775b0891d16--------------------------------)
    ·16 min read·Oct 4, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8775b0891d16&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftopic-modelling-using-chatgpt-api-8775b0891d16&user=Mariya+Mansurova&userId=15a29a4fc6ad&source=-----8775b0891d16---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F15a29a4fc6ad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftopic-modelling-using-chatgpt-api-8775b0891d16&user=Mariya+Mansurova&userId=15a29a4fc6ad&source=post_page-15a29a4fc6ad----8775b0891d16---------------------post_header-----------)
    发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8775b0891d16--------------------------------)
    · 16分钟阅读·2023年10月4日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8775b0891d16&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftopic-modelling-using-chatgpt-api-8775b0891d16&user=Mariya+Mansurova&userId=15a29a4fc6ad&source=-----8775b0891d16---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8775b0891d16&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftopic-modelling-using-chatgpt-api-8775b0891d16&source=-----8775b0891d16---------------------bookmark_footer-----------)![](../Images/9b8c199c3e9d4af61dc5e63fdec0154d.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8775b0891d16&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftopic-modelling-using-chatgpt-api-8775b0891d16&source=-----8775b0891d16---------------------bookmark_footer-----------)![](../Images/9b8c199c3e9d4af61dc5e63fdec0154d.png)'
- en: Photo by [Mia Baker](https://unsplash.com/@miabaker?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Mia Baker](https://unsplash.com/@miabaker?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: In [the previous article](/topics-per-class-using-bertopic-252314f2640), I used
    BERTopic for Topic Modelling. The task was to compare the main topics in reviews
    for various hotel chains. This approach with BERTopic worked out, and we got some
    insights from the data. For example, from reviews, we could see that Holiday Inn,
    Travelodge and Park Inn have more reasonable prices for value.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [上一篇文章](/topics-per-class-using-bertopic-252314f2640) 中，我使用了BERTopic进行主题建模。任务是比较各大酒店连锁的评论中的主要话题。这种使用BERTopic的方法奏效了，我们从数据中获得了一些见解。例如，从评论中我们可以看到假日酒店、Travelodge和Park
    Inn的价格更为合理。
- en: '![](../Images/8765ecf920cb7225ac217142a3f0c668.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8765ecf920cb7225ac217142a3f0c668.png)'
- en: Graph by author
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图表
- en: However, the most cutting-edge technology to analyse texts nowadays is LLMs
    (Large Language Models).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如今分析文本的最前沿技术是LLMs（大型语言模型）。
- en: LLMs disrupted the process of building ML applications. Before LLMs, if we wanted
    to do sentiment analysis or chatbot, we would first spend several months getting
    labelled data and training models. Then, we would deploy it in production (it
    would also take a couple of months at least). With LLMs, we can solve such problems
    within a few hours.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: LLM改变了构建机器学习应用程序的过程。在LLM出现之前，如果我们想进行情感分析或创建聊天机器人，我们首先要花几个月的时间获取标记数据和训练模型。然后，我们将其部署到生产环境中（这也至少需要几个月）。有了LLM，我们可以在几小时内解决这些问题。
- en: '![](../Images/363a3e61def4bbc987e1d238f9383b7d.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/363a3e61def4bbc987e1d238f9383b7d.png)'
- en: Slide from the talk [“Opportunities in AI”](https://www.youtube.com/watch?v=5p248yoa3oE)
    by Andrew Ng
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 来自Andrew Ng的讲座[“人工智能中的机会”](https://www.youtube.com/watch?v=5p248yoa3oE)的幻灯片
- en: 'Let’s see whether LLMs could help us solve our task: to define one or several
    topics for customer reviews.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看LLM是否能帮助我们解决任务：为客户评论定义一个或多个主题。
- en: LLM basics
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM基础知识
- en: Before jumping into our task, let’s discuss the basics of LLMs and how they
    could be used.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入我们的任务之前，让我们讨论一下LLM的基础知识及其如何被使用。
- en: 'Large Language Models are trained on enormous amounts of text to predict the
    next word for the sentence. It’s a straightforward supervised Machine Learning
    task: we have the set of the sentences’ beginnings and the following words for
    them.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型在大量文本上进行训练，以预测句子的下一个词。这是一项直接的监督学习任务：我们有一组句子的开头和对应的后续词。
- en: '![](../Images/ee392a485821eff34485232efa5746ec.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ee392a485821eff34485232efa5746ec.png)'
- en: Graph by author
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图表
- en: You can play with a basic LLM, for example, `text-davinci-003`, on [nat.dev](https://nat.dev/).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[nat.dev](https://nat.dev/)上玩玩基础LLM，例如`text-davinci-003`。
- en: In most business applications, we need not a generic model but one that can
    solve problems. Basic LLMs are not perfect for such tasks because they are trained
    to predict the most likely next word. But on the internet, there are a lot of
    texts where the next word is not a correct answer, for example, jokes or just
    a list of questions to prepare for the exam.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数商业应用中，我们需要的不是通用模型，而是能够解决问题的模型。基础LLM不适合这种任务，因为它们被训练来预测最可能的下一个词。但是在互联网上，有很多文本的下一个词并不是正确的答案，例如笑话或仅仅是为考试准备的问题列表。
- en: That’s why, nowadays, Instruction Tuned LLMs are very popular for business cases.
    These models are basic LLMs, fine-tuned on datasets with instructions and good
    answers (for example, [OpenOrca dataset](https://huggingface.co/datasets/Open-Orca/OpenOrca)).
    Also, RLHF (Reinforcement Learning with Human Feedback) approach is often used
    to train such models.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如今，经过指令调整的LLM在商业案例中非常受欢迎。这些模型是基础LLM，在带有指令和良好答案的数据集上进行了微调（例如，[OpenOrca数据集](https://huggingface.co/datasets/Open-Orca/OpenOrca)）。此外，RLHF（基于人类反馈的强化学习）方法通常用于训练这些模型。
- en: The other important feature of Instruction Tuned LLMs is that they are trying
    to be helpful, honest and harmless, which is crucial for the models that will
    communicate with customers (especially vulnerable ones).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 指令调整的LLM的另一个重要特性是它们努力提供帮助、诚实和无害，这对于将与客户（尤其是脆弱客户）沟通的模型至关重要。
- en: What are the primary tasks for LLMs
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM的主要任务是什么
- en: 'LLMs are primarily used for tasks with unstructured data (not the cases when
    you have a table with lots of numbers). Here is the list of the most common applications
    for texts:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: LLM主要用于处理非结构化数据的任务（而不是拥有大量数字的表格情况）。以下是文本的最常见应用列表：
- en: '**Summarisation** — giving a concise overview of the text.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总结**——提供文本的简明概述。'
- en: '**Text analysis**, for example, sentiment analysis or extracting specific features
    (for example, labels mentioned in hotel reviews).'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本分析**，例如，情感分析或提取特定特征（例如，酒店评论中提到的标签）。'
- en: '**Text transformations** include translating to different languages, changing
    tone, or formatting from HTML to JSON.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本转换**包括翻译成不同的语言、改变语气或将HTML格式转换为JSON。'
- en: '**Generation**, for example, to generate a story from a prompt, respond to
    customer questions or help to brainstorm about some problem.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成**，例如，从提示中生成一个故事、回答客户问题或帮助进行问题头脑风暴。'
- en: It looks like our task of topic modelling is the one where LLMs could be rather
    beneficial. It’s an example of **Text analysis**.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来我们的主题建模任务是LLM可以相当有用的一个例子。这是**文本分析**的一个例子。
- en: Prompt Engineering 101
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示工程101
- en: We give tasks to LLMs using instructions that are often called prompts. You
    can think of LLM as a very motivated and knowledgeable junior specialist who is
    ready to help but needs clear instructions to follow. So, a prompt is critical.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: There are a few main principles that you should take into account while creating
    prompts.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: 'Principle #1: Be as clear and specific as possible'
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Use delimiters to split different sections of your prompt, for example, separating
    different steps in the instruction or framing user message. The common delimeters
    are `”””` , `---` , `###` , `<>` or XML tags.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define the format for the output. For example, you could use JSON or HTML and
    even specify a list of possible values. It will make response parsing much easier
    for you.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Show a couple of input & output examples to the model so it can see what you
    expect as separate messages. Such an approach is called few-shot prompting.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Also, it could be helpful to instruct the model to check assumptions and conditions.
    For example, to ensure that the output format is JSON and returned values are
    from the specified list.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Principle #2:** Push the model to think about the answer'
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Daniel Kahneman’s famous book “Thinking Fast and Slow” shows that our mind consists
    of 2 systems. System 1 works instinctively and allows us to give answers extremely
    quickly and with minimal effort (this system helped our ancestors to survive after
    meeting tigers). System 2 requires more time and concentration to get an answer.
    We tend to use System 1 in as many situations as possible because it’s more effective
    for basic tasks. Surprisingly, LLMs do the same and often jump to conclusions.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: We can push the model to think before answering and increase the quality.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: We can give a model step-by-step instructions to force it to go through all
    the steps and don’t rush to conclusions. This approach is called “Chain of thought”
    reasoning.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The other approach is to split your complex task into smaller ones and use
    different prompts for each elementary step. Such an approach has multiple advantages:
    it’s easier to support this code (good analogy: spaghetti code vs. modular one);
    it may be less costly (you don’t need to write long instructions for all possible
    cases); you can augment external tools at specific points of the workflow or include
    human in the loop.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the above approaches, we don’t need to share all the reasoning with the
    end user. We can just keep it as an inner monologue.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suppose we want the model to check some results (for example, from the other
    model or students). In that case, we can ask it to independently get the result
    first or evaluate it against the list of criteria before coming to conclusions.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can find an example of a helpful system prompt from Jeremy Howard that pushes
    the model to reason in [this jupyter notebook](https://github.com/fastai/lm-hackers/blob/main/lm-hackers.ipynb).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: 'Principle #3: Beware hallucinations'
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The well-known problem of LLMs is hallucinations. It’s when a model tells you
    information that looks plausible but not true.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 的一个著名问题是幻觉。这是指模型告诉你看似可信但不真实的信息。
- en: For example, if you ask GPT to provide the most popular papers on DALL-E 3,
    two out of three URLs are invalid.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你要求 GPT 提供关于 DALL-E 3 的最受欢迎的论文，三分之二的网址无效。
- en: '![](../Images/b0eb48faf52a7ce342bd161c3fa97fb0.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b0eb48faf52a7ce342bd161c3fa97fb0.png)'
- en: 'The common sources of hallucinations:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 幻觉的常见来源：
- en: The model doesn’t see many URLs, and it doesn’t know much about it. So, it tends
    to create fake URLs.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型无法看到很多网址，也对这些网址了解甚少。因此，它往往会生成虚假的网址。
- en: It doesn’t know about itself (because there was no info about GPT-4 when the
    model was pre-trained).
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它对自身并不了解（因为在模型预训练时没有关于 GPT-4 的信息）。
- en: The model doesn’t have real-time data and will likely tell you something random
    if you ask about recent events.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型没有实时数据，如果你询问最近的事件，它很可能会告诉你一些随机的内容。
- en: 'To reduce hallucinations, you can try the following approaches:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少幻觉，你可以尝试以下方法：
- en: Ask the model to link the answer to the relevant information from the context,
    then answer the question based on the found data.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让模型将答案与上下文中的相关信息联系起来，然后基于找到的数据回答问题。
- en: In the end, ask the model to validate the result based on provided factual information.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，让模型根据提供的事实信息验证结果。
- en: Remember that Prompt Engineering is an iterative process. It’s unlikely that
    you will be able to solve your task ideally from the first attempt. It’s worth
    trying multiple prompts on a set of example inputs.
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 记住，提示工程是一个迭代过程。从第一次尝试开始，你不太可能完美地解决任务。值得尝试多个提示以处理一组示例输入。
- en: The other thought-provoking idea about LLM answers’ quality is that if the model
    starts to tell you absurd or non-relevant things, it’s likely to proceed. Because,
    on the internet, if you see a thread where nonsense is discussed, the following
    discussion will likely be of poor quality. So, if you’re using the model in a
    chat mode (passing the previous conversation as the context), it might be worth
    starting from scratch.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 LLM 回答质量的另一个发人深省的想法是，如果模型开始告诉你荒谬或不相关的内容，它很可能会继续这样做。因为在互联网上，如果你看到一个讨论胡言乱语的帖子，接下来的讨论很可能质量很差。因此，如果你在聊天模式中使用模型（将之前的对话作为上下文），可能值得从头开始。
- en: ChatGPT API
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT API
- en: ChatGPT from OpenAI is one of the most popular LLMs now, so for this example,
    we will be using ChatGPT API.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 的 ChatGPT 现在是最受欢迎的语言模型之一，因此在这个例子中，我们将使用 ChatGPT API。
- en: For now, GPT-4 is the best-performing LLM we have (according to [fasteval](https://fasteval.github.io/FastEval/)).
    However, it may be enough for non-chat tasks to use the previous version, GPT-3.5.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，GPT-4 是我们拥有的表现最好的语言模型（根据 [fasteval](https://fasteval.github.io/FastEval/)）。然而，对于非聊天任务，使用之前的版本
    GPT-3.5 可能也足够。
- en: Setting up account
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 账户设置
- en: To use ChatGPT API, you need to register on [platform.openai.com](https://platform.openai.com/).
    As usual, you can use authentication from Google. Keep in mind that ChatGPT API
    access is not related to the ChatGPT Plus subscription you might have.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 ChatGPT API，你需要在 [platform.openai.com](https://platform.openai.com/) 注册。像往常一样，你可以使用
    Google 认证。请记住，ChatGPT API 访问与可能拥有的 ChatGPT Plus 订阅无关。
- en: 'After registration, you also need to top up your balance. Since you will pay
    for API calls as you go. You can do it at the “Billing” tab. The process is straightforward:
    you need to fill in your card details and the initial amount you are ready to
    pay.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 注册后，你还需要充值你的余额，因为你将按需支付 API 调用费用。你可以在“账单”选项卡中完成。过程很简单：你需要填写你的卡片信息和你准备支付的初始金额。
- en: The last important step is to create an API Key (a secret key you will use to
    access API). You can do it at the “API Keys” tab. Ensure you save the key since
    you won’t be able to access it afterwards. However, you can create a new key if
    you’ve lost the previous one.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个重要步骤是创建 API 密钥（你将用于访问 API 的秘密密钥）。你可以在“API 密钥”选项卡中完成。确保保存密钥，因为你之后将无法访问它。不过，如果你丢失了之前的密钥，可以创建一个新密钥。
- en: Pricing
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定价
- en: As I mentioned, you will be paying for API calls, so understanding how it works
    is worth it. I advise you to look through [the Pricing documentation](https://openai.com/pricing)
    for the most up-to-date info.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，你将为 API 调用付费，因此了解它的工作原理是值得的。我建议你查看 [定价文档](https://openai.com/pricing) 以获取最新信息。
- en: 'Overall, the price depends on the model and the number of tokens. The more
    complex model would cost you more: ChatGPT 4 is more expensive than ChatGPT 3.5,
    and ChatGPT 3.5 with 16K context is more costly than ChatGPT 3.5 with 4K context.
    You will also have slightly different prices for input tokens (your prompt) and
    output (model response).'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，价格取决于模型和标记的数量。更复杂的模型将花费更多：ChatGPT 4 比 ChatGPT 3.5 更贵，而 ChatGPT 3.5 的 16K
    上下文比 4K 上下文的 ChatGPT 3.5 更昂贵。你还会发现输入标记（你的提示）和输出（模型响应）的价格略有不同。
- en: However, all prices are for 1K tokens, so one of the main factors is the size
    of your input and output.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，所有价格都是针对 1K 标记的，因此一个主要因素是输入和输出的大小。
- en: Let’s discuss what a token is. The model splits text into tokens (widely used
    words or parts of the word). For the English language, one token on average is
    around four characters, and each word is 1.33 tokens.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一下标记是什么。模型将文本分割成标记（广泛使用的词汇或词的一部分）。对于英语语言，平均而言，一个标记大约是四个字符，每个词是 1.33 个标记。
- en: Let’s see how one of our hotels review will be split into tokens.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们的一个酒店评论将如何被分割成标记。
- en: '![](../Images/797d1d2accfd035b12420713b260b7c6.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/797d1d2accfd035b12420713b260b7c6.png)'
- en: You can find the exact number of tokens for your model using `tiktoken` python
    library.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 `tiktoken` Python 库查找你模型的确切标记数。
- en: '[PRE0]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ChatGPT API calls
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT API 调用
- en: OpenAI provides a python package that could help you work with ChatGPT. Let’s
    start with a simple function that will get messages and return responses.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 提供了一个 Python 包，可以帮助你使用 ChatGPT。让我们从一个简单的函数开始，该函数将获取消息并返回响应。
- en: '[PRE1]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let’s discuss the meaning of the main parameters:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一下主要参数的含义：
- en: '`max_tokens` — limit on the number of tokens in the output.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_tokens` — 输出中标记的数量限制。'
- en: '`temperature` here is the measure of entropy (or randomness in the model).
    So if you specify `temperature = 0`, you will always get the same result. Increasing
    `temperature` will let the model to deviate a bit.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`temperature` 这里是熵（或模型中的随机性）的度量。因此，如果你指定 `temperature = 0`，你将始终得到相同的结果。增加 `temperature`
    将使模型有所偏离。'
- en: '`messages` is a set of messages for which the model will create a response.
    Each message has `content` and `role`. There could be several roles for messages:
    `user`, `assistant` (model) and `system` (an initial message that sets assistant
    behaviour).'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`messages` 是一组模型将为其创建响应的消息。每条消息都有 `content` 和 `role`。消息可以有几种角色：`user`、`assistant`（模型）和
    `system`（设置助手行为的初始消息）。'
- en: Let’s look at the case of topic modelling with two stages. First, we will translate
    the review into English and then define the main topics.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下分两阶段的主题建模的情况。首先，我们将评论翻译成英文，然后定义主要主题。
- en: '![](../Images/93f080b59d431989a6693f93e826f0fd.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/93f080b59d431989a6693f93e826f0fd.png)'
- en: Since the model doesn’t keep a state for each question in the session, we need
    to pass the whole context. So, in this case, our `messages` argument should look
    like this.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 由于模型不会为会话中的每个问题保持状态，我们需要传递整个上下文。因此，在这种情况下，我们的 `messages` 参数应该如下所示。
- en: '[PRE2]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Also, OpenAI provides a Moderation API that could help you check whether your
    customer input or model output is good enough and doesn’t contain violence, hate,
    discrimination, etc. These calls are free.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，OpenAI 提供了一个 Moderation API，可以帮助你检查客户输入或模型输出是否足够好，是否包含暴力、仇恨、歧视等内容。这些调用是免费的。
- en: '[PRE3]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: As a result, we will get a dictionary with both flags for each category and
    raw weights. You can use lower thresholds if you need more strict moderation (for
    example, if you’re working on products for kids or vulnerable customers).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是，我们将得到一个包含每个类别的标志和原始权重的字典。如果你需要更严格的审核（例如，如果你正在开发儿童或易受影响客户的产品），可以使用较低的阈值。
- en: '[PRE4]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We won’t need the Moderation API for our task of topic modelling, but it could
    be useful if you are working on a chatbot.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的主题建模任务，我们不需要使用 Moderation API，但如果你在开发聊天机器人，它可能会很有用。
- en: Another good piece of advice, if you’re working with customers’ input, is to
    eliminate the delimiter from the text to avoid prompt injections.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个好的建议是，如果你正在处理客户输入，最好从文本中删除分隔符，以避免提示注入。
- en: '[PRE5]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Model evaluation
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型评估
- en: The last crucial question to discuss is how to evaluate the results of LLM.
    There are two main cases.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个重要的问题是如何评估 LLM 的结果。主要有两种情况。
- en: '**There’s one correct answer (for example, a classification problem)**. In
    this case, you can use supervised learning approaches and look at standard metrics
    (like precision, recall, accuracy, etc.).'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**存在一个正确的答案（例如，分类问题）**。在这种情况下，你可以使用监督学习方法，并查看标准指标（如精确度、召回率、准确度等）。'
- en: '**There’s no correct answer (topic modelling or chat use case).**'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**没有正确的答案（主题建模或聊天用例）。**'
- en: You can use another LLM to access the results of this model. It’s helpful to
    provide the model with a set of criteria to understand the answers’ quality. Also,
    it’s worth using a more complex model for evaluation. For example, you use ChatGPT-3.5
    in production since it’s cheaper and good enough for the use case, but for the
    offline assessment on a sample of cases, you can use ChatGPT-4 to ensure the quality
    of your model.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以使用另一个LLM来访问该模型的结果。为模型提供一组标准以理解答案的质量是很有帮助的。此外，使用更复杂的模型进行评估也是值得的。例如，你可以在生产中使用ChatGPT-3.5，因为它更便宜并且足够好，但对于样本案例的离线评估，你可以使用ChatGPT-4以确保模型的质量。
- en: The other approach is to compare with an “ideal” or expert answer. You can use
    [BLEU score](https://en.wikipedia.org/wiki/BLEU) or another LLM ([OpenAI evals
    project](https://github.com/openai/evals/blob/main/evals/registry/modelgraded/fact.yaml)
    has a lot of helpful prompts for it).
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一种方法是与“理想”或专家答案进行比较。你可以使用[BLEU评分](https://en.wikipedia.org/wiki/BLEU)或其他LLM（[OpenAI
    evals项目](https://github.com/openai/evals/blob/main/evals/registry/modelgraded/fact.yaml)有很多有用的提示）。
- en: In our case, we don’t have one correct answer for customer review, so we will
    need to compare results with expert answers or use another prompt to assess the
    quality of results.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，我们没有一个正确的答案用于客户评论，因此我们需要将结果与专家答案进行比较，或使用其他提示来评估结果的质量。
- en: We’ve quickly looked at the LLM basics and are now ready to move on to the initial
    topic modelling task.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经快速了解了LLM的基本知识，现在准备继续进行初步的主题建模任务。
- en: Empowering BERTopic with ChatGPT
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用ChatGPT增强BERTopic
- en: The most logical enhancement of the previous approach is using LLM to define
    the topics we’ve already identified using BERTopic. We can use the OpenAI representation
    model with a summarisation prompt for this.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 对之前方法的最合乎逻辑的改进是使用LLM来定义我们已经用BERTopic确定的主题。我们可以使用OpenAI的表示模型和总结提示来完成这项工作。
- en: '[PRE6]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Then, BERTopic makes a request to ChatGPT API for each topic, providing keywords
    and a set of representative documents. The response from ChatGPT API is used as
    a model representation.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，BERTopic会向ChatGPT API发出请求，为每个主题提供关键词和一组代表性文档。ChatGPT API的响应被用作模型表示。
- en: You can find more details in the [BERTopic documentation](https://maartengr.github.io/BERTopic/getting_started/representation/llm.html).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[BERTopic文档](https://maartengr.github.io/BERTopic/getting_started/representation/llm.html)中找到更多详细信息。
- en: It’s a reasonable approach, but still we rely entirely on BERTopic to cluster
    documents using embeddings and we can see that topics are a bit entangled. Could
    we get rid of it and use our initial texts as the source of truth?
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种合理的方法，但我们仍然完全依赖BERTopic通过嵌入来对文档进行聚类，我们可以看到主题有些纠缠。我们能否摆脱它，使用初始文本作为真实来源？
- en: Topic Modelling using ChatGPT
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用ChatGPT进行主题建模
- en: 'Actually, we can use ChatGPT for this task and split it into two steps: define
    a list of topics and then assign one or multiple topics for each customer review.
    Let’s try to do it.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们可以使用ChatGPT来完成这个任务，并将其分为两个步骤：定义主题列表，然后为每个客户评论分配一个或多个主题。让我们尝试一下。
- en: Defining a list of topics
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义主题列表
- en: First of all, we need to define the list of topics. Then, we could use it to
    classify reviews.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要定义主题列表。然后，我们可以使用它来分类评论。
- en: Ideally, we could send all texts to ChatGPT and ask it to define the main topics.
    However, it might be pretty costly and not so straightforward. There are more
    than 2.5M tokens in the whole dataset of hotels’ reviews. So we won’t be able
    to feed all comments into one dataset (because the ChatGPT-4 now has only 32K
    as a context).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，我们可以将所有文本发送到ChatGPT，并要求它定义主要主题。然而，这可能非常昂贵且不那么直接。整个酒店评论的数据集中有超过250万tokens。因此，我们无法将所有评论放入一个数据集中（因为ChatGPT-4目前只有32K的上下文）。
- en: To overcome this limitation, we can define a representative subset of documents
    that fit the context size. BERTopic returns a set of the most representative documents
    for each topic so we can fit a basic BERTopic model.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这个限制，我们可以定义一个适合上下文大小的代表性文档子集。BERTopic会返回每个主题的最具代表性的文档集合，因此我们可以拟合一个基本的BERTopic模型。
- en: '[PRE7]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now, we can use these documents to define a list of relevant topics.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用这些文档来定义一个相关主题的列表。
- en: '[PRE8]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Let’s check the size of `user_message` to ensure that it fits the context.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一下`user_message`的大小，以确保它适合上下文。
- en: '[PRE9]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: It exceeds 4K, so we need to use `gpt-3.5-turbo-16k` for this task.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 它超过了4K，因此我们需要使用`gpt-3.5-turbo-16k`来完成这个任务。
- en: '[PRE10]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As a result, we got a list of relevant topics, and it looks pretty reasonable.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们得到了一个相关话题的列表，这看起来非常合理。
- en: '![](../Images/211eb530e63f2d15be600e108eff577a.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/211eb530e63f2d15be600e108eff577a.png)'
- en: Classifying reviews by topics
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 按主题分类评论
- en: The next step is to assign one or several topics for each customer review. Let’s
    compose a prompt for it.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是为每个客户评论分配一个或多个主题。让我们为此编写一个提示。
- en: '[PRE11]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Such an approach gives pretty good results. It can handle even comments in other
    languages (like German in the example below).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法能取得相当不错的结果。它甚至可以处理其他语言的评论（例如下面的德语评论）。
- en: '![](../Images/a25d042dea8303f0ffaf0fbdf73eb812.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a25d042dea8303f0ffaf0fbdf73eb812.png)'
- en: The only mistake in this small data sample is the `Restaurant` topic for the
    first comment. There were no mentions of the hotel’s restaurant in the customer
    review, only the ones nearby. But let’s look at our prompt. We don’t tell the
    model that we are interested only in specific restaurants, so it’s plausible for
    it to assign such a topic to the comment.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这个小数据样本中的唯一错误是第一个评论的 `Restaurant` 主题。客户评论中没有提到酒店餐厅，只提到了附近的餐馆。但让我们看看我们的提示。我们并没有告诉模型我们只对特定的餐馆感兴趣，因此它将这样的主题分配给评论是合理的。
- en: Let’s think about how we could solve this problem. If we change the prompt a
    bit and provide the model with not only topic names (for example, “*Restaurant*”)
    but also topic descriptions (for example, “*A few reviews mention the hotel’s
    restaurant, either positively or negatively.*”), the model will have enough info
    to fix this issue. With the new prompt, the model returns only relevant `Location`
    and `Room Size` topics for the first comment.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一下如何解决这个问题。如果我们稍微修改提示，给模型提供不仅仅是主题名称（例如，“*Restaurant*”），还包括主题描述（例如，“*一些评论提到酒店餐厅，无论是积极还是消极的。*”），模型将有足够的信息来修复这个问题。使用新的提示，模型仅返回与第一个评论相关的
    `Location` 和 `Room Size` 主题。
- en: '[PRE12]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Summary
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this article, we’ve discussed the main questions related to LLM practical
    usage: how they work, their main applications, and how to use LLMs.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们讨论了与 LLM 实际使用相关的主要问题：它们是如何工作的、它们的主要应用以及如何使用 LLM。
- en: We’ve built a prototype for Topic Modelling using ChatGPT API. Based on a small
    sample of examples, it works amazingly and gives results that can be easily interpreted.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经构建了一个使用 ChatGPT API 的主题建模原型。基于一小部分示例，它的表现非常出色，结果也容易解释。
- en: The only drawback of the ChatGPT approach is its cost. It would cost more than
    75 USD to classify all the texts in our hotel reviews dataset (based on 2.5M tokens
    in the dataset and pricing for GPT-4). So, even though ChatGPT is the best-performing
    model now, it might be worth looking at open-source alternatives if you need to
    work with massive datasets.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 方法的唯一缺点是其成本。根据数据集中的 250 万个令牌和 GPT-4 的定价，将所有文本分类为酒店评论将花费超过 75 美元。因此，即使
    ChatGPT 现在是表现最好的模型，如果您需要处理大规模数据集，可能值得考虑开源替代方案。
- en: Thank you a lot for reading this article. I hope it was insightful to you. If
    you have any follow-up questions or comments, please leave them in the comments
    section.
  id: totrans-137
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 非常感谢您阅读这篇文章。希望它对您有所启发。如果您有任何后续问题或评论，请在评论区留言。
- en: Dataset
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集
- en: '*Ganesan, Kavita and Zhai, ChengXiang. (2011). OpinRank Review Dataset.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '*Ganesan, Kavita 和 Zhai, ChengXiang. (2011). OpinRank 评审数据集。'
- en: UCI Machine Learning Repository.* [*https://doi.org/10.24432/C5QW4W*](https://doi.org/10.24432/C5QW4W.)
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: UCI 机器学习库。* [*https://doi.org/10.24432/C5QW4W*](https://doi.org/10.24432/C5QW4W.)
- en: Reference
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'This article is based on information from the following sources:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章基于以下来源的信息：
- en: '[The Hacker’s Guide to Language Models](https://www.youtube.com/watch?v=jkrNMKz9pWU)
    by Jeremy Howard'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[黑客的语言模型指南](https://www.youtube.com/watch?v=jkrNMKz9pWU) 由 Jeremy Howard 提供'
- en: '[ChatGPT Prompt Engineering for Developers](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)
    by DeepLearning.AI'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ChatGPT 提示工程师指南](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)
    由 DeepLearning.AI 提供'
- en: '[Building Systems with ChatGPT API](https://www.deeplearning.ai/short-courses/building-systems-with-chatgpt/)
    by DeepLearning.AI'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 ChatGPT API 构建系统](https://www.deeplearning.ai/short-courses/building-systems-with-chatgpt/)
    由 DeepLearning.AI 提供'
