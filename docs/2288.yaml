- en: Effectively Optimize Your Regression Model with Bayesian Hyperparameter Tuning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/effectively-optimize-your-regression-model-with-bayesian-hyperparameter-tuning-819c19f5dab3?source=collection_archive---------8-----------------------#2023-07-17](https://towardsdatascience.com/effectively-optimize-your-regression-model-with-bayesian-hyperparameter-tuning-819c19f5dab3?source=collection_archive---------8-----------------------#2023-07-17)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learn to effectively optimize hyperparameters, and prevent creating overtrained
    models for XGBoost, CatBoost, and LightBoost
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://erdogant.medium.com/?source=post_page-----819c19f5dab3--------------------------------)[![Erdogan
    Taskesen](../Images/8e62cdae0502687710d8ae4bbcd8966e.png)](https://erdogant.medium.com/?source=post_page-----819c19f5dab3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----819c19f5dab3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----819c19f5dab3--------------------------------)
    [Erdogan Taskesen](https://erdogant.medium.com/?source=post_page-----819c19f5dab3--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4e636e2ef813&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffectively-optimize-your-regression-model-with-bayesian-hyperparameter-tuning-819c19f5dab3&user=Erdogan+Taskesen&userId=4e636e2ef813&source=post_page-4e636e2ef813----819c19f5dab3---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----819c19f5dab3--------------------------------)
    ·15 min read·Jul 17, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F819c19f5dab3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffectively-optimize-your-regression-model-with-bayesian-hyperparameter-tuning-819c19f5dab3&user=Erdogan+Taskesen&userId=4e636e2ef813&source=-----819c19f5dab3---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F819c19f5dab3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffectively-optimize-your-regression-model-with-bayesian-hyperparameter-tuning-819c19f5dab3&source=-----819c19f5dab3---------------------bookmark_footer-----------)![](../Images/85d161655226ea3f51d0055d58fa9bfe.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Alexey Ruban](https://unsplash.com/@intelligenciya?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/tune?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: Gradient boosting techniques such as *XGBoost, CatBoost, and LightBoost* has
    gained much popularity in recent years for both classification and regression
    tasks. An important part of the process is the tuning of hyperparameters to gain
    the best model performance. The key is to optimize the hyperparameter search space
    together with finding a model that can generalize on new unseen data. *In this
    blog, I will demonstrate 1\. how to learn a boosted decision tree* ***regression***
    *model with optimized hyperparameters using Bayesian optimization, 2\. how to
    select a model that can generalize (and is not overtrained), 3\. how to interpret
    and visually explain the optimized hyperparameter space together with the model
    performance accuracy. The* [*HGBoost*](https://erdogant.github.io/hgboost/) *library
    is ideal for this task which performs, among others a double loop cross-validation
    to protect against overtraining.*
  prefs: []
  type: TYPE_NORMAL
- en: A brief introduction.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Gradient boosting algorithms such as Extreme Gradient Boosting (*XGboost*),
    Light Gradient Boosting (*Lightboost*), and *CatBoost* are powerful ensemble machine
    learning…
  prefs: []
  type: TYPE_NORMAL
