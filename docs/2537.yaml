- en: 'Pioneering Data Observability: Data, Code, Infrastructure, & AI'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/pioneering-data-observability-data-code-infrastructure-ai-c22a26706866?source=collection_archive---------5-----------------------#2023-08-08](https://towardsdatascience.com/pioneering-data-observability-data-code-infrastructure-ai-c22a26706866?source=collection_archive---------5-----------------------#2023-08-08)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://barrmoses.medium.com/?source=post_page-----c22a26706866--------------------------------)[![Barr
    Moses](../Images/4c74558ee692a85196d5a55ac1920718.png)](https://barrmoses.medium.com/?source=post_page-----c22a26706866--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c22a26706866--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c22a26706866--------------------------------)
    [Barr Moses](https://barrmoses.medium.com/?source=post_page-----c22a26706866--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2818bac48708&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpioneering-data-observability-data-code-infrastructure-ai-c22a26706866&user=Barr+Moses&userId=2818bac48708&source=post_page-2818bac48708----c22a26706866---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c22a26706866--------------------------------)
    ·8 min read·Aug 8, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc22a26706866&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpioneering-data-observability-data-code-infrastructure-ai-c22a26706866&user=Barr+Moses&userId=2818bac48708&source=-----c22a26706866---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc22a26706866&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpioneering-data-observability-data-code-infrastructure-ai-c22a26706866&source=-----c22a26706866---------------------bookmark_footer-----------)![](../Images/079ebda08bb05632eee7b75a1e165fa8.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The four dimensions of data observability: data, code, infrastructure, and
    ai? Image courtesy of the author.'
  prefs: []
  type: TYPE_NORMAL
- en: Outlining the past, present, and future of architecting reliable data systems.
  prefs: []
  type: TYPE_NORMAL
- en: When we launched the [**data observability**](https://www.montecarlodata.com/blog-what-is-data-observability/)
    category in 2019, the term was something I could barely pronounce.
  prefs: []
  type: TYPE_NORMAL
- en: Four years later, the category has squarely established itself as [**a core
    layer of the modern data stack**](/how-to-build-a-5-layer-data-stack-508ed09711f2).
    Data Observability is [a G2 category,](https://www.g2.com/categories/data-observability)
    recognized by Gartner, Forrester, and more, and most importantly, widely adopted
    by hundreds of companies, including some of the world’s most advanced data organizations.
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, the CTO of a fast growing company told me recently: “This is the secular
    trend given how the world is changing. Data observability was going to happen
    sooner or later and there’s nothing anyone can do to stop it.”'
  prefs: []
  type: TYPE_NORMAL
- en: While I still can’t always pronounce it (ESL, anyone?), data observability has
    become a must have for modern data teams, and I couldn’t be prouder of how far
    this movement has come — and where we’re going.
  prefs: []
  type: TYPE_NORMAL
- en: So, what’s in store for the future of data reliability? To understand where
    we’re going, it helps to first take a step back and assess how far we’ve come.
  prefs: []
  type: TYPE_NORMAL
- en: Where we started
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the mid-2010s, data teams began migrating to the cloud and adopting data
    storage and compute technologies — Redshift, Snowflake, Databricks, GCP, oh my!
    — to meet the growing demand for analytics. The cloud made data faster to process,
    easier to transform and far more accessible.
  prefs: []
  type: TYPE_NORMAL
- en: As data became more ubiquitous, pipelines grew more complex, new personas entered
    the scene to manage this chaos (hello, data engineers), and the number of possible
    use cases exploded.
  prefs: []
  type: TYPE_NORMAL
- en: The upside? More informed decision making, more data use cases, and smarter
    software.
  prefs: []
  type: TYPE_NORMAL
- en: The downside? The basics — like data quality — were neglected and took a back
    seat to shinier parts of this modern data stack.
  prefs: []
  type: TYPE_NORMAL
- en: In a past life, I saw firsthand the implications of bad data. 5 a.m. pings from
    our CFO when “the data looks wrong.” Sticky notes on my computer monitor from
    stakeholders when dashboards failed to update. Frustrated customers scratching
    their heads because our product was fed inaccurate data.
  prefs: []
  type: TYPE_NORMAL
- en: '[Data observability](https://www.montecarlodata.com/blog-what-is-data-observability/)
    was born from this pain — what we referred to as [data downtime](https://www.montecarlodata.com/blog-the-rise-of-data-downtime/)
    — and offered a tangible solution. Inspired by application observability and site
    reliability engineering, data observability monitors and alerts organizations
    to data incidents before they impact the business. Data observability offered
    an automated, process-driven alternative to achieving data reliability that cut
    costs, drove growth, and substantially reduced 5 a.m. fire drills.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Historically, the strongest data observability approaches incorporate three
    main stages: **detection**, **resolution**, and **prevention**.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Detection:** Data observability detects anomalies and other issues in your
    data and alerts the appropriate owners on the data team before stakeholders find
    out.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Resolution:** Simultaneously, data observability platforms give teams the
    tools to resolve the issue, including field-level lineage, automated root cause
    analysis and impact analysis, information about past incidents affecting that
    asset, related query logs and dbt models, affected reports, and more.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Prevention:** Finally, data observability also provides mechanisms to prevent
    data issues from happening in the first place, like placing circuit breaking in
    pipelines and creating visibility around the impact code changes would make on
    data, among other proactive measures of preventing bad data from entering your
    pipelines in the first place.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the beginning, data observability focused exclusively on detecting, resolving,
    and preventing data issues by leveraging both metadata and the data itself to
    piece together a picture of data health. By monitoring and alerting to issues
    in data from ingestion to consumption, teams could detect changes in upstream
    tables that weren’t anticipated, which caused downstream sources to break or become
    unreliable.
  prefs: []
  type: TYPE_NORMAL
- en: Extending detection and resolution beyond data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'However, like any industry, the data space evolved, impacting the way teams
    need to think about incident detection and resolution, and data observability
    more broadly. This evolution is owing to a few exciting trends: **the rise of
    data products** and, as a result, **the ongoing migration of data teams closer
    to or directly into the Engineering org.**'
  prefs: []
  type: TYPE_NORMAL
- en: As data teams increase their scope in the organization and data use cases grow,
    the data team is more [impactful](https://www.nasdaq.com/articles/why-unity-software-tanked-39-this-week)
    to the bottomline than ever before. Now, everyone across the business leverages
    data every day to drive insights, power digital services, and train ML models.
    In fact, we’ve gone beyond simply [treating data like a product](https://insidebigdata.com/2022/06/09/dont-call-it-a-data-product-unless-it-meets-these-5-requirements/).
    In 2023, **data IS a product.**
  prefs: []
  type: TYPE_NORMAL
- en: 'Hundreds of customers later, including teams at Pepsi, Gusto, MasterClass,
    and Vimeo, and what we’ve discovered is that we need to look beyond just the **data**
    to achieve data reliability. Unreliable data doesn’t live in a silo… it’s impacted
    by all three ingredients of the data ecosystem: **data** + **code** + **infrastructure**.'
  prefs: []
  type: TYPE_NORMAL
- en: This broader vision reflects how our friends in software engineering tackle
    detection and resolution, too. Application observability starts with infrastructure
    but analyzes way more than that to detect and resolve software downtime; root
    cause analysis takes into account code, infrastructure, services, network and
    plenty of other factors. For software engineers, reliability isn’t achieved in
    a vacuum — it’s often impacted by multiple factors, frequently acting in tandem
    or compounding on one another.
  prefs: []
  type: TYPE_NORMAL
- en: In data, the scenario is often the same and it’s time we start treating it that
    way.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s walk through a hypothetical example from the data world.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you have a dashboard showing stale results. You might first **look at
    your data**, in this case, perhaps an upstream table ingested from Google describing
    your ad campaigns. Did someone change a campaign name, breaking a hardcoded data
    pipeline? Or perhaps you’re getting nulls instead of user UUIDs in your click
    events table?No dice, so what’s next?
  prefs: []
  type: TYPE_NORMAL
- en: '**You look at the code**. Maybe your analytics engineer made a change to your
    SQL that filters out the most recent data? They had good intentions, but perhaps
    it had unintended consequences? You take a peek into your dbt repo. Nope — all
    good there.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you **look at your infrastructure**. You quickly click over to your
    Airflow UI — maybe you’re running Airflow on a small instance and it ran out of
    memory (shouldn’t have loaded those rows into memory!!), causing the downstream
    freshness issue. Eureka — you’ve found it!
  prefs: []
  type: TYPE_NORMAL
- en: Experience teaches us that all three factors contribute meaningfully to data
    downtime. So no matter where you look first, you are in for a long, tedious process
    of making educated guesses and eliminating them one by one. Oh, and did we mention
    it requires access to and proficiency in the 8 different tools that make up your
    data stack?
  prefs: []
  type: TYPE_NORMAL
- en: Now, imagine you could quickly correlate the symptom you’re seeing (stale dashboard…)
    with all the changes that have happened to the data, to code and to infrastructure.
    Oh, and you don’t need a PHD in statistics or 10 years experience in the company
    knowing every single column in the data warehouse. It’s all at your fingertips
    — an end-to-end understanding of how data, code and infrastructure worked together
    to result in a broken dashboard. Think about all the time and resources you could
    have saved and stakeholder frustration you could have avoided, not to mention
    the early morning wakeup call.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/241446b62edeb1e92024042187ee3262.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Data observability requires insight into three layers of the data environment:
    data, code, and infrastructure. Image courtesy of author.*'
  prefs: []
  type: TYPE_NORMAL
- en: To truly realize the potential of data observability and achieve reliable data,
    teams need to take a three-tiered approach that weaves together a comprehensive
    picture of the data, code, and infrastructure impacting data health.
  prefs: []
  type: TYPE_NORMAL
- en: What we’ve also come to realize is that achieving data reliability is not just
    about turning on a tool. It’s about creating a new discipline on the team — an
    operational mindset if you will. Teams need to introduce processes around monitoring
    data systems, responding to incidents and iteratively getting better over time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Organizational structures, processes, and technologies must evolve to accomplish
    those goals. Think: [dashboards](https://www.montecarlodata.com/blog-announcing-monte-carlos-data-reliability-dashboard-a-better-way-understand-the-health-of-your-data/)
    that define and monitor the reliability of data products based on the upstream
    tables powering them that can be easily shared across the org for transparency,
    collaboration and accountability. And [domains](https://www.montecarlodata.com/blog-5-steps-to-getting-started-with-data-observability/)
    that segment data and pipelines based on use case and owners for targeted triaging
    and incident resolution.'
  prefs: []
  type: TYPE_NORMAL
- en: Reliable Data and the Future of AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Betting on large language models (LLMs) as the future of [insert industry here]
    is almost cliché at this point, but the impact on the data industry is different.
  prefs: []
  type: TYPE_NORMAL
- en: Current generative AI use cases in data and engineering are focused almost exclusively
    on scaling productivity, like GitHub Co-Pilot, Snowflake Document AI, and Databricks
    LakehouseIQ. In many ways, we don’t know what the future of Generative AI will
    hold but we do know that data teams will play a big part in its success.
  prefs: []
  type: TYPE_NORMAL
- en: 'There’s an exciting opportunity for LLMs to help with data quality, but the
    even more powerful thesis is that data quality and reliability can help LLMs.
    In fact, I’d argue LLMs serving production use cases cannot exist without a solid
    foundation: having lots of high quality, reliable, trusted data.'
  prefs: []
  type: TYPE_NORMAL
- en: By and large, the vast majority of generative AI applications today are hosted
    in the cloud and surfaced with an API. To support them, you need a robust, cloud-based
    data stack to reliably store, transform, train, and serve the data powering them.
  prefs: []
  type: TYPE_NORMAL
- en: Echoing this sentiment, during Snowflake’s Q1 2023 earnings call, Frank Slootman,
    CEO of Snowflake, argued that “generative AI is powered by data. That’s how models
    train and become progressively more interesting and relevant… You cannot just
    indiscriminately let these [LLMs] loose on data that people don’t understand in
    terms of its quality and its definition and its lineage.”
  prefs: []
  type: TYPE_NORMAL
- en: We’ve already seen the implications of unreliable model training. Just last
    year, Equifax, the global credit giant, [shared](https://www.cnn.com/2022/08/03/business/equifax-wrong-credit-scores/index.html)
    that an ML model trained on bad data caused them to send lenders incorrect credit
    scores for millions of consumers. And not long before that, [Unity Technologies
    reported](https://seekingalpha.com/news/3836713-unity-crashes-20-as-guidance-shows-slowing-growth-ad-delay-could-hurt-revenue-for-a-year)
    a revenue loss of $110M due to bad ads data fueling its targeting algorithms.
    In the coming years, this will inevitably become an even bigger problem unless
    we prioritize trust.
  prefs: []
  type: TYPE_NORMAL
- en: As we witness the rise of AI applications for the enterprise in the coming years,
    data observability will emerge as a critical capability to support LLMs and all
    other AI use cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'As Databricks co-founders Matei Zaharia, Patrick Wendell, Reynold Xin and Ali
    Ghodsi [suggest](https://www.databricks.com/blog/databricks-mosaicml?trk=feed_main-feed-card_reshare_feed-article-content):
    “Enterprise applications also have little tolerance for hallucinations or incorrect
    responses… In every stage of the machine learning lifecycle, the data and models
    must be jointly curated in order to build the best applications. This is even
    more important for generative models, where quality and safety depend so much
    on good training data.”'
  prefs: []
  type: TYPE_NORMAL
- en: I couldn’t agree more. First step to better, more impactful AI? Good, reliable
    data — and lots of it.
  prefs: []
  type: TYPE_NORMAL
- en: Join us, won’t you?
  prefs: []
  type: TYPE_NORMAL
- en: '***Reach out to*** [***Barr Moses***](https://www.linkedin.com/in/barrmoses/)
    ***via LinkedIn with thoughts, feelings, and emotions. Where do you think this
    space is headed?***'
  prefs: []
  type: TYPE_NORMAL
