["```py\nfrom googletrans import Translator, constants\nfrom httpx import Timeout\n\nimport json\nimport pandas as pd\nimport time\n```", "```py\nsrc_lang = \"en\"\ndest_lang = \"nl\"\n\ntranslator = Translator(timeout = Timeout(60))\n```", "```py\ndef read_squad(path):\n    with open(path, 'rb') as f:\n        squad_dict = json.load(f)\n    contexts, questions, answers = [], [], []\n    for group in squad_dict['data']:\n        for passage in group['paragraphs']:\n            context = passage['context']\n\n            for qa in passage['qas']:\n                question = qa['question']\n                if 'plausible_answers' in qa.keys():\n                    access = 'plausible_answers'\n                else:\n                    access = 'answers'\n                for answer in qa[access]:\n                    contexts.append(context)\n                    questions.append(question)\n                    answers.append(answer['text'])\n    return contexts, questions, answers\n\ntrain_c, train_q, train_a = read_squad('squad-train-v2.0.json')\nval_c, val_q, val_a= read_squad('squad-dev-v2.0.json')\n```", "```py\ndef time_translation(entries, name):\n    start_time = time.time()\n    translation = translator.translate(entries[0], dest=dest_lang, src= src_lang)\n    duration = time.time() - start_time\n    total_duration = len(entries)*duration\n    print(f\"translating {name} takes {total_duration/60/60} hours\")\n\ntime_translation(train_c, \"train contexts\")\ntime_translation(train_q, \"train questions\")\ntime_translation(train_a, \"train answers\")\ntime_translation(val_c, \"validation contexts\")\ntime_translation(val_q, \"validation questions\")\ntime_translation(val_a, \"validation answers\")\n```", "```py\ndef get_translation(text):\n    success = False\n    translation = \"\"\n    while not success:\n        translation = translator.translate(text, dest=dest_lang, src=src_lang).text\n        success = True\n    return translation\n```", "```py\ndef translate_context(contexts, name):\n    start_time = time.time()\n    context_current = \"\"\n    translated_contexts = []\n    index = 0\n\n    for context in contexts:\n        index+=1\n        if context != context_current:\n            context_current = context\n            print(f\"[{index}/{len(contexts)}]\")\n            get_translation(context)\n            context_translated = get_translation(context)\n            translated_contexts.append(context_translated)\n        else:\n            translated_contexts.append(context_translated)\n\n    duration = time.time() - start_time\n    print(f\"Translating {name} took {round(duration, 2)}s\") \n    return translated_contexts\n```", "```py\ndef translate_qa(input, name):\n    start_time = time.time()\n    input_translated = []\n    index = 0\n    for text in input:\n        text_nl = get_translation(text)\n        input_translated.append(text_nl)\n        index+=1\n        print(f\"[{index}/{len(input)}]\")\n    duration = time.time() - start_time\n    print(f\"Translating {name} took {round(duration, 2)}s\") \n    return input_translated\n```", "```py\ntrain_c_translated = translate_context(train_c, \"train contexts\")\ntrain_q_translated = translate_qa(train_q, \"train questions\")\ntrain_a_translated = translate_qa(train_a, \"train answers\")\n\nval_c_translated = translate_context(val_c, \"val contexts\")\nval_q_translated = translate_qa(val_q, \"val questions\")\nval_a_translated = translate_qa(val_a, \"val answers\")\n```", "```py\ndef save_data(data, name, header):\n    data_df = pd.DataFrame(data)\n    data_df.to_csv(name + \"_pdcsv.csv\", encoding='utf-16', index_label = \"Index\", header = [header])\n\nsave_data(train_c_translated, \"train_contexts\", \"contexts\")\nsave_data(train_q_translated, \"train_questions\", \"questions\")\nsave_data(train_a_translated, \"train_answers\", \"answers\")\nsave_data(val_c_translated, \"val_contexts\", \"contexts\")\nsave_data(val_q_translated, \"val_questions\", \"questions\")\nsave_data(val_a_translated, \"val_answers\", \"answers\")\n```", "```py\nimport pandas as pd\nimport unicodedata\n\nimport torch\nfrom torch.utils.data import DataLoader\n\nfrom transformers import T5Tokenizer\nfrom transformers import T5ForConditionalGeneration\nfrom transformers import AdamW\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import train_test_split \nfrom datetime import datetime\n\nmax_text_length = 512\nmax_output_length = 256\n```", "```py\ndef load_data(path):\n    df = pd.read_csv(path, encoding='utf-16')\n    df = df.drop('Index', axis=1)\n    data = df.values.tolist()\n    data = [a[0] for a in data]\n    return data\n\ndef to_utf8(text):\n    try:\n        text = unicode(text, 'utf-8')\n    except NameError:\n        pass\n    text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore').decode(\"utf-8\")\n    return str(text)\n```", "```py\ncontexts_csv = 'train_contexts_pdcsv.csv'\nquestions_csv = 'train_questions_pdcsv.csv'\nanswers_csv = 'train_answers_pdcsv.csv'\n\ncontexts = load_data(contexts_csv)\nquestions = load_data(questions_csv)\nanswers = load_data(answers_csv)\n\nc_train, c_val, q_train, q_val, a_train, a_val = train_test_split(contexts,\n                                                questions, answers,\n                                                test_size=0.2,\n                                                random_state=42)\n```", "```py\ndef clean_data(contexts, questions, answers):\n    cleaned_contexts, cleaned_questions, cleaned_answers = [], [], []\n    for i in range(len(answers)):\n        cleaned_contexts.append(to_utf8(contexts[i]))\n        cleaned_questions.append(to_utf8(questions[i]))\n        cleaned_answers.append(to_utf8(answers[i]))\n    return cleaned_contexts, cleaned_questions, cleaned_answers\n\ncc_train, cq_train, ca_train = clean_data(c_train, q_train, a_train); \ncc_val, cq_val, ca_val = clean_data(c_val, q_val, a_val); \n\nprint(\"Original data size: \" + str(len(q_train)))\nprint(\"Filtered data size: \" + str(len(cq_train)))\n\n#cc_train = cc_train[0:1000]\n#cq_train = cq_train[0:1000]\n#ca_train = ca_train[0:1000]\n```", "```py\ndef clean_data(contexts, questions, answers):\n    cleaned_contexts, cleaned_questions, cleaned_answers = [], [], []\n    for i in range(len(answers)):\n        index = contexts[i].find(answers[i])\n        if(index != -1):\n        #print(str(index) + \" + \" + str(index+len(answers[i])))\n            cleaned_contexts.append(contexts[i])\n            cleaned_questions.append(questions[i])\n            cleaned_answers.append({\n                'text':answers[i],\n                'answer_start': index,\n                'answer_end': index+len(answers[i])\n                })\n    return cleaned_contexts, cleaned_questions, cleaned_answers\n\ncc_train, cq_train, ca_train = clean_data(c_train, q_train, a_train); \ncc_val, cq_val, ca_val = clean_data(c_val, q_val, a_val);\n```", "```py\ntokenizer = T5Tokenizer.from_pretrained('google/t5-v1_1-base')\ntrain_encodings = tokenizer(cc_train, cq_train, max_length=max_text_length, truncation=True, padding=True)\nval_encodings = tokenizer(cc_val, cq_val, max_length=max_text_length, truncation=True, padding=True)\n\ndef add_token_positions(encodings, answers):\n    tokenized = tokenizer(answers, truncation=True, padding=True)\n    encodings.update({'target_ids': tokenized['input_ids'], 'target_attention_mask': tokenized['attention_mask']})\n\nadd_token_positions(train_encodings, ca_train)\nadd_token_positions(val_encodings, ca_val)\n```", "```py\nclass SquadDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n        print(encodings.keys())\n\n    def __getitem__(self, idx):\n        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n\n    def __len__(self):\n        return len(self.encodings.input_ids)\n\ntrain_dataset = SquadDataset(train_encodings)\nval_dataset = SquadDataset(val_encodings)\n\ntrain_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n```", "```py\nmodel = T5ForConditionalGeneration.from_pretrained('google/t5-v1_1-base')\ncuda = torch.cuda.is_available()\ndevice = torch.device('cuda') if cuda else torch.device('cpu')\nmodel.to(device)\nmodel.train()\n\noptimizer = AdamW(model.parameters(), lr=1e-4)\n\ndef save_model():\n    now = datetime.now()\n    date_time = now.strftime(\" %m %d %Y %H %M %S\")\n    torch.save(model.state_dict(), \"answer_gen_models/nlpModel\"+date_time+\".pt\")\n```", "```py\nfor epoch in range(3):\n    loop = tqdm(train_loader, leave=True)\n    for batch in loop:\n        optim.zero_grad()\n\n        # >\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        target_ids = batch['target_ids'].to(device)\n        target_attention_mask = batch['target_attention_mask'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask,\n                        labels=target_ids,\n                        decoder_attention_mask=target_attention_mask)\n        # >\n        loss = outputs[0]\n        loss.backward()\n        optimizer.step()\n\n        loop.set_description(f'Epoch {epoch}')\n        loop.set_postfix(loss=loss.item())\nsave_model()\n```", "```py\nmodel = T5ForConditionalGeneration.from_pretrained('google/t5-v1_1-base')\nmodel.load_state_dict(torch.load(\"answer_gen_models/some_model.pt\"))\n\ncuda = torch.cuda.is_available()\ndevice = torch.device('cuda') if cuda else torch.device('cpu')\nmodel.to(device)\nmodel.eval()\n\ndef test(context, question):\n    input = tokenizer([to_utf8(context)],\n                      [to_utf8(question)],\n                      max_length=max_text_length,\n                      truncation=True,\n                      padding=True)\n    with torch.no_grad():\n        input_ids = torch.tensor(input['input_ids']).to(device)\n        attention_mask = torch.tensor(input['attention_mask']).to(device)\n        out = model.generate(input_ids,\n                             attention_mask=attention_mask,\n                             max_length=max_output_length,\n                             early_stopping=True)\n        print([tokenizer.decode(ids,\n        skip_special_tokens=True) for ids in out][0])\n\ntest(\"Dit is een voorbeeld\", \"Wat is dit?\")\n```"]