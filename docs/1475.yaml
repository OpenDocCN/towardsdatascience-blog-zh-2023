- en: The Case Against Enterprise LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 反对企业 LLMs 的案例
- en: 原文：[https://towardsdatascience.com/the-case-against-enterprise-llms-43795a0db501?source=collection_archive---------2-----------------------#2023-04-29](https://towardsdatascience.com/the-case-against-enterprise-llms-43795a0db501?source=collection_archive---------2-----------------------#2023-04-29)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-case-against-enterprise-llms-43795a0db501?source=collection_archive---------2-----------------------#2023-04-29](https://towardsdatascience.com/the-case-against-enterprise-llms-43795a0db501?source=collection_archive---------2-----------------------#2023-04-29)
- en: Opinion
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 观点
- en: A sober perspective as to why boring is best, even for AI
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一种清醒的视角，说明为什么无聊可能是最好的，甚至对于AI来说也是如此
- en: '[](https://medium.com/@lsci?source=post_page-----43795a0db501--------------------------------)[![Mathieu
    Lemay](../Images/39db2877c94829bef1d6642daf3ccecb.png)](https://medium.com/@lsci?source=post_page-----43795a0db501--------------------------------)[](https://towardsdatascience.com/?source=post_page-----43795a0db501--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----43795a0db501--------------------------------)
    [Mathieu Lemay](https://medium.com/@lsci?source=post_page-----43795a0db501--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@lsci?source=post_page-----43795a0db501--------------------------------)[![Mathieu
    Lemay](../Images/39db2877c94829bef1d6642daf3ccecb.png)](https://medium.com/@lsci?source=post_page-----43795a0db501--------------------------------)[](https://towardsdatascience.com/?source=post_page-----43795a0db501--------------------------------)[![数据科学之路](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----43795a0db501--------------------------------)
    [Mathieu Lemay](https://medium.com/@lsci?source=post_page-----43795a0db501--------------------------------)'
- en: ·
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff84a70d8f74&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-case-against-enterprise-llms-43795a0db501&user=Mathieu+Lemay&userId=f84a70d8f74&source=post_page-f84a70d8f74----43795a0db501---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----43795a0db501--------------------------------)
    ·6 min read·Apr 29, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F43795a0db501&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-case-against-enterprise-llms-43795a0db501&user=Mathieu+Lemay&userId=f84a70d8f74&source=-----43795a0db501---------------------clap_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff84a70d8f74&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-case-against-enterprise-llms-43795a0db501&user=Mathieu+Lemay&userId=f84a70d8f74&source=post_page-f84a70d8f74----43795a0db501---------------------post_header-----------)
    发表在 [数据科学之路](https://towardsdatascience.com/?source=post_page-----43795a0db501--------------------------------)
    ·6分钟阅读·2023年4月29日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F43795a0db501&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-case-against-enterprise-llms-43795a0db501&user=Mathieu+Lemay&userId=f84a70d8f74&source=-----43795a0db501---------------------clap_footer-----------)'
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F43795a0db501&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-case-against-enterprise-llms-43795a0db501&source=-----43795a0db501---------------------bookmark_footer-----------)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F43795a0db501&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-case-against-enterprise-llms-43795a0db501&source=-----43795a0db501---------------------bookmark_footer-----------)'
- en: Over the last few weeks, we’ve had a trove of custom LLM requests from clients
    and partners. This excitement, although warranted, is based on tech news inundation,
    not on getting a fundamental corporate advantage.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的几周里，我们收到了大量来自客户和合作伙伴的定制 LLM 请求。这种兴奋感，虽然是合理的，但更多是基于技术新闻的轰炸，而不是获取根本的企业优势。
- en: LLMs, even though they are not conceptually far off from most transformer-based
    training pipelines, require much more complex machinery to fine-tune and operate
    smoothly in a corporate setting. All the ones we already tested and deployed for
    clients are good, but they don’t have the same gloss as polished commercial products,
    which is an issue with business leads.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 LLMs 在概念上并不比大多数基于变换器的训练管道差，但在企业环境中微调和顺利操作需要更复杂的机制。我们已经测试和部署给客户的所有模型都很好，但它们没有像抛光的商业产品那样的光泽，这对业务负责人来说是个问题。
- en: 'Don’t get me wrong: LLMs are the best thing in AI since GPU-accelerated training,
    but they should be a tool of last resort, not a first dip of the toe in the enterprise
    AI pool.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 别误解我的意思：LLMs 是自 GPU 加速训练以来 AI 中最棒的东西，但它们应该是最后的手段，而不是在企业 AI 领域中首次尝试的工具。
- en: '![](../Images/82f7477b2193751b3997054be184aa65.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/82f7477b2193751b3997054be184aa65.png)'
- en: Photo by [Pixabay](https://www.pexels.com/photo/abandoned-broken-cabinets-demolished-206829/)
    on Pexels.com
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 [Pixabay](https://www.pexels.com/photo/abandoned-broken-cabinets-demolished-206829/)  见于
    Pexels.com
- en: “Software gets slower faster than hardware gets faster” is an old adage in computer
    science. It’s easy to bloat some software, as it’s usually easier to add modules
    to a piece of code than remove some.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: “软件变慢的速度比硬件变快的速度快”是计算机科学中的一个古老谚语。软件容易膨胀，因为通常添加模块比删除模块要容易。
- en: When it comes to AI, the growth of models (from machine learning models to deep
    neural networks, to LSTMs, to pre-trained CNNs, to now transformers) is following
    a similar path. Although the case for using best-in-class technology makes sense,
    there are some situations where asymptotic gains are just diminishing returns
    if the total cost of ownership exceeds any identified benefit.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AI 方面，从机器学习模型到深度神经网络，再到 LSTM、预训练 CNNs 以及现在的 Transformers，模型的增长遵循了类似的路径。虽然使用顶级技术是合理的，但在某些情况下，如果总拥有成本超过任何已识别的收益，渐近收益就会变成递减回报。
- en: 'In our conversations with clients, an eerily familiar pattern is re-emerging:
    the same execs that are pushing for ChatGPT clones today are the ones that were
    adamant about chatbots a few years ago. It’s an easy play to get a demonstrable
    win without linking it to enterprise value or requiring one to think about its
    justification. Their religiosity behind “you just don’t see the value yet" is
    a lazy trope at best, and at worse a resource sink turned corporate liability.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在与客户的对话中，一个诡异的熟悉模式正在重新出现：那些今天推动 ChatGPT 克隆的高管，几年前对聊天机器人也是态度坚决的。这是一个容易取得可证明胜利的手段，而无需将其与企业价值关联或考虑其正当性。他们对于“你只是不看到价值”的宗教式坚持，充其量只是懒惰的陈词滥调，最坏的情况则是一个资源浪费变成企业负担。
- en: A lot of issues arise in these deployments not in the projects’ rationale or
    in their feasibility, but around the justification as to why starting off with
    the most complex piece of technology ever developed by mankind is a valid first
    option for improving your next quarter by 10%.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些部署中出现的许多问题并不在于项目的理由或可行性，而是在于为什么从人类开发的最复杂技术中选择作为改善下一个季度业绩的有效首选的正当性。
- en: AI is not fairy dust; it creates value in its relationship with data, context,
    and inference validity. Hope and prayer are usually not valid strategies when
    it comes to technical debt. American football games are won with strategy and
    execution, not with Hail Mary passes.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: AI 不是魔法粉；它在与数据、上下文和推断有效性的关系中创造价值。希望和祈祷通常不是应对技术债务的有效策略。美国足球比赛的胜利来自于战略和执行，而不是“绝望传球”。
- en: My Bias
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我的偏见
- en: As an engineer, my concerns are about deployment feasibility, total cost of
    ownership, and value for money. Our clients trust us to be transparent adjudicators
    of new technologies and their applications within our clients’ organizations.
    Deployment risks need to be evaluated against business upside and ROI. Implementing
    a technology simply because it is à la mode usually triggers numerous alarms,
    and rightly so.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名工程师，我关注的是部署的可行性、总拥有成本以及性价比。我们的客户信任我们成为新技术及其在客户组织中的应用的透明裁决者。部署风险需要与商业回报和投资回报率进行评估。仅仅因为一项技术流行就实施它，通常会引发许多警报，这也是有道理的。
- en: It’s not that we have an issue (whether ethical or economical) with LLMs — we
    love technology. We have a track record of giving the [Rorschach test to pre-trained
    models](https://medium.com/towards-data-science/rorschach-tests-for-deep-learning-image-classifiers-68c019fcc9a9),
    building a [horoscope trading bot](/silly-stock-trading-on-onepanel-io-gpus-51cde1772bd1),
    and even creating an emergency party button with disco balls. Technology is cool.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对 LLMs 并没有（无论是伦理的还是经济的）问题——我们热爱技术。我们有给 [预训练模型做罗夏测试](https://medium.com/towards-data-science/rorschach-tests-for-deep-learning-image-classifiers-68c019fcc9a9)
    的记录，构建了一个 [星座交易机器人](/silly-stock-trading-on-onepanel-io-gpus-51cde1772bd1)，甚至创建了一个带有迪斯科球的紧急聚会按钮。技术很酷。
- en: However, I must insist that technology will not solve your problems if you don’t
    know what your problems actually are. Compounding that lack of visibility are
    the engineering challenges associated with LLMs means that every typical project
    risk is now an existential crisis against delivery.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我必须坚持，如果你不知道你的问题是什么，技术将无法解决你的问题。更糟糕的是，与 LLMs 相关的工程挑战意味着每个典型项目风险现在都是交付的生存危机。
- en: What Success Looks Like
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 成功的样子
- en: 'In all our years of running our [AI consultancy](https://www.lemay.ai/), the
    biggest driver of AI adoption wins is clear measures of success. This means:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们经营[AI咨询公司](https://www.lemay.ai/)的这些年里，AI采纳成功的最大驱动因素是明确的成功衡量标准。这意味着：
- en: The business context has been clarified with KPIs;
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 业务背景已经通过KPI明确；
- en: The requirements of the project have been established; and
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 项目的需求已经确定；
- en: The delivery of the project has established goals.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 项目的交付已经设定了目标。
- en: Quality management systems, a natural yardstick to compare your machine learning
    projects against, require traceability between established requirements and verification/validation
    and new management techniques call for Objective/Key-Result (OKR) task assignments.
    Expectations surrounding an AI deployment should equally be evaluated against
    measurable and objective success metrics.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 质量管理系统，作为比较您的机器学习项目的自然尺度，需要在已建立的需求与验证/确认之间保持可追溯性，而新的管理技术则要求进行目标/关键结果（OKR）任务分配。围绕AI部署的期望也应根据可测量和客观的成功指标进行评估。
- en: Costs Without Justifications
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 未提供理由的成本
- en: Especially with LLMs, the AI drive over the last few years has had a series
    of push-and-pull forces between elective projects and projects of necessity. Elective
    projects are fun and turn into cool stories at the proverbial water cooler; projects
    of necessity are the monochrome suits that get the job done in the backroom. Which
    one would you rather have during market uncertainty?
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是对于LLM，近年来AI推动的项目经历了自愿项目和必要项目之间的推拉力量。自愿项目有趣，并在传说中的饮水机旁成为有趣的故事；必要项目则是完成任务的单色西装。你在市场不确定性时更愿意拥有哪一种？
- en: Good AI, just like good design, should be invisible, not the centerpiece.
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 优秀的AI，就像优秀的设计一样，应当是隐形的，而非焦点。
- en: So Many Options Before LLMs
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在LLM之前的众多选择
- en: Before even considering generative AI, the older families of transformer-based
    models and pipelines can get you equivalent business outcomes without breaking
    the bank.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑生成型AI之前，较老的基于变压器的模型和流程能够在不花费大量资金的情况下获得相同的商业结果。
- en: Most use cases are knowledge bases, historical analysis, and insights generation,
    so let’s see what alternative approaches we can find.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数用例是知识库、历史分析和洞察生成，因此让我们看看可以找到哪些替代方法。
- en: Navigating your data
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导航你的数据
- en: 'In the last few years, two technologies have made intelligent text search a
    breeze: sentence embeddings and vector databases.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年里，有两项技术使智能文本搜索变得轻而易举：句子嵌入和向量数据库。
- en: Sentence (or document) embeddings have truly been a differentiator since the
    last few word- or subword-embedding technologies. Awareness of word order (thanks
    to positional encoding) creates much more comprehension within nuances and has
    incredible complexity navigation. Complex sentence structures, even documents,
    can reliably be vectorized, clustered, and compared.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 自从最后几种词嵌入或子词嵌入技术以来，句子（或文档）嵌入确实成为了一个区分因素。对词序的意识（得益于位置编码）在细微差别中创造了更多的理解，并具有令人难以置信的复杂性导航。复杂的句子结构，甚至文档，可以可靠地向量化、聚类和比较。
- en: Vector databases, many of which are comfortably open-source (such as [Vald](https://vald.vdaas.org/)
    and [Weaviate](https://weaviate.io/)) already include self-optimization and approximate-nearest
    search right out of the box.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 向量数据库，许多是舒适的开源（例如[Vald](https://vald.vdaas.org/)和[Weaviate](https://weaviate.io/)），已经包含了开箱即用的自我优化和近似最近邻搜索。
- en: 'The number of applications in the business context of this simple model is
    dizzying: you now have a mini-search engine that can retrieve historical RFP sentences
    that are the most similar to your latest proposal, or even find and organize the
    relevant documents needed for a contract.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简单模型的商业背景下，应用数量令人眼花缭乱：你现在拥有一个迷你搜索引擎，可以检索与您最新提案最相似的历史RFP句子，甚至可以查找和组织合同所需的相关文件。
- en: 'The advantage of this approach is you avoid LLM hallucinations: ranked results
    provide contextual value first, meaning that you don’t need to dig beyond the
    first few results for your answer. Either you have a direct answer in front of
    you or you don’t. This is not as reassuring as the cajoling pace of a prompted
    response, the information is extremely accurate, and even the absence of worthwhile
    results is an indication of the internal state of affairs within your team.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的优势在于，你能够避免LLM的幻觉：排名结果首先提供了上下文价值，意味着你不需要深入研究前几个答案之外。要么你面前直接有一个答案，要么就没有。尽管这不如提示性反应的舒缓步调令人放心，信息却极为精准，即使没有有价值的结果，也可以体现出团队内部状态的迹象。
- en: '*Note: you don’t even need a VD to gain value from similarity searches. A flat
    file with cosine similarity is actually fast enough on a multi-core system to
    be usable in an enterprise setting. If you want to try it yourself, I recommend
    converting all your documents to Markdown and splitting the text between headers.
    Congratulations, you now have your mini-search engine.*'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '*注：你甚至不需要VD来从相似搜索中获取价值。在多核系统上，带有余弦相似度的平面文件实际上足够快速，在企业环境中可用。如果你想亲自尝试，请将所有文档转换为Markdown，并在标题之间分割文本。恭喜，你现在有了你的小型搜索引擎。*'
- en: Before LLMs (which is a bit of a misnomer; it seems to include everything and
    anything that generates text), the NLP world was abuzz with various applications
    and well-defined solution patterns. (Take a look at the NLP section of [Papers
    With Code](https://paperswithcode.com/area/natural-language-processing) for examples.)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLMs之前（这有点名不副实；它似乎包含了生成文本的一切和所有），NLP世界充斥着各种应用和明确定义的解决方案模式。（查看[Papers With Code](https://paperswithcode.com/area/natural-language-processing)的NLP部分作为例子。）
- en: Building a sentence or document classifier is still a tried and true approach
    to organizing data; not least of which is the data cleanup process itself which
    forces the organization to recognize its half-empty databases.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个句子或文档分类器仍然是组织数据的一种可靠方法；其中不乏强制组织认识其半空数据库的数据清理过程。
- en: Whatever Happened to Basic Data Hygiene?
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基础数据卫生到底发生了什么？
- en: 'I cannot stress this enough: data will solve your AI problems; AI will not
    solve your data problems.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我无法再强调了：数据将解决你的AI问题；AI不会解决你的数据问题。
- en: I have [written at length](https://medium.com/towards-data-science/how-does-artificial-intelligence-create-value-bec14c785b40)
    about the relationship between data and AI and value creation, and how AI not
    only generates insights but helps with cleaning up the cobweb-filled digital archives.
    In a business context, it’s natural to have inertia due to processes and historical
    culture. This fog of war is due to the sheer number of individual relationships
    between people to accomplish vision and mission success.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我曾[详细写过](https://medium.com/towards-data-science/how-does-artificial-intelligence-create-value-bec14c785b40)关于数据与AI的关系以及价值创造，AI不仅生成见解，还有助于清理布满蜘蛛网的数字档案。在商业环境中，由于流程和历史文化，产生惯性是很自然的。这种战争迷雾源于个人之间关系的巨大数量，以实现愿景和使命的成功。
- en: In these processes, however, incomplete forms and missing reports are expected
    findings. The energy shouldn't go into skipping over those, it should go into
    properly filing them.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在这些过程中，预计会发现不完整的表单和缺失的报告。精力不应该用来跳过这些问题，而应该用来正确地归档它们。
- en: '![](../Images/7782eda6beb3468270470ac46d0d8344.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7782eda6beb3468270470ac46d0d8344.png)'
- en: Image by [G.C.](https://pixabay.com/users/garten-gg-201217/) from [Pixabay](https://pixabay.com/)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[G.C.](https://pixabay.com/users/garten-gg-201217/)提供，来自[Pixabay](https://pixabay.com/)。
- en: Still, LLMs Are the Future
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 然而，LLMs 是未来。
- en: The key takeaway is that companies new to AI adoption should, under most circumstances,
    walk before they run. Successful project delivery while saving money is an all-around
    solid strategy.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 关键的要点是，对于刚开始采用AI的公司而言，大多数情况下，先稳扎稳打比冒进更为明智。成功的项目交付能够节省资金，是一种全面稳固的策略。
- en: LLMs have an otherworldly ability to navigate complex ideas and cleanly summarize
    them in a fraction of a second, but most news articles reference the best-case
    scenarios, not the total amount of effort to get there. Just like social media,
    the reality is often deceiving. If it looks effortless, it probably wasn't.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs有着超凡的能力，可以处理复杂的思想，并在几秒钟内干净地总结它们，但大多数新闻文章只引用最佳案例，而不是达到这一点所需的总体努力量。就像社交媒体一样，现实往往是欺骗性的。如果看起来毫不费力，那可能并非如此。
- en: I’m not making a case against enterprise LLMs; I’m making a case against enterprise
    LLMs as a first AI project.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我并不是在反对企业级LLM；我在反对将企业级LLM作为首个AI项目。
- en: Other articles you may enjoy
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 您可能会喜欢的其他文章
- en: '[How We Won our First Government AI Project](https://medium.com/towards-data-science/how-we-won-our-first-government-ai-project-8c67e58c22f0)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[我们如何赢得第一个政府AI项目](https://medium.com/towards-data-science/how-we-won-our-first-government-ai-project-8c67e58c22f0)'
- en: '[Interpreting the Business Considerations of MLOps](https://medium.com/towards-data-science/interpreting-the-business-considerations-of-mlops-f32613c4bcb4)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[解读MLOps的商业考虑](https://medium.com/towards-data-science/interpreting-the-business-considerations-of-mlops-f32613c4bcb4)'
- en: '[PyTorch vs. TensorFlow for Transformer-Based NLP Applications](/pytorch-vs-tensorflow-for-transformer-based-nlp-applications-b851bdbf229a)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch与TensorFlow在基于Transformer的NLP应用中的比较](/pytorch-vs-tensorflow-for-transformer-based-nlp-applications-b851bdbf229a)'
- en: '[MLOps for Batch Processing: Running Airflow on GPUs](/mlops-for-batch-processing-running-airflow-on-gpus-dc94367869c6)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于批处理的MLOps：在GPU上运行Airflow](/mlops-for-batch-processing-running-airflow-on-gpus-dc94367869c6)'
- en: '[Dataset Biases: Institutionalized Discrimination or Adequate Transparency?](/dataset-biases-institutionalized-discrimination-or-adequate-transparency-ae4119e2a65c)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据集偏差：制度化歧视还是充分透明？](/dataset-biases-institutionalized-discrimination-or-adequate-transparency-ae4119e2a65c)'
- en: '*If you have additional questions about this article or our AI consulting,
    feel free to reach out via* [***LinkedIn***](https://www.linkedin.com/in/mnlemay/)*or
    by* [***email***](mailto:matt@lemay.ai)*.*'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果您对本文或我们的AI咨询有额外的问题，请随时通过* [***LinkedIn***](https://www.linkedin.com/in/mnlemay/)*或*
    [***电子邮件***](mailto:matt@lemay.ai)*联系我们。*'
- en: -Matt.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: -Matt.
