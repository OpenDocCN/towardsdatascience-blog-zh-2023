- en: The Case Against Enterprise LLMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-case-against-enterprise-llms-43795a0db501?source=collection_archive---------2-----------------------#2023-04-29](https://towardsdatascience.com/the-case-against-enterprise-llms-43795a0db501?source=collection_archive---------2-----------------------#2023-04-29)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Opinion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A sober perspective as to why boring is best, even for AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@lsci?source=post_page-----43795a0db501--------------------------------)[![Mathieu
    Lemay](../Images/39db2877c94829bef1d6642daf3ccecb.png)](https://medium.com/@lsci?source=post_page-----43795a0db501--------------------------------)[](https://towardsdatascience.com/?source=post_page-----43795a0db501--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----43795a0db501--------------------------------)
    [Mathieu Lemay](https://medium.com/@lsci?source=post_page-----43795a0db501--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff84a70d8f74&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-case-against-enterprise-llms-43795a0db501&user=Mathieu+Lemay&userId=f84a70d8f74&source=post_page-f84a70d8f74----43795a0db501---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----43795a0db501--------------------------------)
    ·6 min read·Apr 29, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F43795a0db501&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-case-against-enterprise-llms-43795a0db501&user=Mathieu+Lemay&userId=f84a70d8f74&source=-----43795a0db501---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F43795a0db501&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-case-against-enterprise-llms-43795a0db501&source=-----43795a0db501---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: Over the last few weeks, we’ve had a trove of custom LLM requests from clients
    and partners. This excitement, although warranted, is based on tech news inundation,
    not on getting a fundamental corporate advantage.
  prefs: []
  type: TYPE_NORMAL
- en: LLMs, even though they are not conceptually far off from most transformer-based
    training pipelines, require much more complex machinery to fine-tune and operate
    smoothly in a corporate setting. All the ones we already tested and deployed for
    clients are good, but they don’t have the same gloss as polished commercial products,
    which is an issue with business leads.
  prefs: []
  type: TYPE_NORMAL
- en: 'Don’t get me wrong: LLMs are the best thing in AI since GPU-accelerated training,
    but they should be a tool of last resort, not a first dip of the toe in the enterprise
    AI pool.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/82f7477b2193751b3997054be184aa65.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Pixabay](https://www.pexels.com/photo/abandoned-broken-cabinets-demolished-206829/)
    on Pexels.com
  prefs: []
  type: TYPE_NORMAL
- en: “Software gets slower faster than hardware gets faster” is an old adage in computer
    science. It’s easy to bloat some software, as it’s usually easier to add modules
    to a piece of code than remove some.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to AI, the growth of models (from machine learning models to deep
    neural networks, to LSTMs, to pre-trained CNNs, to now transformers) is following
    a similar path. Although the case for using best-in-class technology makes sense,
    there are some situations where asymptotic gains are just diminishing returns
    if the total cost of ownership exceeds any identified benefit.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our conversations with clients, an eerily familiar pattern is re-emerging:
    the same execs that are pushing for ChatGPT clones today are the ones that were
    adamant about chatbots a few years ago. It’s an easy play to get a demonstrable
    win without linking it to enterprise value or requiring one to think about its
    justification. Their religiosity behind “you just don’t see the value yet" is
    a lazy trope at best, and at worse a resource sink turned corporate liability.'
  prefs: []
  type: TYPE_NORMAL
- en: A lot of issues arise in these deployments not in the projects’ rationale or
    in their feasibility, but around the justification as to why starting off with
    the most complex piece of technology ever developed by mankind is a valid first
    option for improving your next quarter by 10%.
  prefs: []
  type: TYPE_NORMAL
- en: AI is not fairy dust; it creates value in its relationship with data, context,
    and inference validity. Hope and prayer are usually not valid strategies when
    it comes to technical debt. American football games are won with strategy and
    execution, not with Hail Mary passes.
  prefs: []
  type: TYPE_NORMAL
- en: My Bias
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As an engineer, my concerns are about deployment feasibility, total cost of
    ownership, and value for money. Our clients trust us to be transparent adjudicators
    of new technologies and their applications within our clients’ organizations.
    Deployment risks need to be evaluated against business upside and ROI. Implementing
    a technology simply because it is à la mode usually triggers numerous alarms,
    and rightly so.
  prefs: []
  type: TYPE_NORMAL
- en: It’s not that we have an issue (whether ethical or economical) with LLMs — we
    love technology. We have a track record of giving the [Rorschach test to pre-trained
    models](https://medium.com/towards-data-science/rorschach-tests-for-deep-learning-image-classifiers-68c019fcc9a9),
    building a [horoscope trading bot](/silly-stock-trading-on-onepanel-io-gpus-51cde1772bd1),
    and even creating an emergency party button with disco balls. Technology is cool.
  prefs: []
  type: TYPE_NORMAL
- en: However, I must insist that technology will not solve your problems if you don’t
    know what your problems actually are. Compounding that lack of visibility are
    the engineering challenges associated with LLMs means that every typical project
    risk is now an existential crisis against delivery.
  prefs: []
  type: TYPE_NORMAL
- en: What Success Looks Like
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In all our years of running our [AI consultancy](https://www.lemay.ai/), the
    biggest driver of AI adoption wins is clear measures of success. This means:'
  prefs: []
  type: TYPE_NORMAL
- en: The business context has been clarified with KPIs;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The requirements of the project have been established; and
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The delivery of the project has established goals.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quality management systems, a natural yardstick to compare your machine learning
    projects against, require traceability between established requirements and verification/validation
    and new management techniques call for Objective/Key-Result (OKR) task assignments.
    Expectations surrounding an AI deployment should equally be evaluated against
    measurable and objective success metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Costs Without Justifications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Especially with LLMs, the AI drive over the last few years has had a series
    of push-and-pull forces between elective projects and projects of necessity. Elective
    projects are fun and turn into cool stories at the proverbial water cooler; projects
    of necessity are the monochrome suits that get the job done in the backroom. Which
    one would you rather have during market uncertainty?
  prefs: []
  type: TYPE_NORMAL
- en: Good AI, just like good design, should be invisible, not the centerpiece.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: So Many Options Before LLMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before even considering generative AI, the older families of transformer-based
    models and pipelines can get you equivalent business outcomes without breaking
    the bank.
  prefs: []
  type: TYPE_NORMAL
- en: Most use cases are knowledge bases, historical analysis, and insights generation,
    so let’s see what alternative approaches we can find.
  prefs: []
  type: TYPE_NORMAL
- en: Navigating your data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the last few years, two technologies have made intelligent text search a
    breeze: sentence embeddings and vector databases.'
  prefs: []
  type: TYPE_NORMAL
- en: Sentence (or document) embeddings have truly been a differentiator since the
    last few word- or subword-embedding technologies. Awareness of word order (thanks
    to positional encoding) creates much more comprehension within nuances and has
    incredible complexity navigation. Complex sentence structures, even documents,
    can reliably be vectorized, clustered, and compared.
  prefs: []
  type: TYPE_NORMAL
- en: Vector databases, many of which are comfortably open-source (such as [Vald](https://vald.vdaas.org/)
    and [Weaviate](https://weaviate.io/)) already include self-optimization and approximate-nearest
    search right out of the box.
  prefs: []
  type: TYPE_NORMAL
- en: 'The number of applications in the business context of this simple model is
    dizzying: you now have a mini-search engine that can retrieve historical RFP sentences
    that are the most similar to your latest proposal, or even find and organize the
    relevant documents needed for a contract.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The advantage of this approach is you avoid LLM hallucinations: ranked results
    provide contextual value first, meaning that you don’t need to dig beyond the
    first few results for your answer. Either you have a direct answer in front of
    you or you don’t. This is not as reassuring as the cajoling pace of a prompted
    response, the information is extremely accurate, and even the absence of worthwhile
    results is an indication of the internal state of affairs within your team.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: you don’t even need a VD to gain value from similarity searches. A flat
    file with cosine similarity is actually fast enough on a multi-core system to
    be usable in an enterprise setting. If you want to try it yourself, I recommend
    converting all your documents to Markdown and splitting the text between headers.
    Congratulations, you now have your mini-search engine.*'
  prefs: []
  type: TYPE_NORMAL
- en: Before LLMs (which is a bit of a misnomer; it seems to include everything and
    anything that generates text), the NLP world was abuzz with various applications
    and well-defined solution patterns. (Take a look at the NLP section of [Papers
    With Code](https://paperswithcode.com/area/natural-language-processing) for examples.)
  prefs: []
  type: TYPE_NORMAL
- en: Building a sentence or document classifier is still a tried and true approach
    to organizing data; not least of which is the data cleanup process itself which
    forces the organization to recognize its half-empty databases.
  prefs: []
  type: TYPE_NORMAL
- en: Whatever Happened to Basic Data Hygiene?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I cannot stress this enough: data will solve your AI problems; AI will not
    solve your data problems.'
  prefs: []
  type: TYPE_NORMAL
- en: I have [written at length](https://medium.com/towards-data-science/how-does-artificial-intelligence-create-value-bec14c785b40)
    about the relationship between data and AI and value creation, and how AI not
    only generates insights but helps with cleaning up the cobweb-filled digital archives.
    In a business context, it’s natural to have inertia due to processes and historical
    culture. This fog of war is due to the sheer number of individual relationships
    between people to accomplish vision and mission success.
  prefs: []
  type: TYPE_NORMAL
- en: In these processes, however, incomplete forms and missing reports are expected
    findings. The energy shouldn't go into skipping over those, it should go into
    properly filing them.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7782eda6beb3468270470ac46d0d8344.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [G.C.](https://pixabay.com/users/garten-gg-201217/) from [Pixabay](https://pixabay.com/)
  prefs: []
  type: TYPE_NORMAL
- en: Still, LLMs Are the Future
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The key takeaway is that companies new to AI adoption should, under most circumstances,
    walk before they run. Successful project delivery while saving money is an all-around
    solid strategy.
  prefs: []
  type: TYPE_NORMAL
- en: LLMs have an otherworldly ability to navigate complex ideas and cleanly summarize
    them in a fraction of a second, but most news articles reference the best-case
    scenarios, not the total amount of effort to get there. Just like social media,
    the reality is often deceiving. If it looks effortless, it probably wasn't.
  prefs: []
  type: TYPE_NORMAL
- en: I’m not making a case against enterprise LLMs; I’m making a case against enterprise
    LLMs as a first AI project.
  prefs: []
  type: TYPE_NORMAL
- en: Other articles you may enjoy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[How We Won our First Government AI Project](https://medium.com/towards-data-science/how-we-won-our-first-government-ai-project-8c67e58c22f0)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Interpreting the Business Considerations of MLOps](https://medium.com/towards-data-science/interpreting-the-business-considerations-of-mlops-f32613c4bcb4)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PyTorch vs. TensorFlow for Transformer-Based NLP Applications](/pytorch-vs-tensorflow-for-transformer-based-nlp-applications-b851bdbf229a)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MLOps for Batch Processing: Running Airflow on GPUs](/mlops-for-batch-processing-running-airflow-on-gpus-dc94367869c6)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Dataset Biases: Institutionalized Discrimination or Adequate Transparency?](/dataset-biases-institutionalized-discrimination-or-adequate-transparency-ae4119e2a65c)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*If you have additional questions about this article or our AI consulting,
    feel free to reach out via* [***LinkedIn***](https://www.linkedin.com/in/mnlemay/)*or
    by* [***email***](mailto:matt@lemay.ai)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: -Matt.
  prefs: []
  type: TYPE_NORMAL
