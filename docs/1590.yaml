- en: Fill-in-the-blanks Self-Supervision in NLP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/fill-in-the-blanks-self-supervision-in-nlp-f0afb16dc7fd?source=collection_archive---------16-----------------------#2023-05-10](https://towardsdatascience.com/fill-in-the-blanks-self-supervision-in-nlp-f0afb16dc7fd?source=collection_archive---------16-----------------------#2023-05-10)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Why it's powerful and how to solve it
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://jagota-arun.medium.com/?source=post_page-----f0afb16dc7fd--------------------------------)[![Arun
    Jagota](../Images/3c3eb142f671b5fb933c2826d8ed78d9.png)](https://jagota-arun.medium.com/?source=post_page-----f0afb16dc7fd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f0afb16dc7fd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f0afb16dc7fd--------------------------------)
    [Arun Jagota](https://jagota-arun.medium.com/?source=post_page-----f0afb16dc7fd--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fef9ed921edad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffill-in-the-blanks-self-supervision-in-nlp-f0afb16dc7fd&user=Arun+Jagota&userId=ef9ed921edad&source=post_page-ef9ed921edad----f0afb16dc7fd---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f0afb16dc7fd--------------------------------)
    ·14 min read·May 10, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff0afb16dc7fd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffill-in-the-blanks-self-supervision-in-nlp-f0afb16dc7fd&user=Arun+Jagota&userId=ef9ed921edad&source=-----f0afb16dc7fd---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff0afb16dc7fd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffill-in-the-blanks-self-supervision-in-nlp-f0afb16dc7fd&source=-----f0afb16dc7fd---------------------bookmark_footer-----------)![](../Images/03be7b5832a9d134961e51b08dd7a5a7.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Patrick Tomasso](https://unsplash.com/@impatrickt?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/Oaqk7qqNh_c?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: 'Predicting the next word has a long and successful history in language modeling,
    most recently in large language models. It leverages the existence of huge corpora
    of text: Wikipedia, public web pages strewn over the globe, and others. It is
    more powerful than other types of unsupervised learning on these corpora, as the
    learning is supervised. Furthermore, because it is self-supervised, no human effort
    is needed to create labeled data.'
  prefs: []
  type: TYPE_NORMAL
- en: Consider
  prefs: []
  type: TYPE_NORMAL
- en: exposure to sunlight causes __
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: From a rich enough corpus of English sentences, machine learning should be able
    to learn a language model that can fill in the blanks sensibly, in this case with
    the term “skin cancer”.
  prefs: []
  type: TYPE_NORMAL
- en: Why do we call this supervision? Because we start from a complete sequence of
    tokens, blur out the last word, ask our model to predict what it is, reward it
    if it predicts correctly, and penalize it if it gets it wrong. So this is supervised
    learning.
  prefs: []
  type: TYPE_NORMAL
- en: Recently, this self-supervision approach has been extended in a simple yet powerful
    way. Specifically, the blanks to be filled in may be anywhere in the text. In
    view of this, we might call it the text reconstruction task, not merely the text
    completion task.
  prefs: []
  type: TYPE_NORMAL
