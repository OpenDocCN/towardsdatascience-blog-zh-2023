- en: Enhanced Large Language Models as Reasoning Engines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/enhanced-large-language-models-as-reasoning-engines-582bff782113?source=collection_archive---------3-----------------------#2023-12-23](https://towardsdatascience.com/enhanced-large-language-models-as-reasoning-engines-582bff782113?source=collection_archive---------3-----------------------#2023-12-23)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@alcarazanthony1?source=post_page-----582bff782113--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----582bff782113--------------------------------)[](https://towardsdatascience.com/?source=post_page-----582bff782113--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----582bff782113--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----582bff782113--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F30bc9ffd2f4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fenhanced-large-language-models-as-reasoning-engines-582bff782113&user=Anthony+Alcaraz&userId=30bc9ffd2f4b&source=post_page-30bc9ffd2f4b----582bff782113---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----582bff782113--------------------------------)
    ·12 min read·Dec 23, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F582bff782113&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fenhanced-large-language-models-as-reasoning-engines-582bff782113&user=Anthony+Alcaraz&userId=30bc9ffd2f4b&source=-----582bff782113---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F582bff782113&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fenhanced-large-language-models-as-reasoning-engines-582bff782113&source=-----582bff782113---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Artificial intelligence software was used to enhance the grammar, flow, and
    readability of this article’s text.*'
  prefs: []
  type: TYPE_NORMAL
- en: The recent exponential advances in natural language processing capabilities
    from large language models (LLMs) have stirred tremendous excitement about their
    potential to achieve human-level intelligence. Their ability to produce remarkably
    coherent text and engage in dialogue after exposure to vast datasets seems to
    point towards flexible, general purpose reasoning skills.
  prefs: []
  type: TYPE_NORMAL
- en: However, a growing chorus of voices urges caution against unchecked optimism
    by highlighting fundamental blindspots that limit neural approaches. LLMs still
    frequently make basic logical and mathematical mistakes that reveal a lack of
    systematicity behind their responses. Their knowledge remains intrinsically statistical
    without deeper semantic structures.
  prefs: []
  type: TYPE_NORMAL
- en: More complex reasoning tasks further expose these limitations. LLMs struggle
    with causal, counterfactual, and compositional reasoning challenges that require
    going beyond surface pattern recognition. Unlike humans who learn abstract schemas
    to flexibly recombine modular concepts, neural networks memorize correlations
    between co-occurring terms. This results in brittle generalization outside narrow
    training distributions.
  prefs: []
  type: TYPE_NORMAL
- en: The chasm underscores how human cognition employs structured symbolic representations
    to enable systematic composability and causal models for conceptualizing dynamics.
    We reason by manipulating…
  prefs: []
  type: TYPE_NORMAL
