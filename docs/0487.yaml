- en: 'Optimization, Newton’s Method, & Profit Maximization: Part 2— Constrained Optimization
    Theory'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化、牛顿法与利润最大化：第二部分——约束优化理论
- en: 原文：[https://towardsdatascience.com/optimization-newtons-method-profit-maximization-part-2-constrained-optimization-theory-dc18613c5770?source=collection_archive---------9-----------------------#2023-02-02](https://towardsdatascience.com/optimization-newtons-method-profit-maximization-part-2-constrained-optimization-theory-dc18613c5770?source=collection_archive---------9-----------------------#2023-02-02)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/optimization-newtons-method-profit-maximization-part-2-constrained-optimization-theory-dc18613c5770?source=collection_archive---------9-----------------------#2023-02-02](https://towardsdatascience.com/optimization-newtons-method-profit-maximization-part-2-constrained-optimization-theory-dc18613c5770?source=collection_archive---------9-----------------------#2023-02-02)
- en: '![](../Images/d3d6794ce774945474e8adef3314e157.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d3d6794ce774945474e8adef3314e157.png)'
- en: All Images by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的所有图片
- en: Learn how to extend Newton’s Method to and solve constrained optimization problems
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解如何扩展牛顿法并解决约束优化问题
- en: '[](https://medium.com/@jakepenzak?source=post_page-----dc18613c5770--------------------------------)[![Jacob
    Pieniazek](../Images/2d9c6295d39fcaaec4e62f11c359cb29.png)](https://medium.com/@jakepenzak?source=post_page-----dc18613c5770--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dc18613c5770--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dc18613c5770--------------------------------)
    [Jacob Pieniazek](https://medium.com/@jakepenzak?source=post_page-----dc18613c5770--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@jakepenzak?source=post_page-----dc18613c5770--------------------------------)[![Jacob
    Pieniazek](../Images/2d9c6295d39fcaaec4e62f11c359cb29.png)](https://medium.com/@jakepenzak?source=post_page-----dc18613c5770--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dc18613c5770--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dc18613c5770--------------------------------)
    [Jacob Pieniazek](https://medium.com/@jakepenzak?source=post_page-----dc18613c5770--------------------------------)'
- en: ·
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6f0948d99b1c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimization-newtons-method-profit-maximization-part-2-constrained-optimization-theory-dc18613c5770&user=Jacob+Pieniazek&userId=6f0948d99b1c&source=post_page-6f0948d99b1c----dc18613c5770---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----dc18613c5770--------------------------------)
    ·13 min read·Feb 2, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdc18613c5770&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimization-newtons-method-profit-maximization-part-2-constrained-optimization-theory-dc18613c5770&user=Jacob+Pieniazek&userId=6f0948d99b1c&source=-----dc18613c5770---------------------clap_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6f0948d99b1c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimization-newtons-method-profit-maximization-part-2-constrained-optimization-theory-dc18613c5770&user=Jacob+Pieniazek&userId=6f0948d99b1c&source=post_page-6f0948d99b1c----dc18613c5770---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----dc18613c5770--------------------------------)
    ·13分钟阅读·2023年2月2日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdc18613c5770&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimization-newtons-method-profit-maximization-part-2-constrained-optimization-theory-dc18613c5770&user=Jacob+Pieniazek&userId=6f0948d99b1c&source=-----dc18613c5770---------------------clap_footer-----------)'
- en: --
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc18613c5770&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimization-newtons-method-profit-maximization-part-2-constrained-optimization-theory-dc18613c5770&source=-----dc18613c5770---------------------bookmark_footer-----------)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc18613c5770&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimization-newtons-method-profit-maximization-part-2-constrained-optimization-theory-dc18613c5770&source=-----dc18613c5770---------------------bookmark_footer-----------)'
- en: This article is the **2nd** in a 3 part series. In the [1st part](https://medium.com/towards-data-science/optimization-newtons-method-profit-maximization-part-1-basic-optimization-theory-ff7c5f966565),
    we studied basic optimization theory. Now, in pt. 2, we will extend this theory
    to constrained optimization problems. Lastly, in pt. 3, we will apply the optimization
    theory covered, as well as econometric and economic theory, to solve a profit
    maximization problem.
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这篇文章是一个三部分系列中的**第二部分**。在[第一部分](https://medium.com/towards-data-science/optimization-newtons-method-profit-maximization-part-1-basic-optimization-theory-ff7c5f966565)中，我们研究了基本的优化理论。现在，在第二部分中，我们将把这一理论扩展到受限优化问题。最后，在第三部分中，我们将应用所涵盖的优化理论，以及计量经济学和经济理论，来解决一个利润最大化问题。
- en: 'Consider the following problem: You want to determine how much money to invest
    in specific financial instruments to maximize your return on investment. However,
    the problem of simply maximizing your return on investment is too broad and simple
    of an optimization question to ask. By virtue of the simplicity, the solution
    is to just invest *all* of your money in the financial instrument that shows promise
    for highest return. Clearly this is not a good investment strategy; so, how can
    we improve this? *By putting constraints on the investment decisions, our choice
    variables.* For example, we can specify constraints that, to name a couple, 1)
    limit the amount of financial risk we are willing to entertain (see [modern portfolio
    theory](https://en.wikipedia.org/wiki/Modern_portfolio_theory)) or 2) specify
    the amount of our portfolio to be allocated towards each category of financial
    instruments (equity, bonds, derivatives, etc.) — the possibilities are endless.
    Notice how this problem becomes significantly more tractable as we add constraints.
    Despite this simple example, it helps to capture a fundamental motivation of constrained
    optimization:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下问题：你想确定在特定金融工具上投资多少资金以最大化你的投资回报。然而，单纯最大化投资回报的问题过于宽泛和简单。由于其简单性，解决方案就是将*所有*资金投入到回报潜力最高的金融工具中。显然，这不是一个好的投资策略；那么，我们如何改进呢？*通过对投资决策施加约束，我们的选择变量。*
    例如，我们可以指定约束条件，比如 1) 限制我们愿意承担的金融风险量（见[现代投资组合理论](https://en.wikipedia.org/wiki/Modern_portfolio_theory)），或者
    2) 指定我们投资组合中每类金融工具（如股票、债券、衍生品等）的分配比例——可能性无穷无尽。注意，当我们添加约束时，这个问题变得显著更具可处理性。尽管这是一个简单的例子，但它有助于捕捉受限优化的一个基本动机：
- en: The essence of constrained optimization is to provide unconstrained optimization
    problems a sense of tractability and applicability to complex real world problems.
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 受限优化的本质在于为无约束优化问题提供一种适用性和解决复杂现实世界问题的能力。
- en: Constrained optimization is defined as “the process of optimizing an objective
    function with respect to some variables in the presence of constraints on those
    variables.”[1] The process of adding constraints on the variables transforms an
    unconstrained and, perhaps, intractable optimization problem into one which can
    help model and solve a real world problem. However, the addition of constraints
    can turn a simple optimization problem into a problem that is no longer trivial.
    In this post, we will dive into some of the techniques that we can add to our
    toolbox to extend the unconstrained optimization theory, learned in [part 1](https://medium.com/towards-data-science/optimization-newtons-method-profit-maximization-part-1-basic-optimization-theory-ff7c5f966565)
    of this series, to now solve constrained optimization problems.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 受限优化被定义为“在变量受到约束的情况下，对目标函数进行优化的过程。”[1] 添加对变量的约束将一个无约束的、或许是难以处理的优化问题转化为一个有助于建模和解决现实世界问题的问题。然而，添加约束可能将一个简单的优化问题转变为一个不再是微不足道的问题。在这篇文章中，我们将深入探讨一些可以添加到我们工具箱中的技术，以扩展在[第
    1 部分](https://medium.com/towards-data-science/optimization-newtons-method-profit-maximization-part-1-basic-optimization-theory-ff7c5f966565)中学习的无约束优化理论，从而解决受限优化问题。
- en: In [part 1](https://medium.com/towards-data-science/optimization-newtons-method-profit-maximization-part-1-basic-optimization-theory-ff7c5f966565),
    we covered basic optimization theory — including 1) setting up and solving a simple
    single variable optimization problem analytically, 2) iterative optimization schemes
    — namely, gradient descent & Newton’s Method, and 3) implementing Newton’s method
    by hand and in python for a multi-dimensional optimization problem. This article
    is designed to be accessible for those who are already familiar with the content
    covered in [part 1](https://medium.com/towards-data-science/optimization-newtons-method-profit-maximization-part-1-basic-optimization-theory-ff7c5f966565).
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在 [第1部分](https://medium.com/towards-data-science/optimization-newtons-method-profit-maximization-part-1-basic-optimization-theory-ff7c5f966565)中，我们介绍了基本的优化理论——包括
    1) 解析设置和解决一个简单的单变量优化问题，2) 迭代优化方案——即梯度下降法和牛顿法，以及 3) 手动和使用 Python 实现牛顿法用于多维优化问题。本文旨在使那些已经熟悉
    [第1部分](https://medium.com/towards-data-science/optimization-newtons-method-profit-maximization-part-1-basic-optimization-theory-ff7c5f966565)
    中内容的读者能够轻松理解。
- en: Constrained Optimization Basics (& [Part 1](https://medium.com/towards-data-science/optimization-newtons-method-profit-maximization-part-1-basic-optimization-theory-ff7c5f966565)
    Recap)
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 约束优化基础（& [第1部分](https://medium.com/towards-data-science/optimization-newtons-method-profit-maximization-part-1-basic-optimization-theory-ff7c5f966565)
    回顾）
- en: 'A mathematical optimization problem can be formulated abstractly as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 一个数学优化问题可以抽象地表示如下：
- en: '![](../Images/91d0602859b3778af388eb855d77cd2a.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/91d0602859b3778af388eb855d77cd2a.png)'
- en: (1)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: (1)
- en: where we choose real values of the vector **x** that minimize the *objective
    function* *f*(**x**) (or maximize -*f*(**x**)) subject to the *inequality constraints*
    *g*(**x**) and *equality constraints* *h*(**x**). In [part 1](https://medium.com/towards-data-science/optimization-newtons-method-profit-maximization-part-1-basic-optimization-theory-ff7c5f966565),
    we discussed how to solve these problems in the absence of *g*(**x**) and *h*(**x**)
    and now we will introduce these back into our optimization problem. First, let’s
    succinctly recap how to implement Newton’s method for unconstrained problems.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们选择 **x** 的实际值，以最小化 *目标函数* *f*(**x**)（或最大化 -*f*(**x**）），同时满足 *不等式约束* *g*(**x**)
    和 *等式约束* *h*(**x**)。在 [第1部分](https://medium.com/towards-data-science/optimization-newtons-method-profit-maximization-part-1-basic-optimization-theory-ff7c5f966565)
    中，我们讨论了如何在没有 *g*(**x**) 和 *h*(**x**) 的情况下解决这些问题，现在我们将这些约束重新引入到我们的优化问题中。首先，让我们简明扼要地回顾如何实现牛顿法用于无约束问题。
- en: 'Recall that we can approximate the first order necessary condition of a minimum
    using a Taylor Series expansion:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾一下，我们可以使用泰勒级数展开来近似最小值的一阶必要条件：
- en: '![](../Images/f671020420ba3b2e88ede14734e5cb88.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f671020420ba3b2e88ede14734e5cb88.png)'
- en: (2)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: (2)
- en: 'where **H**(**x**)and **∇***f*(**x**) denote the Hessian and gradient of*f*(**x**),
    respectively. Each iterative addition of delta, **Δ,** is an expected better approximation
    of the optimal values **x***. Thus, each iterative step using the NM can be represented
    as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 **H**(**x**) 和 **∇***f*(**x**) 分别表示 **f**(**x**) 的 Hessian 矩阵和梯度。每次迭代增加的
    delta, **Δ,** 是对最优值 **x*** 的预期更好近似。因此，每次使用牛顿法的迭代步骤可以表示如下：
- en: '![](../Images/aeea601b1cde8c66b5fd09c5d76f1710.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aeea601b1cde8c66b5fd09c5d76f1710.png)'
- en: (3) Newton Method Iterative Scheme
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: (3) 牛顿法迭代方案
- en: 'We do this scheme until we reach convergence across one or more of the following
    criteria:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们执行这个方案直到在以下一个或多个标准上达到收敛：
- en: '![](../Images/855991698a9b3c03d179ffcba7c2ef8c.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/855991698a9b3c03d179ffcba7c2ef8c.png)'
- en: (4) Convergence Criteria for Iterative Optimization Schemes
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: (4) 迭代优化方案的收敛标准
- en: 'Putting this into python code, we make use of [SymPy](https://www.sympy.org/en/index.html)
    — a python library for symbolic mathematics — and create generalizable functions
    to compute the gradient, compute the Hessian, and implement Newton’s method for
    an *n*-dimensional function:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 将其转化为 Python 代码，我们使用 [SymPy](https://www.sympy.org/en/index.html) —— 一个用于符号数学的
    Python 库 —— 并创建可泛化的函数来计算梯度、计算 Hessian 矩阵，并实现牛顿法用于 *n* 维函数：
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'And to solve an unconstrained optimization problem, we can run the following
    code:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决无约束优化问题，我们可以运行以下代码：
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'With the corresponding output:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 及其对应的输出：
- en: '![](../Images/e02ab685850059438bb587571f23aa35.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e02ab685850059438bb587571f23aa35.png)'
- en: If all of the material reviewed above feels extremely foreign, then I recommend
    taking a look at [part 1](https://medium.com/towards-data-science/optimization-newtons-method-profit-maximization-part-1-basic-optimization-theory-ff7c5f966565)
    which will dive into everything above in more depth and bring you up to speed!
    Without further ado, let’s dive into implementing constraints in our optimization
    problems.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果上述所有材料感觉非常陌生，那么我建议查看[part 1](https://medium.com/towards-data-science/optimization-newtons-method-profit-maximization-part-1-basic-optimization-theory-ff7c5f966565)，它将更深入地探讨上述内容并帮助你跟上进度！话不多说，让我们深入实施优化问题中的约束。
- en: 'Note: All of the following constrained optimization techniques can and should
    be incorporated w/ gradient descent algorithms when applicable!'
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意：所有以下约束优化技术都可以且应该在适用时与梯度下降算法结合使用！
- en: Solving Constrained Optimization Problems
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 求解带约束的优化问题
- en: As we discussed above there are two possible constraints on an objective function
    — equality and inequality constraints. Note that there are varying methodologies
    out there for dealing with each type of constraint with varying pros and cons.
    See [2] for a further discussion of different methodologies. Nevertheless, we
    will home our focus in on two methodologies, one for equality and one for inequality
    constraints, that I believe are robust in their performance, easy to grasp for
    newcomers, and easily integrated together into one cohesive problem.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们上面讨论的，目标函数可能有两种约束——等式约束和不等式约束。注意，对于每种类型的约束，都有不同的方法，具有不同的优缺点。有关不同方法的进一步讨论，请参见[2]。不过，我们将重点关注两种方法，一种用于等式约束，另一种用于不等式约束，这些方法在性能上可靠，对新手易于理解，并且可以很容易地集成到一个有机的问题中。
- en: '**Equality Constraints — The Lagrangian**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**等式约束 — 拉格朗日**'
- en: 'First, we will address optimization problems with equality constraints in our
    optimization problem. That is, optimization problems that take the form:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将处理带有等式约束的优化问题。即，具有以下形式的优化问题：
- en: '![](../Images/1c3591911df6b1fdfbc9e110bd125a96.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1c3591911df6b1fdfbc9e110bd125a96.png)'
- en: (5)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: (5)
- en: 'Suppose we are working with the Rosenbrock’s Parabolic Valley, as in [part
    1](https://medium.com/towards-data-science/optimization-newtons-method-profit-maximization-part-1-basic-optimization-theory-ff7c5f966565),
    but now with the equality constraint that x² - y = 2:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们正在处理Rosenbrock的抛物谷，如[part 1](https://medium.com/towards-data-science/optimization-newtons-method-profit-maximization-part-1-basic-optimization-theory-ff7c5f966565)中所述，但现在添加了等式约束x²
    - y = 2：
- en: '![](../Images/8432624d0786198013c82b316631ac28.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8432624d0786198013c82b316631ac28.png)'
- en: (6) Rosenbrock’s Parabolic Valley w/ Equality Constraint **(Problem 1)**
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: (6) 带有等式约束的Rosenbrock的抛物谷 **（问题1）**
- en: 'Note that, for simplicity and consistency, the equality constraints should
    be written such that they are equal to zero. Now our optimization problem looks
    like:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，为了简化和一致性，等式约束应写成等于零的形式。现在我们的优化问题看起来像：
- en: '![](../Images/f53819cf3d990f8b3b66a9a4f099f9f1.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f53819cf3d990f8b3b66a9a4f099f9f1.png)'
- en: Rosenbrock’s Parabolic Valley (purple-yellow color map) & Equality Constraint
    Curve (Black)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Rosenbrock的抛物谷（紫黄色色图）和等式约束曲线（黑色）
- en: where the ***feasible region*** of the optimal values lie somewhere ***along***
    the ***intersection*** of the equality constraint curve and our objective function
    above.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，***可行区域***的最优值位于等式约束曲线与我们上面的目标函数的***交点***之一。
- en: 'Joseph-Louis Lagrange developed a method for incorporating an equality constraint
    directly into the objective function — creatingthe ***Lagrangian function***—
    so that traditional approaches using first and second derivates can still be applied.[2][3]
    Formally, the Lagrangian function takes the following form:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 约瑟夫-路易·拉格朗日开发了一种方法，将等式约束直接纳入目标函数中——创建***拉格朗日函数***——以便可以继续应用传统方法使用一阶和二阶导数。[2][3]
    形式上，拉格朗日函数具有以下形式：
- en: '![](../Images/9006bcb26fb988f6e540e010e4406b0e.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9006bcb26fb988f6e540e010e4406b0e.png)'
- en: (7) Formal Definition of Lagrangian Function
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: (7) 拉格朗日函数的正式定义
- en: where *f*(**x**) and *h*(**x**) are the objective function and equality constraints,
    respectively.**Λ** are the ***Lagrange multipliers*** that correspond to each
    equality constraint *j.* The Lagrange multipliers are treated as new choice variables
    in the Lagrangian function. It just so happens that the *necessary conditions*
    for **x*** to be a minimum of the equality constrained problem is that **x***
    corresponds to the stationarity points of the Lagrangian (**x***, **Λ***). That
    is,
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *f*(**x**) 和 *h*(**x**) 分别是目标函数和等式约束。**Λ** 是与每个等式约束 *j* 对应的 ***拉格朗日乘子***。拉格朗日乘子被视为拉格朗日函数中的新选择变量。正好，**x***
    作为等式约束问题的最小值的*必要条件*是 **x*** 对应于拉格朗日函数的驻点 (**x***, **Λ***). 即，
- en: '![](../Images/7e5891acaa9ae389cfef97f4643c8c26.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7e5891acaa9ae389cfef97f4643c8c26.png)'
- en: (8) Lagrangian First Order Conditions
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: (8) 拉格朗日一阶条件
- en: 'For our example above — the equality constrained Rosenbrock’s Parabolic Valley
    (Eq. 1)— we can write our Lagrangian function as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于上述示例——等式约束的Rosenbrock抛物线谷（公式1）——我们可以将拉格朗日函数写为：
- en: '![](../Images/22009a1b32d8186a21a319735d60e285.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/22009a1b32d8186a21a319735d60e285.png)'
- en: (9)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: (9)
- en: We can then solve this Lagrangian using Newton’s method, but now including the
    Lagrange multipliers as additional choice variables.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以使用牛顿法求解这个拉格朗日函数，但现在需要将拉格朗日乘子作为附加选择变量。
- en: '[PRE2]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'With the corresponding output:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 对应的输出为：
- en: '![](../Images/4ff125c962b23c9f672350f9325ec12c.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4ff125c962b23c9f672350f9325ec12c.png)'
- en: One can easily verify that the solution satisfies our equality constraint. And
    there you have it! That wasn’t too bad, right? This method can be extended to
    add any number of equality constraints — just add another Lagrange multiplier.
    Let’s move on now to the incorporation of inequality constraints.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 可以很容易验证解满足我们的等式约束。就这样！这还不算太难，对吧？这种方法可以扩展以添加任何数量的等式约束——只需添加另一个拉格朗日乘子。现在我们继续讨论如何纳入不等式约束。
- en: '**Inequality Constraints — The Logarithmic Barrier Function**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**不等式约束—对数障碍函数**'
- en: 'Now we will address optimization problems with inequality constraints in our
    optimization problem. That is, optimization problems that take the form:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将处理带有不等式约束的优化问题。即，具有如下形式的优化问题：
- en: '![](../Images/58c27b771f787bcae0f5d488a401ed27.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/58c27b771f787bcae0f5d488a401ed27.png)'
- en: (10)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: (10)
- en: 'Suppose, again, we are working with Rosenbrock’s Parabolic Valley but now with
    the inequality constraints x ≤ 0 and y ≥ 3:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 再次假设，我们在处理Rosenbrock的抛物线谷，但现在有不等式约束 x ≤ 0 和 y ≥ 3：
- en: '![](../Images/d59ea38998b5b8c688ae979913d5d93d.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d59ea38998b5b8c688ae979913d5d93d.png)'
- en: (11) Rosenbrock’s Parabolic Valley w/ Inequality Constraint **(Problem 2)**
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: (11) 带有不等式约束的Rosenbrock抛物线谷 **（问题2）**
- en: 'Now our optimization problem looks like:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的优化问题变成了：
- en: '![](../Images/9114ed61ed48e7bb6a35c7a4bce20b19.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9114ed61ed48e7bb6a35c7a4bce20b19.png)'
- en: Rosenbrock’s Parabolic Valley (purple-yellow color map) & Inequality Constraint
    Planes (Black)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Rosenbrock的抛物线谷（紫黄色色彩图）和不等式约束平面（黑色）
- en: where the ***feasible region*** of the optimal values lies in the quadrant bounded
    by the constraints that is marked by the red star.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 最优值的***可行区域***位于由红星标记的约束所界定的象限中。
- en: 'Because these constraints do not have a strict equality, our ability to directly
    include them into the objective function is not as straightforward. However, we
    can get creative — what we can do is augment our objective function to include
    a “barrier” in the objective function that penalizes values of the solution that
    approach the bounds of the inequality constraints. These class of methods are
    known as “interior-point methods” or “barrier methods.”[4][5] Like the Lagrangian
    function, we can transform our original constrained optimization problem into
    an unconstrained optimization problem by incorporating barrier functions (the
    logarithmic barrier function in our case) that can be solved using traditional
    methods— thereby creating the ***barrier function***. Formally, the logarithmic
    barrier function is characterized by:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些约束没有严格的等式，我们无法将它们直接纳入目标函数。然而，我们可以动脑筋——我们可以做的是增强目标函数，在目标函数中加入一个“障碍”，对接近不等式约束边界的解值进行惩罚。这些方法被称为“内点法”或“障碍法”[4][5]。像拉格朗日函数一样，我们可以通过引入障碍函数（在我们这个案例中是对数障碍函数）将原来的约束优化问题转化为无约束优化问题，从而创建***障碍函数***。形式上，对数障碍函数的特点是：
- en: '![](../Images/00ca107eb8bf9a5ca094939980679c6e.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/00ca107eb8bf9a5ca094939980679c6e.png)'
- en: (12) Formal Definition of Logarithmic Barrier Function
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: (12) 对数障碍函数的正式定义
- en: where *ρ* is a small positive scalar — known as the barrier parameter. As *ρ*
    → 0, the solution of the barrier function *B*(**x**,*ρ*) should converge to the
    solution of our original constrained optimization function. Note, the *c*(**x**)
    states that depending on how we formulate our inequality constraints (greater
    than or less than zero) will dictate whether we use the negative or positive of
    that constraint. We know that y=log(x) is undefined for x ≤ 0, thus we need to
    formulate our constraint to always be ≥ 0.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 其中*ρ*是一个小的正标量——称为障碍参数。随着*ρ* → 0，障碍函数*B*(**x**,*ρ*)的解应收敛到我们原始约束优化函数的解。注意，*c*(**x**)表示，根据我们如何制定不等式约束（大于或小于零），将决定我们使用该约束的负值或正值。我们知道y=log(x)在x
    ≤ 0时未定义，因此我们需要将约束制定为始终≥0。
- en: How exactly does the barrier method work, you may ask? To begin with, when using
    the barrier method, we must choose starting values that are in the feasible region.
    As the optimal values approach the “barrier” outlined by the constraint, this
    method relies on the fact that the logarithmic function approaches negative infinity
    as the value approaches zero, thereby penalizing the objective function value.
    As *ρ* → 0, the penalization decreases (see figure directly below) and we converge
    to the solution. However, it is necessary to start with a sufficiently large *ρ*
    so that the penalization is large enough to prevent “jumping” out of the barriers.
    Therefore, the algorithm has one extra loop than Newton’s method alone — namely,
    we choose a starting value *ρ,* optimize the barrier function using Newton’s method,
    then update *ρ* by slowly decreasing it (*ρ* → 0), and repeat until convergence.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问，对数障碍法究竟是如何工作的？首先，在使用障碍法时，我们必须选择位于可行区域的起始值。随着最优值接近由约束定义的“障碍”，该方法依赖于对数函数在值接近零时趋向负无穷的特性，从而惩罚目标函数值。随着*ρ*
    → 0，惩罚减小（见下图），我们逐渐收敛到解。然而，需要从足够大的*ρ*开始，以确保惩罚足够大，防止“跳出”障碍。因此，该算法比牛顿法多了一个额外的循环——即，我们选择一个起始值*ρ*，使用牛顿法优化障碍函数，然后通过缓慢减小*ρ*（*ρ*
    → 0）来更新*ρ*，直到收敛。
- en: '![](../Images/242fcc7a4203dfeda32e1586b7de38e1.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/242fcc7a4203dfeda32e1586b7de38e1.png)'
- en: Logarithmic Barrier for Different Values of *ρ*
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 不同值的*ρ*的对数障碍
- en: 'Revisiting our example above — the inequality constrained Rosenbrock’s Parabolic
    Valley (Eq. 2)— we can write our barrier function as follows:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们之前的例子——不等式约束的罗森布罗克抛物谷（公式2）——我们可以将障碍函数写为：
- en: '![](../Images/1e4ea9a6ecc31e36040a0a9085014df6.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e4ea9a6ecc31e36040a0a9085014df6.png)'
- en: (13)
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: (13)
- en: 'Recall that log(a) + log(b) = log(ab) and our one constraint x ≤ 0 → -x ≥ 0\.
    We must then update our code to accommodate the barrier method algorithm:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 记住log(a) + log(b) = log(ab)，以及我们的一个约束x ≤ 0 → -x ≥ 0。我们必须更新我们的代码以适应障碍法算法：
- en: '[PRE3]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We can now solve the Barrier function with the code above (Note: Make sure
    starting values are in the feasible range of inequality constraints & you may
    have to increase the starting value of rho if you jump out of inequality constraints):'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以用上述代码求解障碍函数（注意：确保起始值在不等式约束的可行范围内，如果跳出不等式约束，可能需要增加*ρ*的起始值）：
- en: '[PRE4]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'With the corresponding output:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 其对应的输出为：
- en: '![](../Images/1047398ab08e2f8ad3015f9fa87a4ace.png)![](../Images/d2b0cc746107ec260184b19a31b4199c.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1047398ab08e2f8ad3015f9fa87a4ace.png)![](../Images/d2b0cc746107ec260184b19a31b4199c.png)'
- en: Clearly the solution satisfies the inequality constraints specified. And there
    you have it. We have now tackled inequality constraints in our optimization problems.
    To wrap up, let’s put everything together and move on to tackling constrained
    optimization problems with mixed constraints — which is simply the combination
    of what we have done above.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，解满足指定的不等式约束。就是这样。我们现在已经处理了优化问题中的不等式约束。最后，让我们将一切整合起来，继续处理具有混合约束的约束优化问题——这只是我们上述工作组合的结果。
- en: '**Putting it All Together**'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**汇总**'
- en: 'Let’s now solve our optimization problem by combining both the equality and
    inequality constraints from above. That is, we want to solve an optimization of
    the form:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过结合上述的等式和不等式约束来解决我们的优化问题。也就是说，我们想要解决一个形式的优化问题：
- en: '![](../Images/91d0602859b3778af388eb855d77cd2a.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/91d0602859b3778af388eb855d77cd2a.png)'
- en: (14)
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: (14)
- en: 'All we have to do is combine the Lagrangian and the Barrier functions into
    one function. Thus, we can create a generalizable function, call it *O*, for dealing
    with optimization problems that have both equality and inequality constraints:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要将拉格朗日函数和障碍函数结合成一个函数。因此，我们可以创建一个通用函数，称之为 *O*，用于处理具有等式和不等式约束的优化问题：
- en: '![](../Images/46185c03e54a45fd89007a0ab112edb1.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/46185c03e54a45fd89007a0ab112edb1.png)'
- en: (15) Generalizable function for constrained optimization problems
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: (15) 可推广的约束优化问题的函数
- en: 'where, as before, **Λ** is the vector of Lagrange multipliers and*ρ* is the
    barrier parameter.Thus, combining our constrained (Eq. 6) and unconstrained problems
    from above (Eq. 11), we can formulate our mixed constrained optimization problem
    as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，如前所述，**Λ** 是拉格朗日乘子向量，*ρ* 是障碍参数。因此，结合我们上面的受限（公式6）和无约束问题（公式11），我们可以将我们的混合受限优化问题表述如下：
- en: '![](../Images/bae4b09261694380a079cc64b665c83f.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bae4b09261694380a079cc64b665c83f.png)'
- en: (16)
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: (16)
- en: In python,
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中，
- en: '[PRE5]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'With the corresponding output:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 以及相应的输出：
- en: '![](../Images/50feae3f14b28f95d2f2da062f6e5c6d.png)![](../Images/5965f76b2276c8b3ecffa41085fc5f14.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/50feae3f14b28f95d2f2da062f6e5c6d.png)![](../Images/5965f76b2276c8b3ecffa41085fc5f14.png)'
- en: We can verify that this solution does in fact obey the constraints. Specifically,
    x ≤ 0, y ≥ 3, & x² - y = 2\. Satisfying, no?
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以验证这个解确实符合约束条件。具体来说，x ≤ 0，y ≥ 3，& x² - y = 2。令人满意，不是吗？
- en: Conclusion
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: Phew. Take a deep breath — you earned it. Hopefully at this point you should
    have a much better understanding of the techniques to incorporate constraints
    into your optimization problems. We are still just brushing the surface of the
    different tools and techniques utilized in mathematical optimization.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 哎呀。深呼吸一下——你值得拥有。希望到目前为止，你对将约束条件融入优化问题的技术有了更好的理解。我们仍然只是触及了数学优化中各种工具和技术的表面。
- en: Stay tuned for **part 3 of this series**, the final part, where we will apply
    the optimization material learned thus far alongside econometric & economic theory
    to solve a profit maximization problem. It is my goal that part 3 will bring home
    everything we have covered and show a practical use case. As usual, I hope you
    have enjoyed reading this much as much I have enjoyed writing it!
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 敬请关注**系列的第3部分**，即最后一部分，我们将应用到目前为止学到的优化材料，并结合计量经济学和经济理论来解决利润最大化问题。我的目标是第3部分将总结我们所涵盖的内容，并展示一个实际应用案例。像往常一样，我希望你能像我写作时一样享受阅读这篇文章！
- en: Resources
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: '[1] [https://en.wikipedia.org/wiki/Constrained_optimization](https://en.wikipedia.org/wiki/Constrained_optimization)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [https://en.wikipedia.org/wiki/Constrained_optimization](https://en.wikipedia.org/wiki/Constrained_optimization)'
- en: '[2] Snyman, J. A., & Wilke, D. N. (2019). *Practical mathematical optimization:
    Basic optimization theory and gradient-based algorithms* (2nd ed.). Springer.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Snyman, J. A., & Wilke, D. N. (2019). *实用数学优化：基本优化理论与基于梯度的算法*（第2版）。Springer。'
- en: '[3] [https://en.wikipedia.org/wiki/Lagrange_multiplier](https://en.wikipedia.org/wiki/Lagrange_multiplier)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [https://en.wikipedia.org/wiki/Lagrange_multiplier](https://en.wikipedia.org/wiki/Lagrange_multiplier)'
- en: '[4] [https://en.wikipedia.org/wiki/Interior-point_method](https://en.wikipedia.org/wiki/Interior-point_method)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [https://en.wikipedia.org/wiki/Interior-point_method](https://en.wikipedia.org/wiki/Interior-point_method)'
- en: '[5] [https://en.wikipedia.org/wiki/Barrier_function](https://en.wikipedia.org/wiki/Barrier_function)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] [https://en.wikipedia.org/wiki/Barrier_function](https://en.wikipedia.org/wiki/Barrier_function)'
- en: '*Access all the code via this GitHub Repo:* [https://github.com/jakepenzak/Blog-Posts](https://github.com/jakepenzak/Blog-Posts)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '*通过这个 GitHub 仓库访问所有代码：* [https://github.com/jakepenzak/Blog-Posts](https://github.com/jakepenzak/Blog-Posts)'
- en: '*I appreciate you reading my post! My posts on Medium seek to explore real-world
    and theoretical applications utilizing* ***econometric*** *and* ***statistical/machine
    learning*** *techniques. Additionally, I seek to provide posts on the theoretical
    underpinnings of various methodologies via theory and simulations. Most importantly,
    I write to learn! I hope to make complex topics slightly more accessible to all.
    If you enjoyed this post, please consider* [***following me on Medium***](https://medium.com/@jakepenzak)*!*'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '*感谢你阅读我的文章！我在 Medium 上的文章旨在探索利用* ***计量经济学*** *和* ***统计/机器学习*** *技术的现实世界和理论应用。此外，我还希望通过理论和模拟提供各种方法论的理论基础。最重要的是，我写作是为了学习！我希望能让复杂的话题对所有人更易于理解。如果你喜欢这篇文章，请考虑*
    [***在 Medium 上关注我***](https://medium.com/@jakepenzak)*！*'
