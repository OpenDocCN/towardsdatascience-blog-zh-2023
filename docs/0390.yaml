- en: Building a Data Lake on PB scale with Apache Spark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/building-a-data-lake-on-pb-scale-with-apache-spark-1622d7073d46?source=collection_archive---------1-----------------------#2023-01-26](https://towardsdatascience.com/building-a-data-lake-on-pb-scale-with-apache-spark-1622d7073d46?source=collection_archive---------1-----------------------#2023-01-26)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How we deal with Big Data at Emplifi
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@vrba.dave?source=post_page-----1622d7073d46--------------------------------)[![David
    Vrba](../Images/7689bf42fcfc0c029de87450d01069ba.png)](https://medium.com/@vrba.dave?source=post_page-----1622d7073d46--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1622d7073d46--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1622d7073d46--------------------------------)
    [David Vrba](https://medium.com/@vrba.dave?source=post_page-----1622d7073d46--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb7f216c64e33&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-data-lake-on-pb-scale-with-apache-spark-1622d7073d46&user=David+Vrba&userId=b7f216c64e33&source=post_page-b7f216c64e33----1622d7073d46---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1622d7073d46--------------------------------)
    ·15 min read·Jan 26, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1622d7073d46&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-data-lake-on-pb-scale-with-apache-spark-1622d7073d46&user=David+Vrba&userId=b7f216c64e33&source=-----1622d7073d46---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1622d7073d46&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-data-lake-on-pb-scale-with-apache-spark-1622d7073d46&source=-----1622d7073d46---------------------bookmark_footer-----------)![](../Images/ec428d788058b2d1569bf4768b4938db.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image by [Victor Hanacek](https://picjumbo.com/author/viktorhanacek/) on [picjumbo](https://picjumbo.com/big-data/)
  prefs: []
  type: TYPE_NORMAL
- en: Professionally, I have spent the last four years in the data engineering team
    at the company Emplifi (formerly Socialbakers) and one of the largest projects
    I have been working on is building a distributed data storage system that holds
    currently nearly one PB of data with the goal to provide data analysts and researchers
    with tables of data they can efficiently analyze and research. As you can probably
    imagine — building and maintaining such a Data Lake is not a trivial task considering
    that not only does the data change frequently but also its schema evolves over
    time having dozens or even hundreds of fields with different levels of nesting.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I would like to share my experience and highlights from this
    journey mainly on the technical level.
  prefs: []
  type: TYPE_NORMAL
- en: The origin of the data we are processing on a daily basis is social networks
    such as Facebook, Twitter, Instagram, YouTube, LinkedIn, or TikTok. The processed
    datasets are mainly public profiles with published posts on these networks. Some
    smaller portion of the data comes also from internal systems. Our storage system
    is built on S3 AWS and we call it the Data Lake because we store here data in
    the raw format and also in preprocessed, processed, and aggregated form. The raw
    data is mainly in…
  prefs: []
  type: TYPE_NORMAL
