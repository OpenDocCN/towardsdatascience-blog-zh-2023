- en: Hybrid Discrete-Continuous Geometric Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/hybrid-discrete-continuous-geometric-deep-learning-2e5871293184?source=collection_archive---------12-----------------------#2023-03-15](https://towardsdatascience.com/hybrid-discrete-continuous-geometric-deep-learning-2e5871293184?source=collection_archive---------12-----------------------#2023-03-15)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Scalable and equivariant spherical CNNs by DISCO convolutions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://jasonmcewen.medium.com/?source=post_page-----2e5871293184--------------------------------)[![Jason
    McEwen](../Images/794e7e6546ed049860dab5e294535880.png)](https://jasonmcewen.medium.com/?source=post_page-----2e5871293184--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2e5871293184--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2e5871293184--------------------------------)
    [Jason McEwen](https://jasonmcewen.medium.com/?source=post_page-----2e5871293184--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fea87e920245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhybrid-discrete-continuous-geometric-deep-learning-2e5871293184&user=Jason+McEwen&userId=ea87e920245&source=post_page-ea87e920245----2e5871293184---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2e5871293184--------------------------------)
    ¬∑7 min read¬∑Mar 15, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2e5871293184&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhybrid-discrete-continuous-geometric-deep-learning-2e5871293184&user=Jason+McEwen&userId=ea87e920245&source=-----2e5871293184---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2e5871293184&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhybrid-discrete-continuous-geometric-deep-learning-2e5871293184&source=-----2e5871293184---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: '*No existing spherical convolutional neural network (CNN) framework is both
    computationally scalable and rotationally equivariant. Continuous approaches capture
    rotational equivariance but are often prohibitively computationally demanding.
    Discrete approaches offer more favorable computational performance but at the
    cost of equivariance. We develop a hybrid discrete-continuous (DISCO) group convolution
    that is simultaneously equivariant and computationally scalable to high-resolution.
    This approach achieves state-of-the-art (SOTA) performance on many benchmark dense
    prediction tasks. (Further details can be found in our ICLR paper on* [*Scalable
    and Equivariant Spherical CNNs by DISCO Convolutions*](https://arxiv.org/abs/2209.13603)*.)*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0d7a81a6427d5be617a5918199498400.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Dustin Tramel](https://unsplash.com/@dustintramel?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'Geometric deep learning on groups has many applications, such as analysing
    observations over the Earth and panoramic 360¬∞ photos and videos, to name just
    a few. However, current approaches suffer a dichotomy: they either exhibit good
    equivariance properties or good computationally scalability; but not both simultaneously.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Dichotomy: discrete vs continuous approaches'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The key goals of geometric deep learning techniques on groups is to [encode
    equivariance](https://medium.com/towards-data-science/what-einstein-can-teach-us-about-machine-learning-1661e26bef2c)
    to various group transformations (which typically translates to very good performance),
    while also being highly computationally scalable.
  prefs: []
  type: TYPE_NORMAL
- en: As discussed in our [previous TDS article](/geometric-deep-learning-on-groups-cec82eb9366),
    focusing on the group setting of homogenous spaces with global symmetries, geometric
    deep learning on groups can be broadly classified into discrete and continuous
    approaches. Continuous approaches offer equivariance but with a large computational
    cost. Discrete approaches, on the other hand, are typically relatively computationally
    efficient but sacrifice equivariance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Breaking the **dichotomy**: discrete-continuous (DISCO) approach'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At [Copernic AI](https://copernicai.com/) we have recently developed techniques
    that break this dichotomy (recently published in ICLR [1]). That is, we have developed
    geometric deep learning techniques on groups that provide excellent equivariance
    properties, while also being highly computationally efficient so that they can
    be effectively scaled to huge, high-resolution datasets.
  prefs: []
  type: TYPE_NORMAL
- en: The key to breaking the discrete versus continuous dichotomy is to take a hybrid
    approach, where some parts of the representation are discretized, to facilitate
    efficient computation, while other parts are left continuous to facilitate equivariance.
    Due to its hybrid nature (as illustrated in the diagram below) we name this approach
    DISCO, for DIScrete-COntinous.
  prefs: []
  type: TYPE_NORMAL
- en: While the DISCO approach is general, we focus on the sphere as the archetypical
    example of the group setting of homogenous spaces with global symmetries.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2de8720278abce3b8483cda5e31abb2a.png)'
  prefs: []
  type: TYPE_IMG
- en: Breaking the continuous vs discrete dichotomy through a hybrid discrete-continuous
    (DISCO) approach that is both rotationally equivariant and computationally scalable.
    [Original figure created by authors.]
  prefs: []
  type: TYPE_NORMAL
- en: Discrete-continuous (DISCO) group convolutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The DISCO approach is based on convolutional layers, where the DISCO group convolution
    follows by a careful hybrid representation of the standard group convolution.
    Some components of the representation are left continuous, to facilitate accurate
    rotational equivariance, while other components are discretized, to yield scalable
    computation.
  prefs: []
  type: TYPE_NORMAL
- en: The DISCO group convolution of a signal (i.e. data, feature map) *f* defined
    over the group, with a filter *ùù≠*, is given by
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/238d0bbb91abad97fc466bac9e89153f.png)'
  prefs: []
  type: TYPE_IMG
- en: where *g* is an element of the group *G,* d*¬µ(u)* is the (Haar) measure of integration,
    and *q(u·µ¢)* are quadrature weights. Square brackets and index subscripts denote
    discretized quantities, with *i* denoting sample index, and round brackets denote
    continuous quantities.
  prefs: []
  type: TYPE_NORMAL
- en: On the sphere we consider transformations given by 3D rotations and so the DISCO
    convolution of a signal on the sphere reads
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/762b297f89bf797a95e2778eaf6e8a9d.png)'
  prefs: []
  type: TYPE_IMG
- en: where *R* denotes a rotation and *œâ* spherical coordinates.
  prefs: []
  type: TYPE_NORMAL
- en: Focusing on the spherical case, clearly the signal of interest must be discretized
    at sample positions *œâ·µ¢*. Critically, however, in the DISCO approach the filter
    *ùù≠* and the group action *R* remain continuous. This allows the filter to be transformed
    continuously by any *R*, keeping a coherent representation that avoids any discretization
    errors and, consequently, affords rotational equivariance, unlike a fully discrete
    method.
  prefs: []
  type: TYPE_NORMAL
- en: The integral with respect to *œâ* mustalso be discretized. For bandlimited signals
    on compact homogeneous manifolds, such as the sphere, the existence of a sampling
    theorem ensures that the integral can be approximated very accurately using quadrature
    weights *q(œâ·µ¢)*.
  prefs: []
  type: TYPE_NORMAL
- en: The DISCO approximation of the group convolution is highly accurate for bandlimited
    signals, which real-world signals can be well approximately by for a sufficient
    bandlimit. By appealing to a sampling theorem, all information content of the
    signal can be captured in the finite set of samples *{f[œâ·µ¢]}*. The filter is represented
    continuously and so does not introduce any error. The only source of approximation
    error is thus the quadrature used to evaluate the integral. For a sufficiently
    dense sampling one can appeal to the sampling theorem and corresponding quadrature
    to evaluate this exactly. Therefore, it is possible in principle to compute the
    DISCO group convolution exactly, without any approximation error. Since the approximation
    is highly accurate, which can be made exact for a sufficiently dense sampling,
    and group actions are treated continuously, the DISCO group convolution exhibits
    excellent equivariance properties, as validated numerically [1].
  prefs: []
  type: TYPE_NORMAL
- en: Scalable computation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The DISCO convolution affords a computationally scalable implementation through
    sparse tensor representations [1]. Specifically, we leverage sparse-dense tensor
    multiplication operators to compute the DISCO spherical convolution efficiently
    on hardware accelerators (e.g. GPUs, TPUs).
  prefs: []
  type: TYPE_NORMAL
- en: By restricting the space of rotations further (to the quotient space SO(3)/SO(2))
    and exploiting symmetries of the sampling scheme, we achieve linear scaling in
    both computational cost and memory requirements.
  prefs: []
  type: TYPE_NORMAL
- en: The plots below show the number of floating point operations (FLOPs) and memory
    requirements for the DISCO spherical convolution as a function of resolution/bandlimit,
    compared to the most efficient alternative spherical convolution that exhibits
    rotational equivariance.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/83e4e1d128da89b53b82de442ca43e67.png)'
  prefs: []
  type: TYPE_IMG
- en: Computational cost and memory requirements of the DISCO spherical convolution
    as a function of resolution/bandlimit, compared to the most efficient alternative
    spherical convolution that exhibits rotational equivariance. [Original figure
    created by authors.]
  prefs: []
  type: TYPE_NORMAL
- en: For 4k spherical images we achieve a saving of 10‚Åπ in computational cost and
    10‚Å¥ in memory usage.
  prefs: []
  type: TYPE_NORMAL
- en: DISCO spherical CNNs architectures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A transpose DISCO convolution can also be constructed in an analogous way to
    the forward convolution discussed above, which can then be used to increase the
    resolution of internal feature representations for dense-prediction tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Efficient spherical implementations of common CNN architectures can then be
    constructed by combining the DISCO forward and transpose spherical convolutions
    with pointwise non-linear activations and other common architectural features,
    such as skip connections, batch-normalization, multiple channels, etc.
  prefs: []
  type: TYPE_NORMAL
- en: We consider a number of dense-prediction tasks below, such as semantic segmentation
    and depth estimation, for which we adopt a common backbone of a residual UNet
    architecture with DISCO convolutions. Our resulting DISCO models achieve state-of-the-art
    (SOTA) performance on all of the benchmark problems considered to date.
  prefs: []
  type: TYPE_NORMAL
- en: Semantic segmentation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We consider the dense-prediction problem of semantic segmentation of 360¬∞ photos.
  prefs: []
  type: TYPE_NORMAL
- en: For the 2D3DS dataset of indoor 360¬∞ photos, we show below examples of spherical
    RGB images, ground truth segmentations, and segmentations predicted by the DISCO
    model simply from the RGB image.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f3f13d8ef766e10bcf59fafdbed3d5f6.png)'
  prefs: []
  type: TYPE_IMG
- en: Example segmentation of 2D3DS data of indoor 360¬∞ photos. [Original figure created
    by authors.]
  prefs: []
  type: TYPE_NORMAL
- en: While the predicted segmentations aren‚Äôt perfect, they are generally highly
    accurate. In fact, our DISCO approach achieves SOTA performance compared to all
    other alternatives (see [1] for further details).
  prefs: []
  type: TYPE_NORMAL
- en: For the Omni-SYNTHIA dataset of ourdoor 360¬∞ photos, we also show below examples
    of spherical RGB images, ground truth segmentations, and predicted segmentations.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e0bb4385a793de7cfb76308cf381b0ce.png)'
  prefs: []
  type: TYPE_IMG
- en: Example segmentation of Omni-SYNTHIA data of outdoor 360¬∞ photos. [Original
    figure created by authors.]
  prefs: []
  type: TYPE_NORMAL
- en: Again, predicted segmentations are generally highly accurate and we achieve
    SOTA performance compared to all other alternatives (see [1] for further details).
  prefs: []
  type: TYPE_NORMAL
- en: Depth estimation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another common dense-prediction task is depth estimation. We consider the task
    of monocular depth estimation from 360¬∞ photos, tackling the Pano3D benchmark
    for the Matterport3D dataset.
  prefs: []
  type: TYPE_NORMAL
- en: We show below examples of spherical RGB images, ground truth depth, and depths
    predicted by the DISCO model simply from the RGB image.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/43c0f63ec29069e6e6722f6e7735da5b.png)'
  prefs: []
  type: TYPE_IMG
- en: Example depth estimation of Matterport3D data of indoor 360¬∞ photos. [Original
    figure created by authors.]
  prefs: []
  type: TYPE_NORMAL
- en: Predicted depths are generally highly accurate. Indeed, we again achieve SOTA
    performance compared to all other alternatives (see [1] for further details).
  prefs: []
  type: TYPE_NORMAL
- en: Future perspectives
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The problem of both equivariant and computationally scalable geometric deep
    learning on groups has now be cracked through the hybrid discrete-continuous (DISCO)
    representation. As we have seen on the benchmark tasks considered above where
    we achieve SOTA performance, excellent equivariance properties translate to excellent
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: We now have the underlying building blocks needed to extend modern deep learning
    architectures to the group setting of homogenous spaces with global symmetries,
    such as the sphere. There are vast number of such applications where we can now
    unlock the potential of modern deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] Ocampo, Price, McEwen, *Scalable and equivariant spherical CNNs by discrete-continuous
    (DISCO) convolutions*, ICLR (2023), [arXiv:2209.13603](https://arxiv.org/abs/2209.13603)'
  prefs: []
  type: TYPE_NORMAL
