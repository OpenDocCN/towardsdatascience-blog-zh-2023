["```py\nimport gensim\nimport nltk\nfrom gensim import corpora\nfrom gensim.models import LdaModel\nfrom gensim.utils import simple_preprocess\nfrom nltk.corpus import stopwords\nfrom pypdf import PdfReader\nfrom langchain.chains import LLMChain\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.llms import OpenAI\n```", "```py\ndef preprocess(text, stop_words):\n    \"\"\"\n    Tokenizes and preprocesses the input text, removing stopwords and short \n    tokens.\n\n    Parameters:\n        text (str): The input text to preprocess.\n        stop_words (set): A set of stopwords to be removed from the text.\n    Returns:\n        list: A list of preprocessed tokens.\n    \"\"\"\n    result = []\n    for token in simple_preprocess(text, deacc=True):\n        if token not in stop_words and len(token) > 3:\n            result.append(token)\n    return result\n```", "```py\ndef get_topic_lists_from_pdf(file, num_topics, words_per_topic):\n    \"\"\"\n    Extracts topics and their associated words from a PDF document using the \n    Latent Dirichlet Allocation (LDA) algorithm.\n\n    Parameters:\n        file (str): The path to the PDF file for topic extraction.\n        num_topics (int): The number of topics to discover.\n        words_per_topic (int): The number of words to include per topic.\n\n    Returns:\n        list: A list of num_topics sublists, each containing relevant words \n        for a topic.\n    \"\"\"\n    # Load the pdf file\n    loader = PdfReader(file)\n\n    # Extract the text from each page into a list. Each page is considered a document\n    documents= []\n    for page in loader.pages:\n        documents.append(page.extract_text())\n\n    # Preprocess the documents\n    nltk.download('stopwords')\n    stop_words = set(stopwords.words(['english','spanish']))\n    processed_documents = [preprocess(doc, stop_words) for doc in documents]\n\n    # Create a dictionary and a corpus\n    dictionary = corpora.Dictionary(processed_documents)\n    corpus = [dictionary.doc2bow(doc) for doc in processed_documents]\n\n    # Build the LDA model\n    lda_model = LdaModel(\n        corpus, \n        num_topics=num_topics, \n        id2word=dictionary, \n        passes=15\n        )\n\n    # Retrieve the topics and their corresponding words\n    topics = lda_model.print_topics(num_words=words_per_topic)\n\n    # Store each list of words from each topic into a list\n    topics_ls = []\n    for topic in topics:\n        words = topic[1].split(\"+\")\n        topic_words = [word.split(\"*\")[1].replace('\"', '').strip() for word in words]\n        topics_ls.append(topic_words)\n\n    return topics_ls\n```", "```py\ndef topics_from_pdf(llm, file, num_topics, words_per_topic):\n    \"\"\"\n    Generates descriptive prompts for LLM based on topic words extracted from a \n    PDF document.\n\n    This function takes the output of `get_topic_lists_from_pdf` function, \n    which consists of a list of topic-related words for each topic, and \n    generates an output string in table of content format.\n\n    Parameters:\n        llm (LLM): An instance of the Large Language Model (LLM) for generating \n        responses.\n        file (str): The path to the PDF file for extracting topic-related words.\n        num_topics (int): The number of topics to consider.\n        words_per_topic (int): The number of words per topic to include.\n\n    Returns:\n        str: A response generated by the language model based on the provided \n        topic words.\n    \"\"\"\n\n    # Extract topics and convert to string\n    list_of_topicwords = get_topic_lists_from_pdf(file, num_topics, \n                                                  words_per_topic)\n    string_lda = \"\"\n    for list in list_of_topicwords:\n        string_lda += str(list) + \"\\n\"\n\n    # Create the template\n    template_string = '''Describe the topic of each of the {num_topics} \n        double-quote delimited lists in a simple sentence and also write down \n        three possible different subthemes. The lists are the result of an \n        algorithm for topic discovery.\n        Do not provide an introduction or a conclusion, only describe the \n        topics. Do not mention the word \"topic\" when describing the topics.\n        Use the following template for the response.\n\n        1: <<<(sentence describing the topic)>>>\n        - <<<(Phrase describing the first subtheme)>>>\n        - <<<(Phrase describing the second subtheme)>>>\n        - <<<(Phrase describing the third subtheme)>>>\n\n        2: <<<(sentence describing the topic)>>>\n        - <<<(Phrase describing the first subtheme)>>>\n        - <<<(Phrase describing the second subtheme)>>>\n        - <<<(Phrase describing the third subtheme)>>>\n\n        ...\n\n        n: <<<(sentence describing the topic)>>>\n        - <<<(Phrase describing the first subtheme)>>>\n        - <<<(Phrase describing the second subtheme)>>>\n        - <<<(Phrase describing the third subtheme)>>>\n\n        Lists: \"\"\"{string_lda}\"\"\" '''\n\n    # LLM call\n    prompt_template = ChatPromptTemplate.from_template(template_string)\n    chain = LLMChain(llm=llm, prompt=prompt_template)\n    response = chain.run({\n        \"string_lda\" : string_lda,\n        \"num_topics\" : num_topics\n        })\n\n    return response\n```", "```py\nopenai_key = \"sk-p...\"\nllm = OpenAI(openai_api_key=openai_key, max_tokens=-1)\n```", "```py\n!gdown https://drive.google.com/uc?id=1mpXUmuLGzkVEqsTicQvBPcpPJW0aPqdL\n\nfile = \"./the-metamorphosis.pdf\"\nnum_topics = 6\nwords_per_topic = 30\n\nsummary = topics_from_pdf(llm, file, num_topics, words_per_topic)\n```", "```py\n1: Exploring the transformation of Gregor Samsa and the effects on his family and lodgers\n- Understanding Gregor's metamorphosis\n- Examining the reactions of Gregor's family and lodgers\n- Analyzing the impact of Gregor's transformation on his family\n\n2: Examining the events surrounding the discovery of Gregor's transformation\n- Investigating the initial reactions of Gregor's family and lodgers\n- Analyzing the behavior of Gregor's family and lodgers\n- Exploring the physical changes in Gregor's environment\n\n3: Analyzing the pressures placed on Gregor's family due to his transformation\n- Examining the financial strain on Gregor's family\n- Investigating the emotional and psychological effects on Gregor's family\n- Examining the changes in family dynamics due to Gregor's metamorphosis\n\n4: Examining the consequences of Gregor's transformation\n- Investigating the physical changes in Gregor's environment\n- Analyzing the reactions of Gregor's family and lodgers\n- Investigating the emotional and psychological effects on Gregor's family\n\n5: Exploring the impact of Gregor's transformation on his family\n- Analyzing the financial strain on Gregor's family\n- Examining the changes in family dynamics due to Gregor's metamorphosis\n- Investigating the emotional and psychological effects on Gregor's family\n\n6: Investigating the physical changes in Gregor's environment\n- Analyzing the reactions of Gregor's family and lodgers\n- Examining the consequences of Gregor's transformation\n- Exploring the impact of Gregor's transformation on his family\n```", "```py\n1: Analyzing the properties of geometric shapes and their relationships\n- Exploring the axioms of geometry\n- Analyzing the congruence of angles and lines\n- Investigating theorems of geometry\n\n2: Studying the behavior of rational functions and algebraic equations\n- Examining the straight lines and points of a problem\n- Investigating the coefﬁcients of a function\n- Examining the construction of a deﬁnite integral\n\n3: Investigating the properties of a number system\n- Exploring the domain of a true group\n- Analyzing the theorem of equal segments\n- Examining the circle of arbitrary displacement\n\n4: Examining the area of geometric shapes\n- Analyzing the parallel lines and points\n- Investigating the content of a triangle\n- Examining the measures of a polygon\n\n5: Examining the theorems of algebraic geometry\n- Exploring the congruence of segments\n- Analyzing the system of multiplication\n- Investigating the valid theorems of a call\n\n6: Investigating the properties of a ﬁgure\n- Examining the parallel lines of a triangle\n- Analyzing the equation of joining sides\n- Examining the intersection of segments\n```"]