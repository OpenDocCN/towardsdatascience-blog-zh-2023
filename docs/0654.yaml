- en: Finding the Fastest Lane at Border Crossings Using Machine Vision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/finding-the-fastest-lane-at-border-crossings-using-machine-vision-2e8dec6e03a3?source=collection_archive---------14-----------------------#2023-02-16](https://towardsdatascience.com/finding-the-fastest-lane-at-border-crossings-using-machine-vision-2e8dec6e03a3?source=collection_archive---------14-----------------------#2023-02-16)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Optimizing border crossing with object detection and tracking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@danilo.najkov?source=post_page-----2e8dec6e03a3--------------------------------)[![Danilo
    Najkov](../Images/e0e8976f1f9f78ae58ba7efcc90a4f00.png)](https://medium.com/@danilo.najkov?source=post_page-----2e8dec6e03a3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2e8dec6e03a3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2e8dec6e03a3--------------------------------)
    [Danilo Najkov](https://medium.com/@danilo.najkov?source=post_page-----2e8dec6e03a3--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F19802d0e7d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffinding-the-fastest-lane-at-border-crossings-using-machine-vision-2e8dec6e03a3&user=Danilo+Najkov&userId=19802d0e7d&source=post_page-19802d0e7d----2e8dec6e03a3---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2e8dec6e03a3--------------------------------)
    ·12 min read·Feb 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2e8dec6e03a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffinding-the-fastest-lane-at-border-crossings-using-machine-vision-2e8dec6e03a3&user=Danilo+Najkov&userId=19802d0e7d&source=-----2e8dec6e03a3---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2e8dec6e03a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffinding-the-fastest-lane-at-border-crossings-using-machine-vision-2e8dec6e03a3&source=-----2e8dec6e03a3---------------------bookmark_footer-----------)![](../Images/af3adda86dc5315b4d508bf6e84bc172.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Generated image from the proposed solution of the [“Blace” border crossing camera](http://www.roads.org.mk/411/live-webcast)
    in North Macedonia (public domain)
  prefs: []
  type: TYPE_NORMAL
- en: Crossing the border can be an exciting part of any road trip, but the frustration
    of long queues at border crossings can quickly take the excitement out of it.
    What if we could determine the fastest lane and position ourselves accordingly?
    Thanks to advancements in machine vision, this is now a possibility. By leveraging
    OpenCV and YOLOv3, a deep learning algorithm, it’s now possible to detect and
    track moving vehicles in real time. In this post, we’ll explore how this technology
    can be used to help people save time and avoid the stress of long queues at border
    crossings.
  prefs: []
  type: TYPE_NORMAL
- en: '**Contents**'
  prefs: []
  type: TYPE_NORMAL
- en: Overview of the problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Object detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: – Car detection
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: – Lane detection
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Object tracking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Orchestrating everything
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limitations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Future work
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overview of the problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The main idea of this task is to process the raw image data coming from border
    camera live streams to detect and track moving vehicles. The problem can be divided
    into several steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Get raw image data from the border cameras' livestream
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preprocess the image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apply algorithms to find the location of the vehicles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determine the lane for these vehicles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apply algorithms to determine the speed of the vehicles (and in turn the speed
    of every lane)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of these steps are combined and orchestrated with docker-compose for running
    the solution on multiple border video streams.
  prefs: []
  type: TYPE_NORMAL
- en: The data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The video data is sourced from border cameras that are open to the public. The
    solutions proposed here can be used on any live stream *(.m3u8)* of border/toll
    cameras and can be easily adapted for other forms of video. Nearly all the countries
    in the world have some sort of service that allows users to see the live conditions
    of border crossings. For this specific case, I used the live feeds of the cameras
    of my country. You can find the streams on this [link](http://www.roads.org.mk/315/video-kameri).
  prefs: []
  type: TYPE_NORMAL
- en: Object detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before running any algorithms, we need to load the stream and preprocess the
    image. This can be easily done with OpenCV2\. I created a function that resizes
    the image to 416x416 pixels (the format required by the implementation of the
    YOLOv3 model I used)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In a while loop, images are loaded from the stream and are preprocessed using
    the above function. All the following changes will also be done in this while
    loop. Additionally, I check if something has changed from the previous frame,
    as it would be unnecessary to process the image again if nothing has changed.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Car detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/ebf61150cc4e20d7e4497eca832d44a1.png)'
  prefs: []
  type: TYPE_IMG
- en: YOLOv3 architecture for detecting objects (credit to the original [YOLOv3 paper](https://arxiv.org/abs/1804.02767))
  prefs: []
  type: TYPE_NORMAL
- en: Now, we are all set for detecting vehicles in the image. I used YOLOv3 for getting
    the bounding boxes of all the classes that the model was trained on, but kept
    only the ones that are vehicles. The weights and configuration files are required
    for loading this model, and you can download them from the [official website](https://pjreddie.com/darknet/yolo/).
    This function returns the bounding boxes, the confidence of the model for the
    detected object, the class of the object (ex. car, truck, person, etc.), and the
    centers of each of the bounding boxes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/6070fbf83d622be655a71e44de616777.png)'
  prefs: []
  type: TYPE_IMG
- en: The output of the algorithm before applying NMS on the [“Blace” border crossing
    camera](http://www.roads.org.mk/411/live-webcast) (public domain)
  prefs: []
  type: TYPE_NORMAL
- en: We have all the information about the bounding boxes, however, when we run the
    application we see that there are a lot of overlapping boxes that need to be removed.
    For this challenge, I used Non-Maximum Suppression (NMS). Non-Maximum Suppression
    (NMS) is a post-processing algorithm used in object detection tasks, specifically
    to remove redundant or overlapping bounding boxes for the same object.
  prefs: []
  type: TYPE_NORMAL
- en: NMS is applied to filter out redundant bounding boxes and keep only the most
    appropriate ones. The basic idea behind NMS is to first sort the bounding boxes
    based on their detection confidence score (i.e., the probability that the bounding
    box contains an object). Starting with the bounding box with the highest confidence
    score, NMS suppresses all overlapping bounding boxes that have an Intersection
    over Union (IoU) value greater than a certain threshold (e.g., 0.5).
  prefs: []
  type: TYPE_NORMAL
- en: The following function performs this algorithm. It takes as parameters the bounding
    boxes, the confidence of the bounding boxes, and the threshold we want to filter
    out the duplicates. It returns the IDs of the boxes we need to keep.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: After using this algorithm, only one bounding box is retained per vehicle. You
    may need to adjust your threshold value to find what works for you.
  prefs: []
  type: TYPE_NORMAL
- en: Lane detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While there are lane detection algorithms that could be effective for this
    task, they may not be the most efficient option. Since the cameras are fixed and
    lane positions don’t change, it would be a waste of processing time to use such
    algorithms. To address this, I saved the lane positions in a JSON file as a list
    of points. However, before determining the speed of the lanes, one additional
    challenge remains: identifying which lane each car is in.'
  prefs: []
  type: TYPE_NORMAL
- en: For this, I created the following functions which find where each car is depending
    on its x-coordinate. It returns the index of the lane in which the car is. If
    the car is outside the lanes it returns -1.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We have everything ready to see the rate of change in each lane, by implementing
    object tracking.
  prefs: []
  type: TYPE_NORMAL
- en: Object tracking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Object tracking is the process of locating a specific object or multiple objects
    in a video stream and following their movement over time. The goal of object tracking
    is to maintain the identity of the objects across successive frames of the video,
    despite changes in the object’s position, orientation, size, and appearance. Many
    object-tracking algorithms exist, but for this specific use case, I decided to
    use optical flow, as it works fairly well with streams with a lower frame rate.
  prefs: []
  type: TYPE_NORMAL
- en: Optical flow is a technique that involves analyzing the changes in the intensity
    of adjacent pixels in successive video frames to determine the direction and speed
    of movement of objects in the scene. Optical flow algorithms rely on the assumption
    that the brightness of a pixel in one frame is the same as its corresponding pixel
    in the next frame, allowing for the calculation of the displacement of objects
    between frames.
  prefs: []
  type: TYPE_NORMAL
- en: This algorithm is much more complicated, so I will not be explaining it in detail.
    As parameters, it takes the image and previous image, the centers of the cars
    from the YOLOv3 model, the lanes to determine if the movement is happening in
    each lane, and cars in lanes to see if the movement is a result of vehicle movement
    or other factors. It returns a list of speeds for each lane.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The output of the optical flow algorithm is saved and compared to the output
    of the previous frame. If there is a significant change in the optical flow values
    for each lane, it is recorded as 1 movement point. This is implemented in the
    following function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Now that everything is implemented, we can visualize the results. This function
    shows the image with the bounding boxes of each car, and lanes of traffic, and
    prints the speed of lanes in the console.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: After running everything in the main while loop, we get the following video.
    The program outputs that the second lane (lane 2) had the most movement and therefore
    is the fastest.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8dc09007c977a239ce532419064c2ab8.png)'
  prefs: []
  type: TYPE_IMG
- en: Sped up GIF of around 3 minutes of border footage from the [“Blace” border crossing](http://www.roads.org.mk/411/live-webcast)
    (public domain)
  prefs: []
  type: TYPE_NORMAL
- en: Orchestrating everything
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although the algorithm is complete for detecting and tracking vehicles in a
    single border crossing, I wanted to extend the solution to work across multiple
    crossings while still saving the results of speed. To achieve this, I decided
    to run each border camera script as a separate container that communicates within
    a docker-compose. Since running a separate instance of the YOLOv3 model for each
    camera would be inefficient, I created a separate container with a flask app that
    serves the other containers. However, to ensure that multiple requests don’t use
    the same neural network simultaneously, it’s important to incorporate semaphores
    or other locking mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, I developed a .Net web API that saves the speeds and cars in each
    lane to a database. It is out of this post’s scope to include the full code here,
    but you can find it on my [GitHub repository](https://github.com/dani2221/bordercount).
    With this implementation, the solution can be deployed to multiple border crossings,
    and the resulting data can be efficiently collected and analyzed, providing valuable
    insights into traffic patterns and congestion at different locations.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Limitations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While our algorithm has proven to be highly effective, it is important to acknowledge
    its limitations. Firstly, YOLOv3, the object detection model I utilized, is less
    accurate in low-light conditions, such as at night. As a result, the number of
    vehicles detected will be significantly lower, potentially leading to incorrect
    assumptions about traffic volume. Additionally, the model struggles to detect
    objects at long distances, meaning that there is a cap on the number of vehicles
    that can be detected in long queues.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, it’s important to consider that border crossings can vary significantly
    in design. While the majority of borders may follow a similar layout, there are
    some with more complex features, such as curved lanes and additional barriers.
    These variations can render the algorithm unusable in certain scenarios. It’s
    worth noting that further development and optimization could potentially address
    these limitations, but for now, it’s essential to take these factors into account
    when implementing our solution.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2541e9469d4106cdb12d15f8d2a37f77.png)'
  prefs: []
  type: TYPE_IMG
- en: Example border checkpoint from the [“Tabanovce” crossing](http://www.roads.org.mk/411/live-webcast)
    (public domain) where the lane speed algorithm cannot be used.
  prefs: []
  type: TYPE_NORMAL
- en: Future work
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While this solution provides an effective means of determining vehicle speed
    and traffic congestion at border checkpoints, there is still room for improvement.
    One area for future work is to explore other object detection models to see if
    they offer improved accuracy in low-light conditions or when detecting objects
    at longer distances.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, it may be useful to investigate the feasibility of implementing
    this algorithm at border crossings with more complex layouts. This could involve
    developing new algorithms to address the challenges posed by curved lanes, additional
    barriers, or other features unique to those crossings.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, the current solution could be extended to incorporate machine learning
    techniques that could adapt to changing traffic patterns over time. By training
    the model on data collected over an extended period, it could potentially learn
    to adjust its parameters based on traffic conditions, improving its accuracy and
    reliability over time.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, it may be possible to integrate data from other sources, such as social
    media or traffic cameras, to provide a more comprehensive understanding of traffic
    patterns at border crossings. By incorporating data from a range of sources, it
    may be possible to find correlations between traffic patterns and external factors,
    such as weather or public events, providing valuable insights for traffic management
    and future planning. This data can help people better plan their trips, by setting
    departure times in which there is the least expected traffic.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In conclusion, by using machine vision algorithms, we have developed an effective
    solution for determining vehicle speed and traffic volume at border crossings.
    You can experiment with the code on [GitHub](https://github.com/dani2221/bordercount)
    and try what results you get with the border crossings near you. Thank you for
    reading!
  prefs: []
  type: TYPE_NORMAL
