- en: A Good Description Is All You Need
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个好的描述就是你所需要的一切
- en: 原文：[https://towardsdatascience.com/a-good-description-is-all-you-need-1d0b47be10ec?source=collection_archive---------12-----------------------#2023-08-10](https://towardsdatascience.com/a-good-description-is-all-you-need-1d0b47be10ec?source=collection_archive---------12-----------------------#2023-08-10)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-good-description-is-all-you-need-1d0b47be10ec?source=collection_archive---------12-----------------------#2023-08-10](https://towardsdatascience.com/a-good-description-is-all-you-need-1d0b47be10ec?source=collection_archive---------12-----------------------#2023-08-10)
- en: How to use few shot learning to improve text classification performance
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何使用少量学习来提高文本分类性能
- en: '[](https://medium.com/@ilia.teimouri?source=post_page-----1d0b47be10ec--------------------------------)[![Ilia
    Teimouri PhD](../Images/0eb948c4d3f81c116cd16fa4d5016629.png)](https://medium.com/@ilia.teimouri?source=post_page-----1d0b47be10ec--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1d0b47be10ec--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1d0b47be10ec--------------------------------)
    [Ilia Teimouri PhD](https://medium.com/@ilia.teimouri?source=post_page-----1d0b47be10ec--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@ilia.teimouri?source=post_page-----1d0b47be10ec--------------------------------)[![Ilia
    Teimouri PhD](../Images/0eb948c4d3f81c116cd16fa4d5016629.png)](https://medium.com/@ilia.teimouri?source=post_page-----1d0b47be10ec--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1d0b47be10ec--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1d0b47be10ec--------------------------------)
    [Ilia Teimouri PhD](https://medium.com/@ilia.teimouri?source=post_page-----1d0b47be10ec--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbf9b9036159&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-good-description-is-all-you-need-1d0b47be10ec&user=Ilia+Teimouri+PhD&userId=bf9b9036159&source=post_page-bf9b9036159----1d0b47be10ec---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1d0b47be10ec--------------------------------)
    ·7 min read·Aug 10, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1d0b47be10ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-good-description-is-all-you-need-1d0b47be10ec&user=Ilia+Teimouri+PhD&userId=bf9b9036159&source=-----1d0b47be10ec---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbf9b9036159&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-good-description-is-all-you-need-1d0b47be10ec&user=Ilia+Teimouri+PhD&userId=bf9b9036159&source=post_page-bf9b9036159----1d0b47be10ec---------------------post_header-----------)
    发表在[Towards Data Science](https://towardsdatascience.com/?source=post_page-----1d0b47be10ec--------------------------------)
    ·7分钟阅读·2023年8月10日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1d0b47be10ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-good-description-is-all-you-need-1d0b47be10ec&user=Ilia+Teimouri+PhD&userId=bf9b9036159&source=-----1d0b47be10ec---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1d0b47be10ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-good-description-is-all-you-need-1d0b47be10ec&source=-----1d0b47be10ec---------------------bookmark_footer-----------)![](../Images/03be7b5832a9d134961e51b08dd7a5a7.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1d0b47be10ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-good-description-is-all-you-need-1d0b47be10ec&source=-----1d0b47be10ec---------------------bookmark_footer-----------)![](../Images/03be7b5832a9d134961e51b08dd7a5a7.png)'
- en: Photo by [Patrick Tomasso](https://unsplash.com/@impatrickt) on [Unsplash](https://unsplash.com/).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 由[Patrick Tomasso](https://unsplash.com/@impatrickt)拍摄，来源于[Unsplash](https://unsplash.com/)。
- en: I have been using large language models (LLMs) for a while now, both for personal
    projects and as part of my day-to-day work. Like many people, I am excited by
    the powerful capabilities of these models. Yet it’s important to know that while
    these models are very strong, one can always improve them for various tasks.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经使用大语言模型（LLMs）一段时间了，既用于个人项目，也作为日常工作的组成部分。像许多人一样，我对这些模型的强大能力感到兴奋。然而，重要的是要知道，尽管这些模型非常强大，但仍然可以针对各种任务进行改进。
- en: And NO, I am not going to write about [fine-tuning LLMs](https://platform.openai.com/docs/guides/fine-tuning),
    which can be costly and often requires a good GPU-powered device. In fact, I’m
    going to show you a very simple method of improving your model using few-shot
    learning.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 而且不，我不会写关于[微调LLMs](https://platform.openai.com/docs/guides/fine-tuning)的内容，因为这可能会很昂贵，并且通常需要一台好的GPU设备。事实上，我将展示一种非常简单的使用少量学习来改善你的模型的方法。
- en: 'Few-shot learning is a machine learning technique where models are trained
    to solve new tasks using only a few examples, often just 1–5 examples per class.
    There are a number of key points to few-shot learning:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 少样本学习是一种机器学习技术，其中模型通过仅使用少量示例（通常每类仅1–5个示例）来解决新任务。少样本学习有一些关键点：
- en: 'Learning to generalize from small data: Few-shot learning methods aim to learn
    models that can generalize well from a small number of examples, in contrast to
    traditional deep learning methods that require thousands or millions of examples.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从小数据中学习归纳：少样本学习方法旨在学习能够从少量示例中很好地归纳模型，这与传统的深度学习方法（需要数千或数百万个示例）形成对比。
- en: 'Transfer learning: Few-shot learning methods leverage knowledge gained from
    solving previous tasks and transfer that knowledge to help learn new tasks faster
    and from less data. This transfer learning capability is key.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迁移学习：少样本学习方法利用从解决先前任务中获得的知识，并将这些知识转移到帮助更快地学习新任务和更少的数据。这种迁移学习能力是关键。
- en: 'Learning similarity metrics: Some few-shot learning techniques focus on learning
    a similarity metric between examples. This allows comparing new examples to existing
    labeled examples to make predictions.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习相似度度量：一些少样本学习技术专注于学习示例之间的相似度度量。这允许将新示例与现有标记示例进行比较以进行预测。
- en: But how can one use few-shot learning in a classification problem to improve
    model performance? Let’s walk through an example.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 但如何在分类问题中使用少样本学习以提高模型性能？让我们通过一个例子来演示。
- en: Data and Prep
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据和准备
- en: I have started my analysis by obtaining data from HuggingFace. The dataset is
    called [financial-reports-sec](https://huggingface.co/datasets/JanosAudran/financial-reports-sec)
    (This dataset has Apache License 2.0 and permits for commercial use), and according
    to the dataset authors, it contains the annual reports of U.S. public companies
    filing with the SEC [EDGAR system](https://www.sec.gov/edgar/sec-api-documentation)
    from 1993–2020\. Each annual report (10-K filing) is divided into 20 sections.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我通过从HuggingFace获取数据来开始我的分析。数据集名为[financial-reports-sec](https://huggingface.co/datasets/JanosAudran/financial-reports-sec)（该数据集具有Apache许可证2.0并允许商业使用），根据数据集作者的说法，它包含了1993–2020年美国上市公司向SEC
    [EDGAR系统](https://www.sec.gov/edgar/sec-api-documentation)提交的年度报告（10-K文件）。每份年度报告（10-K文件）被分为20个部分。
- en: 'Two relevant attributes of this data are useful for the current task:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当前任务的两个相关属性对数据很有用：
- en: '**Sentence**: Excerpts from the 10-K filing reports'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**句子**：来自10-K文件报告的摘录'
- en: '**Section**: Labels denoting the section of the 10-K filing that the sentence
    belongs to'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**部分**：标记句子所属的10-K文件部分'
- en: 'I have focused on three sections:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我关注了三个部分：
- en: 'Business (Item 1): Describes the company’s business, including subsidiaries,
    markets, recent events, competition, regulations, and labor. Denoted by 0 in the
    data.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 业务（项目1）：描述公司的业务，包括子公司、市场、最近事件、竞争、法规和劳动力。在数据中用0表示。
- en: 'Risk Factors (Item 1A): Discusses risks that could impact the company, such
    as external factors, potential failures, and other disclosures to warn investors.
    Denoted by 1.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 风险因素（项目1A）：讨论可能影响公司的风险，例如外部因素、潜在故障和其他警告投资者的披露。用1表示。
- en: 'Properties (Item 2): Details significant physical property assets. Does not
    include intellectual or intangible assets. Denoted by 3.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 属性（项目2）：详细说明重要的实物资产。不包括知识产权或无形资产。在数据中用3表示。
- en: 'For each label, I sampled 10 examples without replacement. The data is structured
    as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个标签，我抽取了10个示例（不放回）。数据结构如下：
- en: '![](../Images/7efd497ca2a4c2bd5f4fa465874d2a60.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7efd497ca2a4c2bd5f4fa465874d2a60.png)'
- en: '**Off the shelf** prediction'
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**现成**预测'
- en: Once the data is ready, all I have to do is to make a classifier function that
    takes the sentence from the dataframe and predicts the label.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据准备好，我所要做的就是制作一个分类器函数，该函数从数据框中获取句子并预测标签。
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'I’m using GPT-4 here since it’s OpenAI’s most capable model so far. I’ve also
    set the temperature to 0 just to make sure the model does not go off track. The
    really fun part is how I define the Role — that’s where I get to guide the model
    on what I want it to do. The Role tells it to stay focused and deliver the kind
    of output I’m looking for. Defining a clear role for the model helps it generate
    relevant, high-quality responses. The prompt in this function is:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这里使用GPT-4，因为这是迄今为止OpenAI最强大的模型。我还将温度设置为0，以确保模型不会偏离轨道。真正有趣的部分是如何定义角色——这就是我可以指导模型做我想要它做的事情的地方。角色指示模型保持专注并提供我所期望的输出。为模型定义一个清晰的角色有助于生成相关的、高质量的响应。这个功能中的提示是：
- en: You are expert in SEC 10-K forms.
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你是SEC 10-K表格的专家。
- en: You will be presented by a text and you need to classify the text into either
    ‘Item 1’, ‘Item 1A’ or ‘Item 2’.
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你将收到一段文本，你需要将文本分类为‘第1项’，‘第1A项’或‘第2项’。
- en: The text only belongs to one of the mentioned categories so only return one
    category.
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 文本只属于提到的一个类别，因此只返回一个类别。
- en: After applying the classification function across all data rows, I generated
    a classification report to evaluate model performance. The macro average F1 score
    was 0.62, indicating reasonably strong predictive capabilities for this multi-class
    problem. Since the number of examples was balanced across all 3 classes, the macro
    and weighted averages converged to the same value. This baseline score reflects
    the out-of-the-box accuracy of the pretrained model prior to any additional tuning
    or optimization.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在对所有数据行应用分类功能后，我生成了一个分类报告来评估模型的性能。宏平均F1分数为0.62，表明该多类问题的预测能力相当强。由于所有3个类别的示例数量均衡，宏平均和加权平均值收敛到相同的值。这个基准分数反映了在任何额外调整或优化之前，预训练模型的开箱即用的准确性。
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Description is all you need (few-shot prediction)
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 描述是你所需要的（少样本预测）
- en: 'As mentioned, few-shot learning is all about generalising the model with a
    few good examples. To that end, I’ve modified my class by describing what Item
    1, Item 1A and Item2 are ([based on Wikipedia](https://en.wikipedia.org/wiki/Form_10-K)):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，少样本学习就是通过少量好的示例来推广模型。为此，我通过描述第1项、第1A项和第2项是什么（[基于维基百科](https://en.wikipedia.org/wiki/Form_10-K)）来修改了我的类别：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The prompt now reads:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的提示是：
- en: You are expert in SEC 10-K forms.
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你是SEC 10-K表格的专家。
- en: You will be presented by a text and you need to classify the text into either
    ‘Item 1’, ‘Item 1A’ or ‘Item 2’.
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你将收到一段文本，你需要将文本分类为‘第1项’，‘第1A项’或‘第2项’。
- en: The text only belongs to one of the mentioned categories so only return one
    category.
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 文本只属于提到的一个类别，因此只返回一个类别。
- en: '**In your classification take the following definitions into account:**'
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**在你的分类中考虑以下定义：**'
- en: ''
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Item 1 (i.e. Business) describes the business of the company: who and what
    the company does, what subsidiaries it owns, and what markets it operates in.'
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**第1项（即业务）描述了公司的业务：公司是谁，做什么，拥有哪些子公司，以及运营的市场。**'
- en: It may also include recent events, competition, regulations, and labor issues.
    (Some industries are heavily regulated, have complex labor requirements, which
    have significant effects on the business.)
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 它还可能包括近期事件、竞争、法规和劳动问题。（一些行业受到严格监管，具有复杂的劳动要求，这些都对业务产生重大影响。）
- en: Other topics in this section may include special operating costs, seasonal factors,
    or insurance matters.**
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本节中的其他主题可能包括特殊操作成本、季节性因素或保险问题。**
- en: ''
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Item 1A (i.e. Risk Factors) is the section where the company lays anything
    that could go wrong, likely external effects, possible future failures to meet
    obligations, and other risks disclosed to adequately warn investors and potential
    investors.**'
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**第1A项（即风险因素）是公司列出可能出现问题的部分，包括可能的外部影响、未来未能履行义务的可能性以及其他风险，以充分警示投资者和潜在投资者。**'
- en: ''
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Item 2 (i.e. Properties) is the section that lays out the significant properties,
    physical assets, of the company. This only includes physical types of property,
    not intellectual or intangible property.**'
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**第2项（即属性）是列出公司重要属性、实物资产的部分。这仅包括实物类型的财产，而不包括知识产权或无形财产。**'
- en: 'If we run this on the texts we get the following performance:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在这些文本上运行，就会得到以下性能：
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The macro average **F1 is now 0.80, that is 29%** improvement in our prediction,
    only by providing a good description of each class.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**宏平均F1现在是0.80，也就是我们的预测提升了29%**，这仅仅是通过提供每个类别的良好描述。'
- en: 'Finally you can see the full dataset:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，你可以查看完整的数据集：
- en: '![](../Images/ac490bda07bc6c8fd2c5bc560fd643b0.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ac490bda07bc6c8fd2c5bc560fd643b0.png)'
- en: In fact the examples I provided gives the model concrete instances to learn
    from. Examples allow the model to infer patterns and features, by looking at multiple
    examples, the model can start to notice commonalities and differences that characterise
    the overall concept being learned. This helps the model form a more robust representation.
    Furthermore, providing examples essentially acts as a weak form of supervision,
    guiding the model towards the desired behaviour in lieu of large labeled datasets.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我提供的示例为模型提供了具体的学习实例。通过查看多个示例，模型可以推断出模式和特征，开始注意到标志总体概念的共同点和差异。这有助于模型形成更为稳健的表示。此外，提供示例本质上充当了一种弱监督形式，引导模型朝着期望的行为发展，而不依赖于大型标记数据集。
- en: In the few-shot function, concrete examples help point the model to the types
    of information and patterns it should pay attention to. In summary, concrete examples
    are important for few-shot learning as they provide anchor points for the model
    to build an initial representation of a novel concept, which can then be refined
    over the few examples provided. The inductive learning from specific instances
    helps models develop nuanced representations of abstract concepts.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在少量样本功能中，具体示例帮助引导模型关注应注意的信息和模式。总之，具体示例对少量样本学习至关重要，因为它们为模型提供了建立新概念初步表示的锚点，然后可以在提供的少量示例中进行细化。通过特定实例的归纳学习帮助模型形成抽象概念的细致表示。
- en: 'If you’ve enjoyed reading this and want to keep in touch, you can find me on
    my [LinkedIn](https://www.linkedin.com/in/iliateimouri/) or via my webpage: [iliateimouri.com](https://www.iliateimouri.com)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢阅读这些内容并希望保持联系，你可以在我的[LinkedIn](https://www.linkedin.com/in/iliateimouri/)上找到我，或通过我的网页：[iliateimouri.com](https://www.iliateimouri.com)
- en: '*Note: All images, unless otherwise noted, are by the author.*'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：所有图片，除非另有说明，均由作者提供。*'
