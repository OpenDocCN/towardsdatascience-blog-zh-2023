- en: Cooking with Snowflake
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Snowflake 进行数据处理
- en: 原文：[https://towardsdatascience.com/cooking-with-snowflake-833a1139ab01?source=collection_archive---------6-----------------------#2023-05-17](https://towardsdatascience.com/cooking-with-snowflake-833a1139ab01?source=collection_archive---------6-----------------------#2023-05-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/cooking-with-snowflake-833a1139ab01?source=collection_archive---------6-----------------------#2023-05-17](https://towardsdatascience.com/cooking-with-snowflake-833a1139ab01?source=collection_archive---------6-----------------------#2023-05-17)
- en: Snowflake optimisation
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Snowflake 优化
- en: Simple recipes & instant gratification on your Data Warehouse
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简单的配方与数据仓库中的即时满足
- en: '[](https://medium.com/@pbd_94?source=post_page-----833a1139ab01--------------------------------)[![Prabodh
    Agarwal](../Images/c4aa2193795fbc56edecbd78172da021.png)](https://medium.com/@pbd_94?source=post_page-----833a1139ab01--------------------------------)[](https://towardsdatascience.com/?source=post_page-----833a1139ab01--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----833a1139ab01--------------------------------)
    [Prabodh Agarwal](https://medium.com/@pbd_94?source=post_page-----833a1139ab01--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@pbd_94?source=post_page-----833a1139ab01--------------------------------)[![Prabodh
    Agarwal](../Images/c4aa2193795fbc56edecbd78172da021.png)](https://medium.com/@pbd_94?source=post_page-----833a1139ab01--------------------------------)[](https://towardsdatascience.com/?source=post_page-----833a1139ab01--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----833a1139ab01--------------------------------)
    [Prabodh Agarwal](https://medium.com/@pbd_94?source=post_page-----833a1139ab01--------------------------------)'
- en: ·
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9856a06a88a6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcooking-with-snowflake-833a1139ab01&user=Prabodh+Agarwal&userId=9856a06a88a6&source=post_page-9856a06a88a6----833a1139ab01---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----833a1139ab01--------------------------------)
    ·10 min read·May 17, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F833a1139ab01&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcooking-with-snowflake-833a1139ab01&user=Prabodh+Agarwal&userId=9856a06a88a6&source=-----833a1139ab01---------------------clap_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9856a06a88a6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcooking-with-snowflake-833a1139ab01&user=Prabodh+Agarwal&userId=9856a06a88a6&source=post_page-9856a06a88a6----833a1139ab01---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----833a1139ab01--------------------------------)
    ·10 分钟阅读·2023年5月17日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F833a1139ab01&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcooking-with-snowflake-833a1139ab01&user=Prabodh+Agarwal&userId=9856a06a88a6&source=-----833a1139ab01---------------------clap_footer-----------)'
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F833a1139ab01&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcooking-with-snowflake-833a1139ab01&source=-----833a1139ab01---------------------bookmark_footer-----------)![](../Images/73dfb2244fbf2936dcb1412336728421.png)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F833a1139ab01&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcooking-with-snowflake-833a1139ab01&source=-----833a1139ab01---------------------bookmark_footer-----------)![](../Images/73dfb2244fbf2936dcb1412336728421.png)'
- en: Generated using Midjourney (paid subscription)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Midjourney 生成（付费订阅）
- en: The Snowflake community is rife with information dumps on how to optimize expensive
    queries. We know because we combed through a ton of them. What we present here
    are three tactical ways in which we’ve done this at [Toplyne](https://www.toplyne.io/).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Snowflake 社区充斥着有关如何优化昂贵查询的信息倾销。我们知道这一点，因为我们翻阅了大量这样的信息。我们在这里展示的是我们在[Toplyne](https://www.toplyne.io/)中采用的三种战术方法。
- en: Toplyne’s business involves extracting real-time insights from real-time data.
    This data is currently sourced from our customers’ Product Analytics, CRM, and
    payments system.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Toplyne 的业务涉及从实时数据中提取实时洞察。这些数据目前来源于我们客户的产品分析、CRM 和支付系统。
- en: CRM and payment data volumes are mostly manageable. A product will have a limited
    set of paying customers and marginally more who are tracked in a CRM. However,
    product analytics data is much higher in volume.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: CRM 和支付数据的体量大多是可控的。一个产品会有有限的付费客户，以及在 CRM 中跟踪的略多一些的客户。然而，产品分析数据的体量要大得多。
- en: 'Toplyne’s POC (proof-of-concept) and MVP (minimum viable product) were built
    on product analytics data. We knew right from the beginning we needed to use a
    Data Warehousing solution to handle the data. The solution had to pass two clear
    requirements:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Toplyne 的POC（概念验证）和MVP（最简可行产品）是基于产品分析数据构建的。我们从一开始就知道需要使用数据仓库解决方案来处理这些数据。该解决方案必须满足两个明确的要求：
- en: It should easily ingest a few 100 gigabytes of data.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它应该能轻松处理几百GB的数据。
- en: It should offer a simple yet concise API to interact with this data.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它应该提供一个简单而简明的 API 来与这些数据交互。
- en: 'We compared 3 solutions: BigQuery, Redshift & Snowflake.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们比较了三种解决方案：BigQuery、Redshift 和 Snowflake。
- en: Post-exploration, Snowflake was a clear choice. The simple reason is its SQL-based
    interface. SQL meant there was no cold start latency for our engineering ops.
    None of the engineers at Toplyne came from a DWH background, still, we found ourselves
    up to speed very quickly.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 探索后，Snowflake 是明显的选择。简单的原因是它的 SQL 基础接口。SQL 意味着我们的工程操作没有冷启动延迟。Toplyne 的工程师没有来自
    DWH 背景的经验，但我们很快上手了。
- en: 'The process of interacting with customers’ product analytics data is simple
    as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 与客户产品分析数据交互的过程简单如下：
- en: The product analytics data lands into Snowflake via a connector. (There are
    a lot of over-the-counter as well as native connectors for the same).
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 产品分析数据通过连接器进入 Snowflake。（有很多现成的和本地的连接器可以使用）。
- en: Login to Snowflake and use the in-built worksheets to write SQL. 🎉
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录 Snowflake 并使用内置的工作表编写 SQL。🎉
- en: This simple 2-step process means that we can get on top of the data that our
    customers share with us in no time.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的 2 步过程意味着我们可以迅速掌握客户与我们分享的数据。
- en: In a short period, we cooked up two algorithms to transform the data we receive
    into a schema that can be trained by our data scientists. The first algorithm
    took care of transforming the product analytics events data. The second took care
    of identifying users’ profile data. Additional feature engineering algorithms
    are then written on top of this data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在短时间内，我们开发了两个算法，将我们接收到的数据转换为数据科学家可以训练的模式。第一个算法负责转换产品分析事件数据。第二个算法负责识别用户的个人资料数据。然后在这些数据上编写附加的特征工程算法。
- en: SQL is a fourth-generation language (4GL) that is relatively easier to learn.
    Combined with a worksheet-based interface that just requires you to have a browser
    tab — Snowflake; a scrappy startup could do a lot of data-heavy lifting with minimal
    setup effort.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: SQL 是一种第四代语言（4GL），相对较容易学习。结合一个只需浏览器标签的基于工作表的界面——Snowflake；一个初创公司可以以最小的设置工作量完成大量的数据处理。
- en: We wrote a few SQLs in the worksheet to transform the data and then our data
    scientists could just `SELECT *` the data and write their ML training programs.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在工作表中编写了一些 SQL 语句来转换数据，然后我们的数据科学家可以直接 `SELECT *` 数据并编写他们的 ML 训练程序。
- en: 'Over time the entire above-mentioned process has scaled up significantly. The
    scaling up has happened in the following aspects:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，上述整个过程显著扩展。扩展发生在以下几个方面：
- en: We have multiple customers, each of whom has their product analytics data in
    multiple platforms viz., Amplitude, Mixpanel, Segment, Clevertap, etc.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们有多个客户，每个客户的产品分析数据分布在多个平台上，如 Amplitude、Mixpanel、Segment、Clevertap 等。
- en: Our teams have written multiple algorithms to crunch the data along different
    axes.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的团队编写了多个算法，以不同的维度处理数据。
- en: We now integrate CRM as well as payment data. Further, these datasets have their
    own set of ETL algorithms.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在集成了 CRM 和支付数据。此外，这些数据集有自己的一套 ETL 算法。
- en: We use Airflow to orchestrate enormous pipelines which have multiple stages.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用 Airflow 编排庞大的管道，这些管道有多个阶段。
- en: Sample architecture diagram of our ETL flow. Snowflake sits at the heart of
    this system.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们 ETL 流程的样本架构图。Snowflake 是该系统的核心。
- en: '![](../Images/260a503ca0b67035740ce4d76415aaa0.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/260a503ca0b67035740ce4d76415aaa0.png)'
- en: Toplyne’s Data Pipeline architecture
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Toplyne 的数据管道架构
- en: Sync source data into Snowflake.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将源数据同步到 Snowflake。
- en: Use Apache Airflow for ETL orchestration.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Apache Airflow 进行 ETL 编排。
- en: Land the transformed data into Snowflake.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将转换后的数据存入 Snowflake。
- en: DS/ML/Analysts/Product consumes data from Snowflake for their flows.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DS/ML/分析师/产品从 Snowflake 获取数据用于他们的工作流程。
- en: Over the months, there have been multiple changes and major rewrites of different
    components of the system with Snowflake being the only constant.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 几个月来，系统的不同组件经历了多次更改和重大重写，而 Snowflake 是唯一不变的。
- en: As we have run and maintained a system, we would like to present a few ideas
    around query optimization in Snowflake. We have a super simple technique that
    has allowed us to extract a lot of performance from the system with minor tweaks
    in your existing queries.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经运行并维护了一个系统，我们想提出一些关于Snowflake中查询优化的想法。我们有一种超级简单的技术，通过对现有查询进行轻微调整，能够从系统中提取出大量的性能。
- en: '**Query optimization**'
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**查询优化**'
- en: We run a multi-tenant system wherein a single Snowflake instance is responsible
    for the ETL of a lot of customer data. ETL is orchestrated by Airflow.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们运行一个多租户系统，其中单个Snowflake实例负责处理大量客户数据的ETL。ETL由Airflow编排。
- en: We create a warehouse per customer and run all the ETL & feature engineering
    on that warehouse. There are 100s of SQL queries that are fired against a warehouse
    in sequence and/or in parallel during the entire ETL run for the customer. One
    run can last for an hour and there can be multiple runs for the customer in a
    day.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为每个客户创建一个仓库，并在该仓库上运行所有ETL和特征工程。在整个ETL运行期间，对一个仓库会依次和/或并行地执行数百个SQL查询。一次运行可能持续一个小时，并且一天中可能有多次运行。
- en: Essentially, one warehouse size runs all expensive as well as cheap queries.
    So our objective is to keep warehouse size at a minimum. We define minimums by
    defining SLAs for different ETL runs. Then we modify the warehouse size so that
    ETL SLAs can be met at that size. Like any engineering org, we want to keep the
    warehouse size at a bare minimum given the SLA.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，一个仓库的大小运行所有昂贵的以及便宜的查询。因此我们的目标是将仓库大小保持在最低限度。我们通过为不同的ETL运行定义服务水平协议（SLA）来定义最小值。然后，我们调整仓库大小，以便可以在该大小下满足ETL
    SLA。像任何工程组织一样，我们希望在满足SLA的情况下将仓库大小保持在最低限度。
- en: We have dashboards where we monitor query patterns of the most expensive queries.
    These dashboards are at different levels of granularity. We monitor these dashboards
    constantly and keep tweaking the queries. Over time we have identified a few patterns
    in expensive queries and have come up with a playbook on how to minimize the run
    time of these queries. We’ll present 3 case studies outlining the problem statement
    for the query, how it was originally written, what was the bottleneck in that
    query and what was the optimal solution for the same.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有仪表板来监控最昂贵查询的查询模式。这些仪表板有不同的粒度级别。我们不断监控这些仪表板，并不断调整查询。随着时间的推移，我们识别出了一些昂贵查询中的模式，并制定了一本关于如何最小化这些查询运行时间的操作手册。我们将展示三个案例研究，概述查询的问题陈述、最初编写方式、该查询中的瓶颈以及其最终的最佳解决方案。
- en: Window queries
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 窗口查询
- en: Scenario
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 情景
- en: We track users’ profile information from product analytics data. Product Analytics
    systems save multiple data points about their users, e.g., location, device, subscription
    status, etc. Some data points change frequently while others do not so much. Given
    the nature of these data, the information is represented as an append-only log
    in a database.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从产品分析数据中跟踪用户的个人资料信息。产品分析系统保存有关用户的多个数据点，例如位置、设备、订阅状态等。一些数据点经常变化，而另一些则不那么频繁。鉴于这些数据的性质，这些信息在数据库中以追加日志的形式表示。
- en: One of our feature engineering requirements is to capture the users’ latest
    profile info as of the ETL run.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的一个特征工程需求是捕获用户最新的个人资料信息，作为ETL运行的一部分。
- en: '![](../Images/b758fff47289b6182bb792dbf288cb70.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b758fff47289b6182bb792dbf288cb70.png)'
- en: The above diagram gives a flowchart of the ETL.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 上图给出了ETL的流程图。
- en: '**1** is the raw_data from product analytics, **2** is the algorithm that we
    want to apply & **3** is the final result of the ETL.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**1** 是来自产品分析的原始数据，**2** 是我们想要应用的算法，**3** 是ETL的最终结果。'
- en: 'The SQL query that we have is this:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们拥有的SQL查询是这样的：
- en: '[PRE0]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Bottleneck
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 瓶颈
- en: This query is pretty simple to come up with and works great in Snowflake. However,
    the window function in this query is a bottleneck.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这个查询很简单，而且在Snowflake中效果很好。然而，这个查询中的窗口函数是一个瓶颈。
- en: 'Here’s how the query works:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 查询的工作原理如下：
- en: create as many logical buckets as there are `user_ids`
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建与`user_ids`数量相同的逻辑桶
- en: '`sort` data in every bucket in descending order'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每个桶中按降序`排序`数据
- en: assign `row_numbers` to the arranged data
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`row_numbers`分配给已排列的数据
- en: '`qualify` the first entry in the bucket'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`标记`桶中的第一个条目'
- en: '*discard* the remaining data.'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*丢弃*剩余的数据。'
- en: Based on the above explanation, we can see that as the data in the table increases,
    the number of buckets and the bucket sizes both will increase. Since we are dealing
    with an append-only dataset, we should be prepared for this eventuality. In Snowflake,
    you’ll notice the size increase trend as **Byte Spillage** in your query profiler.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 根据上述解释，我们可以看到，随着表中数据的增加，桶的数量和桶的大小都会增加。由于我们处理的是仅追加数据集，我们应该为这种情况做好准备。在 Snowflake
    中，您会在查询分析器中注意到大小增加的趋势，表现为**字节溢出**。
- en: Further, we need to understand that based on business requirements, it is expected
    for the number of buckets to increase, but as engineers, we can still keep the
    **size of an individual bucket** to a minimum.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们需要理解，根据业务需求，桶的数量预计会增加，但作为工程师，我们仍然可以将**单个桶的大小**保持到最小。
- en: Optimal solution
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最优解决方案
- en: We’ll come up with a technique to keep the entries being bucketed to a minimum
    by using **CTEs** & an **aggregate function**.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将采用一种技术，通过使用**CTE**和**聚合函数**来将桶的数量保持到最小。
- en: '[PRE1]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We convert our `descending sort expression` in-the-window query clause to the
    `max() function` and then join that to our source data to obtain a filter. By
    using this filter, we ensure that the data that would have been *discarded* by
    the `qualify` clause anyways would never be bucketed in the first place. This
    reduces the work performed by the window query drastically. Also, the additional
    cost of using an aggregate function is massively offset by the reduction, so the
    overall query becomes performant.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将 `descending sort expression` 的窗口查询子句转换为 `max() function`，然后将其与源数据连接以获得过滤器。通过使用此过滤器，我们确保数据不会被
    `qualify` 子句丢弃，从而一开始就不会被桶化。这大大减少了窗口查询所执行的工作。此外，使用聚合函数的额外成本被减少的成本大大抵消，因此整体查询变得高效。
- en: Pivot queries
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Pivot 查询
- en: Scenario
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 场景
- en: We use a feature on event data that requires getting a per-user per-event count.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用事件数据中的一个功能，该功能要求获取每个用户每个事件的计数。
- en: To obtain this data, we perform a group by query and then transpose this data
    to organize it into columns as shown in the image below.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得这些数据，我们执行一个分组查询，然后将这些数据转置以组织成列，如下图所示。
- en: '**1** is the raw data & **2** is the output after the transformation.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**1** 是原始数据，**2** 是转换后的输出。'
- en: '![](../Images/23964d6ab2492da9ff62c5fd92a86fd3.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/23964d6ab2492da9ff62c5fd92a86fd3.png)'
- en: 'The SQL query that we have is this:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 SQL 查询如下：
- en: '[PRE2]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Bottleneck
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 瓶颈
- en: Although the sample shows a pivot along 3 elements, our production use case
    generally functions on around a million users for approximately 1000 events.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管示例显示了沿着 3 个元素的 pivot，但我们的生产用例通常在大约 1000 个事件的情况下处理大约一百万用户。
- en: The pivot function on this query is the slowest step of the query. So we want
    to replace this logic with a manual pivot query. We generate this query by using
    a combination of `Group By` clause & `Filter clause`.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 此查询中的 pivot 函数是查询中最慢的步骤。因此，我们希望用手动 pivot 查询替换此逻辑。我们通过结合使用 `Group By` 子句和 `Filter`
    子句来生成此查询。
- en: Optimal solution 1
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最优解决方案 1
- en: '[PRE3]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This query improved performance significantly.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这个查询显著提高了性能。
- en: We then **reduced** the warehouse size to see if the query remains equally performant.
    We observed that the query slowed down significantly and **byte spillage** was
    significant. However, an advantage of byte spillage is that we have more room
    for improvement in the reduced warehouse size.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们**减少**了仓库的大小，以查看查询是否保持同样的性能。我们观察到查询显著变慢，并且**字节溢出**也很严重。然而，字节溢出的一个优点是，我们在减少的仓库大小中有更多的改进空间。
- en: Optimal Solution 2
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最优解决方案 2
- en: We rewrote this query as per the **Map-Reduce** framework and observed a significant
    improvement in runtime.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们根据**Map-Reduce**框架重写了此查询，并观察到运行时间显著改善。
- en: 'The objective is to perform the above operation on a smaller set of events
    at a time and join all the data together in one go as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是对较小的事件集执行上述操作，然后一次性将所有数据合并在一起，如下所示：
- en: '[PRE4]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Our production system will break up **1000 events** into **10 chunks** of **100
    events** each. This query speeds up significantly as it reduces byte spillage
    to near 0.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的生产系统将**1000个事件**拆分成**10个块**，每块包含**100个事件**。此查询显著加速，因为它将字节溢出减少到接近 0。
- en: Also, this optimization is quite intuitive to derive once we replace the Pivot
    function with Optimal Solution 1.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一旦我们用最优解决方案 1 替换 Pivot 函数，这个优化是非常直观的。
- en: '*Scroll to the bottom to find some accompaniment code for this article.*'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '*向下滚动以查找本文的配套代码。*'
- en: Aggregate queries
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚合查询
- en: SQL spec defines a lot of aggregate functions and Snowflake does a great job
    at this. There is a massive repository of aggregate functions in Snowflake as
    well.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: SQL规范定义了许多汇总函数，Snowflake在这方面表现出色。Snowflake中也有一个庞大的汇总函数库。
- en: Different aggregate functions have varying runtimes and in our opinion, every
    aggregate function should be treated on its merit. A strategy for optimizing aggregate
    functions is to first identify aggregate functions to be a bottleneck and then
    motivate yourself that there **might** be an algorithmic solution to your problem
    statement.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的汇总函数有不同的运行时间，在我们看来，每个汇总函数都应根据其优点进行处理。优化汇总函数的策略是首先识别出成为瓶颈的汇总函数，然后激励自己相信**可能**存在算法解决方案。
- en: We would like to share one case study with you where we identified a query in
    which a suboptimal aggregate function was chosen. We redid the algorithm for the
    solution using a simpler aggregate function thereby getting a far superior performance
    for the same result.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想与您分享一个案例研究，在这个案例中，我们识别了一个查询，其中选择了一个次优的汇总函数。我们重新设计了该解决方案的算法，使用了一个更简单的汇总函数，从而获得了相同结果的更优性能。
- en: Scenario
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 情景
- en: We have a time series of events that are fired in the product analytics system.
    We need to answer 2 questions from this dataset for one of feature engineering.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个事件时间序列，这些事件在产品分析系统中触发。我们需要从这个数据集中回答两个问题，以进行特征工程。
- en: Q1) Identify all data points that are mostly fired multiple times within a second
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Q1) 识别所有在一秒内大多被多次触发的数据点
- en: Q2) Identify data points that are mostly fired at least an hour apart
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Q2) 识别大多在至少一小时间隔内触发的数据点
- en: '![](../Images/94bc234e71ecdc85f1c613ee208e0eef.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/94bc234e71ecdc85f1c613ee208e0eef.png)'
- en: To answer these questions, we transform input data in `tbl_1` to `tbl_2` using
    a **window query** with the Snowflake **lag function**.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这些问题，我们使用Snowflake的**window query**和**lag function**将`tbl_1`中的输入数据转换为`tbl_2`。
- en: We then write the solution query using the **median function** as follows.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用**median function**编写了解决方案查询。
- en: '[PRE5]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Bottleneck
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 瓶颈
- en: The `median` function is super slow.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '`median`函数非常慢。'
- en: We asked ChatGPT to suggest an optimal solution. It did come up with a solution
    to use a **Percentile** function, but that was equally slow and seemed synonymous
    with the **Median** function itself.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们让ChatGPT建议一个最佳解决方案。它确实提出了使用**Percentile**函数的解决方案，但这同样很慢，并且似乎与**Median**函数本身类似。
- en: However, ChatGPT did a good job of explaining why it came up with that solution.
    We then came up with a solution by iterating & improving ChatGPT’s solution.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，ChatGPT很好地解释了为什么提出了那个解决方案。然后我们通过迭代和改进ChatGPT的解决方案，提出了一个新的解决方案。
- en: Optimal solution
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最优解决方案
- en: We identified that for our requirement, we can just use count queries. For both
    **Q1)** & **Q2)**, we want the majority of our events to have **sec_diff** & **hour_diff**
    respectively equal to & greater than 0.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确定，对于我们的需求，我们只需使用计数查询。对于**Q1)**和**Q2)**，我们希望大多数事件的**sec_diff**和**hour_diff**分别大于或等于0。
- en: '[PRE6]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Lessons learned
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 经验教训
- en: We observe our systems constantly and then identify what optimizations require
    urgent analysis and what can be backlogged.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们持续观察我们的系统，然后确定哪些优化需要紧急分析，哪些可以积压。
- en: Snowflake provides multiple configuration parameters which can be tuned in conjunction
    to obtain performance. The Snowflake community regularly publishes tricks & techniques.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Snowflake提供了多个配置参数，可以进行调优以获得性能。Snowflake社区定期发布技巧和技术。
- en: Among all this information overload, we need to focus and build a playbook &
    a repo of techniques that works for us and can be applied mindlessly.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些信息过载中，我们需要专注并建立一个适合我们的剧本和技术库，这些技术可以毫不费力地应用。
- en: 'These are the parameters that we use for our purpose:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我们用于目的的参数：
- en: Inspect every node in the query profiler
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查查询分析器中的每个节点
- en: Do an input v/s output ratio for the node
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对节点进行输入与输出比率分析
- en: i) Try to bring down this ratio
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: i) 尝试降低这个比率
- en: ii) The output will remain constant given a problem statement
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ii) 给定问题描述时，输出将保持不变
- en: iii) Hence, try to reduce input to the aggregate node
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: iii) 因此，尽量减少对汇总节点的输入
- en: Another way is to constantly measure the disk spillage. Reduce spillage whenever
    possible
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 另一种方法是持续测量磁盘溢出。尽可能减少溢出
- en: i) Larger warehouses have low spillage but also cost higher
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: i) 较大的仓库有较低的溢出，但成本也较高
- en: ii) You get optimization only if you can reduce spillage in the same warehouse
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ii) 只有在减少同一仓库中的溢出时，你才能获得优化
- en: '***Reproducing this article as code:*** You can refer [this github link](https://github.com/prabodh1194/sf-query-benchmarks)
    for code related to benchmarking of these queries.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '***将本文作为代码复现：*** 你可以参考[这个 GitHub 链接](https://github.com/prabodh1194/sf-query-benchmarks)来获取与这些查询的基准测试相关的代码。'
- en: Conclusion
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: The article provides three highly actionable optimization techniques that you
    can apply right away. You might have a suboptimal pattern in your codebase that
    is similar to the case we have presented here. Feel free to use the code examples
    to get an instant resolution. In any other scenario, put on the thinking hat and
    I’ll be excited to learn about your solutions.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章提供了三种高度可操作的优化技术，你可以立即应用。你可能在代码库中有类似于我们这里展示的情况的次优模式。随时使用这些代码示例来获得即时解决方案。在其他情况下，请动脑筋，我将很高兴了解你的解决方案。
- en: '[Follow me](https://medium.com/@pbd_94) for more articles on Snowflake, Data,
    and MLOps.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注我](https://medium.com/@pbd_94)以获取更多关于 Snowflake、数据和 MLOps 的文章。'
- en: P.S. All the images unless noted otherwise are from the author
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 附言：除非另有说明，否则所有图片均来自作者。
