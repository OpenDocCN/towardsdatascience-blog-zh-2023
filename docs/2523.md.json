["```py\nflorida = [-2.40062016,  0.00478901]\ncalifornia = [-2.54245794, -0.37579669]\ntexas = [-2.24764634, -0.12963368]\npolitics = [3.02004564,  2.88826688]\ntruth = [4.17067881, -2.38762552]\n```", "```py\nimport pandas as pd\n\npath_to_glove_embds = 'glove.6B.100d.txt'\n\nglove = pd.read_csv(path_to_glove_embds, sep=\" \", header=None, index_col=0)\nglove_embedding = {key: val.values for key, val in glove.T.items()}\n```", "```py\nwords = ['florida', 'california', 'texas', 'politics', 'truth']\nword_embeddings = [glove_embedding[word] for word in words]\n\nprint(word_embeddings[0]).shape # 100 numbers to represent each word.\n---------------------\noutput:\n(100,)\n```", "```py\npca = PCA(n_components=2) # reduce dimensionality from 100 to 2.\nword_embeddings_pca = pca.fit_transform(word_embeddings)\n```", "```py\nfor i in range(5):\n    print(word_embeddings_pca[i])\n\n---------------------\noutput:\n[-2.40062016  0.00478901] # florida\n[-2.54245794 -0.37579669] # california\n[-2.24764634 -0.12963368] # texas\n[3.02004564 2.88826688] # politics\n[ 4.17067881 -2.38762552] # truth\n```", "```py\nimport numpy as np\n\nflorida_vector = [-2.40062016,  0.00478901]\nflorida_vector_magnitude = np.linalg.norm(florida_vector)\n\nprint(florida_vector_magnitude)\n---------------------\noutput:\n2.4006249368060817 # The magnitude of the vector \"florida\" is 2.4.\n```", "```py\nimport numpy as np\n\nflorida_vector = [-2.40062016,  0.00478901]\ntexas_vector = [-2.24764634 -0.12963368]\n\nprint(np.dot(florida_vector, texas_vector))\n\n---------------------\noutput:\n5.395124299364358\n```", "```py\nimport numpy as np\n\nflorida_vector = [-2.40062016,  0.00478901]\ntruth_vector = [4.17067881, -2.38762552]\n\nprint(np.dot(florida_vector, truth_vector))\n\n---------------------\noutput:\n-10.023649994662344\n```", "```py\n# x being the input.\n\n(x - mean(x)) / sqrt(variance(x) + epsilon) * gamma + beta\n```"]