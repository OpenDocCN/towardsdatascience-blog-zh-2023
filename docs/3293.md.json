["```py\nθ(0) = θ_init       # Initialization of optimization variable\nη = 0.02            # Arbitrary step-size parameter\nЄ = 0.01            # Optimization accuracy\nk = 0               # Iteration counter\n\nwhile |f(θ(k+1) - f(θ(k))| > Є:\n θ(k+1) = θ(k) - η ∇f(θ(k))\n k = k + 1\n```", "```py\nw = [0, ... ,0]    # Initialize the weights\nfor k = 1,..., n_iters:          # Repeat for n iterations\n  grad = ∇w TrainLoss(w)         # Gradient of the Training losses \n\n  w[k] <-- w[k-1] - η * grad     # Update the model weights\n```", "```py\nw = [0, ... ,0]                          # Initialize the weights\nfor k = 1,..., n_epoch:      \n    for (x, y) ∈ Dtrain:                 # For each sample \n        grad = ∇w J(x,y,w)              \n        w[k] <--  w[k-1] - η(k) * grad   # Update the model weights\n```"]