- en: Why and How to Adjust P-values in Multiple Hypothesis Testing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆä»¥åŠå¦‚ä½•åœ¨å¤šé‡å‡è®¾æ£€éªŒä¸­è°ƒæ•´På€¼
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/why-and-how-to-adjust-p-values-in-multiple-hypothesis-testing-2ccf174cdbf8?source=collection_archive---------0-----------------------#2023-05-05](https://towardsdatascience.com/why-and-how-to-adjust-p-values-in-multiple-hypothesis-testing-2ccf174cdbf8?source=collection_archive---------0-----------------------#2023-05-05)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/why-and-how-to-adjust-p-values-in-multiple-hypothesis-testing-2ccf174cdbf8?source=collection_archive---------0-----------------------#2023-05-05](https://towardsdatascience.com/why-and-how-to-adjust-p-values-in-multiple-hypothesis-testing-2ccf174cdbf8?source=collection_archive---------0-----------------------#2023-05-05)
- en: P-values below a certain threshold are often used as a method to select relevant
    features. Advice below suggests how to use them correctly.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åœ¨é€‰æ‹©ç›¸å…³ç‰¹å¾æ—¶ï¼Œé€šå¸¸ä¼šä½¿ç”¨ä½äºæŸä¸ªé˜ˆå€¼çš„På€¼ä½œä¸ºä¸€ç§æ–¹æ³•ã€‚ä»¥ä¸‹å»ºè®®è¯´æ˜äº†å¦‚ä½•æ­£ç¡®ä½¿ç”¨å®ƒä»¬ã€‚
- en: '[](https://medium.com/@igor-s?source=post_page-----2ccf174cdbf8--------------------------------)[![Igor
    Å egota](../Images/17c592b71fef9526a0679d47937837f6.png)](https://medium.com/@igor-s?source=post_page-----2ccf174cdbf8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2ccf174cdbf8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2ccf174cdbf8--------------------------------)
    [Igor Å egota](https://medium.com/@igor-s?source=post_page-----2ccf174cdbf8--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@igor-s?source=post_page-----2ccf174cdbf8--------------------------------)[![Igor
    Å egota](../Images/17c592b71fef9526a0679d47937837f6.png)](https://medium.com/@igor-s?source=post_page-----2ccf174cdbf8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2ccf174cdbf8--------------------------------)[![æ•°æ®ç§‘å­¦å‰æ²¿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2ccf174cdbf8--------------------------------)
    [Igor Å egota](https://medium.com/@igor-s?source=post_page-----2ccf174cdbf8--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe5f8ebca4ad8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-and-how-to-adjust-p-values-in-multiple-hypothesis-testing-2ccf174cdbf8&user=Igor+%C5%A0egota&userId=e5f8ebca4ad8&source=post_page-e5f8ebca4ad8----2ccf174cdbf8---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2ccf174cdbf8--------------------------------)
    Â·9 min readÂ·May 5, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2ccf174cdbf8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-and-how-to-adjust-p-values-in-multiple-hypothesis-testing-2ccf174cdbf8&user=Igor+%C5%A0egota&userId=e5f8ebca4ad8&source=-----2ccf174cdbf8---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe5f8ebca4ad8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-and-how-to-adjust-p-values-in-multiple-hypothesis-testing-2ccf174cdbf8&user=Igor+%C5%A0egota&userId=e5f8ebca4ad8&source=post_page-e5f8ebca4ad8----2ccf174cdbf8---------------------post_header-----------)
    å‘è¡¨åœ¨ [æ•°æ®ç§‘å­¦å‰æ²¿](https://towardsdatascience.com/?source=post_page-----2ccf174cdbf8--------------------------------)
    Â· 9åˆ†é’Ÿé˜…è¯» Â· 2023å¹´5æœˆ5æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2ccf174cdbf8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-and-how-to-adjust-p-values-in-multiple-hypothesis-testing-2ccf174cdbf8&user=Igor+%C5%A0egota&userId=e5f8ebca4ad8&source=-----2ccf174cdbf8---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2ccf174cdbf8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-and-how-to-adjust-p-values-in-multiple-hypothesis-testing-2ccf174cdbf8&source=-----2ccf174cdbf8---------------------bookmark_footer-----------)![](../Images/d511c23677ff0b8f644e2dbec2ba25c2.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2ccf174cdbf8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-and-how-to-adjust-p-values-in-multiple-hypothesis-testing-2ccf174cdbf8&source=-----2ccf174cdbf8---------------------bookmark_footer-----------)![](../Images/d511c23677ff0b8f644e2dbec2ba25c2.png)'
- en: Photo by the author. Taken at Westfield UTC Mall, La Jolla, California.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚æ‹æ‘„äºåŠ å·æ‹‰è·äºšçš„Westfield UTCè´­ç‰©ä¸­å¿ƒã€‚
- en: Multiple hypothesis testing occurs when we repeatedly test models on a number
    of features, as the probability of obtaining one or more false discoveries increases
    with the number of tests. For example, in the field of genomics, scientists often
    want to test whether any of the thousands of genes have a significantly different
    activity in an outcome of interest. Or whether [jellybeans cause acne](https://xkcd.com/882/).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šé‡å‡è®¾æ£€éªŒå‘ç”Ÿåœ¨æˆ‘ä»¬åœ¨å¤šä¸ªç‰¹å¾ä¸Šé‡å¤æµ‹è¯•æ¨¡å‹æ—¶ï¼Œå› ä¸ºéšç€æµ‹è¯•æ•°é‡çš„å¢åŠ ï¼Œè·å¾—ä¸€ä¸ªæˆ–å¤šä¸ªå‡å‘ç°çš„æ¦‚ç‡ä¹Ÿä¼šå¢åŠ ã€‚ä¾‹å¦‚ï¼Œåœ¨åŸºå› ç»„å­¦é¢†åŸŸï¼Œç§‘å­¦å®¶ä»¬ç»å¸¸æƒ³è¦æµ‹è¯•æˆåƒä¸Šä¸‡çš„åŸºå› ä¸­æ˜¯å¦æœ‰ä»»ä½•åŸºå› åœ¨æŸä¸ªç»“æœä¸­è¡¨ç°å‡ºæ˜¾è‘—ä¸åŒçš„æ´»æ€§ã€‚æˆ–è€…[ç³–æœæ˜¯å¦ä¼šå¯¼è‡´ç—¤ç–®](https://xkcd.com/882/)ã€‚
- en: 'In this blog post, we will cover few of the popular methods used to account
    for multiple hypothesis testing by adjusting model p-values:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡åšå®¢æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»å‡ ç§å¸¸ç”¨çš„æ–¹æ³•ï¼Œé€šè¿‡è°ƒæ•´æ¨¡å‹på€¼æ¥è€ƒè™‘å¤šé‡å‡è®¾æ£€éªŒï¼š
- en: False Positive Rate (FPR)
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å‡é˜³æ€§ç‡ï¼ˆFPRï¼‰
- en: Family-Wise Error Rate (FWER)
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å®¶åº­é”™è¯¯ç‡ï¼ˆFWERï¼‰
- en: False Discovery Rate (FDR)
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å‡é˜³æ€§ç‡ï¼ˆFDRï¼‰
- en: and explain when it makes sense to use them.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶è§£é‡Šä½•æ—¶ä½¿ç”¨è¿™äº›æ–¹æ³•æ˜¯æœ‰æ„ä¹‰çš„ã€‚
- en: 'This document can be summarized in the following image:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä»½æ–‡æ¡£å¯ä»¥æ€»ç»“ä¸ºä»¥ä¸‹å›¾åƒï¼š
- en: '![](../Images/5943b7c02580e3f0811215a96b4c40be.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5943b7c02580e3f0811215a96b4c40be.png)'
- en: Image by the author.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: Create test data
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åˆ›å»ºæµ‹è¯•æ•°æ®
- en: We will create a simulated example to better understand how various manipulation
    of p-values can lead to different conclusions. To run this code, we need Python
    with `pandas`, `numpy`, `scipy` and `statsmodels` libraries installed.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿç¤ºä¾‹ï¼Œä»¥æ›´å¥½åœ°ç†è§£å¦‚ä½•é€šè¿‡å„ç§på€¼æ“ä½œå¾—å‡ºä¸åŒçš„ç»“è®ºã€‚è¦è¿è¡Œæ­¤ä»£ç ï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…`pandas`ã€`numpy`ã€`scipy`å’Œ`statsmodels`åº“çš„Pythonç¯å¢ƒã€‚
- en: For the purpose of this example, we start by creating a Pandas DataFrame of
    1000 features. 990 of which (99%) will have their values generated from a Normal
    distribution with mean = 0, called a Null model. (In a function `norm.rvs()` used
    below, mean is set using a `loc` argument.) The remaining 1% of the features will
    be generated from a Normal distribution mean = 3, called a Non-Null model. We
    will use these as representing interesting features that we would like to discover.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è¿™ä¸ªç¤ºä¾‹ï¼Œæˆ‘ä»¬ä»åˆ›å»ºä¸€ä¸ªåŒ…å«1000ä¸ªç‰¹å¾çš„Pandas DataFrameå¼€å§‹ã€‚å…¶ä¸­990ä¸ªç‰¹å¾ï¼ˆ99%ï¼‰çš„å€¼å°†ä»å‡å€¼ä¸º0çš„æ­£æ€åˆ†å¸ƒä¸­ç”Ÿæˆï¼Œè¿™ç§°ä¸ºç©ºæ¨¡å‹ã€‚ï¼ˆåœ¨ä¸‹é¢ä½¿ç”¨çš„å‡½æ•°`norm.rvs()`ä¸­ï¼Œå‡å€¼æ˜¯é€šè¿‡`loc`å‚æ•°è®¾ç½®çš„ã€‚ï¼‰å…¶ä½™çš„1%çš„ç‰¹å¾å°†ä»å‡å€¼ä¸º3çš„æ­£æ€åˆ†å¸ƒä¸­ç”Ÿæˆï¼Œè¿™ç§°ä¸ºéç©ºæ¨¡å‹ã€‚æˆ‘ä»¬å°†ç”¨è¿™äº›ç‰¹å¾æ¥è¡¨ç¤ºæˆ‘ä»¬å¸Œæœ›å‘ç°çš„æœ‰è¶£ç‰¹å¾ã€‚
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: For each of the 1000 features, p-value is a probability of observing the value
    at least as large, if we assume it was generated from a Null distribution.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ª1000ä¸ªç‰¹å¾ä¸­çš„ç‰¹å¾ï¼Œpå€¼æ˜¯è§‚å¯Ÿåˆ°çš„å€¼è‡³å°‘å¦‚æ­¤ä¹‹å¤§ï¼ˆå‡è®¾å®ƒæ˜¯ä»ç©ºåˆ†å¸ƒç”Ÿæˆçš„ï¼‰çš„æ¦‚ç‡ã€‚
- en: 'P-values can be calculated from a cumulative distribution ( `norm.cdf()` from
    `scipy.stats`) which represents the probability of obtaining a value equal to
    or **less than** the one observed. Then to calculate the p-value we calculate
    `1 - norm.cdf()` to find the probability **greater than** the one observed:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: på€¼å¯ä»¥é€šè¿‡ç´¯ç§¯åˆ†å¸ƒï¼ˆ`norm.cdf()`æ¥è‡ª`scipy.stats`ï¼‰è®¡ç®—ï¼Œç´¯ç§¯åˆ†å¸ƒè¡¨ç¤ºè·å¾—ä¸€ä¸ªå€¼ç­‰äºæˆ–**å°äº**è§‚å¯Ÿåˆ°çš„å€¼çš„æ¦‚ç‡ã€‚ç„¶åä¸ºäº†è®¡ç®—på€¼ï¼Œæˆ‘ä»¬è®¡ç®—`1
    - norm.cdf()`æ¥æ‰¾åˆ°**å¤§äº**è§‚å¯Ÿåˆ°çš„å€¼çš„æ¦‚ç‡ï¼š
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/1e09fe5152cdf959d5bb5fa916a04c49.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e09fe5152cdf959d5bb5fa916a04c49.png)'
- en: False Positive Rate
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‡é˜³æ€§ç‡
- en: 'The first concept is called a False Positive Rate and is defined as a fraction
    of null hypotheses that we flag as â€œsignificantâ€ (also called Type I errors).
    The p-values we calculated earlier can be interpreted as a false positive rate
    by their very definition: they are probabilities of obtaining a value at least
    as large as a specified value, when we sample a Null distribution.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ä¸ªæ¦‚å¿µç§°ä¸ºå‡é˜³æ€§ç‡ï¼Œå®šä¹‰ä¸ºæˆ‘ä»¬æ ‡è®°ä¸ºâ€œæ˜¾è‘—â€çš„ç©ºå‡è®¾çš„æ¯”ä¾‹ï¼ˆä¹Ÿç§°ä¸ºç¬¬ä¸€ç±»é”™è¯¯ï¼‰ã€‚æˆ‘ä»¬ä¹‹å‰è®¡ç®—çš„på€¼å¯ä»¥æŒ‰å…¶å®šä¹‰è§£é‡Šä¸ºå‡é˜³æ€§ç‡ï¼šå®ƒä»¬æ˜¯ä»ç©ºåˆ†å¸ƒä¸­è·å–ä¸€ä¸ªå€¼è‡³å°‘ä¸æŒ‡å®šå€¼ä¸€æ ·å¤§çš„æ¦‚ç‡ã€‚
- en: 'For illustrative purposes, we will apply a common (magical ğŸ§™) p-value threshold
    of 0.05, but any threshold can be used:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è¯´æ˜ï¼Œæˆ‘ä»¬å°†åº”ç”¨ä¸€ä¸ªå¸¸è§çš„ï¼ˆç¥å¥‡çš„ğŸ§™ï¼‰på€¼é˜ˆå€¼0.05ï¼Œä½†å¯ä»¥ä½¿ç”¨ä»»ä½•é˜ˆå€¼ï¼š
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'notice that out of our 9900 null hypotheses, 493 are flagged as â€œsignificantâ€.
    Therefore, a False Positive Rate is: FPR = 493 / (493 + 9407) = 0.053.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œåœ¨æˆ‘ä»¬çš„9900ä¸ªé›¶å‡è®¾ä¸­ï¼Œ493ä¸ªè¢«æ ‡è®°ä¸ºâ€œæ˜¾è‘—â€ã€‚å› æ­¤ï¼Œå‡é˜³æ€§ç‡ä¸ºï¼šFPR = 493 / (493 + 9407) = 0.053ã€‚
- en: The main problem with FPR is that in a real scenario we do not a priori know
    which hypotheses are null and which are not. Then, the raw p-value on its own
    (False Positive Rate) is of limited use. In our case when the fraction of non-null
    features is very small, most of the features flagged as significant will be null,
    because there are many more of them. Specifically, out of 92 + 493 = 585 features
    flagged true (â€œpositiveâ€), only 92 are from our non-null distribution. That means
    that a majority or about 84% of reported significant features (493 / 585) are
    false positives!
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: FPRçš„ä¸»è¦é—®é¢˜æ˜¯ï¼Œåœ¨å®é™…æƒ…å†µä¸­ï¼Œæˆ‘ä»¬ä¸çŸ¥é“å“ªäº›å‡è®¾æ˜¯ç©ºçš„ï¼Œå“ªäº›ä¸æ˜¯ã€‚å› æ­¤ï¼Œä»…å‡­åŸå§‹på€¼ï¼ˆå‡é˜³æ€§ç‡ï¼‰ç”¨é€”æœ‰é™ã€‚åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œå½“éç©ºç‰¹å¾çš„æ¯”ä¾‹éå¸¸å°ï¼Œå¤§å¤šæ•°æ ‡è®°ä¸ºæ˜¾è‘—çš„ç‰¹å¾å°†æ˜¯ç©ºçš„ï¼Œå› ä¸ºå®ƒä»¬çš„æ•°é‡æ›´å¤šã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨92
    + 493 = 585ä¸ªæ ‡è®°ä¸ºçœŸæ­£ï¼ˆâ€œæ­£â€ï¼‰çš„ç‰¹å¾ä¸­ï¼Œåªæœ‰92ä¸ªæ¥è‡ªæˆ‘ä»¬çš„éç©ºåˆ†å¸ƒã€‚è¿™æ„å‘³ç€å¤§å¤šæ•°æˆ–çº¦84%ï¼ˆ493 / 585ï¼‰çš„æŠ¥å‘Šæ˜¾è‘—ç‰¹å¾æ˜¯å‡é˜³æ€§ï¼
- en: 'So, what can we do about this? There are two common methods of addressing this
    issue: instead of False Positive Rate, we can calculate Family-Wise Error Rate
    (FWER) or a False Discovery Rate (FDR). Each of these methods takes the set of
    raw, unadjusted, p-values as an input, and produces a new set of â€œadjusted p-valuesâ€
    as an output. These â€œadjusted p-valuesâ€ represent estimates of *upper bounds*
    on FWER and FDR. They can be obtained from `multipletests()` function, which is
    part of the `statsmodels` Python library:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æ­¤åšäº›ä»€ä¹ˆï¼Ÿæœ‰ä¸¤ç§å¸¸è§çš„æ–¹æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼šæˆ‘ä»¬å¯ä»¥è®¡ç®—å®¶åº­-wise é”™è¯¯ç‡ï¼ˆFWERï¼‰æˆ–è™šå‡å‘ç°ç‡ï¼ˆFDRï¼‰ï¼Œè€Œä¸æ˜¯è™šå‡æ­£ç‡ã€‚è¿™äº›æ–¹æ³•éƒ½ä»¥åŸå§‹æœªè°ƒæ•´çš„
    p å€¼é›†åˆä½œä¸ºè¾“å…¥ï¼Œäº§ç”Ÿä¸€ç»„æ–°çš„â€œè°ƒæ•´å p å€¼â€ä½œä¸ºè¾“å‡ºã€‚è¿™äº›â€œè°ƒæ•´å p å€¼â€ä»£è¡¨äº† *FWER* å’Œ *FDR* çš„ *ä¸Šç•Œ* ä¼°è®¡å€¼ã€‚å®ƒä»¬å¯ä»¥é€šè¿‡
    `multipletests()` å‡½æ•°è·å¾—ï¼Œè¯¥å‡½æ•°æ˜¯ `statsmodels` Python åº“çš„ä¸€éƒ¨åˆ†ï¼š
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Family-Wise Error Rate
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®¶åº­-wise é”™è¯¯ç‡
- en: Family-Wise Error Rate is a probability of falsely rejecting one or more null
    hypotheses, or in other words flagging true Null as Non-null, or a probability
    of seeing one or more false positives.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å®¶åº­-wise é”™è¯¯ç‡æ˜¯é”™è¯¯æ‹’ç»ä¸€ä¸ªæˆ–å¤šä¸ªé›¶å‡è®¾çš„æ¦‚ç‡ï¼Œæ¢å¥è¯è¯´ï¼Œå°±æ˜¯å°†çœŸå®çš„é›¶å‡è®¾æ ‡è®°ä¸ºéé›¶å‡è®¾çš„æ¦‚ç‡ï¼Œæˆ–çœ‹åˆ°ä¸€ä¸ªæˆ–å¤šä¸ªè™šå‡æ­£ä¾‹çš„æ¦‚ç‡ã€‚
- en: 'When there is only one hypothesis being tested, this is equal to the raw p-value
    (false positive rate). However, the more hypotheses are tested, the more likely
    we are going to get one or more false positives. There are two popular ways to
    estimate FWER: Bonferroni and Holm procedures. Although neither Bonferroni nor
    Holm procedures make any assumptions about the dependence of tests run on individual
    features, they will be overly conservative. For example, in the extreme case when
    all of the features are identical (same model repeated 10,000 times), no correction
    is needed. While in the other extreme, where no features are correlated, some
    type of correction is required.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä»…æµ‹è¯•ä¸€ä¸ªå‡è®¾æ—¶ï¼Œè¿™ç­‰äºåŸå§‹ p å€¼ï¼ˆè™šå‡æ­£ç‡ï¼‰ã€‚ç„¶è€Œï¼Œæµ‹è¯•çš„å‡è®¾è¶Šå¤šï¼Œæˆ‘ä»¬è·å¾—ä¸€ä¸ªæˆ–å¤šä¸ªè™šå‡æ­£ä¾‹çš„å¯èƒ½æ€§å°±è¶Šå¤§ã€‚ä¼°è®¡ FWER æœ‰ä¸¤ç§æµè¡Œçš„æ–¹æ³•ï¼šåšå°¼è´¹ç½—å°¼å’Œéœå°”å§†ç¨‹åºã€‚è™½ç„¶åšå°¼è´¹ç½—å°¼å’Œéœå°”å§†ç¨‹åºéƒ½æ²¡æœ‰å¯¹æµ‹è¯•åœ¨å•ä¸ªç‰¹å¾ä¸Šè¿è¡Œçš„ä¾èµ–æ€§åšå‡ºä»»ä½•å‡è®¾ï¼Œä½†å®ƒä»¬ä¼šè¿‡äºä¿å®ˆã€‚ä¾‹å¦‚ï¼Œåœ¨æ‰€æœ‰ç‰¹å¾å®Œå…¨ç›¸åŒï¼ˆç›¸åŒçš„æ¨¡å‹é‡å¤äº†
    10,000 æ¬¡ï¼‰çš„æç«¯æƒ…å†µä¸‹ï¼Œä¸éœ€è¦æ ¡æ­£ã€‚è€Œåœ¨å…¶ä»–æç«¯æƒ…å†µä¸‹ï¼Œå¦‚æœæ²¡æœ‰ç‰¹å¾ç›¸å…³ï¼Œåˆ™éœ€è¦æŸç§ç±»å‹çš„æ ¡æ­£ã€‚
- en: Bonferroni procedure
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åšå°¼è´¹ç½—å°¼ç¨‹åº
- en: One of the most popular methods for correcting for multiple hypothesis testing
    is a Bonferroni procedure. The reason this method is popular is because it is
    very easy to calculate, even by hand. This procedure multiplies each p-value by
    the total number of tests performed or sets it to 1 if this multiplication would
    push it past 1.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä¿®æ­£å¤šé‡å‡è®¾æ£€éªŒçš„æœ€æµè¡Œæ–¹æ³•ä¹‹ä¸€æ˜¯åšå°¼è´¹ç½—å°¼ç¨‹åºã€‚ä¹‹æ‰€ä»¥è¿™ç§æ–¹æ³•æµè¡Œï¼Œæ˜¯å› ä¸ºå®ƒéå¸¸å®¹æ˜“è®¡ç®—ï¼Œå³ä½¿æ˜¯æ‰‹åŠ¨è®¡ç®—ä¹Ÿå¾ˆç®€å•ã€‚è¯¥ç¨‹åºå°†æ¯ä¸ª p å€¼ä¹˜ä»¥æ‰€è¿›è¡Œçš„æµ‹è¯•æ€»æ•°ï¼Œæˆ–è€…å¦‚æœè¿™ç§ä¹˜æ³•ä¼šä½¿
    p å€¼è¶…è¿‡ 1ï¼Œåˆ™å°†å…¶è®¾ç½®ä¸º 1ã€‚
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/55e0101586bf95c693bd99efb4c1e5c1.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/55e0101586bf95c693bd99efb4c1e5c1.png)'
- en: Holm procedure
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: éœå°”å§†ç¨‹åº
- en: Holmâ€™s procedure provides a correction that is more powerful than Bonferroniâ€™s
    procedure. The only difference is that the p-values are not all multiplied by
    the total number of tests (here, 10000). Instead, each sorted p-value is multiplied
    progressively by a decreasing sequence 10000, 9999, 9998, 9997, â€¦, 3, 2, 1.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: éœå°”å§†çš„ç¨‹åºæä¾›äº†ä¸€ç§æ¯”åšå°¼è´¹ç½—å°¼ç¨‹åºæ›´å¼ºå¤§çš„æ ¡æ­£æ–¹æ³•ã€‚å”¯ä¸€çš„åŒºåˆ«åœ¨äºï¼Œp å€¼å¹¶ä¸æ˜¯å…¨éƒ¨ä¹˜ä»¥æµ‹è¯•æ€»æ•°ï¼ˆè¿™é‡Œæ˜¯ 10000ï¼‰ã€‚è€Œæ˜¯ï¼Œæ¯ä¸ªæ’åºåçš„ p å€¼ä¾æ¬¡ä¹˜ä»¥é€’å‡åºåˆ—
    10000ã€9999ã€9998ã€9997ã€â€¦â€¦ã€3ã€2ã€1ã€‚
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/19df8cf11b5389281f44407675a2cfe9.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/19df8cf11b5389281f44407675a2cfe9.png)'
- en: 'We can verify this ourselves: the last 10th p-value on this output is multiplied
    by 9991: 7.943832e-06 * 9991 = 0.079367\. Holmâ€™s correction is also the default
    method for adjusting p-values in `p.adjust()` function in R language.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥è‡ªå·±éªŒè¯è¿™ä¸€ç‚¹ï¼šè¾“å‡ºä¸­çš„ç¬¬åä¸ª p å€¼è¢«ä¹˜ä»¥ 9991ï¼š7.943832e-06 * 9991 = 0.079367ã€‚éœå°”å§†çš„æ ¡æ­£ä¹Ÿæ˜¯ R è¯­è¨€ä¸­
    `p.adjust()` å‡½æ•°è°ƒæ•´ p å€¼çš„é»˜è®¤æ–¹æ³•ã€‚
- en: 'If we again apply our p-value threshold of 0.05, letâ€™s take a look how these
    adjusted p-values affect our predictions:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å†æ¬¡åº”ç”¨ p å€¼é˜ˆå€¼ 0.05ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹è¿™äº›è°ƒæ•´åçš„ p å€¼å¦‚ä½•å½±å“æˆ‘ä»¬çš„é¢„æµ‹ï¼š
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: These results are much different than when we applied the same threshold to
    the raw p-values! Now, only 8 features are flagged as â€œsignificantâ€, and all 8
    are correct â€” they were generated from our Non-null distribution. This is because
    the probability of getting even one feature flagged incorrectly is only 0.05 (5%).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›ç»“æœä¸æˆ‘ä»¬å°†ç›¸åŒé˜ˆå€¼åº”ç”¨äºåŸå§‹ p å€¼æ—¶å¤§ç›¸å¾„åº­ï¼ç°åœ¨ï¼Œåªæœ‰ 8 ä¸ªç‰¹å¾è¢«æ ‡è®°ä¸ºâ€œæ˜¾è‘—â€ï¼Œè€Œè¿™ 8 ä¸ªç‰¹å¾éƒ½æ˜¯æ­£ç¡®çš„â€”â€”å®ƒä»¬æ¥è‡ªäºæˆ‘ä»¬çš„éé›¶åˆ†å¸ƒã€‚è¿™æ˜¯å› ä¸ºå³ä½¿æœ‰ä¸€ä¸ªç‰¹å¾è¢«é”™è¯¯æ ‡è®°çš„æ¦‚ç‡ä¹Ÿåªæœ‰
    0.05ï¼ˆ5%ï¼‰ã€‚
- en: 'However, this approach has a downside: it failed to flag other 92 Non-null
    features as significant. While it was very stringent to make sure none of the
    null features slipped in, it was able to find only 8% (8 out of 100) non-null
    features. This can be seen as taking a different extreme than the False Positive
    Rate approach.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•æœ‰ä¸€ä¸ªç¼ºç‚¹ï¼šå®ƒæœªèƒ½å°†å…¶ä»– 92 ä¸ªéé›¶ç‰¹å¾æ ‡è®°ä¸ºæ˜¾è‘—ã€‚å°½ç®¡å®ƒéå¸¸ä¸¥æ ¼ï¼Œä»¥ç¡®ä¿æ²¡æœ‰é›¶ç‰¹å¾è¢«æ¼å…¥ï¼Œä½†å®ƒåªèƒ½æ‰¾åˆ° 8%ï¼ˆ100 ä¸ªä¸­çš„ 8 ä¸ªï¼‰éé›¶ç‰¹å¾ã€‚è¿™å¯ä»¥è¢«è§†ä¸ºæ¯”è™šå‡æ­£ä¾‹ç‡æ–¹æ³•é‡‡å–äº†ä¸åŒçš„æç«¯ã€‚
- en: Is there a more middle ground? The answer is â€œyesâ€, and that middle ground is
    False Discovery Rate.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯å¦æœ‰ä¸€ç§æ›´ä¸­é—´çš„æ–¹æ¡ˆï¼Ÿç­”æ¡ˆæ˜¯â€œæœ‰â€ï¼Œè¿™ç§ä¸­é—´æ–¹æ¡ˆå°±æ˜¯è™šå‡å‘ç°ç‡ã€‚
- en: False Discovery Rate
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è™šå‡å‘ç°ç‡
- en: What if we are OK with letting some false positives in, but capturing more than
    single-digit percent of true positives? Maybe we are OK with having *some* false
    positive, just not that many that they overwhelm all of the features we flag as
    significant â€” as was the case in the FPR example.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å¯ä»¥æ¥å—ä¸€äº›è™šå‡æ­£ä¾‹ï¼Œä½†å¸Œæœ›æ•è·æ›´å¤šçš„çœŸæ­£æ­£ä¾‹ï¼Œè€Œä¸ä»…ä»…æ˜¯ä¸ªä½æ•°çš„ç™¾åˆ†æ¯”å‘¢ï¼Ÿä¹Ÿè®¸æˆ‘ä»¬å¯ä»¥æ¥å—*ä¸€äº›*è™šå‡æ­£ä¾‹ï¼Œåªè¦è¿™äº›è™šå‡æ­£ä¾‹ä¸ä¼šæ·¹æ²¡æˆ‘ä»¬æ ‡è®°ä¸ºæ˜¾è‘—çš„æ‰€æœ‰ç‰¹å¾â€”â€”å°±åƒåœ¨
    FPR ç¤ºä¾‹ä¸­é‚£æ ·ã€‚
- en: 'This can be done by controlling for False Discovery Rate (rather than FWER
    or FPR) at a specified threshold level, say 0.05\. False Discovery Rate is defined
    a fraction of false positives among all features flagged as positive: FDR = FP
    / (FP + TP), where FP is the number of False Positives and TP is the number of
    True Positives. By setting FDR threshold to 0.05, we are saying we are OK with
    having 5% (on average) false positives among all of our features we flag as positive.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯ä»¥é€šè¿‡åœ¨æŒ‡å®šçš„é˜ˆå€¼æ°´å¹³ï¼ˆä¾‹å¦‚ 0.05ï¼‰ä¸‹æ§åˆ¶è™šå‡å‘ç°ç‡ï¼ˆè€Œä¸æ˜¯ FWER æˆ– FPRï¼‰æ¥å®Œæˆã€‚è™šå‡å‘ç°ç‡å®šä¹‰ä¸ºæ‰€æœ‰è¢«æ ‡è®°ä¸ºæ­£é¢çš„ç‰¹å¾ä¸­è™šå‡æ­£ä¾‹çš„æ¯”ä¾‹ï¼šFDR
    = FP / (FP + TP)ï¼Œå…¶ä¸­ FP æ˜¯è™šå‡æ­£ä¾‹çš„æ•°é‡ï¼ŒTP æ˜¯çœŸæ­£æ­£ä¾‹çš„æ•°é‡ã€‚é€šè¿‡å°† FDR é˜ˆå€¼è®¾ç½®ä¸º 0.05ï¼Œæˆ‘ä»¬è¡¨ç¤ºæˆ‘ä»¬æ¥å—åœ¨æ‰€æœ‰è¢«æ ‡è®°ä¸ºæ­£é¢çš„ç‰¹å¾ä¸­æœ‰
    5%ï¼ˆå¹³å‡ï¼‰è™šå‡æ­£ä¾‹ã€‚
- en: 'There are several methods to control FDR and here we will describe how to use
    two popular ones: Benjamini-Hochberg and Benjamini-Yekutieli procedures. Both
    of these procedures are similar although more involved than FWER procedures. They
    still rely on sorting the p-values, multiplying them with a specific number, and
    then using a cut-off criterion.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: æ§åˆ¶ FDR æœ‰å‡ ç§æ–¹æ³•ï¼Œæˆ‘ä»¬å°†åœ¨è¿™é‡Œæè¿°å¦‚ä½•ä½¿ç”¨ä¸¤ç§æµè¡Œçš„æ–¹æ³•ï¼šBenjamini-Hochberg å’Œ Benjamini-Yekutieli ç¨‹åºã€‚è¿™ä¸¤ç§ç¨‹åºè™½ç„¶æ¯”
    FWER ç¨‹åºæ›´å¤æ‚ï¼Œä½†ä»ç„¶ç±»ä¼¼ã€‚å®ƒä»¬ä»ç„¶ä¾èµ–äºå¯¹ p å€¼è¿›è¡Œæ’åºã€ä¹˜ä»¥ä¸€ä¸ªç‰¹å®šçš„æ•°å­—ï¼Œç„¶åä½¿ç”¨æˆªæ–­æ ‡å‡†ã€‚
- en: Benjamini-Hochberg procedure
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Benjamini-Hochberg ç¨‹åº
- en: 'Benjamini-Hochberg (BH) procedure assumes that each of the tests are *independent*.
    Dependent tests occur, for example, if the features being tested are correlated
    with each other. Letâ€™s calculate the BH-adjusted p-values and compare it to our
    earlier result from FWER using Holmâ€™s correction:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Benjamini-Hochberg (BH) ç¨‹åºå‡è®¾æ¯ä¸ªæµ‹è¯•éƒ½æ˜¯*ç‹¬ç«‹çš„*ã€‚ä¾èµ–çš„æµ‹è¯•ä¼šå‘ç”Ÿï¼Œä¾‹å¦‚ï¼Œå½“è¢«æµ‹è¯•çš„ç‰¹å¾ä¹‹é—´å­˜åœ¨ç›¸å…³æ€§æ—¶ã€‚è®©æˆ‘ä»¬è®¡ç®— BH
    è°ƒæ•´åçš„ p å€¼ï¼Œå¹¶å°†å…¶ä¸æˆ‘ä»¬ä¹‹å‰ä½¿ç”¨ Holm æ ¡æ­£çš„ FWER ç»“æœè¿›è¡Œæ¯”è¾ƒï¼š
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/e13078444fc6c5d26695e9dfb9f3aa33.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e13078444fc6c5d26695e9dfb9f3aa33.png)'
- en: '[PRE10]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'BH procedure now correctly flagged 33 out of 100 non-null features as significant
    â€” an improvement from the 8 with the Holmâ€™s correction. However, it also flagged
    2 null features as significant. So, out of the 35 features flagged as significant,
    the fraction of incorrect features is: 2 / 33 = 0.06 so 6%.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: BH ç¨‹åºç°åœ¨æ­£ç¡®åœ°å°† 100 ä¸ªéé›¶ç‰¹å¾ä¸­çš„ 33 ä¸ªæ ‡è®°ä¸ºæ˜¾è‘—â€”â€”ç›¸æ¯”äº Holm æ ¡æ­£çš„ 8 ä¸ªï¼Œè¿™æ˜¯ä¸€ç§æ”¹è¿›ã€‚ç„¶è€Œï¼Œå®ƒä¹Ÿå°† 2 ä¸ªé›¶ç‰¹å¾æ ‡è®°ä¸ºæ˜¾è‘—ã€‚å› æ­¤ï¼Œåœ¨
    35 ä¸ªæ ‡è®°ä¸ºæ˜¾è‘—çš„ç‰¹å¾ä¸­ï¼Œä¸æ­£ç¡®ç‰¹å¾çš„æ¯”ä¾‹æ˜¯ï¼š2 / 33 = 0.06ï¼Œå³ 6%ã€‚
- en: 'Note that in this case we have 6% FDR rate, even though we aimed to control
    it at 5%. FDR will be controlled at a 5% rate *on average*: sometimes it may be
    lower and sometimes it may be higher.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çš„ FDR ç‡ä¸º 6%ï¼Œå°½ç®¡æˆ‘ä»¬æ—¨åœ¨å°†å…¶æ§åˆ¶åœ¨ 5%ã€‚FDR å°†ä»¥ 5% çš„é€Ÿç‡*å¹³å‡*æ§åˆ¶ï¼šæœ‰æ—¶å®ƒå¯èƒ½æ›´ä½ï¼Œæœ‰æ—¶å¯èƒ½æ›´é«˜ã€‚
- en: Benjamini-Yekutieli procedure
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Benjamini-Yekutieli ç¨‹åº
- en: 'Benjamini-Yekutieli (BY) procedure controls FDR regardless of whether tests
    are independent or not. Again, it is worth noting that all of these procedures
    try to establish *upper bounds* on FDR (or FWER), so they may be less or more
    conservative. Letâ€™s compare the BY procedure with a BH and Holm procedures above:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Benjamini-Yekutieli (BY) ç¨‹åºåœ¨æµ‹è¯•æ˜¯å¦ç‹¬ç«‹çš„æƒ…å†µä¸‹éƒ½èƒ½æ§åˆ¶ FDRã€‚å†æ¬¡å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ‰€æœ‰è¿™äº›ç¨‹åºéƒ½è¯•å›¾å»ºç«‹ FDRï¼ˆæˆ– FWERï¼‰çš„*ä¸Šé™*ï¼Œå› æ­¤å®ƒä»¬å¯èƒ½æ›´ä¿å®ˆæˆ–æ›´å®½æ¾ã€‚è®©æˆ‘ä»¬å°†
    BY ç¨‹åºä¸ä¸Šè¿° BH å’Œ Holm ç¨‹åºè¿›è¡Œæ¯”è¾ƒï¼š
- en: '[PRE14]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/5009f6b28842380845296c6dd2c3cdea.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5009f6b28842380845296c6dd2c3cdea.png)'
- en: '[PRE15]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: BY procedure is stricter in controlling FDR; in this case even more so than
    the Holmâ€™s procedure for controlling FWER, by flagging only 7 non-null features
    as significant! The main advantage of using it is when we know the data may contain
    a high number of correlated features. However, in that case we may also want to
    consider filtering out correlated features so that we do not need to test all
    of them.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: BY ç¨‹åºåœ¨æ§åˆ¶ FDR æ–¹é¢æ›´ä¸¥æ ¼ï¼›åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç”šè‡³æ¯”ç”¨äºæ§åˆ¶ FWER çš„ Holm æ–¹æ³•æ›´ä¸¥æ ¼ï¼Œä»…æ ‡è®°äº† 7 ä¸ªéç©ºç‰¹å¾ä¸ºæ˜¾è‘—ï¼ä½¿ç”¨å®ƒçš„ä¸»è¦ä¼˜åŠ¿æ˜¯å½“æˆ‘ä»¬çŸ¥é“æ•°æ®å¯èƒ½åŒ…å«å¤§é‡ç›¸å…³ç‰¹å¾æ—¶ã€‚ç„¶è€Œï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½è¿˜å¸Œæœ›è€ƒè™‘è¿‡æ»¤ç›¸å…³ç‰¹å¾ï¼Œä»¥ä¾¿ä¸éœ€è¦æµ‹è¯•æ‰€æœ‰è¿™äº›ç‰¹å¾ã€‚
- en: Summary
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ€»ç»“
- en: 'At the end, the choice of procedure is left to the user and depends on what
    the analysis is trying to do. Quoting Benjamini, Hochberg (Royal Stat. Soc. 1995):'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œç¨‹åºçš„é€‰æ‹©ç•™ç»™ç”¨æˆ·ï¼Œå–å†³äºåˆ†æè¯•å›¾åšä»€ä¹ˆã€‚å¼•ç”¨æœ¬é›…æ˜ã€éœå¥‡ä¼¯æ ¼ï¼ˆRoyal Stat. Soc. 1995ï¼‰ï¼š
- en: Often the control of the FWER is not quite needed. The control of the FWER is
    important when a conclusion from the various individual inferences is likely to
    be erroneous when at least one of them is.
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: é€šå¸¸ä¸å¤ªéœ€è¦æ§åˆ¶ FWERã€‚åœ¨å¤šä¸ªå•ç‹¬æ¨æ–­çš„ç»“è®ºå¯èƒ½å‡ºé”™æ—¶ï¼Œæ§åˆ¶ FWER æ˜¯é‡è¦çš„ã€‚
- en: ''
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This may be the case, for example, when several new treatments are competing
    against a standard, and a single treatment is chosen from the set of treatments
    which are declared significantly better than the standard.
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œåœ¨å‡ ç§æ–°æ²»ç–—æ–¹æ³•ä¸æ ‡å‡†è¿›è¡Œç«äº‰æ—¶ï¼Œå¯èƒ½ä¼šå‡ºç°è¿™ç§æƒ…å†µï¼Œå¹¶ä¸”ä»è¢«å£°æ˜æ˜¾è‘—ä¼˜äºæ ‡å‡†çš„æ²»ç–—æ–¹æ³•é›†åˆä¸­é€‰æ‹©å•ä¸€æ²»ç–—æ–¹æ³•ã€‚
- en: In other cases, where we may be OK to have some false positives, FDR methods
    such as BH correction provide less stringent p-value adjustments and may be preferrable
    if we primarily want to increase the number of true positives that pass a certain
    p-value threshold.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œå½“æˆ‘ä»¬å¯ä»¥æ¥å—ä¸€äº›å‡é˜³æ€§æ—¶ï¼ŒFDR æ–¹æ³•å¦‚ BH æ ¡æ­£æä¾›äº†ä¸é‚£ä¹ˆä¸¥æ ¼çš„ p å€¼è°ƒæ•´ï¼Œå¹¶ä¸”å¦‚æœæˆ‘ä»¬ä¸»è¦æƒ³å¢åŠ é€šè¿‡æŸä¸ª p å€¼é˜ˆå€¼çš„çœŸé˜³æ€§æ•°é‡ï¼Œåˆ™å¯èƒ½æ›´å¯å–ã€‚
- en: There are other adjustment methods not mentioned here, notably a [q-value](https://en.wikipedia.org/wiki/Q-value_(statistics))
    which is also used for FDR control, and at the time of writing exists only as
    an R package.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰å…¶ä»–æœªåœ¨æ­¤æåŠçš„è°ƒæ•´æ–¹æ³•ï¼Œå°¤å…¶æ˜¯ä¸€ä¸ª[q-value](https://en.wikipedia.org/wiki/Q-value_(statistics))ï¼Œä¹Ÿç”¨äº
    FDR æ§åˆ¶ï¼Œåœ¨æ’°å†™æ—¶ä»…å­˜åœ¨ä½œä¸º R åŒ…ã€‚
