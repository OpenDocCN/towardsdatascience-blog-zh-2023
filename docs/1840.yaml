- en: Speeding up vision transformer prediction by 9 times with PyTorch, ONNX and
    TensorRT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/making-vision-transformers-predict-9-times-faster-with-pytorch-onnx-tensorrt-and-multi-threading-dc1f09b6814?source=collection_archive---------4-----------------------#2023-06-04](https://towardsdatascience.com/making-vision-transformers-predict-9-times-faster-with-pytorch-onnx-tensorrt-and-multi-threading-dc1f09b6814?source=collection_archive---------4-----------------------#2023-06-04)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How to use 16bit float, TensorRT, network rewriting and multi-threading to dramatically
    speed up deep learning model prediction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://jasonweiyi.medium.com/?source=post_page-----dc1f09b6814--------------------------------)[![Wei
    Yi](../Images/24b7a438912082519f24d18e11ac9638.png)](https://jasonweiyi.medium.com/?source=post_page-----dc1f09b6814--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dc1f09b6814--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dc1f09b6814--------------------------------)
    [Wei Yi](https://jasonweiyi.medium.com/?source=post_page-----dc1f09b6814--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1b4bd5317a6e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmaking-vision-transformers-predict-9-times-faster-with-pytorch-onnx-tensorrt-and-multi-threading-dc1f09b6814&user=Wei+Yi&userId=1b4bd5317a6e&source=post_page-1b4bd5317a6e----dc1f09b6814---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----dc1f09b6814--------------------------------)
    ·11 min read·Jun 4, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdc1f09b6814&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmaking-vision-transformers-predict-9-times-faster-with-pytorch-onnx-tensorrt-and-multi-threading-dc1f09b6814&user=Wei+Yi&userId=1b4bd5317a6e&source=-----dc1f09b6814---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc1f09b6814&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmaking-vision-transformers-predict-9-times-faster-with-pytorch-onnx-tensorrt-and-multi-threading-dc1f09b6814&source=-----dc1f09b6814---------------------bookmark_footer-----------)![](../Images/8072ede2bfa4cf3d5e55d53741fc8600.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Sanjeevan SatheesKumar](https://unsplash.com/@sanjeevan_s?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Vision transformer such as [UNET](https://en.wikipedia.org/wiki/U-Net), [SwinUNETR](https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Self-Supervised_Pre-Training_of_Swin_Transformers_for_3D_Medical_Image_Analysis_CVPR_2022_paper.html)
    are state-of-the-art in computer vision tasks, such as semantic segmentation.
    But it takes a lot of time for such models to make a prediction. This article
    shows how to speed up such model’s prediction by 9 times. This improvement paves
    the way for many real-time or near real-time applications.
  prefs: []
  type: TYPE_NORMAL
- en: The tumours segmentation task
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To set the scene, I’m using the SwinUNETR model to segment lung tumours from
    chest CT scan images, which are single channel grayscale 3D images. Here is an
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4b7a6181e9ed9bc45a923632e2cc2783.png)'
  prefs: []
  type: TYPE_IMG
- en: Images from the public [NSCLC-Radiomics dataset](https://wiki.cancerimagingarchive.net/display/Public/NSCLC-Radiomics)
  prefs: []
  type: TYPE_NORMAL
- en: Left column shows a few 2D slices from a 3D CT scan image, at the axial plane.
    The two crescent black areas are lungs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Right column shows the manual annotation of lung tumours.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chest CT scans are typically sized 512×512×300, taking roughly 60 to 90 megabytes…
  prefs: []
  type: TYPE_NORMAL
