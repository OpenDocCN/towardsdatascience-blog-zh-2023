- en: 'Polars: Pandas DataFrame but Much Faster'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/pandas-dataframe-but-much-faster-f475d6be4cd4?source=collection_archive---------1-----------------------#2023-01-03](https://towardsdatascience.com/pandas-dataframe-but-much-faster-f475d6be4cd4?source=collection_archive---------1-----------------------#2023-01-03)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Perform multithreaded, optimized pandas operations
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://travis-tang.medium.com/?source=post_page-----f475d6be4cd4--------------------------------)[![Travis
    Tang](../Images/8372ea73b8cf8fe344de6274b5d9ad17.png)](https://travis-tang.medium.com/?source=post_page-----f475d6be4cd4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f475d6be4cd4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f475d6be4cd4--------------------------------)
    [Travis Tang](https://travis-tang.medium.com/?source=post_page-----f475d6be4cd4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F169b6a57c01e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpandas-dataframe-but-much-faster-f475d6be4cd4&user=Travis+Tang&userId=169b6a57c01e&source=post_page-169b6a57c01e----f475d6be4cd4---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f475d6be4cd4--------------------------------)
    ·11 min read·Jan 3, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff475d6be4cd4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpandas-dataframe-but-much-faster-f475d6be4cd4&user=Travis+Tang&userId=169b6a57c01e&source=-----f475d6be4cd4---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff475d6be4cd4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpandas-dataframe-but-much-faster-f475d6be4cd4&source=-----f475d6be4cd4---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Let’s face it. Pandas is slow. When you have millions of rows in your dataframe,
    it becomes incredibly frustrating to wait for a minute for a single line of code
    to execute. You will end up spending more time waiting than doing actual analytics.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Multiple libraries exist to solve this problem. PySpark, Vaex, Modin, and Dask
    are some examples.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Today, let’s look at **Polars**.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/de7dd964e7660bc5a6a894d8a12a9287.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
- en: Polars is fast. Image by Midjourney.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '*I am not affiliated with Polars, PySpark, Vaex, Modin, and Dask in anyway.*'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Polars is a blazingly fast DataFrame library.
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Polars is fast. Two benchmarks compare Polars against its alternatives. Polars
    come up as one of the fastest libraries out there.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: O[ne benchmark](https://www.pola.rs/benchmarks.html) pitted Polars against its
    alternatives for the task of reading in data and performing various analytics
    tasks. Polars consistently perform faster than other libraries.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[一个基准测试](https://www.pola.rs/benchmarks.html)将 Polars 与其替代品进行对比，任务是读取数据并执行各种分析任务。Polars
    的表现始终优于其他库。'
- en: '![](../Images/9b4ff6583ed81a21191c77079902fc21.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9b4ff6583ed81a21191c77079902fc21.png)'
- en: Lower is faster. *Do note that the benchmark is published by Polars so there
    might be some bias here.* ([Source](https://github.com/pola-rs/tpch))
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数值越低，速度越快。*请注意，基准测试是由 Polars 发布的，因此可能存在一些偏见。* ([Source](https://github.com/pola-rs/tpch))
- en: Another [benchmark](https://h2oai.github.io/db-benchmark/) published by H2O.ai
    compared Polars against its alternative using 5 queries. Here, the input table
    is 50GB in size, with 1 billion rows and 9 columns.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个 [基准测试](https://h2oai.github.io/db-benchmark/) 由 H2O.ai 发布，比较了 Polars 与其替代品在
    5 个查询中的表现。在这里，输入表的大小为 50GB，包含 10 亿行和 9 列。
- en: Again, Polars defended its title.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Polars 再次证明了其优势。
- en: '![](../Images/db0b84918d6179cda3b8e18850b422ab.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/db0b84918d6179cda3b8e18850b422ab.png)'
- en: Polars is fast according to H2O’s benchmark. [Source](https://h2oai.github.io/db-benchmark/)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 H2O 的基准测试，Polars 非常快速。 [Source](https://h2oai.github.io/db-benchmark/)
- en: 'Why Polars is fast: Parallelization'
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Polars 快速的原因：并行化
- en: Polars is fast because it uses parallelization and cache efficient algorithms
    to speed up analytics task. Here are its strategies.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Polars 之所以快速，是因为它使用了并行化和缓存高效算法来加速分析任务。以下是它的策略。
- en: Reduce redundant copies
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少冗余的复制
- en: Traverse memory cache efficiently
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高效遍历内存缓存
- en: Minimize contention in parallelism
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最小化并行中的竞争
- en: It is created with Rust, not Python
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是用 Rust 创建的，而不是 Python
- en: Polars is much faster than libraries that try to implement concurrency using
    python, like Pandas. That’s because Polars is written with Rust, and Rust is much
    better than Python at implementing concurrency.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Polars 比那些尝试使用 Python 实现并发的库（如 Pandas）要快得多。这是因为 Polars 是用 Rust 编写的，而 Rust 在实现并发方面比
    Python 更出色。
- en: The reason Python is bad at implementing concurrency is that it uses a [*global
    interpreter lock (GIL)*](https://realpython.com/python-gil/), a feature absent
    in Rust. GIL is a lock which allows only thread to take control of the *python
    interpreter*.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Python 在实现并发方面表现不佳的原因是它使用了 [*全局解释器锁 (GIL)*](https://realpython.com/python-gil/)，而
    Rust 中没有这一特性。GIL 是一个锁，只允许一个线程控制 *Python 解释器*。
- en: '![](../Images/d3cc9e33c004f8919a910889be3068c9.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d3cc9e33c004f8919a910889be3068c9.png)'
- en: The reason why python is slower than Rust. Photo by [FLY:D](https://unsplash.com/es/@flyd2069?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Python 比 Rust 慢的原因。照片由 [FLY:D](https://unsplash.com/es/@flyd2069?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Think about it this way. You are in a toy factor (the processor) with fourworkers
    (cores in the processor).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这样想：你在一个玩具工厂（处理器）里，有四个工人（处理器中的核心）。
- en: 'In Python’s case: At any one point, a worker needs to hold a key (the *GIL*)
    before they can run the toy machine *(*python interpreter*).* They cannot share
    the machine, and one worker must finish working the toy before they pass the key
    to another worker. Thus, essentially, only one worker can run the toy machine
    at any one point. The other three workers are idle.'
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在 Python 的情况下：任何时候，一个工人需要持有钥匙（*GIL*）才能运行玩具机器（*Python 解释器*）。他们不能共享机器，一个工人必须在将钥匙传递给另一个工人之前完成玩具的工作。因此，本质上，任何时候只有一个工人可以运行玩具机器。其他三个工人处于闲置状态。
- en: ''
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In Rust’s case: At any one point, a worker need not hold a key before they
    can use the toy machine*.* They can all share the machine, and a worker need not
    finish working a toy before another one starts on the same machine. Thus, essentially,
    multiple workers can run the toy machine at any one point. No one needs to be
    idle.'
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在 Rust 的情况下：任何时候，一个工人不需要持有钥匙才能使用玩具机器*。* 他们可以共享机器，一个工人不必在另一个工人开始使用同一台机器之前完成玩具的工作。因此，本质上，多个工人可以同时使用玩具机器。没有人需要闲置。
- en: It supports lazy execution
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它支持惰性执行
- en: '**Lazy execution** means that an expression is evaluated not immediately, but
    only when needed. In contrast, **eager execution** evaluates the expression immediately.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**惰性执行** 意味着表达式不会立即被评估，而是仅在需要时才评估。相比之下，**急切执行** 立即评估表达式。'
- en: Thus, Polars can perform optimization — only running what is needed and ignoring
    what is not required. It can also parallelize these evaluations at run-time.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，Polars 可以进行优化——仅运行所需的部分，忽略不必要的部分。它还可以在运行时并行化这些评估。
- en: On the other hand, Pandas executes eagerly, contributing to waste of resources.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: You can see an example of the difference between eager and lazy execution by
    fast-forwarding to the section “Lazily selecting a column” and “Eagerly selecting
    a column” below
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Installing Polars
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Installing Polars is easy. Run the following in your terminal. (Note that the
    `[all]` clause is optional here.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Data set: NYC Parking Tickets (42 mil rows x 51 cols)'
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To illustrate the use of Polars, we will use a large dataset, **42.3 million
    rows** of [NYC parking tickets](https://www.kaggle.com/datasets/new-york-city/nyc-parking-tickets)
    from Kaggle (It has a [Public Domain](https://creativecommons.org/publicdomain/zero/1.0/)
    license, so feel free to use it!)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: The NYC Department of Finance collects data on every parking ticket issued in
    NYC (~10M per year!).
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/b31411c12e785a746ff8ba1245cb78f8.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
- en: New York City Car Parking. Photo by [Scott Gummerson](https://unsplash.com/@scottgummerson26?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: The complete dataset has 42 million rows and is distributed across 4 files —
    one file for each year. For the rest of the blog, we will use only **one file**
    (2013 to 2014).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '*Why didn’t we use all four files? Unfortunately, Polars crashed when I tried
    concatenating all four files together.*'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: 'All the code below is executed in a [Kaggle notebook](https://www.kaggle.com/travisvoon/polars-demo-by-travis-tang/edit),
    which has:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: 4 CPU cores
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 30 GB RAM
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reading in data with Polars
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Polars provide the `scan_csv` option. Scanning delays the actual parsing of
    the file and instead returns a lazy computation holder called a `LazyFrame`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: The actual computation occurs when `collect()` is called.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Why should we delay the actual parsing of the file? Doing so will allow Polars
    to generate an optimal execution plan. For example, when `collect` is called,
    Polars can skip the process of loading certain columns if they are not needed
    in the computation.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You can also use other functions to read in data, including:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '[Parquet files](https://pola-rs.github.io/polars-book/user-guide/howcani/io/parquet.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[JSON files](https://pola-rs.github.io/polars-book/user-guide/howcani/io/json.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Database](https://pola-rs.github.io/polars-book/user-guide/howcani/io/read_db.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AWS](https://pola-rs.github.io/polars-book/user-guide/howcani/io/aws.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Google BigQuery](https://pola-rs.github.io/polars-book/user-guide/howcani/io/google-big-query.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Postgres](https://pola-rs.github.io/polars-book/user-guide/howcani/io/postgres.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filtering rows based on condition
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Filtering for exact values
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can also filter for particular rows using the `filter` keyword. To do so,
    you will need to use the `pl.col(['column_name_here'])` function to specify the
    column name.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You can imagine that we can use other operators like `>` (smaller than), `<`
    (larger than), `>=` (larger than or equal to), `&` (and) , `|` (or) to achieve
    more complex conditions.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Filtering for more complex conditions
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can also filter by more complex criteria. In here, I use Regular Expression
    to filter the rows. The condition is that `Plate ID` must contain either ‘a’ or
    ‘1’.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Filtering for exact values (the very slow way)
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can also select **rows using indices,** a familiar way of selecting data
    for pandas users.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: To do so, you cannot use the `scan_csv` function which lazily reads the CSV.
    Instead you should opt for the `open_csv` function which eagerly reads the CSV.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Note that this is **anti-pattern** as it does not allow Polars to perform parallelization.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Selecting a column
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lazily selecting a column
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can select a column using the `select` keyword. Note that this syntax here
    is already different from the regular pandas syntax.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Eagerly selecting a column
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In a similar vein, you can use the square bracket notation to select columns.
    However, like I mentioned in the “filtering with indices” section above, this
    is anti-pattern.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Let’s compare the speed of the lazy versus eager execution. The lazy execution
    takes 1.59s while the eager selection takes 12.8s. The 7x speedup is achieved
    because Polars *only* read in the “Plate ID” column in lazy execution, while it
    needs to read in **all** columns (not only “Plate ID”) in eager execution.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Creating a new column
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To create a new column, Polars uses the `with_columns` syntax.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: Creating columns using string functions
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following finds the `length` of the string column `Plate ID` and gives it
    a column name `plate_id_letter_count` .
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Creating columns using lambda functions
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One can specify a `lambda`function within a `map` function in order to specify
    the function to apply to a particular column. Then, we can create a new column
    using the result of the function.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Performing aggregation
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We also have an example of a `groupby` and an aggregation as follows.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Combining multiple functions
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data scientists often need to perform multiple steps at the same time. We can
    do that in Polars using the `.` notation.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: In the following example, we first use `with_column`to replace the `Issue Date`
    column from a `string`column to a `datetime` column.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: Then, we perform a `groupby` on the `Registration State` . For each state, we
    find the earliest `Issue Date` of the ticket.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we sort the data by `Registration State` by alphabetically order.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Concatenating two tables into one
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What if you have two tables stored in two separate files, and you’d like to
    combine them into one dataframe? Use the `concat` method.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Joining tables on keys
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You might need to join information from one table to another. To do that, you
    can use the `join` method.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: There are multiple types of `join` , including the familiar types (inner, left,
    right) and some novel ones (anti, asof, semi). Read the [documentation](https://pola-rs.github.io/polars-book/user-guide/howcani/combining_data/joining.html)
    for more details.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种类型的`join`，包括熟悉的类型（inner、left、right）以及一些新型的（anti、asof、semi）。更多细节请阅读[文档](https://pola-rs.github.io/polars-book/user-guide/howcani/combining_data/joining.html)。
- en: '[PRE12]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: How is it different from Vaex?
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它与Vaex有何不同？
- en: I wrote a post on Vaex early, and received many comments on whether Vaex and
    Polars are different. Here are some of my observations.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我早期写了一篇关于Vaex的帖子，并收到许多关于Vaex和Polars是否不同的评论。以下是我的一些观察。
- en: Vaex’s syntax is more similar to Pandas; Polar’s syntax is more similar to R
    or PySpark.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Vaex的语法更类似于Pandas；Polar的语法更类似于R或PySpark。
- en: Vaex has more API for machine learning and data visualization. Polar’s focus
    is rudimentary data processing (filtering, selecting, aggregating)
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Vaex具有更多的机器学习和数据可视化API。Polar的重点是基础的数据处理（过滤、选择、聚合）。
- en: Vaex is written using CPP while Polars is written with Rust.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Vaex是用CPP编写的，而Polars是用Rust编写的。
- en: Depending on your use case, you might find Vaex or Polars to be better. For
    example, in the New York datset, I am not able to concatenate all four CSV files
    using Polars (it causes an out-of-memory issue) while I could do so with Vaex.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的使用案例，你可能会发现Vaex或Polars更好。例如，在纽约数据集中，我无法使用Polars连接所有四个CSV文件（它会导致内存不足问题），而我可以用Vaex做到这一点。
- en: '[PRE14]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Verdict: Use Polars under this condition.'
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 判决：在这种条件下使用Polars。
- en: 'Should you use Polars? Vaex? PySpark? Dask? Here’s how I would think about
    it:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该使用Polars？Vaex？PySpark？Dask？以下是我的思考方式：
- en: If your data is huge, going into the ‘big data’ realm of 10GB+, you want to
    consider using PySpark. Otherwise, Polars, Vaex and Dask are possible choices.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的数据很庞大，进入了10GB以上的“大数据”领域，你可能要考虑使用PySpark。否则，Polars、Vaex和Dask是可能的选择。
- en: If you have multiple computers in a cluster and you want to distribute your
    workload across those, use Dask.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你有多台计算机在一个集群中，并且你想在这些计算机之间分配工作负载，使用Dask。
- en: If you need visualization, machine learning and deep learning, use Vaex. If
    not, use Polars.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你需要可视化、机器学习和深度学习，使用Vaex。如果不需要，使用Polars。
- en: This is a rough guideline because the final answer depends on your use case.
    So I encourage you to experiment with each. In some cases, Polars and Vaex can
    be faster than PySpark ([when the dataset has millions of rows](https://www.confessionsofadataguy.com/dataframe-showdown-polars-vs-spark-vs-pandas-vs-datafusion-guess-who-wins/)).
    In some cases, Vaex can run but Polars break down (like in the `concat` example
    above)
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个粗略的指南，因为最终的答案取决于你的使用案例。因此，我鼓励你尝试每一个。在某些情况下，Polars和Vaex可能比PySpark更快（[当数据集有数百万行时](https://www.confessionsofadataguy.com/dataframe-showdown-polars-vs-spark-vs-pandas-vs-datafusion-guess-who-wins/)）。在某些情况下，Vaex可以运行，但Polars可能会崩溃（如上面的`concat`示例）。
- en: '![](../Images/756f34674fb42ae969c6ac195eacc858.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/756f34674fb42ae969c6ac195eacc858.png)'
- en: Super speed pandas. Image by Midjourney.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 超级速度的pandas。图片由Midjourney提供。
- en: I am a data scientist and I share data science tips on [LinkedIn](https://www.linkedin.com/in/travistang/)
    and Medium. Follow me for more tips like this.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我是一名数据科学家，我在[LinkedIn](https://www.linkedin.com/in/travistang/)和Medium分享数据科学技巧。关注我以获取更多类似的技巧。
