- en: 'Polars: Pandas DataFrame but Much Faster'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/pandas-dataframe-but-much-faster-f475d6be4cd4?source=collection_archive---------1-----------------------#2023-01-03](https://towardsdatascience.com/pandas-dataframe-but-much-faster-f475d6be4cd4?source=collection_archive---------1-----------------------#2023-01-03)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Perform multithreaded, optimized pandas operations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://travis-tang.medium.com/?source=post_page-----f475d6be4cd4--------------------------------)[![Travis
    Tang](../Images/8372ea73b8cf8fe344de6274b5d9ad17.png)](https://travis-tang.medium.com/?source=post_page-----f475d6be4cd4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f475d6be4cd4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f475d6be4cd4--------------------------------)
    [Travis Tang](https://travis-tang.medium.com/?source=post_page-----f475d6be4cd4--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F169b6a57c01e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpandas-dataframe-but-much-faster-f475d6be4cd4&user=Travis+Tang&userId=169b6a57c01e&source=post_page-169b6a57c01e----f475d6be4cd4---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f475d6be4cd4--------------------------------)
    ·11 min read·Jan 3, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff475d6be4cd4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpandas-dataframe-but-much-faster-f475d6be4cd4&user=Travis+Tang&userId=169b6a57c01e&source=-----f475d6be4cd4---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff475d6be4cd4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpandas-dataframe-but-much-faster-f475d6be4cd4&source=-----f475d6be4cd4---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s face it. Pandas is slow. When you have millions of rows in your dataframe,
    it becomes incredibly frustrating to wait for a minute for a single line of code
    to execute. You will end up spending more time waiting than doing actual analytics.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple libraries exist to solve this problem. PySpark, Vaex, Modin, and Dask
    are some examples.
  prefs: []
  type: TYPE_NORMAL
- en: Today, let’s look at **Polars**.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/de7dd964e7660bc5a6a894d8a12a9287.png)'
  prefs: []
  type: TYPE_IMG
- en: Polars is fast. Image by Midjourney.
  prefs: []
  type: TYPE_NORMAL
- en: '*I am not affiliated with Polars, PySpark, Vaex, Modin, and Dask in anyway.*'
  prefs: []
  type: TYPE_NORMAL
- en: Polars is a blazingly fast DataFrame library.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Polars is fast. Two benchmarks compare Polars against its alternatives. Polars
    come up as one of the fastest libraries out there.
  prefs: []
  type: TYPE_NORMAL
- en: O[ne benchmark](https://www.pola.rs/benchmarks.html) pitted Polars against its
    alternatives for the task of reading in data and performing various analytics
    tasks. Polars consistently perform faster than other libraries.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9b4ff6583ed81a21191c77079902fc21.png)'
  prefs: []
  type: TYPE_IMG
- en: Lower is faster. *Do note that the benchmark is published by Polars so there
    might be some bias here.* ([Source](https://github.com/pola-rs/tpch))
  prefs: []
  type: TYPE_NORMAL
- en: Another [benchmark](https://h2oai.github.io/db-benchmark/) published by H2O.ai
    compared Polars against its alternative using 5 queries. Here, the input table
    is 50GB in size, with 1 billion rows and 9 columns.
  prefs: []
  type: TYPE_NORMAL
- en: Again, Polars defended its title.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/db0b84918d6179cda3b8e18850b422ab.png)'
  prefs: []
  type: TYPE_IMG
- en: Polars is fast according to H2O’s benchmark. [Source](https://h2oai.github.io/db-benchmark/)
  prefs: []
  type: TYPE_NORMAL
- en: 'Why Polars is fast: Parallelization'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Polars is fast because it uses parallelization and cache efficient algorithms
    to speed up analytics task. Here are its strategies.
  prefs: []
  type: TYPE_NORMAL
- en: Reduce redundant copies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traverse memory cache efficiently
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimize contention in parallelism
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is created with Rust, not Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Polars is much faster than libraries that try to implement concurrency using
    python, like Pandas. That’s because Polars is written with Rust, and Rust is much
    better than Python at implementing concurrency.
  prefs: []
  type: TYPE_NORMAL
- en: The reason Python is bad at implementing concurrency is that it uses a [*global
    interpreter lock (GIL)*](https://realpython.com/python-gil/), a feature absent
    in Rust. GIL is a lock which allows only thread to take control of the *python
    interpreter*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d3cc9e33c004f8919a910889be3068c9.png)'
  prefs: []
  type: TYPE_IMG
- en: The reason why python is slower than Rust. Photo by [FLY:D](https://unsplash.com/es/@flyd2069?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Think about it this way. You are in a toy factor (the processor) with fourworkers
    (cores in the processor).
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python’s case: At any one point, a worker needs to hold a key (the *GIL*)
    before they can run the toy machine *(*python interpreter*).* They cannot share
    the machine, and one worker must finish working the toy before they pass the key
    to another worker. Thus, essentially, only one worker can run the toy machine
    at any one point. The other three workers are idle.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In Rust’s case: At any one point, a worker need not hold a key before they
    can use the toy machine*.* They can all share the machine, and a worker need not
    finish working a toy before another one starts on the same machine. Thus, essentially,
    multiple workers can run the toy machine at any one point. No one needs to be
    idle.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It supports lazy execution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Lazy execution** means that an expression is evaluated not immediately, but
    only when needed. In contrast, **eager execution** evaluates the expression immediately.'
  prefs: []
  type: TYPE_NORMAL
- en: Thus, Polars can perform optimization — only running what is needed and ignoring
    what is not required. It can also parallelize these evaluations at run-time.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, Pandas executes eagerly, contributing to waste of resources.
  prefs: []
  type: TYPE_NORMAL
- en: You can see an example of the difference between eager and lazy execution by
    fast-forwarding to the section “Lazily selecting a column” and “Eagerly selecting
    a column” below
  prefs: []
  type: TYPE_NORMAL
- en: Installing Polars
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Installing Polars is easy. Run the following in your terminal. (Note that the
    `[all]` clause is optional here.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Data set: NYC Parking Tickets (42 mil rows x 51 cols)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To illustrate the use of Polars, we will use a large dataset, **42.3 million
    rows** of [NYC parking tickets](https://www.kaggle.com/datasets/new-york-city/nyc-parking-tickets)
    from Kaggle (It has a [Public Domain](https://creativecommons.org/publicdomain/zero/1.0/)
    license, so feel free to use it!)
  prefs: []
  type: TYPE_NORMAL
- en: The NYC Department of Finance collects data on every parking ticket issued in
    NYC (~10M per year!).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/b31411c12e785a746ff8ba1245cb78f8.png)'
  prefs: []
  type: TYPE_IMG
- en: New York City Car Parking. Photo by [Scott Gummerson](https://unsplash.com/@scottgummerson26?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: The complete dataset has 42 million rows and is distributed across 4 files —
    one file for each year. For the rest of the blog, we will use only **one file**
    (2013 to 2014).
  prefs: []
  type: TYPE_NORMAL
- en: '*Why didn’t we use all four files? Unfortunately, Polars crashed when I tried
    concatenating all four files together.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'All the code below is executed in a [Kaggle notebook](https://www.kaggle.com/travisvoon/polars-demo-by-travis-tang/edit),
    which has:'
  prefs: []
  type: TYPE_NORMAL
- en: 4 CPU cores
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 30 GB RAM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reading in data with Polars
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Polars provide the `scan_csv` option. Scanning delays the actual parsing of
    the file and instead returns a lazy computation holder called a `LazyFrame`.
  prefs: []
  type: TYPE_NORMAL
- en: The actual computation occurs when `collect()` is called.
  prefs: []
  type: TYPE_NORMAL
- en: Why should we delay the actual parsing of the file? Doing so will allow Polars
    to generate an optimal execution plan. For example, when `collect` is called,
    Polars can skip the process of loading certain columns if they are not needed
    in the computation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also use other functions to read in data, including:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Parquet files](https://pola-rs.github.io/polars-book/user-guide/howcani/io/parquet.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[JSON files](https://pola-rs.github.io/polars-book/user-guide/howcani/io/json.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Database](https://pola-rs.github.io/polars-book/user-guide/howcani/io/read_db.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AWS](https://pola-rs.github.io/polars-book/user-guide/howcani/io/aws.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Google BigQuery](https://pola-rs.github.io/polars-book/user-guide/howcani/io/google-big-query.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Postgres](https://pola-rs.github.io/polars-book/user-guide/howcani/io/postgres.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filtering rows based on condition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Filtering for exact values
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can also filter for particular rows using the `filter` keyword. To do so,
    you will need to use the `pl.col(['column_name_here'])` function to specify the
    column name.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: You can imagine that we can use other operators like `>` (smaller than), `<`
    (larger than), `>=` (larger than or equal to), `&` (and) , `|` (or) to achieve
    more complex conditions.
  prefs: []
  type: TYPE_NORMAL
- en: Filtering for more complex conditions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can also filter by more complex criteria. In here, I use Regular Expression
    to filter the rows. The condition is that `Plate ID` must contain either ‘a’ or
    ‘1’.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Filtering for exact values (the very slow way)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can also select **rows using indices,** a familiar way of selecting data
    for pandas users.
  prefs: []
  type: TYPE_NORMAL
- en: To do so, you cannot use the `scan_csv` function which lazily reads the CSV.
    Instead you should opt for the `open_csv` function which eagerly reads the CSV.
  prefs: []
  type: TYPE_NORMAL
- en: Note that this is **anti-pattern** as it does not allow Polars to perform parallelization.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Selecting a column
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lazily selecting a column
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can select a column using the `select` keyword. Note that this syntax here
    is already different from the regular pandas syntax.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Eagerly selecting a column
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In a similar vein, you can use the square bracket notation to select columns.
    However, like I mentioned in the “filtering with indices” section above, this
    is anti-pattern.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Let’s compare the speed of the lazy versus eager execution. The lazy execution
    takes 1.59s while the eager selection takes 12.8s. The 7x speedup is achieved
    because Polars *only* read in the “Plate ID” column in lazy execution, while it
    needs to read in **all** columns (not only “Plate ID”) in eager execution.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a new column
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To create a new column, Polars uses the `with_columns` syntax.
  prefs: []
  type: TYPE_NORMAL
- en: Creating columns using string functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following finds the `length` of the string column `Plate ID` and gives it
    a column name `plate_id_letter_count` .
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Creating columns using lambda functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One can specify a `lambda`function within a `map` function in order to specify
    the function to apply to a particular column. Then, we can create a new column
    using the result of the function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Performing aggregation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We also have an example of a `groupby` and an aggregation as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Combining multiple functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data scientists often need to perform multiple steps at the same time. We can
    do that in Polars using the `.` notation.
  prefs: []
  type: TYPE_NORMAL
- en: In the following example, we first use `with_column`to replace the `Issue Date`
    column from a `string`column to a `datetime` column.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we perform a `groupby` on the `Registration State` . For each state, we
    find the earliest `Issue Date` of the ticket.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we sort the data by `Registration State` by alphabetically order.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Concatenating two tables into one
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What if you have two tables stored in two separate files, and you’d like to
    combine them into one dataframe? Use the `concat` method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Joining tables on keys
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You might need to join information from one table to another. To do that, you
    can use the `join` method.
  prefs: []
  type: TYPE_NORMAL
- en: There are multiple types of `join` , including the familiar types (inner, left,
    right) and some novel ones (anti, asof, semi). Read the [documentation](https://pola-rs.github.io/polars-book/user-guide/howcani/combining_data/joining.html)
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: How is it different from Vaex?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I wrote a post on Vaex early, and received many comments on whether Vaex and
    Polars are different. Here are some of my observations.
  prefs: []
  type: TYPE_NORMAL
- en: Vaex’s syntax is more similar to Pandas; Polar’s syntax is more similar to R
    or PySpark.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Vaex has more API for machine learning and data visualization. Polar’s focus
    is rudimentary data processing (filtering, selecting, aggregating)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Vaex is written using CPP while Polars is written with Rust.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Depending on your use case, you might find Vaex or Polars to be better. For
    example, in the New York datset, I am not able to concatenate all four CSV files
    using Polars (it causes an out-of-memory issue) while I could do so with Vaex.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Verdict: Use Polars under this condition.'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Should you use Polars? Vaex? PySpark? Dask? Here’s how I would think about
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: If your data is huge, going into the ‘big data’ realm of 10GB+, you want to
    consider using PySpark. Otherwise, Polars, Vaex and Dask are possible choices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you have multiple computers in a cluster and you want to distribute your
    workload across those, use Dask.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you need visualization, machine learning and deep learning, use Vaex. If
    not, use Polars.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is a rough guideline because the final answer depends on your use case.
    So I encourage you to experiment with each. In some cases, Polars and Vaex can
    be faster than PySpark ([when the dataset has millions of rows](https://www.confessionsofadataguy.com/dataframe-showdown-polars-vs-spark-vs-pandas-vs-datafusion-guess-who-wins/)).
    In some cases, Vaex can run but Polars break down (like in the `concat` example
    above)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/756f34674fb42ae969c6ac195eacc858.png)'
  prefs: []
  type: TYPE_IMG
- en: Super speed pandas. Image by Midjourney.
  prefs: []
  type: TYPE_NORMAL
- en: I am a data scientist and I share data science tips on [LinkedIn](https://www.linkedin.com/in/travistang/)
    and Medium. Follow me for more tips like this.
  prefs: []
  type: TYPE_NORMAL
