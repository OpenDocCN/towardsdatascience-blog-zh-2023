- en: 'Variance Reduction in Experiments — Part 1: Intuition'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/variance-reduction-in-experiments-part-1-intuition-68b270a0df71?source=collection_archive---------4-----------------------#2023-02-02](https://towardsdatascience.com/variance-reduction-in-experiments-part-1-intuition-68b270a0df71?source=collection_archive---------4-----------------------#2023-02-02)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The intuition behind variance reduction and why it is important in randomized
    experiments.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@murat.unal?source=post_page-----68b270a0df71--------------------------------)[![Murat
    Unal](../Images/9f00db7597d7ece01213a6b0589c87d8.png)](https://medium.com/@murat.unal?source=post_page-----68b270a0df71--------------------------------)[](https://towardsdatascience.com/?source=post_page-----68b270a0df71--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----68b270a0df71--------------------------------)
    [Murat Unal](https://medium.com/@murat.unal?source=post_page-----68b270a0df71--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F15a64c9fc55d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvariance-reduction-in-experiments-part-1-intuition-68b270a0df71&user=Murat+Unal&userId=15a64c9fc55d&source=post_page-15a64c9fc55d----68b270a0df71---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----68b270a0df71--------------------------------)
    ·7 min read·Feb 2, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F68b270a0df71&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvariance-reduction-in-experiments-part-1-intuition-68b270a0df71&user=Murat+Unal&userId=15a64c9fc55d&source=-----68b270a0df71---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F68b270a0df71&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvariance-reduction-in-experiments-part-1-intuition-68b270a0df71&source=-----68b270a0df71---------------------bookmark_footer-----------)![](../Images/d834f0d9e4aeb93318682085641fbfa8.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Mars Plex](https://unsplash.com/@mars_plex?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the first part in a series of two articles where we are going to dive
    deep into variance reduction in experiments. In this article we are going to discuss
    why variance reduction is necessary and build an intuition behind its mechanism.
    In the second part we are going to evaluate the latest method in this space: MLRATE,
    as well as compare it to other well-established methods such as, CUPED.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with discussing why variance reduction is necessary in experiments.
    See, when it comes to causal inference, our conclusions may be wrong for two different
    reasons: systematic bias and random variability. Systematic bias is the bad stuff
    that happens mainly due to self-selection or unmeasured confounding, whereas random
    variability, happens because the data we have access to is only a sample of the
    population we are trying to study. Randomized experiments allow us to eliminate
    systematic bias, but they are not immune to error based on random variability.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: The Difference-in-Means Estimator
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s consider the example, where our marketing team wants to figure out the
    impact of sending an email promotion. As a team of marketing data scientists,
    we decide to run an experiment by selecting 2000 random customers from our customer
    base. Our response variable is the amount of spending in the two weeks following
    the email, and for every customer, we let a coin flip decide whether that customer
    receives the promotion or not.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the treatment is delivered at random, we have no systematic bias, and
    a simple difference in means (DIM) between the treated (T) and control (C) in
    our experiment is an unbiased estimate of the population average treatment effect
    (ATE):'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: The critical point here is that this estimator gives us the true effect on average,
    but for a given sample that we end up analyzing, it might as well be far away
    from it.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: In the following code we first generate a sample of 2000 customers, randomly
    select half of them to treatment that has a constant effect of $5 on customer
    spending. We then apply the DIM estimator using linear regression on this sample,
    hoping to recover the true effect.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/7ed9d19d0d4e46fb5cda6de68d5fe278.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
- en: Unfortunately, the DIM estimate for this particular sample is far away than
    the true effect and is negative in sign. It also comes with a quite wide confidence
    interval, which prevents us from drawing any conclusions.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if we had the opportunity to repeat this experiment thousands
    of times in parallel with a different sample of the population each time, we would
    see that the density of our estimates would peak around the true effect. To see
    this, let’s create a simulation that generates a sample of 2000 customers and
    runs the previous experiment every time it is called, for 10000 times.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Sure enough, the average of our 10000 estimates recovers the true effect of
    $5.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b2f354713855084bb8c4ccf46d73352f.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
- en: Figure 1 by author
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Variation in the Outcome
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To understand why we fail to uncover the treatment effect when it is in fact
    present, we need to think about what actually determines customer spending. If
    our email promotion only has a limited impact in customer spending compared to
    other factors such as income, tenure with the business, recency, frequency and
    value of previous purchases etc. then it would be no surprise to see the variation
    of spending being explained much more by factors other than our email promotion.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: In fact, plotting customer spending against the treatment indicator reveals
    how it varies from around $4 to more than $400\. Since we know that the promotion
    only has a small effect on spending, it becomes quite challenging to detect it
    inside all the variation. Hence, the regression line from control to treatment
    has a slight negative slope below.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b1c34ae64769e0dfc9ec94be2c50d8a5.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
- en: Figure 2 by author
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: One way we can make it easier for the DIM estimator to detect the true effect
    is by increasing our sample size. If we have access to, say 10000 customers instead
    of 2000, we can get a much closer estimate of the true effect as shown below.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/b99859165ca55d5fb463bd6aee2c0c8e.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
- en: Regression Adjustment
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, what if we are constrained in time or other resources and can’t increase
    our sample size, but still want to be able to detect a small effect? This brings
    us to the idea of reducing the variance of our outcome, which similar to increasing
    sample size, makes it easier to detect an effect if it is in fact present.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the easiest way to accomplish that, is by using regression adjustment
    to control for all other factors that determine spending. Notice that the sample
    we generated for this example has 10 covariates and 5 of them are directly related
    to the outcome. As mentioned earlier, we can think of them as the following: income,
    tenure with the business, recency, frequency and value of previous purchases.
    Including them as controls in a regression means holding them constant while looking
    at the treatment. This means that if we look at customers with similar levels
    of income and purchase behavior at the time of the experiment, the variance of
    the outcome will be smaller and we will be able to capture the small treatment
    effect as shown next:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/b66403cb770bc847546dd9990e3dd786.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: To aid in intuition, let’s partial out the effects of the covariates from both
    the treatment and the outcome first, and then plot the resulting residuals.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We see how the remaining variation in outcome residuals is much smaller in both
    groups and the regression line from the residuals of control to the residuals
    of treatment has a positive slope now.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f77ecc67940de24a77020a1d1163c88f.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
- en: Figure 3 by author
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Comparing the variance of the original spending amount to that of the residuals
    of the spending amount confirms that we are able to achieve a more than 80% reduction
    in variance.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/16998e616ed4576669826c802cb1b17b.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
- en: 'Due to the mechanics of regression, which if you’re interested can learn more
    about in this [post](https://medium.com/towards-data-science/the-fwl-theorem-or-how-to-make-all-regressions-intuitive-59f801eb3299),
    we can obtain the same result by regressing the residuals of the spending amount
    against the residuals of the treatment:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于回归机制，你如果感兴趣可以在这篇[文章](https://medium.com/towards-data-science/the-fwl-theorem-or-how-to-make-all-regressions-intuitive-59f801eb3299)中了解更多，我们可以通过对支出金额的残差进行回归，得到与对处理的残差回归相同的结果：
- en: '[PRE9]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/14e5501f9f9d8f261e39a6f4685148f5.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/14e5501f9f9d8f261e39a6f4685148f5.png)'
- en: Conclusion
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: Applying a simple regression adjustment to our experiment analysis can go a
    long way in reducing the variance of our outcome metric, which can be particularly
    helpful if we are trying to detect a small effect in our experiment. In part 2
    of this series we will do a deep dive into finding out the performances of various
    methods in this space. Specifically, we will be running simulations with varying
    degrees of complexities in the data generating process and applying MLRATE - machine
    learning regression-adjusted treatment effect estimator, the latest invention
    in this space, as well as other methods such as CUPED and regression adjustment.
    Stay tuned.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们的实验分析应用简单的回归调整，可以大大减少结果指标的方差，这在我们尝试检测实验中的小效果时尤为有用。在本系列的第2部分，我们将深入探讨各种方法在这个领域的表现。具体而言，我们将运行具有不同复杂度的数据生成过程的模拟，并应用MLRATE
    - 机器学习回归调整处理效应估计器，这一领域的最新发明，以及其他方法如CUPED和回归调整。敬请关注。
- en: Code
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: The code for this analysis can be found in my github [repository](https://github.com/muratunalphd/Blog-Posts).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 此分析的代码可以在我的github[仓库](https://github.com/muratunalphd/Blog-Posts)中找到。
- en: Thanks for reading! Comments/suggestions are welcome.
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 感谢阅读！欢迎评论/建议。
