- en: The Lifetime of a Machine Learning Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-lifetime-of-a-machine-learning-model-392e1fadf84a?source=collection_archive---------1-----------------------#2023-05-11](https://towardsdatascience.com/the-lifetime-of-a-machine-learning-model-392e1fadf84a?source=collection_archive---------1-----------------------#2023-05-11)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: When are they born and how do they transform?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@valefonsecadiaz?source=post_page-----392e1fadf84a--------------------------------)[![Valeria
    Fonseca Diaz](../Images/880222be555e8fa7df660f9dd1233818.png)](https://medium.com/@valefonsecadiaz?source=post_page-----392e1fadf84a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----392e1fadf84a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----392e1fadf84a--------------------------------)
    [Valeria Fonseca Diaz](https://medium.com/@valefonsecadiaz?source=post_page-----392e1fadf84a--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6e363caf1c79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-lifetime-of-a-machine-learning-model-392e1fadf84a&user=Valeria+Fonseca+Diaz&userId=6e363caf1c79&source=post_page-6e363caf1c79----392e1fadf84a---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----392e1fadf84a--------------------------------)
    ·7 min read·May 11, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F392e1fadf84a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-lifetime-of-a-machine-learning-model-392e1fadf84a&user=Valeria+Fonseca+Diaz&userId=6e363caf1c79&source=-----392e1fadf84a---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F392e1fadf84a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-lifetime-of-a-machine-learning-model-392e1fadf84a&source=-----392e1fadf84a---------------------bookmark_footer-----------)![](../Images/1b2d405d6df597874188f4b038592a42.png)'
  prefs: []
  type: TYPE_NORMAL
- en: The Lifetime of a machine learning model (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: How are your models changing?
  prefs: []
  type: TYPE_NORMAL
- en: Many are those entities that have a lifetime, living things, inert ones, and
    nowadays, digital bodies. For the first ones, we know a lot about when they are
    born, how they grow, and when they die. For the second ones, even if they don’t
    have a biological lifetime, inert things emerge from something and they can also
    be transformed to become something else. As for the third ones, when are the digital
    entities born, and how do they experience transformation?
  prefs: []
  type: TYPE_NORMAL
- en: Talking about the lifetime of a digital entity is quite similar to talking about
    it for inert things. Let’s think about a rock. There’s a point for the formation
    of a rock starting from magma. Then, there are many ways in which a rock can change.
    It can be back to the magma point after melting, or it can be disintegrated by
    many other types of transformations. If geology is too much, let’s think about
    another tool, like a simple pencil. We gather some materials, like wood and polishers,
    and we *build* a pencil. After being in the hands of others, pencils are consumed,
    or broken and even divided into small pieces to make tiny pencils. Our original
    pencil has *lived a life*. As a matter of fact, this process is not different
    for digital or virtual entities, such as our machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: '**A model is born**'
  prefs: []
  type: TYPE_NORMAL
- en: These digital tools are born when we *build, train, fit, or estimate* our model.
    This phase pretty much starts with having an analytical objective, data, computers,
    algorithms, and everything else data scientists are by now well aware of. Whatever
    other tools you gather, never forget about the analytical or scientific objective
    so your final model means something and serves a specific need. When is your model
    born? When you finish training it and save it for employment/deployment, the lifetime
    of this tool has begun.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3897f0a63969cd73acdff522ffac1884.png)'
  prefs: []
  type: TYPE_IMG
- en: A model is born (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: What’s ahead of this newborn? That will depend on the analytical objective,
    so that’s why we cannot forget that part when building it. This model may serve
    prediction tasks, interpretation of indicators, or simulation of what-if scenarios,
    among many other alternatives. This tool will be used for something. Something
    that can be easy and fast, or something that can be complex, time-consuming, and
    long-term. Such usage will determine the rest of the life of this model. If the
    model is used for a one-time interpretation of parameters, not much life is ahead.
    But if the model is used for prediction and it’s intended to serve systems with
    online data collection, life is ahead of this newborn. What’s next then?
  prefs: []
  type: TYPE_NORMAL
- en: '**Maintaining the model**'
  prefs: []
  type: TYPE_NORMAL
- en: As we continue using the model, the conditions of the data that supported the
    training of the model will start changing. Right at that change the model starts
    experiencing changes as well. If we build a model for, say, churn prediction with
    a high prediction accuracy at the moment of training, in the near or far future
    the conditions or behavior of customers to be predicted start changing. This change
    is what challenges the prediction performance of our learned model. When those
    changes happen, our model enters a new phase which we call *maintenance*.
  prefs: []
  type: TYPE_NORMAL
- en: During the maintenance stage, we’ll likely need new data. With it, we can update
    the specification of the model. This is not different from taking another machine,
    say a car, and adjusting pieces when the machinery is not working properly. We
    won’t dive into strategies or solutions to perform model maintenance, but generally
    speaking, our models need to undergo a process of adjustment to bring them back
    to satisfactory performance.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/789ecb6d600c820992c1452bf31d5377.png)'
  prefs: []
  type: TYPE_IMG
- en: A model needs maintainance (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: Maintenance of machine learning models is not quite the same as retraining the
    models. Some models may be so simple that retraining them with updated data is
    just as simple. This may be the case with linear architectures or networks with
    very few layers and neurons. But when the models are so complex with large and
    deep architectures, the maintenance phase needs to be much simpler than the expense
    of retraining the model. [This is one of the most important topics nowadays in
    the world of machine learning, as these tools can be so powerful, yet so expensive
    to maintain in the long run.](https://huyenchip.com/2022/02/07/data-distribution-shifts-and-monitoring.html)
  prefs: []
  type: TYPE_NORMAL
- en: Once the model has been adjusted or updated, it is ready to go back to usage,
    so whatever process the model is serving can continue with the updated version.
    Our machine can continue to *live.* Nonetheless, this machine has already experienced
    changes. It has been used, consumed, if you will, and has been transformed into
    something slightly different from its original state. Like pencils, our models
    encounter those moments in which we need to sharpen their tips to preserve them
    so we can continue using them.
  prefs: []
  type: TYPE_NORMAL
- en: '**Transferring a model**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Along the machine learning road, there’s an exit we might need to take: Transfer.
    I was once visiting stunning Iceland when I saw for the first time someone switching
    the tires of their car to go on the icy road. Then when they were back in the
    city, they switched back to the normal tires. When I started studying transfer
    learning, the concept became so clear while remembering the switch of tires for
    cars in Iceland. When new environments/domains come into play, our models enter
    a new phase known as *transfer.*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9f5d02690d5289a389df50a11ad147a2.png)'
  prefs: []
  type: TYPE_IMG
- en: Models can be transferred (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: Just as the same car can be adapted to different grounds by switching the tires
    without having to purchase another separate car, we can add or adapt some parts
    of our models to serve new purposes in new domains without having to build new
    models. Transfer learning is another subfield of study in the machine learning
    literature aiming at optimizing the adjustment of models to simplify the effort
    of training models for new contexts. Popular examples of this are the models for
    image recognition. We train them with images of certain categories and later others
    transfer these models to recognize new categories of images. Many businesses use
    nowadays models such as [RegNet, VGG, Inception, or AlexNet](/the-w3h-of-alexnet-vggnet-resnet-and-inception-7baaaecccc96)
    to adapt them to their own needs.
  prefs: []
  type: TYPE_NORMAL
- en: When we transfer a model, in a way, a new model is born with a lifetime of its
    own, separated from the original one. It will need maintenance just as the original
    model does. With that, we have gone from having one initial entity to probably
    creating a whole population of models. No doubt there’s indeed a lifetime behind
    these digital tools.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/58d19fc21075c772cefa42a8550d960d.png)'
  prefs: []
  type: TYPE_IMG
- en: A population of models. Our models transform in time (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: '**Does our model c*ease to live*?**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The short answer is: yes. They can indeed cease to live when, for example,
    their analytical performance is just systematically unsatisfactory or when they
    have become something so big and so different that the original models are just
    a thing of the past. As we said in the beginning, rocks, pencils, and also cars
    stop existing at some point. Models are not different from these things in that
    regard.'
  prefs: []
  type: TYPE_NORMAL
- en: As real as it is that the model can become extinct, the answer to the question
    of when they reach this point is, to this day, the biggest question we want to
    answer within the machine learning research community. So many developments in
    monitoring the performance of machine learning and model maintenance are all related
    to the question of when the model is just not functional anymore.
  prefs: []
  type: TYPE_NORMAL
- en: One of the reasons why this answer is not a trivial one is because we constantly
    need labels to quantify how satisfactory the performance is. But the biggest paradox
    for machine and statistical learning is exactly that the labels are not available
    and we build these tools to predict them. Another reason is that it can be pretty
    subjective to define the limit of acceptance of change in performance. While scientists
    can propose some limits, businesses may have different tolerance levels.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some points that the data scientist can also think of as part of answering
    this question (with the current open questions):'
  prefs: []
  type: TYPE_NORMAL
- en: Is the training data too outdated? (What is “too outdated”)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How similar is the current version to the original version of the model? (What
    is “similar”?)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Has the variability of the input features and the relationship to the target
    variable completely drifted? (Covariate and concept drift, the two biggest topics
    of research in machine learning maintenance).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the physical process where the model is deployed still in use? If the physical
    infrastructure does not support the deployment of the model anymore, this surely
    marks the end of its lifetime.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ceasing to live for models is not necessarily a negative thing, it also resembles
    a path of their evolution. We need to make sense of its lifetime to keep our physical
    and digital systems up to date and with satisfactory performance.
  prefs: []
  type: TYPE_NORMAL
- en: '**TL;DR: Models are machines that emerge and transform over time**'
  prefs: []
  type: TYPE_NORMAL
- en: When we train a model and start using it, it starts a lifetime road
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simple uses of a model open simple lifetime roads. Complex uses make our models
    change.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changes come from the maintenance of our models. We need to update them or fix
    them. This gives us a new model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Models can be transferred. New domains of use ask for an adjustment of the model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The life of the model is bound to its ongoing valid performance and its suitability
    in our systems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Long live the model!*'
  prefs: []
  type: TYPE_NORMAL
