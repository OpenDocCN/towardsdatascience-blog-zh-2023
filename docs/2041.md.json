["```py\n# Set Run Parameters\n\ntesting=False\nhyperparam_jobs=10\n\n# Set Max Jobs\n\nif testing==False: max_jobs=hyperparam_jobs\nelse: max_jobs=1\n\n# Load Packages\n\nfrom sagemaker.xgboost.estimator import XGBoost\nfrom sagemaker.tuner import IntegerParameter\nfrom sagemaker.tuner import ContinuousParameter\nfrom sagemaker.tuner import HyperparameterTuner\nfrom sagemaker.tuner import WarmStartConfig, WarmStartTypes\n\n# Configure Warm Start\nnumber_of_parent_jobs=1\n\n# Can be up to 5, but currently only a value of 1 is supported in the code\n# Note base_dir needs to be set, can also be set blank\n\ntry: eligible_parent_tuning_jobs=pd.read_csv(f\"\"\"{base_dir}logs/tuningjobhistory.csv\"\"\")\nexcept: \n    eligible_parent_tuning_jobs=pd.DataFrame({'datetime':[],'tuningjob':[],'metric':[],'layer':[],'objective':[],'eval_metric':[],'eval_metric_value':[],'trainingjobcount':[]})\n    eligible_parent_tuning_jobs.to_csv(f\"\"\"{base_dir}logs/tuningjobhistory.csv\"\"\",index=False)\neligible_parent_tuning_jobs=eligible_parent_tuning_jobs[(eligible_parent_tuning_jobs['layer']==prefix)&(eligible_parent_tuning_jobs['metric']==metric)&(eligible_parent_tuning_jobs['objective']==trainingobjective)&(eligible_parent_tuning_jobs['eval_metric']==objective_metric_name)&(eligible_parent_tuning_jobs['trainingjobcount']>1)].sort_values(by='datetime',ascending=True)\neligible_parent_tuning_jobs_count=len(eligible_parent_tuning_jobs)\nif eligible_parent_tuning_jobs_count>0:\n    parent_tuning_jobs=eligible_parent_tuning_jobs.iloc[(eligible_parent_tuning_jobs_count-(number_of_parent_jobs)):eligible_parent_tuning_jobs_count,1].iloc[0]\n    warm_start_config = WarmStartConfig(\n    WarmStartTypes.TRANSFER_LEARNING, parents={parent_tuning_jobs})\n    # Note that WarmStartTypes.IDENTICAL_DATA_AND_ALGORITHM can be used when applicable\n\n    print(f\"\"\"Warm starting using tuning job: {parent_tuning_jobs[0]}\"\"\")\n\nelse: warm_start_config = None\n\n# Define exploration boundaries (default suggested values from Amazon SageMaker Documentation)\n\nhyperparameter_ranges = {\n    'eta': ContinuousParameter(0.1, 0.5, scaling_type='Logarithmic'),\n    'max_depth': IntegerParameter(0,10,scaling_type='Auto'),\n    'num_round': IntegerParameter(1,4000,scaling_type='Auto'),\n    'subsample': ContinuousParameter(0.5,1,scaling_type='Logarithmic'),\n    'colsample_bylevel': ContinuousParameter(0.1, 1,scaling_type=\"Logarithmic\"),\n    'colsample_bytree': ContinuousParameter(0.5, 1, scaling_type='Logarithmic'),\n    'alpha': ContinuousParameter(0, 1000, scaling_type=\"Auto\"),\n    'lambda': ContinuousParameter(0,100,scaling_type='Auto'),\n    'max_delta_step': IntegerParameter(0,10,scaling_type='Auto'),\n    'min_child_weight': ContinuousParameter(0,10,scaling_type='Auto'),\n    'gamma':ContinuousParameter(0, 5, scaling_type='Auto'),\n}\ntuner_log = HyperparameterTuner(\n    estimator,\n    objective_metric_name,\n    hyperparameter_ranges,\n    objective_type='Minimize', \n    max_jobs=max_jobs,\n    max_parallel_jobs=10,\n    strategy='Bayesian',\n    base_tuning_job_name=\"transferlearning\",\n    warm_start_config=warm_start_config\n)\n\n# Note a SageMaker XGBoost estimater needs to be instantiated in advance\ntraining_input_config = sagemaker.TrainingInput(\"s3://{}/{}/{}\".format(bucket,prefix,filename), content_type='csv')\nvalidation_input_config = sagemaker.TrainingInput(\"s3://{}/{}/{}\".format(bucket,prefix,filename), content_type='csv')\n\n# Note bucket, prefix, and filename objects/aliases need to be set\n\n# Starts the hyperparameter tuning job\n\ntuner_log.fit({'train': training_input_config, 'validation': validation_input_config})\n\n# Prints the status of the latest hyperparameter tuning job\n\nboto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n    HyperParameterTuningJobName=tuner_log.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']\n```", "```py\neligible_parent_tuning_jobs=eligible_parent_tuning_jobs[(eligible_parent_tuning_jobs['layer']==prefix)&(eligible_parent_tuning_jobs['metric']==metric)&(eligible_parent_tuning_jobs['objective']==trainingobjective)&(eligible_parent_tuning_jobs['eval_metric']==objective_metric_name)&(eligible_parent_tuning_jobs['trainingjobcount']>1)].sort_values(by='datetime',ascending=True)\n```", "```py\n# Append Last Parent Job for Next Warm Start\n\neligible_parent_tuning_jobs=pd.read_csv(f\"\"\"{base_dir}logs/tuningjobhistory.csv\"\"\")\nlatest_tuning_job=boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n    HyperParameterTuningJobName=tuner_log.latest_tuning_job.job_name)\nupdatetuningjobhistory=pd.concat([eligible_parent_tuning_jobs,pd.DataFrame({'datetime':[datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")],'tuningjob':[latest_tuning_job['HyperParameterTuningJobName']],'metric':[metric],'layer':prefix,'objective':[trainingobjective],'eval_metric':[latest_tuning_job['BestTrainingJob']['FinalHyperParameterTuningJobObjectiveMetric']['MetricName']],'eval_metric_value':latest_tuning_job['BestTrainingJob']['FinalHyperParameterTuningJobObjectiveMetric']['Value'],'trainingjobcount':[latest_tuning_job['HyperParameterTuningJobConfig']['ResourceLimits']['MaxNumberOfTrainingJobs']]})],axis=0)\nprint(updatetuningjobhistory)\n\n# Write locally\n\nupdatetuningjobhistory.to_csv(f\"\"\"{base_dir}logs/tuningjobhistory.csv\"\"\",index=False)\n\n# Upload to s3\n\ns3.upload_file(f\"\"\"{base_dir}logs/tuningjobhistory.csv\"\"\",bucket,'logs/tuningjobhistory.csv')\n```", "```py\n# Connect to Data Warehouse\n\ndbname='<insert here>'\nhost='<insert here>'\npassword='<insert here>'\nport='<insert here>'\nsearch_path='<insert here>'\nuser='<insert here>'\n\nimport psycopg2\ndata_warehouse= psycopg2.connect(f\"\"\"host={host} port={port} dbname={dbname} user={user} password={password} options = '-c search_path={search_path}'\"\"\")\n\n# Set Dataset Date Floor and Ceiling Applied to Pass in & Apply to Query\n\ndatestart=date(2000, 1, 1)\npushbackdays=30\ndateend=date.today() - timedelta(days=pushbackdays)\nprint(datestart)\nprint(dateend)\n\n# Query data warehouse\n\nmodelbuildingset=pd.read_sql_query(f\"\"\"<insert query>\"\"\",data_warehouse)\n\n# Write .csv\n\nmodelbuildingset.to_csv(f\"{base_dir}datasets/{filename}\", index=False)\nmodelbuildingset\n\n# Upload to s3 for Lineage Tracking\n\ns3 = boto3.client('s3')\ns3.upload_file(f\"{base_dir}datasets/{filename}\",bucket,f\"datasets/{filename}\")\n```", "```py\n# Get the Best Training Job\n\nbest_overall_training_job_name = latest_tuning_job['BestTrainingJob']['TrainingJobName']\n\n# latest_tuning_job was obtained from the hyperparameter tuning section\nlatest_tuning_job['BestTrainingJob']\n\n# Install XGBoost\n\n! pip install xgboost\n\n# Download the Best Model\n\ns3 = boto3.client('s3')\ns3.download_file('<s3 bucket>', f\"\"\"output/{best_overall_training_job_name}/output/model.tar.gz\"\"\", f\"\"\"{base_dir}models/{metric}/model.tar.gz\"\"\")\n\n# Open and Load the Downloaded Model Artifact in Memory\n\ntar = tarfile.open(f\"\"\"{base_dir}models/{metric}/model.tar.gz\"\"\")\ntar.extractall(f\"\"\"{base_dir}models/{metric}\"\"\")\ntar.close()\nmodel = pkl.load(open(f\"\"\"{base_dir}models/{layer}/{metric}/xgboost-model\"\"\", 'rb'))\n\n# Perform Model Evaluation\n\nimport json\nimport pathlib\nimport joblib\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nimport math\nevaluationset=pd.read_csv(f\"\"\"{base_dir}datasets/{layer}/{metric}/{metric}modelbuilding_test.csv\"\"\")\nevaluationset['prediction']=model.predict(xgboost.DMatrix(evaluationset.drop(evaluationset.columns.values[0], axis=1), label=evaluationset[[evaluationset.columns.values[0]]]))\n\n# In the Example a Regression Problem is Used with MAE & RMSE as Eval Metrics\n\nmae = mean_absolute_error(evaluationset[evaluationset.columns.values[0]], evaluationset['prediction'])\nrmse = math.sqrt(mean_squared_error(evaluationset[evaluationset.columns.values[0]], evaluationset['prediction']))\nstdev_error = np.std(evaluationset[evaluationset.columns.values[0]] - evaluationset['prediction'])\nevaluation_report=pd.DataFrame({'datetime':[datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")], 'testing':[testing], 'trainingjob': [best_overall_training_job_name], 'objective':[trainingobjective], 'hyperparameter_tuning_metric':[objective_metric_name], 'mae':[mae], 'rmse':[rmse], 'stdev_error':[stdev_error]})\n\n# Load Past Evaluation Reports\n\ntry: past_evaluation_reports=pd.read_csv(f\"\"\"{base_dir}models/{metric}/evaluationhistory.csv\"\"\")\nexcept: past_evaluation_reports=pd.DataFrame({'datetime':[],'testing':[], 'trainingjob': [], 'objective':[], 'hyperparameter_tuning_metric':[], 'mae':[], 'rmse':[], 'stdev_error':[]})\nevaluation_report=pd.concat([past_evaluation_reports,evaluation_report],axis=0)\nprint(evaluation_report)\n\n# Write .csv\n\nevaluation_report.to_csv(f\"\"\"{base_dir}models/{metric}/evaluationhistory.csv\"\"\",index=False)\n\n# Write to s3\n\ns3.upload_file(f\"\"\"{base_dir}models/{metric}/evaluationhistory.csv\"\"\",'<s3 bucket>',f\"\"\"{layer}/{metric}/evaluationhistory.csv\"\"\")\n\n# Note Can Also Associate a Registered Model with Eval Metrics, But Will Skip it Here\n\nreport_dict = {}\n\n# Register Model\n\nmodel_package_group_name='<>'\nmodelpackage_inference_specification =  {\n    \"InferenceSpecification\": {\n      \"Containers\": [\n         {\n            \"Image\": xgboost_container,\n     \"ModelDataUrl\": f\"\"\"s3://{s3 bucket}/output/{best_overall_training_job_name}/output/model.tar.gz\"\"\"\n         }\n      ],\n      \"SupportedContentTypes\": [ \"text/csv\" ],\n      \"SupportedResponseMIMETypes\": [ \"text/csv\" ],\n   }\n }\ncreate_model_package_input_dict = {\n    \"ModelPackageGroupName\" : model_package_group_name,\n    \"ModelPackageDescription\" : \"<insert description here>\",\n    \"ModelApprovalStatus\" : \"PendingManualApproval\",\n    \"ModelMetrics\" :report_dict\n}\ncreate_model_package_input_dict.update(modelpackage_inference_specification)\nsm_client = boto3.client('sagemaker')\ncreate_model_package_response = sm_client.create_model_package(**create_model_package_input_dict)\nmodel_package_arn = create_model_package_response[\"ModelPackageArn\"]\nprint('ModelPackage Version ARN : {}'.format(model_package_arn))\n```", "```py\n# Load Container\n\nfrom sagemaker.xgboost.estimator import XGBoost\nxgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-2\")\n\n# One Time: Build Multi Model\n\nestimator = sagemaker.estimator.Estimator.attach('sagemaker-xgboost-220611-1453-011-699894eb')\nxgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-2\")\nmodel = estimator.create_model(role=role, image_uri=xgboost_container)\nfrom sagemaker.multidatamodel import MultiDataModel\nsagemaker_session=sagemaker.Session()\n\n# This is where our MME will read models from on S3.\n\nmodel_data_prefix = f\"s3://{bucket}/models/\"\nmme = MultiDataModel(\n    name=model_name,\n    model_data_prefix=model_data_prefix,\n    model=model,  # passing our model - passes container image needed for the endpoint\n    sagemaker_session=sagemaker_session,\n)\n\n# One Time: Deploy the MME\n\nENDPOINT_INSTANCE_TYPE = \"ml.m4.xlarge\"\nENDPOINT_NAME = \"<insert here>\"\npredictor = mme.deploy(\n    initial_instance_count=1, instance_type=ENDPOINT_INSTANCE_TYPE, endpoint_name=ENDPOINT_NAME,kms_key='<insert here if desired>'\n)\n```", "```py\nmodel=sagemaker.model.Model(model_name)\n\nfrom sagemaker.multidatamodel import MultiDataModel\nsagemaker_session=sagemaker.Session()\n\n# This is where our MME will read models from on S3.\nmodel_data_prefix = f\"s3://{bucket}/models/\"\n\nmme = MultiDataModel(\n    name=model_name,\n    model_data_prefix=model_data_prefix,\n    model=model,  # passing our model - passes container image needed for the endpoint\n    sagemaker_session=sagemaker_session,\n)\n```", "```py\n# Get the latest model version and associated artifact location for a given model package group\n\nModelPackageGroup = 'model_package_group'\n\nlist_model_packages_response = client.list_model_packages(ModelPackageGroupName=f\"arn:aws:sagemaker:{region}:{aws_account_id}:model-package-group/{ModelPackageGroup}\")\nlist_model_packages_response\n\nlatest_model_version_arn = list_model_packages_response[\"ModelPackageSummaryList\"][0][\n    \"ModelPackageArn\"\n]\nprint(latest_model_version_arn)\n\nmodelpackage=client.describe_model_package(ModelPackageName=latest_model_version_arn)\nmodelpackage\n\nartifact_path=modelpackage['InferenceSpecification']['Containers'][0]['ModelDataUrl']\nartifact_path\n\n# Add model if approved\n\nif list_model_packages_response[\"ModelPackageSummaryList\"][0]['ModelApprovalStatus']==\"Approved\":\n    model_artifact_name='<model_name>.tar.gz'\n    mme.add_model(model_data_source=artifact_path, model_data_path=model_artifact_name)\n```", "```py\nlist(mme.list_models())\n\n# Output we'd see if we added the following two models\n['modela.tar.gz','modelb.tar.gz']\n```", "```py\nresponse = runtime_sagemaker_client.invoke_endpoint(\n                        EndpointName = \"<endpoint_name>\",\n                        ContentType  = \"text/csv\",\n                        TargetModel  = \"<model_name>.tar.gz\",\n                        Body         = body)\n```", "```py\n# Get datetime for endpoint configuration\n\ntime=str(datetime.now())[0:10]+'--'+str(datetime.now())[11:13]+'-'+'00'\ntime\n\n# Create new endpoint config in order to 'refresh' loaded models to account for new deployments\ncreate_endpoint_config_api_response = client.create_endpoint_config(\n                                            EndpointConfigName=f\"\"\"<endpoint name>-{time}\"\"\",\n                                            ProductionVariants=[\n                                                {\n                                                    'VariantName': model_name,\n                                                    'ModelName': model_name,\n                                                    'InitialInstanceCount': 1,\n                                                    'InstanceType': instance_type\n                                                },\n                                            ]\n                                       )\n\n# Update endpoint with new config\n\nresponse = client.update_endpoint(\n    EndpointName=endpoint_name,\n    EndpointConfigName=f\"\"\"{model_name}-{time}\"\"\")\nresponse\n```", "```py\n# Get AWS Account ID\n\naws_account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\naws_account_id\n\n# Set Bucket & Instance Type Across Accounts\n\nif aws_account_id=='<insert AWS Account_ID 1>': \n    bucket='<insert s3 bucket name 1>'\n    instance_type='ml.t2.medium'\nelif aws_account_id=='<insert AWS Account_ID 2>': \n    bucket='<insert s3 bucket name 2>'\n    instance_type='ml.t2.medium'\nelif aws_account_id=='<insert AWS Account_ID 3>': \n    bucket='<insert s3 bucket name 3>'\n    instance_type='ml.m5.large'\ntraining_account_bucket='<insert training account bucket name>'\nbucket_path = 'https://s3-{}.amazonaws.com/{}'.format(region,bucket)\n```"]