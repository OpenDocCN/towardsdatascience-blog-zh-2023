["```py\ntokenizer = AutoTokenizer.from_pretrained(\"yanekyuk/bert-uncased-keyword-extractor\")\nmodel = AutoModelForTokenClassification.from_pretrained(\n    \"yanekyuk/bert-uncased-keyword-extractor\"\n)\n\nnlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n```", "```py\ndef extract_keywords(text):\n    \"\"\"\n    Extract keywords and construct them back from tokens\n    \"\"\"\n    result = list()\n    keyword = \"\"\n    for token in nlp(text):\n        if token['entity'] == 'I-KEY':\n            keyword += token['word'][2:] if \\\n              token['word'].startswith(\"##\") else f\" {token['word']}\"\n        else:\n            if keyword:\n                result.append(keyword)\n            keyword = token['word']\n    # Add the last keyword\n    result.append(keyword)\n    return list(set(result))\n\nextract_keywords(\"\"\"\nBroadcom agreed to acquire cloud computing company VMware in a $61 billion (â‚¬57bn) cash-and stock deal.\n\"\"\") # ['cloud computing', 'vmware', 'broadcom']\n```", "```py\nfrom sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n\ndef generate_embeddings(text):\n    embeddings = model.encode(text)\n    return [float(x) for x in embeddings.tolist()]\n```", "```py\ngds.run_cypher(\"\"\"\nCALL apoc.meta.stats()\nYIELD labels, relTypesCount\n\"\"\")\n```", "```py\ngds.run_cypher(\"\"\"\nMATCH (p:Page)\nRETURN p.has_text AS has_text,\n       count(*) AS count\n\"\"\")\n```", "```py\ngds.run_cypher(\"\"\"\nMATCH (p:Page)\nWHERE p.has_text IS NULL\nRETURN p.url AS page,\n       count{(p)<-[:LINKS_TO|REDIRECTS]-()} AS links\nORDER BY links DESC\nLIMIT 5\n\"\"\")\n```", "```py\ngds.run_cypher(\"\"\"\nMATCH (:Page)-[:LINKS_TO|REDIRECTS]->(:Page{is_404:true})\nRETURN count(*) AS brokenLinkCount\n\"\"\")\n```", "```py\ngds.run_cypher(\"\"\"\nMATCH (start:Page {url:\"https://neo4j.com/docs\"}), \n      (end:Page {url:\"https://console.neo4j.io\"})\nMATCH p=shortestPath((start)-[:LINKS_TO|REDIRECTS*..10]->(end))\nRETURN [n in nodes(p) | n.url] AS path\n\"\"\")\n```", "```py\nG, metadata = gds.graph.project('structure', 'Page', \n  ['LINKS_TO', 'REDIRECTS'])\n```", "```py\ndf = gds.degree.stream(G, orientation=\"REVERSE\")\ndf[\"url\"] = [d[\"url\"] for d in gds.util.asNodes(df[\"nodeId\"].to_list())]\ndf.sort_values(\"score\", ascending=False, inplace=True)\ndf.head()\n```", "```py\npr_df = gds.pageRank.stream(G)\npr_df[\"pagerank\"] = pr_df.pop(\"score\")\ncombined_df = df.merge(pr_df, on=\"nodeId\")\ncombined_df.sort_values(\"pagerank\", ascending=False, inplace=True)\n```", "```py\ngds.run_cypher(\"\"\"\nMATCH (k:Keyword)\nRETURN k.name AS keyword,\n       count {(k)<-[:HAS_KEYWORD]-()} AS mentions\nORDER BY mentions DESC\nLIMIT 5\n\"\"\")\n```", "```py\ngds.run_cypher(\"\"\"\nMATCH (p:Page)-[:HAS_KEYWORD]->(k:Keyword)\nWHERE p.url CONTAINS \"graph-data-science\"\nRETURN k.name AS keyword,\n       count(*) AS mentions\nORDER BY mentions DESC\nLIMIT 5\n\"\"\")\n```", "```py\nG, metadata = gds.graph.project(\n    \"keywords\", [\"Page\", \"Keyword\"], {\"HAS_KEYWORD\": {\"orientation\": \"REVERSE\"}}\n)\n```", "```py\ngds.nodeSimilarity.mutate(\n    G, mutateRelationshipType=\"CO_OCCUR\", mutateProperty=\"score\", \n    similarityCutoff=0.4\n)\n```", "```py\ntopic_df = gds.louvain.stream(G, nodeLabels=[\"Keyword\"], relationshipTypes=[\"CO_OCCUR\"])\ntopic_df[\"keyword\"] = [\n    n[\"name\"] for n in gds.util.asNodes(topic_df[\"nodeId\"].to_list())\n]\ntopic_df.groupby(\"communityId\").agg(\n    {\"keyword\": [\"size\", list]}\n).reset_index().sort_values([(\"keyword\", \"size\")], ascending=False).head()\n```"]