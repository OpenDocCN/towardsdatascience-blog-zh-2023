- en: Model Optimization with TensorFlow
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow 的模型优化
- en: 原文：[https://towardsdatascience.com/model-optimization-with-tensorflow-629342d1a96f?source=collection_archive---------16-----------------------#2023-04-17](https://towardsdatascience.com/model-optimization-with-tensorflow-629342d1a96f?source=collection_archive---------16-----------------------#2023-04-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/model-optimization-with-tensorflow-629342d1a96f?source=collection_archive---------16-----------------------#2023-04-17](https://towardsdatascience.com/model-optimization-with-tensorflow-629342d1a96f?source=collection_archive---------16-----------------------#2023-04-17)
- en: MLOps
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLOps
- en: Reduce your models' latency, storage, and inference costs with quantization
    and pruning
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过量化和剪枝减少模型的延迟、存储和推理成本
- en: '[](https://michaloleszak.medium.com/?source=post_page-----629342d1a96f--------------------------------)[![Michał
    Oleszak](../Images/61b32e70cec4ba54612a8ca22e977176.png)](https://michaloleszak.medium.com/?source=post_page-----629342d1a96f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----629342d1a96f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----629342d1a96f--------------------------------)
    [Michał Oleszak](https://michaloleszak.medium.com/?source=post_page-----629342d1a96f--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://michaloleszak.medium.com/?source=post_page-----629342d1a96f--------------------------------)[![Michał
    Oleszak](../Images/61b32e70cec4ba54612a8ca22e977176.png)](https://michaloleszak.medium.com/?source=post_page-----629342d1a96f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----629342d1a96f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----629342d1a96f--------------------------------)
    [Michał Oleszak](https://michaloleszak.medium.com/?source=post_page-----629342d1a96f--------------------------------)'
- en: ·
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc58320fab2a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-optimization-with-tensorflow-629342d1a96f&user=Micha%C5%82+Oleszak&userId=c58320fab2a8&source=post_page-c58320fab2a8----629342d1a96f---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----629342d1a96f--------------------------------)
    ·9 min read·Apr 17, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F629342d1a96f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-optimization-with-tensorflow-629342d1a96f&user=Micha%C5%82+Oleszak&userId=c58320fab2a8&source=-----629342d1a96f---------------------clap_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc58320fab2a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-optimization-with-tensorflow-629342d1a96f&user=Micha%C5%82+Oleszak&userId=c58320fab2a8&source=post_page-c58320fab2a8----629342d1a96f---------------------post_header-----------)
    发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----629342d1a96f--------------------------------)
    ·9分钟阅读·2023年4月17日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F629342d1a96f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-optimization-with-tensorflow-629342d1a96f&user=Micha%C5%82+Oleszak&userId=c58320fab2a8&source=-----629342d1a96f---------------------clap_footer-----------)'
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F629342d1a96f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-optimization-with-tensorflow-629342d1a96f&source=-----629342d1a96f---------------------bookmark_footer-----------)![](../Images/ff833d1ba8f3475a8a12f0187b1f2a2c.png)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F629342d1a96f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-optimization-with-tensorflow-629342d1a96f&source=-----629342d1a96f---------------------bookmark_footer-----------)![](../Images/ff833d1ba8f3475a8a12f0187b1f2a2c.png)'
- en: 'Over the last few years, machine learning models have seen two seemingly opposing
    trends. On the one hand, the models tend to get bigger and bigger, culminating
    in what’s all the rage these days: the [large language models](https://pub.towardsai.net/forget-about-chatgpt-f17a7f5089c3).
    Nvidia’s [Megatron-Turing Natural Language Generation](https://developer.nvidia.com/megatron-turing-natural-language-generation)
    model has 530 billion parameters! On the other hand, these models are being deployed
    onto smaller and smaller devices, such as smartwatches or drones, whose memory
    and computing power are naturally limited by their size.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，机器学习模型出现了两种看似对立的趋势。一方面，模型越来越大，达到当前流行的[大型语言模型](https://pub.towardsai.net/forget-about-chatgpt-f17a7f5089c3)。Nvidia
    的[Megatron-Turing自然语言生成](https://developer.nvidia.com/megatron-turing-natural-language-generation)模型有5300亿个参数！另一方面，这些模型被部署到越来越小的设备上，例如智能手表或无人机，这些设备的内存和计算能力自然受到其尺寸的限制。
- en: 'How do we squeeze ever larger models into increasingly smaller devices? The
    answer is model optimization: the process of compressing the model in size and
    reducing its latency. In this article, we will see how it works and how to implement
    two popular model optimization methods — quantization and pruning — in TensorFlow.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何将越来越大的模型压缩到越来越小的设备中？答案是模型优化：压缩模型的大小并减少其延迟的过程。在本文中，我们将深入了解其工作原理以及如何在 TensorFlow
    中实现两种流行的模型优化方法——量化和剪枝。
- en: Baseline model
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基线模型
- en: 'Before we jump to model optimization techniques, we need a toy model to be
    optimized. Let’s train a simple binary classifier to differentiate between Paris’
    two famous landmarks: the Eiffel Tower and the Mona Lisa, as drawn by the players
    of [Google’s game called “Quick, Draw!”](https://quickdraw.withgoogle.com/). The
    [QuickDraw dataset](https://github.com/googlecreativelab/quickdraw-dataset)…'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨模型优化技术之前，我们需要一个可以优化的玩具模型。让我们训练一个简单的二分类器，以区分巴黎的两个著名地标：**埃菲尔铁塔**和**蒙娜丽莎**，这些都是由[谷歌的“快速绘画！”游戏](https://quickdraw.withgoogle.com/)的玩家绘制的。[QuickDraw
    数据集](https://github.com/googlecreativelab/quickdraw-dataset)…
