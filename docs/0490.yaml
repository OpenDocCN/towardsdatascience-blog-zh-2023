- en: 'Prediction Performance Drift: The Other Side of the Coin'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/prediction-performance-drift-the-other-side-of-the-coin-4bd3c7334b70?source=collection_archive---------12-----------------------#2023-02-02](https://towardsdatascience.com/prediction-performance-drift-the-other-side-of-the-coin-4bd3c7334b70?source=collection_archive---------12-----------------------#2023-02-02)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We know the causes, let’s talk about the types
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@valefonsecadiaz?source=post_page-----4bd3c7334b70--------------------------------)[![Valeria
    Fonseca Diaz](../Images/880222be555e8fa7df660f9dd1233818.png)](https://medium.com/@valefonsecadiaz?source=post_page-----4bd3c7334b70--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4bd3c7334b70--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4bd3c7334b70--------------------------------)
    [Valeria Fonseca Diaz](https://medium.com/@valefonsecadiaz?source=post_page-----4bd3c7334b70--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6e363caf1c79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprediction-performance-drift-the-other-side-of-the-coin-4bd3c7334b70&user=Valeria+Fonseca+Diaz&userId=6e363caf1c79&source=post_page-6e363caf1c79----4bd3c7334b70---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4bd3c7334b70--------------------------------)
    ·7 min read·Feb 2, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4bd3c7334b70&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprediction-performance-drift-the-other-side-of-the-coin-4bd3c7334b70&user=Valeria+Fonseca+Diaz&userId=6e363caf1c79&source=-----4bd3c7334b70---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4bd3c7334b70&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprediction-performance-drift-the-other-side-of-the-coin-4bd3c7334b70&source=-----4bd3c7334b70---------------------bookmark_footer-----------)![](../Images/9b43ea980938020e8a079c13523b8d4c.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Two sides of prediction performance drift (Image by author)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: The world of machine learning has moved and grown so fast that in less than
    two decades we are already at the next stage. The models are built, and now we
    need to know if they provide accurate predictions in the short, medium, and long
    term. So many methods, theoretical approaches, schools of thought, paradigms,
    and digital tools are in our pockets when it comes to building our models. Now
    then, we want to understand better what’s at stake when it comes to prediction
    performance in time.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: One may think that the prediction performance of the model is ensured by the
    dictated quality based on a test set, a separate set of samples that were not
    involved in the task during the training of the model at all, yet measured or
    observed at that moment. The reality is that, while the model may have been delivered
    with a certain (hopefully very satisfactory) prediction performance based on that
    test set, the observations that will come in time will not fully share the same
    properties or trends as the training and test sets. Recall that the models are
    [machines](https://medium.com/towards-data-science/is-interpreting-ml-models-a-dead-end-f5b9dd78ba77),
    not thinking entities. If they see something new for which they were not trained,
    they cannot be critical of these new things. We, humans, can.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 有人可能认为，模型的预测性能是由测试集的规定质量来保证的，测试集是一组在模型训练过程中未参与的样本，但在那时进行测量或观察。现实是，尽管模型可能在基于该测试集的情况下以某种（希望非常令人满意的）预测性能交付，但随时间推移的观测将不会完全具备与训练集和测试集相同的属性或趋势。请记住，模型是[机器](https://medium.com/towards-data-science/is-interpreting-ml-models-a-dead-end-f5b9dd78ba77)，而不是思考实体。如果它们看到一些新的、未曾训练过的东西，它们无法对这些新事物进行批判。我们，人类，可以。
- en: '**Prediction performance drift: Side A**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**预测性能漂移：A面**'
- en: The way in which we have been thinking about prediction performance involves
    separating the variability distributions that influence a model. There’s the distribution
    of the input features *P(X****)***, the distribution of the labels *P(Y),* and
    the conditional distribution of the labels given the inputs *P(Y|X).*Any changes
    in any of these components are potential *causes* for the model to make more inaccurate
    predictions with respect to its original performance. With this in mind, if we
    monitor these components and something in them changes at some point, well, that’s
    a moment for a deep check-up to see what’s happening and fix it if necessary.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对预测性能的思考方式涉及将影响模型的变异分布分开。有输入特征的分布*P(X)*、标签的分布*P(Y)*，以及给定输入的标签的条件分布*P(Y|X)*。这些组件中的任何变化都是模型在预测中产生更多不准确结果的潜在*原因*。考虑到这一点，如果我们监控这些组件并且它们中的某些部分发生变化，那么就需要进行深入检查，看看发生了什么，并在必要时修复。
- en: '**Prediction performance drift: Side B**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**预测性能漂移：B面**'
- en: 'While the previous is unquestionable, we can also look at another dimension
    when it comes to prediction performance drift: The *types* of drift. When we look
    at the prediction performance, it’s possible to discriminate between different
    types of drift. Now, why would this be of any use? Well, not only we’ll detect
    that something is changing, but we’ll more easily know how to fix it.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然之前的内容无可争议，但我们也可以从预测性能漂移的另一个维度来观察：*漂移的类型*。当我们观察预测性能时，可以区分不同类型的漂移。那这样做有什么用呢？实际上，这不仅能检测到某些变化，还能更容易地知道如何修复这些变化。
- en: 'There can essentially be 4 types of drift: *Bias, Slope, Variance, and Non-linearities*.
    While these names might hint more particularly at a linear regression model, they
    apply to the general menu of machine learning models. More generalized names for
    these types could be *Constant shift, Rotation with respect to prediction boundary,
    Dispersion collapsing with boundary, and Change of boundary shape*. We may agree
    that the latter names are long and time-consuming to write and talk about, so
    let’s stick to the former names. And while doing so, let’s not confuse any of
    the types with the nature of the model. Any of the 4 types of drifts can occur
    in any type of model.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 漂移的类型大致可以分为四种：*偏差、斜率、方差和非线性*。虽然这些名称可能更具体地指向线性回归模型，但它们也适用于一般的机器学习模型。这些类型的更通用名称可以是*常量偏移、相对于预测边界的旋转、与边界收敛的分散以及边界形状的变化*。我们可能会同意，后者的名称较长且书写和讨论起来比较费时，因此我们坚持使用前者的名称。在这样做的同时，也不要将任何类型与模型的性质混淆。任何四种类型的漂移都可能发生在任何类型的模型中。
- en: '![](../Images/0dc23f137b86b23a721f91e18ed4e4bd.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0dc23f137b86b23a721f91e18ed4e4bd.png)'
- en: Types of drift for regression models (Image by author)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 回归模型的漂移类型（作者提供的图片）
- en: By checking for the different types of drift, not only we’ll detect that something
    is changing, but we’ll more easily know how to fix it.
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 通过检查不同类型的漂移，不仅可以检测到某些变化，还能更容易地知道如何修复这些变化。
- en: '**Side B: The 4 types**'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**B面：四种类型**'
- en: A *bias* drift refers to a constant shift. In a regression model, a bias drift
    is happening if we observe that our predictions are a constant away from the observed
    values. In a classification model, a bias drift will happen if the features for
    each class have a constant shift, which may also be class-specific. This type
    of drift may simply happen because of a change in the average of the population
    without any other changes in the relationships among the features and their impact
    on the target variable. Being a simple change, it may be easily repairable by
    re-shifting the bias of the model or the average in the sample.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: A *slope* drift happens when there’s a rotation with respect to the center of
    the regression function or decision boundary. This type of drift can be very common
    in learning tasks involving images that are taken from different angles while
    being essentially the same image. Depending on the degree of rotation and whether
    the rotation is class-specific for classification tasks, a slope drift may be
    fixed by a simple adjustment of the rotation or by completely retraining the model.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9efcbaf5c190718c64163767a5db6224.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
- en: Example of types of drift for a linear classifier (Image by author)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: A *variance* drift, as its name specifies, it’s an increase in dispersion. It
    will become damaging to the prediction performance if the dispersion pushes the
    samples to cross the task boundaries. In the case of regression, a variance drift
    manifests by larger residuals. In the case of classification, this drift may be
    an expansion of the original dispersion of the features in each class. Here again,
    this drift may be class-specific. This drift may occur due to different causes,
    it may correspond to a bigger sampling close to the decision boundaries or an
    uneven shift of the input features. If due to sampling, this problem might be
    solved by a recalculation of the model with updated data which is more representative
    of the current sampling.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6ee32a4efcadeff058bf73a4a6201fcc.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
- en: Example of types of drift for a non-linear classifier (Image by author)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: The last type of drift is called *non-linear* drift. While looking very specific
    and systematic from the shown examples, this type of drift may contain all types
    of combinations of the aforementioned three types. The famous case when teaching
    artificial neural networks involves 2 input features to separate 2 classes. In
    a 2D space, the 2 classes may be separated by a linear function, but the simple
    rotation of 2 points induces and non-linear change. If the classes can no longer
    be separated by one line, well, the problem has become non-linear. Just as in
    the other cases, for classification tasks, this drift may also be class-specific
    as shown in the linear classification example above. As this is the most complex
    type of drift, the non-linear patterns that may be observed in the prediction
    quality of the model may always force the retraining of the model.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1d0bfad042d282a6aa01ba011a178d8c.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
- en: Example from linear to non-linear classification (Image by author)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '**When is the prediction performance degrading?**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Drifts are not always problematic. Let’s dive a bit into this. A change in the
    center of *X* without a change in the center of *Y*, or vice-versa, will lead
    to a bias drift. However, if both, *X* and *Y* are moving accordingly with the
    model function, there won’t be a prediction performance drift as the model will
    continue making accurate predictions. When it comes to the slope, while for regression
    there’s less room for rotation, in classification tasks the classes may rotate
    without damaging the performance when this rotation does not collapse with the
    decision boundary. This may be a very theoretical fact with a little incidence
    in practice, but hey, that’s how it goes.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Variance drifts may be more realistic for classification problems than slope
    drifts. The model can handle a variance drift as long as the dispersion is not
    collapsing with the decision boundary. When the points start crossing decision
    boundaries, the prediction performance is compromised. The same is true for regression
    models, although, just as in the case of slope drift, there’s very little tolerance
    for dispersion expansion without accounting for prediction degradation.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Non-linear drifts are the least permissive. These changes might *always* be
    problematic. Models can be robust to a lot of changes corresponding to the previous
    drifts, but they are designed to handle a specific task with a specific shape.
    That shape is the representation of the concept that we created the model to predict,
    and if that shape starts changing, the whole concept might be changing. So here
    it’s hard to think of cases in which a non-linear change is not problematic.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '**Let’s keep flipping the coin**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: So here we have a new view to think about the degradation in the prediction
    performance of our models. Having us equipped with not only the causes but now
    with the types, we can keep flipping the coin when monitoring the quality of prediction
    of our models. That way, we not only get information about **what and when** something
    is changing, but also **why** it’s changing as well as **how** it is changing.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '*Are we going to end up formulating the “who” and “where”?*'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
