["```py\n# Start MLflow run for this experiment\n\n# End any existing runs\nmlflow.end_run()\n\nwith mlflow.start_run() as run:\n  # Turn autolog on to save model artifacts, requirements, etc.\n  mlflow.autolog(log_models=True)\n\n  diabetes_X = diabetes.data\n  diabetes_y = diabetes.target\n\n  # Split data into test training sets, 3:1 ratio\n  diabetes_X_train, diabetes_X_test, diabetes_y_train, diabetes_y_test = train_test_split(diabetes_X, diabetes_y, test_size=0.25, random_state=42)\n\n  alpha = 1\n  solver = 'cholesky'\n  regr = linear_model.Ridge(alpha=alpha,solver=solver)\n\n  regr.fit(diabetes_X_train, diabetes_y_train)\n\n  diabetes_y_pred = regr.predict(diabetes_X_test)\n\n  # Log desired metrics\n  mlflow.log_metric(\"mse\", mean_squared_error(diabetes_y_test, diabetes_y_pred))\n  mlflow.log_metric(\"rmse\", sqrt(mean_squared_error(diabetes_y_test, diabetes_y_pred)))\n  mlflow.log_metric(\"r2\", r2_score(diabetes_y_test, diabetes_y_pred))\n```", "```py\nmodel_uri = \"dbfs:/databricks/mlflow-tracking/<>/<>/artifacts/model\"\ndesc = 'Initial model deployment'\nnew_run_id = run.info.run_id\nclient.create_model_version(name, model_uri, new_run_id, description=desc)\nversion = client.search_model_versions(\"run_id='{}'\".format(new_run_id))[0].version\nclient.transition_model_version_stage(name, version, \"Production\")\n```", "```py\n# Import packages\nfrom mlflow.client import MlflowClient\n\n# Set the experiment name to an experiment in the shared experiments folder\nmlflow.set_experiment(\"/diabetes_regression_lab\")\n\nclient = MlflowClient()\n\n# Set model name\nname = 'DiabetesRegressionLab'\n```", "```py\n# Load the diabetes dataset\ndiabetes = datasets.load_diabetes()\n```", "```py\n# 1\\. Mimic results from a week ago, used by our registered production model\ndiabetes_X = diabetes.data[:-20]\ndiabetes_y = diabetes.target[:-20]\n\n# 2\\. Dataset as of point of retraining, used in our latest experiment run\ndiabetes_X = diabetes.data\ndiabetes_y = diabetes.target\n```", "```py\n# Start MLflow run for this experiment: This is similar to your experimentation script\nmlflow.end_run()\n\nwith mlflow.start_run() as run:\n    # Turn autolog on to save model artifacts, requirements, etc.\n  mlflow.autolog(log_models=True)\n\n  # Split data into test training sets, 3:1 ratio\n  diabetes_X_train, diabetes_X_test, diabetes_y_train, diabetes_y_test = train_test_split(diabetes_X, diabetes_y, test_size=0.25, random_state=42)\n\n  alpha = 1\n  solver = 'cholesky'\n  regr = linear_model.Ridge(alpha=alpha,solver=solver)  \n\n  regr.fit(diabetes_X_train, diabetes_y_train)\n\n  diabetes_y_pred = regr.predict(diabetes_X_test)\n\n  # Log desired metrics\n  mlflow.log_metric(\"mse\", mean_squared_error(diabetes_y_test, diabetes_y_pred))\n  mlflow.log_metric(\"rmse\", sqrt(mean_squared_error(diabetes_y_test, diabetes_y_pred)))\n  mlflow.log_metric(\"r2\", r2_score(diabetes_y_test, diabetes_y_pred))\n```", "```py\n# Collect latest run's metrics\nnew_run_id = run.info.run_id\nnew_run = client.get_run(new_run_id)\nnew_metrics = new_run.data.metrics\n\n# Collect production run's metrics\nprod_run_id = client.get_latest_versions(name, stages=[\"Production\"])[0].run_id\nprod_run = client.get_run(prod_run_id)\nprod_metrics = prod_run.data.metrics\n\n# Collate metrics into DataFrame for comparison\ncolumns = ['mse','rmse','r2']\ncolumns = ['version'] + [x for x in sorted(columns)]\nnew_vals = ['new'] + [new_metrics[m] for m in sorted(new_metrics) if m in columns]\nprod_vals = ['prod'] + [prod_metrics[m] for m in sorted(prod_metrics) if m in columns]\ndata = [new_vals, prod_vals]\n\nmetrics_df = pd.DataFrame(data, columns=columns)\nmetrics_df\n```", "```py\n# Retrieve validation variables from the metrics DataFrame\nnew_mse = metrics_df[metrics_df['version'] == 'new']['mse'].values[0]\nnew_rmse = metrics_df[metrics_df['version'] == 'new']['rmse'].values[0]\nnew_r2 = metrics_df[metrics_df['version'] == 'new']['r2'].values[0]\n\nprod_mse = metrics_df[metrics_df['version'] == 'prod']['mse'].values[0]\nprod_rmse = metrics_df[metrics_df['version'] == 'prod']['rmse'].values[0]\nprod_r2 = metrics_df[metrics_df['version'] == 'prod']['r2'].values[0]\n\n# Check new model meets our validation criteria before promoting to production\nif (new_mse < prod_mse) and (new_rmse < prod_rmse) and (new_r2 > prod_r2):\n  model_uri = \"dbfs:/databricks/mlflow-tracking/<>/<>/artifacts/model\"\n  print('run_id is: ', new_run_id)\n\n  desc = 'This model uses Ridge Regression to predict diabetes.'\n\n  client.create_model_version(name, model_uri, new_run_id, description=desc)\n  to_prod_version = client.search_model_versions(\"run_id='{}'\".format(new_run_id))[0].version\n  to_archive_version = client.search_model_versions(\"run_id='{}'\".format(prod_run_id))[0].version\n\n  # Transition new model to Production stage\n  client.transition_model_version_stage(name, to_prod_version, \"Production\")\n\n  # Wait for the transition to complete\n  new_prod_version = client.get_model_version(name, to_prod_version)\n  while new_prod_version.current_stage != \"Production\":\n      new_prod_version = client.get_model_version(name, to_prod_version)\n      print('Transitioning new model... Current model version is: ', new_prod_version.current_stage)\n      time.sleep(1)\n\n  # Transition old model to Archived stage\n  client.transition_model_version_stage(name, to_archive_version, \"Archived\")\n\nelse:\n  print('no improvement') \n```"]