- en: DETR (Transformers for Object Detection)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DETR（用于物体检测的Transformers）
- en: 原文：[https://towardsdatascience.com/detr-transformers-for-object-detection-a8b3327b737a?source=collection_archive---------4-----------------------#2023-10-07](https://towardsdatascience.com/detr-transformers-for-object-detection-a8b3327b737a?source=collection_archive---------4-----------------------#2023-10-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/detr-transformers-for-object-detection-a8b3327b737a?source=collection_archive---------4-----------------------#2023-10-07](https://towardsdatascience.com/detr-transformers-for-object-detection-a8b3327b737a?source=collection_archive---------4-----------------------#2023-10-07)
- en: Deep Dive and clear explanations on the paper “End to end detection with transformers”
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对论文《基于Transformers的端到端检测》的**深度剖析**和清晰解释
- en: '[](https://medium.com/@francoisporcher?source=post_page-----a8b3327b737a--------------------------------)[![François
    Porcher](../Images/9ddb233f8cadbd69026bd79e2bd62dea.png)](https://medium.com/@francoisporcher?source=post_page-----a8b3327b737a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a8b3327b737a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a8b3327b737a--------------------------------)
    [François Porcher](https://medium.com/@francoisporcher?source=post_page-----a8b3327b737a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@francoisporcher?source=post_page-----a8b3327b737a--------------------------------)[![François
    Porcher](../Images/9ddb233f8cadbd69026bd79e2bd62dea.png)](https://medium.com/@francoisporcher?source=post_page-----a8b3327b737a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a8b3327b737a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a8b3327b737a--------------------------------)
    [François Porcher](https://medium.com/@francoisporcher?source=post_page-----a8b3327b737a--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8e8e73046f53&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetr-transformers-for-object-detection-a8b3327b737a&user=Fran%C3%A7ois+Porcher&userId=8e8e73046f53&source=post_page-8e8e73046f53----a8b3327b737a---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a8b3327b737a--------------------------------)
    ·8 min read·Oct 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa8b3327b737a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetr-transformers-for-object-detection-a8b3327b737a&user=Fran%C3%A7ois+Porcher&userId=8e8e73046f53&source=-----a8b3327b737a---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8e8e73046f53&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetr-transformers-for-object-detection-a8b3327b737a&user=Fran%C3%A7ois+Porcher&userId=8e8e73046f53&source=post_page-8e8e73046f53----a8b3327b737a---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a8b3327b737a--------------------------------)
    · 8分钟阅读 · 2023年10月7日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa8b3327b737a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetr-transformers-for-object-detection-a8b3327b737a&user=Fran%C3%A7ois+Porcher&userId=8e8e73046f53&source=-----a8b3327b737a---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa8b3327b737a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetr-transformers-for-object-detection-a8b3327b737a&source=-----a8b3327b737a---------------------bookmark_footer-----------)![](../Images/dae11e25d74f1483e61af5a29e11a35f.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa8b3327b737a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetr-transformers-for-object-detection-a8b3327b737a&source=-----a8b3327b737a---------------------bookmark_footer-----------)![](../Images/dae11e25d74f1483e61af5a29e11a35f.png)'
- en: Photo by [Aditya Vyas](https://unsplash.com/@aditya1702?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 由 [Aditya Vyas](https://unsplash.com/@aditya1702?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) 上拍摄的照片
- en: 'Note: This article delves into the intricate world of Computer Vision, specifically
    focusing on Transformers and the Attention Mechanism. It’s recommended to be acquainted
    with the key concepts from the paper [“Attention is All You Need.”](https://arxiv.org/abs/1706.03762)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：本文**深入**探讨了计算机视觉的复杂世界，特别关注了Transformers和注意力机制。建议了解论文中的关键概念 [“Attention is
    All You Need.”](https://arxiv.org/abs/1706.03762)
- en: A Snapshot of History
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 历史快照
- en: '**DETR**, short for **DE**tection **TR**ansformer, pioneered a novel wave in
    object detection upon its conception by Nicolas Carion and team at **Facebook
    AI Research in 2020.**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**DETR**，即**DE**tection **TR**ansformer，在**2020年由Nicolas Carion及其团队在Facebook
    AI Research**首次提出，开创了物体检测的新潮流。'
- en: While not currently holding the SOTA (State Of The Art) status, DETR’s innovative
    reformulation of object detection tasks has significantly influenced subsequent
    models, such as CO-DETR, which is the current State-of-the-Art in **Object Detection**
    and **Instance Segmentation** on [LVIS](https://www.lvisdataset.org).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然目前并不具备SOTA（最先进技术）的地位，DETR对目标检测任务的创新重新定义已经对后续模型产生了显著影响，如CO-DETR，它是当前在[LVIS](https://www.lvisdataset.org)上的**目标检测**和**实例分割**领域的最先进技术。
- en: Moving away from the conventional one-to-many problem scenario, where each ground
    truth corresponds to myriad anchor candidates, DETR introduces a fresh perspective
    by viewing object detection as a **set prediction problem**, with a one-to-one
    correspondance between predictions and ground truth, thereby eliminating the need
    for certain post-processing techniques.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 摆脱了传统的一对多问题场景，其中每个真实值对应着众多锚点候选，DETR通过将目标检测视为**集合预测问题**，实现了预测与真实值之间的一对一对应，从而消除了某些后处理技术的需求。
- en: Refresher on Object Detection
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标检测概述
