- en: DETR (Transformers for Object Detection)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/detr-transformers-for-object-detection-a8b3327b737a?source=collection_archive---------4-----------------------#2023-10-07](https://towardsdatascience.com/detr-transformers-for-object-detection-a8b3327b737a?source=collection_archive---------4-----------------------#2023-10-07)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Deep Dive and clear explanations on the paper “End to end detection with transformers”
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@francoisporcher?source=post_page-----a8b3327b737a--------------------------------)[![François
    Porcher](../Images/9ddb233f8cadbd69026bd79e2bd62dea.png)](https://medium.com/@francoisporcher?source=post_page-----a8b3327b737a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a8b3327b737a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a8b3327b737a--------------------------------)
    [François Porcher](https://medium.com/@francoisporcher?source=post_page-----a8b3327b737a--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8e8e73046f53&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetr-transformers-for-object-detection-a8b3327b737a&user=Fran%C3%A7ois+Porcher&userId=8e8e73046f53&source=post_page-8e8e73046f53----a8b3327b737a---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a8b3327b737a--------------------------------)
    ·8 min read·Oct 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa8b3327b737a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetr-transformers-for-object-detection-a8b3327b737a&user=Fran%C3%A7ois+Porcher&userId=8e8e73046f53&source=-----a8b3327b737a---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa8b3327b737a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetr-transformers-for-object-detection-a8b3327b737a&source=-----a8b3327b737a---------------------bookmark_footer-----------)![](../Images/dae11e25d74f1483e61af5a29e11a35f.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Aditya Vyas](https://unsplash.com/@aditya1702?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: This article delves into the intricate world of Computer Vision, specifically
    focusing on Transformers and the Attention Mechanism. It’s recommended to be acquainted
    with the key concepts from the paper [“Attention is All You Need.”](https://arxiv.org/abs/1706.03762)'
  prefs: []
  type: TYPE_NORMAL
- en: A Snapshot of History
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**DETR**, short for **DE**tection **TR**ansformer, pioneered a novel wave in
    object detection upon its conception by Nicolas Carion and team at **Facebook
    AI Research in 2020.**'
  prefs: []
  type: TYPE_NORMAL
- en: While not currently holding the SOTA (State Of The Art) status, DETR’s innovative
    reformulation of object detection tasks has significantly influenced subsequent
    models, such as CO-DETR, which is the current State-of-the-Art in **Object Detection**
    and **Instance Segmentation** on [LVIS](https://www.lvisdataset.org).
  prefs: []
  type: TYPE_NORMAL
- en: Moving away from the conventional one-to-many problem scenario, where each ground
    truth corresponds to myriad anchor candidates, DETR introduces a fresh perspective
    by viewing object detection as a **set prediction problem**, with a one-to-one
    correspondance between predictions and ground truth, thereby eliminating the need
    for certain post-processing techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Refresher on Object Detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
