["```py\nimport numpy as np\nfrom PIL import Image\nfrom torchvision.datasets.vision import VisionDataset\ninput_img_size = [533, 800]\nimg_size = 256\n\nclass FakeDataset(VisionDataset):\n    def __init__(self, transform):\n        super().__init__(root=None, transform=transform)\n        size = 10000\n        self.img_files = [f'{i}.jpg' for i in range(size)]\n        self.targets = np.random.randint(low=0,high=num_classes,\n                                         size=(size),dtype=np.uint8).tolist()\n\n    def __getitem__(self, index):\n        img_file, target = self.img_files[index], self.targets[index]\n        img = Image.open(img_file)\n        if self.transform is not None:\n            img = self.transform(img)\n        return img, target\n\n    def __len__(self):\n        return len(self.img_files)\n\ntransform = T.Compose(\n    [T.PILToTensor(),\n     T.RandomCrop(img_size),\n     RandomMask(),\n     ConvertColor(),\n     Scale()])\n```", "```py\nconda install -c conda-forge libjpeg-turbo\n```", "```py\ntorch::Tensor decode_and_crop_jpeg(const torch::Tensor& data,\n                                   unsigned int crop_y,\n                                   unsigned int crop_x,\n                                   unsigned int crop_height,\n                                   unsigned int crop_width) {\n  struct jpeg_decompress_struct cinfo;\n  struct torch_jpeg_error_mgr jerr;\n\n  auto datap = data.data_ptr<uint8_t>();\n  // Setup decompression structure\n  cinfo.err = jpeg_std_error(&jerr.pub);\n  jerr.pub.error_exit = torch_jpeg_error_exit;\n  /* Establish the setjmp return context for my_error_exit to use. */\n  setjmp(jerr.setjmp_buffer);\n  jpeg_create_decompress(&cinfo);\n  torch_jpeg_set_source_mgr(&cinfo, datap, data.numel());\n\n  // read info from header.\n  jpeg_read_header(&cinfo, TRUE);\n\n  int channels = cinfo.num_components;\n\n  jpeg_start_decompress(&cinfo);\n\n  int stride = crop_width * channels;\n  auto tensor =\n     torch::empty({int64_t(crop_height), int64_t(crop_width), channels},\n                  torch::kU8);\n  auto ptr = tensor.data_ptr<uint8_t>();\n\n  unsigned int update_width = crop_width;\n  jpeg_crop_scanline(&cinfo, &crop_x, &update_width);\n  jpeg_skip_scanlines(&cinfo, crop_y);\n\n  const int offset = (cinfo.output_width - crop_width) * channels;\n  uint8_t* temp = nullptr;\n  if(offset > 0) temp = new uint8_t[cinfo.output_width * channels];\n\n  while (cinfo.output_scanline < crop_y + crop_height) {\n    /* jpeg_read_scanlines expects an array of pointers to scanlines.\n     * Here the array is only one element long, but you could ask for\n     * more than one scanline at a time if that's more convenient.\n     */\n    if(offset>0){\n      jpeg_read_scanlines(&cinfo, &temp, 1);\n      memcpy(ptr, temp + offset, stride);\n    }\n    else\n      jpeg_read_scanlines(&cinfo, &ptr, 1);\n    ptr += stride;\n  }\n  if(offset > 0){\n    delete[] temp;\n    temp = nullptr;\n  }\n  if (cinfo.output_scanline < cinfo.output_height) {\n    // Skip the rest of scanlines, required by jpeg_destroy_decompress.\n    jpeg_skip_scanlines(&cinfo,\n                        cinfo.output_height - crop_y - crop_height);\n  }\n  jpeg_finish_decompress(&cinfo);\n  jpeg_destroy_decompress(&cinfo);\n  return tensor.permute({2, 0, 1});\n}\n\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n  m.def(\"decode_and_crop_jpeg\",&decode_and_crop_jpeg,\"decode_and_crop_jpeg\");\n}\n```", "```py\nfrom setuptools import setup\nfrom torch.utils import cpp_extension\n\nsetup(name='decode_and_crop_jpeg',\n      ext_modules=[cpp_extension.CppExtension('decode_and_crop_jpeg', \n                                              ['decode_and_crop_jpeg.cpp'], \n                                              libraries=['jpeg'])],\n      cmdclass={'build_ext': cpp_extension.BuildExtension})\n```", "```py\nimport os\nimport sys\nimport subprocess\nimport shlex\nimport filelock\n\np_dir = os.path.dirname(__file__)\n\nwith filelock.FileLock(os.path.join(pkg_dir, f\".lock\")):\n  try:\n    from custom_op.decode_and_crop_jpeg import decode_and_crop_jpeg\n  except ImportError:\n    install_cmd = f\"{sys.executable} setup.py build_ext --inplace\"\n    subprocess.run(shlex.split(install_cmd), capture_output=True, cwd=p_dir)\n    from custom_op.decode_and_crop_jpeg import decode_and_crop_jpeg\n```", "```py\nfrom torchvision.datasets.vision import VisionDataset\ninput_img_size = [533, 800]\nclass FakeDataset(VisionDataset):\n    def __init__(self, transform):\n        super().__init__(root=None, transform=transform)\n        size = 10000\n        self.img_files = [f'{i}.jpg' for i in range(size)]\n        self.targets = np.random.randint(low=0,high=num_classes,\n                                        size=(size),dtype=np.uint8).tolist()\n\n    def __getitem__(self, index):\n        img_file, target = self.img_files[index], self.targets[index]\n        with torch.profiler.record_function('decode_and_crop_jpeg'):\n            import random\n            from custom_op.decode_and_crop_jpeg import decode_and_crop_jpeg\n            with open(img_file, 'rb') as f:\n                x = torch.frombuffer(f.read(), dtype=torch.uint8)\n            h_offset = random.randint(0, input_img_size[0] - img_size)\n            w_offset = random.randint(0, input_img_size[1] - img_size)\n            img = decode_and_crop_jpeg(x, h_offset, w_offset, \n                                       img_size, img_size)\n\n        if self.transform is not None:\n            img = self.transform(img)\n        return img, target\n\n    def __len__(self):\n        return len(self.img_files)\n\ntransform = T.Compose(\n    [RandomMask(),\n     ConvertColor(),\n     Scale()])\n```"]