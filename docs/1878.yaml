- en: 'From Chaos to Clarity: Streamlining Data Cleansing Using Large Language Models'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/from-chaos-to-clarity-streamlining-data-cleansing-using-large-language-models-a539fa0b2d90?source=collection_archive---------5-----------------------#2023-06-07](https://towardsdatascience.com/from-chaos-to-clarity-streamlining-data-cleansing-using-large-language-models-a539fa0b2d90?source=collection_archive---------5-----------------------#2023-06-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Cleaning up survey responses using OpenAIâ€™s GPT Model. Full Code with Github
    link.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@naresh-ram?source=post_page-----a539fa0b2d90--------------------------------)[![Naresh
    Ram](../Images/4a20b5646f75fb6cc2a5684fd3daf6db.png)](https://medium.com/@naresh-ram?source=post_page-----a539fa0b2d90--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a539fa0b2d90--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a539fa0b2d90--------------------------------)
    [Naresh Ram](https://medium.com/@naresh-ram?source=post_page-----a539fa0b2d90--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa5665b0dac5f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-chaos-to-clarity-streamlining-data-cleansing-using-large-language-models-a539fa0b2d90&user=Naresh+Ram&userId=a5665b0dac5f&source=post_page-a5665b0dac5f----a539fa0b2d90---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a539fa0b2d90--------------------------------)
    Â·17 min readÂ·Jun 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa539fa0b2d90&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-chaos-to-clarity-streamlining-data-cleansing-using-large-language-models-a539fa0b2d90&user=Naresh+Ram&userId=a5665b0dac5f&source=-----a539fa0b2d90---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa539fa0b2d90&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-chaos-to-clarity-streamlining-data-cleansing-using-large-language-models-a539fa0b2d90&source=-----a539fa0b2d90---------------------bookmark_footer-----------)![](../Images/629cba145be86d7a78351b5798f1bb46.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Image by Dall-E 2\. Generated and modified by the author.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: In the digital age, accurate and reliable data is paramount for businesses striving
    to deliver personalized experiences and make informed decisions[1]. However, the
    sheer volume and complexity of data often pose significant challenges requiring
    many hours of tedious and manual work. Enter the game-changing technology of large
    language models (LLMs). These advanced AI tools, with their natural language processing
    capabilities and pattern recognition, have the potential to revolutionize the
    process of cleansing data to make it more usable.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ•°å­—æ—¶ä»£ï¼Œå‡†ç¡®å¯é çš„æ•°æ®å¯¹è‡´åŠ›äºæä¾›ä¸ªæ€§åŒ–ä½“éªŒå’Œåšå‡ºæ˜æ™ºå†³ç­–çš„ä¼ä¸šè‡³å…³é‡è¦[1]ã€‚ç„¶è€Œï¼Œæ•°æ®çš„åºå¤§æ•°é‡å’Œå¤æ‚æ€§å¸¸å¸¸å¸¦æ¥é‡å¤§æŒ‘æˆ˜ï¼Œéœ€è¦å¤§é‡ç¹ççš„æ‰‹å·¥å·¥ä½œã€‚æ­¤æ—¶ï¼Œæ”¹å˜æ¸¸æˆè§„åˆ™çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æŠ€æœ¯ç™»åœºã€‚è¿™äº›å…ˆè¿›çš„AIå·¥å…·å‡­å€Ÿå…¶è‡ªç„¶è¯­è¨€å¤„ç†èƒ½åŠ›å’Œæ¨¡å¼è¯†åˆ«ï¼Œæœ‰å¯èƒ½å½»åº•æ”¹å˜æ•°æ®æ¸…æ´—è¿‡ç¨‹ï¼Œä½¿å…¶æ›´åŠ å¯ç”¨ã€‚
- en: Among the wrenches and the screwdrivers in the data scientistsâ€™ tool chest are
    the LLMs, reshaping activities and harnessing powers to enhance data quality.
    The proverbial whack of a hammer will unlock actionable insights and ultimately
    pave the way for better customer experiences.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ•°æ®ç§‘å­¦å®¶çš„å·¥å…·ç®±ä¸­ï¼ŒLLMså°±åƒæ˜¯æ‰³æ‰‹å’Œèºä¸åˆ€ï¼Œé‡æ–°å¡‘é€ æ´»åŠ¨ï¼Œåˆ©ç”¨å…¶å¼ºå¤§èƒ½åŠ›æé«˜æ•°æ®è´¨é‡ã€‚éšå–»ä¸­çš„é”¤å­å°†æ­ç¤ºå¯æ“ä½œçš„è§è§£ï¼Œå¹¶*æœ€ç»ˆ*ä¸ºæ›´å¥½çš„å®¢æˆ·ä½“éªŒé“ºå¹³é“è·¯ã€‚
- en: That said, letâ€™s drill right into the use case that I will be using as an example
    today.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: è¯è™½å¦‚æ­¤ï¼Œè®©æˆ‘ä»¬ç›´æ¥æ·±å…¥åˆ°ä»Šå¤©å°†ç”¨ä½œç¤ºä¾‹çš„ç”¨ä¾‹ä¸­ã€‚
- en: '![](../Images/97f979d0821efb5af6e1b55a5fd222fc.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97f979d0821efb5af6e1b55a5fd222fc.png)'
- en: Photo by [Scott Graham](https://unsplash.com/@homajob?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/OQMZwNd3ThU?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”± [Scott Graham](https://unsplash.com/@homajob?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    æä¾›ï¼Œæ¥æºäº [Unsplash](https://unsplash.com/photos/OQMZwNd3ThU?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: The Use Case
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç”¨ä¾‹
- en: The worst thing you could do when conducting a survey among students is to leave
    a factual field as free-form text! You can imagine some of the responses we got.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¯¹å­¦ç”Ÿè¿›è¡Œè°ƒæŸ¥æ—¶ï¼Œæœ€ç³Ÿç³•çš„äº‹æƒ…å°±æ˜¯æŠŠä¸€ä¸ªäº‹å®å­—æ®µç•™ä½œè‡ªç”±æ–‡æœ¬ï¼ä½ å¯ä»¥æƒ³è±¡æˆ‘ä»¬æ”¶åˆ°äº†å“ªäº›å›åº”ã€‚
- en: Jokes aside, one of our clients, [Study Fetch](https://www.studyfetch.com/),
    an AI-powered platform that uses course material to create personalized all-in-one
    study sets for students, conducted a survey among university students. After receiving
    a whopping 10K+ responses, their CEO and Co-Founder, Esan Durrani, stumbled upon
    a little hiccup. Turns out, the â€œmajorâ€ field in the survey was a free-form text
    box, meaning respondents could type in whatever they pleased. Now, as data scientists,
    we know thatâ€™s not the brightest move if you want to crunch some statistical numbers.
    So, the raw data from the survey ended up looking like thisâ€¦
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: å¼€ç©ç¬‘çš„è¯é¢˜ï¼Œæˆ‘ä»¬çš„ä¸€ä½å®¢æˆ·ï¼Œ[Study Fetch](https://www.studyfetch.com/)ï¼Œä¸€ä¸ªåˆ©ç”¨è¯¾ç¨‹ææ–™ä¸ºå­¦ç”Ÿåˆ›å»ºä¸ªæ€§åŒ–å…¨èƒ½å­¦ä¹ é›†çš„AIé©±åŠ¨å¹³å°ï¼Œè¿›è¡Œäº†ä¸€é¡¹é’ˆå¯¹å¤§å­¦ç”Ÿçš„è°ƒæŸ¥ã€‚åœ¨æ”¶åˆ°è¶…è¿‡10Kçš„å›åº”åï¼Œä»–ä»¬çš„CEOå…¼è”åˆåˆ›å§‹äººEsan
    Durranié‡åˆ°äº†ä¸€ç‚¹å°éº»çƒ¦ã€‚åŸæ¥ï¼Œè°ƒæŸ¥ä¸­çš„â€œä¸»è¦â€å­—æ®µæ˜¯ä¸€ä¸ªè‡ªç”±æ–‡æœ¬æ¡†ï¼Œæ„å‘³ç€å—è®¿è€…å¯ä»¥éšæ„è¾“å…¥å†…å®¹ã€‚ä½œä¸ºæ•°æ®ç§‘å­¦å®¶ï¼Œæˆ‘ä»¬çŸ¥é“å¦‚æœä½ æƒ³è¿›è¡Œç»Ÿè®¡åˆ†æï¼Œè¿™ä¸æ˜¯æœ€æ˜æ™ºçš„åšæ³•ã€‚å› æ­¤ï¼Œè°ƒæŸ¥çš„åŸå§‹æ•°æ®çœ‹èµ·æ¥å°±æ˜¯è¿™æ ·çš„â€¦â€¦
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Oh my! Get ready to grab your Excel and embark on a sorting adventure that might
    take you a mere hour or, who knows, maybe even three. Only then will this data
    heresy be thoroughly purged.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å“¦å¤©å“ªï¼å‡†å¤‡å¥½æ‹¿èµ·ä½ çš„Excelï¼Œå¼€å§‹ä¸€ä¸ªæ’åºå†’é™©ï¼Œè¿™å¯èƒ½ä»…éœ€ä¸€ä¸ªå°æ—¶ï¼Œæˆ–è€…ï¼Œè°çŸ¥é“ï¼Œä¹Ÿè®¸éœ€è¦ä¸‰å°æ—¶ã€‚åªæœ‰è¿™æ ·ï¼Œè¿™äº›æ•°æ®å¼‚ç«¯æ‰ä¼šè¢«å½»åº•æ¸…é™¤ã€‚
- en: Yet, fear not, as we have the hammer of the Large Language Model (LLM).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œä¸ç”¨æ‹…å¿ƒï¼Œå› ä¸ºæˆ‘ä»¬æœ‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é”¤å­ã€‚
- en: As a wise man once said, if a hammer is all you have, everything looks like
    a nail. And boy, doesnâ€™t the data cleansing job look like the most perfect nail?
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚ä¸€ä½æ™ºè€…æ›¾è¯´çš„ï¼Œå¦‚æœä½ åªæœ‰ä¸€æŠŠé”¤å­ï¼Œé‚£ä¹ˆä¸€åˆ‡çœ‹èµ·æ¥éƒ½åƒé’‰å­ã€‚è€Œä¸”ï¼Œæ•°æ®æ¸…æ´—å·¥ä½œä¼¼ä¹å°±æ˜¯æœ€å®Œç¾çš„é’‰å­äº†ã€‚
- en: We can simply ask our friendly neighborhood LLM to classify these into known
    majors. Specifically, OpenAIâ€™s Generative Pre-trained Transformers (GPT), an LLM
    that powers the popular Chatbot app ChatGPT, will work for this case. GPT models
    use upwards of 175 billion parameters and have been trained on 2.6 billion stored
    web pages scraped from Common Crawl, an open dataset. Additionally, through a
    technique known as reinforcement learning from human feedback (RLHF), trainers
    can nudge and prod the model into providing more accurate and useful responses.
    [2]
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ç®€å•åœ°è®©æˆ‘ä»¬å‹å¥½çš„ LLM å°†è¿™äº›åˆ†ç±»åˆ°å·²çŸ¥çš„ä¸“ä¸šä¸­ã€‚å…·ä½“æ¥è¯´ï¼ŒOpenAI çš„ç”Ÿæˆé¢„è®­ç»ƒå˜æ¢å™¨ï¼ˆGPTï¼‰ï¼Œä¸€ä¸ªæ”¯æŒæµè¡Œçš„èŠå¤©æœºå™¨äººåº”ç”¨ ChatGPT
    çš„ LLMï¼Œå°†é€‚ç”¨äºè¿™ç§æƒ…å†µã€‚GPT æ¨¡å‹ä½¿ç”¨è¶…è¿‡ 1750 äº¿ä¸ªå‚æ•°ï¼Œå¹¶ä¸”å·²ç»åœ¨ä» Common Crawl æå–çš„ 26 äº¿ä¸ªå­˜å‚¨ç½‘é¡µä¸Šè¿›è¡Œäº†è®­ç»ƒã€‚æ­¤å¤–ï¼Œé€šè¿‡ä¸€ç§ç§°ä¸ºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰çš„æŠ€æœ¯ï¼Œè®­ç»ƒå¸ˆå¯ä»¥å¼•å¯¼å’Œä¿ƒä½¿æ¨¡å‹æä¾›æ›´å‡†ç¡®å’Œæœ‰ç”¨çš„å“åº”ã€‚[2]
- en: I think for our purpose, 175 billion+ parameters, should do just fine. As long
    as we are able to come up with the right prompt.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºå¯¹äºæˆ‘ä»¬çš„ç›®çš„æ¥è¯´ï¼Œ1750 äº¿+ å‚æ•°åº”è¯¥è¶³å¤Ÿäº†ã€‚åªè¦æˆ‘ä»¬èƒ½å¤Ÿæå‡ºæ­£ç¡®çš„æç¤ºã€‚
- en: '![](../Images/3010dd28b52df0da8ba791e7211a3cca.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3010dd28b52df0da8ba791e7211a3cca.png)'
- en: Photo by [Kelly Sikkema](https://unsplash.com/@kellysikkema?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/BoAbPMRKLS0?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[Kelly Sikkema](https://unsplash.com/@kellysikkema?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    çš„ç…§ç‰‡ï¼Œæ¥æºäº [Unsplash](https://unsplash.com/photos/BoAbPMRKLS0?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)'
- en: Itâ€™s all in the Prompt
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸€åˆ‡éƒ½åœ¨æç¤ºä¸­
- en: 'Ryan and Esan, from the AI company whose bread-and-butter is writing great
    prompts, proposed the first version of our prompt. It was a great one and did
    work very well using language inference[3], but there were two things that could
    be improved:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥è‡ª AI å…¬å¸ Ryan å’Œ Esanï¼Œä»–ä»¬çš„ä¸“é•¿æ˜¯ç¼–å†™å‡ºè‰²çš„æç¤ºï¼Œæå‡ºäº†æˆ‘ä»¬æç¤ºçš„ç¬¬ä¸€ä¸ªç‰ˆæœ¬ã€‚è¿™ä¸ªç‰ˆæœ¬éå¸¸å¥½ï¼Œå¹¶ä¸”åœ¨ä½¿ç”¨è¯­è¨€æ¨æ–­[3]æ—¶æ•ˆæœå¾ˆå¥½ï¼Œä½†è¿˜æœ‰ä¸¤ä¸ªæ–¹é¢å¯ä»¥æ”¹è¿›ï¼š
- en: It was written to work for one record
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™ç¯‡æ–‡ç« æ˜¯ä¸ºäº†ä¸€ä¸ªè®°å½•è€Œå†™çš„
- en: It was written as a â€˜Completionâ€™ using the Da Vinci Model (My bank account recoiled
    in fear at the mere mention of IT)
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒæ˜¯ä½œä¸ºâ€˜å®Œæˆâ€™ä½¿ç”¨ Da Vinci æ¨¡å‹ç¼–å†™çš„ï¼ˆæåˆ° IT è®©æˆ‘é“¶è¡Œè´¦æˆ·éƒ½å“äº†ä¸€è·³ï¼‰
- en: It would cost us too much and that simply wasnâ€™t going to do. So, Ryan and I
    independently rewrote the prompt as a chat prompt using â€˜gpt-3.5-turboâ€™ to perform
    bulk action. OpenAIâ€™s [prompt best practices](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)
    and the course [ChatGPT Prompt Engineering for Developers](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)
    came in handy for me. We went through a few more iterations of ideate, implement,
    analyze, and reform and we had a good working version.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼šèŠ±è´¹æˆ‘ä»¬å¤ªå¤šï¼Œè€Œä¸”è¿™æ˜¾ç„¶æ˜¯ä¸è¡Œçš„ã€‚å› æ­¤ï¼ŒRyan å’Œæˆ‘åˆ†åˆ«å°†æç¤ºé‡å†™ä¸ºä¸€ä¸ªä½¿ç”¨â€˜gpt-3.5-turboâ€™è¿›è¡Œæ‰¹é‡æ“ä½œçš„èŠå¤©æç¤ºã€‚OpenAI çš„
    [æç¤ºæœ€ä½³å®è·µ](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)
    å’Œè¯¾ç¨‹ [ChatGPT Prompt Engineering for Developers](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)
    å¯¹æˆ‘éå¸¸æœ‰å¸®åŠ©ã€‚æˆ‘ä»¬ç»è¿‡äº†å‡ æ¬¡è¿­ä»£çš„æ„æ€ã€å®æ–½ã€åˆ†æå’Œæ”¹è¿›ï¼Œæœ€ç»ˆå¾—åˆ°äº†ä¸€ä¸ªå¥½çš„å·¥ä½œç‰ˆæœ¬ã€‚
- en: 'Without further ado, here is the prompt after revision 2:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å†åºŸè¯ï¼Œä»¥ä¸‹æ˜¯ä¿®è®¢ç‰ˆ 2 åçš„æç¤ºï¼š
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Response from the LLM for this Prompt was
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¿™ä¸ªæç¤ºï¼ŒLLM çš„å“åº”æ˜¯
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This will work, sort of. But I didnâ€™t quite like the redundant text with the
    long program names repeating. With LLMs, text is tokens and tokens cost money.
    You see, my programming skills were forged in the fiery depths of the Dot Com
    Bust. And let me tell you, I never pass up an opportunity for some cost-saving
    optimizations.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†æœ‰æ•ˆï¼Œè™½ç„¶æœ‰ç‚¹ã€‚ ä½†æˆ‘ä¸å¤ªå–œæ¬¢å†—é•¿çš„ç¨‹åºåç§°é‡å¤çš„å†—ä½™æ–‡æœ¬ã€‚å¯¹äº LLMï¼Œæ–‡æœ¬æ˜¯æ ‡è®°ï¼Œè€Œæ ‡è®°æ˜¯è¦èŠ±é’±çš„ã€‚ä½ çœ‹ï¼Œæˆ‘çš„ç¼–ç¨‹æŠ€èƒ½æ˜¯åœ¨äº’è”ç½‘æ³¡æ²«çš„ç†Šç†Šçƒˆç«ä¸­é”»é€ å‡ºæ¥çš„ã€‚è®©æˆ‘å‘Šè¯‰ä½ ï¼Œæˆ‘ä»ä¸æ”¾è¿‡ä»»ä½•èŠ‚çœæˆæœ¬çš„æœºä¼šã€‚
- en: So, I changed the prompt slightly in the â€˜Desired Formatâ€™ section. I asked the
    model to output just the ordinal number of the survey responses (E.g. 1 for Drama
    above) and the ordinal number of the program (E.g. 1 for Literature). Then Ryan
    suggested I should request a JSON output instead of CSV to make it simpler to
    parse. He also recommended I add an â€˜example outputâ€™ section, an excellent suggestion.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œæˆ‘åœ¨â€˜æœŸæœ›æ ¼å¼â€™éƒ¨åˆ†ç¨å¾®æ›´æ”¹äº†æç¤ºã€‚æˆ‘è¦æ±‚æ¨¡å‹ä»…è¾“å‡ºè°ƒæŸ¥å“åº”çš„åºå·ï¼ˆä¾‹å¦‚ä¸Šé¢çš„ 1 ä»£è¡¨æˆå‰§ï¼‰å’Œç¨‹åºçš„åºå·ï¼ˆä¾‹å¦‚ 1 ä»£è¡¨æ–‡å­¦ï¼‰ã€‚ç„¶å Ryan
    å»ºè®®æˆ‘è¯·æ±‚ JSON è¾“å‡ºè€Œä¸æ˜¯ CSVï¼Œä»¥ä¾¿æ›´å®¹æ˜“è§£æã€‚ä»–è¿˜å»ºè®®æˆ‘æ·»åŠ ä¸€ä¸ªâ€˜ç¤ºä¾‹è¾“å‡ºâ€™éƒ¨åˆ†ï¼Œè¿™ä¸ªå»ºè®®éå¸¸å¥½ã€‚
- en: 'The final prompt is as follows (simplified for clarity):'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ç»ˆçš„æç¤ºå¦‚ä¸‹ï¼ˆä¸ºäº†æ¸…æ™°ç®€åŒ–ï¼‰ï¼š
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The full prompt we used can be viewed on the GitHub link [here](https://github.com/aaxis-nram/data-cleanser-llm-node).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨çš„å®Œæ•´æç¤ºå¯ä»¥åœ¨GitHubé“¾æ¥[è¿™é‡Œ](https://github.com/aaxis-nram/data-cleanser-llm-node)æŸ¥çœ‹ã€‚
- en: '**The output from the model**:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹çš„è¾“å‡º**ï¼š'
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'So, as discussed earlier, the output from the model is a mapping between the
    ordinal numbers of survey responses and the categories we defined. Take the first
    line for example: 1,1\. That means 1 is the response number and 1 is the corresponding
    mapped program number. Survey response 1 is â€œDramaâ€ and the mapped program 1 is
    â€œArts and Humanitiesâ€. This seems right! Drama in its proper #1 place, all eyes
    on it.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚ä¹‹å‰è®¨è®ºçš„é‚£æ ·ï¼Œæ¨¡å‹çš„è¾“å‡ºæ˜¯è°ƒæŸ¥å“åº”çš„åºæ•°ä¸æˆ‘ä»¬å®šä¹‰çš„ç±»åˆ«ä¹‹é—´çš„æ˜ å°„ã€‚ä»¥ç¬¬ä¸€è¡Œä¸¾ä¾‹ï¼š1,1ã€‚é‚£æ„å‘³ç€1æ˜¯å“åº”å·ï¼Œ1æ˜¯å¯¹åº”çš„æ˜ å°„ç¨‹åºå·ã€‚è°ƒæŸ¥å“åº”1æ˜¯â€œæˆå‰§â€ï¼Œæ˜ å°„ç¨‹åº1æ˜¯â€œè‰ºæœ¯ä¸äººæ–‡å­¦ç§‘â€ã€‚è¿™ä¼¼ä¹æ˜¯å¯¹çš„ï¼æˆå‰§åœ¨å…¶æ­£ç¡®çš„#1ä½ç½®ï¼Œæ‰€æœ‰çš„ç›®å…‰éƒ½é›†ä¸­åœ¨å®ƒä¸Šé¢ã€‚
- en: While the output at first glance looks like the output of embeddings (used in
    clustering and dimensionality reduction), they are simply the same mapped information
    with just the ordinal positions. In addition to providing some cost benefits on
    token usage, the numbers are easier to parse.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡è¾“å‡ºä¹çœ‹èµ·æ¥åƒæ˜¯åµŒå…¥ï¼ˆç”¨äºèšç±»å’Œé™ç»´ï¼‰çš„ç»“æœï¼Œä½†å®ƒä»¬åªæ˜¯å¸¦æœ‰åºæ•°ä½ç½®çš„ç›¸åŒæ˜ å°„ä¿¡æ¯ã€‚é™¤äº†åœ¨ä»¤ç‰Œä½¿ç”¨ä¸Šæä¾›ä¸€äº›æˆæœ¬ä¼˜åŠ¿å¤–ï¼Œè¿™äº›æ•°å­—ä¹Ÿæ›´å®¹æ˜“è§£æã€‚
- en: We can now translate the original survey response in the file into meaningful
    majors, do aggregation, and gain valuable actionable insights.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å¯ä»¥å°†æ–‡ä»¶ä¸­çš„åŸå§‹è°ƒæŸ¥å“åº”ç¿»è¯‘ä¸ºæœ‰æ„ä¹‰çš„ä¸“ä¸šï¼Œè¿›è¡Œæ±‡æ€»ï¼Œå¹¶è·å¾—æœ‰ä»·å€¼çš„å¯æ“ä½œè§è§£ã€‚
- en: But wait, Iâ€™m not going to sit in front of my computer, type each block of survey
    responses into the browser and calculate the mappings. Besides being mind-numbing,
    the error rate would simply not do.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ç­‰ç­‰ï¼Œæˆ‘ä¸æ‰“ç®—ååœ¨ç”µè„‘å‰ï¼Œå°†æ¯ä¸€å—è°ƒæŸ¥å“åº”è¾“å…¥åˆ°æµè§ˆå™¨ä¸­å¹¶è®¡ç®—æ˜ å°„ã€‚é™¤äº†ä»¤äººåŒçƒ¦å¤–ï¼Œé”™è¯¯ç‡ä¹Ÿå®Œå…¨æ— æ³•æ¥å—ã€‚
- en: What we need is some good old automation. Enter the API â€¦
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦ä¸€äº›è€å¼çš„è‡ªåŠ¨åŒ–ã€‚è¿›å…¥APIâ€¦
- en: '![](../Images/3fa72dd277d6faa436ff71e5527e30fe.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3fa72dd277d6faa436ff71e5527e30fe.png)'
- en: Photo by [Laura Ockel](https://unsplash.com/@viazavier?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/UQ2Fw_9oApU?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºäº[åŠ³æ‹‰Â·å¥¥å…‹å°”](https://unsplash.com/@viazavier?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)æ‹æ‘„äº[Unsplash](https://unsplash.com/photos/UQ2Fw_9oApU?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: API to the Rescue
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: APIçš„æ•‘æ´
- en: As you may be aware, the Application Programming Interface (API) allows our
    program to interact with third-party services efficiently. While many people are
    accomplishing impressive feats with ChatGPT, the real potential of Language Models
    lies in utilizing the API to seamlessly integrate natural language capabilities
    into an application, making it imperceptible to the users. Much like the incredible
    science and technology that goes into making the phone or computer you are using
    to read this article on.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä½ æ‰€çŸ¥ï¼Œåº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£ï¼ˆAPIï¼‰å…è®¸æˆ‘ä»¬çš„ç¨‹åºé«˜æ•ˆåœ°ä¸ç¬¬ä¸‰æ–¹æœåŠ¡äº’åŠ¨ã€‚å°½ç®¡è®¸å¤šäººåœ¨ä½¿ç”¨ChatGPTæ—¶å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„æˆå°±ï¼Œä½†è¯­è¨€æ¨¡å‹çš„çœŸæ­£æ½œåŠ›åœ¨äºåˆ©ç”¨APIå°†è‡ªç„¶è¯­è¨€èƒ½åŠ›æ— ç¼é›†æˆåˆ°åº”ç”¨ç¨‹åºä¸­ï¼Œä½¿å…¶å¯¹ç”¨æˆ·ä¸å¯å¯Ÿè§‰ã€‚è¿™å°±åƒä½ ç”¨æ¥é˜…è¯»è¿™ç¯‡æ–‡ç« çš„æ‰‹æœºæˆ–ç”µè„‘ä¸­æ‰€è•´å«çš„ä¸å¯æ€è®®çš„ç§‘æŠ€ã€‚
- en: If you donâ€™t already have it, you can request access to the API here, [https://openai.com/blog/openai-api](https://openai.com/blog/openai-api)
    [4]. Once you sign up and get your API key, the specification can be found [here](https://platform.openai.com/docs/api-reference/chat).
    Some really helpful examples with code samples can be found [here](https://platform.openai.com/examples).
    The [playground](https://platform.openai.com/playground) is a nice feature to
    test the prompt with various settings before you put it in [5].
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è¿˜æ²¡æœ‰ï¼Œå¯ä»¥åœ¨è¿™é‡Œç”³è¯·APIè®¿é—®ï¼Œ[https://openai.com/blog/openai-api](https://openai.com/blog/openai-api)
    [4]ã€‚ä¸€æ—¦æ³¨å†Œå¹¶è·å¾—APIå¯†é’¥ï¼Œå¯ä»¥åœ¨[è¿™é‡Œ](https://platform.openai.com/docs/api-reference/chat)æ‰¾åˆ°è§„æ ¼è¯´æ˜ã€‚åŒ…å«ä»£ç ç¤ºä¾‹çš„ä¸€äº›éå¸¸æœ‰ç”¨çš„ç¤ºä¾‹å¯ä»¥åœ¨[è¿™é‡Œ](https://platform.openai.com/examples)æ‰¾åˆ°ã€‚[playground](https://platform.openai.com/playground)æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„åŠŸèƒ½ï¼Œå¯ä»¥åœ¨å°†å…¶æŠ•å…¥ä½¿ç”¨å‰æµ‹è¯•å„ç§è®¾ç½®ã€‚
- en: 'We will be using the chat completion API using REST. A sample payload of the
    call is as follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨RESTçš„èŠå¤©å®ŒæˆAPIã€‚è°ƒç”¨çš„ç¤ºä¾‹æœ‰æ•ˆè´Ÿè½½å¦‚ä¸‹ï¼š
- en: '[PRE5]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Letâ€™s take a quick look at the parameters and their effects
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¿«é€ŸæŸ¥çœ‹ä¸€ä¸‹å‚æ•°åŠå…¶æ•ˆæœ
- en: '**model**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹**'
- en: The only one open to the public at this point for chat completions is gpt-3.5-turbo.
    Esan had access to GPT 4 model, which I was very jealous about. While gpt-4 is
    more accurate and hallucinates less [2], it is roughly 20 times more expensive
    and for our needs, Mr. Turbo was quite adequate, thank you.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®å‰å”¯ä¸€å¯¹å…¬ä¼—å¼€æ”¾çš„èŠå¤©å®Œæˆæ¨¡å‹æ˜¯ gpt-3.5-turboã€‚Esan æœ‰è®¿é—® GPT 4 æ¨¡å‹çš„æƒé™ï¼Œè¿™è®©æˆ‘éå¸¸å«‰å¦’ã€‚è™½ç„¶ gpt-4 æ›´åŠ å‡†ç¡®ï¼Œå¹¶ä¸”å¹»è§‰æ›´å°‘[2]ï¼Œä½†å®ƒçš„è´¹ç”¨å¤§çº¦æ˜¯
    gpt-3.5-turbo çš„ 20 å€ã€‚å¯¹äºæˆ‘ä»¬çš„éœ€æ±‚æ¥è¯´ï¼ŒTurbo å…ˆç”Ÿå·²ç»ç›¸å½“åˆé€‚äº†ï¼Œè°¢è°¢ã€‚
- en: '**temperature**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ¸©åº¦**'
- en: Next to the prompt, the temperature is one of the most important settings we
    can pass to the model. It can be set to a value between 0 and 2, as per the API
    docs. It has a significant impact [6] as it controls how much randomness is in
    the output, sort of like the amount of caffeine in your system before you start
    writing. A guide to values you can use for each application is given here [7]
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æç¤ºæ—è¾¹ï¼Œæ¸©åº¦æ˜¯æˆ‘ä»¬å¯ä»¥ä¼ é€’ç»™æ¨¡å‹çš„æœ€é‡è¦è®¾ç½®ä¹‹ä¸€ã€‚æ ¹æ® API æ–‡æ¡£ï¼Œå®ƒå¯ä»¥è®¾ç½®ä¸º 0 åˆ° 2 ä¹‹é—´çš„å€¼ã€‚å®ƒæœ‰ç€æ˜¾è‘—çš„å½±å“[6]ï¼Œå› ä¸ºå®ƒæ§åˆ¶è¾“å‡ºçš„éšæœºæ€§ï¼Œç±»ä¼¼äºä½ åœ¨å¼€å§‹å†™ä½œå‰ä½“å†…çš„å’–å•¡å› å«é‡ã€‚å…³äºæ¯ä¸ªåº”ç”¨ç¨‹åºå¯ä½¿ç”¨çš„å€¼çš„æŒ‡å—åœ¨è¿™é‡Œç»™å‡º[7]ã€‚
- en: For our use case, we simply want no variations. We want the engine to give us
    mappings as is and the same ones every single time. So, we used a value of 0.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæˆ‘ä»¬çš„ä½¿ç”¨æ¡ˆä¾‹ï¼Œæˆ‘ä»¬ä»…ä»…å¸Œæœ›æ²¡æœ‰å˜åŒ–ã€‚æˆ‘ä»¬å¸Œæœ›å¼•æ“æ¯æ¬¡éƒ½ç»™å‡ºå®Œå…¨ä¸€æ ·çš„æ˜ å°„ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† 0 çš„å€¼ã€‚
- en: '**n**'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**n**'
- en: How many chat completions choices to generate? If we were doing this for creative
    writing and wanted more than 1 choice to select from, we can use 2 or even 3\.
    For our case n=1 (default) will work well.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: è¦ç”Ÿæˆå¤šå°‘ä¸ªèŠå¤©å®Œæˆé€‰é¡¹ï¼Ÿå¦‚æœæˆ‘ä»¬æ˜¯åœ¨è¿›è¡Œåˆ›æ„å†™ä½œï¼Œå¹¶ä¸”å¸Œæœ›é€‰æ‹©çš„é€‰é¡¹è¶…è¿‡ 1 ä¸ªï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ 2 ç”šè‡³ 3 ä¸ªã€‚å¯¹äºæˆ‘ä»¬çš„æƒ…å†µï¼Œn=1ï¼ˆé»˜è®¤ï¼‰æ•ˆæœå¾ˆå¥½ã€‚
- en: '**message**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ¶ˆæ¯**'
- en: The role can be system, user, or assistant. The system role provides instructions
    and sets the context. The user role represents the prompt from the end user. The
    assistant role is the responses based on the conversation history. These roles
    help structure conversations and enable effective interaction between users and
    the AI assistant.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: è§’è‰²å¯ä»¥æ˜¯ç³»ç»Ÿã€ç”¨æˆ·æˆ–åŠ©æ‰‹ã€‚ç³»ç»Ÿè§’è‰²æä¾›æŒ‡ä»¤å¹¶è®¾å®šä¸Šä¸‹æ–‡ã€‚ç”¨æˆ·è§’è‰²ä»£è¡¨æœ€ç»ˆç”¨æˆ·çš„æç¤ºã€‚åŠ©æ‰‹è§’è‰²åŸºäºå¯¹è¯å†å²è¿›è¡Œå›åº”ã€‚è¿™äº›è§’è‰²æœ‰åŠ©äºæ„å»ºå¯¹è¯ï¼Œå¹¶å®ç°ç”¨æˆ·ä¸
    AI åŠ©æ‰‹ä¹‹é—´çš„æœ‰æ•ˆäº’åŠ¨ã€‚
- en: '**MODEL MAX TOKENS**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹æœ€å¤§ä»¤ç‰Œ**'
- en: This isnâ€™t necessarily a parameter we pass in the request, though another parameter
    called max_tokens limits the total length of the response from the chat.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ä¸€å®šæ˜¯æˆ‘ä»¬åœ¨è¯·æ±‚ä¸­ä¼ é€’çš„å‚æ•°ï¼Œä¸è¿‡å¦ä¸€ä¸ªåä¸º max_tokens çš„å‚æ•°é™åˆ¶äº†èŠå¤©å“åº”çš„æ€»é•¿åº¦ã€‚
- en: Firstly, a token can be thought of as a piece of a word. One token is approximately
    4 characters in English. For example, the quote â€œThe best way to predict the future
    is to create itâ€ attributed to Abraham Lincoln and others, contains 11 tokens.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œä»¤ç‰Œå¯ä»¥è¢«è®¤ä¸ºæ˜¯ä¸€ä¸ªå•è¯çš„ä¸€éƒ¨åˆ†ã€‚ä¸€ä¸ªä»¤ç‰Œå¤§çº¦æ˜¯ 4 ä¸ªè‹±æ–‡å­—ç¬¦ã€‚ä¾‹å¦‚ï¼Œå¼•ç”¨â€œé¢„è§æœªæ¥çš„æœ€ä½³æ–¹å¼æ˜¯åˆ›é€ æœªæ¥â€ï¼Œè¿™ä¸ªå¼•è¨€è¢«å½’å› äºäºšä¼¯æ‹‰ç½•Â·æ—è‚¯ç­‰äººï¼ŒåŒ…å«äº†
    11 ä¸ªä»¤ç‰Œã€‚
- en: '![](../Images/69813147518fbb984cbb356dc463a64a.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/69813147518fbb984cbb356dc463a64a.png)'
- en: Image from Open AI Tokenizer. Generated by the Author.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºäº Open AI Tokenizerã€‚ç”±ä½œè€…ç”Ÿæˆã€‚
- en: If you are thinking that a token is exactly a word, here is another example
    of 64 tokens, to show it isnâ€™t all that straightforward.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è®¤ä¸ºä¸€ä¸ªä»¤ç‰Œå°±æ˜¯ä¸€ä¸ªå•è¯ï¼Œè¿™é‡Œæœ‰å¦å¤–ä¸€ä¸ª 64 ä¸ªä»¤ç‰Œçš„ä¾‹å­ï¼Œæ¥è¯´æ˜è¿™å¹¶ä¸æ˜¯é‚£ä¹ˆç®€å•ã€‚
- en: '![](../Images/45ebcfd49afaab54bb19814bf769cbc0.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/45ebcfd49afaab54bb19814bf769cbc0.png)'
- en: Image from Open AI Tokenizer. Generated by the Author.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºäº Open AI Tokenizerã€‚ç”±ä½œè€…ç”Ÿæˆã€‚
- en: 'Brace yourself for a shocking revelation: every emoji you include in your message
    adds a hefty toll of up to 6\. Thatâ€™s right, your beloved smileys and winks are
    sneaky little token thieves! ğŸ˜‰ğŸ’¸'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: å‡†å¤‡å¥½æ¥å—éœ‡æ’¼çš„æ­ç¤ºï¼šä½ åœ¨æ¶ˆæ¯ä¸­åŒ…å«çš„æ¯ä¸€ä¸ªè¡¨æƒ…ç¬¦å·éƒ½å¢åŠ äº†æœ€å¤š 6 çš„è´¹ç”¨ã€‚æ²¡é”™ï¼Œä½ å–œçˆ±çš„ç¬‘è„¸å’Œçœ¨çœ¼ç¬¦å·éƒ½æ˜¯ç‹¡çŒ¾çš„å°ä»¤ç‰Œçªƒè´¼ï¼ğŸ˜‰ğŸ’¸
- en: The model max token window is a technical limit. Your prompt (including any
    additional data you place into it) and the answer must all fit within the model
    max limit listed [here](https://platform.openai.com/docs/models/model-endpoint-compatibility).
    In the case of chat completions, the content, role, and all of the previous messages
    all consume tokens. If you remove a message from the input or the output (assistant
    messages), the model will lose all knowledge of it [8]. Like Dory as she helps
    find Chico, no Fabio, no Bingo, no Harpo, no Elmo?â€¦ Nemo!
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹çš„æœ€å¤§ä»¤ç‰Œçª—å£æ˜¯ä¸€ä¸ªæŠ€æœ¯é™åˆ¶ã€‚ä½ çš„æç¤ºï¼ˆåŒ…æ‹¬ä½ æ”¾å…¥çš„ä»»ä½•é¢å¤–æ•°æ®ï¼‰å’Œç­”æ¡ˆå¿…é¡»éƒ½åœ¨æ¨¡å‹æœ€å¤§é™åˆ¶å†…ï¼Œè¯¦ç»†ä¿¡æ¯è¯·æŸ¥çœ‹[è¿™é‡Œ](https://platform.openai.com/docs/models/model-endpoint-compatibility)ã€‚åœ¨èŠå¤©å®Œæˆçš„æƒ…å†µä¸‹ï¼Œå†…å®¹ã€è§’è‰²å’Œæ‰€æœ‰ä¹‹å‰çš„æ¶ˆæ¯éƒ½æ¶ˆè€—ä»¤ç‰Œã€‚å¦‚æœä½ ä»è¾“å…¥æˆ–è¾“å‡ºï¼ˆåŠ©æ‰‹æ¶ˆæ¯ï¼‰ä¸­åˆ é™¤ä¸€æ¡æ¶ˆæ¯ï¼Œæ¨¡å‹å°†å¤±å»å¯¹å…¶çš„æ‰€æœ‰è®°å¿†[8]ã€‚å°±åƒå¤šè‰åœ¨å¯»æ‰¾å¥‡ç§‘æ—¶ä¸€æ ·ï¼Œæ²¡æœ‰æ³•æ¯”å¥¥ï¼Œæ²¡æœ‰å®¾æˆˆï¼Œæ²¡æœ‰å“ˆæ³¢ï¼Œæ²¡æœ‰è‰¾å°”è«ï¼Ÿâ€¦
    å°¼è«ï¼
- en: 'For gpt-3.5-turbo, the model maximum limit is 4096 tokens or roughly 16K characters.
    For our use case, the prompt is roughly 2000 characters, each survey response
    is roughly 20 chars (average) and the mapping response is 7 characters. So, if
    we put N survey responses in each prompt, the max characters will be:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºgpt-3.5-turboï¼Œæ¨¡å‹çš„æœ€å¤§é™åˆ¶æ˜¯4096ä¸ªtokenï¼Œæˆ–è€…å¤§çº¦16Kå­—ç¬¦ã€‚å¯¹äºæˆ‘ä»¬çš„ç”¨ä¾‹ï¼Œæç¤ºå¤§çº¦æ˜¯2000ä¸ªå­—ç¬¦ï¼Œæ¯ä¸ªè°ƒæŸ¥å›å¤å¤§çº¦æ˜¯20ä¸ªå­—ç¬¦ï¼ˆå¹³å‡ï¼‰ï¼Œæ˜ å°„å›å¤æ˜¯7ä¸ªå­—ç¬¦ã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬åœ¨æ¯ä¸ªæç¤ºä¸­æ”¾å…¥Nä¸ªè°ƒæŸ¥å›å¤ï¼Œæœ€å¤§å­—ç¬¦æ•°å°†æ˜¯ï¼š
- en: 2000 + 20*N + 7*N should be less than 16,000.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 2000 + 20*N + 7*N åº”å°äº16,000ã€‚
- en: Solving we get an N value less than 518 or roughly 500\. Technically, we could
    put 500 survey responses in each request and go through our data 20 times. Instead,
    we chose to put 50 in each response and do it 200 times as we were receiving abnormal
    responses intermittently if we put more than 50 survey responses in a single request.
    Once in a while, the service threw a temper tantrum! Weâ€™re not sure if itâ€™s a
    chronic case of systemic petulance or if we just happened to stumble upon the
    grumpy side of luck.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: è§£ç®—åï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªå°äº518æˆ–å¤§çº¦500çš„Nå€¼ã€‚ä»æŠ€æœ¯ä¸Šè®²ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æ¯ä¸ªè¯·æ±‚ä¸­æ”¾å…¥500ä¸ªè°ƒæŸ¥å›å¤ï¼Œå¹¶å¤„ç†æ•°æ®20æ¬¡ã€‚ç›¸åï¼Œæˆ‘ä»¬é€‰æ‹©æ¯ä¸ªè¯·æ±‚ä¸­æ”¾å…¥50ä¸ªè°ƒæŸ¥å›å¤ï¼Œå¤„ç†200æ¬¡ï¼Œå› ä¸ºå¦‚æœæˆ‘ä»¬åœ¨å•ä¸ªè¯·æ±‚ä¸­æ”¾å…¥è¶…è¿‡50ä¸ªè°ƒæŸ¥å›å¤ï¼Œå¶å°”ä¼šæ”¶åˆ°å¼‚å¸¸å›å¤ã€‚æœ‰æ—¶ï¼ŒæœåŠ¡ä¼šå‘è„¾æ°”ï¼æˆ‘ä»¬ä¸ç¡®å®šè¿™æ˜¯ç³»ç»Ÿæ€§ä¹–æˆ¾çš„æ…¢æ€§ç—…ï¼Œè¿˜æ˜¯åˆšå¥½ç¢°ä¸Šäº†è¿æ°”ä¸å¥½çš„ä¸€é¢ã€‚
- en: So, how do we use this API we have? Letâ€™s get to the good part, the code.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œæˆ‘ä»¬å¦‚ä½•ä½¿ç”¨è¿™ä¸ªAPIå‘¢ï¼Ÿè®©æˆ‘ä»¬è¿›å…¥é‡ç‚¹ï¼Œä»£ç éƒ¨åˆ†ã€‚
- en: '![](../Images/b6ca9b8296d4852b235147598e4088ad.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b6ca9b8296d4852b235147598e4088ad.png)'
- en: Photo by [Markus Spiske](https://unsplash.com/ko/@markusspiske?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/iar-afB0QQw?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[Markus Spiske](https://unsplash.com/ko/@markusspiske?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)æ‹æ‘„äº[Unsplash](https://unsplash.com/photos/iar-afB0QQw?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)'
- en: The Way of the Code
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»£ç çš„æ–¹å¼
- en: 'Node.js is a JavaScript runtime environment [9]. We will write a Node.js/Javascript
    program that will perform the actions as described in this flow chart:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Node.jsæ˜¯ä¸€ä¸ªJavaScriptè¿è¡Œç¯å¢ƒ[9]ã€‚æˆ‘ä»¬å°†ç¼–å†™ä¸€ä¸ªNode.js/JavaScriptç¨‹åºï¼Œè¯¥ç¨‹åºå°†æ‰§è¡Œåœ¨è¿™ä¸ªæµç¨‹å›¾ä¸­æè¿°çš„æ“ä½œï¼š
- en: '![](../Images/822cff75f20673c7821f6388fd4629d3.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/822cff75f20673c7821f6388fd4629d3.png)'
- en: Flowchart of the program. Image by the Author.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨‹åºçš„æµç¨‹å›¾ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: My Javascript skills arenâ€™t that great. I can write better Java, PHP, Julia,
    Go, C#, or even Python. But Esan was insisting on Node, so Javascript it is.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çš„JavaScriptæŠ€èƒ½ä¸æ˜¯ç‰¹åˆ«å‡ºè‰²ã€‚æˆ‘å¯ä»¥å†™æ›´å¥½çš„Javaã€PHPã€Juliaã€Goã€C#ï¼Œç”šè‡³Pythonã€‚ä½†EsanåšæŒä½¿ç”¨Nodeï¼Œæ‰€ä»¥å°±ç”¨JavaScriptå§ã€‚
- en: 'The entire code, the prompt, and the sample input are available at this [GitHub
    link](https://github.com/aaxis-nram/data-cleanser-llm-node).However, letâ€™s take
    a gander at the juiciest bits:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰ä»£ç ã€æç¤ºå’Œç¤ºä¾‹è¾“å…¥å¯ä»¥åœ¨è¿™ä¸ª[GitHubé“¾æ¥](https://github.com/aaxis-nram/data-cleanser-llm-node)ä¸­æ‰¾åˆ°ã€‚ä¸è¿‡ï¼Œè®©æˆ‘ä»¬æ¥çœ‹çœ‹æœ€é‡è¦çš„éƒ¨åˆ†ï¼š
- en: First, letâ€™s see how we read the CSV file in using the â€œcsv-parserâ€™ Node Library.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä½¿ç”¨â€œcsv-parserâ€Nodeåº“è¯»å–CSVæ–‡ä»¶ã€‚
- en: '[PRE6]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Next, we call the classifier to generate the mappings.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è°ƒç”¨åˆ†ç±»å™¨ç”Ÿæˆæ˜ å°„ã€‚
- en: '[PRE7]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The prompt is then constructed from the categories, main prompt text, and the
    data from the CSV. We then send the prompt to the service using their OpenAI Node
    Library.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæç¤ºç”±ç±»åˆ«ã€ä¸»è¦æç¤ºæ–‡æœ¬å’ŒCSVä¸­çš„æ•°æ®æ„æˆã€‚æˆ‘ä»¬å°†æç¤ºé€šè¿‡ä»–ä»¬çš„OpenAI Nodeåº“å‘é€åˆ°æœåŠ¡ã€‚
- en: '[PRE8]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Finally, when all the iterations are done, we can translate the srcCol text
    (the survey response) to the targetCol (the normalized program name), and write
    out the CSV.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œå½“æ‰€æœ‰è¿­ä»£å®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥å°†srcColæ–‡æœ¬ï¼ˆè°ƒæŸ¥å›å¤ï¼‰ç¿»è¯‘ä¸ºtargetColï¼ˆæ ‡å‡†åŒ–çš„ç¨‹åºåç§°ï¼‰ï¼Œå¹¶å†™å‡ºCSVæ–‡ä»¶ã€‚
- en: '[PRE9]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: That bit of JavaScript wasnâ€™t as hairy as I expected and it got done in 2 to
    3 hours. I guess it always looks daunting until you get into it.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£æ®µJavaScriptä»£ç æ²¡æœ‰æˆ‘æƒ³è±¡ä¸­çš„é‚£ä¹ˆå¤æ‚ï¼Œ2åˆ°3å°æ—¶å†…å®Œæˆäº†ã€‚æˆ‘æƒ³ï¼Œç›´åˆ°å¼€å§‹åšä¹‹å‰æ€»æ˜¯çœ‹èµ·æ¥å¾ˆä»¤äººç”Ÿç•ã€‚
- en: So, now that we have the code ready, itâ€™s time for the final executionâ€¦
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œä»£ç å·²ç»å‡†å¤‡å¥½ï¼Œæ˜¯æ—¶å€™è¿›è¡Œæœ€ç»ˆæ‰§è¡Œäº†â€¦â€¦
- en: '![](../Images/c1dccfd7b15920a59038fb6d2723ee56.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c1dccfd7b15920a59038fb6d2723ee56.png)'
- en: Photo by [Alexander Grey](https://unsplash.com/@sharonmccutcheon?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/8lnbXtxFGZw?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[Alexander Grey](https://unsplash.com/@sharonmccutcheon?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)æ‹æ‘„äº[Unsplash](https://unsplash.com/photos/8lnbXtxFGZw?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)'
- en: The Execution
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ‰§è¡Œ
- en: Now, we needed a place to run the code. After debating if we should get a cloud
    instance to run the load, I did some quick math and realized that I could run
    it on my laptop in less than an hour. That wasnâ€™t so bad.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªåœ°æ–¹æ¥è¿è¡Œä»£ç ã€‚åœ¨äº‰è®ºæ˜¯å¦åº”è¯¥è·å¾—ä¸€ä¸ªäº‘å®ä¾‹æ¥è¿è¡Œè´Ÿè½½åï¼Œæˆ‘åšäº†ä¸€äº›å¿«é€Ÿè®¡ç®—ï¼Œå‘ç°æˆ‘å¯ä»¥åœ¨ä¸åˆ°ä¸€å°æ—¶å†…åœ¨æˆ‘çš„ç¬”è®°æœ¬ç”µè„‘ä¸Šè¿è¡Œå®ƒã€‚è¿™ä¹Ÿä¸ç®—å¤ªç³Ÿç³•ã€‚
- en: We started with a test round and noticed that the service, 1 out of 10 times,
    would respond back with the data that was provided to it instead of the mappings.
    So, we would just get the list of the survey responses back. Since no mappings
    were found, those responses in the CSV file would be mapped to an empty string.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¼€å§‹äº†æµ‹è¯•è½®æ¬¡ï¼Œå¹¶æ³¨æ„åˆ°æœåŠ¡æœ‰1/10çš„å‡ ç‡ä¼šè¿”å›æä¾›ç»™å®ƒçš„æ•°æ®ï¼Œè€Œä¸æ˜¯æ˜ å°„ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åªä¼šæ”¶åˆ°è°ƒæŸ¥å›åº”çš„åˆ—è¡¨ã€‚ç”±äºæ²¡æœ‰æ‰¾åˆ°æ˜ å°„ï¼Œè¿™äº›CSVæ–‡ä»¶ä¸­çš„å›åº”ä¼šè¢«æ˜ å°„ä¸ºç©ºå­—ç¬¦ä¸²ã€‚
- en: Instead of detecting this and retrying in code, I decided to rerun the script
    but have it only process records for which the target column was empty.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å…¶åœ¨ä»£ç ä¸­æ£€æµ‹å¹¶é‡è¯•ï¼Œæˆ‘å†³å®šé‡æ–°è¿è¡Œè„šæœ¬ï¼Œä½†åªå¤„ç†ç›®æ ‡åˆ—ä¸ºç©ºçš„è®°å½•ã€‚
- en: The script would start with the target column in all rows empty and fill in
    the normalized program name. Due to the error in the response, some of the rows
    would have the target column not be mapped and remain empty. When the script ran
    the second time, it would construct the prompt for only those responses which
    were not processed in the first run. We reran the program a couple of times and
    got everything mapped out.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: è„šæœ¬å°†ä»æ‰€æœ‰è¡Œä¸­ç›®æ ‡åˆ—ä¸ºç©ºå¼€å§‹ï¼Œå¹¶å¡«å†™æ ‡å‡†åŒ–çš„ç¨‹åºåç§°ã€‚ç”±äºå“åº”ä¸­çš„é”™è¯¯ï¼Œä¸€äº›è¡Œçš„ç›®æ ‡åˆ—æ²¡æœ‰è¢«æ˜ å°„å¹¶ä¿æŒä¸ºç©ºã€‚å½“è„šæœ¬ç¬¬äºŒæ¬¡è¿è¡Œæ—¶ï¼Œå®ƒåªä¼šä¸ºç¬¬ä¸€æ¬¡è¿è¡Œä¸­æœªå¤„ç†çš„å›åº”æ„é€ æç¤ºã€‚æˆ‘ä»¬é‡è·‘äº†å‡ æ¬¡ç¨‹åºï¼Œæœ€ç»ˆå°†æ‰€æœ‰å†…å®¹æ˜ å°„å®Œæˆã€‚
- en: 'The multiple runs took roughly about 30 minutes and did not need much supervision.
    Here is a selection of some of the more interesting mappings from the model:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šæ¬¡è¿è¡Œå¤§çº¦èŠ±äº†30åˆ†é’Ÿï¼Œå¹¶ä¸”ä¸éœ€è¦å¤ªå¤šç›‘ç£ã€‚è¿™é‡Œæ˜¯æ¨¡å‹çš„ä¸€äº›æ›´æœ‰è¶£çš„æ˜ å°„çš„é€‰æ‹©ï¼š
- en: '![](../Images/99e85c0374f04c76b2cc3ad622f97dfc.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/99e85c0374f04c76b2cc3ad622f97dfc.png)'
- en: Sample Mappings between input and program name. Image by the Author.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å…¥å’Œç¨‹åºåç§°ä¹‹é—´çš„ç¤ºä¾‹æ˜ å°„ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: Most look right. Not sure if Organizational Behavior is Social Science or Business?
    I guess either would work.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å¤šæ•°çœ‹èµ·æ¥å¯¹ã€‚ç»„ç»‡è¡Œä¸ºå­¦æ˜¯ç¤¾ä¼šç§‘å­¦è¿˜æ˜¯å•†ä¸šå­¦ç§‘å‘¢ï¼Ÿæˆ‘æƒ³ä¸¤è€…éƒ½å¯ä»¥ã€‚
- en: Each request of about 50 records took a total of roughly 800 tokens. The cost
    of the entire exercise was 40 cents. We probably spent 10 cents, doing testing,
    reruns, etc. So for a total cost of about 50 cents, about 2 Â½ hrs of coding/testing
    time, and Â½ hr of runtime, we got the job done.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªçº¦50æ¡è®°å½•çš„è¯·æ±‚æ€»å…±ä½¿ç”¨äº†å¤§çº¦800ä¸ªtokensã€‚æ•´ä¸ªè¿‡ç¨‹çš„è´¹ç”¨æ˜¯40ç¾åˆ†ã€‚æˆ‘ä»¬å¯èƒ½èŠ±äº†10ç¾åˆ†è¿›è¡Œæµ‹è¯•ã€é‡è·‘ç­‰ã€‚æ‰€ä»¥ï¼Œæ€»è´¹ç”¨çº¦50ç¾åˆ†ï¼Œå¤§çº¦2
    Â½å°æ—¶çš„ç¼–ç /æµ‹è¯•æ—¶é—´å’ŒÂ½å°æ—¶çš„è¿è¡Œæ—¶é—´ï¼Œæˆ‘ä»¬å®Œæˆäº†å·¥ä½œã€‚
- en: '**Total Cost:** Approx. Less than $1'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ€»è´¹ç”¨ï¼š** çº¦1ç¾å…ƒä»¥å†…'
- en: '**Total Time:** Approx. 3 hours'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ€»æ—¶é—´ï¼š** å¤§çº¦3å°æ—¶'
- en: Perhaps manual conversion using Excel, sorting, regex, and drag-and-copy, we
    could have accomplished it in the same amount of time and saved a little change.
    But, this was way more fun, we learned something, we have a repeatable script/process,
    and got an article out of it. Besides, I have a feeling [StudyFetch](https://www.studyfetch.com/)
    can afford the 50 cents.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿè®¸ä½¿ç”¨Excelã€æ’åºã€æ­£åˆ™è¡¨è¾¾å¼ä»¥åŠæ‹–æ‹½å¤åˆ¶çš„æ‰‹åŠ¨è½¬æ¢ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨åŒæ ·çš„æ—¶é—´å†…å®Œæˆå¹¶èŠ‚çœä¸€ç‚¹è´¹ç”¨ã€‚ä½†æ˜¯ï¼Œè¿™è¦æœ‰è¶£å¾—å¤šï¼Œæˆ‘ä»¬å­¦åˆ°äº†ä¸œè¥¿ï¼Œæˆ‘ä»¬æœ‰äº†ä¸€ä¸ªå¯é‡å¤çš„è„šæœ¬/è¿‡ç¨‹ï¼Œå¹¶ä¸”è¿˜å†™äº†ä¸€ç¯‡æ–‡ç« ã€‚è€Œä¸”ï¼Œæˆ‘è§‰å¾—[StudyFetch](https://www.studyfetch.com/)å¯ä»¥æ‰¿æ‹…è¿™50ç¾åˆ†ã€‚
- en: This was a good use that we achieved efficiently and cost-effectively, but what
    else can LLMs be used for?
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬é«˜æ•ˆä¸”ç»æµåœ°å®ç°çš„ä¸€ä¸ªå¥½ç”¨ä¾‹ï¼Œä½†LLMsè¿˜èƒ½ç”¨äºä»€ä¹ˆå…¶ä»–ç”¨é€”å‘¢ï¼Ÿ
- en: '![](../Images/16d14ddbac51d8d5b5a9d9c84159a6af.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/16d14ddbac51d8d5b5a9d9c84159a6af.png)'
- en: Photo by [Marcel StrauÃŸ](https://unsplash.com/@martzzl?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/NMGFl05r728?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ç…§ç‰‡ç”±[Marcel StrauÃŸ](https://unsplash.com/@martzzl?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)æä¾›ï¼Œæ¥è‡ª[Unsplash](https://unsplash.com/photos/NMGFl05r728?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: Looking for More Nails
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¯»æ‰¾æ›´å¤šçš„é’‰å­
- en: 'Adding language capability to your applications can have further use cases
    than the one I illustrated above. Here are more use cases just pertaining to the
    review data we were looking at:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºä½ çš„åº”ç”¨ç¨‹åºæ·»åŠ è¯­è¨€èƒ½åŠ›å¯èƒ½ä¼šæœ‰æ¯”æˆ‘ä¸Šé¢æ‰€å±•ç¤ºçš„æ›´å¤šçš„ç”¨é€”ã€‚è¿™é‡Œæ˜¯ä¸€äº›ä»…ä¸æˆ‘ä»¬æŸ¥çœ‹çš„å®¡æ ¸æ•°æ®ç›¸å…³çš„æ›´å¤šç”¨ä¾‹ï¼š
- en: '**Data Parsing and Standardization**: LLMs can help in parsing and standardizing
    data by identifying and extracting relevant information from unstructured or semi-structured
    data sources like the one we just looked at.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ•°æ®è§£æå’Œæ ‡å‡†åŒ–**ï¼šLLMs å¯ä»¥é€šè¿‡è¯†åˆ«å’Œæå–æ¥è‡ªéç»“æ„åŒ–æˆ–åŠç»“æ„åŒ–æ•°æ®æºçš„ç›¸å…³ä¿¡æ¯ï¼Œæ¥å¸®åŠ©è§£æå’Œæ ‡å‡†åŒ–æ•°æ®ï¼Œä¾‹å¦‚æˆ‘ä»¬åˆšåˆšæŸ¥çœ‹çš„æ•°æ®ã€‚'
- en: '**Data Deduplication**: LLMs can help identify duplicate records by comparing
    various data points. For example, we can compare names, majors, and universities
    in the review data and flag potential duplicates.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ•°æ®å»é‡**ï¼šLLMs å¯ä»¥é€šè¿‡æ¯”è¾ƒå„ç§æ•°æ®ç‚¹æ¥å¸®åŠ©è¯†åˆ«é‡å¤è®°å½•ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥æ¯”è¾ƒè¯„è®ºæ•°æ®ä¸­çš„å§“åã€ä¸“ä¸šå’Œå¤§å­¦ï¼Œå¹¶æ ‡è®°æ½œåœ¨çš„é‡å¤é¡¹ã€‚'
- en: '**Data Summarization**: LLMs can summarize distinct records to get an idea
    of the response. For E.g. for the question â€œWhat is the biggest challenge you
    face while studying?â€, a large language model can summarize several responses
    from the same major and university to see if there are any patterns. We can then
    put all the summarizations into a single request and get an overall list. But
    I suspect summarization from each customer segment will be more useful.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ•°æ®æ€»ç»“**ï¼šLLMs å¯ä»¥æ€»ç»“ä¸åŒçš„è®°å½•ï¼Œä»¥äº†è§£å“åº”æƒ…å†µã€‚ä¾‹å¦‚ï¼Œå¯¹äºâ€œä½ åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­é¢ä¸´çš„æœ€å¤§æŒ‘æˆ˜æ˜¯ä»€ä¹ˆï¼Ÿâ€è¿™ä¸ªé—®é¢˜ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹å¯ä»¥æ€»ç»“æ¥è‡ªç›¸åŒä¸“ä¸šå’Œå¤§å­¦çš„å¤šä¸ªå›ç­”ï¼Œä»¥æŸ¥çœ‹æ˜¯å¦å­˜åœ¨ä»»ä½•æ¨¡å¼ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥å°†æ‰€æœ‰æ€»ç»“æ”¾å…¥ä¸€ä¸ªè¯·æ±‚ä¸­ï¼Œè·å–æ€»ä½“åˆ—è¡¨ã€‚ä½†æˆ‘æ€€ç–‘å¯¹æ¯ä¸ªå®¢æˆ·ç»†åˆ†å¸‚åœºçš„æ€»ç»“ä¼šæ›´æœ‰ç”¨ã€‚'
- en: '**Sentiment Analysis**: LLMs can analyze the reviews to determine sentiment
    and extract valuable insights. For the question â€œWould you pay for a service to
    help you study?â€, LLMs can categorize the sentiment as 0 (very negative) to 5
    (very positive). We can then use this to analyze student interest in a paid service
    by segment.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**æƒ…æ„Ÿåˆ†æ**ï¼šLLMs å¯ä»¥åˆ†æè¯„è®ºä»¥ç¡®å®šæƒ…æ„Ÿå¹¶æå–æœ‰ä»·å€¼çš„è§è§£ã€‚å¯¹äºâ€œä½ ä¼šä¸ºå¸®åŠ©ä½ å­¦ä¹ çš„æœåŠ¡ä»˜è´¹å—ï¼Ÿâ€è¿™ä¸ªé—®é¢˜ï¼ŒLLMs å¯ä»¥å°†æƒ…æ„Ÿåˆ†ç±»ä¸º 0ï¼ˆéå¸¸è´Ÿé¢ï¼‰åˆ°
    5ï¼ˆéå¸¸ç§¯æï¼‰ã€‚æˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™ä¸€ç‚¹æŒ‰ç»†åˆ†å¸‚åœºåˆ†æå­¦ç”Ÿå¯¹ä»˜è´¹æœåŠ¡çš„å…´è¶£ã€‚'
- en: While student reviews are a great example of a smaller microcosm, the wider
    world has several uses for this technology as well. At [AAXIS](https://www.aaxisdigital.com),
    where I work, we implement business-to-business as well as business-to-consumer
    digital commerce solutions. Doing so includes migrating large amounts of data
    from an existing older system to a newer system with different data structures.
    We use a variety of data tools to analyze source data to ensure consistency. The
    techniques outlined in this article could be of good use for that purpose.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡å­¦ç”Ÿè¯„ä»·æ˜¯ä¸€ä¸ªè¾ƒå°çš„ç¼©å½±ï¼Œä½†è¿™ä¸ªæŠ€æœ¯åœ¨æ›´å¹¿æ³›çš„é¢†åŸŸä¹Ÿæœ‰è®¸å¤šç”¨é€”ã€‚åœ¨æˆ‘å·¥ä½œçš„[AAXIS](https://www.aaxisdigital.com)å…¬å¸ï¼Œæˆ‘ä»¬å®æ–½äº†ä¼ä¸šå¯¹ä¼ä¸šå’Œä¼ä¸šå¯¹æ¶ˆè´¹è€…çš„æ•°å­—å•†åŠ¡è§£å†³æ–¹æ¡ˆã€‚è¿™åŒ…æ‹¬å°†å¤§é‡æ•°æ®ä»ç°æœ‰çš„æ—§ç³»ç»Ÿè¿ç§»åˆ°å…·æœ‰ä¸åŒæ•°æ®ç»“æ„çš„æ–°ç³»ç»Ÿã€‚æˆ‘ä»¬ä½¿ç”¨å„ç§æ•°æ®å·¥å…·æ¥åˆ†ææºæ•°æ®ï¼Œä»¥ç¡®ä¿ä¸€è‡´æ€§ã€‚æœ¬æ–‡ä¸­æ¦‚è¿°çš„æŠ€æœ¯å¯èƒ½ä¼šå¯¹è¿™ä¸ªç›®çš„æœ‰å¾ˆå¤§å¸®åŠ©ã€‚
- en: Some of the other digital commerce use cases are checking the product catalog
    for errors, writing product copy, scanning review responses, and product review
    summarization, to name a few. A lot simpler to code for than the murky waters
    of undergrad creativity when asked for their majors.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä»–ä¸€äº›æ•°å­—å•†åŠ¡ç”¨ä¾‹åŒ…æ‹¬æ£€æŸ¥äº§å“ç›®å½•ä¸­çš„é”™è¯¯ã€ç¼–å†™äº§å“æ–‡æ¡ˆã€æ‰«æè¯„è®ºå›å¤å’Œäº§å“è¯„è®ºæ€»ç»“ç­‰ç­‰ã€‚æ¯”èµ·å½“è¯¢é—®ä»–ä»¬çš„ä¸“ä¸šæ—¶çš„æœ¬ç§‘ç”Ÿåˆ›æ„ï¼Œç¼–ç¨‹è¦ç®€å•å¾—å¤šã€‚
- en: Still, it is important to note that while LLMs can be powerful tools in cleansing
    data, they should be used in conjunction with other techniques and human oversight.
    Data cleansing processes often require domain expertise, context understanding,
    and manual review to make informed decisions and maintain data integrity. LLMs
    are also not inference engines[10]. They are next-word predictors. And they tend
    to provide incorrect information very confidently and convincingly (hallucinations)
    [2][11]. Fortunately, during our testing, we didnâ€™t encounter any hallucinations
    since our use case primarily involved classification.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ•°æ®æ¸…æ´—ä¸­å¯èƒ½æ˜¯å¼ºå¤§çš„å·¥å…·ï¼Œä½†ä»éœ€æ³¨æ„ï¼Œå®ƒä»¬åº”è¯¥ä¸å…¶ä»–æŠ€æœ¯å’Œäººå·¥ç›‘ç£ç»“åˆä½¿ç”¨ã€‚æ•°æ®æ¸…æ´—è¿‡ç¨‹é€šå¸¸éœ€è¦é¢†åŸŸä¸“ä¸šçŸ¥è¯†ã€ä¸Šä¸‹æ–‡ç†è§£å’Œæ‰‹åŠ¨å®¡æŸ¥ï¼Œä»¥åšå‡ºæ˜æ™ºçš„å†³ç­–å¹¶ä¿æŒæ•°æ®å®Œæ•´æ€§ã€‚LLMs
    ä¹Ÿä¸æ˜¯æ¨ç†å¼•æ“[10]ã€‚å®ƒä»¬æ˜¯ä¸‹ä¸€ä¸ªè¯é¢„æµ‹å™¨ã€‚å®ƒä»¬å¾€å¾€éå¸¸è‡ªä¿¡ä¸”ä»¤äººä¿¡æœåœ°æä¾›é”™è¯¯ä¿¡æ¯ï¼ˆå¹»è§‰ï¼‰[2][11]ã€‚å¹¸è¿çš„æ˜¯ï¼Œåœ¨æˆ‘ä»¬çš„æµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰é‡åˆ°ä»»ä½•å¹»è§‰ï¼Œå› ä¸ºæˆ‘ä»¬çš„ç”¨ä¾‹ä¸»è¦æ¶‰åŠåˆ†ç±»ã€‚
- en: LLMs can be a great tool in your arsenal if you proceed with caution and are
    aware of the pitfalls.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœè°¨æ…ä½¿ç”¨å¹¶äº†è§£æ½œåœ¨é™·é˜±ï¼ŒLLMs å¯ä»¥æˆä¸ºä½ å·¥å…·ç®±ä¸­çš„ä¸€ä¸ªå¾ˆå¥½çš„å·¥å…·ã€‚
- en: '![](../Images/14ea7f5c68fc1c141a45404c249fc973.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/14ea7f5c68fc1c141a45404c249fc973.png)'
- en: Photo by [Paul Szewczyk](https://unsplash.com/fr/@allphotobangkok?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/xTPiSriowpA?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”± [Paul Szewczyk](https://unsplash.com/fr/@allphotobangkok?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    æä¾›ï¼Œæ¥è‡ª [Unsplash](https://unsplash.com/photos/xTPiSriowpA?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: The Final Nail
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœ€ç»ˆçš„å…³é”®
- en: 'We started out, in this article, by looking at a specific use case of data
    cleansing: normalizing survey responses to a specific set of values. This would
    allow us to group the responses and gain valuable insights. We used a Large Language
    Model (LLM), Open AIâ€™s GPT 3.5 Turbo, to help classify these responses. We reviewed
    the prompt that was used, how to make use of the API calls using the prompt, and
    the code needed to automate it all. Finally, we got it all put together and got
    the job done for a total OpenAI utility cost of less than one dollar.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆæ¢è®¨äº†æ•°æ®æ¸…ç†çš„å…·ä½“ç”¨ä¾‹ï¼šå°†è°ƒæŸ¥å›åº”æ ‡å‡†åŒ–ä¸ºä¸€ç»„ç‰¹å®šå€¼ã€‚è¿™å°†ä½¿æˆ‘ä»¬èƒ½å¤Ÿå¯¹å›åº”è¿›è¡Œåˆ†ç»„ï¼Œå¹¶è·å¾—æœ‰ä»·å€¼çš„è§è§£ã€‚æˆ‘ä»¬ä½¿ç”¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼ŒOpen
    AI çš„ GPT 3.5 Turboï¼Œæ¥å¸®åŠ©åˆ†ç±»è¿™äº›å›åº”ã€‚æˆ‘ä»¬å›é¡¾äº†ä½¿ç”¨çš„æç¤ºã€å¦‚ä½•åˆ©ç”¨æç¤ºè¿›è¡Œ API è°ƒç”¨ä»¥åŠæ‰€éœ€çš„ä»£ç æ¥è‡ªåŠ¨åŒ–æ‰€æœ‰æ“ä½œã€‚æœ€åï¼Œæˆ‘ä»¬å°†æ‰€æœ‰å†…å®¹æ•´åˆåœ¨ä¸€èµ·ï¼Œæ€»å…±èŠ±è´¹çš„
    OpenAI å·¥å…·æˆæœ¬ä¸åˆ°ä¸€ç¾å…ƒã€‚
- en: Did we have a proverbial LLM hammer and found the perfectly shiny nail in free-form
    survey responses? Maybe. More likely, we had a Swiss army knife and used it to
    skin and eat some fish. Not quite purpose-built, but still very adequate. And
    Esan really loves Sushi.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ˜¯å¦æ‹¥æœ‰ä¸€ä¸ªå…¸å‹çš„å¤§å‹è¯­è¨€æ¨¡å‹å·¥å…·ï¼Œå¹¶æ‰¾åˆ°å®Œç¾çš„è§£å†³æ–¹æ¡ˆï¼Ÿä¹Ÿè®¸ã€‚ä½†æ›´å¯èƒ½çš„æ˜¯ï¼Œæˆ‘ä»¬æ‹¥æœ‰äº†ä¸€æŠŠç‘å£«å†›åˆ€ï¼Œå¹¶ç”¨å®ƒæ¥å‰¥çš®å’Œåƒé±¼ã€‚è™½ç„¶ä¸æ˜¯ç‰¹åˆ«ä¸“ä¸šï¼Œä½†ä»ç„¶éå¸¸åˆé€‚ã€‚è‡³äºEsanï¼ŒçœŸçš„å¾ˆå–œæ¬¢å¯¿å¸ã€‚
- en: What is your use case? Weâ€™d love to hear from you!
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ çš„ç”¨ä¾‹æ˜¯ä»€ä¹ˆï¼Ÿæˆ‘ä»¬å¾ˆæƒ³å¬å¬ä½ çš„æ„è§ï¼
- en: The Co-conspirators
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åŒè°‹è€…
- en: The main work in this article was performed by me, [Esan Durrani](http://linkedin.com/in/esan-durrani-576b611b4),
    and Ryan Trattner, Co-Founders of [StudyFetch](https://www.linkedin.com/company/studyfetch/about/),
    an AI-powered platform that uses course material to create personalized all-in-one
    study sets for students.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡çš„ä¸»è¦å·¥ä½œç”±æˆ‘ **Esan Durrani** å’Œ Ryan Trattner æ‰§è¡Œï¼Œæˆ‘ä»¬æ˜¯ [StudyFetch](https://www.linkedin.com/company/studyfetch/about/)
    çš„è”åˆåˆ›å§‹äººï¼Œè¯¥å¹³å°åˆ©ç”¨è¯¾ç¨‹ææ–™ä¸ºå­¦ç”Ÿåˆ›å»ºä¸ªæ€§åŒ–çš„å…¨èƒ½å­¦ä¹ é›†ã€‚
- en: I would like to thank Prashant Mishra, Rajeev Hans, Israel Moura, and Andy Wagner,
    my colleagues at [AAXIS Digital](https://www.aaxisdigital.com/) for their review
    of this article and suggestions.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è¿˜è¦æ„Ÿè°¢ Prashant Mishraã€Rajeev Hansã€Israel Moura å’Œ Andy Wagnerï¼Œæˆ‘åœ¨ [AAXIS Digital](https://www.aaxisdigital.com/)
    çš„åŒäº‹ä»¬ï¼Œæ„Ÿè°¢ä»–ä»¬å¯¹æœ¬æ–‡çš„å®¡é˜…å’Œå»ºè®®ã€‚
- en: I would also like to thank my friend of thirty years, Kiran Bondalapati, VP
    of Engineering at TRM Labs for his initial formative guidance through the world
    of Generative AI and for reviewing this article.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è¿˜è¦æ„Ÿè°¢æˆ‘ä¸‰åå¹´çš„æœ‹å‹ **åŸºå…°Â·é‚¦è¾¾æ‹‰å¸•æ**ï¼ŒTRM Labs çš„å·¥ç¨‹å‰¯æ€»è£ï¼Œæ„Ÿè°¢ä»–åœ¨ç”Ÿæˆ AI é¢†åŸŸçš„åˆæ­¥æŒ‡å¯¼å’Œå¯¹æœ¬æ–‡çš„å®¡é˜…ã€‚
- en: Also, thanks to my editor, [Megan Polstra](https://www.linkedin.com/in/megan-polstra-3b6561171/),
    for making the article look and feel professional as always.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: å¦å¤–ï¼Œæ„Ÿè°¢æˆ‘çš„ç¼–è¾‘ [æ¢…æ ¹Â·æ³¢å°”æ–¯ç‰¹æ‹‰](https://www.linkedin.com/in/megan-polstra-3b6561171/)ï¼Œä¸€å¦‚æ—¢å¾€åœ°ä½¿æ–‡ç« çœ‹èµ·æ¥å’Œæ„Ÿè§‰ä¸“ä¸šã€‚
- en: Reference
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: 1\. Temu Raitaluoto, â€œThe importance of personalized marketing in the digital
    ageâ€, MaketTailor Blog, May 2023, [https://www.markettailor.io/blog/importance-of-personalized-marketing-in-digital-age](https://www.markettailor.io/blog/importance-of-personalized-marketing-in-digital-age)
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. **æ³°ç©†Â·èµ–å¡”å¢å¥¥æ‰˜**ï¼Œã€Šæ•°å­—æ—¶ä»£ä¸ªæ€§åŒ–è¥é”€çš„é‡è¦æ€§ã€‹ï¼ŒMaketTailor Blogï¼Œ2023å¹´5æœˆï¼Œ[https://www.markettailor.io/blog/importance-of-personalized-marketing-in-digital-age](https://www.markettailor.io/blog/importance-of-personalized-marketing-in-digital-age)
- en: '2\. Ankur A. Patel, Bryant Linton and Dina Sostarec, GPT-4, GPT-3, and GPT-3.5
    Turbo: A Review Of OpenAIâ€™s Large Language Models, Apr 2023, Ankurâ€™s Newsletter,
    [https://www.ankursnewsletter.com/p/gpt-4-gpt-3-and-gpt-35-turbo-a-review](https://www.ankursnewsletter.com/p/gpt-4-gpt-3-and-gpt-35-turbo-a-review)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. **å®‰åº“å°”Â·AÂ·å¸•ç‰¹å°”**ã€**å¸ƒèµ–æ©ç‰¹Â·æ—é¡¿** å’Œ **è¿ªå¨œÂ·ç´¢æ–¯å¡”é›·å…‹**ï¼Œã€ŠGPT-4ã€GPT-3 å’Œ GPT-3.5 Turboï¼šOpenAI
    å¤§å‹è¯­è¨€æ¨¡å‹ç»¼è¿°ã€‹ï¼Œ2023å¹´4æœˆï¼ŒAnkurâ€™s Newsletterï¼Œ[https://www.ankursnewsletter.com/p/gpt-4-gpt-3-and-gpt-35-turbo-a-review](https://www.ankursnewsletter.com/p/gpt-4-gpt-3-and-gpt-35-turbo-a-review)
- en: 3\. Alexandra Mendes, Ultimate ChatGPT prompt engineering guide for general
    users and developers, Jun 2023, Imaginary Cloud Blog, [https://www.imaginarycloud.com/blog/chatgpt-prompt-engineering/](https://www.imaginarycloud.com/blog/chatgpt-prompt-engineering/)
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. **äºšå†å±±å¾·æ‹‰Â·é—¨å¾·æ–¯**ï¼Œã€Šç»ˆæChatGPTæç¤ºå·¥ç¨‹æŒ‡å—ï¼šé¢å‘æ™®é€šç”¨æˆ·å’Œå¼€å‘è€…ã€‹ï¼Œ2023å¹´6æœˆï¼ŒImaginary Cloud Blogï¼Œ[https://www.imaginarycloud.com/blog/chatgpt-prompt-engineering/](https://www.imaginarycloud.com/blog/chatgpt-prompt-engineering/)
- en: 4\. Sebastian, How to Use OpenAIâ€™s ChatGPT API in Node.js, Mar 2023, Medium
    â€” Coding the Smart Way, [https://medium.com/codingthesmartway-com-blog/how-to-use-openais-chatgpt-api-in-node-js-3f01c1f8d473](https://medium.com/codingthesmartway-com-blog/how-to-use-openais-chatgpt-api-in-node-js-3f01c1f8d473)
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. **å¡å·´æ–¯è’‚å®‰**ï¼Œã€Šå¦‚ä½•åœ¨ Node.js ä¸­ä½¿ç”¨ OpenAI çš„ ChatGPT APIã€‹ï¼Œ2023å¹´3æœˆï¼ŒMedium â€” **æ™ºèƒ½ç¼–ç¨‹æ–¹å¼**ï¼Œ[https://medium.com/codingthesmartway-com-blog/how-to-use-openais-chatgpt-api-in-node-js-3f01c1f8d473](https://medium.com/codingthesmartway-com-blog/how-to-use-openais-chatgpt-api-in-node-js-3f01c1f8d473)
- en: 5\. Tristan Wolff, Liberate Your Prompts From ChatGPT Restrictions With The
    OpenAI API Playground, Feb 2023, Medium â€” Tales of Tomorrow, [https://medium.com/tales-of-tomorrow/liberate-your-prompts-from-chatgpt-restrictions-with-the-openai-api-playground-a0ac92644c6f](https://medium.com/tales-of-tomorrow/liberate-your-prompts-from-chatgpt-restrictions-with-the-openai-api-playground-a0ac92644c6f)
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. **ç‰¹é‡Œæ–¯å¦Â·æ²ƒå°”å¤«**ï¼Œã€Šåˆ©ç”¨ OpenAI API Playground è§£æ”¾ä½ çš„ ChatGPT æç¤ºã€‹ï¼Œ2023å¹´2æœˆï¼ŒMedium â€”
    **æ˜æ—¥æ•…äº‹**ï¼Œ[https://medium.com/tales-of-tomorrow/liberate-your-prompts-from-chatgpt-restrictions-with-the-openai-api-playground-a0ac92644c6f](https://medium.com/tales-of-tomorrow/liberate-your-prompts-from-chatgpt-restrictions-with-the-openai-api-playground-a0ac92644c6f)
- en: 6\. AlgoWriting, A simple guide to setting the GPT-3 temperature, Nov 2020,
    Medium, [https://algowriting.medium.com/gpt-3-temperature-setting-101-41200ff0d0be](https://algowriting.medium.com/gpt-3-temperature-setting-101-41200ff0d0be)
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 6\. **AlgoWriting**ï¼Œã€Šç®€å•æŒ‡å—ï¼šè®¾ç½® GPT-3 æ¸©åº¦ã€‹ï¼Œ2020å¹´11æœˆï¼ŒMediumï¼Œ[https://algowriting.medium.com/gpt-3-temperature-setting-101-41200ff0d0be](https://algowriting.medium.com/gpt-3-temperature-setting-101-41200ff0d0be)
- en: 7\. Kane Hooper, Mastering the GPT-3 Temperature Parameter with Ruby, Jan 2023,
    Plain English, [https://plainenglish.io/blog/mastering-the-gpt-3-temperature-parameter-with-ruby](https://plainenglish.io/blog/mastering-the-gpt-3-temperature-parameter-with-ruby)
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 7\. **å‡¯æ©Â·èƒ¡ç€**ï¼Œã€Šç”¨ Ruby æŒæ¡ GPT-3 æ¸©åº¦å‚æ•°ã€‹ï¼Œ2023å¹´1æœˆï¼ŒPlain Englishï¼Œ[https://plainenglish.io/blog/mastering-the-gpt-3-temperature-parameter-with-ruby](https://plainenglish.io/blog/mastering-the-gpt-3-temperature-parameter-with-ruby)
- en: 8\. OpenAI Authors, GPT Guide â€” Managing tokens, 2023, OpenAI Documentation,
    [https://platform.openai.com/docs/guides/gpt/managing-tokens](https://platform.openai.com/docs/guides/gpt/managing-tokens)
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 8\. **OpenAI ä½œè€…**ï¼Œã€ŠGPT æŒ‡å— â€” ç®¡ç†ä»¤ç‰Œã€‹ï¼Œ2023å¹´ï¼ŒOpenAI æ–‡æ¡£ï¼Œ[https://platform.openai.com/docs/guides/gpt/managing-tokens](https://platform.openai.com/docs/guides/gpt/managing-tokens)
- en: 9\. Priyesh Patel, What exactly is Node.js?, Apr 2018, Medium â€” Free Code Camp,
    [https://medium.com/free-code-camp/what-exactly-is-node-js-ae36e97449f5](https://medium.com/free-code-camp/what-exactly-is-node-js-ae36e97449f5)
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 9\. **æ™®é‡Œè€¶ä»€Â·å¸•ç‰¹å°”**ï¼Œã€ŠNode.js ç©¶ç«Ÿæ˜¯ä»€ä¹ˆï¼Ÿã€‹ï¼Œ2018å¹´4æœˆï¼ŒMedium â€” **è‡ªç”±ä»£ç è¥**ï¼Œ[https://medium.com/free-code-camp/what-exactly-is-node-js-ae36e97449f5](https://medium.com/free-code-camp/what-exactly-is-node-js-ae36e97449f5)
- en: 10\. Ben Dickson, Large language models have a reasoning problem, June 2022,
    Tech Talks Blog, [https://bdtechtalks.com/2022/06/27/large-language-models-logical-reasoning/](https://bdtechtalks.com/2022/06/27/large-language-models-logical-reasoning/)
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 10\. **æœ¬Â·è¿ªå…‹æ£®**ï¼Œã€Šå¤§å‹è¯­è¨€æ¨¡å‹å­˜åœ¨æ¨ç†é—®é¢˜ã€‹ï¼Œ2022å¹´6æœˆï¼ŒTech Talks Blogï¼Œ[https://bdtechtalks.com/2022/06/27/large-language-models-logical-reasoning/](https://bdtechtalks.com/2022/06/27/large-language-models-logical-reasoning/)
- en: 11\. Frank Neugebauer, Understanding LLM Hallucinations, May 2023, Towards Data
    Science, [https://towardsdatascience.com/llm-hallucinations-ec831dcd7786](/llm-hallucinations-ec831dcd7786)
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 11\. **å¼—å…°å…‹Â·è¯ºä¼Šæ ¹é²å°”**ï¼Œã€Šç†è§£ LLM å¹»è§‰ã€‹ï¼Œ2023å¹´5æœˆï¼ŒTowards Data Scienceï¼Œ[https://towardsdatascience.com/llm-hallucinations-ec831dcd7786](/llm-hallucinations-ec831dcd7786)
