- en: 'Beyond LLaMA: The Power of Open LLMs'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/beyond-llama-the-power-of-open-llms-cef807a54a4f?source=collection_archive---------10-----------------------#2023-07-18](https://towardsdatascience.com/beyond-llama-the-power-of-open-llms-cef807a54a4f?source=collection_archive---------10-----------------------#2023-07-18)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How LLaMA is making open-source cool again
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://wolfecameron.medium.com/?source=post_page-----cef807a54a4f--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----cef807a54a4f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cef807a54a4f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cef807a54a4f--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----cef807a54a4f--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F28aa6026c553&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-llama-the-power-of-open-llms-cef807a54a4f&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=post_page-28aa6026c553----cef807a54a4f---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cef807a54a4f--------------------------------)
    ·18 min read·Jul 18, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcef807a54a4f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-llama-the-power-of-open-llms-cef807a54a4f&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=-----cef807a54a4f---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcef807a54a4f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-llama-the-power-of-open-llms-cef807a54a4f&source=-----cef807a54a4f---------------------bookmark_footer-----------)![](../Images/29a535e5c06be6b564ccfb3b42238ab5.png)'
  prefs: []
  type: TYPE_NORMAL
- en: (Photo by [Paz Arando](https://unsplash.com/@pazarando?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/llama?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText))
  prefs: []
  type: TYPE_NORMAL
- en: Despite recent advances in large language models (LLMs), many of the most powerful
    models are only accessible via [paid APIs](https://console.anthropic.com/docs/api)
    and trained using large amounts of [proprietary data](https://openai.com/research/gpt-4),
    thus limiting the research community from accessing or reproducing such models.
    This trend raises serious concerns about whether LLMs will be mostly controlled
    by a small number of centralized groups that force others to pay for interaction
    with these models. Such a scenario strictly prevents most researchers from directly
    accessing or improving LLMs on their own.
  prefs: []
  type: TYPE_NORMAL
- en: “[Many] LLMs require huge computational resources to train, and oftentimes use
    large and proprietary datasets. This suggests that in the future, highly capable
    LLMs will be largely controlled by a small number of organizations.” *— from [5]*
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Given the computational burden of training and hosting LLMs, we might wonder
    whether open-sourcing these models is even helpful for the research community.
    If we are not part of a massive organization with extensive compute resources,
    *can we even do useful research with LLMs?* If not,maybe we are doomed to a world
    of centralized control of and access to LLMs. These models seem to have too much
    “gravity” (i.e., require access to tons of data and compute) for most people to
    easily work with…
  prefs: []
  type: TYPE_NORMAL
