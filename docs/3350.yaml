- en: Using LLMs to evaluate LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 LLM 来评估 LLM
- en: 原文：[https://towardsdatascience.com/using-llms-to-evaluate-llms-ce390ae575c6?source=collection_archive---------6-----------------------#2023-11-10](https://towardsdatascience.com/using-llms-to-evaluate-llms-ce390ae575c6?source=collection_archive---------6-----------------------#2023-11-10)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/using-llms-to-evaluate-llms-ce390ae575c6?source=collection_archive---------6-----------------------#2023-11-10](https://towardsdatascience.com/using-llms-to-evaluate-llms-ce390ae575c6?source=collection_archive---------6-----------------------#2023-11-10)
- en: '[](https://medium.com/@petyak.mi?source=post_page-----ce390ae575c6--------------------------------)[![Maksym
    Petyak](../Images/0c2d4054352a58537c9e76b5911b8b2e.png)](https://medium.com/@petyak.mi?source=post_page-----ce390ae575c6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ce390ae575c6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ce390ae575c6--------------------------------)
    [Maksym Petyak](https://medium.com/@petyak.mi?source=post_page-----ce390ae575c6--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@petyak.mi?source=post_page-----ce390ae575c6--------------------------------)[![Maksym
    Petyak](../Images/0c2d4054352a58537c9e76b5911b8b2e.png)](https://medium.com/@petyak.mi?source=post_page-----ce390ae575c6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ce390ae575c6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ce390ae575c6--------------------------------)
    [Maksym Petyak](https://medium.com/@petyak.mi?source=post_page-----ce390ae575c6--------------------------------)'
- en: ·
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2ab7d66fcd36&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-llms-to-evaluate-llms-ce390ae575c6&user=Maksym+Petyak&userId=2ab7d66fcd36&source=post_page-2ab7d66fcd36----ce390ae575c6---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ce390ae575c6--------------------------------)
    ·7 min read·Nov 10, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fce390ae575c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-llms-to-evaluate-llms-ce390ae575c6&user=Maksym+Petyak&userId=2ab7d66fcd36&source=-----ce390ae575c6---------------------clap_footer-----------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2ab7d66fcd36&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-llms-to-evaluate-llms-ce390ae575c6&user=Maksym+Petyak&userId=2ab7d66fcd36&source=post_page-2ab7d66fcd36----ce390ae575c6---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ce390ae575c6--------------------------------)
    ·7 分钟阅读·2023年11月10日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fce390ae575c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-llms-to-evaluate-llms-ce390ae575c6&user=Maksym+Petyak&userId=2ab7d66fcd36&source=-----ce390ae575c6---------------------clap_footer-----------)'
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fce390ae575c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-llms-to-evaluate-llms-ce390ae575c6&source=-----ce390ae575c6---------------------bookmark_footer-----------)![](../Images/44441b26ad2c878ab0d5fbe3ea98a1b6.png)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fce390ae575c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-llms-to-evaluate-llms-ce390ae575c6&source=-----ce390ae575c6---------------------bookmark_footer-----------)![](../Images/44441b26ad2c878ab0d5fbe3ea98a1b6.png)'
- en: Image generated by OpenAI’s DALL-E 3.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 OpenAI 的 DALL-E 3 生成。
- en: 'You can ask ChatGPT to act in a million different ways: as your nutritionist,
    language tutor, doctor, etc. It’s no surprise we see a lot of demos and products
    launching on top of the OpenAI API. But while it’s easy to make LLMs act a certain
    way, ensuring they perform well and accurately complete the given task is a completely
    different story.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以要求 ChatGPT 以百万种不同的方式进行工作：作为你的营养师、语言导师、医生等。不奇怪我们看到很多基于 OpenAI API 的演示和产品发布。但虽然让
    LLM 以某种方式运作很容易，确保它们表现良好并准确完成给定任务则是完全不同的故事。
- en: The problem is that many criteria that we care about are extremely subjective.
    Are the answers accurate? Are the responses coherent? Was anything hallucinated?
    It’s hard to build quantifiable metrics for evaluation. Mostly, you need human
    judgment, but it’s expensive to have humans check a large number of LLM outputs.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于我们关注的许多标准都是极其主观的。回答是否准确？回答是否连贯？有没有虚假信息？建立可量化的评估指标很困难。通常，你需要人工判断，但让人类检查大量
    LLM 输出是非常昂贵的。
- en: Moreover, LLMs have a lot of parameters that you can tune. Prompt, temperature,
    context, etc. You can fine-tune the models on a specific dataset to fit your use
    case. With prompt engineering, even asking a model to take a deep breath [1] or
    making your request more emotional [2] can change performance for the better.
    There is a lot of room to tweak and experiment, but after you change something,
    you need to be able to tell if the system overall got better or worse.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: With human labour being slow and expensive, there is a strong incentive to find
    automatic metrics for these more subjective criteria. One interesting approach,
    which is gaining popularity, is using LLMs to evaluate the output from LLMs. After
    all, if ChatGPT can generate a good, coherent response to a question, can it also
    not say if a given text is coherent? This opens up a whole box of potential biases,
    techniques, and opportunities, so let’s dive into it.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: LLM biases
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you have a negative gut reaction about building metrics and evaluators using
    LLMs, your concerns are well-founded. This could be a horrible way to just propagate
    the existing biases.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: For example, in the G-Eval paper, which we will discuss in more detail later,
    researchers showed that their LLM-based evaluation gives higher scores to GPT-3.5
    summaries than human-written summaries, even when human judges prefer human-written
    summaries.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Another study, titled [“Large Language Models are not Fair Evaluators”](https://arxiv.org/abs/2305.17926)
    [3], found that when asked to choose which of the two presented options is better,
    there is a significant bias in the order in which order you present the options.
    GPT-4, for example, often preferred the first given option, while ChatGPT the
    second one. You can just ask the same question with the order flipped and see
    how consistent LLMs are in their answers. They subsequently developed techniques
    to mitigate this bias by running the LLM multiple times with different orders
    of options.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating the evaluators
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At the end of the day, we want to know if LLMs can perform as well as or similarly
    to human evaluators. We can still approach this as a scientific problem:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Set up evaluation criteria.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ask humans and LLMs to evaluate according to the criteria.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the correlation between human and LLM evaluation.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This way, we can get an idea of how closely LLMs resemble human evaluators.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, there are already several studies like this, showing that for certain
    tasks, LLMs do a much better job than more traditional evaluation metrics. And
    it’s worth noting that we don’t need a perfect correlation. If we evaluate over
    many examples, even if the evaluation isn’t perfect, we could still get some idea
    of whether the new system is performing better or worse. We could also use LLM
    evaluators to flag the worrying edge cases for human evaluators.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Let’s have a look at some of the recently proposed metrics and evaluators that
    rely on LLMs at their core.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: G-Eval
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[G-Eval](https://arxiv.org/abs/2303.16634) [4] works by first outlining the
    evaluation criteria and then simply asking the model to give the rating. It could
    be used for summarisation and dialogue generation tasks, for example.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[G-Eval](https://arxiv.org/abs/2303.16634) [4] 的工作方式是首先概述评估标准，然后简单地要求模型给出评分。它可以用于摘要和对话生成任务，例如。'
- en: 'G-Eval has the following components:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: G-Eval 包含以下组件：
- en: '**Prompt.** Defines the evaluation task and its criteria.'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**提示。** 定义了评估任务及其标准。'
- en: '**Intermediate instructions.** Outlines the intermediate instructions for evaluation.
    They actually ask the LLM to generate these steps.'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**中间指令。** 概述了评估的中间指令。它们实际上要求 LLM 生成这些步骤。'
- en: '**Scoring function.** Instead of taking the LLM score at face value, we look
    under the hood at the token probabilities to get the final score. So, if you ask
    to rate between 1 and 5, instead of just taking whatever number is given by the
    LLM (say “3”), we would look at the probability of each rank and calculate the
    weighted score. This is because researchers found that usually one digit dominates
    the evaluation (e.g. outputting mostly 3), and even when you ask the LLM to give
    a decimal value, it still tends to return integers.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**评分函数。** 我们不会直接采纳 LLM 的评分，而是查看底层的标记概率以获得最终得分。因此，如果你要求在 1 到 5 之间评分，我们不会仅仅采用
    LLM 给出的数字（例如“3”），而是会查看每个等级的概率并计算加权得分。这是因为研究人员发现通常一个数字主导了评估（例如主要输出 3），即使你要求 LLM
    给出一个小数值，它仍然倾向于返回整数。'
- en: '![](../Images/d17a2fd00441c0db75b8a279d9adb929.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d17a2fd00441c0db75b8a279d9adb929.png)'
- en: G-Eval prompt for calculating coherence on a scale 1–5\. You can find more examples
    in the [original paper](https://arxiv.org/pdf/2303.16634.pdf).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: G-Eval 提供的提示用于在 1 到 5 的范围内计算连贯性。你可以在[原始论文](https://arxiv.org/pdf/2303.16634.pdf)中找到更多示例。
- en: G-Eval was found to significantly outperform traditional reference-based metrics,
    such as BLEU and ROUGE, which had a relatively low correlation with human judgments.
    On the surface, it looks pretty straightforward, as we just ask the LLM to perform
    the evaluation. We could also try to break down the tasks into smaller components.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 研究发现 G-Eval 在显著程度上超越了传统的基于参考的指标，如 BLEU 和 ROUGE，这些指标与人工判断的相关性相对较低。表面上看，这似乎非常简单，因为我们只是要求
    LLM 执行评估。我们也可以尝试将任务分解为更小的组件。
- en: FactScore
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: FactScore
- en: '[FactScore](https://arxiv.org/abs/2305.14251) (Factual precision in Atomicity
    Score) [5] is a metric for factual precision. The two key ideas there are to treat
    atomic facts as a unit and to base trustfulness on a particular knowledge source.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[FactScore](https://arxiv.org/abs/2305.14251)（原子性得分中的事实精确度）[5] 是一个用于事实精确度的指标。这里的两个关键概念是将原子事实视为一个单元，并基于特定的知识来源来评估可信度。'
- en: For evaluation, you break down the generation into small “atomic“ facts (e.g.
    “He was born in New York”) and then check for each fact if it is supported by
    the given ground-truth knowledge source. The final score is calculated by dividing
    the number of supported facts by the total number of facts.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估中，你将生成内容分解为小的“原子”事实（例如“他出生在纽约”），然后检查每个事实是否得到给定真实知识来源的支持。最终得分是通过将被支持的事实数量除以总事实数量来计算的。
- en: In the paper, the researchers asked LLMs to generate biographies of people and
    then used Wikipedia articles about them as the source of truth. The error rate
    for LLMs doing the same procedure as humans was less than 2%.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在论文中，研究人员让 LLM 生成人物传记，然后使用关于他们的维基百科文章作为真实来源。LLM 进行与人类相同程序的错误率低于 2%。
- en: '![](../Images/bef8489a9e71bd5102d9e0527dc96a75.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bef8489a9e71bd5102d9e0527dc96a75.png)'
- en: FactScore for generating a biography of Bridget Moynahan. See also the [original
    paper](https://arxiv.org/abs/2305.14251).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: FactScore 用于生成布里奇特·莫伊纳汉的传记。请参阅[原始论文](https://arxiv.org/abs/2305.14251)。
- en: RAGAS
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RAGAS
- en: Now, let’s have a look at some metrics for retrieval-augmented generation (RAG).
    With RAG, you first retrieve the relevant context in an external knowledge base
    and then ask the LLM to answer the question based on those facts.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看一些检索增强生成（RAG）的指标。使用 RAG 时，你首先在外部知识库中检索相关的上下文，然后让 LLM 根据这些事实回答问题。
- en: '[RAGAS](https://arxiv.org/abs/2309.15217v1) (Retrieval Augmented Generation
    Assessment) [6] is a new framework for evaluating RAGs. It’s not a single metric
    but rather a collection of them. The three proposed in the paper are faithfulness,
    answer relevance, and context relevance. These metrics perfectly illustrate how
    you can break down evaluation into simpler tasks for LLMs.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[RAGAS](https://arxiv.org/abs/2309.15217v1)（检索增强生成评估）[6]是一个用于评估RAG的新框架。它不是一个单一的指标，而是一系列指标的集合。论文中提出的三个指标是忠实度、回答相关性和上下文相关性。这些指标完美地展示了如何将评估分解为LLMs的简单任务。'
- en: '**Faithfulness** measures how grounded the answers are in the given context.
    It’s very similar to FactScore, in that you first break down the generation into
    the set of statements and then ask the LLM if the statement is supported by the
    given context. The score is the number of supported statements divided by the
    number of all statements. For faithfulness, researchers found a very high correlation
    to human annotators.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**忠实度**衡量回答在给定上下文中的扎实程度。这与FactScore非常相似，你首先将生成的内容分解为一系列陈述，然后询问LLM这些陈述是否得到给定上下文的支持。得分是支持的陈述数除以所有陈述的总数。对于忠实度，研究人员发现与人工标注者有很高的相关性。'
- en: '**Answer relevance** tries to capture the idea that the answer addresses the
    actual question. You start by asking the LLM to generate questions based on the
    answer. For each generated question, you can calculate the similarity (by creating
    an embedding and using cosine similarity) between the generated question and the
    original question. By doing this *n* times and averaging out the similarity scores,
    you get the final value for answer relevance.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**回答相关性**试图捕捉回答是否针对实际问题的概念。你可以先要求LLM根据答案生成问题。对于每个生成的问题，你可以计算生成的问题与原始问题之间的相似度（通过创建嵌入并使用余弦相似度）。通过这样做*n*次并计算相似度得分的平均值，你将得到最终的回答相关性值。'
- en: '**Context relevance** refers to how relevant the provided context is. Meaning,
    the provided context contains only the information that is needed to answer the
    question. In the ideal case, we give the LLM the right information to answer the
    question and only that. Context relevance is calculated by asking the LLM to extract
    the sentences in the given context that were relevant to the answer. Then just
    divide the number of relevant sentences by the total number of sentences to get
    the final score.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**上下文相关性**指的是提供的上下文的相关性。也就是说，提供的上下文仅包含回答问题所需的信息。在理想情况下，我们只向LLM提供回答问题所需的正确信息。上下文相关性是通过要求LLM提取上下文中与答案相关的句子来计算的。然后只需将相关句子的数量除以总句子数以获得最终得分。'
- en: You can find further metrics and explanations (along with the open-sourced GitHub
    repo) [here](https://docs.ragas.io/en/latest/getstarted/index.html).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[这里](https://docs.ragas.io/en/latest/getstarted/index.html)找到更多的指标和解释（以及开源的GitHub仓库）。
- en: The key point is that we can transform evaluation into a smaller subproblem.
    Instead of asking if the entire text is supported by the context, we ask only
    if a small specific fact is supported by the context. Instead of directly giving
    a number for if the answer is relevant, we ask LLM to think up a question for
    the given answer.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 关键点是我们可以将评估转化为更小的子问题。我们不是询问整个文本是否得到上下文支持，而是询问一个小的具体事实是否得到上下文支持。我们不是直接给出答案是否相关的数字，而是要求LLM为给定的答案想出一个问题。
- en: Conclusion
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Evaluating LLMs is an extremely interesting research topic that will get more
    and more attention as more systems start reaching production and are also applied
    in more safety-critical settings.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 评估LLMs是一个极具趣味的研究课题，随着越来越多的系统进入生产阶段并应用于更多安全关键的环境，这一话题将受到越来越多的关注。
- en: We could also use these metrics to monitor the performance of LLMs in production
    to notice if the quality of outputs starts degrading. Especially for applications
    with high costs of mistakes, such as healthcare, it will be crucial to develop
    guardrails and systems to catch and reduce errors.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用这些指标来监控LLMs在生产中的表现，以便发现输出质量是否开始下降。特别是在错误成本高的应用场景中，如医疗保健，开发保护措施和系统以捕捉和减少错误将是至关重要的。
- en: While there are definitely biases and problems with using LLMs as evaluators,
    we should still keep an open mind and approach it as a research problem. Of course,
    humans will still be involved in the evaluation process, but automatic metrics
    could help partially assess the performance in some settings.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管使用LLM作为评估器时肯定存在偏见和问题，我们仍应以研究问题的态度保持开放的心态。当然，人类仍将参与评估过程，但在某些场景中，自动化指标可以部分评估性能。
- en: These metrics don’t always have to be perfect; they just need to work well enough
    to guide the development of products in the right way.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标不必总是完美的；它们只需要足够好以正确指导产品的开发。
- en: '*Special thanks to Daniel Raff and Yevhen Petyak for their feedback and suggestions.*'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*特别感谢Daniel Raff和Yevhen Petyak的反馈和建议。*'
- en: '*Originally published on* [*Medplexity substack*](https://medplexity.substack.com/p/using-llms-to-evaluate-llms)*.*'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '*最初发表于* [*Medplexity substack*](https://medplexity.substack.com/p/using-llms-to-evaluate-llms)*。*'
- en: Yang, Chengrun, et al. [*Large Language Models as Optimizers*](https://arxiv.org/abs/2309.03409).
    arXiv, 6 Sept. 2023\. *arXiv.org*, [https://doi.org/10.48550/arXiv.2309.03409.](https://doi.org/10.48550/arXiv.2309.03409.)
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 杨成润等人。[*大语言模型作为优化器*](https://arxiv.org/abs/2309.03409)。arXiv，2023年9月6日。*arXiv.org*，[https://doi.org/10.48550/arXiv.2309.03409.](https://doi.org/10.48550/arXiv.2309.03409.)
- en: Li, Cheng, et al. *Large Language Models Understand and Can Be Enhanced by Emotional
    Stimuli*. arXiv, 5 Nov. 2023\. *arXiv.org*, [https://doi.org/10.48550/arXiv.2307.11760.](https://doi.org/10.48550/arXiv.2307.11760.)
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 李成等人。*大语言模型理解并能通过情感刺激进行增强*。arXiv，2023年11月5日。*arXiv.org*，[https://doi.org/10.48550/arXiv.2307.11760.](https://doi.org/10.48550/arXiv.2307.11760.)
- en: Wang, Peiyi, et al. [*Large Language Models Are Not Fair Evaluators*](https://arxiv.org/abs/2305.17926).
    arXiv, 30 Aug. 2023\. *arXiv.org*, [https://doi.org/10.48550/arXiv.2305.17926.](https://doi.org/10.48550/arXiv.2305.17926.)
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 王培毅等人。[*大语言模型并非公平的评估器*](https://arxiv.org/abs/2305.17926)。arXiv，2023年8月30日。*arXiv.org*，[https://doi.org/10.48550/arXiv.2305.17926.](https://doi.org/10.48550/arXiv.2305.17926.)
- en: 'Liu, Yang, et al. [*G-Eval: NLG Evaluation Using GPT-4 with Better Human Alignment*](https://arxiv.org/abs/2303.16634).
    arXiv, 23 May 2023\. *arXiv.org*, [https://doi.org/10.48550/arXiv.2303.16634.](https://doi.org/10.48550/arXiv.2303.16634.)'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '刘洋等人。[*G-Eval: 使用GPT-4进行更好人类对齐的NLG评估*](https://arxiv.org/abs/2303.16634)。arXiv，2023年5月23日。*arXiv.org*，[https://doi.org/10.48550/arXiv.2303.16634.](https://doi.org/10.48550/arXiv.2303.16634.)'
- en: 'Min, Sewon, et al. [*FActScore: Fine-Grained Atomic Evaluation of Factual Precision
    in Long Form Text Generation*](https://arxiv.org/abs/2305.14251). arXiv, 11 Oct.
    2023\. *arXiv.org*, [https://doi.org/10.48550/arXiv.2305.14251.](https://doi.org/10.48550/arXiv.2305.14251.)'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '闵世温等人。[*FActScore: 长篇文本生成中细粒度原子级事实精确度评估*](https://arxiv.org/abs/2305.14251)。arXiv，2023年10月11日。*arXiv.org*，[https://doi.org/10.48550/arXiv.2305.14251.](https://doi.org/10.48550/arXiv.2305.14251.)'
- en: 'Es, Shahul, et al. [*RAGAS: Automated Evaluation of Retrieval Augmented Generation*](https://arxiv.org/abs/2309.15217v1).
    1, arXiv, 26 Sept. 2023\. *arXiv.org*, [https://doi.org/10.48550/arXiv.2309.15217.](https://doi.org/10.48550/arXiv.2309.15217.)'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Shahul Es等人。[*RAGAS: 自动化评估检索增强生成*](https://arxiv.org/abs/2309.15217v1)。1，arXiv，2023年9月26日。*arXiv.org*，[https://doi.org/10.48550/arXiv.2309.15217.](https://doi.org/10.48550/arXiv.2309.15217.)'
