- en: How to Build an Interconnected Multi-Page Streamlit App
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/how-to-build-an-interconnected-multi-page-streamlit-app-3114c313f88f?source=collection_archive---------8-----------------------#2023-07-24](https://towardsdatascience.com/how-to-build-an-interconnected-multi-page-streamlit-app-3114c313f88f?source=collection_archive---------8-----------------------#2023-07-24)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: From planning to execution ‚Äî how I built GPT lab
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@dclin?source=post_page-----3114c313f88f--------------------------------)[![Dave
    Lin](../Images/630f84748ac5ea04912ca28cffdbfd15.png)](https://medium.com/@dclin?source=post_page-----3114c313f88f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3114c313f88f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3114c313f88f--------------------------------)
    [Dave Lin](https://medium.com/@dclin?source=post_page-----3114c313f88f--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6b1d830863a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-interconnected-multi-page-streamlit-app-3114c313f88f&user=Dave+Lin&userId=6b1d830863a3&source=post_page-6b1d830863a3----3114c313f88f---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3114c313f88f--------------------------------)
    ¬∑9 min read¬∑Jul 24, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3114c313f88f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-interconnected-multi-page-streamlit-app-3114c313f88f&user=Dave+Lin&userId=6b1d830863a3&source=-----3114c313f88f---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3114c313f88f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-interconnected-multi-page-streamlit-app-3114c313f88f&source=-----3114c313f88f---------------------bookmark_footer-----------)![](../Images/e492690c6892273adc45a13ebb488b40.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Cl√©ment H√©lardot](https://unsplash.com/@clemhlrdt?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: This article was originally featured on* [*Streamlit blog*](https://blog.streamlit.io/how-to-build-an-interconnected-multi-page-streamlit-app/)*.
    I wanted to share it here for the Medium community to see.*'
  prefs: []
  type: TYPE_NORMAL
- en: Wow! What an incredible three months since I first published my blog post on
    [the lessons learned from building GPT Lab](https://www.notion.so/Building-GPT-Lab-with-Streamlit-2b8e8694a1384373a0bf176506d79444?pvs=21)!
    üöÄ
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to your tremendous support, GPT Lab has received over 9K app views, 1150+
    unique signed-in users, 900+ sessions with assistants, 650+ prompts tested, and
    180+ assistants created. The app has also been featured in the Streamlit App Gallery
    alongside other great apps.
  prefs: []
  type: TYPE_NORMAL
- en: '[http://gptlab.streamlit.app/?embed=true](http://gptlab.streamlit.app/?embed=true)'
  prefs: []
  type: TYPE_NORMAL
- en: Many of you have asked me, ‚ÄúHow did you plan and build such a large application
    with Streamlit?‚Äù Eager to answer, I‚Äôve decided to open-source GPT Lab.
  prefs: []
  type: TYPE_NORMAL
- en: In this post, I‚Äôll share insights into the strategies and thought processes
    behind this ambitious project. I hope it will inspire you to push Streamlit to
    its limits and bring your ambitious apps to life.
  prefs: []
  type: TYPE_NORMAL
- en: '*üí° Want to skip ahead? Check out the* [*app*](https://gptlab.streamlit.app/)
    *and the* [*code*](https://github.com/dclin/gptlab-streamlit)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: Planning a large Streamlit app
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Building large Streamlit apps, such as GPT Lab, requires careful planning rather
    than just throwing code together. For GPT Lab, I focused on planning these four
    key aspects:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Feature and UX.** What will the app do? What kind of user experience do we
    aim to provide?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Data model.** How will data be persisted? What should be stored in the database
    versus session state variables?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Code structure.** How should the app be architected to ensure modularity,
    maintainability, and scalability?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Session states.** Which session state variables are needed to link the user
    interface?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Understanding these aspects offered a clearer view of what I was trying to build
    and provided a framework to approach the complex task systematically.
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs dive into each aspect in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'Feature and UX: Creating initial spec and low-fi UX mocks'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To start, I created a simple specification document (or ‚Äúspec‚Äù) outlining the
    overall scope and approach. I also included a sitemap detailing the use cases
    I wanted to support. The spec provided me with a clear roadmap to follow and a
    means to measure my progress.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here‚Äôs an excerpt from the original spec:'
  prefs: []
  type: TYPE_NORMAL
- en: '***Scope***'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Build a platform that allows generative AI (GA) bot enthusiasts to build their
    own GPT-3 prompt-based chatbot for their friends and families. The goal is to
    test the hypothesis that enough GA bot enthusiasts would want to build their niche-domain
    bots.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '***Approach***'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*A public Streamlit site that allows users to interact with one of the four
    pre-trained coach bots or create and interact with their bots.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As with most development projects, I made some changes. But the original sitemap
    remained intact for the most part, as I was able to implement most of the planned
    features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the final version of the sitemap:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: I can‚Äôt overstate the importance of feature planning. It provides a roadmap,
    a way to measure progress, and a starting point for thinking about the data model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Data model: Determining the schema'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From the start, I recognized that a backend data store was crucial for persisting
    user, assistant, and session records. After considering my options, I decided
    on Google Firestore due to its scalability, real-time capabilities, and generous
    free tier. To support future expansions, I strategically designed the data model.
    Although the current app only uses a fraction of its potential, it‚Äôs possible
    to add prompt version controls to GPT Lab. This would enable users to edit or
    revert their assistants.
  prefs: []
  type: TYPE_NORMAL
- en: '*üí° NOTE: In the app backend and data model, assistants are referred to as bots,
    despite my previous insistence on not calling them bots in the user interface
    üòÖ.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let‚Äôs explore the four main Firestore collections in GPT Lab: users, user_hash,
    bots, and sessions.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Users and user_hash**'
  prefs: []
  type: TYPE_NORMAL
- en: The users collection is where the app stores information about its users. To
    protect user privacy, the app doesn‚Äôt store any personally identifiable information
    (PII) about users. Instead, each user is associated only with the one-way hash
    value of their OpenAI API key. The metric fields are incremented whenever a user
    creates an assistant or starts/ends a session with an assistant. This allows for
    basic analytics gathering within the app.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Google Firestore doesn‚Äôt provide a way to ensure the uniqueness of a document
    field value within a collection, so I created a separate collection called user_hash.
    This ensures that each unique API key has only one associated user record. Each
    user document is uniquely associated with a user_hash document, and each user_hash
    document may be associated with a user document. The data model is flexible enough
    to accommodate users who change their API keys in the future (users can log in
    with their old API key and then swap it out for a new one).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Bots**'
  prefs: []
  type: TYPE_NORMAL
- en: The bots collection stores configurations for AI assistants. The crux of each
    AI assistant is its large language model (LLM), model configurations, and prompts.
    To enable proper version control of prompts and model configurations in the future,
    model_configs and prompts are modeled as subcollections (part of GPT Lab‚Äôs vision
    is to be the repository of your prompts).
  prefs: []
  type: TYPE_NORMAL
- en: To minimize subcollection reads (so you don‚Äôt need to constantly query the subcollections
    for the active record), the document IDs of the active subcollection are also
    stored at the document level. The session_type field indicates whether the assistant
    is in a brainstorming or coaching session, which affects the session message truncation
    technique.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the metric fields are incremented when a user starts or ends a session
    with an assistant.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: S**essions**
  prefs: []
  type: TYPE_NORMAL
- en: 'The sessions collection stores session data. It contains two types of sessions:
    lab sessions (used for testing prompts) and assistant sessions (used for chatting
    with created assistants). To reduce the need for frequent retrieval of the bot
    document, its information is cached within the session document. This makes conceptual
    sense, as the bot document could drift if an editing assistant use case were ever
    implemented.'
  prefs: []
  type: TYPE_NORMAL
- en: The `messages_str` field stores the most recent payload sent to OpenAI's LLM.
    This feature allows users to resume their previous assistant sessions. The `messages`
    subcollection stores the actual chat messages. Note that lab session chat messages
    aren‚Äôt stored.
  prefs: []
  type: TYPE_NORMAL
- en: To ensure user confidentiality and privacy, OpenAI request payloads and session
    messages are encrypted before being saved in the database. This data model allows
    users to restart a previous session and continue chatting with the assistant.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: By carefully considering all potential use cases from the beginning, I created
    a data model that is future-proof and able to accommodate the evolving needs and
    features of the app. In the following section, we‚Äôll examine the structure of
    the backend application code to see how it supports and implements this robust
    data model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Code structure: Structuring for scalability and modularity'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I created GPT Lab to empower users with low or no technical skills to build
    their own prompt-based LLM-based AI applications, without having to worry about
    the underlying infrastructure. My goal is to eventually offer backend APIs that
    connect users‚Äô custom front-end apps (whether using Streamlit or not) with their
    AI assistants. This motivated me to design a decoupled architecture that separates
    the front-end Streamlit application from the backend logic.
  prefs: []
  type: TYPE_NORMAL
- en: 'The backend code was structured as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The modules are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**api_util_firebase** handles CRUD operations with the Firestore database.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**api_util_openai** interacts with OpenAI‚Äôs models, provides a unified chat
    model to upstream models, prunes chat messages, and tries to detect and prevent
    prompt injection attacks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**api_util_users**, **api_util_sessions**, and **api_util_bots** are interfaces
    to their corresponding Firestore collections. They interact with api_util_firebase
    and api_util_openai and implement GPT Lab-specific business logic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This design enables separate development, testing, and scaling of different
    parts of the code. It also establishes an easier migration path to convert the
    backend util_collections modules into Google Cloud Functions, which can be exposed
    via API Gateways.
  prefs: []
  type: TYPE_NORMAL
- en: 'Session states: Managing UI and user flow'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As explained in the [first blog article](https://blog.streamlit.io/building-gpt-lab-with-streamlit/#2-developing-advanced-uis-with-ui-functions-rendered-by-session-states),
    I used session state variables to control and manage functionalities on Streamlit
    pages. The following illustrates how these variables are utilized throughout the
    app:'
  prefs: []
  type: TYPE_NORMAL
- en: '*home.py*'
  prefs: []
  type: TYPE_NORMAL
- en: '**user** controls whether to render the OpenAI API key module'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: pages/1_lounge.py
  prefs: []
  type: TYPE_NORMAL
- en: '**user** controls whether to render the OpenAI API key module, enable assistant
    selections, and show the My Assistants tab.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After users choose to interact with an assistant, the assistant details are
    stored in **bot_info**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: pages/2_assistant.py
  prefs: []
  type: TYPE_NORMAL
- en: '**user** controls whether to render the OpenAI API key module.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bot_info**, **session_id**, and **session_ended** determine which screen
    variation to display.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bot_info** does not exist: check to see if assistant_id is in the URL parameter.
    Else, prompt users to search for an assistant.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bot_info** and **session_id** exist, and **session_ended** is false: display
    the chat session screen.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bot_info** and **session_id** exist, and **session_ended** is true: display
    the chat session recap screen.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the chat session, **session_msg_list** stores the conversation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: pages/3_lab.py
  prefs: []
  type: TYPE_NORMAL
- en: '**user** gates whether to render the OpenAI API key module and whether to allow
    users to start creating assistants in the lab.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**lab_active_step** controls which lab session state to render:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If 1: render step 1 UI to set assistant initial prompt and model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If 2: render step 2 UI to test chat with assistant.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If 3: render step 3 UI to finalize assistant details. On create, the bot record
    is created in Firestore DB, and the document ID is saved to lab_bot_id.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If 4 and lab_bot_id is set: render step 4 UI to show assistant creation confirmation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: During the test chat session, **lab_msg_list** stores the test messages. By
    using separate **lab_bot_id** and **bot_info**, I can allow users to jump back
    and forth between lounge/assistant and lab without losing progress in each.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the upfront planning done, the rest of the execution was a lot more manageable.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this post, I covered the upfront planning required for creating GPT Lab,
    including the features, data model, code, and session state. I hope this inspires
    you to build your own ambitious Streamlit apps.
  prefs: []
  type: TYPE_NORMAL
- en: Connect with me on [Twitter](https://twitter.com/dclin) or [Linkedin](https://www.linkedin.com/in/d2clin/).
    I‚Äôd love to hear from you.
  prefs: []
  type: TYPE_NORMAL
- en: Happy Streamlit-ing! üéà
  prefs: []
  type: TYPE_NORMAL
