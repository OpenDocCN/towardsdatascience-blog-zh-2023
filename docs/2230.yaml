- en: 'Expected Calibration Error (ECE): A Step-by-Step Visual Explanation'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/expected-calibration-error-ece-a-step-by-step-visual-explanation-with-python-code-c3e9aa12937d?source=collection_archive---------0-----------------------#2023-07-12](https://towardsdatascience.com/expected-calibration-error-ece-a-step-by-step-visual-explanation-with-python-code-c3e9aa12937d?source=collection_archive---------0-----------------------#2023-07-12)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: With a simple example and Python code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@majapavlo?source=post_page-----c3e9aa12937d--------------------------------)[![Maja
    Pavlovic](../Images/a3b8a94c236519bc86c5c6319db5bc66.png)](https://medium.com/@majapavlo?source=post_page-----c3e9aa12937d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c3e9aa12937d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c3e9aa12937d--------------------------------)
    [Maja Pavlovic](https://medium.com/@majapavlo?source=post_page-----c3e9aa12937d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9b1766e00cb4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexpected-calibration-error-ece-a-step-by-step-visual-explanation-with-python-code-c3e9aa12937d&user=Maja+Pavlovic&userId=9b1766e00cb4&source=post_page-9b1766e00cb4----c3e9aa12937d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c3e9aa12937d--------------------------------)
    ·8 min read·Jul 12, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc3e9aa12937d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexpected-calibration-error-ece-a-step-by-step-visual-explanation-with-python-code-c3e9aa12937d&user=Maja+Pavlovic&userId=9b1766e00cb4&source=-----c3e9aa12937d---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc3e9aa12937d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexpected-calibration-error-ece-a-step-by-step-visual-explanation-with-python-code-c3e9aa12937d&source=-----c3e9aa12937d---------------------bookmark_footer-----------)![](../Images/94b66e02fd61acdc004df7270bcd8aee.png)'
  prefs: []
  type: TYPE_NORMAL
- en: image by author
  prefs: []
  type: TYPE_NORMAL
- en: In classification tasks machine learning models output **estimated probabilities
    or *also called confidences*** *(see image above)*. These tell us how certain
    a model is in its label predictions. However, for most models these confidences
    are not aligned with the true frequencies of the events that it is predicting.
    They need to be ***calibrated***!
  prefs: []
  type: TYPE_NORMAL
- en: '**Model calibration** aims to align the predictions of a model with the true
    probabilities and thereby making sure that the predictions of a model are ***reliable
    and accurate*** *(see this* [*blog post*](https://www.unofficialgoogledatascience.com/2021/04/why-model-calibration-matters-and-how.html)
    *for more details on the importance of model calibration)*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Alright, so model calibration is important, but how do we measure it? There
    are a few options, but the **purpose and focus** of this article is to explain
    and run through only one ***simple*** *yet relatively sufficient* ***measure***
    for assessing model calibration: the **Expected Calibration Error (ECE)**. It
    calculates the weighted average error of the estimated “probabilities” thus resulting
    in a single value that we can use to compare different models.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will run through the ECE-formula as described in the paper: [*On Calibration
    of Modern Neural Networks*](https://arxiv.org/pdf/1706.04599.pdf)*.* To make it
    simple we will look at a small example with 9 data-points and binary targets.
    We will then also **code** up this simple example in **Python**, and lastly, showcase
    the code on a multi-class classification example.'
  prefs: []
  type: TYPE_NORMAL
- en: Definition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'ECE measures how well a model’s estimated “probabilities” match the true (observed)
    probabilities by taking a weighted average over the absolute difference between
    accuracy *(acc)* and confidence *(conf)*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e9326052edfb47643fca00c269856e9c.png)'
  prefs: []
  type: TYPE_IMG
- en: The measure involves splitting the data into M equally spaced bins*.* ***B***
    is used for representing “bins” and ***m*** for the bin number. We’ll get back
    to the individual parts of this formula such as ***B***, ***|Bₘ|***, ***acc(Bₘ)***
    and ***conf(Bₘ)*** in more detail later. Let’s first look at our example which
    will help make the formula easier to digest step-by-step.
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have 9 samples with estimated probabilities or also called ‘confidences’
    ***(pᵢ)*** for predicting either 0 or 1\. If the probability ***pᵢ*** for label
    0 is above 0.5, then the predicted label will be 0\. If it is below 0.5, then
    the probability will be higher for label 1 and thereby the predicted label will
    be 1 (see table below). The final column shows the true label of a sample ***i***.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/57158db74a0635c0bee6f63df4cba747.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Table 1** | image by author'
  prefs: []
  type: TYPE_NORMAL
- en: From the table above we can see that we have 9 samples, ***n=9***. To determine
    any of the rest in the formula we will first need to split our samples into bins.
  prefs: []
  type: TYPE_NORMAL
- en: 'Only the probabilities, which determine the predicted label are used in calculating
    ECE. Therefore, we will only bin samples based upon the maximum probability across
    labels (see table 2). To keep the example simple we split the data into 5 **equally
    spaced** bins ***M=5*** (see binning plot 1 on the right)***.*** Let’s assign
    each bin a colour:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/095e3d1be665f7a853279e007eb940af.png)'
  prefs: []
  type: TYPE_IMG
- en: Now if we look at each sample’s maximum estimated probability, we can group
    it into one of the 5 bins. Sample ***i=1*** has an estimated probability of ***0.78***
    this is higher than 0.6 but lower than 0.8, which means we group it into ***B₄***,
    see image below.Now let’s look at sample ***i=3,*** which has an estimate of ***0.92***.
    This falls between 0.8 and 1, so into bin ***B₅.*** We repeat this for every sample
    ***i*** and end up with a categorisation as in table 2 (see below).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9fc061194b4ab16a908a231631fd12e8.png)![](../Images/0c1a9fc914b68cbf714ee1e88e245078.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Table 2 & Binning Plot 1** | image by author'
  prefs: []
  type: TYPE_NORMAL
- en: '***B₁*** and ***B₂*** don’t contain any samples *(due to the nature of the
    binary example max. probabilities will always be ≥ 0.5 in the binary case)****.
    B₃*** contains ***2*** samples. ***4*** samples end up falling into bin ***B₄***
    and ***3*** end up in ***B₅***. This already gives us some information to start
    filling in the ECE formula from above. Specifically, we can calculate the empirical
    probability of a sample falling into bin ***m*** : ***|Bₘ|*/*n*** (see red highlight
    below).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1521c47a0b4a2265f60c95eb6be767ca.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We know that ***n*** equals ***9*** and from the binning process above we also
    know the size of each bin: ***|Bₘ|*** *(the size of a set S is written as |S|
    — for the values, see numbers above)*. If we split out the formula colour-coded
    for each bin, this gives us the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/931b7119c208e1b1787ceb13adbe51e0.png)'
  prefs: []
  type: TYPE_IMG
- en: For B₁ and B₂ we have 0 samples (|B***₁***|=|B***₂***|=0), so these bins end
    up being equal to 0.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the binning done above we can now also determine ***conf(Bₘ)***, which
    represents the average estimated probabilities in bin ***m***, defined as follows
    in the paper:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e6bffe6deb5ef79a4f6419917160b058.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To calculate ***conf(Bₘ)*** we take the sum of the maximum estimated probabilities
    ***p̂ᵢ*** for each bin ***m*** in table 2 and then divide it by the size of the
    bin **|*Bₘ*|**, see below on the right:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b6d86d8d6b8df198ac6defa8dca0ee31.png)![](../Images/874c95a862f950f2af34b6d224f1f186.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Table 3 & Calculations** | image by author'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can then update the ECE calculation with these values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6c3929e93e5fd4ad359142e2b8791bb1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And now we are only left with filling in ***acc(Bₘ)***, whichrepresents the
    ***accuracy*** per bin ***m***, defined as follows in the paper:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/070098521fbe859e7aae1c1ce2dad61a.png)'
  prefs: []
  type: TYPE_IMG
- en: '**1** is an [*indicator function*](https://www.statlect.com/fundamentals-of-probability/indicator-functions#:~:text=The%20indicator%20function%20of%20an,the%20event%20does%20not%20happen.),
    meaning when the predicted label ***ŷᵢ*** equals the true label***yᵢ***it evaluates
    to 1, otherwise 0\. This simply means you count the number of correctly predicted
    samples per bin ***m*** and divide it by the size of the bin **|*Bₘ*|.** To do
    this we need to first determine if a sample was correctly predicted or not. Let’s
    use the following colours'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/605c5ae33ca661f6add2eb7415ead4b3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'and apply them to the last 2 columns and we can then colour the samples in
    the plot to the right in the same way:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/382ee862054f5898b1d9a63c0d697ab9.png)![](../Images/1bab28334c4902bf85ea575f103db5f0.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Table 4 & Binning Plot 2** | image by author'
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking at the **right side** of the plot above, we can see that in bin ***B₃***
    we have 2 samples and *1 correct* prediction, meaning that the accuracy for ***B₃***
    is 1/2\. Repeating this for ***B₄*** gives an accuracy of 3/4 as we have 3 correct
    predictions and 4 samples in bin ***B₄***. Lastly, looking at ***B₅*** we have
    3 samples and 2 correct predictions, so we end up with 2/3\. This gives us the
    following accuracy values for each bin:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b2748e91f40c057b46dd5d0f0ddc68f5.png)'
  prefs: []
  type: TYPE_IMG
- en: '**We now have all elements for calculating the ECE:**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/601824f944f93d9e28bb4e8be5c6ec3d.png)'
  prefs: []
  type: TYPE_IMG
- en: In our small example of 9 samples we end up with an ECE of 0.10445\. A perfectly
    calibrated model would have an ECE of 0\. The larger the ECE, the more uncalibrated
    the model.
  prefs: []
  type: TYPE_NORMAL
- en: ECE is a helpful first measure and is widely used for assessing model calibration.
    However, ECE has drawbacks that one should be aware of when using it to measure
    calibration *(see:* [*Measuring Calibration in Deep Learning*](https://openaccess.thecvf.com/content_CVPRW_2019/papers/Uncertainty%20and%20Robustness%20in%20Deep%20Visual%20Learning/Nixon_Measuring_Calibration_in_Deep_Learning_CVPRW_2019_paper.pdf)*).*
  prefs: []
  type: TYPE_NORMAL
- en: Python Code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Numpy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First we will set up the same example from above:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We then define the ECE function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Calling the function on the **binary example** returns the same value as we
    calculated above ***0.10444*** (rounded).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to the binary example, we can now also quickly run through a multi-class
    classification case. Let’s use [*James D. McCaffrey’s*](https://jamesmccaffrey.wordpress.com/2021/01/22/how-to-calculate-expected-calibration-error-for-multi-class-classification/)
    example*.* This gives us 5 target classes and the associated sample confidences.
    We really only need the target indices for our calculation: [0,1,2,3,4] and can,
    with regard to ECE, ignore the label that they correspond to. Looking at sample
    ***i=1***, we can see that we now have 5 estimated probabilities, one associated
    with each class: [0.25,0.2,0.22,0.18,0.15].'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Calling the function on the multi-classexample returns ***0.192*** (*which differs
    from* [*McCaffrey’s*](https://jamesmccaffrey.wordpress.com/2021/01/22/how-to-calculate-expected-calibration-error-for-multi-class-classification/)
    *calculation by* ***0.002*** *due to differences in rounding!*).
  prefs: []
  type: TYPE_NORMAL
- en: Give the ***Google Colab Notebook*** a go and try it out for yourself in numpy
    or PyTorch (see below).
  prefs: []
  type: TYPE_NORMAL
- en: You should now know how to calculate ECE by hand and using numpy :)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[**Link to Google Colab Notebook**](https://colab.research.google.com/github/majapavlo/medium/blob/main/ece_medium.ipynb)*that
    runs through the binary and multi-class classification example in both numpy and
    PyTorch.**Note: The code in this article was adapted from the* [*paper’s*](https://arxiv.org/pdf/1706.04599.pdf)
    *ECE torch class from their* [*GitHub repo*](https://github.com/gpleiss/temperature_scaling)*.*'
  prefs: []
  type: TYPE_NORMAL
