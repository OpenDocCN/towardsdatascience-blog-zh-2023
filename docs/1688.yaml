- en: Customizing your Cloud Based Machine Learning Training Environment — Part 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/customizing-your-cloud-based-machine-learning-training-environment-part-2-b65a6cf91812?source=collection_archive---------8-----------------------#2023-05-21](https://towardsdatascience.com/customizing-your-cloud-based-machine-learning-training-environment-part-2-b65a6cf91812?source=collection_archive---------8-----------------------#2023-05-21)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Additional solutions for increasing your development flexibility
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://chaimrand.medium.com/?source=post_page-----b65a6cf91812--------------------------------)[![Chaim
    Rand](../Images/c52659c389f167ad5d6dc139940e7955.png)](https://chaimrand.medium.com/?source=post_page-----b65a6cf91812--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b65a6cf91812--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b65a6cf91812--------------------------------)
    [Chaim Rand](https://chaimrand.medium.com/?source=post_page-----b65a6cf91812--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9440b37e27fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcustomizing-your-cloud-based-machine-learning-training-environment-part-2-b65a6cf91812&user=Chaim+Rand&userId=9440b37e27fe&source=post_page-9440b37e27fe----b65a6cf91812---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b65a6cf91812--------------------------------)
    ·7 min read·May 21, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb65a6cf91812&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcustomizing-your-cloud-based-machine-learning-training-environment-part-2-b65a6cf91812&user=Chaim+Rand&userId=9440b37e27fe&source=-----b65a6cf91812---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb65a6cf91812&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcustomizing-your-cloud-based-machine-learning-training-environment-part-2-b65a6cf91812&source=-----b65a6cf91812---------------------bookmark_footer-----------)![](../Images/0137657cb93e86e967efbb3c4911403f.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Murilo Gomes](https://unsplash.com/pt-br/@murilog8?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: This is the second part of a two-part post on the topic of customizing your
    cloud-based AI model training environment. In the [first part](https://chaimrand.medium.com/customizing-your-cloud-based-machine-learning-training-environment-part-1-2622e10ed65a),
    a prerequisite for this part, we introduced the conflict that may arise between
    the **desire** to use a pre-built specially-designed training environment and
    the **requirement** that we have the ability to customize the environment to our
    project’s needs. The key to discovering potential opportunities for customization
    is a deep understanding of the end-to-end flow of running a training job in the
    cloud. We described this flow for the managed Amazon SageMaker training service
    while emphasizing the value of analyzing the publicly available underlying source
    code. We then presented the first method for customization — installing pip package
    dependencies at the very beginning of the training session — and demonstrated
    its limitations.
  prefs: []
  type: TYPE_NORMAL
- en: In this post we will present two additional methods. Both methods involve creating
    our own custom Docker image, but they are fundamentally different in their approach.
    The first method uses an official cloud-service provided image and expands it
    according to the project needs. The second takes a user defined (cloud agnostic)
    Docker image and extends it to support training in the cloud. As we will see,
    each has its pros and cons and the best option will highly depend on the details
    of your project.
  prefs: []
  type: TYPE_NORMAL
- en: Extending the Official Cloud Service Docker Image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Creating a fully functional, performance optimal, Docker image for training
    on a cloud-based GPU can be painstaking, requiring navigation of a multitude of
    intertwined HW and SW dependencies. Doing this for a wide variety of training
    use cases and HW platforms is even more difficult. Rather than attempt to do this
    on our own, our first choice will always be to take advantage of the pre-defined
    image created for us by the cloud service provider. If we need to customize this
    image, we will simply create a new Dockerfile that extends the official image
    and adds the required dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: The [AWS Deep Learning Container (DLC) github repository](https://github.com/aws/deep-learning-containers)
    includes [instructions](https://github.com/aws/deep-learning-containers/blob/master/custom_images.md)
    for extending an official AWS DLC. This requires logging in to access the Deep
    Learning Containers image repository in order to pull the image, build the extended
    image, and then upload it to an [Amazon Elastic Container Registry (ECR)](https://aws.amazon.com/ecr/)
    in your account.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code block demonstrates how to extend the official AWS DLC from
    our SageMaker example (in part 1). We show three types of extensions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Linux Package**: We install [Nvidia Nsight Systems](https://developer.nvidia.com/nsight-systems)
    for advanced GPU profiling of our training jobs.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Conda Package**: We install the [S5cmd](https://github.com/peak/s5cmd) conda
    package which we use for [pulling data files from cloud storage](/training-from-cloud-storage-with-s5cmd-5c8fb5c06056).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Pip Package**: We install a specific version of the [opencv-python](https://pypi.org/project/opencv-python/)
    pip package.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'For more details on extending the official AWS DLC, including how to upload
    the resultant image to ECR, see [here](https://sagemaker-examples.readthedocs.io/en/latest/advanced_functionality/pytorch_extending_our_containers/pytorch_extending_our_containers.html).
    The code block below shows how to modify the training job deployment script to
    use the extended image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: A similar option you have for customizing an official image, assuming you have
    access to its corresponding Dockerfile, is to simply make the desired edits to
    the Dockerfile and build from scratch. For AWS DLC, this option is documented
    [here](https://github.com/aws/deep-learning-containers#building-your-image). However,
    keep in mind that although based on the same Dockerfile, the resultant image might
    differ due to differences in the build environment and updated package versions.
  prefs: []
  type: TYPE_NORMAL
- en: Environment customization via extension of an official Docker image is a great
    way to get the most out of the fully functional, fully validated, cloud-optimal
    training environment predefined by the cloud service while still allowing you
    the freedom and flexibility to make the additions and adaptations you require.
    However, this option also has its limitations as we demonstrate via example.
  prefs: []
  type: TYPE_NORMAL
- en: Training in a User Defined Python Environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For a variety of reasons, you may require the ability to train in a user-defined
    Python environment. This could be for the sake of reproducibility, platform independence,
    safety/security/compliance considerations, or some other purpose. One option you
    might consider would be to extend an official Docker image with your custom Python
    environment. That way you could, at the very least, benefit from the platform
    related installations and optimizations from the image. However, this could get
    kind of tricky if your intended use relies on some form of Python based automation.
    For example, in a managed training environment, the Dockerfile *ENTRYPOINT* runs
    a Python script that performs all kinds of actions including downloading the code
    source directory from cloud storage, installing Python dependencies, running the
    user defined training script, and more. This Python script resides in the predefined
    Python environment of the official Docker image. Programming the automated script
    to start up the training script in a separate Python environment is doable but
    might require some manual code changes in the predefined environment and could
    get very messy. In the next section we will demonstrate a cleaner way of doing
    this.
  prefs: []
  type: TYPE_NORMAL
- en: Bringing Your Own Image (BYO)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The final scenario we consider is one in which you are required to train in
    a specific environment defined by your own Docker image. As before, the drive
    for this could be regulatory, or the desire to run with the same image in the
    cloud as you do locally (“on-prem”). Some cloud services provide the ability to
    bring your own user-defined image and adapt it for use in the cloud. In this section
    we demonstrate two ways in which Amazon SageMaker supports this.
  prefs: []
  type: TYPE_NORMAL
- en: 'BYO Option 1: The SageMaker Training Toolkit'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first option, documented [here](https://docs.aws.amazon.com/sagemaker/latest/dg/docker-containers-adapt-your-own.html),
    allows you to add the specialized (managed) training start-up flow we described
    in [part 1](https://chaimrand.medium.com/2622e10ed65a) into you custom Python
    environment. This essentially enables you to train in SageMaker using your custom
    image in the same manner in which you would use an official image. In particular,
    you can re-use the same image for multiple projects/experiments and rely on the
    SageMaker APIs to download the experiment-specific code into the training environment
    at start-up (as described in [part 1](https://chaimrand.medium.com/2622e10ed65a)).
    You do not need to create and upload a new image every time you change your training
    code.
  prefs: []
  type: TYPE_NORMAL
- en: The code block below demonstrates how to take a custom image and enhance it
    with the [SageMaker training toolkit](https://github.com/aws/sagemaker-training-toolkit)
    following the instructions detailed [here](https://docs.aws.amazon.com/sagemaker/latest/dg/adapt-training-container.html).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'BYO Option 2: Configuring the Entrypoint'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The second option, documented [here](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo-dockerfile.html),
    allows you to train in SageMaker in a user-defined Docker environment with **zero**
    changes to the Docker image. All that is required is to explicitly set the *ENTRYPOINT*
    instruction of the Docker container. One of the ways to do this (as documented
    [here](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo-dockerfile.html#your-algorithms-training-algo-dockerfile-api-pass-ep))
    is to pass in *ContainerEntrypoint* and/or *ContainerArguments* parameters to
    the [*AlgorithmSpecification*](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_AlgorithmSpecification.html)of
    the API request. Unfortunately, as of the time of this writing, this option is
    not supported by the [SageMaker Python API](https://pypi.org/project/sagemaker/)
    (version 2.146.1). However, we can easily enable this by extending the [SageMaker
    Session class](https://sagemaker.readthedocs.io/en/stable/api/utility/session.html#sagemaker.session.Session)
    as demonstrated in the code block below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Optimizing Your Docker Image
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the disadvantages of the BYO option is that you lose the opportunity
    to benefit from the specialization of the official pre-defined image. You can
    manually and selectively reintroduce some of these into your custom image. For
    example, the SageMaker documentation includes [detailed instructions](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-efa.html)
    for integrating support for [Amazon EFA](https://aws.amazon.com/hpc/efa/). Moreover,
    you always have the option of looking back at the publicly available [Dockerfile](https://github.com/aws/deep-learning-containers/blob/master/pytorch/training/docker/1.13/py3/cu117/Dockerfile.gpu)
    to cherry pick what you want.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this two-part post we have discussed different methods for customizing your
    cloud-based training environment. The methods we chose were intended to demonstrate
    ways of addressing different types of use cases. In practice, the best solution
    will directly depend on your project needs. You might decide to create a single
    custom Docker image for all of your training experiments and combine this with
    an option to install experiment-specific dependencies (using the first method).
    You might find that a different method, not discussed here, e.g., one that involves
    tweaking some portion of the [sagemaker-training](https://pypi.org/project/sagemaker-training/)
    Python package, to better suit your needs. The bottom line is that when you are
    faced with a need to customize your training environment — you have options; and
    if the standard options we have covered do not suffice, do not despair, get creative!
  prefs: []
  type: TYPE_NORMAL
