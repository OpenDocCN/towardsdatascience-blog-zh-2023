- en: The Decontaminated Evaluation of GPT-4
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPT-4 的去污染评估
- en: 原文：[https://towardsdatascience.com/the-decontaminated-evaluation-of-gpt-4-38a27fc45c30?source=collection_archive---------4-----------------------#2023-03-27](https://towardsdatascience.com/the-decontaminated-evaluation-of-gpt-4-38a27fc45c30?source=collection_archive---------4-----------------------#2023-03-27)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-decontaminated-evaluation-of-gpt-4-38a27fc45c30?source=collection_archive---------4-----------------------#2023-03-27](https://towardsdatascience.com/the-decontaminated-evaluation-of-gpt-4-38a27fc45c30?source=collection_archive---------4-----------------------#2023-03-27)
- en: GPT-4 won’t be your lawyer anytime soon
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPT-4 不会很快成为你的律师
- en: '[](https://medium.com/@bnjmn_marie?source=post_page-----38a27fc45c30--------------------------------)[![Benjamin
    Marie](../Images/3ea1ad230cb1e67610418a8e36a5e5dd.png)](https://medium.com/@bnjmn_marie?source=post_page-----38a27fc45c30--------------------------------)[](https://towardsdatascience.com/?source=post_page-----38a27fc45c30--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----38a27fc45c30--------------------------------)
    [Benjamin Marie](https://medium.com/@bnjmn_marie?source=post_page-----38a27fc45c30--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@bnjmn_marie?source=post_page-----38a27fc45c30--------------------------------)[![本杰明·玛丽](../Images/3ea1ad230cb1e67610418a8e36a5e5dd.png)](https://medium.com/@bnjmn_marie?source=post_page-----38a27fc45c30--------------------------------)[](https://towardsdatascience.com/?source=post_page-----38a27fc45c30--------------------------------)[![数据科学前沿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----38a27fc45c30--------------------------------)
    [本杰明·玛丽](https://medium.com/@bnjmn_marie?source=post_page-----38a27fc45c30--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fad2a414578b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-decontaminated-evaluation-of-gpt-4-38a27fc45c30&user=Benjamin+Marie&userId=ad2a414578b3&source=post_page-ad2a414578b3----38a27fc45c30---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----38a27fc45c30--------------------------------)
    ·7 min read·Mar 27, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F38a27fc45c30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-decontaminated-evaluation-of-gpt-4-38a27fc45c30&user=Benjamin+Marie&userId=ad2a414578b3&source=-----38a27fc45c30---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fad2a414578b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-decontaminated-evaluation-of-gpt-4-38a27fc45c30&user=Benjamin+Marie&userId=ad2a414578b3&source=post_page-ad2a414578b3----38a27fc45c30---------------------post_header-----------)
    发表在 [数据科学前沿](https://towardsdatascience.com/?source=post_page-----38a27fc45c30--------------------------------)
    ·7 分钟阅读·2023年3月27日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F38a27fc45c30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-decontaminated-evaluation-of-gpt-4-38a27fc45c30&user=Benjamin+Marie&userId=ad2a414578b3&source=-----38a27fc45c30---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F38a27fc45c30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-decontaminated-evaluation-of-gpt-4-38a27fc45c30&source=-----38a27fc45c30---------------------bookmark_footer-----------)![](../Images/d402e6d2653cbbb19e0b8a91f3899e1c.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F38a27fc45c30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-decontaminated-evaluation-of-gpt-4-38a27fc45c30&source=-----38a27fc45c30---------------------bookmark_footer-----------)![](../Images/d402e6d2653cbbb19e0b8a91f3899e1c.png)'
- en: Image from [Pixabay](https://pixabay.com/vectors/monster-alien-chasing-hunting-149013/)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Pixabay](https://pixabay.com/vectors/monster-alien-chasing-hunting-149013/)
- en: GPT-4 was announced by OpenAI in March with impressive demonstrations and outstanding
    claims.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4 在三月由 OpenAI 宣布，伴随令人印象深刻的展示和突出的声明。
- en: Most of these claims come from their own evaluation of GPT-4.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这些声明大多数来自他们对 GPT-4 的自我评估。
- en: OpenAI used many existing professional and academic exams for this evaluation.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 使用了许多现有的专业和学术考试进行评估。
- en: '**But evaluating large language models on public benchmarks is extremely challenging.**'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**但在公共基准测试中评估大型语言模型是极具挑战性的。**'
- en: Models such as GPT-4 are exposed to “data contamination”, i.e., **they may have
    been trained on their evaluation data.**
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 像 GPT-4 这样的模型可能会受到“数据污染”，即**它们可能在评估数据上进行了训练。**
- en: '*Why is this a problem?*'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*为什么这是个问题？*'
- en: Let’s take an example.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们举个例子。
- en: GPT-4 was evaluated on the LSAT exam. To perform a scientifically credible evaluation,
    OpenAI had to check whether the LSAT questions used for evaluation were not in
    the training data of GPT-4\. If they were, GPT-4 could have memorized the questions
    and then would obviously perform better on these specific questions at evaluation
    time.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4在LSAT考试中进行了评估。为了进行科学可信的评估，OpenAI必须检查用于评估的LSAT问题是否不在GPT-4的训练数据中。如果在其中，GPT-4可能已经记住了这些问题，那么在评估时显然会在这些特定问题上表现更好。
- en: It’s like a human who had access to the exam questions before it happened.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 就像一个在考试前已经知道考试题目的人。
- en: '**You can say it’s like cheating.**'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**你可以说这就像是作弊。**'
- en: In the [GPT-4 technical report](https://cdn.openai.com/papers/gpt-4.pdf), one
    of the few things OpenAI disclosed about GPT-4 is the data contamination of their
    evaluation. They exposed their strategy to quantify and assess this contamination
    and drew several conclusions from their observations.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在[GPT-4技术报告](https://cdn.openai.com/papers/gpt-4.pdf)中，OpenAI透露了关于GPT-4的少数几件事，其中之一是他们评估中的数据污染。他们公开了量化和评估这种污染的策略，并从观察中得出了几个结论。
- en: In this article, I review and discuss how OpenAI dealt with the data contamination
    of GPT-4\. I expose several pitfalls in their method.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我回顾和讨论了OpenAI如何处理GPT-4的数据污染。我揭示了他们方法中的几个陷阱。
- en: I can’t agree with several of their conclusions.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我无法同意他们的几个结论。
- en: Decontamination of the evaluation data
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估数据的去污染
- en: To check whether there is an intersection between the training and evaluation
    data, OpenAI used a very simple technique relying on a substring matching algorithm
    (described page 28 of the technical report).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查训练数据和评估数据之间是否存在交集，OpenAI使用了一种依赖于子字符串匹配算法的非常简单的技术（在技术报告第28页描述）。
- en: First, they removed all spaces and symbols in the training and evaluation data
    (the exams). They kept the numbers.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，他们删除了训练数据和评估数据（考试）中的所有空格和符号。他们保留了数字。
- en: Then, they **randomly** picked 3 substrings of 50 characters for each question
    (or equivalent) in the exams used for evaluation. If one of these substrings happened
    to be in the training data of GPT-4, the question is removed from the **evaluation
    data**.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，他们**随机**挑选了考试中每个问题的3个50字符的子字符串（或等效的）。如果这些子字符串中的任何一个恰好出现在GPT-4的训练数据中，则该问题会从**评估数据**中删除。
- en: With this method, they made two critical choices.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法，他们做出了两个关键选择。
- en: The first one is that this method is random.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，这种方法是随机的。
- en: Choosing 3 random substrings is particularly problematic for exams with very
    long questions.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 对于问题非常长的考试来说，选择3个随机子字符串尤其具有问题。
- en: 'For instance, one question in the Uniform Bar Exam may contain 1,500 sequences
    of 50 characters. *Note: They are very long questions,* [*see some examples*](https://www.ncbex.org/pdfviewer/?file=%2Fdmsdocument%2F310)*.*'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，统一律师资格考试中的一个问题可能包含1,500个50字符的序列。*注意：它们是非常长的问题，* [*查看一些示例*](https://www.ncbex.org/pdfviewer/?file=%2Fdmsdocument%2F310)*。*
- en: Randomly choosing 3 substrings among 1,500 means that a large part of each question
    is completely ignored by this decontamination strategy.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在1,500个子字符串中随机选择3个，这意味着该去污染策略完全忽略了每个问题的大部分内容。
- en: This strategy can’t reliably detect whether a large part of a question is in
    the training data.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这种策略无法可靠地检测出问题的大部分是否存在于训练数据中。
- en: We can imagine that some of these exam questions have been studied or discussed
    in the GPT-4 training data, but partly and not entirely since they are very long
    questions. So a partial but significant match wouldn’t be detected in that case.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以想象这些考试问题中的一些可能已经在GPT-4训练数据中被研究或讨论过，但只是部分而非全部，因为它们是非常长的问题。因此，在这种情况下，部分但重要的匹配将不会被检测到。
- en: The uniform bar exam has 400 questions. But by randomly checking 3 substrings
    for each question, OpenAI did not find any of these questions in the training
    data.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 统一律师资格考试有400道题目。但是通过随机检查每个问题的3个子字符串，OpenAI并未发现这些问题出现在训练数据中。
- en: The second critical choice is that they decontaminated the evaluation data and
    not the training data.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个关键选择是他们去污染了评估数据，而不是训练数据。
- en: Removing questions from the training data, retraining GPT-4, and then evaluating
    it on the exams again would have been too costly, obviously.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 从训练数据中删除问题，重新训练GPT-4，然后再在考试中评估它显然会花费过高。
- en: However, if they had assessed this contamination earlier in their development
    process, i.e., before training, they could have removed all the exam examples
    from the training data.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果他们在开发过程中早些时候评估了这种污染，即在训练之前，他们本可以从训练数据中移除所有的考试示例。
- en: It is also important to note that they didn’t include the data of RLHF in their
    decontamination process. If a question of an exam is in the RLHF, it will remain
    in the evaluation data.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，他们在去污染过程中没有包括RLHF的数据。如果一个考试的问题在RLHF中，它将保留在评估数据中。
- en: '**Definition**'
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**定义**'
- en: ''
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: RLHF stands for Reinforcement Learning from Human Feedback. Once pre-trained,
    GPT-4 is further fine-tuned using reinforcement learning on human feedback to
    improve its performance. This dataset of “feedback” was not checked for the decontamination.
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: RLHF代表来自人类反馈的强化学习。GPT-4在预训练后，通过在人工反馈上进行强化学习进一步微调，以提高其性能。这个“反馈”数据集没有被检查以进行去污染。
- en: The main reason given for not including the RLHF training data is that the fine-tuning
    exploiting RLHF did not significantly improve the performance of GPT-4\. They
    only observed a +0.3% on the average score after RLHF post-training.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 不包括RLHF训练数据的主要原因是利用RLHF进行微调并未显著提高GPT-4的性能。它们仅观察到在RLHF后训练的平均得分提高了+0.3%。
- en: It’s contaminated
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是被污染的
- en: '![](../Images/6ed4c65c02b829ce16c5b95190b01ab7.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6ed4c65c02b829ce16c5b95190b01ab7.png)'
- en: Image from [Pixabay](https://pixabay.com/illustrations/smiley-scared-surprised-fear-shock-1958283/)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 [Pixabay](https://pixabay.com/illustrations/smiley-scared-surprised-fear-shock-1958283/)
- en: The details of the contamination for each exam are given page 30 of the report.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 每个考试的污染细节在报告的第30页中给出。
- en: 'Among the 49 exams used for evaluation, 12 were found completely absent from
    the training data. They are: all the Leetcode datasets, the Uniform Bar Exam,
    SAT EBRW exam, and some AP exams.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在用于评估的49个考试中，发现有12个完全没有出现在训练数据中。它们是：所有Leetcode数据集、Uniform Bar Exam、SAT EBRW考试和一些AP考试。
- en: 'In total, the exams used for evaluation contain 4,123 questions. 545**.5**
    of these questions have been found in the training data. *Note: Why is there a
    “****.5****”? As far as I understand, OpenAI removed the question entirely if
    there is a match. But for the exam “USA Biolympiad Semifinal Exam 2020”, that
    contains 150 questions, they note that they removed 3.00% of the questions (see
    Table 10 of the paper). 3% of 150, that’s 4.5\. One of these numbers is probably
    wrong.*'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，用于评估的考试包含4,123个问题。其中545**.5**个问题已在训练数据中找到。*注意：为什么会有“****.5****”？据我了解，如果有匹配，OpenAI会完全移除该问题。但对于考试“USA
    Biolympiad Semifinal Exam 2020”，包含150个问题，他们指出他们移除了3.00%的问题（见论文的表10）。150的3%是4.5。这些数字中的一个可能是错误的。*
- en: This is 13.2% of the evaluation data that are contaminated.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这是13.2%的评估数据被污染。
- en: Interestingly, for several exams, the decontamination seems to improve the results
    obtained by GPT-4.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，对于几个考试，去污染似乎改善了GPT-4的结果。
- en: This is counter-intuitive.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这与直觉相反。
- en: We may think that if the removed questions were in the training data, GPT-4
    should be good at answering them since it had the opportunity to memorize them.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能认为，如果被移除的问题在训练数据中，GPT-4应该擅长回答它们，因为它有机会记住它们。
- en: But we know nothing of these excluded questions.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们对这些被排除的问题一无所知。
- en: They may be the most difficult ones for some exams, hence the higher percentage
    of correct answers after excluding them from the evaluation.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一些考试来说，它们可能是最困难的，因此在从评估中排除这些问题后正确答案的百分比更高。
- en: 'OpenAI claims that the contamination didn’t have a significant impact. They
    note:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI声称污染没有显著影响。他们指出：
- en: Overall across most exams, both contamination and vision have relatively little
    effect. (Caption of Table 9)
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 总体来看，大多数考试中，污染和视力的影响相对较小。 （表9的标题）
- en: ''
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The degration is generally small and as often postive as negative […] (Caption
    of Table 10)
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 退化通常很小，正面和负面效果一样多 […] （表10的标题）
- en: This is the “overall” conclusion. If we look closer at the results, that’s not
    so obvious. Let’s see some of the details.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这是“总体”结论。如果我们更仔细地查看结果，这并不那么明显。让我们看看一些细节。
- en: 'In Table 10 of the technical report, OpenAI has also evaluated GPT-4 on two
    separate set of questions for each exam:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在技术报告的表10中，OpenAI还在每个考试中对两个独立的问题集合评估了GPT-4：
- en: '“contaminated”: This set contains only the questions found in the training
    data.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “contaminated”：这个集合仅包含在训练数据中找到的问题。
- en: '“non-contaminated”: This set contains all the remaining questions.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “non-contaminated”：这个集合包含了所有剩余的问题。
- en: This is an interesting experiment. The performance of GPT-4 on these two kinds
    of datasets (5th and 6th columns) varies extremely for some exams, for instance
    from 41.67% to 0% for AMC 12.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个有趣的实验。GPT-4 在这两种数据集（第5和第6列）上的表现对某些考试变化极大，例如AMC 12的表现从41.67%到0%。
- en: For some other exams, GPT-4 performed better on the evaluation data it didn’t
    use during training (non-contaminated).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他一些考试，GPT-4 在没有使用的评估数据（未受污染）上的表现更好。
- en: '*Does it mean that GPT-4 is better for questions it did not see during training?*'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '*这是否意味着 GPT-4 在训练期间未见过的问题上表现更好？*'
- en: No, “contaminated” and “non-contaminated” are just two different evaluation
    data.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 不，“受污染”和“未受污染”只是两种不同的评估数据。
- en: GPT-4 may perform better on one of the two datasets for many different reasons,
    for instance, given the topic of the questions, their length, their difficulty,
    etc.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4 可能因多种原因在两个数据集中的表现不同，例如问题的主题、长度、难度等。
- en: Is GPT-4 good at these exams?
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPT-4 对这些考试表现如何？
- en: Let’s have a specific look at the LSAT exam. And let’s say that a score above
    160 is a good score on this exam.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们具体看看 LSAT 考试。假设 160 以上的分数在此考试中是一个好分数。
- en: GPT-4 achieved a score of 163\. After decontamination, removing 39% of the questions,
    GPT-4 achieved an even better score of 167.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4 获得了163的分数。在去污染后，移除39%的问题，GPT-4获得了更高的167分。
- en: '*Can we conclude that GPT-4 can achieve a good score on the LSAT exam?*'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们可以得出结论，GPT-4 能在 LSAT 考试中取得好分数吗？*'
- en: Yes, we can. But only if cheating is allowed.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，我们可以。但前提是允许作弊。
- en: On one hand, we have the full exam on which GPT-4 performs at 163\. It’s a good
    score but GPT-4 saw some of the questions before passing the exam.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一方面，我们有完整的考试，GPT-4 的分数为163。这是一个好分数，但 GPT-4 在考试前见过一些问题。
- en: On the other hand, if we remove 39% of the questions for decontamination, this
    is not an LSAT exam anymore. No human passed a 61% LSAT. This exam doesn’t exist.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果我们移除39%的问题进行去污染，这就不再是 LSAT 考试了。没有人能通过61%的 LSAT。这种考试并不存在。
- en: Moreover, the 39% of questions removed may contain the most difficult questions.
    We don’t know if a score of 167 is good or bad on this 61% LSAT.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，移除的 39% 问题可能包含最难的问题。我们不知道在这61%的LSAT中，167的分数好坏如何。
- en: We can reason similarly for all the other “contaminated” exams used for evaluation.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有其他用于评估的“受污染”考试，我们可以类似地推理。
- en: Some exams were not “contaminated”, such as the Uniform Bar Exam and Leet code
    questions, but there are additional issues.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 一些考试没有“受污染”，例如统一律师资格考试和Leet代码问题，但还有其他问题。
- en: 'I won’t write about these issues here. [Arvind Narayanan](https://substack.com/profile/19265909-arvind-narayanan)
    and [Sayash Kapoor](https://substack.com/profile/891603-sayash-kapoor) already
    discussed the results for these questions in their formidable article that you
    can read here:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会在这里讨论这些问题。[Arvind Narayanan](https://substack.com/profile/19265909-arvind-narayanan)
    和 [Sayash Kapoor](https://substack.com/profile/891603-sayash-kapoor) 已经在他们的权威文章中讨论了这些问题的结果，你可以在这里阅读：
- en: '[](https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks?source=post_page-----38a27fc45c30--------------------------------)
    [## GPT-4 and professional benchmarks: the wrong answer to the wrong question'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks?source=post_page-----38a27fc45c30--------------------------------)
    [## GPT-4 和专业基准：错误的问题的错误答案'
- en: We don't know the answer, but we hope to inject some reality into the conversation.
    OpenAI may have violated the…
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我们不知道答案，但我们希望能将一些现实注入对话中。OpenAI 可能违反了…
- en: aisnakeoil.substack.com](https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks?source=post_page-----38a27fc45c30--------------------------------)
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: aisnakeoil.substack.com](https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks?source=post_page-----38a27fc45c30--------------------------------)
- en: Conclusion
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: As I wrote in the introduction, assessing the data contamination of large language
    models is an extremely difficult task.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我在介绍中写的，评估大型语言模型的数据污染是一个极其困难的任务。
- en: When collecting and preprocessing the training data, ideally we should have
    already identified a list of publicly relevant exams and benchmarks to exclude
    from the training data.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在收集和预处理训练数据时，理想情况下我们应该已经确定了一份需要从训练数据中排除的公共相关考试和基准的清单。
- en: Nonetheless, my opinion is that it actually makes a lot of sense for OpenAI
    to train GPT-4 on all these exams.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我的观点是，OpenAI 训练 GPT-4 时包含所有这些考试实际上是非常有意义的。
- en: The goal is also to have a GPT-4 as good as possible for the questions posed
    by these exams. I can see a lot of potential use cases for GPT-4 in this area,
    such as helping students and teachers to prepare exams.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 目标也是让GPT-4尽可能地适应这些考试提出的问题。我可以看到GPT-4在这个领域的许多潜在应用，比如帮助学生和老师准备考试。
- en: 'Yet, this choice has a cost: **We cannot use these exams to evaluate GPT-4
    with scientific credibility.**'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这个选择是有代价的：**我们不能用这些考试来以科学的可信度评估GPT-4。**
- en: '*If you like this article and would be interested to read the next ones, the
    best way to support my work is to become a Medium member using this link:*'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你喜欢这篇文章并且有兴趣阅读接下来的文章，支持我的工作的最佳方式是通过这个链接成为Medium会员：*'
- en: '[](https://medium.com/@bnjmn_marie/membership?source=post_page-----38a27fc45c30--------------------------------)
    [## Join Medium with my referral link - Benjamin Marie'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@bnjmn_marie/membership?source=post_page-----38a27fc45c30--------------------------------)
    [## 通过我的推荐链接加入Medium - Benjamin Marie'
- en: Read every story from Benjamin Marie (and thousands of other writers on Medium).
    Your membership fee directly supports…
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 阅读Benjamin Marie的每一个故事（以及Medium上的其他成千上万的作家）。你的会员费直接支持…
- en: medium.com](https://medium.com/@bnjmn_marie/membership?source=post_page-----38a27fc45c30--------------------------------)
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@bnjmn_marie/membership?source=post_page-----38a27fc45c30--------------------------------)
- en: '*If you are already a member and want to support this work,* [*just follow
    me on Medium*](https://medium.com/@bnjmn_marie)*.*'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你已经是会员并且想要支持这项工作，* [*只需在Medium上关注我*](https://medium.com/@bnjmn_marie)*。*'
