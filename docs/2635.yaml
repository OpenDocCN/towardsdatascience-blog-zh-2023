- en: Finding data slices in unstructured data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在非结构化数据中找到数据切片
- en: 原文：[https://towardsdatascience.com/finding-data-slices-in-unstructured-data-f36244bb044e?source=collection_archive---------7-----------------------#2023-08-18](https://towardsdatascience.com/finding-data-slices-in-unstructured-data-f36244bb044e?source=collection_archive---------7-----------------------#2023-08-18)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/finding-data-slices-in-unstructured-data-f36244bb044e?source=collection_archive---------7-----------------------#2023-08-18](https://towardsdatascience.com/finding-data-slices-in-unstructured-data-f36244bb044e?source=collection_archive---------7-----------------------#2023-08-18)
- en: A short introduction to data-slicing methods including hands-on examples on
    the CIFAR-100 dataset.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简要介绍了数据切片方法，包括对CIFAR-100数据集的实际操作示例。
- en: '[](https://medium.com/@stefan.suwelack?source=post_page-----f36244bb044e--------------------------------)[![Stefan
    Suwelack](../Images/33b66c9119d47fd668bad7b739586200.png)](https://medium.com/@stefan.suwelack?source=post_page-----f36244bb044e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f36244bb044e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f36244bb044e--------------------------------)
    [Stefan Suwelack](https://medium.com/@stefan.suwelack?source=post_page-----f36244bb044e--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@stefan.suwelack?source=post_page-----f36244bb044e--------------------------------)[![Stefan
    Suwelack](../Images/33b66c9119d47fd668bad7b739586200.png)](https://medium.com/@stefan.suwelack?source=post_page-----f36244bb044e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f36244bb044e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f36244bb044e--------------------------------)
    [Stefan Suwelack](https://medium.com/@stefan.suwelack?source=post_page-----f36244bb044e--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Faa4f0c2a0e38&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffinding-data-slices-in-unstructured-data-f36244bb044e&user=Stefan+Suwelack&userId=aa4f0c2a0e38&source=post_page-aa4f0c2a0e38----f36244bb044e---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f36244bb044e--------------------------------)
    ·9 min read·Aug 18, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff36244bb044e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffinding-data-slices-in-unstructured-data-f36244bb044e&user=Stefan+Suwelack&userId=aa4f0c2a0e38&source=-----f36244bb044e---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Faa4f0c2a0e38&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffinding-data-slices-in-unstructured-data-f36244bb044e&user=Stefan+Suwelack&userId=aa4f0c2a0e38&source=post_page-aa4f0c2a0e38----f36244bb044e---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f36244bb044e--------------------------------)
    ·9 min read·2023年8月18日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff36244bb044e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffinding-data-slices-in-unstructured-data-f36244bb044e&user=Stefan+Suwelack&userId=aa4f0c2a0e38&source=-----f36244bb044e---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff36244bb044e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffinding-data-slices-in-unstructured-data-f36244bb044e&source=-----f36244bb044e---------------------bookmark_footer-----------)![](../Images/6be6049b15d746a07cf5bf5d512a8baa.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff36244bb044e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffinding-data-slices-in-unstructured-data-f36244bb044e&source=-----f36244bb044e---------------------bookmark_footer-----------)![](../Images/6be6049b15d746a07cf5bf5d512a8baa.png)'
- en: 'Data slices on CIFAR100\. Source: created by the author.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: CIFAR100中的数据切片。来源：作者创作。
- en: 'tl;dr:'
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'tl;dr:'
- en: Data slices are semantically meaningful subsets of the data, where the model
    performs anomalously. When dealing with an unstructured data problem (e.g. images,
    text), finding these slices is an important part of every data scientist’s job.
    In practice this task involves a lot of individual experience and manual work.
    In this post, we present some methods and tools to make finding data slices more
    systematic and efficient. We discuss current challenges and demonstrate some hands-on
    example workflows based on open-source tooling.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 数据切片是数据中具有语义意义的子集，在这些子集中，模型的表现异常。当处理非结构化数据问题（例如图像、文本）时，找到这些切片是每个数据科学家的重要工作。在实践中，这项任务涉及大量的个人经验和手工工作。在本文中，我们介绍了一些使数据切片发现更加系统化和高效的方法和工具。我们讨论了当前的挑战，并展示了一些基于开源工具的实际操作示例工作流。
- en: There is an [interactive demo](https://huggingface.co/spaces/renumics/cifar100-sliceguard-demo)
    based on the CIFAR100 dataset available.
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 有一个基于CIFAR100数据集的[互动演示](https://huggingface.co/spaces/renumics/cifar100-sliceguard-demo)可用。
- en: Introduction
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Debugging, testing and monitoring artificial intelligence (AI) systems is hard.
    Most efforts in the [software 2.0](https://karpathy.medium.com/software-2-0-a64152b37c35)
    development process is spent on curating high-quality data sets.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 调试、测试和监控人工智能（AI）系统很困难。大多数[软件2.0](https://karpathy.medium.com/software-2-0-a64152b37c35)开发过程中的工作都花在了策划高质量数据集上。
- en: An important strategy for developing robust machine learning (ML) algorithms
    is to identify so called data slices. Data slices are semantically meaningful
    subsets where the model performs anomalously. Identifying and tracking these data
    segments is at the heart of every data-centric AI development process. It is also
    a core aspect for deploying safe AI solutions in domains such as healthcare and
    automated driver assistance systems.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 开发强大机器学习（ML）算法的一个重要策略是识别所谓的数据切片。数据切片是语义上有意义的子集，其中模型表现异常。识别和跟踪这些数据片段是每个以数据为中心的AI开发过程的核心。它也是在医疗保健和自动驾驶辅助系统等领域部署安全AI解决方案的核心方面。
- en: Traditionally, finding data slices has been an integral part of a data scientist’s
    work. In practice, finding data slices heavily relies on the individual experience
    and domain knowledge of the data scientist. In the wake of the data-centric AI
    movement, there is a lot of current work and tooling that seek to make this process
    more systematic.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，寻找数据切片一直是数据科学家工作的重要组成部分。在实践中，寻找数据切片很大程度上依赖于数据科学家的个人经验和领域知识。随着以数据为中心的人工智能（AI）运动的发展，许多当前的工作和工具旨在使这一过程更加系统化。
- en: In this article, we give an overview over the current state of data slice finding
    on unstructured data. We specifically demonstrate some hands-on example workflows
    based on open-source tooling.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们概述了在非结构化数据上找到数据切片的当前状态。我们特别展示了一些基于开源工具的实际操作示例工作流程。
- en: What is slice finding?
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是切片查找？
- en: Data scientists use simple manual slice finding techniques all the time. The
    most famous example is probably the confusion matrix, a debugging method for classification
    problems. In practice, the slice finding process relies on a combination of pre-computed
    heuristics, the individual experience of the data scientist and a lot of interactive
    data exploration.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家一直在使用简单的手动切片查找技术。最著名的例子可能是混淆矩阵，这是一种用于分类问题的调试方法。在实践中，切片查找过程依赖于预计算的启发式方法、数据科学家的个人经验以及大量的互动数据探索。
- en: A classical data slice can be described by a conjunction of predicates on tabular
    features or metadata. In a people dataset this might be persons in a certain age
    range who are male and above 1.85m tall. In an engine condition monitoring dataset,
    a data slice might consist of data points in a certain RPM, operating hour, and
    torque range.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一个经典的数据切片可以通过对表格特征或元数据的谓词连接来描述。在一个人员数据集中，这可能是某个年龄范围内的男性，身高超过1.85米。在一个发动机状态监测数据集中，一个数据切片可能由某个转速、操作时间和扭矩范围的数据点组成。
- en: 'In the case of unstructured data, the semantic data slice definition can be
    more implicit: It can be a human understandable description such as “*driving
    scenarios in light rain on a curvy road with heavy traffic in the mountains*”.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在非结构化数据的情况下，语义数据切片定义可能更加隐含：它可以是人类可理解的描述，如“*在山区的弯曲道路上，轻微降雨情况下的驾驶场景*”。
- en: 'Identifying data slices on unstructured dataset can be done in two different
    ways:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在非结构化数据集上识别数据切片可以通过两种不同的方式进行：
- en: Metadata can be extracted from the unstructured data either with classical signal
    processing algorithms (e.g. dark images, low SNR audio), or pre-trained deep neural
    networks for auto-tagging. Slice finding can then be done on this metadata.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以使用经典信号处理算法（例如黑暗图像、低信噪比音频）或用于自动标记的预训练深度神经网络从非结构化数据中提取元数据。然后可以在这些元数据上进行切片查找。
- en: Latent representations in the embedding space can be used to group data clusters.
    These clusters can then be inspected to identify relevant data slices directly.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 嵌入空间中的潜在表示可以用于对数据集群进行分组。这些集群可以被检查以直接识别相关的数据切片。
- en: '![](../Images/4b8165e71e6a983fdff9db17166d17b2.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b8165e71e6a983fdff9db17166d17b2.png)'
- en: 'Workflow to identify data slices on unstructured data. Source: created by the
    author.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 识别非结构化数据上的数据切片的工作流程。来源：作者创建。
- en: Automated slice finding techniques always seek to balance the support of the
    slice (should be large) with the severity of the model performance anomaly (should
    also be large).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化切片发现技术总是试图在切片的支持度（应该很大）和模型性能异常的严重性（也应该很大）之间取得平衡。
- en: 'Slice finding methods on tabular data share a lot of similarities with decision
    trees: In the context of ML model analysis, both techniques can be used to formulate
    rules that describe where model errors exist. However, there is one important
    difference: The slice finding problem allows for overlapping slices. This makes
    the problem computationally hard because it is more difficult to prune the search
    space.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 表格数据上的切片发现方法与决策树有很多相似之处：在机器学习模型分析的背景下，这两种技术都可以用来制定描述模型错误存在位置的规则。然而，有一个重要的区别：切片发现问题允许重叠切片。这使得问题在计算上变得困难，因为更难以修剪搜索空间。
- en: Why is data slice finding important?
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么数据切片发现很重要？
- en: 'Especially within the last decade, the machine learning community did benefit
    tremendously from benchmark datasets: Starting with ImageNet, such datasets and
    competitions have been a big success factor for deep learning algorithms on unstructured
    data problems. In this context, the quality of a new algorithm is typically judged
    based on very few quantitative metrics such as F1-score or mean average precision.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是在过去十年中，机器学习社区从基准数据集中受益匪浅：从ImageNet开始，这些数据集和竞赛成为深度学习算法在非结构化数据问题上的成功因素。在这种背景下，新算法的质量通常基于极少的定量指标，如F1分数或平均精度。
- en: 'With more and more ML models being deployed into production, it has become
    apparent that real-world datasets are very different from their benchmark peers:
    Real data is typically very noisy and imbalanced, but also rich in metadata information.
    For some use cases, cleaning and annotating these datasets can be prohibitively
    expensive.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 随着越来越多的机器学习模型投入生产，现实世界的数据集与其基准数据集的差异变得显而易见：真实数据通常非常嘈杂和不平衡，但也富含元数据。对于某些用例，清理和标注这些数据集可能代价高昂。
- en: Many teams have found that iterating the training dataset and monitoring drift
    in production is necessary to build and maintain safe AI systems.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 许多团队发现，迭代训练数据集并监控生产中的漂移对于构建和维护安全的AI系统是必要的。
- en: 'Finding data slices is a core part of this iteration process. Only by knowing
    where the model fails, it becomes possible to improve the system performance:
    By collecting more data, by correcting false labels, by selecting the best features
    or by simply restricting the operation domain of the system.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 发现数据切片是这一迭代过程的核心部分。只有了解模型的失败点，才能提升系统性能：通过收集更多数据、纠正错误标签、选择最佳特征或简单地限制系统的操作领域。
- en: Why is data slice finding so difficult?
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么数据切片发现如此困难？
- en: 'A critical aspect of slice finding is its computational complexity. We can
    illustrate this with a small example: Consider n binary features with one-hot
    encoding (can be obtained by binning or recoding, for example). Then the search
    space of all possible feature combination is O(2^n). This exponential nature means
    that heuristics are typically used for pruning. Consequently, automated slice
    finding not only takes quite long (depending on the number of features), but the
    output will not be an optimal stable solution, but some heuristics.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 切片发现的一个关键方面是其计算复杂性。我们可以通过一个小例子来说明这一点：考虑n个二进制特征，采用独热编码（例如，通过分箱或重新编码获得）。那么所有可能特征组合的搜索空间是O(2^n)。这种指数性质意味着通常使用启发式方法来进行修剪。因此，自动化切片发现不仅需要很长时间（取决于特征数量），而且输出不会是一个最优稳定的解决方案，而是一些启发式方法。
- en: During the AI development process, poor model performance often stems from different
    root causes. Given the inherent stochastic nature of ML models, this can easily
    lead to spurious findings that have to be manually inspected and verified. Thus,
    even if a slice finding technique can produce a theoretically optimal result,
    it’s results must be manually inspected and verified. Building tools that allow
    cross-functional teams to this efficiently is a bottleneck for many ML teams.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在AI开发过程中，模型性能差常常源于不同的根本原因。鉴于机器学习模型的固有随机性，这很容易导致需要手动检查和验证的虚假发现。因此，即使一个切片发现技术可以产生理论上最优的结果，其结果仍必须经过人工检查和验证。为跨职能团队提供高效工具是许多机器学习团队的瓶颈。
- en: We already stated that it is typically desirable to find slices with a large
    support, but also a distinct gap in model performance from the dataset baseline.
    Often, the relationships between different data slices are hierarchical in nature.
    Handling these hierarchies both during the automated slice finding process and
    during the interactive review phase is quite challenging.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经指出，通常希望找到具有大支持的切片，但也希望从数据集基线中获得显著的模型性能差距。不同数据切片之间的关系通常是层次性的。在自动切片查找过程中和互动审查阶段处理这些层次结构是相当具有挑战性的。
- en: Automated slice finding methods are most effective on metadata-rich problems.
    This is often the case for real-world problems. In contrast, Benchmark datasets
    are always quite sparse in metadata. Two primary reasons for this are data protection
    and anonymization requirements. With the lack of suitable example datasets, it
    is very difficult both to develop and to demonstrate effective slice finding workflows.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 自动切片查找方法在元数据丰富的问题上最为有效。这通常是实际问题的情况。相比之下，基准数据集在元数据方面总是相当稀疏。这主要有两个原因：数据保护和匿名化要求。由于缺乏合适的示例数据集，开发和展示有效的切片查找工作流变得非常困难。
- en: We (unfortunately) must deal with this challenge in the following example section.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们（不幸地）必须在接下来的示例部分中处理这一挑战。
- en: 'Hands-on: Finding data slices on CIFAR-100'
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实践操作：在 CIFAR-100 上查找数据切片
- en: The CIFAR-100 dataset is an established computer vision benchmark. We use it
    for this tutorial as its small size makes it easy to handle and keeps computational
    requirements low. The results are also easy to understand as they don’t require
    special domain knowledge.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: CIFAR-100 数据集是一个成熟的计算机视觉基准。我们在本教程中使用它，因为它的体积小，易于处理，并且计算需求低。结果也易于理解，因为它们不需要特殊的领域知识。
- en: Unfortunately, CIFAR-100 is already perfectly balanced, highly curated and lacks
    meaningful metadata. The results of the slice finding workflows we produce in
    this section are thus not as meaningful as in a real-world setting. However, the
    presented workflows should be sufficient to understand how to quickly use them
    on your real-world data.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，CIFAR-100 已经非常平衡，经过高度整理且缺乏有意义的元数据。因此，我们在本节中生成的切片查找工作流的结果不如在实际环境中有意义。然而，所呈现的工作流应足以理解如何快速在实际数据中使用它们。
- en: In a preparation step we compute image metadata with the [Cleanvision](https://github.com/cleanlab/cleanvision)
    library. More information on this enrichment can be found in our [data-centric
    AI playbook](https://renumics.com/docs/playbook/cv-issues).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备步骤中，我们使用 [Cleanvision](https://github.com/cleanlab/cleanvision) 库计算图像元数据。有关此增强的更多信息，请参阅我们的
    [数据驱动 AI 操作手册](https://renumics.com/docs/playbook/cv-issues)。
- en: 'We also define some important variables for our data slice analysis: The features
    to be analyzed as well as the names of the label and prediction columns:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还定义了一些重要的变量用于数据切片分析：待分析的特征以及标签和预测列的名称：
- en: 'Most slicing techniques only work on binned features. As the SliceLine and
    WisePizza libraries do not provide binning functionality themselves, we perform
    this as a pre-processing step:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数切片技术仅适用于分箱特征。由于 SliceLine 和 WisePizza 库本身不提供分箱功能，我们将其作为预处理步骤：
- en: SliceLine
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SliceLine
- en: The [Sliceline algorithm](https://mboehm7.github.io/resources/sigmod2021b_sliceline.pdf)
    was proposed by Sagadeeva et al- in 2021\. It is intended to work with large tabular
    datasets that contain many features. It leverages a novel pruning technique based
    on sparse linear algebra techniques and allows to find data slices quickly even
    on a single machine.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sliceline 算法](https://mboehm7.github.io/resources/sigmod2021b_sliceline.pdf)
    是由 Sagadeeva 等人于 2021 年提出的。它旨在处理包含许多特征的大型表格数据集。它利用基于稀疏线性代数技术的新型剪枝技术，并允许在单台机器上快速查找数据切片。'
- en: In this tutorial, we use the [SliceLine implementation](https://github.com/DataDome/sliceline)
    from the DataDome team. It runs very stable, but currently only supports Python
    versions <=3.9.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们使用 [SliceLine 实现](https://github.com/DataDome/sliceline) 来自 DataDome
    团队。它运行非常稳定，但目前仅支持 Python 版本 <=3.9。
- en: 'Most parameters of the SliceLine algorithm are very straight forward: The minimal
    support of the slice (*min_sup*), the maximum number of predicates to define a
    slice (*max_l*) and the maximum number of slices to be returned (*k*). The parameter
    *alpha* assigns a weight to the importance of the slice error and essential controls
    the trade-off between the size and the error drop-off of the slice.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: SliceLine 算法的大多数参数非常简单：切片的最小支持度 (*min_sup*)、定义切片的最大谓词数 (*max_l*) 和要返回的切片的最大数量
    (*k*)。参数 *alpha* 为切片错误的重要性分配权重，并且基本控制切片大小与错误降低之间的权衡。
- en: 'We call the SliceLine library to get the 20 most interesting slices:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们调用 SliceLine 库以获取 20 个最有趣的切片：
- en: 'To interactively explore the slices, we enrich the description of each data
    slice:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了交互式探索切片，我们丰富了每个数据切片的描述：
- en: We start Spotlight to explore the data slices interactively. You can directly
    experience the results in the [Huggingface space](https://huggingface.co/spaces/renumics/cifar100-sliceline-demo).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们启动 Spotlight 以交互式探索数据切片。你可以直接在 [Huggingface 空间](https://huggingface.co/spaces/renumics/cifar100-sliceline-demo)
    体验结果。
- en: '![](../Images/b19e40e350f9a75c6e45b5ed4884a198.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b19e40e350f9a75c6e45b5ed4884a198.png)'
- en: 'Fig. 3: Interactively exploring data slices generated by SliceLine. An [interactive
    demo](https://huggingface.co/spaces/renumics/cifar100-sliceline-demo) is available
    on Huggingface. Source: created by the author.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：通过 SliceLine 生成的数据切片进行交互式探索。一个 [互动演示](https://huggingface.co/spaces/renumics/cifar100-sliceline-demo)
    在 Huggingface 上可以使用。来源：作者创建。
- en: We see that the Sliceline algorithm did find some meaningful data slices in
    the CIFAR-100 dataset. The classes *maple tree*, *willow tree* and *oak tree*
    seem to be problematic. We also find that data points in these classes that have
    a high *dark score* are particularly challenging. Upon closer inspection we identify
    that this is because trees with a bright background are difficult for the model.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现 Sliceline 算法确实在 CIFAR-100 数据集中找到了有意义的数据切片。*枫树*、*柳树* 和 *橡树* 类别似乎存在问题。我们还发现，这些类别中具有较高
    *暗色评分* 的数据点尤其具有挑战性。经过仔细检查，我们发现这是因为背景明亮的树木对模型来说很困难。
- en: Wise Pizza
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Wise Pizza
- en: '[WisePizza](https://github.com/transferwise/wise-pizza) is a recent development
    by the team from Wise. It is aimed at finding and visualizing interesting data
    slices in tabular data. The core idea is to use Lasso regression to find importance
    coefficients for each slice. More information on how Wise Pizza works can be found
    in the [blog post](/figuring-out-the-most-unusual-segments-in-data-af5fbeacb2b2).'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[WisePizza](https://github.com/transferwise/wise-pizza) 是 Wise 团队最近开发的工具。它旨在发现和可视化表格数据中的有趣数据切片。核心思想是使用
    Lasso 回归为每个切片找到重要性系数。有关 Wise Pizza 工作原理的更多信息，请参阅 [博客文章](/figuring-out-the-most-unusual-segments-in-data-af5fbeacb2b2)。'
- en: 'It is important to note that WisePizza was not developed as a ML debugging
    tool. Instead, it is primarily aimed at supporting segment analysis during EDA.
    That is why it is possible to manually define segment candidates and assign a
    weight to them. In our experiments, we run WisePizza directly on the dataset and
    set the weight for each data point to 1:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，WisePizza 并不是作为机器学习调试工具开发的。相反，它主要旨在支持 EDA 过程中的分段分析。这就是为什么可以手动定义段候选项并为其分配权重。在我们的实验中，我们直接在数据集上运行
    WisePizza，并将每个数据点的权重设置为 1：
- en: To explore the issues in our unstructured data set, we extract issues in the
    same way as in the Sliceline example.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了探索我们非结构化数据集中的问题，我们以与 Sliceline 示例相同的方式提取问题。
- en: '![](../Images/f21a4cb9282ba3e0536421a599bd9d54.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f21a4cb9282ba3e0536421a599bd9d54.png)'
- en: 'Fig. 4: WisePizza also identifies the willow tree class with large dark scores
    as problematic. However, the slices are not as fine-granular as the SliceLine
    results. Source: created by the author.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：WisePizza 还识别出柳树类别具有较大暗色评分的问题。然而，这些切片的细粒度不如 SliceLine 结果。来源：作者创建。
- en: 'From Fig.4 wee see that on the simple CIFAR-100 benchmark dataset, WisePizza
    finds relevant segments: It also lists the *willow tree* class with a high *dark
    score* as the top slice. However, the following results are limited to different
    class categories and are not as fine-granular as the SliceLine output. One reason
    is that the WisePizza algorithm does not directly provide a weighting mechanism
    between the support of the slice and the accuracy drop.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 从图 4 中我们可以看到，在简单的 CIFAR-100 基准数据集上，WisePizza 找到了相关的片段：它还列出了带有高 *dark score*
    的 *willow tree* 类作为顶部切片。然而，以下结果仅限于不同的类别，并且不像 SliceLine 输出那样细粒度。一个原因是 WisePizza
    算法没有直接提供切片支持和准确性下降之间的加权机制。
- en: Sliceguard
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Sliceguard
- en: The [Sliceguard](https://github.com/Renumics/sliceguard) library uses [hierarchical
    clustering](https://arxiv.org/abs/2203.12997) to determine possible data slices.
    Then, methods from fair learning are used to rank these clusters and predicates
    are mined through explainable AI techniques. More information on Sliceguard can
    be found in [this blog post](https://medium.com/@daniel-klitzke/fast-audio-machine-learning-model-debugging-using-embedding-space-clustering-1fc1ca232592).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sliceguard](https://github.com/Renumics/sliceguard) 库使用 [层次聚类](https://arxiv.org/abs/2203.12997)
    来确定可能的数据切片。然后，使用公平学习的方法对这些聚类进行排序，并通过可解释 AI 技术挖掘谓词。有关 Sliceguard 的更多信息可以在 [这篇博客文章](https://medium.com/@daniel-klitzke/fast-audio-machine-learning-model-debugging-using-embedding-space-clustering-1fc1ca232592)
    中找到。'
- en: The main reason we built Sliceguard is the fact that it not only works on tabular
    data, but also directly on embeddings. The library offers a lot of built-in functionality
    for pre-processing (e.g. binning) and post-processing.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建 Sliceguard 的主要原因是它不仅适用于表格数据，还能直接应用于嵌入。该库提供了大量内置功能用于预处理（如分箱）和后处理。
- en: 'We can run Sliceguard on CIFAR-100 with just a few lines of code:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用几行代码在 CIFAR-100 上运行 Sliceguard：
- en: 'Sliceguard uses [Spotlight](https://renumics.com/docs/getting-started) to provide
    an interactive visualization of the identified data slices:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Sliceguard 使用 [Spotlight](https://renumics.com/docs/getting-started) 提供识别的数据切片的互动可视化：
- en: '[PRE0]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Sliceguard can uncover fine-granular data slices on the CIFAR-100 datset (Fig.
    5). In addition to the previously discovered data slices in the tree categories,
    we also identify other issues (e.g. in the *mouse* class).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Sliceguard 可以在 CIFAR-100 数据集上揭示细粒度的数据切片（图 5）。除了之前发现的树类数据切片外，我们还识别了其他问题（如 *mouse*
    类）。
- en: '![](../Images/f2513d68f56ea9fffb1cbb85b7c2f7b5.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2513d68f56ea9fffb1cbb85b7c2f7b5.png)'
- en: 'Fig. 5: Sliceguard uncovers fine-granular data slices. An [interactive demo](https://huggingface.co/spaces/renumics/cifar100-sliceline-demo)
    is available on Huggingface. Source: created by the author.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：Sliceguard 揭示了细粒度的数据切片。在 Huggingface 上提供了一个 [互动演示](https://huggingface.co/spaces/renumics/cifar100-sliceline-demo)。来源：作者创建。
- en: Conclusions
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: We have presented three open source tools for mining data slices. Even on the
    simple CIFAR-100 benchmark, they can be used to uncover critical data segments
    quickly. Identifying these data slices is an important step to understand model
    failure modes and to improve the training dataset.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们介绍了三种开源工具，用于挖掘数据切片。即使在简单的 CIFAR-100 基准上，它们也可以快速揭示关键数据片段。识别这些数据切片是理解模型失败模式和改善训练数据集的重要步骤。
- en: The [SliceLine](https://github.com/DataDome/sliceline) tool works on tabular
    data and identifies data slices that are described by a combination of predicates.
    [Sliceguard](https://github.com/Renumics/sliceguard) does not return a mathematically
    guaranteed optimal combination of predicates, but it can directly work with embeddings.
    Additionally, it can be run on unstructured data sets with just a few lines of
    code.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[SliceLine](https://github.com/DataDome/sliceline) 工具适用于表格数据，并通过谓词组合描述数据切片。[Sliceguard](https://github.com/Renumics/sliceguard)
    不返回数学上保证的最佳谓词组合，但可以直接处理嵌入。此外，它可以在几行代码的基础上运行于非结构化数据集。'
- en: In practice, both SliceLine and Sliceguard are very helpful for identifying
    data slices. However, both tools cannot be used for a fully automated slice analysis.
    Instead, they provide powerful heuristics that can be combined with interactive
    exploration. If done correctly, this approach is an important tool for interdisciplinary
    data teams to build reliable ML systems.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，SliceLine 和 Sliceguard 对识别数据切片非常有帮助。然而，这两种工具都不能用于完全自动化的切片分析。相反，它们提供了强大的启发式方法，可以与互动探索相结合。如果操作得当，这种方法是跨学科数据团队构建可靠
    ML 系统的重要工具。
- en: Do you have experience with the presented data slicing tools or can you recommend
    other open source libraries? I’d be happy to hear from you in the comments.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否有使用过展示的数据切割工具的经验，或者能否推荐其他开源库？我很乐意在评论中听到你的意见。
