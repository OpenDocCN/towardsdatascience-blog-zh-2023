- en: A better way to analyze feature release impact
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/a-better-way-to-analyze-feature-release-impact-72529f907ccd?source=collection_archive---------14-----------------------#2023-05-23](https://towardsdatascience.com/a-better-way-to-analyze-feature-release-impact-72529f907ccd?source=collection_archive---------14-----------------------#2023-05-23)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Or — why naive “before-after” comparisons can drive bad product decisions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://iyarlin.medium.com/?source=post_page-----72529f907ccd--------------------------------)[![Iyar
    Lin](../Images/8d27b185b273b7ea035250cdbd3eddbf.png)](https://iyarlin.medium.com/?source=post_page-----72529f907ccd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----72529f907ccd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----72529f907ccd--------------------------------)
    [Iyar Lin](https://iyarlin.medium.com/?source=post_page-----72529f907ccd--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F407629a566a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-better-way-to-analyze-feature-release-impact-72529f907ccd&user=Iyar+Lin&userId=407629a566a2&source=post_page-407629a566a2----72529f907ccd---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----72529f907ccd--------------------------------)
    ·5 min read·May 23, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F72529f907ccd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-better-way-to-analyze-feature-release-impact-72529f907ccd&user=Iyar+Lin&userId=407629a566a2&source=-----72529f907ccd---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F72529f907ccd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-better-way-to-analyze-feature-release-impact-72529f907ccd&source=-----72529f907ccd---------------------bookmark_footer-----------)![](../Images/08a70e75fe0b546a969513b89e5fec07.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by author — using DALL-E 2
  prefs: []
  type: TYPE_NORMAL
- en: A/B tests are the gold standard for estimating causal effects in product analytics.
    But in many cases they aren’t feasible. One of the most common ones is the feature
    release.
  prefs: []
  type: TYPE_NORMAL
- en: In this post I’ll discuss the common practice of measuring feature release impact
    using simple “before-after” comparisons and the biases that often plague such
    analyses. I’ll also give some advise on how those biases can be mitigated.
  prefs: []
  type: TYPE_NORMAL
- en: Some background
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Quite often, a company would release a new product feature or app version without
    running an A/B test to assess its impact on its main KPIs. That could be due to
    a myriad of reasons such as low traffic or high technical complexity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having deployed the feature to all users on a specific date product managers
    would usually try to gauge the feature release impact by doing a simple “before-after”
    analysis: comparing the KPI a short period after the launch to the same period
    before.'
  prefs: []
  type: TYPE_NORMAL
- en: While intuitive, such naive comparisons may overlook important sources of bias.
  prefs: []
  type: TYPE_NORMAL
- en: Below I’ll discuss 2 of the most common sources of bias present in simple before-after
    analyses and how they can lead to erroneous conclusions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Bias 1: Time effects'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One common scenario is for a product manager to do a “before-after” analysis
    and obtain a positive result.
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking at a plot of the KPI over time however they might run into a disappointing
    reckoning:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4f504fa35e1a335701a9a4b899a4455d.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by author
  prefs: []
  type: TYPE_NORMAL
- en: The KPI is on an upward trend throughout the period regardless of the release,
    whereas the release itself seems to have a negative impact. The simple “before-after”
    comparison assumes no time dynamics which can be very wrong like in the case illustrated
    above.
  prefs: []
  type: TYPE_NORMAL
- en: 'Bias 2: Change in mix of business'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While biases introduced by time effects can be quite visible — others might
    be more subtle.
  prefs: []
  type: TYPE_NORMAL
- en: 'In another scenario a product manager might measure a negative “before-after”
    release impact. Plotting the KPI over time does not seem to offer an alternative
    conclusion:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/28e1e54781c8fd1da2059181720d3f98.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by author
  prefs: []
  type: TYPE_NORMAL
- en: Many companies would stop here and assume the release was bad and needed to
    be rolled back.
  prefs: []
  type: TYPE_NORMAL
- en: In many cases however the difference between the periods before and after the
    release may be due to a change in the mix of users. This can happen by chance
    but very often is related to marketing campaigns that accompany feature releases.
  prefs: []
  type: TYPE_NORMAL
- en: To make the example concrete it could be that the proportion of Android users
    has risen significantly during the period after the release compared with the
    one prior.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ad6d4feac55c91350567f86977b626c0.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by author
  prefs: []
  type: TYPE_NORMAL
- en: 'In this specific example, those Android users tend to convert less than iOS
    users, but the release effect itself within those groups is actually positive:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/44d14fc92e4f1cf5bd6fadce65076b27.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by author
  prefs: []
  type: TYPE_NORMAL
- en: So taking device into account the release impact was actually positive. The
    scenario where the aggregate difference is opposite to the within group difference
    is a classic example of [Simpson’s paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox)).
  prefs: []
  type: TYPE_NORMAL
- en: Does that mean we can’t do without A/B tests?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The above cases were relatively simple. Time effects can include complex trends
    and daily seasonality, segment proportion changes can be more subtle and spread
    across many subsets etc.
  prefs: []
  type: TYPE_NORMAL
- en: One might get the impression that analyzing data from a feature release is useless.
    I argue however that must not necessarily be the case.
  prefs: []
  type: TYPE_NORMAL
- en: Enter the Release Impact Algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Working at [Loops](https://getloops.ai/) I’ve devised an algorithm to automatically
    and transparently deal with the above biases. I can’t share the full implementation
    details for business and IP reasons, but below I present a general overview:'
  prefs: []
  type: TYPE_NORMAL
- en: Use an ML algorithm to find segments whose proportion in the population changed
    the most between the pre and post-release periods.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Model time trends and seasonality along with the release impact **separately**
    within each segment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Take a weighted average of the release impact estimated within all segments
    to arrive at the final impact estimate.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Testing the algorithm validity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can never know for sure if any method works on a particular dataset. You
    can however get a rough estimate by using past A/B tests.
  prefs: []
  type: TYPE_NORMAL
- en: For example, an A/B test with control and treatment populations was executed
    for some period. Comparing the average KPI between those two groups yields an
    **unbiased** estimate of the treatment impact. This serves as our “Gold standard.”
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c16b8fc1c0b37c156f383cba31d35036.png)'
  prefs: []
  type: TYPE_IMG
- en: We’ll name the segment of users in the period before the test “pre-control.”
    Comparing the pre-control population to the treatment population is analogous
    to the comparison we do in a before-after analysis.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3f66d6c48a3189ed4a608e5e1ac3c140.png)'
  prefs: []
  type: TYPE_IMG
- en: Using many different tests, we can compare the “Gold standard” estimates with
    the “before-after” estimates to see how close they tend to be.
  prefs: []
  type: TYPE_NORMAL
- en: Working at [Loops](https://getloops.ai/) I have access to hundreds of A/B tests
    from dozens of clients using our system. Using the above benchmarking method we’ve
    found that the algorithm has vastly superior accuracy to a simple “before-after”
    comparison.
  prefs: []
  type: TYPE_NORMAL
- en: In summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I hope by this point the reader is convinced of the perils associated with using
    simple “before-after” comparison and that the algorithm outlined above will serve
    as a basis for anyone looking to better assess the impact generated by releasing
    a feature in their product.
  prefs: []
  type: TYPE_NORMAL
- en: '*A modified version of this piece was published at* [*https://getloops.ai*](https://getloops.ai/the-false-sense-of-confidence-with-before-after-analysis/)
    *on May 11, 2023.*'
  prefs: []
  type: TYPE_NORMAL
