- en: Topics per Class Using BERTopic
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用BERTopic的类别话题
- en: 原文：[https://towardsdatascience.com/topics-per-class-using-bertopic-252314f2640?source=collection_archive---------0-----------------------#2023-09-09](https://towardsdatascience.com/topics-per-class-using-bertopic-252314f2640?source=collection_archive---------0-----------------------#2023-09-09)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/topics-per-class-using-bertopic-252314f2640?source=collection_archive---------0-----------------------#2023-09-09](https://towardsdatascience.com/topics-per-class-using-bertopic-252314f2640?source=collection_archive---------0-----------------------#2023-09-09)
- en: How to understand the differences in texts by categories
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何理解按类别分类的文本差异
- en: '[](https://miptgirl.medium.com/?source=post_page-----252314f2640--------------------------------)[![Mariya
    Mansurova](../Images/b1dd377b0a1887db900cc5108bca8ea8.png)](https://miptgirl.medium.com/?source=post_page-----252314f2640--------------------------------)[](https://towardsdatascience.com/?source=post_page-----252314f2640--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----252314f2640--------------------------------)
    [Mariya Mansurova](https://miptgirl.medium.com/?source=post_page-----252314f2640--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://miptgirl.medium.com/?source=post_page-----252314f2640--------------------------------)[![玛丽亚·曼苏罗娃](../Images/b1dd377b0a1887db900cc5108bca8ea8.png)](https://miptgirl.medium.com/?source=post_page-----252314f2640--------------------------------)[](https://towardsdatascience.com/?source=post_page-----252314f2640--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----252314f2640--------------------------------)
    [玛丽亚·曼苏罗娃](https://miptgirl.medium.com/?source=post_page-----252314f2640--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F15a29a4fc6ad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftopics-per-class-using-bertopic-252314f2640&user=Mariya+Mansurova&userId=15a29a4fc6ad&source=post_page-15a29a4fc6ad----252314f2640---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----252314f2640--------------------------------)
    ·15 min read·Sep 9, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F252314f2640&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftopics-per-class-using-bertopic-252314f2640&user=Mariya+Mansurova&userId=15a29a4fc6ad&source=-----252314f2640---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F15a29a4fc6ad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftopics-per-class-using-bertopic-252314f2640&user=Mariya+Mansurova&userId=15a29a4fc6ad&source=post_page-15a29a4fc6ad----252314f2640---------------------post_header-----------)
    发表在[Towards Data Science](https://towardsdatascience.com/?source=post_page-----252314f2640--------------------------------)
    ·15 min阅读·2023年9月9日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F252314f2640&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftopics-per-class-using-bertopic-252314f2640&user=Mariya+Mansurova&userId=15a29a4fc6ad&source=-----252314f2640---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F252314f2640&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftopics-per-class-using-bertopic-252314f2640&source=-----252314f2640---------------------bookmark_footer-----------)![](../Images/33e46ed4709dca6e73fabaadff83025f.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F252314f2640&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftopics-per-class-using-bertopic-252314f2640&source=-----252314f2640---------------------bookmark_footer-----------)![](../Images/33e46ed4709dca6e73fabaadff83025f.png)'
- en: Photo by [Fas Khan](https://unsplash.com/@fasbytes?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Fas Khan](https://unsplash.com/@fasbytes?utm_source=medium&utm_medium=referral)提供，发布在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)上
- en: 'Nowadays, working in product analytics, we face a lot of free-form texts:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在产品分析工作中，我们面对许多自由格式的文本：
- en: Users leave comments in AppStore, Google Play or other services;
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户在AppStore、Google Play或其他服务中留下评论；
- en: Clients reach out to our Customer Support and describe their problems using
    natural language;
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户联系到我们的客户支持，使用自然语言描述他们的问题；
- en: We launch surveys ourselves to get even more feedback, and in most cases, there
    are some free-form questions to get a better understanding.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们自己发起调查以获取更多反馈，并且在大多数情况下，有一些自由格式的问题来获得更好的理解。
- en: We have hundreds of thousands of texts. It would take years to read them all
    and get some insights. Luckily, there are a lot of DS tools that could help us
    automate this process. One such tool is Topic Modelling, which I would like to
    discuss today.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有成千上万的文本。阅读它们并获取一些洞察可能需要数年时间。幸运的是，有许多数据科学工具可以帮助我们自动化这个过程。今天我想讨论的一个这样的工具就是主题建模。
- en: Basic Topic Modelling can give you an understanding of the main topics in your
    texts (for example, reviews) and their mixture. But it’s challenging to make decisions
    based on one point. For example, 14.2% of reviews are about too many ads in your
    app. Is it bad or good? Should we look into it? To tell the truth, I have no idea.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 基本的主题建模可以让你了解文本（例如评论）中的主要主题及其混合情况。但仅凭一个点来做决定是具有挑战性的。例如，14.2%的评论提到了应用中的广告过多。这是好还是坏？我们需要调查一下吗？说实话，我也不太确定。
- en: But if we try to segment customers, we may learn that this share is 34.8% for
    Android users and 3.2% for iOS. Then, it’s apparent that we need to investigate
    whether we show too many ads on Android or why Android users’ tolerance to ads
    is lower.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果我们尝试细分客户，我们可能会发现这个比例对于Android用户是34.8%，而对于iOS是3.2%。那么，显然我们需要调查一下我们是否在Android上展示了过多的广告，或者为什么Android用户对广告的容忍度较低。
- en: That’s why I would like to share not only how to build a topic model but also
    how to compare topics across categories. In the end we will get such insightful
    graphs for each topic.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我想分享的不仅是如何建立主题模型，还包括如何在不同类别之间比较主题。最终，我们将得到每个主题的有洞察力的图表。
- en: '![](../Images/50eb38c77d141bb59505642199693fa2.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/50eb38c77d141bb59505642199693fa2.png)'
- en: Graph by author
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 作者绘制的图表
- en: Data
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据
- en: The most common real-life cases of free-form texts are some kind of reviews.
    So, let’s use a [dataset](https://archive.ics.uci.edu/dataset/205/opinrank+review+dataset)
    with hotel reviews for this example.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现实生活中最常见的自由形式文本案例是某种评论。因此，让我们使用一个包含酒店评论的[数据集](https://archive.ics.uci.edu/dataset/205/opinrank+review+dataset)作为这个示例。
- en: I’ve filtered comments related to several hotel chains in London.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经筛选了与伦敦几个酒店连锁相关的评论。
- en: Before starting text analysis, it’s worth getting an overview of our data. In
    total, we have 12 890 reviews on 7 different hotel chains.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始文本分析之前，值得先了解一下我们的数据。总共有12,890条关于7个不同酒店连锁的评论。
- en: '![](../Images/797f31ce6919c232d63770e14410fb19.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/797f31ce6919c232d63770e14410fb19.png)'
- en: Graph by author
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 作者绘制的图表
- en: BERTopic
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BERTopic
- en: Now we have data and can apply our new fancy tool Topic Modeling to get insights
    from it. As I mentioned in the beginning, we will use Topic Modelling and a powerful
    and easy-to-use `BERTopic` package ([documentation](https://maartengr.github.io/BERTopic/index.html))
    for this text analysis.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有数据，并可以应用我们新的炫酷工具主题建模来获取洞察。如我在开始时提到的，我们将使用主题建模和一个强大且易于使用的`BERTopic`包（[文档](https://maartengr.github.io/BERTopic/index.html)）进行这次文本分析。
- en: You might wonder what Topic Modelling is. It is an unsupervised ML technique
    related to Natural Language Processing. It allows you to find hidden semantic
    patterns in texts (usually called documents) and assign “topics” to them. You
    don’t need to have a list of topics beforehand. The algorithm will define them
    automatically — usually in the form of a bag of the most important words (tokens)
    or N-grams.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道什么是主题建模。它是一种与自然语言处理相关的无监督机器学习技术。它允许你在文本（通常称为文档）中发现隐藏的语义模式，并为其分配“主题”。你无需事先准备主题列表。算法会自动定义它们——通常以最重要的单词（标记）或N-gram的形式呈现。
- en: '`BERTopic` is a package for Topic Modelling using HuggingFace transformers
    and [class-based TF-IDF](/creating-a-class-based-tf-idf-with-scikit-learn-caea7b15b858).
    `BERTopic` is a highly flexible modular package so that you can tailor it to your
    needs.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '`BERTopic`是一个使用HuggingFace transformers进行主题建模的包，[基于类的TF-IDF](https://creating-a-class-based-tf-idf-with-scikit-learn-caea7b15b858)。`BERTopic`是一个高度灵活的模块化包，你可以根据需要进行调整。'
- en: '![](../Images/a7f3e9f0124fea2827709869b90467dc.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a7f3e9f0124fea2827709869b90467dc.png)'
- en: Image from BERTopic docs ([source](https://github.com/MaartenGr/BERTopic/tree/master/images))
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 来自BERTopic文档的图片（[来源](https://github.com/MaartenGr/BERTopic/tree/master/images)）
- en: If you want to understand how it works better, I advise you to watch this video
    from the author of the library.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想更好地理解其工作原理，我建议你观看这个来自库作者的视频。
- en: Preprocessing
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预处理
- en: You can find the full code on [GitHub](https://github.com/miptgirl/miptgirl_medium/tree/main/bertopic_for_hotels).
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你可以在[GitHub](https://github.com/miptgirl/miptgirl_medium/tree/main/bertopic_for_hotels)上找到完整的代码。
- en: According to [the documentation](https://maartengr.github.io/BERTopic/faq.html#should-i-preprocess-the-data),
    we typically don’t need to preprocess data unless there is a lot of noise, for
    example, HTML tags or other markdowns that don’t add meaning to the documents.
    It’s a significant advantage of `BERTopic` because, for many NLP methods, there
    is a lot of boilerplate to preprocess your data. If you are interested in how
    it could look like, see [this guide](/topic-modelling-f51e5ebfb40a) for Topic
    Modelline using LDA.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[文档](https://maartengr.github.io/BERTopic/faq.html#should-i-preprocess-the-data)，我们通常不需要预处理数据，除非数据中有大量噪声，例如HTML标签或其他不增加文档意义的标记。这是`BERTopic`的一个显著优势，因为许多NLP方法需要大量的样板代码来预处理数据。如果你对其样子感兴趣，可以查看[这个指南](/topic-modelling-f51e5ebfb40a)了解使用LDA的主题建模。
- en: You can use `BERTopic` with data in multiple languages specifying `BERTopic(language=
    "multilingual")`. However, from my experience, the model works a bit better with
    texts translated into one language. So, I will translate all comments into English.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用`BERTopic`处理多语言数据，指定`BERTopic(language= "multilingual")`。然而，根据我的经验，模型在将文本翻译成一种语言时表现略好。因此，我将把所有评论翻译成英语。
- en: For translation, we will use `deep-translator` package (you can install it from
    [PyPI](https://pypi.org/project/deep-translator/)).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于翻译，我们将使用`deep-translator`包（可以从[PyPI](https://pypi.org/project/deep-translator/)安装）。
- en: Also, it could be interesting to see distribution by languages, for that we
    could use `langdetect` package.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，查看按语言分布可能会很有趣，为此我们可以使用`langdetect`包。
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In our case, 95+% of comments are already in English.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，95%以上的评论已经是英语。
- en: '![](../Images/51b3b12bb732e846c080aab9542fb1fa.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/51b3b12bb732e846c080aab9542fb1fa.png)'
- en: Graph by author
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图
- en: To understand our data better, let’s look at the distribution of reviews’ length.
    It shows that there are a lot of extremely short (and most likely not meaningful
    comments) — around 5% of reviews are less than 20 symbols.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解我们的数据，让我们看看评论长度的分布。它显示了许多极短的评论（很可能没有意义的评论）——大约5%的评论少于20个符号。
- en: '![](../Images/f90489f6e837c08eacd489bb40e4011a.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f90489f6e837c08eacd489bb40e4011a.png)'
- en: Graph by author
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图
- en: We can look at the most common examples to ensure that there’s not much information
    in such comments.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查看最常见的例子，以确保这些评论中没有太多信息。
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: So we can filter out all comments shorter than 20 symbols — 556 out of 12 890
    reviews (4.3%). Then, we will analyse only long statements with more context.
    It’s an arbitrary threshold based on examples, you can try a couple of levels
    and see what texts are filtered out.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们可以过滤掉所有少于20个符号的评论——12,890条评论中的556条（4.3%）。然后，我们只分析具有更多上下文的长评论。这是一个基于示例的任意阈值，你可以尝试几个不同的级别，看看哪些文本被过滤掉了。
- en: It’s worth checking whether this filter disproportionally affects some hotels.
    Shares of short comments are pretty close for different categories. So, the data
    looks OK.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 值得检查一下这个过滤器是否对某些酒店产生了不成比例的影响。不同类别的短评论比例相当接近。所以，数据看起来还不错。
- en: '![](../Images/db00af7437b154c1f3ef37efe8257ab4.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/db00af7437b154c1f3ef37efe8257ab4.png)'
- en: Graph by author
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图
- en: The simpliest topic model
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最简单的主题模型
- en: Now, it’s time to build our first topic model. Let’s start simple with the most
    basic one to understand how library works, then we will improve it.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候构建我们的第一个主题模型了。让我们从最基本的模型开始，以了解库的工作原理，然后我们将对其进行改进。
- en: We can train a topic model in just a few code lines that could be easily understood
    by anyone who has used at least one ML package before.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用几行代码训练一个主题模型，这些代码对任何曾使用过至少一个机器学习包的人来说都很容易理解。
- en: '[PRE2]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The default model returned 113 topics. We can look at top topics.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 默认模型返回了113个主题。我们可以查看顶部主题。
- en: '[PRE3]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/8e73ff2d0dd373322f265f8d0e382908.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8e73ff2d0dd373322f265f8d0e382908.png)'
- en: The biggest group is `Topic -1` , which corresponds to outliers. By default,
    `BERTopic` uses `HDBSCAN` for clustering, and it doesn’t force all data points
    to be part of clusters. In our case, 6 356 reviews are outliers (around 49.3%
    of all reviews). It is almost a half of our data, so we will work with this group
    later.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 最大的组是`Topic -1`，它对应于异常值。默认情况下，`BERTopic`使用`HDBSCAN`进行聚类，它不会强制所有数据点成为聚类的一部分。在我们的案例中，6,356条评论是异常值（约49.3%的所有评论）。这几乎是我们数据的一半，因此我们稍后将处理这一组。
- en: A topic representation is usually a set of most important words specific to
    this topic and not others. So, the best way to understand a topic is to look at
    the main terms (in `BERTopic`, a [class-based TF-IDF](/creating-a-class-based-tf-idf-with-scikit-learn-caea7b15b858)
    score is used to rank the words).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 主题表示通常是一组特定于该主题而非其他主题的最重要的词。因此，理解主题的最佳方法是查看主要术语（在 `BERTopic` 中，使用 [基于类别的 TF-IDF](/creating-a-class-based-tf-idf-with-scikit-learn-caea7b15b858)
    分数来对词语进行排序）。
- en: '[PRE4]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/a960aeccd8b3c5594637dfb3299752d0.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a960aeccd8b3c5594637dfb3299752d0.png)'
- en: Graph by author
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图表由作者提供
- en: '`BERTopic` even has [Topics per Class](https://maartengr.github.io/BERTopic/getting_started/topicsperclass/topicsperclass.html)
    representation that can solve our task of understanding the differences in course
    reviews.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '`BERTopic` 甚至提供了 [每类主题](https://maartengr.github.io/BERTopic/getting_started/topicsperclass/topicsperclass.html)
    的表示方式，这可以解决我们理解课程评论差异的任务。'
- en: '[PRE5]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/7db8c5297bdcf3ef79213ce4a93cf977.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7db8c5297bdcf3ef79213ce4a93cf977.png)'
- en: Graph by author
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图表由作者提供
- en: If you are wondering how to interpret this graph, you are not alone — I also
    wasn’t able to guess. However, the author kindly supports this package, and there
    are a lot of answers on GitHub. From the [discussion](https://github.com/MaartenGr/BERTopic/issues/446),
    I learned that the current normalisation approach doesn’t show the share of different
    topics for classes. So, it hasn’t completely solved our initial task.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在想如何解读这张图表，你并不孤单——我也无法猜测。不过，作者友好地支持了这个包，在 GitHub 上有很多答案。从 [讨论](https://github.com/MaartenGr/BERTopic/issues/446)
    中，我了解到当前的归一化方法没有显示每个类别的不同主题的份额。因此，它还没有完全解决我们的初始任务。
- en: However, we did the first iteration in less than 10 rows of code. It’s fantastic,
    but there’s some room for improvement.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们在不到 10 行代码中完成了第一次迭代。这非常棒，但还有改进的空间。
- en: Dealing with the outliers
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理异常值
- en: As we saw earlier, almost 50% of data points are considered outliers. It’s quite
    a lot, let’s see what we could do with it.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所见，几乎 50% 的数据点被视为异常值。这确实不少，让我们看看我们可以怎么处理。
- en: 'The [documentation](https://maartengr.github.io/BERTopic/getting_started/outlier_reduction/outlier_reduction.html)
    provides four different strategies to deal with the outliers:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[文档](https://maartengr.github.io/BERTopic/getting_started/outlier_reduction/outlier_reduction.html)
    提供了四种不同的策略来处理异常值：'
- en: based on topic-document probabilities,
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于主题-文档概率，
- en: based on topic distributions,
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于主题分布，
- en: based on c-TF-IFD representations,
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于 c-TF-IFD 表示，
- en: based on document and topic embeddings.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于文档和主题嵌入。
- en: You can try different strategies and see which one fits your data the best.
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你可以尝试不同的策略，看看哪种最适合你的数据。
- en: Let’s look at examples of outliers. Even though these reviews are relatively
    short, they have multiple topics.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下异常值的例子。尽管这些评论相对较短，但它们包含多个主题。
- en: '![](../Images/9f9153957e56f274473142d30aca9d79.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9f9153957e56f274473142d30aca9d79.png)'
- en: '`BERTopic` uses clustering to define topics. It means that not more than one
    topic is assigned to each document. In most real-life cases, you can have a mixture
    of topics in your texts. We may be unable to assign a topic to the documents because
    they have multiple ones.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`BERTopic` 使用聚类来定义主题。这意味着每个文档分配的不超过一个主题。在大多数实际情况下，你的文本中可能会有多个主题的混合。我们可能无法为这些文档分配一个主题，因为它们有多个主题。'
- en: Luckily, there’s a solution for it — use [Topic Distributions](https://maartengr.github.io/BERTopic/getting_started/distribution/distribution.html).
    With such an approach, each document will be split into tokens. Then, we will
    form subsentences (defined by sliding window and stride) and assign a topic for
    each such subsentence.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，有一个解决方案——使用 [主题分布](https://maartengr.github.io/BERTopic/getting_started/distribution/distribution.html)。通过这种方法，每个文档将被分割成词元。然后，我们将形成子句（由滑动窗口和步幅定义），并为每个子句分配一个主题。
- en: Let’s try this approach and see whether we will be able to reduce the number
    of outliers without topics.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试这种方法，看看是否能在没有主题的情况下减少异常值的数量。
- en: Improving the topic model
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进主题模型
- en: However, Topic Distributions are based on the fitted topic model, so let’s enhance
    it.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，主题分布是基于拟合的主题模型，因此让我们来改进它。
- en: First of all, we can use [CountVectorizer](https://maartengr.github.io/BERTopic/getting_started/vectorizers/vectorizers.html#countvectorizer).
    It defines how a document will be split into tokens. Also, it can help us to get
    rid of meaningless words like `to`, `not` or `the` (there are a lot of such words
    in our first model).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们可以使用[CountVectorizer](https://maartengr.github.io/BERTopic/getting_started/vectorizers/vectorizers.html#countvectorizer)。它定义了文档如何被拆分成标记。此外，它还可以帮助我们去除像`to`、`not`或`the`这样的无意义词（在我们的第一个模型中有很多这样的词）。
- en: Also, we could improve topics’ representations and even try a couple of different
    models. I used the `KeyBERTInspired` model ([more details](https://maartengr.github.io/BERTopic/getting_started/representation/representation.html#keybertinspired)),
    but you could try other options (for example, [LLMs](https://maartengr.github.io/BERTopic/getting_started/representation/llm.html)).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以改善话题的表示，甚至尝试几种不同的模型。我使用了`KeyBERTInspired`模型（[更多细节](https://maartengr.github.io/BERTopic/getting_started/representation/representation.html#keybertinspired)），但你也可以尝试其他选项（例如，[LLMs](https://maartengr.github.io/BERTopic/getting_started/representation/llm.html)）。
- en: '[PRE6]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: I specified `nr_topics = 'auto'` to reduce the number of topics. Then, all topics
    with a similarity over threshold will be merged automatically. With this feature,
    we got 99 topics.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我指定了`nr_topics = 'auto'`以减少话题数量。然后，所有相似度超过阈值的话题将被自动合并。通过此功能，我们得到了99个话题。
- en: I’ve created a function to get top topics and their shares so we could analyse
    it easier. Let’s look at the new set of topics.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我创建了一个函数来获取最热门的话题及其份额，以便我们可以更容易地进行分析。让我们看看新的话题集合。
- en: '[PRE7]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/5d34f53fbcd237badd2812791bbe58b6.png)![](../Images/d0083a5b923beee193a5ff1c7fc2ac5d.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d34f53fbcd237badd2812791bbe58b6.png)![](../Images/d0083a5b923beee193a5ff1c7fc2ac5d.png)'
- en: Graph by author
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图表由作者提供
- en: We can also look at the Interoptic distance map to better understand our clusters,
    for example, which are close to each other. You can also use it to define some
    parent topics and subtopics. It’s called [Hierarchical Topic Modelling](https://maartengr.github.io/BERTopic/getting_started/hierarchicaltopics/hierarchicaltopics.html)
    and you can use other tools for it.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以查看话题间距图，以更好地理解我们的聚类，例如，哪些彼此接近。你还可以用它来定义一些父话题和子话题。这叫做[层次化话题建模](https://maartengr.github.io/BERTopic/getting_started/hierarchicaltopics/hierarchicaltopics.html)，你也可以使用其他工具来实现。
- en: '[PRE8]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/bb1397be050d6663681d9e0d2b7314a2.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bb1397be050d6663681d9e0d2b7314a2.png)'
- en: Graph by author
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图表由作者提供
- en: Another insightful way to better understand your topics is to look at `visualize_documents`
    graph ([documentation](https://maartengr.github.io/BERTopic/getting_started/visualization/visualize_documents.html)).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种深入理解话题的有用方法是查看`visualize_documents`图表（[文档](https://maartengr.github.io/BERTopic/getting_started/visualization/visualize_documents.html)）。
- en: We can see that the number of topics has reduced significantly. Also, there
    are no meaningless stop words in topics’ representations.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到话题数量显著减少。此外，话题表示中没有无意义的停用词。
- en: Reducing the number of topics
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 减少话题数量
- en: However, we still see similar topics in the results. We can investigate and
    merge such topics manually.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们仍然在结果中看到类似的话题。我们可以手动调查并合并这些话题。
- en: For this, we can draw a Similarity matrix. I specified `n_clusters`, and our
    topics were clustered to visualise them better.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们可以绘制相似度矩阵。我指定了`n_clusters`，并对话题进行了聚类，以更好地可视化它们。
- en: '[PRE9]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/0522d0d57f94d7c879c762ea784c2029.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0522d0d57f94d7c879c762ea784c2029.png)'
- en: Graph by author
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图表由作者提供
- en: There are some pretty close topics. Let’s calculate the pair distances and look
    at the top topics.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些相当接近的话题。让我们计算话题对的距离并查看最热门的话题。
- en: '[PRE10]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: I found guidance on how to get the distance matrix from [GitHub discussions](https://github.com/MaartenGr/BERTopic/issues/292).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我从[GitHub讨论](https://github.com/MaartenGr/BERTopic/issues/292)中找到了获取距离矩阵的指导。
- en: We can now see the top pairs of topics by cosine similarity. There are topics
    with close meanings that we could merge.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以看到按余弦相似度排列的最热门话题对。我们可以合并那些意义相近的话题。
- en: '![](../Images/7a1a307bde2c14ca410fc7e52e446507.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a1a307bde2c14ca410fc7e52e446507.png)'
- en: '[PRE11]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '***Attention:*** after merging, all topics’ IDs and representations will be
    recalculated, so it’s worth updating if you use them.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '***注意：*** 合并后，所有话题的ID和表示将被重新计算，因此如果你使用它们，值得更新。'
- en: Now, we’ve improved our initial model and are ready to move on.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已改进了初始模型，准备继续前进。
- en: With real-life tasks, it’s worth spending more time on merging topics and trying
    different approaches to representation and clustering to get the best results.
  id: totrans-112
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在实际任务中，值得花更多时间合并话题并尝试不同的表示和聚类方法，以获得最佳结果。
- en: ''
  id: totrans-113
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The other potential idea is splitting reviews into separate sentences because
    comments are rather long.
  id: totrans-114
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 另一个潜在的想法是将评论拆分成单独的句子，因为评论通常较长。
- en: Topic Distributions
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主题分布
- en: Let’s calculate topics’ and tokens’ distributions. I’ve used a window equal
    to 4 (the author advised using 4–8 tokens) and stride equal 1.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算主题和词汇的分布。我使用了窗口大小为4（作者建议使用4–8个词汇）和步长为1。
- en: '[PRE12]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: For example, this comment will be split into subsentences (or sets of four tokens),
    and the closest of existing topics will be assigned to each. Then, these topics
    will be aggregated to calculate probabilities for the whole sentence. You can
    find more details in [the documentation](https://maartengr.github.io/BERTopic/getting_started/distribution/distribution.html).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这条评论将被拆分为子句（或四个词汇的集合），并将为每个子句分配最接近的现有主题。然后，这些主题将被聚合，以计算整个句子的概率。您可以在[文档](https://maartengr.github.io/BERTopic/getting_started/distribution/distribution.html)中找到更多详细信息。
- en: '![](../Images/191c15ad06267d8710cbba9a45eb3a8c.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/191c15ad06267d8710cbba9a45eb3a8c.png)'
- en: Example shows how split works with basic CountVectorizer, window = 4 and stride
    = 1
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 示例显示了如何使用基本的CountVectorizer进行拆分，窗口大小为4，步长为1
- en: Using this data, we can get the probabilities of different topics for each review.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些数据，我们可以获得每条评论的不同主题的概率。
- en: '[PRE13]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](../Images/e980128534ba025d5ffc822c37cddd14.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e980128534ba025d5ffc822c37cddd14.png)'
- en: Graph by author
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图表
- en: We can even see the distribution of terms for each topic and understand why
    we got this result. For our sentence, `best very beautiful`was the main term for
    `Topic 74`, while `location close to`defined a bunch of location-related topics.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们甚至可以看到每个主题的术语分布，并理解为什么会得到这个结果。对于我们的句子，`best very beautiful`是`Topic 74`的主要术语，而`location
    close to`定义了一系列与位置相关的主题。
- en: '[PRE14]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/d627cb15f2b1e27ef30296031a7091d7.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d627cb15f2b1e27ef30296031a7091d7.png)'
- en: Graph by author
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图表
- en: This example also shows that we might have spent more time merging topics because
    there are still pretty similar ones.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子还显示了我们可能需要花更多时间合并主题，因为仍然存在一些相似的主题。
- en: Now, we have probabilities for each topic and review. The next task is to select
    a threshold to filter irrelevant topics with too low probability.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们拥有每个主题和评论的概率。下一步是选择一个阈值，以过滤掉概率过低的不相关主题。
- en: We can do it as usual using data. Let’s calculate the distribution of selected
    topics per review for different threshold levels.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像往常一样使用数据来处理它。让我们计算不同阈值水平下每条评论的选定主题分布。
- en: '[PRE15]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](../Images/43d349da0086309e4e644c8871cddd43.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/43d349da0086309e4e644c8871cddd43.png)'
- en: Graph by author
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图表
- en: '`threshold = 0.05` looks like a good candidate because, with this level, the
    share of reviews without any topic is still low enough (less than 6%), while the
    percentage of comments with 4+ topics is also not so high.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`threshold = 0.05` 看起来是一个不错的候选值，因为在这个水平下，没有任何主题的评论比例仍然足够低（少于6%），而拥有4个以上主题的评论比例也不高。'
- en: This approach has helped us to reduce the number of outliers from 53.4% to 5.8%.
    So, assigning multiple topics could be an effective way to handle outliers.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法帮助我们将异常值的比例从53.4%减少到了5.8%。因此，分配多个主题可能是处理异常值的有效方法。
- en: Let’s calculate the topics for each doc with this threshold.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用这个阈值计算每个文档的主题。
- en: '[PRE16]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Comparing distributions by hotels
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按酒店比较分布
- en: Now, we have multiple topics mapped to each review and we can compare topics’
    mixtures for different hotel chains.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有多个主题映射到每条评论，我们可以比较不同酒店连锁的主题组合。
- en: Let’s find cases when a topic has too high or low share for a particular hotel.
    For that, we will calculate for each pair topic + hotel share of comments related
    to the topic for this hotel vs. all others.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们找出某个主题在特定酒店中占比过高或过低的情况。为此，我们将计算每对主题+酒店相关的评论占该酒店总评论数的比例，并与其他酒店进行比较。
- en: '[PRE17]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: However, not all differences are significant for us. We can say that the difference
    in topics’ distribution is worth looking at if there are
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，并不是所有的差异对我们来说都是显著的。如果主题分布的差异值得关注，则我们可以这样说。
- en: '**statistical significance** — the difference is not just by chance,'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**统计显著性** — 差异不仅仅是偶然的，'
- en: '**practical significance** — the difference is bigger than X% points (I used
    1%).'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实际显著性** — 差异大于X%点（我使用了1%）。'
- en: '[PRE18]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We have all the stats for all topics and hotels, and the last step is to create
    a visualisation comparing topic shares by categories.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经掌握了所有主题和酒店的统计数据，最后一步是创建一个按类别比较主题份额的可视化图表。
- en: '[PRE19]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Then, we can calculate the top topics list and make graphs for them.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以计算出最热门的主题列表，并为其制作图表。
- en: '[PRE20]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Here are a couple of examples of resulting charts. Let’s try to make some conclusions
    based on this data.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几个结果图表的例子。让我们尝试根据这些数据得出一些结论。
- en: We can see that Holiday Inn, Travelodge and Park Inn have better prices and
    value for money compared to Hilton or Park Plaza.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，Holiday Inn、Travelodge和Park Inn的价格和性价比优于Hilton或Park Plaza。
- en: '![](../Images/17c052fd162fc829d727053e3d3d2d6f.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/17c052fd162fc829d727053e3d3d2d6f.png)'
- en: Graph by author
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 作者绘制的图表
- en: The other insight is that in Travelodge noise may be a problem.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个见解是，在Travelodge噪音可能是一个问题。
- en: '![](../Images/3bce345923e1bfb3143b0dc6209bbea8.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3bce345923e1bfb3143b0dc6209bbea8.png)'
- en: Graph by author
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 作者绘制的图表
- en: It’s a bit challenging for me to interpret this result. I’m not sure what this
    topic is about.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 对我来说，解读这个结果有点挑战。我不确定这个主题是什么。
- en: '![](../Images/d4134f75b10738b3dc523e98ce730948.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d4134f75b10738b3dc523e98ce730948.png)'
- en: Graph by author
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 作者绘制的图表
- en: The best practice for such cases is to look at some examples.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这种情况，最佳实践是查看一些示例。
- en: '*We stayed in the East tower where* ***the lifts are under renovation****,
    only one works, but there are signs showing the way to service lifts which can
    be used also.*'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*我们住在东塔，其中* ***电梯正在翻修中****，只有一个在工作，但有指示牌指向可以使用的服务电梯。*'
- en: '*However, the carpet and the furniture could have a* ***refurbishment****.*'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*然而，地毯和家具可能需要* ***翻新****。'
- en: '*It’s built right over Queensway station. Beware that this tube stop will be
    closed for* ***refurbishing*** *for one year! So you might consider noise levels.*'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*它建在Queensway车站上方。请注意，这个地铁站将在* ***翻新*** *一年！所以你可能要考虑噪音问题。*'
- en: So, this topic is about the cases of temporary issues during the hotel stay
    or furniture not in the best condition.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，这个主题是关于酒店住宿期间出现的临时问题或家具状况不佳的情况。
- en: You can find the full code on [GitHub](https://github.com/miptgirl/miptgirl_medium/tree/main/bertopic_for_hotels).
  id: totrans-166
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你可以在[GitHub](https://github.com/miptgirl/miptgirl_medium/tree/main/bertopic_for_hotels)上找到完整的代码。
- en: Summary
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'Today, we’ve done an end-to-end Topic Modelling analysis:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，我们完成了一个端到端的主题建模分析：
- en: Build a basic topic model using the BERTopic library.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用BERTopic库构建一个基本的主题模型。
- en: Then, we’ve handled outliers, so only 5.8% of our reviews don’t have a topic
    assigned.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，我们处理了离群值，因此只有5.8%的评论没有分配主题。
- en: Reduced the number of topics both automatically and manually to have a concise
    list.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过自动和手动方法减少了主题数量，以获得一个简明的列表。
- en: Learned how to assign multiple topics to each document because, in most cases,
    your text will have a mixture of topics.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学会了如何为每个文档分配多个主题，因为在大多数情况下，你的文本会包含多种主题。
- en: Finally, we were able to compare reviews for different courses, create inspiring
    graphs and get some insights.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们能够比较不同课程的评论，创建激励性的图表并获得一些见解。
- en: Thank you a lot for reading this article. I hope it was insightful to you. If
    you have any follow-up questions or comments, please leave them in the comments
    section.
  id: totrans-174
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 非常感谢你阅读这篇文章。希望它对你有所启发。如果你有任何后续问题或评论，请在评论区留下。
- en: Dataset
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集
- en: '*Ganesan, Kavita and Zhai, ChengXiang. (2011). OpinRank Review Dataset.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '*Ganesan, Kavita 和 Zhai, ChengXiang. (2011). OpinRank 评论数据集。*'
- en: UCI Machine Learning Repository.* [*https://doi.org/10.24432/C5QW4W*](https://doi.org/10.24432/C5QW4W.)
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: UCI机器学习资源库。[*https://doi.org/10.24432/C5QW4W*](https://doi.org/10.24432/C5QW4W.)
- en: If you want to dive deeper into BERTopic
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如果你想深入了解BERTopic
- en: '[Article “Interactive Topic Modelling with BERTopic”](/interactive-topic-modeling-with-bertopic-1ea55e7d73d8)
    by Maarten Grootendorst (*BERTopic* *author*)'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[文章《使用BERTopic进行交互式主题建模》](/interactive-topic-modeling-with-bertopic-1ea55e7d73d8)由Maarten
    Grootendorst（*BERTopic* *作者*）撰写'
- en: Article [“Topic Modelling with BERT”](/topic-modeling-with-bert-779f7db187e6)
    by Maarten Grootendorst
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文章 [“使用BERT进行主题建模”](/topic-modeling-with-bert-779f7db187e6) 由Maarten Grootendorst撰写
- en: 'Paper [“BERTopic: Neural topic modeling with a class-based TF-IDF procedure”](https://arxiv.org/abs/2203.05794)
    by Maarten Grootendorst'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 论文 [“BERTopic：基于类别的TF-IDF程序的神经主题建模”](https://arxiv.org/abs/2203.05794) 由Maarten
    Grootendorst撰写
