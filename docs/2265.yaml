- en: Deploying Large Language Models With HuggingFace TGI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/deploying-large-language-models-with-huggingface-tgi-981747c669e3?source=collection_archive---------3-----------------------#2023-07-14](https://towardsdatascience.com/deploying-large-language-models-with-huggingface-tgi-981747c669e3?source=collection_archive---------3-----------------------#2023-07-14)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Another way to efficiently host and scale your LLMs with Amazon SageMaker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://ram-vegiraju.medium.com/?source=post_page-----981747c669e3--------------------------------)[![Ram
    Vegiraju](../Images/07d9334e905f710d9f3c6187cf69a1a5.png)](https://ram-vegiraju.medium.com/?source=post_page-----981747c669e3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----981747c669e3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----981747c669e3--------------------------------)
    [Ram Vegiraju](https://ram-vegiraju.medium.com/?source=post_page-----981747c669e3--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6e49569edd2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploying-large-language-models-with-huggingface-tgi-981747c669e3&user=Ram+Vegiraju&userId=6e49569edd2b&source=post_page-6e49569edd2b----981747c669e3---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----981747c669e3--------------------------------)
    ·5 min read·Jul 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F981747c669e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploying-large-language-models-with-huggingface-tgi-981747c669e3&user=Ram+Vegiraju&userId=6e49569edd2b&source=-----981747c669e3---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F981747c669e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploying-large-language-models-with-huggingface-tgi-981747c669e3&source=-----981747c669e3---------------------bookmark_footer-----------)![](../Images/87080a29c8a17cddf9ed8b4ece860f12.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image from [Unsplash](https://unsplash.com/photos/4NYtYSiZVlA)
  prefs: []
  type: TYPE_NORMAL
- en: Large Language Models (LLMs) continue to soar in popularity as a new one is
    released nearly every week. With the number of these models increasing, so are
    the options for how we can host them. In my previous article we explored how we
    could utilize [DJL Serving](https://github.com/deepjavalibrary/djl-serving) within
    Amazon SageMaker to efficiently host LLMs. In this article we explore another
    optimized model server and solution in [HuggingFace Text Generation Inference
    (TGI)](https://github.com/huggingface/text-generation-inference).
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**: For those of you new to AWS, make sure you make an account at the
    following [link](https://aws.amazon.com/console/) if you want to follow along.
    The article also assumes an intermediate understanding of SageMaker Deployment,
    I would suggest following this [article](https://aws.amazon.com/blogs/machine-learning/part-2-model-hosting-patterns-in-amazon-sagemaker-getting-started-with-deploying-real-time-models-on-sagemaker/)
    for understanding Deployment/Inference more in depth.'
  prefs: []
  type: TYPE_NORMAL
- en: '**DISCLAIMER**: I am a Machine Learning Architect at AWS and my opinions are
    my own.'
  prefs: []
  type: TYPE_NORMAL
- en: Why HuggingFace Text Generation Inference? How Does It Work With Amazon SageMaker?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: TGI is a Rust, Python, gRPC model server created by HuggingFace that can be
    used to host specific large language models. HuggingFace has long been the central
    hub for NLP and it contains a large set of…
  prefs: []
  type: TYPE_NORMAL
