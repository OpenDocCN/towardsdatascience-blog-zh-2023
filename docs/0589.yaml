- en: Wordle Word Length and Letter Frequency Analysis Using Julia
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/wordle-word-length-and-letter-frequency-analysis-using-julia-3fc5c63fedba?source=collection_archive---------12-----------------------#2023-02-10](https://towardsdatascience.com/wordle-word-length-and-letter-frequency-analysis-using-julia-3fc5c63fedba?source=collection_archive---------12-----------------------#2023-02-10)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Exploring English word datasets to improve our game
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@naresh-ram?source=post_page-----3fc5c63fedba--------------------------------)[![Naresh
    Ram](../Images/4a20b5646f75fb6cc2a5684fd3daf6db.png)](https://medium.com/@naresh-ram?source=post_page-----3fc5c63fedba--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3fc5c63fedba--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3fc5c63fedba--------------------------------)
    [Naresh Ram](https://medium.com/@naresh-ram?source=post_page-----3fc5c63fedba--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa5665b0dac5f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwordle-word-length-and-letter-frequency-analysis-using-julia-3fc5c63fedba&user=Naresh+Ram&userId=a5665b0dac5f&source=post_page-a5665b0dac5f----3fc5c63fedba---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3fc5c63fedba--------------------------------)
    ·19 min read·Feb 10, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3fc5c63fedba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwordle-word-length-and-letter-frequency-analysis-using-julia-3fc5c63fedba&user=Naresh+Ram&userId=a5665b0dac5f&source=-----3fc5c63fedba---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3fc5c63fedba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwordle-word-length-and-letter-frequency-analysis-using-julia-3fc5c63fedba&source=-----3fc5c63fedba---------------------bookmark_footer-----------)![](../Images/626ad3edde1f12cd388d3eeb5dc4f5e5.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Inspired by [Wordle](https://www.nytimes.com/games/wordle/index.html). Image
    by the Author.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '[Wordle](https://www.nytimes.com/games/wordle/index.html)™ is a great game
    that needs no introduction. But keeping a streak alive is no easy task. So, to
    better understand how the gameplay works, let’s load up the English words in Julia
    and perform a little analysis on them. We’ll look at letter frequencies in general
    and the 5-letter words specifically to help make better-informed guesses in the
    game. Along the way, let’s also look at why five was chosen as the word length
    for the game.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: While I cannot guarantee it will reduce the number of guesses you make, I can
    guarantee a fun session of data analysis using [Julia](https://julialang.org/)
    and [Julia Plots](https://docs.juliaplots.org/).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我不能保证它会减少你的猜测次数，但我可以保证使用 [Julia](https://julialang.org/) 和 [Julia Plots](https://docs.juliaplots.org/)
    进行数据分析会很有趣。
- en: At [AAXIS](https://www.aaxisdigital.com/), where I work, we implement business-to-business
    as well as business-to-consumer digital commerce solutions. Doing so includes
    migrating large amounts of data from an existing older system to a newer system
    with different data structures. We use a variety of data tools to analyze source
    data to ensure consistency. I routinely use techniques outlined in this article
    for that purpose. A good way to become familiar with these techniques is to use
    them often and the Wordle word list sounds like a fun way to practice.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在我工作的 [AAXIS](https://www.aaxisdigital.com/) 公司，我们实施了面向企业的数字商务解决方案以及面向消费者的数字商务解决方案。这包括将大量数据从现有的旧系统迁移到具有不同数据结构的新系统。我们使用各种数据工具来分析源数据，以确保一致性。我通常会使用本文中概述的技巧。熟悉这些技巧的好方法是经常使用它们，而
    Wordle 单词列表听起来是一个有趣的练习方式。
- en: So, let’s get started.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: Setup
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置
- en: '![](../Images/d988ce41b881f02bb5d44abf69e1cb32.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d988ce41b881f02bb5d44abf69e1cb32.png)'
- en: Photo by [Linus Mimietz](https://unsplash.com/@linusmimietz?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/gvptKmonylk?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Linus Mimietz](https://unsplash.com/@linusmimietz?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，来源于 [Unsplash](https://unsplash.com/photos/gvptKmonylk?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: If you are planning to work alongside me to learn Julia, I strongly recommend
    you go through this section. If not, you can safely skip it.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你计划跟我一起学习 Julia，我强烈建议你阅读这一部分。如果不计划，你可以安全地跳过。
- en: Installing Julia
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 Julia
- en: Please install Julia from the [Julia Language](https://julialang.org/downloads/)
    site. Installers are available for Windows, Mac, and Linux operating systems.
    I also installed the *Julia Language Support* extension for [VSCode](https://code.visualstudio.com/download)
    and am executing these commands in the [Julia REPL](https://docs.julialang.org/en/v1/stdlib/REPL/)
    in VSCode. That way, my graphs show up in the window, making it mightily convenient
    to analyze datasets.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 请从 [Julia Language](https://julialang.org/downloads/) 网站安装 Julia。该网站提供适用于 Windows、Mac
    和 Linux 操作系统的安装程序。我还为 [VSCode](https://code.visualstudio.com/download) 安装了 *Julia
    Language Support* 扩展，并在 VSCode 中执行这些命令的 [Julia REPL](https://docs.julialang.org/en/v1/stdlib/REPL/)。这样，我的图形会显示在窗口中，使数据集分析变得极为方便。
- en: '![](../Images/db73c709c922b58b1a4b2a0c04b99df5.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/db73c709c922b58b1a4b2a0c04b99df5.png)'
- en: Julia REPL in Visual Studio Code. Image by the Author.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Visual Studio Code 中的 Julia REPL。图片由作者提供。
- en: 'Now, let’s go ahead and load up the graphics and other required libraries.
    You’ll want to pull up a Julia REPL Window by typing CNTRL-SHIFT-P and selecting
    *Julia: Start REPL* after installation.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '现在，让我们加载图形和其他所需的库。安装完成后，你可以通过输入 CNTRL-SHIFT-P 并选择 *Julia: Start REPL* 来打开 Julia
    REPL 窗口。'
- en: 'Type these in the Julia REPL to check to see if everything is working:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Julia REPL 中输入这些命令来检查一切是否正常：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In VSCode, pressing SHIFT-ENTER while the code is selected, executes it and
    outputs the result in the Julia REPL underneath. You can just cut the code from
    this article, paste it into VSCode, select it, and press SHIFT-ENTER to execute
    it. To facilitate this method, I am going to be skipping the `julia>` prompt in
    the code. Note that you can type all these commands into the REPL, even the long
    ones with for-loops or functions in them.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在 VSCode 中，当代码被选中时，按 SHIFT-ENTER 可以执行它，并在下方的 Julia REPL 中输出结果。你可以直接从本文中剪切代码，粘贴到
    VSCode 中，选择代码，然后按 SHIFT-ENTER 执行它。为了方便这种方法，我将跳过代码中的 `julia>` 提示。请注意，你可以在 REPL
    中输入所有这些命令，即使是包含 for-loops 或函数的长命令。
- en: 'Next, let’s load Plots. Your UI may be a little different as Julia might download
    and install some of the packages. We will also need DelimitedFiles and Statistics
    packages:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们加载 Plots。你的用户界面可能会有所不同，因为 Julia 可能会下载和安装一些包。我们还需要 DelimitedFiles 和 Statistics
    包：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: That last line should generate a graph as seen in the screenshot above.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一行应该会生成一个如上图所示的图形。
- en: Word Datasets
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 词汇数据集
- en: 'Several word datasets are available online with varying degrees of cleanliness.
    Unfortunately, I don’t have permission to use most of them in this article. I
    have chosen SCOWL (Spell Checker Oriented Word Lists) and Friends, a database
    of information on English words useful for creating high-quality word lists suitable
    for use in spell checkers of most dialects of English, and is available for our
    [use](http://wordlist.aspell.net/scowl-readme/). Other word lists available to
    the public for educational purposes should you decide to explore them are listed
    here:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '[Infochimp''s simple English word list](https://github.com/dwyl/english-words)
    is a list of English words by Infochimp. The GitHub site provides the list but
    specifies that the copyright lies with Infochimp. The link to Infochimp goes to
    a non-existent page.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Collins Official Scrabble™ Words](https://www.collinsdictionary.com/games/scrabble/tools)
    list is endorsed by [WESPA](https://www.wespa.org/) for use in Tournament & Club
    play worldwide, excluding USA and Canada. The software is made [available](https://github.com/scrabblewords?tab=repositories)
    for private, non-commercial use only. It is an excellently curated list of English
    words.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Wordle Guess List](https://gist.github.com/dracos/dd0668f281e685bad51479e5acaadb93)
    is the complete list of 13K allowed words in the game and is copyrighted by Josh
    Wardle and now probably by the NY Times. This list closely matches the subset
    of 5-letter words from the Scrabble list above. The answer list, which is the
    2.5K possible answers for Wordle can be found [here](https://www.wordunscrambler.net/word-list/wordle-word-list).'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let's go ahead and grab the SCOWL word list and get it prepared for analysis.
    Head over to [http://app.aspell.net/create](http://app.aspell.net/create) and
    download the word list. The options I selected are shown here. I used the 80-size
    list for the next part and named the file scowl_american_words_80.txt.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/163d525c2cfb7657b8aec3078969dc06.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
- en: Image of options chosen for generating the word list. Screenshot by the Author.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: I also downloaded the 35-size option and named it scowl_american_ words_35.txt.
    I use this for analyzing more common words later in the article.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: For word usage, I use the presidential speeches available at [Miller Center](https://millercenter.org/the-presidency/presidential-speeches)¹.
    The speeches are in the public domain, so there are no restrictions on their use.
    Simply select the name of the president, click on the speech, and then click on
    the transcript. I copied the text and pasted it into a text editor (VSCode) for
    analysis.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '**Why 5-letter words?**'
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/95acbaadb23fee399a80f37672431646.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: Photo by [Glen Carrie](https://unsplash.com/@glencarrie?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/oHoBIbDj7lo?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: My good friend and neighbor, Milan, brought up this question. He thought perhaps
    5-letter words might be the most common in the English language. It’s certainly
    worth checking by loading the SCOWL word list dataset we discussed in setup and
    computing the frequency of word lengths.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我的好朋友和邻居Milan提出了这个问题。他认为5字母词汇可能是英语中最常见的词汇。通过加载我们在设置中讨论的SCOWL词汇表数据集并计算词汇长度的频率，这确实值得检查。
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The aspell wordlist contains possessives like `zymurgy's` and proper nouns like
    `Albert.` Let’s get rid of them
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: aspell词汇表包含了像`zymurgy's`这样的所有格词和像`Albert.`这样的专有名词。让我们把它们去掉。
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, we should build a histogram for word lengths. We can do this in three
    ways that I know of; list comprehension, map function, and for-loop. They should
    all be approximately the same in Julia with regard to performance. Let’s take
    a look:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们应该为词汇长度构建一个直方图。我知道有三种方法可以做到这一点：列表推导、map函数和for循环。考虑到性能，在Julia中它们都应该差不多。让我们来看看：
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Generally speaking, while the list comprehension is slightly better in performance,
    they are all pretty close and I would pick the for-loop as it makes the logic
    clear and easy to follow. Now, the *word lengths* array should contain the length
    of each word. The min and max are:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，虽然列表推导在性能上略好，但它们都非常接近，我会选择for循环，因为它使逻辑清晰易懂。现在，*词汇长度*数组应该包含每个词的长度。最小值和最大值是：
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The min is 1 and the max is 45, but for the purpose of the histogram, I decided
    to put all the words greater than 20 in the “20” bin ( `len>20 ? 20 : len)`. Now
    let’s look at the distribution of each word length. Julia Plots make it easy.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '最小值为1，最大值为45，但为了直方图的目的，我决定将所有大于20的词汇放入“20”箱中（`len>20 ? 20 : len`）。现在，让我们来看看每个词汇长度的分布。Julia
    Plots使这一过程变得简单。'
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/6a27f2e0991e8315cf4f2a3d5792c67e.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a27f2e0991e8315cf4f2a3d5792c67e.png)'
- en: Word Lengths in the English words dataset. Image by the Author
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 英语词汇数据集中的词汇长度。图像作者提供
- en: I actually ran the command above with some options to make the graph look a
    little more informative.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我实际上用了一些选项运行了上述命令，以使图表看起来更具信息性。
- en: '[PRE7]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: And surprise, 5-letter words aren’t even in the 5 most frequent word lengths!
    They make up just 4.6% of our word dataset. Ravi Parikh² and Reginald Smith³ also
    report similar findings (5.2%). The difference may be because I chose a word dataset
    which probably does not have slang, hyphenated words, etc.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 令人惊讶的是，5字母词汇甚至不在前五个最常见的词汇长度中！它们仅占我们词汇数据集的4.6%。Ravi Parikh²和Reginald Smith³也报告了类似的发现（5.2%）。差异可能是因为我选择了一个不包含俚语、连字符词等的词汇数据集。
- en: Firstly, the graph looks like a classic bell curve distribution. This bell-shaped
    curve is a common feature of nature and psychology⁴ such as birthweights of babies,
    the heights of males, blood pressure measurements, etc. I am no linguist, but
    in my opinion, this reveals to me that the English language seemed to have evolved
    as if it were nature-based and random.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，图表看起来像经典的钟形曲线分布。这种钟形曲线是自然界和心理学中常见的特征⁴，例如婴儿出生体重、男性身高、血压测量等。我不是语言学家，但在我看来，这表明英语语言似乎像是自然基础和随机演化的。
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The most common word lengths are 8 and 9, but I can’t seem to readily think
    of any. So, let’s list a few to make sure:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的词汇长度是8和9，但我似乎很难想到任何一个。因此，让我们列出几个以确保：
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: AASVOGELS? Apparently, it’s a South African vulture. SASSAFRAS? No wonder I
    am no good at Scrabble.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: AASVOGELS？显然，这是南非的一种秃鹫。SASSAFRAS？难怪我在拼字游戏中不太行。
- en: So, how many 5-letter words are there?
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，有多少5字母词汇呢？
- en: '[PRE10]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As opposed to 36K 9-letter words, there are only 11K 5-letter words. Hmm …
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 相较于36K个9字母词汇，5字母词汇只有11K个。嗯……
- en: '**Then why 5-letter words for Wordle?**'
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**那么为什么Wordle使用5字母词汇？**'
- en: Perhaps we use them more.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 也许我们使用它们更多。
- en: My editor Megan, the good lady who helps me with these articles, was of the
    opinion that an average person is most comfortable with 5-letter words. This would
    mean that 5-letter words should make up most of our communication and appear at
    a higher frequency. To validate this theory, I turned to presidential speeches.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我的编辑Megan，那个帮助我写这些文章的好女士，认为普通人最适应5字母词汇。这意味着5字母词汇应该占据我们交流的大部分，并且出现频率较高。为了验证这个理论，我查看了总统演讲。
- en: Presidential speeches are often written professionally for a wide audience that
    includes people from different backgrounds and perspectives, so it’s important
    for the writing to be inclusive, culturally sensitive, and accessible. The speechwriter
    must also have a deep understanding of current events and political issues to
    effectively communicate the president’s stance and goals. There is a lot riding
    on a presidential speech, as it can impact public opinion and shape the political
    discourse. And hence, they make excellent representative texts of the language
    of that time.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 总统演讲通常是为不同背景和观点的广泛受众专业撰写的，因此写作必须具有包容性、文化敏感性和可及性。演讲稿撰写者还必须对当前事件和政治问题有深刻的理解，以有效传达总统的立场和目标。总统演讲对公众舆论和政治话语的形成有着重要影响，因此它们成为了那个时代语言的极佳代表文本。
- en: And these speeches are in the public domain and easily [accessible](https://millercenter.org/the-presidency/presidential-speeches)
    for us to analyze¹.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这些演讲属于公有领域，且易于[访问](https://millercenter.org/the-presidency/presidential-speeches)进行分析¹。
- en: For this exercise, I grabbed speeches from the last four presidents of the United
    States of America. I then analyzed the word lengths and graphed them.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这项练习，我抓取了美国过去四位总统的演讲。我分析了单词长度并进行了图示。
- en: To make the graphing easy, I wrote a function to return the histogram data.
    Words that are longer than 18 letters, get bucketed under 18 letters.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化图表绘制，我编写了一个函数来返回直方图数据。长度超过18个字母的单词，会被归入18字母以下的桶中。
- en: '[PRE11]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: I am using the Poor man’s tokenizer. A tokenizer, essentially, splits a text
    into words or sub-words so we can process them individually. Poor man’s tokenizer
    deletes all punctuation and splits into spaces, which isn’t all that sophisticated
    but is enough for our purpose.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了穷人版的分词器。分词器本质上是将文本拆分为单词或子单词，以便我们可以逐个处理它们。穷人版分词器删除所有标点符号，并按空格拆分，虽然不够复杂，但足够满足我们的目的。
- en: Julia’s tokenizer interface takes a `text` as input and returns an array of
    individual words. Then, we simply loop through all the words in the array, compute
    the length and increment the bucket that represents that length.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Julia的分词器接口接受一个`text`作为输入，并返回一个单词数组。然后，我们简单地遍历数组中的所有单词，计算长度，并增加表示该长度的桶。
- en: Now that the function is ready, we can process the speech files in text format.
    First, let’s take a look at the inaugural speeches found [here](https://millercenter.org/the-presidency/presidential-speeches).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在函数已经准备好，我们可以处理文本格式的演讲文件。首先，让我们看看[这里](https://millercenter.org/the-presidency/presidential-speeches)的就职演讲。
- en: '[PRE12]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: So, we process each inaugural speech and create an array of buckets. We horizontally
    concatenate ( `hcat`) them to get a single 18x5 array that we can plot.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们处理每篇就职演讲，并创建一个桶数组。我们将这些数组水平拼接（`hcat`），得到一个可以绘制的单一18x5数组。
- en: '[PRE13]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The first line above does the plot and then I save the graph as an image file.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的第一行绘制了图表，然后我将图表保存为图像文件。
- en: '![](../Images/0ef5fa66d7a0e7996f0fd73b9c2228df.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0ef5fa66d7a0e7996f0fd73b9c2228df.png)'
- en: Word length in presidential speeches. Image by the Author.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 总统演讲中的单词长度。图片来源：作者。
- en: The graph here shows the distribution for each of the speeches. For example,
    under 3% of all unique words that made up President Obama’s inaugural speech consisted
    of 2-letter words
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的图表显示了每篇演讲的分布。例如，奥巴马总统的就职演讲中不到3%的独特单词由2个字母的单词组成。
- en: 5-letter words seem to be popular along with 4, 6-letter words. Note that while
    9-letter words make up 15% of the dictionary, they only constitute less than 8%
    of all unique words used in the speech.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 5个字母的单词似乎很受欢迎，同时4个和6个字母的单词也不少。注意，虽然9个字母的单词占字典的15%，但在演讲中只占所有独特单词的不到8%。
- en: Now, let's look at a more unscripted setting. This should give us an idea of
    daily diction instead of well-thought-through scripted work. I pick one press
    conference for each of the last four presidents and analyze them.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看一下更为即兴的环境。这应该能给我们一个日常用词的感觉，而不是经过深思熟虑的脚本化工作。我选择了过去四位总统中的每位的一个新闻发布会进行分析。
- en: '[PRE14]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'And plot the results:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 然后绘制结果：
- en: '[PRE15]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](../Images/68650cd1995cfa74a7f9fb1fdeaf8117.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/68650cd1995cfa74a7f9fb1fdeaf8117.png)'
- en: Word length of presidential press conferences. Image by the Author.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 总统新闻发布会中的单词长度。图片来源：作者。
- en: Here the pattern is clearer. Except for President Biden (who seems to favor
    4-letter words), 5-letter words are a clear winner.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的模式更加清晰。除了拜登总统（他似乎偏爱4个字母的单词）之外，5个字母的单词明显更受欢迎。
- en: In literature and online, we can find further evidence of this fact. The average
    word length of articles in the New York Times apparently is 4.9⁵. According to
    [WolframAlpha](https://www.wolframalpha.com/input?i=average+english+word+length),
    the average word length in the English language works is 5.1 characters. The same
    site also claims that the average word length for Encyclopaedia Britannica Online
    is 5.3 and for Wikipedia, it is 5.2\. This article has an average of 4.75 letters
    per word, computed [here](https://countwordsworth.com/). That doesn’t seem like
    too bad of a company.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在文学和网络上，我们可以找到更多的证据。纽约时报文章的平均单词长度显然是4.9⁵。根据[WolframAlpha](https://www.wolframalpha.com/input?i=average+english+word+length)，英语中的平均单词长度是5.1个字符。该网站还声称，《大英百科全书在线》的平均单词长度为5.3，而维基百科为5.2。本文的单词平均长度为4.75个字母，计算[这里](https://countwordsworth.com/)。这似乎不算太差。
- en: So, why 5 letters? In English, our diction appears to make up of 5-letter words
    even though there is a larger variety of words that are longer to choose from.
    Perhaps Josh Wardle tried four, five, and six and decided five makes the most
    sense for the target audience and the target time to solve it. The game should
    be a little challenging so you feel like you accomplished something but not too
    hard. Or, though less likely, he went through this kind of analysis and decided
    on five letters. Guess we will never know.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么是5个字母呢？在英语中，我们的词汇似乎由5个字母的单词组成，尽管有更多更长的单词可供选择。也许Josh Wardle尝试了四个、五个和六个字母，决定五个字母最适合目标受众和解决时间。游戏应该有一点挑战性，这样你会觉得自己完成了一些事情，但又不会太难。或者，虽然可能性较小，他可能经过了这种分析并决定了五个字母。我们可能永远不会知道。
- en: Letter Frequency
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 字母频率
- en: '![](../Images/057867e72a40485bfab375742041096e.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/057867e72a40485bfab375742041096e.png)'
- en: Photo by [Isaac Smith](https://unsplash.com/es/@isaacmsmith?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/6EnTPvPPL6I?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Isaac Smith](https://unsplash.com/es/@isaacmsmith?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)提供，来源于[Unsplash](https://unsplash.com/photos/6EnTPvPPL6I?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: Now that we have put the question of why five letters to bed, let’s focus on
    improving our game.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经把为什么是五个字母的问题搞清楚了，就让我们专注于改进我们的游戏。
- en: One strategy for playing Wordle is to maximize hits (yellows or greens) so as
    to reduce the number of total guesses. An obvious approach is to choose words
    with the most common letters in them⁶. Simulations at the University College Dublin
    found that the mean number of guesses could go from 5 to 4, based on a good first-word
    choice⁷. This is where letter frequency analysis can help.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 玩Wordle的一种策略是最大化命中率（黄色或绿色），以减少总猜测次数。显而易见的方法是选择包含最常见字母的单词⁶。都柏林大学的模拟发现，根据一个好的首字母选择，平均猜测次数可以从5减少到4⁷。这就是字母频率分析可以帮助的地方。
- en: First, let’s do some work on the entire word dataset we downloaded earlier.
    These will include words of all lengths. Once we have figured out the frequency
    in all English words, we can compare that with letter frequency in 5-letter words
    to see if there are any significant differences.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们处理一下我们之前下载的整个单词数据集。这些将包括所有长度的单词。一旦我们弄清楚了所有英语单词中的频率，我们可以将其与5个字母单词中的字母频率进行比较，看看是否有显著差异。
- en: I can’t readily think of a way to do this using list comprehension. However,
    “map” and “for-loop” are quite easy. Since the map was a little faster, let’s
    do that first.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我暂时想不到用列表推导的方式来做这个。不过，“map”和“for-loop”相当简单。由于map稍微快一些，我们先用它。
- en: '[PRE16]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'I don’t know about you, but if that wasn’t my code, I’d be a little lost as
    to what it is doing. Let’s see if for-loop is any better:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我不知道你怎么样，但如果这不是我的代码，我可能会对它的作用感到有些迷惑。让我们看看for循环是否更好：
- en: '[PRE17]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This one I can read: a for-loop for the words and then a for-loop for the characters.
    After that, I simply tally the letters. The performance isn’t that bad either,
    a ten percent drop with increased readability seems worth it.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这个我可以读懂：一个针对单词的for循环，然后是一个针对字符的for循环。之后，我只是简单地统计字母。性能也不差，增加可读性带来的百分之十的下降似乎是值得的。
- en: 'Let’s graph this array:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制这个数组：
- en: '[PRE18]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: And here it is.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是结果。
- en: '![](../Images/c7a86e3c0827cb89d4ef8a8bb21573d8.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c7a86e3c0827cb89d4ef8a8bb21573d8.png)'
- en: Percent of appearance of letters in the entire word dataset. Image by the Author.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 字母在整个单词数据集中的出现百分比。图片由作者提供。
- en: The way the code works, we ended up counting 2 for an ‘E’ in ‘SLEEP’. That is
    why we are seeing over 100% for the appearance of E in the dataset. We should
    only count 1, even if the letter appears more than once in the word. We can fix
    this by simply removing duplicate characters in the word, before doing the tally.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 由于代码的工作方式，我们最终对 ‘SLEEP’ 中的‘E’进行了 2 次计数。这就是为什么我们在数据集中看到 E 的出现率超过 100%。我们应该只计数
    1 次，即使字母在单词中出现多次。我们可以通过在计数之前简单地去除单词中的重复字符来解决这个问题。
- en: '[PRE19]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'I changed the `collect`in the second for-loop to `unique`. Now, let’s graph
    both and see if things change:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我将第二个 for 循环中的 `collect` 更改为 `unique`。现在，让我们绘制两个图表，看看是否有变化：
- en: '[PRE20]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Here is the graph:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这是图表：
- en: '![](../Images/a8a15e3bb31ef34fd45d8ad903d33058.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a8a15e3bb31ef34fd45d8ad903d33058.png)'
- en: Comparison of the count of appearances with and without unique letters. Image
    by the Author.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 有无独特字母的出现次数比较。图片由作者提供。
- en: I can’t see anything majorly different in the patterns. The most frequent letters
    are the most repeating. We can use the unique letters to drive our word choice
    decision in Wordle from this point forward.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我没有看到模式上有什么显著的不同。最常出现的字母也是出现次数最多的。从现在起，我们可以使用独特的字母来推动我们在 Wordle 中的词汇选择决策。
- en: The guess and answer word sets
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 猜测词和答案词集合
- en: The above analysis is for the entire English word dataset, however, would it
    be different with just the 5-letter words? Let’s find out. Let's make a new array
    with just the 5-letter words using the `filter` Julia keyword.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 上述分析适用于整个英语词汇数据集，不过，仅考虑 5 个字母的词汇会有所不同吗？让我们找出答案。使用 `filter` Julia 关键字，我们来制作一个只包含
    5 个字母的词汇的新数组。
- en: '[PRE21]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The official Wordle [guess word list](https://github.com/tabatkins/wordle-list/blob/main/words)
    contains slightly under 13K words. So, we are close enough. These are words that
    you are allowed to enter in the game box. The [Wordle answer word](https://www.wordunscrambler.net/word-list/wordle-word-list)
    list is a subset that contains 2.3K words and constitutes only words that could
    possibly come as the hidden answer. So, why the difference?
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 官方 Wordle [猜测词汇表](https://github.com/tabatkins/wordle-list/blob/main/words)
    包含略低于 13K 个词汇。所以，我们已经足够接近了。这些是你可以在游戏框中输入的词汇。[Wordle 答案词汇表](https://www.wordunscrambler.net/word-list/wordle-word-list)
    是一个子集，包含 2.3K 个词汇，只包含可能作为隐藏答案出现的词汇。那么，为什么会有差异呢？
- en: Josh Wardle and his partner, Palak Shah, created a curated list of [answer words](https://www.wordunscrambler.net/word-list/wordle-word-list)
    avoiding obscure and cryptic words to make the game fun for everyone⁸. While you’ll
    find ZOPPA is a valid guess word that you can use, don’t hold your breath for
    it to appear as the answer any time soon.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: Josh Wardle 和他的伙伴 Palak Shah 创建了一个经过精心筛选的 [答案词汇表](https://www.wordunscrambler.net/word-list/wordle-word-list)，避免了晦涩和难解的词汇，以便让游戏对每个人都充满乐趣⁸。虽然你会发现
    ZOPPA 是一个有效的猜测词，但不要指望它很快会出现作为答案。
- en: To see if there is a difference in letter frequency patterns between the two,
    let’s generate that list as well. I use the size-35 [aspell](http://app.aspell.net/create)
    word list as a starting point as it is supposed to have more common English words
    in it.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 为了查看两者之间的字母频率模式是否存在差异，让我们也生成那个列表。我使用了 size-35 的 [aspell](http://app.aspell.net/create)
    词汇表作为起点，因为它应该包含更多常见的英语词汇。
- en: '[PRE22]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This list contains 39K words as compared to 343K words in the 85-size word list.
    Let’s filter for just the 5-letter words.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这个列表包含 39K 个词汇，而 85 大小的词汇表则包含 343K 个词汇。让我们只筛选出 5 个字母的词汇。
- en: '[PRE23]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Wardle and Shah also removed all the plural words from their answer word list.
    Plurals such as CROPS, ROCKS, DROPS, etc have been removed from the answer list
    where as they are still present in the guess list. Let’s see how many plurals
    we have roughly.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Wardle 和 Shah 还从他们的答案词汇表中删除了所有的复数词汇。像 CROPS、ROCKS、DROPS 等复数形式的词汇已经从答案列表中删除，而它们仍然存在于猜测列表中。让我们大致看看有多少复数词汇。
- en: '[PRE24]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 35% or 1185 of the 3467 words in the guess word list are plurals! CROSS, CLASS,
    etc. are some representative words in the answer list and they do not have a 3
    or 4-letter singular variant (all of these words have already appeared in Wordle,
    so no spoilers here).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在猜测词汇表中，35% 或 1185 个词汇是复数！CROSS、CLASS 等是答案列表中的一些代表性词汇，它们没有 3 或 4 个字母的单数变体（这些词汇已经在
    Wordle 中出现过，因此这里没有剧透）。
- en: This explains why recently, my good friend, Sirisha, uncharacteristically struggled
    with that day’s word, finally solving it in 6 tries. She is an active member of
    my middle school group which solves Wordle on a daily basis and is usually very
    good at it. However, she felt that she had too many choices not knowing that 30%
    of the plurals forms were removed from the answer list⁸. Now armed with this information,
    she is unlikely to get stumped next time an S is flagged green in 5th slot. And
    so are we.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这解释了为什么最近我的好朋友 Sirisha 在那天的单词上表现得与平时不同，最终用 6 次尝试解决了它。她是我们中学小组的活跃成员，该小组每天解决 Wordle，并且通常表现很好。然而，她觉得选择太多，不知道答案列表中已经去除了
    30% 的复数形式⁸。现在掌握了这些信息，她不太可能在下次 S 在第 5 位标记为绿色时被难住，我们也是如此。
- en: Before we start analyzing the answer list for patterns, let's take a look at
    the letter frequency in the three sets we have so far; the entire 85-word list,
    5-letter guess word list, and the 5-letter answer word list.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始分析答案列表的模式之前，让我们看看目前拥有的三组字母频率；完整的 85 个单词列表、5 个字母的猜测单词列表和 5 个字母的答案单词列表。
- en: Let’s write a helper function to load the word lists,
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写一个辅助函数来加载单词列表，
- en: '[PRE25]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: With the function ready, let’s load it up.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 函数准备好了，我们加载它吧。
- en: '[PRE26]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: And now the comparison plot,
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是比较图，
- en: '[PRE27]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: I concatenated the frequencies and then, plotted them on the line plot.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我将频率串联起来，然后在折线图上绘制它们。
- en: '![](../Images/89699e816906cd739c58fc68d0d27b41.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/89699e816906cd739c58fc68d0d27b41.png)'
- en: Letter frequencies for words from the entire dataset, guess, and answer lists.
    Image by the Author.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 来自整个数据集、猜测和答案列表的字母频率。图片由作者提供。
- en: In the graph above, each data point indicates the percentage of words that contain
    that specific letter. As an example, for A, 47% of all words in the English word
    list have at least one A in them. Comparatively, only 37% of the words in the
    guess, and answer word list contain an A. The difference between the frequency
    percent is due probably to the longer words in the English word list as some of
    the letters like A, E, I, R etc. appear with higher frequency in longer words.
    We already know that S is so much lower in the answer word list because of the
    removal of plurals.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的图表中，每个数据点表示包含特定字母的单词百分比。例如，对于 A，47% 的所有英语单词中至少有一个 A。相比之下，猜测和答案单词列表中的单词中只有
    37% 包含 A。频率百分比之间的差异可能是由于英语单词列表中的长单词，因为像 A、E、I、R 等字母在长单词中出现的频率较高。我们已经知道，答案单词列表中的
    S 频率低得多，这是因为去除了复数形式。
- en: Looking at the guess list may give incorrect patterns for S. So, let’s focus
    on the answer list and analyze it for trends in more detail.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 查看猜测列表可能会给出不正确的 S 模式。因此，让我们专注于答案列表，并更详细地分析其趋势。
- en: Frequency of letters
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 字母频率
- en: We will now plot the letter frequency in sequential order so that the letters
    with the highest frequency of appearance are shown on top of the graph.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将按顺序绘制字母频率，以便在图表的顶部显示出现频率最高的字母。
- en: '[PRE28]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Julia’s sortperm return a permutation vector `I` that puts `cfAnswerlist[I]`
    in sorted order. The bar chart gets `cfAnswerlist[listOrder]` which is a sorted
    list of frequency values. The yticks parameter of the `bar` function is assigned`('A':'Z')[listOrder]`
    , which sorts the array from A to Z in order of decreasing frequencies.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Julia 的 sortperm 返回一个排列向量 `I`，将 `cfAnswerlist[I]` 按排序顺序排列。条形图获取 `cfAnswerlist[listOrder]`，这是一个频率值的排序列表。`bar`
    函数的 yticks 参数被分配为 `('A':'Z')[listOrder]`，这将数组从 A 到 Z 按频率递减的顺序排序。
- en: '![](../Images/d1dbb827ad99c82791bc0c8112ee1fca.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d1dbb827ad99c82791bc0c8112ee1fca.png)'
- en: Frequency of appearance of letters in the answer list. Image by the Author.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 答案列表中字母的出现频率。图片由作者提供。
- en: E is the most frequent with it appearing at least once in 52% of the answer
    words. A, R, O, I, and T are the next five. ORATE appears to be a good starting
    word.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: E 是最频繁的字母，至少出现在 52% 的答案单词中。A、R、O、I 和 T 是接下来的五个。ORATE 似乎是一个好的起始词。
- en: V, X, Z, Q, and J are the least common, with J appearing in slightly over 1%
    of the answer list. I haven't verified this, but the analysis stating that XYLYL
    was the worst starting word⁹ seems to be right.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: V、X、Z、Q 和 J 是出现最少的字母，其中 J 出现在答案列表中的比例稍微超过 1%。我还没有验证这一点，但分析指出 XYLYL 是最差的起始词⁹
    看起来是对的。
- en: How to use the distribution
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何使用分布
- en: The distribution of letters in the answer list can be quite useful to study
    and remember. Let’s say you went with your first guess of ‘ORATE’ or (my other
    favorite) ‘AROSE’. For ORATE, You received 3 yellows R, A, and E. The next choice
    could be LASER, WAVER to name a few. I am assuming you are playing using the “Hard
    Mode”. The graph above tells us that, L and S are more likely to be in the answer
    word than the letters W and V. In fact, roughly 3 times as likely. So, my guess
    would be LASER.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 答案列表中字母的分布可以非常有用进行研究和记忆。假设你使用了第一个猜测单词 ‘ORATE’ 或者（我另一个喜欢的）‘AROSE’。对于 ORATE，你得到了
    3 个黄色字母 R、A 和 E。下一个选择可以是 LASER、WAVER 等。我假设你是在使用“困难模式”进行游戏。上面的图表告诉我们，L 和 S 比 W
    和 V 更可能出现在答案单词中。实际上，可能性大约是 W 和 V 的 3 倍。因此，我的猜测是 LASER。
- en: As another example, if you received no hits on AROSE, I usually try ‘UNWIT’
    followed by GLYPH. For a no-hit on ORATE, SULCI can be a good second guess followed
    by NYMPH.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 作为另一个例子，如果你在 AROSE 上没有得到任何匹配，我通常会尝试 ‘UNWIT’，然后是 GLYPH。如果 ORATE 没有匹配，SULCI 可以是一个不错的第二个猜测，然后是
    NYMPH。
- en: As a strategy, you can either remember the fill sequence of frequencies;
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种策略，你可以记住频率的填充顺序；
- en: EAROI TLSDN CUHYP GMBKW FVXZQ J
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: EAROI TLSDN CUHYP GMBKW FVXZQ J
- en: Or, remember the three words ORATE, SULCI, and NYMPH (and D). When you get a
    hit on ORATE, say E, you can start picking letters from SULCI and NYMPH for your
    next word (CLUES comes to mind here).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，记住这三个单词 ORATE、SULCI 和 NYMPH（以及 D）。当你在 ORATE 中得到一个匹配项，比如 E，你可以开始从 SULCI 和
    NYMPH 中挑选字母作为你的下一个单词（这里可以想到 CLUES）。
- en: Other researchers have recommended a similar strategy of picking three words
    with mutually exclusive letters. Nisansa de Silva¹⁰ recommends RAISE, CLOUT, and
    NYMPH. I personally have also used AROSE, UNWIT, and GLYPH in the past.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 其他研究者也推荐了类似的策略，即选择三个字母互不重叠的单词。Nisansa de Silva¹⁰ 推荐了 RAISE、CLOUT 和 NYMPH。我个人也曾使用过
    AROSE、UNWIT 和 GLYPH。
- en: Conclusion
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: '![](../Images/0d7486ff6e274a639a5c0715c07b8a6a.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0d7486ff6e274a639a5c0715c07b8a6a.png)'
- en: Photo by [Sigmund](https://unsplash.com/@sigmund?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/By-tZImt0Ms?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Sigmund](https://unsplash.com/@sigmund?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    拍摄，发布于 [Unsplash](https://unsplash.com/photos/By-tZImt0Ms?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: We’ve looked at two aspects of the game Wordle, using Julia to analyze the words.
    First, I tried to justify the choice of the number of letters (five) in the game
    and, it turns out, our speech and written works tend to use 5-letter words with
    higher frequency than words of other lengths. So, the choice of 5-letters for
    the game makes a lot of sense.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经从两个方面分析了游戏 Wordle，使用 Julia 来分析单词。首先，我试图证明游戏中选择五个字母的合理性。结果发现，我们的口语和书面表达中，五个字母的单词使用频率高于其他长度的单词。因此，选择五个字母的单词对于游戏是很有意义的。
- en: Secondly, we looked at the entire English word list first and then the frequency
    of letters in the five-letter guess and the condensed answer lists. The distribution
    graph for the letters can be used to guess words more effectively. I noted that
    remembering ORATE, SULCI, and NYMPH can help us to guess words that are likely
    to return more hits. Using these letters as a guide will help improve your game.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们首先查看了整个英语单词列表，然后查看了五个字母猜测和浓缩答案列表中字母的频率。字母的分布图可以用来更有效地猜测单词。我注意到记住 ORATE、SULCI
    和 NYMPH 可以帮助我们猜测更可能返回更多匹配的单词。使用这些字母作为指南将有助于提高你的游戏水平。
- en: With these tips in mind, all the best with your next Wordle game tomorrow!
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 记住这些技巧，祝你明天的 Wordle 游戏一切顺利！
- en: References
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Miller Center of Public Affairs, University of Virginia. “Presidential Speeches:
    Downloadable Data.” Accessed March 17, 2022\. [https://millercenter.org/presidential-speeches-downloadable-data](https://millercenter.org/presidential-speeches-downloadable-data).'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 弗吉尼亚大学公共事务米勒中心。“总统演讲：可下载数据。”访问于 2022 年 3 月 17 日。 [https://millercenter.org/presidential-speeches-downloadable-data](https://millercenter.org/presidential-speeches-downloadable-data)。
- en: Ravi Parikh, “Distribution of Word Lengths in Various Languages”, Website [http://www.ravi.io/language-word-lengths](http://www.ravi.io/language-word-lengths)
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Ravi Parikh，《各种语言中的单词长度分布》，网站 [http://www.ravi.io/language-word-lengths](http://www.ravi.io/language-word-lengths)
- en: 'Reginald Smith, “Distinct word length frequencies: distributions and symbol
    entropies”, [https://arxiv.org/ftp/arxiv/papers/1207/1207.2334.pdf](https://arxiv.org/ftp/arxiv/papers/1207/1207.2334.pdf)'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Reginald Smith，《不同单词长度频率：分布与符号熵》，[https://arxiv.org/ftp/arxiv/papers/1207/1207.2334.pdf](https://arxiv.org/ftp/arxiv/papers/1207/1207.2334.pdf)
- en: Liston Tellis, “Normal Distribution — The Bell Curve”, Medium, July 5, 2020\.
    [https://medium.com/analytics-vidhya/normal-distribution-the-bell-curve-4f4a5fc2caaa](https://medium.com/analytics-vidhya/normal-distribution-the-bell-curve-4f4a5fc2caaa)
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Liston Tellis，“正态分布——钟形曲线”，Medium，2020年7月5日，[https://medium.com/analytics-vidhya/normal-distribution-the-bell-curve-4f4a5fc2caaa](https://medium.com/analytics-vidhya/normal-distribution-the-bell-curve-4f4a5fc2caaa)
- en: Ann Wylie, “What’s the best length of a word online?”, Ann Wylie’s blog of writing
    tips, [https://www.wyliecomm.com/2021/11/whats-the-best-length-of-a-word-online/](https://www.wyliecomm.com/2021/11/whats-the-best-length-of-a-word-online/)
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Ann Wylie，“在线词语的最佳长度是什么？”，Ann Wylie的写作技巧博客，[https://www.wyliecomm.com/2021/11/whats-the-best-length-of-a-word-online/](https://www.wyliecomm.com/2021/11/whats-the-best-length-of-a-word-online/)
- en: Ste Knight, “12 Wordle Tips and Tricks to Improve Your Score”, Make Use Of,
    Sept 2022, [https://www.makeuseof.com/wordle-tips-hints-tricks/](https://www.makeuseof.com/wordle-tips-hints-tricks/)
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Ste Knight，“提高你得分的12个Wordle技巧和窍门”，Make Use Of，2022年9月，[https://www.makeuseof.com/wordle-tips-hints-tricks/](https://www.makeuseof.com/wordle-tips-hints-tricks/)
- en: Barry Smyth, “Big Data in Little Wordle”, Jun 2022, Towards Data Science, [https://towardsdatascience.com/big-data-in-little-wordle-306d5502c4d9](/big-data-in-little-wordle-306d5502c4d9)
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Barry Smyth，“Wordle中的大数据”，2022年6月，Towards Data Science，[https://towardsdatascience.com/big-data-in-little-wordle-306d5502c4d9](https://towardsdatascience.com/big-data-in-little-wordle-306d5502c4d9)
- en: Jonathan Lee, “The New York Times is finally making changes to Wordle”, The
    Washington Post, Nov 2022, [https://www.washingtonpost.com/video-games/2022/11/07/wordle-new-answers-new-york-times-update/](https://www.washingtonpost.com/video-games/2022/11/07/wordle-new-answers-new-york-times-update/)
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Jonathan Lee，“纽约时报终于对Wordle做出改变”，华盛顿邮报，2022年11月，[https://www.washingtonpost.com/video-games/2022/11/07/wordle-new-answers-new-york-times-update/](https://www.washingtonpost.com/video-games/2022/11/07/wordle-new-answers-new-york-times-update/)
- en: Brittany Alva, “The Worst Starting Word in Wordle, According to Science”, SVG,
    Mar 2022, [https://www.svg.com/751712/the-worst-starting-word-in-wordle-according-to-science/](https://www.svg.com/751712/the-worst-starting-word-in-wordle-according-to-science/)
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Brittany Alva，“根据科学，Wordle中最糟糕的起始词”，SVG，2022年3月，[https://www.svg.com/751712/the-worst-starting-word-in-wordle-according-to-science/](https://www.svg.com/751712/the-worst-starting-word-in-wordle-according-to-science/)
- en: Nisansa de Silva, “Selecting Seed Words for Wordle using Character Statistics”,
    Feb 2022, *arXiv:2202.03457,* [https://arxiv.org/pdf/2202.03457.pdf](https://arxiv.org/pdf/2202.03457.pdf)
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Nisansa de Silva，“使用字符统计选择Wordle种子词”，2022年2月，*arXiv:2202.03457*，[https://arxiv.org/pdf/2202.03457.pdf](https://arxiv.org/pdf/2202.03457.pdf)
