- en: Visual Question Answering with Frozen Large Language Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/visual-question-answering-with-frozen-large-language-models-353d42791054?source=collection_archive---------4-----------------------#2023-10-09](https://towardsdatascience.com/visual-question-answering-with-frozen-large-language-models-353d42791054?source=collection_archive---------4-----------------------#2023-10-09)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Talking with LLMs about images, without training LLMs on images.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@danielwarfield1?source=post_page-----353d42791054--------------------------------)[![Daniel
    Warfield](../Images/c1c8b4dd514f6813e08e401401324bca.png)](https://medium.com/@danielwarfield1?source=post_page-----353d42791054--------------------------------)[](https://towardsdatascience.com/?source=post_page-----353d42791054--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----353d42791054--------------------------------)
    [Daniel Warfield](https://medium.com/@danielwarfield1?source=post_page-----353d42791054--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbdc4072cbfdc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-question-answering-with-frozen-large-language-models-353d42791054&user=Daniel+Warfield&userId=bdc4072cbfdc&source=post_page-bdc4072cbfdc----353d42791054---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----353d42791054--------------------------------)
    ·18 min read·Oct 9, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F353d42791054&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-question-answering-with-frozen-large-language-models-353d42791054&user=Daniel+Warfield&userId=bdc4072cbfdc&source=-----353d42791054---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F353d42791054&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-question-answering-with-frozen-large-language-models-353d42791054&source=-----353d42791054---------------------bookmark_footer-----------)![](../Images/20a13db13c9eda0a5658fa9c857f7ff0.png)'
  prefs: []
  type: TYPE_NORMAL
- en: “Bridging modalities”, made with MidJourney. All images by the author unless
    otherwise stated.
  prefs: []
  type: TYPE_NORMAL
- en: In this article we’ll use a Q-Former, a technique for bridging computer vision
    and natural language models, to create a visual question answering system. We’ll
    go over the necessary theory, following the [BLIP-2 paper](https://arxiv.org/abs/2301.12597),
    then implement a system which can be used to talk with a large language model
    about an image.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d999ca849fd33e7ae32b9d4a3a667559.png)'
  prefs: []
  type: TYPE_IMG
- en: What we’ll be building
  prefs: []
  type: TYPE_NORMAL
- en: '**Who is this useful for?** Data scientists interested in computer vision,
    natural language processing, and multimodal modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: '**How advanced is this post?** Intermediate. You might struggle if you don’t
    have some experience in both computer vision and natural language processing.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Prerequisites:** High level familiarity with transformers, embeddings, and
    encoder-decoders. All of these topics are covered in the following article:'
  prefs: []
  type: TYPE_NORMAL
