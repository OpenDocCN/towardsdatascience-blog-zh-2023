["```py\nfrom math import log2\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim\nimport torch.profiler\nimport torch.utils.data\nimport torchvision.transforms as T\nfrom torchvision.datasets.vision import VisionDataset\nimport numpy as np\nfrom PIL import Image\n\nimg_size = 32\nnum_classes = 8192\nhidden_size = 50\n\n# simple patch classification model\nclass Net(nn.Module):\n    def __init__(self, img_size=img_size,\n                 hidden_size=hidden_size,\n                 num_classes=num_classes):\n        super().__init__()\n        self.conv_in = nn.Conv2d(3, hidden_size, 3, padding='same')\n        num_hidden = int(log2(img_size))\n        hidden = []\n        for i in range(num_hidden):\n            hidden.append(nn.Conv2d(hidden_size, hidden_size, 3, padding='same'))\n            hidden.append(nn.ReLU())\n            hidden.append(nn.MaxPool2d(2))\n        self.hidden = nn.Sequential(*hidden)\n        self.conv_out = nn.Conv2d(hidden_size, num_classes, 3, padding='same')\n\n    def forward(self, x):\n        x = F.relu(self.conv_in(x))\n        x = self.hidden(x)\n        x = self.conv_out(x)\n        x = torch.flatten(x, 1)\n        return x\n```", "```py\ndef log_softmax(x):\n    return x - x.exp().sum(-1).log().unsqueeze(-1)\n\ndef weighted_nll(pred, target, weight):\n    assert target.max() < num_classes\n    nll = -pred[range(target.shape[0]), target]\n    nll = nll * weight[target]\n    nll = nll / weight[target].sum()\n    sum_nll = nll.sum()\n    return sum_nll\n\n# custom loss definition\nclass CrossEntropyLoss(nn.Module):\n    def forward(self, input, target):\n        pred = log_softmax(input)\n        loss = weighted_nll(pred, target, torch.Tensor([0.1] * num_classes).cuda())\n        return loss\n```", "```py\n# dataset with random patches of size 32x32\nclass FakePatches(VisionDataset):\n    def __init__(self, transform):\n        super().__init__(root=None, transform=transform)\n        self.data = np.random.randint(low=0,high=256,size=(10000,32,32,3),dtype=np.uint8)\n        self.targets = np.random.randint(low=0,high=num_classes,size=(10000),dtype=np.uint16).tolist()\n\n    def __getitem__(self, index):\n        img, target = self.data[index], self.targets[index]\n        img = Image.fromarray(img)\n        if self.transform is not None:\n            img = self.transform(img)\n        return img, target\n\n    def __len__(self) -> int:\n        return len(self.data)\n\ntransform = T.Compose([T.PILToTensor()])\n\ntrain_set = FakePatches(transform=transform)\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=128,\n                               shuffle=True, num_workers=8, pin_memory=True)\n\ndevice = torch.device(\"cuda:0\")\nmodel = Net().cuda(device)\ncriterion = CrossEntropyLoss().cuda(device)\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\nmodel.train()\n\n# training loop wrapped with profiler object\nwith torch.profiler.profile(\n        schedule=torch.profiler.schedule(wait=1, warmup=4, active=3, repeat=1),\n        on_trace_ready=torch.profiler.tensorboard_trace_handler(’./log/example’),\n        record_shapes=True,\n        profile_memory=True,\n        with_stack=True\n) as prof:\n    for step, data in enumerate(train_loader):\n        inputs = data[0].to(device=device, non_blocking=True)\n        labels = data[1].to(device=device, non_blocking=True)\n        inputs = (inputs.to(torch.float32) / 255\\. - 0.5) / 0.5\n        if step >= (1 + 4 + 3) * 1:\n            break\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        optimizer.zero_grad(set_to_none=True)\n        loss.backward()\n        optimizer.step()\n        prof.step()\n```", "```py\n# custom loss definition\nclass CrossEntropyLoss(nn.Module):\n    def forward(self, input, target):\n        with torch.profiler.record_function('log_softmax'):\n            pred = log_softmax(input)\n        with torch.profiler.record_function('define_weights'):\n            weights = torch.Tensor([0.1]*num_classes).cuda()\n        with torch.profiler.record_function('weighted_nll'):\n            loss = weighted_nll(pred, target, weights)\n        return loss\n```", "```py\nclass CrossEntropyLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.weight = torch.Tensor([0.1]*num_classes).cuda()\n\n    def forward(self, input, target):\n        with torch.profiler.record_function('log_softmax'):\n            pred = log_softmax(input)\n        with torch.profiler.record_function('weighted_nll'):\n            loss = weighted_nll(pred, target, self.weight)\n        return loss\n```", "```py\ndef weighted_nll(pred, target, weight):\n    with torch.profiler.record_function('assert'):\n        assert target.max() < num_classes\n    with torch.profiler.record_function('range'):\n        r = range(target.shape[0])\n    with torch.profiler.record_function('index'):\n        nll = -pred[r, target]\n    with torch.profiler.record_function('nll_calc'):\n        nll = nll * weight[target]\n        nll = nll/ weight[target].sum()\n        sum_nll = nll.sum()\n    return sum_nll\n```", "```py\ndef weighted_nll(pred, target, weight):\n    with torch.profiler.record_function('range'):\n        r = torch.arange(target.shape[0], device=\"cuda:0\")\n    with torch.profiler.record_function('index'):\n        nll = -pred[r, target]\n    with torch.profiler.record_function('nll_calc'):\n        nll = nll * weight[target]\n        nll = nll/ weight[target].sum()\n        sum_nll = nll.sum()\n    return sum_nll\n```", "```py\nfor step, data in enumerate(train_loader):\n    inputs = data[0].to(device=device, non_blocking=True)\n    labels = data[1].to(device=device, non_blocking=True)\n    inputs = (inputs.to(torch.float32) / 255\\. - 0.5) / 0.5\n    if step >= (1 + 4 + 3) * 1:\n        break\n    outputs = model(inputs)\n    loss = criterion(outputs, labels)\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()\n    torch.cuda.synchronize()\n    prof.step()\n```", "```py\nclass CrossEntropyLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.weight = torch.Tensor([0.1]*num_classes).cuda()\n\n    def forward(self, input, target):\n        pred = log_softmax(input)\n        nll = torch.nn.NLLLoss(self.weight)\n        loss = nll(pred, target)\n        return loss\n```", "```py\nclass CrossEntropyLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.weight = torch.Tensor([0.1]*num_classes).cuda()\n        self.nll = torch.nn.NLLLoss(self.weight) \n\n    def forward(self, input, target):\n        pred = log_softmax(input)\n        loss = self.nll(pred, target)\n        return loss\n```", "```py\ncriterion = torch.nn.CrossEntropyLoss().cuda(device)\n```", "```py\ncriterion = torch.compile(torch.nn.CrossEntropyLoss().cuda(device))\n```"]