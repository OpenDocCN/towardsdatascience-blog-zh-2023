- en: Bootstrapping Labels with GPT-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/bootstrapping-labels-with-gpt-4-8dc85ab5026d?source=collection_archive---------2-----------------------#2023-06-09](https://towardsdatascience.com/bootstrapping-labels-with-gpt-4-8dc85ab5026d?source=collection_archive---------2-----------------------#2023-06-09)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/7364bb5c4883661737f7aa5783ca675d.png)'
  prefs: []
  type: TYPE_IMG
- en: '(Source: Image generated by author with DALL-E, modified by author.)'
  prefs: []
  type: TYPE_NORMAL
- en: A cost-effective approach to data labeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://jimmymwhitaker.medium.com/?source=post_page-----8dc85ab5026d--------------------------------)[![Jimmy
    Whitaker](../Images/7aa8c0d58dd1244ffca7ed9003cbb1d3.png)](https://jimmymwhitaker.medium.com/?source=post_page-----8dc85ab5026d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8dc85ab5026d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8dc85ab5026d--------------------------------)
    [Jimmy Whitaker](https://jimmymwhitaker.medium.com/?source=post_page-----8dc85ab5026d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff40e6fd303f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbootstrapping-labels-with-gpt-4-8dc85ab5026d&user=Jimmy+Whitaker&userId=f40e6fd303f9&source=post_page-f40e6fd303f9----8dc85ab5026d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8dc85ab5026d--------------------------------)
    ·9 min read·Jun 9, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8dc85ab5026d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbootstrapping-labels-with-gpt-4-8dc85ab5026d&user=Jimmy+Whitaker&userId=f40e6fd303f9&source=-----8dc85ab5026d---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8dc85ab5026d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbootstrapping-labels-with-gpt-4-8dc85ab5026d&source=-----8dc85ab5026d---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: Data labeling is a critical component for machine learning projects. It is built
    on the old adage, “garbage in, garbage out.” Labeling involves creating annotated
    datasets for training and evaluation. But this process can be time-consuming and
    expensive, especially for projects with lots of data. But, what if we could use
    the advances in LLMs to reduce the cost and effort involved in data labeling tasks?
  prefs: []
  type: TYPE_NORMAL
- en: GPT-4 is a state-of-the-art language model developed by OpenAI. It has a remarkable
    ability to understand and generate human-like text and has been a game changer
    in the natural language processing (NLP) community and beyond. In this blog post,
    we’ll explore how you can use GPT-4 to bootstrap labels for various tasks. This
    can significantly reduce the time and cost involved in the labeling process. We’ll
    focus on sentiment classification to demonstrate how prompt engineering can enable
    you to create accurate and reliable labels using GPT-4 and how this technique
    can be used for much more powerful things as well.
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging GPT-4’s Predictions for Data Pre-labeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As in writing, editing is often less strenuous than composing the original work.
    That’s why starting with pre-labeled data is more attractive than starting with
    a blank slate. Using GPT-4 as a prediction engine to pre-label data stems from
    its ability to understand context and generate human-like text. Therefore, it
    would be excellent to leverage GPT-4 to reduce the manual effort required for
    data labeling. This could result in cost savings and make the labeling process
    less mundane.
  prefs: []
  type: TYPE_NORMAL
- en: So how do we do this? If you’ve used GPT models, you’re probably familiar with
    prompts. Prompts set the context for the model before it begins generating output
    and can be tweaked and engineered (i.e. prompt engineering) to help the model
    deliver highly specific results. This means we can create prompts that GPT-4 can
    use to generate text that looks like model predictions. For our use case, we will
    craft our prompts in a way that guides the model toward producing the desired
    output format as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a straightforward example of sentiment analysis. If we are trying
    to classify the sentiment of a given string of text as `positive`, `negative`,
    or `neutral` we could provide a prompt like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have a well-structured prompt, we can use the OpenAI API to generate
    predictions from GPT-4\. Here’s an example using Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We can run this with a single example to inspect the output we’re receiving
    from the API.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Once we’re satisfied with our prompt and the results we’re getting, we can scale
    this up to our entire dataset. Here, we’ll assume a text file with one example
    per line.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We can import the data with pre-labeled predictions into Label Studio and have
    reviewers verify or correct the labels. This approach significantly reduces the
    manual work required for data labeling, as human reviewers only need to validate
    or correct the model-generated labels rather than annotate the entire dataset
    from scratch. See our [full example notebook here](https://gist.github.com/JimmyWhitaker/e2dbf7403f60489048287dc05ec420f6).
  prefs: []
  type: TYPE_NORMAL
- en: Note that in most situations, OpenAI is allowed to use any information sent
    to their APIs to train their models further. So it’s important to not send protected
    or private data to these APIs for labeling if we don’t want to expose the information
    more broadly.
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing Pre-labeled Data in Label Studio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once we have our pre-labeled data ready, we will import it into a data labeling
    tool, such as Label Studio, for review. This section will guide you through setting
    up a Label Studio project, importing the pre-labeled data, and reviewing the annotations.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cb436b1216cf242646e5c6b89f62abb7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Reviewing Sentiment Classification in Label Studio. (Image by author,
    screenshot with Label Studio)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: Install and Launch Label Studio'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, you need to have Label Studio installed on your machine. You can install
    it using pip:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'After installing Label Studio, launch it by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This will open Label Studio in your default web browser.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 2: Create a New Project'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Click on “Create Project” and enter a project name, such as “Review Bootstrapped
    Labels.” Next, you need to define the labeling configuration. For Sentiment Analysis,
    we can use the text [Sentiment Analysis Text Classification](https://labelstud.io/templates/sentiment_analysis.html).
  prefs: []
  type: TYPE_NORMAL
- en: These templates are configurable, so if we want to change any of the properties,
    it’s really straightforward. The default labeling configuration is shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Click “Create” to finish setting up the project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 3: Import Pre-labeled Data'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To import the pre-labeled data, click the “Import” button. Choose the json file
    and select the pre-labeled data file generated earlier (e.g., “output_responses.json”).
    The data will be imported along with the pre-populated predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 4: Review and Update Labels'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After importing the data, you can review the model-generated labels. The annotation
    interface will display the pre-labeled sentiment for each text sample, and reviewers
    can either accept or correct the suggested label.
  prefs: []
  type: TYPE_NORMAL
- en: You can improve quality further by having multiple annotators review each example.
  prefs: []
  type: TYPE_NORMAL
- en: By utilizing GPT-4-generated labels as a starting point, the review process
    becomes much more efficient, and reviewers can focus on validating or correcting
    the annotations rather than creating them from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 5: Export Labeled Data'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once the review process is complete, you can export the labeled data by clicking
    the “Export” button in the “Data Manager” tab. Choose the desired output format
    (e.g., JSON, CSV, or TSV), and save the labeled dataset for further use in your
    machine learning project.
  prefs: []
  type: TYPE_NORMAL
- en: Cost Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One question rolling around in my mind was: “How much did this cost me at the
    end of the day?”'
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: Prices shown below reflect current data for the author at the time of
    publication. Pricing may differ in the future or based on geographic location.*'
  prefs: []
  type: TYPE_NORMAL
- en: For language models, OpenAI charges based on the number of tokens in your request.
    Tokens are typically the number of words in the query, but special characters
    and emojis can sometimes count as an individual token. OpenAI’s pricing page states,
    “You can think of tokens as pieces of words, where 1,000 tokens is about 750 words.”
    For more information on how tokens are counted, [see this page](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them).
  prefs: []
  type: TYPE_NORMAL
- en: The cost per token differs according to the model used. For example, the GPT-4
    8K-context model costs $0.03/1K tokens for the prompt, and each generated token
    costs $0.06/1K tokens, while the GPT-3.5-turbo model costs $0.002/1K tokens.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c57de6757c3495e22ac8e276ba4743b7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Summary of token prices for OpenAI. (Source: [OpenAI forum](https://community.openai.com/t/gpt4-and-gpt-3-5-turb-api-cost-comparison-and-understanding/106192),
    image by author)'
  prefs: []
  type: TYPE_NORMAL
- en: To estimate the cost of pre-labeling a dataset, we can use a simple formula
    that considers the number of examples in the dataset, the price per token for
    prompts and completions, and the average number of tokens per example.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/273980473542534d60bc3c4169530b21.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Where:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a51bc3523be67652d4ce34503a97a9df.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Additionally, we can calculate the total number of tokens in the dataset as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8d1c6cb1efb7289bee820553bea2d4c4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Where:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2eadd9c6d72e7a06d7acf3404a35b44d.png)'
  prefs: []
  type: TYPE_IMG
- en: Using this formula, we can estimate the cost of pre-labeling a dataset by multiplying
    the number of examples by the sum of the prompt cost and the completion cost,
    adjusted for the average number of tokens per example.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, if we have a dataset with 1,000 examples that we want to pre-label
    for sentiment analysis with GPT-4, we can compute it with the following: a prompt
    price of $0.03 per 1K tokens, a completion price of $0.06 per 1K tokens, a prompt
    length of 20 tokens, an average example length of 80 tokens, and an average result
    token length of 3 tokens, the total cost of pre-labeling would be:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/649674d146b05fa6125f41409ff1fd76.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this example, pre-labeling the dataset using GPT-4 would cost $3.18\. Note:
    the same dataset with **GPT-3.5-turbo would cost ~$0.21**.'
  prefs: []
  type: TYPE_NORMAL
- en: If our pre-labeling task requires less specialized knowledge, we may want to
    use a less robust model to save cost. It’s usually worth manually reviewing a
    handful of examples with varying levels of complexity to get a sense of how accurate
    one model is compared to another. For information on the models, see the [OpenAI
    Pricing page](https://openai.com/pricing).
  prefs: []
  type: TYPE_NORMAL
- en: 'Beyond Sentiment Analysis: Label Any NLP Task'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/2c64712f863815f74d4911ebd4f685df.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of Named Entity Recognition in Label Studio. (Image by author, screenshot
    with Label Studio)
  prefs: []
  type: TYPE_NORMAL
- en: The great thing about this approach is that it’s not limited to just sentiment
    analysis. We can pre-label data for various NLP tasks using GPT-4 by using prompt
    engineering and guiding it to produce the correct output. Here are a few examples
    of prompts for different NLP tasks, all of which can be reviewed and labeled in
    Label Studio (examples given were generated using GPT-4). Remember that more complex
    tasks may require longer prompts, which will count towards your token count and
    subsequently, cost.
  prefs: []
  type: TYPE_NORMAL
- en: Summarization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Prompt:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Respond in the json format with a summary for the following text: {‘summary’:
    summary}'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Text: I love going to the park on a sunny day. The customer service was terrible;
    they were rude and unhelpful. I am neither happy nor sad about the new policy
    changes. The cake was delicious and the presentation was fantastic. I had a really
    bad experience with the product; it broke after two days.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Summary:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Taxonomy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Respond in the JSON format with a summary for the following text: {‘diagnosis’:
    diagnosis}, where the possible diagnoses are Pneumonia, Acute bronchitis, Asthma
    exacerbation, Congestive heart failure, Chronic obstructive pulmonary disease
    (COPD), Pulmonary embolism, Pleural effusion, Interstitial lung disease, or Lung
    cancer.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Text: The patient presented with shortness of breath and a persistent cough.
    On physical examination, crackles were heard in the lower lung fields. Chest X-ray
    revealed bilateral infiltrates consistent with pneumonia. The patient was started
    on antibiotics and showed improvement in symptoms within 48 hours.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Diagnosis:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Named Entity Recognition (NER)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: You are an expert NER labeler. Only return JSON. Do not return explanations.
    Return the CoNLL format for the following sentence in JSON format.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In my opinion, there’s no substitute for human evaluation, but using the GPT
    models to give us a starting point can be a huge advantage.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Labeling data is always difficult, and sometimes, even getting that starting
    point is a huge advantage. In this blog, we showed how you can use the GPT models
    by OpenAI to generate predictions for data to serve as the starting point for
    your data labeling workflows. This process can significantly reduce the amount
    of human effort involved, and focus labelers’ attention on providing more value
    for their efforts. Check out the resources for more info on the topics presented
    in this blog.
  prefs: []
  type: TYPE_NORMAL
- en: Resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Full example notebook](https://gist.github.com/JimmyWhitaker/e2dbf7403f60489048287dc05ec420f6)
    — notebook with all code ready to run in Colab'
  prefs: []
  type: TYPE_NORMAL
- en: '[Label Studio](https://labelstud.io/) — Open Source data labeling tool'
  prefs: []
  type: TYPE_NORMAL
- en: '[OpenAI Pricing page](https://openai.com/pricing) — details for the pricing
    estimate in this post'
  prefs: []
  type: TYPE_NORMAL
