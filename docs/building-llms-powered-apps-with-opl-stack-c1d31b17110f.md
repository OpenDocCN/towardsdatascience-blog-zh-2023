# ä½¿ç”¨OPLå †æ ˆæ„å»ºLLMsé©±åŠ¨çš„åº”ç”¨ç¨‹åº

> åŸæ–‡ï¼š[https://towardsdatascience.com/building-llms-powered-apps-with-opl-stack-c1d31b17110f?source=collection_archive---------2-----------------------#2023-04-03](https://towardsdatascience.com/building-llms-powered-apps-with-opl-stack-c1d31b17110f?source=collection_archive---------2-----------------------#2023-04-03)

## OPLï¼šOpenAIã€Pinecone å’Œ Langchain ç”¨äºçŸ¥è¯†é©±åŠ¨çš„AIåŠ©æ‰‹

[](https://medium.com/@wen_yang?source=post_page-----c1d31b17110f--------------------------------)[![Wen Yang](../Images/5eac438762d015a0ab128757cc951967.png)](https://medium.com/@wen_yang?source=post_page-----c1d31b17110f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c1d31b17110f--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c1d31b17110f--------------------------------) [Wen Yang](https://medium.com/@wen_yang?source=post_page-----c1d31b17110f--------------------------------)

Â·

[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcbb5383bd438&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-llms-powered-apps-with-opl-stack-c1d31b17110f&user=Wen+Yang&userId=cbb5383bd438&source=post_page-cbb5383bd438----c1d31b17110f---------------------post_header-----------) å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c1d31b17110f--------------------------------) Â·12 min é˜…è¯»Â·2023å¹´4æœˆ3æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc1d31b17110f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-llms-powered-apps-with-opl-stack-c1d31b17110f&user=Wen+Yang&userId=cbb5383bd438&source=-----c1d31b17110f---------------------clap_footer-----------)

--

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc1d31b17110f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-llms-powered-apps-with-opl-stack-c1d31b17110f&source=-----c1d31b17110f---------------------bookmark_footer-----------)![](../Images/017e9316f7ecbd4f794d51802ab23255.png)

Midjourney æç¤ºï¼šä¸€ä¸ªå¥³å­©ç”¨å¤šä¸ªç§¯æœ¨å—å»ºé€ ä¹é«˜æ¡¥æ¢

æˆ‘è®°å¾—ä¸€ä¸ªæœˆå‰ï¼ŒEugene Yan åœ¨ LinkedIn ä¸Šå‘å¸ƒäº†ä¸€é¡¹ [æŠ•ç¥¨](https://www.linkedin.com/posts/eugeneyan_activity-7029289248209977344-oteC?utm_source=share&utm_medium=member_desktop)ï¼š

> ä½ æ˜¯å¦æ„Ÿåˆ°å› ä¸ºæ²¡æœ‰å‚ä¸LLMs/ç”Ÿæˆå‹AIè€Œé”™å¤±è‰¯æœºï¼Ÿ

å¤§å¤šæ•°äººå›ç­”äº†â€œæ˜¯â€ã€‚è€ƒè™‘åˆ°chatGPTå¼•å‘çš„å¹¿æ³›å…³æ³¨ä»¥åŠç°åœ¨gpt-4çš„å‘å¸ƒï¼Œå¾ˆå®¹æ˜“ç†è§£ä¸ºä»€ä¹ˆä¼šè¿™æ ·ã€‚äººä»¬å½¢å®¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å´›èµ·å°±åƒiPhoneçš„æ—¶åˆ»ã€‚ç„¶è€Œï¼Œæˆ‘è®¤ä¸ºçœŸçš„æ²¡æœ‰å¿…è¦æ„Ÿåˆ°FOMOã€‚è€ƒè™‘ä¸€ä¸‹ï¼šé”™è¿‡äº†å¼€å‘iPhonesçš„æœºä¼šå¹¶ä¸æ’é™¤åˆ›é€ åˆ›æ–°iPhoneåº”ç”¨ç¨‹åºçš„å·¨å¤§æ½œåŠ›ã€‚LLMsä¹Ÿæ˜¯å¦‚æ­¤ã€‚æˆ‘ä»¬åˆšåˆšè¿›å…¥äº†ä¸€ä¸ªæ–°æ—¶ä»£ï¼Œç°åœ¨æ­£æ˜¯åˆ©ç”¨LLMsæ•´åˆæ„å»ºå¼ºå¤§åº”ç”¨ç¨‹åºçš„ç»ä½³æ—¶æœºã€‚

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†æ¶µç›–ä»¥ä¸‹ä¸»é¢˜ï¼š

1.  ä»€ä¹ˆæ˜¯OPLæŠ€æœ¯æ ˆï¼Ÿ

1.  å¦‚ä½•ä½¿ç”¨OPLæ„å»ºå…·æœ‰é¢†åŸŸçŸ¥è¯†çš„chatGPTï¼Ÿï¼ˆåŒ…å«ä»£ç æ¼”ç¤ºçš„å…³é”®ç»„ä»¶ï¼‰

1.  ç”Ÿäº§è€ƒè™‘å› ç´ 

1.  å¸¸è§è¯¯è§£

# 1\. ä»€ä¹ˆæ˜¯OPLæŠ€æœ¯æ ˆï¼Ÿ

![](../Images/5efe1d72069d166bbe99a2cee6c8a240.png)

ä½œè€…åˆ›å»ºçš„å›¾åƒ

**OPLä»£è¡¨OpenAIã€Pineconeå’ŒLangchainï¼Œ** å®ƒå·²é€æ¸æˆä¸ºå…‹æœLLMsä¸¤ä¸ªå±€é™æ€§çš„è¡Œä¸šè§£å†³æ–¹æ¡ˆï¼š

1.  **LLMså¹»è§‰ï¼š** chatGPTæœ‰æ—¶ä¼šæä¾›è¿‡åº¦è‡ªä¿¡çš„é”™è¯¯å›ç­”ã€‚ä¸€ä¸ªæ½œåœ¨çš„åŸå› æ˜¯è¿™äº›è¯­è¨€æ¨¡å‹è¢«è®­ç»ƒå¾—éå¸¸æœ‰æ•ˆåœ°é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼Œæˆ–è€…æ›´å‡†ç¡®åœ°è¯´æ˜¯ä¸‹ä¸€ä¸ªæ ‡è®°ã€‚ç»™å®šè¾“å…¥æ–‡æœ¬ï¼ŒchatGPTä¼šè¿”å›é«˜æ¦‚ç‡çš„è¯ï¼Œè¿™å¹¶ä¸æ„å‘³ç€chatGPTå…·æœ‰æ¨ç†èƒ½åŠ›ã€‚

1.  **çŸ¥è¯†æ›´æ–°ä¸å¤ŸåŠæ—¶ï¼š** chatGPTçš„è®­ç»ƒæ•°æ®ä»…é™äº2021å¹´9æœˆä¹‹å‰çš„äº’è”ç½‘æ•°æ®ã€‚å› æ­¤ï¼Œå¦‚æœä½ çš„é—®é¢˜æ¶‰åŠæœ€è¿‘çš„è¶‹åŠ¿æˆ–è¯é¢˜ï¼Œå®ƒå¯èƒ½ä¼šäº§ç”Ÿä¸å¤ªç†æƒ³çš„å›ç­”ã€‚

å¸¸è§çš„è§£å†³æ–¹æ¡ˆæ˜¯åœ¨LLMsä¸Šæ·»åŠ çŸ¥è¯†åº“ï¼Œå¹¶ä½¿ç”¨Langchainä½œä¸ºæ„å»ºæµæ°´çº¿çš„æ¡†æ¶ã€‚æ¯é¡¹æŠ€æœ¯çš„å…³é”®ç»„ä»¶å¯ä»¥æ€»ç»“å¦‚ä¸‹ï¼š

+   **OpenAI**ï¼š

    - æä¾›å¯¹å¼ºå¤§LLMså¦‚chatGPTå’Œgpt-4çš„APIè®¿é—®

    - æä¾›å°†æ–‡æœ¬è½¬æ¢ä¸ºåµŒå…¥çš„æ¨¡å‹ã€‚

+   **Pinecone**ï¼šæä¾›åµŒå…¥å‘é‡å­˜å‚¨ã€è¯­ä¹‰ç›¸ä¼¼åº¦æ¯”è¾ƒå’Œå¿«é€Ÿæ£€ç´¢ã€‚

+   **Langchain**ï¼šå®ƒåŒ…å«6ä¸ªæ¨¡å—ï¼ˆ`Models`ã€`Prompts`ã€`Indexes`ã€`Memory`ã€`Chains`å’Œ`Agents`ï¼‰ã€‚

    - `Models` æä¾›äº†çµæ´»çš„åµŒå…¥æ¨¡å‹ã€èŠå¤©æ¨¡å‹å’ŒLLMsï¼ŒåŒ…æ‹¬ä½†ä¸é™äºOpenAIçš„äº§å“ã€‚ä½ è¿˜å¯ä»¥ä½¿ç”¨Hugging Faceä¸Šçš„å…¶ä»–æ¨¡å‹ï¼Œå¦‚BLOOMå’ŒFLAN-T5ã€‚

    - `Memory` : æœ‰å¤šç§æ–¹å¼å¯ä»¥è®©èŠå¤©æœºå™¨äººè®°ä½è¿‡å»çš„å¯¹è¯è®°å½•ã€‚æ ¹æ®æˆ‘çš„ç»éªŒï¼Œå®ä½“è®°å¿†æ•ˆæœå¥½ä¸”é«˜æ•ˆã€‚

    - `Chains` : å¦‚æœä½ æ˜¯Langchainçš„æ–°æ‰‹ï¼ŒChainsæ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ã€‚å®ƒéµå¾ªç±»ä¼¼æµæ°´çº¿çš„ç»“æ„æ¥å¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œé€‰æ‹©LLMæ¨¡å‹ï¼Œåº”ç”¨Promptæ¨¡æ¿ï¼Œå¹¶ä»çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³ä¸Šä¸‹æ–‡ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘å°†ä»‹ç»æˆ‘ä½¿ç”¨OPLæŠ€æœ¯æ ˆæ„å»ºçš„åº”ç”¨ç¨‹åºã€‚

# 2\. å¦‚ä½•ä½¿ç”¨OPLæ„å»ºå…·æœ‰é¢†åŸŸçŸ¥è¯†çš„chatGPTï¼Ÿï¼ˆåŒ…å«ä»£ç æ¼”ç¤ºçš„å…³é”®ç»„ä»¶ï¼‰

æˆ‘æ„å»ºçš„åº”ç”¨ç¨‹åºç§°ä¸º[chatOutside](https://outsidechat.streamlit.app/)ï¼Œå®ƒæœ‰ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ï¼š

+   **chatGPT**ï¼šè®©ä½ ç›´æ¥ä¸chatGPTèŠå¤©ï¼Œæ ¼å¼ç±»ä¼¼äºé—®ç­”åº”ç”¨ï¼Œæ¯æ¬¡æ¥æ”¶ä¸€ä¸ªè¾“å…¥å’Œè¾“å‡ºã€‚

+   **chatOutside**ï¼šè®©ä½ ä¸å…·æœ‰æˆ·å¤–æ´»åŠ¨åŠè¶‹åŠ¿ä¸“ä¸šçŸ¥è¯†çš„chatGPTç‰ˆæœ¬è¿›è¡Œå¯¹è¯ã€‚æ ¼å¼æ›´ç±»ä¼¼äºèŠå¤©æœºå™¨äººçš„é£æ ¼ï¼Œæ‰€æœ‰æ¶ˆæ¯åœ¨å¯¹è¯è¿‡ç¨‹ä¸­éƒ½ä¼šè¢«è®°å½•ã€‚æˆ‘è¿˜åŒ…å«äº†ä¸€ä¸ªæä¾›æºé“¾æ¥çš„éƒ¨åˆ†ï¼Œè¿™å¯ä»¥å¢å¼ºç”¨æˆ·ä¿¡å¿ƒï¼Œå¹¶ä¸”æ€»æ˜¯æœ‰ç”¨çš„ã€‚

å¦‚ä½ æ‰€è§ï¼Œå¦‚æœä½ é—®åŒæ ·çš„é—®é¢˜ï¼šâ€œ2023å¹´æœ€å¥½çš„è·‘é‹æ˜¯ä»€ä¹ˆï¼Ÿæˆ‘çš„é¢„ç®—åœ¨$200å·¦å³ã€‚â€chatGPTä¼šè¯´â€œä½œä¸ºä¸€ä¸ªAIè¯­è¨€æ¨¡å‹ï¼Œæˆ‘æ— æ³•è®¿é—®æœªæ¥çš„ä¿¡æ¯ã€‚â€è€ŒchatOutsideä¼šä¸ºä½ æä¾›æ›´åŠæ—¶çš„ç­”æ¡ˆï¼Œå¹¶é™„ä¸Šæºé“¾æ¥ã€‚

![](../Images/90480e9dfc8f81b47e0fe6bf4e2e3f4b.png)

å¼€å‘è¿‡ç¨‹æ¶‰åŠä¸‰ä¸ªä¸»è¦æ­¥éª¤ï¼š

+   ç¬¬ä¸€æ­¥ï¼šåœ¨Pineconeä¸­æ„å»ºå¤–éƒ¨çŸ¥è¯†åº“

+   ç¬¬äºŒæ­¥ï¼šä½¿ç”¨Langchainè¿›è¡Œé—®ç­”æœåŠ¡

+   ç¬¬ä¸‰æ­¥ï¼šåœ¨Streamlitä¸­æ„å»ºæˆ‘ä»¬çš„åº”ç”¨ç¨‹åº

æ¯ä¸ªæ­¥éª¤çš„å®æ–½ç»†èŠ‚å°†åœ¨ä¸‹é¢è®¨è®ºã€‚

## **æ­¥éª¤1ï¼š** åœ¨Pineconeä¸­æ„å»ºå¤–éƒ¨çŸ¥è¯†åº“

+   **æ­¥éª¤1.1ï¼š** æˆ‘è¿æ¥åˆ°æˆ‘ä»¬çš„å¤–éƒ¨ç›®å½•æ•°æ®åº“ï¼Œå¹¶é€‰æ‹©äº†åœ¨2022å¹´1æœˆ1æ—¥è‡³2023å¹´3æœˆ29æ—¥ä¹‹é—´å‘å¸ƒçš„æ–‡ç« ã€‚è¿™ä¸ºæˆ‘ä»¬æä¾›äº†å¤§çº¦20,000æ¡è®°å½•ã€‚

![](../Images/a55bed6eacdefdd3ad7e8a6bb57cae7c.png)

å¤–éƒ¨çš„ç¤ºä¾‹æ•°æ®é¢„è§ˆ

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦è¿›è¡Œä¸¤ä¸ªæ•°æ®è½¬æ¢ã€‚

+   **æ­¥éª¤1.2ï¼š** å°†ä¸Šè¿°æ•°æ®æ¡†è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨ï¼Œä»¥ç¡®ä¿æ•°æ®å¯ä»¥æ­£ç¡®åœ°æ’å…¥åˆ°Pineconeä¸­ã€‚

```py
# Convert dataframe to a list of dict for Pinecone data upsert
data = df_item.to_dict('records')
```

+   **æ­¥éª¤1.3ï¼š** ä½¿ç”¨Langchainçš„`RecursiveCharacterTextSplitter`å°†`content`æ‹†åˆ†æˆæ›´å°çš„å—ã€‚å°†æ–‡æ¡£æ‹†åˆ†ä¸ºæ›´å°çš„å—æœ‰ä¸¤ä¸ªå¥½å¤„ï¼š

    - ä¸€ç¯‡å…¸å‹æ–‡ç« å¯èƒ½è¶…è¿‡1000ä¸ªå­—ç¬¦ï¼Œè¿™éå¸¸é•¿ã€‚æƒ³è±¡ä¸€ä¸‹æˆ‘ä»¬æƒ³æ£€ç´¢å‰3ç¯‡æ–‡ç« ä½œä¸ºæç¤ºç»™chatGPTï¼Œæˆ‘ä»¬å¾ˆå®¹æ˜“å°±ä¼šè¶…è¿‡4000ä¸ªå­—å…ƒé™åˆ¶ã€‚

    - æ›´å°çš„å—æä¾›æ›´ç›¸å…³çš„ä¿¡æ¯ï¼Œä»è€Œä¸ºchatGPTæä¾›æ›´å¥½çš„æç¤ºä¸Šä¸‹æ–‡ã€‚

```py
from langchain.text_splitter import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=400,
    chunk_overlap=20,
    length_function=tiktoken_len,
    separators=["\n\n", "\n", " ", ""]
)
```

åˆ†å‰²åï¼Œæ¯æ¡è®°å½•çš„å†…å®¹è¢«æ‹†åˆ†æˆå¤šä¸ªéƒ¨åˆ†ï¼Œæ¯ä¸ªéƒ¨åˆ†å°‘äº400ä¸ªå­—å…ƒã€‚

![](../Images/309b912e454adbd6526dcc71bbd2aab6.png)

å°†å†…å®¹æ‹†åˆ†ä¸ºå¤šä¸ªå—

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä½¿ç”¨çš„æ–‡æœ¬åˆ†å‰²å™¨ç§°ä¸º`RecursiveCharacterTextSplitter`ï¼Œè¿™æ˜¯Langchainçš„åˆ›å»ºè€…Harrison Chaseæ¨èä½¿ç”¨çš„ã€‚åŸºæœ¬æ€è·¯æ˜¯é¦–å…ˆæŒ‰æ®µè½æ‹†åˆ†ï¼Œç„¶åæŒ‰å¥å­æ‹†åˆ†ï¼Œé‡å ï¼ˆ20å­—å…ƒï¼‰ã€‚è¿™æœ‰åŠ©äºä¿ç•™æ¥è‡ªå‘¨å›´å¥å­çš„æœ‰æ„ä¹‰ä¿¡æ¯å’Œä¸Šä¸‹æ–‡ã€‚

+   **æ­¥éª¤ 1.4ï¼š** å°†æ•°æ®æ’å…¥ Pineconeã€‚ä¸‹é¢çš„ä»£ç æ”¹ç¼–è‡ª [James Briggs](https://medium.com/u/b9d77a4ca1d1?source=post_page-----c1d31b17110f--------------------------------) çš„ç²¾å½© [æ•™ç¨‹](https://github.com/pinecone-io/examples/blob/master/generation/langchain/handbook/05-langchain-retrieval-augmentation.ipynb)ã€‚

```py
import pinecone
from langchain.embeddings.openai import OpenAIEmbeddings

# 0\. Initialize Pinecone Client
with open('./credentials.yml', 'r') as file:
    cre = yaml.safe_load(file)
    # pinecone API
    pinecone_api_key = cre['pinecone']['apikey']

pinecone.init(api_key=pinecone_api_key, environment="us-west1-gcp")

# 1\. Create a new index
index_name = 'outside-chatgpt'

# 2\. Use OpenAI's ada-002 as embedding model
model_name = 'text-embedding-ada-002'
embed = OpenAIEmbeddings(
    document_model_name=model_name,
    query_model_name=model_name,
    openai_api_key=OPENAI_API_KEY
)
embed_dimension = 1536

# 3\. check if index already exists (it shouldn't if this is first time)
if index_name not in pinecone.list_indexes():
    # if does not exist, create index
    pinecone.create_index(
        name=index_name,
        metric='cosine',
        dimension=embed_dimension
    )

# 3\. Connect to index
index = pinecone.Index(index_name)
```

æˆ‘ä»¬æ‰¹é‡ä¸Šä¼ å¹¶åµŒå…¥æ‰€æœ‰æ–‡ç« ï¼Œè¿™èŠ±è´¹äº†å¤§çº¦ 20 åˆ†é’Ÿæ¥æ’å…¥ 2 ä¸‡æ¡è®°å½•ã€‚è¯·æ ¹æ®ä½ çš„ç¯å¢ƒè°ƒæ•´ `tqdm` å¯¼å…¥ï¼ˆä½ ä¸éœ€è¦åŒæ—¶å¯¼å…¥ä¸¤ä¸ªï¼ï¼‰

```py
# If using terminal
from tqdm.auto import tqdm

# If using in Jupyter notebook
from tqdm.autonotebook import tqdm

from uuid import uuid4

batch_limit = 100

texts = []
metadatas = []

for i, record in enumerate(tqdm(data)):
    # 1\. Get metadata fields for this record
    metadata = {
        'item_uuid': str(record['id']),
        'source': record['url'],
        'title': record['title']
    }
    # 2\. Create chunks from the record text
    record_texts = text_splitter.split_text(record['content'])

    # 3\. Create individual metadata dicts for each chunk
    record_metadatas = [{
        "chunk": j, "text": text, **metadata
    } for j, text in enumerate(record_texts)]

    # 4\. Append these to current batches
    texts.extend(record_texts)
    metadatas.extend(record_metadatas)

    # 5\. Special case: if we have reached the batch_limit we can add texts
    if len(texts) >= batch_limit:
        ids = [str(uuid4()) for _ in range(len(texts))]
        embeds = embed.embed_documents(texts)
        index.upsert(vectors=zip(ids, embeds, metadatas))
        texts = []
        metadatas = []
```

åœ¨å°† Outside æ–‡ç« æ•°æ®æ’å…¥åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨ `index.describe_index_stats()` æ£€æŸ¥æˆ‘ä»¬çš„ Pinecone ç´¢å¼•ã€‚éœ€è¦æ³¨æ„çš„ç»Ÿè®¡æ•°æ®ä¹‹ä¸€æ˜¯ `index_fullness`ï¼Œåœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ä¸º 0.2ã€‚è¿™æ„å‘³ç€ Pinecone pod å·²æ»¡ 20%ï¼Œæš—ç¤ºä¸€ä¸ª p1 pod å¤§çº¦å¯ä»¥å­˜å‚¨ 10 ä¸‡ç¯‡æ–‡ç« ã€‚

![](../Images/e58bbd39a40d1f5ca391d0328c3206d7.png)

åœ¨å°†æ•°æ®æ’å…¥ Pinecone å

## æ­¥éª¤ 2ï¼šä½¿ç”¨ Langchain è¿›è¡Œé—®ç­”æœåŠ¡

*æ³¨æ„ï¼šLangchain æœ€è¿‘æ›´æ–°éå¸¸å¿«ï¼Œä¸‹é¢ä»£ç ä½¿ç”¨çš„ç‰ˆæœ¬æ˜¯* `*0.0.118*` *ã€‚*

![](../Images/84f252a1857dc61124514ae1c921ecfe.png)

OPL å †æ ˆä¸­çš„æ•°æ®æµ

ä¸Šé¢çš„è‰å›¾è¯´æ˜äº†æ¨ç†é˜¶æ®µæ•°æ®æµåŠ¨çš„æ–¹å¼ï¼š

+   ç”¨æˆ·æé—®ï¼šâ€œ2023 å¹´æœ€å¥½çš„è·‘é‹æ˜¯ä»€ä¹ˆï¼Ÿâ€

+   é—®é¢˜ä½¿ç”¨ `ada-002` æ¨¡å‹è½¬æ¢ä¸ºåµŒå…¥ã€‚

+   ç”¨æˆ·é—®é¢˜åµŒå…¥ä¸ Pinecone ä¸­å­˜å‚¨çš„æ‰€æœ‰å‘é‡é€šè¿‡ `similarity_search` å‡½æ•°è¿›è¡Œæ¯”è¾ƒï¼Œè¯¥å‡½æ•°æ£€ç´¢æœ€æœ‰å¯èƒ½å›ç­”é—®é¢˜çš„å‰ä¸‰ä¸ªæ–‡æœ¬å—ã€‚

+   Langchain ç„¶åå°†å‰ä¸‰ä¸ªæ–‡æœ¬å—ä½œä¸º `context`ï¼Œä¸ç”¨æˆ·é—®é¢˜ä¸€èµ·ä¼ é€’ç»™ gpt-3.5ï¼ˆ`ChatCompletion`ï¼‰ç”Ÿæˆç­”æ¡ˆã€‚

æ‰€æœ‰è¿™äº›éƒ½å¯ä»¥é€šè¿‡ä¸åˆ° 30 è¡Œä»£ç å®ç°ï¼š

```py
from langchain.vectorstores import Pinecone
from langchain.chains import VectorDBQAWithSourcesChain
from langchain.embeddings.openai import OpenAIEmbeddings

# 1\. Specify Pinecone as Vectorstore
# =======================================
# 1.1 get pinecone index name
index = pinecone.Index(index_name) #'outside-chatgpt'

# 1.2 specify embedding model
model_name = 'text-embedding-ada-002'
embed = OpenAIEmbeddings(
    document_model_name=model_name,
    query_model_name=model_name,
    openai_api_key=OPENAI_API_KEY
)

# 1.3 provides text_field
text_field = "text"

vectorstore = Pinecone(
    index, embed.embed_query, text_field
)

# 2\. Wrap the chain as a function
qa_with_sources = VectorDBQAWithSourcesChain.from_chain_type(
    llm=llm,
    chain_type="stuff",
    vectorstore=vectorstore
)
```

ç°åœ¨æˆ‘ä»¬å¯ä»¥é€šè¿‡æå‡ºä¸€ä¸ªä¸å¾’æ­¥æ—…è¡Œç›¸å…³çš„é—®é¢˜è¿›è¡Œæµ‹è¯•ï¼šâ€œä½ èƒ½æ¨èä¸€äº›åŠ å·æ¹¾åŒºå¸¦æ°´æ™¯çš„é«˜çº§å¾’æ­¥æ—…è¡Œè·¯çº¿å—ï¼Ÿâ€

![](../Images/20894ccdec7880545e25efa3b0beb363.png)

Langchain VectorDBQA å¸¦æ¥æº

## æ­¥éª¤ 3ï¼šåœ¨ Streamlit ä¸­æ„å»ºæˆ‘ä»¬çš„åº”ç”¨

åœ¨ Jupyter notebook ä¸­éªŒè¯é€»è¾‘æœ‰æ•ˆåï¼Œæˆ‘ä»¬å¯ä»¥å°†æ‰€æœ‰å†…å®¹æ•´åˆåœ¨ä¸€èµ·ï¼Œå¹¶ä½¿ç”¨ streamlit æ„å»ºå‰ç«¯ã€‚åœ¨æˆ‘ä»¬çš„ streamlit åº”ç”¨ä¸­ï¼Œæœ‰ä¸¤ä¸ª python æ–‡ä»¶ï¼š

- `app.py`ï¼šå‰ç«¯çš„ä¸»è¦ python æ–‡ä»¶ï¼Œé©±åŠ¨åº”ç”¨

- `utils.py`ï¼šç”± `app.py` è°ƒç”¨çš„æ”¯æŒå‡½æ•°

è¿™å°±æ˜¯æˆ‘çš„ `utils.py` çœ‹èµ·æ¥çš„æ ·å­ï¼š

```py
import pinecone
import streamlit as st
from langchain.chains import VectorDBQAWithSourcesChain
from langchain.chat_models import ChatOpenAI
from langchain.vectorstores import Pinecone
from langchain.embeddings.openai import OpenAIEmbeddings

# ------OpenAI: LLM---------------
OPENAI_API_KEY = st.secrets["OPENAI_KEY"]
llm = ChatOpenAI(
    openai_api_key=OPENAI_API_KEY,
    model_name='gpt-3.5-turbo',
    temperature=0.0
)

# ------OpenAI: Embed model-------------
model_name = 'text-embedding-ada-002'
embed = OpenAIEmbeddings(
    document_model_name=model_name,
    query_model_name=model_name,
    openai_api_key=OPENAI_API_KEY
)

# --- Pinecone ------
pinecone_api_key = st.secrets["PINECONE_API_KEY"]
pinecone.init(api_key=pinecone_api_key, environment="us-west1-gcp")
index_name = "outside-chatgpt"
index = pinecone.Index(index_name)
text_field = "text"
vectorstore = Pinecone(index, embed.embed_query, text_field)

#  ======= Langchain ChatDBQA with source chain =======
def qa_with_sources(query):
    qa = VectorDBQAWithSourcesChain.from_chain_type(
        llm=llm,
        chain_type="stuff",
        vectorstore=vectorstore
    )

    response = qa(query)
    return response 
```

æœ€åï¼Œè¿™å°±æ˜¯æˆ‘çš„ `app.py` çœ‹èµ·æ¥çš„æ ·å­ï¼š

```py
 import os
import openai
from PIL import Image
from streamlit_chat import message
from utils import *

openai.api_key = st.secrets["OPENAI_KEY"]
# For Langchain
os.environ["OPENAI_API_KEY"] = openai.api_key

# ==== Section 1: Streamlit Settings ======
with st.sidebar:
    st.markdown("# Welcome to chatOutside ğŸ™Œ")
    st.markdown(
        "**chatOutside** allows you to talk to version of **chatGPT** \n"
        "that has access to latest Outside content!  \n"
        )
    st.markdown(
        "Unlike chatGPT, chatOutside can't make stuff up\n"
        "and will answer from Outside knowledge base. \n"
    )
    st.markdown("ğŸ‘©â€ğŸ« Developer: Wen Yang")
    st.markdown("---")
    st.markdown("# Under The Hood ğŸ© ğŸ‡")
    st.markdown("How to Prevent Large Language Model (LLM) hallucination?")
    st.markdown("- **Pinecone**: vector database for Outside knowledge")
    st.markdown("- **Langchain**: to remember the context of the conversation")

# Homepage title
st.title("chatOutside: Outside + ChatGPT")
# Hero Image
image = Image.open('VideoBkg_08.jpg')
st.image(image, caption='Get Outside!')

st.header("chatGPT ğŸ¤–")

# ====== Section 2: ChatGPT only ======
def chatgpt(prompt):
    res = openai.ChatCompletion.create(
        model='gpt-3.5-turbo',
        messages=[
            {"role": "system",
             "content": "You are a friendly and helpful assistant. "
                        "Answer the question as truthfully as possible. "
                        "If unsure, say you don't know."},
            {"role": "user", "content": prompt},
        ],
        temperature=0,
    )["choices"][0]["message"]["content"]

    return res

input_gpt = st.text_input(label='Chat here! ğŸ’¬')
output_gpt = st.text_area(label="Answered by chatGPT:",
                          value=chatgpt(input_gpt), height=200)
# ========= End of Section 2 ===========

# ========== Section 3: chatOutside ============================
st.header("chatOutside ğŸ•ï¸")

def chatoutside(query):
    # start chat with chatOutside
    try:
        response = qa_with_sources(query)
        answer = response['answer']
        source = response['sources']

    except Exception as e:
        print("I'm afraid your question failed! This is the error: ")
        print(e)
        return None

    if len(answer) > 0:
        return answer, source

    else:
        return None
# ============================================================

# ========== Section 4\. Display ChatOutside in chatbot style ===========
if 'generated' not in st.session_state:
    st.session_state['generated'] = []

if 'past' not in st.session_state:
    st.session_state['past'] = []

if 'source' not in st.session_state:
    st.session_state['source'] = []

def clear_text():
    st.session_state["input"] = ""

# We will get the user's input by calling the get_text function
def get_text():
    input_text = st.text_input('Chat here! ğŸ’¬', key="input")
    return input_text

user_input = get_text()

if user_input:
    # source contain urls from Outside
    output, source = chatoutside(user_input)

    # store the output
    st.session_state.past.append(user_input)
    st.session_state.generated.append(output)
    st.session_state.source.append(source)

    # Display source urls
    st.write(source)

if st.session_state['generated']:
    for i in range(len(st.session_state['generated'])-1, -1, -1):
        message(st.session_state["generated"][i],  key=str(i))
        message(st.session_state['past'][i], is_user=True,
                avatar_style="big-ears",  key=str(i) + '_user')
```

# 3\. ç”Ÿäº§è€ƒè™‘

å¥½äº†ï¼Œå¤Ÿäº†ï¼

åº”ç”¨å®é™…ä¸Šå·²ç»å¾ˆä¸é”™äº†ã€‚ä½†æ˜¯å¦‚æœæˆ‘ä»¬æƒ³è¿›å…¥ç”Ÿäº§ç¯å¢ƒï¼Œè¿˜æœ‰ä¸€äº›é¢å¤–çš„äº‹é¡¹éœ€è¦è€ƒè™‘ï¼š

1.  åœ¨ Pinecone ä¸­æ‘„å–æ–°çš„å’Œæ›´æ–°çš„æ•°æ®ï¼šæˆ‘ä»¬å¯¹æ–‡ç« æ•°æ®è¿›è¡Œäº†å•æ¬¡æ‰¹é‡æ’å…¥ã€‚å®é™…ä¸Šï¼Œæ¯å¤©éƒ½æœ‰æ–°çš„æ–‡ç« æ·»åŠ åˆ°æˆ‘ä»¬çš„ç½‘ç«™ä¸­ï¼Œè€Œä¸”ä¸€äº›å­—æ®µå¯èƒ½ä¼šæ›´æ–°å·²ç»æ‘„å–åˆ° Pinecone çš„æ•°æ®ã€‚è¿™ä¸æ˜¯æœºå™¨å­¦ä¹ çš„é—®é¢˜ï¼Œè€Œæ˜¯å¯¹åª’ä½“å…¬å¸è€Œè¨€å¸¸å¸¸å­˜åœ¨çš„é—®é¢˜ï¼šå¦‚ä½•ä¿æŒæ¯ä¸ªæœåŠ¡ä¸­çš„æ•°æ®æ›´æ–°ã€‚æ½œåœ¨çš„è§£å†³æ–¹æ¡ˆæ˜¯è®¾ç½®ä¸€ä¸ªå®šæ—¶ä»»åŠ¡æ¥å®šæœŸæ‰§è¡Œæ’å…¥å’Œæ›´æ–°ä»»åŠ¡ã€‚æœ‰å…³å¦‚ä½•å¹¶è¡Œå‘é€æ’å…¥æ“ä½œçš„æŒ‡ä»¤ï¼Œå¦‚æœæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ Django å’Œ Celery çš„å¼‚æ­¥ä»»åŠ¡ï¼Œè¿™å¯èƒ½ä¼šéå¸¸æœ‰ç”¨ã€‚

1.  [Pinecone pod å­˜å‚¨](https://docs.pinecone.io/docs/limits#:~:text=Pod%20storage%20capacity,5M%20vectors%20with%20768%20dimensions.)çš„é™åˆ¶ï¼šå½“å‰åº”ç”¨ä½¿ç”¨çš„æ˜¯ p1 podï¼Œèƒ½å¤Ÿå­˜å‚¨æœ€å¤š 1M ä¸ª 768 ç»´å‘é‡ï¼Œæˆ–è€…å¦‚æœæˆ‘ä»¬ä½¿ç”¨ OpenAI çš„ `ada-002` åµŒå…¥æ¨¡å‹ï¼ˆå…¶ç»´åº¦ä¸º 1536ï¼‰ï¼Œåˆ™å¤§çº¦èƒ½å­˜å‚¨ 50 ä¸‡ä¸ªå‘é‡ã€‚

1.  æµå¼å¤„ç†åŠŸèƒ½ä»¥æé«˜å“åº”é€Ÿåº¦ï¼šä¸ºäº†å‡å°‘ç”¨æˆ·æ„ŸçŸ¥çš„å»¶è¿Ÿï¼Œå¯èƒ½æœ‰åŠ©äºå‘åº”ç”¨æ·»åŠ æµå¼å¤„ç†åŠŸèƒ½ã€‚è¿™å°†æ¨¡æ‹Ÿ chatGPT æŒ‰ token è¿”å›ç”Ÿæˆçš„è¾“å‡ºï¼Œè€Œä¸æ˜¯ä¸€æ¬¡æ€§æ˜¾ç¤ºæ•´ä¸ªå“åº”ã€‚è™½ç„¶è¿™ç§åŠŸèƒ½åœ¨ä½¿ç”¨ LangChain å‡½æ•°çš„ REST API ä¸­æœ‰æ•ˆï¼Œä½†å¯¹äºæˆ‘ä»¬æ¥è¯´ï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨ GraphQL è€Œä¸æ˜¯ RESTï¼Œè¿™å¸¦æ¥äº†ç‹¬ç‰¹çš„æŒ‘æˆ˜ã€‚

# 4\. å¸¸è§è¯¯è§£å’Œé—®é¢˜

1.  **chatGPT è®°ä½äº†æˆªè‡³ 2021 å¹´ 9 æœˆçš„äº’è”ç½‘æ•°æ®ï¼Œå¹¶ä¸”åŸºäºè®°å¿†æ£€ç´¢ç­”æ¡ˆã€‚**

    - è¿™å¹¶ä¸æ˜¯å®ƒçš„å·¥ä½œæ–¹å¼ã€‚è®­ç»ƒä¹‹åï¼ŒchatGPT ä»å†…å­˜ä¸­åˆ é™¤æ•°æ®ï¼Œå¹¶ä½¿ç”¨å…¶ 1750 äº¿ä¸ªå‚æ•°ï¼ˆæƒé‡ï¼‰æ¥é¢„æµ‹æœ€å¯èƒ½çš„ tokenï¼ˆæ–‡æœ¬ï¼‰ã€‚å®ƒä¸ä¼šåŸºäºè®°å¿†æ£€ç´¢ç­”æ¡ˆã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå¦‚æœä½ åªæ˜¯å¤åˆ¶ chatGPT ç”Ÿæˆçš„ç­”æ¡ˆï¼Œä½ ä¸å¤ªå¯èƒ½æ‰¾åˆ°æ¥è‡ªäº’è”ç½‘çš„ä»»ä½•æ¥æºã€‚

1.  **æˆ‘ä»¬å¯ä»¥è®­ç»ƒ/å¾®è°ƒ/æç¤ºå·¥ç¨‹ chatGPTã€‚**

    - è®­ç»ƒå’Œå¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹æ„å‘³ç€å®é™…æ›´æ”¹æ¨¡å‹å‚æ•°ã€‚ä½ éœ€è¦è®¿é—®å®é™…çš„æ¨¡å‹æ–‡ä»¶ï¼Œå¹¶æ ¹æ®ä½ çš„å…·ä½“ä½¿ç”¨æƒ…å†µæŒ‡å¯¼æ¨¡å‹ã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¸ä¼šè®­ç»ƒæˆ–å¾®è°ƒ chatGPTã€‚æˆ‘ä»¬æ‰€éœ€è¦çš„åªæ˜¯æç¤ºå·¥ç¨‹ï¼šä¸º chatGPT æä¾›é¢å¤–çš„ä¸Šä¸‹æ–‡ï¼Œå¹¶è®©å®ƒæ ¹æ®è¿™äº›ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚

1.  **token å’Œè¯æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ**

    -** Token æ˜¯ä¸€ä¸ªè¯ç‰‡æ®µã€‚100 ä¸ª token å¤§çº¦ç­‰äº 75 ä¸ªè¯ã€‚ä¾‹å¦‚ï¼Œâ€œUnbelievableâ€ æ˜¯ä¸€ä¸ªè¯ï¼Œä½†åŒ…å« 3 ä¸ª tokenï¼ˆun, belie, ableï¼‰ã€‚**

1.  **4000-token é™åˆ¶æ„å‘³ç€ä»€ä¹ˆï¼Ÿ**

    -** OpenAI gpt-3.5 çš„ token é™åˆ¶ä¸º 4096ï¼Œç”¨äºç»“åˆç”¨æˆ·è¾“å…¥ã€ä¸Šä¸‹æ–‡å’Œå“åº”ã€‚å½“ä½¿ç”¨ Langchain çš„å†…å­˜æ—¶ï¼Œï¼ˆç”¨æˆ·é—®é¢˜ + ä¸Šä¸‹æ–‡ + å†…å­˜ + chatGPT å“åº”ï¼‰ä½¿ç”¨çš„æ€»è¯æ•°éœ€è¦å°‘äº 3000 ä¸ªè¯ï¼ˆ4000 ä¸ª tokenï¼‰ã€‚**

    - gpt-4 æœ‰æ›´é«˜çš„ token é™åˆ¶ï¼Œä½†ä¹Ÿè´µäº† 20 å€ï¼ï¼ˆgpt-3.5ï¼š$0.002/1000 tokensï¼›gpt-4ï¼š$0.045/1000 tokensï¼Œå‡è®¾ 500 ä¸ªç”¨äºæç¤ºå’Œ 500 ä¸ªç”¨äºå®Œæˆï¼‰ã€‚

1.  **æˆ‘æ˜¯å¦å¿…é¡»ä½¿ç”¨åƒ Pinecone è¿™æ ·çš„å‘é‡å­˜å‚¨ï¼Ÿ**

    -** ä¸ï¼ŒPinecone ä¸æ˜¯å”¯ä¸€çš„å‘é‡å­˜å‚¨é€‰é¡¹ã€‚å…¶ä»–å‘é‡å­˜å‚¨é€‰é¡¹åŒ…æ‹¬ Chromaã€FAISSã€Redis ç­‰ã€‚æ­¤å¤–ï¼Œä½ å¹¶ä¸æ€»æ˜¯éœ€è¦å‘é‡å­˜å‚¨ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ æƒ³ä¸ºç‰¹å®šç½‘ç«™æ„å»ºä¸€ä¸ªé—®ç­”ç³»ç»Ÿï¼Œä½ å¯ä»¥çˆ¬å–ç½‘é¡µå¹¶å‚è€ƒè¿™ä¸ª [openai-cookbook-recipe](https://github.com/openai/openai-cookbook/blob/main/apps/web-crawl-q-and-a/web-qa.ipynb)ã€‚

# å‘Šåˆ«çš„è¯

æ„Ÿè°¢ä½ é˜…è¯»è¿™ç¯‡é•¿æ–‡ï¼å¦‚æœä½ å¯¹ä½¿ç”¨ Langchain æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·éšæ—¶è”ç³»æˆ‘ã€‚

æ­¤å¤–ï¼Œæˆ‘å°†å‚åŠ  [LLM Bootcamp](https://fullstackdeeplearning.com/llm-bootcamp/)ï¼Œå¸Œæœ›èƒ½å­¦ä¹ åˆ°æ›´å¤šå…³äºå°† LLMs åº”ç”¨åˆ°ç”Ÿäº§ä¸­çš„æœ€ä½³å®è·µã€‚å¦‚æœä½ å¯¹è¿™ä¸ªè¯é¢˜æ„Ÿå…´è¶£ï¼Œè¯·å…³æ³¨æˆ‘æœªæ¥çš„å¸–å­ï¼ğŸ˜ƒ
