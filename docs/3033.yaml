- en: What are Query, Key, and Value in the Transformer Architecture and Why Are They
    Used?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Transformer 架构中，Query、Key 和 Value 是什么？它们为何被使用？
- en: 原文：[https://towardsdatascience.com/what-are-query-key-and-value-in-the-transformer-architecture-and-why-are-they-used-acbe73f731f2?source=collection_archive---------2-----------------------#2023-10-05](https://towardsdatascience.com/what-are-query-key-and-value-in-the-transformer-architecture-and-why-are-they-used-acbe73f731f2?source=collection_archive---------2-----------------------#2023-10-05)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/what-are-query-key-and-value-in-the-transformer-architecture-and-why-are-they-used-acbe73f731f2?source=collection_archive---------2-----------------------#2023-10-05](https://towardsdatascience.com/what-are-query-key-and-value-in-the-transformer-architecture-and-why-are-they-used-acbe73f731f2?source=collection_archive---------2-----------------------#2023-10-05)
- en: An analysis of the intuition behind the notion of Key, Query, and Value in Transformer
    architecture and why is it used.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对 Transformer 架构中 Key、Query 和 Value 概念的直觉分析及其用途。
- en: '[](https://ebrahimpichka.medium.com/?source=post_page-----acbe73f731f2--------------------------------)[![Ebrahim
    Pichka](../Images/8add6e8e875d9e921caf7f5eaa77d545.png)](https://ebrahimpichka.medium.com/?source=post_page-----acbe73f731f2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----acbe73f731f2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----acbe73f731f2--------------------------------)
    [Ebrahim Pichka](https://ebrahimpichka.medium.com/?source=post_page-----acbe73f731f2--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ebrahimpichka.medium.com/?source=post_page-----acbe73f731f2--------------------------------)[![Ebrahim
    Pichka](../Images/8add6e8e875d9e921caf7f5eaa77d545.png)](https://ebrahimpichka.medium.com/?source=post_page-----acbe73f731f2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----acbe73f731f2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----acbe73f731f2--------------------------------)
    [Ebrahim Pichka](https://ebrahimpichka.medium.com/?source=post_page-----acbe73f731f2--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcf08d1e97a71&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-are-query-key-and-value-in-the-transformer-architecture-and-why-are-they-used-acbe73f731f2&user=Ebrahim+Pichka&userId=cf08d1e97a71&source=post_page-cf08d1e97a71----acbe73f731f2---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----acbe73f731f2--------------------------------)
    ·10 min read·Oct 5, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Facbe73f731f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-are-query-key-and-value-in-the-transformer-architecture-and-why-are-they-used-acbe73f731f2&user=Ebrahim+Pichka&userId=cf08d1e97a71&source=-----acbe73f731f2---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcf08d1e97a71&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-are-query-key-and-value-in-the-transformer-architecture-and-why-are-they-used-acbe73f731f2&user=Ebrahim+Pichka&userId=cf08d1e97a71&source=post_page-cf08d1e97a71----acbe73f731f2---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----acbe73f731f2--------------------------------)
    ·10 min 阅读·2023年10月5日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Facbe73f731f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-are-query-key-and-value-in-the-transformer-architecture-and-why-are-they-used-acbe73f731f2&user=Ebrahim+Pichka&userId=cf08d1e97a71&source=-----acbe73f731f2---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Facbe73f731f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-are-query-key-and-value-in-the-transformer-architecture-and-why-are-they-used-acbe73f731f2&source=-----acbe73f731f2---------------------bookmark_footer-----------)![](../Images/36bd08a0784d8f29ebfaca4463809896.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Facbe73f731f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-are-query-key-and-value-in-the-transformer-architecture-and-why-are-they-used-acbe73f731f2&source=-----acbe73f731f2---------------------bookmark_footer-----------)![](../Images/36bd08a0784d8f29ebfaca4463809896.png)'
- en: Image by author — generated by [**Midjourney**](https://www.midjourney.com/)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供 — 由 [**Midjourney**](https://www.midjourney.com/) 生成
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Recent years have seen the Transformer architecture make waves in the field
    of natural language processing (NLP), achieving state-of-the-art results in a
    variety of tasks including machine translation, language modeling, and text summarization,
    as well as other domains of AI i.e. Vision, Speech, RL, etc.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，Transformer 架构在自然语言处理（NLP）领域引起了轰动，在包括机器翻译、语言建模、文本摘要等各种任务中取得了最先进的成果，以及其他
    AI 领域，如视觉、语音、强化学习等。
- en: Vaswani et al. (2017), first introduced the transformer in their paper *“Attention
    Is All You Need”*, in which they used the self-attention mechanism without incorporating
    recurrent connections while the model can focus selectively on specific portions
    of input sequences.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Vaswani 等人（2017）在他们的论文 *《Attention Is All You Need》* 中首次介绍了 Transformer，其中他们使用了自注意力机制，而没有引入递归连接，同时模型可以有选择地关注输入序列的特定部分。
- en: '![](../Images/5c8d9226a835a3ef8723261c98b8ff73.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5c8d9226a835a3ef8723261c98b8ff73.png)'
- en: 'The Transformer model architecture — Image from the Vaswani et al. (2017) paper
    (Source: [**arXiv:1706.03762v7**](https://arxiv.org/abs/1706.03762v7))'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer 模型架构——图片来自 Vaswani 等人（2017）的论文（来源：[**arXiv:1706.03762v7**](https://arxiv.org/abs/1706.03762v7)）
- en: In particular, previous sequence models, such as recurrent encoder-decoder models,
    were limited in their ability to capture long-term dependencies and parallel computations.
    In fact, right before the Transformers paper came out in 2017, state-of-the-art
    performance in most NLP…
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，以前的序列模型，如递归编码器-解码器模型，在捕捉长期依赖关系和并行计算方面存在限制。事实上，在 Transformer 论文于 2017 年发表之前，大多数
    NLP…
