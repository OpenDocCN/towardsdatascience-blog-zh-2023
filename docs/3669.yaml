- en: 'MLX vs MPS vs CUDA: a Benchmark'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/mlx-vs-mps-vs-cuda-a-benchmark-c5737ca6efc9?source=collection_archive---------3-----------------------#2023-12-15](https://towardsdatascience.com/mlx-vs-mps-vs-cuda-a-benchmark-c5737ca6efc9?source=collection_archive---------3-----------------------#2023-12-15)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A first benchmark of Apple’s new ML framework MLX
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://tristanbilot.medium.com/?source=post_page-----c5737ca6efc9--------------------------------)[![Tristan
    Bilot](../Images/64c2628ae710042d80ca2ee2feb3da37.png)](https://tristanbilot.medium.com/?source=post_page-----c5737ca6efc9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c5737ca6efc9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c5737ca6efc9--------------------------------)
    [Tristan Bilot](https://tristanbilot.medium.com/?source=post_page-----c5737ca6efc9--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2f664301d394&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmlx-vs-mps-vs-cuda-a-benchmark-c5737ca6efc9&user=Tristan+Bilot&userId=2f664301d394&source=post_page-2f664301d394----c5737ca6efc9---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c5737ca6efc9--------------------------------)
    ·6 min read·Dec 15, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc5737ca6efc9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmlx-vs-mps-vs-cuda-a-benchmark-c5737ca6efc9&user=Tristan+Bilot&userId=2f664301d394&source=-----c5737ca6efc9---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc5737ca6efc9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmlx-vs-mps-vs-cuda-a-benchmark-c5737ca6efc9&source=-----c5737ca6efc9---------------------bookmark_footer-----------)![](../Images/e7da28e0049ecdc0858d1969c4856536.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Javier Allegue Barros](https://unsplash.com/@soymeraki?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: If you’re a Mac user and a deep learning enthusiast, you’ve probably wished
    at some point that your Mac could handle those heavy models, right? Well, guess
    what? Apple just released [MLX](https://ml-explore.github.io/mlx/build/html/index.html),
    a framework for running ML models efficiently on Apple Silicon.
  prefs: []
  type: TYPE_NORMAL
- en: The recent introduction of the [MPS backend](https://developer.apple.com/metal/pytorch/)
    in PyTorch 1.12 was already a bold step, but with the announcement of MLX, it
    seems that Apple wants to make a significant leap into open source deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we’ll put these new approaches through their paces, benchmarking
    them against the traditional CPU backend on three different Apple Silicon chips,
    and two CUDA-enabled GPUs. By doing so, we aim to reveal just how much these novel
    Mac-compatible methods can be used in 2024 for deep learning experiments.
  prefs: []
  type: TYPE_NORMAL
- en: As a GNN-oriented researcher, I’ll focus the benchmark on a Graph Convolutional
    Network (GCN) model. But since this model mainly consists of linear layers, our
    findings could be insightful even for those not specifically in the GNN sphere.
  prefs: []
  type: TYPE_NORMAL
- en: Crafting an environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To build an environment for MLX, we have to specify whether using the i386
    or arm architecture. With conda, this can be done using:'
  prefs: []
  type: TYPE_NORMAL
