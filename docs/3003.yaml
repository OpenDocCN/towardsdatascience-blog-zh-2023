- en: 'SHAP vs. ALE for Feature Interactions: Understanding Conflicting Results'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/shap-vs-ale-for-feature-interactions-understanding-conflicting-results-ac506149f678?source=collection_archive---------2-----------------------#2023-10-02](https://towardsdatascience.com/shap-vs-ale-for-feature-interactions-understanding-conflicting-results-ac506149f678?source=collection_archive---------2-----------------------#2023-10-02)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Model Explainers Require Thoughtful Interpretation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@vla6?source=post_page-----ac506149f678--------------------------------)[![Valerie
    Carey](../Images/9ef394fe5a6a5439521c1905e0195751.png)](https://medium.com/@vla6?source=post_page-----ac506149f678--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ac506149f678--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ac506149f678--------------------------------)
    [Valerie Carey](https://medium.com/@vla6?source=post_page-----ac506149f678--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1a7c9171898f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fshap-vs-ale-for-feature-interactions-understanding-conflicting-results-ac506149f678&user=Valerie+Carey&userId=1a7c9171898f&source=post_page-1a7c9171898f----ac506149f678---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ac506149f678--------------------------------)
    ·10 min read·Oct 2, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fac506149f678&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fshap-vs-ale-for-feature-interactions-understanding-conflicting-results-ac506149f678&user=Valerie+Carey&userId=1a7c9171898f&source=-----ac506149f678---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac506149f678&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fshap-vs-ale-for-feature-interactions-understanding-conflicting-results-ac506149f678&source=-----ac506149f678---------------------bookmark_footer-----------)![](../Images/a6c0057846dba5111997ce4bc1191bb4.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Diogo Nunes](https://unsplash.com/@dialex?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I compare model explainability techniques for feature interactions.
    In a surprising twist, two commonly used tools, SHAP and ALE, produce opposing
    results.
  prefs: []
  type: TYPE_NORMAL
- en: Probably, I should not have been surprised. After all, explainability tools
    measure specific responses in distinct ways. Interpretation requires understanding
    test methodologies, data characteristics, and problem context. **Just because
    something is called an *explainer* doesn’t mean it generates an *explanation,*
    if you define an explanation as a human understanding how a model works.**
  prefs: []
  type: TYPE_NORMAL
- en: This post focuses on explainability techniques for feature interactions. I use
    a common project dataset derived from real loans [1], and a typical mode type
    (a boosted tree model). Even in this everyday situation, explanations require
    thoughtful interpretation.
  prefs: []
  type: TYPE_NORMAL
- en: If methodology details are overlooked, explainability tools can impede understanding
    or even undermine efforts to ensure model fairness.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Below, I show disparate SHAP and ALE curves and demonstrate that the disagreement
    between the techniques arise from differences in the measured responses and feature
    perturbations performed by the…
  prefs: []
  type: TYPE_NORMAL
