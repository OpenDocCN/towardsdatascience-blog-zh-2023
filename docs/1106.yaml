- en: Deploy Machine Learning Models Right From Your Jupyter Notebook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://towardsdatascience.com/deploy-machine-learning-models-right-from-your-jupyter-notebook-3241d47408cd?source=collection_archive---------2-----------------------#2023-03-28](https://towardsdatascience.com/deploy-machine-learning-models-right-from-your-jupyter-notebook-3241d47408cd?source=collection_archive---------2-----------------------#2023-03-28)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Deploy machine learning models in one line of code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@avi_chawla?source=post_page-----3241d47408cd--------------------------------)[![Avi
    Chawla](../Images/c9c3e4fc7549c3e388f8b4a5560c7cc6.png)](https://medium.com/@avi_chawla?source=post_page-----3241d47408cd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3241d47408cd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3241d47408cd--------------------------------)
    [Avi Chawla](https://medium.com/@avi_chawla?source=post_page-----3241d47408cd--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Â·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5d33decdf4c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploy-machine-learning-models-right-from-your-jupyter-notebook-3241d47408cd&user=Avi+Chawla&userId=5d33decdf4c4&source=post_page-5d33decdf4c4----3241d47408cd---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3241d47408cd--------------------------------)
    Â·7 min readÂ·Mar 28, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3241d47408cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploy-machine-learning-models-right-from-your-jupyter-notebook-3241d47408cd&user=Avi+Chawla&userId=5d33decdf4c4&source=-----3241d47408cd---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3241d47408cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploy-machine-learning-models-right-from-your-jupyter-notebook-3241d47408cd&source=-----3241d47408cd---------------------bookmark_footer-----------)![](../Images/4645ee16b71f68d11b5b7a71086fcb33.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Roman Synkevych ðŸ‡ºðŸ‡¦](https://unsplash.com/ko/@synkevych?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Amidst this AI revolution, building intelligent systems at scale has been of
    great interest lately to countless organizations.
  prefs: []
  type: TYPE_NORMAL
- en: While plenty of time and energy is being actively spent in training large machine
    learning models, taking these models to production and maintaining them is a task
    of its own.
  prefs: []
  type: TYPE_NORMAL
- en: This, in some cases, may even require specialized teams.
  prefs: []
  type: TYPE_NORMAL
- en: And while more and more organizations are resorting to artificial intelligence
    (AI) to serve end customers, smooth deployment of these models remains somewhat
    cumbersome yet at the forefront of ensuring that the intended services are delivered
    as promised.
  prefs: []
  type: TYPE_NORMAL
- en: But have you ever wondered why deployment is a challenging process? If yes,
    let me help.
  prefs: []
  type: TYPE_NORMAL
- en: In this blog, I will provide a detailed overview of why ML deployment is typically
    a tedious process.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, I will share how you can simplify this process and deploy models from
    jupyter notebook using the [Modelbit](https://www.modelbit.com/) API.
  prefs: []
  type: TYPE_NORMAL
- en: Letâ€™s begin ðŸš€!
  prefs: []
  type: TYPE_NORMAL
- en: What is Deployment?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For starters, deployment is the process of integrating a trained machine learning
    model into a production environment.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment is the last stage in the development lifecycle of a machine learning
    product. This is when the model has been trained, validated, tested, and is finally
    ready to be served to an end user.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can read my previous article on machine learning deployment here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/deploying-machine-learning-models-with-heroku-4dec1df87f71?source=post_page-----3241d47408cd--------------------------------)
    [## Deploying Machine Learning Models with Heroku'
  prefs: []
  type: TYPE_NORMAL
- en: 'Donâ€™t just train, but also deploy: a step-by-step guide'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/deploying-machine-learning-models-with-heroku-4dec1df87f71?source=post_page-----3241d47408cd--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Pain Points of ML Model Deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '#1) Consistency challenges'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In almost all ML use cases, the algorithm used is typically never coded from
    scratch. Instead, one uses open-source implementations offered by libraries like
    PyTorch, Sklearn, and many more.
  prefs: []
  type: TYPE_NORMAL
- en: To ensure reproducibility in production, the production environment should be
    consistent with the environment it was trained in.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2a497e7ca8b1dc4308b8f819af4135f7.png)'
  prefs: []
  type: TYPE_IMG
- en: Dev and Production Environments (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: This involves installing similar versions of libraries used, software dependencies,
    OS configurations, and many more.
  prefs: []
  type: TYPE_NORMAL
- en: Achieving this consistency can, at times, be challenging.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, while writing the Heroku blog I mentioned above, I came across numerous
    errors and challenges when I was trying to deploy a machine learning model on
    Heroku, and overall, the process was a bit tedious and time-consuming to resolve,
    which I also discussed in that blog.
  prefs: []
  type: TYPE_NORMAL
- en: '#2) Infrastructural challenges'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ML models typically require specialized processors like GPUs for training.
  prefs: []
  type: TYPE_NORMAL
- en: Depending upon the complexity, a specialized infrastructure may also be needed
    during inference, i.e., post-deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up these specialized infrastructures is often challenging for data teams.
  prefs: []
  type: TYPE_NORMAL
- en: '#3) Inadequate Expertise (or Knowledge Gap)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ML engineers may not have experience with deployment. They may not have the
    necessary expertise in areas such as software engineering, DevOps, and infrastructure
    management.
  prefs: []
  type: TYPE_NORMAL
- en: This can make it difficult for them to effectively deploy and scale models in
    production environments.
  prefs: []
  type: TYPE_NORMAL
- en: In such cases, organizations hire specialized talents.
  prefs: []
  type: TYPE_NORMAL
- en: However, engineers hired specifically for deployment may not have an in-depth
    understanding of ML algorithms and techniques.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c2412d35281401c7aa0585386d0b48a4.png)'
  prefs: []
  type: TYPE_IMG
- en: Dev and Production Teams (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: This makes it difficult for them to understand the code and make necessary optimizations,
    leading to issues with scaling, performance, and reliability, and can ultimately
    impact the effectiveness of the model in production.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying ML models from Jupyter Notebook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The above pain points, to an extent, highlight the necessity for a data scientist
    to have the necessary deployment expertise.
  prefs: []
  type: TYPE_NORMAL
- en: Now, data scientists spend most of their time working in a Jupyter notebook.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, to simplify the deployment process and integrate it with Jupyter to create
    a model endpoint, I will use the [Modelbit](https://www.modelbit.com/) API.
  prefs: []
  type: TYPE_NORMAL
- en: Workflow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before building the application, it will be better to highlight the process
    workflow, which one can replicate in any of their projects.
  prefs: []
  type: TYPE_NORMAL
- en: The image below depicts a high-level diagrammatic overview of the steps involved
    in the deployment process.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/40c568c3284c79f2075aed3d13be8cb5.png)'
  prefs: []
  type: TYPE_IMG
- en: Deployment workflow (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: First, inside a jupyter notebook, we will train a machine learning model.
  prefs: []
  type: TYPE_NORMAL
- en: Next, weâ€™ll create a prediction function, which will accept the input as its
    parameters and return the modelâ€™s prediction.
  prefs: []
  type: TYPE_NORMAL
- en: After that, weâ€™ll gather the list of packages used along with their version
    and the python version we trained our model in. This info, along with the function
    object will be sent for deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we will retrieve the model endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: Letâ€™s look at the steps below.
  prefs: []
  type: TYPE_NORMAL
- en: '**To reiterate, we will do everything from a Jupyter notebook.**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: Training the Machine Learning Model'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, weâ€™ll train a machine learning model we intend to deploy. For simplicity,
    letâ€™s consider a linear regression model trained on the following dummy dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/16c4e983926ce84a85ea1f4b1fcb50fe.png)'
  prefs: []
  type: TYPE_IMG
- en: Dummy dataset (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will train a linear regression model using [scikit-learn](https://scikit-learn.org/stable/index.html):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following regression plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e6c1353f835b69bf64147e1cf458caba.png)'
  prefs: []
  type: TYPE_IMG
- en: Regression Fit (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 2: Setup Modelbit'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '#2.1) Install Modelbit'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Firstly, install the Modelbit package via `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '#2.2) Login to Modelbit'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To deploy models using Modelbit, create your account [here](https://app.modelbit.com/signup).
    Next, login to Modelbit from Jupyter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: And done!
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can start pushing our models to deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 3: Deploy Models'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To deploy the model using Modelbit, we should set up a python function to ensure
    seamless deployment and inference post-deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Essentially, this function will contain the code that will be executed at runtime,
    and it will be responsible to return the prediction.
  prefs: []
  type: TYPE_NORMAL
- en: We should specify the input parameters as needed by the model in this method.
    Also, you can name it anything you want.
  prefs: []
  type: TYPE_NORMAL
- en: Letâ€™s create a `my_lr_deployement()` method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '**Note:** Every dependency of the function (`model` in this case) is pickled
    and sent to production automatically along with the function. Thus, you are free
    to reference anything in this method.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To deploy, run the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Thatâ€™s it! The model has been successfully deployed. A demonstration is shown
    below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7133b117ce443ebe66c541eadcdb9e47.png)'
  prefs: []
  type: TYPE_IMG
- en: Deployment demonstration (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: Once your model has been successfully deployed, it will appear in your Modelbit
    dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a9c6ebfc8adec79825a9db8a709db340.png)'
  prefs: []
  type: TYPE_IMG
- en: Deployment dashboard (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: As shown above, Modelbit provides an API endpoint. We can use it for inference
    purposes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In the above request, `data` is a list of lists.
  prefs: []
  type: TYPE_NORMAL
- en: The first number in the list (`1`) is the input ID. The `ID` can be any identifier
    that you prefer to use. The numbers following the ID are the function parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, for our `my_lr_deployement(input_x)` method, the data list of
    lists will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Letâ€™s invoke the API with the above input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The endpoint responds with a JSON response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Invoking the deployed model is not just limited to `curl`. We can also use
    the `requests` library in python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is a python dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Custom Environments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes we may want to specify specific versions of the libraries used while
    deploying your model.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can pass these as an argument to the `md.deploy()` method call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also deploy to a specific version of Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To conclude, in this post, we learned how to deploy machine learning models
    right from a jupyter notebook using Modelbit API.
  prefs: []
  type: TYPE_NORMAL
- en: More specifically, I first demonstrated the training of a simple linear regression
    model, followed by integrating the Modelbit API into Jupyter notebook to deploy
    the model.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading!
  prefs: []
  type: TYPE_NORMAL
