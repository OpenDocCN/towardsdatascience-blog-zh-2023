# 我为什么签署了“暂停大型 AI 实验”请愿书

> 原文：[`towardsdatascience.com/why-i-signed-the-pause-giant-ai-experiments-petition-e9711f672d18`](https://towardsdatascience.com/why-i-signed-the-pause-giant-ai-experiments-petition-e9711f672d18)

[](https://rafebrena.medium.com/?source=post_page-----e9711f672d18--------------------------------)![Rafe Brena, Ph.D.](https://rafebrena.medium.com/?source=post_page-----e9711f672d18--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e9711f672d18--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----e9711f672d18--------------------------------) [Rafe Brena, Ph.D.](https://rafebrena.medium.com/?source=post_page-----e9711f672d18--------------------------------)

·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----e9711f672d18--------------------------------) ·阅读时间 8 分钟·2023 年 4 月 1 日

--

“精神”是对的；但“身体”存在许多缺陷

![](img/39703612df5c867141587e1adc2f3c36.png)

照片由[Álvaro Serrano](https://unsplash.com/@alvaroserrano?utm_source=medium&utm_medium=referral)拍摄，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

上周二，我收到来自未来生命研究所的一封电子邮件，邀请我签署一份[暂停大型 AI 实验的请愿书](https://futureoflife.org/open-letter/pause-giant-ai-experiments/?utm_source=pocket_saves)。当我签署这封信时，组织者要求我们在信件发布前保持保密。当时，我没想到它会引起如此多的新闻、评论、文章等。

在文章发布后不久，我接到了一些新闻媒体的联系，一家来自阿根廷，另一家来自墨西哥，邀请我参加他们的直播节目并发表我的观点。

就在那时，我意识到 FLI 的信确实是一个具有高影响力的倡议。

尽管最后我决定签署它，但我也发现信中有许多我不同意的陈述，因此在这篇文章中，我想澄清记录，阐述支持和反对这封信的理由。我鼓励你也阅读这封信，它并不长。

# 为什么现在？

重要的是要意识到，公开信中的紧迫感并不是关于人工智能一般问题，而是关于最近开发和发布的被称为“生成性 AI”或简称 GenAI 的技术。

除非你一直躲在石头下，否则你应该听说过 ChatGPT（去年 11 月发布，天哪，感觉已经很久了），它是 GenAI 最显著的例子，但还有很多其他的，比如[DALL-E](https://www.vox.com/future-perfect/23023538/ai-dalle-2-openai-bias-gpt-3-incentives)、Claude、[Stable Diffusion](https://www.vox.com/recode/2023/1/5/23539055/generative-ai-chatgpt-stable-diffusion-lensa-dall-e)、Poe、[You.com](http://You.com)、[Copy.ai](http://Copy.ai)等等。AI 能力也被融入到许多产品中，如 Notion、Microsoft Office、Google Workplace 套件、GitHub 等。

我们许多人[认为 GenAI 是一个真正的颠覆者](https://medium.com/towards-data-science/how-generative-ia-will-disrupt-everything-in-the-current-decade-b4e8ce7dd4f1)，而其他人则称其为“一时的潮流”。比尔·盖茨[写道](https://www.gatesnotes.com/The-Age-of-AI-Has-Begun)他在自己漫长的生命中见过两次变革性技术，GenAI 是第二次（第一次是当他看到图形用户界面时）。

但这并不是一帆风顺的道路。

除了那些臭名昭著的“[邪恶人格](https://medium.com/geekculture/chatgpts-doppelgänger-12d236743a92)”劫持聊天机器人的案例，我们还见过很多事实错误甚至是虚构的事实——被称为“幻觉”——这些误导性的内容让人类感到困惑，因为这些文本看起来像是极其自信地写成的；我们人类在不确定自己所说内容时往往会表现出不安，但当然，机器不会感到不安（实际上也没有自信）。

像 OpenAI 这样的公司试图给人一种错误被修正的印象，但一些专家认为错误和幻觉是技术的固有部分，而不是小细节。我[提出了一种减少错误的方法](https://medium.com/towards-artificial-intelligence/this-is-how-to-stop-chatgpt-bing-poe-and-you-from-hallucinating-42e8e80c2ef7)，并非假装完全消除它们。

尽管缺陷远未得到纠正，尤其是 OpenAI（背后有微软）与谷歌（及其关联公司 DeepMind 和 Anthropic）之间的竞争却在全速进行。产品以令人窒息的速度发布，只为了市场份额的优势，而不真正担心对社会的后果。

我们——公民——只能独自应对 GenAI 在我们生活中的引入，面对各种虚假信息、偏见、假新闻、假音频，甚至假视频的可能性。

政府对此无动于衷。国际组织对此无动于衷。

我理解图像生成的文本看起来可能不如医学诊断或药物治疗那样重要，但仍然有重要的后果。我们首次体会到误信息（被像 Twitter 这样的科技平台利用）在美国 2016 年和 2020 年选举中所扮演的角色，现在我们在全球范围内都在遭受社会的两极化。但几年前的 Twitter 机器人与即将到来的 GenAI 相比简直微不足道，如果我们对其采用无动于衷的话。

现在让我们回顾一下这封信正确的部分，然后再看看在我看来它的错误之处。

# 公开信中的正确之处

1.  GenAI 系统是“*强大的数字思维，没有人——甚至它们的创造者——可以理解、预测或可靠地控制*。” 他们是“*不可预测的黑箱模型，具有新兴能力*。” 这解释了为什么它们本质上是危险的系统。例如，“*新兴能力*”意味着当 GenAI 系统变得足够大时，新行为会突然出现——比如幻觉。新兴行为不是经过工程设计或编程的；它们只是突然出现。

1.  “*AI 实验室[正]陷入失控的竞赛，开发和部署越来越强大的数字思维*。” 这场不停的竞赛可以从公司市场份额的主导地位来理解，但社会后果又如何呢？他们说他们关心这些问题，但这种无休止的节奏却显示了其他的东西。

1.  我们不应该让这种鲁莽的竞赛继续下去，而应“*制定和实施一套共享的高级 AI 设计和开发安全协议，这些协议应由独立的外部专家进行严格的审计和监督*。”

1.  另一个好的观点是不试图完全停止 AI 研究或创新：“*这并不意味着对 AI 发展的总体暂停，只是从危险的竞赛中后退一步，以避免更大、更不可预测的黑箱模型及其新兴能力*。” 此外，提出了技术努力的重新定位：“*AI 研究和开发应重新聚焦于使今天强大、最先进的系统更加准确、安全、可解释、透明、稳健、对齐、值得信赖和忠诚*。”

1.  最后，提出了将政策制定作为解决方案的重点：“*AI 开发者必须与政策制定者合作，以显著加快强有力的 AI 治理系统的发展。这些系统至少应包括：致力于 AI 的新和有能力的监管机构；对高度能力的 AI 系统和大量计算能力的监督和追踪；用于区分真实与合成以及追踪模型泄漏的来源和水印系统；一个稳健的审计和认证生态系统；对 AI 造成的伤害的责任；对技术 AI 安全研究的稳健公共资金；以及应对 AI 所引起的剧烈经济和政治冲击（尤其是对民主的影响）的资源充足的机构*。”

# 这封信中的错误

我认为信中的大部分问题在开头没有说对；后来情况大有改善。我清楚地感觉到信的开头和结尾部分是由不同的人写的（我不怀疑这两部分是由机器人写的）。让我们深入探讨具体内容：

1.  参考文献权威性不够。口头声明不是客观证据。即使是[Bubeck 等人的参考文献](https://arxiv.org/abs/2303.12712)也不是真正的科学论文，因为它甚至没有经过审稿！你知道，发表在著名期刊上的论文都会经过匿名评审的过程。我每年审稿的数量超过十篇。如果 Bubeck 的论文被送到经过审稿的期刊，肯定不会被接受，因为它使用了主观语言（比如“*人工通用智能的火花*”）。

1.  信中的一些说法完全荒谬：它以“*具有与人类竞争的智能的 AI 系统*”开始，但正如我在[之前的帖子](https://medium.com/@rafebrena/the-human-level-performance-of-gpt-4-5b840828f8d6)中解释的那样，目前的 AI 系统根本不具备与人类竞争的能力，大多数人类与生成 AI 的比较都是误导性的。[支持机器竞争力的参考资料](https://arxiv.org/abs/2303.12712)也是虚假的，正如我在前一点中解释的那样。

1.  信中暗示了人工通用智能（AGI）的说法，如“*当代 AI 系统现在在一般任务上变得与人类竞争*”，但我认为 AGI 是一个非常遥远的未来，甚至不认为 GPT-4 是通向 AGI 的实质性步骤。

1.  对就业市场的危险描述不准确：“*我们是否应该自动化所有工作，包括那些令人满足的工作*？”拜托，AI 并不会取代大多数工作，但它接管某些工作的方式（比如从数千张图片中提取图形设计能力，却没有给人类作者任何经济补偿）可以通过征税大科技公司和支持图形设计师社区来解决，而不是通过暂停。

1.  对不起，但信中几乎每个问题的表述都很糟糕：“*我们是否应该发展非人类思想，这些思想可能最终会超越、智胜、淘汰并取代我们*？”这是一个“*人类与机器*”的场景，这不仅荒谬，而且助长了对 AI 系统的错误宣传，正如[Arvind Narayanan](https://twitter.com/random_walker/status/1641079347531448320) (@random_walker) 在推特上指出的那样。像终结者那样的场景并不是真正的危险。

1.  最后，针对信中毫无意义的问题，我们来看看这个：“*我们是否应该冒失去对文明控制的风险*？”这在很多方面都是错的，难以评论。首先，我们现在有控制我们的文明吗？请告诉我除了富人和国家元首之外，还有谁控制我们的文明。然后，“*我们*”指的是什么？人类？如果是这样，我们回到了人类与机器的对立思维，这是基本错误的。真正的危险是*一些人类*利用 AI 工具来支配*其他人类*。

1.  提议的“补救措施”（暂停开发比 GPT-4 更强大的大语言模型）既不现实也不恰当。这不现实，因为它针对的是主要受大科技公司控制的 AI 实验室，这些公司有特定的财务利益——其中之一就是*增加市场份额*。你认为他们会做 FoL 研究所建议的事，还是做他们老板希望的事？你说得对。这也不恰当，因为暂停措施无法解决已经发生的从人类作者那里抢劫或人类行为者利用工具传播虚假信息所造成的损害，这些工具不需要比 GPT-4 更强大。

1.  最后，一些签署这封信的人，特别是埃隆·马斯克，不能被视为 AI 伦理行为的典范：马斯克通过将“*完全自动驾驶*”称为特斯拉的能力来误导特斯拉客户，而这些能力不仅未能符合由汽车工程师学会提出的 5 级标准，也未能符合 4 级标准，甚至勉强符合 3 级标准。不仅如此，特斯拉在确保安全之前就将潜在致命的机器推向公众，而且特斯拉的自动驾驶模式[实际上造成了人员伤亡](https://impakter.com/tesla-autopilot-crashes-with-at-least-a-dozen-dead-whos-fault-man-or-machine/#:~:text=After%20a%20Tesla%20car%20on,attempts%20to%20shift%20the%20blame)。那么，埃隆·马斯克有什么道德权威要求“*安全、可解释、透明、可靠、对齐、值得信赖且忠诚*”的 AI 系统，而他自己公司里并未付诸实践？

# 那么，我到底为什么签署了这封信？

尽管这封信有很多错误，我为什么决定签署？

我并不是唯一一个签署这封信并批评它的人。例如，@GaryMarcus 也表示，[纽约时报](https://www.nytimes.com/2023/03/29/technology/ai-artificial-intelligence-musk-risks.html)报道了他的观点：

> “这封信不完美，但精神正合适。”

这是一种表示需要采取行动的方式，信件可以被视为第一次尝试这样做。这一点我可以同意。

但如果你想对这个话题有更清晰的理解，可以阅读例如[尤瓦尔·赫拉利在《纽约时报》的专栏](https://www.nytimes.com/2023/03/24/opinion/yuval-harari-ai-chatgpt.html?utm_source=pocket_reader)。除了像“起初是言语”这样的过于宏大的措辞外，我喜欢他对终结者式情景的批评以及他对真正危险的看法：

> … 仅仅通过掌握语言，人工智能就能拥有控制我们在一个类似矩阵的幻觉世界中存在的一切，而无需开枪或植入任何芯片。如果需要开枪，人工智能可以通过讲述正确的故事让人类扣动扳机。
