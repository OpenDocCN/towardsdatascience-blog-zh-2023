- en: Replace Manual Normalization with Batch Normalization in Vision AI Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/replace-manual-normalization-with-batch-normalization-in-vision-ai-models-e7782e82193c?source=collection_archive---------9-----------------------#2023-05-18](https://towardsdatascience.com/replace-manual-normalization-with-batch-normalization-in-vision-ai-models-e7782e82193c?source=collection_archive---------9-----------------------#2023-05-18)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A neat trick to avoid expensive manual pixel normalization for Vision (Image/Video)
    AI models is to stick a Batch normalization layer as the first layer of your model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@dhruvbird?source=post_page-----e7782e82193c--------------------------------)[![Dhruv
    Matani](../Images/d63bf7776c28a29c02b985b1f64abdd3.png)](https://medium.com/@dhruvbird?source=post_page-----e7782e82193c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e7782e82193c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e7782e82193c--------------------------------)
    [Dhruv Matani](https://medium.com/@dhruvbird?source=post_page-----e7782e82193c--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F63f5d5495279&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freplace-manual-normalization-with-batch-normalization-in-vision-ai-models-e7782e82193c&user=Dhruv+Matani&userId=63f5d5495279&source=post_page-63f5d5495279----e7782e82193c---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e7782e82193c--------------------------------)
    ·8 min read·May 18, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe7782e82193c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freplace-manual-normalization-with-batch-normalization-in-vision-ai-models-e7782e82193c&user=Dhruv+Matani&userId=63f5d5495279&source=-----e7782e82193c---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe7782e82193c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freplace-manual-normalization-with-batch-normalization-in-vision-ai-models-e7782e82193c&source=-----e7782e82193c---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: Co-authored with [Naresh](https://medium.com/u/1e659a80cffd?source=post_page-----e7782e82193c--------------------------------).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4c45a0398260aad3d9333c698c15e9e9.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Kevin Ku](https://unsplash.com/ko/@ikukevk?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Channel Normalization for image pre-processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Colour images usually have 3 channels (RGB). It’s common for vision AI models
    to pre-process image pixels and normalize them so that the pixels in a given channel
    are normalized to have a mean of 0.0 and a variance of 1.0\. Normalization is
    performed per-channel since each channel can have its own statistics. The use
    of batch normalization is a general best practice used in vision models to avoid
    a phenomenon known as covariate shift.
  prefs: []
  type: TYPE_NORMAL
- en: What is covariate shift?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Covariate shift](https://en.wikipedia.org/wiki/Batch_normalization) is a phenomenon
    that occurs when the distribution of the input features (i.e., covariates) changes
    between the training and testing phases of a machine learning model. This can
    lead to degraded performance of the model, as the assumptions made during training
    may not hold true during testing. Covariate shift can occur due to changes in
    the data collection process, changes in the population being sampled, or changes
    in the environment in which the model is being used. In order to address covariate
    shift, techniques such as [domain adaptation](https://en.wikipedia.org/wiki/Domain_adaptation)
    and importance weighting can be used to adjust the model’s predictions based on
    the changes in the input distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: However, these techniques are fairly complex, and require a deeper understanding
    of the input data distribution.
  prefs: []
  type: TYPE_NORMAL
- en: How does batch normalization avoid covariate shift?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Batch normalization](https://en.wikipedia.org/wiki/Batch_normalization) helps
    with covariate shift by normalizing the activations of each layer in a neural
    network. This means that the mean and variance of the activations are maintained
    at a fixed value, regardless of the distribution of the inputs to that layer.
    By doing so, batch normalization reduces the effect of covariate shift between
    the training and testing datasets. Batch normalization can be applied to any domain
    and scales well to various use cases without any modifications.'
  prefs: []
  type: TYPE_NORMAL
- en: More specifically, during training, batch normalization centers and scales the
    activations of each layer based on the mean and variance of the activations computed
    over the current batch. This normalizes the activations to have zero mean and
    unit variance, which helps to stabilize and accelerate the training process. A
    running mean and variance is tracked during the training phase.
  prefs: []
  type: TYPE_NORMAL
- en: During testing, the mean and variance computed during training are used to normalize
    the activations. This ensures that the normalization is consistent with the training
    data and reduces the effect of covariate shift.
  prefs: []
  type: TYPE_NORMAL
- en: By reducing the effect of covariate shift, batch normalization can improve the
    generalization performance of neural networks and make them more robust to changes
    in the input distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Why to pre-process inputs?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is done to allow a model to converge faster and generalize well to the
    input data. Models perform relatively better when the input data distribution
    is in a consistent and well-specified range. Specifically, it has the following
    benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: '**To prevent overflow or underflow**: Machine learning models often involve
    mathematical operations such as addition, multiplication, and exponentiation.
    If the input values are too large or too small, the operations can result in overflow
    or underflow, leading to inaccurate or undefined results. For example, adding
    a small floating point (fp32) number to a large one can end up [ignoring the small
    number](https://stackoverflow.com/questions/22186589/why-does-adding-a-small-float-to-a-large-float-just-drop-the-small-one).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**To ensure efficient learning**: Neural networks often use a backpropagation
    algorithm to update the weights in the network. This algorithm relies on calculating
    gradients, which can become very small or very large if the input values are not
    normalized, making the learning process slower and less efficient.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**To improve generalization**: When a model is trained on a specific range
    of input values, it may not perform well on inputs outside of that range. Normalizing
    the inputs can help the model generalize to new and unseen data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Batch normalization** can help address some of these issues by normalizing
    the inputs to each layer of the network during training. This can improve the
    stability of the model and make it less sensitive to the scale of the inputs.
    However, Batch normalization is not always a drop-in replacement for input normalization
    done manually with hard-coded constants.'
  prefs: []
  type: TYPE_NORMAL
- en: What is Batch normalization?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The topic of what Batch normalization is and how it helps models has been covered
    extensively in numerous articles, so we shall link to the ones that provide the
    most detailed insights and allow the reader to develop an intuition for the operation.
    We also provide some links that compare batch normalization with other normalization
    techniques.
  prefs: []
  type: TYPE_NORMAL
- en: '[Batch normalization in 3 levels of understanding](/batch-normalization-in-3-levels-of-understanding-14c2da90a338)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Batch Normalisation Explained](/batch-normalisation-explained-5f4bd9de5feb)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Dive Into Deep Learning: Batch Normalization](https://d2l.ai/chapter_convolutional-modern/batch-norm.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are the consequences of layer norm vs batch norm?](https://ai.stackexchange.com/questions/27309/what-are-the-consequences-of-layer-norm-vs-batch-norm)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How is input normalization typically done?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Typically, the person training the model is responsible for computing the per-channel
    statistics (mean and variance) for the entire training dataset, and normalizing
    the input before training the vision AI model. This normalization is also expected
    to be performed during inference.
  prefs: []
  type: TYPE_NORMAL
- en: The code for this pre-processing may look like this when using [torchvision
    transforms](https://pytorch.org/vision/main/transforms.html).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You can read more about the [Normalize transform here](https://pytorch.org/vision/main/generated/torchvision.transforms.Normalize.html#torchvision.transforms.Normalize).
  prefs: []
  type: TYPE_NORMAL
- en: You’ll notice that the **means and standard deviations are pre-computed** and
    **then hard-coded** into the **pre-processing pipeline**. There’s a lot of **discussion
    online** about how to do this both **correctly** and **efficiently**. For example,
  prefs: []
  type: TYPE_NORMAL
- en: '[Computing the mean and std of dataset](https://discuss.pytorch.org/t/computing-the-mean-and-std-of-dataset/34949)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Kaggle Notebook: Computing Dataset Mean and STD (using PyTorch)](https://www.kaggle.com/code/kozodoi/computing-dataset-mean-and-std/notebook)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[How to calculate mean and standard deviation of images in PyTorch](https://www.binarystudy.com/2021/04/how-to-calculate-mean-standard-deviation-images-pytorch.html)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to make this less painful?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we know how painful this process is, we’ll see a neat trick to make
    this less painful for you!
  prefs: []
  type: TYPE_NORMAL
- en: Simply stick a [BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)
    layer as the first layer of your vision AI model, and drop the [Normalize](https://pytorch.org/vision/main/generated/torchvision.transforms.Normalize.html#torchvision.transforms.Normalize)
    transform from your pre-processing steps!
  prefs: []
  type: TYPE_NORMAL
- en: By using batch normalization as the first layer of the model, the input data
    will be **normalized automatically during the training process**, and you won’t
    need to manually normalize the image pixels. This can save you some coding time
    and reduce the chances of introducing errors in the normalization process.
  prefs: []
  type: TYPE_NORMAL
- en: The rough equivalence of manual normalization and Batch normalization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here we’ll see some code that can convince us about the rough equivalence of
    the 2 approaches.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll take 1000 batches of a randomly generated 1x1 image with 3 channels, and
    see if the manually computed mean and variance are similar to the ones computed
    using PyTorch’s BatchNorm2d layer.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: You can see that output of the code cell below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We started with a random tensor initialized using torch.randn_like(), so we
    expect that over a sufficiently large (40k) number of samples, the mean and variance
    will tend to 0.0 and 1.0 respectively, since that’s what we expect [torch.randn_like()](https://pytorch.org/docs/stable/generated/torch.randn_like.html)
    to generate.
  prefs: []
  type: TYPE_NORMAL
- en: We see that the difference between the manually computed mean and variance over
    the entire input and the mean and variance computed using BatchNorm2d’s rolling
    average based method is close enough for all practical purposes. We can see that
    the means computed using BatchNorm2d are consistently higher or lower (by up to
    40x) than those computed manually. However, in practical terms, this should not
    matter.
  prefs: []
  type: TYPE_NORMAL
- en: Caveats
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are definitely pros and cons of using this Batch normalization substitution
    in place of manual normalization, and this article wouldn’t be complete without
    a detailed comparison between the 2 in terms of when each one may or may not be
    applicable.
  prefs: []
  type: TYPE_NORMAL
- en: Transfer learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When using transfer learning, it is often recommended to keep the normalization
    method used in the [pre-trained model](https://pytorch.org/vision/main/models.html)
    to avoid introducing unnecessary changes. In this case, it may not be appropriate
    to replace manual normalization with batch normalization.
  prefs: []
  type: TYPE_NORMAL
- en: For example, here’s what the torchvision page has to say on this subject.
  prefs: []
  type: TYPE_NORMAL
- en: “Before using the pre-trained models, one must preprocess the image (resize
    with right resolution/interpolation, apply inference transforms, rescale the values
    etc). There is no standard way to do this as it depends on how a given model was
    trained. It can vary across model families, variants or even weight versions.
    Using the correct preprocessing method is critical and failing to do so may lead
    to decreased accuracy or incorrect outputs.”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Training Efficiency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When considering training efficiency, it may be beneficial to pre-compute the
    mean and variance of your dataset and hard-code it as a pre-training normalization
    step. This prevents the repeated computation of these statistics during training.
  prefs: []
  type: TYPE_NORMAL
- en: Note that using either method uses an equal amount of compute during inference
    since you’ll normalize the inputs using the computed mean and variance either
    before feeding the inputs into the model (manually computed) or as the first step
    of the model (using Batch normalization).
  prefs: []
  type: TYPE_NORMAL
- en: Human Efficiency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Based on what we’ve seen above, it’s much easier for a human to stick a Batch
    normalization layer instead of manually computing statistics.
  prefs: []
  type: TYPE_NORMAL
- en: Data Augmentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When augmenting inputs before feeding them into the model, one must be careful
    to apply the normalization **after** all the augmentation and other pre-processing
    steps are done to avoid computing incorrect statistics. For example, if you’re
    using a [ColorJitter transform](https://pytorch.org/vision/main/generated/torchvision.transforms.ColorJitter.html#torchvision.transforms.ColorJitter),
    then it will change the computed statistics meaningfully.
  prefs: []
  type: TYPE_NORMAL
- en: This leads us to another interesting question ***“When should the mean and variance
    of the dataset be computed when using data augmentation?”***
  prefs: []
  type: TYPE_NORMAL
- en: This is tricky since manually computing the mean and variance accurately across
    augmented inputs would require you to know a priori which images will be augmented
    with which transforms, and then requires you to compute the statistics and apply
    augmentations during model training in a consistent manner. This is somewhat hard
    to do in general since augmentations are applied to input images at random. In
    addition, the same image is augmented differently at every training epoch to prevent
    the model from overfitting on the training dataset. Hence, in this case, using
    Batch normalization would result in better model accuracy as well, since it’s
    computing the mean and variance on the augmented image and not on the original
    un-augmented images.
  prefs: []
  type: TYPE_NORMAL
- en: Mini-batch distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since Batch normalization computes the mean and variance of the mini-batch for
    normalizing values during training, it is important to randomize the input data
    to ensure the mean and variance of the mini-batch are somewhat representative
    of the entire training dataset. If your mini-batches are small or biased, then
    you should consider un-biasing them or using manual normalization.
  prefs: []
  type: TYPE_NORMAL
- en: This problem doesn’t exist at test or inference time.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Normalization is an important pre-processing step in any vision AI pipeline.
    Computing it correctly and efficiently via manual steps can be tedious and error
    prone. Using Batch normalization as the first layer of your vision AI model is
    a viable substitute for manual normalization in many scenarios.
  prefs: []
  type: TYPE_NORMAL
