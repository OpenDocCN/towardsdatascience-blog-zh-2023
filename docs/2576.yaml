- en: Turn and Face the Strange
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/turn-and-face-the-strange-a3a59fdb69e5?source=collection_archive---------7-----------------------#2023-08-11](https://towardsdatascience.com/turn-and-face-the-strange-a3a59fdb69e5?source=collection_archive---------7-----------------------#2023-08-11)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How to leverage anomaly detection methods to improve your supervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@efowler_86027?source=post_page-----a3a59fdb69e5--------------------------------)[![Evie
    Fowler](../Images/74aa5bfa8932dbca98a4bde7777e03ea.png)](https://medium.com/@efowler_86027?source=post_page-----a3a59fdb69e5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a3a59fdb69e5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a3a59fdb69e5--------------------------------)
    [Evie Fowler](https://medium.com/@efowler_86027?source=post_page-----a3a59fdb69e5--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fabec8950b7b6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fturn-and-face-the-strange-a3a59fdb69e5&user=Evie+Fowler&userId=abec8950b7b6&source=post_page-abec8950b7b6----a3a59fdb69e5---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a3a59fdb69e5--------------------------------)
    ·7 min read·Aug 11, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa3a59fdb69e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fturn-and-face-the-strange-a3a59fdb69e5&user=Evie+Fowler&userId=abec8950b7b6&source=-----a3a59fdb69e5---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa3a59fdb69e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fturn-and-face-the-strange-a3a59fdb69e5&source=-----a3a59fdb69e5---------------------bookmark_footer-----------)![](../Images/b8b76ad770f0f7491e6863f3e079d911.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Stefan Fluck](https://unsplash.com/@sfluck?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/twIzCL3YSRI?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditional predictive analytics offers two paradigms through which to view
    most problems: point estimation and classification. Modern data science is largely
    concerned with the latter, framing many questions in terms of categorization (think
    of how an insurer might seek to identify which clients will generate high costs,
    rather than predict costs for each client; or how a marketer might be more interested
    in which ads will return positive ROI rather than predicting the specific ROI
    of each ad). Given that, data scientists have developed and are familiar with
    a number of classification methods, from logistic regression to tree and forest
    based methods to neural nets. There’s a hitch, though — many of these methods
    work best on data with roughly balanced outcome classes, which real world applications
    rarely deliver. In this piece, I’ll show how to use anomaly detection methods
    to mitigate the problems created by imbalanced outcome classes in supervised learning.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s imagine that I’m planning a trip out of my home city of Pittsburgh, Pennsylvania.
    I’m not picky about where I go, but I’d really like to avoid travel hiccups like
    a canceled, diverted, or even severely delayed flight. A classification model
    could help me identify which flights are likely to experience problems, and [Kaggle](https://www.kaggle.com/datasets/robikscube/flight-delay-dataset-20182022)
    has some data that could help me build one.
  prefs: []
  type: TYPE_NORMAL
- en: I begin by reading in my data and developing my own definition of a bad flight
    — anything canceled, diverted, or with an arrival delay longer than 30 minutes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: About 15% of flights fall into my “bad flights” category. That’s not low enough
    to traditionally consider this an anomaly detection problem, but it is low enough
    that supervised methods might not perform as well as I’d hope. Nevertheless, I’ll
    get started by building a simple gradient boosted tree model to predict whether
    a flight will experience the type of problem I’d like to avoid.
  prefs: []
  type: TYPE_NORMAL
- en: To begin I need to identify which features I’d like to use in my model. For
    the sake of this example I’ll select just a few promising-looking features to
    model with; in reality, feature selection is a very important part of any data
    science project. Most of the features available here are categorical and need
    to be encoded as part of this data prep stage; the distance between cities needs
    to be scaled.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The development and tuning of a tree based model could easily be its own post,
    so I won’t get into it here. I’ve used the feature importance ratings of an initial
    model to do some reverse feature selection, and tuned the model from there. The
    resulting model performs decently at identifying late, canceled, or diverted flights.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: But could it be better? Perhaps there is more to be learned about flight patterns
    using other methods. An isolation forest is a tree-based anomaly detection method.
    It works by iteratively selecting a random feature from the input dataset, and
    a random split point along the range of that feature. It continues building a
    tree this way until each observation in the input dataset has been split into
    its own leaf. The idea is that anomalies, or data outliers, are different from
    other observations, and so it is easier to isolate them with this pick and split
    process. Thus, observations that are isolated with just a few rounds of pick and
    split are considered anomalous, and those that can’t be separated from their neighbors
    quickly are not.
  prefs: []
  type: TYPE_NORMAL
- en: The isolation forest is an unsupervised method, so it can’t be used to identify
    a particular kind of anomaly of the data scientist’s own choosing (e.g. canceled,
    diverted, or very late flights). Still, it can be useful for identifying observations
    that are different from others in some unspecified way (e.g. flights on which
    something is different).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Combining the anomaly scores with the supervised model scores provides additional
    insight.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: There are a few things to note here. One is that the supervised model is better
    at predicting “good” flights than “bad” flights — this is a common dynamic in
    rare event prediction, and why it’s important to look at metrics like precision
    and recall on top of simple accuracy. More interesting is the fact that the “bad
    flight” rate is nearly 1.5 times higher among flights the isolation forest has
    classified as anomalous. That’s in spite of the fact that the isolation forest
    is an unsupervised method and is identifying atypical flights in general, rather
    than flights that are atypical in the particular way I’d like to avoid. This seems
    like it must be valuable information for the supervised model. The binary outlier
    flag is already in a good format to use as a predictor in my supervised model,
    so I will feed it in and see if it improves model performance.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Including outlier status as a predictor in the supervised model does in fact
    boost its top decile lift by several points. It seems that being “strange” in
    an undefined way is sufficiently correlated with my desired outcome as to provide
    predictive power.
  prefs: []
  type: TYPE_NORMAL
- en: There are limits to how useful this quirk is, of course. It’s certainly not
    true of *all* imbalanced classification problems, and isn’t particularly helpful
    if explainability is very important to the final product. Still, this alternative
    framing can provide helpful insights on a variety of classification problems,
    and is worth a try.
  prefs: []
  type: TYPE_NORMAL
