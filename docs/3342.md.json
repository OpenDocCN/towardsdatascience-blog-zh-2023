["```py\nimport torch\nfrom torch.nn import Linear, Dropout\nfrom torch_geometric.nn import SAGEConv, GATv2Conv, GCNConv\nimport torch.nn.functional as F\n\nclass GraphSAGE(torch.nn.Module):\n  \"\"\"GraphSAGE\"\"\"\n  def __init__(self, dim_in, dim_h, dim_out):\n    super().__init__()\n    self.sage1 = SAGEConv(dim_in, dim_h)\n    self.sage2 = SAGEConv(dim_h, dim_out)#830 for my case\n    self.optimizer = torch.optim.Adam(self.parameters(),\n                                      lr=0.01,\n                                      weight_decay=5e-4)\n\n  def forward(self, x, edge_index):\n    h = self.sage1(x, edge_index).relu()\n    h = F.dropout(h, p=0.5, training=self.training)\n    h = self.sage2(h, edge_index)\n    return F.log_softmax(h, dim=1)\n\n  def fit(self, data, epochs):\n    criterion = torch.nn.CrossEntropyLoss()\n    optimizer = self.optimizer\n\n    self.train()\n    for epoch in range(epochs+1):\n      total_loss = 0\n      acc = 0\n      val_loss = 0\n      val_acc = 0\n\n      # Train on batches\n      for batch in train_loader:\n        optimizer.zero_grad()\n        out = self(batch.x, batch.edge_index)\n        loss = criterion(out[batch.train_mask], batch.y[batch.train_mask])\n        total_loss += loss\n        acc += accuracy(out[batch.train_mask].argmax(dim=1), \n                        batch.y[batch.train_mask])\n        loss.backward()\n        optimizer.step()\n\n        # Validation\n        val_loss += criterion(out[batch.val_mask], batch.y[batch.val_mask])\n        val_acc += accuracy(out[batch.val_mask].argmax(dim=1), \n                            batch.y[batch.val_mask])\n\n      # Print metrics every 10 epochs\n      if(epoch % 10 == 0):\n          print(f'Epoch {epoch:>3} | Train Loss: {total_loss/len(train_loader):.3f} '\n                f'| Train Acc: {acc/len(train_loader)*100:>6.2f}% | Val Loss: '\n                f'{val_loss/len(train_loader):.2f} | Val Acc: '\n                f'{val_acc/len(train_loader)*100:.2f}%')\n\ndef accuracy(pred_y, y):\n    \"\"\"Calculate accuracy.\"\"\"\n    return ((pred_y == y).sum() / len(y)).item()\n\n@torch.no_grad()\ndef test(model, data):\n    \"\"\"Evaluate the model on test set and print the accuracy score.\"\"\"\n    model.eval()\n    out = model(data.x, data.edge_index)\n    acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n    return acc\n```", "```py\nprobabilities = torch.softmax(raw_output, dim = 1)\n#torch.topk to get the top 3 probabilites and their indices for each prediction\ntopk_values, topk_indices = torch.topk(probabilities, k = 2, dim = 1)\n```"]