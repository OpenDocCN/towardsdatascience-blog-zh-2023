["```py\ndef preprocess(image):\n    resized_image = cv2.resize(image, (416, 416))\n    blob = cv2.dnn.blobFromImage(resized_image, 1 / 255, (416, 416), swapRB=True, crop=False)\n    return resized_image, blob\n```", "```py\nold_frame = None\nwhile True:\n    # read the stream and get the current image\n    cap = cv2.VideoCapture(BORDER_URL.m3u8)\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n    # resize the image to correct formant\n    image, blob = preprocess(frame)\n\n    # check if the image is the same as the previous one by calculating the mean squared error between the two\n    if old_frame is not None:\n        mse = np.mean((image - old_frame) ** 2)\n        if mse < 0.001:\n            old_frame = image\n            continue\n```", "```py\ndef detect_cars(image, blob):\n    net = cv2.dnn.readNet(\"./yolov3.weights\", \"./yolov3.cfg\")\n    net.setInput(blob)\n    layer_names = net.getLayerNames()\n    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n    predictions = net.forward(output_layers)\n    boxes = []\n    confidences = []\n    class_ids = []\n    centers = []\n    for prediction in predictions:\n        for detection in prediction:\n            scores = detection[5:]\n            class_id = int(np.argmax(scores))\n            confidence = float(scores[class_id])\n\n            # Filter out weak detections\n            if confidence > 0.5:\n                # Get detection coordinates\n                x, y, w, h = (detection[0:4] * np.array(\n                    [image.shape[1], image.shape[0], image.shape[1], image.shape[0]])).astype(\"int\")\n                x = int(x - w / 2)\n                y = int(y - h / 2)\n\n                center_x = int(x + w // 2)\n                center_y = int(y + h // 2)\n\n                centers.append((center_x, center_y))\n                boxes.append([int(x), int(y), int(x + w), int(y + h)])\n                confidences.append(float(confidence))\n                class_ids.append(class_id)\n\n    return boxes, confidences, class_ids, centers\n```", "```py\ndef NMS(boxes, confidences, threshold):\n    if len(boxes) == 0:\n        return []\n\n    boxes = np.array(boxes)\n    x1 = boxes[:, 0]\n    y1 = boxes[:, 1]\n    x2 = boxes[:, 2]\n    y2 = boxes[:, 3]\n\n    scores = confidences\n    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n    order = scores.argsort()[::-1]\n\n    keep = []\n    while order.size > 0:\n        i = order[0]\n        keep.append(i)\n        xx1 = np.maximum(x1[i], x1[order[1:]])\n        yy1 = np.maximum(y1[i], y1[order[1:]])\n        xx2 = np.minimum(x2[i], x2[order[1:]])\n        yy2 = np.minimum(y2[i], y2[order[1:]])\n\n        w = np.maximum(0.0, xx2 - xx1 + 1)\n        h = np.maximum(0.0, yy2 - yy1 + 1)\n        inter = w * h\n        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n\n        inds = np.where(ovr <= threshold)[0]\n        order = order[inds + 1]\n\n    return keep\n```", "```py\ndef get_x_at_y(line, y):\n    loc = -1\n    for segment in range(len(line)-1):\n        if line[segment][1] <= y <= line[segment + 1][1] or line[segment][1] >= y >= line[segment + 1][1]:\n            loc = segment\n    if loc == -1:\n        return None\n    slope = (line[segment+1][1] - line[segment][1]) / (line[segment+1][0]-line[segment][0])\n    return (y-line[segment+1][1])/slope + line[segment+1][0]\n\ndef track_lanes(car_centers, image, lanes):\n    if len(car_centers) < 2:\n        return []\n    ccs_with_pos = []\n    for cc in car_centers:\n        xs = []\n        for lane in lanes:\n            xs.append(get_x_at_y(lane, cc[1]))\n        dists = []\n        if None in xs:\n            ccs_with_pos.append((cc, -1))\n            continue\n        for x in xs:\n            dists.append(x-cc[0])\n        if dists[0]>0 or dists[-1]<0:\n            ccs_with_pos.append((cc, -1))\n            continue\n        # check if x value of the car is between each two lines\n        for i in range(len(dists)-1):\n            if dists[i] < 0 < dists[i + 1]:\n                ccs_with_pos.append((cc, i))\n                break\n    return ccs_with_pos\n```", "```py\ndef optical_flow(image, prev_image, features_to_track, lanes, cars_in_lanes):\n    if len(cars_in_lanes) == 0:\n        return list([-1 for el in range(len(lanes))])\n    feature_params = dict(maxCorners=100,\n                          qualityLevel=0.3,\n                          minDistance=20,\n                          blockSize=7)\n    lk_params = dict(winSize=(30, 30),\n                     maxLevel=5,\n                     criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n\n    prev_gray = cv2.convertScaleAbs(prev_image)\n    prev_gray = cv2.cvtColor(prev_gray, cv2.COLOR_BGR2GRAY)\n    p0 = np.array(features_to_track).reshape((-1, 1, 2))\n    p0 = np.float32(p0)\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    # Compute optical flow\n    p1, st, err = cv2.calcOpticalFlowPyrLK(prev_gray, gray, p0, None, **lk_params)\n\n    # Filter good points\n    good_new = p1[st == 1]\n    good_prev = p0[st == 1]\n\n    # Find the speed of each lane\n    lane_speeds = list([0 for el in range(len(lanes))])\n    for i, (new, prev) in enumerate(zip(good_new, good_prev)):\n        x_new, y_new = new.ravel()\n        x_prev, y_prev = prev.ravel()\n        xs_new = []\n        xs_old = []\n        for lane in lanes:\n            xs_new.append(get_x_at_y(lane, y_new))\n            xs_old.append(get_x_at_y(lane, y_prev))\n        dists_new = []\n        dists_old = []\n        if None in xs_new or None in xs_old:\n            continue\n        for x in xs_new:\n            dists_new.append(x - x_new)\n        for x in xs_old:\n            dists_old.append(x - x_prev)\n        if dists_new[0] > 0 or dists_new[-1] < 0 or dists_old[0] > 0 or dists_old[-1] < 0:\n            continue\n        lane_new = None\n        lane_old = None\n        for j in range(len(dists_new) - 1):\n            if dists_new[j] < 0 < dists_new[j + 1]:\n                lane_new = j\n                break\n        for j in range(len(dists_old) - 1):\n            if dists_old[j] < 0 < dists_old[j + 1]:\n                lane_old = j\n                break\n        lane_speeds[lane_new] += math.dist([x_new, y_new],[x_prev, y_prev])\n\n    for i, ls in enumerate(lane_speeds):\n        cnt = 0\n        for car in cars_in_lanes:\n            if car[1] == i:\n                cnt += 1\n        if cnt == 0:\n            lane_speeds[i] = -1\n            continue\n        lane_speeds[i] = lane_speeds[i]/cnt\n\n    return lane_speeds\n```", "```py\ndef calc_movement(new_movement, old_movement, sum_movement):\n    for i in range(len(new_movement)):\n        if new_movement[i] > old_movement[i] + 1:\n            sum_movement[i] += 1\n    return sum_movement\n```", "```py\n def visualize(boxes, centers, class_ids, keep, image, colors, lanes, ccs_with_pos):\n    for lane in lanes:\n        cv2.polylines(image, [np.array(lane).reshape((-1, 1, 2))], False, (0,0,255), 2)\n    for i, (box, c, ci) in enumerate(zip(boxes, centers, class_ids)):\n        if i not in keep:\n            continue\n        class_list = ['car', 'motorbike', 'bus', 'truck', 'person']\n        if classes[ci] in class_list:\n            color = colors[class_list.index(classes[ci])]\n            thickness = 2\n            x, y, w, h = box\n            cv2.rectangle(image, (x, y), (w, h), color, thickness)\n\n    if ccs_with_pos is not None:\n        prev_vehs = list([None for el in range(len(lanes))])\n        for i in range(416, 0, -1):\n            for car in ccs_with_pos:\n                if car[0][1] == i and car[1] != -1:\n                    if prev_vehs[car[1]] is None:\n                        prev_vehs[car[1]] = car\n                        cv2.putText(image, 'lane ' + str(car[1]+1), (car[0][0]-10, car[0][1]+10), cv2.FONT_HERSHEY_SIMPLEX,\n                                    0.5, (255, 0, 0), 2, cv2.LINE_AA)\n                    else:\n                        cv2.line(image, car[0], prev_vehs[car[1]][0], (255,0,0), 2)\n                        prev_vehs[car[1]] = car\n    cv2.imshow(\"image\", image)\n```", "```py\nversion: '3'\nservices:\n  api:\n    container_name: api\n    build:\n      context: ./api\n      dockerfile: Dockerfile\n    image: api:latest\n    ports:\n      - 80:80\n    restart: always\n\n  yolo:\n    build: ./yolo_detector\n    command: python script.py\n    container_name: yolo\n    ports:\n      - 5001:5001\n    restart: always\n\n  script0:\n    build: ./image_processing\n    command: python count.py 0\n    container_name: script0\n    restart: always\n\n  script1:\n    build: ./image_processing\n    command: python count.py 1\n    container_name: script1\n    restart: always\n\n  ...\n```"]