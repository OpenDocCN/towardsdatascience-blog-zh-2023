["```py\nbin/zookeeper-server-start.sh config/zookeeper.properties\n```", "```py\nbin\\windows\\zookeeper-server-start.bat .\\config\\zookeeper.properties\n```", "```py\nbin/kafka-server-start.sh config/server.properties\n```", "```py\nbin\\windows\\kafka-server-start.bat .\\config\\server.properties\n```", "```py\nbin/kafka-topics.sh --create --topic transactions --bootstrap-server localhost:9092\n```", "```py\nbin\\windows\\kafka-topics.bat --create --topic transactions --bootstrap-server localhost:9092\n```", "```py\n>>> import pandas as pd\n>>> df = pd.read_csv(\"online_retail_II.csv\", encoding=\"unicode_escape\")\n>>> print(df.info())\n```", "```py\nRangeIndex: 1067371 entries, 0 to 1067370\nData columns (total 8 columns):\n# Column Non-Null Count Dtype\n - - - - - - - - - - - - - - -\n0 Invoice 1067371 non-null object\n1 StockCode 1067371 non-null object\n2 Description 1062989 non-null object\n3 Quantity 1067371 non-null int64\n4 InvoiceDate 1067371 non-null object\n5 Price 1067371 non-null float64\n6 Customer ID 824364 non-null float64\n7 Country 1067371 non-null object\ndtypes: datetime64[ns](1), float64(2), int64(1), object(4)\nmemory usage: 65.1+ MB\n```", "```py\n>>> df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n>>> df.set_index('InvoiceDate', inplace=True)\n```", "```py\n# Import packages\nimport pandas as pd\nimport json\nimport datetime as dt\nfrom time import sleep\nfrom kafka import KafkaProducer\n\n# Initialize Kafka Producer Client\nproducer = KafkaProducer(bootstrap_servers=['localhost:9092'])\nprint(f'Initialized Kafka producer at {dt.datetime.utcnow()}')\n```", "```py\n# Set a basic message counter and define the file path\ncounter = 0\nfile = \"online_retail_II.csv\"\n\nfor chunk in pd.read_csv(file,encoding='unicode_escape',chunksize=10):\n\n  # For each chunk, convert the invoice date into the correct time format\n  chunk[\"InvoiceDate\"] = pd.to_datetime(chunk[\"InvoiceDate\"])\n\n  # Set a counter as the message key\n  key = str(counter).encode()\n\n  # Convert the data frame chunk into a dictionary\n  chunkd = chunk.to_dict()\n\n      # Encode the dictionary into a JSON Byte Array\n      data = json.dumps(chunkd, default=str).encode('utf-8')\n\n      # Send the data to Kafka\n      producer.send(topic=\"transactions\", key=key, value=data)\n\n      # Sleep to simulate a real-world interval\n      sleep(0.5)\n\n      # Increment the message counter for the message key\n      counter = counter + 1\n\n      print(f'Sent record to topic at time {dt.datetime.utcnow()}')\n```", "```py\nfrom kafka import KafkaConsumer\nimport json\nimport pandas as pd\n\n# Consume all the messages from the topic but do not mark them as 'read' (enable_auto_commit=False)\n# so that we can re-read them as often as we like.\nconsumer = KafkaConsumer('transactions',\n                         group_id='test-consumer-group',\n                         bootstrap_servers=['localhost:9092'],\n                         value_deserializer=lambda m: json.loads(m.decode('utf-8')),\n                         auto_offset_reset='earliest',\n                         enable_auto_commit=False)\n```", "```py\nfor message in consumer:\n    mframe = pd.DataFrame(message.value)\n\n    # Multiply the quantity by the price and store in a new \"revenue\" column\n    mframe['revenue'] = mframe.apply(lambda x: x['Quantity'] * x['Price'], axis=1)\n\n    # Aggregate the StockCodes in the individual batch by revenue\n    summary = mframe.groupby('StockCode')['revenue'].sum()\n\n    print(summary)\n```", "```py\nName: revenue, dtype: float64\nStockCode\n16161P 10.50\n16169N 10.50\n21491 11.70\n22065 17.40\n22138 44.55\n22139 44.55\n22352 30.60\n85014A 17.85\n85014B 17.85\n85183B 144.00\n```"]