- en: 'Clearing the Dust: How CNNs and Transfer Learning Can Detect Dust on Solar
    Panels'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/clearing-the-dust-how-cnns-and-transfer-learning-can-detect-dust-on-solar-panels-7f4892405123?source=collection_archive---------6-----------------------#2023-03-15](https://towardsdatascience.com/clearing-the-dust-how-cnns-and-transfer-learning-can-detect-dust-on-solar-panels-7f4892405123?source=collection_archive---------6-----------------------#2023-03-15)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: With the aid of convolutional neural networks and transfer learning, it is possible
    to build a classifier in determining whether solar panels are clean or dusty
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://suhas-maddali007.medium.com/?source=post_page-----7f4892405123--------------------------------)[![Suhas
    Maddali](../Images/933f27eab8ba9ee1f06ed2f24746d788.png)](https://suhas-maddali007.medium.com/?source=post_page-----7f4892405123--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7f4892405123--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7f4892405123--------------------------------)
    [Suhas Maddali](https://suhas-maddali007.medium.com/?source=post_page-----7f4892405123--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2a74f90399ae&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclearing-the-dust-how-cnns-and-transfer-learning-can-detect-dust-on-solar-panels-7f4892405123&user=Suhas+Maddali&userId=2a74f90399ae&source=post_page-2a74f90399ae----7f4892405123---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7f4892405123--------------------------------)
    ·15 min read·Mar 15, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7f4892405123&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclearing-the-dust-how-cnns-and-transfer-learning-can-detect-dust-on-solar-panels-7f4892405123&user=Suhas+Maddali&userId=2a74f90399ae&source=-----7f4892405123---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7f4892405123&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclearing-the-dust-how-cnns-and-transfer-learning-can-detect-dust-on-solar-panels-7f4892405123&source=-----7f4892405123---------------------bookmark_footer-----------)![](../Images/c640f9174c213c720fbad0176255063c.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Moritz Kindler](https://unsplash.com/@moritz_photography?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '**Solar panels** have become a popular source of renewable energy in a variety
    of industries, from agriculture and transportation to construction and hospitality.
    By harnessing the power of the sun, we can generate electricity without harming
    the environment. However, there are challenges associated with using solar panels,
    and one of the biggest is the accumulation of **dust** on their surfaces. This
    can significantly reduce their efficiency and limit their usefulness for energy
    production and other applications.'
  prefs: []
  type: TYPE_NORMAL
- en: To address this issue, automation can play a key role in ensuring regular and
    timely maintenance of solar panels. By automating the cleaning process, we can
    increase **productivity** and **efficiency**, while also reducing the **environmental
    impact** of energy generation. Overall, the potential **benefits** of solar panels
    are vast and varied, and with the help of automation, we can overcome the challenges
    associated with their use and continue to drive progress in this exciting and
    rapidly-evolving field.
  prefs: []
  type: TYPE_NORMAL
- en: With the aid of deep learning and heavy computing resources, it is possible
    to alert the authorities when there is dust accumulation in solar panels. **Convolutional
    Neural Networks (CNNs)** are known for their image recognition abilities. **Transfer
    learning** is an approach that uses pre-trained weights for complex tasks for
    our task of solar panel dust detection. Therefore, these methods could be leveraged
    to improve the accuracy and f1-score of deep learning models.
  prefs: []
  type: TYPE_NORMAL
- en: We will be **implementing** a project in this article about building a solar
    panel dust detection classifier. A large number of neural network configurations
    are tested to finally determine the best architecture to be deployed in real-time
    to aid in determining dust in solar panels.
  prefs: []
  type: TYPE_NORMAL
- en: Reading the libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will be looking at a list of libraries that were used in the process of building
    a solar panel dust detection classifier.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to building deep learning applications, there are a **wealth**
    of libraries at our disposal, including TensorFlow, NumPy, Pandas, and OS. While
    it may seem overwhelming at first, understanding how to use these libraries in
    code can greatly simplify the development process and make our models more effective.
  prefs: []
  type: TYPE_NORMAL
- en: By leveraging these powerful tools, we can **streamline** data processing, feature
    engineering, model training, and deployment. With a solid grasp of these libraries
    and their capabilities, we can build more complex and accurate models with greater
    ease and efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we’ll be using these libraries **extensively** to build our
    solar panel dust detection classifier. Through practical examples and **step-by-step**
    instructions, you’ll learn how to harness the power of these tools and apply them
    to real-world problems.
  prefs: []
  type: TYPE_NORMAL
- en: Reading the Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To begin building our solar panel dust detection classifier, the first step
    is to load the images from **pre-defined paths** on our local computer. However,
    the exact location of these images may vary depending on the user’s computer configuration.
  prefs: []
  type: TYPE_NORMAL
- en: To perform this loading operation, we define a separate function that extracts
    the images from the specified paths while discarding any **low-resolution** images.
    This ensures that our dataset only contains high-quality images that are suitable
    for training our deep learning model.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** The dataset was taken from [Solar Panel dust detection | Kaggle](https://www.kaggle.com/datasets/hemanthsai7/solar-panel-dust-detection)
    under [Creative Commons — CC0 1.0 Universal](https://creativecommons.org/publicdomain/zero/1.0/)
    license'
  prefs: []
  type: TYPE_NORMAL
- en: We have stored the clean and dusty solar panels as a list of arrays that are
    used for computation. Note that we are dealing with a small dataset, there are
    no issues such as out-of-memory errors. If dealing with a large dataset, it is
    recommended to use ImageDataGenerator as it loads data from **disk** in **batches**.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exploratory Data Analysis (EDA)**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is an important part of a machine learning lifecycle where the dataset
    used by ML models is examined to see if there are **discrepancies** and **outliers**
    in data. In this way, feature engineering steps can be taken to remove such datapoints
    and aid in building a strong classifier.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/708a28f6e223f5d6eaa715b2e06d2a89.png)'
  prefs: []
  type: TYPE_IMG
- en: Solar Panel Images (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: Above is a list of images that we are going to be using in the classifier for
    it to determine whether the panels are clean or dusty. It is to be noted that
    there are few images that contain text. There are other images that contain white
    backgrounds or are not cropped appropriately. During the feature engineering phase,
    therefore, steps are taken to **remove** these images as they can confuse our
    classifier in making accurate predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Feature Engineering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to ensure that only **high-quality** images are used for training,
    we take steps to discard images with a **white background** in the dataset. This
    is achieved by implementing the following code, which identifies and removes any
    images with a predominantly white background. By doing so, we can improve the
    overall accuracy and reliability of the model’s training process.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/93a37127305681bc4124ad78171207d1.png)'
  prefs: []
  type: TYPE_IMG
- en: Solar Panels with White Background (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: It is seen based on the output that the white background images are accurately
    identified. However, there are a few false positives in the data. But we can go
    ahead and use this method to collect images without white background.
  prefs: []
  type: TYPE_NORMAL
- en: Model Training
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let us look at a list of all the possible models that could be used to train
    a solar panel dust classifier. The initial configuration is a convolutional neural
    network with decent layer depth. There are layers such as the **convolution layer**,
    **max-pooling layer** and **flatten layers**. Below is the code implementation.
  prefs: []
  type: TYPE_NORMAL
- en: '**Configuration 1**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d856b265a33c2c71f4561738be89a45d.png)![](../Images/17df8ffc4c14161be59a8782a253441a.png)![](../Images/32ced378f50864164939c7b98a94196d.png)'
  prefs: []
  type: TYPE_IMG
- en: Model Performance, Model Architecture and Classification Report (Images by Author)
  prefs: []
  type: TYPE_NORMAL
- en: There is a function that is designed to **plot** a list of all the metrics and
    give us a good understanding of the performance of models with these metrics.
    There is information such as classification reports, confusion matrices, and other
    plots that help guide us in determining the best models to be used for production.
  prefs: []
  type: TYPE_NORMAL
- en: With the increase in the number of epochs, there is an improvement in the accuracy
    and also a decrease in the error. In addition, it is good to note that the cross-validation
    error is also reduced with additional training. This implies that there is still
    more room for further training. Care must be taken such that the model does not
    **overfit** the training data. We can look at other configurations as well to
    determine the best model to be deployed in real-time.
  prefs: []
  type: TYPE_NORMAL
- en: '**Configuration 2**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9047f62b65e3f933458aaa2471fec525.png)![](../Images/798fdbc50e64c66962f28d953d83e6b0.png)![](../Images/0461065588f55c65f2dc5226fbe1fb43.png)'
  prefs: []
  type: TYPE_IMG
- en: Model Performance, Model Architecture and Classification Report (Images by Author)
  prefs: []
  type: TYPE_NORMAL
- en: A new configuration is defined as shown in the code above. Metrics are tracked
    for the dataset about its performance. This configuration tends to overfit the
    data as there is a good improvement in the training accuracy while decreasing
    or a **steady value** for cross-validation accuracy. This is also reflected by
    the loss curves as with the increase in the number of epochs, there is a reduction
    in training loss while an increase in the cross-validation loss. Hence this model
    is overfitting the training data without much improvement on the test set.
  prefs: []
  type: TYPE_NORMAL
- en: '**Configuration 3**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/57336ecd249caaa2cffee467e0151f16.png)![](../Images/70694fe228b21ac6cbdca0973a648638.png)![](../Images/df460486af5d0cd7ac4fadc0b34ebde4.png)'
  prefs: []
  type: TYPE_IMG
- en: Model Performance, Model Architecture and Classification Report (Images by Author)
  prefs: []
  type: TYPE_NORMAL
- en: This configuration also behaves similarly to the previous configuration where
    there is an issue with overfitting. However, these curves show that the model
    is not overfitting too much on the training data as compared to the previous configuration.
    The accuracy of the model on the test data is about **68 percent** on the test
    data. The precision on the positive class is quite low as well. As a result, additional
    configurations and transfer learning methodologies can be used to improve the
    performance of the model to a large extent.
  prefs: []
  type: TYPE_NORMAL
- en: '**Configuration 4**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9b379a9dc95e62cba9161a43aa012fea.png)![](../Images/60e6fee29d3bea49c723c20586028308.png)![](../Images/b193d7a3ec1bc6537ae5269e2dd9a7fd.png)'
  prefs: []
  type: TYPE_IMG
- en: Model Performance, Model Architecture and Classification Report (Images by Author)
  prefs: []
  type: TYPE_NORMAL
- en: This model performance is quite similar to the previous two configurations that
    were tested. There is overfitting on the training data as illustrated in the training
    and loss curves. Defining custom configurations of CNN was not working as intended
    especially giving rise to lower accuracy and lower f1-score for the positive class.
    Additional models with increased **complexity** can be used as they should be
    able to find underlying patterns in the data and make good predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Transfer Learning Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can go ahead and look at a list of transfer learning models and determine
    the performance on the test set. These models are pre-trained on **ImageNet**
    data that contain a large number of samples. We extract the weights of these networks
    for our task of solar panel dust detection and retrain the last few layers to
    **save computation**.
  prefs: []
  type: TYPE_NORMAL
- en: '**VGG 16**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/07cae3982bb00052fe988a061d4b43ed.png)![](../Images/53e33fbabf1146dc627550c27af8a9d6.png)![](../Images/cab6f6716df8b40f5f0175e7c3e5fa5e.png)'
  prefs: []
  type: TYPE_IMG
- en: Model Performance, Model Architecture and Classification Report (Images by Author)
  prefs: []
  type: TYPE_NORMAL
- en: The architecture seems to be performing well with an accuracy of about **70
    percent** on the test data. However, there tends to be some overfitting on the
    cross-validation data. As a result, there is a decrease in the accuracy with the
    increase in the number of epochs (iterations over the entire dataset). Let us
    also consider a list of other architectures and determine the best model to be
    deployed.
  prefs: []
  type: TYPE_NORMAL
- en: '**VGG 19**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/df539f6d705d342143b3af57fdffc1a1.png)![](../Images/51b6192ef9ad1232d1b6edcc60670b17.png)![](../Images/a20f24adc6158fbb565b858ef1472604.png)'
  prefs: []
  type: TYPE_IMG
- en: Model Performance, Model Architecture and Classification Report (Images by Author)
  prefs: []
  type: TYPE_NORMAL
- en: VGG 19 network tends to be performing **less accurately** as compared to VGG
    16\. This is because the former network is more complex, leading to a higher chance
    of overfitting. When we explored VGG 16 network, it was also prone to overfitting.
    By increasing the complexity of the network, there are higher chances that the
    model can overfit the training data.
  prefs: []
  type: TYPE_NORMAL
- en: '**InceptionNet**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/70178be37720af940b14aff1521b1400.png)![](../Images/3d2509130afb735407354a8c596edad0.png)![](../Images/ab876750288aa007187ceebf6adae8f3.png)![](../Images/1f2db537332a85bc66c52a91b7c2218b.png)![](../Images/ef9cb35dbf4e915951eaf72caa99799d.png)![](../Images/d9e5ec4cb35226c6b183e56ce1f2e122.png)![](../Images/1174a7606fedb0129009b57d508c29e2.png)![](../Images/754a4add12c277c0bfd97213857e1b09.png)![](../Images/c8af7bb45f90eaaaec44c3881dabee33.png)![](../Images/ca9f2a36847755f5b19369b9cce2bad1.png)![](../Images/e8a76196b5f68802500441a5a3213821.png)![](../Images/977cccc6e9a76c7d0e703fec0a329a78.png)'
  prefs: []
  type: TYPE_IMG
- en: Model Performance, Model Architecture and Classification Report (Images by Author)
  prefs: []
  type: TYPE_NORMAL
- en: The architecture for **InceptionNet** is quite complex as shown above with a
    large depth and a lot of hidden units. Since the network was already trained on
    “ImageNet”, we can extract useful weights from it and only consider training the
    last few layers to speed up the process. Overall, InceptionNet is performing the
    best on the test data with an accuracy of about **77 percent** on the test data.
  prefs: []
  type: TYPE_NORMAL
- en: '**MobileNet**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d5189d57bc5338f6a654134389ec0c2d.png)![](../Images/390af83bdc9f883445ae03132efc84a5.png)![](../Images/27d16b317d4575d8906aa538fe219262.png)![](../Images/a73b81a32d1341c75d41600774d0de2a.png)![](../Images/b37d117f3b4f6d76ad95782dfcb2c5bd.png)'
  prefs: []
  type: TYPE_IMG
- en: Model Performance, Model Architecture and Classification Report (Images by Author)
  prefs: []
  type: TYPE_NORMAL
- en: MobileNet was able to perform exceptionally well with an overall accuracy of
    about **79 percent** on the test data. The accuracy curves and loss curves also
    show that the model is trained well with an increase in performance not just on
    the training set but also on the cross-validation data. In addition, the model
    can be trained further and also used with hyperparameter tuning to improve the
    performance and generalization capabilities of the test data (unseen data). Note
    the computational complexity needed to make an inference. It indicates that it
    can generalize well with smaller configurations and is also able to deliver good
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: '**Xception Network**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/399e3c46336133ac0acb37c8dc991b42.png)![](../Images/e8b8aaf4e29a452857763e45da4c109d.png)![](../Images/430a3fa6f55261995140a293f542761d.png)![](../Images/5501d320216ecbfce482a6c351299e54.png)![](../Images/e0bcf7e2da911ce32db2a246c8b77f81.png)![](../Images/485952ee584f32d0e710bd9ad052a5fa.png)![](../Images/017bc893885fd05e54b0613d5c7c08c6.png)'
  prefs: []
  type: TYPE_IMG
- en: Model Performance, Model Architecture and Classification Report (Images by Author)
  prefs: []
  type: TYPE_NORMAL
- en: Xception architecture is also complex as shown above. The last few layers are
    modified to ensure that these are trainable for the task of solar panel dust detection.
    It shows a good performance on the test data with an accuracy of about **71 percent**.
    However, it tends to be overfitting as with the increase in the number of epochs,
    the gap between the training accuracy and cross-validation accuracy is increasing.
    MobileNet was performing the best out of all the models. But let us also explore
    a list of potential models to determine the best ones to use and make predictions.
  prefs: []
  type: TYPE_NORMAL
- en: '**MobileNetV2**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7c726f7fcec6318b537196ca0c8b8f41.png)![](../Images/17d2b803bede465c016993a0e86d9d54.png)![](../Images/0af2b5fac152c80e1be6469a8acd4444.png)![](../Images/7397ac19f3251d83d354810743334c33.png)![](../Images/fcfbb98cdfdeda25b75580331908ebbd.png)![](../Images/4b1ae495345c6aaf186906f188d37388.png)![](../Images/fc031229d81cafa82d8963b351d0f558.png)![](../Images/9b64b48c8c5007546de0e79914accd8c.png)'
  prefs: []
  type: TYPE_IMG
- en: Model Performance, Model Architecture and Classification Report (Images by Author)
  prefs: []
  type: TYPE_NORMAL
- en: The figures above show the architecture and the overall performance of MobileNetV2
    architecture on the image recognition task of predicting whether there are clean
    or dusty solar panels. This architecture is complex to a certain extent. On the
    final few set of layers, additional layers and units are added to optimize the
    weights for our task. The overall performance of the model was not as good as
    that of the initial MobileNet model that is referenced earlier. Furthermore, this
    architecture is **more complex**, and it requires good computing power to ensure
    that there are **low-latency** applications. Therefore, we can use MobileNet as
    one of the best models for deploying in real-time for making predictions.
  prefs: []
  type: TYPE_NORMAL
- en: '**ResNet 50**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f4690aed9e151bed5110146855c527cf.png)![](../Images/26648055402701c3beeed148d8003280.png)![](../Images/d7e9390224192113b8bed3998f7a990b.png)![](../Images/fd7910646b173e431da7ff9735b4cc2c.png)![](../Images/be38dfe6b41ea71b616988af7573f156.png)![](../Images/c7e9bfdf59dce72c51710a529ce52c6f.png)![](../Images/3ea4ea11e82b214e763a6aa3e768406d.png)![](../Images/0627fa23c6b7d8c16cea7f99f5fdd382.png)'
  prefs: []
  type: TYPE_IMG
- en: Model Performance, Model Architecture and Classification Report (Images by Author)
  prefs: []
  type: TYPE_NORMAL
- en: There is a lot of **randomness** in ResNet architecture when looking at curves
    such as the accuracy curve and the loss curve. Overall, there is an increasing
    trend when it comes to the accuracy of the cross-validation data. However, the
    model fails to capture important distinctions from the training data to make good
    predictions on the test data. As a result, it gives a sub-par performance on the
    test set. Further training could be performed to improve the performance. Considering
    the computational complexity, we can go ahead and use MobileNet architecture for
    deployment after performing hyperparameter optimization. ResNet can be good for
    other image-related tasks but for this task, MobileNet performs the best.
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameter Tuning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This step is important in computer vision where the best model is taken and
    the hyperparameters are altered to determine the change in performance in the
    model. They can improve the model performance to a large extent. Let us now focus
    on altering a few hyperparameters from the best model. **Learning rate** and **batch
    size** are some hyperparameters that can improve model performance. We will use
    these hyperparameters to improve performance. Since MobileNet was performing the
    best on the test data, we use this model and perform hyperparameter tuning to
    get the best achievable results.
  prefs: []
  type: TYPE_NORMAL
- en: '**Learning Rate**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/79bcedd71ed7dc2e03f212d48a6ff045.png)![](../Images/390af83bdc9f883445ae03132efc84a5.png)![](../Images/27d16b317d4575d8906aa538fe219262.png)![](../Images/a73b81a32d1341c75d41600774d0de2a.png)![](../Images/6a146bc328e92fb25425776acf693568.png)'
  prefs: []
  type: TYPE_IMG
- en: Model Performance, Model Architecture and Classification Report (Images by Author)
  prefs: []
  type: TYPE_NORMAL
- en: After conducting hyperparameter tuning and determining the optimal learning
    rate, our chosen model (MobileNet) demonstrated a notable **1%** improvement in
    performance on the test dataset. Notably, we retained the same architecture as
    before, while focusing on identifying the best learning rate to achieve optimal
    results.
  prefs: []
  type: TYPE_NORMAL
- en: While we won’t delve into the specifics of how we performed hyperparameter tuning,
    it’s worth noting that there’s another key hyperparameter we can explore in order
    to maximize performance on unseen data points. By taking into account this additional
    hyperparameter, we can ensure that our model is even more effective at accurately
    predicting outcomes beyond the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '**Batch Size**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/20d4aa951ce2d196651193673adce51e.png)![](../Images/390af83bdc9f883445ae03132efc84a5.png)![](../Images/27d16b317d4575d8906aa538fe219262.png)![](../Images/a73b81a32d1341c75d41600774d0de2a.png)![](../Images/ad27f184d44e16aab66b3b4d9b012a69.png)'
  prefs: []
  type: TYPE_IMG
- en: Model Performance, Model Architecture and Classification Report (Images by Author)
  prefs: []
  type: TYPE_NORMAL
- en: Following our successful hyperparameter tuning process, we utilized the optimal
    learning rate to determine the best batch size for our deep learning model. In
    this case, a batch size of **128** yielded the greatest performance gains, resulting
    in a notable **2%** improvement on the test dataset. This reinforces the importance
    of hyperparameter tuning, which can be a powerful tool in enhancing the **accuracy**
    and **reliability** of deep learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Looking ahead, our next step is to save the final, hyperparameter-tuned model
    and deploy it in real-time, using it in a camera module or web interface where
    users can upload images of solar panels. By leveraging the power of deep learning,
    our model can accurately identify whether panels are clean or dusty, providing
    valuable insights to users. This project underscores the potential of hyperparameter
    tuning to **boost** performance across a wide range of problems and applications.
  prefs: []
  type: TYPE_NORMAL
- en: Saving the Best Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we’ve put in the effort to develop, train, and test a range of sophisticated
    deep learning models, it’s time to save the best-performing model for future use.
    We do this by storing the model in a way that enables us to easily **retrieve**
    it later, allowing for **real-time** or **batch inferences** based on the specific
    needs of developers.
  prefs: []
  type: TYPE_NORMAL
- en: By saving the best model, we can ensure that our efforts to **optimize** model
    performance don’t go to waste, and that our hard work pays off in the form of
    accurate, reliable results. This represents an important step in the deep learning
    process and underscores the power of these techniques to drive improvements across
    a wide range of applications and domains.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By reading this article, you should now have a comprehensive understanding of
    the various stages involved in a machine learning project, including data collection,
    feature engineering, model training, model selection, hyperparameter tuning, and
    model deployment. Each of these steps is **critical** to the success of the project,
    and requires careful attention and consideration to achieve optimal results.
  prefs: []
  type: TYPE_NORMAL
- en: However, the work doesn’t stop once the model is deployed. It’s important to
    monitor its performance on an ongoing basis, particularly when dealing with real-time
    data. This allows you to identify potential issues such as model drift, data drift,
    or security concerns, and take steps to **address** them in a timely manner.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, this article provides a valuable overview of the deep learning process,
    highlighting the many **challenges** and **opportunities** involved in building
    accurate and reliable models for a wide range of applications. I hope you’ve found
    it informative and helpful, and I look forward to continuing to explore this exciting
    and rapidly evolving field in the future. Thank you for taking the time to read
    this article.
  prefs: []
  type: TYPE_NORMAL
- en: '*Here is the link to the GitHub repository for full working code of the project.*'
  prefs: []
  type: TYPE_NORMAL
- en: '***Link:*** [*https://tinyurl.com/ycyybf55*](https://tinyurl.com/ycyybf55)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Below are the ways where you could contact me or take a look at my work.*'
  prefs: []
  type: TYPE_NORMAL
- en: '***GitHub:***[*suhasmaddali (Suhas Maddali ) (github.com)*](https://github.com/suhasmaddali)'
  prefs: []
  type: TYPE_NORMAL
- en: '***YouTube:***[*https://www.youtube.com/channel/UCymdyoyJBC_i7QVfbrIs-4Q*](https://www.youtube.com/channel/UCymdyoyJBC_i7QVfbrIs-4Q)'
  prefs: []
  type: TYPE_NORMAL
- en: '***LinkedIn:***[*(1) Suhas Maddali, Northeastern University, Data Science |
    LinkedIn*](https://www.linkedin.com/in/suhas-maddali/)'
  prefs: []
  type: TYPE_NORMAL
- en: '***Medium:*** [*Suhas Maddali — Medium*](https://suhas-maddali007.medium.com/)'
  prefs: []
  type: TYPE_NORMAL
- en: '***Kaggle:***[*Suhas Maddali | Contributor | Kaggle*](https://www.kaggle.com/suhasmaddali007)'
  prefs: []
  type: TYPE_NORMAL
