- en: 'Something-of-Thoughts in LLM Prompting: An Overview of Structured LLM Reasoning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/something-of-thought-in-llm-prompting-an-overview-of-structured-llm-reasoning-70302752b390?source=collection_archive---------1-----------------------#2023-09-16](https://towardsdatascience.com/something-of-thought-in-llm-prompting-an-overview-of-structured-llm-reasoning-70302752b390?source=collection_archive---------1-----------------------#2023-09-16)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Chain-of-Thoughts (CoT), Tree-of-Thoughts (ToT), Graph-of-Thoughts (GoT), and
    beyond, … What are these thoughts?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://wangyz.medium.com/?source=post_page-----70302752b390--------------------------------)[![Yunzhe
    Wang](../Images/2e6f7fdae8cf731a616927bf7742d514.png)](https://wangyz.medium.com/?source=post_page-----70302752b390--------------------------------)[](https://towardsdatascience.com/?source=post_page-----70302752b390--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----70302752b390--------------------------------)
    [Yunzhe Wang](https://wangyz.medium.com/?source=post_page-----70302752b390--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F31c691ae725d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsomething-of-thought-in-llm-prompting-an-overview-of-structured-llm-reasoning-70302752b390&user=Yunzhe+Wang&userId=31c691ae725d&source=post_page-31c691ae725d----70302752b390---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----70302752b390--------------------------------)
    ·9 min read·Sep 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F70302752b390&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsomething-of-thought-in-llm-prompting-an-overview-of-structured-llm-reasoning-70302752b390&user=Yunzhe+Wang&userId=31c691ae725d&source=-----70302752b390---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F70302752b390&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsomething-of-thought-in-llm-prompting-an-overview-of-structured-llm-reasoning-70302752b390&source=-----70302752b390---------------------bookmark_footer-----------)![](../Images/ee9435141d0b3a2d40140e778b071961.png)'
  prefs: []
  type: TYPE_NORMAL
- en: “Tree of Thought”, generated by Midjourney
  prefs: []
  type: TYPE_NORMAL
- en: 'In the age of smartphones and smart homes, imagine an AI that doesn’t merely
    follow instructions, but actually thinks, grappling with complex logic just as
    we do. Sounds like science fiction, doesn’t it? However, if you’ve played around
    with ChatGPT, you’ve likely witnessed this astonishing capability firsthand. Even
    Hector Levesque, a renowned figure in AI reasoning, was so astounded that he once
    commented to AI legend Geoffrey Hinton: [*“How can such a stupid method (referring
    to neural networks) can deal with reasoning?”*](https://www.youtube.com/watch?v=rGgGOccMEiY&t=1598s)'
  prefs: []
  type: TYPE_NORMAL
- en: While this story underscores the monumental advances in AI, the true essence
    of these advancements is found in the intricate dance of Large Language Models
    (LLMs) with reasoning. The entry point to this dance is Prompt Engineering — the
    art and science of optimizing the textual input provided to LLMs to elicit desired
    outputs. At its core, it’s about understanding the intricacies of how language
    models like ChatGPT, Bard, Claude, LLama, and others respond to different prompts,
    and then leveraging this knowledge to achieve specific results.
  prefs: []
  type: TYPE_NORMAL
- en: Think of LLMs as vast knowledge reservoirs. The way you phrase your question
    or statement (the prompt) determines how you tap into that reservoir. Just as
    humans might offer different answers based on how a question is posed, LLMs too
    can give varied responses based on the input.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this article, you’ll receive a concise overview of various prompt engineering
    frameworks designed to enhance LLM reasoning, including:'
  prefs: []
  type: TYPE_NORMAL
- en: Chain-of-Thought
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chain-of-Thought-Self-Consistency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tree-of-Thoughts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Graph-of-Thoughts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Algorithm-of-Thoughts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Skeleton-of-Thought
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Program-of-Thoughts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chain-of-Thought (CoT)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Instead of directly outputting an answer, provide the language model with intermediate
    reasoning examples to guide its response.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Chain-of-Thought (CoT)](https://arxiv.org/abs/2201.11903) prompting has been
    recognized as one of the pioneering and most impactful prompt engineering techniques,
    enhancing the decision-making processes in large language models. Distinct from
    conventional prompting methodologies that emphasize direct input-output interactions,
    CoT compels a model to segment its reasoning into intermediary steps. This method
    draws parallels to human cognitive processes wherein intricate challenges are
    segmented into smaller, more manageable components.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate, consider a mathematical problem: “Roger possesses 5 tennis balls
    and subsequently purchases 2 cans of tennis balls, with each can containing 3
    balls. How many tennis balls does he possess now?”. Rather than directly deducing
    the answer as 11, an individual might rationalize: “Initially, Roger has 5 balls.
    The combined total of 2 cans, each containing 3 balls, amounts to 6 balls. Summing
    the values, 5 + 6, yields 11.” Integrating such step-by-step analytical reasoning
    into the input prompt not only augments the accuracy of the model’s response but
    also accomplishes this without necessitating additional training datasets or alterations
    to the fundamental model configuration.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7ba1090dc166a973d850c78f042dc18b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Chain-of-Thought Prompting, source: [Wei et al. (2022)](https://arxiv.org/abs/2201.11903)'
  prefs: []
  type: TYPE_NORMAL
- en: Chain-of-Thought-Self-Consistency (CoT-SC)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Construct multiple chains of thought, evaluate each one, and ultimately select
    the most effective and coherent chain.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A subsequent advancement from the Chain of Thought framework is [CoT-Self-consistency](https://arxiv.org/abs/2203.11171).
    This method instigates multiple concurrent reasoning pathways in response to a
    query and applies weighting mechanisms prior to finalizing an answer. This approach
    resembles ensemble techniques observed in traditional machine learning but is
    applied to thought sequences in large language models.
  prefs: []
  type: TYPE_NORMAL
- en: Tree-of-Thoughts (ToT)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Expand on the chains of thought in a tree format. This allows for backtracking,
    exploring multiple branches of reasoning stemming from a single root idea.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Tree-of-Thoughts (ToT)](https://arxiv.org/abs/2305.10601) offers a more structured
    prompting framework for LLM reasoning by breaking down complex problems into more
    manageable parts. Unlike the CoT which reasons in a linked chain, ToT organizes
    its problem-solving strategy in a tree format. Each node, referred to as a ‘thought,’
    is a coherent language sequence serving as a step towards the final answer. By
    dividing problems into these discrete ‘thought’ units — from a brief series of
    words in a crossword puzzle to a component of a mathematical equation — ToT ensures
    that each phase of the problem is systematically addressed.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/180d5a85d8fc814621426807b4fb77c1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'ToT reasoning in the game of 24, source: [Yao et al. (2023)](https://arxiv.org/abs/2305.10601)'
  prefs: []
  type: TYPE_NORMAL
- en: The operational strength of ToT lies in its methodical organization. First,
    the system breaks down a problem and, from its current state, generates a list
    of potential reasoning steps or ‘thought’ candidates. These thoughts are then
    evaluated, with the system gauging the likelihood that each one will lead to the
    desired solution. Standard search algorithms, such as Breadth-first search (BFS)
    and Depth-first search (DFS), are used to navigate this tree, aiding the model
    in identifying the most effective sequence of thoughts.
  prefs: []
  type: TYPE_NORMAL
- en: ToT’s importance stems from its holistic design, adaptability, and efficiency.
    The Chain-of-Thought prompting can be viewed as a specific instance within the
    ToT framework. Its modular nature indicates that individual components, from the
    initial breakdown of a problem to the search algorithms employed, can operate
    independently.
  prefs: []
  type: TYPE_NORMAL
- en: Graph-of-Thoughts (GoT)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Evolve the tree structure into Direct Acyclic Graphs. This introduces self-loops
    which can either solidify a particular line of thought or aggregate multiple thoughts
    into a cohesive one.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The [Graph-of-Thoughts (GoT)](https://arxiv.org/abs/2308.09687) framework represents
    an advanced progression from CoT and ToT methodologies. Central to the GoT framework
    is the conceptualization of ideas as vertices in a Directed Acyclic Graph (DAG).
    In this context, each vertex corresponds to a specific thought or solution — be
    it preliminary, intermediary, or terminal — elicited by an input stimulus. The
    directed edges within this graph depict the interdependency among these thoughts.
    Specifically, if an edge extends from thought t1​ to t2​, it signifies that t2​
    was conceived based on t1​. This systematization permits a multiplicity of thoughts
    since nodes may be classified into distinct categories such as “plans” or “outcomes”.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f832191be1dfbcabf2682a84c8859370.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Graph-of-Thoughts, source: [Besta et al. (2023)](https://arxiv.org/abs/2308.09687)'
  prefs: []
  type: TYPE_NORMAL
- en: GoT’s novelty lies in its ability to apply transformations to these thoughts,
    further refining the reasoning process. The cardinal transformations encompass
    Aggregation, which allows for the fusion of several thoughts into a consolidated
    idea; Refinement, where continual iterations are performed on a singular thought
    to improve its precision; and Generation, which facilitates the conception of
    novel thoughts stemming from extant ones. Such transformations, with an emphasis
    on the amalgamation of reasoning routes, deliver a more intricate viewpoint relative
    to preceding models like CoT or ToT.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, GoT introduces an evaluative dimension through Scoring and Ranking.
    Each individual thought, represented by a vertex, undergoes an assessment based
    on its pertinence and quality, facilitated by a designated scoring function. Importantly,
    this function contemplates the entire chain of reasoning, assigning scores that
    might be contextualized vis-a-vis other vertices in the graph. The framework also
    equips the system with the competence to hierarchize these thoughts predicated
    on their respective scores, a feature that proves instrumental when discerning
    which ideas warrant precedence or implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm-of-Thoughts (AoT)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Maintains a single evolving context chain, eliminating the need for redundant
    queries as in the Tree-of-Thought. It explores a mutable path of reasoning.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: While ToT and GoT address the LLM reasoning challenge through search-based mechanisms,
    producing a myriad of reasoning paths in graph forms. However, their heavy reliance
    on numerous LLM queries, sometimes numbering in the hundreds for a singular problem,
    poses computational inefficiencies.
  prefs: []
  type: TYPE_NORMAL
- en: The [Algorithm-of-Thoughts (AoT)](https://arxiv.org/abs/2308.10379) offers an
    innovative method that features a dynamic and mutable reasoning path. By maintaining
    a single evolving thought context chain, AoT consolidates thought exploration,
    enhancing efficiency and reducing computational overhead.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/36b10dfbbf7392043cdf07558effb4d0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Algorithm-of-Thoughts. Each box signifies a distinct thought. Greens are promising
    thoughts while reds are less promising ones. Note: ToT has multiple queries while
    AoT keeps a single context, source: [Sel et al. (2023)](https://arxiv.org/abs/2308.10379)'
  prefs: []
  type: TYPE_NORMAL
- en: The ingenuity behind AoT springs from the observation that LLMs, although powerful,
    occasionally revert to prior solutions when faced with new yet familiar problems.
    To overcome this, AoT assimilates in-context examples, drawing from time-tested
    search algorithms such as depth-first search (DFS) and breadth-first search (BFS).
    By emulating algorithmic behavior, AoT underscores the importance of achieving
    successful outcomes and gleaning insights from unsuccessful attempts.
  prefs: []
  type: TYPE_NORMAL
- en: 'The cornerstone of AoT lies in its four main components: 1) Decomposing complex
    problems into digestible subproblems, considering both their interrelation and
    the ease with which they can be individually addressed; 2) Proposing coherent
    solutions for these subproblems in a continuous and uninterrupted manner; 3) Intuitively
    evaluating the viability of each solution or subproblem without relying on explicit
    external prompts; and 4) Determining the most promising paths to explore or backtrack
    to, based on in-context examples and algorithmic guidelines.'
  prefs: []
  type: TYPE_NORMAL
- en: Skeleton-of-Thought (SoT)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generate an answer blueprint first before parallelly fleshing out the details,
    reducing the time taken to generate a complete response.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The [Skeleton-of-Thought (SoT)](https://arxiv.org/abs/2307.15337) paradigm is
    distinctively designed not primarily to augment the reasoning capabilities of
    Large Language Models (LLMs), but to address the pivotal challenge of minimizing
    end-to-end generation latency. The methodology operates based on a dual-stage
    approach that focuses on producing a preliminary blueprint of the answer, followed
    by its comprehensive expansion.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dd7fb01b086fb80b4f666696ac0dd5d9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Skeleton-of-Thought, source: [Ning et al. (2023)](https://arxiv.org/abs/2307.15337)'
  prefs: []
  type: TYPE_NORMAL
- en: In the initial “Skeleton Stage,” rather than producing a comprehensive response,
    the model is prompted to generate a concise answer skeleton. This abbreviated
    representation prompted through a meticulously crafted skeleton template, captures
    the core elements of the prospective answer, thus establishing a foundation for
    the subsequent stage.
  prefs: []
  type: TYPE_NORMAL
- en: In the ensuing “Point-Expanding Stage,” the LLM systematically amplifies each
    component delineated in the answer skeleton. Leveraging a point-expanding prompt
    template, the model concurrently elaborates on each segment of the skeleton. This
    dichotomous approach, which separates the generative process into preliminary
    skeletal formulation and parallelized detailed expansion, not only accelerates
    response generation but also strives to uphold the coherence and precision of
    the outputs.
  prefs: []
  type: TYPE_NORMAL
- en: Program-of-Thoughts (PoT)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Formulate the reasoning behind question answering into an executable program,
    incorporated the program intepretor output as part of the final answer.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Program-of-Thoughts (PoT)](https://arxiv.org/abs/2211.12588) is a unique approach
    to LLM reasoning, instead of merely generating an answer in natural language,
    PoT mandates the creation of an executable program, which means it can be run
    on a program interpreter, like Python, to produce tangible outcomes. This method
    stands in contrast to more direct models, emphasizing its ability to break down
    reasoning into sequential steps and associate semantic meanings with variables.
    As a result, PoT offers a clearer, more expressive, and grounded model of how
    answers are derived, enhancing accuracy and understanding, especially for math-type
    logical questions where numerical calculations are needed.'
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note that the program execution of PoT is not necessarily
    targeting the final answer but can be part of the intermediate step to the final
    answer.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9aa904330a995f6724768bd6b6088c44.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Comparison between CoT and PoT, source: [Chen et al. (2022)](https://arxiv.org/abs/2211.12588)'
  prefs: []
  type: TYPE_NORMAL
- en: In the ever-evolving realm of AI, structured reasoning frameworks like Chain-of-Thought
    have dramatically transformed how we perceive and harness the power of Large Language
    Models. They symbolize a shift towards models that not only regurgitate information
    but also engage in intricate reasoning, much akin to human cognitive processes.
    As we look ahead, the potential horizons seem limitless. Imagine an AI, adept
    at generating not only accurate answers but also robust, programmable solutions
    or having the ability to visualize its thought processes, making AI-human collaboration
    even more seamless. Such advancements, building upon the foundational frameworks
    explored in this article, herald a future where LLMs become indispensable companions
    in problem-solving, creativity, and decision-making, catalyzing a paradigm shift
    in our symbiotic relationship with technology.
  prefs: []
  type: TYPE_NORMAL
