- en: PyTorch Model Performance Analysis and Optimization — Part 3
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch模型性能分析与优化 — 第3部分
- en: 原文：[https://towardsdatascience.com/pytorch-model-performance-analysis-and-optimization-part-3-1c5876d78fe2?source=collection_archive---------4-----------------------#2023-08-10](https://towardsdatascience.com/pytorch-model-performance-analysis-and-optimization-part-3-1c5876d78fe2?source=collection_archive---------4-----------------------#2023-08-10)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/pytorch-model-performance-analysis-and-optimization-part-3-1c5876d78fe2?source=collection_archive---------4-----------------------#2023-08-10](https://towardsdatascience.com/pytorch-model-performance-analysis-and-optimization-part-3-1c5876d78fe2?source=collection_archive---------4-----------------------#2023-08-10)
- en: How to reduce “Cuda Memcpy Async” events and why you should beware of boolean
    mask operations
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何减少“Cuda Memcpy Async”事件以及为什么你需要警惕布尔掩码操作
- en: '[](https://chaimrand.medium.com/?source=post_page-----1c5876d78fe2--------------------------------)[![Chaim
    Rand](../Images/c52659c389f167ad5d6dc139940e7955.png)](https://chaimrand.medium.com/?source=post_page-----1c5876d78fe2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1c5876d78fe2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1c5876d78fe2--------------------------------)
    [Chaim Rand](https://chaimrand.medium.com/?source=post_page-----1c5876d78fe2--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://chaimrand.medium.com/?source=post_page-----1c5876d78fe2--------------------------------)[![Chaim
    Rand](../Images/c52659c389f167ad5d6dc139940e7955.png)](https://chaimrand.medium.com/?source=post_page-----1c5876d78fe2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1c5876d78fe2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1c5876d78fe2--------------------------------)
    [Chaim Rand](https://chaimrand.medium.com/?source=post_page-----1c5876d78fe2--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9440b37e27fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpytorch-model-performance-analysis-and-optimization-part-3-1c5876d78fe2&user=Chaim+Rand&userId=9440b37e27fe&source=post_page-9440b37e27fe----1c5876d78fe2---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1c5876d78fe2--------------------------------)
    ·11 min read·Aug 10, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1c5876d78fe2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpytorch-model-performance-analysis-and-optimization-part-3-1c5876d78fe2&user=Chaim+Rand&userId=9440b37e27fe&source=-----1c5876d78fe2---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9440b37e27fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpytorch-model-performance-analysis-and-optimization-part-3-1c5876d78fe2&user=Chaim+Rand&userId=9440b37e27fe&source=post_page-9440b37e27fe----1c5876d78fe2---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1c5876d78fe2--------------------------------)
    ·11分钟阅读·2023年8月10日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1c5876d78fe2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpytorch-model-performance-analysis-and-optimization-part-3-1c5876d78fe2&user=Chaim+Rand&userId=9440b37e27fe&source=-----1c5876d78fe2---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1c5876d78fe2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpytorch-model-performance-analysis-and-optimization-part-3-1c5876d78fe2&source=-----1c5876d78fe2---------------------bookmark_footer-----------)![](../Images/f0e37ec189e53254268fdae595fb5d6e.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1c5876d78fe2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpytorch-model-performance-analysis-and-optimization-part-3-1c5876d78fe2&source=-----1c5876d78fe2---------------------bookmark_footer-----------)![](../Images/f0e37ec189e53254268fdae595fb5d6e.png)'
- en: Photo by [Braden Jarvis](https://unsplash.com/@jarvisphoto?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Braden Jarvis](https://unsplash.com/@jarvisphoto?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: This is the third part of a series of posts on the topic of analyzing and optimizing
    PyTorch models using [PyTorch Profiler](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html)
    and [TensorBoard](https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html).
    Our intention has been to highlight the **benefits of performance profiling and
    optimization** of GPU-based training workloads and their potential impact on the
    speed and cost of training. In particular, we wish to demonstrate the accessibility
    of profiling tools such as [PyTorch Profiler](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html)
    and [TensorBoard](https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html)
    to all ML developers. **You do not need to be a CUDA expert in order to derive
    meaningful performance gains** from applying the techniques we discuss in our
    posts.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这是关于使用 [PyTorch Profiler](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html)
    和 [TensorBoard](https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html)
    分析和优化 PyTorch 模型的系列文章的第三部分。我们的意图是突出**性能分析和优化**在 GPU 训练负载中的好处及其对训练速度和成本的潜在影响。特别是，我们希望展示诸如
    [PyTorch Profiler](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html)
    和 [TensorBoard](https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html)
    等分析工具对所有 ML 开发者的可及性。**你不需要成为 CUDA 专家即可从我们讨论的技术中获得有意义的性能提升**。
- en: In our [first post](https://medium.com/@chaimrand/pytorch-model-performance-analysis-and-optimization-10c3c5822869)
    we demonstrated how the different *views* of the [PyTorch Profiler TensorBoard
    plugin](https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html)
    can be used to identify performance issues and reviewed a few popular techniques
    for accelerating training. In the [second post](/pytorch-model-performance-analysis-and-optimization-part-2-3bc241be91)
    we showed how the [TensorBoard plugin](https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html)
    *Trace View* can be used to identify when tensors are being copied from the CPU
    to the GPU, and back. Such movement of data — which can cause points of synchronization
    and slow the speed of training considerably — is often unintentional and can sometimes
    be easily avoided. The topic of this post will be situations in which we encounter
    points of synchronization between the GPU and CPU that are **not** associated
    with tensor copies. As in the case of tensor copies, these can cause stagnation
    in your training step and slow the overall time of your training considerably.
    We will demonstrate the existence of such occurrences, how they can be identified
    using [PyTorch Profiler](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html)
    and the [PyTorch Profiler TensorBoard plugin](https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html)
    *Trace View*, and the potential performance benefits of building your model in
    a way that minimizes such synchronization events.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的 [第一篇文章](https://medium.com/@chaimrand/pytorch-model-performance-analysis-and-optimization-10c3c5822869)
    中，我们演示了 [PyTorch Profiler TensorBoard 插件](https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html)
    的不同*视图*如何用于识别性能问题，并回顾了几种加速训练的流行技术。在 [第二篇文章](/pytorch-model-performance-analysis-and-optimization-part-2-3bc241be91)
    中，我们展示了 [TensorBoard 插件](https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html)
    *Trace View* 如何用于识别张量从 CPU 到 GPU 的拷贝以及反向拷贝的情况。这种数据移动——可能会导致同步点并显著降低训练速度——通常是无意的，有时可以很容易地避免。本篇文章的主题是我们遇到的
    GPU 和 CPU 之间的同步点，这些同步点**不**与张量拷贝有关。与张量拷贝的情况一样，这些同步点可能会导致训练步骤的停滞，显著减慢整体训练时间。我们将展示此类情况的存在、如何使用
    [PyTorch Profiler](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html)
    和 [PyTorch Profiler TensorBoard 插件](https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html)
    *Trace View* 进行识别，以及以最小化此类同步事件的方式构建模型的潜在性能收益。
- en: As in our previous posts, we will define a toy PyTorch model and then *iteratively*
    profile its performance, identify bottlenecks, and attempt to fix them. We will
    run our experiments on an [Amazon EC2 g5.2xlarge](https://aws.amazon.com/ec2/instance-types/g5/)
    instance (containing an NVIDIA A10G GPU and 8 vCPUs) and using the official [AWS
    PyTorch 2.0 Docker image](https://github.com/aws/deep-learning-containers). Keep
    in mind that some of the behaviors we describe may vary between versions of PyTorch.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们之前的帖子一样，我们将定义一个玩具 PyTorch 模型，然后 *迭代地* 分析其性能，识别瓶颈，并尝试修复它们。我们将在一个 [Amazon
    EC2 g5.2xlarge](https://aws.amazon.com/ec2/instance-types/g5/) 实例上运行实验（该实例包含一个
    NVIDIA A10G GPU 和 8 个 vCPU），并使用官方的 [AWS PyTorch 2.0 Docker 镜像](https://github.com/aws/deep-learning-containers)。请记住，我们描述的某些行为可能因
    PyTorch 版本而异。
- en: Toy Example
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例
- en: In the following blocks we introduce a toy PyTorch model that performs semantic
    segmentation on a 256x256 input image, i.e., it takes a 256x256 RGB image and
    outputs a 256x256 map of “per-pixel” labels from a class of ten semantic categories.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的块中，我们引入一个玩具 PyTorch 模型，它对 256x256 的输入图像进行语义分割，即，它接收一个 256x256 的 RGB 图像，并输出一个来自十个语义类别的“每像素”标签的
    256x256 图。
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To train our model we will use the standard [cross-entropy loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)
    with a few modifications:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练我们的模型，我们将使用标准的 [交叉熵损失](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)
    并做一些修改：
- en: We will assume that the target labels include an *ignore* value indicating pixels
    that we want to exclude from the loss calculation.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们假设目标标签包含一个 *ignore* 值，用于表示我们想从损失计算中排除的像素。
- en: We will assume that one of the semantic labels identifies certain pixels as
    belonging to the “background” of the image. We define our loss function to treat
    these as *ignore* labels.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们假设其中一个语义标签将某些像素标识为图像的“背景”。我们将定义我们的损失函数将这些视为 *ignore* 标签。
- en: We will update our model weights only when we encounter batches with targets
    tensors that include at least two unique values.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只会在遇到包含至少两个唯一值的目标张量的批次时更新模型权重。
- en: While we have chosen these modifications for the purposes of our demonstration,
    these types of operations are not uncommon and can be found in many “standard”
    PyTorch models. Since we are already “experts” at performance profiling, we have
    already gone ahead and wrapped each of the operations in our loss function with
    a [torch.profiler.record_function](https://pytorch.org/tutorials/beginner/profiler.html#performance-debugging-using-profiler)
    context manager, (as described in our [second post](/pytorch-model-performance-analysis-and-optimization-part-2-3bc241be91)).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们为演示目的选择了这些修改，但这类操作并不罕见，可以在许多“标准” PyTorch 模型中找到。由于我们已经是性能分析的“专家”，我们已经提前将损失函数中的每个操作都用
    [torch.profiler.record_function](https://pytorch.org/tutorials/beginner/profiler.html#performance-debugging-using-profiler)
    上下文管理器进行了封装，（如我们 [第二篇帖子](/pytorch-model-performance-analysis-and-optimization-part-2-3bc241be91)
    中所述）。
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Our loss function seems innocent enough, right? Wrong! As we will see below,
    the loss function includes a number of operations that trigger host-device synchronization
    events that slow the speed of training considerably — none of which involve copying
    tensors into or out of the GPU. As in our previous post, we challenge you to try
    to identify three opportunities for performance optimization before reading on.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的损失函数看起来很无害，对吧？错！正如我们下面将看到的，损失函数包含了许多触发主机-设备同步事件的操作，这些操作会显著降低训练速度——这些操作不涉及将张量复制进出
    GPU。就像我们之前的帖子一样，我们挑战你在继续阅读之前尝试识别出三个性能优化的机会。
- en: For the purposes of our demo, we use randomly generated images and per-pixel
    label maps, as defined below.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 出于演示目的，我们使用随机生成的图像和每像素标签图，如下所定义。
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Last, we define our training step with the [PyTorch Profiler](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html)
    configured to our desire:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用 [PyTorch Profiler](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html)
    配置到我们的需求来定义训练步骤：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If you were to naively run this training script, you would probably see high
    GPU (~90%) utilization and not know that there was anything wrong with it. It
    is only through profiling that we are able to identify the underlying performance
    bottlenecks and potential opportunities for training acceleration. So, without
    further ado, let’s see how our model performs.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你直接运行这个训练脚本，你可能会看到高达 ~90% 的 GPU 使用率，却不知道其中存在任何问题。只有通过性能分析，我们才能识别出潜在的性能瓶颈和训练加速的机会。那么，话不多说，让我们看看模型的表现吧。
- en: Initial Performance Results
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 初步性能结果
- en: In this post we will focus on the *Trace View* of the [PyTorch Profiler TensorBoard
    plugin](https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html).
    Please see our [previous posts](/pytorch-model-performance-analysis-and-optimization-10c3c5822869)
    for tips on how to use some of the other *views* supported by the plugin.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将重点关注 [PyTorch Profiler TensorBoard 插件](https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html)
    的 *跟踪视图*。请参见我们的 [先前文章](/pytorch-model-performance-analysis-and-optimization-10c3c5822869)
    获取有关如何使用插件支持的其他 *视图* 的提示。
- en: In the image below we show the *Trace View* of a single training step of our
    toy model.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，我们展示了玩具模型单次训练步骤的 *跟踪视图*。
- en: '![](../Images/e9f0678cc9de59ec988d0c458fd7e050.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e9f0678cc9de59ec988d0c458fd7e050.png)'
- en: Trace View of Baseline Model (Captured by Author)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 基线模型的跟踪视图（作者捕获）
- en: We can clearly see that our 1.3 second long training step is *completely* dominated
    by the [torch.nonzero](https://pytorch.org/docs/stable/generated/torch.nonzero.html)
    operator in the first line of our loss function. All the other operations appear
    bunched together on either side of the huge *cudaMemcpyAsyn* event. What is going
    on??!! Why would such a seemingly innocent operation cause such a huge eyesore?
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以清楚地看到，我们 1.3 秒的训练步骤被 [torch.nonzero](https://pytorch.org/docs/stable/generated/torch.nonzero.html)
    操作在损失函数的第一行中 *完全* 主导了。所有其他操作似乎都集中在巨大 *cudaMemcpyAsync* 事件的两侧。发生了什么？？!! 为什么这么一个看似无害的操作会造成如此大的困扰？
- en: 'Perhaps we should not be so surprised, as the [torch.nonzero](https://pytorch.org/docs/stable/generated/torch.nonzero.html)
    documentation *does* include the following note: “When `input` is on CUDA, `[torch.nonzero()](https://pytorch.org/docs/stable/generated/torch.nonzero.html#torch.nonzero)`
    causes host-device synchronization.” The need for synchronization arises from
    the fact that, contrary to other common PyTorch ops, the size of the tensor that
    is returned by [torch.nonzero](https://pytorch.org/docs/stable/generated/torch.nonzero.html)
    is *not* pre-determined. The CPU does not know how many non-zero elements there
    are in the input tensor ahead of time. It needs to wait for the sync event from
    the GPU in order to perform the appropriate GPU memory allocation and appropriately
    prepare the subsequent PyTorch ops.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们或许不应感到如此惊讶，因为 [torch.nonzero](https://pytorch.org/docs/stable/generated/torch.nonzero.html)
    的文档确实包含了以下说明：“当 `input` 在 CUDA 上时，`[torch.nonzero()](https://pytorch.org/docs/stable/generated/torch.nonzero.html#torch.nonzero)`
    会导致主机与设备的同步。” 需要同步的原因在于，与其他常见的 PyTorch 操作不同，[torch.nonzero](https://pytorch.org/docs/stable/generated/torch.nonzero.html)
    返回的张量大小是 *未* 预先确定的。CPU 事先不知道输入张量中有多少个非零元素。它需要等待来自 GPU 的同步事件，以便执行适当的 GPU 内存分配并正确准备后续的
    PyTorch 操作。
- en: Note that the length of *cudaMempyAsync* is not indicative of the complexity
    of the [torch.nonzero](https://pytorch.org/docs/stable/generated/torch.nonzero.html)
    op, but rather reflects the amount of time that the CPU needs to wait for the
    GPU to finish all of the previous kernels that the CPU launched. For example,
    were we to make an additional [torch.nonzero](https://pytorch.org/docs/stable/generated/torch.nonzero.html)
    call immediately after our first one, our second *cudaMempyAsync* event would
    appear significantly shorter than the first since the CPU and GPU are already
    more or less “in sync”. (Keep in mind that this explanation is coming from a non-CUDA
    expert, so make of it what you will…)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，*cudaMempyAsync* 的长度并不能体现 [torch.nonzero](https://pytorch.org/docs/stable/generated/torch.nonzero.html)
    操作的复杂性，而是反映了 CPU 需要等待 GPU 完成所有之前由 CPU 启动的内核的时间。例如，如果我们在第一次调用后立即进行额外的 [torch.nonzero](https://pytorch.org/docs/stable/generated/torch.nonzero.html)
    调用，我们第二次的 *cudaMempyAsync* 事件会显著比第一次短，因为 CPU 和 GPU 已经或多或少“同步”了。（请记住，这个解释来自非 CUDA
    专家，所以请自行斟酌……）
- en: 'Optimization #1: Reduce the use of the [torch.nonzero](https://pytorch.org/docs/stable/generated/torch.nonzero.html)
    op'
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '优化 #1: 减少对 [torch.nonzero](https://pytorch.org/docs/stable/generated/torch.nonzero.html)
    操作的使用'
- en: 'Now that we understand the source of the bottleneck, the challenge becomes
    finding an alternative sequence of operations that performs the same logic but
    that does *not* trigger a host-device synchronization event. In the case of our
    loss function, we can easily accomplish this using the [torch.where](https://pytorch.org/docs/stable/generated/torch.where.html)
    operator as shown in the code block below:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们理解了瓶颈的来源，挑战在于找到一个执行相同逻辑但*不*触发主机-设备同步事件的替代操作序列。在我们的损失函数的情况下，我们可以使用[torch.where](https://pytorch.org/docs/stable/generated/torch.where.html)操作符，如下代码块所示：
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In the image below we show the *Trace View* following this change.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，我们展示了*Trace View*的变化。
- en: '![](../Images/6dbd9a5565a840bc4c1f2fdb38130aca.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6dbd9a5565a840bc4c1f2fdb38130aca.png)'
- en: 'Trace View Following Optimization #1 (Captured by Author)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '优化 #1 后的 Trace View（作者拍摄）'
- en: While we have succeeded in removing the *cudaMempyAsync* coming from the [torch.nonzero](https://pytorch.org/docs/stable/generated/torch.nonzero.html)
    op, it has been immediately replaced with one coming from the [torch.unique](https://pytorch.org/docs/stable/generated/torch.unique.html)
    op, and our step time has not budged. Here the PyTorch documentation is less kind,
    but based on our previous experience we can assume that, once again, we are suffering
    from a host-device synchronization event due to our use of tensors with undetermined
    size.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们成功去除了来自[torch.nonzero](https://pytorch.org/docs/stable/generated/torch.nonzero.html)操作符的*cudaMempyAsync*，但它立即被来自[torch.unique](https://pytorch.org/docs/stable/generated/torch.unique.html)操作符的*cudaMempyAsync*所替代，我们的步骤时间没有变化。这里PyTorch文档并不友好，但根据我们之前的经验，我们可以假设，我们再次因为使用未确定大小的张量而遭遇了主机-设备同步事件。
- en: 'Optimization #2: Reduce the use of the [torch.unique](https://pytorch.org/docs/stable/generated/torch.unique.html)
    op'
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '优化 #2：减少使用[torch.unique](https://pytorch.org/docs/stable/generated/torch.unique.html)操作符'
- en: Replacing the [torch.unique](https://pytorch.org/docs/stable/generated/torch.unique.html)
    operator with an equivalent alternative is not always possible. However, in our
    case we don’t actually need to know the values of the unique labels, we need to
    know only the *number* of unique labels. This can be calculated by applying the
    [torch.sort](https://pytorch.org/docs/stable/generated/torch.sort.html) op on
    the flattened *target* tensor and counting the number of steps in the resultant
    step function.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 替换[torch.unique](https://pytorch.org/docs/stable/generated/torch.unique.html)操作符为等效的替代方案并非总是可能的。然而，在我们的情况中，我们实际上不需要知道唯一标签的值，只需要知道唯一标签的*数量*。这可以通过在展平的*target*张量上应用[torch.sort](https://pytorch.org/docs/stable/generated/torch.sort.html)操作并计算结果步函数中的步骤数量来完成。
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In the image below we capture the *Trace View* following our second optimization:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，我们捕捉了第二次优化后的*Trace View*：
- en: '![](../Images/ca57df982059830ca04dc4ddae4df288.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ca57df982059830ca04dc4ddae4df288.png)'
- en: 'Trace View Following Optimization #2 (Captured by Author)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '优化 #2 后的 Trace View（作者拍摄）'
- en: Once again, we have solved one bottleneck only to be faced with a new one, this
    time coming from the boolean mask routine.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次解决了一个瓶颈，却面临新的问题，这次来自布尔掩码例程。
- en: Boolean masking is a routine we commonly use in order to reduce the overall
    number of machine operations that are required. In our case, our intention was
    to reduce the amount of computation by removing the “ignore” pixels and limiting
    the cross-entropy calculation to the pixels of interest. Clearly, this has backfired.
    As before, applying a boolean mask results in a tensor of undetermined size, and
    the *cudaMempyAsync* that it triggers greatly overshadows any of the savings from
    excluding the “ignore” pixels.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 布尔掩码是我们常用的例程之一，用于减少所需的总体机器操作数。在我们的情况下，我们的目的是通过去除“忽略”像素来减少计算量，将交叉熵计算限制在感兴趣的像素上。显然，这适得其反。与之前一样，应用布尔掩码会导致一个未确定大小的张量，而触发的*cudaMempyAsync*大大超过了排除“忽略”像素所节省的任何开销。
- en: 'Optimization #3: Beware of boolean mask operations'
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '优化 #3：注意布尔掩码操作'
- en: In our case, fixing this issue is rather simple as the [PyTorch CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)
    has a built-in option for setting an *ignore_index*.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，解决这个问题相当简单，因为[PyTorch CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)内置了设置*ignore_index*的选项。
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In the image below we show the resultant *Trace View*:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，我们展示了结果的*Trace View*：
- en: '![](../Images/0b0585885e68560323544aec83256de0.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0b0585885e68560323544aec83256de0.png)'
- en: Final Trace View (Captured by Author)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最终 Trace View（作者拍摄）
- en: Holy cow!! Our step time has dropped all the way down to 5.4 milliseconds. What
    happened?!! By simply changing around a few function calls and without any modification
    to the loss function logic, we were able to remove the synchronization points
    from the training step. Importantly, the average step time when calculated over
    a few hundred steps is actually ~**330 milliseconds, roughly four times faster
    than what we started with**. This is quite a bit higher than the 5.4 milliseconds
    reported above. The discrepancy stems from the fact that PyTorch Profiler measures
    the time of the CPU activity (e.g., kernel loading) per training step which is
    not necessarily aligned with the GPU activity. Although the synchronization events
    discussed above introduced unnecessary overhead, they had a positive side-effect
    of increasing the alignment between the CPU and GPU activities and increasing
    the accuracy of our time measurements. In their absence, it is not uncommon to
    see the step time measured by the profiler fluctuate wildly. In such cases it
    is recommended to average the step time over a large number of steps. See [here](https://pytorch.org/docs/stable/notes/cuda.html#asynchronous-execution)
    for more on the impact of [asynchronous execution](https://pytorch.org/docs/stable/notes/cuda.html#asynchronous-execution)
    on the accuracy of time measurement.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 天哪！！我们的步骤时间已经降到了5.4毫秒。发生了什么？！！通过简单地调整几个函数调用，而无需修改损失函数逻辑，我们能够从训练步骤中移除同步点。重要的是，当计算几百个步骤的平均时间时，实际上为~**330毫秒，大约是我们开始时的四倍快**。这比上面报告的5.4毫秒要高得多。这个差异源于PyTorch
    Profiler测量的是每个训练步骤的CPU活动时间（例如，内核加载），这不一定与GPU活动对齐。虽然上述同步事件引入了不必要的开销，但它们有一个积极的副作用，即提高了CPU和GPU活动之间的对齐，并提高了时间测量的准确性。在它们不存在的情况下，通过分析器测量的步骤时间出现大幅波动并不罕见。在这种情况下，建议对大量步骤的步骤时间进行平均。有关[异步执行](https://pytorch.org/docs/stable/notes/cuda.html#asynchronous-execution)对时间测量准确性影响的更多信息，请参见[这里](https://pytorch.org/docs/stable/notes/cuda.html#asynchronous-execution)。
- en: '**Important Note**: In the toy example we have chosen, the steps that we took
    to reduce the number *cudaMempyAsync* events had a clear impact on the training
    step time. However, there may be situations where the same types of changes will
    harm performance rather than improve it. For example, in the case of boolean masking,
    if our mask is extremely sparse and the original tensors extremely large, the
    savings in computation from applying the mask might outweigh the price of the
    host-device synchronization. Importantly, the impact of each optimization should
    be evaluated on a case-by-case basis.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**重要说明**：在我们选择的示例中，我们采取的步骤减少了*cudaMempyAsync*事件的数量，对训练步骤时间产生了明显的影响。然而，也可能存在一些情况，相同类型的改变可能会损害性能而不是提升它。例如，在布尔掩码的情况下，如果我们的掩码极其稀疏且原始张量非常大，应用掩码所节省的计算可能会超过主机与设备同步的成本。重要的是，每种优化的影响应根据具体情况进行评估。'
- en: Summary
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this post we have focused on performance issues in training applications
    that are caused by host-device synchronization events. We saw several examples
    of PyTorch operators that trigger such events — the common property of all of
    them being that the *size* of the tensors that they output are dependent on the
    input. You might also encounter synchronization events from other operators, not
    covered in this post. We demonstrated how performance analyzers such as [PyTorch
    Profiler](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html)
    and its associated [TensorBoard plugin](https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html)
    can be used to identify these kinds of events.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们重点讨论了由于主机与设备同步事件而引发的训练应用中的性能问题。我们看到了一些触发这些事件的PyTorch操作符的例子——它们的共同特点是它们输出的张量的*大小*取决于输入。你也可能会遇到其他操作符引发的同步事件，这些操作符在这篇文章中没有涉及。我们展示了如何使用性能分析器，如[PyTorch
    Profiler](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html)及其关联的[TensorBoard插件](https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html)来识别这些类型的事件。
- en: In the case of our toy example, we were able to find equivalent alternatives
    to the problematic operators that use fixed sized tensors and avoid the need for
    synchronization events. These led to a significant improvement in training time.
    However, in practice you might find it much harder — even impossible — to solve
    these kinds of bottlenecks. Sometimes, overcoming them might require redesigning
    parts of your model.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我们找到了使用固定大小张量的替代操作符，避免了同步事件的需求，从而显著改善了训练时间。然而，在实际应用中，你可能会发现解决这些瓶颈要困难得多——甚至不可能。有时，克服这些问题可能需要重新设计模型的部分内容。
- en: What Next?
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一步是什么？
- en: In [next part](/solving-bottlenecks-on-the-data-input-pipeline-with-pytorch-profiler-and-tensorboard-5dced134dbe9)
    of our series of posts on the topic of PyTorch model optimization, we will analyze
    and address performance bottlenecks in the data pre-processing pipeline of a DL
    training workload. Be sure to [check it out](/how-to-optimize-your-dl-data-input-pipeline-with-a-custom-pytorch-operator-7f8ea2da5206).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们关于PyTorch模型优化的系列文章的[下一部分](/solving-bottlenecks-on-the-data-input-pipeline-with-pytorch-profiler-and-tensorboard-5dced134dbe9)中，我们将分析和解决DL训练工作负载的数据预处理管道中的性能瓶颈。一定要[查看](/how-to-optimize-your-dl-data-input-pipeline-with-a-custom-pytorch-operator-7f8ea2da5206)。
