["```py\n# Helper method to get accuracy and pred_probs from Trainer.\ndef compute_metrics(p):   \n    logits, labels = p\n    pred = np.argmax(logits, axis=1)\n    pred_probs = softmax(logits, axis=1)\n    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n    return {\"logits\":logits, \"pred_probs\":pred_probs, \"accuracy\": accuracy}\n\n# Helper method to initiate a new Trainer with given train and test sets.\ndef get_trainer(train_set, test_set):\n\n    # Model params.\n    model_name = \"distilbert-base-uncased\"\n    model_folder = \"model_training\"\n    max_training_steps = 300\n    num_classes = 2\n\n    # Set training args.\n    # We time-seed to ensure randomness between different benchmarking runs.\n    training_args = TrainingArguments(\n        max_steps=max_training_steps, \n        output_dir=model_folder,\n        seed = int(datetime.now().timestamp())\n    )\n\n    # Tokenize train/test set.\n    dataset_train = tokenize_data(train_set)\n    dataset_test = tokenize_data(test_set)\n\n    # Initiate a pre-trained model.\n    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_classes)\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        compute_metrics = compute_metrics,\n        train_dataset = train_tokenized_dataset,\n        eval_dataset = test_tokenized_dataset,\n    )\n    return trainer\n```", "```py\nfrom cleanlab.multiannotator import get_active_learning_scores\n\npred_probs, pred_probs_unlabeled = get_pred_probs(train_set, X_unlabeled)\n\n# Compute active learning scores.\nactive_learning_scores, active_learning_scores_unlabeled = get_active_learning_scores(\n    multiannotator_labels, pred_probs, pred_probs_unlabeled\n)\n# Get the indices of examples to collect more labels for.\nchosen_examples_labeled, chosen_examples_unlabeled = get_idx_to_label(\n    X_labeled_full,\n    X_unlabeled,\n    extra_annotations,\n    batch_size_to_label,\n    active_learning_scores,\n    active_learning_scores_unlabeled,\n)\n```", "```py\n# Combine ids of labeled and unlabeled chosen examples.\nchosen_example_ids = np.concatenate([X_labeled_full.iloc[chosen_examples_labeled].index.values, X_unlabeled.iloc[chosen_examples_unlabeled].index.values])\n\n# Collect annotations for the selected examples.\nfor example_id in chosen_example_ids:\n  # Collect new annotation and who it's coming from.\n    new_annotation = get_annotation(example_id, chosen_annotator)\n\n  # New annotator has been selected.\n    if chosen_annotator not in X_labeled_full.columns.values:\n        empty_col = np.full((len(X_labeled_full),), np.nan)\n        X_labeled_full[chosen_annotator] = empty_col\n\n    # Add selected annotation to the training set.\n    X_labeled_full.at[example_id, chosen_annotator] = new_annotation\n```"]