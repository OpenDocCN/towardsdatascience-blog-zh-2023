- en: 'Efficient Deep Learning: Unleashing the Power of Model Compression'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/efficient-deep-learning-unleashing-the-power-of-model-compression-7b5ea37d4d06?source=collection_archive---------3-----------------------#2023-09-03](https://towardsdatascience.com/efficient-deep-learning-unleashing-the-power-of-model-compression-7b5ea37d4d06?source=collection_archive---------3-----------------------#2023-09-03)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/e3f104a88962263b5a88baa0f644362f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image By Author
  prefs: []
  type: TYPE_NORMAL
- en: Accelerate model inference speed in production
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@marcellopoliti?source=post_page-----7b5ea37d4d06--------------------------------)[![Marcello
    Politi](../Images/484e44571bd2e75acfe5fef3146ab3c2.png)](https://medium.com/@marcellopoliti?source=post_page-----7b5ea37d4d06--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7b5ea37d4d06--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7b5ea37d4d06--------------------------------)
    [Marcello Politi](https://medium.com/@marcellopoliti?source=post_page-----7b5ea37d4d06--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7390355d40fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fefficient-deep-learning-unleashing-the-power-of-model-compression-7b5ea37d4d06&user=Marcello+Politi&userId=7390355d40fe&source=post_page-7390355d40fe----7b5ea37d4d06---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7b5ea37d4d06--------------------------------)
    ·9 min read·Sep 3, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7b5ea37d4d06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fefficient-deep-learning-unleashing-the-power-of-model-compression-7b5ea37d4d06&user=Marcello+Politi&userId=7390355d40fe&source=-----7b5ea37d4d06---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7b5ea37d4d06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fefficient-deep-learning-unleashing-the-power-of-model-compression-7b5ea37d4d06&source=-----7b5ea37d4d06---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When a Machine Learning model is deployed into production there are often requirements
    to be met that are not taken into account in a prototyping phase of the model.
    For example, the model in production will have to handle lots of requests from
    different users running the product. So you will want to optimize for instance
    latency and/o throughput.
  prefs: []
  type: TYPE_NORMAL
- en: '**Latency**: is the time it takes for a task to get done, like how long it
    takes to load a webpage after you click a link. It’s the waiting time between
    starting something and seeing the result.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Throughput**: is how much requests a system can handle in a certain time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This means that the Machine Learning model has to be very fast at making its
    predictions, and for this there are various techniques that serve to increase
    the speed of model inference, let’s look at the most important ones in this article.
  prefs: []
  type: TYPE_NORMAL
- en: Model Compression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are techniques that aim to make **models smaller**, which is why they
    are called **model compression** techniques, while others that focus on making
    models **faster at inference** and thus fall under the field of **model**…
  prefs: []
  type: TYPE_NORMAL
