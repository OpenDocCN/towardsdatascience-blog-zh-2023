- en: Integrate LLM workflows with Knowledge Graph using Neo4j and APOC
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Neo4j和APOC将LLM工作流与知识图谱集成
- en: 原文：[https://towardsdatascience.com/integrate-llm-workflows-with-knowledge-graph-using-neo4j-and-apoc-27ef7e9900a2?source=collection_archive---------0-----------------------#2023-06-07](https://towardsdatascience.com/integrate-llm-workflows-with-knowledge-graph-using-neo4j-and-apoc-27ef7e9900a2?source=collection_archive---------0-----------------------#2023-06-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/integrate-llm-workflows-with-knowledge-graph-using-neo4j-and-apoc-27ef7e9900a2?source=collection_archive---------0-----------------------#2023-06-07](https://towardsdatascience.com/integrate-llm-workflows-with-knowledge-graph-using-neo4j-and-apoc-27ef7e9900a2?source=collection_archive---------0-----------------------#2023-06-07)
- en: OpenAI and VertexAI endpoints are now available as APOC Extended procedures
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenAI和VertexAI端点现已作为APOC扩展程序提供
- en: '[](https://bratanic-tomaz.medium.com/?source=post_page-----27ef7e9900a2--------------------------------)[![Tomaz
    Bratanic](../Images/d5821aa70918fcb3fc1ff0013497b3d5.png)](https://bratanic-tomaz.medium.com/?source=post_page-----27ef7e9900a2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----27ef7e9900a2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----27ef7e9900a2--------------------------------)
    [Tomaz Bratanic](https://bratanic-tomaz.medium.com/?source=post_page-----27ef7e9900a2--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://bratanic-tomaz.medium.com/?source=post_page-----27ef7e9900a2--------------------------------)[![Tomaz
    Bratanic](../Images/d5821aa70918fcb3fc1ff0013497b3d5.png)](https://bratanic-tomaz.medium.com/?source=post_page-----27ef7e9900a2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----27ef7e9900a2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----27ef7e9900a2--------------------------------)
    [Tomaz Bratanic](https://bratanic-tomaz.medium.com/?source=post_page-----27ef7e9900a2--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F57f13c0ea39a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintegrate-llm-workflows-with-knowledge-graph-using-neo4j-and-apoc-27ef7e9900a2&user=Tomaz+Bratanic&userId=57f13c0ea39a&source=post_page-57f13c0ea39a----27ef7e9900a2---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----27ef7e9900a2--------------------------------)
    ·8 min read·Jun 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F27ef7e9900a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintegrate-llm-workflows-with-knowledge-graph-using-neo4j-and-apoc-27ef7e9900a2&user=Tomaz+Bratanic&userId=57f13c0ea39a&source=-----27ef7e9900a2---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F57f13c0ea39a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintegrate-llm-workflows-with-knowledge-graph-using-neo4j-and-apoc-27ef7e9900a2&user=Tomaz+Bratanic&userId=57f13c0ea39a&source=post_page-57f13c0ea39a----27ef7e9900a2---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----27ef7e9900a2--------------------------------)
    ·8 分钟阅读·2023年6月7日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F27ef7e9900a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintegrate-llm-workflows-with-knowledge-graph-using-neo4j-and-apoc-27ef7e9900a2&user=Tomaz+Bratanic&userId=57f13c0ea39a&source=-----27ef7e9900a2---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F27ef7e9900a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintegrate-llm-workflows-with-knowledge-graph-using-neo4j-and-apoc-27ef7e9900a2&source=-----27ef7e9900a2---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F27ef7e9900a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintegrate-llm-workflows-with-knowledge-graph-using-neo4j-and-apoc-27ef7e9900a2&source=-----27ef7e9900a2---------------------bookmark_footer-----------)'
- en: Probably a day doesn’t go by that you don’t hear about new and exciting things
    happening in the Large Language Model (LLM) space. There are so many opportunities
    and use cases for any company to utilize the power of LLMs to enhance their productivity,
    transform or manipulate their data, and be used in conversational AI and QA systems.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 或许每天都有新鲜激动人心的事情发生在大型语言模型（LLM）领域。任何公司都有众多机会和应用场景，可以利用LLM的力量来提升生产力，转化或处理数据，以及用于对话AI和问答系统。
- en: To make it easier for you to [integrate LLMs with Knowledge Graphs](https://neo4j.com/generativeai/),
    the team at Neo4j has begun the journey of adding support for LLM integrations.
    The integrations are available as APOC Extended procedures. At the moment, OpenAI
    and VertexAI endpoints are supported, but we plan to add support for many more.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让你更容易[将 LLM 与知识图谱集成](https://neo4j.com/generativeai/)，Neo4j 的团队已经开始了添加对 LLM
    集成支持的旅程。这些集成作为 APOC 扩展过程提供。目前支持 OpenAI 和 VertexAI 端点，但我们计划添加更多的支持。
- en: When I was brainstorming what would be a cool use case to demonstrate the newly
    added APOC procedures, my friend [Michael Hunger](https://medium.com/u/3865848842f9?source=post_page-----27ef7e9900a2--------------------------------)
    suggested an exciting idea. What if we used graph context, or the neighborhood
    of a node, to enrich the information stored in text embeddings? That way, the
    vector similarity search could produce better results due to the increased richness
    of embedded information. The idea is simple but compelling and could be helpful
    in many use cases.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当我在头脑风暴展示新添加的 APOC 过程的酷炫用例时，我的朋友[Michael Hunger](https://medium.com/u/3865848842f9?source=post_page-----27ef7e9900a2--------------------------------)提出了一个激动人心的想法。如果我们利用图谱上下文或节点的邻域来丰富文本嵌入中的信息怎么办？这样，由于嵌入信息的丰富性增加，向量相似性搜索可能会产生更好的结果。这个想法简单但引人入胜，可能在许多用例中都很有用。
- en: All the code is available on [GitHub](https://github.com/tomasonjo/blogs/blob/master/llm/Neo4jOpenAIApoc.ipynb).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 所有代码都可以在[GitHub](https://github.com/tomasonjo/blogs/blob/master/llm/Neo4jOpenAIApoc.ipynb)上找到。
- en: Neo4j environment setup
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Neo4j 环境设置
- en: In this example, we will use both the APOC and Graph Data Science libraries.
    Luckily, [Neo4j Sandbox](https://neo4j.com/sandbox/) projects have both libraries
    installed and additionally come with a prepopulated database. Therefore, you can
    set up the environment with a couple of clicks. We will use the [small Movie project](https://sandbox.neo4j.com/?usecase=movies)
    to avoid incurring a more considerable LLM API cost.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将同时使用 APOC 和图数据科学库。幸运的是，[Neo4j Sandbox](https://neo4j.com/sandbox/)
    项目已经安装了这两个库，并且附带了一个预填充的数据库。因此，你可以通过几次点击设置环境。我们将使用[小型电影项目](https://sandbox.neo4j.com/?usecase=movies)以避免产生更高的
    LLM API 成本。
- en: '![](../Images/75628fd51fac874fdfaa7a0be250c4b9.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75628fd51fac874fdfaa7a0be250c4b9.png)'
- en: Sample of the movies graph. Image by the author.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 电影图谱的示例。图像由作者提供。
- en: The dataset contains **Movie** and **Person** nodes. There are only 38 movies,
    so we are dealing with a tiny dataset. The information provides a movie’s title
    and tagline, when it was released, and who acted in or directed it.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包含**电影**和**人物**节点。只有 38 部电影，因此我们处理的是一个微小的数据集。信息提供了电影的标题和标语、发布日期以及演员或导演。
- en: Constructing text embedding values
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建文本嵌入值
- en: We will be using the [OpenAI API endpoints](https://openai.com/). Therefore,
    you will end to create an OpenAI account if you haven’t already.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用[OpenAI API 端点](https://openai.com/)。因此，如果你还没有 OpenAI 账户，你需要创建一个。
- en: As mentioned, the idea is to use the neighborhood of a node to construct its
    text embedding representation. Since the graph model is simple, we don’t have
    a lot of creative freedom. We will create text embedding representations of movies
    by using their properties and neighbor information. In this instance, the neighbor
    information is only about its actors and directors. However, I believe that this
    concept can be applied to more complex graph schema and be used to improve your
    vector similarity search applications.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，这个想法是使用节点的邻域来构建其文本嵌入表示。由于图谱模型简单，我们没有太多的创造性自由。我们将通过使用电影的属性和邻居信息来创建电影的文本嵌入表示。在这种情况下，邻居信息仅包括其演员和导演。然而，我相信这个概念可以应用于更复杂的图谱模式，并用于改进你的向量相似性搜索应用。
- en: '![](../Images/8c63ba0a64729b916c5864a9117df353.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8c63ba0a64729b916c5864a9117df353.png)'
- en: Idea of using the information from neighbor nodes to enrich the text embedding
    representations of central node. Image by the author. Icons from [flaticon](https://www.flaticon.com/).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 利用邻居节点的信息来丰富中心节点的文本嵌入表示。图像由作者提供。图标来自[flaticon](https://www.flaticon.com/)。
- en: The typical approach we see nowadays, where we simply chunk and embed documents,
    might fail when looking for information that spans multiple documents. This problem
    is also known as multi-hop question answering. However, the multi-hop QA problem
    can be solved using knowledge graphs. One way to look at a knowledge graph is
    as condensed information storage. For example, an [information extraction pipeline](https://medium.com/neo4j/creating-a-knowledge-graph-from-video-transcripts-with-gpt-4-52d7c7b9f32c)
    can be used to extract relevant information from various records. Using knowledge
    graphs, you can represent highly-connected information that spans multiple documents
    as relationships between various entities.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在看到的典型方法是简单地分块并嵌入文档，但当寻找跨越多个文档的信息时，这种方法可能会失败。这种问题也被称为多跳问答。然而，多跳问答问题可以使用知识图谱来解决。看待知识图谱的一种方式是将其视为浓缩的信息存储。例如，可以使用[信息提取管道](https://medium.com/neo4j/creating-a-knowledge-graph-from-video-transcripts-with-gpt-4-52d7c7b9f32c)从各种记录中提取相关信息。使用知识图谱，您可以将跨越多个文档的高度连接的信息表示为各种实体之间的关系。
- en: One solution is to use [LLMs to generate a Cypher statement that can be used
    to retrieve connected information from the database](/langchain-has-added-cypher-search-cb9d821120d5).
    Another solution, which we will use here, is to use the connection information
    to enrich the text embedding representations. Additionally, the enhanced information
    can be retrieved at query time to provide additional context to the LLM from which
    it can base its response.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一种解决方案是使用[LLMs生成Cypher语句，以从数据库中检索连接的信息](/langchain-has-added-cypher-search-cb9d821120d5)。另一种解决方案是使用连接信息来丰富文本嵌入表示。此外，增强的信息可以在查询时检索，以向LLM提供额外的上下文，从而作为其回答的基础。
- en: The following Cypher query can be used to retrieve all the relevant information
    about the movie nodes from their neighbors.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 以下Cypher查询可用于从邻居节点中检索所有相关的电影信息。
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The query return the following context for the Matrix movie.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 查询返回了以下Matrix电影的上下文。
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Depending on your domain, you might also use custom queries that retrieve information
    more than one hop away or sometimes want to aggregate some results.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的领域，您可能还会使用自定义查询来检索多跳之外的信息，或者有时需要聚合一些结果。
- en: We will now use OpenAI’s embedding endpoint to generate text embeddings representing
    the movies and their context and store them as node properties.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用OpenAI的嵌入端点来生成表示电影及其上下文的文本嵌入，并将其存储为节点属性。
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The newly added `apoc.ml.openai.embedding`procedures make generating text embeddings
    very easy using OpenAI’s API. We wrap the API call with `apoc.periodic.iterate`
    to batch the transactions and introduce the retry policy.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 新增的`apoc.ml.openai.embedding`过程使使用OpenAI的API生成文本嵌入变得非常容易。我们用`apoc.periodic.iterate`来包装API调用，以批处理事务并引入重试策略。
- en: Retrieval-augmented LLMs
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检索增强型LLMs
- en: It looks like the mainstream trend is to provide LLMs with external information
    at query time. We can even find OpenAI’s guides how to [provide relevant information
    as part of the prompt to generate the answer](https://platform.openai.com/docs/guides/gpt-best-practices/strategy-provide-reference-text).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来主流趋势是查询时向LLMs提供外部信息。我们甚至可以找到OpenAI的指南，了解如何[将相关信息作为提示的一部分来生成答案](https://platform.openai.com/docs/guides/gpt-best-practices/strategy-provide-reference-text)。
- en: '![](../Images/f5ef0f66b66657b98f3ad70c49cdc01a.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f5ef0f66b66657b98f3ad70c49cdc01a.png)'
- en: Retrieval-augmented approach to LLMs. Image by the author.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 检索增强型LLMs的方法。图片由作者提供。
- en: 'Here, we will use vector similarity search to find relevant movies given the
    user input. The workflow is the following:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用向量相似度搜索来根据用户输入查找相关电影。工作流程如下：
- en: We embed the user question with the same text embedding model we used to embed
    node context information
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用与嵌入节点上下文信息相同的文本嵌入模型来嵌入用户问题
- en: We use the cosine similarity to find the top 3 most relevant nodes and return
    their information to the LLM
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用余弦相似度来找到前三个最相关的节点，并将它们的信息返回给LLM
- en: The LLM constructs the final answer based on the provided information
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM根据提供的信息构建最终答案
- en: Since we will be using the **gpt-3.5-turbo** model to generate the final answer,
    it is a good practice to define the system prompt. To make it more readable, we
    will define the system prompt as Python variable and then use query parameters
    when executing Cypher statements.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将使用**gpt-3.5-turbo**模型来生成最终答案，因此定义系统提示是一个良好的实践。为了使其更具可读性，我们将系统提示定义为Python变量，然后在执行Cypher语句时使用查询参数。
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Next, we will define a function that constructs a user prompt based on the user
    question and the provided context from the database.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将定义一个函数，该函数根据用户问题和数据库中提供的上下文构建用户提示。
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Before asking the LLM to generate answers, we must define the intelligent search
    tool that will provide relevant context information based on the vector similarity
    search. As mentioned, we need to embed the user input and then use the cosine
    similarity to identify relevant nodes. With graphs, you can decide the type of
    information you want to retrieve and provide as context. In this example, we will
    return the same context information that was used to generate text embeddings
    along with similar movie information.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在要求语言模型生成答案之前，我们必须定义智能搜索工具，该工具将基于向量相似性搜索提供相关的上下文信息。如前所述，我们需要嵌入用户输入，然后使用余弦相似性来识别相关节点。通过图形，你可以决定你想要检索和提供作为上下文的信息类型。在这个示例中，我们将返回与生成文本嵌入相同的上下文信息，以及类似的电影信息。
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: At the moment, you need to use the `gds.similarity.cosine` function to calculate
    the cosine similarity between the question and relevant nodes. After identifying
    the relevant nodes, we retrieve the context using two additional `MATCH`clauses.
    You can check out [Neo4j’s GraphAcademy](https://graphacademy.neo4j.com/) to learn
    more about Cypher query language.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，你需要使用`gds.similarity.cosine`函数来计算问题和相关节点之间的余弦相似性。在识别相关节点后，我们使用两个额外的`MATCH`子句来检索上下文。你可以查看
    [Neo4j 的 GraphAcademy](https://graphacademy.neo4j.com/) 以了解更多关于 Cypher 查询语言的内容。
- en: Finally, we can define the function that takes in the user question and returns
    an answer.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以定义一个函数，该函数接受用户问题并返回答案。
- en: '[PRE6]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Let’s test our retrieval-augmented LLM workflow.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们测试一下增强检索的语言模型工作流程。
- en: '![](../Images/f4ad9a6afe98b3ac53152fa3af87d238.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4ad9a6afe98b3ac53152fa3af87d238.png)'
- en: Image by author
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: We can observe that the workflow first retrieves relevant movies and uses that
    information to generate an answer. An easter egg is hidden here that Emil Eifrem
    supposedly played in The Matrix.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以观察到，工作流程首先检索相关的电影，并使用这些信息生成答案。这里隐藏了一个彩蛋，Emil Eifrem 被认为出演了《黑客帝国》。
- en: Let’s try another one.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再试一个。
- en: '![](../Images/0ebe8f13410cbda6aa3ac7502bee8955.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0ebe8f13410cbda6aa3ac7502bee8955.png)'
- en: Image by author
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: The vector similarity search was able to retrieve movies where Jack Nicholson
    is mentioned and use that information to construct the answer. As mentioned, we
    can retrieve information from the graph that wasn’t included in the text embedding
    generation of the node.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 向量相似性搜索能够检索提到 Jack Nicholson 的电影，并使用这些信息构建答案。如前所述，我们可以从图形中检索未包含在节点文本嵌入生成中的信息。
- en: '![](../Images/8f14fe8b412d9c0081644345562a4358.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8f14fe8b412d9c0081644345562a4358.png)'
- en: Image by author
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Summary
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: And there you have it, a glimpse into the fascinating world of integrating Large
    Language Models with Knowledge Graphs. As the field continues to evolve, so too
    will the tools and techniques at our disposal. With Neo4j and APOC’s continued
    advancements, we can expect even greater innovation in how we handle and process
    data.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是将大型语言模型与知识图谱集成的迷人世界的一瞥。随着这一领域的不断发展，我们手头的工具和技术也会不断进步。随着 Neo4j 和 APOC 的不断进步，我们可以期待在数据处理和处理方面出现更大的创新。
- en: As always, the code is available on [GitHub](https://github.com/tomasonjo/blogs/blob/master/llm/Neo4jOpenAIApoc.ipynb).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，代码可以在 [GitHub](https://github.com/tomasonjo/blogs/blob/master/llm/Neo4jOpenAIApoc.ipynb)
    上找到。
