- en: Integrate LLM workflows with Knowledge Graph using Neo4j and APOC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/integrate-llm-workflows-with-knowledge-graph-using-neo4j-and-apoc-27ef7e9900a2?source=collection_archive---------0-----------------------#2023-06-07](https://towardsdatascience.com/integrate-llm-workflows-with-knowledge-graph-using-neo4j-and-apoc-27ef7e9900a2?source=collection_archive---------0-----------------------#2023-06-07)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: OpenAI and VertexAI endpoints are now available as APOC Extended procedures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://bratanic-tomaz.medium.com/?source=post_page-----27ef7e9900a2--------------------------------)[![Tomaz
    Bratanic](../Images/d5821aa70918fcb3fc1ff0013497b3d5.png)](https://bratanic-tomaz.medium.com/?source=post_page-----27ef7e9900a2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----27ef7e9900a2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----27ef7e9900a2--------------------------------)
    [Tomaz Bratanic](https://bratanic-tomaz.medium.com/?source=post_page-----27ef7e9900a2--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F57f13c0ea39a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintegrate-llm-workflows-with-knowledge-graph-using-neo4j-and-apoc-27ef7e9900a2&user=Tomaz+Bratanic&userId=57f13c0ea39a&source=post_page-57f13c0ea39a----27ef7e9900a2---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----27ef7e9900a2--------------------------------)
    ·8 min read·Jun 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F27ef7e9900a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintegrate-llm-workflows-with-knowledge-graph-using-neo4j-and-apoc-27ef7e9900a2&user=Tomaz+Bratanic&userId=57f13c0ea39a&source=-----27ef7e9900a2---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F27ef7e9900a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintegrate-llm-workflows-with-knowledge-graph-using-neo4j-and-apoc-27ef7e9900a2&source=-----27ef7e9900a2---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: Probably a day doesn’t go by that you don’t hear about new and exciting things
    happening in the Large Language Model (LLM) space. There are so many opportunities
    and use cases for any company to utilize the power of LLMs to enhance their productivity,
    transform or manipulate their data, and be used in conversational AI and QA systems.
  prefs: []
  type: TYPE_NORMAL
- en: To make it easier for you to [integrate LLMs with Knowledge Graphs](https://neo4j.com/generativeai/),
    the team at Neo4j has begun the journey of adding support for LLM integrations.
    The integrations are available as APOC Extended procedures. At the moment, OpenAI
    and VertexAI endpoints are supported, but we plan to add support for many more.
  prefs: []
  type: TYPE_NORMAL
- en: When I was brainstorming what would be a cool use case to demonstrate the newly
    added APOC procedures, my friend [Michael Hunger](https://medium.com/u/3865848842f9?source=post_page-----27ef7e9900a2--------------------------------)
    suggested an exciting idea. What if we used graph context, or the neighborhood
    of a node, to enrich the information stored in text embeddings? That way, the
    vector similarity search could produce better results due to the increased richness
    of embedded information. The idea is simple but compelling and could be helpful
    in many use cases.
  prefs: []
  type: TYPE_NORMAL
- en: All the code is available on [GitHub](https://github.com/tomasonjo/blogs/blob/master/llm/Neo4jOpenAIApoc.ipynb).
  prefs: []
  type: TYPE_NORMAL
- en: Neo4j environment setup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this example, we will use both the APOC and Graph Data Science libraries.
    Luckily, [Neo4j Sandbox](https://neo4j.com/sandbox/) projects have both libraries
    installed and additionally come with a prepopulated database. Therefore, you can
    set up the environment with a couple of clicks. We will use the [small Movie project](https://sandbox.neo4j.com/?usecase=movies)
    to avoid incurring a more considerable LLM API cost.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/75628fd51fac874fdfaa7a0be250c4b9.png)'
  prefs: []
  type: TYPE_IMG
- en: Sample of the movies graph. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset contains **Movie** and **Person** nodes. There are only 38 movies,
    so we are dealing with a tiny dataset. The information provides a movie’s title
    and tagline, when it was released, and who acted in or directed it.
  prefs: []
  type: TYPE_NORMAL
- en: Constructing text embedding values
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will be using the [OpenAI API endpoints](https://openai.com/). Therefore,
    you will end to create an OpenAI account if you haven’t already.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned, the idea is to use the neighborhood of a node to construct its
    text embedding representation. Since the graph model is simple, we don’t have
    a lot of creative freedom. We will create text embedding representations of movies
    by using their properties and neighbor information. In this instance, the neighbor
    information is only about its actors and directors. However, I believe that this
    concept can be applied to more complex graph schema and be used to improve your
    vector similarity search applications.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8c63ba0a64729b916c5864a9117df353.png)'
  prefs: []
  type: TYPE_IMG
- en: Idea of using the information from neighbor nodes to enrich the text embedding
    representations of central node. Image by the author. Icons from [flaticon](https://www.flaticon.com/).
  prefs: []
  type: TYPE_NORMAL
- en: The typical approach we see nowadays, where we simply chunk and embed documents,
    might fail when looking for information that spans multiple documents. This problem
    is also known as multi-hop question answering. However, the multi-hop QA problem
    can be solved using knowledge graphs. One way to look at a knowledge graph is
    as condensed information storage. For example, an [information extraction pipeline](https://medium.com/neo4j/creating-a-knowledge-graph-from-video-transcripts-with-gpt-4-52d7c7b9f32c)
    can be used to extract relevant information from various records. Using knowledge
    graphs, you can represent highly-connected information that spans multiple documents
    as relationships between various entities.
  prefs: []
  type: TYPE_NORMAL
- en: One solution is to use [LLMs to generate a Cypher statement that can be used
    to retrieve connected information from the database](/langchain-has-added-cypher-search-cb9d821120d5).
    Another solution, which we will use here, is to use the connection information
    to enrich the text embedding representations. Additionally, the enhanced information
    can be retrieved at query time to provide additional context to the LLM from which
    it can base its response.
  prefs: []
  type: TYPE_NORMAL
- en: The following Cypher query can be used to retrieve all the relevant information
    about the movie nodes from their neighbors.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The query return the following context for the Matrix movie.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Depending on your domain, you might also use custom queries that retrieve information
    more than one hop away or sometimes want to aggregate some results.
  prefs: []
  type: TYPE_NORMAL
- en: We will now use OpenAI’s embedding endpoint to generate text embeddings representing
    the movies and their context and store them as node properties.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The newly added `apoc.ml.openai.embedding`procedures make generating text embeddings
    very easy using OpenAI’s API. We wrap the API call with `apoc.periodic.iterate`
    to batch the transactions and introduce the retry policy.
  prefs: []
  type: TYPE_NORMAL
- en: Retrieval-augmented LLMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It looks like the mainstream trend is to provide LLMs with external information
    at query time. We can even find OpenAI’s guides how to [provide relevant information
    as part of the prompt to generate the answer](https://platform.openai.com/docs/guides/gpt-best-practices/strategy-provide-reference-text).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f5ef0f66b66657b98f3ad70c49cdc01a.png)'
  prefs: []
  type: TYPE_IMG
- en: Retrieval-augmented approach to LLMs. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we will use vector similarity search to find relevant movies given the
    user input. The workflow is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We embed the user question with the same text embedding model we used to embed
    node context information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We use the cosine similarity to find the top 3 most relevant nodes and return
    their information to the LLM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The LLM constructs the final answer based on the provided information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since we will be using the **gpt-3.5-turbo** model to generate the final answer,
    it is a good practice to define the system prompt. To make it more readable, we
    will define the system prompt as Python variable and then use query parameters
    when executing Cypher statements.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will define a function that constructs a user prompt based on the user
    question and the provided context from the database.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Before asking the LLM to generate answers, we must define the intelligent search
    tool that will provide relevant context information based on the vector similarity
    search. As mentioned, we need to embed the user input and then use the cosine
    similarity to identify relevant nodes. With graphs, you can decide the type of
    information you want to retrieve and provide as context. In this example, we will
    return the same context information that was used to generate text embeddings
    along with similar movie information.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: At the moment, you need to use the `gds.similarity.cosine` function to calculate
    the cosine similarity between the question and relevant nodes. After identifying
    the relevant nodes, we retrieve the context using two additional `MATCH`clauses.
    You can check out [Neo4j’s GraphAcademy](https://graphacademy.neo4j.com/) to learn
    more about Cypher query language.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we can define the function that takes in the user question and returns
    an answer.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Let’s test our retrieval-augmented LLM workflow.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f4ad9a6afe98b3ac53152fa3af87d238.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: We can observe that the workflow first retrieves relevant movies and uses that
    information to generate an answer. An easter egg is hidden here that Emil Eifrem
    supposedly played in The Matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try another one.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0ebe8f13410cbda6aa3ac7502bee8955.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: The vector similarity search was able to retrieve movies where Jack Nicholson
    is mentioned and use that information to construct the answer. As mentioned, we
    can retrieve information from the graph that wasn’t included in the text embedding
    generation of the node.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8f14fe8b412d9c0081644345562a4358.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: And there you have it, a glimpse into the fascinating world of integrating Large
    Language Models with Knowledge Graphs. As the field continues to evolve, so too
    will the tools and techniques at our disposal. With Neo4j and APOC’s continued
    advancements, we can expect even greater innovation in how we handle and process
    data.
  prefs: []
  type: TYPE_NORMAL
- en: As always, the code is available on [GitHub](https://github.com/tomasonjo/blogs/blob/master/llm/Neo4jOpenAIApoc.ipynb).
  prefs: []
  type: TYPE_NORMAL
