- en: 'Character Encoding in NLP: The Role of ASCII and Unicode'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/character-encoding-in-nlp-the-role-of-ascii-and-unicode-9349b4fe3cee?source=collection_archive---------13-----------------------#2023-01-12](https://towardsdatascience.com/character-encoding-in-nlp-the-role-of-ascii-and-unicode-9349b4fe3cee?source=collection_archive---------13-----------------------#2023-01-12)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A closer look at the technicalities and practical applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@javi_sanchez?source=post_page-----9349b4fe3cee--------------------------------)[![Javi
    Sánchez](../Images/4b24d1e1aaef9581f1d085c9a6a5990d.png)](https://medium.com/@javi_sanchez?source=post_page-----9349b4fe3cee--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9349b4fe3cee--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9349b4fe3cee--------------------------------)
    [Javi Sánchez](https://medium.com/@javi_sanchez?source=post_page-----9349b4fe3cee--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdadb8e5314e0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcharacter-encoding-in-nlp-the-role-of-ascii-and-unicode-9349b4fe3cee&user=Javi+S%C3%A1nchez&userId=dadb8e5314e0&source=post_page-dadb8e5314e0----9349b4fe3cee---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9349b4fe3cee--------------------------------)
    ·7 min read·Jan 12, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9349b4fe3cee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcharacter-encoding-in-nlp-the-role-of-ascii-and-unicode-9349b4fe3cee&user=Javi+S%C3%A1nchez&userId=dadb8e5314e0&source=-----9349b4fe3cee---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9349b4fe3cee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcharacter-encoding-in-nlp-the-role-of-ascii-and-unicode-9349b4fe3cee&source=-----9349b4fe3cee---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article we will cover the topic of character encoding standards, specifically
    focusing on the ASCII and Unicode systems. We will dive into how they work and
    their role in deep learning. In addition, we will provide some examples of character
    encoding using Tensorflow, to have an overview of how this library manages strings
    on the inside.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2a0c219212d87bfa8b058ae41b488b43.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Giammarco](https://unsplash.com/es/@giamboscaro) on [Unsplash](https://unsplash.com/)
  prefs: []
  type: TYPE_NORMAL
- en: But first of all, we will present some important concepts.
  prefs: []
  type: TYPE_NORMAL
- en: What is a character encoding standard?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Character encoding is a system for representing characters as numerical values,
    known as code points. These code points allow computers to store and manipulate
    text, which can then be displayed or used in other ways. In this article, we will
    explain the ASCII and Unicode character encoding systems and discuss their usefulness
    in the field of natural language processing (NLP).
  prefs: []
  type: TYPE_NORMAL
- en: ASCII
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ASCII (American Standard Code for Information Interchange) is a character encoding
    standard that assigns unique numbers to each letter, digit, and other symbol used
    in written text. It is widely used, but it has some limitations.
  prefs: []
  type: TYPE_NORMAL
- en: ASCII has 128 code points, which means that it can represent 128 characters
    and symbols. Some of these code points represent instructions for the computer,
    while others represent printable characters such as letters and digits.
  prefs: []
  type: TYPE_NORMAL
- en: 'The mapping system used in ASCII can be found in this table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c443857bcfbabbafc942f1f70d1e6549.png)'
  prefs: []
  type: TYPE_IMG
- en: ASCII table, [link](https://commons.wikimedia.org/wiki/File:ASCII-Table-wide.svg)
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, out of 128 code points, only 94 are printables.
  prefs: []
  type: TYPE_NORMAL
- en: For example, using the hexadecimal column of this table, we can encode the string
    “Language” as “4C 61 6E 67 75 61 67 65”.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations of ASCII
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The main limitation of ASCII code as we said earlier is that it only has 94
    printable characters. These include upper and lower case English letters (52 characters),
    digits (10 characters), and punctuation marks and symbols (32 characters). So
    ASCII is not suited for any language that uses more than the basic Latin alphabet.
    There are different characters in other languages (Chinese, Russian, Norwegian),
    or even accented letters in languages such as French and Spanish, for example,
    that can not be displayed using this character encoding system. Also, there are
    special symbols, like emojis or currency symbols that are not included in ASCII
    either, which limits its potential. For those reasons, a new character encoding
    system was required, to make it more extensible and have taken into account all
    these characters and symbols that have been forgotten in the ASCII code. This
    is where the Unicode Standard arises.
  prefs: []
  type: TYPE_NORMAL
- en: Unicode
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unicode is a character encoding standard developed in the late 1980s and early
    1990s to expand upon the capabilities of ASCII and other existing standards. One
    of the main motivations for its development was the need to have a single-character
    encoding standard that could be used to represent text in any language. To address
    this problem, the Unicode consortium was formed, to create a single, universal
    character encoding standard that could represent all the world’s languages. Unicode
    uses a 16-bit encoding scheme, which allows it to represent over 65,000 different
    characters. This is significantly more than the 128 characters that can be represented
    using ASCII. It has since become the dominant character encoding standard for
    the WWW and is widely supported by modern computing systems and software. It can
    encode and display text in a wide range of languages, including those using scripts
    other than the Latin alphabet (e.g. Chinese, Japanese, Arabic), as well as special
    symbols like emojis and currency symbols.
  prefs: []
  type: TYPE_NORMAL
- en: You can find more information on their website.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://home.unicode.org/?source=post_page-----9349b4fe3cee--------------------------------)
    [## Home'
  prefs: []
  type: TYPE_NORMAL
- en: Edit description
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: home.unicode.org](https://home.unicode.org/?source=post_page-----9349b4fe3cee--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unicode defines a codespace, a set of numerical values ranging from 0 through
    10FFFF (in hexadecimal), called code points and denoted with a U at the beginning,
    so it ranges from U+0000 to U+10FFFF. We will use the U followed by the code point
    value of the character in hexadecimal and use it for digits (with leading zeros
    if necessary, e.g., U+00F7). The Unicode codespace is divided into seventeen planes,
    numbered 0 to 16\. Each plane consists of 65,536 (2¹⁶) consecutive code points.
    Plane 0, known as the Basic Multilingual Plane (BMP), contains the most commonly
    used characters. The remaining planes (1 to 16) are called supplementary planes.
    Within each plane, characters are allocated within named blocks of related characters.
    A Unicode block is one of several contiguous ranges of numeric character codes.
    They are used to organize the vast number of characters in the Unicode standard.
    Each block is generally, but not always, meant to supply glyphs used by one or
    more specific languages, or in some general application area.
  prefs: []
  type: TYPE_NORMAL
- en: Mapping and encodings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Unicode defines two mapping methods: UTF encodings and UCS encodings. An encoding
    maps the range of Unicode code points to a sequence of values within a fixed range.
    All UTF encodings map code points to a unique sequence of bytes. The number in
    the names of the encodings indicates the number of bits per code unit. UTF-8 and
    UTF-16 are the most commonly used encodings.'
  prefs: []
  type: TYPE_NORMAL
- en: UTF-8 uses one to four bytes for each cope point. It is very compatible with
    ASCII.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: UTF-16 uses one or two 16-bit code units per code point.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unicode in NLP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will see how to use Unicode in NLP tasks and how is it useful.
    We will use some Tensorflow code to make these examples more illustrative.
  prefs: []
  type: TYPE_NORMAL
- en: NLP models often handle different languages with different character sets. The
    most representative task could be Neural Machine Translation (NMT), where the
    model has to translate sentences into other languages. But in general, all language
    models have to use string sequences as input, so Unicode is a pretty important
    step. Using Unicode representation is generally the most effective choice.
  prefs: []
  type: TYPE_NORMAL
- en: Here we will see how to represent a string in Tensorflow and manipulate them
    using Unicode. The basic TensorFlow tf.string type allows us to build tensors
    of the byte string. Unicode strings are UTF-8 by default.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Here we can see that the emoji is encoded as “\xf0\x9f\x8c\x8e”. It is represented
    in UTF-8.
  prefs: []
  type: TYPE_NORMAL
- en: Representation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can represent a Unicode string in Tensorflow in two standards:'
  prefs: []
  type: TYPE_NORMAL
- en: string scalar — where the sequence of code points is encoded using a known character
    encoding (such as Unicode).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: int32 vector — where each position contains a single code point.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, the following values all represent the Unicode string “语言处理” (which
    means “language processing” in Chinese).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: And we can also represent it using UTF-16.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: And finally, in a vector of Unicode code points.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Conversion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Tensorflow provides operations to convert between these different representations:'
  prefs: []
  type: TYPE_NORMAL
- en: '*tf.strings.unicode_decode*: Converts an encoded string scalar to a vector
    of code points.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '*tf.strings.unicode_encode*: Converts a vector of code points to an encoded
    string scalar.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '*tf.strings.unicode_transcode*: Converts an encoded string scalar to a different
    encoding.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Character length
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can use the unit parameter of the *tf.strings.length* operation to indicate
    how character lengths should be computed. The default unit value is “BYTE”, but
    it can be set to other values such as “UTF8_CHAR” or “UTF16_CHAR”, to determine
    the number of Unicode code points in each encoded string.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: If you count the number of bytes in the string “Hello World \xf0\x9f\x8c\x8d”
    (counting each letter, space, and byte) you will see that there are 16 bytes as
    we can see in the output code.
  prefs: []
  type: TYPE_NORMAL
- en: This string has 13 UTF-8 characters if we count the same as before but count
    the emoji as one character and not 4 bytes.
  prefs: []
  type: TYPE_NORMAL
- en: If you want a more complete tutorial about this section, I recommend you to
    visit this TensorFlow tutorial.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.tensorflow.org/text/guide/unicode?source=post_page-----9349b4fe3cee--------------------------------)
    [## Unicode strings | Text | TensorFlow'
  prefs: []
  type: TYPE_NORMAL
- en: NLP models often handle different languages with different character sets. Unicode
    is a standard encoding system that…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.tensorflow.org](https://www.tensorflow.org/text/guide/unicode?source=post_page-----9349b4fe3cee--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In conclusion, the character encoding is an essential aspect of computer systems
    and natural language processing (NLP). ASCII is a widely used standard that assigns
    unique numbers to each letter, digit, and symbol in the text, but it has limitations
    in its representation of characters. The Unicode standard was developed to address
    the limitations of ASCII, by using a 16-bit encoding scheme that allows it to
    represent over 65,000 different characters and support text in any language. Unicode
    has since become the dominant character encoding standard for the World Wide Web
    and modern computing systems and is essential for displaying and processing text
    in a wide range of languages and symbols. In this article, we have seen a detailed
    overview of the ASCII and Unicode encoding systems, and how Tensorflow manages
    the strings in Unicode.
  prefs: []
  type: TYPE_NORMAL
- en: If you have any doubts or suggestions please leave a comment. Thanks for reading!
  prefs: []
  type: TYPE_NORMAL
