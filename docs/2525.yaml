- en: Three challenges in deploying generative models in production
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/three-challenges-in-deploying-generative-models-in-production-8e4c0fcf63c3?source=collection_archive---------5-----------------------#2023-08-07](https://towardsdatascience.com/three-challenges-in-deploying-generative-models-in-production-8e4c0fcf63c3?source=collection_archive---------5-----------------------#2023-08-07)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How to deploy Large Language and Diffusion models for your product without scaring
    the users away.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://mikhailiuk.medium.com/?source=post_page-----8e4c0fcf63c3--------------------------------)[![Aliaksei
    Mikhailiuk](../Images/f4bf3f15f3e0b42f34e50b3ffc436b2a.png)](https://mikhailiuk.medium.com/?source=post_page-----8e4c0fcf63c3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8e4c0fcf63c3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8e4c0fcf63c3--------------------------------)
    [Aliaksei Mikhailiuk](https://mikhailiuk.medium.com/?source=post_page-----8e4c0fcf63c3--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F30bef13bba71&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthree-challenges-in-deploying-generative-models-in-production-8e4c0fcf63c3&user=Aliaksei+Mikhailiuk&userId=30bef13bba71&source=post_page-30bef13bba71----8e4c0fcf63c3---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8e4c0fcf63c3--------------------------------)
    ·9 min read·Aug 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8e4c0fcf63c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthree-challenges-in-deploying-generative-models-in-production-8e4c0fcf63c3&user=Aliaksei+Mikhailiuk&userId=30bef13bba71&source=-----8e4c0fcf63c3---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8e4c0fcf63c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthree-challenges-in-deploying-generative-models-in-production-8e4c0fcf63c3&source=-----8e4c0fcf63c3---------------------bookmark_footer-----------)![](../Images/4d0d67dbb4548f550d2b5fbbc3b28114.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image generated by the Author in [SDXL 1.0](https://stability.ai/blog/stable-diffusion-sdxl-1-announcement).
  prefs: []
  type: TYPE_NORMAL
- en: '[OpenAI](https://openai.com/), [Google](https://ai.google/discover/generativeai/),
    [Microsoft](https://blogs.microsoft.com/blog/2023/05/23/microsoft-build-brings-ai-tools-to-the-forefront-for-developers/),
    [Midjourney](https://www.midjourney.com/home/?callbackUrl=%2Fapp%2F), [StabilityAI](https://stability.ai/),
    [CharacterAI](https://beta.character.ai/) and many more — everyone is racing to
    bring the best solution for text-to-text, text-to-image, image-to-image and image-to-text
    models.'
  prefs: []
  type: TYPE_NORMAL
- en: The reason is simple — the vast field of opportunities the space offers; after
    all, it’s not only entertainment but also utility that was impossible to unlock.
    From [better search engines](https://blogs.microsoft.com/blog/2023/02/07/reinventing-search-with-a-new-ai-powered-microsoft-bing-and-edge-your-copilot-for-the-web/)
    to more impressive and [personalized ad campaigns](https://www.optimatik.ai/ai-product-photos)
    and friendly chatbots, like [Snap’s MyAI](https://newsroom.snap.com/en-GB/say-hi-to-my-ai).
  prefs: []
  type: TYPE_NORMAL
- en: And while the space is very fluid, with lots of moving parts and model checkpoints
    released every few days, there are challenges that every company working with
    Generative AI is looking to address.
  prefs: []
  type: TYPE_NORMAL
- en: Here, I will talk about the major challenges and how to address them in deploying
    generative models in production. While there are many different kinds of generative
    models, in this article, I will focus on the recent advancements in diffusion
    and GPT-based models. However, many topics discussed here would apply to other
    models as well.
  prefs: []
  type: TYPE_NORMAL
- en: What is generative AI?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generative AI broadly describes a set of models that can generate new content.
    Widely known Generative Adversarial Networks do so by learning the distribution
    of real data and generating variability from the added noise.
  prefs: []
  type: TYPE_NORMAL
- en: The recent boom in Generative AI comes from the models attaining human-level
    quality at scale. The reason for unlocking this transformation is simple — we
    only now have enough compute power (hence the [NVIDIA skyrocketing stock price](https://www.investors.com/news/nvidia-stock-2023-buy-now/))
    for training and maintaining models with enough capacity to achieve high-quality
    results. Current advancement is fuelled by two base architectures — transformers
    and diffusion models.
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps the most significant breakthrough of the recent year was OpenAI’s ChatGPT
    — a text-based generative model, with 175 billion for one of the latest ChatGPT-3.5
    versions that has a knowledge base sufficient to maintain conversations on various
    topics. While ChatGPT is a single modality model, as it can only support text,
    multimodal models can take as input and output several kinds of input, e.g. text
    and images.
  prefs: []
  type: TYPE_NORMAL
- en: Image-to-text and text-to-image multimodal architectures operate in a latent
    space shared by textual and image concepts. The latent space is obtained by training
    on a task requiring both concepts (for example, image captioning) by penalizing
    the distance in the latent space between the same concept in two different modalities.
    Once this latent space is obtained, it can be re-used for other tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/20b680f4fdfaaeea4a1b4ecae945ed5b.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of an Image-to-Text model. Image by the Author.
  prefs: []
  type: TYPE_NORMAL
- en: Notable generative models released this year are [DALLE](https://openai.com/dall-e-2)/[Stable-Diffusion](https://stability.ai/blog)
    (text-to-image / image-to-image) and [BLIP](https://arxiv.org/abs/2201.12086)
    (image-to-text [implementation](https://github.com/salesforce/BLIP)). DALLE models
    take as input either a prompt or an image and a prompt generates an image as a
    response, while BLIP-based models can answer questions about the contents of the
    picture.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges and Solutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unfortunately, there is no free lunch when it comes to machine learning, and
    large-scale generative models stumble upon a few challenges when it comes to their
    deployment in production — size and latency, bias and fairness, and the quality
    of the generated results.
  prefs: []
  type: TYPE_NORMAL
- en: Model size and latency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/809bb30040a03db448990c63422f1c66.png)'
  prefs: []
  type: TYPE_IMG
- en: Model size trends. Data from [P. Villalobos](https://arxiv.org/pdf/2207.02852.pdf).
    Image by the Author
  prefs: []
  type: TYPE_NORMAL
- en: State-of-the-art GenAI models are huge. For example, text-to-text [Meta’s LLaMA](https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/)
    models range between 7 and 65 billion parameters, and ChatGPT-3.5 is 175B parameters.
    These numbers are justified — in a simplified world, the rule of thumb is the
    larger the model the more data is used for training, the better the quality.
  prefs: []
  type: TYPE_NORMAL
- en: Text-to-image models, while smaller, are still significantly bigger than their
    Generative Adversarial Network predecessors — Stable Diffusion 1.5 checkpoints
    are just under 1B parameter (taking over three gigabytes of space), and DALLE
    2.0 has 3.5B parameters. Few GPUs would have enough memory to maintain these models
    and typically you would need a fleet to maintain a single large model, which can
    become very costly very soon, not even speaking of deploying these models on mobile
    devices.
  prefs: []
  type: TYPE_NORMAL
- en: Generative models take time to produce the output. For some, the latency is
    due to their size — propagating the signal through several billions of parameters
    even on a fleet of GPUs takes time, while for others, it’s due to the iterative
    nature of producing high-quality results. Diffusion models, in their default configuration,
    take 50 steps to generate an image, making a smaller number of steps deteriorates
    the quality of the output image.
  prefs: []
  type: TYPE_NORMAL
- en: '**Solutions:** Making the model smaller often helps make it faster — [distilling,
    compressing and quantizing](/on-the-edge-deploying-deep-applications-on-constrained-devices-f2dac997dd4d)
    the model would also reduce the latency. [Qualcomm has paved the way](https://www.qualcomm.com/news/onq/2023/02/worlds-first-on-device-demonstration-of-stable-diffusion-on-android)
    by compressing the stable diffusion model enough to be deployed on mobile. Recently
    smaller, distilled and much quicker versions of [Stable Diffusion (tiny and small)
    have been released](https://blog.segmind.com/introducing-sd-small-and-sd-tiny-stable-diffusion-models/).'
  prefs: []
  type: TYPE_NORMAL
- en: Model-specific optimization can also aid in speeding up the inference — for
    diffusion models; one might generate low-resolution output and then upscale it
    or use a lower number of steps and a different scheduler, as some work best with
    the lower number of steps, while others generate superior quality for a higher
    number of iterations. For example, [Snap recently showed that eight steps would
    be](https://snap-research.github.io/SnapFusion/) enough to create high-quality
    results with Stable Diffusion 1.5, employing various optimizations at training
    time.
  prefs: []
  type: TYPE_NORMAL
- en: Compiling the model with, for example, NVIDIAs [tensorrt](https://developer.nvidia.com/tensorrt)
    and [torch.compile](https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html)
    could substantially reduce the latency with minimal engineering effort.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/on-the-edge-deploying-deep-applications-on-constrained-devices-f2dac997dd4d?source=post_page-----8e4c0fcf63c3--------------------------------)
    [## On the edge — deploying deep learning applications on mobile'
  prefs: []
  type: TYPE_NORMAL
- en: Techniques on striking the efficiency-accuracy trade-off for deep neural networks
    on constrained devices
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/on-the-edge-deploying-deep-applications-on-constrained-devices-f2dac997dd4d?source=post_page-----8e4c0fcf63c3--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Bias, fairness and safety
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Have you ever tried to break ChatGPT? Many have succeeded in uncovering bias
    and fairness issues, and kudos to [OpenAI is doing a great job](https://openai.com/blog/how-should-ai-systems-behave)
    addressing these. Without fixes at scale, chatbots can create real-world problems
    by propagating harmful and unsafe ideas and behaviours.
  prefs: []
  type: TYPE_NORMAL
- en: Examples where people managed to break the model, are in [politics](https://www.brookings.edu/articles/the-politics-of-ai-chatgpt-and-political-bias/);
    for instance, ChatGPT [refused to create poems about Trump but would create one
    about Biden](https://www.forbes.com/sites/ariannajohnson/2023/02/03/is-chatgpt-partisan-poems-about-trump-and-biden-raise-questions-about-the-ai-bots-bias-heres-what-experts-think/),
    gender equality and jobs in particular — implying that some [professions are for
    men and some are for women](https://nationalcentreforai.jiscinvolve.org/wp/2023/01/26/exploring-the-potential-for-bias-in-chatgpt/)
    and [race](https://www.forbes.com/sites/janicegassam/2023/01/28/the-dark-side-of-chatgpt/).
  prefs: []
  type: TYPE_NORMAL
- en: Like text-to-text models, text-to-image and image-to-text models also contain
    biases and fairness issues. [The Stable Diffusion 2.1](https://huggingface.co/spaces/stabilityai/stable-diffusion)
    model when asked to generate images of a doctor and a nurse, produces a white
    male for the former and a white female for the latter. Interestingly, the bias
    would depend on the country specified in the prompt — e.g., a Japanese doctor
    or Brazilian nurse.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/baa3dac2aafafa0b794e59e99ca6c871.png)![](../Images/8b3a9600a74a17914d49faa08ad66012.png)'
  prefs: []
  type: TYPE_IMG
- en: Asking a Stable Diffusion model to generate an image of doctor and and an image
    of a nurse. Image generated by the Author with [SD 2.1 interface](https://huggingface.co/spaces/stabilityai/stable-diffusion).
  prefs: []
  type: TYPE_NORMAL
- en: Playing with [BLIP image-to-text model](https://replicate.com/salesforce/blip)
    and feeding in an image of an overweight person and male and female doctors I
    was getting judgemental and biased image descriptions — “a fat man”, “a male doctor”,
    “a woman in a lab coat with a stethoscope ”.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cf2feb754f75ca4371738cb1d773b8f1.png)![](../Images/fdc551bf4f5e9c224a664c52bc7adf34.png)![](../Images/d21ef055d5108c9a708d0614c95e4af6.png)'
  prefs: []
  type: TYPE_IMG
- en: Images Generated by the author with Stable Diffusion 2.1 and captions generated
    with BLIP model from left to right [1] a fat man eating an ice cream cone; [2]
    a male doctor in a white coat and tie; [3] a woman in a white lab coat with a
    stethoscope on her neck. Images are generated by the Author with [SD 2.1 interface](https://huggingface.co/spaces/stabilityai/stable-diffusion)
    and passed through [BLIP](https://replicate.com/salesforce/blip).
  prefs: []
  type: TYPE_NORMAL
- en: '**How to test for the issue:** It is a fairly hard-to-diagnose issue — in many
    cases, you would need to know what to look for. Having a separate benchmark dataset
    with a wide variety of prompts, where things might or might not go wrong, template
    responses and red flags for each answer that we would detect, as well as a dataset
    of humans from various backgrounds and in multiple scenarios storing all possible
    attributes about the person in the picture would help. These datasets need to
    have hundreds of thousands of entries to obtain reliable statistics.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Solution:** Almost all bias, fairness, and safety issues come from the training
    data. I like the analogy that AI models are a mirror of humanity that exacerbates
    all our biases. Training on clean, unbiased data would drastically improve the
    results. However, even with these, models make mistakes.'
  prefs: []
  type: TYPE_NORMAL
- en: Result post-processing and filtering is another possible solution; for example,
    Stable Diffusion trained on data that contains nude images has an NSFW content
    detector to catch potential issues. Similar filters can be applied to the output
    of text-to-text models.
  prefs: []
  type: TYPE_NORMAL
- en: Output quality, relevance and correctness
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Generative models can be very creative in interpreting user requests, and while
    recent large-scale models attain human-level quality, for each use-case, they
    wouldn’t be working out of the box, requiring additional tweaks and prompt engineering.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating quality in early, very limited image-to-text and text-to-text models
    was relatively straightforward — after all, an improvement over gibberish is obvious.
    High-quality generative models start exhibiting behaviours that are harder to
    detect; for example, text-to-text models can become evasive, confidently spitting
    out incorrect and outdated information.
  prefs: []
  type: TYPE_NORMAL
- en: Diffusion models exhibit output imperfections in other ways. Typical problems
    attributed to image-based models are broken geometry, mutated anatomy, a mismatch
    between the prompt and the image result, skin colour and gender mismatch in the
    case of image transfer. Automated assessment of aesthetics and realism is lagging,
    with typical metrics, like FID, incapable of capturing these variations.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2b8d4859a35e13936fa651c4f8e2f811.png)![](../Images/32cd2b6b56dc856a362fff98f44f625a.png)![](../Images/45c5f9cfd8461d6ab0e52c1424f8b012.png)'
  prefs: []
  type: TYPE_IMG
- en: 'From left to right: [1] two people hugging; [2] a man with thumbs up; [3] a
    dog is running in the park. An image from [Stable Diffusion 1.5](https://stablediffusionweb.com/#demo)
    generated by the Author'
  prefs: []
  type: TYPE_NORMAL
- en: '**How to test for the issue**: Testing the quality of generative models is
    challenging; after all, there is no ground truth for these models — they are made
    to provide novel outputs. And hence, so far, no metric would reliably capture
    quality aspects. And the most reliable metric is human evaluation.'
  prefs: []
  type: TYPE_NORMAL
- en: Like in bias and fairness evaluation, the best way is to have a large dataset
    of prompts and images to test the quality. With text-to-text models becoming more
    personalized and tuning to each user, in addition to the coherence of the dialogues,
    correctness and relevance, we would also want to evaluate how well they can remember
    information about the conversation.
  prefs: []
  type: TYPE_NORMAL
- en: '**Solution:** Many of the quality problems can be attributed to the training
    data and size of the models; they might yet be just a little bit too small to
    have another quality leap ([think GPT-3.5 versus GPT-4](https://www.linkedin.com/pulse/chatgpt-35-vs-chatgpt-4-comparison-latest-gpt-based-chatbot-kunerth/))
    — current latent space is an abstraction and is not designed to store precise
    information.Many problems can be resolved with better prompt engineering — both
    prompt augmentation for text-to-text and text-to-image and negative prompts for
    text-to-image models.'
  prefs: []
  type: TYPE_NORMAL
- en: Text-to-image and image-to-image models can have additional tools that might
    boost the quality — image enhancement, either through conventional deep learning
    methods or diffusion-based refiners. Addition modules like [ControlNet](https://huggingface.co/blog/controlnet)
    and orthogonal to the diffusion architecture can aid with additional control over
    the generated results. Dreambooth techniques for fine-tuning the model for a specific
    application would also help to get that edge in the results. Playing with additional
    parameters, like scheduler, CFG, and the number of diffusion steps, can drastically
    affect quality.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generative models have opened a new scope of applications both fun, like [AI
    Lenses](https://www.snapchat.com/lens/87aca516bfa74b86b708849c617e51c1?locale=en-GB)
    and commercial, like better search engines, co-pilots and advertisements. At the
    same time the rush to get the product out by the companies and consumer excitement
    about the new functionalities sometimes making apparent flows in the technology
    go unnoticed.
  prefs: []
  type: TYPE_NORMAL
- en: And while there is a general push to make the model benchmarking more transparent
    by publishing large scale open-source datasets, training code and evaluation results,
    there is also a push for stricter regulation of the large scale AI models. In
    an ideal world both wouldn’t go to an extreme and would aid each other in making
    AI safer and more fun to use.
  prefs: []
  type: TYPE_NORMAL
- en: Liked the author? Stay connected!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Have I missed anything? Do not hesitate to leave a note, comment or message
    me directly on [LinkedIn](https://www.linkedin.com/in/aliakseimikhailiuk/) or
    [Twitter](https://twitter.com/mikhailiuka)!
  prefs: []
  type: TYPE_NORMAL
- en: '[](/deep-image-quality-assessment-30ad71641fac?source=post_page-----8e4c0fcf63c3--------------------------------)
    [## Deep Image Quality Assessment'
  prefs: []
  type: TYPE_NORMAL
- en: Deep dive into full-reference image quality assessment. From subjective image
    quality experiments to deep objective…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/deep-image-quality-assessment-30ad71641fac?source=post_page-----8e4c0fcf63c3--------------------------------)
    [](/perceptual-losses-for-image-restoration-dd3c9de4113?source=post_page-----8e4c0fcf63c3--------------------------------)
    [## Perceptual Losses for Deep Image Restoration
  prefs: []
  type: TYPE_NORMAL
- en: From mean squared error to GANs — what makes a good perceptual loss function?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/perceptual-losses-for-image-restoration-dd3c9de4113?source=post_page-----8e4c0fcf63c3--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '**The opinions in this blog are my own and not attributable to or on behalf
    of Snap.**'
  prefs: []
  type: TYPE_NORMAL
