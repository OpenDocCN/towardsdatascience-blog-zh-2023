- en: Conformal Prediction for Machine Learning Classification ‚ÄîFrom the Ground Up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/conformal-prediction-for-machine-learning-classification-from-the-ground-up-a12fcf6860d0?source=collection_archive---------1-----------------------#2023-11-24](https://towardsdatascience.com/conformal-prediction-for-machine-learning-classification-from-the-ground-up-a12fcf6860d0?source=collection_archive---------1-----------------------#2023-11-24)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Implementing conformal prediction for classification without need of bespoke
    packages, and how to balance coverage (recall) across classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@michael.allen1966?source=post_page-----a12fcf6860d0--------------------------------)[![Michael
    Allen](../Images/eb0a81cd7c813076ec99955c844a3e94.png)](https://medium.com/@michael.allen1966?source=post_page-----a12fcf6860d0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a12fcf6860d0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a12fcf6860d0--------------------------------)
    [Michael Allen](https://medium.com/@michael.allen1966?source=post_page-----a12fcf6860d0--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F82abbb73efe6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconformal-prediction-for-machine-learning-classification-from-the-ground-up-a12fcf6860d0&user=Michael+Allen&userId=82abbb73efe6&source=post_page-82abbb73efe6----a12fcf6860d0---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a12fcf6860d0--------------------------------)
    ¬∑11 min read¬∑Nov 24, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa12fcf6860d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconformal-prediction-for-machine-learning-classification-from-the-ground-up-a12fcf6860d0&user=Michael+Allen&userId=82abbb73efe6&source=-----a12fcf6860d0---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa12fcf6860d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconformal-prediction-for-machine-learning-classification-from-the-ground-up-a12fcf6860d0&source=-----a12fcf6860d0---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: This blog post is inspired by Chris Molner‚Äôs book ‚Äî [Introduction to Conformal
    Prediction](https://christophmolnar.com/books/conformal-prediction/) with Python.
    Chris is brilliant at making new machine learning techniques accessible to others.
    I‚Äôd especially also recommend his books on Explainable Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'A GitHub repository with the full code (and a link to running the code online)
    may be found here: [Conformal Prediction](https://github.com/MichaelAllen1966/conformal_prediction).'
  prefs: []
  type: TYPE_NORMAL
- en: '**What is Conformal Prediction?**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Conformal prediction is both a method of uncertainty quantification, and a method
    of classifying instances (which may be fine-tuned for classes or subgroups). Uncertainty
    is conveyed by classification being in sets of potential classes rather than single
    predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Conformal prediction specifies a *coverage*, which specifies the probability
    that the true outcome is covered by the prediction region. The interpretation
    of prediction regions in conformal prediction depends on the task. For classification
    we get prediction sets, while for regression we get prediction intervals.
  prefs: []
  type: TYPE_NORMAL
- en: Below is an example of the difference between ‚Äòtraditional‚Äô classification (balance
    of likelihood) and conformal prediction (sets).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/db455810fcc3fac08b3ad198877d9226.png)'
  prefs: []
  type: TYPE_IMG
- en: The difference between ‚Äònormal‚Äô classification based on most likely class, and
    conformal prediction which creates sets of possible classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The advantages of this method are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Guaranteed coverage**: Prediction sets generated by conformal prediction
    come with coverage guarantees of the true outcome ‚Äî that is that they will detect
    whatever percentage of true values you set as a minimum target coverage. Conformal
    prediction does not depend on a well calibrated model ‚Äî the only thing that matters
    is that, like all machine learning, the new samples being classified must come
    from similar data distributions to the training and calibration data. Coverage
    can also be guaranteed across classes or subgroups, though this takes an extra
    step in the method which we will cover.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Easy to use**: Conformal prediction approaches can be implemented from scratch
    with just a few lines of code, as we will do here.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model-agnostic**: Conformal prediction works with any machine learning model.
    It uses the normal outputs of whatever you preferred model is.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distribution-free**: Conformal prediction makes no assumptions about underlying
    distributions of data; it is a non-parametric method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**No retraining required**: Conformal prediction can be used without retraining
    your model. It is another way of looking at, and using, model outputs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Broad application**: conformal prediction works for tabular data classification,
    image or time-series classification, regression, and many other tasks, though
    we will demonstrate just classification here.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Why should we care about uncertainty quantificiation?**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Uncertainty quantification is essential in many situations:'
  prefs: []
  type: TYPE_NORMAL
- en: When we use model predictions to make decisions. How sure are we of those predictions?
    Is using just ‚Äòmost likely class‚Äô good enough for the task we have?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When we want to communicate the uncertainty associated with our predictions
    to stakeholders, without talking about probabilities or odds, or even log-odds!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alpha in conformal prediction ‚Äî describes** *coverage*'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Coverage* is key to conformal prediction. In classification it is the normal
    region of data that a particular class inhabits. Coverage is equivalent to *sensitivity*
    or *recall*; it is the proportion of observed values that are identified in the
    classification sets. We can tighten or loosen the area of coverage by adjusting
    ùõº (*coverage = 1 ‚Äî* ùõº).'
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs code!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Import packages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**Create synthetic data for classification**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Example data will be produced using SK-Learn‚Äôs `make_blobs` method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/6ffd685be074b4e5c58e77947acd8a3b.png)'
  prefs: []
  type: TYPE_IMG
- en: Generated data (the data is created to be imbalanced ‚Äî the blue class has only
    about 30% of the data points of either the green or orange classes).
  prefs: []
  type: TYPE_NORMAL
- en: '**Build a classifier**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will use a simple logistic regression model here, but the method can work
    with any model from a simple logistic regression model based on tabular data through
    to 3D ConvNets for image classification.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Note how recall for the minority class is lower than the other classes. Recall,
    otherwise known as sensitivity, is the number in a class that are correctly identified
    by the classifier.
  prefs: []
  type: TYPE_NORMAL
- en: S_i**, or the** *non-conformity score* **score**
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In conformal prediction, the non-conformity score, often denoted as *s_i*, is
    a measure of how much a new instance deviates from the existing instances in the
    training set. It‚Äôs used to determine whether a new instance belongs to a particular
    class or not.
  prefs: []
  type: TYPE_NORMAL
- en: In the context of classification, the most common non-conformity measure is
    *1 ‚Äî predicted class probability* for the given label. So, if the predicted probability
    of a new instance belonging to a certain class is high, the non-conformity score
    will be low, and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: 'For conformal prediction we obtain *s_i* scores for all classes (note: here
    we only look at the model output for the true class of an instance, even when
    there is a higher predicted probability of being another class). We then find
    a threshold of scores that contains (or *covers*) 95% of the data. The classification
    will then identify 95% of new instances (so long as our new data is similar to
    our training data).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Calculate conformal prediction threshold**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will now predict classification probabilities of the calibration set. This
    will be used to set a classification threshold for new data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '**Calculate non-conformality scores**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will calculate *s_i* scores only based on looking at probabilities associated
    with the observed class. For each instance we will get the predicted probability
    for the class of that instance. The *s_i* score (non-conformality) is *1-probability*.
    The higher the *s_i* score, the less that example conforms to that class in comparison
    to other classes. Other methods of calculating a non-conformity score are available!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '**Get 95th percentile threshold**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The threshold determines what *coverage* our classification will have. Coverage
    refers to the proportion of predictions that actually contain the true outcome.
  prefs: []
  type: TYPE_NORMAL
- en: The threshold is the percentile corresponding to *1 ‚Äî* ùõº. To get 95% coverage,
    we set an ùõº of 0.05.
  prefs: []
  type: TYPE_NORMAL
- en: When used in real life, the quantile level (based on ùõº) requires a finite sample
    correction to calculate the corresponding quantile ùëû. We multiple 0.95 by *(n+1)/n*,
    which means that ùëûùëôùëíùë£ùëíùëô would be 0.951 for n = 1000.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Show chart of s_i values, with cut-off threshold.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/83e794b29b74b30e8a4999cffa8e1377.png)'
  prefs: []
  type: TYPE_IMG
- en: s_i scores for all data. The threshold is the s_i level that contains 95% of
    all data (if ùõº is set at 0.05).
  prefs: []
  type: TYPE_NORMAL
- en: Get samples/classes from test set classified as positive
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can now find all those model outputs less than the threshold.
  prefs: []
  type: TYPE_NORMAL
- en: It is possible for an individual example to have no predicted value (an empty
    set), or more than one value, below the threshold.
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs get the classifications that are below our non-comformality threshold
    and look at the first 10 examples. Each set is a list of True/False for each possible
    class.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '**Get prediction set labels, and compare to standard classification.**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Note instance 7 is actually orange class, but has been classified by the simple
    classifier as blue. The conformal prediction classes it as a set of orange and
    blue.
  prefs: []
  type: TYPE_NORMAL
- en: '**Plot data showing instance 7 which is predicted to possibly be in 2 classes:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/3abd04aeff55e2e5748a4a17712beccc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Scatter plot showing how test instance 7 was classified as belonging to two
    possible sets: {‚Äòblue‚Äô, ‚Äòorange‚Äô},'
  prefs: []
  type: TYPE_NORMAL
- en: '**Show coverage and average set size**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Coverage* is the proportion of prediction sets that actually contain the true
    outcome.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Average set size* is the average number of predicted classes per instance.'
  prefs: []
  type: TYPE_NORMAL
- en: We will define some functions to calculate the results.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Show results for each class. The average set size is the average number of predicted
    classes per instance, for each class. Higher numbers represent more overlap between
    classification regions for the different classes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '**Show overall results**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'NOTE: Though our overall coverage is as desired, being very close to 95%, coverage
    of the different classes varies, and is lowest (83%) for our smallest class. If
    coverage of individual classes is important we can set out thresholds for classes
    independently, which is what we will now do.'
  prefs: []
  type: TYPE_NORMAL
- en: Conformal classification with equal coverage across classes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we want to be sure of coverage across all classes, we can set thresholds
    for each class independently.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: we could also do this for subgroups of data, such as ensuring equal coverage
    for a diagnostic across racial groups, if we found coverage using a shared threshold
    led to problems.'
  prefs: []
  type: TYPE_NORMAL
- en: Get thresholds for each class independently
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For each class we will find the threshold s_i score that covers 95% of insdtances
    in that particular class.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '**Apply class-specific threshold to each class classification**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will test instances for whether they are below the threshold for each class.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '**Check coverage and set size across classes**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We now have about 95% coverage across all classes. The conformal prediction
    method gives us better coverage of the minority class than the standard method
    of classification.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Conformal prediction was used to classify instances in sets rather than single
    predictions. Instances on the borders between two classes were labelled with both
    classes rather than picking the class with highest probability.
  prefs: []
  type: TYPE_NORMAL
- en: When it is important that all classes are detected with the same coverage, the
    threshold for classifying instances may be set separately (this method could also
    be used for subgroups of data, for example to guarantee the same coverage across
    different ethnic groups).
  prefs: []
  type: TYPE_NORMAL
- en: Conformal prediction does not change the model predictions. It just uses them
    in a different way to traditional classification. It may be used alongside more
    traditional methods.
  prefs: []
  type: TYPE_NORMAL
- en: (All images are by the author)
  prefs: []
  type: TYPE_NORMAL
