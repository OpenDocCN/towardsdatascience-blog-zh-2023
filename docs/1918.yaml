- en: Chain of Thought Prompting Facilitate LLMs Reasoning Abilities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/chain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938?source=collection_archive---------5-----------------------#2023-06-12](https://towardsdatascience.com/chain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938?source=collection_archive---------5-----------------------#2023-06-12)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Demonstrated with examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://sonery.medium.com/?source=post_page-----313cd7714938--------------------------------)[![Soner
    Yıldırım](../Images/c589572e9d1ee176cd4f5a0008173f1b.png)](https://sonery.medium.com/?source=post_page-----313cd7714938--------------------------------)[](https://towardsdatascience.com/?source=post_page-----313cd7714938--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----313cd7714938--------------------------------)
    [Soner Yıldırım](https://sonery.medium.com/?source=post_page-----313cd7714938--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2cf6b549448&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=post_page-2cf6b549448----313cd7714938---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----313cd7714938--------------------------------)
    ·6 min read·Jun 12, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F313cd7714938&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=-----313cd7714938---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F313cd7714938&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938&source=-----313cd7714938---------------------bookmark_footer-----------)![](../Images/002f67384a5ad5ec102fb526b86c9eea.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Juan Rumimpunu](https://unsplash.com/@earbiscuits?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/nLXOatvTaLo?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: Large language models (LLMs) are proven to be highly efficient at solving a
    variety of tasks from summarizing documents to writing code in different programming
    languages.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, they just get better with newly announced models like ChatGPT and
    GPT-4, unlocking a world of opportunities with LLM-based applications.
  prefs: []
  type: TYPE_NORMAL
- en: Contrary to their extraordinary skills, LLMs sometimes fail to demonstrate very
    simple reasoning abilities and fail to solve questions that can easily be tackled
    down by a fourth grader.
  prefs: []
  type: TYPE_NORMAL
- en: A lot of research has been done in this area aiming to understand why LLMs fail
    to perform such tasks and to make them get better.
  prefs: []
  type: TYPE_NORMAL
- en: One study that focuses on this particular issue is [chain-of-thought prompting](https://arxiv.org/abs/2201.11903),
    introduced by Google research, brain team.
  prefs: []
  type: TYPE_NORMAL
- en: Chain-of-thought prompting
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A prompting technique with a structure of {input, chain-of-thought, output},
    where chain-of-thought is a series of intermediate natural language reasoning
    steps.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The models are given a few examples with input and output (few-shot learning)
    and then asked a question that involves a multi-step or arithmetic reasoning tasks.
  prefs: []
  type: TYPE_NORMAL
