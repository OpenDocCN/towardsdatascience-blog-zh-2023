- en: Chain of Thought Prompting Facilitate LLMs Reasoning Abilities
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 思维链提示法促进 LLM 的推理能力
- en: 原文：[https://towardsdatascience.com/chain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938?source=collection_archive---------5-----------------------#2023-06-12](https://towardsdatascience.com/chain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938?source=collection_archive---------5-----------------------#2023-06-12)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/chain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938?source=collection_archive---------5-----------------------#2023-06-12](https://towardsdatascience.com/chain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938?source=collection_archive---------5-----------------------#2023-06-12)
- en: Demonstrated with examples
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过示例展示
- en: '[](https://sonery.medium.com/?source=post_page-----313cd7714938--------------------------------)[![Soner
    Yıldırım](../Images/c589572e9d1ee176cd4f5a0008173f1b.png)](https://sonery.medium.com/?source=post_page-----313cd7714938--------------------------------)[](https://towardsdatascience.com/?source=post_page-----313cd7714938--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----313cd7714938--------------------------------)
    [Soner Yıldırım](https://sonery.medium.com/?source=post_page-----313cd7714938--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://sonery.medium.com/?source=post_page-----313cd7714938--------------------------------)[![Soner
    Yıldırım](../Images/c589572e9d1ee176cd4f5a0008173f1b.png)](https://sonery.medium.com/?source=post_page-----313cd7714938--------------------------------)[](https://towardsdatascience.com/?source=post_page-----313cd7714938--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----313cd7714938--------------------------------)
    [Soner Yıldırım](https://sonery.medium.com/?source=post_page-----313cd7714938--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2cf6b549448&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=post_page-2cf6b549448----313cd7714938---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----313cd7714938--------------------------------)
    ·6 min read·Jun 12, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F313cd7714938&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=-----313cd7714938---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2cf6b549448&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=post_page-2cf6b549448----313cd7714938---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----313cd7714938--------------------------------)
    ·6 min read·2023年6月12日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F313cd7714938&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=-----313cd7714938---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F313cd7714938&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938&source=-----313cd7714938---------------------bookmark_footer-----------)![](../Images/002f67384a5ad5ec102fb526b86c9eea.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F313cd7714938&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938&source=-----313cd7714938---------------------bookmark_footer-----------)![](../Images/002f67384a5ad5ec102fb526b86c9eea.png)'
- en: Photo by [Juan Rumimpunu](https://unsplash.com/@earbiscuits?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/nLXOatvTaLo?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Juan Rumimpunu](https://unsplash.com/@earbiscuits?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    由 [Unsplash](https://unsplash.com/photos/nLXOatvTaLo?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供
- en: Large language models (LLMs) are proven to be highly efficient at solving a
    variety of tasks from summarizing documents to writing code in different programming
    languages.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）已被证明在解决各种任务方面非常高效，从总结文档到用不同编程语言编写代码。
- en: Moreover, they just get better with newly announced models like ChatGPT and
    GPT-4, unlocking a world of opportunities with LLM-based applications.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，随着新发布的模型如 ChatGPT 和 GPT-4，它们的表现只会变得更好，为基于 LLM 的应用打开了无限的可能性。
- en: Contrary to their extraordinary skills, LLMs sometimes fail to demonstrate very
    simple reasoning abilities and fail to solve questions that can easily be tackled
    down by a fourth grader.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管具有非凡的技能，LLM有时仍未能展现非常简单的推理能力，无法解决那些四年级学生也能轻松应对的问题。
- en: A lot of research has been done in this area aiming to understand why LLMs fail
    to perform such tasks and to make them get better.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 许多研究已经在这一领域开展，旨在理解为何LLM在执行此类任务时会失败，并使其表现更好。
- en: One study that focuses on this particular issue is [chain-of-thought prompting](https://arxiv.org/abs/2201.11903),
    introduced by Google research, brain team.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 针对这一特定问题的研究之一是[连锁思维提示](https://arxiv.org/abs/2201.11903)，由Google研究团队引入。
- en: Chain-of-thought prompting
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 连锁思维提示
- en: ''
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A prompting technique with a structure of {input, chain-of-thought, output},
    where chain-of-thought is a series of intermediate natural language reasoning
    steps.
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一种提示技术，其结构为{输入，连锁思维，输出}，其中连锁思维是一系列中间自然语言推理步骤。
- en: The models are given a few examples with input and output (few-shot learning)
    and then asked a question that involves a multi-step or arithmetic reasoning tasks.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 模型会被提供几个带有输入和输出的示例（少量学习），然后提出一个涉及多步骤或算术推理任务的问题。
