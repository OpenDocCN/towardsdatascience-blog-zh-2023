- en: Voice Assistant Accessibility
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/voice-assistant-accessibility-dc737cde0394?source=collection_archive---------12-----------------------#2023-03-31](https://towardsdatascience.com/voice-assistant-accessibility-dc737cde0394?source=collection_archive---------12-----------------------#2023-03-31)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Ensuring that everyone is understood
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://addlesee.medium.com/?source=post_page-----dc737cde0394--------------------------------)[![Angus
    Addlesee](../Images/0a6a016590ca622cc3c8cae24e188f6e.png)](https://addlesee.medium.com/?source=post_page-----dc737cde0394--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dc737cde0394--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dc737cde0394--------------------------------)
    [Angus Addlesee](https://addlesee.medium.com/?source=post_page-----dc737cde0394--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7f06284203ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvoice-assistant-accessibility-dc737cde0394&user=Angus+Addlesee&userId=7f06284203ea&source=post_page-7f06284203ea----dc737cde0394---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----dc737cde0394--------------------------------)
    ·10 min read·Mar 31, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdc737cde0394&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvoice-assistant-accessibility-dc737cde0394&user=Angus+Addlesee&userId=7f06284203ea&source=-----dc737cde0394---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc737cde0394&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvoice-assistant-accessibility-dc737cde0394&source=-----dc737cde0394---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: I have been working on conversational AI with large language models (like GPT-4)
    for many years. The recent huge burst in popularity due to chatGPT is very exciting,
    but how can they be improved? There are many answers to that question of course,
    but in this article I will focus on accessibility.
  prefs: []
  type: TYPE_NORMAL
- en: How do we tweak our future machine learning models make use of limited datasets?
    And how should we design our agents to ensure that everyone can make use of advancements
    in voice artificial intelligence?
  prefs: []
  type: TYPE_NORMAL
- en: '*This is an abridgement of* [*my*](http://addlesee.co.uk/) *paper published
    at* [*IWSDS 2023*](https://sites.google.com/view/iwsds2023/home)*. If you would
    like to cite anything discussed in this article, please cite the paper titled
    “*[*Voice Assistant Accessibility*](https://drive.google.com/file/d/1gANMtWuP1w0gba7g4nv-ehCMax25itaZ/view)*”:*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Over one billion people in the world are living with some form of disability,
    and voice assistants have the potential to improve people’s lives. For example,
    while I was visiting a respite care home called [Leuchie House](https://www.leuchiehouse.org.uk/),
    one resident with Multiple Sclerosis (MS) explained how the disease’s progression
    slowly eroded away their independence. An Amazon Alexa device enabled this person
    to turn off their bedroom light without asking for a carer’s help. They told us
    that this was the first time they had regained some personal independence since
    diagnosis.
  prefs: []
  type: TYPE_NORMAL
- en: '*Stories like the one above motivate charities to promote the use of voice
    assistants as they can have* real positive impact*.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/1a99404d542c0f20ec335e86d1ba2260.png)'
  prefs: []
  type: TYPE_IMG
- en: I (on the right) visited [Leuchie House](https://www.leuchiehouse.org.uk/) with
    colleagues in September 2021
  prefs: []
  type: TYPE_NORMAL
- en: The creators of voice assistants are getting HIPAA compliance for further application
    in the healthcare domain, and features are released *specifically targeting vulnerable
    user groups*. We similarly see early-stage researchers collaborating with other
    disciplines to apply their work to more specific healthcare applications (see
    my [TDS article on voice research trends](/the-future-of-voice-assistants-what-are-the-early-research-trends-dc02215fe2aa)).
  prefs: []
  type: TYPE_NORMAL
- en: Voice assistant accessibility is therefore critical to ensure future systems
    are designed with the end user’s interaction patterns and needs in mind. Today’s
    voice assistants are trained and evaluated on huge datasets that represent the
    ‘average’ user, yet we know that [speech changes as cognition declines](http://www.lrec-conf.org/proceedings/lrec2020/workshops/LEGAL2020/pdf/2020.legal2020-1.4.pdf).
    Existing commercial systems to assist people with visual impairments have [huge
    privacy concerns](https://heartbeat.comet.ml/am-i-allergic-to-this-developing-a-voice-assistant-for-sight-impaired-people-3f036fe7792b),
    and people would need to openly announce disabilities when interacting with voice
    assistants in public spaces (discussed below).
  prefs: []
  type: TYPE_NORMAL
- en: As both research and industry push the hugely beneficial use of voice assistants
    beyond mass-market application - new challenges and ethical concerns arise that
    must be highlighted. In this article, I discuss the state-of-the-art research
    and currently available commercial systems for many user groups, e.g. people with
    dementia, motor neurone disease, sight loss, mental health conditions, and more.
  prefs: []
  type: TYPE_NORMAL
- en: '*I first discuss designing voice assistants for people with cognitive impairments
    and mental health conditions, then designing systems for people with physical
    impairments, thirdly I discuss voice privacy in public environments, and I finally
    conclude with a summary.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Dialogue Systems for People with Cognitive Impairments and Mental Health Conditions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cognitive impairments impact memory, attention, problem-solving skills, decision-making,
    *speech production*, and more. The onset and progression of cognitive impairments
    typically correlate with a person’s age, but certain conditions (e.g., early-onset
    dementia) can be caused by strokes or head trauma. Mild cognitive impairment (MCI)
    shares the above symptoms but does not substantially interfere with the person’s
    life. While people with MCI are also usually older adults, another subset of brain
    health impacts people of all ages - mental health conditions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/66e9b7269c1ca1ae5a162ae7b9d7dc00.png)'
  prefs: []
  type: TYPE_IMG
- en: The ARI robot (by [PAL Robotics](https://pal-robotics.com/)) used in the SPRING
    Project mentioned below ([source](https://spring-h2020.eu/news/with-spring-pal-robotics-is-developing-robots-that-could-help-tackle-the-covid-19-pandemic/))
  prefs: []
  type: TYPE_NORMAL
- en: Dementia and MCI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'People pause mid-sentence more frequently and for longer durations as cognition
    declines. Other speech production changes also occur including: increased repetition,
    slowed speech rate, increased number of prepositions, [and more](https://heartbeat.comet.ml/how-dementia-effects-conversation-f538d2d9507a).
    Today’s voice assistants mistake these long pauses for the end of the user’s turn,
    requiring the user to frustratingly repeat their entire utterance again.'
  prefs: []
  type: TYPE_NORMAL
- en: People with dementia and MCI are recommended standard voice assistants (like
    Google Home and Amazon Alexa) for their daily use. Companies like [CogniHealth](https://www.cognihealth.uk/)
    work to curate content to help people with dementia and their families - providing
    valuable information, advice, and support through voice assistants - but the speech
    processing and understanding components of these systems do not have accessibility
    options for the specific challenges described above.
  prefs: []
  type: TYPE_NORMAL
- en: 'Research in this area is stifled due to the lack of data. Collecting natural
    spoken dialogue data with vulnerable older adults is [ethically challenging](/ethically-collecting-conversations-with-people-that-have-cognitive-impairments-9ad0d2714bdd),
    especially over the past few years due to COVID, and requires [bespoke tools](https://aclanthology.org/2022.nlp4pi-1.3/)
    for data security. Research like the [EU’s H2020 SPRING Project](https://spring-h2020.eu/)
    are collecting data to tackle these challenges in a hospital memory-clinic waiting
    room. In this setting, a patient with dementia or MCI will likely be accompanied
    by a family member or carer, introducing further multi-party complications (spoiler:
    the topic of my next article). Once collected, a sub-repository of [TalkBank](https://www.talkbank.org/)
    called [DementiaBank](https://dementia.talkbank.org/) can be used to share data
    with other researchers studying communication in dementia.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mental Health Conditions**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Certain mental health conditions also impact people’s speech production and
    behavior. People with anxiety speak at a faster rate and pause for shorter durations
    than healthy controls, whereas people with depression or PTSD speak more slowly
    and are more silent.
  prefs: []
  type: TYPE_NORMAL
- en: There do not appear to be commercial voice assistants that adapt their speech
    processing to better understand people with mental health conditions - although
    companies do exist targeting these user groups. Voice assistant apps like [UB-OK](https://www.ubok.app/)
    and [Kindspace](https://createyourkindspace.com/) provide a safe space for people
    to share their worries without judgment. People, particularly young adults, can
    ask about mental health and other concerns that they may not want to ask friends,
    teachers, or family.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6bc7b7d5d351be2bc800bed4f1d950b6.png)'
  prefs: []
  type: TYPE_IMG
- en: Michael McTernan presenting UBOK at the Scottish Edge Awards 2019
  prefs: []
  type: TYPE_NORMAL
- en: Human-Robot Interaction (HRI) research is abundant in this area. The system’s
    speech processing again remains standard, but the robot’s interactions are modified.
    For example, communication techniques can be leveraged from psychology to encourage
    self-reflection and help with loneliness (common comorbidity with depression).
  prefs: []
  type: TYPE_NORMAL
- en: There really is a wide range of applications. Minimally verbal children with
    autism were given speech-generation devices that encouraged them to spontaneously
    talk and use novel vocabulary after long-term use. Similar work effectively used
    interactive social robots for autism therapy.
  prefs: []
  type: TYPE_NORMAL
- en: '*All of the above is exciting, but critically, no research focused on improving
    the system’s* speech processing and understanding*.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Designing Dialogue Systems for People with **Physical Impairments**
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Physical impairments impact what a user may ask a voice assistant and how they
    can take action when given a response. For example, people affected by sight loss
    will [ask about their visual surroundings](https://heartbeat.comet.ml/the-spoon-is-in-the-sink-assisting-visually-impaired-people-in-the-kitchen-ccea20b098cd),
    and people with hearing difficulties will expect a multimodal response.
  prefs: []
  type: TYPE_NORMAL
- en: '**Visual Impairment**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Blind and partially sighted people often suffer from seemingly unrelated health
    conditions like malnutrition. This is sadly due to difficulties completing everyday
    tasks like shopping, preparing food, and cooking. A panel of visually impaired
    computer scientists [talked](https://www.youtube.com/watch?v=f613diLbVAc) at the
    Computer Vision and Pattern Recognition Conference (CVPR 2020) - detailing how
    difficult it is to navigate a train station when you cannot see the timetables,
    platform numbers, carriage letters, or direction signs.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f6617bf71164482b3e9c635cc797c479.png)'
  prefs: []
  type: TYPE_IMG
- en: Similar to a train station, people will ask questions about textual information
    on food packaging. This image is from an article on this exact problem in the
    kitchen ([here](https://heartbeat.comet.ml/am-i-allergic-to-this-developing-a-voice-assistant-for-sight-impaired-people-3f036fe7792b)).
  prefs: []
  type: TYPE_NORMAL
- en: Human-in-the-loop solutions are available, where you can connect with a sighted
    person to answer a question. A photo or video must be sent along with the question
    to relay the visual scene. [BeMyEyes](https://bemyeyes.com/) and [BeSpecular](https://bespecular.com/)
    rely on sighted volunteers to answer questions in a timely manner, whereas [Aira](https://aira.io/)
    has a trained team of professional agents.
  prefs: []
  type: TYPE_NORMAL
- en: '*One clear issue emerges when relying on volunteers: visually impaired people
    do not know if sensitive information can be seen in the sent images. Volunteers
    could therefore see mail with names, addresses, ID numbers, or valuables in the
    individuals home. Aira mitigates this by hiring and training staff with a focus
    on safety and security - but this comes at a price.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: End-to-end (E2E) systems also exist like [TapTapSee](https://taptapseeapp.com/)
    and [Microsoft Seeing AI](https://microsoft.com/ai/seeing-ai). These systems run
    securely on the cloud with encryption, so privacy concerns are minimal, but they
    introduce a new concern - accuracy. A visually impaired person can not verify
    that the system’s answer is in fact correct. With no ability to have a dialogue,
    user’s have to resort to trusting the system’s answer. This can lead to dilemmas
    like asking questions about medication. The E2E system could be incorrect, potentially
    harming the user, but the human-in-the-loop system requires them to send medication
    pictures to an unknown volunteer.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/021fae2a79826c457abdecf7aa61c6ea.png)'
  prefs: []
  type: TYPE_IMG
- en: This image shows an example from some work attempting to answer clarification
    questions from people with sight impairments. The goal is to let users know when
    the system is unsure ([here](https://heartbeat.comet.ml/the-spoon-is-in-the-sink-assisting-visually-impaired-people-in-the-kitchen-ccea20b098cd)).
  prefs: []
  type: TYPE_NORMAL
- en: '**Limited Mobility**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Household open-domain voice assistants are very convenient: we can set timers
    while our hands are oily from cooking, or turn up our music from the comfort of
    a warm blanket on the couch.'
  prefs: []
  type: TYPE_NORMAL
- en: '*These functions are not just convenient for people living with limited mobility,
    they are critical for mental wellness. People with limited mobility in their hand,
    arms, or legs can retain some personal independence through their voice.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Mobility loss itself does not commonly impact speech production, but voice assistants
    can still be accessibly designed. The hardware exists (like advanced wheelchairs)
    to increase a person’s comfort and ability to complete daily tasks, but these
    technologies are not currently integrated with existing voice assistants. While
    visiting a respite care home called [Leuchie House](https://www.leuchiehouse.org.uk/),
    a resident described their frustration when a voice assistant could open their
    curtains and turn off the TV, but they had to ask a carer to adjust their electric
    wheelchair’s headrest. This highlights the need for inclusive design.
  prefs: []
  type: TYPE_NORMAL
- en: '**Hearing Impairments**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: People living with hearing difficulties get frustrated with voice assistants,
    causing them to abandon their use altogether. This is even more difficult for
    those who developed hearing issues at a young age, as this often leads to speech
    impairments. For example, pronunciations are impossible to learn if you cannot
    hear a conversation. The impact of speech impairments is discussed below, but
    even without them - available voice assistants appear limited. Research notes
    that people with partial hearing loss really struggle to follow a conversation
    in a noisy environment (like a public space), but they felt more included in a
    conversation when a screen with a live-transcription of the ongoing conversation
    was set up. [Real-time speaker identification](https://aclanthology.org/2020.coling-main.312.pdf)
    would be even more effective. We should therefore ensure that voice assistants
    and social robots include a screen to enable this feature in public multi-party
    settings.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5b10f22394bcaace824072dc6d41ff08.png)'
  prefs: []
  type: TYPE_IMG
- en: Honda’s Asimo robot saying “I love you” in ASL ([source](https://unsplash.com/photos/g29arbbvPjo))
  prefs: []
  type: TYPE_NORMAL
- en: Many people with hearing impairments know one of around 200 signed languages.
    Research has shown that assistants can learn sign language, but an increased effort
    from the NLP community could utilise existing resources to improve sign language
    processing and generation. People with hearing impairments are keen to engage
    with the inclusive design of voice assistants to ensure accessibility progress.
  prefs: []
  type: TYPE_NORMAL
- en: '**Speech Diversity**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Speech production is nuanced and unique to every individual, but automatic speech
    recognition (ASR) learns general speech patterns and therefore struggles to understand
    non-native speakers or people with thick accents (like in Scotland). This problem
    extends further, however. People with stammers are misunderstood, people who struggle
    with pronunciation (e.g. caused by hearing loss at an early-age) are misunderstood,
    and people with Tourettes are excluded from dialogue research. Non-standard speech
    can also be caused by conditions that affect the muscles we use to produce speech,
    like muscular dystrophy.
  prefs: []
  type: TYPE_NORMAL
- en: Google is innovating on this front with three projects. [Project Euphonia](https://sites.research.google/euphonia/about/)
    and [Project Relate](https://sites.research.google/relate/) are Google’s initiatives
    to help people with non-standard speech be better understood, and [Project Understood](https://projectunderstood.ca/)
    is their program to better understand people with Down Syndrome. Google has even
    opened [The Accessibility Discovery Centre](https://blog.google/around-the-globe/google-europe/united-kingdom/the-accessibility-discovery-centre-is-open-for-collaboration/)
    to collaborate with academics, communities, and charitable/non-profit organisations
    to “remove barriers to accessibility”.
  prefs: []
  type: TYPE_NORMAL
- en: Project Relate
  prefs: []
  type: TYPE_NORMAL
- en: '**Loss of Speech**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: People with certain conditions like motor neurone disease (MND) slowly lose
    the ability to speak entirely. Stephen Hawking famously had a synthetic voice
    due to MND, but today they have improved hugely in terms of quality and diversity.
    Companies like [Cereproc](https://www.cereproc.com/) synthesise characterful,
    engaging, and emotional voices with varying accents to help people with MND choose
    a voice to best represent themselves.
  prefs: []
  type: TYPE_NORMAL
- en: Voice cloning is also possible, opening up the use of voice banking technology
    to people at risk of losing their voice. People capture hours of their speech
    to enable cloning at a later date if needed. One of these companies, [SpeakUnique](https://www.speakunique.co.uk/),
    can even reconstruct a person’s original voice if it has partially deteriorated
    since diagnosis.
  prefs: []
  type: TYPE_NORMAL
- en: '**Privacy**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Personal voice assistants are often only used by an individual user in a private
    space. The voice assistant can therefore be highly customised to that user’s needs.
    However, this is not the case for assistants in public spaces. Social robots in
    museums, hospitals, airports, etc… will be used by many people in a day. Some
    accessible design implementations benefit everyone (we all forget words mid-sentence
    sometimes for example), but others would not.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/df691042c1a010c5ceb507c1a4fc1364.png)'
  prefs: []
  type: TYPE_IMG
- en: A Pepper robot in a shopping centre ([source](https://unsplash.com/photos/hND1OG3q67k)).
    People would likely feel uncomfortable disclosing personal accessibility needs
    in a public space with other people around.
  prefs: []
  type: TYPE_NORMAL
- en: '*Most disabilities are invisible, so people would have to describe their disabilities
    aloud in a public space to activate certain accessibility features. This is similarly
    problematic without a voice assistant - disabled people often need to announce
    their disabilities and assistance needs in a shop.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Technologies like [Neatebox](https://neatebox.com/) are rising in popularity
    to tackle this issue. Disabled users get the app and note how they would personally
    like to be assisted (e.g. being led by arm). Then, when they enter the shop or
    airport premises, the customer service team are notified and personalised assistance
    is subtly provided. A similar technology could be used with social robots in public
    spaces to activate features when interacting with someone that requires an accessible
    voice assistant.
  prefs: []
  type: TYPE_NORMAL
- en: '**Conclusion**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Voice assistants can improve people’s lives beyond simple convenience, and this
    can be achieved through ethical data collection and inclusive design. It is not
    simple, however, every system component in a voice assistant must be considered
    when designing systems for **everyone**.
  prefs: []
  type: TYPE_NORMAL
- en: 'I have summarised which specific components must be tweaked in order to make
    voice assistants more accessible for the user groups discussed in this article:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/68b1833fbcaee048963e81788ba4705f.png)'
  prefs: []
  type: TYPE_IMG
- en: Table 1 in the [paper](https://drive.google.com/file/d/1gANMtWuP1w0gba7g4nv-ehCMax25itaZ/view)
  prefs: []
  type: TYPE_NORMAL
- en: You can reach [me](http://addlesee.co.uk/) on [Medium](https://medium.com/@addlesee),
    on [Twitter](https://twitter.com/Addlesee_AI), or on [LinkedIn](https://www.linkedin.com/in/angusaddlesee/).
  prefs: []
  type: TYPE_NORMAL
