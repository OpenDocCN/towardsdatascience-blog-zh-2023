["```py\nimport langdetect\nfrom deep_translator import GoogleTranslator\n\ndef get_language(text):\n    try:\n        return langdetect.detect(text)\n    except KeyboardInterrupt as e:\n        raise(e)\n    except:\n        return '<-- ERROR -->'\n\ndef get_translation(text):\n    try:\n        return GoogleTranslator(source='auto', target='en')\\\n          .translate(str(text))\n    except KeyboardInterrupt as e:\n        raise(e)\n    except:\n        return '<-- ERROR -->'\n\ndf['language'] = df.review.map(get_language)\ndf['reviews_transl'] = df.review.map(get_translation)\n```", "```py\ndf.reviews_transl.map(lambda x: x.lower().strip()).value_counts().head(10)\n\nreviews\nnone                          74\n<-- error -->                 37\ngreat hotel                   12\nperfect                        8\nexcellent value for money      7\ngood value for money           7\nvery good hotel                6\nexcellent hotel                6\ngreat location                 6\nvery nice hotel                5\n```", "```py\nfrom bertopic import BERTopic\ndocs = list(df.reviews.values)\ntopic_model = BERTopic()\ntopics, probs = topic_model.fit_transform(docs)\n```", "```py\ntopic_model.get_topic_info().head(7).set_index('Topic')[\n   ['Count', 'Name', 'Representation']]\n```", "```py\ntopic_model.visualize_barchart(top_n_topics = 16, n_words = 10)\n```", "```py\ntopics_per_class = topic_model.topics_per_class(docs, \n    classes=filt_df.hotel)\n\ntopic_model.visualize_topics_per_class(topics_per_class, \n    top_n_topics=10, normalize_frequency = True)\n```", "```py\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom bertopic.representation import KeyBERTInspired, PartOfSpeech, MaximalMarginalRelevance\n\nmain_representation_model = KeyBERTInspired()\naspect_representation_model1 = PartOfSpeech(\"en_core_web_sm\")\naspect_representation_model2 = [KeyBERTInspired(top_n_words=30), \n                                MaximalMarginalRelevance(diversity=.5)]\n\nrepresentation_model = {\n   \"Main\": main_representation_model,\n   \"Aspect1\":  aspect_representation_model1,\n   \"Aspect2\":  aspect_representation_model2 \n}\n\nvectorizer_model = CountVectorizer(min_df=5, stop_words = 'english')\ntopic_model = BERTopic(nr_topics = 'auto', \n                      vectorizer_model = vectorizer_model,\n                      representation_model = representation_model)\n\ntopics, ini_probs = topic_model.fit_transform(docs)\n```", "```py\ndef get_topic_stats(topic_model, extra_cols = []):\n    topics_info_df = topic_model.get_topic_info().sort_values('Count', ascending = False)\n    topics_info_df['Share'] = 100.*topics_info_df['Count']/topics_info_df['Count'].sum()\n    topics_info_df['CumulativeShare'] = 100.*topics_info_df['Count'].cumsum()/topics_info_df['Count'].sum()\n    return topics_info_df[['Topic', 'Count', 'Share', 'CumulativeShare', \n                           'Name', 'Representation'] + extra_cols]\n\nget_topic_stats(topic_model, ['Aspect1', 'Aspect2']).head(10)\\\n    .set_index('Topic')\n```", "```py\ntopic_model.visualize_topics()\n```", "```py\ntopic_model.visualize_heatmap(n_clusters = 20)\n```", "```py\nfrom sklearn.metrics.pairwise import cosine_similarity\ndistance_matrix = cosine_similarity(np.array(topic_model.topic_embeddings_))\ndist_df = pd.DataFrame(distance_matrix, columns=topic_model.topic_labels_.values(), \n                       index=topic_model.topic_labels_.values())\n\ntmp = []\nfor rec in dist_df.reset_index().to_dict('records'):\n    t1 = rec['index']\n    for t2 in rec:\n        if t2 == 'index': \n            continue\n        tmp.append(\n            {\n                'topic1': t1, \n                'topic2': t2, \n                'distance': rec[t2]\n            }\n        )\n\npair_dist_df = pd.DataFrame(tmp)\n\npair_dist_df = pair_dist_df[(pair_dist_df.topic1.map(\n      lambda x: not x.startswith('-1'))) & \n            (pair_dist_df.topic2.map(lambda x: not x.startswith('-1')))]\npair_dist_df = pair_dist_df[pair_dist_df.topic1 < pair_dist_df.topic2]\npair_dist_df.sort_values('distance', ascending = False).head(20)\n```", "```py\ntopic_model.merge_topics(docs, [[26, 74], [43, 68, 62], [16, 50, 91]])\ndf['merged_topic'] = topic_model.topics_\n```", "```py\ntopic_distr, topic_token_distr = topic_model.approximate_distribution(\n      docs, window = 4, calculate_tokens=True)\n```", "```py\ntopic_model.visualize_distribution(topic_distr[doc_id], min_probability=0.05)\n```", "```py\nvis_df = topic_model.visualize_approximate_distribution(docs[doc_id], \n  topic_token_distr[doc_id])\nvis_df\n```", "```py\ntmp_dfs = []\n\n# iterating through different threshold levels\nfor thr in tqdm.tqdm(np.arange(0, 0.35, 0.001)):\n    # calculating number of topics with probability > threshold for each document\n    tmp_df = pd.DataFrame(list(map(lambda x: len(list(filter(lambda y: y >= thr, x))), topic_distr))).rename(\n        columns = {0: 'num_topics'}\n    )\n    tmp_df['num_docs'] = 1\n\n    tmp_df['num_topics_group'] = tmp_df['num_topics']\\\n        .map(lambda x: str(x) if x < 5 else '5+')\n\n    # aggregating stats\n    tmp_df_aggr = tmp_df.groupby('num_topics_group', as_index = False).num_docs.sum()\n    tmp_df_aggr['threshold'] = thr\n\n    tmp_dfs.append(tmp_df_aggr)\n\nnum_topics_stats_df = pd.concat(tmp_dfs).pivot(index = 'threshold', \n                              values = 'num_docs',\n                              columns = 'num_topics_group').fillna(0)\n\nnum_topics_stats_df = num_topics_stats_df.apply(lambda x: 100.*x/num_topics_stats_df.sum(axis = 1))\n\n# visualisation\ncolormap = px.colors.sequential.YlGnBu\npx.area(num_topics_stats_df, \n       title = 'Distribution of number of topics',\n       labels = {'num_topics_group': 'number of topics',\n                'value': 'share of reviews, %'},\n       color_discrete_map = {\n          '0': colormap[0],\n          '1': colormap[3],\n          '2': colormap[4],\n          '3': colormap[5],\n          '4': colormap[6],\n          '5+': colormap[7]\n      })\n```", "```py\nthreshold = 0.13\n\n# define topic with probability > 0.13 for each document\ndf['multiple_topics'] = list(map(\n    lambda doc_topic_distr: list(map(\n        lambda y: y[0], filter(lambda x: x[1] >= threshold, \n                               (enumerate(doc_topic_distr)))\n    )), topic_distr\n))\n\n# creating a dataset with docid, topic\ntmp_data = []\n\nfor rec in df.to_dict('records'):\n    if len(rec['multiple_topics']) != 0:\n        mult_topics = rec['multiple_topics']\n    else:\n        mult_topics = [-1]\n\n    for topic in mult_topics: \n        tmp_data.append(\n            {\n                'topic': topic,\n                'id': rec['id'],\n                'course_id': rec['course_id'],\n                'reviews_transl': rec['reviews_transl']\n            }\n        )\n\nmult_topics_df = pd.DataFrame(tmp_data)\n```", "```py\ntmp_data = []\nfor hotel in mult_topics_df.hotel.unique():\n    for topic in mult_topics_df.topic.unique():\n        tmp_data.append({\n            'hotel': hotel,\n            'topic_id': topic,\n            'total_hotel_reviews': mult_topics_df[mult_topics_df.hotel == hotel].id.nunique(),\n            'topic_hotel_reviews': mult_topics_df[(mult_topics_df.hotel == hotel) \n                                                  & (mult_topics_df.topic == topic)].id.nunique(),\n            'other_hotels_reviews': mult_topics_df[mult_topics_df.hotel != hotel].id.nunique(),\n            'topic_other_hotels_reviews': mult_topics_df[(mult_topics_df.hotel != hotel) \n                                                  & (mult_topics_df.topic == topic)].id.nunique()\n        })\n\nmult_topics_stats_df = pd.DataFrame(tmp_data)\nmult_topics_stats_df['topic_hotel_share'] = 100*mult_topics_stats_df.topic_hotel_reviews/mult_topics_stats_df.total_hotel_reviews\nmult_topics_stats_df['topic_other_hotels_share'] = 100*mult_topics_stats_df.topic_other_hotels_reviews/mult_topics_stats_df.other_hotels_reviews\n```", "```py\nfrom statsmodels.stats.proportion import proportions_ztest\n\nmult_topics_stats_df['difference_pval'] = list(map(\n    lambda x1, x2, n1, n2: proportions_ztest(\n        count = [x1, x2],\n        nobs = [n1, n2],\n        alternative = 'two-sided'\n    )[1],\n    mult_topics_stats_df.topic_other_hotels_reviews,\n    mult_topics_stats_df.topic_hotel_reviews,\n    mult_topics_stats_df.other_hotels_reviews,\n    mult_topics_stats_df.total_hotel_reviews\n))\n\nmult_topics_stats_df['sign_difference'] = mult_topics_stats_df.difference_pval.map(\n    lambda x: 1 if x <= 0.05 else 0\n)\n\ndef get_significance(d, sign):\n    sign_percent = 1\n    if sign == 0:\n        return 'no diff'\n    if (d >= -sign_percent) and (d <= sign_percent):\n        return 'no diff'\n    if d < -sign_percent:\n        return 'lower'\n    if d > sign_percent:\n        return 'higher'\n\nmult_topics_stats_df['diff_significance_total'] = list(map(\n    get_significance,\n    mult_topics_stats_df.topic_hotel_share - mult_topics_stats_df.topic_other_hotels_share,\n    mult_topics_stats_df.sign_difference\n))\n```", "```py\nimport plotly\n\n# define color depending on difference significance\ndef get_color_sign(rel):\n    if rel == 'no diff':\n        return plotly.colors.qualitative.Set2[7]\n    if rel == 'lower':\n        return plotly.colors.qualitative.Set2[1]\n    if rel == 'higher':\n        return plotly.colors.qualitative.Set2[0]\n\n# return topic representation in a suitable for graph title format\ndef get_topic_representation_title(topic_model, topic):\n    data = topic_model.get_topic(topic)\n    data = list(map(lambda x: x[0], data))\n\n    return ', '.join(data[:5]) + ', <br>         ' + ', '.join(data[5:])\n\ndef get_graphs_for_topic(t):\n    topic_stats_df = mult_topics_stats_df[mult_topics_stats_df.topic_id == t]\\\n        .sort_values('total_hotel_reviews', ascending = False).set_index('hotel')\n\n    colors = list(map(\n        get_color_sign,\n        topic_stats_df.diff_significance_total\n    ))\n\n    fig = px.bar(topic_stats_df.reset_index(), x = 'hotel', y = 'topic_hotel_share',\n                title = 'Topic: %s' % get_topic_representation_title(topic_model, \n                                                            topic_stats_df.topic_id.min()),\n                text_auto = '.1f',\n                labels = {'topic_hotel_share': 'share of reviews, %'},\n                hover_data=['topic_id'])\n    fig.update_layout(showlegend = False)\n    fig.update_traces(marker_color=colors, marker_line_color=colors,\n                  marker_line_width=1.5, opacity=0.9)\n\n    topic_total_share = 100.*((topic_stats_df.topic_hotel_reviews + topic_stats_df.topic_other_hotels_reviews)\\\n        /(topic_stats_df.total_hotel_reviews + topic_stats_df.other_hotels_reviews)).min()\n    print(topic_total_share)\n\n    fig.add_shape(type=\"line\",\n        xref=\"paper\",\n        x0=0, y0=topic_total_share,\n        x1=1, y1=topic_total_share,\n        line=dict(\n            color=colormap[8],\n            width=3, dash=\"dot\"\n        )\n    )\n\n    fig.show()\n```", "```py\ntop_mult_topics_df = mult_topics_df.groupby('topic', as_index = False).id.nunique()\ntop_mult_topics_df['share'] = 100.*top_mult_topics_df.id/top_mult_topics_df.id.sum()\ntop_mult_topics_df['topic_repr'] = top_mult_topics_df.topic.map(\n    lambda x: get_topic_representation(topic_model, x)\n)\n\nfor t in top_mult_topics_df.head(32).topic.values:\n    get_graphs_for_topic(t)\n```"]