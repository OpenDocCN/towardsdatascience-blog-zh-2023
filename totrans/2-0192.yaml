- en: A fAIry tale of the Inductive Bias
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/a-fairy-tale-of-the-inductive-bias-d418fc61726c](https://towardsdatascience.com/a-fairy-tale-of-the-inductive-bias-d418fc61726c)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '|INDUCTIVE BIAS| TRANSFORMERS| COMPUTER VISION|'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Do we need inductive bias? How simple models can reach the performance of complex
    models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://salvatore-raieli.medium.com/?source=post_page-----d418fc61726c--------------------------------)[![Salvatore
    Raieli](../Images/6bb4520e2df40d20283e7283141b5e06.png)](https://salvatore-raieli.medium.com/?source=post_page-----d418fc61726c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d418fc61726c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d418fc61726c--------------------------------)
    [Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page-----d418fc61726c--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d418fc61726c--------------------------------)
    ·18 min read·Jul 10, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/278a752aca7a7bf5da388e32bb3ac8a8.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Natalia Y.](https://unsplash.com/@foxfox?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: As we have seen in recent years deep learning has had exponential growth both
    in use and in the number of models. What paved the way for this success is perhaps
    the [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning) itself-the
    idea that a model could be trained with a large amount of data and then used for
    a myriad of specific tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'In recent years, a paradigm has emerged: [transformer](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model))
    (or otherwise based on this model) is used for NLP applications. While for images,
    [vision transformers](https://en.wikipedia.org/wiki/Vision_transformer) or [convolutional
    networks](https://en.wikipedia.org/wiki/Convolutional_neural_network) are used
    instead.'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/the-infinite-babel-library-of-llms-90e203b2f6b0?source=post_page-----d418fc61726c--------------------------------)
    [## The Infinite Babel Library of LLMs'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open-source, data, and attention: How the future of LLMs will change'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'towardsdatascience.com](/the-infinite-babel-library-of-llms-90e203b2f6b0?source=post_page-----d418fc61726c--------------------------------)
    [](/metas-hiera-reduce-complexity-to-increase-accuracy-30f7a147ad0b?source=post_page-----d418fc61726c--------------------------------)
    [## META’s Hiera: reduce complexity to increase accuracy'
  prefs: []
  type: TYPE_NORMAL
- en: Simplicity allows AI to reach incredible performance and surprising speed
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/metas-hiera-reduce-complexity-to-increase-accuracy-30f7a147ad0b?source=post_page-----d418fc61726c--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, while we have plenty of work showing in practice that these
    models work well, the theoretical understanding of why has lagged behind. This
    is because these models are very broad and it comes difficult to experiment. The
    fact that [Vision Transformers](https://en.wikipedia.org/wiki/Vision_transformer)
    outperform convolutional neural networks [by having a theoretically less inductive
    bias for vision](/metas-hiera-reduce-complexity-to-increase-accuracy-30f7a147ad0b)
    shows that there is a theoretical gap to be filled.
  prefs: []
  type: TYPE_NORMAL
- en: 'This article focuses on:'
  prefs: []
  type: TYPE_NORMAL
- en: What exactly is inductive bias? Why this is important and what inductive bias
    do our favorite models have?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The inductive bias of transformers and CNNs. What are the differences between
    these two models and why these discussions are important?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can we study inductive bias? How to be able to leverage the similarity between
    different models in order to capture their differences.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can a model with weak inductive bias succeed in the same in computer vision?
    a field where inductive bias is traditionally believed to be important instead.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is inductive bias?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/7330727da0ff61425df2b2883b29de9e.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Raphael Schaller](https://unsplash.com/@raphaelphotoch?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Learning is the process of apprehending useful knowledge by observing and interacting
    with the world. It involves searching a space of solutions for one expected to
    provide a better explanation of the data or to achieve higher rewards. But in
    many cases, there are multiple solutions which are equally good. ([source](https://en.wikipedia.org/wiki/Fact,_Fiction,_and_Forecast))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Imagine encountering a swan in a lake. From this simple swan, we might assume
    that all swans are white (until we see a [black swan](https://en.wikipedia.org/wiki/Black_swan_theory)),
    that they are waterfowl, that they feed on fish, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: This process is called [inductive reasoning](https://en.wikipedia.org/wiki/Inductive_reasoning).
    From a simple observation, we may be able to derive thousands (if not billions)
    of hypotheses, and clearly, not all of them are true. In fact, we might think
    that the swan is incapable of flight since we only observe it swimming at that
    time.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, it is difficult to be able to decide which hypothesis is correct
    without direct observations. So according to [Occam’s principle](https://en.wikipedia.org/wiki/Occam%27s_razor),
    we could state “Swans can swim in lakes.”
  prefs: []
  type: TYPE_NORMAL
- en: Why is this important for machine learning?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A dataset is a collection of observations, and we want to create a model that
    can [generalize](https://developers.google.com/machine-learning/crash-course/generalization/video-lecture)
    from these observations. The idea is that starting from our dataset we can infer
    some rules that are also valid for the general population. In other words, we
    can consider our model as a set of hypotheses.
  prefs: []
  type: TYPE_NORMAL
- en: In theory, the hypothesis space is infinite. In fact, if we consider two points
    in [Cartesian space](https://en.wikipedia.org/wiki/Cartesian_coordinate_system)
    it can pass a straight line but infinite curves. Without more points, we cannot
    know which hypothesis is the most correct.
  prefs: []
  type: TYPE_NORMAL
- en: Generally, the simplest hypothesis is the most correct one. A curve that fits
    the points perfectly is generally [overfitting](https://en.wikipedia.org/wiki/Overfitting).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3988a13e30781fff3edd2b6f4eb01095.png)'
  prefs: []
  type: TYPE_IMG
- en: image from [here](https://en.wikipedia.org/wiki/Overfitting)
  prefs: []
  type: TYPE_NORMAL
- en: Inductive bias can be defined as the prioritization of certain hypotheses (thus
    reducing the hypothesis space). For example, when there is a [regression task](https://en.wikipedia.org/wiki/Regression_analysis)
    we decide to consider linear models, at this time we are reducing our hypothesis
    space by allowing our hypotheses to be only linear.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/638a306aca2d817b6794915b837180eb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'linear regression. image source: [here](https://en.wikipedia.org/wiki/Linear_regression)'
  prefs: []
  type: TYPE_NORMAL
- en: An inductive bias allows a learning algorithm to prioritize one solution (or
    interpretation) over another, independent of the observed data ([source](https://arxiv.org/pdf/1806.01261.pdf))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: On the one hand, we have different types of data, and we have different types
    of models with different assumptions and different inductive biases (i.e., different
    reductions in the [hypothesis space](https://stats.stackexchange.com/questions/183989/what-exactly-is-a-hypothesis-space-in-machine-learning)).
    One might therefore be tempted to choose one model for all types of data.
  prefs: []
  type: TYPE_NORMAL
- en: In 1997, though, the [no-free lunch theorem](https://en.wikipedia.org/wiki/No_free_lunch_theorem)
    ended this temptation. No one model can work for all situations. In fact, there
    is no optimal bias that allows a model to generalize for all tasks. In other words,
    assumptions in a model that may be optimal for one task may not be optimal for
    another.
  prefs: []
  type: TYPE_NORMAL
- en: This is one reason why we use convolutional neural networks for images, RNNs
    (or LSTMs) for text sequences, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6525c8da72d4cbba03643a63a3298837.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To better understand here are some examples of inductive bias:'
  prefs: []
  type: TYPE_NORMAL
- en: '[**Decision trees**](https://en.wikipedia.org/wiki/Decision_tree) are based
    on the assumption that a task can be solved by a series of binary decisions (binary
    splits).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Regularization**](https://en.wikipedia.org/wiki/Regularization_(mathematics)),
    the assumption is directed to solutions where the parameters have small values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Fully connected layer**](https://www.oreilly.com/library/view/tensorflow-for-deep/9781491980446/ch04.html).
    There is an all-to-all bias where all the units of layer i are connected with
    the following layer j (all the neurons in one layer are connected to the next
    layer). Which it s meaning there is a very weak relational bias since any unit
    can interact with other units.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Convolutional neural networks**](https://en.wikipedia.org/wiki/Convolutional_neural_network)
    are based on the idea of locality where the features are drawn using local pixels
    and are combined in hierarchical patterns. In another world, we are assuming that
    pixels that are near are actually related and this relationship should be considered
    by the model (during the convolutional step).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Recurrent neural networks**](https://en.wikipedia.org/wiki/Recurrent_neural_network)
    have a bias related to sequentiality since each word is processed in sequence.
    There is also temporal equivariance (or recursion) because the weights are reused
    for all the elements of the sequence (we update the hidden state).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Transformer**](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model))**.**
    It has not a strong inductive bias, which should provide more flexibility (at
    the cost of high data for training). In fact, in a low data regimen, the model
    is performing worst than others.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/5c054cd6a3b12bd68912a55acc04d922.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/pdf/1806.01261.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '**The inductive bias of CNN and transformer**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/0788572e8b5790c78658ffd20b94acb7.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Tudose Alexandru](https://unsplash.com/de/@pandatudii?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '[Convolutional neural networks](https://en.wikipedia.org/wiki/Convolutional_neural_network)
    for a long time dominated computer vision, until [Vision Transformers](https://en.wikipedia.org/wiki/Vision_transformer)
    came along. As we mentioned above, CNNs are based on the principle that neighboring
    pixels have a relationship. Therefore during [convolution](https://en.wikipedia.org/wiki/Convolution),
    several pixels share the same weight.'
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, the use of the [pooling layer](https://www.geeksforgeeks.org/cnn-introduction-to-pooling-layer/)
    is used to achieve [translational invariance](https://stats.stackexchange.com/questions/208936/what-is-translation-invariance-in-computer-vision-and-convolutional-neural-netwo).
    Which is meaning that a pattern is recognized wherever it is in the image (for
    example, a face that is at the left or right corner of an image)
  prefs: []
  type: TYPE_NORMAL
- en: These biases are very effective for processing natural image data because there
    is high covariance within local neighborhoods, which diminishes with distance,
    and because the statistics are mostly stationary across an image. ([source](https://arxiv.org/abs/1806.01261))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: These biases actually were inspired by the [inferior temporal cortex](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6404234/),
    which seems to provide the corresponding biological for scale, translation, and
    rotation invariance. These biases were considered important for the CNN to be
    resistant to changes in image translation, scaling, or other deformations and
    therefore incorporated through convolution and pooling.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/416fc7dd7fc8c6971899c6d95bf223a2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/abs/1801.01450)'
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, images are complex and information-rich objects. Given their
    use, an attempt was made to understand in more detail what [CNNs](https://en.wikipedia.org/wiki/Convolutional_neural_network)
    see and what other biases are present.
  prefs: []
  type: TYPE_NORMAL
- en: '[In a 2017 study](https://arxiv.org/pdf/1706.08606.pdf), the authors showed
    that [Inception models](https://www.geeksforgeeks.org/ml-inception-network-v1/)
    (a type of CNNs) have a strong “shape bias.” In other words, CNNs rely more on
    the shape of an object to recognize it than on other types of patterns. The authors
    used an image triplet to classify an object and used an image that had the same
    color but a different shape (color match) or the same shape but different color
    (shape match) to study whether the pattern gave more importance to shape or color.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1b784192e0b0bda23ba25f045096bd3e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/abs/1706.08606)'
  prefs: []
  type: TYPE_NORMAL
- en: '[In a later study](https://arxiv.org/pdf/1811.12231.pdf), some authors showed
    instead that more than color is a texture that is important for the model. The
    authors used ResNet50 to test this hypothesis.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d23cd21bef549162d393942df58037c9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/abs/1811.12231)'
  prefs: []
  type: TYPE_NORMAL
- en: They showed that in case of texture-shape conflict the model tends to use texture.
    so for the authors, CNNs have a strong “texture bias”
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/71b2101f93a2d1fa6df09bceaa83d541.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/abs/1811.12231)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The authors conclude, however, that models that have a shape bias are more
    robust:'
  prefs: []
  type: TYPE_NORMAL
- en: Remarkably, networks with a higher shape bias are inherently more robust to
    many different image distortions (for some even reaching or surpassing human performance,
    despite never being trained on any of them) and reach higher performance on classification
    and object recognition tasks. ([here](https://arxiv.org/pdf/1811.12231.pdf))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: So actually, for images, it would be desirable to have shape bias. This can
    be achieved by using either the appropriate dataset or [by using data augmentation
    techniques](https://arxiv.org/pdf/1911.09071.pdf) that include color distortion,
    noise, and blur (which precisely decrease texture bias). While conversely, random
    cropping increases texture bias.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7340b40268cc08ae0b2f18a2e825374b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/abs/1911.09071)'
  prefs: []
  type: TYPE_NORMAL
- en: So concretely we can say that the bias depends not only on the architecture
    for a [CNN](https://en.wikipedia.org/wiki/Convolutional_neural_network) but also
    on the dataset with which it is trained. Depending on the dataset a CNN acquires
    a bias toward either shape or texture.
  prefs: []
  type: TYPE_NORMAL
- en: '[The authors of a study](https://arxiv.org/abs/2010.05981) state that these
    biases are complementary. The model can then focus on either texture or shape
    for prediction. Sometimes, however, only one of these two elements is not enough
    for correct prediction (reduces performance). The authors state that as the model
    can learn either bias it can also “*automatically figure out how to avoid being
    biased toward either shape or texture from their training samples.*” In other
    words, using examples that are conflicting (for texture and shape) can instruct
    the model not to have bias.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/88f7467e4c1ffdd560e9b6fad8b6c873.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/pdf/2010.05981.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[The Vision transformer](https://en.wikipedia.org/wiki/Vision_transformer)
    is derived from the transformer, and as mentioned above it is a model that does
    not have a strong bias.'
  prefs: []
  type: TYPE_NORMAL
- en: Some studies have shown that there are still several similarities between [CNNs](https://en.wikipedia.org/wiki/Convolutional_neural_network)
    and ViTs. In fact, ViTs also learn a layer-by-layer hierarchical view that can
    also be visualized.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/44b389f9e66fbd4e4b77177c398793b1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image: [source](https://arxiv.org/pdf/2212.06727.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://pub.towardsai.net/a-visual-journey-in-what-vision-transformers-see-9db9c8ba62d4?source=post_page-----d418fc61726c--------------------------------)
    [## A Visual Journey in What Vision-Transformers See'
  prefs: []
  type: TYPE_NORMAL
- en: How some of the largest models see the world
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: pub.towardsai.net](https://pub.towardsai.net/a-visual-journey-in-what-vision-transformers-see-9db9c8ba62d4?source=post_page-----d418fc61726c--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'A later study though suggests that [ViTs](https://en.wikipedia.org/wiki/Vision_transformer)
    actually have a higher shape bias than [CNNs](https://en.wikipedia.org/wiki/Convolutional_neural_network).
    Which is actually surprising. Moreover, the authors point out how this shape bias
    plays a positive role in robustness to image corruption:'
  prefs: []
  type: TYPE_NORMAL
- en: '[…] highlight a general inverse relationship between shape bias and mean corruption
    error. As a model is more robust to common corruptions (smaller mCE), its shape
    bias increases. ([source](https://arxiv.org/abs/2106.13122))'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0e04cf6fad9e3b49710f997409f73bc7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'shape bias of vision transformers. image source: [here](https://arxiv.org/abs/2106.13122)'
  prefs: []
  type: TYPE_NORMAL
- en: Several groups hypothesized that adding adequate inductive bias might have allowed
    ViTs to outperform CNNs even without having to train them with millions of images.
    On the one hand, this hypothesis led to the creation of so many models [but made
    training extremely inefficient](/metas-hiera-reduce-complexity-to-increase-accuracy-30f7a147ad0b).
  prefs: []
  type: TYPE_NORMAL
- en: 'So remains the question:'
  prefs: []
  type: TYPE_NORMAL
- en: how much of the lack of inductive bias can be compensated by scaling of parameters
    and the number of training examples?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How to study inductive bias?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/14cdb32ee83108d6bbf0f85a4784ebe2.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Aaron Burden](https://unsplash.com/@aaronburden?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: As we have seen, several open questions remain. Although there are a great many
    studies on [CNNs](https://en.wikipedia.org/wiki/Convolutional_neural_network)
    and [ViTs](https://en.wikipedia.org/wiki/Vision_transformer), many points of theoretical
    background behind these advances in performance remain obscure.
  prefs: []
  type: TYPE_NORMAL
- en: “MLPs are the simplest of these neural network architectures that hinge on this
    stacking idea, and thus provide a minimal model for an effective theory of deep
    learning.” ([source](https://arxiv.org/abs/2106.10165))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In general, many such studies on more theoretical aspects are conducted using
    [multi-layer perceptrons](https://en.wikipedia.org/wiki/Multilayer_perceptron)
    (MLPs). This is because it is a layer composed of simple matrix multiplications
    encapsulated in a nonlinear function. Its simplicity allows many experiments to
    be conducted at a low computational cost. Studies then conducted on simpler models
    are then translated to more complex and sophisticated models. MLP has inferior
    performance in many settings, though, leaving open how much of what is seen can
    then be carried over to models that have far superior performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, MLP has another advantage, it has a weak inductive bias.
    Which makes it a good candidate for ViT studies. There is also a derivative model
    that has even less inductive bias: [MLP-Mixer](https://arxiv.org/abs/2105.01601)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/427eb1e5c288aab1ba585158e40f7613.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/abs/2105.01601)'
  prefs: []
  type: TYPE_NORMAL
- en: Intriguingly, MLP-Mixer uses neither convolution nor self-attention. Instead,
    it relies on multi-layer perception layers that are either applied to spatial
    locations or feature channels. All this is thanks to the clever usage of matrix
    multiplication and non-linearity.
  prefs: []
  type: TYPE_NORMAL
- en: Briefly, patches are linearly projected into an embedding space (then transformed
    into tabular data that can be harnessed by MLP). After that, we have a series
    of mixer layers. The input enters and is transposed, after which we have a simple
    fully connected layer. This layer identifies features that are common in the patches
    (aggregating channels). Then the result is transposed and a second fully connected
    layer to identify features in the patches themselves (associating it with the
    channel).
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, there are also [skip connections](https://en.wikipedia.org/wiki/Residual_neural_network),
    [GELU](https://paperswithcode.com/paper/gaussian-error-linear-units-gelus) as
    a non-linear function, and [layer normalization](https://arxiv.org/abs/1607.06450).
    In addition, the authors comment:'
  prefs: []
  type: TYPE_NORMAL
- en: Our architecture can be seen as a unique CNN, which uses (1×1) convolutions
    for channel mixing, and single-channel depth-wise convolutions for token mixing.
    However, the converse is not true as CNNs are not special cases of Mixer. ([source](https://arxiv.org/abs/2105.01601))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/50a7a5be9818b3ee9409ea9002e89cdf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/abs//2306.13575)'
  prefs: []
  type: TYPE_NORMAL
- en: Another interesting relationship is that convolution [can be seen as a special
    case of an MLP](https://arxiv.org/abs//2306.13575), where the matrix of W weights
    is sparse and has shared entries. This sharing of the weights does in fact cause
    the learning to be spatially localized (as we mentioned above about the spatial
    bias of convolution).
  prefs: []
  type: TYPE_NORMAL
- en: 'Considering a matrix W, an image 2x3x1 pixels, and a filter f of size 2x2 this
    relationship becomes clear:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ae0c8735774a415a5384388edd228ad7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/abs//2306.13575)'
  prefs: []
  type: TYPE_NORMAL
- en: This has the advantage of making the model translation invariant, sacrificing
    the robustness of [MLPs](https://en.wikipedia.org/wiki/Multilayer_perceptron)
    if there are permutations in the image.
  prefs: []
  type: TYPE_NORMAL
- en: But what about the Vision Transformers?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: There is also a close relationship between [ViTs](https://en.wikipedia.org/wiki/Vision_transformer)
    and convolution (despite having the same biases). In fact, as shown above, self-attention
    layers process images in a similar way to convolution layers. In [a 2020 paper](https://arxiv.org/abs/1911.03584),
    the authors show how [self-attention](https://en.wikipedia.org/wiki/Attention_(machine_learning))
    layers can express any convolutional layer.
  prefs: []
  type: TYPE_NORMAL
- en: So as we said there are strong relationships between MLP, MLP-mixer, convolutional
    networks, and Vision Transformer. While these models have strong differences in
    inductive bias and how they process images.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6037dcaaf8cb199d9e2c6f45cf5d7ea1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/abs//2306.13575)'
  prefs: []
  type: TYPE_NORMAL
- en: In summary, since there are strong relationships and correspondences between
    the various models, but also differences between induction bias, we can use [MLP](https://en.wikipedia.org/wiki/Multilayer_perceptron)
    as a simple model to understand whether the lack of inductive bias can be compensated
    by scaling and examples in the training set.
  prefs: []
  type: TYPE_NORMAL
- en: David against Goliath
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/6e3a1a8826927456d46dec71a799bb59.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Sean Robertson](https://unsplash.com/ko/@knuknuk?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '[In a recent paper, they did exactly that](https://arxiv.org/abs//2306.13575).
    They took [MLP](https://en.wikipedia.org/wiki/Multilayer_perceptron), a model
    that is simple in structure anyway and tried to understand what was happening
    with scaling. **Can scaling improve the performance of the simple fully connected
    layer?**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The authors took an MLP and built a model where they stacked equal layers of
    MLPs of the same size. Taking advantage of recent literature, they added [layer
    normalization](https://arxiv.org/abs/1607.06450) and skip connections to see if
    they made the training more stable. They also created a simple architecture called
    inverted bottleneck, where with two weight matrices they expand and collapse in
    the same block the input:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/28ec3c531acf1099b68f23e24217c67b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'inverted block. image source: [here](https://arxiv.org/abs//2306.13575)'
  prefs: []
  type: TYPE_NORMAL
- en: On the one hand, it is true that these additions increase the [inductive bias](https://en.wikipedia.org/wiki/Inductive_bias)
    but compared to modern complex architectures this is negligible. After that, they
    decided to explore what happens when comparing [MLP](https://en.wikipedia.org/wiki/Multilayer_perceptron)
    with other models in [computer vision](https://en.wikipedia.org/wiki/Computer_vision)
    tasks (where generally [MLP](https://en.wikipedia.org/wiki/Multilayer_perceptron)
    performance is far inferior).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/99a1a8d9486e7b6dab6b49961bc408ab.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/abs//2306.13575)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The authors tested these architectures with interesting results on some popular
    computer vision datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: the [MLP](https://en.wikipedia.org/wiki/Multilayer_perceptron) standard goes
    directly into overfitting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding [data augmentation](https://en.wikipedia.org/wiki/Data_augmentation)
    marginally improves performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using bottleneck increases performance. Using data augmentation with an inverted
    bottleneck has a significantly higher impact (about 20 % in performance gain).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Despite this, [ResNet18](https://pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html)
    has far superior performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These data are in line with the literature, where it is stated that with a small
    sample size (after all, these datasets are small) [inductive bias](https://en.wikipedia.org/wiki/Inductive_bias)
    is important. In fact, the same has been observed with [ViTs](https://en.wikipedia.org/wiki/Vision_transformer)
    and MLP mixers.
  prefs: []
  type: TYPE_NORMAL
- en: In recent years, the advantage of large models has been that they can be trained
    on large amounts of images and then transfer knowledge to smaller datasets (transfer
    learning). For this, the authors used [ImageNet21k](https://arxiv.org/abs/2104.10972)
    (12 million images and 11k classes). After that, they conducted [fine-tuning](https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning))
    on a new task.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/aa44819198362be5749ae6928cd72c64.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/abs//2306.13575)'
  prefs: []
  type: TYPE_NORMAL
- en: The results are surprising, the model is able to transfer what it has learned
    about a dataset to another task. Moreover, the results are far superior to what
    has been seen before.
  prefs: []
  type: TYPE_NORMAL
- en: While of course pre-trained on a large quantity of data, we nevertheless want
    to highlight that such an MLP becomes competitive with a ResNet18 trained from
    scratch for all the datasets, except for ImageNet1k where performance falls surprisingly
    short. ([source](https://arxiv.org/abs//2306.13575))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This confirms that [MLP](https://en.wikipedia.org/wiki/Multilayer_perceptron)
    is a good proxy for being able to analyze [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning),
    data augmentation, and other theoretical elements. This is surprising because
    it is an elementary model in comparison with modern models.
  prefs: []
  type: TYPE_NORMAL
- en: Another surprising result is that using large [batch sizes](https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/)
    in training increases performance.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a53df083ca89e74eca826725883e3803.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/abs//2306.13575)'
  prefs: []
  type: TYPE_NORMAL
- en: Generally, the opposite effect is observed. Especially in the case of [CNN](https://en.wikipedia.org/wiki/Convolutional_neural_network)
    where one tries to preserve the performance of small [batch size](https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/)
    when training with many more examples. After all, using a small batch means doing
    many more gradient updates during an [epoch](https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/)
    (at the cost of longer training, though). On the other hand, large batch sizes
    are faster and can be split across multiple devices with decisive time gain.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, [some observations conducted on transformers](https://arxiv.org/abs/2001.08361)
    would seem that even these wide models benefit from a larger [batch size](https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/56d040102c94739f967c4f9904d7561e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/abs/2001.08361)'
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, there has been much discussion in recent years about the scaling
    law: according to which as parameters increase there is a highly predictable increase
    in performance (and a quantifiable power law follows). This scaling law has been
    observed for LLMs although in recent times several groups have questioned it.'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/emergent-abilities-in-ai-are-we-chasing-a-myth-fead754a1bf9?source=post_page-----d418fc61726c--------------------------------)
    [## Emergent Abilities in AI: Are We Chasing a Myth?'
  prefs: []
  type: TYPE_NORMAL
- en: Changing Perspective on Large Language Models emerging properties
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/emergent-abilities-in-ai-are-we-chasing-a-myth-fead754a1bf9?source=post_page-----d418fc61726c--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Although the discussion on scaling law is still open, it is still interesting
    to analyze whether this is possible with simple models like [MLP](https://en.wikipedia.org/wiki/Multilayer_perceptron)
    (after all, MLP by increasing the number of parameters should tend to overfit).
  prefs: []
  type: TYPE_NORMAL
- en: In this study, the authors also defined a family of models with an increasing
    number of parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2db27fd4359298759b487bd14420eb5b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/abs//2306.13575)'
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, [MLP](https://en.wikipedia.org/wiki/Multilayer_perceptron) also seems
    to exhibit power-law-like behavior.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2d9cfd645c8563dba1888ded46073eb3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/abs//2306.13575)'
  prefs: []
  type: TYPE_NORMAL
- en: This is definitely an interesting result because it shows even a simple model
    like [MLP](https://en.wikipedia.org/wiki/Multilayer_perceptron) can show a presumed
    power law.
  prefs: []
  type: TYPE_NORMAL
- en: '[MLP](https://en.wikipedia.org/wiki/Multilayer_perceptron) is a model that
    was not designed to work with images. In fact, the authors note that [MLP](https://en.wikipedia.org/wiki/Multilayer_perceptron)
    given its bad inductive bias is more dependent on the number of examples. So yes
    one can compensate for a weak [inductive bias](https://en.wikipedia.org/wiki/Inductive_bias),
    but this requires a large number of examples.'
  prefs: []
  type: TYPE_NORMAL
- en: A decidedly interesting point is that all these models were run on a single
    GPU. A single epoch for [ImageNet21k](https://arxiv.org/abs/2104.10972) with the
    largest architecture took 450 seconds on a single 24 GB GPU. In other words, these
    experiments can be run quickly on any commercial GPU.
  prefs: []
  type: TYPE_NORMAL
- en: 'The authors point out that [MLPs](https://en.wikipedia.org/wiki/Multilayer_perceptron)
    are clearly more efficient and much larger batches can be used:'
  prefs: []
  type: TYPE_NORMAL
- en: As it quickly becomes eminent, MLPs require significantly less FLOPs to make
    predictions on individual images, in essence utilizing their parameters a lot
    more methodically. As a result, latency and throughput are significantly better
    compared to other candidate architectures. (source)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/47edd5072fcaab87c3c8dc9e6be00d39.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/abs//2306.13575)'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/800abe1819fa05a1d81be24ca9cec38d.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Philip Myrtorp](https://unsplash.com/@philipmyr?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '[Inductive bias](https://en.wikipedia.org/wiki/Inductive_bias) is one of the
    fundamental concepts of machine learning. In general, it is one of the main reasons
    why depending on the type of data we choose one model and not another. Although
    there have been a lot of studies still there are gaps in theory.'
  prefs: []
  type: TYPE_NORMAL
- en: It is intriguing to think how narrow the field of hypotheses a priori can lead
    to better results. That comes at a cost, though, both level of theory and model
    complexity. As we have seen previously trying to add inductive bias to models
    of ViTs has led to creating increasingly complex and computationally inefficient
    models.
  prefs: []
  type: TYPE_NORMAL
- en: Although MLP is an extremely simple model, it has the advantage of being computationally
    efficient, which is why it has been used for many studies to try to fill theoretical
    holes. One of the main problems is that the performance of MLP in computer vision
    is far inferior to other models.
  prefs: []
  type: TYPE_NORMAL
- en: Recent results show that with the right accommodations, this gap can be overcome.
    Also, the lack of inductive bias can be compensated for with scaling. So MLPs
    can be a good proxy for studying modern architectures and how they behave in different
    situations.
  prefs: []
  type: TYPE_NORMAL
- en: Why is all this important?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In general, the last few years of research in AI have focused on a single paradigm:
    more parameters, more data. There has been a new race to the percentage point
    of accuracy. After all, though, the architecture of the Transformer remained the
    same since 2017.'
  prefs: []
  type: TYPE_NORMAL
- en: 'These huge models have a not inconsiderable training cost. In recent months
    a research interest in alternatives has begun to grow: both in terms of obtaining
    the same results with fewer parameters and in looking for an alternative to the
    transformer ( and its quadratic computational cost).'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://levelup.gitconnected.com/welcome-back-80s-transformers-could-be-blown-away-by-convolution-21ff15f6d1cc?source=post_page-----d418fc61726c--------------------------------)
    [## Welcome Back 80s: Transformers Could Be Blown Away by Convolution'
  prefs: []
  type: TYPE_NORMAL
- en: The Hyena model shows how convolution could be faster than self-attention
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'levelup.gitconnected.com](https://levelup.gitconnected.com/welcome-back-80s-transformers-could-be-blown-away-by-convolution-21ff15f6d1cc?source=post_page-----d418fc61726c--------------------------------)
    [](https://medium.com/mlearning-ai/metas-llama-a-small-language-model-beating-giants-5065948e0b7f?source=post_page-----d418fc61726c--------------------------------)
    [## META’s LLaMA: A small language model beating giants'
  prefs: []
  type: TYPE_NORMAL
- en: META open-source model will help us to understand how LMs biases arise
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/mlearning-ai/metas-llama-a-small-language-model-beating-giants-5065948e0b7f?source=post_page-----d418fc61726c--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: In each case, academic research is being forced to chase industry-led research.
    Very few institutions can afford to train an LLM from scratch. [Yet studies like
    this](https://arxiv.org/abs//2306.13575) show that results can be obtained at
    scale even with simple models like MLP. This opens up very interesting perspectives
    to better understand model behavior and start thinking about an alternative to
    the transformer.
  prefs: []
  type: TYPE_NORMAL
- en: '**What do you think? Let me know in the comments.**'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have found this interesting:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*You can look for my other articles, you can also* [***subscribe***](https://salvatore-raieli.medium.com/subscribe)
    *to get notified when I publish articles, you can* [***become a Medium member***](https://medium.com/@salvatore-raieli/membership)
    *to access all its stories (affiliate links of the platform for which I get small
    revenues without cost to you) and you can also connect or reach me on*[***LinkedIn***](https://www.linkedin.com/in/salvatore-raieli/)***.***'
  prefs: []
  type: TYPE_NORMAL
- en: '*Here is the link to my GitHub repository, where I am planning to collect code
    and many resources related to machine learning, artificial intelligence, and more.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/SalvatoreRa/tutorial?source=post_page-----d418fc61726c--------------------------------)
    [## GitHub - SalvatoreRa/tutorial: Tutorials on machine learning, artificial intelligence,
    data science…'
  prefs: []
  type: TYPE_NORMAL
- en: Tutorials on machine learning, artificial intelligence, data science with math
    explanation and reusable code (in python…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/SalvatoreRa/tutorial?source=post_page-----d418fc61726c--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '*or you may be interested in one of my recent articles:*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://levelup.gitconnected.com/the-ai-college-student-goes-back-to-the-bench-daa6d9bdfb14?source=post_page-----d418fc61726c--------------------------------)
    [## The AI college student goes back to the bench'
  prefs: []
  type: TYPE_NORMAL
- en: How LLM can solve college exams and why this is important
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/the-ai-college-student-goes-back-to-the-bench-daa6d9bdfb14?source=post_page-----d418fc61726c--------------------------------)
    [](https://levelup.gitconnected.com/can-we-detect-ai-generated-text-91293463dc52?source=post_page-----d418fc61726c--------------------------------)
    [## Can we detect AI-generated text?
  prefs: []
  type: TYPE_NORMAL
- en: Watermarking could be the solution for detecting it
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/can-we-detect-ai-generated-text-91293463dc52?source=post_page-----d418fc61726c--------------------------------)
    [](/say-once-repeating-words-is-not-helping-ai-58f38035f66e?source=post_page-----d418fc61726c--------------------------------)
    [## Say Once! Repeating Words Is Not Helping AI
  prefs: []
  type: TYPE_NORMAL
- en: How and why is repeating tokens harming LLMs? Why is this a problem?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/say-once-repeating-words-is-not-helping-ai-58f38035f66e?source=post_page-----d418fc61726c--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Reference
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here is the list of the principal references I consulted to write this article,
    only the first name for an article is cited.
  prefs: []
  type: TYPE_NORMAL
- en: Goodman, Nelson. *Fact, Fiction, and Forecast* (Fourth Edition). Harvard University
    Press, 1983
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Battaglia et al, 2018, Relational inductive biases, deep learning, and graph
    networks, [link](https://arxiv.org/abs/1806.01261)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Kauderer-Abrams, 2017, Quantifying Translation-Invariance in Convolutional Neural
    Networks, [link](https://arxiv.org/abs/1801.01450)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Ritter et al, 2017, Cognitive Psychology for Deep Neural Networks: A Shape
    Bias Case Study, [link](https://arxiv.org/abs/1706.08606)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Conway et al, 2018, The Organization and Operation of Inferior Temporal Cortex,
    [link](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6404234/)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Geirhos et al, 2022, ImageNet-trained CNNs are biased towards texture; increasing
    shape bias improves accuracy and robustness, [link](https://arxiv.org/abs/1811.12231)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hermann et al, 2020, The Origins and Prevalence of Texture Bias in Convolutional
    Neural Networks, [link](https://arxiv.org/abs/1911.09071)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Li et al, 2021, Shape-Texture Debiased Neural Network Training, [link](https://arxiv.org/abs/2010.05981)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ghiasi et al, 2022, What do Vision Transformers Learn? A Visual Exploration,
    [link](https://arxiv.org/abs/2212.06727)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Morrison et al, 2021, Exploring Corruption Robustness: Inductive Biases in
    Vision Transformers and MLP-Mixers, [link](https://arxiv.org/abs/2106.13122)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Mormille et al, 2023, Introducing inductive bias on vision transformers through
    Gram matrix similarity based regularization, [link](https://link.springer.com/article/10.1007/s10015-022-00845-9)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Tolstikhin et al, 2021, MLP-Mixer: An all-MLP Architecture for Vision, [link](https://arxiv.org/abs/2105.01601)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Cordonnier et al, 2020, On the Relationship between Self-Attention and Convolutional
    Layers, [link](https://arxiv.org/abs/1911.03584)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Bachmann et al 2023, Scaling MLPs: A Tale of Inductive Bias, [link](https://arxiv.org/abs//2306.13575)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Kaplan et al, 2020, Scaling Laws for Neural Language Models, [link](https://arxiv.org/abs/2001.08361)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Lei Ba et al, 2016, Layer Normalization, [link](https://arxiv.org/abs/1607.06450)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: He et al, 2015, Deep Residual Learning for Image Recognition, [link](https://arxiv.org/abs/1512.03385)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ridnik et al, 2021, ImageNet-21K Pretraining for the Masses, [link](https://arxiv.org/abs/2104.10972)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Sharad Joshi](https://medium.com/u/b88796fee2b6?source=post_page-----d418fc61726c--------------------------------),
    2022, Everything you need to know about : Inductive bias, MLearning.ai'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
