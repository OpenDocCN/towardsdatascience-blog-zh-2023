- en: Collecting Data with Apache Airflow on a Raspberry Pi
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Raspberry Pi 上使用 Apache Airflow 收集数据
- en: 原文：[https://towardsdatascience.com/collecting-data-with-apache-airflow-on-a-raspberry-pi-0ac3f72e377f](https://towardsdatascience.com/collecting-data-with-apache-airflow-on-a-raspberry-pi-0ac3f72e377f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/collecting-data-with-apache-airflow-on-a-raspberry-pi-0ac3f72e377f](https://towardsdatascience.com/collecting-data-with-apache-airflow-on-a-raspberry-pi-0ac3f72e377f)
- en: A Raspberry Pi is All You Need
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个 Raspberry Pi 就能满足你的需求
- en: '[](https://dmitryelj.medium.com/?source=post_page-----0ac3f72e377f--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page-----0ac3f72e377f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----0ac3f72e377f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----0ac3f72e377f--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page-----0ac3f72e377f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dmitryelj.medium.com/?source=post_page-----0ac3f72e377f--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page-----0ac3f72e377f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----0ac3f72e377f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----0ac3f72e377f--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page-----0ac3f72e377f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----0ac3f72e377f--------------------------------)
    ·8 min read·Oct 21, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----0ac3f72e377f--------------------------------)
    ·8 分钟阅读·2023年10月21日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/1fdf15ccbedadf88e443d6b5a1fc8a14.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1fdf15ccbedadf88e443d6b5a1fc8a14.png)'
- en: Raspberry Pi Zero (model 2021), Image source [Wikipedia](https://en.wikipedia.org/wiki/Raspberry_Pi)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Raspberry Pi Zero（2021型号），图片来源 [维基百科](https://en.wikipedia.org/wiki/Raspberry_Pi)
- en: Often, we need to collect some data within a certain period of time. It can
    be data from the IoT sensor, statistical data from social networks, or something
    else. As an example, the [YouTube Data API](https://developers.google.com/youtube/v3)
    allows us to get the number of views and subscribers for any channel at the current
    moment, but the analytics and historical data are available only to the channel
    owner. Thus, if we want to get weekly or monthly summaries about these channels,
    we need to collect this data ourselves. In the case of the IoT sensor, there may
    be no API at all, and we also need to collect and save data on our own. In this
    article, I will show how to configure Apache Airflow on a Raspberry Pi, which
    allows running tasks for a long period of time without involving any cloud provider.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们需要在一定时间内收集一些数据。这些数据可以来自物联网传感器、社交网络的统计数据或其他来源。举个例子，[YouTube Data API](https://developers.google.com/youtube/v3)
    允许我们获取任何频道当前的观看次数和订阅者数量，但分析和历史数据仅对频道所有者可用。因此，如果我们想要获取这些频道的每周或每月总结数据，我们需要自己收集这些数据。对于物联网传感器，可能根本没有
    API，我们也需要自己收集和保存数据。在这篇文章中，我将展示如何在 Raspberry Pi 上配置 Apache Airflow，这样可以在长时间内运行任务，而无需依赖任何云服务提供商。
- en: Obviously, if you’re working for a large company, you will probably not need
    a Raspberry Pi. In that case, if you need an extra cloud instance, just create
    a Jira ticket for your MLOps department ;) But for a pet project or a low-budget
    startup, it can be an interesting solution.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，如果你在一家大公司工作，你可能不需要 Raspberry Pi。在这种情况下，如果你需要额外的云实例，只需为你的 MLOps 部门创建一个 Jira
    工单即可 ;) 但对于一个小项目或低预算的创业公司，它可能是一个有趣的解决方案。
- en: Let’s see how it works.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它是如何工作的。
- en: Raspberry Pi
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Raspberry Pi
- en: What is actually a Raspberry Pi? For those readers who have never been interested
    in hardware for the last 10 years (the first Raspberry Pi model was introduced
    in 2012), I can briefly explain that this is a single-board computer running full-fledged
    Linux. Usually, a Raspberry Pi has a 1GHz, 2–4-core ARM CPU and 1–8 MB of RAM.
    It is small, cheap, and silent; it has no fans and no disk drive (the OS is running
    from a Micro SD card). A Raspberry Pi needs only a standard USB power supply;
    it can be connected via Wi-Fi or Ethernet to a network and run different tasks
    within months or even years.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 那么 Raspberry Pi 到底是什么？对于那些在过去10年里从未对硬件感兴趣的读者（第一款 Raspberry Pi 模型是在2012年推出的），我可以简要地解释一下，这是一款运行完整
    Linux 系统的单板计算机。通常，Raspberry Pi 配备有 1GHz 的 2–4 核 ARM CPU 和 1–8 MB 的 RAM。它小巧、便宜且安静；没有风扇，也没有磁盘驱动器（操作系统从
    Micro SD 卡运行）。Raspberry Pi 只需要一个标准的 USB 电源；它可以通过 Wi-Fi 或以太网连接到网络，并可以在几个月甚至几年内运行各种任务。
- en: For my data science pet project, I wanted to collect the YouTube channel statistics
    within 2 weeks. For a task that requires only 30–60 seconds twice per day, a serverless
    architecture can be a perfect solution, and we can use something like [Google
    Cloud Function](https://cloud.google.com/functions?hl=en) for that. But every
    tutorial from Google started with the phrase “enable billing for your project”.
    There is free first credit and free quotas provided by Google, but I did not want
    to have another headache of monitoring how much money I spent and how many requests
    I made, so I decided to use a [Raspberry Pi](https://en.wikipedia.org/wiki/Raspberry_Pi)
    for that. It turned out that the Raspberry Pi is an excellent data science tool
    for collecting data. This $50 single-board computer has only 2W of power consumption;
    it is small, silent, and can be placed anywhere. Last but not least, I already
    had a Raspberry Pi at home, so my cost was literally zero. I just plugged a power
    supply into the socket, and the problem of cloud computing was solved ;)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我的数据科学小项目，我想在2周内收集YouTube频道统计信息。对于一个每天只需30-60秒的任务，无服务器架构可以是一个完美的解决方案，我们可以使用类似[Google
    Cloud Function](https://cloud.google.com/functions?hl=en)的服务。但Google的每个教程都以“启用项目计费”开始。Google提供了免费首信用和免费配额，但我不想再有另一个监控花费和请求量的麻烦，因此决定使用[Raspberry
    Pi](https://en.wikipedia.org/wiki/Raspberry_Pi)。结果发现Raspberry Pi是一个出色的数据科学工具，用于收集数据。这台$50的单板计算机仅消耗2W的功率；它体积小，安静，可以放在任何地方。最后但同样重要的是，我家里已经有了一台Raspberry
    Pi，因此我的成本几乎为零。我只需将电源插入插座，云计算问题就解决了 ;)
- en: There are different Raspberry Pi models on the market, and at the time of writing
    this article, the Raspberry Pi 4 and Raspberry Pi 5 are the most powerful. But
    for tasks that do not require a lot of requests or “heavy” postprocessing, the
    earliest models will also do the job.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 市场上有不同的Raspberry Pi型号，在撰写本文时，Raspberry Pi 4和Raspberry Pi 5是最强大的。但对于不需要大量请求或“重”后处理的任务，最早的型号也能完成工作。
- en: Apache Airflow
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Apache Airflow
- en: For my pet project, I had a list of 3,000 YouTube channels, and the YouTube
    Data API limit is 10,000 requests per day. So, I decided to collect data twice
    per day. If we want to run Python code twice per day, we can use a CRON job or
    just add `time.sleep(12*60*60)` to the main application loop. But a much more
    effective and fun way is to use [Apache Airflow](https://airflow.apache.org) for
    that. Apache Airflow is a professional workflow management platform, and it is
    also open-source and free to use.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我的小项目，我有一个包含3000个YouTube频道的列表，而YouTube数据API限制为每天10000个请求。因此，我决定每天收集数据两次。如果我们想要每天运行Python代码两次，可以使用CRON作业或仅在主应用循环中添加`time.sleep(12*60*60)`。但一种更有效和有趣的方法是使用[Apache
    Airflow](https://airflow.apache.org)。Apache Airflow是一个专业的工作流管理平台，它也是开源的，且免费使用。
- en: 'It is easy to install Airflow on a Raspberry Pi using a *pip* command (here,
    I used Apache Airflow 2.7.1 and Python 3.9):'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 使用*pip*命令在Raspberry Pi上安装Airflow很简单（这里，我使用了Apache Airflow 2.7.1和Python 3.9）：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: It’s generally not recommended to use *sudo* with pip, but on my Raspberry Pi,
    Python airflow libraries were not found when I started airflow as a service (services
    are running as root), and using `sudo pip3` was the easiest fix for that.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一般不建议使用*sudo*与pip，但在我的Raspberry Pi上，当我将airflow作为服务启动时（服务以root身份运行），找不到Python
    airflow库，使用`sudo pip3`是最简单的解决方法。
- en: 'When Apache Airflow is installed, we need to initialize it and create a user:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 安装Apache Airflow后，我们需要初始化它并创建一个用户：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now, the Airflow is installed, but I wanted it to run automatically as a service
    after the boot.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，Airflow已安装，但我希望它在启动后自动作为服务运行。
- en: 'First, I created a `/etc/systemd/system/airflow-webserver.service` file to
    run the Apache Airflow web server as a service:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我创建了一个`/etc/systemd/system/airflow-webserver.service`文件，将Apache Airflow网络服务器作为服务运行：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In the same way, I created a `/etc/systemd/system/airflow-scheduler.service`file
    for an Airflow scheduler:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以相同的方式，我为Airflow调度器创建了一个`/etc/systemd/system/airflow-scheduler.service`文件：
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We also need a `/home/pi/airflow/env` file:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要一个`/home/pi/airflow/env`文件：
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, we can start new services, and Apache Airflow is ready to use:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以启动新服务，Apache Airflow已准备好使用：
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If everything was done correctly, we can make a login to the Apache Airflow
    web panel (credentials — “airflow”, “airflow”):'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切操作正确，我们可以登录到Apache Airflow网页面（凭据为“airflow”，“airflow”）：
- en: '![](../Images/80ebada6c41b3cba46938cbe614a3b1c.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/80ebada6c41b3cba46938cbe614a3b1c.png)'
- en: Apache Airflow login page, Image by author
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Airflow 登录页面，图像由作者提供
- en: Apache Airflow DAG
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Apache Airflow DAG
- en: A DAG (Directed Acyclic Graph) is a core concept of Apache Airflow. Combining
    different tasks into a graph allows us to organize pretty complex data processing
    pipelines. A DAG itself is created in the form of a Python file, and it has to
    be placed in the “dags” folder of Apache Airflow (this path is specified in the
    `dags_folder` parameter of the “airflow.cfg” file). During the start, or after
    pressing the “Refresh” button, Apache Airflow imports these Python files and gets
    all the needed information from them.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: DAG（有向无环图）是 Apache Airflow 的核心概念。将不同的任务组合成一个图形可以让我们组织相当复杂的数据处理管道。DAG 本身是以 Python
    文件的形式创建的，必须放置在 Apache Airflow 的“dags”文件夹中（该路径在“airflow.cfg”文件的 `dags_folder` 参数中指定）。在启动时或按下“刷新”按钮后，Apache
    Airflow 会导入这些 Python 文件，并从中获取所有所需的信息。
- en: 'In my case, I created a `process_channels` method located in a `get_statistics.py`
    file:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的例子中，我创建了一个位于 `get_statistics.py` 文件中的 `process_channels` 方法：
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: (getting the YouTube data itself is out of the scope of this article; it can
    just be any method we want to run periodically)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: （获取 YouTube 数据本身超出了本文的范围；它可以是我们想要定期运行的任何方法）
- en: 'A DAG file for running our code in Apache Airflow is simple:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 用于在 Apache Airflow 中运行我们代码的 DAG 文件非常简单：
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: As we can see, here I made the `create_dag` method, and the most important part
    is the `schedule_interval` parameter, which is equal to 12 hours. In total, I
    have 3 tasks in my DAG; they are represented by three almost identical `get_channels_stats_gr1..3`
    methods. Each task is isolated and will be executed separately by Apache Airflow.
    I also created a variable `RequestLimit`. A YouTube API is limited to 10,000 requests
    per day, and during the debugging, it makes sense to make this parameter low.
    Later, this value can be changed at any time by using the “Variables” control
    panel of Apache Airflow.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，我在这里创建了 `create_dag` 方法，其中最重要的部分是 `schedule_interval` 参数，它等于 12 小时。总的来说，我的
    DAG 中有 3 个任务；它们由三个几乎相同的 `get_channels_stats_gr1..3` 方法表示。每个任务都是隔离的，将由 Apache Airflow
    单独执行。我还创建了一个变量 `RequestLimit`。YouTube API 每天的请求限制为 10,000 次，在调试过程中，将此参数设置为较低的值是有意义的。稍后，可以通过使用
    Apache Airflow 的“变量”控制面板随时更改此值。
- en: Running the DAG
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行 DAG
- en: Our task is ready. We can press the “Refresh” button, and a new DAG will appear
    in the list and will be executed according to our programmed schedule. As we can
    see, installing Apache Airflow and creating a DAG is not rocket science, but it
    still requires some effort. What is it for? Can we just add one line to the CRON
    job instead? Well, even for a simple task like this, Apache Airflow provides a
    lot of functionality.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的任务已经准备好了。我们可以按“刷新”按钮，一个新的 DAG 将出现在列表中，并按照我们编程的时间表执行。如我们所见，安装 Apache Airflow
    和创建 DAG 并不是火箭科学，但仍然需要一些努力。这是为了什么？我们能否仅仅在 CRON 作业中添加一行呢？即使是像这样的简单任务，Apache Airflow
    也提供了大量功能。
- en: 'We can see the task status, the number of completed and failed tasks, the time
    for the next run, and other parameters:'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以看到任务状态、完成和失败任务的数量、下次运行的时间以及其他参数：
- en: '![](../Images/7bc63c5d369514c89ce799db9c8924c6.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7bc63c5d369514c89ce799db9c8924c6.png)'
- en: Apache Airflow DAGs list, Image by author
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Airflow DAGs 列表，图片来源于作者
- en: 'If the task failed, it is easy to click it and see what is going on and when
    the incident happened:'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果任务失败，可以轻松点击它，查看发生了什么以及事件发生的时间：
- en: '![](../Images/cddd1aa7a71d6aa8acb0c1d1c622850b.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cddd1aa7a71d6aa8acb0c1d1c622850b.png)'
- en: Apache Airflow graph view, Image by author
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Airflow 图形视图，图片来源于作者
- en: 'I can even click on the failed task and see its crash log. In my case, a crash
    occurred during the retrieval of YouTube channel data. One of the channels was
    probably removed or disabled by the owner, and no data was available anymore:'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我甚至可以点击失败的任务，查看其崩溃日志。在我的例子中，崩溃发生在检索 YouTube 频道数据时。一个频道可能已经被所有者删除或禁用，因此不再有数据可用：
- en: '![](../Images/c2ff793efdaf431bf50a62a2c6827648.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c2ff793efdaf431bf50a62a2c6827648.png)'
- en: Apache Airflow crash log, Image by author
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Airflow 崩溃日志，图片来源于作者
- en: 'I can see a calendar with a pretty detailed log of previous and future tasks:'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我可以看到一个日历，详细记录了之前和未来任务的日志：
- en: '![](../Images/7d41ddef5e1420f8432cd094348f5677.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7d41ddef5e1420f8432cd094348f5677.png)'
- en: Apache Airflow calendar view, Image by author
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Airflow 日历视图，图片来源于作者
- en: 'I can also see a duration log that can give some insights about the task execution
    time:'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我还可以看到一个持续时间日志，这可以提供有关任务执行时间的一些见解：
- en: '![](../Images/f015abdd10f476e8d8454940b90f1b11.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f015abdd10f476e8d8454940b90f1b11.png)'
- en: Apache Airflow duration log, Image by author
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Airflow 持续时间日志，图片来源于作者
- en: So, using Apache Airflow is way better in functionality compared to adding a
    simple CRON job. Last but not least, knowledge of Airflow is also a nice skill
    that is often required in the industry ;)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，与添加简单的 CRON 作业相比，使用 Apache Airflow 在功能上要好得多。最后但同样重要的是，掌握 Airflow 也是一个在行业中常常需要的不错技能
    ;)
- en: Conclusion
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: In this article, I installed and configured Apache Airflow and was able to run
    it on a Raspberry Pi. Apache Airflow is a professional workflow management platform;
    according to [6sense.com](https://6sense.com/tech/workflow-automation/apache-airflow-market-share),
    it has 29% of the market share and is used by large companies such as Ubisoft,
    SEB, or Hitachi. But as we can see, even on a “nano” scale, Apache Airflow can
    be successfully used on microcomputers like the Raspberry Pi.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我安装并配置了 Apache Airflow，并成功在 Raspberry Pi 上运行它。Apache Airflow 是一个专业的工作流管理平台；根据
    [6sense.com](https://6sense.com/tech/workflow-automation/apache-airflow-market-share)，它拥有
    29% 的市场份额，被 Ubisoft、SEB 或 Hitachi 等大型公司使用。但正如我们所见，即使在“nano”规模上，Apache Airflow
    也可以成功地在像 Raspberry Pi 这样的微型计算机上使用。
- en: 'Those who are interested in using a Raspberry Pi for data science-related projects
    are welcome to read my other TDS articles:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 对于有兴趣在 Raspberry Pi 上进行数据科学相关项目的读者，欢迎阅读我的其他 TDS 文章：
- en: '[Exploratory Analysis of MEMS Sensor Data](/exploratory-analysis-of-mems-sensor-data-bbfc0aa0a887)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MEMS 传感器数据的探索性分析](/exploratory-analysis-of-mems-sensor-data-bbfc0aa0a887)'
- en: '[YOLO Object Detection on the Raspberry Pi](/yolo-object-detection-on-the-raspberry-pi-6de3629256fa)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Raspberry Pi 上的 YOLO 目标检测](/yolo-object-detection-on-the-raspberry-pi-6de3629256fa)'
- en: If you enjoyed this story, feel free [to subscribe](https://medium.com/@dmitryelj/membership)
    to Medium, and you will get notifications when my new articles will be published,
    as well as full access to thousands of stories from other authors. If you want
    to get the full source code for this and my next posts, feel free to visit my
    [Patreon page](https://www.patreon.com/deliuseev).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这个故事，可以随时 [订阅](https://medium.com/@dmitryelj/membership) Medium，你将收到我的新文章发布通知，并能完全访问其他作者的成千上万的故事。如果你想获取本文及我下一篇文章的完整源代码，可以访问我的
    [Patreon 页面](https://www.patreon.com/deliuseev)。
- en: Thanks for reading.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读。
