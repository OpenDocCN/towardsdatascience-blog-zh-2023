["```py\nimport sys\nimport os\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# step 1: Load the dataset from the csv file. \n# You can download the dataset from Kaggle\nfilepath = os.path.join(\"data\", \"creditcard.csv\")\ndf = pd.read_csv(filepath)\n\n# step 2: check data imbalance on target\ncount_neg_class = np.sum(df[\"Class\"] == 0)\ncount_pos_class = np.sum(df[\"Class\"] == 1)\n\nprint(f\"There are {count_neg_class} negative samples ({np.round(100 * count_neg_class / num_samples, 2)} % of total data).\")\nprint(f\"There are {count_pos_class} positive samples ({np.round(100 * count_pos_class / num_samples, 2)} % of total data).\")\n\n# step 3: split data into train and test set\nX = df.drop(columns=\"Class\").to_numpy()\ny = df[\"Class\"].to_numpy()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# step 4: scale the data\nscaler = StandardScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n```", "```py\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import confusion_matrix\n\nfrom sklearn.linear_model import LogisticRegression\n\nlog_model = LogisticRegression()\nlog_model.fit(X_train, y_train)\n\npreds = log_model.predict(X_test)\nprint(f\"Test Acc: {accuracy_score(y_test, preds)}\")\nprint(f\"Test F1-Score: {f1_score(y_test, preds)}\")\nprint(f\"Test Precision: {precision_score(y_test, preds)}\")\nprint(f\"Test Recall: {recall_score(y_test, preds)}\")\n```", "```py\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.model_selection import cross_val_predict\n\ndict_models = {\n    \"Decision Tree\": DecisionTreeClassifier(),\n    \"SVM\": SVC(),\n    \"Nearest Neighbor\": KNeighborsClassifier(),\n    \"Random Forest\": RandomForestClassifier(),\n    \"Ada Boost\": AdaBoostClassifier()\n}\n\n# train all models by using the models dictionary\nresults_dict = {}\nfor model_name, model in dict_models.items():\n    print(f\"Start training {model_name}...\")\n    preds = cross_val_predict(model, X_train, y_train, cv=5)\n\n    f1 = f1_score(y_train, preds)\n    precision = precision_score(y_train, preds)\n    recall = recall_score(y_train, preds)\n\n    print(f\"F1-Score: {f1}\")\n    print(f\"Precision: {precision}\")\n    print(f\"Recall: {recall}\")\n    print(\"\\n\\n\")\n    results_dict[model_name] = (f1, precision, recall)\n\n# create a pandas dataframe with the results on sort on f1-score\ndf_results = (pd.DataFrame.from_dict(results_dict, orient=\"index\", columns=[\"F1-Score\", \"Precision\", \"Recall\"])\n             .sort_values(by=\"F1-Score\", ascending=False))\ndf_results\n```", "```py\nfrom sklearn.model_selection import RandomizedSearchCV\n\nparams = {\n    \"n_estimators\": [10, 20, 30, 60, 80, 100],\n    \"criterion\" : [\"gini\", \"entropy\"],\n    \"max_depth\" : [4, 5, 10, None],\n    \"min_samples_split\": [2, 4, 6],\n    \"class_weight\": [None, \"balanced\", \"balanced_subsample\"]\n}\n\nclf_rf = RandomizedSearchCV(RandomForestClassifier(), params, n_iter=50, scoring=\"f1\", cv=5, verbose=1, n_jobs=-1)\nclf_rf.fit(X_train, y_train)\n\n# let's print the best score and save the best model\nprint(f\"Best f1-score: {clf_rf.best_score_}\")\nprint(f\"Best parameters: {clf_rf.best_params_}\")\nbest_random_forest_model = clf_rf.best_estimator_\n```", "```py\nfinal_preds = best_random_forest_model.predict(X_test)\n\nf1 = f1_score(y_test, final_preds)\nprecision = precision_score(y_test, final_preds)\nrecall = recall_score(y_test, final_preds)\n\nprint(f\"F1-Score: {f1}\")\nprint(f\"Precision: {precision}\")\nprint(f\"Recall: {recall}\")\n```", "```py\nimport numpy as np \nimport pandas as pd\nimport boto3\nimport sagemaker\nimport os, sys\n\n# get some variables required for AutoML later\nsess   = sagemaker.Session()\nbucket = sess.default_bucket()                     \nregion = boto3.Session().region_name\nprefix = 'sagemaker/fraud-detection-auto-ml'\n# Role when working on a notebook instance\nrole = sagemaker.get_execution_role()\n\n# get some sagemaker clients\nsm = boto3.Session().client(service_name='sagemaker',region_name=region)\nsm_rt = boto3.Session().client('runtime.sagemaker', region_name=region)\n\n# load data from s3\nbucket_data = 'patrick-fraud-detection-ml-kaggle'\nfilename = 'creditcard.csv'\ns3 = boto3.client('s3') \nobj = s3.get_object(Bucket=bucket_data, Key=filename) \ndf = pd.read_csv(obj['Body']) # 'Body' is a key word\n```", "```py\nfrom sklearn.model_selection import train_test_split\n\ntrain_data, test_data = train_test_split(df, test_size=0.2)\n\n# Save to CSV files and upload to S3\ntrain_file = \"automl-train.csv\"\ntrain_data.to_csv(train_file, index=False, header=True, sep=',') # Need to keep column names\ntrain_data_s3_path = sess.upload_data(path=train_file, key_prefix=prefix + \"/train\")\nprint(\"Train data uploaded to: \" + train_data_s3_path)\n\n# save test file only to a CSV file \n# -> will be send as POST request to inference endpoint later\ntest_file = \"automl-test.csv\"\ntest_data.to_csv(test_file, index=False, header=False, sep=',')\n```", "```py\nfrom time import gmtime, strftime, sleep\n# setup config for input data\ninput_data_config = [{\n      'DataSource': {\n        'S3DataSource': {\n          'S3DataType': 'S3Prefix',\n          'S3Uri': 's3://{}/{}/input'.format(bucket,prefix)\n        }\n      },\n      'TargetAttributeName': 'Class'  # the column we want to predict\n    }\n]\n\n# setup config for output data\noutput_data_config = { 'S3OutputPath': 's3://{}/{}/output'.format(bucket,prefix) }\n\n# Optional parameters\nproblem_type = 'BinaryClassification'\njob_objective = { 'MetricName': 'F1' } # using F1 because of highly imbalanced dataset\n\n# launch the AutoML job \n# but: limit to max. 20 candidates to limit overall execution time\ntimestamp_suffix = strftime('%d-%H-%M-%S', gmtime())\n\nauto_ml_job_name = 'fraud-detection-' + timestamp_suffix\n\nsm.create_auto_ml_job(AutoMLJobName=auto_ml_job_name,\n                      InputDataConfig=input_data_config,\n                      OutputDataConfig=output_data_config,\n                      AutoMLJobConfig={\"CompletionCriteria\": {\"MaxCandidates\": 20}},\n                      AutoMLJobObjective=job_objective,\n                      ProblemType=problem_type,\n                      RoleArn=role)\n```", "```py\njob_run_status = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)['AutoMLJobStatus']\n\nprint(job_run_status)\n\nwhile job_run_status not in ('Failed', 'Completed', 'Stopped'):\n    describe_response = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)\n    job_run_status = describe_response['AutoMLJobStatus']\n\n    print (describe_response['AutoMLJobStatus'] + \" - \" + describe_response['AutoMLJobSecondaryStatus'])\n    sleep(60)\n```", "```py\nbest_candidate = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)['BestCandidate']\nbest_candidate_name = best_candidate['CandidateName']\n```", "```py\ntimestamp_suffix = strftime(\"%d-%H-%M-%S\", gmtime())\nmodel_name = best_candidate_name + timestamp_suffix + \"-model\"\n\n# create a model in SageMaker that can be hosted as endpoint\nmodel_arn = sm.create_model(\n    Containers=best_candidate[\"InferenceContainers\"], ModelName=model_name, ExecutionRoleArn=role\n)\n\n# setup config for endpoint (including instance type)\nepc_name = best_candidate_name + timestamp_suffix + \"-epc\"\nep_config = sm.create_endpoint_config(\n    EndpointConfigName=epc_name,\n    ProductionVariants=[\n        {\n            \"InstanceType\": \"ml.m5.2xlarge\",\n            \"InitialInstanceCount\": 1,\n            \"ModelName\": model_name,\n            \"VariantName\": \"main\",\n        }\n    ],\n)\n\n# deploy endpoint\nep_name = best_candidate_name + timestamp_suffix + \"-ep\"\ncreate_endpoint_response = sm.create_endpoint(EndpointName=ep_name, EndpointConfigName=epc_name)\n\n# wait until endpoint is ready for inference\nsm.get_waiter(\"endpoint_in_service\").wait(EndpointName=ep_name)\n```", "```py\ntp = tn = fp = fn = count = 0\n\nwith open('automl-test.csv') as f:\n    lines = f.readlines()\n    for l in lines[1:]:   # Skip header\n        l = l.split(',')  # Split CSV line into features\n        label = l[-1]     # Store 0/1 label\n        l = l[:-1]        # Remove label\n        l = ','.join(l)   # Rebuild CSV line without label\n\n        response = sm_rt.invoke_endpoint(EndpointName=ep_name, ContentType='text/csv', Accept='text/csv', Body=l)\n\n        response = response['Body'].read().decode(\"utf-8\")\n        #print (\"label %s response %s\" %(label,response))\n\n        if '1' in label:\n            # Sample is positive\n            if '1' in response:\n                # True positive\n                tp=tp+1\n            else:\n                # False negative\n                fn=fn+1\n        else:\n            # Sample is negative\n            if '0' in response:\n                # True negative\n                tn=tn+1\n            else:\n                # False positive\n                fp=fp+1\n        count = count+1\n        if (count % 100 == 0):   \n            sys.stdout.write(str(count)+' ')\n\n# get final scores\n # Confusion matrix\n\naccuracy  = (tp+tn)/(tp+tn+fp+fn)\nprecision = tp/(tp+fp)\nrecall    = tp/(tp+fn)\nf1        = (2*precision*recall)/(precision+recall)\n\nprint (\"Accuracy: %.4f, Precision: %.4f, Recall: %.4f, F1: %.4f\" % (accuracy, precision, recall, f1))\n```"]