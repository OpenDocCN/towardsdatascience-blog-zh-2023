- en: Conformal Predictions in Time Series Forecasting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/conformal-predictions-in-time-series-forecasting-32d3243d7479](https://towardsdatascience.com/conformal-predictions-in-time-series-forecasting-32d3243d7479)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Explore the concept of conformal predictions applied to the field of time series
    forecasting and implement it in Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@marcopeixeiro?source=post_page-----32d3243d7479--------------------------------)[![Marco
    Peixeiro](../Images/7cf0a81d87281d35ff47f51e3026a3e9.png)](https://medium.com/@marcopeixeiro?source=post_page-----32d3243d7479--------------------------------)[](https://towardsdatascience.com/?source=post_page-----32d3243d7479--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----32d3243d7479--------------------------------)
    [Marco Peixeiro](https://medium.com/@marcopeixeiro?source=post_page-----32d3243d7479--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----32d3243d7479--------------------------------)
    ·10 min read·Dec 12, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c4815b8031d5f2b1e038b0ee4a966ea6.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Keith Markilie](https://unsplash.com/@rhino007?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Consider the task of forecasting call volumes in a call center. The predictions
    play a primordial role, as they inform the budget allocation and workforce planning
    (if more calls are expected, more agents should be available to answer).
  prefs: []
  type: TYPE_NORMAL
- en: So we build a forecasting model and report that next week the center will receive
    2451 calls.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, with any prediction in the future comes some error and uncertainty.
    But how can we quantify it?
  prefs: []
  type: TYPE_NORMAL
- en: The logical answer is using **prediction intervals**. That way, we can report
    a range of possible future values with a certain confidence level.
  prefs: []
  type: TYPE_NORMAL
- en: While there are many methods for calculating prediction intervals, they are
    not applicable for all models and often rely on a particular distribution.
  prefs: []
  type: TYPE_NORMAL
- en: This comes with two major problems. First, the distribution assumption may not
    hold in certain scenarios. Second, we may be restricted in our choice of modeling
    techniques.
  prefs: []
  type: TYPE_NORMAL
- en: For example, there are no straightforward ways to measuring prediction intervals
    for neural networks, but these models can possibly generate better predictions.
  prefs: []
  type: TYPE_NORMAL
- en: This is where **conformal predictions** come in. They represent a method of
    quantifying uncertainty in predictions that is both model-free and distribution-free.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we first explore the general idea behind conformal predictions
    and discover the **EnbPI** method for time series forecasting. Finally, we apply
    it in a small forecasting exercise.
  prefs: []
  type: TYPE_NORMAL
- en: '***Learn the latest time series analysis techniques with my*** [***free time
    series cheat sheet***](https://www.datasciencewithmarco.com/pl/2147608294) ***in
    Python! Get the implementation of statistical and deep learning techniques, all
    in Python and TensorFlow!***'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let’s get started!
  prefs: []
  type: TYPE_NORMAL
- en: Quick overview of conformal predictions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Conformal predictions represent an entire field of study to quantify uncertainty
    in predictions.
  prefs: []
  type: TYPE_NORMAL
- en: They are applied across various tasks like regression, binary classification,
    multilabel classification and time series forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: The general idea behind conformal predictions is to generate a calibrated prediction
    interval, at a given confidence level, that guarantees that a point will lie inside
    it.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, with conformal predictions, you can create an 80% confidence
    interval that guarantees that the future real value will fall inside that interval
    80% of the time.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike other methods of estimating predictions intervals, conformal predictions
    can be used with any modeling techniques. Plus, they do not assume a normal distribution,
    which is usually the case for statistical methods.
  prefs: []
  type: TYPE_NORMAL
- en: Conformal predictions for time series forecasting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, most methods of conformal predictions for regressions tasks rely on the
    *exchangeability hypothesis*.
  prefs: []
  type: TYPE_NORMAL
- en: This means that the order in which data arrives does not impact inference.
  prefs: []
  type: TYPE_NORMAL
- en: While this holds true for many regression scenarios, it is obviously not applicable
    in the context of time series forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: We know that time series are points ordered in time and that order must remain
    intact. In other words, Monday must always come after Sunday and before Tuesday.
  prefs: []
  type: TYPE_NORMAL
- en: Hence the need for a dedicated method for generating conformal prediction for
    time series.
  prefs: []
  type: TYPE_NORMAL
- en: In 2020, researchers Chen Xu and Yao Xie presented the **En**semble **b**atch
    **P**rediction **I**ntervals (**EnbPI**) method in their article [Conformal prediction
    for time series](https://arxiv.org/pdf/2010.09107.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: This method removes the data exchangeability requirement and can thus be applied
    in time series forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: Explore the EnbPI method
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The EnbPI algorithm is a general conformal prediction framework for time series.
  prefs: []
  type: TYPE_NORMAL
- en: At a high level, the EnbPI method is composed of a training phase and a prediction
    phase. The training phase is shown in blue, and the prediction phase is shown
    in green in the figure below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/949d09f06dad7c5ad47d0172fe4ded23.png)'
  prefs: []
  type: TYPE_IMG
- en: High-level overview of the EnbPI method. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: During the training phase, we fit a fixed number of *B* bootstrap models on
    non-overlapping subsets of the data. Usually, *B* is set to a value between 20
    and 50.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, the number of models that we can fit depends on the amount of data
    available, especially since the subsets cannot overlap.
  prefs: []
  type: TYPE_NORMAL
- en: Then, the predictions from each *B* model are aggregated in a leave-one-out
    (LOO) fashion, resulting in both LOO residuals and LOO models for predictions.
  prefs: []
  type: TYPE_NORMAL
- en: In the prediction phase, EnbPI uses each predictor to make a prediction on every
    single test data point. The predictions are aggregated to compute the center of
    the prediction interval. Then, using the residuals, prediction intervals are constructed
    using the quantiles from the residuals. The width is also optimized in the process,
    such that we get the narrowest width possible for a certain confidence level.
  prefs: []
  type: TYPE_NORMAL
- en: Note that in the prediction phase, as new values are observed, the intervals
    are updated to ensure their adpativeness.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand how the EnbPI method can generate prediction intervals
    for any forecasting model, let’s apply it in a small forecasting project using
    Python.
  prefs: []
  type: TYPE_NORMAL
- en: Apply EnbPI in forecasting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are now ready to use the EnbPI method to generate prediction intervals for
    our forecasting model.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily for us, the EnbPI algorithm is implemented and ready to use through
    the [MAPIE library](https://mapie.readthedocs.io/en/latest/), which stands for
    **M**odel **A**gnostic **P**rediction **I**nterval **E**stimator.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we use a dataset recording the daily visits to a website’s blog, publicly
    available [here](https://github.com/marcopeix/time-series-analysis/blob/master/data/medium_views_published_holidays.csv).
  prefs: []
  type: TYPE_NORMAL
- en: As always, the entire source code for this project is available on [GitHub](https://github.com/marcopeix/time-series-analysis/blob/master/data/medium_views_published_holidays.csv).
  prefs: []
  type: TYPE_NORMAL
- en: The natural first step is to make the necessary imports and read our data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/2ec997fc130ee11aa1619f43de9cfbed.png)'
  prefs: []
  type: TYPE_IMG
- en: First five rows of the dataset. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: From the figure above, we see that our dataset contains a timestamp, the number
    of unique visitors, a flag to indicate if a new article was published or not,
    and a flag to indicate a national holiday.
  prefs: []
  type: TYPE_NORMAL
- en: Since we will be applying a machine learning model, we need to construct some
    features. Specifically, we extract the year, month and day from the date. We also
    add a flag to indicate the weekend and add the past seven lagged values.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/fb9e34451685241862b53446ae0a330b.png)'
  prefs: []
  type: TYPE_IMG
- en: Dataset with engineered features. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: In the figure above, we notice that we have missing values. This is normal,
    since the first seven entries of the dataset do not have a complete list of seven
    past values.
  prefs: []
  type: TYPE_NORMAL
- en: We can either drop the first seven rows of data or use a model that can natively
    deal with missing data. In this case, I decided to use a [Histogram-based Gradient
    Boosting Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html),
    which natively supports data with missing values.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we split our data into a training and a test set. Here, I decided to
    reserve 112 time steps for the test set.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Optionally, we can visualize the split of our data resulting in the figure below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/d05e53bc8728cd7ed0e430053fd2308e.png)'
  prefs: []
  type: TYPE_IMG
- en: Visualizing the train/test split. The last 112 time steps are reserved for the
    test set. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Train a model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once the data is preprocessed and split, we can focus on training a forecasting
    model.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned, we implement here a histogram-based gradient boosting regressor.
    We also perform hyperparameter tuning to have the optimal model using random search.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Note that the best model is then saved using the `best_estimator_` attribute.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have an optimized model, we can now build prediction intervals using
    the EnbPI method.
  prefs: []
  type: TYPE_NORMAL
- en: Estimate prediction intervals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, we make the necessary imports for this step.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: To apply the EnbPI algorithm, we must use the `MapieTimeSeriesRegressor` object
    with `BlockBootstrap`. Remember that EnbPI fits a fixed number of models on non-overlapping
    blocks, and `BlockBootstrap` handles that for us.
  prefs: []
  type: TYPE_NORMAL
- en: Then, to evaluate the quality of our prediction intervals, we use the coverage
    and mean width score. Coverage reports the percentage of actual values that fall
    inside the intervals. The mean width score simply reports the average width of
    confidence intervals.
  prefs: []
  type: TYPE_NORMAL
- en: In an ideal situation, we have the narrowest intervals possible achieving the
    highest coverage possible.
  prefs: []
  type: TYPE_NORMAL
- en: With all of that in mind, let’s complete the setup to generate the intervals.
    Here, we wish to have 95% confidence intervals, and our model will make forecasts
    for the next time step.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In the code block above, note that we use `n_blocks=9` since the training set
    is divisible by 9\. Also, make sure to set `overlapping=False` as the EnbPI methods
    requires the blocks to be non-overlapping.
  prefs: []
  type: TYPE_NORMAL
- en: Then, the regression model is simply wrapped in the `MapieTimeSeriesRegressor`object,
    which we can then fit and use to make predictions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Now, we have access to both the predictions of the model and the confidence
    intervals. We can visualize them using the code block below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/a76e4dd6ee638d14360ccd44801151ef.png)'
  prefs: []
  type: TYPE_IMG
- en: Forecasting with a 95% confidence interval using the EnbPI method. Image by
    the author.
  prefs: []
  type: TYPE_NORMAL
- en: From the figure above, we can see that the model fails to predict the peaks
    in visitors. However, it seems that the prediction intervals contain the majority
    of the actual values.
  prefs: []
  type: TYPE_NORMAL
- en: To verify that, we can compute the coverage and mean interval width.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Here, we get a coverage of 58% and a mean interval width of 432.
  prefs: []
  type: TYPE_NORMAL
- en: Again, in an ideal situation, the coverage should approach the value of 95%,
    since that was the probability that we set earlier. However, due to the model
    not being able to forecast those peaks, the coverage clearly suffered.
  prefs: []
  type: TYPE_NORMAL
- en: To potentially improve the coverage, let’s implement the EnbPI method with partial
    fit so that the intervals can adapt as new values are observed.
  prefs: []
  type: TYPE_NORMAL
- en: Apply EnbPI with partial fit
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we learned earlier, the EnbPI method can benefit from new observed values
    and tweak the confidence intervals accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: This can be simulated by fitting the model on parts of data and computing the
    prediction intervals at each step.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In the code block above, the logic remains identical. This time, we are simply
    doing a for loop to gradually fit the model on more data, simulating the fact
    that new data is being observed and generating a new prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Again, we can visualize the predictions and their confidence intervals.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/c425bbf7fcbdaccee49f1f2030bac12c.png)'
  prefs: []
  type: TYPE_IMG
- en: Conformal prediction intervals using partial fit. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Visually, from the figure above, it seems that using partial fit does not make
    a significant difference.
  prefs: []
  type: TYPE_NORMAL
- en: For that reason, let’s compute the coverage and mean interval width for the
    partial fit protocol.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This gives us a coverage of 63% and an average interval width of 436.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/49f74b39cc090af0fd46607d2abdc8f9.png)'
  prefs: []
  type: TYPE_IMG
- en: Comparing the coverage and mean interval width for each protocol. Image by the
    author.
  prefs: []
  type: TYPE_NORMAL
- en: From the figure above, we can see that using partial fit allows us to increase
    the coverage while keeping the mean interval width fairly constant. Therefore,
    there is an advantage in using partial fit in this situation.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article we learned that conformal predictions group methodologies to
    estimate uncertainty in predictions. They can be applied for both classification
    and regression algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of time series, the Ensemble Prediction Interval method fits a fixed
    number of models over non-overlapping blocks of data to get the residuals and
    estimate the confidence bounds from their distribution.
  prefs: []
  type: TYPE_NORMAL
- en: To evaluate the quality of our intervals, we use the coverage and mean interval
    width. The coverage indicates the percentage of true values that fall inside the
    intervals. Ideally, this value should approach the confidence set by the user,
    while minimizing the width of the interval.
  prefs: []
  type: TYPE_NORMAL
- en: As we have seen, this is not always the case, as it also depends on the quality
    of the predictions of the model.
  prefs: []
  type: TYPE_NORMAL
- en: Still, thanks to MAPIE, we can generate conformal prediction intervals for virtually
    any model.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading! I hope that you enjoyed it and that you learned something
    new!
  prefs: []
  type: TYPE_NORMAL
- en: Looking to master time series forecasting? Then check out my course [Applied
    Time Series Forecasting in Python](https://www.datasciencewithmarco.com/offers/zTAs2hi6/checkout?coupon_code=ATSFP10).
    This is the only course that uses Python to implement statistical, deep learning
    and state-of-the-art models in 16 guided hands-on projects.
  prefs: []
  type: TYPE_NORMAL
- en: Cheers 🍻
  prefs: []
  type: TYPE_NORMAL
- en: Support me
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Enjoying my work? Show your support with [Buy me a coffee](http://buymeacoffee.com/dswm),
    a simple way for you to encourage me, and I get to enjoy a cup of coffee! If you
    feel like it, just click the button below 👇
  prefs: []
  type: TYPE_NORMAL
- en: '[![](../Images/79199b76a90721439ab41d9e1afcfb58.png)](https://www.buymeacoffee.com/dswm)'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chen Xu, Yao Xie — [Conformal Predictions for Time Series](https://arxiv.org/pdf/2010.09107.pdf)
  prefs: []
  type: TYPE_NORMAL
- en: 'MAPIE: [official documentation](https://mapie.readthedocs.io/en/latest/)'
  prefs: []
  type: TYPE_NORMAL
