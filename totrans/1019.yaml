- en: A guide to handling categorical variables in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/guide-to-handling-categorical-variables-in-python-854d0b65a6ae](https://towardsdatascience.com/guide-to-handling-categorical-variables-in-python-854d0b65a6ae)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*A guide on how to approach categorical variables for machine learning and
    data science purposes*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@theDrewDag?source=post_page-----854d0b65a6ae--------------------------------)[![Andrea
    D''Agostino](../Images/58c7c218815f25278aae59cea44d8771.png)](https://medium.com/@theDrewDag?source=post_page-----854d0b65a6ae--------------------------------)[](https://towardsdatascience.com/?source=post_page-----854d0b65a6ae--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----854d0b65a6ae--------------------------------)
    [Andrea D''Agostino](https://medium.com/@theDrewDag?source=post_page-----854d0b65a6ae--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----854d0b65a6ae--------------------------------)
    ·13 min read·Jun 16, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e99d8b89a83f713a851916579c9a484c.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Thomas Haas](https://unsplash.com/@thomashaas?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit)
    / [Unsplash](https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit)
  prefs: []
  type: TYPE_NORMAL
- en: Handling categorical variables in a data science or machine learning project
    is no easy task. This type of work requires deep knowledge of the field of application
    and a broad understanding of the multiple methodologies available.
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, the present article will focus on explaining the following
    concepts
  prefs: []
  type: TYPE_NORMAL
- en: '**what are categorical variables** and how to divide them into the different
    types'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: how to convert them to **numeric value** based on their type
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: tools and technologies for their management mainly using **Sklearn**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Proper handling of categorical variables can greatly improve the result of our
    predictive model or analysis. In fact, most of the information relevant to learning
    and understanding data could be contained in the available categorical variables.
  prefs: []
  type: TYPE_NORMAL
- en: Just think of tabular data, split by the variable `gender` or by a certain `color`.
    These spits, based on the number of categories, can bring out significant differences
    between groups and which can inform the analyst or the learning algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by defining what they are and how they can present themselves.
  prefs: []
  type: TYPE_NORMAL
- en: Definition of categorical variable
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Categorical variables are a type of variable used in statistics and data science
    to represent qualitative or nominal data. These variables can be defined as a
    class or category of data that cannot be quantified continuously, but only discretely.
  prefs: []
  type: TYPE_NORMAL
- en: For example, an example of a categorical variable might be a **person’s eye
    color,** which can be blue, green, or brown.
  prefs: []
  type: TYPE_NORMAL
- en: Most learning models don’t work with data in a categorical format. We must first
    convert them into numeric format so that the information is preserved.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Categorical variables can be classified into two types:'
  prefs: []
  type: TYPE_NORMAL
- en: Nominal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ordinal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Nominal variables** are variables that are not constrained by a precise order.
    Gender, color, or brands are examples of nominal variables since they are not
    sortable.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ordinal variables** are instead categorical variables divided into logically
    orderable levels. A column in a dataset that consists of levels such as *First,
    Second, and Third* can be considered an ordinal categorical variable.'
  prefs: []
  type: TYPE_NORMAL
- en: You can go deeper into the breakdown of categorical variables by considering
    **binary and cyclic variables.**
  prefs: []
  type: TYPE_NORMAL
- en: 'A **binary variable** is simple to understand: it is a categorical variable
    that can only take on two values.'
  prefs: []
  type: TYPE_NORMAL
- en: A **cyclic variable**, on the other hand, is characterized by a repetition of
    its values. For example, the days of the week are cyclical, and so are the seasons.
  prefs: []
  type: TYPE_NORMAL
- en: How to transform categorical variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we’ve defined what categorical variables are and what they look like,
    let’s tackle the question of transforming them using a practical example — a Kaggle
    dataset called *cat-in-the-dat*.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is an open source dataset at the basis of an introductory competition to
    the management and modeling of categorical variables, called the Categorical Feature
    Encoding Challenge II. You can download the data directly from the link below.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.kaggle.com/c/cat-in-the-dat-ii?source=post_page-----854d0b65a6ae--------------------------------)
    [## Categorical Feature Encoding Challenge II'
  prefs: []
  type: TYPE_NORMAL
- en: Binary classification, with every feature a categorical (and interactions!)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.kaggle.com](https://www.kaggle.com/c/cat-in-the-dat-ii?source=post_page-----854d0b65a6ae--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: The peculiarity of this dataset is that it contains exclusively categorical
    data. So it becomes the perfect use case for this guide. It includes nominal,
    ordinal, cyclic, and binary variables.
  prefs: []
  type: TYPE_NORMAL
- en: We will see techniques for transforming each variable into a format usable by
    a learning model.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset looks like this
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7dfe5816387a98c71f30b084a1b0cf26.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Since the target variable can only take on two values, this is a binary classification
    task. We will use the AUC metric to evaluate our model.
  prefs: []
  type: TYPE_NORMAL
- en: Now we are going to apply techniques for managing categorical variables using
    the mentioned dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Label Encoding (mapping to an arbitrary number)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The simplest technique there is for converting a category into a usable format
    is to assign each category to an arbitrary number.
  prefs: []
  type: TYPE_NORMAL
- en: Take for example the `ord_2` column which contains the categories
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The mapping could be done like this using Python and Pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'However, this method has a problem: you have to manually declare the mapping.
    For a small number of categories this is not a problem, but for a large number
    it could be.'
  prefs: []
  type: TYPE_NORMAL
- en: For this we will use Scikit-Learn and the `LabelEncoder` object to achieve the
    same result in a more flexible way.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Mapping is controlled by Sklearn. We can visualize it like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Note the `.fillna(“NONE")` in the code snippet above. In fact, Sklearn’s label
    encoder does not handle empty values and will give an error when applying it if
    any are found.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most important things to keep in mind for the correct handling of
    categorical variables is to always handle the empty values. In fact, most of the
    relevant techniques don’t work if these aren’t taken care of.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The label encoder maps arbitrary numbers to each category in the column, without
    an explicit declaration of the mapping. This is convenient, but introduces a problem
    for some predictive models: *it introduces the need to scale the data if the column
    is not the target one*.'
  prefs: []
  type: TYPE_NORMAL
- en: In fact, machine learning beginners often ask what the difference is between
    label encoder and one hot encoder, which we will see shortly. **The label encoder,
    by design, should be applied to the labels, ie the target variable we want to
    predict and not to the other columns.**
  prefs: []
  type: TYPE_NORMAL
- en: Having said that, some models also very relevant in the field work well even
    with an encoding of this type. I’m talking about tree models, among which XGBoost
    and LightGBM stand out.
  prefs: []
  type: TYPE_NORMAL
- en: So feel free to use label encoders if you decide to use tree models, but otherwise,
    we have to use one hot encoding.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. One Hot Encoding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As I already mentioned in my article about [vector representations in machine
    learning](https://medium.com/towards-data-science/vector-representations-for-machine-learning-5047c50aaeff),
    one hot encoding is a very common and famous vectorization technique (i.e. converting
    a text into a number).
  prefs: []
  type: TYPE_NORMAL
- en: 'It works like this: for each category present, a square matrix is created whose
    only possible values are 0 and 1\. This matrix informs the model that among all
    possible categories, this observed row has the value denoted by 1.'
  prefs: []
  type: TYPE_NORMAL
- en: 'An example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The array is of size *n_categories*. This is very useful information, because
    one hot encoding typically requires **a sparse representation** of the converted
    data.
  prefs: []
  type: TYPE_NORMAL
- en: What does it mean? It means that for large numbers of categories, the matrix
    could become equally large. Being populated only by values of 0 and 1 and since
    only one of the positions can be populated by a 1, this makes the one hot representation
    very redundant and cumbersome.
  prefs: []
  type: TYPE_NORMAL
- en: A sparse matrix solves this problem — only the positions of the 1’s are saved,
    while values equal to 0 are not saved. This simplifies the mentioned problem and
    allows us to save a huge array of information in exchange for very little memory
    usage.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see what such an array looks like in Python, applying the code from before
    again
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Python returns an object by default, not a list of values. To get such a list,
    you need to use `.toarray()`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Don’t worry if you don’t fully understand the concept: we will soon see how
    to apply the label and one hot encoder to the dataset to train a predictive model.'
  prefs: []
  type: TYPE_NORMAL
- en: Label encoding and one hot encoding are the most important techniques for handling
    categorical variables. Knowing these two techniques will allow you to handle most
    cases that involve categorical variables.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 3\. Transformations and aggregations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another method of converting from categorical to numeric format is to perform
    a transformation or aggregation on the variable.
  prefs: []
  type: TYPE_NORMAL
- en: By grouping with `.groupby()` it is possible to use the count of the values
    present in the column as the output of the transformation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: using `.transform()` we can replace these numbers to the corresponding cell
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: It is possible to apply this logic also with other mathematical operations —
    the method that most improves the performance of our model should be tested.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Create new categorical features from categorical variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We look at the ord_1 column together with ord_2
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b9ed1890cb1951a94860379758143a9f.png)'
  prefs: []
  type: TYPE_IMG
- en: image by author.
  prefs: []
  type: TYPE_NORMAL
- en: We can create new categorical variables by merging existing variables. For example,
    we can merge ord_1 with ord_2 to create a new feature
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This technique can be applied in practically any case. The idea that must guide
    the analyst is to improve the performance of the model by adding information that
    was originally difficult to understand to the learning model.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Use NaN as a categorical variable
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Very often null values are removed. This is typically not a move I recommend,
    **as the NaNs contain potentially useful information to our model.**
  prefs: []
  type: TYPE_NORMAL
- en: One solution is to treat NaNs as a category in their own right.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the ord_2 column again
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Now let’s try applying the `.fillna(“NONE")` to see how many empty cells exist
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: As a percentage, NONE represents about 3% of the entire column. It’s a pretty
    noticeable amount. Exploiting the NaN makes even more sense and can be done with
    the One Hot Encoder mentioned earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Tracking rare categories
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s remember what the OneHotEncoder does: it creates a sparse matrix whose
    number of columns and rows is equal to the number of unique categories in the
    referenced column. *This means that we must also take into account the categories
    that could be present in the test set and that could be absent in the train set.*'
  prefs: []
  type: TYPE_NORMAL
- en: The situation is similar for the LabelEncoder — there may be categories in the
    test set but which are not present in the training set and this could create problems
    during the transformation.
  prefs: []
  type: TYPE_NORMAL
- en: We solve this problem by concatenating the datasets. This will allow us to apply
    the encoders to all data and not just the training data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/e8556ff3c302b82438c4094d26f5789f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: This methodology helps us if we have the test set. If we don’t have the test
    set, we will take into account a value like NONE when a new category becomes part
    of our training set.
  prefs: []
  type: TYPE_NORMAL
- en: Model categorical data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now let’s move on to the training of a simple model. We will follow the steps
    from the article on how to design and implement a cross-validation at the following
    link 👇
  prefs: []
  type: TYPE_NORMAL
- en: '[](/what-is-cross-validation-in-machine-learning-14d2a509d6a5?source=post_page-----854d0b65a6ae--------------------------------)
    [## What is cross-validation in machine learning'
  prefs: []
  type: TYPE_NORMAL
- en: Learn what cross-validation is — a fundamental technique for building generalizable
    models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/what-is-cross-validation-in-machine-learning-14d2a509d6a5?source=post_page-----854d0b65a6ae--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: We start from scratch, importing our data and creating our folds with Sklearn’s
    `StratifiedKFold`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This little snippet of code will create a Pandas dataframe with 5 groups to
    test our model against.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bb127860185f608bac6b4229aa4ab9cf.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s define a function that will test a logistic regression model on each
    group.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: I invite the interested reader to read the article on cross-validation to understand
    in more detail the functioning of the code shown.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s see how instead to apply a tree model like XGBoost, which also works
    well with a LabelEncoder.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In conclusion, there are also other techniques worth mentioning for handling
    categorical variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Target-based encoding**, where the category is converted into the average
    value assumed by the target variable in correspondence with it'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**The embeddings of a neural network**](https://medium.com/towards-data-science/vector-representations-for-machine-learning-5047c50aaeff),
    which can be used to represent the textual entity'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In summary, here are the essential steps for a correct management of categorical
    variables
  prefs: []
  type: TYPE_NORMAL
- en: always treat null values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: apply LabelEncoder or OneHotEncoder based on the type of variable and template
    we want to use
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: reason in terms of variable enrichment, considering NaN or NONE as categorical
    variables that can inform the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model the data!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thank you for your time,
  prefs: []
  type: TYPE_NORMAL
- en: Andrea
  prefs: []
  type: TYPE_NORMAL
- en: Recommended Reads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the interested, here are a list of books that I recommended for each ML-related
    topic. There are ESSENTIAL books in my opinion and have greatly impacted my professional
    career.
  prefs: []
  type: TYPE_NORMAL
- en: '*Disclaimer: these are Amazon affiliate links. I will receive a small commission
    from Amazon for referring you these items. Your experience won’t change and you
    won’t be charged more, but it will help me scale my business and produce even
    more content around AI.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Intro to ML:** [*Confident Data Skills: Master the Fundamentals of Working
    with Data and Supercharge Your Career*](https://amzn.to/3ZzKTz6)by Kirill Eremenko'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sklearn / TensorFlow:** [*Hands-On Machine Learning with Scikit-Learn, Keras,
    and TensorFlow*](https://amzn.to/433F4Nm) by Aurelien Géron'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NLP:** [*Text as Data: A New Framework for Machine Learning and the Social
    Sciences*](https://amzn.to/3zvH43j)by Justin Grimmer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sklearn / PyTorch:** [*Machine Learning with PyTorch and Scikit-Learn: Develop
    machine learning and deep learning models with Python*](https://amzn.to/3Gcavve)
    by Sebastian Raschka'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data Viz:** [*Storytelling with Data: A Data Visualization Guide for Business
    Professionals*](https://amzn.to/3HUtGtB) by Cole Knaflic'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Useful Links (written by me)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Learn how to perform a top-tier Exploratory Data Analysis in Python**: [*Exploratory
    Data Analysis in Python — A Step-by-Step Process*](/exploratory-data-analysis-in-python-a-step-by-step-process-d0dfa6bf94ee)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Learn the basics of PyTorch:** [*Introduction to PyTorch: from training loop
    to prediction*](https://medium.com/towards-data-science/introduction-to-pytorch-from-training-loop-to-prediction-a70372764432)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Learn the basics of TensorFlow**: [*Get started with TensorFlow 2.0 — Introduction
    to deep learning*](https://medium.com/towards-data-science/a-comprehensive-introduction-to-tensorflows-sequential-api-and-model-for-deep-learning-c5e31aee49fa)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Perform text clustering with TF-IDF in Python**: [*Text Clustering with TF-IDF
    in Python*](https://medium.com/mlearning-ai/text-clustering-with-tf-idf-in-python-c94cd26a31e7)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**If you want to support my content creation activity, feel free to follow
    my referral link below and join Medium’s membership program**. I will receive
    a portion of your investment and you’ll be able to access Medium’s plethora of
    articles on data science and more in a seamless way.'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/@theDrewDag/membership?source=post_page-----854d0b65a6ae--------------------------------)
    [## Join Medium with my referral link - Andrea D''Agostino'
  prefs: []
  type: TYPE_NORMAL
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every story…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@theDrewDag/membership?source=post_page-----854d0b65a6ae--------------------------------)
  prefs: []
  type: TYPE_NORMAL
