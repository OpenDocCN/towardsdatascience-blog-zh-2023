- en: A Visual Microphone? The Revolutionary Tech That Can Extract Audio from Images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/a-visual-microphone-the-revolutionary-tech-that-can-extract-audio-from-images-8a22d111e42b](https://towardsdatascience.com/a-visual-microphone-the-revolutionary-tech-that-can-extract-audio-from-images-8a22d111e42b)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The power of subtle motions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://pmarinko.medium.com/?source=post_page-----8a22d111e42b--------------------------------)[![Pavle
    Marinkovic](../Images/cfef9474edb54402a23bfad60f0aa227.png)](https://pmarinko.medium.com/?source=post_page-----8a22d111e42b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8a22d111e42b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8a22d111e42b--------------------------------)
    [Pavle Marinkovic](https://pmarinko.medium.com/?source=post_page-----8a22d111e42b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8a22d111e42b--------------------------------)
    ·9 min read·Jan 30, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3b01b113bf1aeaa912c3f2734aa47244.png)'
  prefs: []
  type: TYPE_IMG
- en: What if we could get sound just from a video recording? Image created by [Midjourney](https://midjourney.com/)
  prefs: []
  type: TYPE_NORMAL
- en: What if we could retrieve sounds without a single sound recorder?
  prefs: []
  type: TYPE_NORMAL
- en: If you can *perceive* a vibration you can unveil the world around you.
  prefs: []
  type: TYPE_NORMAL
- en: Vibrations are everywhere but many times they’re so **subtle** we need sophisticated
    equipment to see them.
  prefs: []
  type: TYPE_NORMAL
- en: But it pays off, big time.
  prefs: []
  type: TYPE_NORMAL
- en: A **motion pattern** can reveal useful information about an object such as its
    internal structure (e.g. a fruit’s ripeness with [ultrasound](https://medium.com/p/c4338b32a9e9))
    and its properties (e.g. flexibility of pipes), but it can also serve as a **resonator
    box** for surrounding sounds.
  prefs: []
  type: TYPE_NORMAL
- en: This acoustic feature has opened a gate into new data that we weren’t able to
    access ever before.
  prefs: []
  type: TYPE_NORMAL
- en: By capturing and analyzing these vibrations, we can **recover sounds** like
    *speech* and *music* that would otherwise be lost.
  prefs: []
  type: TYPE_NORMAL
- en: We just need to *see* the vibrations.
  prefs: []
  type: TYPE_NORMAL
- en: How to extract sound from visuals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When sound waves hit an object, it vibrates in a specific pattern.
  prefs: []
  type: TYPE_NORMAL
- en: These vibrations are enough to **generate a visual signal**, even if they’re
    very subtle. Our eyes can’t see it, but a high-speed camera of the object can
    detect this motion and retrieve the sounds that caused these surface distortions.
  prefs: []
  type: TYPE_NORMAL
- en: You’re essentially translating the object’s movement back into sound.
  prefs: []
  type: TYPE_NORMAL
- en: This technology allows us to listen to speech and music inside a room by analyzing
    the movement of objects in it at the time the sound(s) was made.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This means that you don’t need a sound recorder in the room to get what people
    were talking about or the sounds they heard while being there.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The object serves as a proxy for all the sonic world you missed for being outside.
  prefs: []
  type: TYPE_NORMAL
- en: It acts as a beacon.
  prefs: []
  type: TYPE_NORMAL
- en: By analyzing the motion pattern of the object, it is possible to extract the
    original sonic information that caused these vibrations.
  prefs: []
  type: TYPE_NORMAL
- en: And this tech is known as the **visual microphone**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Your newest spy: potato chips'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’re now able to reveal a secret conversation inside a room with a bag of chips.
  prefs: []
  type: TYPE_NORMAL
- en: Sounds ridiculous, but that’s exactly what a [group of researchers](https://people.csail.mit.edu/mrub/papers/VisualMic_SIGGRAPH2014.pdf)
    from MIT, Microsoft, and Adobe did in a series of experiments back in 2014.
  prefs: []
  type: TYPE_NORMAL
- en: They first tried extracting the sound from the vibrations of a bag of chips
    while a loudspeaker played the song “Mary Had a Little Lamb”.
  prefs: []
  type: TYPE_NORMAL
- en: They would record the bag’s movements with a high-speed camera and extract the
    pitch and duration of each note with their algorithm. These signals were further
    processed to get rid of some of the underlying noise.
  prefs: []
  type: TYPE_NORMAL
- en: 'This was the result:'
  prefs: []
  type: TYPE_NORMAL
- en: Seeing sound. Retrieved from one of the [author’s Youtube](https://www.youtube.com/@mikirubinstein/videos).
  prefs: []
  type: TYPE_NORMAL
- en: The same worked with [leaves from a potted plant](http://people.csail.mit.edu/mrub/VisualMic/Demos/MaryMIDI_Plant.mp3).
  prefs: []
  type: TYPE_NORMAL
- en: So they knew that music can be extracted from these odd objects, but what about
    getting other types of sounds as well?
  prefs: []
  type: TYPE_NORMAL
- en: They tried extracting **human speech** this time around with an additional challenge.
    The camera would be placed behind a thick **soundproof window** while recording
    a back of chips laying on the floor in the room where the speech took place.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f157110f6124ec90233b1ba602cb2dc2.png)'
  prefs: []
  type: TYPE_IMG
- en: Setup of the experiment. Retrieved from [MIT’s paper.](https://people.csail.mit.edu/mrub/papers/VisualMic_SIGGRAPH2014.pdf)
  prefs: []
  type: TYPE_NORMAL
- en: 'The recording of a **male’s voice reciting the same song** (“Mery had a little
    lamb”) was compared between a cellphone’s recording next to the chip bag, and
    the sound recovered through the high-speed camera:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/10517368b4c2b63333c5362ab745ad9f.png)'
  prefs: []
  type: TYPE_IMG
- en: Spectrogram of the cellphone’s recording (b) vs high-speed video (c)
  prefs: []
  type: TYPE_NORMAL
- en: Although subtle, there’s some resemblance between the spectrograms which becomes
    even more evident in the [recovered sound](http://people.csail.mit.edu/mrub/VisualMic/Demos/MarySpeech_Chips_20kHz.mp3).
  prefs: []
  type: TYPE_NORMAL
- en: Can you understand what is being said?
  prefs: []
  type: TYPE_NORMAL
- en: Remember that this is the early phase of new tech. Imagine the improvements
    we’ll have in the years to come.
  prefs: []
  type: TYPE_NORMAL
- en: What makes a sound more recoverable than others?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the limited range of experiments carried out by these scientists, they
    were able to identify some features that made the process easier. They found that:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Lower frequencies** are easier to recover since they create more movement
    in the object and are less attenuated by the material’s composition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Higher frequencies** can be recovered more easily with lighter objects since
    they’re easier to move and thus create a motion pattern to extract afterward.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Light and rigid objects** serve as a good visual microphones such as thin
    plates, membranes, bags of chips, leaves, and aluminum foil.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Identifiable sounds** (e.g. melody, words from a speech, etc.) can be recovered
    from a 3 to the 4-meter range for a 400mm lens. Recovery can increase with a more
    powerful zoom lens.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of course, more research is needed but the implications of these results are
    already astounding.
  prefs: []
  type: TYPE_NORMAL
- en: Any visible object can be turned into a visual microphone.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It’s both fascinating and scary.
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Researchers used a high-speed video camera (1kHz — 20kHz) to record an object
    being hit with sound waves. They would look at extremely subtle changes in its
    surface and display it on a graph that showed different sound properties like
    pitch and duration.
  prefs: []
  type: TYPE_NORMAL
- en: Then, they would process this video with their algorithm and retrieve the sound
    from its surface motion.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/56fa0a19fd29d908b0e0ed2166506008.png)'
  prefs: []
  type: TYPE_IMG
- en: Visual representation of the extraction process. Retrieved from the [MIT paper.](https://dspace.mit.edu/handle/1721.1/100023)
  prefs: []
  type: TYPE_NORMAL
- en: This technology allows us to capture very small movements of an object in a
    video, even if they’re only a tiny fraction of a pixel in size (ranging from one
    hundredth to one-thousandth of a pixel). By analyzing all the pixels in the video,
    we can detect and interpret these subtle movements.
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s a 3-step process:'
  prefs: []
  type: TYPE_NORMAL
- en: The first step is to break down the video into smaller parts based on different
    shapes and sizes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, look at each of these small parts and identify any movement that will
    then be averaged and aligned to create a single motion signal of the object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Combine all the information about the movement and use special techniques to
    remove any noise and improve the sound quality. From this input, they get the
    sound they want to recover.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This technology enables the recovery of sound inside a room, even if it was
    not directly recorded.
  prefs: []
  type: TYPE_NORMAL
- en: However, in their experiments, researchers used rather **loud sounds** ranging
    from 80dB (an actor’s stage voice) to 100dB (e.g. jet engine from a 100m distance)
    which limits the volume range that can be extracted from an object…for now.
  prefs: []
  type: TYPE_NORMAL
- en: The research is still in its early stage and it’s not yet clear if it would
    be feasible to use it in **mass production**. The study notes that the method
    requires high-speed video recording and advanced image processing techniques to
    extract the sound, which is expensive, and that certain factors such as lighting
    and the object’s material and shape can affect the quality of the recovered sound,
    limiting the conditions under which it’s useful.
  prefs: []
  type: TYPE_NORMAL
- en: Use cases for this sound extraction tech
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Surveillance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If any object can act as a visual microphone, the first thing that comes to
    mind is using it for security reasons.
  prefs: []
  type: TYPE_NORMAL
- en: Governments and security agencies can use visual microphones to **recover sound
    from surveillance footage** to gain valuable information. For example, during
    a protest or a public event, authorities can use visual microphones to recover
    speech from videos of individuals in a crowd to identify potential threats or
    criminal activity.
  prefs: []
  type: TYPE_NORMAL
- en: Consider that the researchers of this academic paper also discussed the possibility
    of recovering sound from normal video cameras with promising results. They were
    able to recover frequencies 5 times higher than the frame rate of the video. This
    was the [result](https://youtu.be/FKXOucXB4a8?t=238).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: By using a denoise of the signal with their speech enhancement algorithm and
    lowpass filter to remove undesired frequencies, you could boost the quality even
    more.
  prefs: []
  type: TYPE_NORMAL
- en: Forensics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Similar to the above use case, law enforcement agencies could also use this
    tech to **recover audio from crime scenes** or accident sites.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if a crime is committed and the suspects are caught on camera,
    the visual microphone can be used to extract any audio that was present during
    the recording. This could include the suspects’ voices, any background noise,
    or even the sound of the crime being committed.
  prefs: []
  type: TYPE_NORMAL
- en: The audio evidence could later be used in court to help identify suspects, establish
    a timeline of events, or even link suspects to the crime.
  prefs: []
  type: TYPE_NORMAL
- en: Film and Television Production
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Production companies can use visual microphones to **recover audio from silent
    footage or to enhance existing audio recordings**.
  prefs: []
  type: TYPE_NORMAL
- en: For example, during a film shoot, a visual microphone can be used to recover
    dialogue from a scene shot on a noisy set, making it usable for the final cut.
  prefs: []
  type: TYPE_NORMAL
- en: 'The authors of the study briefly [discussed](http://people.csail.mit.edu/mrub/VisualMic/)
    the idea of retrieving sound from silent films. Sadly, it’s still not possible:'
  prefs: []
  type: TYPE_NORMAL
- en: “because of their low frame-rates (12–26 fps according to [Wikipedia](http://en.wikipedia.org/wiki/Silent_film))
    and low image quality, we do not believe they have enough visual information for
    our technique to recover sound”.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Retrieval is now only possible with modern cameras where video has missing audio
    for whatever reason.
  prefs: []
  type: TYPE_NORMAL
- en: Music Recording
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Music recording studios could use this tech to recover audio from **music videos
    or live performances**.
  prefs: []
  type: TYPE_NORMAL
- en: By placing a high-speed camera near the stage and filming the performance it
    could extract the sound from the video of the performance. The extracted sound
    would be of a much higher quality than traditional microphone recordings, as it
    would not be affected by ambient noise or the acoustics of the room. Think of
    an ultra HD live album release.
  prefs: []
  type: TYPE_NORMAL
- en: This technology could also be used in a **studio setting** to record music,
    where the visual microphone could be used to capture the sounds of individual
    instruments. This could be especially useful for recording orchestral music, where
    traditional microphone placements may not be able to capture the full sound of
    all instruments.
  prefs: []
  type: TYPE_NORMAL
- en: Taking it a step further with AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/58376791f17ac2f9b6c6739901e46af3.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Charanjeet Dhiman](https://unsplash.com/@charanjeet_dhiman)
  prefs: []
  type: TYPE_NORMAL
- en: Imagine being a fly on the wall during private conversations between The Beatles.
  prefs: []
  type: TYPE_NORMAL
- en: You might feel this way in Peter Jackson’s new documentary, “[Get Back](https://musictech.com/news/music/peter-jacksons-beatles-documentary-uses-ai-to-reveal-hidden-studio-conversations/)”.
    Peter used AI magic to **reveal hidden studio talks between the fab four**. The
    film explores the band’s relationship as they created their final studio effort,
    “Let It Be” in 1970.
  prefs: []
  type: TYPE_NORMAL
- en: But the catch is, the band was trying to keep these chats a secret.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of letting the director in on the secret, they turned the filming into
    a game of hide and seek by using their instruments to cover up their conversations.
    But, with the help of some tech wizards and something called “demixing”, Peter
    and his team were able to strip away the guitar noise and expose the private conversations
    for all to hear.
  prefs: []
  type: TYPE_NORMAL
- en: Not only that but the audio from the band’s Twickenham Studios rehearsals was
    also cleaned up using AI to isolate the instruments and vocals. This allowed mono
    tracks to become stereo and enrich the music in a new fascinating way.
  prefs: []
  type: TYPE_NORMAL
- en: Where do we go from now on?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now imagine combining this AI tech with sound extraction from visual information.
  prefs: []
  type: TYPE_NORMAL
- en: Could we retrieve the original sound from silent footage, such as early films
    or home movies, that was not originally recorded with sound? We could use AI to
    add lip-syncing or voice reconstruction and bring the characters in the footage
    to life in a more realistic and immersive way.
  prefs: []
  type: TYPE_NORMAL
- en: Or recover sounds that were not audible during filming (e.g. background noise
    or muffled conversation) which could then be used to create a more immersive and
    historically authentic soundtrack for the film?
  prefs: []
  type: TYPE_NORMAL
- en: And this last one is very sci-fi. What if one day we could recover audio from
    ancient or historical artifacts, such as pottery or statues, that may have been
    used in rituals or ceremonies to hear what’s been stored inside of them for centuries?
  prefs: []
  type: TYPE_NORMAL
- en: A naive little fantasy of mine.
  prefs: []
  type: TYPE_NORMAL
- en: Only time will tell.
  prefs: []
  type: TYPE_NORMAL
- en: 'Interested in other **data** that can be turned into **sound**? Then, check
    this other article:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/sonification-when-you-go-beyond-the-visual-representation-of-data-cf6c7229a557?source=post_page-----8a22d111e42b--------------------------------)
    [## Sonification — When You Go Beyond the Visual Representation Of Data'
  prefs: []
  type: TYPE_NORMAL
- en: Communicate and find patterns with sound as your guide
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/sonification-when-you-go-beyond-the-visual-representation-of-data-cf6c7229a557?source=post_page-----8a22d111e42b--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'Or find how **sound** can be used to change your **sense of taste**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://pmarinko.medium.com/how-to-become-a-music-sommelier-2966903da766?source=post_page-----8a22d111e42b--------------------------------)
    [## How to Become a Music Sommelier'
  prefs: []
  type: TYPE_NORMAL
- en: Add some sonic seasoning to people’s tasting experience
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: pmarinko.medium.com](https://pmarinko.medium.com/how-to-become-a-music-sommelier-2966903da766?source=post_page-----8a22d111e42b--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '*If you enjoy reading stories like these and would like to support writers
    on Medium, consider* [*signing up to become a Medium member.*](https://pmarinko.medium.com/membership)
    *It’s just $5 a month and you’ll have unlimited access to articles from amazing
    writers all over the world.*'
  prefs: []
  type: TYPE_NORMAL
