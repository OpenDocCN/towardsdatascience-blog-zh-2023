- en: Unleashing the Power of Prompt Engineering for Data Scientists
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/unleashing-the-power-of-prompt-engineering-for-data-scientists-16b6d1f2bf85](https://towardsdatascience.com/unleashing-the-power-of-prompt-engineering-for-data-scientists-16b6d1f2bf85)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How and why write effective prompts if you work with data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://federicotrotta.medium.com/?source=post_page-----16b6d1f2bf85--------------------------------)[![Federico
    Trotta](../Images/e997e3a96940c16ab5071629016d82fd.png)](https://federicotrotta.medium.com/?source=post_page-----16b6d1f2bf85--------------------------------)[](https://towardsdatascience.com/?source=post_page-----16b6d1f2bf85--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----16b6d1f2bf85--------------------------------)
    [Federico Trotta](https://federicotrotta.medium.com/?source=post_page-----16b6d1f2bf85--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----16b6d1f2bf85--------------------------------)
    ·18 min read·Jun 7, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/861db2c8c6d2d4a0826e0d619b005bff.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [Gerd Altmann](https://pixabay.com/it/users/geralt-9301/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=4126485)
    on [Pixabay](https://pixabay.com/it//?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=4126485)
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to GPT models, prompt engineering is becoming a field of interest in
    Data Science. In the beginning, we’ve seen a lot of curious people across the
    globe testing ChatGPT to trick it. Then, while this trend has (finally!) finished,
    the movement of people using it to automate boring stuff or to be helped with
    general tasks, is steadily increased.
  prefs: []
  type: TYPE_NORMAL
- en: Developers and Data Scientists are the ones that are having great benefits from
    using prompt systems like ChatGPT. So, in this article, we’ll see an overview
    of prompt engineering and how to write efficient prompts for Data Scientists.
  prefs: []
  type: TYPE_NORMAL
- en: I know you’re benefiting a lot from ChatGPT, don’t you?! But the truth is that
    sometimes we’re not just able to obtain what we’d like from it as Data Scientists.
    So, let’s see how we can improve our prompt skills with some easy precautions.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what you’ll read in this article:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The importance of prompt engineering today
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The word of the last 150 years could be “automation”. In fact, the world has
    evolved from making stuff by hand to assembly lines. And while crafts are still
    (highly) valuable, “mass production” has become a word coupled with “automation”.
  prefs: []
  type: TYPE_NORMAL
- en: The mechanization and automation of the work are increasing and this has permeated
    different fields, not only the ones directly involved in producing goods like,
    for example, manufacturing or agriculture.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we take a look at a Software, for example, the first thing that we should
    see is automation. When I was learning Python about three years ago a mentor,
    reviewing my first project, told me: “Federico, developing software means automating
    stuff!”. And, if you’re asking, then yes: my first project was a mess (as with
    everything we do for the first time!).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Anyway, here’s the truth: human beings have evolved with a clear goal: automating
    stuff. This can be related to automating boring stuff or “hard work”. It doesn’t
    matter; the point is the direction towards automation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this scenario, prompt engineering is just the latest tool that can help
    us automate stuff. On a “code sight,” this means automating the automatable: software
    development is automation at its core, and using prompt engineering means pushing
    automation even harder.'
  prefs: []
  type: TYPE_NORMAL
- en: The truth, in fact, is that even in software development there are boring tasks,
    even if, for example, we’ve created classes that can be imported (but need to
    be modified a little bit).
  prefs: []
  type: TYPE_NORMAL
- en: 'Think of that for a moment: as a Data Scientist, how many prototypes per week
    do you develop? And how much time do you have to develop them?'
  prefs: []
  type: TYPE_NORMAL
- en: You create a prototype and then what? The specifications of the projects change,
    the customer changes ideas, your boss is not satisfied…well, you named it.
  prefs: []
  type: TYPE_NORMAL
- en: So, why should we spend a lot of effort on low-value but time-consuming tasks
    rather than automate them? Here are the core concepts of prompt engineering, to
    me.
  prefs: []
  type: TYPE_NORMAL
- en: So, let’s see how prompt engineering can affect Data scientists, and then let’s
    see how we can create useful and efficient prompts.
  prefs: []
  type: TYPE_NORMAL
- en: How prompt engineering can affect Data Scientists
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every new technology has some pros and some cons, and so does prompt engineering.
    First, let’s see the pros and then the cons.
  prefs: []
  type: TYPE_NORMAL
- en: 'Prompt Engineering for Data Scientists: pros'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Faster learning**. If you’re a beginner in Data Science (and in Software
    Development, in general) you’ll find very beneficial a tool like ChatGPT because
    it’s like having a senior developer available 24/7\. Anyway, it shouldn’t be trusted
    as an oracle, primarily because it still makes some errors. I’ve written a dedicated
    article on how to effectively start coding in the era of ChatGPT [here](https://medium.com/towards-data-science/how-to-effectively-start-coding-in-the-era-of-chatgpt-cfc5151e1c42)
    if you’re interested.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Faster prototypes**. In my opinion, one of the most important parts of the
    job of a Data Scientist is prototyping. In fact, very often we need to give a
    fast answer based on data (often, with little available data. Very often, with
    dirty data). So, a prototype is what can give the sense of the answer a customer
    needs, giving us time for: a) ask/get for more data, b) ask/get for more specifications,
    c) clean data, and d) make necessary research.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Faster debugging and error management**. We have to be honest: debugging
    and error management in software development is more a curse than a delight. This
    is also true when we develop software for Machine/Deep Learning algorithms. ChatGPT
    is a great tool for debugging and error management: with the right prompt, it
    can find errors and bugs in a matter of seconds, making us save a lot of time
    and effort. Just a quick reminder: since ChatGPT (and similar tools) work in the
    cloud and also they may use our prompts to train their algorithms, remember to
    not write code with sensible information because they can get you in trouble in
    cases of data breaches.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Faster research**. An important part of the job of a Data Scientist is making
    research. We absolutely need to research a lot of stuff to solve our problems
    like: info on particular libraries and their usages, info related to the domain
    knowledge of the problem we’re facing, etc…Well, a good prompt is generally useful
    to let us grab the info we need. The only thing to remember is that we always
    need to verify the correctness of the output by deepening it on the internet or
    on books. Especially with code, is always important to read the documentation:
    otherwise, the risk is to copy and paste the code without actually understanding
    it.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Prompt Engineering for Data Scientists: cons'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Possibility to lose your job**. Yes, we have to say it: AI tools can make
    us lose our job. It seems a contradiction: the necessity for data professionals
    in the market is increasing in these months, but tools like ChatGPT may substitute
    us. Well, let’s say the truth: this possibility is far away at the time because
    AI tools need the supervision of an expert, as we’ve also discussed in the pros.
    Sure, you can ask for some code and for some data analysis, but if you don’t know
    how to use it what do you do with the code? So, yes: prompt engineering may lead
    to job loss for some data professionals, but it’s a matter of years not months.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Possibility to forgot how to code**. This is an actual problem. If we rely
    too much on prompt engineering rather than writing code by ourselves, we can forget
    how to code. You know: coding is a matter of practicing and it needs everyday
    practice. Sure, is like going on a bicycle: you’ll never forget how to do so.
    But, you know: relying too much on the prompts rather than on writing code can
    atrophy your muscles because you’ve become too much comfortable. So, use tools
    like ChatGPT but don’t rely only on those: strive to write code as much as you
    can. Because I know you love to code, so don’t leave it too much to machines.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Possibility to not learn new things**. The beauty of working in IT, especially
    in the data field, is that new topics and technologies are born barely every day.
    This is one of the most important reasons [why I changed my career to work in
    IT](https://betterhumans.pub/from-gears-to-code-how-i-successfully-transitioned-from-mechanical-engineering-to-tech-44909e31cbb0):
    because I love to always learn new things, and I’d like that this is recognized
    as a good thing (yes, there are fields/companies where self-improvement is not
    considered a good thing). But if you rely only on the answer you get from your
    prompts and copy and paste the code (or the info you get) you won’t learn new
    things. On the code sight, at least you need to ask for explanations, then read
    the documentation. And then, if possible, try the code in different scenarios
    so that you can get comfortable with the code you received. This is also the same
    approach we need to have when we ask for general information: always deepen them
    by reading other sources (as it always should be: but let’s just keep this in
    mind!).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Possibility to implement “wordy code”.** The fact that a piece of code just
    works is not a good reason to leave it as is, as you know. Code quality is also
    important for those who will read that snippet in the future (maybe, you). Sometimes,
    due to different factors (often, to not correct prompts), tools like ChatGPT can
    give us “wordy code” with unnecessary parts. And here comes the importance of
    a professional: don’t blindly copy and paste it. If you copy and paste it, after
    you verified it works, strive to improve it as much as you can.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Examples of effective prompts for Data Scientists
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, with these pros and cons in mind, let’s see some effective prompts we can
    create in ChatGPT to improve and speed up our jobs as Data Scientists.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example n°1: prototype'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Suppose we are studying a binary classification example. We want to compare
    three ML models using learning curves, but we don’t actually remember the code
    to use. Also, our repositories are a little bit messy and we don’t want to waste
    much time.
  prefs: []
  type: TYPE_NORMAL
- en: 'To speed up our job in such situations, we can ask ChatGPT a prompt like the
    following: “*Create, in Python, a binary classification problem with synthetic
    data. Standardize the data using the standard scaler, then split the data into
    the train and the test set. Then, fit the train set with a random forest, a KNN,
    and a SVM classifiers. Then, plot ROC curve to compare the models.*” And these
    are the results:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Certainly! I can help you create a binary classification problem using synthetic
    data in Python and apply the standard scaler for data standardization. Then, we
    can split the data into train and test sets. Finally, we’ll fit the train set
    with three classifiers: Random Forest, K-Nearest Neighbors (KNN), and Support
    Vector Machine (SVM), and plot the ROC curve to compare the models.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The provided code generates a synthetic binary classification problem using
    scikit-learn’s `make_classification` function. It then applies the `StandardScaler`
    to standardize the data and splits it into a train set and a test set.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Three classifiers are then trained on the train set: Random Forest, K-Nearest
    Neighbors (KNN), and Support Vector Machine (SVM). For evaluation, the classifiers
    generate probabilities for the test set using the `predict_proba` method.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The next step involves plotting the Receiver Operating Characteristic (ROC)
    curve to compare the performance of the classifiers. The False Positive Rate (FPR)
    and True Positive Rate (TPR) are calculated using the `roc_curve` function, and
    the Area Under the Curve (AUC) is computed using the `auc` function.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Finally, the ROC curve is plotted using matplotlib, with each classifier’s AUC
    displayed in the legend. The curve represents the trade-off between the true positive
    rate and the false positive rate for each classifier, allowing visual comparison
    of their performance.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: By examining the ROC curve and comparing the AUC values, you can assess the
    relative performance of the Random Forest, KNN, and SVM classifiers for the given
    binary classification problem.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Now, if we copy and paste this code into a Jupyter Notebook we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ff4a1bda1112ceb978647e8d1bf3f515.png)'
  prefs: []
  type: TYPE_IMG
- en: The ROC curve resulting from the above code. Image by Federico Trotta.
  prefs: []
  type: TYPE_NORMAL
- en: 'We get what we wanted, so let’s analyze the prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '**It’s specific**. I specified: a) the language (Python), b) the type of problem
    (binary classification), c) the process to follow (data creation, data normalization,
    data split), and d) the ML models to use.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**It has everything needed**. There are no extra words that may create confusion.
    The prompt goes straight to the point.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**It’s short**. It’s only 3 lines. Longer prompts may lead to incorrect outputs
    or can lead the model to add information we may not need. If you have to insert
    “long prompts” my advice is to subdivide the “big task” into smaller tasks and
    input different short prompts that can be sequential. To be clear, the above prompt
    could be subdivided into sequential chats like so: a) “*create a binary classification
    dataset with Python, normalize the data, and split them into the train and the
    test set*”, b) “*fit the train test with random forest, SVM, and KNN classifiers.
    Then, print the ROC curve*”'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Example n°2: research'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Suppose we know that polynomial regression generally overfits, but we want
    a prove because we’ve never seen this. The prompt could be something like that:
    “ *I know that polynomial regression models generally overfit: can you show me
    something, creating some data in Python*?”'
  prefs: []
  type: TYPE_NORMAL
- en: 'And here’s what we get:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Certainly! I can generate some random data and demonstrate how polynomial regression
    can lead to overfitting. Here’s an example in Python:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This code generates random data points with a quadratic relationship and adds
    some noise to the y values. It then fits polynomial regression models of different
    degrees (1, 4, and 15 in this example) to the data and plots the resulting curves.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You will observe that as the degree of the polynomial increases, the model starts
    to fit the noise in the data rather than the underlying trend. This is an example
    of overfitting. The linear model (degree 1) is too simple to capture the underlying
    quadratic relationship, while the high-degree polynomial (degree 15) tries to
    fit every data point precisely, resulting in a highly oscillating curve.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It’s important to note that the example I provided is a simple illustration
    of overfitting in polynomial regression. In practice, you would typically use
    more realistic and complex datasets to evaluate and address overfitting issues.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Now, let’s see what we get in a Jupyter Notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/72c90aa22d0e36b4dd936037124ca499.png)'
  prefs: []
  type: TYPE_IMG
- en: A plot showing the difference in fitting the data created with the above code.
    Image by Federico Trotta.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, this plot shows that, given some quadratic distributed data:'
  prefs: []
  type: TYPE_NORMAL
- en: A linear model can’t grab the path.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The 4-degree and the 15-degree polynomials “grab the path too well”.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, tell me: does it means that the two polynomials overfit?'
  prefs: []
  type: TYPE_NORMAL
- en: Stop reading for a second a think about that.
  prefs: []
  type: TYPE_NORMAL
- en: 'Well, yes and no, but primarily no. In fact, as we know, overfitting occurs
    when:'
  prefs: []
  type: TYPE_NORMAL
- en: We define metrics to evaluate our data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The metrics are calculated both on the train and test sets and we find big numerical
    differences between them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'So, this prompt is not a satisfying one and we have to ask for more. For example,
    we could ask: “*Good, so use the same data and the same polynomials. Then, normalize
    the data, split the dataset into train and test sets, and calculate R² for both
    sets*”.'
  prefs: []
  type: TYPE_NORMAL
- en: 'And we get:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Certainly! Here’s an updated version of the code that normalizes the data,
    splits it into train and test sets, and calculates the R² score for both sets:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In this updated code, the data is first normalized by subtracting the mean and
    dividing by the standard deviation. Then, the data is split into a train set (80%
    of the data) and a test set (20% of the data) using `train_test_split()` from
    scikit-learn.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The polynomial regression models are fitted using the normalized training data,
    and the R² scores are calculated for both the train and test sets using `r2_score()`
    from scikit-learn. The R² scores are then displayed in the legend of each fitted
    curve.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: By normalizing the data and calculating R² scores on both the train and test
    sets, you can evaluate the performance of the polynomial regression models and
    assess whether they overfit or generalize well to unseen data.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In this case, we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/951d88dd080eaedd46f6dd2f9ae8b216.png)'
  prefs: []
  type: TYPE_IMG
- en: A plot showing the difference in fitting the data created with the above code.
    Image by Federico Trotta.
  prefs: []
  type: TYPE_NORMAL
- en: So, what did we get? Well…We can’t see great signs of overfitting because R²
    slightly increases for the 4-degree polynomial on the test set while it slightly
    decreases for the 15-degree polynomial.
  prefs: []
  type: TYPE_NORMAL
- en: Here the mistake is that we’ve continued the chat we started. Let’s remember
    that LLM are neural networks and they have the tendency to overfit. So, sometimes,
    if you just continue prompting you get the same answer (or something very similar)
    even if it returns you some “apologies for the mistake”.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, I don’t want any plot. So, in this case, we''d better create another
    chat. Let’s try to be more specific now:” *Create a 2-degree data set in Python.
    Normalize the data, and split it into the train and the test set. Fit the data
    with: linear regression, 4-degree polynomial, and 15-degree polynomial models.
    Print r-squared for each model for both train and test sets.*”'
  prefs: []
  type: TYPE_NORMAL
- en: 'And we get:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a 2-degrees dataset in Python, normalize it, and split it into train
    and test sets, you can use the `numpy` and `sklearn` libraries. Here''s an example
    of how you can achieve this:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we generate a random dataset with a quadratic relationship
    between the independent variable `X` and the dependent variable `y`. The data
    is then normalized using z-score normalization. Next, the dataset is split into
    a train set (80%) and a test set (20%) using `train_test_split` from the `sklearn.model_selection`
    module.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'We then fit three different models: linear regression, 4-degree polynomial
    regression, and 15-degree polynomial regression. For polynomial regression, we
    use the `PolynomialFeatures` class from `sklearn.preprocessing` to create polynomial
    features up to the desired degree. The models are fitted using the normalized
    training data.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Finally, we calculate the R-squared value for both the train and test sets for
    each model using the `score` method of the respective models. The R-squared value
    represents the proportion of the variance in the dependent variable that can be
    explained by
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Good, so we get what we wanted and with some explanations. Now, if we try it
    we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Ops! As we said, it can happen to get some errors. So, in these cases, we can
    simply continue the chat like so: “*I get: ValueError: X has 16 features, but
    LinearRegression is expecting 5 features as input.*”'
  prefs: []
  type: TYPE_NORMAL
- en: 'And now it returns:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Apologies for the error. It seems that there was an issue with the polynomial
    features transformation. To fix the problem, we need to ensure that we apply the
    polynomial transformation on the normalized `X` data, rather than the original
    `X` data. Here''s the corrected code:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Now the code should work correctly, applying the polynomial transformation on
    the normalized data and fitting the models accordingly.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Now, if we test it we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'So, here we can see some slight overfitting of the 4-degree model and a clear
    overfitting of the 15-degree model. In fact, the higher the degree of the polynomial
    the higher the probability it has to overfit the data. Let’s think about that:
    we have a 2-degree data distribution and we’re trying to fit it with a 15-degree
    polynomial. So, it’s easy that the 15-degree polynomial can grab every small modification
    in the data, leading to overfitting.'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this article, we’ve seen the importance of prompt engineering today, how
    it can affect Data Scientists, and some prompt examples for Data Scientists.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that a prompt should be short and clear and that we always have to
    verify the answers. But, as we’ve shown, the benefits are huge.
  prefs: []
  type: TYPE_NORMAL
- en: '**FREE PYTHON EBOOK:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Started learning Python Data Science but struggling with it? [***Subscribe
    to my newsletter and get my free ebook: this will give you the right learning
    path to follow to learn Python for Data Science with hands-on experience.***](https://federico-trotta.ck.page/a3970f33f4)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Enjoyed the story? Become a Medium member for 5$/month [through my referral
    link](https://medium.com/@federicotrotta/membership): I’ll earn a small commission
    to no additional fee to you:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://federicotrotta.medium.com/membership?source=post_page-----16b6d1f2bf85--------------------------------)
    [## Join Medium with my referral link - Federico Trotta'
  prefs: []
  type: TYPE_NORMAL
- en: Read every story from Federico Trotta (and thousands of other writers on Medium).
    Your membership fee directly supports…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: federicotrotta.medium.com](https://federicotrotta.medium.com/membership?source=post_page-----16b6d1f2bf85--------------------------------)
  prefs: []
  type: TYPE_NORMAL
