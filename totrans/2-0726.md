# 检测协变量偏移：多变量方法指南

> 原文：[https://towardsdatascience.com/detecting-covariate-shift-a-guide-to-the-multivariate-approach-c099bd1891b9](https://towardsdatascience.com/detecting-covariate-shift-a-guide-to-the-multivariate-approach-c099bd1891b9)

## MLOps

## 好的旧PCA可以在生产数据的分布发生变化时提醒你

[](https://michaloleszak.medium.com/?source=post_page-----c099bd1891b9--------------------------------)[![Michał Oleszak](../Images/61b32e70cec4ba54612a8ca22e977176.png)](https://michaloleszak.medium.com/?source=post_page-----c099bd1891b9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c099bd1891b9--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c099bd1891b9--------------------------------) [Michał Oleszak](https://michaloleszak.medium.com/?source=post_page-----c099bd1891b9--------------------------------)

·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c099bd1891b9--------------------------------) ·阅读时长16分钟·2023年1月17日

--

![](../Images/43ed7a846bc901d5218d81828fd041fb.png)

任何机器学习模型的最终目的都是为其所有者带来价值。通常，这种价值表现为算法比人类更好或更快地完成任务（或两者兼而有之）。开发和部署模型的投资成本通常很高。为了收回这笔投入，模型需要在生产中提供足够长时间的价值。协变量偏移可能会妨碍这一点，它是一种导致模型在生产中随时间退化的现象。让我们来看看如何检测它，以及为什么流行的简单方法通常不够好。

![](../Images/b7814b740dbdd56bf28850809a36088a.png)

# 介绍协变量偏移

[协变量偏移](https://medium.com/towards-data-science/dont-let-your-model-s-quality-drift-away-53d2f7899c09)是指模型的输入特征在生产中的分布与模型在训练和验证时看到的分布发生变化的情况。

> 协变量偏移是指模型输入在训练数据和生产数据之间分布的变化。

在大多数应用中，协变量偏移发生是时间问题。例如，如果你在建模客户，他们的行为模式会随着经济变化、年龄增长或由于营销活动而改变客户基础。生活中唯一不变的就是变化，正如希腊哲学家赫拉克利特所说的。

确保模型在生产中持续有效的关键是及早检测协变量偏移。我们该如何做到这一点呢？让我们来探讨一下！

![](../Images/762c36e5777aa117d1422e1ed5687fe5.png)

# 检测协变量偏移：一种天真的方法

我们已经提到协变量漂移是模型输入分布的变化。我们知道训练数据中每个特征的分布，我们也应该能够获取生产中的特征分布。那我们为什么不直接比较这两者呢？

实际上，这是一个有效的方法。像[TensorFlow数据验证](/dont-let-your-model-s-quality-drift-away-53d2f7899c09)或[Great Expectations](https://medium.com/towards-data-science/reducing-pipeline-debt-with-great-expectations-f1afddbfdc0b)这样的工具可以让我们轻松地逐特征比较训练数据和生产数据之间的分布。

确定给定特征的训练分布和生产分布是否不同的最简单方法是比较它们的摘要统计量，如均值、中位数等。

更复杂的方法是直接计算这两个分布的差异，使用如[地球搬运工距离](https://en.wikipedia.org/wiki/Earth_mover%27s_distance)或[詹森-香农散度](https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence)这样的（不）相似性度量。

更加统计学严格的方法是进行[适当的假设检验](https://medium.com/towards-data-science/the-hypothesis-testers-guide-75f7db2e4d0d)。连续特征的[Kolmogorov-Smirnov检验](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test)和分类特征的[卡方检验](https://en.wikipedia.org/wiki/Chi-squared_test)可以帮助我们确定特征分布是否以显著的方式不同。

然而，后一种方法存在一个严重的缺点。像这样测试生产数据需要不断地对大数据量进行许多测试。许多测试肯定会发出显著效果的信号，但从监控的角度来看，这并不总是值得担忧的原因。在许多情况下，统计上显著的分布变化并不一定对应于导致模型性能下降的协变量漂移。

但是，还有一个更显著的缺点是上述所有方法都共享的：它们是*单变量*的，这意味着它们将每个特征与其他特征隔离开来处理。在现实生活中，我们经常观察到*多变量数据漂移*，即单个特征的分布不一定发生变化，但它们的联合分布会发生变化。考虑以下示例。

![](../Images/762c36e5777aa117d1422e1ed5687fe5.png)

# 当单变量漂移检测失败时

我们有一个由两个特征组成的数据集：年龄和收入，数据是在几周内收集的。

![](../Images/7d55c55623e88be6d2e84d78ffae2f61.png)

收入与年龄。作者提供的图像。

两个特征已经被标准化，以便可以整齐地一起可视化。标准化使用了来自总体的均值和方差值，即未从这些数据计算的，这意味着我们不需要担心任何数据泄漏。

在第10周（蓝色），两个特征之间有相当强的正相关。这是有道理的：大多数人随着年龄增长获得更多经验，他们也得到晋升，这导致平均收入更高。

在第16周（黄色），每个特征的边际单变量分布仍然是标准正态分布，但相关模式发生了剧烈变化；现在，两个特征之间呈负相关。也许第16周的数据是从年长的人那里收集的。在这种情况下，年纪越大，越有可能退休，因此收入较低。

> 当单变量特征分布保持不变而联合分布发生变化时，单变量漂移检测方法会失败。

我们显然正在经历强烈的协变量漂移；任何基于第10周数据训练的机器学习模型在第16周的数据上表现都会非常糟糕。然而，我们之前讨论的单变量漂移检测方法不会提醒我们这一危险的变化。

![](../Images/8a2369dbb77f8623e8f9d3602abc4cd1.png)

# 检测协变量漂移：一种多变量方法

为了可靠地检测任何情况下的协变量漂移，我们需要（在单变量方法之外）另一种能够捕捉所有特征联合分布变化的方法。一种非常简单但巧妙的方法是基于经典的主成分分析（PCA）。

## 主成分分析

主成分分析是一种降维技术。它识别出数据中包含最多方差的方向。这些方向称为主成分，按捕获的方差从高到低排序。这意味着通过限制自己选择前几个主成分，我们可以捕捉数据的大部分变异性，同时减少维度。换句话说，我们可以说PCA将数据投影到一个低维空间。

> PCA将原始数据映射到低维空间，保留了大部分信息信号。

PCA的降维在多个应用中都找到了用武之地。在模型训练之前进行降维处理可以减少特征数量，因为一些机器学习模型在特征过多时训练速度变得非常慢。

但使用PCA作为预处理步骤获得的好处不仅仅是速度。在某些情况下，基于PCA转换数据训练的机器学习模型表现更好。这是因为当我们降低维度时，我们试图将*相同*数量的信息挤入更少的变量中。这个过程是有损的，这意味着一些信息将不可避免地被丢弃。PCA假设数据集的有用信息由其方差捕捉，因此使用捕捉大部分方差的独立主成分作为特征可以带来更好的决策阈值。

最后，PCA对于可视化和发现多维数据集中的模式也非常有用——在将数据压缩为两个或三个特征后，我们可以轻松地绘制这些特征，用一个感兴趣的属性为每个数据点着色，并发现有趣的模式。

## 数据重建与PCA

好吧，但我听到你在问，这种降维如何帮助漂移检测。这里是想法。

我们唯一缺少的拼图是PCA变换是可逆的。一旦我们将数据压缩为较少的特征，我们可以使用PCA模型来解压数据，即：将数据集恢复到其原始特征数量。由于有损压缩过程，结果可能不会与原始数据完全相同，但应该非常相似。我们将原始数据与解压数据之间的差异称为*重建误差*。

让我们回到我们的示例数据集。回忆一下，我们将第10周与第16周进行了比较，以发现期间发生了多变量数据漂移。现在，让我们关注第9周、第10周和第11周，在这段时间内没有发生协变量漂移，也就是说：这些三周内特征的联合多变量分布是相同的。

如果我们在第9周学习了PCA映射，我们可以使用它来压缩和解压第10周和第11周的数据，从而获得类似的、较低的重建误差。

![](../Images/9bbbb691ba12aa54b5a184cd3d82b0db.png)

没有协变量漂移的PCA重建误差。图像由作者提供。

我们现在实际上不关心误差的具体数值。重要的是，第10周和第11周的误差可能大致相同，因为数据的内部结构保持不变，PCA学到的压缩-解压映射仍然适用。

现在，如果我们在第10周和第16周而不是第10周和第11周使用我们的PCA模型，会发生什么呢？这次，PCA学到的映射仍然适用于第10周，但不适用于第16周。因此，第16周的重建误差将显著大于第10周的重建误差。

![](../Images/d0e31580273d4aad1caeba5b97a3285a.png)

带有协变量漂移的PCA重建误差。图像由作者提供。

我们刚刚讨论的想法可以用来检测生产中的协变量漂移。如果我们知道在没有漂移的情况下数据的重建误差（考虑第10周的误差），我们可以将其与生产数据的重建误差进行比较。如果后者显著较大，我们可以声明存在协变量漂移。

> 我们可以通过比较生产数据的PCA重建误差与其预期水平来检测协变量漂移。

唯一剩下的两个问题是：什么是*预期重建误差*，以及*显著较大*意味着什么？

## 比较重建误差

估计期望重建误差的一种方法是取一部分我们知道没有协变量漂移的训练数据（称为参考数据集），将其拆分为块，并计算每个块的重建误差。这样，我们得到一系列误差值，从中可以计算均值和方差。

然后，声明协变量漂移的一个简单经验法则是检查生产数据中的重建误差是否超出了从参考集获得的范围。如果它偏离参考均值至少三个标准差，那么很可能发生了漂移。

## Python中的多变量漂移检测

现在，让我们看看如何使用NannyML包在Python中实现这些想法。

我们将使用Yandex的[天气数据集](https://research.yandex.com/shifts/weather)。多变量概念漂移在天气测量中固有存在；随着季节的更替，不同气候组件相互作用的方式也往往会发生变化。数据集包含超过一百个描述各种气象测量的特征，如温度、湿度、气压等。

首先，让我们加载和准备数据，并将其拆分为两个不相交的集合：九月数据（我们的参考集，用于训练PCA）和十月数据（我们的分析集，用于测试协变量漂移）。我们还需要将时间戳列解析为适当的pandas datetime格式。

[PRE0]

接下来，我们使用NannyML的漂移计算器，该计算器完成上述所有步骤。我们需要传递要检查的特征名称（除了时间戳列之外的所有列）、时间戳列名称，以及根据其估计期望重建误差的块大小。然后，我们简单地将其拟合到参考数据上，并将其应用于分析数据以测试协变量漂移。

[PRE1]

利用生成的结果对象最简单的方法是将其渲染为图表。

[PRE2]

![](../Images/961e4cb268b2e5e429b4e0edc54f2e56.png)

生产数据中的重建误差与其预期范围的对比。图片由作者提供。

两条虚线表示从九月数据估计的重建误差值的预期区间。如你所见，月末附近有一个异常观测值——可能是一次特别强烈的雷暴或其他有影响的事件。

在十月的头几天，没有协变量漂移；似乎这个月的开始天气与九月最后一周的天气类似。但随后秋天来临，十月剩余的数据特征表现出明显的协变量漂移。

尽管上面的图表清晰且视觉上很吸引人，但它不适合用作带有自动警报的管道中检测协变量漂移的便捷方法。但是，只需对`results`对象调用`.to_df()`方法即可获取包含图表背后所有数据的数据框。

[PRE3]

它包含一个 `alert` 列，其中包含一个布尔标志，表示每个数据点是否超出了预期范围。这是一种将协变量漂移检测添加到现有数据验证检查中的好方法！

![](../Images/619f04f6449ebd7dd342b9dd2cfac826.png)

# 假设与限制

对于任何统计方法的讨论，都不应该遗漏对其假设的深入探讨。这将给我们一些指示，了解方法何时有效，何时无效，以及它的局限性。基于 PCA 重建误差变化的数据漂移检测也不例外。

## 数据完整性

首先，我们的算法需要处理数据集中可能存在的缺失值。这一要求来自于基础 PCA，它假设所有数据点都被观测到，以便能够找到主成分。

显而易见的解决办法是在进行漂移检测之前对缺失值进行填充。实际上，我们之前使用的 DataReconstrucionDriftCalculator 类接受两个参数 `imputer_categorical` 和 `imputer_continuous`，通过这两个参数我们可以指定填充缺失数据的方法。我们只需传递一个 scikit-learn 的 SimpleImputer 实例，如下所示：

[PRE4]

然而，采用这种方法存在风险。scikit-learn 的 `SimpleImputer` 是非常简单的。撰写本文时，它只能执行四种简单的基于捐赠者的填充方法；它用列中其他值的均值、中位数或众数，或指定的常数值替代缺失值。

如果你参加过[我的 DataCamp 数据填充课程](https://datacamp.com/courses/handling-missing-data-with-imputations-in-r)或阅读过[我关于这一主题的博客文章](/handling-missing-data-5be11eddbdd)，那么你就会知道这些填充策略并不是最佳选择。均值、中位数、众数或常数填充都存在两个相同的问题：它们减少了均值填充值变量的方差，并破坏了这些变量与其他数据之间的相关性。这可能会对我们造成两次伤害：首先，当我们运行基于数据方差的 PCA 方法时，其次，当我们寻找联合数据分布的变化时，这种变化可能会受到填充值的影响。

> 我们的漂移检测器不允许缺失值。如果存在，它们应该提前填充，最好使用基于模型的方法。

因此，可能更好的解决方案是在进行漂移检测之前使用模型基础的填充方法，如 MICE。

## 在没有漂移的情况下，重建误差的稳定性

我们的漂移检测器还做了一个重要假设，即在没有协变量漂移的情况下，重建误差是稳定的。让我们试着解析一下这个说法。

让我们回到算法的后续步骤。我们首先在第9周的数据上学习PCA映射。然后，我们说可以使用这个映射来压缩和解压缩来自第10周和第11周的数据（两者均无漂移），得到的重构误差将低且相似。我们之前没有提到的一点是，在用于学习PCA映射的相同数据上计算的误差会更低。当我们在数据发生漂移的第16周进行此操作时，我们会发现重构误差更高。

![](../Images/9d6f8b79a17c6d95c0f04c076f87bff4.png)

随时间推移的重构误差。图片来自作者。

重构误差稳定性的假设指的是，虽然误差从第9周增加到第10周，但在接下来的几周中保持稳定，直到发生协变量偏移。让我们看看为什么这个假设是合理的。

当我们对第9周的数据进行PCA拟合时，我们在多维数据空间中寻找那些捕捉最大方差的方向。然后，我们可以使用这些主成分在相同的数据上获得一些重构误差值，称之为*RE9*。

当我们使用相同的主成分来计算第10周的重构误差时，我们会发现*RE10*大于*RE9*。这是因为第9周的组件可能不是第10周数据的最佳选择（即没有捕捉到最多的方差），而第10周的数据具有不同的噪声模式。这种效应被称为[回归均值](https://en.wikipedia.org/wiki/Regression_toward_the_mean)。这类似于机器学习模型通常在训练集上的表现优于测试集。

关键假设是我们期望*RE10 ≈ RE11*，所以第11周的误差应接近第10周的误差。这使我们能够发现漂移；我们假设第10周、第11周、第12周等的误差保持稳定，直到误差上升，这将提醒我们可能存在漂移。

> 我们的漂移检测器假设在没有协变量偏移的情况下，重构误差会随着时间保持稳定（除了用于学习PCA映射的时期）。

这个假设的理由是，虽然*RE9*因过拟合于特定的第9周数据而被低估，但*RE10*是我们预期看到的每个新数据样本的*预期重构误差*（前提是其联合分布保持不变）。

## 偏移（非）线性

我们方法中最重要的限制之一是PCA重构误差能够捕捉和无法捕捉的漂移类型。即，我们所做的协变量偏移检测不能捕捉到存在非线性变换的漂移，这种变换保持特征之间的相关性，同时保持每个特征的均值和标准差。

> 基于PCA的漂移检测器在存在非线性漂移且保持每个特征的均值和标准差以及不同特征之间的相关性时将不起作用。

让我们用一个简单的例子来说明。假设我们有一个仅包含两个特征 *x* 和 *y* 的参考数据集。仅使用两个维度可以让我们轻松地可视化它们之间的关系。

![](../Images/4cd36ea08973007a538e61b64e025b2a.png)

假设的参考集。图像由作者提供。

显然，我们的两个特征之间存在非随机的关系。现在，设想在某个时刻，这种关系变化为以下的形式。

![](../Images/5955fd79e93d7f56afc3feeb0684bf0e.png)

假设分析集。图像由作者提供。

*y* 的可能值范围增加了，而在联合分布的中间存在一个低密度区域，其中没有数据点。

注意，这个新数据集的线性相关系数几乎与上面的参考数据集相同。如果我们在这些数据上运行漂移检测器，结果将如下：

![](../Images/22b95f19609ba5d62616b66c3d7670f1.png)

对于具有非线性协变量漂移且PCA无法捕捉的数据集的漂移检测。图像由作者提供。

检测器未能捕捉到我们知道已经发生的变化：蓝色误差线在预期范围内。这是因为漂移没有改变特征的均值和标准差，也没有改变特征之间的相关性。

我们可以将这个论点推向极端。设想我们的分析数据集呈现出恐龙的形状（本节讨论的所有数据来自于[Datasaurus set](https://cran.r-project.org/web/packages/datasauRus/vignettes/Datasaurus.html)：这是一个包含相同线性相关性和基本统计量的x-y对的集合，但具有非常不同的联合分布）。

![](../Images/d2b8e01bdc51718aae560340e19d723b.png)

假设的恐龙分析集。图像由作者提供。

只要线性相关性以及特征的均值和标准差保持不变，基于PCA的漂移检测器将不起作用。

![](../Images/47ffaa8ecf9ad1f560a8bc54ea0b7ca4.png)

对于具有非线性协变量漂移且PCA无法捕捉的数据集的漂移检测。图像由作者提供。

在我们的二维示例中，我们可以很容易地观察到数据的联合分布。然而，在大多数实际应用中，我们处理的是更多特征，这使得判断漂移是否线性变得更加困难。

如果你的特征不多，我建议查看它们的总结统计量以及每对特征之间的线性相关性。如果它们在参考数据和分析数据之间类似，这表明基于PCA的漂移检测可能不可靠。

虽然通过 PCA 数据重建来检测协变量漂移不能检测到我们刚刚讨论的一些漂移情况，但我们可以使用单变量漂移检测方法来检测这些情况。敬请关注有关它们的单独文章！

*这篇文章也发表在* [*NannyML 博客*](https://www.nannyml.com/blog/detecting-covariate-shift-multivariate-approach)*上。*

![](../Images/619f04f6449ebd7dd342b9dd2cfac826.png)

感谢阅读！

如果你喜欢这篇文章，为什么不[**订阅电子邮件更新**](https://michaloleszak.medium.com/subscribe)以获取我的新文章？通过[**成为 Medium 会员**](https://michaloleszak.medium.com/membership)，你可以支持我的写作，并无限制地访问所有其他作者和我自己的故事。

想始终保持对迅速发展的机器学习和人工智能领域的关注吗？查看我的新通讯，[**AI Pulse**](https://pulseofai.substack.com/)。需要咨询？你可以在[**这里**](https://topmate.io/michaloleszak)向我提问或预约一对一咨询。

你还可以尝试阅读[我的其他文章](https://michaloleszak.github.io/blog/)。难以选择？试试这些：

[特征选择方法及其选择方式](https://www.example.com/feature-selection-methods-and-how-to-choose-them-1e7469100e7e?source=post_page-----c099bd1891b9--------------------------------) [## 特征选择方法及其选择方式

### 特征选择的原因、方法和时机，加上一些实用的技巧和窍门

[关于贝叶斯思维在日常生活中的重要性](https://www.example.com/on-the-importance-of-bayesian-thinking-in-everyday-life-a74475fcceeb?source=post_page-----c099bd1891b9--------------------------------) [## 关于贝叶斯思维在日常生活中的重要性

### 这种简单的思维转变将帮助你更好地理解你周围的不确定世界。

[关于置信区间与预测区间的区别](https://www.example.com/confidence-intervals-vs-prediction-intervals-7b296ae58745?source=post_page-----c099bd1891b9--------------------------------) [## 置信区间与预测区间

### 混淆这两者可能会很昂贵。了解它们的不同之处以及何时使用每一种！

[关于置信区间与预测区间的区别](https://www.example.com/confidence-intervals-vs-prediction-intervals-7b296ae58745?source=post_page-----c099bd1891b9--------------------------------)
