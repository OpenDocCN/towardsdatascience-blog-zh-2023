- en: Metal Programming in Julia
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Juliaä¸­çš„Metalç¼–ç¨‹
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/metal-programming-in-julia-2db5fe8ee32c](https://towardsdatascience.com/metal-programming-in-julia-2db5fe8ee32c)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/metal-programming-in-julia-2db5fe8ee32c](https://towardsdatascience.com/metal-programming-in-julia-2db5fe8ee32c)
- en: '![](../Images/1b0fa479f9906bf1570e41eed0082af9.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1b0fa479f9906bf1570e41eed0082af9.png)'
- en: Little Heavy | Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Little Heavy | ä½œè€…æä¾›çš„å›¾ç‰‡
- en: Leveraging the power of macOS GPUs with the Metal.jl Framework.
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆ©ç”¨macOS GPUçš„å¼ºå¤§åŠŸèƒ½ï¼Œé€šè¿‡Metal.jlæ¡†æ¶ã€‚
- en: '[](https://lausena.medium.com/?source=post_page-----2db5fe8ee32c--------------------------------)[![Gabriel
    Sena](../Images/713235a9a7f276a72862c38293d7ac89.png)](https://lausena.medium.com/?source=post_page-----2db5fe8ee32c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2db5fe8ee32c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2db5fe8ee32c--------------------------------)
    [Gabriel Sena](https://lausena.medium.com/?source=post_page-----2db5fe8ee32c--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://lausena.medium.com/?source=post_page-----2db5fe8ee32c--------------------------------)[![Gabriel
    Sena](../Images/713235a9a7f276a72862c38293d7ac89.png)](https://lausena.medium.com/?source=post_page-----2db5fe8ee32c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2db5fe8ee32c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2db5fe8ee32c--------------------------------)
    [Gabriel Sena](https://lausena.medium.com/?source=post_page-----2db5fe8ee32c--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2db5fe8ee32c--------------------------------)
    Â·11 min readÂ·Dec 4, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page-----2db5fe8ee32c--------------------------------)
    Â·é˜…è¯»æ—¶é—´11åˆ†é’ŸÂ·2023å¹´12æœˆ4æ—¥
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»‹ç»
- en: Just last year, we were [introduced](https://www.youtube.com/watch?v=IARikXzRU7s&ab_channel=TheJuliaProgrammingLanguage)
    to the [Metal.jl](https://github.com/JuliaGPU/Metal.jl) Framework, a GPU backend
    for Apple Hardware. This is exciting news for [Julia](https://julialang.org/)
    practitioners looking to leverage the full potential of their macOS M-series chips.
    In particular, data scientists and ML engineers can speed up their computational
    workflows by tapping into the parallel processing power of [GPUs](/what-is-a-gpu-and-do-you-need-one-in-deep-learning-718b9597aa0d),
    resulting in faster training and inference times. The integration of Metal.jl
    into the Julia ecosystem signifies an important push towards aligning the languageâ€™s
    capabilities with the continually evolving landscape of scientific computing and
    machine learning on Apple platforms.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: å°±åœ¨å»å¹´ï¼Œæˆ‘ä»¬[äº†è§£åˆ°äº†](https://www.youtube.com/watch?v=IARikXzRU7s&ab_channel=TheJuliaProgrammingLanguage)
    [Metal.jl](https://github.com/JuliaGPU/Metal.jl)æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè‹¹æœç¡¬ä»¶çš„GPUåç«¯ã€‚è¿™å¯¹å¸Œæœ›åˆ©ç”¨å…¶macOS
    Mç³»åˆ—èŠ¯ç‰‡å…¨éƒ¨æ½œåŠ›çš„[Julia](https://julialang.org/)ä»ä¸šè€…æ¥è¯´æ˜¯ä»¤äººå…´å¥‹çš„æ¶ˆæ¯ã€‚ç‰¹åˆ«æ˜¯ï¼Œæ•°æ®ç§‘å­¦å®¶å’Œæœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆå¯ä»¥é€šè¿‡åˆ©ç”¨[GPU](/what-is-a-gpu-and-do-you-need-one-in-deep-learning-718b9597aa0d)çš„å¹¶è¡Œå¤„ç†èƒ½åŠ›æ¥åŠ é€Ÿä»–ä»¬çš„è®¡ç®—å·¥ä½œæµç¨‹ï¼Œä»è€Œå®ç°æ›´å¿«çš„è®­ç»ƒå’Œæ¨æ–­æ—¶é—´ã€‚Metal.jlçš„å¼•å…¥æ ‡å¿—ç€å¯¹å°†è¯­è¨€çš„èƒ½åŠ›ä¸è‹¹æœå¹³å°ä¸Šä¸æ–­å‘å±•çš„ç§‘å­¦è®¡ç®—å’Œæœºå™¨å­¦ä¹ é¢†åŸŸå¯¹æ¥çš„é‡è¦æ¨åŠ¨ã€‚
- en: In [2020](https://www.apple.com/newsroom/2020/06/apple-announces-mac-transition-to-apple-silicon/),
    Apple began transitioning its Mac lineup from Intel-based processors to Apple
    Silicon, starting with the M1 chip. While this has been a historic and impressive
    achievement from Apple it did come with its fair share of criticisms and issues.
    Since picking up my 32-core Mac Studio M1-chip, I have been looking to fully leverage
    the GPU and tinker with new applications. I must say, it hasnâ€™t been all fun and
    games. From [ARM](https://en.wikipedia.org/wiki/ARM_architecture_family) architecture
    compatibility issues to unsupported machine learning libraries â€” it has been a
    challenge at times to get a working environment. This is expected with any huge
    major transition and way of operating. I remain hopeful and have seen major improvements
    across the board for stability and features.
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åœ¨[2020å¹´](https://www.apple.com/newsroom/2020/06/apple-announces-mac-transition-to-apple-silicon/)æ—¶ï¼Œè‹¹æœå…¬å¸å¼€å§‹å°†å…¶Macç³»åˆ—ä»åŸºäºIntelçš„å¤„ç†å™¨è¿‡æ¸¡åˆ°Apple
    Siliconï¼Œä»M1èŠ¯ç‰‡å¼€å§‹ã€‚å°½ç®¡è¿™æ˜¯è‹¹æœå…¬å¸å†å²æ€§ä¸”ä»¤äººå°è±¡æ·±åˆ»çš„æˆå°±ï¼Œä½†ä¹Ÿä¼´éšç€ä¸å°‘æ‰¹è¯„å’Œé—®é¢˜ã€‚è‡ªä»æˆ‘æ‹¿åˆ°32æ ¸çš„Mac Studio M1èŠ¯ç‰‡åï¼Œæˆ‘ä¸€ç›´å¸Œæœ›å……åˆ†åˆ©ç”¨GPUå¹¶å°è¯•æ–°çš„åº”ç”¨ç¨‹åºã€‚æˆ‘å¿…é¡»è¯´ï¼Œè¿™å¹¶éå…¨æ˜¯è½»æ¾æ„‰å¿«çš„ç»å†ã€‚ä»[ARM](https://en.wikipedia.org/wiki/ARM_architecture_family)æ¶æ„å…¼å®¹æ€§é—®é¢˜åˆ°ä¸æ”¯æŒçš„æœºå™¨å­¦ä¹ åº“â€”â€”æœ‰æ—¶è¦è·å¾—ä¸€ä¸ªå·¥ä½œç¯å¢ƒç¡®å®æ˜¯ä¸€ç§æŒ‘æˆ˜ã€‚è¿™æ˜¯ä»»ä½•é‡å¤§è¿‡æ¸¡å’Œæ“ä½œæ–¹å¼ä¸­éƒ½ä¼šé‡åˆ°çš„é¢„æœŸé—®é¢˜ã€‚æˆ‘ä»ç„¶ä¿æŒä¹è§‚ï¼Œå¹¶çœ‹åˆ°åœ¨ç¨³å®šæ€§å’ŒåŠŸèƒ½æ–¹é¢çš„å…¨é¢é‡å¤§æ”¹è¿›ã€‚
- en: '**In this article, we will preview the Metal.jl Framework in order to understand
    its capabilities. We will also demonstrate a practical example using** [**Flux**](https://fluxml.ai/)**,
    a library for machine learning in Julia, with the Metal backend.**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†é¢„è§ˆ Metal.jl æ¡†æ¶ä»¥äº†è§£å…¶èƒ½åŠ›ã€‚æˆ‘ä»¬è¿˜å°†å±•ç¤ºä¸€ä¸ªä½¿ç”¨** [**Flux**](https://fluxml.ai/)**çš„å®é™…ç¤ºä¾‹ï¼Œå®ƒæ˜¯
    Julia ä¸­çš„ä¸€ä¸ªæœºå™¨å­¦ä¹ åº“ï¼Œå¹¶é…åˆ Metal åç«¯ã€‚**'
- en: '*Here is the outline for the topics covered:*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*ä»¥ä¸‹æ˜¯æ¶µç›–ä¸»é¢˜çš„çº²è¦ï¼š*'
- en: '**I.** [**Project Setup**](#35fc)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**I.** [**é¡¹ç›®è®¾ç½®**](#35fc)'
- en: i. [Julia environment setup](#39c6)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: i. [Julia ç¯å¢ƒè®¾ç½®](#39c6)
- en: ii. [Dependency overview](#8e23)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ii. [ä¾èµ–æ¦‚è¿°](#8e23)
- en: '**II.** [**Leveraging the Metal API**](#6b3d)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**II.** [**åˆ©ç”¨ Metal API**](#6b3d)'
- en: i. [Kernel Functions](#0501)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: i. [å†…æ ¸å‡½æ•°](#0501)
- en: ii. [Benchmarking](#0ab7)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ii. [åŸºå‡†æµ‹è¯•](#0ab7)
- en: iii. [Profiling](#9a1c)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: iii. [æ€§èƒ½åˆ†æ](#9a1c)
- en: '**III.** [**Working with Flux and Metal Backend**](#4dd6)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**III.** [**ä½¿ç”¨ Flux å’Œ Metal Backend**](#4dd6)'
- en: i. [Dataset overview](#29ea)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: i. [æ•°æ®é›†æ¦‚è¿°](#29ea)
- en: ii. [Simple neural network](#76ed)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ii. [ç®€å•ç¥ç»ç½‘ç»œ](#76ed)
- en: iii. [Model evaluation](#3777)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: iii. [æ¨¡å‹è¯„ä¼°](#3777)
- en: 'Readers who wish to follow along should have:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›è·Ÿéšçš„è¯»è€…åº”å…·å¤‡ï¼š
- en: Basic knowledge of the [Julia programming language](https://pub.aimind.so/getting-started-with-the-julia-programming-language-0c0d8521a381).
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹ [Julia ç¼–ç¨‹è¯­è¨€](https://pub.aimind.so/getting-started-with-the-julia-programming-language-0c0d8521a381)
    çš„åŸºæœ¬çŸ¥è¯†ã€‚
- en: High-level understanding of Machine Learning concepts.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹æœºå™¨å­¦ä¹ æ¦‚å¿µçš„é«˜çº§ç†è§£ã€‚
- en: '*Letâ€™s dive in!*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*è®©æˆ‘ä»¬æ·±å…¥äº†è§£å§ï¼*'
- en: '**PROJECT SETUP**'
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é¡¹ç›®è®¾ç½®**'
- en: i. Julia Environment Setup
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: i. Julia ç¯å¢ƒè®¾ç½®
- en: It is considered good practice to set up an environment unique to your project.
    By doing so you will isolate exact versions of packages required for a project
    and allow for an easily reproducible environment for yourself and team members.
    This is easily done in [Julia](https://pub.aimind.so/getting-started-with-the-julia-programming-language-0c0d8521a381)
    as seen below.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾ç½®ä¸€ä¸ªç‰¹å®šäºé¡¹ç›®çš„ç¯å¢ƒè¢«è§†ä¸ºè‰¯å¥½å®è·µã€‚è¿™æ ·å¯ä»¥éš”ç¦»é¡¹ç›®æ‰€éœ€çš„ç¡®åˆ‡ç‰ˆæœ¬çš„åŒ…ï¼Œå¹¶ä¸ºè‡ªå·±å’Œå›¢é˜Ÿæˆå‘˜æä¾›ä¸€ä¸ªå®¹æ˜“å¤ç°çš„ç¯å¢ƒã€‚è¿™åœ¨ [Julia](https://pub.aimind.so/getting-started-with-the-julia-programming-language-0c0d8521a381)
    ä¸­å¾ˆå®¹æ˜“åšåˆ°ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚
- en: ii. Dependency overview
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ii. ä¾èµ–æ¦‚è¿°
- en: '[**Metal**](https://github.com/JuliaGPU/Metal.jl)**:** This is the framework
    that makes it possible to program GPUs on macOS. As mentioned by the contributors,
    the package is a **work-in-progress** and there are bugs, functionality missing,
    and performance that hasnâ€™t been fully optimized yet. **Please ensure you have
    also met the following system requirements:**'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[**Metal**](https://github.com/JuliaGPU/Metal.jl)**:** è¿™æ˜¯ä¸€ä¸ªä½¿åœ¨ macOS ä¸Šç¼–ç¨‹ GPU
    æˆä¸ºå¯èƒ½çš„æ¡†æ¶ã€‚å¦‚è´¡çŒ®è€…æ‰€è¿°ï¼Œè¯¥åŒ…æ˜¯**æ­£åœ¨å¼€å‘ä¸­**ï¼Œå­˜åœ¨é”™è¯¯ã€åŠŸèƒ½ç¼ºå¤±å’Œæ€§èƒ½å°šæœªå®Œå…¨ä¼˜åŒ–çš„æƒ…å†µã€‚**è¯·ç¡®ä¿æ‚¨è¿˜æ»¡è¶³ä»¥ä¸‹ç³»ç»Ÿè¦æ±‚ï¼š**'
- en: âœ” Mac device with M-series chipï¸ï¸ï¸
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: âœ” é…å¤‡ M ç³»åˆ—èŠ¯ç‰‡çš„ Mac è®¾å¤‡ï¸ï¸ï¸
- en: âœ” Julia 1.8â€“1.10
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: âœ” Julia 1.8â€“1.10
- en: âœ” macOS 13 (Ventura) or 14 (Sonoma)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: âœ” macOS 13 (Ventura) æˆ– 14 (Sonoma)
- en: '[**BenchmarkTools**](https://github.com/JuliaGPU/Metal.jl)**:** We will be
    using this library to execute benchmarks for some of the operations we send to
    our GPU via the Metal APIs. This package makes it easy to configure, execute,
    and analyze results.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[**BenchmarkTools**](https://github.com/JuliaGPU/Metal.jl)**:** æˆ‘ä»¬å°†ä½¿ç”¨è¿™ä¸ªåº“æ¥æ‰§è¡Œä¸€äº›æ“ä½œçš„åŸºå‡†æµ‹è¯•ï¼Œè¿™äº›æ“ä½œé€šè¿‡
    Metal APIs å‘é€åˆ°æˆ‘ä»¬çš„ GPUã€‚è¿™ä¸ªåŒ…ä½¿é…ç½®ã€æ‰§è¡Œå’Œåˆ†æç»“æœå˜å¾—å®¹æ˜“ã€‚'
- en: '[**Flux**](https://fluxml.ai/Flux.jl/stable/)**:** Flux is an intuitive machine
    learning library for Julia; it is designed to provide a high-level and user-friendly
    interface for building and training neural networks. We will be using this library
    for the example and leveraging the Metal Backend to leverage our GPUs.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[**Flux**](https://fluxml.ai/Flux.jl/stable/)**:** Flux æ˜¯ä¸€ä¸ªç›´è§‚çš„ Julia æœºå™¨å­¦ä¹ åº“ï¼›å®ƒæ—¨åœ¨æä¾›ä¸€ä¸ªé«˜çº§ä¸”ç”¨æˆ·å‹å¥½çš„ç•Œé¢æ¥æ„å»ºå’Œè®­ç»ƒç¥ç»ç½‘ç»œã€‚æˆ‘ä»¬å°†ä½¿ç”¨è¿™ä¸ªåº“ä½œä¸ºç¤ºä¾‹ï¼Œå¹¶åˆ©ç”¨
    Metal Backend æ¥åˆ©ç”¨æˆ‘ä»¬çš„ GPUã€‚'
- en: Below are the versions for the dependencies at the time of this article.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯æœ¬æ–‡å‘å¸ƒæ—¶çš„ä¾èµ–ç‰ˆæœ¬ã€‚
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: With our environment configured and a high-level understanding of the libraries
    in use, letâ€™s explore the Metal API.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: é…ç½®å¥½æˆ‘ä»¬çš„ç¯å¢ƒå¹¶å¯¹æ‰€ä½¿ç”¨çš„åº“æœ‰äº†é«˜çº§ç†è§£åï¼Œè®©æˆ‘ä»¬æ¢ç´¢ Metal APIã€‚
- en: LEVERAGING THE METAL API
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆ©ç”¨ Metal API
- en: Metal.jl interfaces with Appleâ€™s Metal Graphics API â€” a low-level API developed
    by Apple for their various platforms (macOS, iPhone, watch,â€¦).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Metal.jl ä¸ Apple çš„ Metal å›¾å½¢ API è¿›è¡Œæ¥å£â€”â€”è¿™æ˜¯ Apple ä¸ºå…¶å„ç§å¹³å°ï¼ˆmacOSã€iPhoneã€æ‰‹è¡¨ç­‰ï¼‰å¼€å‘çš„ä½çº§
    APIã€‚
- en: This gives users direct control over the [GPU (Graphics Processing Unit)](https://en.wikipedia.org/wiki/Graphics_processing_unit)
    for tasks such as rendering graphics and parallel computations. Letâ€™s look at
    a basic example.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä½¿ç”¨æˆ·å¯ä»¥ç›´æ¥æ§åˆ¶ [GPU (å›¾å½¢å¤„ç†å•å…ƒ)](https://en.wikipedia.org/wiki/Graphics_processing_unit)ï¼Œç”¨äºæ¸²æŸ“å›¾å½¢å’Œå¹¶è¡Œè®¡ç®—ç­‰ä»»åŠ¡ã€‚è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªåŸºæœ¬çš„ç¤ºä¾‹ã€‚
- en: i. Kernel Functions
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: i. å†…æ ¸å‡½æ•°
- en: In the context of the Apple Metal framework, a **Kernel Function** is a special
    type of function that is executed on the GPU. These functions are written in a
    shading language; in our case, the [Metal Shading Language](https://developer.apple.com/metal/Metal-Shading-Language-Specification.pdf)
    (MSL).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨Apple Metalæ¡†æ¶çš„èƒŒæ™¯ä¸‹ï¼Œ**å†…æ ¸å‡½æ•°**æ˜¯ä¸€ç§åœ¨GPUä¸Šæ‰§è¡Œçš„ç‰¹æ®Šç±»å‹çš„å‡½æ•°ã€‚è¿™äº›å‡½æ•°æ˜¯ç”¨ç€è‰²è¯­è¨€ç¼–å†™çš„ï¼›åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­æ˜¯[Metal Shading
    Language](https://developer.apple.com/metal/Metal-Shading-Language-Specification.pdf)
    (MSL)ã€‚
- en: â€œMSL allows users to write a *shader program,* which is graphics and data-parallel
    compute code that runs on the GPU. Shader programs run on different programmable
    units of the GPU. MSL is a single, unified language that allows tighter integration
    between the graphics and compute programs.â€ Â³
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œMSLå…è®¸ç”¨æˆ·ç¼–å†™ä¸€ä¸ª*shaderç¨‹åº*ï¼Œè¿™æ˜¯ä¸€ç§åœ¨GPUä¸Šè¿è¡Œçš„å›¾å½¢å’Œæ•°æ®å¹¶è¡Œè®¡ç®—ä»£ç ã€‚Shaderç¨‹åºåœ¨GPUçš„ä¸åŒå¯ç¼–ç¨‹å•å…ƒä¸Šè¿è¡Œã€‚MSLæ˜¯ä¸€ä¸ªç»Ÿä¸€çš„è¯­è¨€ï¼Œå…è®¸å›¾å½¢å’Œè®¡ç®—ç¨‹åºä¹‹é—´æœ‰æ›´ç´§å¯†çš„é›†æˆã€‚â€
    Â³
- en: 'Prior to getting started, letâ€™s ensure we can monitor our GPUâ€™s load. Apple
    has built-in GPU history. In the Activity Monitor app on your Mac, choose Window
    > GPU History. You should see something similar to mine:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¼€å§‹ä¹‹å‰ï¼Œè®©æˆ‘ä»¬ç¡®ä¿èƒ½å¤Ÿç›‘æ§GPUçš„è´Ÿè½½ã€‚Appleå…·æœ‰å†…ç½®çš„GPUå†å²è®°å½•ã€‚åœ¨Macä¸Šçš„æ´»åŠ¨ç›‘è§†å™¨åº”ç”¨ä¸­ï¼Œé€‰æ‹©çª—å£ > GPUå†å²è®°å½•ã€‚ä½ åº”è¯¥èƒ½çœ‹åˆ°ç±»ä¼¼æˆ‘çš„ç”»é¢ï¼š
- en: '![](../Images/046fd1e1d9cfc2121cbcc352daec59af.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/046fd1e1d9cfc2121cbcc352daec59af.png)'
- en: GPU History. Spikes to the top indicate max GPU usage | Image by Author
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: GPUå†å²è®°å½•ã€‚é¡¶éƒ¨çš„å°–å³°è¡¨ç¤ºæœ€å¤§GPUä½¿ç”¨ç‡ | å›¾ç‰‡æ¥æºï¼šä½œè€…
- en: For this example, we will create a *matrix multiplication kernel*. To make use
    of the GPU, we will intentionally create compute complexity by iterating *N =
    1 million* times over the matrix operation.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ª*çŸ©é˜µä¹˜æ³•å†…æ ¸*ã€‚ä¸ºäº†åˆ©ç”¨GPUï¼Œæˆ‘ä»¬å°†æ•…æ„é€šè¿‡åœ¨çŸ©é˜µæ“ä½œä¸Šè¿­ä»£*N = 100ä¸‡*æ¬¡æ¥åˆ›å»ºè®¡ç®—å¤æ‚æ€§ã€‚
- en: We will define **A** as an *m x n* matrix, **B** an *n x p* matrix, and **C**
    as the resulting matrix product defined by *m x p.* **C=AB.** The resulting Kernel
    Function is shown below; other than a few tweaks to the Kernel Function and the
    Matrix variables defined at the bottom, the code is quite similar to what you
    would expect in Julia.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†å®šä¹‰**A**ä¸ºä¸€ä¸ª*m x n*çŸ©é˜µï¼Œ**B**ä¸ºä¸€ä¸ª*n x p*çŸ©é˜µï¼Œ**C**ä¸ºç”±*m x p*å®šä¹‰çš„ç»“æœçŸ©é˜µã€‚**C=ABã€‚** ç»“æœçš„å†…æ ¸å‡½æ•°å¦‚ä¸‹æ‰€ç¤ºï¼›é™¤äº†å¯¹å†…æ ¸å‡½æ•°å’Œåº•éƒ¨å®šä¹‰çš„çŸ©é˜µå˜é‡è¿›è¡Œä¸€äº›å°çš„è°ƒæ•´å¤–ï¼Œä»£ç ä¸ä½ åœ¨Juliaä¸­æœŸæœ›çš„ç›¸å½“ç›¸ä¼¼ã€‚
- en: 'The subtle differences, or additions, are as follows: The **thread_position_in_grid_1d()**
    function returns the index of the current thread within its one-dimensional grid.
    Essentially, it will know which data on each thread the GPU should operate. This
    fine-grained approach in controlling thread assignment gives the user the power
    to maximize the computational power of their system.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å¾®å¦™çš„å·®å¼‚æˆ–é™„åŠ å†…å®¹å¦‚ä¸‹ï¼š**thread_position_in_grid_1d()**å‡½æ•°è¿”å›å½“å‰çº¿ç¨‹åœ¨å…¶ä¸€ç»´ç½‘æ ¼ä¸­çš„ç´¢å¼•ã€‚åŸºæœ¬ä¸Šï¼Œå®ƒä¼šçŸ¥é“GPUåº”è¯¥åœ¨æ¯ä¸ªçº¿ç¨‹ä¸Šæ“ä½œå“ªäº›æ•°æ®ã€‚è¿™ç§ç²¾ç»†åŒ–çš„çº¿ç¨‹åˆ†é…æ§åˆ¶æ–¹æ³•ä½¿ç”¨æˆ·èƒ½å¤Ÿæœ€å¤§é™åº¦åœ°å‘æŒ¥ç³»ç»Ÿçš„è®¡ç®—èƒ½åŠ›ã€‚
- en: 'When we initialize our matrices **A**, **B**, and **C** we want to ensure we
    are initializing values on the GPU using Metal; this ensures we are making it
    suitable for GPU-accelerated computations. In addition, the **storage=Shared**
    parameter indicates that the matrix data should be stored in [shared memory](https://developer.apple.com/documentation/metal/mtlstoragemode/mtlstoragemodeshared?language=objc),
    giving access to both CPU and GPU. By doing so, we need to ensure we synchronize
    prior to accessing that resource:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬åˆå§‹åŒ–çŸ©é˜µ**A**ã€**B**å’Œ**C**æ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›ç¡®ä¿åœ¨GPUä¸Šä½¿ç”¨Metalåˆå§‹åŒ–å€¼ï¼›è¿™ç¡®ä¿æˆ‘ä»¬ä½¿å…¶é€‚åˆGPUåŠ é€Ÿè®¡ç®—ã€‚æ­¤å¤–ï¼Œ**storage=Shared**å‚æ•°æŒ‡ç¤ºçŸ©é˜µæ•°æ®åº”å­˜å‚¨åœ¨[å…±äº«å†…å­˜](https://developer.apple.com/documentation/metal/mtlstoragemode/mtlstoragemodeshared?language=objc)ä¸­ï¼Œä»è€Œä½¿CPUå’ŒGPUéƒ½èƒ½è®¿é—®ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿åœ¨è®¿é—®è¯¥èµ„æºä¹‹å‰è¿›è¡ŒåŒæ­¥ï¼š
- en: â€œEnsure that all changes you schedule on either the CPU or GPU for a resource
    that uses shared memory complete before accessing that resource on the other processor.â€
    Â²
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œç¡®ä¿ä½ åœ¨CPUæˆ–GPUä¸Šä¸ºä½¿ç”¨å…±äº«å†…å­˜çš„èµ„æºå®‰æ’çš„æ‰€æœ‰æ›´æ”¹åœ¨è®¿é—®è¯¥èµ„æºçš„å¦ä¸€ä¸ªå¤„ç†å™¨ä¹‹å‰å®Œæˆã€‚â€ Â²
- en: Last thing to mention is the `C_cpu` variable at the end. The `unsafe_wrap`
    function is used to create a CPU array, `C_cpu`, that shares the same underlying
    memory as the GPU array `C`. This enables us to transfer data between the CPU
    and GPU in order to perform computations later on. In the example below, I will
    show that we can modify the resulting matrix C by doing a inverse on it after
    all GPU operations have completed (*inv(C_cpu)).*
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åè¦æåˆ°çš„æ˜¯æœ«å°¾çš„`C_cpu`å˜é‡ã€‚`unsafe_wrap`å‡½æ•°ç”¨äºåˆ›å»ºä¸€ä¸ªä¸GPUæ•°ç»„`C`å…±äº«ç›¸åŒåº•å±‚å†…å­˜çš„CPUæ•°ç»„`C_cpu`ã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨CPUå’ŒGPUä¹‹é—´ä¼ è¾“æ•°æ®ï¼Œä»¥ä¾¿åç»­è¿›è¡Œè®¡ç®—ã€‚åœ¨ä¸‹é¢çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘å°†å±•ç¤ºåœ¨æ‰€æœ‰GPUæ“ä½œå®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å¯¹å…¶è¿›è¡Œé€†æ“ä½œæ¥ä¿®æ”¹ç»“æœçŸ©é˜µCï¼ˆ*inv(C_cpu))ã€‚*
- en: Great! Now that we have our kernel ready, letâ€™s move on to do the computation
    and benchmarking.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: å¤ªæ£’äº†ï¼ç°åœ¨æˆ‘ä»¬å·²ç»å‡†å¤‡å¥½äº†å†…æ ¸ï¼Œæ¥ä¸‹æ¥è¿›è¡Œè®¡ç®—å’ŒåŸºå‡†æµ‹è¯•å§ã€‚
- en: ii. Benchmarking
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ii. åŸºå‡†æµ‹è¯•
- en: The **benchmark** macro (*macros start with â€œ@â€*) is used to measure the performance
    of the GPU kernel **matrix_multiplication_kernel.**
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**benchmark**å®ï¼ˆ*å®ä»¥â€œ@â€å¼€å¤´*ï¼‰ç”¨äºæµ‹é‡GPUå†…æ ¸**matrix_multiplication_kernel**çš„æ€§èƒ½ã€‚'
- en: Prior to executing our `begin...end` block we will use the `Metal.@sync` to
    ensure synchronization between the CPU and GPU occurs and that all GPU commands
    have completed prior to moving onto the CPU code.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ‰§è¡Œæˆ‘ä»¬çš„`begin...end`å—ä¹‹å‰ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨`Metal.@sync`ç¡®ä¿CPUå’ŒGPUä¹‹é—´çš„åŒæ­¥ï¼Œå¹¶ä¸”æ‰€æœ‰GPUå‘½ä»¤åœ¨åˆ‡æ¢åˆ°CPUä»£ç ä¹‹å‰å·²ç»å®Œæˆã€‚
- en: Within the **metal** macro, we specify both the number of `threads`and `groups`.
    Each thread is responsible for performing a computation. This number also determines
    how many operations occur in parallel. For instance, if we specify 256 threads
    then each thread will be responsible for a portion of the computation. Threads
    are organized in groups; a thread group is a collection of threads that can work
    together and coordinate the parallel execution of threads.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨**metal**å®ä¸­ï¼Œæˆ‘ä»¬æŒ‡å®šäº†`threads`å’Œ`groups`çš„æ•°é‡ã€‚æ¯ä¸ªçº¿ç¨‹è´Ÿè´£æ‰§è¡Œè®¡ç®—ã€‚è¿™ä¸ªæ•°é‡è¿˜å†³å®šäº†å¤šå°‘æ“ä½œå¯ä»¥å¹¶è¡Œè¿›è¡Œã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æŒ‡å®š256ä¸ªçº¿ç¨‹ï¼Œåˆ™æ¯ä¸ªçº¿ç¨‹å°†è´Ÿè´£ä¸€éƒ¨åˆ†è®¡ç®—ã€‚çº¿ç¨‹è¢«ç»„ç»‡æˆç»„ï¼›ä¸€ä¸ªçº¿ç¨‹ç»„æ˜¯å¯ä»¥ä¸€èµ·å·¥ä½œå¹¶åè°ƒçº¿ç¨‹å¹¶è¡Œæ‰§è¡Œçš„çº¿ç¨‹é›†åˆã€‚
- en: In total, the M1 GPU contains up to 128 [Execution units](https://en.wikipedia.org/wiki/Execution_unit)
    or 1024 ALUs,â´ which Apple says can execute up to 24,576 threads simultaneously
    and which have a maximum floating point (FP32) performance of 2.6 [TFLOPs](https://en.wikipedia.org/wiki/TFLOPS).âµ
    â¶
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ€»çš„æ¥è¯´ï¼ŒM1 GPUåŒ…å«æœ€å¤š128ä¸ª[æ‰§è¡Œå•å…ƒ](https://en.wikipedia.org/wiki/Execution_unit)æˆ–1024ä¸ªALUï¼Œâ´
    è‹¹æœè¡¨ç¤ºè¿™äº›æ‰§è¡Œå•å…ƒå¯ä»¥åŒæ—¶æ‰§è¡Œæœ€å¤š24,576ä¸ªçº¿ç¨‹ï¼Œå¹¶ä¸”å…¶æœ€å¤§æµ®ç‚¹ï¼ˆFP32ï¼‰æ€§èƒ½ä¸º2.6 [TFLOPs](https://en.wikipedia.org/wiki/TFLOPS)ã€‚âµ
    â¶
- en: Here are the results after playing around with the ***N (100)***, ***threads
    (256)***, and ***groups (256)*** parameters.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢æ˜¯å¯¹***N (100)***ã€***threads (256)***å’Œ***groups (256)***å‚æ•°è¿›è¡Œè°ƒæ•´åçš„ç»“æœã€‚
- en: '![](../Images/8aa87b1f71d7a814246f48f7a8e3ae48.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8aa87b1f71d7a814246f48f7a8e3ae48.png)'
- en: Benchmark Results | Image by Author
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºå‡†æµ‹è¯•ç»“æœ | ä½œè€…æä¾›çš„å›¾ç‰‡
- en: iii. Profiling
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: iii. æ€§èƒ½åˆ†æ
- en: '*In order to Profile and view the results you must have* [*XCode*](https://developer.apple.com/xcode/)
    *installed.*'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '*è¦è¿›è¡Œæ€§èƒ½åˆ†æå¹¶æŸ¥çœ‹ç»“æœï¼Œæ‚¨å¿…é¡»å®‰è£…* [*XCode*](https://developer.apple.com/xcode/)ã€‚'
- en: Profiling code, an often overlooked discipline, is a crucial aspect of software
    development and performance optimization. Profiling involves measuring various
    aspects of a programâ€™s execute. This can be things such as time taken by different
    functions, frequency of function calls, memory and usage or leaks. Profiling is
    also useful for ensuring any code changes made are quantified by means of performance.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: æ€§èƒ½åˆ†æä»£ç æ˜¯ä¸€ä¸ªå¸¸è¢«å¿½è§†çš„å­¦ç§‘ï¼Œå®ƒæ˜¯è½¯ä»¶å¼€å‘å’Œæ€§èƒ½ä¼˜åŒ–çš„å…³é”®æ–¹é¢ã€‚æ€§èƒ½åˆ†ææ¶‰åŠæµ‹é‡ç¨‹åºæ‰§è¡Œçš„å„ç§æ–¹é¢ã€‚è¿™å¯ä»¥åŒ…æ‹¬ä¸åŒå‡½æ•°æ‰€éœ€çš„æ—¶é—´ã€å‡½æ•°è°ƒç”¨çš„é¢‘ç‡ã€å†…å­˜ä½¿ç”¨æˆ–æ³„æ¼ã€‚æ€§èƒ½åˆ†æè¿˜æœ‰åŠ©äºç¡®ä¿å¯¹ä»£ç æ‰€åšçš„ä»»ä½•æ›´æ”¹é€šè¿‡æ€§èƒ½é‡åŒ–ã€‚
- en: If youâ€™ve experienced a scenario where code deployed to production unexpectedly
    causes a significant slowdown in system performance, only to discover later that
    a junior programmer inadvertently introduced a nested loop with quadratic time
    complexity O(nÂ²), youâ€™re not alone. While nested for-loops may seem acceptable
    in some situations the implications become increasingly problematic with a large
    number of values â€” leading to considerable performance challenges. **Catch this
    early, catch this with profiling!**
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ›¾ç»å†è¿‡ä»£ç éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒåæ„å¤–å¯¼è‡´ç³»ç»Ÿæ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œåæ¥å‘ç°æ˜¯å› ä¸ºåˆçº§ç¨‹åºå‘˜æ— æ„ä¸­å¼•å…¥äº†ä¸€ä¸ªæ—¶é—´å¤æ‚åº¦ä¸ºO(nÂ²)çš„åµŒå¥—å¾ªç¯ï¼Œä½ å¹¶ä¸å­¤å•ã€‚è™½ç„¶åµŒå¥—çš„forå¾ªç¯åœ¨æŸäº›æƒ…å†µä¸‹çœ‹ä¼¼å¯ä»¥æ¥å—ï¼Œä½†éšç€å€¼çš„æ•°é‡å¢åŠ ï¼Œå…¶å½±å“å˜å¾—è¶Šæ¥è¶Šéº»çƒ¦ï¼Œå¯¼è‡´æ˜¾è‘—çš„æ€§èƒ½æŒ‘æˆ˜ã€‚**åŠæ—©å‘ç°ï¼Œå€ŸåŠ©æ€§èƒ½åˆ†ææ¥æ•æ‰ï¼**
- en: 'Profiling is done trivially with two steps. First, we need to specify the `Metal.@profile`
    macro in front of our `metal` macro. Next, ensure you have the following environment
    variable set: **ENV[â€œMETAL_CAPTURE_ENABLEDâ€] = 1**'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: æ€§èƒ½åˆ†æå¯ä»¥é€šè¿‡ä¸¤ä¸ªæ­¥éª¤ç®€å•å®Œæˆã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦åœ¨`metal`å®å‰é¢æŒ‡å®š`Metal.@profile`å®ã€‚æ¥ä¸‹æ¥ï¼Œç¡®ä¿ä½ è®¾ç½®äº†ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š**ENV[â€œMETAL_CAPTURE_ENABLEDâ€]
    = 1**
- en: 'Now you can execute the following line:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ä½ å¯ä»¥æ‰§è¡Œä»¥ä¸‹ä»£ç ï¼š
- en: '`Metal.@profile @metal threads=n_threads groups=n_groups matrix_multiplication_kernel(A,
    B, C)`'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '`Metal.@profile @metal threads=n_threads groups=n_groups matrix_multiplication_kernel(A,
    B, C)`'
- en: From there, we get a resulting **julia_capture_*N*.gputrace** stored in the
    same directory as the project. To interact with this, open it in XCode and replay
    the trace. We are presented with various useful metrics that we can dig into.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é‚£é‡Œï¼Œæˆ‘ä»¬è·å¾—ä¸€ä¸ª**julia_capture_*N*.gputrace**æ–‡ä»¶ï¼Œå­˜å‚¨åœ¨ä¸é¡¹ç›®ç›¸åŒçš„ç›®å½•ä¸­ã€‚è¦ä¸ä¹‹äº¤äº’ï¼Œè¯·åœ¨XCodeä¸­æ‰“å¼€å®ƒå¹¶é‡æ”¾è·Ÿè¸ªã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å„ç§æœ‰ç”¨çš„æŒ‡æ ‡ï¼Œå¯ä»¥è¿›ä¸€æ­¥æŒ–æ˜ã€‚
- en: '![](../Images/679ccf8c1699e5581792249c64d55f66.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/679ccf8c1699e5581792249c64d55f66.png)'
- en: Xcode | Image by Author
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Xcode | ä½œè€…æä¾›çš„å›¾ç‰‡
- en: At this point, we have covered how to interact with Appleâ€™s Metal Graphics API
    through Metal.jl â€” giving us direct GPU control for parallel computations. We
    have introduced Kernel Functions in the Metal Shading Language with a matrix multiplication
    kernel that intentionally increases GPU workloads. Additionally, we have introduced
    benchmarking tools and profiling capabilities through Metalâ€™s macros.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°æ­¤ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»ä»‹ç»äº†å¦‚ä½•é€šè¿‡Metal.jlä¸Appleçš„Metalå›¾å½¢APIäº¤äº’â€”â€”è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿç›´æ¥æ§åˆ¶GPUä»¥è¿›è¡Œå¹¶è¡Œè®¡ç®—ã€‚æˆ‘ä»¬ä»‹ç»äº†Metalç€è‰²è¯­è¨€ä¸­çš„å†…æ ¸å‡½æ•°ï¼Œå¹¶ä½¿ç”¨äº†ä¸€ä¸ªæ•…æ„å¢åŠ GPUå·¥ä½œè´Ÿè½½çš„çŸ©é˜µä¹˜æ³•å†…æ ¸ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡Metalçš„å®ä»‹ç»äº†åŸºå‡†æµ‹è¯•å·¥å…·å’Œæ€§èƒ½åˆ†æèƒ½åŠ›ã€‚
- en: '*Letâ€™s move on to a practical scenario!*'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*è®©æˆ‘ä»¬è¿›å…¥ä¸€ä¸ªå®é™…çš„åœºæ™¯ï¼*'
- en: WORKING WITH FLUX AND METAL BACKEND
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Fluxå’ŒMetalåç«¯
- en: i. Dataset overview
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: i. æ•°æ®é›†æ¦‚è¿°
- en: We will be using a Breast Cancer database obtained from the University of Wisconsin
    Hospitals, Madison from Dr. William H. Wolberg.Â¹â° Â¹Â¹ The ***Class*** feature will
    be the target where there are two possible values (2 for benign and 4 for malignant).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨ä»å¨æ–¯åº·æ˜Ÿå¤§å­¦åŒ»é™¢éº¦è¿ªé€Šåˆ†é™¢çš„å¨å»‰Â·HÂ·æ²ƒå°”ä¼¯æ ¼åšå£«é‚£é‡Œè·å¾—çš„ä¹³è…ºç™Œæ•°æ®åº“ã€‚Â¹â° Â¹Â¹ ***Class***ç‰¹å¾å°†ä½œä¸ºç›®æ ‡ï¼Œå…¶ä¸­æœ‰ä¸¤ä¸ªå¯èƒ½çš„å€¼ï¼ˆ2è¡¨ç¤ºè‰¯æ€§ï¼Œ4è¡¨ç¤ºæ¶æ€§ï¼‰ã€‚
- en: 'For brevity, I will not demonstrate the preprocessing required for the dataset,
    instead I will refer the reader to [Appendix I: The Julia source code](#e585).'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç®€æ´èµ·è§ï¼Œæˆ‘å°†ä¸ä¼šæ¼”ç¤ºæ•°æ®é›†æ‰€éœ€çš„é¢„å¤„ç†ï¼Œè€Œæ˜¯å°†è¯»è€…å‚è€ƒåˆ°[é™„å½•Iï¼šJuliaæºä»£ç ](#e585)ã€‚
- en: ii. Simple neural network
  id: totrans-81
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ii. ç®€å•çš„ç¥ç»ç½‘ç»œ
- en: We will be building a simple neural network with [Flux](https://fluxml.ai/Flux.jl/stable/)
    that leverages the [Metal](https://developer.apple.com/documentation/metal) backend.
    Starting with v0.14, Flux doesnâ€™t force a specific GPU backend and the corresponding
    package dependencies on the users.â· Although we are using Metal as the backend,
    Flux supports other [backends](https://fluxml.ai/Flux.jl/stable/gpu/) such as
    AMDGPU and CUDA.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨[Flux](https://fluxml.ai/Flux.jl/stable/)æ„å»ºä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œï¼Œè¯¥ç½‘ç»œåˆ©ç”¨äº†[Metal](https://developer.apple.com/documentation/metal)åç«¯ã€‚ä»v0.14å¼€å§‹ï¼ŒFluxä¸å¼ºåˆ¶ç”¨æˆ·ä½¿ç”¨ç‰¹å®šçš„GPUåç«¯å’Œç›¸åº”çš„è½¯ä»¶åŒ…ä¾èµ–ã€‚â·
    å°½ç®¡æˆ‘ä»¬ä½¿ç”¨Metalä½œä¸ºåç«¯ï¼ŒFluxä¹Ÿæ”¯æŒå…¶ä»–[åç«¯](https://fluxml.ai/Flux.jl/stable/gpu/)ï¼Œå¦‚AMDGPUå’ŒCUDAã€‚
- en: Letâ€™s do a quick sanity check to ensure our environment is setup.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åšä¸€ä¸ªå¿«é€Ÿçš„åˆç†æ€§æ£€æŸ¥ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬çš„ç¯å¢ƒè®¾ç½®æ­£ç¡®ã€‚
- en: '![](../Images/afda8bc58b7407e04fdf3adcdc2dd4d8.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/afda8bc58b7407e04fdf3adcdc2dd4d8.png)'
- en: Testing Metal with Flux | Image by Author
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Fluxæµ‹è¯•Metal | ä½œè€…æä¾›çš„å›¾ç‰‡
- en: Now that we have the `device` variable we will be using that to move data and
    model to the GPU. **Be careful here as you can perform all business logic in Flux
    without ever exporting the model to the GPU â€” meaning, youâ€™re still using the
    CPU (yikes)!**
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰äº†`device`å˜é‡ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å®ƒå°†æ•°æ®å’Œæ¨¡å‹ç§»åˆ°GPUä¸Šã€‚**åœ¨è¿™é‡Œè¦å°å¿ƒï¼Œä½ å¯ä»¥åœ¨Fluxä¸­æ‰§è¡Œæ‰€æœ‰ä¸šåŠ¡é€»è¾‘ï¼Œè€Œä¸éœ€è¦å°†æ¨¡å‹å¯¼å‡ºåˆ°GPUâ€”â€”è¿™æ„å‘³ç€ä½ ä»åœ¨ä½¿ç”¨CPUï¼ˆå“å‘€ï¼‰ï¼**
- en: '![](../Images/4611a46eaa8be2e2c617e2a9deba28b0.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4611a46eaa8be2e2c617e2a9deba28b0.png)'
- en: Model Definition (This will be a Logistic Regression model for our 2-class problem)
    | Image by Author
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹å®šä¹‰ï¼ˆå¯¹äºæˆ‘ä»¬çš„äºŒåˆ†ç±»é—®é¢˜ï¼Œè¿™å°†æ˜¯ä¸€ä¸ªé€»è¾‘å›å½’æ¨¡å‹ï¼‰ | ä½œè€…æä¾›çš„å›¾ç‰‡
- en: To prepare our data for the run, we will be leveraging [Flux.DataLoader](https://fluxml.ai/Flux.jl/previews/PR1786/data/dataloader/).
    This module handles iterations over mini-batches of data. Iâ€™ve keep it simple
    for this demo with a `batchsize=1` . This means that if my data contains 800 rows
    each batch is associated to a row. In a more efficient scenario you may want to
    split that up so you can group the data you are processing.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å‡†å¤‡æˆ‘ä»¬çš„æ•°æ®è¿è¡Œï¼Œæˆ‘ä»¬å°†åˆ©ç”¨ [Flux.DataLoader](https://fluxml.ai/Flux.jl/previews/PR1786/data/dataloader/)ã€‚è¿™ä¸ªæ¨¡å—å¤„ç†å¯¹å°æ‰¹é‡æ•°æ®çš„è¿­ä»£ã€‚ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä¿æŒç®€å•ï¼Œè®¾ç½®äº†`batchsize=1`ã€‚è¿™æ„å‘³ç€å¦‚æœæˆ‘çš„æ•°æ®åŒ…å«800è¡Œï¼Œæ¯ä¸ªæ‰¹æ¬¡ä¸ä¸€è¡Œæ•°æ®ç›¸å…³ã€‚åœ¨æ›´é«˜æ•ˆçš„åœºæ™¯ä¸­ï¼Œä½ å¯èƒ½å¸Œæœ›å°†æ•°æ®åˆ†å¼€ï¼Œä»¥ä¾¿å°†å¤„ç†çš„æ•°æ®è¿›è¡Œåˆ†ç»„ã€‚
- en: Before jumping into the next section, it is important to note that I faced issues
    passing my DataFrame directly to the DataLoader, so here are a few workarounds
    I had to implement.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è·³åˆ°ä¸‹ä¸€éƒ¨åˆ†ä¹‹å‰ï¼Œé‡è¦çš„æ˜¯è¦æ³¨æ„æˆ‘åœ¨å°† DataFrame ç›´æ¥ä¼ é€’ç»™ DataLoader æ—¶é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œæ‰€ä»¥è¿™é‡Œæœ‰ä¸€äº›æˆ‘å¿…é¡»å®ç°çš„è§£å†³æ–¹æ³•ã€‚
- en: '![](../Images/515646d0995f178f0a87d144b469105c.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/515646d0995f178f0a87d144b469105c.png)'
- en: Data Prep | Image by Author
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ | å›¾ç‰‡æ¥æºï¼šä½œè€…
- en: iii. Model evaluation
  id: totrans-93
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: iii. æ¨¡å‹è¯„ä¼°
- en: The following code illustrates the model training and evaluation process. It
    is crucial to utilize the GPU when the `x_cpu` and `y_cpu` variables (our rows
    and labels) are returned from the [DataLoader](https://fluxml.ai/Flux.jl/previews/PR1786/data/dataloader/)
    â€” a failure to do so will crash due to compatibility issues as our model is expecting
    data on the GPU to work with.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹ä»£ç æ¼”ç¤ºäº†æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°è¿‡ç¨‹ã€‚å½“ `x_cpu` å’Œ `y_cpu` å˜é‡ï¼ˆæˆ‘ä»¬çš„è¡Œå’Œæ ‡ç­¾ï¼‰ä» [DataLoader](https://fluxml.ai/Flux.jl/previews/PR1786/data/dataloader/)
    è¿”å›æ—¶ï¼Œåˆ©ç”¨ GPU æ˜¯è‡³å…³é‡è¦çš„â€”â€”å¦åˆ™ï¼Œç”±äºå…¼å®¹æ€§é—®é¢˜ï¼Œæ¨¡å‹æœŸæœ›åœ¨ GPU ä¸Šçš„æ•°æ®å°†å¯¼è‡´å´©æºƒã€‚
- en: '![](../Images/716e15b34c3f867abfe2b083e390b83d.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/716e15b34c3f867abfe2b083e390b83d.png)'
- en: Demo of project running and leveraging M1-Max GPU! | Image by Author
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: é¡¹ç›®è¿è¡Œæ¼”ç¤ºåŠåˆ©ç”¨ M1-Max GPUï¼ | å›¾ç‰‡æ¥æºï¼šä½œè€…
- en: 'In this brief look into the Metal.jl Framework, we have covered the basics
    of GPU programming on Appleâ€™s hardware. By exploring three core concepts â€” *Kernel
    Functions, Benchmarking, and Profiling* â€” the reader now has a high-level understanding
    of how to get started and is encouraged to dive deeper into the APIâ€™s capabilities.
    Additionally, we have demonstrated a practical example that leverages Flux to
    build a simple neural network application that leverages the [Metal backend](https://fluxml.ai/Flux.jl/stable/gpu/).
    If youâ€™re a data scientist or ML engineer looking to tap into the power of your
    Apple M-series GPU, I hope this article has served as a starting point for accelerating
    your computational workflows. From here, I will leave the reader with a few more
    resources to check out:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¯¹ Metal.jl æ¡†æ¶çš„ç®€è¦ä»‹ç»ä¸­ï¼Œæˆ‘ä»¬æ¶µç›–äº†åœ¨ Apple ç¡¬ä»¶ä¸Šè¿›è¡Œ GPU ç¼–ç¨‹çš„åŸºç¡€çŸ¥è¯†ã€‚é€šè¿‡æ¢ç´¢ä¸‰ä¸ªæ ¸å¿ƒæ¦‚å¿µâ€”â€”*å†…æ ¸å‡½æ•°ã€åŸºå‡†æµ‹è¯•å’Œæ€§èƒ½åˆ†æ*â€”â€”è¯»è€…ç°åœ¨å¯¹å¦‚ä½•å…¥é—¨æœ‰äº†è¾ƒé«˜å±‚æ¬¡çš„ç†è§£ï¼Œå¹¶è¢«é¼“åŠ±æ·±å…¥æ¢ç´¢
    API çš„åŠŸèƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¼”ç¤ºäº†ä¸€ä¸ªå®é™…ç¤ºä¾‹ï¼Œåˆ©ç”¨ Flux æ„å»ºäº†ä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œåº”ç”¨ç¨‹åºï¼Œä½¿ç”¨äº† [Metal åç«¯](https://fluxml.ai/Flux.jl/stable/gpu/)ã€‚å¦‚æœä½ æ˜¯æ•°æ®ç§‘å­¦å®¶æˆ–
    ML å·¥ç¨‹å¸ˆï¼Œæƒ³è¦åˆ©ç”¨ Apple M ç³»åˆ— GPU çš„å¼ºå¤§åŠŸèƒ½ï¼Œå¸Œæœ›è¿™ç¯‡æ–‡ç« èƒ½ä½œä¸ºåŠ é€Ÿä½ çš„è®¡ç®—å·¥ä½œæµçš„èµ·ç‚¹ã€‚ä»è¿™é‡Œï¼Œæˆ‘å°†ç•™ä¸‹æ›´å¤šèµ„æºä¾›è¯»è€…æŸ¥çœ‹ï¼š
- en: '[](https://fluxml.ai/Flux.jl/stable/?source=post_page-----2db5fe8ee32c--------------------------------)
    [## Welcome Â· Flux'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://fluxml.ai/Flux.jl/stable/?source=post_page-----2db5fe8ee32c--------------------------------)
    [## æ¬¢è¿ Â· Flux'
- en: Flux is a library for machine learning. It comes "batteries-included" with many
    useful tools built in, but also letsâ€¦
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Flux æ˜¯ä¸€ä¸ªæœºå™¨å­¦ä¹ åº“ã€‚å®ƒåŒ…å«è®¸å¤šæœ‰ç”¨çš„å·¥å…·ï¼Œä½†ä¹Ÿå…è®¸â€¦
- en: fluxml.ai](https://fluxml.ai/Flux.jl/stable/?source=post_page-----2db5fe8ee32c--------------------------------)
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: fluxml.ai](https://fluxml.ai/Flux.jl/stable/?source=post_page-----2db5fe8ee32c--------------------------------)
- en: '*I hope you enjoyed this article, thank you for reading!*'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*å¸Œæœ›ä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œè°¢è°¢é˜…è¯»ï¼*'
- en: ğŸ‘
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ‘
- en: '**Lastly, I want to give a big shoutout to the creators of the Metal.jl project.
    I am looking forward to the continued success of the project. For anyone looking
    to contribute, please check out their Github page** [**here**](https://github.com/JuliaGPU/Metal.jl)**.**'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**æœ€åï¼Œæˆ‘è¦å¤§åŠ›æ„Ÿè°¢ Metal.jl é¡¹ç›®çš„åˆ›ä½œè€…ã€‚æˆ‘æœŸå¾…è¯¥é¡¹ç›®ç»§ç»­æˆåŠŸã€‚å¯¹äºä»»ä½•å¸Œæœ›è´¡çŒ®çš„äººï¼Œè¯·æŸ¥çœ‹ä»–ä»¬çš„ Github é¡µé¢** [**è¿™é‡Œ**](https://github.com/JuliaGPU/Metal.jl)**ã€‚**'
- en: 'Appendix I: Julia Source Code'
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é™„å½• Iï¼šJulia æºä»£ç 
- en: Prior to running the source code found in the Github, I highly recommend matching
    the versions found in this article to ensure a successful compilation. Furthermore,
    the Metal.jl library is a work in progress and may lack or contains different
    features depending on the version specified.
  id: totrans-105
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åœ¨è¿è¡ŒGithubä¸Šæ‰¾åˆ°çš„æºä»£ç ä¹‹å‰ï¼Œæˆ‘å¼ºçƒˆå»ºè®®åŒ¹é…æœ¬æ–‡ä¸­æ‰¾åˆ°çš„ç‰ˆæœ¬ï¼Œä»¥ç¡®ä¿æˆåŠŸç¼–è¯‘ã€‚æ­¤å¤–ï¼ŒMetal.jlåº“ä»åœ¨å¼€å‘ä¸­ï¼Œå¯èƒ½ä¼šæ ¹æ®æŒ‡å®šçš„ç‰ˆæœ¬ç¼ºå°‘æˆ–åŒ…å«ä¸åŒçš„åŠŸèƒ½ã€‚
- en: ğŸ”— [https://github.com/lausena/JuliaExperiments/tree/main](https://github.com/lausena/JuliaExperiments/tree/main)
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ”— [https://github.com/lausena/JuliaExperiments/tree/main](https://github.com/lausena/JuliaExperiments/tree/main)
- en: '*A supplement for preprocessing can be found in this* [*post*](https://medium.com/ai-mind-labs/practical-julia-logistic-regression-4e97a3cc3df8)*.*'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '*é¢„å¤„ç†çš„è¡¥å……å†…å®¹å¯ä»¥åœ¨æ­¤* [*å¸–å­*](https://medium.com/ai-mind-labs/practical-julia-logistic-regression-4e97a3cc3df8)*ä¸­æ‰¾åˆ°*ã€‚'
- en: '[](https://medium.com/subscribe/@lausena?source=post_page-----2db5fe8ee32c--------------------------------)
    [## Get an email whenever Gabriel Sena publishes.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/subscribe/@lausena?source=post_page-----2db5fe8ee32c--------------------------------)
    [## æ¯å½“Gabriel Senaå‘å¸ƒæ–°å†…å®¹æ—¶ï¼Œä½ å°†ä¼šæ”¶åˆ°ç”µå­é‚®ä»¶ã€‚'
- en: Get an email whenever Gabriel Sena publishes. By signing up, you will create
    a Medium account if you don't already haveâ€¦
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ¯å½“Gabriel Senaå‘å¸ƒæ–°å†…å®¹æ—¶ï¼Œä½ å°†ä¼šæ”¶åˆ°ç”µå­é‚®ä»¶ã€‚é€šè¿‡æ³¨å†Œï¼Œå¦‚æœä½ è¿˜æ²¡æœ‰Mediumè´¦æˆ·ï¼Œå°†ä¼šåˆ›å»ºä¸€ä¸ªâ€¦
- en: medium.com](https://medium.com/subscribe/@lausena?source=post_page-----2db5fe8ee32c--------------------------------)
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/subscribe/@lausena?source=post_page-----2db5fe8ee32c--------------------------------)
- en: '***References***'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '***å‚è€ƒæ–‡çŒ®***'
- en: '[1] [https://www.youtube.com/watch?v=IARikXzRU7s&ab_channel=TheJuliaProgrammingLanguage](https://www.youtube.com/watch?v=IARikXzRU7s&ab_channel=TheJuliaProgrammingLanguage)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [https://www.youtube.com/watch?v=IARikXzRU7s&ab_channel=TheJuliaProgrammingLanguage](https://www.youtube.com/watch?v=IARikXzRU7s&ab_channel=TheJuliaProgrammingLanguage)'
- en: '[2] [https://juliagpu.org/post/2022-06-24-metal/index.html](https://juliagpu.org/post/2022-06-24-metal/index.html)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [https://juliagpu.org/post/2022-06-24-metal/index.html](https://juliagpu.org/post/2022-06-24-metal/index.html)'
- en: '[3] [https://developer.apple.com/metal/Metal-Shading-Language-Specification.pdf](https://developer.apple.com/metal/Metal-Shading-Language-Specification.pdf)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [https://developer.apple.com/metal/Metal-Shading-Language-Specification.pdf](https://developer.apple.com/metal/Metal-Shading-Language-Specification.pdf)'
- en: '[4] Frumusanu, Andrei. [â€œThe 2020 Mac Mini Unleashed: Putting Apple Silicon
    M1 To The Testâ€](https://www.anandtech.com/show/16252/mac-mini-apple-m1-tested).
    [*www.anandtech.com*.](http://www.anandtech.com.) [Archived](https://web.archive.org/web/20210201183558/https://www.anandtech.com/show/16252/mac-mini-apple-m1-tested)
    from the original on 2021â€“02â€“01\. Retrieved 2021â€“01â€“30.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Frumusanu, Andreiã€‚ [â€œ2020 Mac Miniå¤§æ­ç§˜ï¼šæµ‹è¯•Apple Silicon M1â€](https://www.anandtech.com/show/16252/mac-mini-apple-m1-tested)ã€‚
    [*www.anandtech.com*](http://www.anandtech.com)ã€‚ [å­˜æ¡£](https://web.archive.org/web/20210201183558/https://www.anandtech.com/show/16252/mac-mini-apple-m1-tested)
    è‡ªåŸå§‹é¡µé¢å­˜æ¡£äº2021å¹´2æœˆ1æ—¥ã€‚æ£€ç´¢æ—¥æœŸä¸º2021å¹´1æœˆ30æ—¥ã€‚'
- en: '[5] [â€œApple M1 Chipâ€](https://www.apple.com/mac/m1/). *Apple.com*. Apple. [Archived](https://web.archive.org/web/20201110184757/https://www.apple.com/mac/m1/)
    from the original on 10 November 2020\. Retrieved 11 November 2020.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] [â€œApple M1èŠ¯ç‰‡â€](https://www.apple.com/mac/m1/)ã€‚ *Apple.com*ã€‚Appleã€‚ [å­˜æ¡£](https://web.archive.org/web/20201110184757/https://www.apple.com/mac/m1/)
    è‡ªåŸå§‹é¡µé¢å­˜æ¡£äº2020å¹´11æœˆ10æ—¥ã€‚æ£€ç´¢æ—¥æœŸä¸º2020å¹´11æœˆ11æ—¥ã€‚'
- en: '[6] Kingsley-Hughes, Adrian (10 Nov 2020). [â€œApple Silicon M1 chip: Hereâ€™s
    what we knowâ€](https://www.zdnet.com/article/apple-silicon-m1-chip-heres-what-we-know/).
    *ZDnet*. Red Ventures. [Archived](https://web.archive.org/web/20210917094527/https://www.zdnet.com/article/apple-silicon-m1-chip-heres-what-we-know/)
    from the original on 17 September 2021\. Retrieved 1 July 2021.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] Kingsley-Hughes, Adrian (2020å¹´11æœˆ10æ—¥)ã€‚ [â€œApple Silicon M1èŠ¯ç‰‡ï¼šæˆ‘ä»¬çŸ¥é“ä»€ä¹ˆâ€](https://www.zdnet.com/article/apple-silicon-m1-chip-heres-what-we-know/)ã€‚
    *ZDnet*ã€‚Red Venturesã€‚ [å­˜æ¡£](https://web.archive.org/web/20210917094527/https://www.zdnet.com/article/apple-silicon-m1-chip-heres-what-we-know/)
    è‡ªåŸå§‹é¡µé¢å­˜æ¡£äº2021å¹´9æœˆ17æ—¥ã€‚æ£€ç´¢æ—¥æœŸä¸º2021å¹´7æœˆ1æ—¥ã€‚'
- en: '[7] [https://fluxml.ai/Flux.jl/stable/gpu/](https://fluxml.ai/Flux.jl/stable/gpu/)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] [https://fluxml.ai/Flux.jl/stable/gpu/](https://fluxml.ai/Flux.jl/stable/gpu/)'
- en: '[8] [https://juliagpu.org/post/2023-03-03-metal_0.2/](https://juliagpu.org/post/2023-03-03-metal_0.2/)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] [https://juliagpu.org/post/2023-03-03-metal_0.2/](https://juliagpu.org/post/2023-03-03-metal_0.2/)'
- en: '[9] [https://fluxml.ai/Flux.jl/stable/tutorials/logistic_regression/](https://fluxml.ai/Flux.jl/stable/tutorials/logistic_regression/)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] [https://fluxml.ai/Flux.jl/stable/tutorials/logistic_regression/](https://fluxml.ai/Flux.jl/stable/tutorials/logistic_regression/)'
- en: '[10] William H. Wolberg and O.L. Mangasarian: â€œMultisurface method of'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] William H. Wolbergå’ŒO.L. Mangasarian: â€œç”¨äºåŒ»ç–—è¯Šæ–­çš„æ¨¡å¼åˆ†ç¦»ï¼Œåº”ç”¨äºä¹³è…ºç»†èƒå­¦â€ã€‚'
- en: pattern separation for medical diagnosis applied to breast cytologyâ€,
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: â€œç”¨äºåŒ»ç–—è¯Šæ–­çš„æ¨¡å¼åˆ†ç¦»ï¼Œåº”ç”¨äºä¹³è…ºç»†èƒå­¦â€ï¼Œ
- en: Proceedings of the National Academy of Sciences, U.S.A., Volume 87,
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ã€Šç¾å›½å›½å®¶ç§‘å­¦é™¢é™¢åˆŠã€‹ï¼Œç¬¬87å·ï¼Œ
- en: December 1990, pp 9193â€“9196\.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 1990å¹´12æœˆï¼Œç¬¬9193â€“9196é¡µã€‚
- en: '[11] This dataset is licensed under a [Creative Commons Attribution 4.0 International](https://creativecommons.org/licenses/by/4.0/legalcode)
    (CC BY 4.0) license. [https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[11] è¯¥æ•°æ®é›†éµå¾ª [çŸ¥è¯†å…±äº«ç½²å 4.0 å›½é™…](https://creativecommons.org/licenses/by/4.0/legalcode)
    (CC BY 4.0) è®¸å¯åè®®ã€‚ [https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names)'
