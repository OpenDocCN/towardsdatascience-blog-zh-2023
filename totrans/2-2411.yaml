- en: 'YOLO-NAS: How to Achieve the Best Performance on Object Detection Tasks'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: YOLO-NAS：如何在目标检测任务中实现最佳性能
- en: 原文：[https://towardsdatascience.com/yolo-nas-how-to-achieve-the-best-performance-on-object-detection-tasks-6b95347908d4](https://towardsdatascience.com/yolo-nas-how-to-achieve-the-best-performance-on-object-detection-tasks-6b95347908d4)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/yolo-nas-how-to-achieve-the-best-performance-on-object-detection-tasks-6b95347908d4](https://towardsdatascience.com/yolo-nas-how-to-achieve-the-best-performance-on-object-detection-tasks-6b95347908d4)
- en: A foundational model generated through neural architecture search, innovative
    quantization blocks, and a robust pre-training paradigm
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过神经网络结构搜索、创新的量化块和强大的预训练范式生成的基础模型
- en: '[](https://thomasdorfer.medium.com/?source=post_page-----6b95347908d4--------------------------------)[![Thomas
    A Dorfer](../Images/9258a1735cee805f1d9b02e2adf01096.png)](https://thomasdorfer.medium.com/?source=post_page-----6b95347908d4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6b95347908d4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6b95347908d4--------------------------------)
    [Thomas A Dorfer](https://thomasdorfer.medium.com/?source=post_page-----6b95347908d4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://thomasdorfer.medium.com/?source=post_page-----6b95347908d4--------------------------------)[![Thomas
    A Dorfer](../Images/9258a1735cee805f1d9b02e2adf01096.png)](https://thomasdorfer.medium.com/?source=post_page-----6b95347908d4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6b95347908d4--------------------------------)[![数据科学前沿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6b95347908d4--------------------------------)
    [Thomas A Dorfer](https://thomasdorfer.medium.com/?source=post_page-----6b95347908d4--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6b95347908d4--------------------------------)
    ·7 min read·May 19, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[数据科学前沿](https://towardsdatascience.com/?source=post_page-----6b95347908d4--------------------------------)
    ·阅读时间7分钟·2023年5月19日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/25a5a1f2e9fb6454fa899c6b66c2c7b3.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/25a5a1f2e9fb6454fa899c6b66c2c7b3.png)'
- en: Photo by [Anubhav Saxena](https://unsplash.com/@anubhav) on [Unsplash](https://unsplash.com/photos/RA5ntyyDHlw).
    Processed with YOLO-NAS-L by the author.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Anubhav Saxena](https://unsplash.com/@anubhav)提供，[Unsplash](https://unsplash.com/photos/RA5ntyyDHlw)上可见。由作者使用YOLO-NAS-L处理。
- en: In the domain of object detection, YOLO (**Y**ou **O**nly **L**ook **O**nce)
    has become a household name. Since the [release](https://arxiv.org/abs/1506.02640)
    of the first model in 2015, the YOLO family has been growing steadily, with each
    new model outperforming its predecessor in mean average precision (mAP) and inference
    latency.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在目标检测领域，YOLO（**你**只需**看**一次）已成为家喻户晓的名字。自2015年[发布](https://arxiv.org/abs/1506.02640)第一个模型以来，YOLO家族一直在稳步增长，每个新模型在平均精度（mAP）和推理延迟上均超越了其前身。
- en: 'Two weeks ago, the YOLO family has welcomed yet another member: [YOLO-NAS](https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md),
    a novel and foundational model developed by the deep learning company [Deci](https://deci.ai/).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 两周前，YOLO家族迎来了新成员：[YOLO-NAS](https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md)，这是由深度学习公司[Deci](https://deci.ai/)开发的一种新型基础模型。
- en: In this article, we’ll explore its advantages over previous YOLO models and
    demonstrate how it can be used for your own object detection tasks.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将探讨它相对于之前YOLO模型的优势，并展示如何将其用于你自己的目标检测任务。
- en: 'YOLO-NAS: What’s New?'
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: YOLO-NAS：新变化是什么？
- en: While previous YOLO models were leading in innovation and performance when it
    comes to object detection, they did have some limitations. One of the main issues
    was the lack of proper quantization support, which aims to decrease the model’s
    memory and computation requirements. Another issue was the insufficient trade-off
    between accuracy and latency, whereby an improvement in one often resulted in
    a considerable decline in the other.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管之前的YOLO模型在目标检测方面在创新和性能上领先，但它们也存在一些局限性。主要问题之一是缺乏适当的量化支持，这旨在减少模型的内存和计算需求。另一个问题是精度和延迟之间的权衡不足，其中一个的改进往往会导致另一个的显著下降。
- en: By leveraging a concept called **neural architecture search (NAS)**, researchers
    at Deci addressed these limitations head-on. Essentially, the concept of NAS can
    be considered a makeover for a trained deep learning model.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用一种称为**神经网络结构搜索（NAS）**的概念，Deci的研究人员直接解决了这些局限性。实质上，NAS的概念可以被视为对训练好的深度学习模型的一次改造。
- en: Traditionally, neural network architectures were manually designed by human
    experts based on their experience and intuition. However, this process, which
    involves the exploration of vast design spaces of possible architectures, has
    always been very time-consuming and cumbersome.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，神经网络架构由人类专家根据经验和直觉进行手动设计。然而，这一过程涉及探索可能架构的广阔设计空间，始终非常耗时且繁琐。
- en: '**NAS**, on the other hand, automatically re-designs the model’s architecture
    in order to boost its performance when it comes to things like speed, memory usage,
    and throughput. It typically involves a search space that defines the set of possible
    architectural choices, such as the number of layers, layer types, kernel sizes,
    and connectivity patterns. The search algorithm then assesses different architectures
    by training and evaluating them on a given task and dataset. Based on these evaluations,
    the algorithm iteratively explores and refines the architecture space, ultimately
    returning the one that yields the best performance.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**NAS**，另一方面，自动重新设计模型架构，以提升其在速度、内存使用和吞吐量等方面的性能。它通常涉及一个定义可能架构选择的搜索空间，例如层数、层类型、卷积核大小和连接模式。搜索算法然后通过在给定任务和数据集上训练和评估不同架构来评估它们。基于这些评估，算法迭代地探索和完善架构空间，最终返回最佳性能的架构。'
- en: '![](../Images/8ffbda473f7f6b1ff153e596571ee018.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8ffbda473f7f6b1ff153e596571ee018.png)'
- en: Photo by [Google DeepMind](https://unsplash.com/@deepmind) on [Unsplash](https://unsplash.com/photos/Krw-2KP7bOE)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Google DeepMind](https://unsplash.com/@deepmind) 在 [Unsplash](https://unsplash.com/photos/Krw-2KP7bOE)
- en: In order to perform NAS, Deci leveraged its proprietary [AutoNAC](https://deci.ai/deep-learning-glossary/automated-neural-architecture-construction-autonac/)
    technology, which is an optimization engine that redesigns a model’s architecture
    to squeeze out maximum inference performance for a specific piece of hardware
    while at the same time preserving accuracy.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行NAS，Deci利用了其专有的[AutoNAC](https://deci.ai/deep-learning-glossary/automated-neural-architecture-construction-autonac/)技术，这是一种优化引擎，可以重新设计模型的架构，以最大限度地提高特定硬件的推理性能，同时保持准确性。
- en: Aside from NAS, another major improvement of this new YOLO member involves the
    usage of **quantization**. Quantization, in this context, refers to the conversion
    of the neural network’s weights, biases, and activations from floating point values
    to integer values (INT-8), thus making the model more efficient.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 除了NAS，这个新的YOLO成员的另一个重大改进涉及**量化**的使用。在这种情况下，量化指的是将神经网络的权重、偏置和激活从浮点值转换为整数值（INT-8），从而使模型更加高效。
- en: 'This effort is two-fold: (1) The model uses quantization-friendly blocks that
    combine the advantages of re-parameterization and INT-8 quantization. These blocks
    use a methodology proposed by [Chu et al. (2022)](https://arxiv.org/pdf/2212.01593.pdf),
    which redesigns the blocks so that the weight and activation distributions they
    generate are advantageous for quantization. (2) The authors utilize a hybrid quantization
    method, which selectively quantizes specific layers of the model, thus minimizing
    information loss and striking a balance between latency and accuracy.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这项工作有两个方面：(1) 该模型使用了适合量化的块，这些块结合了重新参数化和INT-8量化的优点。这些块采用了[Chu等人（2022）](https://arxiv.org/pdf/2212.01593.pdf)提出的方法，重新设计这些块，使其生成的权重和激活分布有利于量化。(2)
    作者采用了一种混合量化方法，有选择地量化模型的特定层，从而最小化信息丢失，在延迟和准确性之间取得平衡。
- en: The results of this novel methodology speak for themselves. As can be seen in
    the graph below, the quantized, medium-sized model, *YOLO-NAS-INT8-M*, demonstrates
    a 50% improvement in inference latency, while at the same time sporting a 1 mAP
    increase in accuracy compared to the latest state-of-the-art model.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这种新方法的结果不言而喻。如下图所示，量化后的中型模型*YOLO-NAS-INT8-M*在推理延迟方面提高了50%，同时与最新的最先进模型相比，准确性提高了1
    mAP。
- en: '![](../Images/05179e7654f1412702e9ec890fc1b888.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05179e7654f1412702e9ec890fc1b888.png)'
- en: 'Source: [Deci-AI](https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md).
    License: [Apache License 2.0](https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.md)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [Deci-AI](https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md)。许可证:
    [Apache License 2.0](https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.md)'
- en: 'At the time of writing, three models of YOLO-NAS have been released: small,
    medium, and large, each with a quantized INT-8 counterpart.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写时，已经发布了 YOLO-NAS 的三种模型：小型、中型和大型，每种模型都有一个量化的 INT-8 版本。
- en: '![](../Images/03ad61150761e4ca0f0a09d9e2c5a467.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03ad61150761e4ca0f0a09d9e2c5a467.png)'
- en: 'Source: [Deci-AI](https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md).
    License: [Apache License 2.0](https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.md)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [Deci-AI](https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md)。许可证:
    [Apache License 2.0](https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.md)'
- en: Not surprisingly, the quantized versions experience a slight drop in precision.
    However, due to the employment of these novel quantization-friendly blocks as
    well as selective quantization, this precision drop remains relatively small.
    In addition, the upside here considerably outweighs the downside, with significant
    improvements being observed in inference latency.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 毫不奇怪，量化版本的精度略有下降。然而，由于采用了这些新颖的量化友好型块以及选择性量化，这种精度下降仍然相对较小。此外，这里的优势远大于劣势，推理延迟显著改善。
- en: YOLO-NAS also comes **pre-trained** on the COCO, Objects365, and Roboflow 100
    datasets, which makes it extremely suitable for downstream object detection tasks.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO-NAS 还在 COCO、Objects365 和 Roboflow 100 数据集上进行**预训练**，这使得它非常适合下游的物体检测任务。
- en: The pre-training regimen leveraged a concept known as **knowledge-distillation**,
    which allows the model to learn from its own predictions, rather than relying
    solely on external, labeled data, in order to improve performance. In this paradigm,
    a teacher model generates predictions on the training data, which then serve as
    guidance (or soft targets) for the student model. The student model is trained
    using both the original labeled data and the soft targets generated by the teacher
    model. It essentially tries to mimic the teacher model’s predictions while also
    adjusting its parameters to match the original labeled data. Overall, this approach
    allows the model to generalize better, reduce overfitting, and achieve higher
    accuracy, especially when labeled data is not abundantly available.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练过程利用了**知识蒸馏**的概念，这使得模型可以从自身的预测中学习，而不仅仅依赖于外部标记数据，从而提高性能。在这种范式中，教师模型对训练数据生成预测，这些预测作为学生模型的指导（或软目标）。学生模型使用原始标记数据和教师模型生成的软目标进行训练。它基本上尝试模仿教师模型的预测，同时调整其参数以匹配原始标记数据。总体而言，这种方法使模型能够更好地泛化，减少过拟合，并实现更高的准确性，特别是当标记数据不丰富时。
- en: The training process was further enhanced through the incorporation of **distribution
    focal loss (DFL).** DFL is a loss function that extends the concept of focal loss,
    which addresses the issue of class imbalance by assigning higher weights to hard-to-classify
    samples. In the context of object detection, DFL is used in the training process
    by learning box regression as a classification task. It discretizes bounding box
    predictions into limited options and predicts distributions over these options.
    The final predictions are then obtained by combining these distributions using
    weighted sums. By considering the class distribution and adjusting the loss function
    accordingly, the model is able to increase its detection accuracy for underrepresented
    classes.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程通过加入**分布焦点损失（DFL）**进一步增强。DFL 是一种损失函数，扩展了焦点损失的概念，通过对难以分类的样本分配更高的权重来解决类别不平衡的问题。在物体检测的背景下，DFL
    在训练过程中将框回归作为分类任务进行学习。它将边界框预测离散化为有限的选项，并对这些选项进行分布预测。最终的预测通过加权求和将这些分布结合起来。通过考虑类别分布并相应地调整损失函数，模型能够提高对欠代表类别的检测准确性。
- en: Finally, YOLO-NAS has been made available under an open source license with
    pre-trained weights available for research use on Deci’s PyTorch-based computer
    vision library called [SuperGradients](https://github.com/Deci-AI/super-gradients).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，YOLO-NAS 已经以开源许可证发布，并且在 Deci 的基于 PyTorch 的计算机视觉库 [SuperGradients](https://github.com/Deci-AI/super-gradients)
    上提供了预训练权重供研究使用。
- en: How To Use YOLO-NAS
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何使用 YOLO-NAS
- en: 'In order to use YOLO-NAS for inference, we need to install the `super_gradients`
    package first:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用 YOLO-NAS 进行推理，我们需要首先安装 `super_gradients` 包：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To set ourselves up for the inference task, let’s take a sample image that
    we’re going to call `image.jpg`:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备推理任务，让我们取一张样本图像，我们称之为 `image.jpg`：
- en: '![](../Images/f40b27aca75577921c73a4eb3aa0915d.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f40b27aca75577921c73a4eb3aa0915d.png)'
- en: Photo by [krakenimages](https://unsplash.com/@krakenimages) on [Unsplash](https://unsplash.com/photos/376KN_ISplE)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[krakenimages](https://unsplash.com/@krakenimages) 的照片，来源于 [Unsplash](https://unsplash.com/photos/376KN_ISplE)'
- en: 'In order to perform inference, we can use the following code snippet:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行推断，我们可以使用以下代码片段：
- en: '[PRE1]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: First, we need to import `torch` and `models` from the `super_gradients` library.
    Then, we declare a variable `device`, which is set to use the first available
    GPU (if one is available), or, otherwise, is set to use the CPU.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要从 `super_gradients` 库中导入 `torch` 和 `models`。然后，我们声明一个变量 `device`，设置为使用第一个可用的
    GPU（如果有的话），否则设置为使用 CPU。
- en: Subsequently, we are specifying that we’d like to use the small version of the
    model, YOLO-NAS-S, and the pre-trained weights from the COCO dataset. Furthermore,
    we’re saving the output image with the detected objects as `image_yolo.jpg`.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，我们指定使用模型的小型版本 YOLO-NAS-S，并使用 COCO 数据集的预训练权重。此外，我们将检测到的物体保存到 `image_yolo.jpg`
    中。
- en: 'Our output image looks as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的输出图像如下所示：
- en: '![](../Images/a31bef37532fca8a76b5a5db986ae6fb.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a31bef37532fca8a76b5a5db986ae6fb.png)'
- en: Photo by [krakenimages](https://unsplash.com/@krakenimages) on [Unsplash](https://unsplash.com/photos/376KN_ISplE).
    Processed with YOLO-NAS-S by the author.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[krakenimages](https://unsplash.com/@krakenimages) 的照片，来源于 [Unsplash](https://unsplash.com/photos/376KN_ISplE)。由作者使用
    YOLO-NAS-S 处理。'
- en: We can see various objects being detected spanning a wide range of confidence
    levels. The model is mostly confident for objects in focus, such as the two persons,
    cups, and the laptop. However, we also observe some misclassifications, probably
    due to the objects being out of focus. This includes a penholder being misclassified
    as a potted plant, and a pen being misclassified as a toothbrush. Amazingly, we
    can also see that the model accurately detects objects that are only partially
    visible, such as the chairs that the persons are sitting on, where only the backrest
    is visible.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到各种物体在不同的置信度水平下被检测到。对于聚焦中的物体（如两个人、杯子和笔记本电脑），模型的置信度较高。然而，我们也观察到一些误分类，可能是由于物体失焦。这包括一个笔筒被误分类为盆栽植物，以及一支笔被误分类为牙刷。令人惊讶的是，我们还可以看到模型准确地检测到了仅部分可见的物体，如人物坐的椅子，只有靠背部分可见。
- en: Finally, it is worth mentioning that object detection can be performed in exactly
    the same way with videos by simply changing the input parameter of the `predict()`
    call to the corresponding video file.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，值得一提的是，通过简单地将 `predict()` 调用的输入参数更改为相应的视频文件，可以以完全相同的方式进行视频目标检测。
- en: Conclusion
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: The YOLO family has grown by yet another member, YOLO-NAS, which is proudly
    outperforming its younger siblings like YOLOv6, YOLOv7, and YOLOv8.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO 系列又迎来了一员新成员——YOLO-NAS，它自豪地超越了 YOLOv6、YOLOv7 和 YOLOv8 等年轻兄弟。
- en: Through an innovative combination of neural architecture search, quantization
    support, and a robust pre-training procedure that includes knowledge-distillation
    and distribution focal loss, YOLO-NAS achieves remarkable trade-offs between precision
    and inference latency.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 通过神经架构搜索、量化支持以及包含知识蒸馏和分布式焦点损失的强大预训练程序的创新组合，YOLO-NAS 实现了精度和推理延迟之间的显著权衡。
- en: Considering the rapid pace at which the landscape of computer vision and object
    detection keeps evolving, it is highly likely that another YOLO model will soon
    come to see the light of day.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到计算机视觉和目标检测领域的快速发展，另一款 YOLO 模型很可能很快会面世。
- en: More Resources
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多资源
- en: '[YOLO-NAS by Deci Achieves State-of-the-Art Performance on Object Detection
    Using Neural Architecture Search](https://deci.ai/blog/YOLO-NAS-object-detection-foundation-model)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Deci 的 YOLO-NAS 使用神经架构搜索在目标检测上达到了最先进的性能](https://deci.ai/blog/YOLO-NAS-object-detection-foundation-model)'
- en: '[super-gradients/YOLONAS.md at master · Deci-AI/super-gradients · GitHub](https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[super-gradients/YOLONAS.md at master · Deci-AI/super-gradients · GitHub](https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md)'
- en: Liked this article?
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 喜欢这篇文章吗？
- en: Let’s connect! You can find me on [Twitter](https://twitter.com/ThomasADorfer),
    [LinkedIn](https://www.linkedin.com/in/thomasdorfer/) and [Substack](https://thomasdorfer.substack.com/).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们联系吧！你可以在 [Twitter](https://twitter.com/ThomasADorfer)、[LinkedIn](https://www.linkedin.com/in/thomasdorfer/)
    和 [Substack](https://thomasdorfer.substack.com/) 找到我。
- en: If you like to support my writing, you can do so through a [Medium Membership](https://thomasdorfer.medium.com/membership),
    which provides you access to all my stories as well as those of thousands of other
    writers on Medium.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想支持我的写作，可以通过[Medium会员](https://thomasdorfer.medium.com/membership)来做到，这将使你可以访问我所有的故事以及Medium上成千上万其他作家的故事。
- en: '[](https://medium.com/@thomasdorfer/membership?source=post_page-----6b95347908d4--------------------------------)
    [## Join Medium with my referral link - Thomas A Dorfer'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@thomasdorfer/membership?source=post_page-----6b95347908d4--------------------------------)
    [## 通过我的推荐链接加入Medium - 托马斯·A·多费尔'
- en: Read every story from Thomas A Dorfer (and thousands of other writers on Medium).
    Your membership fee directly supports…
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 阅读托马斯·A·多费尔（Thomas A Dorfer）以及成千上万其他作者在Medium上的每个故事。你的会员费直接支持…
- en: medium.com](https://medium.com/@thomasdorfer/membership?source=post_page-----6b95347908d4--------------------------------)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[medium.com](https://medium.com/@thomasdorfer/membership?source=post_page-----6b95347908d4--------------------------------)'
