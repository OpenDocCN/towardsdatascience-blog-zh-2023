- en: 'Enhancing RAG’s Answer: Self-Debugging Techniques and Cognitive Load Reduction'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 增强 RAG 的答案：自我调试技术和认知负荷减少
- en: 原文：[https://towardsdatascience.com/enhancing-rags-answer-self-debugging-techniques-and-cognitive-load-reduction-8c4273013d39](https://towardsdatascience.com/enhancing-rags-answer-self-debugging-techniques-and-cognitive-load-reduction-8c4273013d39)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/enhancing-rags-answer-self-debugging-techniques-and-cognitive-load-reduction-8c4273013d39](https://towardsdatascience.com/enhancing-rags-answer-self-debugging-techniques-and-cognitive-load-reduction-8c4273013d39)
- en: Asking the LLM to self-diagnose and self-correct the prompt to improve answer
    quality.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 要求 LLM 自我诊断并自我修正提示，以提高答案质量。
- en: '[](https://agustinus-nalwan.medium.com/?source=post_page-----8c4273013d39--------------------------------)[![Agustinus
    Nalwan](../Images/7c5ade9ab8bca1d27a317b5c09d1b734.png)](https://agustinus-nalwan.medium.com/?source=post_page-----8c4273013d39--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8c4273013d39--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8c4273013d39--------------------------------)
    [Agustinus Nalwan](https://agustinus-nalwan.medium.com/?source=post_page-----8c4273013d39--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://agustinus-nalwan.medium.com/?source=post_page-----8c4273013d39--------------------------------)[![Agustinus
    Nalwan](../Images/7c5ade9ab8bca1d27a317b5c09d1b734.png)](https://agustinus-nalwan.medium.com/?source=post_page-----8c4273013d39--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8c4273013d39--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8c4273013d39--------------------------------)
    [Agustinus Nalwan](https://agustinus-nalwan.medium.com/?source=post_page-----8c4273013d39--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8c4273013d39--------------------------------)
    ·22 min read·Nov 26, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8c4273013d39--------------------------------)
    ·阅读时间 22 分钟·2023年11月26日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/ed765e2b448efe4ab6655b25da525fab.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ed765e2b448efe4ab6655b25da525fab.png)'
- en: LLM performs self-debugging (image generated with MidJourney)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 进行自我调试（图像由 MidJourney 生成）
- en: Retrieval Augmented Generation (RAG) is undoubtedly a powerful tool, easily
    crafted using frameworks like LangChain or LlamaIndex. Such ease of integration
    might give an impression that RAG is a magic solution that is easy to build for
    every use case. However, in our journey to upgrade our editorial article search
    tool to offer semantically richer search results and direct answers to queries,
    we found the basic RAG setup and is lacking and discovered many challenges. Constructing
    a RAG for a demonstration is quick and easy, often yielding sufficiently impressive
    results for small subset of scenarios. Yet, the final stretch to achieve production-ready
    status, where exceptional quality is mandatory, presents significant challenges.
    This is particularly true when dealing with a vast knowledge base filled with
    thousands of domain-specific articles, a not-so-rare occurrence.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）无疑是一种强大的工具，使用像 LangChain 或 LlamaIndex 这样的框架可以轻松构建。这样的集成便利性可能会让人觉得
    RAG 是一种对于每个使用案例都容易构建的神奇解决方案。然而，在我们升级编辑文章搜索工具以提供语义更丰富的搜索结果和直接答案的过程中，我们发现基本的 RAG
    设置存在不足，并遇到了许多挑战。构建一个用于演示的 RAG 既快速又简单，通常能在少量场景中产生足够令人印象深刻的结果。然而，实现生产就绪状态的最后阶段，即要求卓越质量的阶段，面临着重大挑战。特别是在处理包含成千上万篇领域特定文章的庞大知识库时，这种情况尤为明显，这种情况并不罕见。
- en: 'Our approach to RAG consists of two distinct steps:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对 RAG 的方法包括两个不同的步骤：
- en: 'Relevant Document Retrieval By employing a fuse of dense and sparse embeddings,
    we extract relevant document chunks from our Pinecone database, considering both
    content and title. These chunks are subsequently re-ranked based on relevance
    to the title, content, and the document’s age. The top four documents are then
    chosen: both as potential search results and as document context for generating
    direct answers. Notably, this approach diverges from the common RAG setup, addressing
    our unique document retrieval challenges more effectively.'
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 相关文档检索 通过采用密集和稀疏嵌入的融合，我们从 Pinecone 数据库中提取相关的文档块，考虑内容和标题。这些文档块随后根据与标题、内容以及文档年龄的相关性重新排序。然后选择排名前四的文档：既作为潜在的搜索结果，也作为生成直接答案的文档上下文。值得注意的是，这种方法不同于常见的
    RAG 设置，更有效地解决了我们独特的文档检索挑战。
- en: Direct Answer Generation Here, the question, instruction, and the previously
    retrieved top four document chunks (document context) are fed into a Large Language
    Model (LLM) to produce a direct answer.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 直接答案生成 在这里，问题、指令以及之前检索到的前四个文档片段（文档上下文）被输入到大型语言模型（LLM）中，以生成直接答案。
- en: '![](../Images/f2a7498db31ebbcb6287cc1e3d273786.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2a7498db31ebbcb6287cc1e3d273786.png)'
- en: RAG architecture
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: RAG架构
- en: I’ve delved deeply into enhancing document retrieval quality through the use
    of [Hybrid Search and Hierarchical Document Ranking techniques](/the-untold-side-of-rag-addressing-its-challenges-in-domain-specific-searches-808956e3ecc8)
    in previous discussions. In this blog, I aim to share insights on refining and
    troubleshooting the direct answer generation process.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我之前深入探讨了通过使用[混合搜索和层次化文档排名技术](/the-untold-side-of-rag-addressing-its-challenges-in-domain-specific-searches-808956e3ecc8)来提升文档检索质量。在这篇博客中，我旨在分享关于优化和故障排除直接答案生成过程的见解。
- en: Ensuring High-Quality Document Retrieval
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确保高质量的文档检索
- en: The presence of a highly capable LLM for direct answer generation becomes futile
    when fed with low-quality document context. For example, if the document portions
    lack the pertinent information necessary to derive an answer for a given question,
    the effectiveness of the LLM diminishes, regardless the size and the cognitive
    capability of the model. Achieving this goal is quite challenging because it requires
    optimising both recall and precision simultaneously. Recall is essential to avoid
    overlooking document chunks that contain vital information for answer generation,
    while precision is essential to minimise the number of document chunks sent, focusing
    solely on the most relevant ones. This consideration takes into account the limitations
    of a restricted context window size and the associated costs of transmitting extensive
    document contexts. Consequently, the top-k document chunks selected should represent
    the highest quality available.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当输入低质量的文档上下文时，即使有一个高效的LLM进行直接答案生成也是徒劳的。例如，如果文档部分缺乏必要的信息来推导出某个问题的答案，那么LLM的有效性就会降低，无论模型的规模和认知能力如何。实现这一目标非常具有挑战性，因为它需要同时优化召回率和准确率。召回率对于避免忽略包含关键答案信息的文档片段至关重要，而准确率则对于减少传输的文档片段数量，专注于最相关的内容也很重要。这种考虑需要考虑到限制的上下文窗口大小和传输大量文档上下文的相关成本。因此，所选的top-k文档片段应代表最高质量。
- en: '![](../Images/87b2c221c0042402824c2248733f762b.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/87b2c221c0042402824c2248733f762b.png)'
- en: The LLM scoured the document to find content of high quality (image generated
    using MidJourney).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: LLM扫描了文档以寻找高质量的内容（图像由MidJourney生成）。
- en: So, if you find that the direct answer generated isn’t satisfactory, the first
    step should be to scrutinise your document retrieval process. In our case, it
    accounts for half of the inaccuracies in the generated answers. Examine the full
    prompt dispatched to the LLM to ensure the necessary relevant information is present
    within the document context of your prompt. If it’s absent or inadequate, consider
    enhancing your document retrieval strategies using techniques like [hybrid search,
    hierarchical document ranking, or score boosting](https://medium.com/towards-data-science/the-untold-side-of-rag-addressing-its-challenges-in-domain-specific-searches-808956e3ecc8).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果你发现生成的直接答案不令人满意，第一步应该是仔细审查你的文档检索过程。在我们的案例中，这占据了生成答案不准确的半数问题。检查完整的提示信息以确保在提示的文档上下文中存在必要的相关信息。如果缺失或不足，考虑使用[混合搜索、层次化文档排名或评分提升](https://medium.com/towards-data-science/the-untold-side-of-rag-addressing-its-challenges-in-domain-specific-searches-808956e3ecc8)等技术来改进你的文档检索策略。
- en: For the remainder of this blog, I will walk you through the four techniques
    I’ve used for enhancing the quality of direct answers and how I incorporate these
    techniques into my prompts. Please note that the prompts I share in this blog
    may be edited for brevity, with certain parts omitted to emphasise the relevant
    aspects for our discussion and to prevent overwhelming this blog with excessive
    content. Additionally, while I consistently use the question “What is Mazda CX-9
    2019 fuel efficiency?” as an example throughout the blog, it’s important to understand
    that I don’t limit our evaluation to just this question. We have conducted evaluations
    with sets of similar questions to ensure that the behaviours we observe are representative
    across a substantial number of evaluation samples. So, let’s begin.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本博客的其余部分，我将向你介绍我用来提高直接回答质量的四种技术，以及我如何将这些技术融入我的提示中。请注意，我在博客中分享的提示可能会为简洁起见进行编辑，某些部分可能被省略，以突出讨论的相关方面，并避免使博客内容过于繁琐。此外，虽然我在整个博客中始终使用“2019年马自达CX-9的燃油效率是多少？”作为示例，但重要的是要理解，我们的评估不仅限于这个问题。我们已使用类似问题的集合进行评估，以确保我们观察到的行为在大量评估样本中具有代表性。那么，我们开始吧。
- en: 'Clarity is Key: Be Explicit in Your Instructions.'
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 清晰至关重要：在你的指令中要明确。
- en: Ensuring your prompts to the LLM are explicit and well-defined is crucial. For
    instance, if you want the LLM to refrain from generating an answer when the necessary
    information isn’t available in the document context, you must specify this clearly.
    As an example, take a look at the example prompt below.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你给LLM的提示是明确且定义良好的至关重要。例如，如果你希望LLM在文档上下文中没有必要信息时避免生成答案，你必须明确指定这一点。以下是一个示例提示。
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: There is a specific emphasis on the instruction **“If you don’t know the answer,
    simply return nothing.”** The LLM faced challenges related to boundaries, much
    like that smart but annoying friend in your high school who always raised their
    hand to answer the teacher’s questions, regardless of their confidence in the
    response. They were uncertain whether providing an incorrect answer (term coined
    as hallucination) would be more detrimental than refraining from answering altogether.
    Therefore, by including this directive, you are expressing your preference.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 特别强调指令**“如果你不知道答案，就什么也不要返回。”** LLM面临与界限相关的挑战，就像你高中时那个聪明但让人讨厌的朋友，总是举手回答老师的问题，无论他们对回答的信心如何。他们不确定提供一个错误答案（称为虚幻）的影响是否比完全不回答更糟。因此，通过包含这一指令，你在表达你的偏好。
- en: 'Moreover, the specific requirements vary according to your use case. For ours,
    we expect the LLM to rely solely on our knowledge base, meaning it should generate
    answers only from the information present in the provided document chunks. All
    LLMs has been trained on a vast array of data from the internet, books, and other
    mediums. While such sources may contain information that could potentially be
    used to derive answers, their reliability and consistency with our knowledge base
    are not assured. Consequently, we have incorporated an additional directive: **“Do
    not source information from anything other than the provided document excerpts.”**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，具体要求根据你的使用案例而异。对于我们的需求，我们期望LLM仅依赖于我们的知识库，这意味着它应该仅从提供的文档片段中的信息生成答案。所有LLM都在大量的互联网、书籍和其他媒介数据上进行过训练。尽管这些来源可能包含潜在的答案信息，但它们的可靠性和与我们知识库的一致性无法保证。因此，我们加入了额外的指令：**“不要从提供的文档摘录以外的地方获取信息。”**
- en: '![](../Images/4f501fb54937f7b8ce6ba2107fbe1361.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f501fb54937f7b8ce6ba2107fbe1361.png)'
- en: The LLM is carefully reading provided instruction (image generated using MidJourney).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: LLM正在仔细阅读提供的指令（图像由MidJourney生成）。
- en: By being direct and precise in your prompts, you can greatly minimise the likelihood
    of the LLM producing unfounded or “hallucinated” answers.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 通过直接和精确的提示，你可以大大减少LLM产生毫无根据或“虚幻”答案的可能性。
- en: Asking the LLM to Self-Diagnose and Self-Correct.
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 让LLM自我诊断和自我修正。
- en: That’s correct! It’s possible to ask the LLM to identify and rectify its own
    errors. In contrast to traditional algorithms, LLMs have the ability to reason,
    which enables them to perform a range of tasks, self-debugging included.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 没错！可以要求LLM识别并纠正自身错误。与传统算法相比，LLM具有推理能力，这使得它能够执行多种任务，包括自我调试。
- en: '![](../Images/98adfb2875a26dc1601212f35ba88575.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/98adfb2875a26dc1601212f35ba88575.png)'
- en: The LLM is performing a self-diagnostic on itself (image generated using MidJourney).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: LLM正在进行自我诊断（图像由MidJourney生成）。
- en: For example, within our project, we encountered an issue with the query “What
    is the fuel efficiency of Mazda CX-9 2019?” where the LLM generated an inaccurate
    response, stating, “The fuel efficiency of Mazda CX-9 2019 is 8.8L/100km.” Upon
    closer examination, we confirmed that we had indeed provided the correct document
    context. The relevant information was contained within an article titled “Mazda
    CX-8 vs. Mazda CX-9 2019 Comparison” in our prompt. However, inexplicably, the
    LLM extracted the fuel efficiency information from a Mazda CX-9 2018 article instead.
    Below, you can find our original prompt.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在我们的项目中，我们遇到了一个问题，查询“2019年Mazda CX-9的燃油效率是多少？”时，LLM生成了一个不准确的回答，声称“2019年Mazda
    CX-9的燃油效率是8.8L/100km。”经过仔细检查，我们确认确实提供了正确的文档上下文。相关信息包含在我们提示中的一篇标题为“2019年Mazda CX-8与Mazda
    CX-9比较”的文章中。然而，不知为何，LLM却从2018年Mazda CX-9的文章中提取了燃油效率信息。下面是我们的原始提示。
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Using GPT3.5 turbo, it produces the following incorrect response (The correct
    answer is 10.1L/100 km).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 使用GPT3.5 turbo，它生成了以下不正确的回答（正确答案是10.1L/100 km）。
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: When I tested the identical prompt with GPT4.0, I received the correct answer.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 当我使用GPT4.0测试相同的提示时，得到了正确的答案。
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Nonetheless, GPT4 is not economically feasible for our use case, as it costs
    10 times more than GPT3.5 Turbo. Consequently, this challenge compelled us to
    seek a solution that is compatible with GPT 3.5 Turbo, sparking the concept of
    self-debugging.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，GPT4在我们的使用案例中并不经济，因为它的成本是GPT3.5 Turbo的10倍。因此，这一挑战促使我们寻找与GPT3.5 Turbo兼容的解决方案，激发了自我调试的概念。
- en: Imagine asking someone to answer a question based on a document you’ve provided,
    and they give you an incorrect response. What steps would you take to understand
    why the mistake occurred? **You would simply ask them why they made the mistake
    by showing them the correct answer alongside the source material**. With LLM,
    it’s much the same. We ask the LLM, but to do so effectively, we need the ability
    to continue the conversation with our LLM after it provides an answer.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，让某人根据您提供的文档回答问题，而他们给出了错误的回应。您会采取什么步骤来了解错误发生的原因？**您可以通过展示正确答案和来源材料来简单地询问他们为什么犯错**。与LLM也是一样。我们询问LLM，但为了有效地进行此操作，我们需要能够在LLM提供答案后继续与其对话。
- en: By employing platforms such as [www.poe.com](http://www.poe.com/), we can reproduce
    our interactions with the LLM. We opt for the same LLM model and input the entire
    prompt into the console. The resulting output mirrors the precise incorrect answer
    we encountered within our code. Following this, we commence a conversation with
    the LLM, which serves as a crucial step in facilitating the self-debugging process,
    as outlined below.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用如[www.poe.com](http://www.poe.com/)这样的平台，我们可以重现与LLM的交互。我们选择相同的LLM模型，将整个提示输入控制台。生成的输出与我们代码中遇到的精确错误答案相符。随后，我们与LLM进行对话，这在促进自我调试过程中是一个关键步骤，如下所述。
- en: '![](../Images/a37a3367cd7543d37b07894d26c69862.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a37a3367cd7543d37b07894d26c69862.png)'
- en: poe.com web interface
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: poe.com网络界面
- en: Here’s the complete dialogue record I had with the LLM.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我与LLM的完整对话记录。
- en: 'Me: The answer you give me is incorrect. It is the fuel efficiency of Mazda
    CX-9 2018 as stated in article with title Mazda CX-9 2018 Review. The correct
    answer is 10.1L/100km as stated in article with title “Mazda CX-8 vs Mazda CX-9
    2019 Comparison'
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我：您给我的答案不正确。它是2018年Mazda CX-9的燃油效率，如文章标题“Mazda CX-9 2018 Review”所述。正确的答案是10.1L/100km，如文章标题“Mazda
    CX-8与Mazda CX-9 2019比较”所述。
- en: ''
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'LLM: I apologise for this mistake. You are right that the correct information
    was provided in the article you stated.'
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: LLM：我为这个错误道歉。您说得对，正确的信息确实在您提到的文章中提供了。
- en: ''
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Me: That’s ok. Why did you make this mistake?'
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我：没关系。你为什么犯了这个错误？
- en: ''
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'LLM: I did not realise that the year quoted in the article is the model year
    of the car. I thought it is an article year.'
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: LLM：我没有意识到文章中引用的年份是汽车的型号年份。我以为这是文章的年份。
- en: 'Based on the last response, I’ve now identified the cause behind the LLM’s
    error. This sparked another idea: If the LLM can comprehend and explain its misunderstanding,
    perhaps it can also adjust my initial prompt to prevent repeating the same mistake
    in the future. It’s definitely worth a try!'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 根据最后的回应，我现在已识别出LLM错误的原因。这激发了另一个想法：如果LLM可以理解并解释其误解，也许它还可以调整我的初始提示，以防未来重复同样的错误。这绝对值得一试！
- en: 'Me: How should I modify my prompt so next time you won’t repeat this same mistake?'
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我：我应该如何修改我的提示，以便下次你不会重复这个错误？
- en: ''
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'LLM: You can add to specifically say that the article title/content might contain
    car model year which should match the model year asked in the question.'
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: LLM：你可以具体说明文章标题/内容可能包含汽车型号年份，这应该与问题中询问的型号年份匹配。
- en: ''
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Me: Could u pls modify my prompt to include your suggestion?'
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我：请你修改我的提示以包含你的建议吗？
- en: Upon requesting a second time, the LLM provided me with a revised prompt that
    integrated the suggested improvement.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二次请求时，LLM向我提供了一个整合了建议改进的修订提示。
- en: '[PRE4]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Despite utilising this adjusted prompt, it was rather disheartening to observe
    that it still yielded an incorrect response to my earlier question.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管使用了这个调整后的提示，但观察到它仍然对我之前的问题产生了错误的回答，这让人感到相当沮丧。
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Nevertheless, it has provided me with insights into the necessary information
    that needed to be included regarding the model year. Consequently, I took it upon
    myself to manually modify the prompt by incorporating the recommended mention
    of the model year. I even provided a brief example of the expected behaviour to
    guide the LLM.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，它还是给了我一些关于需要包含模型年份的信息的见解。因此，我决定手动修改提示，加入了推荐提到的模型年份。我甚至提供了一个简短的期望行为示例来指导LLM。
- en: '**Revised prompt based on the LLM suggestion**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于LLM建议的修订提示**'
- en: '[PRE6]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The new prompt has now provided me with the correct answer!
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 新的提示现在给了我正确的答案！
- en: '[PRE7]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: However, it’s important to keep in mind that this method may not consistently
    yield positive results. My success rate using this method stands at approximately
    75% in gaining insight from LLM explanations regarding why it made the mistake,
    and it’s around 25% effective in getting the LLM to modify the prompt for me to
    produce correct answer. Nevertheless, having this method at our disposal is still
    preferable to having no method at all.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，需要记住的是，这种方法可能不会始终产生积极的结果。我使用这种方法获得关于LLM解释为何犯错的见解的成功率约为75%，而让LLM为我修改提示以产生正确答案的效果约为25%。尽管如此，拥有这种方法总比没有方法要好。
- en: '**Aware of cognitive overload.**'
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**意识到认知负荷。**'
- en: Keeping instructions precise is crucial for directing the LLM to produce the
    desired answer. However, overly detailed prompts that result in complexity can
    have adverse effects on smaller-size LLMs like GPT-3.5 Turbo, which have less
    cognitive capacity compared to GPT-4\. Wondering why? Let’s go through an example
    to demonstrate this.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 保持指示准确对于引导LLM产生期望的答案至关重要。然而，过于详细的提示可能会对像GPT-3.5 Turbo这样较小的LLM产生不利影响，因为它们的认知能力比GPT-4低。想知道为什么吗？让我们通过一个示例来演示这一点。
- en: '![](../Images/73a535677c9ccff4a1c88fbc9e2d08f9.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/73a535677c9ccff4a1c88fbc9e2d08f9.png)'
- en: The LLM is experiencing cognitive overload (image generated using MidJourney).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 正在经历认知负荷（图像由MidJourney生成）。
- en: Our initial prompt, which was constructed using the Langchain template, employs
    a one-shot technique. For instance, it includes a single example of full interaction
    in the hope that the LLM can gain a better understanding of our intent. However,
    when using GPT3.5 Turbo, we observed that the one-shot prompt resulted in more
    ambiguous answers compared to the prompt with zero shots.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最初使用Langchain模板构建的提示采用了一次性技术。例如，它包括了一个完整互动的单一示例，希望LLM能够更好地理解我们的意图。然而，当使用GPT3.5
    Turbo时，我们观察到一次性提示比零次提示产生了更模糊的回答。
- en: Below, you can find our one-shot prompt based on the [Langchain](https://www.langchain.com/)
    template. The example provided is from a completely different domain (non-automotive),
    and the prompt is generic, with no mention of car-related articles.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们基于[Langchain](https://www.langchain.com/)模板的一次性提示。提供的示例来自一个完全不同的领域（非汽车），提示是通用的，没有提及汽车相关的文章。
- en: '[PRE8]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: An extremely unclear response, mentioning the fuel efficiency of Mazda CX-9
    across different model years, was given.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 给出的回答极其不清晰，提到了不同车型年份的马自达CX-9的燃油效率。
- en: '[PRE9]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: It’s possible that the vague nature of the initial prompt, along with an unrelated
    one-shot example, might be partly to blame for the issue. To test this theory,
    I crafted a more tailored prompt that incorporates domain-specific instructions
    and an example that aligns closely with our actual use case. The details of this
    new prompt are as follows, which will help determine if it makes a noticeable
    difference.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 初始提示的模糊性质，加上一个无关的单次示例，可能部分地导致了这个问题。为验证这个理论，我制定了一个更具针对性的提示，其中包含了特定领域的指令和一个与我们实际用例紧密相关的示例。以下是这个新提示的详细信息，这将有助于确定它是否能带来显著的差异。
- en: '[PRE10]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The response provided remains inaccurate. It also claimed that the necessary
    information was unavailable to address the question, which is inaccurate.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 提供的回答仍然不准确。它还声称没有必要的信息来回答问题，这也是不准确的。
- en: '[PRE11]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: By omitting the example and opting for a zero-shot approach, we successfully
    get the LLM to generate the correct answer.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 通过省略示例并选择零次提示方法，我们成功地使LLM生成了正确的答案。
- en: '[PRE12]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: To further validate that the issue stems from cognitive overload, we conducted
    a one-shot prompt test with a GPT-4, which, as anticipated, yielded a correct
    response.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为进一步验证问题是否源于认知过载，我们使用GPT-4进行了单次提示测试，结果如预期地得到了正确的回答。
- en: '[PRE14]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: To reinforce our hypothesis, we conducted similar tests with other language
    models, Claude Instant and Claude 2, which resulted in the same pattern of outcomes.
    Claude 2 successfully processed our one-shot prompt to provide the correct answer,
    while Claude Instant did not. Claude 2 and GPT-4 share comparable cognitive capacities,
    both superior to those of Claude Instant and GPT-3.5 Turbo. This supports our
    theory that models with lesser cognitive capabilities struggle with complex instructions.
    I am quite satisfied with these results, as the zero-shot approach allows for
    a more concise prompt, reducing costs, and it works with the less expensive, smaller
    models like GPT-3.5 Turbo or Claude Instant.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证我们的假设，我们对其他语言模型，如Claude Instant和Claude 2，进行了类似的测试，结果显示了相同的模式。Claude 2成功处理了我们的单次提示，提供了正确的答案，而Claude
    Instant则没有。Claude 2和GPT-4具有相似的认知能力，均优于Claude Instant和GPT-3.5 Turbo。这支持了我们的理论，即认知能力较低的模型在处理复杂指令时会遇到困难。我对这些结果感到非常满意，因为零次提示法可以使提示更简洁，从而降低成本，并且它适用于像GPT-3.5
    Turbo或Claude Instant这样的较便宜、更小的模型。
- en: '**Asking for a proof.**'
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**要求提供证明。**'
- en: Requesting that a language model provide the source of its generated answer
    is a highly effective strategy to reduce hallucination and prevent hallucination,
    particularly when the relevant information is not present within the provided
    document context.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 要求语言模型提供其生成答案的来源是一种非常有效的策略，能够减少幻觉并防止幻觉，特别是当相关信息不在提供的文档上下文中时。
- en: '![](../Images/89de88e21fac1f06d9de9de78a74785d.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/89de88e21fac1f06d9de9de78a74785d.png)'
- en: The LLM is tracing the source material’s origin (image generated with MidJourney).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: LLM正在追踪源材料的来源（图像由MidJourney生成）。
- en: This objective can be met by using different prompts to guide the language model.
    A strategy involves directing the LLM to identify the specific part of the document
    context that informed its response. Incorporating a command that obliges the LLM
    to reference the document source ID in its answer allows you to disregard the
    response if the source ID is absent or wrong. While it’s infrequent, the LLM may
    reference an external source not included in your document chunk, such as a website
    it was exposed to during its training.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这个目标可以通过使用不同的提示来引导语言模型。一个策略是指导LLM识别出影响其响应的文档上下文的特定部分。加入一个命令，要求LLM在回答中引用文档源ID，可以让你忽略没有源ID或源ID错误的回应。虽然不常见，但LLM可能会引用你文档块中未包含的外部来源，例如它在训练期间接触到的网站。
- en: '[PRE15]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Another strategy is to direct the LLM to respond by explicitly quoting the sentence(s)
    in the document chunk that answer the question.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种策略是指导LLM通过明确引用回答问题的文档块中的句子来回应。
- en: '[PRE16]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This method can impose additional constraints on the LLM and isn’t always practical,
    as is the case with our documents. Often, our documents lack sentences that explicitly
    respond to frequently asked questions. Therefore, the LLM has no specific sentences
    to quote, which results in no response. Should we permit the LLM to compose its
    own sentences using the knowledge embedded in the document, it would be capable
    of providing an answer.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法可能对 LLM 施加额外的约束，并不总是实用，就像我们文档的情况一样。我们的文档经常缺乏明确回应常见问题的句子。因此，LLM 没有特定的句子可供引用，这导致没有回应。如果我们允许
    LLM 使用文档中嵌入的知识来构造自己的句子，它将能够提供答案。
- en: '**Conclusion**'
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**结论**'
- en: Building an application using Language Model (LLM) is quite distinct from using
    traditional algorithms. With traditional algorithms, detailed instructions give
    you complete control over the process, and debugging involves watching variable
    values, ensuring those instructions are correct. In contrast, using an LLM is
    akin to employing a human to execute these processes within your software. Because
    LLMs are human-like in their responses, troubleshooting and debugging require
    techniques similar to those used to determine why a person might have made an
    error, primarily through questioning.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 使用语言模型（LLM）构建应用程序与使用传统算法截然不同。传统算法中，详细的指令使你完全控制过程，调试涉及观察变量值，确保这些指令是正确的。相比之下，使用
    LLM 就像是雇用一个人来在你的软件中执行这些过程。由于 LLM 的反应类似于人类，故障排除和调试需要类似于确定一个人可能犯错的技术，主要通过提问。
- en: Even though Language Model (LLM) technology is still emerging and subject to
    mistakes and inaccuracies, it has shown considerable promise, and there are effective
    strategies to greatly mitigate these issues. Given the rapid development of LLM
    technology and the continuous creation of innovative methods and tools, there
    is a strong sense of excitement about the transformative prospects of this field
    in the near future.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管语言模型（LLM）技术仍在发展中，且可能出现错误和不准确，但它显示出了相当大的潜力，并且有有效的策略可以大大减轻这些问题。鉴于 LLM 技术的快速发展以及不断创新的方法和工具，关于这一领域在不久的将来可能带来的变革前景，充满了强烈的兴奋感。
- en: We are on the verge of deploying our RAG setup for production use, and as we
    continue to learn, I look forward to sharing more insights in upcoming blog posts.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们即将部署我们的 RAG 设置用于生产，并且在我们继续学习的过程中，我期待在即将发布的博客中分享更多见解。
- en: Should you find this article enjoyable and helpful, I would appreciate your
    support with 20 claps. I’m also eager to learn from your insights and experiences,
    so feel free to share your thoughts by posting a response. Additionally, if you’re
    interested, I welcome you to connect with me on [LinkedIn](https://www.linkedin.com/in/agustinus-nalwan/).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你发现这篇文章有趣且有帮助，我将感激你用 20 次鼓掌来支持我。我也渴望从你的见解和经验中学习，所以欢迎通过回复分享你的想法。此外，如果你有兴趣，我欢迎你在
    [LinkedIn](https://www.linkedin.com/in/agustinus-nalwan/) 上与我联系。
- en: In closing, I want to express my gratitude to my incredible team at Carsales.com
    for their support throughout this journey.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我想向 Carsales.com 的杰出团队表达我的感谢，感谢他们在这一旅程中的支持。
