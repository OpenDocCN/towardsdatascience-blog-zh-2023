- en: 'Understanding AUC Scores in Depth: What’s the Point?'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入理解AUC分数：意义何在？
- en: 原文：[https://towardsdatascience.com/understanding-auc-scores-in-depth-whats-the-point-5f2505eb499f](https://towardsdatascience.com/understanding-auc-scores-in-depth-whats-the-point-5f2505eb499f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/understanding-auc-scores-in-depth-whats-the-point-5f2505eb499f](https://towardsdatascience.com/understanding-auc-scores-in-depth-whats-the-point-5f2505eb499f)
- en: Exploring alternative metrics alongside for deeper insights
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索替代度量标准以获得更深入的见解
- en: '[](https://medium.com/@MahamsMultiverse?source=post_page-----5f2505eb499f--------------------------------)[![Maham
    Haroon](../Images/5a9ac82369ecbf7719b765ec160a70ef.png)](https://medium.com/@MahamsMultiverse?source=post_page-----5f2505eb499f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5f2505eb499f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5f2505eb499f--------------------------------)
    [Maham Haroon](https://medium.com/@MahamsMultiverse?source=post_page-----5f2505eb499f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@MahamsMultiverse?source=post_page-----5f2505eb499f--------------------------------)[![Maham
    Haroon](../Images/5a9ac82369ecbf7719b765ec160a70ef.png)](https://medium.com/@MahamsMultiverse?source=post_page-----5f2505eb499f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5f2505eb499f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5f2505eb499f--------------------------------)
    [Maham Haroon](https://medium.com/@MahamsMultiverse?source=post_page-----5f2505eb499f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5f2505eb499f--------------------------------)
    ·11 min read·Sep 2, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5f2505eb499f--------------------------------)
    ·阅读时间11分钟·2023年9月2日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/3dfdfb8105f958d905f36f02fa339e0a.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3dfdfb8105f958d905f36f02fa339e0a.png)'
- en: Photo by [Jonathan Greenaway](https://unsplash.com/@jogaway?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/TNUEQ73frkA?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Jonathan Greenaway](https://unsplash.com/@jogaway?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    在 [Unsplash](https://unsplash.com/photos/TNUEQ73frkA?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: Hello there!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你好！
- en: Today, we are delving into a specific metrics used for evaluating model performance
    — the AUC score. But before we delve into the specifics, have you ever wondered
    why unintuitive scores are at times necessary to assess the performance of our
    models?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，我们将深入探讨用于评估模型性能的特定度量标准——AUC分数。但在深入细节之前，你是否曾经想过为什么有时需要一些不直观的分数来评估我们模型的性能？
- en: 'Whether our model handles a single class or multiple classes, the underlying
    objective remains constant: optimizing accurate predictions while minimizing incorrect
    ones. To explore this basic objective, let’s first look at the obligatory confusion
    matrix encompassing True Positives, False Positives, True Negatives, and False
    Negatives.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 无论我们的模型处理的是单一类别还是多个类别，根本目标始终不变：优化准确预测的同时最小化错误预测。为了探讨这个基本目标，让我们首先来看一下包含真实正例、假正例、真实负例和假负例的混淆矩阵。
- en: '![](../Images/4fc6d99b4ef3d5cf0a1584103cfb21c3.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4fc6d99b4ef3d5cf0a1584103cfb21c3.png)'
- en: Image by Author
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'For any classification or prediction problem, there are only two outcomes:
    True or False.'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于任何分类或预测问题，只有两种结果：真或假。
- en: Consequently, every metric designed to gauge the performance of a prediction
    or classification algorithm is founded on these two measures. The simplest metric
    that accomplishes this is **Accuracy**.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，评估预测或分类算法性能的每个度量标准都基于这两项指标。实现这一点的最简单度量标准是**准确率**。
- en: Accuracy
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准确率
- en: In context of classification and prediction accuracy signifies the proportion
    of correctly predicted instances amongst the total. It’s a very straightforward
    and intuitive measure of a model’s predictive performance.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类和预测的背景下，准确率表示正确预测的实例在总实例中的比例。这是对模型预测性能非常直接和直观的度量标准。
- en: '![](../Images/7a5fc8223fbf73e0eb5ef4a6e20fa02a.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a5fc8223fbf73e0eb5ef4a6e20fa02a.png)'
- en: Image by Author
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: '**However, is accuracy truly sufficient?**'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**然而，准确率真的足够吗？**'
- en: While accuracy is a good general measure of a models performance, it’s inadequacy
    becomes evident when we examine the table below that we will frequently reference
    in this article. The table shows performance metrics of four models, each with
    somewhat suboptimal results but, all these models exhibit high accuracy. For instance
    in the first and second case, there’s a clear bias towards one class, resulting
    in dismal classification for the less common class yet the accuracy is 90% which
    is quite misleading.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然准确率是评估模型表现的一个良好一般指标，但当我们查看下面的表格时，它的不足之处变得显而易见。该表展示了四个模型的性能指标，每个模型的结果都有些次优，但这些模型都表现出高准确率。例如，在第一和第二个案例中，明显存在对某一类别的偏倚，导致对不常见类别的分类结果不佳，但准确率为
    90%，这非常具有误导性。
- en: '![](../Images/b13f52866214becd569a5cf32ec220cb.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b13f52866214becd569a5cf32ec220cb.png)'
- en: Image by Author
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: 'This helps us conclude:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这帮助我们得出结论：
- en: While accuracy is valuable, it can sometimes mislead, especially in scenarios
    of class imbalances or when certain errors carry substantial consequences.
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 尽管准确率很有价值，但它有时会误导，尤其是在类别不平衡的场景中或某些错误具有重大后果时。
- en: For instance, in situations where the cost of missing positive cases (Type 2
    error) or falsely identifying negatives (Type 1 error) is high, relying solely
    on accuracy might not provide a comprehensive assessment of a model’s effectiveness.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在漏掉正例（类型 2 错误）或错误识别负例（类型 1 错误）的代价高昂的情况下，单靠准确率可能无法全面评估模型的有效性。
- en: The strengths of accuracy lie in its simplicity and its applicability across
    classes.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率的优点在于其简单性以及在各个类别中的适用性。
- en: 'Now, having considered accuracy, let’s venture a little deeper into the realm
    of prediction and classification, several questions emerge:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，考虑到准确率，让我们深入探索预测和分类的领域，几个问题出现了：
- en: What is our objective?
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的目标是什么？
- en: Is our data balanced?
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的数据是否平衡？
- en: Do we prioritize one class over the other?
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否优先考虑一个类别而非另一个类别？
- en: Do we lean towards avoiding False Positives (Type 2 error), or do we emphasize
    minimizing False Negatives (Type 1 error)?
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们倾向于避免假正例（类型 2 错误），还是强调最小化假负例（类型 1 错误）？
- en: After asking these questions, it seems a little trivial to evaluate model performance
    based on just accuracy so we turn our attention to three other metrics for evaluating
    model performance, namely precision, recall and f1-score
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在提出这些问题之后，仅根据准确率评估模型性能似乎有些微不足道，因此我们将注意力转向评估模型性能的其他三个指标，即精确度、召回率和 F1 分数。
- en: Precision
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 精确度
- en: Precision gauges the accuracy with which our model identifies a specific class,
    in a 2 class scenario that is usually the positive class. It measures the reliability
    of predictions for the said class.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度衡量模型在识别特定类别（通常是积极类别）时的准确性。它衡量了对该类别预测的可靠性。
- en: Consider a scenario where a machine learning algorithm predicts loan approvals
    based on borrower characteristics. While occasional loan denials of eligible candidate
    (False Negative) might be acceptable to the company, the primary concern is avoiding
    unwarranted approval of loans to individuals who should not qualify (False Positive).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个场景，其中机器学习算法基于借款人特征预测贷款批准。虽然偶尔对合格候选人的贷款拒绝（假负例）可能对公司是可以接受的，但主要问题是避免对那些不应获得贷款的人（假正例）做出不必要的批准。
- en: '![](../Images/e4aaf3a1d480989f4919823e04d30be3.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e4aaf3a1d480989f4919823e04d30be3.png)'
- en: Image by Author
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: In that essence, precision aims to minimize Type 2 errors — instances where
    items are incorrectly accepted when they should be rejected.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，精确度旨在最小化类型 2 错误——那些应被拒绝但错误被接受的实例。
- en: 'Let’s demonstrate this by returning to our table:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过返回到我们的表格来演示这一点：
- en: '![](../Images/b13f52866214becd569a5cf32ec220cb.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b13f52866214becd569a5cf32ec220cb.png)'
- en: Image by Author
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: We observe here from cases 1 and 3 that a higher precision is achieved when
    the ratio of true positive to false positive predictions for a specific (positive)
    class is large irrespective of the actual model performance. Thus,
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从案例 1 和 3 中观察到，当特定（积极）类别的真正正例与假正例的比例较大时，可以实现更高的精确度，而不管实际的模型表现如何。因此，
- en: For a specific class, high precision points towards a low Type 2 error.
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于特定类别，高精确度意味着低类型 2 错误。
- en: 'Next, we have a counterpart to precision for Type 1 errors:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们有一个精确度的对应物来处理类型 1 错误：
- en: Recall, Sensitivity, or TPR
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 召回率、敏感度或 TPR
- en: Recall just like precision centers on our predictive ability for a specific
    class. It quantifies how effectively we can accurately select instances belonging
    to a particular category from the entire pool.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率与精确率一样，关注的是我们对特定类别的预测能力。它量化了我们从整个池中准确选择属于特定类别的实例的能力。
- en: Consider a scenario where our models aim is to prevent credit fraud. We can
    probably handle cases where a non-fraudulent activity is flagged as fraudulent(False
    Positive) but we do not want to miss an activity that might actually be fraudulent
    (False Negative).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个场景，其中我们模型的目标是防止信用欺诈。我们可能可以处理将非欺诈性活动标记为欺诈性（假阳性）的情况，但我们不希望遗漏可能实际上是欺诈的活动（假阴性）。
- en: In this context, aiming for high recall involves minimizing Type 1 errors —
    ensuring that you capture as many relevant instances as possible, even if it means
    flagging a few innocent ones along the way.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，追求高召回率涉及到最小化Type 1错误——确保尽可能捕捉到所有相关实例，即使这意味着标记一些无辜的实例。
- en: '![](../Images/ba3b20bc631a9c2205023f879db40e7f.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ba3b20bc631a9c2205023f879db40e7f.png)'
- en: Image by Author
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'Lets return to our table for the third time:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们第三次回到我们的表格：
- en: '![](../Images/b13f52866214becd569a5cf32ec220cb.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b13f52866214becd569a5cf32ec220cb.png)'
- en: Image by Author
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: We can see from cases 1 and 4 that, recall excels when positive classifications
    are maximized. In these cases, even if false positives are present or the negative
    class’s performance is subpar, recall remains high. Therefore,
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 从案例1和4中我们可以看到，当最大化正分类时，召回率表现优异。在这些情况下，即使存在假阳性或负类别的表现不佳，召回率仍然很高。因此，
- en: High recall for a specific class ensures the minimization of Type 1 errors.
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于特定类别，高召回率确保了Type 1错误的最小化。
- en: '**Now, what if we aim to minimize both types of errors for a class?**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**现在，如果我们旨在最小化类别的两种错误类型呢？**'
- en: 'This is where the F1 score comes into play:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是F1得分发挥作用的地方：
- en: F1-Score
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: F1-得分
- en: F1-Score is the harmonic mean between precision and recall. F1 score essentially
    tries to find a balance between precision and recall of a class and in that manner
    also attempts at a balance between type 1 and type 2 errors.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: F1-得分是精确率和召回率的调和平均数。F1得分本质上试图在类别的精确率和召回率之间找到平衡，并在这种方式中也尝试平衡Type 1和Type 2错误。
- en: In essence, he F1 score shows a classification model’s overall effectiveness
    for a particular class.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，F1得分展示了分类模型在特定类别上的整体有效性。
- en: '![](../Images/8f8bba75bc0197707df53cdd9eeaba4a.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8f8bba75bc0197707df53cdd9eeaba4a.png)'
- en: Image by Author
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'Let’s return to our table for the fourth and final perspective:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从第四个也是最后一个角度回到我们的表格：
- en: '![](../Images/b13f52866214becd569a5cf32ec220cb.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b13f52866214becd569a5cf32ec220cb.png)'
- en: Image by Author
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: This time, we observe that the F1 score performs well when both precision and
    recall excel which is true for case 1\. Note that the model is still performing
    sub-optimally for this scenario but since the number of True Positives is high,
    and both False Positives and False Negatives are small in number, the score for
    F1 is high. We can therefore infer,
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次，我们观察到，当精确率和召回率都表现优异时，F1得分表现良好，这在案例1中是正确的。注意，尽管模型在这种情况下的表现仍然不够理想，但由于真正的正例数量很高，而假阳性和假阴性的数量都很小，因此F1得分很高。因此，我们可以推断，
- en: A high F1 score, being more conservative, for a specific class, minimizes both
    Type 1 and Type 2 errors.
  id: totrans-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 高F1得分对于特定类别来说更为保守，可以最小化Type 1和Type 2错误。
- en: Having examined the other metrics, it’s evident that each of them possesses
    certain limitations. Further more unlike accuracy, F1, Precision, and Recall are
    not class-agnostic, while accuracy remains vulnerable to class imbalances.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在检查了其他指标后，很明显每个指标都有其局限性。此外，与准确率不同，F1、精确率和召回率并不具备类无关性，而准确率仍然容易受到类不平衡的影响。
- en: 'Moreover, we never asked the question: “What’s the prediction threshold?” In
    other words, is there a clear separation between classes? Are positive instances
    assigned predictions around 0.8–0.9, or are they closer to 0.51?'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们从未提出过这样的问题：“预测阈值是多少？”换句话说，类别之间是否存在明显的分界？正实例的预测分数是集中在0.8-0.9之间，还是更接近0.51？
- en: This is where the ROC Curve and AUC score come into play, albeit with a fair
    degree of unintuitiveness.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是ROC曲线和AUC得分发挥作用的地方，尽管这些方法有一定程度的直观性不足。
- en: Understanding the AUC Score
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解AUC得分
- en: The AUC Score, also known as the Area Under the Curve, is a score measured by
    calculating the area under the Receiver Operating Characteristic (ROC) Curve.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: AUC 分数，也称为曲线下面积，是通过计算接收者操作特征（ROC）曲线下的面积来衡量的分数。
- en: The ROC curve is a plot with Recall/True Positive Rate (TPR) on the y-axis and
    False Positive Rate (FPR) on the x-axis. The peculiar name of ROC stems from its
    origin in the field of Electrical Engineering.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ROC 曲线是一个图表，y 轴为召回率/真阳性率（TPR），x 轴为假阳性率（FPR）。ROC 的名字源于其在电气工程领域的起源。
- en: In order to construct the ROC curve, FPR and TPR are calculated for various
    classification thresholds. A classification threshold refers to the prediction
    value, such as 0.5, above which instances are classified differently than those
    below 0.5.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构造 ROC 曲线，需要计算不同分类阈值下的 FPR 和 TPR。分类阈值指的是预测值，例如 0.5，超过该值的实例被分类为正类，而低于 0.5 的实例则被分类为负类。
- en: '![](../Images/09b994478b7997e5f0ab24c5e007e97c.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/09b994478b7997e5f0ab24c5e007e97c.png)'
- en: By cmglee, MartinThoma — Roc-draft-xkcd-style.svg, CC BY-SA 4.0, [https://commons.wikimedia.org/w/index.php?curid=109730045](https://commons.wikimedia.org/w/index.php?curid=109730045)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 由 cmglee 和 MartinThoma 制作 — Roc-draft-xkcd-style.svg，CC BY-SA 4.0，[https://commons.wikimedia.org/w/index.php?curid=109730045](https://commons.wikimedia.org/w/index.php?curid=109730045)
- en: However, since creating the complete curve can be cumbersome and does not provide
    a quantifiable measure, the area under the curve is measured instead.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于创建完整的曲线可能会很繁琐且无法提供量化的衡量，因此测量曲线下的面积（AUC）成为了更常用的做法。
- en: Below, I show progression of creating a ROC curve by plotting FPR vs TPR values
    for various classification thresholds. I mark each new point added as red and
    the prior ones as blue. We can see that upon joining these independent points
    the curve looks quite a bit similar to the light blue curve in the above image
    and seems consistent with the AUC score of 0.91 for the model.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 下面，我展示了通过绘制 FPR 与 TPR 值的进展，以显示 ROC 曲线的创建过程。我将每个新添加的点标记为红色，而之前的点标记为蓝色。我们可以看到，当这些独立的点连接起来时，曲线与上图中的浅蓝色曲线非常相似，并且与模型的
    AUC 分数 0.91 一致。
- en: '![](../Images/8eb9a498e09fc491e27836767e5bd5fe.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8eb9a498e09fc491e27836767e5bd5fe.png)'
- en: Image by Author
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: The figure also shows how changing thresholds affects other metrics like Accuracy,
    F1, precision and recall.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图中还展示了阈值的变化如何影响其他指标，如准确率、F1 分数、精确度和召回率。
- en: 'The code use to create the above is as follows:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 用于创建上述图形的代码如下：
- en: '[PRE0]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This code snippet showcases the process of creating an ROC curve and calculating
    the AUC score using Python. It involves generating a synthetic dataset, splitting
    it into training and testing sets, training a logistic regression model, and then
    plotting points on the ROC curve for different classification thresholds.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码展示了如何使用 Python 创建 ROC 曲线并计算 AUC 分数。它包括生成一个合成数据集，将其拆分为训练集和测试集，训练一个逻辑回归模型，然后绘制不同分类阈值下的
    ROC 曲线点。
- en: '**A tangent: Would it matter if instead it was True Negative Rate against False
    Negative Rate?**'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**一个题外话：如果换成真负率与假负率对比会有什么影响吗？**'
- en: Nope, since TNR = 1-FPR and FNR = 1-TPR
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 不，因为 TNR = 1-FPR 和 FNR = 1-TPR
- en: '![](../Images/d9e14e165db77e4dacc68f5a353a16dd.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9e14e165db77e4dacc68f5a353a16dd.png)'
- en: Image by Author
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: What about multiple classes?
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多类别情况如何？
- en: Well at a time ROC Curve can be calculated for only two classes so for multiple
    classes it can get a bit complex but can do one-vs-all for every class.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 ROC 曲线一次只能计算两个类别，所以对于多个类别来说会稍显复杂，但可以对每个类别进行一对多的比较。
- en: Now that we’ve seen how it’s constructed let’s go a little bit deeper on how
    to interpret the AUC score and what does it mean for the model.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了 AUC 分数的构造方式，让我们更深入地探讨如何解释 AUC 分数及其对模型的意义。
- en: Interpreting the AUC Score
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释 AUC 分数
- en: We want to look at 4 cases and I demonstrate this via images where everything
    at the right side of the classification threshold is predicted as positive and
    everything on the left is predicted as negative. The actual labels for the data
    are in the respective rectangles representing them.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将查看 4 种情况，我通过图片展示了在分类阈值右侧的所有数据被预测为正类，而左侧的数据被预测为负类。数据的实际标签在各自的矩形框中表示。
- en: 0 AUC Score
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 0 AUC 分数
- en: A 0 AUC score would be quite hard to achieve and possibly points towards some
    serious human error. It means that TPR is 0 at every classification threshold
    except when FPR is 1\. At FPR 1, TPR goes from 0–1 at various classification thresholds
    this making area under this curve effectively 0\. Visually it’ll mean that there’s
    perfect class separation but every label is reversed.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: AUC分数为0将很难达到，并且可能指向一些严重的人为错误。这意味着TPR在每个分类阈值下都是0，除非FPR为1。在FPR为1时，TPR在不同的分类阈值下从0到1，这使得曲线下的面积有效地为0。视觉上，这将意味着存在完美的类别分离，但每个标签都被反转了。
- en: '![](../Images/f725b5762337884cde40295855d90657.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f725b5762337884cde40295855d90657.png)'
- en: Image by Author
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: '**0.5 AUC Score**'
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**0.5 AUC分数**'
- en: Now this is the case where the model didn’t learn anything and classification
    or prediction is just random. In this case the ROC curve shows a linear relationship
    or straight proportional line between TPR and FPR. Visually, it would seem that
    there’s effectively no class separation at all.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在这是模型没有学到任何东西，分类或预测仅仅是随机的情况。在这种情况下，ROC曲线显示了TPR和FPR之间的线性关系或直线比例线。视觉上，它看起来好像完全没有类别分离。
- en: '![](../Images/7c7891467fe1d6a4ab7f3cc2c865275c.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7c7891467fe1d6a4ab7f3cc2c865275c.png)'
- en: Image by Author
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: '**0.5 <AUC Score < 1**'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**0.5 < AUC分数 < 1**'
- en: These are the most common cases if we do things right in our model. An AUC score
    between 0.5 and 1 means that the model has at least learned something superior
    to a random classifier but there are still instances in the data that overlap
    and the model can’t effectively separate the classes completely. The closer the
    AUC score is to one, the greater is the separation between the classes achieved.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在模型中正确操作，这些是最常见的情况。AUC分数在0.5到1之间意味着模型至少学到了一些优于随机分类器的东西，但数据中仍然存在重叠实例，模型无法完全有效地分离类别。AUC分数越接近1，类别之间的分离程度就越大。
- en: '![](../Images/3cb76116d4735e976377d8a315fac229.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3cb76116d4735e976377d8a315fac229.png)'
- en: Image by Author
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: '**Perfect AUC Score**'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**完美的AUC分数**'
- en: A perfect AUC score of 1.0 indicates that the model has perfect discrimination
    ability. However, achieving such a perfect AUC score can indeed be a sign of potential
    overfitting and unrealistic model behavior, particularly when dealing with real-world
    datasets and scenarios.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 完美的AUC分数1.0表示模型具有完美的区分能力。然而，达到如此完美的AUC分数确实可能是潜在过拟合和不切实际的模型行为的标志，尤其是在处理现实世界数据集和场景时。
- en: The TPR is effectively 1 for all cases except for when FPR is 0\. Eventually
    leading to an area under curve equalling 1\. Visually this means that there is
    perfect class separation between the two classes and the prediction is also correct.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 除非FPR为0，否则TPR在所有情况下都有效为1。最终导致曲线下的面积等于1。这在视觉上意味着两个类别之间有完美的类别分离，并且预测也是正确的。
- en: '![](../Images/e805e857c9e26b9a51d2627d3ff6780c.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e805e857c9e26b9a51d2627d3ff6780c.png)'
- en: Image by Author
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: It’s important to note that, real-world data is often noisy and contains inherent
    uncertainty. Expecting a model to produce perfect separation can be unrealistic
    and even if it happens, it’s probably a case of overfitting.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，现实世界的数据通常是嘈杂的并且包含固有的不确定性。期望一个模型产生完美的分离可能是不现实的，即使它发生了，这也可能是过拟合的情况。
- en: In case, where an unlikely AUC score of 1 is achieved, the model will likely
    fail to generalize effectively and perform well in practical scenarios due to
    high probability of overfitting.
  id: totrans-112
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果达到了不太可能的AUC分数1，模型可能会由于过拟合的高概率而无法有效地进行泛化，并在实际场景中表现良好。
- en: A more balanced and robust model is one that achieves a reasonably high AUC
    score while also allowing for some level of uncertainty in its predictions.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更平衡和稳健的模型是一个在达到合理高的AUC分数的同时，还允许一定程度的不确定性。
- en: Let’s look at some benefits of using AUC score.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看使用AUC分数的一些好处。
- en: Benefits of AUC Score
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AUC分数的好处
- en: There are quite a few benefits to AUC score compared to other metrics
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他指标相比，AUC分数有很多好处
- en: '**Class Agnostic:** In contrast to metrics like precision, recall, and F1 score,
    which are dependent on a chosen positive class, AUC provides a more global assessment
    of a model’s discriminative power, regardless of class distribution.'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**与类别无关：** 与依赖于选定正类的精度、召回率和F1分数等指标相比，AUC提供了对模型区分能力的更全面评估，而不受类别分布的影响。'
- en: '**Prediction Threshold Agnostic:** One of the distinguishing features of AUC
    score is that it considers the model’s performance across different classification
    thresholds, providing a comprehensive view of its ability to discriminate between
    classes.'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**预测阈值无关性：** AUC评分的一个显著特点是它考虑了模型在不同分类阈值下的表现，提供了其区分类别能力的全面视图。'
- en: '**Insensitive to Class Imbalance:** Since AUC measures how well the model can
    rank positive and negative instances relative to each other, it is less prone
    to distortions caused by imbalanced class distributions.'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**对类别不平衡不敏感：** 由于AUC衡量模型如何相对排序正负实例，它不容易受到类别分布不平衡引起的扭曲。'
- en: '**ROC Curve Threshold Selection:** While AUC is threshold-agnostic, the ROC
    curve itself can help you visually choose a threshold that gives the best performance.'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ROC曲线阈值选择：** 尽管AUC不受阈值影响，但ROC曲线本身可以帮助你直观地选择一个提供最佳性能的阈值。'
- en: Disadvantages of AUC Score
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AUC评分的缺点
- en: While there aren’t many disadvantage and this isn’t an exhaustive list, it’s
    important to note that under extreme imbalance of data AUC score may be affected.
    Furthermore, AUC treats all misclassifications equally. In many real-world scenarios,
    the costs and benefits associated with different types of errors can vary. AUC
    doesn’t take this into account and might not fully represent the performance in
    cases where one type of error is more critical than another.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然没有很多缺点，而且这不是一个详尽的列表，但需要注意的是，在数据极度不平衡的情况下，AUC评分可能会受到影响。此外，AUC对所有误分类一视同仁。在许多现实世界的场景中，不同类型错误相关的成本和收益可能会有所不同。AUC没有考虑这些因素，可能无法完全代表在某种错误比另一种更为关键的情况下的性能。
- en: Wrapping UP
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: So let’s wrap up by saying that although AUC score is an excellent measure of
    model performance each metric has its strengths under the right context.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们总结一下，虽然AUC评分是评估模型性能的一个极佳指标，但每个指标在合适的上下文中都有其优点。
- en: As we come to an end I hope this was a valuable read and would like you to walk
    away with clear understanding of what an AUC score is and how to interpret it.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束时，我希望这篇文章对你有价值，并希望你能清楚地理解AUC评分是什么以及如何解读它。
- en: If you found this insightful let me know in the comments. :)
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你觉得这很有启发性，请在评论中告诉我。:)
- en: Other Resource for AUC Score…
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AUC评分的其他资源……
- en: '[](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8204137/?source=post_page-----5f2505eb499f--------------------------------)
    [## Magician''s Corner: 9\. Performance Metrics for Machine Learning Models'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 魔术师角落：9\. 机器学习模型性能指标](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8204137/?source=post_page-----5f2505eb499f--------------------------------)'
- en: '"There are no solutions; there are only trade-offs." In the previous articles,
    we showed how to process images and…'
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: “没有解决方案，只有权衡。”在之前的文章中，我们展示了如何处理图像和……
- en: www.ncbi.nlm.nih.gov](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8204137/?source=post_page-----5f2505eb499f--------------------------------)
    [](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks?source=post_page-----5f2505eb499f--------------------------------)
    [## CS 229 — Machine Learning Tips and Tricks Cheatsheet
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[## CS 229 — 机器学习技巧和窍门备忘单](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks?source=post_page-----5f2505eb499f--------------------------------)'
- en: Teaching page of Shervine Amidi, Graduate Student at Stanford University.
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 斯坦福大学研究生Shervine Amidi的教学页面。
- en: stanford.edu](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks?source=post_page-----5f2505eb499f--------------------------------)
    [](https://www.statology.org/what-is-a-good-auc-score/?source=post_page-----5f2505eb499f--------------------------------)
    [## What is Considered a Good AUC Score? - Statology
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 什么是好的AUC评分？ - Statology](https://www.statology.org/what-is-a-good-auc-score/?source=post_page-----5f2505eb499f--------------------------------)'
- en: This tutorial explains what is considered to be a good value for AUC (area under
    curve), including several examples.
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本教程解释了什么被认为是AUC（曲线下面积）的好值，包括几个示例。
- en: www.statology.org](https://www.statology.org/what-is-a-good-auc-score/?source=post_page-----5f2505eb499f--------------------------------)
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 统计学](https://www.statology.org/what-is-a-good-auc-score/?source=post_page-----5f2505eb499f--------------------------------)'
