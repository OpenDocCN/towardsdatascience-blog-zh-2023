["```py\n# Code snippet from SHAP github page\nimport xgboost\nimport shap\n\n# train an XGBoost model\nX, y = shap.datasets.boston()\nmodel = xgboost.XGBRegressor().fit(X, y)\n\n# explain the model's predictions using SHAP\n# (same syntax works for LightGBM, CatBoost, scikit-learn, transformers, Spark, etc.)\nexplainer = shap.Explainer(model)\nshap_values = explainer(X)\n\n# visualize the first prediction's explanation\nshap.plots.waterfall(shap_values[0])\n```", "```py\n# Code snippet from SHAP github page\n# visualize the first prediction's explanation with a force plot\nshap.plots.force(shap_values[0])\n```", "```py\n# Code snippet from SHAP github page\n# visualize all the training set predictions\nshap.plots.force(shap_values)\n```", "```py\nimport shap\n\n# Load the data\nX_train, y_train, X_test, y_test = load_data()\n\n# Train the model\nmodel = MyModel.train(X_train, y_train)\n\n# Explain the model's predictions using the tree path dependent approach\nexplainer = shap.TreeExplainer(\n    model,\n    X_train,\n    feature_perturbation='tree_path_dependent')\nshap_values_path = explainer.shap_values(X_test)\n\n# Display the explanations\nshap.summary_plot(shap_values_path, X_test)\n\n# Explain the model's predictions using the interventional approach\nexplainer = shap.TreeExplainer(\n    model,\n    X_train,\n    feature_perturbation='interventional')\nshap_values_interv = explainer.shap_values(X_test)\n\n# Display the explanations\nshap.summary_plot(shap_values_interv, X_test)\n```", "```py\nimport shap\n\n# Load the data\nX_train, y_train, X_test, y_test = load_data()\n\n# Train the model\nmodel = MyModel.train(X_train, y_train)\n\n# Explain the model's predictions using TreeSHAP\nexplainer = shap.DeepExplainer(model, X_train)\nshap_values = explainer.shap_values(X_test)\n\n# Display the explanations\nshap.summary_plot(shap_values, X_test)\n```", "```py\npip install lime\n```", "```py\nimport lime\nimport lime.lime_tabular\n\n# Load the data\nX_train, y_train, X_test, y_test = load_data()\nfeature_names = X_train.columns\n\n# Train the model\nmodel = MyModel.train(X_train, y_train)\n\n# Explain the model's predictions using LIME\nexplainer = lime.lime_tabular.LimeTabularExplainer(\n    X_train, feature_names=feature_names)\n\n# Choose a kernel size for the local neighborhood\nkernel_size = 10\n\n# Explain the model's prediction for a single instance\ninstance = X_test[0]\nexp = explainer.explain_instance(\n    instance,\n    model.predict,\n    num_features=10,\n    kernel_size=kernel_size)\n\n# Display the explanations\nexp.show_in_notebook(show_all=False)\n```"]