["```py\nimport transformers, huggingface_hub, diffusers, torch\nfrom platform import python_version\nprint(f'python: {python_version()}')\nprint(f'transformers: {transformers.__version__}')\nprint(f'huggingface_hub: {huggingface_hub.__version__}')\nprint(f'diffusers: {diffusers.__version__}')\nprint(f'torch: {torch.__version__}')\n```", "```py\n%%sh\n\npip install transformers==4.29.0\n\npip install huggingface_hub==0.14.1\n\npip install diffusers==0.16.1\n\npip install --upgrade torch torchvision\n\npip install openai==0.27.6\n```", "```py\nimport huggingface_hub\nfrom huggingface_hub import login\n\nmy_hf_token = 'ADD_YOUR_TOKEN_HERE'\n\nlogin(my_hf_token)\n```", "```py\nimport transformers\nfrom transformers import HfAgent\n\n# Starcoder\nagent_starcoder = HfAgent(\"https://api-inference.huggingface.co/models/bigcode/starcoder\")\n```", "```py\ntask = \"Draw me a picture of the ocean\"\n\npicture_ocean = agent_starcoder.run(task)\n\npicture_ocean\n```", "```py\npicture_ocean = agent_starcoder.run(task)\n\npicture_ocean\n```", "```py\npicture_ocean_updated = agent.run(\"Transform the image in `picture_ocean` to add a ship to it.\", picture=picture_ocean)\n\npicture_ocean_updated\n```", "```py\ntask = \"Draw me a picture of the ocean\"\n\nagent_starcoder.run(task, return_code=True)\n```", "```py\nfrom transformers import load_tool\nimage_generator = load_tool(\"huggingface-tools/text-to-image\")\nimage = image_generator(prompt=\"ocean\")\n```", "```py\n from transformers import load_tool\n\nimage_generator = load_tool(\"huggingface-tools/text-to-image\")\n\nimage = image_generator(prompt=\"ocean\")\n\nimage\n```", "```py\nfrom transformers import load_tool\n\nimage_generator = load_tool(\"huggingface-tools/text-to-image\")\n\nimage_generator(prompt=\"toy car\")\n```", "```py\nfrom PIL import Image\n\ntask = 'Caption the following image'\n\nimage = Image.open('/content/picture.png')\n\nagent_starcoder.run(task, image=image)\n```", "```py\nagent_starcoder.run(task, image=image, return_code=True)\n```", "```py\nfrom transformers import load_tool\nimage_captioner = load_tool(\"image-captioning\")\ncaption = image_captioner(image)\n```", "```py\nfrom PIL import Image\nimage = Image.open('/content/jack.jpg')\nimage.show()\n```", "```py\ntask = \"in the following 'document', what is Jack's favorite color?\"\n\nagent_starcoder.run(task, document=image)\n```", "```py\ntask = \"in the following 'document', what is Jack's favorite color?\"\n\nagent_starcoder.run(task, document=image, return_code=True)\n```", "```py\nfrom transformers import load_tool\n\ndocument_qa = load_tool(\"document-question-answering\")\n\nanswer = document_qa(document, question=\"What is Jack's favorite color?\")\nprint(f\"The answer is {answer}.\")\n```", "```py\ntext = 'this is a sentence in English'\n\ntask = \"translate the following 'document' to French\"\n\nagent_starcoder.run(task, document=text)\n```", "```py\nagent_starcoder.run(task, document=text, return_code=True)\n```", "```py\nfrom transformers import load_tool\ntranslator = load_tool(\"translation\")\ntranslated_document = translator(document, src_lang=\"English\", tgt_lang=\"French\")\n```", "```py\ntask = \"in the following 'document', what is Jack's favorite color? After you answer the question, translate the answer to French\"\n\nagent_starcoder.run(task, document=image)\n```"]