["```py\nimport os\nfrom itertools import combinations\n\nimport numpy as np\nfrom scipy import linalg \nfrom scipy import stats \n\nimport matplotlib.pyplot as plt\n\nfrom langchain.agents import load_tools, initialize_agent\nfrom langchain.agents import AgentType\n\nfrom langchain.chat_models import ChatOpenAI\n\nfrom castle.common import GraphDAG\nfrom castle.metrics import MetricsDAG\nfrom castle.algorithms import PC\n\nfrom castle.common.priori_knowledge import PrioriKnowledge\n```", "```py\nwith open(r'my_folder/my_openai_key.dat') as f:\n    key = f.read()\n\nos.environ['OPENAI_API_KEY'] = key\n```", "```py\nall_vars = {\n    'altitude': 0,\n    'oxygen_density': 1,\n    'temperature': 2,\n    'risk_of_death': 3,\n    'mehendretex': 4\n}\n```", "```py\nSAMPLE_SIZE = 1000\n\naltitude = stats.halfnorm.rvs(scale=2000, size=SAMPLE_SIZE)\ntemperature = 25 - altitude / 100 + stats.norm.rvs(\n    loc=0,\n    scale=2,\n    size=SAMPLE_SIZE\n)\n\nmehendretex = stats.halfnorm.rvs(size=SAMPLE_SIZE)\n\noxygen_density = np.clip(\n    1 - altitude / 8000 \n    - temperature / 50 \n    + stats.norm.rvs(size=SAMPLE_SIZE) / 20,\n    0, \n    1)\n\nrisk_of_death = np.clip(\n    altitude / 20000 \n    + np.abs(temperature) / 100 \n    - oxygen_density / 5 \n    - mehendretex / 5\n    + stats.norm.rvs(size=SAMPLE_SIZE) / 10,\n    0,\n    1\n)\n```", "```py\ndataset = np.stack(\n    [\n        altitude,\n        oxygen_density,\n        temperature,\n        risk_of_death,\n        mehendretex\n    ]\n).T\n```", "```py\ntrue_dag = np.array(\n    [\n        [0, 1, 1, 1, 0],\n        [0, 0, 0, 1, 0],\n        [0, 1, 0, 1, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 1, 0]\n    ]\n)\n```", "```py\n# PC discovery without LLM assist\npc = PC(variant='stable')\npc.learn(dataset)\n\n# Vizualize\nGraphDAG(\n    est_dag=pc.causal_matrix, \n    true_dag=true_dag)\n\nplt.show()\n\n# Compute metrics\nmetrics = MetricsDAG(\n    B_est=pc.causal_matrix, \n    B_true=true_dag)\n\nprint(metrics.metrics)\n```", "```py\n# Instantiate the priori knowledge object\npriori_knowledge = PrioriKnowledge(n_nodes=len(all_vars))\n```", "```py\nllm = ChatOpenAI(\n    temperature=0, \n    model='gpt-4')\n```", "```py\n# Load tools\ntools = load_tools(\n    [\n        \"wikipedia\"\n    ], \n    llm=llm)\n```", "```py\n# Instantiate the agent\nagent = initialize_agent(\n    tools, \n    llm, \n    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n    handle_parsing_errors=True,\n    verbose=False)\n```", "```py\ndef get_llm_info(llm, agent, var_1, var_2):\n\n    out = agent(f\"Does {var_1} cause {var_2} or the other way around?\\\n    We assume the following definition of causation:\\\n    if we change A, B will also change.\\\n    The relationship does not have to be linear or monotonic.\\\n    We are interested in all types of causal relationships, including\\\n    partial and indirect relationships, given that our definition holds.\\\n    \")\n\n    print(out)\n\n    pred = llm.predict(f'We assume the following definition of causation:\\\n    if we change A, B will also change.\\\n    Based on the following information: {out[\"output\"]},\\\n    print (0,1) if {var_1} causes {var_2},\\\n    print (1, 0) if {var_2} causes {var_1}, print (0,0)\\\n    if there is no causal relationship between {var_1} and {var_2}.\\\n    Finally, print (-1, -1) if you don\\'t know. Importantly, don\\'t try to\\\n    make up an answer if you don\\'t know.')\n\n    print(pred)\n\n    return pred\n```", "```py\nfor var_1, var_2 in combinations(all_vars.keys(), r=2):\n    print(var_1, var_2)\n    out = get_llm_info(llm, agent, var_1, var_2)\n    if out=='(0,1)':\n        priori_knowledge.add_required_edges(\n            [(all_vars[var_1], all_vars[var_2])]\n        )\n\n        priori_knowledge.add_forbidden_edges(\n            [(all_vars[var_2], all_vars[var_1])]\n        )\n\n    elif out=='(1,0)':\n        priori_knowledge.add_required_edges(\n            [(all_vars[var_2], all_vars[var_1])]\n        )\n        priori_knowledge.add_forbidden_edges(\n            [(all_vars[var_1], all_vars[var_2])]\n        )\n\nprint('\\nLLM knowledge vs true DAG')\npriori_dag = np.clip(priori_knowledge.matrix, 0, 1)\n\nGraphDAG(\n    est_dag=priori_dag, \n    true_dag=true_dag)\n\nplt.show()\n```", "```py\n{'input': 'Does risk_of_death cause mehendretex or the other way around?    \nWe assume the following definition of causation:    \nif we change A, B will also change.    \nThe relationship does not have to be linear or monotonic.    \nWe are interested in all types of causal relationships, including    \npartial and indirect relationships, given that our definition holds.', \n'output': 'I\\'m sorry, but I couldn\\'t \nfind any information on \"mehendretex\". \nTherefore, it\\'s impossible to determine a causal relationship \nbetween \"risk_of_death\" and \"mehendretex\". \nCould you please provide more context or \ncheck if \"mehendretex\" is spelled correctly?'}\n(-1, -1)\n```", "```py\nprint('\\nRunning PC')\n# Instantiate the model with expert knowledge\npc_priori = PC(\n    priori_knowledge=priori_knowledge,\n    variant='stable'\n)\n\n# Learn\npc_priori.learn(dataset)\n\nGraphDAG(\n    est_dag=pc_priori.causal_matrix, \n    true_dag=true_dag)\n\nplt.show()\n\n# Compute metrics\nmetrics = MetricsDAG(\n    B_est=pc_priori.causal_matrix, \n    B_true=true_dag)\n\nprint(metrics.metrics)\n```"]