["```py\nfrom generative.networks.nets import AutoencoderKL\n\n...\n\nmodel = AutoencoderKL(\n    spatial_dims=2,\n    in_channels=1,\n    out_channels=1,\n    num_channels=[64, 128, 128, 128],\n    latent_channels=3,\n    num_res_blocks=2,\n    attention_levels=[False, False, False, False],\n    with_encoder_nonlocal_attn=False,\n    with_decoder_nonlocal_attn=False,\n)\n```", "```py\n# Inside training loop\nreconstruction, z_mu, z_sigma = model(x=images)\n\nâ€¦\n\nkl_loss = 0.5 * torch.sum(z_mu.pow(2) + z_sigma.pow(2) - torch.log(z_sigma.pow(2)) - 1, dim=[1, 2, 3])\nkl_loss = torch.sum(kl_loss) / kl_loss.shape[0]\n```", "```py\nl1_loss = F.l1_loss(reconstruction.float(), images.float())\n```", "```py\n# Instantiating the perceptual loss\nperceptual_loss = PerceptualLoss(\n     spatial_dims=2,\n     network_type=\"squeeze\",\n)\n\n...\n\n# Inside training loop\n...\np_loss = perceptual_loss(reconstruction.float(), images.float())\n```", "```py\nfrom generative.networks.nets import DiffusionModelUNet\n\n...\n\ndiffusion = DiffusionModelUNet(\n    spatial_dims=2,\n    in_channels=3,\n    out_channels=3,\n    num_res_blocks=2,\n    num_channels=[256, 512, 768],\n    attention_levels=[False, True, True],\n    with_conditioning=True,\n    cross_attention_dim=1024,\n    num_head_channels=[0, 512, 768],\n)\n```", "```py\nfrom generative.networks.schedulers import DDPMScheduler\n\n...\n\nscheduler = DDPMScheduler(\n    beta_schedule=\"scaled_linear\",\n    num_train_timesteps=1000,\n    beta_start=0.0015,\n    beta_end=0.0205,\n    prediction_type=\"v_prediction\",\n)\n```", "```py\n# Inside training loop\n...\n\nwith torch.no_grad():\n    e = stage1(images) * scale_factor\n    prompt_embeds = text_encoder(reports.squeeze(1))[0]\n\ntimesteps = torch.randint(0, scheduler.num_train_timesteps, (images.shape[0],), device=device).long()\nnoise = torch.randn_like(e).to(device)\nnoisy_e = scheduler.add_noise(original_samples=e, noise=noise, timesteps=timesteps)\nnoise_pred = model(x=noisy_e, timesteps=timesteps, context=prompt_embeds)\n\nif scheduler.prediction_type == \"v_prediction\":\n    # Use v-prediction parameterization\n    target = scheduler.get_velocity(e, noise, timesteps)\nelif scheduler.prediction_type == \"epsilon\":\n    target = noise\n\nloss = F.mse_loss(noise_pred.float(), target.float())\n```"]