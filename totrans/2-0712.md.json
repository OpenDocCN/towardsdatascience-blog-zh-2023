["```py\ngit clone git@github.com:ahmedbesbes/BentoChain.git\ncd BentoChain/\npoetry install \n```", "```py\nmkdir ssl\ncd ssl\nopenssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -sha256 -days 365 -nodes\n```", "```py\nimport logging\nimport bentoml\nfrom transformers import (\n    SpeechT5Processor,\n    SpeechT5ForTextToSpeech,\n    SpeechT5HifiGan,\n    WhisperForConditionalGeneration,\n    WhisperProcessor,\n)\n\nlogging.basicConfig(level=logging.WARN)\n\nif __name__ == \"__main__\":\n    t5_processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n    t5_model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n    t5_vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n\n    whisper_processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n    whisper_model = WhisperForConditionalGeneration.from_pretrained(\n        \"openai/whisper-tiny\"\n    )\n    whisper_model.config.forced_decoder_ids = None\n```", "```py\n saved_t5_processor = bentoml.transformers.save_model(\n        \"speecht5_tts_processor\", t5_processor\n    )\n    print(f\"Saved: {saved_t5_processor}\")\n\n    saved_t5_model = bentoml.transformers.save_model(\n        \"speecht5_tts_model\",\n        t5_model,\n        signatures={\"generate_speech\": {\"batchable\": False}},\n    )\n    print(f\"Saved: {saved_t5_model}\")\n\n    saved_t5_vocoder = bentoml.transformers.save_model(\n        \"speecht5_tts_vocoder\", t5_vocoder\n    )\n    print(f\"Saved: {saved_t5_vocoder}\")\n\n    saved_whisper_processor = bentoml.transformers.save_model(\n        \"whisper_processor\",\n        whisper_processor,\n    )\n    print(f\"Saved: {saved_whisper_processor}\")\n\n    saved_whisper_model = bentoml.transformers.save_model(\n        \"whisper_model\",\n        whisper_model,\n    )\n    print(f\"Saved: {saved_whisper_model}\")\n```", "```py\npoetry shell\npython train.py\n```", "```py\nimport torch\nimport bentoml\n\ns2t_processor_ref = bentoml.models.get(\"whisper_processor:latest\")\ns2t_model_ref = bentoml.models.get(\"whisper_model:latest\")\n\nclass Speech2TextRunnable(bentoml.Runnable):\n    SUPPORTED_RESOURCES = (\"nvidia.com/gpu\", \"cpu\")\n    SUPPORTS_CPU_MULTI_THREADING = True\n\n    def __init__(self):\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.processor = bentoml.transformers.load_model(s2t_processor_ref)\n        self.model = bentoml.transformers.load_model(s2t_model_ref)\n        self.model.to(self.device)\n\n    @bentoml.Runnable.method(batchable=False)\n    def transcribe_audio(self, tensor):\n        if tensor is not None:\n            predicted_ids = self.model.generate(tensor.to(self.device))\n            transcriptions = self.processor.batch_decode(\n                predicted_ids, skip_special_tokens=True\n            )\n            transcription = transcriptions[0]\n            return transcription \n```", "```py\nimport bentoml\nimport torch\nfrom datasets import load_dataset\n\nt2s_processor_ref = bentoml.models.get(\"speecht5_tts_processor:latest\")\nt2s_model_ref = bentoml.models.get(\"speecht5_tts_model:latest\")\nt2s_vocoder_ref = bentoml.models.get(\"speecht5_tts_vocoder:latest\")\n\nclass Text2SpeechRunnable(bentoml.Runnable):\n    SUPPORTED_RESOURCES = (\"nvidia.com/gpu\", \"cpu\")\n    SUPPORTS_CPU_MULTI_THREADING = True\n\n    def __init__(self):\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.processor = bentoml.transformers.load_model(t2s_processor_ref)\n        self.model = bentoml.transformers.load_model(t2s_model_ref)\n        self.vocoder = bentoml.transformers.load_model(t2s_vocoder_ref)\n        self.embeddings_dataset = load_dataset(\n            \"Matthijs/cmu-arctic-xvectors\",\n            split=\"validation\",\n        )\n        self.speaker_embeddings = torch.tensor(\n            self.embeddings_dataset[7306][\"xvector\"]\n        ).unsqueeze(0)\n        self.model.to(self.device)\n        self.vocoder.to(self.device)\n\n    @bentoml.Runnable.method(batchable=False)\n    def generate_speech(self, inp: str):\n        inputs = self.processor(text=inp, return_tensors=\"pt\")\n        speech = self.model.generate_speech(\n            inputs[\"input_ids\"].to(self.device),\n            self.speaker_embeddings.to(self.device),\n            vocoder=self.vocoder,\n        )\n        return speech.cpu().numpy()\n```", "```py\nimport bentoml\nimport gradio as gr\nfrom chatbot import create_block, ChatWrapper\nfrom fastapi import FastAPI\nfrom speech2text_runner import s2t_processor_ref, s2t_model_ref, Speech2TextRunnable\nfrom text2speech_runner import (\n    t2s_processor_ref,\n    t2s_model_ref,\n    t2s_vocoder_ref,\n    Text2SpeechRunnable,\n)\n\nspeech2text_runner = bentoml.Runner(\n    Speech2TextRunnable,\n    name=\"speech2text_runner\",\n    models=[s2t_processor_ref, s2t_model_ref],\n)\ntext2speech_runner = bentoml.Runner(\n    Text2SpeechRunnable,\n    name=\"text2speech_runner\",\n    models=[t2s_processor_ref, t2s_model_ref, t2s_vocoder_ref],\n)\n```", "```py\nsvc = bentoml.Service(\n    \"voicegpt\",\n    runners=[\n        text2speech_runner,\n        speech2text_runner,\n    ],\n)\n```", "```py\n@svc.api(input=bentoml.io.NumpyNdarray(), output=bentoml.io.Text())\ndef generate_text(tensor):\n    text = speech2text_runner.transcribe_audio.run(tensor)\n    return text\n```", "```py\n @svc.api(input=bentoml.io.Text(), output=bentoml.io.NumpyNdarray())\ndef generate_speech(inp: str):\n    return text2speech_runner.generate_speech.run(inp)\n```", "```py\nchat = ChatWrapper(generate_speech, generate_text)\napp = FastAPI()\napp = gr.mount_gradio_app(app, create_block(chat), path=\"/chatbot\")\nsvc.mount_asgi_app(app, \"/\")\n```", "```py\nclass ChatWrapper:\n    def __init__(self, generate_speech, generate_text):\n        self.lock = Lock()\n        self.generate_speech = generate_speech\n        self.generate_text = generate_text\n        self.s2t_processor_ref = bentoml.models.get(\"whisper_processor:latest\")\n        self.processor = bentoml.transformers.load_model(self.s2t_processor_ref)\n\n    def __call__(\n        self,\n        api_key: str,\n        audio_path: str,\n        text_message: str,\n        history: Optional[Tuple[str, str]],\n        chain: Optional[ConversationChain],\n    ):\n        \"\"\"Execute the chat functionality.\"\"\"\n        self.lock.acquire()\n        try:\n            if audio_path is None and text_message is not None:\n                transcription = text_message\n            elif audio_path is not None and text_message in [None, \"\"]:\n                audio_dataset = Dataset.from_dict({\"audio\": [audio_path]}).cast_column(\n                    \"audio\",\n                    Audio(sampling_rate=16000),\n                )\n                sample = audio_dataset[0][\"audio\"]\n\n                if sample is not None:\n                    input_features = self.processor(\n                        sample[\"array\"],\n                        sampling_rate=sample[\"sampling_rate\"],\n                        return_tensors=\"pt\",\n                    ).input_features\n\n                    transcription = self.generate_text(input_features)\n                else:\n                    transcription = None\n                    speech = None\n\n            if transcription is not None:\n                history = history or []\n                # If chain is None, that is because no API key was provided.\n                if chain is None:\n                    response = \"Please paste your Open AI key.\"\n                    history.append((transcription, response))\n                    speech = (PLAYBACK_SAMPLE_RATE, self.generate_speech(response))\n                    return history, history, speech, None, None\n                # Set OpenAI key\n                import openai\n\n                openai.api_key = api_key\n                # Run chain and append input.\n                output = chain.run(input=transcription)\n                speech = (PLAYBACK_SAMPLE_RATE, self.generate_speech(output))\n                history.append((transcription, output))\n\n        except Exception as e:\n            raise e\n        finally:\n            self.lock.release()\n        return history, history, speech, None, None\n```", "```py\nchat = ChatWrapper(generate_speech, generate_text)\napp = FastAPI()\napp = gr.mount_gradio_app(app, create_block(chat), path=\"/chatbot\")\nsvc.mount_asgi_app(app, \"/\")\n```", "```py\nwith block:\n    with gr.Row():\n        gr.Markdown(\"<h3><center>BentoML LangChain Demo</center></h3>\")\n\n        openai_api_key_textbox = gr.Textbox(\n            placeholder=\"Paste your OpenAI API key (sk-...)\",\n            show_label=False,\n            lines=1,\n            type=\"password\",\n        )\n```", "```py\ndef set_openai_api_key(api_key: str):\n    if api_key:\n        os.environ[\"OPENAI_API_KEY\"] = api_key\n        chain = load_chain()\n        os.environ[\"OPENAI_API_KEY\"] = \"\"\n        return chain\n\nagent_state = gr.State()\n\nopenai_api_key_textbox.change(\n  set_openai_api_key,\n  inputs=[openai_api_key_textbox],\n  outputs=[agent_state],\n  show_progress=False,\n)\n```", "```py\naudio_message.change(\n    chat,\n    inputs=[\n        openai_api_key_textbox,\n        audio_message,\n        text_message,\n        state,\n        agent_state,\n    ],\n    outputs=[chatbot, state, audio, audio_message, text_message],\n    show_progress=False,\n)\n```", "```py\npoetry shell \nbentoml serve service:svc --reload --ssl-certfile ssl/cert.pem --ssl-keyfile ssl/key.pem\n```", "```py\nbentoml build\n```", "```py\nbentoml push voicegpt:jnalivxin2qcehqa\n```"]