- en: Finding Spelling Bee Pangrams with GPT-4 and SpaCy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用GPT-4和SpaCy查找拼字游戏全字母句
- en: 原文：[https://towardsdatascience.com/finding-spelling-bee-pangrams-with-gpt-4-and-spacy-64d042969954](https://towardsdatascience.com/finding-spelling-bee-pangrams-with-gpt-4-and-spacy-64d042969954)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/finding-spelling-bee-pangrams-with-gpt-4-and-spacy-64d042969954](https://towardsdatascience.com/finding-spelling-bee-pangrams-with-gpt-4-and-spacy-64d042969954)
- en: The quest to solve the New York Times puzzle
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决《纽约时报》拼图的探寻
- en: '[](https://reddotblues.medium.com/?source=post_page-----64d042969954--------------------------------)[![Sean
    Zhai](../Images/c10a04893c3baac3252dea0b9f140271.png)](https://reddotblues.medium.com/?source=post_page-----64d042969954--------------------------------)[](https://towardsdatascience.com/?source=post_page-----64d042969954--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----64d042969954--------------------------------)
    [Sean Zhai](https://reddotblues.medium.com/?source=post_page-----64d042969954--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://reddotblues.medium.com/?source=post_page-----64d042969954--------------------------------)[![Sean
    Zhai](../Images/c10a04893c3baac3252dea0b9f140271.png)](https://reddotblues.medium.com/?source=post_page-----64d042969954--------------------------------)[](https://towardsdatascience.com/?source=post_page-----64d042969954--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----64d042969954--------------------------------)
    [Sean Zhai](https://reddotblues.medium.com/?source=post_page-----64d042969954--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----64d042969954--------------------------------)
    ·7 min read·Mar 21, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----64d042969954--------------------------------)
    ·7分钟阅读·2023年3月21日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/d9f49cf95d3a6aee9a44964094d5d557.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9f49cf95d3a6aee9a44964094d5d557.png)'
- en: Photo by [Nemichandra Hombannavar](https://unsplash.com/@nemichandra?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[Nemichandra Hombannavar](https://unsplash.com/@nemichandra?utm_source=medium&utm_medium=referral)拍摄的照片，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)'
- en: Solving the New York Times Spelling Bee can be a rewarding experience that balances
    a challenge with the pleasure of word exploration. While it’s not always a walk
    in the park, the satisfaction gained from finding each word is well worth the
    effort. Among the various linguistic achievements in the puzzle, uncovering the
    **pangram** is like discovering a hidden treasure. This special word, which uses
    all the given letters, highlights the player’s skill in navigating the rich complexities
    of the English lexicon.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 解决《纽约时报拼字游戏》可以是一次令人满意的经历，它在挑战与词汇探索的乐趣之间取得平衡。虽然这并不总是轻而易举，但找到每个单词所获得的满足感是值得付出努力的。在拼图中的各种语言成就中，发现**全字母句**就像发现了一块隐藏的宝藏。这个特别的词汇使用了所有给定的字母，突显了玩家在驾驭英语词汇丰富复杂性的技能。
- en: Finding the pangram is an exhilarating activity for many people, and it also
    serves as a compelling case for natural language processing (NLP) exercises. SpaCy
    (Honnibal & Montani, 2017) is my favorite tool for such tasks. It is open-sourced
    under the MIT license. You can write a program for SpaCy manually, but I’d like
    to show you how to develop such a solution using GPT-4.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 发现全字母句对许多人来说是一项令人兴奋的活动，同时也为自然语言处理（NLP）练习提供了一个引人入胜的案例。SpaCy（Honnibal & Montani,
    2017）是我最喜欢的工具，它是根据MIT许可开源的。你可以手动为SpaCy编写程序，但我想向你展示如何使用GPT-4开发这样的解决方案。
- en: Background
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 背景
- en: Spelling Bee
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拼字游戏
- en: 'The New York Times Spelling Bee is a popular word puzzle game found in the
    New York Times newspaper and online on the New York Times website. In the game,
    players are given a set of seven letters, with one of the letters designated as
    the “center” letter. The objective of the game is to create as many words as possible
    using the given letters while adhering to the following rules:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 《纽约时报拼字游戏》是一个流行的单词拼图游戏，可以在《纽约时报》报纸和《纽约时报》网站上找到。在游戏中，玩家会得到一组七个字母，其中一个字母被指定为“中心”字母。游戏的目标是使用给定的字母尽可能多地创建单词，同时遵守以下规则：
- en: Each word must be at least four letters long.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个单词必须至少四个字母长。
- en: The “center” letter must appear in every word.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “中心”字母必须出现在每个单词中。
- en: Words must be in the English dictionary.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单词必须在英语词典中存在。
- en: Proper nouns and obscure or offensive words are not allowed.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不允许使用专有名词和晦涩或冒犯性的词汇。
- en: The game assigns a point value to each word based on its length. Players receive
    one point for a four-letter word, and the point value increases with each additional
    letter. A pangram is a word that uses all seven given letters at least once, and
    it awards bonus points.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 该游戏根据每个单词的长度分配点数。玩家获得一个四个字母单词的分数，每增加一个字母，分数会增加。全字母句是一个使用所有七个给定字母至少一次的单词，并且它会获得额外的分数。
- en: 'See How Human resolves the puzzle: William Jackson Harper Solves the NYT Spelling
    Bee | Source: YouTube.com'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 参见人类如何解决难题：威廉·杰克逊·哈珀解答NYT拼字游戏 | 来源：YouTube.com
- en: GPT-4
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPT-4
- en: GPT, or Generative Pre-trained Transformer, is a cutting-edge AI language model
    developed by OpenAI that leverages deep learning techniques to comprehend and
    generate human-like text. With its powerful transformer architecture and pre-training
    on vast amounts of textual data, GPT is capable of impressive performances across
    a wide range of natural language processing tasks, including text completion,
    translation, summarization, and more.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: GPT，即生成预训练变换器，是由OpenAI开发的前沿AI语言模型，利用深度学习技术来理解和生成类似人类的文本。凭借其强大的变换器架构和对大量文本数据的预训练，GPT能够在广泛的自然语言处理任务中表现出色，包括文本完成、翻译、摘要等。
- en: Spacy
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SpaCy
- en: SpaCy is a high-performance, open-source Python library designed for advanced
    natural language processing (NLP) tasks. Developed by Explosion AI, SpaCy offers
    efficient, production-ready tools for text processing, tokenization, part-of-speech
    tagging, named entity recognition, dependency parsing, and more. Built with a
    focus on speed and ease of use, SpaCy enables developers to quickly build custom
    NLP applications.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: SpaCy是一个高性能的开源Python库，旨在处理高级自然语言处理（NLP）任务。由Explosion AI开发，SpaCy提供了高效、生产就绪的文本处理、标记化、词性标注、命名实体识别、依存分析等工具。SpaCy以速度和易用性为重点，使开发者能够快速构建自定义的NLP应用程序。
- en: Develop a Program in Spacy with GPT-4
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用GPT-4开发SpaCy程序
- en: Get Ready
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Let’s get the toolchain ready to develop Spacy. You should have *Python* and
    *pip* installed, as SpaCy is a Python library.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们准备工具链来开发SpaCy。你应该已经安装了*Python*和*pip*，因为SpaCy是一个Python库。
- en: 'To write a program in SpaCy to find pangrams in the NYT Spelling Bee, we’ll
    need to get a list of words from a dictionary or a corpus. For this example, I’ll
    use the NLTK (Natural Language Toolkit) (Bird et al., 2009) library to get a list
    of words. Install NLTK if you haven’t already:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要在SpaCy中编写一个程序来查找NYT拼字游戏中的全字母句，我们需要从词典或语料库中获取单词列表。在这个例子中，我将使用NLTK（自然语言工具包）（Bird等人，2009）库来获取单词列表。如果你还没有安装NLTK，请先安装：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, download the ‘words’ corpus from NLTK:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，从NLTK下载‘words’语料库：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '*Note: NTLK’s words corpus is a list of words used in the English language.
    The words corpus in NLTK is sourced from the “Words” dataset, which was originally
    derived from the Unix “Words” file. This file is a list of English words that
    were commonly used in Unix systems for various purposes, such as spell-checking
    and generating random text. The Unix words file is not an exhaustive list of English
    words, and it may contain some archaic or uncommon words. It also lacks proper
    nouns and may not include more recent additions to the English language. Nonetheless,
    it provides a useful starting point for various NLP tasks, such as word segmentation,
    tokenization, and spelling correction.*'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：NTLK的单词语料库是一个使用于英语的单词列表。NLTK中的单词语料库来源于“Words”数据集，该数据集最初来源于Unix的“Words”文件。该文件是一个包含在Unix系统中用于各种目的（例如拼写检查和生成随机文本）常用的英语单词列表。Unix单词文件并非英语单词的详尽列表，可能包含一些古老或不常见的单词。它也缺乏专有名词，并可能不包括英语语言中较新的词汇。然而，它为各种自然语言处理任务，如单词分割、标记化和拼写校正，提供了一个有用的起点。*'
- en: First Attempt
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初次尝试
- en: Let’s make a straightforward request to GPT-4.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们向GPT-4提出一个简单的请求。
- en: Can you write a program in SpaCy to find pangrams in the New York Times’s Spelling
    Bee?
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你能在SpaCy中编写一个程序来查找《纽约时报》拼字游戏中的全字母句吗？
- en: The answer provided by GPT-4 looks promising. It includes the steps to set up
    SpaCy and the following Python program.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4提供的答案看起来很有希望。它包括设置SpaCy的步骤和以下Python程序。
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This is the output.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果。
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Taking a closer look, we find that it includes letters that are not on the given
    letters list.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 经过仔细观察，我们发现它包括一些不在给定字母列表中的字母。
- en: Second Attempt
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第二次尝试
- en: With our observation, we can ask GPT to improve.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 通过我们的观察，我们可以要求GPT进行改进。
- en: The program does not work properly. It gives words containing the “given_letters”,
    but what we need is words ONLY contain the given_letters. It cannot have any other
    letters.
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 程序无法正常工作。它返回了包含“given_letters”的单词，但我们需要的是仅包含 given_letters 的单词。它不能有其他字母。
- en: GPT-4 rewrites the program.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4 重写了程序。
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The output is three words this time. The word that NYTimes Spelling Bee looks
    for is ‘daytime’.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这次的输出是三个单词。NYTimes 拼字比赛中要找的单词是“daytime”。
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Can we call this a win?
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以称之为胜利吗？
- en: '![](../Images/61e20f6a8c91ea0db64eff91993d05ab.png)![](../Images/6d814f576eea354ef6ef8f222e665d9d.png)![](../Images/5b0792bf2e9d403647d7c55ad20a2ae6.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61e20f6a8c91ea0db64eff91993d05ab.png)![](../Images/6d814f576eea354ef6ef8f222e665d9d.png)![](../Images/5b0792bf2e9d403647d7c55ad20a2ae6.png)'
- en: 'Screenshots of NYTimes Spelling Bee: 1) May 16\. 2023 2) May 17, 2023 3) May
    18, 2023 | Screen capture by Sean Zhai'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: NYTimes 拼字比赛的截图：1) 2023年5月16日 2) 2023年5月17日 3) 2023年5月18日 | 截图由 Sean Zhai 提供
- en: An Exception and the Solution
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异常与解决方案
- en: 'The Spelling Bee of May 17, 2023, has the following given letters: **C** D
    E N L O W, but our program returned an empty output. It cannot find a pangram.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 2023年5月17日的拼字比赛有以下给定字母：**C** D E N L O W，但我们的程序返回了一个空输出。它无法找到一个全字句。
- en: This is when we need to help GPT-4\. I tried to ask GPT-4 to analyze the mistake,
    but it did not work well, so I stepped in. The algorithm looked correct, and my
    next inspection was the NLTK corpus. I ran a quick search in Python for the pangram
    of that day — clowned, and it was not in. So we found the problem.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这时我们需要帮助 GPT-4。我尝试让 GPT-4 分析错误，但效果不好，于是我介入了。算法看起来是正确的，我接下来的检查是 NLTK 语料库。我在 Python
    中对当天的全字句——clowned 进行了快速搜索，但没有找到。所以我们找到了问题。
- en: I stated the issue and asked GPT-4 for a new solution.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我陈述了问题，并要求 GPT-4 提供新解决方案。
- en: In the Python program for finding pangrams, the ‘words’ in nltk.corpus did not
    cover all the words the NYTimes use. For instance, ‘clowned’ is not included.
    Is there a better place to retrieve the ‘words’?
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在用于查找全字句的 Python 程序中，nltk.corpus 中的“words”没有涵盖 NYTimes 使用的所有单词。例如，“clowned”
    就没有包括在内。有没有更好的地方可以获取“words”？
- en: GPT-4 acknowledged the issue and provided a new source for English words, along
    with the updated Python program.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4 认识到问题，并提供了新的英语单词来源及更新后的 Python 程序。
- en: 'A more comprehensive source for English words is the `words.txt` file, which
    is derived from the SCOWL (Spell Checker Oriented Word Lists) project. You can
    find it in the GitHub repository here: [https://github.com/dwyl/english-words](https://github.com/dwyl/english-words)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更全面的英语单词来源是 `words.txt` 文件，它来源于 SCOWL（拼写检查器导向单词列表）项目。你可以在 GitHub 仓库中找到它： [https://github.com/dwyl/english-words](https://github.com/dwyl/english-words)
- en: '[PRE6]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Save the new program as *pangram.py*. Now the result is as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 将新程序保存为 *pangram.py*。现在结果如下：
- en: '[PRE7]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: It is satisfactory!
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 满意！
- en: Discussion
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 讨论
- en: Putting GPT-4 to a practical task is a fun way to test the capacity of the program.
    It certainly is impressive and will change the way we work. Here are a couple
    of things that might help when giving prompts to GPT-4.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 将 GPT-4 应用于实际任务是测试程序能力的有趣方式。它确实令人印象深刻，并将改变我们的工作方式。以下是一些可能在给 GPT-4 提示时有所帮助的事项。
- en: Be specific. Define a proper scope for your questions.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具体明确。为你的问题定义一个合适的范围。
- en: Give examples to illustrate your statement.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给出例子以说明你的陈述。
- en: Work with GPT-4, and always validate the outputs.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与 GPT-4 合作，并始终验证输出结果。
- en: Use your own mind to analyze complicated situations.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运用自己的思维分析复杂情况。
- en: References
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Honnibal, M., & Montani, I. (2017). *spaCy 2: Natural language understanding
    with Bloom embeddings, convolutional neural networks and incremental parsing*.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 'Honnibal, M., & Montani, I. (2017). *spaCy 2: 使用 Bloom 嵌入、卷积神经网络和增量解析进行自然语言理解*。'
- en: 'Bird, S., Klein, E., & Loper, E. (2009). *Natural language processing with
    Python: analyzing text with the natural language toolkit*. O’Reilly Media, Inc.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Bird, S., Klein, E., & Loper, E. (2009). *使用 Python 进行自然语言处理：用自然语言工具包分析文本*。O’Reilly
    Media, Inc.
