- en: Are Prompts Generated by Large Language Models (LLMs) Reliable?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）生成的提示可靠吗？
- en: 原文：[https://towardsdatascience.com/are-prompt-generated-by-large-language-models-llms-reliable-4162fd10c845](https://towardsdatascience.com/are-prompt-generated-by-large-language-models-llms-reliable-4162fd10c845)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/are-prompt-generated-by-large-language-models-llms-reliable-4162fd10c845](https://towardsdatascience.com/are-prompt-generated-by-large-language-models-llms-reliable-4162fd10c845)
- en: Unleashing the Power of LLMs with Auto-Generated Prompts
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 释放大型语言模型（LLMs）与自动生成提示的力量
- en: '[](https://medium.com/@a0987284901?source=post_page-----4162fd10c845--------------------------------)[![Henry
    Lai](../Images/eaa1b4eb6f6cebc131f4cf0cfdd4cda7.png)](https://medium.com/@a0987284901?source=post_page-----4162fd10c845--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4162fd10c845--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4162fd10c845--------------------------------)
    [Henry Lai](https://medium.com/@a0987284901?source=post_page-----4162fd10c845--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@a0987284901?source=post_page-----4162fd10c845--------------------------------)[![Henry
    Lai](../Images/eaa1b4eb6f6cebc131f4cf0cfdd4cda7.png)](https://medium.com/@a0987284901?source=post_page-----4162fd10c845--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4162fd10c845--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4162fd10c845--------------------------------)
    [Henry Lai](https://medium.com/@a0987284901?source=post_page-----4162fd10c845--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4162fd10c845--------------------------------)
    ·6 min read·Apr 14, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4162fd10c845--------------------------------)
    ·6 分钟阅读·2023年4月14日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/427afef3b6084a0384d5114014f7246c.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/427afef3b6084a0384d5114014f7246c.png)'
- en: Figure 1\. An example of performance variability of two different ChatGPT-generated
    prompts
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1\. 两个不同的 ChatGPT 生成提示的性能变异示例
- en: The rapid development of large language models (LLMs), including [ChatGPT](https://openai.com/blog/chatgpt)
    and [GPT-4](https://cdn.openai.com/papers/gpt-4.pdf), has revolutionized data
    science. In the past, data scientists typically devoted a substantial amount of
    time to preparing data, designing models, and fine-tuning them to solve various
    problems. Nowadays, with the advent of LLMs, we can accomplish many tasks in a
    pure data-centric manner without spending any effort on modeling (see the [data-centric
    AI framework](https://github.com/daochenzha/data-centric-AI)).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的快速发展，包括 [ChatGPT](https://openai.com/blog/chatgpt) 和 [GPT-4](https://cdn.openai.com/papers/gpt-4.pdf)，已经彻底改变了数据科学。过去，数据科学家通常需要花费大量时间来准备数据、设计模型并进行调整以解决各种问题。而现在，随着
    LLMs 的出现，我们可以在纯数据驱动的方式下完成许多任务，而无需花费任何建模工作（参见 [数据驱动 AI 框架](https://github.com/daochenzha/data-centric-AI)）。
- en: One key idea drives the advancement is prompting, which refers to use of specific
    input text or questions to guide a language model in generating a desired output.
    For instance, when summarizing a lengthy article, we can provide the LLM with
    a prompt, such as “*Summarize the above in one sentence*”, and input the article
    text. This enables the LLM to generate a concise summary of the article, making
    it easier for researchers to extract relevant information quickly. The use of
    prompts has opened up new opportunities in data science, enabling scientists to
    streamline their workflows and increase their productivity.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 推进的一个关键理念是提示，它指的是使用特定的输入文本或问题来引导语言模型生成所需的输出。例如，在总结一篇长文章时，我们可以向 LLM 提供一个提示，比如“*用一句话总结以上内容*”，并输入文章文本。这使得
    LLM 能够生成文章的简洁总结，帮助研究人员快速提取相关信息。提示的使用开辟了数据科学的新机会，使科学家能够简化工作流程，提高生产力。
- en: Creating effective prompts remains a significant challenge, as even prompts
    that seem similar can produce vastly different outputs. For example, using “*Write
    a brief summary*” or “*Provide a concise summary*” may lead to substantially different
    summaries, as illustrated in Figure 1\. This variation in output can make it difficult
    for data scientists to determine which prompt to use to achieve the desired results.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 创建有效的提示仍然是一个重大挑战，因为即使是看似相似的提示也可能产生截然不同的输出。例如，使用“*写一个简要总结*”或“*提供一个简洁的总结*”可能会导致大相径庭的总结，如图
    1 所示。这种输出的变异可能使数据科学家难以确定使用哪个提示来实现预期的结果。
- en: To address the challenge of creating effective prompts, automated prompting
    can be a viable solution that utilizes LLMs to generate prompt templates directly.
    For instance, when summarizing clinical notes, one can ask an LLM for prompt suggestions
    by posing the question “*What would be an effective prompt for summarizing clinical
    notes?*” The model can then generate a variety of prompt candidates tailored to
    this specific task, potentially accelerating the process of effective prompt creation.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对创建有效提示的挑战，自动提示可以是一个可行的解决方案，它利用LLM直接生成提示模板。例如，在总结临床笔记时，可以通过提问“*什么是总结临床笔记的有效提示？*”来请求LLM提供提示建议。模型随后可以生成各种针对特定任务的提示候选，从而可能加速有效提示创建的过程。
- en: LLM-generated prompts are usually unpredictable in terms of their quality, resulting
    in outputs that exhibit significant variability. This, in turn, necessitates a
    significant amount of manual effort to examine each candidate prompt individually.
    In this article, we will introduce a framework named SPeC, to make the LLM-generated
    prompts more effective and reliable. SPeC exploits soft prompt tokens to calibrate
    performance variability while preserving performance gain brought by LLM-generated
    prompts, resulting in notably more consistent outputs.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 由LLM生成的提示通常在质量上具有不可预测性，导致输出结果表现出显著的变异性。这反过来又需要大量的手动工作来逐一检查每个候选提示。在本文中，我们将介绍一个名为SPeC的框架，以提高LLM生成的提示的有效性和可靠性。SPeC利用软提示令牌来校准性能变异性，同时保留LLM生成提示带来的性能提升，从而实现明显更一致的输出。
- en: Prompt Tuning in LLMs
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM中的提示调整
- en: '![](../Images/575d106a8983d3c576717cf33486b575.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/575d106a8983d3c576717cf33486b575.png)'
- en: Figure2\. Prompt Tuning. Image from the paper [https://arxiv.org/abs/2303.10158](https://arxiv.org/pdf/2303.10158.pdf)
    with original authors’ permission.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图2\. 提示调整。图像来自于[https://arxiv.org/abs/2303.10158](https://arxiv.org/pdf/2303.10158.pdf)的论文，经过原作者许可。
- en: Prompt tuning is a revolution to data science following the concpet of [data-centric
    AI](https://arxiv.org/abs/2303.10158). In addition to collecting more training
    data, prompt tuning is an alternative approach to improve the performance of LLMs
    without any further fine-tuning. Notably, effective prompts are a critical factor
    in the success of prompt tuning, as the specific input words can trigger the corresponding
    information learned by LLMs, resulting in a significant improvement in LLMs’ adaptation
    and performance on specific downstream tasks. Data scientists and researchers
    can benefit greatly from this approach as it enables them to efficiently and effectively
    utilize LLMs in various downstream tasks. It has also been advocated by [Jeff
    Dean](https://twitter.com/JeffDean), a leading director of Google Research.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 提示调整是继[数据驱动AI](https://arxiv.org/abs/2303.10158)概念之后对数据科学的一次革命。除了收集更多的训练数据，提示调整是一种提高LLM性能的替代方法，无需进一步的微调。值得注意的是，有效的提示是提示调整成功的关键因素，因为特定的输入词语可以激发LLM所学到的相应信息，从而显著提高LLM在特定下游任务中的适应性和性能。数据科学家和研究人员可以从这一方法中受益匪浅，因为它使他们能够高效且有效地利用LLM在各种下游任务中。谷歌研究的首席主管[杰夫·迪恩](https://twitter.com/JeffDean)也提倡这一方法。
- en: How to Automatically Generate Prompts?
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何自动生成提示？
- en: Designing an effective prompt is never a trivial task, as tremendous domain-specific
    expertise is still required to extract certain keywords and sentences to form
    the prompts. The advent of powerful LLMs has made it possible for users to increase
    their productivity in designated tasks by taking advantage of prompts that are
    automatically generated. When users input a question into an LLM, it can generate
    corresponding prompt templates. For instance, a data scientist could ask ChatGPT
    for guidance on a good prompt for text summarization, and then utilize the resulting
    feedback to summarize text. This approach can significantly streamline workflows,
    saving users considerable time and effort.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 设计一个有效的提示从来不是一件简单的事，因为仍然需要大量领域特定的专业知识来提取某些关键词和句子以形成提示。强大的LLM的出现使用户可以通过利用自动生成的提示来提高他们在指定任务中的生产力。当用户向LLM输入问题时，它可以生成相应的提示模板。例如，数据科学家可以向ChatGPT询问有关文本摘要的好提示，然后利用得到的反馈来进行文本摘要。这种方法可以显著简化工作流程，为用户节省大量时间和精力。
- en: Are Automatically Generated Prompts Reliable?
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动生成的提示可靠吗？
- en: However, the quality of prompts generated by LLMs can be highly unpredictable,
    which in turn leads to a significant increase in the performance variance of LLMs.
    Even when prompts are semantically similar, they can produce vastly different
    outputs. For instance, as demonstrated in Figure 1, prompt-2 and prompt-1, generated
    from a frozen LLM and highly similar to each other, resulted in entirely different
    summarization. This issue is particularly problematic in high-stakes domains,
    such as the financial and healthcare industries, where the variance in generated
    prompts can erode trust in LLMs’ results among researchers and engineers. Therefore,
    it is critical to find ways to control the quality of prompts generated by LLMs
    to ensure the reliability of their outputs, especially in such domains.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，LLM生成的提示质量可能高度不可预测，这反过来会导致LLM性能方差的显著增加。即使提示在语义上相似，它们也可能产生截然不同的输出。例如，如图 1
    所示，从冻结的LLM生成的提示-2和提示-1虽然高度相似，但产生了完全不同的总结。这一问题在高风险领域尤其成问题，如金融和医疗行业，其中生成提示的方差可能会削弱研究人员和工程师对LLM结果的信任。因此，关键是找到控制LLM生成的提示质量的方法，以确保其输出的可靠性，特别是在这些领域。
- en: '**Can We Trust the Results from the Generated Prompts?**'
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**我们可以信任生成提示的结果吗？**'
- en: In reality, the answer is a clear negative. The uncertainty that frequently
    arises in LLMs is a significant issue for scientists who need to trust the output
    produced by these models. If significant uncertainty also occurs in LLM-generated
    prompts, it can considerably erode scientists’ confidence in the results. Therefore,
    it is essential to have a mechanism in place that reduces the output variance
    caused by the quality of these auto-generated prompts in order to ensure that
    LLMs work more reliably.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，答案是否定的。LLM中经常出现的不确定性对需要信任这些模型生成结果的科学家来说是一个重大问题。如果LLM生成的提示也出现显著的不确定性，它可能会严重削弱科学家对结果的信心。因此，必须有一种机制来减少由这些自动生成的提示质量引起的输出方差，以确保LLM能够更可靠地工作。
- en: A Soft Prompt-Based Calibration on LLMs
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于软提示的LLM校准
- en: '![](../Images/6ee6b7e43baff9b8fee655ba654deed3.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6ee6b7e43baff9b8fee655ba654deed3.png)'
- en: Figure 3\. An overview of soft prompt-based calibration (SPeC) framework. Image
    from the paper [https://arxiv.org/abs/2303.10158](https://medium.com/r?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2303.13035v2.pdf)
    with original authors’ permission.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3\. 基于软提示的校准（SPeC）框架概述。图像来源于论文 [https://arxiv.org/abs/2303.10158](https://medium.com/r?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2303.13035v2.pdf)
    经原作者许可。
- en: '[*Full Paper Link*](https://arxiv.org/pdf/2303.13035v2.pdf)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[*完整论文链接*](https://arxiv.org/pdf/2303.13035v2.pdf)'
- en: Motivated by prompt tuning from [*data-centric AI*](https://arxiv.org/abs/2303.10158)
    concepts, a framework *Soft Prompt-Based Calibration (SPeC)*, as depicted in *Figure
    3,* discusses the techniques to reduce the outcome variance of different prompts.
    SpeC framework exploits soft prompt tokens to calibrate performance variability
    while preserving performance gain brought by LLM-generated prompts. The soft prompt
    tokens can be any sentence that is semantically related to the input text. For
    example, “radiologist describes the stable abnormality in the exam” can be good
    soft prompt tokens for clinical note summarization. This way, given a well-trained
    soft prompt encoder, by adding soft prompt tokens with the input text, we will
    be able to achieve stable inference outcomes of LLMs. For instance, medical doctors
    can easily provide the appropriate soft prompt tokens by using relevant keywords
    or terms to get desired outcomes with consistency.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 受[*数据驱动的人工智能*](https://arxiv.org/abs/2303.10158)概念的启发，一个框架*基于软提示的校准（SPeC）*，如*图
    3*所示，讨论了减少不同提示结果方差的技术。SpeC框架利用软提示令牌来校准性能的变异，同时保持由LLM生成的提示带来的性能提升。软提示令牌可以是与输入文本语义相关的任何句子。例如，“放射科医师描述检查中的稳定异常”可以作为临床笔记总结的良好软提示令牌。通过这种方式，给定一个经过良好训练的软提示编码器，通过将软提示令牌与输入文本一起添加，我们将能够实现LLM的稳定推断结果。例如，医学医生可以通过使用相关的关键词或术语轻松提供适当的软提示令牌，以获得一致的期望结果。
- en: Experimental Analytics on Clinical Note Summarization
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 临床笔记总结的实验分析
- en: SPeC framework is evaluated on an important healthcare task, the clinical note
    summarization for medical doctors. In this work, the LLM-generated prompts are
    collected by the asking the question, “What is a good prompt for clinical note
    summarization?”, to ChatGPT.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: SPeC 框架在一个重要的医疗任务——医生的临床笔记总结中进行了评估。在这项工作中，LLM 生成的提示是通过向 ChatGPT 提问“什么是一个好的临床笔记总结提示？”来收集的。
- en: SPeC effectively guides pre-trained LLMs that have been frozen in place to perform
    with less variability in clinical note summarization. This ensures that the LLMs
    can maintain the performance improvements gained from using prompts generated
    by ChatGPT, while also reducing variability in performance to make sure the resulting
    clinical summaries are more accurate and faithful to the original data.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: SPeC 有效指导了那些已被冻结的预训练 LLMs，以在临床笔记总结中减少变异性。这确保了 LLMs 能够保持使用 ChatGPT 生成的提示所带来的性能改进，同时减少性能的变异性，以确保最终的临床总结更加准确，并忠实于原始数据。
- en: The effectiveness of SPeC in maintaining consistent summarization performance
    in frozen pre-trained LLMs was demonstrated in their case study, which highlighted
    the potential for incorrect outcomes (highlighted in red) if SPeC was not used.
    The study’s results are displayed in *Figure 4.*
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: SPeC 在保持冻结的预训练 LLMs 一致总结性能方面的有效性在其案例研究中得到了证明，该研究强调了如果不使用 SPeC 可能导致的错误结果（以红色标出）。研究结果显示在*图
    4*中。
- en: '![](../Images/5231136ab7a273b33deef678d0a42677.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5231136ab7a273b33deef678d0a42677.png)'
- en: Figure 4\. Performance variability comparison of Flan-T5 w/ and w/o exploiting
    SPeC.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4\. Flan-T5 使用和不使用 SPeC 的性能变异性比较。
- en: How Can SPeC Framework Be Used in Daily Workflow?
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SPeC 框架如何在日常工作流程中使用？
- en: In the era of [data-centric AI](https://arxiv.org/abs/2303.10158), LLMs have
    the potential to revolutionize data science by providing fast and accurate analysis
    with prompt tuning techniques, leading to more efficient and effective workflow.
    However, several concerns about the uncertainty of LLMs’ outputs have been raised,
    especially in situations where critical and emergent decisions are needed to make.
    It is important to address these concerns to ensure that LLMs can be effectively
    integrated into AI systems.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在[数据中心化人工智能](https://arxiv.org/abs/2303.10158)的时代，LLMs 具有通过提供快速和准确的分析以及使用提示调优技术来彻底改变数据科学的潜力，从而实现更高效和有效的工作流程。然而，关于
    LLMs 输出的不确定性已引发了一些担忧，特别是在需要做出关键和紧急决策的情况下。重要的是要解决这些担忧，以确保 LLMs 可以有效地融入人工智能系统中。
- en: SPeC framework has effectively mitigated the uncertainty concerns raised by
    scientists while using LLMs, increasing their willingness to trust the decisions
    made by LLMs. For example, for biomedical data scientists, the success of the
    SPeC framework in providing dependable and consistent medical information summaries
    has the potential to empower healthcare practitioners to make informed decisions
    for optimal patient care.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: SPeC 框架有效减轻了科学家在使用 LLMs 时提出的不确定性担忧，提高了他们对 LLMs 做出决策的信任度。例如，对于生物医学数据科学家来说，SPeC
    框架在提供可靠和一致的医疗信息总结方面的成功，具有使医疗从业人员能够为优化患者护理做出明智决策的潜力。
- en: Resource
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源
- en: 'You can learn more about how SPeC helps in the healthcare industry and increase
    the willingness of healthcare experts to trust the decisions made by LLMs in the
    following papers:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过以下论文了解更多关于 SPeC 如何在医疗保健行业提供帮助，并提高医疗专家对 LLMs 做出决策的信任度：
- en: '[1] [SPeC: A Soft Prompt-Based Calibration on Mitigating Performance Variability
    in Clinical Notes Summarization](https://arxiv.org/abs/2303.13035)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] [SPeC：基于软提示的校准以减轻临床笔记总结中的性能变异性](https://arxiv.org/abs/2303.13035)'
- en: '[2] [Data-centric Artificial Intelligence: A Survey](https://arxiv.org/abs/2303.10158)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] [数据中心化人工智能：综述](https://arxiv.org/abs/2303.10158)'
- en: '[3] [Awesome Data-centric AI](https://github.com/daochenzha/data-centric-AI)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] [优秀的数据中心化人工智能](https://github.com/daochenzha/data-centric-AI)'
- en: If you are interested in how to apply SPeC on different downstream tasks. Some
    more instructions can be found in the [Github Repository](https://github.com/ynchuang/SPeC-A-Soft-Prompt-Based-Calibration).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对如何在不同的下游任务中应用 SPeC 感兴趣，可以在[Github 仓库](https://github.com/ynchuang/SPeC-A-Soft-Prompt-Based-Calibration)中找到更多说明。
