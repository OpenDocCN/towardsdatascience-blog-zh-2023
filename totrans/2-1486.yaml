- en: 'Mastering Linear Regression: The Definitive Guide For Aspiring Data Scientists'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/mastering-linear-regression-the-definitive-guide-for-aspiring-data-scientists-7abd37fcb9ed](https://towardsdatascience.com/mastering-linear-regression-the-definitive-guide-for-aspiring-data-scientists-7abd37fcb9ed)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: All you need to know about Linear Regression is here (including an application
    in Python)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://federicotrotta.medium.com/?source=post_page-----7abd37fcb9ed--------------------------------)[![Federico
    Trotta](../Images/e997e3a96940c16ab5071629016d82fd.png)](https://federicotrotta.medium.com/?source=post_page-----7abd37fcb9ed--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7abd37fcb9ed--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7abd37fcb9ed--------------------------------)
    [Federico Trotta](https://federicotrotta.medium.com/?source=post_page-----7abd37fcb9ed--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7abd37fcb9ed--------------------------------)
    ·22 min read·Apr 17, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b598c04052b566c5fdd8e24dde8376ae.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [Dariusz Sankowski](https://pixabay.com/it/users/dariuszsankowski-1441456/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1052010)
    on [Pixabay](https://pixabay.com/it//?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1052010)
  prefs: []
  type: TYPE_NORMAL
- en: 'If you’re approaching Machine Learning, one of the first models you may encounter
    is Linear Regression. It’s probably the easiest model to understand, but don’t
    underestimate it: there are a lot of things to understand and master.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you’re a beginner in Data Science or an aspiring Data Scientist, you’re
    probably facing some difficulties because there are a lot of resources out there,
    but are fragmented. I know how you’re feeling, and this is why I created this
    complete guide: I want to give you all the knowledge you need without searching
    for anything else.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, if you want to have complete knowledge of Linear Regression this article
    is for you. You can study it deeply and re-read it whenever you need it the most.
    Also, consider that, to cover this topic, we’ll need some knowledge generally
    associated with regression analysis: we’ll cover it in deep.'
  prefs: []
  type: TYPE_NORMAL
- en: 'And…you’ll excuse me if I’ll link a resource you’ll need: in the past, I’ve
    created an article on some topics related to Linear Regression so, to have a complete
    overview, I advise you to read it (I’ll link later when we’ll need it).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: What do we mean by “regression analysis”?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here we’re studying Linear Regression, but what do we mean by “regression analysis”?
    Paraphrasing from [Wikipedia](https://en.wikipedia.org/wiki/Regression_analysis):'
  prefs: []
  type: TYPE_NORMAL
- en: Regression analysis is a mathematical technique used to find a functional relationship
    between a dependent variable and one or more independent variable(s).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In other words, we know that in mathematics we can define a function like so:
    `y=f(x)`. Generally, `y` is called the dependent variable and `x` the independent.
    So, we express `y` in relationship with `x`, using a certain function `f`. The
    aim of regression analysis is, then, to find the function `f` .'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, this seems easy but is not. And I know you know it. And the reason why
    is not easy is:'
  prefs: []
  type: TYPE_NORMAL
- en: We know `x` and `y`. For example, if we are working with tabular data (with
    `Pandas`, for example) `x` are the features and `y` is the label.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unfortunately, the data rarely follow a very clear path. So our job is to find
    the best function `f` that **approximates** the relationship between `x` and `y`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, let me summarize it: regression analysis aims to find an estimated relationship
    (a good one!) between the dependent and the independent variable(s).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s visualize why this process may be difficult. Consider the following
    code and its outcome:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/e7523fbaeb05463f87a72782fc26991a.png)'
  prefs: []
  type: TYPE_IMG
- en: The outcome of the above code. Image by Federico Trotta.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, tell me: can the relationship between `x` and `y` be a line? So…can this
    data be approximated by a line? Like the following, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3312a31b1b2ed1a1c24b92fd752f6dd7.png)'
  prefs: []
  type: TYPE_IMG
- en: A line approximating the given data. Image by Federico Trotta.
  prefs: []
  type: TYPE_NORMAL
- en: Stop reading for a moment and think about that.
  prefs: []
  type: TYPE_NORMAL
- en: Well, it could. And how about the following one?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/160bc73c7ab57263d2b439e3498149ac.png)'
  prefs: []
  type: TYPE_IMG
- en: A curve approximating the given data. Image by Federico Trotta.
  prefs: []
  type: TYPE_NORMAL
- en: Well, even this could! So, what’s the best one? And why not another one?
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the aim of regression: to find the best-estimated function that can
    approximate the given data. And it does so using some methodologies: we’ll cover
    them later in this article. We’ll apply them to the Linear Regression model but
    some of them can be used with any other regression technique. Don’t worry: I’ll
    be very specific so you don’t get confused.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding correlation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Quoting from [Wikipedia](https://en.wikipedia.org/wiki/Correlation):'
  prefs: []
  type: TYPE_NORMAL
- en: In statistics, correlation is any statistical relationship, whether causal or
    not, between two random variables. Although in the broadest sense, “correlation”
    may indicate any type of association, in statistics it usually refers to the degree
    to which a pair of variables are linearly related.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In other words, **correlation** is a statistical measure that expresses the
    **linear relationship between variables**.
  prefs: []
  type: TYPE_NORMAL
- en: We can say that two variables are correlated if each value of the first variable
    corresponds to a value for the second variable, following a path. If two variables
    are highly correlated, the path would be linear, because the correlation describes
    the linear relation between the variables.
  prefs: []
  type: TYPE_NORMAL
- en: The math behind the correlation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is a comprehensive guide, as promised. So, I want to cover the math behind
    the correlation, but don’t worry: we’ll make it easy so that you can understand
    it even if you’re not specialized in math.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We generally refer to the correlation coefficient, also known as the **Pearson
    correlation coefficient**. This gives an estimate of the correlation between two
    variables. Suppose we have two variables, `a` and `b` and they can reach `n` values.
    We can calculate the correlation coefficient as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The definition of the Pearson coefficient, powered by embed-dot-fun by the Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Where we have:'
  prefs: []
  type: TYPE_NORMAL
- en: 'the mean value of `a`(but it applies to both variables, `a` and `b`):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The definition of the mean value, powered by embed-dot-fun by the Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'the standard deviation:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The definitions of the standard deviation and the variance, powered by embed-dot-fun
    by the Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, putting it all together:'
  prefs: []
  type: TYPE_NORMAL
- en: The definition of the Pearson coefficient, powered by embed-dot-fun by the Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you may know:'
  prefs: []
  type: TYPE_NORMAL
- en: 'the **mean** is the sum of all the values of a variable divided by the number
    of values. So, for example, if our variable `a` has the values 1,3,7,13,25 the
    mean value of `a` will be:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The calculation of the mean for 5 values, powered by embed-dot-fun by the Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'the **standard deviation** is an index of statistical dispersion and is an
    estimate of the variability of a variable (or of a population, as we would say
    in statistics). It is one of the ways to express the dispersion of data around
    an index; in the case of the correlation coefficient, the index around which we
    calculate the dispersion is the mean (see the above formula). The more the standard
    deviation is high, the more the dispersion around the mean is high: the majority
    of the data points are distant from the mean value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Numerically speaking, we have to remember that the value of the correlation
    coefficient is constrained between 1 and -1; this means that:'
  prefs: []
  type: TYPE_NORMAL
- en: 'if *r=1*: the variables are highly positively correlated; it means that if
    one variable increases its value, the other does the same, following a linear
    path.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'if *r=-1*: the variables are highly negatively correlated; it means that if
    one variable increases its value, the other one decreases its value, following
    a linear path.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: if *r=0***:** there is no correlation between the variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, two variables are generally considered highly correlated if `r>0.75`.
  prefs: []
  type: TYPE_NORMAL
- en: Correlation is not causation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We need to have very clear in our mind the fact that “**correlation is not causation**”;
    we want to make an example that might be useful to remember it.
  prefs: []
  type: TYPE_NORMAL
- en: It is a hot summer; we don’t like the high temperatures in our city, so we go
    to the mountain. Luckily, we get to the mountain top, measure the temperature
    and find it’s lower than in our city. We get a little suspicious, and we decide
    to go to a higher mountain, finding that the temperature is even lower than the
    one on the previous mountain.
  prefs: []
  type: TYPE_NORMAL
- en: We try mountains with different heights, measure the temperature, and plot a
    graph; we find that with the height of the mountain increasing, the temperature
    decreases, and we can see a linear trend.
  prefs: []
  type: TYPE_NORMAL
- en: 'What does it mean? It means that the temperature is related to the height of
    the mountains, with a linear path: so there is a correlation between the decrease
    in temperature and the height (of the mountains). It doesn’t mean the height of
    the mountain caused the decrease in temperature; in fact, if we get to the same
    height, at the same latitude, with a hot air balloon we’d measure the same temperature.'
  prefs: []
  type: TYPE_NORMAL
- en: The correlation matrix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So, how do we calculate the correlation coefficient in Python? Well, we generally
    calculate the correlation matrix. Suppose we have two variables, `X` and `y`*;*
    we store them in a data frame called `df` and we can plot the correlation matrix
    using `seaborn` like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/d9de081f5fcecd12d8c8208d89cf6f7b.png)'
  prefs: []
  type: TYPE_IMG
- en: The correlation matrix for the above code. Image by Federico Trotta.
  prefs: []
  type: TYPE_NORMAL
- en: The difference between correlation and regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If we have a 0 correlation coefficient, it means that the data points do not
    tend to increase or decrease following a linear path, because we have no correlation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us have a look at some plots of correlation coefficients with different
    values (image from [Wikipedia here](https://en.wikipedia.org/wiki/Correlation)):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d61dc2370373f100b723c36b49340eb2.png)'
  prefs: []
  type: TYPE_IMG
- en: Data distribution with different correlation values. Image rights for distribution
    [here](https://commons.wikimedia.org/wiki/File:Correlation_examples2.svg).
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, when the correlation coefficient is equal to 1 or -1 the tendency
    of the data points is clearly to be along a line. But, as the correlation coefficient
    deviates from the two extreme values, the distribution of the data points deviates
    from a linear path. Finally, for the correlation coefficient of 0, the distribution
    of the data can be anything.
  prefs: []
  type: TYPE_NORMAL
- en: So, when we get a correlation coefficient of 0 we can’t say anything about the
    distribution of the data, but we can investigate it (if needed) with a regression
    analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, correlation and regression are linked but are different:'
  prefs: []
  type: TYPE_NORMAL
- en: Correlation analyzes the tendency of variables to be linearly distributed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression is the study of the relationship between variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Linear Regression model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have two kinds of Linear Regression models: the Simple and the Multiple
    ones. Let’s see them both.'
  prefs: []
  type: TYPE_NORMAL
- en: The Simple Linear Regression model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The goal of the Simple Linear Regression is to model the relationship between
    a single feature and a continuous label. This is the mathematical equation that
    describes this ML model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The parameter `b` (also called “bias”) represents the y-axis intercept (is the
    value of `y`when `X=0`), and `w` is the weight coefficient. Our goal is to learn
    the weight `w` that describes the relationship between `x` and `y`. This weight
    will later be used to predict the response for new values of `x`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s consider a practical example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/eef66406ac354d0b5292506809d6f598.png)'
  prefs: []
  type: TYPE_IMG
- en: The output of the above code. Image by Federico Trotta.
  prefs: []
  type: TYPE_NORMAL
- en: 'The question is: can this data distribution be approximated with a line? Well,
    we could create something like that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/21d9aede1dd1f26e41d07ca15aa3d6c1.png)'
  prefs: []
  type: TYPE_IMG
- en: The output of the above code. Image by Federico Trotta.
  prefs: []
  type: TYPE_NORMAL
- en: Well, as in the example we’ve seen above, it could be a line but it could be
    a general curve.
  prefs: []
  type: TYPE_NORMAL
- en: And, in a moment we’ll see how we can say if the data distribution can be better
    described by a line or by a general curve.
  prefs: []
  type: TYPE_NORMAL
- en: The Multiple Linear Regression model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since reality is complex, the typical cases we’ll face are related to the Multiple
    Linear Regression case. We mean that the feature `x` is not a single one: we’ll
    have multiple features. For example, if we work with tabular data, a data frame
    with 9 columns has 8 features and 1 label: this means that our problem is eight-dimensional.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As we can understand, this case is very complicated to visualize and the equation
    of the line has to be expressed with vectors and matrices, becoming:'
  prefs: []
  type: TYPE_NORMAL
- en: The equation of the Multiple Linear Regression model powered by embed-dot-fun
    by the Author.
  prefs: []
  type: TYPE_NORMAL
- en: So, the equation of the line becomes the sum of all the weights (`w`) multiplied
    by the independent variable (`x`) and it can even be written as the product of
    two matrices.
  prefs: []
  type: TYPE_NORMAL
- en: Assumptions for the Linear Regression model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, to apply the Linear Regression model, our data should respect some assumptions.
    These are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Linearity**: the relationship between the dependent variable and independent
    variables should be linear. This means that a change in the independent variable
    should result in a proportional change in the dependent variable, following a
    linear path.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Independence**: the observations in the dataset should be independent of
    each other. This means that the value of one observation should not depend on
    the value of another observation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Homoscedasticity**: the variance of the residuals should be constant across
    all levels of the independent variable. In other words, the spread of the residuals
    should be roughly the same across all levels of the independent variable.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Normality**: the residuals should be normally distributed. In other words,
    the distribution of the residuals should be a normal (or bell-shaped) curve.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**No multicollinearity**: the independent variables should not be highly correlated
    with each other. If two or more independent variables are highly correlated, it
    can be difficult to distinguish the individual effects of each variable on the
    dependent variable.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Unfortunately, testing all these hypotheses is not always possible, especially
    in the case of the Multiple Linear Regression model. Anyway, there is a way to
    test all the hypotheses. It’s called the `p-value` test, and maybe you heard of
    that before. Anyway, we won’t cover this test here for two reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: It’s a general test, not specifically related to the Linear Regression model.
    So, it needs a specific treatment in a dedicated article.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'I’m one of those (maybe one of the few) who believes that calculating the `p-value`
    is not always a must when we need to analyze data. For this reason, I’ll create
    in the future a dedicated article on this controversial topic. But just for the
    sake of curiosity, since I’m an engineer I have a very practical approach, and
    I like applied mathematics. I wrote an article on this topic here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[](/please-no-more-flipping-coins-in-data-science-f21e893d4fbd?source=post_page-----7abd37fcb9ed--------------------------------)
    [## Please: No More Flipping Coins in Data Science'
  prefs: []
  type: TYPE_NORMAL
- en: Why statistics for data science should be engineered.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/please-no-more-flipping-coins-in-data-science-f21e893d4fbd?source=post_page-----7abd37fcb9ed--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Finding the line that best fits the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So, above we were reasoning which one of the following can be the best fit:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2ba3c70826f4b1047201e48c94c28934.png)'
  prefs: []
  type: TYPE_IMG
- en: A comparison between models. Image by Federico Trotta.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand if the best model is the left one (the line) or the right one
    (a general curve) we proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: We split the data we have into the training and the test set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We validate both models on both sets, testing how well our models generalize
    their learning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We won’t cover the polynomial model here (useful for general curves), but consider
    that there are two approaches to validate ML models:'
  prefs: []
  type: TYPE_NORMAL
- en: The analytical one.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The graphical one.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Generally speaking, we’ll use both to get a better understanding of the performance
    of the model. Anyway, **generalizing** means that our ML model learns from the
    training set and **applies correctly its learning to the test set**. If it doesn''t,
    we try another ML model. Here’s the process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fdfb4f60b739f61db311ff0e27817add.png)'
  prefs: []
  type: TYPE_IMG
- en: The workflow of training and validating ML models. Image by Federico Trotta.
  prefs: []
  type: TYPE_NORMAL
- en: This means that **an ML model generalizes well when it has good performances
    on both the training and the test set**.
  prefs: []
  type: TYPE_NORMAL
- en: 'I’ve discussed the analytical way to validate an ML model in the case of linear
    regression in the following article:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/mastering-the-art-of-regression-analysis-5-key-metrics-every-data-scientist-should-know-1e2a8a2936f5?source=post_page-----7abd37fcb9ed--------------------------------)
    [## Mastering the Art of Regression Analysis: 5 Key Metrics Every Data Scientist
    Should Know'
  prefs: []
  type: TYPE_NORMAL
- en: The definitive guide on all the knowledge you should have on the metrics used
    in regression analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/mastering-the-art-of-regression-analysis-5-key-metrics-every-data-scientist-should-know-1e2a8a2936f5?source=post_page-----7abd37fcb9ed--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: I advise you to read it because we’ll use some metrics discussed there in the
    example at the end of this article.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, the metrics discussed can be applied to any ML model in the case
    of a regression problem. But you’re lucky: I’ve used the linear model as an example.'
  prefs: []
  type: TYPE_NORMAL
- en: The graphical ways to validate an ML model in the case of a regression problem
    are discussed in the next paragraph.
  prefs: []
  type: TYPE_NORMAL
- en: Graphical methods to validate your ML model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s see three graphical ways to validate our ML models.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. The residual analysis plot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This method is specific to the Linear Regression model and consists in visualizing
    how the residuals are distributed. Here’s what we expect:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/33785afb3b1c516f0efaae2921da4a7f.png)'
  prefs: []
  type: TYPE_IMG
- en: A residual analysis plot. Image by Federico Trotta.
  prefs: []
  type: TYPE_NORMAL
- en: To plot this we can use the built-in function `sns.residplot()` in `Seaborn`
    ([here’s the documentation](https://seaborn.pydata.org/generated/seaborn.residplot.html)).
  prefs: []
  type: TYPE_NORMAL
- en: A plot like that is good because we want to see randomly distributed data points
    along the horizontal axis. One of the **assumptions of the linear regression model**,
    in fact, is that the **residuals must be normally distributed** (assumption n°4
    listed above). If the residuals are normally distributed, it means that the errors
    of the observed values from the predicted ones are randomly distributed around
    zero, with no clear pattern or trend; and this is exactly the case in our plot.
    So, in these cases, our ML model may be a good one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, if there is a particular pattern in our residual plot, our model is
    not good for our ML problem. For example, consider the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1773af90cdbb5b803ec761aa32fa77b8.png)'
  prefs: []
  type: TYPE_IMG
- en: A parabolical residuals analysis plot. Image by Federico Trotta.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, we can see that there is a parabolic trend: this means that our
    model (the Linear model) is not good to solve our ML problem.'
  prefs: []
  type: TYPE_NORMAL
- en: 2\. The actual vs. predicted values plot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another plot we may use to validate our ML model is the **actual vs. predicted
    plot**. In this case, we plot a graph having the actual values on the horizontal
    axis and the predicted values on the vertical axis. The goal is to find the data
    points distributed as much as possible to a line, in the case of Linear Regression.
    We can even use the method in the case of a polynomial regression: in this case,
    we’d expect the data distributed as much as possible to a generic curve.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we have a result as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c56a07613e3f27c02b4ed664a8e9fa14.png)'
  prefs: []
  type: TYPE_IMG
- en: An actual vs. predicted values plot in the case of linear regression. Image
    by Federico Trotta.
  prefs: []
  type: TYPE_NORMAL
- en: The above graph shows that the predicted data points are distributed along a
    line. It is not a perfect linear distribution, so the linear model may not be
    ideal.
  prefs: []
  type: TYPE_NORMAL
- en: 'If, for our specific problem, we have`y_train` (the label on the training set)
    and we’ve calculated `y_train_pred` (the prediction on the training set), we can
    plot the following graph like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 3\. The Kernel Density Estimation (KDE) plot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The last graph we want to talk about to validate our ML models is the Kernel
    Density Estimation (KDE) plot. This is a general method and can be used to validate
    both regression and classification models.
  prefs: []
  type: TYPE_NORMAL
- en: The KDE is the application of a **kernel smoother** for probability density
    estimation. A kernel smoother is a statistical method that is used to estimate
    a function as the weighted average of the neighbor observed data. The kernel defines
    the weight, giving a higher weight to closer data points.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand the usefulness of a smoother function, see the graph below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d1593564bbe6c3f71737da04af50ff6a.png)'
  prefs: []
  type: TYPE_IMG
- en: The idea behind KDE. Image by Federico Trotta.
  prefs: []
  type: TYPE_NORMAL
- en: It is helpful to approximate our data points with a smoothing function if we
    want to compare two quantities. In the case of an ML problem, in fact, we typically
    like to see the comparison between the actual labels and the labels predicted
    by our model, so we use the KDE to compare two smoothed functions.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say we have predicted our labels using a linear regression model. We want
    to compare the KDE for our training set’s actual and predicted labels. We can
    do so with `Seaborn` invoking the method `sns.kdeplot()` ([here’s the documentation](https://seaborn.pydata.org/generated/seaborn.kdeplot.html)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we have the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/face58523221bd6cb27060e88203599d.png)'
  prefs: []
  type: TYPE_IMG
- en: A KDE plot. Image by Federico Trotta.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the comparison between the actual and the predicted label is
    easy to do, since we are comparing two smoothed functions; in a case like that,
    our model is good because the curves are very similar.
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, what we expect from a “good” ML model are:'
  prefs: []
  type: TYPE_NORMAL
- en: The curves are similar to bell curves, as much as possible.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The two curves are similar between them, as much as possible.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An example in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, let’s apply all the things we’ve learned so far here. We’ll use the famous
    “Ames Housing” dataset, which is perfect for our scopes.
  prefs: []
  type: TYPE_NORMAL
- en: 'This dataset has 80 features, but for simplicity, we’ll work with just a subset
    of them which are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Overall Qual`: it is the rating of the overall material and finish of the
    house on a scale from 1 (bad) to 10 (excellent).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Overall Cond`: it is the rating of the overall condition of the house on a
    scale from 1 (bad) to 10 (excellent).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Gr Liv Area`: it is the above-ground living area, measured in squared feet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Total Bsmt SF`: it is the total basement area, measured in squared feet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SalePrice`: it is the sale price, in USD $.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll consider our `SalePrice` column as the target (label) variable, and the
    other columns as the features.
  prefs: []
  type: TYPE_NORMAL
- en: Exploratory Data Analysis EDA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s import our data, create a subset with the mentioned features, and display
    some statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/4ca09aef6932b19979933f856623cd50.png)'
  prefs: []
  type: TYPE_IMG
- en: Statistics of the dataset. Image by Federico Trotta.
  prefs: []
  type: TYPE_NORMAL
- en: 'An important observation here is that the mean values for all labels have a
    different range (the `Overall Qual` mean value is `6.09` while `Gr Liv Area` mean
    value is `1499.69`). This tells us an important fact: we have to scale the features.'
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What does “**features scaling**” mean?
  prefs: []
  type: TYPE_NORMAL
- en: 'Scaling a feature implies that the feature range is scaled between 0 and 1
    or between 1 and -1\. There are two typical methods to scale the features:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mean normalization:** Mean normalization is a method of scaling numeric data
    so that it has a minimum value of zero and a maximum value of one and all the
    values are normalized around the mean value. Suppose *c* is a value reached by
    our feature; to scale around the mean (*c*′ is the new value of *c* after the
    normalization process):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The formula for the mean normalization, powered by embed-dot-fun by the Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see an example in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '**Standardization** (or z-score normalization): This method transforms a variable
    so that it has a mean of zero and a standard deviation of one. The formula is
    the following (c′c’c′ is the new value of ccc after the normalization process):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The formula for the standardization, powered by embed-dot-fun by the Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see an example in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the normalized data have a mean of 0 and a standard deviation
    of 1, as we wanted. The good news is that we can use the library `scikit-learn`
    to standardize the features, and we're going to do it in a moment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Features scaling is an important thing to do when working on an ML problem,
    for a simple reason:'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we perform exploratory data analysis with features that are not scaled,
    when calculating the mean values (for example, during the calculation of the coefficient
    of correlation) we’ll get numbers that are very different from each other. If
    we take a look at the statistics we’ve got above when we’ve invoked the `df.describe()`
    method, we can see that, for each column, we get a very different value of the
    mean. If we scale or normalize the features, instead, we''ll get 0s, 1s, and -1s:
    and this will help us mathematically.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, this dataset has some `NaN` values. We won’t show it for brevity (try
    it on your own), but we’ll remove them. Also, we’ll calculate the correlation
    matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/0aa6ea1abbc4730b785ac779fb5ec4bf.png)'
  prefs: []
  type: TYPE_IMG
- en: The correlation matrix for our data frame. Image by Federico Trotta.
  prefs: []
  type: TYPE_NORMAL
- en: So, with `np.triu(np.ones_like(df.corr()))` we have created a mask that it’s
    useful to display a triangular correlation matrix, which is more readable (especially
    when we have much more features than in this case).
  prefs: []
  type: TYPE_NORMAL
- en: So, there is a moderate `0.6` correlation between `Total Bsmt SF` and `SalePrice`,
    quite a high `0.7` correlation between `Gr Liv Area` and `SalePrice`, and a high
    correlation `0.8` between `Overall Qual` and `SalePrice`; Also, there is a moderate
    correlation between `Overall Qual` and `Gr Liv Area` `0.6` and `0.5` between `Overall
    Qual` and `Total Bsmt SF`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here there’s no multicollinearity, so no features are highly correlated with
    each other (so, our features satisfy the hypothesis n°5 listed above). If we’d
    found some highly correlated features, we could delete them because **two highly
    correlated features have the same effect on the label** (**this applies to every
    general ML model: if two features are highly correlated, we can drop one of the
    two**).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we subdivide the data frame `df`into `X` ( the features) and `y`(the
    label) and scale the features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Fitting the linear regression model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now we have to split the features `X` into the training and the test set and
    we’re fitting them with the Linear Regression model. Then, we calculate R² for
    both sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: So we get R² of 0.77 on the training test and 0.73 on the test set which are
    quite good, suggesting the Linear model is a good one to solve this ML problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see the KDE plots for both sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/26074176e3f27e13165a2496d87af585.png)'
  prefs: []
  type: TYPE_IMG
- en: KDE for the training set. Image by Federico Trotta.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/ffd03a635c9618a39285ca91295094c6.png)'
  prefs: []
  type: TYPE_IMG
- en: KDE for the test set. Image by Federico Trotta.
  prefs: []
  type: TYPE_NORMAL
- en: 'Regardless of the fact that we’ve obtained an R² of 0.73 on the test set which
    is good (but remember: the higher, the better), this plot shows us that the linear
    model is indeed a good model to solve this ML problem. This is why I love the
    KDE plot: is a very powerful tool, as we can see.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, this shows why shouldn''t rely on just one method to validate our ML
    model: a combination of one analytical method with one graphical one generally
    gives us the right insights to decide whether to change our ML model or not. In
    this case, the Linear Regression model is perfect to make predictions.'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I hope you’ll find useful this article. I know it’s very long, but I wanted
    to give you all the knowledge you need on this topic, so that you can return to
    it whenever you need it the most.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the things we’ve discussed here are general topics, while others are
    specific to the Linear Regression model. Let’s summarize them:'
  prefs: []
  type: TYPE_NORMAL
- en: The definition of **regression** is, of course, a general definition.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Correlation** is generally referred to as the Linear model**.** In fact,
    as we said before, correlation is the tendency of two variables to be linearly
    dependent.However**,** there are ways to define non-linear correlations, but we
    leave them for other articles (but, as knowledge for you: just consider that they
    exist).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ve discussed the Simple and the Multiple Linear Regression models with their
    assumptions (the assumptions apply to both models).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When talking about how to find the line that best fits the data, we’ve referred
    to the article “[Mastering the Art of Regression Analysis: 5 Key Metrics Every
    Data Scientist Should Know](/mastering-the-art-of-regression-analysis-5-key-metrics-every-data-scientist-should-know-1e2a8a2936f5)”.
    Here, we find all the metrics to know to solve a regression analysis. So, this
    is a generical topic that applies to any regression model, including the Linear
    one, of course.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We’ve shown three methods to validate our ML models: 1) **The residual analysis
    plot**: which applies to Linear Regression models, 2) **The actual vs. predicted
    values plot**: which can be applied to Linear and Polynomial models, 3) the **KDE
    plot**: this can be applied to any ML model, even in the case of a classification
    problem'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, I want to remind you that we’ve spent a couple of lines stressing the
    fact that we can avoid using `p-values` to test the hypotheses of our ML models.
    I’m writing an article on this topic very soon, but, as you can see, the KDE has
    shown us that our Linear model is good to solve this ML problem, and we haven’t
    validated our hypothesis with `p-values`.
  prefs: []
  type: TYPE_NORMAL
- en: '*So far in this article, we’ve used some plots. You can* [*clone this repo*](https://github.com/federico-trotta/plots_custom_functions)
    *I’ve created so that you can import the code and use it to easily plot the graphs.
    If you have some difficulties, you find examples of usages on my projects on GitHub.
    If you have any other difficulties, you can* [*contact me*](https://bio.link/federicotrotta)
    *and I’ll help you.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**FREE PYTHON EBOOK:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Started learning Python Data Science but struggling with it? [***Subscribe
    to my newsletter and get my free ebook: this will give you the right learning
    path to follow to learn Python for Data Science with hands-on experience.***](https://federico-trotta.ck.page/a3970f33f4)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Enjoyed the story? Become a Medium member for 5$/month [through my referral
    link](https://medium.com/@federicotrotta/membership): I’ll earn a small commission
    to no additional fee to you:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://federicotrotta.medium.com/membership?source=post_page-----7abd37fcb9ed--------------------------------)
    [## Join Medium with my referral link - Federico Trotta'
  prefs: []
  type: TYPE_NORMAL
- en: Read every story from Federico Trotta (and thousands of other writers on Medium).
    Your membership fee directly supports…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: federicotrotta.medium.com](https://federicotrotta.medium.com/membership?source=post_page-----7abd37fcb9ed--------------------------------)
  prefs: []
  type: TYPE_NORMAL
