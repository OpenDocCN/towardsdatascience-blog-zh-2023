- en: 'IID: Meaning and Interpretation for Beginners'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/iid-meaning-and-interpretation-for-beginners-dbffab29022f](https://towardsdatascience.com/iid-meaning-and-interpretation-for-beginners-dbffab29022f)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Independent and Identically Distributed
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@jaekim8080?source=post_page-----dbffab29022f--------------------------------)[![Jae
    Kim](../Images/34716958ecfe8c0540f5cf5c1640d587.png)](https://medium.com/@jaekim8080?source=post_page-----dbffab29022f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dbffab29022f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dbffab29022f--------------------------------)
    [Jae Kim](https://medium.com/@jaekim8080?source=post_page-----dbffab29022f--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----dbffab29022f--------------------------------)
    ·9 min read·Aug 19, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7fb20a7ddc2a72850a13b99b256989e0.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Yu Kato](https://unsplash.com/@yukato?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: In statistics, data analysis, and machine learning topics, the concept of IID
    frequently appears as a fundamental assumption or condition. It stands for “*independent
    and identically distributed*”. An IID random variable or sequence is an important
    component of a statistical or machine models, also playing a role in time series
    analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this post, in an intuitive way, I explain the concept of IID in three different
    contexts: sampling, modelling, and predictability. An application with R code
    is presented in the context of time series analysis and predictability.'
  prefs: []
  type: TYPE_NORMAL
- en: IID in Sampling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The notation X ~ IID(μ,σ²) represents sampling of (X1, …, Xn) in a *purely random*
    way from the population withthe mean μ and variance σ². That is,
  prefs: []
  type: TYPE_NORMAL
- en: each successive realization of X is *independent*, showing no association with
    the previous one or with the one after; and
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: each successive realization of X is obtained from the same distribution with
    *identical* mean and variance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Suppose a sample (X1, …, Xn) is collected from the distribution of annual incomes
    of individuals of a country.
  prefs: []
  type: TYPE_NORMAL
- en: A researcher has selected income of a male for X1, a female for X2, a male of
    X3, then a female for X4, and this pattern is kept to Xn. This is *not* an IID
    sampling, because a predictable or systematic pattern in sampling is non-random,
    in violation of the *condition of independence*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A researcher has selected (X1, … X500) from the poorest group of individuals
    and then (X501, … X1000) from the richest group. This is *not* an IID sampling,
    because the two groups have different income distributions with different means
    and variances, in violation of the *condition of identicality*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: IID in Modelling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Suppose *Y* is the variable of interest you want to model or explain. Then,
    it can be decomposed into two parts: namely,'
  prefs: []
  type: TYPE_NORMAL
- en: '*Y* = Systematic Component + Unsystematic Component.'
  prefs: []
  type: TYPE_NORMAL
- en: The *systematic component* is the part of *Y* driven by the fundamental relationship
    with other factors. It is the component that can be explained or expected from
    *theories*, *common sense*, or *stylized facts*. It is the fundamental part of
    *Y* that is associated with substantive and practical importance.
  prefs: []
  type: TYPE_NORMAL
- en: The *unsystematic component* is the part of Y that is not driven by the fundamentals,
    which cannot be explained nor expected by theories, reasoning, or stylized facts.
    It captures variations of Y that cannot be explained by its systematic component.
    It should be *purely random* and idiosyncratic, *without any systematic* or *predictable
    pattern*. It is referred to as an error term in a statistical model, which is
    often represented as an IID random variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, consider a linear regression model of the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: Equation (1)
  prefs: []
  type: TYPE_NORMAL
- en: Here, *α* + *βX* in (1) is the systematic component and the error term *u* in
    (1) is the unsystematic component.
  prefs: []
  type: TYPE_NORMAL
- en: If the value of *β* is close 0 or practically negligible, then the variable
    *X* has a low explanatory power (measured by R²) for *Y*, indicating that it is
    cannot satisfactorily explain the fundamental variation of *Y*.
  prefs: []
  type: TYPE_NORMAL
- en: The error term *u* is assumed to be an IID random variable with zero mean and
    fixed variance, denoted as *u* ~ IID(0, σ²), which is purely random representing
    the unsystematic or unexpected variation in *Y*.
  prefs: []
  type: TYPE_NORMAL
- en: If *u* is not purely random and has a noticeable pattern, then the systematic
    component may not correctly specified because it is missing something substantive
    or fundamental.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Autocorrelation'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Suppose that the error term has a following pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: Equation (2)
  prefs: []
  type: TYPE_NORMAL
- en: This is a linear dependence (or autocorrelation), which is a systematic pattern.
    This predictable pattern should be incorporated into the model part, which will
    in turn better explain the systematic component of *Y*. One way of achieving this
    is to include a lagged term of Y in (2). That is,
  prefs: []
  type: TYPE_NORMAL
- en: Equation (3)
  prefs: []
  type: TYPE_NORMAL
- en: The lag of *Yt* included in (3) is able to capture the autocorrelation of error
    term in (2), so that the error term *e* in (3) is an IID.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Heteroskedasticity'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Suppose that the error term shows the following systematic pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: Equation (4)
  prefs: []
  type: TYPE_NORMAL
- en: This pattern of error term is called heteroskedasticity where the variability
    of error term changes as a function of *X* variable. For example, suppose *Y*
    is food expenditure and *X* is disposable income for individuals. The equation
    (4) means that high-income earners show a higher variability in food expenditure.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a predictable pattern, and the error term with the property of (4)
    violates the assumption of IID, because the variance of the error term is not
    a constant. To incorporate this pattern into the systematic component, the generalized
    or weighted least-squares estimation can be conducted in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: Equation (5)
  prefs: []
  type: TYPE_NORMAL
- en: The equation (5) is a regression with transformed variables, which can be written
    as
  prefs: []
  type: TYPE_NORMAL
- en: Equation (6)
  prefs: []
  type: TYPE_NORMAL
- en: where
  prefs: []
  type: TYPE_NORMAL
- en: Transformations for heteroskedastic errors
  prefs: []
  type: TYPE_NORMAL
- en: The above transformations of *Y* and *X* provide the transformed error term
    (*ut** ) in (6), which is an IID and no longer heteroskedastic. That is,
  prefs: []
  type: TYPE_NORMAL
- en: This means that a systematic pattern in the error term is now effectively incorporated
    into the systematic component by the above transformation.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c2bd897c09eb62248a3a325c413ae009.png)'
  prefs: []
  type: TYPE_IMG
- en: Image Created by the Author
  prefs: []
  type: TYPE_NORMAL
- en: The above plots present the effect of the transformation in an intuitive way.
    Before the transformation (plot on the left), the variable *Y* shows an increasing
    variability as a function of *X*, which is a reflection of the heteroskedasticity.
    The transformation effectively incorporates the heteroskedastic pattern into the
    systematic component of *Y*, and the transformed error term is now an IID random
    variable, as the right-hand side plot shows.
  prefs: []
  type: TYPE_NORMAL
- en: Many of the model diagnostic tests in regression or machine learning models
    are designed to check if the error term follows an IID random variable, using
    the residuals from the estimated model. This is also called the residual analysis.
    Through the residual analysis and diagnostic checks, specification of the systematic
    component of the model can be improved.
  prefs: []
  type: TYPE_NORMAL
- en: IID and predictability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Being purely random, an IID sequence shows no predictable pattern at all. That
    is, its past history provides no information about the future course of the sequence.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Autoregressive model'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Consider an autoregressive model of order 1, denoted AR(1),
  prefs: []
  type: TYPE_NORMAL
- en: Equation (7)
  prefs: []
  type: TYPE_NORMAL
- en: where *ut* ~ IID(0,σ²) and -1 < ρ < 1 (ρ ≠ 0).
  prefs: []
  type: TYPE_NORMAL
- en: If ρ = 0, the time series Yt is an IID and non-predictable, since it shows no
    dependence on its own past, driven only by unpredictable shocks.
  prefs: []
  type: TYPE_NORMAL
- en: 'For simplicity, let us assume that Y0 = 0 and ρ ≠ 0 and conduct the following
    continual substitution:'
  prefs: []
  type: TYPE_NORMAL
- en: Y1 = u1;
  prefs: []
  type: TYPE_NORMAL
- en: Y2 = ρY1 + u2 = ρu1 + u2;
  prefs: []
  type: TYPE_NORMAL
- en: Y3 = ρY2 + u3 = ρ²u1 + ρ u2 + u3;
  prefs: []
  type: TYPE_NORMAL
- en: Y4 = ρY3 + u4 = ρ³u1 + ρ²u2 + ρu3 + u4;
  prefs: []
  type: TYPE_NORMAL
- en: with the general expression being
  prefs: []
  type: TYPE_NORMAL
- en: Equation (8)
  prefs: []
  type: TYPE_NORMAL
- en: The equation (6) shows that a time series (such as an autoregression) can be
    expressed as a moving-average of the past and current IID errors (or shocks),
    with exponentially declining weights.
  prefs: []
  type: TYPE_NORMAL
- en: Note that that the distant shocks such as u1 and u2 in (8) have little impact
    on *Yt*, because their weights are negligible. For example, when *ρ* = 0.5 and
    *t* = 100, *ρ*⁹⁹ and *ρ*⁹⁸ are practically 0\. Only the current or recent shock
    such as u100, u99, and u98 may matter practically.
  prefs: []
  type: TYPE_NORMAL
- en: Hence, if a researcher at time t has a good estimate of ρ (from data) and observed
    the current and recent shocks such as ut, ut-1, ut-2, and ut-3, she or he may
    be able to predict the value of Yt+1, with a reasonable accuracy, by projecting
    the moving-average in (8) into the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Random walk'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When ρ = 1, the time series in (7) become a random walk where the current change
    of *Y* is an IID shock that is purely unpredictable: i.e.,'
  prefs: []
  type: TYPE_NORMAL
- en: In this case, from (8) with ρ = 1, we have
  prefs: []
  type: TYPE_NORMAL
- en: In other words, a random walk is *sum of all past and current IID shocks* with
    an equal weight of 1\. As a result, distant shocks are equally important as the
    recent and current shocks. For example, if t = 100, the shock u1 has the same
    impact on Y100 as u100.
  prefs: []
  type: TYPE_NORMAL
- en: As a sum of all past and current shocks, a random walk time series is purely
    unpredictable. It also shows a high degree of uncertainty and persistence (dependence
    on past), with the analytical results that
  prefs: []
  type: TYPE_NORMAL
- en: Equation (9)
  prefs: []
  type: TYPE_NORMAL
- en: This means that the variability of a random walk increases with time, indicative
    of high degree of uncertainty and low degree of predictability over time.
  prefs: []
  type: TYPE_NORMAL
- en: In addition the correlation between Yt and Yt-k are almost equal to 1, for nearly
    all values of *k*. For example, Y100 and Y99 are correlated with the correlation
    coefficient of 99/100 = 0.99, when t = 100.
  prefs: []
  type: TYPE_NORMAL
- en: Application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As an application, basic descriptive properties of an IID process, AR(1) time
    series of ρ ∈ {0.3, 0.6, 0.9}, and a random walk are compared using time plots
    and autocorrelation functions.
  prefs: []
  type: TYPE_NORMAL
- en: Time plots
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/90a97f8168f8c9a520a27bf201f61098.png)![](../Images/dd74888f14f860148522d8b3dfe20ee7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Time Plots: Image Created by the Author'
  prefs: []
  type: TYPE_NORMAL
- en: An IID series Y1, as an AR(1) time series with ρ = 0, shows no pattern at all,
    randomly and frequently fluctuating around the mean of 0\. It has a strong tendency
    to revert back to the mean.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For Y2 to Y4, as the value of ρ increases from 0.3 to 0.9, the time series gets
    smoother and less frequent, reflecting an increasing degree of dependence on its
    own past. The degree of mean-reversion also declines as the value of ρ gets higher.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A random walk Y5 shows a trend which can change its direction randomly (called
    *stochastic trend*). It shows an increasing variability over time, as shown in
    the first result in (9), with a little tendency to revert back to its mean over
    time (*mean-aversion*).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autocorrelation Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0a9c70c9a88413f5b2cfd827688c2628.png)![](../Images/66fc82ebca3a917a33ac75508c2ecdb5.png)'
  prefs: []
  type: TYPE_IMG
- en: Autocorrelation functions (Image provided by the Author)
  prefs: []
  type: TYPE_NORMAL
- en: The autocorrelation function of a time series plots Corr(Yt,Yt-k) against the
    lag value of k. It provides a visual summary of the dependence of structure of
    a time series. For example, Corr(Yt,Yt-1) measures how much the values of Y 1-period
    apart are correlated. The blue band is 95% confidence band, and a value of autocorrelation
    inside this band means that the correlation is statistically no different from
    0 at the 5% level of significance.
  prefs: []
  type: TYPE_NORMAL
- en: An IID time series Y1 has all of the autocorrelation values practically negligible
    and statistically 0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As the value of ρ increases from 0.3 to 0.9, the degree of dependence Y on its
    own past increases, as more autocorrelation values get practically larger and
    statistically different from 0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A random walk time series Y5 has all autocorrelation values extremely close
    to 1, indicative of extremely high degree of dependence on its own past (*persistence*).
    This is a reflection of the second property given in (9).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This application presents the basic statistical properties of an IID time series,
    in comparison with those of AR(1) and random walk. It illustrates that the degree
    of dependence on past (or predictability) changes as the value of AR(1) coefficient
    changes from 0 to 1, i.e., from an IID time series to a random walk. As explained
    above, a time series is predictable when the degree of dependence is moderately
    strong, characterized by the value of ρ greater than 0 but less than 1.
  prefs: []
  type: TYPE_NORMAL
- en: R code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The time series and plots are generated using the following R code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The concept of IID is fundamental in statistical analysis and machine learning
    models. This post has reviewed the IID in three different contexts: sampling,
    modelling, and predictability in time series analysis. An application is presented,
    which compares the basic descriptive statistical properties of an IID time series
    with those of stationary AR(1) and a random walk.'
  prefs: []
  type: TYPE_NORMAL
