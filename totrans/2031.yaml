- en: The Magic of LLMs — Prompt Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-magic-of-llms-prompt-engineering-9c3e46130131](https://towardsdatascience.com/the-magic-of-llms-prompt-engineering-9c3e46130131)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Garbage in, garbage out has never been more true.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://franklyai.medium.com/?source=post_page-----9c3e46130131--------------------------------)[![Frank
    Neugebauer](../Images/0da70d082d0f9c7ad8ccf574ed215df2.png)](https://franklyai.medium.com/?source=post_page-----9c3e46130131--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9c3e46130131--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9c3e46130131--------------------------------)
    [Frank Neugebauer](https://franklyai.medium.com/?source=post_page-----9c3e46130131--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9c3e46130131--------------------------------)
    ·6 min read·Apr 8, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8c28b5ab704518e11aef83823349fb09.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Gary Chan](https://unsplash.com/es/@gary_at_unsplash?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Rise of the Machines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Large language models (LLMs) are able to conversationally provide an unprecedented
    level of ML-generated information when *asked the right question*. For example,
    LLMs can generate articles (no, an LLM didn’t generate this text), poetry, song
    lyrics, have a conversation with someone about a topic, interpret some types of
    documents / forms, and more. However, a seldom talked about problem with LLMs
    is that it’s not always easy to know the **right question** and without that critical
    part, LLMs can be overly accurate (i.e., too much information), inaccurate, or
    far too variable for many commercial applications.
  prefs: []
  type: TYPE_NORMAL
- en: The art of asking the right question, or **prompt engineering**, is how we overcome
    this limitation (for at least the near term) and is *the magic behind the magic*
    of LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: Shifting the Problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Without providing an overview of LLMs (written by an LLM), I want to jump right
    into an important characteristic of LLMs — they are non-deterministic; you won’t
    necessarily get the same answer to the same question every time. For example,
    if I ask Google Bard a simple question such as “What is 1 + 1”, multiple times
    in a row, here’s the unedited result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Only the 2nd and 3rd prompts yielded the same answer but also notice that the
    answer isn’t simply “2,” it’s a variation of the prompt and the answer, and some
    fairly unpredictable formats of the answers. (NOTE: the output above is not what
    Bard looks like, it’s just the text.)'
  prefs: []
  type: TYPE_NORMAL
- en: Going from unstructured to unstructured doesn’t really solve the problem, it
    shifts the problem.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In the 1+1 case, the shift is figuring out how to parse/transform the answer;
    working with a variable answer is a lot like throwing darts in a spinning room
    — the answer variation would be too great and we are almost back to the original
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, we focus on prompt engineering, or the art form of asking questions
    to get specific responses. Here’s what Bard thinks prompt engineering is:'
  prefs: []
  type: TYPE_NORMAL
- en: Prompt engineering is the process of designing and optimizing prompts to LLMs
    for a wide variety of applications and research topics. Prompts are short pieces
    of text that are used to guide the LM’s output. They can be used to specify the
    task that the LM is supposed to accomplish, provide additional information that
    the LM needs to complete the task, or simply make the task easier for the LM to
    understand.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Thanks for that Bard, it’s a pretty good non-nuanced description, although “short”
    is relative in this context.
  prefs: []
  type: TYPE_NORMAL
- en: Engineering the Question — You Control That
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the 1+1 example, the one thing I controlled is the question, or the prompt.
    For that reason, the focus is on engineering the question (or prompt) and doing
    so by adding specificity and context.
  prefs: []
  type: TYPE_NORMAL
- en: Watch what happens when I add some specifics to the prompt for 1+1.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Wait! That’s **SO MUCH WORSE**. I don’t want a narrative answer, I just want
    a number! And that’s why prompt engineering is an art form. Let me try again…
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Look at that! How about another example…
  prefs: []
  type: TYPE_NORMAL
- en: In this example, I’m going to do two things — first, show how data can be included
    in a prompt and second, how a prompt can be engineered to get something specific.
  prefs: []
  type: TYPE_NORMAL
- en: I’m starting by using OCR to extract the following table as text.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c8f6523f875aeadd5cb01d5eb256e459.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: My objective is to ask that data some questions about itself. This is a pretty
    interesting (and awesome, to be technical) use case, applicable in many (but not
    all) situations.
  prefs: []
  type: TYPE_NORMAL
- en: I want to know the size of the file for 2022 Q2 (ignore the highlighted row
    in the table, I want the one below it). The answer is **48.79 MB**.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: So the cool part here is that it got the answer correct (48.79 MB). The bad
    part is, as we saw with 1+1, the answer is unstructured. I need to modify the
    prompt with specificity.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: That’s better (even if not perfect), and really makes this useful as a zero-shot
    way to read certain types of data, maybe even form data. In a real-world situation,
    I’d continue to iterate with the prompt until I got a fully consistent deterministic-looking
    answer.
  prefs: []
  type: TYPE_NORMAL
- en: Beware the Ides of Hype
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Reading a simple table does not mean LLMs can read all tables or forms, they
    really can’t. A good example is found in the insurance industry where very complex
    (and even illogical) forms are the way information is exchanged. LLMs can understand
    some form, but not the complex ones because:'
  prefs: []
  type: TYPE_NORMAL
- en: LLMs don’t understand insurance (they can, but they don’t). The idea that an
    endorsement can contain an endorsement or a form, and the second use of endorsement
    is a noun and the use of “form” has nothing to do with an actual form, is really
    a nuance beyond general LLMs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Complex forms contain context that is very difficult (maybe impossible?) for
    language models to understand because the form is used as a layout structure,
    not a content structure. (Tables sometimes have this same issue for the same reason
    and sometimes tables are the mechanism used for layout structure.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To avoid getting pulled into the LLM hype spin, it’s important to get good at
    using the models to understand what they can and cannot do and how you can influence
    their behavior. Understand also that the models themselves continue to evolve
    so don’t write something off just because it doesn’t work right now.
  prefs: []
  type: TYPE_NORMAL
- en: Be Real(istic)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The hype cycle can cause unrealistic expectations. We’ve seen this repeated
    in history — e.g., services-oriented architecture (SOA) never resulted in dynamic
    applications, but we did get a pretty massive proliferation of APIs. LLMs could
    very well be like this because we seem to expect LLMs to solve all the world’s
    problems (my prediction: it won’t). If you’re realistic and curious about what
    these models can do, expectation and reality can align and I believe that alignment
    is where history is made.'
  prefs: []
  type: TYPE_NORMAL
- en: Go Forth, Change the World
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Large language models (LLMs) are powerful and usable for a variety of tasks,
    but they also have limitations, some of which can be overcome with prompt engineering.
    That engineering is an art form requiring significant experimentation, which really
    can’t be read in a book — go forth and do this yourself. Get good at prompt engineering
    and you’ll be able to maximize the value of LLMs and maybe even keep yourself
    out of the hype spin cycle.
  prefs: []
  type: TYPE_NORMAL
- en: The opinions expressed in this article are my own and do not reflect those of
    my employer.
  prefs: []
  type: TYPE_NORMAL
