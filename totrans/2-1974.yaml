- en: Text Correction Using NLP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/text-correction-using-nlp-b68c7233b86](https://towardsdatascience.com/text-correction-using-nlp-b68c7233b86)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Detecting and correcting common errors: problems and methods**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://jagota-arun.medium.com/?source=post_page-----b68c7233b86--------------------------------)[![Arun
    Jagota](../Images/3c3eb142f671b5fb933c2826d8ed78d9.png)](https://jagota-arun.medium.com/?source=post_page-----b68c7233b86--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b68c7233b86--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b68c7233b86--------------------------------)
    [Arun Jagota](https://jagota-arun.medium.com/?source=post_page-----b68c7233b86--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b68c7233b86--------------------------------)
    ·19 min read·Jan 13, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bcadaafc6c2554d8c8a66ada008560c7.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [Lorenzo Cafaro](https://pixabay.com/users/3844328-3844328/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1870721)
    from [Pixabay](https://pixabay.com/)
  prefs: []
  type: TYPE_NORMAL
- en: Anyone who writes text will miss a comma here and there. Or use the wrong preposition
    in a certain context. Or make spelling errors. Or phrase awkwardly. Or use overly
    complicated or excessively long sentences. Or overly long paragraphs. Or ramble
    on excessively.
  prefs: []
  type: TYPE_NORMAL
- en: On all but the shortest of writeups, perhaps all of the above. And more.
  prefs: []
  type: TYPE_NORMAL
- en: I had a student who was missing articles such as *a* or *the* in everything
    he wrote. I read hundreds of his pages. Didn’t find a single article.
  prefs: []
  type: TYPE_NORMAL
- en: I’ve made — and continue to make — all such errors repeatedly. Even in my short
    writeups such as emails.
  prefs: []
  type: TYPE_NORMAL
- en: For content that is quite elaborate, such as entire books or even short blog
    posts, textual issues of course will be much more prolific. This is why we have
    copy editors, whose responsibilities include proofreading and editing content.
  prefs: []
  type: TYPE_NORMAL
- en: This is also why NLP-based tools such as Grammarly are becoming increasingly
    popular. These tools can help one find and correct such errors within a matter
    of minutes in short texts such as emails. On longer texts, they’ll likely find
    more, which of course means they will take more time to fix.
  prefs: []
  type: TYPE_NORMAL
- en: For more on Grammarly, see [10].
  prefs: []
  type: TYPE_NORMAL
- en: Regardless, there is no way a writer can compete with such tools on the measure
    of increased throughput of producing quality writing. And I might add, with much
    less eye strain.
  prefs: []
  type: TYPE_NORMAL
- en: This brings to mind the following. A long, long time ago I wrote a Ph.D. thesis.
    Hundreds of pages. It was painful. I would not repeat the process now without
    a tool such as Grammarly.
  prefs: []
  type: TYPE_NORMAL
- en: '**Preamble**'
  prefs: []
  type: TYPE_NORMAL
- en: In this post, we will first describe and explain the various types of errors
    that people tend to make when they write. We will limit ourselves to basic errors
    such as missing commas, missing articles, or using the wrong preposition. (In
    this post, we use the term “error” in a somewhat soft sense. We really mean “suggestions
    for improvement”.)
  prefs: []
  type: TYPE_NORMAL
- en: Following that, we will brainstorm specific ways using NLP to detect such issues
    and offer solutions.
  prefs: []
  type: TYPE_NORMAL
- en: We have chosen to limit the scope of this post to basic errors for the following
    reasons. First, they are very common. Second, some basic methods from statistical
    natural language processing, combined with some feature engineering, lend themselves
    to their detection and correction.
  prefs: []
  type: TYPE_NORMAL
- en: So in this process, the reader will also get a firm grounding on basic methods
    in statistical NLP in a useful and real setting.
  prefs: []
  type: TYPE_NORMAL
- en: By contrast, detecting and offering corrections for more elaborate issues such
    as awkward phrasing or reexpressing something more concisely or in a way that
    reads much better requires more advanced NLP. In a separate post [11], in which
    we also model *context*, we go beyond the basic issues we cover in this post.
    This still does not cover awkward phrasing or expressing something more concisely
    or informatively as those are even more complex topics.
  prefs: []
  type: TYPE_NORMAL
- en: '**Basic Errors In Text**'
  prefs: []
  type: TYPE_NORMAL
- en: Here is what we will cover, with realistic examples.
  prefs: []
  type: TYPE_NORMAL
- en: Missing commas.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Missing articles.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leaving out the apostrophe in It’s.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Using singular instead of plural, or vice-versa.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a hyphen when it shouldn’t be used, or vice-versa.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Casing words: *Not capitalizing a letter when one should;* Not having a word
    in all caps when one should. E.g., *fyi*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Using the wrong preposition, or using one when it is not needed.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Following this, we will take a second pass over them in which we discuss basic
    solutions from statistical NLP. This discussion will involve what training sets
    to use, what features to extract, and what statistical models to use.
  prefs: []
  type: TYPE_NORMAL
- en: We will not even attempt to solve the issues in the above list highlighted in
    italics. These issues will need more advanced methods from NLP, ones that model
    context.
  prefs: []
  type: TYPE_NORMAL
- en: '**Missing Commas**'
  prefs: []
  type: TYPE_NORMAL
- en: The most frequent error I make is missing a comma when there should be one.
    Consider
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In each case, there should be a comma immediately after the first word.
  prefs: []
  type: TYPE_NORMAL
- en: '**Casing Words**'
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes one forgets to capitalize the first letter in the word that begins
    a sentence, or the ‘i’ when referring to oneself. As in
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This conveys a poor impression.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: reads better as
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: There are numerous other examples in which the all-upper case is preferred.
    Such as *pdf*, *gpx*, *cdc*, *nlp*, *ai*, …
  prefs: []
  type: TYPE_NORMAL
- en: '**Missing Articles**'
  prefs: []
  type: TYPE_NORMAL
- en: It’s also common to omit articles. As in
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The text before the ⇒ is what is written. The text after the ⇒ is how it should
    be written. We will follow this convention in depicting examples throughout this
    post.
  prefs: []
  type: TYPE_NORMAL
- en: Another frequent error I make is to leave out the apostrophe in *Its*. In fact,
    I made this error on the *Its* that begins this section!
  prefs: []
  type: TYPE_NORMAL
- en: '**Using Hyphens Incorrectly**'
  prefs: []
  type: TYPE_NORMAL
- en: I’ve made such errors frequently. Here are some examples from a nice post [2].
  prefs: []
  type: TYPE_NORMAL
- en: At this stage, I’ll just show the examples. Later on in this post, when we look
    at methods we’ll bring in some of the additional points in [2]. They will help
    us with engineering the right features or with deciding which method from statistical
    NLP we should use.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: And these.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Let’s see a few examples in the opposite direction. In these, we should not
    be using hyphens.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**Errors Involving Prepositions**'
  prefs: []
  type: TYPE_NORMAL
- en: I make errors involving prepositions quite frequently. Specifically, I use the
    wrong preposition. For instance, I often use *by* when I should be using *with*.
  prefs: []
  type: TYPE_NORMAL
- en: And were I not using Grammarly, I wouldn’t even know I was doing so. Even after
    reviewing my text.
  prefs: []
  type: TYPE_NORMAL
- en: Below is the first example I want to share. It's not specific to propositions
    but does illustrate the point I am trying to make.
  prefs: []
  type: TYPE_NORMAL
- en: While writing the above sentence. I wrote it as
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Grammarly suggested that I drop *to* and *be*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: reads better.
  prefs: []
  type: TYPE_NORMAL
- en: Oh, in fact, I just realized that there were two additional errors, just in
    the above few lines. Which are now fixed. Here are the versions with the errors
    in them.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In the first sentence, I am missing the *to* between *want* and *share*. In
    the second sentence, *Its* should be *It’s* or *It is*.
  prefs: []
  type: TYPE_NORMAL
- en: And one more thing.
  prefs: []
  type: TYPE_NORMAL
- en: I just realized that after writing *Oh, in fact* … I introduced a couple of
    additional errors!
  prefs: []
  type: TYPE_NORMAL
- en: Well, I’ll stop here as I could go on forever, in an infinite loop of generating
    new text with errors in it to explain the errors I made in the previous version
    of my text!
  prefs: []
  type: TYPE_NORMAL
- en: Okay, let’s see other examples.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Clearly, the writer meant *into* in this context. (Should the “*from the living
    room”* have been missing, it would be less clear-cut.)
  prefs: []
  type: TYPE_NORMAL
- en: The one below is from [1].
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The *of* doesn’t need to be there.
  prefs: []
  type: TYPE_NORMAL
- en: Previously I mentioned that I often use *by* when I should be using *with*.
    Here is an example.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In the above, *linear by sigmoidal* should be *linear with sigmoidal*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Towards Solutions**'
  prefs: []
  type: TYPE_NORMAL
- en: If we had access to a large language model such as ChatGPT [3] and could run
    it on-demand or in batch mode, we probably wouldn’t need to proceed piece-meal
    as below.
  prefs: []
  type: TYPE_NORMAL
- en: We assume the reader doesn’t have such access. Moreover, we assume the reader
    is interested in learning about the methods as they relate to these use cases
    and possibly in implementing them from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: As the interested reader will see later, the methods discussed in this post
    will be very easy to implement from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: Using pre-built large models would not provide any such insights. That said,
    it is a great idea to try out a large language model if one can gain access to
    it. To experience how it behaves. To observe what sorts of problems it is able
    to solve. To assess, in the context of this post, in what ways its solutions are
    better than ours?
  prefs: []
  type: TYPE_NORMAL
- en: Okay, back to the discussion on our specific suggestions. First, we will discuss
    what dataset to use for training. A single judiciously chosen data set will suffice
    for all our use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will discuss a handful of “building block” methods from statistical
    NLP. We will start by developing them on a few initial use cases. We will then
    discuss how these same methods are applicable to many of the other use cases we
    described earlier in this post. Albeit with some different preprocessing or features
    extracted.
  prefs: []
  type: TYPE_NORMAL
- en: That said, there are certain use cases that we described in some detail earlier
    in this post for which we will not even attempt to discuss solutions. This is
    because they seem to need more advanced methods that take context into account.
    That is, elaborate language models. We will cover these in a future post.
  prefs: []
  type: TYPE_NORMAL
- en: '**Training Data**'
  prefs: []
  type: TYPE_NORMAL
- en: The models we need for all the use cases discussed in this post can be learned
    in principle from a single data set. A corpus of text documents that are of reasonable
    quality, writing-wise.
  prefs: []
  type: TYPE_NORMAL
- en: Such as Wikipedia. In fact, one can download the entire text from Wikipedia
    onto one’s computer. See [4].
  prefs: []
  type: TYPE_NORMAL
- en: For some of the problems, even manually copying a few pages from Wikipedia or
    from some reasonable quality page on the web will suffice for quick initial training
    and evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: '**Simple Count-based Methods**'
  prefs: []
  type: TYPE_NORMAL
- en: Consider trying to detect sentences or paragraphs that are excessively long.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll train methods for such detections as follows. First, we will tokenize
    the text in each document into paragraphs, then tokenize each paragraph into sentences,
    and finally tokenize each sentence into its words.
  prefs: []
  type: TYPE_NORMAL
- en: A paragraph may be tokenized into its sentences using NLTK. See [5].
  prefs: []
  type: TYPE_NORMAL
- en: Tokenizing a document into its paragraphs, and paragraphs into its sentences
    are in themselves somewhat interesting NLP problems. We will cover methods for
    them in a separate post. Here our focus lies elsewhere.
  prefs: []
  type: TYPE_NORMAL
- en: Now we can build models of the numbers of words in sentences and in paragraphs
    respectively. Using these models we can flag unusually long sentences or unusually
    long paragraphs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Parametric Models Of Length Distributions**'
  prefs: []
  type: TYPE_NORMAL
- en: The main additional thing we’d like to say on this topic is that the normal
    distribution is not a good one for modeling sentence or paragraph lengths.
  prefs: []
  type: TYPE_NORMAL
- en: The normal distribution is symmetric with tails at negative infinity and positive
    infinity. By contrast, sentence lengths are more likely to be distributed as follows.
    Single-word sentences, while they do exist, are relatively rare. As we increase
    the length, sentences of that length will start becoming more common. As we increase
    the sentence length further, sentences of that length will start becoming less
    common. Exponentially so.
  prefs: []
  type: TYPE_NORMAL
- en: The reader may test this reasoning out quickly by scrolling up and down this
    post and eye-balling the lengths of the various sentences. The reader will find
    a handful of two-word sentences. Most sentences will contain between five to ten
    words. The reader won’t find any sentences containing, say thirty words. These
    are just too long.
  prefs: []
  type: TYPE_NORMAL
- en: Okay, back to characterizing the distribution we want. It should look like this.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7ac072e7caf2247dc759acc747dc7879.png)'
  prefs: []
  type: TYPE_IMG
- en: The Poisson distribution fits this shape better than the Normal distribution.
    See [6].
  prefs: []
  type: TYPE_NORMAL
- en: The Poisson distribution has a parameter, i.e. a tunable knob, which can fine-tune
    the shape further. This parameter can be tuned from the data.
  prefs: []
  type: TYPE_NORMAL
- en: Also, see [7], which is a paper devoted to the topic of modeling distributions
    of lengths of sentences in text. As discussed there, the lognormal distribution
    also merits consideration.
  prefs: []
  type: TYPE_NORMAL
- en: '**Non-parametric Models Of Length Distributions**'
  prefs: []
  type: TYPE_NORMAL
- en: Say our corpus contains lots of sentences. We can avoid making any assumptions
    about the distribution’s form. Should it be Poisson? Should it be Pareto? Should
    it be lognormal? Some other?
  prefs: []
  type: TYPE_NORMAL
- en: Simply estimate it empirically from the data. That is, essentially just create
    a histogram over the various sentence lengths. It would like something like this.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This says that there were 10 three-word sentences in our corpus and 500 eight-word
    ones.
  prefs: []
  type: TYPE_NORMAL
- en: The histogram may need some smoothing. Both interpolation and extrapolation.
  prefs: []
  type: TYPE_NORMAL
- en: To see the need for interpolation, consider this scenario. In our corpus, say
    there is one occurrence of a 50-word sentence but none of a 45-word one. (Never
    mind how the 40-word sentence got in there.) We wouldn’t want to say that a 45-word
    sentence has a zero probability of occurring. Sure small, but not zero.
  prefs: []
  type: TYPE_NORMAL
- en: Okay, back to the histogram discussion.
  prefs: []
  type: TYPE_NORMAL
- en: A histogram, suitably smoothed, may then be used to score a new sentence for
    how unusual its length is. An unusually long sentence should score very low.
  prefs: []
  type: TYPE_NORMAL
- en: The smoothed histogram has all the information in it for such scoring. We can
    call this “*P*-value or percentile scoring”. If for instance, 99% of the sentences
    in our corpus are no more than twenty words long, the *P*-value of a 21-word sentence
    is no more than 0.01, i.e. 1%. This could be expressed as a score in percentile
    units. *1* would mean a very low score.
  prefs: []
  type: TYPE_NORMAL
- en: To keep the description of the above paragraph simple enough, we are glossing
    over details such as *right*-tail *P*-values versus *both*-tail ones. In practice,
    this does not matter much unless the score thresholds are based on *P*-value cutoffs.
    Typically in practice, they are not. Instead, they are calibrated based on where
    we think the cutoffs should be. That is, we ask people which sentences they deem
    to be too long, and derive a score cutoff from such feedback.
  prefs: []
  type: TYPE_NORMAL
- en: '**Methods Involving Token-specific Distributions**'
  prefs: []
  type: TYPE_NORMAL
- en: Consider the problem involving hyphens that we described earlier in the post.
    That is should there be a hyphen or not joining certain adjacent words? If not,
    should there be a space or should the words be fused?
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by repeating the examples we saw earlier, to better understand the
    nature of the problem.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: As a first attempt, it does seem that even without modeling context we could
    do a reasonable job at detecting suspect hyphenation and offer sensible alternatives.
  prefs: []
  type: TYPE_NORMAL
- en: Clearly, we don’t need either perfect precision or perfect recall. Just enough
    so the user finds value. We can always iterate and improve.
  prefs: []
  type: TYPE_NORMAL
- en: We’d like to note that we should focus on the precision of the detection much
    more than the quality of the alternatives proposed. This is because there are
    only three possibilities — hyphenate, use white space, or glue — for the adjacent
    words. So if the detected hyphenation is indeed poor, even showing both of the
    other two provides value to the user.
  prefs: []
  type: TYPE_NORMAL
- en: So we will proceed to model the problem as follows. First, let’s consider the
    case of a token that was found to have a hyphen in it. Such as *heart-broken*.
    When we encounter this token during the training process, we will do the following.
  prefs: []
  type: TYPE_NORMAL
- en: We will create a new token with the hyphen dropped. In our example, it would
    be *heartbroken*. We would then add an instance of *heartbroken* → *heart-broken*
    to a map every time we encounter *heart-broken* in the text. In python pseudocode,
    it would look something like this
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: When (and if) we encounter *heartbroken* in the corpus (as opposed to *heart-broken*)
    we would do the following
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: So once the training has finished, *style_map*[‘*heartbroken*’] will have the
    distribution over the two versions *heart-broken* and *heartbroken*.
  prefs: []
  type: TYPE_NORMAL
- en: So if *P*(*heartbroken*|*heartbroken*) is much higher than *P*(*heart*-*broken*|*heartbroken*)
    we would be inclined to flag *heart-broken* as suspect and offer *heartbroken*
    as a suggested improvement.
  prefs: []
  type: TYPE_NORMAL
- en: If the word during scoring is expressed as *heart-broken*, then we would first
    drop the hyphen, the same way as we did during training. If the resulting key
    does not match the most likely rewrite, we would flag that instance as suspect.
    In our case, that is what would happen since the most likely rewrite for *heartbroken*
    is *heartbroken* itself. But the text had it as *heart-broken*.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s consider how we would model adjacent words in the training corpus.
    Not hyphenated. Such as *boat house*. Does it read better as *boat house*, *boathouse*,
    or *boat-house*?
  prefs: []
  type: TYPE_NORMAL
- en: To cover such cases, we just need some additional logic as below.
  prefs: []
  type: TYPE_NORMAL
- en: Consider one instance of two adjacent words that appear in the corpus and say
    they happen to be *boat house*. We will derive a new token *boathouse* that fuses
    the two and add an instance of *boat house* to *boathouse* as the key. As depicted
    below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We would expect that *boathouse* would occur much more frequently than *boat
    house* in the corpus. That is, *P*(*boathouse*|*boathouse*) would be much larger
    than *P*(*boat house*|*boathouse*).
  prefs: []
  type: TYPE_NORMAL
- en: '**Generalization in Hyphenation Modeling**'
  prefs: []
  type: TYPE_NORMAL
- en: By generalization, we mean learning rules involving hyphenation that go beyond
    the specific instances we encounter in our training data.
  prefs: []
  type: TYPE_NORMAL
- en: Read on to see specific types of generalization in this setting.
  prefs: []
  type: TYPE_NORMAL
- en: '**Generalizations Involving Specific Prefixes**'
  prefs: []
  type: TYPE_NORMAL
- en: From the training corpus, we might observe that the word *very* is never followed
    by a hyphen. So
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: is incorrect. It should be *very happy*.
  prefs: []
  type: TYPE_NORMAL
- en: This example, and more generally this rule, are from [2].
  prefs: []
  type: TYPE_NORMAL
- en: Can we essentially learn this rule from the data itself?
  prefs: []
  type: TYPE_NORMAL
- en: Yes. Here’s how.
  prefs: []
  type: TYPE_NORMAL
- en: We will use a second map which we will call *hyphenation_prefix_map*. This map’s
    keys will be prefixes. Every time we see this prefix in the training corpus with
    a hyphen immediately following it, we will increment the count of value “1” by
    one. Every time we see this prefix in the training corpus without a hyphen immediately
    following it, we will increment the count of value “0” instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'The logic in the above paragraph looks in pseudocode as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Now let’s illustrate what we do when we see *very-happy* in the text being scored.
    Assume that from the corpus we have learned that
  prefs: []
  type: TYPE_NORMAL
- en: '*P*(next character is -|current word is *very*)'
  prefs: []
  type: TYPE_NORMAL
- en: is zero, or nearly so. We will flag *very-happy* as being suspect and suggest
    dropping the hyphen.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s also note that this solution also covers rules that are described further
    downstream in [2].
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Below are examples, also from [2].
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: In fact, our data-driven learning will do a better job than following this rule
    100% of the time. Let’s elaborate.
  prefs: []
  type: TYPE_NORMAL
- en: There are words that begin with *self* but don’t have a hyphen following the
    prefix. For example, *selfish*.
  prefs: []
  type: TYPE_NORMAL
- en: So our model will learn both the general rule
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: as well as exceptions such as *selfish*. so long as they appear in the training
    corpus.
  prefs: []
  type: TYPE_NORMAL
- en: There is a little bit of tweaking to do to make sure that the rule “*selfish*
    stays *selfish”* fires and not the general rule. This is easy to do but we’ll
    leave it as an exercise to the reader.
  prefs: []
  type: TYPE_NORMAL
- en: '**Generalizations Involving Numbers**'
  prefs: []
  type: TYPE_NORMAL
- en: Consider these examples from [2].
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The hyphenation is correct in the first one. The hyphenation *four-year old*
    wouldn’t be. The absence of hyphenation in the second sentence is correct as well.
  prefs: []
  type: TYPE_NORMAL
- en: Say the term *four-year-old* appears frequently in the training corpus. Extending
    the method we described earlier to work with three adjacent tokens, we could detect
    that *four-year old* should really be *four-year-old*.
  prefs: []
  type: TYPE_NORMAL
- en: Now, what if the text we want to score contains the term *hundred year old*?
    Say this exact term does not appear in the training corpus. We want to be able
    to flag it as suspect and suggest that the writer consider reexpressing it as
    *hundred-year-old*.
  prefs: []
  type: TYPE_NORMAL
- en: This is another example of generalization.
  prefs: []
  type: TYPE_NORMAL
- en: Clearly, we want to be able to learn the pattern <*number*>-*year*-*old* from
    the particular instances that do appear in the corpus.
  prefs: []
  type: TYPE_NORMAL
- en: If we see instances *1-year-old*, *2-year-old*, *one-year-old*, *two-year-old*,
    … in the corpus, from these we can reasonably surmise in principle the pattern
    <*number*>-*year*-*old*.
  prefs: []
  type: TYPE_NORMAL
- en: We will outline, at a high level, one way to approach this problem. We’ll illustrate
    it below.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the instance *2-year-old* in the corpus. As before we will update *stylemap*
    for the key *2yearold*. In addition to that, we will do the following. We will
    recognize *2* as a number using a named entity recognizer, possibly a simple one
    combining dictionary-based and regex-based approaches.
  prefs: []
  type: TYPE_NORMAL
- en: See [8] for a detailed post on named entity recognition in NLP that covers scenarios
    at this level. And ones that are much more elaborate.
  prefs: []
  type: TYPE_NORMAL
- en: We can express what results as the key <*num*>-*year*-*old*. We update this
    key as before. That is,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Now let’s see what we need to do when we see *100 year-old* in a text being
    scored. First, we strip off the hyphen and look up *100yearold* in *style_map*.
    Say it does not exist. Then we recognize *100* as <*num*> and try to lookup <*num*>*yearold*
    in *style_map*. It does exist as a key. Next, we find which styling has the highest
    probability and by a significant-enough margin. In our case, it would be <*num*>-*year*-*old*.
    Next, we substitute back *100* for <*num*>. Finally, we offer the result, *100-year-old*,as
    the suggested reexpression.
  prefs: []
  type: TYPE_NORMAL
- en: Next, consider the following example, also from [2].
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Replacing *fifty-seven* with *fifty seven* would be incorrect.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can learn this pattern automatically from the data. For this, we would want
    to introduce a further distinction in our named entities: *spelled-out number*
    as distinct from *written-out number*. *Five* is a *spelled-out number*. *5* is
    a *written-out number*. Armed with this distinction we can learn the rule that'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: This approach can be refined to cover examples such as the one below, also from
    [2].
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '*two thirds* would be incorrect.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Word Casing**'
  prefs: []
  type: TYPE_NORMAL
- en: This approach also works for certain scenarios in word casing. Such as *fyi*
    is better expressed as *FYI*. We just need to preprocess the token differently.
    This is illustrated below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: That is, when we encounter *FYI* in the corpus, first we lowercase it entirely,
    then add one more instance of *FYI* to be associated with *fyi*.
  prefs: []
  type: TYPE_NORMAL
- en: Once the training has finished, assuming the corpus was sufficiently clean and
    sufficiently rich, *P*(*FYI*|*fyi*) should be much larger than *P*(*fyi*|*fyi*).
    So if we encountered *fyi* in the text being scored, we would suggest replacing
    it with *FYI*.
  prefs: []
  type: TYPE_NORMAL
- en: '**The Apostrophe In Its**'
  prefs: []
  type: TYPE_NORMAL
- en: Say the first word in a particular sentence in the corpus is written as *Its*.
    It should really be *It’s*.
  prefs: []
  type: TYPE_NORMAL
- en: How can we model to detect such an error and recommend a specific fix?
  prefs: []
  type: TYPE_NORMAL
- en: The same approach works here as well. With slightly different preprocessing.
  prefs: []
  type: TYPE_NORMAL
- en: Consider an occurrence of *It’s* in the corpus. We would do the following.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: That is, we strip off the apostrophe giving us *Its*. We then add one more instance
    of *It’s* to be associated with *Its*.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that in this case, we did not downcase *It’s* only stripped off the apostrophe.
    This is because we want to retain that the *i* in *I*t’s was in upper case.
  prefs: []
  type: TYPE_NORMAL
- en: Once the training has finished, assuming the corpus was sufficiently clean and
    sufficiently rich, *P*(*It’s*|*Its*) should be much larger than *P*(*Its*|*Its*).
    So if we encountered *its* as the first word in a sentence being scored, we would
    first convert it to *Its*, then suggest replacing this *Its* with *It’s*.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, if we see *Its* as the first word in a sentence, we should recommend
    replacing it with either *It’s* or *It is*. We can extend our model to learn to
    offer the second suggestion as well in a straightforward way. We will leave this
    an exercise for the reader.
  prefs: []
  type: TYPE_NORMAL
- en: '**Missing Commas**'
  prefs: []
  type: TYPE_NORMAL
- en: Consider the examples we saw earlier.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: In each case, there should be a comma after the first word in the sentence.
  prefs: []
  type: TYPE_NORMAL
- en: Below, we’ll dive into how to detect that a comma is missing in such scenarios.
    We will focus only on these scenarios, specifically ones in which the *first*
    word or two (or three) in a sentence should be followed by a comma.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting commas in more nuanced situations, i.e. somewhere in the middle of
    a sentence, is trickier. We will address this problem in a future post.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll use the same method we used earlier for other use cases. Except that we
    will only apply it to a word that begins a sentence.
  prefs: []
  type: TYPE_NORMAL
- en: For every word in the lexicon that begins a sentence in the training corpus,
    we will track how often it is followed by a comma versus not. After training,
    we can detect missing commas in the manner we described for our earlier use cases.
  prefs: []
  type: TYPE_NORMAL
- en: '**How This Relates To Association Rules**'
  prefs: []
  type: TYPE_NORMAL
- en: The main method we discussed in this post may be seen as an instance of mining
    association rules.
  prefs: []
  type: TYPE_NORMAL
- en: Viewed this way, the various map data structures that we used encode specific
    association rules of the form
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The probabilistic inference we used, for detecting whether a particular rule
    should fire or not, is called *confidence* in the language of mining association
    rules. It took the form of *P*(*Y*|*X*).
  prefs: []
  type: TYPE_NORMAL
- en: In association rules mining, an alternative called *lift* is often used. See
    [9] for more on associative rules and lift.
  prefs: []
  type: TYPE_NORMAL
- en: '**Summary**'
  prefs: []
  type: TYPE_NORMAL
- en: In this post, we discussed the topic of detecting and correcting issues in text
    as it is being written. This use case has tremendous value, from improving emails
    as they are being written, to helping writers improve their writing as they are
    putting together longer articles.
  prefs: []
  type: TYPE_NORMAL
- en: This is what makes Grammarly so popular.
  prefs: []
  type: TYPE_NORMAL
- en: In this post, we covered the following types of common errors with examples.
  prefs: []
  type: TYPE_NORMAL
- en: Missing commas.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Missing articles.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leaving out the apostrophe in *It’s*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using singular instead of plural, or vice-versa.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a hyphen when it shouldn’t be used, or vice-versa.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Casing words. Not capitalizing a letter when one should. Not having a word in
    all caps when one should. E.g., *fyi*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the wrong preposition, or using one when it is not needed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In each case, we described the issue with real examples. Often nuances emerged.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we took a second pass over these issues in which we discussed methods
    from statistical NLP that help detect and address them. We discussed training
    data, feature engineering, and some specific statistical models that fit these
    use cases.
  prefs: []
  type: TYPE_NORMAL
- en: '**References**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Of vs. For: Differences and Proper Grammar Use | YourDictionary](https://grammar.yourdictionary.com/vs/of-vs-for-differences-and-proper-grammar-use.html)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[When to Use a Hyphen: eContent Pro](https://www.econtentpro.com/blog/when-to-use-a-hyphen/8)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[ChatGPT: Optimizing Language Models for Dialogue](https://openai.com/blog/chatgpt/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Wikipedia:Database download](https://en.wikipedia.org/wiki/Wikipedia:Database_download)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[NLTK Tokenize: Words and Sentences Tokenizer with Example](https://www.guru99.com/tokenize-words-sentences-nltk.html)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Poisson distribution — Wikipedia](https://en.wikipedia.org/wiki/Poisson_distribution)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[On a Distribution Representing Sentence-Length in Written Prose](https://www.jstor.org/stable/2345142)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Named Entity Recognition in NLP. Real-world use cases, models, methods…](/named-entity-recognition-in-nlp-be09139fa7b8)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Association rule learning — Wikipedia](https://en.wikipedia.org/wiki/Association_rule_learning)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Grammarly](https://app.grammarly.com/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Contextual Text Correction Using NLP, Arun Jagota, Towards Data Science, Medium](https://jagota-arun.medium.com/contextual-text-correction-using-nlp-81a1363c5fc3)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
