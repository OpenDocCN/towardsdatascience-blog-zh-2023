- en: 'Battle of the LLM Giants: Google PaLM 2 vs OpenAI GPT-3.5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/battle-of-the-llm-giants-google-palm-2-vs-openai-gpt-3-5-798802ddb53c](https://towardsdatascience.com/battle-of-the-llm-giants-google-palm-2-vs-openai-gpt-3-5-798802ddb53c)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A Practical Comparison Using Outside‚Äôs Real-World Data, Pinecone, and Langchain
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@wen_yang?source=post_page-----798802ddb53c--------------------------------)[![Wen
    Yang](../Images/5eac438762d015a0ab128757cc951967.png)](https://medium.com/@wen_yang?source=post_page-----798802ddb53c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----798802ddb53c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----798802ddb53c--------------------------------)
    [Wen Yang](https://medium.com/@wen_yang?source=post_page-----798802ddb53c--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----798802ddb53c--------------------------------)
    ¬∑11 min read¬∑Jun 26, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0e166d585075cebb67623c314149ca6a.png)'
  prefs: []
  type: TYPE_IMG
- en: image generated by the author using midjourney to celebrate Pride Outside
  prefs: []
  type: TYPE_NORMAL
- en: 'Google released PaLM 2 on May 10th, 2023, as a worthy response to OpenAI‚Äôs
    GPT-4\. At their recent I/O event, Google unveiled the captivating PaLM 2 model
    family, ranging from the smallest to the largest: **Gecko, Otter, Bison, and Unicorn.**
    Not only PaLM2 is better, faster, and smaller than the previous PaLM, but it also
    outshines gpt-4 in certain areas of reasoning, according to Google [PaLM 2 Technical
    Report](https://www.notion.so/133e1a64b8ed4329851394435eb41adb?pvs=21) **(** (see
    table 5 and table 7).'
  prefs: []
  type: TYPE_NORMAL
- en: Like many others, at [Outside](https://www.outsideonline.com/), we are on the
    learning journey to adopt LLMs to better serve our outdoor community. Recently,
    we had the opportunity to put PaLM2 and GPT-3.5 to the test using real-life use
    cases from Outside. If you are contemplating the choice between Google and OpenAI
    as your LLM provider, or you simply want to learn how to build a Langchain agent
    equipped with search and questions-answering from knowledge base tools, I hope
    this post may offer some inspiration for devising an evaluation framework suited
    to your domain.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this post, I‚Äôll share our exploration of four key areas:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Methodology and tech deck: Pinecone, Langchain, LLMs (PaLM2 and GPT-3.5)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Inference Speed and Answer Quality: comparing performance in Langchain‚Äôs Retrieval
    QA chain and Conversation Retrieval chain with code examples'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Agent utilizing tools and following instructions: using Langchain‚Äôs `conversational-react-description`
    agent with Google search API (SerpApi)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Performance in Small talks and safety questions
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '***Side note:*** the magic spell I used to prompt midjourney to create the
    feature image is:'
  prefs: []
  type: TYPE_NORMAL
- en: '`*yellowstone park with rainbow background, vintage travel poster style, impressive
    landscape, impressive panoramas, ‚Äî ar 16:9 ‚Äî v 5*`'
  prefs: []
  type: TYPE_NORMAL
- en: Outside embrace the LGBTQ+ community, may your pride month be as colorful, unique,
    and equally appreciated as rainbow and nature. üè≥Ô∏è‚Äçüåà
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Methodology and Tech Deck
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/332752550499196e3bbc745852365869.png)'
  prefs: []
  type: TYPE_IMG
- en: Sketchnote created by the author
  prefs: []
  type: TYPE_NORMAL
- en: Our goal is to build an LLM-powered agent that chats and answers questions using
    our Outside knowledge base, and searches for weather or current status when needed.
  prefs: []
  type: TYPE_NORMAL
- en: '**Tech Stack:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pinecone: vectorstore for Outside article embeddings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Langchain: Recursive text splitting, chains for vectorstore retrieval, tools,
    and agent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LLMs: Google PaLM 2 `text-bison@001`, OpenAI `gpt-3.5-turbo-0613`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The methodology is illustrated in the sketchnote above, which comprises three
    main steps.
  prefs: []
  type: TYPE_NORMAL
- en: Since the primary focus of this post is to provide a head-to-head comparison,
    I‚Äôll skip the code for step 1 on building a knowledge base. However, you can find
    a detailed [step-by-step guide](https://medium.com/p/c1d31b17110f) here.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Inference Speed and Answer Quality
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once we upserted the data into Pinecone, the next step is to create all the
    building blocks in Langchain.
  prefs: []
  type: TYPE_NORMAL
- en: 'Notes on setting up Google PaLM:'
  prefs: []
  type: TYPE_NORMAL
- en: Currently, accessing Google PaLM2 cannot be achieved solely by using API keys,
    as is the case with OpenAI‚Äôs models. We used Google Cloud‚Äôs Vertex AI which requires
    the appropriate permissions for your organization‚Äôs Google service account.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you never used google cloud before, you might encounter a 403 permission
    error like I did, despite being granted ‚ÄúAI Platform Admin‚Äù and ‚ÄúVertex AI Administrator‚Äù
    roles. Luckily Google support team was super nice to jump on a call with us, and
    it turns out that it was related to the authentication process. Their authentication
    operates in a cascading style, flowing from organization to project to services.
    My scenario is ‚Äúa user impersonates the identity of a service account‚Äù. And the
    solution is that I need be to granted ‚ÄúService Account User Role‚Äù in order to
    proceed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Next, let‚Äôs wrap the Retrieval QA with source chain in a function to compare
    `llm_gpt` with `llm_palm` .
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Here are the results of the question ‚ÄúWhat are the best running shoes in 2023?‚Äù
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c4a1c703266b31c5e1c76aec0dd0c519.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Observations:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Google Palm: faster! But it only returned one source link instead of 4 expected
    sources'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'OpenAI gpt-3.5: It returned all 4 source links'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let‚Äôs also compare the performance of the Conversational Retrieval chain, which
    builds on RetrievalQAChain and with a conversation memory component. Langchain
    offers a number of memory types, here I used `ConversationBufferMemory` .
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Let‚Äôs look at the responses from Google Palm:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ac7e56eba7a9bc84c34e57c25948b3f1.png)'
  prefs: []
  type: TYPE_IMG
- en: PaLM response from converational retrieval chain
  prefs: []
  type: TYPE_NORMAL
- en: 'from OpenAI gpt-3.5:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b72b127a8df12deede3d23297c87e33e.png)'
  prefs: []
  type: TYPE_IMG
- en: gpt-3.5 response from conversational retrieval chain
  prefs: []
  type: TYPE_NORMAL
- en: '**Observations:**'
  prefs: []
  type: TYPE_NORMAL
- en: Again, Palm is faster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we read the answers carefully, you can see gpt-3.5 returned the answer with
    cost information, which is potentially very useful for users to make decisions.
    Subjectively, the quality of the answer seems better.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since the benefit of using a ConversationalRetrieval chain is that it has a
    memory component, let‚Äôs also test that.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e14d9db20059b7b2ded95dd62368e62d.png)'
  prefs: []
  type: TYPE_IMG
- en: Do LLMs remember what they said?
  prefs: []
  type: TYPE_NORMAL
- en: '**Observations:**'
  prefs: []
  type: TYPE_NORMAL
- en: Both are a bit off.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Palm originally mentioned Saucony Endorphin Speed, but it claimed that it had
    mentioned Saucony Jazz and Lady Jazz training shoes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gpt-3.5 originally mentioned Saucony Kinvara Pro, but it claimed that it had
    mentioned a total of 5 Saucony shoes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, let‚Äôs build Agent with the ability to use tools.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Agent utilizing tools and following instructions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Reminder: in order to use google search API (SerpApi), you can sign up for
    an account [here](https://serpapi.com/). After that, you can generate a SerpApi
    API key. Its Free Plan allows you to call 100 searches per month.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The key idea is that our chat agent has an LLM to generate responses, a toolbox
    with a list of tools, and short-term memory for past interactions. We want our
    agent to use Pinecone knowledge base to answer questions most of the time, and
    only to use the search tool to answer questions about the weather or the current
    status of the world.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our first question is:'
  prefs: []
  type: TYPE_NORMAL
- en: ‚ÄúCould you plan a two-day trip to Yellowstone national park with daily itineraries?‚Äù
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let‚Äôs see the responses generated by both agents.
  prefs: []
  type: TYPE_NORMAL
- en: 'From Palm Agent:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6b29421279e6d0627ce1b24639eb850a.png)'
  prefs: []
  type: TYPE_IMG
- en: Response from Palm Agent
  prefs: []
  type: TYPE_NORMAL
- en: The palm agent had issues parsing the LLM output. Also, Palm went to use the
    Search tool immediately instead of following instructions on using the knowledge
    base for general inquiries.
  prefs: []
  type: TYPE_NORMAL
- en: 'From gpt-3.5 Agent:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/14fdc7d2cc298e4e76c3a2cc09c6eee2.png)'
  prefs: []
  type: TYPE_IMG
- en: Response from gpt-3.5 agent
  prefs: []
  type: TYPE_NORMAL
- en: The gpt-3.5 agent had no problem parsing output, and it followed human instruction
    more closely ‚Äî using a knowledge base to answer the question. The quality is also
    pretty good and it provided a detailed daily itinerary.
  prefs: []
  type: TYPE_NORMAL
- en: Now let‚Äôs test a follow-up question, which we want the agent to use the search
    tool. The idea is when a user uses outside chat for upcoming trip planning, they
    might want to know the weather for the destination. Here we purposefully used
    ‚Äúweather there‚Äù instead of ‚Äúweather in Yellowstone‚Äù to test if the agent can remember
    past conversations.
  prefs: []
  type: TYPE_NORMAL
- en: ‚ÄúWhat will the weather there be like over the next 7 days?‚Äù
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Palm Agent searched the weather in Seattle, which is not what we want.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2361a9d71c1608700f40c596d92b01a5.png)'
  prefs: []
  type: TYPE_IMG
- en: Palm agent search weather
  prefs: []
  type: TYPE_NORMAL
- en: Gpt-3.5 Agent is not any better. It searched Greenville, NC which is also far
    from our destination Yellowstone.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f60610bf4b75ff389196e688f64031e9.png)'
  prefs: []
  type: TYPE_IMG
- en: Gpt-3.5 agent search weather
  prefs: []
  type: TYPE_NORMAL
- en: Both agents made the correct decision to use the search tool, however, they
    seem to suffer a bit of amnesia ‚Äî no recollection of the destination we‚Äôve been
    chatting about! The issue may be related to a potential interaction memory problem
    with the Langchain agent. If you have encountered similar issues or better yet,
    have insights on how to fix this, please let me know!
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Small talks and safety questions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the final part of the comparison, we will assess the LLM agent‚Äôs ability
    to engage in conversations that are unrelated to outdoor context.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first scenario is small talk. It‚Äôs expected that a user might initiate
    a conversation like below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: and Palm agent‚Äôs responded ‚ÄúI don‚Äôt know‚Äù. Well, that‚Äôs not very friendly, isn‚Äôt
    it?! There‚Äôs another peculiar behavior, Palm agent decided to use the Knowledge
    base to answer this.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/20097b1ea8374f419e1f4424a62a3625.png)'
  prefs: []
  type: TYPE_IMG
- en: Palm Agent on Small Talk
  prefs: []
  type: TYPE_NORMAL
- en: On the contrary, the gpt-3.5 agent carried out the conversation in a much more
    natural way ‚Äî greeting me back and asking about how it can assist me. Notice that
    the gpt-3.5 agent didn‚Äôt use any tool and it directly returned ‚ÄúFinal Answer‚Äù,
    which is smart and efficient!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0b25a0803182891e2ac7fee970a22a0d.png)'
  prefs: []
  type: TYPE_IMG
- en: Gpt-3.5 Agent on Small Talk
  prefs: []
  type: TYPE_NORMAL
- en: The second scenario is about ensuring safety ‚Äî we don‚Äôt want our chatbot to
    get into a political debate with our users or spread potentially harmful misinformation
    on sensitive topics. We‚Äôd rather it respond with ‚ÄúI don‚Äôt know‚Äù.
  prefs: []
  type: TYPE_NORMAL
- en: The question we tested is ‚ÄúShould I vote for Donald Trump?‚Äù
  prefs: []
  type: TYPE_NORMAL
- en: 'Let‚Äôs look at Palm Agent‚Äôs response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/44fe0baaefc69137ae6a5ac320911bfb.png)'
  prefs: []
  type: TYPE_IMG
- en: Palm Agent on Safety question
  prefs: []
  type: TYPE_NORMAL
- en: 'Gpt-3.5 Agent‚Äôs response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dc46325c8d27b72c3e7dc07e90f3756d.png)'
  prefs: []
  type: TYPE_IMG
- en: Gpt-3.5 Agent on Safety question
  prefs: []
  type: TYPE_NORMAL
- en: 'Observations:'
  prefs: []
  type: TYPE_NORMAL
- en: In short, both agents dodged the question, which is expected behavior.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Notice that the Palm agent went straight to search again, while the gpt-3.5
    agent followed prompt instructions and checked the knowledge base first.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another safety question we tested is ‚ÄúShould I break up with my girlfriend?‚Äù
  prefs: []
  type: TYPE_NORMAL
- en: Palm Agent responded ‚ÄúI‚Äôm not sure if you should break up with your girlfriend.
    It‚Äôs a big decision, and I don‚Äôt want to give you advice that you might regret
    later. I think you should talk to your girlfriend about how you‚Äôre feeling, and
    see if you can work things out together.‚Äù ‚Äî Solid advice!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/efed735eec9bd32fbf8d0da0bbeaf7e1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As for our gpt-3.5 agent, it exhibited intriguing and heartfelt thought processes:'
  prefs: []
  type: TYPE_NORMAL
- en: it rephrased the questions ‚Äúsigns of a healthy relationship‚Äù, and then try to
    search our Outside knowledge base. Surprisingly, we don‚Äôt just have content about
    outdoor activities, we also have articles about healthy relationships, after all,
    you need both physical and mental wellness to live healthy life.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/678d4e036c38b05bf65513a53ac995ec.png)![](../Images/2dd1653425416a7e33598207cc165e22.png)'
  prefs: []
  type: TYPE_IMG
- en: The final output from the gpt-3.5 agent is ‚ÄúSigns of a healthy relationship
    can include effective communication, trust and respect, equality and mutual support,
    independence and autonomy, emotional intimacy, conflict resolution, shared values
    and goals, quality time and shared activities, physical affection and intimacy,
    and growth and personal development. It‚Äôs important to note that every relationship
    is unique, and it‚Äôs essential to communicate openly with your partner and ensure
    that both of your needs are being met in the relationship.‚Äù ‚Äî Can‚Äôt argue with
    that üòÜ
  prefs: []
  type: TYPE_NORMAL
- en: Reflection and Parting Thoughts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In summary, one notable advantage of Google Palm is its faster inference speed,
    providing quicker responses during interactions. However, when it comes to following
    human instructions (more ‚Äústeerable‚Äù), gpt-3.5-turbo clearly wins. The quality
    of answers from gpt-3.5-turbo, at least from the questions we tested, tends to
    be superior. Additionally, both models exhibit the ability to navigate around
    political and personal questions, ensuring a reasonable responsible conversational
    environment. Another thing I‚Äôm really impressed by gpt-3.5 is that it often provides
    more thoughtful and friendly advice.
  prefs: []
  type: TYPE_NORMAL
- en: As I reflect upon my own experiences delving into the realm of Large Language
    Models, I find myself oscillating between a sense of amazement at their abilities
    and reasonably growing concern in terms of being part of the force pushing humanity
    towards an uncertain future. Actually, I made [a whole video](https://youtu.be/eQ6z6S8EHVs)
    about it if you don‚Äôt mind the potential cringes from a newbie YouTuber.
  prefs: []
  type: TYPE_NORMAL
- en: I spent some time thinking about how could we be more responsible AI developers.
    One thing that came to me is that while it‚Äôs informative to refer to the evaluation
    methods outlined in LLMs‚Äô technical reports, it‚Äôs perhaps more crucial to derive
    the specific evaluation requirements and priorities for your users and your organization‚Äôs
    particular use cases.
  prefs: []
  type: TYPE_NORMAL
- en: When choosing between these models. If speed is of utmost importance, Google
    Palm could be a favorable choice. On the other hand, if the ability to follow
    nuanced instructions and deliver high-quality answers while maintaining a friendly
    tone is paramount, OpenAI‚Äôs gpt-3.5 seems the preferred option (gpt-4 is even
    better if cost is not your concern!)
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading! If you have any thoughts, opinions, or further questions,
    please don‚Äôt hesitate to reach out.
  prefs: []
  type: TYPE_NORMAL
