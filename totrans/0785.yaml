- en: Effective Unit Testing in Python — with Examples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/effective-unit-testing-in-python-with-examples-3860d7fac7cd](https://towardsdatascience.com/effective-unit-testing-in-python-with-examples-3860d7fac7cd)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@christopher_karg?source=post_page-----3860d7fac7cd--------------------------------)[![Christopher
    Karg](../Images/9d163d59e0c3167732f55d497caf9db2.png)](https://medium.com/@christopher_karg?source=post_page-----3860d7fac7cd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3860d7fac7cd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3860d7fac7cd--------------------------------)
    [Christopher Karg](https://medium.com/@christopher_karg?source=post_page-----3860d7fac7cd--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3860d7fac7cd--------------------------------)
    ·16 min read·Oct 1, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4d3e4fc2d2cb528b00e0e5676f4becb5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [https://www.pexels.com/photo/red-vintage-car-stopped-on-the-crossroads-15706251/](https://www.pexels.com/photo/red-vintage-car-stopped-on-the-crossroads-15706251/)'
  prefs: []
  type: TYPE_NORMAL
- en: My next article is on the subject of unit-testing in Python. It is a topic that
    I found is often overlooked in lessons, books and online tutorials. It is however
    a crucial skill when creating production-level, bullet-proof code. The scenarios
    in this article are somewhat skewed toward the world of data/data science. As
    such, my opinion of an ‘effective’ unit-test may differ to someone coming from
    a different background.
  prefs: []
  type: TYPE_NORMAL
- en: The ultimate aim of writing unit-tests is to prevent bugs being pushed into
    production.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The result of which leads to many headaches and time to resolve. Different companies
    have different testing methodologies. Some projects I have worked on (specifically
    web-scraping projects) have not required unit-testing per se but can benefit from
    implementing python’s [inbuilt logging functionality](https://docs.python.org/3/library/logging.html)
    and try/except handling. This article only covers the practical implementations
    of [unit-testing](https://docs.python.org/3/library/unittest.html?highlight=unittest#module-unittest)
    along with examples and links to code that are available in [my GitHub repo](https://github.com/CMaxK/unittesting_examples).
    Feel free to clone it and have a play with some of the testing functions — instructions
    on how to do so can be found in the README of the repo. The repo is split into
    Easy, Medium and Hard categories, each building upon the concepts covered in the
    previous category.
  prefs: []
  type: TYPE_NORMAL
- en: The easy and medium examples in this article go over testing syntax and how
    to use certain features of the unit-testing library. The harder example builds
    on the easy and medium examples but also introduces the idea of ‘***effective***’
    unit-testing and what exactly you should be testing. It is all well and good if
    you are writing unit-tests but if you are testing for irrelevant things, the unit-tests
    themselves become somewhat irrelevant!
  prefs: []
  type: TYPE_NORMAL
- en: 'In a production environment, these tests would be incorporated into a CI/CD
    pipeline so they run automatically when code is updated. This is somewhat outside
    the scope of the article but in summary the general process would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: · Create test scripts
  prefs: []
  type: TYPE_NORMAL
- en: · Create a configuration file for your chosen CI/CD service (GitHub Actions,
    Travis CI, Jenkins etc.) The config file allows you to specify a task name, what
    commands are to be run within the task and the location of the scripts you want
    to run
  prefs: []
  type: TYPE_NORMAL
- en: · Push config file and test scripts to code repo (GitHub/GitLab)
  prefs: []
  type: TYPE_NORMAL
- en: · If the CI/CD service is correctly set-up the tests will be incorporated into
    the pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: · Notifications of failed tests can be sent out via Slack or Email to ensure
    any issues can be resolved quickly.
  prefs: []
  type: TYPE_NORMAL
- en: I will embed the relevant code for each category at the start of each section.
    A link to the respective GitHub repo will also be included.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll start with the Easy category.
  prefs: []
  type: TYPE_NORMAL
- en: Easy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: General unit-testing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to set-up and run testing functions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the [repo](https://github.com/CMaxK/unittesting_examples/tree/master/Easy)
    I have created two functions. One that simply adds two numbers. The 2nd function
    computes the factorial of a given number:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s swap our attention to the testing script (tests.py):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Notice I have imported the functions I want to test at the top of the tests.py
    script along with python’s unittest library. Within the this script you can see
    1 class has been instantiated, along with 5 different functions. Each function
    serves as a single test. Therefore in this example I am writing 5 unit-tests for
    a script containing 2 functions.
  prefs: []
  type: TYPE_NORMAL
- en: Again depending on your desired testing methodology, you may choose to write
    one meaningful test per function, multiple tests per function (encouraged if the
    function is complex), or to combine it with log messages and try/except blocks
    (as you will see in the latter examples) to catch all cases where your code may
    break. In the interests of risk aversion, I would advise writing as many meaningful/effective
    tests as possible. The idea of what constitutes an effective test is discussed
    later in the article.
  prefs: []
  type: TYPE_NORMAL
- en: As I am testing fairly straightforward functions, their logic is not that complex.
    We simply perform specific computations on the function inputs. The most effective
    way to test these functions is by checking the output is what we expect. Take
    the first example — we expect the output of 2+3 to be 5\. To write check using
    the unittesting library, we use the *self.assertEqual* method. Another term for
    this type of test is an ‘assertion test’.
  prefs: []
  type: TYPE_NORMAL
- en: We have our first unit-test written. Let’s check it works.
  prefs: []
  type: TYPE_NORMAL
- en: 'From within the Easy directory run:'
  prefs: []
  type: TYPE_NORMAL
- en: '***python -m unittest tests.py***'
  prefs: []
  type: TYPE_NORMAL
- en: The above command is us telling the python interpreter to run the tests.py script
    using the unittest module. The ***-m*** stands for module.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of our command looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/39d1d83a8170beafbd229a13fc2aceb4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For the sake of testing let’s see the output if the unit-test were to fail.
    I will change the assertion so that 2+3=6 (incorrect…):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/47559fba29f5e837aff9201aa533674c.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see the above test failed. The output of the function was 5\. We told
    the system we were expecting 6\. As you can see the output is very verbose by
    default and allows you to fairly quickly get to the bottom of the issue.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s run all of our 5 tests for the 2 functions and check the output. This
    time we will add the ***-v*** marker to increase verbosity:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b84c9c3604fa7f6a039d50e3556385ba.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see that adding the ***-v*** marker makes it easy to see exactly which
    testing functions are being called. It’s always a good feeling when all tests
    pass 
  prefs: []
  type: TYPE_NORMAL
- en: 'One testing function I’d like to point out is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'If you check back to our original factorial function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: You can see that a factorial computation is not possible for any number less
    than 0\. As per the above code we wanted to raise a ValueError with a comment
    if this error is triggered. If we are taking the effort to catch errors in our
    code, we must also make the effort to trigger these errors in our tests. We ultimately
    need to ensure our function also fails as intended. The test of this function
    is also to be considered an assertion test, however rather than asserting output
    == expected value, we are testing to ensure the ValueError is raised as intended.
    There are other types of assertion test all listed within python’s extensive unit-testing
    [documentation](https://docs.python.org/3/library/unittest.html?highlight=unittest#module-unittest).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s move to the more challenging tests.
  prefs: []
  type: TYPE_NORMAL
- en: Medium
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Patching function outputs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Move into the [Medium directory](https://github.com/CMaxK/unittesting_examples/tree/master/Medium)
    for these tests. Here we build upon the previous examples of assertion tests and
    begin to patch the function outputs we have created within our ***get_weather_data.py***
    script. This script looks to replicate a typical request to an imaginary weather
    API and returns a response JSON that we will look to analyse within our script.
    The ***get_weather_data.py*** is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The use case for this may not be immediately obvious but it is very useful for
    testing your code logic if you do not actually have access to the API in question.
    Since we are making a request to an imaginary API, the function will not return
    any data. How are we supposed to test the remaining code if it breaks after the
    first line? This is where patching comes in handy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s move our attention to the testing script to see how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the imports. They’re similar to the easy example, only now we have also
    included the patch decorator that is imported from the ***unittest.mock*** library.
    Let’s take the first test as an example and go through the syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: As per the previous example, we create out test class. Then we implement a function
    [decorator](https://docs.python.org/3/glossary.html#term-decorator). Decorators
    modify/extend the behaviour of a function — I’d suggest researching a little if
    you are new to the concept. In this example, we use the decorator to ‘mock’ the
    behaviour of the requests.get function call in our ***get_weather_data.py*** script.
    This allows us to control the behaviour of the function call and change the return
    value. This way we can insert an expected return value/s without actually making
    a call to the imaginary API (which would not work anyway). This allows us to test
    our function logic without needing access to the API. The calls to the function
    are replaced with a mock object — ***mock_get***.
  prefs: []
  type: TYPE_NORMAL
- en: The next line looks like a regular function definition, the only thing here
    is that we are passing the ***mock_get*** parameter (the object that is being
    used to replace the ***requests.get*** function call). This allows us to inject
    the mock object into the function for later use.
  prefs: []
  type: TYPE_NORMAL
- en: Next we create a ***mock_response*** object as the return value of the mock_get
    object. Any call to ***mock_get*** will return this ***mock_response*** object.
  prefs: []
  type: TYPE_NORMAL
- en: Now we will set certain variables within our defined function to an expected
    output. This will allow us to test the logic of the function without actually
    making a call to the API. We assign mock_response.status_code = 200\. This simulates
    a successful HTTP response as defined in our ***get_weather_data()*** function
    within our ***get_weather_data.py*** script. We also assign a JSON response to
    mock_response.json.return_value. This again simulates the behaviour of the function
    we want to test.
  prefs: []
  type: TYPE_NORMAL
- en: Next we make an actual call to the main function within the script. Notice this
    function calls the function for which we previously mocked the return values.
    We are now able to run this function with the expected (fake) return values to
    test the overall logic. The output is saved to the ‘result’ variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'So take a moment to double check what variables we mocked above and how this
    should affect the output of the function. The ***status_code = 200***, the JSON
    returns a value of ***{‘temperature’: 30, ‘humidity’: 60}***. When checking the
    logic of the actual function we are testing (***analyze_weather()***), we want
    the return value to be “Hot and dry”, thus we create an assertion test, passing
    in the result variable and checking it equals the expected function output.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When running this test with the verbosity marker we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fabb0342ed07589fab102d36947d8222.png)'
  prefs: []
  type: TYPE_IMG
- en: Excellent.
  prefs: []
  type: TYPE_NORMAL
- en: The 3 further testing functions use a similar methodology to the easy problem,
    we are checking how various inputs trigger the expected logic within the functions
    through assertion checks. In the final test we are triggering an error by passing
    in a 404 status code to mimic a failed API call. We want this to trigger our Exception
    clause within the ***get_weather_data()*** function.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ab5b6b03b81426583fece1e10d54e9fa.png)'
  prefs: []
  type: TYPE_IMG
- en: Which we succeed in doing.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s move to the hard example.
  prefs: []
  type: TYPE_NORMAL
- en: Hard
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ‘Effective’ unit-testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Side-effect
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a sample JSON file/data as the return value of an API call.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The repo for the Hard example can be found [here](https://github.com/CMaxK/unittesting_examples/tree/master/Hard).
    We will cover the examples after a few words on ***effective*** unit-testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'What makes an ***effective*** unit-test? As with many things in data science
    the answer depends on your scenario. In my opinion unit-tests come into their
    own in the initial stages of a project i.e. when you are gathering data or writing
    ETL scripts to handle data transfer from a 3rd party or an internal database.
    This allows you to track the quality of your data and ensure it is formatted the
    way you are expecting. Of course further downstream transformations probably need
    to occur and more unit-tests need to be implemented elsewhere in your pipeline
    but it helps to know you are working with the correct data in the first place.
    I believe effective unit-tests in this initial stage should cover the following
    areas:'
  prefs: []
  type: TYPE_NORMAL
- en: · **Is the schema correct?**
  prefs: []
  type: TYPE_NORMAL
- en: Are the correct number of columns present?
  prefs: []
  type: TYPE_NORMAL
- en: Are all required columns present?
  prefs: []
  type: TYPE_NORMAL
- en: Does the data actually contains records?
  prefs: []
  type: TYPE_NORMAL
- en: Changes to the schema can lead to data integration issues/bugs
  prefs: []
  type: TYPE_NORMAL
- en: · **The values within the data**
  prefs: []
  type: TYPE_NORMAL
- en: Check for a certain number of null values
  prefs: []
  type: TYPE_NORMAL
- en: A lot of discrepancies/anomalies can indicate data quality issues and can be
    raised to the owner of the data source.
  prefs: []
  type: TYPE_NORMAL
- en: · **Semantics**
  prefs: []
  type: TYPE_NORMAL
- en: Do columns have the expected dtypes or units? Is your ***distance*** column
    in miles as expected or has it been changed to km? Is the ***employee_count***
    column an integer as expected or is it a float? Your calculations would be thrown
    off if something like this were to be misinterpreted.
  prefs: []
  type: TYPE_NORMAL
- en: The idea of testing for these specific criteria can be linked to the idea of
    data contracts, which include the above pointers as well as monitoring SLA’s (focussing
    on data accessibility/availability). If you are interested in the topic I’d advise
    looking through some of [Chad Sanderson’s content on LinkedIn](https://www.linkedin.com/in/chad-sanderson/).
    All of the above fits into the bigger picture of quality assurance and regulatory
    requirements (GDPR etc.)
  prefs: []
  type: TYPE_NORMAL
- en: Another tip is to ensure that your code fails gracefully and actually produces
    the descriptive error messages you or another developer require to fix the error.
    By writing tests to ensure graceful failure you will save yourself and others
    a lot of time.
  prefs: []
  type: TYPE_NORMAL
- en: Coming back to the code…
  prefs: []
  type: TYPE_NORMAL
- en: 'Check the code within the ***get_company_data.py*** script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: You can see it is very similar to our previous example only here we use slightly
    different logic where we are also checking for schema related issues. I have left
    space in the script for you to edit and possibly implement some of the checks
    I listed in the bullet points above.
  prefs: []
  type: TYPE_NORMAL
- en: 'A big difference here is that we import a JSON file containing what could be
    a sample output from an API. Check the JSON file within this directory to see
    how it is formatted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This method is how one would potentially test their code using a sample output
    from an API endpoint provided by a 3rd party provider. Simply import the JSON
    and mock the output of the ***requests.get*** function which you can see we have
    done in lines 10+11 of the test script.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you look through the top of the test script it contains very similar syntax
    to what we covered in our previous examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: For the sake of experimentation, I have adapted the syntax somewhat from line
    14 onwards. Rather than creating a ***mock_response object*** by setting it equal
    the ***return_value*** of the mock object (***mock_get***), I have simply create
    a response object by calling the imported ***Mock*** class directly. I would consider
    creating the mock_response object using mock_get.return_value to be the better
    practice and more pythonic — after all [explicit is better than implicit](https://peps.python.org/pep-0020/).
  prefs: []
  type: TYPE_NORMAL
- en: Once the mock object is created, we assign the return values and assign the
    data for company_2 to be the initial return value as we want to double check the
    schema provided is correct. Again we also modify the behaviour of the ***requests.get***
    function call to return the mock response.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we call the function in line 20 we start our assertion checks. Here we
    are ultimately checking the data contains the columns we might require as input
    to downstream algorithms. It is at this stage that if the data does not contain
    a desired datapoint, the tests would fail as we see below (for the sake of testing
    I have included a check for a column named ‘***dogs***’):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2b6335bee29d14410acf03bfc0ea5cc7.png)'
  prefs: []
  type: TYPE_IMG
- en: As we can see the assertion test failed as ‘***dogs***’ was not found in the
    schema.
  prefs: []
  type: TYPE_NORMAL
- en: 'On line 40 we see a new mock_response is created as we want to test the result
    of a 404 error. It is in this code that I introduce the concept of side_effect
    (line 42). In Python, the side_effect attribute of a mock object is used to define
    custom behaviour of a specific method or function. It allows you to define what
    should happen if the method is invoked such as raising exceptions or returning
    specific values etc. A common use is to test different behaviours for multiple
    calls to the same method. I’ll include a brief example for ease of understanding
    below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Let’s return to our original company example in ***test_company_data.py***.
    In line 42 we set the ***side_effect*** object to an exception with a custom message.
    That means when we later call ***mock_repsonse.json()***, it will raise this custom
    exception. Finally we set the ***mock_get.return_value*** equal to the previously
    coded return values of the mock_response object.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, from line 52 onwards, we set-up a [context manager](https://docs.python.org/3/glossary.html#term-context-manager)
    using a self.assertRaises method. It specifies that an exception of type ‘Exception’
    is expected to be raised within this code block. This makes sense as company_1
    (the company we are testing within this new mock_object) has a confidence_score
    of 0.8\. Our code should only accept companies with a confidence score of 0.9
    or higher, otherwise an Exception is thrown. This is the desired behaviour and
    we are checking to confirm this is indeed the case. We check to see if the string
    output from our Exception contains the specified message.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3e88654333d734e14739329b247afa3c.png)'
  prefs: []
  type: TYPE_IMG
- en: Great!
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for sticking around. When writing your unit-tests, remember to consider
    not only the logic of your code but also the bigger picture — how do the scripts
    you are testing fit into your current project. This will help you to formulate
    more ***effective*** unit-tests.
  prefs: []
  type: TYPE_NORMAL
- en: Let me know if you have any questions or wish to discuss any of the above.
  prefs: []
  type: TYPE_NORMAL
- en: '*All images by author unless otherwise noted.*'
  prefs: []
  type: TYPE_NORMAL
