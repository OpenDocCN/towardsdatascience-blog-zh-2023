["```py\nimport tensorflow_datasets as tfds\n\ndata = tfds.load(\"movielens/1m-ratings\")\ndf = tfds.as_dataframe(data[\"train\"])\n\nfiltered_data = (\n    df\n    .sort_values(\"timestamp\") # for a temporal train-eval-test split\n    .astype(\n        {\n            \"bucketized_user_age\": int,\n            \"movie_id\": int,\n            \"movie_title\": str,\n            \"user_gender\": int,\n            \"user_id\": int,\n            \"user_occupation_label\": int,\n            \"user_occupation_text\": str,\n            \"user_rating\": int,\n            \"user_zip_code\": str,\n        }\n    )\n    .drop(columns=[\"timestamp\"])\n)\n\n# temporal train-eval-test split\ntrain = filtered_data.iloc[:80000]\nevaluation = filtered_data.iloc[80000:90000]\ntest = filtered_data.iloc[90000:]\n\nX_train = train.drop(columns=[\"user_rating\"])\ny_train = train[\"user_rating\"]\nX_eval = evaluation.drop(columns=[\"user_rating\"])\ny_eval = evaluation[\"user_rating\"]\nX_test = test.drop(columns=[\"user_rating\"])\ny_test = test[\"user_rating\"]\n```", "```py\nfeatures_config = {\n    \"user_id\": {\"entity\": \"user\", \"dtype\": tf.int64},\n    \"bucketized_user_age\": {\"entity\": \"user\", \"dtype\": tf.int64},\n    \"user_gender\": {\"entity\": \"user\", \"dtype\": tf.int64},\n    \"user_occupation_label\": {\"entity\": \"user\", \"dtype\": tf.int64},\n    \"movie_id\": {\"entity\": \"movie\", \"dtype\": tf.int64},\n    \"user_zip_code\": {\"entity\": \"user\", \"dtype\": tf.string},\n    \"user_occupation_text\": {\"entity\": \"user\", \"dtype\": tf.string},\n}\n\nfor name, config in features_config.items():\n    if config[\"dtype\"] == tf.int64:\n        config[\"encoding_layer_class\"] = tf.keras.layers.IntegerLookup\n    elif config[\"dtype\"] == tf.string:\n        config[\"encoding_layer_class\"] = tf.keras.layers.StringLookup\n    else:\n        raise Exception\n\n    config[\"vocab\"] = train[name].unique()\n```", "```py\n# define input layers for each feature\ninputs = {\n    name: tf.keras.layers.Input(shape=(1,), name=name, dtype=config[\"dtype\"])\n    for name, config in features_config.items()\n}\n\n# encode all features as integers via the lookup layers\ninputs_encoded = {\n    name: config[\"encoding_layer_class\"](vocabulary=config[\"vocab\"])(inputs[name])\n    for name, config in features_config.items()\n}\n\n# create embeddings for all features\nembeddings = {\n    name: tf.keras.layers.Embedding(\n        input_dim=len(config[\"vocab\"]) + 1,\n        output_dim=32,\n    )(inputs_encoded[name])\n    for name, config in features_config.items()\n}\n\n# create embeddings for all features\nbiases = {\n    name: tf.keras.layers.Embedding(input_dim=len(config[\"vocab\"]) + 1, output_dim=1)(\n        inputs_encoded[name]\n    )\n    for name, config in features_config.items()\n}\n\n# compute the user embedding as the sum of all user feature embeddings\nuser_embedding = tf.keras.layers.Add()(\n    [\n        embeddings[name]\n        for name, config in features_config.items()\n        if config[\"entity\"] == \"user\"\n    ]\n)\n\n# compute the movie embedding as the sum of all movie feature embeddings\nmovie_embedding = tf.keras.layers.Add()(\n    [\n        embeddings[name]\n        for name, config in features_config.items()\n        if config[\"entity\"] == \"movie\"\n    ]\n)\n\n# compute the user bias as the sum of all user feature biases\nuser_bias = tf.keras.layers.Add()(\n    [\n        biases[name]\n        for name, config in features_config.items()\n        if config[\"entity\"] == \"user\"\n    ]\n)\n\n# compute the movie bias as the sum of all movie feature biases\nmovie_bias = tf.keras.layers.Add()(\n    [\n        biases[name]\n        for name, config in features_config.items()\n        if config[\"entity\"] == \"movie\"\n    ]\n)\n\n# do the exact same thing as in matrix factorization, \n# i.e. compute the dot product of the user and movie embedding,\n# add the user and movie bias, and squash the result into the range [1, 5]\ndot = tf.keras.layers.Dot(axes=2)([user_embedding, movie_embedding])\nadd = tf.keras.layers.Add()([dot, user_bias, movie_bias])\nflatten = tf.keras.layers.Flatten()(add)\nsquash = tf.keras.layers.Lambda(lambda x: 4 * tf.nn.sigmoid(x) + 1)(flatten)\n\nmodel = tf.keras.Model(\n    inputs=[inputs[name] for name in features_config.keys()], outputs=squash\n)\n\nmodel.compile(loss=\"mse\", metrics=[tf.keras.metrics.MeanAbsoluteError()])\n```", "```py\nmodel.fit(\n    x={name: X_train[name].values for name in features_config.keys()},\n    y=y_train.values,\n    batch_size=256,\n    epochs=100,\n    validation_data=(\n        {name: X_eval[name].values for name in features_config.keys()},\n        y_eval.values,\n    ),\n    callbacks=[tf.keras.callbacks.EarlyStopping(patience=1, restore_best_weights=True)],\n)\n\n# Output:\n# [...]\n# Epoch 6/100\n# 313/313 [==============================] - 1s 3ms/step - loss: 0.7626 - mean_absolute_error: 0.6836 - val_loss: 0.9836 - val_mean_absolute_error: 0.7985\n```", "```py\nmodel.evaluate(\n    x={name: X_test[name].values for name in features_config.keys()},\n    y=y_test.values,\n    batch_size=1_000_000,\n)\n\n# Output:\n# 1/1 [==============================] - 1s 667ms/step - loss: 1.0153 - mean_absolute_error: 0.8135\n```", "```py\nfeatures_config = {\n    \"user_id\": {\"entity\": \"user\", \"dtype\": tf.int64},\n    \"movie_id\": {\"entity\": \"movie\", \"dtype\": tf.int64},\n}\n```", "```py\n# new movie embeddings\nall_movie_genres = train[\"movie_genres\"].explode().unique().astype(int) # get all different genres\nmovie_genres_input = tf.keras.layers.Input(shape=(None,), name=\"movie_genres\")\nmovie_genres_as_integer = tf.keras.layers.IntegerLookup(vocabulary=all_movie_genres)(movie_genres_input)\nmovie_genres_embeddings = tf.keras.layers.Embedding(input_dim=len(all_movie_genres) + 1, output_dim=32)(movie_genres_as_integer)\nmovie_genres_biases = tf.keras.layers.Embedding(input_dim=len(all_movie_genres) + 1, output_dim=1)(movie_genres_as_integer)\nmovie_genres_embedding = tf.keras.layers.GlobalAveragePooling1D(keepdims=True)(movie_genres_embeddings)\nmovie_genres_bias = tf.keras.layers.GlobalAveragePooling1D(keepdims=True)(movie_genres_biases)\n\nmovie_embedding = tf.keras.layers.Add()(\n    [\n        embeddings[name]\n        for name, config in features_config.items()\n        if config[\"entity\"] == \"movie\"\n    ] + [movie_genres_embedding] # add the movie genres embedding here as well\n)\n\n# new movie bias\nmovie_bias = tf.keras.layers.Add()(\n    [\n        biases[name]\n        for name, config in features_config.items()\n        if config[\"entity\"] == \"movie\"\n    ] + [movie_genres_bias] # add the movie genres bias here as well\n)\n\n# add the movie inut to the inputs\nmodel = tf.keras.Model(\n    inputs=[inputs[name] for name in features_config.keys()] + [movie_genres_input], outputs=squash\n)\n```", "```py\nmodel.fit(\n    x={\n        **{name: X_train[name].values for name in features_config.keys()},\n        \"movie_genres\": tf.ragged.constant(X_train[\"movie_genres\"].values)\n    },\n\n# [...]\n```", "```py\nquery = {\n    \"user_id\": tf.constant([-1]), # unknown user!\n    \"bucketized_user_age\": tf.constant([18]),\n    \"user_gender\": tf.constant([0]),\n    \"user_occupation_label\": tf.constant([12]),\n    \"movie_id\": tf.constant([1]),\n    \"user_zip_code\": tf.constant([\"b'65712'\"]),\n    \"user_occupation_text\": tf.constant([\"b'writer'\"]),\n    \"movie_genres\": tf.ragged.constant([[1, 2, 3]])\n}\n\nmodel.predict(query)\n\n# Output:\n# array([[4.0875683]], dtype=float32)\n```"]