# 从生物学习到人工神经网络：接下来会是什么？

> 原文：[https://towardsdatascience.com/from-biological-learning-to-artificial-neural-network-whats-next-c8cf0d351af5](https://towardsdatascience.com/from-biological-learning-to-artificial-neural-network-whats-next-c8cf0d351af5)

## 人工智能能否帮助我们理解大脑是如何工作的？

[](https://jshen9889.medium.com/?source=post_page-----c8cf0d351af5--------------------------------)[![Stephanie Shen](../Images/857cccbe84f0d3a9886c84acfbbac03e.png)](https://jshen9889.medium.com/?source=post_page-----c8cf0d351af5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c8cf0d351af5--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c8cf0d351af5--------------------------------) [Stephanie Shen](https://jshen9889.medium.com/?source=post_page-----c8cf0d351af5--------------------------------)

·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----c8cf0d351af5--------------------------------) ·10分钟阅读·2023年10月26日

--

在21世纪初，当我在NYU Stern学习MBA时，我上过一门叫做数据挖掘的课程，介绍了许多算法用于“挖掘”数据，意思是自动发现数据的意义以进行预测和决策。神经网络就是其中之一，但由于其速度较慢，需要大量数据进行训练，因此其应用案例很少。二十年后，神经网络算法在机器学习和人工智能（AI）的基础中蓬勃发展，这要归功于巨大的计算能力，这种能力去除了根本障碍，从而推动了更先进算法和模型的发明。

随着人工神经网络和深度学习的快速发展，AI在某些领域已超越了人类。许多引人入胜的问题出现了，比如AI与人脑有多相似、AI的未来目标是什么，以及AI可以在多大程度上取代人类智能。在本文中，我将从生物学习的神经机制和它们如何启发AI开始。对历史的更好理解将帮助我们把握人工神经网络与其他机器学习模型（如支持向量机、决策树、随机森林）之间的根本区别。正是受脑部学习特征的启发，人工神经网络取得了最近的突破，包括用于图像识别的卷积神经网络（CNN）和用于生成AI的大型语言模型（LLM）。然后，我将讨论人类智能与AI的区别以及我们对AI未来方向的看法。我们期望看到的是，AI将继续从脑部发现中受益，同样重要的是，AI也可以帮助我们更好地理解大脑的工作原理。思想的不断交流将推动神经科学和AI以健康、快速的步伐发展。

# **生物学习**

学习是动物和人类大脑的重要特征。当一个婴儿出生时，她必须从头开始学习几乎所有的东西，包括识别面孔、说话和走路，随后是多年的学校教育和培训。学习在大脑中是如何发生的？

在19世纪末，西班牙神经科学家圣地亚哥·拉蒙·卡哈尔采用了一种独特的方法（戈尔基法）来染色神经元，并发现了它们特有的形状和连接模式。凭借出色的艺术天赋，卡哈尔详细描绘了许多物种主要脑区的神经解剖结构。他发现每个神经元都有一个轴突和许多类似树枝的树突。下图是他对鸽子小脑的其中一幅图画，展示了两种类型的细胞：顶部的两个大型普金耶神经元和底部的四个小颗粒细胞。每个神经元都有典型的轴突和树突。每个颗粒细胞的轴突接在普金耶神经元丰富的树突分支之一上。由于戈尔基法并不会染色大脑中的每个细胞，普金耶细胞树突的显著大小表明该细胞从小脑的颗粒细胞处接收了数百或数千个连接。

![](../Images/e0a823ec8743cb8aad0de40454b7f459.png)

图为鸽子小脑中的普金耶细胞（A）和颗粒细胞（B）。作者：圣地亚哥·拉蒙·卡哈尔。图片来源 [维基百科公共资源](https://en.wikipedia.org/wiki/File:PurkinjeCell.jpg)。

卡哈尔确认，尽管这些细胞相互连接，但它们的细胞膜并不连续。轴突末端与连接的树突之间存在一个微小的间隙，称为突触。他还绘制了一些关于动物大脑复杂神经连接的非凡图画。下面是海马体的一个例子，今天我们知道它负责短期学习和记忆的大脑区域。我们可以看到，细胞体排成层状。一个轴突在层之间穿行，同时与多个树突和细胞体交叉。这幅图是对大脑中生物神经网络的最早准确描绘之一。他对大脑神经结构的原始研究使他成为现代神经科学的奠基人。卡哈尔和戈尔基于1906年获得了生理学和医学诺贝尔奖。

![](../Images/d6b516040858ff3a899d48e207af3667.png)

哺乳动物海马体神经电路的绘图。作者：圣地亚哥·拉蒙·卡哈尔。图片来源 [维基百科公用资源](https://commons.wikimedia.org/wiki/File:CajalHippocampus.jpeg)

神经通信需要细胞内的动作电位发放和突触中释放的神经递质。动作电位，也称为神经冲动或尖峰，发生在神经元细胞膜的电压迅速升高和降低时。这种去极化导致相邻的膜位置也类似去极化，从而在毫秒内沿轴突快速传播。当尖峰到达轴突末端时，突触释放神经递质，这些小分子在大脑中充当信使，跨神经元进行通信。当突触后神经元通过其多个树突接收到足够的神经递质时，它会发放电信号，这些电信号然后通过突触以相同的方式沿其轴突向下一个连接的细胞传递。

![](../Images/a188137ccd8b174311984d7377398a57.png)

图片来源: [维基百科公用资源](https://en.wikipedia.org/wiki/Action_potential)

单个神经元本身就是一个信息处理系统。树突在接受和传递来自多个来源的信息中发挥作用，而细胞体则整合信号并通过轴突将其传递给下一个神经元。在这一层面上，有许多变量：

1.  神经元在接收到来自树突的信息时并不总是会发放信号，而仅在接收到的信号达到阈值时才会发放。

1.  轴突可以在同一大脑区域内的层之间传递信息，也可以在神经系统中长距离（例如超过1米）传递到另一个区域。

1.  动作电位的频率越高，轴突突触释放的神经递质就越多，突触后细胞发放信号的可能性也就越大。

然而，正如我们身体中的其他细胞一样，神经元非常微小（其细胞体直径为4–100微米），单个神经元的处理能力有限。神经元的另一个重要作用是进行网络内的通信。传输的信息量不仅与单个细胞的放电频率有关，还与网络中同时放电的细胞数量有关。

1949年，心理学家Donal O. Hebb在他的书《行为的组织：一种神经心理学理论》中提出了著名的赫布规则：

*当细胞A的轴突足够接近以激活细胞B，并且重复或持续参与激发它时，会在一个或两个细胞中发生某种生长过程或代谢变化，使得A作为激发B的细胞之一的效率得以提高。*

用简化的术语来说，赫布理论预测那些同时激活的细胞具有更强的生物连接，这解释了大脑中的联想学习。1966年，挪威生理学家Terje Lømo发现了“长期增强”现象，证明了赫布的理论是正确的。Lømo刺激了输入神经纤维，并记录了麻醉兔海马体中突触后细胞的动作电位。在通过单脉冲刺激收集基线后，他施加了一组高频刺激，并观察到增强的反应，这些反应可以持续超过10小时。这是首次展示近期神经活动的历史可以改变脑细胞之间连接强度的现象。此后，学习和记忆的神经科学蓬勃发展。科学家们使用各种动物模型研究不同脑区的长期增强现象，从行为到细胞和分子水平。神经科学家Eric Kandel开发了一个简单的海虹虫动物模型。他和他的实验室彻底研究了海虹虫学习行为相关的各种长期增强现象后，突触中的电学、化学和分子变化。凭借其终身成就，Eric Kandel在2000年获得了诺贝尔奖。

今天在其他神经科学学科的进展也表明了不同类型的神经可塑性，可能涉及细胞生长或新细胞生成。换句话说，赫布规则可能是大脑学习机制中的众多机制之一。神经科学在识别和理解其他学习机制方面仍有很长的路要走。

# **人工神经网络**

1943年，神经生理学家Warren McCulloch和逻辑学家Alter Pitts共同提出了第一个数学神经网络模型，该模型由人工神经元组成，每个神经元具有一个或多个二进制输入（模拟树突）和一个二进制输出（模拟轴突）。这些互连的人工神经元网络能够计算任何逻辑规则。然而，该模型没有学习的功能。

1958年，心理学家弗兰克·罗森布拉特发明了第一个人工神经网络（ANN），称为感知器。它有两个层次的人工神经元：输入层和输出层。弗兰克显著地采用了赫布规则，使得网络在训练过程中调整连接权重，直到结果符合训练数据中的预期。这一特性使得神经网络可以在没有预定义规则的情况下学习任何内容，仅依赖于训练数据中提供的示例结果。这是ANN历史上的一个革命性时刻，因为这是计算机首次能够像生物大脑一样在没有特定规则或指令的情况下解决问题。

随后发生了两个突破，使得人工神经网络真正腾飞。其一是在输入层和输出层之间添加一个或多个内部隐藏层，使深度学习算法能够逐步从原始输入中提取更高层次的特征。其次，通过使用反向传播技术显著优化了权重调整。隐藏层也有生物学上的对应物。例如，新皮质有六个细胞层。海马体有三个层次，如原始的卡哈尔图所示。凭借现代基础设施和大数据的强大计算能力，人工神经网络与深度学习已经大规模扩展，增加了更多隐藏层和可调连接，以解决更复杂的任务。

# **生物神经网络与人工神经网络**

随着人工智能利用人工神经网络和深度学习的快速进展，关于人工智能的未来及其与人类之间的有趣关系提出了许多问题。考虑到我们上面讨论的生物神经网络和人工神经网络之间的相似性，让我们深入探讨两者之间的差异。

1.  **我们仍然对大脑的工作原理知之甚少**

随着过去十年中人工智能取得的巨大进步，我们现在进入了一个人工智能也可能激发神经科学家对大脑内部工作原理的研究时代。由于大脑是思维和驱动行为的器官，在清醒、活动的动物和人类身上研究它是极其困难的。人工神经网络使科学家能够假设、建模并设计未来的实验以进行神经科学研究。此外，人工智能研究人员和神经科学家可以通过整合来自大脑的细胞甚至分子发现，合作模拟神经网络在计算机上的新兴行为。

换句话说，人工智能不仅从神经生物学中获取灵感，神经科学家也可以从人工智能的进展中获得灵感。例如，反向传播是一个数学模型，它极大地提升了人工神经网络（ANN）的性能，达到了或超过了人类水平。然而，目前没有证据表明这种模型在大脑中存在，神经科学家和人工智能研究人员都在积极寻找其生物学版本。

**2\. 人工智能由人类管理**

尽管人工智能可以在没有工程师控制的规则或方程式的情况下自我学习，但人工智能模型高度依赖输入数据的质量，特别是训练数据。工程师和数据科学家还必须深入了解数据，以使训练有效且结果可信。鉴于此，这些模型是被动的，依赖于人类策划的训练。人工智能系统被设计为在特定任务上比人类更高效或准确，特别是在视觉、预测分析、机器人技术、自然语言处理（NLP）和国家语言理解（NLU）方面。

相比之下，人类可以在数据更少且质量较差的情况下学习几乎任何东西。他们通过与环境互动来获取信息，并善于利用上下文。此外，人类可以在未定义的概念空间中无缝推理，并且在收集足够信息在特定时间内不可能的情况下，善于处理不确定性。

**3\. 人类智能和人工智能在根本上不同**

人类智能依赖于生物构造，并受到数百万年的进化和数千年的文化的塑造。它复杂且多面，涵盖了许多认知和情感能力。人类大脑似乎是一个高度集成的系统，能够互动地收集信息、带着感情做决策、使用语言进行交流并同时采取行动。另一方面，我们都受到似乎不可避免的认知偏差和不可靠记忆的困扰，这似乎是卓越进化设计中的“缺陷”。

相反，人工智能是基于软件构建并在计算机硬件上执行的，具备执行通常需要人类智能的任务的能力，如学习、模式识别、问题解决和决策制定。尽管人脑激发了基本原则，但工程师和数据科学家使用算法和数学模型实现了人工神经网络。鉴于此，人工智能提供了具体、详细、可重复和可扩展的结果，这些是人类难以实现的。这些恰恰是自动化和提高人类努力效率的特点，并补充了人类的限制。

# **结论**

正如鸟类启发我们建造飞机飞行一样，人工神经网络因受脑部神经结构的启发而取得成功。由于基础材料本质上不同，我们从不期望人工智能直接复制人脑；相反，我们期待它成为另一种类型的智能，具有自身的设计和优势，能够帮助人类解决特定问题。

此外，大脑是一个高度复杂的生物系统。研究人类行为和认知的神经机制的实验方法相对有限。AI 可以成为一个强大的工具，提供想法和支持证据，以理解大脑的内部运作。我们在未来十年中应该会看到这种相互启发，从而推动两个领域的共同发展。
