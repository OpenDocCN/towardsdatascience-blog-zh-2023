- en: How to Use Chat-GPT and Python to Build a Knowledge Graph in Neo4j Based on
    Your Own Articles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-use-chat-gpt-and-python-to-build-a-knowledge-graph-in-neo4j-based-on-your-own-articles-c622bc4e2eaa](https://towardsdatascience.com/how-to-use-chat-gpt-and-python-to-build-a-knowledge-graph-in-neo4j-based-on-your-own-articles-c622bc4e2eaa)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A graph containing structured knowledge from more than 120 articles on mathematics
    and data science
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://kaspermuller.medium.com/?source=post_page-----c622bc4e2eaa--------------------------------)[![Kasper
    Müller](../Images/336cad595544ba68e3376a038d44df62.png)](https://kaspermuller.medium.com/?source=post_page-----c622bc4e2eaa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c622bc4e2eaa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c622bc4e2eaa--------------------------------)
    [Kasper Müller](https://kaspermuller.medium.com/?source=post_page-----c622bc4e2eaa--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c622bc4e2eaa--------------------------------)
    ·8 min read·Aug 26, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c43ea8409a8a04894916f41afe7075dc.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot by Author
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I will show how you can structure and explore the content of
    your own articles using graph technology and some programming.
  prefs: []
  type: TYPE_NORMAL
- en: The idea of using NLP techniques for structuring unstructured data is not new,
    however, the latest progress in LLMs (Large Language Models) has sparked countless
    opportunities for doing just that. The accessibility for amateurs through the
    booming technology Chat-GPT has created a lot of attention towards LLMs and generator
    models.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, generative AI is on the agenda in many companies already!
  prefs: []
  type: TYPE_NORMAL
- en: The way we will work with the technology in this article is through the programming
    language Python using OpenAI’s developer API. We will work on data from Medium
    (meta huh?) and build a knowledge graph. That may sound like a mouthful, but it
    is actually surprisingly easy to get started with.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First things first. The plan of attack is the following.
  prefs: []
  type: TYPE_NORMAL
- en: Get the API to work and access it through Python.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use a sample text to do prompt engineering ensuring that the GPT-4 model understands
    what you want from it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Download your articles from Medium (you can of course use other pieces of text
    if you want) and pre-process the data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extract and collect output from Chat-GPT.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Post-process the output from Chat-GPT
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write code to structure the data further into a graph using the Cypher query
    language.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Play around with your new best friend and explore your articles.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Without further ado, let’s get started by quickly setting up the basic tech.
  prefs: []
  type: TYPE_NORMAL
- en: Setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We need to have the programming language Python and the graph database Neo4j
    installed on our local computer.
  prefs: []
  type: TYPE_NORMAL
- en: The first thing to do is to ensure that you have a plus account at OpenAI so
    that you can use GPT-4\. The second thing you should make sure of is that you
    have [signed up](https://platform.openai.com/account/billing/overview) for the
    API use. Once that is in place, you need to generate an [API key](https://platform.openai.com/account/api-keys).
    Then you need to *pip install openai*.
  prefs: []
  type: TYPE_NORMAL
- en: Before connecting to ChatGPT, let’s go to the browser and try to find the right
    way to ask about this task. This is called prompt engineering and it is very important
    to get right. By trying out different ways to ask using a random article of mine
    as an example, I found that the right way to ask was to provide a detailed and
    guided prescript before giving it the actual text.
  prefs: []
  type: TYPE_NORMAL
- en: 'I ended up with the following prescript:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3cd99f403e3ce9c9fa0eb1603461a774.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, I gave it a snippet from the article about the Gamma function
    that I wrote a long time ago:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6140a54366f5d59cf2039d4ff217bca2.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'What it came up with was the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/890fb9f93a7201446ed9faf280133be8.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot by Author
  prefs: []
  type: TYPE_NORMAL
- en: Even though it clearly didn’t really understand the task, it did okay, especially
    with the format. However, sometimes it creates duplicates, and note that it hallucinated
    some entities and relationships even though we asked it not to. Annoying disobedient
    machine! We will deal with this later.
  prefs: []
  type: TYPE_NORMAL
- en: For future uses, we will store this prescript in a Python file called *prompt_input.py*.
  prefs: []
  type: TYPE_NORMAL
- en: Now that the basic setup is in place, let’s test if it actually works.
  prefs: []
  type: TYPE_NORMAL
- en: If the code is only for you and only on your local machine, you can hardcode
    the API key in the Python file, otherwise you can set it as an environment variable
    or place it in a config file that you don’t push anywhere!
  prefs: []
  type: TYPE_NORMAL
- en: Let’s test if this setup works. We create a file called *connect.py* containing
    the basic connection to ChatGPT from Python.
  prefs: []
  type: TYPE_NORMAL
- en: We verify that this works!
  prefs: []
  type: TYPE_NORMAL
- en: Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I need to fetch articles from my Medium account. At the time of writing, I have
    published 123 articles, but the download feature from Medium returns 259 files!
    This is because it classifies comments and drafts as posts too. We only want the
    published articles, but that is not the only problem. The files are HTML files!
    That is of course great if you want to read them in a browser, but not if you
    want to work with the pure text.
  prefs: []
  type: TYPE_NORMAL
- en: Well, nice try, Medium, but that can’t stop a data scientist armed with programming
    languages and dirty tricks!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We also note that the file names of the downloaded files are quite messy. A
    standard name is for example “*2020–12–11_The-Most-Beautiful-Equation-in-the-World-5ab6e49c363.html*”
  prefs: []
  type: TYPE_NORMAL
- en: Let’s store these files in a folder called *raw*.
  prefs: []
  type: TYPE_NORMAL
- en: 'We write a small module called *extract_text_from_html.py* with some functionality
    to extract the text from these files:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we can use it to actually get results from ChatGPT, we need to be able
    to split the text up into batches. The reason is that GPT-4 has a token limit.
    Luckily, this is easy. In a file called *preprocess.py*, we write:'
  prefs: []
  type: TYPE_NORMAL
- en: Now we are ready to actually get some data from ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: We write a file called *process_articels.py* where **loop** through the articles,
    retrieve the **titles** from the frightening file names, extract the actual **text**
    from the HTML files, run each batch of text through **ChatGPT**, **collect** the
    results from the files, and **save** the outputs from the model in new files that
    we store in a folder called *data*. We also save the actual texts in a folder
    called **cleaned** for later use.
  prefs: []
  type: TYPE_NORMAL
- en: Phew!! that was a lot. But actually, the code is simple because we have already
    done some of the work in other files.
  prefs: []
  type: TYPE_NORMAL
- en: The above code might take a while to execute as the GPT-4 model is relatively
    slow compared to the other sub-performing models available. We make sure to use
    a cashing setup so that if the program crashes, then we don’t start all over,
    we just start where we left off.
  prefs: []
  type: TYPE_NORMAL
- en: Now (several hours in agony later) we have a structured dataset of results from
    GPT-4\. Perfect. Now we “just” need to build a graph from it.
  prefs: []
  type: TYPE_NORMAL
- en: Building the knowledge graph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will merge the preprocess and graph creation process into one single function.
    This is normally not very advisable (separation of concerns and all), but because
    we need to look at a “relationship and entity” — level in the preprocessing anyway,
    we might as well create the nodes and relationships in the graph while we have
    our hands dirty.
  prefs: []
  type: TYPE_NORMAL
- en: Let us create a small API containing a driver so we can talk to our graph.
  prefs: []
  type: TYPE_NORMAL
- en: We need to **loop** over the results, make sure that the entities are **not**
    too long, **clean** the results, and define the **nodes** and **relationships**
    in the output from the gpt-model, we **don’t** want to call the graph with the
    same query multiple times, we want the entities to be connected to the original
    **articles**, and then we need to make sure that each entity and relationship
    cooked up by Chat-GPT is actually **in** the text so we don’t build a graph of
    **machine dreams**!
  prefs: []
  type: TYPE_NORMAL
- en: The last of the above requirements is to raise the probability that we can trust
    the graph even though it is not fool proof if you think about it.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'No biggie! We write the following:'
  prefs: []
  type: TYPE_NORMAL
- en: There are of course many ways to create a schema for a knowledge graph. It is
    not always easy to see what should be nodes and what should be relationships but
    since we don’t want relationships between relationships, we went for the above.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, I chose a minimalistic approach for this article. Normally, we would
    enrich the nodes and relationships with more properties.
  prefs: []
  type: TYPE_NORMAL
- en: Now we just need a main point of entry.
  prefs: []
  type: TYPE_NORMAL
- en: That is it. Now we have ourselves a knowledge graph containing information from
    my articles on Medium. In fact, we have about 2000 nodes and 4500 relationships.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the graph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So what can we do with this thing? What should we ask of it?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try to find out how many articles the different persons were found in.
    We have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3f012b4855bea74d20b5a06362b50949.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot by author
  prefs: []
  type: TYPE_NORMAL
- en: Not surprisingly, Euler tops the list but I am surprised that Ramanujan and
    Newton were found in 4 of my articles. I could of course find the titles of the
    articles if I wanted but let’s move on. Okay, so this was fun but you don’t need
    a graph to figure this out.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try something else. Let’s see how many articles mention both Riemann and
    Euler.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3f0ef614507164a3ad4b347c3cda3e10.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot by author
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see how many of Euler’s discoveries my articles mention.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/504694e28a228ec117657e1761a49456.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot by author
  prefs: []
  type: TYPE_NORMAL
- en: Hmm no Euler line? I have to write an article about that.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s find out how many articles shared some mathematical keyword with the article
    *Group Theory*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e817643569064a6b1e3bc802326559dd.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot by author
  prefs: []
  type: TYPE_NORMAL
- en: The result is displayed here as 27 other articles connected by the non-orange
    nodes in the above image. Even though this is merely a toy example, one could
    imagine how this could just as well show how business-related documents are related
    by various sensitive keywords important within some disciplines such as GDPR or
    Audit.
  prefs: []
  type: TYPE_NORMAL
- en: Takeaways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Obviously, this work should be seen as what we call a “proof of concept”. We
    can’t use my articles for anything really, but if this had been texts from a company
    containing information about their customers and employees from emails to word
    files, pdfs, and so on, this could be used to map out how customers are related
    and which employees work closely together.
  prefs: []
  type: TYPE_NORMAL
- en: This in turn would give us a 360 view of how data flows through the organization
    as a whole, who is the most important person for a specific type of information
    flow, who is the right one to reach out to if you want to know about a specific
    topic or document, the client we contacted in our department was once contacted
    by another department, etc.
  prefs: []
  type: TYPE_NORMAL
- en: Extremely valuable information. Of course, we can’t use ChatGPT for this because
    we don’t know what happens to the data we send it. Therefore it is not a good
    idea to ask it about sensitive or business-critical information. What we need
    to do is to download another LLM (large language model) that only lives on our
    laptop. A local LLM. We can even fine-tune it on our own data. This is done as
    we speak by many companies already for building chatbots, assistants, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: But using it to build a knowledge graph over your unstructured data is next-level
    if you ask me and I think I have shown that it is more than doable!
  prefs: []
  type: TYPE_NORMAL
- en: If your company wants to know how we can use your data to weave a spiderweb
    of possibilities for your business, then please reach out to [me](https://www.linkedin.com/in/kasper-m%C3%BCller-96ba95169/)
    or my colleague [Kenneth Nielsen](https://www.linkedin.com/in/kenneth-h-m-nielsen-phd/).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Thank you for reading.
  prefs: []
  type: TYPE_NORMAL
- en: '*If you like to read articles like this one on Medium, you can* [*get a membership*](https://kaspermuller.medium.com/membership)
    *for full access. To join the community, simply click* [*here*](https://kaspermuller.medium.com/membership)*.*'
  prefs: []
  type: TYPE_NORMAL
