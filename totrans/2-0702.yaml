- en: 'Delta Lake: Deletion Vectors'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Delta Lake：删除向量
- en: 原文：[https://towardsdatascience.com/delta-lake-deletion-vectors-65bc9dc90b63](https://towardsdatascience.com/delta-lake-deletion-vectors-65bc9dc90b63)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/delta-lake-deletion-vectors-65bc9dc90b63](https://towardsdatascience.com/delta-lake-deletion-vectors-65bc9dc90b63)
- en: How are deletion vectors related to DML commands and how can they improve write
    performance?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除向量与 DML 命令有何关联，它们如何改善写入性能？
- en: '[](https://medium.com/@vitorf24?source=post_page-----65bc9dc90b63--------------------------------)[![Vitor
    Teixeira](../Images/db450ae1e572a49357c02e9ba3eb4f9d.png)](https://medium.com/@vitorf24?source=post_page-----65bc9dc90b63--------------------------------)[](https://towardsdatascience.com/?source=post_page-----65bc9dc90b63--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----65bc9dc90b63--------------------------------)
    [Vitor Teixeira](https://medium.com/@vitorf24?source=post_page-----65bc9dc90b63--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@vitorf24?source=post_page-----65bc9dc90b63--------------------------------)[![维托·特谢拉](../Images/db450ae1e572a49357c02e9ba3eb4f9d.png)](https://medium.com/@vitorf24?source=post_page-----65bc9dc90b63--------------------------------)[](https://towardsdatascience.com/?source=post_page-----65bc9dc90b63--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----65bc9dc90b63--------------------------------)
    [维托·特谢拉](https://medium.com/@vitorf24?source=post_page-----65bc9dc90b63--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----65bc9dc90b63--------------------------------)
    ·9 min read·May 25, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----65bc9dc90b63--------------------------------)
    ·9 分钟阅读·2023年5月25日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/a0f093c1a52476e936a00d6ef3306189.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a0f093c1a52476e936a00d6ef3306189.png)'
- en: Photo by [Sam Pak](https://unsplash.com/@melocokr?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sam Pak](https://unsplash.com/@melocokr?utm_source=medium&utm_medium=referral)
    提供的照片，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)'
- en: Being able to update and delete records is a feature that was lost during the
    transition from traditional data warehouses to data lakes. While data lakes were
    great at solving scale and cost issues, they sacrifice the ability to update and
    delete records. Data lakes were made of many and many files that could quickly
    turn into a data swamp and that’s where things went wrong and the lakehouse architecture
    came to the rescue.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 能够更新和删除记录是从传统数据仓库过渡到数据湖时失去的一个功能。虽然数据湖在解决规模和成本问题上表现出色，但它们牺牲了更新和删除记录的能力。数据湖由许多文件组成，这些文件很快会变成数据沼泽，这正是问题出现的地方，而湖仓架构则解决了这一问题。
- en: The lakehouse architecture is a hybrid between data warehouses and data lakes
    that combines both to address their issues. One of those issues is the lack of
    ACID transactions with DML support that were much beloved in data warehouses and
    that is where Delta Lake shines. However, due to Delta’s ACID guarantees, in-place
    file changes are out of the question.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 湖仓架构是一种结合了数据仓库和数据湖的混合型架构，旨在解决它们各自的问题。其中一个问题是数据仓库中备受喜爱的缺乏 DML 支持的 ACID 事务，而这正是
    Delta Lake 的亮点。然而，由于 Delta 的 ACID 保证，文件的原地修改是不可能的。
- en: In this post, I will address how Delta supports DML commands, how deletion vectors
    work, and why they are important as a performance improvement.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将讨论 Delta 如何支持 DML 命令、删除向量如何工作以及它们作为性能改进的重要性。
- en: Delta Lake — DML, under the hood
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Delta Lake — DML 背后的实现
- en: With the help of the [transaction log](https://www.databricks.com/blog/2019/08/21/diving-into-delta-lake-unpacking-the-transaction-log.html),
    Delta Lake supports DML commands like *Update*, *Delete*, and *Merge*. For simplicity,
    we’ll focus on *Update* and *Delete* commands since they are simpler and work
    the same way under the hood.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [事务日志](https://www.databricks.com/blog/2019/08/21/diving-into-delta-lake-unpacking-the-transaction-log.html)
    的帮助下，Delta Lake 支持如 *Update*、*Delete* 和 *Merge* 的 DML 命令。为了简便起见，我们将专注于 *Update*
    和 *Delete* 命令，因为它们更简单，并且在底层的工作方式相同。
- en: So, what happens when the following query is executed?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，当执行以下查询时会发生什么？
- en: '![](../Images/29e41e90ff7550f37c41c82f0d9a263c.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/29e41e90ff7550f37c41c82f0d9a263c.png)'
- en: Files before/after the update — Image by author
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 更新前后的文件 — 图片来源于作者
- en: 'There are three steps involved:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 涉及三个步骤：
- en: Find the files where the predicate *gender = ‘M’* matches
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查找谓词 *gender = ‘M’* 匹配的文件
- en: For each of the files found, rewrite the file with the records updated
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于找到的每个文件，重写文件并更新记录
- en: Remove File 2 and File 4 from the transaction log and add File 5 and File 6
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从事务日志中删除文件 2 和文件 4，并添加文件 5 和文件 6
- en: The same logic is used for a *Delete* command. The process of rewriting the
    files with the required updates is called **copy-on-write**.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的逻辑也适用于*删除*命令。将文件重写为所需更新的过程称为**写时复制**。
- en: By copying the entire file with the updated records we avoid having to do in-place
    modifications and are able to concurrently navigate through the transaction log
    and the several different versions that make up the latest state of a Delta table
    (time travel).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 通过复制包含更新记录的整个文件，我们避免了就地修改，并能够同时浏览事务日志和构成 Delta 表最新状态的多个不同版本（时间旅行）。
- en: For the above query, this strategy does not seem to be a problem since there
    is a high percentage of the records that will be updated, but what about this
    one?
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于上述查询，这种策略似乎没有问题，因为有很高比例的记录会被更新，但那这个呢？
- en: In this case, the file that contains this specific id will have to be fully
    replaced by a new one without the record. For small files, this should not be
    an issue but let’s say we have files in the range of hundreds of MB, this is highly
    inefficient.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，包含特定 id 的文件必须被没有该记录的新文件完全替换。对于小文件，这不应成为问题，但假设我们有几百 MB 的文件，这种做法是非常低效的。
- en: In sum, copy-on-write is great for fast reads, as all the data is always present
    in the same file, and good when there are not many DML operations. On the contrary,
    the writes are expensive and it is a bad strategy when there are a lot of update
    operations like we’ve seen above.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，写时复制对于快速读取非常好，因为所有数据始终存在于同一个文件中，并且在 DML 操作不多的情况下表现良好。相反，写入操作成本高，当更新操作很多时，这种策略是不理想的，如上所述。
- en: Deletion Vectors
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 删除向量
- en: Delta Deletion Vectors (DVs) are a mechanism that is used to increase the performance
    of writes when an update only changes a very small percentage of the records in
    a file due to copy-on-write.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Delta 删除向量（DVs）是一种机制，用于在由于写时复制而只更新文件中很小百分比的记录时，提高写入性能。
- en: Put in simple terms, they are an array of [RoaringBitmaps](https://github.com/RoaringBitmap/RoaringBitmap)
    that map directly into rows of Parquet files (the default implementation of 32-bit
    integers is not enough to cover the possible number of rows). DVs are created
    by commands that delete or update existing data and act as a marker that will
    be used to filter out rows when scanning data. In the case of a delete, they act
    as a deletion marker as the name indicates, in the case of an update it acts as
    a row invalidator which I’ll detail further below.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，它们是 [RoaringBitmaps](https://github.com/RoaringBitmap/RoaringBitmap) 的数组，直接映射到
    Parquet 文件的行中（32 位整数的默认实现不足以覆盖可能的行数）。DVs 由删除或更新现有数据的命令创建，作为标记用于在扫描数据时过滤行。在删除的情况下，它们充当删除标记，正如名称所示；在更新的情况下，它们充当行无效标记，我将在下面进一步详细说明。
- en: Setup
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置
- en: Let’s use the [people10m public dataset](https://learn.microsoft.com/en-us/azure/databricks/dbfs/databricks-datasets#create-a-table-based-on-a-databricks-dataset)
    that we’ve been using in the previous Delta Lake posts and analyze how DVs actually
    work.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用之前 Delta Lake 文章中使用的 [people10m 公共数据集](https://learn.microsoft.com/en-us/azure/databricks/dbfs/databricks-datasets#create-a-table-based-on-a-databricks-dataset)
    并分析 DVs 实际上是如何工作的。
- en: 'We should have a table like this:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该有这样的表：
- en: '![](../Images/dede0b7bb51dbde1d1d4f2f7620d58fe.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dede0b7bb51dbde1d1d4f2f7620d58fe.png)'
- en: Delta Table people10m — Image by author
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Delta Table people10m — 作者提供的图片
- en: 'The first thing we need to do is enable the feature by running:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事是通过运行以下命令启用该功能：
- en: Set deletion vectors flag
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 设置删除向量标志
- en: '**Note:** Be aware that by turning this feature on the table protocols are
    updated to *readerVersion=3* and *writerVersion=7* and might break compatibility
    with older readers/writers.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 请注意，通过启用此功能，表协议会更新为*readerVersion=3* 和 *writerVersion=7*，可能会与旧版本的读取器/写入器不兼容。'
- en: 'Let’s force the creation of a deletion vector by deleting an id from the table:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过从表中删除一个 id 来强制创建一个删除向量：
- en: Without DVs, we should have had a new file in the transaction log that would
    contain all the ids from the original file except id 1\. Let’s see what happened
    by inspecting the transaction log.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 没有 DVs 的话，我们应该在事务日志中有一个新文件，包含原始文件中的所有 id，除了 id 1。让我们通过检查事务日志来看看发生了什么。
- en: Unpacking the transaction log
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解包事务日志
- en: '**CommitInfo**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**CommitInfo**'
- en: The *commitInfo* entry contains the information about the DELETE operation.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*commitInfo* 条目包含有关 DELETE 操作的信息。'
- en: Commit info entry in the transaction
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 事务中的提交信息条目
- en: Here we see that *numDeletionVectorsAdded:”1"* and *numAddedFiles:”0"* which
    means that we avoided rewriting a file.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们看到 *numDeletionVectorsAdded:”1"* 和 *numAddedFiles:”0"*，这意味着我们避免了重写文件。
- en: '**Remove**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**移除**'
- en: You may find it odd that it includes a *remove* entry as this behavior is similar
    to standard copy-on-write behavior and the above metrics indicate that no file
    was removed *numRemovedFiles:”0"*.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会觉得奇怪，因为它包括一个 *remove* 条目，这种行为类似于标准的写时复制行为，上述指标表明没有文件被移除 *numRemovedFiles:”0"*。
- en: Remove entry in the transaction log
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在事务日志中移除条目
- en: '**Add**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**添加**'
- en: The *add* entry explains everything that is happening with DVs enabled.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*add* 条目解释了启用 DVs 后发生的所有事情。'
- en: Add entry in the transaction log
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在事务日志中添加条目
- en: Here we see that the *path* of the added file is the same as the removed file
    but it now contains a deletion vector. Add and remove entries can now optionally
    include a *deletionVector* field containing information about the DVs associated
    with a file.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们看到，添加的文件的 *path* 与移除的文件相同，但现在包含了删除向量。添加和移除条目现在可以选择性地包含一个 *deletionVector*
    字段，其中包含与文件关联的 DVs 信息。
- en: In versions that support DVs, files are uniquely identified by both the file
    path and the unique deletion vector id which defaults to NULL when DVs are not
    used.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在支持 DVs 的版本中，文件通过文件路径和唯一删除向量 id 唯一标识，当未使用 DVs 时，默认值为 NULL。
- en: '**How is this id defined? What information is provided by the new DV structure?**'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**这个 id 是如何定义的？新的 DV 结构提供了什么信息？**'
- en: It mostly depends on the storage type. In our case, the storage type is “*u”.*
    For this storage type, the *pathOrInlineDv* is `<random prefix — optional><base85
    encoded uuid>`. It is used for DVs that are stored in a path that is relative
    to the Delta table path. The DV file name can be derived from the UUID ([see details](https://github.com/delta-io/delta/pull/1487/files)).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 它主要取决于存储类型。在我们的例子中，存储类型是“*u*”。对于这种存储类型，*pathOrInlineDv* 是 `<random prefix —
    optional><base85 encoded uuid>`。它用于存储在相对于 Delta 表路径的路径中的 DVs。DV 文件名可以从 UUID 派生（[见详细信息](https://github.com/delta-io/delta/pull/1487/files)）。
- en: '![](../Images/8204a970db2daab1f34b69ab0e47cc0c.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8204a970db2daab1f34b69ab0e47cc0c.png)'
- en: Deletion Vector in Delta table path
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Delta 表路径中的删除向量
- en: In our example, we can see the deletion vector stored alongside the table files.
    Be aware that if the table has partitioned values DV files are not kept in the
    partition directories but in the Delta table root directory as a DV can span across
    multiple partitions.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们可以看到删除向量与表文件一起存储。请注意，如果表具有分区值，DV 文件不会保存在分区目录中，而是保存在 Delta 表根目录中，因为
    DV 可以跨多个分区。
- en: Storage type can take other values such as*“i”* wherethe vector is inlined so
    *pathOrInlineDv* is `<base85 encoded bytes>` and*“p”* where the file is stored
    in the absolute path provided by *pathOrInlineDv*.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 存储类型可以采用其他值，例如 *“i”*，其中向量内联，因此 *pathOrInlineDv* 是 `<base85 encoded bytes>`，以及
    *“p”*，其中文件存储在由 *pathOrInlineDv* 提供的绝对路径中。
- en: '*Offset* is an optional field that states the position where the data starts
    in storage types that are backed up by files. It is not present when the DV is
    inlined (storage type *“i”*).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*Offset* 是一个可选字段，表示数据在由文件支持的存储类型中的起始位置。当 DV 内联（存储类型 *“i”*）时，该字段不存在。'
- en: '*SizeInBytes* is the size of the DV in bytes.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*SizeInBytes* 是 DV 的字节大小。'
- en: '*Cardinality* is the number of rows that are logically deleted by the DV.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*Cardinality* 是 DV 逻辑上删除的行数。'
- en: DML with Deletion Vectors enabled
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启用删除向量的 DML
- en: With DVs enabled, the DML commands work differently to make use of the new information.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 启用 DVs 后，DML 命令的工作方式有所不同，以利用新的信息。
- en: Update with no existing DVs
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更新时没有现有的 DVs
- en: '![](../Images/c6de3c08a7b68040a76483fc4fca2521.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c6de3c08a7b68040a76483fc4fca2521.png)'
- en: Update with DVs enabled — Image by author
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 启用 DVs 的更新 — 作者提供的图像
- en: 'With DVs enabled, the update command logic is as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 启用 DVs 后，更新命令逻辑如下：
- en: Scan all the files that satisfy the predicate and need to be updated (File 2,
    File 4)
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扫描所有满足条件并需要更新的文件（File 2, File 4）
- en: Write DVs for the rows that need to be invalidated (DV 2.1, DV 4.1)
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为需要失效的行写入 DVs（DV 2.1，DV 4.1）
- en: Write a new file with the updated rows (File 5)
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 写入更新后的行的新文件（File 5）
- en: Add (File 5, NULL) to the transaction log, remove (File 2, NULL) and (File 4,
    NULL), and add (File 2, DV 2.1) and (File 4, DV 4.1) files
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 (File 5, NULL) 添加到事务日志中，移除 (File 2, NULL) 和 (File 4, NULL)，并添加 (File 2, DV
    2.1) 和 (File 4, DV 4.1) 文件
- en: '**Note:** At the time of writing, DVs are not supported in *UPDATE,* and *MERGE*
    commands, only in *DELETE*. However, they will be [supported in the future](https://github.com/delta-io/delta/issues/1367#issuecomment-1485345562).'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 在写作时，DVs 不支持 *UPDATE* 和 *MERGE* 命令，只支持 *DELETE*。不过，它们将在 [未来支持](https://github.com/delta-io/delta/issues/1367#issuecomment-1485345562)。'
- en: Reading tables with DVs
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 带有 DVs 的表的读取
- en: '![](../Images/958146fc8d4d2c32348a55e5e7b93943.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/958146fc8d4d2c32348a55e5e7b93943.png)'
- en: Reading tables with DVs — Image by author
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 带有 DVs 的表的读取 — 作者提供的图像
- en: When files have associated DVs, the scan will implicitly read the DV and filter
    the resulting rows matched by the vector. While without DVs we read a single file
    to get a set of results, with DVs we’ll have to read both file and DV in order
    to find the correct set of results which might impact the reading performance.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 当文件有相关的 DVs 时，扫描将隐式读取 DV，并根据向量过滤匹配的结果行。没有 DVs 时，我们读取单个文件以获得一组结果，而有 DVs 时，我们必须同时读取文件和
    DV 才能找到正确的结果集，这可能会影响读取性能。
- en: Delete with existing DVs
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除现有的 DVs
- en: '![](../Images/26c11b1f621eab64cc38231cada997be.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/26c11b1f621eab64cc38231cada997be.png)'
- en: Delete with existing DVs — Image by author
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 带有 DVs 的删除 — 作者提供的图像
- en: In this case, we will execute a delete that will affect a file that already
    has an associated DV file. Since we are only deleting we won’t need to write any
    new files with updated rows but only update the existing DV.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将执行一个删除操作，这会影响一个已经有相关 DV 文件的文件。由于我们只是删除，不需要写入任何包含更新行的新文件，只需更新现有 DV。
- en: Scan (File 2, DV 2.1) to find the latest set of rows
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扫描 (File 2, DV 2.1) 以查找最新的行集
- en: Write a new DV containing the old DV deleted rows plus the new one
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 写一个新的 DV，包含删除旧 DV 的行以及新的行。
- en: Remove (File 2, DV 2.1) from the transaction log and add (File 2, DV 2.2)
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从事务日志中移除 (File 2, DV 2.1) 并添加 (File 2, DV 2.2)
- en: Cleanup and compaction with DVs
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 带有 DVs 的清理和压缩
- en: VACUUM
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*VACUUM*'
- en: With constant updates, DVs might be constantly replaced and there are a lot
    of files left behind. *VACUUM* will also target DVs for deletion just like regular
    files.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 随着不断的更新，DVs 可能会不断被替换，留下许多旧文件。*VACUUM* 也会像处理常规文件一样处理 DVs。
- en: OPTIMIZE
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*OPTIMIZE*'
- en: Before DVs, *OPTIMIZE* used *minFileSize* propertyto choose which files should
    be selected for compaction. Since there are files that might have a huge part
    of their rows invalidated, it makes sense to also select those that fall off a
    certain threshold. The property *maxDeletedRowsRatio* defines the max allowed
    ratio for a file to be selected for compaction and have its DV deleted.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有 DVs 的情况下，*OPTIMIZE* 使用 *minFileSize* 属性选择应该进行压缩的文件。由于某些文件可能有大量行被作废，因此选择那些超出某个阈值的文件也是有意义的。*maxDeletedRowsRatio*
    属性定义了文件被选择进行压缩并删除其 DV 的最大允许比例。
- en: Z-ORDER OPTIMIZE
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Z-ORDER OPTIMIZE
- en: This *OPTIMIZE* strategy is not idempotent, each time it is executed it will
    try to generate a new set of organized files, which means that no DVs will result
    from this operation, and all previous DVs and files are marked for deletion.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 *OPTIMIZE* 策略不是幂等的，每次执行时都会尝试生成一组新的有序文件，这意味着这个操作不会生成 DVs，所有以前的 DVs 和文件都标记为待删除。
- en: Performance differences
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能差异
- en: The theory is all covered but let’s see the improvements in practice by running
    a simple *DELETE* query.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 理论已经涵盖，但让我们通过运行一个简单的 *DELETE* 查询来查看实际中的改进。
- en: In order to simulate a real-life scenario of a write-intensive application with
    an average target file size I have compacted the dataset into a single file with
    approximately 236 MB and 10 million records and compared the performance of the
    query for both scenarios, with and without DVs enabled.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟一个写入密集型应用程序的真实场景，并考虑平均目标文件大小，我将数据集压缩到一个大约 236 MB 和 1000 万条记录的单一文件中，并比较了启用和未启用
    DVs 的情况下查询的性能。
- en: '![](../Images/a5e757435fb3bc9e831d9484668a67fc.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a5e757435fb3bc9e831d9484668a67fc.png)'
- en: Job statistics for both approaches — Image by author
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 两种方法的作业统计信息 — 作者提供的图像
- en: The first thing that we can notice on the left is the number of bytes added
    which is the same as the original file minus the row that was just deleted. There
    are two files added that total 9,999,999 rows and took 27.1s to run the entire
    operation which includes scanning the files and rewriting the updated ones.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先注意到左侧的字节数增加，这与原始文件的字节数相同，减去刚刚删除的行。有两个文件被添加，总计 9,999,999 行，运行整个操作（包括扫描文件和重写更新后的文件）花费了
    27.1 秒。
- en: On the right, we can see the DVs in action. We have 0 bytes added, as there
    are 0 new files. We see that a new DV with one row (34 bytes) was added to an
    existing file that still contains 9,999,999 valid rows. **Overall, the operation
    took 2.7s to run which is roughly a tenfold improvement on write compared with
    the previous approach!** This way we avoided having to rewrite the whole file
    just to delete a single row in a 10 million rows dataset by writing a DV that
    took 117ms to write.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在右侧，我们可以看到 DVs 的实际应用。没有新增字节，因为没有新文件。我们看到一个包含一行（34 字节）的新 DV 被添加到一个仍包含 9,999,999
    个有效行的现有文件中。**总体而言，该操作耗时 2.7 秒，相比之前的方法写入速度提高了大约十倍！** 通过写入一个耗时 117 毫秒的 DV，我们避免了为了在一个拥有
    1000 万行的数据集中删除一行而重新写入整个文件。
- en: Wrap up
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this post, we’ve seen how good DVs are for write-intensive use cases where
    there are a lot of small updates or deletes. While the reading times might be
    impacted by having to read more files, they can be highly amortized by the several
    optimizations that can happen either as part of an auto-compaction job or by the
    scheduled *OPTIMIZE* jobs. All in all, it is a trade-off between write and read
    performance so analyzing the kind of workload you are running is key before choosing
    to enable this feature.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们看到 DVs 在写入密集型用例中表现得非常好，尤其是在需要进行大量小的更新或删除时。虽然读取时间可能会受到读取更多文件的影响，但通过自动压缩作业或计划的*OPTIMIZE*作业，这些时间损失可以得到有效弥补。总的来说，这是写入性能和读取性能之间的权衡，因此在决定启用此功能之前，分析你所运行的工作负载类型至关重要。
- en: 'If you wish to read more on Delta Lake make sure to read my previous posts:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望了解更多关于 Delta Lake 的信息，请务必阅读我之前的文章：
- en: '[](/delta-lake-automatic-schema-evolution-11d32bd1aa99?source=post_page-----65bc9dc90b63--------------------------------)
    [## Delta Lake — Automatic Schema Evolution'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[## Delta Lake — 自动模式演进](https://towardsdatascience.com/delta-lake-automatic-schema-evolution-11d32bd1aa99?source=post_page-----65bc9dc90b63--------------------------------)'
- en: What happens and what you can/can’t do when merging evolutive DataFrames
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在合并演进型 DataFrame 时会发生什么，你可以/不能做什么
- en: towardsdatascience.com](/delta-lake-automatic-schema-evolution-11d32bd1aa99?source=post_page-----65bc9dc90b63--------------------------------)
    [](/delta-lake-keeping-it-fast-and-clean-3c9d4f9e2f5e?source=post_page-----65bc9dc90b63--------------------------------)
    [## Delta Lake— Keeping it fast and clean
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[## Delta Lake—保持高效和清洁](https://towardsdatascience.com/delta-lake-keeping-it-fast-and-clean-3c9d4f9e2f5e?source=post_page-----65bc9dc90b63--------------------------------)'
- en: Ever wondered how to improve your Delta tables’ performance? Hands-on on how
    to keep Delta tables fast and clean.
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 曾经想过如何提升你的 Delta 表的性能吗？实践如何保持 Delta 表的高效和清洁。
- en: towardsdatascience.com](/delta-lake-keeping-it-fast-and-clean-3c9d4f9e2f5e?source=post_page-----65bc9dc90b63--------------------------------)
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[## Delta Lake — 自动模式演进](https://towardsdatascience.com/delta-lake-automatic-schema-evolution-11d32bd1aa99?source=post_page-----65bc9dc90b63--------------------------------)'
