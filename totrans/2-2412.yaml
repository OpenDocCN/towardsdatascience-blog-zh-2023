- en: YOLO Object Detection on the Raspberry Pi
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Raspberry Pi 上的 YOLO 目标检测
- en: 原文：[https://towardsdatascience.com/yolo-object-detection-on-the-raspberry-pi-6de3629256fa](https://towardsdatascience.com/yolo-object-detection-on-the-raspberry-pi-6de3629256fa)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/yolo-object-detection-on-the-raspberry-pi-6de3629256fa](https://towardsdatascience.com/yolo-object-detection-on-the-raspberry-pi-6de3629256fa)
- en: Running the object detection model on the low-power devices
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在低功耗设备上运行目标检测模型
- en: '[](https://dmitryelj.medium.com/?source=post_page-----6de3629256fa--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page-----6de3629256fa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6de3629256fa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6de3629256fa--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page-----6de3629256fa--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dmitryelj.medium.com/?source=post_page-----6de3629256fa--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page-----6de3629256fa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6de3629256fa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6de3629256fa--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page-----6de3629256fa--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6de3629256fa--------------------------------)
    ·9 min read·Jul 11, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6de3629256fa--------------------------------)
    ·阅读时长9分钟·2023年7月11日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/3cd8e63bae4b714e54aa6398a1a9e5c3.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3cd8e63bae4b714e54aa6398a1a9e5c3.png)'
- en: YOLO object detection results, Image by author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO 目标检测结果，作者提供的图片
- en: In the [first part](/retro-data-science-testing-the-first-versions-of-yolo-799b9c1835d7)
    of this article, I tested “retro” versions of YOLO (You Only Look Once), a popular
    object detection library. The possibility to run a deep learning model using only
    OpenCV, without “heavy” frameworks like PyTorch or Keras, is promising for low-power
    devices, and I decided to go deeper into this topic and see how the latest YOLO
    v8 model works on a Raspberry Pi.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章的[第一部分](/retro-data-science-testing-the-first-versions-of-yolo-799b9c1835d7)中，我测试了
    YOLO（You Only Look Once）的“复古”版本，这是一个流行的目标检测库。仅使用 OpenCV 运行深度学习模型，而不使用 PyTorch
    或 Keras 等“重型”框架，对低功耗设备来说是很有前景的，我决定深入探讨这个话题，看看最新的 YOLO v8 模型在 Raspberry Pi 上的表现如何。
- en: Let’s get into it.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解一下。
- en: Hardware
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 硬件
- en: It is usually not a problem to run any model in the cloud, where the resources
    are virtually unlimited. But for the hardware “in the field,” there are much more
    constraints. Limited RAM, CPU power, or even different CPU architecture, older
    or incompatible software versions, a lack of a high-speed internet connection,
    and so on. Another big issue with cloud infrastructure is its cost. Let’s say
    we are making a smart doorbell, and we want to add person detection to it. We
    can run a model in the cloud, but every API call costs money, and who will pay
    for that? Not every customer would be happy to have a monthly subscription for
    the doorbell or any similar “smart” device, so it can be essential to run a model
    locally, even if the results may not be so good.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在云端运行任何模型通常没有问题，因为资源几乎是无限的。但对于“现场”的硬件，限制就多得多。有限的 RAM、CPU 功率，甚至不同的 CPU 架构，较旧或不兼容的软件版本，缺乏高速互联网连接等等。云基础设施的另一个大问题是其成本。假设我们正在制作一个智能门铃，并且我们想添加人脸检测功能。我们可以在云端运行模型，但每次
    API 调用都需要付费，那么谁来支付呢？并不是每个客户都愿意为门铃或任何类似的“智能”设备支付月费，因此在本地运行模型可能是必要的，即使结果可能不是最佳的。
- en: 'For this test, I will run the YOLO v8 model on a Raspberry Pi:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个测试中，我将会在 Raspberry Pi 上运行 YOLO v8 模型：
- en: '![](../Images/2a031796bb28e948930837f5d51ef043.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2a031796bb28e948930837f5d51ef043.png)'
- en: Raspberry Pi 4, Image source [https://en.wikipedia.org/wiki/Raspberry_Pi](https://en.wikipedia.org/wiki/Raspberry_Pi)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Raspberry Pi 4，图片来源 [https://en.wikipedia.org/wiki/Raspberry_Pi](https://en.wikipedia.org/wiki/Raspberry_Pi)
- en: 'The Raspberry Pi is a cheap credit-card-size single-board computer that runs
    Raspbian or Ubuntu Linux. I will test two different versions:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Raspberry Pi 是一种便宜的信用卡大小的单板计算机，运行 Raspbian 或 Ubuntu Linux。我将测试两个不同的版本：
- en: Raspberry Pi 3 Model B, made in 2015\. It has a 1.2 GHz Cortex-A53 ARM CPU and
    1 GB of RAM.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2015年制造的 Raspberry Pi 3 Model B。它有一个1.2 GHz Cortex-A53 ARM CPU和1 GB的RAM。
- en: Raspberry Pi 4, made in 2019\. It has a 1.8 GHz Cortex-A72 ARM CPU and 1, 4,
    or 8 GB of RAM.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raspberry Pi 4，制造于2019年。它有一个1.8 GHz Cortex-A72 ARM CPU和1、4或8 GB的RAM。
- en: 'Raspberry Pi computers are widely used nowadays, not only for hobby and DIY
    projects but also for embedded industrial applications (a [Raspberry Pi Compute
    Module](https://www.raspberrypi.com/products/compute-module-4/?variant=raspberry-pi-cm4001000)
    was designed especially for that). So, it is interesting to see how these boards
    can handle such computationally demanding operations as object detection. For
    all further tests, I will use this image:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，Raspberry Pi 计算机被广泛使用，不仅用于爱好和 DIY 项目，还用于嵌入式工业应用（[Raspberry Pi Compute Module](https://www.raspberrypi.com/products/compute-module-4/?variant=raspberry-pi-cm4001000)
    专门为此设计）。因此，了解这些板子如何处理诸如物体检测这样的计算密集型操作是很有趣的。在所有进一步的测试中，我将使用这张图像：
- en: '![](../Images/63eeec416befa124ca3389beeb89f31f.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63eeec416befa124ca3389beeb89f31f.png)'
- en: Test image, made by author
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 测试图像，由作者制作
- en: Now, let’s see how it works.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看它是如何工作的。
- en: '**A “Standard” YOLO v8 Version**'
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**“标准” YOLO v8 版本**'
- en: 'As a warm-up, let’s try the standard version, as it is [described](https://github.com/ultralytics/ultralytics)
    on the official GitHub page:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 作为热身，让我们尝试标准版本，如在官方 GitHub 页面上[描述的](https://github.com/ultralytics/ultralytics)：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In the “production” system, images can be taken from a camera; for our test,
    I am using a “test.jpg” file as was described before. I also executed the “predict”
    method twice to make the time estimation more accurate (the first run usually
    takes more time for the model to “warm up” and allocate all the needed memory).
    A Raspberry Pi is working in “headless” mode without a monitor, so I am using
    the console as an output; this is a more-or-less standard way most embedded systems
    work.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在“生产”系统中，可以通过摄像头获取图像；对于我们的测试，我使用了之前描述的“test.jpg”文件。我还执行了“predict”方法两次，以使时间估计更准确（第一次运行通常需要更多时间来“热身”和分配所有所需的内存）。Raspberry
    Pi 在没有显示器的“无头”模式下工作，因此我使用控制台作为输出；这是大多数嵌入式系统的标准工作方式。
- en: 'On the **Raspberry Pi 3** with a 32-bit OS, this version does not work: pip
    cannot install an “ultralytics” module because of this error:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在**Raspberry Pi 3** 上运行 32 位操作系统时，此版本无法使用：pip 无法安装“ultralytics”模块，原因如下错误：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: It turned out that PyTorch is available only for ARM 64-bit OS.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 结果发现 PyTorch 仅适用于 ARM 64 位操作系统。
- en: On the **Raspberry Pi 4** with a 64-bit OS, the code indeed works, and the calculation
    took about 0.9 s.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在**Raspberry Pi 4** 上运行 64 位操作系统时，代码确实可以运行，计算时间约为 0.9 秒。
- en: 'The console output looks like this:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 控制台输出如下：
- en: '![](../Images/9018160caad640e9889bc522c4d16a6a.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9018160caad640e9889bc522c4d16a6a.png)'
- en: 'I also did the same experiment on the desktop PC to visualize the results:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我还在桌面 PC 上进行了相同的实验以可视化结果。
- en: '![](../Images/15b6adff409166994691e49b58e59a14.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/15b6adff409166994691e49b58e59a14.png)'
- en: YOLO v8 Nano detection results, Image by author
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO v8 Nano 检测结果，由作者提供的图像
- en: As we can see, even for a model of “nano” size, the results are pretty good.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，即使是“nano”尺寸的模型，结果也相当不错。
- en: Python ONNX Version
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python ONNX 版本
- en: 'ONNX ([Open Neural Network Exchange](https://onnx.ai)) is an open format built
    to represent machine learning models. It is also supported by OpenCV, so we can
    easily run our model this way. YOLO developers have already provided a [command-line
    tool](https://docs.ultralytics.com/modes/export/) to make this conversion:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ONNX ([开放神经网络交换](https://onnx.ai)) 是一种用于表示机器学习模型的开放格式。它也得到 OpenCV 的支持，因此我们可以轻松地以这种方式运行我们的模型。YOLO
    开发人员已经提供了一个 [命令行工具](https://docs.ultralytics.com/modes/export/) 来进行这种转换：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here, “yolov8n.pt” is a PyTorch model file, which will be converted. The last
    letter “n” in the filename means “nano”. Different models are available (“n” —
    nano, “s” — small, “m” — medium, “l” — large), obviously, for the Raspberry Pi,
    I will use the smallest and fastest one.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，“yolov8n.pt”是一个 PyTorch 模型文件，将被转换。文件名中的最后一个字母“n”表示“nano”。提供了不同的模型（“n”——nano，“s”——small，“m”——medium，“l”——large），显然，对于
    Raspberry Pi，我将使用最小且最快的一个。
- en: 'Conversion can be done on the desktop PC, and a model can be copied to a Raspberry
    Pi using the “scp” command:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 转换可以在桌面 PC 上完成，并且可以使用“scp”命令将模型复制到 Raspberry Pi 上：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now we are ready to prepare the source. I used [an example](https://github.com/ultralytics/ultralytics/blob/main/examples/YOLOv8-OpenCV-ONNX-Python/main.py)
    from the Ultralytics repository, which I slightly modified to work on the Raspberry
    Pi:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备好准备源代码了。我使用了 [Ultralytics 仓库](https://github.com/ultralytics/ultralytics/blob/main/examples/YOLOv8-OpenCV-ONNX-Python/main.py)
    中的[一个示例](https://github.com/ultralytics/ultralytics/blob/main/examples/YOLOv8-OpenCV-ONNX-Python/main.py)，并对其进行了稍微的修改以在
    Raspberry Pi 上运行：
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As we can see, we don’t use PyTorch and the original Ultralytics library anymore,
    but the required amount of code is bigger. We need to convert the image to a blob,
    which is required for a YOLO model. Before printing the result, we also need to
    convert the output rectangles to the original coordinates. But as an advantage,
    this code works on “pure” OpenCV without any additional dependencies.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，我们不再使用 PyTorch 和原始 Ultralytics 库了，但所需的代码量增加了。我们需要将图像转换为 blob，这对于 YOLO
    模型是必需的。在打印结果之前，我们还需要将输出的矩形转换回原始坐标。但作为一个优点，这段代码在“纯” OpenCV 上运行，不依赖任何额外的库。
- en: On the **Raspberry Pi 3,** the computation time is 28 seconds. Just for fun,
    I also loaded the “medium” model (it’s a 101 MB ONNX file!) to see what would
    happen. Surprisingly, the application did not crash, but the calculation time
    was 224 seconds (almost 4 minutes). It looks obvious that the hardware from 2015
    is not well suited for running SOTA models from 2023, but it was interesting to
    see how it works.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在**Raspberry Pi 3**上，计算时间为 28 秒。为了好玩，我还加载了“medium”模型（这是一个 101 MB 的 ONNX 文件！）看看会发生什么。令人惊讶的是，应用程序没有崩溃，但计算时间为
    224 秒（几乎 4 分钟）。显然，2015 年的硬件不适合运行 2023 年的 SOTA 模型，但看到它如何工作的过程还是很有趣的。
- en: On the **Raspberry Pi 4** the computation time is 1.08 seconds.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在**Raspberry Pi 4**上，计算时间为 1.08 秒。
- en: C++ ONNX Version
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: C++ ONNX 版本
- en: Finally, let’s try the “heaviest guns” in our toolset and write the same code
    in C++. But before doing this, we will need to install OpenCV libraries and headers
    for C++. The easiest way is to run a command like “*sudo apt install libopencv-dev*”.
    But, at least for Raspbian, it does not work. The latest version, available via
    “apt”, is 4.2, and the minimum OpenCV requirement for loading the YOLO model is
    4.5\. So, we will need to build OpenCV from source.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们尝试使用工具集中最强大的武器，并用 C++ 编写相同的代码。但在此之前，我们需要为 C++ 安装 OpenCV 库和头文件。最简单的方法是运行类似“*sudo
    apt install libopencv-dev*”的命令。但至少对于 Raspbian，这种方法不起作用。通过“apt”获得的最新版本是 4.2，而加载
    YOLO 模型的最低 OpenCV 要求是 4.5。因此，我们需要从源代码构建 OpenCV。
- en: 'I will use OpenCV 4.7, the same version that was used in my Python tests:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用 OpenCV 4.7，这是我在 Python 测试中使用的版本：
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The Raspberry Pi is not the fastest Linux computer in the world, and the compilation
    process takes about 2 hours. And for a Raspberry Pi 3 with 1 GB of RAM, the swap
    file size should be increased to at least 512 MB; otherwise, the compilation will
    fail.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Raspberry Pi 不是世界上最快的 Linux 计算机，编译过程大约需要 2 小时。对于拥有 1 GB RAM 的 Raspberry Pi 3，交换文件大小应该增加到至少
    512 MB；否则，编译将失败。
- en: 'The C++ code itself is short:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: C++ 代码本身很简短：
- en: '[PRE6]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In this code, I used “*inference.h*” and “*inference.cpp*” files from the Ultralitics
    [GitHub repository](https://github.com/ultralytics/ultralytics/tree/main/examples/YOLOv8-CPP-Inference),
    these files should be placed in the same folder. I also executed the “runInference”
    method twice, the same way as in previous tests. We can now compile the source
    using this command:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，我使用了 Ultralitics [GitHub 仓库](https://github.com/ultralytics/ultralytics/tree/main/examples/YOLOv8-CPP-Inference)中的“*inference.h*”和“*inference.cpp*”文件，这些文件应该放在同一个文件夹中。我还像以前的测试一样执行了“runInference”方法两次。我们现在可以使用以下命令编译源代码：
- en: '[PRE7]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The results were surprising. A C++ version was *significantly* *slower* than
    the previous one! On the **Raspberry Pi 3**, the execution time was 110 seconds,
    which is more than 3 times longer than a Python version. On the **Raspberry Pi
    4,** the computation time was 1.79 seconds, which is about 1.5 times longer. In
    general, it is hard to say why. An OpenCV library for Python was installed using
    *pip*, but OpenCV for C++ was built from the source, and maybe some ARM CPU optimizations
    were not enabled. If some readers know the reason, please write in the comments
    below. Anyway, it was interesting to see that such an effect can happen.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 结果令人惊讶。C++ 版本的速度比以前的版本*明显* *慢*！在**Raspberry Pi 3**上，执行时间为 110 秒，比 Python 版本长了
    3 倍以上。在**Raspberry Pi 4**上，计算时间为 1.79 秒，比 Python 版本长了约 1.5 倍。总的来说，很难说清楚原因。Python
    的 OpenCV 库是通过 *pip* 安装的，而 C++ 的 OpenCV 是从源代码构建的，也许某些 ARM CPU 优化没有启用。如果有读者知道原因，请在下方评论中写明。无论如何，看到这样的效果是很有趣的。
- en: Conclusion
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: I can make an “educated guess” that most data scientists and data engineers
    are using their models in the cloud or at least on high-end equipment and have
    never tried running code “in the field” on embedded hardware. The goal of this
    text was to give readers some insights into how it works. In this article, we
    tried to run a YOLO v8 model on different versions of the Raspberry Pi, and the
    results were pretty interesting.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以“有根据地猜测”大多数数据科学家和数据工程师都在云端或至少在高端设备上使用他们的模型，并且从未尝试过在嵌入式硬件上“实地”运行代码。本文的目的是为读者提供一些关于它是如何工作的见解。在这篇文章中，我们尝试在不同版本的Raspberry
    Pi上运行YOLO v8模型，结果相当有趣。
- en: Running deep learning models on low-power devices can be a challenge. Even a
    Raspberry Pi 4, which is the best Raspbian-based model at the moment of writing
    this article, was able to provide only ~1 FPS with a YOLO v8 Tiny model. Of course,
    there is room for improvement. Some optimizations may be possible, like converting
    the model into FP16 (a floating point format with less accuracy) or even INT8
    formats. Finally, a more simple model trained on a limited dataset can be used.
    Last but not least, if more computing power is still required, code can run on
    special single-board computers like the NVIDIA Jetson Nano, which has CUDA support
    and can be much faster.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在低功耗设备上运行深度学习模型可能是一个挑战。即使是目前最好的基于Raspbian的模型——Raspberry Pi 4，在使用YOLO v8 Tiny模型时也只能提供大约~1
    FPS。当然，还有改进的空间。一些优化可能是可行的，例如将模型转换为FP16（精度较低的浮点格式）或甚至INT8格式。最后，也可以使用一个在有限数据集上训练的更简单的模型。最后但同样重要的是，如果仍然需要更多的计算能力，可以在像NVIDIA
    Jetson Nano这样的特殊单板计算机上运行代码，它支持CUDA，并且可以更快。
- en: At the beginning of this article, I wrote that “the possibility to run a deep
    learning model using only OpenCV, without heavy frameworks like PyTorch or Keras,
    is promising for low-power devices”. Practically, It turned out that PyTorch is
    an effective and highly optimized framework. The original YOLO version, based
    on PyTorch, was the fastest one, and an OpenCV ONNX code was 10–20% slower. But
    at the moment of writing this article, PyTorch is not available on a 32-bit ARM
    CPU, so on some platforms, there just may be no other choice.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本文开头，我写道“仅使用OpenCV运行深度学习模型，而不依赖像PyTorch或Keras这样沉重的框架，对低功耗设备是有前景的”。实际上，结果是PyTorch是一个有效且高度优化的框架。基于PyTorch的原始YOLO版本是最快的，而OpenCV
    ONNX代码慢了10–20%。但在撰写本文时，PyTorch在32位ARM CPU上不可用，因此在某些平台上可能没有其他选择。
- en: Results with a C++ version were even more interesting. As we can see, it can
    be a challenge to turn on proper optimizations, especially for embedded architecture.
    And without going deep into these nuances, custom-built OpenCV C++ code can run
    even slower compared to a Python version provided by a board manufacturer.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C++版本的结果则更为有趣。正如我们所见，开启适当的优化可能是一个挑战，特别是对于嵌入式架构而言。在不深入探讨这些细节的情况下，定制的OpenCV C++代码可能比板制造商提供的Python版本运行得更慢。
- en: Thanks for reading. If someone would be interested in testing FP16 or INT8 YOLO
    models on the same hardware or on the NVIDIA Jetson Nano board, please write in
    the comments, and I will write the next part of the article about this.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读。如果有人有兴趣在相同硬件或NVIDIA Jetson Nano板上测试FP16或INT8 YOLO模型，请在评论中留言，我会在下一部分文章中讨论这一点。
- en: If you enjoyed this story, feel free [to subscribe](https://medium.com/@dmitryelj/membership)
    to Medium, and you will get notifications when my new articles will be published,
    as well as full access to thousands of stories from other authors.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这个故事，欢迎 [订阅](https://medium.com/@dmitryelj/membership) Medium，这样你会在我的新文章发布时收到通知，并且可以全面访问其他作者的成千上万的故事。
