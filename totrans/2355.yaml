- en: Which Data Format to Use For Your Big Data Project?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/which-data-format-to-use-for-your-big-data-project-837a48d3661d](https://towardsdatascience.com/which-data-format-to-use-for-your-big-data-project-837a48d3661d)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Pickle, Parquet, CSV, Feather, HDF5, ORC, JSON: which one should you be using
    and why?'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://armandsauzay.medium.com/?source=post_page-----837a48d3661d--------------------------------)[![Armand
    Sauzay](../Images/94b12efc184d75380f293b457c95597f.png)](https://armandsauzay.medium.com/?source=post_page-----837a48d3661d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----837a48d3661d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----837a48d3661d--------------------------------)
    [Armand Sauzay](https://armandsauzay.medium.com/?source=post_page-----837a48d3661d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----837a48d3661d--------------------------------)
    ·6 min read·Oct 26, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f6052f807142ff0736003534edc8f2dc.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Maarten van den Heuvel — [Unsplash](https://unsplash.com/photos/assorted-color-book-lot-8EzNkvLQosk)
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the right data format is crucial in Data Science projects, impacting
    everything from data read/write speeds to memory consumption and interoperability.
    This article explores seven popular serialization/deserialization formats in Python,
    focusing on their speed and memory usage implications.
  prefs: []
  type: TYPE_NORMAL
- en: Through the analysis, we’ll also see how we can use profiling in Python (using
    the `cProfile` built-in module) and how we can get statistics on memory usage
    for specific files in your filesystem (using the `os` Python module).
  prefs: []
  type: TYPE_NORMAL
- en: Of course, each project has its specificities, beyond just speed and memory
    usage. But we’ll draw some trends, that can hopefully be useful to shed light
    on which format we can choose for a given project.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Serialization and Deserialization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Serialization is the process of saving an object (in Python, a pandas DataFrame
    for example) to a format that can be saved to a file for later retrieval. Deserialization
    is the reverse process.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A dataframe is a Python object and cannot be persisted as is. It needs to be
    translated to a file to be able to load this object at a later stage.
  prefs: []
  type: TYPE_NORMAL
- en: When you save a dataframe, you “serialize” the data. And when you load it back,
    you “deserialize” or translate it back to a language-readable (here Python-readable)
    format.
  prefs: []
  type: TYPE_NORMAL
- en: Certain formats are widely used because they are human-readable, such as JSON
    or CSV. These two formats are also used because they are language agnostic. Just
    like [protocol buffers](https://protobuf.dev/), which were originally developed
    by Google. JSON and Protocol buffer are also popular for APIs and enable sending
    data between different services written in different languages.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, some formats, like Python’s pickle, are language-specific
    and not ideal for transferring data between services in different programming
    languages. For example, for a machine learning use case, if a repository trains
    a model and serializes it in pickle, this file will only be able to be read from
    Python. So if the API that serves that machine learning model is written in Java,
    some transformations will have to be done before it can be used.
  prefs: []
  type: TYPE_NORMAL
- en: But for storing large data files, formats like CSV, JSON, and Protocol Buffers
    fall short in performance compared to more specialized formats like [HDF5](https://www.hdfgroup.org/solutions/hdf5/),
    [Parquet](https://www.databricks.com/glossary/what-is-parquet), [Feather](https://arrow.apache.org/docs/python/feather.html)
    or [ORC](https://cwiki.apache.org/confluence/display/hive/languagemanual+orc).
  prefs: []
  type: TYPE_NORMAL
- en: 'When working with data in Python, [pandas](https://pandas.pydata.org/) provide
    a convenient API to extract, transform and load data. Pandas supports a wide array
    of formats (all the supported ones can be found [here](https://pandas.pydata.org/docs/user_guide/io.html)),
    among which we chose the seven most used formats and compared their performance:
    JSON, CSV, Parquet, Pickle, Feather, HDF5, and ORC.'
  prefs: []
  type: TYPE_NORMAL
- en: The code found to reproduce the analysis can be found [here](https://www.kaggle.com/code/armandsauzay/save-load-speed-vs-format-csv-feat-pkl-pqt/edit/run/134172694).
  prefs: []
  type: TYPE_NORMAL
- en: Experimental approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Speed** and **memory usage** are two key components to look at when choosing
    the right data format for your project. But these vary based on both the size
    of the data, and which type of data is being used.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To do the analysis, we created 3 datasets that should cover most use cases:
    a number only dataframe, a strings-only dataframe and a dataframe with both numbers
    and strings. Each dataframe is 10,000 rows over 100 columns and are defined by
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: For the memory usage, we just look at what is the size of the dataset when saved.
    To measure memory usage, we’ll use Python’s `os` module, and specifically `os.stat`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'For the speed, we use Python’s [cProfile](https://docs.python.org/3/library/profile.html)
    library to profile the time taken by functions to execute. Here, we take a window
    of 10 seconds and look at how many times the function executed. In essence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Assessing speed: how fast are the different formats?'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Delving straight into the heart of the analysis, let’s look at the graphs created
    for evaluating serialization/deserialization speed. Note that we scale the time
    it took, so you can see on the graph below that csv with numbers only is the slowest
    process while using HDF5 for numbers only is the fastest, taking 1.09% (roughly
    1/100) of the CSV one.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ed0e1e8f503ab2d8f7b6f0519129c569.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by author: save time by format'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2b3adaa9a103d3e9b1ef621fd44f7c0c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by author: load time by format'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the graphs above, we can observe a few interesting take aways in terms of
    speed:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pickle/HDF5** are the fastest to save number-only data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feather** is the fastest format to load the data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Human readable formats such as **JSON** or **CSV** are much slower than other
    formats, especially for saving/loading data that only contains numbers (almost
    100x slower than pickle for instance)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**HDF5** is interestingly very performant for saving data (on par with feather,
    parquet, pickle) but a bit less for loading data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Memory usage: which format consumes less space?'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/b89a6c6f1c4b4c46cdfe2e26b5786987.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by author: scaled memory usage'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can observe that:'
  prefs: []
  type: TYPE_NORMAL
- en: once again, human-readable formats such as **CSV or JSON** are the least memory
    efficient formats. And JSON performs even worse than CSV.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**parquet** is the most memory efficient format with the given size of the
    data (10,000x100), which makes sense given parquet is a column-oriented data format.
    You can read more about it [here](https://www.databricks.com/glossary/what-is-parquet).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: once again, when dealing solely with numerical data, **pickle** is the most
    efficient format. [Pickle](https://docs.python.org/3/library/pickle.html) being
    the native Python package for serialization, it is not surprising.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: while faster, **feather** data takes a lot more memory compared to parquet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The findings can be summarized on the following table (with a bit less nuance
    than the analysis above):'
  prefs: []
  type: TYPE_NORMAL
- en: Gist by author
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The right format always boils down to your project’s unique demands. But we
    can still draw general conclusions from the above analysis. For example, unless
    interoperability is key and you need to visually see what the raw data looks like,
    you’re better off not using human-readable formats such as **CSV or JSON**.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, **parquet** seems to be a very solid choice as it is much better on
    the memory usage side of things while still being relatively fast.
  prefs: []
  type: TYPE_NORMAL
- en: It is also pivotal to understand the specificities of each format. For example,
    pickle is Python specific so you won’t be able to read it from other languages.
    But for Python-centric projects, focused solely on numerical data handling, **pickle**
    seems to be the best choice (both in terms of speed and memory).
  prefs: []
  type: TYPE_NORMAL
- en: If you’re managing a lot of data and want to minimize the amount of GB you’re
    writing to disk, **parquet** is the way to go. But if speed is your primary focus,
    you might want to give **feather** a try but it will take more memory.
  prefs: []
  type: TYPE_NORMAL
- en: Long story short, only the specific requirements of your project will guide
    you towards the right format. But you can hopefully gain some insights from the
    above to get a grasp on which one is better in your specific case. Happy coding!
  prefs: []
  type: TYPE_NORMAL
