["```py\nfrom pyyoutube import Api\n\ndef get_channel_info(api: Api, channel_id: str) -> Tuple[str, str, str]:\n    \"\"\" Get info about the channel. Return values: title, uploads, subscribers \"\"\"\n    channel_info = api.get_channel_info(channel_id=channel_id, parts=[\"snippet\", \"statistics\", \"contentDetails\"], return_json=True)\n    if len(channel_info[\"items\"]) > 0:\n        item = channel_info[\"items\"][0]\n        title = item[\"snippet\"][\"title\"]\n        uploads = item[\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n        subscribers = item[\"statistics\"][\"subscriberCount\"]\n        return title, uploads, subscribers\n\n    logging.warning(f\"get_channel_info::warning cannot get data for the channel {channel_id}\")\n    return None, None, None\n\napi = Api(api_key=\"...\")\nget_channel_info(api, channel_id=\"...\") \n```", "```py\n \"items\": [\n    {\n      \"id\": \"UCBJycsmd...\",\n      \"snippet\": {\n        \"title\": \"Mar...\",\n        \"description\": \"MKBH...\",\n        \"publishedAt\": \"2008-03-21T15:25:54Z\",\n      \"contentDetails\": {\n        \"relatedPlaylists\": {\n          \"likes\": \"\",\n          \"uploads\": \"UUBJy...\"\n        }\n      },\n      \"statistics\": {\n        \"viewCount\": \"3845139099\",\n        \"subscriberCount\": \"17800000\",\n        \"hiddenSubscriberCount\": false,\n        \"videoCount\": \"1602\"\n      }\n    }\n  ]\n```", "```py\ndef get_playlist_items(api: Api, playlist_id: str, limit: int) -> List[Tuple[str, str]]:\n    \"\"\" Get video IDs for a playlist \"\"\"\n    videos = []\n    playlist_items = api.get_playlist_items(playlist_id=playlist_id, count=10, limit=10, parts=[\"contentDetails\"], return_json=True)\n    next_page_token = playlist_items[\"nextPageToken\"]\n    while next_page_token is not None:\n        for video in playlist_items[\"items\"]:\n            video_id = video[\"contentDetails\"][\"videoId\"]\n            video_published_at = video[\"contentDetails\"][\"videoPublishedAt\"]\n            # views, likes, comments = get_video_by_id(api, video_id)\n            videos.append([video_id, video_published_at])\n\n        next_page_token = playlist_items[\"nextPageToken\"]\n        playlist_items = api.get_playlist_items(playlist_id=playlist_id, count=10, limit=10, \n                                                parts=[\"contentDetails\"], return_json=True,\n                                                page_token=next_page_token)\n        if len(videos) >= limit:\n            break\n\n    return videos\n```", "```py\n\"items\": [\n            {\n                \"kind\": \"youtube#playlistItem\",\n                \"etag\": \"tmSJMm9_KwkNTPkpdspUkQiQtuA\",\n                \"id\": \"VVVCSnljc21kdXZZRU...\",\n                \"contentDetails\": {\n                    \"videoId\": \"Ks_7TmG...\",\n                    \"videoPublishedAt\": \"2023-10-28T13:09:50Z\"\n                }\n            },\n            ...\n]\n```", "```py\ndef get_video_by_id(api: Api, video_id: str) -> Tuple[str, str, str]:\n    \"\"\" Get video details by id \"\"\"\n    video_info = api.get_video_by_id(video_id=video_id, parts=[\"statistics\"], return_json=True)\n    if len(video_info[\"items\"]) > 0:\n        item = video_info[\"items\"][0]\n        views = item[\"statistics\"][\"viewCount\"]\n        likes = item[\"statistics\"][\"likeCount\"]\n        comments = item[\"statistics\"][\"commentCount\"]\n        return views, likes, comments\n    return None, None, None\n```", "```py\ndef get_channel_videos(api: Api, channel_id: str, limit: int) -> List:\n    \"\"\" Get videos for the channel \"\"\"\n    videos_data = []\n    title, uploads, subscribers = get_channel_info(api, channel_id)\n    if title is not None and uploads is not None:\n        title_ = title.replace(\";\", \",\")\n        videos = get_playlist_items(api, uploads, limit)\n        for video_id, video_published_at in videos:\n            views, likes, comments = get_video_by_id(api, video_id)\n            videos_data.append((channel_id, title_, subscribers, video_id, video_published_at, views, likes, comments))\n    return videos_data\n```", "```py\nimport pandas as pd\nimport glob\n\nchannel_files = glob.glob(\"data/video*.csv\")\nchannels_data = []\nfor file_in in channel_files:\n    channels_data.append(pd.read_csv(file_in, delimiter=\";\",\n                                     parse_dates=[\"timestamp\"],\n                                     date_format=\"%Y-%m-%d-%H-%M-%S\"))\ndf_channels = pd.concat(channels_data)\n```", "```py\ndisplay(df_channels.query('videoId == \"8J...4\"').sort_values(by=[\"timestamp\"], ascending=True))\n```", "```py\nchannel_id = \"UCu...\"\ndf_channel = df_channels[df_channels[\"channelId\"] == channel_id]\ndf_channel = df_channel.sort_values(by=['timestamp'], ascending=True)\n\n# Videos published within interval\ndays_display = 2*31\nstart_date = df_channel[\"timestamp\"].max() - pd.Timedelta(days=days_display)  \nend_date = df_channel[\"timestamp\"].max()\ndf_channel = df_channel[(df_channel[\"videoPublishedAt\"] >= start_date) &\n                        (df_channel[\"videoPublishedAt\"] < end_date)]\n```", "```py\nstep_size = 3        \ninterval_start = df_channel[\"timestamp\"].max() - pd.Timedelta(hours=step_size)\ninterval_end = df_channel[\"timestamp\"].max()\n\ndf_interval = df_channel[(df_channel[\"timestamp\"] >= interval_start) &\n                         (df_channel[\"timestamp\"] < interval_end)]\ndf_interval = df_interval.drop_duplicates(subset=[\"videoId\"])\n\nv_days = df_interval[\"videoPublishedAt\"].values\nv_views = df_interval[\"viewCount\"].values\n```", "```py\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\n\nfig, ax = plt.subplots(figsize=(16, 4))\n\ncmap = plt.get_cmap(\"Purples\")\nviews_max = 3_000_000\nviews_avg = df_channel.drop_duplicates(subset=[\"videoId\"], keep=\"last\")[\"viewCount\"].median()  # Median value\nrescale = lambda y: 0.5 + 0.5 * y / views_max\n# Bar chart\nax.bar(v_days, v_views,\n       color=cmap(rescale(v_views)),\n       width=pd.Timedelta(hours=12))\n# Add horizontal median line\nax.axhline(y=views_avg, alpha=0.2, linestyle=\"dotted\")\ntrans = ax.get_yaxis_transform()\nax.text(0, views_avg, \" Median \", color=\"gray\", alpha=0.5, transform=trans, ha=\"left\", va=\"bottom\")\n# Title\nsubscribers = df_channel.iloc[[0]][\"subscribers\"].values[0]\ntitle_str = f\"YouTube Channel, {subscribers/1_000_000:.1f}M subscribers\"\n# Adjust axis\nax.xaxis.set_major_formatter(mdates.DateFormatter(\"%d/%m\"))\nax.yaxis.set_major_formatter(FuncFormatter(lambda x, p: format(int(x), \",\")))\nax.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.SU))\nax.set(title=title_str,\n       xlabel=\"Video Publication Date\",\n       ylabel=\"Views\",\n       xlim=(start_date, end_date),\n       ylim=(0, views_max))\nplt.tight_layout()\nplt.show()\n```", "```py\nimport matplotlib.animation as animation\n\ndef animate_bar(frame_num: int):\n    \"\"\" Update graph values according to frame number \"\"\"\n    interval_start = df_channel[\"timestamp\"].min() + pd.Timedelta(hours=step_size*frame_num)\n    interval_end = df_channel[\"timestamp\"].min() + pd.Timedelta(hours=step_size*(frame_num+1))\n    day_str = interval_start.strftime('%d/%m/%Y %H:00')\n    days, views = get_views_per_interval(df_channel, interval_start, interval_end)\n    print(f\"Processing {day_str}: {views.shape[0]} items\")\n    bar = ax.bar(days, views,\n                 color=cmap(rescale(views)),\n                 width=pd.Timedelta(hours=bar_width))\n    day_vline.set_xdata([interval_start])\n\n    ax.set(title=f\"{title_str}: {day_str}\")\n    return bar,\n\nstep_size = 3\nnum_frames = (df_channel[\"timestamp\"].max() - df_channel[\"timestamp\"].min())//pd.Timedelta(hours=step_size)\nanim = animation.FuncAnimation(fig, animate_bar, repeat=True, frames=num_frames)\nwriter = animation.PillowWriter(fps=5)\nanim.save(\"output.gif\", writer=writer)\n```", "```py\nimport seaborn as sns\n\nchannel_id = \"UCu...\"\ndf_channel = df_channels[df_channels[\"channelId\"] == channel_id]\ndisplay(df_channel.drop_duplicates(subset=[\"videoId\"]))\n\nstep_size = 3\ninterval_start = df_channel[\"timestamp\"].max() - pd.Timedelta(hours=step_size)\ninterval_end = df_channel[\"timestamp\"].max()\ndf_interval = df_channel[(df_channel[\"timestamp\"] >= interval_start) & (df_channel[\"timestamp\"] < interval_end)].drop_duplicates(subset=[\"videoId\"])\n\n# Title\nsubscribers = df_channel.iloc[[0]][\"subscribers\"].values[0]\ntitle_str = f\"YouTube Channel, {subscribers/1_000_000:.1f}M subscribers\"\n# Median\nviews_avg = df_channel[\"viewCount\"].median()\n# Draw\nfig, ax = plt.subplots(figsize=(12, 5))\nsns.set_style(\"white\")\nsns.histplot(data=df_interval, x=\"viewCount\", stat=\"percent\", bins=50)\nax.set(title=title_str,\n       xlabel=\"Views Per Video\",\n       ylabel=\"Percentage\",\n       xlim=(0, None),\n       ylim=(0, 18)\n       )\nax.axvline(x=views_avg, alpha=0.2, linestyle=\"dotted\")\nax.xaxis.set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ',')))\nplt.tight_layout()\nplt.show()\n```", "```py\n# Find the newest videos for a specific channel\ndf_channel = df_channels[df_channels[\"channelId\"] == \"UCB...\"]\n\nnum_videos = 5\ndf_videos = df_channel.drop_duplicates(subset=[\"videoId\"]).sort_values(by=[\"videoPublishedAt\"], ascending=False)\n```", "```py\ndef get_normalized_views(df_channel: pd.DataFrame, video_id: str) -> pd.DataFrame:\n    \"\"\" Get relative views for a specific video \"\"\"\n    df_video = df_channel[df_channel[\"videoId\"] == video_id].sort_values(by=['timestamp'], ascending=True)\n\n    # Insert empty row with zero values at the beginning\n    video_pub_time = df_video.iloc[[0]][\"videoPublishedAt\"].values[0]\n    start_row = {'videoPublishedAt': video_pub_time,\n                 'timestamp': video_pub_time,\n                 'viewCount': 0, 'likeCount': 0, 'commentCount': 0}\n    df_first_row = pd.DataFrame(start_row, index=[0])\n    df_video_data = df_video[df_first_row.columns]\n    df_video_data = pd.concat([df_first_row, df_video_data], ignore_index=True)\n\n    # Make timestamps data relative, starting from publication time\n    df_first_row = df_video_data.iloc[[0]].values[0]        \n    df_video_data = df_video_data.apply(lambda row: row - df_first_row, axis=1)\n    df_video_data[\"daysDiff\"] = df_video_data[\"timestamp\"].map(lambda x: x.total_seconds()/(24*60*60), na_action=None)\n    return df_video_data\n```", "```py\nfig, ax = plt.subplots(figsize=(10, 6))\n# Title\nsubscribers = df_channel.iloc[[0]][\"subscribers\"].values[0]\ntitle_str = f\"YouTube Channel with {subscribers/1_000_000:.1f}M Subscribers, Video Views\"\n# Videos data\nfor p in range(num_videos):\n    video_id = df_videos.iloc[[p]][\"videoId\"].values[0]\n    df_video_data = get_normalized_views(df_channel, video_id)\n    plt.plot(df_video_data[\"daysDiff\"], df_video_data[\"viewCount\"])\n# Params\nax.set(title=title_str,\n       xlabel=\"Days Since Publication\",\n       ylabel=\"Views\",\n       xlim=(0, None),\n       ylim=(0, None))\nax.yaxis.set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ',')))\nax.tick_params(axis='x', rotation=0)\nplt.tight_layout()\nplt.show()\n```"]