- en: 'Automating Chemical Entity Recognition: Creating Your ChemNER Model'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/text-mining-for-chemists-a-diy-guide-to-chemical-compound-labeling-ea3145e24dc4](https://towardsdatascience.com/text-mining-for-chemists-a-diy-guide-to-chemical-compound-labeling-ea3145e24dc4)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://victormurcia-53351.medium.com/?source=post_page-----ea3145e24dc4--------------------------------)[![Victor
    Murcia](../Images/0041e70a3e7b6b643338a9570257a719.png)](https://victormurcia-53351.medium.com/?source=post_page-----ea3145e24dc4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ea3145e24dc4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ea3145e24dc4--------------------------------)
    [Victor Murcia](https://victormurcia-53351.medium.com/?source=post_page-----ea3145e24dc4--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ea3145e24dc4--------------------------------)
    ·15 min read·Nov 16, 2023
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8f85d501be5dff1e61e9629b62c49954.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
- en: Photo by [Aakash Dhage](https://unsplash.com/@aakashdhage?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/a-group-of-gold-and-silver-spheres-uV5n4TrFs8M?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: I’ve always had a strong interest in chemistry, and it has played a significant
    role in shaping both my academic and professional journey. As a data professional
    with a background in chemistry, I’ve found many ways to apply both my scientific
    and research skills like creativity, curiosity, patience, keen observation, and
    analysis to data projects. In this article, I’ll walk you through the development
    of a simple Named Entity Recognition (NER) model that I’ve dubbed ChemNER. This
    model can identify chemical compounds within text and classify them into categories
    such as alkanes, alkenes, alkynes, alcohols, aldehydes, ketones, or carboxylic
    acids.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: TL;DR
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you just want to play around with the ChemNER model and/or use the Streamlit
    app I made, you can access them via the links below:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '***HuggingFace link:*** [https://huggingface.co/victormurcia/en_chemner](https://huggingface.co/victormurcia/en_chemner)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '***Streamlit App***: [ChemNER Link](https://chemner-5i7mrvyelw79tzasxwy96x.streamlit.app/)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'NER approaches can be generally classified into one of the following 3 categories:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: 'Lexicon-based: Define a dictionary of classes and terms'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rule-based: Define rules the terms that correspond to each class'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Machine Learning (ML) — based: Let the model learn the naming rules from a
    training corpus'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of these approaches has their strengths and limitations and as always,
    a more complicated and sophisticated model isn’t always the best approach.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the lexicon-based approach would be limiting in terms of scope
    since for every class of compounds we are interested in classifying we’d have
    to manually define ALL the compounds that fall within that category. In other
    words, for this approach to be all encompassing you’d need to manually enter every
    chemical compound for every compound class.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，基于词汇表的方法在范围上会有限，因为对于我们感兴趣的每一类化合物，我们都需要手动定义该类别中的所有化合物。换句话说，为了使这种方法全面，你需要手动输入每个化合物类别的所有化合物。
- en: 'The ML approach could be the most powerful way to go, however, annotating a
    dataset can be quite laborious (spoiler alert: I’ll end up training a model but
    I want to show the entire process for educational purposes). Instead, how about
    we start with some predefined naming rules?'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习方法可能是最强大的选择，然而，注释数据集可能非常繁琐（剧透：我会训练一个模型，但我想展示整个过程以供学习）。那么，我们不妨从一些预定义的命名规则开始？
- en: Chemical nomenclature has a well-established and defined set of rules that allow
    you to readily determine what functional groups are present in a molecule. These
    rules have been established by the International Union of Pure and Applied Chemistry
    (IUPAC) and can be readily accessed via a the [IUPAC Blue Book](https://iupac.org/what-we-do/books/bluebook/),
    a variety of websites, or in any Organic Chemistry textbook. For instance, hydrocarbons
    are compounds composed solely of Carbon and Hydrogen atoms. There are three main
    classes of hydrocarbons named alkanes, alkenes, and alkynes which can be readily
    identified based on whether they have single, double or triple bonds respectively
    as part of their chemical structure. Below I’m showing an example of three chemical
    compounds (ethane, ethene, and ethyne) depicting that.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 化学命名法有一套完善且明确的规则，使你能够轻松确定分子中存在的功能团。这些规则由国际纯粹与应用化学联合会（IUPAC）制定，可以通过[IUPAC蓝皮书](https://iupac.org/what-we-do/books/bluebook/)、各种网站或任何有机化学教科书轻松获取。例如，烃是仅由碳和氢原子组成的化合物。烃主要有三类，分别是烷烃、烯烃和炔烃，可以根据其化学结构中是否包含单键、双键或三键来识别。下面我展示了三个化学化合物（乙烷、乙烯和乙炔）的例子。
- en: '![](../Images/1cb61b47fb9b27efeb79734874746989.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1cb61b47fb9b27efeb79734874746989.png)'
- en: Ethane, ethene, and ethyne. Image by author.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 乙烷、乙烯和乙炔。图片作者提供。
- en: The important thing for us here are the endings of the names (i.e., their suffixes)
    since it is what will allow us to differentiate between chemical compounds. For
    example, alkanes are identified by the suffix of *-ane*, alkenes by the suffix
    *-ene*, and alkynes by the suffix *-yne*. Every class of chemical compounds like
    alcohols, ketones, aldehydes, carboxylic acids, etc. has unique naming schemes
    like that which will serve as the basis for this project.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们来说，重要的是名字的结尾（即后缀），因为这将使我们能够区分化学化合物。例如，烷烃由后缀* -ane* 标识，烯烃由后缀* -ene* 标识，炔烃由后缀*
    -yne* 标识。每类化学化合物如醇、酮、醛、羧酸等都有独特的命名方案，这些方案将作为该项目的基础。
- en: '**Establishing the Rules**'
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**建立规则**'
- en: 'Now that we have a bit of background to understand what’s going on, I’ll show
    how a rule-based approach can be implemented in Python using Spacy. I’ll start
    simple by just dealing with the hydrocarbons. We’ll add the other classes later.
    To do this, we’ll first load a blank English model with Spacy and add an ‘Entity
    Ruler’ component to our pipeline:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一些背景知识来理解发生了什么，我将展示如何使用Spacy在Python中实现基于规则的方法。我将从处理烃开始，稍后会添加其他类别。为此，我们首先将使用Spacy加载一个空白的英语模型，并将‘实体规则器’组件添加到我们的管道中：
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we’ll establish the rules/patterns that define each class and add them
    to the rules component:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将建立定义每一类的规则/模式，并将其添加到规则组件中：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: And that’s it! Now let’s make some text to feed to our model and see how it
    does!
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！现在让我们创建一些文本以供模型使用，看看效果如何！
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output of this is as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'That’s pretty good! However, there are two immediate limitations that you probably
    realized with this initial approach:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 非常好！然而，你可能已经注意到这个初始方法有两个直接的局限性：
- en: Plural versions of a compound will not be detected with the current regex.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当前的正则表达式无法检测化合物的复数形式。
- en: Basing the classification purely on the suffixes will result on lots of incorrectly
    labeled entities.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仅基于后缀的分类会导致很多错误标记的实体。
- en: 'Though chemical compounds are typically considered as uncountable nouns (think
    of words like air or music) there are still instances where the plural version
    can be utilized. For instance, if you were dealing with a collection of ethane
    molecules, someone might refer to that as a group of ethanes instead. Therefore,
    the first point can be easily addressed by modifying our regex to the form below:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now both singular and plural instances will be recognized by the entity ruler.
    However, the second point remains. As an example, words like arcane, humane, thane,
    lane and mundane to name but a few, if present in the text would be incorrectly
    labeled as alkanes.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: 'Though there are other rules that could be implemented to bolster this approach,
    they would require a fair amount of extra work. Because of that there are three
    approaches I’m considering to deal with our limitation:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Build a corpus to train a ML-based NER model for this application
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use Named Entity Linking (NEL) to aid in correcting any labeling mistakes made
    by the model output
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fine-tune a transformer model like SciBERT or PubMedBERT on a custom dataset
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For this article, I’ll just cover the first two approaches. However, if there
    is interest, I’ll show how the fine-tuning process could be achieved in a future
    article.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Making the Dataset
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are a variety of different ways to create a corpus. A quick and easy
    way to generate this corpus is to have chatGPT create a set of sentences that
    contained compounds involving the various classes that I want to extract from
    text. The reason this works nicely is because this approach allows me to curate
    and tailor my dataset which makes the subsequent annotation process much easier.
    My prompt was simply:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: And then I repeated that prompt for the other classes I was interested in (i.e.,
    alkenes, alkynes, alcohols, ketones, aldehydes, and carboxylic acids). Since I
    have 7 classes, I ended up with a total of 350 sentences making up my corpus.
    Ideally, this corpus would be larger but it is a good enough start since I’m primarily
    interested in illustrating this as a proof of concept more than anything else.
    Plus, it is always easier to simply add more data as needed to improve performance.
    I saved my sentences into a document called chem_text.txt.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/455a61682039610e633814072a023265.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
- en: Screenshot of corpus made for ChemNER. Image by author
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: As a final step, I’ll use a sentence tokenizer to split each sentence in the
    document.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now that I have this corpus made, we need to start labeling it. There’s a couple
    ways to do this. For instance, we can use an annotation tool like [Prodigy](https://prodi.gy/)
    (which is amazing and you should use it if you do any kind of NLP) or we can use
    the rule-based approach from earlier to help us with the initial annotation. For
    now, I’ll use the model approach since I’m not annotating a huge dataset.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'To include all the classes I’m interested in, the rules will need to be updated
    to the ones below:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The result of running the rule-based approach allows us to quickly annotate
    our dataset as shown below.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 运行基于规则的方法的结果使我们可以快速标注我们的数据集，如下所示。
- en: '![](../Images/9f09d24df9497b2fbe923820a948d229.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9f09d24df9497b2fbe923820a948d229.png)'
- en: Annotated corpus for ChemNER. Image by author.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ChemNER的标注语料库。图片由作者提供。
- en: 'We are almost ready to split our corpus into training and test sets, however,
    we need to verify the quality of our annotations before moving forward. Upon,
    inspecting my dataset, I noticed that we ran into the mislabeling issue I alluded
    to earlier. Words like “essential”, “crystals”, “potential”, “materials” amongst
    several others were found in the dataset and were labeled as aldehydes which highlights
    the limitation of the rule-based approach. I manually removed these labels using
    the method below and reprocessed the annotations on the corpus:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经接近将语料库分为训练集和测试集，但在继续之前，我们需要验证标注的质量。检查数据集时，我注意到出现了之前提到的错误标注问题。数据集中出现了“essential”、“crystals”、“potential”、“materials”等词语，这些词被标注为醛类，这突显了基于规则的方法的局限性。我使用下面的方法手动移除了这些标签，并重新处理了语料库上的标注：
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now we are ready to create our training and test sets. This can be easily done
    with the train_test_split function from scikit-learn. I used the standard 80:20
    train:test split.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好创建训练集和测试集。这可以通过scikit-learn中的train_test_split函数轻松完成。我使用了标准的80:20训练:测试划分。
- en: '[PRE10]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Training the Model
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练模型
- en: 'We have our training data ready and we can go ahead and start training our
    model. To train the model, I used the default Spacy NER training parameters like
    an Adam optimizer and a 0.001 learning rate. The training took just over an hour
    on a CPU in Google Colab which could be greatly reduced if using a GPU instead.
    The results of the training are shown below:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的训练数据已经准备好，我们可以开始训练模型。为了训练模型，我使用了默认的Spacy NER训练参数，如Adam优化器和0.001的学习率。训练在Google
    Colab的CPU上花费了一个多小时，如果使用GPU，则时间会大大缩短。训练结果如下所示：
- en: '![](../Images/5912100df7ddecfcec5a75bf024e5b39.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5912100df7ddecfcec5a75bf024e5b39.png)'
- en: Training results of ChemNER model. Image by author.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ChemNER模型的训练结果。图片由作者提供。
- en: The plots above show the F1 score, Precision, Recall, and Overall Score of this
    model tended to increase over the course of training which is good. The NER loss
    which corresponds to the loss of the NER component overall tended to a minimum.
    The ultimate performance score of the model is 0.97 which seems promising.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图表显示了该模型在训练过程中F1得分、准确率、召回率和整体得分的趋势都在上升，这很好。与NER组件相关的NER损失总体上趋向于最小值。该模型的最终性能得分为0.97，看起来很有前景。
- en: The Tok2Vec loss however noticeably spiked at around Epoch 300 which could be
    a result of too high of learning rate, vanishing/exploding gradients causing numerical
    instabilities, or overfitting issues amongst others. The Tok2Vec loss represents
    the effectiveness of the token-to-vector part of the model responsible of converting
    tokens to vectors. There are a variety of ways to handle this if we so choose,
    but for now, I’ll carry on.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Tok2Vec损失在大约第300个Epoch时明显上升，这可能是由于学习率过高、梯度消失/爆炸导致数值不稳定或过拟合等问题。Tok2Vec损失表示模型中负责将令牌转换为向量的token-to-vector部分的有效性。如果我们选择，可以有多种方式来处理这个问题，但现在，我会继续进行。
- en: Testing the Model
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试模型
- en: 'Let’s start by doing a simple test. I’ll feed it a few sentences and see how
    well it classifies them. You can see the result below:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从简单的测试开始。我将输入几句话，看看它的分类效果如何。结果如下所示：
- en: '![](../Images/774034f3aa76aeea5e3ccb59771cdd7e.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/774034f3aa76aeea5e3ccb59771cdd7e.png)'
- en: Initial test of ChemNER model. Image by author.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ChemNER模型的初步测试。图片由作者提供。
- en: Nice! It extracted all the relevant entities AND it labeled them all correctly!
    That’s the cool thing about the ML approach. Instead of us having to explicitly
    write the rules, the algorithm will learn it over the course of training. As cool
    as this is however, let’s now put the model onto a bit more stress.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 很棒！它提取了所有相关实体，并且全部标注正确！这就是机器学习方法的酷炫之处。与其我们显式编写规则，不如算法在训练过程中自我学习。虽然这很酷，但现在我们来对模型施加更多压力。
- en: Querying Wikipedia (stress testing)
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查询维基百科（压力测试）
- en: 'I want to stress test my model a bit more, therefore, I figured that a quick
    and easy way to do this is by feeding the model an entire Wikipedia article and
    see how it performs. I’ll write a quick routine to accomplish this via the wikipedia-api
    package in Python:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我想对我的模型进行更多的压力测试，因此我认为快速且简单的方法是将整个维基百科文章输入模型，看看它的表现。我将编写一个简单的程序，通过 Python 的
    wikipedia-api 包来实现：
- en: '[PRE11]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'With that, I will now look for the Wikipedia article on Benzene:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我将查找有关苯的维基百科文章：
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'And the result of this produces:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这样产生的结果是：
- en: '![](../Images/b42ff1469ae35d21054f3cae60c926cf.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b42ff1469ae35d21054f3cae60c926cf.png)'
- en: Screenshot of query for Benzene Wikipedia article.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 苯维基百科文章查询的截图。
- en: 'Neat! Now that we’ve verified the querying works let’s run the ChemNER model.
    The ChemNER model extracted a total of 444 entities from the Benzene article.
    The extraction of these entities took less than a second. I placed the results
    into a dataframe and visualized the label counts in a count plot below:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 很棒！现在我们已经验证了查询工作正常，让我们运行 ChemNER 模型。ChemNER 模型从苯的文章中提取了总共 444 个实体。这些实体的提取时间不到一秒。我将结果放入数据框中，并在下面的计数图中可视化标签计数：
- en: '![](../Images/d4b804735e27d7d70b1c0a0fb38671ec.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d4b804735e27d7d70b1c0a0fb38671ec.png)'
- en: ChemNER results on Benzene Wikipedia article. Image by author.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ChemNER 对苯维基百科文章的结果。图片由作者提供。
- en: The most common class within that article was alkene which makes sense given
    that that’s the class of compound Benzene corresponds to. Something that I thought
    was a bit surprising was that this particular article had entities belonging to
    each class.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 该文章中最常见的类别是烯烃，这很有意义，因为苯对应的正是这一化合物类别。我觉得有点意外的是，这篇文章中包含了每个类别的实体。
- en: This is neat, however, a quick inspection of the first few rows in the dataframe
    of extracted entities we can see that there are issues with the model. The words
    ‘chemical ‘and ‘hexagonal’ were labeled as an aldehyde and the word ‘one’ was
    labeled as a ketone. These are clearly not chemical compounds and should not be
    classified as such. I went ahead and manually identified each entity as being
    correct or not and I determined that the extraction accuracy was 70.3%. Though
    all the extracted entities that were extracted were labeled ‘correctly’ based
    on the rules the model learned, the model has not yet truly learned the context
    of the words.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这很有趣，不过，通过快速检查数据框中提取的实体的前几行，我们可以看到模型存在一些问题。‘chemical’ 和 ‘hexagonal’ 被标注为醛，而‘one’
    被标注为酮。这些显然不是化学化合物，不应被分类为此。我手动识别了每个实体是否正确，并确定提取的准确率为 70.3%。尽管所有提取的实体根据模型学到的规则都被标注为‘正确’，但模型尚未真正理解词汇的上下文。
- en: '![](../Images/40f57f8a7b9917a8a9f1df97ad94b94a.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/40f57f8a7b9917a8a9f1df97ad94b94a.png)'
- en: Comparison of correctly and incorrectly labeled entities on Benzene article
    by ChemNER. Image by author.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ChemNER 对苯的文章中正确和错误标注的实体比较。图片由作者提供。
- en: The cool thing that I noticed though, is that the correctly labeled entities
    were all chemical compounds. In other words, if we had a way to determine whether
    an entity is a chemical compound, then we could significantly bolster the labeling
    performance of this application.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 不过我注意到一个有趣的地方，即正确标注的实体全都是化学化合物。换句话说，如果我们能确定一个实体是否是化学化合物，那么我们可以显著提高该应用程序的标注性能。
- en: At this point, there are a couple avenues we can take. One avenue is to go back
    to the corpus and produce more data to give our model examples to learn from.
    Another avenue, is to use named entity linking (NEL) to help correct the labeling.
    I’ll go with the latter option since it is a little less time consuming.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们可以采取几种途径。其中一种途径是回到语料库中生成更多的数据，以便为我们的模型提供学习示例。另一种途径是使用命名实体链接（NEL）来帮助纠正标注。由于后者耗时较少，我决定选择这个选项。
- en: Using PubChem for NEL
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 PubChem 进行 NEL
- en: The ChemNER model is performing exceptionally well at labeling entities according
    their chemical class so long as the entity is a chemical compound. In order to
    better inform the model, I’ll connect to [PubChem](https://pubchem.ncbi.nlm.nih.gov/docs/pug-rest)
    via their API and conduct a query for a chemical compound. The idea here is that
    a query for a chemical compound will return information whereas a query for nonchemical
    compound will return an empty query. I can use the results of this query to improve
    the labeling performance of my application.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: As an example to showcase this, let’s query for Benzene to start off. The code
    below can be used to query the PubChem API.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The results of this query are shown below.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c0b753cbff662d2f5031629e39272dc5.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
- en: Results of Benzene query via the PubMed API. Image by author.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: There is A LOT of information on Benzene from this query that we can use later.
    But for now, all that matters is that the query returned something. On the other
    hand, if I use this same method to query for something that is not a chemical
    compound, like the word ‘humans’ or ‘giraffe’, for instance, then the result of
    that query is ‘None’.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9392a16b852339ff52a309ac9f1b5e4e.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
- en: Querying for non-chemical compounds on PubMed API. Image by author.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: I can use this to my advantage to aid my application. The queries are quite
    fast, however, to speed up the process a bit more, I’ll remove any duplicate entities
    from my dataframe in order to query only unique terms. In addition to this, the
    PubChem API appears to assume that we are querying for an individual chemical
    compound so words like cinammaldehydes for instance would return an empty query.
    This can be easily fixed by stripping any terminal ‘s’ from any plural terms.
    I used the following code to create a new column in my dataframe called ‘Chemical
    Compound’ that will allow me to classify each entity as either a chemical compound
    or not based on the result of the query.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/88d2a3955a460072909f6b70dc2830f3.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
- en: That worked quite well! One more thing that I noticed upon doing this however
    is that the class labels themselves result in null queries. In other words, if
    I query PubChem for alkane, alkene, alkyne, etc. I get an empty query because
    these are not specific compounds themselves but rather classes of compounds. There
    is a bit of nuance here regarding how to proceed. I decided that I did want these
    classes of compounds to be recognized as chemical entities since the class labels
    can be used independently in sentences devoid of specific compounds (e.g., Alkanes
    are commonly found in petrochemical applications). To resolve this, I simply added
    a simple routine that would check whether the entry in the Entity column is either
    a singular or plural variant of any of our class labels and then set the value
    in the Chemical Compound column to 1 if the entity matches the label or 0 if it
    doesn’t.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Cool! Now I can now merge these results into the original dataframe containing
    all 444 results.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](../Images/7a7c245ecabdc41ed3d2a3bd5362f7a1.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
- en: Entity dataframe after using the PubChem API to check whether an entity is a
    chemical compound. Image by author.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Next, I’ll drop any rows that don’t correspond to a chemical compound.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![](../Images/e7e63c150e714f8283ba558f5c7c56b8.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
- en: Resulting dataframe after removing entities that are not chemical compounds.
    Image by author.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: And now let’s see how it performed!
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d7b5f05d610a860c0e00617bba487031.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
- en: Results of ChemNER after performing NEL via PubChem. Image by author.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Very nice! All of the extracted entities are now correctly labeled. By combining
    our NER model alongside NEL via PubChem we are now able to not only extract the
    entities from the text but also disambiguate results and use that to vastly improve
    our labeling accuracy.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the Model into HuggingFace
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As a little bonus, I thought it would be cool to take all of these routines
    I’ve showed and deploy the model into HuggingFace so that I can showcase it in
    a streamlit application. You can find the model in HuggingFace in this [https://huggingface.co/victormurcia/en_chemner](https://huggingface.co/victormurcia/en_chemner).
    The Inference API results are shown below which look pretty good:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c630e630b1f18e81b3a9f8bfdeea68ea.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
- en: ChemNER in action via the HuggingFace Inference API. Image by author.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: Let me know if you use it or if you have any suggestions! I’m planning on expanding
    the model in the future and there are other functionalities I want to explore.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Connecting Everything with a Streamlit App
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that the model is deployed, I can use it in a Streamlit App. This app will
    allow a user to either link to a Wikipedia article or enter raw text that will
    then be processed by the ChemNER model. The output of this routine will be a downloadable
    dataframe with the extracted and labeled entities, a count plot showing the counts
    for each of the labels in the provided text, and a fully annotated version of
    the text. You can find the Streamlit app hosted here: [https://chemner-5i7mrvyelw79tzasxwy96x.streamlit.app/](https://chemner-5i7mrvyelw79tzasxwy96x.streamlit.app/)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ef419cdb751cd07ec390bb6580fa6939.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
- en: Screenshot of ChemNER Streamlit App. Image by author.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: As an example, I’ll run a query for the Wikipedia article on Benzene below using
    the app. The result is an annotated version of the article as shown below where
    each class has been uniquely color coded.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/43ce6b39b06b7867ca0515c0debcec56.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
- en: Annotated text from ChemNER. Image by author.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: The output is also a dataframe that you can download as a .csv file containing
    the entities and their corresponding labels and a count plot that shows
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a88fe9a5051a3792173776e666fa3e6a.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
- en: Output from Streamlit app. Image by author.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I hope you found this piece informative and helps you build your own NLP applications.
    I plan on continue to work on this model and application a bit more since I think
    there is some nifty stuff I’d like to further explore. For instance, after a bit
    of testing I noticed that there were still certain entities that the model extracted
    and the PubChem method classified as chemical compounds that were not organic
    compounds. For instance, the word ‘pm’ was extracted as an entity and labeled
    as an aldehyde. The PubChem search returned a non-empty query since ‘pm’ (or more
    appropriately Pm) is the chemical symbol for the element Promethium. The model
    is not perfect but I hope it shows that you can get a pretty powerful tool without
    requiring a LLM.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你觉得这篇文章有信息量，并且对你构建自己的NLP应用有所帮助。我计划继续在这个模型和应用上做一些工作，因为我认为还有一些有趣的内容我想进一步探索。例如，经过一些测试，我注意到模型提取出的某些实体被PubChem方法归类为化学化合物，但实际上它们并不是有机化合物。例如，‘pm’这个词被提取为一个实体，并被标记为醛。PubChem搜索返回了一个非空的查询，因为‘pm’（更准确地说是Pm）是元素铽的化学符号。这个模型并不完美，但我希望它能展示出你可以在不需要LLM的情况下获得一个相当强大的工具。
- en: As always, thanks for reading!
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，感谢你的阅读！
