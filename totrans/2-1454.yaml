- en: Machine Learning for Jiu Jitsu
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/machine-learning-for-jiu-jitsu-94a0b44f57ab](https://towardsdatascience.com/machine-learning-for-jiu-jitsu-94a0b44f57ab)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/991deef0a7510879d427ecc024fde83e.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: '*Photo by Kampus Production from Pexels:* [*https://www.pexels.com/photo/a-judoka-throwing-an-opponent-to-the-ground-6765024/*](https://www.pexels.com/photo/a-judoka-throwing-an-opponent-to-the-ground-6765024/*)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Using pose estimation with mediapipe to track Jiu Jitsu movements
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://lucas-soares.medium.com/?source=post_page-----94a0b44f57ab--------------------------------)[![Lucas
    Soares](../Images/205b650cc15f93ddee1c2888e09715d5.png)](https://lucas-soares.medium.com/?source=post_page-----94a0b44f57ab--------------------------------)[](https://towardsdatascience.com/?source=post_page-----94a0b44f57ab--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----94a0b44f57ab--------------------------------)
    [Lucas Soares](https://lucas-soares.medium.com/?source=post_page-----94a0b44f57ab--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----94a0b44f57ab--------------------------------)
    ·18 min read·Mar 13, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '**Pose Tracking To Get Better at Jiu Jitsu**'
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Brazilian Jiu-Jitsu is a martial art that has been getting a lot of popularity
    recently due to its effectiveness and applicability in real-world combat.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: I’ve been practicing Brazilian Jiu Jitsu for over 10 years and I decided to
    join my interests in martial arts and machine learning to come up with a project
    that lived at the intersection of these 2 really interesting fields.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, I turned to [pose estimation](https://en.wikipedia.org/wiki/3D_pose_estimation)
    as a promising technique for a complimentary tool to aid with my development in
    Jiu Jitsu.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '***In this article, I would like to share with you how to use pose tracking
    to enhance feedback correction when performing fighting movements.***'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: 'If you prefer video, check out my Youtube Video on this topic here:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '**What is Pose Tracking?**'
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pose tracking is the process of detecting and tracking the movement of a person’s
    body in real-time using computer vision technology. It involves using algorithms
    to capture and interpret the movement of various body parts, such as the arms,
    legs, and torso.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: This technique can be relevant for analyzing body movement in sports, as it
    allows coaches and athletes to identify and correct movement patterns that may
    be negatively impacting performance or causing injuries.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: By providing real-time feedback, athletes can make adjustments to their technique,
    leading to improved performance and reduced risk of injury. Additionally, this
    technology can be used to compare movements to those of top performers in the
    sport for example, to help beginners identify areas for improvement and refine
    their technique accordingly.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '**What is Jiu Jitsu?**'
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Jiu Jitsu is a martial art centered around the idea of subduing opponents through
    a combination of pins and submission holds like joint locks and chokes.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Jiu Jitsu focuses on grappling and ground fighting techniques. It was initially
    developed in Japan and later modified and popularized in Brazil. But now, it has
    spread all over the world due to its increase in popularity particularly in the
    United States.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: The basic principle is that a smaller, weaker person can defend against a larger,
    stronger opponent by using leverage and technique. Practitioners aim to control
    their opponent’s body and position themselves in a dominant position where they
    can execute techniques such as chokes, joint locks, and throws.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3386f99ab575e1925801eea91c2bce27.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
- en: '*Image by Timoth Eberly in* [*https://unsplash.com/photos/7MRajrPiTqw**](https://unsplash.com/photos/7MRajrPiTqw*)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Jiu Jitsu is now a popular sport and self-defense system practiced all over
    the world. It requires physical and mental discipline, as well as a willingness
    to learn and adapt.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: It has also been found to have numerous benefits, including [improved physical
    fitness and mental acuity, increased confidence and self-esteem, as well as stress
    relief](https://era.library.ualberta.ca/items/205b4732-a385-427c-b12e-45f25d9e5150).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '**Why Pose Tracking for Jiu Jitsu**'
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The large emphasis on technique makes this martial art quite unique, and in
    the context of a jiu jitsu gym, it is usually the role of the black belt coach
    to give feedback to the student regarding the appropriateness of his or her execution
    of different techniques.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: However, it’s often the case that people want to learn but either don’t have
    the access to an expert, or the class contains too many students and it becomes
    difficult for the person conducting the class to give specific and personal feedback
    regarding whether or not the student is performing the movements correctly.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Within this gap of feedback is that I think tools like pose tracking can greatly
    benefit the world of martial arts in general and Jiu Jitsu in particular (although
    one can argue the same for Judo, wrestling, and striking-based martial arts as
    well), because they could be seamlessly integrated into a smartphone only requiring
    athletes to film themselves while performing the movement they are trying to improve.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: The form of this feedback is something that would have to be developed, and
    this article is an attempt to provide directions for how such a machine learning
    based feedback system would work for helping students get better at performing
    foundational movements in the sport.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '**Why Did I Do This?**'
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ok, so here is the story.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: 'Usually, when you develop your Jiu Jitsu skills, you end up falling under one
    of 2 categories: bottom player, or top player. That means whether you tend to
    play from the bottom using your “guard” (a reference to the usage of the legs
    to perform attacks on the opponent) or from the top by first taking down your
    opponent and then proceeding to pass the line of their legs to (usually) reach
    a dominant position like being mounted on your opponent or taking his/her back.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/36475135bb977f7f9b6d4fa11c0377db.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
- en: Image by Nolan Kent in [https://unsplash.com/photos/x_V62hOwnDk?utm_source=unsplash&utm_medium=referral&utm_content=creditShareLink](https://unsplash.com/photos/x_V62hOwnDk?utm_source=unsplash&utm_medium=referral&utm_content=creditShareLink)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Such a duality is obviously artificial, and usually, most experienced players
    can play both positions extremely well.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: However, it is the case that people tend to lean towards preferences at the
    beginning of their journey in Jiu Jitsu, and that can hugely impact their progress
    in other areas if they get stuck executing the same strategy over and over.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: In a way, that’s what happened to me, I used to fight a lot as a guard player,
    due to a predominant culture in Brazil that fosters starting the grappling bouts
    from the knees to avoid either injuries or because the mat space is not big enough
    like wrestling mats in big High School Gyms in the US.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/537ad1e9057363a6fe037e3587aa4390.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: '*Image by the author. Photos of me in competition pulling guard.*'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: This habit of sitting down and fighting from the back willingly without engaging
    my opponents in the standup game, had a negative impact on my development as a
    martial artist because as I became better and better at Jiu Jitsu, I realized
    that one thing holding me back was my lack of high-level knowledge on how to take
    people down.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: This ignited a fire in me to start working more from a standing position, and
    I went on to study and practice Wrestling and Judo after a couple of years into
    my brown belt.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Over the last 2 years I have been mostly a top player, and indeed improved quite
    a bit my ability to take people to the ground.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f5f342992992a27c4331a53aa88c4002.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
- en: '*Image by the author. My wrestling journey.*'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: However, there are certain foundational movements in Judo for example that are
    extremely difficult to develop, and because I don’t know any Judo experts, nor
    do I live close to any high-level Judo or Wrestling gyms, I realized that I needed
    another way to improve certain foundational movements, specifically the hips mobility
    for takedowns like the “Uchimata” and other hip based throws.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/991deef0a7510879d427ecc024fde83e.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
- en: '*Photo by Kampus Production from Pexels:* [*https://www.pexels.com/photo/a-judoka-throwing-an-opponent-to-the-ground-6765024/*](https://www.pexels.com/photo/a-judoka-throwing-an-opponent-to-the-ground-6765024/*)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '**Machine Learning Comes In**'
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Ok, so with the goal of improving my ability to perform Judo throws like the
    Uchimata, I concocted a “geeky” plan: I’m gonna use Machine Learning (I know,
    such a specific plan).'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: I decided I wanted to investigate whether or not I could use Pose Tracking to
    gather insight on how to correct things like the speed and direction of the feet
    and other aspects of executing these movements.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: So let’s get into how I did that.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '**Steps on Using Pose Tracking to Generate Insights for Jiu Jitsu**'
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The overall plan was this:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Find a video reference containing the movement I was looking to emulate
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Record myself performing the movement many times
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Generate insights using pose tracking and visualization with Python.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: 'To do all of that I needed a reference video of an elite-level practitioner
    performing the move I was trying to learn. In the case of the uchimata, I found
    this video of an Olympic-level player performing a warm-up technique against the
    wall that is directly relevant to what I wanted to learn:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Then I started recording myself performing the movement, at least the ones where
    I am actively learning a certain move.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e9845ae3305cf210f0956feeeed1ea42.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
- en: Image by the author.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: In possession of the reference video, and now having recorded some of my own
    footage, I was ready to try out some fun machine learning stuff.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '**Pose Tracking to Track Body Joints**'
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the pose tracking I used something called [mediapipe](https://google.github.io/mediapipe/),
    Google’s open-source project for facilitating the application of machine learning
    to live and streaming media.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/google/mediapipe?source=post_page-----94a0b44f57ab--------------------------------)
    [## GitHub - google/mediapipe: Cross-platform, customizable ML solutions for live
    and streaming media.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: MediaPipe offers cross-platform, customizable ML solutions for live and streaming
    media. End-to-End acceleration …
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/google/mediapipe?source=post_page-----94a0b44f57ab--------------------------------)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: The ease of use of this option got me excited to try it out.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: 'In essence, I did the following:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. First I created some videos with the pose estimation overlayed**'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. Created real-time plots of the x,y, and z coordinates of the feet to
    illustrate the main aspects of the movement**'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '**3\. Created traces that represented the execution of a certain move at a
    given time**'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '**4\. Compared the traces produced by my attempts to a reference trace produced
    by the expert’s video**'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '**The Preliminary Results**'
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**1\. Pose estimation overlayed**'
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I wrote this code to create videos where the model estimates the position of
    the body joints
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: and overlays them in the actual footage to showcase the robustness of the model.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d554d70f9b835e6d4d71854e500e80a4.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
- en: Image by author
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Yes, yes I know, I don’t look exactly elite-level. But give me a break, my Judo
    skills are under construction!
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'The code I used for this was:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This essentially leverages the mediapipe package to generate a visualization
    that detects the keypoints and overlays them on top of the video footage.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. Realtime plots of the X, Y, and Z coordinates of the feet**'
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'And then, I generated a plot containing the timeline of the x,y,z coordinates:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The idea with this would be to have granular control over things like, the direction
    of your feet when executing a movement.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Now that I was confident that the model was properly capturing my body pose,
    I created some trace visualizations of relevant body joints like the feet (which
    is really important when performing takedown techniques).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '**3\. Creating traces of motion**'
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To have an idea of how the move is performed I produced a visualization that
    represented the execution of that movement from the perspective of a body part,
    in this case, the feet:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0985400eb75965f967e0465b4b7be0a5.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
- en: Image by author
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: I did it both for my training sessions and for the reference video containing
    the motion I was trying to imitate.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note here that there are many issues with doing this that
    regard the resolution of the camera, the distance at which the movements were
    performed as well as the frame rate of the recording of each video, however, I
    am just going to bypass all of that to create a fancy plot (LoL).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: 'Again the code for this approach:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Here I am simply processing each frame as I did before to produce the pose videos,
    however, I am also appending the x, and y coordinates of the particular body part
    into a list I call `trace` which is used to produce the tracing line that accompanies
    the body part throughout the video.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Comparing the Traces
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In possession of these capabilities, I could finally get into the part of gathering
    insights from this approach.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: To do that, I needed a way to compare these traces in order to produce some
    type of visually rich feedback that could help me understand how my poor execution
    of the movement compared to that of an elite athlete.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: Now, the actual traces without the video in the background were plotted into
    a graph.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Ok, with this we start to see more clearly the differences between the signature
    shape of the foot moving in different contexts.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: First, we see that while the elite player does more of a straight step into
    a turn, generating an almost complete half circle with his feet, I, on the other
    hand, have this curvature appearance to my initial step inside, and also do not
    create a half circle when throwing my leg into the air.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Also, while the elite player generates a wide circle when moving his leg up,
    I create a shallow circle almost like an eclipse.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bc7057e050b5da3063f48beb53879f87.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
- en: Image by author, comparing traces for movement execution
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: I found these preliminary results to be quite nice because they indicate that,
    despite the limitations of the comparison, one can gauge differences regarding
    the signature shape of the movement’s execution just by observing traces like
    these.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Besides that, I wanted to see if I could make comparisons regarding the speed
    with which the moves are performed, to analyze that I visualized the real-time
    motion of the coordinates of the body joints in time, putting the plots of me
    and the expert side by side to see how off was my timing.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: The challenge with this analysis is that, since the videos have varying speeds
    and are not aligned in any way, I needed first to align them in a meaningful way.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: 'I was not sure which technique to use here, but a conversation with my buddy
    Aaron (a neuroscientist at the Champalimaud Neuroscience Institute in Lisbon)
    kind of illuminated an option for me: dynamic time warping.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '**Comparing Speed and Timing using Dynamic Time Warping**'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '[Dynamic time warping (DTW)](https://en.wikipedia.org/wiki/Dynamic_time_warping)
    is a technique used to measure the similarity between two temporal sequences with
    different speeds.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: The essential idea is that you have two different time series that may have
    some pattern you wish to analyze, so you attempt to align them by applying a few
    rules that allow you to calculate the optimal match between the two sequences.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8f4a399e240ef0c0057a0c7c9f258984.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
- en: Two repetitions of a walking sequence and although they have varying speeds
    we can observe that the tracings of the limbs are quite similar; taken from [Wikipedia](https://en.wikipedia.org/wiki/Motion_capture#cite_note-2)
    referencing [(Olsen et al, 2017)](https://arxiv.org/pdf/1606.03295.pdf).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: 'I found a nice introduction to this topic in this article:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[](/dynamic-time-warping-3933f25fcdd?source=post_page-----94a0b44f57ab--------------------------------)
    [## Dynamic Time Warping'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Explanation and Code Implementation
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/dynamic-time-warping-3933f25fcdd?source=post_page-----94a0b44f57ab--------------------------------)
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: by [Jeremy Zhang](https://medium.com/u/f37783fc8c26?source=post_page-----94a0b44f57ab--------------------------------).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: 'To use dynamic time warping I did the following:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. Normalized the values to have them in the same range**'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. Used a Python implementation of a DTW algorithm.**'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The outputs I get here are:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '1\. `distance`: the [euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance)
    between the two temporal sequence vectors.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '2\. `path`: a mapping between the indexes of the two temporal sequences as
    a nested list of tuples'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, I can use the output stored in the `path` variable to create a plot with
    both sequences aligned:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/ec936f43ab212df6ecdf9d00d1bc37cc.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
- en: Image by the author, t*he temporal sequences aligned using the DTW algorithm*
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Now, given the lack of data mainly for the reference trace, I can’t say that
    this plot gave me a lot more insight than the elements already discussed before,
    however, it does help to highlight what I said before regarding the shape of the
    movement.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: However, as a note for the future, my idea here was that, if certain conditions
    could be met to help with making both videos more uniform, I would like to have
    a reference tracing from which I compare the tracings of my attempts in order
    to use it for immediate feedback.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: I would use the euclidean distance output from the DTW algorithm as my feedback
    metric and have an app that could highlight when I am getting closer or farther
    than the signature shape I would be trying to emulate.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate that, let me show you an example.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/9ba0a80609319ba5db156176de7c1d74.png)![](../Images/ed18abd8bd2187d7af45c7b5d6d8c2a2.png)![](../Images/d44210549874e5d8f23b22462333a1f0.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
- en: Images by the author. Traces of the movement of the feet executed by me.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: 'Here I am showing clips from the video where I execute each individual movement.
    Each of these traces can be compared to a reference trace obtained similarly:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/3d38c0f8ebb757594275cc4a0186ed34.png)![](../Images/f624096f5a7680b701e181afdddf7a9e.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
- en: Images by the author. Traces of the movement of the feet executed by the elite
    player.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: 'When I obtain the reference tracings I get some noise signals as well, but
    I will use the third one as my reference:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/13d3d9da00dd635fe394a4c5ea167396.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: Now I can loop over the tracings representing my actual movement and see how
    they compare to this reference trace across a couple of training sessions.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/a5d15027ebfe5983f40d292919616182.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
- en: Image by the author. Tracings of the x, y coordinates of the feet over a few
    executions of the movement.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Now I get the normalized values from both tracings.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: I get the tracings from the training clip as well as the reference traces to
    help me set a goal.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: The clip size is set manually.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: I show an example of the tracings obtained after having removed a few which
    I manually classified as noise upon empirical observation.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](../Images/1d5ff8574debff8886f822b9830b31ff.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: 'Then I loop over the tracings and plot their score in comparison to a reference
    trace I choose from the ones obtained from the video with the elite player:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](../Images/a127c80bc1cbe27b9ac14c36560a0c92.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: Now, the first weird thing I noticed here is the up and down of the metric,
    which can only be explained by the fact that some of the tracings obtained referred
    to the foot coming down rather than up while executing the movement.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: However, the cool thing about this plot is that the scores for the tracing even
    seemed to improve a bit and at least stay consistent at 20 (which in this case
    is the measure of the Euclidean distance between the two sequences).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: Despite not being to interpret these numbers conclusively at this point, I found
    quite insightful that an approach like this could be converted into a measurable
    metric that compares the quality of a movement with respect to another.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: Final Note
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the future, I would like to look into how to better extract the training
    clips to obtain perfectly aligned segments of each execution of a movement in
    order to produce more consistent results.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 未来，我希望研究如何更好地提取训练片段，以获得每次动作执行的完美对齐段，以便产生更一致的结果。
- en: Overall, I think doing these experiments was quite interesting because it pointed
    to the power of this technique to give a granular assessment of movement, despite
    the fact that it would still need a lot of work in order to become a useful tool
    for insight.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我认为做这些实验相当有趣，因为它突出了这种技术在提供动作的详细评估方面的力量，尽管它仍需大量工作才能成为一个有用的洞察工具。
- en: If you liked this post, [join Medium](https://lucas-soares.medium.com/membership),
    and subscribe to my [Youtube channel](https://www.youtube.com/channel/UCu8WF59Scx9f3H1N_FgZUwQ)
    and [my newsletter](https://lucas-soares.medium.com/subscribe). Thanks and see
    you next time! :)
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这篇文章， [加入 Medium](https://lucas-soares.medium.com/membership)，并订阅我的 [Youtube
    频道](https://www.youtube.com/channel/UCu8WF59Scx9f3H1N_FgZUwQ) 和 [我的新闻通讯](https://lucas-soares.medium.com/subscribe)。谢谢，下次见！
    :)
- en: References
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Benefits of Jiu Jitsu](https://era.library.ualberta.ca/items/205b4732-a385-427c-b12e-45f25d9e5150?utm_source=Victor+Mignone&utm_medium=Pingback&utm_campaign=weeklyboost&utm_term=002)'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[巴西柔术的好处](https://era.library.ualberta.ca/items/205b4732-a385-427c-b12e-45f25d9e5150?utm_source=Victor+Mignone&utm_medium=Pingback&utm_campaign=weeklyboost&utm_term=002)'
