- en: The 6 Benefits of Interpretable Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-6-benefits-of-interpretable-machine-learning-e32fb8b60e9](https://towardsdatascience.com/the-6-benefits-of-interpretable-machine-learning-e32fb8b60e9)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How understanding your model can lead to trust, knowledge and better performance
    in production
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://conorosullyds.medium.com/?source=post_page-----e32fb8b60e9--------------------------------)[![Conor
    O''Sullivan](../Images/2dc50a24edb12e843651d01ed48a3c3f.png)](https://conorosullyds.medium.com/?source=post_page-----e32fb8b60e9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e32fb8b60e9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e32fb8b60e9--------------------------------)
    [Conor O''Sullivan](https://conorosullyds.medium.com/?source=post_page-----e32fb8b60e9--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e32fb8b60e9--------------------------------)
    ·9 min read·Jan 30, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/283acb44320ff7d7c7b10fa2de9113ee.png)'
  prefs: []
  type: TYPE_IMG
- en: '(source: [DALL.E 2](https://labs.openai.com/))'
  prefs: []
  type: TYPE_NORMAL
- en: We seem to be in the golden era of AI. Every week there is a new service that
    can do anything from creating short stories to original images. These innovations
    are powered by machine learning. We use powerful computers and vast amounts of
    data to train these models. The problem is, this process leaves us with a poor
    understanding of how they actually work.
  prefs: []
  type: TYPE_NORMAL
- en: Ever increasing abilities? No idea how they work? Sounds like we want a robot
    uprising! Don’t worry, there is a parallel effort being made to get under the
    hood of these beasts. This comes from the field of interpretable machine learning
    (IML). This research is being driven by the many benefits a better understanding
    of our models can bring.
  prefs: []
  type: TYPE_NORMAL
- en: No, IML won’t stop an AI apocalypse. It can, however, help **increase trust**
    in machine learning and lead to **greater adoption** in other fields. You can
    also **gain knowledge** of your dataset and **tell better stories** about your
    results. You can even improve **accuracy** and **performance** in production.
    We will discuss these 6 benefits in depth. To end, we will touch on the limitations
    of IML.
  prefs: []
  type: TYPE_NORMAL
- en: You may also enjoy this video on the topic. And, if you want to learn more,
    check out my course — [XAI with Python](https://adataodyssey.com/courses/xai-with-python/).
    You can get **free** access if you sign up to my [newsletter](https://mailchi.mp/aa82a5ce1dc0/signup).
  prefs: []
  type: TYPE_NORMAL
- en: What is IML?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[In a previous article](/what-is-interpretable-machine-learning-2d217b62185a),
    we discuss IML in depth. To summarise, it is the field of research aimed at building
    machine learning models that can be understood by humans. This also involves developing
    tools that can help us understand complex models. The two main approaches to doing
    this are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Intrinsically interpretable models** — modelling methodologies to build models
    that are easy to interpret'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model agnostic methods** — applied to any black-box models after they have
    been trained'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The exact benefits will depend on which approach you take. We will focus on
    the latter. [Model agnostic methods](/what-are-model-agnostic-methods-387b0e8441ef#:~:text=Model%20agnostic%20evaluation%20methods%20provide,want%20to%20compare%20model%20performance.)
    can be applied to any model after it has been trained. This gives us flexibility
    in our model choice. That is we can use complicated models while still gaining
    insight into how they work.
  prefs: []
  type: TYPE_NORMAL
- en: The benefits of IML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The obvious benefit is the aim of IML — an understanding of a model. That is
    how it makes individual predictions or its general behaviour over a group of predictions.
    From this, flows many other benefits.
  prefs: []
  type: TYPE_NORMAL
- en: Increased accuracy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first is that IML can improve the accuracy of machine learning. Without
    model-agnostic methods, we were faced with a trade-off:'
  prefs: []
  type: TYPE_NORMAL
- en: Option 1 — use an accurate black-box model that we do not understand.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Option 2 — build a less accurate model that is intrinsically interpretable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we can model our cake and predict it too. By applying methods like [SHAP](https://medium.com/towards-data-science/introduction-to-shap-with-python-d27edc23c454),
    [LIME](https://medium.com/towards-data-science/squeezing-more-out-of-lime-with-python-28f46f74ca8e)
    or [PDPs](/the-ultimate-guide-to-pdps-and-ice-plots-4182885662aa) after the model
    is trained, we can interpret our black box models. We no longer have to exchange
    accuracy for interpretability. In other words, through increased flexibility in
    model choice, IML can improve accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: More directly, model-agnostic methods can also improve the accuracy of black
    box models. By understanding how a model makes predictions, we can also understand
    why it is making *incorrect* predictions. Using this knowledge, we can improve
    our data collection process or build better features.
  prefs: []
  type: TYPE_NORMAL
- en: Improve performance in production
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can take this idea one step further. That is accuracy on a training dataset
    is not the same as on new data in production. Bias and proxy variables can lead
    to unforeseen issues. IML methods can help us identify these issues. In other
    words, they can be used to debug and build more robust models.
  prefs: []
  type: TYPE_NORMAL
- en: An example comes from a model used to power an automated car. It makes predictions
    to turn left or right based on images of a track. It performed well on both the
    training and a validation set. Yet, when we moved to a new room the automated
    car went horribly wrong. The SHAP plots in **Figure 1** can help us understand
    why. Notice that the pixels in the background have high SHAP values.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/996afc6e687106197c27ae1f796ff6d3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: example shap values on a left and right turn (source: author)'
  prefs: []
  type: TYPE_NORMAL
- en: What this means is that the model is using background information to make predictions.
    It was trained on data from only one room and the same objects and background
    are present in all the images. As a result, the model associates these with left
    and right turns. When we moved to a new location, the background changed and our
    predictions became unreliable.
  prefs: []
  type: TYPE_NORMAL
- en: The solution is to collect more data. We can continue to use SHAP to understand
    if this has led to a more robust model. In fact, we do this in the article below.
    Check it out if you want to learn more about this application. Otherwise, if you
    want the basics, you can do my [Python SHAP course](https://adataodyssey.com/courses/shap-with-python/).
    Get free access if you sign up for my [Newsletter](https://mailchi.mp/aa82a5ce1dc0/signup).
  prefs: []
  type: TYPE_NORMAL
- en: '[](/using-shap-to-debug-a-pytorch-image-regression-model-4b562ddef30d?source=post_page-----e32fb8b60e9--------------------------------)
    [## Using SHAP to Debug a PyTorch Image Regression Model'
  prefs: []
  type: TYPE_NORMAL
- en: Using DeepShap to understand and improve the model powering an autonomous car
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/using-shap-to-debug-a-pytorch-image-regression-model-4b562ddef30d?source=post_page-----e32fb8b60e9--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Decrease harm and increase trust
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Debugging is not only about making predictions correctly. It also means ensuring
    they are made ethically. [Scott Lundberg](https://medium.com/u/3a739af9ef3a?source=post_page-----e32fb8b60e9--------------------------------)
    (the creator of SHAP), discusses an example in this [presentation](https://www.youtube.com/watch?v=ngOBhhINWb8&ab_channel=H2O.ai).
    A screenshot is shown in **Figure 2**. Using SHAP, he shows that the model is
    using **months of credit history** to predict default. This is a proxy for age
    — a protected variable.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/18288a9578c4a331d498f3b1d96abae7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: snapshot from a talk on SHAP (source: [H20.ai](https://www.youtube.com/watch?v=ngOBhhINWb8&ab_channel=H2O.ai)
    taken at 14:02)'
  prefs: []
  type: TYPE_NORMAL
- en: What this shows is that retired customers were more likely to be denied loads.
    This was because of their age and not true risk drivers (e.g. existing debt).
    In other words, the model was discriminating against customers based on age.
  prefs: []
  type: TYPE_NORMAL
- en: If we blindly trust black box models these types of problems will go unnoticed.
    IML can be used in your [analysis of fairness](/analysing-fairness-in-machine-learning-with-python-96a9ab0d0705)
    to ensure they will not be used to make decisions that will harm users. This can
    help build trust in our AI systems.
  prefs: []
  type: TYPE_NORMAL
- en: Another way IML can build trust is by providing the basis for [human-friendly
    explanations](/the-art-of-explaining-predictions-22e3584ed7d8). We can explain
    why you were denied a loan or why a product recommendation was made. Users will
    be more likely to accept these decisions if they are given a reason. The same
    goes for professionals making use of machine learning tools.
  prefs: []
  type: TYPE_NORMAL
- en: Extend the reach of ML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Machine learning is everywhere. It is improving or replacing processes in finance,
    law or even farming. An interesting application is to immediately assess the quality
    of grass used to feed dairy cows. A process that used to be both invasive and
    lengthy.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b7032d5bb66442667db8f2a2099de96f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: grass quality model architecture (source: [M. Saadeldin, et. al.](https://www.sciencedirect.com/science/article/pii/S2352938522000490?via%3Dihub=))'
  prefs: []
  type: TYPE_NORMAL
- en: You would not expect your average farmer to have an understanding of neural
    networks. The black-box nature would make it difficult for them to accept predictions.
    Even in more technical fields, there can be mistrust of deep learning methods.
  prefs: []
  type: TYPE_NORMAL
- en: Many scientists in hydrology remote sensing, atmospheric remote sensing, and
    ocean remote sensing etc. even do not believe the prediction results from deep
    learning, since these communities are more inclined to believe models with a clear
    physical meaning. *—* [*Prof. Dr. Lizhe Wang*](https://www.mdpi.com/journal/remotesensing/special_issues/XAI_big_data)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: IML can be seen as a bridge between computer science and other industries/ scientific
    fields. Providing a lens into the black box will make them more likely to accept
    results. This will increase the adoption of machine learning methods.
  prefs: []
  type: TYPE_NORMAL
- en: Improves your ability to tell stories
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The previous two benefits have been about building trust. The trust of customers
    and professionals. You may still need to build trust even in environments where
    ML is readily adopted. That is to convince your colleagues that a model will do
    its job.
  prefs: []
  type: TYPE_NORMAL
- en: Data scientists do this through data storytelling. That is relating results
    found in data to the experience of less technical colleagues. By providing a link
    between data exploration and modelling results, IML can help with this.
  prefs: []
  type: TYPE_NORMAL
- en: Take the scatter plot below. When an employee has a **degree** (degree = 1),
    their annual **bonus** tends to increase with their years of **experience.** However,
    when they do not have a degree their bonus is stable**.** In other words, there
    is an interaction between degree and experience.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9932c639384df9ffb143464382740041.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: scatterplot of experience.degree interaction (source: author)'
  prefs: []
  type: TYPE_NORMAL
- en: Now take the [ICE plot](/the-ultimate-guide-to-pdps-and-ice-plots-4182885662aa)
    below. It comes from a model used to predict bonuses using a set of features that
    includes experience and degree. We can see that the model captures the interaction.
    It is using the relationship we observed in the data to make predictions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9872379daf2d2b5857054626f97f748b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: ICE Plot of experience.degree interaction (source: author)'
  prefs: []
  type: TYPE_NORMAL
- en: With IML we go from saying, “We think the model is using this relationship we
    observed in data” to “Look! See!! The model is using this relationship.” We can
    also compare model results to our colleague's experience. This allows them to
    use their domain knowledge to validate trends captured by the model. Sometimes
    we can even learn something completely new.
  prefs: []
  type: TYPE_NORMAL
- en: Gain knowledge
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Black-box models can automatically model interactions and non-linear relationships
    in data. Using IML, we can analyze the model to reveal these relationships in
    our dataset. This knowledge can be used to:'
  prefs: []
  type: TYPE_NORMAL
- en: Inform **feature engineering** for non-linear models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Help when **making decisions** that go beyond models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ultimately, IML helps machine learning to become a tool for data exploration
    and knowledge generation. If nothing else, it can be fascinating to dive into
    a model to understand how it works.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations of IML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With all these benefits, IML still has its limitations. We need to consider
    these when coming to conclusions using the methods. The most important are the
    assumptions made. For example, both SHAP and [PDPs](/the-ultimate-guide-to-pdps-and-ice-plots-4182885662aa)
    assume there are no feature dependencies (i.e model features are uncorrelated).
    If this assumption is not true, the methods can be unreliable.
  prefs: []
  type: TYPE_NORMAL
- en: Another limitation is that the methods can be abused. It is up to us to interpret
    results and we can force stories onto the analysis. We can do this unconsciously
    as a result of confirmation bias. It can also be done maliciously to support a
    conclusion that will benefit someone. This is similar to p-hacking — we torcher
    the data until it gives us the results we want.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last thing to consider is that these methods only provide technical interpretations.
    They are useful for a data scientist to understand and debug a model. Yet, we
    cannot use them to explain a model to a lay customer or colleague. To do that
    requires a new set of skills and approach. One we discuss in this article:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/the-art-of-explaining-predictions-22e3584ed7d8?source=post_page-----e32fb8b60e9--------------------------------)
    [## The Art of Explaining Predictions'
  prefs: []
  type: TYPE_NORMAL
- en: How to explain your model in a human-friendly way
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/the-art-of-explaining-predictions-22e3584ed7d8?source=post_page-----e32fb8b60e9--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also find introductory articles for some of the IML methods mentioned
    in this article:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/the-ultimate-guide-to-pdps-and-ice-plots-4182885662aa?source=post_page-----e32fb8b60e9--------------------------------)
    [## The Ultimate Guide to PDPs and ICE Plots'
  prefs: []
  type: TYPE_NORMAL
- en: The intuition, maths and code (R and Python) behind partial dependence plots
    and individual conditional expectation…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/the-ultimate-guide-to-pdps-and-ice-plots-4182885662aa?source=post_page-----e32fb8b60e9--------------------------------)
    [](/introduction-to-shap-with-python-d27edc23c454?source=post_page-----e32fb8b60e9--------------------------------)
    [## Introduction to SHAP with Python
  prefs: []
  type: TYPE_NORMAL
- en: 'How to create and interpret SHAP plots: waterfall, force, decision, mean SHAP,
    and beeswarm'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/introduction-to-shap-with-python-d27edc23c454?source=post_page-----e32fb8b60e9--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: I hope you enjoyed this article! You can support me by becoming one of my [**referred
    members**](https://conorosullyds.medium.com/membership) **:)**
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://conorosullyds.medium.com/membership?source=post_page-----e32fb8b60e9--------------------------------)
    [## Join Medium with my referral link — Conor O’Sullivan'
  prefs: []
  type: TYPE_NORMAL
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every story…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: conorosullyds.medium.com](https://conorosullyds.medium.com/membership?source=post_page-----e32fb8b60e9--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '| [Twitter](https://twitter.com/conorosullyDS) | [YouTube](https://www.youtube.com/channel/UChsoWqJbEjBwrn00Zvghi4w)
    | [Newsletter](https://mailchi.mp/aa82a5ce1dc0/signup) — sign up for FREE access
    to a [Python SHAP course](https://adataodyssey.com/courses/shap-with-python/)'
  prefs: []
  type: TYPE_NORMAL
