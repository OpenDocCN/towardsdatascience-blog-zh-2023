- en: How to Rewrite and Optimize Your SQL Queries to Pandas in 5 Simple Examples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-rewrite-and-optimize-your-sql-queries-to-pandas-in-5-simple-examples-6983cae8426e](https://towardsdatascience.com/how-to-rewrite-and-optimize-your-sql-queries-to-pandas-in-5-simple-examples-6983cae8426e)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: PROGRAMMING
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Transitioning from SQL to Pandas to improve your data analysis workflow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://byrondolon.medium.com/?source=post_page-----6983cae8426e--------------------------------)[![Byron
    Dolon](../Images/9ff32138c7b1913be24cc7ab971752b0.png)](https://byrondolon.medium.com/?source=post_page-----6983cae8426e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6983cae8426e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6983cae8426e--------------------------------)
    [Byron Dolon](https://byrondolon.medium.com/?source=post_page-----6983cae8426e--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6983cae8426e--------------------------------)
    ·9 min read·Jun 1, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/802af72a42f8761f0a4ee55bcb3d5954.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Data analysts, engineers, and scientists alike are familiar with SQL. The querying
    language is still widely used across the board for working with relational databases
    of any kind.
  prefs: []
  type: TYPE_NORMAL
- en: However, more and more nowadays, especially for data analysts the technical
    requirements are going up and people are expected to at least know the basics
    of a programming language. When working with data, Python and Pandas specifically
    are a common addition to the list of requirements in a job description.
  prefs: []
  type: TYPE_NORMAL
- en: While Pandas may be new to data people familiar with SQL, the concepts for selecting,
    filtering on, and aggregating data in SQL are easily transferable to Pandas. In
    this piece, let’s take a look at some common SQL queries and how you can write
    and optimize them in Pandas instead.
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to follow along in a notebook or IDE of your own. You can download
    the dataset from Kaggle [here](https://www.kaggle.com/datasets/deepanshuverma0154/sales-dataset-of-ecommerce-electronic-products?resource=download),
    available free for use under the CC0 1.0 Universal (CC0 1.0) Public Domain Dedication
    license.
  prefs: []
  type: TYPE_NORMAL
- en: Just import and run the following code and let’s get started!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Simple examples of SQL and their Pandas equivalents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Querying a whole table
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can dive right into it by looking at the classic SELECT ALL from a table.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the SQL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: And here’s the pandas
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b7ed16647269553597becebeb6b3a5a5.png)'
  prefs: []
  type: TYPE_IMG
- en: Pandas code output — Image by author
  prefs: []
  type: TYPE_NORMAL
- en: All you need to do is call the DataFrame in Pandas to return the whole table
    and all its columns.
  prefs: []
  type: TYPE_NORMAL
- en: You may also want to just look at a small subset of your table as a quick check
    before writing a more complicated query. In SQL, you’d use `LIMIT 10` or something
    similar to get only a select number of rows. In Pandas, similarly, you can call
    `df.head(10)` or `df.tails(10)` to get the first or last 10 rows of the table.
  prefs: []
  type: TYPE_NORMAL
- en: Querying a table without null values
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To add to our initial select query, in addition to just limiting the number
    of rows, you would put conditions to filter the table inside a WHERE clause in
    SQL. For example, if you’d want all rows in the table without any null values
    in the `Order_ID` column, the SQL would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In Pandas, you have two options:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/8e24f10217698d40c468436f73d038a3.png)'
  prefs: []
  type: TYPE_IMG
- en: Pandas code output — Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Now, the table we get back doesn’t have any null values from the `Order_ID`
    column (which you can compare to the first output above). Both options will return
    a table without the null values, but they work slightly differently.
  prefs: []
  type: TYPE_NORMAL
- en: You can use the native `dropna` method in Pandas to return the DataFrame without
    any null rows, specifying in the `subset` parameter which columns you’d like to
    drop nulls from.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, the `loc` method lets you pass a mask or boolean label you can
    specify to filter the DataFrame. Here, we pass `df["Order_ID"].notna()`, which
    if you would call it on its own would return a Series of True and False values
    that can map to the original DataFrame rows for whether the `Order_ID` is null.
    When we pass it to the `loc` method, it instead returns the DataFrame where `df["Order_ID"].notna()`
    evaluates to True (so all rows where the `Order_ID` column isn’t null.
  prefs: []
  type: TYPE_NORMAL
- en: Querying specific columns from a table
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, instead of selecting all columns from the table, let’s instead select
    just a few specific columns. In SQL, you’d write the column names in the SELECT
    part of the query like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'In Pandas, we’d write the code like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/102a928216a9a5b874dda7b8030104cc.png)'
  prefs: []
  type: TYPE_IMG
- en: Pandas code output — Image by author
  prefs: []
  type: TYPE_NORMAL
- en: 'To select a specific subset of columns, you can pass a list of the column names
    into the DataFrame in Pandas. You can also define the list separately like this
    for clarity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Assigning a list of target columns that you can then pass into a DataFrame can
    make working with a table over time when you need to make changes in your code
    a little easier. For example, you could have a function return the columns you
    need as a list, or append and remove columns to the list as needed depending on
    what kind of output the user needs.
  prefs: []
  type: TYPE_NORMAL
- en: The GROUP BY in SQL and Pandas
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can now move on to aggregating data. In SQL, we do this by passing a column
    to the SELECT and GROUP BY clauses that we want to group on and then adding the
    column to an aggregate measure like COUNT in the SELECT clause as well. As an
    example, doing so will let us group all the individual `Order_ID` rows in the
    original table for each `Product` and count how many there are. The query can
    look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In Pandas, it would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/241f0b75bb7b93365d2e4f48e1e62239.png)'
  prefs: []
  type: TYPE_IMG
- en: Pandas code output — Image by author
  prefs: []
  type: TYPE_NORMAL
- en: 'The output is a Pandas Series where the table is grouped the products and there’s
    a count of all the `Order_ID` for each product. In addition to our previous query
    in Pandas where we included a filter, we now do three things:'
  prefs: []
  type: TYPE_NORMAL
- en: Add `groupby` and pass a column (or list of columns) that you want to group
    the DataFrame on;
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pass the name of the column in square brackets on the raw grouped DataFrame;
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Call the `count` (or any other aggregate) method to perform the aggregation
    on the DataFrame for the target column.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For better readability, we can assign the condition to a variable (this will
    come in handy later) and format the query so it’s easier to read.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: A complete SQL query translated and efficiently written in Pandas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have most of the components of a complete SQL query, let’s take
    a look at a more complicated one and see what it would look like in Pandas.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Here, we add a little to our previous query by including multiple filter conditions
    as well as an ORDER BY so that the table returned in our query is sorted by the
    measure we’re aggregating on. Since there are a few more components to this query,
    let’s take a look step by step at how we’d implement this in Pandas.
  prefs: []
  type: TYPE_NORMAL
- en: First, instead of passing multiple conditions when we call the `loc` method,
    let’s instead define a list of conditions and assign them to a variable `FILTER_CONDITIONS`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'As before, a condition passed into `loc` should be a Pandas mask that evaluates
    to either true or false. It’s possible to pass multiple conditions to `loc`, but
    the syntax should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'However, just passing a list of conditions like this won’t work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: You’ll get an error if you try the above because each condition should be separated
    by the `&` operator for “and” conditions (or the `|` operator if you need “or”
    conditions). Instead, we can write some quick code to return the conditions in
    the correct format. We’ll make use of the `functools.reduce` method to put the
    conditions together.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to see what it looks like in a notebook and see what it looks like
    to combine some strings using the `reduce` function, try this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This outputs the string like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Going back to our actual Pandas conditions, we can write this instead (without
    the string formatting and just using our defined list of conditions in the `FILTER_CONDITIONS`
    variable).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'What `reduce` does is apply a function cumulatively to the elements present
    in an iterable, or in our case run the `lambda` function over the items in our
    `FILTER_CONDITIONS` list which combines each of them with the `&` operator. This
    runs until there are no conditions left, or in this case, for all three conditions
    it would effectively return:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let’s add the list of conditions to create a final group by query
    in Pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'You’ll notice two additional differences from the previous query:'
  prefs: []
  type: TYPE_NORMAL
- en: Instead of specifying the specific column to count on, we can simply call the
    `size` method which will return the number of rows in the DataFrame (as before
    where every `Order_ID` value was unique and meant to represent one row when we
    counted on it);
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There are a few different ways to do the ORDER BY in Pandas- one way is to simply
    call `sort_values` and pass `ascending=False` to sort on descending order.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you wanted to use the previous syntax for aggregating the data it would
    look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/60a5fc51f777d90503c1a3fcde57f3a7.png)'
  prefs: []
  type: TYPE_IMG
- en: Pandas code output — Image by author
  prefs: []
  type: TYPE_NORMAL
- en: The output of both methods will be the same as before, which is a Series with
    the column you’re grouping on and the counts for each product.
  prefs: []
  type: TYPE_NORMAL
- en: If instead, you wanted to output a DataFrame, you can call the `reset_index`
    method on the series to get the original column names back for which column you
    grouped on and the column you’re aggregating on (in this case we grouped on “Product”
    and are counting the “Order_ID”.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/2424825fd9300c03675c23d2ab7faad7.png)'
  prefs: []
  type: TYPE_IMG
- en: Pandas code output — Image by author
  prefs: []
  type: TYPE_NORMAL
- en: 'And there we have it! All the components of a full SQL query but finally written
    in Pandas. Some of the things we can do further to optimize this process for working
    with data over time include:'
  prefs: []
  type: TYPE_NORMAL
- en: Putting the different lists of columns to SELECT or GROUP BY to their own variables
    or functions (so you or a user can modify them over time);
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Move the logic to combine the list of columns for a filter condition to its
    own function so the end user doesn’t need to be confused over what the `reduce`
    logic is doing;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After passing `reset_index` we can rename the output column (or columns if we’re
    aggregating on multiple) for clarity, for example to “Count_Order_ID”.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thanks for taking the time to read this piece! If you haven’t already, hit the
    follow button to stay up to date with more tech pieces by me. Also, if you enjoy
    my content I’d love it if you **sign up for Medium using my referral link below.**
    This’ll let me get a portion of your monthly subscription AND you’ll get access
    to some exclusive features only available to Medium members.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://byrondolon.medium.com/membership?source=post_page-----6983cae8426e--------------------------------)
    [## Join Medium with my referral link — Byron Dolon'
  prefs: []
  type: TYPE_NORMAL
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every story…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: byrondolon.medium.com](https://byrondolon.medium.com/membership?source=post_page-----6983cae8426e--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: M**ore by me:** *-* [*5 Practical Tips for Aspiring Data Analysts*](https://byrondolon.medium.com/5-practical-tips-for-aspiring-data-analysts-9917006d4dae?sk=019edbddaca4d313665caafe4b747d26)
    *-* [*Mastering Ecommerce Data Analysis*](https://python.plainenglish.io/mastering-analysis-for-e-commerce-with-pandas-e4219a87b10c?sk=9aa8fd1024b89e89e4b0904c8d00d242)
    *-* [*Check for a Substring in a Pandas DataFrame*](/check-for-a-substring-in-a-pandas-dataframe-column-4b949f64852?sk=bfb5bbab11ae45c47bfb316d931c3b56)
    *-* [*7 Best Repositories on Github to Learn Python*](https://medium.com/towards-data-science/top-7-repositories-on-github-to-learn-python-44a3a7accb44)
    *-* [*5 (and a half) Lines of Code for Understanding Your Data with Pandas*](/5-and-a-half-lines-of-code-for-understanding-your-data-with-pandas-aedd3bec4c89?sk=7007a1ae248cf7ea4ef5fcd4af7ae72b)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
