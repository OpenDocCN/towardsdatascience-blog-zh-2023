- en: Imitation Models and the Open-Source LLM Revolution
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模仿模型与开源 LLM 革命
- en: 原文：[https://towardsdatascience.com/imitation-models-and-the-open-source-llm-revolution-431ce48d4bae](https://towardsdatascience.com/imitation-models-and-the-open-source-llm-revolution-431ce48d4bae)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/imitation-models-and-the-open-source-llm-revolution-431ce48d4bae](https://towardsdatascience.com/imitation-models-and-the-open-source-llm-revolution-431ce48d4bae)
- en: Are proprietary LLMs like ChatGPT and GPT-4 actually easy to replicate?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 像 ChatGPT 和 GPT-4 这样的专有 LLM 是否真的容易复制？
- en: '[](https://wolfecameron.medium.com/?source=post_page-----431ce48d4bae--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----431ce48d4bae--------------------------------)[](https://towardsdatascience.com/?source=post_page-----431ce48d4bae--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----431ce48d4bae--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----431ce48d4bae--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://wolfecameron.medium.com/?source=post_page-----431ce48d4bae--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----431ce48d4bae--------------------------------)[](https://towardsdatascience.com/?source=post_page-----431ce48d4bae--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----431ce48d4bae--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----431ce48d4bae--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----431ce48d4bae--------------------------------)
    ·15 min read·Sep 27, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----431ce48d4bae--------------------------------)
    ·阅读时间15分钟·2023年9月27日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/f8709e8cc037ca4e582e6581004111d2.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f8709e8cc037ca4e582e6581004111d2.png)'
- en: (Photo by [Tanbir Mahmud](https://unsplash.com/@photo_tanbir?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/oyJKjAzAcbU?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText))
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: （图片由 [Tanbir Mahmud](https://unsplash.com/@photo_tanbir?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，来源于 [Unsplash](https://unsplash.com/photos/oyJKjAzAcbU?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)）
- en: The proposal of the LLaMA suite [2] of large language models (LLMs) led to a
    surge in publications on the topic of open-source LLMs. In many cases, the goal
    of these works was to cheaply produce smaller, opens-source LLMs (for research
    purposes) that have comparable quality to proprietary models like [ChatGPT](https://openai.com/blog/chatgpt)
    and [GPT-4](https://openai.com/research/gpt-4). These models adopt an imitation
    strategy, which fine-tunes a base LLM over synthetic dialogue data from a more
    powerful LLM. Despite being cheap to train, these models seemed to perform comparably
    to proprietary LLMs like ChatGPT. As a result, the deep learning research community
    quickly adopted the view that open-source LLMs will rule the future — *re-producing
    open-source variants of proprietary models was both easy and cost-effective*!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: LLaMA 套件 [2] 的大型语言模型（LLMs）的提出引发了关于开源 LLM 的大量出版物。在许多情况下，这些工作的目标是便宜地生产出较小的开源 LLM（用于研究目的），其质量与像
    [ChatGPT](https://openai.com/blog/chatgpt) 和 [GPT-4](https://openai.com/research/gpt-4)
    这样的专有模型相当。这些模型采用了模仿策略，通过更强大的 LLM 上的合成对话数据来微调基础 LLM。尽管训练成本低，这些模型的表现似乎与专有 LLM（如
    ChatGPT）相当。因此，深度学习研究社区迅速采纳了开源 LLM 将主导未来的观点 —— *再现专有模型的开源变体既容易又具成本效益*！
- en: “Will the most powerful LLMs be closed-source or will they be freely distributed
    for anyone to use, modify, and extend?” *— from [1]*
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “最强大的 LLM 会是闭源的，还是会自由分发供任何人使用、修改和扩展？” *— 来源于 [1]*
- en: Unfortunately, preliminary evaluations performed on these models, which relied
    upon ratings provided by other LLMs (e.g., GPT-4) or human crowd workers, were
    somewhat cursory. *Does the performance of imitation models actually match that
    of models like ChatGPT?* To answer this question more rigorously, we will study
    recent research that analyzes whether imitation models truly remove the “moat”
    around proprietary LLMs. Interestingly, we will see that these cheap reproductions
    of powerful LLMs perform well in human evaluations due to their ability to learn
    the style of a powerful LLM. However, they lack factuality and perform poorly
    when subjected to more broad and targeted evaluations. In reality, *imitation
    models do not perform nearly as well as proprietary models like ChatGPT.*
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，对这些模型的初步评估依赖于其他LLM（例如GPT-4）或人工众包工人的评分，这些评估有些粗略。*模仿模型的表现是否真的能与ChatGPT等模型相匹配？*
    为了更严谨地回答这个问题，我们将研究最近的研究，分析模仿模型是否真正去除了专有LLM的“护城河”。有趣的是，我们将看到这些便宜的强大LLM的复制品在人类评估中表现良好，因为它们能够学习强大LLM的风格。然而，它们缺乏事实性，在更广泛和有针对性的评估中表现较差。实际上，*模仿模型的表现远不如ChatGPT这样的专有模型。*
- en: '![](../Images/b5b0956860f66317e22e0409f7014b3a.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b5b0956860f66317e22e0409f7014b3a.png)'
- en: (from [1])
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: （来自[1]）
- en: Model Imitation
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型模仿
- en: “The premise of model imitation is that once a proprietary LM is made available
    via API, one can collect a dataset of API outputs and use it to fine-tune an open-source
    LM.” *— from [1]*
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “模型模仿的前提是，一旦通过API提供了专有LM，就可以收集API输出的数据集，并用它来微调一个开源LM。” *— 来源于[1]*
- en: 'The majority of models that we will see in this overview are trained via a
    model imitation strategy. This strategy, which is based upon the more generic
    idea of knowledge distillation, is a seemingly effective way to fine-tune less
    powerful LLMs to make them behave more similarly to powerful LLMs like ChatGPT
    and GPT-4\. To do this, we just:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本概述中，我们将看到的大多数模型都是通过模型模仿策略进行训练的。这种策略基于更通用的知识蒸馏思想，是一种看似有效的方法，可以微调较不强大的LLM，使其表现得更类似于强大的LLM，如ChatGPT和GPT-4。为此，我们只需：
- en: Collect dialogue examples from the more powerful model (e.g., using the OpenAI
    API).
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从更强大的模型中收集对话示例（例如，使用OpenAI API）。
- en: Use them to fine-tune the smaller model using a normal language modeling objective.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用它们以正常的语言建模目标微调较小的模型。
- en: This approach (although not [commercially viable](https://openai.com/policies/terms-of-use))
    was heavily utilized by a variety of open-source LLMs — including Alpaca, Vicuna,
    Koala, and more [3, 4, 5] — to create language models much closer to the quality
    or ChatGPT or GPT-4.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这种方法（尽管在[商业上不可行](https://openai.com/policies/terms-of-use)）被各种开源LLM广泛使用——包括Alpaca、Vicuna、Koala等[3,
    4, 5]——以创建与ChatGPT或GPT-4的质量更接近的语言模型。
- en: '![](../Images/56a25db6eaa8a5e49cddf36a7e26887f.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/56a25db6eaa8a5e49cddf36a7e26887f.png)'
- en: (from [7])
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: （来自[7]）
- en: '**Knowledge distillation.** The idea of knowledge distillation for deep neural
    networks was originally explored in [1]. To put it simply, knowledge distillation
    uses a (large) fully-trained neural network as a training signal for another (small)
    neural network; see above. If we train a neural network using both *i)* the normal
    training data and *ii)* the output of a larger, more powerful neural network over
    that data, then we will typically arrive at a better result than training a neural
    network over the data alone. By using its output as a training target, we can
    distill some of the information from a larger “teacher” network into a smaller
    “student” network that is being trained. For more details, check out the link
    [here](/knowledge-distillation-simplified-dd4973dbc764).'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**知识蒸馏。** 深度神经网络的知识蒸馏思想最初在[1]中被探索。简单来说，知识蒸馏使用（大型）完全训练的神经网络作为另一个（小型）神经网络的训练信号；见上文。如果我们同时使用*i)*
    正常训练数据和*ii)* 大型、强大神经网络对该数据的输出来训练神经网络，那么通常会比仅用数据训练神经网络获得更好的结果。通过使用其输出作为训练目标，我们可以将一些信息从较大的“教师”网络提炼到正在训练的较小的“学生”网络中。有关更多详细信息，请查看链接[这里](/knowledge-distillation-simplified-dd4973dbc764)。'
- en: Although many types of knowledge distillation exist, the variant considered
    in this overview is referred to as model imitation, where we use the output of
    a teacher LLM as a training target for supervised fine-tuning of another LLM.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在多种类型的知识蒸馏，但本概述中考虑的变体称为模型模仿，其中我们使用教师LLM的输出作为另一个LLM的监督微调的训练目标。
- en: '**Types of model imitation.** There are a variety of high-quality LLMs available
    online, but many of them are only accessible via a [black-box API](https://openai.com/blog/openai-api).
    Instead of having access to the model itself, we can only provide input to the
    model and receive output (possibly with associated [log probabilities](https://chrispiech.github.io/probabilityForComputerScientists/en/part1/log_probabilities/)).
    Model imitation collects data from these APIs and uses it for fine-tuning, allowing
    any model to imitate the output of a proprietary LLM. There are two basic types
    of imitation:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型模仿的类型**。虽然在线上有各种高质量的LLM可用，但其中许多只能通过[黑箱API](https://openai.com/blog/openai-api)访问。我们不能直接访问模型本身，只能向模型提供输入并接收输出（可能还附带有[对数概率](https://chrispiech.github.io/probabilityForComputerScientists/en/part1/log_probabilities/)）。模型模仿从这些API中收集数据，并用于微调，使任何模型都能模仿专有LLM的输出。模仿有两种基本类型：'
- en: '*Local Imitation*: learn to imitate a model’s behavior on a specific task,
    instead of imitating its behavior as a whole.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*局部模仿*：学习在特定任务上模仿模型的行为，而不是整体模仿其行为。'
- en: '*Broad Imitation*: learn to imitate a model’s behavior broadly, across a variety
    of different topics.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*广泛模仿*：学习在各种不同话题中广泛地模仿模型的行为。'
- en: Broad imitation is (generally) more difficult than local imitation, as it aims
    to comprehensively capture a model’s behavior. Although imitating a specific task
    is not hard, replicating a model’s behavior as a whole requires a lot of data
    and can be quite difficult.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 广泛模仿（通常）比局部模仿更难，因为它旨在全面捕捉模型的行为。虽然模仿特定任务不难，但全面复制模型的行为需要大量数据，并且可能相当困难。
- en: “Broad-coverage imitation is challenging because (1) one must collect an extremely
    diverse imitation dataset and (2) imitation models must capture this wide data
    distribution and generalize similarly to the target model on a myriad of held-out
    examples.” *— from [1]*
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “广泛覆盖的模仿是具有挑战性的，因为（1）必须收集一个极其多样化的模仿数据集，以及（2）模仿模型必须捕捉到这种广泛的数据分布，并在大量的保留样本上类似于目标模型进行泛化。”
    *— 引自[1]*
- en: The Wake of LLaMA
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLaMA的影响
- en: 'Model imitation was explored extensively by recent research on open-source
    LLMs. This line of work began with the proposal of [LLaMA](https://cameronrwolfe.substack.com/i/113386783/the-llama-suite)
    [2] and was quickly extended by follow-up models like Alpaca, Vicuna, Koala, and
    more [3, 4, 5]. We learned about most of these models within prior overviews:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 近期对开源LLM的研究广泛探讨了模型模仿。这一研究方向始于[LLaMA](https://cameronrwolfe.substack.com/i/113386783/the-llama-suite)
    [2] 的提出，并迅速扩展到后续模型，如Alpaca、Vicuna、Koala等[3, 4, 5]。我们在之前的综述中了解了大多数这些模型：
- en: 'LLaMA: LLMs for Everyone! [[link](/llama-llms-for-everyone-724e737835be)]'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLaMA：人人都能使用的LLM [[link](/llama-llms-for-everyone-724e737835be)]
- en: 'Beyond LLaMA: The Power of Open LLMs [[link](/beyond-llama-the-power-of-open-llms-cef807a54a4f)]'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超越LLaMA：开放LLM的力量 [[link](/beyond-llama-the-power-of-open-llms-cef807a54a4f)]
- en: Here, we will quickly cover the basics of these models and provide relevant
    context that will make this overview more understandable.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将快速介绍这些模型的基本知识，并提供相关背景，使本概述更易于理解。
- en: What is LLaMA?
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是LLaMA？
- en: '![](../Images/1a9b81e0b026709338996e8d2dc2e3b5.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1a9b81e0b026709338996e8d2dc2e3b5.png)'
- en: LLaMA catalyzed an explosion of open-source LLMs (from [3, 4, 5, 16] and DreamStudio)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: LLaMA催生了开源LLM的爆炸性增长（来源于[3, 4, 5, 16]和DreamStudio）
- en: LLaMA is not a single language model, but rather a suite of LLMs with sizes
    ranging from 7 billion to 65 billion parameters. Taking inspiration from Chinchilla
    [13], these LLMs are a bit smaller than their counterparts but are pre-trained
    extensively (i.e., [smaller models, more tokens](https://twitter.com/cwolferesearch/status/1603837192346165248?s=20)).
    LLaMA models perform surprisingly well; e.g., the 13 billion parameter model is
    comparable to GPT-3 [14], while the 65 billion parameter model surpasses the performance
    of PaLM [15].
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: LLaMA不是单一的语言模型，而是一套从70亿到650亿参数的LLM。受到Chinchilla [13] 的启发，这些LLM比其对手稍小，但经过了广泛的预训练（即，[更小的模型，更多的tokens](https://twitter.com/cwolferesearch/status/1603837192346165248?s=20)）。LLaMA模型表现惊人；例如，130亿参数的模型与GPT-3
    [14] 相当，而650亿参数的模型超越了PaLM [15] 的表现。
- en: '**Fully open-source.** Unlike closed-source models that are trained on a combination
    of public and proprietary data, LLaMA uses only publicly available data for pre-training
    — *LLaMA models can be reproduced completely from online resources*! After being
    publicly released for research purposes, the weights of the model were “leaked”
    online. Even still, LLaMA is prohibited from being used in any commercial applications
    even if one has access to the model’s weights.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**完全开源。** 与使用公共和专有数据的闭源模型不同，LLaMA 仅使用公开可用的数据进行预训练——*LLaMA 模型可以完全从在线资源中复制*！在公开发布用于研究目的后，该模型的权重被“泄露”到网上。即便如此，即使有人访问模型的权重，LLaMA
    仍然被禁止用于任何商业应用。'
- en: 'Imitation Models: Alpaca, Vicuna, Koala, and More'
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模仿模型：阿尔帕卡、维库纳、考拉以及更多
- en: '![](../Images/6212fdab42fbe79441d475b51ca9accb.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6212fdab42fbe79441d475b51ca9accb.png)'
- en: (from [3, 4, 5, 16])
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [3, 4, 5, 16]）
- en: Interestingly, LLaMA weights being leaked online led to a massive explosion
    in the model’s popularity. Researchers quickly began to release a variety of interesting,
    open-source derivatives. Primarily, LLaMA was used to create imitation models
    based on data derived from dialogues with powerful LLMs like ChatGPT. Let’s take
    a look at some of the popular LLMs derived from LLaMA.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，LLaMA 权重的泄露导致了该模型受欢迎程度的巨大爆炸。研究人员很快开始发布各种有趣的开源衍生模型。主要是，LLaMA 被用来创建基于与强大
    LLM 如 ChatGPT 对话数据的模仿模型。让我们来看看一些从 LLaMA 衍生出的流行 LLM。
- en: '**Alpaca [3]** is a fine-tuned version of the LLaMA-7B LLM. The fine-tuning
    process is based on self-instruct [17], in which instruction-following data is
    collected from a higher-performing LLM (i.e., `text-davinci-003`) and used for
    supervised fine-tuning. The entire fine-tuning process of Alpaca costs only $600
    (including both data collection and fine-tuning).'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**阿尔帕卡 [3]** 是 LLaMA-7B LLM 的一个微调版本。微调过程基于自我指导 [17]，其中从表现更高的 LLM（即 `text-davinci-003`）收集了遵循指令的数据，用于监督微调。阿尔帕卡的整个微调过程成本仅为
    $600（包括数据收集和微调）。'
- en: '**Vicuna [4]** is an open-source chatbot that is created by fine-tuning LLaMA-13B
    (i.e., comparable performance to GPT-3). Vicuna is fine-tuned using examples of
    user conversations with ChatGPT, and the entire fine-tuning process can be replicated
    for $300\. Compared to Alpaca, Vicuna is more comparable to ChatGPT and generates
    answers with detail and structure.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**维库纳 [4]** 是一个开源聊天机器人，通过对 LLaMA-13B 进行微调（即性能与 GPT-3 相当）创建的。维库纳使用了与 ChatGPT
    的用户对话示例进行微调，整个微调过程可以以 $300 的成本复制。与 Alpaca 相比，维库纳更接近于 ChatGPT，并生成详细且结构化的回答。'
- en: '**Koala [5]** is a version of LLaMA-13B that has been fine-tuned on dialogue
    data from a variety of sources, ranging from public datasets to dialogues with
    other high-quality LLMs that are available on the internet. Compared to Alpaca,
    Koala is fine-tuned over more dialogue data and evaluated more extensively (using
    a larger number of crown workers).'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**考拉 [5]** 是一种基于对话数据微调的 LLaMA-13B 版本，这些对话数据来自各种来源，包括公共数据集和与其他高质量 LLM 的对话，这些数据在互联网上可以获得。与
    Alpaca 相比，Koala 在更多对话数据上进行了微调，并且评估更为广泛（使用了更多的冠状工作者）。'
- en: '**GPT4ALL [16]** is a fine-tuned LLaMA-7B model that has been trained on over
    800K chat completions from `GPT-3.5-turbo`. Along with releasing the code and
    model, authors of GPT4ALL release the 4-bit quantized weights of the model, which
    can be used to run model inference on CPUs. As a result, we can use this model
    on a normal laptop!'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**GPT4ALL [16]** 是一个经过微调的 LLaMA-7B 模型，该模型在超过 80 万次来自 `GPT-3.5-turbo` 的聊天完成数据上进行了训练。除了发布代码和模型，GPT4ALL
    的作者还发布了模型的 4 位量化权重，可以用于在 CPU 上运行模型推理。因此，我们可以在普通笔记本电脑上使用这个模型！'
- en: “Open-source models are faster, more customizable, more private, and … more
    capable. They are doing things with $100 and 13B params that [Google] struggles
    with at $10M and 540B. And they are doing so in weeks, not months.” *— from [9]*
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “开源模型更快、更可定制、更隐私，并且……更强大。它们以 $100 和 13B 参数完成的任务， [Google] 则需要 $10M 和 540B 参数才能做到，而且还需要数周，而不是数月。”
    *— 来自 [9]*
- en: '**The massive potential of imitation models.** The models mentioned above were
    published in close succession and (in most cases) claimed to achieve results that
    were comparable to top proprietary models like ChatGPT or GPT-4\. As such, the
    research community quickly adopted the opinion that open-source model will soon
    dominate the LLM landscape. But, *is this actually the case?*'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**模仿模型的巨大潜力。** 上述模型在短时间内相继发布，并且（在大多数情况下）声称取得了与ChatGPT或GPT-4等顶级专有模型相当的结果。因此，研究界迅速采纳了开源模型将很快主导LLM领域的观点。但，*情况真的如此吗？*'
- en: Are we missing something?
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们是否遗漏了什么？
- en: Open-source, LLaMA-based imitation models seem to perform well, as they are
    much better at instruction following compared to the base LLM (i.e., the model
    that has been pre-trained but not fine-tuned) and have a comparable style to ChatGPT.
    In fact, crowd workers initially rate the outputs of a LLaMA-13B model that has
    been trained to imitate ChatGPT as better 70% of the time; see below.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLaMA的开源模仿模型似乎表现良好，因为它们在指令跟随方面远胜于基础LLM（即，已经预训练但未微调的模型），且风格与ChatGPT相当。事实上，众包工作者最初评估经过训练以模仿ChatGPT的LLaMA-13B模型的输出时，70%的时间认为其表现更好；见下文。
- en: '![](../Images/ea069be5025b2d45aa9ae06ab1f8a171.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ea069be5025b2d45aa9ae06ab1f8a171.png)'
- en: (from [1])
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: (来自 [1])
- en: With these results in mind, it seems like model imitation provides an easy way
    to distill the capabilities of any proprietary model into a smaller, open-source
    LLM. If this is the case, we can match the performance of the best proprietary
    models via an open-source LLM by just using fine-tuning and imitation data, leaving
    closed-source models like GPT-4 with [no true advantage](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些结果，模仿模型似乎提供了一种将任何专有模型的能力提炼到一个较小的开源LLM中的简单方法。如果确实如此，我们可以通过仅使用微调和模仿数据，匹配最佳专有模型的性能，使得像GPT-4这样的闭源模型[没有真正的优势](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither)。
- en: '**The (unfortunate) truth.** Although the ability to easily re-create open-source
    variants of proprietary models for research purposes is enticing, evaluation using
    crowd workers can be misleading. A model can score well simply by outputting answers
    with the correct style and structure, even if an answer is factually weak or incorrect.
    *Why is this the case?* Verifying factual correctness requires a larger time investment
    (or existing knowledge) from the crowd worker.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**（不幸的）真相。** 尽管轻松重新创建开源专有模型的变体用于研究目的是很有吸引力的，但使用众包工作者进行的评估可能具有误导性。一个模型仅通过输出具有正确风格和结构的答案就能得分高，即使答案在事实层面上较弱或不正确。*为什么会这样？*
    验证事实的正确性需要众包工作者投入更多时间（或现有知识）。'
- en: '![](../Images/a57483178f518b275afd2996c8993043.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a57483178f518b275afd2996c8993043.png)'
- en: (from [3, 4, 5])
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: (来自 [3, 4, 5])
- en: '**How are open-source LLMs evaluated?** With this in mind, we might start to
    question whether post-LLaMA LLMs are *actually* closing the gap between paid and
    open-source LLMs. These models are definitely exciting and impressive, but when
    we look at how they are evaluated, we typically see that the evaluation is:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**开源LLM是如何被评估的？** 有了这些考虑，我们可能会开始质疑，后LLaMA时代的LLM是否*真的*在缩小付费LLM与开源LLM之间的差距。这些模型确实令人兴奋和印象深刻，但当我们查看它们的评估方式时，通常会看到评估是：'
- en: Not very comprehensive
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不够全面
- en: Primarily based upon human (or LLM) evaluation
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 主要基于人类（或LLM）评估
- en: As such, it’s easy to be misled regarding the true quality of these models given
    the limitations of human evaluation. Put simply, *these models are not evaluated
    rigorously enough to gain an accurate picture of their quality*.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，考虑到人工评估的局限性，关于这些模型的真实质量容易被误导。简单来说，*这些模型的评估不够严格，因此无法准确反映其质量*。
- en: '[The False Promise of Imitating Proprietary LLMs](https://arxiv.org/abs/2305.15717)
    [1]'
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[模仿专有LLM的虚假承诺](https://arxiv.org/abs/2305.15717) [1]'
- en: '![](../Images/8221454b54ffc4d478d3dd48347239a6.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8221454b54ffc4d478d3dd48347239a6.png)'
- en: (from [1])
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: (来自 [1])
- en: 'Authors in [1] aim to comprehensively analyze the performance of model imitation,
    thus answering the question: *can we really imitate proprietary LLMs with weaker,
    open-source models?* A variety of models are fine-tuned over different sets of
    imitation data, then extensively evaluated using both crowd workers and a variety
    of different natural language benchmarks. Initially, LLMs produced via model imitation
    of ChatGPT seem to perform well, but targeted evaluations reveal that they do
    far less to close the gap between the base LLM (i.e., LLaMA [2]) and ChatGPT than
    it seems. These models are less factual and only improve performance on tasks
    that are heavily represented in the fine-tuning set. The model oftentimes *declines*
    in accuracy on tasks that aren’t seen during fine-tuning!'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]中的作者旨在全面分析模型模仿的性能，从而回答问题：*我们真的能用较弱的开源模型模仿专有LLM吗？* 各种模型在不同的模仿数据集上进行了微调，然后通过众包工作者和各种自然语言基准进行了广泛评估。最初，通过ChatGPT模型模仿生成的LLM似乎表现良好，但有针对性的评估表明，它们在缩小基础LLM（即LLaMA
    [2]）与ChatGPT之间的差距方面远不如预期。这些模型在事实性方面较差，仅在那些在微调集中大量出现的任务上有所改进。在微调期间未见过的任务上，这些模型往往在准确性上*下降*！'
- en: Experimental Setup
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验设置
- en: Analysis in [1] critically evaluates recent work on model imitation by exploring
    a variety of experimental setups. All models used are [decoder-only transformers](https://twitter.com/cwolferesearch/status/1640446111348555776?s=20),
    including GPT-2 [6], LLaMA-7B, and LLaMA-13B [2]. Evaluation is performed using
    [GPT-4](https://openai.com/research/gpt-4), crowd workers, and widely-used natural
    language benchmarks.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]中的分析通过探索多种实验设置，批判性地评估了近期关于模型模仿的研究。所有使用的模型都是[仅解码器变换器](https://twitter.com/cwolferesearch/status/1640446111348555776?s=20)，包括GPT-2
    [6]、LLaMA-7B和LLaMA-13B [2]。评估使用了[GPT-4](https://openai.com/research/gpt-4)、众包工作者和广泛使用的自然语言基准。'
- en: '![](../Images/03e0ff34132d3b0b21fea351973929ec.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03e0ff34132d3b0b21fea351973929ec.png)'
- en: (from [1])
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [1]）
- en: '**Building the dataset.** Fine-tuning datasets are created using a combination
    of human and LLM-provided examples for both local and broad imitation. For local
    imitation, a task-specific fine-tuning dataset is created by bootstrapping the
    [Natural Questions dataset](https://ai.google.com/research/NaturalQuestions) (i.e.,
    based on factual knowledge of Wikipedia). In particular, authors in [1] take a
    small set of QA pairs from Natural Questions, then prompt ChatGPT to curate 6,000
    more examples of similar questions; see above.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**构建数据集。** 微调数据集是通过结合人工和LLM提供的示例创建的，既用于本地模仿也用于广泛模仿。对于本地模仿，通过引导[自然问题数据集](https://ai.google.com/research/NaturalQuestions)（即基于维基百科的事实知识）来创建特定任务的微调数据集。具体而言，[1]中的作者从自然问题数据集中抽取了一小部分QA对，然后提示ChatGPT策划了6,000个类似问题的示例；见上文。'
- en: Curating a broad imitation dataset is more difficult, as the data needs to comprehensively
    cover desired LLM behavior. To create such a dataset, authors in [1] rely upon
    public, high-quality dialogues from sources like [ShareGPT](https://sharegpt.com/),
    ChatGPT-focused discord servers (e.g., [TuringAI](https://top.gg/servers/899761438996963349)),
    and even `r/ChatGPT` on Reddit. The result is ~130K examples of freely-collected
    dialogue examples—referred to as ShareGPT-Mix—that are used for imitation fine-tuning.
    The quality of this data is high, and there is a large diversity in instructions—the
    most similar user queries have a [BLEU score](/foundations-of-nlp-explained-bleu-score-and-wer-metrics-1a5ba06d812b)
    similarity of only 8%. Each dialogue example from ShareGPT-Mix is post-processed
    by adding special tokens that mark the beginning of each user query and model
    output; see below.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 创建广泛模仿数据集更为困难，因为数据需要全面覆盖期望的LLM行为。为了创建这样的数据集，[1]中的作者依赖于来自[ShareGPT](https://sharegpt.com/)、以ChatGPT为焦点的discord服务器（例如，[TuringAI](https://top.gg/servers/899761438996963349)）以及Reddit上的`r/ChatGPT`等来源的公共高质量对话。结果是~130K个自由收集的对话示例——称为ShareGPT-Mix——用于模仿微调。这些数据的质量很高，并且指令的多样性很大——最相似的用户查询的[BLEU分数](/foundations-of-nlp-explained-bleu-score-and-wer-metrics-1a5ba06d812b)相似度仅为8%。每个ShareGPT-Mix对话示例通过添加特殊标记来标记每个用户查询和模型输出的开始进行后处理；见下文。
- en: '![](../Images/68e035eddbd52b8c83b92cfcb62e8413.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/68e035eddbd52b8c83b92cfcb62e8413.png)'
- en: (from [1])
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [1]）
- en: '**Fine-tuning approach.** Models are fine-tuned using a standard language modeling
    loss. However, this loss is only applied over the portion of tokens corresponding
    to model output. In other words, the fine-tuning loss is only applied over the
    blue portions of each dialogue example within the above figure. Several fine-tuning
    runs are performed with dataset sizes ranging from 0.3M to 150M tokens.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**微调方法。** 模型使用标准的语言建模损失进行微调。然而，这种损失只应用于对应于模型输出的标记部分。换句话说，微调损失仅应用于上图中每个对话示例的蓝色部分。进行多次微调实验，数据集大小从
    0.3M 到 150M 标记不等。'
- en: Are imitation models actually useful?
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模仿模型真的有用吗？
- en: At initial glance, the quality of models trained via ShareGPT-mix imitation
    data seems to be quite high. While base models fail to follow instructions, the
    imitation fine-tuned variants stay on task and are capable of solving problems
    in a similar manner to ChatGPT. Plus, increasing the size of the model leads to
    consistent improvements in performance, and these models are rated positively
    when evaluated with GPT-4; see above.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 初看起来，通过 ShareGPT-mix 模仿数据训练的模型质量似乎相当高。虽然基础模型未能遵循指令，但经过模仿微调的变体能够保持任务一致性，并以类似
    ChatGPT 的方式解决问题。而且，模型规模的增加导致性能持续改进，这些模型在与 GPT-4 进行评估时获得了积极评价；见上文。
- en: However, more detailed analysis seems to indicate that these results might be
    slightly misleading. For example, human evaluation scores saturate quickly (and
    even degrade) as more imitation data is used; see below. Such a surprising result
    indicates that there is something we might be missing within the evaluation of
    these models.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，更详细的分析似乎表明这些结果可能略显误导。例如，随着更多模仿数据的使用，人类评估分数很快就会饱和（甚至下降）；见下文。如此惊人的结果表明，在这些模型的评估中，我们可能遗漏了某些东西。
- en: '![](../Images/38cb7b73a87cf6fa8479647603b11519.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/38cb7b73a87cf6fa8479647603b11519.png)'
- en: (from [1])
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: （来源于 [1]）
- en: '**Targeted evaluations.** When imitation models are evaluated across a wider
    variety of natural language benchmarks, we see that their performance is comparable
    to or below that of the corresponding base LLM. In other words, *fine-tuning over
    imitation does not improve the performance across a wider variety of tasks*; see
    below.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**针对性评估。** 当模仿模型在更广泛的自然语言基准测试中进行评估时，我们看到它们的表现与相应的基础LLM相当或更差。换句话说，*对模仿进行微调并没有提高在更广泛任务中的表现*；见下文。'
- en: '![](../Images/ffc1c220b974987d11cbbcaec87daf72.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ffc1c220b974987d11cbbcaec87daf72.png)'
- en: (from [1])
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: （来源于 [1]）
- en: Such lackluster performance on benchmarks like [MMLU](https://huggingface.co/datasets/lukaemon/mmlu)
    [10], [HumanEval](https://huggingface.co/datasets/openai_humaneval) [11], and
    [Natural Questions](https://ai.google.com/research/NaturalQuestions) [12] reveals
    that imitation models do not have improved factuality, coding abilities, or problem-solving
    capabilities compared to base LLMs. Given that [most of an LLM’s knowledge](https://twitter.com/cwolferesearch/status/1660744247123890179?s=20)
    is learned during pre-training, such a trend makes sense. We see in [1] that the
    imitation models can match the style of powerful LLMs like ChatGPT (see below),
    *but they lack the same knowledge base*. These models hallucinate more frequently,
    which is difficult to detect in basic human evaluations without extensive research
    or time investment.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在像 [MMLU](https://huggingface.co/datasets/lukaemon/mmlu) [10]、[HumanEval](https://huggingface.co/datasets/openai_humaneval)
    [11] 和 [Natural Questions](https://ai.google.com/research/NaturalQuestions) [12]
    等基准测试中的表现平平，表明与基础LLMs相比，模仿模型在事实准确性、编码能力或解决问题的能力上并没有提升。鉴于 [LLM的知识大多](https://twitter.com/cwolferesearch/status/1660744247123890179?s=20)
    是在预训练期间获得的，这一趋势是可以理解的。我们在 [1] 中看到，模仿模型可以匹配像 ChatGPT（见下文）这样的强大LLMs的风格，*但它们缺乏相同的知识库*。这些模型更频繁地出现幻觉现象，在没有大量研究或时间投入的基本人类评估中很难发现。
- en: '![](../Images/b2a5b61ad63160c4ebc7d57596d69a0f.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b2a5b61ad63160c4ebc7d57596d69a0f.png)'
- en: (from [1])
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: （来源于 [1]）
- en: '**Local imitation works well.** Despite the limitations of imitation models
    when evaluated on a broader set of tasks, we see that local imitation is actually
    quite effective. Learning specific behaviors of ChatGPT is possible via imitation,
    but we run into roadblocks when mimicking behavior more broadly; see below. Local
    imitation can be a useful point solution for adapting open-source LLMs to solve
    specific tasks or mimic proprietary models in particular scenarios.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**局部模仿效果良好。** 尽管在更广泛任务集上评估时模仿模型存在局限性，我们发现局部模仿实际上非常有效。通过模仿可以学习ChatGPT的特定行为，但当我们尝试更广泛地模仿行为时则会遇到障碍；见下文。局部模仿可以成为适应开源大型语言模型（LLM）以解决特定任务或在特定场景中模仿专有模型的一个有用解决方案。'
- en: '![](../Images/70fb9298b3d1b3ad88911edf8739cba6.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/70fb9298b3d1b3ad88911edf8739cba6.png)'
- en: (from [1])
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [1]）
- en: To broadly imitate the behavior of a model like ChatGPT, we need a significantly
    larger and more diverse source of imitation data. However, curating this dataset
    might not be the best approach — *we see a much larger performance benefit from
    simply increasing the size of the base model*. As such, creating more powerful
    base LLMs might be a more promising direction for open-source LLM research compared
    to creating cheap imitation models.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 为了广泛模仿像ChatGPT这样的模型的行为，我们需要一个显著更大且更多样化的模仿数据源。然而，策划这个数据集可能不是最佳方法——*我们发现仅仅增加基础模型的规模可以带来更大的性能提升*。因此，创建更强大的基础LLM可能是开源LLM研究比创建廉价模仿模型更有前景的方向。
- en: “We argue that the highest leverage action for improving open-source models
    is to tackle the difficult challenge of developing better base LMs, rather than
    taking the shortcut of imitating proprietary systems.” *— from [1]*
  id: totrans-88
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “我们认为，改善开源模型的最大杠杆作用在于解决开发更好基础语言模型的难题，而不是通过模仿专有系统来走捷径。” *— 来自 [1]*
- en: Final Thoughts
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后的思考
- en: Although the deep learning community has embraced openness and transparency
    for years, the explosion in popularity of LLMs has given birth to an alternative
    paradigm in which development is performed with proprietary APIs that provide
    no access to the actual model itself. To combat this shift away from open-source,
    researchers have developed open-source LLM alternatives. The creation of imitation
    models made this area of research seem to progress incredibly fast, leading many
    to assume that proprietary LLMs would quickly fall out of favor. Within this overview,
    we have seen that such imitation LLMs have major limitations. However, the development
    of powerful, open-source LLMs continues to progress. Some major takeaways from
    this work are outlined below.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管深度学习社区多年来一直推崇开放和透明，但LLM的流行爆炸催生了一种替代范式，即开发使用不提供实际模型访问的专有API的系统。为了应对这种远离开源的转变，研究人员开发了开源LLM替代方案。模仿模型的创建使这一研究领域似乎进展极快，许多人因此认为专有LLM会迅速失宠。在这一概述中，我们看到这些模仿LLM存在重大局限性。然而，强大的开源LLM的开发仍在持续推进。这项工作的主要结论如下。
- en: '**The importance of rigorous evaluation.** Imitation models seem to perform
    well when qualitatively evaluated by humans. When subjected to more rigorous quantitative
    evaluation, however, the performance of such models is found to be somewhat lackluster
    (and even worse than base models in some cases)! The findings from this work highlight
    the importance of rigorous evaluation in research. For a field to progress, we
    need to be sure that techniques and models being proposed are actually improving
    upon those that exist.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**严格评估的重要性。** 模仿模型在由人工进行的定性评估中表现良好。然而，当进行更严格的定量评估时，这些模型的表现则显得有些平庸（在某些情况下甚至不如基础模型）！这项工作的发现突显了研究中严格评估的重要性。为了推动一个领域的发展，我们需要确保提出的技术和模型实际上在改进现有的技术和模型。'
- en: '**Local imitation is still very useful.** Although imitation models are found
    to perform poorly when evaluated broadly, they perform quite well for any task
    that is included in their fine-tuning dataset. As such, *local imitation is still
    a useful and effective technique*. We can easily teach a smaller, open-source
    LLM to match the performance and behavior of a popular model like ChatGPT in a
    specific domain via imitation. However, we run into problems when trying to replicate
    the behavior of proprietary LLMs as a whole. This would require curating a massive
    dataset of dialogue examples for imitation fine-tuning.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**局部模仿仍然非常有用。** 尽管模仿模型在广泛评估时表现不佳，但它们在其微调数据集中包含的任何任务上表现相当好。因此，*局部模仿仍然是一个有用且有效的技术*。我们可以很容易地通过模仿来教会一个较小的开源
    LLM 在特定领域中匹配像 ChatGPT 这样的流行模型的性能和行为。然而，当尝试整体复制专有 LLM 的行为时，我们会遇到问题。这将需要策划一个大量的对话示例数据集用于模仿微调。'
- en: '**Implications for open-source LLMs.** As we have seen, imitation models (although
    useful for local imitation and specific use-cases) are not a general-purpose solution
    for producing high-quality, open-source foundation models. However, we see within
    [1] that LLM performance continues to improve with the size and quality of the
    underlying base model. Such a finding indicates that the creation of larger and
    more powerful base models is necessary for further advancements in open-source
    LLMs to occur.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**开源 LLM 的影响。** 如我们所见，模仿模型（尽管对局部模仿和特定用例有用）并不是生产高质量开源基础模型的通用解决方案。然而，我们在 [1]
    中看到 LLM 性能随着基础模型的规模和质量的提高而持续改进。这一发现表明，创建更大、更强大的基础模型对于开源 LLM 的进一步进展是必要的。'
- en: Connect with me!
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与我联系！
- en: Thanks so much for reading this article. I am [Cameron R. Wolfe](https://cameronrwolfe.me/),
    Director of AI at [Rebuy](https://www.rebuyengine.com/). I study the empirical
    and theoretical foundations of deep learning. If you liked this overview, subscribe
    to my [Deep (Learning) Focus newsletter](https://cameronrwolfe.substack.com/),
    where I help readers understand AI research via overviews of relevant topics from
    the ground up. You can also follow me on [X](https://twitter.com/cwolferesearch)
    and [LinkedIn](https://www.linkedin.com/in/cameron-r-wolfe-ph-d-04744a238/), or
    check out my [other writings](https://medium.com/@wolfecameron) on medium!
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 非常感谢阅读这篇文章。我是 [Cameron R. Wolfe](https://cameronrwolfe.me/)，[Rebuy](https://www.rebuyengine.com/)
    的人工智能总监。我研究深度学习的实证和理论基础。如果你喜欢这个概述，请订阅我的 [Deep (Learning) Focus 新闻通讯](https://cameronrwolfe.substack.com/)，在这里我通过从基础开始的相关主题概述帮助读者理解人工智能研究。你还可以在
    [X](https://twitter.com/cwolferesearch) 和 [LinkedIn](https://www.linkedin.com/in/cameron-r-wolfe-ph-d-04744a238/)
    上关注我，或者查看我在 medium 上的 [其他著作](https://medium.com/@wolfecameron)！
- en: Bibliography
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考书目
- en: '[1] Gudibande, Arnav, et al. “The false promise of imitating proprietary llms.”
    *arXiv preprint arXiv:2305.15717* (2023).'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Gudibande, Arnav 等。“模仿专有语言模型的虚假承诺。” *arXiv 预印本 arXiv:2305.15717*（2023年）。'
- en: '[2] Touvron, Hugo, et al. “Llama: Open and efficient foundation language models.”
    *arXiv preprint arXiv:2302.13971* (2023).'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Touvron, Hugo 等。“Llama: 开放且高效的基础语言模型。” *arXiv 预印本 arXiv:2302.13971*（2023年）。'
- en: '[3] Taori, Rohan et al. “Stanford Alpaca: An Instruction-following LLaMA model.”
    (2023).'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Taori, Rohan 等。“斯坦福阿尔帕卡：一个跟随指令的 LLaMA 模型。”（2023年）。'
- en: '[4] Chiang, Wei-Lin et al. “Vicuna: An Open-Source Chatbot Impressing GPT-4
    with 90%* ChatGPT Quality.” (2023).'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Chiang, Wei-Lin 等。“Vicuna: 一个开源聊天机器人，令人印象深刻的 90%* ChatGPT 质量。”（2023年）。'
- en: '[5] Geng, Xinyang et al. “Koala: A Dialogue Model for Academic Research.” (2023).'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Geng, Xinyang 等。“Koala: 一个用于学术研究的对话模型。”（2023年）。'
- en: '[6] Radford, Alec, et al. “Language Models are Unsupervised Multitask Learners.”'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] Radford, Alec 等。“语言模型是无监督的多任务学习者。”'
- en: '[7] Gou, Jianping, et al. “Knowledge distillation: A survey.” *International
    Journal of Computer Vision* 129 (2021): 1789–1819.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] Gou, Jianping 等。“知识蒸馏：综述。” *计算机视觉国际期刊* 129（2021年）：1789–1819。'
- en: '[8] Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. “Distilling the knowledge
    in a neural network.” *arXiv preprint arXiv:1503.02531* (2015).'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] Hinton, Geoffrey, Oriol Vinyals 和 Jeff Dean。“蒸馏神经网络中的知识。” *arXiv 预印本 arXiv:1503.02531*（2015年）。'
- en: '[9] Dylan Patel and Afzal Ahmad. Google “we have no moat, and neither does
    OpenAI”, 2023.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] Dylan Patel 和 Afzal Ahmad。谷歌“我们没有护城河，OpenAI 也没有”，2023年。'
- en: '[10] Hendrycks, Dan, et al. “Measuring massive multitask language understanding.”
    *arXiv preprint arXiv:2009.03300* (2020).'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] Hendrycks, Dan 等。“衡量大规模多任务语言理解。” *arXiv 预印本 arXiv:2009.03300*（2020年）。'
- en: '[11] Chen, Mark, et al. “Evaluating large language models trained on code.”
    *arXiv preprint arXiv:2107.03374* (2021).'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[11] Chen, Mark 等. “评估基于代码训练的大型语言模型。” *arXiv 预印本 arXiv:2107.03374* (2021)。'
- en: '[12] Kwiatkowski, Tom, et al. “Natural questions: a benchmark for question
    answering research.” *Transactions of the Association for Computational Linguistics*
    7 (2019): 453–466.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[12] Kwiatkowski, Tom 等. “自然问题：问题回答研究基准。” *计算语言学协会会刊* 7 (2019): 453–466。'
- en: '[13] Hoffmann, Jordan, et al. “Training compute-optimal large language models.”
    *arXiv preprint arXiv:2203.15556* (2022).'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[13] Hoffmann, Jordan 等. “训练计算最优的大型语言模型。” *arXiv 预印本 arXiv:2203.15556* (2022)。'
- en: '[14] Brown, Tom, et al. “Language models are few-shot learners.” *Advances
    in neural information processing systems* 33 (2020): 1877–1901.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[14] Brown, Tom 等. “语言模型是少量样本学习者。” *神经信息处理系统进展* 33 (2020): 1877–1901。'
- en: '[15] Chowdhery, Aakanksha, et al. “Palm: Scaling language modeling with pathways.”
    *arXiv preprint arXiv:2204.02311* (2022).'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[15] Chowdhery, Aakanksha 等. “Palm: 通过路径扩展语言建模。” *arXiv 预印本 arXiv:2204.02311*
    (2022)。'
- en: '[16] Yuvanesh Anand, Zach Nussbaum, Brandon Duderstadt, Benjamin Schmidt, and
    Andriy Mulyar. GPT4All: Training an assistant-style chatbot with large scale data
    distillation from GPT-3.5-Turbo, 2023.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[16] Yuvanesh Anand, Zach Nussbaum, Brandon Duderstadt, Benjamin Schmidt, 和
    Andriy Mulyar. GPT4All: 使用大规模数据蒸馏从 GPT-3.5-Turbo 训练助手风格的聊天机器人，2023年。'
- en: '[17] Wang, Yizhong, et al. “Self-Instruct: Aligning Language Model with Self
    Generated Instructions.” *arXiv preprint arXiv:2212.10560* (2022).'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[17] Wang, Yizhong 等. “Self-Instruct: 将语言模型与自生成指令对齐。” *arXiv 预印本 arXiv:2212.10560*
    (2022)。'
