# 堆叠时间序列模型以提高准确性

> 原文：[https://towardsdatascience.com/stacking-time-series-models-to-improve-accuracy-7977c6667d29](https://towardsdatascience.com/stacking-time-series-models-to-improve-accuracy-7977c6667d29)

## 从RNN、ARIMA和Prophet模型中提取信号，以便用Catboost进行预测

[](https://mikekeith52.medium.com/?source=post_page-----7977c6667d29--------------------------------)[![Michael Keith](../Images/4ebd39b25a1faae3586eb25ec83d3e91.png)](https://mikekeith52.medium.com/?source=post_page-----7977c6667d29--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7977c6667d29--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7977c6667d29--------------------------------) [Michael Keith](https://mikekeith52.medium.com/?source=post_page-----7977c6667d29--------------------------------)

·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----7977c6667d29--------------------------------) ·阅读时长7分钟·2023年2月28日

--

![](../Images/d4a54a6899fe0dff94fe8914297c3a54.png)

图片由[Robert Sachowski](https://unsplash.com/@rsachowski?utm_source=medium&utm_medium=referral)拍摄，发布在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)上。

关于强大的时间序列模型的研究非常丰富。可供选择的选项很多，远远超出了传统的ARIMA技术。最近，递归神经网络和LSTM模型已成为许多研究人员关注的重点。根据[PePy](https://pepy.tech/project/prophet)上列出的下载数量，Prophet模型可能是时间序列预测者使用最广泛的模型，因为它的入门门槛较低。对于你的时间序列来说，哪种选项最合适呢？

也许答案是你应该尝试所有这些模型，并结合它们的各种优点。一个常见的技术是堆叠。流行的机器学习库scikit-learn提供了一个[StackingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html)，可以用于时间序列任务。我[之前演示了如何使用它](https://medium.com/towards-data-science/expand-your-time-series-arsenal-with-these-models-10c807d37558)来处理这种情况。

然而，StackingRegressor 有一个限制；它只接受其他 scikit-learn 模型类和 API。因此，像 ARIMA 这样的模型（在 scikit-learn 中不可用）或来自 tensorflow 的深度网络将无法放入堆栈中。这里有一个解决方案。在这篇文章中，我将展示如何使用 [scalecast](https://github.com/mikekeith52/scalecast) 包和一个 Jupyter [notebook](https://scalecast-examples.readthedocs.io/en/latest/misc/stacking/custom_stacking.html) 扩展时间序列的堆叠方法。使用的数据集可以在 GitHub 上 [open access](https://github.com/Mcompetitions/M4-methods/issues/16) 获取。需要以下要求：

[PRE0]

# 数据集概述

数据集是按小时划分的，分为训练集（700 个观测值）和测试集（48 个观测值）。我的 notebook 使用了 H1 系列，但修改为利用 M4 数据集中任何一个小时序列是很直接的。这是如何读取数据并将其存储在 `Forecaster` 对象中的：

[PRE1]

这是该序列的图表：

![](../Images/f401c9799631034696a0527e7bcc829b.png)

作者提供的图片

# 应用模型

在开始堆叠模型之前，我们需要从它们生成预测。我选择使用简单模型作为 ARIMA、LSTM 和 Prophet 模型的基准。在接下来的部分中，我将解释为什么做出每个选择，但也可以做出其他决策，这些决策同样有趣，甚至更具吸引力。

## 简单基准测试

为了对所有模型进行基准测试，我们可以调用季节性简单估计方法，该方法将给定小时序列中的最后24个观测值向前传播。在 scalecast 中，这非常简单。

[PRE2]

## ARIMA

自回归积分滑动平均是一种流行且简单的时间序列技术，它利用序列的滞后值和误差以线性方式预测未来。通过探索性数据分析（您可以在链接的 [notebook](https://scalecast-examples.readthedocs.io/en/latest/misc/stacking/custom_stacking.html) 中看到），我确定序列不是平稳的，并且具有很强的季节性。我最终选择应用了一个季节性 ARIMA 模型，订单为 (5,1,4) x (1,1,1,24)。

[PRE3]

## LSTM

如果 ARIMA 属于时间序列模型中的简单方法，[LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM) 是更先进的方法之一。这是一种深度学习技术，具有许多参数，包括一个注意力机制，可以在序列数据中找到长期和短期的模式，这使其理论上成为时间序列的理想选择。使用 tensorflow 设置这个模型很困难，但在 scalecast 中并不太难（请参见 [这篇文章](https://medium.com/towards-data-science/exploring-the-lstm-neural-network-model-for-time-series-8b7685aa8cf)）。我应用了两个 LSTM 模型：一个使用 Tanh 激活函数，一个使用 ReLu。

[PRE4]

## Prophet

尽管Prophet模型极受欢迎，但它最近却被[贬低](https://www.microprediction.com/blog/prophet)。有人声称它的准确性令人失望，主要是因为它对趋势的外推过于不现实，并且它没有通过自回归建模考虑局部模式。然而，它确实有一些独特之处。比如，它会自动将节假日效应应用到模型中。它还考虑了几种季节性类型。它以用户需要的最少规格完成这些功能。我喜欢将它作为一个信号使用，即使它不适合生成点预测。

[PRE5]

## 比较结果

现在我们已经为每个模型生成了预测结果，让我们看看它们在验证集上的表现，这些是我们训练集中的最后48个观测值（这仍然与之前提到的测试集分开）。

[PRE6]

![](../Images/2a7e19fb3374c21513b3d8cde09abeee.png)

图片由作者提供

好消息是每个模型都优于朴素方法。ARIMA模型表现最佳，百分比误差为4.7%，其次是Prophet。让我们查看所有预测与验证集的对比图：

[PRE7]

![](../Images/16529891e70fd018f0bfc795c16964f9.png)

图片由作者提供

所有这些模型在这个系列上表现得相当合理，之间没有大的偏差。让我们进行模型叠加！

# 模型叠加

每个叠加模型都需要一个最终估计器，该估计器将筛选其他模型的各种估计值，以创建一组新的预测。我们将用一个叫做[Catboost](https://catboost.ai)的增强树估计器来叠加我们之前探索的结果。Catboost是一个强大的程序，我们希望它能从每个已经应用的模型中提取最佳信号。

[PRE8]

上述代码将每个评估模型的预测结果添加到`Forecaster`对象中。它将这些预测称为“信号”。这些信号与存储在同一对象中的其他协变量一样对待。我们还将最后48个系列的滞后添加为Catboost模型可以用来进行预测的额外回归量。现在我们将调用三个Catboost模型：一个使用所有可用的信号和系列滞后，一个仅使用信号，还有一个仅使用滞后。

[PRE9]

让我们利用在分析开始时与Forecaster对象分开的测试集，比较所有应用模型的结果。这次，我们将关注两个指标：SMAPE和平均绝对尺度误差（MASE）。这两个指标在实际的M4竞赛中被使用。

[PRE10]

![](../Images/c20085add01772635dd715cbd05d4e8d.png)

图片由作者提供

通过结合来自不同类别模型的信号，我们生成了两个优于其他模型的估计器：一个使用所有信号和48个系列滞后的Catboost模型，以及一个仅使用信号的Catboost模型。这两个模型的误差大约为2.8%。我们可以看到这两个模型与测试集中的实际数据进行对比的图示。

[PRE11]

![](../Images/26cf88caea4e6acf646451780e2bffd3.png)

作者提供的图片

# 哪些信号最为重要？

为了完善分析，我们可以使用 Shapley 分数来确定在这个模型堆叠中哪些信号最为重要。[Shapley 分数](https://christophm.github.io/interpretable-ml-book/shapley.html)被认为是确定输入在给定机器学习模型中的预测能力的最先进方法之一。分数越高，表示这些输入在该模型中越重要。

[PRE12]

![](../Images/70806022263aa125dea516fb8b33e938.png)

作者提供的图片

上面的截图仅显示了前几个最重要的预测因子，但我们可以从中看出，ARIMA 信号最为重要，其次是系列的第一个滞后项，然后是 Prophet 信号。RNN 模型的得分也高于许多包含的滞后项。如果我们希望将来训练一个更简洁的模型，这可以是一个很好的起点。

# 结论

在这篇文章中，我展示了在时间序列上下文中堆叠模型的威力，以及如何通过使用多样的模型类别提高探索系列的准确性。所有这些都通过 scalecast 包轻松实现。如果你觉得这个分析有趣，请在[GitHub](https://github.com/mikekeith52/scalecast)上给这个包一个星标。感谢你的关注！
