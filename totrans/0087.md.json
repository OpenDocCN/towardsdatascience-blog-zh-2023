["```py\npip install transformers\n```", "```py\nimport pandas as pd\n\n# Create wrapper to properly format the text\nfrom textwrap import TextWrapper\n\n# Wrap text to 80 characters.\nwrapper = TextWrapper(width=80)\n\n# Load the data\nnews_data = pd.read_csv(\"consumer_engagement_data.csv\")\n\n# Choose candidate descriptions\ndescription_76 = news_data.iloc[76][\"description\"]\ndescription_118 = news_data.iloc[118][\"description\"]\ndescription_178 = news_data.iloc[178][\"description\"]\n\nenglish_texts = [description_76, description_118, description_178]\n\nfor english_text in english_texts:\n    print(wrapper.fill(english_text))\n    print(\"\\n\")\n```", "```py\npip install sentencepiece\nfrom transformers import MarianTokenizer, MarianMTModel\n```", "```py\n# Get the name of the model\ntrans_model_name = 'Helsinki-NLP/opus-mt-en-fr'\n```", "```py\n# Get the tokenizer\ntrans_model_tkn = MarianTokenizer.from_pretrained(trans_model_name)\n```", "```py\n# Instanciate the model\ntrans_model = MarianMTModel.from_pretrained(trans_model_name)\n```", "```py\nfrom transformers import pipeline\n```", "```py\ncandidate_labels = [\"tech\", \"politics\", \"business\", \"finance\"]\n```", "```py\nmy_classifier = pipeline(\"zero-shot-classification\",       \n                         model='joeddav/xlm-roberta-large-xnli')\n```", "```py\n#For the first description\nprediction_desc_76 = run_predictions(english_texts[0])\n\nprint(wrapper.fill(prediction_desc_76[\"Text\"]))\n```", "```py\nprint(prediction_desc_76[\"Result\"])\n```", "```py\n#For the last description\nprediction_desc_178 = run_predictions(english_texts[-1])\n\nprint(wrapper.fill(prediction_desc_178[\"Text\"]))\n```", "```py\nprint(prediction_desc_178[\"Result\"])\n```", "```py\nfrom transformers import pipeline\n```", "```py\ndistil_bert_model = pipeline(task = \"sentiment-analysis\", \n                          model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n```", "```py\n# Run the predictions\ndistil_bert_model(english_texts[1:])\n```", "```py\nfrom transformers import AutoModelForQuestionAnswering, AutoTokenizer\n```", "```py\nmodel_name = \"deepset/roberta-base-squad2\"\nQA_model = pipeline('question-answering', model=model_name, \n                     tokenizer=model_name)\n```", "```py\nQA_input = {\n           'question': 'when is Apple hosting an event?',\n           'context': english_texts[-1]\n           }\n```", "```py\nmodel_response = QA_model(QA_input)\npd.DataFrame([model_response])\n```"]