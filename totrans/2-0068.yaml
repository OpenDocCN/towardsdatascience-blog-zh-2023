- en: 3D Point Cloud Shape Detection for Indoor Modelling
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®¤å†…å»ºæ¨¡çš„ 3D ç‚¹äº‘å½¢çŠ¶æ£€æµ‹
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/3d-point-cloud-shape-detection-for-indoor-modelling-70e36e5f2511](https://towardsdatascience.com/3d-point-cloud-shape-detection-for-indoor-modelling-70e36e5f2511)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/3d-point-cloud-shape-detection-for-indoor-modelling-70e36e5f2511](https://towardsdatascience.com/3d-point-cloud-shape-detection-for-indoor-modelling-70e36e5f2511)
- en: '[Hands-on Tutorials](https://towardsdatascience.com/tagged/hands-on-tutorials),
    3D Python'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[åŠ¨æ‰‹æ•™ç¨‹](https://towardsdatascience.com/tagged/hands-on-tutorials)ï¼Œ3D Python'
- en: A 10-step Python Guide to Automate 3D Shape Detection, Segmentation, Clustering,
    and Voxelization for Space Occupancy 3D Modeling of Indoor Point Cloud Datasets.
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10 æ­¥ Python æŒ‡å—ï¼Œç”¨äºè‡ªåŠ¨åŒ– 3D å½¢çŠ¶æ£€æµ‹ã€åˆ†å‰²ã€èšç±»å’Œä½“ç´ åŒ–ï¼Œä»¥å®ç°å®¤å†…ç‚¹äº‘æ•°æ®é›†çš„ç©ºé—´å ç”¨ 3D å»ºæ¨¡ã€‚
- en: '[](https://medium.com/@florentpoux?source=post_page-----70e36e5f2511--------------------------------)[![Florent
    Poux, Ph.D.](../Images/74df1e559b2edefba71ffd0d1294a251.png)](https://medium.com/@florentpoux?source=post_page-----70e36e5f2511--------------------------------)[](https://towardsdatascience.com/?source=post_page-----70e36e5f2511--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----70e36e5f2511--------------------------------)
    [Florent Poux, Ph.D.](https://medium.com/@florentpoux?source=post_page-----70e36e5f2511--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@florentpoux?source=post_page-----70e36e5f2511--------------------------------)[![Florent
    Poux, Ph.D.](../Images/74df1e559b2edefba71ffd0d1294a251.png)](https://medium.com/@florentpoux?source=post_page-----70e36e5f2511--------------------------------)[](https://towardsdatascience.com/?source=post_page-----70e36e5f2511--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----70e36e5f2511--------------------------------)
    [Florent Poux, Ph.D.](https://medium.com/@florentpoux?source=post_page-----70e36e5f2511--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----70e36e5f2511--------------------------------)
    Â·28 min readÂ·Sep 7, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----70e36e5f2511--------------------------------)
    Â·é˜…è¯»æ—¶é•¿ 28 åˆ†é’ŸÂ·2023å¹´9æœˆ7æ—¥
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: If you have experience with point clouds or data analysis, you know how crucial
    it is to spot patterns. Recognizing data points with similar patterns, or "objects,"
    is important to gain more valuable insights. Our visual cognitive system accomplishes
    this task easily, but replicating this human ability through computational methods
    is a significant challenge.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æœ‰ç‚¹äº‘æˆ–æ•°æ®åˆ†æçš„ç»éªŒï¼Œä½ çŸ¥é“è¯†åˆ«æ¨¡å¼æœ‰å¤šé‡è¦ã€‚è¯†åˆ«å…·æœ‰ç›¸ä¼¼æ¨¡å¼çš„æ•°æ®ç‚¹æˆ–â€œå¯¹è±¡â€å¯¹è·å–æœ‰ä»·å€¼çš„è§è§£è‡³å…³é‡è¦ã€‚æˆ‘ä»¬çš„è§†è§‰è®¤çŸ¥ç³»ç»Ÿå¯ä»¥è½»æ¾å®Œæˆè¿™é¡¹ä»»åŠ¡ï¼Œä½†é€šè¿‡è®¡ç®—æ–¹æ³•å¤åˆ¶è¿™ç§äººç±»èƒ½åŠ›æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚
- en: The goal is to utilize the natural tendency of the human visual system to group
    sets of elements. ğŸ‘€
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®æ ‡æ˜¯åˆ©ç”¨äººç±»è§†è§‰ç³»ç»Ÿè‡ªç„¶çš„å…ƒç´ åˆ†ç»„å€¾å‘ã€‚ğŸ‘€
- en: '![](../Images/f7a3a366e3f8d7cc6c3e1b7a11307505.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f7a3a366e3f8d7cc6c3e1b7a11307505.png)'
- en: Example of a result of the Segmentation phase on the 3D Point Cloud. Â© F. Poux
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 3D ç‚¹äº‘åˆ†å‰²é˜¶æ®µç»“æœç¤ºä¾‹ã€‚Â© F. Poux
- en: But why is it useful?
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½†è¿™æœ‰ä»€ä¹ˆç”¨å‘¢ï¼Ÿ
- en: First, it lets you easily access and work with specific parts of the data by
    grouping them into segments. Secondly, it makes the data processing faster by
    looking at regions instead of individual points. This can save a lot of time and
    energy. And finally, segmentation can help you find patterns and relationships
    you wouldnâ€™t be able to see just by looking at the raw data. ğŸ” Overall, segmentation
    is crucial for getting useful information from point cloud data. If you are unsure
    how to do it, do not worry â€” We will figure this out together! ğŸ¤¿
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œå®ƒé€šè¿‡å°†æ•°æ®åˆ†ç»„åˆ°ä¸åŒçš„æ®µä¸­ï¼Œè®©ä½ è½»æ¾è®¿é—®å’Œå¤„ç†æ•°æ®çš„ç‰¹å®šéƒ¨åˆ†ã€‚å…¶æ¬¡ï¼Œé€šè¿‡æŸ¥çœ‹åŒºåŸŸè€Œä¸æ˜¯å•ä¸ªç‚¹ï¼Œå®ƒä½¿æ•°æ®å¤„ç†æ›´å¿«ã€‚è¿™å¯ä»¥èŠ‚çœå¤§é‡æ—¶é—´å’Œç²¾åŠ›ã€‚æœ€åï¼Œåˆ†å‰²å¯ä»¥å¸®åŠ©ä½ å‘ç°é€šè¿‡æŸ¥çœ‹åŸå§‹æ•°æ®æ— æ³•çœ‹åˆ°çš„æ¨¡å¼å’Œå…³ç³»ã€‚ğŸ”
    æ€»çš„æ¥è¯´ï¼Œåˆ†å‰²å¯¹äºä»ç‚¹äº‘æ•°æ®ä¸­è·å–æœ‰ç”¨ä¿¡æ¯è‡³å…³é‡è¦ã€‚å¦‚æœä½ ä¸ç¡®å®šå¦‚ä½•åšï¼Œåˆ«æ‹…å¿ƒâ€”â€”æˆ‘ä»¬ä¼šä¸€èµ·æå®šçš„ï¼ğŸ¤¿
- en: The Strategy
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç­–ç•¥
- en: Let us frame the overall approach before approaching the project with an efficient
    solution. This tutorial follows a strategy comprising ten straightforward steps,
    as illustrated in our strategy diagram below.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬ä»¥æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆå¤„ç†é¡¹ç›®ä¹‹å‰ï¼Œè®©æˆ‘ä»¬æ¡†å®šæ•´ä½“æ–¹æ³•ã€‚æœ¬æ•™ç¨‹éµå¾ªä¸€ä¸ªç”±åä¸ªç®€å•æ­¥éª¤ç»„æˆçš„ç­–ç•¥ï¼Œå¦‚ä¸‹æ–¹çš„ç­–ç•¥å›¾æ‰€ç¤ºã€‚
- en: '![](../Images/49c746a4375f4f284fe81f501c11fb4f.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/49c746a4375f4f284fe81f501c11fb4f.png)'
- en: The workflow for 3D Point Cloud Indoor Modelling shown in this guide. Â© F. Poux
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æŒ‡å—å±•ç¤ºäº† 3D ç‚¹äº‘å®¤å†…å»ºæ¨¡çš„å·¥ä½œæµç¨‹ã€‚Â© F. Poux
- en: 'The strategy is laid out, and below, you can find the quick links to the different
    steps:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ç­–ç•¥å·²åˆ—å‡ºï¼Œä¸‹é¢ä½ å¯ä»¥æ‰¾åˆ°ä¸åŒæ­¥éª¤çš„å¿«æ·é“¾æ¥ï¼š
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now that we are set up, let us jump right in.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¢ç„¶æˆ‘ä»¬å·²åšå¥½å‡†å¤‡ï¼Œé‚£å°±ç›´æ¥å¼€å§‹å§ã€‚
- en: 'ğŸµ**Note to Readers***: This hands-on guide is part of a* [***UTWENTE***](https://www.itc.nl/)
    *joint work, with co-authors* ***F. Poux*** *and* ***V. Lehtola****. We acknowledge
    the financial contribution from the digital twins* [*@ITC*](http://twitter.com/ITC)
    *-project granted by the ITC faculty of the University of Twente.* ***All images
    are Â© Florent Poux****.*'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸµ**è¯»è€…æ³¨æ„**ï¼šæ­¤åŠ¨æ‰‹æŒ‡å—æ˜¯* [***UTWENTE***](https://www.itc.nl/) *è”åˆå·¥ä½œçš„ä¸€éƒ¨åˆ†ï¼Œç”±* ***F. Poux***
    *å’Œ* ***V. Lehtola*** *å…±åŒä½œè€…ã€‚æˆ‘ä»¬æ„Ÿè°¢æ¥è‡ªæ•°å­—åŒèƒèƒ* [*@ITC*](http://twitter.com/ITC) *é¡¹ç›®çš„èµ„åŠ©ï¼Œè¯¥é¡¹ç›®ç”±ç‰¹æ¸©ç‰¹å¤§å­¦
    ITC ç³»æä¾›ã€‚***æ‰€æœ‰å›¾åƒ Â© Florent Poux***ã€‚*
- en: 1\. Set up your Python environment.
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. è®¾ç½®æ‚¨çš„ Python ç¯å¢ƒã€‚
- en: '![](../Images/b862dfa664dd54db82f77e3449a9a117.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b862dfa664dd54db82f77e3449a9a117.png)'
- en: In a previous article below, we saw how to quickly set up an environment with
    Anaconda and use the IDE JupyterLab to manage your code. Continuing in this fashion
    if you set yourself up to become a fully-fledged Python app developer ğŸ˜†.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹é¢çš„ä¸Šä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•å¿«é€Ÿè®¾ç½® Anaconda ç¯å¢ƒå¹¶ä½¿ç”¨ IDE JupyterLab ç®¡ç†ä»£ç ã€‚å¦‚æœæ‚¨ç»§ç»­ä»¥è¿™ç§æ–¹å¼è®¾ç½®è‡ªå·±ï¼Œæ‚¨å°†æˆä¸ºä¸€åå®Œæ•´çš„
    Python åº”ç”¨ç¨‹åºå¼€å‘è€… ğŸ˜†ã€‚
- en: '[](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----70e36e5f2511--------------------------------)
    [## 3D Python Workflows for LiDAR City Models: A Step-by-Step Guide'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----70e36e5f2511--------------------------------)
    [## 3D Python å·¥ä½œæµç¨‹ç”¨äº LiDAR åŸå¸‚æ¨¡å‹ï¼šé€æ­¥æŒ‡å—'
- en: The Ultimate Guide to unlocking a streamlined workflow for 3D City Modelling
    Applications. The tutorial covers Pythonâ€¦
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è§£é” 3D åŸå¸‚å»ºæ¨¡åº”ç”¨ç¨‹åºçš„ç²¾ç®€å·¥ä½œæµç¨‹çš„ç»ˆææŒ‡å—ã€‚æ•™ç¨‹æ¶µç›–äº† Python...
- en: towardsdatascience.com](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----70e36e5f2511--------------------------------)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----70e36e5f2511--------------------------------)
- en: 'ğŸ¦Š **Florent***: I highly recommend using a desktop setup or IDE and avoiding
    Google Colab IF you need to visualize 3D point clouds using the libraries provided,
    as they will be unstable at best or not working at worse (unfortunatelyâ€¦).*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦Š **Florent**ï¼š*æˆ‘å¼ºçƒˆæ¨èä½¿ç”¨æ¡Œé¢è®¾ç½®æˆ– IDEï¼Œé¿å…ä½¿ç”¨ Google Colabï¼Œå°¤å…¶æ˜¯å½“æ‚¨éœ€è¦ä½¿ç”¨æä¾›çš„åº“å¯è§†åŒ– 3D ç‚¹äº‘æ—¶ï¼Œå› ä¸ºå®ƒä»¬åœ¨æœ€ä½³æƒ…å†µä¸‹ä¼šä¸ç¨³å®šï¼Œæœ€ç³Ÿç³•çš„æƒ…å†µä¸‹åˆ™æ— æ³•å·¥ä½œï¼ˆä¸å¹¸çš„æ˜¯â€¦ï¼‰ã€‚*
- en: 'ğŸ¤  **Ville**: *We guess that you are running on Windows? This is fine, but if
    you want to get into computational methods, Linux is the go-to choice!*'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤  **Ville**ï¼š*æˆ‘ä»¬çŒœæ‚¨æ˜¯åœ¨ Windows ä¸Šè¿è¡Œï¼Ÿè¿™æ²¡é—®é¢˜ï¼Œä½†å¦‚æœæ‚¨æƒ³è¿›å…¥è®¡ç®—æ–¹æ³•é¢†åŸŸï¼ŒLinux æ˜¯é¦–é€‰ï¼*
- en: Well, we will take a â€œparti-prisâ€ to quickly get results. Indeed, we will accomplish
    excellent segmentation by following a minimalistic approach to coding ğŸ’». That
    means being very picky about the underlying libraries! We will use three very
    robust ones, namely. `numpy`, `matplotlib`, and `open3d`.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ï¼Œæˆ‘ä»¬å°†é‡‡å–ä¸€ç§â€œå¿«é€Ÿæˆæœâ€çš„æ–¹æ³•ã€‚å®é™…ä¸Šï¼Œæˆ‘ä»¬å°†é€šè¿‡éµå¾ªæœ€ç®€åŒ–çš„ç¼–ç æ–¹æ³•æ¥å®ç°å“è¶Šçš„åˆ†å‰²ğŸ’»ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯¹åº•å±‚åº“éå¸¸æŒ‘å‰”ï¼æˆ‘ä»¬å°†ä½¿ç”¨ä¸‰ä¸ªéå¸¸å¼ºå¤§çš„åº“ï¼Œåˆ†åˆ«æ˜¯`numpy`ã€`matplotlib`å’Œ`open3d`ã€‚
- en: 'Okay, to install the library package above in a fresh virtual environment,
    we suggest you run the following command from the `cmd` terminal:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œè¦åœ¨ä¸€ä¸ªå…¨æ–°çš„è™šæ‹Ÿç¯å¢ƒä¸­å®‰è£…ä¸Šè¿°åº“åŒ…ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨ä»`cmd`ç»ˆç«¯è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ğŸœ ***Disclaimer Note****:* We choose Python, not C++ nor Julia, so performances
    are what they are ğŸ˜„. Hopefully, it will be enough for your application ğŸ˜‰, for
    what we call â€œofflineâ€ processes (not real-time).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸœ ***å…è´£å£°æ˜***ï¼š*æˆ‘ä»¬é€‰æ‹©äº† Pythonï¼Œè€Œä¸æ˜¯ C++ æˆ– Juliaï¼Œæ‰€ä»¥æ€§èƒ½å°±æ˜¯é‚£æ · ğŸ˜„ã€‚å¸Œæœ›å®ƒèƒ½æ»¡è¶³æ‚¨çš„åº”ç”¨éœ€æ±‚ ğŸ˜‰ï¼Œå¯¹äºæˆ‘ä»¬æ‰€è°“çš„â€œç¦»çº¿â€è¿‡ç¨‹ï¼ˆéå®æ—¶ï¼‰ã€‚*
- en: 'Within your Python IDE, make sure to import the three libraries that will be
    under heavy use:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ‚¨çš„ Python IDE ä¸­ï¼Œè¯·ç¡®ä¿å¯¼å…¥å°†è¢«é¢‘ç¹ä½¿ç”¨çš„ä¸‰ä¸ªåº“ï¼š
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: And that is it! We are ready to rock indoor point cloud modeling workflows!
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å°±è¿™æ ·ï¼æˆ‘ä»¬å‡†å¤‡å¥½è¿›è¡Œå®¤å†…ç‚¹äº‘å»ºæ¨¡å·¥ä½œæµç¨‹äº†ï¼
- en: 2\. Point Cloud Data Preparation
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. ç‚¹äº‘æ•°æ®å‡†å¤‡
- en: '![](../Images/e18d10ffc4d22a7dfa415f9b85211b8a.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e18d10ffc4d22a7dfa415f9b85211b8a.png)'
- en: 'In previous tutorials, we illustrated point cloud processing and meshing over
    a 3D dataset obtained using an aerial LiDAR from the AHN4 LiDAR Campaign. This
    time, we will use a dataset gathered using a Terrestrial Laser Scanner: the ITC
    new building. It was organized into three different sets for you to experiment
    on. In purple, you have an outdoor part. In red is the ground level, and in green
    is the first floor, as illustrated below.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¹‹å‰çš„æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬æ¼”ç¤ºäº†å¦‚ä½•å¤„ç†ç‚¹äº‘å¹¶åœ¨ä½¿ç”¨ AHN4 LiDAR æ´»åŠ¨è·å–çš„ 3D æ•°æ®é›†ä¸Šè¿›è¡Œç½‘æ ¼åŒ–ã€‚è¿™ä¸€æ¬¡ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªé€šè¿‡åœ°é¢æ¿€å…‰æ‰«æä»ªæ”¶é›†çš„æ•°æ®é›†ï¼šITC
    æ–°å»ºç­‘ã€‚å®ƒè¢«ç»„ç»‡æˆä¸‰ä¸ªä¸åŒçš„é›†åˆä¾›æ‚¨å®éªŒã€‚ç´«è‰²çš„æ˜¯æˆ·å¤–éƒ¨åˆ†ã€‚çº¢è‰²æ˜¯åœ°é¢å±‚ï¼Œç»¿è‰²æ˜¯ç¬¬ä¸€å±‚ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚
- en: '![](../Images/a3a4446fe2fae77b40da248fa8e3081b.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a3a4446fe2fae77b40da248fa8e3081b.png)'
- en: The 3D Point Cloud parts of the ITC Dataset used. Â© F. Poux
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨çš„ ITC æ•°æ®é›†çš„ 3D ç‚¹äº‘éƒ¨åˆ†ã€‚Â© F. Poux
- en: 'You can download the data from the Drive Folder here: [ITC Datasets](https://drive.google.com/drive/folders/1sCBT1lc9A8Zn4grpxwFrBrvos86c0HZR?usp=share_link).
    Once you have a firm grasp on the data locally, you can load the dataset in your
    Python execution runtime with two simple lines:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥ä»è¿™é‡Œä¸‹è½½æ•°æ®ï¼š[ITC æ•°æ®é›†](https://drive.google.com/drive/folders/1sCBT1lc9A8Zn4grpxwFrBrvos86c0HZR?usp=share_link)ã€‚ä¸€æ—¦ä½ åœ¨æœ¬åœ°å¯¹æ•°æ®æœ‰äº†ç‰¢å›ºçš„æŒæ¡ï¼Œä½ å¯ä»¥ç”¨ä¸¤è¡Œç®€å•çš„ä»£ç å°†æ•°æ®é›†åŠ è½½åˆ°ä½ çš„
    Python æ‰§è¡Œç¯å¢ƒä¸­ï¼š
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'ğŸ¦Š **Florent**: *This Python code snippet uses the* `*Open3D*` *library to read
    a point cloud data file* `*ITC_groundfloor.ply*` *located in the directory. â€œ*`*../DATA/*`*â€
    and assign it to the variable* `*pcd*`*.*'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸ¦Š **Florent**: *è¿™æ®µ Python ä»£ç ç‰‡æ®µä½¿ç”¨* `*Open3D*` *åº“æ¥è¯»å–ä½äºç›®å½•â€œ*`*../DATA/*`*â€ä¸­çš„ç‚¹äº‘æ•°æ®æ–‡ä»¶*
    `*ITC_groundfloor.ply*` *ï¼Œå¹¶å°†å…¶èµ‹å€¼ç»™å˜é‡* `*pcd*`*ã€‚*'
- en: 'The variable now holds your point cloud `pcd` you will play with the following:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å˜é‡ç°åœ¨ä¿å­˜ç€ä½ çš„ç‚¹äº‘ `pcd`ï¼Œä½ å°†ç”¨ä»¥ä¸‹ä»£ç è¿›è¡Œæ“ä½œï¼š
- en: '![](../Images/6ac078d0d708734f455c9e8907b18642.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6ac078d0d708734f455c9e8907b18642.png)'
- en: Once the point cloud data has been successfully loaded using Open3D, the next
    step is to apply various pre-processing techniques to enhance its quality and
    extract meaningful information.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦ç‚¹äº‘æ•°æ®æˆåŠŸåŠ è½½åˆ° Open3D ä¸­ï¼Œä¸‹ä¸€æ­¥æ˜¯åº”ç”¨å„ç§é¢„å¤„ç†æŠ€æœ¯æ¥æå‡å…¶è´¨é‡å¹¶æå–æœ‰æ„ä¹‰çš„ä¿¡æ¯ã€‚
- en: 3\. Point Cloud Pre-Processing
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. ç‚¹äº‘é¢„å¤„ç†
- en: '![](../Images/0bb8b750bb4d32115dac7abbc406fbde.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0bb8b750bb4d32115dac7abbc406fbde.png)'
- en: 'If you intend on visualizing the point cloud within `open3d`It is good practice
    to shift your point cloud to bypass the large coordinates approximation, which
    creates shaky visualization effects. To apply such a shift to your `pcd` point
    cloud, first get the center of the point cloud, then translate it by subtracting
    it from the original variable:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ‰“ç®—åœ¨ `open3d` ä¸­å¯è§†åŒ–ç‚¹äº‘ï¼Œå»ºè®®ä½ å°†ç‚¹äº‘ç§»åŠ¨ä»¥ç»•è¿‡å¤§åæ ‡çš„è¿‘ä¼¼ï¼Œè¿™æ ·å¯ä»¥é¿å…äº§ç”Ÿæ™ƒåŠ¨çš„å¯è§†åŒ–æ•ˆæœã€‚è¦å¯¹ä½ çš„ `pcd` ç‚¹äº‘åº”ç”¨è¿™ç§ç§»åŠ¨ï¼Œé¦–å…ˆè·å–ç‚¹äº‘çš„ä¸­å¿ƒï¼Œç„¶åé€šè¿‡ä»åŸå§‹å˜é‡ä¸­å‡å»å®ƒæ¥è¿›è¡Œå¹³ç§»ï¼š
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Which can now be interactively visualized with the following line of code:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨å¯ä»¥é€šè¿‡ä»¥ä¸‹ä»£ç è¡Œè¿›è¡Œäº¤äº’å¼å¯è§†åŒ–ï¼š
- en: '[PRE5]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'ğŸ¦š **Note**: `o3d.visualization.draw_geometries([pcd])` *calls the* `*draw_geometries()*`
    *function from the* `*visualization*` *Module in Open3D. The function takes a
    list of geometries as an argument and displays them in a visualization window.
    In this case, the list contains a single geometry, which is the* `*pcd*` *variable
    representing the point cloud. The* `*draw_geometries()*` *function creates a 3D
    visualization window and renders the point cloud. You can interact with the visualization
    window to rotate, zoom, and explore the point cloud from different perspectives.*'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸ¦š **æ³¨æ„**: `o3d.visualization.draw_geometries([pcd])` *è°ƒç”¨äº†* `*draw_geometries()*`
    *å‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°å±äº Open3D çš„* `*visualization*` *æ¨¡å—ã€‚è¯¥å‡½æ•°æ¥å—ä¸€ä¸ªå‡ ä½•ä½“åˆ—è¡¨ä½œä¸ºå‚æ•°ï¼Œå¹¶åœ¨å¯è§†åŒ–çª—å£ä¸­æ˜¾ç¤ºå®ƒä»¬ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåˆ—è¡¨åŒ…å«ä¸€ä¸ªå‡ ä½•ä½“ï¼Œå³è¡¨ç¤ºç‚¹äº‘çš„*
    `*pcd*` *å˜é‡ã€‚* `*draw_geometries()*` *å‡½æ•°åˆ›å»ºä¸€ä¸ª 3D å¯è§†åŒ–çª—å£å¹¶æ¸²æŸ“ç‚¹äº‘ã€‚ä½ å¯ä»¥ä¸å¯è§†åŒ–çª—å£äº’åŠ¨ä»¥æ—‹è½¬ã€ç¼©æ”¾ï¼Œå¹¶ä»ä¸åŒè§’åº¦æ¢ç´¢ç‚¹äº‘ã€‚*'
- en: '![](../Images/38196ff8a2b3f0d77fa32690deefe8ba.png)![](../Images/1b23848831179d63eccaa3cf24969e6a.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/38196ff8a2b3f0d77fa32690deefe8ba.png)![](../Images/1b23848831179d63eccaa3cf24969e6a.png)'
- en: GreatğŸ‘Œ, we are all set up to test some sampling strategies to unify our downward
    processes.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: å¤ªæ£’äº†ğŸ‘Œï¼Œæˆ‘ä»¬å·²ç»å‡†å¤‡å¥½æµ‹è¯•ä¸€äº›é‡‡æ ·ç­–ç•¥æ¥ç»Ÿä¸€æˆ‘ä»¬çš„ä¸‹æ¸¸å¤„ç†ã€‚
- en: 3.1\. Point Cloud Random Sampling
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.1\. ç‚¹äº‘éšæœºé‡‡æ ·
- en: 'Let us consider random sampling methods that can effectively reduce point cloud
    size while preserving overall structural integrity and representativeness. If
    we define a point cloud as a matrix (m x n), then a **decimated cloud** is obtained
    by keeping one row out of n of this matrix :'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è€ƒè™‘é‚£äº›å¯ä»¥æœ‰æ•ˆå‡å°‘ç‚¹äº‘å¤§å°åŒæ—¶ä¿æŒæ•´ä½“ç»“æ„å®Œæ•´æ€§å’Œä»£è¡¨æ€§çš„æ–¹æ³•ã€‚å¦‚æœæˆ‘ä»¬å°†ç‚¹äº‘å®šä¹‰ä¸ºä¸€ä¸ªçŸ©é˜µ (m x n)ï¼Œé‚£ä¹ˆé€šè¿‡ä¿ç•™è¯¥çŸ©é˜µæ¯éš” n è¡Œçš„ä¸€ä¸ªè¡Œï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸€ä¸ª**ç®€åŒ–çš„ç‚¹äº‘**ï¼š
- en: '![](../Images/43048e0ad321a1ec9cb3b8607d68133a.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/43048e0ad321a1ec9cb3b8607d68133a.png)'
- en: A Point Cloud Decimation Strategy. Â© F. Poux
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªç‚¹äº‘ç®€åŒ–ç­–ç•¥ã€‚Â© F. Poux
- en: 'At the matrix level, the decimation acts by keeping points for every n-th row
    depending on the n factor. Of course, this is made based on how the points are
    stored in the file. Slicing a point cloud with `open3d` It is pretty straightforward.
    To shorten and parametrize the expression, you can write the lines:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨çŸ©é˜µçº§åˆ«ï¼Œç®€åŒ–æ“ä½œæ˜¯é€šè¿‡æ ¹æ® n å› å­ä¿ç•™æ¯éš” n è¡Œçš„ç‚¹æ¥è¿›è¡Œçš„ã€‚å½“ç„¶ï¼Œè¿™å–å†³äºç‚¹åœ¨æ–‡ä»¶ä¸­çš„å­˜å‚¨æ–¹å¼ã€‚ç”¨ `open3d` åˆ‡ç‰‡ç‚¹äº‘æ˜¯ç›¸å½“ç›´æ¥çš„ã€‚ä¸ºäº†ç®€åŒ–å’Œå‚æ•°åŒ–è¡¨è¾¾å¼ï¼Œä½ å¯ä»¥å†™å‡ºä»¥ä¸‹ä»£ç ï¼š
- en: '[PRE6]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'ğŸ¦š **Note**: `sampled_pcd = pcd.random_down_sample(retained_ratio)` *applies
    random downsampling to the original point cloud* `*pcd*` *using the* `random_down_sample()`
    *function provided by Open3D. The* `retained_ratio` *parameter determines the
    proportion of points to be retained after downsampling. For example, if* `retained_ratio`
    *it is set to 0.5, approximately 50% of the points will be randomly selected and
    retained in the sampled point cloud.*'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š`sampled_pcd = pcd.random_down_sample(retained_ratio)` *å¯¹åŸå§‹ç‚¹äº‘* `*pcd*`
    *åº”ç”¨éšæœºä¸‹é‡‡æ ·ï¼Œä½¿ç”¨çš„æ˜¯* `random_down_sample()` *å‡½æ•°ï¼Œè¯¥å‡½æ•°ç”± Open3D æä¾›ã€‚* `retained_ratio` *å‚æ•°å†³å®šäº†ä¸‹é‡‡æ ·åä¿ç•™çš„ç‚¹çš„æ¯”ä¾‹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœ*
    `retained_ratio` *è®¾ç½®ä¸º 0.5ï¼Œåˆ™å¤§çº¦ 50% çš„ç‚¹å°†è¢«éšæœºé€‰æ‹©å¹¶ä¿ç•™åœ¨é‡‡æ ·åçš„ç‚¹äº‘ä¸­ã€‚*
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/f4d15aa96e162454499be387b499b6e3.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4d15aa96e162454499be387b499b6e3.png)'
- en: Results of the subsampling of the point cloud. Â© F. Poux
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ç‚¹äº‘çš„ä¸‹é‡‡æ ·ç»“æœã€‚Â© F. Poux
- en: 'ğŸŒ± **Growing**: *When studying 3D point clouds, random sampling has limitations
    that could result in missing important information and inaccurate analysis. It
    doesnâ€™t consider the spatial component or relationships between the points. Therefore,
    itâ€™s essential to use other methods to ensure a more comprehensive analysis.*'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸŒ± **å‘å±•**ï¼š*åœ¨ç ”ç©¶ 3D ç‚¹äº‘æ—¶ï¼Œéšæœºé‡‡æ ·æœ‰å…¶å±€é™æ€§ï¼Œå¯èƒ½ä¼šå¯¼è‡´é—æ¼é‡è¦ä¿¡æ¯å’Œåˆ†æä¸å‡†ç¡®ã€‚å®ƒæ²¡æœ‰è€ƒè™‘ç‚¹ä¹‹é—´çš„ç©ºé—´ç»„ä»¶æˆ–å…³ç³»ã€‚å› æ­¤ï¼Œä½¿ç”¨å…¶ä»–æ–¹æ³•ä»¥ç¡®ä¿æ›´å…¨é¢çš„åˆ†ææ˜¯è‡³å…³é‡è¦çš„ã€‚*
- en: While this strategy is quick, random sampling may not be most adapted to a â€œstandardizationâ€
    use case. The next step is to address potential outliers through statistical outlier
    removal techniques, ensuring the data quality and reliability for subsequent analysis
    and processing.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡è¿™ç§ç­–ç•¥å¿«é€Ÿï¼Œä½†éšæœºé‡‡æ ·å¯èƒ½ä¸é€‚åˆâ€œæ ‡å‡†åŒ–â€ç”¨ä¾‹ã€‚ä¸‹ä¸€æ­¥æ˜¯é€šè¿‡ç»Ÿè®¡å¼‚å¸¸å€¼å»é™¤æŠ€æœ¯æ¥å¤„ç†æ½œåœ¨çš„å¼‚å¸¸å€¼ï¼Œä»¥ç¡®ä¿æ•°æ®çš„è´¨é‡å’Œå¯é æ€§ï¼Œä»¥ä¾¿è¿›è¡Œåç»­åˆ†æå’Œå¤„ç†ã€‚
- en: 3.2\. Statistical outlier removal
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.2\. ç»Ÿè®¡å¼‚å¸¸å€¼å»é™¤
- en: Using an outlier filter on 3D point cloud data can help identify and remove
    any data points significantly different from the rest of the dataset. These outliers
    could result from measurement errors or other factors that can skew the analysis.
    By removing these outliers, we can get a more valid representation of the data
    and better adjust algorithms. However, we need to be careful not to delete valuable
    points.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹ 3D ç‚¹äº‘æ•°æ®ä½¿ç”¨å¼‚å¸¸å€¼è¿‡æ»¤å™¨å¯ä»¥å¸®åŠ©è¯†åˆ«å’Œå»é™¤ä»»ä½•æ˜¾è‘—ä¸åŒäºæ•°æ®é›†å…¶ä½™éƒ¨åˆ†çš„æ•°æ®ç‚¹ã€‚è¿™äº›å¼‚å¸¸å€¼å¯èƒ½æ˜¯ç”±äºæµ‹é‡è¯¯å·®æˆ–å…¶ä»–å› ç´ é€ æˆçš„ï¼Œè¿™äº›å› ç´ å¯èƒ½ä¼šå½±å“åˆ†æã€‚é€šè¿‡å»é™¤è¿™äº›å¼‚å¸¸å€¼ï¼Œæˆ‘ä»¬å¯ä»¥è·å¾—æ›´æœ‰æ•ˆçš„æ•°æ®è¡¨ç¤ºï¼Œå¹¶æ›´å¥½åœ°è°ƒæ•´ç®—æ³•ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬éœ€è¦å°å¿ƒä¸è¦åˆ é™¤æœ‰ä»·å€¼çš„ç‚¹ã€‚
- en: 'We will define a `statistical_outlier_removal` filter to remove points that
    are further away from their neighbors compared to the average for the point cloud.
    It takes two input parameters:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†å®šä¹‰ä¸€ä¸ª `statistical_outlier_removal` è¿‡æ»¤å™¨ï¼Œä»¥å»é™¤ä¸å…¶é‚»å±…ç›¸æ¯”è¿œç¦»å¹³å‡å€¼çš„ç‚¹ã€‚å®ƒéœ€è¦ä¸¤ä¸ªè¾“å…¥å‚æ•°ï¼š
- en: '`nb_neighbors`, which specifies how many neighbors are considered to calculate
    the average distance for a given point.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nb_neighbors`ï¼Œç”¨äºæŒ‡å®šåœ¨è®¡ç®—ç»™å®šç‚¹çš„å¹³å‡è·ç¦»æ—¶è€ƒè™‘å¤šå°‘ä¸ªé‚»å±…ã€‚'
- en: '`std_ratio`, which allows setting the threshold level based on the standard
    deviation of the average distances across the point cloud. The lower this number,
    the more aggressive the filter will be.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std_ratio`ï¼Œå…è®¸æ ¹æ®ç‚¹äº‘ä¸­å¹³å‡è·ç¦»çš„æ ‡å‡†å·®è®¾ç½®é˜ˆå€¼æ°´å¹³ã€‚è¿™ä¸ªæ•°å€¼è¶Šä½ï¼Œè¿‡æ»¤å™¨çš„ä½œç”¨å°±è¶Šå¼ºã€‚'
- en: 'This amount to the following:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åŒ…æ‹¬ä»¥ä¸‹å†…å®¹ï¼š
- en: '[PRE8]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'ğŸ¦š **Note**: *the* `*remove_statistical_outlier()*` *the function applies statistical
    outlier removal to the point cloud using a specified number of nearest neighbors
    (*`*nn*`*) and a standard deviation multiplier (*`*std_multiplier*`*). The function
    returns two values:* `*filtered_pcd*` *and* `*filtered_idx*`*.* `*filtered_pcd*`
    *represents the filtered point cloud, where statistical outliers have been removed.*
    `*filtered_idx*` *is an array of indices corresponding to the points in the original
    point cloud* `*pcd*` *that were retained after the outlier removal process.*'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*`*remove_statistical_outlier()*` *å‡½æ•°é€šè¿‡æŒ‡å®šæ•°é‡çš„æœ€è¿‘é‚»ï¼ˆ*`*nn*`*ï¼‰å’Œä¸€ä¸ªæ ‡å‡†å·®ä¹˜æ•°ï¼ˆ*`*std_multiplier*`*ï¼‰æ¥å¯¹ç‚¹äº‘åº”ç”¨ç»Ÿè®¡å¼‚å¸¸å€¼å»é™¤ã€‚è¯¥å‡½æ•°è¿”å›ä¸¤ä¸ªå€¼ï¼š*
    `*filtered_pcd*` *å’Œ* `*filtered_idx*`*ã€‚* `*filtered_pcd*` *è¡¨ç¤ºç»è¿‡æ»¤çš„ç‚¹äº‘ï¼Œå…¶ä¸­å·²å»é™¤ç»Ÿè®¡å¼‚å¸¸å€¼ã€‚*
    `*filtered_idx*` *æ˜¯ä¸€ä¸ªç´¢å¼•æ•°ç»„ï¼Œå¯¹åº”äºåœ¨å¼‚å¸¸å€¼å»é™¤è¿‡ç¨‹ä¸­ä¿ç•™çš„åŸå§‹ç‚¹äº‘* `*pcd*` *ä¸­çš„ç‚¹ã€‚*
- en: 'To visualize the results of this filtering technique, we color the outliers
    in red and add them to the list of point cloud objects we want to visualize:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å¯è§†åŒ–è¿™ç§è¿‡æ»¤æŠ€æœ¯çš„ç»“æœï¼Œæˆ‘ä»¬å°†å¼‚å¸¸å€¼æ ‡è®°ä¸ºçº¢è‰²ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ°æˆ‘ä»¬å¸Œæœ›å¯è§†åŒ–çš„ç‚¹äº‘å¯¹è±¡åˆ—è¡¨ä¸­ï¼š
- en: '[PRE9]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/6ef3e983fc62a7eda4eaf143ce2330a5.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6ef3e983fc62a7eda4eaf143ce2330a5.png)'
- en: The outliers are in tagged and visualized in red in the point cloud. Â© F. Poux
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: å¼‚å¸¸å€¼åœ¨ç‚¹äº‘ä¸­ç”¨çº¢è‰²æ ‡è®°å’Œå¯è§†åŒ–ã€‚Â© F. Poux
- en: After removing statistical outliers from the point cloud, the next step involves
    applying voxel-based sampling techniques to downsample the data further, facilitating
    efficient processing and analysis while preserving the essential structural characteristics
    of the point cloud.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä»ç‚¹äº‘ä¸­ç§»é™¤ç»Ÿè®¡å¼‚å¸¸å€¼ä¹‹åï¼Œä¸‹ä¸€æ­¥æ˜¯åº”ç”¨åŸºäºä½“ç´ çš„é‡‡æ ·æŠ€æœ¯ï¼Œè¿›ä¸€æ­¥ä¸‹é‡‡æ ·æ•°æ®ï¼Œä»¥ä¾¿é«˜æ•ˆå¤„ç†å’Œåˆ†æï¼ŒåŒæ—¶ä¿ç•™ç‚¹äº‘çš„åŸºæœ¬ç»“æ„ç‰¹å¾ã€‚
- en: 3.3\. Point Cloud Voxel (Grid) Sampling
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.3. ç‚¹äº‘ä½“ç´ ï¼ˆç½‘æ ¼ï¼‰é‡‡æ ·
- en: The grid subsampling strategy is based on the division of the 3D space in regular
    cubic cells called voxels. For each cell of this grid, we only keep one representative
    point, and this point, the representative of the cell, can be chosen in different
    ways. When subsampling, we keep that cell's closest point to the barycenter.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ç½‘æ ¼ä¸‹é‡‡æ ·ç­–ç•¥åŸºäºå°†3Dç©ºé—´åˆ’åˆ†ä¸ºè§„åˆ™çš„ç«‹æ–¹ä½“å•å…ƒï¼Œç§°ä¸ºä½“ç´ ã€‚å¯¹äºè¿™ä¸ªç½‘æ ¼çš„æ¯ä¸ªå•å…ƒï¼Œæˆ‘ä»¬åªä¿ç•™ä¸€ä¸ªä»£è¡¨æ€§ç‚¹ï¼Œå¹¶ä¸”å¯ä»¥ç”¨ä¸åŒçš„æ–¹å¼é€‰æ‹©è¿™ä¸ªç‚¹ã€‚å½“ä¸‹é‡‡æ ·æ—¶ï¼Œæˆ‘ä»¬ä¿ç•™è¯¥å•å…ƒæœ€æ¥è¿‘é‡å¿ƒçš„ç‚¹ã€‚
- en: '![](../Images/802a55909c5aa28b959e4357b8e2f9e4.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/802a55909c5aa28b959e4357b8e2f9e4.png)'
- en: Example of Voxel Grid Sampling. Â© F. Poux
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ä½“ç´ ç½‘æ ¼é‡‡æ ·ç¤ºä¾‹ã€‚Â© F. Poux
- en: 'Concretely, we define a `voxel_size` that we then use to filter our point cloud:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ª`voxel_size`ï¼Œç„¶åç”¨å®ƒæ¥è¿‡æ»¤æˆ‘ä»¬çš„ç‚¹äº‘ï¼š
- en: '[PRE10]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'ğŸ¦š **Note**: *This line performs voxel downsampling on the filtered point cloud,*
    `*filtered_pcd*`*, using the* `*voxel_down_sample()*` *function. The* `*voxel_size*`
    *parameter specifies the size of each voxel for downsampling the point cloud.
    Larger voxel sizes result in a more significant reduction in point cloud density.
    The result of the downsampling operation is assigned to the variable* `*pcd_downsampled*`*,
    representing the downsampled point cloud*.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*æ­¤è¡Œå¯¹è¿‡æ»¤åçš„ç‚¹äº‘æ‰§è¡Œä½“ç´ ä¸‹é‡‡æ ·ï¼Œ* `*filtered_pcd*`*ï¼Œä½¿ç”¨* `*voxel_down_sample()*` *å‡½æ•°ã€‚*
    `*voxel_size*` *å‚æ•°æŒ‡å®šä½“ç´ ä¸‹é‡‡æ ·ç‚¹äº‘çš„æ¯ä¸ªä½“ç´ çš„å¤§å°ã€‚è¾ƒå¤§çš„ä½“ç´ å°ºå¯¸ä¼šå¯¼è‡´ç‚¹äº‘å¯†åº¦æ˜¾è‘—å‡å°‘ã€‚ä¸‹é‡‡æ ·æ“ä½œçš„ç»“æœåˆ†é…ç»™å˜é‡* `*pcd_downsampled*`*ï¼Œä»£è¡¨ä¸‹é‡‡æ ·åçš„ç‚¹äº‘*ã€‚
- en: 'Time to visualize the repartition closely after our downsampling:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ˜¯ä»”ç»†å¯è§†åŒ–ä¸‹é‡‡æ ·ååˆ†å¸ƒçš„æ—¶é—´ï¼š
- en: '[PRE11]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/f65a10e76a7e48feae0b94ffc246e5db.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f65a10e76a7e48feae0b94ffc246e5db.png)'
- en: The result of the sampling strategy applied on the point cloud. Â© F. Poux
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: åº”ç”¨åœ¨ç‚¹äº‘ä¸Šçš„é‡‡æ ·ç­–ç•¥ç»“æœã€‚Â© F. Poux
- en: At this stage, we have an outlier point set left untouched in further processing
    and a downsampled point cloud that constitutes the new subject of the subsequent
    processes.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ­¤é˜¶æ®µï¼Œæˆ‘ä»¬æœ‰ä¸€ç»„æœªåœ¨è¿›ä¸€æ­¥å¤„ç†æ—¶è§¦åŠçš„å¼‚å¸¸ç‚¹å’Œä¸€ä¸ªä¸‹é‡‡æ ·åçš„ç‚¹äº‘ï¼Œæ„æˆäº†åç»­è¿‡ç¨‹çš„æ–°ä¸»é¢˜ã€‚
- en: 3.4\. Point Cloud Normals Extraction
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.4. ç‚¹äº‘æ³•çº¿æå–
- en: 'A point cloud normal refers to the direction of a surface at a specific point
    in a 3D point cloud. It can be used for segmentation by dividing the point cloud
    into regions with similar normals, for example. In our case, normals will help
    identify objects and surfaces within the point cloud, making it easier to visualize.
    And it is an excellent opportunity to introduce a way to compute such normals
    semi-automatically. We first define the average distance between each point in
    the point cloud and its neighbors:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ç‚¹äº‘æ³•çº¿æŒ‡çš„æ˜¯3Dç‚¹äº‘ä¸­ç‰¹å®šç‚¹å¤„è¡¨é¢çš„æ–¹å‘ã€‚å®ƒå¯ä»¥ç”¨äºé€šè¿‡å°†ç‚¹äº‘åˆ’åˆ†ä¸ºå…·æœ‰ç›¸ä¼¼æ³•çº¿çš„åŒºåŸŸæ¥è¿›è¡Œåˆ†å‰²ã€‚ä¾‹å¦‚ï¼Œåœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œæ³•çº¿å°†æœ‰åŠ©äºè¯†åˆ«ç‚¹äº‘ä¸­çš„ç‰©ä½“å’Œè¡¨é¢ï¼Œä½¿å…¶æ›´å®¹æ˜“å¯è§†åŒ–ã€‚è¿™ä¹Ÿæ˜¯ä»‹ç»ä¸€ç§åŠè‡ªåŠ¨è®¡ç®—æ³•çº¿çš„æ–¹æ³•çš„ç»ä½³æœºä¼šã€‚æˆ‘ä»¬é¦–å…ˆå®šä¹‰ç‚¹äº‘ä¸­æ¯ä¸ªç‚¹ä¸å…¶é‚»å±…ä¹‹é—´çš„å¹³å‡è·ç¦»ï¼š
- en: '[PRE12]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then we use this information to extract a limited `max_nn` points within a
    radius `radius_normals` to compute a normal for each point in the 3D point cloud:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬åˆ©ç”¨è¿™äº›ä¿¡æ¯åœ¨åŠå¾„ä¸º`radius_normals`çš„èŒƒå›´å†…æå–æœ‰é™çš„`max_nn`ä¸ªç‚¹ï¼Œä¸º3Dç‚¹äº‘ä¸­çš„æ¯ä¸ªç‚¹è®¡ç®—æ³•çº¿ï¼š
- en: '[PRE13]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The pcd_downsampled point cloud object is now proud to have normals, ready
    to display its prettiest side ğŸ˜Š. You know the drill at this stage:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œ`pcd_downsampled`ç‚¹äº‘å¯¹è±¡å¾ˆé«˜å…´åœ°æ‹¥æœ‰æ³•çº¿ï¼Œå‡†å¤‡å±•ç¤ºå…¶æœ€æ¼‚äº®çš„ä¸€é¢ğŸ˜Šã€‚æ­¤æ—¶ä½ çŸ¥é“è¯¥åšä»€ä¹ˆï¼š
- en: '[PRE14]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/92aa19172478994bb05bcd86ef4bd146.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/92aa19172478994bb05bcd86ef4bd146.png)'
- en: The point cloud used for the follow-up experiments.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºåç»­å®éªŒçš„ç‚¹äº‘ã€‚
- en: Upon completing the voxel downsampling of the point cloud, the subsequent step
    involves configuring the parameters for point cloud shape detection and clustering,
    which plays a crucial role in grouping similar points together and extracting
    meaningful structures or objects from the downsampled point cloud data.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: å®Œæˆç‚¹äº‘çš„ä½“ç´ ä¸‹é‡‡æ ·åï¼Œä¸‹ä¸€æ­¥æ˜¯é…ç½®ç‚¹äº‘å½¢çŠ¶æ£€æµ‹å’Œèšç±»çš„å‚æ•°ï¼Œè¿™åœ¨å°†ç›¸ä¼¼ç‚¹åˆ†ç»„ä»¥åŠä»ä¸‹é‡‡æ ·ç‚¹äº‘æ•°æ®ä¸­æå–æœ‰æ„ä¹‰çš„ç»“æ„æˆ–å¯¹è±¡ä¸­èµ·ç€å…³é”®ä½œç”¨ã€‚
- en: 4\. Point Cloud Parameter setting
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. ç‚¹äº‘å‚æ•°è®¾ç½®
- en: '![](../Images/4d43adb22c40912f783a2cb44c0064b4.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4d43adb22c40912f783a2cb44c0064b4.png)'
- en: 'In this tutorial, we have selected two of the most effective and reliable methods
    for 3D Shape detection and clustering for you to master: RANSAC and Euclidean
    Clustering using DBSCAN. However, before utilizing these approaches, hence understanding
    the parameters, it is crucial to comprehend the fundamental concepts in simple
    terms.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¸ºæ‚¨ç²¾é€‰äº†ä¸¤ç§æœ€æœ‰æ•ˆä¸”å¯é çš„3Då½¢çŠ¶æ£€æµ‹å’Œèšç±»æ–¹æ³•ï¼šRANSACå’Œä½¿ç”¨DBSCANçš„æ¬§å‡ é‡Œå¾—èšç±»ã€‚ç„¶è€Œï¼Œåœ¨ä½¿ç”¨è¿™äº›æ–¹æ³•ä¹‹å‰ï¼Œäº†è§£å‚æ•°çš„åŒæ—¶ï¼Œç†è§£åŸºæœ¬æ¦‚å¿µæ˜¯è‡³å…³é‡è¦çš„ã€‚
- en: RANSAC
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RANSAC
- en: 'The RANSAC algorithm, short for RANdom SAmple Consensus, is a powerful tool
    for handling data that contains outliers, which is often the case when working
    with real-world sensors. The algorithm works by grouping data points into two
    categories: inliers and outliers. By identifying and ignoring the outliers, you
    can focus on working with reliable inliers, making your analysis more effective.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: RANSACç®—æ³•ï¼ŒRANdom SAmple Consensusçš„ç¼©å†™ï¼Œæ˜¯ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·ï¼Œç”¨äºå¤„ç†åŒ…å«å¼‚å¸¸å€¼çš„æ•°æ®ï¼Œè¿™åœ¨ä½¿ç”¨ç°å®ä¸–ç•Œä¼ æ„Ÿå™¨æ—¶å¸¸å¸¸ä¼šé‡åˆ°ã€‚è¯¥ç®—æ³•é€šè¿‡å°†æ•°æ®ç‚¹åˆ†ä¸ºä¸¤ç±»ï¼šå†…ç‚¹å’Œå¤–ç‚¹æ¥å·¥ä½œã€‚é€šè¿‡è¯†åˆ«å¹¶å¿½ç•¥å¤–ç‚¹ï¼Œæ‚¨å¯ä»¥ä¸“æ³¨äºå¤„ç†å¯é çš„å†…ç‚¹ï¼Œä»è€Œä½¿åˆ†ææ›´åŠ æœ‰æ•ˆã€‚
- en: '![](../Images/a5c122fcaa8c0f6453ae2b2363de65b9.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a5c122fcaa8c0f6453ae2b2363de65b9.png)'
- en: Planar detection with RANSAC in a 3D Point Cloud. Â© F. Poux
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨3Dç‚¹äº‘ä¸­ä½¿ç”¨RANSACè¿›è¡Œå¹³é¢æ£€æµ‹ã€‚Â© F. Poux
- en: So let me use a tiny but simple example to illustrate how RANSAC works. Let
    us say that we want to fit a plane through the point cloud below. How can we do
    that?
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ç”¨ä¸€ä¸ªç®€å•çš„ä¾‹å­æ¥è¯´æ˜RANSACçš„å·¥ä½œåŸç†ã€‚å‡è®¾æˆ‘ä»¬æƒ³é€šè¿‡ä¸‹é¢çš„ç‚¹äº‘æ‹Ÿåˆä¸€ä¸ªå¹³é¢ã€‚æˆ‘ä»¬æ€ä¹ˆåšå‘¢ï¼Ÿ
- en: '![](../Images/bb85346e13ae187ec137bef80050cce3.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bb85346e13ae187ec137bef80050cce3.png)'
- en: RANSAC Plane detection simulation in a random point cloud. Â© F. Poux
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨éšæœºç‚¹äº‘ä¸­è¿›è¡Œçš„RANSACå¹³é¢æ£€æµ‹æ¨¡æ‹Ÿã€‚Â© F. Poux
- en: First, we create a plane from the data, and for this, we randomly select 3 points
    from the point cloud necessary to establish a plane. And then, we simply check
    how many of the remaining points kind of fall on the plane (to a certain threshold),
    which will give a score to the proposal.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬ä»æ•°æ®ä¸­åˆ›å»ºä¸€ä¸ªå¹³é¢ï¼Œä¸ºæ­¤ï¼Œæˆ‘ä»¬ä»ç‚¹äº‘ä¸­éšæœºé€‰æ‹©3ä¸ªç‚¹æ¥å»ºç«‹å¹³é¢ã€‚ç„¶åï¼Œæˆ‘ä»¬ç®€å•åœ°æ£€æŸ¥å‰©ä½™çš„ç‚¹ä¸­æœ‰å¤šå°‘ç‚¹è½åœ¨è¯¥å¹³é¢ä¸Šï¼ˆè¾¾åˆ°æŸä¸ªé˜ˆå€¼ï¼‰ï¼Œè¿™å°†ä¸ºææ¡ˆæ‰“åˆ†ã€‚
- en: '![](../Images/4162c310eb51619b469d062fc8078732.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4162c310eb51619b469d062fc8078732.png)'
- en: RANSAC Scoring system illustrated. You can see that each iteration samples 3
    random points from which it will create a plan and then select the points that
    would fall on it. Here, iteration 159 would be the best candidate. Â© F. Poux
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: RANSACè¯„åˆ†ç³»ç»Ÿè¯´æ˜ã€‚æ‚¨å¯ä»¥çœ‹åˆ°ï¼Œæ¯æ¬¡è¿­ä»£éƒ½ä¼šéšæœºæŠ½å–3ä¸ªç‚¹ï¼Œä»ä¸­åˆ›å»ºä¸€ä¸ªå¹³é¢ï¼Œç„¶åé€‰æ‹©è½åœ¨å¹³é¢ä¸Šçš„ç‚¹ã€‚åœ¨è¿™é‡Œï¼Œç¬¬159æ¬¡è¿­ä»£ä¼šæ˜¯æœ€ä½³å€™é€‰ã€‚Â© F.
    Poux
- en: 'Then, we repeat the process with 3 new random points and see how we are doing.
    Is it better? Is it worse? And again, we repeat this process over and over again,
    letâ€™s say 10 times, 100 times, 1000 times, and then we select the plane model
    with the highest score (i.e. which has the best â€œsupportâ€ of the remaining data
    points). And that will be our solution: the supporting points plus the three points
    that we have sampled constitute our **inlier point set**, and the rest is our
    **outlier point set**. Easy enough, hun ğŸ˜?'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬ç”¨3ä¸ªæ–°çš„éšæœºç‚¹é‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œçœ‹çœ‹æ•ˆæœå¦‚ä½•ã€‚æ˜¯æ›´å¥½äº†å—ï¼Ÿæ›´å·®äº†å—ï¼Ÿç„¶åï¼Œæˆ‘ä»¬åå¤è¿›è¡Œè¿™ä¸ªè¿‡ç¨‹ï¼Œæ¯”å¦‚è¯´10æ¬¡ã€100æ¬¡ã€1000æ¬¡ï¼Œç„¶åé€‰æ‹©å¾—åˆ†æœ€é«˜çš„å¹³é¢æ¨¡å‹ï¼ˆå³å…·æœ‰æœ€ä½³â€œæ”¯æŒâ€çš„å‰©ä½™æ•°æ®ç‚¹ï¼‰ã€‚è¿™å°†æ˜¯æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆï¼šæ”¯æŒç‚¹åŠ ä¸Šæˆ‘ä»¬é‡‡æ ·çš„ä¸‰ä¸ªç‚¹æ„æˆæˆ‘ä»¬çš„**å†…ç‚¹é›†**ï¼Œå…¶ä½™éƒ¨åˆ†æ˜¯æˆ‘ä»¬çš„**å¤–ç‚¹é›†**ã€‚å¤Ÿç®€å•å§
    ğŸ˜ï¼Ÿ
- en: 'Haha, but for the skeptics, donâ€™t you have a rising question? How do we actually
    determine how many times we should repeat the process? How often should we try
    that? Well, that is actually something that we can compute, but let''s put it
    aside, for now, to focus on the matter at hand: point cloud segmentation ğŸ˜‰.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: å“ˆå“ˆï¼Œå¯¹äºé‚£äº›æ€€ç–‘è€…ï¼Œä½ ä»¬éš¾é“æ²¡æœ‰ä¸€ä¸ªä¸Šå‡çš„é—®é¢˜å—ï¼Ÿæˆ‘ä»¬å¦‚ä½•å®é™…ç¡®å®šåº”è¯¥é‡å¤å¤šå°‘æ¬¡è¿‡ç¨‹ï¼Ÿæˆ‘ä»¬åº”è¯¥å¤šé¢‘ç¹åœ°å°è¯•ï¼Ÿå¥½å§ï¼Œè¿™å®é™…ä¸Šæ˜¯å¯ä»¥è®¡ç®—çš„ï¼Œä½†æˆ‘ä»¬å…ˆæŠŠå®ƒæ”¾åˆ°ä¸€è¾¹ï¼Œä¸“æ³¨äºå½“å‰çš„é—®é¢˜ï¼šç‚¹äº‘åˆ†å‰²ğŸ˜‰ã€‚
- en: RANSAC Parameter Setting
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RANSACå‚æ•°è®¾ç½®
- en: 'We want to use RANSAC for detecting 3D planar shapes in our point cloud. To
    use RANSAC, we need to define three parameters: a distance threshold `distance_threshold`
    that allows tagging a point inlier or outlier to the 3D shape; a minimal number
    of point `ransac_n` selected to fit the geometric model; a number of iterations
    `num_iterations`.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¸Œæœ›ä½¿ç”¨RANSACæ¥æ£€æµ‹ç‚¹äº‘ä¸­çš„3Då¹³é¢å½¢çŠ¶ã€‚ä½¿ç”¨RANSACæ—¶ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ä¸‰ä¸ªå‚æ•°ï¼šä¸€ä¸ªè·ç¦»é˜ˆå€¼`distance_threshold`ï¼Œç”¨äºå°†ç‚¹æ ‡è®°ä¸ºå†…ç‚¹æˆ–å¤–ç‚¹ï¼›ä¸€ä¸ªæœ€å°ç‚¹æ•°`ransac_n`ï¼Œç”¨äºæ‹Ÿåˆå‡ ä½•æ¨¡å‹ï¼›ä¸€ä¸ªè¿­ä»£æ¬¡æ•°`num_iterations`ã€‚
- en: '**Determination of the Distance threshold:** We may be a bit limited by needing
    some domain knowledge to set up future segmentation and modeling threshold. Therefore,
    it would be exciting to try and bypass this to open the approach to non-experts.
    we will share with you a straightforward thought that could be useful. What if
    we were to compute the mean distance between points in our datasets and use this
    as a base to set up our threshold?'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**è·ç¦»é˜ˆå€¼çš„ç¡®å®š**ï¼šæˆ‘ä»¬å¯èƒ½ä¼šå› ä¸ºéœ€è¦ä¸€äº›é¢†åŸŸçŸ¥è¯†æ¥è®¾ç½®æœªæ¥çš„åˆ†å‰²å’Œå»ºæ¨¡é˜ˆå€¼è€Œå—åˆ°é™åˆ¶ã€‚å› æ­¤ï¼Œå°è¯•ç»•è¿‡è¿™ä¸€ç‚¹ä»¥ä½¿æ–¹æ³•å¯¹éä¸“å®¶å¼€æ”¾å°†æ˜¯ä»¤äººå…´å¥‹çš„ã€‚æˆ‘ä»¬å°†ä¸ä½ åˆ†äº«ä¸€ä¸ªç®€å•çš„æƒ³æ³•ï¼Œè¿™å¯èƒ½ä¼šæœ‰ç”¨ã€‚å¦‚æœæˆ‘ä»¬è®¡ç®—æ•°æ®é›†ä¸­ç‚¹ä¹‹é—´çš„å¹³å‡è·ç¦»ï¼Œå¹¶å°†å…¶ä½œä¸ºè®¾ç½®é˜ˆå€¼çš„åŸºç¡€ï¼Œä¼šæ€æ ·å‘¢ï¼Ÿ'
- en: 'Well, it is an idea worth exploring. To determine such a value, we use a `KD-Tree`
    to speed up the process of querying the nearest neighbors for each point. From
    there, we can then query the k-nearest neighbors for each point in the point cloud,
    which is then packed in the `open3d` function shown below:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ï¼Œè¿™æ˜¯ä¸€ä¸ªå€¼å¾—æ¢ç´¢çš„æƒ³æ³•ã€‚ä¸ºäº†ç¡®å®šè¿™æ ·çš„å€¼ï¼Œæˆ‘ä»¬ä½¿ç”¨ `KD-Tree` æ¥åŠ é€Ÿæ¯ä¸ªç‚¹çš„æœ€è¿‘é‚»æŸ¥è¯¢è¿‡ç¨‹ã€‚ä»é‚£é‡Œå¼€å§‹ï¼Œæˆ‘ä»¬å¯ä»¥æŸ¥è¯¢ç‚¹äº‘ä¸­æ¯ä¸ªç‚¹çš„ k
    ä¸ªæœ€è¿‘é‚»ï¼Œç„¶åå°†å…¶æ‰“åŒ…åˆ°ä¸‹é¢æ˜¾ç¤ºçš„ `open3d` å‡½æ•°ä¸­ï¼š
- en: '[PRE15]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: without much surprise, it is close to 5 cm as we sampled our point cloud to
    this value. It means that if we reasoned by considering the nearest neighbor,
    we would have an average distance of 51 mm.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯«æ— æ„å¤–ï¼Œå®ƒæ¥è¿‘ 5 cmï¼Œå› ä¸ºæˆ‘ä»¬å°†ç‚¹äº‘é‡‡æ ·åˆ°è¿™ä¸ªå€¼ã€‚è¿™æ„å‘³ç€å¦‚æœæˆ‘ä»¬è€ƒè™‘æœ€è¿‘é‚»ï¼Œæˆ‘ä»¬ä¼šæœ‰ 51 mm çš„å¹³å‡è·ç¦»ã€‚
- en: 'ğŸŒ± **Growing**: *From there, what we could do it to set the RANSAC parameter
    to a value derived from the nn_distance variable, which would then be adapted
    to the considered dataset, independently from domain knowledge. How would you
    approach this?*'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸŒ± **æˆé•¿**ï¼š*ä»è¿™é‡Œå¼€å§‹ï¼Œæˆ‘ä»¬å¯ä»¥å°† RANSAC å‚æ•°è®¾ç½®ä¸ºä» nn_distance å˜é‡å¾—å‡ºçš„å€¼ï¼Œè¿™æ ·å¯ä»¥æ ¹æ®è€ƒè™‘çš„æ•°æ®é›†è¿›è¡Œè°ƒæ•´ï¼Œè€Œä¸ä¾èµ–äºé¢†åŸŸçŸ¥è¯†ã€‚ä½ ä¼šæ€ä¹ˆå¤„ç†è¿™ä¸ªé—®é¢˜ï¼Ÿ*
- en: '**Determination of the point number**: Here, it is quick. We want to find planes,
    so we will take the minimum number of points needed to define a 3D plane: 3.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç‚¹æ•°çš„ç¡®å®š**ï¼šè¿™é‡Œå¾ˆç®€å•ã€‚æˆ‘ä»¬æƒ³è¦æ‰¾å‡ºå¹³é¢ï¼Œå› æ­¤æˆ‘ä»¬å°†å–å®šä¹‰ 3D å¹³é¢æ‰€éœ€çš„æœ€å°ç‚¹æ•°ï¼š3ã€‚'
- en: '**Determination of the iteration number**: The more iteration you have, the
    more robust your 3D shape detection works, but the longer it takes. For now, we
    can leave that to 1000, which yields good results. We will explore more ingenious
    ways to find the noise ratio of a point cloud in future tutorials. ğŸ˜‰'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**è¿­ä»£æ¬¡æ•°çš„ç¡®å®š**ï¼šè¿­ä»£æ¬¡æ•°è¶Šå¤šï¼Œä½ çš„ 3D å½¢çŠ¶æ£€æµ‹å°±è¶Šç¨³å¥ï¼Œä½†æ‰€éœ€æ—¶é—´ä¹Ÿè¶Šé•¿ã€‚ç›®å‰ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶è®¾ç½®ä¸º 1000ï¼Œè¿™æ ·å¯ä»¥è·å¾—è‰¯å¥½çš„ç»“æœã€‚æˆ‘ä»¬å°†åœ¨æœªæ¥çš„æ•™ç¨‹ä¸­æ¢ç´¢æ›´å¤šå·§å¦™çš„æ–¹æ³•æ¥æ‰¾å‡ºç‚¹äº‘çš„å™ªå£°æ¯”ä¾‹ã€‚ğŸ˜‰'
- en: 'ğŸ§™â€â™‚ï¸ **Experts**: *There exists an automatic way to get the iteration number
    right every time. If we want to succeed with a probability p (e.g., 99%), the
    outlier ratio in our data is e (e.g., 60%), and we need s point to define our
    model (here 3). The formula below gives us the expected number of iterations:*'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ§™â€â™‚ï¸ **ä¸“å®¶**ï¼š*æœ‰ä¸€ç§è‡ªåŠ¨è·å–æ¯æ¬¡è¿­ä»£æ¬¡æ•°çš„æ–¹æ³•ã€‚å¦‚æœæˆ‘ä»¬å¸Œæœ›ä»¥æ¦‚ç‡ pï¼ˆä¾‹å¦‚ 99%ï¼‰æˆåŠŸï¼Œæ•°æ®ä¸­çš„ç¦»ç¾¤ç‚¹æ¯”ä¾‹æ˜¯ eï¼ˆä¾‹å¦‚ 60%ï¼‰ï¼Œæˆ‘ä»¬éœ€è¦
    s ä¸ªç‚¹æ¥å®šä¹‰æˆ‘ä»¬çš„æ¨¡å‹ï¼ˆè¿™é‡Œæ˜¯ 3ï¼‰ã€‚ä»¥ä¸‹å…¬å¼ç»™å‡ºäº†é¢„æœŸçš„è¿­ä»£æ¬¡æ•°ï¼š*
- en: '![](../Images/f34e9a8ff5e9d1dd5f22f9c860ef44df.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f34e9a8ff5e9d1dd5f22f9c860ef44df.png)'
- en: Now that our RANSAC parameters are defined, we can study a first segmentation
    pass.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»å®šä¹‰äº† RANSAC å‚æ•°ï¼Œæˆ‘ä»¬å¯ä»¥ç ”ç©¶ç¬¬ä¸€æ¬¡åˆ†å‰²è¿‡ç¨‹ã€‚
- en: 5\. Point Cloud Segmentation with RANSAC
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. ä½¿ç”¨ RANSAC è¿›è¡Œç‚¹äº‘åˆ†å‰²
- en: '![](../Images/17e07a01da7ba28e3c757053c097f9b7.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/17e07a01da7ba28e3c757053c097f9b7.png)'
- en: 'Let us first set the different thresholds to non-automatic values for testing:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆå°†ä¸åŒçš„é˜ˆå€¼è®¾ç½®ä¸ºéè‡ªåŠ¨å€¼è¿›è¡Œæµ‹è¯•ï¼š
- en: '[PRE16]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'From there, we can segment the point cloud using RANSAC to detect planes with
    the following lines:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é‚£é‡Œå¼€å§‹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ RANSAC å¯¹ç‚¹äº‘è¿›è¡Œåˆ†å‰²ä»¥æ£€æµ‹å¹³é¢ï¼Œå…·ä½“å¦‚ä¸‹ï¼š
- en: '[PRE17]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We gather results in two variables: `plane_model`, which holds the parameters
    `a`,`b`,`c`,`d` of a plane, and the `inliers` as point indexes.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ç»“æœæ”¶é›†åˆ°ä¸¤ä¸ªå˜é‡ä¸­ï¼š`plane_model`ï¼Œå®ƒåŒ…å«å¹³é¢çš„å‚æ•° `a`,`b`,`c`,`d`ï¼Œä»¥åŠ `inliers` ä½œä¸ºç‚¹ç´¢å¼•ã€‚
- en: 'This allows to use the indexes to segment the point cloud in a `inlier_cloud`
    point set (that we color in red), and `outlier_cloud` point set (that we color
    in grey:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä½¿å¾—å¯ä»¥ä½¿ç”¨ç´¢å¼•å°†ç‚¹äº‘åˆ†å‰²ä¸º `inlier_cloud` ç‚¹é›†ï¼ˆæˆ‘ä»¬å°†å…¶æ ‡è®°ä¸ºçº¢è‰²ï¼‰å’Œ `outlier_cloud` ç‚¹é›†ï¼ˆæˆ‘ä»¬å°†å…¶æ ‡è®°ä¸ºç°è‰²ï¼‰ï¼š
- en: '[PRE18]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'ğŸ¦Š **Florent***: The argument* `*invert=True*` *permits to select the opposite
    of the first argument, which means all indexes not present in* `*inliers*`*. If
    you are lacking the shading, remember to compute the normals, as shown above.*'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦Š **Florent** *ï¼š`*invert=True*` *å‚æ•°å…è®¸é€‰æ‹©ç¬¬ä¸€ä¸ªå‚æ•°çš„åä¹‰ï¼Œå³æ‰€æœ‰ä¸åœ¨* `*inliers*`* ä¸­çš„ç´¢å¼•ã€‚å¦‚æœä½ ç¼ºå°‘é˜´å½±ï¼Œè®°å¾—è®¡ç®—æ³•çº¿ï¼Œå¦‚ä¸Šæ‰€ç¤ºã€‚*
- en: '![](../Images/36f15121cce1019bae4e2e1fe3e1ebcc.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/36f15121cce1019bae4e2e1fe3e1ebcc.png)'
- en: 'ğŸŒ± **Growing**: *Try and adjust the various parameters, and study the impact
    with a qualitative analysis. Remember first to decorrelate changes (one variable
    at a time); else your analysis may be biased* ğŸ˜Š.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸŒ± **æˆé•¿**ï¼š*å°è¯•è°ƒæ•´å„ç§å‚æ•°ï¼Œå¹¶é€šè¿‡å®šæ€§åˆ†æç ”ç©¶å…¶å½±å“ã€‚é¦–å…ˆè®°ä½è¦å»ç›¸å…³å˜åŒ–ï¼ˆä¸€æ¬¡ä¸€ä¸ªå˜é‡ï¼‰ï¼›å¦åˆ™ä½ çš„åˆ†æå¯èƒ½ä¼šæœ‰åå·®* ğŸ˜Šã€‚
- en: '![](../Images/385ce6263c78e78ca2ce72c1d56b7849.png)![](../Images/d0cf065a6a1ee3ea0f54091a3c00d1fb.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/385ce6263c78e78ca2ce72c1d56b7849.png)![](../Images/d0cf065a6a1ee3ea0f54091a3c00d1fb.png)'
- en: Great! You know how to segment your point cloud in an inlier point set and an
    outlier point set ğŸ¥³! Now, let us study how to find some clusters close to one
    another. So let us imagine that once we detected the big planar portions, we have
    some â€œfloatingâ€ objects that we want to delineate. How to do this? (yes, it is
    a false question, we have the answer for you ğŸ˜€)
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆæ£’ï¼ä½ çŸ¥é“å¦‚ä½•å°†ç‚¹äº‘åˆ†å‰²ä¸ºå†…ç‚¹é›†å’Œå¤–ç‚¹é›† ğŸ¥³ï¼ç°åœ¨ï¼Œè®©æˆ‘ä»¬ç ”ç©¶å¦‚ä½•æ‰¾åˆ°å½¼æ­¤æ¥è¿‘çš„ä¸€äº›ç°‡ã€‚è®©æˆ‘ä»¬æƒ³è±¡ä¸€ä¸‹ï¼Œä¸€æ—¦æˆ‘ä»¬æ£€æµ‹åˆ°å¤§çš„å¹³é¢éƒ¨åˆ†ï¼Œæˆ‘ä»¬æœ‰ä¸€äº›â€œæ¼‚æµ®â€çš„ç‰©ä½“éœ€è¦
    delineateã€‚æ€ä¹ˆåšå‘¢ï¼Ÿï¼ˆæ˜¯çš„ï¼Œè¿™æ˜¯ä¸€ä¸ªå‡é—®é¢˜ï¼Œæˆ‘ä»¬æœ‰ç­”æ¡ˆç»™ä½  ğŸ˜€ï¼‰
- en: '6\. Scaling 3D Segmentation: Multi-Order RANSAC'
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6\. æ‰©å±• 3D åˆ†å‰²ï¼šå¤šé˜¶ RANSAC
- en: '![](../Images/24389692747d404df62d0d88855514cd.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/24389692747d404df62d0d88855514cd.png)'
- en: Our philosophy will be very simple. We will first run RANSAC multiple times
    (let say `n` times) to extract the different planar regions constituting the scene.
    Then we will deal with the â€œfloating elementsâ€ through Euclidean Clustering (DBSCAN).
    It means that we have to make sure we have a way to store the results during iterations.
    Ready?
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„ç†å¿µå°†éå¸¸ç®€å•ã€‚æˆ‘ä»¬å°†é¦–å…ˆå¤šæ¬¡è¿è¡Œ RANSACï¼ˆå‡è®¾ `n` æ¬¡ï¼‰ä»¥æå–æ„æˆåœºæ™¯çš„ä¸åŒå¹³é¢åŒºåŸŸã€‚ç„¶åï¼Œæˆ‘ä»¬å°†é€šè¿‡æ¬§å‡ é‡Œå¾—èšç±»ï¼ˆDBSCANï¼‰å¤„ç†â€œæ¼‚æµ®å…ƒç´ â€ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¿…é¡»ç¡®ä¿æœ‰ä¸€ç§æ–¹æ³•åœ¨è¿­ä»£è¿‡ç¨‹ä¸­å­˜å‚¨ç»“æœã€‚å‡†å¤‡å¥½äº†å—ï¼Ÿ
- en: 'Okay, let us instantiate an empty dictionary that will hold the results of
    the iterations (the plane parameters in `segment_models`, and the planar regions
    from the point cloud in `segments`):'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œè®©æˆ‘ä»¬å®ä¾‹åŒ–ä¸€ä¸ªç©ºå­—å…¸ï¼Œä»¥ä¿å­˜è¿­ä»£ç»“æœï¼ˆ`segment_models`ä¸­çš„å¹³é¢å‚æ•°å’Œ`segments`ä¸­çš„ç‚¹äº‘å¹³é¢åŒºåŸŸï¼‰ï¼š
- en: '[PRE19]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Then, we want to make sure that we can influence later on the number of times
    we want to iterate for detecting the planes. To this end, let us create a variable
    `max_plane_idx` that holds the number of iterations:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿å¯ä»¥å½±å“ä»¥åè¿­ä»£çš„æ¬¡æ•°ï¼Œä»¥æ£€æµ‹å¹³é¢ã€‚ä¸ºæ­¤ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå˜é‡`max_plane_idx`æ¥ä¿å­˜è¿­ä»£æ¬¡æ•°ï¼š
- en: '[PRE20]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'ğŸ¦Š **Florent***: Here, we say that we want to iterate 10 times to find 10 planes,
    but there are smarter ways to define such a parameter. It actually extends the
    scope of the article and will be covered in another session.*'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦Š **Florent***ï¼šåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è¯´æˆ‘ä»¬å¸Œæœ›è¿­ä»£ 10 æ¬¡ä»¥æ‰¾åˆ° 10 ä¸ªå¹³é¢ï¼Œä½†æœ‰æ›´èªæ˜çš„æ–¹æ³•æ¥å®šä¹‰è¿™æ ·çš„å‚æ•°ã€‚è¿™å®é™…ä¸Šæ‰©å±•äº†æ–‡ç« çš„èŒƒå›´ï¼Œå°†åœ¨å¦ä¸€èŠ‚ä¸­è®¨è®ºã€‚*
- en: Now let us go into a working loopy-loopy ğŸ˜, that I will first quickly illustrate.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬è¿›å…¥ä¸€ä¸ªå·¥ä½œå¾ªç¯ ğŸ˜ï¼Œæˆ‘å°†é¦–å…ˆå¿«é€Ÿè¯´æ˜ã€‚
- en: '![](../Images/75431eb5d58c5a9972a73c461b4868ee.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75431eb5d58c5a9972a73c461b4868ee.png)'
- en: The loop to be executed to perform the segmentation within the RANSAC pass.
    Â© F. Poux
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰§è¡Œä»¥åœ¨ RANSAC è¿‡ç¨‹ä¸­è¿›è¡Œåˆ†å‰²çš„å¾ªç¯ã€‚Â© F. Poux
- en: 'In the first pass (loop `i=0`), we separate the inliers from the outliers.
    We store the inliers in `segments`, and then we want to pursue with only the remaining
    points stored in `rest`, that becomes the subject of interest for the loop n+1
    (loop `i=1`). That means that we want to consider the outliers from the previous
    step as the base point cloud until reaching the above threshold of iterations
    (not to be confused with RANSAC iterations). This translates into the following:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£ï¼ˆå¾ªç¯`i=0`ï¼‰ä¸­ï¼Œæˆ‘ä»¬å°†å†…ç‚¹ä¸å¤–ç‚¹åˆ†å¼€ã€‚æˆ‘ä»¬å°†å†…ç‚¹å­˜å‚¨åœ¨`segments`ä¸­ï¼Œç„¶åæˆ‘ä»¬åªå¯¹å­˜å‚¨åœ¨`rest`ä¸­çš„å‰©ä½™ç‚¹æ„Ÿå…´è¶£ï¼Œè¿™å°†æˆä¸ºå¾ªç¯
    n+1ï¼ˆå¾ªç¯`i=1`ï¼‰çš„ç ”ç©¶å¯¹è±¡ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¸Œæœ›å°†ä¸Šä¸€é˜¶æ®µçš„å¤–ç‚¹ä½œä¸ºåŸºç¡€ç‚¹äº‘ï¼Œç›´åˆ°è¾¾åˆ°ä¸Šè¿°çš„è¿­ä»£é˜ˆå€¼ï¼ˆä¸ RANSAC è¿­ä»£ä¸åŒï¼‰ã€‚è¿™è½¬åŒ–ä¸ºä»¥ä¸‹å†…å®¹ï¼š
- en: '[PRE21]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'And that is pretty much it! Now, for visualizing the ensemble, as we paint
    each segment detected with a color from `tab20` through the first line in the
    loop (`colors = plt.get_cmap("tab20")(i)`), you just need to write:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: å°±æ˜¯è¿™æ ·ï¼ç°åœ¨ï¼Œä¸ºäº†å¯è§†åŒ–æ•´ä½“ï¼Œæˆ‘ä»¬é€šè¿‡å¾ªç¯ä¸­çš„ç¬¬ä¸€è¡Œå°†æ¯ä¸ªæ£€æµ‹åˆ°çš„åˆ†æ®µæ¶‚ä¸Šæ¥è‡ª`tab20`çš„é¢œè‰²ï¼ˆ`colors = plt.get_cmap("tab20")(i)`ï¼‰ï¼Œä½ åªéœ€å†™ï¼š
- en: '[PRE22]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ğŸ¦š **Note***:* The list `[segments[i] for i in range(max_plane_idx)]` that we
    pass to the function `o3d.visualization.draw_geometries()` is actually a â€œlist
    comprehensionâ€ ğŸ¤”. It is equivalent to writing a `for` loop that appends the first
    element `segments[i]` to a list. Conveniently, we can then add the `[rest]` to
    this list and the `draw.geometries()` method will understand we want to consider
    one point cloud to draw. How cool is that?
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼šæˆ‘ä»¬ä¼ é€’ç»™å‡½æ•°`o3d.visualization.draw_geometries()`çš„åˆ—è¡¨`[segments[i] for i
    in range(max_plane_idx)]`å®é™…ä¸Šæ˜¯ä¸€ä¸ªâ€œåˆ—è¡¨æ¨å¯¼å¼â€ğŸ¤”ã€‚å®ƒç­‰åŒäºç¼–å†™ä¸€ä¸ª`for`å¾ªç¯ï¼Œå°†ç¬¬ä¸€ä¸ªå…ƒç´ `segments[i]`è¿½åŠ åˆ°åˆ—è¡¨ä¸­ã€‚æ–¹ä¾¿çš„æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥å°†`[rest]`æ·»åŠ åˆ°è¿™ä¸ªåˆ—è¡¨ä¸­ï¼Œ`draw.geometries()`æ–¹æ³•ä¼šç†è§£æˆ‘ä»¬æƒ³è¦ç»˜åˆ¶ä¸€ä¸ªç‚¹äº‘ã€‚è¿™ä¸æ˜¯å¾ˆé…·å—ï¼Ÿ
- en: '![](../Images/149829534a11885af97f3ff19dea8f8f.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/149829534a11885af97f3ff19dea8f8f.png)'
- en: The result of the DBSCAN first pass on the 3D Point Cloud
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: DBSCANå¯¹3Dç‚¹äº‘çš„ç¬¬ä¸€æ¬¡æ‰«æç»“æœ
- en: Ha! We think we are doneâ€¦ But are we? Do you notice something strange here?
    If you look closely, there are some strange artifacts, like â€œred lines/planesâ€
    that actually cut some planar elements. Why? ğŸ§
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: å“ˆï¼æˆ‘ä»¬ä»¥ä¸ºå®Œæˆäº†â€¦â€¦ä½†æˆ‘ä»¬çœŸçš„å®Œæˆäº†å—ï¼Ÿä½ æ³¨æ„åˆ°è¿™é‡Œæœ‰ä»€ä¹ˆå¥‡æ€ªçš„åœ°æ–¹å—ï¼Ÿå¦‚æœä½ ä»”ç»†çœ‹ï¼Œä¼šå‘ç°ä¸€äº›å¥‡æ€ªçš„ä¼ªå½±ï¼Œæ¯”å¦‚å®é™…åˆ‡å‰²ä¸€äº›å¹³é¢å…ƒç´ çš„â€œçº¢è‰²çº¿æ¡/å¹³é¢â€ã€‚ä¸ºä»€ä¹ˆï¼ŸğŸ§
- en: '![](../Images/1c67e5140011a746f7e66524ef332420.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1c67e5140011a746f7e66524ef332420.png)'
- en: In fact, because we fit all the points to RANSAC plane candidates (which have
    no limit extent in the Euclidean space) independently of the point's density continuity,
    then we have these â€œlinesâ€ artifacts depending on the order in which the planes
    are detected. So the next step is to prevent such behavior! For this, I propose
    to include in the iterative process a condition based on Euclidean clustering
    to refine inlier point sets in contiguous clusters. To this end, we will rely
    on the DBSCAN algorithm.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šï¼Œç”±äºæˆ‘ä»¬å°†æ‰€æœ‰ç‚¹æ‹Ÿåˆåˆ°RANSACå¹³é¢å€™é€‰è€…ï¼ˆåœ¨æ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­æ²¡æœ‰é™åˆ¶èŒƒå›´ï¼‰è€Œä¸è€ƒè™‘ç‚¹çš„å¯†åº¦è¿ç»­æ€§ï¼Œå› æ­¤æ ¹æ®å¹³é¢çš„æ£€æµ‹é¡ºåºï¼Œæˆ‘ä»¬ä¼šå‡ºç°è¿™äº›â€œçº¿â€ä¼ªå½±ã€‚æ‰€ä»¥ä¸‹ä¸€æ­¥æ˜¯é˜²æ­¢è¿™ç§è¡Œä¸ºï¼ä¸ºæ­¤ï¼Œæˆ‘å»ºè®®åœ¨è¿­ä»£è¿‡ç¨‹ä¸­åŒ…å«ä¸€ä¸ªåŸºäºæ¬§å‡ é‡Œå¾—èšç±»çš„æ¡ä»¶ï¼Œä»¥åœ¨è¿ç»­çš„ç°‡ä¸­ç»†åŒ–å†…ç‚¹é›†ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä¾èµ–äºDBSCANç®—æ³•ã€‚
- en: Euclidean Clustering (DBSCAN)
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¬§å‡ é‡Œå¾—èšç±»ï¼ˆDBSCANï¼‰
- en: With point cloud datasets, we often need to group sets of points spatially contiguous
    (i.e. that are physically close or adjacent to each other in 3D space), as illustrated
    below. But how can we do this efficiently?
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç‚¹äº‘æ•°æ®é›†ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸éœ€è¦å°†ç©ºé—´ä¸Šè¿ç»­çš„ç‚¹é›†åˆï¼ˆå³åœ¨3Dç©ºé—´ä¸­ç‰©ç†ä¸Šæ¥è¿‘æˆ–ç›¸é‚»ï¼‰è¿›è¡Œåˆ†ç»„ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚ä½†æˆ‘ä»¬å¦‚ä½•æœ‰æ•ˆåœ°åšåˆ°è¿™ä¸€ç‚¹å‘¢ï¼Ÿ
- en: '![](../Images/2d3ff3a05173c7b35dfab22f6883f9a2.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2d3ff3a05173c7b35dfab22f6883f9a2.png)'
- en: In this image, it seems obvious that we want to group points that are closed
    to one another, finding 5 sets of points. Â© F. Poux
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™å¼ å›¾ä¸­ï¼Œå¾ˆæ˜æ˜¾æˆ‘ä»¬æƒ³è¦å°†å½¼æ­¤æ¥è¿‘çš„ç‚¹åˆ†ç»„ï¼Œæ‰¾åˆ°5ç»„ç‚¹ã€‚Â© F. Poux
- en: The DBSCAN (Density-Based Spatial Clustering of Applications with Noise) algorithm
    was introduced in 1996 for this purpose. This algorithm is widely used, which
    is why it was awarded a scientific contribution award in 2014 that has stood the
    test of time.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: DBSCANï¼ˆåŸºäºå¯†åº¦çš„ç©ºé—´èšç±»åº”ç”¨ä¸å™ªå£°ï¼‰ç®—æ³•äº1996å¹´ä¸ºæ­¤ç›®çš„è€Œæå‡ºã€‚è¯¥ç®—æ³•è¢«å¹¿æ³›ä½¿ç”¨ï¼Œå› æ­¤åœ¨2014å¹´è·å¾—äº†ç»å¾—èµ·æ—¶é—´è€ƒéªŒçš„ç§‘å­¦è´¡çŒ®å¥–ã€‚
- en: The DBSCAN algorithm involves scanning through each point in the dataset and
    constructing a set of reachable points based on density. This is achieved by analyzing
    the neighborhood of each point and including it in the region if it contains enough
    points. The process is repeated for each neighboring point until the cluster can
    no longer expand. Points that do not have enough neighbors are labeled as noise,
    making the algorithm robust to outliers. Itâ€™s pretty impressive, isnâ€™t it? ğŸ˜†
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: DBSCANç®—æ³•æ¶‰åŠæ‰«ææ•°æ®é›†ä¸­çš„æ¯ä¸ªç‚¹ï¼Œå¹¶åŸºäºå¯†åº¦æ„å»ºä¸€ä¸ªå¯è¾¾ç‚¹é›†åˆã€‚è¿™æ˜¯é€šè¿‡åˆ†ææ¯ä¸ªç‚¹çš„é‚»åŸŸå¹¶åœ¨å…¶åŒ…å«è¶³å¤Ÿç‚¹æ—¶å°†å…¶åŒ…å«åœ¨åŒºåŸŸå†…æ¥å®ç°çš„ã€‚è¿™ä¸ªè¿‡ç¨‹å¯¹æ¯ä¸ªé‚»è¿‘ç‚¹é‡å¤ï¼Œç›´åˆ°ç°‡æ— æ³•å†æ‰©å±•ã€‚æ²¡æœ‰è¶³å¤Ÿé‚»å±…çš„ç‚¹è¢«æ ‡è®°ä¸ºå™ªå£°ï¼Œä½¿å¾—è¯¥ç®—æ³•å¯¹ç¦»ç¾¤ç‚¹å…·æœ‰é²æ£’æ€§ã€‚è¿™ä¸æ˜¯å¾ˆä»¤äººå°è±¡æ·±åˆ»å—ï¼ŸğŸ˜†
- en: '![](../Images/5f884ed20535463901f44913fbc652f1.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5f884ed20535463901f44913fbc652f1.png)'
- en: Illustration of the DBSCAN algorithm process and influence of the two parameters
    Ïµ and min_points on the results. You can see that the bigger the value, the fewer
    clusters are constituted. Â© F. Poux
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: DBSCANç®—æ³•è¿‡ç¨‹å’Œä¸¤ä¸ªå‚æ•°Ïµå’Œmin_pointså¯¹ç»“æœçš„å½±å“çš„ç¤ºæ„å›¾ã€‚ä½ å¯ä»¥çœ‹åˆ°ï¼Œå€¼è¶Šå¤§ï¼Œç»„æˆçš„ç°‡å°±è¶Šå°‘ã€‚Â© F. Poux
- en: 'Ah, we almost forgot. The choice of parameters (Ïµ for the neighborhood and
    n_min for the minimal number of points) can also be tricky: One must take great
    care when setting parameters to create enough interior points (which will not
    happen if n_min is too large or Ïµ too small). In particular, this means that DBSCAN
    will have trouble finding clusters of different densities. BUT, DBSCAN has the
    great advantage of being computationally efficient without requiring to predefine
    the number of clusters, unlike Kmeans, for example. Finally, it allows for finding
    clusters of arbitrary shapes. We are now ready to dive in the parameter dark side
    of things ğŸ’»'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: å•Šï¼Œæˆ‘ä»¬å·®ç‚¹å¿˜äº†ã€‚å‚æ•°é€‰æ‹©ï¼ˆÏµç”¨äºé‚»åŸŸï¼Œn_minç”¨äºæœ€å°ç‚¹æ•°ï¼‰ä¹Ÿå¯èƒ½å¾ˆæ£˜æ‰‹ï¼šè®¾ç½®å‚æ•°æ—¶å¿…é¡»å°å¿ƒï¼Œä»¥ç¡®ä¿åˆ›å»ºè¶³å¤Ÿçš„å†…éƒ¨ç‚¹ï¼ˆå¦‚æœn_minå¤ªå¤§æˆ–Ïµå¤ªå°ï¼Œå°±ä¸ä¼šå‘ç”Ÿï¼‰ã€‚ç‰¹åˆ«æ˜¯ï¼Œè¿™æ„å‘³ç€DBSCANåœ¨å‘ç°ä¸åŒå¯†åº¦çš„ç°‡æ—¶ä¼šé‡åˆ°å›°éš¾ã€‚ä½†DBSCANæœ‰ä¸€ä¸ªå¾ˆå¤§çš„ä¼˜åŠ¿ï¼Œå°±æ˜¯è®¡ç®—æ•ˆç‡é«˜ï¼Œä¸éœ€è¦åƒKmeansé‚£æ ·é¢„å®šä¹‰ç°‡çš„æ•°é‡ã€‚æœ€åï¼Œå®ƒå…è®¸å‘ç°ä»»æ„å½¢çŠ¶çš„ç°‡ã€‚ç°åœ¨æˆ‘ä»¬å‡†å¤‡æ·±å…¥æ¢è®¨å‚æ•°çš„é»‘æš—é¢
    ğŸ’»
- en: DBSCAN for 3D Point Cloud Clustering
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DBSCANç”¨äº3Dç‚¹äº‘èšç±»
- en: 'Let me detail the logical process (Activate the beast modeğŸ‘¹). First, we need
    to define the parameters to run DBSCAN:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘è¯¦ç»†è¯´æ˜é€»è¾‘è¿‡ç¨‹ï¼ˆæ¿€æ´»çŒ›å…½æ¨¡å¼ğŸ‘¹ï¼‰ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰è¿è¡ŒDBSCANçš„å‚æ•°ï¼š
- en: '[PRE23]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'ğŸŒ± **Growing**: *The definition of these parameters is something to explore.
    You have to find a way to balance over-segmentation and under-segmentation problematics.
    Eventually, you can use some heuristics determination based on the initial distance
    definition of RANSAC. Something to explore* ğŸ˜‰.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸŒ± **æˆé•¿**ï¼š*è¿™äº›å‚æ•°çš„å®šä¹‰æ˜¯ä¸€ä¸ªéœ€è¦æ¢ç´¢çš„é—®é¢˜ã€‚ä½ å¿…é¡»æ‰¾åˆ°ä¸€ç§æ–¹æ³•æ¥å¹³è¡¡è¿‡åº¦åˆ†å‰²å’Œä¸è¶³åˆ†å‰²çš„é—®é¢˜ã€‚æœ€ç»ˆï¼Œä½ å¯ä»¥åŸºäºRANSACçš„åˆå§‹è·ç¦»å®šä¹‰ä½¿ç”¨ä¸€äº›å¯å‘å¼æ–¹æ³•ã€‚è¿™æ˜¯ä¸€ä¸ªå€¼å¾—æ¢ç´¢çš„æ–¹é¢*
    ğŸ˜‰ã€‚
- en: 'Within the for loop that we defined before, we will run DBSCAN just after the
    assignment of the inliers (`segments[i]=rest.select_by_index(inliers)`), by adding
    the following line right after:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬ä¹‹å‰å®šä¹‰çš„forå¾ªç¯ä¸­ï¼Œæˆ‘ä»¬å°†åœ¨åˆ†é…å†…ç‚¹ï¼ˆ`segments[i]=rest.select_by_index(inliers)`ï¼‰åç«‹å³è¿è¡ŒDBSCANï¼Œæ–¹æ³•æ˜¯ç´§æ¥ç€æ·»åŠ ä»¥ä¸‹ä¸€è¡Œï¼š
- en: '[PRE24]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Then, we will count how many points each cluster that we found holds, using
    a weird notation that makes use of a list comprehension. The result is then stored
    in the variable `candidates`:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬å°†è®¡ç®—æ¯ä¸ªæ‰¾åˆ°çš„ç°‡åŒ…å«å¤šå°‘ä¸ªç‚¹ï¼Œä½¿ç”¨ä¸€ç§å¥‡æ€ªçš„ç¬¦å·è¡¨ç¤ºæ³•ï¼Œè¯¥è¡¨ç¤ºæ³•åˆ©ç”¨äº†åˆ—è¡¨æ¨å¯¼ã€‚ç»“æœå­˜å‚¨åœ¨å˜é‡`candidates`ä¸­ï¼š
- en: '[PRE25]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'And now? We have to find the â€œbest candidateâ€, which is normally the cluster
    that holds the more points! And for this, here is the line:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ç°åœ¨å‘¢ï¼Ÿæˆ‘ä»¬éœ€è¦æ‰¾åˆ°â€œæœ€ä½³å€™é€‰è€…â€ï¼Œé€šå¸¸æ˜¯åŒ…å«æœ€å¤šç‚¹çš„ç°‡ï¼ä¸ºæ­¤ï¼Œè¿™é‡Œæ˜¯è¿™è¡Œä»£ç ï¼š
- en: '[PRE26]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Okay, many tricks are happening under the hood here, but essentially, we use
    our Numpy proficiency to search and return the index of the points that belong
    to the biggest cluster. From here, it is downhill skiing, and we just need to
    ensure that we include any remaining clusters from each iteration for consideration
    in subsequent RANSAC iterations (ğŸ”¥ recommendation to to read 5 times the sentence
    to digest!):'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ï¼Œå¾ˆå¤šæŠ€å·§åœ¨è¿™é‡Œå‘ç”Ÿï¼Œä½†æœ¬è´¨ä¸Šï¼Œæˆ‘ä»¬åˆ©ç”¨Numpyçš„ç†Ÿç»ƒåº¦æ¥æœç´¢å¹¶è¿”å›å±äºæœ€å¤§ç°‡çš„ç‚¹çš„ç´¢å¼•ã€‚ä»è¿™é‡Œå¼€å§‹ï¼Œæ¥ä¸‹æ¥çš„è¿‡ç¨‹å°±ç®€å•äº†ï¼Œæˆ‘ä»¬åªéœ€ç¡®ä¿åœ¨æ¯æ¬¡è¿­ä»£ä¸­å°†ä»»ä½•å‰©ä½™ç°‡çº³å…¥åç»­RANSACè¿­ä»£ä¸­ï¼ˆğŸ”¥
    æ¨èé˜…è¯»5éä»¥æ¶ˆåŒ–ï¼ï¼‰ï¼š
- en: '[PRE27]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'ğŸ¦š **Note***: the* `rest` *variable now makes sure to hold both the remaining
    points from RANSAC and DBSCAN. And of course, the inliers are now filtered to
    the biggest cluster present in the raw RANSAC inlier set*.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*`rest`* å˜é‡ç°åœ¨ç¡®ä¿åŒ…å«RANSACå’ŒDBSCANå‰©ä½™çš„ç‚¹ã€‚å½“ç„¶ï¼Œå†…ç‚¹ç°åœ¨è¢«ç­›é€‰ä¸ºåŸå§‹RANSACå†…ç‚¹é›†ä¸­æœ€å¤§çš„ç°‡*ã€‚
- en: 'When the loop is over, you get a clean set of segments holding spatially contiguous
    point sets that follow planar shapes, that you can visualize with different colors
    using the following lines of code in the loop:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å¾ªç¯ç»“æŸæ—¶ï¼Œä½ ä¼šå¾—åˆ°ä¸€ç»„å¹²å‡€çš„æ®µï¼Œè¿™äº›æ®µåŒ…å«ç©ºé—´ä¸Šè¿ç»­çš„ç‚¹é›†ï¼Œç¬¦åˆå¹³é¢å½¢çŠ¶ï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç è¡Œä»¥ä¸åŒé¢œè‰²å¯è§†åŒ–ï¼š
- en: '[PRE28]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The results should be something similar to this:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœåº”è¯¥ç±»ä¼¼äºè¿™ä¸ªï¼š
- en: '![](../Images/e91a792806f2bc948d988ded50f423c9.png)![](../Images/111103f10b8da9050953ae4423df66d6.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e91a792806f2bc948d988ded50f423c9.png)![](../Images/111103f10b8da9050953ae4423df66d6.png)'
- en: But is this the end? Noooo, never ğŸ˜„! Once the multi-order RANSAC segmentation
    has been applied to the point cloud, the next stage involves refining the remaining
    non-segmented points through the utilization of DBSCAN, which aids in further
    enhancing the granularity of the point cloud analysis with additional clusters.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™å°±ç»“æŸäº†å—ï¼Ÿä¸ï¼Œä¸å¯èƒ½çš„ ğŸ˜„ï¼ä¸€æ—¦å¯¹ç‚¹äº‘åº”ç”¨äº†å¤šé˜¶RANSACåˆ†å‰²ï¼Œä¸‹ä¸€é˜¶æ®µå°±æ˜¯é€šè¿‡åˆ©ç”¨DBSCANæ¥ç»†åŒ–å‰©ä½™çš„æœªåˆ†å‰²ç‚¹ï¼Œè¿™æœ‰åŠ©äºè¿›ä¸€æ­¥æå‡ç‚¹äº‘åˆ†æçš„ç²’åº¦ï¼Œå¢åŠ æ›´å¤šçš„ç°‡ã€‚
- en: 'ğŸ¦š **Note**: *Granularity is a useful academic word that is used a lot in data
    science. The granularity of data means the level of detail in how it is organized
    or modeled. Here, the smaller objects we can model from the point cloud, the finer
    granularity our representation has. (fancy, right?!)*'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*ç²’åº¦æ˜¯ä¸€ä¸ªåœ¨æ•°æ®ç§‘å­¦ä¸­ç»å¸¸ä½¿ç”¨çš„å­¦æœ¯è¯æ±‡ã€‚æ•°æ®çš„ç²’åº¦æ„å‘³ç€æ•°æ®ç»„ç»‡æˆ–å»ºæ¨¡çš„è¯¦ç»†ç¨‹åº¦ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥ä»ç‚¹äº‘ä¸­å»ºæ¨¡çš„å¯¹è±¡è¶Šå°ï¼Œæˆ‘ä»¬çš„è¡¨ç¤ºçš„ç²’åº¦å°±è¶Šç»†ã€‚ï¼ˆå¾ˆé«˜å¤§ä¸Šï¼Œå¯¹å§ï¼Ÿï¼ï¼‰*
- en: 7\. Euclidean Clustering Refinement
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7\. æ¬§å‡ é‡Œå¾—èšç±»ç²¾ç‚¼
- en: '![](../Images/664bd457a80f786f5d09aa8239aaeca7.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/664bd457a80f786f5d09aa8239aaeca7.png)'
- en: 'Okay, time to evade the loop, and work on the remaining points assigned to
    the`rest` variable, that are not yet attributed to any segment. Let us first get
    a visual grasp on what we are talking about:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½äº†ï¼Œæ˜¯æ—¶å€™æ‘†è„±å¾ªç¯ï¼Œå¤„ç†åˆ†é…ç»™ `rest` å˜é‡çš„å‰©ä½™ç‚¹ï¼Œè¿™äº›ç‚¹å°šæœªåˆ†é…ç»™ä»»ä½•æ®µã€‚è®©æˆ‘ä»¬é¦–å…ˆå¯¹æˆ‘ä»¬è®¨è®ºçš„å†…å®¹æœ‰ä¸€ä¸ªè§†è§‰ä¸Šçš„äº†è§£ï¼š
- en: '[PRE29]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '![](../Images/76fdada74949c1d91e41829464bb87af.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/76fdada74949c1d91e41829464bb87af.png)'
- en: 'We can apply a simple pass of Euclidean clustering with DBSCAN and capture
    the results in a `labels` variable. You know the drill:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ DBSCAN è¿›è¡Œç®€å•çš„æ¬§å‡ é‡Œå¾—èšç±»ï¼Œå¹¶å°†ç»“æœæ•è·åˆ°ä¸€ä¸ª `labels` å˜é‡ä¸­ã€‚ä½ çŸ¥é“æ€ä¹ˆåšçš„ï¼š
- en: '[PRE30]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: ğŸŒ± **Growing:** *We use a radius of 10 cm for â€œgrowingâ€ clusters and consider
    one only if, after this step, we have at least 10 points. But is this the right
    choice?* ğŸ¤”*Feel free to experiment to find a good balance and, ideally, a way
    to automate this*ğŸ˜€.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸŒ± **ç”Ÿé•¿ï¼š** *æˆ‘ä»¬ä½¿ç”¨ 10 cm çš„åŠå¾„æ¥â€œç”Ÿé•¿â€ç°‡ï¼Œåªæœ‰åœ¨æ­¤æ­¥éª¤ä¹‹åè‡³å°‘æœ‰ 10 ä¸ªç‚¹æ—¶æ‰è€ƒè™‘ä¸€ä¸ªç°‡ã€‚ä½†è¿™æ˜¯æ­£ç¡®çš„é€‰æ‹©å—ï¼Ÿ* ğŸ¤”*å¯ä»¥éšæ„å®éªŒä»¥æ‰¾åˆ°ä¸€ä¸ªå¥½çš„å¹³è¡¡ç‚¹ï¼Œç†æƒ³æƒ…å†µä¸‹ï¼Œæ‰¾åˆ°ä¸€ç§è‡ªåŠ¨åŒ–çš„æ–¹æ³•*ğŸ˜€ã€‚
- en: The labels vary between `-1` and `n`, where `-1` indicate it is a â€œnoiseâ€ point
    and values `0` to `n` are then the cluster labels given to the corresponding point.
    Note that we want to get the labels as a NumPy array thereafter.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: æ ‡ç­¾çš„èŒƒå›´åœ¨ `-1` å’Œ `n` ä¹‹é—´ï¼Œå…¶ä¸­ `-1` è¡¨ç¤ºâ€œå™ªå£°â€ç‚¹ï¼Œ`0` åˆ° `n` çš„å€¼åˆ™æ˜¯åˆ†é…ç»™ç›¸åº”ç‚¹çš„ç°‡æ ‡ç­¾ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬å¸Œæœ›å°†æ ‡ç­¾ä½œä¸º
    NumPy æ•°ç»„è·å–ã€‚
- en: '![](../Images/3eb8a5f384d733521bb73466db0acea9.png)![](../Images/4f479ccf0472670ad4b5a84553201700.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3eb8a5f384d733521bb73466db0acea9.png)![](../Images/4f479ccf0472670ad4b5a84553201700.png)'
- en: 'On the left: parameters are not well defined. On the right, we have a better
    delineation of objects for downward processes.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: å·¦ä¾§ï¼šå‚æ•°å®šä¹‰ä¸ä½³ã€‚å³ä¾§ï¼Œæˆ‘ä»¬å¯¹ç‰©ä½“çš„è½®å»“æœ‰äº†æ›´å¥½çš„åˆ’åˆ†ï¼Œä»¥ä¾¿è¿›è¡Œåç»­å¤„ç†ã€‚
- en: 'Nice. Now that we have groups of points defined with a label per point, let
    us color the results. This is optional, but it is handy for iterative processes
    to search for the right parameterâ€™s values. To this end, we propose to use the
    Matplotlib library to get specific [color ranges](https://matplotlib.org/stable/tutorials/colors/colormaps.html),
    such as the tab20:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå¥½ã€‚ç°åœ¨æˆ‘ä»¬å·²ç»å®šä¹‰äº†æ¯ä¸ªç‚¹çš„æ ‡ç­¾ç»„ï¼Œè®©æˆ‘ä»¬ä¸ºç»“æœç€è‰²ã€‚è¿™æ˜¯å¯é€‰çš„ï¼Œä½†å¯¹äºè¿­ä»£è¿‡ç¨‹ä»¥æœç´¢åˆé€‚çš„å‚æ•°å€¼éå¸¸æœ‰ç”¨ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨ Matplotlib
    åº“è·å–ç‰¹å®šçš„[é¢œè‰²èŒƒå›´](https://matplotlib.org/stable/tutorials/colors/colormaps.html)ï¼Œä¾‹å¦‚
    tab20ï¼š
- en: '[PRE31]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'ğŸ¦š **Note***: The* `max_label` *should be intuitive: it stores the maximal value
    in the labels list. This permits to use it as a denominator for the coloring scheme
    while treating with an â€œ*`if`*â€ statement the special case where the clustering
    is skewed and delivers only noise + one cluster. After, we make sure to set these
    noisy points with the label* `-1` *to black* (`0`). *Then, we give to the attribute*
    `colors` *of the point cloud* `pcd` *the 2D NumPy array of 3 â€œcolumnsâ€, representing
    R, G, B.*'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*`max_label`* *åº”è¯¥æ˜¯ç›´è§‚çš„ï¼šå®ƒå­˜å‚¨æ ‡ç­¾åˆ—è¡¨ä¸­çš„æœ€å¤§å€¼ã€‚è¿™å…è®¸å°†å…¶ç”¨ä½œç€è‰²æ–¹æ¡ˆçš„åˆ†æ¯ï¼ŒåŒæ—¶å¤„ç†ä¸€ä¸ªç‰¹æ®Šæƒ…å†µï¼Œå…¶ä¸­èšç±»è¢«æ‰­æ›²ï¼Œä»…äº§ç”Ÿå™ªå£°+ä¸€ä¸ªç°‡ã€‚ä¹‹åï¼Œæˆ‘ä»¬ç¡®ä¿å°†è¿™äº›å™ªå£°ç‚¹çš„æ ‡ç­¾è®¾ç½®ä¸º*
    `-1` *ï¼ˆé»‘è‰²*ï¼ˆ`0`ï¼‰*ï¼‰ã€‚*ç„¶åï¼Œæˆ‘ä»¬å°†ç‚¹äº‘* `pcd` *çš„* `colors` *å±æ€§è®¾ç½®ä¸ºè¡¨ç¤º Rã€Gã€B çš„ 3 åˆ—çš„ 2D NumPy
    æ•°ç»„ã€‚*
- en: Et voilÃ ! I employ the same methodology as before, no sorcery! I just make sure
    to use coherent parameters to have a refined clustering to get the beautiful rainbow
    scene you always dreamed of ğŸ¥³!
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: å°±è¿™æ ·ï¼æˆ‘é‡‡ç”¨äº†ä¸ä¹‹å‰ç›¸åŒçš„æ–¹æ³•ï¼Œæ²¡æœ‰ä»»ä½•é­”æ³•ï¼æˆ‘åªæ˜¯ç¡®ä¿ä½¿ç”¨ä¸€è‡´çš„å‚æ•°æ¥è¿›è¡Œç²¾ç»†çš„èšç±»ï¼Œä»¥è·å¾—ä½ ä¸€ç›´æ¢¦æƒ³çš„ç¾ä¸½å½©è™¹åœºæ™¯ ğŸ¥³ï¼
- en: '![](../Images/0e7ebe11fc52adac83a2b93374501062.png)![](../Images/727dec15d27cdf31f1fcf08a86dd71b1.png)![](../Images/a4fd6c629333ca0ddd5943b6fd1c602b.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0e7ebe11fc52adac83a2b93374501062.png)![](../Images/727dec15d27cdf31f1fcf08a86dd71b1.png)![](../Images/a4fd6c629333ca0ddd5943b6fd1c602b.png)'
- en: After refining the point cloud clustering results using DBSCAN, the focus shifts
    to the voxelization technique, which involves organizing the data into a meaningful
    spatial structure, thereby enabling efficient modeling of the point cloud information.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä½¿ç”¨ DBSCAN ç²¾ç‚¼ç‚¹äº‘èšç±»ç»“æœä¹‹åï¼Œç„¦ç‚¹è½¬å‘ä½“ç´ åŒ–æŠ€æœ¯ï¼Œè¿™æ¶‰åŠå°†æ•°æ®ç»„ç»‡æˆæœ‰æ„ä¹‰çš„ç©ºé—´ç»“æ„ï¼Œä»è€Œå®ç°å¯¹ç‚¹äº‘ä¿¡æ¯çš„é«˜æ•ˆå»ºæ¨¡ã€‚
- en: 8\. Voxelization and Labelling
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8\. ä½“ç´ åŒ–å’Œæ ‡è®°
- en: '![](../Images/b83044b78cead7000efc9944696472ca.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b83044b78cead7000efc9944696472ca.png)'
- en: Now that we have a point cloud with segment labels, it would be very interesting
    to see if we could fit indoor modeling workflows. One way to approach this is
    the use of voxels to accommodate for O-Space and R-Space. By dividing a point
    cloud into small cubes, it becomes easier to understand a model's occupied and
    empty spaces. Let us get into it.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰äº†ä¸€ä¸ªå¸¦æœ‰åˆ†æ®µæ ‡ç­¾çš„ç‚¹äº‘ï¼ŒæŸ¥çœ‹æˆ‘ä»¬æ˜¯å¦èƒ½é€‚åº”å®¤å†…å»ºæ¨¡å·¥ä½œæµå°†ä¼šéå¸¸æœ‰è¶£ã€‚ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨ä½“ç´ æ¥é€‚åº”O-Spaceå’ŒR-Spaceã€‚é€šè¿‡å°†ç‚¹äº‘åˆ’åˆ†ä¸ºå°ç«‹æ–¹ä½“ï¼Œå¯ä»¥æ›´å®¹æ˜“åœ°ç†è§£æ¨¡å‹çš„å ç”¨å’Œç©ºç™½ç©ºé—´ã€‚è®©æˆ‘ä»¬æ·±å…¥äº†è§£ä¸€ä¸‹ã€‚
- en: 9.1\. Voxel Grid Generation
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.1\. ä½“ç´ ç½‘æ ¼ç”Ÿæˆ
- en: Creating accurate and detailed 3D models of the space means generating a nice
    and tight voxel grid. This technique divides a point cloud into small cubes or
    voxels with their own coordinate system.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ›å»ºå‡†ç¡®ä¸”è¯¦ç»†çš„ç©ºé—´3Dæ¨¡å‹æ„å‘³ç€ç”Ÿæˆä¸€ä¸ªç´§å‡‘çš„ä½“ç´ ç½‘æ ¼ã€‚è¿™ç§æŠ€æœ¯å°†ç‚¹äº‘åˆ’åˆ†ä¸ºå…·æœ‰è‡ªå·±åæ ‡ç³»ç»Ÿçš„å°ç«‹æ–¹ä½“æˆ–ä½“ç´ ã€‚
- en: '![](../Images/6ddeb653af9fa95611230f33d792e393.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6ddeb653af9fa95611230f33d792e393.png)'
- en: Voxel Grid Generation to structure the 3D Point Cloud with the segment information.
    Â© F. Poux
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: ä½“ç´ ç½‘æ ¼ç”Ÿæˆä»¥ç»“æ„åŒ–å¸¦æœ‰åˆ†æ®µä¿¡æ¯çš„3Dç‚¹äº‘ã€‚Â© F. Poux
- en: 'To create such a structure, we first define the size of our new entity: the
    voxel:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åˆ›å»ºè¿™æ ·çš„ç»“æ„ï¼Œæˆ‘ä»¬é¦–å…ˆå®šä¹‰æˆ‘ä»¬æ–°å®ä½“çš„å¤§å°ï¼šä½“ç´ ï¼š
- en: '[PRE32]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Now, we want to know how many of these cubes we must stack onto one another
    to fill the bounding box defined by our point cloud. This means that we have first
    to compute the extent of our point cloud:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬æƒ³çŸ¥é“æˆ‘ä»¬éœ€è¦å †å å¤šå°‘ä¸ªè¿™æ ·çš„ç«‹æ–¹ä½“æ‰èƒ½å¡«å……ç”±ç‚¹äº‘å®šä¹‰çš„è¾¹ç•Œæ¡†ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬é¦–å…ˆéœ€è¦è®¡ç®—ç‚¹äº‘çš„èŒƒå›´ï¼š
- en: '[PRE33]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Great, now we use the `o3d.geometry.VoxelGrid.create_from_point_cloud()` function
    onto any point cloud of choice to fit a voxel grid on it. but wait. Which point
    cloud do we want to distinguish for further processes?
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå¥½ï¼Œç°åœ¨æˆ‘ä»¬ä½¿ç”¨`o3d.geometry.VoxelGrid.create_from_point_cloud()`å‡½æ•°å¯¹ä»»ä½•é€‰æ‹©çš„ç‚¹äº‘è¿›è¡Œæ“ä½œï¼Œä»¥ä¾¿åœ¨å…¶ä¸Šæ‹Ÿåˆä½“ç´ ç½‘æ ¼ã€‚ä½†æ˜¯ç­‰ç­‰ï¼Œæˆ‘ä»¬æƒ³åŒºåˆ†å“ªä¸ªç‚¹äº‘ä»¥ä¾¿è¿›ä¸€æ­¥å¤„ç†ï¼Ÿ
- en: 'Okay, let us illustrate the case where you want to have voxels of â€œstructuralâ€
    elements vs voxels of clutter that do not belong to structural elements. Without
    labeling, we could guide our choice based on whether or not they belong to RANSAC
    segments or other segments; This means first concatenating the segments from the
    RANSAC pass:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œè®©æˆ‘ä»¬ä¸¾ä¾‹è¯´æ˜ä½ æƒ³æ‹¥æœ‰â€œç»“æ„æ€§â€å…ƒç´ çš„ä½“ç´ ä¸ä¸å±äºç»“æ„æ€§å…ƒç´ çš„æ‚ç‰©ä½“ç´ çš„æƒ…å†µã€‚æ²¡æœ‰æ ‡ç­¾çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®å®ƒä»¬æ˜¯å¦å±äºRANSACåˆ†æ®µæˆ–å…¶ä»–åˆ†æ®µæ¥æŒ‡å¯¼æˆ‘ä»¬çš„é€‰æ‹©ï¼›è¿™æ„å‘³ç€é¦–å…ˆå°†RANSACå¤„ç†çš„åˆ†æ®µè¿›è¡Œæ‹¼æ¥ï¼š
- en: '[PRE34]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'ğŸ¦š **Note**: *At this stage, you have the ability to color the point clouds
    with a uniform color later picked up by the voxels. If this is something you would
    like, you can use:* `pcd_ransac.paint_uniform_color([1, 0, 0])`'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸ¦š **æ³¨æ„**: *åœ¨è¿™ä¸ªé˜¶æ®µï¼Œä½ æœ‰èƒ½åŠ›ç”¨ä½“ç´ ç¨åæ‹¾å–çš„å‡åŒ€é¢œè‰²ä¸ºç‚¹äº‘ç€è‰²ã€‚å¦‚æœè¿™æ˜¯ä½ æƒ³è¦çš„ï¼Œä½ å¯ä»¥ä½¿ç”¨ï¼š* `pcd_ransac.paint_uniform_color([1,
    0, 0])`'
- en: 'Then, we can simply extract our voxel grid:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°æå–æˆ‘ä»¬çš„ä½“ç´ ç½‘æ ¼ï¼š
- en: '[PRE35]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'and do the same thing for the remaining elements:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶å¯¹å‰©ä½™å…ƒç´ åšåŒæ ·çš„å¤„ç†ï¼š
- en: '[PRE36]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The final step is to visualize our result:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åä¸€æ­¥æ˜¯å¯è§†åŒ–æˆ‘ä»¬çš„ç»“æœï¼š
- en: '[PRE37]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '![](../Images/a710cdc6698553309602a38d1349b361.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a710cdc6698553309602a38d1349b361.png)'
- en: A semantic representation of the space using voxel representation. Â© F. Poux
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ä½“ç´ è¡¨ç¤ºçš„ç©ºé—´çš„è¯­ä¹‰è¡¨ç¤ºã€‚Â© F. Poux
- en: This is awesome! It looks like one of those computer games where the whole world
    is constructed out of cubes! And we can actually use the segment labels to guide
    our voxel modeling! This opens up many perspectives! But an issue remains. With
    Open3D, it is hard to extract the voxels that are not filled; So, having achieved
    the structuration of the voxelized point cloud, the subsequent step involves exploring
    voxel space modeling techniques to provide alternative perspectives for analyzing
    the spatial relationships and properties of the voxelized data, opening up new
    avenues for advanced point cloud modeling.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¤ªæ£’äº†ï¼å®ƒçœ‹èµ·æ¥åƒé‚£äº›æ•´ä¸ªä¸–ç•Œç”±ç«‹æ–¹ä½“æ„æˆçš„è®¡ç®—æœºæ¸¸æˆï¼è€Œä¸”æˆ‘ä»¬å®é™…ä¸Šå¯ä»¥ä½¿ç”¨åˆ†æ®µæ ‡ç­¾æ¥æŒ‡å¯¼æˆ‘ä»¬çš„ä½“ç´ å»ºæ¨¡ï¼è¿™å¼€å¯äº†è®¸å¤šè§†è§’ï¼ä½†é—®é¢˜ä¾ç„¶å­˜åœ¨ã€‚ä½¿ç”¨Open3Dï¼Œæå–æœªå¡«å……çš„ä½“ç´ æ˜¯å›°éš¾çš„ï¼›å› æ­¤ï¼Œå®Œæˆä½“ç´ åŒ–ç‚¹äº‘çš„ç»“æ„åŒ–åï¼Œä¸‹ä¸€æ­¥æ¶‰åŠæ¢ç´¢ä½“ç´ ç©ºé—´å»ºæ¨¡æŠ€æœ¯ï¼Œä»¥æä¾›åˆ†æä½“ç´ åŒ–æ•°æ®ç©ºé—´å…³ç³»å’Œå±æ€§çš„æ›¿ä»£è§†è§’ï¼Œä¸ºé«˜çº§ç‚¹äº‘å»ºæ¨¡å¼€è¾Ÿæ–°é€”å¾„ã€‚
- en: 'ğŸ¤  **Ville**: *Voxelization is a different spatial representation of the same
    point cloud data. Great for robots if they need to avoid collisions! And for great
    for simulatingâ€¦ fire drills, for example!*'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸ¤  **Ville**: *ä½“ç´ åŒ–æ˜¯å¯¹ç›¸åŒç‚¹äº‘æ•°æ®çš„ä¸åŒç©ºé—´è¡¨ç¤ºã€‚å¦‚æœæœºå™¨äººéœ€è¦é¿å¼€ç¢°æ’ï¼Œè¿™ç§è¡¨ç¤ºéå¸¸æœ‰ç”¨ï¼æ¯”å¦‚åœ¨æ¨¡æ‹Ÿâ€¦ç«ç¾æ¼”ä¹ æ—¶ä¹Ÿéå¸¸æœ‰ç”¨ï¼*'
- en: 9\. Spatial Modelling
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9\. ç©ºé—´å»ºæ¨¡
- en: '![](../Images/8f45765461494fbd3c658993a1b48144.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8f45765461494fbd3c658993a1b48144.png)'
- en: 'In indoor modeling applications, the voxel-based representation of point clouds
    plays a pivotal role in capturing and analyzing the geometric properties of complex
    environments. As the scale and complexity of point cloud datasets increase, it
    becomes essential to delve deeper into voxel segmentation techniques to extract
    meaningful structures and facilitate higher-level analysis. Let us thus define
    a function that fits a voxel grid and return both filled and empty spaces:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å®¤å†…å»ºæ¨¡åº”ç”¨ä¸­ï¼ŒåŸºäºä½“ç´ çš„ç‚¹äº‘è¡¨ç¤ºåœ¨æ•æ‰å’Œåˆ†æå¤æ‚ç¯å¢ƒçš„å‡ ä½•å±æ€§æ–¹é¢èµ·ç€å…³é”®ä½œç”¨ã€‚éšç€ç‚¹äº‘æ•°æ®é›†çš„è§„æ¨¡å’Œå¤æ‚æ€§çš„å¢åŠ ï¼Œæ·±å…¥æ¢è®¨ä½“ç´ åˆ†å‰²æŠ€æœ¯å˜å¾—è‡³å…³é‡è¦ï¼Œä»¥æå–æœ‰æ„ä¹‰çš„ç»“æ„å¹¶ä¿ƒè¿›æ›´é«˜å±‚æ¬¡çš„åˆ†æã€‚å› æ­¤ï¼Œè®©æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥æ‹Ÿåˆä½“ç´ ç½‘æ ¼ï¼Œå¹¶è¿”å›å¡«å……å’Œç©ºç™½åŒºåŸŸï¼š
- en: '[PRE38]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Within the function, we will (1) Determine the minimum and maximum coordinates
    of the point cloud, (2) Calculate the dimensions of the voxel grid, (3) Create
    an empty voxel grid, (4) Calculate the indices of the occupied voxels and (5)
    Mark occupied voxels as True.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å‡½æ•°å†…éƒ¨ï¼Œæˆ‘ä»¬å°† (1) ç¡®å®šç‚¹äº‘çš„æœ€å°å’Œæœ€å¤§åæ ‡ï¼Œ(2) è®¡ç®—ä½“ç´ ç½‘æ ¼çš„å°ºå¯¸ï¼Œ(3) åˆ›å»ºä¸€ä¸ªç©ºçš„ä½“ç´ ç½‘æ ¼ï¼Œ(4) è®¡ç®—å·²å æ®ä½“ç´ çš„ç´¢å¼•ä»¥åŠ (5)
    å°†å æ®ä½“ç´ æ ‡è®°ä¸º Trueã€‚
- en: '![](../Images/c8495062282952b988f871455aef9eb1.png)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c8495062282952b988f871455aef9eb1.png)'
- en: Algorithm workflow to create an occupancy grid from the point cloud. Â© F. Poux
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ç‚¹äº‘åˆ›å»ºå æ®ç½‘æ ¼çš„ç®—æ³•å·¥ä½œæµç¨‹ã€‚Â© F. Poux
- en: 'This translates into the following code that we want to have inside this function:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è½¬åŒ–ä¸ºæˆ‘ä»¬å¸Œæœ›åœ¨æ­¤å‡½æ•°ä¸­åŒ…å«çš„ä»¥ä¸‹ä»£ç ï¼š
- en: '[PRE39]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Our function is defined, and we can now use it to extract the voxels, segmented
    between structural, clutter, and empty ones:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»å®šä¹‰äº†å‡½æ•°ï¼Œç°åœ¨å¯ä»¥ä½¿ç”¨å®ƒæå–ä½“ç´ ï¼ŒæŒ‰ç»“æ„ã€æ‚ä¹±å’Œç©ºä½“ç´ è¿›è¡Œåˆ†æ®µï¼š
- en: '[PRE40]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'ğŸ¦š **Note**: *The* `*nonzero()*` *function from NumPy finds the indices of the
    nonzero elements in the* `*ransac_voxels*` *variable. The* `*nonzero()*` *function
    returns a tuple of arrays, where each array corresponds to the indices along a
    specific axis where the elements are nonzero. then we apply the* `*np.transpose()*`
    *NumPy function to the result obtained from* `*np.nonzero(ransac_voxels)*`*. The*
    `*transpose()*` *function finally permutes the axes of the array. (effectively
    swapping the rows with the columns). By combining these operations, the code line
    transposes the indices of the nonzero elements of* `*ransac_voxels*`*, resulting
    in a transposed array where each row represents the coordinates or indices of
    a nonzero element in the original* `*ransac_voxels*` *array*. ğŸ˜Š'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*NumPy ä¸­çš„ `*nonzero()*`* å‡½æ•°æŸ¥æ‰¾ `*ransac_voxels*` å˜é‡ä¸­éé›¶å…ƒç´ çš„ç´¢å¼•ã€‚`*nonzero()*`*
    å‡½æ•°è¿”å›ä¸€ä¸ªæ•°ç»„çš„å…ƒç»„ï¼Œæ¯ä¸ªæ•°ç»„å¯¹åº”äºç‰¹å®šè½´ä¸Šéé›¶å…ƒç´ çš„ç´¢å¼•ã€‚ç„¶åï¼Œæˆ‘ä»¬å°† `*np.transpose()*`* NumPy å‡½æ•°åº”ç”¨äºä» `*np.nonzero(ransac_voxels)*`*
    è·å¾—çš„ç»“æœã€‚`*transpose()*`* å‡½æ•°æœ€ç»ˆä¼šæ’åˆ—æ•°ç»„çš„è½´ï¼ˆæœ‰æ•ˆåœ°äº¤æ¢è¡Œå’Œåˆ—ï¼‰ã€‚é€šè¿‡ç»“åˆè¿™äº›æ“ä½œï¼Œä»£ç è¡Œå¯¹ `*ransac_voxels*`*
    çš„éé›¶å…ƒç´ ç´¢å¼•è¿›è¡Œè½¬ç½®ï¼Œç”Ÿæˆä¸€ä¸ªè½¬ç½®æ•°ç»„ï¼Œå…¶ä¸­æ¯è¡Œè¡¨ç¤ºåŸå§‹ `*ransac_voxels*`* æ•°ç»„ä¸­éé›¶å…ƒç´ çš„åæ ‡æˆ–ç´¢å¼•ã€‚ğŸ˜Š
- en: This voxel modeling approach offers valuable insights into the spatial relationships
    and properties of the voxelized data. To visualize the results as shown below
    outside of Python with transparency, we need to export our data.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§ä½“ç´ å»ºæ¨¡æ–¹æ³•æä¾›äº†å¯¹ä½“ç´ åŒ–æ•°æ®ç©ºé—´å…³ç³»å’Œå±æ€§çš„å®è´µè§è§£ã€‚ä¸ºäº†åœ¨ Python ä¹‹å¤–ä»¥é€æ˜åº¦å¯è§†åŒ–ç»“æœï¼Œæˆ‘ä»¬éœ€è¦å¯¼å‡ºæ•°æ®ã€‚
- en: '![](../Images/26688159b8fd845b7e77716526a41603.png)![](../Images/b5cf1042943b2491366570bf5785fea4.png)![](../Images/ac7654c650a1171f5b0bc0629506989d.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/26688159b8fd845b7e77716526a41603.png)![](../Images/b5cf1042943b2491366570bf5785fea4.png)![](../Images/ac7654c650a1171f5b0bc0629506989d.png)'
- en: Results of the Occupancy grid matching. On the left are both the filled voxels
    and empty voxels, in the middle are the filled voxels, and in the right are the
    empty voxels. Â© F. Poux
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: å æ®ç½‘æ ¼åŒ¹é…çš„ç»“æœã€‚å·¦ä¾§æ˜¯å¡«å……ä½“ç´ å’Œç©ºä½“ç´ ï¼Œä¸­é—´æ˜¯å¡«å……ä½“ç´ ï¼Œå³ä¾§æ˜¯ç©ºä½“ç´ ã€‚Â© F. Poux
- en: After achieving the structuration of the voxelized point cloud, the next step
    involves exporting both the point cloud and voxel data to external formats, facilitating
    interoperability and enabling seamless integration with other software tools and
    workflows. This export process ensures that the structured voxel data and the
    original point cloud can be easily shared, visualized, or utilized for further
    analysis in various applications, fostering a collaborative and versatile approach
    to point cloud data utilization.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å®ç°ä½“ç´ åŒ–ç‚¹äº‘çš„ç»“æ„åŒ–åï¼Œä¸‹ä¸€æ­¥æ¶‰åŠå°†ç‚¹äº‘å’Œä½“ç´ æ•°æ®å¯¼å‡ºä¸ºå¤–éƒ¨æ ¼å¼ï¼Œä»¥ä¾¿å®ç°äº’æ“ä½œæ€§ï¼Œå¹¶ä¸å…¶ä»–è½¯ä»¶å·¥å…·å’Œå·¥ä½œæµç¨‹æ— ç¼é›†æˆã€‚æ­¤å¯¼å‡ºè¿‡ç¨‹ç¡®ä¿ç»“æ„åŒ–çš„ä½“ç´ æ•°æ®å’ŒåŸå§‹ç‚¹äº‘å¯ä»¥è½»æ¾å…±äº«ã€å¯è§†åŒ–æˆ–ç”¨äºè¿›ä¸€æ­¥åˆ†æï¼Œä»è€Œä¿ƒè¿›å¯¹ç‚¹äº‘æ•°æ®åˆ©ç”¨çš„åä½œå’Œå¤šåŠŸèƒ½æ–¹æ³•ã€‚
- en: 10\. Exporting 3D Datasets
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10\. å¯¼å‡º 3D æ•°æ®é›†
- en: '![](../Images/61eb9b7f6baa27577836ecc3290f343b.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61eb9b7f6baa27577836ecc3290f343b.png)'
- en: Let us first focus on exporting the point cloud segmented datasets.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é¦–å…ˆå…³æ³¨å¯¼å‡ºç‚¹äº‘åˆ†å‰²æ•°æ®é›†ã€‚
- en: 10.1\. Segmented point cloud export
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.1\. åˆ†å‰²ç‚¹äº‘å¯¼å‡º
- en: 'To export the segmented point cloud, we must ensure that we can write the label
    per point within a readable ASCII file. To do this, we will create a list of XYZ
    segments to which we will append the label feature. This can be done with the
    following for loop:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: è¦å¯¼å‡ºåˆ†å‰²åçš„ç‚¹äº‘ï¼Œæˆ‘ä»¬å¿…é¡»ç¡®ä¿å¯ä»¥åœ¨å¯è¯»çš„ASCIIæ–‡ä»¶ä¸­ä¸ºæ¯ä¸ªç‚¹å†™å…¥æ ‡ç­¾ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªXYZç‰‡æ®µåˆ—è¡¨ï¼Œå¹¶å°†æ ‡ç­¾ç‰¹å¾é™„åŠ åˆ°è¯¥åˆ—è¡¨ã€‚è¿™å¯ä»¥é€šè¿‡ä»¥ä¸‹`for`å¾ªç¯å®Œæˆï¼š
- en: '[PRE41]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'From there, we want not to forget the remaining elements from the DBSCAN clustering,
    on which we apply the same principle:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é‚£é‡Œï¼Œæˆ‘ä»¬ä¸æƒ³å¿˜è®°DBSCANèšç±»ä¸­çš„å‰©ä½™å…ƒç´ ï¼Œå¯¹å…¶åº”ç”¨ç›¸åŒçš„åŸåˆ™ï¼š
- en: '[PRE42]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'finally, we append this to the segments list:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬å°†å…¶é™„åŠ åˆ°ç‰‡æ®µåˆ—è¡¨ä¸­ï¼š
- en: '[PRE43]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'all that we have to do is then to use numpy to export the dataset and visualize
    it externally:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬æ‰€éœ€è¦åšçš„å°±æ˜¯ä½¿ç”¨numpyå¯¼å‡ºæ•°æ®é›†å¹¶è¿›è¡Œå¤–éƒ¨å¯è§†åŒ–ï¼š
- en: '[PRE44]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '![](../Images/9a6913b5b3158a617aa100ac50f293b6.png)![](../Images/3f317d5083906d7a4c6ef6e961bc04df.png)![](../Images/3d6ef345ce0c619c4c2e337ea05070c8.png)![](../Images/678224d1204a44582879919bd30270e1.png)![](../Images/a40abe9f177b691d00b9bc7991871a61.png)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9a6913b5b3158a617aa100ac50f293b6.png)![](../Images/3f317d5083906d7a4c6ef6e961bc04df.png)![](../Images/3d6ef345ce0c619c4c2e337ea05070c8.png)![](../Images/678224d1204a44582879919bd30270e1.png)![](../Images/a40abe9f177b691d00b9bc7991871a61.png)'
- en: Following the successful export of the segmented point cloud dataset, the focus
    now shifts to exporting the voxel dataset as a `.obj` file.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆåŠŸå¯¼å‡ºåˆ†å‰²åçš„ç‚¹äº‘æ•°æ®é›†åï¼Œç°åœ¨çš„é‡ç‚¹æ˜¯å°†ä½“ç´ æ•°æ®é›†å¯¼å‡ºä¸º`.obj`æ–‡ä»¶ã€‚
- en: 10.2\. Voxel Model Export
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.2\. ä½“ç´ æ¨¡å‹å¯¼å‡º
- en: 'To export the voxels, we first have to generate a cube for each voxel; These
    cubes are then combined in a `voxel_assembly`, stacked together to generate the
    final file. We create the `voxel_modelling(filename, indices, voxel_size)` function
    to do this:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: è¦å¯¼å‡ºä½“ç´ ï¼Œæˆ‘ä»¬é¦–å…ˆå¿…é¡»ä¸ºæ¯ä¸ªä½“ç´ ç”Ÿæˆä¸€ä¸ªç«‹æ–¹ä½“ï¼›è¿™äº›ç«‹æ–¹ä½“ç„¶ååœ¨`voxel_assembly`ä¸­ç»„åˆåœ¨ä¸€èµ·ï¼Œå †å ç”Ÿæˆæœ€ç»ˆæ–‡ä»¶ã€‚æˆ‘ä»¬åˆ›å»ºäº†`voxel_modelling(filename,
    indices, voxel_size)`å‡½æ•°æ¥å®Œæˆè¿™ä¸ªä»»åŠ¡ï¼š
- en: '[PRE45]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'ğŸ¦š **Note**: *the function* `[cube()](https://drive.google.com/file/d/1kPu85YHl66gQH8Qumxlyd-Sp4PjgvBVm/view?usp=sharing)`
    *reads the provided indices, generates voxel cubes based on the indices and voxel
    size, writes the voxel cubes to a file, and keeps track of the assembled voxel
    cubes in the* `*voxel_assembly*` *list, which is ultimately returned by the function.*'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*å‡½æ•°* `[cube()](https://drive.google.com/file/d/1kPu85YHl66gQH8Qumxlyd-Sp4PjgvBVm/view?usp=sharing)`
    *è¯»å–æä¾›çš„ç´¢å¼•ï¼Œæ ¹æ®ç´¢å¼•å’Œä½“ç´ å¤§å°ç”Ÿæˆä½“ç´ ç«‹æ–¹ä½“ï¼Œå°†ä½“ç´ ç«‹æ–¹ä½“å†™å…¥æ–‡ä»¶ï¼Œå¹¶è·Ÿè¸ªåœ¨* `*voxel_assembly*` *åˆ—è¡¨ä¸­çš„ç»„è£…ä½“ç´ ç«‹æ–¹ä½“ï¼Œæœ€ç»ˆç”±å‡½æ•°è¿”å›ã€‚*
- en: 'This is then used to export three different voxel assemblies:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åç”¨æ¥å¯¼å‡ºä¸‰ç§ä¸åŒçš„ä½“ç´ ç»„åˆï¼š
- en: '[PRE46]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '![](../Images/2d627d5ec536ba3c638629a25ce4f5f5.png)![](../Images/7860e71bb83efd674302b5c044716254.png)![](../Images/442975beca59c66312b3cdbbcfc21310.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2d627d5ec536ba3c638629a25ce4f5f5.png)![](../Images/7860e71bb83efd674302b5c044716254.png)![](../Images/442975beca59c66312b3cdbbcfc21310.png)'
- en: The results of the Segmentation and voxel modeling. Â© F. Poux
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†å‰²å’Œä½“ç´ å»ºæ¨¡çš„ç»“æœã€‚Â© F. Poux
- en: 'ğŸ’» Get Access to the Code here: [Code Samples](https://drive.google.com/drive/folders/1-sGlVvsPcyp9VZ8cw-J8kbhj4-aK_8p8?usp=sharing)'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ’» åœ¨è¿™é‡Œè·å–ä»£ç è®¿é—®æƒé™ï¼š[ä»£ç ç¤ºä¾‹](https://drive.google.com/drive/folders/1-sGlVvsPcyp9VZ8cw-J8kbhj4-aK_8p8?usp=sharing)
- en: 'ğŸ‡ Get Access to the Data here: [3D Datasets](https://drive.google.com/drive/folders/1sCBT1lc9A8Zn4grpxwFrBrvos86c0HZR?usp=sharing)'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ‡ åœ¨è¿™é‡Œè·å–æ•°æ®è®¿é—®æƒé™ï¼š[3D æ•°æ®é›†](https://drive.google.com/drive/folders/1sCBT1lc9A8Zn4grpxwFrBrvos86c0HZR?usp=sharing)
- en: 'ğŸ‘¨â€ğŸ«3D Data Processing and AI Courses: [3D Academy](https://learngeodata.eu/)'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ‘¨â€ğŸ«3D æ•°æ®å¤„ç†å’ŒAIè¯¾ç¨‹ï¼š[3D å­¦é™¢](https://learngeodata.eu/)
- en: 'ğŸ“– Subscribe to get early access to 3D Tutorials: [3D AI Automation](https://medium.com/@florentpoux/subscribe)'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ“– è®¢é˜…ä»¥è·å¾—3Dæ•™ç¨‹çš„æå‰è®¿é—®æƒé™ï¼š[3D AI è‡ªåŠ¨åŒ–](https://medium.com/@florentpoux/subscribe)
- en: '![](../Images/ceab061ce5f1ea698c109d269cc41fd2.png)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ceab061ce5f1ea698c109d269cc41fd2.png)'
- en: Conclusion
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: 'ğŸ¦Š **Florent**: Massive congratulations ğŸ‰! You just learned how to develop an
    automatic shape detection, clustering, voxelization, and indoor modeling program
    for 3D point clouds composed of millions of points with different strategies!
    Sincerely, well done! But the path certainly does not end here because you just
    unlocked a tremendous potential for intelligent processes that reason at a segment
    level!'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦Š **Florent**ï¼šå¤§è§„æ¨¡ç¥è´ºğŸ‰ï¼ä½ åˆšåˆšå­¦ä¼šäº†å¦‚ä½•å¼€å‘ä¸€ä¸ªè‡ªåŠ¨å½¢çŠ¶æ£€æµ‹ã€èšç±»ã€ä½“ç´ åŒ–å’Œå®¤å†…å»ºæ¨¡ç¨‹åºï¼Œç”¨äºå¤„ç†ç”±æ•°ç™¾ä¸‡ä¸ªç‚¹ç»„æˆçš„3Dç‚¹äº‘ï¼Œå¹¶é‡‡ç”¨ä¸åŒçš„ç­–ç•¥ï¼çœŸå¿ƒåœ°ï¼Œåšå¾—å¾ˆå¥½ï¼ä½†é“è·¯æ˜¾ç„¶ä¸æ­¢äºæ­¤ï¼Œå› ä¸ºä½ åˆšåˆšè§£é”äº†ä¸€ä¸ªå·¨å¤§çš„æ™ºèƒ½è¿‡ç¨‹æ½œåŠ›ï¼Œèƒ½å¤Ÿåœ¨ç‰‡æ®µçº§åˆ«è¿›è¡Œæ¨ç†ï¼
- en: 'ğŸ¤  **Ville**: So, now youâ€™re wondering if we can make 3D modeling a completely
    hands-off process? Weâ€™re halfway there with the technique weâ€™ve got. Why? Our
    technique can find parameters, for example, for the plane models. This is why
    the folks in academia call it parametric modeling. However, we still need to carefully
    choose some of the other parameters, such as the ones for RANSAC. I encourage
    you to experiment by applying your code on a different point cloud!'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤  **Ville**ï¼šé‚£ä¹ˆï¼Œä½ æ˜¯å¦åœ¨æƒ³æˆ‘ä»¬æ˜¯å¦å¯ä»¥è®© 3D å»ºæ¨¡æˆä¸ºå®Œå…¨æ— éœ€äººå·¥å¹²é¢„çš„è¿‡ç¨‹ï¼Ÿå‡­å€Ÿæˆ‘ä»¬ç›®å‰çš„æŠ€æœ¯ï¼Œæˆ‘ä»¬å·²ç»å®Œæˆäº†ä¸€åŠã€‚ä¸ºä»€ä¹ˆï¼Ÿæˆ‘ä»¬çš„æŠ€æœ¯å¯ä»¥æ‰¾åˆ°ï¼Œä¾‹å¦‚ï¼Œå¹³é¢æ¨¡å‹çš„å‚æ•°ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå­¦æœ¯ç•Œçš„äººç§°ä¹‹ä¸ºå‚æ•°å»ºæ¨¡ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬ä»ç„¶éœ€è¦ä»”ç»†é€‰æ‹©å…¶ä»–ä¸€äº›å‚æ•°ï¼Œæ¯”å¦‚
    RANSAC çš„å‚æ•°ã€‚æˆ‘é¼“åŠ±ä½ å°è¯•åœ¨ä¸åŒçš„ç‚¹äº‘ä¸Šåº”ç”¨ä½ çš„ä»£ç ï¼
- en: '![](../Images/4b6c35c1665bd5dbdfac5fc7031fb72a.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b6c35c1665bd5dbdfac5fc7031fb72a.png)'
- en: Example of 3D meshing based on the semantics of the ground. Â© F. Poux
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºåœ°é¢è¯­ä¹‰çš„ 3D ç½‘æ ¼ç¤ºä¾‹ã€‚Â© F. Poux
- en: Going Further
  id: totrans-283
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ›´è¿›ä¸€æ­¥
- en: The learning journey does not end here. Our lifelong search begins, and future
    steps will dive into deepening 3D Voxel work, exploring semantics, and point cloud
    analysis with deep learning techniques. We will unlock advanced 3D LiDAR analytical
    workflows. A lot to be excited about!
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: å­¦ä¹ ä¹‹æ—…å¹¶æœªç»“æŸã€‚æˆ‘ä»¬çš„ç»ˆèº«æ¢ç´¢æ‰åˆšåˆšå¼€å§‹ï¼Œæœªæ¥çš„æ­¥éª¤å°†æ·±å…¥åˆ° 3D Voxel å·¥ä½œï¼Œæ¢ç´¢è¯­ä¹‰å’Œç‚¹äº‘åˆ†æä¸æ·±åº¦å­¦ä¹ æŠ€æœ¯ã€‚æˆ‘ä»¬å°†è§£é”é«˜çº§çš„ 3D LiDAR
    åˆ†æå·¥ä½œæµç¨‹ã€‚ä»¤äººå…´å¥‹çš„äº‹æƒ…è¿˜æœ‰å¾ˆå¤šï¼
- en: '**Lehtola, V.**, Nikoohemat, S., & NÃ¼chter, A. (2020). Indoor 3D: Overview
    on scanning and reconstruction methods. Handbook of Big Geospatial Data, 55â€“97\.
    [https://doi.org/10.1007/978-3-030-55462-0_3](https://doi.org/10.1007/978-3-030-55462-0_3)'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Lehtola, V.**ï¼ŒNikoohemat, S.ï¼Œ& NÃ¼chter, A.ï¼ˆ2020ï¼‰ã€‚å®¤å†… 3Dï¼šæ‰«æå’Œé‡å»ºæ–¹æ³•æ¦‚è¿°ã€‚å¤§åœ°ç©ºé—´æ•°æ®æ‰‹å†Œï¼Œ55â€“97\.
    [https://doi.org/10.1007/978-3-030-55462-0_3](https://doi.org/10.1007/978-3-030-55462-0_3)'
- en: '**Poux, F.**, & Billen, R. (2019). Voxel-based 3D point cloud semantic segmentation:
    unsupervised geometric and relationship featuring vs deep learning methods. *ISPRS
    International Journal of Geo-Information*. 8(5), 213; [https://doi.org/10.3390/ijgi8050213](https://doi.org/10.3390/ijgi8050213)
    â€” Jack Dangermond Award ([Link to press coverage](https://www.geographie.uliege.be/cms/c_5724437/en/florent-poux-and-roland-billen-winners-of-the-2019-jack-dangermond-award))'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Poux, F.**ï¼Œ& Billen, R.ï¼ˆ2019ï¼‰ã€‚åŸºäºä½“ç´ çš„ 3D ç‚¹äº‘è¯­ä¹‰åˆ†å‰²ï¼šæ— ç›‘ç£å‡ ä½•å’Œå…³ç³»ç‰¹å¾ä¸æ·±åº¦å­¦ä¹ æ–¹æ³•ã€‚*ISPRS å›½é™…åœ°ç†ä¿¡æ¯æ‚å¿—*ã€‚8(5)ï¼Œ213ï¼›[https://doi.org/10.3390/ijgi8050213](https://doi.org/10.3390/ijgi8050213)
    â€” Jack Dangermond å¥–ï¼ˆ[æ–°é—»æŠ¥é“é“¾æ¥](https://www.geographie.uliege.be/cms/c_5724437/en/florent-poux-and-roland-billen-winners-of-the-2019-jack-dangermond-award)ï¼‰'
- en: Bassier, M., Vergauwen, M., **Poux, F.**, (2020). Point Cloud vs. Mesh Features
    for Building Interior Classification. *Remote Sensing*. 12, 2224\. https://doi:10.3390/rs12142224
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Bassier, M., Vergauwen, M., **Poux, F.**ï¼Œï¼ˆ2020ï¼‰ã€‚å»ºç­‘å†…éƒ¨åˆ†ç±»ä¸­çš„ç‚¹äº‘ä¸ç½‘æ ¼ç‰¹å¾ã€‚*é¥æ„Ÿ*ã€‚12ï¼Œ2224\.
    https://doi:10.3390/rs12142224
