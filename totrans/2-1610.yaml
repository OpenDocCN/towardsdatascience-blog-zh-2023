- en: Organizational Processes for Machine Learning Risk Management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/organizational-processes-for-machine-learning-risk-management-14f4444dd07f](https://towardsdatascience.com/organizational-processes-for-machine-learning-risk-management-14f4444dd07f)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Responsible AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Organizational processes are a key nontechnical determinant of reliability
    in ML systems.*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://pandeyparul.medium.com/?source=post_page-----14f4444dd07f--------------------------------)[![Parul
    Pandey](../Images/760b72a4feacfad6fc4224835c2e1f19.png)](https://pandeyparul.medium.com/?source=post_page-----14f4444dd07f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----14f4444dd07f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----14f4444dd07f--------------------------------)
    [Parul Pandey](https://pandeyparul.medium.com/?source=post_page-----14f4444dd07f--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----14f4444dd07f--------------------------------)
    ·7 min read·Sep 23, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6f17ca9325b10e97b1e4f7c65396c676.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: In our ongoing series on Machine Learning Risk Management, we've been looking
    at some of the critical elements that ensure the trustworthiness of Machine Learning
    (ML) systems. In our first installment, we discussed the [**Cultural Competencies
    for Machine Learning Risk Managemen**](/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf?sk=8ed4f0c5e9624e21d9f6dae9017d5bed)**t**,
    in detail. The insights presented therein lay the foundation for our current exploration,
    and therefore, I highly recommend that you go through the part before continuing
    with this article.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf?source=post_page-----14f4444dd07f--------------------------------)
    [## Cultural Competencies for Machine Learning Risk Management'
  prefs: []
  type: TYPE_NORMAL
- en: An organization's culture is an essential aspect of responsible AI.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf?source=post_page-----14f4444dd07f--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'In this second article, we’ll shift our focus to another vital element in the
    context of ML systems: **Organizational Processes**. While technical intricacies
    often overshadow these processes, they hold the key to guaranteeing the safety
    and performance of machine learning models. Just as we recognized the significance
    of cultural competencies, we now acknowledge that organizational processes are
    the foundational cornerstone upon which the reliability of ML systems is constructed.'
  prefs: []
  type: TYPE_NORMAL
- en: This article discusses the vital role of organizational processes in the area
    of Machine Learning Risk Management (MRM). Throughout the article, we emphasize
    the criticality of practitioners meticulously considering, documenting, and proactively
    addressing any known or foreseeable failure modes within their ML systems.
  prefs: []
  type: TYPE_NORMAL
- en: 1️. *Forecasting Failure Modes*
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While it is crucial to identify and address possible problems in ML systems,
    turning this idea into action takes time and effort. However, in recent years,
    there has been a significant increase in resources that can help ML system designers
    predict issues more systematically. By carefully sorting out potential problems,
    making ML systems stronger and safer in real-world situations becomes easier.
    In this context, the following strategies can be explored:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Learning from past failures**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Much like how transportation professionals investigate and catalog incidents
    to prevent future occurrences, ML researchers and organizations have started collecting
    and analyzing A.I. incidents. The [**A.I. Incident Database**](https://incidentdatabase.ai/),
    which we also brought up in the [last article](/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf),
    is a prominent repository that allows users to search for incidents and glean
    valuable insights. When developing an ML system, consulting this resource is crucial.
  prefs: []
  type: TYPE_NORMAL
- en: If a similar approach has caused an incident in the past, it serves as a strong
    warning sign that the new system may also pose risks, necessitating careful consideration.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/ca438fee401ddf54467264085c27b526.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Preventing Repeated Real-World A.I. Failures by Cataloging Incidents: The A.I.
    Incident Database | Source: [https://arxiv.org/pdf/2011.08512.pdf](https://arxiv.org/pdf/2011.08512.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Addressing *failures of imagination***'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/81f296fe49ada9a1879b9e79680e678c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Overcoming Failures of Imagination in AI-Infused System Development and Deployment
    | Source: [https://arxiv.org/pdf/2011.13416.pdf](https://arxiv.org/pdf/2011.13416.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: Often, A.I. incidents stem from unforeseen or poorly understood contexts and
    details of ML systems' operations. Structured approaches outlined in the paper
    [Overcoming Failures of Imagination in AI-Infused System Development and Deployment](https://arxiv.org/pdf/2011.13416.pdf)
    offer ways to hypothesize about these challenging future risks, in addition to
    considering aspects such as **who** (including investors, customers, and vulnerable
    nonusers), **what** (covering well-being, opportunities, and dignity), **when**
    (including immediate, frequent, and long-term scenarios), and **how** (involving
    actions and belief alterations) related to A.I. incidents.
  prefs: []
  type: TYPE_NORMAL
- en: '*While AI incidents can be embarrassing, costly, or even illegal for organizations,
    foresight can mitigate many known incidents, potentially leading to system improvements.
    In such cases, the temporary delay in implementation is far less costly than the
    potential harm to the organization and the public from a flawed system release.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 2\. Model Risk Management Processes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/7b4207ae290dab7f3c97c3ad8024a2cd.png)'
  prefs: []
  type: TYPE_IMG
- en: '***A snapshot of the 21-page S.R. 11–7 model risk management guidance. The
    document is for free public access |*** *Source:* [https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf](https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning Risk Management (MRM) constitutes a comprehensive framework
    and a series of procedures designed to identify, assess, mitigate, and monitor
    risks associated with developing, deploying, and operating machine learning systems.
    These elements form a significant part of the governance structure, particularly
    within the context of the U.S. Federal Reserve's [**Supervisory Guidance on Model
    Risk Management (S.R. 11–07)**](https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf),
    which oversees predictive models employed in substantial consumer finance applications.
  prefs: []
  type: TYPE_NORMAL
- en: Documentation is where compliance becomes tangible, holding practitioners accountable
    and guiding them to build robust models
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: While complete MRM implementation may be more attainable for larger organizations,
    smaller ones can also extract valuable insights. This section dissects MRM procedures
    into smaller, more manageable components, making them easier to understand and
    use.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Risk Tiering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When evaluating risk in ML system deployment, a common approach involves calculating
    ***materiality*** considering the likelihood of harm and anticipated loss. High-materiality
    applications demand greater attention. Effective governance appropriately allocates
    resources to high, medium, and low-risk systems. For example, the recently released
    [Anthropic A.I.''s Responsible Scaling policy](https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf)
    introduces the concept of A.I. safety levels (ASL), loosely inspired by the U.S.
    government''s biosafety level (BSL) standards for managing hazardous biological
    materials. Here is a snapshot of the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5ccd0ed5e761e5b7ed5f122e78eb3305.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A snapshot from Anthropic’s RSP | Source: [https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf](https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Model Documentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: MRM standards require comprehensive system documentation, fulfilling multiple
    purposes, including stakeholder accountability, ongoing maintenance, and incident
    response. Standardized documentation across systems streamlines audit and review
    processes, making it a critical aspect of compliance. Documentation templates
    guide data scientists and engineers throughout the model development process,
    ensuring that all necessary steps are conducted to construct a reliable model.
    Incomplete documentation indicates inadequacies in the training process, as most
    templates require practitioners to fill in every section. Furthermore, including
    one's name and contact information in the final model document fosters accountability.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1aba70f788f661e75a31bb5cb22babbc.png)'
  prefs: []
  type: TYPE_IMG
- en: '*A rough combination of typical sections in MRM documentation and the sections
    recommended by the Annexes to the* [*E.U. Artificial Intelligence Act*](https://eur-lex.europa.eu/legal-content/EN/TXT/?qid=1623335154975&uri=CELEX%3A52021PC0206)
    *| Image by the author*'
  prefs: []
  type: TYPE_NORMAL
- en: Extensive model documentation can be daunting; smaller organizations can opt
    for simpler frameworks like datasheets, and model cards can assist smaller organizations
    in achieving these objectives.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2f426bcc44d64d2d794cb7ec03cc971a.png)![](../Images/cb9e0a734a53bcad1744cfd60e983a79.png)'
  prefs: []
  type: TYPE_IMG
- en: 'L: **Datasheets for Datasets** : Source: [https://arxiv.org/pdf/1803.09010.pdf](https://arxiv.org/pdf/1803.09010.pdf)
    | R: **Model cards for Model Monitoring** : Source: [https://arxiv.org/pdf/1810.03993.pdf](https://arxiv.org/pdf/1810.03993.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Model Monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The foundation of machine learning (ML) safety rests on the intrinsic unpredictability
    of ML system behavior in real-world contexts, necessitating the continuous surveillance
    of these systems from their deployment until their decommissioning. A principal
    concern revolves around **input drift**, which emerges when real-world circumstances
    deviate from the static training data due to factors like market fluctuations,
    regulatory alterations, or unexpected occurrences like pandemics. This divergence
    poses a potential threat to the system's functionality.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e2abd24be1bc0362670cd4b5f2a8667f.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Machine Learning in Research vs. Production.** | Slide from ''Safe and Reliable
    Machine Learning: Preventing and Identifying Failures'' presented at ICLR-2019,
    accessible at [https://slideslive.com/38915708/safe-and-reliable-machine-learning-preventing-and-identifying-failures](https://slideslive.com/38915708/safe-and-reliable-machine-learning-preventing-and-identifying-failures)
    under the CCO License'
  prefs: []
  type: TYPE_NORMAL
- en: Efficient ML systems reduce these risks by carefully monitoring for changes
    in data and model quality. This monitoring goes beyond just performance; it also
    looks for unusual data or predictions, security problems, and fairness issues.
    This helps ensure thorough risk management in a changing operational setting.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Model Inventories
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At the heart of MRM is the **model inventory** — comprehensive databases that
    list all of an organization's ML systems and connect to essential resources like
    monitoring strategies, audit results, system maintenance records, and incident
    response plans.
  prefs: []
  type: TYPE_NORMAL
- en: 'Any organization that is deploying ML should be able to answer straightforward
    questions like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/123759f71b67dccacaf128b5dc13a17b.png)'
  prefs: []
  type: TYPE_IMG
- en: Any organization that is deploying ML should be able to answer these straightforward
    questions | Image by the Author
  prefs: []
  type: TYPE_NORMAL
- en: For any organization serious about leveraging ML, maintaining a robust model
    inventory isn't just a good practice — it's a necessity.
  prefs: []
  type: TYPE_NORMAL
- en: '*5\. System validation and process auditing*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An essential aspect of traditional MRM practice is that it undergoes two primary
    evaluations before an ML system is released. First, experts test its technical
    parts, finding and fixing issues. Next, a team ensures the system follows all
    rules and guidelines, including its design and future plans. These systems are
    reviewed again if they have big updates. Some smaller companies might feel they
    can only do some of these checks, but the basic idea is to have someone outside
    the design team test it, ensure it meets all rules, and get approval before using
    essential systems.
  prefs: []
  type: TYPE_NORMAL
- en: Effective MRM in Machine Learning means dual scrutiny
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*6\. Change management*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ML systems, like other complex software, have various parts like backend code,
    APIs, and user interfaces. Changes in one component can affect others. Challenges
    like shifting data patterns, new privacy laws, and reliance on third-party software
    make managing these changes crucial. In the early stages of a critical ML system,
    planning for these changes is essential. Without this planning, mistakes, such
    as using data without permission or system mismatches, can occur and might go
    unnoticed until problems arise.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From [cultural competencies](/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf?sk=8ed4f0c5e9624e21d9f6dae9017d5bed)
    to organizational processes, we've explored various aspects that contribute to
    ensuring the safety and performance of machine learning systems. As we've seen,
    forecasting failure modes, meticulous model risk management, and vigilant monitoring
    are key pillars in this journey. Building robust models, maintaining comprehensive
    inventories, and embracing change management are crucial steps toward responsible
    AI. These foundational elements not only ensure the safety and performance of
    the ML systems but also the trust of their users and stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: '***> Read the next article in this series >***'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/bridging-domains-infusing-financial-privacy-and-software-best-practices-into-ml-risk-management-3de1fa1e6dd2?source=post_page-----14f4444dd07f--------------------------------)
    [## Bridging Domains: Infusing Financial, Privacy, and Software Best Practices
    into ML Risk Management'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding strategies that go beyond traditional Model Risk Management
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/bridging-domains-infusing-financial-privacy-and-software-best-practices-into-ml-risk-management-3de1fa1e6dd2?source=post_page-----14f4444dd07f--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: References & Further Reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Preventing Repeated Real-World A.I. Failures by Cataloging Incidents: The
    A.I. Incident Database](https://arxiv.org/pdf/2011.08512.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Overcoming Failures of Imagination in AI-Infused System Development and Deployment](https://arxiv.org/pdf/2011.13416.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning For High-Risk Application, Chapter 1 — Organizational Processes
    for Machine Learning Risk Management](https://www.amazon.in/Machine-Learning-High-Risk-Applications-Responsible/dp/1098102436)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[E.U. Artificial Intelligence Act](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52021PC0206)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[S.R. 11–7 Model risk management guidance](https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
