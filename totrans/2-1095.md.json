["```py\nfrom vllm import LLM, SamplingParams\nmodel = LLM(\"selfrag/selfrag_llama2_7b\", download_dir=\"/gscratch/h2lab/akari/model_cache\", dtype=\"half\")\nsampling_params = SamplingParams(temperature=0.0, top_p=1.0, max_tokens=100, skip_special_tokens=False)\ndef format_prompt(input, paragraph=None):\nprompt = \"### Instruction:\\n{0}\\n\\n### Response:\\n\".format(input)\nif paragraph is not None:\nprompt += \"[Retrieval]<paragraph>{0}</paragraph>\".format(paragraph)\nreturn prompt\nquery_1 = \"Leave odd one out: twitter, instagram, whatsapp.\"\nquery_2 = \"Can you tell me the difference between llamas and alpacas?\"\nqueries = [query_1, query_2]\n# for a query that doesn't require retrieval\npreds = model.generate([format_prompt(query) for query in queries], sampling_params)\nfor pred in preds:\nprint(\"Model prediction: {0}\".format(pred.outputs[0].text))\n```", "```py\nparagraph=\"\"\"Llamas range from 200 to 350 lbs., while alpacas weigh in at 100 to 175 lbs.\"\"\"\n\ndef format_prompt_p(input, paragraph=paragraph):\n  prompt = \"### Instruction:\\n{0}\\n\\n### Response:\\n\".format(input)\n  if paragraph is not None:\n    prompt += \"[Retrieval]<paragraph>{0}</paragraph>\".format(paragraph)\n  return prompt\n\nquery_1 = \"Leave odd one out: twitter, instagram, whatsapp.\"\nquery_2 = \"Can you tell me the differences between llamas and alpacas?\"\nqueries = [query_1, query_2]\n\n# for a query that doesn't require retrieval\npreds = model.generate([format_prompt_p(query) for query in queries], sampling_params)\nfor pred in preds:\n  print(\"Model prediction: {0}\".format(pred.outputs[0].text))\n```", "```py\n[Irrelevant]Whatsapp is the odd one out.\n[No Retrieval]Twitter and Instagram are both social media platforms, \nwhile Whatsapp is a messaging app.[Utility:5]\n\n[Relevant]Llamas are larger than alpacas, with males weighing up to 350 pounds.\n[Partially supported][Utility:5]\n```", "```py\nparagraph=\"\"\"I like Avocado.\"\"\"\ndef format_prompt_p(input, paragraph=paragraph):\n  prompt = \"### Instruction:\\n{0}\\n\\n### Response:\\n\".format(input)\n  if paragraph is not None:\n    prompt += \"[Retrieval]<paragraph>{0}</paragraph>\".format(paragraph)\n  return prompt\n\nquery_1 = \"Leave odd one out: twitter, instagram, whatsapp.\"\nquery_2 = \"Can you tell me the differences between llamas and alpacas?\"\nqueries = [query_1, query_2]\n\n# for a query that doesn't require retrieval\npreds = model.generate([format_prompt_p(query) for query in queries], sampling_params)\nfor pred in preds:\n  print(\"Model prediction: {0}\".format(pred.outputs[0].text))\n```", "```py\nModel prediction: [Irrelevant]Twitter is the odd one out.[Utility:5]\n\n[Irrelevant]Sure![Continue to Use Evidence]\nAlpacas are a much smaller than llamas.\nThey are also bred specifically for their fiber.[Utility:5]\n```"]