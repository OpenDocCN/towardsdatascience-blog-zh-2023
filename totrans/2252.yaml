- en: Use LangChain’s Output Parser with ChatGPT for Structured Outputs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/use-langchains-output-parser-with-chatgpt-for-structured-outputs-cf536f692685](https://towardsdatascience.com/use-langchains-output-parser-with-chatgpt-for-structured-outputs-cf536f692685)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Explained with an example use case.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://sonery.medium.com/?source=post_page-----cf536f692685--------------------------------)[![Soner
    Yıldırım](../Images/c589572e9d1ee176cd4f5a0008173f1b.png)](https://sonery.medium.com/?source=post_page-----cf536f692685--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cf536f692685--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cf536f692685--------------------------------)
    [Soner Yıldırım](https://sonery.medium.com/?source=post_page-----cf536f692685--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cf536f692685--------------------------------)
    ·6 min read·Jun 6, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/54a0133f94d54e24a9aacf811a4d7d6b.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Dmitry Ratushny](https://unsplash.com/@ratushny?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/wpi3sDUrSEk?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT and many other LLMs have led the way for creating LLM-based applications
    in different domains. These models are extremely powerful at processing text inputs
    and creating text outputs based on your queries. However, they’re not designed
    as a development framework.
  prefs: []
  type: TYPE_NORMAL
- en: LangChain is an open-source development framework for applications that use
    large language models (LLMs). It provides abstractions in the form of components
    to use LLMs in a more efficient or programmatic way.
  prefs: []
  type: TYPE_NORMAL
- en: 'These components are:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Models: ChatGPT or other LLMs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Prompts: Prompt templates and output parsers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Indexes: Ingests external data such as document loaders and vector stores'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chains: Combines components to create end-to-end use cases. An example of a
    simple chain can be Prompt + LLM + Output Parser'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Agents: Makes LLMs use external tools'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The main idea behind LangChain is to chain multiple components together to extend
    the abilities of LLM and create more functional tools, or applications.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/78e994de6821ff11587da8f189e06901.png)'
  prefs: []
  type: TYPE_IMG
- en: (image by author)
  prefs: []
  type: TYPE_NORMAL
- en: The developers of LangChain keep adding new features at a very rapid pace. It
    changes the way we interact with LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we will go through an example use case to demonstrate how using
    output parsers with prompt templates helps getting more structured output from
    LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll first do the example using only a prompt template and LLM. Then we’ll
    do the same example but adding an output parser.
  prefs: []
  type: TYPE_NORMAL
- en: Prompt template + LLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Prompt template and an LLM is the simplest chain you can create with LangChain.
  prefs: []
  type: TYPE_NORMAL
- en: Using a prompt template has many advantages over manually customizing prompts
    with f-strings. It allows for reusing prompts when applicable. Also, LangChain
    provides ready-to-use templates for common tasks such as querying a database.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll use OpenAI’s ChatGPT as our LLM so we need to set up an API key.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: For this code to work and set up the API key, you need to create an environment
    variable named OPENAI_API_KEY, which holds the API key you obtained from the [API
    Keys](https://platform.openai.com/account/api-keys) menu on OpenAI website.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with creating a model. `ChatOpenAI` is LangChain’s abstraction for
    ChatGPT API endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: By default, LangChain creates the chat model with a temperature value of 0.7\.
    The `temperature` parameter adjusts the randomness of the output. Higher values
    like 0.7 will make the output more random, while lower values like 0.2 will make
    it more focused and deterministic. We can set its value when creating the model
    instance.
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to create the prompt template. We’ll create a template for
    extracting information from product reviews.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The code snippet above creates a prompt template from the given prompt string.
    The review is saved as an input variable, which can be checked using the `input_variables`
    attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We can now create an actual prompt using this template and a product review.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The `messages` is a Python list that contains the actual prompt. We can see
    the prompt using `messages[0].content` , which outputs the following prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the following review, extract the following information:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'recommended: Does the buyer recommend the product Answer True if yes, False
    if not or unknown.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'delivery_days: How many days did it take for the product to arrive? If this
    information is not found, output -1.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'setup: Extract any sentences about the setup of the product.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Format the output as JSON with the following keys: recommended delivery_days
    setup'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'review: I got this product to plug my internet based phone for work from home
    (Avaya desktop phone). It works! It arrived in 5 days, which was earlier than
    the estimated delivery date. The setup was EXTREMELY easy. At completion, I plugged
    the phone into the extender’s ethernet port and made a few phone calls which all
    worked perfectly with complete clarity. VERY happy with this purchase since a
    cordless headset is around $250 (which I would have needed since the phone had
    to be at the ethernet port on the wall). I recommend this product!'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'We have the model and prompt ready. The next step is to query the model using
    the prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Although the `response` looks like a JSON, it is a string, which makes it difficult
    to parse.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We’ll now learn how to use an output parser together with the prompt template
    to make it easier to parse the output.
  prefs: []
  type: TYPE_NORMAL
- en: Prompt template + LLM + Output Parser
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The output parser is added to the prompt by using the `format_instructions`
    . Let’s go over the process step-by-step.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to import the required modules and define a `ResponseSchema`
    for each piece of information to be extracted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to create the output parser and format instructions using
    these schemas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ll now create the prompt template as we did before. When creating the actual
    prompt, we’ll pass in the `format_instructions` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Let’s use our new prompt to query the model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We used the `parse` method for parsing output. The type of the `output_dict`
    is dictionary, which is much easier than a string to parse. We can extract a particular
    piece of information using the `get` method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Final words
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You may argue that we can use the built-in `json` module to parse string into
    a JSON file and it’s a simple process using the `loads` method. You’re correct!
    It’s easier than creating an output parser and implementing it into a prompt template.
  prefs: []
  type: TYPE_NORMAL
- en: However, there are more complex cases where an output parser simplifies the
    process in a way that cannot be simply done with the built-in `json` module. Also,
    output parser provides additional benefits when working with longer chains with
    different types of modules.
  prefs: []
  type: TYPE_NORMAL
- en: '*You can become a* [*Medium member*](https://sonery.medium.com/membership)
    *to unlock full access to my writing, plus the rest of Medium. If you already
    are, don’t forget to* [*subscribe*](https://sonery.medium.com/subscribe) *if you’d
    like to get an email whenever I publish a new article.*'
  prefs: []
  type: TYPE_NORMAL
- en: Thank you for reading. Please let me know if you have any feedback.
  prefs: []
  type: TYPE_NORMAL
