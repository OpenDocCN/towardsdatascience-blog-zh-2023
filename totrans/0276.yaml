- en: Airflow 2.7 Is Now Out
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/airflow-2-7-0-505f7cda9fd4](https://towardsdatascience.com/airflow-2-7-0-505f7cda9fd4)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Here are the most important feature updates that will make your life easier
    and save you time
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://gmyrianthous.medium.com/?source=post_page-----505f7cda9fd4--------------------------------)[![Giorgos
    Myrianthous](../Images/ff4b116e4fb9a095ce45eb064fde5af3.png)](https://gmyrianthous.medium.com/?source=post_page-----505f7cda9fd4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----505f7cda9fd4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----505f7cda9fd4--------------------------------)
    [Giorgos Myrianthous](https://gmyrianthous.medium.com/?source=post_page-----505f7cda9fd4--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----505f7cda9fd4--------------------------------)
    ·5 min read·Aug 22, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/95857018b07b867da39e2c1abf6d8df6.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated via DALL-E-2 using prompt “data flowing from external system
    into destination system as a system design graph, digital art”
  prefs: []
  type: TYPE_NORMAL
- en: Apache Airflow 2.7.0 is finally out and we are all excited to see all these
    notable features being shipped in this latest release. The new version consists
    of 40 new features, 53 bug fixes, 49 improvements and 15 documentation updates.
  prefs: []
  type: TYPE_NORMAL
- en: The main focus of this release has been security but at the same time, many
    exciting non-security related features have also been made available.
  prefs: []
  type: TYPE_NORMAL
- en: The new Cluster Activity UI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As of Airflow 2.7.0, a new tab is introduced in the top level menu of the Airflow
    UI and is called **Cluster Activity**.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/27e0d7eabb941dfe0463b86345e65170.png)'
  prefs: []
  type: TYPE_IMG
- en: 'New Cluster Activity tab in main Airflow menu — Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: The new Cluster Activity UI gives an overview of the overall cluster state,
    including component health (for MetaDatabase, Scheduler, Triggerer and DAG processor)
    as well as details about DAG/Task run states and DAG run types.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d2a707ee34b801b418698fe63baad245.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The new Cluster Activity UI is shipped as part of the new Airflow 2.7.0 release
    — Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: See when the source code was last parsed
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the past I was really annoyed by the fact that I couldn’t really see whether
    the changes I was making to the source code of a particular DAG were actually
    parsed. I would usually have to refresh the page (multiple times) and start looking
    for the specific areas in the source code that I applied some changes in order
    to ensure that they have been parsed so I can re-trigger the DAG.
  prefs: []
  type: TYPE_NORMAL
- en: The new Airflow version introduces a `Parsed at` field within the Code tab of
    a DAG, indicating the timestamp when the DAG’s source code was last updated.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4022e9dc868f0d9251e108effe21c535.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The new code tab includes a timestamp indicating when the DAG source code was
    last parsed — Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: Simple but yet useful addition!
  prefs: []
  type: TYPE_NORMAL
- en: Keyboard shortcut support
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Airflow Grid view now also supports keyboard shortcuts. Once you enter the Grid
    screen of a DAG, you will notice a note just underneath filtering section, indicating
    that you can access the list of supported shortcuts, by typing `shift` + `/` .
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a3cc8e204c1a16977d4c8003c07c6298.png)'
  prefs: []
  type: TYPE_IMG
- en: 'shift + / Shortcut will list all abailable shortcuts you can use in order to
    interact with Airflow DAGs and Tasks — Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: The actions you can take via keyboard shortcuts include clearing a DAG run and
    marking them as success or failed among others.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b9bf3ddfe05e69e90eb1c9c0b84b90c6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A full list of shortcuts for interacting with Airflow DAGs and Tasks — Source:
    Author'
  prefs: []
  type: TYPE_NORMAL
- en: Graph and Gantt views all in one place
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Gantt and Graph views are now moved into the Grid view of DAGs such that
    it’s easier to navigate between task details, graphs, logs and Gantt views — especially
    when it comes to viewing more complex DAGs.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/135d43aaf0d8f1c2f6378df7d9c21ebe.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Gant and Graph views can now be found under Grid view — Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the old graph view is also removed and the new Graph View is the default
    one.
  prefs: []
  type: TYPE_NORMAL
- en: Setup and Teardown tasks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When designing data pipelines, it’s common to create a resource that is used
    to perform a certain work and then tear it down. The new Airflow release introduced
    setup and teardown tasks that make this pattern feasible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s suppose we have a DAG that creates a compute resource, runs a query and
    finally tears down the previously created resource. Normally, we would have to
    create three tasks and specify the dependencies as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'With the new features, we can now easily mark the first and last tasks as setup
    and teardown respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Notes:'
  prefs: []
  type: TYPE_NORMAL
- en: When `run_query` task is cleared, both `create_resource` (setup) and `delete_resource`
    (teardown) tasks will also be cleared
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When `run_query` fails, the teardown task `delete_resource` will still run
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`create_resource` and `delete_resource` state won’t be used to determing the
    success of a DAG run. This means that the DAG will be marked as success even if
    only `run_query` tasks is successful'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Drops support for end-of-life Python 3.7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Additionally, Airflow 2.7.0 has dropped its support for the end-of-life Python
    3.7\. In order to make use of Airflow 2.7.0, you need to have one of the following
    Python versions:'
  prefs: []
  type: TYPE_NORMAL
- en: '3.8'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '3.9'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '3.10'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: or, 3.11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that Python 3.7 is no longer supported by Python community. If you are
    still using it (even outside the context of Airflow), make sure to upgrade into
    a more recent version.
  prefs: []
  type: TYPE_NORMAL
- en: The `airflow db migrate` command
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `db init` and `db upgrade` commands are now deprecated. Instead, you should
    make use of the `airflow db migrate` command in order to create or upgrade Airflow
    database.
  prefs: []
  type: TYPE_NORMAL
- en: Likewise, `load_default_connections` configuration option is also deprecated.
    In order to create default connections, you need to run `airflow connections create-default-commenctions`
    command, after running `airflow db migrate`.
  prefs: []
  type: TYPE_NORMAL
- en: Handful of security updates
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As mentioned already, the main focus of the latest Airflow release was to make
    it a bit more secure. Here are some security-related changes:'
  prefs: []
  type: TYPE_NORMAL
- en: The test connection functionality is now disabled by default. If you still need
    to enable it, you will either specify the `test_connection` flag in `core` section
    of `airflow.cfg` or by setting up the environment variable `AIRFLOW__CORE__TEST_CONNECTION`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/dags/*/dagRuns/*/taskInstances/*/xcomEntries/*` API endpoint now disables
    the `deserialize` option'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The context now uses Python’s default `default_ssl_contest` context when working
    with SMTP SSL connections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Giving Airflow 2.7 a go
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you would like to test new features out I’d recommend doing so by running
    Airflow via Docker, on your local machine. You can find a step-by-step guide that
    can help you get it up and running in less than a minute in the link below.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/run-airflow-docker-1b83a57616fb?source=post_page-----505f7cda9fd4--------------------------------)
    [## How to Run Airflow Locally With Docker'
  prefs: []
  type: TYPE_NORMAL
- en: A step by step guide for running Airflow with Docker on your local machine
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/run-airflow-docker-1b83a57616fb?source=post_page-----505f7cda9fd4--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Final Thoughts..
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Keeping up with the latest Airflow versions ensures that you get access to the
    latest features as well as to any new security patches so that you won’t keep
    yourself awake at nights.
  prefs: []
  type: TYPE_NORMAL
- en: The very latest Airflow release comes with tons of new features, improvements,
    bug fixes, documentation updates and security patches. It is important to test
    it out and if possible, upgrade your production instances in order to make the
    most out of it while also enhancing security.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we covered only a small subset of the changes introduced in
    Airflow 2.7.0\. You can see the full list of changes shipped as part of the latest
    release, in the [release notes](https://airflow.apache.org/docs/apache-airflow/2.7.0/release_notes.html#airflow-2-7-0-2023-08-14).
  prefs: []
  type: TYPE_NORMAL
- en: 👇**Related articles you may also like** 👇
  prefs: []
  type: TYPE_NORMAL
- en: '[](/airflow-skip-task-a5a6ab319378?source=post_page-----505f7cda9fd4--------------------------------)
    [## How to Skip Tasks in Airflow DAGs'
  prefs: []
  type: TYPE_NORMAL
- en: Skipping tasks in Airflow DAGs based on specific conditions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/airflow-skip-task-a5a6ab319378?source=post_page-----505f7cda9fd4--------------------------------)
    [](https://levelup.gitconnected.com/run-dbt-airflow-b6107d849ddb?source=post_page-----505f7cda9fd4--------------------------------)
    [## How To Run dbt on Airflow
  prefs: []
  type: TYPE_NORMAL
- en: Automated rendering of dbt projects on Apache Airflow
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/run-dbt-airflow-b6107d849ddb?source=post_page-----505f7cda9fd4--------------------------------)
  prefs: []
  type: TYPE_NORMAL
