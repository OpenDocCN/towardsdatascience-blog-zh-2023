- en: Deploy Your Own MLflow Workspace On-Premise with Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/deploy-your-own-mlflow-workspace-on-premise-with-docker-b54294676f0b](https://towardsdatascience.com/deploy-your-own-mlflow-workspace-on-premise-with-docker-b54294676f0b)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Manage the lifecycle of your ML models like a Pro
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://tinztwinspro.medium.com/?source=post_page-----b54294676f0b--------------------------------)[![Janik
    and Patrick Tinz](../Images/a08aa54f553f606ef5df86f9411c36ac.png)](https://tinztwinspro.medium.com/?source=post_page-----b54294676f0b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b54294676f0b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b54294676f0b--------------------------------)
    [Janik and Patrick Tinz](https://tinztwinspro.medium.com/?source=post_page-----b54294676f0b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b54294676f0b--------------------------------)
    ·8 min read·Apr 17, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fa03e98f888a6fd039fc9344664945b8.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Isaac Smith](https://unsplash.com/@isaacmsmith?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '[MLflow](https://mlflow.org) is an **open source platform** to manage the lifecycle
    of ML models end to end. It tracks the code, data and results for each ML experiment,
    which means you have a history of all experiments at any time. A dream for every
    Data Scientist. Moreover, MLflow is **library-agnostic**, which means you can
    use all ML libraries like TensorFlow, PyTorch or scikit-learn. All MLflow functions
    are available via a [REST API](https://mlflow.org/docs/latest/rest-api.html#rest-api),
    [CLI](https://mlflow.org/docs/latest/cli.html), [Python API](https://mlflow.org/docs/latest/python_api/index.html),
    [R API](https://mlflow.org/docs/latest/R-api.html) and [Java API](https://mlflow.org/docs/latest/java_api/index.html).'
  prefs: []
  type: TYPE_NORMAL
- en: As a Data Scientist, you spend a lot of time optimizing ML models. The best
    models often depend on an optimal hyperparameter or feature selection, and it
    is challenging to find an optimal combination. Also, you have to remember all
    experiments, which is very time-consuming. MLflow is an efficient platform to
    address these challenges.
  prefs: []
  type: TYPE_NORMAL
- en: In this post, we briefly introduce the basics of MLflow and show how to set
    up an MLflow workspace on-premise. We set up the MLflow environment in a Docker
    stack so that we can run it on all systems. In this context, we have the services
    Postgres database, SFTP server, JupyterLab and MLflow tracking server UI. Let’s
    start.
  prefs: []
  type: TYPE_NORMAL
- en: MLflow basics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Currently, MLflow offers four components for managing the ML lifecycle. The
    following figure shows an overview.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6322e381f4201221dcd3172e5b3ba394.png)'
  prefs: []
  type: TYPE_IMG
- en: MLflow components overview (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: '**MLflow Tracking** is used to track and query experiments. It tracks the model
    parameters, code, data and model artifacts. In addition, MLFlow’s tracking server
    provides a web UI, which shows the history of all experiments. The MLﬂow library
    already provides the web UI. The tracking server distinguishes between different
    experiments. You can compare your ML models in the experiments by visualising
    the results.'
  prefs: []
  type: TYPE_NORMAL
- en: '**MLflow Project** is a component used for packaging data science code in a
    reusable and reproducible way.'
  prefs: []
  type: TYPE_NORMAL
- en: The **MLﬂow Models** format provides a uniform storage format for ML models
    created with different libraries (e.g. TensorFlow, PyTorch or scikit-learn). The
    uniform format enables deployment in diverse environments.
  prefs: []
  type: TYPE_NORMAL
- en: The **Model Registry** component allows providing of produced models from staging
    to production. It enables the management of ML models in a central model repository.
  prefs: []
  type: TYPE_NORMAL
- en: You can learn more about the components in the [official documentation](https://mlflow.org/docs/latest/index.html)
    or the MLflow [GitHub repo](https://github.com/mlflow/mlflow).
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You will need the following prerequisites:'
  prefs: []
  type: TYPE_NORMAL
- en: The latest version of Docker must be installed on your machine. If you do not
    have it installed yet, please follow the [instructions](https://docs.docker.com/get-docker/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The latest version of Docker Compose must be installed on your machine. Please
    follow the [instructions](https://docs.docker.com/compose/install/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to a terminal (macOS, Linux or Windows).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setup MLflow Workspace
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, you should check that you have Docker and Docker Compose installed correctly.
    Open the terminal of your choice and enter the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: If the installation is correct, you can see the Docker version (Maybe you have
    a different version.). Next, you can check the same for your Docker Compose installation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Yeah. Everything is ok. Now we can start with the MLflow Workspace.
  prefs: []
  type: TYPE_NORMAL
- en: There are [several ways](https://mlflow.org/docs/latest/tracking.html#how-runs-and-artifacts-are-recorded)
    to use MLflow. You can use MLflow with localhost or you deploy a complete stack
    for a production environment. We will focus on the second option in this article.
    We have set up a production-ready MLflow workspace, which we explain in this article.
  prefs: []
  type: TYPE_NORMAL
- en: Please download or clone the [MLflow Workspace](https://github.com/tinztwins/mlflow-workspace)
    from our GitHub repo. The project contains four services, which you can see in
    the following figure.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e93e48a936372041b38426e4f5712a47.png)'
  prefs: []
  type: TYPE_IMG
- en: Various services MLflow Workspace (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: You can start all services by executing the following command in the terminal.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The first time you start it, it takes a while until all the Docker images are
    pulled. It’s the right time to get a coffee. ☕️
  prefs: []
  type: TYPE_NORMAL
- en: After everything has started, please open a web browser of your choice. Next,
    you can access the Jupyter server by entering the following URL [http://127.0.0.1:8888](http://127.0.0.1:8888/)
    into your web browser. You can log in with the password `mlflow`. Next, visit
    the MLflow UI website at [http://127.0.0.1:5001](http://127.0.0.1:5001/). Note
    that we are on localhost. If you run the MLflow Workspace on a remote server,
    please specify the IP address of your server.
  prefs: []
  type: TYPE_NORMAL
- en: You can test the MLflow Workspace by running the notebook `/notebooks/mlflow_example.ipynb`.
    If no error appears, the setup was successful. Congratulations!
  prefs: []
  type: TYPE_NORMAL
- en: 'When you have finished working on a notebook, you can shut down the Workspace.
    The Workspace saves your work persistently so that you can continue working the
    next time. You can shut down the Workspace with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: After we have completed the setup, we can now take a closer look at the individual
    services.
  prefs: []
  type: TYPE_NORMAL
- en: JupyterLab
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This service provides a JupyterLab environment. In the MLflow Workspace, we
    use the [jupyter/scipy-notebook](https://hub.docker.com/r/jupyter/scipy-notebook)
    image from DockerHub. You can also use other Jupyter images if you want. In the
    future, we plan to replace the image with a JuypterHub image so that each Data
    Scientist has their own account. An advantage of this approach is that the accounts
    also communicate with the MLflow tracking server. It allows us a better user management.
    Look forward to more updates on the Workspace.
  prefs: []
  type: TYPE_NORMAL
- en: SFTP Server
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This service provides remote data storage. SFTP (Secure File Transfer Protocol)
    is a file transfer protocol that provides secure access to a remote computer.
    For more information about SFTP, please read the following article.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://levelup.gitconnected.com/set-up-an-sftp-server-with-docker-353fb513ccfd?source=post_page-----b54294676f0b--------------------------------)
    [## Set up an SFTP server with Docker'
  prefs: []
  type: TYPE_NORMAL
- en: Free — Open Source — Secure
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/set-up-an-sftp-server-with-docker-353fb513ccfd?source=post_page-----b54294676f0b--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: In this project, we use the [atmoz/sftp](https://hub.docker.com/r/atmoz/sftp)
    image from DockerHub. You can also use other storage technologies, such as AWS
    S3 or HDFS. In the MLflow Workspace, the SFTP server provides the artifact store.
    In this store, we save the ML models and other artifacts such as Jupyter notebooks
    or Python scripts.
  prefs: []
  type: TYPE_NORMAL
- en: MLflow Tracking Server
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This service provides the MLflow UI. This web UI enables the management of your
    ML experiments. You can also compare different ML models via the web UI. To build
    this service we used the Docker image [python](https://hub.docker.com/_/python).
    The web UI is accessible via [http://127.0.0.1:5001](http://127.0.0.1:5001/).
  prefs: []
  type: TYPE_NORMAL
- en: Postgres database
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This service provides a Postgres database for the backend store. PostgreSQL
    is a free and open-source relational database management system. We use it to
    store parameters and evaluation metrics. The MLflow Workspace uses the official
    [postgres](https://hub.docker.com/_/postgres) Docker image from DockerHub.
  prefs: []
  type: TYPE_NORMAL
- en: The MLflow Workspace is running, and we have understood the basic functionality
    of the services. It’s time to implement a practical example with the Workspace.
  prefs: []
  type: TYPE_NORMAL
- en: Use of the MLflow Workspace
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We explain the functionality of the workspace with a small ML example. In this
    example, we will try to separate the two classes in the [sklearn moon dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html).
    We use the Random Forest as ML model. First, we load the data and visualise it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/96c9b37bb71e27ca0560768aa721b204.png)'
  prefs: []
  type: TYPE_IMG
- en: Moon data (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: You can see that we have two classes. We want to separate these two classes
    with a Random Forest. In addition, we also want to track the metrics and parameters
    of the individual experiments. We achieve this by including MLflow commands in
    our code. You can check out the full code in our [GitHub repo](https://github.com/tinztwins/mlflow-workspace/blob/main/notebooks/examples/logging/logging_example.ipynb).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: After running the code with different parameters for the Random forest model,
    our experiments appear in the web UI.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e0a5fa4af75e3c5b9d1b7601f56ab4dd.png)'
  prefs: []
  type: TYPE_IMG
- en: MLflow tracking UI (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: You can see two runs. Next, we can compare these two runs. To do this, click
    on the checkboxes of the two runs and click on Compare. A new web page opens where
    you can carry out extensive comparisons. The following figure shows an example.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9e99af1090b6dc942c9461608127853e.png)'
  prefs: []
  type: TYPE_IMG
- en: Comparison of two Random Forest runs (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: We see the details for the two runs. MLflow distinguishes the runs via run IDs.
    It also saves the start time, the end time and the duration of the run. The second
    section lists the model parameters. In the first run we used 100 trees, and in
    the second run only two trees. It is practical that you can filter by differences.
    The third section lists all the metrics we tracked. The metrics show that both
    models work similarly well, with the first model performing slightly better. MLflow
    offers many more comparison functions, e.g. you can compare different metrics
    or parameters in graphs (Parallel Coordinates Plot, Scatter Plot, Box Plot and
    Contour Plot). The MLflow Workspace is extremely helpful for Data Scientists because
    it tracks all model combinations with metrics and code. It avoids chaos with many
    experiments, and you always keep an overview.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article we presented a production-ready MLflow Workspace. We briefly
    described the setup with Docker and run an example in the Workspace. In addition,
    we invite all Data Scientists to test the MLflow Workspace so that we can improve
    it continuously. Feedback is always welcome. Write your thoughts in the comments.
    Thanks.
  prefs: []
  type: TYPE_NORMAL
- en: 👉🏽 [**You can find all our Freebies on our digital products page!**](https://shop.tinztwins.de/)
  prefs: []
  type: TYPE_NORMAL
- en: 👉🏽 [**Join our free weekly Magic AI newsletter for the latest AI updates!**](https://magicai.tinztwins.de)
  prefs: []
  type: TYPE_NORMAL
- en: '[**Subscribe for free**](https://tinztwinspro.medium.com/subscribe) **to get
    notified when we publish a new story:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://tinztwinspro.medium.com/subscribe?source=post_page-----b54294676f0b--------------------------------)
    [## Get an email whenever Janik and Patrick Tinz publishes.'
  prefs: []
  type: TYPE_NORMAL
- en: Get an email whenever Janik and Patrick Tinz publishes. By signing up, you will
    create a Medium account if you don’t…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: tinztwinspro.medium.com](https://tinztwinspro.medium.com/subscribe?source=post_page-----b54294676f0b--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Learn more about us on our [About page](https://medium.com/@tinztwinspro/about).
    Don’t forget to follow us on [X](https://twitter.com/tinztwins). Thanks so much
    for reading. If you liked this article, feel free to share it. **Have a great
    day!**
  prefs: []
  type: TYPE_NORMAL
- en: Sign up for a Medium membership using [our link](https://tinztwinspro.medium.com/membership)
    to read unlimited Medium stories.
  prefs: []
  type: TYPE_NORMAL
