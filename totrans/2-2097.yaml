- en: Through the Looking Glass, and What Google find there in the eye
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 透过镜子，谷歌在眼睛中发现了什么
- en: 原文：[https://towardsdatascience.com/through-the-looking-glass-and-what-google-find-there-in-the-eye-e7a836eb9571](https://towardsdatascience.com/through-the-looking-glass-and-what-google-find-there-in-the-eye-e7a836eb9571)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/through-the-looking-glass-and-what-google-find-there-in-the-eye-e7a836eb9571](https://towardsdatascience.com/through-the-looking-glass-and-what-google-find-there-in-the-eye-e7a836eb9571)
- en: '| COMPUTER VISION | AI IN HEALTHCARE | CNN'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '| 计算机视觉 | 医疗AI | CNN'
- en: Or How Google is Using Deep Learning to Diagnose Diseases in Eye Photos
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 或者，谷歌如何利用深度学习来诊断眼部照片中的疾病
- en: '[](https://salvatore-raieli.medium.com/?source=post_page-----e7a836eb9571--------------------------------)[![Salvatore
    Raieli](../Images/6bb4520e2df40d20283e7283141b5e06.png)](https://salvatore-raieli.medium.com/?source=post_page-----e7a836eb9571--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e7a836eb9571--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e7a836eb9571--------------------------------)
    [Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page-----e7a836eb9571--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://salvatore-raieli.medium.com/?source=post_page-----e7a836eb9571--------------------------------)[![Salvatore
    Raieli](../Images/6bb4520e2df40d20283e7283141b5e06.png)](https://salvatore-raieli.medium.com/?source=post_page-----e7a836eb9571--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e7a836eb9571--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e7a836eb9571--------------------------------)
    [Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page-----e7a836eb9571--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e7a836eb9571--------------------------------)
    ·12 min read·Mar 30, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----e7a836eb9571--------------------------------)
    ·阅读时间12分钟·2023年3月30日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/f4f232c4e1c318f5fce9ec857c2775d1.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4f232c4e1c318f5fce9ec857c2775d1.png)'
- en: image by the author using OpenAI DALL-E
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者使用OpenAI DALL-E生成
- en: Google recently published a scientific paper showing how an artificial intelligence
    model is able to predict a number of systemic biomarkers from a simple photo of
    the eye.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌最近发布了一篇科学论文，展示了人工智能模型如何通过一张简单的眼睛照片预测多个系统性生物标志物。
- en: How does it work? How were such results arrived at? Why is it important? We
    discuss this in this article.
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这如何运作？这些结果是如何得出的？这为何重要？我们将在本文中讨论这些问题。
- en: The hidden treasure in the eyes
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 眼睛中的隐藏宝藏
- en: '![](../Images/35db24ac8670c2348b942cd5ebabcba1.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/35db24ac8670c2348b942cd5ebabcba1.png)'
- en: image by [v2osk](https://unsplash.com/it/@v2osk) on Unsplash
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[v2osk](https://unsplash.com/it/@v2osk)提供，来自Unsplash
- en: Diagnosis of disease often requires examinations with expensive instruments
    and then interpretation by a medical professional who is trained. This is not
    always possible. Not all hospitals have the same instruments and sometimes there
    is a shortage of specialists.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 疾病诊断通常需要昂贵仪器的检查，然后由受过训练的医疗专业人员进行解读。这并不总是可行。并非所有医院都有相同的仪器，有时还缺乏专家。
- en: For example, [diabetic retinopathy (DR)](https://en.wikipedia.org/wiki/Diabetic_retinopathy)
    diagnosis requires a fundus camera that examines the back of the eye. This then
    requires it to be analyzed by a highly qualified person. This examination can
    also highlight other conditions such as cardiovascular risk, anemia, chronic kidney
    disease, and other systemic parameters.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，[糖尿病视网膜病变（DR）](https://en.wikipedia.org/wiki/Diabetic_retinopathy)的诊断需要使用检查眼睛后部的眼底相机。这需要由资质高的人员进行分析。此检查还可以揭示其他状况，如心血管风险、贫血、慢性肾病及其他系统性参数。
- en: It was thought that images, of the fundus of the eye, can be analyzed using
    machine learning algorithms. However, [a paper published by Google](https://www.nature.com/articles/s41551-018-0195-0.epdf?author_access_token=YWBi0EzCgfAVb_S540xl-tRgN0jAjWel9jnR3ZoTv0OMsbBDq-7d5VZef-dAA8S4kHGY_hXONc93gwXXjuO908b_ruUDVkgB5jW3RnvvRdLFLmvpTsPku5cXZoTEtr09fPvTK40ZbWzpoOGfLab-NA%3D%3D)
    in 2017 showed that external photographs of the eye can enable the diagnosis of
    diabetic retinal disease and detect poor blood sugar control.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 曾经认为，眼底图像可以使用机器学习算法进行分析。然而，[谷歌发布的一篇论文](https://www.nature.com/articles/s41551-018-0195-0.epdf?author_access_token=YWBi0EzCgfAVb_S540xl-tRgN0jAjWel9jnR3ZoTv0OMsbBDq-7d5VZef-dAA8S4kHGY_hXONc93gwXXjuO908b_ruUDVkgB5jW3RnvvRdLFLmvpTsPku5cXZoTEtr09fPvTK40ZbWzpoOGfLab-NA%3D%3D)在2017年展示了外部眼睛照片能够诊断糖尿病视网膜病变并检测血糖控制不佳。
- en: '![](../Images/63c3f7204bfb6f3869cbebcd9c593a1a.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63c3f7204bfb6f3869cbebcd9c593a1a.png)'
- en: '“Diabetes-related complications can be diagnosed by using specialized cameras
    to take fundus photographs, which visualize the posterior segment of the eye.
    By contrast, anterior imaging using a standard consumer-grade camera can reveal
    conditions affecting the eyelids, conjunctiva, cornea and lens.”. image source:
    [here](https://europepmc.org/article/med/35352000)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: “糖尿病相关并发症可以通过使用专用相机拍摄眼底照片来诊断，这些照片可视化眼睛的后部区域。相反，使用标准消费级相机进行前眼成像可以揭示影响眼睑、结膜、角膜和晶状体的情况。”
    图片来源：[这里](https://europepmc.org/article/med/35352000)
- en: 'In this work, the authors used photos of 145,832 patients with diabetes from
    California and additional cohorts. The authors then used [Inception V3](https://en.wikipedia.org/wiki/Inceptionv3)
    (which had been trained previously on [ImageNet](https://en.wikipedia.org/wiki/ImageNet))
    for this study, showing:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，作者使用了来自加利福尼亚和其他队列的145,832名糖尿病患者的照片。作者然后使用了[Inception V3](https://en.wikipedia.org/wiki/Inceptionv3)（它之前已经在[ImageNet](https://en.wikipedia.org/wiki/ImageNet)上进行过训练）进行这项研究，结果显示：
- en: Our results show that external images of the eye contain signals of diabetes-related
    retinal conditions, poor blood sugar control and elevated lipids. ([source](https://europepmc.org/article/med/35352000))
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们的结果显示，眼睛的外部图像包含糖尿病相关视网膜病变、血糖控制不良和脂质升高的信号。([来源](https://europepmc.org/article/med/35352000))
- en: 'Briefly, the [Inception V3](https://arxiv.org/pdf/1512.00567.pdf) showed at
    the time state-of-the-art performance on ImageNet (accuracy > 78.1 %). Moreover,
    Inception was more computationally efficient than previous models. The model reached
    these results using parallel structures (different types of [convolution](https://en.wikipedia.org/wiki/Convolution)
    layers in the same block) and aggressive [regularization](https://en.wikipedia.org/wiki/Regularization_(mathematics)).
    In the same article, the authors defined some principles that shaped the [convolutional
    neural network](https://en.wikipedia.org/wiki/Convolutional_neural_network) (CNN)
    field for the following years:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，[Inception V3](https://arxiv.org/pdf/1512.00567.pdf) 当时在 ImageNet 上展示了最先进的性能（准确率
    > 78.1%）。此外，Inception 比以前的模型计算效率更高。该模型通过使用并行结构（在同一个块中使用不同类型的[卷积](https://en.wikipedia.org/wiki/Convolution)层）和积极的[正则化](https://en.wikipedia.org/wiki/Regularization_(mathematics))来达到这些结果。在同一篇文章中，作者定义了一些原则，这些原则在接下来的几年里塑造了[卷积神经网络](https://en.wikipedia.org/wiki/Convolutional_neural_network)（CNN）领域：
- en: Avoid representational bottlenecks. The representation size should decrease
    gently from the inputs to the outputs.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免表示瓶颈。表示大小应从输入到输出逐渐减少。
- en: Higher dimensional representations are easier to process locally within a network.
    This showed to allow us to train faster the network.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高维表示在网络内部本地处理起来更容易。这显示出可以更快地训练网络。
- en: Spatial aggregation allows a better reduction of dimension without loss of information
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 空间聚合可以更好地减少维度而不会丢失信息
- en: Balance the width and depth of the network
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平衡网络的宽度和深度
- en: '![](../Images/7a5263c9e49e8ffd7d07d770761d3768.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a5263c9e49e8ffd7d07d770761d3768.png)'
- en: '“A high-level diagram of the model” image source: [here](https://cloud.google.com/tpu/docs/inception-v3-advanced)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: “模型的高层次图示” 图片来源：[这里](https://cloud.google.com/tpu/docs/inception-v3-advanced)
- en: The authors used classical supervised learning, in fact, they used images of
    the patient’s eyes as ground truth whether they had a disease (diabetic retinal
    disease, elevated glucose, or elevated lipids). The model thus trained shows an
    area under the curve (AUC) of more than 80 percent for diabetic retinal disease
    diagnosis and prominent (but lower) results for glucose and lipids.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 作者使用了经典的监督学习，实际上，他们使用了患者眼睛的图像作为是否存在疾病（糖尿病视网膜病、升高的血糖或升高的脂质）的基础真值。因此，训练出的模型在糖尿病视网膜病诊断方面显示出超过80%的曲线下面积（AUC），而对于血糖和脂质则显示出突出的（但较低的）结果。
- en: Results are surprising, because typically these kinds of systemic parameters
    can be derived from the front eye, and instead, this first study showed that from
    photos of the outer eye, the same can be derived through deep learning.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 结果令人惊讶，因为通常这些系统参数可以从前眼得出，而这项初步研究表明，从外眼的照片中，通过深度学习也可以得出相同的结论。
- en: 'In addition, using [ablation studies](https://en.wikipedia.org/wiki/Ablation_(artificial_intelligence))
    and [saliency maps](https://en.wikipedia.org/wiki/Saliency_map) the authors can
    also better understand why the model makes these predictions:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，通过使用[消融研究](https://en.wikipedia.org/wiki/Ablation_(artificial_intelligence))和[显著性图](https://en.wikipedia.org/wiki/Saliency_map)，作者也能更好地理解模型为何做出这些预测：
- en: First, the ablation analysis indicates the centre of the image (pupil/lens,
    iris/cornea and conjunctiva/sclera) is substantially more important than the image
    periphery (for example, eyelids) for all predictions. Second, the saliency analysis
    similarly indicates that the DLS is most influenced by areas near the centre of
    the image. ([source](https://europepmc.org/article/med/35352000))
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 首先，消融分析表明，对于所有预测，图像的中心（瞳孔/晶状体、虹膜/角膜和结膜/巩膜）比图像的周边（例如眼睑）更为重要。其次，显著性分析同样表明，DLS最受图像中心附近区域的影响。（[来源](https://europepmc.org/article/med/35352000)）
- en: '![](../Images/e5c51685f8324c3a4046b59fb3327d1a.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e5c51685f8324c3a4046b59fb3327d1a.png)'
- en: 'Saliency map. image source: [here](https://europepmc.org/article/med/35352000)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 重要性图。图片来源：[这里](https://europepmc.org/article/med/35352000)
- en: '![](../Images/dcf74de03ebebe8ff23339e2601cae14.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dcf74de03ebebe8ff23339e2601cae14.png)'
- en: 'ablation study: Importance of different regions of the image. image source:
    [here](https://europepmc.org/article/med/35352000)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 消融研究：图像不同区域的重要性。图片来源：[这里](https://europepmc.org/article/med/35352000)
- en: These results show that for the growing population of diabetics, some parameters
    can be measured without the need for specialized medical personnel. In addition,
    photos of the outer eye could also be obtained using photos with simple cameras.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果表明，对于日益增长的糖尿病患者群体，一些参数可以在不需要专业医疗人员的情况下进行测量。此外，外眼的照片也可以使用简单相机拍摄获取。
- en: While further work is needed to determine whether there are additional requirements
    for lighting, photography distance or angle, image stabilization, lens quality
    or sensor fidelity, we hope that disease detection techniques via external eye
    images can eventually be widely accessible to patients, whether in clinics, pharmacies
    or even at home. ([source](https://europepmc.org/article/med/35352000))
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 虽然需要进一步工作来确定是否有额外的要求，例如光线、拍摄距离或角度、图像稳定性、镜头质量或传感器保真度，但我们希望通过外眼图像进行疾病检测的技术最终可以广泛提供给患者，无论是在诊所、药店还是在家中。（[来源](https://europepmc.org/article/med/35352000)）
- en: In any case, at present these models are not intended to replace extensive screening
    but rather to signal which patients would benefit from further screening (this
    method is more reliable than a questionnaire).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，目前这些模型并不打算取代广泛筛查，而是用于标识哪些患者需要进一步筛查（这种方法比问卷调查更可靠）。
- en: The authors continued to evaluate the model and drew attention to [potential
    biases and inclusions](https://www.forbes.com/sites/bernardmarr/2022/09/30/the-problem-with-biased-ais-and-how-to-make-ai-better/?sh=1ced823c4770).
    Indeed, one of the biggest problems with artificial intelligence models in the
    biomedical field is that if the dataset is not representative of the general population
    this can lead to misleading results.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 作者们继续评估模型，并引起了对[潜在偏见和包含问题](https://www.forbes.com/sites/bernardmarr/2022/09/30/the-problem-with-biased-ais-and-how-to-make-ai-better/?sh=1ced823c4770)的关注。确实，生物医学领域人工智能模型最大的问题之一是，如果数据集不能代表总体人群，这可能会导致误导性结果。
- en: our development dataset spanned a diverse set of locations within the U.S.,
    encompassing over 300,000 de-identified photos taken at 301 diabetic retinopathy
    screening sites. Our evaluation datasets comprised over 95,000 images from 198
    sites in 18 US states, including datasets of predominantly Hispanic or Latino
    patients, a dataset of majority Black patients, and a dataset that included patients
    without diabetes. We conducted extensive subgroup analyses across groups of patients
    with different demographic and physical characteristics (such as age, sex, race
    and ethnicity, presence of cataract, pupil size, and even camera type), and controlled
    for these variables as covariates. ([source](https://ai.googleblog.com/2022/03/detecting-signs-of-disease-from.html))
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们的开发数据集覆盖了美国范围内多个不同地点，包括在301个糖尿病视网膜病筛查点拍摄的超过300,000张去标识化照片。我们的评估数据集包括来自18个美国州的198个地点的超过95,000张图像，其中包括主要为西班牙裔或拉丁裔患者的数据集、主要为黑人患者的数据集以及包括非糖尿病患者的数据集。我们对不同人口统计学和身体特征（如年龄、性别、种族和民族、白内障存在、瞳孔大小，甚至相机类型）的患者群体进行了广泛的亚组分析，并将这些变量作为协变量进行控制。（[来源](https://ai.googleblog.com/2022/03/detecting-signs-of-disease-from.html)）
- en: The eye, a mirror for the soul
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 眼睛，灵魂的镜子
- en: '![](../Images/b22db7de19e379484e3a775415a6e26a.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b22db7de19e379484e3a775415a6e26a.png)'
- en: image by [Caroline Veronez](https://unsplash.com/it/@carolineveronez) on Unpslash
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Caroline Veronez](https://unsplash.com/it/@carolineveronez)在Unpslash提供
- en: The authors at Google and other researchers also considered promising this approach.
    So they later attempted to extend it to other markers and other diseases.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Google 和其他研究人员也认为这种方法很有前途。因此，他们后来尝试将其扩展到其他标记和其他疾病。
- en: So far, the authors have shown that their model is capable of efficiently diagnosing
    eye diseases (diabetic retinopathy). On the other hand, there are thousands of
    diseases, and diagnosing them is complex (locating the right test, expensive instruments
    not always present, and so on). So the question remains whether the model can
    also capture signs of other diseases in the image of the eye.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，作者已展示他们的模型能够有效诊断眼科疾病（糖尿病视网膜病）。另一方面，疾病种类繁多，诊断复杂（例如，找到合适的测试，昂贵的仪器并不总是存在等等）。因此，问题仍然是模型是否也能捕捉到眼睛图像中的其他疾病迹象。
- en: Can we extend this approach to other diseases?
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们可以将这种方法扩展到其他疾病吗？
- en: After all, deep learning models can recognize patterns that are subtle and perhaps
    difficult for nonexperts to recognize. With these assumptions in mind, [Google
    researchers decided to test](https://www.nature.com/articles/s41551-018-0195-0)
    whether cardiovascular risk factors could be detected in ocular fundus images.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 毕竟，深度学习模型能够识别那些微妙的模式，而这些模式可能对非专家来说难以识别。考虑到这些假设，[Google 研究人员决定测试](https://www.nature.com/articles/s41551-018-0195-0)是否可以在眼底图像中检测心血管风险因素。
- en: Cardiovascular disease is the [leading global cause of death](https://pubmed.ncbi.nlm.nih.gov/32501203/),
    and being able to diagnose it early could save countless lives. In addition, [risk
    stratification](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8299990/) is key
    to identifying and managing groups of patients at risk. Typically, a number of
    variables obtained through medical history and different tests (blood samples
    for glucose and cholesterol levels, age, gender, smoking status, blood pressure,
    and body mass index) are used to diagnose and stratify patients. Sometimes all
    the necessary data are not present ([as shown by a metastudy](https://pubmed.ncbi.nlm.nih.gov/25593051/)).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 心血管疾病是[全球主要死亡原因](https://pubmed.ncbi.nlm.nih.gov/32501203/)，能够早期诊断可能拯救无数生命。此外，[风险分层](https://www.nci.nlm.nih.gov/pmc/articles/PMC8299990/)对于识别和管理高风险患者群体至关重要。通常，通过病史和不同测试（血糖和胆固醇水平的血液样本、年龄、性别、吸烟状态、血压和体重指数）获得的多个变量用于诊断和分层患者。有时所有必要的数据可能并不齐全（[如一项综述研究所示](https://pubmed.ncbi.nlm.nih.gov/25593051/)）。
- en: The authors in this study show that it is possible not only to predict some
    patient characteristics (useful in case some data are not recorded or are missing)
    such as [BMI](https://www.nhlbi.nih.gov/health/educational/lose_wt/BMI/bmicalc.htm),
    age, gender, and smoking status but also parameters associated with cardiovascular
    diseases such as [systolic blood pressure](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1124431/)
    (SBP) and [diastolic blood pressure](https://www.webmd.com/hypertension-high-blood-pressure/guide/diastolic-and-systolic-blood-pressure-know-your-numbers)
    (DBP).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这项研究的作者展示了不仅可以预测一些患者特征（在某些数据未记录或缺失的情况下非常有用），例如[BMI](https://www.nhlbi.nih.gov/health/educational/lose_wt/BMI/bmicalc.htm)、年龄、性别和吸烟状态，还可以预测与心血管疾病相关的参数，例如[收缩压](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1124431/)（SBP）和[舒张压](https://www.webmd.com/hypertension-high-blood-pressure/guide/diastolic-and-systolic-blood-pressure-know-your-numbers)（DBP）。
- en: '![](../Images/4442b4bc8dac94439a3a2321ec8d27f9.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4442b4bc8dac94439a3a2321ec8d27f9.png)'
- en: '“The top left image is a sample retinal image in colour from the UK Biobank
    dataset. The remaining images show the same retinal image, but in black and white.
    The soft attention heat map for each prediction is overlaid in green, indicating
    the areas of the heat map that the neural-network model is using to make the prediction
    for the image.” image source: [here](https://arxiv.org/ftp/arxiv/papers/1708/1708.09843.pdf)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: “左上角的图像是来自英国生物库数据集的彩色视网膜图像样本。其余图像显示的是相同的视网膜图像，但为黑白色。每个预测的软注意力热图以绿色覆盖，指示神经网络模型在进行图像预测时所使用的热图区域。”
    图片来源：[这里](https://arxiv.org/ftp/arxiv/papers/1708/1708.09843.pdf)
- en: The authors have the same Inception V3 model as well. In addition, to deal with
    continuous variables the authors used binning, basically, they divided the variable
    into different segments using different cut-offs (for example, <120, 120–140,
    140–160, and ≥160 for SBP).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 作者们也使用了相同的 Inception V3 模型。此外，为了处理连续变量，作者们使用了分箱技术，基本上是将变量划分为不同的区间，使用不同的分割点（例如，<120，120–140，140–160
    和 ≥160 作为 SBP）。
- en: In addition, the authors used a technique called [soft attention](https://arxiv.org/pdf/1502.03044.pdf)
    to identify regions that are associated with certain features. In short, [soft
    attention](https://arxiv.org/pdf/1507.01053.pdf) is a method that takes into account
    different subregions of the images and uses [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent)
    and [back-propagation](https://en.wikipedia.org/wiki/Backpropagation) (no need
    to implement an attention mechanism in the model).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，作者使用了一种称为[soft attention](https://arxiv.org/pdf/1502.03044.pdf)的技术来识别与特定特征相关的区域。简而言之，[soft
    attention](https://arxiv.org/pdf/1507.01053.pdf)是一种考虑图像不同子区域并使用[梯度下降](https://en.wikipedia.org/wiki/Gradient_descent)和[反向传播](https://en.wikipedia.org/wiki/Backpropagation)的方法（无需在模型中实现注意力机制）。
- en: '![](../Images/fbea3de2132c10d1dc35e7d5c8bd32fa.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fbea3de2132c10d1dc35e7d5c8bd32fa.png)'
- en: 'soft-attention can allow to spot prediction mistakes of the model. image source:
    [here](https://arxiv.org/pdf/1502.03044.pdf)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: soft-attention可以帮助发现模型的预测错误。图像来源：[这里](https://arxiv.org/pdf/1502.03044.pdf)
- en: In another work, the authors tested with [anemia](https://en.wikipedia.org/wiki/Anemia).
    A condition, which afflicts [more than 1.6 billion](https://www.cambridge.org/core/journals/public-health-nutrition/article/worldwide-prevalence-of-anaemia-who-vitamin-and-mineral-nutrition-information-system-19932005/E201EDE33949AF3D632F6596052FCF8F)
    people and requires monitoring [hemoglobin](https://en.wikipedia.org/wiki/Hemoglobin)
    concentration in the blood to be diagnosed (an invasive test,c which can cause
    pain and risk of infection).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一项工作中，作者测试了[贫血](https://en.wikipedia.org/wiki/Anemia)。一种影响[超过16亿](https://www.cambridge.org/core/journals/public-health-nutrition/article/worldwide-prevalence-of-anaemia-who-vitamin-and-mineral-nutrition-information-system-19932005/E201EDE33949AF3D632F6596052FCF8F)人的病症，需要监测[血红蛋白](https://en.wikipedia.org/wiki/Hemoglobin)浓度以进行诊断（这是一种侵入性测试，可能引起疼痛和感染风险）。
- en: '![](../Images/57786f580f3571154ef396c9b0be2162.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/57786f580f3571154ef396c9b0be2162.png)'
- en: 'Prediction of anemia classifications with deep learning. Image source: [here](https://arxiv.org/ftp/arxiv/papers/1904/1904.06435.pdf)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 使用深度学习对贫血分类进行预测。图像来源：[这里](https://arxiv.org/ftp/arxiv/papers/1904/1904.06435.pdf)
- en: In this case, they used [Inception V4](https://arxiv.org/pdf/1602.07261.pdf).
    A later version of the model that was described earlier (in this follow-up article,
    the authors describe that the architecture of Inception V3 can be improved by
    adding [residual connections](https://arxiv.org/pdf/1512.03385.pdf)). Inception
    V4 shows how different types of Inception blocks (in which there are different
    layers of convolution both parallel and sequential) can be tested and used.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，他们使用了[Inception V4](https://arxiv.org/pdf/1602.07261.pdf)。这是一个比之前描述的模型更晚的版本（在这篇后续文章中，作者描述了通过添加[残差连接](https://arxiv.org/pdf/1512.03385.pdf)可以改进Inception
    V3的架构）。Inception V4展示了如何测试和使用不同类型的Inception块（其中有不同的卷积层，既有并行也有顺序）。
- en: '![](../Images/da7f0c17b72ccb25c495b12aa3ef67ac.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/da7f0c17b72ccb25c495b12aa3ef67ac.png)'
- en: '. Residual connections. Image source: [here](https://arxiv.org/pdf/1602.07261.pdf)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 残差连接。图像来源：[这里](https://arxiv.org/pdf/1602.07261.pdf)
- en: In this later work, [Google shows that the approach is not limited to classification](https://www.nature.com/articles/s41551-019-0487-z)
    (patient has anemia or not) but also to whether [hemoglobin concentration](https://www.ncbi.nlm.nih.gov/books/NBK259/)
    can be measured (regression task). The authors train a model for classification
    and one for the [regression task](https://www.sciencedirect.com/topics/computer-science/regression-task)
    (Inception V4 which was pre-trained on ImageNet).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项后续工作中，[Google展示了这种方法不限于分类](https://www.nature.com/articles/s41551-019-0487-z)（患者是否有贫血），还包括是否可以测量[血红蛋白浓度](https://www.ncbi.nlm.nih.gov/books/NBK259/)（回归任务）。作者训练了一个用于分类的模型和一个用于[回归任务](https://www.sciencedirect.com/topics/computer-science/regression-task)的模型（Inception
    V4，预训练于ImageNet）。
- en: For the regression, the authors simply used [mean squared error](https://en.wikipedia.org/wiki/Mean_squared_error)
    as the loss (instead of [cross-entropy](https://en.wikipedia.org/wiki/Cross_entropy)).
    The final predictions were made created an [ensemble](https://en.wikipedia.org/wiki/Ensemble_learning)
    of 10 models (trained in the same manner) and the outputs were averaged to yield
    the final prediction.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于回归问题，作者仅使用了[均方误差](https://en.wikipedia.org/wiki/Mean_squared_error)作为损失函数（而非[交叉熵](https://en.wikipedia.org/wiki/Cross_entropy)）。最终的预测是通过创建一个包含10个模型的[集成](https://en.wikipedia.org/wiki/Ensemble_learning)（以相同方式训练）来实现的，并将这些模型的输出进行平均，以得到最终的预测结果。
- en: '![](../Images/b6ebd0b5261865d71c9f9766c4fc3eab.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b6ebd0b5261865d71c9f9766c4fc3eab.png)'
- en: '“Prediction of hemoglobin concentration. Each blue dot represents each patient’s
    measured hemoglobin concentration and predicted value”. Image source: [here](https://arxiv.org/ftp/arxiv/papers/1904/1904.06435.pdf)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: “预测血红蛋白浓度。每个蓝点代表每位患者的测量血红蛋白浓度和预测值”。图片来源：[这里](https://arxiv.org/ftp/arxiv/papers/1904/1904.06435.pdf)
- en: A glimpse of a wide landscape
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 广阔景观的一瞥
- en: '![](../Images/a30a4162cdd27117d2c7a2577b96dcb2.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a30a4162cdd27117d2c7a2577b96dcb2.png)'
- en: image by [Bailey Zindel](https://unsplash.com/it/@baileyzindel) on Unsplash
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Bailey Zindel](https://unsplash.com/it/@baileyzindel)提供，来源于Unsplash
- en: So far what researchers have observed has been a few parameters at a time. Typically,
    though, a blood test allows them to monitor many more parameters in a single exam.
    **Can a model from a photo of the eye estimate a panel of systemic biomarkers?**
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，研究人员观察到的通常是少量参数。通常，血液检测可以在一次检查中监测更多的参数。**一个眼睛的照片模型能否估计一组系统性生物标志物？**
- en: 'This is what Google tested this year and has just published:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这是谷歌今年测试并刚刚发布的内容：
- en: '[](https://www.thelancet.com/journals/landig/article/PIIS2589-7500%2823%2900022-5/fulltext?source=post_page-----e7a836eb9571--------------------------------)
    [## A deep learning model for novel systemic biomarkers in photographs of the
    external eye: a…'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.thelancet.com/journals/landig/article/PIIS2589-7500%2823%2900022-5/fulltext?source=post_page-----e7a836eb9571--------------------------------)
    [## 一种用于外眼照片中新型系统性生物标志物的深度学习模型：…'
- en: Ocular sequelae resulting from systemic disease have been well documented and
    are the basis for globally established…
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 系统性疾病引起的眼部后遗症已被充分记录，并作为全球公认的基础…
- en: www.thelancet.com](https://www.thelancet.com/journals/landig/article/PIIS2589-7500%2823%2900022-5/fulltext?source=post_page-----e7a836eb9571--------------------------------)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: www.thelancet.com](https://www.thelancet.com/journals/landig/article/PIIS2589-7500%2823%2900022-5/fulltext?source=post_page-----e7a836eb9571--------------------------------)
- en: Obviously, this is not an easy task, partly because when you want to conduct
    such an analysis there is a risk of finding a spurious and erroneous result (also
    called [multiple comparisons problem](https://en.wikipedia.org/wiki/Multiple_comparisons_problem)).
    In other words, the greater the number of statistical inferences conducted at
    the same time, the greater the risk of finding erroneous inferences.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这不是一项容易的任务，部分原因是当你想进行这样的分析时，存在发现虚假和错误结果的风险（也称为[多重比较问题](https://en.wikipedia.org/wiki/Multiple_comparisons_problem)）。换句话说，同时进行的统计推断越多，发现错误推断的风险就越大。
- en: '![](../Images/92c4ef6295751a4647815166d0fd6d2b.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/92c4ef6295751a4647815166d0fd6d2b.png)'
- en: 'example of spurious correlation. image source: [here](https://en.wikipedia.org/wiki/Multiple_comparisons_problem)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 虚假相关的示例。图片来源：[这里](https://en.wikipedia.org/wiki/Multiple_comparisons_problem)
- en: For this reason, the authors first divided the dataset into two parts. They
    trained the model and conducted the analyses on the “development dataset,” selected
    the nine most promising prediction tasks, and evaluated the model on the test
    dataset (they still [corrected for multiple comparisons](https://en.wikipedia.org/wiki/Bonferroni_correction)).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，作者首先将数据集分成两部分。他们在“开发数据集”上训练模型并进行分析，选择了九个最有前景的预测任务，并在测试数据集上评估了模型（他们仍然[纠正了多重比较](https://en.wikipedia.org/wiki/Bonferroni_correction)）。
- en: They first collected a dataset that contained eye images and the results of
    corresponding laboratory tests. The authors then trained a convolutional neural
    network that takes as input an image of the outer eye and predicts clinical and
    laboratory measurements. It is in this case a multitask classification, in which
    there is a prediction head for each task (so that cross-entropy can be used as
    a loss). The authors decided to select cut-offs for each task (selected in consultation
    with clinicians).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 他们首先收集了包含眼睛图像和相应实验室测试结果的数据集。然后，作者训练了一个卷积神经网络，该网络以外眼图像为输入，并预测临床和实验室测量结果。在这种情况下，这是一个多任务分类，每个任务都有一个预测头（以便可以使用交叉熵作为损失）。作者决定为每个任务选择阈值（与临床医生协商后选择）。
- en: The authors, in this case, used Big Transfer (BiT), a model published in 2020
    that when trained generalized well across a range of other datasets. The model,
    in short, is very similar to ResNet, though for training they used some tricks
    such as [Group Normalization](https://arxiv.org/pdf/1803.08494.pdf) (GN) and [Weight
    Standardization](https://arxiv.org/pdf/1405.0312.pdf) (WS). You can find the model
    in this [GitHub repository](https://github.com/google-research/big_transfer).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，作者使用了2020年发布的Big Transfer（BiT）模型，该模型在训练时能够在各种其他数据集上很好地推广。简而言之，该模型与ResNet非常相似，不过在训练过程中使用了一些技巧，例如[组归一化](https://arxiv.org/pdf/1803.08494.pdf)（GN）和[权重标准化](https://arxiv.org/pdf/1405.0312.pdf)（WS）。你可以在这个[GitHub仓库](https://github.com/google-research/big_transfer)中找到该模型。
- en: '![](../Images/24d9d9ab63cdb4ca1f761a1c10e58d66.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/24d9d9ab63cdb4ca1f761a1c10e58d66.png)'
- en: 'Transfer performance of the pre-trained model, beating the state-of-the-art.
    image source: [here](https://arxiv.org/pdf/1912.11370.pdf)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练模型的转移性能超越了现有技术。图像来源：[这里](https://arxiv.org/pdf/1912.11370.pdf)
- en: The outperformed the baseline model (logistic regression on patient data). Although
    these results are still insufficient for the diagnostic application, they are
    in line with initial screening tools ([pre-screening for diabetes](https://www.bmj.com/content/343/bmj.d7163.long)).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 超过了基线模型（对患者数据进行的逻辑回归）。虽然这些结果仍然不足以用于诊断应用，但与初步筛查工具一致（[糖尿病预筛查](https://www.bmj.com/content/343/bmj.d7163.long)）。
- en: '![](../Images/9a1481a4c32a3926055f75c372d02968.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9a1481a4c32a3926055f75c372d02968.png)'
- en: '**Comparison of AUC of the baseline model and the deep learning model. image
    source:** [**here**](https://arxiv.org/ftp/arxiv/papers/2207/2207.08998.pdf)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**基线模型与深度学习模型的AUC比较。图像来源：** [**这里**](https://arxiv.org/ftp/arxiv/papers/2207/2207.08998.pdf)'
- en: In this and the previous study, the authors acquired images using tabletop cameras
    (also using a headrest for the patient) and produced high-quality images under
    good lighting conditions. Therefore, the authors tried to see if the model worked
    by reducing the resolution.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究及之前的研究中，作者使用了桌面相机（患者还使用了头托）获取图像，并在良好的照明条件下生成了高质量的图像。因此，作者尝试通过降低分辨率来查看模型是否有效。
- en: The authors noted that the pattern is robust to image quality, even when images
    are scaled down to 150x150 pixels.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 作者注意到，即使将图像缩小到150x150像素，模式仍然对图像质量具有鲁棒性。
- en: This pixel count is under 0.1 megapixels, much smaller than the typical smartphone
    camera. ([source](https://ai.googleblog.com/2023/03/detecting-novel-systemic-biomarkers-in.html))
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这个像素计数低于0.1百万像素，比典型的智能手机相机要小得多。（[来源](https://ai.googleblog.com/2023/03/detecting-novel-systemic-biomarkers-in.html)）
- en: '![](../Images/4a1892b8042158695500778e524bd56b.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4a1892b8042158695500778e524bd56b.png)'
- en: '“*Effect of input image resolution.* ***Top:*** *Sample images scaled to different
    sizes for this experiment.* ***Bottom****: Comparison of the performance of the
    DLS with image size*”. image source: [here](https://arxiv.org/ftp/arxiv/papers/2207/2207.08998.pdf)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: “*输入图像分辨率的影响。* ***上图：*** *为本实验缩放到不同尺寸的样本图像。* ***下图：*** *DLS在图像尺寸下的性能比较*”。图像来源：[这里](https://arxiv.org/ftp/arxiv/papers/2207/2207.08998.pdf)
- en: In addition, the authors investigated which part of the image is important for
    the purpose of prediction for the model. For this reason, the authors masked several
    regions during both training and evaluation (the pupil or iris, transformed the
    image to black and white)
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，作者研究了图像的哪个部分对模型的预测目的重要。为此，作者在训练和评估期间遮蔽了几个区域（瞳孔或虹膜，将图像转换为黑白）。
- en: Results suggested that the information is generally not isolated to only the
    pupil or iris, and that colour information is at least somewhat important for
    most prediction targets ([source](https://www.thelancet.com/journals/landig/article/PIIS2589-7500(23)00022-5/fulltext#seccestitle160))
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 结果表明，信息通常不仅仅局限于瞳孔或虹膜，并且颜色信息对大多数预测目标至少有一定的重要性（[来源](https://www.thelancet.com/journals/landig/article/PIIS2589-7500(23)00022-5/fulltext#seccestitle160)）
- en: '![](../Images/de4a2ceafc857c6491b9086938795f16.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/de4a2ceafc857c6491b9086938795f16.png)'
- en: 'Experiments masking different image regions or removing colour**.** image source:
    [here](https://arxiv.org/ftp/arxiv/papers/2207/2207.08998.pdf)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 实验遮蔽不同的图像区域或移除颜色**。** 图像来源：[这里](https://arxiv.org/ftp/arxiv/papers/2207/2207.08998.pdf)
- en: As impressive as this article is, it still has limitations. In fact, it is still
    premature to think that it can be used in the real world. First, the photos were
    obtained under optimal conditions, and we need to verify the accuracy with photos
    obtained under other conditions.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这篇文章令人印象深刻，但仍然存在一些局限性。实际上，认为它可以在现实世界中使用仍然为时尚早。首先，照片是在最佳条件下获取的，我们需要验证在其他条件下获取的照片的准确性。
- en: Furthermore, the datasets used in this work consist primarily of patients with
    diabetes and did not have sufficient representation of a number of important subgroups
    — more focused data collection for DLS refinement and evaluation on a more general
    population and across subgroups will be needed before considering clinical use.
    ([source](https://ai.googleblog.com/2023/03/detecting-novel-systemic-biomarkers-in.html))
  id: totrans-95
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 此外，这项工作中使用的数据集主要包括糖尿病患者，并没有充分代表一些重要的亚组——在考虑临床使用之前，需要对DLS的改进和评估进行更加针对性的数据收集，包括对更广泛人群和亚组的评估。（[来源](https://ai.googleblog.com/2023/03/detecting-novel-systemic-biomarkers-in.html)）
- en: Parting thoughts
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析思考
- en: '![](../Images/c7c5a81296fe18f347780466460582b4.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c7c5a81296fe18f347780466460582b4.png)'
- en: image from [Saif71.com](https://unsplash.com/it/@saif71) on Unsplash
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 [Saif71.com](https://unsplash.com/it/@saif71) 在 Unsplash 的图片
- en: As seen in this article, a deep learning model is capable of capturing patterns
    and information in the eye that is sometimes difficult to diagnose. In addition,
    diagnosis is often conducted using expensive tools, and invasive testing, and
    requires experienced personnel. Google has shown over the years that instead,
    it is possible to obtain similar information using the image of the eye.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如本文所示，深度学习模型能够捕捉眼睛中的模式和信息，这些信息有时难以诊断。此外，诊断通常使用昂贵的工具和侵入性测试，并且需要经验丰富的人员。Google多年来已经表明，可以通过眼睛的图像获取类似的信息。
- en: In the future, many diseases could be diagnosed (or at least pre-screened) using
    a simple photo of the outer eye. These photos could be captured simply using a
    cell phone camera. Also, since quantitative results (such as hemoglobin concentration)
    can be obtained, they could be used for noninvasive patient monitoring.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 未来，许多疾病可以通过简单的眼睛外部照片来诊断（或至少进行初步筛查）。这些照片可以通过手机摄像头简单地拍摄。此外，由于可以获得定量结果（如血红蛋白浓度），这些结果可以用于非侵入性的患者监测。
- en: On the technical side, it is interesting how a model such as Incenption V3 achieved
    results on the first attempt. This shows how transfer learning and convolutional
    networks are capable. In addition, the authors adapted the models for both classification
    and regression and multi-tasking classification.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在技术方面，有趣的是像Inception V3这样的模型如何在第一次尝试时就取得了结果。这表明迁移学习和卷积网络的能力。此外，作者对模型进行了分类、回归和多任务分类的适配。
- en: However, there are several scenarios open. Certainly, Google plans to expand
    the dataset (as they wrote in the article). On the other hand, the authors used
    CNN and could also test several other models such as the Vision Transformers.
    Also, it is not excluded that in the future they will experiment with a language
    model that uses patient or doctor’s notes as input (after all, the future is multi-modal).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，还有几个情境是开放的。显然，Google计划扩展数据集（正如他们在文章中所写的）。另一方面，作者使用了CNN，也可以测试其他几种模型，如视觉变换器。此外，未来他们也可能会尝试使用语言模型作为输入，这些输入包括患者或医生的笔记（毕竟，未来是多模态的）。
- en: On the other hand, even though these applications could be used where patients
    do not have equipped hospitals, it also opens up ethical issues. As seen, the
    model is also capable of predicting sensitive data such as age, gender, lifestyle
    (smoking/not smoking), and other parameters. This technology could also be used
    for other, more problematic applications.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，尽管这些应用可以用于没有装备医院的患者，但它也引发了伦理问题。如所见，模型还能够预测诸如年龄、性别、生活方式（吸烟/不吸烟）以及其他参数等敏感数据。这项技术也可能用于其他更具争议的应用。
- en: In any case, these studies open very interesting applications. It is not just
    Google working on such models. For example, other groups have shown that other
    diseases [such as hepatobiliary diseases](https://pubmed.ncbi.nlm.nih.gov/33509389/)
    can be identified from the eye, and [others may be as well](https://pubmed.ncbi.nlm.nih.gov/10758212/)
    in the near future.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，这些研究开启了非常有趣的应用领域。这不仅仅是Google在研究这样的模型。例如，其他团队已经显示，其他疾病[如肝胆疾病](https://pubmed.ncbi.nlm.nih.gov/33509389/)可以通过眼睛识别，[其他疾病也可能](https://pubmed.ncbi.nlm.nih.gov/10758212/)在不久的将来被识别。
- en: 'If you have found this interesting:'
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如果你觉得这很有趣：
- en: You can look for my other articles, you can also [**subscribe**](https://salvatore-raieli.medium.com/subscribe)
    to get notified when I publish articles, and you can also connect or reach me
    on[**LinkedIn**](https://www.linkedin.com/in/salvatore-raieli/)**.**
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以查看我的其他文章，也可以[**订阅**](https://salvatore-raieli.medium.com/subscribe)以便在我发布文章时获得通知，还可以通过[**LinkedIn**](https://www.linkedin.com/in/salvatore-raieli/)**联系**我。
- en: Here is the link to my GitHub repository, where I am planning to collect code
    and many resources related to machine learning, artificial intelligence, and more.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我 GitHub 仓库的链接，我计划在这里收集与机器学习、人工智能等相关的代码和许多资源。
- en: '[](https://github.com/SalvatoreRa/tutorial?source=post_page-----e7a836eb9571--------------------------------)
    [## GitHub - SalvatoreRa/tutorial: Tutorials on machine learning, artificial intelligence,
    data science…'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/SalvatoreRa/tutorial?source=post_page-----e7a836eb9571--------------------------------)
    [## GitHub - SalvatoreRa/tutorial: 关于机器学习、人工智能、数据科学的教程…'
- en: Tutorials on machine learning, artificial intelligence, data science with math
    explanation and reusable code (in python…
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提供关于机器学习、人工智能、数据科学的教程，包括数学解释和可重用的代码（用 Python…
- en: github.com](https://github.com/SalvatoreRa/tutorial?source=post_page-----e7a836eb9571--------------------------------)
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/SalvatoreRa/tutorial?source=post_page-----e7a836eb9571--------------------------------)'
- en: 'or you may be interested in one of my recent articles:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 或许你对我最近的一篇文章感兴趣：
- en: '[](/making-language-models-similar-to-human-brain-b6ea8270be08?source=post_page-----e7a836eb9571--------------------------------)
    [## Making Language Models Similar to the Human Brain'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/making-language-models-similar-to-human-brain-b6ea8270be08?source=post_page-----e7a836eb9571--------------------------------)
    [## 使语言模型更像人脑'
- en: There is still a gap between LMs and the human brain in NLP, inspiring AI to
    the latter could fill it
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 语言模型和人脑在自然语言处理方面仍存在差距，激励人工智能填补这一差距
- en: 'towardsdatascience.com](/making-language-models-similar-to-human-brain-b6ea8270be08?source=post_page-----e7a836eb9571--------------------------------)
    [](/google-med-palm-the-ai-clinician-a4482143d60e?source=post_page-----e7a836eb9571--------------------------------)
    [## Google Med-PaLM: The AI Clinician'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/making-language-models-similar-to-human-brain-b6ea8270be08?source=post_page-----e7a836eb9571--------------------------------)
    [](/google-med-palm-the-ai-clinician-a4482143d60e?source=post_page-----e7a836eb9571--------------------------------)
    [## 谷歌 Med-PaLM：人工智能临床医生
- en: Google's new model is trained to answer medical questions. How?
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 谷歌的新模型经过训练可以回答医学问题。怎么做的？
- en: 'towardsdatascience.com](/google-med-palm-the-ai-clinician-a4482143d60e?source=post_page-----e7a836eb9571--------------------------------)
    [](/multimodal-chain-of-thoughts-solving-problems-in-a-multimodal-world-961a8ab9d0fa?source=post_page-----e7a836eb9571--------------------------------)
    [## Multimodal Chain of Thoughts: Solving Problems in a Multimodal World'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/google-med-palm-the-ai-clinician-a4482143d60e?source=post_page-----e7a836eb9571--------------------------------)
    [](/multimodal-chain-of-thoughts-solving-problems-in-a-multimodal-world-961a8ab9d0fa?source=post_page-----e7a836eb9571--------------------------------)
    [## 多模态思维链：解决多模态世界中的问题
- en: 'The world is not only text: How to extend the chain of thoughts to image and
    text?'
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 世界不仅仅是文字：如何将思维链扩展到图像和文字？
- en: towardsdatascience.com](/multimodal-chain-of-thoughts-solving-problems-in-a-multimodal-world-961a8ab9d0fa?source=post_page-----e7a836eb9571--------------------------------)
    [](https://levelup.gitconnected.com/stable-diffusion-to-fill-gaps-in-medical-image-data-b78a2a7d6c9d?source=post_page-----e7a836eb9571--------------------------------)
    [## Stable diffusion to fill gaps in medical image data
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/multimodal-chain-of-thoughts-solving-problems-in-a-multimodal-world-961a8ab9d0fa?source=post_page-----e7a836eb9571--------------------------------)
    [](https://levelup.gitconnected.com/stable-diffusion-to-fill-gaps-in-medical-image-data-b78a2a7d6c9d?source=post_page-----e7a836eb9571--------------------------------)
    [## 稳定扩散填补医疗图像数据中的空白
- en: A new study shows that stable diffusion could help with medical image analysis
    and rare diseases. How?
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一项新研究表明，稳定扩散可能有助于医学图像分析和稀有疾病。怎么做的？
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/stable-diffusion-to-fill-gaps-in-medical-image-data-b78a2a7d6c9d?source=post_page-----e7a836eb9571--------------------------------)
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[在医疗图像数据中填补空白的稳定扩散](https://levelup.gitconnected.com/stable-diffusion-to-fill-gaps-in-medical-image-data-b78a2a7d6c9d?source=post_page-----e7a836eb9571--------------------------------)'
