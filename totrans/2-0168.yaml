- en: A Business Lens on Precision and Recall
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 精度和召回率的商业视角
- en: 原文：[https://towardsdatascience.com/a-business-lens-on-precision-and-recall-1ce2f5b77eed](https://towardsdatascience.com/a-business-lens-on-precision-and-recall-1ce2f5b77eed)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-business-lens-on-precision-and-recall-1ce2f5b77eed](https://towardsdatascience.com/a-business-lens-on-precision-and-recall-1ce2f5b77eed)
- en: Social media spam as a case study
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 社交媒体垃圾信息作为案例研究
- en: '[](https://mgsosna.medium.com/?source=post_page-----1ce2f5b77eed--------------------------------)[![Matt
    Sosna](../Images/c3175c0dc62b795a8d0fa57532fb669b.png)](https://mgsosna.medium.com/?source=post_page-----1ce2f5b77eed--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1ce2f5b77eed--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1ce2f5b77eed--------------------------------)
    [Matt Sosna](https://mgsosna.medium.com/?source=post_page-----1ce2f5b77eed--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://mgsosna.medium.com/?source=post_page-----1ce2f5b77eed--------------------------------)[![Matt
    Sosna](../Images/c3175c0dc62b795a8d0fa57532fb669b.png)](https://mgsosna.medium.com/?source=post_page-----1ce2f5b77eed--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1ce2f5b77eed--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1ce2f5b77eed--------------------------------)
    [Matt Sosna](https://mgsosna.medium.com/?source=post_page-----1ce2f5b77eed--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1ce2f5b77eed--------------------------------)
    ·18 min read·Dec 22, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1ce2f5b77eed--------------------------------)
    ·阅读时间18分钟·2023年12月22日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/53e528d12045f764f11592bfc30a7e90.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/53e528d12045f764f11592bfc30a7e90.png)'
- en: Photo by [Nong](https://unsplash.com/@californong?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Nong](https://unsplash.com/@californong?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '*Disclaimer: the examples in this post are for illustrative purposes and are
    not commentary on any specific content policy at any specific company. All views
    expressed in this article are mine and do not reflect my employer.*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*免责声明：本帖中的示例仅用于说明目的，并不对任何特定公司或其内容政策发表评论。本文所表达的观点仅代表我个人，不代表我的雇主。*'
- en: Why is there *any* spam on social media? No one aside from the spammers themselves
    enjoys clickbait scams or phishing attempts. We have *decades* of training data
    to feed machine learning classifiers. So why does spam on every major tech platform
    feel inevitable? After all these years, why do bot farms still exist?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么社交媒体上会有*垃圾信息*？除了垃圾信息发送者自己，没有人喜欢点击诱饵骗局或网络钓鱼尝试。我们有*几十年*的训练数据来喂养机器学习分类器。那么为什么每个主要技术平台上的垃圾信息似乎都是不可避免的？经过这么多年，为什么机器人农场依然存在？
- en: '![](../Images/f3742b4bacf2a7a25ac11d479d79b32f.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f3742b4bacf2a7a25ac11d479d79b32f.png)'
- en: Image by author
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: The answer, in short, is that it is *really* hard to fight spam at scale, and
    exponentially harder to do so without harming genuine users and advertisers. In
    this post, we’ll use **precision** and **recall** as a framework for understanding
    the spam problem. We’ll see that eradicating 100% of spam is impractical, and
    that there is some “equilibrium” spam prevalence based on finance, regulations,
    and user sentiment.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，答案是*真正*在大规模上打击垃圾信息是非常困难的，而且在不伤害真实用户和广告商的情况下，这种难度是指数级增长的。在这篇文章中，我们将使用**精度**和**召回率**作为理解垃圾信息问题的框架。我们将看到，彻底消灭100%的垃圾信息是不切实际的，并且存在基于金融、法规和用户情绪的某种“平衡”垃圾信息发生率。
- en: '![](../Images/f7b96d0737462f4897e21748e0555497.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f7b96d0737462f4897e21748e0555497.png)'
- en: Photo by [Joseph Barrientos](https://unsplash.com/@jbcreate_?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Joseph Barrientos](https://unsplash.com/@jbcreate_?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Our app
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们的应用
- en: 'Imagine we’re launching a competitor to TikTok and Instagram. (Forget that
    they have [**1.1 billion**](https://www.demandsage.com/tiktok-user-statistics/)
    and [**2 billion**](https://www.statista.com/statistics/272014/global-social-networks-ranked-by-number-of-users/)
    monthly active users, respectively; we’re feeling ambitious!) Our key differentiator
    in this tight market is that we guarantee users will have only the highest quality
    of videos: absolutely no “get rich quick” schemes, blatant reposts of existing
    content, URLs that infect your computer with malware, etc.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: 'Attempt 1: Human Review'
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To achieve this quality guarantee, we’ve hired a staggering 1,000 reviewers
    to audit every upload before it’s allowed on the platform. **Some things just
    need a human touch**, we argue: video spam is too complex and context-dependent
    to rely on automated logic. A video that urges users to click on a URL could be
    a malicious phishing attempt or a benign fundraiser for Alzheimer’s research,
    for example — the stakes are too high to automate a decision like that.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/96e51619d2cd07f9f82f8faa757104d1.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
- en: Image by author
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: The app launches. To our delight, our “integrity first” message resonates with
    users and they join in droves. We quickly reach millions of users uploading 50,000
    hours of video per day.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: 'In other words, each reviewer now has *50 hours of video to review per day*.
    They try watching at 6x speed to get through all the videos, but they make mistakes:
    users start complaining both that **their benign videos are being blocked *and*
    that spam is making it onto the platform.** We quickly hire more reviewers, but
    as our app grows and the firehose of uploads only gets bigger, we realize we’ll
    bankrupt the company long before we can hire enough eyes. [1] We need a different
    strategy.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: 'Attempt 2: Machine Learning'
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can’t replace a human’s intuition, but maybe we can get close with machine
    learning. Given the tremendous advances in [computer vision](https://www.ibm.com/topics/computer-vision)
    and [natural language processing](https://www.ibm.com/topics/natural-language-processing)
    over the past decade, we can extract **features** from the videos: the pixel similarity
    to existing videos, keywords from the audio, whether the video appears to have
    been [generated with AI](https://www.techtarget.com/searchenterpriseai/definition/generative-AI),
    etc. We can then see how these features relate to whether a video is spam.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/861195ec440efb4768b90d2ab3d3e4a7.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
- en: Image by author
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: 'Determining the relationship between features and spam labels is best left
    to an algorithm. [2] The feature space is simply too large for a human to understand:
    features interact non-linearly, have complex dependencies, are useful in some
    contexts but useless in others, and so on. So we use machine learning to **train
    a classifier that *predicts* whether a video is spam.** Our model takes in a video
    and outputs the probability that the video is spam. [3]'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0731005f62ce0f60cbfa2d9b360ea4da.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0731005f62ce0f60cbfa2d9b360ea4da.png)'
- en: Image by author
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: 'When we first run our classifier on videos we know are spam and benign, we
    hope to see something like below: two distributions neatly separable by their
    probability of being spam. In this ideal state, there is a spam probability threshold
    below which *all videos are benign* and above which *all videos are spam*, and
    we can use that threshold to perfectly categorize new videos.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们首次运行分类器在我们知道是垃圾邮件和正常的视频上时，我们希望看到如下情况：两个分布通过其垃圾邮件概率整齐地分开。在这种理想状态下，存在一个垃圾邮件概率阈值，低于此阈值的*所有视频都是正常邮件*，高于此阈值的*所有视频都是垃圾邮件*，我们可以利用这个阈值来完美地分类新视频。
- en: '![](../Images/4fba261de733d74cfa20d84bdded425d.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4fba261de733d74cfa20d84bdded425d.png)'
- en: Image by author
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: But what we actually see is that **the probability distributions overlap.**
    Yes, the vast majority of benign videos have a low probability and the vast majority
    of spam videos have a high probability. But **there’s an uncomfortable “intermediate”
    spam probability where it’s impossible to tell if a video is spam or benign.**
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们实际看到的是**概率分布重叠**。是的，大多数正常视频的概率较低，大多数垃圾邮件视频的概率较高。但**存在一个不舒服的“中间”垃圾邮件概率，在这个概率下很难判断视频是垃圾邮件还是正常邮件。**
- en: '![](../Images/39dd918daf7b54a8c07e40b3067051f1.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/39dd918daf7b54a8c07e40b3067051f1.png)'
- en: Image by author
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: If we zoom in on where the distributions overlap, it looks something like this.
    Nowhere can we draw a line that perfectly separates benign videos from spam. If
    we set the threshold too high, then spam makes it onto the platform. If we set
    the threshold too low, then benign videos are incorrectly blocked.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们放大分布重叠的地方，情况可能如下。我们无法画出一条完美分隔正常视频和垃圾邮件的视频线。如果我们将阈值设置得太高，垃圾邮件就会进入平台。如果我们将阈值设置得太低，正常视频会被错误地阻止。
- en: '![](../Images/3c5b3df47c311c353dd7883fca805c77.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3c5b3df47c311c353dd7883fca805c77.png)'
- en: Image by author
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: '**So how do we choose a “least-bad” threshold?** To answer this question, we
    need to understand **precision** and **recall**, two metrics that provide a framework
    for navigating the tradeoffs of any classification system. We’ll then revisit
    our app with our new understanding and see if there’s a way to optimally classify
    spam.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**那么我们如何选择一个“最不差”的阈值？** 要回答这个问题，我们需要理解**精确度**和**召回率**，这两个指标为任何分类系统的权衡提供了框架。然后我们将以新的理解重新审视我们的应用，并查看是否有办法来最佳地分类垃圾邮件。'
- en: '![](../Images/3fb2153d0ad6d44ca25e5516269d4bbf.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3fb2153d0ad6d44ca25e5516269d4bbf.png)'
- en: Photo by [Robert Wiedemann](https://unsplash.com/@antilumen?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Robert Wiedemann](https://unsplash.com/@antilumen?utm_source=medium&utm_medium=referral)拍摄，发布在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Evaluation Framework
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估框架
- en: Model Creation
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型创建
- en: Let’s start with a quick overview of how machine learning classifiers are created
    and evaluated, using our spam classifier as an example. The first step when training
    our model is to split our data into ***train*** and ***test*** sets. An algorithm
    then parses the training data to learn the relationship between features and labels
    (spam or benign). The result is a model that can take in the features of a video
    and return the probability it is spam.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速了解一下如何创建和评估机器学习分类器，以我们的垃圾邮件分类器为例。训练模型的第一步是将数据分成***训练***集和***测试***集。然后，算法解析训练数据以学习特征与标签（垃圾邮件或正常）的关系。结果是一个能够接收视频特征并返回其为垃圾邮件的概率的模型。
- en: '![](../Images/84a26d9f398fc5f5bb846a4a8283203e.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/84a26d9f398fc5f5bb846a4a8283203e.png)'
- en: Image by author
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: Probabilities are great, but we need some way to convert numbers like 0.17 or
    0.55 into a decision on whether a video is spam or not. So we binarize the outputted
    probabilities — by default at 0.5 — into *spam* or *benign* classifications. For
    an arbitrary feature in our model, the model’s probability curve (black line)
    and classifications (yellow and green regions) might look like this.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 概率很好，但我们需要一种方法将如0.17或0.55这样的数字转换为是否为垃圾邮件的决策。因此，我们将输出的概率二值化——默认值为0.5——成*垃圾邮件*或*正常邮件*分类。对于模型中的任意特征，模型的概率曲线（黑线）和分类（黄色和绿色区域）可能看起来像这样。
- en: '![](../Images/a26b8e4e1d7e9939b9537c303c4ffc68.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a26b8e4e1d7e9939b9537c303c4ffc68.png)'
- en: Image by author
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: 'Our model is a best effort at understanding the data it was given. But while
    understanding the data *we have* is useful, the real goal is to be able to predict
    the labels for data *we haven’t seen before*, like incoming uploaded videos. [4]
    We measure our model’s ability to do so with the *test* data: feature-label pairs
    that weren’t used to train the model. We feed in the features from our test data,
    see what the model predicts, and compare those predictions to the actual labels.
    (This is why we don’t train the model on all available data: we need some holdout
    labels to audit the model’s predictions.)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型是对所给数据的最佳理解。然而，虽然理解 *我们已有* 的数据是有用的，但真正的目标是能够预测 *我们未见过* 的数据的标签，比如即将上传的视频。[4]
    我们通过 *测试* 数据来衡量模型的能力：这些特征-标签对没有用于训练模型。我们输入测试数据的特征，查看模型的预测，并将这些预测与实际标签进行比较。（这就是为什么我们不对所有可用数据进行训练：我们需要一些保留的标签来审计模型的预测。）
- en: '![](../Images/30d28872caa5f9392fc57ba3a69ec371.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/30d28872caa5f9392fc57ba3a69ec371.png)'
- en: Image by author
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'There are four components to measuring our model’s ability to classify new
    data, based on the four possible outcomes of a prediction:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 基于预测的四种可能结果，有四个组成部分来衡量我们模型分类新数据的能力：
- en: '**True Positive:** the model correctly identifies spam.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真正例：** 模型正确识别垃圾邮件。'
- en: '**False Positive:** the model predicts spam, but the video is benign.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阳性：** 模型预测为垃圾邮件，但视频是良性。'
- en: '**False Negative:** the model predicts benign, but the video is spam.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阴性：** 模型预测为良性，但视频是垃圾邮件。'
- en: '**True Negative:** the model correctly identifies a benign video.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真负例：** 模型正确识别一个良性视频。'
- en: We can arrange these outcomes in a **confusion matrix.** The columns of the
    matrix are the *predicted* spam and benign labels, and the rows are the *actual*
    spam and benign labels.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这些结果排列在 **混淆矩阵** 中。矩阵的列是 *预测* 的垃圾邮件和良性标签，行是 *实际* 的垃圾邮件和良性标签。
- en: '![](../Images/46cd0b5971f558254a0d5c8cf30692d4.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/46cd0b5971f558254a0d5c8cf30692d4.png)'
- en: Image by author
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: We said earlier that our model’s spam probabilities are binarized at 0.5 into
    *spam* and *benign* classifications. But 0.5 isn’t always the best threshold,
    especially if the data is imbalanced. We could set our threshold to any value
    between 0 and 1 to better partition our classifications.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前提到过，我们模型的垃圾邮件概率在 0.5 处被二值化为*垃圾邮件*和*良性*分类。但 0.5 并不总是最佳阈值，尤其是在数据不平衡的情况下。我们可以将阈值设置为
    0 和 1 之间的任何值，以更好地划分分类。
- en: '![](../Images/3620c14defc7401d6c8343ee679221c8.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3620c14defc7401d6c8343ee679221c8.png)'
- en: Image by author
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: '**These thresholds will generate different confusion matrices, reflecting differing
    ability of each model to accurately generalize to new data.** So how we choose
    a threshold? To answer this, we’ll need to review a few metrics.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**这些阈值将生成不同的混淆矩阵，反映每个模型对新数据的准确泛化能力的不同。** 那么我们如何选择一个阈值呢？为了解答这个问题，我们需要回顾一些指标。'
- en: 'Metric 1: Accuracy'
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指标 1：准确性
- en: Our first strategy for finding a metric that produces the best model may be
    to maximize **accuracy:** our model’s ability to detect true positives (TP) and
    true negatives (TN). Accuracy, in other words, is ***the proportion of labels
    that our model correctly predicted***. A model with perfect accuracy would have
    zero false positives (FP) or false negatives (FN).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们寻找最佳模型的第一个策略可能是最大化 **准确性：** 我们模型检测真正例 (TP) 和真负例 (TN) 的能力。换句话说，准确性是 ***我们模型正确预测的标签的比例***。一个具有完美准确性的模型将没有假阳性
    (FP) 或假阴性 (FN)。
- en: '![](../Images/2833cc189f684e2e7d50d07e00b75fc7.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2833cc189f684e2e7d50d07e00b75fc7.png)'
- en: Accuracy is an intuitive metric to start with, but it can hide some blindspots
    in our model. If [one label is far more frequent than the other](https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data),
    for example, our model may struggle to predict the less frequent labels or even
    converge on a nonsensical rule! If our training data was just a random sample
    of uploaded videos, for example, we may end up with 99.9% benign videos and 0.1%
    spam. **A model that always predicts that a video is benign would be 99.9% accurate.**
    That’s not good at all — we’d miss all the videos we want to catch!
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 准确性是一个直观的指标，但它可能掩盖我们模型中的一些盲点。例如，如果 [一种标签远比另一种标签频繁](https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data)，我们的模型可能会难以预测不太频繁的标签，甚至可能收敛到一个无意义的规则上！例如，如果我们的训练数据只是上传视频的随机样本，我们可能会得到
    99.9% 的良性视频和 0.1% 的垃圾邮件。**一个总是预测视频为良性的模型将有 99.9% 的准确率。** 这完全不合格——我们会错过所有我们想要捕捉的视频！
- en: Even with balanced data, we should never rely solely on accuracy when judging
    a model. Let’s look at other metrics that can give us a more holistic picture.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 即使数据平衡，我们在评估模型时也绝不能仅仅依赖准确率。让我们来看一些其他指标，以获得更全面的视角。
- en: 'Metric 2: Recall'
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指标 2：召回率
- en: 'To measure how well our model classified the positive samples in the test set,
    we’ll want to look at our model’s **recall**. Recall is ***the proportion of positive
    labels our model correctly predicted***. In other words:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了衡量我们模型在测试集中对正样本的分类效果，我们需要查看模型的**召回率**。召回率是***模型正确预测的正标签的比例***。换句话说：
- en: '![](../Images/54999bd6f86e63318430209710eb65a4.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/54999bd6f86e63318430209710eb65a4.png)'
- en: 'We can think of this as the top row of the confusion matrix. Recall is the
    number of true positives divided by the total number of *positive labels*: labels
    our model caught (true positives) and missed (false negatives). A model with 100%
    recall is one that correctly classified all positive labels in the test set.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这视为混淆矩阵的顶行。召回率是指真正例的数量与*正标签*总数的比值：模型捕捉到的标签（真正例）和遗漏的标签（假阴性）。一个具有100%召回率的模型是一个在测试集中正确分类所有正标签的模型。
- en: '![](../Images/9ecdd9cf6cbbe9181bb0705e55638496.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9ecdd9cf6cbbe9181bb0705e55638496.png)'
- en: Image by author
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: 'That 99.9% accurate “always predict benign” model would have *zero* recall,
    a glaring red flag indicating the model should be immediately thrown out. Ideally,
    our model is sensitive enough to catch all spam labels in the test set. But to
    ensure this sensitivity doesn’t come at the expense of mis-labeling benign videos,
    we need to look at one more metric: precision.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 那个99.9%准确的“总是预测良性”模型将会有*零*召回率，这是一个明显的红旗，表明该模型应该立即被丢弃。理想情况下，我们的模型应该足够敏感，能捕捉测试集中所有的垃圾邮件标签。但为了确保这种敏感性不会以错误标记良性视频为代价，我们需要查看一个额外的指标：精度。
- en: 'Metric 3: Precision'
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指标 3：精度
- en: 'When our model classifies a video as spam, how often is it *actually* spam?
    This is the core idea behind **precision**, or ***the proportion of predicted
    positive labels that are true positives***. As an equation, precision takes the
    following form:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们的模型将一个视频分类为垃圾邮件时，它*实际*是垃圾邮件的频率如何？这就是**精度**的核心思想，或者说***预测的正标签中真实正例的比例***。作为一个方程，精度呈现以下形式：
- en: '![](../Images/e1b48fd0f8179b9fbd1217f4b076d1fd.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e1b48fd0f8179b9fbd1217f4b076d1fd.png)'
- en: 'We can think of this as the left column of the confusion matrix. Precision
    is the number of true positives divided by the total number of *predictions*:
    those that were correct (true positives) and incorrect (false positives).'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这视为混淆矩阵的左列。精度是指真正例的数量与*预测*总数的比值：包括正确的（真正例）和不正确的（假正例）。
- en: '![](../Images/3c7c3bc78dd80eadee5f0853412bbe7c.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3c7c3bc78dd80eadee5f0853412bbe7c.png)'
- en: Image by author
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: Precision is a crucial metric for understanding how confident we should be when
    our model predicts that a video is spam. When a high-precision model predicts
    that a video is spam, the video is likely spam; if the model has low precision,
    who knows if it’s actually spam unless we look at it ourselves.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 精度是理解当我们的模型预测视频为垃圾邮件时我们应该有多大信心的关键指标。当一个高精度模型预测视频是垃圾邮件时，该视频很可能是垃圾邮件；如果模型精度低，除非我们自己查看，否则无法知道它是否真的垃圾邮件。
- en: It may therefore be tempting to just optimize for precision, maximizing our
    confidence in the model’s predictions. **But the more we prioritize precision,
    the more *conservative* our model will be with labeling videos as spam**, meaning
    we’ll inevitably miss some spam videos that should have been caught.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，可能会有诱惑去优化精度，最大化对模型预测的信心。**但我们越是优先考虑精度，我们的模型在将视频标记为垃圾邮件时就会越*保守***，这意味着我们不可避免地会错过一些应该被捕捉的垃圾邮件视频。
- en: 'To illustrate this, let’s look at that diagram of the overlap of benign and
    spam distributions again. We can binarize our spam probabilities at two thresholds:
    A or B.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这一点，我们再次查看良性和垃圾邮件分布重叠的图示。我们可以在两个阈值下对垃圾邮件概率进行二值化：A或B。
- en: '![](../Images/591ba441bd5d4f0d4e7ba768c370a3b2.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/591ba441bd5d4f0d4e7ba768c370a3b2.png)'
- en: Image by author
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: Every video to the right of threshold B is spam, so a classifier that binarizes
    at that spam probability will have 100% precision. That’s impressive, but that
    threshold misses the two spam videos to the left. Those videos would be incorrectly
    classified benign (false negatives) because our model isn’t confident enough that
    they’re spam. Meanwhile, a model whose cutoff is threshold A would catch those
    spam videos, but it would also mis-label the three benign videos to the right
    (false positives), resulting in lower precision.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 阈值B右侧的每个视频都是垃圾视频，因此在该垃圾概率下进行二分类的分类器将具有100%的精确率。这很令人印象深刻，但该阈值会错过左侧的两个垃圾视频。这些视频将被错误地分类为良性（假阴性），因为我们的模型对它们是否为垃圾视频不够自信。与此同时，阈值A的模型会捕捉到这些垃圾视频，但也会错误地标记右侧的三个良性视频（假阳性），导致精确率降低。
- en: Striking a balance
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 寻找平衡
- en: 'This tradeoff gets at the inherent tension between precision and recall: **when
    we increase our classification threshold, we *increase precision* but *decrease
    recall***. We can redraw our figure to highlight this tradeoff.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这种权衡涉及到精确率和召回率之间的固有矛盾：**当我们提高分类阈值时，我们会*提高精确率*但*降低召回率***。我们可以重新绘制我们的图形以突出这种权衡。
- en: '![](../Images/eb4ab04798c914699eeb53488990a247.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eb4ab04798c914699eeb53488990a247.png)'
- en: Image by author
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Another way to visualize this is to plot precision and recall as a function
    of the classification threshold. Using a classifier I trained on some sample data
    (code at end of post), we can see how precision increases as we increase our threshold
    but recall steadily decreases. The higher our threshold, the more accurate our
    model’s predictions become, but also the more spam videos we miss.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种可视化这种情况的方法是将精确率和召回率绘制为分类阈值的函数。使用我在一些样本数据上训练的分类器（代码在帖子末尾），我们可以看到随着阈值的提高，精确率增加，而召回率稳定下降。阈值越高，我们模型的预测越准确，但也会错过更多的垃圾视频。
- en: '![](../Images/bc019ef7baa1b12786fbfe71ba000802.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bc019ef7baa1b12786fbfe71ba000802.png)'
- en: Image by author
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: So how do we strike a balance? Ultimately, **we must ask whether we’re more
    comfortable with false positives or false negatives, and by how much**. Is it
    worse if some users are incorrectly blocked from uploading videos or if they encounter
    scams on the platform? Is it worth blocking 100 benign videos to prevent 1 spam
    video? 1000 benign videos?
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们如何找到平衡点呢？归根结底，**我们必须问自己，是更倾向于接受假阳性还是假阴性，并且程度如何**。如果一些用户被错误地阻止上传视频，还是他们在平台上遇到诈骗更糟糕？阻止100个良性视频以防止1个垃圾视频是否值得？阻止1000个良性视频呢？
- en: Our app’s main selling point was that users would never see spam videos. To
    achieve 100% recall with our classifier, we’d have to settle for around 45% precision
    — an embarrassingly imprecise model that would result in thousands of benign videos
    being blocked daily. If we were comfortable with only catching 90% of spam, we
    could perhaps get up to 60% precision, but we’d still be blocking far too many
    videos as well as allowing spam through.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用的主要卖点是用户永远不会看到垃圾视频。为了在我们的分类器中实现100%的召回率，我们不得不接受大约45%的精确率——这是一种令人尴尬的不精确模型，将导致每天阻止数千个良性视频。如果我们能接受只捕捉到90%的垃圾视频，我们可能能达到60%的精确率，但我们仍然会阻止过多的视频并允许垃圾信息通过。
- en: Comparing models
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较模型
- en: We go back to the drawing board, digging deep into the data to find better features
    associated with spam. We identify some promising trends and retrain our classifier.
    When we visualize the precision and recall versus classification threshold for
    our two models, we see something like the plot below; the solid lines are the
    old model and the dashed lines are the new.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们回到设计阶段，深入挖掘数据以寻找与垃圾视频相关的更好特征。我们发现了一些有前景的趋势，并重新训练了我们的分类器。当我们可视化两个模型的精确率和召回率与分类阈值的关系时，我们看到如下图所示的情况；实线是旧模型，虚线是新模型。
- en: '![](../Images/0e6a0b7ce7b663811a6ae4233c78a8b3.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0e6a0b7ce7b663811a6ae4233c78a8b3.png)'
- en: Image by author
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: That’s looking a lot better! For most thresholds, the new model is a huge improvement
    in both precision and recall, making our tradeoff discussions more palatable.
    The highest precision we can now get while maintaining 100% recall is roughly
    60%. At 90% recall, we have 85% precision.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来好多了！对于大多数阈值，新模型在精确率和召回率上都取得了巨大的改进，使我们的权衡讨论更加容易接受。现在在保持100%召回率的同时，我们可以获得的最高精确率大约是60%。在90%的召回率下，我们有85%的精确率。
- en: We can summarize our improvement in model fit across all thresholds with **AUC-ROC**,
    or the **Area Under the ROC** (Receiver Operator Characteristic). An ROC curve
    is a plot of the true positive rate (recall) versus the false positive rate (how
    often benign videos are flagged as spam). The area under this curve is 1 if our
    model can perfectly separate benign and spam videos across all thresholds, 0.5
    if it is no better than randomly guessing (the gray dashed line below), and somewhere
    in between otherwise. This one number provides a quick way to show the overall
    improvement in our new model (AUC = 0.96) compared to the old one (AUC = 0.84).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用**AUC-ROC**，即**ROC曲线下面积**，来总结我们在所有阈值上的模型拟合改进。ROC曲线是一个绘制真正例率（召回率）与假正例率（良性视频被标记为垃圾邮件的频率）之间关系的图表。如果我们的模型能在所有阈值下完美区分良性和垃圾邮件视频，则曲线下面积为1；如果模型的效果与随机猜测无异（下方的灰色虚线），则为0.5；否则则介于两者之间。这个数值提供了一种快速展示我们新模型（AUC
    = 0.96）相对于旧模型（AUC = 0.84）整体改进的方式。
- en: '![](../Images/9bff6fe748e9032421c06ce8ced5d6ac.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9bff6fe748e9032421c06ce8ced5d6ac.png)'
- en: Image by author
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: So by any metric, we can celebrate our improved ability to fight spam with our
    new classifier. But we’re left looking uncomfortably at our commitment to absolutely
    zero spam videos on our app. To achieve 100% recall, do we really need to settle
    for 60% precision, barely better than a coin flip, when classifying videos uploaded
    to our app? Do we need to go back to model development, or is there anything else
    we can do?
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，无论用什么指标来衡量，我们都可以庆祝我们通过新的分类器提高了对抗垃圾邮件的能力。但我们仍需面对一个不太舒适的问题：我们的应用中绝对零垃圾邮件的承诺。为了实现100%的召回率，我们是否真的需要在对上传到应用的视频进行分类时接受60%的精确度，这仅比掷硬币稍好？我们是否需要回到模型开发阶段，或者还有其他方法可以尝试？
- en: '![](../Images/92e4404d0d1c9f41f20f048b1ac99f38.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/92e4404d0d1c9f41f20f048b1ac99f38.png)'
- en: Photo by [Rohit Tandon](https://unsplash.com/@sepoys?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Rohit Tandon](https://unsplash.com/@sepoys?utm_source=medium&utm_medium=referral)
    拍摄，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Back to our App
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回到我们的应用
- en: 'Attempt 3: Machine Learning + Human Review'
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 尝试3：机器学习 + 人工审核
- en: If we continue thinking solely in terms of machine learning, we’re going to
    spend a lot of effort chasing diminishing returns. Yes, we can find better features,
    algorithms, and hyperparameters to improve model fit. But if we take a step back,
    we can see that **our classifier is really only one part of a *funnel* for identifying
    spam**, and that we’ll be far more successful investing in *the funnel as a whole*
    rather than just the machine learning portion.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们继续仅仅依赖机器学习的思维方式，我们将花费大量精力去追求递减的收益。是的，我们可以找到更好的特征、算法和超参数来提高模型的拟合度。但如果我们退一步来看，我们会发现**我们的分类器实际上只是识别垃圾邮件的一个*漏斗*的部分**，投资于*整个漏斗*会比仅仅关注机器学习部分更为成功。
- en: 'If we revisit our overlapping spam distribution figure from before, we can
    define three regions of spam probabilities: confidently benign, confidently spam,
    and “not sure.” We just discussed how to use precision and recall to quantify
    the tradeoffs of binarizing that uncertainty region into benign and spam. But
    it doesn’t have to be so black and white if we combine our classifier with those
    human reviewers from before.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们重新审视之前的垃圾邮件分布图，我们可以定义三个垃圾邮件概率区域：确定的良性、确定的垃圾邮件和“不确定”。我们刚刚讨论了如何利用精确度和召回率来量化将这个不确定区域二元化为良性和垃圾邮件的权衡。但如果我们将分类器与之前的人类审核员结合起来，这一切就不再是黑白分明的了。
- en: '![](../Images/71c2d5ce64807a56e81faf6d4215c331.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/71c2d5ce64807a56e81faf6d4215c331.png)'
- en: Image by author
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: What if instead of wringing our hands trying to find the perfect classification
    threshold, we instead set thresholds for the boundaries of that purple region
    above? If our classifier is confident a video is spam or benign, we let it automate
    that decision for us. **But if it’s unsure, we send the video to a human for the
    final decision.**
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不再为寻找完美的分类阈值而苦恼，而是设置上述紫色区域边界的阈值会怎样？如果我们的分类器确信一个视频是垃圾邮件或良性邮件，我们就让它为我们自动决定。**但如果分类器不确定，我们就把视频交给人工来做最终决定。**
- en: '![](../Images/bfd9e4312dfadfad35c9202e6838f82c.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bfd9e4312dfadfad35c9202e6838f82c.png)'
- en: Image by author
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'We now face two precision-recall tradeoffs — the lower and upper thresholds
    of the uncertainty region — but **the stakes for false positives are much lower**:
    rather than risk blocking benign videos outright, we now risk wasting human review
    capacity. (While inefficient, our reviewers won’t complain if they review some
    benign videos, whereas users will quit our app if we incorrectly block enough
    of their videos.)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在面临两个精度-召回权衡——不确定性区域的下限和上限——但**误报的风险要低得多**：我们现在面临的风险是浪费人工审查能力，而不是直接阻止无害视频。（尽管效率低下，我们的审查员不会抱怨审查一些无害视频，而如果我们错误地阻止了足够多的视频，用户会退出我们的应用程序。）
- en: False negatives (letting a spam video through) are still costly, given our app’s
    commitment to quality. So as long as we have human review capacity, we can make
    our uncertainty window as large as possible to ensure as many spam videos are
    caught as possible. But is this enough to assure that no spam videos make it onto
    the platform?
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 假阴性（漏过一个垃圾邮件视频）仍然代价高昂，考虑到我们应用程序对质量的承诺。所以只要我们有人工审查能力，我们可以尽可能扩大我们的不确定性窗口，以确保捕获尽可能多的垃圾邮件视频。但这足够确保没有垃圾邮件视频进入平台吗？
- en: Opportunity costs and adversarial actors
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机会成本和对抗性行为者
- en: The answer, unfortunately, is no. Even when combining the best of machine learning
    and human review, we cannot prevent 100% of spam from entering the platform.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，答案是否定的。即使结合了机器学习和人工审查的最佳方案，我们也不能阻止100%垃圾邮件进入平台。
- en: The first reason, which we covered earlier, is financial. Human review is expensive,
    and we cannot hire enough people to process all videos with an intermediate spam
    probability without bankrupting the company. **Beyond a certain level of investment,
    we both catch marginally less spam and cut into funding for other company initiatives**
    such as new features, market expansion, or customer support. There is also plenty
    of other safety work that needs funding, such as preventing bad actors from hacking
    or impersonating users. At some point, the opportunity costs of other work are
    so high that we can actually have a better app overall if we accept some level
    of spam on the platform.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个原因，我们之前讨论过，是财务问题。人工审查成本高昂，我们无法雇佣足够的人来处理所有中级垃圾邮件概率的视频，而不至于使公司破产。**超出一定投资水平，我们不仅能减少一些垃圾邮件，还会削减其他公司项目的资金**，比如新功能、市场扩展或客户支持。还有许多其他安全工作需要资金，比如防止恶意行为者入侵或冒充用户。在某些情况下，其他工作的机会成本如此之高，以至于如果我们在平台上接受一定程度的垃圾邮件，我们实际上可能会有一个更好的应用程序。
- en: '![](../Images/532440ba402622b1d331db8573d2d1d8.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/532440ba402622b1d331db8573d2d1d8.png)'
- en: Image by author
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: The second reason we can’t prevent 100% of spam is that **our classifier quickly
    becomes outdated as the spam feature space changes**. Spammers are *adversarial*,
    meaning they [change tactics](https://www.zdnet.com/article/facebooks-meta-says-bad-actors-are-changing-tactics-as-it-takes-down-six-more-groups/)
    as soon as companies identify rules to consistently block spam. These bad actors
    are relentless; scamming people is [how they feed their families](https://open.spotify.com/episode/4b5s6nPbU7mE9ZXt8IdqXA?si=3bc062cf88e44b47),
    and they have infinite motivation to find ways to circumvent our defenses.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能阻止100%垃圾邮件的第二个原因是**我们的分类器很快就会过时，因为垃圾邮件特征空间不断变化**。垃圾邮件发送者是*对抗性的*，这意味着他们会[改变战术](https://www.zdnet.com/article/facebooks-meta-says-bad-actors-are-changing-tactics-as-it-takes-down-six-more-groups/)，一旦公司确定了阻止垃圾邮件的规则。这些恶意行为者是无情的；诈骗他人是[他们养家糊口的方法](https://open.spotify.com/episode/4b5s6nPbU7mE9ZXt8IdqXA?si=3bc062cf88e44b47)，他们有无尽的动力找到绕过我们防御的方法。
- en: Cruelly, the features with the highest predictive power often become irrelevant
    as spammers investigate why their content is being blocked and then change their
    approach. The result is a [Red Queen arms race](https://en.wikipedia.org/wiki/Red_Queen_hypothesis)
    between platforms and spammers. If we don’t constantly invest in innovating and
    iterating how we fight spam, spammers will quickly circumvent our defenses and
    overrun our platform with junk. But even with a stellar team of engineers and
    investigators, some spam will make it onto the platform before we can update our
    systems to catch it.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 残酷的是，预测能力最强的特征通常会变得无关紧要，因为垃圾邮件发送者会调查他们的内容为何被阻止，然后改变他们的方法。结果是平台与垃圾邮件发送者之间的[红皇后竞赛](https://en.wikipedia.org/wiki/Red_Queen_hypothesis)。如果我们不不断投资于创新和迭代如何打击垃圾邮件，垃圾邮件发送者会迅速绕过我们的防御，淹没我们的平台。但即使拥有一支优秀的工程师和调查团队，仍然会有一些垃圾邮件在我们更新系统之前进入平台。
- en: Spam equilibrium
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 垃圾邮件平衡
- en: So if we can’t have 0% spam on our platform, where do we end up? The answer
    to this depends on a number of competing factors.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，如果我们无法在平台上实现0%的垃圾邮件，我们会在哪里结束？这个问题的答案取决于许多竞争因素。
- en: '![](../Images/88fc28da33fe08e79eef67c59d49056a.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/88fc28da33fe08e79eef67c59d49056a.png)'
- en: Image by author
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: The first, and potentially strongest force, is regulation. If laws are passed
    that impose severe financial penalties whenever users get scammed on our app,
    the investment equilibrium shifts pretty heavily towards minimizing spam. But
    unless the laws really have some teeth, this force is countered by the opportunity
    cost of not working on other company initiatives (which themselves may have legal
    pressure from their own regulations).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，也是可能最强的力量是监管。如果通过法律，对我们应用程序上用户受骗的情况处以严重的经济罚款，那么投资平衡会大幅向最小化垃圾邮件倾斜。但除非法律真正有约束力，否则这一力量会被未投入其他公司计划的机会成本所抵消（这些计划可能本身也受到自身法规的法律压力）。
- en: The second set of forces comes from users. When spam is noticeable, users get
    angry; there are viral posts about family members losing life savings, users call
    on Congress to reign in our company, users leave or boycott our app. So we spend
    more effort fighting spam, spam prevalence decreases, and users stop complaining.
    But in the absence of this pressure from users, it can be hard to justify increased
    investment when no one notices the results.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 第二组力量来自用户。当垃圾邮件明显时，用户会愤怒；关于家庭成员失去积蓄的病毒式帖子出现，用户呼吁国会制止我们的公司，用户离开或抵制我们的应用程序。因此，我们花更多精力对抗垃圾邮件，垃圾邮件的普遍性降低，用户停止抱怨。但是在没有用户这种压力的情况下，当没有人注意到结果时，很难证明增加投资的必要性。
- en: Finally, there is our company’s internal stance on spam. How much of our company’s
    maximum possible revenue are we willing to lose if it means investing more in
    fighting spam than what’s economically optimal? Spam hurts our business, but so
    does over-investing in fighting it. How far down the diminishing returns are we
    willing to go based on our moral stance on spam?
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这是我们公司对垃圾邮件的内部立场。如果在对抗垃圾邮件的投资超过经济最优水平的情况下，我们愿意损失多少公司最大可能的收入？垃圾邮件对我们的业务造成伤害，但过度投资于对抗垃圾邮件也会造成伤害。基于我们对垃圾邮件的道德立场，我们愿意在收益递减的情况下走多远？
- en: Ultimately, the sum of these forces results in some non-zero (and hopefully
    non-100!) amount of spam on our app. We realize our initial goal with launching
    our app was naïve given the world we live in. But we decide that’s no reason to
    give up, so we build a strong anti-spam team, give them the resources they need,
    and start the never-ending fight for user safety.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，这些力量的总和会导致我们应用程序上出现一些非零（希望不是100%！）的垃圾邮件。我们意识到，启动我们应用程序的初衷在我们所生活的世界里显得有些天真。但是，我们决定这不是放弃的理由，因此我们建立了一个强大的反垃圾邮件团队，为他们提供所需的资源，并开始了对用户安全的无休止的斗争。
- en: '![](../Images/e5f0ddb85b729e14bfa7bf236d7ee107.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e5f0ddb85b729e14bfa7bf236d7ee107.png)'
- en: Photo by [Tim Mossholder](https://unsplash.com/@timmossholder?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Tim Mossholder](https://unsplash.com/@timmossholder?utm_source=medium&utm_medium=referral)
    提供，发布在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Conclusions
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This post used the question of “Why is there any spam on social media?” to explore
    precision, recall, and investment tradeoffs in classification systems. We started
    by covering different approaches to fighting spam (human review and machine learning)
    before discussing ways to quantify what we gain and lose when we set classification
    thresholds. We then discussed the numerous challenges with fighting spam on social
    media.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 本文使用了“为什么社交媒体上会有垃圾邮件？”这个问题来探讨分类系统中的精准度、召回率和投资权衡。我们从讨论对抗垃圾邮件的不同方法（人工审核和机器学习）开始，然后讨论了在设置分类阈值时我们获得和失去的内容。接着，我们讨论了在社交媒体上对抗垃圾邮件的众多挑战。
- en: Again, this post is solely my opinions and is not commentary on any content
    policy at any company. Thanks for reading!
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 再次声明，本文仅代表我的个人观点，并不评论任何公司的内容政策。感谢阅读！
- en: Best,
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳，
- en: Matt
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 马特
- en: Code
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码
- en: Below is the code for generating the data and classifier mentioned in this post.
    The improved classifier was generated by decreasing the standard deviation of
    the random noise during feature generation.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是生成本文中提到的数据和分类器的代码。改进的分类器是通过减少特征生成过程中随机噪声的标准差生成的。
- en: '[PRE0]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Footnotes
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 脚注
- en: '1\. Attempt 1: Human Review'
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 尝试 1：人工审核
- en: To illustrate how impractical 100% human review is, consider YouTube. Users
    upload [**over 500 hours of video every minute**](https://www.statista.com/statistics/259477/hours-of-video-uploaded-to-youtube-every-minute/),
    or **1.8 million hours per day.** Reviewing this number of videos manually would
    require *75,000 reviewers* watching videos 24/7, or *240,000* if reviewers only
    work 8-hour shifts and have a lunch break. Add 1,000 to handle *re-reviewing*
    videos whose creators [claim were incorrectly deleted](https://www.tspa.org/curriculum/ts-fundamentals/content-moderation-and-operations/user-appeals/).
    We’re left with **241,000 reviewers**, or [160% the number of Google employees](https://www.macrotrends.net/stocks/charts/GOOG/alphabet/number-of-employees).
    That’s not going to work.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明100%人工审核的不切实际，可以考虑YouTube。用户每分钟上传[**超过 500 小时的视频**](https://www.statista.com/statistics/259477/hours-of-video-uploaded-to-youtube-every-minute/)，即**每天
    180 万小时**。手动审核这么多视频需要*75,000 名审核员*全天候观看视频，如果审核员每班只工作8小时并有午休，则需要*240,000 名*审核员。再加上1,000名审核员处理*重新审核*那些创作者[声称被错误删除](https://www.tspa.org/curriculum/ts-fundamentals/content-moderation-and-operations/user-appeals/)的视频。我们剩下的就是**241,000
    名审核员**，或者是[Google 员工的160%](https://www.macrotrends.net/stocks/charts/GOOG/alphabet/number-of-employees)。这行不通。
- en: '2\. Attempt 2: Machine Learning'
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 尝试 2：机器学习
- en: Note that machine learning isn’t the only option for fighting spam. There *is*
    a solid use case for hand-crafted deterministic rules for subsets of spam. Something
    like “how often should a user be allowed to post a video?” probably doesn’t need
    a dedicated classifier and could be inferred from a distribution of the number
    of times users post in a day, for example.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，机器学习并不是对抗垃圾邮件的唯一选择。*确实*存在针对垃圾邮件子集的手工确定性规则的有力用例。例如，“用户应该允许多久发布一次视频？”这种问题可能不需要专门的分类器，可以从用户每天发布次数的分布中推断出来。
- en: '3\. Attempt 2: Machine Learning'
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 尝试 2：机器学习
- en: Throughout this post I use the singular “model” or “classifier” to refer to
    our system for catching spam. But spam is a vast, multi-faceted space, so we probably
    actually want an [ensemble](https://en.wikipedia.org/wiki/Ensemble_learning) of
    models, each trained on different subsets of spam. This ensemble approach is how
    [Facebook’s News Feed](https://about.fb.com/news/2021/01/how-does-news-feed-predict-what-you-want-to-see/)
    works. Individual items in Feed are ranked by many models, each outputting a likelihood
    that a user will like the item, or comment on it, or start following the page
    that posted the item, etc.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我使用单数形式的“模型”或“分类器”来指代我们用于捕捉垃圾邮件的系统。但垃圾邮件是一个广泛且多方面的领域，因此我们可能实际上需要一个[集成](https://en.wikipedia.org/wiki/Ensemble_learning)模型，每个模型都在不同的垃圾邮件子集上进行训练。这种集成方法是[Facebook
    新闻推送](https://about.fb.com/news/2021/01/how-does-news-feed-predict-what-you-want-to-see/)的工作原理。Feed中的每个项目都由多个模型排名，每个模型输出用户可能喜欢该项目、评论该项目或开始关注发布该项目的页面等的可能性。
- en: 4\. Evaluation framework
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 评估框架
- en: Modeling just the existing data can be useful, too, but this falls more in the
    realm of business intelligence or data analytics. The goal there is to understand
    our data, but there is not necessarily a *predictive* component of trying to understand
    future data.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅建模现有数据也是有用的，但这更多属于商业智能或数据分析的领域。目标是理解我们的数据，但不一定有*预测*未来数据的组件。
