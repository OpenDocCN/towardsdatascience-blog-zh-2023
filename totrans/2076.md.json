["```py\nfrom datasets import load_dataset\n\nraw_datasets = load_dataset(\"greek_legal_code\", \"chapter\")\n```", "```py\ntraining_corpus = (\n    raw_datasets[\"train\"][i : i + 1000][\"text\"]\n    for i in range(0, len(raw_datasets[\"train\"]), 1000)\n)\n```", "```py\nfrom transformers import AutoTokenizer\n\nold_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n```", "```py\nexample = (\"Μηχανική μάθηση είναι υποπεδίο της επιστήμης των υπολογιστών,\"\n           \" που αναπτύχθηκε από τη μελέτη της αναγνώρισης προτύπων και της\"\n           \" υπολογιστικής θεωρίας μάθησης στην τεχνητή νοημοσύνη. Το 1959,\"\n           \" ο Άρθουρ Σάμουελ ορίζει τη μηχανική μάθηση ως 'Πεδίο μελέτης που\"\n           \" δίνει στους υπολογιστές την ικανότητα να μαθαίνουν, χωρίς να έχουν\"\n           \" ρητά προγραμματιστεί'\")\n\ntokens = old_tokenizer.tokenize(example)\nprint(tokens); print(len(tokens))\n```", "```py\n['μ', '##η', '##χ', '##α', '##ν', '##ι', '##κ', '##η', 'μ', '##α', '##θ', '##η', '##σ', '##η', 'ε', '##ι', '##ν', '##α', '##ι', 'υ', '##π', '##ο', '##π', '##ε', '##δ', '##ι', '##ο', 'τ', '##ης', 'ε', '##π', '##ι', '##σ', '##τ', '##η', '##μ', '##ης', 'τ', '##ω', '##ν', 'υ', '##π', '##ο', '##λ', '##ο', '##γ', '##ι', '##σ', '##τ', '##ω', '##ν', ',', 'π', '##ου', 'α', '##ν', '##α', '##π', '##τ', '##υ', '##χ', '##θ', '##η', '##κ', '##ε', 'α', '##π', '##ο', 'τ', '##η', 'μ', '##ε', '##λ', '##ε', '##τ', '##η', 'τ', '##ης', 'α', '##ν', '##α', '##γ', '##ν', '##ω', '##ρ', '##ι', '##σ', '##ης', 'π', '##ρ', '##ο', '##τ', '##υ', '##π', '##ω', '##ν', 'κ', '##α', '##ι', 'τ', '##ης', 'υ', '##π', '##ο', '##λ', '##ο', '##γ', '##ι', '##σ', '##τ', '##ι', '##κ', '##ης', 'θ', '##ε', '##ω', '##ρ', '##ια', '##ς', 'μ', '##α', '##θ', '##η', '##σ', '##ης', 'σ', '##τ', '##η', '##ν', 'τ', '##ε', '##χ', '##ν', '##η', '##τ', '##η', 'ν', '##ο', '##η', '##μ', '##ο', '##σ', '##υ', '##ν', '##η', '.', 'τ', '##ο', '1959', ',', 'ο', 'α', '##ρ', '##θ', '##ου', '##ρ', 'σ', '##α', '##μ', '##ου', '##ε', '##λ', 'ο', '##ρ', '##ι', '##ζ', '##ε', '##ι', 'τ', '##η', 'μ', '##η', '##χ', '##α', '##ν', '##ι', '##κ', '##η', 'μ', '##α', '##θ', '##η', '##σ', '##η', 'ω', '##ς', \"'\", 'π', '##ε', '##δ', '##ι', '##ο', 'μ', '##ε', '##λ', '##ε', '##τ', '##ης', 'π', '##ου', 'δ', '##ι', '##ν', '##ε', '##ι', 'σ', '##τ', '##ου', '##ς', 'υ', '##π', '##ο', '##λ', '##ο', '##γ', '##ι', '##σ', '##τ', '##ε', '##ς', 'τ', '##η', '##ν', 'ι', '##κ', '##α', '##ν', '##ο', '##τ', '##η', '##τ', '##α', 'ν', '##α', 'μ', '##α', '##θ', '##α', '##ι', '##ν', '##ου', '##ν', ',', 'χ', '##ω', '##ρ', '##ι', '##ς', 'ν', '##α', 'ε', '##χ', '##ου', '##ν', 'ρ', '##η', '##τ', '##α', 'π', '##ρ', '##ο', '##γ', '##ρ', '##α', '##μ', '##μ', '##α', '##τ', '##ι', '##σ', '##τ', '##ε', '##ι', \"'\"]\n274\n```", "```py\ntokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 50000)\n```", "```py\ntokens = tokenizer.tokenize(example)\nprint(tokens); print(len(tokens))\n```", "```py\n['μηχανικη', 'μαθη', '##ση', 'ειναι', 'υποπε', '##διο', 'της', 'επιστημης', 'των', 'υπολογιστων', ',', 'που', 'αναπτυχ', '##θηκε', 'απο', 'τη', 'μελετη', 'της', 'αναγνωρισης', 'προτυπων', 'και', 'της', 'υπολογισ', '##τικης', 'θεωριας', 'μαθησης', 'στην', 'τεχνητη', 'νοη', '##μοσυνη', '.', 'το', '1959', ',', 'ο', 'αρθ', '##ουρ', 'σαμου', '##ελ', 'οριζει', 'τη', 'μηχανικη', 'μαθη', '##ση', 'ως', \"'\", 'πεδιο', 'μελετης', 'που', 'δινει', 'στους', 'υπολογιστες', 'την', 'ικανοτητα', 'να', 'μα', '##θαι', '##νου', '##ν', ',', 'χωρις', 'να', 'εχουν', 'ρητα', 'προγραμματισ', '##τει', \"'\"]\n67\n```"]