- en: 'Text Pattern Extraction: Comparing GPT-3 & Human-in-the-Loop Tool'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/text-pattern-extraction-comparing-gpt-3-human-in-the-loop-tool-f2380fd13cf1](https://towardsdatascience.com/text-pattern-extraction-comparing-gpt-3-human-in-the-loop-tool-f2380fd13cf1)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Preliminary experiments and results from comparing LLMs and human-in-the-loop
    tools for text pattern extraction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://maeda-han.medium.com/?source=post_page-----f2380fd13cf1--------------------------------)[![Maeda
    Hanafi](../Images/c1ceef15ccbe82a5b8655593d685db74.png)](https://maeda-han.medium.com/?source=post_page-----f2380fd13cf1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f2380fd13cf1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f2380fd13cf1--------------------------------)
    [Maeda Hanafi](https://maeda-han.medium.com/?source=post_page-----f2380fd13cf1--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f2380fd13cf1--------------------------------)
    ·10 min read·Jan 26, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3c44a30478df4c48cb757c512b575935.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Aaron Burden](https://unsplash.com/@aaronburden?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/nDeo4F3Zq28?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: In the past years, AI garnered a lot of interest in several industrial applications.
    End-users such as doctors, analysts, and journalists want to build AI models for
    their specific use cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the workflow of building AI models requires technical expertise that
    end-users may not necessarily have:'
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the data, such as extracting, cleaning, and transforming the training
    data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training the AI model, which includes finetuning parameters and retraining layers
    of the model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/5862ab47b5a9c4c07d14c3f881ecef5f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Motivation: enabling end users to build AI models. Image by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: An end-user is likely to apply existing tools ***out-of-the-box***. There are
    several tools applicable for end-users to build AI models out-of-the-box.
  prefs: []
  type: TYPE_NORMAL
- en: Recently, a class of tools called human-in-the-loop (HITL) tools aims to lower
    the barrier of entry for building AI models for end-users. The “human-in-the-loop”
    incorporates human knowledge in the process of model building. It is essentially
    a framework for human-computer collaboration for the task at hand. In this framework,
    there is a continuous feedback between model building and user input.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, there are the popularly researched models in AI, namely the
    large generative language models such as GPT-3, OPT, BLOOM, etc. Language models
    are trained on large datasets and have incredible language understanding capabilities.
    The scale of these models is in the hundreds of millions of parameters, and they
    have been proven great *few-shot* performance (meaning they have been given a
    handful of inputs) for several natural language processing tasks, e.g. extraction,
    classification, etc.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/60f6e8dc6bae212b3e9b4343a1d141a5.png)'
  prefs: []
  type: TYPE_IMG
- en: Existing work. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: We want to understand how these popularly researched large language models perform
    against human-in-the-loop tools, in the context of enabling end-users to build
    AI models. *In our experiments, we mimic how an end-user or a business user, someone
    who does not have much technical training, might use these tools to perform text
    pattern extraction tasks.* In this brief blog post, I want to talk about a couple
    of experiments from our work at IBM where we compare human-in-the-loop systems
    with large language models for pattern extraction tasks. We presented this work
    at DaSH@EMNLP 2022, and you can find [the paper here](https://aclanthology.org/2022.dash-1.7/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, we looked into the following tools:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pattern Induction** is a HITL tool for text pattern extraction on IBM Watson
    Discovery'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GPT-3** is a popular large generative language model. GPT-3 is one of the
    largest of the large language models with 175 billion parameters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/ccb50b60ff825ecbc2b2a849f987ae4a.png)'
  prefs: []
  type: TYPE_IMG
- en: The goal of our comparison work. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Text pattern extraction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is text pattern extraction? Below, we have a scenario where we have a collection
    of financial press releases and we need to extract the fiscal time periods. We
    want extractions such as “2014 first-quarter” and “fourth-quarter of 2013”. Notice
    that the fiscal time periods can have the year appear at the beginning of the
    extraction or at the end of the extraction, and the quarter varies with it either
    being “first”, “second”, “third”, or “fourth”.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/996c313fa5129d1351e11a99b28389ba.png)'
  prefs: []
  type: TYPE_IMG
- en: Text pattern extraction. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Text Pattern Extraction with Pattern Induction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pattern Induction is available on IBM Watson Discovery. It is a HITL tool for
    text pattern extraction. The end-user extracts text patterns by providing feedback.
    The tool does not require any coding and the user does not need to provide a large
    training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pattern Induction supports two user actions:'
  prefs: []
  type: TYPE_NORMAL
- en: End-users highlight examples of text that they wish to extract.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: End-users also provide feedback to the system’s extractions. The user accepts
    or rejects these extractions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For our experiments, we ran a user simulation by simulating the two user actions:
    (1) highlighting example texts, and (2) providing feedback.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/10eaa83cfdf4b30015c6f5e5b37ba658.png)'
  prefs: []
  type: TYPE_IMG
- en: Evaluate the HITL tool by simulating the user actions. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the backend, Pattern Induction learns *extraction rules*. Think of them
    as something similar to regular expressions: an expression that describes patterns
    over a sequence of tokens, or words.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6a337ac23048b501216414bdb11b006c.png)'
  prefs: []
  type: TYPE_IMG
- en: Pattern induction flow & underlying rule model. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Text Pattern Extraction with GPT-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While the end-user would provide text highlights and feedback in Pattern Induction,
    completing text extraction tasks in GPT-3 requires crafting an input prompt, and
    GPT-3 outputs a *completion text*, which we expect to contain the extracted texts.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8aacfbfe400216c1cfbed505e5a4a651.png)'
  prefs: []
  type: TYPE_IMG
- en: The naive, basic way of prompting GPT-3 for text pattern extraction. Image by
    Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we need to extract ISO numbers such as “ISO 18788” or “ISO 223000”
    from a dataset of reports. In the above image, we have an input prompt that is
    crafted as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The first part of the input prompt is the sentence from the dataset we want
    to extract from. We put this sentence in between square brackets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second part of the prompt contains the example extractions in list form,
    where each example extraction is placed in between the bar character, “|”.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The format of the input prompt is used to show and demonstrate to GPT-3 what
    kinds of text we want to extract from the sentence. In the above example, GPT-3
    completes the text with its output, “ISO 9001” from the sentence. The above input
    prompt is a rather naïve approach and it mimics how an end-user might construct
    a prompt. Constructing a prompt requires some level of engineering, and a whole
    sub-field of research is dedicated to prompt engineering.
  prefs: []
  type: TYPE_NORMAL
- en: Prompts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0d8740fc0ab58ee3243de934e2a65f83.png)'
  prefs: []
  type: TYPE_IMG
- en: Experimented with a handful of different input formats. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many ways of formatting the input prompt. We experimented with a
    couple of formattings:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Basic prompts**: mimics how an end-user who may not have much technical expertise
    may craft a prompt.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Structured prompts**: instead of listing the extraction examples, each extraction
    example is paired with a sentence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/998c937acea0e78f8b28dc1818128e91.png)'
  prefs: []
  type: TYPE_IMG
- en: Structured Prompts. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: '**Structured prompts with additional and negative examples:** In the last type
    of prompt, we added both additional examples and negative examples. In Pattern
    Induction, users were able to accept and reject extractions. In GPT-3 we added
    those types of extractions as additional examples.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/edff1ed0cd87cfc9e4f8c3399a7f2c1f.png)'
  prefs: []
  type: TYPE_IMG
- en: Structured prompts with negative examples. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: To read more about the specifics of the input prompt format, refer to the [paper
    here](https://aclanthology.org/2022.dash-1.7/).
  prefs: []
  type: TYPE_NORMAL
- en: Post-processing GPT-3’s outputs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the major challenges with using GPT-3 for text pattern extraction was
    how it sometimes got creative with its outputs. This is a common occurrence with
    GPT-3, given its text generation capabilities. GPT-3’s extracted texts are not
    always a part of the document dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7d04884bb49171756c4367f9b03e0fcf.png)'
  prefs: []
  type: TYPE_IMG
- en: GPT-3 outputs creative texts. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: In one of the use cases, we wanted to extract percentages of criminal incidents
    from crime reports, such as percentages of “crimes against property” or percentages
    of “crimes against persons”. But GPT-3 generates percentages about other topics
    such as race or gender, e.g. “0.6 percent were American Indian or Alaska Native”.
    This text did not even appear in the dataset, which negatively affected the precision
    scores. So we post-processed all of the outputs from GPT-3\. The post-processing
    step included cleaning the output text (removing delimiters) and removing outputs
    that were not part of the document dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Experimental Setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are the details for our experimental setup for comparing GPT-3 against
    Pattern Induction:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/29f68d7572a783f93de94c60d43c1e71.png)'
  prefs: []
  type: TYPE_IMG
- en: Experiment Setup with User Simulations. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'The user simulation was run on both Pattern Induction and GPT-3\. Each tool
    was given 7 use case tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/12c948f71ff2a5257d2930ba9c07585e.png)'
  prefs: []
  type: TYPE_IMG
- en: Use case tasks we gave to GPT-3 and Pattern Induction. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: The user simulation recorded the precision and recall of each run.
  prefs: []
  type: TYPE_NORMAL
- en: GPT-3 Experiments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/ee285086ec3134b1c8edd8918652a609.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: During our evaluations for GPT-3, we used the same seed examples that the user
    simulation would use as highlighted texts in Pattern Induction. The seed examples
    were taken from the logs of the Pattern Induction user simulations, and then those
    seed examples were used in the input prompt for GPT-3\. This was to make it comparable
    to the Pattern Induction runs. We also split the documents into partials due to
    a limit on the number of tokens the input prompt can have in GPT-3 (around 4K
    tokens).
  prefs: []
  type: TYPE_NORMAL
- en: 'Results: precision scores'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We calculated the average precision, which was an aggregate over the 100 user
    simulation runs for each of the 7 use cases. The results show that GPT-3 precision
    scores are lower than Pattern Induction’s precision scores (green line with the triangular marks):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0d9f6e0c285419e70b2c242a834dca1b.png)'
  prefs: []
  type: TYPE_IMG
- en: GPT-3 precision scores are lower than Pattern Induction’s. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: There are several lines on the chart for GPT-3, where each one belongs to some
    different variation of formatting the input prompt. While varying formats of input
    prompt improved the precision scores, GPT-3 did not beat the HITL precision scores
    on average. Overall, **precision-wise, Pattern Induction is on average 38.8% better
    than the best GPT-3 model** (structured prompting with additional examples).
  prefs: []
  type: TYPE_NORMAL
- en: 'Results: recall scores'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We also calculated the average recall, which is the aggregate over the 100 user
    simulation runs for each of the 7 use case tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/050b41d6ef7406f67112d4c9d1d4ac17.png)'
  prefs: []
  type: TYPE_IMG
- en: GPT-3 recall scores are similar and higher. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Overall, **recall-wise, Pattern Induction is on average 4.0% better than the
    best GPT-3 model.** However, when the recall scores are analyzed per use case
    task, we notice that the GPT-3 runs have either similar or even higher recall
    scores than the Pattern Induction runs:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Tasks U1, U3, U4: In these tasks the expected extractions don’t abide by some
    syntactic pattern. For instance, Task U3, requires extractions regarding different
    crime types, e.g. “crimes against property”, “crimes against persons”. Or, Task
    U4 requires extractions of measuring cups of both integer and fractional types.
    These tasks extract *concepts* and GPT-3 does pretty well with these tasks. GPT-3
    understands that some words refers to concepts and entities such as countries,
    crime types, or integer and fractional quantities. **GPT-3 understands concepts
    in text very well.**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/6721cbcee53eefab344b4f57758ba403.png)'
  prefs: []
  type: TYPE_IMG
- en: GPT-3 understands concepts in text very well. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Tasks U2, U5, U6, U7: On the other hand, we see that tasks with stricter, syntactic
    patterns are handled better with Pattern Induction. For instance, in Task U2,
    we wanted to extract counts of incidents. The literal “incidents” constantly appear
    at the end of a 6-digit integer. This pattern is for all expected extractions.
    Such tasks are more syntactic and **Pattern Induction on average performs better
    for extraction tasks that have stricter, syntactic patterns.** And this makes
    sense since the underlying Pattern Induction model is rule-based.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/9896e83ce41c7e719b20d2830a158bc0.png)'
  prefs: []
  type: TYPE_IMG
- en: Pattern Induction learns stricter patterns better. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Improving prompt format improved recall scores
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One other key thing we observed in only the GPT-3 runs is that improving the
    input prompt format improves the recall score.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4c50c06640cee4d2c87790b5da34a070.png)'
  prefs: []
  type: TYPE_IMG
- en: Structured prompting improved recall scores. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: From the above chart, moving from basic prompting scores (orange line) to the
    structured prompting scores (yellow line), the **recall score increased on average
    by 59.8 percent**. The key takeaway for this particular chart is that prompt engineering
    and formatting are important for improving recall scores.
  prefs: []
  type: TYPE_NORMAL
- en: Summary of the Comparative Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/7a42e52aaa29e88daeed149dfac91807.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'The HITL method for text pattern extraction results in higher precision and
    is great for end-users who do not have much technical background. Moreover, there
    are two aspects that are not found in GPT-3 but are found in HITL:'
  prefs: []
  type: TYPE_NORMAL
- en: HITL method is able to elicit targeted user feedback and
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It allows for an iterative approach to building the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: However, the HITL method has a lower recall and it works better with syntactic
    text patterns.
  prefs: []
  type: TYPE_NORMAL
- en: In the large generative model, given a structured prompting and post-processing
    step, GPT-3 gives higher recall scores. GPT-3 is able to contextualize the prompts
    and learn a more general model. However, the downside of GPT-3 for text pattern
    extraction is that it in itself does not perform the extraction tasks as the HITL
    method does. In fact, for us to get comparable results to the HITL model, we had
    to
  prefs: []
  type: TYPE_NORMAL
- en: Engineer and design the structure of the prompts to leverage GPT-3’s powerful
    language abilities and
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Post-process the string output from GPT-3.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: However, such steps may not necessarily be taken by an end-user who doesn’t
    have much technical training.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion & Future Work
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our preliminary work, we compared HITL and pre-trained large generative language
    models over text pattern extraction tasks. We wanted to understand how an end-user
    might use popularly researched models for text pattern extraction. We found that
    the HITL method performed better precision-wise on average, while GPT-3 had comparable
    or higher recall scores.
  prefs: []
  type: TYPE_NORMAL
- en: Our future work builds on top of these results. **How do we combine the advantages
    of each approach, HITL and pre-trained large generative language models?** How
    can we take advantage of the user inputs to improve the prompt design and in turn
    leverage the large language model’s contextual and language abilities?
  prefs: []
  type: TYPE_NORMAL
