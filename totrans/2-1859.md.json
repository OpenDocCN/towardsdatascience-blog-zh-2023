["```py\nimport pandas as pd\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.model_selection import train_test_split\n\n# Load diabetes dataset into pandas DataFrames\nX, y = load_diabetes(scaled=False, return_X_y=True, as_frame=True)\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\ndisplay(X_train.head())\ndisplay(y_train.head())\n```", "```py\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import set_config\n\n# Return pandas DataFrames instead of numpy arrays\nset_config(transform_output=\"pandas\")\n\n# Build pipeline\npipe = Pipeline(steps=[\n    ('impute_mean', SimpleImputer(strategy='mean')),\n    ('rescale', MinMaxScaler())\n])\n```", "```py\n# Fit the pipeline to the training data\npipe.fit(X_train)\n\n# Transform data using the fitted pipeline\nX_train_transformed = pipe.transform(X_train)\nX_test_transformed = pipe.transform(X_test)\n```", "```py\npreprocessor = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', MinMaxScaler()),\n    ('step_3', ...),\n    ('step_4', ...),\n    ...,\n    ('step_k', ...)\n])\n\npreprocessor.fit(X_train)\n\nX_train_transformed = pipe.transform(X_train)\nX_test_transformed = pipe.transform(X_test)\n```", "```py\n# This code will only work if you've already run the code in the previous sections\n\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, FunctionTransformer, MinMaxScaler\nfrom sklearn.impute import SimpleImputer\n\n# Categorical columns transformer - (a) impute NAs with the mode, and (b) one-hot encode\ncategorical_features = ['sex']\ncategorical_transformer = Pipeline(steps=[\n    ('impute_mode', SimpleImputer(strategy='mode')),\n    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False, drop='first')) # handle_unknown='ignore' ensures that any values not encountered in the training dataset are ignored (i.e. all ohe columns will be set to zero)\n])\n\n# Numerical columns transformer - (a) impute NAs with the mean, and (b) rescale\nnumerical_features = ['bp', 'bmi', 's1', 's2', 's3', 's4', 's5', 's6'] # All except 'age' and 'sex'\nnumerical_transformer = Pipeline(steps=[\n    ('impute_mean', SimpleImputer(strategy='mean')),\n    ('rescale', MinMaxScaler())\n])\n\n# Combine the individual transformers into a single ColumnTransformer\npreprocessor = ColumnTransformer(\n\n    # Chain together the individual transformers\n    transformers = [\n        ('categorical_transformer', categorical_transformer, categorical_features),\n        ('numerical_transformer', numerical_transformer, numerical_features),\n    ],\n\n    # By default, columns which are not transformed by the ColumnTransformer \n    # will be dropped. By setting remainder='passthrough', we ensure that\n    # these columns are retained, in their original form.\n    remainder='passthrough',\n\n    # Prefix feature names with the name of the transformer that generated them (optional)\n    verbose_feature_names_out=True\n)\n# Get visual representation of the preprocessing/feature engineering pipeline\npreprocessor\n```", "```py\n# Fit the preprocessor to the training data\npreprocessor.fit(X_train)\n\n# Transform data using the fitted preprocessor\nX_train_transformed = preprocessor.transform(X_train)\nX_test_transformed = preprocessor.transform(X_test)\n```", "```py\n# This code will only work if you've already run the code in the previous sections\n\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.decomposition import PCA, TruncatedSVD\n\n# Define a feature_union object which will create reduced-dimensionality features\nunion = FeatureUnion(transformer_list=[\n    (\"pca\", PCA(n_components=1)),\n    (\"svd\", TruncatedSVD(n_components=2))\n])\n\n# Adapt the numerical transformer so that it includes the FeatureUnion\nnumerical_features = ['bp', 'bmi', 's1', 's2', 's3', 's4', 's5', 's6'] # All except 'age' and 'sex'\nnumerical_transformer = Pipeline(steps=[\n    ('impute_mean', SimpleImputer(strategy='mean')),\n    ('rescale', MinMaxScaler()),\n    ('reduce_dimensionality', union)\n])\n\n# Categorical columns transformer - same as above\ncategorical_features = ['sex']\ncategorical_transformer = Pipeline(steps=[\n    ('impute_mode', SimpleImputer(strategy='mode')),\n    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False, drop='first')) # handle_unknown='ignore' ensures that any values not encountered in the training dataset are ignored (i.e. all ohe columns will be set to zero)\n])\n\n# Build the ColumnTransformer\npreprocessor = ColumnTransformer(\n    transformers = [\n        ('categorical_transformer', categorical_transformer, categorical_features),\n        ('numerical_transformer', numerical_transformer, numerical_features),\n    ],\n    remainder='passthrough',\n    verbose_feature_names_out=True\n)\npreprocessor\n```", "```py\n# Fit the preprocessor to the training data\npreprocessor.fit(X_train)\n\n# Transform data using the fitted preprocessor\nX_train_transformed = preprocessor.transform(X_train)\nX_test_transformed = preprocessor.transform(X_test)\n```", "```py\nfrom sklearn.preprocessing import FunctionTransformer\n\ndef add_features(X):\n    X['feature_1_2'] = X['feature_1'] + X['feature_2']\n    return X\n\ndef subtract_features(X):\n    X['feature_3_4'] = X['feature_3'] - X['feature_4']\n    return X\n\n# Put into a pipeline\nfeature_engineering = Pipeline(steps=[\n    ('add_features', FunctionTransformer(add_features)),\n    ('subtract_features', FunctionTransformer(subtract_features))\n])\n```", "```py\ndef add_subtract_features(X):\n    X['feature_1_2'] = X['feature_1'] + X['feature_2'] # Add features\n    X['feature_3_4'] = X['feature_3'] - X['feature_4'] # Subtract features\n    return X\n\n# Put into a pipeline\nfeature_engineering = Pipeline(steps=[\n    ('add_subtract_features', FunctionTransformer(add_subtract_features)),\n])\n```", "```py\n# Combine preprocessing and feature engineering in a single pipeline\npipe = Pipeline([\n    ('preprocessing', preprocessor),\n    ('feature_engineering', feature_engineering),\n])\n\npipe\n```", "```py\n# Fit the preprocessor to the training data\npipe.fit(X_train)\n\n# Transform data using the fitted preprocessor\nX_train_transformed = pipe.transform(X_train)\nX_test_transformed = pipe.transform(X_test)\n```", "```py\nimport joblib\n\n# Save pipeline\njoblib.dump(pipe, \"pipe.pkl\")\n\n# Assume that the below steps are applied in another notebook/script\n\n# Load pipeline\npretrained_pipe = joblib.load(\"pipe.pkl\")\n\n# Apply pipeline to a new dataset, X_test_new\nX_test_new_transformed = pretrained_pipe.transform(X_test_new)\n```"]