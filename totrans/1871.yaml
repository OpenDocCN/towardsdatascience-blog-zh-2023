- en: Singular Value Decomposition vs Eigendecomposition for Dimensionality Reduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/singular-value-decomposition-vs-eigendecomposition-for-dimensionality-reduction-fc0d9ac24a8e](https://towardsdatascience.com/singular-value-decomposition-vs-eigendecomposition-for-dimensionality-reduction-fc0d9ac24a8e)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Performing PCA using both methods and comparing the results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://rukshanpramoditha.medium.com/?source=post_page-----fc0d9ac24a8e--------------------------------)[![Rukshan
    Pramoditha](../Images/b80426aff64ff186cb915795644590b1.png)](https://rukshanpramoditha.medium.com/?source=post_page-----fc0d9ac24a8e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fc0d9ac24a8e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fc0d9ac24a8e--------------------------------)
    [Rukshan Pramoditha](https://rukshanpramoditha.medium.com/?source=post_page-----fc0d9ac24a8e--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fc0d9ac24a8e--------------------------------)
    ·8 min read·Mar 20, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/249648322ceade3a63b6972cb91564d2.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [Viktor Peschel](https://pixabay.com/users/1a-photoshop-6724285/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=2886285)
    from [Pixabay](https://pixabay.com//?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=2886285)
  prefs: []
  type: TYPE_NORMAL
- en: Singular value decomposition (SVD) and eigendecomposition (ED) are both matrix
    factorization methods that come from linear algebra.
  prefs: []
  type: TYPE_NORMAL
- en: In the field of machine learning (ML), both can be used as data reduction methods
    (i.e. for dimensionality reduction).
  prefs: []
  type: TYPE_NORMAL
- en: Previously, we’ve discussed [eigendecomposition](https://medium.com/data-science-365/eigendecomposition-of-a-covariance-matrix-with-numpy-c953334c965d)
    in detail. Today, we’ll give more emphasis on discussing SVD.
  prefs: []
  type: TYPE_NORMAL
- en: Principal component analysis (PCA) can be performed using both methods. PCA
    is the most popular linear dimensionality reduction technique in ML. SVD is considered
    as the underlying mathematics behind PCA. The popular ML library, Scikit-learn
    also uses SVD within its `PCA()`function to perform PCA. Therefore, SVD is more
    popular than eigendecomposition in dimensionality reduction.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy provides high-level and easy-to-use functions to perform SVD and eigendecomposition.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: What is singular value decomposition?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Singular value decomposition (SVD) is a type of matrix factorization method.
    It is an important mathematical operation that comes from linear algebra.
  prefs: []
  type: TYPE_NORMAL
- en: There are multiple ways to factorize (decompose / break down) a matrix like
    we can factorize the number 16, for example, into 2 x 8 = 16, 4 x 4 = 16, 2 x
    2 x 4 = 16, 2 x 2 x 2 x 2 = 16\. Not all factorization methods are equally important.
    It depends on the use case.
  prefs: []
  type: TYPE_NORMAL
- en: Likewise, we can factorize a matrix in multiple ways of which some are more
    important. Singular value decomposition (SVD) and eigendecomposition are such
    important methods of factorizing a matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Singular value decomposition is the process of decomposing matrix **A** into
    the product of three matrices as in the following equation.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/c7b6ce2cfc1fcf20b9a01bec3589f197.png)'
  prefs: []
  type: TYPE_IMG
- en: '**SVD equation** (Image by author)'
  prefs: []
  type: TYPE_NORMAL
- en: '**A:** The matrix on which we perform SVD'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**U:** A square matrix. This is called the right singular vectors matrix.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Σ:** A diagonal matrix. This is called the singular value matrix which is
    the same size as **A**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**V^T:** A square matrix. This is called the left singular vectors matrix.
    By default, NumPy’s SVD function returns **V^T** which is the transform of **V**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The matrix **A** can be square or non-square as SVD is defined for both square
    and non-square matrices. In contrast, eigendecomposition is defined only for square
    matrices.
  prefs: []
  type: TYPE_NORMAL
- en: The matrix **Σ** contains singular values which are always non-negative values.
    Zero values can be included.
  prefs: []
  type: TYPE_NORMAL
- en: The number of non-zero singular values equals the rank of matrix **A**.
  prefs: []
  type: TYPE_NORMAL
- en: Singular value decomposition in NumPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In NumPy, SVD can be easily performed using the `svd()`function. Here is an
    example.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/a6000f866e46a999252e6f2f05d2d075.png)'
  prefs: []
  type: TYPE_IMG
- en: (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: NumPy’s **svd()** function returns **Σ** (singular value matrix) as a vector
    (denoted by **s**), not a diagonal matrix. That vector contains all the singular
    values of **A**.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to get the **Σ** as it is, you can do some modifications using the
    following code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/81082c5e0db19903518e8da2eeb64741.png)'
  prefs: []
  type: TYPE_IMG
- en: (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: If you only need to compute singular values and don’t need U and Vt matrices,
    you can run the following code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b0a958c19f33e309dde1407c08eae037.png)'
  prefs: []
  type: TYPE_IMG
- en: (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: That’s how we can perform SVD in NumPy. It is much easier than you think. Next,
    we will move into the eigendecomposition part.
  prefs: []
  type: TYPE_NORMAL
- en: What is eigendecomposition?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Eigendecompostionn is another important matrix factorizing method.
  prefs: []
  type: TYPE_NORMAL
- en: Eigendecomposition is the process of decomposing a square matrix A into the
    product of eigenvalues and eigenvectors as in the following equation.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/93f7324a37f8fe17c6cb97ebaa464bd9.png)'
  prefs: []
  type: TYPE_IMG
- en: '**The relationship between square matrix, A and its pair of eigenvalue and
    eigenvector** (Image by author)'
  prefs: []
  type: TYPE_NORMAL
- en: '**A:** The matrix on which we perform eigendecomposition. It should be a square
    matrix.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**λ:** A scalar called the eigenvalue.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**x:** A vector called the eigenvector.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The matrix **A** should be a square matrix as eigendecomposition is defined
    only for square matrices.
  prefs: []
  type: TYPE_NORMAL
- en: The eigenvalues can be positive or negative.
  prefs: []
  type: TYPE_NORMAL
- en: '*The eigenvalues and eigenvectors come in pairs. Such a pair is known as an*
    ***eigenpair****. So, matrix* ***A*** *can have multiple such eigenpairs. The
    above equation shows the relationship between* ***A*** *and one of its eigenpairs*
    [ref: [Eigendecomposition of a Covariance Matrix with NumPy](https://medium.com/data-science-365/eigendecomposition-of-a-covariance-matrix-with-numpy-c953334c965d)]'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Eigendecomposition in NumPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In NumPy, eigendecomposition can be easily performed using the `eig()`function.
    Here is an example.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/ec500f583fcaf1f81e031b0932cafcc6.png)'
  prefs: []
  type: TYPE_IMG
- en: (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: NumPy’s **eig()** function returns eigenvalues as a vector. That vector contains
    all the eigenvalues of **A**.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ve performed both SVD and eigendecomposition on the same matrix, **A**.
    By looking at the outputs, we can say that:'
  prefs: []
  type: TYPE_NORMAL
- en: Singular value decomposition and the eigendecomposition are not the same things
    even if the matrix is square.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Performing PCA using singular value decomposition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PCA is often performed by applying SVD to the covariance matrix of standardized
    data. The covariance matrix of standardized data is exactly the same as the correlation
    matrix of non-standardized data.
  prefs: []
  type: TYPE_NORMAL
- en: We standardize data before SVD because singular values are highly sensitive
    to the relative ranges of original features.
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate the PCA process using SVD, we’ll use the Wine dataset which has
    13 input features.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1:** Getting Wine data.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b663ea243afd2ae6e9336d66fcfd0cba.png)'
  prefs: []
  type: TYPE_IMG
- en: (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 2:** Standardizing data.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 3:** Computing the covariance matrix of standardized data.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 4:** Performing SVD on the covariance matrix and getting the singular
    values of the covariance matrix.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/68288b1015e9d7208bc07f7c08a37e2a.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Singular values** (Image by author)'
  prefs: []
  type: TYPE_NORMAL
- en: The sum of these singular values is equal to the total amount of variance in
    the data. Each singular value represents the amount of variance captured by each
    component. To calculate these things, we need to convert singular values to the
    variance explained.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 5:** Converting singular values to the variance explained.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/394112bd6155fb0378806a7b75bd823b.png)'
  prefs: []
  type: TYPE_IMG
- en: (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: The first component captures a 36.2% variance in the data. The second component
    captures a 19.2% variance in the data, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 6:** Visualizing singular values to select the right number of components'
  prefs: []
  type: TYPE_NORMAL
- en: Not all components contribute the same to the model. We can drop the components
    that do not capture much variance in the data and keep only the most important
    components. For that, we need to visualize all the singular values by creating
    the [*cumulative explained variance plot*](https://medium.com/data-science-365/2-plots-that-help-me-to-choose-the-right-number-of-principal-components-351a87e15a9f).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/77ddeacfd777ca9be48faf980e421099.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Cumulative explained variance plot** (Image by author)'
  prefs: []
  type: TYPE_NORMAL
- en: So, it is very clear that the first 7 components capture about 90% variance
    in the data. So, we can select the first 7 components for the Wine dataset.
  prefs: []
  type: TYPE_NORMAL
- en: See all selection criteria [here](/how-to-select-the-best-number-of-principal-components-for-the-dataset-287e64b14c6d).
  prefs: []
  type: TYPE_NORMAL
- en: Performing PCA using eigendecomposition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PCA can also be performed by applying eigendecomposition to the covariance matrix
    of standardized data.
  prefs: []
  type: TYPE_NORMAL
- en: The first 3 steps are the same as before. So, I will continue with the fourth
    step.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1, Step 2, Step 3:** Same as before.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 4:** Performing eigendecomposition on the covariance matrix and getting
    the eigenvalues of the covariance matrix.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/7b2205e5e8489f299d4811f258afc84b.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Eigenvalues** (Image by author)'
  prefs: []
  type: TYPE_NORMAL
- en: The eigenvalues are exactly the same as the singular values. The reason is that
    the covariance matrix is symmetric.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/782200fd556cd02404edb3ea4da8d15d.png)'
  prefs: []
  type: TYPE_IMG
- en: '**The covariance matrix of the standardized Wine data** (Image by author)'
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, we can say that:'
  prefs: []
  type: TYPE_NORMAL
- en: For a symmetric matrix, eigenvalues are exactly the same as the singular values.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In other words,
  prefs: []
  type: TYPE_NORMAL
- en: For a symmetric matrix, singular value decomposition and the eigendecomposition
    are the same things.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Unlike the **svd()** function, the eigenvalues returned by the **eig()** function
    are not in descending order. So, we need to manually sort them from largest to
    smallest.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/88f8995a3da863e8c9203d03f6e4a1fd.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Sorted eigenvalues in descending order** (Image by author)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 5, Step 6:** Same as before.'
  prefs: []
  type: TYPE_NORMAL
- en: We can visualize the eigenvalues as the same as before. You will get exactly
    the same plot.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By default, PCA is performed by using SVD. It can also be performed by using
    eigendecomposition. Both approaches give the same results because the covariance
    matrix is symmetric.
  prefs: []
  type: TYPE_NORMAL
- en: In general, singular value decomposition and eigendecomposition are completely
    two different things, but for a symmetric matrix like the covariance matrix used
    in PCA, both are the same!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is the end of today’s article.
  prefs: []
  type: TYPE_NORMAL
- en: '**Please let me know if you’ve any questions or feedback.**'
  prefs: []
  type: TYPE_NORMAL
- en: Read next (Recommended)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[**PCA and Dimensionality Reduction Special Collection**](https://rukshanpramoditha.medium.com/list/pca-and-dimensionality-reduction-special-collection-146045a5acb5)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How about an AI course?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[**Neural Networks and Deep Learning Course**](https://rukshanpramoditha.medium.com/list/neural-networks-and-deep-learning-course-a2779b9c3f75)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support me as a writer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*I hope you enjoyed reading this article. If you’d like to support me as a
    writer, kindly consider* [***signing up for a membership***](https://rukshanpramoditha.medium.com/membership)
    *to get unlimited access to Medium. It only costs $5 per month and I will receive
    a portion of your membership fee.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://rukshanpramoditha.medium.com/membership?source=post_page-----fc0d9ac24a8e--------------------------------)
    [## Join Medium with my referral link - Rukshan Pramoditha'
  prefs: []
  type: TYPE_NORMAL
- en: Read every story from Rukshan Pramoditha (and thousands of other writers on
    Medium). Your membership fee directly…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: rukshanpramoditha.medium.com](https://rukshanpramoditha.medium.com/membership?source=post_page-----fc0d9ac24a8e--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Join my private list of emails
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Never miss a great story from me again. By* [***subscribing to my email list***](https://rukshanpramoditha.medium.com/subscribe)*,
    you will directly receive my stories as soon as I publish them.*'
  prefs: []
  type: TYPE_NORMAL
- en: Thank you so much for your continuous support! See you in the next article.
    Happy learning to everyone!
  prefs: []
  type: TYPE_NORMAL
- en: Wine dataset info
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Dataset source:** You can download the original dataset [here](https://archive.ics.uci.edu/ml/datasets/Wine).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dataset license:** This dataset is available under the [*CC BY 4.0*](https://creativecommons.org/licenses/by/4.0/)
    (*Creative Commons Attribution 4.0*) license.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Citation:** Lichman, M. (2013). UCI Machine Learning Repository [[https://archive.ics.uci.edu/ml](https://archive.ics.uci.edu/ml)].
    Irvine, CA: University of California, School of Information and Computer Science.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Rukshan Pramoditha](https://medium.com/u/f90a3bb1d400?source=post_page-----fc0d9ac24a8e--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: '**2023–03–20**'
  prefs: []
  type: TYPE_NORMAL
