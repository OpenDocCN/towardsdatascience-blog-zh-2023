["```py\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nnp.random.seed(0)\n```", "```py\nfrom sklearn.datasets import fetch_california_housing\n\ndata = fetch_california_housing()\nX, y = data.data, data.target\nfeature_names = data.feature_names\n```", "```py\nmat = np.column_stack((X, y))\ndf = pd.DataFrame(mat, columns=np.append(feature_names, 'MedianValue'))\ndf.head()\n```", "```py\ndf.info()\n```", "```py\nX_with_bias = np.column_stack((np.ones(len(X)), X))\n```", "```py\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_with_bias, y, test_size=0.2, random_state=0)\n```", "```py\ndef closed_form_solution(X, y):\n    w = np.linalg.inv(X.T @ X) @ X.T @ y\n    return w \n```", "```py\nw = closed_form_solution(X_train, y_train)\nprint(w)\n```", "```py\n[-3.68585691e+01  4.33333407e-01  9.29324337e-03 -9.86433739e-02\n  5.93215487e-01 -7.56192502e-06 -4.74516383e-03 -4.21449336e-01\n -4.34166041e-01]\n```", "```py\ny_train_pred = X_train @ w\n```", "```py\nfrom sklearn.metrics import r2_score\n\ntrain_score = r2_score(y_train, y_train_pred)\nprint(f'R2 score (train): {train_score:.4f}')\n```", "```py\nR2 score (train): 0.6089\n```", "```py\ny_test_pred = X_test @ w\n\ntest_score = r2_score(y_test, y_test_pred)\nprint(f'R2 score (test): {test_score:.4f}')\n```", "```py\nR2 score (test): 0.5943\n```", "```py\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n```", "```py\nfrom sklearn.linear_model import LinearRegression\n\nreg = LinearRegression()\nreg.fit(X_train, y_train)\n```", "```py\nprint(reg.intercept_)\nprint(reg.coef_)\n```", "```py\n-36.858569106801234\n[ 4.33333407e-01  9.29324337e-03 -9.86433739e-02  5.93215487e-01\n -7.56192502e-06 -4.74516383e-03 -4.21449336e-01 -4.34166041e-01]\n```", "```py\ntrain_score = reg.score(X_train, y_train)\nprint(f'R2 score (train): {train_score:.4f}')\n\ntest_score = reg.score(X_test, y_test)\nprint(f'R2 score (test): {test_score:.4f}')\n```", "```py\nR2 score (train): 0.6089\nR2 score (test): 0.5943\n```", "```py\ndef plot_residuals(y_train_pred, y_train, y_test_pred, y_test):\n    plt.scatter(y_train_pred, y_train_pred - y_train, s=2, marker='o', c='b', label='Training')    \n    plt.scatter(y_test_pred, y_test_pred - y_test, s=2, marker='s', c='m', label='Test') \n\n    xmin = min(y_train_pred.min(), y_test_pred.min())\n    xmax = max(y_train_pred.max(), y_test_pred.max())\n    plt.hlines(y=0, xmin=xmin, xmax=xmax, color='black')    \n\n    plt.xlim(xmin, xmax)\n    plt.xlabel('Predicted values')\n    plt.ylabel('Residuals')\n    plt.legend()\n```", "```py\nplot_residuals(y_train_pred, y_train, y_test_pred, y_test)\n```", "```py\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.pipeline import Pipeline\n\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('reg', SGDRegressor())\n])\n```", "```py\npipeline.fit(X_train, y_train)\n```", "```py\ntrain_score = pipeline.score(X_train, y_train)\nprint(f'R2 score (train): {train_score:.4f}')\n\ntest_score = pipeline.score(X_test, y_test)\nprint(f'R2 score (test): {test_score:.4f}')\n```", "```py\nR2 score (train): -511.0496\nR2 score (test): -4735.6157\n```", "```py\npipeline.set_params(reg__eta0=0.001)\n```", "```py\npipeline.fit(X_train, y_train)\n```", "```py\ntrain_score = pipeline.score(X_train, y_train)\nprint(f'R2 score (train): {train_score:.4f}')\n\ntest_score = pipeline.score(X_test, y_test)\nprint(f'R2 score (test): {test_score:.4f}')\n```", "```py\nR2 score (train): 0.6018\nR2 score (test): 0.5841\n```"]