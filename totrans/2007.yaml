- en: The Critical Role of Loss Function Selection in Creating Accurate Time Series
    Forecasts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/the-critical-role-of-loss-function-selection-in-creating-accurate-time-series-forecasts-77cf69dc9d2f](https://towardsdatascience.com/the-critical-role-of-loss-function-selection-in-creating-accurate-time-series-forecasts-77cf69dc9d2f)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Mastering Time Series Forecasting with Machine Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: How your choice of loss function can make or break your time series forecasts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://johnadeojo.medium.com/?source=post_page-----77cf69dc9d2f--------------------------------)[![John
    Adeojo](../Images/f6460fae462b055d36dce16fefcd142c.png)](https://johnadeojo.medium.com/?source=post_page-----77cf69dc9d2f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----77cf69dc9d2f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----77cf69dc9d2f--------------------------------)
    [John Adeojo](https://johnadeojo.medium.com/?source=post_page-----77cf69dc9d2f--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----77cf69dc9d2f--------------------------------)
    ¬∑8 min read¬∑Mar 14, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/50c340d8f06526401323807ca45397a4.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Dan Asaki](https://unsplash.com/@danasaki?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this post I‚Äôll be demonstrating to you the importance of something that I
    believe is often overlooked in machine learning, the choice of loss function.
    I will do this by walking you through my approach to the Dengue Fever competition
    hosted by [Driven Data](https://www.drivendata.org/competitions/44/dengai-predicting-disease-spread/page/80/).
  prefs: []
  type: TYPE_NORMAL
- en: I have built a Ridge regressor as my baseline model and several ‚Äúflavours‚Äù of
    the XGBoost regressor each with a different loss function.
  prefs: []
  type: TYPE_NORMAL
- en: '*Competitors are asked to predict the total cases of dengue fever over weekly
    time intervals in Iquitos and San Juan. Each competitor is ranked according to
    the mean absolute error (MAE) their model(s) scores against the test data set.
    To learn more about the challenge, dengue fever or enter the competition yourself,
    you can visit the challenge* [*homepage*](https://www.drivendata.org/competitions/44/dengai-predicting-disease-spread/page/80/)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: Notebooks & Repositories
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I have made my working Jupyter notebook and GitHub repo available to you via
    the links below. The notebook may take a few minutes to load, please be patient.
  prefs: []
  type: TYPE_NORMAL
- en: üìí [Jupyter Notebook](https://mybinder.org/v2/gh/john-adeojo/dengue-model/b0424c69bf29f05c0d3eef159f4419536fd770e6?urlpath=lab%2Ftree%2Fnotebooks%2FDengue+Fever+Data+Profilingv3.ipynb)
  prefs: []
  type: TYPE_NORMAL
- en: üìÅ[Github Repo](https://github.com/john-adeojo/dengue-model)
  prefs: []
  type: TYPE_NORMAL
- en: Please feel free to experiment with your own loss function within the notebook.
  prefs: []
  type: TYPE_NORMAL
- en: Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The data comes in csv format with training features, labels and test features
    (similar to the Kaggle competition format). Data features include weather forecast,
    climate forecasts, and vegetation indices.
  prefs: []
  type: TYPE_NORMAL
- en: The label (total cases of dengue) is long tailed having a small number of extreme
    values. This holds across both cities. The shape of these distributions should
    give you a clue about what might be appropriate loss functions for the model.
  prefs: []
  type: TYPE_NORMAL
- en: '*The data used in this project is curated and provided by Driven Data, it is
    freely available for use outside of the competition according to* [*Driven Data*](https://www.drivendata.org/competitions/44/dengai-predicting-disease-spread/data/)*¬π.
    The original source of the data is available from the* [*National Oceanic and
    Atmospheric Administration*](https://dengueforecasting.noaa.gov/)*, the data is
    publicly available and may be used without charge according to the the* [*terms
    and conditions of the NOAA*](https://www.weather.gov/disclaimer#:~:text=Use%20of%20NOAA/NWS%C2%A0Data%20and%20Products)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5b89fe539632b7df737479760c8514f3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Distribution of dengue fever total cases Iquitos'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/846ffac69405389dcd48a704bcd039ec.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Time series Iquitos'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d18d77b461720201c02d0a12f4ce4c29.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Distribution of dengue fever total cases San Juan'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bcebae54cf4f1eea3eadd96b6b0e9286.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Time series San Juan'
  prefs: []
  type: TYPE_NORMAL
- en: Data pre-processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Outside of splitting the data I performed three data pre-processing steps. The
    first, imputing missing values. I simply imputed the mean value across these missing
    features as a quick and dirty way to address this without causing too much distributional
    shift.
  prefs: []
  type: TYPE_NORMAL
- en: The second was to standardise the data. Standardisation is a form of feature
    scaling that sets your numeric features to have a variance of one and a mean of
    zero. Scaling isn‚Äôt necessary for XGBoost, however it is useful to scale features
    before fitting the Ridge regression model.
  prefs: []
  type: TYPE_NORMAL
- en: The third operation I applied was one-hot-encoding. This converts categorical
    variables to their numeric representations such that they can be used to train
    a model.
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: to prevent data leakage all preprocessing was done on the train, validation,
    and test sets separately.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Feature Engineering**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I engineered some lagged features. These can be particularly useful for improving
    the predictive performance of time series models due to autocorrelation.
  prefs: []
  type: TYPE_NORMAL
- en: There were some limitations in the data putting constraints on the lags I could
    create. First off, the test data was 3 years ahead of the training data with no
    labels. The implication of this is that the shortest lag I could create was 3
    years, which feels quite long. Next, the number of cases were not uniformly recorded
    at the week level. I had to overcome this by aggregating the number of cases at
    the month level and creating my lagged features based on the aggregations. Lagged
    features were engineered as the mean, minimum and maximum.
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning Approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are two separate time series tracking total cases of dengue fever in weekly
    intervals. One time series is for Iquitos (Iq) and the other is for San Juan (Sj),
    I have trained separate models for each.
  prefs: []
  type: TYPE_NORMAL
- en: It helps me to conceptualise machine learning as an optimisation problem in
    which you are trying to minimise an objective function.
  prefs: []
  type: TYPE_NORMAL
- en: Objective Function = Loss Function + Regularisation Function
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The loss function dictates how to ‚Äòscore‚Äô the overall performance of the model
    in predicting the label, which in this case is the total number of dengue cases.
    The regularisation function penalises model complexity helping to mitigate overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: Data Splitting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before I go into the details of hyperparameter tuning, I should briefly talk
    about data splitting. A random split isn‚Äôt appropriate for time series problems.
    Splitting data randomly would cause future data points to be included in your
    test set giving false (and likely overoptimistic) performance results. I have
    split data by date to prevent any leakage and set up accurate validation.
  prefs: []
  type: TYPE_NORMAL
- en: '*For Iquitos the train data set is all observations prior to 30‚Äì09‚Äì2008\. For
    San Juan the split was placed at 30‚Äì07‚Äì2004.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*To further mitigate overfitting, I used time series cross validation with
    5 folds while training the model.* [*Read this for more detail on time series
    cross validation*](https://scikit-learn.org/stable/modules/cross_validation.html#time-series-split)*.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hyperparameter Tuning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I used random search over a uniform distribution to tune my regularisation parameter.
    I find this to be a prudent approach to quickly explore a large hyperparameter
    space. [Read this for more details on randomised search](https://scikit-learn.org/stable/modules/grid_search.html#randomized-parameter-search).
  prefs: []
  type: TYPE_NORMAL
- en: '*Note that I have tuned l2 regularisation only. This is alpha and lambda for
    Ridge and XGBoost respectively.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*If you would like to experiment with regularisation parameters to see how
    they impact model fit, check out this* [*stream lit app I made earlier*](https://john-adeojo-dengue-model-streamlitdengue-streamlit-x2f4ij.streamlit.app/)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/17cc51925915f00f0ec3bed0c51c8957.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: An example of the hyperparameter tuning process on the Ridge
    model for Iquitos. Mean test score is MAE'
  prefs: []
  type: TYPE_NORMAL
- en: Loss Functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: My choice of loss functions were Poisson, Mean Absolute Error (MAE), and Mean
    Squared Error (MSE).
  prefs: []
  type: TYPE_NORMAL
- en: Poisson
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For dengue fever transmission the independence assumption makes sense because
    cases are not transferred from person to person. However, the constant rate assumption
    is probably not right for this case study, I would imagine the rate of occurrence
    of dengue cases varies significantly based on multidimensional factors. Poisson
    distributions however do take an average rate as a model parameter.
  prefs: []
  type: TYPE_NORMAL
- en: '*A Poisson loss function is used when the target variable is count data that
    follows a Poisson distribution. This type of distribution assumes events occur
    independently and at a constant rate.*'
  prefs: []
  type: TYPE_NORMAL
- en: Mean Absolute Error
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The mean absolute error (MAE) simply measures the absolute difference between
    the predicted and actual values. MAE is less sensitive to outliers than some of
    the other loss functions, particularly MSE.
  prefs: []
  type: TYPE_NORMAL
- en: I think many people confuse the loss functions with the scoring metric and presume
    that the best loss function is MAE because this is what the tournament is being
    scored on, you‚Äôll see that this isn‚Äôt necessarily the case.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Means Squared Error
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Mean squared error (MSE) calculates the square difference between the modelled
    output and the expected output. MSE is sensitive to outliers because of the squaring
    of the differences. It penalises large differences between the predicted and actual
    variables more than small ones.
  prefs: []
  type: TYPE_NORMAL
- en: Model Performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Model performance is assessed on the validation set. Scoring (not to be confused
    with loss function) is MAE based on the scoring in the competition and ease of
    interpretability (simply measure in dengue cases). You will see from the charts
    below how the choice of loss function has drastically impacted how each model
    fits the data. As you analyse these charts, think about how the choice of loss
    function has caused the model to fit the data the way it does.
  prefs: []
  type: TYPE_NORMAL
- en: Ridge Regressor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Iquitos**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Iquitos Model MAE: 7*'
  prefs: []
  type: TYPE_NORMAL
- en: The model captures some seasonality but doesn‚Äôt effectively predict the outliers.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7260d2cefe5e269dd03b0d4082115922.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Ridge regression model forecasts vs actuals for Iquitos'
  prefs: []
  type: TYPE_NORMAL
- en: '**San Juan**'
  prefs: []
  type: TYPE_NORMAL
- en: '*San Juan Model MAE: 23.7*'
  prefs: []
  type: TYPE_NORMAL
- en: The model can capture some seasonality but doesn‚Äôt effectively predict the outliers.
    There is an offset in the Ridge predictions being slightly higher than actual
    cases.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1d18ffbceaae3155d8f7569abf3202a8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Ridge regression model forecasts vs actuals for San Juan'
  prefs: []
  type: TYPE_NORMAL
- en: 'XGBoost Regressor: Poisson Loss'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Iquitos**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Iquitos Model MAE: 7.8*'
  prefs: []
  type: TYPE_NORMAL
- en: The model captures some seasonality but doesn‚Äôt effectively predict the outliers.
    Where the model does predict spikes, they are underpredicted.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5ecdf135fa0b1cbcc85774ca1829582b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Poisson XGBoost model forecasts vs actuals for Iquitos'
  prefs: []
  type: TYPE_NORMAL
- en: '**San Juan**'
  prefs: []
  type: TYPE_NORMAL
- en: '*San Juan Model MAE: 18.9*'
  prefs: []
  type: TYPE_NORMAL
- en: The model appears to predict spikes well on the training data. The model attempts
    this for the validation data but can overshoot. Training with a Poisson loss has
    allowed the model to try an anticipate spikes.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3eb785f12f5c7be4d436be654804b2aa.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Poisson XGBoost model forecasts vs actuals for San Juan'
  prefs: []
  type: TYPE_NORMAL
- en: 'XGBoost Regressor: MAE Loss'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Iquitos**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Iquitos Model MAE: 7*'
  prefs: []
  type: TYPE_NORMAL
- en: Although the MAE is low, the model appears to just be drawing a straight line
    through the data. It is not sensitive at all to outliers and seasonality.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8d4f4112fdd705d233092ecf4d012388.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: MAE XGBoost model forecasts vs actuals for Iquitos'
  prefs: []
  type: TYPE_NORMAL
- en: '**San Juan**'
  prefs: []
  type: TYPE_NORMAL
- en: '*San Juan Model MAE: 16.6*'
  prefs: []
  type: TYPE_NORMAL
- en: The model appears to be effective predicting seasonality but failing to predict
    the spikes, although it does make attempts at doing this.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/746fc10e0901e8826a038ac65213c963.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: MAE XGBoost model forecasts vs actuals for San Juan'
  prefs: []
  type: TYPE_NORMAL
- en: 'XGBoost Regressor: MSE Loss'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Iquitos**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Iquitos Model MAE: 7.3*'
  prefs: []
  type: TYPE_NORMAL
- en: The model is able to capture some seasonality, however it fails at capturing
    the outliers.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ddde1939d5f0c05b12b43bd9e554a52a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: MSE XGBoost model forecasts vs actuals for Iquitos'
  prefs: []
  type: TYPE_NORMAL
- en: '**San Juan**'
  prefs: []
  type: TYPE_NORMAL
- en: '*San Juan Model MAE: 18.48*'
  prefs: []
  type: TYPE_NORMAL
- en: The model captures seasonality but does not capture the outliers particularly
    well.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c359633b928dab38d877c6c1070d95c3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: MSE XGBoost model forecasts vs actuals for San Juan'
  prefs: []
  type: TYPE_NORMAL
- en: Submission Results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Poisson model scored the highest overall accuracy on the test data with
    an MAE of 27.6, the MSE model was next at 27.8, and last was the MAE model at
    29.
  prefs: []
  type: TYPE_NORMAL
- en: '*Poisson loss XGBoost placed in the top 27% of competition entrances. Not bad
    for minimal hyperparameter tuning and feature engineering.*'
  prefs: []
  type: TYPE_NORMAL
- en: Final Thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Choosing the best model completely depends on the objectives of the forecast.
    Strictly speaking, if we were just talking about the model that minimises MAE
    on the validation set then the best overall would be the XGBoost Regressor with
    MAE loss. However, the model that demonstrates the best ability to model the underlying
    phenomena appears to be the Poisson loss variant.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading.
  prefs: []
  type: TYPE_NORMAL
- en: '*[1] Bull, P., Slavitt, I. and Lipstein, G. (2016). Harnessing the Power of
    the Crowd to Increase Capacity for Data Science in the Social Sector. [online]
    Available at:* [*https://arxiv.org/abs/1606.07781*](https://arxiv.org/abs/1606.07781)
    *[Accessed 13 Mar. 2023].*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/@johnadeojo/membership?source=post_page-----77cf69dc9d2f--------------------------------)
    [## Join Medium with my referral link - John Adeojo'
  prefs: []
  type: TYPE_NORMAL
- en: I share data science projects, experiences, and expertise to assist you on your
    journey You can sign up to medium via‚Ä¶
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@johnadeojo/membership?source=post_page-----77cf69dc9d2f--------------------------------)
    [](https://www.john-adeojo.com/?source=post_page-----77cf69dc9d2f--------------------------------)
    [## Home | John Adeojo
  prefs: []
  type: TYPE_NORMAL
- en: A Bit About Me Welcome to my professional portfolio! I'm a seasoned data scientist
    and machine learning (ML) expert‚Ä¶
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.john-adeojo.com](https://www.john-adeojo.com/?source=post_page-----77cf69dc9d2f--------------------------------)
  prefs: []
  type: TYPE_NORMAL
