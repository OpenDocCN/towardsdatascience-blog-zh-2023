["```py\nfrom sklearn.datasets import fetch_california_housing\nimport pandas as pd\n\n# load dataset\nhousing = fetch_california_housing()\nX, y = housing.data, housing.target\nX = pd.DataFrame(X, columns=housing.feature_names)\n# feature dataset\nX = X.drop(['Population', 'AveBedrms', 'AveOccup'], axis=1)\n```", "```py\n# split data into train and test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n# train an XGBoost model\nfrom xgboost import XGBRegressor\nmodel = xgb.XGBRegressor(objective='reg:squarederror', random_state=4)\nmodel.fit(X_train, y_train)\n```", "```py\ny_pred = model.predict(X_test)\n```", "```py\nX_test.iloc[0,]\n```", "```py\nMedInc         4.151800\nHouseAge      22.000000\nAveRooms       5.663073\nLatitude      32.580000\nLongitude   -117.050000\n```", "```py\ny_pred[0]\n> 1.596\n```", "```py\ny_pred.mean()\n> 2.07\n```", "```py\nimport shap\nexplainer = shap.Explainer(model)\nshap_values = explainer(X_test)\n```", "```py\n# visualize the SHAP values of the first sample\nshap.plots.waterfall(shap_values[0])\n```", "```py\n# visualize the SHAP values of the second sample\nshap.plots.waterfall(shap_values[0])\n```", "```py\nshap.plots.force(shap_values[0])\n```", "```py\nshap.plots.bar(shap_values)\n```", "```py\nshap.plots.beeswarm(shap_values)\n```", "```py\nshap.plots.scatter(shap_values[:,\"MedInc\"])\n```", "```py\nshap.plots.scatter(shap_values[:,\"Latitude\"])\n```"]