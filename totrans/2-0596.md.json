["```py\n!pip install --upgrade huggingface_hub\n```", "```py\nfrom huggingface_hub import notebook_login\nnotebook_login()\n```", "```py\n!pip install -qq -U diffusers transformers\n```", "```py\nfrom diffusers import StableDiffusionPipeline\npipe = StableDiffusionPipeline.from_pretrained('runwayml/stable-diffusion-v1–5')\n.to('cuda')\n```", "```py\nimport torch\n\n# Initialize a prompt\nprompt = “polar bear on an iceberg”\n\n# Pass the prompt in the pipeline\npipe(prompt).images[0]\n```", "```py\ntorch.cuda.empty_cache()\n```", "```py\n$ git clone https://github.com/GoogleCloudPlatform/vertex-ai-samples\n```", "```py\n$ export GOOGLE_APPLICATION_CREDENTIALS=”path/to/your.json file”\n```", "```py\nimport base64\nimport logging\nfrom io import BytesIO\nfrom google.cloud import aiplatform as aip\n\nPROJECT_NAME = “YOUR-PROJECT-ID”\nREGION = “us-central1”\nENDPOINT_ID = “YOUR-ENDPOINT-ID”\n\naip.init(project=PROJECT_NAME, location=REGION)\nendpoint = aip.Endpoint(endpoint_name=ENDPOINT_ID)\ntext_input = “””Polar bear on an iceberg”””\n\n# Invoke the Vertex AI endpoint \ndef query_endpoint(endpoint, text_input):\n  payload = {“prompt”: text_input}\n  response = endpoint.predict(instances=[payload])\n  return response\n\nresponse = query_endpoint(endpoint, text_input)\n\nwith open(“generated_imgage.jpg”, “wb”) as g:\n    g.write(base64.b64decode(response.predictions[0]))\n```", "```py\nimport base64\nfrom google.cloud import aiplatform as aip\nfrom flask import Flask, jsonify, request, send_file\nfrom PIL import Image\nfrom io import BytesIO\n\napp = Flask(__name__)\n\n@app.route(‘/predict’, methods=[‘POST’])\ndef predict():\n  PROJECT_NAME = ‘YOUR-PROJECT-ID’\n  REGION = ‘us-central1’\n  ENDPOINT_ID = ‘YOUR-ENDPOINT-ID’\n\n  # Get the input data from the HTTP request\n  input_data = request.get_json()\n\n  # Extract the text parameter from the input data\n  prompt = input_data.get(‘prompt’, ‘’)\n\n  aip.init(project=PROJECT_NAME, location=REGION)\n  endpoint = aip.Endpoint(endpoint_name=ENDPOINT_ID)\n  text_input = prompt\n\n  # Invoke the Vertex AI\n  payload = {“prompt”: text_input}\n  response = endpoint.predict(instances=[payload])\n\n  # Decode the image data from base64 format\n  image_data = response.predictions[0]\n  image_bytes = base64.b64decode(image_data)\n\n  # Create a PIL Image object from the decoded image data\n  image = Image.open(BytesIO(image_bytes))\n\n  # Save the image to a BytesIO buffer\n  buffer = BytesIO()\n  image.save(buffer, format=’JPEG’)\n  buffer.seek(0)\n\n  # Return the image file in the response\n  return send_file(buffer, mimetype=’image/jpeg’)\n\nif __name__ == ‘__main__’:\n    app.run(debug=True)\n```", "```py\ncurl -X POST \\\n-H “Content-Type: application/json” \\\n-d ‘{“prompt”: “Astronauts in the ocean”}’ \\\nhttp://127.0.0.1:5000/predict \\\n-- output generated_image.jpg\n```"]