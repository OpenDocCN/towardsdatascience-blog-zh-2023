- en: Conversations as Directed Graphs with LangChain
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 LangChain 将对话作为有向图
- en: 原文：[https://towardsdatascience.com/conversations-as-directed-graphs-with-lang-chain-46d70e1a846c](https://towardsdatascience.com/conversations-as-directed-graphs-with-lang-chain-46d70e1a846c)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/conversations-as-directed-graphs-with-lang-chain-46d70e1a846c](https://towardsdatascience.com/conversations-as-directed-graphs-with-lang-chain-46d70e1a846c)
- en: Building a chatbot designed to understand key information about new prospective
    customers.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建一个聊天机器人，旨在了解关于新潜在客户的关键信息。
- en: '[](https://medium.com/@danielwarfield1?source=post_page-----46d70e1a846c--------------------------------)[![Daniel
    Warfield](../Images/c1c8b4dd514f6813e08e401401324bca.png)](https://medium.com/@danielwarfield1?source=post_page-----46d70e1a846c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----46d70e1a846c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----46d70e1a846c--------------------------------)
    [Daniel Warfield](https://medium.com/@danielwarfield1?source=post_page-----46d70e1a846c--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@danielwarfield1?source=post_page-----46d70e1a846c--------------------------------)[![Daniel
    Warfield](../Images/c1c8b4dd514f6813e08e401401324bca.png)](https://medium.com/@danielwarfield1?source=post_page-----46d70e1a846c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----46d70e1a846c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----46d70e1a846c--------------------------------)
    [Daniel Warfield](https://medium.com/@danielwarfield1?source=post_page-----46d70e1a846c--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----46d70e1a846c--------------------------------)
    ·18 min read·Sep 25, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----46d70e1a846c--------------------------------)
    ·18分钟阅读·2023年9月25日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/e4c31cbbc41f201ecdab003a52889978.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e4c31cbbc41f201ecdab003a52889978.png)'
- en: Image by Daniel Warfield using MidJourney. All images by the author unless otherwise
    specified.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 Daniel Warfield 使用 MidJourney 制作。所有图片均由作者提供，除非另有说明。
- en: In this post we’ll use LangChain to do lead qualification in a real-estate context.
    We imagine a scenario where new potential customers contact a real-estate agent
    for the first time. We’ll design a system which communicates with a new prospective
    lead to extract key information before the real-estate agent takes over.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将使用 LangChain 在房地产环境中进行线索资格审查。我们设想一个场景，新潜在客户首次联系房地产代理。我们将设计一个系统，与新潜在线索沟通，以提取关键信息，然后由房地产代理接手。
- en: '**Who is this useful for?** Anyone interested in applying natural language
    processing (NLP) in a practical context.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**这对谁有用？** 任何对在实际环境中应用自然语言处理（NLP）感兴趣的人。'
- en: '**How advanced is this post?** This example is conceptually straightforward,
    but you might struggle to follow along if you don’t have a firm grasp of Python
    and a general understanding of language models'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**这篇文章的高级程度如何？** 这个例子在概念上很直接，但如果你对 Python 和语言模型没有牢固的理解，可能会很难跟上。'
- en: '**Prerequisites:** Fundamental programming knowledge in Python, and a high
    level understanding of language models.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**先决条件：** 基础的 Python 编程知识以及对语言模型的高级理解。'
- en: A Description of the Problem
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题描述
- en: 'This use case is directly inspired by a work request I received while operating
    as a contractor. The prospective client owned a real-estate company, and found
    that a significant amount of their agent’s time was spent performing the same
    repetitive task at the beginning of each conversation: lead qualification.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这个用例直接受到了我作为承包商时收到的工作请求的启发。潜在客户拥有一家房地产公司，并发现他们的代理在每次对话开始时花费了大量时间执行相同的重复任务：线索资格审查。
- en: 'Lead qualification is the real-estate term for the first pass at a lead. Getting
    their contact information, their budget, etc. It’s a pretty broad term, and the
    details can fluctuate from organization to organization. For this post, we’ll
    consider extracting the following information as “qualifying” a lead:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 线索资格审查是房地产术语中对线索的初步筛选。获取他们的联系信息、预算等。这是一个相当广泛的术语，具体细节可能因组织而异。在这篇文章中，我们将“资格审查”线索的以下信息视为有效：
- en: '**Name:** the name of the lead.'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**姓名：** 线索的姓名。'
- en: '**Contact Info:** The email or phone number of the lead.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**联系信息：** 线索的电子邮件或电话号码。'
- en: '**Financing:** Their budget to rent monthly.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**融资：** 他们的月租预算。'
- en: '**Readiness:** How quickly can they meet with an agent.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**准备情况：** 他们能多快与代理见面。'
- en: The Approach
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方法
- en: The naive approach
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 天真的方法
- en: 'While large language models are incredibly powerful, they need proper contextualization
    of the use case to be consistently successful. You could, for instance, give a
    language model a prompt saying something like:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大型语言模型非常强大，但它们需要对用例进行适当的上下文化才能持续成功。例如，你可以给语言模型一个提示，类似于：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Then, you could put your new client in a chat room with a model initialized
    with that prompt. This would be a great way to start experimenting with an LLM
    in a particular business context, but is also a great way to begin realizing how
    fragile LLMs are to certain types of feedback. The conversation could quickly
    derail if a user asked a benign but irrelevant question like “Did you catch the
    game last night?” or “Yeah, I was walking down the road and I saw your complex
    on second.” This may or may not be a serious issue depending on the use case,
    but imposing a rigid structure around the conversation can help keep things on
    track.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以将新的客户放入一个与该提示初始化的模型的聊天房间中。这将是开始在特定业务环境中尝试 LLM 的好方法，同时也是开始意识到 LLM 对某些类型反馈的脆弱性的好方法。如果用户问了一个无害但无关的问题，比如“你昨晚看比赛了吗？”或“是的，我在路上走时看到你们的建筑了。”对某些用例来说这可能是个严重的问题，也可能不是，但对话周围的严格结构可以帮助保持对话的正常进行。
- en: Conversations as Directed Graphs
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对话作为有向图
- en: We can frame a conversation as a directed graph, where each node represents
    a certain conversational state, and each edge represents an impetus to change
    the conversational state, like a completed introduction or acquired piece of information.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将对话框架设为有向图，其中每个节点代表某个对话状态，每条边代表改变对话状态的动力，如完成的介绍或获得的信息。
- en: '![](../Images/d9cdbcb8fe724aeec7bb01e703f9417a.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9cdbcb8fe724aeec7bb01e703f9417a.png)'
- en: Example of what directed graph traversal might look like in the context of the
    problem we’re trying to solve
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们尝试解决的问题的背景下，有向图遍历的示例
- en: This is just about the most fundamental directed graph we could compose for
    this problem. It’s worth noting that this approach can easily grow, shrink, or
    otherwise change based on the needs of the system.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们为这个问题构建的最基本的有向图。值得注意的是，这种方法可以根据系统的需要轻松地扩展、收缩或以其他方式改变。
- en: For instance, if your clients consistently ask the chatbot about sports, which
    was unanticipated in the initial design phase, then you can add the relevant logic
    to check for this type of question and respond appropriately.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你的客户持续向聊天机器人询问体育问题，而这在初始设计阶段没有预料到，那么你可以添加相关逻辑以检查此类问题并作出适当回应。
- en: '![](../Images/d75387683582c046884ecfc7107d4be1.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d75387683582c046884ecfc7107d4be1.png)'
- en: Example modification of dealing with sports related questions. We’ll stick with
    the original simple graph, but it’s easy to see how emerging edge cases and poor
    performance scenarios can be mitigated by adding additional elements to an existing
    directed graph.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 处理与体育相关的问题的示例修改。我们将继续使用原始的简单图，但很容易看出，通过向现有有向图中添加额外元素，可以缓解出现的边界情况和性能较差的场景。
- en: When creating a new system which interacts with humans in an organic way it’s
    vital for it to be easily iterated on as new and unexpected issues arise. We’ll
    keep it simple for the purposes of this example, but extensibility is one of the
    core abilities of this approach.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 当创建一个以自然方式与人类互动的新系统时，它必须能够轻松迭代以应对新出现的意外问题。为了本示例的目的，我们将保持简单，但可扩展性是这种方法的核心能力之一。
- en: Key Technologies
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关键技术
- en: 'We’ll be using LangChain to do most of the heavy lifting. Specifically, we’ll
    be using:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 LangChain 来完成大部分繁重的工作。具体来说，我们将使用：
- en: '**an LLM:** We’ll be using OpenAI’s Text DaVinci 3 model.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**一个 LLM：** 我们将使用 OpenAI 的 Text DaVinci 3 模型。'
- en: '**Output Parsing:** We’ll be using LangChain’s Pydantic parser to parse results
    into easy to consume formats.'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**输出解析：** 我们将使用 LangChain 的 Pydantic 解析器将结果解析成易于处理的格式。'
- en: We’ll also be implementing a **Directed Graph** from scratch, with some functionality
    baked into that graph to achieve the desired functionality.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将从头开始实现一个**有向图**，并在该图中内置一些功能以实现所需的功能。
- en: The Model
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型
- en: In this example we’re using OpenAI’s *Text Davinci 3* model. While you could
    use almost any modern large language model, I chose to use this particular model
    because it’s widely used in LangChain examples and documentation.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们使用的是 OpenAI 的*Text Davinci 3* 模型。虽然你可以使用几乎任何现代的大型语言模型，但我选择使用这个特定模型，因为它在
    LangChain 示例和文档中被广泛使用。
- en: LangChain does its best to be a robust and resilient framework, but working
    with large language models is fiddly work. Different models can behave drastically
    differently to a given prompt. I found that Text Davinci 3 behaved consistently
    with prompts from LangChain.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 尽力成为一个强大而稳健的框架，但处理大型语言模型的工作很繁琐。不同的模型对给定的提示可能会有截然不同的行为。我发现 Text Davinci
    3 对来自 LangChain 的提示反应一致。
- en: LangChain allows you to use self-hosted models, models hosted for free on Hugging
    Face, or models from numerous other sources. Feel free to experiment with your
    choice of model; it’s pretty easy to swap between them (though, in my experience,
    you will probably have to adjust your prompts to the particular model you’re using).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 允许你使用自托管模型、Hugging Face 上免费托管的模型或来自其他多个来源的模型。随意尝试你选择的模型；它们之间的切换相当简单（尽管根据我的经验，你可能需要根据你使用的特定模型调整提示）。
- en: 'Text Davinci 3 is a transformer model, feel free to read the following article
    for more information:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Text Davinci 3 是一个变换器模型，随意阅读以下文章以获取更多信息：
- en: '[](https://medium.com/@danielwarfield1/transformers-intuitively-and-exhaustively-explained-58a5c5df8dbb?source=post_page-----46d70e1a846c--------------------------------)
    [## Transformers — Intuitively and Exhaustively Explained'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 变换器 — 直观且详尽的解释](https://medium.com/@danielwarfield1/transformers-intuitively-and-exhaustively-explained-58a5c5df8dbb?source=post_page-----46d70e1a846c--------------------------------)'
- en: Yet another post exploring the modern wave of machine learning. I hope you’ll
    find this one intuitive and thought…
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 又一篇探讨现代机器学习浪潮的文章。希望你会觉得这篇直观且发人深省…
- en: medium.com](https://medium.com/@danielwarfield1/transformers-intuitively-and-exhaustively-explained-58a5c5df8dbb?source=post_page-----46d70e1a846c--------------------------------)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[medium.com](https://medium.com/@danielwarfield1/transformers-intuitively-and-exhaustively-explained-58a5c5df8dbb?source=post_page-----46d70e1a846c--------------------------------)'
- en: LangChain Parsing
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LangChain 解析
- en: LangChain has a variety of parsers designed to be used with large language models.
    We’ll be using the PydanticOutputParser.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 拥有多种解析器，旨在与大型语言模型配合使用。我们将使用 PydanticOutputParser。
- en: 'LangChain parsers not only extract key information from LLM responses, but
    also modify prompts to entice more parsable responses from the LLM. With the Pydantic
    parser you first define a class representing the format of the results you want
    from the LLM. Let’s say you want to get a joke, complete with setup and punchline,
    from an LLM:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 解析器不仅从 LLM 响应中提取关键信息，还修改提示以引导 LLM 提供更多可解析的响应。使用 Pydantic 解析器时，你首先定义一个表示你希望从
    LLM 中获得结果格式的类。假设你想从 LLM 中获得一个笑话，包括开场白和笑点：
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: you can then define the actual query you want to send to the model.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以定义要发送给模型的实际查询。
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This query then gets modified by the parser, combining the user’s query and
    information about the final parsing format to construct the prompt to the llm.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这个查询随后被解析器修改，结合用户的查询和有关最终解析格式的信息，以构建对 LLM 的提示。
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The prompt for this particular example is the following:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特定示例的提示如下：
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '{"properties": {"setup": {"title": "Setup", "description": "question to set
    up a joke", "type": "string"}, "punchline": {"title": "Punchline", "description":
    "answer to resolve the joke", "type": "string"}}, "required": ["setup", "punchline"]}'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '{"properties": {"setup": {"title": "开场白", "description": "设置笑话的提问", "type":
    "string"}, "punchline": {"title": "笑点", "description": "解决笑话的回答", "type": "string"}},
    "required": ["setup", "punchline"]}'
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Notice how the query from the user “Tell me a joke about parrots” is combined
    with information about the desired end format.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 注意用户的查询“告诉我一个关于鹦鹉的笑话”是如何与关于所需最终格式的信息结合的。
- en: 'This formatted query can then be passed to the model, and the parser can be
    used to extract the result:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，这个格式化的查询可以传递给模型，解析器可以用来提取结果：
- en: '[PRE6]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Here’s the result from this particular example:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这是这个特定示例的结果：
- en: '[PRE7]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The PydanticOutputParser is both powerful and flexible, which is why it’s the
    most commonly used parser in LangChain. We’ll be exploring this parser more throughout
    this post. The OutputFixingParser and RetryOutputParser are two other very useful
    output parsers which will not be explored in this post, but certainly could be
    used in this use case.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: PydanticOutputParser 既强大又灵活，这就是它在 LangChain 中最常用的解析器的原因。我们将在本篇文章中进一步探讨这个解析器。OutputFixingParser
    和 RetryOutputParser 是另外两个非常有用的输出解析器，在本篇文章中不会详细探讨，但在此用例中肯定可以使用。
- en: Conversations as a Directed Graph
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对话作为一个有向图
- en: We’ll be abstracting a conversation into a directed graph.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把对话抽象为一个有向图。
- en: '![](../Images/d9cdbcb8fe724aeec7bb01e703f9417a.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9cdbcb8fe724aeec7bb01e703f9417a.png)'
- en: The approach in its most basic form. A series of conversational states, where
    the state of the conversation progresses once certain information is received
    from the human being communicated with.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最基本形式的这种方法。它是一个对话状态的序列，当从对方接收到特定信息时，对话状态就会进展。
- en: 'Each node and edge will need to be customized, but will follow the same general
    structure:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 每个节点和边都需要自定义，但会遵循相同的一般结构：
- en: '![](../Images/bd5c5a4cb2bb07c7bd42bfda364c635e.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bd5c5a4cb2bb07c7bd42bfda364c635e.png)'
- en: How nodes and edges will work. The box in blue represents a conversational state,
    so the entire box in blue represents a single node and its functionality. The
    box in red represents the required steps to transition between conversational
    states, so the entire box in red represents an edge and its functionality.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 节点和边的工作原理。蓝色的框表示对话状态，因此蓝色框表示单个节点及其功能。红色的框表示在对话状态之间过渡所需的步骤，因此红色框表示边及其功能。
- en: It’s worth noting that LangChain has a similar structure, called a Chain. We
    won't be discussing Chains in this post, but they are useful for direct and sequential
    LLM tasks.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，LangChain 具有类似的结构，称为 Chain。我们在这篇文章中不会讨论 Chains，但它们对于直接和顺序的 LLM 任务很有用。
- en: Defining Nodes and Edges
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义节点和边
- en: This is where we start coding up an LLM supported directed graph with the core
    aforementioned structure. We’ll be using Pydantic parsers for both the input validation
    step as well as the actual content parsing.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们开始编码一个支持 LLM 的定向图，具有上述核心结构。我们将使用 Pydantic 解析器来处理输入验证步骤以及实际内容解析。
- en: 'I’m including the code for reference, but don’t be daunted by the length. You
    can skim through the code, or not refer to the code at all if you don’t want to.
    The final notebook can be found here:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我提供了代码作为参考，但不要被代码的长度吓到。你可以快速浏览代码，或者完全不参考代码。最终的笔记本可以在这里找到：
- en: '[](https://colab.research.google.com/drive/1oSKFO2ho6BN__pZp0uQNwP-HWeXGPpKU?source=post_page-----46d70e1a846c--------------------------------#scrollTo=IgzZooHUoIQw)
    [## Google Colaboratory'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://colab.research.google.com/drive/1oSKFO2ho6BN__pZp0uQNwP-HWeXGPpKU?source=post_page-----46d70e1a846c--------------------------------#scrollTo=IgzZooHUoIQw)
    [## Google Colaboratory'
- en: Edit description
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编辑描述
- en: colab.research.google.com](https://colab.research.google.com/drive/1oSKFO2ho6BN__pZp0uQNwP-HWeXGPpKU?source=post_page-----46d70e1a846c--------------------------------#scrollTo=IgzZooHUoIQw)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: colab.research.google.com](https://colab.research.google.com/drive/1oSKFO2ho6BN__pZp0uQNwP-HWeXGPpKU?source=post_page-----46d70e1a846c--------------------------------#scrollTo=IgzZooHUoIQw)
- en: General Utilities
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通用工具
- en: 'For demonstrative purposes, all of this will exist within a single Jupyter
    notebook, and the final back and forth between the model will be executed in the
    final cell. In order to improve readability, we’ll define three functions: one
    for model output to the user, one for user input to the model, and another for
    printing key information for demonstration, like the results of parsing.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 出于演示目的，所有这些内容将存在于一个 Jupyter 笔记本中，模型之间的最终往返将在最后一个单元格中执行。为了提高可读性，我们将定义三个函数：一个用于模型输出给用户，一个用于用户输入给模型，另一个用于打印演示所需的关键信息，如解析结果。
- en: '[PRE8]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Defining the Edge
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义边
- en: As the code suggests, an edge takes some input, checks it against a condition,
    and then parses the input if the condition was met. The edge contains the relevant
    logic for recording the number of times it’s been attempted and failed, and is
    responsible for telling higher level units whether we should progress through
    the directed graph along the edge or not.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 正如代码所示，边缘接受一些输入，将其与条件进行比较，如果条件满足，则解析输入。边缘包含相关的逻辑来记录尝试失败的次数，并负责告诉更高级别的单元是否应该沿着边缘在定向图中继续前进。
- en: '[PRE9]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: I created a few unit tests in the code [here](https://colab.research.google.com/drive/1oSKFO2ho6BN__pZp0uQNwP-HWeXGPpKU#scrollTo=Dc7XI7NlU71j&line=1&uniqifier=1)
    which illustrate how the edge functions.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我在代码中创建了一些单元测试 [这里](https://colab.research.google.com/drive/1oSKFO2ho6BN__pZp0uQNwP-HWeXGPpKU#scrollTo=Dc7XI7NlU71j&line=1&uniqifier=1)，展示了边缘的功能。
- en: Defining the Node
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义节点
- en: Now that we have an Edge, which handles input validation and parsing, we can
    define a Node, which handles conversational state. The Node requests a user for
    input, and passes that input to the directed edges coming from that Node. If none
    of the edges execute successfully, the Node asks the user for the input again.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个处理输入验证和解析的边，我们可以定义一个处理对话状态的节点。节点请求用户输入，并将该输入传递给来自该节点的定向边。如果没有一条边成功执行，节点会再次询问用户输入。
- en: '[PRE10]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'With this implemented, we can begin seeing conversations take place. We’ll
    implement a Node which requests contact information, and two edges: one which
    attempts to parse out a valid email, and one that attempts to parse out a valid
    phone number.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 实现了这个，我们可以开始看到对话的进行。我们将实现一个请求联系信息的节点，以及两个边：一个尝试解析有效的邮箱，另一个尝试解析有效的电话号码。
- en: '[PRE11]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Here’s a few examples of conversations with this single node:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这是几个具有单一节点的对话示例：
- en: '[PRE12]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In example 1 the user includes some irrelevant information, but has a valid
    email in the response. In example 2 the user does not have a valid email or phone
    number in the first response, but does have one in the second. In example 3 the
    user has no valid responses, and one of the edges gives up and allows the conversation
    to progress.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在示例 1 中，用户包括了一些无关的信息，但在响应中有一个有效的邮箱。在示例 2 中，用户在第一次响应中没有有效的邮箱或电话号码，但在第二次响应中有一个。在示例
    3 中，用户没有有效的响应，其中一个边缘放弃并允许对话继续。
- en: It’s worth noting, from a user feel perspective, this approach feels a bit robotic.
    While not explored in this post, it’s easy to imagine how the user input could
    be used to construct the systems output to the user, either through string formatting
    or by asking an LLM to format a response.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，从用户体验的角度来看，这种方法感觉有点机械。虽然在本文中没有探讨，但很容易想象用户输入如何被用来构造系统的输出，可能通过字符串格式化或请求LLM格式化响应。
- en: Defining the Conversation
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义对话
- en: 'Now that we have Nodes and Edges, and have defined their functionality, we
    can put it all together to create the final conversation. We covered a general
    blueprint previously, but let’s brush it up to be more reflective of what the
    graph will actually be doing. Recall the following:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了节点和边缘，并定义了它们的功能，我们可以将所有这些整合在一起，创建最终的对话。我们之前已经覆盖了一个大致的蓝图，但让我们修改它，以更好地反映图实际要做的事情。请回顾以下内容：
- en: '**Nodes have an initial prompt and a retry prompt**'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点有初始提示和重试提示**'
- en: '**Edges have a condition, a parsing prompt, and a parsing structure**. The
    condition is a boolean question asked about the users input. If the condition
    is satisfied, the parsing structure is parsed based on the parsing prompt and
    the users input. This is done by asking the large language model to reformat the
    users input into a parsable representation using the pydantic parser.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**边缘有一个条件、一个解析提示和一个解析结构**。条件是一个关于用户输入的布尔问题。如果条件满足，则根据解析提示和用户输入解析解析结构。这是通过请求大型语言模型将用户输入重新格式化为可解析的表示，使用pydantic解析器来完成的。'
- en: 'Lets construct a conversational graph based on these definitions:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们根据这些定义构建一个对话图：
- en: '![](../Images/403d709d4121109480cb4aac503222f4.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/403d709d4121109480cb4aac503222f4.png)'
- en: The conversational graph we’ll be implementing, complete with all the necessary
    parameters for the nodes and edges.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要实现的对话图，包括所有必要的节点和边缘参数。
- en: As can be seen in the diagram above, some prompt engineering has been done to
    accommodate certain edge cases. For instance, the parsing prompt for Budget allows
    the parser to parse user responses like “my budget is around 1.5k”.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的图示可以看出，已经做了一些提示工程以适应某些边缘情况。例如，预算的解析提示允许解析器解析用户响应，例如“我的预算大约是1.5k”。
- en: Because of the flexibility of LLMs, it’s really up to the engineer exactly how
    a graph like this might be implemented. if price parsing proves to be an issue
    in the future, one might have a few edges, each with different conditions and
    parsing prompts. For instance, one could imagine an edge that checks if a budget
    is over a certain value, thus implying that they’re providing a yearly budget
    instead of a monthly budget. The power of this system is for the seamless addition
    or removal of these modifications.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 由于LLMs的灵活性，究竟如何实现这样的图完全取决于工程师。如果价格解析在未来成为问题，可以有几个边，每个边有不同的条件和解析提示。例如，可以想象一个边检查预算是否超过某个值，从而暗示他们提供的是年度预算而不是月度预算。这个系统的强大之处在于可以无缝添加或删除这些修改。
- en: Implementing the Conversational Graph
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现对话图
- en: 'We’ve already done all the heavy lifting, now we just need to code it up and
    see how it works. Here’s the implementation:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了所有的重头戏，现在只需要编码并查看它是如何工作的。以下是实现代码：
- en: '[PRE15]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'And here are a few example conversations:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些示例对话：
- en: '[PRE16]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Conclusion
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this article we formatted a lead qualification use case as a directed graph,
    implemented the necessary parsing functionality and data structures, and made
    an example graph which extracts key information from users. As can be seen in
    the example conversations this system is by no means perfect, but because of the
    nature of directed graphs we can easily add new nodes to alleviate the impact
    of certain edge cases.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将一个潜在客户资格的用例格式化为有向图，实施了必要的解析功能和数据结构，并制作了一个示例图，该图从用户那里提取关键信息。正如示例对话所示，这个系统并不完美，但由于有向图的性质，我们可以轻松添加新节点，以缓解某些边界情况的影响。
- en: 'While not discussed in this article, there’s a lot of ways to improve upon
    this system:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本文未讨论，但还有许多方法可以改进这个系统：
- en: We could use different LangChain parsers to attempt to re-try or correct queries.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用不同的LangChain解析器来尝试重试或纠正查询。
- en: We could use an LLM Cache to try to cache certain common responses, thus saving
    on budget.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用LLM缓存来尝试缓存某些常见响应，从而节省预算。
- en: We could connect this system with a vector database to allow question answering
    against a knowledge base.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以将该系统与矢量数据库连接，以便对知识库进行问答。
- en: We could use the LLM to construct the prompts to the user, along with context
    about the conversation, to encourage more organic responses.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用LLM来构建用户的提示，并提供有关对话的上下文，以鼓励更自然的回应。
- en: While my contracting gig didn’t pan out, I think this approach highlights a
    flexible and robust framework which is extensible and applicable to a variety
    of applications.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我的合同工作没有成功，但我认为这种方法突显了一个灵活且强大的框架，该框架具有可扩展性，适用于各种应用。
- en: Follow For More!
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关注获取更多信息！
- en: I describe papers and concepts in the ML space, with an emphasis on practical
    and intuitive explanations.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我描述了机器学习领域的论文和概念，重点放在实际和直观的解释上。
- en: '**Attribution:** All of the images in this document were created by Daniel
    Warfield, unless a source is otherwise provided. You can use any images in this
    post for your own non-commercial purposes, so long as you reference this article,
    [https://danielwarfield.dev](https://danielwarfield.dev/), or both.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**致谢：** 本文档中的所有图片均由**丹尼尔·沃菲尔德**创建，除非另有来源说明。您可以将此帖中的任何图片用于个人非商业用途，只需引用本文， [https://danielwarfield.dev](https://danielwarfield.dev/)，或两者兼用。'
