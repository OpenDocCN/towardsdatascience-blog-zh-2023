- en: Conversations as Directed Graphs with LangChain
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 LangChain 将对话作为有向图
- en: 原文：[https://towardsdatascience.com/conversations-as-directed-graphs-with-lang-chain-46d70e1a846c](https://towardsdatascience.com/conversations-as-directed-graphs-with-lang-chain-46d70e1a846c)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/conversations-as-directed-graphs-with-lang-chain-46d70e1a846c](https://towardsdatascience.com/conversations-as-directed-graphs-with-lang-chain-46d70e1a846c)
- en: Building a chatbot designed to understand key information about new prospective
    customers.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建一个聊天机器人，旨在了解关于新潜在客户的关键信息。
- en: '[](https://medium.com/@danielwarfield1?source=post_page-----46d70e1a846c--------------------------------)[![Daniel
    Warfield](../Images/c1c8b4dd514f6813e08e401401324bca.png)](https://medium.com/@danielwarfield1?source=post_page-----46d70e1a846c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----46d70e1a846c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----46d70e1a846c--------------------------------)
    [Daniel Warfield](https://medium.com/@danielwarfield1?source=post_page-----46d70e1a846c--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@danielwarfield1?source=post_page-----46d70e1a846c--------------------------------)[![Daniel
    Warfield](../Images/c1c8b4dd514f6813e08e401401324bca.png)](https://medium.com/@danielwarfield1?source=post_page-----46d70e1a846c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----46d70e1a846c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----46d70e1a846c--------------------------------)
    [Daniel Warfield](https://medium.com/@danielwarfield1?source=post_page-----46d70e1a846c--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----46d70e1a846c--------------------------------)
    ·18 min read·Sep 25, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----46d70e1a846c--------------------------------)
    ·18分钟阅读·2023年9月25日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/e4c31cbbc41f201ecdab003a52889978.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e4c31cbbc41f201ecdab003a52889978.png)'
- en: Image by Daniel Warfield using MidJourney. All images by the author unless otherwise
    specified.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 Daniel Warfield 使用 MidJourney 制作。所有图片均由作者提供，除非另有说明。
- en: In this post we’ll use LangChain to do lead qualification in a real-estate context.
    We imagine a scenario where new potential customers contact a real-estate agent
    for the first time. We’ll design a system which communicates with a new prospective
    lead to extract key information before the real-estate agent takes over.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将使用 LangChain 在房地产环境中进行线索资格审查。我们设想一个场景，新潜在客户首次联系房地产代理。我们将设计一个系统，与新潜在线索沟通，以提取关键信息，然后由房地产代理接手。
- en: '**Who is this useful for?** Anyone interested in applying natural language
    processing (NLP) in a practical context.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**这对谁有用？** 任何对在实际环境中应用自然语言处理（NLP）感兴趣的人。'
- en: '**How advanced is this post?** This example is conceptually straightforward,
    but you might struggle to follow along if you don’t have a firm grasp of Python
    and a general understanding of language models'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**这篇文章的高级程度如何？** 这个例子在概念上很直接，但如果你对 Python 和语言模型没有牢固的理解，可能会很难跟上。'
- en: '**Prerequisites:** Fundamental programming knowledge in Python, and a high
    level understanding of language models.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**先决条件：** 基础的 Python 编程知识以及对语言模型的高级理解。'
- en: A Description of the Problem
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题描述
- en: 'This use case is directly inspired by a work request I received while operating
    as a contractor. The prospective client owned a real-estate company, and found
    that a significant amount of their agent’s time was spent performing the same
    repetitive task at the beginning of each conversation: lead qualification.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这个用例直接受到了我作为承包商时收到的工作请求的启发。潜在客户拥有一家房地产公司，并发现他们的代理在每次对话开始时花费了大量时间执行相同的重复任务：线索资格审查。
- en: 'Lead qualification is the real-estate term for the first pass at a lead. Getting
    their contact information, their budget, etc. It’s a pretty broad term, and the
    details can fluctuate from organization to organization. For this post, we’ll
    consider extracting the following information as “qualifying” a lead:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 线索资格审查是房地产术语中对线索的初步筛选。获取他们的联系信息、预算等。这是一个相当广泛的术语，具体细节可能因组织而异。在这篇文章中，我们将“资格审查”线索的以下信息视为有效：
- en: '**Name:** the name of the lead.'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**姓名：** 线索的姓名。'
- en: '**Contact Info:** The email or phone number of the lead.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**联系信息：** 线索的电子邮件或电话号码。'
- en: '**Financing:** Their budget to rent monthly.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**融资：** 他们的月租预算。'
- en: '**Readiness:** How quickly can they meet with an agent.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**准备情况：** 他们能多快与代理见面。'
- en: The Approach
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方法
- en: The naive approach
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 天真的方法
- en: 'While large language models are incredibly powerful, they need proper contextualization
    of the use case to be consistently successful. You could, for instance, give a
    language model a prompt saying something like:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Then, you could put your new client in a chat room with a model initialized
    with that prompt. This would be a great way to start experimenting with an LLM
    in a particular business context, but is also a great way to begin realizing how
    fragile LLMs are to certain types of feedback. The conversation could quickly
    derail if a user asked a benign but irrelevant question like “Did you catch the
    game last night?” or “Yeah, I was walking down the road and I saw your complex
    on second.” This may or may not be a serious issue depending on the use case,
    but imposing a rigid structure around the conversation can help keep things on
    track.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Conversations as Directed Graphs
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can frame a conversation as a directed graph, where each node represents
    a certain conversational state, and each edge represents an impetus to change
    the conversational state, like a completed introduction or acquired piece of information.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d9cdbcb8fe724aeec7bb01e703f9417a.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
- en: Example of what directed graph traversal might look like in the context of the
    problem we’re trying to solve
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: This is just about the most fundamental directed graph we could compose for
    this problem. It’s worth noting that this approach can easily grow, shrink, or
    otherwise change based on the needs of the system.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: For instance, if your clients consistently ask the chatbot about sports, which
    was unanticipated in the initial design phase, then you can add the relevant logic
    to check for this type of question and respond appropriately.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d75387683582c046884ecfc7107d4be1.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
- en: Example modification of dealing with sports related questions. We’ll stick with
    the original simple graph, but it’s easy to see how emerging edge cases and poor
    performance scenarios can be mitigated by adding additional elements to an existing
    directed graph.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: When creating a new system which interacts with humans in an organic way it’s
    vital for it to be easily iterated on as new and unexpected issues arise. We’ll
    keep it simple for the purposes of this example, but extensibility is one of the
    core abilities of this approach.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Key Technologies
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We’ll be using LangChain to do most of the heavy lifting. Specifically, we’ll
    be using:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '**an LLM:** We’ll be using OpenAI’s Text DaVinci 3 model.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Output Parsing:** We’ll be using LangChain’s Pydantic parser to parse results
    into easy to consume formats.'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We’ll also be implementing a **Directed Graph** from scratch, with some functionality
    baked into that graph to achieve the desired functionality.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: The Model
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this example we’re using OpenAI’s *Text Davinci 3* model. While you could
    use almost any modern large language model, I chose to use this particular model
    because it’s widely used in LangChain examples and documentation.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: LangChain does its best to be a robust and resilient framework, but working
    with large language models is fiddly work. Different models can behave drastically
    differently to a given prompt. I found that Text Davinci 3 behaved consistently
    with prompts from LangChain.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 尽力成为一个强大而稳健的框架，但处理大型语言模型的工作很繁琐。不同的模型对给定的提示可能会有截然不同的行为。我发现 Text Davinci
    3 对来自 LangChain 的提示反应一致。
- en: LangChain allows you to use self-hosted models, models hosted for free on Hugging
    Face, or models from numerous other sources. Feel free to experiment with your
    choice of model; it’s pretty easy to swap between them (though, in my experience,
    you will probably have to adjust your prompts to the particular model you’re using).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 允许你使用自托管模型、Hugging Face 上免费托管的模型或来自其他多个来源的模型。随意尝试你选择的模型；它们之间的切换相当简单（尽管根据我的经验，你可能需要根据你使用的特定模型调整提示）。
- en: 'Text Davinci 3 is a transformer model, feel free to read the following article
    for more information:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Text Davinci 3 是一个变换器模型，随意阅读以下文章以获取更多信息：
- en: '[](https://medium.com/@danielwarfield1/transformers-intuitively-and-exhaustively-explained-58a5c5df8dbb?source=post_page-----46d70e1a846c--------------------------------)
    [## Transformers — Intuitively and Exhaustively Explained'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 变换器 — 直观且详尽的解释](https://medium.com/@danielwarfield1/transformers-intuitively-and-exhaustively-explained-58a5c5df8dbb?source=post_page-----46d70e1a846c--------------------------------)'
- en: Yet another post exploring the modern wave of machine learning. I hope you’ll
    find this one intuitive and thought…
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 又一篇探讨现代机器学习浪潮的文章。希望你会觉得这篇直观且发人深省…
- en: medium.com](https://medium.com/@danielwarfield1/transformers-intuitively-and-exhaustively-explained-58a5c5df8dbb?source=post_page-----46d70e1a846c--------------------------------)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[medium.com](https://medium.com/@danielwarfield1/transformers-intuitively-and-exhaustively-explained-58a5c5df8dbb?source=post_page-----46d70e1a846c--------------------------------)'
- en: LangChain Parsing
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LangChain 解析
- en: LangChain has a variety of parsers designed to be used with large language models.
    We’ll be using the PydanticOutputParser.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 拥有多种解析器，旨在与大型语言模型配合使用。我们将使用 PydanticOutputParser。
- en: 'LangChain parsers not only extract key information from LLM responses, but
    also modify prompts to entice more parsable responses from the LLM. With the Pydantic
    parser you first define a class representing the format of the results you want
    from the LLM. Let’s say you want to get a joke, complete with setup and punchline,
    from an LLM:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 解析器不仅从 LLM 响应中提取关键信息，还修改提示以引导 LLM 提供更多可解析的响应。使用 Pydantic 解析器时，你首先定义一个表示你希望从
    LLM 中获得结果格式的类。假设你想从 LLM 中获得一个笑话，包括开场白和笑点：
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: you can then define the actual query you want to send to the model.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以定义要发送给模型的实际查询。
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This query then gets modified by the parser, combining the user’s query and
    information about the final parsing format to construct the prompt to the llm.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这个查询随后被解析器修改，结合用户的查询和有关最终解析格式的信息，以构建对 LLM 的提示。
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The prompt for this particular example is the following:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特定示例的提示如下：
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '{"properties": {"setup": {"title": "Setup", "description": "question to set
    up a joke", "type": "string"}, "punchline": {"title": "Punchline", "description":
    "answer to resolve the joke", "type": "string"}}, "required": ["setup", "punchline"]}'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '{"properties": {"setup": {"title": "开场白", "description": "设置笑话的提问", "type":
    "string"}, "punchline": {"title": "笑点", "description": "解决笑话的回答", "type": "string"}},
    "required": ["setup", "punchline"]}'
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Notice how the query from the user “Tell me a joke about parrots” is combined
    with information about the desired end format.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 注意用户的查询“告诉我一个关于鹦鹉的笑话”是如何与关于所需最终格式的信息结合的。
- en: 'This formatted query can then be passed to the model, and the parser can be
    used to extract the result:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，这个格式化的查询可以传递给模型，解析器可以用来提取结果：
- en: '[PRE6]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Here’s the result from this particular example:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这是这个特定示例的结果：
- en: '[PRE7]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The PydanticOutputParser is both powerful and flexible, which is why it’s the
    most commonly used parser in LangChain. We’ll be exploring this parser more throughout
    this post. The OutputFixingParser and RetryOutputParser are two other very useful
    output parsers which will not be explored in this post, but certainly could be
    used in this use case.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: PydanticOutputParser 既强大又灵活，这就是它在 LangChain 中最常用的解析器的原因。我们将在本篇文章中进一步探讨这个解析器。OutputFixingParser
    和 RetryOutputParser 是另外两个非常有用的输出解析器，在本篇文章中不会详细探讨，但在此用例中肯定可以使用。
- en: Conversations as a Directed Graph
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对话作为一个有向图
- en: We’ll be abstracting a conversation into a directed graph.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把对话抽象为一个有向图。
- en: '![](../Images/d9cdbcb8fe724aeec7bb01e703f9417a.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9cdbcb8fe724aeec7bb01e703f9417a.png)'
- en: The approach in its most basic form. A series of conversational states, where
    the state of the conversation progresses once certain information is received
    from the human being communicated with.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 'Each node and edge will need to be customized, but will follow the same general
    structure:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bd5c5a4cb2bb07c7bd42bfda364c635e.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
- en: How nodes and edges will work. The box in blue represents a conversational state,
    so the entire box in blue represents a single node and its functionality. The
    box in red represents the required steps to transition between conversational
    states, so the entire box in red represents an edge and its functionality.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: It’s worth noting that LangChain has a similar structure, called a Chain. We
    won't be discussing Chains in this post, but they are useful for direct and sequential
    LLM tasks.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Defining Nodes and Edges
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is where we start coding up an LLM supported directed graph with the core
    aforementioned structure. We’ll be using Pydantic parsers for both the input validation
    step as well as the actual content parsing.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: 'I’m including the code for reference, but don’t be daunted by the length. You
    can skim through the code, or not refer to the code at all if you don’t want to.
    The final notebook can be found here:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://colab.research.google.com/drive/1oSKFO2ho6BN__pZp0uQNwP-HWeXGPpKU?source=post_page-----46d70e1a846c--------------------------------#scrollTo=IgzZooHUoIQw)
    [## Google Colaboratory'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Edit description
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: colab.research.google.com](https://colab.research.google.com/drive/1oSKFO2ho6BN__pZp0uQNwP-HWeXGPpKU?source=post_page-----46d70e1a846c--------------------------------#scrollTo=IgzZooHUoIQw)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: General Utilities
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For demonstrative purposes, all of this will exist within a single Jupyter
    notebook, and the final back and forth between the model will be executed in the
    final cell. In order to improve readability, we’ll define three functions: one
    for model output to the user, one for user input to the model, and another for
    printing key information for demonstration, like the results of parsing.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Defining the Edge
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As the code suggests, an edge takes some input, checks it against a condition,
    and then parses the input if the condition was met. The edge contains the relevant
    logic for recording the number of times it’s been attempted and failed, and is
    responsible for telling higher level units whether we should progress through
    the directed graph along the edge or not.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: I created a few unit tests in the code [here](https://colab.research.google.com/drive/1oSKFO2ho6BN__pZp0uQNwP-HWeXGPpKU#scrollTo=Dc7XI7NlU71j&line=1&uniqifier=1)
    which illustrate how the edge functions.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Defining the Node
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have an Edge, which handles input validation and parsing, we can
    define a Node, which handles conversational state. The Node requests a user for
    input, and passes that input to the directed edges coming from that Node. If none
    of the edges execute successfully, the Node asks the user for the input again.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'With this implemented, we can begin seeing conversations take place. We’ll
    implement a Node which requests contact information, and two edges: one which
    attempts to parse out a valid email, and one that attempts to parse out a valid
    phone number.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Here’s a few examples of conversations with this single node:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In example 1 the user includes some irrelevant information, but has a valid
    email in the response. In example 2 the user does not have a valid email or phone
    number in the first response, but does have one in the second. In example 3 the
    user has no valid responses, and one of the edges gives up and allows the conversation
    to progress.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: It’s worth noting, from a user feel perspective, this approach feels a bit robotic.
    While not explored in this post, it’s easy to imagine how the user input could
    be used to construct the systems output to the user, either through string formatting
    or by asking an LLM to format a response.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Defining the Conversation
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have Nodes and Edges, and have defined their functionality, we
    can put it all together to create the final conversation. We covered a general
    blueprint previously, but let’s brush it up to be more reflective of what the
    graph will actually be doing. Recall the following:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '**Nodes have an initial prompt and a retry prompt**'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Edges have a condition, a parsing prompt, and a parsing structure**. The
    condition is a boolean question asked about the users input. If the condition
    is satisfied, the parsing structure is parsed based on the parsing prompt and
    the users input. This is done by asking the large language model to reformat the
    users input into a parsable representation using the pydantic parser.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lets construct a conversational graph based on these definitions:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/403d709d4121109480cb4aac503222f4.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
- en: The conversational graph we’ll be implementing, complete with all the necessary
    parameters for the nodes and edges.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: As can be seen in the diagram above, some prompt engineering has been done to
    accommodate certain edge cases. For instance, the parsing prompt for Budget allows
    the parser to parse user responses like “my budget is around 1.5k”.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Because of the flexibility of LLMs, it’s really up to the engineer exactly how
    a graph like this might be implemented. if price parsing proves to be an issue
    in the future, one might have a few edges, each with different conditions and
    parsing prompts. For instance, one could imagine an edge that checks if a budget
    is over a certain value, thus implying that they’re providing a yearly budget
    instead of a monthly budget. The power of this system is for the seamless addition
    or removal of these modifications.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the Conversational Graph
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We’ve already done all the heavy lifting, now we just need to code it up and
    see how it works. Here’s the implementation:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'And here are a few example conversations:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Conclusion
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article we formatted a lead qualification use case as a directed graph,
    implemented the necessary parsing functionality and data structures, and made
    an example graph which extracts key information from users. As can be seen in
    the example conversations this system is by no means perfect, but because of the
    nature of directed graphs we can easily add new nodes to alleviate the impact
    of certain edge cases.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将一个潜在客户资格的用例格式化为有向图，实施了必要的解析功能和数据结构，并制作了一个示例图，该图从用户那里提取关键信息。正如示例对话所示，这个系统并不完美，但由于有向图的性质，我们可以轻松添加新节点，以缓解某些边界情况的影响。
- en: 'While not discussed in this article, there’s a lot of ways to improve upon
    this system:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本文未讨论，但还有许多方法可以改进这个系统：
- en: We could use different LangChain parsers to attempt to re-try or correct queries.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用不同的LangChain解析器来尝试重试或纠正查询。
- en: We could use an LLM Cache to try to cache certain common responses, thus saving
    on budget.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用LLM缓存来尝试缓存某些常见响应，从而节省预算。
- en: We could connect this system with a vector database to allow question answering
    against a knowledge base.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以将该系统与矢量数据库连接，以便对知识库进行问答。
- en: We could use the LLM to construct the prompts to the user, along with context
    about the conversation, to encourage more organic responses.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用LLM来构建用户的提示，并提供有关对话的上下文，以鼓励更自然的回应。
- en: While my contracting gig didn’t pan out, I think this approach highlights a
    flexible and robust framework which is extensible and applicable to a variety
    of applications.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我的合同工作没有成功，但我认为这种方法突显了一个灵活且强大的框架，该框架具有可扩展性，适用于各种应用。
- en: Follow For More!
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关注获取更多信息！
- en: I describe papers and concepts in the ML space, with an emphasis on practical
    and intuitive explanations.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我描述了机器学习领域的论文和概念，重点放在实际和直观的解释上。
- en: '**Attribution:** All of the images in this document were created by Daniel
    Warfield, unless a source is otherwise provided. You can use any images in this
    post for your own non-commercial purposes, so long as you reference this article,
    [https://danielwarfield.dev](https://danielwarfield.dev/), or both.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**致谢：** 本文档中的所有图片均由**丹尼尔·沃菲尔德**创建，除非另有来源说明。您可以将此帖中的任何图片用于个人非商业用途，只需引用本文， [https://danielwarfield.dev](https://danielwarfield.dev/)，或两者兼用。'
