["```py\nInput -> [[[Conv-> ReLU] * N ] -> Pool?] * M -> [[FC+ReLU] * K] -> FC -> Scores\n```", "```py\n # models/detection/lenet.py\n\"\"\"\nPyTorch reference: https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n\"\"\"\nfrom __future__ import annotations\n\nimport lightning.pytorch as pl\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchmetrics\n\nclass LeNet(pl.LightningModule):\n    def __init__(self, in_channels: int, out_channels: int, lr: float = 2e-4):\n        \"\"\"\n        Args:\n        - in_channels: One for grayscale input image (which is the case for MNIST), 3 for RGB input image.\n        - out_channels: Number of classes of the classifier. 10 for MNIST.\n        \"\"\"\n        super().__init__()\n        # Debugging tool to display intermediate input/output size of all your layer (called before fit)\n        self.example_input_array = torch.Tensor(16, in_channels, 32, 32)\n        self.learning_rate = lr\n\n        self.train_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=out_channels)\n        self.val_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=out_channels)\n        self.test_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=out_channels)\n\n        # [img_size] 32 -> conv -> 32 -> (max_pool) -> 16\n        # with 6 output activation maps\n        self.conv_layer1 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=in_channels,\n                out_channels=6,\n                kernel_size=5,\n                stride=1,\n                # Either resize (28x28) MNIST images to (32x32) or pad the imput to be 32x32\n                # padding=2,\n            ),\n            nn.MaxPool2d(kernel_size=2),\n        )\n        # [img_size] 16 -> (conv) -> 10 -> (max pool) 5\n        self.conv_layer2 = nn.Sequential(\n            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        # The activation size (number of values after passing through one layer) is getting gradually smaller and smaller.\n        # The output is flatten and then used as a long input into the next dense layers.\n        self.fc1 = nn.Linear(in_features=16 * 5 * 5, out_features=120)  # 5 from the image dimension\n        self.fc2 = nn.Linear(in_features=120, out_features=84)\n        # \"Softmax\" layer = Linear + Softmax.\n        self.fc3 = nn.Linear(in_features=84, out_features=out_channels)\n```", "```py\n self.fc1 = nn.Linear(in_features=16 * 5 * 5, out_features=120)  # 5 from the image dimension\n  self.fc2 = nn.Linear(in_features=120, out_features=84)\n  # \"Softmax\" layer = Linear + Softmax.\n  self.fc3 = nn.Linear(in_features=84, out_features=out_channels) \n```", "```py\n# Method of LetNet class in models/detection/lenet.py\ndef forward(self, x: torch.Tensor) -> torch.Tensor:\n    x = F.relu(self.conv_layer1(x))\n    x = F.relu(self.conv_layer2(x))\n    x = torch.flatten(x, 1)  # flatten all dimensions except the batch dimension\n    x = F.relu(self.fc1(x))\n    x = F.relu(self.fc2(x))\n    x = self.fc3(x)\n    return x\n```", "```py\ndef configure_optimizers(self) -> torch.optim.Adam:\n      return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n```", "```py\n # Methods in LeNet class in models/detection.lenet.py\n  ###############################\n  # --- For Pytorch Lightning ---\n  ###############################\n\n  def validation_step(\n      self,\n      batch: list[torch.Tensor, torch.Tensor],\n      batch_idx: int,\n      verbose: bool = True,\n  ) -> torch.Tensor:\n      \"\"\"Function called when using `trainer.validate()` with trainer a\n      lightning `Trainer` instance.\"\"\"\n      x, y = batch\n      logit_preds = self(x)\n      loss = F.cross_entropy(logit_preds, y)\n      self.val_accuracy.update(torch.argmax(logit_preds, dim=1), y)\n      self.log(\"val_loss\", loss)\n      self.log(\"val_acc_step\", self.val_accuracy, on_epoch=True)\n      return loss\n\n  def training_step(\n      self,\n      batch: list[torch.Tensor, torch.Tensor],\n      batch_idx: int,\n  ) -> torch.Tensor:\n      \"\"\"Function called when using `trainer.fit()` with trainer a\n      lightning `Trainer` instance.\"\"\"\n      x, y = batch\n      logit_preds = self(x)\n      loss = F.cross_entropy(logit_preds, y)\n      self.train_accuracy.update(torch.argmax(logit_preds, dim=1), y)\n      self.log(\"train_acc_step\", self.train_accuracy, on_step=True, on_epoch=True, logger=True)\n      # logs metrics for each training_step,\n      # and the average across the epoch, to the progress bar and logger\n      self.log(\"train_loss\", loss, on_step=True, on_epoch=True, logger=True)\n      return loss \n```", "```py\ndef test_step(\n      self,\n      batch: list[torch.Tensor, torch.Tensor],\n      batch_idx: int,\n  ):\n      \"\"\"Function called when using `trainer.test()` with trainer a\n      lightning `Trainer` instance.\"\"\"\n      x, y = batch\n      logit_preds = self(x)\n      loss = F.cross_entropy(logit_preds, y)\n      self.test_accuracy.update(torch.argmax(logit_preds, dim=1), y)\n      self.log_dict({\"test_loss\": loss, \"test_acc\": self.test_accuracy})\n\n  def predict_step(\n      self, batch: list[torch.Tensor, torch.Tensor], batch_idx: int\n  ) -> tuple[torch.Tensor, torch.Tensor]:\n      \"\"\"Function called when using `trainer.predict()` with trainer a\n      lightning `Trainer` instance.\"\"\"\n      x, _ = batch\n      logit_preds = self(x)\n      softmax_preds = F.softmax(logit_preds, dim=1)\n      return x, softmax_preds\n```", "```py\n# datasets/mnist.py\n\"\"\"\nMore at https://lightning.ai/docs/pytorch/stable/data/datamodule.html\n\"\"\"\nimport logging\nfrom pathlib import Path\n\nimport lightning.pytorch as pl\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import transforms\nfrom torchvision.datasets import MNIST\n\n# Create a logger\nlogger = logging.getLogger(Path(__file__).stem)\nlogger.setLevel(logging.INFO)\n\n_DEFAULT_MNIST_BATCH_SIZE = 32\n_DEFAULT_RESIZE_SIZE = 32\n\nclass MNISTDataModule(pl.LightningDataModule):\n    def __init__(self, data_dir: str, batch_size: int = _DEFAULT_MNIST_BATCH_SIZE):\n        super().__init__()\n        self.data_dir = data_dir\n        self.batch_size = batch_size\n        self.transform = transforms.Compose(\n            [\n                transforms.ToTensor(),\n                transforms.Resize((_DEFAULT_RESIZE_SIZE, _DEFAULT_RESIZE_SIZE)),\n                transforms.Normalize((0.1307,), (0.3081,)),\n            ]\n        )\n\n    def prepare_data(self):\n        \"\"\"Ensure we download using one process only on CPU and avoid data corruption when downloading the data.\n        It's recommended to avoid creating class attributes `self.*` because the state won't be available for\n        other processes.\n        \"\"\"\n        MNIST(self.data_dir, train=True, download=True, transform=self.transform)\n        MNIST(self.data_dir, train=False, download=True, transform=self.transform)\n\n    def setup(self, stage: str):\n        \"\"\"Is called from every process across all nodes.\n        It also uses every GPUs to perform data processing and state assignement.\n        `teardown` is its counterpart used to clean the states.\n        \"\"\"\n        logger.info(f\"Stage: {stage}\")\n        if stage == \"test\" or stage == \"predict\":\n            self.mnist_test = MNIST(self.data_dir, train=False, download=True, transform=self.transform)\n        elif stage == \"fit\" or stage == \"validate\":\n            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000]) \n```", "```py\ndef train_dataloader(self) -> DataLoader:\n        \"\"\"Called by Trainer `.fit` method\"\"\"\n        return DataLoader(self.mnist_train, batch_size=self.batch_size)\n\n    def val_dataloader(self) -> DataLoader:\n        \"\"\"Called by Trainer `validate()` and `validate()` method.\"\"\"\n        return DataLoader(self.mnist_val, batch_size=self.batch_size)\n\n    def test_dataloader(self) -> DataLoader:\n        \"\"\"Called by Trainer `test()` method.\"\"\"\n        return DataLoader(self.mnist_test, batch_size=self.batch_size)\n\n    def predict_dataloader(self) -> DataLoader:\n        \"\"\"Called by Trainer `predict()` method. Use the same data as the test_dataloader.\"\"\"\n        return DataLoader(self.mnist_test, batch_size=self.batch_size, num_workers=3)\n```", "```py\nif __name__ == \"__main__\":\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument(\"--model\", default=\"lenet\", type=str, help=\"Provide an implemented model.\")\n    parser.add_argument(\"--device\", default=0, type=int, help=\"Select a CUDA device.\")\n    parser.add_argument(\"--max-epoch\", default=10, type=int, help=\"Max number of epochs.\")\n    parser.add_argument(\"--out-dir\", type=Path, help=\"Path to output directory\")\n    parser.add_argument(\n        \"--early-stopping\", action=\"store_true\", help=\"If True, stops the training if validation loss stops decreasing.\"\n    )\n\n    args = parser.parse_args()\n\n    main(\n        model_choice=args.model,\n        device=args.device,\n        max_epoch=args.max_epoch,\n        out_dir=args.out_dir,\n        early_stopping=args.early_stopping,\n    )\n```", "```py\ndef main(\n    model_choice: str,\n    device: int,\n    max_epoch: int,\n    out_dir: Path | None,\n    early_stopping: bool | None,\n):\n    accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n    if out_dir is None:\n        out_dir = Path(__file__).parent / \"output\"\n    out_dir.mkdir(parents=True, exist_ok=True)\n    # Select architecture\n    if model_choice == \"lenet\":\n        model = LeNet(in_channels=1, out_channels=10)\n        data_module = MNISTDataModule(data_dir=_PATH_DATASETS, batch_size=_BATCH_SIZE)\n    else:\n      raise NotImplementedError(f\"{model_choice} is not implemented!\")\n    callbacks = (\n        [\n            EarlyStopping(\n                monitor=\"val_loss\",\n                min_delta=0.00,\n                patience=_EARLY_STOPPING_PATIENCE,\n                verbose=True,\n                mode=\"min\",\n            )\n        ]\n        if early_stopping\n        else []\n    )\n\n    # If your machine has GPUs, it will use the GPU Accelerator for training.\n    trainer = L.Trainer(\n        accelerator=accelerator,\n        devices=[device],\n        strategy=\"auto\",\n        max_epochs=max_epoch,\n        callbacks=callbacks,\n        default_root_dir=out_dir,\n    )\n\n    # Train the model ⚡\n    # data_module.setup(stage=\"fit\")  # Is called by trainer.fit().\n    # Call training_step + validation_step for all the epochs.\n    trainer.fit(model, datamodule=data_module)\n    # Validate\n    trainer.validate(datamodule=data_module)\n\n    # Automatically auto-loads the best weights from the previous run.\n    # data_module.setup(stage=\"test\")  # Is called by trainer.test().\n    # The checkpoint path is logged on the terminal.\n    trainer.test(datamodule=data_module)\n\n    # Run the prediction on the test set and save a subset of the resulting prediction along with the\n    # original image.\n\n    output_preds = trainer.predict(datamodule=data_module, ckpt_path=\"best\")\n    img_tensors, softmax_preds = zip(*output_preds)\n    out_dir_imgs = out_dir / \"test_images\"\n    out_dir_imgs.mkdir(exist_ok=True, parents=True)\n    save_results(\n        img_tensors=img_tensors,\n        output_tensors=softmax_preds,\n        out_dir=out_dir_imgs,\n    )\n```", "```py\ndef save_results(\n    img_tensors: list[torch.Tensor], output_tensors: list[torch.Tensor], out_dir: Path, max_number_of_imgs: int = 10\n):\n    \"\"\"Save test results as images in the provided output directory.\n    Args:\n        img_tensors: List of the tensors containing the input images.\n        output_tensors: List of softmax activation from the trained model.\n        out_dir: Path to output directory.\n        max_number_of_imgs: Maximum number of images to output from the provided images. The images will be selected randomly.\n    \"\"\"\n    selected_img_indices = random.sample(range(len(img_tensors)), min(max_number_of_imgs, len(img_tensors)))\n    for img_indice in selected_img_indices:\n        # Take the first instance of the batch (index 0)\n        img_filepath = out_dir / f\"{img_indice}_predicted_{torch.argmax(output_tensors[img_indice], dim=1)[0]}.png\"\n        torchvision.utils.save_image(img_tensors[img_indice][0], fp=img_filepath)\n```", "```py\n# Train.py script\n#!/usr/bin/python3\n\n\"\"\"Example training script to fit a model on MNIST dataset.\"\"\"\nfrom __future__ import annotations  # Enable PEP 563 for Python 3.7\n\nfrom argparse import ArgumentParser\nfrom lightning.pytorch.callbacks.early_stopping import EarlyStopping\nfrom pathlib import Path\nimport lightning as L\n\nimport os\nimport random\nimport torch\nimport torchvision\n\nfrom datasets.mnist import MNISTDataModule\nfrom models import AlexNet, LeNet\n\n_PATH_DATASETS = os.environ.get(\"PATH_DATASETS\", \".\")\n_BATCH_SIZE = 64 if torch.cuda.is_available() else 32\n_EARLY_STOPPING_PATIENCE = 4  # epochs\n\ndef save_results(\n    img_tensors: list[torch.Tensor], output_tensors: list[torch.Tensor], out_dir: Path, max_number_of_imgs: int = 10\n):\n    \"\"\"Save test results as images in the provided output directory.\n    Args:\n        img_tensors: List of the tensors containing the input images.\n        output_tensors: List of softmax activation from the trained model.\n        out_dir: Path to output directory.\n        max_number_of_imgs: Maximum number of images to output from the provided images. The images will be selected randomly.\n    \"\"\"\n    selected_img_indices = random.sample(range(len(img_tensors)), min(max_number_of_imgs, len(img_tensors)))\n    for img_indice in selected_img_indices:\n        # Take the first instance of the batch (index 0)\n        img_filepath = out_dir / f\"{img_indice}_predicted_{torch.argmax(output_tensors[img_indice], dim=1)[0]}.png\"\n        torchvision.utils.save_image(img_tensors[img_indice][0], fp=img_filepath)\n\ndef main(\n    model_choice: str,\n    device: int,\n    max_epoch: int,\n    out_dir: Path | None,\n    early_stopping: bool | None,\n):\n    accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n    if out_dir is None:\n        out_dir = Path(__file__).parent / \"output\"\n    out_dir.mkdir(parents=True, exist_ok=True)\n    # Select architecture\n    if model_choice == \"lenet\":\n        model = LeNet(in_channels=1, out_channels=10)\n        data_module = MNISTDataModule(data_dir=_PATH_DATASETS, batch_size=_BATCH_SIZE)\n    else:\n      raise NotImplementedError(f\"{model_choice} is not implemented!\")\n    callbacks = (\n        [\n            EarlyStopping(\n                monitor=\"val_loss\",\n                min_delta=0.00,\n                patience=_EARLY_STOPPING_PATIENCE,\n                verbose=True,\n                mode=\"min\",\n            )\n        ]\n        if early_stopping\n        else []\n    )\n\n    # If your machine has GPUs, it will use the GPU Accelerator for training.\n    trainer = L.Trainer(\n        accelerator=accelerator,\n        devices=[device],\n        strategy=\"auto\",\n        max_epochs=max_epoch,\n        callbacks=callbacks,\n        default_root_dir=out_dir,\n    )\n\n    # Train the model ⚡\n    # data_module.setup(stage=\"fit\")  # Is called by trainer.fit().\n    # Call training_step + validation_step for all the epochs.\n    trainer.fit(model, datamodule=data_module)\n    # Validate\n    trainer.validate(datamodule=data_module)\n\n    # Automatically auto-loads the best weights from the previous run.\n    # data_module.setup(stage=\"test\")  # Is called by trainer.test().\n    # The checkpoint path is logged on the terminal.\n    trainer.test(datamodule=data_module)\n\n    # Run the prediction on the test set and save a subset of the resulting prediction along with the\n    # original image.\n\n    output_preds = trainer.predict(datamodule=data_module, ckpt_path=\"best\")\n    img_tensors, softmax_preds = zip(*output_preds)\n    out_dir_imgs = out_dir / \"test_images\"\n    out_dir_imgs.mkdir(exist_ok=True, parents=True)\n    save_results(\n        img_tensors=img_tensors,\n        output_tensors=softmax_preds,\n        out_dir=out_dir_imgs,\n    )\n\nif __name__ == \"__main__\":\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument(\"--model\", default=\"lenet\", type=str, help=\"Provide an implemented model.\")\n    parser.add_argument(\"--device\", default=0, type=int, help=\"Select a CUDA device.\")\n    parser.add_argument(\"--max-epoch\", default=10, type=int, help=\"Max number of epochs.\")\n    parser.add_argument(\"--out-dir\", type=Path, help=\"Path to output directory\")\n    parser.add_argument(\n        \"--early-stopping\", action=\"store_true\", help=\"If True, stops the training if validation loss stops decreasing.\"\n    )\n\n    args = parser.parse_args()\n\n    main(\n        model_choice=args.model,\n        device=args.device,\n        max_epoch=args.max_epoch,\n        out_dir=args.out_dir,\n        early_stopping=args.early_stopping,\n    )\n```"]