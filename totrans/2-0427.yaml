- en: Build Industry-Specific LLMs Using Retrieval Augmented Generation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用检索增强生成技术构建行业特定的语言模型
- en: 原文：[https://towardsdatascience.com/build-industry-specific-llms-using-retrieval-augmented-generation-af9e98bb6f68](https://towardsdatascience.com/build-industry-specific-llms-using-retrieval-augmented-generation-af9e98bb6f68)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/build-industry-specific-llms-using-retrieval-augmented-generation-af9e98bb6f68](https://towardsdatascience.com/build-industry-specific-llms-using-retrieval-augmented-generation-af9e98bb6f68)
- en: Organizations are in a race to adopt Large Language Models. Let’s dive into
    how you can build industry-specific LLMs Through RAG
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 组织们正在竞相采用大型语言模型。让我们深入了解如何通过 RAG 构建行业特定的语言模型。
- en: '[](https://skanda-vivek.medium.com/?source=post_page-----af9e98bb6f68--------------------------------)[![Skanda
    Vivek](../Images/9d25bee2fb75176ca7f7ea6eff7d7ab5.png)](https://skanda-vivek.medium.com/?source=post_page-----af9e98bb6f68--------------------------------)[](https://towardsdatascience.com/?source=post_page-----af9e98bb6f68--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----af9e98bb6f68--------------------------------)
    [Skanda Vivek](https://skanda-vivek.medium.com/?source=post_page-----af9e98bb6f68--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://skanda-vivek.medium.com/?source=post_page-----af9e98bb6f68--------------------------------)[![Skanda
    Vivek](../Images/9d25bee2fb75176ca7f7ea6eff7d7ab5.png)](https://skanda-vivek.medium.com/?source=post_page-----af9e98bb6f68--------------------------------)[](https://towardsdatascience.com/?source=post_page-----af9e98bb6f68--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----af9e98bb6f68--------------------------------)
    [Skanda Vivek](https://skanda-vivek.medium.com/?source=post_page-----af9e98bb6f68--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----af9e98bb6f68--------------------------------)
    ·10 min read·May 31, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----af9e98bb6f68--------------------------------)
    ·阅读时间 10 分钟·2023年5月31日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: 'Companies stand to gain a lot of productivity improvements through LLMs like
    ChatGPT. But try asking ChatGPT “what is the current inflation in the U.S.” and
    it gives:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 公司可以通过像 ChatGPT 这样的语言模型获得大量生产力提升。但试着问 ChatGPT “美国当前的通货膨胀率是多少”，它给出的答案是：
- en: I apologize for the confusion, but as an AI language model, I don’t have real-time
    data or browsing capabilities. My responses are based on information available
    up until September 2021\. Therefore, I cannot provide you with the current inflation
    rate in the U.S.
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于混淆表示歉意，但作为一个人工智能语言模型，我没有实时数据或浏览能力。我的回答基于截至 2021 年 9 月的信息。因此，我无法提供美国当前的通货膨胀率。
- en: Which is a problem. ChatGPT is clearly missing relevant timely context, which
    could be essential while making informed decisions.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是一个问题。ChatGPT 明显缺少相关的及时上下文，而这些上下文在做出明智决策时可能至关重要。
- en: How Microsoft Is Solving This
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微软是如何解决这个问题的
- en: In the Microsoft Build session [Vector Search Isn’t Enough](https://build.microsoft.com/en-US/sessions/038984b3-7c5d-4cc6-b24e-5d9f62bc2f0e?wt.mc_ID=Build2023_esc_corp_em_oo_mto_Marketo_FPnews_Elastic),
    they lay out their product that combines less context-aware LLMs with vector search,
    to create a more engaging experience.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在微软的 Build 会议中 [Vector Search Isn’t Enough](https://build.microsoft.com/en-US/sessions/038984b3-7c5d-4cc6-b24e-5d9f62bc2f0e?wt.mc_ID=Build2023_esc_corp_em_oo_mto_Marketo_FPnews_Elastic)，他们展示了将较少上下文感知的语言模型与向量搜索结合的产品，以创造更具吸引力的体验。
- en: The talk starts from the opposite direction of this piece — from the point of
    view of Elastic Search (or vector search) — and the idea that search by itself
    is limited, and adding the layer of LLMs can vastly improve the search experience.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 讲座从与本文相反的方向开始——从 Elastic Search（或向量搜索）的角度——以及搜索本身的局限性，并且添加语言模型层可以大幅提升搜索体验。
- en: The basic idea is that adding relevant context to LLMs can vastly improve user
    experience especially in most commercial cases, where LLMs haven’t seen these
    sorts of data. Vector search helps in choosing what the relevant context is, when
    you have vast amounts of data, including 100s (or more) documents.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 基本思路是，向语言模型中添加相关上下文可以大幅提升用户体验，尤其是在大多数商业场景中，在这些场景下，语言模型未曾见过这些数据。向量搜索帮助选择相关上下文，当你拥有大量数据，包括数百份（或更多）文档时。
- en: Vector Search 101
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向量搜索 101
- en: '![](../Images/df4126ecf386cf34f81c491832c86c37.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/df4126ecf386cf34f81c491832c86c37.png)'
- en: Vector Search 101 | Skanda Vivek
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 向量搜索 101 | Skanda Vivek
- en: 'Vectorizing is converting data into dimensions. In the case above, you can
    see 2 dimensions: size and type. Size has 2 values (small or big), and type has
    2 values (tree or animal). This is just a conceptual example, and can be scaled
    to hundreds (or more values).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 向量化是将数据转换为维度。在上述情况下，你可以看到2个维度：大小和类型。大小有2个值（小或大），类型有2个值（树或动物）。这只是一个概念性示例，可以扩展到数百个（或更多值）。
- en: '![](../Images/98f0411346236ea58fff19a27e99849e.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/98f0411346236ea58fff19a27e99849e.png)'
- en: Vector Search 101 With Words | Skanda Vivek
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 向量搜索101与词汇 | Skanda Vivek
- en: You can do the same thing with words or sentences, instead of pictures. Notice
    how in the above example, the vectorization is able to capture the semantic representation
    i.e. it knows that a sentence talking about a bird swooping in on a baby chipmunk
    should be in the (small, animal) quadrant, whereas the sentence talking about
    yesterday’s storm when a large tree fell on the road should be in the (big, tree)
    quadrant. In reality, there are more than 2 dimensions — 384 for sentence transformer
    embeddings (sentences or chunks of text are passed through the BERT transformer,
    and 384 numbers corresponding to the 384 dimensions are outputted.)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以用单词或句子做同样的事情，而不是图片。注意在上述示例中，向量化能够捕捉到语义表示，即它知道谈论一只鸟俯冲到小松鼠上的句子应该位于（小，动物）象限，而谈论昨天风暴中一棵大树倒在路上的句子应该位于（大，树）象限。实际上，维度不止2个——句子转换嵌入有384个维度（句子或文本片段通过BERT转换器，输出384个数字，对应384个维度）。
- en: Vector Search + LLM (RAG)
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向量搜索 + LLM（RAG）
- en: Vector search is now commonplace in all search (Google, Bing, pick your favorite
    search engine). Think about if your entire search database has only these 4 documents.
    You can ask the question, “Tell me something about a big tree.”
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 向量搜索现在在所有搜索引擎中都很常见（Google、Bing，选择你喜欢的搜索引擎）。想象一下，如果你的整个搜索数据库仅包含这4份文档。你可以提出问题，“告诉我关于一棵大树的事情。”
- en: 'The output will be:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将是：
- en: During yesterday’s storm, a large tree fell on the road.
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在昨天的风暴中，一棵大树倒在了路上。
- en: 'Just the most relevant document in the database. But if you asked an LLM the
    same question (and append in the 4 “documents” at the end), this is what you get
    (ChatGPT in this example):'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅是数据库中最相关的文档。但如果你向LLM提出相同的问题（并在最后附上这4份“文档”），你会得到这样的结果（以ChatGPT为例）：
- en: A big tree is typically a large, towering plant with a sturdy trunk, branches,
    and an extensive network of roots. These trees can reach impressive heights, often
    extending well above the surrounding vegetation. They serve as essential components
    of many ecosystems, providing shade, shelter, and food for various organisms.
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一棵大树通常是一个大型的、耸立的植物，具有坚固的树干、枝条和广泛的根系。这些树木可以达到令人印象深刻的高度，通常高出周围的植被。它们是许多生态系统的重要组成部分，为各种生物提供遮荫、庇护和食物。
- en: ''
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The incident you mentioned about a large tree falling on the road during a storm
    indicates the power and impact of severe weather conditions. Storms with strong
    winds can uproot or break trees, leading to road blockages and potential hazards
    for vehicles and pedestrians.
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你提到的关于一棵大树在风暴中倒在路上的事件表明了恶劣天气条件的力量和影响。强风的风暴可以连根拔起或折断树木，导致道路阻塞，对车辆和行人构成潜在的危险。
- en: ''
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In another scenario you mentioned, while driving on the road in Bandipur, you
    encountered a large elephant crossing the road. Bandipur is a national park and
    wildlife sanctuary located in India, known for its rich biodiversity and diverse
    animal population. Elephants are one of the prominent species found in Bandipur
    and are known to traverse the area, sometimes crossing roads. Encounters like
    these highlight the importance of wildlife conservation and the need for humans
    to coexist with animals in their natural habitats.
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在你提到的另一个场景中，当你在班迪布尔的道路上行驶时，你遇到了一只大象穿过道路。班迪布尔是印度的一座国家公园和野生动物保护区，以其丰富的生物多样性和各种动物群体而闻名。大象是班迪布尔的主要物种之一，通常会穿越该地区，有时会穿过道路。这些遭遇突显了野生动物保护的重要性以及人类与动物在其自然栖息地共存的必要性。
- en: ''
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Switching topics to Bonsai, they are miniature trees that are grown in small
    pots and meticulously shaped and pruned to maintain their small size. Bonsai cultivation
    is an ancient art form that originated in East Asia and has gained popularity
    worldwide. Due to their limited root space, Bonsai trees require regular watering
    to prevent them from drying out. The small pots can cause the soil to dry quickly,
    so it’s crucial to monitor the moisture levels and water them accordingly.
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 转到盆景，它们是生长在小花盆中的迷你树木，通过精心修剪来保持其小巧的尺寸。盆景栽培是一种起源于东亚的古老艺术形式，现已在全球范围内获得普及。由于其根部空间有限，盆景树需要定期浇水以防止干枯。小花盆可能导致土壤迅速干燥，因此必须监控湿度水平并相应地浇水。
- en: ''
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Finally, you mentioned observing a bird swooping in on a baby chipmunk through
    your window. This observation reflects a moment of nature in action, where a bird
    might have been hunting for food. Birds of prey and certain bird species, such
    as hawks or owls, are known to swoop down on small mammals like chipmunks as part
    of their natural hunting behavior. It’s fascinating to witness such interactions,
    as they provide insights into the dynamics of the animal kingdom.
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 最后，你提到通过窗户观察到一只鸟俯冲向一只小花栗鼠。这一观察反映了自然行动的一个瞬间，其中一只鸟可能在寻找食物。猛禽和某些鸟类，如鹰或猫头鹰，通常会俯冲捕捉像花栗鼠这样的微小哺乳动物，作为其自然猎食行为的一部分。目睹这种互动非常吸引人，因为它们提供了关于动物王国动态的见解。
- en: ''
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Overall, these snippets of nature — whether they involve big trees, elephants,
    Bonsai trees, or bird predation — highlight the diversity and wonder of the natural
    world that surrounds us.
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 总的来说，这些自然片段——无论是涉及大树、大象、盆景还是鸟类捕食——都突显了围绕我们自然世界的多样性和奇观。
- en: That answer seemed much more well rounded. ChatGPT was using its internal knowledge
    from being trained on trillions of documents, in combination with the context
    it was given.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 那个回答似乎更加全面。ChatGPT 利用了其从数万亿文档中训练得到的内部知识，并结合了所提供的上下文。
- en: 'But let’s say you have more than just 4 documents — maybe thousands or millions,
    that you can’t fit into the ChatGPT prompt. In this case, you can use vector search
    to narrow down the context most likely to contain the answer, append it to the
    prompt, and ask the same question as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 但假设你有的不仅仅是4个文档——可能是成千上万甚至百万个，无法全部放入 ChatGPT 的提示中。在这种情况下，你可以使用向量搜索来缩小最可能包含答案的上下文，将其附加到提示中，并按照以下方式提问：
- en: 'This is the (truncated) answer it now gives:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它现在给出的（截断的）答案：
- en: '![](../Images/916cbd5dcf05aabd6693ebb0a7bb4d78.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/916cbd5dcf05aabd6693ebb0a7bb4d78.png)'
- en: ChatGPT answer | Skanda Vivek
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 回答 | Skanda Vivek
- en: 'You could then have a database, that stores documents and embeddings. You can
    have another DB that stores queries, and finds the most relevant documents based
    on the queries:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以有一个数据库，存储文档和嵌入。你可以有另一个数据库，存储查询，并根据查询找到最相关的文档：
- en: '![](../Images/9574fca57d2d8141c4113402aa2b5ee7.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9574fca57d2d8141c4113402aa2b5ee7.png)'
- en: Document DB (Left) and Quey DB (Right) | Skanda Vivek
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 文档数据库（左）和 Quey 数据库（右） | Skanda Vivek
- en: Once you have the most similar document(s) by query, you can feed that to any
    LLM like ChatGPT. By this simple trick, you have augmented your LLM using document
    retrieval! This is also known as retrieval augmented generation (RAG).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你通过查询获得最相似的文档，你可以将其输入到任何像 ChatGPT 这样的语言模型中。通过这个简单的技巧，你已经增强了你的语言模型，使用了文档检索！这也被称为检索增强生成（RAG）。
- en: Building Industry-Specific Q&A Models Using RAG
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 RAG 构建行业特定的问答模型
- en: '![](../Images/a9add121e8626cc6254e3c2d362647db.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a9add121e8626cc6254e3c2d362647db.png)'
- en: RAG Prototype | Skanda Vivek
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 原型 | Skanda Vivek
- en: The above diagram outlines how to build a basic RAG that utilizes an LLM over
    custom documents for question answering. The first part is splitting multiple
    documents into manageable chunks, the associated parameter is the ***maximum chunk
    length***. These chunks should be of the typical (minimum) size of text that contain
    the answers to the typical questions asked. This is because sometimes the question
    you ask might have answers at multiple locations within the document. For example,
    you might ask the question “What was X company’s performance from 2015 to 2020?”
    And you might have a large document (or multiple documents) containing specific
    information about company performance over the years in different parts of the
    document. You would ideally want to capture all disparate parts of the document(s)
    containing this information, link them together, and pass to an LLM for answering
    based on these filtered and concatenated document chunks.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图表概述了如何构建一个基本的 RAG，该 RAG 利用 LLM 对自定义文档进行问答。第一部分是将多个文档拆分成可管理的片段，相关的参数是 ***最大片段长度***。这些片段应为包含回答典型问题所需的文本的典型（最小）大小。这是因为有时你提出的问题可能在文档的多个位置都有答案。例如，你可能会问“X
    公司在 2015 年到 2020 年的表现如何？”而你可能有一份大文档（或多份文档）包含公司多年表现的具体信息，这些信息分布在文档的不同部分。你理想的做法是捕获包含这些信息的文档的所有不同部分，将它们链接在一起，然后传递给
    LLM 进行基于这些过滤和拼接后的文档片段的回答。
- en: 'The ***maximum context length*** is basically the maximum length for concatenating
    various chunks together — leaving some space for the question itself, and the
    output answer (remember that LLMs like ChatGPT have a strict length limit that
    includes all the content: question, context, and answer.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '***最大上下文长度*** 基本上是将各种片段拼接在一起的最大长度——为问题本身和输出答案留出一些空间（记住，像 ChatGPT 这样的 LLM 有严格的长度限制，包括所有内容：问题、上下文和答案）。'
- en: The ***similarity threshold*** is the way to compare the question with document
    chunks, to find the top chunks, most likely to contain the answer. Cosine similarity
    is the typical metric used, but you might want to weight different metrics. Such
    as including a keyword metric to weight contexts with certain keywords more. For
    example, you might want to weight contexts that contain the words “abstract” or
    “summary” when you ask the question to an LLM to summarize a document.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '***相似度阈值*** 是将问题与文档片段进行比较的方式，以找到最有可能包含答案的顶部片段。余弦相似度是通常使用的度量，但你可能希望对不同的度量进行加权。例如，可以包括一个关键词度量，以便对包含特定关键词的上下文给予更多权重。例如，当你要求
    LLM 总结一份文档时，你可能希望对包含“摘要”或“总结”这两个词的上下文给予更多权重。'
- en: If you want an easy way to test out Generative Q&A over custom documents, check
    out my [API](https://rapidapi.com/skandavivek/api/chatgpt-powered-question-answering-over-documents)
    and [code](https://github.com/skandavivek/web-qa) that uses ChatGPT in the backend.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想测试生成性问答在自定义文档上的简单方法，可以查看我的 [API](https://rapidapi.com/skandavivek/api/chatgpt-powered-question-answering-over-documents)
    和 [代码](https://github.com/skandavivek/web-qa)，它们在后台使用了 ChatGPT。
- en: Prototype ChatGPT boosted by RAG
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 原型 ChatGPT 通过 RAG 增强
- en: 'Let’s illustrate the usefulness of RAG through an example. [EMAlpha](https://www.emalpha.com/)
    is a company that provides insights into emerging markets — basically the economies
    of up and coming nations like India, China, Brazil, etc (full disclosure — I’m
    an advisor at EMAlpha). The company is building a ChatGPT powered app to generate
    insights into emerging economies based on user inputs. The dashboard looks something
    like this — where you can compare the output of ChatGPT vs the RAG version of
    ChatGPT (EM-GPT) that is able to query financial documents from IMF in the backend:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来说明 RAG 的实用性。[EMAlpha](https://www.emalpha.com/) 是一家提供新兴市场洞察的公司——基本上是像印度、中国、巴西等新兴国家的经济（完全披露——我在
    EMAlpha 担任顾问）。该公司正在开发一个 ChatGPT 驱动的应用程序，根据用户输入生成对新兴经济体的洞察。仪表盘大致如下——你可以比较 ChatGPT
    的输出与能够在后台从 IMF 查询财务文档的 RAG 版本 ChatGPT（EM-GPT）的结果：
- en: '![](../Images/15afaf108e3ad7cb76296e37a68b7029.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/15afaf108e3ad7cb76296e37a68b7029.png)'
- en: EM-GPT from [EMAlpha](https://www.emalpha.com/)| Skanda Vivek
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[EMAlpha](https://www.emalpha.com/) 的 EM-GPT | Skanda Vivek'
- en: 'Below is the answer from ChatGPT for the question “What is Nepal’s GDP by year?”:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 ChatGPT 对问题“尼泊尔按年份的 GDP 是多少？”的回答：
- en: '![](../Images/0ac4fe7cefd5459cfa8b5988647b2988.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0ac4fe7cefd5459cfa8b5988647b2988.png)'
- en: ChatGPT Response | Skanda Vivek
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 响应 | Skanda Vivek
- en: ChatGPT only returns the GDP until 2019 and it says that if you want more information,
    look at IMF. But if you want to figure out where this data is located in the IMF
    website, it is hard and you need to have an idea about where documents are stored
    on the website. After some searching, you [find the document is here](https://www.imf.org/en/Publications/CR/Issues/2023/05/04/Nepal-Staff-Report-for-the-2023-Article-IV-Consultation-First-and-Second-Reviews-Under-the-533075).
    Even then, figuring out where exactly the GDP information is present needs a lot
    of scrolling.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT只返回了2019年之前的GDP数据，并表示如果需要更多信息，可以查看IMF。但是，如果你想找出这些数据在IMF网站上的具体位置，这很困难，你需要对网站上的文档存储位置有个大致了解。经过一些搜索，你[可以在这里找到文档](https://www.imf.org/en/Publications/CR/Issues/2023/05/04/Nepal-Staff-Report-for-the-2023-Article-IV-Consultation-First-and-Second-Reviews-Under-the-533075)。即便如此，确定GDP信息的具体位置仍需要大量的滚动。
- en: '![](../Images/12c8e35f80594a211a2905f72a983f9c.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/12c8e35f80594a211a2905f72a983f9c.png)'
- en: IMF Document on Nepal Economics | Skanda Vivek
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: IMF关于尼泊尔经济的文档 | Skanda Vivek
- en: 'As you see above, it is quite hard to find this data. But when you ask EM-GPT
    the same question, it tracks down the relevant context, and finds the answer as
    below:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所示，找到这些数据确实很困难。但当你问EM-GPT同样的问题时，它会追踪到相关上下文，并找到如下答案：
- en: '![](../Images/166f3df5dbabead53a551c71c3bad470.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/166f3df5dbabead53a551c71c3bad470.png)'
- en: EM-GPT Answer | Skanda Vivek
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: EM-GPT答案 | Skanda Vivek
- en: Below is the exact prompt sent to ChatGPT to answer this question. It’s pretty
    impressive that it managed to make sense of this formatted text, extract the right
    information — and format it into a nice human readable format!
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是发送给ChatGPT以回答这个问题的确切提示。它能够理解这个格式化的文本，提取正确的信息——并将其格式化成一个易读的格式，这一点相当令人印象深刻！
- en: '![](../Images/4cb6feca4c004dd7d864f864002c6633.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4cb6feca4c004dd7d864f864002c6633.png)'
- en: ChatGPT prompt using context retrieved based on query | Skanda Vivek
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使用基于查询检索的上下文的ChatGPT提示 | Skanda Vivek
- en: I took half an hour to find this information on the IMF website, whereas the
    RAG modified ChatGPT only took a few seconds. Vector search alone would be no
    good, as it would probably at best find the text “Nominal GDP”, and not associate
    the numbers with the years. ChatGPT has been trained on multiple such documents
    in the past, so that once the relevant context is added, it knows which parts
    of the text contain the answer and how to format this answer in a nice readable
    format.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我花了半小时在IMF网站上查找这些信息，而RAG修改版的ChatGPT只用了几秒钟。仅使用向量搜索是不够的，因为它最多只能找到“名义GDP”这段文本，而不会将数字与年份关联起来。ChatGPT在过去已经训练过多个此类文档，因此一旦添加了相关上下文，它就知道文本中的哪些部分包含答案以及如何以良好的可读格式格式化这个答案。
- en: Conclusions
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: RAG offers a great way to use LLMs powered on custom documents. Companies like
    [Microsoft](https://www.elastic.co/blog/may-2023-launch-announcement?utm_source=organic-social&utm_medium=twitter&utm_campaign=cee-gc&ultron=t1_launch&blade=twitter&hulk=social&utm_content=10092954746&linkId=215905348),
    Google, and Amazon are in a race to build apps that organizations can use in a
    plug-and-play manner. However, the field is still nascent, and industry specific
    apps that use vector search powered LLMs over their custom documents can be first
    movers and edge out their competition.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: RAG提供了一种很好的方式来使用基于自定义文档的LLMs。像[微软](https://www.elastic.co/blog/may-2023-launch-announcement?utm_source=organic-social&utm_medium=twitter&utm_campaign=cee-gc&ultron=t1_launch&blade=twitter&hulk=social&utm_content=10092954746&linkId=215905348)、谷歌和亚马逊这样的公司正在竞相开发组织可以以即插即用的方式使用的应用程序。然而，这一领域仍处于初期阶段，利用向量搜索驱动的LLMs对自定义文档进行行业特定应用的公司可以成为首批先行者并超越竞争对手。
- en: 'While I have had people asking me which LLM to use and whether or not to fine-tune
    or completely train models over custom documents, **the role of engineering the
    sync between LLMs and vector search is underrated.** Here are a few considerations
    that can significantly enhance or reduce the quality of responses:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有人问我应该使用哪个LLM，以及是否需要对自定义文档进行微调或完全训练模型，**LLM与向量搜索之间的同步工程作用被低估了。** 以下是一些可以显著提高或降低响应质量的考虑因素：
- en: '**Length of document chunks.** If it is more likely that the right answers
    are contained in diverse parts of the text and need to be stitched together, documents
    should be separated into smaller chunks so that multiple contexts can be appended
    to queries.'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**文档块的长度。** 如果正确答案更可能分布在文本的不同部分并需要拼接在一起，则文档应分割成较小的块，以便可以将多个上下文附加到查询中。'
- en: '**Similarity and retrieval metrics.** Sometimes, plain cosine similarity is
    not enough. For example if many documents contain conflicting information about
    the same topic, you might want to restrict searches to certain documents based
    on metadata within those documents. For this, in addition to similarity, you can
    use other filtering metrics.'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**相似性和检索度量。** 有时候，单纯的余弦相似度是不够的。例如，如果许多文档包含关于同一主题的冲突信息，你可能需要根据这些文档中的元数据限制搜索范围。为此，除了相似度，还可以使用其他过滤度量。'
- en: '**Model Architecture:** The architecture I have shown is a prototype. For efficiency
    and scalability, considerations of various aspects have to be made including vector
    embedding model, document database, prompt, LLM model choice, etc.'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型架构：** 我展示的架构是一个原型。为了提高效率和可扩展性，需要考虑多个方面，包括向量嵌入模型、文档数据库、提示、LLM 模型选择等。'
- en: '**Avoiding Hallucinations:** You might have noticed that the example I showed
    above was ***almost*** correct. The augmented ChatGPT got the amounts right for
    Nepal’s GDP — but the years wrong. In such cases, there needs to be a lot of feedback
    between choosing prompts, extracting data in a ChatGPT friendly format, and evaluating
    in what percentage of the cases there are hallucinations, and what solutions work
    well.'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**避免幻觉：** 你可能注意到我上面展示的例子是***几乎***正确的。增强版 ChatGPT 对尼泊尔 GDP 的金额是正确的——但年份是错误的。在这种情况下，需要在选择提示、以
    ChatGPT 友好的格式提取数据和评估在多少情况下会出现幻觉以及哪些解决方案有效之间进行大量反馈。'
- en: Now that you know how to apply LLMs to your custom data, go build awesome LLM
    based products!
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道如何将 LLM 应用到你的自定义数据上，快去构建令人惊叹的 LLM 基础产品吧！
- en: '*If you like this post, follow me — I write on topics related to applying state-of-the-art
    NLP in real-world applications and, more generally, on the intersections between
    data and society.*'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你喜欢这篇文章，请关注我——我写的内容涉及在实际应用中应用最先进的 NLP 技术，以及数据与社会之间的交集。*'
- en: '*Feel free to connect with me on* [*LinkedIn*](https://www.linkedin.com/in/skanda-vivek-01619311b/)*!*'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*随时通过* [*LinkedIn*](https://www.linkedin.com/in/skanda-vivek-01619311b/)*与我联系！*'
- en: '*If you are not yet a Medium member and want to support writers like me, feel
    free to sign-up through my referral link:* [*https://skanda-vivek.medium.com/membership*](https://skanda-vivek.medium.com/membership)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你还不是 Medium 会员并希望支持像我这样的作者，请通过我的推荐链接注册：* [*https://skanda-vivek.medium.com/membership*](https://skanda-vivek.medium.com/membership)'
- en: '**Here are some related articles:**'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**以下是一些相关的文章：**'
- en: '[When Should You Fine-Tune LLMs?](https://medium.com/towards-data-science/when-should-you-fine-tune-llms-2dddc09a404a)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[你应该在什么时候微调 LLM？](https://medium.com/towards-data-science/when-should-you-fine-tune-llms-2dddc09a404a)'
- en: '[LLM Economics: ChatGPT vs Open-Source](https://medium.com/towards-data-science/llm-economics-chatgpt-vs-open-source-dfc29f69fec1)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[LLM 经济学：ChatGPT 与开源](https://medium.com/towards-data-science/llm-economics-chatgpt-vs-open-source-dfc29f69fec1)'
- en: '[How Do You Build A ChatGPT-Powered App?](https://medium.com/geekculture/how-do-you-build-a-chatgpt-powered-app-89c83f3e2143)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[如何构建一个 ChatGPT 驱动的应用程序？](https://medium.com/geekculture/how-do-you-build-a-chatgpt-powered-app-89c83f3e2143)'
- en: '[Extractive vs Generative Q&A — Which is better for your business?](https://medium.com/towards-data-science/extractive-vs-generative-q-a-which-is-better-for-your-business-5a8a1faab59a)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[提取式问答与生成式问答 — 哪种更适合你的业务？](https://medium.com/towards-data-science/extractive-vs-generative-q-a-which-is-better-for-your-business-5a8a1faab59a)'
- en: '[Fine-Tune Transformer Models For Question Answering On Custom Data](https://medium.com/towards-data-science/fine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[在自定义数据上微调 Transformer 模型以进行问答](https://medium.com/towards-data-science/fine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80)'
- en: '[Unleashing the Power of Generative AI For Your Customers](https://medium.com/geekculture/unleashing-the-power-of-generative-ai-for-your-customers-70297f1c9698)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[释放生成 AI 的力量，为你的客户带来价值](https://medium.com/geekculture/unleashing-the-power-of-generative-ai-for-your-customers-70297f1c9698)'
