- en: 'Document-Oriented Agents: A Journey with Vector Databases, LLMs, Langchain,
    FastAPI, and Docker'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 面向文档的智能体：与向量数据库、LLMs、Langchain、FastAPI 和 Docker 的探索之旅
- en: 原文：[https://towardsdatascience.com/document-oriented-agents-a-journey-with-vector-databases-llms-langchain-fastapi-and-docker-be0efcd229f4](https://towardsdatascience.com/document-oriented-agents-a-journey-with-vector-databases-llms-langchain-fastapi-and-docker-be0efcd229f4)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/document-oriented-agents-a-journey-with-vector-databases-llms-langchain-fastapi-and-docker-be0efcd229f4](https://towardsdatascience.com/document-oriented-agents-a-journey-with-vector-databases-llms-langchain-fastapi-and-docker-be0efcd229f4)
- en: 'Leveraging ChromaDB, Langchain, and ChatGPT: Enhanced Responses and Cited Sources
    from Large Document Databases'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用 ChromaDB、Langchain 和 ChatGPT：从大型文档数据库中获得增强的响应和引用来源
- en: '[](https://medium.com/@luisroque?source=post_page-----be0efcd229f4--------------------------------)[![Luís
    Roque](../Images/e281d470b403375ba3c6f521b1ccf915.png)](https://medium.com/@luisroque?source=post_page-----be0efcd229f4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----be0efcd229f4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----be0efcd229f4--------------------------------)
    [Luís Roque](https://medium.com/@luisroque?source=post_page-----be0efcd229f4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@luisroque?source=post_page-----be0efcd229f4--------------------------------)[![Luís
    Roque](../Images/e281d470b403375ba3c6f521b1ccf915.png)](https://medium.com/@luisroque?source=post_page-----be0efcd229f4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----be0efcd229f4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----be0efcd229f4--------------------------------)
    [Luís Roque](https://medium.com/@luisroque?source=post_page-----be0efcd229f4--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----be0efcd229f4--------------------------------)
    ·11 min read·Jul 5, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----be0efcd229f4--------------------------------)
    ·阅读时长 11 分钟·2023 年 7 月 5 日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Document-oriented agents are starting to get traction in the business landscape.
    Companies increasingly leverage these tools to capitalize on internal documentation,
    enhancing their business processes. A recent McKinsey report [1] underscores this
    trend, suggesting generative AI could boost the global economy by $2.6–4.4 trillion
    annually and automate up to 70% of current work activities. The study identifies
    customer service, sales and marketing, and software development as the main sectors
    that will be affected by the transformation. Most of the change is coming from
    the fact that the information that powers these areas within a company can be
    more accessible to both employees and customers through the usage of solutions
    such as document-oriented agents.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 面向文档的智能体在商业领域开始获得关注。公司越来越多地利用这些工具来充分发挥内部文档的作用，从而优化业务流程。最近的一份麦肯锡报告[1]强调了这一趋势，指出生成式
    AI 每年可能为全球经济贡献 2.6 至 4.4 万亿美元，并自动化目前 70% 的工作活动。该研究指出，客户服务、销售和营销以及软件开发是主要受到转型影响的领域。大部分变化来自于这样的事实，即驱动公司这些领域的信息可以通过使用如面向文档的智能体等解决方案，让员工和客户更加容易获取。
- en: With the current technology, we are still facing some challenges. Even if you
    consider the new Large Language Models (LLMs) with 100k token limits, the models
    still have limited context windows. While 100k tokens seem to be a high number,
    it is a tiny number when we look at the size of the databases powering, for example,
    a customer service department. Another problem that often arises is the inaccuracies
    in model outputs. In this article, we’ll provide a step-by-step guide to building
    a document-oriented agent that can handle documents of any size and deliver verifiable
    answers.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 目前的技术条件下，我们仍面临一些挑战。即使考虑到具有 100k 令牌限制的新型大型语言模型（LLMs），这些模型的上下文窗口仍然有限。虽然 100k 令牌看似是一个较大的数字，但当我们查看支持例如客户服务部门的数据库规模时，这个数字就显得微不足道。另一个经常出现的问题是模型输出的准确性。在本文中，我们将提供一个逐步指南，帮助构建一个可以处理任何大小文档并提供可验证答案的面向文档的智能体。
- en: We use a vector database — ChromaDB — to augment our model context length capabilities
    and Langchain to facilitate integrations between the different components in our
    architecture. As our LLM, we use OpenAI’s chatGPT. Since we want to serve our
    application, we use FastAPI to create endpoints for users to interact with our
    agent. Finally, our application is containerized using Docker, which allows us
    to easily deploy it in any type of environment.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用向量数据库——ChromaDB——来增强我们的模型上下文长度能力，并使用Langchain来促进我们架构中不同组件之间的集成。作为我们的LLM，我们使用OpenAI的chatGPT。由于我们希望服务于我们的应用程序，我们使用FastAPI创建用户与我们的代理交互的端点。最后，我们的应用程序使用Docker进行容器化，这使我们可以在任何类型的环境中轻松部署。
- en: '![](../Images/d0523469e24ad18eb21453c5c7fe2ed5.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d0523469e24ad18eb21453c5c7fe2ed5.png)'
- en: 'Figure 1: The AI agents are getting smarter everyday ([image source](https://unsplash.com/photos/1DjbGRDh7-E))'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：AI代理每天变得更聪明 ([图片来源](https://unsplash.com/photos/1DjbGRDh7-E))
- en: As always, the code is available on my [Github](https://github.com/luisroque/large_laguage_models).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，代码可以在我的[Github](https://github.com/luisroque/large_laguage_models)上找到。
- en: 'Vector Databases: The Essential Core of Semantic Search Applications'
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向量数据库：语义搜索应用的核心要素
- en: Vector databases are essential to unlocking the power of generative AI. These
    types of databases are optimized to handle vector embeddings — data representations
    containing rich semantic information from the original data. Unlike traditional
    scalar-based databases, which struggle with the complexity of vector embeddings,
    vector databases index these embeddings, associating them with their source content
    and allowing for advanced features like semantic information retrieval and long-term
    memory in AI applications.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 向量数据库对于释放生成式AI的潜力至关重要。这些类型的数据库经过优化，以处理向量嵌入——包含原始数据丰富语义信息的数据表示。与传统的标量数据库不同，传统数据库在处理向量嵌入的复杂性方面表现不佳，而向量数据库则对这些嵌入进行索引，将它们与源内容关联，并支持高级功能，如语义信息检索和AI应用中的长期记忆。
- en: Vector databases are not the same as vector indices, such as Facebook’s AI Similarity
    Search (FAISS) — which we already covered in this series in a previous article
    [2]. They allow data insertion, deletion, and updating, store associated metadata,
    and support real-time data updates without needing full re-indexing — a time-consuming
    and computationally expensive process.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 向量数据库与向量索引不同，如Facebook的AI相似性搜索（FAISS）——我们在系列中的上一篇文章[2]已经介绍过。这些数据库允许数据的插入、删除和更新，存储相关的元数据，并支持实时数据更新，而无需全面重新索引——这是一个耗时且计算上昂贵的过程。
- en: 'Rather than exact matches, vector databases employ similarity metrics to find
    vectors closest to a query. They use Approximate Nearest Neighbor (ANN) search
    algorithms for optimized search. Some examples of such algorithms are: Random
    Projection, Product Quantization, or Hierarchical Navigable Small World. These
    algorithms compress the original vector, speeding up the query process. Furthermore,
    similarity measures like Cosine similarity, Euclidean distance, and Dot product
    compare and identify the most relevant results for a query.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 向量数据库使用相似性度量而非精确匹配来查找最接近查询的向量。它们使用近似最近邻（ANN）搜索算法来优化搜索。一些此类算法的例子包括：随机投影、产品量化或层次导航小世界。这些算法压缩原始向量，加快查询过程。此外，类似余弦相似度、欧几里得距离和点积的相似性度量比较并识别与查询最相关的结果。
- en: Figure 2 succinctly illustrates the similarity search process in vector databases.
    Starting with ingestion of raw documents (i), the data is broken into manageable
    chunks (ii) and converted into vector embeddings (iii). These embeddings are indexed
    for quick retrieval (iv), and similarity metrics between the chunks vectors and
    the user query are computed (v). The process ends with the most relevant data
    chunks being output (vi), offering users insights aligned with their original
    query.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图2简洁地展示了向量数据库中的相似性搜索过程。从原始文档的摄取 (i) 开始，数据被拆分成可管理的块 (ii)，并转换为向量嵌入 (iii)。这些嵌入被索引以便快速检索
    (iv)，并计算块向量与用户查询之间的相似性度量 (v)。该过程以输出最相关的数据块 (vi) 结束，为用户提供与其原始查询一致的见解。
- en: '![](../Images/c048ed15d1633de81a99fea9a6f27138.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c048ed15d1633de81a99fea9a6f27138.png)'
- en: 'Figure 2: The similarity search process: i) ingestion of raw documents, ii)
    process into chunks, iii) creation of embeddings, iv) indexing, v) compute of
    similarity metrics and, finally, vi) producing the output chunks (image by author)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：相似性搜索过程：i) 原始文档摄取，ii) 处理为块，iii) 创建嵌入，iv) 索引，v) 计算相似性度量，最后，vi) 生成输出块（图片由作者提供）
- en: Building a Document-Oriented Agent
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建面向文档的智能体
- en: We start by loading all necessary models and data at server startup.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从服务器启动时加载所有必要的模型和数据。
- en: We load our data from a predefined directory and process them into manageable
    chunks. These chunks are designed to be sized so that we can pass the chunks to
    the LLM as we got the results from the similarity search procedure. This process
    utilizes the DirectoryLoader to load documents into memory and the RecursiveCharacterTextSplitter
    to break them down into manageable chunks. It splits documents at a character
    level, with a default chunk size of 1000 characters and a chunk overlap of 20
    characters. The chunk overlap ensures there is contextual continuity between chunks,
    minimizing the risk of losing meaningful context at the chunk borders.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从预定义的目录加载数据，并将其处理成可管理的块。这些块的设计大小使我们能够在从相似性搜索过程中获得结果后将块传递给 LLM。此过程利用 DirectoryLoader
    将文档加载到内存中，并使用 RecursiveCharacterTextSplitter 将其拆分为可管理的块。它在字符级别拆分文档，默认块大小为 1000
    个字符，块重叠为 20 个字符。块重叠确保了块之间的上下文连续性，最小化了在块边界丢失有意义上下文的风险。
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Then, we generate vector embeddings from these chunks using the SentenceTransformerEmbeddings
    method and index them in ChromaDB, our vector database. These embeddings are stored
    in the database and serve as our searchable data. The database does not live in
    memory; notice that we are persisting it on disk, which reduces our memory overhead.
    Next, we load the chat model, specifically OpenAI’s gpt-3.5-turbo, which serves
    as our LLM.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用 SentenceTransformerEmbeddings 方法从这些块中生成向量嵌入，并将其索引到我们的向量数据库 ChromaDB
    中。这些嵌入被存储在数据库中，作为可搜索的数据。数据库并不驻留在内存中；请注意，我们将其持久化到磁盘，这减少了内存开销。接下来，我们加载聊天模型，具体来说是
    OpenAI 的 gpt-3.5-turbo，它作为我们的 LLM。
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Finally, the “/query/{question}” endpoint receives user queries. It runs a similarity
    search on the database, using the question as input. If matching documents exist,
    they are fed into the LLM, and the answer is generated. The answer and the sources
    (the original documents and their metadata) are returned, ensuring that the provided
    information is easily verifiable.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，“/query/{question}” 端点接收用户查询。它在数据库上运行相似性搜索，使用问题作为输入。如果存在匹配的文档，它们将被送入 LLM，并生成答案。答案和来源（原始文档及其元数据）会被返回，确保提供的信息易于验证。
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We containerized the application using Docker, which ensures isolation and
    environment consistency, regardless of the deployment platform. The Dockerfile
    below details our setup:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 Docker 对应用程序进行容器化，这确保了隔离性和环境一致性，无论部署平台如何。下面的 Dockerfile 详细说明了我们的设置：
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The application runs in a Python 3.9 environment and we need to install all
    necessary dependencies from a requirements.txt file:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序运行在 Python 3.9 环境中，我们需要从 requirements.txt 文件中安装所有必要的依赖项：
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The application is then served through Uvicorn on port 1010.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序随后通过 Uvicorn 在 1010 端口提供服务。
- en: Note that we need to configure our environment variables. Our application requires
    the OPENAI_API_KEY for the ChatOpenAI model. The best practice for sensitive information
    like API keys is to store them as environment variables rather than hardcoding
    them into the application.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们需要配置环境变量。我们的应用程序需要 OPENAI_API_KEY 以便使用 ChatOpenAI 模型。处理 API 密钥等敏感信息的最佳实践是将其存储为环境变量，而不是硬编码到应用程序中。
- en: We use the python-dotenv package to load environment variables from a .env file
    at the project root. In a production environment, we would want to use a more
    secure method, such as Docker secrets or a secure vault service.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 python-dotenv 包从项目根目录的 .env 文件加载环境变量。在生产环境中，我们希望使用更安全的方法，例如 Docker secrets
    或安全保险库服务。
- en: 'Experiment: Understanding the Effectiveness of Document-Oriented Agents'
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验：理解面向文档的智能体的有效性
- en: The experiment primary goal was to assess our document-oriented agent’s effectiveness
    in providing comprehensive and accurate responses to user queries.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 实验的主要目标是评估我们的面向文档的智能体在提供全面和准确的用户查询响应方面的有效性。
- en: 'We use a series of our Medium articles as our knowledge base. These articles,
    covering a variety of AI and machine learning topics, are ingested and indexed
    in our Chroma vector database. The selected articles were:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用一系列 Medium 文章作为我们的知识库。这些文章涵盖了各种 AI 和机器学习主题，被摄取并在我们的 Chroma 向量数据库中建立索引。所选的文章有：
- en: '“Whisper JAX vs PyTorch: Uncovering the Truth about ASR Performance on GPUs”'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “Whisper JAX vs PyTorch：揭示 GPU 上 ASR 性能的真相”
- en: “Testing the Massively Multilingual Speech (MMS) Model that Supports 1162 Languages”
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “测试支持1162种语言的大规模多语言语音（MMS）模型”
- en: “Harnessing the Falcon 40B Model, the Most Powerful Open-Source LLM”
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “利用Falcon 40B模型，最强大的开源LLM”
- en: '“The Power of OpenAI’s Function Calling in Language Learning Models: A Comprehensive
    Guide”'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “OpenAI函数调用在语言学习模型中的力量：全面指南”
- en: The articles were broken into manageable chunks, converted into vector embeddings,
    and indexed in our database, thus forming the backbone of the agent’s knowledge.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这些文章被拆分成可管理的块，转换为向量嵌入，并索引到我们的数据库中，从而形成了智能体知识的骨架。
- en: 'The user query was executed by calling the API endpoint of our application,
    which is implemented using FastAPI and deployed via Docker. The query we used
    for the experiment was: “What is Falcon-40b and can I use it for commercial use?”.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 用户查询通过调用我们应用的API端点来执行，该端点是使用FastAPI实现并通过Docker部署的。我们在实验中使用的查询是：“什么是Falcon-40b，我可以将其用于商业用途吗？”。
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In response to our query, the LLM explained what Falcon-40b is and confirmed
    that it can be used commercially. The information was backed up by four different
    source chunks, all coming from the article: “Harnessing the Falcon 40B Model,
    the Most Powerful Open-Source LLM”. Each source chunk was also added to the response,
    as we saw above, so that the user could verify the original text supporting the
    answer of the LLM. The chunks were also scored on their relevance to the query,
    which gives us an additional perspective on the importance of that section to
    the overall answer of the agent.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 针对我们的查询，LLM解释了什么是Falcon-40b，并确认它可以用于商业用途。信息得到了来自四个不同来源块的支持，这些来源块均来自文章：“利用Falcon
    40B模型，最强大的开源LLM”。每个来源块也被添加到回答中，如我们所见，以便用户可以验证支持LLM答案的原始文本。这些块还根据与查询的相关性进行了评分，这为我们提供了关于该部分对智能体整体回答重要性的额外视角。
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Conclusions
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this article, we built a solution to overcome the challenges of handling
    large-scale documents in AI systems, leveraging vector databases and a suite of
    open-source tools. Our approach employs ChromaDB and Langchain with OpenAI’s ChatGPT
    to build a capable document-oriented agent.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们构建了解决在AI系统中处理大规模文档挑战的解决方案，利用向量数据库和一套开源工具。我们的方法采用ChromaDB和Langchain与OpenAI的ChatGPT一起构建一个高效的文档导向智能体。
- en: Our approach enables the agent to answer complex queries by searching and processing
    chunks of text from large-scale databases — in our case, a series of Medium articles
    on various AI topics. In addition to the agent’s answers, we also returned the
    chunks of the original documents used to support the LLM’s claims and their score
    regarding similarity to the user’s query. It is an important feature since these
    agents can sometimes provide inaccurate information.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的方法使得智能体能够通过搜索和处理来自大规模数据库的文本块——在我们的案例中，是一系列关于各种AI主题的Medium文章——来回答复杂的查询。除了智能体的回答，我们还返回了用于支持LLM主张的原始文档块及其与用户查询的相似性评分。这是一个重要的特性，因为这些智能体有时可能提供不准确的信息。
- en: About me
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于我
- en: Serial entrepreneur and leader in the AI space. I develop AI products for businesses
    and invest in AI-focused startups.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 连续创业者和AI领域的领军人物。我为企业开发AI产品，并投资于专注于AI的初创公司。
- en: '[Founder @ ZAAI](http://zaai.ai) | [LinkedIn](https://www.linkedin.com/in/luisbrasroque/)
    | [X/Twitter](https://x.com/luisbrasroque)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[创始人 @ ZAAI](http://zaai.ai) | [LinkedIn](https://www.linkedin.com/in/luisbrasroque/)
    | [X/Twitter](https://x.com/luisbrasroque)'
- en: 'Large Language Models Chronicles: Navigating the NLP Frontier'
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大型语言模型编年史：探索NLP前沿
- en: 'This article belongs to “Large Language Models Chronicles: Navigating the NLP
    Frontier”, a new weekly series of articles that will explore how to leverage the
    power of large models for various NLP tasks. By diving into these cutting-edge
    technologies, we aim to empower developers, researchers, and enthusiasts to harness
    the potential of NLP and unlock new possibilities.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 本文属于“**大型语言模型编年史：探索NLP前沿**”，这是一个新的每周系列文章，将探讨如何利用大型模型的力量进行各种NLP任务。通过深入这些前沿技术，我们旨在赋能开发者、研究人员和爱好者，挖掘NLP的潜力，开启新的可能性。
- en: 'Articles published so far:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今为止发布的文章：
- en: '[Summarizing the latest Spotify releases with ChatGPT](https://medium.com/towards-data-science/summarizing-the-latest-spotify-releases-with-chatgpt-553245a6df88)'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[用ChatGPT总结最新的Spotify发布](https://medium.com/towards-data-science/summarizing-the-latest-spotify-releases-with-chatgpt-553245a6df88)'
- en: '[Master Semantic Search at Scale: Index Millions of Documents with Lightning-Fast
    Inference Times using FAISS and Sentence Transformers](https://medium.com/towards-data-science/master-semantic-search-at-scale-index-millions-of-documents-with-lightning-fast-inference-times-fa395e4efd88)'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[掌握大规模语义搜索：使用 FAISS 和 Sentence Transformers 索引数百万份文档，获得闪电般快速的推理时间](https://medium.com/towards-data-science/master-semantic-search-at-scale-index-millions-of-documents-with-lightning-fast-inference-times-fa395e4efd88)'
- en: '[Unlock the Power of Audio Data: Advanced Transcription and Diarization with
    Whisper, WhisperX, and PyAnnotate](https://medium.com/towards-data-science/unlock-the-power-of-audio-data-advanced-transcription-and-diarization-with-whisper-whisperx-and-ed9424307281)'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[解锁音频数据的力量：使用 Whisper、WhisperX 和 PyAnnotate 进行高级转录和标记](https://medium.com/towards-data-science/unlock-the-power-of-audio-data-advanced-transcription-and-diarization-with-whisper-whisperx-and-ed9424307281)'
- en: '[Whisper JAX vs PyTorch: Uncovering the Truth about ASR Performance on GPUs](https://medium.com/towards-data-science/whisper-jax-vs-pytorch-uncovering-the-truth-about-asr-performance-on-gpus-8794ba7a42f5)'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Whisper JAX 与 PyTorch：揭示 GPU 上 ASR 性能的真相](https://medium.com/towards-data-science/whisper-jax-vs-pytorch-uncovering-the-truth-about-asr-performance-on-gpus-8794ba7a42f5)'
- en: '[Vosk for Efficient Enterprise-Grade Speech Recognition: An Evaluation and
    Implementation Guide](https://medium.com/towards-data-science/vosk-for-efficient-enterprise-grade-speech-recognition-an-evaluation-and-implementation-guide-87a599217a6c)'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Vosk 用于高效企业级语音识别：评估与实施指南](https://medium.com/towards-data-science/vosk-for-efficient-enterprise-grade-speech-recognition-an-evaluation-and-implementation-guide-87a599217a6c)'
- en: '[Testing the Massively Multilingual Speech (MMS) Model that Supports 1162 Languages](https://medium.com/towards-data-science/testing-the-massively-multilingual-speech-mms-model-that-supports-1162-languages-5db957ee1602)'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[测试支持 1162 种语言的极大规模多语言语音 (MMS) 模型](https://medium.com/towards-data-science/testing-the-massively-multilingual-speech-mms-model-that-supports-1162-languages-5db957ee1602)'
- en: '[Harnessing the Falcon 40B Model, the Most Powerful Open-Source LLM](https://medium.com/towards-data-science/harnessing-the-falcon-40b-model-the-most-powerful-open-source-llm-f70010bc8a10)'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[利用 Falcon 40B 模型，最强大的开源 LLM](https://medium.com/towards-data-science/harnessing-the-falcon-40b-model-the-most-powerful-open-source-llm-f70010bc8a10)'
- en: '[The Power of OpenAI’s Function Calling in Language Learning Models: A Comprehensive
    Guide](https://medium.com/towards-data-science/the-power-of-openais-function-calling-in-language-learning-models-a-comprehensive-guide-cce8cd84dc3c)'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[OpenAI 的函数调用在语言学习模型中的力量：全面指南](https://medium.com/towards-data-science/the-power-of-openais-function-calling-in-language-learning-models-a-comprehensive-guide-cce8cd84dc3c)'
- en: References
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] [https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier#introduction](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier#introduction)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier#introduction](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier#introduction)'
- en: '[2] [Master Semantic Search at Scale: Index Millions of Documents with Lightning-Fast
    Inference Times using FAISS and Sentence Transformers](https://medium.com/towards-data-science/master-semantic-search-at-scale-index-millions-of-documents-with-lightning-fast-inference-times-fa395e4efd88)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [掌握大规模语义搜索：使用 FAISS 和 Sentence Transformers 索引数百万份文档，获得闪电般快速的推理时间](https://medium.com/towards-data-science/master-semantic-search-at-scale-index-millions-of-documents-with-lightning-fast-inference-times-fa395e4efd88)'
