- en: 'Prompt Engineering: How to Trick AI into Solving Your Problems'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示工程：如何让AI解决你的问题
- en: 原文：[https://towardsdatascience.com/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f](https://towardsdatascience.com/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f](https://towardsdatascience.com/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f)
- en: 7 prompting tricks, LangChain, and Python example code
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7个提示技巧、LangChain和Python示例代码
- en: '[](https://shawhin.medium.com/?source=post_page-----7ce1ed3b553f--------------------------------)[![Shaw
    Talebi](../Images/1449cc7c08890e2078f9e5d07897e3df.png)](https://shawhin.medium.com/?source=post_page-----7ce1ed3b553f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7ce1ed3b553f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7ce1ed3b553f--------------------------------)
    [Shaw Talebi](https://shawhin.medium.com/?source=post_page-----7ce1ed3b553f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shawhin.medium.com/?source=post_page-----7ce1ed3b553f--------------------------------)[![Shaw
    Talebi](../Images/1449cc7c08890e2078f9e5d07897e3df.png)](https://shawhin.medium.com/?source=post_page-----7ce1ed3b553f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7ce1ed3b553f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7ce1ed3b553f--------------------------------)
    [Shaw Talebi](https://shawhin.medium.com/?source=post_page-----7ce1ed3b553f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7ce1ed3b553f--------------------------------)
    ·14 min read·Aug 25, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7ce1ed3b553f--------------------------------)
    ·14分钟阅读·2023年8月25日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: This is the fourth article in a [series on using large language models](/a-practical-introduction-to-llms-65194dda1148)
    (LLMs) in practice. Here, I will discuss prompt engineering (PE) and how to use
    it to build LLM-enabled applications. I start by reviewing key PE techniques and
    then walk through Python example code of using LangChain to build an LLM-based
    application.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这是[大型语言模型实践系列]( /a-practical-introduction-to-llms-65194dda1148)中的第四篇文章。在这里，我将讨论提示工程（PE）以及如何使用它来构建支持LLM的应用程序。我首先回顾关键的PE技术，然后通过Python示例代码演示如何使用LangChain构建基于LLM的应用程序。
- en: '![](../Images/51cee05215f7e6b279687f028ed20dcc.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/51cee05215f7e6b279687f028ed20dcc.png)'
- en: Photo by [Jason Leung](https://unsplash.com/@ninjason?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Jason Leung](https://unsplash.com/@ninjason?utm_source=medium&utm_medium=referral)
    提供，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: When first hearing about prompt engineering, many technical people (including
    myself) tend to scoff at the idea. We might think, “*Prompt engineering? Psssh,
    that’s lame. Tell me how to build an LLM from scratch.*”
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当首次听说提示工程时，许多技术人员（包括我自己）往往对这个想法嗤之以鼻。我们可能会想，“*提示工程？噗，这太无聊了。告诉我怎么从头开始构建一个LLM吧。*”
- en: However, after diving into it more deeply, I’d caution developers against writing
    off prompt engineering automatically. I’ll go even further and say that **prompt
    engineering can realize 80% of the value** of most LLM use cases with (relatively)
    very low effort.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，深入探讨之后，我要提醒开发者不要自动忽视提示工程。我甚至可以说，**提示工程可以实现大多数LLM使用案例的80%价值**，且（相对）花费的精力非常少。
- en: My goal with this article is to convey this point via a practical review of
    prompt engineering and illustrative examples. While there are surely gaps in what
    prompt engineering can do, it opens the door to discovering simple and clever
    solutions to our problems.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我写这篇文章的目标是通过对提示工程的实际回顾和示例来传达这一观点。虽然提示工程的功能确实有一些不足，但它为发现简单而聪明的解决方案打开了大门。
- en: Supplemental Video.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 附加视频。
- en: '**What is Prompt Engineering?**'
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**什么是提示工程？**'
- en: In the [first article of this series](/a-practical-introduction-to-llms-65194dda1148),
    I defined **prompt engineering** as **any use of an LLM out-of-the-box** (i.e.
    not training any internal model parameters). However, there is much more that
    can be said about it.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在[本系列的第一篇文章](/a-practical-introduction-to-llms-65194dda1148)中，我将**提示工程**定义为**任何开箱即用的LLM的使用**（即不训练任何内部模型参数）。然而，还有更多可以说的。
- en: Prompt Engineering is “*the means by which LLMs are programmed with prompts.*”
    [[1](https://arxiv.org/abs/2302.11382)]
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提示工程是“*通过提示编程LLM的方法。*” [[1](https://arxiv.org/abs/2302.11382)]
- en: Prompt Engineering is “a*n empirical art of composing and formatting the prompt
    to maximize a model’s performance on a desired task.*” [[2](https://arxiv.org/abs/2106.09685)]
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提示工程是“*一种将提示进行构建和格式化的经验性艺术，以最大化模型在特定任务上的表现*。” [[2](https://arxiv.org/abs/2106.09685)]
- en: '*“language models… want to complete documents, and so you can trick them into
    performing tasks just by arranging fake documents*.” [[3](https://www.youtube.com/watch?v=bZQun8Y4L2A)]'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*“语言模型…希望完成文档，因此你可以通过安排虚假的文档来欺骗它们执行任务*。” [[3](https://www.youtube.com/watch?v=bZQun8Y4L2A)]'
- en: The first definition conveys the key innovation coming from LLMs, which is that
    **computers can now be programmed using plain English**. The second point frames
    prompt engineering as a largely empirical endeavor, where practitioners, tinkerers,
    and builders are the key explorers of this new way of programming.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个定义传达了来自 LLM 的关键创新，即**计算机现在可以使用简单的英语进行编程**。第二点将提示工程框架化为一种主要经验性的工作，其中从业者、修补者和构建者是这一新编程方式的主要探索者。
- en: The third point (from [Andrej Karpathy](https://medium.com/u/ac9d9a35533e?source=post_page-----7ce1ed3b553f--------------------------------))
    reminds us that **LLMs aren’t explicitly trained to do almost anything we ask
    them to do**. Thus, in some sense, we are “tricking” these language models to
    solve problems. I feel this captures the essence of prompt engineering, which
    relies less on your technical skills and more on your creativity.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 第三点（来自 [Andrej Karpathy](https://medium.com/u/ac9d9a35533e?source=post_page-----7ce1ed3b553f--------------------------------)）提醒我们**LLM
    并未明确训练来做几乎我们要求的任何事情**。因此，从某种意义上说，我们是在“欺骗”这些语言模型以解决问题。我觉得这捕捉到了提示工程的本质，它依赖于你的创造力而非技术技能。
- en: '**2 Levels of Prompt Engineering**'
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**提示工程的两个层次**'
- en: There are two distinct ways in which one can do prompt engineering, which I
    called the “**easy way**” and the “**less easy way**” in the [first article](/a-practical-introduction-to-llms-65194dda1148)
    of this series.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过两种不同的方式进行提示工程，我在本系列的 [第一篇文章](/a-practical-introduction-to-llms-65194dda1148)
    中将其称为“**简单方法**”和“**较难的方法**”。
- en: The Easy Way
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简单的方法
- en: This is how most of the world does prompt engineering, which is via ChatGPT
    (or something similar). It is an intuitive, no-code, and cost-free way to interact
    with an LLM.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这是大多数世界上人们进行提示工程的方式，即通过 ChatGPT（或类似的工具）。这是一种直观的、无需编码且无需费用的与 LLM 互动的方式。
- en: While this is a great approach for something quick and simple, e.g. summarizing
    a page of text, rewriting an email, helping you brainstorm birthday party plans,
    etc., it has its downsides. A big one is that **it’s not easy to integrate this
    approach into a larger automated process or software system**. To do this, we
    need to go one step further.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这种方法适合快速和简单的任务，例如总结一页文本、重写一封邮件、帮助你头脑风暴生日派对计划等，但它也有其缺点。一个主要问题是**将这种方法整合到更大的自动化流程或软件系统中并不容易**。为了做到这一点，我们需要更进一步。
- en: The Less Easy Way
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 较难的方法
- en: This resolves many of the drawbacks of the “easy way” by interacting with LLMs
    programmatically i.e. using Python. We got a sense of how we can do this in the
    previous two articles of this series, where explored [OpenAI’s Python API](/cracking-open-the-openai-python-api-230e4cae7971)
    and the [Hugging Face Transformers library](/cracking-open-the-hugging-face-transformers-library-350aa0ef0161).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这通过以编程方式与 LLM 互动来解决了“简单方法”的许多缺点，即使用 Python。我们在本系列的前两篇文章中了解了如何做到这一点，其中探索了 [OpenAI
    的 Python API](/cracking-open-the-openai-python-api-230e4cae7971) 和 [Hugging Face
    Transformers 库](/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)。
- en: While this requires more technical knowledge, **this is where the real power
    of prompt engineering lies** because it allows developers to integrate LLM-based
    modules into larger software systems.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这需要更多的技术知识，**但这正是提示工程的真正力量所在**，因为它允许开发人员将基于 LLM 的模块集成到更大的软件系统中。
- en: A good (and perhaps ironic) example of this is ChatGPT. The core of this product
    is prompting a pre-trained model (i.e. GPT-3.5-turbo) to act like a chatbot and
    then wrapping it in an easy-to-use web interface.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好的（也许是具有讽刺意味的）例子是 ChatGPT。这个产品的核心是提示一个预训练的模型（即 GPT-3.5-turbo）充当聊天机器人，然后将其封装在一个易于使用的网页界面中。
- en: Of course, developing GPT-3.5-turbo is the hard part, **but that’s not something
    we need to worry about here**. With all the pre-trained LLMs we have at our fingertips,
    almost anyone with basic programming skills can create a powerful AI application
    like ChatGPT without being an AI researcher or a machine learning Ph.D.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，开发GPT-3.5-turbo是困难的，**但这不是我们需要担心的事情**。借助我们手头的所有预训练LLM，几乎任何具备基本编程技能的人都可以创建一个像ChatGPT这样的强大AI应用程序，而不必是AI研究员或机器学习博士。
- en: '**Building AI Apps with Prompt Engineering**'
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**利用提示工程构建AI应用**'
- en: The less easy way unlocks a **new paradigm of programming and software development**.
    No longer are developers required to define every inch of logic in their software
    systems. They now have the option to offload a non-trivial portion to LLMs. Let’s
    look at a concrete example of what this might look like.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 更困难的方法解锁了**编程和软件开发的新范式**。开发者不再需要在软件系统中定义每一寸逻辑。他们现在可以选择将非琐碎的部分转移给LLM。让我们来看一个具体的例子，这可能是什么样的。
- en: Suppose you want to create an **automatic grader for a high school history class**.
    The trouble, however, is that all the questions have written responses, so there
    often can be multiple versions of a correct answer. For example, the following
    responses to “*Who was the 35th president of the United States of America?*” could
    be correct.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想为高中历史课创建一个**自动评分系统**。问题在于所有问题都有书面回答，因此通常会有多个正确答案的版本。例如，以下对“*谁是美国的第35任总统？*”的回答可能都是正确的。
- en: John F. Kennedy
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 约翰·F·肯尼迪
- en: JFK
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JFK
- en: Jack Kennedy (a common nickname)
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 杰克·肯尼迪（一个常见的昵称）
- en: John Fitzgerald Kennedy (probably trying to get extra credit)
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 约翰·F·肯尼迪（可能试图获得额外的学分）
- en: John F. Kenedy (misspelled last name)
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 约翰·F·肯尼迪（拼写错误的姓氏）
- en: In the **traditional programming paradigm**, it was on the developer to figure
    out how to account for all these variations. To do this, they might list all possible
    correct answers and use an exact string-matching algorithm or maybe even use fuzzy
    matching to help with misspelled words.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在**传统编程范式**中，开发者需要找出如何处理所有这些变体。为此，他们可能会列出所有可能的正确答案，并使用精确的字符串匹配算法，甚至可能使用模糊匹配来帮助处理拼写错误的单词。
- en: However, with this new **LLM-enabled paradigm**, **the problem can be solved
    through simple prompt engineering**. For instance, we could use the following
    prompt to evaluate student answers.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，借助这种新的**LLM启用的范式**，**问题可以通过简单的提示工程来解决**。例如，我们可以使用以下提示来评估学生的答案。
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We can think of this prompt as a function, where given a ***question***, ***correct_answer***,
    and ***student_answer***, it generates the student's grade. This can then be integrated
    into a larger piece of software that implements the automatic grader.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这个提示视为一个函数，给定一个***问题***、***正确答案***和***学生答案***，它生成学生的评分。然后，这可以集成到一个更大的实现自动评分系统的软件中。
- en: In terms of time-saving, this prompt took me about 2 minutes to write, while
    if I were to try to develop an algorithm to do the same thing, it would take me
    hours (if not days) and probably have worse performance. **So the time savings
    for tasks like this are 100–1000x**.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 从节省时间的角度来看，这个提示我花了大约2分钟来编写，而如果我尝试开发一个算法来做同样的事情，它可能需要几个小时（甚至几天），而且性能可能更差。**因此，这类任务的时间节省是100–1000倍**。
- en: Of course, there are many tasks in which LLMs do not provide any substantial
    benefit, and other existing methods are much better suited (e.g. predicting tomorrow’s
    weather). In no way are LLMs the solution to every problem, but they do create
    a new set of solutions to tasks that require processing natural language effectively—something
    that has been historically difficult for computers to do.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，有许多任务中LLM并没有提供实质性的好处，其他现有方法更适合（例如预测明天的天气）。LLM绝不是解决所有问题的方案，但它们确实创造了一套新的解决方案，用于处理需要有效处理自然语言的任务——这是计算机历史上一直困难的任务。
- en: '**7 Tricks for Prompt Engineering**'
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**提示工程的7个技巧**'
- en: While the prompt example from before may seem like a natural and obvious way
    to frame the automatic grading task, it deliberately employed specific prompt
    engineering heuristics (or “tricks,” as I’ll call them). These (and other) tricks
    have emerged as reliable ways to improve the quality of LLM responses.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然之前的提示示例看起来像是一种自然且明显的自动评分任务框架，但它刻意使用了特定的提示工程启发式方法（或者说“技巧”，如我所称）。这些（以及其他）技巧已成为提高LLM响应质量的可靠方法。
- en: Although there are many tips and tricks for writing good prompts, here I restrict
    the discussion to the ones that seem the most fundamental (IMO) based on a handful
    of references [1,3–5]. For a deeper dive, I recommend the reader explore the sources
    cited here.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有许多撰写良好提示的技巧和窍门，但在这里我将讨论那些基于少数参考资料（IMO）看起来最基本的技巧。对于更深入的了解，我建议读者探索此处引用的来源。
- en: '**Trick 1: Be Descriptive (More is Better)**'
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**技巧 1：描述性强（多多益善）**'
- en: A defining feature of LLMs is that they are trained on massive text corpora.
    This equips them with a vast knowledge of the world and the ability to perform
    an enormous variety of tasks. However, this impressive generality may hinder performance
    on a specific task if the proper context is not provided.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 的一个决定性特征是它们在大量文本语料库上进行训练。这使它们具备了广泛的世界知识和执行各种任务的能力。然而，这种令人印象深刻的普遍性可能会在没有提供适当上下文的情况下，影响特定任务的表现。
- en: For example, let’s compare two prompts for generating a birthday message for
    my dad.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们比较两个生成我爸爸生日祝福的提示。
- en: '***Without Trick***'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '***不使用技巧***'
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '***With Trick***'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '***使用技巧***'
- en: '[PRE2]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Trick 2: Give Examples**'
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**技巧 2：提供示例**'
- en: The next trick is to give the LLM example responses to improve its performance
    on a particular task. The technical term for this is **few-shot learning,** and
    has been shown to improve LLM performance significantly [6].
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个技巧是给 LLM 示例响应，以提高其在特定任务上的表现。这个技术术语是**少量学习**，已被证明能显著提高 LLM 的表现 [6]。
- en: Let’s look at a specific example. Say we want to write a subtitle for a Towards
    Data Science article. We can use existing examples to help guide the LLM completion.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个具体的例子。假设我们想为 Towards Data Science 文章写一个副标题。我们可以使用现有的示例来指导 LLM 完成。
- en: '***Without Trick***'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '***不使用技巧***'
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '***With Trick***'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '***使用技巧***'
- en: '[PRE4]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Trick 3: Use Structured Text**'
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**技巧 3：使用结构化文本**'
- en: Ensuring prompts follow an organized structure not only makes them easier to
    read and write, but also tends to help the model generate good completions. We
    employed this technique in the example for **Trick 2**, where we explicitly labeled
    the *title* and *subtitle* for each example.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 确保提示遵循有组织的结构，不仅使其更易读和编写，还往往有助于模型生成良好的完成。我们在**技巧 2**的示例中应用了这一技术，其中我们明确标记了每个示例的*标题*和*副标题*。
- en: 'However, there are countless ways we can give our prompts structure. Here are
    a handful of examples: use ALL CAPS for emphasis, use delimiters like [PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们可以以无数种方式为提示提供结构。这里有一些例子：使用全大写来强调，使用分隔符如 [PRE5]
- en: Write me a recipe for chocolate chip cookies.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 给我一个巧克力曲奇饼干的食谱。
- en: '[PRE6]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Create a well-organized recipe for chocolate chip cookies. Use the following
    \
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个组织良好的巧克力曲奇饼干食谱。使用以下\
- en: 'formatting elements:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 格式元素：
- en: '**Title**: Classic Chocolate Chip Cookies'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**标题**：经典巧克力曲奇饼干'
- en: '**Ingredients**: List the ingredients with precise measurements and formatting.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**材料**：列出配料及其准确的测量和格式。'
- en: '**Instructions**: Provide step-by-step instructions in numbered format, detailing
    the baking process.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤**：以编号格式提供逐步说明，详细说明烘焙过程。'
- en: '**Tips**: Include a separate section with helpful baking tips and possible
    variations.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示**：包括一个单独的部分，提供有用的烘焙提示和可能的变化。'
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Write me a LinkedIn post based on the following Medium blog.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 根据以下 Medium 博客写一篇 LinkedIn 帖子。
- en: 'Medium blog: {Medium blog text}'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Medium 博客：{Medium 博客文本}
- en: '[PRE8]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Write me a LinkedIn post based on the step-by-step process and Medium blog \
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 根据逐步过程和 Medium 博客写一篇 LinkedIn 帖子\
- en: given below.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如下所示。
- en: 'Step 1: Come up with a one line hook relevant to the blog.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 第 1 步：想出一个与博客相关的一句话引子。
- en: 'Step 2: Extract 3 key points from the article'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 第 2 步：从文章中提取 3 个关键点
- en: 'Step 3: Compress each point to less than 50 characters.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 第 3 步：将每个要点压缩到 50 个字符以内。
- en: 'Step 4: Combine the hook, compressed key points from Step 3, and a call to
    action \'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 第 4 步：将引子、第 3 步中的压缩要点和行动号召结合起来\
- en: to generate the final output.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 以生成最终输出。
- en: 'Medium blog: {Medium blog text}'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Medium 博客：{Medium 博客文本}
- en: '[PRE9]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Make me a travel itinerary for a weekend in New York City.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 给我制定一个在纽约市度过周末的旅行计划。
- en: '[PRE10]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Act as an NYC native and cabbie who knows everything about the city. \
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 充当一位了解纽约市的一切的纽约本地人和出租车司机。\
- en: Please make me a travel itinerary for a weekend in New York City based on \
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 请根据\
- en: your experience. Don't forget to include your charming NY accent in your \
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 你的经历。不要忘记在你的\
- en: response.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 响应。
- en: '[PRE11]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: What is an idea for an LLM-based application?
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一个基于 LLM 的应用程序的想法是什么？
- en: '[PRE12]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: I want you to ask me questions to help me come up with an LLM-based \
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你问我问题，以帮助我提出基于 LLM 的
- en: application idea. Ask me one question at a time to keep things conversational.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序想法。一次问我一个问题，以保持对话性。
- en: '[PRE13]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Review your previous response, pinpoint areas for enhancement, and offer an
    \
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 复查你之前的响应，找出改进的地方，并提供
- en: improved version. Then explain your reasoning for how you improved the response.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 改进版。然后解释你如何改进响应的理由。
- en: '[PRE14]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: You are a high school history teacher grading homework assignments. \
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 你是一名高中历史老师，负责评分作业。
- en: Based on the homework question indicated by "Q:" and the correct answer \
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 基于由 "Q:" 指示的作业问题和正确答案
- en: indicated by "A:", your task is to determine whether the student's answer is
    \
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 由 "A:" 指示，你的任务是确定学生的答案是否
- en: correct.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 正确。
- en: Grading is binary; therefore, student answers can be correct or wrong.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 评分是二元的，因此，学生的回答可以是正确的或错误的。
- en: Simple misspellings are okay.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的拼写错误是可以的。
- en: 'Q: {question}'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 'Q: {question}'
- en: 'A: {correct_answer}'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 'A: {correct_answer}'
- en: 'Student Answer: {student_answer}'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '学生答案: {student_answer}'
- en: '[PRE15]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: from langchain.chat_models import ChatOpenAI
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 从 langchain.chat_models 导入 ChatOpenAI
- en: from langchain.prompts import PromptTemplate
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 从 langchain.prompts 导入 PromptTemplate
- en: from langchain.chains import LLMChain
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 从 langchain.chains 导入 LLMChain
- en: from langchain.schema import BaseOutputParser
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 从 langchain.schema 导入 BaseOutputParser
- en: '[PRE16]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'from sk import my_sk #importing secret key from another python file'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '从 sk 导入 my_sk #从另一个 Python 文件导入密钥'
- en: '[PRE17]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: define LLM object
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义 LLM 对象
- en: chat_model = ChatOpenAI(openai_api_key=my_sk, temperature=0)
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: chat_model = ChatOpenAI(openai_api_key=my_sk, temperature=0)
- en: '[PRE18]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: define prompt template
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义提示模板
- en: prompt_template_text = """You are a high school history teacher grading \
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: prompt_template_text = """你是一名高中历史老师，负责评分
- en: homework assignments. Based on the homework question indicated by “**Q:**” \
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 作业。基于由 “**Q:**” 指示的作业问题
- en: and the correct answer indicated by “**A:**”, your task is to determine \
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 以及由 “**A:**” 指示的正确答案，你的任务是确定
- en: whether the student's answer is correct. Grading is binary; therefore, \
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 确定学生的答案是否正确。评分是二元的，因此，
- en: student answers can be correct or wrong. Simple misspellings are okay.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 学生的回答可以是正确的或错误的。简单的拼写错误是可以的。
- en: '**Q:** {question}'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** {question}'
- en: '**A:** {correct_answer}'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**A:** {correct_answer}'
- en: '**Student''s Answer:** {student_answer}'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**学生的答案:** {student_answer}'
- en: '"""'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: prompt = PromptTemplate(
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: prompt = PromptTemplate(
- en: input_variables=["question", "correct_answer", "student_answer"], \
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'input_variables=["question", "correct_answer", "student_answer"], '
- en: template = prompt_template_text)
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: template = prompt_template_text)
- en: '[PRE19]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: define chain
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义链
- en: chain = LLMChain(llm=chat_model, prompt=prompt)
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: chain = LLMChain(llm=chat_model, prompt=prompt)
- en: '[PRE20]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: define inputs
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义输入
- en: question = "Who was the 35th president of the United States of America?"
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 = "谁是美国第35任总统？"
- en: correct_answer = "John F. Kennedy"
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 正确答案 = "John F. Kennedy"
- en: student_answer =  "FDR"
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: student_answer = "FDR"
- en: run chain
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行链
- en: chain.run({'question':question, 'correct_answer':correct_answer, \
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: chain.run({'question':question, 'correct_answer':correct_answer,
- en: '''student_answer'':student_answer})'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '''student_answer'':student_answer})'
- en: 'output: Student''s Answer is wrong.'
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '输出: 学生的答案是错误的。'
- en: '[PRE21]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: define output parser
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义输出解析器
- en: 'class GradeOutputParser(BaseOutputParser):'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 'class GradeOutputParser(BaseOutputParser):'
- en: '"""Determine whether grade was correct or wrong"""'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"""确定评分是否正确或错误"""'
- en: 'def parse(self, text: str):'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'def parse(self, text: str):'
- en: '"""Parse the output of an LLM call."""'
  id: totrans-150
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"""解析 LLM 调用的输出。"""'
- en: return "wrong" not in text.lower()
  id: totrans-151
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 返回 "wrong" 不在 text.lower() 中
- en: '[PRE22]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: update chain
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更新链
- en: chain = LLMChain(
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: chain = LLMChain(
- en: llm=chat_model,
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: llm=chat_model,
- en: prompt=prompt,
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: prompt=prompt,
- en: output_parser=GradeOutputParser()
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: output_parser=GradeOutputParser()
- en: )
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: '[PRE23]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: run chain in for loop
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 for 循环中运行链
- en: student_answer_list = ["John F. Kennedy", "JFK", "FDR", "John F. Kenedy", \
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: student_answer_list = ["John F. Kennedy", "JFK", "FDR", "John F. Kenedy",
- en: '"John Kennedy", "Jack Kennedy", "Jacquelin Kennedy", \'
  id: totrans-162
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"John Kennedy", "Jack Kennedy", "Jacquelin Kennedy",'
- en: '"Robert F. Kenedy"]'
  id: totrans-163
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"Robert F. Kenedy"]'
- en: 'for student_answer in student_answer_list:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '对于 student_answer_list 中的 student_answer:'
- en: print(student_answer + " - " +
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: print(student_answer + " - " +
- en: str(chain.run({'question':question, 'correct_answer':correct_answer, \
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: str(chain.run({'question':question, 'correct_answer':correct_answer,
- en: '''student_answer'':student_answer})))'
  id: totrans-167
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '''student_answer'':student_answer})))'
- en: print('\n')
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: print('\n')
- en: 'Output:'
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '输出:'
- en: John F. Kennedy - True
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: John F. Kennedy - 正确
- en: JFK - True
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: JFK - 正确
- en: FDR - False
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: FDR - 错误
- en: John F. Kenedy - True
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: John F. Kenedy - 正确
- en: John Kennedy - True
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: John Kennedy - 正确
- en: Jack Kennedy - True
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Jack Kennedy - 正确
- en: Jacqueline Kennedy - False
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Jacqueline Kennedy - 错误
- en: Robert F. Kenedy - False
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Robert F. Kenedy - 错误
- en: '```'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '```'
- en: '[](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/langchain-example?source=post_page-----7ce1ed3b553f--------------------------------)
    [## YouTube-Blog/LLMs/langchain-example at main · ShawhinT/YouTube-Blog'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/langchain-example?source=post_page-----7ce1ed3b553f--------------------------------)
    [## YouTube-Blog/LLMs/langchain-example at main · ShawhinT/YouTube-Blog'
- en: Codes to complement YouTube videos and blog posts on Medium. - YouTube-Blog/LLMs/langchain-example
    at main ·…
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码用于补充 YouTube 视频和 Medium 博客文章。- YouTube-Blog/LLMs/langchain-example at main
    ·…
- en: github.com](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/langchain-example?source=post_page-----7ce1ed3b553f--------------------------------)
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/langchain-example?source=post_page-----7ce1ed3b553f--------------------------------)
- en: Limitations
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 限制
- en: Prompt Engineering is more than asking ChatGPT for help writing an email or
    learning about Quantum Computing. It is a ***new programming paradigm that changes
    how developers can build applications***.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: Prompt Engineering 不仅仅是向 ChatGPT 求助写电子邮件或了解量子计算。它是一个***改变开发者构建应用程序方式的新编程范式***。
- en: While this is a powerful innovation, it has its limitations. For one, optimal
    prompting strategies are LLM-dependent. For example, prompting GPT-3 to “think
    step-by-step” resulted in significant performance gains on simple mathematical
    reasoning tasks [8]. However, for the latest version of ChatGPT, the same strategy
    doesn’t seem helpful (it already thinks step-by-step).
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这是一个强大的创新，但它也有其局限性。例如，最佳的提示策略依赖于 LLM。例如，提示 GPT-3 “逐步思考” 在简单的数学推理任务中带来了显著的性能提升
    [8]。然而，对于最新版本的 ChatGPT，相同的策略似乎并没有帮助（它已经逐步思考）。
- en: Another limitation of Prompt Engineering is it requires large-scale general-purpose
    language models such as ChatGPT, which come at significant computational and financial
    costs. This may be overkill for many use cases that are more narrowly defined
    e.g. string matching, sentiment analysis, or text summarization.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: Prompt Engineering 的另一个限制是它需要大规模的通用语言模型，例如 ChatGPT，这需要显著的计算和经济成本。这对于许多更狭义的用例，例如字符串匹配、情感分析或文本摘要，可能过于复杂。
- en: We can overcome both these limitations via **fine-tuning** pre-trained language
    models. This is where we **take an existing language model and tweak it for a
    particular use case.** In the [next article](https://medium.com/towards-data-science/fine-tuning-large-language-models-llms-23473d763b91)
    of this series, we will explore popular fine-tuning techniques supplemented with
    example Python code.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过**微调**预训练语言模型来克服这两种限制。这是我们**对现有语言模型进行调整以适应特定用例的过程**。在[下一篇文章](https://medium.com/towards-data-science/fine-tuning-large-language-models-llms-23473d763b91)中，我们将探讨流行的微调技术，并附有示例
    Python 代码。
- en: '👉 **More on LLMs**: [Introduction](/a-practical-introduction-to-llms-65194dda1148)
    | [OpenAI API](https://medium.com/towards-data-science/cracking-open-the-openai-python-api-230e4cae7971)
    | [Hugging Face Transformers](https://medium.com/towards-data-science/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)
    | [Fine-tuning](https://medium.com/towards-data-science/fine-tuning-large-language-models-llms-23473d763b91)
    | [Build an LLM](/how-to-build-an-llm-from-scratch-8c477768f1f9) | [QLoRA](/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32)
    | [RAG](/how-to-improve-llms-with-rag-abdc132f76ac) | [Text Embeddings](/text-embeddings-classification-and-semantic-search-8291746220be)'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '👉 **关于 LLMs 的更多信息**: [介绍](/a-practical-introduction-to-llms-65194dda1148) |
    [OpenAI API](https://medium.com/towards-data-science/cracking-open-the-openai-python-api-230e4cae7971)
    | [Hugging Face Transformers](https://medium.com/towards-data-science/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)
    | [微调](https://medium.com/towards-data-science/fine-tuning-large-language-models-llms-23473d763b91)
    | [构建 LLM](/how-to-build-an-llm-from-scratch-8c477768f1f9) | [QLoRA](/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32)
    | [RAG](/how-to-improve-llms-with-rag-abdc132f76ac) | [文本嵌入](/text-embeddings-classification-and-semantic-search-8291746220be)'
- en: '![Shaw Talebi](../Images/02eefb458c6eeff7cd29d40c212e3b22.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![Shaw Talebi](../Images/02eefb458c6eeff7cd29d40c212e3b22.png)'
- en: '[Shaw Talebi](https://shawhin.medium.com/?source=post_page-----7ce1ed3b553f--------------------------------)'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '[Shaw Talebi](https://shawhin.medium.com/?source=post_page-----7ce1ed3b553f--------------------------------)'
- en: Large Language Models (LLMs)
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）
- en: '[View list](https://shawhin.medium.com/list/large-language-models-llms-8e009ae3054c?source=post_page-----7ce1ed3b553f--------------------------------)13
    stories![](../Images/82e865594c68f5307e75665842d197bb.png)![](../Images/b9436354721f807e0390b5e301be2119.png)![](../Images/59c8db581de77a908457dec8981f3c37.png)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://shawhin.medium.com/list/large-language-models-llms-8e009ae3054c?source=post_page-----7ce1ed3b553f--------------------------------)13
    个故事![](../Images/82e865594c68f5307e75665842d197bb.png)![](../Images/b9436354721f807e0390b5e301be2119.png)![](../Images/59c8db581de77a908457dec8981f3c37.png)'
- en: Resources
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源
- en: '**Connect**: [My website](https://shawhintalebi.com/) | [Book a call](https://calendly.com/shawhintalebi)
    | [Ask me anything](https://shawhintalebi.com/contact/)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '**联系**: [我的网站](https://shawhintalebi.com/) | [预约电话](https://calendly.com/shawhintalebi)
    | [问我任何问题](https://shawhintalebi.com/contact/)'
- en: '**Socials**: [YouTube 🎥](https://www.youtube.com/channel/UCa9gErQ9AE5jT2DZLjXBIdA)
    | [LinkedIn](https://www.linkedin.com/in/shawhintalebi/) | [Twitter](https://twitter.com/ShawhinT)'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '**社交媒体**: [YouTube 🎥](https://www.youtube.com/channel/UCa9gErQ9AE5jT2DZLjXBIdA)
    | [LinkedIn](https://www.linkedin.com/in/shawhintalebi/) | [Twitter](https://twitter.com/ShawhinT)'
- en: '**Support**: [Buy me a coffee](https://www.buymeacoffee.com/shawhint) ☕️'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '**支持**: [请我喝咖啡](https://www.buymeacoffee.com/shawhint) ☕️'
- en: '[](https://shawhin.medium.com/subscribe?source=post_page-----7ce1ed3b553f--------------------------------)
    [## Get FREE access to every new story I write'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shawhin.medium.com/subscribe?source=post_page-----7ce1ed3b553f--------------------------------)
    [## 免费获取我写的每一个新故事'
- en: Get FREE access to every new story I write P.S. I do not share your email with
    anyone By signing up, you will create a…
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 免费获取我写的每一个新故事 P.S. 我不会将你的电子邮件分享给任何人 通过注册，你将创建一个…
- en: shawhin.medium.com](https://shawhin.medium.com/subscribe?source=post_page-----7ce1ed3b553f--------------------------------)
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: shawhin.medium.com](https://shawhin.medium.com/subscribe?source=post_page-----7ce1ed3b553f--------------------------------)
- en: '[1] [arXiv:2302.11382](https://arxiv.org/abs/2302.11382) **[cs.SE]**'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [arXiv:2302.11382](https://arxiv.org/abs/2302.11382) **[cs.SE]**'
- en: '[2] [arXiv:2106.09685](https://arxiv.org/abs/2106.09685) **[cs.CL]**'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [arXiv:2106.09685](https://arxiv.org/abs/2106.09685) **[cs.CL]**'
- en: '[3] [State of GPT](https://www.youtube.com/watch?v=bZQun8Y4L2A) by [Andrej
    Karpathy](https://medium.com/u/ac9d9a35533e?source=post_page-----7ce1ed3b553f--------------------------------)
    at Microsoft Build 2023'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [GPT 状态](https://www.youtube.com/watch?v=bZQun8Y4L2A) 由 [Andrej Karpathy](https://medium.com/u/ac9d9a35533e?source=post_page-----7ce1ed3b553f--------------------------------)
    在 Microsoft Build 2023 上演讲'
- en: '[4] [arXiv:2206.07682](https://arxiv.org/abs/2206.07682) **[cs.CL]**'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [arXiv:2206.07682](https://arxiv.org/abs/2206.07682) **[cs.CL]**'
- en: '[5] [ChatGPT Prompt Engineering for Developers](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)
    by deeplearning.ai'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] [为开发者设计的 ChatGPT 提示工程](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)
    由 deeplearning.ai 提供'
- en: '[6] [arXiv:2005.14165](https://arxiv.org/abs/2005.14165) **[cs.CL]**'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] [arXiv:2005.14165](https://arxiv.org/abs/2005.14165) **[cs.CL]**'
- en: '[7] [arXiv:2201.11903](https://arxiv.org/abs/2201.11903) **[cs.CL]**'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] [arXiv:2201.11903](https://arxiv.org/abs/2201.11903) **[cs.CL]**'
- en: '[8] [arXiv:2210.03493](https://arxiv.org/abs/2210.03493) **[cs.CL]**'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] [arXiv:2210.03493](https://arxiv.org/abs/2210.03493) **[cs.CL]**'
