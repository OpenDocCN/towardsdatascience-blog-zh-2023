- en: Leveraging LLMs to Complete Recommendation Knowledge Graphs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/augmenting-intelligence-leveraging-llms-to-complete-recommendation-knowledge-graphs-a0585e311d3f](https://towardsdatascience.com/augmenting-intelligence-leveraging-llms-to-complete-recommendation-knowledge-graphs-a0585e311d3f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@alcarazanthony1?source=post_page-----a0585e311d3f--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----a0585e311d3f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a0585e311d3f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a0585e311d3f--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----a0585e311d3f--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a0585e311d3f--------------------------------)
    ·6 min read·Nov 6, 2023
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '*Artificial intelligence software was used to enhance the grammar, flow, and
    readability of this article’s text.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: With the rapid growth of the internet and online platforms, users are inundated
    with choices. Recommender systems have become essential in cutting through this
    information overload by predicting users’ preferences and suggesting relevant
    content. However, providing accurate and personalized recommendations remains
    a persistent challenge.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: The crux of the problem lies in understanding users’ true interests and intents
    by modeling their behavior. Recommender systems rely on patterns gleaned from
    user data like browsing history, purchases, ratings, and interactions. But real-world
    user data is often sparse and limited, lacking crucial contextual signals needed
    to capture the nuances of user intent.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Consequently, recommender models fail to learn comprehensive user and item representations.
    Their suggestions end up being too generic, repetitive, or irrelevant. The cold
    start problem compounds matters for new users with minimal activity history. Businesses
    also suffer from subpar customer experience leading to lost revenue.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: This calls for solutions that can unlock deeper insights from user data. An
    emerging approach is to use knowledge graphs that encapsulate facts and connections
    between entities. Well-constructed knowledge graphs hold tremendous potential
    for addressing critical challenges in recommendation systems.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Knowledge graphs go beyond just modeling user-item interactions. They encode
    diverse contextual metadata, attributes, and relationships across multiple entities.
    This multidimensional linked structure mimics how human memory stores world knowledge.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: By training specialized graph neural network models on such interconnected knowledge,
    recommender systems can learn more informative representations of user behavior
    and item characteristics. The enriched understanding leads to suggestions tailored
    to nuanced user needs and scenarios.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: However, a roadblock to this vision is that real-world knowledge graphs are
    far from perfect. They suffer from incompleteness, lacking crucial connections
    and details. This inhibits recommendation models from truly grasping user contexts
    and intents.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, recent advances in language models provide a ray of hope. Pre-trained
    models like GPT-3 have demonstrated remarkable natural language generation capabilities,
    powered by their vast stores of world knowledge. Early exploration of leveraging
    such models with in context learning to enhance knowledge graphs shows great promise
    (Wei et al., 2023).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we will dive deeper into how the augmented intelligence of
    language models can transform knowledge graphs. We will explore techniques like
    relationship prediction and attribute enrichment powered by models like GPT-3\.
    Through comprehensive examples, we will demonstrate how language model-enhanced
    knowledge graphs unlock the next level of intelligent recommendation systems.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Knowledge Graphs — Encoding Connections
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A knowledge graph represents entities (users, products) as nodes and their relationships
    as edges. Connecting users to their interests, demographics, purchase history
    etc. allows recommendation systems to learn better representations.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: However, real-world knowledge graphs derived from user data often suffer from
    sparsity and incompleteness. Many potential connections are simply missing, which
    limits the system’s ability to truly understand user intent.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: This is where large language models (LLMs) promise a breakthrough.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: LLMs — Augmenting Intelligence
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: LLMs have gained immense popularity due to their ability to generate remarkably
    human-like text. But what’s more impressive is the vast knowledge encoded in their
    parameters through pre-training on massive text corpora.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Recent research has explored leveraging this knowledge to improve recommender
    systems powered by graph neural networks (GNNs). The key idea is to use LLMs to
    augment existing knowledge graphs by reinforcing edges and enhancing node attributes.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: LLMs Reinforce Graph Connections
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: LLMs can predict potential connections between users and items that may not
    be explicitly present in the source data. For instance, by analyzing a user’s
    purchase history, they can suggest relevant products the user may be interested
    in.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: These LLM-predicted links help densify the sparse graphs, providing crucial
    signals for preference modeling. Reinforcing edges strengthens neighborhoods and
    allows collaborative patterns to emerge.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: LLMs Enhance Node Attributes
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Nodes in knowledge graphs represent entities like users and items. LLMs can
    augment attributes for these nodes based on the textual data associated with them.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: For example, product descriptions and reviews can be processed by LLMs to extract
    missing specs or tags. User comments and posts can be similarly analyzed to fill
    in sparse profile information.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: This results in nodes with rich feature vectors, overcoming cold start issues.
    The enhanced attributes improve semantics for better recommendations.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Improved Modeling with Augmented Graphs
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By training graph neural networks on LLM-enhanced knowledge graphs, recommendation
    systems can learn superior user and item representations.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: The improved structure and node features lead to embeddings that capture nuanced
    preferences and item characteristics. This addresses key challenges like sparsity
    and cold start that plague many recommendation engines.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Studies show significant gains on metrics like recall and lower latency from
    augmenting graphs with LLMs before feeding them to GNN architectures.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: 'The LLMRec technique :'
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The LLMRec techniques for augmenting knowledge graphs using equations in a
    step-by-step manner:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: Construct Prompts for the LLM'
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, we need to create prompts that provide context for the LLM to generate
    useful augmentations.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: 'For reinforcing user-item connections:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Where:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: 'PUI: User-item interaction prompt'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'D: Task description'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'H: User’s historical interactions'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'C: Candidate items'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'F: Desired output format'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For enhancing node attributes:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Where:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: 'PA: Attribute enhancement prompt'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'D: Task description'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'E: Available entity attributes'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'F: Output format for missing attributes'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Step 2: Obtain Augmentations from LLM'
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can now use the prompts to get augmented data from the LLM:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Where:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'EA: Augmented user-item interactions'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'AA: Augmented attributes'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LLM(): Language model (e.g. GPT-3)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Step 3: Incorporate Augmentations'
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The augmented data can be incorporated as:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Where:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: 'E’: Union of original and augmented interactions'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A’: Union of original and augmented attributes'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Step 4: Train Enhanced Recommender'
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The recommender model is then trained on the improved graph:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Where:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: 'θ*: Optimized model parameters'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'P(): Posterior probability'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data robustification technique
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Denoised data robustification technique used in LLMRec to handle noise in the
    augmented data:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '**Noisy User-Item Interaction Pruning**'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Sort the loss values calculated using the augmented user-item pairs in ascending
    order after each training iteration.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prune or discard a certain percentage of the pairs with the highest loss values.
    These likely correspond to noisy or unreliable samples.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retain only the most reliable pairs with lowest losses for training in the next
    iteration.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mathematically, this is implemented by sorting and slicing the loss tensor:'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Where N is the number of samples to retain after pruning.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '**Enhancing Augmented Features via MAE**'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Mask a subset of the augmented node features in the graph using [MASK] tokens.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reconstruct the original features from the masked versions using a masked autoencoder.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用掩码自编码器从掩码版本中重建原始特征。
- en: The feature reconstruction loss between original and masked features acts as
    regularization to improve feature quality.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始特征与掩码特征之间的特征重建损失作为正则化手段，以提高特征质量。
- en: 'Mathematically, the loss is computed as:'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从数学角度看，损失计算公式如下：
- en: '[PRE6]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Where f is the original feature, f’ is the masked feature, and V is the set
    of masked nodes.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，f是原始特征，f’是掩码特征，V是掩码节点的集合。
- en: Together, these techniques prune unreliable augmentations and impose constraints
    to ensure the noisy artificial data does not degrade performance. This results
    in a clean, robust training process using the high-quality augmented graph.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术共同作用，修剪不可靠的增强内容，并施加约束，以确保噪声人工数据不会降低性能。这导致使用高质量增强图谱的干净、稳健的训练过程。
- en: Limitless Possibilities with LLMs
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无限可能性与LLMs
- en: Knowledge graphs represent an incredibly promising direction for building more
    intelligent and contextual next-generation recommender systems. By encoding multifaceted
    connections between diverse entities, they can capture nuanced user behavior patterns
    and item relationships.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱代表了构建更智能、更具上下文理解的下一代推荐系统的一个极具潜力的方向。通过编码多方面的实体连接，它们可以捕捉到细微的用户行为模式和项目关系。
- en: However, real-world knowledge graphs often suffer from critical issues like
    sparsity and incompleteness that limit their effectiveness. This is where large
    language models provide a game-changing opportunity through their ability to predict
    missing connections and generate missing descriptive attributes.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，现实世界的知识图谱通常面临如稀疏性和不完整性等关键问题，这限制了它们的有效性。这正是大型语言模型通过预测缺失的连接和生成缺失的描述性属性提供颠覆性机会的地方。
- en: As we have seen through detailed examples, techniques like relationship reinforcement
    and attribute enhancement powered by LLMs can significantly augment existing knowledge
    graphs. The augmented intelligence acts as a missing jigsaw puzzle piece, connecting
    the dots to create a more holistic picture.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们通过详细的示例所见，像关系强化和属性增强这样的技术，借助LLMs可以显著增强现有的知识图谱。增强的智能如同缺失的拼图碎片，将各部分连接起来，创建一个更完整的图景。
- en: Training graph neural networks on such enriched representations unlocks the
    full potential of knowledge graphs. It allows learning sophisticated user and
    item embeddings that capture subtleties and semantics.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种丰富的表示上训练图神经网络，释放了知识图谱的全部潜力。这使得学习复杂的用户和项目嵌入成为可能，从而捕捉细微和语义信息。
- en: The result is recommender systems that truly understand user contexts and intents.
    LLM-powered knowledge graphs pave the path for intelligent assistants that can
    cater to nuanced user needs and scenarios.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是能够真正理解用户上下文和意图的推荐系统。LLM驱动的知识图谱为智能助手铺平了道路，这些助手可以满足细致的用户需求和场景。
- en: As language models continue to evolve, so will their capabilities for knowledge
    augmentation. With advances like causal reasoning and conversational interaction,
    they could help construct explanatory graphs that link recommendations to user
    behaviors and rationales.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 随着语言模型的不断进化，它们的知识增强能力也将不断提升。通过因果推理和对话互动等进展，它们可能帮助构建解释性图谱，将推荐与用户行为和理由联系起来。
- en: Adoption at scale does require addressing challenges like computational overhead
    and algorithmic biases that could creep in. But the possibilities make this one
    of the most promising directions for future recommender systems.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 大规模应用确实需要解决计算开销和可能出现的算法偏差等挑战。但这些可能性使得这是未来推荐系统中最有前景的方向之一。
- en: Knowledge is power. In the domain of recommendation systems, knowledge graphs
    complemented by language models looks set to unleash that power. It marks the
    beginning of a new era of intelligent recommendation. An era where systems transcend
    simply pattern matching, but exhibit a deeper understanding of user contexts and
    needs for thoughtful suggestions.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 知识就是力量。在推荐系统领域，语言模型补充的知识图谱看似将释放这种力量。这标志着智能推荐的新纪元的开始。在这个时代，系统不仅仅是模式匹配，而是表现出对用户上下文和需求的更深刻理解，从而提供有针对性的建议。
- en: '![](../Images/80fa24d339b7d18a5ce26a715d2778a2.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/80fa24d339b7d18a5ce26a715d2778a2.png)'
- en: Image by the author
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
