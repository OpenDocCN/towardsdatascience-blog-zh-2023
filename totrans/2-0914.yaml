- en: Forecast Multiple Time Series Like a Master
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 像大师一样预测多个时间序列
- en: 原文：[https://towardsdatascience.com/forecast-multiple-time-series-like-a-master-1579a2b6f18d](https://towardsdatascience.com/forecast-multiple-time-series-like-a-master-1579a2b6f18d)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/forecast-multiple-time-series-like-a-master-1579a2b6f18d](https://towardsdatascience.com/forecast-multiple-time-series-like-a-master-1579a2b6f18d)
- en: From local to global algorithms
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从局部到全局算法
- en: '[](https://medium.com/@zukaschikume?source=post_page-----1579a2b6f18d--------------------------------)[![Bartosz
    Szabłowski](../Images/2115d18d8d0463a6c680b0461472c203.png)](https://medium.com/@zukaschikume?source=post_page-----1579a2b6f18d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1579a2b6f18d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1579a2b6f18d--------------------------------)
    [Bartosz Szabłowski](https://medium.com/@zukaschikume?source=post_page-----1579a2b6f18d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@zukaschikume?source=post_page-----1579a2b6f18d--------------------------------)[![Bartosz
    Szabłowski](../Images/2115d18d8d0463a6c680b0461472c203.png)](https://medium.com/@zukaschikume?source=post_page-----1579a2b6f18d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1579a2b6f18d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1579a2b6f18d--------------------------------)
    [Bartosz Szabłowski](https://medium.com/@zukaschikume?source=post_page-----1579a2b6f18d--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1579a2b6f18d--------------------------------)
    ·30 min read·Apr 26, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----1579a2b6f18d--------------------------------)
    ·阅读时间30分钟·2023年4月26日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/3393fc3c8c56dbacebe783c486b2d2e7.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3393fc3c8c56dbacebe783c486b2d2e7.png)'
- en: Photo by [Jesús Rocha](https://unsplash.com/@jjrocha?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Jesús Rocha](https://unsplash.com/@jjrocha?utm_source=medium&utm_medium=referral)
    于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: I deal with forecasting multiple time series in business (to be precise, demand
    forecasting). In my previous article [*Sell Out Sell In Forecasting*](https://medium.com/towards-data-science/sell-out-sell-in-forecasting-45637005d6ee)
    I presented the methodology that I implemented at Nestlé for demand forecasting.
    In this article, I would like to introduce you to the universal (which doesn’t
    mean ideal) algorithms currently in use for forecasting multiple time series —
    such as **state of the art** for time series. For a retailer or manufacturer,
    forecasting demand is key to business. It allows them to create more accurate
    production plans and optimize their inventory. Unfortunately, many companies (not
    Nestlé :) ) don’t see this problem and they use spreadsheets with simple statistics.
    If they would change this they could significantly reduce their costs. After all,
    warehousing and out-of-date products — that’s an additional cost.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我在商业中处理多个时间序列的预测（准确来说，是需求预测）。在我之前的文章中[*Sell Out Sell In Forecasting*](https://medium.com/towards-data-science/sell-out-sell-in-forecasting-45637005d6ee)，我介绍了我在雀巢实施的需求预测方法。在这篇文章中，我想向你介绍目前用于预测多个时间序列的通用（这并不意味着理想）算法——例如**最先进**的时间序列算法。对于零售商或制造商来说，预测需求对业务至关重要。它允许他们制定更准确的生产计划并优化库存。不幸的是，许多公司（并非雀巢
    :) ）并未意识到这个问题，他们仍然使用简单统计的电子表格。如果他们能改变这种情况，他们可以显著降低成本。毕竟，仓储和过时产品——这也是额外的成本。
- en: '![](../Images/6b8f08996d06912402198087dc3b5e19.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6b8f08996d06912402198087dc3b5e19.png)'
- en: How to forecast multiple time series, Image by Author
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如何预测多个时间序列，作者提供的图片
- en: It’s hard to find someone working in Data Science who isn’t familiar with [**Scikit-learn**](https://scikit-learn.org/).
    For dataframes, you can use **Scikit-learn** to do most of the elements involved
    in machine learning — from preprocessing to hyperparameters selection, evaluation,
    and model prediction. We can assign Linear Regression, Decision Tree, or Support
    Vector Machine (SVM) to a variable *model* and use the same methods each time,
    like *fit* and *predict*. We have a lot of flexibility, but we also have an easy
    way of implementing solutions.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 很难找到一个数据科学领域的人不熟悉[**Scikit-learn**](https://scikit-learn.org/)。对于数据框架，你可以使用**Scikit-learn**来完成机器学习中涉及的大部分元素——从预处理到超参数选择、评估和模型预测。我们可以将线性回归、决策树或支持向量机（SVM）分配给变量*model*，并每次使用相同的方法，如*fit*和*predict*。我们有很大的灵活性，但也有一种简单的方式来实现解决方案。
- en: For time series the situation is different. If you are experimenting and want
    to compare different algorithms, the algorithms themselves are not only a problem.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 对于时间序列来说，情况是不同的。如果你在实验并想比较不同的算法，算法本身不仅仅是一个问题。
- en: If you are starting to work with time series, you need to process them, for
    resampling or filling in missing values — [**Pandas**](https://pandas.pydata.org/)
    is useful for that.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你开始处理时间序列，你需要对它们进行处理，例如重新采样或填补缺失值——[**Pandas**](https://pandas.pydata.org/)对此非常有用。
- en: If you want to do a decomposition, visualize ACF/PACF, or check a stationarity
    test, then the [**Statsmodels**](https://www.statsmodels.org/) library is useful.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想进行分解、可视化 ACF/PACF，或检查平稳性测试，那么[**Statsmodels**](https://www.statsmodels.org/)库将非常有用。
- en: For visualization, you will probably use [**Matplotlib**](https://matplotlib.org/),
    even if not this library, there are many built on it.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 对于可视化，你可能会使用[**Matplotlib**](https://matplotlib.org/)，即使不是这个库，也有许多建立在它之上的库。
- en: The fun begins when you want to use different algorithms. When you want to use
    **ARIMA** then you will probably use [**pmdarima**](https://alkaline-ml.com/pmdarima),
    [**Prophet**](https://facebook.github.io/prophet/) is another library. Typical
    **M**achine **L**earning algorithms can be found in the previously mentioned **Scikit-learn**,
    but you may also want to use boosting models like [**LightGBM**](https://lightgbm.readthedocs.io/)
    or [**CatBoost**](https://catboost.ai/). For **D**eep **N**eural **N**etworks
    and architectures from the most recent papers, [**PyTorch Forecasting**](https://pytorch-forecasting.readthedocs.io/)
    is worth using.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当你想使用不同的算法时，乐趣才开始。当你想使用**ARIMA**时，你可能会使用[**pmdarima**](https://alkaline-ml.com/pmdarima)，[**Prophet**](https://facebook.github.io/prophet/)是另一个库。典型的**M**achine
    **L**earning算法可以在之前提到的**Scikit-learn**中找到，但你也可能想使用像[**LightGBM**](https://lightgbm.readthedocs.io/)或[**CatBoost**](https://catboost.ai/)这样的提升模型。对于**D**eep
    **N**eural **N**etworks和最新论文中的架构，[**PyTorch Forecasting**](https://pytorch-forecasting.readthedocs.io/)值得使用。
- en: WOW🤯 A lot of libraries you probably need. If you want to be able to use the
    previously mentioned libraries it will be a lot of work, because most of them
    use different APIs, data types, and for each of the libraries with models you
    will have to prepare your own functions for backtesting and selection of hyperparameters.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: WOW🤯 你可能需要的库非常多。如果你想能够使用上述提到的库，这将是一个大量的工作，因为大多数库使用不同的 API、数据类型，并且对于每个库中的模型，你都必须准备自己的回测和超参数选择函数。
- en: '![](../Images/bd03ac32b8e2a4f05d9177ceaf14df14.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bd03ac32b8e2a4f05d9177ceaf14df14.png)'
- en: Library Darts, Image by Author, Inspired by library documentation
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Library Darts，由作者提供的图片，灵感来自于图书馆文档
- en: Here helps us [**Darts**](https://unit8co.github.io/darts/), which tries to
    be a **Scikit-learn** for time series, and its purpose is precise to simplify
    working with time series. Often its functionality is based on other libraries,
    for example, it uses **Statsmodels** for decomposition. It also makes **Darts**
    work well with other libraries if something isn’t implemented there, you can compare
    it to how you can mutually use **Matplotlib** to work with **Seaborn**.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们得到帮助的是[**Darts**](https://unit8co.github.io/darts/)，它试图成为时间序列的**Scikit-learn**，其目的是简化时间序列的工作。它的功能通常基于其他库，例如，它使用**Statsmodels**进行分解。如果某些功能在其他库中没有实现，**Darts**也能很好地与其他库协作，你可以将其与**Matplotlib**和**Seaborn**互相配合使用进行比较。
- en: Where it is necessary they have their own implementations, but they don’t want
    to reinvent the wheel and use what is already there in other popular libraries
    for time series.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在必要的地方，它们有自己的实现，但它们不想重新发明轮子，而是使用其他流行时间序列库中已经存在的东西。
- en: This idea is not new for time series, and there are other good libraries, such
    as [**sktime**](https://www.sktime.org/), [**GluonTS**](https://ts.gluon.ai/),or
    [**nixtla**](https://www.nixtla.io/), but in my opinion, **Darts** has the lowest
    entry threshold and is more complete. This is not an advertisement for this library,
    at the end of the day your forecast should bring value to the business you work
    for. You might as well write each of these models in code from scratch. I am going
    to use Darts in the below examples, but you will also be able to find these models
    (all or part of them) in the libraries mentioned above. I see space for improvement
    for the Darts library in **optimizing computation** if we want to train multiple
    local models ~ this tries **nixtla** library, which offers compatibility with
    Spark, Dask, and Ray.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这一概念在时间序列领域并不新鲜，还有其他很好的库，例如[**sktime**](https://www.sktime.org/)、[**GluonTS**](https://ts.gluon.ai/)或[**nixtla**](https://www.nixtla.io/)，但在我看来，**Darts**的入门门槛最低，功能也更为完善。这不是对这个库的广告，归根结底，你的预测应该为你工作的企业带来价值。你也可以从头开始用代码编写这些模型。我将使用Darts进行以下示例，但你也可以在上述提到的库中找到这些模型（全部或部分）。如果我们想训练多个本地模型，我认为Darts库在**优化计算**方面还有改进的空间——可以尝试**nixtla**库，它提供与Spark、Dask和Ray的兼容性。
- en: 'From my perspective, Darts is already a mature library and it is still being
    developed, just look at the [**changelog**](https://github.com/unit8co/darts/blob/master/CHANGELOG.md).
    Now you can install it in the standard way:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 从我的角度来看，Darts已经是一个成熟的库，并且仍在不断开发中，只需查看[**变更日志**](https://github.com/unit8co/darts/blob/master/CHANGELOG.md)即可。现在你可以按照标准方式进行安装：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Once we have the library installed in our environment then we can import it
    and use it in practice.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们在环境中安装了库，就可以导入并在实践中使用它。
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Single vs Multiple time series
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单变量与多变量时间序列
- en: '![](../Images/83b03160c0fff2b64f2e1b076f5efd04.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/83b03160c0fff2b64f2e1b076f5efd04.png)'
- en: One vs Multiple time series, Image by Author
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 单变量与多变量时间序列，作者提供的图像
- en: Above, based on the [**Walmart dataset**](https://www.kaggle.com/datasets/yasserh/walmart-dataset),
    you can see **single** and **multiple** time series. Nowadays, many problems involve
    multiple points at the same time. This data can come from a variety of processes,
    it can be this example and my daily work which is demand forecasting, but it can
    also be energy consumption forecasting, the closing price of a company on the
    stock market, the number of bicycles rented from a station and many many others
    problems.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，基于[**Walmart 数据集**](https://www.kaggle.com/datasets/yasserh/walmart-dataset)，你可以看到**单变量**和**多变量**时间序列。现在，许多问题涉及同时处理多个点。这些数据可以来自各种过程，可以是这个例子和我日常工作的需求预测，也可以是能源消耗预测、公司股市收盘价、从车站租用的自行车数量等等许多其他问题。
- en: In addition to the time series itself, we may also have other *variables* for
    them, some of which may be known for the future and others only available for
    the past — about that in a moment.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 除了时间序列本身，我们还可能有其他*变量*，其中一些可能已知未来值，而其他仅在过去可用——稍后会详细讲解。
- en: In this article, I want to show you different approaches for forecasting multiple
    time series, but I want it to be practical — so that you are not left with just
    theory. So let’s import all the libraries used later — darts and others well known
    by Data Scientists.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我想向你展示预测多个时间序列的不同方法，但我希望它是实用的——以便你不仅仅停留在理论层面。所以让我们导入所有后续使用的库——包括Darts和其他数据科学家熟知的库。
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now let’s load the dataset, which is about **demand forecasting** and comes
    from the [**Kaggle**](https://www.kaggle.com/competitions/demand-forecasting-kernels-only).
    If you agree with the terms of the competition on Kaggle then you can also download
    this dataset.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们加载数据集，这个数据集涉及**需求预测**，并来自[**Kaggle**](https://www.kaggle.com/competitions/demand-forecasting-kernels-only)。如果你同意Kaggle上的比赛条款，那么你也可以下载这个数据集。
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: There are 10 stores and in each of them are 50 items making a total of 500 time
    series.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 共有10家商店，每家商店有50种商品，总计500个时间序列。
- en: Let’s take a look at the 10 among the least, median, and most sold in total
    store-item combinations. To find what relations are in a time series it is often
    enough to look at it because this already tells us a lot, like a trend or seasonality,
    but often much more.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下在所有商店商品组合中销售最少、中等和最多的10种商品。要找出时间序列中的关系，通常只需观察它，因为这已经能告诉我们很多信息，比如趋势或季节性，但往往还有更多。
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/0c022ede1dbd871b535d8233bd4c8be8.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0c022ede1dbd871b535d8233bd4c8be8.png)'
- en: There is a lot of similarity between these time series. We’ll check for the
    existence of seasonality (day of the week or week/month of the year) or trend
    in a moment, but you can already intuitively imagine that model learning relationships
    from all time series will be able to forecast one single time series better than
    if it only learned from its history.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这些时间序列之间有很多相似性。我们将稍后检查是否存在季节性（周几或一年中的周/月）或趋势，但你可以直观地想象，从所有时间序列中学习的模型将比仅从其历史中学习的模型更好地预测单个时间序列。
- en: I create a copy of my dataset for **EDA** (exploratory data analysis). Then
    I scale the time series using **MinMAXScaler** and then all the time series will
    be comparable to each other. Finally, I create Box Plots with which I check if
    there is a trend and seasonality.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我为**EDA**（探索性数据分析）创建了数据集的副本。然后，我使用**MinMAXScaler**对时间序列进行缩放，使所有时间序列可以互相比较。最后，我创建箱型图，以检查是否存在趋势和季节性。
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/389fc7b02f361ab79d5cac60527593cc.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/389fc7b02f361ab79d5cac60527593cc.png)'
- en: Yes, there is a trend and two types of seasonality. If you think that these
    time series are easy to forecast —you are right. The purpose of this article is
    to show you the most popular approaches to forecasting multiple time series. The
    data is not always as easy as, for example, stock market indexes, but that’s a
    topic for another article.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，有趋势和两种季节性。如果你认为这些时间序列很容易预测——你是对的。本文的目的是向你展示预测多个时间序列的最流行的方法。数据并不总是像股票市场指数那样简单，但那是另一个话题。
- en: I think this exploration is enough to understand what relationships the model
    should learn.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这种探索足以理解模型应该学习哪些关系。
- en: Here we have **multiple time series** (sales of multiple items in multiple stores).
    For each **time series**, let’s create a **TimeSeries** object from a Pandas DataFrame.
    This type is required by models from the Darts library. Then save these time series
    in a **list**.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们有**多个时间序列**（多个商店中的多个商品销售）。对于每一个**时间序列**，我们从 Pandas DataFrame 中创建一个**TimeSeries**对象。这种类型是
    Darts 库中的模型所需的。然后将这些时间序列保存到**列表**中。
- en: '[PRE6]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Working with multiple time series can be helpful, but often it is problematic.
    When we have one time series then we have a lot of time to work with it. Look
    at it, verify the trend and seasonality, and transform anomalies. We can polish
    our Forecast. For multiple series this approach becomes impossible. We want the
    approach to be as automatic as possible, but then we may miss details, such as
    anomalies, or perhaps we should not process each time series in the same way.
    There may be more typical problems: missing data, data drift, and rare events
    (black swans). More series can potentially help us because our model will be able
    to use more data, and therefore there will be more representative observations
    for a particular pattern. Using my work as an example — to forecast the demand
    caused by a promotion for product X in the following week, our model can also
    use the historical effects of such a promotion from other promotions.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 处理多个时间序列可能很有帮助，但通常也会带来问题。当我们只有一个时间序列时，我们有很多时间来处理它。查看它，验证趋势和季节性，并处理异常。我们可以优化我们的预测。对于多个序列，这种方法变得不可行。我们希望方法尽可能自动化，但这样可能会错过细节，比如异常，或者我们不应该以相同的方式处理每个时间序列。可能还有更多典型的问题：缺失数据、数据漂移和稀有事件（黑天鹅事件）。更多的序列可能对我们有帮助，因为我们的模型可以使用更多的数据，因此会有更多的代表性观察数据来识别特定模式。以我的工作为例——为了预测产品
    X 在下周因促销造成的需求，我们的模型还可以利用其他促销的历史效果。
- en: Hence the question — how to forecast multiple time series?
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 所以问题来了——如何预测多个时间序列？
- en: You may often ask yourself *Do I have a* ***multiple*** *or* ***multivariate***
    *time series?*. These questions are legitimate and the answer is not always clear.
    When your time series are from a **single process**, are **interconnected**, **correlated,**
    and **interact** with each other then the answer will be *my time series are*
    ***multivariate***.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能经常会问自己*我是否有一个* ***多变量*** *或* ***多元*** *时间序列？* 这些问题是合理的，但答案并不总是明确的。当你的时间序列来自**单一过程**，**相互关联**、**相关**，并且**相互作用**时，答案将是*我的时间序列是*
    ***多元***。
- en: When you forecast sales of product X in **multiple stores** then you have a
    **multiple time series**, but when you have an additional product Y then for a
    single store you have a **multivariate time series**, because sales of one product
    in a store can **affect** sales of **another**, or it can affect — it was only
    an assumption.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在**多个商店**预测产品 X 的销售时，你有一个**多时间序列**，但当你有一个额外的产品 Y 时，对于单个商店来说，你有一个**多变量时间序列**，因为一个产品在商店中的销售可能**影响**另一个产品的销售，或者这只是一个假设。
- en: How to evaluate the forecast?
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何评估预测结果？
- en: Before we get into the different approaches and models, let’s discuss first
    how to measure the quality of a forecast. This is a regression problem, so we
    will still compare forecasts to true values, here there is no doubt. You can use
    metrics familiar to the regression problem, such as **RMSE**(*Root Mean Squared
    Error*), **MSE**(*Mean Squared Error*), **MAE**(*Mean Absolute Error*), or more
    typical time series metrics such as **MAPE**(*Mean Absolute Percentage Error*),
    **MARRE**(*Mean Absolute Ranged Relative Error*) or **MASE**(*Mean Absolute Scaled
    Error*). Further discussion will use **MAPE** as an evaluation metric. This article
    is not about demand forecasting, but because of the data and my experience, there
    are many references to it. So what metric to choose for that problem you can think.
    Always the metric should reflect the business objective. In this [*article*](/forecast-kpi-rmse-mae-mape-bias-cdc5703d242d),
    [Nicolas Vandeput](https://www.linkedin.com/in/vandeputnicolas/) described the
    metrics used for demand forecasting as KPIs.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入讨论不同的方法和模型之前，让我们先讨论如何衡量预测的质量。这是一个回归问题，因此我们仍然会将预测结果与真实值进行比较，这一点毫无疑问。你可以使用回归问题中熟悉的指标，如**RMSE**(*均方根误差*),
    **MSE**(*均方误差*), **MAE**(*平均绝对误差*)，或者更典型的时间序列指标，如**MAPE**(*平均绝对百分比误差*), **MARRE**(*平均绝对范围相对误差*),
    或**MASE**(*平均绝对缩放误差*)。进一步的讨论将使用**MAPE**作为评估指标。本文不是关于需求预测的，但由于数据和我的经验，有很多相关参考。因此，你可以考虑为该问题选择什么指标。始终选择能够反映业务目标的指标。在这篇[*文章*](/forecast-kpi-rmse-mae-mape-bias-cdc5703d242d)中，[Nicolas
    Vandeput](https://www.linkedin.com/in/vandeputnicolas/) 描述了需求预测中使用的 KPI 指标。
- en: We can extend this approach to multiple series and then calculate our metrics
    for all series at once or for each series separately and then aggregate them.
    So let’s move on to how to evaluate a single series. Then this can be extended
    to multiple.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这种方法扩展到多个序列，然后一次性计算所有序列的指标，或者分别对每个序列计算指标后再进行汇总。所以让我们继续探讨如何评估单个序列，然后再将其扩展到多个序列。
- en: Yes, this is a regression problem, you may wonder why I explain it. In time
    series, time plays a key role. The data are sorted relative to time, and the observations
    are relative to each other. Therefore, it is not possible to use randomization
    when dividing the training/test set and use cross-validation, because in this
    situation there would be data leakage.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，这是一个回归问题，你可能会想为什么我解释这一点。在时间序列中，时间扮演了关键角色。数据是相对于时间排序的，观测值是相互关联的。因此，分割训练/测试集并使用交叉验证时无法使用随机化，因为这样会导致数据泄漏。
- en: '![](../Images/d6eb56fa82acdc8a681e06625ce075fb.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d6eb56fa82acdc8a681e06625ce075fb.png)'
- en: Evaluation of the forecasting model, Image by Author
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 预测模型的评估，图像由作者提供
- en: First, divide the data into a **train** set and a **test** set, easy right?
    The model fits on the train set and tests on the test set. We can divide this
    proportionally, for example, the test set includes 20% of the last weeks, or indicate
    from which date the test set is to be — perhaps due to business considerations
    it is important that the test set is the last year.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，将数据分为**训练**集和**测试**集，很简单，对吧？模型在训练集上进行拟合，在测试集上进行测试。我们可以按比例划分，例如，测试集包括最后 20%
    的数据，或者指定测试集的起始日期——可能由于业务考虑，测试集为过去一年数据会更重要。
- en: In our example, the test set will be the last year.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，测试集将是最后一年。
- en: '[PRE7]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: From the **train** set, we separate **validation** subsets, which we use to
    select **hyperparameters**. For models implemented in Darts, we can use the *gridsearch*
    method, but for models based on neural networks, the [**Optuna**](https://optuna.org/)
    is recommended. The gridsearch method actually has everything we need and works
    the same regardless of which model we choose.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 从**训练**集分离**验证**子集，用于选择**超参数**。对于在 Darts 中实现的模型，我们可以使用*gridsearch*方法，但对于基于神经网络的模型，推荐使用[**Optuna**](https://optuna.org/)。gridsearch
    方法实际上具备了我们所需的一切，无论选择哪个模型都能正常工作。
- en: 'What’s important:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是：
- en: parameters ➜ a dictionary with hyperparameters to check
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: parameters ➜ 一个包含待检查超参数的字典
- en: series ➜ TimeSeries object or a list containing TimeSeries objects (if the algorithm
    is global)
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: series ➜ TimeSeries 对象或包含 TimeSeries 对象的列表（如果算法是全局的）
- en: start ➜ *Pandas Timestamp* defines when the first forecast will occur or *float*
    as the proportion of observations before the first forecast.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: start ➜ *Pandas Timestamp* 定义第一次预测发生的时间，或者 *float* 作为第一次预测之前观察值的比例。
- en: forecast_horizon ➜ number(*int*) of forecast horizons by the model.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: forecast_horizon ➜ 模型预测的时间范围数量（*int*）
- en: stride ➜ Offset between next predictions. To make everything in accordance with
    the art of Data Science and most reflect the actual operation of the algorithm
    then stride should be equal to 1\. But remember, after each step your algorithm
    is retrained and your grid of hyperparameters may have a lot of combinations,
    it often takes ages. Therefore, for common sense reasons, a stride can be higher
    than 1, especially since the purpose of this is to select the best hyperparameters
    and the result may (though not necessarily) be the same for a stride equal to
    1 as for a stride equal to 5.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: stride ➜ 下一次预测之间的偏移量。为了使一切符合数据科学的艺术，并最能反映算法的实际操作，stride 应该等于1。但请记住，在每一步之后你的算法都会重新训练，而且你的超参数网格可能有很多组合，这通常需要很长时间。因此，出于常识考虑，stride
    可以大于1，尤其是因为此目的在于选择最佳超参数，结果可能（但不一定）在 stride 等于1 时与 stride 等于5 时相同。
- en: metric ➜ function, which compares true values and predictions. The best hyperparameters
    are then selected based on this metric.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: metric ➜ 函数，用于比较真实值和预测值。然后根据这个指标选择最佳超参数。
- en: '[PRE8]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: So how to evaluate the model on the test set? We have 2 approaches.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 那么如何在测试集上评估模型呢？我们有两种方法。
- en: The **first** is that we fit our model on the train set and make one forecast
    that covers the test set. In the following examples, we will use this option —
    it is simply faster to calculate since we generate one forecast for each time
    series.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**第一种**方法是我们在训练集上拟合模型，并做一个覆盖测试集的预测。在以下示例中，我们将使用这个选项——计算速度更快，因为我们为每个时间序列生成一个预测。'
- en: The **second** approach is that we test different forecast horizons. We fit
    the model, make a forecast, retrain, make a forecast, and so on, but we have to
    start training the algorithm first before the end of the train set, and that’s
    so that we can compare horizons on the same data — we’re comparing apples to apples.
    If you were to start by training on the entire train set then the further horizons
    have fewer observations. In this method, we should retrain (especially in local
    models), so we definitely have more calculations in this approach.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**第二种**方法是我们测试不同的预测时间范围。我们拟合模型，做一个预测，重新训练，再做一个预测，以此类推，但我们必须在训练集结束之前开始训练算法，这样我们才能在相同的数据上比较时间范围——我们在比较相同的苹果。如果你从整个训练集开始训练，那么较远的时间范围有较少的观察值。在这种方法中，我们应该重新训练（特别是在局部模型中），因此这种方法中我们肯定会有更多的计算。'
- en: 'It’s also simple because the models in darts have the ability to return historical
    predictions according to the above visualization. You have already learned about
    some of the variables in the gridsearch method, which work the same here. However,
    there will be new variables here:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这也很简单，因为 darts 中的模型具有根据上述可视化返回历史预测的能力。你已经学习了一些在 gridsearch 方法中使用的变量，这些变量在这里也适用。然而，这里会有新的变量：
- en: retrain ➜ if equal to *True*, then after each step the model is retrained, which
    best reflects reality.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: retrain ➜ 如果等于 *True*，则在每一步之后模型会重新训练，这最能反映现实情况。
- en: overlap_end ➜ if equal to *True*, then the predictions may extend beyond the
    dates in the test set. Useful if, we are doing a forecast for several horizons
    and the farther ones are beyond the test set and the closer ones are not.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: overlap_end ➜ 如果等于 *True*，则预测可能超出测试集中的日期。如果我们对多个时间范围进行预测，而较远的时间范围超出测试集，而较近的时间范围不超出，这样的设置很有用。
- en: last_points_only ➜ if equal to *False*, then the forecast for all horizons is
    returned.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: last_points_only ➜ 如果等于 *False*，则返回所有时间范围的预测。
- en: '[PRE9]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: However, we want to take forecasts from the interested us horizon, and in the
    variable backtests_results, there are forecasts from different points in time.
    To take forecasts from the specific horizon then you can use my function *take_backtest_horizon*.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们希望从感兴趣的时间范围中获取预测，并且在变量 backtests_results 中，有来自不同时间点的预测。要从特定的时间范围中获取预测，你可以使用我的函数
    *take_backtest_horizon*。
- en: backtests_5W ➜ there are forecasts for each point of the test set that were
    made 5 weeks earlier.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: backtests_5W ➜ 有针对测试集每个点的预测，这些预测是在5周前做出的。
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Variables used
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的变量
- en: In fact, the time series themselves are not fully explainable by themselves.
    Often, time series are dependent on other variables. Here we don’t have them,
    but good to know how to distinguish them when they will appear in your projects.
    If we do not inform the model about an upcoming promotion/lower price then it
    will not be able to forecast increased sales. If you want to forecast the change
    in the price of a stock company, helpful can be added variables from technical
    or fundamental analysis. These variables are dependent on the price, that is,
    you can only know these indicators for the past, after all, we do not know the
    company’s financial reports in the future or its price — we want to forecast it
    :)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，时间序列本身并不能完全自我解释。时间序列通常依赖于其他变量。这里我们没有这些变量，但了解如何在项目中遇到这些变量时进行区分是很有帮助的。如果我们没有通知模型即将到来的促销/降价，那么它将无法预测销售额的增加。如果你想预测股票公司的价格变化，添加来自技术分析或基本面分析的变量可能会有所帮助。这些变量依赖于价格，即你只能知道这些指标的过去值，毕竟，我们无法知道未来的公司财务报告或价格——我们希望进行预测
    :)
- en: '![](../Images/fdfdefebca39dab3d6d4fc34c837df1a.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fdfdefebca39dab3d6d4fc34c837df1a.png)'
- en: Variables used by algorithms for time series, Image by Author
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列算法使用的变量，图源作者
- en: We can have variables that are also time series, that is, for different points
    in time they have different values, and we can have **static covariates** (constant
    over time), usually categorical variables. In our example that will be store ID
    and item ID. They are very relevant to global models. Because in 1 out of 100
    time series, you may have different relationships, and thanks to this variable
    your model can distinguish between time series.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以有也是时间序列的变量，即在不同时间点有不同的值，同时我们也可以有**静态协变量**（随时间保持不变），通常是分类变量。在我们的例子中，这将是商店ID和商品ID。它们对全局模型非常重要。因为在每100个时间序列中，可能会有不同的关系，借助这些变量，你的模型可以区分不同的时间序列。
- en: As for variables that are time series, we can distinguish between **covariates**
    that are also **known for the future** (for example we can know what the promotional
    mechanisms are in the future and also we know them for the past) and **covariates
    known only for the past** (we can know what price competing products had, but
    we do not know what they will have in the future).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 至于时间序列变量，我们可以区分**协变量**，其中有些**已知未来**（例如，我们可以知道未来的促销机制，也知道过去的促销机制）和**仅已知过去的协变量**（我们可以知道竞争产品的价格，但不知道它们未来的价格）。
- en: Models used
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的模型
- en: '![](../Images/dd185e633c9b5ffbdd0e2c15162d7077.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dd185e633c9b5ffbdd0e2c15162d7077.png)'
- en: Local vs Global algorithms, Image by Author
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 局部算法与全局算法对比，图源作者
- en: We can separate machine learning into supervised learning, unsupervised learning,
    and reinforcement learning. When we get into the details, we can divide supervised
    learning into regression and classification. We can make a similar split for time
    series forecasting, which is using **local** or **global** algorithms to forecast
    these time series.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将机器学习分为监督学习、无监督学习和强化学习。进入详细内容后，我们可以将监督学习分为回归和分类。我们可以对时间序列预测进行类似的划分，即使用**局部**或**全局**算法来预测这些时间序列。
- en: The **local algorithm** is fitted on a **single time series**, and only this
    time series can the model predict. More time series mean more models. Here we
    see pros and cons, simple models, but for many time series, this approach becomes
    difficult to maintain.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**局部算法**是针对**单一时间序列**进行拟合的，模型仅能预测这一时间序列。更多的时间序列意味着更多的模型。在这里我们看到优缺点，模型简单，但对于许多时间序列来说，这种方法变得难以维护。'
- en: The **global algorithm**, on the other hand, is that **one model** can be fitted
    on **multiple time series**. So if we have **multiple time series** then we can
    have **one** model that can forecast them all. This approach is definitely more
    flexible, for example, you could use Transfer Learning. For time series it means
    that you fit the model on a different time series than you are making the prediction.
    [Here](https://unit8co.github.io/darts/examples/14-transfer-learning.html) is
    an example of this usage. One more important point related to global models, because
    I could forget it later and it is really important — that is, **time series scaling**.
    The most common approach is *MinMaxScaler*, but you can use something more specific
    for your data. Nevertheless, I’m not going to write here how you can scale time
    series, that’s definitely a topic for another article. Let’s consider why we should
    scale our time series. The answer may be simple, many global algorithms are neural
    networks and it is a reason why we scale data, as we do with pixels for convolutional
    neural networks. However, this is not the full picture. However, we can use a
    model like Random Forest (nonparametric models) and we still should scale them.
    But STOP, why? After all, for these types of models, you don’t need to scale the
    variables. The reason we should scale the time series is so that the model learns
    the relationship, not the scale, for example, for seasonality such a relationship
    might be that in the summer months, the value is on average 150% higher than in
    the winter months. Another example would be that after 3 significant increases
    are followed by a decrease. It is difficult to learn these relationships by the
    model if we do not scale time series. This is a slightly different approach to
    scaling a variable for tabular data because here we scale each time series separately.
    If we use the mentioned *MinMaxScaler* then for each time series from the train
    set the maximum value is 1\. So let’s scale our data, which will be used by global
    models.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In a moment you will read about the most popular **local** and **global** algorithms.
    It is impossible to describe all possible algorithms, but there are a few that
    are often used by specialists and usually meet expectations.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: No free lunch theorem
  id: totrans-95
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: There is no answer — this model is the best, do not use others. Nevertheless,
    if you are creating an MVP — it is best to start with something simple.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: In the following examples, I do not choose the best hyperparameters on validation
    sets, I use default models. So if you write to me that the model may have better
    results — **I already agree with you**.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Local models
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we move on to specific local models, I have prepared functions for you
    to use multiprocessing for faster calculations using all Cores.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: I am going to use this function for local models to generate a single prediction
    for the test set. Also, you can use it to generate multiple historical forecasts
    (the second approach, variable ***single_forecast*** should be ***False***). Nevertheless,
    I do not do that here, because it would take a lot of time.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: If you use Cluster and Spark then you can use Spark UDF and speed up the calculations
    significantly.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: I know, you probably want to move to the models part. Last but not least — a
    function to evaluate our forecasts. I am going to use **MAPE** as a metric for
    evaluation, however, if you work on a demand forecasting project then WMAPE or
    MAE is definitely closer to business expectations.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Baseline
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Well, okay, but why make a neural network if a better idea is to forecast the
    value from a year ago? That’s exactly why we create such a model first. When you
    work with real data, you’d better start with such an approach too (it can also
    be the last value from the training set, NaiveDrift if there’s a trend or a combination
    of several simple methods). Then if you move on to more advanced methods you can
    evaluate how much better it is than the simpler ones, because if, for example,
    you start with a neural network and its MAPE is 10% then my question (probably
    also stakeholders) is — *Is it good?*
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Our models(one ts=one model) below will repeat the value from a year ago.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '**overall MAPE: 22.42%**'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s visualize the forecast and true value on a test set for time series
    with the highest total sales.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7c37de66f2d835d976d5c5f681f16803.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
- en: It doesn’t look too bad.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: ARIMA
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/3c037dbaa86cd65df7dd14078eb1c315.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
- en: Visualize how the ARIMA algorithm works, Image by Author
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '**ARIMA** is a statistical model, both popular and powerful in its simplicity.
    When you hear **ARIMA** it can mean this one model but also a collection of models
    that are extensions of just **ARIMA**. For this collection, we can include **ARIMAX**
    (takes into account additional variables), **SARIMA** (takes into account seasonality),
    or **VARIMA** (for multivariate time series). But let’s go back to **ARIMA** (**A**uto**R**egressive
    **I**ntegrated **M**oving **A**verage), which is where it all starts. If you understand
    it well then you should have no problem using the mentioned before models.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Many articles have already been written about this algorithm. I would like to
    give you the intuition behind this model. I hope after all you will easily implement
    it in code and understand how it works. I am going to start from the end. I myself
    remember having a question about this during recruitment and at the time I didn’t
    understand it yet. The **ARMA model can only work with stationary time series**,
    so we have a component — **Integration** (**I**), which often (not always) **transforms
    a non-stationary into a stationary time series**. **ARMA** is the model, while
    **I** part is responsible for preparing the data for modeling, if necessary of
    course. There are a few questions you should know the answer to them, what it
    means that a time series is stationary or not, and what kind of transformation
    the **Integration** (**I**) component makes. So let’s start with stationarity.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 许多文章已经对此算法进行了阐述。我想给你这个模型背后的直观理解。我希望最终你能轻松地在代码中实现它，并理解它是如何工作的。我打算从最后开始。我自己记得在招聘过程中有过一个关于这个问题的疑问，当时我还没有理解它。**ARMA模型只能与平稳时间序列一起使用**，因此我们有一个组件——**积分**（**I**），它通常（但不总是）**将非平稳时间序列转换为平稳时间序列**。**ARMA**是模型，而**I**部分负责为建模准备数据（当然，如果需要的话）。你应该知道几个问题的答案，那就是时间序列平稳或非平稳的含义，以及**积分**（**I**）组件进行的转换类型。所以让我们从平稳性开始。
- en: If the distribution of values (mean and variance) is invariant over time then
    the time series is stationary.
  id: totrans-118
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果值的分布（均值和方差）在时间上是不变的，那么时间序列就是平稳的。
- en: Therefore, if there is a trend and/or seasonality then a time series is non-stationary.
    To check whether your time series is stationary then the simplest method is to
    visualize it and on the graph also add the moving average and moving standard
    deviation. If they are constant over time (or close to constant) then you can
    conclude that your time series is stationary. This approach may seem naive and
    doesn’t always work, because given too large a window into the rolling statistics
    you may think your time series is stationary, when in fact it is not. Another
    way is to split your time series into random partitions, for each partition calculate
    the mentioned statistics. The last method is to calculate the **A**ugmented **D**ickey-**F**uller
    (**ADF**) test. What if our time series is not stationary and we need to use the
    **Integration** (**I**) component? It makes the time series stationary (but not
    always, there are time series that can’t be stationary) using **differencing**,
    that is, calculating the differences between observations. What if our time series
    isn’t still stationary? We can select order **d**, which means how many times
    we are differencing time series.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果存在趋势和/或季节性，那么时间序列就是非平稳的。要检查时间序列是否平稳，最简单的方法是将其可视化，并在图上添加移动平均和移动标准差。如果它们随时间保持不变（或接近不变），那么你可以得出你的时间序列是平稳的结论。这种方法可能显得天真，并且并不总是有效，因为如果对滚动统计数据使用过大的窗口，你可能会认为时间序列是平稳的，而实际上并非如此。另一种方法是将时间序列拆分成随机分区，对每个分区计算上述统计数据。最后一种方法是计算**扩展的迪基-福勒**（**ADF**）检验。如果我们的时间序列仍然不是平稳的，我们需要使用**积分**（**I**）组件怎么办？它通过**差分**来使时间序列平稳，即计算观察值之间的差异。如果我们的时间序列仍然不是平稳的呢？我们可以选择**d**的阶数，这表示我们对时间序列进行差分的次数。
- en: This long fragment was about **Integration** (**I**) which prepares data that
    will be used by the **Autoregressive** (**AR**) and **Moving Averag**e (**MA**)
    components. **AR** is a linear regression of the last **p** values, known as lags.
    The current value is correlated with and dependent on the last values. **MA**
    is complementary and takes into account the **q** last errors in the forecast
    (assumed to be white noise) to better forecast the current point in time.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这个长段落是关于**积分**（**I**），它准备数据以供**自回归**（**AR**）和**移动平均**（**MA**）组件使用。**AR**是对最后**p**个值的线性回归，这些值被称为滞后。当前值与最后的值相关联，并且依赖于这些值。**MA**是补充性的，考虑了预测中**q**个最后的误差（假设为白噪声），以更好地预测当前的时间点。
- en: To select the order **p** for **AR** we use [**PACF**](https://en.wikipedia.org/wiki/Partial_autocorrelation_function)
    (**P**artial **A**uto**C**orrelation **F**unction), while to select the order
    **q** for **MA** we use [**ACF**](https://en.wikipedia.org/wiki/Autocorrelation)
    (**A**uto**C**orrelation **F**unction). Outside of university classes, we are
    unlikely to do this in practice because we have [**AutoARIMA**](https://unit8co.github.io/darts/generated_api/darts.models.forecasting.auto_arima.html)
    which selects the **p**, **d**, and **q** for us.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 选择**AR**的阶数**p**时，我们使用[**PACF**](https://en.wikipedia.org/wiki/Partial_autocorrelation_function)（**P**artial
    **A**uto**C**orrelation **F**unction），而选择**MA**的阶数**q**时，我们使用[**ACF**](https://en.wikipedia.org/wiki/Autocorrelation)（**A**uto**C**orrelation
    **F**unction）。在大学课程之外，我们在实际操作中不太可能这样做，因为我们有[**AutoARIMA**](https://unit8co.github.io/darts/generated_api/darts.models.forecasting.auto_arima.html)可以为我们选择**p**、**d**和**q**。
- en: Let’s go back to practice and implement in a similar way as we did with the
    Baseline model. As you might have read earlier thanks to the Darts library it
    is simple.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到实践中，按照与基线模型相似的方式来实现。正如你可能已经了解到的，由于 Darts 库，这个过程非常简单。
- en: '[PRE15]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '**overall MAPE: 28.18%**'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**总体 MAPE: 28.18%**'
- en: '[PRE16]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![](../Images/31546af743b6b1fa56efe95d9cdccb78.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/31546af743b6b1fa56efe95d9cdccb78.png)'
- en: It would probably look better if I chose the parameter *m* (The period for seasonal
    differencing). You can try it and give me feedback about how the results changed.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我选择参数*m*（季节性差分的周期），结果可能会更好。你可以尝试一下，并告诉我结果的变化情况。
- en: Exponential smoothing
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指数平滑
- en: '![](../Images/8cd796b93178f570b18ddeb944b0474a.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8cd796b93178f570b18ddeb944b0474a.png)'
- en: Visualize how the Exponential Smoothing (ETS) algorithm works, Image by Author
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化指数平滑（ETS）算法的工作原理，图片由作者提供
- en: '**Exponential smoothing** is another **family** of similar models for univariate
    time series. You can find ‘this family’ under the term **ETS** (**E**-Error, **T**-Trend,
    **S**-Seasonal). In this method, observations are weighted, for older observations
    are lower weights, because they decrease exponentially. We can distinguish between
    three types, a simple one that assumes the future will be similar to recent values,
    an extension that handles the trend, and the last one that also handles seasonality.
    I am going to describe these three types in a moment, but a small aside now. In
    the **M**-4 **Competition** ([Makridakis Competitions](https://en.wikipedia.org/wiki/Makridakis_Competitions),
    the most well-known competition for time series forecasters) Slawek Smyl won,
    he proposed [**ES-RNN**](https://www.sciencedirect.com/science/article/abs/pii/S0169207019301153),
    which is a hybrid between **E**xponential **S**moothing and **R**ecurrent **N**eural
    **N**etwork.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '**指数平滑**是另一种用于单变量时间序列的**模型家族**。你可以在术语**ETS**（**E**-误差，**T**-趋势，**S**-季节性）下找到“这个家族”。在这种方法中，观察值被赋予权重，较旧的观察值权重较低，因为它们按指数衰减。我们可以区分三种类型：一种简单的类型假设未来将类似于近期值，一种扩展类型处理趋势，最后一种还处理季节性。我将会在稍后描述这三种类型，不过现在先插一个小插曲。在**M**-4
    **比赛**（[Makridakis 比赛](https://en.wikipedia.org/wiki/Makridakis_Competitions)，这是最著名的时间序列预测比赛）中，Slawek
    Smyl 获胜，他提出了[**ES-RNN**](https://www.sciencedirect.com/science/article/abs/pii/S0169207019301153)，这是**指数平滑**与**递归神经网络**的混合体。'
- en: Now we’re back to the topic and the first type, which is **Simple Exponential
    Smoothing**. As a Baseline model, we can choose a model that always predicts the
    last value from the training set, a bit naive approach but can give us good results.
    Another approach could be to calculate the average of the whole training set,
    but then the same importance is given to the recent as the oldest observation.
    Exponential Smoothing is a combination of these two approaches, where greater
    weights are assigned to the most recent observations. They decrease exponentially
    for older observations, meaning the oldest ones will have the smallest weights.
    It uses an **α** parameter, its range is between 0 and 1\. The higher the value
    is the greater the impact of the latest values on the prediction. Please take
    a look at the above graphic, where the formulas are also. They are really easy
    to understand and often these models give good results. Before we move on to more
    advanced models we should stop here for a moment, because if a simple model gives
    the same results as very advanced models (for example, deep neural networks) then
    we should stay with the simpler ones, because their operation is more predictable
    for us and once again, more people are able to understand their operation.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们回到话题的第一个类型，即**简单指数平滑**。作为基线模型，我们可以选择一个总是预测训练集中的最后一个值的模型，这是一种稍显天真的方法，但可以给我们带来不错的结果。另一种方法是计算整个训练集的平均值，但这样的话，最近的观察值和最古老的观察值会被赋予同等的重要性。指数平滑结合了这两种方法，赋予最近的观察值更大的权重，权重会随着观察值的古老程度呈指数下降，这意味着最古老的观察值将拥有最小的权重。它使用**α**参数，其范围在0到1之间。值越高，最新值对预测的影响越大。请查看上面的图形，那里也有公式。这些公式非常容易理解，通常这些模型能给出不错的结果。在我们进入更高级的模型之前，我们应该在这里稍作停留，因为如果一个简单的模型给出的结果与非常先进的模型（例如深度神经网络）相同，那么我们应该保持使用更简单的模型，因为它们的操作对我们来说更可预测，并且更多的人能够理解它们的运作。
- en: SES doesn’t handle a trend in data by the nature of the formula. If there is
    an increasing trend then the forecast underestimates because it doesn’t include
    this increase in the data. Therefore, we have another model, which is **Double
    Exponential Smoothing**. It has an additional factor that is responsible for taking
    into account the impact of the trend. We use the **β** parameter, which controls
    the impact of the trend change. Hence we have 2 formulas, one for **level** (Level
    equation) and the other for **trend** (Trend equation).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: SES本质上无法处理数据中的趋势。如果存在上升趋势，则预测会低估，因为它没有包含这种增加。因此，我们有另一种模型，即**双重指数平滑**。它有一个额外的因素，用于考虑趋势的影响。我们使用**β**参数，它控制趋势变化的影响。因此我们有两个公式，一个用于**水平**（水平方程），另一个用于**趋势**（趋势方程）。
- en: The **Triple Exponential Smoothing** also takes into account seasonality. You
    can know it as Holt-Winters’ seasonal method. Here another parameter, **γ**, comes
    into the formula. This method allows changing the **level**, **trend**, and patterns
    of **seasonality** over time. Like a trend, seasonality can be additive or multiplicative,
    but here I am not going to describe details assuming that you know the difference
    or can easily find them. I just don’t want to make a book out of this article
    now, and I want you to smoothly go through the whole article. 😉
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**三重指数平滑**也考虑了季节性。你可以将它称为Holt-Winters的季节性方法。这里另一个参数**γ**进入了公式。这种方法允许**水平**、**趋势**和**季节性**的模式随时间变化。像趋势一样，季节性可以是加法的或乘法的，但在这里我不会描述详细信息，假设你知道区别或可以轻松找到它们。我只是不想把这篇文章写成一本书，现在我希望你能顺利阅读整个文章。😉'
- en: '[PRE17]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '**overall MAPE: 31.88%**'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '**总体MAPE: 31.88%**'
- en: '[PRE18]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![](../Images/caee69055bc0f0fa97677781373db3dd.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/caee69055bc0f0fa97677781373db3dd.png)'
- en: As for ARIMA, I did not add seasonality information. Now is your step, add this
    information using the *seasonal_periods* parameter for [**Exponential Smoothing**](https://unit8co.github.io/darts/generated_api/darts.models.forecasting.exponential_smoothing.html).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 至于ARIMA，我没有添加季节性信息。现在轮到你了，使用*seasonal_periods*参数为[**指数平滑**](https://unit8co.github.io/darts/generated_api/darts.models.forecasting.exponential_smoothing.html)添加这些信息。
- en: Prophet
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Prophet
- en: '![](../Images/b90f59872f2815910c9764bd0a782d1e.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b90f59872f2815910c9764bd0a782d1e.png)'
- en: Visualize how the Prophet algorithm works, Image by Author
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化Prophet算法的工作原理，作者提供的图片
- en: '[**Prophet**](https://facebook.github.io/prophet/) was proposed in the [*Forecasting
    at scale*](https://peerj.com/preprints/3190.pdf) paper from 2017 by Facebook.
    It is both a model and a library by the same name. Like the previous models, you
    will find this one at Darts. This algorithm is a **G**eneralized **A**dditive
    **M**odel, so the forecast is the sum of components. These components are **g(*t*)**
    — trend, **s(*t*)** — seasonality (yearly, weekly, and daily), and **h(*t*)**
    — the effect of holidays.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: y(t) = g(t) + s(t) + h(t) + error(t)
  id: totrans-144
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The first one is the **trend**, it can change over time and doesn’t have to
    be constant over time. When students start learning classes with analyzing time
    series, they usually work with simple time series. In a time series, they can
    see a continuous growth trend. However, in real data, the trend can change several
    times. Prophet has implemented **changepoints** (think of them as a hyperparameter,
    such as their number, range, and prior scale). These points are trend changes,
    for example, increase trend -> changepoint -> decrease trend -> changepoint ->
    stronger decrease trend, and so on. This approach is closer to what we can usually
    see in the data. Positions of these changepoints Prophet set behind of you. The
    trend function between changepoints can be a simple regression.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Next, we have the **seasonality** function which is the **Fourier series**.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Another function is the **holiday** effect, which adds or subtracts value to
    our forecast. You can use the dates that the Prophet library provides or define
    your own events. You can imagine that the Black Friday effect significantly affects
    the value of sales. In addition, you can take into account the range around the
    date where the holiday affects the forecast, for example, Christmas does not affect
    sales on the day of the holiday, but the days before (many days).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '**overall MAPE: 14.38%**'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![](../Images/ca2b1293788c97c73332b2ec77cf20ed.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
- en: Global models
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now let’s turn to the approach where we have one model for all time series.
    This is also known as **cross-learning**, because the model to make a good prediction
    of time series A learned the relationships from time series A and also B, C, D,
    etc.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Supervised Model ~ Time Series as a regression problem
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/1044de425c3f4a039c506ed1ec58736c.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
- en: Visualize How to create features for a supervised learning model, Image by Author
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s try to apply supervised learning models to time series forecasting.
    This is nothing new, but they often give great results and are better than neural
    networks (see the best solutions from M-5 Competition). However, regression models
    are not dedicated to time series, so if we want to use them we need to **convert
    the time series problem into a machine learning problem**. I wrote more about
    this in my previous article [**Sell Out Sell In Forecasting**](/sell-out-sell-in-forecasting-45637005d6ee),
    but I will also now describe how to use the well-known regression algorithms for
    this problem.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Before I start with the previously mentioned transformation, we first need to
    **scale** the data. Earlier I described the need for this transformation for global
    models. In this case, I used *MinMaxScaler*.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: The next step is **feature engineering**, which is the transformation that was
    repeated several times. Based on the history of the time series, we create features
    that will help the model better forecast the future. These variables can refer
    to the recent history of selected time series, such as **lagged** values (for
    weekly data t-1W, t-2W, t-3W, and so on). Another example is the calculation of
    **rolling statistics**, median (it can be a median of the recent 4 weeks), mean,
    min, max, std, and whatever you are going to calculate on the window. If there
    is **seasonality** in the data then it is good to give the model a hint as to
    where in time the t is. I often use the **sin and cos of a cyclic variable** (in
    the above visualization it is a day of the year and a day of the week).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: The last step is to choose a **model**, you have a wide range of choices, so
    it can be Linear regression, Linear mixed effect model, Random Forest, LightGBM,
    and much more. The choice of model depends on the nature of the time series and
    the complexity of the problem. Another question might be if you want one model
    or as many models as horizons. When you choose a model then you need to keep in
    mind its weaknesses. For example, when you choose Random Forest then remember
    that the leaf counts the mean, so it can’t go beyond the training range. LightGBM
    doesn’t have this problem because it doesn’t count a naive mean, but regression
    is counted in the background.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Now it’s time again to return to the practical part and implement the model
    in code. I chose [**LightGBM**](https://lightgbm.readthedocs.io/en/v3.3.2/) as
    the model. Using it in Darts is much easier than in a similar way I would like
    to use it without this library. As you can see in the code we are using the lags
    of the last 14 days. I also added encoders that add covariates used by the model
    and they are added automatically and everything counts inside.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '*cyclic* — adds 2 columns, sin cos encoding based on cyclic variable, here
    month'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*datetime_attribute* — adds scalar based on datetime variable'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*position* — adds the relative index positions as integer values based on time
    series index, where 0 is set at the forecasting point.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*position* — 基于时间序列索引，将相对索引位置添加为整数值，其中0设置在预测点。'
- en: '[PRE21]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '**overall MAPE: 15.01%**'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '**总体MAPE: 15.01%**'
- en: '[PRE22]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![](../Images/45a39d49094bcdf9d257b90ae08828b8.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/45a39d49094bcdf9d257b90ae08828b8.png)'
- en: The results are really promising especially since this is one model for all
    time series. However, I would like to warn you based on my experience. These types
    of models work well based on feature engineering, which is an advantage and a
    big disadvantage. Suppose you are using lags and moving mean. You are now going
    to forecast the value of one of the time series, but you have anomalies in it
    — several large values before the forecast point. Your model will definitely overestimate.
    When you create variables then try to imagine what effect they will have on the
    model.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 结果非常有前景，尤其是因为这是一个适用于所有时间序列的模型。然而，基于我的经验，我想提醒你。这些类型的模型在特征工程上表现良好，这既是优势也是大缺陷。假设你使用了滞后和移动平均。现在你将预测一个时间序列的值，但它中有异常值——在预测点之前有几个大值。你的模型肯定会高估。当你创建变量时，尽量想象它们对模型的影响。
- en: DeepAR
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DeepAR
- en: '![](../Images/ed577969a790507e6cbac998587cca53.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ed577969a790507e6cbac998587cca53.png)'
- en: Screenshot of arxiv and model architecture, based on Paper
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 基于论文的arxiv和模型架构的截图
- en: '[**DeepAR**](https://arxiv.org/abs/1704.04110) is a deep learning algorithm
    developed by Amazon team. It is designed to model the complex dependencies and
    relationships in time series data using recurrent neural networks (RNNs).'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '[**DeepAR**](https://arxiv.org/abs/1704.04110) 是由Amazon团队开发的一种深度学习算法。它旨在使用递归神经网络（RNNs）对时间序列数据中的复杂依赖关系进行建模。'
- en: 'As we can read in Abstract (which is very close to me):'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在摘要中阅读到的（这与我非常接近）：
- en: In retail businesses, for example, forecasting demand is crucial for having
    the right inventory available at the right time at the right place.
  id: totrans-175
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 例如，在零售业务中，预测需求对于在正确的时间和地点提供合适的库存至关重要。
- en: The model is autoregressive and generates a probabilistic forecast using Monte
    Carlo samples. The NN architecture is based on the LSTM layer. With a probabilistic
    approach, we are not interested in a single good prediction, but rather in the
    full predictive distribution of where the true value can be found. Instead of
    using LSTMs to calculate predictions directly, DeepAR leverages LSTMs to parameterize
    a Gaussian likelihood function. That is, to estimate mean and standard deviation
    of the Gaussian function (θ = (μ, σ) parameters).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型是自回归的，并使用蒙特卡洛样本生成概率预测。神经网络架构基于LSTM层。通过概率方法，我们不关心单一的良好预测，而是整个预测分布，来确定真实值可能出现的位置。DeepAR不是直接使用LSTMs进行预测，而是利用LSTMs来参数化高斯似然函数。即，估计高斯函数的均值和标准差（θ
    = (μ, σ) 参数）。
- en: DeepAR supports Future-known covariates, we don’t have such, but let’s create
    them. As these features, I created OHE with the day of the week and the month.
    Probably a better approach would be sin and cos, I encourage you to experiment
    and return to me with your feedback.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: DeepAR支持未来已知协变量，我们没有这样的数据，但可以创建它们。作为这些特征，我创建了带有星期几和月份的独热编码（OHE）。可能更好的方法是使用正弦和余弦函数，我鼓励你进行实验，并将反馈意见告诉我。
- en: '[PRE23]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '**overall MAPE: 19.35%**'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '**总体MAPE: 19.35%**'
- en: '[PRE24]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![](../Images/5e2d94c8d9ccdbe19449ff4fab8ce6c4.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5e2d94c8d9ccdbe19449ff4fab8ce6c4.png)'
- en: N-BEATS
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: N-BEATS
- en: '![](../Images/86f2949104c8355bd78ad466b50eea5f.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/86f2949104c8355bd78ad466b50eea5f.png)'
- en: Screenshot of arxiv and model architecture, based on Paper
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 基于论文的arxiv和模型架构的截图
- en: '[**N-BEATS**](https://arxiv.org/abs/1905.10437) (Neural basis expansion analysis
    for interpretable time series forecasting) is a deep learning algorithm, but it
    doesn’t include recurrent layers, such as LSTM or GRU.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '[**N-BEATS**](https://arxiv.org/abs/1905.10437)（用于可解释时间序列预测的神经基础扩展分析）是一种深度学习算法，但它不包含递归层，如LSTM或GRU。'
- en: The architecture may seem complex, but once you get into the details it is quite
    simple and is a combination of blocks and all layers are feed forward.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 架构可能看起来复杂，但一旦你深入了解细节，它实际上非常简单，是由块组合而成，所有层都是前馈的。
- en: Let’s start with the smallest element, the block, each of them has one input
    and generates two outputs. The input is lockback period. Outputs are the forecast
    and the backcast. I think the idea of forecast is easy for you. Backcast is prediction,
    but for lockback period — it is fitted value and show how well block has relationship
    on the lookback period window.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: Let’s move on to stacks, or the combination of multiple blocks. As you read,
    each block has two outputs and one input. The next blocks are responsible for
    forecasting residuals — similar to what happens in boosting forest models, like
    AdaBoost. In each step, the backcast generated by the block is subtracted from
    the input of the block before. At the end, all forecasts from blocks are aggregated.
    In addition, it is an interpretable model, you can decompose and see the effect
    of trend and seasonality.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s move on to the combined stacks. This part increases the depth of the
    model and provides an opportunity to learn more about complexity.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '**overall MAPE: 13.18%**'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![](../Images/0a61c6e32b3eb36bc2e90b0ce40b9973.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
- en: TFT
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/341ef264d69b65087f3d9ac99030c59b.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
- en: Screenshot of arxiv and model architecture, based on Paper
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '[**Temporal Fusion Transformers**](https://arxiv.org/abs/1912.09363) (TFT)
    is a deep learning algorithm developed by Google for time series forecasting.
    It is designed to model the complex dependencies and relationships in time series
    data using a combination of transformer networks and autoregressive modeling.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: TFT is the most complex architecture and uses various techniques underneath.
    It is like an onion, composed of many layers. Also based on my experience, it
    learns the longest time compared to the above models. TFT uses a multi-head attention
    block to find long-time patterns, but LSTM sequence-to-sequence encoders/decoders
    to find these shorter patterns.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '**overall MAPE: 13.37%**'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![](../Images/d7ca8f7f8ffb0cd88937b1b5bc969e2d.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
- en: Summary
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article, I wanted to show you what approaches you can choose to forecast
    multiple time series. I have provided you with fully practical code, feel free
    to use them and don’t hesitate to write to me.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: 'This was just an introduction to the topic. I think also relevant from the
    work of Data Scientists for Supply Chain companies are the following topics:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '- **Hierarchical forecasting** and then combining forecasts from different
    hierarchies, i.e. Hierarchical Reconciliation. We can make a forecast at the store
    level and also at the country level, but when we aggregate the forecast at the
    store level then as a sum we would like to get the same thing that the forecast
    at the country level shows. That is why Hierarchical Reconciliation is important.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '- Another topic is **inventory optimization**, i.e. how many products we should
    have in stock so that we don’t have a situation where we don’t have our products
    in stock, but on the other hand, we don’t stock one product for months.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: Questions?
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/21d1e065cb242a0fd6cb114ae9823fec.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/21d1e065cb242a0fd6cb114ae9823fec.png)'
- en: Questions, Image by Author
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 问题，图片由作者提供
- en: I am aware that I have touched on many topics in this article. I wanted to give
    you an indication of the directions you can take. Perhaps some of them should
    be described in more detail here and others described in detail in a new article.
    Do not hesitate and write to me, **you can find me on** [**Linkedin**](https://www.linkedin.com/in/bartosz-szablowski/).
    In future articles, I would like them to cover detailed topics and show you how
    to implement models for time series from scratch using PyTorch library.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我意识到在这篇文章中我触及了许多主题。我想给你一个可以采取的方向的指示。也许其中一些应该在这里更详细地描述，而其他的则在新文章中详细描述。请不要犹豫，**你可以在**
    [**Linkedin**](https://www.linkedin.com/in/bartosz-szablowski/) **找到我**。在未来的文章中，我希望它们能够涵盖详细的主题，并展示如何使用
    PyTorch 库从头开始实现时间序列模型。
- en: THANKS FOR YOUR TIME!
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢你的时间！
- en: 'Dataset source:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集来源：
- en: misc{demand-forecasting-kernels-only,
  id: totrans-214
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 杂项{仅限需求预测内核，
- en: author = {inversion},
  id: totrans-215
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 作者 = {inversion},
- en: title = {Store Item Demand Forecasting Challenge},
  id: totrans-216
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 标题 = {商店商品需求预测挑战},
- en: publisher = {Kaggle},
  id: totrans-217
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 出版商 = {Kaggle},
- en: year = {2018},
  id: totrans-218
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 年份 = {2018},
- en: url = {https://kaggle.com/competitions/demand-forecasting-kernels-only},
  id: totrans-219
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 网址 = {https://kaggle.com/competitions/demand-forecasting-kernels-only},
- en: license=CC
  id: totrans-220
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 许可证 = CC
- en: '}'
  id: totrans-221
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '}'
