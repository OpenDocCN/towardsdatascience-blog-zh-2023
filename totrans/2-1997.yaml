- en: The Bias-Variance Tradeoff, Explained
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-bias-variance-tradeoff-explained-2d1311c2b7c2](https://towardsdatascience.com/the-bias-variance-tradeoff-explained-2d1311c2b7c2)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Irreverent Demystifiers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bias-variance tradeoff, part 3 of 3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://kozyrkov.medium.com/?source=post_page-----2d1311c2b7c2--------------------------------)[![Cassie
    Kozyrkov](../Images/ad18dd12979a4a3ec130bdf8b889af23.png)](https://kozyrkov.medium.com/?source=post_page-----2d1311c2b7c2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2d1311c2b7c2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2d1311c2b7c2--------------------------------)
    [Cassie Kozyrkov](https://kozyrkov.medium.com/?source=post_page-----2d1311c2b7c2--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2d1311c2b7c2--------------------------------)
    ·4 min read·Feb 15, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: We covered a lot of ground in [Part 1](http://bit.ly/quaesita_bivar1) and [Part
    2](http://bit.ly/quaesita_bivar2) of this series. [Part 1](http://bit.ly/quaesita_bivar1)
    was the appetizer, where we covered some basics you’d need to know on your journey
    to understanding the bias-variance tradeoff. [Part 2](http://bit.ly/quaesita_bivar2)
    was our hearty main course, where we devoured concepts like overfitting, underfitting,
    and regularization.
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s a very good idea to eat your veggies, so do head over to those earlier
    articles before continuing here, because Part 3 is dessert: the summary you’ve
    earned by following the logic.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2d5041225c864fe2f6084d3983c5220e.png)'
  prefs: []
  type: TYPE_IMG
- en: Our dessert will be served in a nutshell. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: The bias-variance tradeoff in a nutshell
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The bias-variance tradeoff idea boils down to this:'
  prefs: []
  type: TYPE_NORMAL
- en: When you get an excellent [model performance score](http://bit.ly/mfml_039)
    during the [training phase](http://bit.ly/quaesita_mrbean), you can’t tell whether
    you’re [overfitting](http://bit.ly/mfml_049) or [underfitting](http://bit.ly/mfml_050)
    or living your best life.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training performance and actual performance ([the one you care about](http://bit.ly/quaesita_parrot))
    aren’t the same thing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training performance is about how well your model does on the old data that
    it learns from whereas what you actually care about is how well your model will
    perform when you feed in brand new data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you **increase complexity** to ratchet up **overfitting** without improving
    real performance, what happens when you apply your model to your [validation set](http://bit.ly/quaesita_idiot)?
    (Or to your [debugging set](http://bit.ly/mfml_062) if you’re using a [four-way
    split](http://bit.ly/quaesita_history2) like a champ.) You’ll see standard deviation
    (square root of variance) grow more than bias shrinks. You made things better
    in training but worse in general!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you **decrease complexity** to ratchet up your **underfitting** without improving
    real performance, what happens when you apply your model to your [validation set](http://bit.ly/quaesita_12steps)
    (or debugging set)? You’ll see bias grow more than standard deviation shrinks.
    You made things better in training but worse in general!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **goldilocks model** is the one where you can’t improve bias without hurting
    standard deviation proportionately more, and vice versa. That’s where you stop.
    You made things as good as they can be!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/c62c3c409acb496d2023996f2c40f30f.png)'
  prefs: []
  type: TYPE_IMG
- en: This graph is a cartoon sketch and is not general enough for the discerning
    mathematician, but it gets the point across. Created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Long story short: the bias-variance tradeoff is a useful way to think about
    tuning the regularization [hyperparameter](http://bit.ly/mfml_063) (that’s a fancy
    word for knob or *“setting that you have to pick before fitting the model”*).
    The most important takeaway is that there’s a way to find the complexity sweet
    spot! It involves observing the MSE in a debugging dataset as you change the regularization
    settings. But if you’re not planning on doing this, you’re probably better off
    forgetting everything you just read and remembering this instead:'
  prefs: []
  type: TYPE_NORMAL
- en: Don’t try to cheat. You can’t do “better” than the best model your information
    can buy you.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Don’t try to cheat. If your information is imperfect, there’s an upper bound
    on how well you can model the task. You can do “better” than the best model in
    your *training* set, but not in your (properly sized) [test set](http://bit.ly/mfml_071)
    or in the rest of reality.
  prefs: []
  type: TYPE_NORMAL
- en: So, stop taking training performance results seriously and learn to *validate
    and test* like a grown-up. (I even wrote a simple [explanation featuring Mr. Bean](http://bit.ly/quaesita_mrbean)
    for you so you have no excuses.)
  prefs: []
  type: TYPE_NORMAL
- en: If you understand the importance of data-splitting, you can forget this whole
    discussion.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Honestly, those of us who understand the importance of [data-splitting](http://bit.ly/quaesita_sydd)
    (and that the true test of a model is its performance in *data it hasn’t seen
    before)* can mostly forget this whole discussion and get on with our lives.
  prefs: []
  type: TYPE_NORMAL
- en: 'In other words, unless you’re planning on tuning regularized models, the famous
    bias-variance trade off is something you don’t need to know much about if your
    [step-by-step process](http://bit.ly/mfml_12steps) for applied ML/AI is solid.
    Simply avoid the bad behaviors in this guide for [AI idiots](http://bit.ly/quaesita_idiot)
    and you’ll be just fine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/how-to-be-an-ai-idiot-8559c65d91a8?source=post_page-----2d1311c2b7c2--------------------------------)
    [## How to be an AI idiot'
  prefs: []
  type: TYPE_NORMAL
- en: 7 ways to royally mess up your machine learning project
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/how-to-be-an-ai-idiot-8559c65d91a8?source=post_page-----2d1311c2b7c2--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading! How about a course?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you had fun here and you’re looking for an unboring leadership-oriented
    course designed to delight AI beginners and experts alike, [here’s a little something](https://bit.ly/funaicourse)
    I made for you:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/300b5280620ea948fc3dbffb708084d4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Course link: [https://bit.ly/funaicourse](https://bit.ly/funaicourse)'
  prefs: []
  type: TYPE_NORMAL
- en: Prefer to hone your decision skills instead of building your AI muscles? You
    can learn decision intelligence from me via this [link to my free course:](https://bit.ly/decisioncourse)
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://bit.ly/decisioncourse?source=post_page-----2d1311c2b7c2--------------------------------)
    [## The steering wheel for your life — Decision Intelligence Video Tutorial |
    LinkedIn Learning…'
  prefs: []
  type: TYPE_NORMAL
- en: 'Decision-making is the most valuable skill you can learn. Your life boils down
    to two things: the quality of your…'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: bit.ly](https://bit.ly/decisioncourse?source=post_page-----2d1311c2b7c2--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '*P.S. Have you ever tried hitting the clap button here on Medium more than
    once to see what happens?* ❤️'
  prefs: []
  type: TYPE_NORMAL
- en: Liked the author? Connect with Cassie Kozyrkov
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s be friends! You can find me on [Twitter](https://twitter.com/quaesita),
    [YouTube](https://www.youtube.com/channel/UCbOX--VOebPe-MMRkatFRxw), [Substack](http://decision.substack.com),
    and [LinkedIn](https://www.linkedin.com/in/kozyrkov/). Interested in having me
    speak at your event? Use [this form](http://bit.ly/makecassietalk) to get in touch.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://kozyrkov.medium.com/membership?source=post_page-----2d1311c2b7c2--------------------------------)
    [## Join Medium'
  prefs: []
  type: TYPE_NORMAL
- en: Read every story from Cassie Kozyrkov (and thousands of other writers on Medium).
    Your membership fee directly supports…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: kozyrkov.medium.com](https://kozyrkov.medium.com/membership?source=post_page-----2d1311c2b7c2--------------------------------)
  prefs: []
  type: TYPE_NORMAL
