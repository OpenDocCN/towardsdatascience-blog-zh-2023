- en: 'Imperfections Unveiled: The Intriguing Reality Behind Our MLOps Course Creation'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/imperfections-unveiled-the-intriguing-reality-behind-our-mlops-course-creation-6ff7d52ecb7e](https://towardsdatascience.com/imperfections-unveiled-the-intriguing-reality-behind-our-mlops-course-creation-6ff7d52ecb7e)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[THE FULL STACK 7-STEPS MLOPS FRAMEWORK](https://towardsdatascience.com/tagged/full-stack-mlops)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Bonus Lesson: Behind the Scenes of an ‘Imperfect’ ML Project — Lessons and
    Insights'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://pauliusztin.medium.com/?source=post_page-----6ff7d52ecb7e--------------------------------)[![Paul
    Iusztin](../Images/d07551a78fa87940220b49d9358f3166.png)](https://pauliusztin.medium.com/?source=post_page-----6ff7d52ecb7e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6ff7d52ecb7e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6ff7d52ecb7e--------------------------------)
    [Paul Iusztin](https://pauliusztin.medium.com/?source=post_page-----6ff7d52ecb7e--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6ff7d52ecb7e--------------------------------)
    ·10 min read·Jun 19, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ca4bbb68e598e29ca3bd372976f3b483.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Hassan Pasha](https://unsplash.com/@hpzworkz?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: This article represents a **last** **bonus lesson** **out of a 7-lesson course**
    that walked you step-by-step through how to **design, implement, and deploy an
    ML system** using **MLOps good practices**. During the course, you built a production-ready
    model to forecast energy consumption levels for the next 24 hours across multiple
    consumer types from Denmark.
  prefs: []
  type: TYPE_NORMAL
- en: '*During the course, you learned all the fundamentals of designing, coding and
    deploying an ML system using a batch-serving architecture.*'
  prefs: []
  type: TYPE_NORMAL
- en: This course *targets mid/advanced ML or software engineers* who want to level
    up their skills by building their own ML end-to-end projects.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, certificates are everywhere. Building advanced end-to-end projects
    that you can later show off is the best way to get recognition as a professional
    engineer.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Table of Contents:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Course Introduction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Course Lessons
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data Source
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Bonus Lesson: Behind the Scenes of an ‘Imperfect’ ML Project — Lessons and
    Insights*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Course Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '***During the 7 lessons course, you learned how to:***'
  prefs: []
  type: TYPE_NORMAL
- en: design a batch-serving architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use Hopsworks as a feature store
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: design a feature engineering pipeline that reads data from an API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: build a training pipeline with hyper-parameter tunning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use W&B as an ML Platform to track your experiments, models, and metadata
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: implement a batch prediction pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use Poetry to build your own Python packages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: deploy your own private PyPi server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: orchestrate everything with Airflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use the predictions to code a web app using FastAPI and Streamlit
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use Docker to containerize your code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use Great Expectations to ensure data validation and integrity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: monitor the performance of the predictions over time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: deploy everything to GCP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: build a CI/CD pipeline using GitHub Actions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you haven’t followed the series and it sounds like something you are interested
    in, I want to let you know that after completing the course, you will understand
    everything I said before. Most importantly, you will see WHY I used all these
    tools and how they work together as a system.
  prefs: []
  type: TYPE_NORMAL
- en: '**If you want to get the most out of this course,** [**I suggest you access
    the GitHub repository**](https://github.com/iusztinpaul/energy-forecasting) **containing
    all the lessons'' code. This course is designed to quickly read and replicate
    the code along the articles.**'
  prefs: []
  type: TYPE_NORMAL
- en: During the course, you learned how to implement the diagram below. After explaining
    it step-by-step, it doesn't sound so scary anymore, right?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4b5c3b0b8e2162ea8fd268ca745199ec.png)'
  prefs: []
  type: TYPE_IMG
- en: Diagram of the architecture built during the course [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: In this **final bonus lesson**, we want to talk about *potential improvements*
    that can be made to the current architecture and *design choices* made during
    the course. We also want to highlight the *trade-offs* we had to make and give
    you some ideas for future projects.
  prefs: []
  type: TYPE_NORMAL
- en: Think of it as the behind of scenes section 👀
  prefs: []
  type: TYPE_NORMAL
- en: 'Course Lessons:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Batch Serving. Feature Stores. Feature Engineering Pipelines.](https://medium.com/towards-data-science/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Training Pipelines. ML Platforms. Hyperparameter Tuning.](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Batch Prediction Pipeline. Package Python Modules with Poetry.](https://medium.com/towards-data-science/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Private PyPi Server. Orchestrate Everything with Airflow.](/unlocking-mlops-using-airflow-a-comprehensive-guide-to-ml-system-orchestration-880aa9be8cff)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Data Validation for Quality and Integrity using GE. Model Performance Continuous
    Monitoring.](/ensuring-trustworthy-ml-systems-with-data-validation-and-real-time-monitoring-89ab079f4360)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Consume and Visualize your Model''s Predictions using FastAPI and Streamlit.
    Dockerize Everything.](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Deploy All the ML Components to GCP. Build a CI/CD Pipeline Using Github Actions.](https://medium.com/towards-data-science/seamless-ci-cd-pipelines-with-github-actions-on-gcp-your-tools-for-effective-mlops-96f676f72012)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**[Bonus] Behind the Scenes of an ‘Imperfect’ ML Project — Lessons and Insights**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The bonus lesson will openly share the course’s trade-offs, design choices,
    and potential improvements.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, we strongly encourage you to read the rest of the [course](https://towardsdatascience.com/tagged/full-stack-mlops)
    if building production-ready ML systems interest you 👇
  prefs: []
  type: TYPE_NORMAL
- en: '[](/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f?source=post_page-----6ff7d52ecb7e--------------------------------)
    [## A Framework for Building a Production-Ready Feature Engineering Pipeline'
  prefs: []
  type: TYPE_NORMAL
- en: 'Lesson 1: Batch Serving. Feature Stores. Feature Engineering Pipelines.'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f?source=post_page-----6ff7d52ecb7e--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Data Source
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We used a free & open API that provides hourly energy consumption values for
    all the energy consumer types within Denmark [1].
  prefs: []
  type: TYPE_NORMAL
- en: They provide an intuitive interface where you can easily query and visualize
    the data. [You can access the data here](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour)
    [1].
  prefs: []
  type: TYPE_NORMAL
- en: 'The data has 4 main attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Hour UTC:** the UTC datetime when the data point was observed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Price Area:** Denmark is divided into two price areas: DK1 and DK2 — divided
    by the Great Belt. DK1 is west of the Great Belt, and DK2 is east of the Great
    Belt.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consumer Type:** The consumer type is the Industry Code DE35, owned and maintained
    by Danish Energy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total Consumption:** Total electricity consumption in kWh'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Note:** The observations have a lag of 15 days! But for our demo use case,
    that is not a problem, as we can simulate the same steps as it would in real-time.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4eab6debdb7ba94406b8d0a8e28e3438.png)'
  prefs: []
  type: TYPE_IMG
- en: A screenshot from our web app showing how we forecasted the energy consumption
    for area = 1 and consumer_type = 212 [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: 'The data points have an hourly resolution. For example: "2023–04–15 21:00Z",
    "2023–04–15 20:00Z", "2023–04–15 19:00Z", etc.'
  prefs: []
  type: TYPE_NORMAL
- en: We will model the data as multiple time series. Each unique **price area** and
    **consumer type tuple represents its** unique time series.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, we will build a model that independently forecasts the energy consumption
    for the next 24 hours for every time series.
  prefs: []
  type: TYPE_NORMAL
- en: '*Check out the video below to better understand what the data looks like* 👇'
  prefs: []
  type: TYPE_NORMAL
- en: Course & data source overview [Video by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: 'Bonus Lesson: Behind the Scenes of an ‘Imperfect’ ML Project — Lessons and
    Insights'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: No more chit-chat. Let's jump directly behind the scenes 🔥
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4b5c3b0b8e2162ea8fd268ca745199ec.png)'
  prefs: []
  type: TYPE_IMG
- en: Diagram of the architecture built during the course [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: Overall Code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '***#1\. Duplicated code***'
  prefs: []
  type: TYPE_NORMAL
- en: The big elephant in the room is that we had quite a lot of duplicated code between
    different Python modules, which doesn't respect the almighty DRY principle.
  prefs: []
  type: TYPE_NORMAL
- en: Such as the [settings.py](https://github.com/iusztinpaul/energy-forecasting/blob/main/feature-pipeline/feature_pipeline/settings.py)
    and [utils.py](https://github.com/iusztinpaul/energy-forecasting/blob/main/feature-pipeline/feature_pipeline/utils.py)
    files of the ML pipelines or the UI's [dropdown + line plot component](https://github.com/iusztinpaul/energy-forecasting/blob/main/app-frontend/frontend/main.py).
  prefs: []
  type: TYPE_NORMAL
- en: This code could be refactored into a ***common***module shared across all other
    modules.
  prefs: []
  type: TYPE_NORMAL
- en: '***#2\. Classes, not functions!***'
  prefs: []
  type: TYPE_NORMAL
- en: Modeling your code using classes is good practice, but we used only functions
    during the course.
  prefs: []
  type: TYPE_NORMAL
- en: We could have created a central class for every pipeline, such as FeaturesExtractor,
    Trainer, and BatchPredictor.
  prefs: []
  type: TYPE_NORMAL
- en: Also, instead of returning plain dictionaries containing the metadata of a run,
    we could have created a RunResult class to have more control over how the data
    is passed.
  prefs: []
  type: TYPE_NORMAL
- en: '***#3\. No tests*** 😟'
  prefs: []
  type: TYPE_NORMAL
- en: Any code base is better with a bunch of unit & integration tests to validate
    all the changes done to the code.
  prefs: []
  type: TYPE_NORMAL
- en: Pipeline Design
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '***#1\. The DAG has state***'
  prefs: []
  type: TYPE_NORMAL
- en: Because the DAG has a state, it isn’t very easy to run it in parallel. Our issue
    is that you need predictions from previous runs to compute the monitoring metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, by definition, you can't run multiple parallel instances of the same DAG
    at different points in time.
  prefs: []
  type: TYPE_NORMAL
- en: '*When does this become a problem?*'
  prefs: []
  type: TYPE_NORMAL
- en: '*When backfilling*. Let''s say you want to backfill every hour for the latest
    2 months. If you run the program sequentially, it will take forever.'
  prefs: []
  type: TYPE_NORMAL
- en: As a solution, we would suggest moving the monitoring component to a different
    DAG.
  prefs: []
  type: TYPE_NORMAL
- en: '***#2\. Avoid using ":latest" as your resources version***'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you use the ***":latest"*** tag to access resources such as:'
  prefs: []
  type: TYPE_NORMAL
- en: the model's artifact,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: data (Feature Store feature view or training dataset),
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the best configuration artifact, etc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: … you introduce dependencies between multiple runs of the ML pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: It is subtle, but let me explain 👇
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s say you run in parallel 2 ML pipelines: A & B. Pipeline A first generates
    a new dataset version. Then for any reason, pipeline B starts the training pipeline
    before pipeline A and accesses the "latest" dataset version, which is created
    by pipeline A.'
  prefs: []
  type: TYPE_NORMAL
- en: This is also known as a "race condition" in parallel computing.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, it can easily be solved by hardcoding the version of the resources
    between tasks of the same pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: For example, instead of accessing *"****dataset:latest****"*, access *"****dataset:v3****".*
  prefs: []
  type: TYPE_NORMAL
- en: As you saw, speed is crucial when it comes to backfilling. Thus, running a DAG
    in parallel is essential in the long run.
  prefs: []
  type: TYPE_NORMAL
- en: Airflow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '***#1\. Use Docker Tasks***'
  prefs: []
  type: TYPE_NORMAL
- en: This is not necessarily an issue, but I wanted to highlight that instead of
    using a Python environment, you could have also shipped your code inside a Docker
    container — [Task Docker Decorator Docs](https://airflow.apache.org/docs/apache-airflow-providers-docker/stable/decorators/docker.html)
    [2].
  prefs: []
  type: TYPE_NORMAL
- en: The primary benefit is that this makes the system more scalable.
  prefs: []
  type: TYPE_NORMAL
- en: But the good news is that the process learned during the course is extremely
    similar. Instead of pushing the Python package to a PyPi registry, you push a
    Docker image to a Docker registry.
  prefs: []
  type: TYPE_NORMAL
- en: '***#2\. Smaller, Atomic Tasks***'
  prefs: []
  type: TYPE_NORMAL
- en: In our case, the Tasks inside the DAG contain a lot of logic. They basically
    run an entire application.
  prefs: []
  type: TYPE_NORMAL
- en: This is not necessarily bad, but dividing it into smaller pieces is good practice.
    Thus, debugging, monitoring, and restarting the DAG from a given point of failure
    is more accessible.
  prefs: []
  type: TYPE_NORMAL
- en: For example, instead of reading/writing data from GCS in Python, we could have
    used one of Airflow's GCS operators — [GCS Airflow operators](https://airflow.apache.org/docs/apache-airflow-providers-google/stable/_api/airflow/providers/google/cloud/operators/gcs/index.html)
    [3].
  prefs: []
  type: TYPE_NORMAL
- en: '***#3\. Inject the hyperparameter tuning settings from Airflow***'
  prefs: []
  type: TYPE_NORMAL
- en: Currently, the hyperparameter tuning setting is hardcoded into a [***configs/gridsearch.py***](https://github.com/iusztinpaul/energy-forecasting/blob/main/training-pipeline/training_pipeline/configs/gridsearch.py)
    file.
  prefs: []
  type: TYPE_NORMAL
- en: This is not very flexible, as the only option to modify the configuration is
    to push a new version to git, which isn't very practical.
  prefs: []
  type: TYPE_NORMAL
- en: A solution would be injecting the settings from a YAML file, which can be easily
    added to the Airflow workflow.
  prefs: []
  type: TYPE_NORMAL
- en: A nice YAML configuration tool for ML models is [Hydra](https://github.com/facebookresearch/hydra)
    by *facebookresearch*. Just try it, you will thank me later.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '***#1\. Not monitoring the system’s health***'
  prefs: []
  type: TYPE_NORMAL
- en: We could have easily added a system health monitor mechanism by periodically
    pinging the */health* endpoint of the API.
  prefs: []
  type: TYPE_NORMAL
- en: We could have reflected this with a green/red panel on the UI.
  prefs: []
  type: TYPE_NORMAL
- en: '***#2\. No alerts***'
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on the MAPE metric we are constantly monitoring, we could have added
    a system of alerts such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '*warnings [threshold_B > MAPE > threshold_A]:* inform the engineer that something
    might be wrong;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*alarms [MAPE > threshold_B > threshold_A]:* inform the engineer that something
    is wrong + trigger the hyperparameter tuning logic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***#3\. Enrich the UI***'
  prefs: []
  type: TYPE_NORMAL
- en: We could have added the MAPE metric for every time series individually.
  prefs: []
  type: TYPE_NORMAL
- en: '***#4\. Don''t reinvent the wheel!***'
  prefs: []
  type: TYPE_NORMAL
- en: We implemented a mini-monitoring tool just as an example. But in a real-world
    scenario, you should leverage existing tools such as [EvidentlyAI](https://www.evidentlyai.com/)
    or [Arize](https://arize.com/).
  prefs: []
  type: TYPE_NORMAL
- en: These tools & packages already give you professional solutions. Thus you can
    focus on adding value.
  prefs: []
  type: TYPE_NORMAL
- en: '***#5\. Monitor drifts***'
  prefs: []
  type: TYPE_NORMAL
- en: As a nice to have, it would also be helpful to monitor data & concept drifts.
    But as we have almost real-time GT, this is just nice to have.
  prefs: []
  type: TYPE_NORMAL
- en: Web App — Predictions Dashboard
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '***#1\. Enrich the UI***'
  prefs: []
  type: TYPE_NORMAL
- en: The UI is quite basic. For example, we could have enriched the UI by adding
    texts and alerts when the data is invalid (it doesn't pass the validation suit).
  prefs: []
  type: TYPE_NORMAL
- en: '***#2\. We request data in a naive way***'
  prefs: []
  type: TYPE_NORMAL
- en: Out requests to the API are quite naive. Usually, those steps are guarded by
    a set of Exceptions that catch different behaviors on 300, 400, and 500 response
    codes.
  prefs: []
  type: TYPE_NORMAL
- en: '***#3\. The settings are hardcoded***'
  prefs: []
  type: TYPE_NORMAL
- en: We could have injected the settings using a ***.env*** file. Thus making the
    program more configurable. Similar to the Web App FastAPI code.
  prefs: []
  type: TYPE_NORMAL
- en: Deploy & CI/CD Pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '***#1\. Partially CI implementation***'
  prefs: []
  type: TYPE_NORMAL
- en: To fully complete the CI/CD pipeline, we could have built the Web App Docker
    images, pushed them to a Docker registry and pulled them from there when deploying
    them to the GCP VM.
  prefs: []
  type: TYPE_NORMAL
- en: Same story when building the Python packages with Poetry.
  prefs: []
  type: TYPE_NORMAL
- en: This is how it is done by the book.
  prefs: []
  type: TYPE_NORMAL
- en: Also, if we had any tests, we should have run them before deploying the code.
  prefs: []
  type: TYPE_NORMAL
- en: Another idea is to run commands such as ***flake8*** to verify that the code
    is written using PEP8 conventions.
  prefs: []
  type: TYPE_NORMAL
- en: '***#2\. Host PyPi on a different VM***'
  prefs: []
  type: TYPE_NORMAL
- en: Also, hosting the PyPi server on a different VM or at least completely independently
    from the Airflow component would be recommended.
  prefs: []
  type: TYPE_NORMAL
- en: In doing so, the system would have been more modular and flexible.
  prefs: []
  type: TYPE_NORMAL
- en: '***#3\. Host the .env files on a GCS bucket***'
  prefs: []
  type: TYPE_NORMAL
- en: Instead of manually completing and copying the **.env** files, we could have
    stored them on a GCS bucket and automatically downloaded them inside the CI/CD
    pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: '***#4\. Automate the infrastructure***'
  prefs: []
  type: TYPE_NORMAL
- en: You have seen how boring it is to set up all the GCP resources you need manually…
    and this is a small infrastructure. Imagine how it is when you have 100 or 1000
    components inside your infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: That is why it is suggested to automate the creation of your infrastructure
    with IoC tools such as Terraform.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you got this far, I want to thank you and tell you how deeply I appreciate
    that you followed my **Full Stack 7-Steps MLOps Framework** course 🙏
  prefs: []
  type: TYPE_NORMAL
- en: 'In this bonus lesson, you saw that no system is perfect and you always have
    to take certain trade-offs due to:'
  prefs: []
  type: TYPE_NORMAL
- en: time constraints,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: resource constraints,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: bad planning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that you see that everyone is still learning and doesn’t know everything,
    you have no excuse but to go and build your next awesome project 🔥
  prefs: []
  type: TYPE_NORMAL
- en: Let’s connect on [LinkedIn](https://www.linkedin.com/in/pauliusztin/), and let
    me know if you have any questions or just share the awesome projects you built
    after this course.
  prefs: []
  type: TYPE_NORMAL
- en: '[***Access the GitHub repository here.***](https://github.com/iusztinpaul/energy-forecasting)'
  prefs: []
  type: TYPE_NORMAL
- en: 💡 My goal is to help machine learning engineers level up in designing and productionizing
    ML systems. Follow me on [LinkedIn](https://www.linkedin.com/in/pauliusztin/)
    or subscribe to my [weekly newsletter](https://pauliusztin.substack.com/) for
    more insights!
  prefs: []
  type: TYPE_NORMAL
- en: 🔥 If you enjoy reading articles like this and wish to support my writing, consider
    [becoming a Medium member](https://pauliusztin.medium.com/membership). Using [my
    referral link](https://pauliusztin.medium.com/membership), you can support me
    without extra cost while enjoying limitless access to Medium's rich collection
    of stories.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://pauliusztin.medium.com/membership?source=post_page-----6ff7d52ecb7e--------------------------------)
    [## Join Medium with my referral link - Paul Iusztin'
  prefs: []
  type: TYPE_NORMAL
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every story…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: pauliusztin.medium.com](https://pauliusztin.medium.com/membership?source=post_page-----6ff7d52ecb7e--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Thank you ✌🏼 !
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] [Energy Consumption per DE35 Industry Code from Denmark API](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour),
    [Denmark Energy Data Service](https://www.energidataservice.dk/about/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] [Task Docker Decorator](https://airflow.apache.org/docs/apache-airflow-providers-docker/stable/decorators/docker.html),
    Airflow Docs'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] [GCS Airflow Operators](https://airflow.apache.org/docs/apache-airflow-providers-google/stable/_api/airflow/providers/google/cloud/operators/gcs/index.html),
    Airflow Docs'
  prefs: []
  type: TYPE_NORMAL
