["```py\ndf = df1.union(df2).union(df3)\n```", "```py\n## Create two data frames from 1 to 1000000\\. Let's call them df1 and df2\ndf1 = spark.createDataFrame([i for i in range(1000000)], IntegerType())\ndf2 = spark.createDataFrame([i for i in range(1000000)], IntegerType())\n\n## Perform inner join on df1 and df2\ndf = df1.join(df2, how=\"inner\", on=\"value\")\n\n## Split the joined result into two data frames: one only contains the odd numbers, another one for the even numbers\ndf_odd = df.filter(df.value % 2 == 1)\ndf_even = df.filter(df.value % 2 == 0)\n\n## Add a transformation with a field called magic_value which is generated by two dummy transformations.\ndf_odd = df_odd.withColumn(\"magic_value\", df.value+1)\ndf_even = df_even.withColumn(\"magic_value\", df.value/2)\n\n## Union the odd and even number data frames\ndf_odd.union(df_even).count()\n```", "```py\n# ...........................\n## Perform inner join on df1 and df2\ndf = df1.join(df2, how=\"inner\", on=\"value\")\n\n## add cache here\ndf.cache()\n\n## Split the joined result into two data frames: one only contains the odd numbers, another one for the even numbers\ndf_odd = df.filter(df.value % 2 == 1)\n# ...........................\n```"]