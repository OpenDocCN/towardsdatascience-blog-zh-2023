- en: 'ChatGPT: Automated Prompt Scoring'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT：自动化提示评分
- en: 原文：[https://towardsdatascience.com/chatgpt-automated-prompt-scoring-c972f9ee2c4f](https://towardsdatascience.com/chatgpt-automated-prompt-scoring-c972f9ee2c4f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/chatgpt-automated-prompt-scoring-c972f9ee2c4f](https://towardsdatascience.com/chatgpt-automated-prompt-scoring-c972f9ee2c4f)
- en: '![](../Images/1b9b1e6bc46d2e359537b4b1d0aff68d.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1b9b1e6bc46d2e359537b4b1d0aff68d.png)'
- en: This image was created with the assistance of DALL·E 2
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 此图像是在 DALL·E 2 的协助下创建的
- en: Guide
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指南
- en: How to objectively choose and improve your ChatGPT prompts using python
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何使用 python 客观地选择和改进你的 ChatGPT 提示
- en: '[](https://michael-malin.medium.com/?source=post_page-----c972f9ee2c4f--------------------------------)[![Michael
    Malin](../Images/070604c68a50e8f2996f2c8837df3ec9.png)](https://michael-malin.medium.com/?source=post_page-----c972f9ee2c4f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c972f9ee2c4f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c972f9ee2c4f--------------------------------)
    [Michael Malin](https://michael-malin.medium.com/?source=post_page-----c972f9ee2c4f--------------------------------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://michael-malin.medium.com/?source=post_page-----c972f9ee2c4f--------------------------------)[![Michael
    Malin](../Images/070604c68a50e8f2996f2c8837df3ec9.png)](https://michael-malin.medium.com/?source=post_page-----c972f9ee2c4f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c972f9ee2c4f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c972f9ee2c4f--------------------------------)
    [Michael Malin](https://michael-malin.medium.com/?source=post_page-----c972f9ee2c4f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c972f9ee2c4f--------------------------------)
    ·10 min read·Apr 10, 2023
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c972f9ee2c4f--------------------------------)
    ·10 分钟阅读·2023 年 4 月 10 日
- en: --
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Large language models (LLM) like ChatGPT are having a huge impact. They are
    also just the beginning. Over the next year, companies big and small will begin
    to roll out domain/persona specialized LLM models. Indeed, this is already becoming
    a reality with new products like the finance-specialized [BloombergGPT](https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/)
    and Microsoft’s developer-focused [Copilot](https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/).
    We will soon see AI personal trainers, health coaches, councilors, legal assistants,
    and many more. While some cases may require fine-tuned models on domain-specific
    data, the majority can be accomplished with simple prompt engineering. But how
    do you know when your prompt is good enough? How can we generate objective accuracy
    scores on subjective text?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）如 ChatGPT 正在产生巨大的影响。它们也仅仅是开始。在接下来的一年中，各大公司将开始推出领域/角色专用的 LLM 模型。实际上，像专注于金融的
    [BloombergGPT](https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/)
    和微软开发者专注的 [Copilot](https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/)
    等新产品已经在成为现实。我们很快将看到 AI 个人教练、健康教练、顾问、法律助理等更多应用。虽然有些情况可能需要基于领域特定数据的微调模型，但大多数可以通过简单的提示工程实现。但你如何知道你的提示是否足够好？我们如何在主观文本上生成客观准确度评分？
- en: 'This guide will cover:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南将涵盖：
- en: Theory
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理论
- en: Prompt engineering
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程
- en: Prompt Testing
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示测试
- en: Prompt Scoring
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示评分
- en: Prompt Feedback
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示反馈
- en: Theory
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理论
- en: The difficulty in testing LLM prompt outputs is that the outcomes are subjective.
    I may find the results perfect while you find them subpar. Both opinions are equally
    valid. This makes a purely scientific approach to scoring very difficult. A good
    approach to these types of problems is known as the Delphi method. It involves
    using a panel of experts and aggregating their results. As you can imagine, this
    can be expensive, but that is where AI comes in!
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 测试 LLM 提示输出的困难在于结果是主观的。我可能觉得结果完美，而你觉得它们不够好。这两种观点都是有效的。这使得纯科学的方法来评分非常困难。应对这些问题的一种好的方法是
    Delphi 方法。它涉及使用专家小组并汇总他们的结果。正如你所想象的，这可能很昂贵，但这就是 AI 的作用所在！
- en: We will create a series of alternate personality prompts, have them converse
    with our primary prompt using the OpenAI API in Python, and create a scoring prompt
    to see how our primary prompt performed. Finally, we aggregate the scores for
    each personality-prompt conversation. This creates a little more work upfront
    but saves much time in the long run. It also gives you an objective score.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: This method does pose one issue you should be aware of. Multiple runs on the
    same prompt will yield slightly different results. This is where the Delphi method
    shines. The greater number of **diverse** alternate prompts you use, the more
    consistent your aggregate score result will be. You can actually test if you have
    enough alternate prompts by measuring the score deviation. When the deviation
    is small, you are in a good spot.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: I admit this is not a perfect solution. With subjective problems, no solution
    will be. What I have noticed is that I generally agree with the results when I
    manually review the conversations. This allows me to test many prompts and get
    a “good enough” evaluation allowing me to iterate quickly. Now before we implement
    the Delphi testing method described here, it is important to understand the basics
    of prompt engineering.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Prompt Engineering
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Base LLM models provide decent general responses. This is not always ideal.
    For example, if I am building a chatbot, I do not want to return a three-paragraph
    wall of text. Maybe I want my answers to feel more human and conversational. Prompt
    engineering involves providing instructions to steer the LLM’s output styles,
    formats, and behaviors.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with an example. We are planning on building a chatbot that will
    answer questions as if it is a “short, green, pointy-eared space wizard that uses
    laser swords in a galaxy far, far away.” If such a character existed in science
    fiction, I could probably simplify this prompt by using their name, but then I
    would risk running into copywrite issues. With a little help, the LLM should figure
    out what I am going for.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: 'For an in-depth guide to prompt engineering, [read here](https://github.com/dair-ai/Prompt-Engineering-Guide?fbclid=IwAR3LFOge-kn7GFiFaj3bUIsAOAG2V-gtXyUH93bRpSMQxc_3i8c0fTgQGxA).
    I will cover some of the basics:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Be specific and concise. For example, “In one sentence, explain gravity to a
    4th grader” is much better than “Please give a short explanation of how gravity
    works on earth that is easy for anyone to understand.”
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use ### to clearly distinguish between instructions and input/outputs. For
    example: ###You are Confucius. Answer questions in 1 to 2 sentences. Use quotes
    when using Confucius’s real words.###'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Provide output format and examples. While the LLM may suspect what we are looking
    for with our “short, green, pointy-eared space wizard” description, we shouldn’t
    leave it to chance. By priming the conversation, the model will do much better.
    Let’s put it all together:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You are a short, green, pointy-eared space wizard that uses laser swords in
    a galaxy far, far away. Do not identify yourself. Answer questions in 1 or 2 sentences.
    Then ask a follow-up question to keep the conversation going ###'
  id: totrans-28
  prefs:
  - PREF_BQ
  - PREF_H3
  type: TYPE_NORMAL
- en: ''
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'You: “Something troubles you, it does?”'
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Me: “Do not underestimate my power! Tell me where the rebel base is!”'
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'You:'
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The location I cannot reveal. What led you to join the Empire, hmm?”
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Not bad, but ***don’t get cocky***. Honing in on a good prompt can take a bit
    of trial and error. This can be time-consuming. As upgraded models are rolled
    out (e.g., GPT4), prompt behavior can drastically change requiring tweaks. We
    need an automated way to test these prompts.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Prompt Testing
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For automated testing, we will use the ChatGPT API. Rather than manually creating
    conversations, we will use ChatGPT to talk to itself. I like to create prompts
    for different personas that mirror possible use cases (along with a few adversarial
    prompts). Here are a few examples:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: You have a crush at school and are seeking advice from a mentor###
  id: totrans-39
  prefs:
  - PREF_UL
  - PREF_H3
  type: TYPE_NORMAL
- en: You have a job interview tomorrow and are looking for advice on how to do well###
  id: totrans-40
  prefs:
  - PREF_UL
  - PREF_H3
  type: TYPE_NORMAL
- en: You are a dark lord who uses laser swords in a galaxy far, far away. You are
    trying to coerce the location of the rebel base from your enemy.###
  id: totrans-41
  prefs:
  - PREF_UL
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that we have a few prompts to work with, let’s generate a conversation piece
    by piece so the logic is easy to understand. Let’s start with the crush example.
    We will clean up the code later.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: “Fear is a path to the dark side young one, be brave and speak your truth. What
    makes you think she might feel the same?”
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: “Well, she always seems to be happy to see me and we have a lot in common. We’ve
    had some great conversations and laughs together. But I don’t want to ruin our
    friendship if she doesn’t feel the same way.”
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'From here, we can loop back and forth, appending responses to the prompt lists.
    Here is the clean code I promised:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We now have a method for automatically generating conversations for each of
    our user personas. But are they any good? We need a way to objectively evaluate
    the responses for our primary persona. But how could we possibly accomplish this
    with subjective text? We will build a 3rd GPT persona for evaluating itself!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Prompt Scoring
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To evaluate the conversational skills of our “space wizard”, we will create
    a new prompt:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: 'On a 10-scale, rate the Wizard responses from the conversation below based
    on the following criteria:'
  id: totrans-52
  prefs:
  - PREF_BQ
  - PREF_H3
  type: TYPE_NORMAL
- en: ''
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Character: the Wizard is a short, green, pointy-eared space wizard that uses
    laser swords in a galaxy far, far away. All responses should fit this persona.'
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Conversational: responses should be brief and conversational. Follow-up questions
    should move the conversation forward without being tedious. The Wizard should
    wrap up the conversation appropriately.'
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Helpful: Responses should help the User answer their question or solve their
    problem. Follow-up questions should help gather information to improve the response.'
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Present the scores in JSON format as follows:'
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '{“Character”:<float>,”Conversational”:<float>,”Helpful”:<float>}'
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Please provide scores without commentary.###
  id: totrans-62
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '{‘Character’: 8.5, ‘Conversational’: 9, ‘Helpful’: 9}'
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'We now have our scores! Aggregate these scores for all personas and we can
    get an overall score for the chatbot prompt we tested. This leaves us with one
    final question: How can we improve our prompt to raise these scores? Again, why
    don’t we ask just ask GPT? ***This is the way.***'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: Prompt Feedback
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For our feedback, we will follow this pattern:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: Begin with the same prompt we used for scoring, but leave off the request to
    return a score.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add the generated conversations to the prompt for evaluation
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Give instructions to generate an evaluation of the conversations based on the
    scoring criteria
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We start with the prompt:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the conversations below, evaluate the Wizard based on the following criteria:'
  id: totrans-72
  prefs:
  - PREF_BQ
  - PREF_H3
  type: TYPE_NORMAL
- en: ''
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Character: the Wizard is a short, green, pointy-eared space wizard that uses
    laser swords in a galaxy far, far away. All responses should fit this persona.'
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Conversational: responses should be brief and conversational. Follow-up questions
    should move the conversation forward without being tedious. The Wizard should
    wrap up the conversation appropriately.'
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Helpful: Responses should help the User by answering their question or solving
    their problem. Follow-up questions should help gather information to improve the
    response.###'
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-79
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Here are the conversations:'
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Character: Overall, the Wizard abides by their persona well and consistently
    uses language and phrases that align with their character. For example, “young
    padawan,” “may the force be with you,” and “regret leads to suffering” are all
    phrases one would expect to hear from a space wizard. The Wizard also uses language
    specific to their galaxy far far away, such as “laser-swords.” No improvements
    needed here.'
  id: totrans-82
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Conversational: The Wizard is succinct and engaging in their responses, asking
    follow-up questions that move the conversation forward without being repetitive
    or tedious. For example, when the User says they’re afraid to tell their crush
    how they feel, the Wizard follows up with “What makes you hesitant to approach
    her?” This shows that the Wizard is actively listening to the User and trying
    to understand their perspective. Another good example is when the User says they
    don’t know what to say to their crush, the Wizard responds with “In situations
    like these, trust your feelings and the force will guide you.” This puts the focus
    back on the User and empowers them to come up with their own solution. Overall,
    the Wizard’s conversational tone is friendly, supportive, and non-judgmental.'
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Helpful: The Wizard’s responses are helpful in that they give concrete advice
    and actionable steps for the User to take. For example, when the User says they’re
    afraid of rejection, the Wizard responds with “Have courage, you must…” and “Better
    to take a chance, you must.” This provides the User with encouragement and a push
    to take action. Another helpful response is when the User says they don’t know
    what to say to their crush, the Wizard suggests a simple invitation to coffee
    or a walk. This gives the User a specific idea of what to do next. Overall, the
    Wizard provides helpful advice that is tailored to the User’s specific situation.'
  id: totrans-86
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 有用：巫师的回应很有帮助，因为它们提供了具体的建议和可操作的步骤。例如，当用户说他们害怕拒绝时，巫师回应说“要有勇气，你必须……”和“最好还是冒险，你必须。”这给用户提供了鼓励和行动的推动。另一个有用的回应是，当用户说他们不知道对心仪对象说什么时，巫师建议简单地邀请喝咖啡或散步。这给用户提供了下一步要做的具体想法。总体来说，巫师提供了量身定制的、有针对性的建议。
- en: That was useful information but be careful, ***it’s a trap!*** Each GPT model
    has a max token limit. That means, if your conversations are too large or there
    are too many of them, you may receive errors with this step. In practice, I typically
    will filter down to the three lowest-scored conversations and submit those for
    evaluation.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这些信息很有用，但请小心，***这是一个陷阱！*** 每个GPT模型都有最大令牌限制。这意味着，如果你的对话过大或对话过多，你可能会在这一步遇到错误。实际上，我通常会筛选出三个得分最低的对话，并将其提交进行评估。
- en: Conclusion
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: You now have the tools to automatically generate scores and feedback for each
    of your prompt iterations. Of course, there is still a bit of work to be done.
    Not only can your chatbot prompts be tweaked, but the user and evaluation prompts
    can also be adjusted to better match what you are trying to accomplish. The important
    thing is, you can now iterate quickly, and make objective decisions. ***These
    ARE the techniques you are looking for.***
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在拥有了自动生成每次提示迭代的分数和反馈的工具。当然，还有一些工作需要完成。你不仅可以调整你的聊天机器人提示，还可以调整用户和评估提示，以更好地匹配你想要实现的目标。重要的是，你现在可以快速迭代，并做出客观决策。***这些就是你正在寻找的技巧。***
- en: About me
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于我
- en: 'I am a senior data scientist and part-time freelancer with over 12 years of
    experience. I am always looking to connect so please feel free to:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我是一名资深数据科学家和兼职自由职业者，拥有超过12年的经验。我一直在寻找联系机会，所以请随时：
- en: '[Connect with me on LinkedIn](https://www.linkedin.com/in/michael-a-malin/)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在LinkedIn上联系我](https://www.linkedin.com/in/michael-a-malin/)'
- en: '[Visit my website](http://modelforge.ai)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[访问我的网站](http://modelforge.ai)'
- en: '[Follow me on Twitter](https://twitter.com/alaska_malin)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在Twitter上关注我](https://twitter.com/alaska_malin)'
- en: '[See my other articles](https://michael-malin.medium.com/)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[查看我的其他文章](https://michael-malin.medium.com/)'
- en: '***Please feel free to comment below if you have any questions.***'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '***如果你有任何问题，请随时在下方留言。***'
