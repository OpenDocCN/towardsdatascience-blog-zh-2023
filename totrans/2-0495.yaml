- en: 'ChatGPT: Automated Prompt Scoring'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT：自动化提示评分
- en: 原文：[https://towardsdatascience.com/chatgpt-automated-prompt-scoring-c972f9ee2c4f](https://towardsdatascience.com/chatgpt-automated-prompt-scoring-c972f9ee2c4f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/chatgpt-automated-prompt-scoring-c972f9ee2c4f](https://towardsdatascience.com/chatgpt-automated-prompt-scoring-c972f9ee2c4f)
- en: '![](../Images/1b9b1e6bc46d2e359537b4b1d0aff68d.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1b9b1e6bc46d2e359537b4b1d0aff68d.png)'
- en: This image was created with the assistance of DALL·E 2
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 此图像是在 DALL·E 2 的协助下创建的
- en: Guide
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指南
- en: How to objectively choose and improve your ChatGPT prompts using python
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何使用 python 客观地选择和改进你的 ChatGPT 提示
- en: '[](https://michael-malin.medium.com/?source=post_page-----c972f9ee2c4f--------------------------------)[![Michael
    Malin](../Images/070604c68a50e8f2996f2c8837df3ec9.png)](https://michael-malin.medium.com/?source=post_page-----c972f9ee2c4f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c972f9ee2c4f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c972f9ee2c4f--------------------------------)
    [Michael Malin](https://michael-malin.medium.com/?source=post_page-----c972f9ee2c4f--------------------------------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://michael-malin.medium.com/?source=post_page-----c972f9ee2c4f--------------------------------)[![Michael
    Malin](../Images/070604c68a50e8f2996f2c8837df3ec9.png)](https://michael-malin.medium.com/?source=post_page-----c972f9ee2c4f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c972f9ee2c4f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c972f9ee2c4f--------------------------------)
    [Michael Malin](https://michael-malin.medium.com/?source=post_page-----c972f9ee2c4f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c972f9ee2c4f--------------------------------)
    ·10 min read·Apr 10, 2023
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c972f9ee2c4f--------------------------------)
    ·10 分钟阅读·2023 年 4 月 10 日
- en: --
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Large language models (LLM) like ChatGPT are having a huge impact. They are
    also just the beginning. Over the next year, companies big and small will begin
    to roll out domain/persona specialized LLM models. Indeed, this is already becoming
    a reality with new products like the finance-specialized [BloombergGPT](https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/)
    and Microsoft’s developer-focused [Copilot](https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/).
    We will soon see AI personal trainers, health coaches, councilors, legal assistants,
    and many more. While some cases may require fine-tuned models on domain-specific
    data, the majority can be accomplished with simple prompt engineering. But how
    do you know when your prompt is good enough? How can we generate objective accuracy
    scores on subjective text?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）如 ChatGPT 正在产生巨大的影响。它们也仅仅是开始。在接下来的一年中，各大公司将开始推出领域/角色专用的 LLM 模型。实际上，像专注于金融的
    [BloombergGPT](https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/)
    和微软开发者专注的 [Copilot](https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/)
    等新产品已经在成为现实。我们很快将看到 AI 个人教练、健康教练、顾问、法律助理等更多应用。虽然有些情况可能需要基于领域特定数据的微调模型，但大多数可以通过简单的提示工程实现。但你如何知道你的提示是否足够好？我们如何在主观文本上生成客观准确度评分？
- en: 'This guide will cover:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南将涵盖：
- en: Theory
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理论
- en: Prompt engineering
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程
- en: Prompt Testing
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示测试
- en: Prompt Scoring
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示评分
- en: Prompt Feedback
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示反馈
- en: Theory
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理论
- en: The difficulty in testing LLM prompt outputs is that the outcomes are subjective.
    I may find the results perfect while you find them subpar. Both opinions are equally
    valid. This makes a purely scientific approach to scoring very difficult. A good
    approach to these types of problems is known as the Delphi method. It involves
    using a panel of experts and aggregating their results. As you can imagine, this
    can be expensive, but that is where AI comes in!
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 测试 LLM 提示输出的困难在于结果是主观的。我可能觉得结果完美，而你觉得它们不够好。这两种观点都是有效的。这使得纯科学的方法来评分非常困难。应对这些问题的一种好的方法是
    Delphi 方法。它涉及使用专家小组并汇总他们的结果。正如你所想象的，这可能很昂贵，但这就是 AI 的作用所在！
- en: We will create a series of alternate personality prompts, have them converse
    with our primary prompt using the OpenAI API in Python, and create a scoring prompt
    to see how our primary prompt performed. Finally, we aggregate the scores for
    each personality-prompt conversation. This creates a little more work upfront
    but saves much time in the long run. It also gives you an objective score.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一系列不同的个性提示，通过使用Python中的OpenAI API让它们与我们的主要提示进行对话，并创建一个评分提示来评估我们的主要提示表现如何。最后，我们汇总每个个性-提示对话的评分。这在前期工作上稍微多一些，但从长远来看可以节省很多时间。它还提供了一个客观的评分。
- en: This method does pose one issue you should be aware of. Multiple runs on the
    same prompt will yield slightly different results. This is where the Delphi method
    shines. The greater number of **diverse** alternate prompts you use, the more
    consistent your aggregate score result will be. You can actually test if you have
    enough alternate prompts by measuring the score deviation. When the deviation
    is small, you are in a good spot.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法确实存在一个问题，你需要注意。对同一个提示的多次运行将产生略有不同的结果。这是德尔菲方法表现出色的地方。你使用的**多样**的备用提示越多，你的汇总评分结果将越一致。你实际上可以通过测量评分偏差来测试是否有足够的备用提示。当偏差较小时，你就处于一个不错的状态。
- en: I admit this is not a perfect solution. With subjective problems, no solution
    will be. What I have noticed is that I generally agree with the results when I
    manually review the conversations. This allows me to test many prompts and get
    a “good enough” evaluation allowing me to iterate quickly. Now before we implement
    the Delphi testing method described here, it is important to understand the basics
    of prompt engineering.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我承认这不是一个完美的解决方案。对于主观问题，没有解决方案是完美的。我注意到，当我手动审查对话时，通常会同意结果。这使我可以测试许多提示，并获得“足够好”的评估，从而快速迭代。在我们实施这里描述的德尔菲测试方法之前，了解提示工程的基础是重要的。
- en: Prompt Engineering
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示工程
- en: Base LLM models provide decent general responses. This is not always ideal.
    For example, if I am building a chatbot, I do not want to return a three-paragraph
    wall of text. Maybe I want my answers to feel more human and conversational. Prompt
    engineering involves providing instructions to steer the LLM’s output styles,
    formats, and behaviors.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 基础LLM模型提供不错的一般响应。但这并不总是理想的。例如，如果我在构建聊天机器人，我不想返回三段文字的内容。也许我希望我的回答听起来更像人类，更具对话性。提示工程涉及提供指令来引导LLM的输出风格、格式和行为。
- en: Let’s start with an example. We are planning on building a chatbot that will
    answer questions as if it is a “short, green, pointy-eared space wizard that uses
    laser swords in a galaxy far, far away.” If such a character existed in science
    fiction, I could probably simplify this prompt by using their name, but then I
    would risk running into copywrite issues. With a little help, the LLM should figure
    out what I am going for.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个例子开始。我们计划构建一个聊天机器人，它将回答问题，就像是一个“短小、绿色、尖耳的宇宙巫师，在一个遥远的银河系中使用激光剑。”如果这样的角色存在于科幻小说中，我可以通过使用他们的名字来简化这个提示，但这样会面临版权问题。在一点帮助下，LLM应该能够理解我的意图。
- en: 'For an in-depth guide to prompt engineering, [read here](https://github.com/dair-ai/Prompt-Engineering-Guide?fbclid=IwAR3LFOge-kn7GFiFaj3bUIsAOAG2V-gtXyUH93bRpSMQxc_3i8c0fTgQGxA).
    I will cover some of the basics:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 关于提示工程的详细指南， [请点击这里](https://github.com/dair-ai/Prompt-Engineering-Guide?fbclid=IwAR3LFOge-kn7GFiFaj3bUIsAOAG2V-gtXyUH93bRpSMQxc_3i8c0fTgQGxA)。我将介绍一些基础知识：
- en: Be specific and concise. For example, “In one sentence, explain gravity to a
    4th grader” is much better than “Please give a short explanation of how gravity
    works on earth that is easy for anyone to understand.”
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要具体而简洁。例如，“用一句话向4年级学生解释引力”要比“请简短地解释地球上引力的工作原理，以便任何人都能理解”要好得多。
- en: 'Use ### to clearly distinguish between instructions and input/outputs. For
    example: ###You are Confucius. Answer questions in 1 to 2 sentences. Use quotes
    when using Confucius’s real words.###'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用###来清晰地区分指令和输入/输出。例如：###你是孔子。用1到2句话回答问题。使用引号来引用孔子的真实话语。###
- en: 'Provide output format and examples. While the LLM may suspect what we are looking
    for with our “short, green, pointy-eared space wizard” description, we shouldn’t
    leave it to chance. By priming the conversation, the model will do much better.
    Let’s put it all together:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供输出格式和示例。虽然LLM可能会根据我们对“短小、绿色、尖耳的宇宙巫师”的描述猜测我们在寻找什么，但我们不应该将其留给运气。通过引导对话，模型的表现会更好。让我们把所有内容整合在一起：
- en: 'You are a short, green, pointy-eared space wizard that uses laser swords in
    a galaxy far, far away. Do not identify yourself. Answer questions in 1 or 2 sentences.
    Then ask a follow-up question to keep the conversation going ###'
  id: totrans-28
  prefs:
  - PREF_BQ
  - PREF_H3
  type: TYPE_NORMAL
  zh: '你是一个短小、绿色、尖耳的太空巫师，在遥远的星系中使用激光剑。不要自我介绍。用1到2句话回答问题。然后问一个跟进问题以保持对话的进行 ###'
- en: ''
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'You: “Something troubles you, it does?”'
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你：“有什么困扰你的吗？”
- en: ''
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Me: “Do not underestimate my power! Tell me where the rebel base is!”'
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我：“不要低估我的力量！告诉我反叛基地的位置！”
- en: ''
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'You:'
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你：
- en: “The location I cannot reveal. What led you to join the Empire, hmm?”
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “我不能透露位置。是什么让你加入了帝国，嗯？”
- en: Not bad, but ***don’t get cocky***. Honing in on a good prompt can take a bit
    of trial and error. This can be time-consuming. As upgraded models are rolled
    out (e.g., GPT4), prompt behavior can drastically change requiring tweaks. We
    need an automated way to test these prompts.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 不错，但***别太自满***。找到一个好的提示可能需要一些试错过程。这可能会很耗时。随着升级模型的推出（例如，GPT4），提示行为可能会发生剧烈变化，需要调整。我们需要一种自动化测试这些提示的方法。
- en: Prompt Testing
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示测试
- en: 'For automated testing, we will use the ChatGPT API. Rather than manually creating
    conversations, we will use ChatGPT to talk to itself. I like to create prompts
    for different personas that mirror possible use cases (along with a few adversarial
    prompts). Here are a few examples:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 对于自动化测试，我们将使用ChatGPT API。我们将用ChatGPT与自己对话，而不是手动创建对话。我喜欢为不同的角色创建提示，这些提示反映了可能的使用场景（以及一些对抗性的提示）。以下是几个例子：
- en: You have a crush at school and are seeking advice from a mentor###
  id: totrans-39
  prefs:
  - PREF_UL
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你在学校有一个暗恋对象，正在寻求导师的建议###
- en: You have a job interview tomorrow and are looking for advice on how to do well###
  id: totrans-40
  prefs:
  - PREF_UL
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你明天有一个工作面试，正在寻找如何表现好的建议###
- en: You are a dark lord who uses laser swords in a galaxy far, far away. You are
    trying to coerce the location of the rebel base from your enemy.###
  id: totrans-41
  prefs:
  - PREF_UL
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你是一个在遥远星系中使用激光剑的黑暗领主。你正在试图从敌人那里逼迫出反叛基地的位置。###
- en: Now that we have a few prompts to work with, let’s generate a conversation piece
    by piece so the logic is easy to understand. Let’s start with the crush example.
    We will clean up the code later.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一些提示可以使用，让我们一块一块地生成对话，以便逻辑易于理解。让我们从暗恋的例子开始。稍后我们会清理代码。
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: “Fear is a path to the dark side young one, be brave and speak your truth. What
    makes you think she might feel the same?”
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “恐惧是通向黑暗面的道路，年轻人，要勇敢并说出你的真相。是什么让你觉得她可能有同样的感觉？”
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: “Well, she always seems to be happy to see me and we have a lot in common. We’ve
    had some great conversations and laughs together. But I don’t want to ruin our
    friendship if she doesn’t feel the same way.”
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “好吧，她总是很高兴见到我，我们有很多共同点。我们有过一些很棒的对话和笑声。但如果她不感觉一样，我不想破坏我们的友谊。”
- en: 'From here, we can loop back and forth, appending responses to the prompt lists.
    Here is the clean code I promised:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，我们可以来回循环，将回应附加到提示列表中。这是我承诺的干净代码：
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We now have a method for automatically generating conversations for each of
    our user personas. But are they any good? We need a way to objectively evaluate
    the responses for our primary persona. But how could we possibly accomplish this
    with subjective text? We will build a 3rd GPT persona for evaluating itself!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一种自动生成每个用户角色对话的方法。但这些对话好吗？我们需要一种客观评估主要角色回应的方法。但是我们怎么可能用主观文本完成这一点呢？我们将为自我评估建立一个第三个GPT角色！
- en: Prompt Scoring
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示评分
- en: 'To evaluate the conversational skills of our “space wizard”, we will create
    a new prompt:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估我们“太空巫师”的对话技能，我们将创建一个新的提示：
- en: 'On a 10-scale, rate the Wizard responses from the conversation below based
    on the following criteria:'
  id: totrans-52
  prefs:
  - PREF_BQ
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在10分制下，根据以下标准为巫师的回应打分：
- en: ''
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Character: the Wizard is a short, green, pointy-eared space wizard that uses
    laser swords in a galaxy far, far away. All responses should fit this persona.'
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 角色：巫师是一个短小、绿色、尖耳的太空巫师，在一个遥远的星系中使用激光剑。所有回应应符合这一角色。
- en: ''
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Conversational: responses should be brief and conversational. Follow-up questions
    should move the conversation forward without being tedious. The Wizard should
    wrap up the conversation appropriately.'
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对话：回应应简洁而对话化。跟进问题应推动对话向前发展，而不至于乏味。巫师应适当地结束对话。
- en: ''
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Helpful: Responses should help the User answer their question or solve their
    problem. Follow-up questions should help gather information to improve the response.'
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 有用：回应应帮助用户回答他们的问题或解决他们的问题。跟进问题应帮助收集信息以改善回应。
- en: ''
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Present the scores in JSON format as follows:'
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 以 JSON 格式呈现分数，如下所示：
- en: '{“Character”:<float>,”Conversational”:<float>,”Helpful”:<float>}'
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '{“Character”:<float>,”Conversational”:<float>,”Helpful”:<float>}'
- en: Please provide scores without commentary.###
  id: totrans-62
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 请提供不带评论的评分。###
- en: '[PRE3]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '{‘Character’: 8.5, ‘Conversational’: 9, ‘Helpful’: 9}'
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '{‘Character’: 8.5, ‘Conversational’: 9, ‘Helpful’: 9}'
- en: 'We now have our scores! Aggregate these scores for all personas and we can
    get an overall score for the chatbot prompt we tested. This leaves us with one
    final question: How can we improve our prompt to raise these scores? Again, why
    don’t we ask just ask GPT? ***This is the way.***'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有了分数！将这些分数汇总到所有角色中，我们可以得到我们测试的聊天机器人提示的整体分数。这使我们面临一个最终的问题：我们如何改进我们的提示以提高这些分数？再说一次，为什么不直接问
    GPT 呢？***这就是方法。***
- en: Prompt Feedback
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 及时反馈
- en: 'For our feedback, we will follow this pattern:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的反馈，我们将遵循以下模式：
- en: Begin with the same prompt we used for scoring, but leave off the request to
    return a score.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从我们用来评分的相同提示开始，但省略要求返回分数的请求。
- en: Add the generated conversations to the prompt for evaluation
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将生成的对话添加到提示中进行评估
- en: Give instructions to generate an evaluation of the conversations based on the
    scoring criteria
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给出生成对话评估的指示，基于评分标准
- en: 'We start with the prompt:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从提示开始：
- en: 'Using the conversations below, evaluate the Wizard based on the following criteria:'
  id: totrans-72
  prefs:
  - PREF_BQ
  - PREF_H3
  type: TYPE_NORMAL
  zh: 根据以下对话内容，依据以下标准评估巫师：
- en: ''
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Character: the Wizard is a short, green, pointy-eared space wizard that uses
    laser swords in a galaxy far, far away. All responses should fit this persona.'
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 角色：巫师是一个短小、绿色、尖耳的太空巫师，在一个遥远的银河系中使用激光剑。所有回应应符合这一角色。
- en: ''
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Conversational: responses should be brief and conversational. Follow-up questions
    should move the conversation forward without being tedious. The Wizard should
    wrap up the conversation appropriately.'
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对话风格：回应应该简洁且富有对话性。后续问题应推动对话向前发展，而不显得冗长。巫师应适当地结束对话。
- en: ''
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Helpful: Responses should help the User by answering their question or solving
    their problem. Follow-up questions should help gather information to improve the
    response.###'
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 有帮助：回应应通过回答用户的问题或解决他们的问题来帮助用户。后续问题应有助于收集信息以改善回应。###
- en: ''
  id: totrans-79
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Here are the conversations:'
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这是对话：
- en: '[PRE4]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Character: Overall, the Wizard abides by their persona well and consistently
    uses language and phrases that align with their character. For example, “young
    padawan,” “may the force be with you,” and “regret leads to suffering” are all
    phrases one would expect to hear from a space wizard. The Wizard also uses language
    specific to their galaxy far far away, such as “laser-swords.” No improvements
    needed here.'
  id: totrans-82
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 角色：总体而言，巫师很好地遵守了他们的角色设定，并始终使用与其角色相符的语言和短语。例如，“年轻的学徒”，“愿力量与你同在”，以及“悔恨带来痛苦”都是人们期望从太空巫师那里听到的短语。巫师还使用了特定于他们的遥远银河系的语言，例如“激光剑”。这里不需要改进。
- en: ''
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Conversational: The Wizard is succinct and engaging in their responses, asking
    follow-up questions that move the conversation forward without being repetitive
    or tedious. For example, when the User says they’re afraid to tell their crush
    how they feel, the Wizard follows up with “What makes you hesitant to approach
    her?” This shows that the Wizard is actively listening to the User and trying
    to understand their perspective. Another good example is when the User says they
    don’t know what to say to their crush, the Wizard responds with “In situations
    like these, trust your feelings and the force will guide you.” This puts the focus
    back on the User and empowers them to come up with their own solution. Overall,
    the Wizard’s conversational tone is friendly, supportive, and non-judgmental.'
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对话风格：巫师在回应时要简洁且引人入胜，提出的后续问题应推动对话向前发展，而不会显得重复或乏味。例如，当用户说他们害怕向心仪的人表达感情时，巫师应接着问“是什么让你犹豫接近她？”这表明巫师在积极倾听用户并试图理解他们的观点。另一个好的例子是当用户说他们不知道对心仪的人说什么时，巫师可以回应“在这种情况下，相信你的感觉，力量会引导你。”这将重点放回用户身上，赋予他们提出自己解决方案的能力。总体而言，巫师的对话语气友好、支持且不带偏见。
- en: ''
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Helpful: The Wizard’s responses are helpful in that they give concrete advice
    and actionable steps for the User to take. For example, when the User says they’re
    afraid of rejection, the Wizard responds with “Have courage, you must…” and “Better
    to take a chance, you must.” This provides the User with encouragement and a push
    to take action. Another helpful response is when the User says they don’t know
    what to say to their crush, the Wizard suggests a simple invitation to coffee
    or a walk. This gives the User a specific idea of what to do next. Overall, the
    Wizard provides helpful advice that is tailored to the User’s specific situation.'
  id: totrans-86
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 有用：巫师的回应很有帮助，因为它们提供了具体的建议和可操作的步骤。例如，当用户说他们害怕拒绝时，巫师回应说“要有勇气，你必须……”和“最好还是冒险，你必须。”这给用户提供了鼓励和行动的推动。另一个有用的回应是，当用户说他们不知道对心仪对象说什么时，巫师建议简单地邀请喝咖啡或散步。这给用户提供了下一步要做的具体想法。总体来说，巫师提供了量身定制的、有针对性的建议。
- en: That was useful information but be careful, ***it’s a trap!*** Each GPT model
    has a max token limit. That means, if your conversations are too large or there
    are too many of them, you may receive errors with this step. In practice, I typically
    will filter down to the three lowest-scored conversations and submit those for
    evaluation.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这些信息很有用，但请小心，***这是一个陷阱！*** 每个GPT模型都有最大令牌限制。这意味着，如果你的对话过大或对话过多，你可能会在这一步遇到错误。实际上，我通常会筛选出三个得分最低的对话，并将其提交进行评估。
- en: Conclusion
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: You now have the tools to automatically generate scores and feedback for each
    of your prompt iterations. Of course, there is still a bit of work to be done.
    Not only can your chatbot prompts be tweaked, but the user and evaluation prompts
    can also be adjusted to better match what you are trying to accomplish. The important
    thing is, you can now iterate quickly, and make objective decisions. ***These
    ARE the techniques you are looking for.***
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在拥有了自动生成每次提示迭代的分数和反馈的工具。当然，还有一些工作需要完成。你不仅可以调整你的聊天机器人提示，还可以调整用户和评估提示，以更好地匹配你想要实现的目标。重要的是，你现在可以快速迭代，并做出客观决策。***这些就是你正在寻找的技巧。***
- en: About me
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于我
- en: 'I am a senior data scientist and part-time freelancer with over 12 years of
    experience. I am always looking to connect so please feel free to:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我是一名资深数据科学家和兼职自由职业者，拥有超过12年的经验。我一直在寻找联系机会，所以请随时：
- en: '[Connect with me on LinkedIn](https://www.linkedin.com/in/michael-a-malin/)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在LinkedIn上联系我](https://www.linkedin.com/in/michael-a-malin/)'
- en: '[Visit my website](http://modelforge.ai)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[访问我的网站](http://modelforge.ai)'
- en: '[Follow me on Twitter](https://twitter.com/alaska_malin)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在Twitter上关注我](https://twitter.com/alaska_malin)'
- en: '[See my other articles](https://michael-malin.medium.com/)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[查看我的其他文章](https://michael-malin.medium.com/)'
- en: '***Please feel free to comment below if you have any questions.***'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '***如果你有任何问题，请随时在下方留言。***'
