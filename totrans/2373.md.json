["```py\n**Topics\n------**\n**1\\. Feature scaling in different scenarios**\n\n   a. Feature scaling in PCA\n   b. Feature scaling in k-means\n   c. Feature scaling in KNN and SVM\n   d. Feature scaling in linear models\n   e. Feature scaling in neural networks\n   f. Feature scaling in the convergence\n   g. Feature scaling in tree-based algorithms\n   h. Feature scaling in LDA\n\n**2\\. Feature scaling methods**\n\n   a. Standardization\n   b. Min-Max Scaling (Normalization)\n   c. Robust Scaling\n   d. Mean Normalization\n   e. Maximum Absolute Scaling\n   f. Vector Unit-Length Scaling\n\n**3\\. Feature scaling and distribution of data\n\n4\\. Data leakage when feature scaling\n\n5\\. Summary of feature scaling methods**\n```", "```py\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nsc.fit(data)\nscaled_data = sc.transform(data)\n```", "```py\nfrom sklearn.preprocessing import MinMaxScaler\n\nsc = MinMaxScaler(feature_range=(0,1))\nsc.fit(data)\nscaled_data = sc.transform(data)\n```", "```py\nfrom sklearn.preprocessing import RobustScaler\n\nsc = RobustScaler()\nsc.fit(data)\nscaled_data = sc.transform(data)\n```", "```py\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\n\nss = StandardScaler(with_mean=True, with_std=False)\nrs = RobustScaler(with_centering=False, quantile_range=(0, 100))\n\nmean_normalizer = Pipeline([('Std_Scaler', ss),\n                            ('Rob_Scaler', rs)\n])\n\nmean_normalizer.fit(data)\nscaled_data = mean_normalizer.transform(data)\n```", "```py\nss = StandardScaler(with_mean=True, with_std=False)\n```", "```py\nrs = RobustScaler(with_centering=False, quantile_range=(0, 100))\n```", "```py\nfrom sklearn.preprocessing import MaxAbsScaler\n\nsc = MaxAbsScaler()\nsc.fit(data)\nscaled_data = sc.transform(data)\n```", "```py\nOb1 = (2, 3, 5)\n\nLength of Ob1 = Sqrt(2² + 3² + 5²) = Sqrt(38) --> Euclidean distance (L2 norm)\n\nUnit Vector = [2/Sqrt(38), 3/Sqrt(38), 5/Sqrt(38)]\n\nLength of Unit Vector = 1\n```", "```py\nfrom sklearn.preprocessing import Normalizer\n\nsc = Normalizer(norm='l2')\nsc.fit(data)\nscaled_data = sc.transform(data)\n```", "```py\n# Load iris data\nfrom sklearn.datasets import load_iris\n\niris_data = load_iris().data\np = iris_data[:, 0] # Select the first feature\n\n# Apply feature standardization\nfrom sklearn.preprocessing import StandardScaler\np_scaled = StandardScaler().fit_transform(iris_data)[:, 0]\n```", "```py\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n\nfig = plt.figure(figsize=(5.5, 4))\nplt.hist(p, bins=20)\nplt.title(\"Before scaling\")\nplt.show()\n```", "```py\nfig = plt.figure(figsize=(5.5, 4))\nplt.hist(p_scaled, bins=20, color='green')\nplt.title(\"After scaling\")\nplt.show()\n```", "```py\nimport numpy as np\n\nnp.min(p), np.max(p) # Before scaling\n```", "```py\nnp.min(p_scaled), np.max(p_scaled) # After scaling\n```", "```py\nfrom sklearn.datasets import load_iris\nX = load_iris().data\ny = load_iris().target\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_scaled = sc.fit_transform(X)\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, \n                                                    test_size=0.20,\n                                                    random_state=42)\n```", "```py\nfrom sklearn.datasets import load_iris\nX = load_iris().data\ny = load_iris().target\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20,\n                                                    random_state=42)\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit(X_train)\nX_train_scaled = sc.transform(X_train)\nX_test_scaled = sc.transform(X_test)\n```", "```py\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train_scaled = sc.fit_transform(X_train)\nX_test_scaled = sc.fit_transform(X_test)\n```", "```py\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train_scaled = sc.fit_transform(X_train)\nX_test_scaled = sc.transform(X_test)\n\n# Or\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit(X_train)\nX_train_scaled = sc.transform(X_train)\nX_test_scaled = sc.transform(X_test)\n```"]