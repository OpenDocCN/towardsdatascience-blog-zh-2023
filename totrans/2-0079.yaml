- en: 4 Faster Pandas Alternatives for Data Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/4-faster-pandas-alternatives-for-data-analysis-1ff787d795](https://towardsdatascience.com/4-faster-pandas-alternatives-for-data-analysis-1ff787d795)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Performance Benchmark on Popular Data Analysis Tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://chengzhizhao.medium.com/?source=post_page-----1ff787d795--------------------------------)[![Chengzhi
    Zhao](../Images/186bba91822dbcc0f926426e56faf543.png)](https://chengzhizhao.medium.com/?source=post_page-----1ff787d795--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1ff787d795--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1ff787d795--------------------------------)
    [Chengzhi Zhao](https://chengzhizhao.medium.com/?source=post_page-----1ff787d795--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1ff787d795--------------------------------)
    ·9 min read·Feb 9, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5bcd0c2d4c70afe2ff9a9f29d02c97e8.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Mateusz Butkiewicz](https://unsplash.com/@puszkins?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Pandas is no doubt one of the most popular libraries in Python. Its DataFrame
    is intuitive and has rich APIs for data manipulation tasks. Many Python libraries
    integrated with Pandas DataFrame to increase their adoption rate.
  prefs: []
  type: TYPE_NORMAL
- en: However, Pandas doesn’t shine in the land of data processing with a large dataset.
    It is predominantly used for data analysis on a single machine, not a cluster
    of machines. In this article, I will try to measure performance for **Polars,
    DuckDB, Vaex, and Modin as alternatives to compare with Pandas.**
  prefs: []
  type: TYPE_NORMAL
- en: '[Database-like ops benchmark](https://h2oai.github.io/db-benchmark/) published
    by [h2oai](https://h2oai.github.io/) inspires the idea of this post. The benchmark
    experiment was conducted in May 2021\. This article is to review this field after
    two years with many feature and improvements.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Why is Pandas slow on large datasets?**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The main reason is that Pandas wasn’t designed to run on multiple cores. Pandas
    **uses only one CPU core at a time to perform the data manipulation tasks** and
    takes no advantage on modern PC with multiple cores on parallelism.
  prefs: []
  type: TYPE_NORMAL
- en: How to mitigate the issue when data size is large (still can fit on one machine)
    but Pandas takes time to execute? One solution is to leverage a framework like
    Apache Spark to perform data manipulation tasks utilizing clusters. But sometimes,
    data analysis can be done more efficiently by sampling data and analyze on a single
    machine.
  prefs: []
  type: TYPE_NORMAL
- en: If you prefer to stay on a single machine, let’s review **Polars, DuckDB, Vaex,
    and Modin** as alternatives to compare with Pandasin this article. To measure
    how long it takes to process extensive data, I will share the performance benchmark
    on a single machine.
  prefs: []
  type: TYPE_NORMAL
- en: Performance Evaluation Preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**The specs of the tested machine**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: MacBook Pro (13-inch, 2020, Four Thunderbolt 3 ports)
  prefs: []
  type: TYPE_NORMAL
- en: 'CPU: 2 GHz Quad-Core Intel Core i5 (4 cores)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Memory: 16 GB 3733 MHz LPDDR4X'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'OS: MacOS Monterey 12.2'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The test dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this case, a medium-large dataset for the process would be good enough to
    show the differences. The [NYC Parking Tickets](https://www.kaggle.com/new-york-city/nyc-parking-tickets)[1]
    are a good dataset for this evaluation. It has 42.3M rows from Aug 2013-June 2017
    with 51 columns including Registration State, Vehicle Make, and Vehicle Color
    that are interesting to know the insights. We will use the fiscal 2017 dataset
    with 10.8M rows, and the file size is about 2.09G.
  prefs: []
  type: TYPE_NORMAL
- en: The evaluation process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Due to the entire running time that includes reading the data into memory, it
    is necessary to consider the data loading separately.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’d process the same call 5**x times** to avoid edge cases and use the median
    value to report as our final performance result.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Helper function to repeat and compute the median
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '***Warning****: we will show a lot of code, so it’s easier for readers on what
    I did instead of either not showing the process or pointing you to a GitHub. If
    you don’t bother about the process, please skip and proceed to the result at the
    bottom.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pandas: The Baseline'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To set up the baseline for comparison, we shall examine the famous use cases
    for daily analytics jobs: **filter, aggregation, joins, and window function.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**filter**: find the Vehicle Make is BMW'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**aggregation**: group by Vehicle Make and perform count'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**join**: SELF join on Summons Number'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**window function**: rank the Vehicle Make based on the count of the'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I selected on only the used fields for our testing, which are `‘Summons Number’,
    ‘Vehicle Make’, ‘Issue Date’` . Note if I choose to select everything, the last
    two queries run significantly slower.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'DuckDb: Efficient OLAP In-Process DB'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[DuckDB](https://duckdb.org/) is gaining popularity as its columnar-vectorized
    engine powers analytical types of queries. It’s an analytical or OLAP version
    of [SQLite](https://sqlite.org/), a widely adopted simple embedded in-process
    DBMS.'
  prefs: []
  type: TYPE_NORMAL
- en: Although it’s a DBMS, installation isn’t complex compared to Microsoft SQL Server
    or Postgres; Additionally, no external dependencies are required to run a query.
    I am astonished how easy it is to execute a SQL query with [DuckDb CLI](https://duckdb.org/docs/api/cli.html).
  prefs: []
  type: TYPE_NORMAL
- en: If you prefer SQL interface, DuckDb might be your best alternative to performing
    data analysis directly on CSV or Parquet file. Let’s continue with some code examples
    and simultaneously show how straightforward it is to work with SQL with DuckDb.
  prefs: []
  type: TYPE_NORMAL
- en: DuckDb has a magic `read_csv_auto` function to infer a CSV file and load that
    data into memory. At runtime, I found I have to change `SAMPLE_SIZE=-1` to skip
    sampling due some fields in my dataset isn’t inferred correctly, with sample is
    default as 1,000 rows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The result on DuckDb is impressive. We have the filter test at parity but much
    better performance in the rest three tests compared with pandas.
  prefs: []
  type: TYPE_NORMAL
- en: If you are not comfortable writing Python, you can use the DuckDb CLI with SQL
    interface in command line or [TAD](https://duckdb.org/docs/guides/data_viewers/tad)
    easily.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/be0704db6ce878cf11e77afb37e64846.png)'
  prefs: []
  type: TYPE_IMG
- en: Author Shows how to use SQL to query DuckDB via CLI | Image By Author
  prefs: []
  type: TYPE_NORMAL
- en: 'Polars: Astonishing Fast Build On Rust + Arrow'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Ritchie Vink](https://github.com/ritchie46) created [Polars](https://github.com/pola-rs/polars).
    Ritchie also has a blog post, “[I wrote one of the fastest DataFrame libraries](https://www.ritchievink.com/blog/2021/02/28/i-wrote-one-of-the-fastest-dataframe-libraries/),”
    and it was well-received. The impressive part for Polars is that on the [Database-like
    ops benchmark](https://h2oai.github.io/db-benchmark/) by h2oai, it ranked the
    top on the group by and join operations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few reasons Polars can replace Pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: Polars starts with the parallelization of DataFrame from the beginning. It doesn’t
    restrict itself to single-core operation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PyPolars is Rust-based with Python bindings, which has outstanding performance
    comparable to C, and “Arrow Columnar Format” is an excellent choice for the analytics
    OLAP type query.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lazy evaluation: plan (not execute) the query until triggered. This can be
    used to optimize queries like additional pushdown further.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: WOW, Polars is blazingly fast! Coding in Polars give you a feeling of mixed
    pySpark and Pandas, but the interface is so familiar, and it took less than 15
    mins for me to write the query above with no experience with Polars API. You can
    refer [Polars documentation on Python](https://pola-rs.github.io/polars/py-polars/html/reference/index.html)
    to comprehend it quickly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Vaex: Out-of-Core DataFrames'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Vaex is another alternative that does the lazy evaluation, avoiding additional
    memory wastage for performance penalty. It uses memory mapping and will only execute
    when explicitly asked to. Vaex has a set of handy data visualizations, making
    it easier to explore the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Vaex has implemented parallelized group by, and it’s efficient on join.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: However, I found the window function isn’t implemented, and [open issue](https://github.com/vaexio/vaex/issues/804)
    tracked here. We can iterate by each group and assign each row a value with the
    suggestion mentioned in this [issue](https://github.com/vaexio/vaex/issues/250#issuecomment-491027460).
    However, I didn’t find the window function implemented out of the box for Vaex.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Modin: Scale pandas by changing one line of code'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With a line of the code change, will Modin enable user better performance than
    Pandas? In Modin, it is to do the following change, replace the Pandas library
    with Modin.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: However, there is still [a list of implementations](https://modin.readthedocs.io/en/stable/supported_apis/dataframe_supported.html)
    that still need to be done in Modin. Besides code change, we’d still need to set
    up its backend for scheduling. I tried to use *Ray* in this example.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The window function on Modin hasn’t been supported on Ray, so it still uses
    the Pandas implementation. The time spent is closer to Pandas on window function.
  prefs: []
  type: TYPE_NORMAL
- en: (py)datatable
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you come from R community, `data.table` it shouldn’t be a unfamiliar package.
    As any package gets popular, its core idea will be brought to the other languages.
    (py)datatable is one the attempts to mimic R’s `data.table` core algorithms and
    API.
  prefs: []
  type: TYPE_NORMAL
- en: However, during testing, this doesn’t work well to qualify faster than pandas,
    given the syntax is similar to R’s `data.table` I think it’s nice to mention here
    as a Pandas alternative.
  prefs: []
  type: TYPE_NORMAL
- en: Result
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/cccce809f6e7d8d2d2e45640379fec04.png)'
  prefs: []
  type: TYPE_IMG
- en: Final Comparison | Image By Author
  prefs: []
  type: TYPE_NORMAL
- en: Final Thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Those are Pandas alternatives that gave users better performance for the cases
    I tested. At the same time, the API change is not significant to Pandas. If you
    consider one of those libraries, it should be a smooth transition. On the other
    hand, Pandas still hold the best coverage on functionality for APIs. The alternative
    solutions are short for advanced API support like window function.
  prefs: []
  type: TYPE_NORMAL
- en: Running Pandas on a single machine is still the best option for data analysis
    or ad-hoc queries. The alternative libraries may boost the performance in some
    cases, but only sometimes in all cases on a single machine.
  prefs: []
  type: TYPE_NORMAL
- en: '**Let me know what you think is the best alternative to Pandas you’d choose
    by leaving comments.**'
  prefs: []
  type: TYPE_NORMAL
- en: '[1] NYC Parking Tickets Dataset, CITY OF NEW YORK, [CC0: Public Domain](https://creativecommons.org/publicdomain/zero/1.0/),
    [https://www.kaggle.com/datasets/new-york-city/nyc-parking-tickets](https://www.kaggle.com/datasets/new-york-city/nyc-parking-tickets)'
  prefs: []
  type: TYPE_NORMAL
- en: 'I hope this story is helpful to you. This article is **part of a series** of
    my engineering & data science stories that currently consist of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chengzhi Zhao](../Images/51b8d26809e870b4733e4e5b6d982a9f.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Chengzhi Zhao](https://chengzhizhao.medium.com/?source=post_page-----1ff787d795--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Data Engineering & Data Science Stories
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://chengzhizhao.medium.com/list/data-engineering-data-science-stories-ddab37f718e7?source=post_page-----1ff787d795--------------------------------)53
    stories![](../Images/8b5085966553259eef85cc643e6907fa.png)![](../Images/9dcdca1fc00a5694849b2c6f36f038d4.png)![](../Images/2a6b2af56aa4d87fa1c30407e49c78f7.png)'
  prefs: []
  type: TYPE_NORMAL
- en: You can also [**subscribe to my new articles**](https://chengzhizhao.medium.com/subscribe)
    or become a [**referred Medium member**](https://chengzhizhao.medium.com/membership)who
    gets unlimited access to all the stories on Medium.
  prefs: []
  type: TYPE_NORMAL
- en: In case of questions/comments, **do not hesitate to write in the comments**
    of this story or **reach me directly** through [Linkedin](https://www.linkedin.com/in/chengzhizhao/)
    or [Twitter](https://twitter.com/ChengzhiZhao).
  prefs: []
  type: TYPE_NORMAL
