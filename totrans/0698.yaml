- en: 'Deep Learning in Recommender Systems: A Primer'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/deep-learning-in-recommender-systems-a-primer-96e4b07b54ca](https://towardsdatascience.com/deep-learning-in-recommender-systems-a-primer-96e4b07b54ca)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A tour of the most important technological breakthroughs behind modern industrial
    recommender systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@samuel.flender?source=post_page-----96e4b07b54ca--------------------------------)[![Samuel
    Flender](../Images/390d82a673de8a8bb11cef66978269b5.png)](https://medium.com/@samuel.flender?source=post_page-----96e4b07b54ca--------------------------------)[](https://towardsdatascience.com/?source=post_page-----96e4b07b54ca--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----96e4b07b54ca--------------------------------)
    [Samuel Flender](https://medium.com/@samuel.flender?source=post_page-----96e4b07b54ca--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----96e4b07b54ca--------------------------------)
    ·9 min read·Jun 26, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b5168e4df2a891b3242b01347e9ac486.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image credit: [Pixabay](https://pixabay.com/illustrations/network-cloud-computing-data-4851119/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Recommender systems are among the fastest-evolving industrial Machine Learning
    applications today. From a business point of view, this is not a surprise: better
    recommendations bring more users. It’s as simple as that.'
  prefs: []
  type: TYPE_NORMAL
- en: The underlying technology however is far from simple. Ever since the rise of
    deep learning — [powered by the commoditization of GPUs](/algorithms-are-not-enough-fdee1d65e536)
    — recommender systems have become more and more complex.
  prefs: []
  type: TYPE_NORMAL
- en: In this post, we’ll take a tour of a handful of the most important modeling
    breakthroughs from the past decade, roughly reconstructing the pivotal points
    marking the rise of deep learning in recommender systems. It’s a story of technological
    breakthroughs, scientific exploration, and an arms race spanning continents and
    cooperations.
  prefs: []
  type: TYPE_NORMAL
- en: Buckle up. Our tour starts in 2017’s Singapore.
  prefs: []
  type: TYPE_NORMAL
- en: NCF (Singapore University, 2017)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/fd240f60ca9cd1b84333433f89cc813c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image credit: [He et al (2017)](https://arxiv.org/abs/1708.05031)'
  prefs: []
  type: TYPE_NORMAL
- en: Any discussion of deep learning in recommender systems would be incomplete without
    a mention of one of the most important breakthroughs in the field, Neural Collaborative
    Filtering (NCF), introduced in [He et al (2017)](https://arxiv.org/abs/1708.05031)
    from the University of Singapore.
  prefs: []
  type: TYPE_NORMAL
- en: Prior to NCF, the gold standard in recommender systems was matrix factorization,
    in which we learn latent vectors (aka embeddings) for both users and items, and
    then generate recommendations for a user by taking the dot product between the
    user vector and the item vectors. The closer the dot product is to 1, as we know
    from linear algebra, the better the predicted match. As such, matrix factorization
    can be simply viewed as a linear model of latent factors.
  prefs: []
  type: TYPE_NORMAL
- en: The key idea in NCF is to replace the inner product in matrix factorization
    with a neural network. In practice, this is done by first concatenating the user
    and item embeddings, and then passing them into a multi-layer perceptron (MLP)
    with a single task head that predicts user engagement such as click. Both the
    MLP weights and the embedding weights (which map ids to their respective embeddings)
    are then learned during model training via backpropagation of loss gradients.
  prefs: []
  type: TYPE_NORMAL
- en: The hypothesis behind NCF is that user/item interactions aren’t linear, as assumed
    in matrix factorization, but instead non-linear. If that’s true, we should see
    better performance as we add more layers to the MLP. And that’s precisely what
    He et al find. With 4 layers, they’re able to beat the best matrix factorization
    algorithms at the time by around 5% hit rate on the Movielens and Pinterest benchmark
    datasets.
  prefs: []
  type: TYPE_NORMAL
- en: He et al proved that there’s immense value of deep learning in recommender systems,
    marking the pivotal transition away from matrix factorization and towards deep
    recommenders.
  prefs: []
  type: TYPE_NORMAL
- en: Wide & Deep (Google, 2016)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/66bc799ed29146e926b4c19f07eec6ef.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image credit: [Cheng et al (2016)](https://arxiv.org/abs/1606.07792)'
  prefs: []
  type: TYPE_NORMAL
- en: Our tour continues from Singapore to Mountain View, California.
  prefs: []
  type: TYPE_NORMAL
- en: 'While NCF revolutionized the domain of recommender system, it lacks an important
    ingredient that turned out to be extremely important for the success of recommenders:
    cross features. The idea of cross features has been popularized in Google’s 2016
    paper “[Wide & Deep Learning for Recommender Systems](https://arxiv.org/abs/1606.07792)”.'
  prefs: []
  type: TYPE_NORMAL
- en: What is a cross feature? It’s a second-order feature that’s created by “crossing”
    two of the original features. For example, in the Google Play Store, first-order
    features include the impressed app, or the list of user-installed apps. These
    two can be combined to create powerful cross-features, such as
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: which is 1 if the user has Netflix installed and the impressed app is Hulu.
  prefs: []
  type: TYPE_NORMAL
- en: Cross features can also be more generalized such as
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: and so on. The authors argue that adding cross features of different granularities
    enables both memorization (from more granular crosses) and generalization (from
    less granular crosses).
  prefs: []
  type: TYPE_NORMAL
- en: The key architectural choice in Wide&Deep is to have both a wide module, which
    is a linear layer that takes all cross features directly as inputs, and a deep
    module, which is essentially an NCF, and then combine both modules into a single
    output task head that learns from user/app engagements.
  prefs: []
  type: TYPE_NORMAL
- en: 'And indeed, Wide&Deep works remarkably well: the authors find a lift in online
    app acquisitions of 1% by going from deep-only to wide and deep. Consider that
    Google makes tens of Billions in revenue each year from its Play Store, and it’s
    easy to see how impactful Wide&Deep was.'
  prefs: []
  type: TYPE_NORMAL
- en: DCN (Google, 2017)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/70104138435cbf8b93f8dc55dfc9ddd0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image credit: [Wang et al (2017)](https://arxiv.org/pdf/1708.05123.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Wide&Deep has proven the significance of cross features, however it has a huge
    downside: the cross features need to be manually engineered, which is a tedious
    process that requires engineering resources, infrastructure, and domain expertise.
    Cross features à la Wide & Deep are expensive. They don’t scale.'
  prefs: []
  type: TYPE_NORMAL
- en: Enter “[Deep and Cross neural networks](https://arxiv.org/pdf/1708.05123.pdf)”
    (DCN), introduced in a 2017 paper, also from Google. The key idea in DCN is to
    replace the wide component in Wide&Deep with a “cross neural network”, a neural
    network dedicated to learning cross features of arbitrarily high order.
  prefs: []
  type: TYPE_NORMAL
- en: 'What makes a cross neural network different from a standard MLP? As a reminder,
    in an MLP, each neuron in the next layer is a linear combination of all layers
    in the previous layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/62a1b6e50deae84849e47994ce7eb7b1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'By contrast, in the cross neural network the next layer is constructed by forming
    second-order combinations of the first layer with itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6eb9f66786bbed85a41d9e5c8ab9cd89.png)'
  prefs: []
  type: TYPE_IMG
- en: Hence, a cross neural network of depth L will learn cross features in the form
    of polynomials of degrees up to L. The deeper the neural network, the higher-order
    interactions are learned.
  prefs: []
  type: TYPE_NORMAL
- en: And indeed, the experiments confirm that DCN works. Compared to a model with
    just the deep component, DCN has a 0.1% lower logloss (which is considered to
    be statistically significant) on the Criteo display ads benchmark dataset. And
    that’s without any manual feature engineering, as in Wide&Deep!
  prefs: []
  type: TYPE_NORMAL
- en: (It would have been nice to see a comparison between DCN and Wide&Deep. Alas,
    the authors of DCN didn’t have a good method to manually create cross features
    for the Criteo dataset, and hence skipped this comparison.)
  prefs: []
  type: TYPE_NORMAL
- en: DeepFM (Huawei, 2017)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/8adc12a29cdf378d7e7ec26f22abb03a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image credit: [Guo et al (2017)](https://arxiv.org/abs/1703.04247)'
  prefs: []
  type: TYPE_NORMAL
- en: Next, our tour takes us from 2017’s Google to 2017’s Huawei.
  prefs: []
  type: TYPE_NORMAL
- en: Huawei’s solution for deep recommendation, “[DeepFM](https://arxiv.org/abs/1703.04247)”,
    also replaces manual feature engineering in the wide component of Wide&Deep with
    a dedicated neural network that learns cross features. However, unlike DCN, the
    wide component is not a cross neural network, but instead a so-called FM (“factorization
    machine”) layer.
  prefs: []
  type: TYPE_NORMAL
- en: What does the FM layer do? It’s simply taking the dot-products of all pairs
    of embeddings. For example, if a movie recommender takes 4 id-features as inputs,
    such as user id, movie id, actor ids, and director id, then the model learns embeddings
    for all of these id features, and the FM layer computes 6 dot products, corresponding
    to the combinations user-movie, user-actor, user-director, movie-actor, movie-director,
    and actor-director. It’s a comeback of the idea of matrix factorization. The output
    of the FM layer is then combined with the output of the deep component into a
    sigmoid-activated output, resulting in the model’s prediction.
  prefs: []
  type: TYPE_NORMAL
- en: And indeed, as you may have guessed, DeepFM has been shown to work. The authors
    show that DeepFM beats a host of the competitors (including Google’s Wide&Deep)
    by more than 0.37% and 0.42% in terms of AUC and Logloss, respectively, on company-internal
    data.
  prefs: []
  type: TYPE_NORMAL
- en: DLRM (Meta, 2019)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/6889940b6c0218d3caaf74460184f84b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image credit: [Naumov et al (2019)](https://arxiv.org/abs/1906.00091)'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s leave Google and Huawei for now. The next stop on our tour is 2019’s Meta.
  prefs: []
  type: TYPE_NORMAL
- en: 'Meta’s DLRM (“deep learning for recommender systems”) architecture, presented
    in [Naumov et al (2019)](https://arxiv.org/abs/1906.00091), works as follows:
    all categorical features are transformed into embeddings using embedding tables.
    All dense features are being passed into an MLP that computes embeddings for them
    as well. Importantly, all embeddings have the same dimension. Then, we simply
    compute the dot products of all pairs of embeddings, concatenate them into a single
    vector, and pass that vector through a final MLP with a single sigmoid-activated
    task head that produces the prediction.'
  prefs: []
  type: TYPE_NORMAL
- en: 'DLRM, then, is almost something like a simplified version of DeepFM: if you
    take DeepFM and drop the deep component (keeping just the FM component), you have
    something like DLRM, but without DLRM’s dense MLP.'
  prefs: []
  type: TYPE_NORMAL
- en: In experiments, Naumov et al show that DLRM beats DCN in terms of both training
    and validation accuracy on the Criteo display ads benchmark dataset. This result
    indicates that the deep component in DCN may indeed be redundant, and all that
    we really need in order to make the best possible recommendations are just the
    feature interactions, which in DLRM are captured with the dot products.
  prefs: []
  type: TYPE_NORMAL
- en: DHEN (Meta, 2022)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/6adf06ffcec687055262c4b769443978.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image credit: [Zhang et al (2022)](https://arxiv.org/abs/2203.11014)'
  prefs: []
  type: TYPE_NORMAL
- en: 'In contrast to DCN, the feature interactions in DLRM are limited to be second-order
    only: they’re just dot products of all pairs of embeddings. Going back to the
    movie example (with features user, movie, actors, director), the second-order
    interactions would be user-movie, user-actor, user-director, movie-actor, movie-director,
    and actor-director. A third-order interaction would be something like user-movie-director,
    actor-actor-user, director-actor-user, and so on. Certain users may be fans of
    Steven Spielberg movies starring Tom Hanks, and there should be a cross feature
    for that! Alas, in standard DLRM, there isn’t. That’s a major limitation.'
  prefs: []
  type: TYPE_NORMAL
- en: Enter [DHEN](https://arxiv.org/abs/2203.11014), the final landmark paper in
    our tour of modern recommender systems. DHEN stands for “Deep Hierarchical Ensemble
    Network”, and the key idea is to create a “hierarchy” of cross features that grows
    deeper with the number of DHEN layers.
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s easiest to understand DHEN with a simple example first. Suppose we have
    two input features going into DHEN, and let’s denote them by A and B (which could
    stand for user ids and video ids, for example). A 2-layer DHEN module would then
    create the entire hierarchy of cross features up to second order, namely:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'where “x” is either one or a combination of the following 5 interactions:'
  prefs: []
  type: TYPE_NORMAL
- en: dot product,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: self-attention,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: convolution,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'linear: y = Wx, or'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the cross module from DCN.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DHEN is a beast, and its computational complexity (due to its recursive nature)
    is nightmare. In order to get it to work, the authors of the DHEN paper had to
    invent a new [distributed training](/distributed-learning-a-primer-790812b817f1)
    paradigm called “Hybrid Sharded Data Parallel”, which achieves 1.2X higher throughput
    than the (then) state-of-the-art.
  prefs: []
  type: TYPE_NORMAL
- en: 'But most importantly, the beast works: in their experiments on internal click-through
    rate data, the authors measure a 0.27% improvement in NE compared to DLRM, using
    a stack of 8 (!) DHEN layers.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/8adc72dde9170f899402770469b0e632.png)'
  prefs: []
  type: TYPE_IMG
- en: Evolution of the Criteo display ads competition leaderboard. Screenshot from
    [paperswithcode.com](https://paperswithcode.com/sota/click-through-rate-prediction-on-criteo).
  prefs: []
  type: TYPE_NORMAL
- en: 'And this concludes our tour. Allow me to summarize each of these landmarks
    with a single headline:'
  prefs: []
  type: TYPE_NORMAL
- en: '**NCF**: All we need are embeddings for users and items. The MLP will handle
    the rest.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Wide&Deep**: Cross features matter. In fact, they’re so important we feed
    them directly into the task head.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DCN**: Cross features matter, but shouldn’t be engineered by hand. Let the
    cross neural network handle that.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DeepFM**: Let’s generate cross features in the FM layer instead, and still
    keep the deep component from Wide&Deep.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DRLM**: FM is all we need — and also another, dedicated MLP for dense features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DHEN**: FM is not enough. We need a hierarchy of higher-order (beyond second
    order), hierarchical feature interactions. And also a bunch of optimizations to
    make it work in practice.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And the journey is really just getting started. At the time of this writing,
    DCN has evolved into DCN-M, DeepFM has evolved into xDeepFM, and the leaderboard
    of the Criteo competition has been claimed by Huawei’s latest invention, FinalMLP.
  prefs: []
  type: TYPE_NORMAL
- en: Given the huge economic incentive for better recommendations, it’s guaranteed
    that we’ll continue to see new breakthroughs in this domain for the foreseeable
    future. Watch this space.
  prefs: []
  type: TYPE_NORMAL
