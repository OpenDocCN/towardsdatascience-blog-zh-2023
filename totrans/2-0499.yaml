- en: 'ChatGPT Generated Food Industry Reviews: Realism Assessment'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/chatgpt-generated-food-industry-reviews-realism-assessment-2ee28155970f](https://towardsdatascience.com/chatgpt-generated-food-industry-reviews-realism-assessment-2ee28155970f)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Investigating how review and survey collection by food industry companies can
    be supported by ChatGPT-generated data.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://ben-mccloskey20.medium.com/?source=post_page-----2ee28155970f--------------------------------)[![Benjamin
    McCloskey](../Images/7118f5933f2affe2a7a4d3375452fa4c.png)](https://ben-mccloskey20.medium.com/?source=post_page-----2ee28155970f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2ee28155970f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2ee28155970f--------------------------------)
    [Benjamin McCloskey](https://ben-mccloskey20.medium.com/?source=post_page-----2ee28155970f--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2ee28155970f--------------------------------)
    ·13 min read·Jun 9, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/45ea0b6597515a537982a20603e6b762.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Annie Spratt](https://unsplash.com/@anniespratt?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Where It Started
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The bulk of my research in the past used *Generative Adversarial Networks (GAN)*
    for creating deepfake images of my dataset. I wanted to do this to increase the
    diversity of information within my dataset, which I predicted would result in
    better object detection models (s[ee more about this research here!](https://journals.sagepub.com/doi/abs/10.1177/15485129231170225?journalCode=dmsa)).
    While a completely different task than deepfake image creation, I wondered; ***is
    there a way to increase the size of the datasets I used containing reviews for
    different companies in the food industry?***
  prefs: []
  type: TYPE_NORMAL
- en: Could I train a GAN? Yes, but GANs are not great at generating tabular data,
    and to me, words in the text are more aligned with data found in spreadsheets.
    Then came ChatGPT. Voila! Could I create new reviews for my dataset by simply
    *asking* ChatGPT to generate them with different prompts?
  prefs: []
  type: TYPE_NORMAL
- en: Why It Matters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a few reasons we would want to increase the size of a dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Lacking enough data to train a model.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Biased dataset (hence we need to bias it with the underrepresented class of
    data).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Lack of diversity within the dataset
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The datasets I was creating (with the approval from the company I used in my
    example today) lacked negative reviews, review diversity, and size, warranting
    an implementation of dataset augmentation.
  prefs: []
  type: TYPE_NORMAL
- en: '**Lacking enough data to train a model**. If you attempt to build a model with
    a lack of data, a multitude of problems could occur. One problem may be the model
    overfits the data and performs poorly on real-world examples.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Biased dataset**. If a dataset is dominated by one class, it lacks representations
    for other classes which will lead to models and analyses unfit for said class.
    We want to have a balanced dataset to ensure our model performs well in operations
    across all classes of data we are interested in investigating.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Lack of diversity within the dataset.** The real world is messy. If our dataset
    lacks diversity, our model will not *generalize* well to changes in the details
    of samples once put into production. **Generalizability** is the model’s ability
    to classify or know a sample belongs to a certain class, even if that sample contains
    features that are distinct from or underrepresented in the class it belongs to.'
  prefs: []
  type: TYPE_NORMAL
- en: The Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following APIs were used for today’s analysis.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The original dataset was compiled together with the permission of the company
    (Altomontes Inc) to use the reviews (see these two articles where I show how to
    use Natural Language Processing on the reviews).
  prefs: []
  type: TYPE_NORMAL
- en: '[](/machine-learning-is-not-just-for-big-tech-using-natural-language-processing-to-support-small-8f571249c073?source=post_page-----2ee28155970f--------------------------------)
    [## Machine Learning is Not Just for Big Tech'
  prefs: []
  type: TYPE_NORMAL
- en: Using Natural Language Processing to Support Small Businesses.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/machine-learning-is-not-just-for-big-tech-using-natural-language-processing-to-support-small-8f571249c073?source=post_page-----2ee28155970f--------------------------------)
    [](/topic-modeling-analysis-for-small-businesses-73ba23474261?source=post_page-----2ee28155970f--------------------------------)
    [## Topic Modeling Analysis for Small Businesses
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/topic-modeling-analysis-for-small-businesses-73ba23474261?source=post_page-----2ee28155970f--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '**Example of an original review:**'
  prefs: []
  type: TYPE_NORMAL
- en: '*“Highly recommend!!! I never knew about Altomontes until a friend dropped
    off a meal at my house recently. My husband and I decided to go and check it out
    and while we were there, we met the owner and she was the sweetest person ever!
    She basically gave us a tour. We bought the chicken marsala for dinner and it
    was wonderful! We also bought the Brooklyn pizza for lunch and it was delicious!
    We sampled their coffee and they let us taste a cannoli, biscotti and a cookie.
    Very good! We bought shells, marinara sauce, a bottle of wine, some cheese etc.
    Everything looked good, taste good and we could spend hours there! We will be
    back!! Maybe today?”*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The next two datasets I created using ChatGPT. One contained positive reviews
    about an Italian Market and the goods it sells, while the other contained negative
    reviews about an Italian Market and the goods it sells.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example of a ChatGPT-generated positive review:**'
  prefs: []
  type: TYPE_NORMAL
- en: '*“The Pecorino Toscano cheese I bought had a robust and savory taste. Its firm
    and crumbly texture, with a hint of grassiness, made it a great choice for grating,
    shaving, or enjoying on its own.”*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Example of a ChatGPT-generated negative review:**'
  prefs: []
  type: TYPE_NORMAL
- en: '*”The prosciutto and arugula pizza I tried had wilted arugula and the prosciutto
    was tough. It wasn’t appetizing.”*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Once all of the reviews were created and placed into CSV files (find them [here](https://medium.com/towards-data-science/topic-modeling-analysis-for-small-businesses-73ba23474261)),
    I formatted them into a dictionary where each key was the source (source being
    ***original, generated positive***, or ***generated negative*** ) and the items
    were its reviews and a list of tuples where each tuple contained the review and
    its source.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Sentence Assessments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Realism Assessment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, I simply wanted to assess if the reviews seemed “realistic.” This is
    similar to calculating the *coherence* of a given body of text and its connections.
    My initial thought is they will all be deemed realistic, but I thought it would
    be interesting to also visualize the scores from the original reviews, artificial
    positive reviews, and artificial negative reviews.
  prefs: []
  type: TYPE_NORMAL
- en: To start this assessment, we are first going to create an *assess_sentence_realism*
    function. This function seeks to look at the cohesiveness of a sentence and if
    the input sentence is “realistic” to how a human would interpret it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: You will need to download an embedding model to create your word embeddings.
    The model I chose to use was the Google News 300 model (check it out [here](https://huggingface.co/fse/word2vec-google-news-300)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: → **Original Dataset Score:** 0.17
  prefs: []
  type: TYPE_NORMAL
- en: → **ChatGPT-generated Positive Dataset Score:** 0.15
  prefs: []
  type: TYPE_NORMAL
- en: → C**hatGPT-generated Negative Dataset Score:** 0.16
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/29b9e7c8486e85ac4e1987444ec88289.png)'
  prefs: []
  type: TYPE_IMG
- en: Mean Realism Scores (Image from Author)
  prefs: []
  type: TYPE_NORMAL
- en: As expected (well maybe), the original reviews were scored to be the most realistic.
    Why could this be? Well, for starters, **they were the real reviews**. One of
    the big reasons I also suspect why ChatGPT scored lower is linked to how over
    time the model was following somewhat of a pattern with the reviews it was creating.
    Some of the reviews were very close to being the same, and ChatGPT would simply
    alter a few words around.
  prefs: []
  type: TYPE_NORMAL
- en: (ie. *The* ***pizza*** *was not good and was very dry → The* ***pasta*** w*as
    not good and was very dry)*
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: There was also a lack of **diversity** in the ChatGPT reviews compared to the
    real reviews, which we can expect (think about it, multiple people made the real
    reviews while one model created the fake reviews). With that being said, the reviews
    created by ChatGPT still scored relatively well compared to the original reviews
    and I would say it's worth a shot to go ahead and train our models with them in
    the future.
  prefs: []
  type: TYPE_NORMAL
- en: '**Before doing so, let’s also do a similarity assessment between the reviews.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Similarity Assessment**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next, I wanted to look at the similarities between each batch of the generated
    reviews and the original reviews. To do this, we can use *cosine similarity* to
    calculate how similar the different sentence vectors from each source are. First,
    we can create a cosine similarity matrix that will first transform our sentences
    into vectors using TfidVectorizer() and then calculate the cosine similarity between
    the two new sentence vectors.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: One problem I had was the datasets were now so big that the calculations were
    taking too long (and sometimes I did not have enough RAM on Google Colab to continue).
    To combat this issue, I randomly sampled 200 reviews from each of the datasets
    for calculating the similarity.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have the randomly selected samples, we can look at cosine similarities
    between different combinations of the datasets.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/d594f9d323c86bc698842286861e4799.png)'
  prefs: []
  type: TYPE_IMG
- en: Cosine Similarity Results (Image from Author)
  prefs: []
  type: TYPE_NORMAL
- en: For the original dataset, the negative reviews were more similar. My hypothesis
    is this is due to my using more prompts to create negative reviews than positive
    reviews. No surprise, the ChatGPT-generated reviews showed the highest signs of
    similarity between themselves.
  prefs: []
  type: TYPE_NORMAL
- en: Great, we have the cosine similarities, but is there another step we can take
    to assess the similarities of the reviews? There is! Let’s visualize the sentences
    as vectors. To do this, we must embed the sentences (turn them into vectors of
    numbers) and then we can visualize them in 2D space. I used Spacy to embed my
    vectors and visualize them.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b9f69002cab2db51681c3d5d439a6204.png)'
  prefs: []
  type: TYPE_IMG
- en: Sentence Vectors (Image from Author)
  prefs: []
  type: TYPE_NORMAL
- en: The good news is we can clearly see the embeddings and distributions of the
    sentence vectors closely align. Visual inspection shows there is more variability
    in the distribution of the *original reviews*, supporting the assertion **they
    are more *diverse****.* Since ChatGPT generated positive and negative reviews,
    we would suspect their distributions to be the same. Notice, however, the fake
    negative reviews actually have a wider distribution and more variance than positive
    reviews. *Why might this be?* Probably it is due in part to the fact that I had
    to trick ChatGPT to create the fake negative reviews (ChatGPT is designed to say
    positive statements) and I had to actually provide more prompts to ChatGPT to
    get enough negative reviews vs. positive ones. This helps the dataset because,
    with the additional diversity in the dataset, we can train higher-performing machine
    learning models.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9242966364ffcbedb0fdbfdb78a7c957.png)'
  prefs: []
  type: TYPE_IMG
- en: Sentence Vectors by Dataset (Image from Author)
  prefs: []
  type: TYPE_NORMAL
- en: Next, we can inspect the differences in the three different distributions of
    reviews and see if there are any distinguishing patterns.
  prefs: []
  type: TYPE_NORMAL
- en: '*What do we see*? Visually, we can see that the bulk of the reviews for the
    dataset are centered around the origin and span from -10 to 10\. This is a positive
    sign and supports the use of fake reviews for training prediction models. The
    variances are somewhat the same, however, the original reviews had a wider variance
    in their distribution, both laterally and longitudinally, a proxy that there is
    more diversity in the lexicon within those reviews. The reviews from ChatGPT definitely
    had similar distributions, but the positive reviews had more outliers. As stated,
    these distinctions could be a result of the way I was prompting the system to
    generate reviews.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pitfalls and Shortcomings**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While increasing the size and diversity of a dataset has many added benefits,
    there are weaknesses and pitfalls to this approach. The newly generated data may
    not be representative or close to the format of the real data. While we can make
    some math calculations and visualizations to support similarity, we can never
    be sure how the reviews will be interpreted in machine language. We could develop
    models for reading surveys and reviews for a company in the food industry with
    this data, but the model may break down when given the unstructured, “dirty” data
    from the real world since we have trained it more on generated fake data that
    follows an underlying pattern.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another issue is once the fake data is added, we forfeit the ability to do
    various analytical techniques for information extraction for example if I conduct
    topic modeling analysis with this new dataset, the topics won’t be defining just
    the original data. They now will be defining the fake data as well and that tells
    my customer nothing. Why does my customer care if “spaghetti is dry” is a topic
    when I created fake reviews saying stating such a fact? That’s my problem, not
    theirs. To be frank, this process hinders our ability to conduct exploratory data
    analysis (EDA). I see this as the biggest trade: with this data set, we can create
    classification and prediction models which may be suitable for interpreting new
    reviews (maybe even better due to the increase in the size of the dataset but
    you will need to build in processes for testing this) at the expense of not being
    able to extrapolate as much information from the data the company already (if
    we use this dataset).'
  prefs: []
  type: TYPE_NORMAL
- en: My biggest caution to anyone using generating data is, do not to forget about
    the original data you collected. Do not forget about the original questions and
    problems you are trying to solve. Forgetting this could lead you down a rabbit
    hole of trying to solve a problem that lies in the fake data itself!
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One problem that arises in Data Science is the lack of data and diversity in
    the data. There are various methods for generating new data, and today showed
    how ChatGPT could be used for creating more data for your dataset. Today’s findings
    are especially helpful for those working in the *Food Industry.* Doing this could
    alleviate issues of imbalance and lack of diversity in datasets, leading to models
    which perform better on real-world data post-training.
  prefs: []
  type: TYPE_NORMAL
- en: '***What did today show?***'
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT data could be helpful for your next Natural Language Processing Project
    (NLP), especially if you are implementing data science techniques for businesses
    in the food industry. **I would caution it is always good to try to collect the
    real data first.** If you find that you need more data for your dataset, it may
    not hurt to explore options like Generative Adversarial Networks (GAN), or Large
    Language Models (LLM), like ChatGPT. Finally, I always want to foot stomp, especially
    when working with Generative AI, it is important to use these tools ethically
    and in a positive manner for all impact parties.
  prefs: []
  type: TYPE_NORMAL
- en: '**You may be wondering, what does it mean to use these tools ethically?** You
    should use generative AI to help support people and bring a positive impact in
    their lives. There are use cases of people creating deepfakes that are hurtful
    to a person’s image, which is never okay. Additionally, generative AI should never
    be used to trick someone or change their thoughts with fake, untrue data. Today’s
    example is a perfect use case of how we can create data that will be used to train
    models for a company to understand the sentiment of customers'' reviews. It will
    help the company change its goods and processes to cater to the needs of the customer,
    positively impacting both parties!'
  prefs: []
  type: TYPE_NORMAL
- en: '**If you enjoyed today’s reading, PLEASE give me a follow and let me know if
    there is another topic you would like me to explore! If you do not have a Medium
    account, sign up through my link** [**here**](https://ben-mccloskey20.medium.com/membership)
    **(I receive a small commission when you do this)! Additionally, add me on** [**LinkedIn**](https://www.linkedin.com/in/benjamin-mccloskey-169975a8/),
    **or feel free to reach out! Thanks for reading!**'
  prefs: []
  type: TYPE_NORMAL
- en: Sources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data usage approved by Altomontes Inc.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Full code here](https://github.com/benmccloskey/food_industry)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
