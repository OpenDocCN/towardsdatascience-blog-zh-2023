# LLMs，新型大规模虚假信息武器？

> 原文：[https://towardsdatascience.com/llms-weapons-of-mass-disinformation-4def0dc3dc7](https://towardsdatascience.com/llms-weapons-of-mass-disinformation-4def0dc3dc7)

## 大型语言模型（LLMs）的双刃剑

## 你以为2016年的脱欧和美国总统竞选已经够糟糕了？再想想吧。

[](https://medium.com/@anthony.mensier?source=post_page-----4def0dc3dc7--------------------------------)[![Anthony Mensier](../Images/46ba933ade6f7f7f88ece0c6248ebda8.png)](https://medium.com/@anthony.mensier?source=post_page-----4def0dc3dc7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4def0dc3dc7--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4def0dc3dc7--------------------------------) [Anthony Mensier](https://medium.com/@anthony.mensier?source=post_page-----4def0dc3dc7--------------------------------)

·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----4def0dc3dc7--------------------------------) ·阅读时间17分钟·2023年5月29日

--

![](../Images/95df736816ab4bcb32741ce617df12ba.png)

图片由作者使用Midjourney 5生成

# 欢迎来到LLMs的双刃剑系列！

不妨直言不讳，ChatGPT这一大型语言模型（LLM）的重大发布是一场席卷全球的现象，揭示了自然语言处理（NLP）进步的崭新世界。仿佛帷幕拉开，公众、政府以及国际机构一同目睹了这项技术在他们面前迈出的大胆步伐。随之而来的是一场真正的创新烟花表演。例如，[ThinkGPT](https://github.com/jina-ai/thinkgpt)，这是一个巧妙的Python库，为LLMs提供了人工思维链和长期记忆，几乎使它们能够‘思考’（并非玩笑）。或者[AutoGPT](https://github.com/Significant-Gravitas/Auto-GPT)，另一个能够处理复杂请求并生成AI代理以完成这些请求的库。

这些只是基于LLMs API开发的数百个应用中的两个例子。我对人们利用这些新工具的独创性感到印象深刻，他们巧妙地重新利用了这些由OpenAI、Facebook、Cohere和Google等公司慷慨提供的乐高积木。但现在我得戴上我的严肃帽子了，大家。正如我们亲爱的本叔叔明智地告诫的那样（漫画迷们，你们知道的；如果不知道，我建议你们赶紧去看看最近一期的《蜘蛛侠》），“能力越大，责任越大。” 坦率地说，我并不完全相信这些公司在将他们的脑力结晶放出世界让人们琢磨时，尽到了应有的责任。

![](../Images/3ef0fe7c940ee691d01719f3bd598871.png)

图片来自于[维基百科](https://en.wikipedia.org/wiki/With_great_power_comes_great_responsibility)

别误会我的意思。我在过去六年里一直深入应用NLP技术，以创建新型国家安全智能解决方案，我坚信它们的变革潜力（即便在2017年“变形金刚”兴起之前——[查看我关于OSINT和LLMs的文章](https://medium.com/@anthony.mensier/how-large-language-models-changed-my-entire-osint-workflow-35960099e258)）。我预见到一个“现代”将成为古老、过时术语的未来，因为这些技术将重塑我们所知的社会。但像硬币的另一面一样，潜藏着危险——并不是恶意的通用人工智能（AGI）意图进行类似天网的人类灭绝（是的，我真心希望你对那个参考有所了解！）。而是，我在暗指这种技术的意外滥用，甚至更糟的是故意扭曲。

所以，各位女士们、先生们，欢迎来到《大型语言模型（LLMs）的双刃剑》系列，这一系列旨在揭示这一突破性技术的阴暗面。我并不是来否定先进人工智能的发展。相反，我的目的是引发对这些技术的性质和应用的热烈讨论，努力将它们的潜力用于善，而非恶。

## 你会在这篇文章中发现什么？

这篇文章分为两个主要部分，每个部分对应于语言学习模型（LLMs）出现之前和之后的时代。请随意按需探索！

+   第一部分*深入探讨*了宣传的各个方面、其历史使用情况，以及技术如何逐步被利用来提升其效果。我们谈论的是社会科学、操控技术、Web 1.0、Web 2.0，以及这些元素如何被用于大规模的虚假/误导信息运动，例如在英国脱欧和特朗普竞选期间。

+   第二部分则更专注地探讨了LLMs，考察它们对我们信息消费的变革性影响以及它们在这一特定领域所带来的潜在风险。我还提供了关于我们如何达到这一点的观点，并建议了缓解这些负面影响的潜在措施。

# 宣传与技术：一段爱情故事

宣传是一种巧妙的技术，追求权力，不通过战争的武力，而是通过微妙的劝说艺术（向[克劳塞维茨](https://en.wikipedia.org/wiki/Carl_von_Clausewitz)致以敬意）。这一策略，和治理本身一样古老，自早期帝国和民族国家以来一直被使用。一些历史学家追溯其首次使用到公元前515年的波斯帝国！

随着社会的扩展和政治结构的复杂化，统治者发现有多种方法是维持秩序和合作所必需的。在这些策略中，包括经典的“面包和马戏”以及其他方法，宣传找到了自己的位置。虽然这当时的宣传非常粗糙和直白，与我们今天的体验相去甚远，远未成为主角，但它确实发挥了作用。

## **第一个改变游戏规则的因素：印刷术的发明。**

这改变了信息传播的方式。突然间，曾经主要局限于宫廷和通过信使传播的叙述找到了更广泛的受众。随着影响范围的扩大，信息开始转变为更强大的影响工具。笔，或者说在这种情况下的印刷术，开始展现其力量，并不掩盖，但确实与剑并肩而立。因此，影响的动态呈现出一种全新的形式。

我为什么今天提到这个话题，尤其是在印刷术逐渐淡出历史的今天？为了提醒我们**成功的信息传播的关键在于其覆盖范围，即它影响的人群。**而它影响的人越多，它的力量就越大。

![](../Images/2b165458648d331184f2964c72ecc3bc.png)

英国如何为第一次世界大战做准备，图片来源于[维基百科](https://en.wikipedia.org/wiki/History_of_propaganda#/media/File:How_Britain_Prepared.jpg)

现在，让我们快进到20世纪。

## 第二个改变游戏规则的因素：社会科学和操控杠杆

随着社会科学的发展和**新兴的群众心理学领域**，欧洲国家找到了一些新方法来影响其民众。**印刷术提供了受众，社会科学提供了方法。** 法国作家古斯塔夫·勒庞的著作成为1930年代专制政权领导者的手册。他们利用这些理论来触及公民的挫败感和恐惧，给他们提供了一个简化的世界观，在这个世界观中，明确的敌人威胁着他们的国家、生活方式和传统。这些领导者将自己描绘成全知的守护者，引领人民走向胜利。

民主政权也采用了这种方法，帮助他们引导民众接受（或至少不反对）在战争条件下生活和参与战争努力所带来的约束和限制。有些人可能会认为这是为了更大利益所必要的一步。

尽管如此，必须牢记的是，尽管在艰难时期对复杂现实的简化有时被视为必要的恶，但绝不应被提倡。**诉诸过于简单的真相和情绪化的语言以激发情感而非理性反应，会煽动恐惧、仇恨和分裂的火焰。** 这种策略有可能引发灾难性的后果，并在促成不可想象的人类悲剧中发挥了重要作用，正如大屠杀悲惨地证明了这一点。

## 信息时代已经过去：Web 1.0 & 2.0

快进到1993年——**万维网的诞生——第三次革命**。源于“链接信息系统”的想法，计算机科学家蒂姆·伯纳斯-李发布了世界上第一个网页浏览器和编辑器的源代码。突然间，Web 1.0的愿景成为现实，带来了对人类更好未来的雄心壮志。毕竟，既然可以访问到世界的集体知识，我们怎么可能不提升自己呢？

初衷是理想主义的，真正乐观的。想象一个世界，任何人都可以访问由最佳大学和智库发布的内容，参与公开讨论，并通过透明的信息访问使这些机构问责。**这是一个由信息力量驱动的更开明社会的梦想**。

**相反，我们得到的是……LOL猫咪。** 当然，情况并非完全如此。确实有意义的贡献和令人印象深刻的知识分享进展（LLMs的兴起依然如此）。但与此同时，一种新的娱乐文化、闲逛和吸引注意力的头条新闻也开始扎根。

![](../Images/b069980a3e5dcdbe9bcdc85563e5c5e9.png)

互联网路由路径的可视化，图片由[维基百科](https://en.wikipedia.org/wiki/History_of_the_Internet#/media/File:Internet_map_1024_-_transparent,_inverted.png)提供

**Web 2.0的兴起**，以社交媒体平台的创建和增加为特征，**使这种动态变得尤为突出。** 起初被誉为连接人类的新媒介，它们也成为了反映我们分裂的镜子，通过算法和回音室放大这些分裂。曾经局限于Web 1.0特定论坛和博客的讨论溢出了主流，塑造了我们对现实的认知，这种影响我们还在开始理解。游说者和活动家现在清楚地知道应该集中精力的方向和目标，因为现在大多数成年人和青少年都在网上。**网络影响力活动的潜在媒介已从数百个社区网站和博客转移到几个主导的社交媒体平台**，这些平台现在使用语义搜索引擎和数据分析工具来托管和监控这些社区，**因此简化了其物流，并将其效果放大了几个数量级。**

我们终于来到了今天。曾经乌托邦般的互联网承诺已经偏离了轨道。一项旨在启发我们的技术，现在却成为了争夺我们注意力的战场。信息时代已经成为过去。

**这并不是说更大的利益完全丧失了，而是说阴影变得越来越难以忽视**。互联网和社交媒体的近乎普及导致了许多早期先驱可能从未预见的意外后果。虽然这些平台被誉为信息的“伟大民主化者”，但它们也无意中创造了一个虚假信息滋生的环境。快速广泛分享信息的能力可以是一个极大的利好力量，但它也为传播虚假信息和宣传提供了有力的工具。作为用户，我们曾被承诺知识的盛宴，但现在，我们却在拼命区分事实与虚构，真相与幻象。最近‘假新闻’的趋势及其在网上迅速传播的能力，清晰地证明了这一点。

# 2016年发生了什么？回音室和定向算法。

## 完美风暴：病毒式传播、数据分析和人群操控

2016年发生了一次强大的汇聚，将社会科学的进步、Web 1.0 和 Web 2.0 技术结合在一起，从而在政治领域掀起了前所未有的风暴。这一年是英国脱欧公投和美国总统选举之年，特朗普和希拉里·克林顿正面交锋。这些事件的特点是**四个关键现象：针对未决定选民的定向消息、对专家意见的组织性攻击、复杂的定向算法的实施，以及回音室现象的传播**。社交媒体平台突然间，从最初设计为信息分享和促进联系的无害工具，变成了虚假信息和宣传的强大工具。它们以**超过中立方和专家验证信息真实性能力的速度传播内容**。

![](../Images/f93050dce2015f7201ef1a0720d3120f.png)

由 [John Cameron](https://unsplash.com/@john_cameron?utm_source=medium&utm_medium=referral) 提供的照片，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

以英国脱欧公投为例。离开阵营提出了一个大胆的主张，即英国脱离欧盟将每周为NHS释放额外的3.5亿英镑。**尽管这一主张很快被独立的事实检查员揭穿，但它在相当数量的选民中找到了共鸣。问题是，为什么？** 答案部分在于社交媒体分析的不断演变，使得竞选者能够衡量各个社区对欧盟的‘情感’，而不仅仅是意见。这些数据揭示了英国大部分人对欧盟成员资格的好处感到不确定，主要关心更迫切的问题，如移民和NHS的状况。掌握了这些见解后，竞选者设计了高度定制的信息策略，借助社交媒体分析确定了正确的目标群体。这些平台固有的传播性完成了剩下的工作。

与此同时，在大西洋另一边，特朗普的总统竞选也采用了类似的战术。大胆的主张，如承诺让墨西哥资助边界墙，尽管被广泛揭穿，但仍在许多选民中获得了认可。

## 剑桥分析公司：患者还是零号病毒

在这两个事件中，一个值得注意的参与者是**咨询公司剑桥分析公司**，其在这些政治事件中的争议角色已被Netflix纪录片《大黑客》生动地记录下来。

该公司从数百万个社交媒体个人资料中收集数据，以执行高度针对性的选民影响策略。借鉴了群体心理学家古斯塔夫·勒庞的见解，该公司利用恐惧、无知和挫折来影响公众情绪。然而，这些策略并非孤立操作。社交媒体平台部署的算法促成了**‘回音室’效应**。这些算法选择性地向用户展示与其现有观点一致的内容，强化他们的信念，并在某些情况下，推动他们朝更极端的立场发展。此外，如上所述，尚未决定的选民被识别出来并遭受了**大量高度定制的信息轰炸**，旨在改变他们的立场。通过这种方式，技术不仅用于传播特定的叙事，还创造了有利于其接受的条件。

外国势力，特别是俄罗斯国家，也参与其中，发布机密的竞选内容，并利用Facebook和Twitter传播谣言，以诋毁那些对他们自己的议程最不利的候选人，[这一点在美国参议院关于俄罗斯主动措施和干预2016年美国大选的情报委员会报告中有所揭示](https://www.intelligence.senate.gov/sites/default/files/documents/report_volume5.pdf)。

**请注意，每条消息的制作都是由数据分析和社会科学专家团队负责，他们花费了数天时间创建内容和规划活动——随着基础模型的使用，这种情况将会改变。**

# 向机器生成的真相时代问好

我喜欢在与高级领导讨论深度学习的进展时引用一句发人深省的谚语：**“通往地狱的道路是由善意铺成的。”** 变革性技术的误用以达到有害目的似乎是一种反复出现的人类模式。各种例子支持了这种观点，包括核聚变的应用，这既带来了核能，也带来了核弹。人工智能也是如此，尤其是大型语言模型（LLMs）。

## 破解人类语言

这些技术具有显著提升我们效率的潜力，但它们也体现了近乎存在性的风险。我反对这样一种观点，即人工智能的好处只需超过其负面影响即可造福人类。**如果结果是人类再也无法区分真实与虚假，那么大型语言模型（LLMs）可能促进的众多其他革命将变得毫无意义，被机器速度带来的虚假信息和我们民主机构的潜在崩溃所淹没。**

实际上，最新大型语言模型的发布为信息操控引入了一个新维度，这可能会破坏我们民主社会的基础。GPT-4、Claude、BARD及其同类产品，凭借其以空前规模和速度生成类似人类的文本的能力，实际上已经获得了**‘破解’语言的能力，这是人类沟通的主要手段**。

语言是我们社会的基石。它是我们表达思想、分享想法和塑造集体叙事的媒介。语言也是我们形成意见和做出决定的工具，包括政治选择。通过操控语言，大型语言模型（LLMs）有可能以微妙而深刻的方式影响这些过程。

![](../Images/73f1d13900ebf9268b216fa318b92568.png)

图片由 [Jonathan Kemper](https://unsplash.com/@jupp?utm_source=medium&utm_medium=referral) 提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

大型语言模型（LLMs）生成符合特定叙事或诉诸特定情感的内容的能力**已成为2016年虚假信息活动中的缺失部分**。回想一下，为了与特定社区产生共鸣而投入的大量精力，以及为这些任务所需的专家团队？LLMs的出现使这一整个过程几乎变得多余和过时。**有说服力和针对性的内容创建可以实现自动化，使得生成大量虚假信息成为可能，规模和速度超出了人类的能力**。这不仅仅是传播虚假信息，更是关于塑造叙事和影响认知。滥用的潜力巨大。想象一下这些模型被用来淹没社交媒体平台，发布旨在煽动分裂、挑起暴力或影响公众对关键问题的看法的帖子。这对我们民主社会的影响是深远且令人深感担忧的。

## 深度伪造技术与后真相时代

**当LLMs与其他基础模型如Stable Diffusion或Midjourney结合使用时，危险性就会加剧。** 这些模型可以生成超现实的图像和视频，成为虚假信息活动的强大工具。想象一下由AI生成的假文章和看似真实的图片、视频。大规模伪造有说服力的多媒体内容的能力可能会显著放大虚假信息活动的影响，使其更有效且更难以对抗。

**以总统沃洛基米尔·泽连斯基在社交媒体上现场直播投降的深度伪造视频为例。** 尽管这个事件因其重要性而很容易被揭穿，但它证明了大型变换器模型，当它们结合在一起时，具有的颠覆性力量。另一个引人注目的事件是**[**理查德·布卢门撒尔**](https://www.blumenthal.senate.gov/)**在参议院关于人工智能的听证会上提到的这一逻辑（完整视频见文章末尾），在他播放了一段录音，读出了他的开场白，结果揭示了文本和音频都是由人工智能生成的：**“如果它 [GPT-4] 提供了对乌克兰投降的支持，或对弗拉基米尔·普京领导力的认可呢？”**

**此外，社交网络的病毒式传播可以加速虚假信息的传播，使其以机器速度传播。** 这种快速传播可能超越了严肃新闻出版物、智库和其他事实核查组织验证和驳斥虚假信息的努力。**例如，设想一种场景：一场虚假的恐怖袭击通过社交媒体传播，配有数十个虚假的智能手机视频和照片记录袭击细节，得到数百条社交媒体帖子和伪造的新闻文章支持，这些文章模仿BBC、CNN或《世界报》的风格。** 传统媒体在担心错过报道并失去观众的压力下，可能会在事件的真实性得到确认之前报道该事件。这可能导致广泛的恐慌和虚假信息，进一步加剧问题。

## 为什么我们不暂停LLMs的发展呢？

转型技术本质上具有带来深远变化的能力。在资本主义社会中，它们被视为重要的商品，急于被开发，这转化为对供应商锁定和销售其产出的黄金热潮。**这在地缘政治中表现为各国努力控制和掌握这些重要的权力资产。** 这在核聚变上是如此，现在在人工智能上也是如此。过去三年里，国家安全机构中出现了大量专注于创建和控制AI驱动技术的政策、专门办公室和团队。人工智能已成功取代数据，成为所有重要国防组织和政府部门的流行词。

例如，五角大楼整合了多个负责数据管理、人工智能开发和研究的部门，最终于2022年2月成立了[首席数字与人工智能办公室](https://www.ai.mil/)。英国现在已经建立了专门的[国防人工智能战略](https://www.gov.uk/government/publications/defence-artificial-intelligence-strategy)（于2022年6月发布），法国、[北约](https://www.nato.int/cps/en/natohq/official_texts_187617.htm)、中国、俄罗斯和印度也纷纷效仿。

我为什么要告诉你这些？我相信，强大的AI模型（包括大型语言模型LLMs）对公众的无监管发布可以归因于至少两个主要因素。第一个因素来源于政府官员普遍缺乏技术素养，这一点从我向这类听众做的众多报告中可以看出。

但第二个因素——也许是最关键的因素——是**政府官员和中大型公司高管普遍认为实施人工智能监管会阻碍进步**。他们担心这种监管约束会使他们的组织和国家处于不利地位，尤其是与那些在人工智能领域不受限制快速前进的国家相比。

![](../Images/a2a9e33019f08541fb4f4d45215661c2.png)

照片由[迈克·斯托尔](https://unsplash.com/@bmpskier?utm_source=medium&utm_medium=referral)拍摄，发布在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)上。

这是美国国会、参议院、国防和国家安全委员会中的持续话题：现在对人工智能进行监管将会减缓其发展，美国将落后于中国，从而处于战略劣势。**这一论点在西方国家主要由以国防为导向的人工智能优先公司巧妙地编制和推广**。这些公司中最著名的是彼得·蒂尔生态系统支持的公司。倡导“快速行动，打破常规”方法的公司，如Palantir和Anduril（有趣的是，这两个名字都参考了《指环王》中的最强大魔法神器），格外引人注目。

然而，我们不能忽视欧盟对人工智能不受控发展的监管尝试，尤其是从数据和知识产权保护的角度来看。尽管如此，由于大多数领先的语言学习模型（LLM）创作者是美国人，这些规定不可避免地会事后施行，即在人工智能模型已经在全球范围内部署之后。这时已经为时已晚。

**掌握关键技术无疑是赢得大国竞争的先决条件，但这不应成为缺乏辩论、简单化论证或不加限制地部署这些技术的理由**。我们需要记住至少两个重要的例子： [Facebook LLaMa模型泄露](https://www.theverge.com/2023/3/8/23629362/meta-ai-language-model-llama-leak-online-misuse) 和现行的中国人工智能监管政策。这些话题将是本系列后续文章的重点。

作为一个前瞻性的思考，请考虑这个问题：如果Facebook受到精心设计的人工智能模型部署网络安全规定的约束，LLaMa泄露事件会发生吗？此外，考虑一下中国的人工智能监管框架。从各种指标来看，它比任何西方国家的监管框架都要先进和严格。这挑战了这样一种观念：即中国在没有不必要的繁文缛节的情况下，全速推进先进人工智能解决方案的发展和部署。

# 那么，接下来该怎么办？

当我们迈入机器生成真相的时代，政府、企业和整个社会都有责任建立保障措施，以减少风险并获取利益。**人工智能开发的透明度、负责任的使用规范、强有力的机器主导和人工控制的事实核查机制以及先进的人工智能素养**只是需要紧急关注的一些积极措施。这些话题，特别是最后一个，将是本系列文章的核心内容。

**是时候讨论大型语言模型的负责任使用了**，促进人工智能伦理和包容性的文化。技术最终只是一个工具——其影响取决于使用者的意图。问题是，我们会让它成为促进更有启发性的社会的工具，还是成为加剧分裂的武器？我们对这些强大工具的理解才刚刚开始。

**免责声明：作为曾经的国防和国家安全领域的专业人士，我往往对人类技术利用持有一定的悲观和怀疑态度**，不幸的是。因此，当我看到有关人工智能监管的最新新闻，特别是那些由语言学习模型创作者自己推动的叙事时，它们确实引起了我的注意。例如，OpenAI首席执行官山姆·奥特曼最近在美国国会委员会上的出现。虽然我非常欢迎他的想法，但对我来说，这似乎是一个精心策划的举动，旨在确保他们的优势，提升对新进入者的障碍，并创建这种“护城河”概念，这在几周前的一份谷歌内部备忘录中曾被提及。但我也意识到这可能是我的偏见在作祟，我会尽量在整个系列中保持警觉。**最终**，这可能是我们所需要的：如果政府不愿意或不能对人工智能开发施加严格的监管，那么可能由私营部门来引领。然而，这种方法本质上会带有各自公司的议程和独特的策略。

敬请关注未来的文章，我们将**深入探讨**大型语言模型在操控政治话语中的潜在误用、它们在加剧社会经济不平等中的作用，以及它们如何被用来规避隐私规范。我们还将探索管理这些问题的潜在策略和政策，从技术到监管监督，以及公众对这些不断发展的技术的意识和教育需求。我们的旅程才刚刚开始。

# 喜欢这篇文章吗？

让我们互相认识！正如我所说，我们的旅程才刚刚开始。这一系列既属于你，也属于我。评论、讨论、分享、批评！目标是激发讨论。

如果你想进一步了解，请联系我！你可以在[LinkedIn](https://www.linkedin.com/in/anthony-mensier/)找到我，或在[Medium](https://medium.com/@anthony.mensier/subscribe)上关注我！

感谢你的支持，我们下次见！
