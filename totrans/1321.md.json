["```py\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Math and Vectors\nimport pandas as pd\nimport numpy as np\n\n# Visualizations\nimport plotly.express as px\n\n# ML\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport concurrent.futures\n\n# Utils functions\nfrom utils import prediction, compile_prompt, get_embedding, ml_models, create_auc_chart, gpt_reasoning\npd.set_option('display.max_columns', None)\n\n# load data\ndf = pd.read_csv(\"./data/raw data/heart_attack_predicton_kaggle.csv\")\ndf.shape\n\n# check missing value\ndf.isna().sum()\n\n# check outcome distribution\ndf['output'].value_counts()\n\n# one-hot encoding\ncat_cols = ['sex','exng','cp','fbs','restecg','slp','thall']\ndf_model = pd.get_dummies(df,columns=cat_cols)\ndf_model.shape\n\n# train test stratified split\n# Seperate dependent and independent variables\nX = df_model.drop(axis=1,columns=['output'])\ny = df_model['output'].tolist()\nX_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.2, random_state=101,\n                                                stratify=y,shuffle=True)\n```", "```py\n## model function\ndef ml_models():\n    lr = LogisticRegression(penalty='none', solver='saga', random_state=42, n_jobs=-1)\n    lasso = LogisticRegression(penalty='l1', solver='saga', random_state=42, n_jobs=-1)\n    ridge = LogisticRegression(penalty='l2', solver='saga', random_state=42, n_jobs=-1)\n    rf = RandomForestClassifier(n_estimators=300, max_depth=5, min_samples_leaf=50, \n                                max_features=0.3, random_state=42, n_jobs=-1)\n    models = {'LR': lr, 'LASSO': lasso, 'RIDGE': ridge, 'RF': rf}\n    return models\n\nmodels = ml_models()\nlr = models['LR']\nlasso = models['LASSO'] \nridge = models['RIDGE'] \nrf = models['RF'] \n\npred_dict = {}\nfor k, m in models.items():\n    print(k)\n    m.fit(X_tr, y_tr)\n    preds = m.predict_proba(X_val)[:,1]\n    auc = roc_auc_score(y_val, preds)\n    pred_dict[k] = preds\n    print(k + ': ', auc)\n```", "```py\ndf_gpt = df.copy()\ndf_gpt['sex'] = np.where(df_gpt['sex'] == 1, 'Male', 'Female')\ndf_gpt['cp'] = np.where(df_gpt['cp'] == 1, 'Typical angina', \n                       np.where(df_gpt['cp'] == 2, 'Atypical angina', \n                       np.where(df_gpt['cp'] == 3, 'Non-anginal pain', 'Asymptomatic')))\ndf_gpt['fbs'] = np.where(df_gpt['fbs'] == 1, 'Fasting blood sugar > 120 mg/dl', 'Fasting blood sugar <= 120 mg/dl')\ndf_gpt['restecg'] = np.where(df_gpt['restecg'] == 0, 'Normal', \n                       np.where(df_gpt['restecg'] == 1, 'Having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)', \n                                    \"Showing probable or definite left ventricular hypertrophy by Estes' criteria\"))\ndf_gpt['exng'] = np.where(df_gpt['exng'] == 1, 'Exercise induced angina', 'Without exercise induced angina')\ndf_gpt['slp'] = np.where(df_gpt['slp'] == 0, 'The slope of the peak exercise ST segment is downsloping', \n                       np.where(df_gpt['slp'] == 1, 'The slope of the peak exercise ST segment is flat', \n                                    'The slope of the peak exercise ST segment is upsloping'))\ndf_gpt['thall'] = np.where(df_gpt['thall'] == 1, 'Thall is fixed defect', \n                       np.where(df_gpt['thall'] == 2, 'Thall is normal', 'Thall is reversable defect'))\n\n# test df to dict\napplication_list = X_val.to_dict(orient='records')\nlen(application_list)\n```", "```py\ndef prediction_GPT3_5(data, explain = False):\n    if explain:\n        prompt = prompt_logic(explain)\n    else:    \n        prompt = prompt_logic(explain)\n    print(prompt)\n    response = openai.Completion.create(\n        model = 'text-davinci-003',\n        prompt=prompt,\n        max_tokens=64,\n        n=1,\n        stop=None,\n        temperature=0.5,\n        top_p=1.0,\n        frequency_penalty=0.0,\n        presence_penalty=0.0\n    )\n\n    try:\n        output = response.choices[0].text.strip()\n        output_dict = json.loads(output)\n        return output_dict\n    except (IndexError, ValueError):\n        return None\n\ndef prediction(combined_data_argu):\n    application_data, explain = combined_data_argu\n    response = prediction_GPT3_5(application_data, explain)\n    return response\n```", "```py\n### get prediction from GPT-3.5 model: text-davinci-003 - multiprocessing pool\nwith concurrent.futures.ThreadPoolExecutor() as executor:\n    # Combine credit_data and explain into a single iterable\n    combined_data = zip(application_list, [False] * len(application_list))\n    # Submit the transaction processing tasks to the executor\n    results = executor.map(prediction, combined_data)\n\n    # Collect the responses into a list\n    responses = list(results)\nresponses_df = pd.DataFrame(responses)\nresponses_df.shape\n```", "```py\nauc_gpt= roc_auc_score(y_val, responses_df['output'])\nauc_gpt\n```", "```py\n# define function to fetch the embedding\ndef get_embedding(text, model=\"text-embedding-ada-002\"):\n   text = text.replace(\"\\n\", \" \")\n   return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n\n# API call and merge with raw data\ndf_gpt['ada_embedding'] = df_gpt.combined.apply(lambda x: get_embedding(x, model='text-embedding-ada-002'))\ndf_gpt = df_gpt.join(pd.DataFrame(df_gpt['ada_embedding'].apply(pd.Series)))\ndf_gpt.drop(['combined', 'ada_embedding'], axis = 1, inplace = True)\ndf_gpt.columns = df_gpt.columns.tolist()[:14] + ['Embedding_' + str(i) for i in df_gpt.columns.tolist()[14:]]\ndf = pd.concat([df, df_gpt[[i for i in df_gpt.columns.tolist() if i.startswith('Embedding_')]]], axis=1)\ndf_gpt.shape\n```", "```py\n# Seperate dependent and independent variables\nX = df.drop(axis=1,columns=['output'])\ny = df['output'].tolist()\n\nX_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.2, random_state=101,\n                                                stratify=y,shuffle=True)\nmodels = ml_models()\nlr = models['LR']\nlasso = models['LASSO'] \nridge = models['RIDGE'] \nrf = models['RF'] \npred_dict_gpt = {}\nfor k, m in models.items():\n    print(k)\n    m.fit(X_tr, y_tr)\n    preds = m.predict_proba(X_val)[:,1]\n    auc = roc_auc_score(y_val, preds)\n    pred_dict_gpt[k + '_With_GPT_Embedding'] = preds\n    print(k + '_With_GPT_Embedding' + ': ', auc)\n```", "```py\npred_dict_combine = dict(list(pred_dict.items()) + list(pred_dict_gpt.items()))\ncreate_auc_chart(pred_dict_combine, y_val, 'Model AUC')\n```", "```py\napplication_data = application_list[0]\napplication_data\n\n{'age': 51,\n 'sex': 'Male',\n 'cp': 'Atypical angina',\n 'trtbps': 125,\n 'chol': 245,\n 'fbs': 'Fasting blood sugar > 120 mg/dl',\n 'restecg': 'Normal',\n 'thalachh': 166,\n 'exng': 'Without exercise induced angina',\n 'oldpeak': 2.4,\n 'slp': 'The slope of the peak exercise ST segment is flat',\n 'caa': 0,\n 'thall': 'Thall is normal'}\n```", "```py\nmessage_objects = [\n        {\"role\": \"system\", \"content\": '''You are a medical expert / underwriter in a global insurance company. Your job is to evaluate the chance of having heart attack. Please encode your response as json in the following format\n        {{\n            \"decision\": \"<Either less chance of heart attack or more chance of heart attack>\",\n        }}'''},\n        {\"role\": \"user\", \"content\": prompt},\n    ]\n\ncompletion = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        messages=message_objects,\n        max_tokens=1000,  # Adjust the max_tokens as per your desired response length\n        stop=None,  # Set custom stop conditions if required\n    )\n\n# Extract the response message content\n    response_content = completion.choices[0].message[\"content\"]\n```"]