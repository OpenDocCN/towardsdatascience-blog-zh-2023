- en: Build a Convolutional Neural Network from Scratch using Numpy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/build-a-convolutional-neural-network-from-scratch-using-numpy-139cbbf3c45e](https://towardsdatascience.com/build-a-convolutional-neural-network-from-scratch-using-numpy-139cbbf3c45e)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Master computer vision by building a CNN from scratch all by yourself
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@riccardo.andreoni?source=post_page-----139cbbf3c45e--------------------------------)[![Riccardo
    Andreoni](../Images/5e22581e419639b373019a809d6e65c1.png)](https://medium.com/@riccardo.andreoni?source=post_page-----139cbbf3c45e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----139cbbf3c45e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----139cbbf3c45e--------------------------------)
    [Riccardo Andreoni](https://medium.com/@riccardo.andreoni?source=post_page-----139cbbf3c45e--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----139cbbf3c45e--------------------------------)
    ·8 min read·Nov 23, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e4cdce3bc89847e967f252d44f3c1394.png)'
  prefs: []
  type: TYPE_IMG
- en: 'These colored windows remind me of the layers of CNNs and their filters. Image
    source: [unsplash.com](https://unsplash.com/photos/photo-of-green-leafed-plants-inside-building-CuEvrPd3NYc).'
  prefs: []
  type: TYPE_NORMAL
- en: As **Computer Vision** applications are now present everywhere in our daily
    lives, it is fundamental for every Data Science practitioner to **understand their
    functioning principles** and **familiarize themselves with them**.
  prefs: []
  type: TYPE_NORMAL
- en: In [this article](/building-a-deep-neural-network-from-scratch-using-numpy-4f28a1df157a),
    I built a **Deep Neural Network** without relying on popular modern deep learning
    libraries like Tensorflow, Pytorch, and Keras. I then classified images of handwritten
    digits with it. While the achieved results didn’t reach state-of-the-art levels,
    they were nevertheless satisfactory. Now, I want to take a **further step** in
    developing a [**Convolutional Neural Network**](https://en.wikipedia.org/wiki/Convolutional_neural_network)
    (CNN) using only the Python library [**Numpy**](https://numpy.org/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Python deep learning libraries, like the ones mentioned above, are **extremely
    powerful tools**. However, as a downside, they shield Data Science practitioners
    from understanding the low-level functioning principles of Neural Networks. This
    is especially true with CNNs, as their **processes are less intuitive** compared
    with the classical fully connected networks. The only way to address this issue
    is to get our hands dirty and implement CNNs ourselves: this is the motivation
    behind this task.'
  prefs: []
  type: TYPE_NORMAL
- en: This article is intended as a practical, **hands-on guide** rather than a comprehensive
    guide of CNN functioning principles. As a consequence, the theoretical part is
    concise and mostly serves the understanding of the practical section. For this
    reason, you will find an exhaustive list of resources at the end of this post.
    I warmly invite you to check them out!
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Convolutional Neural Networks use a specific architecture and operations that
    make them **well-suited for tasks related to images**, such as image classification,
    object localization, image segmentation, and more. Their design roughly **mirrors
    the human visual cortex**, where each biological neuron responds to only a small
    portion of the visual field. Moreover, higher-level neurons react to the outputs
    of lower-level neurons.
  prefs: []
  type: TYPE_NORMAL
- en: While classical fully connected networks can handle image-related tasks, their
    effectiveness degrades significantly when applied to medium or large images due
    to the large number of parameters they require. For instance, a 200x200 pixel
    image contains 40,000 pixels, and if the first layer of the network has 1,000
    units, it results in 40 million weights just for that layer. This challenge is
    highly alleviated by CNNs as they implement **partially connected layers** and
    **weight sharing**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **main components** of a Convolutional Neural Network are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Convolutional layers**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pooling layers**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convolutional Layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A convolutional layer consists of a **set of filters**, also known as **kernels**.
    When applied to the input of the layer, these filters **modify the original images**
    in specific ways.
  prefs: []
  type: TYPE_NORMAL
- en: 'A filter can be described as a matrix, whose elements values define the king
    of modification applied to the original image. For instance, a 3x3 kernel, like
    the following one, highlights the vertical edges of the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d1e5ad6d3a441e8ad32efb9c42af310b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This kernel instead accentuates the horizontal edges:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d2ae91eef1c774f3439d13b504f95d01.png)![](../Images/1c898cb273b97f9024c4a000078a319c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [Wikipedia](https://en.wikipedia.org/wiki/Kernel_(image_processing)).'
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note that the values of the elements of these kernels are
    not manually chosen but are parameters that the network learns during the training
    process.
  prefs: []
  type: TYPE_NORMAL
- en: The main function of convolutions is to isolate and highlight the different
    features present in the image. Later on, dense layers will use these features.
  prefs: []
  type: TYPE_NORMAL
- en: Pooling Layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Pooling layers are **more simple than convolutional layers**. Their purpose
    is to minimize the computational load and memory usage of the network. They achieve
    this task by **downsizing the input image’s dimensions**. Reducing the dimension
    results in a reduction of the number of parameters that the CNN has to learn.
  prefs: []
  type: TYPE_NORMAL
- en: Pooling layers also employ a kernel, typically of dimension 2x2, to aggregate
    a section of the input image into a single value. For example, a 2x2 max pooling
    kernel extracts 4 pixels from the input image and outputs only the pixel with
    the maximum value.
  prefs: []
  type: TYPE_NORMAL
- en: Python Implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can find all the code shown in this section in [my GitHub repository](https://github.com/andreoniriccardo/CNN-from-scratch).
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/andreoniriccardo/CNN-from-scratch?source=post_page-----139cbbf3c45e--------------------------------)
    [## GitHub - andreoniriccardo/CNN-from-scratch: Convolutional Neural Network from
    scratch'
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional Neural Network from scratch. Contribute to andreoniriccardo/CNN-from-scratch
    development by creating an…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/andreoniriccardo/CNN-from-scratch?source=post_page-----139cbbf3c45e--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: The concept behind this implementation consists of creating **Python classes**
    that represent the **convolutional and max pooling layers**. Furthermore, as this
    CNN will be applied to the famous open-source [MNIST](https://datahub.io/machine-learning/mnist_784#readme)
    dataset, I also create a specific class for the Softmax layer.
  prefs: []
  type: TYPE_NORMAL
- en: Within each class, I define the methods that perform the forward propagation
    and backpropagation steps.
  prefs: []
  type: TYPE_NORMAL
- en: As a final step, the layers are appended into a list to build the final Convolutional
    Neural Network.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional Layer Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The code defining a **convolutional layer** is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The constructor of the `**ConvolutionLayer**` class takes as inputs the number
    of kernels of the convolutional layer and their size. I assume to use only squared
    kernels of size `**kernel_size**`by `**kernel_size**`**.**
  prefs: []
  type: TYPE_NORMAL
- en: Later, I generate random filters of shape `**(kernel_num, kernel_size, kernel_size)**`and,
    for normalization, I divide each element by the squared kernel size.
  prefs: []
  type: TYPE_NORMAL
- en: The `**patches_generator()**`method is a generator. It yields the portions of
    the images on which to perform each convolution step.
  prefs: []
  type: TYPE_NORMAL
- en: The `**forward_prop()**`method carries out the convolution for each patch generated
    by the method above.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the `**back_prop()**`method is responsible for computing the gradient
    of the loss function with respect to each layer’s weight. It also updates the
    weights’ values correspondingly. Note that the loss function mentioned here is
    not the global loss of the network. Instead, it consists of the loss function
    passed by the max pooling layer to the previous convolutional layer.
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate the actual effect of this class, I created an instance of the
    `**ConvolutionLayer**`with 32 filters, each of size 3x3\. Then I apply the forward
    propagation method on an image, resulting in an output consisting of 32 slightly
    smaller images.
  prefs: []
  type: TYPE_NORMAL
- en: 'The initial input image has size 28x28 pixels and is depicted below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c97ac38d0a385b1777f571765503b480.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once I applied the `**forward_prop()**`method of the convolutional layer, I
    obtain 32 images of size 26x26 pixels. One of them is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5bdbb28eca65137bdebfb6f35b5f46d1.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the image has been reduced in size, and the clarity of the handwritten
    digit is worse. It is important to note that this operation was carried out by
    a filter containing random values, and therefore, it does not accurately represent
    the actual step performed by a trained CNN. Still, you can grasp the idea of how
    these convolutions yield smaller images where the distinctive features of the
    object are isolated.
  prefs: []
  type: TYPE_NORMAL
- en: Max Pooling Layer Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'I used Numpy to define the Max Pooling layer class as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The constructor method only assigns the kernel size value. The following methods
    operate similarly to the ones defined for the convolutional layer, with the main
    difference being that the `**back_prop()**`method doesn’t update any weight values.
    In fact, the pooling layer **doesnt’ rely on weights** to perform the aggregation.
  prefs: []
  type: TYPE_NORMAL
- en: Softmax Layer Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finally, I define the **Softmax layer**. It has the objective of **flattening
    the output volume** obtained from the final max pooling layer. The Softmax layer
    outputs 10 values, which can be interpreted as the probability of an image corresponding
    to the 0-to-9 digits.
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation has the same structure of the ones seen above:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/c105c918d43dbe3f6f996eb14371145d.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this post, we saw a **theoretical introduction** to the fundamental CNN architectural
    elements such as convolutional and pooling layers. I am positive that the step-by-step
    Python implementation will provide you a **practical understanding** of how these
    theoretical concepts can be translated into code.
  prefs: []
  type: TYPE_NORMAL
- en: I invite you to clone the [GitHub repository](https://github.com/andreoniriccardo/CNN-from-scratch)
    containing the code and play with the `**main.py**`script. Of course, this network
    doesn’t achieve state-of-the-art performances, as it is not built for this objective,
    but nevertheless reaches a **96% accuracy** after a few epochs.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, in order to expand your knowledge about CNN and computer vision, I
    suggest checking some of the resources listed below.
  prefs: []
  type: TYPE_NORMAL
- en: If you liked this story, consider following me to be notified of my upcoming
    projects and articles!
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[“Deep Learning” by Ian Goodfellow, Yoshua Bengio, and Aaron Courville](https://www.deeplearningbook.org/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[“Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow” by Aurélien
    Géron](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[“ImageNet Classification with Deep Convolutional Neural Networks” by Alex
    Krizhevsky, Ilya Sutskever, and Geoffrey Hinton](https://proceedings.neurips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[“Very Deep Convolutional Networks for Large-Scale Image Recognition” by Karen
    Simonyan and Andrew Zisserman (VGGNet)](https://arxiv.org/abs/1409.1556)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[“Python Machine Learning” by Sebastian Raschka and Vahid Mirjalili](https://www.amazon.com/Python-Machine-Learning-scikit-learn-TensorFlow/dp/1789955750)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[“Convolutional Neural Networks in Python: Master Data Science and Machine
    Learning with Modern Deep Learning in Python, Theano, and TensorFlow” by Jason
    Brownlee](https://zlibrary-asia.se/book/2740843/d253d5?dsource=recommend)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[“Hands-On Convolutional Neural Networks with TensorFlow 2” by Alex Gotev](https://www.amazon.com/Hands-Neural-Networks-TensorFlow-2-0/dp/1789615550)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
