["```py\nfrom gensim.models import Word2Vec,KeyedVectors\nimport gensim.downloader as api\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport spacy\nimport spacy.cli\nimport spacy\nimport numpy as np\nfrom random import sample\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n#To download \nspacy.cli.download(\"en_core_web_lg\")Dataset\n```", "```py\n#Dictionary: Keys=Source, Values=Reviews\n#Lists: List of reviews for each dataset\n\nreviews = []\nreviews_dict = {}\n\nreviews_dict['original review'] = []\nreviews_dict['fake positive review'] = []\nreviews_dict['fake negative review'] = []\n\n#Original Revews\norig_reviews = pd.read_csv('/content/drive/MyDrive/reviews/Altomontes_reviews.csv')\nfor rev in orig_reviews.Review:\n  reviews_dict['original review'].append(rev)\n  reviews.append((rev,'original review'))\n\n#positive reviews\npos_reviews = pd.read_csv('/content/drive/MyDrive/reviews/generated_positive_reviews - Sheet1.csv')\nfor rev in pos_reviews.Review:\n  reviews.append((rev,'fake positive review'))\n  reviews_dict['fake positive review'].append(rev)\n\n#negstive reviews\nneg_reviews = pd.read_csv('/content/drive/MyDrive/reviews/generated_negative_reviews - Sheet1.csv')\nfor rev in neg_reviews.Review:\n  reviews.append((rev,'fake negative review'))\n  reviews_dict['fake negative review'].append(rev)An example of an original review:\n```", "```py\ndef assess_sentence_realism(sentence, model):\n    \"\"\"\n  A function that accepts a sentence and embeddings model as inputs, and outputs a \n  'realism' score based on the cohesion and similarity between words of the \n  sentence\n\n  Inputs:\n  sentence (str): A string of words.\n  model (.model): An embedding model (user's choice)\n\n  Returns:\n  avg_similarity: An average similarity score between the words of the sentence.\n\n  \"\"\"\n    tokens = sentence.split()\n\n    # Calculate the average similarity between adjacent word pairs\n    similarities = []\n    for i in range(len(tokens) - 1):\n        word1 = tokens[i]\n        word2 = tokens[i + 1]\n        if word1 in model.key_to_index and word2 in model.key_to_index:\n            word1_index = model.key_to_index[word1]\n            word2_index = model.key_to_index[word2]\n            similarity = model.cosine_similarities(\n                model.get_vector(word1),\n                [model.get_vector(word2)]\n            )[0]\n            similarities.append(similarity)\n\n    # Calculate the average similarity score\n    if similarities:\n        avg_similarity = sum(similarities) / len(similarities)\n    else:\n        avg_similarity = 0.0\n\n    return avg_similarity\n```", "```py\n# Download the pre-trained Word2Vec model\n#model_name = 'word2vec-google-news-300'  # Example model name\n#model = api.load(model_name)\n#model.save('/content/drive/MyDrive/models/word2vec-google-news-300.model') \n\npretrained_model_path = '/content/drive/MyDrive/models/word2vec-google-news-300.model'\nmodel = KeyedVectors.load(pretrained_model_path)\n\nscores = {}\nsources = []\n\n# Evaluate the realism score for each sentence and store in scores dictionary\nfor sentence, source in reviews:\n    realism_score = assess_sentence_realism(sentence, model)\n    if source in scores:\n        scores[source].append(realism_score)\n    else:\n        scores[source] = [realism_score]\n    sources.append(source)\n    #print(f\"Realism Score for {source}: {realism_score}\")\n\n# Calculate the mean score for each source\nmean_scores = {source: np.mean(score_list) for source, score_list in scores.items()}\n\n# Plot the mean scores in a scatter plot\ncolors = {'original review': 'green','fake positive review':'blue','fake negative review':'red'}\nsns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\nplt.figure(figsize=(8, 6))\nplt.bar(mean_scores.keys(), mean_scores.values(),color=['green','blue','red'])\nplt.xlabel(\"Source\")\nplt.ylabel(\"Mean Realism Score\")\nplt.title(\"Mean Realism Scores by Source\")\nplt.show()\n```", "```py\ndef cosine_similarity(sentence1, sentence2):\n  \"\"\"\n  A function that accepts two sentences as input and outputs their cosine\n  similarity\n\n  Inputs:\n  sentence1 (str): A string of word\n  sentence2 (str): A string of words \n\n  Returns:\n  cosine_sim: Cosine similarity score for the two input sentences\n  \"\"\"\n  # Initialize the TfidfVectorizer\n  vectorizer = TfidfVectorizer()\n\n  # Create the TF-IDF matrix\n  tfidf_matrix = vectorizer.fit_transform([sentence1, sentence2])\n\n  # Calculate the cosine similarity\n  cosine_sim = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n\n  return cosine_sim[0][0]\n```", "```py\n#Random Sample 200 Reviews\no_review = sample(reviews_dict['original review'],200)\np_review = sample(reviews_dict['fake positive review'],200)\nn_review = sample(reviews_dict['fake negative review'],200)\n\nr_dict = {'original review': o_review,\n          'fake positive review': p_review,\n          'fake negative review':n_review}\n```", "```py\n#Cosine Similarity Calcualtion\nsource = ['original review','fake negative review','fake positive review']\nsource_to_compare = ['original review','fake negative review','fake positive review']\navg_cos_sim_per_word = {}\nfor s in source:\n  count = []\n  for s2 in source_to_compare:\n    if s != s2:\n      for sent in r_dict[s]:\n          for sent2 in r_dict[s2]:\n            similarity = calculate_cosine_similarity(sent, sent2)\n            count.append(similarity)\n      avg_cos_sim_per_word['{0} to {1}'.format(s,s2)] = np.mean(count)\n\nresults = pd.DataFrame(avg_cos_sim_per_word,index=[0]).T \n```", "```py\n# Load pre-trained GloVe model\nnlp = spacy.load('en_core_web_lg')\n\nsource_embeddings = {}\n\nfor source, source_sentences in reviews_dict.items():\n    source_embeddings[source] = []\n    for sentence in source_sentences:\n        # Tokenize the sentence using spaCy\n        doc = nlp(sentence)\n\n        # Retrieve word embeddings\n        word_embeddings = np.array([token.vector for token in doc])\n\n        # Save word embeddings for the source\n        source_embeddings[source].append(word_embeddings)\ndef legend_without_duplicate_labels(figure):\n    handles, labels = plt.gca().get_legend_handles_labels()\n    by_label = dict(zip(labels, handles))\n    figure.legend(by_label.values(), by_label.keys(), loc='lower right')\n\n# Plot embeddings with colors based on source\n\nfig, ax = plt.subplots()\ncolors = ['g', 'b', 'r']  # Colors for each source\ni=0\nfor source, embeddings in source_embeddings.items():\n    for embedding in embeddings:\n        ax.scatter(embedding[:, 0], embedding[:, 1], c=colors[i], label=source)\n    i+=1\nlegend_without_duplicate_labels(plt)\nplt.show()\n```"]