["```py\nimport numpy as np\n​\ndef calculate_log_loss(y_true, y_pred):\n    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n​\n# Example usage\ny_true = np.array([0, 1, 1, 0])\ny_pred = np.array([0.1, 0.9, 0.8, 0.2])\nlog_loss = calculate_log_loss(y_true, y_pred)\nprint(f\"Log Loss: {log_loss}\")\n```", "```py\nLog Loss: 0.164252033486018\n```", "```py\n# With an outlier\ny_true_with_outlier = np.array([0, 1, 1, 0, 1])\ny_pred_with_outlier = np.array([0.1, 0.9, 0.8, 0.2, 0.99])  # The 0.99 is the outlier\nlog_loss_with_outlier = calculate_log_loss(y_true_with_outlier, y_pred_with_outlier)\n​\n# Without the outlier\nlog_loss_without_outlier = calculate_log_loss(y_true, y_pred)\n​\nprint(f\"Log Loss with outlier: {log_loss_with_outlier}\")\nprint(f\"Log Loss without outlier: {log_loss_without_outlier}\")\n```", "```py\nLog Loss with outlier: 0.1334116939595147\nLog Loss without outlier: 0.164252033486018\n```", "```py\ndef calculate_cross_entropy(y_true, y_pred):\n    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n​\n# Example usage\ncross_entropy = calculate_cross_entropy(y_true, y_pred)\nprint(f\"Cross Entropy: {cross_entropy}\")\n```", "```py\nCross Entropy: 0.164252033486018\n```", "```py\n# Assume '1' means the patient has the disease, and '0' means they don't.\ny_true = np.array([0, 1, 1, 0, 1])\ny_pred = np.array([0.1, 0.9, 0.8, 0.2, 0.7])  # Predicted probabilities from the model\n​\nlog_loss_healthcare = calculate_log_loss(y_true, y_pred)\nprint(f\"Healthcare Log-Loss: {log_loss_healthcare}\")\n```", "```py\nHealthcare Log-Loss: 0.20273661557656092\n```", "```py\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\n​\nparams = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}\ngrid_search = GridSearchCV(LogisticRegression(), params, scoring='neg_log_loss', cv=5)\ngrid_search.fit(X_train, y_train)\n​\nprint(f\"Best Parameters: {grid_search.best_params_}\")\n```", "```py\ndef calculate_stable_log_loss(y_true, y_pred, epsilon=1e-15):\n    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n​\n# Example usage\nlog_loss_stable = calculate_stable_log_loss(y_true, y_pred)\nprint(f\"Stable Log-Loss: {log_loss_stable}\")\n```", "```py\nStable Log-Loss: 0.20273661557656092\n```"]