- en: 'Make Python Faster by Caching Functions: Memoization'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过缓存函数提升 Python 速度：记忆化
- en: 原文：[https://towardsdatascience.com/make-python-faster-by-caching-functions-memoization-4fca250ab5f6](https://towardsdatascience.com/make-python-faster-by-caching-functions-memoization-4fca250ab5f6)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/make-python-faster-by-caching-functions-memoization-4fca250ab5f6](https://towardsdatascience.com/make-python-faster-by-caching-functions-memoization-4fca250ab5f6)
- en: PYTHON PROGRAMMING
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PYTHON 编程
- en: The article discusses memoization using the Python standard library. The functools.lru_cache
    decorator makes this so simple!
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这篇文章讨论了使用 Python 标准库进行记忆化。functools.lru_cache 装饰器让这一切变得如此简单！
- en: '[](https://medium.com/@nyggus?source=post_page-----4fca250ab5f6--------------------------------)[![Marcin
    Kozak](../Images/d7faf62e48ed81dab5d8ad92819fff54.png)](https://medium.com/@nyggus?source=post_page-----4fca250ab5f6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4fca250ab5f6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4fca250ab5f6--------------------------------)
    [Marcin Kozak](https://medium.com/@nyggus?source=post_page-----4fca250ab5f6--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@nyggus?source=post_page-----4fca250ab5f6--------------------------------)[![Marcin
    Kozak](../Images/d7faf62e48ed81dab5d8ad92819fff54.png)](https://medium.com/@nyggus?source=post_page-----4fca250ab5f6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4fca250ab5f6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4fca250ab5f6--------------------------------)
    [Marcin Kozak](https://medium.com/@nyggus?source=post_page-----4fca250ab5f6--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4fca250ab5f6--------------------------------)
    ·11 min read·Nov 11, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4fca250ab5f6--------------------------------)
    ·11分钟阅读·2023年11月11日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/e3774b4417d263b6337423d06fdb6a85.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e3774b4417d263b6337423d06fdb6a85.png)'
- en: You can request Python to remember what functions have returned already — and
    to use it. Photo by [Kelly Sikkema](https://unsplash.com/@kellysikkema?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以让 Python 记住函数已经返回的结果，并加以利用。照片由 [Kelly Sikkema](https://unsplash.com/@kellysikkema?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) 提供
- en: 'We all know Python can be slow:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们都知道 Python 可能会很慢：
- en: '[](https://medium.com/pythoniq/the-speed-of-python-it-aint-that-bad-9f703dd2924e?source=post_page-----4fca250ab5f6--------------------------------)
    [## The Speed of Python: It Ain’t That Bad!'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/pythoniq/the-speed-of-python-it-aint-that-bad-9f703dd2924e?source=post_page-----4fca250ab5f6--------------------------------)
    [## Python 的速度：没那么糟糕！'
- en: I hear all the time that Python is way too slow. Is it?
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我经常听到 Python 太慢了。真的如此吗？
- en: medium.com](https://medium.com/pythoniq/the-speed-of-python-it-aint-that-bad-9f703dd2924e?source=post_page-----4fca250ab5f6--------------------------------)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/pythoniq/the-speed-of-python-it-aint-that-bad-9f703dd2924e?source=post_page-----4fca250ab5f6--------------------------------)
- en: What usually takes most time in Python is calling functions and class methods
    that run expensive processes. Imagine for a second that you need to run such a
    function twice for the same arguments; it will need two times as much time even
    though you both calls lead to the very same output. Is it possible to just remember
    this output and use it once more whenever it’s needed?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中，通常最耗时间的操作是调用执行复杂过程的函数和类方法。设想一下，如果你需要对相同的参数运行这样的函数两次，它将需要两倍的时间，即使这两个调用的输出完全相同。是否可以仅仅记住这个输出，并在需要时再次使用它？
- en: 'Yes, you can! It’s called [memoization](https://en.wikipedia.org/wiki/Memoization),
    and it’s a common term in programming. You could implement your own memoization
    techniques, but the truth is, you don’t have to. Python offers you a powerful
    memoization tool, and it does so in the standard library: the `functools.lru_cache`
    decorator.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，你可以！这叫做 [记忆化](https://en.wikipedia.org/wiki/Memoization)，这是编程中的一个常见术语。你可以实现自己的记忆化技术，但实际上你并不需要这样做。Python
    提供了一个强大的记忆化工具，而且它在标准库中：`functools.lru_cache` 装饰器。
- en: Although often very efficient, memoization if often omitted in Python textbooks,
    even those that describe profiling and memory savings during coding. The books
    that do mention memoization in Python include [*Serious Python*](https://nostarch.com/seriouspython)
    by Julien Danjou, [*Fluent Python*, *2nd ed*.](https://www.oreilly.com/library/view/fluent-python-2nd/9781492056348/)
    by Luciano Ramalho, [*Functional Python Programming, 3rd ed.*](https://www.packtpub.com/product/functional-python-programming-third-edition/9781803232577)
    by Steven F. Lott.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管记忆化通常非常高效，但在 Python 教科书中经常被忽略，即使是那些描述代码分析和内存节省的书籍也不例外。提到 Python 中记忆化的书籍包括
    Julien Danjou 的 [*Serious Python*](https://nostarch.com/seriouspython)，Luciano
    Ramalho 的 [*流畅的 Python*, *第2版*](https://www.oreilly.com/library/view/fluent-python-2nd/9781492056348/)，以及
    Steven F. Lott 的 [*函数式 Python 编程, 第3版*](https://www.packtpub.com/product/functional-python-programming-third-edition/9781803232577)。
- en: 'This article shows two things: how simple it is to use memoization in the Python
    standard library (so, using `functools.lru_cache`), and how powerful this technique
    can be. It’s not only milk and honey, however. That’s why we’ll also discuss issues
    you can encounter when using the `functools.lru_cache` caching tool.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本文展示了两件事：如何在 Python 标准库中简单地使用记忆化（即使用`functools.lru_cache`），以及这种技术的强大之处。然而，这并非全是美好的一面。因此，我们也会讨论使用`functools.lru_cache`缓存工具时可能遇到的问题。
- en: '`Caching using the functools module`'
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '`使用 functools 模块进行缓存`'
- en: '`functools.lru_cache`'
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '`functools.lru_cache`'
- en: 'Python offers various memoization tools, but today, we’re talking about the
    one that is part of the Python standard library: `functools.lru_cache`.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Python 提供了各种记忆化工具，但今天，我们讨论的是 Python 标准库的一部分：`functools.lru_cache`。
- en: The LRU caching strategy stands for *Least Recently Used*. In this strategy,
    the least recently used item is removed from the cache when the size of the cache
    has been exceeded.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: LRU 缓存策略代表*最近最少使用*。在这种策略中，当缓存的大小超过限制时，最少使用的项会被从缓存中移除。
- en: 'To use it for a function, decorate it with `@functools.lru_cache`:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要将其用于函数，请使用`@functools.lru_cache`进行装饰：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Note that `foo()` does not take any arguments, which basically means it will
    be run only once during a session:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 注意`foo()`不接受任何参数，这基本上意味着它在一个会话期间只会运行一次：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Indeed, after having been called three times, the function was run only once
    — but we got the same output (`10`) three times.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，在被调用三次之后，函数只运行了一次——但我们得到了相同的输出（`10`）三次。
- en: 'Of course, the real power of function memoization comes with functions that
    take arguments. Such a function is run for each new set of arguments, but whenever
    the same arguments have been used before, the function is not run but the remembered
    output is taken as the function output. Consider the following function:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，函数记忆化的真正威力体现在接受参数的函数上。这样的函数会对每一组新参数进行运行，但每当之前已经使用过相同的参数时，函数不会重新运行，而是使用记住的输出作为函数的输出。考虑以下函数：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Note the type of `sum_of_powers`:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 注意`sum_of_powers`的类型：
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'So its type is not `function` but `lru_cache_wrapper`. Let’s see the function
    in action:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 所以它的类型不是`function`而是`lru_cache_wrapper`。让我们看看函数的实际效果：
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: So, the last two calls of the function did not actually run it — but thanks
    to memoization, the function returned the output anyway.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，函数的最后两次调用实际上并没有运行它——但由于记忆化，函数仍然返回了输出。
- en: You can use the `maxsize` argument to `lru_cache` to indicate how many items
    are being kept in the cache. The default value is `128`. As Luciano Ramalho explains
    in his [*Fluent Python. 2nd ed*](https://www.oreilly.com/library/view/fluent-python-2nd/9781492056348/)*.*
    book, for optimum performance you should use `maxsize` values that are the power
    of `2`. When `maxsize` is `None`, the the cache can keep any number of objects
    more precisely, as many as memory allows. Be cautious, as this may cause the memory
    run out.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用`lru_cache`的`maxsize`参数来指示缓存中保持的项的数量。默认值为`128`。正如 Luciano Ramalho 在他的 [*流畅的
    Python. 第2版*](https://www.oreilly.com/library/view/fluent-python-2nd/9781492056348/)*.*
    书中解释的那样，为了获得最佳性能，你应该使用`maxsize`值为`2`的幂。当`maxsize`为`None`时，缓存可以保存任何数量的对象，更准确地说，是内存允许的数量。请谨慎，因为这可能会导致内存耗尽。
- en: You can use one more argument, that is, `typed`, which is a Boolean object with
    the default value of `False`. When it’s `True`, the same value of different types
    would be kept separately. So, an integer value `1` and a float value of `1.0`
    would be kept as separate items. When `typed=False` (the default), they would
    be kept as one item.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用一个额外的参数，即`typed`，它是一个布尔对象，默认值为`False`。当它为`True`时，不同类型的相同值会被分别保存。因此，整数值`1`和浮点值`1.0`会作为不同的项保存。当`typed=False`（默认值）时，它们会被作为一个项保存。
- en: 'There’s a way to learn how caching worked for a function decorated with `functools.lru_cache`,
    thanks to a `cache_info` attribute added to the function. More precisely, it’s
    a method:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种方法可以了解装饰了`functools.lru_cache`的函数是如何工作的，感谢函数中添加的`cache_info`属性。更准确地说，这是一个方法：
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'And this is how the `cache_info()` works:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是`cache_info()`的工作原理：
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This means the following:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着以下几点：
- en: '`hits=2` → the cache has been used twice; indeed, we used the function twice
    for `x=(1, 1, 2)` and `pow=2` and twice for `x=(1, 1, 2)` and `pow=3`, but the
    cache was used once per each value of `x`.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hits=2` → 缓存被使用了两次；实际上，我们对`x=(1, 1, 2)`和`pow=2`使用了函数两次，对`x=(1, 1, 2)`和`pow=3`也使用了两次，但缓存对于每个`x`的值只使用了一次。'
- en: '`misses=2` → this output represents the two calls to the function with new
    argument values, so when cache was not used. The more misses-to-hits ratio, the
    less useful caching is because the function is often used with new values of arguments
    and seldom with the argument values that have been already used.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`misses=2` → 这个输出表示两个具有新参数值的函数调用，因此缓存未被使用。未命中的次数与命中的次数比率越高，缓存的效果越差，因为函数经常使用新的参数值，而很少使用已经使用过的参数值。'
- en: '`maxsize=128` → the size of the cache; we’ll discuss in below.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxsize=128` → 缓存的大小；我们将在下文中讨论。'
- en: '`currsize=2` → the number of elements already being kept in the cache.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`currsize=2` → 缓存中已保留的元素数量。'
- en: In a real life project in which you want to use caching, it’s good to experiment
    with it, and the `cache_info()` method can be very helpful with that. Remember
    that caching shouldn’t be used automatically for any function; it may lead to
    time losses rather than gains, as caching itself needs some time.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个实际项目中，如果你想使用缓存，最好先进行一些实验，而`cache_info()`方法对此非常有帮助。记住，缓存不应该自动用于任何函数；这可能导致时间损失而不是收益，因为缓存本身也需要一些时间。
- en: '`functools.cache`'
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '`functools.cache`'
- en: As of Python 3.9, the `functools` module offers also [the](https://docs.python.org/3.9/library/functools.html#functools.cache)
    `[cache](https://docs.python.org/3.9/library/functools.html#functools.cache)`
    [decorator](https://docs.python.org/3.9/library/functools.html#functools.cache).
    It’s just a wrapper around `functools.lru_cache` in which `maxsize=None`. So,
    decorating with `functools.cache` is equivalent to decorating with `functools.lru_cache(maxsize=None)`.
    To be honest, I don’t think it’s a necessary amendment — the standard library
    doesn’t need, in my opinion, such overly simplified wrappers. What’s wrong with
    using `functools.lru_cache(maxsize=None)`?
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 从 Python 3.9 开始，`functools`模块还提供了[the](https://docs.python.org/3.9/library/functools.html#functools.cache)
    `[cache](https://docs.python.org/3.9/library/functools.html#functools.cache)`
    [decorator](https://docs.python.org/3.9/library/functools.html#functools.cache)。这只是一个包装器，围绕着`functools.lru_cache`，其中`maxsize=None`。因此，使用`functools.cache`装饰器等同于使用`functools.lru_cache(maxsize=None)`。说实话，我认为这不是一个必要的修正——在我看来，标准库不需要这样过于简化的包装器。使用`functools.lru_cache(maxsize=None)`有什么问题吗？
- en: Comments
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 注释
- en: Use for class methods
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于类方法
- en: 'Function caching is considered to be a functional-programming tool, but it
    can just as well be used for class methods. Unlike Python functions, a Python
    class can have state, which is why it’s simple to implement individual caching
    within a class:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 函数缓存被认为是一种函数式编程工具，但它也可以用于类方法。与 Python 函数不同，Python 类可以有状态，这就是为什么在类中实现单独的缓存很简单：
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This is a very simplified caching approach, and one that would not work after
    changing the `self.letter` attribute in the class’s instance. It’s easy to solve
    this issue, however, for instance by making `self.cache` a dictionary of dictionaries
    being assigned to keys being letters. I’ll leave you the implementation as an
    exercise.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种非常简化的缓存方法，而且在更改类实例中的`self.letter`属性后将无法工作。不过，这个问题很容易解决，例如，可以通过将`self.cache`设为一个以字母为键的字典的字典来解决。我将实现留给你作为练习。
- en: 'This was an example how to do it manually, but we can use the `functools.lru_cache`
    decorator as well. Doing so as simple as for a function: enough to decorate the
    method inside the class definition:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个手动实现的示例，但我们也可以使用`functools.lru_cache`装饰器。与函数的用法一样简单：只需在类定义中装饰方法即可：
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As you can see, this works just like with functions, so don’t hesitate to use
    the `functools.lru_cache` decorator also for class methods when you see such a
    need.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，这与函数的使用方式完全相同，所以当你看到这样的需求时，不要犹豫，也为类方法使用`functools.lru_cache`装饰器。
- en: Only hashable arguments
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 仅支持可哈希参数
- en: 'Standard caching employs mapping using a hash table. This means that it wouldn’t
    work for functions with unhashable arguments. Thus, for example, you cannot use
    caching for objects of the following types: lists, sets and dictionaries.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 标准缓存使用哈希表进行映射。这意味着对于具有不可哈希参数的函数，它将不起作用。因此，例如，你不能对以下类型的对象使用缓存：列表、集合和字典。
- en: 'Let’s analyze the above function, `sum_of_powers()`. Its `x` argument has a
    general type of `Sequence[float]`. `collections.Sequence` does not say anything
    being hashable or not; and indeed, some types that follow this protocol are hashable,
    such as `tuple`, but others aren’t, such as `list`. Note:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入分析上述函数`sum_of_powers()`。它的`x`参数的通用类型是`Sequence[float]`。`collections.Sequence`并未说明其是否可哈希；实际上，遵循该协议的一些类型是可哈希的，例如`tuple`，但其他一些则不是，例如`list`。注意：
- en: '[PRE9]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Just so you know, static type checkers can point you out a call of a caching-decorated
    function that uses an unhashable argument. This call is fine:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 仅供参考，静态类型检查器可以指出使用不可哈希参数调用的缓存装饰函数。这种调用是正常的：
- en: '![](../Images/869711fbc572a9dc49e05152110f663d.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/869711fbc572a9dc49e05152110f663d.png)'
- en: A screenshot from Visual Studio Code. No static errors when the function is
    called with a tuple, which is hashable. Image by author
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 Visual Studio Code 的截图。函数调用时使用了一个可哈希的元组，没有静态错误。图像由作者提供
- en: 'but this one isn’t:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 但这个例外：
- en: '![](../Images/4db0874895e429e27c5bec92f4f38973.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4db0874895e429e27c5bec92f4f38973.png)'
- en: A screenshot from Visual Studio Code. [Mypy](https://mypy.readthedocs.io/en/stable/)
    points out a static error indicating an attempt to cache a function called with
    a list, which is unhashable. Image by author
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 Visual Studio Code 的截图。[Mypy](https://mypy.readthedocs.io/en/stable/) 指出静态错误，表明尝试缓存一个使用列表（不可哈希）的函数。图像由作者提供
- en: Pure and non-pure functions
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 纯函数和非纯函数
- en: You may have heard that memoization should be used solely for so-called pure
    functions, that is, functions without side effects. A side effect is something
    that’s done in the background; for example, a global variable is being changed,
    data are being read from a database, information is being logged.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能听说过，记忆化应该仅用于所谓的纯函数，即没有副作用的函数。副作用是指在后台进行的操作；例如，改变全局变量，从数据库中读取数据，记录信息。
- en: Usually, non-pure functions should not be cached indeed, but there are a few
    exceptions. For example, imagine a function that generates a report and saves
    it to a file, based on the provided values of the function’s arguments. Caching
    the function will mean generating the report for these argument values only once
    instead of every time the function is called with these values. In general, costs
    of I/O operations can be saved thanks to caching. In this case, however, we must
    be sure that the side effect of such a function doesn’t differ for its subsequent
    calls. This could happen, for example, when a function would overwrite the file
    with a new file with the very same contents — but the time of this operations
    matters.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，非纯函数确实不应缓存，但也有一些例外。例如，想象一个生成报告并将其保存到文件中的函数，基于提供的函数参数值。缓存该函数意味着只生成一次这些参数值的报告，而不是每次函数调用时都生成一次。一般来说，通过缓存可以节省
    I/O 操作的成本。然而，在这种情况下，我们必须确保该函数的副作用在后续调用中不会发生变化。例如，如果一个函数会用完全相同内容的新文件覆盖旧文件，但操作时间很重要。
- en: 'In fact, we have observed caching of functions with side effects. We did so
    above, when we cached functions that printed a message to the console. As you
    can recall, the functions printed messages only during the first call but not
    when the cache was used. This is exactly what we’re talking about: When the side
    effect doesn’t matter, you can use caching; when it does, you shouldn’t as you
    risk that the side effect will be observed only during the first call of the function
    but not during the subsequent ones.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们已经观察到具有副作用的函数的缓存。我们在上面做过，当我们缓存打印消息到控制台的函数时。正如你可以回忆的，这些函数只在第一次调用时打印消息，而在使用缓存时不再打印。这正是我们所说的：当副作用不重要时，你可以使用缓存；当副作用重要时，你应该避免，因为你可能会面临副作用只在函数第一次调用时被观察到，而在后续调用中没有观察到的风险。
- en: Performance
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能
- en: I will not present you the example typically presented for caching, that is,
    a function calculating factorials. Instead, I will use a very simple function
    that creates a simple dictionary using a dict comprehension.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会展示通常用于缓存的示例，即计算阶乘的函数。相反，我将使用一个非常简单的函数，它使用 dict comprehension 创建一个简单的字典。
- en: 'I will use the following code:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用以下代码：
- en: '[PRE10]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You can run this script for various `n` values, which is used as an argument
    of the two benchmarked functions. It’s easy to guess the hypothesis behind the
    experiment: the bigger the value of `n`, that is, the larger the dictionary created
    by the two functions, the bigger the caching effect should be.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以对不同的`n`值运行这个脚本，`n`作为两个基准函数的参数。很容易猜到实验背后的假设：`n`值越大，即两个函数创建的字典越大，缓存效果应该越明显。
- en: 'We’ll see if this is the case soon. We will run the script for the following
    `n` values: `1`, `10`, `100`, `1000`, `10_000` and `100_000`. The number of runs
    needs to be adjusted so that the tests don’t take too much time — but you can
    run the experiments yourself with more runs; to do so, change this fragment: `Number=int(1_000_000
    / n)`.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很快就会看到是否如此。我们将对以下`n`值运行脚本：`1`、`10`、`100`、`1000`、`10_000` 和 `100_000`。运行次数需要调整，以避免测试时间过长——但你可以自己用更多的运行次数进行实验；为此，请更改以下片段：`Number=int(1_000_000
    / n)`。
- en: You may be wondering why I did not create a loop to run all the benchmarks in
    one run of the script. This is because each experiment should be independent;
    otherwise, we could risk that the results of the subsequent experiments would
    be biased. It’s always best to run benchmarks individually, without combining
    them in the same run of a script.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道为什么我没有创建一个循环来在脚本的一次运行中运行所有基准测试。这是因为每个实验应该是独立的；否则，我们可能会冒险使后续实验的结果受到偏见。最好是单独运行基准测试，不要在脚本的同一次运行中将它们结合起来。
- en: 'The script prints the best results for each function and one more metrics:
    how many times the cached function was faster than the non-cached one. Below,
    I will show only this ratio:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本打印每个函数的最佳结果以及一个额外的指标：缓存函数比未缓存函数快了多少次。下面，我将只展示这个比率：
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: As you can see, the performance of caching is amazing, but at some point (here,
    for `n` of `10_000`) its performance drops significantly; for even bigger `n`,
    it drops dramatically. Can we fix that?
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，缓存的性能非常出色，但在某个点上（这里是`10_000`的`n`值）性能显著下降；对于更大的`n`，性能则急剧下降。我们能解决这个问题吗？
- en: 'Unfortunately, we can’t. The only change we can make in this function is choosing
    `maxsize`, which would be of no use here as the cache keeps only one element:
    the dictionary for the given value of `n`.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，我们不能。我们可以在这个函数中做的唯一更改是选择`maxsize`，但在这里没有用，因为缓存只保留一个元素：给定`n`值的字典。
- en: Therefore, I am afraid we cannot improve the performance of `functools.lru_cache`
    in the case of so large items being kept in cache. As you’ll see below, this is
    not an issue of the caching technique, but of caching itself.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我担心在处理如此大项的缓存时，我们无法提高`functools.lru_cache`的性能。如你所见，这不是缓存技术的问题，而是缓存本身的问题。
- en: 'Our performance experiment taught us two significant things:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的性能实验教会了我们两件重要的事情：
- en: Caching using `functools.lru_cache` can help increase performance, even a lot.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`functools.lru_cache`进行缓存可以显著提高性能。
- en: Caching very large objects can decrease performance as compared to caching smaller
    objects.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缓存非常大的对象可能会降低性能，而相比之下缓存较小的对象性能更佳。
- en: Let’s implement our own simple caching and check out if the same situation happens
    for it. This will be an overly simplified caching tool, something I wouldn’t decide
    to use in a real life project.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们实现一个简单的自定义缓存，看看它是否会出现相同的情况。这将是一个过于简化的缓存工具，是我在实际项目中不会决定使用的。
- en: 'This is the code:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是代码：
- en: '[PRE12]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'and here are the results:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '[PRE13]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: They differ a little bit from the previous ones, but the trend is the same.
    This shows it’s not the strategy that `functools.lru_cache` uses that was the
    reason behind this significant drop in performance. Most likely, it’s the size
    of the output (here, the dictionary).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 它们与之前的结果有些不同，但趋势是一样的。这表明，`functools.lru_cache`使用的策略并不是导致性能显著下降的原因。最可能的原因是输出的大小（这里是字典）。
- en: Conclusion
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Caching is a fantastic tool, one that can help improve performance, even a lot.
    A great thing is, it doesn’t take much time to learn how to use it, and using
    it is simple, too.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存是一个极好的工具，可以显著提高性能。好的一点是，它学习使用的时间不长，而且使用起来也很简单。
- en: The Python standard library offers caching via the `functools.lru_cache` decorator.
    Oftentimes, it’ll be exactly what you need, but sometimes its limitations can
    make it impossible to use it. The most significant one seems to be inability to
    use unhashable arguments. The other one is that caching should be used only for
    pure functions; nonetheless, it’s not always the case, as we discussed above.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Python 标准库通过 `functools.lru_cache` 装饰器提供缓存功能。它通常能完全满足你的需求，但有时其局限性可能使其无法使用。最显著的限制似乎是无法使用不可哈希的参数。另一个限制是缓存应仅用于纯函数；然而，正如我们上面讨论的，这并不总是如此。
- en: We’re not done with caching. In this article, we discussed the Python standard
    library tool, but in a future article, we’ll discuss PyPi caching tools, such
    as [cache3](https://github.com/StKali/cache3) and [cachetools](https://github.com/tkem/cachetools/).
    We’ll compare their performance with that of `functools.lru_cache`, and we will
    consider their pros and cons.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还没有完成缓存的讨论。在这篇文章中，我们探讨了 Python 标准库工具，但在未来的文章中，我们将讨论 PyPi 缓存工具，如 [cache3](https://github.com/StKali/cache3)
    和 [cachetools](https://github.com/tkem/cachetools/)。我们将比较它们与 `functools.lru_cache`
    的性能，并考虑它们的优缺点。
- en: 'Thanks for reading. If you enjoyed this article, you may also enjoy other articles
    I wrote; you will see them [here](https://medium.com/@nyggus). And if you want
    to join Medium, please use my referral link below:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读。如果你喜欢这篇文章，你也可能会喜欢我写的其他文章；你可以在 [这里](https://medium.com/@nyggus) 查看。如果你想加入
    Medium，请使用下面的推荐链接：
- en: '[](https://medium.com/@nyggus/membership?source=post_page-----4fca250ab5f6--------------------------------)
    [## Join Medium with my referral link - Marcin Kozak'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@nyggus/membership?source=post_page-----4fca250ab5f6--------------------------------)
    [## 使用我的推荐链接加入 Medium - Marcin Kozak'
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every story…
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 作为 Medium 会员，你的一部分会费将分配给你阅读的作者，你可以完全访问每个故事……
- en: medium.com](https://medium.com/@nyggus/membership?source=post_page-----4fca250ab5f6--------------------------------)
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@nyggus/membership?source=post_page-----4fca250ab5f6--------------------------------)
