- en: Can Language Models Make Their Own Tools?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语言模型能否自制工具？
- en: 原文：[https://towardsdatascience.com/can-language-models-make-their-own-tools-cbc7c3777d22](https://towardsdatascience.com/can-language-models-make-their-own-tools-cbc7c3777d22)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/can-language-models-make-their-own-tools-cbc7c3777d22](https://towardsdatascience.com/can-language-models-make-their-own-tools-cbc7c3777d22)
- en: LaTM, CREATOR, and other closed-loop frameworks for LLM tool usage…
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LaTM、CREATOR以及其他LLM工具使用的闭环框架……
- en: '[](https://wolfecameron.medium.com/?source=post_page-----cbc7c3777d22--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----cbc7c3777d22--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cbc7c3777d22--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cbc7c3777d22--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----cbc7c3777d22--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://wolfecameron.medium.com/?source=post_page-----cbc7c3777d22--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----cbc7c3777d22--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cbc7c3777d22--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cbc7c3777d22--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----cbc7c3777d22--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cbc7c3777d22--------------------------------)
    ·16 min read·Sep 17, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----cbc7c3777d22--------------------------------)
    ·阅读时间16分钟·2023年9月17日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/dcbddb8cfa90114c42e1cb68195ad874.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dcbddb8cfa90114c42e1cb68195ad874.png)'
- en: (Photo by [Todd Quackenbush](https://unsplash.com/@toddquackenbush?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/IClZBVw5W5A?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText))
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: （照片由[Todd Quackenbush](https://unsplash.com/@toddquackenbush?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)提供，来源于[Unsplash](https://unsplash.com/photos/IClZBVw5W5A?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)）
- en: In recent overviews, we have explored the utility of augmenting large language
    models (LLMs) with external tools. These models can be taught to leverage tools
    in a variety of ways. However, we should realize that existing tool-following
    LLMs leverage only a limited set of potential tools [3], *whereas the range of
    problems we want to solve with LLMs is nearly endless!* With this in mind, it
    becomes clear that such a paradigm is limiting — we will always be able to find
    scenarios that require tools that do not yet exist. In this overview, we will
    explore recent research that aims to solve this problem by providing LLMs with
    the skills to create their own tools. Such an approach draws an interesting analogy
    to human life, as the ability to fabricate tools led to major technological advancements.
    Now, we explore the impact of similar techniques upon the evolution of LLMs.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在最近的综述中，我们探讨了通过外部工具增强大型语言模型（LLMs）的实用性。这些模型可以被教导以多种方式利用工具。然而，我们应该意识到，现有的工具跟随LLMs仅利用了一小部分潜在工具[3]，*而我们希望用LLMs解决的问题范围几乎是无穷无尽的！*
    考虑到这一点，显而易见，这种范式是有限制的——我们总是能找到需要尚不存在的工具的情景。在本综述中，我们将探讨旨在解决这一问题的最新研究，通过赋予LLMs创造自身工具的能力来解决这一问题。这种方法与人类生活有趣地类比，因为制造工具的能力导致了重大的技术进步。现在，我们探讨类似技术对LLMs进化的影响。
- en: “According to the lessons learned from the evolutionary milestones of humans,
    a crucial turning point was that humans got the ability to fabricate their own
    tools to address emerging challenges. We embark on an initial exploration to apply
    this evolutionary concept to the realm of LLMs.” *— from [1]*
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “根据人类进化里程碑的经验教训，一个关键的转折点是人类获得了制造自身工具以应对新兴挑战的能力。我们开始初步探索将这一进化概念应用于LLMs领域。” *—
    引自 [1]*
- en: '![](../Images/34e0b7f7c970f62479d2f3d43fa0d46b.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/34e0b7f7c970f62479d2f3d43fa0d46b.png)'
- en: (from [1, 2])
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: （来源于 [1, 2]）
- en: Background
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 背景
- en: Prior to learning more about tool-making LLMs, there are a few background concepts
    that we need to refresh. We have covered many of these ideas in recent overviews,
    but we’ll briefly go over them again now to make our discussion of recent publications
    more comprehensive and understandable.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在进一步了解工具制造的LLMs之前，我们需要刷新一些背景概念。我们在最近的综述中已经覆盖了许多这些概念，但我们现在会简要地再次讨论它们，以使我们对最新出版物的讨论更加全面和易于理解。
- en: Why should we use tools?
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么我们应该使用工具？
- en: '![](../Images/5eedac10a8b560004f894d36dcc91c53.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5eedac10a8b560004f894d36dcc91c53.png)'
- en: (from [3, 8, 9])
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: (来自 [3, 8, 9])
- en: 'In prior overviews, we have learned about a few different kinds of tools that
    can be integrated with LLMs to improve their performance, such as:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的概述中，我们已经了解了几种不同类型的工具，这些工具可以与 LLM 集成以改善其性能，例如：
- en: Basic Tools (calculators, search engines, etc.) [[link](/teaching-language-models-to-use-tools-7fd58916c66b)]
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础工具（计算器、搜索引擎等） [[链接](/teaching-language-models-to-use-tools-7fd58916c66b)]
- en: Deep Learning Model APIs [[link](/language-models-and-friends-gorilla-hugginggpt-taskmatrix-and-more-b88c1200afd3)]
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习模型 API [[链接](/language-models-and-friends-gorilla-hugginggpt-taskmatrix-and-more-b88c1200afd3)]
- en: By giving LLMs access to certain tools, we can easily solve limitations that
    these models have, such as lacking up-to-date information, failing to perform
    simple arithmetic, hallucinating facts, or making errors in long chains of reasoning.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 通过让 LLM 访问某些工具，我们可以轻松解决这些模型存在的限制，例如缺乏最新信息、无法进行简单的算术运算、产生虚假信息或在长链推理中出错。
- en: '![](../Images/7718ca32c8d29642c95c0faadec6fcbb.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7718ca32c8d29642c95c0faadec6fcbb.png)'
- en: (from [3])
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: (来自 [3])
- en: '**Tools provide context.** For example, if an LLM is asked a question about
    a pop culture event in recent weeks, it is unlikely to have needed information
    to provide an accurate answer due to its knowledge cutoff. In some cases, the
    LLM might hallucinate an incorrect answer that seems plausible and mislead the
    user with incorrect information — *this is a major problem because many (non-technical)
    users of LLMs like ChatGPT treat these model like a search engine*! To solve this
    issue, we can provide a tool that allows the LLM to perform search queries and
    retrieve up-to-date information from the internet as extra context; see above.
    This way, the LLM can memorize less information, relying instead on in-context
    learning to arrive at an accurate final answer based upon up-to-date information
    provided by a tool.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**工具提供上下文。** 例如，如果 LLM 被问到关于最近几周的流行文化事件的问题，由于知识截止日期，它不太可能提供准确的答案。在某些情况下，LLM
    可能会产生看似可信的错误答案，并误导用户提供不正确的信息 — *这是一个重大问题，因为许多（非技术性）LLM 用户如 ChatGPT 使用这些模型就像使用搜索引擎一样*!
    为了解决这个问题，我们可以提供一个工具，允许 LLM 执行搜索查询并从互联网上获取最新信息作为额外上下文；见上文。这样，LLM 可以记住更少的信息，而依赖上下文学习，通过工具提供的最新信息得出准确的最终答案。'
- en: “By empowering LLMs to use tools, we can grant access to vastly larger and changing
    knowledge bases and accomplish complex computational tasks.” *— from [3]*
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “通过赋能 LLM 使用工具，我们可以获得更广泛和不断变化的知识库，并完成复杂的计算任务。” *— 来自 [3]*
- en: One interesting tool that we will see used as a baseline within this overview
    is the Wolfram ChatGPT plugin. The plugin ecosystem for ChatGPT integrates LLMs
    with external tools via their APIs. Basically, we provide a description of the
    API to ChatGPT, and the model learns how to use this tool (i.e., make calls to
    its API) via a prompting approach; more details [here](https://cameronrwolfe.substack.com/i/123558334/using-tools-is-getting-easier).
    To learn more about the Wolfram plugin (it’s super useful!), check out the awesome
    overview [here](https://www.wolfram.com/wolfram-plugin-chatgpt/).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次概述中，我们将看到一个有趣的工具作为基准使用，即 Wolfram ChatGPT 插件。ChatGPT 的插件生态系统通过 API 将 LLM 与外部工具集成。基本上，我们向
    ChatGPT 提供 API 的描述，模型通过提示方法学习如何使用该工具（即调用其 API）；更多详细信息 [这里](https://cameronrwolfe.substack.com/i/123558334/using-tools-is-getting-easier)。要了解更多关于
    Wolfram 插件的信息（它非常有用！），请查看精彩概述 [这里](https://www.wolfram.com/wolfram-plugin-chatgpt/)。
- en: '**This overview.** A lot of different types or genres of tools exist, but we
    will focus upon a particular type of tool — *those that are actually created by
    an LLM*. Typically, these tools are formatted as standalone Python functions that
    accomplish some task or sub-task that is useful to the LLM. Tools are created
    by directly prompting a code-enabled LLM to generate a needed function. By allowing
    LLMs to create their own tools, *problem-solving systems are no longer limited
    by the fixed set of tools that they have available*. We can identify needed functionality
    over time and enable the LLM to automatically create any tool that would be helpful!'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**本概述。** 存在许多不同类型或类别的工具，但我们将重点关注一种特定类型的工具 — *那些实际上由 LLM 创建的工具*。通常，这些工具被格式化为独立的
    Python 函数，完成对 LLM 有用的某些任务或子任务。工具通过直接提示支持代码的 LLM 生成所需的功能而创建。通过允许 LLM 创建自己的工具，*解决问题的系统不再受限于固定的工具集合*。我们可以随着时间的推移识别所需的功能，并使
    LLM 能够自动创建任何有用的工具！'
- en: Prompting Techniques
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示技术
- en: '![](../Images/e99bd26c9bf61aeed80a9bd70e2fd5fb.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e99bd26c9bf61aeed80a9bd70e2fd5fb.png)'
- en: Language models solve many different tasks with a unified format (from [10])
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型以统一的格式解决许多不同的任务（来自 [10]）
- en: The generic text-to-text structure of a language model is incredibly powerful,
    as it allows us to solve many different tasks by just *i)* formatting the problem
    as a textual prompt and *ii)* extracting relevant output information from the
    text returned by the model. However, using language models is not usually quite
    this simple. The wording and structure of the prompt that we provide to the model
    can drastically alter its effectiveness — prompt engineering is a huge deal!
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型的通用文本到文本结构极为强大，因为它允许我们通过 *i)* 将问题格式化为文本提示和 *ii)* 从模型返回的文本中提取相关输出信息来解决许多不同的任务。然而，使用语言模型通常没有这么简单。我们提供给模型的提示的措辞和结构可以极大地改变其效果——提示工程至关重要！
- en: Recently, we have gone over a lot of different practical tricks and techniques
    for getting the most out of an LLM via prompt engineering.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，我们讨论了许多实用技巧和技术，以通过提示工程充分利用 LLM。
- en: Practical Prompt Engineering [[link](/practical-prompt-engineering-74e96130abc4)]
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实用提示工程 [[link](/practical-prompt-engineering-74e96130abc4)]
- en: Advanced Prompt Engineering [[link](/advanced-prompt-engineering-f07f9e55fe01)]
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级提示工程 [[link](/advanced-prompt-engineering-f07f9e55fe01)]
- en: However, there are two particular prompting techniques that are especially relevant
    to this post — chain of thought (CoT) [6] and program of thoughts (PoT) [7] prompting.
    Both of these techniques aim to improve the ability of a language model to reliably
    solve complex, reasoning-based tasks.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有两种特别相关的提示技术——思维链（CoT） [6] 和思维程序（PoT） [7] 提示。这两种技术都旨在提高语言模型可靠解决复杂推理任务的能力。
- en: '![](../Images/acd0369561136554d21a89c1412a5094.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/acd0369561136554d21a89c1412a5094.png)'
- en: (from [6])
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [6]）
- en: '**Chain of thought.** For a long time, LLMs were criticized for their inability
    to solve reasoning-based tasks. Although this issue has been mitigated with recent
    model variants, techniques such as CoT prompting can elicit better reasoning abilities
    within these models nonetheless. *How is this possible?* We simply need to provide
    the LLM with examples of reasoning-based problems being broken down into a step-by-step
    solution (i.e., a problem-solving rationale or “chain of thought”). These examples
    are inserted directly into the LLM’s prompt. Then, the model can use its in-context
    learning capabilities to generate a similar rationale when solving a problem posed
    by a user. Interestingly, generating such rationales drastically improves LLM
    performance on reasoning-based tasks.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**思维链。** 长期以来，LLM 因无法解决基于推理的任务而受到批评。尽管这一问题已通过最近的模型变体得到缓解，但诸如 CoT 提示等技术仍能引发这些模型更好的推理能力。*这怎么可能？*
    我们只需要向 LLM 提供将基于推理的问题分解为逐步解决的示例（即问题解决的理由或“思维链”）。这些示例直接插入 LLM 的提示中。然后，模型可以利用其上下文学习能力，在解决用户提出的问题时生成类似的理由。有趣的是，生成这样的理由会大幅提高
    LLM 在基于推理的任务上的表现。'
- en: '![](../Images/aa769348f15efcaff10fe1d38cf24960.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aa769348f15efcaff10fe1d38cf24960.png)'
- en: (from [11, 12, 13])
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [11, 12, 13]）
- en: Beyond vanilla CoT prompting, numerous variants have also been proposed; see
    above. The idea of enabling LLMs to solve difficult problems by breaking them
    into smaller parts and solving them step-by-step is incredibly powerful. But,
    we can do this in several different ways (some of which are actually quite a bit
    simpler than CoT prompting) — *CoT prompting is not always our best option*.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 除了普通的 CoT 提示外，还有许多变体被提出；见上文。通过将难题分解成更小的部分并逐步解决，让 LLM 解决复杂问题的理念极为强大。然而，我们可以通过几种不同的方式来实现这一点（其中一些实际上比
    CoT 提示更简单）——*CoT 提示并不总是我们最佳的选择*。
- en: '**Program of thoughts.** Thought CoT prompting variants work well, they fail
    to model concepts like iteration and are subject to a compositionality gap, meaning
    that the LLM may correctly solve every step of a problem but still generate an
    incorrect final answer. To mitigate these problems, recent research has explored
    program-aided language models. These techniques are similar to CoT prompting,
    but we use code-enabled LLMs (e.g., Codex [14]) to generate a hybrid problem-solving
    rationale that contains both code and natural language components — *basically
    a program with informative comments*. Then, we can execute the program created
    by the LLM (using an external interpreter) to yield a final answer!'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**思维程序。** 尽管思维CoT提示变体效果良好，但它们未能建模像迭代这样的概念，并且存在组成性差距，这意味着LLM可能正确解决了问题的每一步，但最终答案仍然可能不正确。为了缓解这些问题，最近的研究探索了程序辅助的语言模型。这些技术类似于CoT提示，但我们使用代码支持的LLM（例如，Codex
    [14]）生成包含代码和自然语言组件的混合问题解决方案——*基本上是带有信息性注释的程序*。然后，我们可以使用外部解释器执行LLM创建的程序，以得出最终答案！'
- en: '![](../Images/1fb4fbd8cd57f15a4fcaadf1ea7ef34e.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1fb4fbd8cd57f15a4fcaadf1ea7ef34e.png)'
- en: (from [7])
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: （来源：[7]）
- en: The basic idea behind PoT prompting is that there are certain ideas and concepts
    that are much easier to model within a program. Instead of using the LLM to both
    solve subtasks and generate a final answer from all of these solutions, we can
    delegate a portion of this process to a system that is more reliable. Namely,
    programs can more easily model and solve mathematical equations, perform iteration,
    and much more, thus lessening the compositionality gap for LLMs.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: PoT提示的基本思想是某些想法和概念在程序中建模起来更容易。与其让LLM既解决子任务又从这些解决方案中生成最终答案，我们可以将部分过程委托给更可靠的系统。即，程序可以更容易地建模和解决数学方程式，执行迭代等，从而减少LLM的组成性差距。
- en: A Turning Point in Tool Usage
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工具使用的转折点
- en: “Instead of letting the LLMs act as the users of tools, we enable them to be
    the creators of tools and solve problems with higher accuracy and flexibility.”
    *— from [2]*
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “与其让LLM作为工具的用户，不如让它们成为工具的创造者，以更高的准确性和灵活性解决问题。” *— 来源于[2]*
- en: At this point, we should probably be convinced that tools are a useful addition
    to existing language models. But, *what becomes possible when we expand the scope
    of available tools to anything that an LLM can create?* Put simply, such an approach
    forms a closed-loop framework, in which LLMs are given the ability to arbitrarily
    improve their own functionality. As we will see moving forward, existing models
    are surprisingly capable of making their own tools, which enables dynamic adaptation
    to solving new, difficult problems over time.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们可能应该确信工具是对现有语言模型的有用补充。但是，*当我们将可用工具的范围扩展到LLM可以创建的任何工具时，会有什么可能性？* 简而言之，这种方法形成了一个闭环框架，在这个框架中，LLM被赋予了随意改进自身功能的能力。正如我们接下来会看到的，现有模型在制作自己的工具方面出乎意料地有能力，这使得它们能够随着时间的推移动态适应解决新的、困难的问题。
- en: Decoupling Tool Making and Tool Usage
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解耦工具制作和工具使用
- en: We know that using external tools can greatly improve the problem solving capabilities
    of LLMs [3]. However, prior work in this area assumes that needed tools already
    exist and are available for the LLM. As such, there exists a dependence upon humans
    to craft and curate a set of needed tools that comprehensively addresses needed
    functionality for solving any task. But, *what if the LLM needs a tool that is
    not included in its tool belt?* Existing tool-following approaches have no solution
    for a problem like this!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道，使用外部工具可以极大地提高LLM的解决问题能力[3]。然而，该领域的先前工作假设所需的工具已经存在并可供LLM使用。因此，这种方法依赖于人工制作和策划一套全面解决任何任务所需功能的工具。但是，*如果LLM需要一个工具，而这个工具不在它的工具箱里怎么办？*
    现有的工具跟随方法对此类问题没有解决方案！
- en: As an alternative approach, authors in [2] propose a “closed-loop” framework
    that uses the LLM itself to construct needed tools on-the-fly. This framework,
    called LLMs as Tool Makers (LaTM), allows LLMs to continually generate tools that
    are needed to solve different complex reasoning tasks; see below.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 作为替代方法，[2]中的作者提出了一种“闭环”框架，该框架利用LLM自身即时构建所需工具。这个框架称为LLMs作为工具制造者（LaTM），它允许LLM不断生成解决不同复杂推理任务所需的工具；见下文。
- en: '![](../Images/c5e94edf24871fa201bd8d3406fadf60.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c5e94edf24871fa201bd8d3406fadf60.png)'
- en: (from [1])
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: （来源：[1]）
- en: '**Two-phase tooling approach.** LaTM uses a two-phase framework of:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**两阶段工具方法。** LaTM使用两阶段框架：'
- en: '*Tool making:* crafting a tool (i.e., a Python function) for a given task'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*工具制作：* 为给定任务制作工具（即 Python 函数）'
- en: '*Tool Using:* using an existing tool to solve a task'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*工具使用：* 使用现有工具来解决任务'
- en: Notably, we do not have to use the same LLM for both of these phases. For example,
    we could apply a more powerful model (e.g., [GPT-4](https://platform.openai.com/docs/models/gpt-4))
    to tool making, while using a lightweight and cost-effective model (e.g., [GPT-3.5-turbo](https://platform.openai.com/docs/models/gpt-3-5))
    for tool using. Given that tool making typically demands a more capable LLM relative
    to tool using, this approach allows LaTM to save costs in practice. We only use
    the most expensive and powerful models in the tool making phase, which we can
    execute once per tool and continually reuse for problem solving!
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，我们不必在这两个阶段使用相同的 LLM。例如，我们可以将更强大的模型（例如，[GPT-4](https://platform.openai.com/docs/models/gpt-4)）应用于工具制作，而使用轻量且成本效益更高的模型（例如，[GPT-3.5-turbo](https://platform.openai.com/docs/models/gpt-3-5)）来进行工具使用。鉴于工具制作通常需要相对于工具使用更强大的
    LLM，这种方法使 LaTM 在实践中能够节省成本。我们只在工具制作阶段使用最昂贵和强大的模型，每个工具执行一次并不断重复使用于问题解决！
- en: '![](../Images/86100da32ee5a12c3488eb6a7e8cdc50.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/86100da32ee5a12c3488eb6a7e8cdc50.png)'
- en: (from [1])
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [1]）
- en: The goal of the tool making process is to generate a generic and reusable tool
    — implemented as a Python function — from a few examples of solving a task. In
    [2], this goal is accomplished by first “proposing” a tool via few-shot learning.
    We provide several demonstrations of desired behavior and prompt the LLM to generate
    a program that reproduces the output of these demonstrations. If a program is
    generated that produces no errors, LaTM uses an LLM to generate several unit tests
    for this tool (i.e., based upon the provided demonstrations) and executes these
    tests to confirm that they pass. Finally, the tool is “wrapped”, or made available
    via a prompt that demonstrates its usage; see above.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 工具制作过程的目标是从少量任务解决示例中生成一个通用且可重用的工具 —— 以 Python 函数的形式实现。在 [2] 中，这一目标通过首先通过少量示例学习“提议”一个工具来实现。我们提供多个期望行为的演示，并提示
    LLM 生成一个程序，该程序再现这些演示的输出。如果生成的程序没有错误，LaTM 使用 LLM 生成几个单元测试（即基于提供的演示）并执行这些测试以确认它们通过。最后，工具被“包装”，或通过展示其用法的提示提供；见上文。
- en: Though tool making is complex and requires a powerful LLM to be successful,
    tool usage can be accomplished with a more cost effective model — *we are just
    using existing tools to solve a task*! We can prompt the LLM to use tools via
    the wrapped tools created during tool making, which provide demonstrations of
    converting tasks into relevant function calls. Here, LaTM relies on the in-context
    learning abilities of LLMs to determine the proper usage of each tool; see below.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管工具制作复杂且需要强大的 LLM 才能成功，但工具使用可以通过更具成本效益的模型来实现 —— *我们只是使用现有工具来解决任务*! 我们可以提示 LLM
    通过工具制作过程中创建的包装工具来使用工具，这些工具提供将任务转换为相关函数调用的演示。在这里，LaTM 依赖 LLM 的上下文学习能力来确定每个工具的正确使用方法；见下文。
- en: '![](../Images/4770df899f2440d79cb6530a5c294274.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4770df899f2440d79cb6530a5c294274.png)'
- en: (from [1])
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [1]）
- en: Notably, using a smaller model for tool using means that we only use more powerful
    models during a small portion of the LaTM pipeline — *tools are only created once
    and can be reused continually as more problems are solved*. The process of creating
    and using tools with LaTM might seem a bit complex, but it is actually quite simple.
    An end-to-end example of creating and using tools for solving a logical deduction
    problem is provided within the figure below.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，使用较小的模型进行工具使用意味着我们只在 LaTM 流程的短暂部分中使用更强大的模型 —— *工具只创建一次，解决更多问题时可以持续重复使用*。创建和使用
    LaTM 工具的过程可能看起来有些复杂，但实际上相当简单。下图中提供了一个创建和使用工具来解决逻辑推理问题的端到端示例。
- en: '![](../Images/d40ae33172262ec07b7f043d66368d83.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d40ae33172262ec07b7f043d66368d83.png)'
- en: (from [1])
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [1]）
- en: '**Adding a dispatcher.** Beyond tool creation and usage, authors in [2] also
    propose a dispatcher module to handle on-the-fly creation and usage of new tools
    with LaTM; see below. Put simply, the dispatcher is an LLM that is used to determine
    whether an incoming task should create a new tool or just use existing tools.
    By using this extra module, we can easily identify new tasks that cannot be handled
    by existing tools and create any tools that are needed, allowing LaTM to better
    handle streaming scenarios in which new tasks arrive sequentially. Interestingly,
    authors in [2] show that a GPT-3.5-based dispatcher can identify correct tools
    to use — or the need for a new tool — with ~95% accuracy.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**添加调度器。** 除了工具创建和使用之外，[2]中的作者还提出了一个调度模块，用于处理 LaTM 中新工具的即时创建和使用；详见下文。简而言之，调度器是一个用于确定传入任务是否应该创建新工具或仅使用现有工具的
    LLM。通过使用这个额外的模块，我们可以轻松识别现有工具无法处理的新任务，并创建所需的任何工具，使 LaTM 能够更好地处理新任务顺序到达的流式场景。有趣的是，[2]中的作者展示了一个基于
    GPT-3.5 的调度器可以以 ~95% 的准确率识别正确的工具使用方式——或是否需要新工具。'
- en: '![](../Images/693c702da58cf17fcd296693a25a9fc9.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/693c702da58cf17fcd296693a25a9fc9.png)'
- en: (from [1])
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: （来源于[1]）
- en: '**Does this work?** LaTM is evaluated over a small set of complex reasoning
    tasks from [BigBench](https://github.com/google/BIG-bench), where [GPT-4](https://openai.com/research/gpt-4)
    is used as the tool maker and [GPT-3.5-turbo](https://platform.openai.com/docs/models/gpt-3-5)
    is used as the tool user. Somewhat unsurprisingly, we see that GPT-4 is capable
    of creating viable and useful tools in most test cases; see below. Less capable
    models (e.g., GPT-3.5-turbo) can be used for making tools on easier problems,
    but GPT-4 is needed in more complex domains. Going further, we see that longer
    context lengths are necessary for tool making, as LaTM uses the full history (i.e.,
    examples of generating all tools so far) when generating a tool to improve [reliability](https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/guides/prompts-reliability.md).'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**这有效吗？** LaTM 在 [BigBench](https://github.com/google/BIG-bench) 提供的一小部分复杂推理任务上进行评估，其中
    [GPT-4](https://openai.com/research/gpt-4) 被用作工具创建者，而 [GPT-3.5-turbo](https://platform.openai.com/docs/models/gpt-3-5)
    被用作工具使用者。某种程度上，GPT-4 能够在大多数测试案例中创建出可行且有用的工具并不令人意外；详见下文。能力较弱的模型（例如 GPT-3.5-turbo）可以用于处理较简单的问题的工具制作，但在更复杂的领域中需要
    GPT-4。进一步地，我们发现工具制作需要更长的上下文长度，因为 LaTM 在生成工具时使用了全部历史（即到目前为止生成的所有工具的示例），以提高[可靠性](https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/guides/prompts-reliability.md)。'
- en: '![](../Images/24c9d326955e0631572964fb6266cb80.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/24c9d326955e0631572964fb6266cb80.png)'
- en: (from [1])
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: （来源于[1]）
- en: When the performance of LaTM is compared to techniques like [CoT prompting](https://cameronrwolfe.substack.com/p/chain-of-thought-prompting-for-llms)
    [4], we see that the proposed approach makes existing LLMs way more capable! By
    using generated tools, models like GPT-3.5-turbo can perform similarly to GPT-4
    and far surpass the performance of CoT prompting; see below. Plus, we see that
    using more lightweight models as the tool user is preferable and even outperforms
    using powerful models like GPT-4 in some cases.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 当 LaTM 的性能与像[链式思维提示](https://cameronrwolfe.substack.com/p/chain-of-thought-prompting-for-llms)
    [4]这样的技术进行比较时，我们发现所提出的方法使现有的 LLM 能力大大增强！通过使用生成的工具，像 GPT-3.5-turbo 这样的模型可以与 GPT-4
    进行类似的表现，并且远超 CoT 提示的性能；详见下文。此外，我们还发现，使用更轻量的模型作为工具使用者更为可取，甚至在某些情况下优于使用像 GPT-4 这样的强大模型。
- en: '![](../Images/d73d4aa9437dd2df17e984710701ba4a.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d73d4aa9437dd2df17e984710701ba4a.png)'
- en: (from [1])
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: （来源于[1]）
- en: LaTM is an interesting, closed-loop framework that enables LLMs to produce their
    own tools. Because it only uses large, expensive LLMs (e.g., GPT-4) for a small
    portion of the problem-solving process, LaTM is a cost-effective approach for
    improving LLM performance. *We can nearly match the performance of GPT-4 on complex
    reasoning tasks with smaller models and at a lower cost.*
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: LaTM 是一个有趣的闭环框架，使 LLM 能够生成自己的工具。由于它仅在解决问题过程中的一小部分使用大型、昂贵的 LLM（例如 GPT-4），LaTM
    是一种提高 LLM 性能的成本效益高的方法。*我们可以以较小的模型和更低的成本，几乎匹配 GPT-4 在复杂推理任务中的表现。*
- en: Rectifying Mistakes in Tool Creation
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 纠正工具创建中的错误
- en: '![](../Images/fd545428ff3d36a211a57b4b94165541.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fd545428ff3d36a211a57b4b94165541.png)'
- en: (from [2])
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: （来源于[2]）
- en: Expanding upon the idea of using LLMs to create their own tools, authors in
    [2] propose a novel framework that *i)* uses LLMs to create their own, relevant
    tools via documentation and code creation, *ii)* adopts a simpler approach for
    planning how to use tools to solve a problem, and *iii)* adds a supplemental error-handling
    mechanism to the tool-using process to make the overall system more robust and
    accurate. The resulting technique, called CREATOR [2], was explored in parallel
    to research in [2]. *The goal of both publications is to create more intelligent
    and adaptable systems for solving complex problems by enabling the creation of
    needed tools.*
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用大型语言模型（LLMs）创建自己工具的想法的基础上，[2]的作者提出了一种新颖的框架，该框架 *i)* 通过文档和代码创建来使用LLMs创建相关工具，*ii)*
    采用一种更简单的方法来规划如何使用工具解决问题，*iii)* 为工具使用过程添加了一个补充的错误处理机制，以使整个系统更具鲁棒性和准确性。 resulting
    technique, 被称为CREATOR [2]，与[2]中的研究并行探索。 *这两篇出版物的目标是通过使所需工具的创建成为可能，从而创建更智能和适应性强的系统以解决复杂问题。*
- en: '![](../Images/45b30fad060a1ea46fca5b03c9bd019c.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/45b30fad060a1ea46fca5b03c9bd019c.png)'
- en: (from [2])
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: (来自 [2])
- en: '**Problem-solving approach.** CREATOR approaches tool creation and usage via
    a four-step process (see above for an illustration):'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题解决方法。** CREATOR通过一个四步过程来处理工具的创建和使用（参见上面的插图）：'
- en: '*Creation*: create tools through documentation and code realization.'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*创建*：通过文档和代码实现来创建工具。'
- en: '*Decision*: decide when and how to use existing tools to solve a problem.'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*决策*：决定何时以及如何使用现有工具来解决问题。'
- en: '*Execution*: execute the program that applies tools to solving a problem.'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*执行*：执行将工具应用于解决问题的程序。'
- en: '*Rectification*: Modify tools and decisions based on results of execution.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*修正*：根据执行结果修改工具和决策。'
- en: The rectification step is not present in prior work. This component acts as
    an automated error handling mechanism that improves the robustness of the system.
    Because LLMs in [2] (and in related publications [1]) use code as a medium for
    creating tools, we can detect and rectify errors (e.g., via a stack trace or something
    similar) that arise when creating or using tools without much effort.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的工作中没有修正步骤。这个组件作为一个自动化的错误处理机制，提高了系统的鲁棒性。由于[2]中的LLMs（以及相关出版物[1]中的LLMs）使用代码作为创建工具的媒介，我们可以轻松地检测和修正创建或使用工具时出现的错误（例如，通过堆栈跟踪或类似的方式）。
- en: '![](../Images/9ddf97431d668febd4fc3bf6c2d74ebe.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9ddf97431d668febd4fc3bf6c2d74ebe.png)'
- en: (from [2])
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: (来自 [2])
- en: 'In [2], tool creation follows an in-context learning approach that provides
    detailed instructions and few-shot examples to guide the LLM towards generating
    the correct tool. Tool creation has two main components:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在[2]中，工具创建遵循一种上下文学习方法，该方法提供详细的说明和少量示例以指导LLM生成正确的工具。工具创建有两个主要组件：
- en: '*Documentation*: outlines relevant information about a tool (e.g., function,
    purpose, signature, etc.).'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*文档*：概述有关工具的相关信息（例如，功能、目的、签名等）。'
- en: '*Realization*: implements the tool in code (see above).'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*实现*：在代码中实现工具（参见上文）。'
- en: Similar to [1], tools created in [2] are captured within a function or method
    (in Python) that can be called upon by the LLM.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于[1]，[2]中创建的工具被封装在一个函数或方法（在Python中）中，可以由LLM调用。
- en: '![](../Images/85a9c5491f2873811d26a945e719d647.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/85a9c5491f2873811d26a945e719d647.png)'
- en: (from [2])
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: (来自 [2])
- en: 'During the decision stage, the LLM considers documentation of all tools and
    determines which tools to use and how to use them to solve the current problem.
    After a problem-solving plan as been created, we can then:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在决策阶段，LLM会考虑所有工具的文档，并确定使用哪些工具以及如何使用它们来解决当前的问题。在制定了问题解决计划后，我们可以：
- en: Format the input for each tool.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 格式化每个工具的输入。
- en: Execute each tool to get the associated output.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行每个工具以获取相关输出。
- en: Perform any needed operations on tool outputs to derive an answer.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对工具输出执行任何需要的操作以推导出答案。
- en: If tool execution leads to the generation of any errors, we can simply record
    this information and iterate over the four-step process again, passing the error
    as an extra input for rectifying existing tools; see above. Otherwise, we can
    use the generated information to extract a final answer for the user’s question.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如果工具执行导致生成任何错误，我们可以简单地记录这些信息，并再次迭代四步过程，将错误作为修正现有工具的额外输入；参见上文。否则，我们可以使用生成的信息提取用户问题的最终答案。
- en: “Our research reveals that leveraging LLMs as tool creators facilitates knowledge
    transfer, and LLMs exhibit varying levels of tool creation abilities, enabling
    them to flexibly tackle diverse situations.” *— from [2]*
  id: totrans-101
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “我们的研究揭示了利用 LLMs 作为工具创建者可以促进知识转移，且 LLMs 表现出不同的工具创建能力，从而使其能够灵活应对各种情况。” *— 来自
    [2]*
- en: '**Improved mathematical reasoning.** The system proposed in [2] is evaluated
    over mathematical (and tabular) reasoning datasets [MATH](https://github.com/hendrycks/math)
    and [TabMWP](https://promptpg.github.io/) [4, 5]. In all experiments, ChatGPT
    (i.e., [GPT-3.5-turbo](https://platform.openai.com/docs/models/gpt-3-5)) is used
    as the base model, due to its code generation and impressive reasoning capabilities.
    CREATOR is compared to baselines such as standard CoT prompting [6], PoT prompting
    [7], and the [Wolfram alpha ChatGPT plugin](https://www.wolfram.com/wolfram-plugin-chatgpt/).
    When all methods use ChatGPT as the base model, we see that CREATOR (combined
    with CoT prompting) yields improved overall accuracy compared to baselines, as
    well as an improved successful execution rate (i.e., meaning the system provides
    an answer with a valid format).'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**改进的数学推理。** 在 [2] 中提出的系统在数学（和表格）推理数据集 [MATH](https://github.com/hendrycks/math)
    和 [TabMWP](https://promptpg.github.io/) [4, 5] 上进行了评估。在所有实验中，ChatGPT（即 [GPT-3.5-turbo](https://platform.openai.com/docs/models/gpt-3-5)）作为基础模型，因其代码生成和令人印象深刻的推理能力。CREATOR
    与基线方法进行比较，如标准 CoT 提示 [6]、PoT 提示 [7] 和 [Wolfram alpha ChatGPT 插件](https://www.wolfram.com/wolfram-plugin-chatgpt/)。当所有方法都使用
    ChatGPT 作为基础模型时，我们发现 CREATOR（结合 CoT 提示）比基线方法具有更高的整体准确性，并且成功执行率也有所提高（即系统提供了有效格式的答案）。'
- en: '![](../Images/cfb8520cdd0b8481a1810c587acf8ce6.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cfb8520cdd0b8481a1810c587acf8ce6.png)'
- en: (from [2])
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [2]）
- en: Beyond these evaluations, authors in [2] propose a new Creation challenge dataset
    that attempts to evaluate the tool creation abilities of an LLM by testing problem-solving
    capabilities in new scenarios for which no existing tool or code package exists.
    On this benchmark, CREATOR slightly outperforms existing baselines. However, this
    performance improvement becomes much larger when the LLM is given a textual hints
    about the utility of the tool that should be created; see below.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些评估，作者在 [2] 中提出了一个新的 Creation 挑战数据集，尝试通过在没有现有工具或代码包的新场景中测试问题解决能力来评估 LLM 的工具创建能力。在这一基准测试中，CREATOR
    稍微超越了现有的基线。然而，当 LLM 获得关于应创建工具的实用性的文本提示时，这种性能改进会更大；见下文。
- en: '![](../Images/44fe3ec0ed5d12a41546dd978c36e793.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/44fe3ec0ed5d12a41546dd978c36e793.png)'
- en: (from [2])
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [2]）
- en: Beyond its ability to match or exceed baseline performance in aggregate, the
    CREATOR framework performs more consistently as problems become increasingly difficult,
    while baselines tend to deteriorate. CREATOR experiences a similar deterioration
    on certain problem classes, but the framework seems to be more adaptable and capable
    of handling complex problems; see below.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在总体上匹配或超越基线性能的能力之外，CREATOR 框架在问题变得越来越困难时表现得更加稳定，而基线方法往往会恶化。CREATOR 在某些问题类别上也会出现类似的恶化，但该框架似乎更加适应并能够处理复杂问题；见下文。
- en: '![](../Images/c9687ff5f312b27c035cf0efc4cdab90.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c9687ff5f312b27c035cf0efc4cdab90.png)'
- en: (from [2])
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [2]）
- en: Takeaways
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 收获
- en: Within this overview, we have explored a more dynamic and flexible approach
    for tool usage with LLMs. Instead of curating a fixed set of tools that can be
    used by the LLM, we can simply enable the LLM to create whatever tool that is
    needed. By following such an approach, we no longer deal with issues created by
    not having access to a tool that is needed by an LLM to solve a problem. We might
    initially question whether such a strategy would be successful (i.e., are LLMs
    powerful enough to create their own tools?), but recent research [1, 2] shows
    us that state-of-the-art LLMs like GPT-4 are more than capable of creating tools
    in the form of standalone Python functions, assuming that measures to rectify
    errors in tool creation are put in place. Then, these tools can be used and re-used
    (even by less powerful LLMs) to solve a variety of complex problems.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在本概述中，我们探讨了一种更具动态性和灵活性的工具使用方法，与 LLMs 结合。我们不再制定一组固定的工具供 LLM 使用，而是可以让 LLM 根据需要创建所需的工具。通过这种方法，我们不再遇到由于没有访问所需工具而导致的问题。我们可能最初会怀疑这种策略是否成功（即
    LLMs 是否足够强大以创建自己的工具？），但最近的研究[1, 2]告诉我们，像 GPT-4 这样的最先进 LLMs 完全有能力创建独立的 Python 函数形式的工具，只要在工具创建中采取纠错措施。这些工具可以被使用和重复使用（即使是由较弱的
    LLMs），以解决各种复杂问题。
- en: “Tool-making enables an LLM to continually generate tools that can be applied
    to different requests so that future requests can call the corresponding APIs
    when beneficial for solving the tasks.” *— from [1]*
  id: totrans-113
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “工具制造使LLM能够不断生成可以应用于不同请求的工具，以便未来的请求在解决任务时可以调用相应的API。” *— 来自 [1]*
- en: Using LLMs to create tools is great, *but how does this relate to parallel efforts
    that have integrated LLMs with a variety of existing tools?* It remains to be
    seen. However, I personally think that the optimal system will use a hybrid of
    existing techniques. There are many useful tools that already exist and are being
    integrated with popular LLMs every day (e.g., see the ChatGPT plugin store). As
    such, relying solely upon LLMs to create their own tools doesn’t make sense. Instead,
    we can leverage existing tools, but also give LLMs needed skills to create any
    tools that they lack. Over time, the suite of tools available to LLMs will continue
    to evolve and make AI-based problem solving systems more effective.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LLMs（大语言模型）来创建工具是很棒的，*但这与已经将LLMs与各种现有工具整合的并行努力有何关系？* 这还有待观察。然而，我个人认为，**最佳系统**将会使用现有技术的混合体。已经存在许多有用的工具，并且这些工具每天都在与流行的LLMs集成（例如，参见ChatGPT插件商店）。因此，单靠LLMs来创建自己的工具并不合适。相反，我们可以利用现有的工具，同时也给LLMs所需的技能，以创造它们所缺乏的任何工具。随着时间的推移，LLMs可用的工具套件将继续演变，使基于AI的问题解决系统变得更加有效。
- en: Connect with me!
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与我联系！
- en: Thanks so much for reading this article. I am [Cameron R. Wolfe](https://cameronrwolfe.me/),
    Director of AI at [Rebuy](https://www.rebuyengine.com/). I study the empirical
    and theoretical foundations of deep learning. If you liked this overview, subscribe
    to my [Deep (Learning) Focus newsletter](https://cameronrwolfe.substack.com/),
    where I help readers understand AI research via overviews of relevant topics from
    the ground up. You can also follow me on [X](https://twitter.com/cwolferesearch)
    and [LinkedIn](https://www.linkedin.com/in/cameron-r-wolfe-ph-d-04744a238/), or
    check out my [other writings](https://medium.com/@wolfecameron) on medium!
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 非常感谢你阅读这篇文章。我是 [Cameron R. Wolfe](https://cameronrwolfe.me/)，[Rebuy](https://www.rebuyengine.com/)的AI总监。我研究深度学习的经验和理论基础。如果你喜欢这个概述，请订阅我的
    [Deep (Learning) Focus newsletter](https://cameronrwolfe.substack.com/)，在这里我通过从基础到高级的相关主题概述来帮助读者理解AI研究。你也可以在
    [X](https://twitter.com/cwolferesearch) 和 [LinkedIn](https://www.linkedin.com/in/cameron-r-wolfe-ph-d-04744a238/)
    上关注我，或者查看我在medium上的 [其他文章](https://medium.com/@wolfecameron)！
- en: Bibliography
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Cai, Tianle, et al. “Large Language Models as Tool Makers.” *arXiv preprint
    arXiv:2305.17126* (2023).'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] 蔡天乐等. “大型语言模型作为工具制造者。” *arXiv预印本arXiv:2305.17126*（2023年）。'
- en: '[2] Qian, Cheng, et al. “CREATOR: Disentangling Abstract and Concrete Reasonings
    of Large Language Models through Tool Creation.” *arXiv preprint arXiv:2305.14318*
    (2023).'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] 钱成等. “CREATOR: 通过工具创建解开大型语言模型的抽象与具体推理。” *arXiv预印本arXiv:2305.14318*（2023年）。'
- en: '[3] Schick, Timo, et al. “Toolformer: Language models can teach themselves
    to use tools.” *arXiv preprint arXiv:2302.04761* (2023).'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Schick, Timo, 等. “Toolformer: 语言模型可以自学使用工具。” *arXiv预印本arXiv:2302.04761*（2023年）。'
- en: '[4] Lu, Pan, et al. “Dynamic prompt learning via policy gradient for semi-structured
    mathematical reasoning.” *arXiv preprint arXiv:2209.14610* (2022).'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Lu, Pan, 等. “通过策略梯度进行动态提示学习，以应对半结构化数学推理。” *arXiv预印本arXiv:2209.14610*（2022年）。'
- en: '[5] Hendrycks, Dan, et al. “Measuring mathematical problem solving with the
    math dataset.” *arXiv preprint arXiv:2103.03874* (2021).'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Hendrycks, Dan, 等. “通过数学数据集衡量数学问题解决能力。” *arXiv预印本arXiv:2103.03874*（2021年）。'
- en: '[6] Wei, Jason, et al. “Chain of thought prompting elicits reasoning in large
    language models.” *arXiv preprint arXiv:2201.11903* (2022).'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] Wei, Jason, 等. “思维链提示在大型语言模型中引发推理。” *arXiv预印本arXiv:2201.11903*（2022年）。'
- en: '[7] Chen, Wenhu, et al. “Program of thoughts prompting: Disentangling computation
    from reasoning for numerical reasoning tasks.” *arXiv preprint arXiv:2211.12588*
    (2022).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] 陈文华等. “思想提示程序：解开数值推理任务中的计算与推理。” *arXiv预印本arXiv:2211.12588*（2022年）。'
- en: '[8] Shen, Yongliang, et al. “Hugginggpt: Solving ai tasks with chatgpt and
    its friends in huggingface.” *arXiv preprint arXiv:2303.17580* (2023).'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] Shen, Yongliang, 等. “Hugginggpt: 用chatgpt和huggingface的朋友解决AI任务。” *arXiv预印本arXiv:2303.17580*（2023年）。'
- en: '[9] Patil, Shishir G., et al. “Gorilla: Large Language Model Connected with
    Massive APIs.” *arXiv preprint arXiv:2305.15334* (2023).'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] Patil, Shishir G., 等. “Gorilla: 连接大量API的大型语言模型。” *arXiv预印本arXiv:2305.15334*（2023年）。'
- en: '[10] Raffel, Colin, et al. “Exploring the limits of transfer learning with
    a unified text-to-text transformer.” *The Journal of Machine Learning Research*
    21.1 (2020): 5485–5551.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] 拉菲尔，科林 等。“通过统一的文本到文本转换器探索迁移学习的极限。” *机器学习研究杂志* 21.1 (2020): 5485–5551。'
- en: '[11] Kojima, Takeshi, et al. “Large language models are zero-shot reasoners.”
    *arXiv preprint arXiv:2205.11916* (2022).'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[11] 小岛武史 等。“大型语言模型是零样本推理器。” *arXiv 预印本 arXiv:2205.11916* (2022)。'
- en: '[12] Wang, Xuezhi, et al. “Self-consistency improves chain of thought reasoning
    in language models.” *arXiv preprint arXiv:2203.11171* (2022).'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[12] 王学智 等。“自我一致性提高了语言模型中的思维链推理能力。” *arXiv 预印本 arXiv:2203.11171* (2022)。'
- en: '[13] Zhou, Denny, et al. “Least-to-most prompting enables complex reasoning
    in large language models.” *arXiv preprint arXiv:2205.10625* (2022).'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[13] 周，丹尼 等。“最少到最多提示方法在大型语言模型中的复杂推理能力。” *arXiv 预印本 arXiv:2205.10625* (2022)。'
- en: '[14] Chen, Mark, et al. “Evaluating large language models trained on code.”
    *arXiv preprint arXiv:2107.03374* (2021).'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[14] 陈马克 等。“评估训练有代码的大型语言模型。” *arXiv 预印本 arXiv:2107.03374* (2021)。'
