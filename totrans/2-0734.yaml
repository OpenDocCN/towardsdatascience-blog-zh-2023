- en: Developing an Autonomous Dual-Chatbot System for Research Paper Digesting
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/developing-an-autonomous-dual-chatbot-system-for-research-paper-digesting-ea46943e9343](https://towardsdatascience.com/developing-an-autonomous-dual-chatbot-system-for-research-paper-digesting-ea46943e9343)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A project walk-through for the concept, implementation, and demonstration
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://shuaiguo.medium.com/?source=post_page-----ea46943e9343--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----ea46943e9343--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ea46943e9343--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ea46943e9343--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----ea46943e9343--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ea46943e9343--------------------------------)
    Â·28 min readÂ·Aug 14, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ccf2282defca7f209f1bce829d03c604.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
- en: Photo by [Aaron Burden](https://unsplash.com/@aaronburden?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: As a researcher, reading and understanding scientific papers has always been
    a crucial part of my daily routine. I still remember the tricks I learned in grad
    school for how to digest a paper efficiently. However, with countless research
    papers being published every day, I felt overwhelmed to keep up to date with the
    latest research trends and insights. The old tricks I learned can only help so
    much.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Things start to change with the recent development of large language models
    (LLMs). Thanks to their remarkable contextual understanding capability, LLMs can
    fairly accurately identify relevant information from the user-provided documents
    and generate high-quality answers to the userâ€™s questions about the documents.
    A myriad of document Q&A tools have been developed based on this idea and some
    tools are designed specifically to assist researchers in understanding complex
    papers within a relatively short amount of time.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: 'Although itâ€™s definitely a step forward, I noticed some friction points when
    using those tools. One of the main issues I had is prompt engineering. Since the
    quality of LLM responses depends heavily on the quality of my questions, I often
    found myself spending quite some time crafting the â€œperfectâ€ question. This is
    especially challenging when reading papers in unfamiliar research fields: oftentimes
    I simply donâ€™t know what questions to ask.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: 'This experience got me thinking: is it possible to develop a system that can
    automate the process of Q&A about research papers? A system that can distill key
    points from a paper more efficiently and autonomously?'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç»å†è®©æˆ‘æ€è€ƒï¼šæ˜¯å¦å¯ä»¥å¼€å‘ä¸€ä¸ªç³»ç»Ÿæ¥è‡ªåŠ¨åŒ–å¤„ç†ç ”ç©¶è®ºæ–‡çš„é—®ç­”è¿‡ç¨‹ï¼Ÿä¸€ä¸ªèƒ½å¤Ÿæ›´é«˜æ•ˆä¸”è‡ªä¸»åœ°æç‚¼è®ºæ–‡å…³é”®ç‚¹çš„ç³»ç»Ÿï¼Ÿ
- en: 'Previously, I worked on [a project where I developed a dual-chatbot system
    for language learning](https://medium.com/towards-data-science/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd).
    The concept there was simple yet effective: by letting two chatbots chat in a
    user-specified foreign language, the user could learn the practical usage of the
    language by simply observing the conversation. The success of this project led
    me to an interesting thought: could a similar dual-chatbot system be useful for
    understanding research papers as well?'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹‹å‰ï¼Œæˆ‘æ›¾åšè¿‡ [ä¸€ä¸ªæˆ‘ä¸ºè¯­è¨€å­¦ä¹ å¼€å‘åŒèŠå¤©æœºå™¨äººç³»ç»Ÿçš„é¡¹ç›®](https://medium.com/towards-data-science/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd)ã€‚é‚£é‡Œçš„æ¦‚å¿µç®€å•è€Œæœ‰æ•ˆï¼šé€šè¿‡è®©ä¸¤ä¸ªèŠå¤©æœºå™¨äººç”¨ç”¨æˆ·æŒ‡å®šçš„å¤–è¯­èŠå¤©ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡è§‚å¯Ÿå¯¹è¯æ¥å­¦ä¹ è¯­è¨€çš„å®é™…ä½¿ç”¨ã€‚è¿™ä¸ªé¡¹ç›®çš„æˆåŠŸè®©æˆ‘äº§ç”Ÿäº†ä¸€ä¸ªæœ‰è¶£çš„æƒ³æ³•ï¼šç±»ä¼¼çš„åŒèŠå¤©æœºå™¨äººç³»ç»Ÿæ˜¯å¦ä¹Ÿæœ‰åŠ©äºç†è§£ç ”ç©¶è®ºæ–‡å‘¢ï¼Ÿ
- en: So, in this blog post, we are going to bring this idea to life. Specifically,
    we will walk through the process of developing a dual-chatbot system that can
    digest research papers in an autonomous manner.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œåœ¨è¿™ç¯‡åšå®¢ä¸­ï¼Œæˆ‘ä»¬å°†æŠŠè¿™ä¸ªæƒ³æ³•å˜ä¸ºç°å®ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†æ¼”ç¤ºå¼€å‘ä¸€ä¸ªå¯ä»¥è‡ªä¸»å¤„ç†ç ”ç©¶è®ºæ–‡çš„åŒèŠå¤©æœºå™¨äººç³»ç»Ÿçš„è¿‡ç¨‹ã€‚
- en: 'To make this journey a fun experience, we are going to approach it as a software
    project and run a Sprint: we will begin with "ideation", where we introduce the
    concept of leveraging a dual-chatbot system to tackle our problem. Then comes
    the â€œSprint executionâ€, during which weâ€™ll incrementally build the features of
    our design. Lastly, we will show our demo in the â€œSprint reviewâ€ and reflect on
    the learnings and future opportunities in the â€œSprint Retrospectiveâ€.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è®©è¿™æ¬¡æ—…ç¨‹å˜å¾—æœ‰è¶£ï¼Œæˆ‘ä»¬å°†å…¶è§†ä¸ºä¸€ä¸ªè½¯ä»¶é¡¹ç›®å¹¶è¿›è¡Œä¸€ä¸ªSprintï¼šæˆ‘ä»¬å°†ä»â€œåˆ›æ„é˜¶æ®µâ€å¼€å§‹ï¼Œä»‹ç»åˆ©ç”¨åŒèŠå¤©æœºå™¨äººç³»ç»Ÿæ¥è§£å†³æˆ‘ä»¬çš„é—®é¢˜çš„æ¦‚å¿µã€‚æ¥ä¸‹æ¥æ˜¯â€œSprint
    æ‰§è¡Œé˜¶æ®µâ€ï¼Œåœ¨æ­¤æœŸé—´ï¼Œæˆ‘ä»¬å°†é€æ­¥æ„å»ºè®¾è®¡çš„åŠŸèƒ½ã€‚æœ€åï¼Œæˆ‘ä»¬å°†åœ¨â€œSprint å›é¡¾é˜¶æ®µâ€å±•ç¤ºæˆ‘ä»¬çš„æ¼”ç¤ºï¼Œå¹¶åœ¨â€œSprint åæ€é˜¶æ®µâ€ä¸­åæ€æ‰€å­¦åˆ°çš„å†…å®¹å’Œæœªæ¥çš„æœºä¼šã€‚
- en: Ready to run the Sprint? letâ€™s get started!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: å‡†å¤‡å¥½è¿›è¡ŒSprintäº†å—ï¼Ÿè®©æˆ‘ä»¬å¼€å§‹å§ï¼
- en: This is the 2nd blog on my series of LLM projects. The 1st one is [Building
    an AI-Powered Language Learning App](/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd),
    and the 3rd one is [Training Soft Skills in Data Science with Real-Life Simulations](/training-soft-skills-in-data-science-with-real-life-simulations-a-role-playing-dual-chatbot-c80dec3dd08c).
    Feel free to check them out!
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ç³»åˆ—LLMé¡¹ç›®çš„ç¬¬äºŒç¯‡åšå®¢ã€‚ç¬¬ä¸€ç¯‡æ˜¯ [æ„å»ºä¸€ä¸ªAIé©±åŠ¨çš„è¯­è¨€å­¦ä¹ åº”ç”¨](/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd)ï¼Œç¬¬ä¸‰ç¯‡æ˜¯
    [é€šè¿‡çœŸå®æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®ç§‘å­¦è½¯æŠ€èƒ½](/training-soft-skills-in-data-science-with-real-life-simulations-a-role-playing-dual-chatbot-c80dec3dd08c)ã€‚æ¬¢è¿æŸ¥çœ‹ï¼
- en: '**Table of Content**'
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç›®å½•**'
- en: '**Â·** [**1\. Concept: dual-chatbot system**](#87c3) **Â·** [**2\. Sprint Planning:
    what we want to build**](#08c8) **Â·** [**3\. Feature 1: Document Embedding Engine**](#c8d4)
    **Â·** [**4\. Feature 2: Dual-Chatbot System**](#bd53)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**Â·** [**1\. æ¦‚å¿µï¼šåŒèŠå¤©æœºå™¨äººç³»ç»Ÿ**](#87c3) **Â·** [**2\. Sprint è®¡åˆ’ï¼šæˆ‘ä»¬æƒ³è¦æ„å»ºä»€ä¹ˆ**](#08c8)
    **Â·** [**3\. åŠŸèƒ½1ï¼šæ–‡æ¡£åµŒå…¥å¼•æ“**](#c8d4) **Â·** [**4\. åŠŸèƒ½2ï¼šåŒèŠå¤©æœºå™¨äººç³»ç»Ÿ**](#bd53)'
- en: âˆ˜ [4.1 Abstract chatbot class](#0806)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [4.1 æŠ½è±¡èŠå¤©æœºå™¨äººç±»](#0806)
- en: âˆ˜ [4.2 Journalist chatbot class](#0a1e)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [4.2 è®°è€…èŠå¤©æœºå™¨äººç±»](#0a1e)
- en: âˆ˜ [4.3 Author bot class](#55dc)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [4.3 ä½œè€…æœºå™¨äººç±»](#55dc)
- en: 'âˆ˜ [4.4 Quick test: the interview](#2a76)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [4.4 å¿«é€Ÿæµ‹è¯•ï¼šé¢è¯•](#2a76)
- en: '**Â·** [**5\. Feature 3: User Interaction**](#3784)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**Â·** [**5\. åŠŸèƒ½3ï¼šç”¨æˆ·äº¤äº’**](#3784)'
- en: âˆ˜ [5.1 Creating the chat environment (in Jupyter Notebook)](#1372)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [5.1 åˆ›å»ºèŠå¤©ç¯å¢ƒï¼ˆåœ¨Jupyter Notebookä¸­ï¼‰](#1372)
- en: âˆ˜ [5.2 Implementing PDF highlighting functionality](#e992)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [5.2 å®ç°PDFé«˜äº®åŠŸèƒ½](#e992)
- en: âˆ˜ [5.3 Allowing user input for questions](#b3df)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [5.3 å…è®¸ç”¨æˆ·è¾“å…¥é—®é¢˜](#b3df)
- en: âˆ˜ [5.4 Allowing downloading the generated script](#aff5)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [5.4 å…è®¸ä¸‹è½½ç”Ÿæˆçš„è„šæœ¬](#aff5)
- en: '**Â·** [**6\. Sprint Review: show the demo!**](#a1e2) **Â·** [**7\. Sprint Retrospective**](#0d19)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**Â·** [**6\. Sprint å›é¡¾ï¼šå±•ç¤ºæ¼”ç¤ºï¼**](#a1e2) **Â·** [**7\. Sprint åæ€**](#0d19)'
- en: '1\. Concept: dual-chatbot system'
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. æ¦‚å¿µï¼šåŒèŠå¤©æœºå™¨äººç³»ç»Ÿ
- en: The foundation of our solution lies in the concept of a dual-chatbot system.
    As its name implies, this system involves two chatbots (powered by large language
    models) engaging in an autonomous dialogue. By specifying a high-level task description
    and assigning relevant roles to the chatbots, users can guide the conversation
    toward their desired direction.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è§£å†³æ–¹æ¡ˆçš„åŸºç¡€åœ¨äºåŒæœºå™¨äººç³»ç»Ÿçš„æ¦‚å¿µã€‚é¡¾åæ€ä¹‰ï¼Œè¿™ä¸ªç³»ç»Ÿæ¶‰åŠä¸¤ä¸ªç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„èŠå¤©æœºå™¨äººè¿›è¡Œè‡ªä¸»å¯¹è¯ã€‚é€šè¿‡æŒ‡å®šä¸€ä¸ªé«˜çº§ä»»åŠ¡æè¿°å¹¶åˆ†é…ç›¸å…³è§’è‰²ç»™èŠå¤©æœºå™¨äººï¼Œç”¨æˆ·å¯ä»¥å¼•å¯¼å¯¹è¯æœç€ä»–ä»¬æœŸæœ›çš„æ–¹å‘å‘å±•ã€‚
- en: 'To give a concrete example: [in my previous project where a dual-chatbot is
    developed for assisting language learning](https://medium.com/towards-data-science/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd),
    the learner (user) can specify a real-life scenario (e.g., dining at a restaurant)
    and assign roles for chatbots to play (e.g., bot 1 as the waitstaff and bot 2
    as the customer), the two bots would then simulate a conversation in the userâ€™s
    chosen foreign language, mimicking the interaction between the assigned roles
    in the given scenario. This allows an on-demand generation of fresh, scenario-specific
    language learning materials, therefore helping users better understand language
    usage in real-life situations.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸¾ä¸€ä¸ªå…·ä½“çš„ä¾‹å­ï¼š[åœ¨æˆ‘ä¹‹å‰çš„é¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªåŒæœºå™¨äººç³»ç»Ÿæ¥è¾…åŠ©è¯­è¨€å­¦ä¹ ](https://medium.com/towards-data-science/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd)ï¼Œå­¦ä¹ è€…ï¼ˆç”¨æˆ·ï¼‰å¯ä»¥æŒ‡å®šä¸€ä¸ªç°å®ç”Ÿæ´»åœºæ™¯ï¼ˆä¾‹å¦‚ï¼Œåœ¨é¤å…ç”¨é¤ï¼‰ï¼Œå¹¶ä¸ºèŠå¤©æœºå™¨äººåˆ†é…è§’è‰²ï¼ˆä¾‹å¦‚ï¼Œæœºå™¨äºº1ä½œä¸ºæœåŠ¡å‘˜ï¼Œæœºå™¨äºº2ä½œä¸ºé¡¾å®¢ï¼‰ï¼Œç„¶åä¸¤ä¸ªæœºå™¨äººä¼šæ¨¡æ‹Ÿç”¨æˆ·é€‰æ‹©çš„å¤–è¯­å¯¹è¯ï¼Œæ¨¡ä»¿åœ¨ç»™å®šåœºæ™¯ä¸­åˆ†é…è§’è‰²ä¹‹é—´çš„äº’åŠ¨ã€‚è¿™å…è®¸æŒ‰éœ€ç”Ÿæˆæ–°é²œã€ç‰¹å®šåœºæ™¯çš„è¯­è¨€å­¦ä¹ ææ–™ï¼Œä»è€Œå¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ç†è§£ç°å®ç”Ÿæ´»ä¸­çš„è¯­è¨€ä½¿ç”¨ã€‚
- en: So, how do we adapt this concept for the autonomous digestion of research papers?
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œæˆ‘ä»¬å¦‚ä½•å°†è¿™ä¸ªæ¦‚å¿µé€‚åº”äºç ”ç©¶è®ºæ–‡çš„è‡ªåŠ¨æ¶ˆåŒ–å‘¢ï¼Ÿ
- en: The key lies in the **role assignment**. More specifically, one bot could take
    the role of a â€œ**journalist**â€, whose main task is to conduct an interview to
    understand and extract key insights from a research paper. Meanwhile, the other
    bot could play the role of an â€œ**author**â€, who has full access to the research
    paper and is tasked with providing comprehensive answers to the â€œjournalistâ€ botâ€™s
    queries.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å…³é”®åœ¨äº**è§’è‰²åˆ†é…**ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œä¸€ä¸ªæœºå™¨äººå¯ä»¥æ‹…ä»»â€œ**è®°è€…**â€çš„è§’è‰²ï¼Œå…¶ä¸»è¦ä»»åŠ¡æ˜¯è¿›è¡Œé‡‡è®¿ä»¥ç†è§£å’Œæå–ç ”ç©¶è®ºæ–‡ä¸­çš„å…³é”®è§è§£ã€‚ä¸æ­¤åŒæ—¶ï¼Œå¦ä¸€ä¸ªæœºå™¨äººå¯ä»¥æ‰®æ¼”â€œ**ä½œè€…**â€çš„è§’è‰²ï¼Œæ‹¥æœ‰å¯¹ç ”ç©¶è®ºæ–‡çš„å…¨é¢è®¿é—®æƒï¼Œè´Ÿè´£å›ç­”â€œè®°è€…â€æœºå™¨äººçš„æé—®ã€‚
- en: When it comes to interaction, the journalist bot will initiate the dialogue
    and kicks off the interview process. The author bot will then serve as a conventional
    document Q&A engine and answer the journalistâ€™s questions based on the relevant
    context of the research paper. The journalist bot then follows up with additional
    questions for further clarification. Through this iterative Q&A process, the key
    contributions, methodology, and findings of the research paper could be automatically
    extracted.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: å½“è°ˆåˆ°äº’åŠ¨æ—¶ï¼Œè®°è€…æœºå™¨äººå°†å¯åŠ¨å¯¹è¯å¹¶å¼€å§‹é‡‡è®¿è¿‡ç¨‹ã€‚ç„¶åï¼Œä½œè€…æœºå™¨äººå°†ä½œä¸ºä¼ ç»Ÿçš„æ–‡æ¡£é—®ç­”å¼•æ“ï¼Œæ ¹æ®ç ”ç©¶è®ºæ–‡çš„ç›¸å…³èƒŒæ™¯å›ç­”è®°è€…çš„é—®é¢˜ã€‚è®°è€…æœºå™¨äººéšåä¼šæå‡ºæ›´å¤šé—®é¢˜ä»¥è¿›ä¸€æ­¥æ¾„æ¸…ã€‚é€šè¿‡è¿™ç§åå¤é—®ç­”çš„è¿‡ç¨‹ï¼Œç ”ç©¶è®ºæ–‡çš„å…³é”®è´¡çŒ®ã€æ–¹æ³•è®ºå’Œå‘ç°å¯ä»¥è¢«è‡ªåŠ¨æå–ã€‚
- en: '![](../Images/5bb2d4d17a40f755bd0509a680ddc114.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5bb2d4d17a40f755bd0509a680ddc114.png)'
- en: An illustration of the workflow of the dual-chatbot system. (Image by author)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: åŒæœºå™¨äººç³»ç»Ÿçš„å·¥ä½œæµç¨‹ç¤ºæ„å›¾ã€‚ï¼ˆå›¾ç‰‡æ¥æºï¼šä½œè€…ï¼‰
- en: 'This dual-chatbot system described above introduces a shift from the traditional
    user-chatbot interaction: instead of users thinking about the right questions
    to ask the LLM model, the introduced â€œjournalistâ€ bot will automatically come
    up with suitable questions on the userâ€™s behalf. This approach could bypass the
    need for users to craft appropriate prompts, thus significantly reducing the usersâ€™
    cognitive load. This is especially useful when delving into unfamiliar research
    fields. Overall, the dual-chatbot system may constitute a more user-friendly,
    efficient, and engaging method for distilling complex scientific research papers.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šè¿°åŒæœºå™¨äººç³»ç»Ÿå¼•å…¥äº†ä¸€ç§ä»ä¼ ç»Ÿç”¨æˆ·-èŠå¤©æœºå™¨äººäº’åŠ¨çš„è½¬å˜ï¼šç”¨æˆ·ä¸å†éœ€è¦æ€è€ƒå‘LLMæ¨¡å‹æå‡ºçš„æ­£ç¡®é—®é¢˜ï¼Œä»‹ç»çš„â€œè®°è€…â€æœºå™¨äººå°†è‡ªåŠ¨ä¸ºç”¨æˆ·æå‡ºåˆé€‚çš„é—®é¢˜ã€‚è¿™ç§æ–¹æ³•å¯ä»¥ç»•è¿‡ç”¨æˆ·è®¾è®¡é€‚å½“æç¤ºçš„éœ€è¦ï¼Œä»è€Œæ˜¾è‘—é™ä½ç”¨æˆ·çš„è®¤çŸ¥è´Ÿæ‹…ã€‚è¿™åœ¨*æ·±å…¥ä¸ç†Ÿæ‚‰çš„ç ”ç©¶é¢†åŸŸ*æ—¶å°¤å…¶æœ‰ç”¨ã€‚æ€»ä½“è€Œè¨€ï¼ŒåŒæœºå™¨äººç³»ç»Ÿå¯èƒ½æ„æˆä¸€ç§æ›´ç”¨æˆ·å‹å¥½ã€é«˜æ•ˆä¸”å¼•äººå…¥èƒœçš„æ–¹æ³•ï¼Œç”¨äºæç‚¼å¤æ‚çš„ç§‘å­¦ç ”ç©¶è®ºæ–‡ã€‚
- en: Next up, letâ€™s move to Sprint planning and define several user stories we would
    like to address in this project.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬è¿›è¡ŒSprintè§„åˆ’ï¼Œå¹¶å®šä¹‰æˆ‘ä»¬å¸Œæœ›åœ¨è¿™ä¸ªé¡¹ç›®ä¸­è§£å†³çš„å‡ ä¸ªç”¨æˆ·æ•…äº‹ã€‚
- en: '2\. Sprint Planning: what we want to build'
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. å†²åˆºè§„åˆ’ï¼šæˆ‘ä»¬æƒ³è¦æ„å»ºçš„å†…å®¹
- en: With the concept in place, itâ€™s time to plan our current Sprint. In line with
    the common practice of Agile development, our Sprint planning will evolve around
    user stories.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡®å®šæ¦‚å¿µåï¼Œæ¥ä¸‹æ¥æ˜¯è§„åˆ’æˆ‘ä»¬å½“å‰çš„å†²åˆºã€‚æ ¹æ®æ•æ·å¼€å‘çš„å¸¸è§„åšæ³•ï¼Œæˆ‘ä»¬çš„å†²åˆºè§„åˆ’å°†å›´ç»•ç”¨æˆ·æ•…äº‹å±•å¼€ã€‚
- en: In Agile development, **a user story** is a concise, informal, and simple description
    of a feature or functionality from an end-user perspective. It is a common practice
    used in Agile development to define and communicate requirements in a way that
    is understandable and actionable for the development team.
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åœ¨æ•æ·å¼€å‘ä¸­ï¼Œ**ç”¨æˆ·æ•…äº‹**æ˜¯ä»æœ€ç»ˆç”¨æˆ·çš„è§’åº¦å¯¹åŠŸèƒ½æˆ–ç‰¹æ€§çš„ç®€æ´ã€éæ­£å¼å’Œç®€å•çš„æè¿°ã€‚è¿™æ˜¯ä¸€ç§åœ¨æ•æ·å¼€å‘ä¸­å¸¸ç”¨çš„åšæ³•ï¼Œç”¨äºä»¥ä¸€ç§å¯ç†è§£å’Œå¯æ“ä½œçš„æ–¹å¼å®šä¹‰å’Œä¼ è¾¾éœ€æ±‚ã€‚
- en: 'ğŸ¯ **User story 1: document embedding**'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'ğŸ¯ **ç”¨æˆ·æ•…äº‹ 1: æ–‡æ¡£åµŒå…¥**'
- en: â€œAs a user, I want to input research papers in PDF format into the system, and
    I want the system to convert my input paper into a **machine-readable format**
    so that the dual-chatbot system can understand and analyze it efficiently.â€ (Generated
    by GPT-4)
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›å°† PDF æ ¼å¼çš„ç ”ç©¶è®ºæ–‡è¾“å…¥ç³»ç»Ÿï¼Œå¹¶å¸Œæœ›ç³»ç»Ÿå°†æˆ‘çš„è¾“å…¥è®ºæ–‡è½¬æ¢æˆ**æœºå™¨å¯è¯»æ ¼å¼**ï¼Œä»¥ä¾¿åŒæœºå™¨äººç³»ç»Ÿèƒ½å¤Ÿé«˜æ•ˆåœ°ç†è§£å’Œåˆ†æå®ƒã€‚â€ï¼ˆç”±
    GPT-4 ç”Ÿæˆï¼‰
- en: This user story focuses on data ingestion. Essentially, we need to build a data-processing
    pipeline that includes document loading, splitting, embedding creation, and embedding
    storage.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç”¨æˆ·æ•…äº‹é›†ä¸­åœ¨æ•°æ®æ‘„å–ä¸Šã€‚æœ¬è´¨ä¸Šï¼Œæˆ‘ä»¬éœ€è¦æ„å»ºä¸€ä¸ªæ•°æ®å¤„ç†ç®¡é“ï¼ŒåŒ…æ‹¬æ–‡æ¡£åŠ è½½ã€æ‹†åˆ†ã€åµŒå…¥åˆ›å»ºå’ŒåµŒå…¥å­˜å‚¨ã€‚
- en: Here, â€œembeddingsâ€ refer to the numerical representations of the text data.
    By creating a numerical representation of each part of a research paper, the author
    bot can better understand the semantic meaning of the research paper and be able
    to accurately answer the journalist botâ€™s questions.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œâ€œåµŒå…¥â€æŒ‡çš„æ˜¯æ–‡æœ¬æ•°æ®çš„æ•°å€¼è¡¨ç¤ºã€‚é€šè¿‡åˆ›å»ºç ”ç©¶è®ºæ–‡æ¯éƒ¨åˆ†çš„æ•°å€¼è¡¨ç¤ºï¼Œä½œè€…æœºå™¨äººå¯ä»¥æ›´å¥½åœ°ç†è§£ç ”ç©¶è®ºæ–‡çš„è¯­ä¹‰å«ä¹‰ï¼Œå¹¶èƒ½å¤Ÿå‡†ç¡®å›ç­”è®°è€…æœºå™¨äººçš„é—®é¢˜ã€‚
- en: Additionally, we need to have a database to store the computed embeddings of
    the research paper. This database needs to be readily accessible by the author
    bot to facilitate fast and accurate answer generation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä¸€ä¸ªæ•°æ®åº“æ¥å­˜å‚¨ç ”ç©¶è®ºæ–‡è®¡ç®—å‡ºçš„åµŒå…¥ã€‚è¿™ä¸€æ•°æ®åº“éœ€è¦èƒ½å¤Ÿè¢«ä½œè€…æœºå™¨äººå¿«é€Ÿè®¿é—®ï¼Œä»¥ä¾¿ç”Ÿæˆå¿«é€Ÿè€Œå‡†ç¡®çš„å›ç­”ã€‚
- en: In section 3, we will address this user story by leveraging the **OpenAI Embeddings
    API** along with the metaâ€™s **FAISS vector store**.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¬¬ 3 èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†åˆ©ç”¨**OpenAI Embeddings API**å’Œ Meta çš„**FAISS å‘é‡å­˜å‚¨**æ¥è§£å†³è¿™ä¸ªç”¨æˆ·æ•…äº‹ã€‚
- en: 'ğŸ¯ **User story 2: dual-chatbot**'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'ğŸ¯ **ç”¨æˆ·æ•…äº‹ 2: åŒæœºå™¨äºº**'
- en: â€œAs a user, I want to observe an autonomous conversation between two chatbots
    â€” one playing the role of a â€˜journalistâ€™ asking questions and the other playing
    the role of an â€˜authorâ€™ answering them, derived from the contents of the research
    paper. This will help me understand the paperâ€™s key points without needing to
    read it in its entirety or craft my own questions.â€ (Generated by GPT-4)
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›è§‚å¯Ÿä¸¤ä¸ªèŠå¤©æœºå™¨äººä¹‹é—´çš„è‡ªä¸»å¯¹è¯â€”â€”ä¸€ä¸ªæ‰®æ¼”â€˜è®°è€…â€™è§’è‰²æé—®ï¼Œå¦ä¸€ä¸ªæ‰®æ¼”â€˜ä½œè€…â€™è§’è‰²å›ç­”ï¼Œè¿™äº›å¯¹è¯æ¥æºäºç ”ç©¶è®ºæ–‡çš„å†…å®¹ã€‚è¿™å°†å¸®åŠ©æˆ‘ç†è§£è®ºæ–‡çš„å…³é”®ç‚¹ï¼Œè€Œæ— éœ€å®Œæ•´é˜…è¯»æˆ–è‡ªå·±æå‡ºé—®é¢˜ã€‚â€ï¼ˆç”±
    GPT-4 ç”Ÿæˆï¼‰
- en: 'This user story represents the cornerstone of our project: the development
    of the dual-chatbot system. As discussed in the â€œConceptâ€ section, we need to
    construct two types of chatbot classes: one that is able to develop a series of
    questions to query the details of the paper (i.e., the journalist bot), and another
    that can leverage document embeddings to generate comprehensive answers to these
    questions (i.e., the author bot).'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç”¨æˆ·æ•…äº‹ä»£è¡¨äº†æˆ‘ä»¬é¡¹ç›®çš„åŸºçŸ³ï¼šåŒæœºå™¨äººç³»ç»Ÿçš„å¼€å‘ã€‚å¦‚â€œæ¦‚å¿µâ€éƒ¨åˆ†æ‰€è¿°ï¼Œæˆ‘ä»¬éœ€è¦æ„å»ºä¸¤ç§ç±»å‹çš„èŠå¤©æœºå™¨äººç±»ï¼šä¸€ç§èƒ½å¤Ÿæå‡ºä¸€ç³»åˆ—é—®é¢˜æ¥æŸ¥è¯¢è®ºæ–‡çš„è¯¦ç»†ä¿¡æ¯ï¼ˆå³è®°è€…æœºå™¨äººï¼‰ï¼Œå¦ä¸€ç§èƒ½å¤Ÿåˆ©ç”¨æ–‡æ¡£åµŒå…¥ç”Ÿæˆå¯¹è¿™äº›é—®é¢˜çš„å…¨é¢å›ç­”ï¼ˆå³ä½œè€…æœºå™¨äººï¼‰ã€‚
- en: In section 4, we will focus on addressing this user story by using the **LangChain**
    framework.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¬¬ 4 èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä½¿ç”¨**LangChain**æ¡†æ¶æ¥è§£å†³è¿™ä¸ªç”¨æˆ·æ•…äº‹ã€‚
- en: 'ğŸ¯ **User story 3: chat environment**'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'ğŸ¯ **ç”¨æˆ·æ•…äº‹ 3: èŠå¤©ç¯å¢ƒ**'
- en: â€œAs a user, I want an intuitive chat interface where I can watch the chatbotsâ€™
    conversation unfold in real-time.â€ (Generated by GPT-4)
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›æœ‰ä¸€ä¸ªç›´è§‚çš„èŠå¤©ç•Œé¢ï¼Œåœ¨è¿™é‡Œæˆ‘å¯ä»¥å®æ—¶è§‚å¯ŸèŠå¤©æœºå™¨äººçš„å¯¹è¯å±•å¼€ã€‚â€ï¼ˆç”± GPT-4 ç”Ÿæˆï¼‰
- en: The goal of this user story is to build a chat environment where users can view
    the generated dialogue between the journalist and author bots. In the spirit of
    MVP (minimum viable product), we will use simple **Jupyter widgets** to demonstrate
    the chat environment in section 5.1.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç”¨æˆ·æ•…äº‹çš„ç›®æ ‡æ˜¯æ„å»ºä¸€ä¸ªèŠå¤©ç¯å¢ƒï¼Œç”¨æˆ·å¯ä»¥æŸ¥çœ‹è®°è€…å’Œä½œè€…æœºå™¨äººä¹‹é—´ç”Ÿæˆçš„å¯¹è¯ã€‚ä¸ºäº†ç¬¦åˆMVPï¼ˆæœ€ç®€å¯è¡Œäº§å“ï¼‰çš„ç²¾ç¥ï¼Œæˆ‘ä»¬å°†åœ¨5.1èŠ‚ä½¿ç”¨ç®€å•çš„**Jupyterå°éƒ¨ä»¶**æ¥æ¼”ç¤ºèŠå¤©ç¯å¢ƒã€‚
- en: 'ğŸ¯ **User story 4: PDF highlighting**'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'ğŸ¯ **ç”¨æˆ·æ•…äº‹ 4: PDFé«˜äº®**'
- en: â€œAs a user, I want to have the corresponding parts in the original research
    paper highlighted based on the chatbotâ€™s discussion. This will help me to quickly
    locate the sources of the information discussed during the conversation.â€ (Generated
    by GPT-4)
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿæ ¹æ®èŠå¤©æœºå™¨äººçš„è®¨è®ºåœ¨åŸç ”ç©¶è®ºæ–‡ä¸­çªå‡ºæ˜¾ç¤ºç›¸å…³éƒ¨åˆ†ã€‚è¿™å°†å¸®åŠ©æˆ‘å¿«é€Ÿæ‰¾åˆ°å¯¹è¯ä¸­è®¨è®ºçš„ä¿¡æ¯çš„æ¥æºã€‚â€ï¼ˆç”±GPT-4ç”Ÿæˆï¼‰
- en: This user story focuses on providing the users with the traceability of the
    Q&A. For every answer generated by the author bot, it is natural for users to
    understand precisely where the discussed information is originating from in the
    research paper. Not only does this feature enhances the transparency of our dual-chatbot
    system, but it also allows for a more interactive and engaging user experience.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç”¨æˆ·æ•…äº‹ç€é‡äºä¸ºç”¨æˆ·æä¾›é—®ç­”çš„å¯è¿½æº¯æ€§ã€‚å¯¹äºæ¯ä¸€ä¸ªç”±ä½œè€…æœºå™¨äººç”Ÿæˆçš„å›ç­”ï¼Œç”¨æˆ·å¯ä»¥è‡ªç„¶åœ°ç†è§£è®¨è®ºçš„ä¿¡æ¯æºè‡ªç ”ç©¶è®ºæ–‡çš„ç¡®åˆ‡ä½ç½®ã€‚è¿™ä¸ªåŠŸèƒ½ä¸ä»…æå‡äº†æˆ‘ä»¬åŒèŠå¤©æœºå™¨äººç³»ç»Ÿçš„é€æ˜åº¦ï¼Œè¿˜ä½¿å¾—ç”¨æˆ·ä½“éªŒæ›´åŠ äº’åŠ¨å’Œå¼•äººå…¥èƒœã€‚
- en: In section 5.2, we will leverage LangChainâ€™s **conversational retrieval chain**
    to return the sources the author bot used to generate the answers and the **PyMuPDF**
    library to highlight the corresponding texts in the original PDF.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨5.2èŠ‚ï¼Œæˆ‘ä»¬å°†åˆ©ç”¨LangChainçš„**å¯¹è¯æ£€ç´¢é“¾**æ¥è¿”å›ä½œè€…æœºå™¨äººç”¨äºç”Ÿæˆå›ç­”çš„æ¥æºï¼Œå¹¶ä½¿ç”¨**PyMuPDF**åº“æ¥çªå‡ºæ˜¾ç¤ºåŸPDFä¸­çš„ç›¸å…³æ–‡æœ¬ã€‚
- en: 'ğŸ¯ **User story 5: user input**'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'ğŸ¯ **ç”¨æˆ·æ•…äº‹ 5: ç”¨æˆ·è¾“å…¥**'
- en: â€œAs a user, I want to be able to intervene and ask my own questions in the midst
    of the chatbotâ€™s conversation, this way I can direct the conversation and extract
    the information I need from the paper.â€ (Generated by GPT-4)
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿåœ¨èŠå¤©æœºå™¨äººçš„å¯¹è¯è¿‡ç¨‹ä¸­è¿›è¡Œå¹²é¢„å¹¶æå‡ºè‡ªå·±çš„é—®é¢˜ï¼Œè¿™æ ·æˆ‘å¯ä»¥å¼•å¯¼å¯¹è¯å¹¶ä»è®ºæ–‡ä¸­æå–æˆ‘éœ€è¦çš„ä¿¡æ¯ã€‚â€ï¼ˆç”±GPT-4ç”Ÿæˆï¼‰
- en: This user story focuses on the need for user participation. While our target
    dual-chatbot system is designed to be autonomous, we also need to provide the
    option for users to ask their own questions. This feature ensures that the conversation
    does not just go in a direction set by the bots, but it can be guided by the userâ€™s
    own curiosity and interests. Also, it is very likely that users may get inspired
    by watching the first rounds of conversation, and would like to ask follow-up
    questions or dig deeper into certain aspects that are of particular interest to
    them. All these underline the importance of user intervention.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç”¨æˆ·æ•…äº‹å…³æ³¨äºç”¨æˆ·å‚ä¸çš„éœ€æ±‚ã€‚è™½ç„¶æˆ‘ä»¬çš„ç›®æ ‡åŒèŠå¤©æœºå™¨äººç³»ç»Ÿæ—¨åœ¨è‡ªä¸»è¿ä½œï¼Œä½†æˆ‘ä»¬ä»éœ€æä¾›ç”¨æˆ·æå‡ºè‡ªå·±é—®é¢˜çš„é€‰é¡¹ã€‚è¿™ä¸ªåŠŸèƒ½ç¡®ä¿äº†å¯¹è¯ä¸ä¼šä»…ä»…æŒ‰ç…§æœºå™¨äººçš„è®¾å®šæ–¹å‘è¿›è¡Œï¼Œè€Œæ˜¯å¯ä»¥ç”±ç”¨æˆ·çš„å¥½å¥‡å¿ƒå’Œå…´è¶£æ¥å¼•å¯¼ã€‚æ­¤å¤–ï¼Œç”¨æˆ·å¯èƒ½ä¼šå—åˆ°ç¬¬ä¸€æ¬¡å¯¹è¯çš„å¯å‘ï¼Œæƒ³è¦æå‡ºåç»­é—®é¢˜æˆ–æ·±å…¥æŒ–æ˜ä»–ä»¬ç‰¹åˆ«æ„Ÿå…´è¶£çš„æŸäº›æ–¹é¢ã€‚è¿™äº›éƒ½å¼ºè°ƒäº†ç”¨æˆ·å¹²é¢„çš„é‡è¦æ€§ã€‚
- en: In section 5.3, we will address this user story by upgrading our user interface
    in Jupyter Notebook.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨5.3èŠ‚ï¼Œæˆ‘ä»¬å°†é€šè¿‡å‡çº§Jupyter Notebookä¸­çš„ç”¨æˆ·ç•Œé¢æ¥å¤„ç†è¿™ä¸ªç”¨æˆ·æ•…äº‹ã€‚
- en: 'ğŸ¯ **User story 6: download scripts**'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'ğŸ¯ **ç”¨æˆ·æ•…äº‹ 6: ä¸‹è½½è„šæœ¬**'
- en: â€œAs a user, I want to be able to download a transcript of the chatbot conversation.
    This will allow me to review the key points offline or share the information with
    my colleagues.â€ (Generated by GPT-4)
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿä¸‹è½½èŠå¤©æœºå™¨äººå¯¹è¯çš„è®°å½•ã€‚è¿™å°†å…è®¸æˆ‘ç¦»çº¿æŸ¥çœ‹è¦ç‚¹æˆ–ä¸æˆ‘çš„åŒäº‹åˆ†äº«ä¿¡æ¯ã€‚â€ï¼ˆç”±GPT-4ç”Ÿæˆï¼‰
- en: This user story focuses on the accessibility and shareability of the generated
    content. Although users can view the conversation in a dedicated chat environment,
    it is beneficial to provide users with a record of the discussion that they can
    review later and share with others.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç”¨æˆ·æ•…äº‹å…³æ³¨äºç”Ÿæˆå†…å®¹çš„å¯è®¿é—®æ€§å’Œå¯åˆ†äº«æ€§ã€‚è™½ç„¶ç”¨æˆ·å¯ä»¥åœ¨ä¸“ç”¨çš„èŠå¤©ç¯å¢ƒä¸­æŸ¥çœ‹å¯¹è¯ï¼Œä½†æä¾›ä¸€ä¸ªå¯ä»¥ä¾›ç”¨æˆ·åç»­æŸ¥çœ‹å’Œåˆ†äº«çš„è®¨è®ºè®°å½•æ˜¯å¾ˆæœ‰ç›Šçš„ã€‚
- en: In section 5.4, we will use the **PDFDocument** libraryto convert the generated
    script into a PDF file for users to download.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨5.4èŠ‚ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨**PDFDocument**åº“å°†ç”Ÿæˆçš„è„šæœ¬è½¬æ¢ä¸ºPDFæ–‡ä»¶ï¼Œä»¥ä¾›ç”¨æˆ·ä¸‹è½½ã€‚
- en: So much for the planning, time to get to work!
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: è§„åˆ’åˆ°æ­¤ä¸ºæ­¢ï¼Œç°åœ¨æ˜¯æ—¶å€™å¼€å§‹å·¥ä½œäº†ï¼
- en: '![](../Images/1aa4c455b93f11b7eb1154eaf4fd48c5.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1aa4c455b93f11b7eb1154eaf4fd48c5.png)'
- en: Our planned user stories. (Image by author)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è§„åˆ’çš„ç”¨æˆ·æ•…äº‹ã€‚ï¼ˆä½œè€…æä¾›çš„å›¾ç‰‡ï¼‰
- en: '3\. Feature 1: Document Embedding Engine'
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. ç‰¹æ€§ 1ï¼šæ–‡æ¡£åµŒå…¥å¼•æ“
- en: 'Letâ€™s implement the first feature of our paper digesting app: the document
    embedding engine. Here, we will build a data-processing class with the functionality
    of document loading, splitting, embedding creation, and storage. This addresses
    our first user story:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å®ç°æˆ‘ä»¬è®ºæ–‡æ¶ˆåŒ–åº”ç”¨çš„ç¬¬ä¸€ä¸ªåŠŸèƒ½ï¼šæ–‡æ¡£åµŒå…¥å¼•æ“ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªæ•°æ®å¤„ç†ç±»ï¼Œå…·å¤‡æ–‡æ¡£åŠ è½½ã€æ‹†åˆ†ã€åµŒå…¥åˆ›å»ºå’Œå­˜å‚¨çš„åŠŸèƒ½ã€‚è¿™è§£å†³äº†æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªç”¨æˆ·æ•…äº‹ï¼š
- en: â€œAs a user, I want to input research papers in PDF format into the system, and
    I want the system to convert my input paper into a **machine-readable format**
    so that the dual-chatbot system can understand and analyze it efficiently.â€ (Generated
    by GPT-4)
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›å°† PDF æ ¼å¼çš„ç ”ç©¶è®ºæ–‡è¾“å…¥ç³»ç»Ÿï¼Œå¹¶å¸Œæœ›ç³»ç»Ÿå°†æˆ‘çš„è¾“å…¥è®ºæ–‡è½¬æ¢ä¸º**æœºå™¨å¯è¯»æ ¼å¼**ï¼Œä»¥ä¾¿åŒé‡èŠå¤©æœºå™¨äººç³»ç»Ÿèƒ½å¤Ÿæœ‰æ•ˆç†è§£å’Œåˆ†æã€‚â€ï¼ˆç”±
    GPT-4 ç”Ÿæˆï¼‰
- en: 'We start by creating a `embedding_engine.py` file and import necessary libraries:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é¦–å…ˆåˆ›å»ºä¸€ä¸ª `embedding_engine.py` æ–‡ä»¶ï¼Œå¹¶å¯¼å…¥å¿…è¦çš„åº“ï¼š
- en: '[PRE0]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We then instantiate an embedding model by using OpenAI embeddings API:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ OpenAI åµŒå…¥ API å®ä¾‹åŒ–äº†ä¸€ä¸ªåµŒå…¥æ¨¡å‹ï¼š
- en: '[PRE1]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, we define the function for loading and processing PDF files:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å®šä¹‰äº†åŠ è½½å’Œå¤„ç† PDF æ–‡ä»¶çš„å‡½æ•°ï¼š
- en: '[PRE2]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here, we have used `PyMuPDFLoader` to load the PDF file, which, under the hood,
    leverages the PyMuPDF library to parse the PDF file. The returned `documents`
    variable is a list of LangChain `Document()` objects. Each `Document()` object
    corresponds to one page of the original PDF, with the page content stored in the
    `page_content` key and associated metadata (e.g., page number, etc.) stored in
    the `metadata` key.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨äº† `PyMuPDFLoader` æ¥åŠ è½½ PDF æ–‡ä»¶ï¼Œè¯¥å·¥å…·åœ¨åº•å±‚åˆ©ç”¨ PyMuPDF åº“è§£æ PDF æ–‡ä»¶ã€‚è¿”å›çš„ `documents`
    å˜é‡æ˜¯ LangChain `Document()` å¯¹è±¡çš„åˆ—è¡¨ã€‚æ¯ä¸ª `Document()` å¯¹è±¡å¯¹åº”åŸå§‹ PDF çš„ä¸€é¡µï¼Œé¡µé¢å†…å®¹å­˜å‚¨åœ¨ `page_content`
    é”®ä¸­ï¼Œç›¸å…³çš„å…ƒæ•°æ®ï¼ˆä¾‹å¦‚ï¼Œé¡µç ç­‰ï¼‰å­˜å‚¨åœ¨ `metadata` é”®ä¸­ã€‚
- en: After parsing the loaded PDF, we used `RecursiveCharacterTextSplitter` from
    LangChain to split the original PDF into multiple smaller chunks. Since the author
    bot will later use relevant texts from the PDF to answer questions, creating small
    chunks of text can not only help the author bot to focus on specific details to
    answer the question, but also ensure that the context provided to the author bot
    will not exceed the token limit of the employed LLM.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: è§£æåŠ è½½çš„ PDF åï¼Œæˆ‘ä»¬ä½¿ç”¨äº† LangChain çš„ `RecursiveCharacterTextSplitter` å°†åŸå§‹ PDF æ‹†åˆ†æˆå¤šä¸ªè¾ƒå°çš„å—ã€‚ç”±äºä½œè€…æœºå™¨äººç¨åå°†ä½¿ç”¨
    PDF ä¸­çš„ç›¸å…³æ–‡æœ¬æ¥å›ç­”é—®é¢˜ï¼Œåˆ›å»ºå°å—æ–‡æœ¬ä¸ä»…å¯ä»¥å¸®åŠ©ä½œè€…æœºå™¨äººä¸“æ³¨äºå…·ä½“ç»†èŠ‚ä»¥å›ç­”é—®é¢˜ï¼Œè¿˜å¯ä»¥ç¡®ä¿æä¾›ç»™ä½œè€…æœºå™¨äººçš„ä¸Šä¸‹æ–‡ä¸ä¼šè¶…å‡ºæ‰€ç”¨ LLM çš„ä»¤ç‰Œé™åˆ¶ã€‚
- en: 'Next, we set up the vector store to manage the text embedding vectors:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è®¾ç½®å‘é‡å­˜å‚¨ä»¥ç®¡ç†æ–‡æœ¬åµŒå…¥å‘é‡ï¼š
- en: '[PRE3]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Here, we used Facebook AI Similarity Search (FAISS) library to serve as our
    vector store, which takes the loaded PDF and the embedding engine as the inputs
    to its constructor. The created `self.vectorstore` holds the embedding vectors
    of individual PDF chunks we created earlier. At query time, it will invoke the
    embedding engine to embed the question and then retrieve the embedding vectors
    that are â€˜most similarâ€™ to the embedded query. The texts that correspond to the
    most similar embedding vectors will be fed to the author bot as the context to
    assist its answer generation. This process is known as **vector search** and forms
    the backbone for document Q&A.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨äº† Facebook AI ç›¸ä¼¼åº¦æœç´¢ï¼ˆFAISSï¼‰åº“ä½œä¸ºæˆ‘ä»¬çš„å‘é‡å­˜å‚¨ï¼Œå®ƒæ¥å—åŠ è½½çš„ PDF å’ŒåµŒå…¥å¼•æ“ä½œä¸ºæ„é€ å‡½æ•°çš„è¾“å…¥ã€‚åˆ›å»ºçš„ `self.vectorstore`
    å­˜å‚¨äº†æˆ‘ä»¬ä¹‹å‰åˆ›å»ºçš„æ¯ä¸ª PDF å—çš„åµŒå…¥å‘é‡ã€‚åœ¨æŸ¥è¯¢æ—¶ï¼Œå®ƒå°†è°ƒç”¨åµŒå…¥å¼•æ“æ¥åµŒå…¥é—®é¢˜ï¼Œç„¶åæ£€ç´¢ä¸åµŒå…¥æŸ¥è¯¢â€œæœ€ç›¸ä¼¼â€çš„åµŒå…¥å‘é‡ã€‚ä¸æœ€ç›¸ä¼¼åµŒå…¥å‘é‡å¯¹åº”çš„æ–‡æœ¬å°†ä½œä¸ºä¸Šä¸‹æ–‡è¾“å…¥åˆ°ä½œè€…æœºå™¨äººï¼Œä»¥å¸®åŠ©ç”Ÿæˆç­”æ¡ˆã€‚è¿™ä¸ªè¿‡ç¨‹è¢«ç§°ä¸º**å‘é‡æœç´¢**ï¼Œæ˜¯æ–‡æ¡£é—®ç­”çš„æ ¸å¿ƒã€‚
- en: Finally, we create a helper function to generate a short summary of the paper.
    This will be useful later for setting the stage for the journalist bot.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªè¾…åŠ©å‡½æ•°æ¥ç”Ÿæˆè®ºæ–‡çš„ç®€çŸ­æ‘˜è¦ã€‚è¿™å°†åœ¨ç¨åä¸ºè®°è€…æœºå™¨äººè®¾å®šåœºæ™¯æ—¶éå¸¸æœ‰ç”¨ã€‚
- en: '[PRE4]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: we resort to LLMs to create the summary. Technically speaking, we can achieve
    that goal by using LangChainâ€™s `load_summarize_chain`, which takes the LLM model
    and the summarization method as inputs.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ±‚åŠ©äº LLM æ¥åˆ›å»ºæ‘˜è¦ã€‚ä»æŠ€æœ¯ä¸Šè®²ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨ LangChain çš„ `load_summarize_chain` æ¥å®ç°è¿™ä¸€ç›®æ ‡ï¼Œè¯¥æ–¹æ³•æ¥å—
    LLM æ¨¡å‹å’Œæ€»ç»“æ–¹æ³•ä½œä¸ºè¾“å…¥ã€‚
- en: In terms of the summarization method, here, we have used the **stuff** method,
    which simply â€œstuffâ€ all the documents into a single context and prompts the LLM
    to generate the summary. For other more advanced methods, please refer to the
    [official page](https://python.langchain.com/docs/use_cases/summarization) of
    LangChain.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ‘˜è¦æ–¹æ³•æ–¹é¢ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†**stuff**æ–¹æ³•ï¼Œå®ƒç®€å•åœ°å°†æ‰€æœ‰æ–‡æ¡£â€œå¡«å……â€åˆ°ä¸€ä¸ªä¸Šä¸‹æ–‡ä¸­ï¼Œå¹¶æç¤ºLLMç”Ÿæˆæ‘˜è¦ã€‚æœ‰å…³å…¶ä»–æ›´é«˜çº§çš„æ–¹æ³•ï¼Œè¯·å‚é˜…LangChainçš„[å®˜æ–¹é¡µé¢](https://python.langchain.com/docs/use_cases/summarization)ã€‚
- en: 'Great! Now that we have developed the `Embedder` class to handle the document
    loading, splitting, as well as embedding creation and storage, we can move on
    to the core of our app: the dual-chatbot system.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: å¤ªæ£’äº†ï¼ç°åœ¨æˆ‘ä»¬å·²ç»å¼€å‘äº†`Embedder`ç±»æ¥å¤„ç†æ–‡æ¡£åŠ è½½ã€æ‹†åˆ†ä»¥åŠåµŒå…¥åˆ›å»ºå’Œå­˜å‚¨ï¼Œæˆ‘ä»¬å¯ä»¥è½¬åˆ°æˆ‘ä»¬åº”ç”¨çš„æ ¸å¿ƒéƒ¨åˆ†ï¼šåŒèŠå¤©æœºå™¨äººç³»ç»Ÿã€‚
- en: '4\. Feature 2: Dual-Chatbot System'
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4. åŠŸèƒ½ 2ï¼šåŒèŠå¤©æœºå™¨äººç³»ç»Ÿ
- en: 'In this section, we address our second user story:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å¤„ç†æˆ‘ä»¬çš„ç¬¬äºŒä¸ªç”¨æˆ·æ•…äº‹ï¼š
- en: â€œAs a user, I want to observe an autonomous conversation between two chatbots
    â€” one playing the role of a â€˜journalistâ€™ asking questions and the other playing
    the role of an â€˜authorâ€™ answering them, derived from the contents of the research
    paper. This will help me understand the paperâ€™s key points without needing to
    read it in its entirety or craft my own questions.â€ (Generated by GPT-4)
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘æƒ³è§‚å¯Ÿä¸¤ä¸ªèŠå¤©æœºå™¨äººä¹‹é—´çš„è‡ªä¸»å¯¹è¯â€”â€”ä¸€ä¸ªæ‰®æ¼”â€˜è®°è€…â€™æé—®ï¼Œå¦ä¸€ä¸ªæ‰®æ¼”â€˜ä½œè€…â€™å›ç­”ï¼Œé—®é¢˜å’Œå›ç­”éƒ½æ¥è‡ªç ”ç©¶è®ºæ–‡çš„å†…å®¹ã€‚è¿™å°†å¸®åŠ©æˆ‘ç†è§£è®ºæ–‡çš„å…³é”®ç‚¹ï¼Œè€Œæ— éœ€å®Œæ•´é˜…è¯»è®ºæ–‡æˆ–è‡ªå·±æå‡ºé—®é¢˜ã€‚â€ï¼ˆç”±GPT-4ç”Ÿæˆï¼‰
- en: We will start by creating an abstract base class for defining the common behaviors
    of the chatbots. Afterward, we will develop the individual journalist bot and
    the author bot that inherit from the chatbot base class. We put all the class
    definitions in `chatbot.py`.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†é¦–å…ˆåˆ›å»ºä¸€ä¸ªæŠ½è±¡åŸºç±»ï¼Œç”¨äºå®šä¹‰èŠå¤©æœºå™¨äººçš„å…±åŒè¡Œä¸ºã€‚ä¹‹åï¼Œæˆ‘ä»¬å°†å¼€å‘ç»§æ‰¿è‡ªèŠå¤©æœºå™¨äººåŸºç±»çš„è®°è€…æœºå™¨äººå’Œä½œè€…æœºå™¨äººã€‚æˆ‘ä»¬å°†æ‰€æœ‰ç±»å®šä¹‰æ”¾åœ¨`chatbot.py`ä¸­ã€‚
- en: 4.1 Abstract chatbot class
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 æŠ½è±¡èŠå¤©æœºå™¨äººç±»
- en: 'Since our journalist bot and the author bot share a lot of similarities (as
    they are all role-playing bots), it is a good practice to encapsulate the definition
    of their shared behaviors within an abstract base class:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬çš„è®°è€…æœºå™¨äººå’Œä½œè€…æœºå™¨äººæœ‰å¾ˆå¤šç›¸ä¼¼ä¹‹å¤„ï¼ˆå› ä¸ºå®ƒä»¬éƒ½æ˜¯è§’è‰²æ‰®æ¼”æœºå™¨äººï¼‰ï¼Œå°†å®ƒä»¬å…±äº«çš„è¡Œä¸ºå®šä¹‰å°è£…åœ¨ä¸€ä¸ªæŠ½è±¡åŸºç±»ä¸­æ˜¯ä¸€ä¸ªå¥½ä¹ æƒ¯ï¼š
- en: '[PRE5]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We defined three common methods:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å®šä¹‰äº†ä¸‰ä¸ªå¸¸ç”¨æ–¹æ³•ï¼š
- en: '`instruct`: this method is used to set up the chatbot and attach memory to
    it.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`instruct`ï¼šè¿™ä¸ªæ–¹æ³•ç”¨äºè®¾ç½®èŠå¤©æœºå™¨äººå¹¶å°†å†…å­˜é™„åŠ åˆ°å®ƒä¸Šé¢ã€‚'
- en: '`step`: this method is used to feed input to the chatbot and receive the botâ€™s
    response.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`step`ï¼šè¿™ä¸ªæ–¹æ³•ç”¨äºå‘èŠå¤©æœºå™¨äººæä¾›è¾“å…¥å¹¶æ¥æ”¶æœºå™¨äººçš„å›åº”ã€‚'
- en: '`specify_system_message`: this method is used to give the chatbot specific
    instructions regarding how it should behave during the conversation.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`specify_system_message`ï¼šè¿™ä¸ªæ–¹æ³•ç”¨äºç»™èŠå¤©æœºå™¨äººæä¾›å…·ä½“çš„æŒ‡ä»¤ï¼Œè¯´æ˜å®ƒåœ¨å¯¹è¯ä¸­åº”è¯¥å¦‚ä½•è¡Œä¸ºã€‚'
- en: With the chatbot template in place, we are ready to create two specific chatbot
    roles, i.e., the journalist bot and the author bot.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰äº†èŠå¤©æœºå™¨äººæ¨¡æ¿ï¼Œæˆ‘ä»¬å‡†å¤‡åˆ›å»ºä¸¤ä¸ªå…·ä½“çš„èŠå¤©æœºå™¨äººè§’è‰²ï¼Œå³è®°è€…æœºå™¨äººå’Œä½œè€…æœºå™¨äººã€‚
- en: 4.2 Journalist chatbot class
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 è®°è€…èŠå¤©æœºå™¨äººç±»
- en: The journalist botâ€™s role is to interview the author bot and extract key insights
    from a research paper. With that in mind, letâ€™s fill the template methods with
    concrete code.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: è®°è€…æœºå™¨äººçš„è§’è‰²æ˜¯é‡‡è®¿ä½œè€…æœºå™¨äººå¹¶ä»ç ”ç©¶è®ºæ–‡ä¸­æå–å…³é”®è§è§£ã€‚è€ƒè™‘åˆ°è¿™ä¸€ç‚¹ï¼Œè®©æˆ‘ä»¬ç”¨å…·ä½“çš„ä»£ç å¡«å……æ¨¡æ¿æ–¹æ³•ã€‚
- en: '[PRE6]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In the constructor method, besides specifying a backbone LLM, another important
    component for the journalist bot is the memory object. Memory tracks the conversation
    history and serves as the key to helping the journalist bot avoid repetitive or
    irrelevant questions and generate meaningful follow-up questions. Technically,
    we achieved that by using the `ConversationBufferMemory` provided by LangChain,
    which simply prepends the last few inputs/outputs to the current input of the
    chatbot.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ„é€ å‡½æ•°æ–¹æ³•ä¸­ï¼Œé™¤äº†æŒ‡å®šä¸€ä¸ªä¸»å¹²LLMï¼Œè®°è€…æœºå™¨äººå¦ä¸€ä¸ªé‡è¦çš„ç»„ä»¶æ˜¯å†…å­˜å¯¹è±¡ã€‚å†…å­˜è·Ÿè¸ªå¯¹è¯å†å²ï¼Œå¹¶å¸®åŠ©è®°è€…æœºå™¨äººé¿å…é‡å¤æˆ–æ— å…³çš„é—®é¢˜ï¼Œå¹¶ç”Ÿæˆæœ‰æ„ä¹‰çš„åç»­é—®é¢˜ã€‚ä»æŠ€æœ¯ä¸Šè®²ï¼Œæˆ‘ä»¬é€šè¿‡ä½¿ç”¨LangChainæä¾›çš„`ConversationBufferMemory`æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œå®ƒç®€å•åœ°å°†æœ€åå‡ æ¬¡è¾“å…¥/è¾“å‡ºé™„åŠ åˆ°èŠå¤©æœºå™¨äººçš„å½“å‰è¾“å…¥ä¸­ã€‚
- en: Next, we set up the journalist chatbot by creating a`ConversationChain`, with
    the previously defined backbone LLM, the memory object, as well as the prompt
    for the chatbot. Note that we have also specified `topic` (the paper topic) and
    `abstract` (the paper summary), which will be used later to provide the context
    of the paper to the journalist bot.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬é€šè¿‡åˆ›å»ºä¸€ä¸ª `ConversationChain` æ¥è®¾ç½®è®°è€…èŠå¤©æœºå™¨äººï¼Œä½¿ç”¨ä¹‹å‰å®šä¹‰çš„éª¨å¹² LLMã€å†…å­˜å¯¹è±¡ä»¥åŠèŠå¤©æœºå™¨äººçš„æç¤ºã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬è¿˜æŒ‡å®šäº†
    `topic`ï¼ˆè®ºæ–‡ä¸»é¢˜ï¼‰å’Œ `abstract`ï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰ï¼Œè¿™äº›å°†åœ¨ç¨åç”¨äºå‘è®°è€…æœºå™¨äººæä¾›è®ºæ–‡çš„èƒŒæ™¯ä¿¡æ¯ã€‚
- en: '[PRE7]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In LangChain, the prompt generation and ingestion for instructing the chatbot
    are handled via different prompt templates. For our current application, the most
    critical piece is setting the `SystemMessagePromptTemplate`, as it allows us to
    give a *high-level purpose* to the journalist bot and also define its desired
    behaviors.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ LangChain ä¸­ï¼Œç”¨äºæŒ‡ç¤ºèŠå¤©æœºå™¨äººçš„æç¤ºç”Ÿæˆå’Œæ¥æ”¶æ˜¯é€šè¿‡ä¸åŒçš„æç¤ºæ¨¡æ¿å¤„ç†çš„ã€‚å¯¹äºæˆ‘ä»¬å½“å‰çš„åº”ç”¨ç¨‹åºï¼Œæœ€å…³é”®çš„éƒ¨åˆ†æ˜¯è®¾ç½® `SystemMessagePromptTemplate`ï¼Œå› ä¸ºå®ƒå…è®¸æˆ‘ä»¬ç»™è®°è€…æœºå™¨äººæä¾›
    *é«˜çº§ç›®çš„*ï¼Œå¹¶å®šä¹‰å…¶æœŸæœ›çš„è¡Œä¸ºã€‚
- en: The followings are the details of the instruction. Note that the instruction/prompt
    is generated and optimized by using ChatGPT (GPT-4). This is beneficial as in
    the current case, the LLM-generated prompts tend to consider more nuances than
    the human-crafted ones. Additionally, generating high-level instructions with
    LLM represents a more scalable solution for adapting the systems to other scenarios
    beyond â€œjournalist-authorâ€ interactions.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯æŒ‡ä»¤çš„è¯¦ç»†ä¿¡æ¯ã€‚è¯·æ³¨æ„ï¼ŒæŒ‡ä»¤/æç¤ºæ˜¯é€šè¿‡ ChatGPT (GPT-4) ç”Ÿæˆå’Œä¼˜åŒ–çš„ã€‚è¿™æ˜¯æœ‰åˆ©çš„ï¼Œå› ä¸ºåœ¨å½“å‰æƒ…å†µä¸‹ï¼ŒLLM ç”Ÿæˆçš„æç¤ºå¾€å¾€æ¯”äººå·¥ç¼–å†™çš„æç¤ºè€ƒè™‘æ›´å¤šç»†èŠ‚ã€‚æ­¤å¤–ï¼Œä½¿ç”¨
    LLM ç”Ÿæˆé«˜çº§æŒ‡ä»¤ä»£è¡¨äº†ä¸€ç§æ›´å…·å¯æ‰©å±•æ€§çš„è§£å†³æ–¹æ¡ˆï¼Œå¯ä»¥å°†ç³»ç»Ÿé€‚åº”åˆ°â€œè®°è€…-ä½œè€…â€äº’åŠ¨ä¹‹å¤–çš„å…¶ä»–æƒ…å¢ƒã€‚
- en: '[PRE8]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Here, we provided the journalist bot with the paperâ€™s research domain and abstract
    to serve as the base for initial questions. This mirrors the real-world scenario
    where a journalist initially only knows a little about the paper and needs to
    ask questions to gather more information.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¸ºè®°è€…æœºå™¨äººæä¾›äº†è®ºæ–‡çš„ç ”ç©¶é¢†åŸŸå’Œæ‘˜è¦ï¼Œä½œä¸ºåˆå§‹é—®é¢˜çš„åŸºç¡€ã€‚è¿™åæ˜ äº†ç°å®ä¸–ç•Œä¸­è®°è€…æœ€åˆå¯¹è®ºæ–‡äº†è§£ä¸å¤šï¼Œéœ€è¦é€šè¿‡æé—®æ¥è·å–æ›´å¤šä¿¡æ¯çš„æƒ…å¢ƒã€‚
- en: 'Finally, we need a `step` method to interact with the journalist bot:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ª `step` æ–¹æ³•æ¥ä¸è®°è€…æœºå™¨äººäº’åŠ¨ï¼š
- en: '[PRE9]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In this case, the input prompt will be the author botâ€™s answer to the journalist
    botâ€™s previous question. If the conversation has not started yet, the input prompt
    will simply be â€œStart the conversationâ€, to prompt the journalist bot to start
    the interview.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¾“å…¥æç¤ºå°†æ˜¯ä½œè€…æœºå™¨äººå¯¹è®°è€…æœºå™¨äººä¸Šä¸€ä¸ªé—®é¢˜çš„å›ç­”ã€‚å¦‚æœå¯¹è¯å°šæœªå¼€å§‹ï¼Œè¾“å…¥æç¤ºå°†ç®€å•ä¸ºâ€œå¼€å§‹å¯¹è¯â€ï¼Œä»¥æç¤ºè®°è€…æœºå™¨äººå¯åŠ¨é‡‡è®¿ã€‚
- en: Thatâ€™s it for the journalist bot. Letâ€™s now turn to the author bot.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯è®°è€…æœºå™¨äººçš„å…¨éƒ¨å†…å®¹ã€‚ç°åœ¨è®©æˆ‘ä»¬è½¬å‘ä½œè€…æœºå™¨äººã€‚
- en: 4.3 Author bot class
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3 ä½œè€…æœºå™¨äººç±»
- en: 'The author botâ€™s role is to answer questions raised by the journalist bot based
    on the research paper. Here is the constructor method for the author bot:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æœºå™¨äººçš„è§’è‰²æ˜¯æ ¹æ®ç ”ç©¶è®ºæ–‡å›ç­”è®°è€…æœºå™¨äººæå‡ºçš„é—®é¢˜ã€‚ä»¥ä¸‹æ˜¯ä½œè€…æœºå™¨äººçš„æ„é€ æ–¹æ³•ï¼š
- en: '[PRE10]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'There are two things changed here: first of all, unlike the journalist bot,
    the author bot should be able to access the full paper. Therefore, the vector
    store we created earlier needs to be provided to the constructor. Also, note that
    we are not using the memory object (e.g., `ConversationBufferMemory`) to track
    chat history anymore. Instead, we will simply use a list to store the history
    and later pass it explicitly to the author bot. Each element of the list will
    be a tuple of (query, answer). Both ways of maintaining conversation history are
    supported in LangChain.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸¤ç‚¹å˜åŒ–ï¼šé¦–å…ˆï¼Œä¸è®°è€…æœºå™¨äººä¸åŒï¼Œä½œè€…æœºå™¨äººåº”è¯¥èƒ½å¤Ÿè®¿é—®å®Œæ•´çš„è®ºæ–‡ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä¹‹å‰åˆ›å»ºçš„å‘é‡å­˜å‚¨éœ€è¦æä¾›ç»™æ„é€ å‡½æ•°ã€‚å¦å¤–ï¼Œè¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä¸å†ä½¿ç”¨å†…å­˜å¯¹è±¡ï¼ˆä¾‹å¦‚`ConversationBufferMemory`ï¼‰æ¥è·Ÿè¸ªèŠå¤©è®°å½•ã€‚ç›¸åï¼Œæˆ‘ä»¬å°†ç®€å•åœ°ä½¿ç”¨ä¸€ä¸ªåˆ—è¡¨æ¥å­˜å‚¨å†å²è®°å½•ï¼Œå¹¶åœ¨ä¹‹åæ˜ç¡®ä¼ é€’ç»™ä½œè€…æœºå™¨äººã€‚åˆ—è¡¨çš„æ¯ä¸ªå…ƒç´ å°†æ˜¯ä¸€ä¸ª
    (query, answer) çš„å…ƒç»„ã€‚åœ¨ LangChain ä¸­ï¼Œä¸¤ç§ç»´æŠ¤å¯¹è¯å†å²çš„æ–¹æ³•éƒ½è¢«æ”¯æŒã€‚
- en: Next, we set up the conversation chain for the author bot.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä¸ºä½œè€…æœºå™¨äººè®¾ç½®å¯¹è¯é“¾ã€‚
- en: '[PRE11]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Since the author bot needs to answer questions by first retrieving relevant
    context, we adopted a `ConversationalRetrievalChain`. To quote from the official
    document of LangChain:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºä½œè€…æœºå™¨äººéœ€è¦é€šè¿‡é¦–å…ˆæ£€ç´¢ç›¸å…³èƒŒæ™¯æ¥å›ç­”é—®é¢˜ï¼Œæˆ‘ä»¬é‡‡ç”¨äº† `ConversationalRetrievalChain`ã€‚å¼•ç”¨ LangChain çš„å®˜æ–¹æ–‡æ¡£ï¼š
- en: '**ConversationalRetrievalChain** first combines the chat history (either explicitly
    passed in or retrieved from the provided memory) and the query into a standalone
    question, then looks up relevant documents from the retriever, and finally passes
    those documents and the query to a question answering chain to return a response.'
  id: totrans-122
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**å¯¹è¯æ£€ç´¢é“¾**é¦–å…ˆå°†èŠå¤©è®°å½•ï¼ˆæ— è®ºæ˜¯æ˜ç¡®ä¼ é€’çš„è¿˜æ˜¯ä»æä¾›çš„è®°å¿†ä¸­æ£€ç´¢åˆ°çš„ï¼‰å’ŒæŸ¥è¯¢åˆå¹¶æˆä¸€ä¸ªç‹¬ç«‹çš„é—®é¢˜ï¼Œç„¶åä»æ£€ç´¢å™¨ä¸­æŸ¥æ‰¾ç›¸å…³æ–‡æ¡£ï¼Œæœ€åå°†è¿™äº›æ–‡æ¡£å’ŒæŸ¥è¯¢ä¼ é€’ç»™é—®é¢˜å›ç­”é“¾ä»¥è¿”å›å“åº”ã€‚'
- en: Therefore, in addition to the backbone LLM, we also need to supply the chain
    with a vector store. Note that here we specified the number of returned relevant
    documents (PDF chunks) via `search_kwargs`. In general, selecting the right number
    is not a trivial task and deserves careful consideration of balancing accuracy,
    relevance, comprehensiveness, and computational resources. Lastly, we set `return_source_documents`
    to True, which is important for ensuring transparency and traceability in the
    Q&A process.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œé™¤äº†åŸºç¡€LLMï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä¸ºé“¾æä¾›ä¸€ä¸ªå‘é‡å­˜å‚¨ã€‚è¯·æ³¨æ„ï¼Œè¿™é‡Œæˆ‘ä»¬é€šè¿‡`search_kwargs`æŒ‡å®šäº†è¿”å›çš„ç›¸å…³æ–‡æ¡£ï¼ˆPDFå—ï¼‰çš„æ•°é‡ã€‚é€šå¸¸ï¼Œé€‰æ‹©æ­£ç¡®çš„æ•°é‡ä¸æ˜¯ä¸€é¡¹ç®€å•çš„ä»»åŠ¡ï¼Œéœ€è¦ä»”ç»†è€ƒè™‘å‡†ç¡®æ€§ã€ç›¸å…³æ€§ã€å…¨é¢æ€§å’Œè®¡ç®—èµ„æºçš„å¹³è¡¡ã€‚æœ€åï¼Œæˆ‘ä»¬å°†`return_source_documents`è®¾ç½®ä¸ºTrueï¼Œè¿™å¯¹ç¡®ä¿é—®ç­”è¿‡ç¨‹ä¸­çš„é€æ˜æ€§å’Œå¯è¿½æº¯æ€§éå¸¸é‡è¦ã€‚
- en: 'To interact with the author bot:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: è¦ä¸ä½œè€…æœºå™¨äººäº’åŠ¨ï¼š
- en: '[PRE12]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As discussed previously, we explicitly supplied the chat history (a list of
    previous query-answer tuples) to the conversation chain. As a result, we also
    need to manually append the newly obtained query-answer tuple to the chat history.
    For the response, we get not only the answer but also the source documents (PDF
    chunks) used by the author bot to generate the answer, which will be used later
    to highlight the corresponding texts in PDF.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å‰æ‰€è¿°ï¼Œæˆ‘ä»¬æ˜ç¡®å°†èŠå¤©è®°å½•ï¼ˆä»¥å‰çš„æŸ¥è¯¢-å›ç­”å…ƒç»„åˆ—è¡¨ï¼‰æä¾›ç»™å¯¹è¯é“¾ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è¿˜éœ€è¦æ‰‹åŠ¨å°†æ–°è·å¾—çš„æŸ¥è¯¢-å›ç­”å…ƒç»„é™„åŠ åˆ°èŠå¤©è®°å½•ä¸­ã€‚å¯¹äºå“åº”ï¼Œæˆ‘ä»¬ä¸ä»…å¾—åˆ°ç­”æ¡ˆï¼Œè¿˜å¾—åˆ°ä½œè€…æœºå™¨äººç”¨äºç”Ÿæˆç­”æ¡ˆçš„æºæ–‡æ¡£ï¼ˆPDFå—ï¼‰ï¼Œè¿™äº›æ–‡æ¡£å°†åœ¨ç¨åç”¨äºçªå‡ºæ˜¾ç¤ºPDFä¸­çš„ç›¸åº”æ–‡æœ¬ã€‚
- en: Finally, we inform the role of the author bot and specify detailed instructions.
    Same as the journalist bot, the instruction/prompt for the author bot is also
    generated and optimized by using ChatGPT (GPT-4).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬å‘ŠçŸ¥ä½œè€…æœºå™¨äººè§’è‰²å¹¶æŒ‡å®šè¯¦ç»†çš„æŒ‡ä»¤ã€‚ä¸è®°è€…æœºå™¨äººä¸€æ ·ï¼Œä½œè€…æœºå™¨äººçš„æŒ‡ä»¤/æç¤ºä¹Ÿç”±ChatGPTï¼ˆGPT-4ï¼‰ç”Ÿæˆå’Œä¼˜åŒ–ã€‚
- en: '[PRE13]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Thatâ€™s it for constructing the author bot.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æ„å»ºä½œè€…æœºå™¨äººçš„å…¨éƒ¨å†…å®¹ã€‚
- en: '4.4 Quick test: the interview'
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.4 å¿«é€Ÿæµ‹è¯•ï¼šé‡‡è®¿
- en: Time to take two bots for a ride!
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ˜¯æ—¶å€™å¸¦ä¸¤ä¸ªæœºå™¨äººâ€œè¯•é©¾â€ä¸€ä¸‹äº†ï¼
- en: To see if the developed journalist and author bot can engage in meaningful conversation
    toward the goal of digesting the paper, we pick one sample scientific research
    paper and run the test.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ£€éªŒå¼€å‘çš„è®°è€…æœºå™¨äººå’Œä½œè€…æœºå™¨äººæ˜¯å¦èƒ½è¿›è¡Œæœ‰æ„ä¹‰çš„å¯¹è¯ä»¥è¾¾åˆ°æ¶ˆåŒ–è®ºæ–‡çš„ç›®çš„ï¼Œæˆ‘ä»¬é€‰æ‹©äº†ä¸€ç¯‡æ ·æœ¬ç§‘å­¦ç ”ç©¶è®ºæ–‡å¹¶è¿›è¡Œæµ‹è¯•ã€‚
- en: As I was working on physics-informed machine learning recently, here, I picked
    an arXiv paper named â€œ[**Improved Training of Physics-Informed Neural Networks
    with Model Ensembles**](https://arxiv.org/abs/2204.05108)**â€** (CC BY 4.0 license)for
    the test.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€è¿‘åœ¨ç ”ç©¶ç‰©ç†ä¿¡æ¯æœºå™¨å­¦ä¹ æ—¶ï¼Œæˆ‘é€‰æ‹©äº†ä¸€ç¯‡åä¸ºâ€œ[**æ”¹è¿›ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œçš„æ¨¡å‹é›†æˆè®­ç»ƒ**](https://arxiv.org/abs/2204.05108)**â€**ï¼ˆCC
    BY 4.0 è®¸å¯ï¼‰çš„arXivè®ºæ–‡è¿›è¡Œæµ‹è¯•ã€‚
- en: '[PRE14]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The generated conversation script is shown below. Note that to save space,
    some of the author botâ€™s answers are not shown in full:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆçš„å¯¹è¯è„šæœ¬å¦‚ä¸‹æ‰€ç¤ºã€‚è¯·æ³¨æ„ï¼Œä¸ºäº†èŠ‚çœç©ºé—´ï¼Œä¸€äº›ä½œè€…æœºå™¨äººçš„å›ç­”æœªå®Œå…¨æ˜¾ç¤ºï¼š
- en: '![](../Images/a6e2d39406c7e6052ecb73d4b7f171fe.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a6e2d39406c7e6052ecb73d4b7f171fe.png)'
- en: The interview between the developed journalist bot and the author bot. (Image
    by author)
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: å¼€å‘çš„è®°è€…æœºå™¨äººå’Œä½œè€…æœºå™¨äººçš„é‡‡è®¿ã€‚ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰
- en: Since the author bot only passively answers questions (i.e., a conventional
    Q&A agent), we focus our attention on the behavior of the journalist bot to assess
    if it can properly steer the interview. Here we can see that the journalist bot
    started with a general question about the paper (the motivation), then adapted
    its questions to dig deeper into the methodology of the proposed strategy. Overall,
    the behavior of the developed journalist bot aligns with our expectations and
    it is capable of conducting the interview toward distilling the key points from
    the given paper. Not badğŸ˜ƒ
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºä½œè€…æœºå™¨äººä»…è¢«åŠ¨å›ç­”é—®é¢˜ï¼ˆå³ä¼ ç»Ÿçš„é—®ç­”ä»£ç†ï¼‰ï¼Œæˆ‘ä»¬å°†é‡ç‚¹æ”¾åœ¨è®°è€…æœºå™¨äººçš„è¡Œä¸ºä¸Šï¼Œä»¥è¯„ä¼°å®ƒæ˜¯å¦èƒ½å¤Ÿæœ‰æ•ˆå¼•å¯¼é‡‡è®¿ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è®°è€…æœºå™¨äººé¦–å…ˆæå‡ºäº†ä¸€ä¸ªå…³äºè®ºæ–‡çš„ä¸€èˆ¬æ€§é—®é¢˜ï¼ˆåŠ¨æœºï¼‰ï¼Œç„¶åè°ƒæ•´é—®é¢˜ä»¥æ·±å…¥æ¢è®¨æè®®ç­–ç•¥çš„æ–¹æ³•ã€‚æ€»ä½“è€Œè¨€ï¼Œå¼€å‘çš„è®°è€…æœºå™¨äººçš„è¡Œä¸ºç¬¦åˆæˆ‘ä»¬çš„é¢„æœŸï¼Œèƒ½å¤Ÿè¿›è¡Œé‡‡è®¿ä»¥æç‚¼å‡ºè®ºæ–‡çš„å…³é”®ç‚¹ã€‚è¡¨ç°ä¸é”™ğŸ˜ƒ
- en: '5\. Feature 3: User Interaction'
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. ç‰¹æ€§ 3ï¼šç”¨æˆ·äº’åŠ¨
- en: In this section, we wrap our previous experiment into a proper user interface.
    Toward that end, we will address three user stories to incrementally build the
    desired features.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä¹‹å‰çš„å®éªŒå°è£…åˆ°ä¸€ä¸ªåˆé€‚çš„ç”¨æˆ·ç•Œé¢ä¸­ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†è§£å†³ä¸‰ä¸ªç”¨æˆ·æ•…äº‹ï¼Œä»¥é€æ­¥æ„å»ºæ‰€éœ€çš„åŠŸèƒ½ã€‚
- en: 5.1 Creating the chat environment (in Jupyter Notebook)
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 åˆ›å»ºèŠå¤©ç¯å¢ƒï¼ˆåœ¨Jupyter Notebookä¸­ï¼‰
- en: 'Letâ€™s start with the 3rd user story:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä»ç¬¬3ä¸ªç”¨æˆ·æ•…äº‹å¼€å§‹ï¼š
- en: â€œAs a user, I want an intuitive chat interface where I can watch the chatbotsâ€™
    conversation unfold in real-time.â€ (Generated by GPT-4)
  id: totrans-143
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›æœ‰ä¸€ä¸ªç›´è§‚çš„èŠå¤©ç•Œé¢ï¼Œå¯ä»¥å®æ—¶è§‚çœ‹èŠå¤©æœºå™¨äººçš„å¯¹è¯å±•å¼€ã€‚â€ï¼ˆç”±GPT-4ç”Ÿæˆï¼‰
- en: To keep things simple, we opt for Jupyter widgets as they allow quickly building
    a chat environment entirely in Jupyter Notebook.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä¿æŒç®€å•ï¼Œæˆ‘ä»¬é€‰æ‹©Jupyterå°éƒ¨ä»¶ï¼Œå› ä¸ºå®ƒä»¬å…è®¸åœ¨Jupyter Notebookä¸­å¿«é€Ÿæ„å»ºæ•´ä¸ªèŠå¤©ç¯å¢ƒã€‚
- en: 'First, we set up the layout of displaying conversation:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬è®¾ç½®æ˜¾ç¤ºå¯¹è¯çš„å¸ƒå±€ï¼š
- en: '[PRE15]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We created a button (`bot_ask`) such that when the user clicks it, a callback
    function `bot_ask_clicked` will be invoked and one round of conversation between
    the journalist and author bot will be generated. Afterward, we used the HTML widgets
    to display the conversation as HTML content in the notebook.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªæŒ‰é’®ï¼ˆ`bot_ask`ï¼‰ï¼Œå½“ç”¨æˆ·ç‚¹å‡»å®ƒæ—¶ï¼Œä¼šè°ƒç”¨ä¸€ä¸ªå›è°ƒå‡½æ•°`bot_ask_clicked`ï¼Œå¹¶ç”Ÿæˆä¸€è½®è®°è€…å’Œä½œè€…æœºå™¨äººä¹‹é—´çš„å¯¹è¯ã€‚ä¹‹åï¼Œæˆ‘ä»¬ä½¿ç”¨HTMLå°éƒ¨ä»¶åœ¨ç¬”è®°æœ¬ä¸­ä»¥HTMLå†…å®¹çš„å½¢å¼æ˜¾ç¤ºå¯¹è¯ã€‚
- en: The callback function `bot_ask_clicked` is defined below. Besides showing the
    journalist botâ€™s question and the author botâ€™s answer, we also indicated the location
    (i.e., page number) of the relevant source texts. This is possible because the
    `step()` method of the author bot also returns the `source` variable, which is
    a list of LangChain `Document` object that contains the page content and its associated
    metadata.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: å›è°ƒå‡½æ•°`bot_ask_clicked`å®šä¹‰å¦‚ä¸‹ã€‚é™¤äº†æ˜¾ç¤ºè®°è€…æœºå™¨äººçš„é—®é¢˜å’Œä½œè€…æœºå™¨äººçš„å›ç­”å¤–ï¼Œæˆ‘ä»¬è¿˜æŒ‡æ˜äº†ç›¸å…³æºæ–‡æœ¬çš„ä½ç½®ï¼ˆå³é¡µé¢ç¼–å·ï¼‰ã€‚è¿™æ˜¯å¯èƒ½çš„ï¼Œå› ä¸ºä½œè€…æœºå™¨äººçš„`step()`æ–¹æ³•è¿˜è¿”å›`source`å˜é‡ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«é¡µé¢å†…å®¹åŠå…¶ç›¸å…³å…ƒæ•°æ®çš„LangChain
    `Document`å¯¹è±¡åˆ—è¡¨ã€‚
- en: '[PRE16]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Putting everything together, we have the following interface:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ç»¼åˆè€ƒè™‘ï¼Œæˆ‘ä»¬å¾—åˆ°äº†ä»¥ä¸‹ç•Œé¢ï¼š
- en: '![](../Images/c229c6cb979f88ccfa584285bad8c376.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c229c6cb979f88ccfa584285bad8c376.png)'
- en: Chat interface. (Image by author)
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: èŠå¤©ç•Œé¢ã€‚ï¼ˆä½œè€…æä¾›çš„å›¾ç‰‡ï¼‰
- en: 5.2 Implementing PDF highlighting functionality
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 å®ç°PDFé«˜äº®åŠŸèƒ½
- en: 'In our current UI, we only indicated on which pages the author bot looked for
    the answers to the journalist botâ€™s question. Ideally, the user would expect the
    relevant texts to be highlighted in the original PDF to allow quick reference.
    This is the motivation for the 4th user story:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬å½“å‰çš„UIä¸­ï¼Œæˆ‘ä»¬ä»…æŒ‡æ˜äº†ä½œè€…æœºå™¨äººæŸ¥æ‰¾è®°è€…æœºå™¨äººé—®é¢˜ç­”æ¡ˆçš„é¡µé¢ã€‚ç†æƒ³æƒ…å†µä¸‹ï¼Œç”¨æˆ·å¸Œæœ›åœ¨åŸå§‹PDFä¸­çªå‡ºæ˜¾ç¤ºç›¸å…³æ–‡æœ¬ï¼Œä»¥ä¾¿å¿«é€Ÿå‚è€ƒã€‚è¿™æ˜¯ç¬¬4ä¸ªç”¨æˆ·æ•…äº‹çš„åŠ¨æœºï¼š
- en: â€œAs a user, I want to have the corresponding parts in the original research
    paper highlighted based on the chatbotâ€™s discussion. This will help me to quickly
    locate the sources of the information discussed during the conversation.â€ (Generated
    by GPT-4)
  id: totrans-155
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›æ ¹æ®èŠå¤©æœºå™¨äººçš„è®¨è®ºï¼Œåœ¨åŸå§‹ç ”ç©¶è®ºæ–‡ä¸­çªå‡ºæ˜¾ç¤ºç›¸åº”çš„éƒ¨åˆ†ã€‚è¿™å°†å¸®åŠ©æˆ‘å¿«é€Ÿå®šä½åœ¨å¯¹è¯è¿‡ç¨‹ä¸­è®¨è®ºçš„ä¿¡æ¯æ¥æºã€‚â€ï¼ˆç”±GPT-4ç”Ÿæˆï¼‰
- en: 'To achieve this goal, we employed the PyMuPDF library to search for relevant
    texts and perform text highlighting:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†PyMuPDFåº“æ¥æœç´¢ç›¸å…³æ–‡æœ¬å¹¶æ‰§è¡Œæ–‡æœ¬é«˜äº®ï¼š
- en: '[PRE17]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In the code above, the `phrases` is a list of strings, where each string represents
    one of the source texts used by the author bot to generate the answers. To highlight
    the texts, the code first loops over each page of the PDF and find if the `phrase`is
    contained on that page. Once the phrase is found, it will be highlighted in the
    original PDF.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šè¿°ä»£ç ä¸­ï¼Œ`phrases`æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨ï¼Œæ¯ä¸ªå­—ç¬¦ä¸²è¡¨ç¤ºä½œè€…æœºå™¨äººç”¨æ¥ç”Ÿæˆå›ç­”çš„æºæ–‡æœ¬ä¹‹ä¸€ã€‚ä¸ºäº†é«˜äº®æ–‡æœ¬ï¼Œä»£ç é¦–å…ˆéå†PDFçš„æ¯ä¸€é¡µï¼ŒæŸ¥æ‰¾è¯¥é¡µæ˜¯å¦åŒ…å«`phrase`ã€‚ä¸€æ—¦æ‰¾åˆ°çŸ­è¯­ï¼Œå®ƒå°†åœ¨åŸå§‹PDFä¸­è¿›è¡Œé«˜äº®æ˜¾ç¤ºã€‚
- en: 'To integrate this highlighting functionality into our previously developed
    chat UI, we first need to update the callback function:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å°†æ­¤é«˜äº®åŠŸèƒ½é›†æˆåˆ°æˆ‘ä»¬ä¹‹å‰å¼€å‘çš„èŠå¤©UIä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦æ›´æ–°å›è°ƒå‡½æ•°ï¼š
- en: '[PRE18]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Although the appearance of our UI stays the same:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡æˆ‘ä»¬çš„UIå¤–è§‚ä¿æŒä¸å˜ï¼š
- en: '![](../Images/e8b533bd5592b34a12daba5bd0529daa.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e8b533bd5592b34a12daba5bd0529daa.png)'
- en: 'under the hood, we would have a new PDF file, with relevant texts (on pages
    1 and 10) properly highlighted:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åº•å±‚ï¼Œæˆ‘ä»¬å°†æœ‰ä¸€ä¸ªæ–°çš„PDFæ–‡ä»¶ï¼Œå…¶ä¸­ç›¸å…³æ–‡æœ¬ï¼ˆåœ¨ç¬¬1å’Œç¬¬10é¡µï¼‰è¢«é€‚å½“åœ°é«˜äº®æ˜¾ç¤ºï¼š
- en: '![](../Images/99ac9965f679532207a325f2837beb8c.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/99ac9965f679532207a325f2837beb8c.png)'
- en: 5.3 Allowing user input for questions
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 å…è®¸ç”¨æˆ·è¾“å…¥é—®é¢˜
- en: 'Up till now, all the conversations between the two bots are autonomous. Ideally,
    users should also be able to ask their own questions if they see fit. This is
    exactly what we want to address for the 5th user story:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œè¿™ä¸¤ä¸ªæœºå™¨äººçš„å¯¹è¯éƒ½æ˜¯è‡ªä¸»çš„ã€‚ç†æƒ³æƒ…å†µä¸‹ï¼Œå¦‚æœç”¨æˆ·è§‰å¾—åˆé€‚ï¼Œä¹Ÿåº”è¯¥èƒ½å¤Ÿæå‡ºè‡ªå·±çš„é—®é¢˜ã€‚è¿™æ­£æ˜¯æˆ‘ä»¬è¦è§£å†³çš„ç¬¬5ä¸ªç”¨æˆ·æ•…äº‹ï¼š
- en: â€œAs a user, I want to be able to intervene and ask my own questions in the midst
    of the chatbotâ€™s conversation, this way I can direct the conversation and extract
    the information I need from the paper.â€ (Generated by GPT-4)
  id: totrans-167
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿåœ¨èŠå¤©æœºå™¨äººçš„å¯¹è¯ä¸­è¿›è¡Œå¹²é¢„å¹¶æå‡ºè‡ªå·±çš„é—®é¢˜ï¼Œè¿™æ ·æˆ‘å¯ä»¥å¼•å¯¼å¯¹è¯å¹¶ä»è®ºæ–‡ä¸­æå–æˆ‘éœ€è¦çš„ä¿¡æ¯ã€‚â€ï¼ˆç”±GPT-4ç”Ÿæˆï¼‰
- en: 'To achieve that goal, we can add another button such that the user can decide
    if a new round of exchange should be initiated by the journalist bot or the user:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å®ç°è¿™ä¸ªç›®æ ‡ï¼Œæˆ‘ä»¬å¯ä»¥æ·»åŠ å¦ä¸€ä¸ªæŒ‰é’®ï¼Œè®©ç”¨æˆ·å†³å®šæ˜¯å¦ç”±è®°è€…æœºå™¨äººæˆ–ç”¨æˆ·å‘èµ·æ–°ä¸€è½®çš„äº¤æµï¼š
- en: '[PRE19]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The above callback function is essentially the same as the callback function
    for defining journalist-author interaction. The only difference is that the â€œquestionâ€
    will be directly input by the user. Also, to make the interview logic consistent,
    we appended the user question to the journalist botâ€™s memory, as if the user-supplied
    question was raised by the journalist bot.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šè¿°å›è°ƒå‡½æ•°æœ¬è´¨ä¸Šä¸å®šä¹‰è®°è€…-ä½œè€…äº’åŠ¨çš„å›è°ƒå‡½æ•°ç›¸åŒã€‚å”¯ä¸€çš„åŒºåˆ«æ˜¯â€œé—®é¢˜â€å°†ç”±ç”¨æˆ·ç›´æ¥è¾“å…¥ã€‚æ­¤å¤–ï¼Œä¸ºäº†ä¿æŒé‡‡è®¿é€»è¾‘çš„ä¸€è‡´æ€§ï¼Œæˆ‘ä»¬å°†ç”¨æˆ·é—®é¢˜é™„åŠ åˆ°è®°è€…æœºå™¨äººçš„è®°å¿†ä¸­ï¼Œå°±åƒç”¨æˆ·æå‡ºçš„é—®é¢˜æ˜¯ç”±è®°è€…æœºå™¨äººæå‡ºçš„ä¸€æ ·ã€‚
- en: 'We updated the main UI logic accordingly:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç›¸åº”åœ°æ›´æ–°äº†ä¸»è¦çš„ç”¨æˆ·ç•Œé¢é€»è¾‘ï¼š
- en: '[PRE20]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'And this is what we got, where users can input their own questions and get
    answered by the author bot:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬å¾—åˆ°çš„ç»“æœï¼Œç”¨æˆ·å¯ä»¥è¾“å…¥è‡ªå·±çš„é—®é¢˜ï¼Œå¹¶ç”±ä½œè€…æœºå™¨äººè¿›è¡Œå›ç­”ï¼š
- en: '![](../Images/37cd0f3b65a6b848749b8cd02a2b9a99.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/37cd0f3b65a6b848749b8cd02a2b9a99.png)'
- en: Besides letting the journalist bot ask questions, users also have the opportunity
    to ask their own questions. (Image by author)
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†è®©è®°è€…æœºå™¨äººæé—®å¤–ï¼Œç”¨æˆ·è¿˜æœ‰æœºä¼šæå‡ºè‡ªå·±çš„é—®é¢˜ã€‚ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰
- en: 5.4 Allowing downloading the generated script
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 å…è®¸ä¸‹è½½ç”Ÿæˆçš„è„šæœ¬
- en: 'So far so good! As the last feature to implement, we want to be able to save
    the conversation history to our disk for later reference. This is the goal of
    the 6th user story:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€åˆ‡é¡ºåˆ©ï¼ä½œä¸ºæœ€åä¸€ä¸ªè¦å®ç°çš„åŠŸèƒ½ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿå°†å¯¹è¯å†å²ä¿å­˜åˆ°ç£ç›˜ä»¥ä¾›ä»¥åå‚è€ƒã€‚è¿™æ˜¯ç¬¬6ä¸ªç”¨æˆ·æ•…äº‹çš„ç›®æ ‡ï¼š
- en: â€œAs a user, I want to be able to download a transcript of the chatbot conversation.
    This will allow me to review the key points offline or share the information with
    my colleagues.â€ (Generated by GPT-4)
  id: totrans-178
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿä¸‹è½½èŠå¤©æœºå™¨äººå¯¹è¯çš„è®°å½•ã€‚è¿™å°†è®©æˆ‘ç¦»çº¿æŸ¥çœ‹å…³é”®ç‚¹æˆ–ä¸åŒäº‹åˆ†äº«ä¿¡æ¯ã€‚â€ï¼ˆç”±GPT-4ç”Ÿæˆï¼‰
- en: 'Toward that end, we added another button for downloading the script and attach
    a callback function to the button. In this callback, we used PDFDocument to convert
    the conversation script into a PDF file:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªæ–°çš„ä¸‹è½½è„šæœ¬æŒ‰é’®ï¼Œå¹¶å°†å›è°ƒå‡½æ•°é™„åŠ åˆ°è¯¥æŒ‰é’®ã€‚åœ¨è¿™ä¸ªå›è°ƒå‡½æ•°ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†PDFDocumentå°†å¯¹è¯è„šæœ¬è½¬æ¢ä¸ºPDFæ–‡ä»¶ï¼š
- en: '[PRE21]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We updated the main UI logic accordingly:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç›¸åº”åœ°æ›´æ–°äº†ä¸»è¦çš„ç”¨æˆ·ç•Œé¢é€»è¾‘ï¼š
- en: '[PRE22]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now, we have a download button appearing in the UI. When the user clicks it,
    a paper summary PDF file will be automatically generated and downloaded to the
    local folder:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œç”¨æˆ·ç•Œé¢ä¸­å‡ºç°äº†ä¸€ä¸ªä¸‹è½½æŒ‰é’®ã€‚å½“ç”¨æˆ·ç‚¹å‡»å®ƒæ—¶ï¼Œä¼šè‡ªåŠ¨ç”Ÿæˆå¹¶ä¸‹è½½ä¸€ä»½è®ºæ–‡æ€»ç»“çš„PDFæ–‡ä»¶åˆ°æœ¬åœ°æ–‡ä»¶å¤¹ï¼š
- en: '![](../Images/fd7da4e202f776400d99d8d260d01c21.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fd7da4e202f776400d99d8d260d01c21.png)'
- en: Users now have the option to download the script of the generated conversation.
    (Image by author)
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨æˆ·ç°åœ¨å¯ä»¥é€‰æ‹©ä¸‹è½½ç”Ÿæˆå¯¹è¯çš„è„šæœ¬ã€‚ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰
- en: '6\. Sprint Review: show the demo!'
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6\. å†²åˆºè¯„å®¡ï¼šå±•ç¤ºæ¼”ç¤ºï¼
- en: Itâ€™s time to put up a demo to showcase our hard work ğŸ’ª
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ˜¯æ—¶å€™å±•ç¤ºæˆ‘ä»¬çš„è¾›å‹¤å·¥ä½œğŸ’ª
- en: 'In this demo, we showed the full functionality of our developed dual-chatbot
    system:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªæ¼”ç¤ºä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†æˆ‘ä»¬å¼€å‘çš„åŒèŠå¤©æœºå™¨äººç³»ç»Ÿçš„å…¨éƒ¨åŠŸèƒ½ï¼š
- en: The two bots can autonomously engage in an interview with the goal of digesting
    the main points from the paper.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™ä¸¤ä¸ªæœºå™¨äººå¯ä»¥è‡ªä¸»è¿›è¡Œé‡‡è®¿ï¼Œç›®çš„æ˜¯æ¶ˆåŒ–è®ºæ–‡çš„ä¸»è¦è§‚ç‚¹ã€‚
- en: The user can jump into the conversation as well and ask interested questions.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨æˆ·ä¹Ÿå¯ä»¥è¿›å…¥å¯¹è¯å¹¶æå‡ºæ„Ÿå…´è¶£çš„é—®é¢˜ã€‚
- en: Relevant texts for the generated answers are automatically highlighted in the
    original PDF.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”Ÿæˆçš„ç­”æ¡ˆçš„ç›¸å…³æ–‡æœ¬ä¼šåœ¨åŸå§‹PDFä¸­è‡ªåŠ¨é«˜äº®æ˜¾ç¤ºã€‚
- en: The conversation history can be downloaded to the local folder.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹è¯å†å²å¯ä»¥ä¸‹è½½åˆ°æœ¬åœ°æ–‡ä»¶å¤¹ã€‚
- en: We have successfully addressed all the user stories, good work ğŸ‰ Now Sprint
    review is over, time for some retrospectives.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æˆåŠŸè§£å†³äº†æ‰€æœ‰ç”¨æˆ·æ•…äº‹ï¼Œå¹²å¾—å¥½ğŸ‰ ç°åœ¨å†²åˆºè¯„å®¡å·²ç»ç»“æŸï¼Œæ˜¯æ—¶å€™è¿›è¡Œä¸€äº›å›é¡¾äº†ã€‚
- en: 7\. Sprint Retrospective
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7\. å†²åˆºå›é¡¾
- en: In this project, we focused on solving the problem of efficiently digesting
    complex research papers. Toward that end, we developed a dual-chatbot system where
    one bot plays the â€œjournalistâ€ while the other bot plays the â€œauthorâ€, and two
    bots are engaged in an interview. In doing so, the journalist bot can act on behalf
    of the user and query the key points of the paper. This is beneficial as it eliminates
    the need for users to devise their own questions â€” an activity that can be challenging
    and time-consuming, particularly when dealing with unfamiliar subjects.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªé¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬ä¸“æ³¨äºè§£å†³é«˜æ•ˆæ¶ˆåŒ–å¤æ‚ç ”ç©¶è®ºæ–‡çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªåŒèŠå¤©æœºå™¨äººç³»ç»Ÿï¼Œå…¶ä¸­ä¸€ä¸ªæœºå™¨äººæ‰®æ¼”â€œè®°è€…â€ï¼Œå¦ä¸€ä¸ªæœºå™¨äººæ‰®æ¼”â€œä½œè€…â€ï¼Œä¸¤ä¸ªæœºå™¨äººè¿›è¡Œé‡‡è®¿ã€‚è¿™æ ·ï¼Œè®°è€…æœºå™¨äººå¯ä»¥ä»£è¡¨ç”¨æˆ·æŸ¥è¯¢è®ºæ–‡çš„å…³é”®ç‚¹ã€‚è¿™æ˜¯æœ‰ç›Šçš„ï¼Œå› ä¸ºå®ƒæ¶ˆé™¤äº†ç”¨æˆ·è‡ªè¡Œè®¾è®¡é—®é¢˜çš„éœ€æ±‚â€”â€”è¿™ä¸€æ´»åŠ¨åœ¨å¤„ç†ä¸ç†Ÿæ‚‰çš„ä¸»é¢˜æ—¶å¯èƒ½æ—¢å…·æœ‰æŒ‘æˆ˜æ€§åˆè€—æ—¶ã€‚
- en: The success of the devised dual-chatbot approach relies critically on the journalist
    botâ€™s ability to steer the interview and generate insightful and relevant questions.
    In the current implementation, we used GPT-3.5-Turbo as the backbone LLM. To further
    enhance the user experience, it may be necessary to employ GPT-4 to boost the
    journalist botâ€™s reasoning capability.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾è®¡çš„åŒèŠå¤©æœºå™¨äººæ–¹æ³•çš„æˆåŠŸå…³é”®åœ¨äºè®°è€…æœºå™¨äººå¼•å¯¼é‡‡è®¿å¹¶ç”Ÿæˆæœ‰è§åœ°ä¸”ç›¸å…³çš„é—®é¢˜çš„èƒ½åŠ›ã€‚åœ¨å½“å‰çš„å®ç°ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† GPT-3.5-Turbo ä½œä¸ºä¸»è¦çš„è¯­è¨€æ¨¡å‹ã€‚ä¸ºäº†è¿›ä¸€æ­¥æå‡ç”¨æˆ·ä½“éªŒï¼Œå¯èƒ½éœ€è¦ä½¿ç”¨
    GPT-4 æ¥å¢å¼ºè®°è€…æœºå™¨äººçš„æ¨ç†èƒ½åŠ›ã€‚
- en: Whatâ€™s also important is that the journalist bot needs to be capable of interpreting
    and understanding the technical terms and concepts used in the broader research
    field to which the paper belongs. Besides using advanced LLM, fine-tuning the
    existing LLM on research papers of the target domain could be a promising strategy
    to pursue.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: å¦å¤–é‡è¦çš„æ˜¯ï¼Œè®°è€…æœºå™¨äººéœ€è¦èƒ½å¤Ÿè§£é‡Šå’Œç†è§£åœ¨ç›¸å…³ç ”ç©¶é¢†åŸŸä¸­ä½¿ç”¨çš„æŠ€æœ¯æœ¯è¯­å’Œæ¦‚å¿µã€‚é™¤äº†ä½¿ç”¨å…ˆè¿›çš„è¯­è¨€æ¨¡å‹ï¼Œé’ˆå¯¹ç›®æ ‡é¢†åŸŸçš„ç ”ç©¶è®ºæ–‡å¯¹ç°æœ‰è¯­è¨€æ¨¡å‹è¿›è¡Œå¾®è°ƒå¯èƒ½æ˜¯ä¸€ç§æœ‰å‰æ™¯çš„ç­–ç•¥ã€‚
- en: 'Looking ahead, there are several possibilities to extend our current project:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: å±•æœ›æœªæ¥ï¼Œæˆ‘ä»¬å¯ä»¥æ‰©å±•æˆ‘ä»¬å½“å‰çš„é¡¹ç›®ï¼Œæœ‰å‡ ç§å¯èƒ½æ€§ï¼š
- en: '**Better UI design.** For simplicity, we have used Jupyter Notebook to showcase
    the main idea of the dual-chatbot system. We could certainly use more sophisticated
    libraries (e.g., Streamlit) to build a more user-friendly, engaging UI.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ›´å¥½çš„ UI è®¾è®¡ã€‚** ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† Jupyter Notebook æ¥å±•ç¤ºåŒèŠå¤©æœºå™¨äººç³»ç»Ÿçš„ä¸»è¦ç†å¿µã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„åº“ï¼ˆä¾‹å¦‚
    Streamlitï¼‰æ¥æ„å»ºæ›´ç”¨æˆ·å‹å¥½ã€äº’åŠ¨æ€§æ›´å¼ºçš„ UIã€‚'
- en: '**Multimodal capability.** For example, text-to-speech (TTS) techniques can
    be used to create audio over the generated script. This could be beneficial to
    users as they can keep consuming the content during a commute, exercising, or
    other activities where reading isnâ€™t convenient.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¤šæ¨¡æ€èƒ½åŠ›ã€‚** ä¾‹å¦‚ï¼Œå¯ä»¥ä½¿ç”¨æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æŠ€æœ¯ä¸ºç”Ÿæˆçš„è„šæœ¬åˆ›å»ºéŸ³é¢‘ã€‚è¿™å¯¹ç”¨æˆ·å¾ˆæœ‰å¸®åŠ©ï¼Œå› ä¸ºä»–ä»¬å¯ä»¥åœ¨é€šå‹¤ã€é”»ç‚¼æˆ–å…¶ä»–é˜…è¯»ä¸ä¾¿çš„æ´»åŠ¨ä¸­ç»§ç»­æ¶ˆè€—å†…å®¹ã€‚'
- en: '**Accessing external databases.** It would be great if the dual-chatbot system
    could have access to larger external repositories of research papers, such that
    the author bot could offer comparison analysis with respect to the latest developments
    in the fields of interest, thereby synthesizing insights across multiple papers.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è®¿é—®å¤–éƒ¨æ•°æ®åº“ã€‚** å¦‚æœåŒèŠå¤©æœºå™¨äººç³»ç»Ÿèƒ½å¤Ÿè®¿é—®æ›´å¤§çš„å¤–éƒ¨ç ”ç©¶è®ºæ–‡åº“ï¼Œé‚£å°†æ˜¯éå¸¸æ£’çš„ï¼Œè¿™æ ·ä½œè€…æœºå™¨äººå¯ä»¥æä¾›ä¸é¢†åŸŸå†…æœ€æ–°å‘å±•çš„æ¯”è¾ƒåˆ†æï¼Œä»è€Œç»¼åˆå¤šä¸ªè®ºæ–‡çš„è§è§£ã€‚'
- en: '**Generating literature review.** Since the generated interview scripts can
    serve as condensed yet richer (than paper abstracts) versions of the full papers,
    we could first accumulate the scripts for a variety of papers in a specific research
    field, and then request a separate LLM to generate comprehensive reviews of that
    field, based on analyzing the accumulated interview scripts. This feature would
    be especially valuable for researchers when they are initiating a new research
    project or a literature review paper.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç”Ÿæˆæ–‡çŒ®ç»¼è¿°ã€‚** ç”±äºç”Ÿæˆçš„è®¿è°ˆè„šæœ¬å¯ä»¥ä½œä¸ºæ¯”è®ºæ–‡æ‘˜è¦æ›´ä¸°å¯Œçš„è®ºæ–‡ç²¾åï¼Œæˆ‘ä»¬å¯ä»¥é¦–å…ˆæ”¶é›†ç‰¹å®šç ”ç©¶é¢†åŸŸä¸­å„ç§è®ºæ–‡çš„è„šæœ¬ï¼Œç„¶åè¯·æ±‚ä¸€ä¸ªå•ç‹¬çš„è¯­è¨€æ¨¡å‹åŸºäºåˆ†æè¿™äº›ç§¯ç´¯çš„è®¿è°ˆè„šæœ¬ç”Ÿæˆè¯¥é¢†åŸŸçš„ç»¼åˆè¯„è¿°ã€‚è¿™ä¸€åŠŸèƒ½å¯¹äºç ”ç©¶äººå‘˜åœ¨å¯åŠ¨æ–°çš„ç ”ç©¶é¡¹ç›®æˆ–æ–‡çŒ®ç»¼è¿°è®ºæ–‡æ—¶å°¤å…¶æœ‰ä»·å€¼ã€‚'
- en: What a fruitful Sprint we had! If you find my content useful, you could buy
    me a coffee [here](https://www.buymeacoffee.com/Shuaiguo09f) ğŸ¤— Thank you very
    much for your support! As always, you can find the companion notebook with full
    code [here](https://github.com/ShuaiGuo16/research_paper_digesting_with_dual_chatbot)
    ğŸ’» Looking forward to sharing with you more exciting LLM projects. Stay tuned!
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„å†²åˆºçœŸæ˜¯å¯Œæœ‰æˆæ•ˆï¼å¦‚æœä½ è§‰å¾—æˆ‘çš„å†…å®¹æœ‰ç”¨ï¼Œå¯ä»¥åœ¨[è¿™é‡Œ](https://www.buymeacoffee.com/Shuaiguo09f)è¯·æˆ‘å–æ¯å’–å•¡ğŸ¤—
    éå¸¸æ„Ÿè°¢ä½ çš„æ”¯æŒï¼å’Œå¾€å¸¸ä¸€æ ·ï¼Œä½ å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/ShuaiGuo16/research_paper_digesting_with_dual_chatbot)æ‰¾åˆ°åŒ…å«å®Œæ•´ä»£ç çš„é…å¥—ç¬”è®°æœ¬ğŸ’»
    æœŸå¾…ä¸ä½ åˆ†äº«æ›´å¤šä»¤äººå…´å¥‹çš„LLMé¡¹ç›®ã€‚æ•¬è¯·å…³æ³¨ï¼
