- en: Developing an Autonomous Dual-Chatbot System for Research Paper Digesting
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/developing-an-autonomous-dual-chatbot-system-for-research-paper-digesting-ea46943e9343](https://towardsdatascience.com/developing-an-autonomous-dual-chatbot-system-for-research-paper-digesting-ea46943e9343)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A project walk-through for the concept, implementation, and demonstration
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://shuaiguo.medium.com/?source=post_page-----ea46943e9343--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----ea46943e9343--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ea46943e9343--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ea46943e9343--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----ea46943e9343--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ea46943e9343--------------------------------)
    ·28 min read·Aug 14, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ccf2282defca7f209f1bce829d03c604.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
- en: Photo by [Aaron Burden](https://unsplash.com/@aaronburden?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: As a researcher, reading and understanding scientific papers has always been
    a crucial part of my daily routine. I still remember the tricks I learned in grad
    school for how to digest a paper efficiently. However, with countless research
    papers being published every day, I felt overwhelmed to keep up to date with the
    latest research trends and insights. The old tricks I learned can only help so
    much.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Things start to change with the recent development of large language models
    (LLMs). Thanks to their remarkable contextual understanding capability, LLMs can
    fairly accurately identify relevant information from the user-provided documents
    and generate high-quality answers to the user’s questions about the documents.
    A myriad of document Q&A tools have been developed based on this idea and some
    tools are designed specifically to assist researchers in understanding complex
    papers within a relatively short amount of time.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: 'Although it’s definitely a step forward, I noticed some friction points when
    using those tools. One of the main issues I had is prompt engineering. Since the
    quality of LLM responses depends heavily on the quality of my questions, I often
    found myself spending quite some time crafting the “perfect” question. This is
    especially challenging when reading papers in unfamiliar research fields: oftentimes
    I simply don’t know what questions to ask.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: 'This experience got me thinking: is it possible to develop a system that can
    automate the process of Q&A about research papers? A system that can distill key
    points from a paper more efficiently and autonomously?'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这个经历让我思考：是否可以开发一个系统来自动化处理研究论文的问答过程？一个能够更高效且自主地提炼论文关键点的系统？
- en: 'Previously, I worked on [a project where I developed a dual-chatbot system
    for language learning](https://medium.com/towards-data-science/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd).
    The concept there was simple yet effective: by letting two chatbots chat in a
    user-specified foreign language, the user could learn the practical usage of the
    language by simply observing the conversation. The success of this project led
    me to an interesting thought: could a similar dual-chatbot system be useful for
    understanding research papers as well?'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我曾做过 [一个我为语言学习开发双聊天机器人系统的项目](https://medium.com/towards-data-science/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd)。那里的概念简单而有效：通过让两个聊天机器人用用户指定的外语聊天，用户可以通过观察对话来学习语言的实际使用。这个项目的成功让我产生了一个有趣的想法：类似的双聊天机器人系统是否也有助于理解研究论文呢？
- en: So, in this blog post, we are going to bring this idea to life. Specifically,
    we will walk through the process of developing a dual-chatbot system that can
    digest research papers in an autonomous manner.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这篇博客中，我们将把这个想法变为现实。具体来说，我们将演示开发一个可以自主处理研究论文的双聊天机器人系统的过程。
- en: 'To make this journey a fun experience, we are going to approach it as a software
    project and run a Sprint: we will begin with "ideation", where we introduce the
    concept of leveraging a dual-chatbot system to tackle our problem. Then comes
    the “Sprint execution”, during which we’ll incrementally build the features of
    our design. Lastly, we will show our demo in the “Sprint review” and reflect on
    the learnings and future opportunities in the “Sprint Retrospective”.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让这次旅程变得有趣，我们将其视为一个软件项目并进行一个Sprint：我们将从“创意阶段”开始，介绍利用双聊天机器人系统来解决我们的问题的概念。接下来是“Sprint
    执行阶段”，在此期间，我们将逐步构建设计的功能。最后，我们将在“Sprint 回顾阶段”展示我们的演示，并在“Sprint 反思阶段”中反思所学到的内容和未来的机会。
- en: Ready to run the Sprint? let’s get started!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好进行Sprint了吗？让我们开始吧！
- en: This is the 2nd blog on my series of LLM projects. The 1st one is [Building
    an AI-Powered Language Learning App](/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd),
    and the 3rd one is [Training Soft Skills in Data Science with Real-Life Simulations](/training-soft-skills-in-data-science-with-real-life-simulations-a-role-playing-dual-chatbot-c80dec3dd08c).
    Feel free to check them out!
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这是我系列LLM项目的第二篇博客。第一篇是 [构建一个AI驱动的语言学习应用](/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd)，第三篇是
    [通过真实模拟训练数据科学软技能](/training-soft-skills-in-data-science-with-real-life-simulations-a-role-playing-dual-chatbot-c80dec3dd08c)。欢迎查看！
- en: '**Table of Content**'
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**目录**'
- en: '**·** [**1\. Concept: dual-chatbot system**](#87c3) **·** [**2\. Sprint Planning:
    what we want to build**](#08c8) **·** [**3\. Feature 1: Document Embedding Engine**](#c8d4)
    **·** [**4\. Feature 2: Dual-Chatbot System**](#bd53)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**·** [**1\. 概念：双聊天机器人系统**](#87c3) **·** [**2\. Sprint 计划：我们想要构建什么**](#08c8)
    **·** [**3\. 功能1：文档嵌入引擎**](#c8d4) **·** [**4\. 功能2：双聊天机器人系统**](#bd53)'
- en: ∘ [4.1 Abstract chatbot class](#0806)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [4.1 抽象聊天机器人类](#0806)
- en: ∘ [4.2 Journalist chatbot class](#0a1e)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [4.2 记者聊天机器人类](#0a1e)
- en: ∘ [4.3 Author bot class](#55dc)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [4.3 作者机器人类](#55dc)
- en: '∘ [4.4 Quick test: the interview](#2a76)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [4.4 快速测试：面试](#2a76)
- en: '**·** [**5\. Feature 3: User Interaction**](#3784)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**·** [**5\. 功能3：用户交互**](#3784)'
- en: ∘ [5.1 Creating the chat environment (in Jupyter Notebook)](#1372)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [5.1 创建聊天环境（在Jupyter Notebook中）](#1372)
- en: ∘ [5.2 Implementing PDF highlighting functionality](#e992)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [5.2 实现PDF高亮功能](#e992)
- en: ∘ [5.3 Allowing user input for questions](#b3df)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [5.3 允许用户输入问题](#b3df)
- en: ∘ [5.4 Allowing downloading the generated script](#aff5)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [5.4 允许下载生成的脚本](#aff5)
- en: '**·** [**6\. Sprint Review: show the demo!**](#a1e2) **·** [**7\. Sprint Retrospective**](#0d19)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**·** [**6\. Sprint 回顾：展示演示！**](#a1e2) **·** [**7\. Sprint 反思**](#0d19)'
- en: '1\. Concept: dual-chatbot system'
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 概念：双聊天机器人系统
- en: The foundation of our solution lies in the concept of a dual-chatbot system.
    As its name implies, this system involves two chatbots (powered by large language
    models) engaging in an autonomous dialogue. By specifying a high-level task description
    and assigning relevant roles to the chatbots, users can guide the conversation
    toward their desired direction.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们解决方案的基础在于双机器人系统的概念。顾名思义，这个系统涉及两个由大型语言模型驱动的聊天机器人进行自主对话。通过指定一个高级任务描述并分配相关角色给聊天机器人，用户可以引导对话朝着他们期望的方向发展。
- en: 'To give a concrete example: [in my previous project where a dual-chatbot is
    developed for assisting language learning](https://medium.com/towards-data-science/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd),
    the learner (user) can specify a real-life scenario (e.g., dining at a restaurant)
    and assign roles for chatbots to play (e.g., bot 1 as the waitstaff and bot 2
    as the customer), the two bots would then simulate a conversation in the user’s
    chosen foreign language, mimicking the interaction between the assigned roles
    in the given scenario. This allows an on-demand generation of fresh, scenario-specific
    language learning materials, therefore helping users better understand language
    usage in real-life situations.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 举一个具体的例子：[在我之前的项目中，我们开发了一个双机器人系统来辅助语言学习](https://medium.com/towards-data-science/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd)，学习者（用户）可以指定一个现实生活场景（例如，在餐厅用餐），并为聊天机器人分配角色（例如，机器人1作为服务员，机器人2作为顾客），然后两个机器人会模拟用户选择的外语对话，模仿在给定场景中分配角色之间的互动。这允许按需生成新鲜、特定场景的语言学习材料，从而帮助用户更好地理解现实生活中的语言使用。
- en: So, how do we adapt this concept for the autonomous digestion of research papers?
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何将这个概念适应于研究论文的自动消化呢？
- en: The key lies in the **role assignment**. More specifically, one bot could take
    the role of a “**journalist**”, whose main task is to conduct an interview to
    understand and extract key insights from a research paper. Meanwhile, the other
    bot could play the role of an “**author**”, who has full access to the research
    paper and is tasked with providing comprehensive answers to the “journalist” bot’s
    queries.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 关键在于**角色分配**。更具体地说，一个机器人可以担任“**记者**”的角色，其主要任务是进行采访以理解和提取研究论文中的关键见解。与此同时，另一个机器人可以扮演“**作者**”的角色，拥有对研究论文的全面访问权，负责回答“记者”机器人的提问。
- en: When it comes to interaction, the journalist bot will initiate the dialogue
    and kicks off the interview process. The author bot will then serve as a conventional
    document Q&A engine and answer the journalist’s questions based on the relevant
    context of the research paper. The journalist bot then follows up with additional
    questions for further clarification. Through this iterative Q&A process, the key
    contributions, methodology, and findings of the research paper could be automatically
    extracted.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈到互动时，记者机器人将启动对话并开始采访过程。然后，作者机器人将作为传统的文档问答引擎，根据研究论文的相关背景回答记者的问题。记者机器人随后会提出更多问题以进一步澄清。通过这种反复问答的过程，研究论文的关键贡献、方法论和发现可以被自动提取。
- en: '![](../Images/5bb2d4d17a40f755bd0509a680ddc114.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5bb2d4d17a40f755bd0509a680ddc114.png)'
- en: An illustration of the workflow of the dual-chatbot system. (Image by author)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 双机器人系统的工作流程示意图。（图片来源：作者）
- en: 'This dual-chatbot system described above introduces a shift from the traditional
    user-chatbot interaction: instead of users thinking about the right questions
    to ask the LLM model, the introduced “journalist” bot will automatically come
    up with suitable questions on the user’s behalf. This approach could bypass the
    need for users to craft appropriate prompts, thus significantly reducing the users’
    cognitive load. This is especially useful when delving into unfamiliar research
    fields. Overall, the dual-chatbot system may constitute a more user-friendly,
    efficient, and engaging method for distilling complex scientific research papers.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 上述双机器人系统引入了一种从传统用户-聊天机器人互动的转变：用户不再需要思考向LLM模型提出的正确问题，介绍的“记者”机器人将自动为用户提出合适的问题。这种方法可以绕过用户设计适当提示的需要，从而显著降低用户的认知负担。这在*深入不熟悉的研究领域*时尤其有用。总体而言，双机器人系统可能构成一种更用户友好、高效且引人入胜的方法，用于提炼复杂的科学研究论文。
- en: Next up, let’s move to Sprint planning and define several user stories we would
    like to address in this project.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们进行Sprint规划，并定义我们希望在这个项目中解决的几个用户故事。
- en: '2\. Sprint Planning: what we want to build'
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 冲刺规划：我们想要构建的内容
- en: With the concept in place, it’s time to plan our current Sprint. In line with
    the common practice of Agile development, our Sprint planning will evolve around
    user stories.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 确定概念后，接下来是规划我们当前的冲刺。根据敏捷开发的常规做法，我们的冲刺规划将围绕用户故事展开。
- en: In Agile development, **a user story** is a concise, informal, and simple description
    of a feature or functionality from an end-user perspective. It is a common practice
    used in Agile development to define and communicate requirements in a way that
    is understandable and actionable for the development team.
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在敏捷开发中，**用户故事**是从最终用户的角度对功能或特性的简洁、非正式和简单的描述。这是一种在敏捷开发中常用的做法，用于以一种可理解和可操作的方式定义和传达需求。
- en: '🎯 **User story 1: document embedding**'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '🎯 **用户故事 1: 文档嵌入**'
- en: “As a user, I want to input research papers in PDF format into the system, and
    I want the system to convert my input paper into a **machine-readable format**
    so that the dual-chatbot system can understand and analyze it efficiently.” (Generated
    by GPT-4)
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “作为用户，我希望将 PDF 格式的研究论文输入系统，并希望系统将我的输入论文转换成**机器可读格式**，以便双机器人系统能够高效地理解和分析它。”（由
    GPT-4 生成）
- en: This user story focuses on data ingestion. Essentially, we need to build a data-processing
    pipeline that includes document loading, splitting, embedding creation, and embedding
    storage.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这个用户故事集中在数据摄取上。本质上，我们需要构建一个数据处理管道，包括文档加载、拆分、嵌入创建和嵌入存储。
- en: Here, “embeddings” refer to the numerical representations of the text data.
    By creating a numerical representation of each part of a research paper, the author
    bot can better understand the semantic meaning of the research paper and be able
    to accurately answer the journalist bot’s questions.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，“嵌入”指的是文本数据的数值表示。通过创建研究论文每部分的数值表示，作者机器人可以更好地理解研究论文的语义含义，并能够准确回答记者机器人的问题。
- en: Additionally, we need to have a database to store the computed embeddings of
    the research paper. This database needs to be readily accessible by the author
    bot to facilitate fast and accurate answer generation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还需要一个数据库来存储研究论文计算出的嵌入。这一数据库需要能够被作者机器人快速访问，以便生成快速而准确的回答。
- en: In section 3, we will address this user story by leveraging the **OpenAI Embeddings
    API** along with the meta’s **FAISS vector store**.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 3 节中，我们将利用**OpenAI Embeddings API**和 Meta 的**FAISS 向量存储**来解决这个用户故事。
- en: '🎯 **User story 2: dual-chatbot**'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '🎯 **用户故事 2: 双机器人**'
- en: “As a user, I want to observe an autonomous conversation between two chatbots
    — one playing the role of a ‘journalist’ asking questions and the other playing
    the role of an ‘author’ answering them, derived from the contents of the research
    paper. This will help me understand the paper’s key points without needing to
    read it in its entirety or craft my own questions.” (Generated by GPT-4)
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “作为用户，我希望观察两个聊天机器人之间的自主对话——一个扮演‘记者’角色提问，另一个扮演‘作者’角色回答，这些对话来源于研究论文的内容。这将帮助我理解论文的关键点，而无需完整阅读或自己提出问题。”（由
    GPT-4 生成）
- en: 'This user story represents the cornerstone of our project: the development
    of the dual-chatbot system. As discussed in the “Concept” section, we need to
    construct two types of chatbot classes: one that is able to develop a series of
    questions to query the details of the paper (i.e., the journalist bot), and another
    that can leverage document embeddings to generate comprehensive answers to these
    questions (i.e., the author bot).'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这个用户故事代表了我们项目的基石：双机器人系统的开发。如“概念”部分所述，我们需要构建两种类型的聊天机器人类：一种能够提出一系列问题来查询论文的详细信息（即记者机器人），另一种能够利用文档嵌入生成对这些问题的全面回答（即作者机器人）。
- en: In section 4, we will focus on addressing this user story by using the **LangChain**
    framework.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 4 节中，我们将通过使用**LangChain**框架来解决这个用户故事。
- en: '🎯 **User story 3: chat environment**'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '🎯 **用户故事 3: 聊天环境**'
- en: “As a user, I want an intuitive chat interface where I can watch the chatbots’
    conversation unfold in real-time.” (Generated by GPT-4)
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “作为用户，我希望有一个直观的聊天界面，在这里我可以实时观察聊天机器人的对话展开。”（由 GPT-4 生成）
- en: The goal of this user story is to build a chat environment where users can view
    the generated dialogue between the journalist and author bots. In the spirit of
    MVP (minimum viable product), we will use simple **Jupyter widgets** to demonstrate
    the chat environment in section 5.1.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这个用户故事的目标是构建一个聊天环境，用户可以查看记者和作者机器人之间生成的对话。为了符合MVP（最简可行产品）的精神，我们将在5.1节使用简单的**Jupyter小部件**来演示聊天环境。
- en: '🎯 **User story 4: PDF highlighting**'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '🎯 **用户故事 4: PDF高亮**'
- en: “As a user, I want to have the corresponding parts in the original research
    paper highlighted based on the chatbot’s discussion. This will help me to quickly
    locate the sources of the information discussed during the conversation.” (Generated
    by GPT-4)
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “作为用户，我希望能够根据聊天机器人的讨论在原研究论文中突出显示相关部分。这将帮助我快速找到对话中讨论的信息的来源。”（由GPT-4生成）
- en: This user story focuses on providing the users with the traceability of the
    Q&A. For every answer generated by the author bot, it is natural for users to
    understand precisely where the discussed information is originating from in the
    research paper. Not only does this feature enhances the transparency of our dual-chatbot
    system, but it also allows for a more interactive and engaging user experience.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这个用户故事着重于为用户提供问答的可追溯性。对于每一个由作者机器人生成的回答，用户可以自然地理解讨论的信息源自研究论文的确切位置。这个功能不仅提升了我们双聊天机器人系统的透明度，还使得用户体验更加互动和引人入胜。
- en: In section 5.2, we will leverage LangChain’s **conversational retrieval chain**
    to return the sources the author bot used to generate the answers and the **PyMuPDF**
    library to highlight the corresponding texts in the original PDF.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在5.2节，我们将利用LangChain的**对话检索链**来返回作者机器人用于生成回答的来源，并使用**PyMuPDF**库来突出显示原PDF中的相关文本。
- en: '🎯 **User story 5: user input**'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '🎯 **用户故事 5: 用户输入**'
- en: “As a user, I want to be able to intervene and ask my own questions in the midst
    of the chatbot’s conversation, this way I can direct the conversation and extract
    the information I need from the paper.” (Generated by GPT-4)
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “作为用户，我希望能够在聊天机器人的对话过程中进行干预并提出自己的问题，这样我可以引导对话并从论文中提取我需要的信息。”（由GPT-4生成）
- en: This user story focuses on the need for user participation. While our target
    dual-chatbot system is designed to be autonomous, we also need to provide the
    option for users to ask their own questions. This feature ensures that the conversation
    does not just go in a direction set by the bots, but it can be guided by the user’s
    own curiosity and interests. Also, it is very likely that users may get inspired
    by watching the first rounds of conversation, and would like to ask follow-up
    questions or dig deeper into certain aspects that are of particular interest to
    them. All these underline the importance of user intervention.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这个用户故事关注于用户参与的需求。虽然我们的目标双聊天机器人系统旨在自主运作，但我们仍需提供用户提出自己问题的选项。这个功能确保了对话不会仅仅按照机器人的设定方向进行，而是可以由用户的好奇心和兴趣来引导。此外，用户可能会受到第一次对话的启发，想要提出后续问题或深入挖掘他们特别感兴趣的某些方面。这些都强调了用户干预的重要性。
- en: In section 5.3, we will address this user story by upgrading our user interface
    in Jupyter Notebook.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在5.3节，我们将通过升级Jupyter Notebook中的用户界面来处理这个用户故事。
- en: '🎯 **User story 6: download scripts**'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '🎯 **用户故事 6: 下载脚本**'
- en: “As a user, I want to be able to download a transcript of the chatbot conversation.
    This will allow me to review the key points offline or share the information with
    my colleagues.” (Generated by GPT-4)
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “作为用户，我希望能够下载聊天机器人对话的记录。这将允许我离线查看要点或与我的同事分享信息。”（由GPT-4生成）
- en: This user story focuses on the accessibility and shareability of the generated
    content. Although users can view the conversation in a dedicated chat environment,
    it is beneficial to provide users with a record of the discussion that they can
    review later and share with others.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这个用户故事关注于生成内容的可访问性和可分享性。虽然用户可以在专用的聊天环境中查看对话，但提供一个可以供用户后续查看和分享的讨论记录是很有益的。
- en: In section 5.4, we will use the **PDFDocument** libraryto convert the generated
    script into a PDF file for users to download.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在5.4节，我们将使用**PDFDocument**库将生成的脚本转换为PDF文件，以供用户下载。
- en: So much for the planning, time to get to work!
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 规划到此为止，现在是时候开始工作了！
- en: '![](../Images/1aa4c455b93f11b7eb1154eaf4fd48c5.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1aa4c455b93f11b7eb1154eaf4fd48c5.png)'
- en: Our planned user stories. (Image by author)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们规划的用户故事。（作者提供的图片）
- en: '3\. Feature 1: Document Embedding Engine'
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 特性 1：文档嵌入引擎
- en: 'Let’s implement the first feature of our paper digesting app: the document
    embedding engine. Here, we will build a data-processing class with the functionality
    of document loading, splitting, embedding creation, and storage. This addresses
    our first user story:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们实现我们论文消化应用的第一个功能：文档嵌入引擎。在这里，我们将构建一个数据处理类，具备文档加载、拆分、嵌入创建和存储的功能。这解决了我们的第一个用户故事：
- en: “As a user, I want to input research papers in PDF format into the system, and
    I want the system to convert my input paper into a **machine-readable format**
    so that the dual-chatbot system can understand and analyze it efficiently.” (Generated
    by GPT-4)
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “作为用户，我希望将 PDF 格式的研究论文输入系统，并希望系统将我的输入论文转换为**机器可读格式**，以便双重聊天机器人系统能够有效理解和分析。”（由
    GPT-4 生成）
- en: 'We start by creating a `embedding_engine.py` file and import necessary libraries:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先创建一个 `embedding_engine.py` 文件，并导入必要的库：
- en: '[PRE0]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We then instantiate an embedding model by using OpenAI embeddings API:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用 OpenAI 嵌入 API 实例化了一个嵌入模型：
- en: '[PRE1]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, we define the function for loading and processing PDF files:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义了加载和处理 PDF 文件的函数：
- en: '[PRE2]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here, we have used `PyMuPDFLoader` to load the PDF file, which, under the hood,
    leverages the PyMuPDF library to parse the PDF file. The returned `documents`
    variable is a list of LangChain `Document()` objects. Each `Document()` object
    corresponds to one page of the original PDF, with the page content stored in the
    `page_content` key and associated metadata (e.g., page number, etc.) stored in
    the `metadata` key.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用了 `PyMuPDFLoader` 来加载 PDF 文件，该工具在底层利用 PyMuPDF 库解析 PDF 文件。返回的 `documents`
    变量是 LangChain `Document()` 对象的列表。每个 `Document()` 对象对应原始 PDF 的一页，页面内容存储在 `page_content`
    键中，相关的元数据（例如，页码等）存储在 `metadata` 键中。
- en: After parsing the loaded PDF, we used `RecursiveCharacterTextSplitter` from
    LangChain to split the original PDF into multiple smaller chunks. Since the author
    bot will later use relevant texts from the PDF to answer questions, creating small
    chunks of text can not only help the author bot to focus on specific details to
    answer the question, but also ensure that the context provided to the author bot
    will not exceed the token limit of the employed LLM.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 解析加载的 PDF 后，我们使用了 LangChain 的 `RecursiveCharacterTextSplitter` 将原始 PDF 拆分成多个较小的块。由于作者机器人稍后将使用
    PDF 中的相关文本来回答问题，创建小块文本不仅可以帮助作者机器人专注于具体细节以回答问题，还可以确保提供给作者机器人的上下文不会超出所用 LLM 的令牌限制。
- en: 'Next, we set up the vector store to manage the text embedding vectors:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们设置向量存储以管理文本嵌入向量：
- en: '[PRE3]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Here, we used Facebook AI Similarity Search (FAISS) library to serve as our
    vector store, which takes the loaded PDF and the embedding engine as the inputs
    to its constructor. The created `self.vectorstore` holds the embedding vectors
    of individual PDF chunks we created earlier. At query time, it will invoke the
    embedding engine to embed the question and then retrieve the embedding vectors
    that are ‘most similar’ to the embedded query. The texts that correspond to the
    most similar embedding vectors will be fed to the author bot as the context to
    assist its answer generation. This process is known as **vector search** and forms
    the backbone for document Q&A.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用了 Facebook AI 相似度搜索（FAISS）库作为我们的向量存储，它接受加载的 PDF 和嵌入引擎作为构造函数的输入。创建的 `self.vectorstore`
    存储了我们之前创建的每个 PDF 块的嵌入向量。在查询时，它将调用嵌入引擎来嵌入问题，然后检索与嵌入查询“最相似”的嵌入向量。与最相似嵌入向量对应的文本将作为上下文输入到作者机器人，以帮助生成答案。这个过程被称为**向量搜索**，是文档问答的核心。
- en: Finally, we create a helper function to generate a short summary of the paper.
    This will be useful later for setting the stage for the journalist bot.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们创建了一个辅助函数来生成论文的简短摘要。这将在稍后为记者机器人设定场景时非常有用。
- en: '[PRE4]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: we resort to LLMs to create the summary. Technically speaking, we can achieve
    that goal by using LangChain’s `load_summarize_chain`, which takes the LLM model
    and the summarization method as inputs.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们求助于 LLM 来创建摘要。从技术上讲，我们可以通过使用 LangChain 的 `load_summarize_chain` 来实现这一目标，该方法接受
    LLM 模型和总结方法作为输入。
- en: In terms of the summarization method, here, we have used the **stuff** method,
    which simply “stuff” all the documents into a single context and prompts the LLM
    to generate the summary. For other more advanced methods, please refer to the
    [official page](https://python.langchain.com/docs/use_cases/summarization) of
    LangChain.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在摘要方法方面，我们使用了**stuff**方法，它简单地将所有文档“填充”到一个上下文中，并提示LLM生成摘要。有关其他更高级的方法，请参阅LangChain的[官方页面](https://python.langchain.com/docs/use_cases/summarization)。
- en: 'Great! Now that we have developed the `Embedder` class to handle the document
    loading, splitting, as well as embedding creation and storage, we can move on
    to the core of our app: the dual-chatbot system.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！现在我们已经开发了`Embedder`类来处理文档加载、拆分以及嵌入创建和存储，我们可以转到我们应用的核心部分：双聊天机器人系统。
- en: '4\. Feature 2: Dual-Chatbot System'
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4. 功能 2：双聊天机器人系统
- en: 'In this section, we address our second user story:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们处理我们的第二个用户故事：
- en: “As a user, I want to observe an autonomous conversation between two chatbots
    — one playing the role of a ‘journalist’ asking questions and the other playing
    the role of an ‘author’ answering them, derived from the contents of the research
    paper. This will help me understand the paper’s key points without needing to
    read it in its entirety or craft my own questions.” (Generated by GPT-4)
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “作为用户，我想观察两个聊天机器人之间的自主对话——一个扮演‘记者’提问，另一个扮演‘作者’回答，问题和回答都来自研究论文的内容。这将帮助我理解论文的关键点，而无需完整阅读论文或自己提出问题。”（由GPT-4生成）
- en: We will start by creating an abstract base class for defining the common behaviors
    of the chatbots. Afterward, we will develop the individual journalist bot and
    the author bot that inherit from the chatbot base class. We put all the class
    definitions in `chatbot.py`.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先创建一个抽象基类，用于定义聊天机器人的共同行为。之后，我们将开发继承自聊天机器人基类的记者机器人和作者机器人。我们将所有类定义放在`chatbot.py`中。
- en: 4.1 Abstract chatbot class
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 抽象聊天机器人类
- en: 'Since our journalist bot and the author bot share a lot of similarities (as
    they are all role-playing bots), it is a good practice to encapsulate the definition
    of their shared behaviors within an abstract base class:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的记者机器人和作者机器人有很多相似之处（因为它们都是角色扮演机器人），将它们共享的行为定义封装在一个抽象基类中是一个好习惯：
- en: '[PRE5]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We defined three common methods:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了三个常用方法：
- en: '`instruct`: this method is used to set up the chatbot and attach memory to
    it.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`instruct`：这个方法用于设置聊天机器人并将内存附加到它上面。'
- en: '`step`: this method is used to feed input to the chatbot and receive the bot’s
    response.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`step`：这个方法用于向聊天机器人提供输入并接收机器人的回应。'
- en: '`specify_system_message`: this method is used to give the chatbot specific
    instructions regarding how it should behave during the conversation.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`specify_system_message`：这个方法用于给聊天机器人提供具体的指令，说明它在对话中应该如何行为。'
- en: With the chatbot template in place, we are ready to create two specific chatbot
    roles, i.e., the journalist bot and the author bot.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 有了聊天机器人模板，我们准备创建两个具体的聊天机器人角色，即记者机器人和作者机器人。
- en: 4.2 Journalist chatbot class
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 记者聊天机器人类
- en: The journalist bot’s role is to interview the author bot and extract key insights
    from a research paper. With that in mind, let’s fill the template methods with
    concrete code.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 记者机器人的角色是采访作者机器人并从研究论文中提取关键见解。考虑到这一点，让我们用具体的代码填充模板方法。
- en: '[PRE6]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In the constructor method, besides specifying a backbone LLM, another important
    component for the journalist bot is the memory object. Memory tracks the conversation
    history and serves as the key to helping the journalist bot avoid repetitive or
    irrelevant questions and generate meaningful follow-up questions. Technically,
    we achieved that by using the `ConversationBufferMemory` provided by LangChain,
    which simply prepends the last few inputs/outputs to the current input of the
    chatbot.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在构造函数方法中，除了指定一个主干LLM，记者机器人另一个重要的组件是内存对象。内存跟踪对话历史，并帮助记者机器人避免重复或无关的问题，并生成有意义的后续问题。从技术上讲，我们通过使用LangChain提供的`ConversationBufferMemory`来实现这一点，它简单地将最后几次输入/输出附加到聊天机器人的当前输入中。
- en: Next, we set up the journalist chatbot by creating a`ConversationChain`, with
    the previously defined backbone LLM, the memory object, as well as the prompt
    for the chatbot. Note that we have also specified `topic` (the paper topic) and
    `abstract` (the paper summary), which will be used later to provide the context
    of the paper to the journalist bot.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们通过创建一个 `ConversationChain` 来设置记者聊天机器人，使用之前定义的骨干 LLM、内存对象以及聊天机器人的提示。请注意，我们还指定了
    `topic`（论文主题）和 `abstract`（论文摘要），这些将在稍后用于向记者机器人提供论文的背景信息。
- en: '[PRE7]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In LangChain, the prompt generation and ingestion for instructing the chatbot
    are handled via different prompt templates. For our current application, the most
    critical piece is setting the `SystemMessagePromptTemplate`, as it allows us to
    give a *high-level purpose* to the journalist bot and also define its desired
    behaviors.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LangChain 中，用于指示聊天机器人的提示生成和接收是通过不同的提示模板处理的。对于我们当前的应用程序，最关键的部分是设置 `SystemMessagePromptTemplate`，因为它允许我们给记者机器人提供
    *高级目的*，并定义其期望的行为。
- en: The followings are the details of the instruction. Note that the instruction/prompt
    is generated and optimized by using ChatGPT (GPT-4). This is beneficial as in
    the current case, the LLM-generated prompts tend to consider more nuances than
    the human-crafted ones. Additionally, generating high-level instructions with
    LLM represents a more scalable solution for adapting the systems to other scenarios
    beyond “journalist-author” interactions.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是指令的详细信息。请注意，指令/提示是通过 ChatGPT (GPT-4) 生成和优化的。这是有利的，因为在当前情况下，LLM 生成的提示往往比人工编写的提示考虑更多细节。此外，使用
    LLM 生成高级指令代表了一种更具可扩展性的解决方案，可以将系统适应到“记者-作者”互动之外的其他情境。
- en: '[PRE8]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Here, we provided the journalist bot with the paper’s research domain and abstract
    to serve as the base for initial questions. This mirrors the real-world scenario
    where a journalist initially only knows a little about the paper and needs to
    ask questions to gather more information.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们为记者机器人提供了论文的研究领域和摘要，作为初始问题的基础。这反映了现实世界中记者最初对论文了解不多，需要通过提问来获取更多信息的情境。
- en: 'Finally, we need a `step` method to interact with the journalist bot:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要一个 `step` 方法来与记者机器人互动：
- en: '[PRE9]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In this case, the input prompt will be the author bot’s answer to the journalist
    bot’s previous question. If the conversation has not started yet, the input prompt
    will simply be “Start the conversation”, to prompt the journalist bot to start
    the interview.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，输入提示将是作者机器人对记者机器人上一个问题的回答。如果对话尚未开始，输入提示将简单为“开始对话”，以提示记者机器人启动采访。
- en: That’s it for the journalist bot. Let’s now turn to the author bot.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是记者机器人的全部内容。现在让我们转向作者机器人。
- en: 4.3 Author bot class
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3 作者机器人类
- en: 'The author bot’s role is to answer questions raised by the journalist bot based
    on the research paper. Here is the constructor method for the author bot:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 作者机器人的角色是根据研究论文回答记者机器人提出的问题。以下是作者机器人的构造方法：
- en: '[PRE10]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'There are two things changed here: first of all, unlike the journalist bot,
    the author bot should be able to access the full paper. Therefore, the vector
    store we created earlier needs to be provided to the constructor. Also, note that
    we are not using the memory object (e.g., `ConversationBufferMemory`) to track
    chat history anymore. Instead, we will simply use a list to store the history
    and later pass it explicitly to the author bot. Each element of the list will
    be a tuple of (query, answer). Both ways of maintaining conversation history are
    supported in LangChain.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有两点变化：首先，与记者机器人不同，作者机器人应该能够访问完整的论文。因此，我们之前创建的向量存储需要提供给构造函数。另外，请注意，我们不再使用内存对象（例如`ConversationBufferMemory`）来跟踪聊天记录。相反，我们将简单地使用一个列表来存储历史记录，并在之后明确传递给作者机器人。列表的每个元素将是一个
    (query, answer) 的元组。在 LangChain 中，两种维护对话历史的方法都被支持。
- en: Next, we set up the conversation chain for the author bot.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们为作者机器人设置对话链。
- en: '[PRE11]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Since the author bot needs to answer questions by first retrieving relevant
    context, we adopted a `ConversationalRetrievalChain`. To quote from the official
    document of LangChain:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 由于作者机器人需要通过首先检索相关背景来回答问题，我们采用了 `ConversationalRetrievalChain`。引用 LangChain 的官方文档：
- en: '**ConversationalRetrievalChain** first combines the chat history (either explicitly
    passed in or retrieved from the provided memory) and the query into a standalone
    question, then looks up relevant documents from the retriever, and finally passes
    those documents and the query to a question answering chain to return a response.'
  id: totrans-122
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**对话检索链**首先将聊天记录（无论是明确传递的还是从提供的记忆中检索到的）和查询合并成一个独立的问题，然后从检索器中查找相关文档，最后将这些文档和查询传递给问题回答链以返回响应。'
- en: Therefore, in addition to the backbone LLM, we also need to supply the chain
    with a vector store. Note that here we specified the number of returned relevant
    documents (PDF chunks) via `search_kwargs`. In general, selecting the right number
    is not a trivial task and deserves careful consideration of balancing accuracy,
    relevance, comprehensiveness, and computational resources. Lastly, we set `return_source_documents`
    to True, which is important for ensuring transparency and traceability in the
    Q&A process.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，除了基础LLM，我们还需要为链提供一个向量存储。请注意，这里我们通过`search_kwargs`指定了返回的相关文档（PDF块）的数量。通常，选择正确的数量不是一项简单的任务，需要仔细考虑准确性、相关性、全面性和计算资源的平衡。最后，我们将`return_source_documents`设置为True，这对确保问答过程中的透明性和可追溯性非常重要。
- en: 'To interact with the author bot:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 要与作者机器人互动：
- en: '[PRE12]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As discussed previously, we explicitly supplied the chat history (a list of
    previous query-answer tuples) to the conversation chain. As a result, we also
    need to manually append the newly obtained query-answer tuple to the chat history.
    For the response, we get not only the answer but also the source documents (PDF
    chunks) used by the author bot to generate the answer, which will be used later
    to highlight the corresponding texts in PDF.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们明确将聊天记录（以前的查询-回答元组列表）提供给对话链。因此，我们还需要手动将新获得的查询-回答元组附加到聊天记录中。对于响应，我们不仅得到答案，还得到作者机器人用于生成答案的源文档（PDF块），这些文档将在稍后用于突出显示PDF中的相应文本。
- en: Finally, we inform the role of the author bot and specify detailed instructions.
    Same as the journalist bot, the instruction/prompt for the author bot is also
    generated and optimized by using ChatGPT (GPT-4).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们告知作者机器人角色并指定详细的指令。与记者机器人一样，作者机器人的指令/提示也由ChatGPT（GPT-4）生成和优化。
- en: '[PRE13]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: That’s it for constructing the author bot.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是构建作者机器人的全部内容。
- en: '4.4 Quick test: the interview'
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.4 快速测试：采访
- en: Time to take two bots for a ride!
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 该是时候带两个机器人“试驾”一下了！
- en: To see if the developed journalist and author bot can engage in meaningful conversation
    toward the goal of digesting the paper, we pick one sample scientific research
    paper and run the test.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检验开发的记者机器人和作者机器人是否能进行有意义的对话以达到消化论文的目的，我们选择了一篇样本科学研究论文并进行测试。
- en: As I was working on physics-informed machine learning recently, here, I picked
    an arXiv paper named “[**Improved Training of Physics-Informed Neural Networks
    with Model Ensembles**](https://arxiv.org/abs/2204.05108)**”** (CC BY 4.0 license)for
    the test.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 最近在研究物理信息机器学习时，我选择了一篇名为“[**改进物理信息神经网络的模型集成训练**](https://arxiv.org/abs/2204.05108)**”**（CC
    BY 4.0 许可）的arXiv论文进行测试。
- en: '[PRE14]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The generated conversation script is shown below. Note that to save space,
    some of the author bot’s answers are not shown in full:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的对话脚本如下所示。请注意，为了节省空间，一些作者机器人的回答未完全显示：
- en: '![](../Images/a6e2d39406c7e6052ecb73d4b7f171fe.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a6e2d39406c7e6052ecb73d4b7f171fe.png)'
- en: The interview between the developed journalist bot and the author bot. (Image
    by author)
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 开发的记者机器人和作者机器人的采访。（图片由作者提供）
- en: Since the author bot only passively answers questions (i.e., a conventional
    Q&A agent), we focus our attention on the behavior of the journalist bot to assess
    if it can properly steer the interview. Here we can see that the journalist bot
    started with a general question about the paper (the motivation), then adapted
    its questions to dig deeper into the methodology of the proposed strategy. Overall,
    the behavior of the developed journalist bot aligns with our expectations and
    it is capable of conducting the interview toward distilling the key points from
    the given paper. Not bad😃
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 由于作者机器人仅被动回答问题（即传统的问答代理），我们将重点放在记者机器人的行为上，以评估它是否能够有效引导采访。在这里，我们可以看到记者机器人首先提出了一个关于论文的一般性问题（动机），然后调整问题以深入探讨提议策略的方法。总体而言，开发的记者机器人的行为符合我们的预期，能够进行采访以提炼出论文的关键点。表现不错😃
- en: '5\. Feature 3: User Interaction'
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. 特性 3：用户互动
- en: In this section, we wrap our previous experiment into a proper user interface.
    Toward that end, we will address three user stories to incrementally build the
    desired features.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将之前的实验封装到一个合适的用户界面中。为此，我们将解决三个用户故事，以逐步构建所需的功能。
- en: 5.1 Creating the chat environment (in Jupyter Notebook)
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 创建聊天环境（在Jupyter Notebook中）
- en: 'Let’s start with the 3rd user story:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从第3个用户故事开始：
- en: “As a user, I want an intuitive chat interface where I can watch the chatbots’
    conversation unfold in real-time.” (Generated by GPT-4)
  id: totrans-143
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “作为用户，我希望有一个直观的聊天界面，可以实时观看聊天机器人的对话展开。”（由GPT-4生成）
- en: To keep things simple, we opt for Jupyter widgets as they allow quickly building
    a chat environment entirely in Jupyter Notebook.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持简单，我们选择Jupyter小部件，因为它们允许在Jupyter Notebook中快速构建整个聊天环境。
- en: 'First, we set up the layout of displaying conversation:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们设置显示对话的布局：
- en: '[PRE15]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We created a button (`bot_ask`) such that when the user clicks it, a callback
    function `bot_ask_clicked` will be invoked and one round of conversation between
    the journalist and author bot will be generated. Afterward, we used the HTML widgets
    to display the conversation as HTML content in the notebook.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个按钮（`bot_ask`），当用户点击它时，会调用一个回调函数`bot_ask_clicked`，并生成一轮记者和作者机器人之间的对话。之后，我们使用HTML小部件在笔记本中以HTML内容的形式显示对话。
- en: The callback function `bot_ask_clicked` is defined below. Besides showing the
    journalist bot’s question and the author bot’s answer, we also indicated the location
    (i.e., page number) of the relevant source texts. This is possible because the
    `step()` method of the author bot also returns the `source` variable, which is
    a list of LangChain `Document` object that contains the page content and its associated
    metadata.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 回调函数`bot_ask_clicked`定义如下。除了显示记者机器人的问题和作者机器人的回答外，我们还指明了相关源文本的位置（即页面编号）。这是可能的，因为作者机器人的`step()`方法还返回`source`变量，这是一个包含页面内容及其相关元数据的LangChain
    `Document`对象列表。
- en: '[PRE16]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Putting everything together, we have the following interface:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 综合考虑，我们得到了以下界面：
- en: '![](../Images/c229c6cb979f88ccfa584285bad8c376.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c229c6cb979f88ccfa584285bad8c376.png)'
- en: Chat interface. (Image by author)
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天界面。（作者提供的图片）
- en: 5.2 Implementing PDF highlighting functionality
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 实现PDF高亮功能
- en: 'In our current UI, we only indicated on which pages the author bot looked for
    the answers to the journalist bot’s question. Ideally, the user would expect the
    relevant texts to be highlighted in the original PDF to allow quick reference.
    This is the motivation for the 4th user story:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们当前的UI中，我们仅指明了作者机器人查找记者机器人问题答案的页面。理想情况下，用户希望在原始PDF中突出显示相关文本，以便快速参考。这是第4个用户故事的动机：
- en: “As a user, I want to have the corresponding parts in the original research
    paper highlighted based on the chatbot’s discussion. This will help me to quickly
    locate the sources of the information discussed during the conversation.” (Generated
    by GPT-4)
  id: totrans-155
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “作为用户，我希望根据聊天机器人的讨论，在原始研究论文中突出显示相应的部分。这将帮助我快速定位在对话过程中讨论的信息来源。”（由GPT-4生成）
- en: 'To achieve this goal, we employed the PyMuPDF library to search for relevant
    texts and perform text highlighting:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一目标，我们使用了PyMuPDF库来搜索相关文本并执行文本高亮：
- en: '[PRE17]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In the code above, the `phrases` is a list of strings, where each string represents
    one of the source texts used by the author bot to generate the answers. To highlight
    the texts, the code first loops over each page of the PDF and find if the `phrase`is
    contained on that page. Once the phrase is found, it will be highlighted in the
    original PDF.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，`phrases`是一个字符串列表，每个字符串表示作者机器人用来生成回答的源文本之一。为了高亮文本，代码首先遍历PDF的每一页，查找该页是否包含`phrase`。一旦找到短语，它将在原始PDF中进行高亮显示。
- en: 'To integrate this highlighting functionality into our previously developed
    chat UI, we first need to update the callback function:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将此高亮功能集成到我们之前开发的聊天UI中，我们首先需要更新回调函数：
- en: '[PRE18]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Although the appearance of our UI stays the same:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们的UI外观保持不变：
- en: '![](../Images/e8b533bd5592b34a12daba5bd0529daa.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e8b533bd5592b34a12daba5bd0529daa.png)'
- en: 'under the hood, we would have a new PDF file, with relevant texts (on pages
    1 and 10) properly highlighted:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在底层，我们将有一个新的PDF文件，其中相关文本（在第1和第10页）被适当地高亮显示：
- en: '![](../Images/99ac9965f679532207a325f2837beb8c.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/99ac9965f679532207a325f2837beb8c.png)'
- en: 5.3 Allowing user input for questions
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 允许用户输入问题
- en: 'Up till now, all the conversations between the two bots are autonomous. Ideally,
    users should also be able to ask their own questions if they see fit. This is
    exactly what we want to address for the 5th user story:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，这两个机器人的对话都是自主的。理想情况下，如果用户觉得合适，也应该能够提出自己的问题。这正是我们要解决的第5个用户故事：
- en: “As a user, I want to be able to intervene and ask my own questions in the midst
    of the chatbot’s conversation, this way I can direct the conversation and extract
    the information I need from the paper.” (Generated by GPT-4)
  id: totrans-167
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “作为用户，我希望能够在聊天机器人的对话中进行干预并提出自己的问题，这样我可以引导对话并从论文中提取我需要的信息。”（由GPT-4生成）
- en: 'To achieve that goal, we can add another button such that the user can decide
    if a new round of exchange should be initiated by the journalist bot or the user:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这个目标，我们可以添加另一个按钮，让用户决定是否由记者机器人或用户发起新一轮的交流：
- en: '[PRE19]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The above callback function is essentially the same as the callback function
    for defining journalist-author interaction. The only difference is that the “question”
    will be directly input by the user. Also, to make the interview logic consistent,
    we appended the user question to the journalist bot’s memory, as if the user-supplied
    question was raised by the journalist bot.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 上述回调函数本质上与定义记者-作者互动的回调函数相同。唯一的区别是“问题”将由用户直接输入。此外，为了保持采访逻辑的一致性，我们将用户问题附加到记者机器人的记忆中，就像用户提出的问题是由记者机器人提出的一样。
- en: 'We updated the main UI logic accordingly:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们相应地更新了主要的用户界面逻辑：
- en: '[PRE20]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'And this is what we got, where users can input their own questions and get
    answered by the author bot:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们得到的结果，用户可以输入自己的问题，并由作者机器人进行回答：
- en: '![](../Images/37cd0f3b65a6b848749b8cd02a2b9a99.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/37cd0f3b65a6b848749b8cd02a2b9a99.png)'
- en: Besides letting the journalist bot ask questions, users also have the opportunity
    to ask their own questions. (Image by author)
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 除了让记者机器人提问外，用户还有机会提出自己的问题。（图片由作者提供）
- en: 5.4 Allowing downloading the generated script
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 允许下载生成的脚本
- en: 'So far so good! As the last feature to implement, we want to be able to save
    the conversation history to our disk for later reference. This is the goal of
    the 6th user story:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 一切顺利！作为最后一个要实现的功能，我们希望能够将对话历史保存到磁盘以供以后参考。这是第6个用户故事的目标：
- en: “As a user, I want to be able to download a transcript of the chatbot conversation.
    This will allow me to review the key points offline or share the information with
    my colleagues.” (Generated by GPT-4)
  id: totrans-178
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “作为用户，我希望能够下载聊天机器人对话的记录。这将让我离线查看关键点或与同事分享信息。”（由GPT-4生成）
- en: 'Toward that end, we added another button for downloading the script and attach
    a callback function to the button. In this callback, we used PDFDocument to convert
    the conversation script into a PDF file:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们添加了一个新的下载脚本按钮，并将回调函数附加到该按钮。在这个回调函数中，我们使用了PDFDocument将对话脚本转换为PDF文件：
- en: '[PRE21]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We updated the main UI logic accordingly:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们相应地更新了主要的用户界面逻辑：
- en: '[PRE22]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now, we have a download button appearing in the UI. When the user clicks it,
    a paper summary PDF file will be automatically generated and downloaded to the
    local folder:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，用户界面中出现了一个下载按钮。当用户点击它时，会自动生成并下载一份论文总结的PDF文件到本地文件夹：
- en: '![](../Images/fd7da4e202f776400d99d8d260d01c21.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fd7da4e202f776400d99d8d260d01c21.png)'
- en: Users now have the option to download the script of the generated conversation.
    (Image by author)
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 用户现在可以选择下载生成对话的脚本。（图片由作者提供）
- en: '6\. Sprint Review: show the demo!'
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6\. 冲刺评审：展示演示！
- en: It’s time to put up a demo to showcase our hard work 💪
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候展示我们的辛勤工作💪
- en: 'In this demo, we showed the full functionality of our developed dual-chatbot
    system:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个演示中，我们展示了我们开发的双聊天机器人系统的全部功能：
- en: The two bots can autonomously engage in an interview with the goal of digesting
    the main points from the paper.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这两个机器人可以自主进行采访，目的是消化论文的主要观点。
- en: The user can jump into the conversation as well and ask interested questions.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户也可以进入对话并提出感兴趣的问题。
- en: Relevant texts for the generated answers are automatically highlighted in the
    original PDF.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的答案的相关文本会在原始PDF中自动高亮显示。
- en: The conversation history can be downloaded to the local folder.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对话历史可以下载到本地文件夹。
- en: We have successfully addressed all the user stories, good work 🎉 Now Sprint
    review is over, time for some retrospectives.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们成功解决了所有用户故事，干得好🎉 现在冲刺评审已经结束，是时候进行一些回顾了。
- en: 7\. Sprint Retrospective
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7\. 冲刺回顾
- en: In this project, we focused on solving the problem of efficiently digesting
    complex research papers. Toward that end, we developed a dual-chatbot system where
    one bot plays the “journalist” while the other bot plays the “author”, and two
    bots are engaged in an interview. In doing so, the journalist bot can act on behalf
    of the user and query the key points of the paper. This is beneficial as it eliminates
    the need for users to devise their own questions — an activity that can be challenging
    and time-consuming, particularly when dealing with unfamiliar subjects.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们专注于解决高效消化复杂研究论文的问题。为此，我们开发了一个双聊天机器人系统，其中一个机器人扮演“记者”，另一个机器人扮演“作者”，两个机器人进行采访。这样，记者机器人可以代表用户查询论文的关键点。这是有益的，因为它消除了用户自行设计问题的需求——这一活动在处理不熟悉的主题时可能既具有挑战性又耗时。
- en: The success of the devised dual-chatbot approach relies critically on the journalist
    bot’s ability to steer the interview and generate insightful and relevant questions.
    In the current implementation, we used GPT-3.5-Turbo as the backbone LLM. To further
    enhance the user experience, it may be necessary to employ GPT-4 to boost the
    journalist bot’s reasoning capability.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 设计的双聊天机器人方法的成功关键在于记者机器人引导采访并生成有见地且相关的问题的能力。在当前的实现中，我们使用了 GPT-3.5-Turbo 作为主要的语言模型。为了进一步提升用户体验，可能需要使用
    GPT-4 来增强记者机器人的推理能力。
- en: What’s also important is that the journalist bot needs to be capable of interpreting
    and understanding the technical terms and concepts used in the broader research
    field to which the paper belongs. Besides using advanced LLM, fine-tuning the
    existing LLM on research papers of the target domain could be a promising strategy
    to pursue.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 另外重要的是，记者机器人需要能够解释和理解在相关研究领域中使用的技术术语和概念。除了使用先进的语言模型，针对目标领域的研究论文对现有语言模型进行微调可能是一种有前景的策略。
- en: 'Looking ahead, there are several possibilities to extend our current project:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 展望未来，我们可以扩展我们当前的项目，有几种可能性：
- en: '**Better UI design.** For simplicity, we have used Jupyter Notebook to showcase
    the main idea of the dual-chatbot system. We could certainly use more sophisticated
    libraries (e.g., Streamlit) to build a more user-friendly, engaging UI.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更好的 UI 设计。** 为了简单起见，我们使用了 Jupyter Notebook 来展示双聊天机器人系统的主要理念。我们可以使用更复杂的库（例如
    Streamlit）来构建更用户友好、互动性更强的 UI。'
- en: '**Multimodal capability.** For example, text-to-speech (TTS) techniques can
    be used to create audio over the generated script. This could be beneficial to
    users as they can keep consuming the content during a commute, exercising, or
    other activities where reading isn’t convenient.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多模态能力。** 例如，可以使用文本转语音（TTS）技术为生成的脚本创建音频。这对用户很有帮助，因为他们可以在通勤、锻炼或其他阅读不便的活动中继续消耗内容。'
- en: '**Accessing external databases.** It would be great if the dual-chatbot system
    could have access to larger external repositories of research papers, such that
    the author bot could offer comparison analysis with respect to the latest developments
    in the fields of interest, thereby synthesizing insights across multiple papers.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**访问外部数据库。** 如果双聊天机器人系统能够访问更大的外部研究论文库，那将是非常棒的，这样作者机器人可以提供与领域内最新发展的比较分析，从而综合多个论文的见解。'
- en: '**Generating literature review.** Since the generated interview scripts can
    serve as condensed yet richer (than paper abstracts) versions of the full papers,
    we could first accumulate the scripts for a variety of papers in a specific research
    field, and then request a separate LLM to generate comprehensive reviews of that
    field, based on analyzing the accumulated interview scripts. This feature would
    be especially valuable for researchers when they are initiating a new research
    project or a literature review paper.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成文献综述。** 由于生成的访谈脚本可以作为比论文摘要更丰富的论文精华，我们可以首先收集特定研究领域中各种论文的脚本，然后请求一个单独的语言模型基于分析这些积累的访谈脚本生成该领域的综合评述。这一功能对于研究人员在启动新的研究项目或文献综述论文时尤其有价值。'
- en: What a fruitful Sprint we had! If you find my content useful, you could buy
    me a coffee [here](https://www.buymeacoffee.com/Shuaiguo09f) 🤗 Thank you very
    much for your support! As always, you can find the companion notebook with full
    code [here](https://github.com/ShuaiGuo16/research_paper_digesting_with_dual_chatbot)
    💻 Looking forward to sharing with you more exciting LLM projects. Stay tuned!
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的冲刺真是富有成效！如果你觉得我的内容有用，可以在[这里](https://www.buymeacoffee.com/Shuaiguo09f)请我喝杯咖啡🤗
    非常感谢你的支持！和往常一样，你可以在[这里](https://github.com/ShuaiGuo16/research_paper_digesting_with_dual_chatbot)找到包含完整代码的配套笔记本💻
    期待与你分享更多令人兴奋的LLM项目。敬请关注！
