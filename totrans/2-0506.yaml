- en: ChatGPT’s energy use per query
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/chatgpts-energy-use-per-query-9383b8654487](https://towardsdatascience.com/chatgpts-energy-use-per-query-9383b8654487)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How much electricity does ChatGPT use to answer one question?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://kaspergroesludvigsen.medium.com/?source=post_page-----9383b8654487--------------------------------)[![Kasper
    Groes Albin Ludvigsen](../Images/3c31c9e54fae4fd1c8f1c441379d1f10.png)](https://kaspergroesludvigsen.medium.com/?source=post_page-----9383b8654487--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9383b8654487--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9383b8654487--------------------------------)
    [Kasper Groes Albin Ludvigsen](https://kaspergroesludvigsen.medium.com/?source=post_page-----9383b8654487--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9383b8654487--------------------------------)
    ·8 min read·Aug 6, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/de264b7d68d991177b6bf38b6e6e98b0.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by Andrey Metelev on Unsplash
  prefs: []
  type: TYPE_NORMAL
- en: This article presents a range within which the electricity consumption per query
    of ChatGPT may fall and compares it to the measured energy consumption of two
    other large language models (LLMs).
  prefs: []
  type: TYPE_NORMAL
- en: 'This is an interesting undertaking for two reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: First of all, if organizations know how much electricity ChatGPT requires to
    answer one question, they can approximate the carbon footprint associated with
    their use of ChatGPT or similar services such as OpenAI’s LLM APIs.
  prefs: []
  type: TYPE_NORMAL
- en: For more than 50,000 European businesses, this may soon become highly relevant,
    as the coming Corporate Social Responsibility Directive (CSRD) will likely force
    them to disclose scope 3 emissions in their management reports [1]. I expect usage
    of services like ChatGPT to fall under scope 3 because cloud compute is considered
    to be scope 3 [2]. I hope this article can provide inspiration for how to estimate
    your organization’s scope 3 emissions from ChatGPT and similar services.
  prefs: []
  type: TYPE_NORMAL
- en: Another reason why it’s interesting to look into ChatGPT’s energy use per query
    is that it’ll enable individuals to come up with their own estimates of ChatGPT’s
    total electricity consumption or carbon footprint. As such, I hope this blog post
    will inspire others to publish similar work.
  prefs: []
  type: TYPE_NORMAL
- en: In the remainder of this article, the terms “query” and “request” will be used
    interchangeably.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://kaspergroesludvigsen.medium.com/membership?source=post_page-----9383b8654487--------------------------------)
    [## Join Medium with my referral link - Kasper Groes Albin Ludvigsen'
  prefs: []
  type: TYPE_NORMAL
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every story…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: kaspergroesludvigsen.medium.com](https://kaspergroesludvigsen.medium.com/membership?source=post_page-----9383b8654487--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Methodology for estimating ChatGPT’s electricity consumption per query
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, I’ll present the methodology used to produce estimates of
    ChatGPT’s electricity consumption per query. The estimates rely on two different
    methods:'
  prefs: []
  type: TYPE_NORMAL
- en: One in which we estimate the total energy consumption of the hardware ChatGPT
    presumably is running on and divide by the assumed number of daily queries
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: One in which we use the reported floating point operations (FLOPS) required
    by GPT-4 to make one forward pass to calculate the energy consumption
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Estimating ChatGPT’s electricity consumption per request with method # 1'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Below is the formula used to produce estimates of ChatGPT’s electricity consumption
    via method 1\. This formula is a standard way of producing estimates of machine
    learning model energy consumption (see e.g. [3] [4]):'
  prefs: []
  type: TYPE_NORMAL
- en: '`Energy consumption per query (KWh) = (Amount of hardware * average hardware
    power draw * TDP * 24 * PUE) / total daily queries`'
  prefs: []
  type: TYPE_NORMAL
- en: 'For method 1, I’ll assume the following values:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Amount of hardware:* 3,617 Nvidia HGX servers containing a total of 28,936
    Nvidia A100 GPUs as per SemiAnalysis’s estimates of how much compute it took to
    serve ChatGPT’s users when the service was based on the GPT-3.5 LLM [5].'
  prefs: []
  type: TYPE_NORMAL
- en: '*Average hardware power draw:* 50 % to 75 %.'
  prefs: []
  type: TYPE_NORMAL
- en: '*TDP (Thermal Design Power)*: TDP is the maximum theoretical power draw of
    a piece of hardware, but is often used as a proxy for actual maximum hardware
    power draw. I’ll assume a TDP of 6.5 kW as that’s the TDP of the Nvidia DGX A100
    server which is reasonably similar to the Nvidia HGX A100 server.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Power usage effectiveness (PUE):* I’ll assume that ChatGPT is deployed to
    Microsoft data centers. Microsoft’s average PUE is 1.18 [6].'
  prefs: []
  type: TYPE_NORMAL
- en: '*Total daily queries:* The estimate of the amount of hardware assumes 13 million
    daily active users, 15 daily queries each, i.e. 195 million daily queries [5].
    It seems like a reasonable estimate and I expect it to increase linearly with
    the amount of users such that if the number of daily queries doubles, so will
    the amount of hardware. Under these assumptions, for the purpose of calculating
    ChatGPT’s energy use per query, it doesn’t matter if ChatGPT currently has fewer
    or more daily queries, as long as it’s reasonably accurate that 195,000,000 daily
    queries require 3,617 Nvidia HGX A100 servers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So the calculation becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Energy consumption per query (KWh) = (3617 * 6.5 * average hardware power
    draw * 24 * 1.18) / 195,000,000`'
  prefs: []
  type: TYPE_NORMAL
- en: where average hardware power draw is 0.5 or 0.75.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/environmental-impact-of-ubiquitous-generative-ai-9e061bac6800?source=post_page-----9383b8654487--------------------------------)
    [## Environmental Impact of Ubiquitous Generative AI'
  prefs: []
  type: TYPE_NORMAL
- en: What could happen to our environment if billions of people began to use generative
    AI technology on a daily basis?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/environmental-impact-of-ubiquitous-generative-ai-9e061bac6800?source=post_page-----9383b8654487--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Estimating ChatGPT’s electricity consumption per request with method 2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Method 2 uses this formula (adapted from Mike Ellis’s approach [7]):'
  prefs: []
  type: TYPE_NORMAL
- en: '`Energy consumption per query (KWh) = (FLOPS per query * joules per FLOP *
    PUE) / 3600000`'
  prefs: []
  type: TYPE_NORMAL
- en: I divide by 3,600,000 to convert from joules to KWh.
  prefs: []
  type: TYPE_NORMAL
- en: 'For method 2, I’ll assume the following values:'
  prefs: []
  type: TYPE_NORMAL
- en: '*FLOPS per query*: 560,000,000,000,000 (560 Teraflops)[8].'
  prefs: []
  type: TYPE_NORMAL
- en: '*Joules per FLOP*: 0.00000000001 [7].'
  prefs: []
  type: TYPE_NORMAL
- en: '*PUE*: 1.18 (same as for method 1).'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, the calculation becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Energy consumption per query (KWh) = (560000000000000 * 0.00000000001 * 1.18)
    / 3600000`'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s apply these methods to produce estimates of ChatGPT’s energy use
    per query.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/the-carbon-footprint-of-gpt-4-d6c676eb21ae?source=post_page-----9383b8654487--------------------------------)
    [## The carbon footprint of GPT-4'
  prefs: []
  type: TYPE_NORMAL
- en: Recently leaked data allows us for the first time to estimate the carbon emissions
    from training OpenAI’s GPT-4.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/the-carbon-footprint-of-gpt-4-d6c676eb21ae?source=post_page-----9383b8654487--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Estimates of ChatGPT’s electricity consumption per request
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, I’ll present the estimates of how much energy ChatGPT needs
    to answer one request, along with the measured energy consumption per query of
    two other large language models, BLOOM and GPT-J, as reported elsewhere [9][10].
  prefs: []
  type: TYPE_NORMAL
- en: In Table 1 below, we can see that method 1 and 2 yield similar estimates of
    ChatGPT’s energy consumption per query. Using method 1, ChatGPT’s estimated energy
    consumption per query is 0.0017 KWh at the lower range (average power draw is
    50 % of TDP) and 0.0026 at the higher range (average power draw is 75 % of TDP).
    Using method 2, ChatGPT’s estimated energy use per request is 0.0018 KWh.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/457c95f9578d6c16bd932f32c9f95a3d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 1: ChatGPT’s estimated energy use per query'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see how the estimates of ChatGPT’s electricty use per query compare to
    the electricty use per query observed for other LLMs. Table 2 below shows the
    energy consumption per query for GPT-J and BLOOM. GPT-J has been measured to consume
    0.196 KWh per query, while BLOOM has been measured to consume 0.0039 KWh per query.
    Notice that BLOOM’s electricity consumption per query is not much larger than
    the estimated electricity consumption per query for ChatGPT, while GPT-J’s energy
    use is noticeably larger.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fdd010187100c940091ef301382584c7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 2: Comparing the estimated electricity consumption per query for ChatGPT
    to the measured electricity consumption per query for BLOOM and GPT-J reported
    in [9][10]'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/how-to-estimate-and-reduce-the-carbon-footprint-of-machine-learning-models-49f24510880?source=post_page-----9383b8654487--------------------------------)
    [## How to estimate and reduce the carbon footprint of machine learning models'
  prefs: []
  type: TYPE_NORMAL
- en: Two ways to easily estimate the carbon footprint of machine learning models
    and 17 ideas for how you might reduce it
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/how-to-estimate-and-reduce-the-carbon-footprint-of-machine-learning-models-49f24510880?source=post_page-----9383b8654487--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Above, we saw that ChatGPT’s electricity consumption per query may be between
    0.0017 and 0.0026 KWh depending on the assumptions we use. We can see that the
    estimated energy use is similar for both method 1 and 2 which to me suggests that
    the estimates are in the right ballpark. The reason method 2 yields an estimate
    that is a bit lower than the upper range of method 1’s estimate could be because
    method 2 only accounts for the energy consumption of the GPUs. However, other
    hardware (CPU, RAM, networking equipment) also consumes energy.
  prefs: []
  type: TYPE_NORMAL
- en: If we believe the estimates by SemiAnalysis [5] to be in the right ballpark,
    then — from my perspective — the main source of uncertainty in the ChatGPT electricity
    consumption estimates are how much electricity each piece of hardware is using.
    In this article I have assumed that each piece of hardware uses 50–75% of its
    maximum power draw, which I personally believe to be reasonable, but please challenge
    this.
  prefs: []
  type: TYPE_NORMAL
- en: Also note that the estimated quantity is the *average* electricity consumption
    of a ChatGPT query because we use Microsoft’s *average* PUE. However, the PUE
    can vary from data center to data cetner. If you’d like to estimate *your* electricity
    consumption from using ChatGPT or similar services, you should use the PUE of
    the data center you expect handles your requests. The MLCO2 Impact calculator
    can show you a list of Microsoft Azure regions [11].
  prefs: []
  type: TYPE_NORMAL
- en: This blog post estimates that ChatGPT’s energy use per request is smaller than
    the measured energy consumption of the LLM called BLOOM. BLOOM is similar in size
    to GPT-3 – the LLM on which ChatGPT was initially based. It would make sense that
    ChatGPT is more energy efficient than BLOOM, because the authors of the BLOOM
    paper did not take any measures to improve the energy efficiency of request processing.
    In addition, it would be reasonable to expect that OpenAI have made such efforts
    since it could reduce their costs.
  prefs: []
  type: TYPE_NORMAL
- en: The results also show that GPT-J was measured to consume much more electricity
    per query than the other models although at 6 billion parameters, GPT-J is significantly
    smaller than BLOOM (176 billion), GPT-3 (175 billion), and GPT-4 (rumored 1.8
    trillion). A likely explanation for this is that in the reported experiment, GPT-J
    was running on an Nvidia RTX3090 GPU that’s probably less energy efficient than
    the Nvidia A100 on which ChatGPT is likely running. In addition, no measures were
    taken to improve the energy efficiency of GPT-J in the experiment.
  prefs: []
  type: TYPE_NORMAL
- en: On AI stack exchange [7], Mike Ellis has calculated ChatGPT’s energy consumption
    using method 2 and arrived at 0.000083 KWh per query. In his calculations, he
    uses 30 teraflops, where I in this article use 560 teraflops. Mike Ellis uses
    30 teraflops because ChatGPT itself said that it uses 30 teraflops. But as Mike
    Ellis himself also points out, we should be vary of trusting ChatGPT’s answer
    because it known to hallucinate and provide false information [12]. Using 560
    teraflops as I do here, yields an energy consumption that is closer to the measured
    energy consumption of BLOOM. Combined with the fact that the 560 teraflops figure
    stems from SemiAnalysis, I therefore believe 560 teraflops per query to be more
    realistic.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, to put ChatGPT’s estimated energy consumption per request into perspective:
    if you turn on a standard 40W light bulb for 1 hour, it will have consumed the
    same amount of energy as 15 to 24 ChatGPT queries as per my estimates.'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This article estimates that ChatGPT may use between 0.0017 and 0.0026 KWh of
    electricity to answer one query. These numbers can be used by organizations to
    approximate their carbon footprint from using ChatGPT and similar services. Two
    different methods were used to obtain these results and both methods yielded estimates
    that are in the same ballpark. These estimates are lower than the measured energy
    consumption of the LLMs BLOOM and GPT-J, which have previously been measured to
    consume 0.0039 and 0.196 KWh per query respectively. According to these estimates
    of ChatGPT’s energy consumption per query, if you turn on a standard 40W light
    bulb for 1 hour, it will have consumed the same amount of energy as 15 to 24 ChatGPT
    queries.
  prefs: []
  type: TYPE_NORMAL
- en: That’s it! I hope you enjoyed the story. Let me know what you think!
  prefs: []
  type: TYPE_NORMAL
- en: Get the benefits of Medium and support my writing by signing up for a Medium
    membership [HERE](https://kaspergroesludvigsen.medium.com/membership).
  prefs: []
  type: TYPE_NORMAL
- en: Follow me for more on AI and sustainability and [subscribe](https://kaspergroesludvigsen.medium.com/subscribe)
    to get my stories via email when I publish.
  prefs: []
  type: TYPE_NORMAL
- en: I also sometimes write about [time series forecasting](/how-to-make-a-pytorch-transformer-for-time-series-forecasting-69e073d4061e).
  prefs: []
  type: TYPE_NORMAL
- en: And feel free to connect on [LinkedIn](https://www.linkedin.com/in/kaspergroesludvigsen).
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] [https://normative.io/insight/csrd-explained](https://normative.io/insight/csrd-explained/)/'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] [https://www.bloomberg.com/news/articles/2022-11-17/hidden-emissions-from-cloud-computing-pose-net-zero-threat](https://www.bloomberg.com/news/articles/2022-11-17/hidden-emissions-from-cloud-computing-pose-net-zero-threat)'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] [https://arxiv.org/pdf/2307.09288.pdf](https://arxiv.org/pdf/2307.09288.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] [https://arxiv.org/ftp/arxiv/papers/2204/2204.05149.pdf](https://arxiv.org/ftp/arxiv/papers/2204/2204.05149.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[5] [https://www.semianalysis.com/p/the-inference-cost-of-search-disruption](https://www.semianalysis.com/p/the-inference-cost-of-search-disruption)'
  prefs: []
  type: TYPE_NORMAL
- en: '[6] [https://azure.microsoft.com/en-us/blog/how-microsoft-measures-datacenter-water-and-energy-use-to-improve-azure-cloud-sustainability/](https://azure.microsoft.com/en-us/blog/how-microsoft-measures-datacenter-water-and-energy-use-to-improve-azure-cloud-sustainability/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[7] [https://ai.stackexchange.com/questions/38970/how-much-energy-consumption-is-involved-in-chat-gpt-responses-being-generated/39418?noredirect=1#comment58882_39418](https://ai.stackexchange.com/questions/38970/how-much-energy-consumption-is-involved-in-chat-gpt-responses-being-generated/39418?noredirect=1#comment58882_39418)'
  prefs: []
  type: TYPE_NORMAL
- en: '[8] [https://archive.md/2RQ8X](https://archive.md/2RQ8X)'
  prefs: []
  type: TYPE_NORMAL
- en: '[9] [https://arxiv.org/abs/2211.02001](https://arxiv.org/abs/2211.02001)'
  prefs: []
  type: TYPE_NORMAL
- en: '[10] [https://borsen.dk/nyheder/baeredygtig/de-har-regnet-paa-chat-gpts-klimaaftryk-nu-raader-de-folk-til-at-taenke-sig-rigtig-godt-om?b_source=topchef-i-sydbank-krigen-i-ukraine-minder-om-finanskrisen&b_medium=row_8&b_campaign=news_2](https://borsen.dk/nyheder/baeredygtig/de-har-regnet-paa-chat-gpts-klimaaftryk-nu-raader-de-folk-til-at-taenke-sig-rigtig-godt-om?b_source=topchef-i-sydbank-krigen-i-ukraine-minder-om-finanskrisen&b_medium=row_8&b_campaign=news_2)
    and BLOOM [https://arxiv.org/abs/2211.02001](https://arxiv.org/abs/2211.0200)'
  prefs: []
  type: TYPE_NORMAL
- en: '[11] [https://mlco2.github.io/impact/](https://mlco2.github.io/impact/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[12] [https://fortune.com/2023/08/01/can-ai-chatgpt-hallucinations-be-fixed-experts-doubt-altman-openai/](https://fortune.com/2023/08/01/can-ai-chatgpt-hallucinations-be-fixed-experts-doubt-altman-openai/)'
  prefs: []
  type: TYPE_NORMAL
