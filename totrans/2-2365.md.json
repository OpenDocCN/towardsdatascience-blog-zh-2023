["```py\nimport pandas as pd\nimport plotly.graph_objects as go\nfrom lightgbm import LGBMRegressor\n```", "```py\n# Load data.\ndata = pd.read_csv('https://raw.githubusercontent.com/unit8co/darts/master/datasets/AirPassengers.csv')\n# Rename columns.\ndata = data.rename(columns = {\"Month\": \"time\", \"#Passengers\": \"passengers\"})\n# Set time to datetime.\ndata.time = pd.to_datetime(data.time)\n# Set time as index.\ndata = data.set_index(\"time\")\n```", "```py\n# Let's visualize the data.\ndef show_data(data,title=\"\"):\n    trace = [go.Scatter(x=data.index,y=data[c],name=c) for c in data.columns]\n    go.Figure(trace,layout=dict(title=title)).show()\n\nshow_data(data,\"Monthly totals of international airline passengers\")\n```", "```py\ndef build_target_features(data, lags, horizon=1):\n    # Build lagged features.\n    feat = pd.concat(\n        [\n            data[[\"passengers\"]].shift(lag).rename(\n                columns={\"passengers\": f\"lag_{lag}\"}\n            )\n            for lag in lags\n        ],\n        axis=1,\n    )\n\n    # Build month feature.\n    feat[\"month\"] = [f\"M{m}\" for m in data.index.month]\n    feat[\"month\"] = feat[\"month\"].astype(\"category\")\n    # Build target at horizon.\n    targ = data[\"passengers\"].shift(-horizon).rename(f\"horizon_{horizon}\")\n    # Drop missing values generated by lags/horizon.\n    idx = ~(feat.isnull().any(axis=1) | targ.isnull())\n    feat = feat.loc[idx]\n    targ = targ.loc[idx]\n    return targ, feat\n\n# Build targets and features.\ntarget, features = build_target_features(\n    data,\n    lags=[0,1,2,5,11,23],\n    horizon=1,\n)\n```", "```py\ndef run_backtest(\n    model,\n    target,\n    features,\n    start_window = 10,\n    retrain_frequency = 6,\n):\n    \"\"\"Simple backtesting implementation.\n\n    Args:\n        model: A model with fit and predict methods.\n        targets: Series with the target in chronological order.\n        features: Dataframe with the features in chronological order.\n        start_window: The initial window to train a model.\n        retrain_frequency: How often to retrain the model.\n\n    Return:\n        A dataframe with the validation target and prediction.\n    \"\"\"\n\n    # Sanity check on shape\n    assert features.shape[0] == target.shape[0]\n\n    all_preds = []\n    all_targets = []\n    last_timestep = start_window\n\n    while last_timestep < len(target):\n        # Split train/valid\n        targ_train = target.iloc[:last_timestep]\n        feat_train = features.iloc[:last_timestep]\n        targ_valid = target.iloc[last_timestep:last_timestep+1]    \n        feat_valid = features.iloc[last_timestep:last_timestep+1]\n\n        # Train the model\n        if last_timestep==start_window or last_timestep % retrain_frequency == 0:\n            model.fit(feat_train,targ_train)\n        # Predict on valid set\n        pred_valid = model.predict(feat_valid)\n        # Save the output\n        all_preds.append(pred_valid[0])\n        all_targets.append(targ_valid)\n\n        # Process next timestep\n        last_timestep += 1\n\n    # Format output\n    output = pd.concat(all_targets).rename(\"target\").to_frame()\n    output[\"prediction\"] = all_preds\n    return output\n```", "```py\n# Apply run_backtest to our data.\noutput_backtest = run_backtest(\n    LGBMRegressor(min_child_samples=1, objective=\"mae\"),\n    target,\n    features,\n    start_window = 36,\n    retrain_frequency = 6,\n)\n# First, let's visualize the data.\nshow_data(output_backtest,\"Backtested predictions at horizon 1\")\n# Then, let's compute the MAE.\nMAE = abs(output_backtest.prediction - output_backtest.target).mean()\nprint(f\"MAE: {MAE:.1f}\")\n```"]