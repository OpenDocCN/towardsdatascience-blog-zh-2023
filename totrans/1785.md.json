["```py\n[net]\nbatch=1\nheight=448\nwidth=448\nchannels=3\nmomentum=0.9\ndecay=0.0005\n...\n\n[convolutional]\nbatch_normalize=1\nfilters=64\nsize=7\nstride=2\npad=1\nactivation=leaky\n```", "```py\nimport cv2\n\nmodel = cv2.dnn.readNetFromDarknet(\"yolo.cfg\", \"yolov1.weights\")\n```", "```py\ndarknet_io.cpp:902: error: \n(-212:Parsing error) Unknown layer type: local in function 'ReadDarknetFromCfgStream'\n```", "```py\nimport cv2\n\nmodel = cv2.dnn.readNetFromDarknet(\"yolov2.cfg\", \"yolov2.weights\")\n```", "```py\nln = model.getLayerNames()\noutput_layers = [ln[i - 1] for i in model.getUnconnectedOutLayers()]\n```", "```py\nimg = cv2.imread('test.jpg')\nH, W = img.shape[:2]\n\nblob = cv2.dnn.blobFromImage(img, 1/255.0, (608, 608), swapRB=True, crop=False)\n```", "```py\nmodel.setInput(blob)\noutputs = model.forward(output_layers)\n```", "```py\nthreshold = 0.5\nboxes, confidences, class_ids = [], [], []\n\n# Get all boxes and labels\nfor output in outputs:\n    for detection in output:\n        scores = detection[5:]\n        class_id = np.argmax(scores)\n        confidence = scores[class_id]\n        if confidence > threshold:\n            center_x, center_y = int(detection[0] * W), int(detection[1] * H)\n            width, height = int(detection[2] * W), int(detection[3] * H)\n            left = center_x - width//2\n            top = center_y - height//2\n            boxes.append([left, top, width, height])\n            class_ids.append(class_id)\n            confidences.append(float(confidence))\n\n# Combine boxes together using non-maximum suppression\nindices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n\n# All COCO classes\nclasses = \"person;bicycle;car;motorbike;aeroplane;bus;train;truck;boat;traffic light;fire hydrant;stop sign;parking meter;bench;bird;\" \\\n          \"cat;dog;horse;sheep;cow;elephant;bear;zebra;giraffe;backpack;umbrella;handbag;tie;suitcase;frisbee;skis;snowboard;sports ball;kite;\" \\\n          \"baseball bat;baseball glove;skateboard;surfboard;tennis racket;bottle;wine glass;cup;fork;knife;spoon;bowl;banana;apple;sandwich;\" \\\n          \"orange;broccoli;carrot;hot dog;pizza;donut;cake;chair;sofa;pottedplant;bed;diningtable;toilet;tvmonitor;laptop;mouse;remote;keyboard;\" \\\n          \"cell phone;microwave;oven;toaster;sink;refrigerator;book;clock;vase;scissors;teddy bear;hair dryer;toothbrush\".split(\";\")\n\n# Draw rectangles on image\ncolors = np.random.randint(0, 255, size=(len(classes), 3), dtype='uint8')\nfor i in indices.flatten():\n    x, y, w, h = boxes[i]\n    color = [int(c) for c in colors[class_ids[i]]]\n    cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n    text = f\"{classes[class_ids[i]]}: {confidences[i]:.2f}\"\n    cv2.putText(img, text, (x + 2, y - 6), cv2.FONT_HERSHEY_COMPLEX, 0.5, color, 1)\n\n# Show\ncv2.imshow('window', img)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n```", "```py\nimport cv2\n\nmodel = cv2.dnn_DetectionModel(\"yolov7.cfg\", \"yolov7.weights\")\nmodel.setInputParams(size=(640, 640), scale=1/255, mean=(127.5, 127.5, 127.5), swapRB=True)\n\nclass_ids, confidences, boxes = model.detect(img, confThreshold=0.5)\n\n# Combine boxes together using non-maximum suppression\nindices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n\n# All COCO classes\nclasses = \"person;bicycle;car;motorbike;aeroplane;bus;train;truck;boat;traffic light;fire hydrant;stop sign;parking meter;bench;bird;\" \\\n          \"cat;dog;horse;sheep;cow;elephant;bear;zebra;giraffe;backpack;umbrella;handbag;tie;suitcase;frisbee;skis;snowboard;sports ball;kite;\" \\\n          \"baseball bat;baseball glove;skateboard;surfboard;tennis racket;bottle;wine glass;cup;fork;knife;spoon;bowl;banana;apple;sandwich;\" \\\n          \"orange;broccoli;carrot;hot dog;pizza;donut;cake;chair;sofa;pottedplant;bed;diningtable;toilet;tvmonitor;laptop;mouse;remote;keyboard;\" \\\n          \"cell phone;microwave;oven;toaster;sink;refrigerator;book;clock;vase;scissors;teddy bear;hair dryer;toothbrush\".split(\";\")\n\n# Draw rectangles on image\ncolors = np.random.randint(0, 255, size=(len(classes), 3), dtype='uint8')\nfor i in indices.flatten():\n    x, y, w, h = boxes[i]\n    color = [int(c) for c in colors[class_ids[i]]]\n    cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n    text = f\"{classes[class_ids[i]]}: {confidences[i]:.2f}\"\n    cv2.putText(img, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n\n# Show\ncv2.imshow('window', img)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n```", "```py\nfrom ultralytics import YOLO\nimport supervision as sv\n\nmodel = YOLO('yolov8m.pt')\nresults = model.predict(source=img, save=False, save_txt=False, verbose=False)\ndetections = sv.Detections.from_yolov8(results[0])\n\n# Create list of labels\nlabels = []\nfor ind, class_id in enumerate(detections.class_id):\n    labels.append(f\"{model.model.names[class_id]}: {detections.confidence[ind]:.2f}\")\n\n# Draw rectangles on image\nbox_annotator = sv.BoxAnnotator(thickness=2, text_thickness=1, text_scale=0.4)\nbox_annotator.annotate(scene=img, detections=detections, labels=labels)\n\n# Show\ncv2.imshow('window', img)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n```"]