- en: Top 5 Alternatives to CSV
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 顶级的5种CSV替代方案
- en: 原文：[https://towardsdatascience.com/top-5-ridiculously-better-csv-alternatives-595f70a9c936](https://towardsdatascience.com/top-5-ridiculously-better-csv-alternatives-595f70a9c936)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/top-5-ridiculously-better-csv-alternatives-595f70a9c936](https://towardsdatascience.com/top-5-ridiculously-better-csv-alternatives-595f70a9c936)
- en: CSV files for big data storage? Think twice — there are radically better options
    available. These 5 will save IO time and disk space.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大数据存储的CSV文件？再想想 — 这里有一些更好的选择。这五种格式将节省IO时间和磁盘空间。
- en: '[](https://medium.com/@radecicdario?source=post_page-----595f70a9c936--------------------------------)[![Dario
    Radečić](../Images/41882a3b30bab9da43d66a59f1df366b.png)](https://medium.com/@radecicdario?source=post_page-----595f70a9c936--------------------------------)[](https://towardsdatascience.com/?source=post_page-----595f70a9c936--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----595f70a9c936--------------------------------)
    [Dario Radečić](https://medium.com/@radecicdario?source=post_page-----595f70a9c936--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@radecicdario?source=post_page-----595f70a9c936--------------------------------)[![Dario
    Radečić](../Images/41882a3b30bab9da43d66a59f1df366b.png)](https://medium.com/@radecicdario?source=post_page-----595f70a9c936--------------------------------)[](https://towardsdatascience.com/?source=post_page-----595f70a9c936--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----595f70a9c936--------------------------------)
    [Dario Radečić](https://medium.com/@radecicdario?source=post_page-----595f70a9c936--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----595f70a9c936--------------------------------)
    ·6 min read·Jan 5, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----595f70a9c936--------------------------------)
    ·阅读时长6分钟·2023年1月5日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/582774573716f7e5671bcd9100e45e77.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/582774573716f7e5671bcd9100e45e77.png)'
- en: Photo by [Maximalfocus](https://unsplash.com/@maximalfocus?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Maximalfocus](https://unsplash.com/@maximalfocus?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Everyone knows CSV, but is it really the file format you should use 100% of
    the time? Well, no. It has some obvious benefits, such as direct file editing
    and ease of understanding, but the drawbacks could cost you thousands of dollars
    in disk space and I/O time.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 每个人都知道CSV，但它真的适合你100%使用吗？其实不是。它有一些明显的优点，比如直接文件编辑和易于理解，但缺点可能会让你在磁盘空间和I/O时间上花费上千美元。
- en: Today I’ll show you the top CSV alternatives with detailed explanations, code,
    and most importantly — numbers. You’ll know precisely how faster alternative file
    formats are and when should you use them.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 今天我会向你展示顶级的CSV替代方案，提供详细的解释、代码，最重要的是 — 数字。你将准确了解替代文件格式的速度，以及何时使用它们。
- en: What’s Wrong With the CSV Format?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CSV格式的问题是什么？
- en: Absolutely nothing. It allows you to edit the file directly without loading
    them with a programming language such as Python, Also, you can send it directly
    to a non-tech-savvy client, and they’ll have no trouble opening it and understanding
    the content.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 完全没有问题。它允许你直接编辑文件，而无需像Python这样的编程语言来加载它们。此外，你可以直接将其发送给非技术人员客户，他们将能够顺利打开并理解内容。
- en: It’s all sunshine and rainbows until files become too big to share, too big
    to open in Excel, or so huge you need to upgrade your cloud storage plan.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一切都是阳光明媚的，直到文件变得太大而无法分享，太大而无法在Excel中打开，或者大到你需要升级你的云存储计划。
- en: When it comes to datasets with millions of rows, you shouldn’t even consider
    saving them in CSV file format. You won’t ever send such a dataset to a non-tech-savvy
    client, nor will you open it in Excel.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于包含数百万行的数据集，你甚至不应该考虑将它们保存为CSV文件格式。你不会将这样的数据集发送给非技术人员客户，也不会在Excel中打开它。
- en: That’s when other file formats or CSV alternatives become a thing. Let’s go
    over them next.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这时其他文件格式或CSV替代方案就显得重要了。接下来我们来逐一介绍它们。
- en: Top 5 CSV Alternatives That Save Time and Space
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 节省时间和空间的5种CSV替代方案
- en: 'I find these file formats much better than CSV when working with huge tabular
    datasets:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理巨大的表格数据集时，我发现这些文件格式比CSV要好得多：
- en: Pickle
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pickle
- en: Parquet
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Parquet
- en: Feather
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feather
- en: Avro
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Avro
- en: ORC
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ORC
- en: I’ll now explain each in a couple of sentences and show you how to work with
    them in Python.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我将用几句话解释每种格式，并展示如何在Python中使用它们。
- en: Pickle
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pickle
- en: You can use Python’s `pickle` library to serialize a Python object into a compact
    binary representation. It allows you to store, or *pickle* any Python object,
    not just Pandas DataFrames. It's often used to save machine learning models.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用 Python 的 `pickle` 库将 Python 对象序列化为紧凑的二进制表示。它允许您存储或 *pickle* 任何 Python
    对象，而不仅仅是 Pandas DataFrames。它通常用于保存机器学习模型。
- en: The biggest downside of Pickle is that its Python-specific, so cross-language
    support isn’t guaranteed.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Pickle 最大的缺点是它是 Python 特有的，因此跨语言支持不能保证。
- en: 'To dump a Pandas DataFrame into a pickle file format, use:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要将 Pandas DataFrame 转储为 pickle 文件格式，请使用：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To read a Pickle file, use:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 要读取 Pickle 文件，请使用：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parquet
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Parquet
- en: Apache Parquet is a data storage format designed for efficiency. The reason
    behind this is the column storage architecture, as it allows you to skip data
    that isn’t relevant quickly. The best part — Pandas has full native support for
    Parquet.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Parquet 是一种为高效设计的数据存储格式。其背后的原因是列存储架构，因为它允许您快速跳过不相关的数据。最棒的是 — Pandas 完全原生支持
    Parquet。
- en: 'To write a Pandas DataFrame to a Parquet file, run:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 要将 Pandas DataFrame 写入 Parquet 文件，请运行：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To read a Parquet file into a Pandas DataFrame, run:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 要将 Parquet 文件读取到 Pandas DataFrame 中，请运行：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Feather
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Feather
- en: Feather is a data format for storing data frames. It’s designed to push data
    frames in and out of memory as efficiently as possible. Its primary use case is
    to enable fast communication between Python and R, but you’re not limited to that
    alone.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Feather 是一种用于存储数据帧的数据格式。它设计用于尽可能高效地将数据帧进出内存。它的主要用途是实现 Python 和 R 之间的快速通信，但不仅限于此。
- en: 'To dump a Pandas DataFrame to a Feather file, run:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 要将 Pandas DataFrame 转储到 Feather 文件中，请运行：
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To read a Feather file as a Pandas DataFrame, run:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 要将 Feather 文件读取为 Pandas DataFrame，请运行：
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Avro
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Avro
- en: Avro is an open-source project which provides services of data serialization
    and exchange for Apache Hadoop. It stores a JSON-like schema with the data, which
    you have to write and parse manually first.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Avro 是一个开源项目，为 Apache Hadoop 提供数据序列化和交换服务。它与数据一起存储 JSON 类似的 schema，您必须先手动编写和解析它。
- en: 'To save a Pandas DataFrame as an Avro file, run:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 要将 Pandas DataFrame 保存为 Avro 文件，请运行：
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'It’s quite a lot, especially if you have many columns. Reading Avro files and
    converting them to a Pandas DataFrame is also a three-step process:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常多，尤其是当您有很多列时。读取 Avro 文件并将其转换为 Pandas DataFrame 也是一个三步过程：
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ORC
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ORC
- en: ORC stands for *Optimized Row Columnar*. It’s a data format optimized for reads
    and writes in Hive. With Python, you can use the `read_orc()` function from Pandas
    to read ORC files. There's no alternative function for writing ORC files, so you'll
    have to use PyArrow.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ORC 代表 *Optimized Row Columnar*。这是一个优化了 Hive 中读取和写入的数据格式。在 Python 中，您可以使用 Pandas
    的 `read_orc()` 函数读取 ORC 文件。没有用于写入 ORC 文件的替代函数，因此您必须使用 PyArrow。
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Reading ORC files is much simpler:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 读取 ORC 文件要简单得多：
- en: '[PRE9]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We’ll now set up a Python benchmark script and how these top CSV alternatives
    for Python and Pandas compare.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将设置一个 Python 基准测试脚本，并比较这些顶级 CSV 替代品在 Python 和 Pandas 中的表现。
- en: Top 5 CSV Alternatives — Benchmark in Python
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前 5 个 CSV 替代品 — Python 中的基准测试
- en: For this benchmark, I’ve decided to create a 5M row Pandas DataFrame with 5
    numeric and 2 textual columns. I was using M1 Pro MacBook Pro (10-core CPU, 16
    GB RAM) for the benchmark, so your mileage may vary.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个基准测试，我决定创建一个包含 5 个数值列和 2 个文本列的 5M 行 Pandas DataFrame。我使用了 M1 Pro MacBook
    Pro（10 核 CPU，16 GB RAM）进行基准测试，因此您的结果可能会有所不同。
- en: 'Here’s the code snippet if you want to recreate it:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想重新创建它，这里是代码片段：
- en: '[PRE10]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'And here’s what the dataset looks like:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是数据集的样子：
- en: '![](../Images/c65e68f4e05d3f005a585b1ae137f0ba.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c65e68f4e05d3f005a585b1ae137f0ba.png)'
- en: Image 1 — Synthetic 5M row dataset (image by author)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图片 1 — 合成的 5M 行数据集（图片来源：作者）
- en: Next, let’s take a look at the benchmark results — both for file save/read,
    and the file size.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看基准测试结果 — 包括文件保存/读取和文件大小。
- en: Benchmark result — Dataset save time
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基准测试结果 — 数据集保存时间
- en: 'Saving a 5M row dataset to a CSV File took the most time — 24.5 seconds. CSV
    alternatives such as Feather took only 0.69 seconds, which is 35 times faster:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 将 5M 行数据集保存为 CSV 文件花费了最多的时间 — 24.5 秒。CSV 替代品如 Feather 仅需 0.69 秒，速度快了 35 倍：
- en: '![](../Images/e84fd30645ed25a7168db050b11a1447.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e84fd30645ed25a7168db050b11a1447.png)'
- en: Image 2 — Dataset save time comparison (image by author)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图片 2 — 数据集保存时间比较（图片来源：作者）
- en: You can see this pattern repeat among most of the top CSV alternatives. Avro
    file format was closest to CSV in save time, only because parsing the schema and
    converting the dataset to a dictionary took some time ( *prep time* column).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到这种模式在大多数顶级CSV替代方案中重复出现。Avro文件格式在保存时间上与CSV最接近，只是因为解析模式和将数据集转换为字典花费了一些时间（*准备时间*列）。
- en: Let’s see how the read times compare.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看读取时间的比较。
- en: Benchmark result — Dataset read time
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基准结果 — 数据集读取时间
- en: 'We don’t see as significant of a difference in dataset read time. Pandas took
    8.45 seconds to read a 5M row CSV file, and alternatives such as Avro were even
    slower if we account for the prep time:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有看到数据集读取时间有显著的差异。Pandas读取一个5M行的CSV文件花费了8.45秒，如果考虑到准备时间，像Avro这样的替代方案甚至更慢：
- en: '![](../Images/64e8a773bc7d95d5bbe35555380fa636.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/64e8a773bc7d95d5bbe35555380fa636.png)'
- en: Image 3 — Dataset read time comparison (image by author)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图3 — 数据集读取时间比较（图片作者提供）
- en: Pickle file format stands out here, but it’s a Python-specific data format,
    which is why you don’t see it commonly used in a multi-language environment. Other
    than that, Parquet looks promising with around 2.5x read time reduction.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Pickle文件格式在这里表现突出，但它是Python特定的数据格式，这也是你在多语言环境中不常见的原因。除此之外，Parquet看起来很有前途，读取时间减少了约2.5倍。
- en: Benchmark result — Dataset file size
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基准结果 — 数据集文件大小
- en: 'And finally, let’s take a look at the file size for each top CSV alternative:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们看看每种顶级CSV替代方案的文件大小：
- en: '![](../Images/b48e15a2ab0fa6485d25a02d34215ded.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b48e15a2ab0fa6485d25a02d34215ded.png)'
- en: Image 4 — Dataset file size comparison (image by author)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图4 — 数据集文件大小比较（图片作者提供）
- en: The differences aren’t huge here, but most of the alternatives offer around
    20%-25% reduction in file size. Avro was a clear winner here, so use this file
    format if small file sizes are preferred, and you don’t care about IO speed.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这些差异并不大，但大多数替代方案能提供约20%-25%的文件大小减少。Avro在这里明显胜出，因此如果你更倾向于小文件大小且不在乎IO速度，可以使用这种文件格式。
- en: Summing Up Top CSV Alternatives for Data Science
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结数据科学中的顶级CSV替代方案
- en: CSV file format isn’t going anywhere. It’s still the most common one (after
    XLSX) if you need to share your data with business clients that expect to examine
    it in Excel. Most business users have no idea what Avro or Parquet mean, so stick
    to CSV in this scenario.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: CSV文件格式并不会消失。如果你需要与希望在Excel中查看数据的商业客户共享数据，它仍然是最常用的格式（仅次于XLSX）。大多数商业用户不了解Avro或Parquet的含义，因此在这种情况下还是使用CSV吧。
- en: Otherwise, if you’re paying for cloud compute resources and storage, optimizing
    how you store data can save you a ton of money in the long run. Use Pickle if
    you know you’ll use Python only, go with Avro if small file size is crucial, or
    opt for alternatives such as Parquet, ORC, or Feather for the best balance between
    file size and IO speeds. Pretty much everything is better than CSV.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在支付云计算资源和存储费用，那么优化数据存储方式可以在长远中为你节省大量金钱。如果你确定只使用Python，请使用Pickle；如果小文件大小至关重要，请选择Avro；或者选择Parquet、ORC或Feather等替代方案，以在文件大小和IO速度之间取得最佳平衡。几乎所有的选择都比CSV要好。
- en: '*What’s your favourite file format for storing large datasets?* Let me know
    in the comment section below.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '*你最喜欢哪种文件格式来存储大型数据集？* 请在下方评论区告诉我。'
- en: '*Loved the article? Become a* [*Medium member*](/@radecicdario/membership)
    *to continue learning without limits. I’ll receive a portion of your membership
    fee if you use the following link, with no extra cost to you.*'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '*喜欢这篇文章？成为* [*Medium会员*](/@radecicdario/membership) *以无限制地继续学习。如果你使用以下链接，我将获得你会员费的一部分，而你无需支付额外费用。*'
- en: '[](https://medium.com/@radecicdario/membership?source=post_page-----595f70a9c936--------------------------------)
    [## Join Medium with my referral link - Dario Radečić'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@radecicdario/membership?source=post_page-----595f70a9c936--------------------------------)
    [## 使用我的推荐链接加入 Medium - 达里奥·拉德齐奇'
- en: Read every story from Dario Radečić (and thousands of other writers on Medium).
    Your membership fee directly supports…
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 阅读达里奥·拉德齐奇的所有故事（以及Medium上的其他成千上万名作家的故事）。你的会员费将直接支持...
- en: medium.com](https://medium.com/@radecicdario/membership?source=post_page-----595f70a9c936--------------------------------)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@radecicdario/membership?source=post_page-----595f70a9c936--------------------------------)
- en: '*Originally published at* [*https://betterdatascience.com*](https://betterdatascience.com/top-csv-alternatives/)
    *on January 5, 2023.*'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '*最初发表于* [*https://betterdatascience.com*](https://betterdatascience.com/top-csv-alternatives/)
    *2023年1月5日。*'
