# 人工智能的膨胀：更多的模型是否总是更好？

> 原文：[https://towardsdatascience.com/the-inflation-of-ai-is-more-always-better-8ea1be75e0aa](https://towardsdatascience.com/the-inflation-of-ai-is-more-always-better-8ea1be75e0aa)

## 新的机器学习模型每小时都会出现，但这种快速的步伐也带来了缺陷；以假设驱动的开发可以帮助减轻这些缺陷。

[](https://medium.com/@benjamin.thuerer?source=post_page-----8ea1be75e0aa--------------------------------)[![Benjamin Thürer](../Images/b4c49698c7270c592bf992fc47f75765.png)](https://medium.com/@benjamin.thuerer?source=post_page-----8ea1be75e0aa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8ea1be75e0aa--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8ea1be75e0aa--------------------------------) [Benjamin Thürer](https://medium.com/@benjamin.thuerer?source=post_page-----8ea1be75e0aa--------------------------------)

·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----8ea1be75e0aa--------------------------------) ·6分钟阅读·2023年11月8日

--

我们生活在人工智能的时代！每天，许多新的人工智能工具和机器学习模型正在被创建、训练、发布，并且常常被宣传。例如，当我们查看[Hugging Face](https://medium.com/u/b1574f0c6c5e?source=post_page-----8ea1be75e0aa--------------------------------)时，我们看到截至今天（2023年11月6日）大约有40万个模型，而2022年11月时仅有约8.4万个模型（见图1）。在短短一年内，模型数量增长了大约470%。请记住，[Hugging Face](https://huggingface.co/)并不是唯一的机器学习模型平台。此外，许多模型甚至没有开源。因此，可以肯定地说，实际可用的机器学习模型数量要高得多。

> 是否真的需要如此大量的模型膨胀？

对人工智能的兴奋之情是巨大的，这首先是好的。人工智能有潜力为一些最严重的全球挑战（如气候变化或疫情）找到解决方案——或者至少减轻这些挑战。此外，人工智能可以使日常任务更高效，从而改善我们的工作与生活平衡。因此，进行人工智能的研究与开发，并将机器学习模型提供给社区，是正确且必要的步骤！然而，鉴于目前人工智能社区的发展速度和兴奋感，我在想：是否真的需要如此大量的模型膨胀？最终，谁将从中受益？

![](../Images/291196a6cd6e5e3fc29484aab68c7aa3.png)

图1：这张图展示了[Hugging Face](https://huggingface.co/)上可用的开源模型数量随时间的变化（蓝色线）。红色线代表了2022年11月ChatGPT的发布，橙色虚线代表了基于ChatGPT发布前数据的三次多项式拟合。

# 模型膨胀的潜在风险

“兴奋”和“炒作”带来的一个常见缺点是，当衍生的动机和工作没有特别指向某个目标，而是更加肤浅和广泛时。上述提到的人工智能的潜在好处并不来自于大量肤浅的模型，而是来自于专门解决困难问题的专业模型。

此外，目前模型开发、部署和广告的速度也带来了一些我们可能已经遇到的缺点。重要的是要解决这些问题，以确保未来取得最佳成果。一些当前人工智能发展速度的潜在缺点：

+   **质量：** 随着市场速度的加快，已经很难跟上社区的进展并对模型结果和研究论文进行适当的审查。缺点是将会有大量质量低下的模型和服务，因为它们没有经过严格的测试和审查。此外，像[置信区间](https://medium.com/towards-data-science/dont-forget-confidence-intervals-for-your-ml-product-272009bfab56)这样的质量指标由于市场速度快而大多被忽视。

+   **影响 + 安全：** 目前开发的大量模型并不以人为（或自然）为中心，也没有非常有用的目标或用例。然而，每个产品开发都应该始终关注使世界变得更美好。开发者必须关注能够带来积极影响的事物，而不是仅仅开发“另一个聊天机器人”。此外，开发者还必须排除模型可能带来的潜在危害，确保安全（类似于[这个](https://humancompatible.ai/news/2023/10/31/prominent-ai-scientists-from-china-and-the-west-propose-joint-strategy-to-mitigate-risks-from-ai/)提案）。

+   **隐私 + 版权：** 模型很少被文档化，难以追踪隐私和版权问题如何处理。这对个人可能产生负面影响。在处理敏感数据时，建模是危险的，因为即使是嵌入后的向量数据库也不具备隐私友好性，容易被反向工程（如[Morris et al. 2023](https://arxiv.org/abs/2310.06816?ref=upstract.com)所示）。此外，新法规如[欧盟人工智能法](https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence)将对这些模型产生影响，强制执行隐私合规。

+   **投资损失：** 即使市场速度很快，任何人工智能项目都需要资源（高技能工程师、大量计算成本、产品维护）。如果结果的人工智能产品质量低或未能服务于明确的用户目的，业务的投资回报是不确定的。在开发产品之前进行产品发现阶段以预见潜在的投资回报是常见做法。然而，当前市场速度下，这一做法在人工智能领域经常被忽视。

总结来说，AI 开发的快速进展不仅是好事，它也给企业和个人带来了潜在的摩擦和不利影响。

![](../Images/4461fb1681ac2f4c682c6644dee43b99.png)

图 2：左侧图表显示了可用 ML 模型的指数增长如何限制未来人类对模型的监督，因为每个模型的时间减少（左）。右侧显示了 AI 领域中可能受此快速发展影响的类别。

# 通过假设驱动的开发来减少模型膨胀

如前所述，当前对 AI 的兴奋主要是件好事。这个故事的目的**不是**停止 AI 开发或减缓其速度。正好相反。意图是将积极的兴奋引导到具体目标上，创造质量而不是数量。这个想法是鼓励每位 AI 工程师和数据科学家在每个项目的开始阶段多花一点时间，提出一些基本问题，比如：“谁会从中受益？”和“我们想要达成什么目标？”。

> 这个故事提出的并不具有革命性，只是遵循科学方法。

与其采取探索性的方法，开始开发下一个 LLM 而没有明确的愿景，从而膨胀社区，不如从最后开始，讨论产品使用案例？例如，可以首先提出项目的目标，例如：“当前的基础 LLM 非常复杂，几乎无法在本地运行。我们希望解决这个问题。”有了这些，项目变得有意义。但意义并不是一切，明确的假设会使工作更加顺利。例如：

> “可以训练一个轻量级的 LLM，在本地运行并且在 LLMU 基准测试集上仍能表现>70。”

心中有明确的目标和推导出的假设将有助于简化整个开发工作。这还将有助于衡量成功并为社区做出有意义的贡献。结合文献/模型评审，它将立即指出提议的项目是否已在其他地方实现，因此只是创造了冗余工作。换句话说，这个故事提出的并不具有革命性，只是遵循科学方法。

![](../Images/37d895b432ef83e1269ad51f9ec424c6.png)

图 3：此示意图展示了科学项目的框架。它强调在实际开始开发 ML 模型之前，还有几个步骤（假设、文献综述、提案）。

# 创新的火花

提议使用科学方法的原因在于，科学界对人工智能快速发展速度带来的当前问题已有充分认识。科学家必须从海量的研究论文中学习，以便对研究社区做出有意义的贡献。加上大型研究实验室的速度，很容易产生“没有足够时间阅读一切”的感觉。这种情况以及发表压力已经导致了[可重复性危机](https://www.nature.com/articles/533452a)。科学方法旨在解决这些问题。

科学方法经过几个世纪的发展和改进，处于任何科学项目的核心。鉴于人工智能发展的快速步伐与海量科学文献的情况非常相似，适应这些原则是有意义的。

> 许多科学突破并非始于实验室，而是始于一个思考，并被形成假设。

作为一个积极的副作用，科学方法不仅用于标准化工作和实验结果，还旨在促进创新。花时间审查现有文献并制定假设是创新的核心。许多科学突破并非始于实验室，而是始于一个思考，并被形成假设。

科学界，例如，提供了[*预注册*](https://www.cos.io/initiatives/prereg)的选项。这意味着，科学家在实际进行实验和分析之前，首先发布他们的目标、假设和方法。这一概念也可以应用于人工智能开发。

**话虽如此，我强烈鼓励大家在开始任何人工智能或机器学习项目之前，先勾勒出目标和假设！此外，我希望** [**Hugging Face**](https://medium.com/u/b1574f0c6c5e?source=post_page-----8ea1be75e0aa--------------------------------) **以及其他知名平台有一天能要求工程师和科学家在开始工作之前先进行目标和假设的预注册。我相信如果像Hugging Face这样的大型平台开始，其他平台也会跟进。**

# 总结

当前人工智能发展的速度既令人兴奋又充满挑战。令人兴奋的是新模型带来的好处，但也因现有模型的数量庞大以及其基本质量、隐私、安全和投资回报的不确定性而具有挑战性。

科学方法，如假设驱动开发，可以帮助解决这些问题，甚至通过确保人工智能/机器学习工程师和数据科学家专注于朝着预定目标和假设进行开发，促进创新。

这是人工智能的时代，因此最重要的是确保我们为所有人创造出最佳的未来。

*所有图片，除非另有说明，均由作者提供。*
