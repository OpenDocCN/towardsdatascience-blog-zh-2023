- en: Artificial Bee Colony — How it differs from PSO
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/artificial-bee-colony-how-it-differs-from-pso-9c6831bfb552](https://towardsdatascience.com/artificial-bee-colony-how-it-differs-from-pso-9c6831bfb552)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Intuition and code implementation for ABC, and exploring where it outperforms
    Particle Swarm Optimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@byjameskoh?source=post_page-----9c6831bfb552--------------------------------)[![James
    Koh, PhD](../Images/8e7af8b567cdcf24805754801683b426.png)](https://medium.com/@byjameskoh?source=post_page-----9c6831bfb552--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9c6831bfb552--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9c6831bfb552--------------------------------)
    [James Koh, PhD](https://medium.com/@byjameskoh?source=post_page-----9c6831bfb552--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9c6831bfb552--------------------------------)
    ·10 min read·Dec 18, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5bdc467ff2ee97b8a9bbc611dd5120fc.png)'
  prefs: []
  type: TYPE_IMG
- en: Image created by DALL·E 3 based on the prompt “Draw a science-fiction themed
    image of bees facing off in battle.”
  prefs: []
  type: TYPE_NORMAL
- en: I shared about the intuition, implementation and usefulness of Particle Swarm
    Optimization (PSO) in a [recent article](/particle-swarm-optimization-search-procedure-visualized-4b0364fb3e5a?sk=478e8d135f6e98e596674cb6fcc3e9a9),
    as part of my series of nature-inspired algorithms. Today, I will explain how
    Artificial Bee Colony (ABC) works.
  prefs: []
  type: TYPE_NORMAL
- en: Aren’t bees part of a swarm? Are these two algorithms simply two sides of the
    same coin?
  prefs: []
  type: TYPE_NORMAL
- en: For this article, I will jump right into the intuition of ABC. Next, I will
    provide the mathematics, followed by the implementation in Python. Finally, I
    will formulate a problem in which PSO fails to solve but ABC does with ease, and
    explain the aspects of ABC which makes this possible.
  prefs: []
  type: TYPE_NORMAL
- en: Intuition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Much like in the case of Reinforcement Learning and Evolutionary Algorithms,
    a fundamental driver behind ABC is the balance between exploration and exploitation.
  prefs: []
  type: TYPE_NORMAL
- en: Those who are new to swarm intelligence algorithms may initially feel intimidated
    by the association with biology, and think that there’s some complicated mathematical
    modelling to mimic what exactly happens in nature. As variables are typically
    represented as Greek alphabets in textbooks, it adds to this false perception
    of complexity.
  prefs: []
  type: TYPE_NORMAL
- en: That is certainly not the case, at least for ABC. There is nothing at all about
    bees’ waggle dance that you need to understand. Nor is there anything beyond just
    high school math in this algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Essentially, it is simply having a local directional search towards promising
    locations, saving the results only if there’s an improvement in the objective
    function, along with a global random search upon encountering prolonged periods
    of no progress.
  prefs: []
  type: TYPE_NORMAL
- en: The creators of this algorithm then packaged it with fanciful names, and tagged
    these to employed bees, onlooker bees, and scout bees.
  prefs: []
  type: TYPE_NORMAL
- en: Formulation of Solution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Like PSO, ABC is a metaheuristic algorithm?
  prefs: []
  type: TYPE_NORMAL
- en: What is ‘metaheuristic’, you might ask?
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with a heuristic solution — it is a technique which, though not
    guaranteed to be optimal, often works well in practice to give something good
    enough.
  prefs: []
  type: TYPE_NORMAL
- en: The ‘meta’ in ‘metaheuristic’ is not Facebook. It is a ‘higher-level’ heuristic
    — it is a general strategy that can be applied to different types of problems.
    Hence, it will be to your advantage to focus on understanding the principles;
    the math then falls in place with ease.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Consider a problem that has a solution space of *D* dimensions. Upon initialization,
    *N* number of solutions are generated using [1]:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/57ca7fb2f647e9820dfb70e1d96130e6.png)'
  prefs: []
  type: TYPE_IMG
- en: It is actually easier to simply represent this in vector or matrix form.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1a42f7aa5e770d0dde7685a5c66d4b6b.png)'
  prefs: []
  type: TYPE_IMG
- en: The ‘**Employed bee**’ phase is simply a local directional search around each
    source *i*, with respect to a randomly chosen neighbor *k*. The word ‘neighbor’
    might be misleading — it is simply another candidate solution, which does not
    necessarily need to be in the vicinity. Having this directional aspect as compared
    to a random Gaussian perturbation in the local search tends to perform better
    in practice. (This is what metaheuristics is about).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3e6e920d9bd5a51b41ef5a88474ad9a0.png)'
  prefs: []
  type: TYPE_IMG
- en: '***ϕ*** is a vector of random numbers drawn from a uniform distribution of
    [-1,1], ie.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Although the neighbor *k* is randomly chosen, keep in mind that each neighbor
    is a potentially good solution in its own right. You may read that the vanilla
    form of ABC actually introduces a perturbation along just a single dimension *j*.
    However, in practice, perturbing along multiple dimensions concurrently can lead
    to fewer iterations. (It is essentially doing a more aggressive exploration —
    as with heuristics, there is no ‘unquestionable truth’ to follow; we are just
    finding what works).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e38578933f2ca7c4e2d507aa5058e350.png)'
  prefs: []
  type: TYPE_IMG
- en: (Image of bees from DALL·E 3; put together by author.) Consider the solution
    i, with the neighbor k, in two-dimensional space. Suppose that phi, the random
    vector is [0.5, 0.1]. This means that the solution at i will be adjusted 50% towards
    k along the first dimension (horizontal), and 10% towards k along the second dimension
    (vertical) — it will be saved and updated if the objective value at x is higher
    than at i.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we move on to the ‘**Onlooker bee**’ phase. Each candidate solution is
    judged based on its fitness (eg. the value of the objective function), and we
    select one of these according to a probability distribution proportional to the
    relative fitness.
  prefs: []
  type: TYPE_NORMAL
- en: As in the case of [Evolutionary Algorithm](https://medium.com/towards-data-science/evolutionary-algorithm-selections-explained-2515fb8d4287),
    it is not absolutely necessary to keep to a roulette wheel selection, there are
    other selection techniques such as Tournament selection (see section 3.2.2 of
    the linked article for details).
  prefs: []
  type: TYPE_NORMAL
- en: In this second phase, there is a stronger element of exploitation, because the
    ‘neighbor’ is one which likely has a good fitness, and a directional search is
    performed with respect to it.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b3c94f418b83f6a181a9aa170d0708f3.png)'
  prefs: []
  type: TYPE_IMG
- en: (Image of bees from DALL·E 3; put together by author.) Search during the ‘Onlooker
    bee’ phase. Modifying the solution at x, with respect to the selected solution
    at s. Note that the new point of interest to be evaluated need not be on the solid
    blue double-sided arrow. Instead, it can be anywhere within the blue triangle
    (if you use a modified phi with random numbers drawn from a uniform distribution
    of [0,1]), or even within the green triangle if drawn from the distribution of
    [-1,1].
  prefs: []
  type: TYPE_NORMAL
- en: In both the ‘Employed bee’ and ‘Onlooker bee’ phase, if the new solution (ie.
    food source in the analogy) is not an improvement over the existing solution,
    a counter corresponding to it is incremented by one. On the other hand, if there
    is an improvement, the solution is updated and the next search will be with respect
    to this new location.
  prefs: []
  type: TYPE_NORMAL
- en: This is followed by the ‘**Scout bee**’ phase. If the counter exceeds a pre-defined
    threshold, that corresponding candidate will be retired and a new candidate is
    re-initialized randomly across the entire solution space. In terms of bee analogy,
    this process represents the depletion of a food source. In terms of data science,
    it simply means that we treat the candidate as a local optima (and possibly global
    too).
  prefs: []
  type: TYPE_NORMAL
- en: Code Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The C++ implementation in the reference [1] textbook actually spans three full
    pages, and comprises nearly 200 lines.
  prefs: []
  type: TYPE_NORMAL
- en: I will give you a simple python implementation in less than 60 lines of easy
    to read code. More importantly, it works effectively.
  prefs: []
  type: TYPE_NORMAL
- en: The basic unit of ABC is a `Bee`, which is analogous to a particle in PSO in
    that it represents a candidate solution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Each `Bee` has an `explore` method, which updates its position with respect
    to another candidate. The fitness corresponding to this new location is updated.
    If the previous record is surpassed, its `pos` and `fitness` attribute will be
    updated, otherwise it increments `self.counter` by one.
  prefs: []
  type: TYPE_NORMAL
- en: The second other class (also the last) is `Colony`, which comprises a number
    of `Bee` instances.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Notice that in every iteration, each bee of the class `Bee` performs the ‘employed
    bee’ phase, ‘onlooker bee’ phase, as well as ‘scout bee’ phase. They are not different
    entities. Essentially, we are just implementing elements of exploration and exploitation
    across each iteration.
  prefs: []
  type: TYPE_NORMAL
- en: Why ABC when we have PSO?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Up till now, we have learnt about the intuition of Artificial Bee Colony, as
    well as did a step-by-step walkthrough for the math and code implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Being a metaheuristic, ABC can be used in multiple different ways. However,
    let’s focus on a particular scenario where ABC is superior over PSO, which was
    what I promised in the last paragraph of the previous article.
  prefs: []
  type: TYPE_NORMAL
- en: ABC is highly capable to get out of local optima and does not get ‘stuck’.
  prefs: []
  type: TYPE_NORMAL
- en: Why would ABC be able to solve something which PSO cannot? Shouldn’t they work
    in the same way since we maintain a population of candidate solutions in both
    ABC and PSO?
  prefs: []
  type: TYPE_NORMAL
- en: The key reason is due to the ‘Scout bee’ phase, which randomly explores a new
    region of the solution space once progress is tapering.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In addition, the exploration in the ‘Employed bee’ and ‘Onlooker bee’ phases
    are also more aggressive (with the possibility of moving not just *towards* but
    *away* from other candidates) than in PSO (which gravitates *towards* the global
    best and local best).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Granted, by moving away from another candidate, we could well be taking a step
    backwards rather than forward. This brings us an important principle to keep in
    mind —we keep only the good stuff. (This is similar to why [mutations in Evolutionary
    Algorithms](https://medium.com/towards-data-science/evolutionary-algorithm-mutations-explained-4a3b5c2d49de)
    leads to improvement). In `Bee.explore`, notice that `self.pos` is overwritten
    only when there is an improvement in `self.fitness`.
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate the efficacy of ABC, let’s create an objective function which
    has multiple local optimal points, and solve it using both ABC and PSO.
  prefs: []
  type: TYPE_NORMAL
- en: Formulation of Problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Consider a simple 2-dimensional problem as follows, generated by the following
    code. (Note that this function, in and of itself, is a useful learning point for
    those who want to create environments to test out optimization algorithms).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/56ac3ee47bdf34aaa265fd256e01a240.png)'
  prefs: []
  type: TYPE_IMG
- en: Function with global optimal of 0.8 and local optima of 0.5 to 0.7\. Image by
    author, generated using Python.
  prefs: []
  type: TYPE_NORMAL
- en: I’ve previously presented the value proposition of solving a high-dimensional
    mathematical equation, using location planning as an example in the first [article](https://medium.com/towards-data-science/particle-swarm-optimization-search-procedure-visualized-4b0364fb3e5a)
    of this series (‘Use-Case’ section; right at the beginning).
  prefs: []
  type: TYPE_NORMAL
- en: In the above two-dimensional problem, we see that there are four peaks, each
    of slightly different magnitude. Three of the peaks are located near the center
    of the search space, while the fourth, which has the highest peak, is located
    at a corner away from the others. The objective of this is to illustrate a problem
    where one might settle for a local optimal instead of the global optimal.
  prefs: []
  type: TYPE_NORMAL
- en: A realistic problem certainly has higher dimensions. Let’s extend the above
    to create a 8-dimensional function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Here, x1, y1, x2, y2, x3, y3, x4, y4 are just different *dimensions* of a single
    vector. You may think of these as coordinates of four locations, which collectively
    makes up the solution.
  prefs: []
  type: TYPE_NORMAL
- en: It can be seen that the points (1,1,1,1,1,1,1,1), (-1,1,-1,1,-1,1,-1,1), and
    (1,-1,1,-1,1,-1,1,-1) are local optima with values of 0.5, 0.6 and 0.7, respectively.
    Meanwhile, the global optimum is at (-2,-2,-2,-2,-2,-2,-2,-2), with an objective
    value of 0.8.
  prefs: []
  type: TYPE_NORMAL
- en: Following my usual practice of having everything as object-oriented, let’s define
    the following class.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This makes it compatible not only with the current ABC code, but also the PSO
    code shared in the linked article above.
  prefs: []
  type: TYPE_NORMAL
- en: Results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using the classes established, solving the use case just takes a couple of lines.
  prefs: []
  type: TYPE_NORMAL
- en: 'For PSO:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/d6d528f36d416bb52d2370755945ddd5.png)'
  prefs: []
  type: TYPE_IMG
- en: Results from Particle Swarm Optimization (screenshot by author). Obtained objective
    value of 0.7 in 52 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: 'For ABC:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/5258a84826db08c578456f5105f25442.png)'
  prefs: []
  type: TYPE_IMG
- en: Results from Artificial Bee Colony (screenshot by author). Obtained objective
    value of 0.8 in 20 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: We have a winner here! Not only did ABC find the true global optimum, it did
    so in less than half the time. Try it yourself!
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We see that Artificial Bee Colony, as a metaheuristic, balances the exploration
    and exploitation very effectively. This article shows that the math involved is
    just simple linear algebra, and that the intuition really does not require any
    knowledge of biology or bees.
  prefs: []
  type: TYPE_NORMAL
- en: Using this, you can solve a multidimensional optimization problem using just
    a few lines of code, to get the optimal solution in seconds.
  prefs: []
  type: TYPE_NORMAL
- en: Congrats! Another useful tool in your pocket!
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] B. Akay and D. Karaboga, Artificial Bee Colony Algorithm in [Swarm Intelligence
    Algorithms](https://books.google.com.sg/books?hl=en&lr=&id=v6P0DwAAQBAJ)(2020)
    CRC Press'
  prefs: []
  type: TYPE_NORMAL
