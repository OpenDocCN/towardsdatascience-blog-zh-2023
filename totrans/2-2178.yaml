- en: Understanding Causal Trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/understanding-causal-trees-920177462149](https://towardsdatascience.com/understanding-causal-trees-920177462149)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[CAUSAL DATA SCIENCE](https://towardsdatascience.com/tagged/causal-data-science)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*How to use regression trees to estimate heterogeneous treatment effects*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@matteo.courthoud?source=post_page-----920177462149--------------------------------)[![Matteo
    Courthoud](../Images/d873eab35a0cf9fc696658c0bee16b33.png)](https://medium.com/@matteo.courthoud?source=post_page-----920177462149--------------------------------)[](https://towardsdatascience.com/?source=post_page-----920177462149--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----920177462149--------------------------------)
    [Matteo Courthoud](https://medium.com/@matteo.courthoud?source=post_page-----920177462149--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----920177462149--------------------------------)
    ·15 min read·Feb 3, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7b179d1c87c2a54be0d5266b5a9d9071.png)'
  prefs: []
  type: TYPE_IMG
- en: Cover, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: In causal inference, we are usually interested in estimating the causal effect
    of a treatment (a drug, ad, product, …) on an outcome of interest (a disease,
    firm revenue, customer satisfaction, …). However, knowing that a treatment works
    on average is often not sufficient and we would like to know for which subjects
    (patients, users, customers, …) it works better or worse, i.e. we would like to
    estimate **heterogeneous treatment effects**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Estimating heterogeneous treatment effects allows us to use the treatment selectively
    and more efficiently through **targeting**. Knowing which customers are more likely
    to react to a discount allows a company to spend less money by offering fewer
    but better-targeted discounts. This works also for negative effects: knowing for
    which patients a certain drug has side effects allows a pharmaceutical company
    to warn or exclude them from the treatment. There is also a more subtle advantage
    of estimating heterogeneous treatment effects: knowing **for whom** a treatment
    works allow us to better understand **how** a treatment works. Knowing that the
    effect of a discount does not depend on the income of its recipient but rather
    on its buying habits tells us that maybe it is not a matter of money, but rather
    a matter of attention or loyalty.'
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we will explore the estimation of heterogeneous treatment effects
    using a modified version of regression trees (and forests). From a machine-learning
    perspective, there are two fundamental **differences between causal trees and
    predictive trees**. First of all, the target is the treatment effect, which is
    an inherently unobservable object. Second, we are interested in doing inference,
    which means quantifying the uncertainty of our estimates.
  prefs: []
  type: TYPE_NORMAL
- en: Online Discounts and Targeting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For the rest of the article, we are going to use a toy example, for the sake
    of exposition: suppose we were an **online shop** and we are interested in understanding
    whether offering discounts to new customers increases their expenditure. In particular,
    we would like to know if offering discounts is more effective for some customers
    with respect to others since we would prefer not to give discounts to customers
    that would spend anyways. Moreover, it could also be that spamming customers with
    pop-ups could deter them from buying, having the opposite effect.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6a3434d66f1b72c454fca46a3b7d94b6.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by Author using [NightCafé](https://creator.nightcafe.studio/)
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand whether and how much the discounts are effective we run an **A/B
    test**: whenever a new user visits our online shop, we randomly decide whether
    to offer them the discount or not. I import the data-generating process `dgp_online_discounts()`
    from `[src.dgp](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/dgp.py)`.
    With respect to previous articles, I generated a new DGP parent class that handles
    randomization and data generation, while its children classes contain specific
    use cases. I also import some plotting functions and libraries from `[src.utils](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/utils.py)`.
    To include not only code but also data and tables, I use [Deepnote](https://deepnote.com/),
    a Jupyter-like web-based collaborative notebook environment.'
  prefs: []
  type: TYPE_NORMAL
- en: We have data on 100.000 website visitors, for whom we observe the `time` of
    the day, the `device` they use, their `browser` and their geographical `region`.
    We also see whether they were offered the `discount`, our treatment, and what
    is their `spend`, the outcome of interest.
  prefs: []
  type: TYPE_NORMAL
- en: Since the treatment was randomly assigned, we can use a simple **difference-in-means**
    estimator to estimate the treatment effect. We expect the treatment and control
    group to be similar, except for the `discount`, therefore we can causally attribute
    any difference in `spend` to the `discount`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The discount seems to be effective: on average the spending in the treatment
    group increases by 1.95$. But are all customers equally affected?'
  prefs: []
  type: TYPE_NORMAL
- en: To answer this question, we would like to estimate **heterogeneous treatment
    effects**, possibly at the individual level.
  prefs: []
  type: TYPE_NORMAL
- en: Heterogeneous Treatment Effects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are many possible ways to estimate heterogeneous treatment effects. The
    most common is to split the population into groups based on some observable characteristic,
    which in our case could be the `device`, the `browser` or the geographical `region`.
    Once you have decided which variable to split your data on, you can simply interact
    with the treatment variable (`discount`) with the dimension of treatment heterogeneity.
    Let's take `device` for example.
  prefs: []
  type: TYPE_NORMAL
- en: How do we interpret the regression results? The effect of the `discount` on
    customers' `spend` is 1.22$ but it increases by a further 1.44$ if the customer
    is accessing the website from a mobile `device`.
  prefs: []
  type: TYPE_NORMAL
- en: Splitting is easy for categorical variables, but for a continuous variable like
    `time` it is not intuitive where to split. Every hour? And which dimension is
    more informative? It would be tempting to try all possible splits, but the more
    we split the data, the more it is likely that we find spurious results (i.e. we
    overfit, in machine learning lingo). It would be great if we could **let the data
    speak** and select the minimum and most informative splits.
  prefs: []
  type: TYPE_NORMAL
- en: In a [separate post](https://medium.com/towards-data-science/understanding-meta-learners-8a9c1e340832),
    I have shown how the so-called **meta-learners** take this approach to causal
    inference. The idea is to predict the outcome conditional on the treatment status
    for each observation, and then compare the predicted conditional on treatment,
    with the predicted outcome conditional on control. The difference is the individual
    treatment effect.
  prefs: []
  type: TYPE_NORMAL
- en: The problem with meta-learners is that they use all their [degrees of freedom](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics))
    in predicting the outcome. However, we are interested to predict treatment effect
    heterogeneity. If most of the variation in the outcome is *not* in the treatment
    dimension, we will get very poor estimates of the treatment effects.
  prefs: []
  type: TYPE_NORMAL
- en: Is it possible to instead directly concentrate on the **prediction of individual
    treatment effects**? Let’s define *Y* as the outcome of interest `spend`, *D*
    the treatment `discount`, and *X* other observable characteristics. The *ideal*
    loss function is
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/625014656a5a9c75f9c9c8425affd810.png)'
  prefs: []
  type: TYPE_IMG
- en: Ideal loss function, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: where *τᵢ* is the treatment effect of individual *i*. However, this objective
    function is **unfeasible** since we do not observe *τᵢ*.
  prefs: []
  type: TYPE_NORMAL
- en: But, turns out that there is a way to get an unbiased estimate of the **individual
    treatment effect**. The **idea** is to use an auxiliary outcome variable, whose
    expected value for each individual is the individual treatment effect. This variable
    is
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8c6ee904e46dcad7945f99fe47a9c19b.png)'
  prefs: []
  type: TYPE_IMG
- en: Auxiliary outcome variable, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: where *p*(*Xᵢ*) is the [**propensity score**](https://en.wikipedia.org/wiki/Propensity_score_matching)
    of observation *i*, i.e. its probability of being treated.
  prefs: []
  type: TYPE_NORMAL
- en: In randomized experiments, the propensity score is known since randomization
    is fully under the control of the experimenter. For example, in our case, the
    probability of treatment was 50%. In quasi-experimental studies instead, when
    the treatment probability is not known, it has to be estimated. Even in randomized
    experiments, it is always better to estimate rather than impute the propensity
    scores, since it guards against sampling variation in the randomization. For more
    details on the propensity scores and how they are used in causal inference, I
    have a separate post [here](https://medium.com/towards-data-science/matching-weighting-or-regression-99bf5cffa0d9).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s first generate dummy variables for our categorical variables, `device`,
    `browser` and `region`.
  prefs: []
  type: TYPE_NORMAL
- en: We fit a `LogisticRegression` and use it to predict the treatment probability,
    i.e. construct the propensity score.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/afa6eb8ef5d4eff1aef7264b9cd1a95e.png)'
  prefs: []
  type: TYPE_IMG
- en: Distribution of estimated propensity scores, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: As expected, most propensity scores are very close to 0.5, the probability of
    treatment used in randomization. Moreover, the distribution is almost identical
    across the treatment and control groups, further confirming that randomization
    worked. If it had not been the case, we would have needed to make further assumptions
    in order to conduct a causal analysis. The most common one is **unconfoundedness**,
    also known as ignorability or selection on observables. In short, we will assume
    that conditional on some observables 𝑋 the treatment assignment is as good as
    random.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7a455561d68df293eac18c050dbd3a7a.png)'
  prefs: []
  type: TYPE_IMG
- en: Unconfoundedness assumption, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: However, in our case, the treatment probability is known and it seems that nothing
    went wrong in the randomization process.
  prefs: []
  type: TYPE_NORMAL
- en: We now have all the elements to compute our auxiliary outcome variable *Y**.
  prefs: []
  type: TYPE_NORMAL
- en: As we said before, the idea is to use *Y** as the target of a prediction problem,
    since the expected value is exactly the individual treatment effect. Let’s check
    its average in the data.
  prefs: []
  type: TYPE_NORMAL
- en: Indeed its average is almost identical to the previously estimated average treatment
    effect of 1.94$.
  prefs: []
  type: TYPE_NORMAL
- en: How is it possible that, with a single observation and an estimate of the propensity
    score, we can estimate the individual treatment effect? What are the drawbacks?
  prefs: []
  type: TYPE_NORMAL
- en: 'The **intuition** is to approach the problem from a different perspective:
    *ex-ante*, before the experiment. Imagine that our dataset had a single observation,
    *i*. We know that the treatment probability is *p*(*Xᵢ*), the propensity score.
    Therefore, in expectation, our dataset has *p*(*Xᵢ*) observations in the treatment
    group and *1–p*(*Xᵢ*) observations in the control group. The rest is business
    as usual: we estimate the treatment effect as the difference in average outcomes
    between the two groups! And indeed that is what we would do:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a61c82853d3864a67fa2af6e2ef190ee.png)'
  prefs: []
  type: TYPE_IMG
- en: Auxiliary outcome variable, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: The only difference is that we have a single observation.
  prefs: []
  type: TYPE_NORMAL
- en: 'This trick comes at a cost: *Yᵢ** is an unbiased estimator for the individual
    treatment effect but has a very **high variance**. This is immediately visible
    by plotting its distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/631c1029186de6b42501d772234bf081.png)'
  prefs: []
  type: TYPE_IMG
- en: Distribution of the auxiliary variable, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: We are now ready to estimate **heterogeneous treatment effects**, by translating
    the causal inference problem into a prediction problem, predicting the auxiliary
    outcome *Y**, given observable characteristics *X*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4f2b5684285e0ab0fdf2e3c667945ccf.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by Author using [NightCafé](https://creator.nightcafe.studio/)
  prefs: []
  type: TYPE_NORMAL
- en: Causal Trees
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, we have seen that we can transform the estimation of
    **heterogeneous treatment effects** into a prediction problem, where the outcome
    is the auxiliary outcome variable
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8c6ee904e46dcad7945f99fe47a9c19b.png)'
  prefs: []
  type: TYPE_IMG
- en: Auxiliary outcome variable, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: We can in principle use any machine learning algorithm at this point to estimate
    individual treatment effects. However, [**regression trees**](https://en.wikipedia.org/wiki/Decision_tree_learning)
    have particularly convenient characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: First of all, how do regression trees work? Classification and regression trees
    (CART) are algorithms that recursively **partition the data in bins** based on
    covariates *X* such that the outcome *Y* *within* each bin is as homogeneous as
    possible and the outcome *across* bins is as heterogeneous as possible. The predicted
    values are simply the outcome averages within each bin, in our case the *auxiliary*
    outcome variable *Y**, whose expected value for each observation is equal to the
    individual treatment effect. Therefore, by averaging *Y** within each bin, we
    can compute the **conditional (on X) heterogeneous treatment effect** 𝔼[*τᵢ |
    Xᵢ*] for observations that fall within that bin**.**
  prefs: []
  type: TYPE_NORMAL
- en: The **averaging** part is one of the big advantages of regression trees for
    inference since we know very well how to do inference with averages, thanks to
    the [**Central Limit Theorem**](https://en.wikipedia.org/wiki/Central_limit_theorem).
    The second advantage of regression trees over other machine learning algorithms
    is that trees are very **interpretable** since we can directly plot the data partition
    as a tree structure. We will see more of this later. Last but not least, regression
    trees are still at the core of the [best-performing predictive algorithms](https://arxiv.org/abs/2207.08815)
    with tabular data, as of 2022.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s use the `[DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)`
    function from `sklearn` to fit our regression tree and estimate the heterogeneous
    treatment effects of `discounts` on customers' `spend`.
  prefs: []
  type: TYPE_NORMAL
- en: We have restricted the tree to have a maximum depth of 2 and at least 30 observations
    per partition (also called *leaf*) so that we can easily plot the tree and visualize
    the estimated groups and treatment effects.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/caff3ccb47368f02118a113b301a7874.png)'
  prefs: []
  type: TYPE_IMG
- en: Regression tree on auxiliary outcome variable Y*, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: How should we **interpret** the tree? On the top, we can see the average *Y**
    in the data, 1.945$, corresponding with the average treatment effect. Starting
    from there, the data gets split into different branches, according to the rules
    highlighted at the top of each node. For example, the first node splits the data
    into two groups of size 51,156 and 48,844 depending on whether the `time` is later
    than 12.325\. At the bottom, we have our final partitions, with the heterogeneous
    treatment effects. For example, the leftmost leaf contains 43,876 observations
    with `time` earlier than 12.325 and non-Safari `browser`, for which we predict
    an effect on `spend` of 0.295$. In short, every node contains an estimate of the
    **conditional average treatment effect** 𝔼[*τᵢ | Xᵢ*], where darker node colors
    indicate higher prediction values.
  prefs: []
  type: TYPE_NORMAL
- en: Should we believe these estimates? Not really, because of a couple of reasons.
    The **first problem** is that we have an unbiased estimate of the average treatment
    effect only if, *within each leaf*, we have the same number of treated and control
    units. This is not automatically the case with an off-the-shelf `DecisionTreeRegressor()`.
  prefs: []
  type: TYPE_NORMAL
- en: Honest Trees
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another problem with our naive procedure is that we have used the **same data**
    to generate the tree and evaluate it. This generates bias because a simple difference
    in means estimator would not take into account the fact that the partition is
    endogenous, i.e. generated on the same data. In machine learning terms, we are
    overfitting. The solution is simple: we can split the sample into two separate
    subsamples and use different data to generate the tree and compute the predictions.
    These trees are called **honest trees**.'
  prefs: []
  type: TYPE_NORMAL
- en: This solution is as simple as effective since it allows us, at the inference
    stage, to treat each sample within a leaf as independent from the tree structure.
    At that point, our estimator is a **difference in means** estimator for an independent
    subsample we can simply use the Central Limit Theorem for inference. One drawback
    of splitting the data is that we lose [power](https://en.wikipedia.org/wiki/Power_of_a_test),
    i.e. the ability to detect non-spurious heterogeneous treatment effects because
    of the smaller sample. The solution is to repeat the procedure twice, swapping
    the sample used to build the tree and the sample used to compute the within-leaf
    averages. Then, we can average the two estimates for each individual and adjust
    the estimated standard errors accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5775862581c9150a1b868f1e86ff8f39.png)'
  prefs: []
  type: TYPE_IMG
- en: Sample splitting procedure, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Generating Splits
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Last but not least, how should the tree be generated? The default rule to generate
    **splits** with the `DecisionTreeRegressor` function is the `squared_error` and
    there is no restriction on the minimum number of observations per leaf. Other
    commonly used rules include, mean absolute error, Gini’s impurity, and Shannon’s
    information. Which one performs better depends on the specific application, but
    the general objective is always prediction accuracy, broadly defined.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our case instead, the objective is **inference**: we want to uncover heterogeneous
    treatment effects that are statistically different from each other. There is no
    value in generating different treatment effects if they are statistically indistinguishable.
    Moreover (but strongly related), when building the tree and generating the data
    partitions, we have to take into account that, since we use honest trees, we will
    use different data to estimate the within-leaf treatment effects.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Athey and Imbens (2016)](https://www.pnas.org/doi/abs/10.1073/pnas.1510489113)
    use a modified version of the [Mean Squared Error (MSE)](https://en.wikipedia.org/wiki/Mean_squared_error)
    as a splitting criterion, the **Expanded Mean Squared Error (EMSE)**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8609eaa4c5d55a4b510cd46719c8ba2a.png)'
  prefs: []
  type: TYPE_IMG
- en: Expanded Root Mean Squared Error, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: where *μ* is the estimated conditional expectation *μ*(*X*) *=* 𝔼 [*Y** | *X*]
    and the difference with respect to the MSE is the additional term *Yᵢ²*, the squared
    outcome variable. In our setting, we can rewrite it as
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f948a88295633b7ec28416436a817605.png)'
  prefs: []
  type: TYPE_IMG
- en: Expanded Root Mean Squared Error for causal trees, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Why is this a sensible error loss? Because we can rewrite it as the expected
    variance of the conditional treatment effects, minus the squared expected value.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/da70d2e82e72ba2f85787338a85176f8.png)'
  prefs: []
  type: TYPE_IMG
- en: Expanded Root Mean Squared Error for causal trees, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: This formulation of the EMSE makes clear that the objective is to **minimize
    the within-leaf variance** of the estimated conditional conditional treatment
    effects *τ*(*X*) (the first term). In other words, small leaves are automatically
    penalized. The second term is just a normalizing factor. Note that both terms
    are unknown and have to be estimated from the training data, used to generate
    the tree.
  prefs: []
  type: TYPE_NORMAL
- en: '**Implementation**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Luckily, there are multiple libraries for causal trees. We import `CausalForestDML`
    from Microsoft's [EconML](https://econml.azurewebsites.net/) library, one of the
    best libraries for causal inference.
  prefs: []
  type: TYPE_NORMAL
- en: We have restricted the number of estimators to 1 to have a single tree instead
    of multiple ones, the so-called [**random forests**](https://en.wikipedia.org/wiki/Random_forest)
    that we will cover in a separate article.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f2df52c573a7a93e249b1a45ceabaeac.png)'
  prefs: []
  type: TYPE_IMG
- en: Estimated causal tree, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the tree representation looks extremely similar to the one we
    got before using the `DecisionTreeRegressor` function. However, now the model
    not only reports estimates of the conditional average treatment effects but also
    the standard errors of the estimates (at the bottom). How were they computed?
  prefs: []
  type: TYPE_NORMAL
- en: Inference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Honest trees, besides improving the out-of-sample prediction accuracy of the
    model, have another great implication: they allow us to **compute standard errors
    as if the tree structure was exogenous**. In fact, since the data used to compute
    the predictions is independent of the data used to build the tree (split the data),
    we can just treat the tree structure as independent from the estimated treatment
    effects. As a consequence, we can estimate the standard errors of the estimates
    as standard errors of difference between sample averages, as in a standard AB
    test.'
  prefs: []
  type: TYPE_NORMAL
- en: If we had used the same data to build the tree and estimate the treatment effects,
    we would have introduced **bias**, because of the spurious correlation between
    the covariates and the outcomes. This bias usually disappears for very large sample
    sizes, but honest trees do not require that.
  prefs: []
  type: TYPE_NORMAL
- en: Performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'How well does the model perform? Since we control the data-generating process,
    we can do something that is not possible with real data: check the predicted treatment
    effects against the true ones. The `add_treatment_effect()` function gives us
    the “true” treatment effects for each observation in the data.'
  prefs: []
  type: TYPE_NORMAL
- en: We can now check how well the causal tree is able to estimate the individual
    treatment effects. Let’s start with the categorical variables. I plot the true
    and estimated average treatment effect conditional on each value of `device`,
    `browser` and `region`.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f3e6cce7dd1271dcdfb076dacf145acb.png)'
  prefs: []
  type: TYPE_IMG
- en: True and estimated treatment effects for each categorical value, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: The causal tree is pretty good at detecting the heterogeneous treatment effects
    for the categorical variables. It overestimates the effect of mobile devices and
    Safari browser but does generally a good job.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, this is also where we expect a tree model to perform particularly
    well: where the effects are **discrete**. How well does it do on our continuous
    variable, time? First, let’s again isolate the predicted treatment effects on
    `time` and ignore the other covariates.'
  prefs: []
  type: TYPE_NORMAL
- en: We now plot the predicted treatment effects against the true ones, along the
    `time` dimension.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1eced6305e633e3542f0a586b28d149f.png)'
  prefs: []
  type: TYPE_IMG
- en: True and estimated treatment effects along the time dimension, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'From the plot, we can appreciate the discrete nature of causal trees: the model
    is only able to split the continuous variable into 4bins. These bins are close
    to the true treatment effects, but they fail to capture a big chunk of the treatment
    effect heterogeneity.'
  prefs: []
  type: TYPE_NORMAL
- en: Can these predictions be improved? The answer is yes, and we will explore how
    in the next post.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article, we have seen how to use causal trees to estimate **heterogeneous
    treatment effects**. The main insight comes from the definition of an auxiliary
    outcome variable that allows us to frame the inference problem as a prediction
    problem. While we can then use any algorithm to predict treatment effects, regression
    trees are particularly useful because of their interpretability, prediction accuracy,
    and feature of generating prediction as subsample averages.
  prefs: []
  type: TYPE_NORMAL
- en: The work by [Athey and Imbens (2016)](https://www.pnas.org/doi/abs/10.1073/pnas.1510489113)
    on regression trees to compute heterogeneous treatment effects brought together
    two separate literatures, causal inference, and machine learning in a very fruitful
    **synergy**. The causal inference literature (re)discovered the inference benefits
    of sample splitting, which allows us to do correct inference even when the data
    partition is complex and hard to analyze. On the other hand, splitting the tree
    generation phase from the within-leaf prediction phase has strong benefits in
    terms of prediction accuracy, by safeguarding against overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: S. Athey, G. Imbens, [Recursive partitioning for heterogeneous causal effects](https://www.pnas.org/doi/abs/10.1073/pnas.1510489113)
    (2016), *PNAS*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: S. Wager, S. Athey, [Estimation and Inference of Heterogeneous Treatment Effects
    using Random Forests](https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1319839)
    (2018), *Journal of the American Statistical Association*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: S. Athey, J. Tibshirani, S. Wager, [Generalized Random Forests](https://projecteuclid.org/journals/annals-of-statistics/volume-47/issue-2/Generalized-random-forests/10.1214/18-AOS1709.full)
    (2019). *The Annals of Statistics*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: M. Oprescu, V. Syrgkanis, Z. Wu, [Orthogonal Random Forest for Causal Inference](http://proceedings.mlr.press/v97/oprescu19a.html?ref=https%3A%2F%2Fgithubhelp.com)
    (2019). *Proceedings of the 36th International Conference on Machine Learning*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Related Articles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[DAGs and Control Variables](/b63dc69e3d8c)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Matching, Weighting, or Regression?](/99bf5cffa0d9)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Understanding Meta Learners](/8a9c1e340832)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Understanding AIPW, the Doubly-Robust Estimator](/ed4097dab27a)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can find the original Jupyter Notebook here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/causal_trees.ipynb](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/causal_trees.ipynb)'
  prefs: []
  type: TYPE_NORMAL
- en: Thank you for reading!
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*I really appreciate it!* 🤗 *If you liked the post and would like to see more,
    consider* [***following me***](https://medium.com/@matteo.courthoud)*. I post
    once a week on topics related to causal inference and data analysis. I try to
    keep my posts simple but precise, always providing code, examples, and simulations.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Also, a small* ***disclaimer****: I write to learn so mistakes are the norm,
    even though I try my best. Please, when you spot them, let me know. I also appreciate
    suggestions on new topics!*'
  prefs: []
  type: TYPE_NORMAL
