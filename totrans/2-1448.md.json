["```py\nx = np.array([0.5, 1.8, 2.4, 3.5, 4.2, 4.8, 5.8, 6.1, 7.2, 8.7, 10])\ny = np.array([0.1, 0.2, 0.3, 0.4, 0.7, 1, 0.9, 1.2, 1.4, 1.8, 10])\n```", "```py\ndef plot_data(x, y):\n    plt.scatter(x, y)\n    plt.xlabel('$x$')\n    plt.ylabel('$y$')\n    plt.grid()\n```", "```py\nplot_data(x, y)\n```", "```py\nfrom sklearn.linear_model import SGDRegressor\n\nX = x.reshape(-1, 1) # Convert x to a matrix with one column\n\nreg = SGDRegressor(loss='squared_error')\nreg.fit(X, y)\n\nreg2 = SGDRegressor(loss='huber')\nreg2.fit(X, y)\n```", "```py\ndef plot_regression_line(x, y, w0, w1, color, label):\n    p_x = np.array([x.min(), x.max()])\n    p_y = w0 + w1 * p_x\n    plt.plot(p_x, p_y, color, label=label)\n```", "```py\nplot_data(x, y)\nplot_regression_line(x, y, reg.intercept_, reg.coef_[0], 'r', label='Squared loss')\nplot_regression_line(x, y, reg2.intercept_, reg2.coef_[0], 'm', label='Huber loss')\nplt.legend()\n```"]