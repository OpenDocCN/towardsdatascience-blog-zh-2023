["```py\noutput = \"Evelyn Hartwell is a Canadian dancer, actor, and choreographer.\" \noutput_embeddings= model.encode(output)\n\narray([ 6.09108340e-03, -8.73148292e-02, -5.30637987e-02, -4.41815751e-03,\n 1.45469820e-02, 4.20340300e-02, 1.99541822e-02, -7.29453489e-02,\nâ€¦\n -4.08893749e-02, -5.41420840e-02, 2.05906332e-02, 9.94611382e-02,\n -2.24501686e-03, 2.29083393e-02, 7.80007839e-02, -9.53456461e-02],\n dtype=float32)\n```", "```py\nfrom sentence_transformers.util import pairwise_cos_sim\nfrom sentence_transformers import SentenceTransformer\n\ndef get_cos_sim(output,sampled_passages):\n    model = SentenceTransformer('all-MiniLM-L6-v2')\n    sentence_embeddings = model.encode(output).reshape(1, -1)\n    sample1_embeddings = model.encode(sampled_passages[0]).reshape(1, -1)\n    sample2_embeddings = model.encode(sampled_passages[1]).reshape(1, -1)\n    sample3_embeddings = model.encode(sampled_passages[2]).reshape(1, -1)\n    cos_sim_with_sample1 = pairwise_cos_sim(\n    sentence_embeddings, sample1_embeddings\n    )\n    cos_sim_with_sample2  = pairwise_cos_sim(\n    sentence_embeddings, sample2_embeddings\n    )\n    cos_sim_with_sample3  = pairwise_cos_sim(\n    sentence_embeddings, sample3_embeddings\n    )\n    cos_sim_mean = (cos_sim_with_sample1 + cos_sim_with_sample2 + cos_sim_with_sample3) / 3\n    cos_sim_mean = cos_sim_mean.item()\n    return round(cos_sim_mean,2)\n```", "```py\ncos_sim_score = get_cos_sim(output, [sample1,sample2,sample3])\n```", "```py\ndef get_bertscore(output, sampled_passages):\n    # spacy sentence tokenization\n    sentences = [sent.text.strip() for sent in nlp(output).sents] \n    selfcheck_bertscore = SelfCheckBERTScore(rescale_with_baseline=True)\n    sent_scores_bertscore = selfcheck_bertscore.predict(\n        sentences = sentences, # list of sentences\n        sampled_passages = sampled_passages, # list of sampled passages\n    )\n    df = pd.DataFrame({\n    'Sentence Number': range(1, len(sent_scores_bertscore) + 1),\n    'Hallucination Score': sent_scores_bertscore\n    })\n    return df\n```", "```py\n['Evelyn Hartwell is an American author, speaker, and life coach.',\n 'She is best known for her book, The Miracle of You: How to Live an Extraordinary Life, which was published in 2007.',\n 'She is a motivational speaker and has been featured on TV, radio, and in many magazines.',\n 'She has authored several books, including How to Make an Impact and The Power of Choice.']\n```", "```py\narray([[0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.]])\n```", "```py\nbertscore_array\narray([[0.43343216, 0\\.        , 0\\.        ],\n       [0.12838356, 0\\.        , 0\\.        ],\n       [0.2571277 , 0\\.        , 0\\.        ],\n       [0.21805632, 0\\.        , 0\\.        ]])\n```", "```py\narray([[0.43343216, 0.34562832, 0.65371764],\n       [0.12838356, 0.28202596, 0.2576825 ],\n       [0.2571277 , 0.48610589, 0.2253703 ],\n       [0.21805632, 0.34698656, 0.28309497]])\n```", "```py\narray([0.47759271, 0.22269734, 0.32286796, 0.28271262])\n```", "```py\ndef get_self_check_nli(output, sampled_passages):\n    # spacy sentence tokenization\n    sentences = [sent.text.strip() for sent in nlp(output).sents] \n    selfcheck_nli = SelfCheckNLI(device=mps_device) # set device to 'cuda' if GPU is available\n    sent_scores_nli = selfcheck_nli.predict(\n        sentences = sentences, # list of sentences\n        sampled_passages = sampled_passages, # list of sampled passages\n    )\n    df = pd.DataFrame({\n    'Sentence Number': range(1, len(sent_scores_nli) + 1),\n    'Probability of Contradiction': sent_scores_nli\n    })\n    return df\n```", "```py\nlogits = model(**inputs).logits # neutral is already removed\nprobs = torch.softmax(logits, dim=-1)\nprob_ = probs[0][1].item() # prob(contradiction)\n```", "```py\ndef llm_evaluate(sentences,sampled_passages):\n    prompt = f\"\"\"You will be provided with a text passage \\\n                and your task is to rate the consistency of that text to \\\n                that of the provided context. Your answer must be only \\\n                a number between 0.0 and 1.0 rounded to the nearest two \\\n                decimal places where 0.0 represents no consistency and \\\n                1.0 represents perfect consistency and similarity. \\n\\n \\\n                Text passage: {sentences}. \\n\\n \\\n                Context: {sampled_passages[0]} \\n\\n \\\n                {sampled_passages[1]} \\n\\n \\\n                {sampled_passages[2]}.\"\"\"\n\n    completion = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"\"},\n        {\"role\": \"user\", \"content\": prompt}\n    ]\n    )\n\n    return completion.choices[0].message.content\n```", "```py\nimport streamlit as st\nimport utils\nimport pandas as pd\n\n# Streamlit app layout\nst.title('Anti-Hallucination Chatbot')\n\n# Text input\nuser_input = st.text_input(\"Enter your text:\")\n\nif user_input:\n\n    prompt = user_input\n\n    output, sampled_passages = utils.get_output_and_samples(prompt)\n\n    # LLM score\n    self_similarity_score = utils.llm_evaluate(output,sampled_passages)\n\n    # Display the output\n    st.write(\"**LLM output:**\")\n    if float(self_similarity_score) > 0.5:\n        st.write(output)\n    else:\n        st.write(\"I'm sorry, but I don't have the specific information required to answer your question accurately. \")\n```"]