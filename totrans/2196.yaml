- en: Understanding Predictive Maintenance — Unit Roots and Stationarity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/understanding-predictive-maintenance-unit-roots-and-stationarity-f05322f7b6df](https://towardsdatascience.com/understanding-predictive-maintenance-unit-roots-and-stationarity-f05322f7b6df)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://marcin-staskopl.medium.com/?source=post_page-----f05322f7b6df--------------------------------)[![Marcin
    Stasko](../Images/5142b9a260a1cce7c6a2ebcc16f46fbb.png)](https://marcin-staskopl.medium.com/?source=post_page-----f05322f7b6df--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f05322f7b6df--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f05322f7b6df--------------------------------)
    [Marcin Stasko](https://marcin-staskopl.medium.com/?source=post_page-----f05322f7b6df--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f05322f7b6df--------------------------------)
    ·13 min read·Nov 13, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2fe2b9db20b9852d4ce6f3bfb405bd63.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Emma Gossett](https://unsplash.com/@emmagossett?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Article Purpose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article, we’re diving into the critical concepts of unit roots and stationarity.
    Buckle up for an exploration into why checking stationarity is crucial, what unit
    roots are, and how these elements play a key role in our predictive maintenance
    arsenal. We will also master the chaos!
  prefs: []
  type: TYPE_NORMAL
- en: This article is part of the series Understanding Predictive Maintenance. I plan
    to create the entire series in a similar style.
  prefs: []
  type: TYPE_NORMAL
- en: '[Check the whole series in this link](https://marcin-staskopl.medium.com/list/understanding-predictive-maintenance-series-e1f44d8a0cc3).
    Ensure you don’t miss out on new articles by following me.'
  prefs: []
  type: TYPE_NORMAL
- en: Data Stationarity — hide and seek analytical game
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/9cb429f26f1318dd3344ef4e4f314a93.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Mitchell Luo](https://unsplash.com/@mitchel3uo?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Ever wondered if your data is playing a game of hide and seek? Let’s cut to
    the chase — we’re talking about stationarity. It’s not just a fancy term; it’s
    the secret sauce to understanding how stable and predictable your time-dependent
    data really is. Buckle up as we explore why data stationarity is the game-changer
    in modeling and forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: Key Rules of Stationarity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Constant Mean**: A stationary time series should exhibit a consistent average
    value over time. If the mean changes, it suggests a shift in the underlying behavior
    of the process.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Constant Variance**: The variance of the time series, representing the spread
    of data points, should remain constant. Fluctuations in variance can make it challenging
    to make accurate predictions.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Constant Autocorrelation**: Autocorrelation measures the correlation between
    a time series and its lagged values. In a stationary series, the strength and
    pattern of autocorrelation should be consistent throughout.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Just “*stability*” of statistical properties.
  prefs: []
  type: TYPE_NORMAL
- en: Why Stationarity is a Big Deal
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine your predictive models as expert navigators sailing through the sea
    of data. To navigate smoothly, they prefer calm waters — that’s where stationarity
    comes in. Stationary data is like a serene ocean, where patterns stay consistent.
    But, if your data is a stormy sea with waves of ups and downs (non-stationary),
    accurate predictions become a real challenge. That’s why we need to spot these
    storms and transform our data into a peaceful pond for effective time series analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Real-world Implications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data stationarity isn’t just a tech thing; it’s everywhere, influencing decisions
    from finance to predicting the weather. In finance, where precision is key for
    risk and return estimates, assuming stationarity is like having a reliable compass.
    Climate scientists rely on stationary models to predict long-term weather patterns
    — it’s like having a trustworthy weather app for Earth’s future.
  prefs: []
  type: TYPE_NORMAL
- en: Journey to Insightful Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Getting our data stationary is more than a tech quest; it’s an adventure toward
    clarity. It’s like transforming a chaotic treasure map into a clear guide that
    helps analysts and decision-makers make sense of it all. In the dynamic world
    of time-dependent data, stationarity becomes our trusty map, guiding us to understand
    the patterns beneath the surface and making our journey through data waters much
    smoother.
  prefs: []
  type: TYPE_NORMAL
- en: Alright, now that we get why it’s cool to have calm data, let’s learn how to
    make it chill. But wait, before we get our hands dirty by code, let me introduce
    you to something called “unit roots.” Think of them as the special ingredients
    that affect how our data behaves. Knowing about unit roots is like having a secret
    recipe to turn our wavy, wild data into a smooth pond, ready for us to dive in
    and explore. So, get ready for the next part of our journey!
  prefs: []
  type: TYPE_NORMAL
- en: Unit Roots — Mischievous Time Travelers in Data’s History Book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/fee7bbfec10ec66cade63856833e9962.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Andy Beales](https://unsplash.com/@andybeales?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Unit roots are fundamental concepts in time series analysis, playing a pivotal
    role in understanding the behavior and characteristics of real-world data. In
    this exploration, we’ll delve into what unit roots are, why they are important
    in real data analysis, and how they influence the predictive maintenance landscape.
    Of course, we will do some experiments in the hands-on section.
  prefs: []
  type: TYPE_NORMAL
- en: What are unit roots?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A unit root in a time series variable implies a stochastic process where the
    variable’s value at any given time is influenced by its past values. Formally,
    a unit root suggests non-stationarity, indicating that the variable does not revert
    to a constant mean over time.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d91ab44242de93c2139cc47d529f2e22.png)'
  prefs: []
  type: TYPE_IMG
- en: Unit root mathematical explanation
  prefs: []
  type: TYPE_NORMAL
- en: The presence of unit roots introduces persistence into the time series, leading
    to challenges in modeling and forecasting. The Augmented Dickey-Fuller (ADF) test
    and other statistical methods are employed to detect the existence of unit roots,
    providing a quantitative measure of non-stationarity.
  prefs: []
  type: TYPE_NORMAL
- en: Unit roots are like the storytellers of our data, weaving narratives that extend
    beyond individual moments and create a continuous storyline. They signify the
    persistence of historical influences, introducing an element of memory into the
    numerical fabric of our datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine your dataset as a historical novel, with each data point representing
    a chapter in the unfolding tale. Unit roots, in this context, are the recurring
    motifs and characters that leave an indelible mark on the narrative, guiding the
    plot with a subtle yet consistent influence.
  prefs: []
  type: TYPE_NORMAL
- en: Why it is important for us?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Understanding unit roots is fundamental for time series analysts and modelers.
    Non-stationary data poses challenges, as traditional models often assume stationarity
    for accurate predictions. Analysts must address unit roots by employing transformations,
    such as differencing, to induce stationarity and facilitate model development.
  prefs: []
  type: TYPE_NORMAL
- en: In predictive maintenance scenarios, unit roots play a crucial role in ensuring
    the accuracy of forecasting models. The long-term influence embedded in unit roots
    can significantly impact the reliability of predictions, making their identification
    and mitigation paramount for effective maintenance strategies.
  prefs: []
  type: TYPE_NORMAL
- en: As we navigate this technical exploration, we will delve deeper into unit root
    testing methodologies, interpret the results, and explore strategies for handling
    non-stationary time series data. The theoretical underpinnings of unit roots provide
    a solid foundation for the practical applications that follow in our analytical
    journey.
  prefs: []
  type: TYPE_NORMAL
- en: '**Augumented Dickey Fuller (ADF) helps us**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eed6bc49efe1774e36f19abbe8c5f35e.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [MD_JERRY](https://unsplash.com/@salijareer?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you have a line of ants moving in a certain direction. The ADF test
    checks if the ants are marching with a purpose (stationary) or if they’re randomly
    scattered all over the place (non-stationary).
  prefs: []
  type: TYPE_NORMAL
- en: 'The ADF test involves a bit of math, but let’s simplify it:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Null Hypothesis (`*H0*`): This is like the default assumption. The null hypothesis
    for ADF is that the data has a unit root, which means it’s non-stationary. It’s
    like saying the ants are wandering randomly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**H0:The data has a unit root (non-stationary)**'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Alternative Hypothesis (`*H1*`): This is what we’re trying to prove. The alternative
    hypothesis is that the data is stationary, like the ants marching in a clear line.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**H1:The data is stationary**'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Test Statistic: The ADF test calculates a number called the test statistic.
    If this number is very small, it suggests that the data is likely stationary.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'P-value: This is a probability score. If the *p-value* is small (less than
    a certain threshold, like 0.05), we reject the null hypothesis and accept the
    alternative, saying our data is probably stationary.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This is not very complicated, just run the tests and check P-value
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'You will probably most of the time use adf like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: But I will explain what is behind these variables
  prefs: []
  type: TYPE_NORMAL
- en: '`adf_statistic`: The test statistic from the ADF test, indicating the strength
    of evidence against the null hypothesis of non-stationarity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`adf_p_value`: The p-value associated with the null hypothesis. A lower p-value
    suggests stronger evidence against non-stationarity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`adf_lags`: The number of lags used in the test.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`adf_nobs`: The number of observations used in the ADF test.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`adf_critical_values`: The critical values for the test statistic at various
    significance levels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`adf_reg_results`: The regression results, which provide additional information
    about the linear regression performed during the test.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While chaos might seem daunting, we can transform it into our ally by understanding
    and harnessing its patterns. In the realm of data and analysis, chaos can be a
    powerful force that, when properly channeled, provides insights, predictions,
    and a clearer path forward. It’s all about turning the unpredictable into an advantage,
    making chaos our strategic companion in the journey of exploration and understanding.
  prefs: []
  type: TYPE_NORMAL
- en: How “random” is your random?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s kick things off by generating a straightforward stationary series, but
    here’s a heads-up: not all “random” is created equal. There are two main flavors
    of randomness — true random and pseudorandom. Chances are, you’ve been hanging
    out with pseudorandom more often because that’s the go-to for computers.'
  prefs: []
  type: TYPE_NORMAL
- en: In computing, generating truly random numbers is a challenge because computers
    are deterministic machines. Pseudorandom numbers, as the name suggests, are not
    genuinely random but instead are generated by algorithms that simulate randomness.
    These algorithms start with an initial value called a seed and use it to produce
    a sequence of numbers that appears random.
  prefs: []
  type: TYPE_NORMAL
- en: Seeds
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The seed is a crucial element in pseudorandom number generation. It serves as
    the starting point for the algorithm. If you use the same seed, you’ll get the
    same sequence of pseudorandom numbers every time. This determinism can be advantageous
    in scenarios where you want reproducibility. For example, if you’re running a
    simulation or an experiment that involves randomness, setting the seed allows
    you to recreate the exact sequence of random numbers.
  prefs: []
  type: TYPE_NORMAL
- en: On the flip side, changing the seed results in a different sequence of pseudorandom
    numbers. This property is often used to introduce variability in simulations or
    to provide different initial conditions for algorithms that use randomness.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, pseudorandom numbers are generated by algorithms, and the seed is
    the starting point for these algorithms. Controlling the seed allows you to control
    the sequence of pseudorandom numbers, providing a balance between determinism
    and variability in computer-generated randomness.
  prefs: []
  type: TYPE_NORMAL
- en: Time to generate our pseudorandom distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Can we use true randomness?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/b714019efbe74c0dd688281439b26f7b.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [aj_aaaab](https://unsplash.com/@ajing_?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Now we might feel suprised that even randomness we are affecting most of the
    time is the deterministic random. But can we make true randomness, ensuring that
    no determism is behind it?
  prefs: []
  type: TYPE_NORMAL
- en: Well, good news! We can tap into something truly physical — atmospheric noise.
    Remember those flickering black and white dots on your TV screen? That’s our atmospheric
    noise, and we’re going to harness it to whip up some genuine randomness. So, your
    TV’s not just for shows; it’s your ticket out of the deterministic world.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Using this function we can genarate true randomness, Horray!
  prefs: []
  type: TYPE_NORMAL
- en: Stationarity check
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First lets generate the series.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Create results plot.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/2884b8655c81cd03b40717e21f56856d.png)'
  prefs: []
  type: TYPE_IMG
- en: Hmm “spectacular”
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/0d12ca08c2de448701e0435bbe84f22f.png)'
  prefs: []
  type: TYPE_IMG
- en: Results
  prefs: []
  type: TYPE_NORMAL
- en: When the p-value is very small (**<0.05**), it provides evidence against the
    null hypothesis, suggesting that your data is likely **stationary**.
  prefs: []
  type: TYPE_NORMAL
- en: So, in this case, with a p-value much smaller than 0.05, you have the confidence
    to say, “Yes, our data is stationary.”
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s take a moment to crunch the numbers. Our pseudorandom boasts a P-value
    approximately 2 million times smaller than the truly random one.
  prefs: []
  type: TYPE_NORMAL
- en: Why does this happen? Pseudorandom numbers are generated by algorithms, introducing
    a level of determinism. These algorithms can unintentionally introduce patterns
    or structure into the data. On the other hand, truly random data, like atmospheric
    noise, is more likely to exhibit the characteristics of pure randomness. The ADF
    test, keen on detecting patterns indicative of non-stationarity, may find less
    evidence of such patterns in truly random data, leading to a relatively higher
    P-value.
  prefs: []
  type: TYPE_NORMAL
- en: Hand`s on experience
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/ee9374aaf65da24e2be4fc1b2e7925cc.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Eddie Kopp](https://unsplash.com/@fiveohfilms?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Now it is the time to make hands dirty by code. We will run some experiments
    to help you get fammilarized with article concepts. I reccomend you to reproduce
    it. Before we will dive deeply into stationarity I want to ask you question.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ec2a77859fa7ef8a56f202f2ff72f769.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Ian Barsby](https://unsplash.com/@ian_barsby?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: And now we will add couple of examples how we can make this data not stationary,
    we are going to break our key rules of stationarity. After explanation we will
    plot all of them.
  prefs: []
  type: TYPE_NORMAL
- en: Linear Trend (Non-Constant Mean)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Introducing a linear trend to violate the constant mean rule means adding a
    systematic increase or decrease over time. In the case of the non-stationary linear
    trend series, the values linearly increase over time. This violates the constant
    mean rule because the average value of the series is changing, indicating a shift
    in the underlying behavior of the process. Unit roots, in this context, contribute
    to the persistence of the linear trend, causing the variable’s value at any given
    time to be influenced by its past values.
  prefs: []
  type: TYPE_NORMAL
- en: Sine Amplitude **(Non-Constant Variance)**
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Adding a sinusoidal component with increasing amplitude violates the constant
    variance rule. In the non-stationary seasonal component series, the amplitude
    of the sinusoidal component grows linearly with time. This results in fluctuations
    in the spread of data points, making the variance non-constant. Unit roots contribute
    to the persistence of the seasonal component, influencing the variance to vary
    as the amplitude changes.
  prefs: []
  type: TYPE_NORMAL
- en: Exponential Growth **(Non-Constant Autocorrelation)**
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Incorporating an exponential growth pattern violates the constant autocorrelation
    rule. The non-stationary expanding amplitude series exhibits exponential growth,
    causing the autocorrelation pattern to change with increasing values. Unit roots
    play a role in introducing persistence into the time series, leading to challenges
    in modeling and forecasting. The presence of unit roots implies non-stationarity,
    indicating that the variable does not revert to a constant mean over time.
  prefs: []
  type: TYPE_NORMAL
- en: Start the experimets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Execute the code and generate the timeseries and plot the results.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b0baea2e0e391683785a2ee71085b3b9.png)'
  prefs: []
  type: TYPE_IMG
- en: Spotting a linear trend or exponential growth during exploratory data analysis
    is relatively straightforward, as these patterns exhibit clear visual cues. However,
    distinguishing between stationary and non-stationary states becomes challenging
    when dealing with sinusoidal amplitude. Visually, it’s hard to differentiate whether
    the amplitude is stationary or non-stationary just by looking at the data.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/18f24cb8512e83ef1e603fdcdd3649dc.png)'
  prefs: []
  type: TYPE_IMG
- en: This case will show the power of statistical tests. We have powerfull tools
    in our hands.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/0345853e1acabce5a6111e30e3e7b0dd.png)'
  prefs: []
  type: TYPE_IMG
- en: The test results are clear only stationary series is stationary in terms of
    ADF test
  prefs: []
  type: TYPE_NORMAL
- en: The ADF test provides a clear distinction between stationary and non-stationary
    time series. In the first case, we can confidently reject the null hypothesis,
    indicating that the time series is stationary. However, for the other cases, we
    must accept the null hypothesis, concluding that the data is non-stationary. Specifically,
    in the case of sinusoidal amplitude, even though the non-stationarity is visually
    evident, the ADF test confirms our observation by not allowing us to reject the
    null hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: Practice the transformation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, let’s have some fun with transformations and attempt to convert our non-stationary
    time series into a stationary one — like a bit of reverse engineering. In real-life
    scenarios, determining the exact transformation needed is often a trial-and-error
    process. I recommend conducting exploratory data analysis, plotting the time series,
    and making empirical attempts. If a transformation renders the series stationary,
    you not only achieve stationarity but also gain valuable insights into the characteristics
    of your data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Having defined our transformation functions, it’s time to put them to work.
    Let’s apply these transformations to our non-stationary time series and see if
    we can successfully induce stationarity.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/e2de2a85964f09574b18335283e6f773.png)'
  prefs: []
  type: TYPE_IMG
- en: Now my data is stationary horray!
  prefs: []
  type: TYPE_NORMAL
- en: 'And how this data looks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/38f20fa76291050df05604acc80bc8ee.png)'
  prefs: []
  type: TYPE_IMG
- en: Great news! With our data now stationary, we confidently reject the null hypothesis
    in each case. Now, for a bit of fun, I’ll take on the challenge of reverse engineering
    your random generation iteration with the given seed. Let’s see if I can unravel
    the mystery! 😄
  prefs: []
  type: TYPE_NORMAL
- en: '[Check the whole series in this link](https://marcin-staskopl.medium.com/list/understanding-predictive-maintenance-series-e1f44d8a0cc3).
    Ensure you don’t miss out on new articles by following me.'
  prefs: []
  type: TYPE_NORMAL
