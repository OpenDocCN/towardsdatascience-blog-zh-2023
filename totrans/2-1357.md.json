["```py\n$ pip install torch -U\n```", "```py\nimport torch\n\nx = torch.rand(5, 3)\nprint(x)\n\n>>> tensor([[0.3890, 0.6087, 0.2300],\n        [0.1866, 0.4871, 0.9468],\n        [0.2254, 0.7217, 0.4173],\n        [0.1243, 0.1482, 0.6797],\n        [0.2430, 0.4608, 0.8886]])\n```", "```py\nimport torch\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.datasets import load_breast_cancer\n\nimport matplotlib.pyplot as plt\n\nbreast_cancer_dataset = load_breast_cancer(as_frame=True, return_X_y=True)\n```", "```py\ndf = breast_cancer_dataset[0]\ndf['target'] = breast_cancer_dataset[1]\ndf\n```", "```py\nimport sweetviz as sv\n\neda_report = sv.analyze(df)\neda_report.show_notebook()\n```", "```py\nimport seaborn as sns\nfrom sklearn import decomposition\n\npca = decomposition.PCA(n_components=2)\n\nX = df.drop(\"target\", axis=1).values\ny = df['target'].values\n\nvecs = pca.fit_transform(X)\nx0 = vecs[:, 0]\nx1 = vecs[:, 1]\n\nsns.set_style(\"whitegrid\")\nsns.scatterplot(x=x0, y=x1, hue=y)\nplt.title(\"Proiezione PCA\")\nplt.xlabel(\"PCA 1\")\nplt.ylabel(\"PCA 2\")\nplt.xticks([])\nplt.yticks([])\nplt.show()\n```", "```py\nfrom torch.utils.data import Dataset\n\nclass BreastCancerDataset(Dataset):\n    def __init__(self, X, y):\n        # create feature tensors\n        self.features = torch.tensor(X, dtype=torch.float32)\n        # create label tensors\n        self.labels = torch.tensor(y, dtype=torch.long) \n\n    def __len__(self):\n        # we define a method to retrieve the length of the dataset\n        return self.features.shape[0]\n\n    def __getitem__(self, idx):\n        # necessary override of the __getitem__ method which helps to index our data\n        x = self.features[idx]\n        y = self.labels[idx]\n        return x, y\n```", "```py\nfrom sklearn import model_selection\n\ntrain_ratio = 0.50\nvalidation_ratio = 0.20\ntest_ratio = 0.20\n\nx_train, x_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=1 - train_ratio)\nx_val, x_test, y_val, y_test = model_selection.train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n\nprint(x_train.shape, x_val.shape, x_test.shape)\n\n>>> (284, 30) (142, 30) (143, 30)\n```", "```py\nfrom sklearn import preprocessing\n\nscaler = preprocessing.StandardScaler()\n\nx_train_scaled = scaler.fit_transform(x_train)\nx_val_scaled = scaler.transform(x_val)\nx_test_scaled = scaler.transform(x_test)\n```", "```py\ntrain_dataset = BreastCancerDataset(x_train_scaled, y_train)\nval_dataset = BreastCancerDataset(x_val_scaled, y_val)\ntest_dataset = BreastCancerDataset(x_test_scaled, y_test)\n```", "```py\nfrom torch.utils.data import DataLoader\n\ntrain_loader = DataLoader(\n    dataset=train_dataset,\n    batch_size=16,\n    shuffle=True,\n    drop_last=True\n)\n\nval_loader = DataLoader(\n    dataset=val_dataset,\n    batch_size=16,\n    shuffle=False,\n    drop_last=True\n)\n\ntest_loader = DataLoader(\n    dataset=test_dataset,\n    batch_size=16,\n    shuffle=False,\n    drop_last=True\n)\n```", "```py\nclass LogisticRegression(nn.Module):\n    \"\"\"\n    Our neural network accepts num_features and num_classes.\n\n    num_features - number of features to learn from\n    num_classes: number of classes in output to expect (in this case, 1 or 2, since the output is binary (0 or 1))\n    \"\"\"\n\n    def __init__(self, num_features, num_classes):\n        super().__init__() # initialize the init method of nn.Module\n\n        self.num_features = num_features\n        self.num_classes = num_classes\n\n        # create a single layer of neurons on which to apply the log reg\n        self.linear1 = nn.Linear(in_features=num_features, out_features=num_classes) \n\n    def forward(self, x):\n        logits = self.linear1(x) # pass our data through the layer\n        probs = torch.sigmoid(logits) # we apply a sigmoid function to obtain the probabilities of belonging to a class (0 or 1)\n        return probs # return probabilities\n```", "```py\ndef compute_accuracy(model, dataloader):\n    \"\"\"\n    This function puts the model in evaluation mode (model.eval()) and calculates the accuracy with respect to the input dataloader\n    \"\"\"\n    model = model.eval()\n    correct = 0\n    total_examples = 0\n    for idx, (features, labels) in enumerate(dataloader):\n        with torch.no_grad():\n            logits = model(features)\n        predictions = torch.where(logits > 0.5, 1, 0)\n        lab = labels.view(predictions.shape)\n        comparison = lab == predictions\n\n        correct += torch.sum(comparison)\n        total_examples += len(comparison)\n    return correct / total_examples\n\ndef plot_results(train_loss, val_loss, train_acc, val_acc):\n    \"\"\"\n    This function takes lists of values and creates side-by-side graphs to show training and validation performance\n    \"\"\"\n    fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n    ax[0].plot(\n        train_loss, label=\"train\", color=\"red\", linestyle=\"--\", linewidth=2, alpha=0.5\n    )\n    ax[0].plot(\n        val_loss, label=\"val\", color=\"blue\", linestyle=\"--\", linewidth=2, alpha=0.5\n    )\n    ax[0].set_xlabel(\"Epoch\")\n    ax[0].set_ylabel(\"Loss\")\n    ax[0].legend()\n    ax[1].plot(\n        train_acc, label=\"train\", color=\"red\", linestyle=\"--\", linewidth=2, alpha=0.5\n    )\n    ax[1].plot(\n        val_acc, label=\"val\", color=\"blue\", linestyle=\"--\", linewidth=2, alpha=0.5\n    )\n    ax[1].set_xlabel(\"Epoch\")\n    ax[1].set_ylabel(\"Accuracy\")\n    ax[1].legend()\n    plt.show()\n```", "```py\nimport torch.nn.functional as F\n\nmodel = LogisticRegression(num_features=x_train_scaled.shape[1], num_classes=1)\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n\nnum_epochs = 10\n\ntrain_losses, val_losses = [], []\ntrain_accs, val_accs = [], []\n\nfor epoch in range(num_epochs):\n\n    model = model.train()\n    t_loss_list, v_loss_list = [], []\n    for batch_idx, (features, labels) in enumerate(train_loader):\n\n        train_probs = model(features)\n        train_loss = F.binary_cross_entropy(train_probs, labels.view(train_probs.shape))\n\n        optimizer.zero_grad()\n        train_loss.backward()\n        optimizer.step()\n\n        if batch_idx % 10 == 0:\n            print(\n                f\"Epoch {epoch+1:02d}/{num_epochs:02d}\"\n                f\" | Batch {batch_idx:02d}/{len(train_loader):02d}\"\n                f\" | Train Loss {train_loss:.3f}\"\n            )\n\n        t_loss_list.append(train_loss.item())\n\n    model = model.eval()\n    for batch_idx, (features, labels) in enumerate(val_loader):\n        with torch.no_grad():\n            val_probs = model(features)\n            val_loss = F.binary_cross_entropy(val_probs, labels.view(val_probs.shape))\n            v_loss_list.append(val_loss.item())\n\n    train_losses.append(np.mean(t_loss_list))\n    val_losses.append(np.mean(v_loss_list))\n\n    train_acc = compute_accuracy(model, train_loader)\n    val_acc = compute_accuracy(model, val_loader)\n\n    train_accs.append(train_acc)\n    val_accs.append(val_acc)\n\n    print(\n        f\"Train accuracy: {train_acc:.2f}\"\n        f\" | Val accuracy: {val_acc:.2f}\"\n    )\n```", "```py\nplot_results(train_losses, val_losses, train_accs, val_accs)\n```", "```py\n# we transform all our features with the scaler\nX_scaled_all = scaler.transform(X)\n\n# transform in tensors\nX_scaled_all_tensors = torch.tensor(X_scaled_all, dtype=torch.float32)\n\n# we set the model in inference mode and create the predictions\nwith torch.inference_mode():\n    logits = model(X_scaled_all_tensors)\n    predictions = torch.where(logits > 0.5, 1, 0)\n\ndf['predictions'] = predictions.numpy().flatten()\n```", "```py\nfrom sklearn import metrics\nfrom pprint import pprint\n\npprint(metrics.classification_report(y_pred=df.predictions, y_true=df.target))\n```", "```py\nmetrics.confusion_matrix(y_pred=df.predictions, y_true=df.target)\n\n>>> array([[197,  15],\n       [ 13, 344]])\n```", "```py\ndef plot_boundary(model):\n\n    w1 = model.linear1.weight[0][0].detach()\n    w2 = model.linear1.weight[0][1].detach()\n    b = model.linear1.bias[0].detach()\n\n    x1_min = -1000\n    x2_min = (-(w1 * x1_min) - b) / w2\n\n    x1_max = 1000\n    x2_max = (-(w1 * x1_max) - b) / w2\n\n    return x1_min, x1_max, x2_min, x2_max\n\nsns.scatterplot(x=x0, y=x1, hue=y)\nplt.title(\"PCA Projection\")\nplt.xlabel(\"PCA 1\")\nplt.ylabel(\"PCA 2\")\nplt.xticks([])\nplt.yticks([])\nplt.plot([x1_min, x1_max], [x2_min, x2_max], color=\"k\", label=\"Classification\", linestyle=\"--\")\nplt.legend()\nplt.show()\n```"]