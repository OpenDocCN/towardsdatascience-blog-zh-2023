- en: 'Emergent Abilities in AI: Are We Chasing a Myth?'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/emergent-abilities-in-ai-are-we-chasing-a-myth-fead754a1bf9](https://towardsdatascience.com/emergent-abilities-in-ai-are-we-chasing-a-myth-fead754a1bf9)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Opinion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Changing Perspective on Large Language Models emerging properties
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://salvatore-raieli.medium.com/?source=post_page-----fead754a1bf9--------------------------------)[![Salvatore
    Raieli](../Images/6bb4520e2df40d20283e7283141b5e06.png)](https://salvatore-raieli.medium.com/?source=post_page-----fead754a1bf9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fead754a1bf9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fead754a1bf9--------------------------------)
    [Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page-----fead754a1bf9--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fead754a1bf9--------------------------------)
    ·11 min read·May 16, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6e488a59261a210747293aba21891933.png)'
  prefs: []
  type: TYPE_IMG
- en: image by the author using DALL-E
  prefs: []
  type: TYPE_NORMAL
- en: The emergent properties of a model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Emergent properties](https://en.wikipedia.org/wiki/Emergence) are not only
    a concept that belongs to artificial intelligence but to all disciplines (from
    physics to biology). This concept has always fascinated scientists, both in describing
    and trying to understand the origin. Nobel Prize-winning physicist [P.W. Anderson](https://en.wikipedia.org/wiki/Philip_W._Anderson)
    synthesized the idea with “More Is Different.” In a certain, sense it can be defined
    as an emergent property, a property that appears as the complexity of the system
    increases and cannot be predicted.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, you can encode information with a small molecule, but DNA (a large
    molecule) is encoding a genome. Or a [small amount of Uranium](https://bounded-regret.ghost.io/future-ml-systems-will-be-qualitatively-different/)
    is not leading to a nuclear reaction.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/42e267a8f3a5e72ec1c124b73371d304.png)'
  prefs: []
  type: TYPE_IMG
- en: '“The formation of complex symmetrical and [fractal](https://en.wikipedia.org/wiki/Fractal)
    [patterns](https://en.wikipedia.org/wiki/Patterns_in_nature) in [snowflakes](https://en.wikipedia.org/wiki/Snowflake)
    exemplifies emergence in a physical system”. image source: [here](https://en.wikipedia.org/wiki/Emergence)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Recently the same behavior has been observed with artificial intelligence models,
    one of the most commonly [used definitions being](https://arxiv.org/abs/2206.07682):
    “An ability is emergent if it is not present in smaller models but is present
    in larger models.”'
  prefs: []
  type: TYPE_NORMAL
- en: What does this mean and how is it observed?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'OpenAI stated in an article that the performance of a model follows a [scaling
    law](https://arxiv.org/abs/2001.08361): the more data and parameters, the better
    the performance. In the case of emergent properties, what is expected is a particular
    pattern: as the number of parameters increases, performance is almost random until
    at a certain threshold a certain property is observed (performance begins to improve
    noticeably). Basically, we see a sharp turn of the curve (called phase transition).
    This also is called emergent, because it is impossible to predict by examining
    a small-scale model.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/57f2aacc51ebcdbc8a2f20c0192b861b.png)'
  prefs: []
  type: TYPE_IMG
- en: Emergent abilities of large language models. image source ([here](https://arxiv.org/abs/2304.15004))
  prefs: []
  type: TYPE_NORMAL
- en: 'So in short, we can say that a property is considered emergent if it satisfies
    these two conditions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sharpness**, the transition is discontinuous between being present or not
    present.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unpredictability**, its appearance cannot be predicted as parameters increase'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In addition, scaling a transformer mainly takes into consideration three factors:
    the amount of computation, the number of model parameters, and the training dataset
    size.'
  prefs: []
  type: TYPE_NORMAL
- en: All three factors make a model expensive. On the other hand, these properties
    are particularly sought after and have also been used as a justification for increasing
    the number of parameters (despite the fact that models are not trained optimally).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a6df68ed07d1dffe957909f7772c0abf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/abs/2206.07682)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Several studies have also focused on why these properties emerge, why they
    do so in this way, and why at a particular threshold. According to some the emergence
    of some properties can be predicted:'
  prefs: []
  type: TYPE_NORMAL
- en: For instance, if a multi-step reasoning task requires l steps of sequential
    computation, this might require a model with a depth of at least O (l) layers.
    ([source](https://arxiv.org/abs/2206.07682))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Alternative explanations have been proposed such as that the larger number of
    parameters aids memorization. The model gains knowledge as the data increases
    and at some point reaches critical mass to be able to support that property
  prefs: []
  type: TYPE_NORMAL
- en: In addition, some authors have proposed that different architectures and better
    data quality could lead to the appearance of these properties in even smaller
    models.
  prefs: []
  type: TYPE_NORMAL
- en: This was noted with LLaMA, where a significantly smaller model of GPT-3 showed
    comparable properties and performance.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/mlearning-ai/metas-llama-a-small-language-model-beating-giants-5065948e0b7f?source=post_page-----fead754a1bf9--------------------------------)
    [## META’s LLaMA: A small language model beating giants'
  prefs: []
  type: TYPE_NORMAL
- en: META open-source model will help us to understand how LMs biases arise
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/mlearning-ai/metas-llama-a-small-language-model-beating-giants-5065948e0b7f?source=post_page-----fead754a1bf9--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: In any case, the question remains, why do these properties appear?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Anthropic in one study states that:'
  prefs: []
  type: TYPE_NORMAL
- en: large generative models have a paradoxical combination of high predictability
    — model loss improves in relation to resources expended on training, and tends
    to correlate loosely with improved performance on many tasks — and high unpredictability
    — specific model capabilities, inputs, and outputs can’t be predicted ahead of
    time ([source](https://arxiv.org/abs/2202.07785))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In simpler words, for an [LLM](https://en.wikipedia.org/wiki/Large_language_model)
    there are things we can predict and things we cannot predict. For example, the
    scaling law allows us to predict that increasing the number of parameters will
    improve performance in scale, but at the same time, we cannot predict the emergence
    of certain properties that instead appear abruptly as the parameters increase.
  prefs: []
  type: TYPE_NORMAL
- en: So according to this principle, we should not even try to predict them.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a9a342a4d06704e5c32536726f596a50.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Scaling laws reliably predict that model performance. image source: [here](https://arxiv.org/abs/2202.07785)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b32237eddc17eb0befa89620880d7e7a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Three examples of abrupt specific capability scaling properties. image source:
    [here](https://arxiv.org/abs/2202.07785)'
  prefs: []
  type: TYPE_NORMAL
- en: Why are we so interested in predicting these properties?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The first reason is pure economics: **if a property emerges only at a certain
    number of parameters, we cannot use a smaller model**. This significantly increases
    the cost of both training and hardware. On the other hand, if a property cannot
    be predicted, we cannot even estimate the cost of obtaining it.'
  prefs: []
  type: TYPE_NORMAL
- en: Second, it justifies the inordinate increase in parameters in the search for
    new properties that appear at trillions of parameters. After all, this may be
    the only way to be able to obtain certain properties.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, this presents a safety problem, as we cannot predict what property
    a model will have at a certain scale. A model may develop problematic properties
    and may not be safe for deployment. Also, models this large are more difficult
    to test for bias and harm.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, scaling law and emergent properties have been one of the reasons for
    the rush to large models.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b7db443fa6264c45636e608fe0a5efd8.png)'
  prefs: []
  type: TYPE_IMG
- en: This opens a scary scenario, on the one hand, we have an explosion of open-source
    models, a reduction in the cost of their training, and an increase in the use
    of [chatbots](https://medium.com/data-driven-fiction/everything-but-everything-you-need-to-know-about-chatgpt-546af7153ee2).
    But on the other hand, we have no way to predict the properties of these models.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/the-infinite-babel-library-of-llms-90e203b2f6b0?source=post_page-----fead754a1bf9--------------------------------)
    [## The Infinite Babel Library of LLMs'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open-source, data, and attention: How the future of LLMs will change'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/the-infinite-babel-library-of-llms-90e203b2f6b0?source=post_page-----fead754a1bf9--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: What if emerging properties were a mirage?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/9e03a1cca803f04578ce99b97125d168.png)'
  prefs: []
  type: TYPE_IMG
- en: image by [Nick Fewings](https://unsplash.com/fr/@jannerboy62) on Unsplash
  prefs: []
  type: TYPE_NORMAL
- en: In 2020, Google researchers realized the potential of LLMs and predicted that
    they would be transformative. So they asked the community to provide examples
    of tasks that were both different and difficult and that could then be used to
    test the capabilities of an LLM. Thus was born the [Beyond the Imitation Game
    Benchmark](https://arxiv.org/abs/2206.04615) (BIG-bench) project.
  prefs: []
  type: TYPE_NORMAL
- en: This project was actually also focused on studying emergent and surprising properties
    and trying to be able to understand their origin.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dd13fb32b2b62412ceb15230b36a25bc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image source: [here](https://arxiv.org/abs/2206.04615)'
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, the dataset and article discussed the emergence of probabilities and
    tried to provide explanations. For example, models over ten billion parameters
    could solve three-digit addition or two-digit multiplication problems.
  prefs: []
  type: TYPE_NORMAL
- en: Building on this article, researchers at Stanford questioned in a recent paper
    the very concept of emergent property for a language model.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://arxiv.org/abs/2304.15004?source=post_page-----fead754a1bf9--------------------------------)
    [## Are Emergent Abilities of Large Language Models a Mirage?'
  prefs: []
  type: TYPE_NORMAL
- en: Recent work claims that large language models display emergent abilities, abilities
    not present in smaller-scale models…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: arxiv.org](https://arxiv.org/abs/2304.15004?source=post_page-----fead754a1bf9--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: In fact, the authors noticed that emergent properties seemed to appear only
    with metrics that were [nonlinear](https://en.wikipedia.org/wiki/Nonlinear_system)
    or otherwise discontinuous.
  prefs: []
  type: TYPE_NORMAL
- en: The authors provided an alternative hypothesis to the emergence of properties.
    according to them is the choice of performance measurement. In other, words the
    error per-tokens grows smoothly, continuously, and predictably with increasing
    model scale. But then the study authors measure performance for tasks using discontinuous
    metrics, and so it appears that the model performs the task abruptly.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, a small model performs decently on a task but we can’t detect
    it because the chosen metric is discontinuous, and only under a certain error
    (achieved over a certain model size) can we observe performance in the tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/899e3e4e70ca8556f75c7274ca73085e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/abs/2304.15004)'
  prefs: []
  type: TYPE_NORMAL
- en: According to the authors, it is also the small number of examples for the test
    that leads to small models not being properly evaluated.
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate this, the authors started with the scaling law, according to
    which performance (or error) increases as a function of the number of metrics
    and which is indeed shown to be consistent at different magnitudes. As the authors
    note, many metrics require all tokens in the sequence to be correct, especially
    when dealing with long sequences leads to seeing sharp increases.
  prefs: []
  type: TYPE_NORMAL
- en: They were able to do these experiments using InstructGPT/GPT-3 because models
    such as LaMDA, Gopher, and Chinchilla are unfortunately not accessible. This prevented
    them to do an extensive evaluation of the different models. Since LLMs are trained
    only on text (and GPT is trained on predicting the next word), one of the surprising
    abilities of LLMs is integer arithmetic tasks. As showed from the GPT-3 introduction
    article, this property is defined as emergent in function of the scale/
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5d53f51d1996ca43a89b97641a7fcd29.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Results on all 10 arithmetic tasks in the few-shot settings for models of different
    sizes. image source: [here](https://arxiv.org/abs/2005.14165)'
  prefs: []
  type: TYPE_NORMAL
- en: As seen in the image (top) when performance is measured with a non-linear metric
    we see an emergent property. when a linear metric is used (bottom) on the other
    hand we see a continuous and predictable increase in performance as a function
    of scale.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/de539001f6d394738e6b710f7828d14c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/abs/2304.15004)'
  prefs: []
  type: TYPE_NORMAL
- en: In addition, the authors noted that by increasing the data for small model evaluation
    even with nonlinear metrics the effect was not as pronounced. In other words,
    if the test dataset is larger even with nonlinear metrics we do not observe such
    a dramatic effect.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, with low resolution (few test data) is more probable to assist in zero
    accuracies for small models, which support the claim that a property emerges just
    after a certain threshold.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/20ad137c1586811363bef1487f979212.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/abs/2304.15004)'
  prefs: []
  type: TYPE_NORMAL
- en: The authors then decided to extend to a meta-analysis on emerging properties,
    using BigBench (since it is public and is also well documented). In addition,
    this dataset offers more than one evaluation metric. When the authors look at
    nonlinear metrics (Exact String Match, Multiple Choice Grade, ROUGE-L-Sum) emergent
    properties could be observed. On the other hand, using linear metrics no emergent
    properties are observed.
  prefs: []
  type: TYPE_NORMAL
- en: The most surprising finding is that 92 % of claimed emergent abilities come
    from using two discontinuous metrics Multiple Choice Grade and Exact String Match.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0907f498f4c607342d153202cee01b6b.png)'
  prefs: []
  type: TYPE_IMG
- en: So if indeed the cause of emergent properties is the use of discontinuous metrics,
    just changing metrics would be enough to make them disappear. Keeping the model
    and task fixed, just change the rating metrics and the emergent properties disappear.
    In this case, the authors simply reused the outputs of the LaMDA family of models
    and changed the metrics from discontinuous (Multiple Choice Grade) to continuous
    (Brier Score).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/98787f64096d8bdbb74e69cbdd157e16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'one final question remains: **but if emergent properties appear by choosing
    discontinuous metrics can we create emergent properties using discontinuous metrics?**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The authors take as an example the classification ability of the handwritten
    digits dataset (MNIST or the data scientist’s favorite dataset). Anyone who has
    tried to train a convolutional network on this dataset has noticed that even with
    a few layers a decent result is obtained. Increasing the number of layers can
    improve the accuracy. If it were an emergent property, we would expect that at
    first, the accuracy would be near zero, and by increasing the parameters above
    a certain threshold the accuracy would start to increase significantly.
  prefs: []
  type: TYPE_NORMAL
- en: 'The authors used the [LeNet](https://en.wikipedia.org/wiki/LeNet) family (several
    models with increasing numbers of parameters). They simply chose a new metric
    called subset accuracy: “1 if the network classifies K out of K (independent)
    test data correctly, 0 otherwise.”'
  prefs: []
  type: TYPE_NORMAL
- en: While using test accuracy we notice the classic increase in accuracy with a
    sigmoidal trend, with the new discontinuous metric it seems that the ability to
    classify handwritten digits is an emergent property.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0e75b3aa8ff5818f310c90f4494cf523.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The authors provide another example: image reconstruction with autoencoders.
    Just by creating a new discontinuous metric, the ability to reconstruct autoencoders
    becomes an emergent property.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/469249a740648835f47191ba03197e76.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The authors conclude:'
  prefs: []
  type: TYPE_NORMAL
- en: Emergent abilities may be creations of the researcher’s choices, not a fundamental
    property of the model family on the specific task ([source](https://arxiv.org/abs/2304.15004))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In other words, if someone wants an emergent property all they have to do is
    choose a discontinuous metric and magically they will see a property appear over
    a certain threshold of parameters.
  prefs: []
  type: TYPE_NORMAL
- en: The authors conservatively state, “*This paper should be interpreted as claiming
    that large language models cannot display emergent abilities.*” They merely claim
    that the properties seen so far are instead produced by choice from the metric.
  prefs: []
  type: TYPE_NORMAL
- en: Now it is true that until you see a black swan, all swans are white. But the
    next time an emergent property appears, though, one must check under what conditions
    it appears. Also, this is another call to rethink benchmarks that may now be unsuitable
    for measuring the quality of a model. Second, LLMs should be open-source, because
    any claim could simply be due to a choice of evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: Parting thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For a long time, emergent properties have been considered among the most surprising
    behaviors of Large Language Models (LLMs). The fact that beyond a certain number
    of parameters, an ability would emerge was a fascinating but at the same time
    terrifying concept. Indeed, on the one hand, it was further justification to look
    for larger and larger models. On the other, the emergence of potentially dangerous
    abilities without warning was problematic.
  prefs: []
  type: TYPE_NORMAL
- en: This article surprisingly shows how the choice of evaluation metrics leads to
    the emergence of properties. This prompts a rethinking of benchmarks with a new
    focus on the choice of evaluation metrics. Second, emergent properties may not
    exist.
  prefs: []
  type: TYPE_NORMAL
- en: More broadly, all along, many authors choose the evaluation metric that makes
    their data shine. Thus, we can only be sure of a claim when a model and its outputs
    are open to the public for independent scientific investigations.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have found this interesting:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*You can look for my other articles, you can also* [***subscribe***](https://salvatore-raieli.medium.com/subscribe)
    *to get notified when I publish articles, you can* [***become a Medium member***](https://medium.com/@salvatore-raieli/membership)
    *to access all its stories (affiliate links of the platform for which I get small
    revenues without cost to you) and you can also connect or reach me on*[***LinkedIn***](https://www.linkedin.com/in/salvatore-raieli/)***.***'
  prefs: []
  type: TYPE_NORMAL
- en: '*Here is the link to my GitHub repository, where I am planning to collect code
    and many resources related to machine learning, artificial intelligence, and more.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/SalvatoreRa/tutorial?source=post_page-----fead754a1bf9--------------------------------)
    [## GitHub - SalvatoreRa/tutorial: Tutorials on machine learning, artificial intelligence,
    data science…'
  prefs: []
  type: TYPE_NORMAL
- en: Tutorials on machine learning, artificial intelligence, data science with math
    explanation and reusable code (in python…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/SalvatoreRa/tutorial?source=post_page-----fead754a1bf9--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '*or you may be interested in one of my recent articles:*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://levelup.gitconnected.com/pmc-llama-because-googling-symptoms-is-not-enough-e1b875ee4c4a?source=post_page-----fead754a1bf9--------------------------------)
    [## PMC-LLaMA: Because Googling Symptoms is Not Enough'
  prefs: []
  type: TYPE_NORMAL
- en: A small model that can be your best friend in medical school (or on trivia night)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'levelup.gitconnected.com](https://levelup.gitconnected.com/pmc-llama-because-googling-symptoms-is-not-enough-e1b875ee4c4a?source=post_page-----fead754a1bf9--------------------------------)
    [](https://levelup.gitconnected.com/welcome-back-80s-transformers-could-be-blown-away-by-convolution-21ff15f6d1cc?source=post_page-----fead754a1bf9--------------------------------)
    [## Welcome Back 80s: Transformers Could Be Blown Away by Convolution'
  prefs: []
  type: TYPE_NORMAL
- en: The Hyena model shows how convolution could be faster than self-attention
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'levelup.gitconnected.com](https://levelup.gitconnected.com/welcome-back-80s-transformers-could-be-blown-away-by-convolution-21ff15f6d1cc?source=post_page-----fead754a1bf9--------------------------------)
    [](https://levelup.gitconnected.com/looking-into-your-eyes-how-google-ai-model-can-predict-your-age-from-the-eye-857979339da9?source=post_page-----fead754a1bf9--------------------------------)
    [## Looking into Your Eyes: How Google AI Model Can Predict Your Age from the
    Eye'
  prefs: []
  type: TYPE_NORMAL
- en: The new model can unlock secrets of aging by analyzing eye photos
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/looking-into-your-eyes-how-google-ai-model-can-predict-your-age-from-the-eye-857979339da9?source=post_page-----fead754a1bf9--------------------------------)
  prefs: []
  type: TYPE_NORMAL
