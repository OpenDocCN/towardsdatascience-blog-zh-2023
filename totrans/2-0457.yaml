- en: Building Powerful Recommender Systems with Deep Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用深度学习构建强大的推荐系统
- en: 原文：[https://towardsdatascience.com/building-powerful-recommender-systems-with-deep-learning-d8a919c52119](https://towardsdatascience.com/building-powerful-recommender-systems-with-deep-learning-d8a919c52119)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/building-powerful-recommender-systems-with-deep-learning-d8a919c52119](https://towardsdatascience.com/building-powerful-recommender-systems-with-deep-learning-d8a919c52119)
- en: '![](../Images/8f6471ecbf2d007861bcf4ab5b5aa65a.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8f6471ecbf2d007861bcf4ab5b5aa65a.png)'
- en: Illustration by the author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者插图
- en: A Step-by-Step Implementation Using the PyTorch Library TorchRec
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 PyTorch 库 TorchRec 的逐步实现
- en: '[](https://linafaik.medium.com/?source=post_page-----d8a919c52119--------------------------------)[![Lina
    Faik](../Images/24a3aa67a2d9dc3e074ceead04ab4cc8.png)](https://linafaik.medium.com/?source=post_page-----d8a919c52119--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d8a919c52119--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d8a919c52119--------------------------------)
    [Lina Faik](https://linafaik.medium.com/?source=post_page-----d8a919c52119--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://linafaik.medium.com/?source=post_page-----d8a919c52119--------------------------------)[![Lina
    Faik](../Images/24a3aa67a2d9dc3e074ceead04ab4cc8.png)](https://linafaik.medium.com/?source=post_page-----d8a919c52119--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d8a919c52119--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d8a919c52119--------------------------------)
    [Lina Faik](https://linafaik.medium.com/?source=post_page-----d8a919c52119--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d8a919c52119--------------------------------)
    ·7 min read·Jul 3, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d8a919c52119--------------------------------)
    ·阅读时长 7 分钟·2023年7月3日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Recommending the right product to customers at the right time is a prevalent
    challenge across industries. For instance, bankers are constantly looking to suggest
    highly relevant services to their existing or potential customers. Retailers strive
    to recommend appealing products that meet customer tastes. Similarly, social networks
    aim to build captivating feeds to foster user adoption.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在正确的时间向客户推荐合适的产品是各行各业普遍面临的挑战。例如，银行家不断寻找向现有或潜在客户推荐高度相关服务的机会。零售商努力推荐符合客户口味的吸引人产品。类似地，社交网络旨在构建引人入胜的动态，以促进用户采纳。
- en: Despite being a widely explored use case, achieving satisfactory performance
    results remains arduous due to the unique nature of the problem. The main reasons
    include the presence of abundant categorical data, which often leads to scarcity
    issues, and the computational aspect of the use case, which poses scalability
    problems. It’s only recently that recommendation models have harnessed neural
    networks.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这是一个被广泛研究的用例，但由于问题的独特性，取得令人满意的性能结果仍然困难重重。主要原因包括存在大量分类数据，通常会导致稀缺问题，以及用例的计算方面，带来扩展性问题。直到最近，推荐模型才开始利用神经网络。
- en: In this context, Meta has developed and made openly available a deep learning
    recommendation model (DRLM). The model is particularly remarkable for combining
    the principles of collaborative filtering and predictive analysis and being suitable
    for large-scale production.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种背景下，Meta 开发并公开了一个深度学习推荐模型（DRLM）。该模型因结合了协同过滤和预测分析的原理，并适用于大规模生产而特别出色。
- en: '**Objective**'
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**目标**'
- en: The objective of this article is to guide you through a step-by-step implementation
    using the PyTorch library TorchRec, enabling you to effectively address your own
    recommendation use case.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的**目标**是通过使用 PyTorch 库 TorchRec 的逐步实现，帮助你有效解决自己的推荐系统问题。
- en: 'After reading this article, you will understand:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读本文后，你将理解：
- en: How does the DLRM model work?
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DLRM 模型如何工作？
- en: What sets DLRM models apart and makes them powerful and scalable?
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DLRM 模型有什么独特之处，使其强大而具有可扩展性？
- en: How can you implement your own recommendation system from end to end?
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你如何从头到尾实现自己的推荐系统？
- en: '*The article requires general knowledge of the recommender system problem and
    familiarity with the pytorch library. The experimentations described in the article
    were carried out using the libraries* [*TorchRec*](https://pytorch.org/torchrec/)
    *and PyTorch. You can find the code* [*here*](https://github.com/linafaik08/recommender_systems_dlrm)
    *on GitHub.*'
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*本文需要对推荐系统问题有一般性的了解，并熟悉 pytorch 库。本文所述的实验使用了库* [*TorchRec*](https://pytorch.org/torchrec/)
    *和 PyTorch。你可以在 GitHub 上找到代码* [*这里*](https://github.com/linafaik08/recommender_systems_dlrm)
    *。*'
- en: '[](https://github.com/linafaik08/recommender_systems_dlrm?source=post_page-----d8a919c52119--------------------------------)
    [## GitHub - linafaik08/recommender_systems_dlrm'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/linafaik08/recommender_systems_dlrm?source=post_page-----d8a919c52119--------------------------------)
    [## GitHub - linafaik08/recommender_systems_dlrm'
- en: Contribute to linafaik08/recommender_systems_dlrm development by creating an
    account on GitHub.
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过在 GitHub 上创建账户来为 linafaik08/recommender_systems_dlrm 的开发做出贡献。
- en: github.co](https://github.com/linafaik08/recommender_systems_dlrm?source=post_page-----d8a919c52119--------------------------------)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: github.co](https://github.com/linafaik08/recommender_systems_dlrm?source=post_page-----d8a919c52119--------------------------------)
- en: 1\. Decoding the DLRM Model
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1. 解码 DLRM 模型
- en: Let’s first dive into the complexities of the DLRM model and explore its underlying
    principles and mechanisms.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先深入了解 DLRM 模型的复杂性，并探索其基本原理和机制。
- en: 1.1\. An Overview of the Model Design
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1. 模型设计概述
- en: To provide a more tangible illustration, let’s consider the scenario of an online
    retailer looking to create a personalized feed for every customer visiting their
    website.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供一个更具体的例子，我们来考虑一个在线零售商希望为每个访问其网站的客户创建个性化推荐的场景。
- en: In order to achieve this, the retailer can train a model that predicts the probability
    of a customer purchasing a particular product. This model assigns a score to each
    product for each individual customer, based on various factors. The feed is built
    by ranking the scores.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，零售商可以训练一个模型，该模型预测客户购买特定产品的概率。该模型根据各种因素为每个客户的每个产品分配一个分数。推荐流通过对这些分数进行排序来构建。
- en: In this case, the model can learn from historical data that encompasses a range
    of information for each customer and product. This includes numerical variables
    like customer age and product price, as well as categorical characteristics such
    as product type, color, and more.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，模型可以从涵盖每个客户和产品一系列信息的历史数据中学习。这包括诸如客户年龄和产品价格等数值变量，以及产品类型、颜色等类别特征。
- en: 'Here’s where the DLRM model excels: it possesses the remarkable ability to
    leverage both numerical and categorical variables, even when dealing with a large
    number of unique categories. This enables the model to comprehensively analyze
    and understand complex relationships between the features. To understand why,
    let’s take a look at the architecture model in Figure 1.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: DLRM 模型的优势在于：它具有利用数值变量和类别变量的非凡能力，即使在处理大量独特类别时也是如此。这使得模型能够全面分析和理解特征之间的复杂关系。要理解原因，我们来看一下图
    1 中的架构模型。
- en: '![](../Images/a5d7e4f4d21de2f6f97990b514200e4b.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a5d7e4f4d21de2f6f97990b514200e4b.png)'
- en: Figure 1 — DLRM model architecture, illustration by the author, inspired from
    [5]
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1 — DLRM 模型架构，由作者绘制，灵感来自 [5]
- en: '**Categorical features**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**类别特征**'
- en: DLRM learns an embedding table for each categorial feature and uses them to
    map these variables to dense representations. Hence, each categorical feature
    is represented as a vector of the same length.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: DLRM 为每个类别特征学习一个嵌入表，并使用这些表将这些变量映射到稠密表示。因此，每个类别特征都表示为相同长度的向量。
- en: '**Numerical features**'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值特征**'
- en: DLRM processes numerical features through an MLP, called bottom MLP. The output
    of this MLP has the same dimension as the previous embedding vectors.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: DLRM 通过一个称为底部 MLP 的多层感知器（MLP）处理数值特征。该 MLP 的输出维度与之前的嵌入向量相同。
- en: '**Pairwise interaction**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**成对交互**'
- en: DLRM calculates the dot product between all pairs of embedding vectors and the
    processed numerical features This allows the model to include second-order feature
    interaction.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: DLRM 计算所有嵌入向量与处理过的数值特征之间的点积。这使得模型能够包括二阶特征交互。
- en: '**Concatenation and final output**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**连接与最终输出**'
- en: DLRM concatenates these dot products with the processed numerical features and
    uses the results to feed another MLP, called the top MLP. The final probability
    is obtained by passing the output of this MLP to a sigmoid function.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: DLRM 将这些点积与处理过的数值特征进行拼接，并将结果输入到另一个 MLP 中，称为顶部 MLP。最终的概率通过将此 MLP 的输出传递到 sigmoid
    函数获得。
- en: 1.2\. The Model Implementation
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2\. 模型实现
- en: While the potential of the model appears promising in theory, its practical
    implementation presents a computational hurdle.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管模型在理论上具有良好的潜力，但其实际实施仍然存在计算难题。
- en: Usually, recommendation use cases involve handling vast volumes of data. Using
    DLRM models, in particular, introduces an very large number of parameters, higher
    than common deep learning models. Consequently, this amplifies the computational
    demands associated with their implementation.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，推荐系统涉及处理大量数据。特别是使用 DLRM 模型会引入非常多的参数，超过了常见深度学习模型。因此，这增加了其实现所需的计算需求。
- en: The majority of parameters in DLRMs can be attributed to embeddings as they
    consist of multiple tables, each demanding a large memory. This makes DLRMs computationally
    demanding, both in terms of memory capacity and bandwidth.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DLRM 中大多数参数可归因于嵌入，因为它们由多个表组成，每个表都需要大量内存。这使得 DLRM 在内存容量和带宽方面都具有较高的计算需求。
- en: Although the memory footprint of MLP parameters is smaller, they still require
    substantial computational resources.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尽管 MLP 参数的内存占用较小，但仍然需要大量计算资源。
- en: To mitigate the memory bottleneck, DLRM relies a unique combination of model
    parallelism for the embeddings and data parallelism for the MLPs.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了缓解内存瓶颈，DLRM 依赖于一种独特的模型并行（用于嵌入）和数据并行（用于 MLP）的组合。
- en: '2\. From Concept to Implementation: A Step-by-Step Guide to Building Your Custom
    Recommendation System'
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 从概念到实现：构建自定义推荐系统的逐步指南
- en: This section provides a detailed step-by-step guide on how to implement your
    own recommendation system from start to finish.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了从头到尾实现自己推荐系统的详细逐步指南。
- en: 2.1\. Data Transformation and Batch Construction
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1\. 数据转换和批处理构建
- en: The first step involves converting the data into tensors and organizing them
    into batches for input into the model.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是将数据转换为张量并将其组织成批次，以输入到模型中。
- en: To illustrate this process, let’s consider this dataframe as an example.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这个过程，让我们以这个数据框为例。
- en: '![](../Images/d1afe7be20a6083ca02cc8a257e052a7.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d1afe7be20a6083ca02cc8a257e052a7.png)'
- en: 'For sparse features, we need to concatenate the values into a single vector
    and compute the lengths. This can be accomplished using the *KeyedJaggedTensor.from_lengths_sync*
    function, which takes both elements as input. Here’s an example of the Python
    script:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于稀疏特征，我们需要将值拼接成一个向量并计算长度。这可以使用 *KeyedJaggedTensor.from_lengths_sync* 函数来完成，该函数接受两个元素作为输入。以下是
    Python 脚本的一个示例：
- en: '[PRE0]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For dense features and labels, the process is more straightforward. Here’s
    an example of the Python script:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对于密集特征和标签，过程更为简单。这是 Python 脚本的一个示例：
- en: '[PRE1]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'By using the outputs from the previous steps, it becomes possible to construct
    a batch. Here’s an example of the Python script:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用前一步骤的输出，可以构建一个批次。这是 Python 脚本的一个示例：
- en: '[PRE2]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: For a more comprehensive implementation, you can refer to the [batch.py](https://github.com/linafaik08/recommender_systems_dlrm/blob/main/src/batch.py)
    file in the corresponding GitHub [repository](https://github.com/linafaik08/recommender_systems_dlrm/).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取更全面的实现，可以参考 GitHub [batch.py](https://github.com/linafaik08/recommender_systems_dlrm/blob/main/src/batch.py)
    文件及相关 GitHub [仓库](https://github.com/linafaik08/recommender_systems_dlrm/)。
- en: 2.2\. Model Initialization and Optimization Setup
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2\. 模型初始化和优化设置
- en: 'The next step involves initializing the model, as demonstrated in the following
    Python code:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步涉及初始化模型，如以下 Python 代码所示：
- en: '[PRE3]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The model can then be trained and evaluated using the following code:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然后可以使用以下代码训练和评估模型：
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: For a more comprehensive implementation, you can refer to the [model.py](https://github.com/linafaik08/recommender_systems_dlrm/blob/main/src/model.py)
    file in the corresponding GitHub [repository](https://github.com/linafaik08/recommender_systems_dlrm/).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取更全面的实现，可以参考 GitHub [model.py](https://github.com/linafaik08/recommender_systems_dlrm/blob/main/src/model.py)
    文件及相关 GitHub [仓库](https://github.com/linafaik08/recommender_systems_dlrm/)。
- en: Key Takeaways
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关键要点
- en: ✔ The DLRM model presents a compelling approach to effectively combine numerical
    and categorical features using embeddings, enabling the model to capture intricate
    patterns and relationships.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ✔ DLRM 模型提供了一种有效结合数值和类别特征的引人注目的方法，使用嵌入技术，使得模型能够捕捉复杂的模式和关系。
- en: ✔ Although its architecture requires considerable computational resources, its
    implementation incorporates a unique combination of model parallelism and data
    parallelism, making the model scalable to production.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ✔ 尽管其架构需要相当的计算资源，但其实现结合了模型并行和数据并行的独特组合，使得模型在生产环境中具有可扩展性。
- en: ✔ However, due to limited data availability, the model’s performance has not
    been extensively tested across diverse real-world datasets. This raises uncertainty
    about its effectiveness in practical scenarios.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ✔ 然而，由于数据的有限性，该模型的性能尚未在各种真实世界的数据集上进行广泛测试。这引发了对其在实际场景中有效性的担忧。
- en: ✔ Additionally, the model necessitates tuning a considerable number of parameters,
    further complicating the process.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ✔ 此外，该模型需要调整大量参数，这进一步使得过程复杂化。
- en: ✔ Considering this, simpler models like LGBM may offer comparable performance
    with easier implementation, tuning, and long-term maintenance, without the same
    computational overhead.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ✔ 考虑到这一点，像 LGBM 这样更简单的模型可能提供类似的性能，并且具有更简单的实现、调优和长期维护，而不会有相同的计算开销。
- en: References
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] M Naumov & al, [Deep Learning Recommendation Model for Personalization
    and Recommendation Systems](https://arxiv.org/abs/1906.00091?fbclid=IwAR1yd08rme7ON-rIRO0IiooMJEtv0JBYyWPpLuAlli3zmPy2XmJP92UtM7k),
    May 2019'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] M Naumov 等，[用于个性化和推荐系统的深度学习推荐模型](https://arxiv.org/abs/1906.00091?fbclid=IwAR1yd08rme7ON-rIRO0IiooMJEtv0JBYyWPpLuAlli3zmPy2XmJP92UtM7k)，2019
    年 5 月'
- en: '[2] [Github repository](https://github.com/facebookresearch/dlrm?fbclid=IwAR1YrymUGB7IG8k2x7h4cw7JXRkdS8NcrITUUQ71K2GrbVE5CNxMFf2esFQ)
    of the Facebook team’s initial implementation of the DLRM model available as open
    source'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [Facebook 团队的 DLRM 模型初步实现的 Github 仓库](https://github.com/facebookresearch/dlrm?fbclid=IwAR1YrymUGB7IG8k2x7h4cw7JXRkdS8NcrITUUQ71K2GrbVE5CNxMFf2esFQ)，开放源代码'
- en: '[3] DLRM: An advanced, open source deep learning recommendation model, Meta
    AI Blog, July 2019'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] DLRM：一种先进的开源深度学习推荐模型，Meta AI 博客，2019 年 7 月'
- en: '[4] Pytorch library for modern production recommendation systems, [torchec](https://pytorch.org/blog/introducing-torchrec/)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] 现代生产推荐系统的 Pytorch 库，[torchec](https://pytorch.org/blog/introducing-torchrec/)'
- en: '[5] Vinh Nguyen, Tomasz Grel and Mengdi Huang, [Optimizing the Deep Learning
    Recommendation Model on NVIDIA GPUs](https://developer.nvidia.com/blog/optimizing-dlrm-on-nvidia-gpus/),
    June 2020'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Vinh Nguyen, Tomasz Grel 和 Mengdi Huang，[优化 NVIDIA GPU 上的深度学习推荐模型](https://developer.nvidia.com/blog/optimizing-dlrm-on-nvidia-gpus/)，2020
    年 6 月'
