- en: Building Powerful Recommender Systems with Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/building-powerful-recommender-systems-with-deep-learning-d8a919c52119](https://towardsdatascience.com/building-powerful-recommender-systems-with-deep-learning-d8a919c52119)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/8f6471ecbf2d007861bcf4ab5b5aa65a.png)'
  prefs: []
  type: TYPE_IMG
- en: Illustration by the author
  prefs: []
  type: TYPE_NORMAL
- en: A Step-by-Step Implementation Using the PyTorch Library TorchRec
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://linafaik.medium.com/?source=post_page-----d8a919c52119--------------------------------)[![Lina
    Faik](../Images/24a3aa67a2d9dc3e074ceead04ab4cc8.png)](https://linafaik.medium.com/?source=post_page-----d8a919c52119--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d8a919c52119--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d8a919c52119--------------------------------)
    [Lina Faik](https://linafaik.medium.com/?source=post_page-----d8a919c52119--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d8a919c52119--------------------------------)
    ·7 min read·Jul 3, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Recommending the right product to customers at the right time is a prevalent
    challenge across industries. For instance, bankers are constantly looking to suggest
    highly relevant services to their existing or potential customers. Retailers strive
    to recommend appealing products that meet customer tastes. Similarly, social networks
    aim to build captivating feeds to foster user adoption.
  prefs: []
  type: TYPE_NORMAL
- en: Despite being a widely explored use case, achieving satisfactory performance
    results remains arduous due to the unique nature of the problem. The main reasons
    include the presence of abundant categorical data, which often leads to scarcity
    issues, and the computational aspect of the use case, which poses scalability
    problems. It’s only recently that recommendation models have harnessed neural
    networks.
  prefs: []
  type: TYPE_NORMAL
- en: In this context, Meta has developed and made openly available a deep learning
    recommendation model (DRLM). The model is particularly remarkable for combining
    the principles of collaborative filtering and predictive analysis and being suitable
    for large-scale production.
  prefs: []
  type: TYPE_NORMAL
- en: '**Objective**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The objective of this article is to guide you through a step-by-step implementation
    using the PyTorch library TorchRec, enabling you to effectively address your own
    recommendation use case.
  prefs: []
  type: TYPE_NORMAL
- en: 'After reading this article, you will understand:'
  prefs: []
  type: TYPE_NORMAL
- en: How does the DLRM model work?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What sets DLRM models apart and makes them powerful and scalable?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can you implement your own recommendation system from end to end?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*The article requires general knowledge of the recommender system problem and
    familiarity with the pytorch library. The experimentations described in the article
    were carried out using the libraries* [*TorchRec*](https://pytorch.org/torchrec/)
    *and PyTorch. You can find the code* [*here*](https://github.com/linafaik08/recommender_systems_dlrm)
    *on GitHub.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://github.com/linafaik08/recommender_systems_dlrm?source=post_page-----d8a919c52119--------------------------------)
    [## GitHub - linafaik08/recommender_systems_dlrm'
  prefs: []
  type: TYPE_NORMAL
- en: Contribute to linafaik08/recommender_systems_dlrm development by creating an
    account on GitHub.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.co](https://github.com/linafaik08/recommender_systems_dlrm?source=post_page-----d8a919c52119--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Decoding the DLRM Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s first dive into the complexities of the DLRM model and explore its underlying
    principles and mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: 1.1\. An Overview of the Model Design
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To provide a more tangible illustration, let’s consider the scenario of an online
    retailer looking to create a personalized feed for every customer visiting their
    website.
  prefs: []
  type: TYPE_NORMAL
- en: In order to achieve this, the retailer can train a model that predicts the probability
    of a customer purchasing a particular product. This model assigns a score to each
    product for each individual customer, based on various factors. The feed is built
    by ranking the scores.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the model can learn from historical data that encompasses a range
    of information for each customer and product. This includes numerical variables
    like customer age and product price, as well as categorical characteristics such
    as product type, color, and more.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s where the DLRM model excels: it possesses the remarkable ability to
    leverage both numerical and categorical variables, even when dealing with a large
    number of unique categories. This enables the model to comprehensively analyze
    and understand complex relationships between the features. To understand why,
    let’s take a look at the architecture model in Figure 1.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a5d7e4f4d21de2f6f97990b514200e4b.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1 — DLRM model architecture, illustration by the author, inspired from
    [5]
  prefs: []
  type: TYPE_NORMAL
- en: '**Categorical features**'
  prefs: []
  type: TYPE_NORMAL
- en: DLRM learns an embedding table for each categorial feature and uses them to
    map these variables to dense representations. Hence, each categorical feature
    is represented as a vector of the same length.
  prefs: []
  type: TYPE_NORMAL
- en: '**Numerical features**'
  prefs: []
  type: TYPE_NORMAL
- en: DLRM processes numerical features through an MLP, called bottom MLP. The output
    of this MLP has the same dimension as the previous embedding vectors.
  prefs: []
  type: TYPE_NORMAL
- en: '**Pairwise interaction**'
  prefs: []
  type: TYPE_NORMAL
- en: DLRM calculates the dot product between all pairs of embedding vectors and the
    processed numerical features This allows the model to include second-order feature
    interaction.
  prefs: []
  type: TYPE_NORMAL
- en: '**Concatenation and final output**'
  prefs: []
  type: TYPE_NORMAL
- en: DLRM concatenates these dot products with the processed numerical features and
    uses the results to feed another MLP, called the top MLP. The final probability
    is obtained by passing the output of this MLP to a sigmoid function.
  prefs: []
  type: TYPE_NORMAL
- en: 1.2\. The Model Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While the potential of the model appears promising in theory, its practical
    implementation presents a computational hurdle.
  prefs: []
  type: TYPE_NORMAL
- en: Usually, recommendation use cases involve handling vast volumes of data. Using
    DLRM models, in particular, introduces an very large number of parameters, higher
    than common deep learning models. Consequently, this amplifies the computational
    demands associated with their implementation.
  prefs: []
  type: TYPE_NORMAL
- en: The majority of parameters in DLRMs can be attributed to embeddings as they
    consist of multiple tables, each demanding a large memory. This makes DLRMs computationally
    demanding, both in terms of memory capacity and bandwidth.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Although the memory footprint of MLP parameters is smaller, they still require
    substantial computational resources.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To mitigate the memory bottleneck, DLRM relies a unique combination of model
    parallelism for the embeddings and data parallelism for the MLPs.
  prefs: []
  type: TYPE_NORMAL
- en: '2\. From Concept to Implementation: A Step-by-Step Guide to Building Your Custom
    Recommendation System'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section provides a detailed step-by-step guide on how to implement your
    own recommendation system from start to finish.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1\. Data Transformation and Batch Construction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first step involves converting the data into tensors and organizing them
    into batches for input into the model.
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate this process, let’s consider this dataframe as an example.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d1afe7be20a6083ca02cc8a257e052a7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For sparse features, we need to concatenate the values into a single vector
    and compute the lengths. This can be accomplished using the *KeyedJaggedTensor.from_lengths_sync*
    function, which takes both elements as input. Here’s an example of the Python
    script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'For dense features and labels, the process is more straightforward. Here’s
    an example of the Python script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'By using the outputs from the previous steps, it becomes possible to construct
    a batch. Here’s an example of the Python script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: For a more comprehensive implementation, you can refer to the [batch.py](https://github.com/linafaik08/recommender_systems_dlrm/blob/main/src/batch.py)
    file in the corresponding GitHub [repository](https://github.com/linafaik08/recommender_systems_dlrm/).
  prefs: []
  type: TYPE_NORMAL
- en: 2.2\. Model Initialization and Optimization Setup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The next step involves initializing the model, as demonstrated in the following
    Python code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The model can then be trained and evaluated using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: For a more comprehensive implementation, you can refer to the [model.py](https://github.com/linafaik08/recommender_systems_dlrm/blob/main/src/model.py)
    file in the corresponding GitHub [repository](https://github.com/linafaik08/recommender_systems_dlrm/).
  prefs: []
  type: TYPE_NORMAL
- en: Key Takeaways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ✔ The DLRM model presents a compelling approach to effectively combine numerical
    and categorical features using embeddings, enabling the model to capture intricate
    patterns and relationships.
  prefs: []
  type: TYPE_NORMAL
- en: ✔ Although its architecture requires considerable computational resources, its
    implementation incorporates a unique combination of model parallelism and data
    parallelism, making the model scalable to production.
  prefs: []
  type: TYPE_NORMAL
- en: ✔ However, due to limited data availability, the model’s performance has not
    been extensively tested across diverse real-world datasets. This raises uncertainty
    about its effectiveness in practical scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: ✔ Additionally, the model necessitates tuning a considerable number of parameters,
    further complicating the process.
  prefs: []
  type: TYPE_NORMAL
- en: ✔ Considering this, simpler models like LGBM may offer comparable performance
    with easier implementation, tuning, and long-term maintenance, without the same
    computational overhead.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] M Naumov & al, [Deep Learning Recommendation Model for Personalization
    and Recommendation Systems](https://arxiv.org/abs/1906.00091?fbclid=IwAR1yd08rme7ON-rIRO0IiooMJEtv0JBYyWPpLuAlli3zmPy2XmJP92UtM7k),
    May 2019'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] [Github repository](https://github.com/facebookresearch/dlrm?fbclid=IwAR1YrymUGB7IG8k2x7h4cw7JXRkdS8NcrITUUQ71K2GrbVE5CNxMFf2esFQ)
    of the Facebook team’s initial implementation of the DLRM model available as open
    source'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] DLRM: An advanced, open source deep learning recommendation model, Meta
    AI Blog, July 2019'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] Pytorch library for modern production recommendation systems, [torchec](https://pytorch.org/blog/introducing-torchrec/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[5] Vinh Nguyen, Tomasz Grel and Mengdi Huang, [Optimizing the Deep Learning
    Recommendation Model on NVIDIA GPUs](https://developer.nvidia.com/blog/optimizing-dlrm-on-nvidia-gpus/),
    June 2020'
  prefs: []
  type: TYPE_NORMAL
