["```py\ndictionary2019=pd.read_csv('Data/datadictionary2019.csv', encoding= \"ISO-8859–1\")\ndictionary2020=pd.read_csv('Data/datadictionary.csv', encoding= \"ISO-8859–1\")\ncommoncolumns=dictionary2020.merge(dictionary2019, how='inner', left_on='name', right_on='name')['name'].values.tolist()\n\ndfa=df2019[commoncolumns]\ndfb=df2020[commoncolumns]\ndf_final=pd.concat([dfa, dfb], axis=0)\ndf_final\n```", "```py\nimport numpy as np\n#create an average overall ED rate by weighting the male and female rates by their percentage of the population and adding\ndf_final['Malerate']=(df_final['ACS_PCT_MALE']*df_final['MMD_ED_VISITS_M_RATE'])/100\ndf_final['Femalerate']=(df_final['ACS_PCT_FEMALE']*df_final['MMD_ED_VISITS_F_RATE'])/100\ndf_final['EDrate']=df_final['Malerate']+df_final['Femalerate']\n#print the mean ED rate to use as our baseline for Good and Bad outcomes\n```", "```py\n#create cutoff value for high EDrate\ncutoff=np.percentile(df_final['EDrate'], 80)\n#if ED rate is greater than the 50th percentile then flag as high or else 0 for low\ndf_final['HighED']=np.where(df_final['EDrate']>cutoff, 1, 0)\n```", "```py\n# drop columns with >10% missing\ndf_final.dropna(thresh=0.90*len(df_final),axis=1, inplace=True)\n\n#list columns remaining with missing values\ndf_final.isnull().sum().to_frame(name='counts').query('counts > 0').sort_values(by='counts', ascending=False)\n```", "```py\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\ncolumns=df_final.loc[:, df_final.dtypes == float].columns.values\nX_train, X_test, y_train, y_test = train_test_split( df_final.index, df_final['HighED'], stratify=df_final['HighED'], test_size=0.25,  random_state=42)\ndf_train=df_final.iloc[X_train]\ndf_test=df_final.iloc[X_test]\nimp = SimpleImputer( strategy='mean')\ndf_impute_train=df_train[columns].copy(deep=True)\ndf_impute_test=df_test[columns].copy(deep=True)\ndf_impute_train[:]=imp.fit_transform(df_train[columns])\ndf_impute_test[:]=imp.fit_transform(df_test[columns])\n\ndf_impute_train\n```", "```py\n#print positive correlations over .2 (small-moderate effect size)\ndef positivecorrelations(threshold=.2):\n    columns=df_impute_train.columns.values\n    positivecolumns=[]\n    for col in columns:        \n        if df_impute_train['EDrate'].corr(df_impute_train[col])>threshold:\n            positivecolumns.append(col)\n    return positivecolumns\n\nposcols=(positivecorrelations())\n#print negative correlations less than -.2 (small-moderate effect size)\ndef negativecorrelations(threshold=-.2):\n    columns=df_impute_train.columns.values\n    negativecolumns=[]\n    for col in columns:        \n        if df_impute_train['EDrate'].corr(df_impute_train[col])<threshold:\n            negativecolumns.append(col)\n    return negativecolumns\n\nnegcols=(negativecorrelations())\n```", "```py\n#make a final list of significant columns\nsigcols=poscols+negcols\nprint(sigcols)\nlen(sigcols)\n```", "```py\nstringVal = \"ED\"\nsigcols.remove('Femalerate')\nsigcols.remove('Malerate')\nfinalcols=[x for x in sigcols if stringVal not in x]\n\nlen(finalcols)\n```", "```py\nstringVal = \"_IP\"\n\nfinalcols=[x for x in finalcols if stringVal not in x]\nstringVal2=\"TEMP_\"\n\nfinalcols=[x for x in finalcols if stringVal2 not in x]\nstringVal3=\"_PA\"\nstringVal4=\"_EM\"\n\nfinalcols=[x for x in finalcols if stringVal3 not in x]\nfinalcols=[x for x in finalcols if stringVal4 not in x]\nlen(finalcols)\n#result is 77\n```", "```py\nfinalcols=[x for x in finalcols if x not in ('ACS_PCT_PRIVATE_SELF_BELOW64', 'ACS_PCT_PRIVATE_SELF','SAIPE_PCT_POV_0_17', 'ACS_PCT_PRIVATE_ANY_BELOW64', 'SAIPE_PCT_POV_5_17', 'NEPHTN_HEATIND_90', 'NEPHTN_HEATIND_95', 'NEPHTN_HEATIND_100')]\n\ndf_impute_train.loc[:, 'MalePQI']=(df_impute_train['ACS_PCT_MALE']*df_impute_train['MMD_OVERALL_PQI_M_RATE'])/100\ndf_impute_train.loc[:, 'FemalePQI']=(df_impute_train['ACS_PCT_FEMALE']*df_impute_train['MMD_OVERALL_PQI_F_RATE'])/100\ndf_impute_train.loc[:, 'PQI']=df_impute_train['MalePQI']+df_impute_train['FemalePQI']\ndf_impute_train['PQI'].describe()\n\ndf_impute_test.loc[:, 'MalePQI']=(df_impute_test['ACS_PCT_MALE']*df_impute_test['MMD_OVERALL_PQI_M_RATE'])/100\ndf_impute_test.loc[:, 'FemalePQI']=(df_impute_test['ACS_PCT_FEMALE']*df_impute_test['MMD_OVERALL_PQI_F_RATE'])/100\ndf_impute_test.loc[:, 'PQI']=df_impute_test['MalePQI']+df_impute_test['FemalePQI']\ndf_impute_test['PQI'].describe()\n\nrate=\"_RATE\"\nfinalcols=[x for x in finalcols if rate not in x]\nrace=\"ACS_PCT_BLACK_\"\nfinalcols=[x for x in finalcols if race not in x]\n\ndictionary2020[['name', 'label']][dictionary2020['name'].isin(finalcols)]\n```", "```py\nimport matplotlib.pyplot as plt\ndef create_scatterplots(var='EDrate'):\n    for col in finalcols:\n        plt.scatter(df_impute_train[col], df_impute_train[var])\n        plt.title((\"{} vs {}\".format(col, var)))\n        plt.show()\ncreate_scatterplots()\n```", "```py\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\nX_train=df_impute_train[finalcols].copy(deep=True)\nX_test=df_impute_test[finalcols].copy(deep=True)\ny_train=df_train['HighED']\ny_test=df_test['HighED']\nscaler.fit(X_train)\nX_train_scaled=scaler.transform(X_train)\nX_test_scaled=scaler.transform(X_test)\n```", "```py\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression(solver='liblinear', random_state=0, class_weight='balanced').fit(X_train_scaled, y_train)\n\nmodel.score(X_test_scaled, y_test)\n```", "```py\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\n\ncm = confusion_matrix(y_test, model.predict(X_test_scaled))\n\nfig, ax = plt.subplots(figsize=(8, 8))\nax.imshow(cm, cmap='summer', alpha=0.3)\nax.grid(False)\nax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted LowED', 'Predicted HighED'))\nax.yaxis.set(ticks=(0, 1), ticklabels=('Actual LowED', 'Actual HighED'))\nax.set_ylim(1.5, -0.5)\nfor i in range(2):\n    for j in range(2):\n        ax.text(j, i, cm[i, j], ha='center', va='center', color='black')\nplt.show()\n```", "```py\nfrom sklearn.svm import SVC\nclf=SVC(class_weight='balanced')\nclf.fit(X_train_scaled, y_train)\nclf.score(X_test_scaled, y_test)\ncm = confusion_matrix(y_test, clf.predict(X_test_scaled))\n\nfig, ax = plt.subplots(figsize=(8, 8))\nax.imshow(cm, cmap='summer', alpha=0.3)\nax.grid(False)\nax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted LowED', 'Predicted HighED'))\nax.yaxis.set(ticks=(0, 1), ticklabels=('Actual LowED', 'Actual HighED'))\nax.set_ylim(1.5, -0.5)\nfor i in range(2):\n    for j in range(2):\n        ax.text(j, i, cm[i, j], ha='center', va='center', color='black')\nplt.show()\nprint(classification_report(y_test, clf.predict(X_test_scaled)))\n```", "```py\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\nclf = RandomForestClassifier( max_features=None, random_state=0, class_weight='balanced')\nclf.fit(X_train, y_train)\nclf.score(X_test, y_test)\ncm = confusion_matrix(y_test, clf.predict(X_test))\n\nfig, ax = plt.subplots(figsize=(8, 8))\nax.imshow(cm, cmap='summer', alpha=0.3)\nax.grid(False)\nax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted LowED', 'Predicted HighED'))\nax.yaxis.set(ticks=(0, 1), ticklabels=('Actual LowED', 'Actual HighED'))\nax.set_ylim(1.5, -0.5)\nfor i in range(2):\n    for j in range(2):\n        ax.text(j, i, cm[i, j], ha='center', va='center', color='black')\nplt.show()\nprint(classification_report(y_test, clf.predict(X_test)))\n```", "```py\n import xgboost as xgb\n\n# Init classifier\nxgb_cl = xgb.XGBClassifier(random_state=0)\n\n# Fit\nxgb_cl.fit(X_train, y_train)\n\n# Predict\npreds = xgb_cl.predict(X_test)\ncm = confusion_matrix(y_test, xgb_cl.predict(X_test))\n\nfig, ax = plt.subplots(figsize=(8, 8))\nax.imshow(cm)\nax.grid(False)\nax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted LowED', 'Predicted HighED'))\nax.yaxis.set(ticks=(0, 1), ticklabels=('Actual LowED', 'Actual HighED'))\nax.set_ylim(1.5, -0.5)\nfor i in range(2):\n    for j in range(2):\n        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\nplt.show()\nprint(classification_report(y_test, xgb_cl.predict(X_test)))\n```", "```py\n features = df_impute_test.columns.values\nimportances = clf.feature_importances_\nindices = np.argsort(importances)\nplt.figure(figsize=(8, 20))\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()\n```", "```py\n import shap\nexplainer = shap.TreeExplainer(clf)\nshap_values = explainer.shap_values(X_test)\nshap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n```"]