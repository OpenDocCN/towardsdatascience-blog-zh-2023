- en: College Football Conference Realignment — Regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/college-football-conference-realignment-regression-8f0776278d55](https://towardsdatascience.com/college-football-conference-realignment-regression-8f0776278d55)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@gspmalloy?source=post_page-----8f0776278d55--------------------------------)[![Giovanni
    Malloy](../Images/e94218e244fab1af845c68e63e5706a1.png)](https://medium.com/@gspmalloy?source=post_page-----8f0776278d55--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8f0776278d55--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8f0776278d55--------------------------------)
    [Giovanni Malloy](https://medium.com/@gspmalloy?source=post_page-----8f0776278d55--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8f0776278d55--------------------------------)
    ·7 min read·Aug 6, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: 'Welcome to part 2 of my series on conference realignment! Last summer when
    conference realignment was in full swing, Tony Altimore published a [study](https://twitter.com/TJAltimore/status/1536438310809247745)
    on Twitter that inspired me to do my own conference realignment analysis. This
    series is organized into four parts (and the full motivation for it is found in
    part 1):'
  prefs: []
  type: TYPE_NORMAL
- en: '[College Football Conference Realignment — Exploratory Data Analysis in Python](https://medium.com/towards-data-science/college-football-conference-realignment-exploratory-data-analysis-in-python-6f4a74037572)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[College Football Conference Realignment — Regression](/college-football-conference-realignment-regression-8f0776278d55)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[College Football Conference Realignment — Clustering](https://medium.com/p/6ca16840ed3d#0733-ef9637a21b53)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[College Football Conference Realignment — node2vec](https://medium.com/towards-data-science/college-football-conference-realignment-node2vec-ba2e931bb1c)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/9ac3d6a3c19c4114817821937ef1c400.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Norbert Braun](https://unsplash.com/@medion4you?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'Hopefully, each part of the series provides you with a fresh perspective on
    the future of the beloved game of college football. For those of you who did not
    read part 1 a quick synopsis is that I created my own data set compiled from sources
    across the web. These data include [basic information about each FBS program](https://en.wikipedia.org/wiki/List_of_NCAA_Division_I_FBS_football_programs),
    a non-canonical approximation of all [college football rivalries](https://en.wikipedia.org/wiki/List_of_NCAA_college_football_rivalry_games),
    [stadium size](https://en.wikipedia.org/wiki/List_of_NCAA_Division_I_FBS_football_stadiums),
    [historical performance](https://en.wikipedia.org/wiki/List_of_NCAA_Division_I_FBS_football_bowl_records),
    [frequency appearances in AP top 25 polls](https://collegepollarchive.com/football/index.cfm),
    whether the school is an [AAU](https://www.aau.edu/) or [R1](https://en.wikipedia.org/wiki/List_of_research_universities_in_the_United_States)
    institution (historically important for membership in the Big Ten and Pac 12),
    the number of [NFL draft picks](https://www.ncaa.com/news/football/article/2020-04-27/college-football-teams-most-nfl-draft-picks-2000),
    [data on program revenue](https://graphics.wsj.com/table/NCAA_2019) from 2017–2019,
    and a [recent estimate](https://drive.google.com/file/d/1MiUOwx8X3H2bSkUOz8a1YhceyJWLLCoJ/view)
    on the size of college football fan bases. As it turns out, stadium capacity,
    2019 revenue, and historical AP poll success correlate strongly with the estimated
    fan base size in Tony Altimore’s analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4cc2b8e4d2962633d1dfb3b1ee4302bd.png)'
  prefs: []
  type: TYPE_IMG
- en: The correlation matrix shows a perfect positive relationship between each feature
    and itself. We also see high correlation between stadium capacity, fan base size,
    2019 revenue, and the percentage of weeks appearing in the AP top 25 between 2001
    and 2021.
  prefs: []
  type: TYPE_NORMAL
- en: '**Supervised Learning**'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, this got me thinking: can we create a simple regression model to estimate
    fan base size?'
  prefs: []
  type: TYPE_NORMAL
- en: Broadly, we can divide machine learning into supervised and unsupervised learning.
    In supervised learning, the goal is to predict a pre-defined discrete class or
    continuous variable. In unsupervised learning, the goal is to discover trends
    in the data that are non-obvious. Regression is a type of supervised learning
    where the prediction target is a continuous variable. A great [reference guide
    and resource](https://stanford.edu/~shervine/teaching/) was put together by Shervine
    and Afshine Amidi. (It has been translated into 11 other languages!)
  prefs: []
  type: TYPE_NORMAL
- en: Our choice of regression model is limited by the low number of observations
    in the data as there are only 133 teams in college football. Regardless of our
    model choice, the [scikit-learn](https://scikit-learn.org/stable/index.html) package
    will have us covered. It is easy to implement and well documented.
  prefs: []
  type: TYPE_NORMAL
- en: '**Feature Engineering**'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have our approach, we can re-structure our data for optimal model
    performance. This is commonly referred to as feature engineering. First, we import
    dependencies and upload the data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We are only going to keep the features that our relevant to this analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Now, we can split this data into features, X, and labels, y. In this case, the
    features are everything except estimated fan base size. That estimate serves as
    the label.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now, we can transform our categorical features into [one-hot encoding](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)
    vectors using pandas. This transforms our column of conference names into several
    columns of Boolean values.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We can easily perform a 70–30 training-test set split of the data using the
    train_test_split function in scikit-learn. For our purposes, that gives us 93
    training observations and 40 test observations.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We will transform the numeric features using min-max scaling. Min-max scaling
    is important because we can change the range of each numeric distribution to between
    0 and 1 while maintaining the shape of the distribution. It is important to implement
    this after splitting the data into a training and test set to avoid data leakage.
    There are pre-defined methods to do this using sci-kit learn including a [built-in
    pipeline function](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler)
    where we can define the type of preprocessing, but for our purposes, I defined
    my own min_max_scaling function and converted all the columns using this function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we convert all our features in the train and test sets separately to avoid
    data leakage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '**Linear Regression**'
  prefs: []
  type: TYPE_NORMAL
- en: With that, we are ready to run our model. Let’s start simple with [linear regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We can measure how well the regression performed using the R-squared metric
    compute by the score() funciton.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Unfortunately, the R-squared is only about 0.5, so our prediction isn’t great.
    We can plot the actual fan base size compared to the projected fan base size using
    plotly. Below, the size of each point in the scatter plot is the size of the absolute
    percent error. The color indicates whether it was an under prediction. You can
    visually see that the model performs worst for small fan bases:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/8534abaf590404d820561c486a2429e5.png)'
  prefs: []
  type: TYPE_IMG
- en: In the plot we can visually see the performance of the linear regression comparing
    actual fan base size (in millions) to the predicted size. The size of the points
    is the absolute percent error and the color represents whether the model over
    or under predicts.
  prefs: []
  type: TYPE_NORMAL
- en: '**Random Forest**'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have seen the performance of our linear model, let’s try a more
    advanced machine learning model called random forest. Random forest relies on
    a concept called bagging to improve prediction. It essentially produces many different
    decision trees which each vary slightly due to introduced randomization. It combines
    what it learns in each of these trees to improve its overall prediction.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/967633e86aaa08e59de2436f17ac00a6.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Wikipedia](https://en.wikipedia.org/wiki/Random_forest) includes a great visualization
    for how random forests work.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Conveniently, we do not need to scale our data for a random forest model because
    it does not make predictions based on distance measures. So, we can re-sample
    from our train_test_split() function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Now, we can easily train a random forest model with 100 trees in the forest
    and unlimited depth in each tree.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s see if we have any improvement in our R-squared value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The R-squared is now 0.78 which is a great improvement! If we create the exact
    same plot as above with our new random forest model, we can see that we have a
    lot better performance with small fan bases. Importantly, we are also no longer
    predicting negative sizes of fan bases.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b6289edeca74c65bdb565da4fa3872c5.png)'
  prefs: []
  type: TYPE_IMG
- en: The random forest model performs much better at comparing actual fan base size
    (in millions) to the predicted size. There are no more teams with negative fans!
  prefs: []
  type: TYPE_NORMAL
- en: So, what is driving the predictions? Random forest is great for explainability
    because it includes an attribute called feature importance. Similar to a coefficient
    in linear regression, these are measures of how much the random forest model relied
    on a feature to make its prediction. Feature importance is a relative metric,
    so it can tell us how useful a feature is within this model only.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/c3c6f903a7cbf54c377aaa35b4605d48.png)'
  prefs: []
  type: TYPE_IMG
- en: The feature importance from the random forest model shows that on-field performance
    is a driver of fan base size.
  prefs: []
  type: TYPE_NORMAL
- en: Based on the bar chart above comparing our different features, on-field performance
    seems to be driving predictions. The most important feature was the percentage
    of weeks a team has been in the AP top 25 in the last 20 years. The next most
    important group of features is the Wall Street Journal value/revenue data. It
    follows that a team with more fans makes more money. Then we see that NFL draft
    picks, stadium capacity (more fans = bigger stadium), bowl game appearances, and
    historical win percentage are important. Geographic location, enrollment, years
    playing football, and academic success don’t seem to make for good predictors.
  prefs: []
  type: TYPE_NORMAL
- en: I save the best takeaway for last, as it is relevant to the conference realignment
    discussion. Did you notice the right side of the graph? Conference membership
    is not an important predictor of fan base size. As we discussed in part 1 of this
    blog series, correlation is not causation, and the same holds for feature importance.
    However, it does seem to indicate that you can just as quickly gain or lose fans
    in any conference. It’s all about the product on the field.
  prefs: []
  type: TYPE_NORMAL
- en: '**Model Improvements**'
  prefs: []
  type: TYPE_NORMAL
- en: I won’t include it in this blog, but we could spend some time improving these
    models with better feature engineering or hyperparameter tuning. It is also better
    to report accuracy from cross-validation, as well. Our dataset is small, so I
    will save this for another blog, as well.
  prefs: []
  type: TYPE_NORMAL
- en: Be sure to keep reading on to part 3 of this blog series as we finally dive
    into some data-driven suggestions for college football conferences.
  prefs: []
  type: TYPE_NORMAL
- en: Interested in my content? Please consider [following me on Medium](https://medium.com/@gspmalloy).
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow me on Twitter: @malloy_giovanni'
  prefs: []
  type: TYPE_NORMAL
- en: Any fun use cases for regression in college football that you’ve found? How
    would you improve on this model?
  prefs: []
  type: TYPE_NORMAL
