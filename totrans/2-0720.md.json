["```py\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport joblib\n\n#Load data\nboston = datasets.load_boston()\ndf = pd.DataFrame(boston.data, columns = boston.feature_names)\ndf['MEDV'] = boston.target \n\n#Split Model\nX = df.drop(['MEDV'], axis = 1) \ny = df['MEDV']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 42)\n\n#Model Creation\nlm = LinearRegression()\nlm.fit(X_train,y_train)\n\nwith open('model.joblib', 'wb') as f:\n    joblib.dump(lm,f)\n\nwith open('model.joblib', 'rb') as f:\n    predictor = joblib.load(f)\n\nprint(\"Testing following input: \")\nprint(X_test[0:1])\nsampInput = [[0.09178, 0.0, 4.05, 0.0, 0.51, 6.416, 84.1, 2.6463, 5.0, 296.0, 16.6, 395.5, 9.04]]\nprint(type(sampInput))\nprint(predictor.predict(sampInput))\n```", "```py\nimport joblib\nimport os\nimport json\n\n\"\"\"\nDeserialize fitted model\n\"\"\"\ndef model_fn(model_dir):\n    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n    return model\n\n\"\"\"\ninput_fn\n    request_body: The body of the request sent to the model.\n    request_content_type: (string) specifies the format/variable type of the request\n\"\"\"\ndef input_fn(request_body, request_content_type):\n    if request_content_type == 'application/json':\n        request_body = json.loads(request_body)\n        inpVar = request_body['Input']\n        return inpVar\n    else:\n        raise ValueError(\"This model only supports application/json input\")\n\n\"\"\"\npredict_fn\n    input_data: returned array from input_fn above\n    model (sklearn model) returned model loaded from model_fn above\n\"\"\"\ndef predict_fn(input_data, model):\n    return model.predict(input_data)\n\n\"\"\"\noutput_fn\n    prediction: the returned value from predict_fn above\n    content_type: the content type the endpoint expects to be returned. Ex: JSON, string\n\"\"\"\n\ndef output_fn(prediction, content_type):\n    res = int(prediction[0])\n    respJSON = {'Output': res}\n    return respJSON\n```", "```py\nimport boto3\nimport json\nimport os\nimport joblib\nimport pickle\nimport tarfile\nimport sagemaker\nfrom sagemaker.estimator import Estimator\nimport time\nfrom time import gmtime, strftime\nimport subprocess\n\n#Setup\nclient = boto3.client(service_name=\"sagemaker\")\nruntime = boto3.client(service_name=\"sagemaker-runtime\")\nboto_session = boto3.session.Session()\ns3 = boto_session.resource('s3')\nregion = boto_session.region_name\nprint(region)\nsagemaker_session = sagemaker.Session()\nrole = \"Replace with your SageMaker IAM Role\"\n\n#Build tar file with model data + inference code\nbashCommand = \"tar -cvpzf model.tar.gz model.joblib inference.py\"\nprocess = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\noutput, error = process.communicate()\n\n#Bucket for model artifacts\ndefault_bucket = sagemaker_session.default_bucket()\nprint(default_bucket)\n\n#Upload tar.gz to bucket\nmodel_artifacts = f\"s3://{default_bucket}/model.tar.gz\"\nresponse = s3.meta.client.upload_file('model.tar.gz', default_bucket, 'model.tar.gz')\n```", "```py\nvariable \"sm-iam-role\" {\n    type = string\n    default = \"Add your SageMaker IAM Role ARN here\"\n    description = \"The IAM Role for SageMaker Endpoint Deployment\"\n}\n\nvariable \"container-image\" {\n    type = string\n    default = \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3\"\n    description = \"The container you are utilizing for your SageMaker Model\"\n}\n\nvariable \"model-data\" {\n    type = string\n    default = \"s3://sagemaker-us-east-1-474422712127/model.tar.gz\"\n    description = \"The pre-trained model data/artifacts, replace this with your training job.\"\n}\n\nvariable \"instance-type\" {\n    type = string\n    default = \"ml.m5.xlarge\"\n    description = \"The instance behind the SageMaker Real-Time Endpoint\"\n}\n```", "```py\nvariable \"memory-size\" {\n    type = number\n    default = 4096\n    description = \"Memory size behind your Serverless Endpoint\"\n}\n\nvariable \"concurrency\" {\n    type = number\n    default = 2\n    description = \"Concurrent requests for Serverless Endpoint\"\n}\n```", "```py\n# SageMaker Model Object\nresource \"aws_sagemaker_model\" \"sagemaker_model\" {\n  name = \"sagemaker-model-sklearn\"\n  execution_role_arn = var.sm-iam-role\n```", "```py\nprimary_container {\n    image = var.container-image\n    mode = \"SingleModel\"\n    model_data_url = var.model-data \n    environment = {\n      \"SAGEMAKER_PROGRAM\" = \"inference.py\"\n      \"SAGEMAKER_SUBMIT_DIRECTORY\" = var.model-data\n    }\n  }\n```", "```py\ntags = {\n    Name = \"sagemaker-model-terraform\"\n  }\n```", "```py\n# Create SageMaker endpoint configuration\nresource \"aws_sagemaker_endpoint_configuration\" \"sagemaker_endpoint_configuration\" {\n  name = \"sagemaker-endpoint-configuration-sklearn\"\n\n  production_variants {\n    initial_instance_count = 1\n    instance_type = var.instance-type\n    model_name = aws_sagemaker_model.sagemaker_model.name\n    variant_name = \"AllTraffic\"\n  }\n\n  tags = {\n    Name = \"sagemaker-endpoint-configuration-terraform\"\n  }\n}\n```", "```py\n# Create SageMaker Real-Time Endpoint\nresource \"aws_sagemaker_endpoint\" \"sagemaker_endpoint\" {\n  name = \"sagemaker-endpoint-sklearn\"\n  endpoint_config_name = aws_sagemaker_endpoint_configuration.sagemaker_endpoint_configuration.name\n\n  tags = {\n    Name = \"sagemaker-endpoint-terraform\"\n  }\n\n}\n```", "```py\naws configure\n```", "```py\nterraform init\n```", "```py\nterraform apply\n```"]