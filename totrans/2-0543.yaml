- en: Comprehensive Time Series Exploratory Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/comprehensive-time-series-exploratory-analysis-78bf40d16083](https://towardsdatascience.com/comprehensive-time-series-exploratory-analysis-78bf40d16083)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A deep dive into air quality data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@erich.hs?source=post_page-----78bf40d16083--------------------------------)[![Erich
    Silva](../Images/448dee1644d3f3e092bbbcfbbf07592d.png)](https://medium.com/@erich.hs?source=post_page-----78bf40d16083--------------------------------)[](https://towardsdatascience.com/?source=post_page-----78bf40d16083--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----78bf40d16083--------------------------------)
    [Erich Silva](https://medium.com/@erich.hs?source=post_page-----78bf40d16083--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----78bf40d16083--------------------------------)
    ·18 min read·Nov 25, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a6c9e51ca7e3e5d265d6379258366dc9.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Jason Blackeye](https://unsplash.com/@jeisblack?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/collections/55366/my-first-collection/981603704225affe48a9007fc5094d84?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: Here you are with a dataset indexed by time stamps. Your data might be about
    storage demand and supply, and you are tasked with predicting the ideal replenishment
    intervals for a strategic product. Or maybe you need to translate historical sales
    information into key actionable insights for your team. Perhaps your data is financial,
    with information about historical interest rates and a selection of stock prices.
    Maybe you are tasked with modelling market volatility and need to quantify monetary
    risk over an investment horizon. From social sciences and energy distribution
    or from healthcare to environmental studies. The examples are numerous. But what
    do these scenarios have in common? One, you have a time series task at hand. And
    two, you will certainly benefit from starting with a **succinct yet comprehensive
    exploratory analysis**.
  prefs: []
  type: TYPE_NORMAL
- en: Table of Contents
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[The Goal of this Article](#d55f)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Dataset Description](#f0f7)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Libraries and Dependencies](#d791)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started](#85bf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Big Picture](#b967)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Detailed View](#fa99)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Missing Values](#9720)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Intermittency](#ce22)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Seasonality](#3002)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Pearson Correlation](#773d)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Stationarity](#0270)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[First-Order Differencing](#4564)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Autocorrelation](#18ad)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[References](#9856)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Goal of this Article
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: But what does it mean to perform an **exploratory time series analysis**? Different
    from other data science problems, gathering insights from time series data can
    be tricky and everything but straightforward. Your data might have important underlying
    trends and seasons or be suitable for nested forecasting within its intricate
    cyclical patterns. Differentiating abnormal outliers caused by a failure in your
    data generation process from actual anomalies that hold key information can be
    challenging. And dealing with missing values might not be as simple as you expect.
  prefs: []
  type: TYPE_NORMAL
- en: This article will outline a process that has worked for me when studying time
    series datasets. You will follow me along as I explore the measurements of fine
    particulate matter, also known as PM 2.5, one of the main contributors to air
    pollution and air quality indices. I will focus on laying out some best practices
    with specific attention to detail to generate sharp and highly informative visualizations
    and statistical summaries.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset Description
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The data studied here are from four monitoring stations in the city of Vancouver,
    British Columbia, Canada. They hold one-hour average measurements of fine particulate
    matter PM 2.5 (fine particles with diameters of 2.5 microns and smaller) in µg/m3
    (micrograms per cubic meter) with values from January 1st, 2016, to July 3rd,
    2022.
  prefs: []
  type: TYPE_NORMAL
- en: PM 2.5 primarily comes from the burn of fossil fuels, and in cities, it normally
    originates from car traffic and construction sites. Another major source of the
    pollutant are forest and grass fires, and they are easily carried away by the
    wind [1].
  prefs: []
  type: TYPE_NORMAL
- en: The image below shows the approximate location of the stations we will explore.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0b4d72407c13441c051091b24c3cbbab.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 1.** Vancouver map with air monitoring stations. Author customized
    map created in Google Maps.'
  prefs: []
  type: TYPE_NORMAL
- en: The dataset is from the [British Columbia Data Catalogue](https://catalogue.data.gov.bc.ca/),
    and as stated by the publisher, it has not been quality-assured [5]. For the version
    you will see here, I have preprocessed some minor problems, such as assigning
    negative measurements (only 6 out of 57k observations) as missing values and generating
    a master DataFrame with the stations of our choice.
  prefs: []
  type: TYPE_NORMAL
- en: Libraries and Dependencies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will use Python 3.9 and the plotting libraries [Matplotlib](https://matplotlib.org/)
    and [Seaborn](https://seaborn.pydata.org/) for our visualizations. For statistical
    tests and data exploration, we will work with the [statsmodels](https://www.statsmodels.org/stable/index.html)
    Python module and the [SciPy](https://scipy.org/) library. All our data manipulation
    and auxiliary tasks will be handled with [Pandas](https://pandas.pydata.org/)
    and [Numpy](https://numpy.org/).
  prefs: []
  type: TYPE_NORMAL
- en: These packages are natively available in popular Python distributions and hosted
    notebooks, such as Anaconda and Miniconda, Google Collab or Kaggle Notebooks.
    So every code example here should be easily reproducible in your environment of
    choice.
  prefs: []
  type: TYPE_NORMAL
- en: Getting Started
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Starting by importing our libraries, we will call `matplotlib.dates.mdates`
    , and the `datetime` module to help us work with our DateTime index. To generate
    consistent visualizations, I also like to start by defining our plot styles and
    the color palette. So let's begin with.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/864c9f40735c096e63f46c16ca015f61.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 2.** Seaborn “mako” color palette. Image by the author.'
  prefs: []
  type: TYPE_NORMAL
- en: After reading the .csv file, we will define the timestamp `DATE_PS` as a NumPy
    `datetime64` object and set it as our DataFrame index. This common step will enable
    some Pandas time series functionalities, such as the one used below to create
    datepart features in our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cc600cbc111b60724441fcdba4ac9979.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 3.** Master DataFrame slice with datepart features. Image by the author.'
  prefs: []
  type: TYPE_NORMAL
- en: The Big Picture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here is an ample view of where we will dive in — This is where we spend some
    time to get a first grasp of our data.
  prefs: []
  type: TYPE_NORMAL
- en: For this visualization, we will use Seaborn relational plots that will read
    from an aggregated long version of our DataFrame. For that, we will use Pandas
    `melt` and `resample` methods with a mean aggregation in 24 hours intervals. This
    will reduce our data granularity from hourly to daily average measurements, and
    it is done to reduce the time it takes to generate the plot.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/391f62107bd34f7ed8a3c8e2d0ef102d.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 4\.** PM 2.5 time series plot of monitoring stations. Image by the
    author.'
  prefs: []
  type: TYPE_NORMAL
- en: 'With a clear picture of all four stations along the entire span of our time
    series, it is already possible to start taking some notes:'
  prefs: []
  type: TYPE_NORMAL
- en: There are some major anomalies, and they seem to be prevalent during summer
    and early autumn.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These anomalies appear to result from large-scale events, as they affect all
    four stations approximately during the same periods.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you look carefully, **I have included a faded gray scatter plot of all stations
    within every chart**. With this subtle detail, it is possible to see that the
    anomaly present in 2017, for example, had a major effect in both North Vancouver
    stations (they reached higher PM 2.5 values), while the opposite is true for the
    2018 event. This technique also ensures that all four line charts are within the
    same Y-axis range.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Some good practices that you can take from this first plot:'
  prefs: []
  type: TYPE_NORMAL
- en: Matplotlib allows for highly customizable axis ticker locators and formatters.
    In this example, I have used a `MonthLocator` from the `mdates` module to create
    **minor month locators** in the X-axis, which help with overall readability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The exact expected dates range from our plot is passed to the plot title or
    subtitle. “Expected” because our visualization might be truncated due to missing
    values on either end of the plotted period, and this practice can help identify
    those problems. It is also a good documentation practice to report your findings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Great start, but let’s narrow down our view slightly. In the next section, we
    will look at shorter periods of time, but now with our original hourly granularity.
  prefs: []
  type: TYPE_NORMAL
- en: A Detailed View
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: From now on, we will start defining some functions we can quickly call to generate
    tailored visualizations. You can think of it as a means of setting up an *analytical
    toolset* that will be extremely helpful moving forward.
  prefs: []
  type: TYPE_NORMAL
- en: This first function will help us look at individual time series within a specific
    period in time. We will start by looking at the year 2017 for the North Vancouver
    Mahon Park Station.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/812ff71eedf73c5eaa96dcefe8b48a02.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 5.** North Vancouver Mahon Park PM 2.5 plot for 2017\. Image by the
    author.'
  prefs: []
  type: TYPE_NORMAL
- en: We can see here that there are localized smaller spikes in addition to the major
    anomalies. There were also periods of higher volatility (where variance increases
    during a short time span) at the beginning of the year and in December 2017.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s dive in a bit further and look outside the anomaly range so we can analyze
    our values within a narrower span in the Y-axis.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2e78a2e70348757efe3101fc5e2e91ce.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 6.** North Vancouver Mahon Park PM 2.5 plot for 15 Apr to 1 Jul 2017\.
    Image by the author.'
  prefs: []
  type: TYPE_NORMAL
- en: We can see some missing values here. The `fill=True` parameter of our function
    helps identify that and is a good way to give visual emphasis to missingness in
    our data. Those small interruptions that are initially hard to notice are now
    clearly visible.
  prefs: []
  type: TYPE_NORMAL
- en: Another detail you might have noticed is the X-axis's custom date format. For
    the plot above, I have enhanced our `plot_sequence()` function with custom major
    and minor locators and formatters. This new functionality now adapts our plot
    to the visualization’s time span and formats the X-axis accordingly. Below is
    the code snippet that was included in the function.
  prefs: []
  type: TYPE_NORMAL
- en: Now we know that our dataset has interruptions, so let's take a better look
    at that.
  prefs: []
  type: TYPE_NORMAL
- en: Missing Values
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For tabular data problems, in this section, we would probably be focused on
    defining MAR (Missing At Random) from MNAR (Missing Not At Random). Instead, knowing
    the nature of our data (sensorial temporal measurements), we know that interruptions
    in the data stream are probably not intended. Hence, in these cases, it is more
    important to distinguish isolated from continuously missing values and missing
    values from completely missing samples. The possibilities here are vast, and if
    you want to learn more, I have dedicated an article to that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/handling-gaps-in-time-series-dc47ae883990?source=post_page-----78bf40d16083--------------------------------)
    [## Handling Gaps in Time Series'
  prefs: []
  type: TYPE_NORMAL
- en: Missingness analysis and evaluation methods for short and long sequences imputation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/handling-gaps-in-time-series-dc47ae883990?source=post_page-----78bf40d16083--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: For now, let’s start by looking at a **missing values heatmap**. Again we will
    define a function for that.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a72564713c437fe887ef281cb73ccf2a.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 7.** Missing values heatmap. Image by the author.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Heatmaps are great as they allow us to quantify missingness and **localize
    them in the time axis**. From here, we can denote:'
  prefs: []
  type: TYPE_NORMAL
- en: We don’t have completely missing samples (where missing values occur simultaneously
    for a time period). That’s expected as the data streaming from the monitoring
    stations happens independently.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are long sequences of missing values early on in our timeline, and data
    availability seems to improve as time goes by.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Some statistical analysis in the latter sections will be problematic with missing
    values. Therefore we will use simple techniques to treat them as we see fit, such
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: Pandas `ffill()` and `bfill()` methods. They are used to carry forward or backwards,
    respectively, the nearest available value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linear or spline interpolation with Pandas `interpolate()` method. It uses neighbouring
    observations to draw a curve to fill in a missing interval.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Intermittency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: From the nature of our data, we should not expect negative values. As mentioned
    in the beginning, I treated them as missing when preprocessing the data. Let’s
    call our summary statistics to confirm that.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/51e391457d564a5562c43407669238b3.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 8.** Summary statistics. Image by the author.'
  prefs: []
  type: TYPE_NORMAL
- en: We see that our minimum measurements are zeros for each station, which leads
    us to the next question. **Is our time series intermittent**?
  prefs: []
  type: TYPE_NORMAL
- en: Intermittency is characterized when your data has a large number of values that
    are exactly zero. This behaviour poses specific challenges and must be taken into
    account during model selection. So how often do we see zero values in our data?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/832ea9b9837e6f59807365e88645494f.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 9.** Zero values count. Image by the author.'
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the amount of zeros is negligible, so we don’t have intermittent
    series. This is an easy but crucial check, especially if your goal is forecasting.
    It might be hard for some models to predict an absolute zero, and that can be
    a problem if you want to forecast demand, for example. You don’t want to plan
    out the delivery of, let’s say, three products to your client if, in fact, he
    is expecting none.
  prefs: []
  type: TYPE_NORMAL
- en: Seasonality
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Understanding the cycles in your time series is fundamental to planning the
    modeling phase. You might be losing key information of smaller cycles if you decide
    to aggregate your data too much, or it can help you determine the feasibility
    of forecasting on a smaller granularity.
  prefs: []
  type: TYPE_NORMAL
- en: We will use some box plots to start looking into that. But first, we will temporarily
    remove the top 5% percentile so we can look at the data on a better scale.
  prefs: []
  type: TYPE_NORMAL
- en: In this next function, we will use a series of boxplots to investigate the cycles
    within our data. We will also map our color palette to the median values so it
    can serve as another neat visual clue.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/feb650bae5cc5093760808797184beec.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 10.** PM 2.5 hourly values. Image by the author.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This first plot returns hourly measurements. Here we can see:'
  prefs: []
  type: TYPE_NORMAL
- en: Consistently higher values for PM 2.5 from 9 AM to 2 PM.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stations outside North Vancouver also show a peak from 8 PM to 10 PM.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Early mornings hold the lowest values for PM 2.5 from 2 AM to 5 AM.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now looking at weekly seasonality and the difference in values across the week.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/abb65cc19357834cc48f4025374b6a6e.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 11.** PM 2.5 daily values. Image by the author.'
  prefs: []
  type: TYPE_NORMAL
- en: 'From here, we see:'
  prefs: []
  type: TYPE_NORMAL
- en: Lower PM 2.5 values during weekends.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A slightly higher trend for pollution levels on Tuesdays.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And finally, looking at the month-to-month trend.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/05164ab242973a9c07c5f9029b02fd44.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 12.** PM 2.5 monthly values. Image by the author.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Where we can observe:'
  prefs: []
  type: TYPE_NORMAL
- en: Consistently higher values for PM 2.5 in August for all years.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The southern stations have lower PM 2.5 values in June and July, while the North
    Vancouver ones show lower measurements in January.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, more good practices from these plots:'
  prefs: []
  type: TYPE_NORMAL
- en: Do not make naive use of your color palette, as they might mislead you to equivocate
    interpretations. Had we simply passed `pallette=”mako”` to our boxplots, it would
    have been mapped to our X-axis and not to our variable of interest.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grid plots are powerful containers of information for low-dimensional data,
    and they can be quickly set up with Seaborn `relplot()` or Matplotlib `subplots()`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can make use of the Seaborn `boxplot()` `order` parameter to reorder your
    X-axis accordingly. I used it to reorganize the day-of-week X labels in a meaningful
    order.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A more elaborate view of seasonalities can be attained from a trend-season decomposition
    from our time series. This, however, will be left for a future article where we
    can dive deeper into time series similarity and model selection. If that is a
    topic you are interested in, **make sure to follow me here on Medium to receive
    my future publications**.
  prefs: []
  type: TYPE_NORMAL
- en: For now, let’s try a quick look at one of our well-known statistical coefficients
    to investigate the **linear relationship** between our four stations.
  prefs: []
  type: TYPE_NORMAL
- en: Pearson Correlation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: R programmers might be familiar with the following plot. A **correlogram** is
    a concise and highly informative visualization that is implemented at multiple
    R libraries, such as the `ggpairs()` in the `GGally` package. The upper diagonal
    of a correlogram shows us bivariate correlations, or Pearson correlation coefficients
    between numeric variables in our data. In the lower diagonal, we see scatterplots
    with regression curves fitted to our data. Finally, in the main diagonal, we have
    histograms and a density curve of each variable.
  prefs: []
  type: TYPE_NORMAL
- en: The following code is an adapted implementation using the Seaborn `PairGrid()`
    plot and yet another function for our analytical toolset.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eb6d69d7e6c13f9f109b8467b5f5d425.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 13.** PM 2.5 Correlogram on all four stations. Image by the author.'
  prefs: []
  type: TYPE_NORMAL
- en: As expected, our stations are highly correlated, especially the ones closer
    to each other, such as both in North Vancouver.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note that to alleviate the computational time, our data was
    aggregated in 6-hours periods. If you experiment with this plot with bigger aggregation
    periods, you will see an increase in the correlation coefficients, as mean aggregations
    tend to smoothen out the outliers present in the data.
  prefs: []
  type: TYPE_NORMAL
- en: If you were already introduced to time series analysis, you might now be thinking
    about other kinds of correlation that are worth checking. But first, we need to
    test our time series for **stationarity**.
  prefs: []
  type: TYPE_NORMAL
- en: Stationarity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A stationary time series is one whose statistical properties do not change over
    time. In other words, it has a constant mean, variance, and autocorrelation independent
    of time [4].
  prefs: []
  type: TYPE_NORMAL
- en: '**Several forecasting models rely on time series stationarity**, hence the
    importance of testing for it in this exploratory phase. Our next function will
    make use of statsmodels implementation of two commonly used tests for stationarity,
    the *Augmented Dickey-Fuller* (“ADF”) test and the *Kwiatkowski-Phillips-Schmidt-Shin*
    (“KPSS”) test.'
  prefs: []
  type: TYPE_NORMAL
- en: I will leave both tests’ hypotheses below. Note that they have opposing null
    hypotheses, so we will create a “Decision” column for an easy interpretation of
    their results. You can read more about both tests in the [statsmodels documentation](https://www.statsmodels.org/dev/examples/notebooks/generated/stationarity_detrending_adf_kpss.html).
  prefs: []
  type: TYPE_NORMAL
- en: '**Augmented Dickey-Fuller (ADF)** test hypothesis:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '• **H0**: A unit root is present in the time series sample (**Non-stationary**)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '• **Ha**: There is no root unit present in the time series sample (**Stationary**)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Kwiatkowski-Phillips-Schmidt-Shin (KPSS)** test hypothesis:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '• **H0**: The data is stationary around a constant (**Stationary**)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '• **Ha**: A unit root is present in the time series sample (**Non-stationary**)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Now an opportune question to ask is on which scale we should check for stationarity.
    The answer will highly depend on how you will model your data, and one of the
    goals of a comprehensive exploratory analysis is exactly to help you with that
    decision.
  prefs: []
  type: TYPE_NORMAL
- en: For illustration purposes, in the following example, we will take a look at
    the months of January 2016 and January 2022 for the Vancouver International Airport
    Station and see if there was a change in behavior from 2016 to 2022 in the data.
  prefs: []
  type: TYPE_NORMAL
- en: You might remember from our Missing Values section that we can use Pandas `ffill()`,
    `bfill()`, and `interpolate()` methods to quickly impute interruptions in the
    series. You can see that I have defined a dedicated argument `fillna` to our function
    to select from either of these methods to quickly work around missing values,
    as both tests only accept complete samples.
  prefs: []
  type: TYPE_NORMAL
- en: Now coming back to our results.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bf5b4a7ec60ce8f9a3fc71af93ca4c23.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 14.** ADF and KPSS stationarity test results for Jan 2016\. Image
    by the author.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/437dc51467485b08b088d10547764b9f.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 15.** ADF and KPSS stationarity test results for Jan 2022\. Image
    by the author.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see that for 2016 both tests indicated Non-Stationarity, but for 2022
    the results diverged. The [statsmodels documentation](https://www.statsmodels.org/dev/examples/notebooks/generated/stationarity_detrending_adf_kpss.html)
    clearly lists the interpretations for the results when the ADF and KPSS tests
    are performed together [6]:'
  prefs: []
  type: TYPE_NORMAL
- en: '• **Case 1**: **Both tests conclude that the series is not stationary** — The
    series is not stationary'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**• Case 2**: **Both tests conclude that the series is stationary** — The series
    is stationary'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**• Case 3**: **KPSS indicates stationarity** and **ADF indicates non-stationarity**
    — The series is trend stationary. **Trend needs to be removed** to make series
    strict stationary. The detrended series is checked for stationarity.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**• Case 4**: **KPSS indicates non-stationarity** and **ADF indicates stationarity**
    — The series is difference stationary. **Differencing is to be used** to make
    series stationary. The differenced series is checked for stationarity.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If you repeat this operation for all four stations across multiple months, you
    will see that *Case 4* is predominant in the data. This leads us to our next section
    about **first-order differencing to make our data stationary**.
  prefs: []
  type: TYPE_NORMAL
- en: First-Order Differencing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As one of the most common transformation techniques, applying first- or second-order
    differencing to a time series is widely used to make the data suitable for statistical
    models that can only be used on stationary time series. Here we will look at the
    technique applied to one of the previous examples in the month of January 2016\.
    But first, let’s take a look at the original data before the transformation with
    our `plot_sequence()` function.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f6e5630d6aca9426311c27297bee9d2d.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 16.** Vancouver International Airport PM 2.5 plot for Jan 2016\. Image
    by the author.'
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the variance in the period changes significantly from the beginning
    to the end of the month. The mean PM 2.5 also seems to go from a higher to a lower,
    more stable value. These are some of the characteristics that confirm the non-stationarity
    of the series.
  prefs: []
  type: TYPE_NORMAL
- en: Again, Pandas has a quite convenient method to differentiate our data. We will
    call `.diff()` to our DataFrame and instantiate it as a first-order differentiated
    version of our data. So let’s plot the same period again.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8e7d8e28adffd3a0893264a4ff99629d.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 17.** Vancouver International Airport differentiated PM 2.5 plot for
    Jan 2016\. Image by the author.'
  prefs: []
  type: TYPE_NORMAL
- en: Besides the still oscillating variance, the data is now clearly more stable
    around a mean value. We can once again call our `stationarity_test()` function
    to check for stationarity on the differentiated data.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b09ca4706b8991fd1210efa77464357e.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 18.** ADF and KPSS stationarity test results for differentiated data.
    Image by the author.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There we have it. We can put another check on our comprehensive exploratory
    time series analysis, as we have now confirmed that:'
  prefs: []
  type: TYPE_NORMAL
- en: We are dealing with non-stationary time series.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: First-order differencing is an appropriate transformation technique to make
    it stationary.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And that finally leads us to our last section.
  prefs: []
  type: TYPE_NORMAL
- en: Autocorrelation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once our data is stationary, we can investigate other key time series attributes:
    **partial autocorrelation** and **autocorrelation**. In formal terms:'
  prefs: []
  type: TYPE_NORMAL
- en: The **autocorrelation function (ACF)** measures the linear relationship between
    lagged values of a time series. In other words, it measures the correlation of
    the time series with itself. *[2]*
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The **partial autocorrelation function (PACF)** measures the correlation between
    lagged values in a time series when we remove the influence of correlated lagged
    values in between. Those are known as confounding variables. *[3]*
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Both metrics can be visualized with statistical plots known as correlograms.
    But first, it is important to develop a better understanding of them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since this article is focused on exploratory analysis and these concepts are
    fundamental to statistical forecasting models, I will keep the explanation brief,
    but bear in mind that these are highly important ideas to build a solid intuition
    upon when working with time series. For a comprehensive read, I recommend the
    great kernel “[Time Series: Interpreting ACF and PACF](https://www.kaggle.com/code/iamleonie/time-series-interpreting-acf-and-pacf)”
    by the Kaggle Notebooks Grandmaster [Leonie Monigatti](https://medium.com/u/3a38da70d8dc?source=post_page-----78bf40d16083--------------------------------).'
  prefs: []
  type: TYPE_NORMAL
- en: As noted above, autocorrelation measures how the time series correlates with
    itself on previous *q* lags. You can think of it as a measurement of the linear
    relationship of a subset of your data with a copy of itself shifted back by *q*
    periods. **Autocorrelation, or ACF, is an important metric to determine the order
    *q* of Moving Average (MA) models**.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, partial autocorrelation is the correlation of the time series
    with its *p* lagged version, but now solely regarding its **direct effects**.
    For example, if I want to check the partial autocorrelation of the *t-3* to *t-1*
    time period with my current *t0* value, I won’t care about how *t-3* influences
    *t-2* and *t-1* or how *t-2* influences *t-1*. I’ll be exclusively focused on
    the direct effects of *t-3*, *t-2*, and *t-1* on my current time stamp, *t0*.
    **Partial autocorrelation, or PACF, is an important metric to determine the order
    *p* of Autoregressive (AR) models.**
  prefs: []
  type: TYPE_NORMAL
- en: With these concepts cleared out, we can now come back to our data. Since the
    two metrics are often analyzed together, our last function will combine the PACF
    and ACF plots in a grid plot that will return correlograms for multiple variables.
    It will make use of statsmodels `plot_pacf()` and `plot_acf()` functions, and
    map them to a Matplotlib `subplots()` grid.
  prefs: []
  type: TYPE_NORMAL
- en: Notice how both statsmodels functions use the same arguments, except for the
    `method` parameter that is exclusive to the `plot_pacf()` plot.
  prefs: []
  type: TYPE_NORMAL
- en: Now you can experiment with different aggregations of your data, but remember
    that when resampling the time series, each lag will then represent a different
    jump back in time. For illustrative purposes, let's analyze the PACF and ACF for
    all four stations in the month of January 2016, with a 6-hours aggregated dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/83ab8f91f04bb1b626dd485efbdb8e54.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 19.** PACF and ACF Correlograms for Jan 2016\. Image by the author.'
  prefs: []
  type: TYPE_NORMAL
- en: Correlograms return the correlation coefficients ranging from -1.0 to 1.0 and
    a shaded area indicating the significance threshold. Any value that extends beyond
    that should be considered statistically significant.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the results above, we can finally conclude that on a 6-hours aggregation:'
  prefs: []
  type: TYPE_NORMAL
- en: Lags 1, 2, 3 (t-6h, t-12h, and t-18h) and sometimes 4 (t-24h) have significant
    PACF.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lags 1 and 4 (t-6h and t-24h) show significant ACF for most cases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And take note of some final good practices:'
  prefs: []
  type: TYPE_NORMAL
- en: Plotting correlograms for large periods of time series with high granularity
    (For example, plotting a whole-year correlogram for a dataset with hourly measurements)
    should be avoided, as the significance threshold narrows down to zero with increasingly
    higher sample sizes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I defined an `x_label` parameter to our function to make it easy to annotate
    the X-axis with the time period represented by each lag. It is common to see correlograms
    without that information, but having easy access to it can avoid misinterpretations
    of the results.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Statsmodels `plot_acf()` and `plot_pacf()` default values are set to include
    the 0-lag correlation coefficient in the plot. Since the correlation of a number
    with itself is always one, I have set our plots to start from the first lag with
    the parameter `zero=False`. It also improves the scale of the Y-axis, making the
    lags we actually need to analyze more readable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With that, we have thoroughly explored our time series. With a toolset of visualizations
    and analytical functions, we could draw a comprehensive understanding of our data.
    You have also learned some of the best practices when exploring time series datasets
    and how to present them succinctly and polishedly with high-quality plots.
  prefs: []
  type: TYPE_NORMAL
- en: Enjoyed this Story?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*You can follow me here on Medium for more articles about data science, machine
    learning, visualization, and data analytics.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*You can also find me on* [*LinkedIn*](https://www.linkedin.com/in/erich-hs/)
    *and on* [*X*](https://twitter.com/EhsErich)*, where I share shorter versions
    of these contents.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/subscribe/@erich.hs?source=post_page-----78bf40d16083--------------------------------)
    [## Get an email whenever Erich Silva publishes.'
  prefs: []
  type: TYPE_NORMAL
- en: Get an email whenever Erich Silva publishes. By signing up, you will create
    a Medium account if you don't already have…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/subscribe/@erich.hs?source=post_page-----78bf40d16083--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] “Department of Health — Fine Particles (PM 2.5) Questions and Answers.”
    Accessed October 14, 2022\. [https://www.health.ny.gov/environmental/indoors/air/pmq_a.htm](https://www.health.ny.gov/environmental/indoors/air/pmq_a.htm)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] Peixeiro, Marco. “3\. Going on a Random Walk.” Essay. In *Time Series Forecasting
    in Python*, 30–58\. O’Reilly Media, 2022.'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] Peixeiro, Marco. “5\. Modeling an Autoregressive Process.” Essay. In *Time
    Series Forecasting in Python*, 81–100\. O’Reilly Media, 2022.'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] Peixeiro, Marco. “8\. Accounting for Seasonality.” Essay. In *Time Series
    Forecasting in Python*, 156–79\. O’Reilly Media, 2022.'
  prefs: []
  type: TYPE_NORMAL
- en: '[5] Services, Ministry of Citizens’. “The BC Data Catalogue.” Province of British
    Columbia. Province of British Columbia, February 2, 2022\. [https://www2.gov.bc.ca/gov/content/data/bc-data-catalogue](https://www2.gov.bc.ca/gov/content/data/bc-data-catalogue)'
  prefs: []
  type: TYPE_NORMAL
- en: '[6] “Stationarity and Detrending (ADF/KPSS).” statsmodels. Accessed October
    17, 2022\. [https://www.statsmodels.org/dev/examples/notebooks/generated/stationarity_detrending_adf_kpss.html](https://www.statsmodels.org/dev/examples/notebooks/generated/stationarity_detrending_adf_kpss.html)'
  prefs: []
  type: TYPE_NORMAL
