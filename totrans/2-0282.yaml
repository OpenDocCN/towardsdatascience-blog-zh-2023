- en: All You Need to Know about Vector Databases and How to Use Them to Augment Your
    LLM Apps
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于向量数据库及其如何增强你的LLM应用，你需要了解的一切
- en: 原文：[https://towardsdatascience.com/all-you-need-to-know-about-vector-databases-and-how-to-use-them-to-augment-your-llm-apps-596f39adfedb](https://towardsdatascience.com/all-you-need-to-know-about-vector-databases-and-how-to-use-them-to-augment-your-llm-apps-596f39adfedb)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/all-you-need-to-know-about-vector-databases-and-how-to-use-them-to-augment-your-llm-apps-596f39adfedb](https://towardsdatascience.com/all-you-need-to-know-about-vector-databases-and-how-to-use-them-to-augment-your-llm-apps-596f39adfedb)
- en: A Step-by-Step Guide to Discover and Harness the Power of Vector Databases
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逐步指南：发现并利用向量数据库的力量
- en: '[](https://dmnkplzr.medium.com/?source=post_page-----596f39adfedb--------------------------------)[![Dominik
    Polzer](../Images/7e48cd15df31a0ab961391c0d57521de.png)](https://dmnkplzr.medium.com/?source=post_page-----596f39adfedb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----596f39adfedb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----596f39adfedb--------------------------------)
    [Dominik Polzer](https://dmnkplzr.medium.com/?source=post_page-----596f39adfedb--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dmnkplzr.medium.com/?source=post_page-----596f39adfedb--------------------------------)[![Dominik
    Polzer](../Images/7e48cd15df31a0ab961391c0d57521de.png)](https://dmnkplzr.medium.com/?source=post_page-----596f39adfedb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----596f39adfedb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----596f39adfedb--------------------------------)
    [Dominik Polzer](https://dmnkplzr.medium.com/?source=post_page-----596f39adfedb--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----596f39adfedb--------------------------------)
    ·24 min read·Sep 17, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----596f39adfedb--------------------------------)
    ·24分钟阅读·2023年9月17日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/ca07a0ddf7a94d762cbb35569b47cfba.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ca07a0ddf7a94d762cbb35569b47cfba.png)'
- en: Why we need Vector Stores for LLM apps — Image by the author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我们需要用于LLM应用的向量存储——作者提供的图片
- en: Table of Contents
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目录
- en: '**Intro**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介**'
- en: '[What is so special about Vector Databases?](#003d)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[向量数据库有什么特别之处？](#003d)'
- en: '[How do we map the meaning of a sentence to a numerical representation?](#8184)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[我们如何将句子的含义映射为数值表示？](#8184)'
- en: '[How does that help our LLM app?](#8184)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[这对我们的LLM应用有什么帮助？](#8184)'
- en: '[Why can’t we just give the LLM all the data we have?](#bc26)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[为什么我们不能直接将所有数据提供给LLM？](#bc26)'
- en: '[**Hands-On Tutorial — Text to Embeddings and Distance Metrics**](#cba0)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[**动手教程——文本到嵌入和距离度量**](#cba0)'
- en: '[1\. Text to Embeddings](#9f3a)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[1\. 文本到嵌入](#9f3a)'
- en: '[2\. Plot 384 dimensions in 2 using PCA](#45a1)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[2\. 使用PCA在2维中绘制384个维度](#45a1)'
- en: '[3\. Calculate the distance metrics](#9c2f)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[3\. 计算距离度量](#9c2f)'
- en: '**Towards Vector Stores**'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**迈向向量存储**'
- en: '[How to accelerate the Similarity Search?](#6009)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[如何加速相似性搜索？](#6009)'
- en: '[What are the different Vector Stores we can choose from?](#f02b)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[我们可以选择哪些不同的向量存储？](#f02b)'
- en: '[**Hands-On Tutorial — Set up your first Vector Store**](#7813)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[**动手教程——设置你的第一个向量存储**](#7813)'
- en: '[1\. Install chroma](#c634)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[1\. 安装chroma](#c634)'
- en: '[2\. Get/create a chroma client and collection](#7d64)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[2\. 获取/创建chroma客户端和集合](#7d64)'
- en: '[3\. Add some text documents to the collection](#fffe)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[3\. 将一些文本文档添加到集合中](#fffe)'
- en: '[4\. Extract all entries from database to excel file](#e71d)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[4\. 从数据库中提取所有条目到Excel文件](#e71d)'
- en: '[5\. Query the collection](#5d22)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[5\. 查询集合](#5d22)'
- en: '[**Summary**](#9128)[**References**](#4113)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[**总结**](#9128)[**参考文献**](#4113)'
- en: Vector databases are a hot topic right now. Companies keep raising money to
    develop their vector databases or to add vector search capabilities to their existing
    SQL or NoSQL databases.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 向量数据库目前是一个热门话题。公司们不断筹集资金以开发他们的向量数据库，或为现有的SQL或NoSQL数据库添加向量搜索功能。
- en: '![](../Images/1491bf4c5448ee19ae952f12ba4518c2.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1491bf4c5448ee19ae952f12ba4518c2.png)'
- en: Vector Store Funding — Image by the author (Chroma, 2023; Cook, 2022; Miller,
    2022)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 向量存储资助——作者提供的图片（Chroma，2023；Cook，2022；Miller，2022）
- en: What is so special about Vector Databases?
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向量数据库有什么特别之处？
- en: Vector Databases make it possible to quickly search and compare large collections
    of vectors. This is so interesting because the most up-to-date embedding models
    are highly capable of understanding the semantics/meaning behind words and translating
    them into vectors. This allows us to efficiently compare sentences with each other.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 向量数据库使得快速搜索和比较大量向量变得可能。这非常有趣，因为最新的嵌入模型能够高度理解单词背后的语义/含义，并将其转换为向量。这使得我们能够高效地比较句子之间的关系。
- en: '**Okay, but why should we care?**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**好吧，但我们为什么要关心这个呢？**'
- en: For most Large Language Model (LLM) applications we rely on that capability
    since our LLM can never know everything. It only sees like a frozen version of
    the world, which depends on the train set the LLM is trained with.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数大型语言模型（LLM）应用程序，我们依赖于这种能力，因为我们的LLM不可能知道一切。它仅仅看到的是世界的一个冻结版本，这取决于LLM的训练数据集。
- en: '![](../Images/349b159551e565144be7d1fad24af317.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/349b159551e565144be7d1fad24af317.png)'
- en: Why we need Vector Stores for LLM apps — Image by the author
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么LLM应用需要向量存储 — 作者提供的图片
- en: So we need to feed our model with additional data, information that the LLM
    can impossibly know by itself. And that all needs to happen during the runtime
    of our application. So we must have a process in place that decides as quickly
    as possible with which additional data we want to feed our model.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要为模型提供额外的数据，这些信息是LLM自己不可能知道的。而且所有这些都需要在应用程序的运行时完成。所以我们必须有一个过程，尽可能快地决定我们要为模型提供哪些额外数据。
- en: 'With traditional keyword search, we run into limitations, mainly because of
    two problems:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 使用传统的关键词搜索，我们会遇到限制，主要是因为两个问题：
- en: '**Languages are complex. In most languages, you can ask more or less the same
    question in 20 different ways.** It is often not enough to simply search our data
    for keywords. We need a way to map the meaning behind words and sentences to find
    content that’s related to the question.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语言是复杂的。在大多数语言中，你可以用20种不同的方式提出相同的问题。** 仅仅搜索关键词通常是不够的。我们需要一种将单词和句子背后的含义映射到相关内容的方式。'
- en: We also need to make sure that this search is done within milliseconds, not
    seconds or minutes. So we need a step that allows us to search the Vector Collection
    as efficiently as possible.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们还需要确保搜索在毫秒级完成，而不是秒或分钟。因此，我们需要一个步骤，以尽可能高效地搜索向量集合。
- en: First things first — How do we map the meaning of a sentence to a numerical
    representation?
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 首先 — 我们如何将句子的含义映射到数值表示？
- en: Before we can search our database, we need to translate our text content into
    vectors that capture the meaning of words and sentences. Pre-trained embedding
    models from OpenAI, Google, MetaAI, or the open source community help us do this.
    They learn from a huge corpus of text, how words are normally used and in what
    contexts. They use this extracted knowledge to map words into a multi-dimensional
    vector space. The location of the new data point in the vector space tells us
    which words are related to each other.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们能够搜索数据库之前，我们需要将文本内容转换为捕捉单词和句子含义的向量。来自OpenAI、Google、MetaAI或开源社区的预训练嵌入模型帮助我们做到这一点。它们从大量文本语料库中学习单词的常见用法及其上下文。它们利用这些提取的知识将单词映射到多维向量空间中。新数据点在向量空间中的位置告诉我们哪些单词彼此相关。
- en: 'For the simple example below, we arrange the “meaning” of various fruits and
    vegetables in a simple two-dimensional vector space. If the embedding model does
    what it is supposed to do, we would expect apple and pear to be closer than apple
    and onion (at least, that is what I would expect with my limited knowledge on
    language and fruits). Similarity can be influenced by various features. For fruits
    and vegetables this may be: Size, colour, taste, country of origin, etc. It all
    depends on what object you want to describe.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的简单示例中，我们将各种水果和蔬菜的“意义”排列在一个简单的二维向量空间中。如果嵌入模型正常工作，我们期望苹果和梨比苹果和洋葱更接近（至少，这就是我根据对语言和水果的有限了解所期望的）。相似性可以受到各种特征的影响。对于水果和蔬菜，这可能包括：大小、颜色、味道、原产国等。这一切都取决于你想描述的对象。
- en: '![](../Images/a4b0ff69a1a79b4ece04be69301cefcd.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a4b0ff69a1a79b4ece04be69301cefcd.png)'
- en: Similarity score between different types of fruit and vegetables — Image by
    the author
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 不同类型水果和蔬菜之间的相似度评分 — 作者提供的图片
- en: The embedding models learn by observing how words are used in context, similar
    to how humans learn a language. When you’re growing up, you learn the meaning
    of words by listening to conversations and reading books.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入模型通过观察词汇在上下文中的使用方式来学习，这类似于人类学习语言的方式。你在成长过程中，通过听对话和阅读书籍来学习词汇的含义。
- en: The train process of our model is not so different. After the train processes,
    it learned that “pears and apples” are more likely to be seen together in a sentence
    than “apples and onions,” so it assumes they have something in common. So when
    it comes to food, it’s likely that what matters most is whether different types
    of food are eaten together.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们模型的训练过程并没有太大不同。经过训练后，它学会了“pears and apples”更可能在一个句子中出现，而不是“apples and onions”，因此它认为它们有某些共同点。因此，在涉及食物时，最重要的可能是不同类型的食物是否一起食用。
- en: Objects, words and sentences have lots of features that don’t fit into two dimensions.
    To tackle this, modern embedding models turn words and sentences into vectors
    with hundreds or thousands of dimensions.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对象、词汇和句子具有许多不适合二维空间的特征。为了解决这个问题，现代嵌入模型将词汇和句子转化为具有数百或数千维的向量。
- en: By transforming our content into a vector, we can measure the distance between
    them. This is easy in the two-dimensional example below, but it can become more
    complex and require more computing power when the vector has hundreds or thousands
    of dimensions.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将我们的内容转化为向量，我们可以测量它们之间的距离。下面的二维示例很简单，但当向量具有数百或数千维时，它可能变得更复杂，需要更多的计算能力。
- en: '**This is where vector databases come into play**.'
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**这就是向量数据库发挥作用的地方**。'
- en: They are incorporating several techniques that allow us to efficiently store
    and search our collection of text content. What we want to do once we have a collection
    of vectors, we want to compare them to each other and somehow quantify the similarities
    between them. Usually we are interested in the k-nearest neighbors, so the data
    points in our vector space that are closest to our query vector. In the example
    below our query would be the word “apple”. But of course not the word “apple”
    itself, we are using the vector we get back from the Embedding Model.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 他们结合了几种技术，允许我们高效地存储和搜索我们的文本内容集合。一旦我们拥有了向量集合，我们希望将它们相互比较，并以某种方式量化它们之间的相似性。通常我们对k-最近邻感兴趣，所以我们在向量空间中最接近查询向量的数据点。在下面的示例中，我们的查询将是“apple”这个词。但当然不是“apple”这个词本身，我们使用的是从嵌入模型中得到的向量。
- en: '![](../Images/3a030f8b477b45dfe44284dfe3c295dd.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3a030f8b477b45dfe44284dfe3c295dd.png)'
- en: Similarity score between different types of fruit and vegetables — Image by
    the author
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 不同种类的水果和蔬菜之间的相似度分数 — 图片由作者提供
- en: '**How does that help our LLM app?**'
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**这对我们的LLM应用有什么帮助？**'
- en: 'We use this approach in many of our LLM applications when the LLM themselves
    reach the limits of their knowledge:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当LLM自身达到知识的极限时，我们在许多LLM应用中使用这种方法：
- en: 'Things LLMs don’t know out of the box:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: LLM自带的不具备的知识：
- en: '**Data that is too new** — Articles about current events, recent innovations,
    etc. Just any new content created after the collection of the LLM train set.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据过于新颖** — 关于时事、最近的创新等的文章。即在LLM训练集收集之后创建的任何新内容。'
- en: '**Data that is not public** — personal data, internal company data, secret
    data, etc.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据不公开** — 个人数据、公司内部数据、机密数据等。'
- en: '![](../Images/e28b61dc89a785cace36a586ec66f86c.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e28b61dc89a785cace36a586ec66f86c.png)'
- en: What the LLM know and what not — Image by the author
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: LLM知道什么和不知道什么 — 图片由作者提供
- en: '**Why can’t we just give the model all the data we have?**'
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**我们为什么不能直接给模型所有的数据？**'
- en: '*Short answer:* The models have a limit, a token limit.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*简短回答：* 模型有一个限制，即令牌限制。'
- en: If we don’t want to train or fine-tune the model, we have no choice but to give
    the model all the necessary information within the prompt. We have to respect
    the token limits of the models.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不想训练或微调模型，我们必须在提示中提供所有必要的信息。我们必须尊重模型的令牌限制。
- en: '![](../Images/683223fdb31dfc8043892bf863848a64.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/683223fdb31dfc8043892bf863848a64.png)'
- en: LLMs and their Token Limit — Image by the author
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs及其令牌限制 — 图片由作者提供
- en: LLMs have a token limit **for practical and technical reasons.** The latest
    models from OpenAI have a token limit of about 4,000–32,000 tokens, while the
    open source LLM LLama has 2,048 tokens (if not fine-tuned). You can increase the
    maximum number of tokens by fine-tuning, but more data is not always better. 32,000
    token limits allow us to pack even large texts into a prompt at once. Whether
    this makes sense is another matter. (Lample, 2023; OpenAI, 2023)
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 的令牌限制**出于实际和技术原因**。OpenAI 最新的模型令牌限制大约为 4,000–32,000 个令牌，而开源 LLM LLama 的令牌限制为
    2,048 个令牌（如果未经过微调）。您可以通过微调来增加最大令牌数，但更多的数据不一定更好。32,000 个令牌的限制允许我们一次性将大量文本打包到提示中。这是否合理是另一回事。（Lample,
    2023; OpenAI, 2023）
- en: The quality of data is more important than the sheer amount of data, irrelevant
    data can have a negative impact on the result.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的质量比数据的数量更为重要，无关的数据可能对结果产生负面影响。
- en: Even reorganizing the information within the prompt can make a big difference
    in how accurately LLMs understand the task. Researcher from the Stanford University
    has found that when important information is placed at the beginning or end of
    the prompt, the answer is usually more accurate. If the same information is located
    in the middle of the prompt, accuracy can decrease significantly. It’s important
    to give careful consideration to what data we are providing our model with and
    how we structure our prompt. (Liu et al., 2023; Raschka, 2023)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 甚至在提示中重新组织信息也可以显著影响 LLM 理解任务的准确性。斯坦福大学的研究人员发现，当重要信息位于提示的开头或结尾时，答案通常更准确。如果相同的信息位于提示的中间，准确性可能会显著下降。我们必须仔细考虑提供给模型的数据以及如何构建提示。（Liu
    et al., 2023; Raschka, 2023）
- en: '![](../Images/8af5b0f7c2d77965d0e357ee0677255f.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8af5b0f7c2d77965d0e357ee0677255f.png)'
- en: How LLMs understand the prompts — Image by the author
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 如何理解提示 — 图像由作者提供
- en: '*The quality of the input data is key to the success of our LLM application,
    so it is essential we implement a process that accurately identifies the relevant
    content and avoids adding too much unnecessary data. To ensure this, we must use
    effective search processes to highlight the most relevant information.*'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '*输入数据的质量对我们 LLM 应用的成功至关重要，因此实施一个准确识别相关内容并避免添加过多不必要数据的过程是必要的。为确保这一点，我们必须使用有效的搜索过程来突出最相关的信息。*'
- en: How exactly do Vector databases help us do that?
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向量数据库如何帮助我们实现这一点？
- en: Vector databases are made up of several parts that help us quickly find what
    we’re looking for. Indexing is the most important part and is done just once,
    when we insert new data into our dataset. After that, searches are much faster,
    saving us time and effort.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 向量数据库由多个部分组成，这些部分帮助我们快速找到所需的信息。索引是最重要的部分，只需在将新数据插入数据集时进行一次。之后，搜索会快得多，节省了时间和精力。
- en: '![](../Images/83876339f9835c4737e8289383660643.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/83876339f9835c4737e8289383660643.png)'
- en: Vector Databases and their components — Image by the author
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 向量数据库及其组成部分 — 图像由作者提供
- en: To feed the data into our vector database, we first have to convert all our
    content into vectors. As described in the first section of this article, we can
    use so-called embedding models for that. Simply because its more convenient, we
    often use one of the ready-to-use services from OpenAI, Google and Co..
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 要将数据输入到我们的向量数据库中，我们首先需要将所有内容转换为向量。正如本文第一部分所述，我们可以使用所谓的嵌入模型。由于更方便，我们通常使用 OpenAI、Google
    等公司的现成服务。
- en: In the image below you can see some Embedding Models you can choose from.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，您可以看到一些可供选择的嵌入模型。
- en: '![](../Images/9a5ca01d8fbee016f5bd0a16a9645b8f.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9a5ca01d8fbee016f5bd0a16a9645b8f.png)'
- en: A collection of available Embedding Models — Image by the author
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的嵌入模型集合 — 图像由作者提供
- en: Hands-On Tutorial — Text to Vectors
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实践教程 — 文本到向量
- en: To use our example, we’ll need the Hugging Face API and the sentence transformer
    model “all-MiniLM-L6-v2”. To get started, just go to [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
    and get your token.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 以我们的示例为例，我们需要使用 Hugging Face API 和句子转换器模型“all-MiniLM-L6-v2”。要开始使用，只需访问 [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
    并获取您的令牌。
- en: 'Using the code snippet below, we:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 使用下面的代码片段，我们：
- en: Transform the text snippets into vectors with 384 dimensions (Depends on the
    Embedding Model you use). This allows us to capture the meaning of sentences in
    a vector.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将文本片段转换为 384 维的向量（取决于您使用的嵌入模型）。这使我们能够在向量中捕捉句子的含义。
- en: We can then identify similarities between data points by calculating the distance
    between the sentences.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们可以通过计算句子之间的距离来识别数据点之间的相似性。
- en: To visualise this in a simple 2-dimensional plot, we reduce the 384 dimensions
    to two using Principal Component Analysis. This may result in a huge loss of information,
    but it’s worth a try!
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了在一个简单的二维图中可视化，我们使用主成分分析将384维缩减为两个维度。这可能会导致大量信息丢失，但值得一试！
- en: 'For the example below I am generating 10 random sample sentences:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我生成了10个随机样本句子：
- en: '[PRE0]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you’d like to try the tutorial for yourself, I’ve broken down the steps into
    data pipelines that you can run independently.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想自己尝试这个教程，我已将步骤拆分为可以独立运行的数据管道。
- en: 'Create a new virtual environment **.venv** using:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**.venv**创建一个新的虚拟环境：
- en: 'Install all modules in “requirements.txt”:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 安装“requirements.txt”中的所有模块：
- en: '**pip install -r requirements.txt**'
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**pip install -r requirements.txt**'
- en: '[PRE1]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If you want to follow along you can simply set up a similar folder structure
    with a folder for the data pipelines and the data (or change the path to the .csv
    files within the pipelines).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想跟随教程，你可以简单地设置一个类似的文件夹结构，包括一个数据管道文件夹和数据文件夹（或者在管道中更改.csv文件的路径）。
- en: '![](../Images/eb72305ac508bb8ed71429ed0a9d2cac.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eb72305ac508bb8ed71429ed0a9d2cac.png)'
- en: Data pipelines overview — Screenshot by the author
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 数据管道概述 — 作者提供的截图
- en: 1\. Text to Embeddings
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 文本到嵌入
- en: The first pipeline, “01_text_to_embeddings.py” uses an Embedding Model to transform
    the 10 sample sentences. The results are saved in a data frame called “embeddings_df”
    and then exported to a CSV file named “embeddings_df.csv”. Make sure you replace
    the HuggingFace Token with you own token.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个管道“01_text_to_embeddings.py”使用嵌入模型转换10个样本句子。结果保存在一个名为“embeddings_df”的数据框中，然后导出到名为“embeddings_df.csv”的CSV文件中。确保用你自己的token替换HuggingFace
    Token。
- en: '![](../Images/e3c12bf12f16f3d6cc9daac95ecb6465.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e3c12bf12f16f3d6cc9daac95ecb6465.png)'
- en: From text chunks to embeddings — Image by the author
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 从文本块到嵌入 — 作者提供的图像
- en: '[PRE2]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You should now find the csv-file “embeddings_df.csv” in the folder “02_Data”.
    It should look something like this:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你应该能在“02_Data”文件夹中找到名为“embeddings_df.csv”的csv文件。它应该类似于以下内容：
- en: '![](../Images/8c30ef15e4ea921312f2c787f9495c2d.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8c30ef15e4ea921312f2c787f9495c2d.png)'
- en: 2\. Plot 384 dimensions vector in 2 dimensions using Principal Component Analysis
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 使用主成分分析将384维向量绘制为2维
- en: Now that you have the csv-file “embeddings_df.csv” in the folder “02_Data”,
    which contains the vectors, let’s try to visualize it. We can use Principal Component
    Analysis to extract the 2 most important “Principal Components” and visualize
    it. We can not capture all of the original information in just two dimensions,
    but maybe it gives us a feeling what is happening when we translate our text into
    vectors.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经在“02_Data”文件夹中拥有了包含向量的csv文件“embeddings_df.csv”，让我们尝试可视化它。我们可以使用主成分分析提取两个最重要的“主成分”并进行可视化。我们不能在二维中捕捉所有的原始信息，但也许它能给我们一个在将文本转换为向量时发生了什么的感觉。
- en: '![](../Images/fe66a351780f01f0b914e6a24cbc3378.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fe66a351780f01f0b914e6a24cbc3378.png)'
- en: Apply principal component analysis to embedding vectors — Image by the author
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 将主成分分析应用于嵌入向量 — 作者提供的图像
- en: 'Create a new file for the second pipeline, I call it: **“02_create_PCA_analysis.py”**'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 为第二个管道创建一个新文件，我称之为：**“02_create_PCA_analysis.py”**
- en: 'The second pipeline contains:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个管道包含：
- en: Loading the embeddings from “embeddings_df.csv”
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从“embeddings_df.csv”加载嵌入
- en: Perform a Principal Component Analysis using scikit-learn to create and find
    the two most important (principal) components
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用scikit-learn执行主成分分析以创建和查找两个最重要的（主）成分
- en: Create a scatter plot to visualize the result in a 2-dimensional plot
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个散点图在二维图中可视化结果
- en: '[PRE3]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/48ebc95c64741e8b1706c581180539f4.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/48ebc95c64741e8b1706c581180539f4.png)'
- en: Screenshot repo
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 截图仓库
- en: I’m not sure how good the example is, but you can at least see that sentences
    about food and drink tend to be on the right side of the plot, the two sentences
    describing the weather are close together on the left side, and the two sentences
    about flowers are close together at the bottom of the plot. I’ll just take this
    as a “not so scientific” evidence that the model is at least somewhat successful
    in mapping the semantics behind the words/phrases.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我不确定这个示例有多好，但你至少可以看到，关于食物和饮料的句子倾向于位于图的右侧，描述天气的两个句子在左侧靠近，而关于花卉的两个句子在图的底部靠近。我把这作为一种“非科学性”的证据，证明该模型在一定程度上成功地映射了词语/短语背后的语义。
- en: '![](../Images/a6386f07c0d55133a84e2654ad28b04f.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a6386f07c0d55133a84e2654ad28b04f.png)'
- en: Sentences to Vectors (first two Principal Components)— Image by the author
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 句子到向量（前两个主成分） — 作者提供的图像
- en: As humans, it is relatively easy to tell which points are closer together when
    plotted in a simple two-dimensional space. But how can we quantify that in a vector
    space with hundreds and thousands of dimensions? — We need a metric for that.
    A metric that describes the similarity. Therefor we calculate the distance between
    the points in the space.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 作为人类，当数据点绘制在简单的二维空间中时，判断哪些点更接近是相对容易的。但是我们如何在有数百或数千维的向量空间中量化这一点？——我们需要一个度量，一个描述相似度的度量。因此，我们计算空间中点之间的距离。
- en: 3\. Calculate the distance
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 计算距离
- en: '**How is the distance defined?**'
  id: totrans-120
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**距离是如何定义的？**'
- en: In Statistics we have several metrics to measure the distance between data points.
    One often used metric is the “Cosine Similarity”. We’ll be using this one for
    our examples below.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学中，我们有几种度量数据点之间距离的指标。一个常用的指标是“余弦相似度”。我们将在下面的示例中使用这个指标。
- en: '![](../Images/000daf8a5828dfd5c92b555341460cad.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/000daf8a5828dfd5c92b555341460cad.png)'
- en: Different Distance Metrics — Image by the author
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的距离度量 — 作者提供的图像
- en: What we want to do with Vector Databases is to find similar entries as fast
    as possible. But what makes Vector Databases so special, why can’t we just perform
    the similarity search by calculating the distance metric to every data point?
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在向量数据库中要做的是尽可能快地找到相似条目。但是什么使得向量数据库如此特别，为什么我们不能仅仅通过计算与每个数据点的距离指标来进行相似度搜索呢？
- en: To make it easier to understand why we need an alternate approach, I have created
    a straightforward process that finds the closest data points. It does this by
    calculating the distance to each data point and then sorting them to find the
    nearest neighbors.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更容易理解为什么我们需要另一种方法，我创建了一个简单的过程来找到最接近的数据点。它通过计算与每个数据点的距离，然后对其进行排序以找到最近的邻居。
- en: For the example below, We use the 10 pieces of text that we have already converted
    into a vector format earlier in this post.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 对于下面的示例，我们使用了之前在这篇文章中已经转换为向量格式的10段文本。
- en: 'So a common query of our database might look like this:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们数据库的一个常见查询可能如下所示：
- en: 'Let’s say we have a new sentence (user query), here: **“Lilies are white.”**'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个新的句子（用户查询），这里是：**“百合是白色的。”**
- en: First, we are obtaining the embeddings for our new sentences. This vector gives
    us a location in our embedding space that allows us to compare them with the other
    text chunks in our collection.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们获取新句子的嵌入向量。这个向量给了我们在嵌入空间中的位置，使我们可以将它们与我们集合中的其他文本块进行比较。
- en: '![](../Images/04b9ba65ccf48fe3ff93baad86072190.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/04b9ba65ccf48fe3ff93baad86072190.png)'
- en: Distance as Similarity Score — Image by the author
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 距离作为相似度分数 — 作者提供的图像
- en: 'Then we are calculating the distance (here: cosine similarity) to each data
    point'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后我们计算与每个数据点的距离（这里指：余弦相似度）。
- en: '![](../Images/aa075272901a313fd0df878f1b01e370.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aa075272901a313fd0df878f1b01e370.png)'
- en: Calculate the cosine similarity to our query vector — Image by the author
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 计算与查询向量的余弦相似度 — 作者提供的图像
- en: Usually, we are interested in the k-nearest neighbors. We simply filter the
    ones with the smallest distance to our new query vector
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常，我们对最近的k个邻居感兴趣。我们只是过滤出与我们的新查询向量距离最小的那些。
- en: For the simple example, we use the sentence “Lilies are white.” and try to describe
    the similarity to the other sentences in the dataset by calculating their distance
    from each other.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个简单的示例，我们使用句子“百合是白色的。”并尝试通过计算它们之间的距离来描述与数据集中其他句子的相似度。
- en: 'To do that, we create a third pipeline, I call it: **“03_calculate_cosine_similarity.py”**'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们创建了第三个管道，我称之为：**“03_calculate_cosine_similarity.py”**
- en: '[PRE4]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/04ea5742b942231b949cec8e7aca8be1.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/04ea5742b942231b949cec8e7aca8be1.png)'
- en: Calculated similarities — Screenshots by the author
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 计算出的相似度 — 作者提供的截图
- en: If we look at the similarity scores, the sentences “Violets are blue.” and “Roses
    are red.” are significantly more similar to our query sentence “Lilies are white.”
    than “Programming is fun.”.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看相似度分数，“‘紫罗兰是蓝色的。’”和“‘玫瑰是红色的。’”与我们的查询句子“‘百合是白色的。’”相比，显著地更相似，而“‘编程很有趣。’”则不然。
- en: Makes sense, I guess.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 有道理，我想。
- en: '**The similarity search seems to work. So why do we need another approach at
    all?**'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**相似度搜索似乎有效。那么我们为什么还需要另一种方法呢？**'
- en: Using the *time.time()* function I am stopping the time it takes to calculate
    the cosine similarity between our query vector and the 10 other vectors.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 使用*time.time()*函数，我记录了计算我们查询向量与其他10个向量之间的余弦相似度所需的时间。
- en: According to that, it takes around 0.005 seconds to search our 10 entries.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这个方法，搜索我们这10条数据大约需要0.005秒。
- en: '![](../Images/dcb784ec13bf2e1ed5b3880440e02b98.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dcb784ec13bf2e1ed5b3880440e02b98.png)'
- en: Comparing each point to every other point is called “exhaustive search” and
    it takes a linear amount of time. For example, if it takes 0.005 seconds to compare
    10 points, it would take several minutes to compare 1 million chunks of text.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 将每一个点与其他每一个点进行比较被称为“穷举搜索”，这种方法需要线性时间。例如，如果比较10个点需要0.005秒，那么比较100万条文本数据可能需要几分钟。
- en: '![](../Images/e9eb5031cd78eb29f21eef4e206be270.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e9eb5031cd78eb29f21eef4e206be270.png)'
- en: Computing time for exhaustive search — Image by the author
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 穷举搜索的计算时间 — 作者提供的图片
- en: We need to find an efficient way to speed up the similarity search process.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要找到一种高效的方法来加快相似性搜索过程。
- en: How to accelerate the similarity search?
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何加速相似性搜索？
- en: Approximate Nearest Neighbor algorithms are used to find the closest neighbors,
    even though they may not always be the exact closest. This trade-off of accuracy
    for speed is usually acceptable for LLM applications, since speed is more important
    and often the same information is found in multiple text snippets anyway. [(Trabelsi,
    2021)](https://www.zotero.org/google-docs/?GbBH8V=)
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 近似最近邻算法用于寻找最接近的邻居，即使它们可能不是最准确的。这种将准确性与速度进行权衡的做法通常对于LLM应用是可以接受的，因为速度更重要，而且通常相同的信息会出现在多个文本片段中。
    [(Trabelsi, 2021)](https://www.zotero.org/google-docs/?GbBH8V=)
- en: I guess it is not essential for the average user to have a deep understanding
    of indexing techniques. But I don’t want to leave you completely without. To give
    you at least a basic understanding of the techniques, here’s an example of how
    to use an Inverted File Index. This way, you can get a sense of where accuracy
    can be lost using these techniques.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为对于普通用户来说，对索引技术有深入了解并不是必要的。但我不想让你完全不了解。为了让你至少对这些技术有一个基本的了解，这里有一个如何使用倒排文件索引的例子。这样，你可以了解使用这些技术时可能会丢失的准确性。
- en: Inverted File Index (IFV) is a popular method for finding similarities between
    different items. It works by creating a database index that stores content and
    connects it to its position in a table or document. We divide the whole collection
    of items into partitions and their centroids. Each item can only be part of one
    partition at a time. When we search for similarities, we use the partition centroids
    to quickly find the items we are looking for.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 倒排文件索引（IFV）是一种流行的找到不同项目之间相似性的方法。它通过创建一个数据库索引来存储内容，并将其连接到表格或文档中的位置。我们将整个项目集合分成多个分区及其质心。每个项目一次只能属于一个分区。当我们进行相似性搜索时，使用分区质心来快速找到我们所寻找的项目。
- en: '![](../Images/b930b59e8b97858b4b1473081c541476.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b930b59e8b97858b4b1473081c541476.png)'
- en: Approximate Nearest Neighbor search using Inverted File Index (IFV) — Image
    by the author
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 使用倒排文件索引（IFV）进行近似最近邻搜索 — 作者提供的图片
- en: If we’re looking for nearby points, we usually just search in the centroid closest
    to our point. But if there are points close to the edge of the neighboring centroid,
    we may miss them.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在寻找附近的点，通常只会在离我们点最近的质心中进行搜索。但如果有些点靠近邻近质心的边缘，我们可能会错过它们。
- en: '![](../Images/aafc4af2c097ca0a693d726a9964182d.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aafc4af2c097ca0a693d726a9964182d.png)'
- en: Where we loose information using ANN algorithms — Image by the author
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 使用ANN算法时我们丢失的信息 — 作者提供的图片
- en: To avoid this issue, we search multiple partitions instead of just one. However,
    the underlying problem still remains. We lose some accuracy. But that is usually
    ok, speed is more important.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这个问题，我们搜索多个分区，而不是仅仅一个。然而，根本问题仍然存在。我们会失去一些准确性。但通常这是可以接受的，速度更为重要。
- en: Chroma supports multiple approximate nearest neighbor (ANN) algorithms, including
    HNSW, IVFADC, and IVFPQ. [(Yadav, 2023)](https://www.zotero.org/google-docs/?k2HoPI=)
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: Chroma支持多种近似最近邻（ANN）算法，包括HNSW、IVFADC和IVFPQ。 [(Yadav, 2023)](https://www.zotero.org/google-docs/?k2HoPI=)
- en: '**Hierarchical Navigable Small World (HNSW):** HNSW is an algorithm that creates
    a hierarchical graph structure to quickly store and search high-dimensional vectors
    with minimal memory usage.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**层次导航小世界（HNSW）：** HNSW是一种创建层次图结构的算法，用于快速存储和搜索高维向量，同时内存使用最小化。'
- en: '**Inverted File with Product Quantization (IVFPQ):** IVFPQ uses product quantization
    to compress vectors before indexing, resulting in a high-accuracy search that
    can handle massive datasets.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**倒排文件与产品量化（IVFPQ）：** IVFPQ 使用产品量化在索引之前压缩向量，从而实现高准确度的搜索，能够处理大规模数据集。'
- en: '![](../Images/fcdc598e0b9a7c065003d52f5eb0d68a.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fcdc598e0b9a7c065003d52f5eb0d68a.png)'
- en: Among the most used Approximate Nearest Neighbor algorithms — Image by the author
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的近似最近邻算法之一 — 作者提供的图片
- en: If you want to know in detail how the different indexing methods work, I can
    recommend [James Briggs](https://www.youtube.com/watch?v=QvKMwLjdK-s) Youtube
    channel. I also liked the blog posts from [Peggy Chang](https://peggy1502.medium.com/)
    to inverted file index (IVF), product quantization (PQ) and co.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想详细了解不同的索引方法是如何工作的，我可以推荐 [James Briggs](https://www.youtube.com/watch?v=QvKMwLjdK-s)
    的 YouTube 频道。我也喜欢 [Peggy Chang](https://peggy1502.medium.com/) 的关于倒排文件索引（IVF）、产品量化（PQ）等的博客文章。
- en: '**What is really relevant for us?**'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**什么对我们真正重要？**'
- en: I think all we need to know is that through the indexing step, we store our
    embeddings in a form that allows us to quickly find “similar” vectors without
    having to calculate the distance to all the data points each time. By doing that,
    we trade speed for some accuracy.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为我们需要知道的是，通过索引步骤，我们将嵌入以一种允许我们快速找到“相似”向量的形式存储，而不需要每次都计算与所有数据点的距离。通过这样做，我们在速度和准确性之间做了权衡。
- en: '![](../Images/e845a2803e0e5780345bdcb268bfb8c3.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e845a2803e0e5780345bdcb268bfb8c3.png)'
- en: How to store text in vector stores — Image by the author
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 如何在向量存储中存储文本 — 作者提供的图片
- en: The accuracy of the task should still be good enough for most of what we try
    to do with it. Translating language into embeddings is not an exact science anyway.
    The same word can have different meanings depending on the context or region of
    the world in which you use it. Therefore, it is usually okay if we lose a few
    accuracy points, but what is much more important is the speed of the response.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 任务的准确性对于我们尝试做的大多数事情来说仍然足够好。毕竟，将语言转换为嵌入并不是一门精确的科学。相同的词语在不同的上下文或世界不同地区中可能具有不同的含义。因此，如果我们丢失了一些准确性点通常是可以接受的，但更重要的是响应的速度。
- en: Google’s fast response time is what makes it so successful. The speed of each
    step of the process is even more important for our application, because we not
    only have to perform the vector search, but also pass the questions and context
    to our LLM.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: Google 快速的响应时间是其成功的关键。每个过程步骤的速度对于我们的应用尤其重要，因为我们不仅需要执行向量搜索，还需要将问题和上下文传递给我们的 LLM。
- en: However, this process takes a bit longer than Google, which is (I guess) why
    Bing Chat (with its LLM support) has not yet conquered the world. It is only a
    few milliseconds or seconds slower, but this small difference is enough to keep
    Google on top.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，这个过程比 Google 稍微长一些，这也是（我猜）为什么 Bing Chat（及其 LLM 支持）尚未征服世界的原因。它只比 Google 慢几毫秒或几秒，但这一小点差距足以让
    Google 继续领先。
- en: '**To illustrate these steps — Let’s say we want to create a chatbot like Bing
    Chat**'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '**为了说明这些步骤 — 假设我们想要创建一个像 Bing Chat 这样的聊天机器人**'
- en: We still have the (traditional) search part that looks for content and news
    that is most relevant. Only when we have found some common results, we provide
    them to our LLM and let it interpret the data and formulate a well-sounding answer.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍然有（传统的）搜索部分，它寻找最相关的内容和新闻。只有当我们找到一些常见结果时，我们才将它们提供给我们的 LLM，让它解释数据并形成一个合理的回答。
- en: '![](../Images/d51ab7bc1abe2ed422ba72a5c0f5a366.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d51ab7bc1abe2ed422ba72a5c0f5a366.png)'
- en: Process flow of a chatbot using LLM models — Image by the author
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 LLM 模型的聊天机器人流程图 — 作者提供的图片
- en: Our vector store takes care of tokenizing, embedding and indexing the data when
    it’s loaded. Once the data is in the store, we can query it with new data points.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的向量存储负责在加载数据时进行分词、嵌入和索引。一旦数据进入存储，我们可以用新的数据点进行查询。
- en: '**Suppose we decide to use a vector store — What options do we have?**'
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**假设我们决定使用向量存储 — 我们有哪些选项？**'
- en: 'Vector databases come in different shapes. We distinguish between:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 向量数据库有不同的形态。我们区分：
- en: Pure vector databases
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 纯向量数据库
- en: Extended capabilities in SQL, NoSQL or text search databases
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SQL、NoSQL 或文本搜索数据库中的扩展功能
- en: Simple vector libraries
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单向量库
- en: '![](../Images/6ae2735fd136028a186b8057624f3788.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6ae2735fd136028a186b8057624f3788.png)'
- en: Different types of Vector Stores — Image by the author
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 不同类型的向量存储 — 作者提供的图片
- en: '**Text search databases** can search through large amounts of text for specific
    words or phrases. Recently, some of these databases have begun to use vector search
    to further improve their ability to find what you’re looking for. At the last
    [Microsoft Developer Conference](https://www.youtube.com/watch?v=5Qaxz2e2dVg&t=584s),
    Elasticsearch explained how they use both traditional search and vector search
    to create a ‘Hybrid Scoring’ system, giving you the best possible search results.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '**文本搜索数据库**可以在大量文本中搜索特定的单词或短语。最近，这些数据库中的一些开始使用向量搜索，以进一步提升找到所需内容的能力。在上届[微软开发者大会](https://www.youtube.com/watch?v=5Qaxz2e2dVg&t=584s)上，Elasticsearch
    解释了他们如何结合传统搜索和向量搜索来创建一个“混合评分”系统，从而提供最佳的搜索结果。'
- en: '![](../Images/05ef43a226a39b222be3eaf4bf73924d.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05ef43a226a39b222be3eaf4bf73924d.png)'
- en: 'Elasticsearch: Combining Traditional with Vector Search improves the search
    results — Image by the author'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: Elasticsearch：结合传统搜索和向量搜索改善搜索结果 — 作者提供的图片
- en: 'Vector Search is also gradually being adopted by more and more **SQL and NoSQL
    databases such as Redis, MongoDB or Postgres**. Pgvector, for example, is the
    open source vector similarity search for Postgres. It supports (Github, 2023):'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '向量搜索也逐渐被越来越多的**SQL 和 NoSQL 数据库，如 Redis、MongoDB 或 Postgres** 采用。例如，Pgvector
    是用于 Postgres 的开源向量相似性搜索工具。它支持 (Github, 2023):'
- en: exact and approximate nearest neighbor search
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确和近似最近邻搜索
- en: L2 distance, inner product, and cosine distance
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: L2 距离、内积和余弦距离
- en: For smaller projects, **vector libraries** are a great option and provide most
    of the features needed.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 对于较小的项目，**向量库**是一个很好的选择，提供了大部分所需的功能。
- en: '**Facebook AI Research released one of the first vector libraries, FAISS**,
    in 2017\. FAISS is a library for efficiently searching and clustering dense vectors,
    and can handle vector sets of any size, even those that don’t fit in memory. It’s
    written in C++ and comes with a Python wrapper, making it easy for data scientists
    to integrate into their code. (FAISS Documentation, 2023)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '**Facebook AI Research 在 2017 年发布了第一个向量库之一，FAISS**。FAISS 是一个高效搜索和聚类密集向量的库，能够处理任何大小的向量集，即使那些无法完全载入内存的向量集也不在话下。它用
    C++ 编写，并配有 Python 封装，使数据科学家能够轻松集成到他们的代码中。（FAISS 文档, 2023）'
- en: '![](../Images/46935d6ec3d53d2003724caebb30cf99.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/46935d6ec3d53d2003724caebb30cf99.png)'
- en: The evolution of Vector Stores — Image by the author
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 向量存储的演变 — 作者提供的图片
- en: '**Chroma, Pinecone, Weaviate on the other side, are pure Vector Databases**
    that can store your vector data and be searched like any other database. In this
    article, I’ll teach you how to set up a Vector Database with Chroma and how to
    fill it with your vector data. If you’re looking for a quick solution, vector
    libraries like FAISS can help you get started easily with all the necessary indexing
    methods.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '**另一方面，Chroma、Pinecone、Weaviate 是纯粹的向量数据库**，可以存储您的向量数据，并像其他数据库一样进行搜索。在本文中，我将教您如何使用
    Chroma 设置一个向量数据库，并如何将您的向量数据填充其中。如果您在寻找快速解决方案，像 FAISS 这样的向量库可以帮助您轻松开始，提供所有必要的索引方法。'
- en: '**So which one should we take?**'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '**那么我们应该选择哪个？**'
- en: 'I guess you’ll have to answer that one for yourselves and your specific project,
    but don’t make things unnecessarily complex. Andre Karpathy described it on Twitter
    with the words: (Andrej Karpathy, 2023):'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我想你们需要为自己的具体项目回答这个问题，但不要让事情变得过于复杂。Andre Karpathy 在 Twitter 上这样描述了它：（Andrej Karpathy,
    2023）：
- en: “Np.array — people keep reaching for much fancier things way too fast these
    days” — [Andrew Karpathy](https://twitter.com/karpathy/status/1647374645316968449?lang=de)
  id: totrans-199
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “Np.array — 现在人们对复杂的东西期望过高” — [Andrew Karpathy](https://twitter.com/karpathy/status/1647374645316968449?lang=de)
- en: If you only need to search a few pages of a PDF or text file, you can simply
    use an np.array or pandas data frames to store your embeddings. The capabilities
    of Vector Databases become interesting when we speak about hundreds, thousands
    or millions of vectors, we want to search on a regular basis. For this article,
    I am using Chroma, but the same principles apply to all databases.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您只需要搜索几页 PDF 或文本文件，您可以简单地使用 np.array 或 pandas 数据框来存储您的嵌入。向量数据库的能力在处理数百、数千或数百万个向量时变得有趣，这些向量我们希望定期搜索。本文中，我使用的是
    Chroma，但相同的原理适用于所有数据库。
- en: Hands-On Tutorial — Set up your first Vector Store
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实操教程 — 设置您的第一个向量存储
- en: To store our content into vectors and improve the performance of our similarity
    search, we need to set up our own Vector Database. Chroma is a great open-source
    option to use, as it is free to use and has an Apache 2.0 license. Other alternatives,
    such as FAISS, Weaviate, and Pinecone, also exist. Some of these options are open-source
    and free to use, while others are only available as a commercial service.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将我们的内容存储为向量并提高相似性搜索的性能，我们需要建立自己的向量数据库。Chroma 是一个很好的开源选择，因为它可以免费使用并且具有 Apache
    2.0 许可证。其他选择，如 FAISS、Weaviate 和 Pinecone，也存在。这些选项中有些是开源并且可以免费使用的，而有些则仅作为商业服务提供。
- en: With just a few steps, we can get chromadb up and running. All we need to do
    is use our package manager **pip** to download the **chromadb** library. Once
    we have that, we can start setting up our first vector store database and get
    going.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 只需几个步骤，我们就能让 chromadb 运行起来。我们需要做的就是使用我们的包管理器**pip**下载**chromadb**库。一旦我们有了它，我们就可以开始设置我们的第一个向量存储数据库并开始使用。
- en: 1\. Install chroma
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 安装 chroma
- en: '[https://pypi.org/project/chromadb/](https://pypi.org/project/chromadb/)'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://pypi.org/project/chromadb/](https://pypi.org/project/chromadb/)'
- en: '[PRE5]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 2\. Get/create a chroma client and collection
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 获取/创建一个 chroma 客户端和集合
- en: A collection is the designated storage for your embeddings, documents, and any
    additional metadata. If you want to save it, so you can later use your indexes
    and collections, you can use “persist_directory”
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 集合是你嵌入、文档和任何附加元数据的指定存储。如果你想保存它，以便以后使用你的索引和集合，你可以使用“persist_directory”
- en: '![](../Images/46eee8311e6a2663a0283739dbc3bb30.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/46eee8311e6a2663a0283739dbc3bb30.png)'
- en: From text chunks to embeddings — Image by the author
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 从文本块到嵌入 — 作者插图
- en: '[PRE6]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 3\. Add some text documents to the collection
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 向集合中添加一些文本文档
- en: Chroma makes it easy to store and organize your text documents. It takes care
    of the tokenization, embedding, and indexing processes for you, and if you have
    already created your own embeddings, you can load them directly into Chroma’s
    vector store.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: Chroma 使得存储和组织你的文本文档变得容易。它为你处理标记化、嵌入和索引过程，如果你已经创建了自己的嵌入，你可以将它们直接加载到 Chroma 的向量存储中。
- en: 'We want to store the already created Data Frame “embeddings_df” into our new
    data store:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想将已经创建的数据框“embeddings_df”存储到我们的新数据存储中：
- en: '[PRE7]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/c0aeece2ff6b0ba94be3cbaa8b8bf8c6.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c0aeece2ff6b0ba94be3cbaa8b8bf8c6.png)'
- en: 4\. Extract all entries from database to excel file
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 从数据库提取所有条目到 Excel 文件
- en: 'If you want to export all entries in your vector store, you can use:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想导出向量存储中的所有条目，可以使用：
- en: '[PRE8]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 5\. Query the collection
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 查询集合
- en: 'Chroma makes it easy to find the ***n*** most similar results to a query texts:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: Chroma 使得查找与查询文本最相似的***n***个结果变得容易：
- en: '[PRE9]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/0a9afd1429e87164ebe3888ab27e9f4f.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0a9afd1429e87164ebe3888ab27e9f4f.png)'
- en: For this example we will get back the two most similar entries in our vector
    store.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，我们将返回向量存储中最相似的两个条目。
- en: Below you can find a summary of
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 下面你可以找到一个总结
- en: '[PRE10]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: These k-nearest neighbors we will then use to feed our LLM. Build a simple prompt
    template around it, insert the found text chunks into it, and you can send it
    to GPT, LLama, or any other LLM of your choice. I described how this works in
    one of [my previous articles.](/all-you-need-to-know-to-build-your-first-llm-app-eb982c78ffac)
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用这些 k-最近邻来为我们的 LLM 提供数据。围绕它构建一个简单的提示模板，将找到的文本块插入其中，然后你可以将其发送到 GPT、LLama
    或你选择的任何其他 LLM。我在[我之前的一篇文章中](https://example.org/all-you-need-to-know-to-build-your-first-llm-app-eb982c78ffac)描述了这如何工作
- en: '**Summary**'
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**总结**'
- en: Vector search is becoming increasingly popular as Machine Learning models can
    now accurately convert various content into vectors. Not only are there more and
    more dedicated vector databases, but existing SQL, NoSQL, and text search databases
    are also incorporating vector search capabilities into their products. This is
    to either improve their search mechanisms or provide a product for those specifically
    looking for databases with vector search capabilities.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 向量搜索越来越受欢迎，因为机器学习模型现在可以准确地将各种内容转换为向量。不仅越来越多的专用向量数据库出现，而且现有的 SQL、NoSQL 和文本搜索数据库也将向量搜索功能整合到其产品中。这是为了改善它们的搜索机制或为那些特别寻找具备向量搜索能力的数据库的用户提供产品。
- en: The interest in Vector Stores is only growing. Thanks to advances in Transformer
    Models in recent years, we can now turn text modules into vectors with confidence.
    This unlocks a world of mathematical possibilities when working with text.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 对向量存储的兴趣只增不减。得益于近年来 Transformer 模型的进步，我们现在可以自信地将文本模块转换为向量。这在处理文本时解锁了数学上的各种可能性。
- en: '*Enjoyed the story?*'
  id: totrans-231
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*喜欢这个故事吗？*'
- en: '[*Subscribe for free*](https://dmnkplzr.medium.com/subscribe) *to get notified
    when I publish a new story.*'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*免费订阅*](https://dmnkplzr.medium.com/subscribe) *以便在我发布新故事时获得通知。*'
- en: '*Want to read more than 3 free stories a month? — Become a Medium member for
    5$/month. You can support me by using my* [*referral link*](https://dmnkplzr.medium.com/membership)
    *when you sign up. I’ll receive a commission at no extra cost to you.*'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*想每月阅读超过3篇免费故事吗？ — 成为Medium会员，费用为5美元/月。注册时使用我的* [*推荐链接*](https://dmnkplzr.medium.com/membership)
    *，你可以支持我。我将获得佣金，而你无需支付额外费用。*'
- en: '*Feel free to reach out to me on* [*LinkedIn*](https://www.linkedin.com/in/polzerdo/)
    *!*'
  id: totrans-234
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*随时通过* [*LinkedIn*](https://www.linkedin.com/in/polzerdo/) *与我联系！*'
- en: ''
  id: totrans-235
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You can find all code snippets on [Github](https://github.com/polzerdo55862/vector-store-tutorial).
    Have fun :)
  id: totrans-236
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你可以在 [Github](https://github.com/polzerdo55862/vector-store-tutorial) 找到所有代码片段。祝玩得愉快
    :)
- en: References
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: Andrej Karpathy. (2023, April 15). *@sinclanich np.array people keep reaching
    for much fancier things way too fast these days* [Tweet]. Twitter. [https://twitter.com/karpathy/status/1647374645316968449](https://twitter.com/karpathy/status/1647374645316968449)
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: Andrej Karpathy. (2023年4月15日). *@sinclanich np.array people keep reaching for
    much fancier things way too fast these days* [推文]. Twitter. [https://twitter.com/karpathy/status/1647374645316968449](https://twitter.com/karpathy/status/1647374645316968449)
- en: Chroma. (2023, April 7). *Chroma raises $18M seed round*. [https://www.trychroma.com/blog/seed](https://www.trychroma.com/blog/seed)
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: Chroma. (2023年4月7日). *Chroma融资1800万美元种子轮*。 [https://www.trychroma.com/blog/seed](https://www.trychroma.com/blog/seed)
- en: Cook, J. (2022, March 1). *SeMI Technologies secures $16 million in Series A
    Round — Business Leader News*. Business Leader. [https://www.businessleader.co.uk/semi-technologies-secures-16-million-in-series-a-round/](https://www.businessleader.co.uk/semi-technologies-secures-16-million-in-series-a-round/)
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: Cook, J. (2022年3月1日). *SeMI Technologies获得1600万美元A轮融资 — Business Leader News*。
    Business Leader. [https://www.businessleader.co.uk/semi-technologies-secures-16-million-in-series-a-round/](https://www.businessleader.co.uk/semi-technologies-secures-16-million-in-series-a-round/)
- en: Github. (2023, August 23). *Pgvector Github Repo*. [https://github.com/pgvector/pgvector](https://github.com/pgvector/pgvector)
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: Github. (2023年8月23日). *Pgvector Github Repo*。 [https://github.com/pgvector/pgvector](https://github.com/pgvector/pgvector)
- en: 'Lample, G. (2023, August 3). *Inquiry about the maximum number of tokens that
    Llama can handle · Issue #148 · facebookresearch/llama*. GitHub. [https://github.com/facebookresearch/llama/issues/148](https://github.com/facebookresearch/llama/issues/148)'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 'Lample, G. (2023年8月3日). *关于Llama能够处理的最大token数量的查询 · Issue #148 · facebookresearch/llama*。
    GitHub. [https://github.com/facebookresearch/llama/issues/148](https://github.com/facebookresearch/llama/issues/148)'
- en: 'Liu, N. F., Lin, K., Hewitt, J., Paranjape, A., Bevilacqua, M., Petroni, F.,
    & Liang, P. (2023). *Lost in the Middle: How Language Models Use Long Contexts*
    (arXiv:2307.03172). arXiv. [http://arxiv.org/abs/2307.03172](http://arxiv.org/abs/2307.03172)'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: Liu, N. F., Lin, K., Hewitt, J., Paranjape, A., Bevilacqua, M., Petroni, F.,
    & Liang, P. (2023). *迷失在中间：语言模型如何使用长上下文* (arXiv:2307.03172)。 arXiv. [http://arxiv.org/abs/2307.03172](http://arxiv.org/abs/2307.03172)
- en: Miller, R. (2022, March 29). *Pinecone announces $28M Series A for purpose-built
    database aimed at data scientists | TechCrunch*. [https://techcrunch.com/2022/03/29/pinecone-announces-28m-series-a-for-purpose-built-database-aimed-at-data-scientists/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAMIKiexS9AALbi0ePIRFgGd-Ck3yS3U6t1VCv3yX_OwLRX-zH0-EVXFnHmq1wCH3blQOZncsBjmEU6H4LunP98AK7H_CJDYnILkchAazm6IF8SuDhf5On1JfywlFOfNC1teEpTpChfnEVt-lZ72KG0Y_yiUM5wdb6-I1-aUOtyiG](https://techcrunch.com/2022/03/29/pinecone-announces-28m-series-a-for-purpose-built-database-aimed-at-data-scientists/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAMIKiexS9AALbi0ePIRFgGd-Ck3yS3U6t1VCv3yX_OwLRX-zH0-EVXFnHmq1wCH3blQOZncsBjmEU6H4LunP98AK7H_CJDYnILkchAazm6IF8SuDhf5On1JfywlFOfNC1teEpTpChfnEVt-lZ72KG0Y_yiUM5wdb6-I1-aUOtyiG)
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: Miller, R. (2022年3月29日). *Pinecone宣布为数据科学家量身定制的数据库完成2800万美元A轮融资 | TechCrunch*。
    [https://techcrunch.com/2022/03/29/pinecone-announces-28m-series-a-for-purpose-built-database-aimed-at-data-scientists/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAMIKiexS9AALbi0ePIRFgGd-Ck3yS3U6t1VCv3yX_OwLRX-zH0-EVXFnHmq1wCH3blQOZncsBjmEU6H4LunP98AK7H_CJDYnILkchAazm6IF8SuDhf5On1JfywlFOfNC1teEpTpChfnEVt-lZ72KG0Y_yiUM5wdb6-I1-aUOtyiG](https://techcrunch.com/2022/03/29/pinecone-announces-28m-series-a-for-purpose-built-database-aimed-at-data-scientists/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAMIKiexS9AALbi0ePIRFgGd-Ck3yS3U6t1VCv3yX_OwLRX-zH0-EVXFnHmq1wCH3blQOZncsBjmEU6H4LunP98AK7H_CJDYnILkchAazm6IF8SuDhf5On1JfywlFOfNC1teEpTpChfnEVt-lZ72KG0Y_yiUM5wdb6-I1-aUOtyiG)
- en: OpenAI. (2023, July 24). *OpenAI Platform*. [https://platform.openai.com](https://platform.openai.com)
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI. (2023年7月24日). *OpenAI平台*。 [https://platform.openai.com](https://platform.openai.com)
- en: Raschka, S. (2023). *LinkedIn Sebastian Raschka*. [https://www.linkedin.com/posts/sebastianraschka_llm-ai-machinelearning-activity-7083427280605089792-MS_N/?utm_source=share&utm_medium=member_desktop](https://www.linkedin.com/posts/sebastianraschka_llm-ai-machinelearning-activity-7083427280605089792-MS_N/?utm_source=share&utm_medium=member_desktop)
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: Raschka, S. (2023年). *LinkedIn Sebastian Raschka*。 [https://www.linkedin.com/posts/sebastianraschka_llm-ai-machinelearning-activity-7083427280605089792-MS_N/?utm_source=share&utm_medium=member_desktop](https://www.linkedin.com/posts/sebastianraschka_llm-ai-machinelearning-activity-7083427280605089792-MS_N/?utm_source=share&utm_medium=member_desktop)
- en: Trabelsi, E. (2021, September 8). *Comprehensive Guide To Approximate Nearest
    Neighbors Algorithms*. Medium. [https://towardsdatascience.com/comprehensive-guide-to-approximate-nearest-neighbors-algorithms-8b94f057d6b6](/comprehensive-guide-to-approximate-nearest-neighbors-algorithms-8b94f057d6b6)
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: Trabelsi, E. (2021年9月8日). *近似最近邻算法综合指南*。Medium。 [https://towardsdatascience.com/comprehensive-guide-to-approximate-nearest-neighbors-algorithms-8b94f057d6b6](https://towardsdatascience.com/comprehensive-guide-to-approximate-nearest-neighbors-algorithms-8b94f057d6b6)
- en: 'Yadav, R. (2023, May 3). *An Evaluation of Vector Database Systems: Features,
    and Use Cases*. Medium. [https://blog.devgenius.io/an-evaluation-of-vector-database-systems-features-and-use-cases-9a90b05eb51f](https://blog.devgenius.io/an-evaluation-of-vector-database-systems-features-and-use-cases-9a90b05eb51f)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: Yadav, R. (2023年5月3日). *对向量数据库系统的评估：特性与应用案例*。Medium。 [https://blog.devgenius.io/an-evaluation-of-vector-database-systems-features-and-use-cases-9a90b05eb51f](https://blog.devgenius.io/an-evaluation-of-vector-database-systems-features-and-use-cases-9a90b05eb51f)
