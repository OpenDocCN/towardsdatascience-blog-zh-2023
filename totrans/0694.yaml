- en: Deep Dive into Handling Apache Spark Data Skew
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/deep-dive-into-handling-apache-spark-data-skew-57ce0d94ee38](https://towardsdatascience.com/deep-dive-into-handling-apache-spark-data-skew-57ce0d94ee38)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The Ultimate Guide To Handle Data Skew In Distributed Compute
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://chengzhizhao.medium.com/?source=post_page-----57ce0d94ee38--------------------------------)[![Chengzhi
    Zhao](../Images/186bba91822dbcc0f926426e56faf543.png)](https://chengzhizhao.medium.com/?source=post_page-----57ce0d94ee38--------------------------------)[](https://towardsdatascience.com/?source=post_page-----57ce0d94ee38--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----57ce0d94ee38--------------------------------)
    [Chengzhi Zhao](https://chengzhizhao.medium.com/?source=post_page-----57ce0d94ee38--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----57ce0d94ee38--------------------------------)
    ·10 min read·Jan 3, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2c9d079782f553e5b7931674b18b46c0.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Lizzi Sassman](https://unsplash.com/@okaylizzi?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/data?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: '**“*Why my Spark job is running slow?*”** is an inevitable question while working
    with Apache Spark. One of the most common scenarios regarding Apache Spark performance
    tuning is **data skew**. In this article, we will cover how to identify whether
    your Spark job slowness is caused by data skew and deep dive into handling Apache
    Spark data skew with code to explain three ways to handle data skew, including
    the “salting” technique.'
  prefs: []
  type: TYPE_NORMAL
- en: How to Identify Data Skew In Spark
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are many factors when it comes to Spark performance tuning. Given the
    complexity of distributed computing, you are halfway to success if you can narrow
    it down to the bottleneck.
  prefs: []
  type: TYPE_NORMAL
- en: Data skew usually happens when partitions have uneven data to process. Let’s
    assume we have three partitions in Spark to process data for 1.5M records. Ideally,
    each partition gets 0.5M to process evenly (Picture 1 left). However, we could
    have a time when a single partition takes much more data than the other partitions
    (Picture 1, right).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8ef676417b929cb0e4813d33f7c8824a.png)'
  prefs: []
  type: TYPE_IMG
- en: Picture 1 | image By Author
  prefs: []
  type: TYPE_NORMAL
- en: '**Why does one partition take more data than the others?** This is related
    to how the distribution system works. In many data processing frameworks, data
    skew is caused by data shuffling, which is moving data from one partition to another.
    Data shuffle needs to be taken care of when it comes to performance tuning, as
    it involves transferring data around the nodes in your cluster. It can cause an
    undesired delay in your data pipeline and is difficult to discover.'
  prefs: []
  type: TYPE_NORMAL
- en: A data shuffle is expensive, but sometimes it is inevitable to perform a [wide
    operation](https://www.databricks.com/glossary/what-are-transformations) such
    as groupBy and joins. Those operations usually are key-based, meaning keys are
    hashed and then mapped to partitions. The same hash value is guaranteed to shuffle
    to the same partition. In the above example, many keys are hashed to partition
    A with massive volume, and partition A becomes a “hot spot” to process close to
    99% of the data. That’s why this entire job is running behind — The data isn’t
    not distributed well, as partition B and C stays idle most of the time, and partition
    A is the guinea pig that handles the heavy load.
  prefs: []
  type: TYPE_NORMAL
- en: '**What are the signs of data skew in Spark?** We cannot blame every slowness
    that comes from data skew. The [Spark Web UI](https://spark.apache.org/docs/latest/web-ui.html)
    is the best native solution to identify the skewness in your Spark job. When you
    are at the Stages tab in Spark UI, the skewed partitions hang within a stage and
    don’t seem to progress for a while on a few partitions. If we look at the summary
    metrics, the max column usually has a much larger value than the medium and more
    records count. Then we know we have encountered a data skew issue.'
  prefs: []
  type: TYPE_NORMAL
- en: '**How to know which part of the code causes data skew?** The stage detail page
    in Spark UI only gives us a visual representation of the DAG.'
  prefs: []
  type: TYPE_NORMAL
- en: 'How do you know which part of the code in Spark is running slow? It is mentioned
    in the Spark official documentation: “[*Whole Stage Code Generation operations
    are also annotated with the* ***code generation id****. For stages of Spark DataFrame
    or SQL execution, this allows for cross-referencing Stage execution details to
    the relevant details in the Web-UI SQL Tab page where SQL plan graphs and execution
    plans are reported.*](https://spark.apache.org/docs/latest/web-ui.html#stage-detail)”'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following case, we can use the WholeStageCodegen ids: 2,4, or 5\. We
    can go to the Spark Data Frame tab to find the code and hover on the SQL plan
    graphs to know the detail of what’s running in your code.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/546dfe2dc17a198239148b12f61b65f9.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of Codegen Id | Image By Author
  prefs: []
  type: TYPE_NORMAL
- en: Data Skew Example Set up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s start by setting up a spark environment with data skew to demonstrate
    the issue. We will set up only 1G for`spark.executor.memory` and one executor
    with three cores, and `spark.sql.shuffle.partitions`to three as well, so we will
    get three partitions finally. We can use [spark_partition_id](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.functions.spark_partition_id.html)
    to determine which partition a record belongs to verify the data distribution.
    To ensure spark is less smart to figure out more optimization like increasing
    the number of partitions or converting the physical plan to broadcast join, we
    will turn off Adaptive Query Execution ([AQE](https://spark.apache.org/docs/3.0.2/sql-performance-tuning.html#adaptive-query-execution))
    by setting`spark.sql.adaptive.enabled` to false.
  prefs: []
  type: TYPE_NORMAL
- en: We don’t need to import additional data sources to set up the example. We can
    create random data and play with it as our example throughout this article.
  prefs: []
  type: TYPE_NORMAL
- en: '**Case 1: evenly distributed case**'
  prefs: []
  type: TYPE_NORMAL
- en: We will create a dataframe with 1,000,000 rows in Spark. In this case, those
    values from 0 to 999,999 are the key that is hashed and shuffled. Notice the key
    here is unique, which means there aren’t any duplications. **Those ensure the
    keys are non-deterministically. There is no guarantee that two different keys
    always being in the same partition.**
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You can verify the number of partitions by using [getNumPartitions](https://www.google.com/search?client=safari&rls=en&q=getNumPartitions&ie=UTF-8&oe=UTF-8&safari_group=9),
    and in this case, it should be three since we only have one executor and three
    cores.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: If everything is distributed evenly, we will get a well-distributed count if
    we group by the partitionId. This is the perfect case we have mentioned above
    *Picture 1 left.*
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/03e9f32795818c2b359f127cb940b7b8.png)'
  prefs: []
  type: TYPE_IMG
- en: Data Partitioned Evenly By PartitionId | Image By Author
  prefs: []
  type: TYPE_NORMAL
- en: We can then perform a self-join to check what the plan looks like, and we’d
    expected [SortMergJoin](https://jaceklaskowski.gitbooks.io/mastering-spark-sql/content/spark-sql-SparkPlan-SortMergeJoinExec.html),
    which is usually the best we can do if two datasets are equally significant.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In the following result, we can see data size total is distributed well among
    three partitions, and if we look at the time it takes for each partition, they
    don’t seem to have substantial gaps.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f1f387858349775eb4956c47e7a0bf44.png)'
  prefs: []
  type: TYPE_IMG
- en: Data Partitioned Evenly As Spark Physical Plan| Image By Author
  prefs: []
  type: TYPE_NORMAL
- en: '**Case 2: Skew case**'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s go extreme to have what *Picture 1 right*showed, where we have an
    extremely skewed dataset.
  prefs: []
  type: TYPE_NORMAL
- en: We will still create a dataframe with 1000000 rows in Spark. However, instead
    of having all keys with different values, we will make most of them the same.
    This ensures that we create a **“hot” key that becomes problematic no matter how
    many hash functions we try. It guarantees to be in the same partition.**
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/05da84454566436f05d9b0c9073431a8.png)'
  prefs: []
  type: TYPE_IMG
- en: Data Skew By PartitionId | Image By Author
  prefs: []
  type: TYPE_NORMAL
- en: In this case, 99.99% of the data is in a single partition. Let’s perform a join
    with our distributed evenly dataset to check what the plan looks like. Before
    we run the join, let’s repartition our skew dataset into three partitions in a
    round-robin way to simulate how we will read data in actual use cases.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Checking on the Spark physical plan, we can see how unevenly distributed it
    is with a large amount of data in one partition (max time), and the time to join
    is exponential.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/95c093fbde8a9f85724ac5bc8475e683.png)'
  prefs: []
  type: TYPE_IMG
- en: Data Partitioned Skew As Spark Physical Plan| Image By Author
  prefs: []
  type: TYPE_NORMAL
- en: How to resolve the data skew problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data Skew causes slow performance in Spark, and a job is stuck in a few partitions
    that hang forever. There are multiple strategies to resolve a skew. Today, with
    Adaptive Query Execution (AQE) on Spark, it’s easier for Spark to be clever to
    figure out the optimized way. In edge cases, AQE isn’t 100% giving the best optimization.
    At those times, we still need to intervene and be familiar with which to use.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Leveraging the Number of Partitions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`spark.sql.shuffle.partitions` might be one of the most critical configurations
    in Spark. [*It configures the number of partitions to use when shuffling data
    for joins or aggregations.*](https://spark.apache.org/docs/3.0.2/sql-performance-tuning.html#adaptive-query-execution)
    *Configuring this* value won’t always mean dealing with the skew issue, but it
    could be general optimization on the Spark job. The default value is 200, which
    is suitable for many big data projects back in the day and still relevant for
    small/medium size data projects.'
  prefs: []
  type: TYPE_NORMAL
- en: Think of this as the number of bins when data has to be tossed around during
    the shuffling stage. Are there too much data for a single bin to handle, or are
    they almost full?
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Broadcast join
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Broadcast join might be the fastest join type that you can use to avoid skewness.
    By giving when the `BROADCAST` hint, we explicitly provide information to Spark
    on which dataframe we’d need to send to each executor.
  prefs: []
  type: TYPE_NORMAL
- en: The broadcast join usually works with smaller size dataframe like dimension
    tables or the data has metadata. It is not appropriate for transaction tables
    with millions of rows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 3\. Salting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The SALT idea from cryptography introduced randomness to the key without knowing
    any context about the dataset. The idea is for a given hot key; if it combines
    with different random numbers, we’ll not have all the data for the given key processed
    in a single partition. A significant benefit of SALT is it is unrelated to any
    of the keys, and you don’t have to worry about some keys with similar contexts
    with the same value again.
  prefs: []
  type: TYPE_NORMAL
- en: I have published another article on [Skewed Data in Spark? Add SALT to Compensate](https://medium.com/towards-data-science/skewed-data-in-spark-add-salt-to-compensate-16d44404088b).
    You can read more to learn about it.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/skewed-data-in-spark-add-salt-to-compensate-16d44404088b?source=post_page-----57ce0d94ee38--------------------------------)
    [## Skewed Data in Spark? Add SALT to Compensate'
  prefs: []
  type: TYPE_NORMAL
- en: A step-by-step guide to handle skewed data with SALT technique
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/skewed-data-in-spark-add-salt-to-compensate-16d44404088b?source=post_page-----57ce0d94ee38--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'However, in the above article, I have only provided code for salting on aggregation.
    Still, I haven’t mentioned how to perform slating on join, which leaves some questions:
    "*I understood we could salt on the key to distributing data evenly, but that
    changed my join key. How do you join back to the original key after salting?*”
    I will provide some code examples in this post.'
  prefs: []
  type: TYPE_NORMAL
- en: The core idea of leveraging key salting is to think space-time tradeoff.
  prefs: []
  type: TYPE_NORMAL
- en: '**Add the salt key as part of the key as a new column**. We also call the original
    key and the salt key a composite key. The newly added key forces Spark to hash
    the new key to a different hash value, so it shuffles to a different partition.
    Note we can also be dynamic to get the number of randomness on the salt key by
    retrieving the value from `spark.sql.shuffle.partitions`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: As you can see below, though value and partitionId are the same, we create an
    additional “salt” column to provide more guidance for Spark to join.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e9a480072a35ea6988632f9c9eced6b9.png)'
  prefs: []
  type: TYPE_IMG
- en: Add the salt key as part of the key as a new column | Image By Author
  prefs: []
  type: TYPE_NORMAL
- en: '**Add an array of all the potential salt keys as a new column**. You can choose
    a dataframe with a smaller number of rows (if they are the same, pick a random
    one), and'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/f8a6e251f8e421da714f255b4f58906e.png)'
  prefs: []
  type: TYPE_IMG
- en: Add an array of all the potential salt keys as a new column | Image By Author
  prefs: []
  type: TYPE_NORMAL
- en: '**Explore the dataframe with that array**. This will replicate the existing
    rows n times (n=number of salt you chose). When the two dataframes joined, since
    we already have the replicated dataframe on one side (usually the right side),
    it is still validated joining. It produces the same result as we are using the
    original key.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can also validate the final distribution after joining. The joined dataframe
    for the same key “0” is distributed evenly across three partitions. This even
    distribution shows the technique of key salting.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/770e5a7abac718cae449cae638ce8671.png)'
  prefs: []
  type: TYPE_IMG
- en: Final PartitionId after Join | Image By Author
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the physical plan, the data is distributed evenly and takes similar
    times to process on percentile metrics. We can tell the significant difference
    if we choose a much larger dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9cc46cf2e26e58b60e994fe2453a56b1.png)'
  prefs: []
  type: TYPE_IMG
- en: Key Salting to improve Spark Performance Physical Plan | Image By Author
  prefs: []
  type: TYPE_NORMAL
- en: '**Final Thought**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data Skew in Apache Spark can be handled in various ways. It can be resolved
    from Spark configuration, from Spark plan optimization, or from hacking a “salt”
    key to guide Spark to distribute data evenly. Identifying the reason for a Spark
    job slowness is the foundation for any Spark tunning. Among those reasons, Data
    skew is one of those frequent blamers.
  prefs: []
  type: TYPE_NORMAL
- en: I wrote this article to help everyone better understand what data skew is in
    Spark and potential solutions to solve them. However, when it comes to Spark performance
    optimization, there isn’t a silver bullet. You’d need to spend more energy looking
    at the query plan and figuring out what’s happening in the code. More knowledge
    is gained by trial and error.
  prefs: []
  type: TYPE_NORMAL
- en: 'I hope this story is helpful to you. This article is **part of a series** of
    my engineering & data science stories that currently consist of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chengzhi Zhao](../Images/51b8d26809e870b4733e4e5b6d982a9f.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Chengzhi Zhao](https://chengzhizhao.medium.com/?source=post_page-----57ce0d94ee38--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Data Engineering & Data Science Stories
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://chengzhizhao.medium.com/list/data-engineering-data-science-stories-ddab37f718e7?source=post_page-----57ce0d94ee38--------------------------------)53
    stories![](../Images/8b5085966553259eef85cc643e6907fa.png)![](../Images/9dcdca1fc00a5694849b2c6f36f038d4.png)![](../Images/2a6b2af56aa4d87fa1c30407e49c78f7.png)'
  prefs: []
  type: TYPE_NORMAL
- en: You can also [**subscribe to my new articles**](https://chengzhizhao.medium.com/subscribe)
    or become a [**referred Medium member**](https://chengzhizhao.medium.com/membership)who
    gets unlimited access to all the stories on Medium.
  prefs: []
  type: TYPE_NORMAL
- en: In case of questions/comments, **do not hesitate to write in the comments**
    of this story or **reach me directly** through [Linkedin](https://www.linkedin.com/in/chengzhizhao/)
    or [Twitter](https://twitter.com/ChengzhiZhao).
  prefs: []
  type: TYPE_NORMAL
