# 监控生产环境中的机器学习模型的难点

> 原文：[https://towardsdatascience.com/the-difficulties-of-monitoring-machine-learning-models-in-production-ed3f87e88253](https://towardsdatascience.com/the-difficulties-of-monitoring-machine-learning-models-in-production-ed3f87e88253)

[](https://maciejbalawejder.medium.com/?source=post_page-----ed3f87e88253--------------------------------)[![Maciej Balawejder](../Images/ad4b417970bfa929283a9da89a091494.png)](https://maciejbalawejder.medium.com/?source=post_page-----ed3f87e88253--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ed3f87e88253--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ed3f87e88253--------------------------------) [Maciej Balawejder](https://maciejbalawejder.medium.com/?source=post_page-----ed3f87e88253--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ed3f87e88253--------------------------------) ·7分钟阅读·2023年3月14日

--

![](../Images/0c292c56c7b178d571dd34d1cc4ec2e1.png)

照片由 [Luke Chesser](https://unsplash.com/@lukechesser?utm_source=medium&utm_medium=referral) 提供，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

成为数据科学家可能听起来像是一份简单的工作 — 准备数据、训练模型并将其部署到生产环境中。然而，现实却远非如此。这个工作更像是照顾一个婴儿 — 一个永无止境的监控周期，确保一切正常。

挑战在于需要关注三个关键组件：代码、数据和模型本身。每个元素都有其自身的难点，使得在生产环境中的监控变得困难。

在这篇文章中，我们将深入探讨这些挑战，并提及可能的解决方法。

# 模型失败的两种方式

## ***‍模型未能进行预测***

![](../Images/67de4312e15f610cd78c109b660fb386.png)

代码中的错误示例。图像由作者提供。图像由作者提供。

当我们谈论模型未能进行预测时，意味着它无法生成输出。由于模型始终是更大软件系统的一部分，它还会面临更多技术挑战。以下是一些可能的例子：

+   **语言障碍** — 将一个用一种编程语言构建的模型集成到用另一种语言编写的系统中。这可能需要额外的代码或“粘合”代码来连接两种语言，增加了复杂性和失败的风险。

+   **维护代码** — 正如我们所知，库和其他依赖项不断更新，因此它们的功能命令等也会变化。跟踪这些变化与代码的关系很重要，以确保代码不会过时。

+   **扩展问题** — 随着我们的模型用户越来越多，基础设施可能无法足够强大以处理所有请求。

良好的软件监控和维护系统应能防止可能的问题。即使发生了问题，我们也会直接获得异常信息。在下一节中，我们将深入探讨那些检测不那么明显的问题。

## 模型的预测失败

在这种情况下，模型生成了输出，但其性能正在下降。这种失败特别棘手，因为它通常是无声的——没有明显的警报或指示器表明发生了什么。整个管道或应用程序可能看起来运作正常，但模型生成的预测可能已不再有效。

这个问题有以下两个原因：

## 协变量漂移

> *输入特征的分布随时间变化。*

![](../Images/1317d85611c9b439860426720b07138c.png)

训练和生产数据中 CLV 预测的协变量漂移分布。作者提供的图片。

上图展示了一个社交媒体平台上客户生命周期价值 (CLV) 预测的假设场景。训练数据的分布严重偏向年轻客户。然而，当模型在生产中部署时，分布发生了变化，年长客户略有增加。

一个可能的解释是，当训练数据被收集时，平台的大多数用户是年轻的。随着平台的流行，年长的客户开始注册。这个新用户群体的特征与历史用户不同，这意味着模型现在更容易出错。

数据漂移的检测相对简单。我们需要比较不同时间段的分布，以识别数据的变化。棘手的部分是，并非所有漂移都会导致性能下降。

有时，数据的变化可能不会影响模型的整体性能。这是因为并非每个输入特征对输出的贡献都是一样的。只有重要特征的变化会对模型的整体性能产生显著影响。

## 概念漂移

> *模型输入和输出之间的关系发生了变化。*

![](../Images/29b0dca1d3b298a185fda5fd8ba08682.png)

训练和生产数据中 CLV 与“年龄”特征的关系。作者提供的图片。

让我们回到客户生命周期价值预测的例子。如我们所见，年轻客户的 CLV 在生产中有所下降。这可能是由于年轻用户迁移到其他社交媒体平台造成的，比如我们看到的从 Facebook 到 Instagram 的快速转移。在训练时提取的年龄与 CLV 的关系在生产中已不再相关。

与协方差转移不同，概念漂移几乎总是影响模型的商业影响。更具挑战性的是，概念漂移并不容易检测。一个可能的解决方案是对标签进行相关性分析，或在分析和参考期训练并比较两个独立模型。另一种方法是仔细监控模型性能随时间的变化。如果性能下降，这可能表明概念漂移正在发生。

然而，监控模型性能并非总是容易的，尤其是当目标标签的访问受到限制时。这是一个关键挑战，我们将在下一段中更详细地探讨。

# 真实值的可用性

如前所述，访问目标值是监控生产中机器学习模型的关键方面。根据这些值的可用性，我们可以区分三种类型：

## 即时

> *真实值是立即可用的。*

一个典型的即时可用性例子是汽车到达预测。在旅行完成后，我们可以立即评估预测结果，并获得模型的实时性能。

![](../Images/2a198a8647d58f21da756be0b509c825.png)

使用 NannyML 进行即时真实值的性能监控。图片由作者提供。

上图展示了分类问题中的一种常见场景，其中**参考期**代表测试数据集，**分析期**代表来自生产的实时数据流。在右侧，我们可以看到一个表格数据的例子，并且突出显示了目标值。通过即时访问真实值，我们可以不断监控模型的性能。如果性能低于某个阈值，如从六月到十月所示，这表明我们需要调查下降的原因。

对目标值的即时访问使得监控和评估模型性能变得更加容易。然而，世界是复杂的，获取即时真实值并非总是那么简单。

## 延迟

> *真实值在时间上被推迟。*

对服装公司的需求预测是一个很好的例子，说明真实值的延迟。这些公司使用机器学习模型预测下一个季节的需求。然而，评估预测结果是一项棘手的任务，因为他们必须等待 3 个月，直到季节结束才能衡量预测的准确性。

![](../Images/87a7fb961ba704a49e565e255ae12300.png)

使用 NannyML 进行带有延迟真实值的性能监控。图片由作者提供。

正如右侧所示，我们的表格数据由于延迟而缺少关键的目标值。这种信息缺失在图表中体现出来，我们可以看到从五月到十一月模型的 ROC AUC 性能存在一个间隙。这使得实时了解模型的表现及其决策是否仍然准确变得具有挑战性。

## 缺失

> *完全没有真实数据。*

在某些情况下，例如完全自动化的流程中，可能无法获得真实数据。一个例子是使用机器学习模型进行保险定价。这些模型在生产环境中部署，根据人口统计信息或车辆信息预测保险价格。然而，由于这个过程是自动化的，没有人参与评估预测的准确性。

![](../Images/93e6816aa5cd1ab90e355cec7786cd4f.png)

使用 NannyML 在缺乏真实数据的情况下进行性能监控。

当我们查看表格数据时，我们可以看到目标值完全缺失。这在我们的性能图中反映出来，部署后图表是空白的。这使得很难清楚地了解我们的模型实际表现如何，以及其预测是否仍然可靠。

尽管缺乏真实数据听起来可能令人沮丧，但这并不意味着模型的性能无法评估。即使模型没有目标值，它仍然会生成输出，我们可以将其与之前的数据进行比较。这些信息足以估计其性能。虽然真实数据的可用性使得评估模型性能的任务更容易，但即使在其[缺失](https://www.nannyml.com/blog)的情况下，也可以进行评估。

# 结论

作为数据科学家，关键责任之一是确保整个模型和管道顺利运行。然而，这通常是一个具有挑战性的任务，因为在生产过程中可能会出现几个障碍，例如：

+   **代码** — 模型因错误无法进行预测

+   **数据** — 协变量偏移、概念漂移或对真实数据的有限访问

但不用担心；现在你知道了需要注意的事项以及这些问题发生的原因，你将能够轻松应对它们。

祝监控愉快！

*这篇博客最初发布于* [*https://www.nannyml.com/blog*](https://www.nannyml.com/blog)
