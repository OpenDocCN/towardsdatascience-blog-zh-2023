["```py\n**Prerequisites\n-------------**\n01\\. [An Introduction to Autoencoders in Deep Learning](https://rukshanpramoditha.medium.com/an-introduction-to-autoencoders-in-deep-learning-ab5a5861f81e)\n02\\. [Autoecnoder Latent Representation and Hidden Layers](/how-number-of-hidden-layers-affects-the-quality-of-autoencoder-latent-representation-181215c8e7d1)\n03\\. [Autoecnoder Latent Representation and Latent Vector Dimension](https://rukshanpramoditha.medium.com/how-the-dimension-of-autoencoder-latent-vector-affects-the-quality-of-latent-representation-c98c38fbe3c3)\n04\\. [Dimensionality Reduction with Autoencoders](/how-autoencoders-outperform-pca-in-dimensionality-reduction-1ae44c68b42f)\n05\\. [Creating Shallow and Deep Autoencoders in Keras](/generate-mnist-digits-using-shallow-and-deep-autoencoders-in-keras-fb011dd3fec3)\n\n**Optional\n--------**\n06\\. [Convolutional Neural Network (CNN) Architecture](/convolutional-neural-network-cnn-architecture-explained-in-plain-english-using-simple-diagrams-e5de17eacc8f)\n07\\. [Coding a Convolutional Neural Network (CNN)](/coding-a-convolutional-neural-network-cnn-using-keras-sequential-api-ec5211126875)\n08\\. [Acquire, Understand and Prepare the MNIST Dataset](https://rukshanpramoditha.medium.com/acquire-understand-and-prepare-the-mnist-dataset-3d71a84e07e7)\n09\\. [Keras Sequential API and Functional API](https://rukshanpramoditha.medium.com/two-different-ways-to-build-keras-models-sequential-api-and-functional-api-868e64594820)\n10\\. [Plotting the Learning Curve](https://rukshanpramoditha.medium.com/plotting-the-learning-curve-to-analyze-the-training-performance-of-a-neural-network-4a35818d01f2)\n11\\. [Image representation in deep learning](/exploring-the-mnist-digits-dataset-7ff62631766a)\n```", "```py\nautoencoder.fit(train_images, train_images)\n```", "```py\nautoencoder.fit(train_images_noisy, train_images)\n```", "```py\nimport numpy as np\n\nnoise = np.random.normal(loc=0.0, scale=0.7, size=train_images.shape)\ntrain_images_noisy = train_images + noise\n```", "```py\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import Model, Input\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Conv2DTranspose\n\n# Load the MNIST dataset\n(train_images, _), (test_images, _) = mnist.load_data()\n\n###########################\n# Feedforward Autoencoder #\n###########################\n\n# Reshape data for the dense layer input\ntrain_images = np.reshape(train_images, (-1, 784))\ntest_images = np.reshape(test_images, (-1, 784))\n\n# Scale the data\ntrain_images = train_images.astype('float32') / 255\ntest_images = test_images.astype('float32') / 255\n\n# Add Gaussian noise to the data\nnoise = np.random.normal(loc=0.0, scale=0.7, size=train_images.shape)\ntrain_images_noisy = train_images + noise\n\nnoise = np.random.normal(loc=0.0, scale=0.7, size=test_images.shape)\ntest_images_noisy = test_images + noise\n\n# Clip the noisy data by 0 and 1:\n# This is because adding noise may push the normalized pixel values \n# into invalid values of less than 0 or greater than 1\n# So, we need to clip pixel values greater than 1 to 1.0 and\n# less than 0 to 0.0\ntrain_images_noisy = np.clip(train_images_noisy, 0., 1.)\ntest_images_noisy = np.clip(test_images_noisy, 0., 1.)\n\nlatent_vec_dim = 16\ninput_dim = 784\n\n# Define the input layer\ninput_layer = Input(shape=(input_dim,))\n\n# Define the feedforward (ff) autoencoder architecture\n# First build the encoder with dense layers\nx = Dense(500, activation='sigmoid')(input_layer)\nx = Dense(300, activation='sigmoid')(x)\nx = Dense(100, activation='sigmoid')(x)\nencoder = Dense(latent_vec_dim, activation='tanh')(x)\n\n# Then build the decoder with dense layers\nx = Dense(100, activation='sigmoid')(encoder)\nx = Dense(300, activation='sigmoid')(x)\nx = Dense(500, activation='sigmoid')(x)\ndecoder = Dense(input_dim, activation='sigmoid')(x)\n\n# Connect both encoder and decoder\nff_autoencoder = Model(input_layer, decoder, name=\"ff_autoencoder\")\n\n# Compile the model\nff_autoencoder.compile(loss='binary_crossentropy', optimizer='adam')\n\n# Train the model\nhistory_ff = ff_autoencoder.fit(train_images_noisy, train_images, epochs=50, \n                                batch_size=128, shuffle=True,\n                                validation_data=(test_images_noisy, test_images))\n\n# Denoise new images (prediction)\nff_autoencoder_denoised_images = ff_autoencoder.predict(test_images_noisy)\n\n# Clear the history of the previous model\n# Otherwise, youâ€™ll run out of memory or \n# will get abnormal results due to clutter from old models and layers.\ntf.keras.backend.clear_session()\n\n# Load the MNIST dataset again\n(train_images, _), (test_images, _) = mnist.load_data()\n\n#############################\n# Convolutional Autoencoder #\n#############################\n\n# Reshape data for the convolutional layer input\ntrain_images = np.reshape(train_images, (len(train_images), 28, 28, 1))\ntest_images = np.reshape(test_images, (len(test_images), 28, 28, 1))\n\n# Scale the data\ntrain_images = train_images.astype('float32') / 255\ntest_images = test_images.astype('float32') / 255\n\n# Add Gaussian noise to the data\nnoise = np.random.normal(loc=0.0, scale=0.7, size=train_images.shape)\ntrain_images_noisy = train_images + noise\n\nnoise = np.random.normal(loc=0.0, scale=0.7, size=test_images.shape)\ntest_images_noisy = test_images + noise\n\n# Clip the noisy data by 0 and 1 as before\ntrain_images_noisy = np.clip(train_images_noisy, 0., 1.)\ntest_images_noisy = np.clip(test_images_noisy, 0., 1.)\n\n# Define the input layer\ninput_layer = Input(shape=(28, 28, 1))\n\n# Define the convolutional (conv) autoencoder architecture\n# First build the encoder with convolutional layers\nx = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\nx = MaxPooling2D((2, 2), padding='same')(x)\n\nx = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\nencoder = MaxPooling2D((2, 2), padding='same')(x)\n\n# Then build the decoder with transposed convolutional layers\nx = Conv2DTranspose(64, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(encoder)\nx = Conv2DTranspose(64, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\ndecoder = Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n\n# Connect both encoder and decoder\nconv_autoencoder = Model(input_layer, decoder, name=\"conv_autoencoder\")\n\n# Compile the model\nconv_autoencoder.compile(loss='binary_crossentropy', optimizer='adam')\n\n# Train the model\nhistory_conv = conv_autoencoder.fit(train_images_noisy, train_images,\n                                    epochs=50, batch_size=128, shuffle=True, \n                                    validation_data=(test_images_noisy, test_images))\n\n# Denoise new images (prediction)\nconv_autoencoder_denoised_images = conv_autoencoder.predict(test_images_noisy)\n```", "```py\n# Plot training and validation loss scores\n# against the number of epochs\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n\nax1.plot(history_ff.history['loss'], label='Train')\nax1.plot(history_ff.history['val_loss'], label='Validation')\nax1.set_title('FF_AE Loss', pad=12)\nax1.set_xlabel('Epoch')\nax1.set_ylabel('Loss')\nax1.legend(loc='upper right')\n\nax2.plot(history_conv.history['loss'], label='Train')\nax2.plot(history_conv.history['val_loss'], label='Validation')\nax2.set_title('Conv_AE Loss', pad=12)\nax2.set_xlabel('Epoch')\nax2.set_ylabel('Loss')\nax2.legend(loc='upper right')\n\nplt.savefig(\"Learning_Curves.png\")\n```", "```py\n# Visualize image outputs\nn = 10\nplt.figure(figsize=(10, 5))\n\nfor i in range(n):\n    # Display noisy images\n    ax = plt.subplot(4, n, i + 1)\n    plt.imshow(test_images_noisy[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # Display denoised images by feedforward autoencoder\n    ax = plt.subplot(4, n, i + 1 + n)\n    plt.imshow(ff_autoencoder_denoised_images[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # Display denoised images by convolutional autoencoder\n    ax = plt.subplot(4, n, i + 1 + 2*n)\n    plt.imshow(conv_autoencoder_denoised_images[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # Display original images for comparison purposes\n    ax = plt.subplot(4, n, i + 1 + 3*n)\n    plt.imshow(test_images[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\nplt.savefig(\"Comparisons.png\")\n```"]