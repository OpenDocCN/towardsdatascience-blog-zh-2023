- en: 8 Best Data Version Control Tools in 2023
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/8-best-data-version-control-tools-in-2023-cc9045d37bb8](https://towardsdatascience.com/8-best-data-version-control-tools-in-2023-cc9045d37bb8)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A complete overview revealing a diverse range of strengths and weaknesses for
    each data versioning tool
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://zoumanakeita.medium.com/?source=post_page-----cc9045d37bb8--------------------------------)[![Zoumana
    Keita](../Images/34a15c1d03687816dbdbc065f5719f80.png)](https://zoumanakeita.medium.com/?source=post_page-----cc9045d37bb8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cc9045d37bb8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cc9045d37bb8--------------------------------)
    [Zoumana Keita](https://zoumanakeita.medium.com/?source=post_page-----cc9045d37bb8--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cc9045d37bb8--------------------------------)
    ¬∑8 min read¬∑Mar 24, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/71e6a65d8be04ae2dec4567edd942ca4.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Alina Grubnyak](https://unsplash.com/@alinnnaaaa) on [Unsplash](https://unsplash.com/photos/ZiQkhI7417A)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With business needs changing constantly and the growing size and structure of
    datasets, it becomes challenging to efficiently keep track of the changes made
    to the data, which leads to unfortunate scenarios such as inconsistencies and
    errors in data.
  prefs: []
  type: TYPE_NORMAL
- en: To help data practitioners, this blog will cover eight of the top data versioning
    tools in the market. It will provide a clear explanation of each tool, including
    their benefits and drawbacks of each of them.
  prefs: []
  type: TYPE_NORMAL
- en: Why do we need to version our data?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Keeping track of the different versions of data can be challenging as trying
    to juggle multiple balls at a time. Without proper coordination, balance, and
    precision, things can quickly fall apart. The following points illustrate some
    of the main reasons why data versioning is crucial to the success of any data
    science and machine learning project:'
  prefs: []
  type: TYPE_NORMAL
- en: Storage space
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the reasons for versioning data is to be able to keep track of multiple
    versions of the same data which obviously need to be stored as well. So, not having
    enough space makes it hard to store them, which ultimately leads to failure.
  prefs: []
  type: TYPE_NORMAL
- en: Data auditing and compliance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Almost every company faces data protection regulations such as GDPR, forcing
    them to store certain information in order to demonstrate compliance and the history
    of data sources. In this scenario, data versioning can help companies in both
    internal and external audits process.
  prefs: []
  type: TYPE_NORMAL
- en: Storage and reproducibility of experiments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Developing machine learning models goes beyond running codes, but about training
    data and the right parameters. Updating the models is an iterative process, and
    it requires tracking all the changes previously made. This tracking becomes crucial
    even in a more complex environment involving multiple users. Using data versioning
    can make it possible to have a snapshot of the training data and experimentation
    results to make the implementation easier at each iteration.
  prefs: []
  type: TYPE_NORMAL
- en: The above challenges can be tackled by using the following eight data version
    control tools.
  prefs: []
  type: TYPE_NORMAL
- en: Best data version control tools for 2023
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you have a clear understanding of the expectations of the blog, let‚Äôs
    explore each one of them, starting with DagsHub.
  prefs: []
  type: TYPE_NORMAL
- en: DagsHub
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[DagsHub](https://dagshub.com/) is a centralized Github-based platform that
    allows Machine Learning and Data Science teams to build, manage and collaborate
    on their projects. In addition to versioning code, teams can also version data,
    models, experiments, and more.'
  prefs: []
  type: TYPE_NORMAL
- en: Released in 2022, DagsHub‚Äôs [Direct Data Access](https://dagshub.com/docs/feature_guide/direct_data_access/)
    (DDA for short) allows Data Scientists and Machine Learning engineers to stream
    files from the DagsHub repository without needing to download them to their local
    environment ahead of time. This can prevent lengthy data downloads to the local
    disks before initiating their mode training.
  prefs: []
  type: TYPE_NORMAL
- en: '**Strengths**'
  prefs: []
  type: TYPE_NORMAL
- en: With DDA, there is no need to pull all the training data to a local disk, which
    can help save time and memory storage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It gives the same organization and reproducibility provided by DVC, with the
    ease of use and flexibility of a data API, without requiring any changes to your
    project.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DDA makes it possible to upload data and version it using DVC without the need
    to pull all the data. DagsHub calculates the new hashes, and commits the new DVC-tracked
    and modified Git-tracked files on the users‚Äô behalf.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Weakness**'
  prefs: []
  type: TYPE_NORMAL
- en: It does not work with connected GitHub repositories to DagsHub.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It does not support the ‚Äòdvc repro‚Äô command to reproduce its data pipeline.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DVC
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Released in 2017, Data Version Control (DVC for short) is an open-source tool
    created by iterative.
  prefs: []
  type: TYPE_NORMAL
- en: DVC can be used for versioning data and models, tracking experiments, and comparing
    any data, code, parameters models, and graphical plots of performance.
  prefs: []
  type: TYPE_NORMAL
- en: '**Strengths**'
  prefs: []
  type: TYPE_NORMAL
- en: Open source, and compatible with all major cloud platforms and storage types.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DVC can efficiently handle large files and machine-learning models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Built as an extension to Git, which is a standard tool used by many developers
    for source code versioning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Weakness**'
  prefs: []
  type: TYPE_NORMAL
- en: It fails when dealing with very large datasets, because of the computation of
    the hashes that takes a considerable amount of time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collaboration with others requires multiple configurations such as setting up
    remote storage, defining roles, and providing access to each contributor, which
    can be frustrating and time-consuming.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding new data to the storage requires pulling the existing data, then calculating
    the new hash before pushing back the whole data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DVC lacks crucial relational database features, making it an unsuitable choice
    for those familiar with relational databases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dolt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Created in 2019, [Dolt](https://docs.dolthub.com/introduction/what-is-dolt)
    is an open-source tool for managing SQL databases that uses version control similar
    to Git. It versions tables instead of files and has a SQL query interface for
    those tables.
  prefs: []
  type: TYPE_NORMAL
- en: This enhancement in the user experience is achieved by enabling simultaneous
    changes to both data and structure through version control.
  prefs: []
  type: TYPE_NORMAL
- en: '**Strengths**'
  prefs: []
  type: TYPE_NORMAL
- en: It can be integrated into the users‚Äô existing infrastructure like any other
    SQL database and guarantees the ACID property.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most developers are familiar with Git for source code versioning. So, Dolt‚Äôs
    integration with Git makes it easier to learn.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Weakness**'
  prefs: []
  type: TYPE_NORMAL
- en: Dolt purely relies on the ACID property, meaning that it is only useful when
    dealing with relational databases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It does not provide high performance for computing very large amounts of data
    (petabyte-scale data).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since it is only designed for relational databases, it does not support unstructured
    data such as images, audio, and free-form text.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Git LFS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Git Large File Storage](https://www.atlassian.com/git/tutorials/git-lfs#:~:text=Git%20LFS%20(Large%20File%20Storage,relevant%20versions%20of%20them%20lazily.))
    (Git LFS) is an open-source project developed by Atlassian to extend Git‚Äôs capability
    to manage large binary files like audio samples, movies, and big datasets while
    retaining Git‚Äôs lightweight design and efficiency.'
  prefs: []
  type: TYPE_NORMAL
- en: With Git LFS, large files are stored in the cloud, and they are referenced via
    pointers in local copies of the remote server.
  prefs: []
  type: TYPE_NORMAL
- en: '**Strengths**'
  prefs: []
  type: TYPE_NORMAL
- en: It stores any type of file regardless of the format, which makes it flexible
    and versatile for versioning large files on Git.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developers can easily move large files to Git LFS without making any changes
    to their existing workflow.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Weakness**'
  prefs: []
  type: TYPE_NORMAL
- en: Git LFS requires a unique remote Git server, making it a one-way door. This
    is a disadvantage for users who in some cases would like to revert back to using
    vanilla Git.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is not intuitive for new users due to its complexity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Git LFS requires an LFS server to work. Such a server is not provided by every
    Git hosting service and in some cases will require either setting it up or switching
    to a different Git provider.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LakeFS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most big data storage solutions such as Azure, Google cloud storage, and Amazon
    S3 have good performance, are cost-effective, and have good connectivity with
    other tooling. However, these tools have functional gaps for more advanced data
    workflows.
  prefs: []
  type: TYPE_NORMAL
- en: Lake File System ([LakeFS](https://lakefs.io/) for short) is an open-source
    version control tool, launched in 2020, to bridge the gap between version control
    and those big data solutions (data lakes).
  prefs: []
  type: TYPE_NORMAL
- en: '**Strengths**'
  prefs: []
  type: TYPE_NORMAL
- en: It works with all data formats without requiring any changes from the user side.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is a multi-user data management system with a secure environment for data
    ingestion and experimentation for all complexity levels of machine learning pipelines.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It provides both UI and CLI interfaces and is also compatible with all major
    cloud platforms and storage types.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Weakness**'
  prefs: []
  type: TYPE_NORMAL
- en: LakeFS is heavily based on the use of object storage and doesn‚Äôt provide much
    value for other use cases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LakeFS is only used for data versioning which is one of the many parts of the
    whole data science lifecycle. This means that the integration of external tools
    is required when dealing with other steps of the data science or machine learning
    pipeline.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neptune
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Neptune](https://neptune.ai/) is a platform for tracking and registering ML
    experiments and models. It can be considered as a consolidated tool for Machine
    Learning engineers to store in a single location the models'' artifacts, metrics,
    hyper-parameters, and any metadata from their MLOps process.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Strengths**'
  prefs: []
  type: TYPE_NORMAL
- en: Intuitive collaborative interface including the capability for tracking, comparing,
    and organizing experiments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrates with more than 25 MLOps libraries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide users with both on-premise and hosted versions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Weakness**'
  prefs: []
  type: TYPE_NORMAL
- en: Not completely open-source. Also, a single subscription likely suffices for
    personal use, however, it is subject to monthly usage restrictions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The user is responsible for manually maintaining the synchronization between
    the offline and online versions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pachyderm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Pachyderm](https://www.pachyderm.com/) is considered to be the data layer
    that powers the machine learning lifecycle by bringing petabyte-scale data versioning
    and lineage tracking as well as fully auto-scaling and data-driven pipelines.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Strengths**'
  prefs: []
  type: TYPE_NORMAL
- en: Full supports both structured and unstructured data and any complex domain-specific
    data types.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It provides both community and enterprise editions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container-based, and optimized for deployment on major cloud providers and also
    on-premise.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It has a built-in mechanism for tracking data versions and preserving data integrity
    over time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Weakness**'
  prefs: []
  type: TYPE_NORMAL
- en: The community edition has a limited number of 16 pipelines.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Incorporating Pachyderm into existing infrastructure can be challenging due
    to the large number of technology components it includes. This can also make the
    learning process challenging.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Delta Lake
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Delta Lake](https://delta.io/), by Databricks, is an open-source data lake
    storage layer that runs on top of existing data lake file systems such as Hadoop
    Distributed File System (HDFS) and Amazon S3\. It provides ACID transactions,
    scalable metadata management, and schema enforcement to data lakes. Delta Lake
    supports batch and streaming data processing and allows multiple concurrent readers
    and writers.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Strengths**'
  prefs: []
  type: TYPE_NORMAL
- en: Delta Lake provides transactional guarantees for data lake operations, which
    ensures that data operations are atomic, consistent, isolated, and durable (ACID).
    This makes Delta Lake more reliable and robust for data lake applications, especially
    for those that require high data integrity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It also provides schema enforcement, which ensures that all data in the data
    lake is well-structured and follows a predefined schema. This helps to prevent
    data inconsistencies, errors, and issues arising from malformed data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The compatibility with Apache Spark APIs facilitates its integration with existing
    big data processing workflows.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automation of the tracking and management of different data versions reduces
    the risk of information loss or any inconsistencies in the data over time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Weakness**'
  prefs: []
  type: TYPE_NORMAL
- en: While Delta Lake provides a lot of powerful features, it also introduces additional
    complexity to the data lake architecture.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It has a limited data format (Parquet), which is not suitable for other popular
    data formats such as CSV, Avro, JSON, etc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning Delta Lake is not straightforward and requires a better understanding
    of distributed systems and big data architecture to efficiently manage large datasets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We covered the best 8 data version management tools, revealing a diverse range
    of strengths and weaknesses for each one. While some tools are more intuitive
    and excel in speed and simplicity, others offer more advanced features and greater
    scalability.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d29f1d23d2bd3871fea8a478e248886c.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary Table (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: When making a choice, I recommend carefully considering the specific requirements
    of your project and to evaluate the benefits and drawbacks of each option. The
    right choice will depend not only on the unique needs and constraints of your
    organization but also on your objectives.
  prefs: []
  type: TYPE_NORMAL
- en: Before you leave üîô
  prefs: []
  type: TYPE_NORMAL
- en: '**Please subscribe to my** [**YouTube channel**](https://www.youtube.com/channel/UC9xKdy8cz6ZuJU5FTNtM_pQ)
    **and Share with Your Friends!**'
  prefs: []
  type: TYPE_NORMAL
- en: Thank you for reading! If you like my stories and wish to support my writing,
    consider [becoming a Medium member](https://zoumanakeita.medium.com/membership).
    With a $ 5-a-month commitment, you unlock unlimited access to stories on Medium.
  prefs: []
  type: TYPE_NORMAL
- en: Would you like to buy me a coffee ‚òïÔ∏è? ‚Üí [Here you go](http://www.buymeacoffee.com/zoumanakeig)!
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to follow me on [Medium](https://zoumanakeita.medium.com/), or [Twitter](https://twitter.com/zoumana_keita_)
    or say Hi on [LinkedIn](https://www.linkedin.com/in/zoumana-keita/). It is always
    a pleasure to discuss AI, ML, Data Science, NLP, and MLOps stuff!
  prefs: []
  type: TYPE_NORMAL
