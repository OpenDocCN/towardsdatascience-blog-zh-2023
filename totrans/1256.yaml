- en: How to Transform Time Series for Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-transform-time-series-for-deep-learning-3b6abbbb3726](https://towardsdatascience.com/how-to-transform-time-series-for-deep-learning-3b6abbbb3726)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Forecasting with deep neural networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://vcerq.medium.com/?source=post_page-----3b6abbbb3726--------------------------------)[![Vitor
    Cerqueira](../Images/9e52f462c6bc20453d3ea273eb52114b.png)](https://vcerq.medium.com/?source=post_page-----3b6abbbb3726--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3b6abbbb3726--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3b6abbbb3726--------------------------------)
    [Vitor Cerqueira](https://vcerq.medium.com/?source=post_page-----3b6abbbb3726--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3b6abbbb3726--------------------------------)
    ·6 min read·Feb 14, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cb6f0d0867764cc51c75e7ccba5d5b7c.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Claudio Testa](https://unsplash.com/@claudiotesta?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Supervised Learning with Time Series
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Supervised learning involves training a machine learning model with an input
    data set. This data set is usually a matrix: A two-dimensional data structure
    composed of rows (samples) and columns (features).'
  prefs: []
  type: TYPE_NORMAL
- en: A time series is a sequence of values ordered in time. So, it needs to be transformed
    for supervised learning.
  prefs: []
  type: TYPE_NORMAL
- en: In [a previous article](https://medium.com/towards-data-science/machine-learning-for-forecasting-transformations-and-feature-extraction-bbbea9de0ac2),
    we learned how to transform a univariate time series from a sequence into a matrix.
    This is done with a sliding window. Each observation of the series is modeled
    based on past recent values, also called lags.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of this transformation using the sequence from 1 to 10:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5bdcdeebe48202190f0e4b8af9c5ca1c.png)'
  prefs: []
  type: TYPE_IMG
- en: Transforming a sequence into a matrix with a sliding window. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: This transformation enables a type of modeling called auto-regression. In auto-regression,
    a model is built using the past recent values (lags) of a time series as explanatory
    variables. These are used to predict future observations (target variable). The
    intuition for the name auto-regression is that the time series is regressed with
    itself.
  prefs: []
  type: TYPE_NORMAL
- en: In the example above, the lags are the initial 5 columns. The target variable
    is the last column (the value of the series in the next time step).
  prefs: []
  type: TYPE_NORMAL
- en: Auto-Regression with Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While most methods work with matrices, deep neural networks need a different
    structure.
  prefs: []
  type: TYPE_NORMAL
- en: The input to deep neural networks such as LSTMs or CNNs is a three-dimensional
    array. The actual data is the same as the one you’d put in a matrix. But, it’s
    structured differently.
  prefs: []
  type: TYPE_NORMAL
- en: Besides rows (samples) and columns (lags), the extra dimension refers to the
    number of variables in the series. In a matrix, you concatenate all attributes
    together irrespective of their source. Neural networks are a bit tidier. The input
    is organized by each variable in the series using a third dimension.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s do a practical example to make this clear.
  prefs: []
  type: TYPE_NORMAL
- en: Hands-On
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/7d9ea87d4f7c58f7da50b8396ab02b04.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Quino Al](https://unsplash.com/@quinoal?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: In this tutorial, you’ll learn how to transform a time series for supervised
    learning with an LSTM (Long Short-Term Memory). An LSTM is a type of neural network
    that is especially useful to model time series.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll split the time series transformation process into two steps:'
  prefs: []
  type: TYPE_NORMAL
- en: From a sequence of values into a matrix;
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From a matrix into a 3-d array for deep learning.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: First, we’ll do an example with a univariate time series. Multivariate time
    series are covered next.
  prefs: []
  type: TYPE_NORMAL
- en: Univariate Time Series
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s start by reading the data. We’ll use a time series related to the sales
    of different kinds of wine. You can check the source in reference [1].
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We focus on the sales of sparkling wine to do an example for the univariate
    case. This time series looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c59d0cee33c882028bc6ce2a9416b536.png)'
  prefs: []
  type: TYPE_IMG
- en: From a sequence of values into a matrix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We apply a sliding window to transform this series for supervised learning.
    You can learn more about this process in [a previous article](https://medium.com/towards-data-science/machine-learning-for-forecasting-transformations-and-feature-extraction-bbbea9de0ac2).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s a sample of the explanatory variables (X) and corresponding target variables
    (Y):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b2f638777254a95acb16c6d88e19f2dc.png)'
  prefs: []
  type: TYPE_IMG
- en: Sample of the explanatory (left) and target (right) variables after transforming
    the time series into a 2-d matrix structure. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: This data set is the basis for training traditional machine learning methods.
    For example, a linear regression or an xgboost.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: From a matrix into a 3-d structure for deep learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You need to reshape this data set to train a neural network like an LSTM. The
    following function can be used to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, you can train an LSTM using the resulting data set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Multivariate Time Series
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, let’s look at a multivariate time series example. In this case, the goal
    is to forecast the future values of several variables, not just one. So, you need
    a model for multivariate and multi-step forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b4b7d136f8ef0ed3711f6fb2a1e85ec1.png)'
  prefs: []
  type: TYPE_IMG
- en: Multivariate time series about the sales of different types of wine. Image by
    author.
  prefs: []
  type: TYPE_NORMAL
- en: The transformation process is like before.
  prefs: []
  type: TYPE_NORMAL
- en: To transform the multivariate time series into a matrix format, you can apply
    the sliding window approach to each variable. Then, you combine all resulting
    matrices into a single one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The explanatory variables look like this for two of the variables (others are
    omitted for conciseness):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3c8f8166d6ed5d300fdca58782bfd38a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can use the same function to transform the data into three dimensions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The training part is also like before. The information about the number of variables
    in the series is provided in the *N_FEATURES* constant. As the name implied, this
    constant is the number of variables in the time series.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The following plot shows a sample of one-step ahead forecasts.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c6568e382eb01fb7687d38aa466cbabb.png)'
  prefs: []
  type: TYPE_IMG
- en: One step ahead forecasts by an LSTM. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: The forecasts are not that good. The time series is small and we didn’t optimize
    the model in any way. Deep learning methods are known to be data-hungry. So, if
    you go for this kind of approach, make sure you have enough data.
  prefs: []
  type: TYPE_NORMAL
- en: Key Takeaways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep learning is increasingly relevant in time series applications.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we explored how to transform a time series for deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: The input to traditional machine learning algorithms is a matrix. But, neural
    networks such as LSTMs work with three-dimensional data sets. So, time series
    need to be transformed from a sequence into this format.
  prefs: []
  type: TYPE_NORMAL
- en: The transformation is based on a sliding window that is applied to each variable
    in the series.
  prefs: []
  type: TYPE_NORMAL
- en: Thank you for reading, and see you in the next story!
  prefs: []
  type: TYPE_NORMAL
- en: Related Articles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Machine Learning for Forecasting: Transformations and Feature Extraction](/machine-learning-for-forecasting-transformations-and-feature-extraction-bbbea9de0ac2)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning for Forecasting: Supervised Learning with Multivariate Time
    Series](/machine-learning-for-forecasting-supervised-learning-with-multivariate-time-series-b5b5044fe068)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] [Rob Hyndman and Yangzhuoran Yang (2018). tsdl: Time Series Data Library.
    v0.1.0.](https://pkg.yangzhuoranyang.com/tsdl/) (GPL-3 Licence)'
  prefs: []
  type: TYPE_NORMAL
