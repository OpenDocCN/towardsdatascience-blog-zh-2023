- en: 'Classification in Machine Learning: An Introduction'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/classification-in-machine-learning-an-introduction-d52595e3dcab](https://towardsdatascience.com/classification-in-machine-learning-an-introduction-d52595e3dcab)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learn about classification in machine learning, looking at what it is, how it’s
    used, and some examples of classification algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://zoumanakeita.medium.com/?source=post_page-----d52595e3dcab--------------------------------)[![Zoumana
    Keita](../Images/34a15c1d03687816dbdbc065f5719f80.png)](https://zoumanakeita.medium.com/?source=post_page-----d52595e3dcab--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d52595e3dcab--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d52595e3dcab--------------------------------)
    [Zoumana Keita](https://zoumanakeita.medium.com/?source=post_page-----d52595e3dcab--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d52595e3dcab--------------------------------)
    ·11 min read·Feb 24, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c16208ec7dde75291c85a0ea05165cfa.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Markus Winkler](https://unsplash.com/@markuswinkler) on [Unsplash](https://unsplash.com/photos/f57lx37DCM4)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Nowadays, many industries have been dealing with very large data sets of different
    types. Manually processing all that information can be time-consuming and might
    not even add value in the long term. Many strategies, from simple automation to
    machine learning techniques, are being applied for a better return on investment.
    This conceptual blog will cover one of the most important concepts; classification
    in machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: We will start by defining what classification is in Machine Learning before
    clarifying the two types of learners in machine learning and the difference between
    classification and regression. Then, we will cover some real-world scenarios where
    classification can be used. After that, we will introduce all the different types
    of classification and deep dive into some examples of classification algorithms.
    Finally, we will provide hands-on practice on the implementation of a few algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: What is Classification in Machine Learning?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Classification is a supervised machine learning method where the model tries
    to predict the correct label of a given input data. In classification, the model
    is fully trained using the training data, and then it is evaluated on test data
    before being used to perform prediction on new unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, an algorithm can learn to predict whether a given email is spam
    or ham (no spam), as illustrated below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7052ba378c7190dcc8504672a320457e.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'Before diving into the classification concept, we will first understand the
    difference between the two types of learners in classification: lazy and eager
    learners. Then we will clarify the misconception between classification and regression.'
  prefs: []
  type: TYPE_NORMAL
- en: Lazy Learners Vs. Eager Learners
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two types of learners in machine learning classification: lazy and
    eager learners.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Eager learners** are machine learning algorithms that first build a model
    from the training dataset before making any prediction on future datasets. They
    spend more time during the training process because of their eagerness to have
    a better generalization during the training from learning the weights, but they
    require less time to make predictions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Most machine learning algorithms are eager learners, and below are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: Logistic Regression.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support Vector Machine.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decision Trees.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Artificial Neural Networks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lazy learners or instance-based learners**, on the other hand, do not create
    any model immediately from the training data, and this is where the lazy aspect
    comes from. They just memorize the training data, and each time there is a need
    to make a prediction, they search for the nearest neighbor from the whole training
    data, which makes them very slow during prediction. Some examples of this kind
    are:'
  prefs: []
  type: TYPE_NORMAL
- en: K-Nearest Neighbor.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Case-based reasoning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, some algorithms, such as [**BallTrees**](https://en.wikipedia.org/wiki/Ball_tree)
    and [**KDTrees**](https://en.wikipedia.org/wiki/K-d_tree), can be used to improve
    the prediction latency.
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning Classification Vs. Regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are four main categories of Machine Learning algorithms: supervised,
    unsupervised, semi-supervised, and reinforcement learning.'
  prefs: []
  type: TYPE_NORMAL
- en: Even though classification and regression are both from the category of supervised
    learning, they are not the same.
  prefs: []
  type: TYPE_NORMAL
- en: The prediction task is a ***classification*** when the target variable is discrete.
    An application is the identification of the underlying sentiment of a piece of
    text.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The prediction task is a ***regression*** when the target variable is continuous.
    An example can be the prediction of the salary of a person given their education
    degree, previous work experience, geographical location, and level of seniority.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/fa813e34177265594d429d77c84945f3.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Examples of Machine Learning Classification in Real Life
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Supervised Machine Learning Classification has different applications in multiple
    domains of our day-to-day life. Below are some examples.
  prefs: []
  type: TYPE_NORMAL
- en: Healthcare
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Training a machine learning model on historical patient data can help healthcare
    specialists accurately analyze their diagnoses:'
  prefs: []
  type: TYPE_NORMAL
- en: During the COVID-19 pandemic, machine learning models were implemented to efficiently
    predict whether a person had COVID-19 or not.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Researchers can use machine learning models to predict new diseases that are
    more likely to emerge in the future.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Education
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Education is one of the domains dealing with the most textual, video, and audio
    data. This unstructured information can be analyzed with the help of Natural Language
    technologies to perform different tasks such as:'
  prefs: []
  type: TYPE_NORMAL
- en: The classification of documents per category.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatic identification of the underlying language of students’ documents during
    their application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analysis of students’ feedback sentiments about a Professor.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transportation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Transportation is the key component of many countries’ economic development.
    As a result, industries are using machine and deep learning models:'
  prefs: []
  type: TYPE_NORMAL
- en: To predict which geographical location will have a rise in traffic volume.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predict potential issues that may occur in specific locations due to weather
    conditions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sustainable agriculture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Agriculture is one of the most valuable pillars of human survival. Introducing
    sustainability can help improve farmers’ productivity at a different level without
    damaging the environment:'
  prefs: []
  type: TYPE_NORMAL
- en: By using classification models to predict which type of land is suitable for
    a given type of seed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predict the weather to help them take proper preventive measures.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different Types of Classification Tasks in Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are four main classification tasks in Machine learning: binary, multi-class,
    multi-label, and imbalanced classifications.'
  prefs: []
  type: TYPE_NORMAL
- en: Binary Classification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In a binary classification task, the goal is to classify the input data into
    two mutually exclusive categories. The training data in such a situation is labeled
    in a binary format: true and false; positive and negative; O and 1; spam and not
    spam, etc. depending on the problem being tackled. For instance, we might want
    to detect whether a given image is a truck or a boat.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/83efb0f883ee1642bddfb23f98673cc5.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Logistic Regression and Support Vector Machines algorithms are natively designed
    for binary classifications. However, other algorithms such as K-Nearest Neighbors
    and Decision Trees can also be used for binary classification.
  prefs: []
  type: TYPE_NORMAL
- en: Multi-Class Classification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The multi-class classification, on the other hand, has at least two mutually
    exclusive class labels, where the goal is to predict to which class a given input
    example belongs to. In the following case, the model correctly classified the
    image to be a plane.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1f785d1f4fc4ed74eaba126d427d9dd1.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'Most of the binary classification algorithms can be also used for multi-class
    classification. These algorithms include but are not limited to:'
  prefs: []
  type: TYPE_NORMAL
- en: Random Forest
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Naive Bayes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: K-Nearest Neighbors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gradient Boosting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SVM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logistic Regression.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: But wait! Didn’t you say that SVM and Logistic Regression do not support multi-class
    classification by default?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: → That’s correct. However, we can apply binary transformation approaches such
    as one-versus-one and one-versus-all to adapt native binary classification algorithms
    for multi-class classification tasks.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**One-versus-one**: this strategy trains as many classifiers as there are pairs
    of labels. If we have a 3-class classification, we will have three pairs of labels,
    thus three classifiers, as shown below.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/04fa1039ab0b254245d2739c71198d55.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: In general, for N labels, we will have Nx(N-1)/2 classifiers. Each classifier
    is trained on a single binary dataset, and the final class is predicted by a majority
    vote between all the classifiers. The one-vs-one approach works best for SVM and
    other kernel-based algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: '**One-versus-rest**: at this stage, we start by considering each label as an
    independent label and consider the rest combined as only one label. With 3-classes,
    we will have three classifiers.'
  prefs: []
  type: TYPE_NORMAL
- en: In general, for N labels, we will have **N** binary classifiers.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cf635a5576a70945c1042981cb82607f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Multi-Label Classification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In multi-label classification tasks, we try to predict 0 or more classes for
    each input example. In this case, there is no mutual exclusion because the input
    example can have more than one label.
  prefs: []
  type: TYPE_NORMAL
- en: 'Such a scenario can be observed in different domains, such as auto-tagging
    in Natural Language Processing, where a given text can contain multiple topics.
    Similarly to computer vision, an image can contain multiple objects, as illustrated
    below: the model predicted that the image contains: a plane, a boat, a truck,
    and a dog.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ffad990a4671ee21f23ce243c2115958.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'It is not possible to use multi-class or binary classification models to perform
    multi-label classification. However, most algorithms used for those standard classification
    tasks have their specialized versions for multi-label classification. We can cite:'
  prefs: []
  type: TYPE_NORMAL
- en: Multi-label Decision Trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-label Gradient Boosting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-label Random Forests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Imbalanced Classification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For the imbalanced classification, the number of examples is unevenly distributed
    in each class, meaning that we can have more of one class than the others in the
    training data. Let’s consider the following 3-class classification scenario where
    the training data contains: 60% of trucks, 25% of planes, and 15% of boats.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5471ae78f92a683de9ac5828cd8edb89.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'The imbalanced classification problem could occur in the following scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: Fraudulent transaction detections in financial industries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rare disease diagnosis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer churn analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using conventional predictive models such as Decision Trees, Logistic Regression,
    etc. could not be effective when dealing with an imbalanced dataset, because they
    might be biased toward predicting the class with the highest number of observations,
    and considering those with fewer numbers as noise.
  prefs: []
  type: TYPE_NORMAL
- en: So, does that mean that such problems are left behind?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Of course not! We can use multiple approaches to tackle the imbalance problem
    in a dataset. The most commonly used approaches include sampling techniques or
    harnessing the power of cost-sensitive algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: '**Sampling Techniques**'
  prefs: []
  type: TYPE_NORMAL
- en: 'These techniques aim to balance the distribution of the original by:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Cluster-based Oversampling:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Random undersampling: random elimination of examples from the majority class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'SMOTE Oversampling: random replication of examples from the minority class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cost-Sensitive Algorithms**'
  prefs: []
  type: TYPE_NORMAL
- en: These algorithms take into consideration the cost of misclassification. They
    aim to minimize the total cost generated by the models.
  prefs: []
  type: TYPE_NORMAL
- en: Cost-sensitive Decision Trees.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cost-sensitive Logistic Regression.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cost-sensitive Support Vector Machines.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep Dive into Classification Algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We now have all the tools in hand to proceed with the implementation of some
    algorithms. This section will cover four algorithms and their implementation on
    the[**loans dataset**](https://www.kaggle.com/datasets/itssuru/loan-data) (freely
    available on Kaggle) to illustrate some of the previously covered concepts, especially
    for the imbalanced datasets using a binary classification task. We will focus
    on only four algorithms for simplicity’s sake.
  prefs: []
  type: TYPE_NORMAL
- en: Distribution of Loans in the Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Look at the first five observations in the dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/3be6b190519c01d11183678b473af40d.png)'
  prefs: []
  type: TYPE_IMG
- en: Borrowers profile in the dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/a99a34c534b45165886daca309c407f5.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: From the graphic above, we notice that 84% of the borrowers paid their loans
    back, and only 16% didn’t pay them back, which makes the dataset really imbalanced.
  prefs: []
  type: TYPE_NORMAL
- en: Variable Types
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before further, we need to check the variables’ type so that we can encode those
    that need to be encoded.
  prefs: []
  type: TYPE_NORMAL
- en: We notice that all the columns are continuous variables, except the **purpose**
    attribute, which needs to be encoded.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e51a3f4288a8ec41557ef894dd83ad23.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/7ba6b29bd3388afacca601a7d55793e3.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Separate data into train and test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Application of the Sampling Strategies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will explore two sampling strategies here: random undersampling, and SMOTE
    oversampling.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Random Undersampling**'
  prefs: []
  type: TYPE_NORMAL
- en: We will undersample the majority class, which corresponds to the “fully paid”
    (class 0).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b2f196317907e9b59368145997a7dc3b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: '**SMOTE Oversampling**'
  prefs: []
  type: TYPE_NORMAL
- en: Perform oversampling on the minority class
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b2f196317907e9b59368145997a7dc3b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: After applying the sampling strategies, we observe that the dataset is equally
    distributed across the different types of borrowers.
  prefs: []
  type: TYPE_NORMAL
- en: Application of Some Machine Learning Classification Algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section will apply these two classification algorithms to the SMOTE smote
    sampled dataset. The same training approach can be applied to undersampled data
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: '**Logistic Regression**'
  prefs: []
  type: TYPE_NORMAL
- en: This is an explainable algorithm. It classifies a data point by modeling its
    probability of belonging to a given class using the sigmoid function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/e125211965c27076b2b859f2c06c633e.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: '**Support Vector Machines**'
  prefs: []
  type: TYPE_NORMAL
- en: This algorithm can be used for both classification and regression. It learns
    to draw the hyperplane (decision boundary) by using the margin to maximization
    principle. This decision boundary is drawn through the two closest support vectors.
  prefs: []
  type: TYPE_NORMAL
- en: SVM provides a transformation strategy called kernel tricks used to project
    non-learner separable data onto a higher dimension space to make them linearly
    separable.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/4f01cc63b93fd247e953fcb8ec3dcf83.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: These results can be of course improved with more feature engineering and fine-tuning.
    But they are better than using the original imbalanced data.
  prefs: []
  type: TYPE_NORMAL
- en: This algorithm is an extension of a well-known algorithm called gradient-boosted
    trees. It is a great candidate not only for combating overfitting but also for
    speed and performance.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This article covered the main aspect of classifications in Machine learning
    and also provided you with some examples of different domains they are applied
    to. Finally, it covered the implementation of Logistic Regression and Support
    Vector Machine after performing the undersampling and SMOTE oversampling strategies
    to generate a balanced dataset for the models’ training.
  prefs: []
  type: TYPE_NORMAL
- en: You can fork the [notebook from my GitHub](https://github.com/keitazoumana/Medium-Articles-Notebooks/blob/main/Introduction_to_classification.ipynb).
  prefs: []
  type: TYPE_NORMAL
- en: Also, If you like reading my stories and wish to support my writing, consider
    [becoming a Medium member](https://zoumanakeita.medium.com/membership). With a
    $ 5-a-month commitment, you unlock unlimited access to stories on Medium.
  prefs: []
  type: TYPE_NORMAL
- en: Would you like to buy me a coffee ☕️? → [Here you go](http://www.buymeacoffee.com/zoumanakeig)!
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to follow me on [Medium](https://zoumanakeita.medium.com/), [Twitter](https://twitter.com/zoumana_keita_),
    and [YouTube](https://www.youtube.com/channel/UC9xKdy8cz6ZuJU5FTNtM_pQ), or say
    Hi on [LinkedIn](https://www.linkedin.com/in/zoumana-keita/). It is always a pleasure
    to discuss AI, ML, Data Science, NLP, and MLOps stuff!
  prefs: []
  type: TYPE_NORMAL
- en: 'Before you leave find below some articles that might be helpful :'
  prefs: []
  type: TYPE_NORMAL
- en: '[Pandas & Python Tricks for Data Science & Data Analysis — Part 1](https://medium.com/towards-data-science/pandas-and-python-tips-and-tricks-for-data-science-and-data-analysis-1b1e05b7d93a)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Pandas & Python Tricks for Data Science & Data Analysis — Part 2](https://medium.com/towards-data-science/pandas-python-tricks-for-data-science-data-analysis-part-2-dc36460de90d)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Pandas & Python Tricks for Data Science & Data Analysis — Part 3](/pandas-python-tricks-for-data-science-data-analysis-part-3-462d0e952925)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Fundamentals of Statistics All Data Scientists & Analysts Should Know — With
    Code — Part 1](/fundamentals-of-statistics-all-data-scientists-analysts-should-know-with-code-part-1-d6ac0f4b99b5)'
  prefs: []
  type: TYPE_NORMAL
