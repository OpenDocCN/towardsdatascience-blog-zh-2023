- en: 'EDA with Polars: Step-by-Step Guide for Pandas Users (Part 1)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/eda-with-polars-step-by-step-guide-for-pandas-users-part-1-b2ec500a1008](https://towardsdatascience.com/eda-with-polars-step-by-step-guide-for-pandas-users-part-1-b2ec500a1008)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Level up your data analysis with Polars
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@antonsruberts?source=post_page-----b2ec500a1008--------------------------------)[![Antons
    Tocilins-Ruberts](../Images/363a4f32aa793cca7a67dea68e76e3cf.png)](https://medium.com/@antonsruberts?source=post_page-----b2ec500a1008--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b2ec500a1008--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b2ec500a1008--------------------------------)
    [Antons Tocilins-Ruberts](https://medium.com/@antonsruberts?source=post_page-----b2ec500a1008--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b2ec500a1008--------------------------------)
    ·12 min read·Jul 6, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1ec62693f9e625f8eb7847708504fcaa.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Mitul Grover](https://unsplash.com/@mitulgrover?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every once in a while, along comes a tool that significantly alters the way
    that data analysis is done. I believe that Polars is one of those tools, so in
    this series of posts, I’ll deep dive into this library, compare it to a more well
    known and established library — Pandas, and will showcase the analysis workflow
    using an example dataset.
  prefs: []
  type: TYPE_NORMAL
- en: What is Polars?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Polars is a blazingly fast DataFrame library written in Rust. Lucky for us
    (data scientists/analysts) it has a very well documented Python wrapper that exposes
    a complete set of features to wrangle data and build data pipelines. Here are
    the main advantages I’ve seen after switching to Polars:'
  prefs: []
  type: TYPE_NORMAL
- en: Much faster pre-processing operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ability to handle larger than RAM datasets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Better quality of code due to the need to properly structure data pipelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can see the full set of benefits in this [user guide](https://pola-rs.github.io/polars-book/user-guide/#philosophy)
    and the speed comparisons in this H20 [benchmark](https://h2oai.github.io/db-benchmark/).
  prefs: []
  type: TYPE_NORMAL
- en: Switching from Pandas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the first glance, Pandas and Polars seem to be quite similar e.g. methods
    like `.read_csv()` or `.head()` are shared between them so you can perform basic
    exploratory operations without any changes. But the more you start working the
    library, the more you’ll notice how different the two libraries are. From syntaxis
    to the way of thinking, switching to Polars is no easy task. That’s why I hope
    that these posts will help you get started.
  prefs: []
  type: TYPE_NORMAL
- en: Setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To follow along the project, make sure to pull this [GitHub repo](https://github.com/aruberts/tutorials/blob/main/polars/basics.ipynb)
    with the latest notebook. Data used in this project can be downloaded from [Kaggle](https://www.kaggle.com/datasets/datasnaek/youtube-new?resource=download&sort=published)
    (CC0: Public Domain). It’s a dataset about YouTube’s top trending videos and should
    provide enough complexity for this series of posts. Also, you’ll need Pandas and
    Polars to be installed which can be done using pip for both packages.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that everything is setup, let’s jump into the project! The main goal here
    is to get you more familiar with Polars, so make sure to follow along or practice
    the concepts on your own dataset. Once again, in the [GitHub repo](https://github.com/aruberts/tutorials/blob/main/polars/basics.ipynb)
    you can find the notebook with all the code used here.
  prefs: []
  type: TYPE_NORMAL
- en: Data Processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reading Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Reading data is going to be familiar to Pandas users since it uses exactly the
    same methods. Let’s read in the statistics for United Kingdom videos for the further
    analysis and print out the DataFrame shapes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: If you time both of these read in operations, you’ll have your first “wow” moment
    with Polars. On my laptop, Polars reads in the file in ~110 ms and Pandas reads
    it in ~ 270 ms. That’s 2.5x speedup, but you’ll frequently see reading/writing
    operation speed ups much more than this (especially with larger files).
  prefs: []
  type: TYPE_NORMAL
- en: Common Exploratory Methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What’s the first thing you do when you read in the data? I assume you print
    out a head (or sample), check the data types, shapes, etc. Polars shares a lot
    of these high-level methods with Pandas, so you can explore the first rows using
    `.head()` method, and the last rows using `.tail()` method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/ee17eb91e56a42cc5a89d49a24fb24ce.png)'
  prefs: []
  type: TYPE_IMG
- en: First two rows. Screenshot by author.
  prefs: []
  type: TYPE_NORMAL
- en: While you’ll be able to see the outputs, it’s formatting is not ideal. You can
    change how the outputs get displayed using the `Config` . For example, to make
    the printouts wider you can set the maximum number of characters per row to 200
    like so `pl.Config.set_tbl_width_chars(200)` . Then the output is going to look
    more pleasant.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a82fd24d1e2f072e1b28e9a498f0399b.png)'
  prefs: []
  type: TYPE_IMG
- en: Wide format. Screenshot by author.
  prefs: []
  type: TYPE_NORMAL
- en: There are a lot of other parameters you can adjust (e.g. hide column data types),
    so make sure to checkout the [Config documentation](https://pola-rs.github.io/polars/py-polars/html/reference/config.html).
  prefs: []
  type: TYPE_NORMAL
- en: Selecting Columns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By Data Types
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You might have seen from the printout that Polars has a bit different set of
    data types for its columns. Numeric columns are usually assigned types of `Int32`
    , `Int64` , `Float32` , `Float64` and categorical columns are usually assigned
    types of `Utf8` . To select columns by data type, the so-called `selectors` can
    be used together with the `.select()` method. These `selectors` are a relatively
    new addition to the API and they give us more intuitive way of selecting columns.
    For example, below you can see the code to select all the numeric and all the
    categorical columns.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/2b867381551357ccc49403733ba679e2.png)![](../Images/4b552e6e511515acc04b5ddf2c85b13e.png)'
  prefs: []
  type: TYPE_IMG
- en: Numerical and Categorical Features. Screenshot by author.
  prefs: []
  type: TYPE_NORMAL
- en: By Column Name
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you want to select a column by name, you can use the same `.select()` method
    but now you’ll need to provide a column’s name wrapped into `pl.col()` . To select
    multiple columns, just provide the names in a list, very similar to Pandas
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: It should be noted that `df_pl[["likes", "views", "comment_count"]]` will also
    work due to syntactic sugar implemented by Polars. Still, it’s a good practice
    to write the full statements, so I recommend you get some practice writing it
    both ways.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting Rows
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To select specific rows you’ll need to use `.filter()` method. Notice that Polars
    doesn’t have index which means that commands like `.iloc` are not available. Let’s
    find out how many rows in the dataset have less than 1000 views. This should be
    very small because it’s highly unlikely that an unpopular video gets into Trending
    tab.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Data Quality Checks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For a more complicated use case, let’s perform basic data quality checks. When
    doing a data quality check, it’s always a good idea to check for the number of
    missing rows per column and the number of static columns. In Pandas, this can
    be done very simply using in-built checks and aggregations.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: With Polars this part is a bit more involved and requires chaining a few methods.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Let’s break down the code to calculate number of missing rows.
  prefs: []
  type: TYPE_NORMAL
- en: '`df_pl.select(pl.all())` repeats the specified operation for all columns'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.is_null().sum()` sums up the number of Null values (Polars representation
    of NA)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.melt()` transforms wide DataFrame into long format'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.filter(pl.col("missing") > 0)` filters out the columns where no rows are
    missing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can see that chaining these operations is quite easy and the flow is quite
    similar to PySpark. Even though the code is a bit more involved, the execution
    speed is ~4x faster in Polars.
  prefs: []
  type: TYPE_NORMAL
- en: What is surprising is that the results of data quality checks don’t match up.
    With Pandas, there are 612 missing rows in `description` column, whereas with
    Polars we don’t see this. This is because Polars treats missing strings as empty
    strings `""` , so they don’t appear in the null counts. You can easily replace
    these strings with Null values if you wish using `.replace()` method.
  prefs: []
  type: TYPE_NORMAL
- en: Data Pre-Processing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two steps that need to be done to prepare the data:'
  prefs: []
  type: TYPE_NORMAL
- en: Convert date columns into `datetime` format
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replace category IDs with the actual category names
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To do this, we’ll need to use `.with_columns()` method because it returns the
    entire DataFrame with altered columns. `.select()` method in this case wouldn’t
    work, because it would only return the processed columns. In addition, we’ll need
    to use the `.str` namespace which is very similar to Pandas. This namespace has
    all the operations available for strings, e.g. `.str.contains()` or `.str.to_lowercase()`
    (see all [here](https://pola-rs.github.io/polars/py-polars/html/reference/expressions/string.html)).
    If you’re interest in working with strings in Polars, checkout this [post](https://medium.com/me/stats/post/fcf7054a929a)
    after finishing with this one.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: To replace a category, we’ll simply apply the `.map_dict()` method which is
    similar to `.map()` in Pandas. In Polars, `.map()` only works with functions,
    so keep this in mind.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Now that the data is ready, let’s finally do some analysis!
  prefs: []
  type: TYPE_NORMAL
- en: Basic Exploratory Data Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will cover the some of the most important techniques when doing
    EDA, namely univariate data analysis, aggregates, and visualisations.
  prefs: []
  type: TYPE_NORMAL
- en: Univariate Data Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Univariate data analysis is the simplest analysis you can do yet it’s crucial.
    Looking at one variable at a time, it can give you a better sense of data and
    can guide your further explorations.
  prefs: []
  type: TYPE_NORMAL
- en: Categorical Columns
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since we’ve mapped the category IDs to their actual names in data pre-processing
    section, let’s see their distribution using `.value_counts()` .
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The `value_counts()` operation is also present in Polars, just don’t forget
    to set `sort=True` if you want the same behaviour as in Pandas. Next, we can use
    this information to create a basic bar plot. Plotting with Polars is relatively
    simple, although there’s no in-built plotting methods so far like with Pandas.
    Some plotting libraries don’t take Polars Series as inputs, but lucky for us it’s
    quite easy to convert the Series to a commonly acceptable formats — Python lists,
    NumPy arrays and Pandas Series.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/51e023bbe43f9df121990a088376f8ac.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Looks like Music is by far the most frequent category in YouTube trends followed
    by Entertainment which is not surprising. On the other hand, people doing content
    for Shows, Non-Profit, Travel, and Autos & Vehicles will have a much harder time
    getting into Trending.
  prefs: []
  type: TYPE_NORMAL
- en: Numerical Columns
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Numerical features univariate analysis can be performed using `.describe()`
    method which behaves very similar to Pandas. Also, we can plot a histogram of
    log views. Log transformation is done to handle heavy outliers like the video
    with a 424 million views. Interestingly, the minimum number of views a video in
    trending has is just 851.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/14f4049400f866322afdb7dac420d298.png)![](../Images/0002d2dce0ea79fed6e6e0a756cf0493.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot and image by author.
  prefs: []
  type: TYPE_NORMAL
- en: There are many more columns to explore, so I’d recommend you go explore them
    on your own since you have the tools now. After you’re done, let’s move to more
    complicated forms of analysis
  prefs: []
  type: TYPE_NORMAL
- en: Multivariate Data Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First things first, which channels appear most frequently in the trending page?
    We can again use `.value_counts()` but let’s use the `.groupby().agg()` method
    instead since it’s much more flexible and will be useful going forward. I’m going
    to group by the *channel title* and count the number of rows using `.count()`
    method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Similar to Pandas, inside of `.groupby()` you need to specify the name of the
    column that you want to create aggregates for. Notice that for Polars, you need
    to wrap the column name with `pl.col()` however it will also work without it due
    to implemented syntactic sugar. Inside of the `.agg()` you usually need to provide
    the column name that you want to aggregate but in this case I’m using a `pl.count()`
    method since I want to count rows. Notice that you can re-name any aggregate/column
    you create using `.alias()` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a few other statistics namely:'
  prefs: []
  type: TYPE_NORMAL
- en: Number of unique trendy videos
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Total number of views, likes and comments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Average number of views likes and comments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/12f6c0e7de3d9bfe87f3a2638e522352.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Looks like everything is working as expected. The same aggregates could be implemented
    in Pandas using their `.agg()` method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The results should be the same, but the **execution time is ~10x faster** in
    Polars.
  prefs: []
  type: TYPE_NORMAL
- en: These aggregates are usually a good first step in the analysis, and they might
    be useful down the line (e.g. in the dashboard), so it would be nice to refactor
    the aggregation code into a function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Above you can see how this aggregation function could look like. Notice that
    we can store the required aggregate operations in a list before passing them into
    a Polars `.agg()` method which is quite powerful. Now, this function can be applied
    not only for the `channel_title` columns, but also e.g. for the `category_id`
    .
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/6f7e6a37ff50a5afd03a4b6dfb825c8b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: From the screenshot above you can see that the top trending channels and the
    top trending categories. These aggregates could be further put into a dashboard
    or used for further analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Writing Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Saving the DataFrames to disk is actually quite easy. All you need to do is
    to make sure that the folder you’re writing to exists. Otherwise, the process
    is very similar to Pandas, except you use `.write_parquet()` method and not `.to_parquet()`
    (I’m making this mistake at least once a day).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Good job for making it this far! Overall, you’ve seen how to do the following
    in Polars:'
  prefs: []
  type: TYPE_NORMAL
- en: Read in data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Investigate the DataFrames
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform basic data quality checks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Select required columns/rows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform basic cleaning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform basic univariate analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform basic multivariate analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Write out the DataFrames to Parquet file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is a great start, so let’s wrap up the first part of this series. Make
    sure to practice it on your own dataset because I firmly believe that the best
    way to learn is by practicing, practicing, and practicing. Thank you for reading
    and see you in the next part!
  prefs: []
  type: TYPE_NORMAL
- en: What Next?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you’ve got the basics of Polars, it’s time to move on to something more advanced.
    Part 2 of this series covers more complicated aggregates and analytical functions
    which are essential for any data professional.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/eda-with-polars-step-by-step-guide-to-aggregate-and-analytic-functions-part-2-a22d986315aa?source=post_page-----b2ec500a1008--------------------------------)
    [## EDA with Polars: Step-by-Step Guide to Aggregate and Analytic Functions (Part
    2)'
  prefs: []
  type: TYPE_NORMAL
- en: Advanced aggregates and rolling averages at lightning speed with Polars
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/eda-with-polars-step-by-step-guide-to-aggregate-and-analytic-functions-part-2-a22d986315aa?source=post_page-----b2ec500a1008--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Not a Medium Member yet?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@antonsruberts/membership?source=post_page-----b2ec500a1008--------------------------------)
    [## Join Medium with my referral link — Antons Tocilins-Ruberts'
  prefs: []
  type: TYPE_NORMAL
- en: Read every story from Antons Tocilins-Ruberts (and thousands of other writers
    on Medium). Your membership fee directly…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@antonsruberts/membership?source=post_page-----b2ec500a1008--------------------------------)
  prefs: []
  type: TYPE_NORMAL
