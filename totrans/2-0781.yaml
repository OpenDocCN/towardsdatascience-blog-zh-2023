- en: 'EDA with Polars: Step-by-Step Guide for Pandas Users (Part 1)'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Polars 进行 EDA：针对 Pandas 用户的逐步指南（第 1 部分）
- en: 原文：[https://towardsdatascience.com/eda-with-polars-step-by-step-guide-for-pandas-users-part-1-b2ec500a1008](https://towardsdatascience.com/eda-with-polars-step-by-step-guide-for-pandas-users-part-1-b2ec500a1008)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/eda-with-polars-step-by-step-guide-for-pandas-users-part-1-b2ec500a1008](https://towardsdatascience.com/eda-with-polars-step-by-step-guide-for-pandas-users-part-1-b2ec500a1008)
- en: Level up your data analysis with Polars
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用 Polars 提升你的数据分析水平
- en: '[](https://medium.com/@antonsruberts?source=post_page-----b2ec500a1008--------------------------------)[![Antons
    Tocilins-Ruberts](../Images/363a4f32aa793cca7a67dea68e76e3cf.png)](https://medium.com/@antonsruberts?source=post_page-----b2ec500a1008--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b2ec500a1008--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b2ec500a1008--------------------------------)
    [Antons Tocilins-Ruberts](https://medium.com/@antonsruberts?source=post_page-----b2ec500a1008--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@antonsruberts?source=post_page-----b2ec500a1008--------------------------------)[![Antons
    Tocilins-Ruberts](../Images/363a4f32aa793cca7a67dea68e76e3cf.png)](https://medium.com/@antonsruberts?source=post_page-----b2ec500a1008--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b2ec500a1008--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b2ec500a1008--------------------------------)
    [Antons Tocilins-Ruberts](https://medium.com/@antonsruberts?source=post_page-----b2ec500a1008--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b2ec500a1008--------------------------------)
    ·12 min read·Jul 6, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b2ec500a1008--------------------------------)
    ·阅读时间 12 分钟·2023年7月6日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/1ec62693f9e625f8eb7847708504fcaa.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1ec62693f9e625f8eb7847708504fcaa.png)'
- en: Photo by [Mitul Grover](https://unsplash.com/@mitulgrover?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Mitul Grover](https://unsplash.com/@mitulgrover?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Every once in a while, along comes a tool that significantly alters the way
    that data analysis is done. I believe that Polars is one of those tools, so in
    this series of posts, I’ll deep dive into this library, compare it to a more well
    known and established library — Pandas, and will showcase the analysis workflow
    using an example dataset.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 每隔一段时间，就会出现一种工具，显著改变数据分析的方式。我认为 Polars 就是这样一种工具，因此在这一系列文章中，我将深入探讨这个库，将其与更知名且成熟的库
    —— Pandas 进行比较，并展示使用示例数据集的分析工作流程。
- en: What is Polars?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 Polars？
- en: 'Polars is a blazingly fast DataFrame library written in Rust. Lucky for us
    (data scientists/analysts) it has a very well documented Python wrapper that exposes
    a complete set of features to wrangle data and build data pipelines. Here are
    the main advantages I’ve seen after switching to Polars:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Polars 是一个用 Rust 编写的极其快速的 DataFrame 库。幸运的是，对于我们（数据科学家/分析师）来说，它有一个非常完善的 Python
    封装，暴露出一整套功能来处理数据和构建数据管道。以下是我在切换到 Polars 后看到的主要优点：
- en: Much faster pre-processing operations
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更快的预处理操作
- en: Ability to handle larger than RAM datasets
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理比 RAM 更大的数据集的能力
- en: Better quality of code due to the need to properly structure data pipelines
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于需要正确构建数据管道，代码质量更高
- en: You can see the full set of benefits in this [user guide](https://pola-rs.github.io/polars-book/user-guide/#philosophy)
    and the speed comparisons in this H20 [benchmark](https://h2oai.github.io/db-benchmark/).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这个 [用户指南](https://pola-rs.github.io/polars-book/user-guide/#philosophy)
    中看到完整的好处，并在这个 H20 [基准测试](https://h2oai.github.io/db-benchmark/) 中查看速度比较。
- en: Switching from Pandas
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从 Pandas 切换
- en: At the first glance, Pandas and Polars seem to be quite similar e.g. methods
    like `.read_csv()` or `.head()` are shared between them so you can perform basic
    exploratory operations without any changes. But the more you start working the
    library, the more you’ll notice how different the two libraries are. From syntaxis
    to the way of thinking, switching to Polars is no easy task. That’s why I hope
    that these posts will help you get started.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 乍一看，Pandas 和 Polars 似乎非常相似，例如 `.read_csv()` 或 `.head()` 这些方法在它们之间是共享的，因此你可以在不进行任何更改的情况下执行基本的探索性操作。但随着你开始使用这个库，你会发现这两个库之间有许多不同之处。从语法到思维方式，切换到
    Polars 并非易事。这就是为什么我希望这些文章能帮助你入门。
- en: Setup
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置
- en: 'To follow along the project, make sure to pull this [GitHub repo](https://github.com/aruberts/tutorials/blob/main/polars/basics.ipynb)
    with the latest notebook. Data used in this project can be downloaded from [Kaggle](https://www.kaggle.com/datasets/datasnaek/youtube-new?resource=download&sort=published)
    (CC0: Public Domain). It’s a dataset about YouTube’s top trending videos and should
    provide enough complexity for this series of posts. Also, you’ll need Pandas and
    Polars to be installed which can be done using pip for both packages.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Now that everything is setup, let’s jump into the project! The main goal here
    is to get you more familiar with Polars, so make sure to follow along or practice
    the concepts on your own dataset. Once again, in the [GitHub repo](https://github.com/aruberts/tutorials/blob/main/polars/basics.ipynb)
    you can find the notebook with all the code used here.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Data Processing
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reading Data
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Reading data is going to be familiar to Pandas users since it uses exactly the
    same methods. Let’s read in the statistics for United Kingdom videos for the further
    analysis and print out the DataFrame shapes.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you time both of these read in operations, you’ll have your first “wow” moment
    with Polars. On my laptop, Polars reads in the file in ~110 ms and Pandas reads
    it in ~ 270 ms. That’s 2.5x speedup, but you’ll frequently see reading/writing
    operation speed ups much more than this (especially with larger files).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Common Exploratory Methods
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What’s the first thing you do when you read in the data? I assume you print
    out a head (or sample), check the data types, shapes, etc. Polars shares a lot
    of these high-level methods with Pandas, so you can explore the first rows using
    `.head()` method, and the last rows using `.tail()` method.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/ee17eb91e56a42cc5a89d49a24fb24ce.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
- en: First two rows. Screenshot by author.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: While you’ll be able to see the outputs, it’s formatting is not ideal. You can
    change how the outputs get displayed using the `Config` . For example, to make
    the printouts wider you can set the maximum number of characters per row to 200
    like so `pl.Config.set_tbl_width_chars(200)` . Then the output is going to look
    more pleasant.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a82fd24d1e2f072e1b28e9a498f0399b.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
- en: Wide format. Screenshot by author.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: There are a lot of other parameters you can adjust (e.g. hide column data types),
    so make sure to checkout the [Config documentation](https://pola-rs.github.io/polars/py-polars/html/reference/config.html).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: Selecting Columns
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By Data Types
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You might have seen from the printout that Polars has a bit different set of
    data types for its columns. Numeric columns are usually assigned types of `Int32`
    , `Int64` , `Float32` , `Float64` and categorical columns are usually assigned
    types of `Utf8` . To select columns by data type, the so-called `selectors` can
    be used together with the `.select()` method. These `selectors` are a relatively
    new addition to the API and they give us more intuitive way of selecting columns.
    For example, below you can see the code to select all the numeric and all the
    categorical columns.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/2b867381551357ccc49403733ba679e2.png)![](../Images/4b552e6e511515acc04b5ddf2c85b13e.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: Numerical and Categorical Features. Screenshot by author.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: By Column Name
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you want to select a column by name, you can use the same `.select()` method
    but now you’ll need to provide a column’s name wrapped into `pl.col()` . To select
    multiple columns, just provide the names in a list, very similar to Pandas
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: It should be noted that `df_pl[["likes", "views", "comment_count"]]` will also
    work due to syntactic sugar implemented by Polars. Still, it’s a good practice
    to write the full statements, so I recommend you get some practice writing it
    both ways.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Selecting Rows
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To select specific rows you’ll need to use `.filter()` method. Notice that Polars
    doesn’t have index which means that commands like `.iloc` are not available. Let’s
    find out how many rows in the dataset have less than 1000 views. This should be
    very small because it’s highly unlikely that an unpopular video gets into Trending
    tab.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Data Quality Checks
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For a more complicated use case, let’s perform basic data quality checks. When
    doing a data quality check, it’s always a good idea to check for the number of
    missing rows per column and the number of static columns. In Pandas, this can
    be done very simply using in-built checks and aggregations.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: With Polars this part is a bit more involved and requires chaining a few methods.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Let’s break down the code to calculate number of missing rows.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '`df_pl.select(pl.all())` repeats the specified operation for all columns'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.is_null().sum()` sums up the number of Null values (Polars representation
    of NA)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.melt()` transforms wide DataFrame into long format'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.filter(pl.col("missing") > 0)` filters out the columns where no rows are
    missing'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can see that chaining these operations is quite easy and the flow is quite
    similar to PySpark. Even though the code is a bit more involved, the execution
    speed is ~4x faster in Polars.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: What is surprising is that the results of data quality checks don’t match up.
    With Pandas, there are 612 missing rows in `description` column, whereas with
    Polars we don’t see this. This is because Polars treats missing strings as empty
    strings `""` , so they don’t appear in the null counts. You can easily replace
    these strings with Null values if you wish using `.replace()` method.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: Data Pre-Processing
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two steps that need to be done to prepare the data:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: Convert date columns into `datetime` format
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replace category IDs with the actual category names
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To do this, we’ll need to use `.with_columns()` method because it returns the
    entire DataFrame with altered columns. `.select()` method in this case wouldn’t
    work, because it would only return the processed columns. In addition, we’ll need
    to use the `.str` namespace which is very similar to Pandas. This namespace has
    all the operations available for strings, e.g. `.str.contains()` or `.str.to_lowercase()`
    (see all [here](https://pola-rs.github.io/polars/py-polars/html/reference/expressions/string.html)).
    If you’re interest in working with strings in Polars, checkout this [post](https://medium.com/me/stats/post/fcf7054a929a)
    after finishing with this one.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: To replace a category, we’ll simply apply the `.map_dict()` method which is
    similar to `.map()` in Pandas. In Polars, `.map()` only works with functions,
    so keep this in mind.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now that the data is ready, let’s finally do some analysis!
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Basic Exploratory Data Analysis
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will cover the some of the most important techniques when doing
    EDA, namely univariate data analysis, aggregates, and visualisations.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Univariate Data Analysis
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Univariate data analysis is the simplest analysis you can do yet it’s crucial.
    Looking at one variable at a time, it can give you a better sense of data and
    can guide your further explorations.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Categorical Columns
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since we’ve mapped the category IDs to their actual names in data pre-processing
    section, let’s see their distribution using `.value_counts()` .
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The `value_counts()` operation is also present in Polars, just don’t forget
    to set `sort=True` if you want the same behaviour as in Pandas. Next, we can use
    this information to create a basic bar plot. Plotting with Polars is relatively
    simple, although there’s no in-built plotting methods so far like with Pandas.
    Some plotting libraries don’t take Polars Series as inputs, but lucky for us it’s
    quite easy to convert the Series to a commonly acceptable formats — Python lists,
    NumPy arrays and Pandas Series.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](../Images/51e023bbe43f9df121990a088376f8ac.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
- en: Image by author.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: Looks like Music is by far the most frequent category in YouTube trends followed
    by Entertainment which is not surprising. On the other hand, people doing content
    for Shows, Non-Profit, Travel, and Autos & Vehicles will have a much harder time
    getting into Trending.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Numerical Columns
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Numerical features univariate analysis can be performed using `.describe()`
    method which behaves very similar to Pandas. Also, we can plot a histogram of
    log views. Log transformation is done to handle heavy outliers like the video
    with a 424 million views. Interestingly, the minimum number of views a video in
    trending has is just 851.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/14f4049400f866322afdb7dac420d298.png)![](../Images/0002d2dce0ea79fed6e6e0a756cf0493.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
- en: Screenshot and image by author.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: There are many more columns to explore, so I’d recommend you go explore them
    on your own since you have the tools now. After you’re done, let’s move to more
    complicated forms of analysis
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 还有很多列需要探索，所以我建议你自己去探索，因为你现在拥有工具了。完成后，我们可以进入更复杂的分析形式。
- en: Multivariate Data Analysis
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多变量数据分析
- en: First things first, which channels appear most frequently in the trending page?
    We can again use `.value_counts()` but let’s use the `.groupby().agg()` method
    instead since it’s much more flexible and will be useful going forward. I’m going
    to group by the *channel title* and count the number of rows using `.count()`
    method.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，哪些频道在趋势页面上出现得最频繁？我们可以再次使用 `.value_counts()`，但让我们改用 `.groupby().agg()` 方法，因为它更灵活，并且对接下来的工作会很有用。我将按
    *频道标题* 分组，并使用 `.count()` 方法计算行数。
- en: '[PRE15]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Similar to Pandas, inside of `.groupby()` you need to specify the name of the
    column that you want to create aggregates for. Notice that for Polars, you need
    to wrap the column name with `pl.col()` however it will also work without it due
    to implemented syntactic sugar. Inside of the `.agg()` you usually need to provide
    the column name that you want to aggregate but in this case I’m using a `pl.count()`
    method since I want to count rows. Notice that you can re-name any aggregate/column
    you create using `.alias()` method.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Pandas 类似，在 `.groupby()` 中你需要指定要创建聚合的列名。注意对于 Polars，你需要用 `pl.col()` 包装列名，但由于实现了语法糖，它也可以在没有它的情况下工作。在
    `.agg()` 内部，你通常需要提供要聚合的列名，但在这种情况下，我使用了 `pl.count()` 方法，因为我想计算行数。注意，你可以使用 `.alias()`
    方法重新命名你创建的任何聚合/列。
- en: 'Let’s create a few other statistics namely:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一些其他统计数据，即：
- en: Number of unique trendy videos
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独特的流行视频数量
- en: Total number of views, likes and comments
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总浏览量、点赞数和评论数
- en: Average number of views likes and comments
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均浏览量、点赞数和评论数
- en: '[PRE17]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](../Images/12f6c0e7de3d9bfe87f3a2638e522352.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/12f6c0e7de3d9bfe87f3a2638e522352.png)'
- en: Image by author.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: Looks like everything is working as expected. The same aggregates could be implemented
    in Pandas using their `.agg()` method.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来一切都按预期工作。相同的聚合可以在 Pandas 中使用 `.agg()` 方法实现。
- en: '[PRE18]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The results should be the same, but the **execution time is ~10x faster** in
    Polars.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该是相同的，但在 Polars 中**执行时间快了 ~10 倍**。
- en: These aggregates are usually a good first step in the analysis, and they might
    be useful down the line (e.g. in the dashboard), so it would be nice to refactor
    the aggregation code into a function.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这些聚合通常是分析的良好第一步，它们在后续可能会有用（例如在仪表盘中），因此将聚合代码重构为一个函数是很有必要的。
- en: '[PRE19]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Above you can see how this aggregation function could look like. Notice that
    we can store the required aggregate operations in a list before passing them into
    a Polars `.agg()` method which is quite powerful. Now, this function can be applied
    not only for the `channel_title` columns, but also e.g. for the `category_id`
    .
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 上面你可以看到这个聚合函数的样子。注意我们可以在将所需的聚合操作传递给 Polars `.agg()` 方法之前，将它们存储在一个列表中，这个方法非常强大。现在，这个函数不仅可以应用于
    `channel_title` 列，还可以应用于例如 `category_id`。
- en: '[PRE20]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![](../Images/6f7e6a37ff50a5afd03a4b6dfb825c8b.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6f7e6a37ff50a5afd03a4b6dfb825c8b.png)'
- en: Image by author.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: From the screenshot above you can see that the top trending channels and the
    top trending categories. These aggregates could be further put into a dashboard
    or used for further analysis.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的截图中，你可以看到顶级流行频道和顶级流行类别。这些聚合可以进一步放入仪表盘或用于进一步分析。
- en: Writing Data
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 写入数据
- en: Saving the DataFrames to disk is actually quite easy. All you need to do is
    to make sure that the folder you’re writing to exists. Otherwise, the process
    is very similar to Pandas, except you use `.write_parquet()` method and not `.to_parquet()`
    (I’m making this mistake at least once a day).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 将 DataFrames 保存到磁盘实际上非常简单。你只需要确保你写入的文件夹存在。否则，过程与 Pandas 非常相似，只是你使用 `.write_parquet()`
    方法而不是 `.to_parquet()`（我每天至少犯一次这个错误）。
- en: '[PRE21]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Conclusion
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'Good job for making it this far! Overall, you’ve seen how to do the following
    in Polars:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 做得好，能做到这一步！总的来说，你已经了解了如何在 Polars 中完成以下操作：
- en: Read in data
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取数据
- en: Investigate the DataFrames
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调查 DataFrames
- en: Perform basic data quality checks
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行基本的数据质量检查
- en: Select required columns/rows
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择所需的列/行
- en: Perform basic cleaning
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行基本清理
- en: Perform basic univariate analysis
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行基本的单变量分析
- en: Perform basic multivariate analysis
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行基本的多变量分析
- en: Write out the DataFrames to Parquet file
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 DataFrames 写入 Parquet 文件
- en: This is a great start, so let’s wrap up the first part of this series. Make
    sure to practice it on your own dataset because I firmly believe that the best
    way to learn is by practicing, practicing, and practicing. Thank you for reading
    and see you in the next part!
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: What Next?
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you’ve got the basics of Polars, it’s time to move on to something more advanced.
    Part 2 of this series covers more complicated aggregates and analytical functions
    which are essential for any data professional.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '[](/eda-with-polars-step-by-step-guide-to-aggregate-and-analytic-functions-part-2-a22d986315aa?source=post_page-----b2ec500a1008--------------------------------)
    [## EDA with Polars: Step-by-Step Guide to Aggregate and Analytic Functions (Part
    2)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: Advanced aggregates and rolling averages at lightning speed with Polars
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/eda-with-polars-step-by-step-guide-to-aggregate-and-analytic-functions-part-2-a22d986315aa?source=post_page-----b2ec500a1008--------------------------------)
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Not a Medium Member yet?
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@antonsruberts/membership?source=post_page-----b2ec500a1008--------------------------------)
    [## Join Medium with my referral link — Antons Tocilins-Ruberts'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Read every story from Antons Tocilins-Ruberts (and thousands of other writers
    on Medium). Your membership fee directly…
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@antonsruberts/membership?source=post_page-----b2ec500a1008--------------------------------)
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
