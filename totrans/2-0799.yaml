- en: 'Embeddings + Knowledge Graphs: The Ultimate Tools for RAG Systems'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 嵌入 + 知识图谱：RAG 系统的**终极工具**
- en: 原文：[https://towardsdatascience.com/embeddings-knowledge-graphs-the-ultimate-tools-for-rag-systems-cbbcca29f0fd](https://towardsdatascience.com/embeddings-knowledge-graphs-the-ultimate-tools-for-rag-systems-cbbcca29f0fd)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/embeddings-knowledge-graphs-the-ultimate-tools-for-rag-systems-cbbcca29f0fd](https://towardsdatascience.com/embeddings-knowledge-graphs-the-ultimate-tools-for-rag-systems-cbbcca29f0fd)
- en: '[](https://medium.com/@alcarazanthony1?source=post_page-----cbbcca29f0fd--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----cbbcca29f0fd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cbbcca29f0fd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cbbcca29f0fd--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----cbbcca29f0fd--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@alcarazanthony1?source=post_page-----cbbcca29f0fd--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----cbbcca29f0fd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cbbcca29f0fd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cbbcca29f0fd--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----cbbcca29f0fd--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cbbcca29f0fd--------------------------------)
    ·10 min read·Nov 14, 2023
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cbbcca29f0fd--------------------------------)
    ·10 分钟阅读·2023年11月14日
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '*Artificial intelligence software was used to enhance the grammar, flow, and
    readability of this article’s text.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*人工智能软件被用来增强本文文本的语法、流畅性和可读性。*'
- en: The advent of large language models (LLMs) , trained on vast amounts of text
    data, has been one of the most significant breakthroughs in natural language processing.
    The ability of these models to generate remarkably fluent and coherent text with
    just a short prompt has opened up new possibilities for conversational AI, creative
    writing, and a wide array of other applications.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）的出现，经过大量文本数据的训练，是自然语言处理领域最重要的突破之一。这些模型仅凭简短的提示生成流畅且连贯的文本，开辟了对话 AI、创意写作和广泛其他应用的新可能性。
- en: However, despite their eloquence, LLMs have some key limitations. Their knowledge
    is restricted to patterns discerned from the training data, which means they lack
    true understanding of the world.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，尽管它们表现出色，LLM 仍然有一些关键限制。它们的知识仅限于从训练数据中辨别出的模式，这意味着它们缺乏对世界的真正理解。
- en: Their reasoning ability is also limited — they cannot perform logical inferences
    or synthesize facts from multiple sources. As we ask more complex, open-ended
    questions, the responses start becoming nonsensical or contradictory.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 他们的推理能力也有限——他们无法进行逻辑推断或从多个来源综合事实。当我们提出更复杂、开放性的问题时，回答开始变得毫无意义或自相矛盾。
- en: To address these gaps, there has been growing interest in retrieval-augmented
    generation (RAG) systems. The key idea is to retrieve relevant knowledge from
    external sources to provide context for the LLM to make more informed responses.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了弥补这些不足，检索增强生成（RAG）系统引起了越来越多的关注。关键思想是从外部来源检索相关知识，为 LLM 提供背景，以做出更有信息量的回答。
- en: Most existing systems retrieve passages using semantic similarity of vector
    embeddings. However, this approach has its own drawbacks like lack of true relevance,
    inability to aggregate facts, and no chain of reasoning.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 目前大多数现有系统通过向量嵌入的语义相似性检索段落。然而，这种方法有其自身的缺陷，如缺乏真正的相关性、无法聚合事实以及没有推理链。
- en: This is where knowledge graphs come into the picture. Knowledge graphs are structured
    representations of real-world entities and relationships. They overcome the deficiencies
    of pure vector search by encoding interconnections between contextual facts. Traversing
    knowledge graphs enables complex multi-hop reasoning across diverse information
    sources.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是知识图谱发挥作用的地方。知识图谱是对现实世界实体和关系的结构化表示。它们通过编码上下文事实之间的相互连接，克服了纯向量搜索的不足。遍历知识图谱能够在多样的信息源之间进行复杂的多跳推理。
- en: In this article, we dive deep on how combining vector embeddings and knowledge
    graphs can unlock new levels of reasoning, accuracy and explanatory ability in
    LLMs. This partnership provides the perfect blend of surface-level semantics along
    with structured knowledge and logic.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们深入探讨了如何将向量嵌入与知识图谱结合，以解锁LLM推理、准确性和解释能力的新层次。这种结合提供了表面语义与结构化知识和逻辑的完美融合。
- en: Like our own minds, LLMs need both statistical learning as well as symbolic
    representations.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 像我们的思维一样，LLM需要统计学习和符号表示的结合。
- en: We first explore the inherent weaknesses of relying solely on vector search
    in isolation.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先探讨了单独依赖向量搜索的固有弱点。
- en: We then elucidate how knowledge graphs and embeddings can complement each other,
    with neither technique alone being sufficient.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们阐明了知识图谱和嵌入如何互相补充，单独使用任何一种技术都不够充分。
- en: The Limits of Raw Vector Search
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原始向量搜索的局限性
- en: '[](/vector-search-is-not-all-you-need-ecd0f16ad65e?source=post_page-----cbbcca29f0fd--------------------------------)
    [## Vector Search Is Not All You Need'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 向量搜索并非你所需的一切](https://towardsdatascience.com/vector-search-is-not-all-you-need-ecd0f16ad65e?source=post_page-----cbbcca29f0fd--------------------------------)'
- en: Introduction
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 介绍
- en: towardsdatascience.com](/vector-search-is-not-all-you-need-ecd0f16ad65e?source=post_page-----cbbcca29f0fd--------------------------------)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](https://towardsdatascience.com/vector-search-is-not-all-you-need-ecd0f16ad65e?source=post_page-----cbbcca29f0fd--------------------------------)'
- en: 'Most RAG systems rely on a vector search process over passages from a document
    collection to find relevant context for the LLM. This process has several key
    steps:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数RAG系统依赖于对文档集合中的段落进行向量搜索，以找到对LLM相关的上下文。此过程包括几个关键步骤：
- en: '**Text Encoding:** The system encodes passages of text from the corpus into
    vector representations using embedding models like BERT. Each passage gets condensed
    into a dense vector capturing semantic meaning.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**文本编码：** 系统使用像BERT这样的嵌入模型将语料库中的文本段落编码成向量表示。每个段落都被压缩成一个密集的向量，捕捉语义意义。'
- en: '**Indexing:** These passage vectors get indexed in a high-dimensional vector
    space to enable fast similarity search. Popular methods include ANNOY, Faiss,
    and Pinecone.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**索引：** 这些段落向量在高维向量空间中进行索引，以实现快速相似性搜索。常用的方法包括ANNOY、Faiss和Pinecone。'
- en: '**Query Encoding:** When a user query comes in, it also gets encoded into a
    vector representation using the same embedding model.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**查询编码：** 当用户查询到达时，它也会使用相同的嵌入模型编码成向量表示。'
- en: '**Similarity Retrieval:** A similarity search is run over the indexed passages
    to find those closest to the query vector based on distance metrics like cosine
    similarity.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**相似性检索：** 通过对索引的段落进行相似性搜索，找到那些与查询向量基于距离度量（如余弦相似性）最接近的段落。'
- en: '**Passage Return:** The most similar passage vectors are returned, and the
    original text is extracted to provide context for the LLM.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**段落返回：** 返回最相似的段落向量，并提取原始文本以提供LLM的上下文。'
- en: 'This pipeline has several key limitations:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 该管道存在几个关键限制：
- en: The passage vectors may not fully capture the semantic intent of the query.
    Important context ends up overlooked because embeddings fail to represent certain
    inferential connections.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 段落向量可能未能完全捕捉查询的语义意图。重要的上下文可能被忽视，因为嵌入未能表示某些推理连接。
- en: Nuances get lost in condensing entire passages to single vectors. Key relevant
    details embedded across sentences get obscured.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在将整个段落压缩为单一向量时，细微之处会丢失。分布在句子中的关键相关细节被掩盖。
- en: Matching is done independently for each passage. There is no joint analysis
    across different passages to connect facts and derive answers requiring aggregation.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 匹配是针对每个段落独立进行的。没有跨不同段落进行联合分析以连接事实和推导需要聚合的答案。
- en: The ranking and matching process is opaque, providing no transparency into why
    certain passages are deemed more relevant.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 排名和匹配过程不透明，无法提供为何某些段落被认为更相关的透明度。
- en: Only semantic similarity is encoded, with no representations of relationships,
    structure, rules and other diverse connections between content.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只编码了语义相似性，没有表示内容之间关系、结构、规则和其他多样化连接的表示。
- en: The singular focus on semantic vector similarity results in retrieval that lacks
    true comprehension. As queries get more complex, these limitations become increasingly
    apparent in the inability to reason across retrieved content.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 仅关注语义向量相似性会导致检索结果缺乏真实理解。随着查询变得更加复杂，这些局限性在无法跨检索内容进行推理时变得愈加明显。
- en: Incorporating Knowledge Graphs
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 融入知识图谱
- en: Knowledge graphs represent information in an interconnected network of entities
    and relationships, enabling more complex reasoning across content.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱将信息表示为一个互联的实体和关系网络，能够在内容中进行更复杂的推理。
- en: 'Here’s how they augment retrieval:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是它们如何增强检索：
- en: '**Explicit Facts** — Facts are directly captured as nodes and edges instead
    of condensed into opaque vectors. This preserves key details.'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**显式事实** — 事实作为节点和边直接捕获，而不是压缩成不透明的向量。这保留了关键细节。'
- en: '**Contextual Details** — Entities contain rich attributes like descriptions,
    aliases, and metadata that provide crucial context.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**上下文细节** — 实体包含丰富的属性，如描述、别名和元数据，提供了关键的上下文。'
- en: '**Network Structure** — Relationships model real-world connections between
    entities, capturing rules, hierarchies, timelines, etc.'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**网络结构** — 关系建模实体之间的现实世界连接，捕捉规则、层级、时间线等。'
- en: '**Multi-Hop Reasoning** — Queries can traverse relationships to connect facts
    from diverse sources. Answers requiring inference across multiple steps can be
    derived.'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**多跳推理** — 查询可以遍历关系以连接来自不同来源的事实。可以推导出需要多步骤推理的答案。'
- en: '**Joint Reasoning** — Entity Resolution links references to the same real-world
    object, allowing collective analysis.'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**联合推理** — 实体解析将对同一现实世界对象的引用连接起来，允许集体分析。'
- en: '**Explainable Relevance** — Graph topology provides transparency into why certain
    facts are relevant based on their connections.'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**可解释的相关性** — 图的拓扑结构提供了为什么某些事实基于其连接而相关的透明度。'
- en: '**Personalization** — User attributes, context, and historical interactions
    are captured to tailor results.'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**个性化** — 捕捉用户属性、上下文和历史交互，以定制结果。'
- en: Rather than isolated matching, knowledge graphs enable a graph traversal process
    to gather interconnected contextual facts relevant to the query. Explainable rankings
    are possible based on topology. The rich knowledge representation empowers more
    complex reasoning.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱使得图遍历过程成为可能，以收集与查询相关的相互连接的上下文事实，而不是孤立的匹配。根据拓扑结构可以实现可解释的排名。丰富的知识表示能力促进了更复杂的推理。
- en: Knowledge graphs augment retrieval by encoding structured facts, relationships
    and context to enable precise, multi-step reasoning. This provides greater relevance
    and explanatory power compared to pure vector search.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱通过编码结构化事实、关系和上下文来增强检索，从而实现精准的多步骤推理。与纯向量搜索相比，这提供了更大的相关性和解释力。
- en: Incorporating Knowledge Graphs with Embeddings & Constraints
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结合知识图谱与嵌入和约束
- en: '[](https://arxiv.org/abs/1805.02408?source=post_page-----cbbcca29f0fd--------------------------------)
    [## Improving Knowledge Graph Embedding Using Simple Constraints'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 提升知识图谱嵌入使用简单约束](https://arxiv.org/abs/1805.02408?source=post_page-----cbbcca29f0fd--------------------------------)'
- en: Embedding knowledge graphs (KGs) into continuous vector spaces is a focus of
    current research. Early works performed…
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将知识图谱（KGs）嵌入到连续向量空间是当前研究的重点。早期的研究进行了…
- en: arxiv.org](https://arxiv.org/abs/1805.02408?source=post_page-----cbbcca29f0fd--------------------------------)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[arxiv.org](https://arxiv.org/abs/1805.02408?source=post_page-----cbbcca29f0fd--------------------------------)'
- en: 'Knowledge graphs represent entities and relationships as vector embeddings
    to enable mathematical operations. Additional constraints can make the representations
    more optimal:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱将实体和关系表示为向量嵌入，以进行数学操作。额外的约束可以使表示更加优化：
- en: '**Non-Negativity Constraints** — Restricting entity embeddings to positive
    values between 0 and 1 induces sparsity. This models only their positive properties
    explicitly and improves interpretability.'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**非负约束** — 将实体嵌入限制在0到1之间的正值，诱导稀疏性。这仅显式地建模它们的正面属性，并提高可解释性。'
- en: '**Entailment Constraints** — Encoding expected logic rules like symmetry, inversion,
    composition directly as constraints on relation embeddings enforces those patterns.'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**蕴含约束** — 通过将预期的逻辑规则如对称性、反转、组合直接编码为关系嵌入的约束，强制这些模式。'
- en: '**Confidence Modeling** — Soft constraints with slack variables can encode
    varying confidence levels of logic rules based on evidence.'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**置信度建模** — 通过松弛变量的软约束可以编码基于证据的逻辑规则的不同置信水平。'
- en: '**Regularization** — Constraints impose useful inductive biases without making
    optimization significantly more complex. Only a projection step is added.'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**正则化** — 约束施加有用的归纳偏置，而不会使优化显著变得更加复杂。只增加一个投影步骤。'
- en: '**Explainability** — The structured constraints provide transparency into the
    patterns learned by the model. This explains the reasoning process.'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**可解释性** — 结构化的约束提供了对模型学习到的模式的透明度。这解释了推理过程。'
- en: '**Accuracy** — Constraints improve generalization by reducing the hypothesis
    space to compliant representations. This improves accuracy on unseen queries.'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**准确性** — 约束通过减少假设空间到符合的表示来提高泛化能力。这提高了对未见查询的准确性。'
- en: Adding simple but universal constraints augments knowledge graph embeddings
    to produce more optimized, explainable, and logically compliant representations.
    The embeddings gain inductive biases that mimic real-world structures and rules.
    This results in more accurate and interpretable reasoning without much additional
    complexity.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 添加简单但通用的约束可以增强知识图谱嵌入，生成更优化、可解释且符合逻辑的表示。这些嵌入获得了模仿现实世界结构和规则的归纳偏差，从而带来更准确且易于解释的推理，而不增加额外的复杂性。
- en: Integrating Diverse Reasoning Frameworks
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 整合多样化的推理框架
- en: '[](https://paperswithcode.com/paper/graph-agent-explicit-reasoning-agent-for?source=post_page-----cbbcca29f0fd--------------------------------)
    [## Papers with Code - Graph Agent: Explicit Reasoning Agent for Graphs'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[## Papers with Code - Graph Agent: Explicit Reasoning Agent for Graphs](https://paperswithcode.com/paper/graph-agent-explicit-reasoning-agent-for?source=post_page-----cbbcca29f0fd--------------------------------)'
- en: No code available yet.
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 尚无可用代码。
- en: paperswithcode.com](https://paperswithcode.com/paper/graph-agent-explicit-reasoning-agent-for?source=post_page-----cbbcca29f0fd--------------------------------)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[paperswithcode.com](https://paperswithcode.com/paper/graph-agent-explicit-reasoning-agent-for?source=post_page-----cbbcca29f0fd--------------------------------)'
- en: 'Knowledge graphs require reasoning to derive new facts, answer queries, and
    make predictions. Different techniques have complementary strengths:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱需要推理来推导新事实、回答查询和进行预测。不同的技术具有互补的优势：
- en: '**Logical Rules** — Express knowledge as logical axioms and ontologies. Sound
    and complete reasoning through theorem proving. Limited uncertainty handling.'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**逻辑规则** — 将知识表达为逻辑公理和本体。通过定理证明进行可靠和完整的推理。处理不确定性的能力有限。'
- en: '**Graph Embeddings** — Embed knowledge graph structure for vector space operations.
    Handle uncertainty but lack expressivity.'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**图谱嵌入** — 嵌入知识图谱结构以进行向量空间操作。处理不确定性，但缺乏表达能力。'
- en: '**Neural Provers** — Differentiable theorem proving modules combined with vector
    lookups. Adaptive but opaque reasoning.'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**神经证明器** — 可微分的定理证明模块与向量查找结合。自适应但推理不透明。'
- en: '**Rule Learners** — Induce rules by statistical analysis of graph structure
    and data. Automates rule creation but uncertain quality.'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**规则学习器** — 通过对图结构和数据的统计分析来引导规则。自动化规则创建但质量不确定。'
- en: '**Hybrid Pipeline** — Logical rules encode unambiguous constraints. Embeddings
    provide vector space operations. Neural provers fuse benefits through joint training.'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**混合管道** — 逻辑规则编码明确的约束。嵌入提供向量空间操作。神经证明器通过联合训练融合了这些优势。'
- en: '**Explainable Modeling** — Use case-based, fuzzy, or probabilistic logic to
    add transparency. Express uncertainty and confidence in rules.'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**可解释建模** — 使用基于案例、模糊或概率逻辑来增加透明度。表达规则中的不确定性和信心。'
- en: '**Iterative Enrichment** — Expand knowledge by materializing inferred facts
    and learned rules back into the graph. Provides a feedback loop.'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**迭代增强** — 通过将推断出的事实和学习到的规则重新呈现到图谱中来扩展知识。提供反馈回路。'
- en: The key is identifying the types of reasoning required and mapping them to appropriate
    techniques. A composable pipeline combining logical formalisms, vector representations,
    and neural components provides both robustness and explainability.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 关键在于识别所需的推理类型并将其映射到适当的技术上。一个结合逻辑形式、向量表示和神经组件的可组合管道提供了鲁棒性和可解释性。
- en: Preserving Information Flow to the LLM
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保持信息流向LLM
- en: 'Retrieving knowledge graph facts for the LLM introduces information bottlenecks.
    Careful design preserves relevance:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 从知识图谱中检索事实以供LLM使用会引入信息瓶颈。精心设计保持相关性：
- en: '**Chunking** — Splitting content into small chunks improves isolation but loses
    surrounding context. This hinders reasoning across chunks.'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分块** — 将内容拆分成小块可以提高隔离性，但会丧失周围的上下文。这阻碍了跨块的推理。'
- en: '**Summarization** — Generating summaries of chunks provides more concise context.
    Key details are condensed to highlight significance.'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**总结** — 生成内容块的摘要提供了更简洁的上下文。关键细节被浓缩以突出其重要性。'
- en: '**Metadata** — Attaching summaries, titles, tags etc as metadata maintains
    context about the source content.'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**元数据** — 附加摘要、标题、标签等作为元数据以维护源内容的上下文。'
- en: '**Query Rewriting** — Rewriting the original query into a more detailed version
    provides retrieval that is better targeted to the LLM’s needs.'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**查询重写** — 将原始查询重写为更详细的版本，提供更符合LLM需求的检索结果。'
- en: '**Relationship Modeling** — Knowledge graph traversals preserve connections
    between facts, maintaining context.'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**关系建模** — 知识图谱遍历保持事实之间的连接，维持上下文。'
- en: '**Information Ordering** — Ordering facts chronologically or by relevance optimizes
    information structure for the LLM.'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**信息排序** — 按时间顺序或相关性排序事实，优化LLM的信息结构。'
- en: '**Explicit Statements** — Converting implicit knowledge into explicit facts
    stated for the LLM makes reasoning easier.'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**显式陈述** — 将隐含知识转换为为LLM陈述的显式事实，使推理更容易。'
- en: The goal is optimizing relevance, context, structure and explicitness of the
    retrieved knowledge to maximize reasoning ability. A balance needs to be struck
    between granularity and cohesiveness. The knowledge graph relationships aid in
    contextualizing isolated facts.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是优化检索知识的相关性、上下文、结构和明确性，以最大化推理能力。需要在粒度和连贯性之间取得平衡。知识图谱关系有助于将孤立的事实进行上下文化。
- en: Unlocking Reasoning Capabilities
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解锁推理能力
- en: 'Knowledge graphs and embeddings each have strengths that overcome the other’s
    weaknesses when combined:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱和嵌入各有优点，相互结合可以弥补对方的不足：
- en: '**Knowledge Graphs** — Provide structured representation of entities and relationships.
    Empower complex reasoning through graph traversals. Handle multi-hop inferences.'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**知识图谱** — 提供实体和关系的结构化表示。通过图遍历赋能复杂推理。处理多跳推理。'
- en: '**Embeddings** — Encode information in vector space for similarity-based operations.
    Enable efficient approximate search at scale. Surface latent patterns.'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**嵌入** — 在向量空间中编码信息以进行基于相似性的操作。实现大规模高效的近似搜索。揭示潜在模式。'
- en: '**Joint Encoding** — Embeddings are generated for entities and relationships
    in the knowledge graph. This distills statistical patterns.'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**联合编码** — 为知识图谱中的实体和关系生成嵌入。这提炼了统计模式。'
- en: '**Neural Networks** — Graph neural networks operate on the graph structure
    and embedded elements through differentiable message passing. This fuses benefits.'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**神经网络** — 图神经网络通过可微分的信息传递在图结构和嵌入元素上操作。这融合了优势。'
- en: '**Reasoning Flow** — Knowledge graph traversals first gather structured knowledge.
    Then embeddings focus the search and retrieve related content at scale.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**推理流程** — 知识图谱遍历首先收集结构化知识。然后嵌入关注搜索并大规模检索相关内容。'
- en: '**Explainability** — Explicit knowledge graph relationships provide explainability
    for the reasoning process. Embeddings lend interpretability.'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**可解释性** — 显式的知识图谱关系为推理过程提供了可解释性。嵌入增强了解释能力。'
- en: '**Iterative Improvement** — Inferred knowledge can expand the graph. GNNs provide
    continuous representation learning.'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**迭代改进** — 推断的知识可以扩展图。GNNs提供持续的表示学习。'
- en: The partnership enables structured knowledge representation and reasoning augmented
    by the pattern recognition capability and scalability of neural networks. This
    is key to advancing language AI requiring both statistical learning and symbolic
    logic.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这种合作关系使结构化知识表示和推理得到了模式识别能力和神经网络的可扩展性的增强。这是推动语言AI的关键，需要统计学习和符号逻辑的结合。
- en: Improving Search with Collaborative Filtering
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过协同过滤改进搜索
- en: 'Collaborative filtering leverages connections between entities to enhance search:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 协同过滤利用实体之间的连接来增强搜索：
- en: '**Knowledge Graph** — Construct a knowledge graph with nodes representing entities
    and edges representing relationships.'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**知识图谱** — 构建一个知识图谱，其中节点表示实体，边表示关系。'
- en: '**Node Embeddings** — Generate an embedding vector for certain key node properties
    like title, description etc.'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**节点嵌入** — 为特定的关键节点属性（如标题、描述等）生成嵌入向量。'
- en: '**Vector Index** — Build a vector similarity index on the node embeddings.'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**向量索引** — 在节点嵌入上构建向量相似性索引。'
- en: '**Similarity Search** — For a search query, find nodes with most similar embeddings.'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**相似性搜索** — 对于搜索查询，找到具有最相似嵌入的节点。'
- en: '**Collaborative Adjustment** — Based on a node’s connections, propagate and
    adjust similarity scores using algorithms like PageRank.'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**协作调整** — 基于节点的连接，使用诸如PageRank的算法传播和调整相似性评分。'
- en: '**Edge Weighting** — Weight adjustments based on edge types, strengths, confidence
    levels etc.'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**边权重** — 根据边的类型、强度、置信度等调整权重。'
- en: '**Score Normalization** — Normalize adjusted scores to maintain relative rankings.'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**评分归一化** — 对调整后的评分进行归一化，以保持相对排名。'
- en: '**Result Reranking** — Rerank initial results based on adjusted collaborative
    scores.'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**结果重新排序** — 基于调整后的协同评分重新排序初始结果。'
- en: '**User Context** — Further adapt based on user profile, history and preferences.'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**用户背景** — 根据用户资料、历史和偏好进一步调整。'
- en: Fueling Knowledge Graphs with Flywheel Learning
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用飞轮学习推动知识图谱
- en: '[](https://ai.plainenglish.io/fueling-the-rag-engine-the-data-flywheel-fc958c6d68d8?source=post_page-----cbbcca29f0fd--------------------------------)
    [## Fueling the RAG Engine : The Data Flywheel'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ai.plainenglish.io/fueling-the-rag-engine-the-data-flywheel-fc958c6d68d8?source=post_page-----cbbcca29f0fd--------------------------------)
    [## 驱动 RAG 引擎：数据飞轮'
- en: Building a high-performing retrieval-augmented generation (RAG) system that
    continuously improves requires implementing…
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建一个高效的检索增强生成（RAG）系统，并不断改进，需要实施…
- en: ai.plainenglish.io](https://ai.plainenglish.io/fueling-the-rag-engine-the-data-flywheel-fc958c6d68d8?source=post_page-----cbbcca29f0fd--------------------------------)
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[ai.plainenglish.io](https://ai.plainenglish.io/fueling-the-rag-engine-the-data-flywheel-fc958c6d68d8?source=post_page-----cbbcca29f0fd--------------------------------)'
- en: Knowledge graphs unlocked new reasoning capabilities for language models by
    providing structured world knowledge. But constructing high-quality graphs remains
    challenging. This is where flywheel learning comes in — continuously improving
    the knowledge graph by analyzing system interactions.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱通过提供结构化的世界知识，为语言模型解锁了新的推理能力。然而，构建高质量的图谱仍然具有挑战性。这就是飞轮学习的作用所在——通过分析系统交互持续改进知识图谱。
- en: The Knowledge Graph Flywheel
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 知识图谱飞轮
- en: '**Instrumentation** — Log all system queries, responses, scores, user actions
    etc. Provide visibility into how the knowledge graph is being used.'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**仪器化** — 记录所有系统查询、响应、评分、用户行为等。提供对知识图谱使用情况的可见性。'
- en: '**Analysis** — Aggregate usage data to surface poor responses. Cluster and
    analyze these responses to identify patterns indicating knowledge gaps.'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分析** — 汇总使用数据以显现不佳的响应。对这些响应进行聚类和分析，以识别表明知识缺口的模式。'
- en: '**Curation** — Manually review problematic responses and trace issues back
    to missing or incorrect facts in the graph.'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**策划** — 手动审查问题响应，并追踪问题到图谱中的缺失或错误的事实。'
- en: '**Remediation** — Directly modify the graph to add missing facts, improve structure,
    increase clarity etc. Fix the underlying data issues.'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**修正** — 直接修改图谱，添加缺失的事实、改进结构、提高清晰度等。修复潜在的数据问题。'
- en: '**Iteration** — Continuously loop through the steps above. Each iteration further
    enhances the knowledge graph.'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**迭代** — 不断循环上述步骤。每次迭代进一步增强知识图谱。'
- en: Streaming Data Ingestion
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流数据摄取
- en: Streaming live data sources like news and social media provides a constant flow
    of new information to keep the knowledge graph current.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流媒体数据源，如新闻和社交媒体，提供了持续的信息流，以保持知识图谱的时效性。
- en: Specialized infrastructure handles high volume ingestion into the graph.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专用基础设施处理高容量的数据摄取。
- en: Active Learning
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主动学习
- en: Use query generation to identify and fill critical knowledge gaps, beyond what
    streaming provides.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用查询生成识别并填补关键的知识空白，超越流媒体提供的信息。
- en: Discover holes in the graph, formulate questions, retrieve missing facts, and
    add them.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现图谱中的漏洞，提出问题，检索缺失的事实，并将其添加。
- en: The Flywheel Effect
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 飞轮效应
- en: With each loop, the knowledge graph gets incrementally stronger through analysis
    of usage patterns and remediation of data issues. The improved graph empowers
    better system performance.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 每次循环，知识图谱通过分析使用模式和修正数据问题逐步增强。改进的图谱提升了系统性能。
- en: This flywheel process enables the knowledge graph and language model to co-evolve
    based on feedback from real-world usage. The graph is actively tailored to fit
    the model’s needs.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这个飞轮过程使知识图谱和语言模型能够基于来自现实世界使用的反馈共同演化。图谱会根据模型的需求进行积极调整。
- en: In summary, flywheel learning provides a scaffolding for continuous, automated
    improvement of the knowledge graph through analysis of system interactions. This
    powers the accuracy, relevance and adaptability of language models relying on
    the graph.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，飞轮学习为知识图谱提供了一个持续、自动化改进的框架，通过分析系统交互来实现。这推动了依赖于图谱的语言模型的准确性、相关性和适应性。
- en: 'Conclusion :'
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论：
- en: To reach human-level intelligence, language AI needs to incorporate external
    knowledge and reasoning. This is where knowledge graphs come into the picture.
    Knowledge graphs provide structured representations of real-world entities and
    relationships, encoding facts about the world and connections between them. This
    allows complex logical reasoning across multiple steps by traversing interconnected
    facts.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 要达到人类水平的智能，语言 AI 需要结合外部知识和推理。这正是知识图谱发挥作用的地方。知识图谱提供了现实世界实体和关系的结构化表示，编码了关于世界的事实及其之间的连接。这允许通过遍历互联的事实进行复杂的逻辑推理。
- en: However, knowledge graphs have their own limitations like sparsity and lack
    of uncertainty handling. This is where graph embeddings help — by encoding knowledge
    graph elements in a vector space, embeddings allow statistical learning from large
    corpora to surface latent patterns. They also enable efficient similarity-based
    operations.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，知识图谱有其自身的局限性，如稀疏性和缺乏不确定性处理能力。在这里，图嵌入发挥作用——通过将知识图谱元素编码到向量空间中，嵌入允许从大规模语料库中进行统计学习，以揭示潜在模式。它们还支持基于相似性的高效操作。
- en: Neither knowledge graphs nor embeddings on their own are sufficient for human-like
    language intelligence. But together, they provide the perfect blend of structured
    knowledge representation, logical reasoning, and statistical learning. Knowledge
    graphs overlay symbolic logic and relationships on top of the pattern recognition
    capability of neural networks.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是知识图谱还是嵌入，单独使用都不足以实现类似人类的语言智能。但将它们结合起来，可以提供结构化知识表示、逻辑推理和统计学习的完美融合。知识图谱在神经网络的模式识别能力之上叠加了符号逻辑和关系。
- en: Techniques like graph neural networks further unify these approaches via differentiable
    message passing over graph structure and embeddings. The symbiosis enables systems
    that leverage both statistical learning as well as symbolic logic — combining
    the strengths of neural networks and structured knowledge representation.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 像图神经网络这样的技术通过在图结构和嵌入上进行可微分的消息传递进一步统一了这些方法。这种共生关系使系统能够利用统计学习和符号逻辑的优势——结合了神经网络和结构化知识表示的优点。
- en: This partnership provides building blocks for the next generation of AI that
    moves beyond just eloquence to true comprehension — conversational agents that
    understand context and history, recommendation engines that discern nuanced preferences,
    search systems that synthesize answers by connecting facts.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这种合作关系为下一代 AI 提供了基础构件，这种 AI 超越了单纯的口才，达到了真正的理解——能够理解上下文和历史的对话代理，能够识别细微偏好的推荐引擎，通过连接事实来合成答案的搜索系统。
- en: Challenges still remain in constructing high-quality knowledge graphs, benchmarking,
    noise handling, and more. But the future is bright for hybrid techniques spanning
    symbolic and neural approaches. As knowledge graphs and language models continue
    advancing, their integration will unlock new frontiers in explainable, intelligent
    language AI.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 构建高质量知识图谱、基准测试、噪声处理等仍然面临挑战。但跨符号和神经方法的混合技术前景光明。随着知识图谱和语言模型的不断进步，它们的整合将开启可解释、智能语言
    AI 的新领域。
- en: '![](../Images/06e2063970c7a7fc5562fd1c389719c4.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/06e2063970c7a7fc5562fd1c389719c4.png)'
- en: This image was created using an AI image generation model.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图像是使用 AI 图像生成模型创建的。
