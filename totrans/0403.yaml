- en: Bootstrap Tests for Beginners
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/bootstrap-tests-for-beginners-5fd9b092e7a6](https://towardsdatascience.com/bootstrap-tests-for-beginners-5fd9b092e7a6)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Part 2 of Non-parametric tests for beginners
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@jaekim8080?source=post_page-----5fd9b092e7a6--------------------------------)[![Jae
    Kim](../Images/34716958ecfe8c0540f5cf5c1640d587.png)](https://medium.com/@jaekim8080?source=post_page-----5fd9b092e7a6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5fd9b092e7a6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5fd9b092e7a6--------------------------------)
    [Jae Kim](https://medium.com/@jaekim8080?source=post_page-----5fd9b092e7a6--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5fd9b092e7a6--------------------------------)
    ·10 min read·Jun 19, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e426ee31bdecd2e830fa13188b8047c3.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Mohamed Nohassi](https://unsplash.com/@coopery?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: In [Part 1](/non-parametric-tests-for-beginners-part-1-rank-and-sign-tests-629704f27f2f?sk=67eea21356f2de5f0a5626a0442df459)
    of this series, I have presented simple rank and sign tests as an introduction
    to non-parametric tests. As mentioned in Part 1, the bootstrap also is a popular
    non-parametric method for statistical inference, based on re-sampling of observed
    data. It has gained a wide popularity (especially in academia), since [Bradley
    Efron](https://scholar.google.com/citations?user=duBlF_YAAAAJ&hl=en) first introduced
    in the 1980’s. [Efron and Tibshirani (1994)](https://www.taylorfrancis.com/books/mono/10.1201/9780429246593/introduction-bootstrap-bradley-efron-tibshirani)
    provide an introductory and comprehensive survey of the bootstrap method. Its
    application has been extensive in the fields of statistical science, with the
    above book attracting more than 50,000 Google Scholar citations to date.
  prefs: []
  type: TYPE_NORMAL
- en: In this post, I present the bootstrap method for beginners in an intuitive way,
    with simple examples and R code.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned in Part 1, the key elements of hypothesis testing include
  prefs: []
  type: TYPE_NORMAL
- en: The null and alternative hypotheses (H0 and H1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test statistic
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sampling distribution of the test statistic under H0
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Decision rule (p-value or critical value, at a given level of significance)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In generating the sampling distribution of a test statistic,
  prefs: []
  type: TYPE_NORMAL
- en: the *parametric tests* (such as the t-test or F-test) assume that the population
    follows a normal distribution. If the population is non- normal, then a normal
    distribution is used as an approximation to the sampling distribution, by virtue
    of the central limit theorem (called asymptotic normal approximation);
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the *rank and sign tests* use rank and signs of the data points to generate
    the *exact* sampling distribution, as discussed in Part 1;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the *bootstrap* generates or approximate the sampling distribution of a statistic,
    based on resampling the observed data (with replacement), in a similar way where
    the samples are taken randomly and repeatedly from the population.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As with the rank and sign tests, the bootstrap does not require normality of
    the population or asymptotic normal approximation based on the central limit theorem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In its basic form, the bootstrap requires pure random sampling from a population
    of fixed mean and variance (without normality), although there are the bootstrap
    methods applicable to dependent or heteroskedastic data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this post, the basic bootstrap method for the data generated randomly from
    a population is presented with examples. For the bootstrap methods for more general
    data structure, their brief details and R resources are presented in a separate
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Toy Examples for the bootstrap
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Example 1: X = (1, 2, 3)**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Suppose a researcher observes a data set X = (1, 2, 3) with the sample mean
    of 2 and standard deviation (*s*) of 1\. Assuming a normal population, the sampling
    distribution of the sample mean (Xbar) under H0: μ = 2 is'
  prefs: []
  type: TYPE_NORMAL
- en: where *s* = 1 and μ is the population mean. This means that, under normal approximation,
    the sample mean follows a normal distribution with mean 2 and and variance of
    1/3.
  prefs: []
  type: TYPE_NORMAL
- en: The bootstrap resamples the observed data X = (1, 2, 3) with replacement, giving
    equal probability of 1/3 to its members. Table 1 below presents all 27 possible
    outcomes of these resamples (or pseudo-data) X* = (X1*, X2*, X3*) with the mean
    values from each outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ae43241dd014dfd53ae618dbc10bc9ad.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 1: Sampling with Replacement from X (Image Created by the Author)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The mean of these 27 outcomes is 2 and the variance is 0.23\. The distribution
    of the sample means from these X*’s represents the exact bootstrap distribution,
    which are plotted in Figure 1 below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/281656f241bfd39a1f6706c8216387b3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Exact bootstrap distribution and its density estimate (Image Created
    by the Author)'
  prefs: []
  type: TYPE_NORMAL
- en: The bar plot on the left shows the exact bootstrap distribution, while the kernel
    density estimates of the bootstrap distribution (in red) is plotted along with
    the normal distribution with the mean 2 and variance 1/3 (in black).
  prefs: []
  type: TYPE_NORMAL
- en: '**Example 2: X = (1, 2, 6)**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now consider the case where X = (1, 2, 6) with the sample mean 3 and and *s*
    = 2.65\. Similar calculation as in Table 1 shows that the mean of the X* is 3
    with the variance of 1.62\. The exact bootstrap distribution is plotted in Figure
    2 below, along with a kernel density estimate (in red), which shows a clear departure
    from the normal distribution with the mean 3 and variance of *s*²/n (in black).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/231020ee34a883157a357b9cf38cf396.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Exact bootstrap distribution and its density estimate (Image Created
    by the Author)'
  prefs: []
  type: TYPE_NORMAL
- en: 'From these two examples, we can state the following points:'
  prefs: []
  type: TYPE_NORMAL
- en: Example 1 is the case where the data set X is exactly symmetric around its mean.
    The bootstrap sampling distribution for the sample mean is also symmetric, well
    approximated by a normal distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Example 2 is the case where the data set X is asymmetric around its mean, which
    is well-reflected in the shape of the bootstrap sampling distribution. However,
    the normal distribution is unable to reflect this asymmetry.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given that the population distribution is unknown in these examples, it is difficult
    to assess whether bootstrap distribution is a better representation of the true
    sampling distribution of the sample mean.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, we observe that the bootstrap has ability to reflect possible asymmetry
    in the population distribution, which asymptotic normal approximation is unable
    to capture.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that the bootstrap is able to capture many non-normal properties of a population,
    such as asymmetry, fat-tail, and bi-modality, which cannot be captured by a normal
    approximation.
  prefs: []
  type: TYPE_NORMAL
- en: Many academic studies that compare the bootstrap and asymptotic normal approximation
    provide strong evidence that the bootstrap in general performs better, in capturing
    the features of the true sampling distribution, especially when the sample size
    is small. They report that, as the sample size increases, the two methods show
    similar properties, which means that the bootstrap should in general be preferred
    when the sample size is small.
  prefs: []
  type: TYPE_NORMAL
- en: Bootstrapping for X = (X1, …, Xn)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The above toy examples present the case where n = 3, where we are able to obtain
    the exact bootstrap distribution for all 27 possible resamples. Noting that the
    number of all possible resamples is nⁿ, calculating the exact bootstrap distribution
    with nⁿ resamples as above may be too computationally burdensome, for a general
    value of n. However, this process is not necessary, because a Monte Carlo simulation
    can provide a fairly accurate approximation to the exact bootstrap distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose the data X is obtained randomly from a population with fixed mean and
    variance. Suppose the statistic of interest, such as the sample mean or t-statistic,
    is denoted as T(X). Then,
  prefs: []
  type: TYPE_NORMAL
- en: we obtain X* = (X₁*, …, Xₙ*) by resampling with replacement from X, purely randomly
    giving the equal probability to each member of X.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since we cannot do this for all possible nⁿ resamples, we repeat the above sufficiently
    many times B, such as 1000, 5000, or 10000\. By doing this, we have B different
    sets of X*, which can be written as {X*(i)}, where i = 1, …, B.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From each X*(i), the statistic of interest [T(X*)] is calculated. Then we have
    {T(X*,i)} (i = 1,…., B), where T*(X*,i) is T(X*) calculated from X*(i).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The bootstrap distribution {T(X*,i)} is used as an approximation to the exact
    bootstrap distribution, as well as to the unknown sampling distribution of T.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, I have generated X = (X1, …, X20) from
  prefs: []
  type: TYPE_NORMAL
- en: the F-distribution with 2 and 10 degrees of freedom [F(2,10)],
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: chi-squared with 3 degrees of freedom [chisq(3)],
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Student-t with 3 degrees of freedom [t(3)], and
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: log-normal distribution with mean 0 and variance 1 (lognormal).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figure 3 below plots the density estimates of {T(X*,i)}(i = 1,…., B), where
    T is the mean and B = 10000, in comparison with the densities of the normal distribution
    with the mean and variance values corresponding to those of X. The bootstrap distributions
    can be different from the normal distribution, especially when the underlying
    population distribution departs substantially from a normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f67d5f5c31ecb848f5c713034b0542cb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Bootstrap Distribution (red) vs. Normal Distribution (black) (Image
    Created by the Author)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The R code for the above Monte Carlo simulations and plots are given below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The bootstrap test and analysis are conducted based on the red curves above,
    which are {T(X*,i)}, instead of normal distributions in black.
  prefs: []
  type: TYPE_NORMAL
- en: Inferential statistics such as the confidence interval or p-value are obtained
    from {T(X*,i)}, in the same way as we do using a normal distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bootstrap distribution can reveal further and more detailed information, such
    as the symmetry, fat-tail, non-normality, bi-modality, and presence of outliers,
    regarding the properties of the population.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suppose T(X) is the sample mean as above.
  prefs: []
  type: TYPE_NORMAL
- en: The *bootstrap confidence interval* for the population mean can be obtained
    by taking appropriate percentiles of {T(X*,i)}. For example, let {T(X*,i;θ)} be
    the θth percentile of {T(X*,i)}. Then, the 95% bootstrap confidence interval obtained
    as the interval [{T(X*,i;2.5)},{T(X*,i;97.5)}].
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose T(X) is the t-test statistic for H0: μ = 0 against H0: μ > 0\. Then,
    the *bootstrap p-value* is calculated as the proportion of {T(X*,i)} greater than
    the T(X) value from the original sample. That is, the p-value is calculated analogously
    to the case of normal distribution, depending on the structure of H1.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4836977bd791a9f0a4b832cbac68f7a1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 2: Bootstrap vs. Normal 95% Confidence Intervals (Image Created by the
    Author)'
  prefs: []
  type: TYPE_NORMAL
- en: Table 2 above presents the bootstrap confidence interval in comparison with
    asymptotic normal confidence interval, both with 95% confidence. The two alternatives
    provide the similar intervals when the population distribution is t(3) or chisq(3),
    but they can be quite different when the population follows F(2,10) or lognorm
    distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Bootstrapping t-test in R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The bootstrap method can be applied to one-sample and two-sample t-tests. In
    this case, the test statistic of interest T(X) is the t-test statistics, and its
    bootstrap distribution can be obtained as above. In R, the package “[MKinfer](https://cran.r-project.org/web/packages/MKinfer/index.html)”
    provides the functions for the bootstrap tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us consider X and Y in the example used in Part 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are summarized in the table below (all tests assuming two-tailed
    H1):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f00ff6194737be2061b028ff5ddae355.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 3: 95% Confidence Intervals and p-values (Image Created by the Author)'
  prefs: []
  type: TYPE_NORMAL
- en: To test for μ(X) = 0, the sample mean of X is 0.19 and the t-statistic is 0.93\.
    The bootstrap and asymptotic confidence intervals and p-values provide similar
    inferential outcomes of failure to reject H0, but the bootstrap confidence interval
    is tighter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To test for μ(Y) = 1, the sample mean of Y is 1.99 and the t-statistic is 2.63\.
    The bootstrap and asymptotic confidence intervals and p-values provide similar
    inferential outcomes of rejecting H0 at he 5% significance level, but the bootstrap
    confidence interval is tighter with a lower p-value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To test for H0: μ(X) — μ(Y) = — 1, the mean difference between X and Y is -1.80
    and the t-statistic is -1.87\. The bootstrap and asymptotic confidence intervals
    and p-values provide similar inferential outcomes of rejecting H0 at the 10% significance
    level.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bootstrap methods for more general data structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As mentioned above, the bootstrap methods also have been developed for linear
    regression model, time series forecasting, and for the data with more general
    structures. Several important extensions of the bootstrap methods are summarized
    below:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the linear regression model, the bootstrap can be conducted by resampling
    the residuals or by resampling the cases: see the “[car](https://socialsciences.mcmaster.ca/jfox/Books/Companion/appendices/Appendix-Bootstrapping.pdf)”
    package in R.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The bootstrap can be applied to time series forecasting based on autoregressive
    model: see “[BootPR](https://cran.r-project.org/web/packages/BootPR/BootPR.pdf)”
    package in R.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For time series data with unknown structure of serial dependence, the [stationary
    bootstrap](https://users.ssc.wisc.edu/~bhansen/718/Politis%20Romano.pdf) (or moving
    block bootstrap) may be used. This involves resampling blocks of time series observations.
    The R package “[tseries](https://search.r-project.org/CRAN/refmans/tseries/html/tsbootstrap.html)”
    provides a function for this method.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For data with heteroskedasticity of unknown form, the [wild bootstrap](https://www.sciencedirect.com/science/article/abs/pii/S0304407608000833)
    can be used, using the R package “[fANCOVA](https://www.rdocumentation.org/packages/fANCOVA/versions/0.6-1/topics/wild.boot)”.
    It resamples the data by scaling with a random variable with zero mean and unit
    variance so that the heteroskedastic structure is effectively replicated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This post has reviewed the bootstrap method as a non-parametric test where repetitive
    resampling of the observed data is used as a way of calculating or approximating
    the sampling distribution of a statistic. Although only the bootstrap method for
    confidence interval and p-value for the test for the population mean are covered
    in this post, application of the bootstrap is extensive, ranging from regression
    analysis to time series data with unknown dependence structure.
  prefs: []
  type: TYPE_NORMAL
- en: Many academic studies have reported the theoretical or computational results
    that the bootstrap test often outperforms the asymptotic normal approximation,
    especially when the sample size is small or moderate.
  prefs: []
  type: TYPE_NORMAL
- en: Hence, in small samples, researchers in statistical and machine learning are
    strongly recommended to use the bootstrap as a useful alternative to the conventional
    statistical inference based on asymptotic normal approximation.
  prefs: []
  type: TYPE_NORMAL
