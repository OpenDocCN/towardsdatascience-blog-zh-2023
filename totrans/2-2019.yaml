- en: The Good, The Bad, and the Ugly of Pd.Get_Dummies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/the-good-the-bad-and-the-ugly-of-pd-get-dummies-75c87e2aadc9](https://towardsdatascience.com/the-good-the-bad-and-the-ugly-of-pd-get-dummies-75c87e2aadc9)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is for the pd.get_dummies diehards
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://adamrossnelson.medium.com/?source=post_page-----75c87e2aadc9--------------------------------)[![Adam
    Ross Nelson](../Images/030b86a8c8bbd40c6acf60d1e387950c.png)](https://adamrossnelson.medium.com/?source=post_page-----75c87e2aadc9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----75c87e2aadc9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----75c87e2aadc9--------------------------------)
    [Adam Ross Nelson](https://adamrossnelson.medium.com/?source=post_page-----75c87e2aadc9--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----75c87e2aadc9--------------------------------)
    ¬∑5 min read¬∑Jul 26, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Howdy folks ü§†
  prefs: []
  type: TYPE_NORMAL
- en: Okay, I get it. One of the easiest ways to convert a categorial to an array
    of dummies in Python is with the Pandas `pd.get_dummies()`. Why would you take
    the time to import `OneHotEncoder`from sklearn, execute a `.fit_transform()` etc,
    etc, etc? Talk about tedious!
  prefs: []
  type: TYPE_NORMAL
- en: This article will first introduce a simple data set for demonstration purposes
    that consists of a testing set that contains categoricals not found in the training
    set. Then, it will demonstrate how using `pd.get_dummies()` can lead to problems
    with the demonstration data. And, finally show how to avoid that problem with
    sklearn‚Äôs `OneHotEncoder`.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fa8e91379f5a2edc4d962a235f228a29.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image Credit: Author‚Äôs illustration using text to image in Canva. Prompted:
    ‚ÄúThree panda bears dressed as country western cowboys.‚Äù'
  prefs: []
  type: TYPE_NORMAL
- en: A simple dataset for demonstration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here we have a simple dataset that includes a categorical feature called OS.
    The OS column lists computer operating systems. We will use this fictional data
    for purposes of demonstration. In `train_df` will be fictional demonstration training
    data. While in `test_df` we have fictional demonstration testing data.
  prefs: []
  type: TYPE_NORMAL
- en: In our fictional demonstration case, the testing set contains categorical values
    not present in the training set. This mis-match will cause problems.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In our training data, we have three operating systems: Windows, MacOS, and
    Linux. But in our testing data, we have the additional categories including Android,
    Unix, and iOS.'
  prefs: []
  type: TYPE_NORMAL
- en: A model ‚Äòfit‚Äô on `pd.get_dummies(train_df)` will not work with with testing
    data from `pd.get_dummies(test_df)` . The results will not match ‚Äî because of
    the mis-matched categories.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/928ac32f04f9d59aa60f5d4c932fcc7f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image Credit: Author‚Äôs illustration created in Canva using Canva stock images.
    An art supply dummy.'
  prefs: []
  type: TYPE_NORMAL
- en: The Problem with pd.get_dummies()
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When applying the `pd.get_dummies()` function to both our training and testing
    datasets here is what you‚Äôll get.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: If you evaluate the `train_encoded` and `test_encoded` DataFrames, you'll notice
    that they do not have the same number of columns. This is because the 'Android'
    category, present only in the testing set, has created an additional column in
    `test_encoded`. This inconsistency in the number of features between training
    and testing datasets can cause significant problems when building and evaluating
    machine learning models, which expect the same feature space in both datasets.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/380c309a5fac4b5da8a646a4858c2347.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image Credit: Author‚Äôs screen grabs, produced with code shown here.'
  prefs: []
  type: TYPE_NORMAL
- en: The Solution with OneHotEncoder
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, let‚Äôs see how `OneHotEncoder` from sklearn solves this problem. When using
    `OneHotEncoder`, the encoder learns the categories during the `.fit()` or `.fit_transform()`
    method on the training data. Then, during the `.transform()` method, it creates
    columns for all learned categories. If a new category is found in the testing
    data there are two options. First you can ignore the new unseen categories.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Note that we set `handle_unknown='ignore'` to tell the encoder to ignore (rather
    than throw an error for) any category in the testing set that it didn't see in
    the training set.
  prefs: []
  type: TYPE_NORMAL
- en: Also note, new as of 2023, sklearn offers a `.set_output(transform="pandas")`
    option that will ensure the encoder returns a Pandas DataFrame (complete with
    easier to read and interpret column names) instead of a the more minimalist NumPy
    array.
  prefs: []
  type: TYPE_NORMAL
- en: By handling unknown categories with `handle_unknown='ignore'`, `OneHotEncoder`
    ensures that the training and testing data have the same feature space, regardless
    of what categorical values appear in the testing data.
  prefs: []
  type: TYPE_NORMAL
- en: The Additional Benefits of OneHotEncoder
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sklearn‚Äôs `OneHotEncoder` is not only super helpful for handling unseen categories
    in your testing data; it also provides additional functionality that can also
    be useful. Her are two of these additional options and how to use them.
  prefs: []
  type: TYPE_NORMAL
- en: min_frequency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `min_frequency` is another powerful option that allows you to specify a
    minimum frequency threshold. Categories with a frequency below this threshold
    get recoded as ‚Äúinfrequent.‚Äù This could be useful when you have categories that
    only appear a few times and may not offer enough information to help the model
    and that may only serve to over-complicate the model with unhelpful features that
    undermine performance without adding any predictive value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here‚Äôs how you can set a `min_frequency` of 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: max_categories
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Also useful is `max_categories`. The `max_categories` argument allows you to
    limit the number of output columns in the dummy array. The encoder will take the
    most frequent categories for encoding.
  prefs: []
  type: TYPE_NORMAL
- en: This option is beneficial and helpful when dealing with features that have many
    categories which would ordinarily result in a high number of dimensions. Possibly
    high enough to significantly reduce training efficiency while increasing model
    complexity all while returning very little value in the form of higher predictive
    power. In short this reduces the dimensionality of your data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here‚Äôs how to limit the encoding to the top 4 most frequent categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the grander scheme of things, using `pd.get_dummies()` instead of a true
    fit and transform procedure, there are worse sins in the field of data science.
    However, if you have been holding out as a diehard for `pd.get_dummies()` now
    you know the good, the bad and the ugly ‚Äî after reading this article, you should
    consider shifting your practice.
  prefs: []
  type: TYPE_NORMAL
- en: While `pd.get_dummies()` can be a quick and easy way to create dummy variables
    in Python, it can lead to problems when your testing data contains categories
    not seen in your training data. On the other hand, sklearn's `OneHotEncoder` handles
    this scenario elegantly, ensuring consistent feature spaces across datasets. It's
    worth the extra lines of code to avoid potential pitfalls down the line.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks For Reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Are you ready to learn more about careers in data science? I perform one-on-one
    career coaching and have a weekly email list that helps data professional job
    candidates. [Contact me to learn more](https://coaching.adamrossnelson.com/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Thanks for reading. Send me your thoughts and ideas. You can write just to
    say hey. And if you really need to tell me how I got it wrong I look forward to
    chatting soon. Twitter: [@adamrossnelson](https://twitter.com/adamrossnelson)
    LinkedIn: [Adam Ross Nelson](https://www.linkedin.com/in/arnelson/).'
  prefs: []
  type: TYPE_NORMAL
