# 多任务机器学习：同时解决多个问题

> 原文：[https://towardsdatascience.com/multi-task-learning-4531eb32d77b](https://towardsdatascience.com/multi-task-learning-4531eb32d77b)

## 在自然语言处理和计算机视觉中，有些是监督的，有些是无监督的，有些是自监督的。

[](https://jagota-arun.medium.com/?source=post_page-----4531eb32d77b--------------------------------)[![Arun Jagota](../Images/3c3eb142f671b5fb933c2826d8ed78d9.png)](https://jagota-arun.medium.com/?source=post_page-----4531eb32d77b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4531eb32d77b--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4531eb32d77b--------------------------------) [Arun Jagota](https://jagota-arun.medium.com/?source=post_page-----4531eb32d77b--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4531eb32d77b--------------------------------) ·阅读时间 11 分钟·2023年4月27日

--

![](../Images/f245371498b59c216924e720580c26fd.png)

图片由 [Gerd Altmann](https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3685928) 提供，来源于 [Pixabay](https://pixabay.com/)

*单任务学习*是从标记数据集中学习预测单一结果（二元、多类别或连续）的过程。

相比之下，*多任务学习*是指在相同模态的输入上联合学习以预测多个结果的过程。例如图像或文本。

显而易见的问题是，为什么要*联合*学习？为什么不独立学习单任务模型来预测各种结果？

答案是，联合学习可以学习到在多个任务之间更好地泛化的特征。那些能够作为多个任务的良好预测器的特征会比那些不能的特征更受青睐。这些学习到的特征甚至可能在相同领域的新预测任务中进行泛化。

**将无监督学习添加到其中**

到目前为止，我们假设多任务设置中的所有选择任务都是监督性质的。让我们放宽这一假设，允许一些任务为无监督任务。

为什么？因为我们可能有更多的数据可以进行训练。一些是用于各种结果的标记数据，还有很多未标记数据。将无监督任务添加到联合学习中可以让我们从更大规模的数据集中进行学习。

我们实际上可以通过实证测试这个假设。我们可以保留一部分标记数据集，并进行两个实验：一个是在其余标记数据上训练，另一个是在其余标记数据和大量未标记数据的组合上训练。然后，我们可以比较这两个实验中学习到的模型在保留（标记）测试集上的质量。

事实上，从标记和未标记数据的混合中学习的概念已经有了一个名称，称为半监督学习。

**将无监督学习精细化为自监督学习**

虽然允许一些任务为无监督任务使我们能够使用潜在的大量未标记数据，但我们能否更好地利用未标记数据？一般的回答是肯定的。使用自监督。

在自监督中，我们定义监督任务，以从其余数据中预测数据的某些特征。例如，我们可能会预测从先前看到的单词中出现的下一个单词。

自监督比无监督学习更强大，因为它是有监督的。此外，它从所有未标记的数据中学习，因为它不需要人工标记。最后，自监督是获得大量多样化标记数据的强大机制，无需人工工作。在计算机视觉和自然语言处理部分，我们将提供简洁且现实的例子，揭示我们如何构建多样化的标记数据集，并且这种方法如何提高学习能力，相较于完全不进行自监督。

在本文中，当我们说多任务学习时，我们真正指的是至少有两个监督学习任务的学习，可能还有额外的无监督学习任务，以及可能的额外自监督任务。

我们在下面以视觉方式展示了这一点。

![](../Images/5f7ca4da8fb3370d1c25a86634908858.png)

图1：（作者提供）某种模态的数据的维恩图。实心圆表示用于各种监督任务的标记子集。虚线圆圈表示用于各种自监督任务的自标记子集。

请注意，此图仅描绘了输入数据的子集，涵盖了各种监督和自监督任务，而不是不同任务标签之间的关系。

图1也描绘了

+   标记用于各种监督任务的数据子集往往较小。

+   添加自监督任务可以覆盖更多的数据。这些子集通常可以做得更大。

+   监督任务的子集可以相互重叠，但通常不完全相同。

**放宽本文中“联合学习”一词的定义**

到目前为止，我们给人的印象是联合学习意味着从所有任务的所有可用数据中同时学习一个模型。

实际上，我们希望放宽这一点以允许更灵活的训练策略。这是因为在实践中，发现首先从未标记数据中学习自监督（以及可能的无监督）任务，然后进一步调整这些模型以进行特定的下游监督任务是有效的。这种方法的一种更灵活的方式是，它自然允许在实时定义新的监督任务并根据需要微调现有模型。

**关于多任务学习的数据**

我们需要多个标记数据集，每个数据集用于预测一个结果。这些数据集中的输入通常来自相同领域。实际输入在数据集中可能会有所不同，因为它们通常来自不同来源。

我们可能还有未标记的数据。只要我们合理地相信这些数据会有帮助，就应该将其用于适当的无监督任务。如前一节所述，我们可以在决定之前通过实证测试我们的信念。如果适当的话，我们还应定义适合的自我监督任务，以便利用和学习从其他数据中预测未标记数据的某些特征。

多任务学习在自然语言处理和计算机视觉中尤其有用。我们将逐一讨论这两个领域。

**计算机视觉中的多任务学习**

想象一下，我们有手写数字、汽车、人脸图像、宠物图像等标签图像。还假设这些数据集中有些是小的。

为每个任务单独构建单任务模型的风险在于我们可能没有足够丰富的标记数据。

将所有数据集结合起来，学习一个单一的多任务模型，可能有助于缓解上述特定任务数据稀疏的问题，只要一些共同学习的特征也有助于这些任务。

思路是图像就是图像，在某些足够低的层次上，某些特征可能对多个任务的结果具有预测性，比如边缘或循环。

**在这种情况下无监督任务的价值**

我们之前提到，在多任务学习中加入适当的无监督任务是有益的。我们将在图像的设置中进一步阐明这一点。

网络上有数十亿张图像，大多数是未标记的。假设我们有一些特定任务的标记图像，比如预测图像中是否有建筑物。

直觉上，使用大量未标记图像进行无监督学习可以帮助发现比仅使用标记图像更好的特征，比如更好的边缘和更好的循环。

**未标记数据上的自监督学习任务**

如前一节所述，通常有大量的未标记图像数据。数十亿张图像。在前一节中，我们关注了半监督学习。即除了这些未标记图像外，我们还拥有一些用于特定任务的标记图像。我们希望从未标记图像中以无监督方式学习，从标记图像中以监督方式学习。

引入自监督学习可以大大提升这种方法。这是因为合适的自监督任务迫使模型学习从其他特征预测图像的一些特征。这通常可以轻松地产生大量标记数据，而不需要人工付出任何努力。

**一些特定形式的自监督**

以下是一些通常适用于图像数据的自监督的具体形式。

**掩盖某些区域**

取一张图像并模糊掉某些整个区域。创建一个新实例，其中模糊的图像是输入，原始实例是其标签。

为了激发我们对这种方法如何帮助的想象，假设我们有一些人的图像，有些人戴着帽子，有些人没有。如果我们以某种方式掩盖所有人的脸，我们可能会学到帽子下方是人的头，但反过来就不一定，即不是所有头上都有帽子。

这引出了一个问题，我们如何确定要掩盖哪些内容？我们将以不同的角度来看待这个问题。我们不尝试优化掩盖，而是建议考虑将图像分割成一定尺寸的矩形网格，并创建每个实例中掩盖一个单一网格的情况。通过选择网格的细粒度，我们可以控制从任何一个图像中获得多少被破坏的实例。

然后我们可以自动化发现哪些被破坏的图像可以被很好地重建。我们甚至可以检验这种自监督是否提高了一个或多个下游监督任务的准确性。

**去色图像**

通过将彩色图像变为灰色，我们可以迫使模型学习从剩余属性中尝试重建颜色。例如，它可能会学到，停牌通常是红色的，因为它们有独特的形状，甚至上面还写着*Stop*。

**降低分辨率**

我们可以降低图像的分辨率，并让模型尝试重建原始图像。这可能迫使模型在可能的情况下学习填补细节。作为一个想象中的生动例子，模型可能会学会填补人脸的某些细节，比如睫毛。

**NLP中的多任务学习**

考虑一个文本句子。我们可能会对标记每个词的词性、标记某些段落为命名实体以及标记某些段落为名词短语或动词短语感兴趣。

在单任务学习中，每个任务都会被独立处理。

在多任务学习中，我们会学习一个具有共享特征的模型，同时处理所有这些任务。当任务之间有协同作用时，这可以产生更好的模型。例如，学习预测句子中每个词的词性可能有助于检测命名实体、名词短语和动词短语。

**在未标记数据上添加合适的任务**

可能有很多句子没有标签。没有标签意味着没有词性标注，没有命名实体标注，也没有名词或动词短语标注。

我们应该考虑定义自监督学习任务，即根据目前为止看到的词来预测句子中的下一个词。这个任务可以以强大的方式利用未标记的数据。预测下一个词可以促使网络学习前面词的复杂表示。

更一般地说，定义自监督学习任务来预测句子中剩余的某些被屏蔽的词可能会很有用。我之所以说“更一般地”，是因为这些词可以出现在句子的任何地方。

这是一个例子。考虑

> 阳光暴露会导致皮肤癌。

我们可能考虑预测的三个被屏蔽的实例在下面两个填空场景中展示。

> _____ 导致皮肤癌。
> 
> 阳光暴露会导致______。
> 
> _ 到 _ 导致皮肤癌

在第一个场景中，我们根据其余部分预测句子的左尾。在第二个场景中，我们根据其余部分预测句子的右尾。第三个场景展示了可以有多个不连续的被屏蔽子序列需要预测。

**预测被屏蔽词背后的直觉**

为什么要从预测下一个词扩展到预测任何被屏蔽的词的子序列？简短的回答是：（i）这大大扩展了可用于训练的标记数据集，（ii）并且有助于在新标记的实例中呈现新类型的场景。

为了提高我们对（i）的直觉，想象一下我们为由 *n* 个词组成的句子的所有可能屏蔽生成被屏蔽的标记实例。屏蔽的数量大约是 2^*n*。相比之下，将句子切分以预测未来的词的方式大约是 *n* 种。

为了详细说明（ii），通过允许屏蔽出现在任何地方，我们允许模型发现潜在地比从左到右限制的关系更一般的预测关系。为了想象这一点，假设我们在语料库中有很多 *X 导致 Y* 的实例。同时，假设只有 *X* 导致 *Y*。如果 *X* 被屏蔽，模型可以从数据中学习到只有 *X* 导致 *Y* 的关系。而从左到右的语言模型不能学习到只有 *X* 导致 *Y*。

**第二个非常简单的例子**

想象一下我们有一个汽车名称的列表。例如

> 本田思域，丰田凯美瑞，福特野马，吉普牧马人。

预测下一个词肯定会帮助模型学习特定品牌的模型。例如*Cherokee*和*Wrangler*（等）对于*Jeep*。然而，以屏蔽任何词的形式进行额外的自监督将帮助模型学习到品牌名称往往能够强烈预测品牌。例如，*Celica* 是 *Toyota* 的，*Mustang* 是 *Ford* 的，*Wrangler* 是 *Jeep* 的，等等。

**特定案例**

这种类型的自监督的两个特殊案例是连续词袋模型（CBOW）和跳字模型[3]。前者对应于在某个数量的左侧和右侧上下文中掩盖中间词。后者则相反——掩盖左侧和右侧的上下文，同时保持中间的词不变。

下面是我们示例中展示的两个。

[PRE0]

另一个被发现有用的自监督任务是下句预测[2]。特别是对于问答系统。在[2]中，这个任务被表述为一个二分类问题。输入（X1，X2）被解释为“句子X1后面跟随句子X2”。正实例是通过语料库中相邻句子的对生成的。负实例是通过将语料库中的一个句子X1与语料库中的随机句子X2配对生成的。

在上述段落的背景下，“句子”一词指的是任何连续的文本序列[2]。因此，从当前段落预测下一个段落也会被视为下句预测问题。

**利用深度架构**

多任务学习可以显著利用深度架构。直觉是这样的。深度架构在靠近输入的层中学习低级特征，而在靠近输出的层中学习高级特征。直觉上认为，学习低级特征的较深层次恰恰是那些可以在任务之间共享的层。

考虑我们的多任务图像分类场景。可以合理推测，像边缘或循环这样的低级特征将在这些任务中的多个任务中成为有用的预测因子。

下面展示了一个深度架构，其中输入层靠近的层由所有监督任务共享，而靠近任务的层则是任务特定的。

![](../Images/e1499550cc1cb9b33d4fe242d30097fb.png)

图2：一个具有共享层的多任务深度架构。（作者提供。）

训练可以通过常规的反向传播算法进行。训练集中的特定实例可能只有一个任务的标签。这个任务的预测与目标之间的误差通过任务特定层反向传播，然后传递到共享层。因此，如果我们混入来自不同任务的实例，共享层会学习到在任务间通用的表示。

**总结**

在这篇文章中，我们涵盖了多任务学习的话题。我们解释了为什么多任务学习可以产生理解和泛化能力比单独学习每个任务的模型更好的模型。当我们将无监督和自监督任务加入混合时，这种方法尤为强大。这些任务使我们能够从未标记的数据中学习很多。

我们还涵盖了计算机视觉和自然语言处理中的多任务学习。在这些设置中，我们讨论了具体的监督任务、可用数据的性质以及具体的自监督方法。

**进一步阅读**

1.  [https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/](https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/)

1.  [https://arxiv.org/pdf/1810.04805.pdf](https://arxiv.org/pdf/1810.04805.pdf)

1.  [https://arxiv.org/pdf/1301.3781.pdf](https://arxiv.org/pdf/1301.3781.pdf)

1.  [https://arxiv.org/pdf/2103.01988.pdf?fbclid=IwAR2pqhYda6MV9r2b3Afx_0eKUiZhX-Es6Pa_FbLOqH8fglQzO2kY3yKxZE8](https://arxiv.org/pdf/2103.01988.pdf?fbclid=IwAR2pqhYda6MV9r2b3Afx_0eKUiZhX-Es6Pa_FbLOqH8fglQzO2kY3yKxZE8)
