["```py\n{\"model_purpose\" : \"predicts the quality of wine using wine attributes\",\n\n\"model_flavor\" : [\"python_function\",\"sklearn\"],\n# The python_function model flavor serves as a default model interface for MLflow Python models. \n# Any MLflow Python model is expected to be loadable as a python_function model.\n# This enables other MLflow tools to work with any python model regardless of \n# which persistence module or framework was used to produce the model.\n\n\"model_algorithm\" : \"sklearn.linear_model.ElasticNet\",\n\n{\"model_signature\" :\n\"model_input_schema\":[\n{\"name\": \"fixed acidity\", \"type\": \"string\"}, \n{\"name\": \"volatile acidity\", \"type\": \"string\"}, \n{\"name\": \"citric acid\", \"type\": \"string\"}, \n{\"name\": \"residual sugar\", \"type\": \"string\"},\n{\"name\": \"chlorides\", \"type\": \"string\"},\n{\"name\": \"free sulfur dioxide\", \"type\": \"string\"},\n{\"name\": \"total sulfur dioxide\", \"type\": \"string\"},\n{\"name\": \"density\", \"type\": \"string\"},\n{\"name\": \"pH\", \"type\": \"string\"},\n{\"name\": \"sulphates\", \"type\": \"string\"},\n{\"name\": \"alcohol\", \"type\": \"string\"}],\n\n\"model_output_schema\" [\n{\"type\": \"tensor\", \"tensor-spec\": {\"dtype\": \"float64\", \"shape\": [-1]}}\n]\n},\n\n\"model_registry_location\" : \"runs:/<RUN_ID>/<MODEL_NAME>\", \n# If you are using mlflow to manage the lifecycle of your models,\n# the model is loggged as an artifact in the current run using MLflow Tracking\n\n\"model_stage\" : \"Production\",\n# With mlflow, you can transition a registered model to one of the stages: \n# Staging, Production or Archived.\n# In the demo of this article, the model is alreay transitioned to the \"production\" stage.\n\n\"model_owner\" : \"<MODEL_OWNER_EMAIL/MODEL_OWNER_GROUP_EMAIL>\"\n\n}\n```", "```py\nStructType([\nStructField('fixed acidity', StringType(), True), \nStructField('volatile acidity', StringType(), True), \nStructField('citric acid', StringType(), True), \nStructField('residual sugar', StringType(), True), \nStructField('chlorides', StringType(), True), \nStructField('free sulfur dioxide', StringType(), True), \nStructField('total sulfur dioxide', StringType(), True), \nStructField('density', StringType(), True), \nStructField('pH', StringType(), True), \nStructField('sulphates', StringType(), True), \nStructField('alcohol', StringType(), True), \nStructField('quality', StringType(), True)\n])\n```", "```py\nstreamingDF = (spark \n    .readStream\n    .option(\"sep\",\",\")     \n    .option(\"header\", \"True\") \n    .option(\"enforceSchema\", \"True\")\n    .schema(csvSchema) \n    .csv(<YOUR-CSV-DATA-LOCATION>))\n```", "```py\nimport mlflow\n\nlogged_model = 'runs:/<RUN_ID>/<MODEL_NAME>'\n\n# Load model as a Spark UDF. \n# Override result_type if the model does not return double values.\nloaded_model = mlflow.pyfunc.spark_udf(spark, model_uri=logged_model, result_type='double')\n```", "```py\n# Predict on a Spark DataFrame.\nfrom pyspark.sql.functions import struct, col\n\nstreamingDF.withColumn('predictions', loaded_model(struct(*map(col, streamingDF.columns))))\n```", "```py\nimport mlflow\nfrom pyspark.sql.functions import struct, col\nfrom pyspark.sql.types import StructType\n```", "```py\nlogged_model = 'runs:/<RUN_ID>/<MODEL_NAME>'\nloaded_model = mlflow.pyfunc.spark_udf(spark, model_uri=logged_model, result_type='double')\ncheckpointLocation = <STREAMING_CHECKPOINT_LOCATION>\ndeltaLocation = <PREDICTION_STORAGE_LOCATION>\n```", "```py\nstreamingDF = (spark \n    .readStream\n    .option(\"sep\",\",\")     \n    .option(\"header\", \"True\") \n    .option(\"enforceSchema\", \"True\")\n    .schema(csvSchema) \n    .csv(<YOUR-CSV-DATA-LOCATION>)\n    .withColumn('predictions', loaded_model(struct(*map(col, streamingDF.columns)))))\n```", "```py\n(streamingDF.writeStream \n    .format(\"delta\")\n    .outputMode(\"append\") # .outputMode(\"complete\"), .outputMode(\"update\")\n    .option(\"checkpointLocation\",checkpointLocation)\n    .option(\"path\", deltaLocation)\n    .trigger(processingTime='5 minutes') # trigger(availableNow=True), .trigger(once=True), .trigger(continuous='1 second')\n    .queryName(\"streaming csv files\")\n    .start())\n```"]