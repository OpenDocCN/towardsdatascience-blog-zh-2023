- en: How to Implement Hierarchical Clustering for Direct Marketing Campaigns— with
    Python Code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-implement-hierarchical-clustering-for-direct-marketing-campaigns-with-python-code-ef897f52d1c5](https://towardsdatascience.com/how-to-implement-hierarchical-clustering-for-direct-marketing-campaigns-with-python-code-ef897f52d1c5)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Understand the ins and outs of hierarchical clustering, and how it applies to
    marketing campaign analysis in the banking industry.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://zoumanakeita.medium.com/?source=post_page-----ef897f52d1c5--------------------------------)[![Zoumana
    Keita](../Images/34a15c1d03687816dbdbc065f5719f80.png)](https://zoumanakeita.medium.com/?source=post_page-----ef897f52d1c5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ef897f52d1c5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ef897f52d1c5--------------------------------)
    [Zoumana Keita](https://zoumanakeita.medium.com/?source=post_page-----ef897f52d1c5--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ef897f52d1c5--------------------------------)
    ·11 min read·Aug 28, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3282ab1d6eae7b1221f28b0d9665653d.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Frederick Warren](https://unsplash.com/@carnations) on [Unsplash](https://unsplash.com/photos/lOg_fQLHo7s)
  prefs: []
  type: TYPE_NORMAL
- en: Motivation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Imagine being a Data Scientist at a leading financial institution, and your
    task is to assist your team in categorizing existing clients into distinct profiles:`low`
    , `average` , `medium` and `platinum` for loan approval.
  prefs: []
  type: TYPE_NORMAL
- en: 'But, here is the catch:'
  prefs: []
  type: TYPE_NORMAL
- en: There is no such historical label attached to these customers, so how do you
    proceed with the creation of these categories?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is where clustering can help, an unsupervised machine-learning technique
    to group unlabeled data into similar categories.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple clustering techniques exist, but this tutorial will focus more on the
    `hierarchical clustering` approach.
  prefs: []
  type: TYPE_NORMAL
- en: It starts by providing an overview of what `hierarchical clustering` is, before
    walking you through a step-by-step implementation in `Python` using the popular
    `Scipy` library.
  prefs: []
  type: TYPE_NORMAL
- en: What is hierarchical clustering?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`Hierarchical clustering` is a technique for grouping data into a tree of clusters
    called dendrograms, representing the hierarchical relationship between the underlying
    clusters.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The hierarchical clustering algorithm relies on distance measures to form clusters,
    and it typically involves the following main steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d6e321eb7c440c1384628f5c89d3497b.png)'
  prefs: []
  type: TYPE_IMG
- en: Four main steps of the hierarchical clustering (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: Computation of the distance matrix containing the distance between each pair
    of data points using a particular distance metric such as Euclidean distance,
    Manhattan distance, or cosine similarity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Merge the two clusters that are the closest in distance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Update the distance matrix with regard to the new clusters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Repeat steps 1, 2, and 3 until all the clusters are merged together to create
    a single cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some graphical illustrations of the hierarchical clustering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before diving into the technical implementation, let’s have an understanding
    of two main hierarchical clustering approaches: `agglomerative` and `divisive`
    clustering.'
  prefs: []
  type: TYPE_NORMAL
- en: '**#1\. Agglomerative clustering**'
  prefs: []
  type: TYPE_NORMAL
- en: Also known as a bottom-up approach, agglomerative clustering starts by considering
    each data point as an individual cluster. It then iteratively merges these clusters
    until only one remains.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s consider the illustration below where:'
  prefs: []
  type: TYPE_NORMAL
- en: We begin by treating each animal as a unique cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then based on the list of animals, three different clusters are formed according
    to their similarities: Eagles and Peacock categorized as `Birds` , Lions and bears
    as `Mammals` , Scorpion and Spiders as `3+ legs`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We continue the merging process to create the `Vertebrate` cluster by combining
    the two most similar clusters: `Birds` and `Mammals`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lastly, the remaining two clusters, `Vertebrate` and `3+ legs`are merged to
    create a single `Animals` cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/029c881105fbde19ccf0088559ef9b26.png)'
  prefs: []
  type: TYPE_IMG
- en: Illustration of the agglomerative clustering (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: '**#2\. Divisive clustering**'
  prefs: []
  type: TYPE_NORMAL
- en: Divisive clustering on the other hand is top-down. It begins by considering
    all the data points as a unified cluster and then progressively splits them until
    each data point stands as a unique cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'By observing the graphic of the divisive approach:'
  prefs: []
  type: TYPE_NORMAL
- en: We notice that the entire `Animal` dataset is considered a unified bloc
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, this block is split into two different clusters: `Vertebrate` and `3+
    legs`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The division process is iteratively applied to the previously created clusters
    until each animal is distinguished as its own unique cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/ca2bdae58ead8064830ae0555950cf0b.png)'
  prefs: []
  type: TYPE_IMG
- en: Illustration of the divisive clustering (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the right distance measure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The choice of an appropriate distance measure is a critical step in clustering,
    and it depends on the specific problem at hand.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, a group of students can be clustered according to their country
    of origin, gender, or previous academic background. While each of these criteria
    is valid for clustering, they convey a unique significance.
  prefs: []
  type: TYPE_NORMAL
- en: The Euclidean distance is the most frequently used measure in many clustering
    software. However other distance measures like Manhattan, Canberra, Pearson correlation,
    and Minkowski distances also exist.
  prefs: []
  type: TYPE_NORMAL
- en: How to measure clusters before merging them
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Clustering might be considered a straightforward process of grouping data. But,
    it is more than that.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three main standard ways to measure the nearest pair of clusters
    before merging them: `(1) single linkage`, `(2) complete linkage`, and `(3) average
    linkage`. Let’s explore each one in more detail.'
  prefs: []
  type: TYPE_NORMAL
- en: '**#1\. Single linkage**'
  prefs: []
  type: TYPE_NORMAL
- en: In the single linkage clustering, the distance between two given clusters `**C1**`
    and `**C2**` corresponds to the minimum distances between all pairs of items in
    the two clusters.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e33f6383a4c9cde530f4dc66bf1135b8.png)'
  prefs: []
  type: TYPE_IMG
- en: Distance formula for single linkage (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: Out of all the pairs of items from the two clusters, `**b**` and `**k**` have
    the minimum distance.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/21d98b7d4045e12a19f634ea858f1024.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Single linkage illustration (Image by Author)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**#2\. Complete linkage**'
  prefs: []
  type: TYPE_NORMAL
- en: For the complete linkage clustering, the distance between two given clusters
    `**C1**` and `**C2**` is the maximum distance between all pairs of items in the
    two clusters.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/034cbf779a83262f179f03e9ca6ec438.png)'
  prefs: []
  type: TYPE_IMG
- en: Distance formula for single linkage (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: Out of all the pairs of items from the two clusters, the ones highlighted in
    green (`**f**` and `**m**`) have the maximum distance.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8c4c45e3f50b77495dfe4e93857e9023.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Complete linkage illustration (Image by Author)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**#3\. Average linkage**'
  prefs: []
  type: TYPE_NORMAL
- en: In the average linkage clustering, the distance between two given clusters `**C1**`
    and `**C2**` is computed using the average of all the distances between each pair
    of items in the two clusters.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f330b8ff9697d4976f3bd94d241a2d44.png)'
  prefs: []
  type: TYPE_IMG
- en: Distance formula for average linkage (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c058c6dea29f61e257ed0c0bb594980b.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Average linkage illustration (Image by Author)*'
  prefs: []
  type: TYPE_NORMAL
- en: '​From the above formula, the average distance can be computed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/96869318a79aec1b19cba846cfe567db.png)'
  prefs: []
  type: TYPE_IMG
- en: Computation of the distance for the average linkage (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Hierarchical Clustering in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now you have an understanding of how hierarchical clustering works, let’s dive
    deep into the technical implementation using `Python`.
  prefs: []
  type: TYPE_NORMAL
- en: We start by configuring the environment, understanding the data along with the
    relevant preprocessing tasks, and lastly applying the clustering.
  prefs: []
  type: TYPE_NORMAL
- en: Configure the environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`[Python](https://www.python.org/downloads/)` is required and needs to be installed
    along with the following libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Pandas` for loading the data frame'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Scikit-learn` for data normalization'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Seaborn and Matplotlib` for data visualization'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Scipy` to apply the clustering'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'All these libraries are installed using the `pip` command as follows from your
    notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Instead of individually installing each library using the `!pip [library]` we
    use the `%%bash` statement instead so that the notebook cell is considered a shell
    command, which ignores the `!` hence facilitates the installation.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We use a subset of the bank marketing campaigns (phone calls) data of a Portuguese
    banking institution.
  prefs: []
  type: TYPE_NORMAL
- en: This dataset is from [UCI](https://archive.ics.uci.edu/dataset/222/bank+marketing)
    and is licensed under a [Creative Commons Attribution 4.0 International](https://creativecommons.org/licenses/by/4.0/legalcode)
    (CC BY 4.0) license.
  prefs: []
  type: TYPE_NORMAL
- en: Due to the unsupervised nature of this tutorial, we get rid of the target column
    `y` column specifying if the client subscribed to a deposit or not.
  prefs: []
  type: TYPE_NORMAL
- en: Using the `head` function only returns the first five entries, which does not
    provide enough information about the structure of the data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/db9c933625656f134e39726a7d8c79ac.png)'
  prefs: []
  type: TYPE_IMG
- en: '*The first five rows of the load data (Image by Author)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, if we use the `info` function, we can have more granular information
    about the dataset such as:'
  prefs: []
  type: TYPE_NORMAL
- en: The total number of entries (4,521) and columns (17)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The name of each column and its type. We can observe that there are two main
    types of columns: `int64` and `object`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The total number of missing values in each column
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/afb6cdf2e0c353909b4c9b9b84508124.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Information about the data (Image by Author)*'
  prefs: []
  type: TYPE_NORMAL
- en: Preprocessing the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Data preprocessing is a major step in every data science task, and clustering
    is not an exception. The main tasks applied to this data include:'
  prefs: []
  type: TYPE_NORMAL
- en: Filling missing values with appropriate information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normalizing the column values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, dropping irrelevant columns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**#1\. Dealing with missing values**'
  prefs: []
  type: TYPE_NORMAL
- en: Missing values can significantly damage the overall quality of the analysis
    and multiple imputation techniques can be applied to efficiently tackle them.
  prefs: []
  type: TYPE_NORMAL
- en: The `percent_missing` reports the percentage of missing value in each column,
    and luckily, there is no missing value in the data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d9dfec3912f70989d3fd142674190146.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Percentage of missing values in the data (Image by Author)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**#2\. Drop irrelevant columns**'
  prefs: []
  type: TYPE_NORMAL
- en: Keeping the `object` columns in the dataset would require more processing tasks
    such as using the relevant encoding technics to encode categorical data into their
    numerical representation.
  prefs: []
  type: TYPE_NORMAL
- en: Only `int64` (numerical) columns are used in the analysis for simplicity’s sake.
    With the `select_dtypes` function, we select the desired column type to preserve.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bb03f127706563e06a274d3ece499adc.png)'
  prefs: []
  type: TYPE_IMG
- en: '*New data without the unwanted columns (Image by Author)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**#3\. Analyze outliers**'
  prefs: []
  type: TYPE_NORMAL
- en: A notable drawback of hierarchical clustering is its sensitivity to outliers,
    which can skew the distance calculations between data points or clusters.
  prefs: []
  type: TYPE_NORMAL
- en: A simple way to determine those outliers is to analyze the distribution of the
    data using a `boxplot` as illustrated below in the `show_boxplot` helper function
    which leverages the `Seaborn` built-in `boxplot` function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/31df9d8434d876b8998f4bff505d2bea.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Boxplot of all the variables in the data (Image by Author)*'
  prefs: []
  type: TYPE_NORMAL
- en: The `balance` attribute representing the clients’ average yearly balance is
    the only one having data points far away from the rest.
  prefs: []
  type: TYPE_NORMAL
- en: By using the interquartile range approach, we can remove all such points that
    lie outside the range defined by the quartiles `+/-1.5*IQR`, where `IQR` is the
    `InterQuartile Range`.
  prefs: []
  type: TYPE_NORMAL
- en: The overall logic is implemented in the `remove_outliers` helper function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Then, we can apply the function to the data set, and compare the new boxplot
    to the one before removing the outliers.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/70f2d6fa723355ee848c284f885ef4c5.png)'
  prefs: []
  type: TYPE_IMG
- en: No more data points lie outside the interquartile range (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: We ended up having a dataset of 4,393 rows and 7 columns, which means that the
    remaining 127 observations dropped from the data were outliers.
  prefs: []
  type: TYPE_NORMAL
- en: '**#4\. Rescale the data**'
  prefs: []
  type: TYPE_NORMAL
- en: Given that hierarchical clustering uses Euclidean distance, which is sensitive
    to variables on different scales, it’s better to rescale all the variables prior
    to distance computing.
  prefs: []
  type: TYPE_NORMAL
- en: The `fit_transform` function from the `StandardScaler` class transforms the
    original data so that each column has a mean of zero and a standard deviation
    of one.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The shape of the data remains unchanged (4,393 rows and 7 columns) since the
    normalization does not affect the shape of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Apply the hierarchical clustering algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are all set to dive deep into the implementation of the clustering algorithm!
  prefs: []
  type: TYPE_NORMAL
- en: At this stage, we can decide which linkage approach to adopt for the clustering
    of the `method` attribute of `linkage()` function.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of focusing on only one method, let’s cover all three linkage techniques
    using the Euclidean distance.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: After computing all three clusterings, the respective dendrograms are visualized
    using the `dendogram` function from `scipy.cluster` module and the `pyplot` function
    from `matplotlib`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each dendrogram is organized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The `x-axis` represents the clusters in the data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `y-axis` corresponds to the distance between those samples. The higher the
    line, the more dissimilar are those clusters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The appropriate number of clusters is obtained by drawing a horizontal line
    through that highest vertical line
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of intersections with the horizontal line corresponds to the number
    of clusters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/61cffad592b6a5825b5560ac02038ab6.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Dendrogram of the complete clustering approach (Image by Author)*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0cf8185d76703dda473b6b6539a4eb35.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Dendrogram of the average clustering approach (Image by Author)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'When running the `single clustering` we might face the `recursion limit` issue.
    This is tackled by using the `setrecursionlimit` function with a large enough
    value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we display the dendrogram:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/213dd0f2e473460ae94de48665c56713.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Dendrogram of the single clustering approach (Image by Author)*'
  prefs: []
  type: TYPE_NORMAL
- en: Determine the number of optimal clusters in the dendrograms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The optimal number of clusters can be obtained by identifying the highest vertical
    line that does not intersect with any other clusters (horizontal line). Such a
    line is found below with a red circle and green check mark.
  prefs: []
  type: TYPE_NORMAL
- en: 'For complete linkage: there is no significant number of clusters generated'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/145ed832d0138585ac979f80ab12393d.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Complete linkage: The optimal number of clusters from the highest distance
    without intersection (Image by Author)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the average linkage: the difference between the two horizontal orange lines
    is slightly more than one. We can consider two clusters instead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/4e8a50666bbedfea41365c83e549e923.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Average linkage: The optimal number of clusters from the highest distance
    without intersection (Image by Author)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the single linkage: no clear number of cluster can be determined'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/0509cb687acdb3b1d8f47e5b6580541c.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Single linkage: The optimal number of clusters from the highest distance without
    intersection (Image by Author)*'
  prefs: []
  type: TYPE_NORMAL
- en: Based on the analysis above, the average linkage seems to provide the optimal
    number of clusters compared to the single and complete linkages which do not provide
    a clear understanding of the number of clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have found the optimal number of clusters let’s interpret these
    clusters in the context of the clients’ average yearly balance using the `cut_tree`
    function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/9c1d9ed75b591101fab3fd7a540b561a.png)'
  prefs: []
  type: TYPE_IMG
- en: Boxplot of the two types of borrowers *(Image by Author)*
  prefs: []
  type: TYPE_NORMAL
- en: 'From the above `boxplot`, we can observe that:'
  prefs: []
  type: TYPE_NORMAL
- en: Clients from cluster 0 possess the highest average annual balance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Borrowers from cluster 1 have a comparatively lower average annual balance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Congratulations!!!🎉
  prefs: []
  type: TYPE_NORMAL
- en: I hope this article provided enough tools to help you take your knowledge to
    the next level. The code is available on my [GitHub](https://github.com/keitazoumana/Medium-Articles-Notebooks/blob/main/Hierarchical_Clustering_Bank_Marketing.ipynb).
  prefs: []
  type: TYPE_NORMAL
- en: Also, If you enjoy reading my stories and wish to support my writing, consider
    becoming a Medium member. It’s $5 a month, giving you unlimited access to thousands
    of Python guides and Data science articles.
  prefs: []
  type: TYPE_NORMAL
- en: By signing up using [my link](https://zoumanakeita.medium.com/membership), I
    will earn a small commission at no extra cost to you.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://zoumanakeita.medium.com/membership?source=post_page-----ef897f52d1c5--------------------------------)
    [## Join Medium with my referral link - Zoumana Keita'
  prefs: []
  type: TYPE_NORMAL
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every story…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: zoumanakeita.medium.com](https://zoumanakeita.medium.com/membership?source=post_page-----ef897f52d1c5--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to follow me on [YouTube](https://www.youtube.com/channel/UC9xKdy8cz6ZuJU5FTNtM_pQ),
    or say Hi on [LinkedIn](https://www.linkedin.com/in/zoumana-keita/). I am also
    open to a [1–1 discussion](https://topmate.io/zoumanakeita) if you need further
    information.
  prefs: []
  type: TYPE_NORMAL
