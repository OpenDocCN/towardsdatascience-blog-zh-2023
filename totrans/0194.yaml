- en: A Gentle Introduction to Bayesian Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/a-gentle-introduction-to-bayesian-deep-learning-d298c7243fd6](https://towardsdatascience.com/a-gentle-introduction-to-bayesian-deep-learning-d298c7243fd6)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Welcome to the exciting world of Probabilistic Programming! This article is
    a gentle introduction to the field, you only need a basic understanding of Deep
    Learning and Bayesian statistics.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@francoisporcher?source=post_page-----d298c7243fd6--------------------------------)[![François
    Porcher](../Images/9ddb233f8cadbd69026bd79e2bd62dea.png)](https://medium.com/@francoisporcher?source=post_page-----d298c7243fd6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d298c7243fd6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d298c7243fd6--------------------------------)
    [François Porcher](https://medium.com/@francoisporcher?source=post_page-----d298c7243fd6--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d298c7243fd6--------------------------------)
    ·8 min read·Jul 26, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this article, you should have a basic understanding of the field,
    its applications, and how it differs from more traditional deep learning methods.
  prefs: []
  type: TYPE_NORMAL
- en: If, like me, you have heard of Bayesian Deep Learning, and you guess it involves
    bayesian statistics, but you don't know exactly how it is used, you are in the
    right place.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations of Traditional Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the main limitation of Traditional deep learning is that even though
    they are very powerful tools, **they don’t provide a measure of their uncertainty.**
  prefs: []
  type: TYPE_NORMAL
- en: Chat GPT can say false information with blatant confidence. Classifiers output
    probabilities that are often not calibrated.
  prefs: []
  type: TYPE_NORMAL
- en: '**Uncertainty estimation is a crucial aspect of decision-making processes,**
    especially in the areas such as healthcare, self-driving cars. We want a model
    to be able to be able to estimate when its very unsure about classifying a subject
    with a brain cancer, and in this case we require further diagnosis by a medical
    expert. Similarly we want autonomous cars to be able to slow down when it identifies
    a new environment.'
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate how bad a neural network can estimates the risk, let’s look at
    a very simple Classifier Neural Network with a softmax layer in the end.
  prefs: []
  type: TYPE_NORMAL
- en: The softmax has a very understandable name, it is a Soft Max function, meaning
    that it is a “smoother” version of a max function. The reason for that is that
    if we had picked a “hard” max function just taking the class with the highest
    probability, we would have a zero gradient to all the other classes.
  prefs: []
  type: TYPE_NORMAL
- en: With a softmax, the probability of a class can be close to 1, but never exactly
    1\. And because the sum of probabilities of all classes is 1, there is still some
    gradient flowing to the other classes.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a92130db127349e0c5d835de703844bf.png)'
  prefs: []
  type: TYPE_IMG
- en: Hard max vs Soft Max, Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: However, the softmax function also presents an issue. It outputs probabilities
    that are **poorly calibrated**. Small changes in the values before applying the
    softmax function are squashed by the exponential, causing minimal changes to the
    output probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: This often results in overconfidence, with the model giving high probabilities
    for certain classes even in the face of uncertainty, a characteristic inherent
    to the ‘max’ nature of the softmax function.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing a traditional Neural Network (NN) with a Bayesian Neural Network (BNN)
    can highlight the importance of uncertainty estimation. A BNN’s certainty is high
    when it encounters familiar distributions from training data, but as we move away
    from known distributions, the uncertainty increases, providing a more realistic
    estimation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is what an estimation of uncertainty can look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3558bea757f19d5881a6071b23f46d22.png)'
  prefs: []
  type: TYPE_IMG
- en: Traditional NN vs Bayesian NN, Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: You can see that when we are close to the distribution we have observed during
    training, the model is very certain, but as we move farther from the known distribution,
    the uncertainty increases.
  prefs: []
  type: TYPE_NORMAL
- en: Short Recap of Bayesian Statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There is one central Theorem to know in Bayesian statistics: The **Bayes Theorem.**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9728bf959ba064a746025dcc956c14e5.png)'
  prefs: []
  type: TYPE_IMG
- en: Bayes Theorem, Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: The **prior** is the distribution of theta we think is the most likely before
    any observation. For a coin toss for example we could assume that the probability
    of having a head is a gaussian around p = 0.5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we want to put as little inductive bias as possible, we could also say p
    is uniform between [0,1].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **likelihood** is given a parameter theta, how likely is that we got our
    observations X, Y
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **marginal likelihood** is the likelihood integrated over all theta possible.
    It is called “marginal” because we marginalized theta by averaging it over all
    probabilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The key idea to understand in Bayesian Statistics is that you start from a prior,
    it's your best guess of what the parameter could be (it is a distribution). And
    with the observations you make, you adjust your guess, and you obtain a **posterior
    distribution.**
  prefs: []
  type: TYPE_NORMAL
- en: Note that the prior and posterior are not a punctual estimations of theta but
    a probability distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d70637d97c364fedfcac19fe62985cb3.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: On this image you can see that the prior is shifted to the right, but the likelihood
    rebalances our prior to the left, and the posterior is somewhere in between.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Bayesian Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Bayesian Deep Learning is an approach that marries two powerful mathematical
    theories: **Bayesian statistics** and **Deep Learning.**'
  prefs: []
  type: TYPE_NORMAL
- en: The essential distinction from traditional Deep Learning **resides in the treatment
    of the model’s weights:**
  prefs: []
  type: TYPE_NORMAL
- en: In traditional Deep Learning, we train a model from scratch, we randomly initialize
    a set of weights, and train the model until it converges to a new set of parameters.
    **We learn a single set of weights.**
  prefs: []
  type: TYPE_NORMAL
- en: Conversely, Bayesian Deep Learning adopts a more **dynamic approach**. We begin
    with a prior belief about the weights, often assuming they follow a normal distribution.
    As we expose our model to data, we adjust this belief, thus updating the posterior
    distribution of the weights. **In essence, we learn a probability distribution
    over the weights, instead of a single set.**
  prefs: []
  type: TYPE_NORMAL
- en: During inference, we average predictions from all models, weighting their contributions
    based on the posterior. **This means, if a set of weights is highly probable,
    its corresponding prediction is given more weight.**
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s formalize all of that:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9e31e2d5e56c00afc926cb5cd67f4931.png)'
  prefs: []
  type: TYPE_IMG
- en: Inference, Image from Author
  prefs: []
  type: TYPE_NORMAL
- en: Inference in Bayesian Deep Learning integrates over all potential values of
    theta (weights) using the posterior distribution.
  prefs: []
  type: TYPE_NORMAL
- en: We can also see that in Bayesian Statistics, integrals are everywhere. This
    is actually the principal limitation of the Bayesian framework. These integrals
    are **often intractable** (we don't always know a primitive of the posterior).
    So we have to do very computationally expensive approximations.
  prefs: []
  type: TYPE_NORMAL
- en: '**Advantages of Bayesian Deep Learning**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Advantage 1: Uncertainty estimation'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Arguably the most prominent benefit of Bayesian Deep Learning is its capacity
    for uncertainty estimation. In many domains including healthcare, autonomous driving,
    language models, computer vision, and quantitative finance, the ability to quantify
    uncertainty is crucial for making informed decisions and managing risk.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Advantage 2: Improved training efficiency'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Closely tied to the concept of uncertainty estimation is improved training efficiency.
    Since Bayesian models are aware of their own uncertainty, they can prioritize
    learning from data points where the uncertainty — and hence, potential for learning
    — is highest. This approach, known as **Active Learning**, leads to impressively
    effective and efficient training.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/d7ef1987d6e5b0ec8885c5bd7996364f.png)'
  prefs: []
  type: TYPE_IMG
- en: Demonstration of the effectiveness of Active Learning, Image from Author
  prefs: []
  type: TYPE_NORMAL
- en: As demonstrated in the graph below, a Bayesian Neural Network using Active Learning
    achieves 98% accuracy with just 1,000 training images. In contrast, models that
    don’t exploit uncertainty estimation tend to learn at a slower pace.
  prefs: []
  type: TYPE_NORMAL
- en: 'Advantage 3: Inductive Bias'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another advantage of Bayesian Deep Learning is the effective use of **inductive
    bias through priors**. The priors allow us to encode our initial beliefs or assumptions
    about the model parameters, which can be particularly useful in scenarios where
    **domain knowledge exists.**
  prefs: []
  type: TYPE_NORMAL
- en: Consider generative AI, where the idea is to create new data (like medical images)
    that resemble the training data. For example, if you’re generating brain images,
    and you already know the general layout of a brain — white matter inside, grey
    matter outside — this knowledge can be included in your prior. This means you
    can assign a higher probability to the presence of white matter in the center
    of the image, and grey matter towards the sides.
  prefs: []
  type: TYPE_NORMAL
- en: In essence, Bayesian Deep Learning not only empowers models to learn from data
    but also enables them to start learning from a point of knowledge, rather than
    starting from scratch. This makes it a potent tool for a wide range of applications.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dfdcd599cad4d636e51538fcdc7467d9.png)'
  prefs: []
  type: TYPE_IMG
- en: White Matter and Gray Matter, Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Limitations of Bayesian Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It seems that Bayesian Deep Learning is incredible! So why is it that this field
    is so underrated? Indeed we often talk about Generative AI, Chat GPT, SAM, or
    more traditional neural networks, but we almost never hear about Bayesian Deep
    Learning, why is that?
  prefs: []
  type: TYPE_NORMAL
- en: 'Limitation 1: Bayesian Deep Learning is slooooow'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The key to understand Bayesian Deep Learning is that we “average” the predictions
    of the model, and whenever there is an average, there is an **integral** over
    the set of parameters.
  prefs: []
  type: TYPE_NORMAL
- en: But **computing an integral is often intractable**, this means that there is
    no closed or explicit form that makes the computation of this integral quick.
    So we can’t compute it directly, we have to approximate the integral by sampling
    some points, and this makes the inference very slow.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine that for each data point *x* we have to average out the prediction of
    10,000 models, and that each prediction can take 1s to run, we end up with a model
    that is not **scalable with a large amount of data.**
  prefs: []
  type: TYPE_NORMAL
- en: In most of the business cases, we need fast and scalable inference, this is
    why Bayesian Deep Learning is not so popular.
  prefs: []
  type: TYPE_NORMAL
- en: 'Limitation 2: Approximation Errors'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Bayesian Deep Learning, it’s often necessary to use approximate methods,
    such as Variational Inference, to compute the posterior distribution of weights.
    These approximations can lead to errors in the final model. The quality of the
    approximation depends on the choice of the variational family and the divergence
    measure, which can be challenging to choose and tune properly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Limitation 3: Increased Model Complexity and Interpretability'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While Bayesian methods offer improved measures of uncertainty, this comes at
    the cost of increased model complexity. BNNs can be difficult to interpret because
    instead of a single set of weights, we now have a distribution over possible weights.
    This complexity might lead to challenges in explaining the model’s decisions,
    especially in fields where interpretability is key.
  prefs: []
  type: TYPE_NORMAL
- en: There is a growing interest for XAI (Explainable AI), and Traditional Deep Neural
    Networks are already challenging to interpret because it is difficult to make
    sense of the weights, Bayesian Deep Learning is even more challenging.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thanks for reading! Before you go:'
  prefs: []
  type: TYPE_NORMAL
- en: Check my [compilation of AI tutorials](https://github.com/FrancoisPorcher/awesome-ai-tutorials)
    on Github
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](https://github.com/FrancoisPorcher/awesome-ai-tutorials?source=post_page-----d298c7243fd6--------------------------------)
    [## GitHub - FrancoisPorcher/awesome-ai-tutorials: The best collection of AI tutorials
    to make you a…'
  prefs: []
  type: TYPE_NORMAL
- en: The best collection of AI tutorials to make you a boss of Data Science! - GitHub
    …
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/FrancoisPorcher/awesome-ai-tutorials?source=post_page-----d298c7243fd6--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Y*ou should get my articles in your inbox.* [***Subscribe here.***](https://medium.com/@francoisporcher/subscribe)
  prefs: []
  type: TYPE_NORMAL
- en: '*If you want to have access to premium articles on Medium, you only need a
    membership for $5 a month. If you sign up* [***with my link***](https://medium.com/@francoisporcher/membership)*,
    you support me with a part of your fee without additional costs.*'
  prefs: []
  type: TYPE_NORMAL
- en: If you found this article insightful and beneficial, please consider following
    me and leaving a clap for more in-depth content! Your support helps me continue
    producing content that aids our collective understanding.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ghahramani, Z. (2015). Probabilistic machine learning and artificial intelligence.
    Nature, 521(7553), 452–459\. [Link](https://www.nature.com/articles/nature14541)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Blundell, C., Cornebise, J., Kavukcuoglu, K., & Wierstra, D. (2015). Weight
    uncertainty in neural networks. arXiv preprint arXiv:1505.05424\. [Link](https://arxiv.org/abs/1505.05424)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Gal, Y., & Ghahramani, Z. (2016). Dropout as a Bayesian approximation: Representing
    model uncertainty in deep learning. In international conference on machine learning
    (pp. 1050–1059). [Link](https://proceedings.mlr.press/v48/gal16.pdf)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Louizos, C., Welling, M., & Kingma, D. P. (2017). Learning sparse neural networks
    through L0 regularization. arXiv preprint arXiv:1712.01312\. [Link](https://arxiv.org/abs/1712.01312)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Neal, R. M. (2012). Bayesian learning for neural networks (Vol. 118). Springer
    Science & Business Media. [Link](https://www.springer.com/gp/book/9780387947242)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
