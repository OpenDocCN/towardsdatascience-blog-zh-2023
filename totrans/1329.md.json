["```py\n# Standard required imports on Pandas and Seaborn\nimport pandas as pd\nimport seaborn as sns\n\n# Load data from Seaborn library\ndf = sns.load_dataset('mpg')\n# Remove records with  missing values\ndf.dropna(inplace=True)\n```", "```py\n# List comprehension to make a new target variable\ndf['isUS'] = [1 if x == 'usa' else 0 for x in df['origin']]\n```", "```py\n# Import train_test_split from sklearn\nfrom sklearn.model_selection import train_test_split\n\n# Specify a feature and target matrix\nX = df[['mpg','cylinders','displacement',\n        'horsepower','weight','acceleration']]\ny = df['isUS']\n\n# Train, test, and split the feature and target matricies\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=1234)\n```", "```py\n# Import KNN classifier from sklearn\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Instantiate and train KNN model\nknn = KNeighborsClassifier(n_neighbors=7)\nknn.fit(X_train, y_train)\n```", "```py\n# Generate and save predictions\npred = knn.predict(X_test)\n```", "```py\n# Find proportion of predictions that were accurate\nprint(f'The accuracy of this model is {(pred == y_test).mean() * 100}')\n```", "```py\n# Use pd.crosstab to generate a confusion matrix\npd.crosstab(pred, y_test)\n```", "```py\n Actual Values\nPredictions         0     1        \n  0                27     9\n  1                 3    40\n```", "```py\n# Concatenate three data sources: Testing data (X_test), \n# actual outcomes (y_test), and predictions (pred)\npd.concat([X_test.reset_index(drop=True), \n           pd.DataFrame(y_test).reset_index(drop=True), \n           pd.DataFrame({'preds':pred})], axis=1)\n```", "```py\n# Concatenate three data sources: Testing data (X_test), \n# actual outcomes (y_test), and predictions (pred)\npost_analysis = pd.concat(\n    [X_test.reset_index(drop=True), \n     pd.DataFrame({'isUS':y_test}).reset_index(drop=True), \n     pd.DataFrame({'preds':pred})], axis=1)\n\n# Add a new column, 'Correct', to act as a filter\npost_analysis['Correct'] = post_analysis['isUS'] == \\\n                           post_analysis['preds']\n\n# Filter and export data as an html file\npost_analysis[\n    post_analysis['Correct']==False].to_html('For_SME_Review.html')\n```", "```py\n# Calculate the baseline model accuracy\nbaseline_accuracy = accuracy_score(y_test, pred)\n\n# Empty dictionary to hold feature importances\nfeature_importances = {}\n\n# For each feature in the dataset...\nfor feature in X.columns:\n    # Create a second set of targets and features\n    X2 = X.drop(feature, axis=1)\n    y2 = y\n\n    # Create a second set of trains tests splits\n    X_train2, X_test2, y_train2, y_test2 = train_test_split(\n        X2, y2, test_size=0.2, random_state=1234)\n\n    # Fit using the second set of trains tests splits\n    knn.fit(X_train2, y_train2)\n    # Predict using the second set of trains tests splits\n    held_out_pred = knn.predict(X_test2)\n    # Get accuracy score on model with hold out\n    held_out_acc = accuracy_score(y_test2, held_out_pred)\n    # Save the accuracy score to the dictionary\n    feature_importances[feature] = baseline_accuracy - held_out_acc\n\n# Produce a data frame from the dictionary\nfeature_imp = pd.DataFrame.from_dict(feature_importances, \n                                     orient='index',\n                                     columns=['importance'])\n\n# Display the data frame with sorted importance values\nfeature_imp.sort_values(by='importance', \n                        ascending=False)\n```", "```py\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Define feature and target variables (X & y)\nX = df[['mpg','cylinders','displacement',\n        'horsepower','weight','acceleration']]\ny = df['isUS']\n\n# Split dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=1234)\n\n# Initialize and train K-Nearest Neighbors\nknn = KNeighborsClassifier(n_neighbors=7)\nknn.fit(X_train, y_train)\n\n# Make predictions on the testing set\npred = knn.predict(X_test)\n\n# Get prediction probabilities\nprobs = knn.predict_proba(X_test)\n\n# Concatenate four data sources: Testing data (X_test), \n# actual outcomes (y_test), probabilities, and predictions (pred)\npost_analysis = pd.concat(\n    [X_test.reset_index(drop=True), \n     pd.DataFrame({'isUS':y_test}).reset_index(drop=True), \n     pd.DataFrame({'preds':pred}),\n     pd.DataFrame(probs, \n                  columns=['Pr 0','Pr 1'])], axis=1)\n\n# Add a new column, 'Correct', to act as a filter\npost_analysis['Correct'] = post_analysis['isUS'] == \\\n                           post_analysis['preds']\n\n# Filter and export data as an html file\npost_analysis[\n    post_analysis['Correct']==False].to_html('For_SME_Review.html')\n```", "```py\n# Predicted probability summary stats among misclassifications\npost_analysis[post_analysis['Correct'] == False][\n    ['Pr 0', 'Pr 1']].describe().transpose()\n```"]