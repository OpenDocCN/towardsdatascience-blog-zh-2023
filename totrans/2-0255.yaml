- en: Adapting Existing LLM Projects to use LangChain
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 适应现有的 LLM 项目以使用 LangChain
- en: 原文：[https://towardsdatascience.com/adapting-existing-llm-projects-to-use-langchain-cd07028c01b0](https://towardsdatascience.com/adapting-existing-llm-projects-to-use-langchain-cd07028c01b0)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/adapting-existing-llm-projects-to-use-langchain-cd07028c01b0](https://towardsdatascience.com/adapting-existing-llm-projects-to-use-langchain-cd07028c01b0)
- en: Refactoring OpenAI calls into something more powerful with LangChain
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将 OpenAI 调用重构为更强大的 LangChain 功能
- en: '[](https://medium.com/@oaguy1?source=post_page-----cd07028c01b0--------------------------------)[![Lily
    Hughes-Robinson](../Images/b610721a40e274e7fb81418395314ae3.png)](https://medium.com/@oaguy1?source=post_page-----cd07028c01b0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cd07028c01b0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cd07028c01b0--------------------------------)
    [Lily Hughes-Robinson](https://medium.com/@oaguy1?source=post_page-----cd07028c01b0--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@oaguy1?source=post_page-----cd07028c01b0--------------------------------)[![Lily
    Hughes-Robinson](../Images/b610721a40e274e7fb81418395314ae3.png)](https://medium.com/@oaguy1?source=post_page-----cd07028c01b0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cd07028c01b0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cd07028c01b0--------------------------------)
    [Lily Hughes-Robinson](https://medium.com/@oaguy1?source=post_page-----cd07028c01b0--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cd07028c01b0--------------------------------)
    ·6 min read·Jul 1, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cd07028c01b0--------------------------------)
    ·6 分钟阅读·2023年7月1日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/814da28df7832cee3963ba401e7ba764.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/814da28df7832cee3963ba401e7ba764.png)'
- en: Photo by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral)
    提供，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Congratulations, you have a working LLM proof-of-concept that you are proud
    of and ready to show off to the world! Maybe you’ve utilized the OpenAI library
    directly or perhaps you’re using a different foundation model and HuggingFace
    transformers. Either way, you worked hard and are looking for the next step. That
    could mean code refactoring, adding support for multiple foundation models, or
    adding more advanced functionality such as agents or vector db. This is where
    LangChain comes in.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你，你拥有一个令人自豪且准备向世界展示的 LLM 概念验证项目！也许你直接使用了 OpenAI 库，或者你使用了不同的基础模型和 HuggingFace
    transformers。无论哪种方式，你都付出了辛勤的努力，并在寻找下一步。那可能意味着代码重构、支持多个基础模型，或者添加更高级的功能，如代理或向量数据库。这时
    LangChain 就派上用场了。
- en: '[LangChain](https://langchain.com) is an open source framework for working
    with LLMs and developing applications on top of them. It has versions in both
    Python and JavaScript and supports multiple foundation models and LLM providers.
    It also has a number of utility functions for handling common tasks such as document
    chunking or interacting with vector dbs. Convinced it’s something worth checking
    out? Have a look at this excellent article which is a great place to start understanding
    what is possible:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[LangChain](https://langchain.com) 是一个开源框架，用于处理 LLM 和在其基础上开发应用程序。它有 Python
    和 JavaScript 版本，支持多个基础模型和 LLM 提供商。它还提供了许多实用函数，用于处理常见任务，如文档分块或与向量数据库交互。你是否相信这值得一试？看看这篇出色的文章，这是了解可能性的一个很好的起点：'
- en: '[](/getting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c?source=post_page-----cd07028c01b0--------------------------------)
    [## Getting Started with LangChain: A Beginner’s Guide to Building LLM-Powered
    Applications'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/getting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c?source=post_page-----cd07028c01b0--------------------------------)
    [## 使用 LangChain 入门：构建 LLM 驱动应用程序的初学者指南'
- en: A LangChain tutorial to build anything with large language models in Python
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一个 LangChain 教程，用于在 Python 中构建基于大型语言模型的应用程序
- en: towardsdatascience.com](/getting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c?source=post_page-----cd07028c01b0--------------------------------)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/getting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c?source=post_page-----cd07028c01b0--------------------------------)
- en: 'This article will be not be focused on greenfield development and instead on
    refactoring an existing app. It will also assume some base understanding of LangChain,
    but there will be links to relevant documentation. Specifically, I will be looking
    at refactoring a project that I wrote called [AdventureGPT](https://github.com/oaguy1/AdventureGPT),
    an autonomous agent for playing the 1977 *Colossal Cave Adventure* text-based
    adventure game. If you are interested in learning more about that project, check
    out my previous article about it:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://betterprogramming.pub/adventuregpt-using-llm-backed-agents-to-play-text-based-adventure-games-be52f243866a?source=post_page-----cd07028c01b0--------------------------------)
    [## AdventureGPT: Using LLM Backed Agents to Play Text-Based Adventure Games'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: betterprogramming.pub](https://betterprogramming.pub/adventuregpt-using-llm-backed-agents-to-play-text-based-adventure-games-be52f243866a?source=post_page-----cd07028c01b0--------------------------------)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: 'There were several areas I was most interested in refactoring:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Utilizing [Chains](https://python.langchain.com/en/latest/modules/chains.html)
    instead of direct OpenAI calls
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Replacing bespoke document utilities for the LangChain [Document/Data](https://python.langchain.com/docs/modules/data_connection/)
    handling
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each of these will be addressed in turn.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Let’s begin with what a chain is. A chain is a method of combining several prompt
    manipulation techniques together into a single unit that results in a single foundation
    model call. Once one has a working chain, chains can be combined and used together
    to achieve more complex tasks.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: LangChain offers a few different types of chains, this article focuses on LLMChain
    and ConversationChain. LLMChain is the simplest type of chain, combining a prompt
    templates with the LLM objects LangChain supports. ConversationChains offer an
    experience tailored conversational workflows such as chatbots. One of the major
    features of ConversationChain is its ability to include memory and store past
    parts of the conversation effortlessly into the prompt.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Prompt templates are one of the most powerful features of LangChain, allowing
    you to include variables inside the prompts. When manually completing this task,
    one might us f-strings combined with string concatenation and careful use of [custom
    __repr__ methods](https://www.digitalocean.com/community/tutorials/python-str-repr-functions)
    to take your data and insert it into a prompt for a foundation model. With the
    prompt template, you can format a string by escaping variables with brackets.
    That’s all you have to do.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the type of chain you are creating, some variables are set for
    you by default, such as the the conversational history or user input. This can
    take a fair amount of complexity. In a traditional conversational prompt, there
    are messages from the system, the the AI assistant, and user or human. When writing
    prompts by hand, you use labels like “System”, “Human”, and “AI” to label each
    of these messages for the prompt. LangChain can take care of this for you, allowing
    you to use the [ChatPromptTemplate](https://api.python.langchain.com/en/latest/modules/prompts.html#langchain.prompts.ChatPromptTemplate)
    method `from_messages` allow you to specify each message as a list of objects,
    allowing for a higher level of abstraction and automatic history inclusion and
    formatting.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你创建的链的类型，一些变量会默认为你设置，例如对话历史或用户输入。这可能会涉及相当复杂的内容。在传统的对话提示中，有来自系统、AI 助手和用户或人类的消息。当手动编写提示时，你会使用“System”、“Human”和“AI”等标签来标记这些消息。LangChain
    可以为你处理这些，使你可以使用 [ChatPromptTemplate](https://api.python.langchain.com/en/latest/modules/prompts.html#langchain.prompts.ChatPromptTemplate)
    方法 `from_messages`，允许你将每条消息指定为对象列表，从而实现更高层次的抽象和自动历史记录包含及格式化。
- en: 'All this power comes at the cost of complexity. Rather than simply adapting
    the prompts with text, one needs to read the extensive documentation and possible
    extend the existing code to fit a specific use case. For example, conversational
    prompts tend to only include the user’s input and conversation history as variables.
    However, I wanted to include additional game context in my prompt for my PlayerAgent,
    which was responsible for interacting with the game world. After adding the additional
    variables to my prompt, I was greeted with the following error:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些强大功能都带来了复杂性的代价。与其仅仅用文本调整提示，还需要阅读详尽的文档，并可能扩展现有代码以适应特定的用例。例如，对话提示通常只包括用户的输入和对话历史作为变量。然而，我希望在我的提示中包含额外的游戏上下文，以供负责与游戏世界互动的
    PlayerAgent 使用。在将额外变量添加到我的提示后，我遇到了以下错误：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: I did some digging and found an existing [GitHub issue](https://github.com/hwchase17/langchain/issues/891)
    describing the exact issue I was having, but with no clear resolution. Unperturbed,
    I looked at the [source code for the ConversationChain](https://github.com/hwchase17/langchain/blob/master/langchain/chains/conversation/base.py)
    class and saw that there was a specific method used to validate that only the
    expected variables were passed in as input. I made a new class subclassing the
    original class and overrode the method. With my CustomConversationChain class
    in hand, I then needed to specify which variable should be utilized by the ConversationalMemoryBuffer
    for the user’s (or in my case, the game’s) input since there were multiple input
    variables. This was simple enough via the input_key instance variable and Bob’s
    your uncle, everything worked.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我做了一些调查，发现了一个现有的 [GitHub 问题](https://github.com/hwchase17/langchain/issues/891)，描述了我遇到的确切问题，但没有明确的解决方案。没有气馁，我查看了
    [ConversationChain](https://github.com/hwchase17/langchain/blob/master/langchain/chains/conversation/base.py)
    类的源代码，发现有一个特定的方法用于验证是否只传入了预期的变量。我创建了一个新类，继承了原始类，并重写了这个方法。拿到我的 CustomConversationChain
    类后，我还需要指定 ConversationalMemoryBuffer 应该利用哪个变量来处理用户（或在我的案例中，游戏）的输入，因为有多个输入变量。通过
    input_key 实例变量这一步很简单，结果一切顺利。
- en: Once I finished converting my OpenAI calls to chains, it was time to address
    the way I was handling document ingestion. As part of my game loop, I accepted
    a path to a walkthrough text which would then be converted into game tasks to
    be completed by the PlayerAgent. When I first added this feature, I simply passed
    the whole walkthrough to the prompt and hoped for the best. As I found more sophisticated
    walkthoughs, that was no longer possible as the length of the walkthroughs exceeded
    the context window OpenAI allowed for ChatGPT. Therefore, I cut the text into
    chunks of 500 tokens and ran the prompt for converting walkthroughs into game
    tasks multiple times.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我完成了将 OpenAI 调用转换为链的工作，就到了处理文档摄取方式的时候。作为游戏循环的一部分，我接受了一个 walkthrough 文本的路径，然后将其转换为由
    PlayerAgent 完成的游戏任务。当我第一次添加这个功能时，我只是把整个 walkthrough 传递给提示，并希望能有所成效。随着我发现更复杂的 walkthrough，这种做法已不再可行，因为
    walkthrough 的长度超出了 OpenAI 为 ChatGPT 允许的上下文窗口。因此，我将文本切分为 500 个标记的块，并多次运行提示，将 walkthrough
    转换为游戏任务。
- en: When I said I chunked the text by around 500 tokens, I did this very crudely,
    relying on Python’s string’s `split` method to tokenize the text (a very rough
    approximation that doesn’t match how most LLM’s tokenize text) and then turned
    the array of tokens back into a string via the `join` method, again from the String
    class. While this works, LangChain offers better solutions.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: LangChain is able to split text in a number of different ways. The most relevant
    for most people is by token, as it preserves the flow the document. There is an
    entire page of documentation [here](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/split_by_token)
    dedicated to the different methods of splitting texts by token. A number of NLP
    libraries are supported for tokenization, but I chose the LLM native solution
    tiktoken, which is the first method described. It was only a few lines of code
    to easily and much more effectively split the text while preserving whitespace.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: This is only scratching the surface of the document preparation that LangChain
    is capable of. It is also capable of converting the text chunks into an appropriate
    text embedding for storage in a vector database and later retrieval and inclusion
    in the prompt. I plan on doing this in the future of my project, including a relevant
    chunk of a supplied walthrough to the PlayerAgent.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: LangChain is a powerful open source framework that offers a range of features
    and utility functions for working with LLMs and developing applications on top
    of them. Whether you’re using the OpenAI library or a different foundation model,
    LangChain provides support for multiple foundation models and LLM providers, making
    it a versatile choice for your projects.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: While LangChain may introduce some complexity compared to raw prompt management,
    it offers numerous benefits and simplifies the interaction with LLMs. It standardizes
    the process and provides helpful tools to enhance your prompts and maximize the
    potential of your chosen LLM.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: If you’re interested in seeing how LangChain can be implemented in a real project,
    you can check out the updated code base for AdventureGPT, which utilizes LangChain
    for refactoring and improving the existing app.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/oaguy1/AdventureGPT/tree/langchain?source=post_page-----cd07028c01b0--------------------------------)
    [## GitHub - oaguy1/AdventureGPT at langchain'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: Contribute to oaguy1/AdventureGPT development by creating an account on GitHub.
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/oaguy1/AdventureGPT/tree/langchain?source=post_page-----cd07028c01b0--------------------------------)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Overall, LangChain is a valuable resource for developers working with LLMs,
    providing a comprehensive framework and a wide range of functionalities to enhance
    LLM-powered applications. Explore LangChain and unlock the full potential of your
    LLM projects!
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
