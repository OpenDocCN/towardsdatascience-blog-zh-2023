- en: A Lean Data Pipeline by Example
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过示例了解精益数据管道
- en: 原文：[https://towardsdatascience.com/a-lean-data-pipeline-by-example-e08bfce58133](https://towardsdatascience.com/a-lean-data-pipeline-by-example-e08bfce58133)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-lean-data-pipeline-by-example-e08bfce58133](https://towardsdatascience.com/a-lean-data-pipeline-by-example-e08bfce58133)
- en: Powerful cloud data platforms like Snowflake and Databricks change how we think
    about normal forms and data warehousing
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 强大的云数据平台，如Snowflake和Databricks，改变了我们对标准形式和数据仓库的思考方式
- en: '[](https://timburnsowlmtn.medium.com/?source=post_page-----e08bfce58133--------------------------------)[![Tim
    Burns](../Images/70e4b9a6510a60cdf343dd0f7f92e943.png)](https://timburnsowlmtn.medium.com/?source=post_page-----e08bfce58133--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e08bfce58133--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e08bfce58133--------------------------------)
    [Tim Burns](https://timburnsowlmtn.medium.com/?source=post_page-----e08bfce58133--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://timburnsowlmtn.medium.com/?source=post_page-----e08bfce58133--------------------------------)[![Tim
    Burns](../Images/70e4b9a6510a60cdf343dd0f7f92e943.png)](https://timburnsowlmtn.medium.com/?source=post_page-----e08bfce58133--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e08bfce58133--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e08bfce58133--------------------------------)
    [Tim Burns](https://timburnsowlmtn.medium.com/?source=post_page-----e08bfce58133--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e08bfce58133--------------------------------)
    ·7 min read·Apr 18, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----e08bfce58133--------------------------------)
    ·7分钟阅读·2023年4月18日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c75ed1033a8be71c7cc1007e08423f67.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c75ed1033a8be71c7cc1007e08423f67.png)'
- en: Photo by [David Di Veroli](https://unsplash.com/@daviddiveroli?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/-m1duEoiJng?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[David Di Veroli](https://unsplash.com/@daviddiveroli?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)拍摄，发布在[Unsplash](https://unsplash.com/photos/-m1duEoiJng?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)上
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: When minimizing cloud data pipeline costs, the first thing that comes to mind
    is finding the cheapest ETL solution. For example, is Databricks cheaper than
    Snowflake? Should I use the cloud or run Spark locally on an in-house cluster?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在最小化云数据管道成本时，首先想到的是寻找最便宜的ETL解决方案。例如，Databricks是否比Snowflake便宜？我应该使用云服务还是在内部集群上本地运行Spark？
- en: A better way to consider cost minimization is by using the principles of Lean.
    One of the Lean Startup principles is validating in small increments [[1](https://theleanstartup.com/)].
    Focusing on value is even more essential for cloud data pipelines because every
    normalization and dimension costs money. Additionally, 50 years of data pipelining
    provides a wealth of transformation we *can* do, but only analytical value to
    the customer defines what we *should* do.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的成本最小化方法是利用精益原则。精益创业原则之一是通过小步骤进行验证[[1](https://theleanstartup.com/)]。对于云数据管道来说，关注价值尤为重要，因为每一次规范化和维度都需要花费金钱。此外，50年的数据管道经验提供了大量我们*可以*做的转换，但只有对客户的分析价值才能定义我们*应该*做的事情。
- en: In this article, I describe how you can approach cost minimization by focusing
    on developing business value by transforming the data only as needed to answer
    specific business questions. That way, you can choose from big data platforms
    based on your unique business cases and not a cost minimization exercise. As long
    as you know the tradeoffs in minimizing your data transforms, it's a good idea
    to avoid performing a transform if your business use case doesn't need it.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我描述了如何通过专注于发展业务价值来进行成本最小化，即仅在需要回答特定业务问题时才转换数据。这样，你可以根据独特的业务案例而不是成本最小化的练习来选择大数据平台。只要你了解在最小化数据转换中的权衡，如果你的业务用例不需要，就最好避免进行转换。
- en: An (Overly) Simple Question
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个（过于）简单的问题
- en: Because I want to illustrate an idea rather than build an actual data pipeline,
    I will take a toy problem to demonstrate how we could implement a multi-stage
    pipeline and then posit that a transformation pipeline is unnecessary.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我想说明一个想法，而不是建立实际的数据管道，所以我将以一个玩具问题来演示我们如何实现一个多阶段管道，然后假设一个转换管道是不必要的。
- en: The toy business use case is that I want to build a personal music playlist
    using the top artists played on alternative radio. Thus, I now have a business
    question to ask that will guide any backend development activities and limit their
    scope.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 玩具业务用例是，我想使用在另类电台中播放的顶级艺术家来构建一个个人音乐播放列表。因此，我现在有一个商业问题需要提问，这将指导任何后端开发活动并限制其范围。
- en: What are the top 10 artists on alternative radio since March 2020?
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 自2020年3月以来，另类电台的前10名艺术家有哪些？
- en: ChatGPT bails out on this question with, "I'm sorry, as a language model, …"
    and then points me to the Billboard Top 100 chart for alternative, which is equally
    unhelpful. I want to know what is being played on the radio and use accurate data
    to give me new ideas for a personal playlist.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 对这个问题的回应是：“对不起，作为一个语言模型，……” 然后将我指向Billboard Top 100的另类电台榜单，这同样没有帮助。我想知道电台上播放的内容，并使用准确的数据为我提供个人播放列表的新想法。
- en: Accurate Data, Real Models, Real Answers
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准确的数据，真实的模型，真实的答案
- en: Public API endpoints to download playlist data are abundant. Start with
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 公共API端点用于下载播放列表数据是丰富的。开始于
- en: '[https://rapidapi.com/blog/top-free-music-data-apis](https://rapidapi.com/blog/top-free-music-data-apis/)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://rapidapi.com/blog/top-free-music-data-apis](https://rapidapi.com/blog/top-free-music-data-apis/)'
- en: As data engineers, we identify the data sources and focus on downloading the
    playlist data cleanly to a data lake on our favorite cloud provider. Cleanliness
    in this process at every step is essential. That means every step leaves the data
    complete and free of duplicates. Modern tools like dbt have built-in functionality
    to make this easy [[8](https://docs.getdbt.com/docs/introduction)].
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据工程师，我们确定数据源，并专注于将播放列表数据干净地下载到我们喜欢的云提供商的数据湖中。这个过程中的每一步都必须保持数据的清洁。也就是说，每一步都应确保数据完整且无重复。像dbt这样的现代工具具有内置功能，可以使这一过程变得简单[[8](https://docs.getdbt.com/docs/introduction)]。
- en: Playlists generally have a schema based on the Airdate and properties like "Artist,
    Album, Song, and Show." The show is another time-based entity that tracks the
    performance of each DJ on the radio station. Changes are that the API producers
    reflect their database, and the best practice is to synchronize the data as is
    to your data lake. The point is that the data we receive from the API is good
    enough for analytics.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 播放列表通常具有基于播出日期的模式以及“艺术家、专辑、歌曲和节目”等属性。节目是另一个基于时间的实体，跟踪每位DJ在电台的表现。API生产者可能会反映他们的数据库，最佳实践是将数据按原样同步到你的数据湖中。关键是我们从API接收到的数据足够用于分析。
- en: A [simple Python code](https://github.com/timowlmtn/bigdataplatforms/blob/master/src/kexp/layers/raw_data_api/ApiReader.py)
    can synchronize raw data from the web to a data lake. So the first response to
    the question is to show here how the data looks for a single play.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[简单的Python代码](https://github.com/timowlmtn/bigdataplatforms/blob/master/src/kexp/layers/raw_data_api/ApiReader.py)可以将原始数据从网络同步到数据湖。因此，回答问题的第一步是展示单次播放的数据是怎样的。
- en: '![](../Images/0be65f0313f49fff152f8168244c2370.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0be65f0313f49fff152f8168244c2370.png)'
- en: Example Snapshot of JSON Output (source [KEXP API](https://api.kexp.org/v2/))
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: JSON输出示例快照（来源 [KEXP API](https://api.kexp.org/v2/)）
- en: The vital strategy is to synchronize all the data from the API and ensure we
    can synchronize data regularly.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 关键策略是同步来自API的所有数据，并确保我们能够定期同步数据。
- en: Make your Data Transformation Choices Intentional
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 让你的数据转换选择具有目的性
- en: Once the data is synchronized into the data lake, it will have a similar output
    from the source. The data lake will capture all the data in its original form
    so it is ready when needed. The data lake required a rigid structure and governance
    to maintain clear boundaries and security of the data [[9](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/a-smarter-way-to-jump-into-data-lakes#/)].
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据同步到数据湖中，它将会有类似于源头的数据输出。数据湖会以原始形式捕获所有数据，以便在需要时随时使用。数据湖需要一个严格的结构和治理，以保持数据的清晰界限和安全性[[9](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/a-smarter-way-to-jump-into-data-lakes#/)]。
- en: When the data is in the data lake, you are ready to build a Data Warehouse (or
    Data Lakehouse if you like). Data warehouses have a rich theory, and data quality
    is crucial. If you answer the question, but the question is wrong, that is worse
    than not answering the question at all. Thus, fully understanding what you *can*
    do is as important as knowing what you *should* do.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据在数据湖中时，你准备好建立一个数据仓库（或者如果你愿意，可以是数据湖仓）。数据仓库有丰富的理论，数据质量至关重要。如果你回答了问题，但问题本身是错的，那比不回答问题更糟。因此，完全理解你*能*做什么与知道你*应该*做什么一样重要。
- en: I like to think of a complete understanding of historical data warehousing as
    "future-proofing knowledge" on my data pipeline. I may not need every transform,
    but I need to have a transform conceived if a new customer question cannot be
    resolved with the current data.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我喜欢将对历史数据仓库的全面理解视为我数据管道中的“未来防护知识”。我可能不需要每一个转换，但如果当前数据无法解决新的客户问题，我需要有一个预想的转换。
- en: Normalization and Cleanup
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 规范化和清理
- en: The standard forms (1NF, 2NF, and 3NF) underly the most common data transformations
    [[2](https://dl.acm.org/doi/10.1145/362384.362685)].
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 标准范式 (1NF、2NF 和 3NF) 是最常见的数据转换的基础 [[2](https://dl.acm.org/doi/10.1145/362384.362685)]。
- en: The **First Normal Form (1NF)** states that each column has a single value,
    so no arrays or comma-separated lists in columns. There are good reasons for keeping
    all column values intrinsic because aggregating and exploding in the same query
    leads to cartesian joins. However, modern data warehouse/lakehouse architectures
    support complex types like lists and maps. Complex structures are beneficial for
    maintaining data lineage and allowing flexibility further down the pipeline and
    are well supported by commercial applications like Snowflake and Databricks.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**第一范式 (1NF)** 规定每一列应只有单一值，因此列中不应有数组或用逗号分隔的列表。保持所有列值为原子的原因很充分，因为在同一查询中进行聚合和展开会导致笛卡尔连接。然而，现代的数据仓库/湖泊架构支持复杂类型，如列表和映射。复杂结构对于维护数据血缘关系和在管道下游提供灵活性非常有益，并且受到像
    Snowflake 和 Databricks 这样的商业应用的良好支持。'
- en: The **Second Normal form (2NF)** states that the data from the 1NF is de-duplicated
    according to a set of attributes. In the big data world, we cannot rely on the
    systems to enforce uniqueness on a key because of distributed data processing.
    The data is processed in columns across multiple machines, and we want to avoid
    global operations because they are expensive both in time and money. In the modern
    bit data world, we pay for what we use by processing time, so managing efficiency
    is crucial.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**第二范式 (2NF)** 规定将1NF的数据根据一组属性去重。在大数据世界中，我们不能依赖系统强制唯一性，因为分布式数据处理的原因。数据在多台机器上的列中处理，我们希望避免全局操作，因为这些操作在时间和金钱上都是昂贵的。在现代大数据世界中，我们按处理时间收费，因此管理效率至关重要。'
- en: The **Third Normal Form (3NF)** states that the data from the 2NF is moved into
    a separate table, every table has a set of data specific to its domain, and a
    foreign key relates the data from the particular table to the original. It serves
    to help performance because data in the 3NF only needs to be queried in a single
    place, and the foreign key can be used to build reports.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**第三范式 (3NF)** 规定将2NF的数据移入一个单独的表中，每个表都有一组特定于其领域的数据，并且一个外键将特定表中的数据与原始数据相关联。这有助于性能，因为3NF中的数据只需要在一个地方查询，外键可以用于生成报告。'
- en: The Kimball Warehouse Model
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kimball 数据仓库模型
- en: The Kimball Warehouse (Dimensional Model) is the Star Schema model described
    in The Kimball Data Warehouse Toolkit [[3](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/books/data-warehouse-dw-toolkit/)].
    It extends ideas from the 3NF and builds on metrics or measures as the core analytical
    components of the data and dimensions as collections of properties on the entities
    involved in those measures. It is generally considered the gold standard for data
    analytics.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Kimball 数据仓库（维度模型）是《Kimball 数据仓库工具包》中描述的星型模式 [[3](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/books/data-warehouse-dw-toolkit/)]。它扩展了3NF的思想，并以度量或衡量指标作为数据的核心分析组件，以维度作为这些度量相关实体的属性集合。它通常被认为是数据分析的黄金标准。
- en: The Kimball Warehouse was designed for relational databases, so it may be optional
    to implement all the aspects of the Kimball model. For example, in a distributed
    Spark environment, sequential surrogate keys can be a hindrance to be avoided
    if possible [[4](/adding-sequential-ids-to-a-spark-dataframe-fa0df5566ff6)]. If
    you can answer all the customer's questions without surrogate keys, you don't
    need them.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Kimball 数据仓库是为关系型数据库设计的，因此实施 Kimball 模型的所有方面可能是可选的。例如，在分布式 Spark 环境中，顺序替代键可能会成为需要避免的障碍
    [[4](/adding-sequential-ids-to-a-spark-dataframe-fa0df5566ff6)]。如果你可以在没有替代键的情况下回答所有客户的问题，那么你就不需要它们。
- en: Validate Small Increments with an Analytics GUI
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用分析 GUI 验证小增量
- en: '"Build it, and they will come" is not a good model for data products. The sheer
    volume of potential sources and analytical use cases for most data projects is
    vast, and it is easy to fall into the trap of focusing on the back end and excluding
    the customer.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: “建造它，他们就会来”并不是数据产品的一个好模型。大多数数据项目的潜在来源和分析用例的数量庞大，很容易陷入专注于后端而排除客户的陷阱。
- en: 'Back to cost control: Every transformation and every pipeline execution costs
    money. An efficient data pipeline does as little as possible. If we can answer
    the business question: STOP. Show the customer. Get their feedback. Answer the
    next set of questions.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 回到成本控制：每次转换和每次管道执行都会花费金钱。高效的数据管道尽可能少做。如果我们能够回答业务问题：停止。展示给客户。获取他们的反馈。回答下一组问题。
- en: A good analytics GUI is extremely valuable because it gives the public access
    to the data. Additionally, it lets the customer ask questions about the data.
    The solutions the customer wants will then be about bringing in new data.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好的分析图形用户界面（GUI）非常有价值，因为它让公众可以访问数据。此外，它让客户可以询问有关数据的问题。客户想要的解决方案将会是关于引入新数据的。
- en: I used Tableau and published a specific answer for the simple application.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了 Tableau，并为简单应用发布了一个具体答案。
- en: '[![](../Images/7b6fea7cabaf0b1d7c391d35d3e38037.png)](https://public.tableau.com/views/KexpTopArtists/Artist?:language=en-US&:display_count=n&:origin=viz_share_link)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/7b6fea7cabaf0b1d7c391d35d3e38037.png)](https://public.tableau.com/views/KexpTopArtists/Artist?:language=en-US&:display_count=n&:origin=viz_share_link)'
- en: What are the ten artists on alternative radio since March 2020? (Source [Author's
    Public Table](https://public.tableau.com/app/profile/timothy.burns))
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 自 2020 年 3 月以来，替代电台上的十位艺术家是谁？（来源 [作者的公开表格](https://public.tableau.com/app/profile/timothy.burns)）
- en: In this example, I didn't need to apply any transformations to achieve the desired
    use case. It is suitable to stop transforming data when you can answer the business
    question and then focus on the next business question.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我不需要进行任何转换来实现预期的用例。当你能够回答业务问题时，停止数据转换，然后专注于下一个业务问题是合适的。
- en: Furthermore, give the customer full access to the data through a GUI like Tableau,
    and then they can answer some of the following questions themselves. The critical
    idea is that you publish the data so that the customer can *explore it on their
    own and provide feedback*.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，通过像 Tableau 这样的图形用户界面（GUI）为客户提供对数据的完全访问权限，然后他们可以自己回答以下一些问题。关键思想是，你发布数据，让客户可以*自行探索并提供反馈*。
- en: Pull more data when you can't answer the question with the data you have—iterate
    — repeat.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当你不能用现有数据回答问题时，获取更多数据——迭代——重复。
- en: Incremental Benefits of Analytics-Driven Data Products
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于分析的数据产品的增量好处
- en: The strongest argument for analytics-driven data products is that users realize
    value with every iteration. The less-obvious benefit is the separation of concerns
    from the data lake. The data lake can grow to parallel to generating use cases
    as a lossless data store. The engineers delivering the use cases can pull more
    and more data in as they satisfy more sophisticated questions.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 分析驱动的数据产品的最强有力的论据是，用户在每次迭代中都能感受到价值。较不明显的好处是将关注点与数据湖分开。数据湖可以作为无损数据存储与生成用例并行增长。交付用例的工程师可以随着他们满足更复杂的问题，拉取越来越多的数据。
- en: For example, in the use case for the toy problem, the playlist data can be continually
    updated while, at the same time, we load ticketing data from sources such as SeatGeek
    [[10](https://platform.seatgeek.com/)]. Even if we don't use it immediately, more
    data helps build value. The power of utilizing a data lake in conjunction with
    big data platforms reveals itself even for a toy problem.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在玩具问题的用例中，播放列表数据可以持续更新，同时我们从如 SeatGeek [[10](https://platform.seatgeek.com/)]
    等来源加载票务数据。即使我们不立即使用它，更多的数据也有助于建立价值。利用数据湖与大数据平台结合的力量，即使是在玩具问题中也会显现出来。
- en: Conclusion
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: The Data Cloud changes how we gather and use data [5]. We should focus on bringing
    data into the cloud and utilizing tools like Snowflake, Redshift, or Databricks
    to query the data. In that case, we open up value based on relationships we can
    imagine or establish using machine learning or other techniques.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 数据云改变了我们收集和使用数据的方式[5]。我们应该专注于将数据导入云端，并利用 Snowflake、Redshift 或 Databricks 等工具查询数据。在这种情况下，我们可以根据我们能想象或通过机器学习等技术建立的关系，发掘出更多的价值。
- en: When building data products, it is essential to pull the backend features through
    analytics use cases to make only the data structures you need, minimize cost,
    and ensure that your data products provide customer value.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建数据产品时，至关重要的是通过分析用例拉动后端功能，仅构建所需的数据结构，最小化成本，并确保您的数据产品提供客户价值。
- en: References
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[E. Ries (2011) The Lean Startup](https://theleanstartup.com/)'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[E. Ries (2011) 精益创业](https://theleanstartup.com/)'
- en: E.F. Codd, (1970) [A relational model of data for large shared data banks](https://dl.acm.org/doi/10.1145/362384.362685)
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: E.F. Codd, (1970) [大规模共享数据银行的关系模型](https://dl.acm.org/doi/10.1145/362384.362685)
- en: Kimball, Ross (2013) [The Data Warehousing Toolkit](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/books/data-warehouse-dw-toolkit/)
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kimball, Ross (2013) [数据仓库工具包](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/books/data-warehouse-dw-toolkit/)
- en: '[M. Karasou (2019) Adding Sequential IDs to a Spark Dataframe](/adding-sequential-ids-to-a-spark-dataframe-fa0df5566ff6)'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M. Karasou (2019) 向 Spark 数据框添加顺序 ID](/adding-sequential-ids-to-a-spark-dataframe-fa0df5566ff6)'
- en: '[F. Slootman, S. Hamm (2020) Rise of the Data Cloud](https://www.snowflake.com/wp-content/uploads/2020/11/Rise-of-the-Data-Cloud-The-Big-Idea.pdf)'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[F. Slootman, S. Hamm (2020) 数据云的崛起](https://www.snowflake.com/wp-content/uploads/2020/11/Rise-of-the-Data-Cloud-The-Big-Idea.pdf)'
- en: '[AWS (2023) What is Amazon Redshift](https://docs.aws.amazon.com/redshift/latest/mgmt/welcome.html)'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[AWS (2023) 什么是 Amazon Redshift](https://docs.aws.amazon.com/redshift/latest/mgmt/welcome.html)'
- en: '[A. Behm et al. (2022) Photon: A Fast Query Engine for Lakehouse Systems](https://cs.stanford.edu/~matei/papers/2022/sigmod_photon.pdf)'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[A. Behm 等人 (2022) Photon: 一个快速的湖仓系统查询引擎](https://cs.stanford.edu/~matei/papers/2022/sigmod_photon.pdf)'
- en: '[dbt Labs (2023) What is dbt?](https://docs.getdbt.com/docs/introduction)'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[dbt Labs (2023) 什么是 dbt?](https://docs.getdbt.com/docs/introduction)'
- en: '[M. Hagstroem et al. (2017) A Smarter Way to Jump into data lakes](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/a-smarter-way-to-jump-into-data-lakes#/)'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M. Hagstroem 等人 (2017) 更聪明地跳入数据湖](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/a-smarter-way-to-jump-into-data-lakes#/)'
- en: Seatgeek (2023) [Client API](https://platform.seatgeek.com/)
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Seatgeek (2023) [客户 API](https://platform.seatgeek.com/)
