- en: Transfer Learning For Beginner
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/transfer-learning-for-beginner-9b59490d1b9d](https://towardsdatascience.com/transfer-learning-for-beginner-9b59490d1b9d)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A practical guide to transfer learning in image classification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@mina.ghashami?source=post_page-----9b59490d1b9d--------------------------------)[![Mina
    Ghashami](../Images/745f53b94f5667a485299b49913c7a21.png)](https://medium.com/@mina.ghashami?source=post_page-----9b59490d1b9d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9b59490d1b9d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9b59490d1b9d--------------------------------)
    [Mina Ghashami](https://medium.com/@mina.ghashami?source=post_page-----9b59490d1b9d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9b59490d1b9d--------------------------------)
    ·7 min read·Oct 29, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: In this post, we will look at the concept of *transfer learning*, and we will
    see an example of it in *image classification task*.
  prefs: []
  type: TYPE_NORMAL
- en: What is Transfer Learning?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Transfer learning is a technique in deep learning where pre-trained models trained
    on large-scale datasets are used to solve new tasks with limited labeled data.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It involves taking a pre-trained model, which has learned rich and generalized
    feature representations from a source task, and fine-tuning it on a target task.
  prefs: []
  type: TYPE_NORMAL
- en: For example, ImageNet which is a large dataset (14 million images of 1000 classes)
    are often used to train large convolutional neural networks such as VGGNet or
    ResNet.
  prefs: []
  type: TYPE_NORMAL
- en: If we train these networks are ImageNet, these models learn to extract powerful
    and informative features. We call this training *pre-training* and these models
    are *pre-trained on ImageNet*. Note they are trained for image classification
    task on ImageNet. We call it the *source task*.
  prefs: []
  type: TYPE_NORMAL
- en: To do transfer learning on a new task which we call *target task*, first of
    all we need to have our labelled dataset which is called *target dataset*. Target
    dataset is often much much smaller than source dataset. Our source dataset here
    was huge (it has 14 million images).
  prefs: []
  type: TYPE_NORMAL
- en: Then, we take these pre-trained models and chop off the final classification
    layer, and add a new classifier layer at the end and train them on our own target
    dataset. When we are training, we freeze all layers except the last layer, as
    a result very few parameters are getting trained and therefore training happens
    fast. And Voila! we have done transfer learning.
  prefs: []
  type: TYPE_NORMAL
- en: The second training that model goes through is called *fine-tuning*. As we saw,
    during fine-tuning, most of the pre-trained weights are frozen, and only the final
    layers are adjusted to the new dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f900286ce6c6dc43ae7eb4b72e4f9a02.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: Benefits of Transfer Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The key advantages of transfer learning are that it allows you to capitalize
    on the expertise already developed in pre-trained models, hence avoids training
    large models from scratch. It also mitigates the need for large labeled datasets
    which are time-consuming to collect and annotate.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning a pre-trained model is much faster and computationally cheaper than
    training from scratch. These models often achieve high accuracy by building on
    top of general features learned during pretraining.
  prefs: []
  type: TYPE_NORMAL
- en: Caveats of Transfer Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Caveats of transfer learning is that the target task and dataset has to be close
    to the source task and dataset. Otherwise the knowledge learned during pre-training
    will be useless for the target task. If that’s the case, we are better off training
    the model from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: Practical Example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will use VGGNet to demonstrate transfer learning. In a [previous post](https://medium.com/towards-data-science/image-classification-for-beginners-8546aa75f331),
    we looked at VGGNet. Take a look if you are unfamiliar.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/image-classification-for-beginners-8546aa75f331?source=post_page-----9b59490d1b9d--------------------------------)
    [## Image Classification For Beginners'
  prefs: []
  type: TYPE_NORMAL
- en: VGG and ResNet architecture from 2014
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/image-classification-for-beginners-8546aa75f331?source=post_page-----9b59490d1b9d--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: VGG (Visual Geometry Group) is a deep convolutional neural network (CNN) architecture
    developed by the Visual Geometry Group at the University of Oxford. It comes in
    many variants such as VGG16 and VGG19\. All variants have similar architecture
    except the number of layers are different. For example, VGG-16 has 16 layers,
    including 13 convolutional layers and 3 fully connected layers.
  prefs: []
  type: TYPE_NORMAL
- en: '*VGGNet trained on ImageNet* is often used as a pre-trained model for transfer
    learning in image classification.'
  prefs: []
  type: TYPE_NORMAL
- en: For fine-tuning, we will use STL10 datasets which has 5000 small-sized color
    images (96x96 pixels) from 10 different classes. The dataset is split into a training
    set of 5000 images and a test set of 8000 images.
  prefs: []
  type: TYPE_NORMAL
- en: The STL10 dataset is our target dataset and the ImageNet is our source dataset
    and they are very similar in nature so it makes sense to use them in transfer
    learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a summary of our setup in a table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d9adc69ae7f73daa4a40e010704fe3bf.png)'
  prefs: []
  type: TYPE_IMG
- en: image by author
  prefs: []
  type: TYPE_NORMAL
- en: Load The Pretrained Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since the last layer of VGG is 1000 (as it was trained for ImageNet which contains
    1000 classes) we are removing that replacing it with a layer of 10 classes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'When we print VGG architecture, we see the following: the last 3 layers are
    the fully connected layers, of which the last fully connected layer is the classification
    head that classifies an input of 4096 dimension into 1000 classes.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7da9fbecfc5047f0493ca31e15b8e5df.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to chop off last layer and put a new layer that classifies input into
    10 classes! because STL10 has only 10 classes. So we do:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Data Preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We first load and transform our target data. The code is as following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We explain each section. First,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '***RandomCrop()*** takes two arguments — output size and padding. For example,
    with output size 32 and padding 4, it first pads the image by 4 pixels on each
    side, then takes a random 32x32 crop from the padded image.'
  prefs: []
  type: TYPE_NORMAL
- en: This allows the crop to include pixels from the edges of the original image,
    hence provides data augmentation by generating diverse crops from the same input.
    Without padding, the crops would always be from the center and not include edge
    regions.
  prefs: []
  type: TYPE_NORMAL
- en: This data augmentation, helps expose the model to different parts of the image,
    and improves generalization.
  prefs: []
  type: TYPE_NORMAL
- en: Second,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The ***ToTensor()***converts a PIL image or numpy array to a Tensor that can
    be fed into a neural network. It handles all the transformations required to go
    from image data to PyTorch-compatible tensor such as normalizing the data so that
    they are in (0,1) range, and transposes (H, W, C) array to (C, H, W) for PyTorch
    model input. For example, a RGB image would become a 3xHxW Tensor, and a grayscale
    image becomes a 1xHxW Tensor.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: normalizes the data by subtracting mean and dividing by standard deviation.
  prefs: []
  type: TYPE_NORMAL
- en: FinetuneThe Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two ways to fine-tune the model:'
  prefs: []
  type: TYPE_NORMAL
- en: either we freeze the previous layers and let the classification head only be
    trained.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: or we train all the layers together.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'While the first method is faster, the second will likely be more accurate.
    Let’s first train the model via option 2\. For that we need the following functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'and then putting them together brings us to the full training:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: If we decide to freeze some layers and not train them, we set `requires_grad
    = False` on the weights and biases of a layer to freeze that layer.
  prefs: []
  type: TYPE_NORMAL
- en: This concludes our topic of transfer learning in image classification.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Transfer learning is a technique where a model trained on one task is reused
    as the starting point for a model on a second related task. It allows you to leverage
    knowledge from a pretrained model instead of training a model from scratch. For
    example, wecan take an ImageNet pretrained model and retrain it on a new dataset
    of similar images. Features learned by the pre-trained model on the first task
    are transferred and reused on the new task.
  prefs: []
  type: TYPE_NORMAL
- en: Let me know if you have any comment or questions.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have any questions or suggestions, feel free to reach out to me:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Email: mina.ghashami@gmail.com'
  prefs: []
  type: TYPE_NORMAL
- en: 'LinkedIn: [https://www.linkedin.com/in/minaghashami/](https://www.linkedin.com/in/minaghashami/)'
  prefs: []
  type: TYPE_NORMAL
