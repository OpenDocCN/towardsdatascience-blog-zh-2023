["```py\n!pip install langchain\n!pip install openai\n!pip install chromadb\n!pip install tiktoken\n```", "```py\nimport requests\n\ntext_url = 'https://raw.githubusercontent.com/hwchase17/chat-your-data/master/state_of_the_union.txt'\nresponse = requests.get(text_url)\n\n#let'extract only the text from the response\ndata = response.text\n```", "```py\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.embeddings.cohere import CohereEmbeddings\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.vectorstores.elastic_vector_search import ElasticVectorSearch\nfrom langchain.vectorstores import Chroma\n```", "```py\nimport os\nos.environ[\"OPENAI_API_KEY\"] = \"your_open_ai_key\"\n```", "```py\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ntexts = text_splitter.split_text(data)\n```", "```py\nlen(texts)\n```", "```py\ntexts[0],texts[1]\n```", "```py\nembeddings = OpenAIEmbeddings()\n```", "```py\npersist_directory = 'db'\ndocsearch = Chroma.from_texts(\n    texts, \n    embeddings,\n    persist_directory = persist_directory,\n    metadatas=[{\"source\": f\"{i}-pl\"} for i in range(len(texts))]\n    )\n```", "```py\nfrom langchain.chains import RetrievalQAWithSourcesChain\n```", "```py\nfrom langchain import OpenAI\n\n#convert the vectorstore to a retriever\nretriever=docsearch.as_retriever()\n```", "```py\nretriever.search_type\n```", "```py\ndocs = retriever.get_relevant_documents(\"What did the president say about Justice Breyer\")\n```", "```py\nlen(docs)\n```", "```py\ndocs\n```", "```py\n#create the chain to answer questions\nchain = RetrievalQAWithSourcesChain.from_chain_type(\n    llm = OpenAI(temperature=0), \n    chain_type=\"stuff\", \n    retriever=retriever,\n    return_source_documents = True\n    )\n```", "```py\ndef process_result(result):\n  print(result['answer'])\n  print(\"\\n\\n Sources : \",result['sources'] )\n  print(result['sources'])\n```", "```py\nquestion = \"What did the president say about Justice Breyer\"\nresult = chain({\"question\": question})\nprocess_result(result)\n```"]