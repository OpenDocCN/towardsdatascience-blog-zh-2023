- en: OpenAI API — Intro & Implementation of the Models Behind ChatGPT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/openai-api-intro-11-practical-implementation-examples-of-the-models-behind-chatgpt-18601f68b51b](https://towardsdatascience.com/openai-api-intro-11-practical-implementation-examples-of-the-models-behind-chatgpt-18601f68b51b)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A programmatic approach to use models behind ChatGPT.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@fmnobar?source=post_page-----18601f68b51b--------------------------------)[![Farzad
    Mahmoodinobar](../Images/2d75209693b712300e6f0796bd2487d0.png)](https://medium.com/@fmnobar?source=post_page-----18601f68b51b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----18601f68b51b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----18601f68b51b--------------------------------)
    [Farzad Mahmoodinobar](https://medium.com/@fmnobar?source=post_page-----18601f68b51b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----18601f68b51b--------------------------------)
    ·19 min read·Nov 7, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/33ae9ba7ca530fc3af3daf6fde9e8927.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Freddy Castro](https://unsplash.com/@readysetfreddy?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/black-twist-pen-near-white-teacup-u3ajSXhZM_U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT needs no further introduction these days and in this post we would like
    to look deeper into how we can programmatically interact with the models and engines
    that power ChatGPT (e.g. GPT-4, GPT-3.5, DALL·E, etc.) through the official [OpenAI
    API](https://openai.com/blog/openai-api) (OpenAI is the company behind ChatGPT).
    Machine learning scientists and engineers generally demonstrate a preference for
    using APIs rather than graphical user interfaces, such as ChatGPT, since APIs
    provide a much higher level of flexibility and customization, as we will see in
    the implementation examples, which are required in business settings.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to use OpenAI’s API, we will set up and activate a Python virtual
    environment (this a recommended but optional step), install OpenAI Python library
    and start implementing 11 practical examples. These examples are my personal favorite
    ones among many that I have explored and will cover the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Explain Code
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Image Generation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Emoji Translation (i.e. we provide a text description and the model returns
    emojis that describe the provided text!)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Grammatical Error Correction
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Airport Code Extractor
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Named-Entity Extractor
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Machine Translation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sentiment Analysis
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Text Summarization
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Parse Unstructured Data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write SQL Queries
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I will provide more details about each task as we go through them but now that
    we know the outline of what we will cover, let’s get started!
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Setup Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This step is just to create a virtual environment so that you can isolate what
    is created and used in this post from your other Python bodies of work. As I mentioned
    earlier in the post, use of a virtual environment is optional but is generally
    among the recommended best practices for machine learning practitioners and programmers.
    There are more than one methods to create this and below is one approach that
    I have used. We will create the virtual environment, then activate it and then
    install OpenAI’s Python library (OpenAI’s Python library installation is a required
    step, even if you decide to skip the virtual environment step).
  prefs: []
  type: TYPE_NORMAL
- en: Mac users open your Terminal and Windows users open the Command Prompt (instructions
    are below, in case you are not familiar with this step) and follow along!
  prefs: []
  type: TYPE_NORMAL
- en: '**Tip:** How to open the “Terminal” (on Mac) or “Command Prompt” (on Windows)
    are as follows:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**- Mac Users:** Go to “Applications” folder or search for “Terminal” using
    “Spotlight” (Command + Space opens “Spotlight”)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**- Windows Users:** Search for “cmd” in the start menu to open the “Command
    Prompt”'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 1.1\. Virtual Environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With the Terminal or Command Prompt open, we can create the virtual environment
    named `openai-env` with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '`python -m venv openai-env`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the virtual environment is created, we can then activate it with the command
    below:'
  prefs: []
  type: TYPE_NORMAL
- en: '`source openai-env/bin/activate`'
  prefs: []
  type: TYPE_NORMAL
- en: Now we are in the newly-created and activated virtual environment. Next, we
    will install OpenAI’s Python library.
  prefs: []
  type: TYPE_NORMAL
- en: 1.2\. Install OpenAI Python Library
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Note that while use of a virtual environment was optional, installation of
    OpenAI Python library is a required step for implementation. The following command
    installs the latest OpenAI Python library:'
  prefs: []
  type: TYPE_NORMAL
- en: '`pip install — upgrade openai`'
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Setup API Key
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using OpenAI API requires setting up an OpenAI account and acquiring an OpenAI
    API Key — I will walk you through both steps.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up an OpenAI account can be accomplished through [OpenAI Sign-Up Website](https://platform.openai.com/signup).
    Once the OpenAI account is created, you can navigate to the [API Key Page](https://platform.openai.com/account/api-keys)
    and click on “Create new secret key”. You would want to save this somewhere safe
    and generally would not want to share your API Keys with others.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the API Key is set up, we will import it as follows, replacing the `YOUR_API_KEY`
    with your own recently-created OpenAI API Key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: With the prep work out of the way, we can finally focus on creating a function
    to call OpenAI’s API and start the fun part of implementing the examples!
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Call Function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will create a function to make a call to OpenAI’s API, which
    I named as the `magicWand`! Invoking OpenAI’s API requires passing a set of variables
    (covered below). Creation of this function will simplify the process so that we
    do not repeat the same steps for each example.
  prefs: []
  type: TYPE_NORMAL
- en: For all the examples, except for image generation, we will be using OpenAI’s
    [Chat Completion](https://platform.openai.com/docs/api-reference/chat/create)
    and will be using the following variables in the request. Understanding these
    variables at the moment is not required. We will learn how they work as we go
    through the examples but I have provided an overview for reference.
  prefs: []
  type: TYPE_NORMAL
- en: '`engine`: Identifies the model to be used, such as `gpt-4` or `gpt-3.5-turbo`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`system_prompt`: System-level prompt used to provide a high-level guidance
    about the task'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`user_prompt`: User-level prompt used to provide a more detailed instruction
    for the task'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`temperature`: This is a sampling temperature between 0 and 2\. Higher numbers
    (e.g. 0.8) will ensure the output is more randomly generated, while lower numbers
    (e.g. 0.2) will make it more deterministic'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_tokens`: Maximum number of tokens that the model will generate (this helps
    limit the length of the response)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will pass these variables as the values of a configuration dictionary with
    the following format in our examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Let’s create our function! At this point, do not worry about completely understanding
    the function. We will ask GPT-4 to explain the code to us, as the very first example!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 4\. Task Implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have the function, let’s try it for our first task, which is code
    explanation.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1\. Explain Code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As promised earlier, let’s ask GPT-4 to explain our own code to us to better
    understand the function!
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to do this, we will use the `magicWand` function that we just created
    and pass the values as demonstrated below. Note that the main instruction is the
    `system_prompt`, where we explain the task to GPT-4 as: `You will be provided
    with a piece of code, and your task is to explain it in a concise way`.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s implement this task and look at the results.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d7cf2f4c2f9408817b5de4f36ccbbf5b.png)'
  prefs: []
  type: TYPE_IMG
- en: GPT-4’s explanation of the `magicWand` function
  prefs: []
  type: TYPE_NORMAL
- en: I find the results quite impressive and fascinating at the same time. It provides
    a step-by-step explanation of what our `magciWand` function variables are and
    what they are intended to accomplish. Once you are done reading through the results,
    let’s move on to generating an image next!
  prefs: []
  type: TYPE_NORMAL
- en: 4.2\. Image Generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As the name suggests, we are going to generate an image this time. This is the
    only example where we do not use OpenAI’s Chat Completion and use OpenAI’s DALL·E
    model instead. Use case is pretty straight forward — we just provide the description
    of the image in `prompt`, the number of images as `n` and the size of the image
    as `size`. Let’s ask for `A black Scottish fold cat with light golden eyes laying
    down on white sheets` and look at the resulting image!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a95726232c85b10dc058de4e14dbd48b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image of a cat generated through OpenAI’s API
  prefs: []
  type: TYPE_NORMAL
- en: That’s a pretty good image and consistent with our prompt. Next, we will work
    on a fun request — we will ask GPT-4 to translate a natural language input (i.e.
    text) into emojis!
  prefs: []
  type: TYPE_NORMAL
- en: 4.3\. Emoji Translation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This one is probably my favorite example! We will ask GPT-4 to translate our
    text to emojis, using our very own `magicWand` function. We will provide GPT4
    the overall instruction as the `system_prompt` of `You will be provided with text,
    and your task is to translate it into emojis. Do not use any regular text. Do
    your best with emojis only` and then provide the `user_prompt` that needs to be
    translated from text to emoji as `Data science articles are fun`. Let’s look at
    the results!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cacce625834fc22556d3bdee818b7b93.png)'
  prefs: []
  type: TYPE_IMG
- en: GPT-4’s translation of text to emojis
  prefs: []
  type: TYPE_NORMAL
- en: That is quite interesting! I can see how the first half of the emojis relate
    to data and science and the second half of the emojis relate to being fun.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will ask GPT models to correct grammatical errors in a given sentence.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4\. Grammatical Error Correction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the use cases of machine learning models is the ability to correct grammatical
    errors present in a sentence. These can have many benefits in business settings.
    For example, businesses dealing with customer communications need to have human
    representatives read, review and respond to such customer communications. Human
    representatives are quite costly and if incoming messages are difficult to understand,
    such communications will require extra work for the humans to understand and then
    respond to. Alternatively, businesses can rely on grammatical error correction
    models to first clean up the incoming communications and then send the corrected
    version of the communications to the human representatives for review and action.
    I wrote a separate post on a different grammatical error correction model in the
    past (linked below) so I decided to use the same sentence with GPT models to see
    how GPT models perform!
  prefs: []
  type: TYPE_NORMAL
- en: '[](/grammatical-error-correction-with-machine-learning-overview-and-implementation-ccd0b50a1700?source=post_page-----18601f68b51b--------------------------------)
    [## Grammatical Error Correction with Machine Learning — Overview and Implementation'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using Grammatical Error Correction: Tag, Not Rewrite (GECTor)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/grammatical-error-correction-with-machine-learning-overview-and-implementation-ccd0b50a1700?source=post_page-----18601f68b51b--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: We will instruct both `gpt-4` or `gpt-3.5-turbo` to correct the grammatical
    errors in the sentence of `she looks at sky yesterday whil brushed her hair` and
    then will compare how they perform. Note there are intentional typos and grammatical
    errors in the sentence for the models to correct. In order to do so, we will use
    a `system_prompt` of `You will be provided with statements, and your task is to
    convert them to standard English` to both models and then provide the sentence
    as the `user_prompt`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s implement with GPT-3.5 and look at the results first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3f8ac713ae43e7b59e9f5280ccf4d638.png)'
  prefs: []
  type: TYPE_IMG
- en: GPT-3.5’s corrected sentence
  prefs: []
  type: TYPE_NORMAL
- en: 'And now let’s implement with GPT-4:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9afe59f4907fc787b532020bb9042628.png)'
  prefs: []
  type: TYPE_IMG
- en: GPT-4’s corrected sentence
  prefs: []
  type: TYPE_NORMAL
- en: First observation is that both models performed very well in correcting the
    grammatical errors and improving readability of the original sentence. The second
    observation is that `gpt-3.5-turbo` performed almost as well as `gpt-4` and given
    the higher cost of `gpt-4`, maybe we can just use the `gpt-3.5-turbo` going forward
    for grammatical error correction.
  prefs: []
  type: TYPE_NORMAL
- en: In the next example, we will ask GPT to identify airport codes inside a sentence!
  prefs: []
  type: TYPE_NORMAL
- en: 4.5\. Airport Code Extractor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I have to confess this task is a bit odd in nature and is something that I personally
    would not be able to do off the top of my head but we are going to ask GPT to
    return the airport codes from a text, with a `system_prompt` of `You will be provided
    with a text, and your task is to extract the airport codes from it` and a `user_prompt`
    of `I flew from Seattle to Boston in August`. Let’s use both `gpt-4` or `gpt-3.5-turbo`
    and compare the results, starting with GPT-3.5.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1754ca3b3280ed8af140277f81ea0e7d.png)'
  prefs: []
  type: TYPE_IMG
- en: GPT-3.5’s extracted airport names
  prefs: []
  type: TYPE_NORMAL
- en: 'And then let’s implement with GPT-4:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b533564d91530d33fb05acee0b1efeb1.png)'
  prefs: []
  type: TYPE_IMG
- en: GPT-4’s attempt at extracting airport names
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the results are both “technically” correct but also very different.
    `gpt-3.5-turbo` correctly returns the actual airport codes for the two city names
    of Seattle and Boston that are in the sentence, although the airport codes are
    not explicitly included in the prompt, as `gpt-4` states. My assumption here is
    that `gpt-3.5-turbo` is fine-tuned to be able return the airport codes, while
    `gpt-4` treats the task more literally and does not retrieve the airport codes
    — both are quite interesting to see.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s move on to identifying named-entities in a provided text.
  prefs: []
  type: TYPE_NORMAL
- en: 4.6\. Named-Entity Extractor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Named-entity recognition is a common natural language processing (NLP) task
    where named-entities such as names, locations, addresses, organizations, etc.
    are identified. This will become much easier to understand through an example.
    We will prompt both `gpt-4` and `gpt-3.5-turbo` with the `system_prompt` of `You
    will be provided with a text, and your task is to extract the named-entities from
    it` and the `user_prompt` of `I flew from Seattle to Boston in August. I remember
    I was wearing my brand new Nike shoes because I was so excited about them that
    I ended up leaving my iPhone in the yellow Camry cab`. We expect the models to
    identify named-entities such as Seattle, Boston, August, Nike, iPhone and Camry
    but let’s see how the models do, starting with GPT-3.5.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/48778af230d356b08a34eac443f2b945.png)'
  prefs: []
  type: TYPE_IMG
- en: GPT-3.5’s extracted named-entities
  prefs: []
  type: TYPE_NORMAL
- en: 'and let’s implement and look at the GPT-4 results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ed070a7f006c45d90c2256f4b3f1c6a3.png)'
  prefs: []
  type: TYPE_IMG
- en: GPT-4’s extracted named-entities
  prefs: []
  type: TYPE_NORMAL
- en: Very good results! Both models were able to recognize all the named-entities
    and unlike `gpt-4`, `gpt-3.5-turbo` was also able to return the type of the named-entity
    (e.g. Seattle and Boston are locations, etc.). So if I have a named-entity recognition
    task, I will be more likely to use `gpt-3.5-turbo`, which has the advantage of
    returning the type of the recognized named-entities and also is less expensive
    than `gpt-4`.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s move to the next task and ask the models to translate for us!
  prefs: []
  type: TYPE_NORMAL
- en: 4.7\. Machine Translation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This task is self-explanatory. We will include a `system_prompt` of `You will
    be provided with a text, and your task is to translate it to French` and then
    provide a `user_prompt` of `Can you help me with this task?` to be translated
    to French. I tested both GPT models and the results were identical so I’ll only
    include one of them below for reference.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/52fa96857b5324259c4cd61e63f493ab.png)'
  prefs: []
  type: TYPE_IMG
- en: GPT-4’s English to French translation results
  prefs: []
  type: TYPE_NORMAL
- en: That’s a good translation as expected! Feel free to play around with the `system_prompt`
    and have the models translate the `user_prompt` to other languages!
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will look at sentiment analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 4.8\. Sentiment Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sentiment analysis is another common NLP task. At its most basic form, it tells
    whether a sentence carries a positive, negative or neutral sentiment. This can
    be quite useful for businesses in understanding their customers’ feedback. For
    example, a model can consume all customer reviews of a restaurant, product or
    service and return the percentage of the comments that are positive, neutral or
    negative and use that as an overall rating for that restaurant, product, or service!
  prefs: []
  type: TYPE_NORMAL
- en: Let’s instruct `gpt-4` with a `system_prompt` of `You will be provided with
    a text, and your task is to provide a nuanced sentiment analysis` and the `user_prompt`
    of `That was such an exciting movie`. Note that the sentence sounds quite positive
    so we want to see whether the sentiment analysis results are aligned with that
    expectation.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the results!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/237409237e9a44114f8abda019aaf88b.png)'
  prefs: []
  type: TYPE_IMG
- en: GPT-4’s sentiment analysis results
  prefs: []
  type: TYPE_NORMAL
- en: As expected, `gpt-4` also agrees that the sentence is a positive one and adds
    a second sentence that sounds like the reasoning behind the model’s decision.
    It is important to note that the “reasoning” provided may or may not be true,
    since LLMs, such as GPT-4 are not exactly deterministic — it only indicates that
    the model associates “exciting” with enjoyment, engagement and a positive sentiment
    — there is a lot we do not know about how these models generate what they generate
    but that is a topic for another day.
  prefs: []
  type: TYPE_NORMAL
- en: As the next task, let’s ask the model to summarize a text!
  prefs: []
  type: TYPE_NORMAL
- en: 4.9\. Text Summarization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Text summarization is another self-explanatory task. Imagine when we call a
    customer support line and the representative wants to read the previous communications
    on this topic between customer support and the customer. Instead of reading the
    entire correspondence, a model would summarize the most important parts of the
    past communications and then the customer support representative would only read
    the summary provided by the model. This saves valuable time both for the customer
    and the service provider.
  prefs: []
  type: TYPE_NORMAL
- en: In order to do so, let’s provide GPT-4 with the `system_prompt` of `You will
    be provided with a text, and your task is to provide a summary of it, without
    using the original words` and provide a lengthy text to be summarized as the `user_prompt`
    of `Text summarization is the task of automatically summarizing textual input,
    while still conveying the main points and gist of the incoming text. One example
    of the business intuition behind the need for such summarization models is the
    situations where humans read incoming text communications (e.g. customer emails)
    and using a summarization model can save human time`.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see the results!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0430abc250092e1842774eca2399b5de.png)'
  prefs: []
  type: TYPE_IMG
- en: GPT-4’s text summarization results
  prefs: []
  type: TYPE_NORMAL
- en: That seems to be a good summary of the provided text! I don’t think I could
    have done a much better job myself.
  prefs: []
  type: TYPE_NORMAL
- en: Next task is for those dealing with data analytics, which is parsing through
    unstructured data.
  prefs: []
  type: TYPE_NORMAL
- en: 4.10\. Parse Unstructured Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This one is quite useful for those users who have to deal with a lot of unstructured
    data. We can have the model go through the text and then organize the data into
    groups. Let’s look at an example to better understand this.
  prefs: []
  type: TYPE_NORMAL
- en: We will provide GPT-4 with the `system_prompt` of `You will be provided with
    unstructured data, and your task is to parse it into a Pandas dataframe` and then
    provide the unstructured data as the `user_prompt` of `As I was walking around
    Mars a few days ago, I came across a group of Amazon employees. The first one,
    Jack, was originally from Boston and wore black pants with a white shirt and black
    running shoes. Another one, Jill, had a long indigo-colored dress on with light
    blue sandals and was originally from Seattle. The third one was named John. I
    cannot remember what he was wearing but I particularly recall that John was from
    Newark, New Jersey. The last individual was Jenna and she was from San Francisco.
    Jenna had a white t-shirt and blue pants on but I cannot recall her shoes`.
  prefs: []
  type: TYPE_NORMAL
- en: You can see that the `user_prompt` includes names of the individuals and what
    they wear. Let’s see how the model can organize this information.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/83d9ada2103499ef038f451c29a2a206.png)'
  prefs: []
  type: TYPE_IMG
- en: GPT-3.5’s structured output of the unstructured input
  prefs: []
  type: TYPE_NORMAL
- en: That is quite impressive and well done! As you can see, GPT-3.5 was able to
    go through the provided text and organize (i.e. parse) it into relevant columns
    for each of the individuals. This parsing used to be done mostly manually in the
    past and can be very helpful when one wishes to analyze the data in a tabular
    format.
  prefs: []
  type: TYPE_NORMAL
- en: As the last task, we will ask the model to write a SQL query for us!
  prefs: []
  type: TYPE_NORMAL
- en: 4.11\. Write SQL Queries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I was personally curious about the SQL writing abilities of GPT models, since
    I use SQL quite frequently for work and had posted the below SQL tutorial on Medium
    in the past.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/@fmnobar/sql-requirements-for-a-data-scientist-in-amazon-cheat-sheet-b1e24004ede7?source=post_page-----18601f68b51b--------------------------------)
    [## SQL Tutorial + Cheat Sheet'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@fmnobar/sql-requirements-for-a-data-scientist-in-amazon-cheat-sheet-b1e24004ede7?source=post_page-----18601f68b51b--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: In order to evaluate the abilities of GPT models, I selected one of the examples
    that I had used in my SQL post above and asked `gpt-3.5-turbo` to write the query
    that I had prepared myself. In order to do so, we want to define the table to
    be queried as part of the `system_prompt` and then define the task in the `user_prompt`
    as usual. Let’s look at the implementation of this example, followed by the results
    and comparison to the query I had written myself.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/20ecac63eff1c1aad69637eba3960aea.png)'
  prefs: []
  type: TYPE_IMG
- en: GPT-3.5’s query
  prefs: []
  type: TYPE_NORMAL
- en: This is quite impressive! This query involves using window functions, which
    are among the more challenging concepts in SQL but the model is handling them
    quite well. Below is my own solution from the post above for reference and as
    you can see the overall structure of the response from the model is quite similar
    to how I had written the query!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e8e69df00c7fa3a83ac678736296c64f.png)'
  prefs: []
  type: TYPE_IMG
- en: My own query
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this post, we walked through OpenAI’s API, which provides access to the behind-the-scene
    models enabling ChatGPT perform various tasks. Then we implemented 11 examples
    of chat completion and image generation using OpenAI’s API and compared the performance
    of `gpt-4` and `gpt-3.5-turbo` for some of these tasks. Overall, I found both
    GPT models quite powerful and consider them useful tools for my personal use and
    DALL·E is an impressive image generator.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks For Reading!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you found this post helpful, please [follow me on Medium](https://medium.com/@fmnobar)
    and [subscribe](https://medium.com/@fmnobar/subscribe) to receive my latest posts!
  prefs: []
  type: TYPE_NORMAL
- en: (All images, unless otherwise noted, are by the author.)
  prefs: []
  type: TYPE_NORMAL
