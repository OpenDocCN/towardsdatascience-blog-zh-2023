["```py\nimport numpy as np\nimport librosa\n```", "```py\nPATH = \"audio_example.wav\" # Replace with your file here\noriginal_audio, sample_rate = librosa.load(PATH)\n```", "```py\n# Code copied and edited from https://www.kaggle.com/code/kaerunantoka/birdclef2022-use-2nd-label-f0\nnoise_factor = 0.005\nwhite_noise = np.random.randn(len(original_audio)) * noise_factor\n```", "```py\n# Code copied and edited from https://www.kaggle.com/code/kaerunantoka/birdclef2022-use-2nd-label-f0\nimport colorednoise as cn\n\npink_noise = cn.powerlaw_psd_gaussian(1, len(original_audio))\n```", "```py\n# Load background noise from another audio file\nbackground_noise, sample_rate = librosa.load(\"background_noise.wav\")\n```", "```py\naugmented_audio = original_audio + noise\n```", "```py\n# Code copied and edited from https://www.kaggle.com/code/CVxTz/audio-data-augmentation/notebook\naugmented_audio = np.roll(original_audio, 3000)\n```", "```py\n# Code copied and edited from https://www.kaggle.com/code/CVxTz/audio-data-augmentation/notebook\nrate = 0.9\naugmented_audio = librosa.effects.time_stretch(original_audio, rate = rate)\n```", "```py\n# Code copied and edited from https://www.kaggle.com/code/CVxTz/audio-data-augmentation/notebook\naugmented_audio = librosa.effects.pitch_shift(original_audio, sampling_rate, pitch_factor)\n```", "```py\n# Increase volume by 5 dB\naugmented_audio = original_audio + 5\n\n# Decrease volume by 5 dB\naugmented_audio = original_audio - 5\n```", "```py\noriginal_melspec = librosa.feature.melspectrogram(y = original_audio,\n                                                  sr = sample_rate, \n                                                  n_fft = 512, \n                                                  hop_length = 256, \n                                                  n_mels = 40).T\n\noriginal_melspec = librosa.power_to_db(original_melspec)\n```", "```py\n# Code copied and edited from https://www.kaggle.com/code/kaerunantoka/birdclef2022-use-2nd-label-f0\ndef mixup(original_melspecs, original_labels, alpha=1.0):\n    indices = torch.randperm(original_melspecs.size(0))\n\n    lam = np.random.beta(alpha, alpha)\n\n    augmented_melspecs = original_melspecs * lam + original_melspecs[indices] * (1 - lam)\n    augmented_labels = [(original_labels * lam), (original_labels[indices] * (1 - lam))]\n\n    return augmented_melspec, augmented_labels\n```", "```py\n# Code copied and edited from https://www.kaggle.com/code/davids1992/specaugment-quick-implementation\ndef spec_augment(original_melspec,\n                 freq_masking_max_percentage = 0.15, \n                 time_masking_max_percentage = 0.3):\n\n    augmented_melspec = original_melspec.copy()\n    all_frames_num, all_freqs_num = augmented_melspec.shape\n\n    # Frequency masking\n    freq_percentage = random.uniform(0.0, freq_masking_max_percentage)\n    num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n    f0 = int(np.random.uniform(low = 0.0, high = (all_freqs_num - num_freqs_to_mask)))\n\n    augmented_melspec[:, f0:(f0 + num_freqs_to_mask)] = 0\n\n    # Time masking\n    time_percentage = random.uniform(0.0, time_masking_max_percentage)\n    num_frames_to_mask = int(time_percentage * all_frames_num)\n    t0 = int(np.random.uniform(low = 0.0, high = (all_frames_num - num_frames_to_mask)))\n\n    augmented_melspec[t0:(t0 + num_frames_to_mask), :] = 0\n\n    return augmented_melspec\n```", "```py\nimport torch\nimport torchaudio\nimport torchaudio.transforms as T\n\ntime_masking = T.TimeMasking(time_mask_param = 80)\nfreq_masking = T.FrequencyMasking(freq_mask_param=80)\n\naugmented_melspec = time_masking(original_melspec)\naugmented_melspec = freq_masking(augmented_melspec)\n```"]