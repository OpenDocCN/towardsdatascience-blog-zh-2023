["```py\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\n\nX, y = make_classification(n_samples=100, n_features=2, \n                           n_classes=2, n_redundant=0, \n                           n_informative=2, n_clusters_per_class=1, \n                           random_state=42)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n```", "```py\nimport matplotlib.pyplot as plt\n\nplt.scatter(X_train[:, 0], X_train[:, 1], color='red', marker='o')\nplt.scatter(X_test[:, 0], X_test[:, 1], color='green', marker='s')\nplt.xlabel('feature_idx_0')\nplt.ylabel('feature_idx_1')\nplt.tight_layout()\nplt.show()\n```", "```py\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(X_train)\n```", "```py\nX_train_std = scaler.transform(X_train)\n```", "```py\nX_train_std = scaler.fit_transform(X_train)\n```", "```py\nX_test_std = scaler.transform(X_test)\n```", "```py\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestClassifier\n\npipeline = Pipeline(steps=[('scaler', StandardScaler()),\n                           ('pca', PCA(n_components=2, random_state=42)),\n                           ('estimator', RandomForestClassifier(n_estimators=3, max_depth=5))])\n```", "```py\nfrom sklearn.pipeline import make_pipeline\n\npipeline_2 = make_pipeline(StandardScaler(),\n                           PCA(n_components=2, random_state=42),\n                           RandomForestClassifier(n_estimators=3, max_depth=5))\n```", "```py\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestClassifier\n\npipeline = Pipeline(steps=[('scaler', StandardScaler()),\n                           ('pca', PCA(n_components=2, random_state=42)),\n                           ('estimator', RandomForestClassifier(n_estimators=3, max_depth=5))])\n```", "```py\nimport time\n\nfrom sklearn.model_selection import GridSearchCV\n\npipeline = Pipeline(steps=[('scaler', StandardScaler()),\n                           ('pca', PCA()),\n                           ('estimator', RandomForestClassifier())])\nparam_grid = {'pca__n_components': [2, 'mle'],\n              'estimator__n_estimators': [3, 5, 7],\n              'estimator__max_depth': [3, 5]}\n\nstart = time.perf_counter()\nclf = GridSearchCV(pipeline, param_grid=param_grid, cv=5, n_jobs=4)\nclf.fit(X, y)\n\n# It takes 2.39 seconds to finish the search on my laptop.\nprint(f\"It takes {time.perf_counter() - start} seconds to finish the search.\")\n```", "```py\npipeline_m = Pipeline(steps=[('scaler', StandardScaler()),\n                           ('pca', PCA()),\n                           ('estimator', RandomForestClassifier())],\n                      memory='./cache')\nstart = time.perf_counter()\nclf_m = GridSearchCV(pipeline_m, param_grid=param_grid, cv=5, n_jobs=4)\nclf_m.fit(X, y)\n\n# It takes 0.22 seconds to finish the search with memory parameter.\nprint(f\"It takes {time.perf_counter() - start} seconds to finish the search with memory.\")\n```", "```py\nimport logging\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger()\n```", "```py\nclass LoggingTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, transformer):\n        self.transformer = transformer\n        self.real_name = self.transformer.__class__.__name__\n\n    def fit(self, X, y=None):\n        logging.info(f\"Begin fit: {self.real_name}\")\n        self.transformer.fit(X, y)\n        logging.info(f\"End fit: {self.real_name}\")\n        return self\n\n    def fit_transform(self, X, y=None):\n        logging.info(f\"Begin fit_transform: {self.real_name}\")\n        X_fit_transformed = self.transformer.fit_transform(X, y)\n        logging.info(f\"End fit_transform: {self.real_name}\")\n        return X_fit_transformed\n\n    def transform(self, X):\n        logging.info(f\"Begin transform: {self.real_name}\")\n        X_transformed = self.transformer.transform(X)\n        logging.info(f\"End transform: {self.real_name}\")\n        return X_transformed\n```", "```py\npipeline_logging = Pipeline(steps=[('scaler', LoggingTransformer(StandardScaler())),\n                             ('pca', LoggingTransformer(PCA(n_components=2))),\n                             ('estimator', RandomForestClassifier(n_estimators=5, max_depth=3))])\npipeline_logging.fit(X_train, y_train)\n```", "```py\nparam_grid = {'scaler': ['passthrough'],\n              'pca__n_components': [2, 'mle'],\n              'estimator__n_estimators': [3, 5, 7],\n              'estimator__max_depth': [3, 5]}\nclf = GridSearchCV(pipeline, param_grid=param_grid, cv=5, n_jobs=4)\nclf.fit(X, y)\n```", "```py\nfrom joblib import dump, load\n\n# save pipeline\ndump(pipeline, 'model_pipeline.joblib')\n\n# load pipeline\nloaded_pipeline = load('model_pipeline.joblib')\n\n# predict with loaded pipeline\nloaded_predictions = loaded_pipeline.predict(X_test)\n```"]