["```py\n**Table of Contents:**\n\nDefiningthe p-values\nWhy we could avoid p-values as Data Scientists\nWhat to use instead of p-values as Data Scientists\nAn example in Python\n```", "```py\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Generate some random data\nn_samples = 1000\nX = np.random.uniform(-10, 10, size=(n_samples, 5))\ny = 3*X[:,0]**3 + 2*X[:,1]**2 + 5*X[:,2] + np.random.normal(0, 20, n_samples)\n\n# Create a pandas DataFrame\ndf = pd.DataFrame(X, columns=['x1', 'x2', 'x3', 'x4', 'x5'])\ndf['y'] = y\n\n# Fit a 3-degree polynomial regression model\nX = df[['x1', 'x2', 'x3', 'x4', 'x5']]\ny = df['y']\npoly_reg = LinearRegression()\npoly_reg.fit(X ** 3 + X ** 2 + X, y)\n\n# Calculate the R-squared value\ny_pred = poly_reg.predict(X ** 3 + X ** 2 + X)\nr2 = r2_score(y, y_pred)\n\n# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n```", "```py\nimport statsmodels.api as sm\n\n# Add a constant term to X_train\nX_train_with_const = sm.add_constant(X_train)\n\n# Fit linear regression model with statsmodels\nlin_reg_sm = sm.OLS(y_train, X_train_with_const).fit()\n\n# Print summary of the model\nprint(lin_reg_sm.summary())\n```", "```py\n#creating quadratic and cubic features\nquadratic = PolynomialFeatures(degree=2)\ncubic = PolynomialFeatures(degree=3)\n\nX_quad = quadratic.fit_transform(X_train) #quadratical transformation\nX_cubic = cubic.fit_transform(X_train) #cubical tranformation\n\n# Add a constant term to X_train\nX_train_with_const_quad = sm.add_constant(X_quad)\nX_train_with_const_cub = sm.add_constant(X_cubic)\n\n# Fit polynomial regression models with statsmodels\nquad_reg_sm = sm.OLS(y_train, X_train_with_const_quad).fit()\ncub_reg_sm = sm.OLS(y_train, X_train_with_const_cub).fit()\n\n# Print summary of the model\nprint(quad_reg_sm.summary())\nprint(cub_reg_sm.summary())\n```", "```py\n**NOTE:**\n\nfor the sake of clarity, we are using again the 2-degree and 3-degree\npolynomial transformation, even if we shouldn't if we were using\na Jupyter Notebook (we've already done the transformation above).\n```", "```py\n# Fit linear regression model to the train set\nlin_reg = LinearRegression().fit(X_train, y_train)\n\n# Create quadratic and cubic features\nquadratic = PolynomialFeatures(degree=2)\ncubic = PolynomialFeatures(degree=3)\n\nX_quad = quadratic.fit_transform(X_train) #quadratical transformation\nX_cubic = cubic.fit_transform(X_train) #cubical tranformation\n\n# Fit quadratic and cubic transformed set\nquad_reg = LinearRegression().fit(X_quad, y_train)\ncubic_reg = LinearRegression().fit(X_cubic, y_train)\n\n# Calculate R^2 on test set\nprint(f'Coeff. of determination linear reg test set:{lin_reg.score(X_test, y_test): .2f}')\nprint(f'Coeff. of determination quadratic reg test set:{quad_reg.score(quadratic.transform(X_test), y_test): .2f}') \nprint(f'Coeff. of determination cubic reg test set:{cubic_reg.score(cubic.transform(X_test), y_test): .2f}')\n\n>>>\n\n  Coeff. of determination linear reg test set: 0.81\n  Coeff. of determination quadratic reg test set: 0.81\n  Coeff. of determination cubic reg test set: 1.00\n```", "```py\n#Kernel Density Estimation plot\nax = sns.kdeplot(y_test, color='r', label='Actual Values') #actual values\nsns.kdeplot(y_test_pred_lin, color='b', label='Predicted Values', ax=ax) #predicted values\n\n#showing title\nplt.title('Actual vs Predicted values for linear model')\n#showing legend\nplt.legend()\n#showing plot\nplt.show()\n```", "```py\n#Kernel Density Estimation plot\nax = sns.kdeplot(y_test, color='r', label='Actual Values') #actual values\nsns.kdeplot(y_test_pred_quad, color='b', label='Predicted Values', ax=ax) #predicted values\n\n#showing title\nplt.title('Actual vs Predicted values for quadratic model')\n#showing legend\nplt.legend()\n#showing plot\nplt.show()\n```", "```py\n#Kernel Density Estimation plot\nax = sns.kdeplot(y_test, color='r', label='Actual Values') #actual values\nsns.kdeplot(y_test_pred_cub, color='b', label='Predicted Values', ax=ax) #predicted values\n\n#showing title\nplt.title('Actual vs Predicted values for the cubic model')\n#showing legend\nplt.legend()\n#showing plot\nplt.show()\n```"]