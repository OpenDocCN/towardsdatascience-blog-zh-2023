["```py\ngit clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git\n```", "```py\ncp 768-v-ema.ckpt models/Stable-diffusion\n```", "```py\npython launch.py\n```", "```py\nRunning on local URL:  http://127.0.0.1:7860\n```", "```py\npython launch.py --api\n```", "```py\npython launch.py --api\n```", "```py\nINFO:     Uvicorn running on http://127.0.0.1:7860 (Press CTRL+C to quit)\n```", "```py\npython launch.py --nowebui\n```", "```py\npip install requests\n```", "```py\nimport json\nimport base64\n\nimport requests\n\ndef submit_post(url: str, data: dict):\n    \"\"\"\n    Submit a POST request to the given URL with the given data.\n    \"\"\"\n    return requests.post(url, data=json.dumps(data))\n\ndef save_encoded_image(b64_image: str, output_path: str):\n    \"\"\"\n    Save the given image to the given output path.\n    \"\"\"\n    with open(output_path, \"wb\") as image_file:\n        image_file.write(base64.b64decode(b64_image))\n\nif __name__ == '__main__':\n    txt2img_url = 'http://127.0.0.1:7860/sdapi/v1/txt2img'\n    data = {'prompt': 'a dog wearing a hat'}\n    response = submit_post(txt2img_url, data)\n    save_encoded_image(response.json()['images'][0], 'dog.png')\n```", "```py\npython sample-request.py\n```", "```py\nimport torch\nfrom torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights\nfrom torchvision.io.image import read_image\nfrom torchvision.utils import draw_segmentation_masks\nimport matplotlib.pyplot as plt\n\nif __name__ == '__main__':\n    img_path = 'woman-on-trail.png'\n\n    # Load model\n    weights = FCN_ResNet50_Weights.DEFAULT\n    model = fcn_resnet50(weights=weights, progress=False)\n    model = model.eval()\n\n    # Load image\n    img = read_image(img_path)\n\n    # Run model\n    input_tform = weights.transforms(resize_size=None)\n    batch = torch.stack([input_tform(img)])\n    output = model(batch)['out']\n\n    # Apply softmax to outputs\n    sem_class_to_idx = {cls: idx for (idx, cls) in enumerate(weights.meta['categories'])}\n    normalized_mask = torch.nn.functional.softmax(output, dim=1)\n\n    # Show results\n    class_idx = 1\n    binary_masks = (normalized_mask.argmax(class_idx) == sem_class_to_idx['person'])\n    img_masked = draw_segmentation_masks(img, masks=binary_masks, alpha=0.7)\n    plt.imshow(img_masked.permute(1, 2, 0).numpy())\n    plt.show()\n```", "```py\npython segment-person.py\n```", "```py\npython inpaint-person.py woman-on-trail.png -W 1152 -H 768\n```", "```py\npython inpaint-person.py woman-on-trail.png -W 1152 -H 768 -B\n```", "```py\npython inpaint-person.py woman-on-trail.png \\\n    -W 1152 -H 768 \\\n    -b 16 -B -D 32 \\\n    -p \"mountain scenery, landscape, trail\"\n```"]