["```py\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dropout\nfrom keras.layers.core import Dense\nfrom keras import backend as K\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import classification_report\nfrom keras.optimizers import SGD\nfrom keras.datasets import cifar10\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline\n```", "```py\nclass MiniVGGNet:\n @staticmethod\n def build(width, height, depth, classes):\n  # initialize the model along with the input shape to be\n  # \"channels last\" and the channels dimension itself\n  model = Sequential()\n  inputShape = (height, width, depth)\n  chanDim = -1\n\n  if K.image_data_format() == \"channels_first\":\n   inputShape = (depth, height, width)\n   chanDim = 1\n\n  # first CONV => Activation => CONV => Activation => POOL layer set\n  model.add(Conv2D(32, (3, 3), padding=\"same\",\n   input_shape=inputShape))\n  model.add(Activation(\"relu\"))\n  model.add(BatchNormalization(axis=chanDim))\n  model.add(Conv2D(32, (3, 3), padding=\"same\"))\n  model.add(Activation(\"relu\"))\n  model.add(BatchNormalization(axis=chanDim))\n  model.add(MaxPooling2D(pool_size=(2, 2)))\n  model.add(Dropout(0.25))\n\n  # second CONV => Activation => CONV => Activation => POOL layer set\n  model.add(Conv2D(64, (3, 3), padding=\"same\"))\n  model.add(Activation(\"relu\"))\n  model.add(BatchNormalization(axis=chanDim))\n  model.add(Conv2D(64, (3, 3), padding=\"same\"))\n  model.add(Activation(\"relu\"))\n  model.add(BatchNormalization(axis=chanDim))\n  model.add(MaxPooling2D(pool_size=(2, 2)))\n  model.add(Dropout(0.25))\n\n  # Dense Layer\n  model.add(Flatten())\n  model.add(Dense(512))\n  model.add(Activation(\"relu\"))\n  model.add(BatchNormalization())\n  model.add(Dropout(0.5))\n\n  # softmax classifier\n  model.add(Dense(classes))\n  model.add(Activation(\"softmax\"))\n\n  # return the constructed network architecture\n  return model\n```", "```py\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nx_train = x_train.astype(\"float\") / 255.0 \nx_test = x_test.astype(\"float\") / 255.0 \n```", "```py\nlabelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n```", "```py\nlb = LabelBinarizer()\ny_train = lb.fit_transform(y_train)\ny_test = lb.transform(y_test)\n```", "```py\noptimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.01, decay=0.01/40, momentum=0.9,\n                                           nesterov=True)\nmodel = miniVGGNet.build(width = 32, height = 32, depth = 3, classes=10)\nmodel.compile(loss='categorical_crossentropy', optimizer = optimizer,\n              metrics=['accuracy'])\nh = model.fit(x_train, y_train, validation_data=(x_test, y_test),\n              batch_size = 64, epochs=10, verbose=1)\n```", "```py\nEpoch 1/10\n782/782 [==============================] - 424s 539ms/step - loss: 1.6196 - accuracy: 0.4592 - val_loss: 1.4083 - val_accuracy: 0.5159\nEpoch 2/10\n782/782 [==============================] - 430s 550ms/step - loss: 1.1437 - accuracy: 0.6039 - val_loss: 1.0213 - val_accuracy: 0.6505\nEpoch 3/10\n782/782 [==============================] - 430s 550ms/step - loss: 0.9634 - accuracy: 0.6618 - val_loss: 0.8495 - val_accuracy: 0.7013\nEpoch 4/10\n782/782 [==============================] - 427s 546ms/step - loss: 0.8532 - accuracy: 0.6998 - val_loss: 0.7881 - val_accuracy: 0.7215\nEpoch 5/10\n782/782 [==============================] - 425s 543ms/step - loss: 0.7773 - accuracy: 0.7280 - val_loss: 0.8064 - val_accuracy: 0.7228\nEpoch 6/10\n782/782 [==============================] - 421s 538ms/step - loss: 0.7240 - accuracy: 0.7451 - val_loss: 0.6757 - val_accuracy: 0.7619\nEpoch 7/10\n782/782 [==============================] - 420s 537ms/step - loss: 0.6843 - accuracy: 0.7579 - val_loss: 0.6564 - val_accuracy: 0.7715\nEpoch 8/10\n782/782 [==============================] - 420s 537ms/step - loss: 0.6405 - accuracy: 0.7743 - val_loss: 0.6833 - val_accuracy: 0.7706\nEpoch 9/10\n782/782 [==============================] - 422s 540ms/step - loss: 0.6114 - accuracy: 0.7828 - val_loss: 0.6188 - val_accuracy: 0.7848\nEpoch 10/10\n782/782 [==============================] - 421s 538ms/step - loss: 0.5799 - accuracy: 0.7946 - val_loss: 0.6166 - val_accuracy: 0.7898\n```", "```py\nclass miniVGGNet:\n  @staticmethod \n\n  def build(width, height, depth, classes):\n    model = Sequential()\n    inputShape = (height, width, depth)\n    chanDim = -1 \n\n    if K.image_data_format() == \"channels_first\":\n      inputShape = (depth, height, width)\n      chanDim = 1\n\n    # first Conv => Activation => Conv => Activation => Pool layer set\n    model.add(Conv2D(64, (3, 3), padding=\"same\",\n   input_shape=inputShape))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization(axis=chanDim))\n    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization(axis=chanDim))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n  # second Conv => Activation => Conv => Activation => Pool layer set\n    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization(axis=chanDim))\n    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization(axis=chanDim))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n  # Dense Layer\n    model.add(Flatten())\n    model.add(Dense(300))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n    model.add(Dense(classes))\n    model.add(Activation(\"softmax\"))\n    return model\n```", "```py\noptimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.01, decay=0.01/40, momentum=0.9,\n                                           nesterov=True)\nmodel = miniVGGNet.build(width = 32, height = 32, depth = 3, classes=10)\nmodel.compile(loss='categorical_crossentropy', optimizer = optimizer,\n              metrics=['accuracy'])\nh = model.fit(x_train, y_train, validation_data=(x_test, y_test),\n              batch_size = 64, epochs=20, verbose=1)\n```", "```py\nEpoch 1/20\n782/782 [==============================] - 22s 18ms/step - loss: 1.5210 - accuracy: 0.4697 - val_loss: 1.1626 - val_accuracy: 0.5854\nEpoch 2/20\n782/782 [==============================] - 14s 18ms/step - loss: 1.0706 - accuracy: 0.6219 - val_loss: 0.9913 - val_accuracy: 0.6586\nEpoch 3/20\n782/782 [==============================] - 14s 18ms/step - loss: 0.8947 - accuracy: 0.6826 - val_loss: 0.8697 - val_accuracy: 0.6941\nEpoch 4/20\n782/782 [==============================] - 14s 18ms/step - loss: 0.7926 - accuracy: 0.7208 - val_loss: 0.7649 - val_accuracy: 0.7294\nEpoch 5/20\n782/782 [==============================] - 14s 18ms/step - loss: 0.7192 - accuracy: 0.7470 - val_loss: 0.6937 - val_accuracy: 0.7593\nEpoch 6/20\n782/782 [==============================] - 13s 17ms/step - loss: 0.6641 - accuracy: 0.7640 - val_loss: 0.6899 - val_accuracy: 0.7639\nEpoch 7/20\n782/782 [==============================] - 13s 17ms/step - loss: 0.6141 - accuracy: 0.7805 - val_loss: 0.6589 - val_accuracy: 0.7742\nEpoch 8/20\n782/782 [==============================] - 13s 17ms/step - loss: 0.5774 - accuracy: 0.7960 - val_loss: 0.6565 - val_accuracy: 0.7734\nEpoch 9/20\n782/782 [==============================] - 14s 17ms/step - loss: 0.5430 - accuracy: 0.8077 - val_loss: 0.6092 - val_accuracy: 0.7921\nEpoch 10/20\n782/782 [==============================] - 14s 18ms/step - loss: 0.5145 - accuracy: 0.8177 - val_loss: 0.5904 - val_accuracy: 0.7944\nEpoch 11/20\n782/782 [==============================] - 13s 17ms/step - loss: 0.4922 - accuracy: 0.8256 - val_loss: 0.6041 - val_accuracy: 0.7975\nEpoch 12/20\n782/782 [==============================] - 14s 18ms/step - loss: 0.4614 - accuracy: 0.8381 - val_loss: 0.5889 - val_accuracy: 0.7981\nEpoch 13/20\n782/782 [==============================] - 14s 18ms/step - loss: 0.4358 - accuracy: 0.8457 - val_loss: 0.5590 - val_accuracy: 0.8120\nEpoch 14/20\n782/782 [==============================] - 13s 17ms/step - loss: 0.4186 - accuracy: 0.8508 - val_loss: 0.5555 - val_accuracy: 0.8092\nEpoch 15/20\n782/782 [==============================] - 13s 17ms/step - loss: 0.4019 - accuracy: 0.8582 - val_loss: 0.5739 - val_accuracy: 0.8108\nEpoch 16/20\n782/782 [==============================] - 14s 17ms/step - loss: 0.3804 - accuracy: 0.8658 - val_loss: 0.5577 - val_accuracy: 0.8136\nEpoch 17/20\n782/782 [==============================] - 13s 17ms/step - loss: 0.3687 - accuracy: 0.8672 - val_loss: 0.5544 - val_accuracy: 0.8170\nEpoch 18/20\n782/782 [==============================] - 13s 17ms/step - loss: 0.3541 - accuracy: 0.8744 - val_loss: 0.5435 - val_accuracy: 0.8199\nEpoch 19/20\n782/782 [==============================] - 13s 17ms/step - loss: 0.3438 - accuracy: 0.8758 - val_loss: 0.5533 - val_accuracy: 0.8167\nEpoch 20/20\n782/782 [==============================] - 13s 17ms/step - loss: 0.3292 - accuracy: 0.8845 - val_loss: 0.5491 - val_accuracy: 0.8199\n```", "```py\n%matplotlib inline\nplt.close('all')\nplt.style.use(\"ggplot\")\nplt.figure(figsize=(8, 6))\nplt.plot(np.arange(0, 20), h.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, 20), h.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, 20), h.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, 20), h.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy\")\nplt.xlabel(\"No of Epochs\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend()\nplt.show()\n```"]