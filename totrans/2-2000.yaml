- en: The Case Against AI Regulation Makes No Sense
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-case-against-ai-regulation-makes-no-sense-a6b5a9ca2b28](https://towardsdatascience.com/the-case-against-ai-regulation-makes-no-sense-a6b5a9ca2b28)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Opinion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Europe is on the right path — the rest of the world should follow it
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://adrien-book.medium.com/?source=post_page-----a6b5a9ca2b28--------------------------------)[![Adrien
    Book](../Images/e0e2e07bbee3f237e6ae60fa4366f2ae.png)](https://adrien-book.medium.com/?source=post_page-----a6b5a9ca2b28--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a6b5a9ca2b28--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a6b5a9ca2b28--------------------------------)
    [Adrien Book](https://adrien-book.medium.com/?source=post_page-----a6b5a9ca2b28--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a6b5a9ca2b28--------------------------------)
    ·9 min read·Aug 12, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/03b49b5d82a2f8c301a4737e3690c93e.png)'
  prefs: []
  type: TYPE_IMG
- en: Created by author via MidJourney
  prefs: []
  type: TYPE_NORMAL
- en: Ever since OpenAI released ChatGPT into the wild in late 2022, the world has
    been abuzz with talks of Generative Artificial Intelligence and [the future it
    could create](https://www.thepourquoipas.com/post/top-9-ways-chatgpt-will-accelerate-society-s-collapse).
    Capitalism’s fanboys see the technology as [a net positive](https://a16z.com/2023/06/06/ai-will-save-the-world/);
    the logical continuation of the digital world, which has contributed to the creation
    of untold wealth… [for a select few](https://www.salon.com/2013/05/12/jaron_lanier_the_internet_destroyed_the_middle_class/).
    Skeptics, meanwhile, recall the best of the 80s’ Sci-Fi, and [fear](https://www.thepourquoipas.com/post/why-are-men-so-scared-of-ai)
    we may be well on our way to create our own [HAL](https://en.wikipedia.org/wiki/HAL_9000)
    / [SHODAN](https://en.wikipedia.org/wiki/SHODAN) / [Ultron](https://en.wikipedia.org/wiki/Ultron)
    / [SkyNet](https://en.wikipedia.org/wiki/Skynet_(Terminator)) / [GLaDOS](https://en.wikipedia.org/wiki/GLaDOS).
  prefs: []
  type: TYPE_NORMAL
- en: These are the loud minorities. Most people presented with the possibilities
    offered by Generative Artificial Intelligence understand that technology is merely
    a tool, without a mind of its own. The onus is on users to “*do good*” with it.
    And if that is not possible because “*good*” is inherently subjective… then *democratic*
    governments need to step in and regulate.
  prefs: []
  type: TYPE_NORMAL
- en: How (and if) this is to be done is [still hotly debated](https://www.theverge.com/2023/6/30/23779611/eu-ai-act-open-letter-artificial-intelligence-regulation-renault-siemens).
    The European Union was first out of the gate with the *proposed* [AI Act](https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence).
    It is an imperfect first draft, but has the benefit of being a real attempt at
    managing a highly disruptive technology rather than letting tech billionaires
    call the shots. Below is a summary of the proposed law, and the pros and cons
    of such regulations.
  prefs: []
  type: TYPE_NORMAL
- en: What is in the EU’s AI Act
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The [AI Act](https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence)
    puts risk at the core of the discussion : “*The new rules establish obligations
    for providers and users depending on the level of risk from artificial intelligence.
    While many AI systems pose minimal risk, they need to be assessed.*”'
  prefs: []
  type: TYPE_NORMAL
- en: AI posing “*unacceptable*” levels of risk (behavioural manipulation, real-time
    and remote biometrics, social scoring…) will be **banned**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High-risk AI systems (relating to law enforcement, education, immigration…)
    “*will be assessed before being put on the market and also throughout their lifecycle*”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limited-risk AI systems will need to “*comply with minimal transparency requirements
    that would allow users to make informed decisions.*”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Generative AI gets a special mention within the proposed regulation. Companies
    using the technology will have to:'
  prefs: []
  type: TYPE_NORMAL
- en: Disclose AI-generated content
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Design safeguards to prevent the generation of illegal content
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Publish summaries of copyrighted data used for training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If that seems satisfyingly pragmatic while remaining overly broad, trust your
    instincts. Companies failing to comply could face fines of up to 6% of their annual
    turnover and be kept from operating in the EU. The region is estimated to represent
    between 20% and 25% of a global AI market that is projected to be [worth more
    than $1.3 trillion](https://www.bloomberg.com/news/articles/2023-06-01/chatgpt-to-fuel-1-3-trillion-ai-market-by-2032-bi-report-says)
    within 10 years… which is why tech companies may [say they’ll leave… but never
    will](https://www.bbc.com/news/technology-65708114). The law is expected to pass
    around 2024.
  prefs: []
  type: TYPE_NORMAL
- en: Why Generative Artificial Intelligence should not be regulated
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There has been plenty written about the fact that [tech billionaires say](https://www.theverge.com/2023/5/30/23742005/ai-risk-warning-22-word-statement-google-deepmind-openai)
    [they want AI to be regulated](https://time.com/6280372/sam-altman-chatgpt-regulate-ai/).
    Let’s make one thing clear: that is a front. Mere PR. [They do not want regulation,
    and if it comes, they want it on their own terms](https://www.bloomberg.com/news/articles/2023-06-27/big-tech-companies-fight-ai-regulation-in-europe-ask-us-lawmakers-for-oversight?).
    Below are some of the best arguments presented by them and their minions over
    the past few months.'
  prefs: []
  type: TYPE_NORMAL
- en: Stifling Innovation and Progress
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The case could be made that [regulations will slow down AI advancements and
    breakthroughs](https://www.vox.com/the-highlight/23621198/artificial-intelligence-chatgpt-openai-existential-risk-china-ai-safety-technology).
    That not allowing companies to test and learn will [make them less competitive
    internationally](https://www.theverge.com/2023/6/30/23779611/eu-ai-act-open-letter-artificial-intelligence-regulation-renault-siemens).
    However, we are yet to see definitive proof that this is true. Even if it were,
    the questions would remain: *is unbridled innovation right for society as a whole*?
    Profits are not everything. Maybe the EU will fall behind China and the US when
    it comes to creating new unicorns and billionaires. Is that so bad, as long as
    [we still have social nets, free healthcare, parental leaves and 6 weeks of holidays
    a year](https://snippetsofparis.com/benefits-france/)? If having this, thanks
    to regulations, means a multi-millionaire cannot become a billionaire, so be it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The non-international competitiveness argument is a lot more relevant for the
    discussion at hand: regulation can create barriers to entry (high costs, standards,
    or requirements on developers or users) for new companies, strengthening the hand
    of incumbents. The EU has already seen this when [implementing the GDPR](https://www.computerweekly.com/opinion/GDPR-like-a-lot-of-regulation-will-mostly-benefit-the-big-incumbents).
    Regulations will need to carve out a space for very small companies to experiment,
    [something that is already being discussed at EU-level](https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai).
    If they’re so small, how much harm can SMEs do anyway, given the exponential nature
    of AI’s power?'
  prefs: []
  type: TYPE_NORMAL
- en: Complex and Challenging Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Regulations relating to world-changing technologies can often be too vague or
    broad to be applicable. This can make them difficult to implement and enforce
    across different jurisdictions. This is particularly true when accounting for
    the lack of clear standards in the field. After all, what are risks and ethics
    if not [culturally relative](https://www.simplypsychology.org/cultural-relativism.html)?
  prefs: []
  type: TYPE_NORMAL
- en: This makes the need to balance international standards and sovereignty a particularly
    touchy subject. AI operates across borders, and its regulation requires international
    cooperation and coordination. This can be complex, given varying legal frameworks
    and cultural differences. This is what *they* will say.
  prefs: []
  type: TYPE_NORMAL
- en: There are however few voices calling for one worldwide regulation. AI is (in
    so many ways) not the same as the atomic bomb, whatever the doomsayers [calling
    for “New START” approach may claim](https://www.vox.com/future-perfect/2023/7/3/23779794/artificial-intelligence-regulation-ai-risk-congress-sam-altman-chatgpt-openai).
    The EU will have its own laws, and [so will other world powers](https://www.technologyreview.com/2023/05/31/1073743/china-generative-ai-quick-regulation/?).
    All we can ask for is a common understanding around the risks posed by the technology,
    and limited cooperation to cover blind spots within and between regional laws.
  prefs: []
  type: TYPE_NORMAL
- en: Potential for Overregulation and Unintended Consequences
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Furthermore, we know that [regulation often fails to adapt to the fast-paced
    nature of technology](https://www.brookings.edu/articles/the-three-challenges-of-ai-regulation/).
    AI is a rapidly evolving field, with new techniques and applications emerging
    regularly. New challenges, risks and opportunities continuously emerge, and we
    need to remain agile / flexible enough to deal with them. Keeping up with the
    advancements and regulating cutting-edge technologies can be challenging for governing
    bodies… but that has never stopped anyone, and the world still stands.
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, governments must make sure that new industries (not considered AI)
    are not caught up in the scope of existing regulation, with unexpected consequences.
    We wouldn’t want, for example, ecology to suffer because a carbon capture system
    uses a technology akin to generative AI to recommend regions to target for cleanup.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to avoid excessive bureaucracy and red tape… but that is not
    a reason to do nothing. The EU’s proposed risk-based governance is a good answer
    to these challenges. Risks are defined well-enough to apply to all people across
    the territory, while allowing for changes should the nature of artificial intelligence
    evolve.
  prefs: []
  type: TYPE_NORMAL
- en: There are, in truth, few real risks in regulating AI… and plenty of benefits.
  prefs: []
  type: TYPE_NORMAL
- en: Why Generative Artificial intelligence needs to be regulated
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many reasons to regulate Gen. AI, specifically when looking through
    the prism of risks to under-privileged or defenceless populations. It can be easy
    not to take [automated and wide-scale discrimination](https://rm.coe.int/discrimination-artificial-intelligence-and-algorithmic-decision-making/1680925d73)
    seriously… when you’ve never been discriminated against. Looking at you, tech
    bros.
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring Ethical Use of Artificial Intelligence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Firstly (and obviously), regulation is needed to apply and adapt existing digital
    laws to AI technology. This means protecting the [privacy of users](https://www.brookings.edu/articles/how-privacy-legislation-can-help-address-ai/)
    ([and their data](https://www.forbes.com/sites/forbestechcouncil/2021/08/04/three-years-on-from-gdpr-and-ccpa-how-has-data-protection-modernized/)).
    AI companies should invest in strong cyber-security capabilities when dealing
    with data-heavy algorithms… and forego some revenues as user data should not be
    sold to third parties. This is a concept American companies [seem to inherently](https://www.nytimes.com/wirecutter/blog/state-of-privacy-laws-in-us/)
    [and wilfully misunderstand](https://penntoday.upenn.edu/news/asc-americans-dont-understand-what-companies-can-do-their-personal-data)
    without regulation.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned in the AI Act, it is also crucial that tech companies remove the
    potential for bias and discrimination from algorithms dealing with sensitive topics.
    That entails A) ensuring none is purposefully injected and B) ensuring naturally
    occurring biases are removed to avoid reproduction at scale. This is [non-negotiable](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52021PC0206),
    and if [regulatory crash testing](https://www.bloomberg.com/news/articles/2023-06-27/europe-to-open-artificial-intelligence-crash-test-centers?)
    is needed, so be it.
  prefs: []
  type: TYPE_NORMAL
- en: More philosophically, regulation can help foster trust, transparency, and accountability
    among users, developers, and stakeholders of generative AI. By having all actors
    disclose the source, purpose, and limitations of AIs’ outputs, we will be able
    to make better choices… and trust the choices of others. The fabric of society
    needs this.
  prefs: []
  type: TYPE_NORMAL
- en: Safeguarding Human Rights and Safety
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Beyond the “basics”, [regulation needs to protect populations at large](https://hbr.org/2021/09/ai-regulation-is-coming)
    from AI-related safety risks, of which there are many.
  prefs: []
  type: TYPE_NORMAL
- en: Most will be human-related risks. Malicious actors can use Generative AI to
    [spread misinformation](https://www.rand.org/pubs/perspectives/PEA1043-1.html)
    or [create deepfakes](https://thumos.uk/generative-ai-and-deepfakes/). [This is
    very easy to do](https://www.thepourquoipas.com/post/30-fake-stories-created-with-chatgpt-what-i-learned),
    and companies seem unable to put a stop to it themselves — mostly because they
    are unwilling (not unable) to tag AI-generated content. Our [next elections](https://news.bloomberglaw.com/artificial-intelligence/regulate-deepfake-ads-election-agency-told-again-after-deadlock)
    may depend on regulations being put in place… while [(mostly young) women the
    world over may ask why we didn’t do it sooner](https://www.bbc.com/news/entertainment-arts-65854112).
  prefs: []
  type: TYPE_NORMAL
- en: 'We also need to avoid letting humans do physical harm to other humans using
    generative Artificial Intelligence: it has been reported that AI can be used to
    describe the best way to [build a dirty bomb](https://outrider.org/nuclear-weapons/articles/could-chatbot-teach-you-how-build-dirty-bomb).
    Here again, if a company cannot prevent it to the best of its abilities, I see
    no reason for us to continue to allow it exist in its current form.'
  prefs: []
  type: TYPE_NORMAL
- en: 'All this is without even going into the topic of [AI-driven warfare](https://www.brookings.edu/articles/applying-arms-control-frameworks-to-autonomous-weapons/)
    and [autonomous weapons](https://www.scientificamerican.com/article/ai-influenced-weapons-need-better-regulation/),
    the creation of which [must be avoided at all cost](https://www.weforum.org/agenda/2021/06/the-accelerating-development-of-weapons-powered-by-artificial-risk-is-a-risk-to-humanity/).
    This scenario is however so catastrophic that we often use it to hide the many
    other problems with AI. Why concentrate on data privacy when Terminator is right
    around the corner, right? Don’t let the doomers distract you from the very boring,
    but very real fact: without strong AI regulation tackling the above, society may
    die a death of a thousand cuts rather than one singular weaponized blow.'
  prefs: []
  type: TYPE_NORMAL
- en: This is why we must ensure that companies agree to create systems that align
    with human values and morals. Easier said than done, but having a vision is a
    good start.
  prefs: []
  type: TYPE_NORMAL
- en: Mitigating Social and Economic Impact
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are important topics that the AI Act (or any other proposed regulation)
    does not completely cover. They will need to be further assessed over the coming
    years, but their very nature makes regulating without over-regulating difficult,
    though not any less needed.
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, rules are needed to [fairly compensate people whose data is used](https://www.theverge.com/2023/7/9/23788741/sarah-silverman-openai-meta-chatgpt-llama-copyright-infringement-chatbots-artificial-intelligence-ai?)
    to [train algorithms that will bring so much wealth to so few](https://www.wired.com/story/stack-overflow-will-charge-ai-giants-for-training-data/).
    Without this, we are only repeating the mistakes of the past, and making a deep
    economical chasm deeper. This is going to be difficult; [there are few legal precedents
    to inform what is happening in the space today](https://www.theverge.com/23444685/generative-ai-copyright-infringement-legal-fair-use-training-data).
  prefs: []
  type: TYPE_NORMAL
- en: It will also be vital to address gen. AI-led [job displacement and unemployment](https://www.weforum.org/agenda/2023/05/jobs-lost-created-ai-gpt/).
    Most roles are expected to be impacted by artificial intelligence, and with greater
    automation often comes greater unemployment. According to [a report by BanklessTimes.com](https://www.banklesstimes.com/news/2022/11/29/ai-could-displace-800-million-jobs-by-2030/),
    AI could displace 800 million jobs (30% of the global workforce) by 2030.
  prefs: []
  type: TYPE_NORMAL
- en: It may be at the macro-economic level for some (“[*AI could also shift job roles
    and create new ones by automating some aspects of work while allowing humans to
    focus on more creative or value-adding tasks*](https://www.linkedin.com/pulse/role-artificial-intelligence-job-displacement-anuja-jain)”,
    they’ll say), but it is decades of despair for others. [We need a regulatory plan
    for those replaced and automated by AI](https://www.theguardian.com/commentisfree/2023/may/22/ai-jobs-policies)
    (training, UBI…).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, it will be important to continuously safeguard the world’s economies
    against AI-driven economic monopolies. [Network effects mean that catching up
    to an internet giant is almost impossible today](https://techcrunch.com/2023/06/02/competition-concerns-in-the-age-of-ai/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAFKYT7V-fGnU5lVmHu4IgpEp_byMaj8vl9_yL_Qab6hLlQMLb14KPCFGPN5s51U1caeI1vINV4YrjjzkHGy0Qwxj5WPhMH2xZbLFjsgM46OgwP4BsV0pHs65itH7f2DcNy6JJ1sF9viHH8XLcwrzPJPQum0xxVwH7pgzcI1fcTJX),
    for lack of data or compute. Anti-trust laws have been left rather untouched for
    decades, and it can no longer go on. Regulations will not make us less competitive
    in this case. *It may make the economy more so*.
  prefs: []
  type: TYPE_NORMAL
- en: The regulatory game has just started. Moving forward, governments will need
    to collaborate and cooperate to establish broad frameworks while promoting and
    encouraging knowledge sharing and interdisciplinary collaboration.
  prefs: []
  type: TYPE_NORMAL
- en: These frameworks will need to be adaptive and collaborative, lest they become
    unable to keep up with AI’s latest development. Regular reviews and updates will
    be key, as will agile experimentation in sandbox environments.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, public engagement and inclusive decision-making will make or break
    any rules brought forwards. We need to Involving diverse stakeholders in regulatory
    discussions, while engaging the public in AI policy decisions. This is for us
    / them, and communicating that fact well will help governments counter-act tech
    companies' lobbying.
  prefs: []
  type: TYPE_NORMAL
- en: 'The regulatory road ahead is long: today, [no foundational LLM currently complies
    with EU AI Act](https://the-decoder.com/no-foundational-llm-currently-complies-with-eu-ai-act/).
    Meanwhile, [China’s regulation concentrates on content control](https://www.ft.com/content/1938b7b6-baf9-46bb-9eb7-70e9d32f4af0?)
    rather than risks, further tightening the Party’s grip on free expression.'
  prefs: []
  type: TYPE_NORMAL
- en: The regulatory game has just started. But… we’ve started, and that makes all
    the difference.
  prefs: []
  type: TYPE_NORMAL
- en: One more thing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Please support my writing by leaving a comment. I love reading them! Except
    the mean ones. They make me sad. Also, avoid missing any of my writing by signing
    up for my newsletter* [*here on Medium*](https://adrien-book.medium.com/subscribe)*,
    or* [*on my blog*](https://www.thepourquoipas.com/)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[*This article*](https://www.wearedevelopers.com/magazine/eu-ai-regulation-artificial-intelligence-regulations)
    *was originally written for* [*wearedevelopers.com*](https://www.wearedevelopers.com/)*,
    Europe’s developer-focused job platform.*'
  prefs: []
  type: TYPE_NORMAL
