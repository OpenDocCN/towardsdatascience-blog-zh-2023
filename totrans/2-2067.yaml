- en: The Three Essential Methods to Evaluate a New Language Model
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估新语言模型的三种基本方法
- en: 原文：[https://towardsdatascience.com/the-three-essential-methods-to-evaluate-a-new-language-model-aa5c526bacfd](https://towardsdatascience.com/the-three-essential-methods-to-evaluate-a-new-language-model-aa5c526bacfd)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-three-essential-methods-to-evaluate-a-new-language-model-aa5c526bacfd](https://towardsdatascience.com/the-three-essential-methods-to-evaluate-a-new-language-model-aa5c526bacfd)
- en: How to check whether the newest, hottest Large Language Model (LLM) fits your
    needs
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何检查最新、最热门的大型语言模型（LLM）是否符合你的需求
- en: '[](https://heiko-hotz.medium.com/?source=post_page-----aa5c526bacfd--------------------------------)[![Heiko
    Hotz](../Images/d08394d46d41d5cd9e76557a463be95e.png)](https://heiko-hotz.medium.com/?source=post_page-----aa5c526bacfd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----aa5c526bacfd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----aa5c526bacfd--------------------------------)
    [Heiko Hotz](https://heiko-hotz.medium.com/?source=post_page-----aa5c526bacfd--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://heiko-hotz.medium.com/?source=post_page-----aa5c526bacfd--------------------------------)[![Heiko
    Hotz](../Images/d08394d46d41d5cd9e76557a463be95e.png)](https://heiko-hotz.medium.com/?source=post_page-----aa5c526bacfd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----aa5c526bacfd--------------------------------)[![数据科学之道](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----aa5c526bacfd--------------------------------)
    [Heiko Hotz](https://heiko-hotz.medium.com/?source=post_page-----aa5c526bacfd--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----aa5c526bacfd--------------------------------)
    ·6 min read·Jul 3, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[数据科学之道](https://towardsdatascience.com/?source=post_page-----aa5c526bacfd--------------------------------)
    ·6分钟阅读·2023年7月3日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/d44df1d02e0e695eedca24b1c6e2d15b.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d44df1d02e0e695eedca24b1c6e2d15b.png)'
- en: Image by author (using Stable Diffusion)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源（使用Stable Diffusion）
- en: What is this about?
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 这是什么？
- en: 'New LLMs are released every week, and if you’re like me, you might ask yourself:
    Does this one finally fit all the use cases I want to utilise an LLM for? In this
    tutorial, I will share the techniques that I use to evaluate new LLMs. I’ll introduce
    three techniques I use regularly — none of them are new (in fact, I will refer
    to blog posts that I have written previously), but by bringing them all together,
    I save a significant amount of time whenever a new LLM is released. I will demonstrate
    examples of testing on the new [OpenChat](https://huggingface.co/openchat/openchat_8192)
    model.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 每周都会发布新的LLM，如果你像我一样，可能会问自己：这个模型是否终于适合我想要利用LLM的所有用例？在这个教程中，我将分享我用来评估新LLM的技术。我将介绍我定期使用的三种技术——它们没有新的（实际上，我会提到我之前写的博客文章），但通过将它们结合在一起，每当有新的LLM发布时，我可以节省大量时间。我将展示在新的[OpenChat](https://huggingface.co/openchat/openchat_8192)模型上进行测试的示例。
- en: Why is this important?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么这很重要？
- en: When it comes to new LLMs, it’s important to understand their capabilities and
    limitations. Unfortunately, figuring out how to deploy the model and then systematically
    testing it can be a bit of a drag. This process is often manual and can consume
    a lot of time. However, with a standardised approach, we can iterate much faster
    and quickly determine whether a model is worth investing more time in, or if we
    should discard it. So, let’s get started.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 对于新的LLM，了解其能力和限制是很重要的。不幸的是，弄清楚如何部署模型并系统地测试它可能会有些麻烦。这个过程通常是手动的，并且可能消耗大量时间。然而，通过标准化的方法，我们可以更快地迭代，并迅速确定一个模型是否值得投入更多时间，还是应该放弃它。所以，让我们开始吧。
- en: '**Getting Started**'
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**开始使用**'
- en: There are many ways to utilise an LLM, but when we distil the most common uses,
    they often pertain to open-ended tasks (e.g. generating text for a marketing ad),
    chatbot applications, and Retrieval Augmented Generation (RAG). Correspondingly,
    I employ relevant methods to test these capabilities in an LLM.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 利用LLM的方式有很多，但当我们提炼出最常见的用途时，它们通常涉及开放性任务（例如，为营销广告生成文本）、聊天机器人应用和检索增强生成（RAG）。相应地，我会使用相关方法来测试这些能力。
- en: 0\. Deploying the model
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 0\. 部署模型
- en: 'Before we get started with the evaluation, we first need to deploy the model.
    I have boilerplate code ready for this, where we can just swap out the model ID
    and the instance to which to deploy (I’m using Amazon SageMaker for model hosting
    in this example) and we’re good to go:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始评估之前，我们首先需要部署模型。我已经准备好了一些模板代码，我们只需更换模型ID和要部署的实例（在这个示例中，我使用的是Amazon SageMaker进行模型托管），就可以开始了：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: It’s worth noting that we can utilise the new [Hugging Face LLM Inference Container
    for SageMaker](https://huggingface.co/blog/sagemaker-huggingface-llm), as the
    new OpenChat model is based on the LLAMA architecture, which is supported in this
    container.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，我们可以利用新的[Hugging Face LLM Inference Container for SageMaker](https://huggingface.co/blog/sagemaker-huggingface-llm)，因为新的OpenChat模型基于LLAMA架构，该架构在这个容器中受支持。
- en: 1\. Playground
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 游乐场
- en: Using the notebook to test a few prompts can be burdensome, and it may also
    discourage non-technical users from experimenting with the model. A much more
    effective way to familiarise yourself with the model, and to encourage others
    to do the same, involves the construction of a playground. I have previously detailed
    how to easily create such a playground in this [blog post](/create-your-own-large-language-model-playground-in-sagemaker-studio-1be5846c5089).
    With the code from that blog post, we can get a playground up and running quickly.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 使用笔记本测试一些提示可能很繁琐，也可能会让非技术用户不愿尝试模型。更有效的方式是构建一个游乐场。我之前在这篇[博客文章](/create-your-own-large-language-model-playground-in-sagemaker-studio-1be5846c5089)中详细说明了如何轻松创建这样一个游乐场。利用那篇博客文章中的代码，我们可以快速搭建一个游乐场。
- en: 'Once the playground is established, we can introduce some prompts to evaluate
    the model’s responses. I prefer using open-ended prompts, where I pose a question
    that requires some degree of common sense to answer:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦建立了游乐场，我们可以引入一些提示来评估模型的回应。我更喜欢使用开放式提示，即提出一个需要一定常识来回答的问题：
- en: '***How can I improve my time management skills?***'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '***我如何提高我的时间管理技能？***'
- en: '![](../Images/4c59792642c67fb692d5da39dac0ed64.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4c59792642c67fb692d5da39dac0ed64.png)'
- en: Image by author
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: '***What if the Suez Canal had never been constructed?***'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '***如果苏伊士运河从未被建造会怎样？***'
- en: '![](../Images/257c34f41bfc5060f0add201b72d2ee3.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/257c34f41bfc5060f0add201b72d2ee3.png)'
- en: Image by author
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Both responses appear promising, suggesting that it could be worthwhile to invest
    additional time and resources in testing the OpenChat model.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 两种回应都很有前景，这表明投资额外的时间和资源来测试OpenChat模型可能是值得的。
- en: 2.Chatbot
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2. 聊天机器人
- en: The second thing we want to explore is a model’s chatbot capabilities. Unlike
    the playground, where the model is consistently stateless, we want to understand
    its ability to “remember” context within a conversation. In this [blog post](https://medium.com/mlearning-ai/unlocking-the-future-of-chatbots-with-falcon-hugging-face-and-amazon-sagemaker-cf6bd8aeba54),
    I described how to set up a chatbot using the Falcon model. It’s a simple plug-and-play
    operation, and by changing the SageMaker endpoint, we can direct it towards the
    new OpenChat model.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要探索的第二件事是模型的聊天机器人能力。与游乐场不同，在游乐场中模型始终是无状态的，我们希望了解其在对话中“记住”上下文的能力。在这篇[博客文章](https://medium.com/mlearning-ai/unlocking-the-future-of-chatbots-with-falcon-hugging-face-and-amazon-sagemaker-cf6bd8aeba54)中，我描述了如何使用Falcon模型设置聊天机器人。这是一个简单的即插即用操作，通过更改SageMaker端点，我们可以将其指向新的OpenChat模型。
- en: 'Let’s see how it fares:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它的表现：
- en: '![](../Images/d384127f6a6d619277833486c512d7bf.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d384127f6a6d619277833486c512d7bf.png)'
- en: Image by author
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: The performance as a chatbot is quite impressive. There was an instance, however,
    where Openchat attempted to abruptly terminate the conversation, cutting off in
    mid-sentence. This occurrence is not rare, in fact. We don’t usually observe this
    with other chatbots because they employ specific stop words to compel the AI to
    cease text generation. The occurrence of this issue in my app is probably due
    to the implementation of stop words within my application.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 作为聊天机器人的表现相当令人印象深刻。然而，有一次Openchat试图突然结束对话，半句话被切断了。实际上，这种情况并不罕见。我们通常不会在其他聊天机器人中观察到这种情况，因为它们使用特定的停止词来迫使AI停止文本生成。这种问题在我的应用程序中发生的原因可能是由于我的应用程序中实施了停止词。
- en: Beyond that, OpenChat has the capability to maintain context throughout a conversation,
    as well as to extract crucial information from a document. Impressive. 😊
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，OpenChat具有在对话中保持上下文的能力，并且能够从文档中提取关键信息。令人印象深刻。😊
- en: 3\. Retrieval Augmented Generation (RAG)
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 检索增强生成（RAG）
- en: 'The last task we want to test involves using LangChain for some RAG tasks.
    I’ve found that RAG tasks can be quite challenging for open source models, often
    requiring me to write my own prompts and custom response parsers to achieve functionality.
    However, what I’d like to see is a model that operates optimally “out of the box”
    for standard RAG tasks. This [blog post](https://medium.com/mlearning-ai/supercharging-large-language-models-with-langchain-1cac3c103b52)
    provides a few examples of such tasks. Let’s examine how well it performs. The
    question we’ll be posing is:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想测试的最后一个任务涉及使用LangChain进行一些RAG任务。我发现RAG任务对于开源模型来说可能相当具有挑战性，通常需要我编写自己的提示和自定义响应解析器来实现功能。然而，我希望看到的是一个在标准RAG任务中“开箱即用”的模型。这个[博客文章](https://medium.com/mlearning-ai/supercharging-large-language-models-with-langchain-1cac3c103b52)提供了一些这样的任务示例。让我们看看它的表现如何。我们要提出的问题是：
- en: '***Who is the prime minister of the UK? Where was he or she born? How far is
    their birth place from London?***'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '***谁是英国的首相？他或她出生在哪里？他们的出生地距离伦敦有多远？***'
- en: '![](../Images/3aaf72deeacd3075e4d82c4bfdd1f528.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3aaf72deeacd3075e4d82c4bfdd1f528.png)'
- en: Image by author
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: This is, without a doubt, the best performance I’ve seen from an open-source
    model using the standard prompt from LangChain. This is probably unsurprising,
    considering OpenChat has been fine-tuned on ChatGPT conversations, and LangChain
    is tailored towards OpenAI models, particularly ChatGPT. Nonetheless, the model
    was capable of retrieving all three facts accurately using the tools at its disposal.
    The only shortcoming was that, in the end, the model failed to recognise that
    it possessed all the necessary information and could answer the user’s question.
    Ideally, it should have stated, “I now have the final answer,” and provided the
    user with the facts it had gathered.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 毋庸置疑，这是我见过的使用LangChain标准提示的开源模型中表现最好的。这可能并不令人惊讶，因为OpenChat已经在ChatGPT对话上进行了微调，而LangChain则针对OpenAI模型，特别是ChatGPT。然而，该模型能够准确地使用其可用的工具检索所有三个事实。唯一的缺点是，最后模型未能认识到它已经掌握了所有必要的信息并能够回答用户的问题。理想情况下，它应该说：“我现在有了最终答案，”并向用户提供其收集到的事实。
- en: '![](../Images/dffb5124caaedb68a80ae033b5ab5478.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dffb5124caaedb68a80ae033b5ab5478.png)'
- en: Image by author
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Conclusion
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this blog post, I’ve introduced you to three standard evaluation techniques
    that I use all the time to evaluate LLMs. We’ve observed that the new OpenChat
    model performs exceptionally well on all these tasks. Surprisingly, it appears
    very promising as the underlying LLM for a RAG application, probably just requiring
    customised prompting to discern when it has arrived at the final answer.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我向你介绍了我经常使用的三种标准评估技术来评估LLMs。我们观察到，新版的OpenChat模型在所有这些任务中表现都非常出色。令人惊讶的是，它作为RAG应用的底层LLM非常有前景，可能只需定制化提示来确定何时达到了最终答案。
- en: It’s noteworthy that this isn’t a comprehensive evaluation, nor is it intended
    to be. Instead, it offers an indication of whether a particular model is worth
    investing more time in and conducting further, more intensive testing. It seems
    that OpenChat is definitely worth spending time on 🤗
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，这不是一个全面的评估，也不打算成为全面评估。相反，它提供了一个关于特定模型是否值得投入更多时间进行进一步、更深入测试的指示。看来OpenChat绝对值得花时间研究
    🤗
- en: Feel free to use all the tools, expand and customise them, and start evaluating
    the LLMs that pique your interest within minutes.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 随意使用所有工具，扩展和定制它们，并在几分钟内开始评估你感兴趣的LLMs。
- en: Heiko Hotz
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 海科·霍茨
- en: 👋 Follow me on [Medium](https://heiko-hotz.medium.com/) and [LinkedIn](https://www.linkedin.com/in/heikohotz/)
    to read more about Generative AI, Machine Learning, and Natural Language Processing.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 👋 在[Medium](https://heiko-hotz.medium.com/)和[LinkedIn](https://www.linkedin.com/in/heikohotz/)上关注我，以了解更多关于生成式人工智能、机器学习和自然语言处理的内容。
- en: 👥 If you’re based in London join one of our [NLP London Meetups](https://www.meetup.com/nlp_london/).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 👥 如果你在伦敦，可以加入我们的[NLP London Meetups](https://www.meetup.com/nlp_london/)。
- en: '![](../Images/e787e5a8febdad2128756ce2a7e75fd4.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e787e5a8febdad2128756ce2a7e75fd4.png)'
- en: Image by author
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
