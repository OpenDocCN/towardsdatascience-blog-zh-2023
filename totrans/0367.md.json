["```py\nimport numpy as np\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom sklearn import datasets\n\nimport matplotlib.pyplot as plt\n\nclass Benchmark:\n  \"\"\"\n  This class allows to compare and evaluate the \n  performance of machine learning models using cross-validation\n\n  Parameters\n  ----------\n  models : dict\n      Dictionary of models, \n      where the key is the name of the model and\n      the value is the model object.\n  \"\"\"\n\n  def __init__(self, models):\n      self.models = models\n\n  def test_models(self, X=None, y=None, cv=5):\n    \"\"\"\n    Test the models using the provided data and cross-validation.\n\n    Parameters\n    ----------\n    X : array-like or DataFrame, shape (n_samples, n_features)\n        Features for the test data.\n    y : array-like or Series, shape (n_samples,)\n        Target for the test data.\n    cv : int, cross-validation generator or an iterable, optional\n        Number of folds for the cross-validation.\n\n    Returns\n    -------\n    best_model : str\n        Name of the model with the highest score.\n    \"\"\"\n    if X is None or y is None:\n        X, y = datasets.make_classification(\n            n_samples=100, \n            n_features=10, \n            n_classes=2, \n            n_clusters_per_class=1, \n            random_state=0\n        )\n    self.results = {}\n    for name, model in self.models.items():\n        scores = model_selection.cross_val_score(model, X, y, cv=cv)\n        self.results[name] = scores.mean()\n    self.best_model = max(self.results, key=self.results.get)\n    return f\"The best model is: {self.best_model} with a score of {self.results[self.best_model]:.3f}\"\n```", "```py\ndef plot_cv_results(self):\n  \"\"\"\n  Create a bar chart to visualize the cross-validation results.\n\n  Returns\n  -------\n  None\n  \"\"\"\n  plt.figure(figsize=(15,5))\n  x = np.arange(len(self.results))\n  plt.bar(x, list(self.results.values()), align='center', color ='g')\n  plt.xticks(x, list(self.results.keys()))\n  plt.ylim([0, 1])\n  plt.ylabel('Cross-Validation Score')\n  plt.xlabel('Models')\n  plt.title('Model Comparison')\n  for index, value in enumerate(self.results.values()):\n      plt.text(index, value, str(round(value,2)))\n  plt.show()\n```", "```py\nfrom sklearn import linear_model, ensemble\n\nmodels = {\n    'logistic': linear_model.LogisticRegression(),\n    'randomforest': ensemble.RandomForestClassifier(),\n    'extratrees': ensemble.ExtraTreesClassifier(),\n    'gbm': ensemble.GradientBoostingClassifier()\n}\n\nbenchmark = Benchmark(models)\nprint(benchmark.test_models())\nbenchmark.plot_cv_results()\n```", "```py\nclass Benchmark:\n    def __init__(self, models):\n        self.models = models\n\n    def test_models(self, X=None, y=None, cv=5):\n        if X is None or y is None:\n            X, y = datasets.make_classification(\n                n_samples=100, \n                n_features=10, \n                n_classes=2, \n                n_clusters_per_class=1, \n                random_state=0\n            )\n        self.results = {}\n        for name, model in self.models.items():\n            scores = model_selection.cross_val_score(model, X, y, cv=cv)\n            self.results[name] = scores.mean()\n        self.best_model = max(self.results, key=self.results.get)\n        return f\"The best model is: {self.best_model} with a score of {self.results[self.best_model]:.3f}\"\n\n    def plot_cv_results(self):\n        plt.figure(figsize=(15,5))\n        x = np.arange(len(self.results))\n        plt.bar(x, list(self.results.values()), align='center', color ='g')\n        plt.xticks(x, list(self.results.keys()))\n        plt.ylim([0, 1])\n        plt.ylabel('Cross-Validation Score')\n        plt.xlabel('Models')\n        plt.title('Model Comparison')\n        for index, value in enumerate(self.results.values()):\n            plt.text(index, value, str(round(value,2)))\n        plt.show()\n\nfrom sklearn import linear_model, ensemble\n\nmodels = {\n    'logistic': linear_model.LogisticRegression(),\n    'randomforest': ensemble.RandomForestClassifier(),\n    'extratrees': ensemble.ExtraTreesClassifier(),\n    'gbm': ensemble.GradientBoostingClassifier()\n}\n\nbenchmark = Benchmark(models)\nprint(benchmark.test_models())\nbenchmark.plot_cv_results()\n```"]