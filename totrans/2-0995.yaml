- en: 'Google Med-PaLM: The AI Clinician'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Google Med-PaLM：AI 临床医生
- en: 原文：[https://towardsdatascience.com/google-med-palm-the-ai-clinician-a4482143d60e](https://towardsdatascience.com/google-med-palm-the-ai-clinician-a4482143d60e)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/google-med-palm-the-ai-clinician-a4482143d60e](https://towardsdatascience.com/google-med-palm-the-ai-clinician-a4482143d60e)
- en: ARTIFICIAL INTELLIGENCE | MEDICINE | NLP |
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能 | 医学 | 自然语言处理 |
- en: Google's new model is trained to answer medical questions. How?
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 谷歌的新模型经过训练以回答医学问题。怎么做到的？
- en: '[](https://salvatore-raieli.medium.com/?source=post_page-----a4482143d60e--------------------------------)[![Salvatore
    Raieli](../Images/6bb4520e2df40d20283e7283141b5e06.png)](https://salvatore-raieli.medium.com/?source=post_page-----a4482143d60e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a4482143d60e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a4482143d60e--------------------------------)
    [Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page-----a4482143d60e--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://salvatore-raieli.medium.com/?source=post_page-----a4482143d60e--------------------------------)[![Salvatore
    Raieli](../Images/6bb4520e2df40d20283e7283141b5e06.png)](https://salvatore-raieli.medium.com/?source=post_page-----a4482143d60e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a4482143d60e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a4482143d60e--------------------------------)
    [Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page-----a4482143d60e--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a4482143d60e--------------------------------)
    ·14 min read·Mar 17, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a4482143d60e--------------------------------)
    ·14 min read·2023年3月17日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/343cb55205bd7b26fac1907a4976f5de.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/343cb55205bd7b26fac1907a4976f5de.png)'
- en: Image by the author using OpenAI DALL-E
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 作者使用 OpenAI DALL-E 制作的图片
- en: Medicine is also based on the interaction between patient and physician. moreover,
    although the patient undergoes different tests and imaging techniques there is
    always a written report. So why AI models for applications in medicine and healthcare
    have failed to fully utilize language?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 医学还基于患者和医生之间的互动。此外，尽管患者接受了不同的检查和影像技术，但总是会有书面报告。那么，为什么医疗和健康领域的 AI 模型未能充分利用语言呢？
- en: A foundation model for medicine?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 医学的基础模型？
- en: '![](../Images/9568bb410aa816f7d631aa907308b6bc.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9568bb410aa816f7d631aa907308b6bc.png)'
- en: photo by [Myriam Zilles](https://unsplash.com/it/@myriamzilles) on Unsplash
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Myriam Zilles](https://unsplash.com/it/@myriamzilles) 在 Unsplash 上拍摄
- en: The trend in recent years has been to try to constrain large [language models](https://en.wikipedia.org/wiki/Language_model)
    (LMs) and then [fine-tune](https://en.wikipedia.org/wiki/Fine-tuning_(machine_learning))
    them for the required applications. A similar approach can be attempted on large
    corpora of the medical text so that the model can learn a useful representation.
    A model that had a good understanding of medical subject matter could be useful
    for countless applications (triage of patients, retrieval of knowledge, summarization
    of key findings, diagnosis assistance, and so on).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来的趋势是尝试限制大型 [语言模型](https://en.wikipedia.org/wiki/Language_model) (LMs)，然后
    [微调](https://en.wikipedia.org/wiki/Fine-tuning_(machine_learning)) 以满足所需的应用。类似的方法可以应用于大量医学文本，使模型能够学习有用的表征。对医学主题有良好理解的模型可能对无数应用有帮助（例如，患者分诊、知识检索、关键发现的总结、诊断辅助等）。
- en: The problem is that the medical domain is a special domain. In contrast to other
    fields, there are different issues and even greater safety issues. As we have
    seen models like ChatGPT can also hallucinate, and be capable of the spread of
    misinformation.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于医学领域是一个特殊领域。与其他领域相比，这里有不同的问题，甚至更大的安全问题。正如我们所见，像 ChatGPT 这样的模型也可能产生幻觉，并且可能传播错误信息。
- en: '[](https://medium.com/data-driven-fiction/everything-but-everything-you-need-to-know-about-chatgpt-546af7153ee2?source=post_page-----a4482143d60e--------------------------------)
    [## Everything but everything you need to know about ChatGPT'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/data-driven-fiction/everything-but-everything-you-need-to-know-about-chatgpt-546af7153ee2?source=post_page-----a4482143d60e--------------------------------)
    [## 关于 ChatGPT 的一切你需要知道的内容'
- en: what is known, the latest news, what it is impacting, and what is changing.
    all in one article
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解已知信息、最新消息、其影响以及正在变化的情况。所有这些都在一篇文章中。
- en: medium.com](https://medium.com/data-driven-fiction/everything-but-everything-you-need-to-know-about-chatgpt-546af7153ee2?source=post_page-----a4482143d60e--------------------------------)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[medium.com](https://medium.com/data-driven-fiction/everything-but-everything-you-need-to-know-about-chatgpt-546af7153ee2?source=post_page-----a4482143d60e--------------------------------)'
- en: 'A new study by Google, focused on the utility of a wide LM to encode clinical
    knowledge and assess its potential in medicine. They decided to start with a specific
    task: [medical question answering](https://en.wikipedia.org/wiki/Question_answering).
    This is because it is a fundamental but also difficult task: the model must provide
    high-quality answers to medical questions. To do this, the model must also understand
    the medical context, find the relevant information, and reason with an expert’s
    questions.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌的一项新研究专注于利用广泛的语言模型编码临床知识，并评估其在医学中的潜力。他们决定从一个具体任务开始：[医学问答](https://en.wikipedia.org/wiki/Question_answering)。这是因为它是一个基本但也困难的任务：模型必须提供高质量的医学问题答案。为此，模型还必须理解医学背景，找到相关信息，并依据专家的问题进行推理。
- en: '[](https://arxiv.org/abs/2212.13138?source=post_page-----a4482143d60e--------------------------------)
    [## Large Language Models Encode Clinical Knowledge'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://arxiv.org/abs/2212.13138?source=post_page-----a4482143d60e--------------------------------)
    [## 大型语言模型编码临床知识'
- en: Large language models (LLMs) have demonstrated impressive capabilities in natural
    language understanding and…
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在自然语言理解方面展示了令人印象深刻的能力…
- en: arxiv.org](https://arxiv.org/abs/2212.13138?source=post_page-----a4482143d60e--------------------------------)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[arxiv.org](https://arxiv.org/abs/2212.13138?source=post_page-----a4482143d60e--------------------------------)'
- en: In fact, the idea of creating an LMs model for medicine is not new. In fact,
    there are already attempts that have been made over the years. This is because
    an LM can be trained in an [unsupervised manner](https://en.wikipedia.org/wiki/Unsupervised_learning)
    using a large amount of text (usually general text such as books or Wikipedia).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，为医学创建语言模型（LM）的想法并不新鲜。事实上，多年来已经有过尝试。这是因为LM可以通过大量文本（通常是书籍或维基百科等通用文本）以[无监督的方式](https://en.wikipedia.org/wiki/Unsupervised_learning)进行训练。
- en: Models are trained without a specific task, but as the scaling law shows, LMs
    are capable of emergent behaviors that allow them to adapt to particular tasks
    without the need for [gradient updates](https://en.wikipedia.org/wiki/Gradient_descent).
    One example is in-context [few-shot learning](https://paperswithcode.com/task/few-shot-learning)
    that allows models to “rapidly generalize to unseen tasks and even exhibit apparent
    reasoning abilities with appropriate prompting strategies.” In addition, the models
    implicitly act as a knowledge base, though also have the disadvantage of amplifying
    the biases present in the training dataset.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在没有具体任务的情况下进行训练，但正如扩展法则所示，LM能够展现出使其能够适应特定任务的突现行为，而无需[梯度更新](https://en.wikipedia.org/wiki/Gradient_descent)。一个例子是在上下文[少样本学习](https://paperswithcode.com/task/few-shot-learning)中，模型能够“快速概括到未见任务，甚至表现出明显的推理能力，配合适当的提示策略。”此外，模型隐式地充当知识库，但也有放大训练数据集中存在的偏见的缺点。
- en: In any case, several approaches have been attempted, as there are millions of
    medical articles and countless medical data that can be exploited. Early models
    were based on [BERT](https://en.wikipedia.org/wiki/BERT_(language_model)) (sciBERT,
    BioBERT, PubMedBERT, DARE, ScholarBERT). In addition, models based on the GPT
    architecture, such as the recent BioGPT, have also been attempted.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，已经尝试了几种方法，因为有数百万篇医学文章和无数医学数据可以利用。早期模型基于[BERT](https://en.wikipedia.org/wiki/BERT_(language_model))（sciBERT、BioBERT、PubMedBERT、DARE、ScholarBERT）。此外，也尝试过基于GPT架构的模型，如最近的BioGPT。
- en: '[](https://levelup.gitconnected.com/microsoft-biogpt-towards-the-chatgpt-of-life-science-56e251536af6?source=post_page-----a4482143d60e--------------------------------)
    [## Microsoft BioGPT: Towards the ChatGPT of life science?'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://levelup.gitconnected.com/microsoft-biogpt-towards-the-chatgpt-of-life-science-56e251536af6?source=post_page-----a4482143d60e--------------------------------)
    [## 微软 BioGPT：迈向生命科学的 ChatGPT？'
- en: BioGPT achieves the SOTA in different biomedical NLP tasks
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: BioGPT 在不同生物医学自然语言处理任务中实现了**SOTA**。
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/microsoft-biogpt-towards-the-chatgpt-of-life-science-56e251536af6?source=post_page-----a4482143d60e--------------------------------)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[levelup.gitconnected.com](https://levelup.gitconnected.com/microsoft-biogpt-towards-the-chatgpt-of-life-science-56e251536af6?source=post_page-----a4482143d60e--------------------------------)'
- en: So what does this study bring that is new?
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 那么这项研究带来了什么新的东西呢？
- en: A new dataset that allows better evaluation of LM in medical question answering.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个允许更好评估语言模型在医学问答中的新数据集。
- en: State-of-the-art results on medical question answering benchmarks.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在医学问答基准上达到最先进的结果。
- en: Instruction prompts tuning to improve alignment to the medical domain.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指令提示调整以提高对医学领域的对齐。
- en: An in-depth analysis of LM limitations in the medical domain.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对语言模型在医学领域的局限性的深入分析。
- en: '![](../Images/8af892e30991b128b683835200dd4ad1.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8af892e30991b128b683835200dd4ad1.png)'
- en: '“Overview of our contributions We curated MultiMedQA, a benchmark for medical
    question answering spanning medical exam, medical research, and consumer medical
    questions. We evaluated PaLM and its instructed-tuned variant, Flan-PaLM, on MultiMedQA.
    With a combination of prompting strategies, Flan-PaLM exceeded SOTA performance
    on MedQA (USMLE), MedMCQA, PubMedQA, and MMLU clinical topics. In particular,
    it improved over the previous SOTA on MedQA (USMLE) by over 17%. We next proposed
    instruction prompt tuning to further align Flan-PaLM to the medical domain, producing
    Med-PaLM. Med-PaLM’s answers to consumer medical questions compared favorably
    with clinician-generated answers under our human evaluation framework, demonstrating
    the effectiveness of instruction prompt tuning”. figure source: [here](https://arxiv.org/pdf/2212.13138.pdf)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: “我们贡献的概述：我们策划了MultiMedQA，一个涵盖医学考试、医学研究和消费者医学问题的医学问答基准。我们在MultiMedQA上评估了PaLM及其指令调整变体Flan-PaLM。通过组合提示策略，Flan-PaLM在MedQA（USMLE）、MedMCQA、PubMedQA和MMLU临床主题上超越了SOTA性能。特别是，它在MedQA（USMLE）上的表现比之前的SOTA提高了超过17%。接下来，我们提出了指令提示调整以进一步将Flan-PaLM与医学领域对齐，生成了Med-PaLM。在我们的人类评估框架下，Med-PaLM对消费者医学问题的回答与临床医生生成的回答相比表现良好，展示了指令提示调整的有效性”。图像来源：[这里](https://arxiv.org/pdf/2212.13138.pdf)
- en: How to evaluate a language model in medicine?
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何评估医学中的语言模型？
- en: '![](../Images/ff3b511131ef7bb5e3cf91e9635d4a60.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ff3b511131ef7bb5e3cf91e9635d4a60.png)'
- en: photo by [Online Marketing](https://unsplash.com/it/@impulsq) on Unsplash
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[在线营销](https://unsplash.com/it/@impulsq) 在Unsplash
- en: 'First, we need a good dataset. The authors note that there are several datasets
    for research but each one focuses on a specific aspect or task: medical exam questions,
    medical exam questions, and helpful answers to medical information needs.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要一个好的数据集。作者指出，尽管有几个用于研究的数据集，但每个数据集都关注于特定的方面或任务：医学考试问题、医学考试问题和医学信息需求的有用答案。
- en: We acknowledge that medical knowledge is vast in both quantity and quality.
    Existing benchmarks are inherently limited and only provide partial coverage of
    the space of medical knowledge. Nonetheless, bringing together a number of different
    datasets for medical question answering enables deeper evaluation of LLM knowledge
    than multiple-choice accuracy or natural language generation metrics such as BLEU.
    ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们承认医学知识在数量和质量上都是巨大的。现有基准固有地有限，只提供了医学知识空间的部分覆盖。然而，将多个不同的数据集合并用于医学问答，使得对LLM知识的评估比选择题准确性或诸如BLEU这样的自然语言生成指标更为深入。([来源](https://arxiv.org/pdf/2212.13138.pdf))
- en: The authors in other words say that one dataset alone is not enough, since the
    domain is quite large. Moreover, evaluating a metric such as [BLEU](https://en.wikipedia.org/wiki/BLEU)
    (or another metric) does not demonstrate the model’s ability to understand the
    domain.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 作者换句话说，一个数据集是不够的，因为该领域相当广泛。此外，评估诸如[BLEU](https://en.wikipedia.org/wiki/BLEU)（或其他指标）这样的指标并不能展示模型理解领域的能力。
- en: The newly constituted dataset requires that the model be capable of answering
    multiple choice questions, open-ended questions (long form), closed domain (the
    answer must be found in the reference text), and open domain questions (limited
    information is present in a specific source).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 新构建的数据集要求模型能够回答选择题、开放性问题（长形式）、封闭领域（答案必须在参考文本中找到）和开放领域问题（特定来源中信息有限）。
- en: So in summary, the authors constructed a new benchmark by combining already
    used datasets and datasets of curated commonly searched health queries. The entire
    dataset is in English and covers either medical examinations, medical searches,
    or even consumer queries. There are also labels and metadata.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，作者通过结合已经使用的数据集和策划的常见健康查询数据集，构建了一个新的基准。整个数据集均为英文，并涵盖了医学考试、医学搜索，甚至是消费者查询。还有标签和元数据。
- en: '![](../Images/0780b401e6f6868091afb988526d523c.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0780b401e6f6868091afb988526d523c.png)'
- en: ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ([source](https://arxiv.org/pdf/2212.13138.pdf))
- en: 'Given the complexity of the domain, they have enriched the dataset with answers
    written by clinicians. In addition:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于领域的复杂性，他们通过临床医生编写的答案丰富了数据集。此外：
- en: Secondly, given the safety-critical requirements of the medical domain, we believe
    it is important to move beyond automated measures of long-form answer generation
    quality using metrics such as BLEU to those involving more nuanced human evaluation
    frameworks such as the one proposed in this study.
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 其次，鉴于医疗领域的安全关键要求，我们认为有必要超越使用BLEU等指标的自动化长答案生成质量测量，转向涉及更细致的人类评估框架，如本研究中提出的框架。
- en: 'an example of multiple choice question:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一个多项选择题的示例：
- en: '![](../Images/81a27b472eb3a865a3a25eac54617e9a.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81a27b472eb3a865a3a25eac54617e9a.png)'
- en: ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ([source](https://arxiv.org/pdf/2212.13138.pdf))
- en: 'and long answer question:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 以及长答案问题：
- en: '![](../Images/98590bf8dee606642f7030f06489c12f.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/98590bf8dee606642f7030f06489c12f.png)'
- en: ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ([source](https://arxiv.org/pdf/2212.13138.pdf))
- en: The authors then defined a framework for which clinicians could measure the
    robustness of the model. Indeed, the use of metrics although useful omits many
    important details and can be misleading in the medical context.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 作者们随后定义了一个框架，以便临床医生能够衡量模型的稳健性。的确，尽管使用指标很有用，但它忽略了许多重要细节，在医学背景下可能会产生误导。
- en: The authors used focus groups and interviews with clinicians based in the UK,
    US, and India to define the axes of evaluation. In addition, they emphasized “notions
    of agreement with scientific consensus, possibility and the likelihood of harm,
    completeness, and missingness of answers and possibility of bias.”
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 作者们使用了来自英国、美国和印度的临床医生的焦点小组和访谈来定义评估轴。此外，他们强调了“与科学共识的一致性、伤害的可能性和概率、答案的完整性和缺失情况以及偏见的可能性。”
- en: '![](../Images/ce46d4c18f0d48e4c1d8781455911f0d.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ce46d4c18f0d48e4c1d8781455911f0d.png)'
- en: “Summary of the different axes along which clinicians evaluate the answers in
    our consumer medical question answering datasets. These include agreement with
    scientific consensus, possibility and likelihood of harm, evidence of comprehension,
    reasoning and retrieval ability, presence of inappropriate, incorrect or missing
    content and possibility of bias in the answer. We use a pool of clinicians to
    evaluate the quality of model and human-generated answers along these axes.” ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: “总结了临床医生在我们的消费者医疗问题回答数据集中评估答案的不同方面。这些包括与科学共识的一致性、伤害的可能性和概率、理解证据、推理和检索能力、不适当、错误或缺失内容的存在以及答案中的偏见可能性。我们使用了一组临床医生来评估模型和人工生成答案在这些方面的质量。”
    ([source](https://arxiv.org/pdf/2212.13138.pdf))
- en: 'The table summarizes the kinds of issues the form presents. As the authors
    state both harm and bias are complex concepts that have no single answer. For
    example, harm can be defined at different levels: “physical health, mental health,
    moral, financial, and many others.” Therefore, the authors created a form with
    different questions and provided it to clinicians in different countries (US,
    UK, and India).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 表格总结了表单呈现的问题种类。正如作者所述，伤害和偏见都是复杂的概念，没有单一答案。例如，伤害可以在不同层面上定义：“身体健康、心理健康、道德、财务等。”因此，作者创建了一个包含不同问题的表单，并将其提供给不同国家（美国、英国和印度）的临床医生。
- en: 'On the other hand, not everyone has medical knowledge, so the authors decided
    to evaluate the helpfulness and utility of the answers to the consumer. They created
    a form and the rating was conducted by people who had no medical background:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，并非每个人都有医学知识，因此作者决定评估答案对消费者的帮助性和实用性。他们创建了一个表单，并由没有医学背景的人进行评分：
- en: The goal of this exercise was to assess how well the answer addressed the perceived
    intent underlying the question and how helpful and actionable it was. ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这项工作旨在评估答案如何应对问题背后的感知意图，以及答案的帮助性和可操作性如何。 ([source](https://arxiv.org/pdf/2212.13138.pdf))
- en: '![](../Images/c0a52b11b34f755350c77c59073dc84d.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c0a52b11b34f755350c77c59073dc84d.png)'
- en: “Summary of the different axes along which lay users evaluate the utility of
    answers in our consumer medical question answering datasets. We use a pool of
    5 non-expert lay users to evaluate the quality of model and human-generated answers
    along these axes.” ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: “总结了普通用户在我们的消费者医学问答数据集中评估答案实用性的不同轴向。我们使用了 5 位非专家普通用户来评估模型和人工生成答案在这些轴向上的质量。”
    ([source](https://arxiv.org/pdf/2212.13138.pdf))
- en: Which model?
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 哪种模型？
- en: '![](../Images/eb4355ee3e3daf25ecac6bb4d5625809.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eb4355ee3e3daf25ecac6bb4d5625809.png)'
- en: photo by [Kimon Maritz](https://unsplash.com/it/@kimonmaritz) on Unsplash
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Kimon Maritz](https://unsplash.com/it/@kimonmaritz) 提供，来源于 Unsplash
- en: The authors started by using the Pathways Language Model (PaLM) and the Flan-PaLM
    family.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 作者开始使用 Pathways 语言模型（PaLM）和 Flan-PaLM 家族。
- en: '[PaLM](https://arxiv.org/abs/2204.02311) is “a densely-activated decoder-only
    transformer language model trained using Pathways.” The model was trained with
    a huge corpus of 780 B tokens including internet data, Wikipedia, source code,
    social media conversation, and books. PaLM in the largest version contains 540
    B of parameters and has achieved state-of-the-art in several benchmarks.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[PaLM](https://arxiv.org/abs/2204.02311) 是“一种密集激活的解码器-only 变换器语言模型，使用 Pathways
    进行训练。” 该模型使用了包括互联网数据、维基百科、源代码、社交媒体对话和书籍在内的大规模语料库进行训练。PaLM 最大版本包含 540 B 的参数，并在多个基准测试中达到了最先进的水平。'
- en: '[Flan-PaLM](https://arxiv.org/abs/2210.11416) is the PaLM instruction-tuned
    counterpart. Flan-PaLM has been trained using different datasets for instruction
    tuning. As demonstrated above, the use of chain-of-thoughts allows the model to
    generalize better.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[Flan-PaLM](https://arxiv.org/abs/2210.11416) 是 PaLM 的指令调整版。Flan-PaLM 使用了不同的数据集进行指令调整。如上所示，使用思维链使模型能够更好地泛化。'
- en: '[](/multimodal-chain-of-thoughts-solving-problems-in-a-multimodal-world-961a8ab9d0fa?source=post_page-----a4482143d60e--------------------------------)
    [## Multimodal Chain of Thoughts: Solving Problems in a Multimodal World'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/multimodal-chain-of-thoughts-solving-problems-in-a-multimodal-world-961a8ab9d0fa?source=post_page-----a4482143d60e--------------------------------)
    [## 多模态思维链：在多模态世界中解决问题'
- en: 'The world is not only text: How to extend the chain of thoughts to image and
    text?'
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 世界不仅仅是文本：如何将思维链扩展到图像和文本？
- en: towardsdatascience.com](/multimodal-chain-of-thoughts-solving-problems-in-a-multimodal-world-961a8ab9d0fa?source=post_page-----a4482143d60e--------------------------------)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/multimodal-chain-of-thoughts-solving-problems-in-a-multimodal-world-961a8ab9d0fa?source=post_page-----a4482143d60e--------------------------------)
- en: 'Once we have the model the main problem is how to adapt it to the medical domain:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们拥有模型，主要的问题就是如何将其适应医学领域：
- en: However, given the safety critical nature of the medical domain, it is necessary
    to adapt and align the model with domain-specific data. ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 然而，考虑到医学领域的安全关键性质，有必要将模型适应并对齐领域特定的数据。 ([source](https://arxiv.org/pdf/2212.13138.pdf))
- en: 'The authors decided to use prompt and prompt tuning as a strategy. LMs as demonstrated
    are few-shot learners (need a few examples) for in-context learning. In other
    words, with a few examples of carefully selected prompts, the model can learn
    a new task without any gradient updates or finetuning. The authors used three
    prompting strategies:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 作者决定使用提示和提示调整作为策略。正如所示，语言模型是少量示例学习者（需要少量示例）以进行上下文学习。换句话说，通过一些精心挑选的提示示例，模型可以在没有任何梯度更新或微调的情况下学习新任务。作者使用了三种提示策略：
- en: '**Few-shot prompting.** few-shot examples describing the task through text-based
    descriptions (input-output pairs). The best demonstrations were done in agreement
    with qualified clinicians (for each of the datasets).'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**少量提示**。通过基于文本的描述（输入-输出对）描述任务的少量示例。最佳演示是在与合格临床医生一致的情况下完成的（针对每个数据集）。'
- en: '**Chain-of-thought prompting.** A set of intermediate reasoning steps toward
    the final answer is added to the prompt (an approach that mimics human reasoning
    in problem-solving). These prompts were also created in conjunction with clinicians.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**思维链提示**。在提示中添加一系列中间推理步骤以得出最终答案（这种方法模仿了人类在解决问题时的推理过程）。这些提示也与临床医生一起创建。'
- en: '**Self-consistency prompting.** One strategy for improving the performance
    of the model in multiple-choice questions is to sample multiple decoding outputs
    from the model (the final answer will then be the one that received the majority
    of votes). The ‘idea behind this is that in a complex domain, there can be multiple
    potential routes to the correct answer.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自一致性提示。** 提高模型在多项选择题中表现的一种策略是从模型中采样多个解码输出（最终答案将是获得多数票的那个）。‘其背后的想法是，在复杂领域中，可能有多条路径可以达到正确答案。'
- en: As mentioned earlier, prompting methods make it possible to improve the model
    relatively inexpensively (fine-tuning such large models is computationally expensive).
    Pero prompting is not enough for many tasks, but they would benefit from fine-tuning.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，提示方法使得相对低成本地改进模型成为可能（微调如此大型的模型计算成本高）。但是提示对许多任务来说是不够的，它们将从微调中受益。
- en: '![](../Images/225390265af7e9c7bec1662b4451a6c6.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/225390265af7e9c7bec1662b4451a6c6.png)'
- en: photo by [Anton Shuvalov](https://unsplash.com/it/@a8ka) on Unsplash
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 由[Anton Shuvalov](https://unsplash.com/it/@a8ka)在Unsplash拍摄
- en: How to do fine-tuning of a 540 B model?
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如何对540B模型进行微调？
- en: '**The answer: prompting tuning.** In short, prompt tuning is some prompts (human
    or AI model-generated vectors) to guide the model to a desired task. There are
    two types of prompts, those encoded by humans (hard prompts) and those learned
    using backpropagation (soft prompts). This narrows the learnable parameters to
    only those representing a small number of tokens (the rest of the model is frozen).'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：提示微调。** 简而言之，提示微调是一些提示（由人类或AI模型生成的向量）用于引导模型完成预期任务。提示有两种类型，一种是由人类编码的（硬提示），另一种是通过反向传播学习到的（软提示）。这将可学习的参数缩小到仅表示少量标记（其余模型被冻结）。'
- en: The authors in this study used both soft prompts and relevant task-specific
    human-engineered prompts (hard).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 该研究的作者使用了软提示和相关任务特定的人类设计提示（硬提示）。
- en: We refer to this method of prompt tuning as “instruction prompt tuning”. Instruction
    prompt tuning can thus be seen as a lightweight way (data-efficient, parameter-efficient,
    compute-efficient during both training and inference) of training a model to follow
    instructions in one or more domains. ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们将这种提示微调的方法称为“指令提示微调”。指令提示微调因此可以被视为一种轻量级的方法（数据高效、参数高效、训练和推理过程中计算高效）来训练模型以遵循一个或多个领域的指令。
    ([source](https://arxiv.org/pdf/2212.13138.pdf))
- en: Then they used instruction prompt tuning on a small set of exemplars to adapt
    Flan-PaLM to the medical domain. Since these are few exemplars, these must be
    good examples “of medical comprehension, recall of clinical knowledge, and reasoning
    on medical knowledge unlikely to lead to patient harm.” **In other words, these
    examples were particularly curated in collaboration with medical experts (clinicians
    from different disciplines).**
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，他们在一小部分示例上使用了指令提示微调，将Flan-PaLM适配到医学领域。由于这些示例较少，它们必须是“医学理解、临床知识回忆和医学知识推理方面的良好示例，不容易导致患者伤害。”
    **换句话说，这些示例特别与医学专家（来自不同学科的临床医生）合作精心策划。**
- en: '![](../Images/4c33efd486cdae4b521426e2d6d28d82.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4c33efd486cdae4b521426e2d6d28d82.png)'
- en: Instruction prompt tuning for Med-PaLM ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 医疗领域的指令提示微调 ([source](https://arxiv.org/pdf/2212.13138.pdf))
- en: 'Med-PaLM: does it is better than the other models?'
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Med-PaLM：它是否比其他模型更好？
- en: '![](../Images/725e4eb56ffff52d1ce66c18399679d4.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/725e4eb56ffff52d1ce66c18399679d4.png)'
- en: image by [Steven Lelham](https://unsplash.com/it/@slelham) on unsplash
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图像由[Steven Lelham](https://unsplash.com/it/@slelham)在Unsplash拍摄
- en: 'The model has reached and surpassed the state of the art:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 模型已达到并超越了现有技术水平：
- en: '**MedQA,** multiple choice questions on general medical knowledge (U.S. medical
    licensing exam).'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MedQA，** 涵盖一般医学知识的多项选择题（美国医学执照考试）。'
- en: '**MedMCQA,** medical entrance exam questions from India (multiple choice questions).'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MedMCQA，** 来自印度的医学入学考试问题（多项选择题）。'
- en: '**PubMedQA,** biomedical scientific literature.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PubMedQA，** 生物医学科学文献。'
- en: '**MMLU,** multiple-choice questions on various topics of clinical knowledge,
    medicine, and biology. related topics'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MMLU，** 多项选择题涵盖临床知识、医学和生物学的各种主题。相关主题'
- en: '![](../Images/bc23ead57fefeff0dfbf0671815c9764.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bc23ead57fefeff0dfbf0671815c9764.png)'
- en: 'left: Comparison of SOTA LLMs on MMLU clinical topics. right: summary of the
    performance of PaLM and Flan-PaLM models across different model size variants.
    adapted from [here](https://arxiv.org/pdf/2212.13138.pdf).'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧：SOTA LLMs在MMLU临床主题上的比较。右侧：PaLM和Flan-PaLM模型在不同模型尺寸变体上的表现总结。改编自[这里](https://arxiv.org/pdf/2212.13138.pdf)。
- en: The results also are consistent along the various categories of clinical topics,
    showing that Flan-PaLM reaches SOTA in all categories.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 结果在不同临床主题类别中也保持一致，显示出Flan-PaLM在所有类别中都达到了SOTA水平。
- en: '![](../Images/5a1a8442e839c0b0339d2f7ccbfcfa8b.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5a1a8442e839c0b0339d2f7ccbfcfa8b.png)'
- en: ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ([source](https://arxiv.org/pdf/2212.13138.pdf))
- en: The authors also decided to evaluate the performance of the model even at different
    model sizes using medical question-answering datasets in MultiMedQA. This shows
    that scaling improves the performance of the model when using few-shot prompting
    Also the result shows that instruction tuning improves the performance in comparison
    to baseline.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 作者们还决定评估模型在不同模型尺寸下的表现，使用了MultiMedQA中的医学问答数据集。这表明，当使用少量示例提示时，扩展模型规模可以提升模型性能。同时，结果还表明，指令微调相比基线提高了性能。
- en: '![](../Images/c312603e59ab7c5c6e127119c7ea695d.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c312603e59ab7c5c6e127119c7ea695d.png)'
- en: ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ([source](https://arxiv.org/pdf/2212.13138.pdf))
- en: 'In addition, the authors note two interesting factors:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，作者提到了两个有趣的因素：
- en: first, Chain-of-Thought (CoT) prompting does not bring improvement in this case
    (which is actually surprising).
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，思维链（CoT）提示在这种情况下并没有带来改进（这实际上令人惊讶）。
- en: Self-consistency (SC) leads to strong improvement in multiple-choice performance
    (which was expected)
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自一致性（SC）在多项选择题表现上带来了显著改善（这是预期中的结果）。
- en: '![](../Images/75aae3ea568125c02926e621d456bc9a.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75aae3ea568125c02926e621d456bc9a.png)'
- en: 'left: Summary of the performance of Flan-PaLM models with few-shot and chain-of-thought
    (CoT) prompting. right: Summary of the performance of Flan-PaLM with and without
    self-consistency prompting (SC). adapted from [here](https://arxiv.org/pdf/2212.13138.pdf).'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧：Flan-PaLM模型在少量示例和思维链（CoT）提示下的表现总结。右侧：Flan-PaLM模型在有无自一致性提示（SC）下的表现总结。改编自[这里](https://arxiv.org/pdf/2212.13138.pdf)。
- en: 'The model is also capable of generating an explanation of why it chose a particular
    response:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型也能够生成解释，说明它为何选择了特定的响应：
- en: '![](../Images/cf5f5abfc0a4a51b49f327f99544bcc6.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cf5f5abfc0a4a51b49f327f99544bcc6.png)'
- en: “example explanations generated by the Flan-PaLM 540B model to support its multiple-choice
    answer” ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: “Flan-PaLM 540B模型生成的示例解释，以支持其多项选择答案”（[source](https://arxiv.org/pdf/2212.13138.pdf)）
- en: LMs are capable of hallucinating, and in the medical context, this can be disastrous.
    Therefore, the authors investigated the relationship between LLM uncertainty and
    statement accuracy. In other words, they used model confidence, and with higher
    confidence, they noticed higher accuracy.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型（LMs）可能会产生幻觉，在医学背景下，这可能是灾难性的。因此，作者调查了LLM不确定性与陈述准确性之间的关系。换句话说，他们使用了模型置信度，发现更高的置信度对应着更高的准确性。
- en: '![](../Images/b60eaf440b2032888b2bfb8bd37898f2.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b60eaf440b2032888b2bfb8bd37898f2.png)'
- en: Analysis of deferral behavior of Flan-PaLM 540B model with self-consistency
    ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: Flan-PaLM 540B模型的推迟行为分析（[source](https://arxiv.org/pdf/2212.13138.pdf)）
- en: Does the model convince the clinicians?
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 该模型是否能说服临床医生？
- en: '![](../Images/07d5920df08e760c201adcc2ff243f3d.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/07d5920df08e760c201adcc2ff243f3d.png)'
- en: image by [Sander Sammy](https://unsplash.com/it/@sammywilliams) on unsplash
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Sander Sammy](https://unsplash.com/it/@sammywilliams)提供，来自unsplash
- en: Best accuracy is enough to use the model in clinics?
  id: totrans-117
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 最佳准确性是否足以在临床中使用该模型？
- en: Metrics are important but can be misleading. Especially for a sensitive field
    like medicine, there is a need for more than just the result on a benchmark.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 指标很重要，但可能会产生误导。特别是在像医学这样敏感的领域中，需要的不仅仅是基准测试的结果。
- en: The authors selected 100 questions that may represent the inquiries of real
    consumers. After that, they used Flan-PaLM and Med-PaLM (both 540B models) to
    predict responses and submitted them to a panel of 9 clinicians (based in the
    US, UK, and India).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 作者选择了100个可能代表真实消费者询问的问题。随后，他们使用Flan-PaLM和Med-PaLM（两个540B模型）来预测回答，并将其提交给了一个由9位临床医生（来自美国、英国和印度）组成的评审小组。
- en: While clinicians showed scientific consensus in 92 % of the questions, Flan-PaLM
    was in agreement in 61 % of the cases.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管临床医生在92%的问题上达成了科学共识，但Flan-PaLM在61%的情况下达成了一致。
- en: This suggested that generic instruction tuning on its own was not sufficient
    to produce scientific and clinically grounded answers. However, we observed that
    92.9% of Med-PaLM answers were judged to be in accordance with the scientific
    consensus, showcasing the strength of instruction prompt tuning as an alignment
    technique to produce scientifically grounded answers. ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-121
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这表明，单独的通用指令微调不足以产生科学和临床上可靠的答案。然而，我们观察到92.9%的Med-PaLM答案被评定为符合科学共识，展示了指令提示微调作为对齐技术在产生科学基础答案方面的优势。
    ([source](https://arxiv.org/pdf/2212.13138.pdf))
- en: '![](../Images/8a8188548cf9d4e6e71bf935f7890619.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8a8188548cf9d4e6e71bf935f7890619.png)'
- en: ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ([source](https://arxiv.org/pdf/2212.13138.pdf))
- en: The models were trained on articles and books that have been published previously,
    so the authors point out that this may be a reason for failure and continued learning
    should be explored.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 模型是在以前发布的文章和书籍上进行训练的，因此作者指出这可能是失败的原因之一，未来应继续探索学习。
- en: The authors then asked clinicians whether the model contained errors in comprehension,
    knowledge retrieval, and reasoning capabilities of medical knowledge. Here again,
    Med-PaLM was shown to be superior to Flan-PaLM.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，作者询问临床医生模型在理解、知识检索和医学知识推理能力方面是否存在错误。在这里，Med-PaLM再次表现优于Flan-PaLM。
- en: '![](../Images/ca4d8f18fc551235e6c9c0cb1f9657f7.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ca4d8f18fc551235e6c9c0cb1f9657f7.png)'
- en: ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ([source](https://arxiv.org/pdf/2212.13138.pdf))
- en: 'The authors asked whether the answers contained errors or missing content (the
    completeness and correctness of the generated answers). That is, whether the model
    omitted information that should have been there or there was information in the
    answer that should not have been there. Med-PaLM answers showed omission of important
    information in 15 % of cases (compared with 47 % in Flan-PaLM). Surprisingly,
    though, Med-PaLM contained more errors than Flan-PaLM (18 % vs. 16 %). The authors
    explain this result thus:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 作者询问答案是否包含错误或缺失内容（生成答案的完整性和正确性）。也就是说，模型是否遗漏了应有的信息，或者答案中是否有不应包含的信息。Med-PaLM的答案在15%的情况下显示了重要信息的遗漏（相比之下，Flan-PaLM为47%）。令人惊讶的是，Med-PaLM的错误率高于Flan-PaLM（18%对16%）。作者对此结果的解释如下：
- en: instruction prompt tuning teaches the Med-PaLM model to generate significantly
    more detailed answers than the Flan-PaLM model, reducing the omission of important
    information. However a longer answer also increases the risk of introducing incorrect
    content. ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-129
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 指令提示微调使Med-PaLM模型生成的答案显著比Flan-PaLM模型更详细，从而减少了重要信息的遗漏。然而，较长的答案也增加了引入不正确内容的风险。
    ([source](https://arxiv.org/pdf/2212.13138.pdf))
- en: '![](../Images/0534f0ca83ee534748e1450b035d43bc.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0534f0ca83ee534748e1450b035d43bc.png)'
- en: The authors also explored the severity and likelihood of potential harm from
    the generated responses. In other words, they asked whether these responses could
    lead to actions by either clinicians or consumers/patients that would lead to
    health-related harm. Although the definition is relative and the rating is in
    this case a subjective measure, instruct fine-tuning produces safer responses
    in comparison with the baseline model.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 作者还探讨了生成响应可能带来的潜在危害的严重性和可能性。换句话说，他们询问这些响应是否可能导致临床医生或消费者/患者采取可能造成健康相关伤害的行动。尽管定义是相对的，评分在这种情况下是主观的，但与基线模型相比，指令微调产生了更安全的响应。
- en: '![](../Images/cc23eb96fb08305a170cab55a911dd7a.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cc23eb96fb08305a170cab55a911dd7a.png)'
- en: ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ([source](https://arxiv.org/pdf/2212.13138.pdf))
- en: In addition, the authors analyzed the potential for the model to amplify bias
    in healthcare. The model could reflect or amplify patterns present in training
    data that reflect disparities in health outcomes and access to care. The results
    show that the new approach significantly reduces the risk of bias.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，作者分析了模型在医疗保健中放大偏见的潜在风险。该模型可能反映或放大训练数据中存在的反映健康结果和护理获取差异的模式。结果显示，新方法显著降低了偏见风险。
- en: '![](../Images/7fcc6f131454969819dde4f393a0c267.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7fcc6f131454969819dde4f393a0c267.png)'
- en: ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ([source](https://arxiv.org/pdf/2212.13138.pdf))
- en: Finally, the authors analyzed how non-expert assess the answers.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，作者分析了非专家如何评估答案。
- en: While Flan-PaLM answers were judged to be helpful in only 60.6% of the cases,
    the number improved to 80.3% for Med-PaLM answers. ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-138
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 尽管Flan-PaLM的回答被评估为在60.6%的情况下有帮助，但Med-PaLM的回答这一数字提高到了80.3%。 ([source](https://arxiv.org/pdf/2212.13138.pdf))
- en: But remain inferior to clinicians. Similar results have been obtained by asking
    the non-expert consumers if the answers directly answered the user’s question.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 但仍然不如临床医生。通过询问非专家消费者回答是否直接回答了用户的问题，得到了类似的结果。
- en: '![](../Images/d750ef52e72706b4d54390645c6ae773.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d750ef52e72706b4d54390645c6ae773.png)'
- en: ([source](https://arxiv.org/pdf/2212.13138.pdf))
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: ([source](https://arxiv.org/pdf/2212.13138.pdf))
- en: Limitations of the model
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型的局限性
- en: '![](../Images/5e0fc29daf1d272b0aaaa2d0a5d6ef9a.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5e0fc29daf1d272b0aaaa2d0a5d6ef9a.png)'
- en: photo by [Joshua Hoehne](https://unsplash.com/it/@mrthetrain) on unsplash
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 由 [Joshua Hoehne](https://unsplash.com/it/@mrthetrain) 在unsplash拍摄
- en: 'The authors note several limitations to the study and future directions:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 作者指出了研究的若干限制和未来方向：
- en: '**The dataset they proposed (MultiMedQA) is not exhaustive** (despite including
    several sources). For example, it is lacking in biology. In addition, the model
    should also include questions and answers closer to the real world (multiple-choice
    questions are easy to fill in but are far from the real world).'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**他们提出的数据集（MultiMedQA）并不全面**（尽管包含了多个来源）。例如，它在生物学方面存在不足。此外，模型还应包括更贴近现实世界的问题和答案（多项选择题容易填补，但与现实世界相距甚远）。'
- en: Performance evaluation with experts shows **that this model is not at the level
    of clinicians.**
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与专家的性能评估显示**该模型尚不具备临床医生的水平**。
- en: '**The same human evaluation approach could be improved.** Certainly, it is
    limited and the number of experts should be increased. The very concept of consensus
    is context and time-dependent. In addition, scientific consensus often does not
    take minorities into account and thus could itself be a source of bias. Not to
    mention that it is influenced by the background of the clinicians themselves.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**相同的人类评估方法可以改进。** 当然，它是有限的，专家的数量应该增加。共识的概念是与上下文和时间相关的。此外，科学共识往往没有考虑到少数群体，因此可能本身就是偏见的来源。更不用说它受到了临床医生自身背景的影响。'
- en: '**The analysis of bias and harm is limited**, considering that this is exploratory
    work. On the other hand, the medical field is an extremely sensitive field and
    these are ethical issues that cannot be ignored. Therefore, the analysis should
    be expanded to include patients as well. In addition, specific benchmark datasets
    for similar tasks are lacking.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**偏见和伤害的分析是有限的**，考虑到这是探索性工作。另一方面，医疗领域是一个极其敏感的领域，这些都是不能忽视的伦理问题。因此，分析应该扩展到包括患者。此外，缺乏类似任务的特定基准数据集。'
- en: Parting thoughts
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后的思考
- en: '![](../Images/1b50ca35b6b4941334b3a4bf4ed4faee.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1b50ca35b6b4941334b3a4bf4ed4faee.png)'
- en: photo by [Amine rock hoovr](https://unsplash.com/it/@hoovr01) on Unsplash
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 由 [Amine rock hoovr](https://unsplash.com/it/@hoovr01) 在Unsplash拍摄
- en: This paper shows how instruction prompt tuning can improve the performance of
    a model in a complex field such as medical question answering. However, this behavior
    emerges with the scale of the model. Moreover, this model manages to achieve state-of-the-art
    in comparison to other models
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇论文展示了如何通过指令提示调优来改善模型在医疗问答等复杂领域的表现。然而，这种行为随着模型规模的增加而出现。此外，与其他模型相比，该模型实现了最先进的技术水平。
- en: The 540 B version of PaLM alone still manages to achieve appreciable results.
    Probably the training data contained several medical sources, and the model stored
    this information among the parameters.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: PaLM的540 B版本单独仍然能够取得显著的成果。可能训练数据包含了多个医学来源，模型在参数中存储了这些信息。
- en: Evaluation with human experts shows that scaling alone is not sufficient anyway.
    Even Med-PaLM itself can produce answers that are either incomplete or wrong.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 与人类专家的评估显示，仅仅扩大规模并不够。即使是Med-PaLM自身也可能产生不完整或错误的回答。
- en: In any case, it is still premature to be able to use such a model in healthcare.
    First, more research is needed to ensure the safety of the model. While for the
    time being it is difficult to hypothesize using it to treat a disease, it could
    be considered as an approach to provide information to a patient about disease
    and medication.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，目前仍然为时尚早，尚无法在医疗保健中使用这样的模型。首先，需要更多的研究以确保模型的安全性。虽然目前很难假设使用它来治疗疾病，但可以考虑作为一种向患者提供有关疾病和药物信息的方法。
- en: On the other hand, physicians also have bias, and LMs could be efficient assistants.
    In the future, LMs could also be useful in mitigating bias and allowing greater
    access to therapies.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，医生也有偏见，而语言模型可能是高效的助手。未来，语言模型还可能在减轻偏见和提供更广泛的治疗选择方面发挥作用。
- en: Lastly, Google released an API of PaLM, with the idea that it can be used for
    prototyping and building generative AI applications ([more here](https://developers.googleblog.com/2023/03/announcing-palm-api-and-makersuite.html))
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，谷歌发布了PaLM的API，旨在用于原型设计和构建生成型AI应用程序（[更多信息](https://developers.googleblog.com/2023/03/announcing-palm-api-and-makersuite.html)）
- en: 'If you have found this interesting:'
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如果你觉得这很有趣：
- en: You can look for my other articles, you can also [**subscribe**](https://salvatore-raieli.medium.com/subscribe)
    to get notified when I publish articles, and you can also connect or reach me
    on[**LinkedIn**](https://www.linkedin.com/in/salvatore-raieli/)**.**
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以查看我的其他文章，也可以[**订阅**](https://salvatore-raieli.medium.com/subscribe)以便在我发布文章时收到通知，还可以在[**LinkedIn**](https://www.linkedin.com/in/salvatore-raieli/)**上联系我**。
- en: Here is the link to my GitHub repository, where I am planning to collect code
    and many resources related to machine learning, artificial intelligence, and more.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我的GitHub库链接，我计划在这里收集与机器学习、人工智能等相关的代码和资源。
- en: '[](https://github.com/SalvatoreRa/tutorial?source=post_page-----a4482143d60e--------------------------------)
    [## GitHub - SalvatoreRa/tutorial: Tutorials on machine learning, artificial intelligence,
    data science…'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/SalvatoreRa/tutorial?source=post_page-----a4482143d60e--------------------------------)
    [## GitHub - SalvatoreRa/tutorial: 机器学习、人工智能、数据科学的教程…'
- en: Tutorials on machine learning, artificial intelligence, data science with math
    explanation and reusable code (in python…
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习、人工智能、数据科学的教程，包含数学解释和可重用的代码（Python…
- en: github.com](https://github.com/SalvatoreRa/tutorial?source=post_page-----a4482143d60e--------------------------------)
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/SalvatoreRa/tutorial?source=post_page-----a4482143d60e--------------------------------)
- en: 'or you may be interested in one of my recent articles:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 或者你可能对我最近的文章感兴趣：
- en: '[](https://pub.towardsai.net/pca-bioinformaticians-favorite-tool-can-be-misleading-fe139262a576?source=post_page-----a4482143d60e--------------------------------)
    [## PCA: Bioinformatician’s Favorite Tool Can Be Misleading'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pub.towardsai.net/pca-bioinformaticians-favorite-tool-can-be-misleading-fe139262a576?source=post_page-----a4482143d60e--------------------------------)
    [## PCA：生物信息学家的最爱工具可能具有误导性'
- en: A new study assesses how a most used technique can be problematic
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一项新的研究评估了一个最常用的技术可能存在的问题
- en: 'pub.towardsai.net](https://pub.towardsai.net/pca-bioinformaticians-favorite-tool-can-be-misleading-fe139262a576?source=post_page-----a4482143d60e--------------------------------)
    [](https://levelup.gitconnected.com/stable-diffusion-and-the-brain-how-ai-can-read-our-minds-45398b395ea9?source=post_page-----a4482143d60e--------------------------------)
    [## Stable diffusion and the brain: how AI can read our minds'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: pub.towardsai.net](https://pub.towardsai.net/pca-bioinformaticians-favorite-tool-can-be-misleading-fe139262a576?source=post_page-----a4482143d60e--------------------------------)
    [](https://levelup.gitconnected.com/stable-diffusion-and-the-brain-how-ai-can-read-our-minds-45398b395ea9?source=post_page-----a4482143d60e--------------------------------)
    [## 稳定扩散与大脑：AI如何读取我们的思想
- en: Researchers were able to reconstruct images using fMRI data
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 研究人员能够使用fMRI数据重建图像
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/stable-diffusion-and-the-brain-how-ai-can-read-our-minds-45398b395ea9?source=post_page-----a4482143d60e--------------------------------)
    [](https://levelup.gitconnected.com/stable-diffusion-to-fill-gaps-in-medical-image-data-b78a2a7d6c9d?source=post_page-----a4482143d60e--------------------------------)
    [## Stable diffusion to fill gaps in medical image data
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: levelup.gitconnected.com](https://levelup.gitconnected.com/stable-diffusion-and-the-brain-how-ai-can-read-our-minds-45398b395ea9?source=post_page-----a4482143d60e--------------------------------)
    [](https://levelup.gitconnected.com/stable-diffusion-to-fill-gaps-in-medical-image-data-b78a2a7d6c9d?source=post_page-----a4482143d60e--------------------------------)
    [## 稳定扩散填补医疗图像数据的空白
- en: A new study shows that stable diffusion could help with medical image analysis
    and rare diseases. How?
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一项新的研究表明，稳定扩散可能有助于医学图像分析和稀有疾病。如何？
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/stable-diffusion-to-fill-gaps-in-medical-image-data-b78a2a7d6c9d?source=post_page-----a4482143d60e--------------------------------)
    [](/why-do-we-have-huge-language-models-and-small-vision-transformers-5d59ac36c1d6?source=post_page-----a4482143d60e--------------------------------)
    [## Why Do We Have Huge Language Models and Small Vision Transformers?
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '[levelup.gitconnected.com](https://levelup.gitconnected.com/stable-diffusion-to-fill-gaps-in-medical-image-data-b78a2a7d6c9d?source=post_page-----a4482143d60e--------------------------------)
    [为什么我们有庞大的语言模型和小型视觉变换器？](https://levelup.gitconnected.com/stable-diffusion-to-fill-gaps-in-medical-image-data-b78a2a7d6c9d?source=post_page-----a4482143d60e--------------------------------)'
- en: Google ViT-22 paves the way for new large transformers and to revolutionize
    computer vision
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Google ViT-22 为新一代大型变换器铺平了道路，并有望革新计算机视觉
- en: towardsdatascience.com](/why-do-we-have-huge-language-models-and-small-vision-transformers-5d59ac36c1d6?source=post_page-----a4482143d60e--------------------------------)
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/why-do-we-have-huge-language-models-and-small-vision-transformers-5d59ac36c1d6?source=post_page-----a4482143d60e--------------------------------)
    [为什么我们有庞大的语言模型和小型视觉变换器？](https://levelup.gitconnected.com/stable-diffusion-to-fill-gaps-in-medical-image-data-b78a2a7d6c9d?source=post_page-----a4482143d60e--------------------------------)'
