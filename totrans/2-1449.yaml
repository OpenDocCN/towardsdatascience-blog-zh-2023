- en: Lost in DALL-E 3 Translation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/lost-in-dall-e-3-translation-b85a3958b9d6](https://towardsdatascience.com/lost-in-dall-e-3-translation-b85a3958b9d6)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Generating AI images in multiple languages leads to different results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@artfish?source=post_page-----b85a3958b9d6--------------------------------)[![Yennie
    Jun](../Images/b635e965f21c3d55833269e12e861322.png)](https://medium.com/@artfish?source=post_page-----b85a3958b9d6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b85a3958b9d6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b85a3958b9d6--------------------------------)
    [Yennie Jun](https://medium.com/@artfish?source=post_page-----b85a3958b9d6--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b85a3958b9d6--------------------------------)
    ·11 min read·Nov 2, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/77d913b783ec6e95f9ffeecc49a33bca.png)'
  prefs: []
  type: TYPE_IMG
- en: Images generated using DALL-E 3 in the six languages for the prompt “an image
    of a person”. Figure created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: '*This article was originally published* [*on artfish intelligence*](https://www.artfish.ai/p/lost-in-dalle3-translation)'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenAI recently launched [DALL-E 3](https://openai.com/blog/dall-e-3-is-now-available-in-chatgpt-plus-and-enterprise),
    the latest in their line of AI image generation models.
  prefs: []
  type: TYPE_NORMAL
- en: But as [recent media coverage](https://restofworld.org/2023/ai-image-stereotypes/)
    and [research](https://arxiv.org/abs/2303.11408) reveal, these AI models come
    with the baggage of biases and stereotypes. For example, AI image generation models
    such as Stable Diffusion and Midjourney tend to amplify existing stereotypes about
    [race, gender](https://www.bloomberg.com/graphics/2023-generative-ai-bias/), and
    [national identity](https://restofworld.org/2023/ai-image-stereotypes/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Most of these studies, however, primarily test the models using English prompts.
    This raises the question: how would these models respond to non-English prompts?'
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I delve into DALL-E 3’s behavior with prompts from diverse
    languages. Drawing from the themes of my [previous works](https://www.artfish.ai/p/all-languages-are-not-created-tokenized),
    I offer a multilingual perspective on the newest AI image generation model.
  prefs: []
  type: TYPE_NORMAL
- en: 'How DALL-E 3 works: Prompt Transformations'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unlike previous AI image generation models, this newest version of the DALL-E
    model does not directly generate what you type in. Instead, DALL-E 3 incorporates
    **automatic prompt transformations**, meaning that it **transforms your original
    prompt into a different, more descriptive version.**
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4c9c7a5c926c6f1072f4cc24756bc519.png)'
  prefs: []
  type: TYPE_IMG
- en: 'An example of prompt transformation from OpenAI’s paper detailing the caption
    improvement process: [Improving Image Generation with Better Captions.](https://cdn.openai.com/papers/dall-e-3.pdf)
    Figure created by the author.'
  prefs: []
  type: TYPE_NORMAL
- en: 'According to the [DALL-E 3 System Card](https://cdn.openai.com/papers/DALL_E_3_System_Card.pdf),
    there were a few reasons for doing this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Improving captions](https://cdn.openai.com/papers/dall-e-3.pdf) to be more
    descriptive'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removing public figure names
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specifying more diverse descriptions of generated people (e.g. before prompt
    transformations, generated people tended to be primarily white, young, and female)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, the image generation process looks something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: You type your prompt into DALL-E 3 (available through ChatGPT Plus)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Your prompt is modified under the hood into four different transformed prompts
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: DALL-E 3 generates an image based off of each of the transformed prompts
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Adding this sort of prompt transformation is fairly new to the world of image
    generation. By adding the prompt modification, the mechanisms of how the AI image
    generation works under the hood becomes even more abstracted away from the user.
  prefs: []
  type: TYPE_NORMAL
- en: Prompt Transformations in multiple languages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most research studying biases in text-to-image AI models focus on using English
    prompts. However, little is known these models’ behavior when prompted in non-English
    languages. Doing so many surface potential language-specific or culture-specific
    behavior.
  prefs: []
  type: TYPE_NORMAL
- en: 'I asked DALL-E 3 to generate images using the following English prompts:'
  prefs: []
  type: TYPE_NORMAL
- en: '`“An image of a man”`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`“An image of a woman”`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`“An image of a person”`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'I used GPT-4 (without DALL-E 3) to translate the phrases into the following
    languages: Korean, Mandarin, Burmese, Armenian, and Zulu.'
  prefs: []
  type: TYPE_NORMAL
- en: Then, I used DALL-E 3 to generate 20 images per language, resulting in 120 images
    per prompt across the 6 languages. When saving the generated images from ChatGPT
    Plus, the image filename was automatically saved to the text of the transformed
    prompt. In the rest of the article, I analyze these transformed prompts.
  prefs: []
  type: TYPE_NORMAL
- en: Metadata extraction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**In my prompts, I never specified a particular culture, ethnicity, or age.
    However, the transformed prompt often included such indicators.**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d2459894e4b05407a82361010ad61273.png)'
  prefs: []
  type: TYPE_IMG
- en: An example of a prompt transformation, annotated with which part of the sentence
    refers to art style, age, ethnicity, and gender. Figure created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: From the transformed prompt, I extracted metadata such as art style (“illustration”),
    age (“middle-aged”), ethnicity (“African”), and gender identifier (“woman”). 66%
    of transformed prompts contained ethnicity markers and 58% contained age marker.
  prefs: []
  type: TYPE_NORMAL
- en: 'Observation 1: All prompts are transformed into English'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: No matter what language the original prompt was in, **the modified prompt was
    always transformed into English.**
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/29436cd49b2e1e5781cf262778b89f49.png)'
  prefs: []
  type: TYPE_IMG
- en: A screenshot of ChatGPT Plus showing an example of the original Korean prompt
    for “An image of a person” modified into four distinct prompt transformations
    in English. Figure created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: I found this behavior surprising — while I was expecting the prompt to be transformed
    into a more descriptive one, I was not expecting translation into English to also
    occur.
  prefs: []
  type: TYPE_NORMAL
- en: The majority of AI generation models, such as Stable Diffusion and Midjourney,
    are primarily trained and tested in English. In general, these models tend to
    have lower performance when [generating images from non-English prompts](https://philippstelzel.medium.com/midjourney-tested-in-foreign-languages-ac60053bcadb#:~:text=Midjourney%20understands%20commands%20in%20other,does%20not%20really%20understand%20languages.),
    leading to some users translating their prompts from their native language into
    English. However, doing risks losing the nuance of that native language.
  prefs: []
  type: TYPE_NORMAL
- en: However, to my knowledge, none of these other models automatically translate
    all prompts into English. Adding this additional step of translation under-the-hood
    (and, I’m sure, unbeknownst to most users, as it is not explicitly explained when
    using the tool) adds more opacity to an already black-box tool.
  prefs: []
  type: TYPE_NORMAL
- en: 'Observation 2: The language of the original prompt affects the modified prompt'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The prompt transformation step also seemed to incorporate unspecified metadata
    about the language of the original prompt.
  prefs: []
  type: TYPE_NORMAL
- en: For example, when the original prompt was in Burmese, **even though the prompt
    did not mention anything about the Burmese language or people, the prompt transformation
    often mentioned a Burmese person**
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/12aab49db6dd37d2a306c42a4ffa98ae.png)'
  prefs: []
  type: TYPE_IMG
- en: An example of a prompt in Burmese for “image of a man” which is transformed
    by DALL-E 3 into a descriptive prompt about a Burmese man. Figure created by the
    author.
  prefs: []
  type: TYPE_NORMAL
- en: This was not the case for all languages and the results varied per language.
    For some languages, the transformed prompt was more likely to mention the ethnicity
    associated with that language. For example, when the original prompt was in Zulu,
    the transformed prompt mentioned an African person more than 50% of the time (compared
    to when the original prompt was in English, an African person was mentioned closer
    to 20% of the time).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bd34cfcb30908c2b795085f07a1a7437.png)'
  prefs: []
  type: TYPE_IMG
- en: Percentages of ethnicity generated by DALL-E 3 for all combined prompts (image
    of a person/man/woman), for each language. Figure created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: I do not aim to pass value judgment on whether this behavior is right or wrong,
    nor am I prescribing what should be an expected behavior. Regardless, I found
    it interesting that DALL-E 3’s behavior varied so much across the original prompt
    language. For example, when the original prompt was in Korean, there were no mentions
    of Korean people in DALL-E 3’s prompt transformations. Similarly, when the original
    prompt was in English, there were no mentions of British people in DALL-E 3’s
    prompt transformations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Observation 3: Even with neutral prompts, DALL-E 3 generates gendered prompts'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I mapped the person identifier nouns in DALL-E 3’s prompt transformations to
    one of three buckets: female, male, or neutral:'
  prefs: []
  type: TYPE_NORMAL
- en: woman, girl, lady → “female”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: man, boy, male doctor → “male”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: athlete, child, teenager, individual, person, people → “neutral”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, I compared the original prompt (“person/man/woman”) to the transformed
    prompt (“neutral/male/female”):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/66fdabc135a54d44548eb5a18fe9b3de.png)'
  prefs: []
  type: TYPE_IMG
- en: Given the original prompt (“An image of a person/man/woman”), the percentage
    of times the transformed prompt contained gendered individuals. Figure created
    by the author.
  prefs: []
  type: TYPE_NORMAL
- en: It is no surprise that the original prompt of “an image of a man” resulted in
    mostly male identifiers (and same for women). However, I found it interesting
    that **when using the gender-neutral prompt “An image of a person”, DALL-E 3 transformed
    the prompt to include gendered (e.g. woman, man) terms 75% of the time.** DALL-E
    3 generated transformed prompts including female individuals slightly more often
    (40%) than male individuals (35%). Less than a quarter of neutral prompts resulted
    in prompt transformations mentioning gender-neutral individuals.
  prefs: []
  type: TYPE_NORMAL
- en: 'Observation 4: Women are often described as young, whereas men’s ages are more
    diverse'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes, DALL-E 3 included an age group (young, middle-aged, or elderly) to
    describe the individual in the modified prompt.
  prefs: []
  type: TYPE_NORMAL
- en: '**In instances where the prompt mentioned a female individual, descriptions
    of age tended to skew younger.** Specifically, 35% of transformed prompts described
    female individuals as “young,” which is more than twice the frequency of descriptions
    labeling them as “elderly” (13%), and over four times as often as “middle-aged”
    (7.7%). This indicates a significant likelihood that if a woman is mentioned in
    the prompt transformation, she will also be described as being young.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/149c4db9a254c9ea729b1b47af76ac93.png)'
  prefs: []
  type: TYPE_IMG
- en: The number of transformed prompts that mention age groups, separated by the
    gender of the individual mentioned in the prompt. Figure created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few examples of prompt transformations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: On the other hand, prompt transformations mentioning male individuals showed
    a more balanced distribution across the age groups. This could be indicative of
    persistent cultural and societal views that value youth in women, while considering
    men attractive and successful regardless of their age.
  prefs: []
  type: TYPE_NORMAL
- en: 'Observation 5: Variations in person age depends on original prompt language'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The age group varied depending on the language of the original prompt as well.
    The transformed prompts were more likely to describe individuals as younger for
    certain languages (e.g. Zulu) and less likely for other languages (e.g. Burmese).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/901af2ec26dbbb441e271d60b15bcd95.png)'
  prefs: []
  type: TYPE_IMG
- en: The number of transformed prompts mentioning age groups for all prompts (an
    image of a man/woman/person), separated by the language of the original prompt.
    Figure created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Observation 6: Variations in art style depends on individual gender'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I expected the art style (e.g. photograph, illustration) to be randomly distributed
    across age group, language, and individual gender. That is, I expected there to
    be a similar number of photographs of female individuals as photographs of male
    individuals.
  prefs: []
  type: TYPE_NORMAL
- en: However, this was not the case. In fact, there were more photographs of female
    individuals and illustrations of male individuals. The art style describing an
    individual did *not* seem to be distributed uniformly across genders, but rather,
    seemed to prefer certain genders over others.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/646eebac90d996636122ca0bedaa0474.png)'
  prefs: []
  type: TYPE_IMG
- en: The number of transformed prompts mentioning each art style, separated by the
    gender of the individual mentioned in the prompt. Figure created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Observation 7: Repetition of tropes, from young Asian women to elderly African
    men'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In my experiments, there were 360 unique demographic descriptions in the prompt
    transformations (e.g. age/ethnicity/gender combinations). While many combinations
    only occurred a few times (such as “young Burmese woman” or “elderly European
    man”), certain demographic descriptions appeared more frequently than others.
  prefs: []
  type: TYPE_NORMAL
- en: One common description was “elderly African man”, which appeared 11 times. Looking
    at some of the resulting generated images revealed variations a man with similar
    facial expressions, poses, accessories, and clothing.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5c10e5c348bdd3f9bfbfc4555f07fdcf.png)'
  prefs: []
  type: TYPE_IMG
- en: A subset images whose transformed prompt contained the phrase “elderly African
    man”. Figure created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Even more common was the description “young Asian woman”, which appeared 23
    times. Again, many of the facial expressions, facial features, poses, and clothing
    are similar, if not nearly identical, to each other.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1deb227f818d1f7e9500775d4d0d4a77.png)'
  prefs: []
  type: TYPE_IMG
- en: A subset images whose transformed prompt contained the phrase “young Asian woman”.
    Figure created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: This phenomenon captures the essence of bias that permeates our world. When
    we observe the faces of [Korean K-Pop stars](https://www.rollingstone.com/music/music-news/k-pop-has-so-many-lookalikes-that-its-government-stepped-in-796791/)
    or [Chinese idols](https://zhuanlan.zhihu.com/p/622175815?fbclid=IwAR06YQQjpd5B8ZBOLF1f3rug_3mO4kTQu2bSrPNR1u_DkYRSyK04DtNrfEo),
    there is a striking similarity in their facial structures. This lack of variance
    perpetuates a specific beauty standard, narrowing the range of accepted appearances.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, in the case of AI-generated images, the narrow interpretations of
    demographic descriptions such as “elderly African men” and “young Asian women”
    contribute to harmful stereotypes. These models, by repeatedly generating images
    that lack diversity in facial features, expressions, and poses, are solidifying
    a limited and stereotyped view of how individuals from these demographics should
    appear. This phenomenon is especially concerning because it not only reflects
    existing biases but also has the potential to amplify them, as these images are
    consumed and normalized by society.
  prefs: []
  type: TYPE_NORMAL
- en: But how does DALL-E 3 compare to other image generation models?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I generated images in the 6 languages for the prompt “an image of a person”
    using two other popular text-to-image AI tools: [Midjourney](https://www.midjourney.com/app/)
    and [Stable Diffusion XL](https://stability.ai/stable-diffusion).'
  prefs: []
  type: TYPE_NORMAL
- en: For images generated using Midjourney, non-English prompts were likely to generate
    images of landscapes rather than humans (although, let’s be fair, the English
    images are pretty creepy). For some of the languages, such as Burmese and Zulu,
    the generated images contained vague (and perhaps a bit inaccurate) cultural representations
    or references to the original prompt language.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d4a2a64016e25d8bf5572c3bf89662a9.png)'
  prefs: []
  type: TYPE_IMG
- en: Images generated using [Midjourney](https://www.midjourney.com/app/) in the
    six languages for the prompt “an image of a person”. Figure created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Similar patterns were observed in the images generated using Stable Diffusion
    XL. Non-English prompts were more likely to generate images of landscapes. The
    Armenian prompt only generated what looks like carpet patterns. Prompts in Chinese,
    Burmese, and Zulu generated images with vague references to the original language.
    (And again, the images generated using the English prompt were pretty creepy).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/618e53d060faf2b266b09eb21b30fff3.png)'
  prefs: []
  type: TYPE_IMG
- en: Images generated using [Stable Diffusion XL](https://stability.ai/stable-diffusion)
    in the six languages for the prompt “an image of a person”. I used [Playground
    AI](https://playgroundai.com/) to use the model. Figure created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: In a way, DALL-E 3’s prompt transformations served as a way to artificially
    introduce more variance and diversity into the image generation process. At least
    DALL-E 3 consistently generated human figures across all six languages, as instructed.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion and concluding remarks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Automatic prompt transformations present considerations of their own: they
    may alter the meaning of the prompt, potentially carry inherent biases, and may
    not always align with individual user preferences.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: —* [*DALL-E 3 System Card*](https://cdn.openai.com/papers/DALL_E_3_System_Card.pdf)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In this article, I explored how DALL-E 3 uses prompt transformations to enhance
    the user’s original prompt. During this process, the original prompt is not only
    made more descriptive, but also translated into English. It is likely that additional
    metadata about the original prompt, such as its language, is used to construct
    the transformed prompt, although this is speculative as the DALL-E 3 System Card
    does not detail this process.
  prefs: []
  type: TYPE_NORMAL
- en: My testing of DALL-E 3 spanned six different languages, but it is important
    to note that this is not an exhaustive examination given the hundreds of languages
    spoken worldwide. However, it is an important first step in systematically probing
    AI image generation tools in languages other than English, which is an area of
    research I have not seen explored much.
  prefs: []
  type: TYPE_NORMAL
- en: The prompt transformation step was not transparent to users when accessing DALL-E
    3 via the ChatGPT Plus web app. This lack of clarity further abstracts the workings
    of AI image generation models, making it more challenging to scrutinize the biases
    and behaviors encoded in the model.
  prefs: []
  type: TYPE_NORMAL
- en: However, in comparison to other AI image generation models, DALL-E 3 was *overall*
    *more* *accurate* in following the prompt to generate a person and *overall* *more*
    *diverse* in generating faces of many ethnicities (due to the prompt transformations).
    Therefore, while there might have been limited diversity within certain ethnic
    categories in terms of facial features, the overall outcome was a higher diversity
    (albeit *artificially induced*) in the generated images compared to other models.
  prefs: []
  type: TYPE_NORMAL
- en: I end this article with open questions about what the desired output of AI text-to-image
    models should be. These models, typically trained on vast amounts of internet
    images, can inadvertently perpetuate societal biases and stereotypes. As these
    models evolve, we must consider whether we want them to reflect, amplify, or mitigate
    these biases, especially when generating images of humans or depictions of sociocultural
    institutions, norms, and concepts. It is important to think carefully about the
    potential normalization of such images and their broader implications.
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: DALL-E 3 and ChatGPT are both products that evolve regularly. Even though
    I conducted my experiments a week ago, some of the results found in this article
    may already be outdated or not replicable anymore. This will inevitably happen
    as the models continue to be trained and as the user interface continues to be
    updated. While that is the nature of the AI space at this current time, the method
    of probing image generation models across non-English languages is still applicable
    for future studies.*'
  prefs: []
  type: TYPE_NORMAL
- en: If you liked this article, I encourage you to [subscribe to my newsletter](http://artfish.ai/)
    to support my work and read more of my work. Thank you!
  prefs: []
  type: TYPE_NORMAL
