- en: 'Sklearn Tutorial: Module 1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Sklearn教程：第1模块
- en: 原文：[https://towardsdatascience.com/sklearn-tutorial-module-1-f31b3964a3b4](https://towardsdatascience.com/sklearn-tutorial-module-1-f31b3964a3b4)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/sklearn-tutorial-module-1-f31b3964a3b4](https://towardsdatascience.com/sklearn-tutorial-module-1-f31b3964a3b4)
- en: '**I took the official sklearn MOOC tutorial. Here are my takeaways.**'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**我参加了官方的sklearn MOOC教程。以下是我的收获。**'
- en: '[](https://mocquin.medium.com/?source=post_page-----f31b3964a3b4--------------------------------)[![Yoann
    Mocquin](../Images/b30a0f70c56972aabd2bc0a74baa90bb.png)](https://mocquin.medium.com/?source=post_page-----f31b3964a3b4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f31b3964a3b4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f31b3964a3b4--------------------------------)
    [Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----f31b3964a3b4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://mocquin.medium.com/?source=post_page-----f31b3964a3b4--------------------------------)[![Yoann
    Mocquin](../Images/b30a0f70c56972aabd2bc0a74baa90bb.png)](https://mocquin.medium.com/?source=post_page-----f31b3964a3b4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f31b3964a3b4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f31b3964a3b4--------------------------------)
    [Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----f31b3964a3b4--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f31b3964a3b4--------------------------------)
    ·9 min read·Nov 22, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f31b3964a3b4--------------------------------)
    ·9分钟阅读·2023年11月22日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: After years of playing with the Python scientific stack (NumPy, Matplotlib,
    SciPy, Pandas, and Seaborn), it became obvious to me that the next step was scikit-learn,
    or “sklearn”.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在多年使用Python科学计算栈（NumPy、Matplotlib、SciPy、Pandas和Seaborn）后，我意识到下一步就是scikit-learn，或称为“sklearn”。
- en: '![](../Images/8bd6d36b3e9ecfab66a7bc1ed7c91f80.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8bd6d36b3e9ecfab66a7bc1ed7c91f80.png)'
- en: Photo by [Thought Catalog](https://unsplash.com/@thoughtcatalog?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Thought Catalog](https://unsplash.com/@thoughtcatalog?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: But why sklearn ?
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 但为什么选择sklearn？
- en: Among the ML libraries, scikit-learn is the de facto simplest and easiest framework
    to learn ML. It is based on the scientific stack (mostly NumPy), focuses on traditional
    yet powerful algorithms like linear regression/support vector machines/dimensionality
    reductions, and provides lots of tools to build around those algorithms (like
    model evaluation and selection, hyperparameter optimization, data preprocessing,
    and feature selection).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有机器学习库中，scikit-learn无疑是最简单、最易于学习的框架。它基于科学计算栈（主要是NumPy），专注于传统但强大的算法，如线性回归/支持向量机/降维，并提供了许多围绕这些算法构建的工具（如模型评估和选择、超参数优化、数据预处理和特征选择）。
- en: '**But its main advantage is, without a doubt, its documentation and user guide.
    You can literally learn almost everything just from the scikit-learn website,
    with lots of examples.**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**但它的主要优势无疑是其文档和用户指南。你可以仅通过scikit-learn网站学到几乎所有的东西，且有大量示例。**'
- en: Note that other popular frameworks are TensorFlow and PyTorch, but they have
    steeper learning curves and focus on more complex subjects like computer vision
    and neural networks. Since this my first real contact with ML, I figured I’d start
    with sklearn.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，其他流行的框架有TensorFlow和PyTorch，但它们学习曲线更陡峭，并且专注于计算机视觉和神经网络等更复杂的主题。由于这是我第一次真正接触机器学习，我决定从sklearn开始。
- en: I already started reading the documentation a few months ago but was kinda lost
    given its size. While the documentation is huge and very well written, I am not
    sure the best way to learn scikit-learn is to follow through the whole documentation
    one page after another.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我几个月前已经开始阅读文档，但由于其庞大感到有些迷茫。虽然文档内容丰富且写得非常好，但我不确定按照页面逐一学习scikit-learn是否是最好的方法。
- en: The good news, and the thing that triggered my intent to learn scikit-learn
    further, was the start of the “official” MOOC of scikit-learn, created by the
    actual team of scikit-learn.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，激发我进一步学习scikit-learn的原因是scikit-learn的“官方”MOOC的推出，这个MOOC是由scikit-learn的实际团队创建的。
- en: '[](https://www.fun-mooc.fr/fr/cours/machine-learning-python-scikit-learn/?source=post_page-----f31b3964a3b4--------------------------------)
    [## Machine learning in Python with scikit-learn'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.fun-mooc.fr/fr/cours/machine-learning-python-scikit-learn/?source=post_page-----f31b3964a3b4--------------------------------)
    [## 使用scikit-learn进行Python机器学习'
- en: Build predictive models with scikit-learn and gain a practical understanding
    of the strengths and limitations of…
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 构建预测模型，并获得对其优缺点的实际理解……
- en: www.fun-mooc.fr](https://www.fun-mooc.fr/fr/cours/machine-learning-python-scikit-learn/?source=post_page-----f31b3964a3b4--------------------------------)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.fun-mooc.fr](https://www.fun-mooc.fr/fr/cours/machine-learning-python-scikit-learn/?source=post_page-----f31b3964a3b4--------------------------------)'
- en: '**In this series, I will try to summarize what I learned from each of the 6
    modules that compose the MOOC.** This is an excellent exercise for me to practice
    my memory and summarize what I learned, and a good introduction for you if you
    want to get in touch with sklearn.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**在本系列中，我将尝试总结我从组成 MOOC 的 6 个模块中学到的内容。** 这对我来说是一个很好的练习，可以锻炼我的记忆并总结所学内容，同时也是一个很好的入门介绍，如果你想接触
    sklearn 的话。'
- en: Note that the MOOC is free, so if you like what you read below, you should definitely
    subscribe! Note that these posts are my curated vision of the MOOC, which is itself
    just an introduction to scikit-learn.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这个 MOOC 是免费的，所以如果你喜欢下面的内容，绝对应该订阅！请注意，这些帖子是我对 MOOC 的精心整理视角，而 MOOC 本身仅仅是对
    scikit-learn 的介绍。
- en: 'Module 1: Machine Learning Concepts'
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模块 1：机器学习概念
- en: 'This first module focuses on introducing the following notions:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个模块专注于介绍以下概念：
- en: splitting data into train/test set
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据拆分为训练集/测试集
- en: column selector/transformers
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列选择器/转换器
- en: model, pipeline, and the estimator API with the `.fit()`, `.transform`, `.predict()`,
    `.score()` methods
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型、管道和带有 `.fit()`、`.transform`、`.predict()`、`.score()` 方法的估算器 API
- en: cross-validation
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交叉验证
- en: So our program for today is to review those concepts with mostly words and very
    little code. If you want to go further, I strongly recommend heading to the documentation.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们今天的计划是用文字而不是代码来复习这些概念。如果你想进一步了解，我强烈建议你去阅读文档。
- en: Splitting data into train set and test set
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据拆分为训练集和测试集
- en: One of the most important best practices in ML is to split the data into train
    sets and test sets. The idea is that given a fixed-size input data, we are going
    to train the model with a subpart of the whole data — the train set — and test
    its performance on the other part — the test set.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中的一个重要最佳实践是将数据拆分为训练集和测试集。其思路是，给定固定大小的输入数据，我们将用整个数据的一部分——训练集——来训练模型，并在另一部分——测试集——上测试其性能。
- en: 'This method is very important for many reasons: **the whole point of ML and
    models is to be able to guess the output from new, unseen data**. If we use the
    whole data to train the model, we have no other choice than to use the same data
    to test its performance. Obviously, this seems like a biased exercise: of course,
    the model would be able to guess the outputs based on inputs it has already seen,
    all the more since it also had access to the corresponding outputs. This concept
    is also known as **generalization versus memorization**: we want the model to
    generalize (extrapolate outputs for new input data), not just memorize the data
    it was trained with.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法非常重要，原因有很多：**机器学习和模型的全部意义在于能够从新的、未见过的数据中预测输出**。如果我们使用全部数据来训练模型，我们别无选择，只能用相同的数据来测试其性能。显然，这似乎是一个有偏的练习：模型当然能够根据已经见过的输入来猜测输出，更何况它还接触过对应的输出。这个概念也被称为
    **泛化与记忆**：我们希望模型能够泛化（为新的输入数据推断输出），而不仅仅是记住它所训练的数据。
- en: Another reason (actually another way to put this) is to avoid overfitting. Overfitting
    is a very important concept in ML and will be studied more in another module.
    For now, let’s just say that a model “overfits” when it learns too much, too precisely
    the data it is trained with. Having a test set, different from the train set,
    lets us check that the performance of the model is about the same on the train
    set as on the test set.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个原因（实际上，换句话说）是为了避免过拟合。过拟合是机器学习中一个非常重要的概念，会在另一个模块中进一步学习。现在，让我们暂且说，当一个模型对它训练的数据学习得过于精细时，就会发生“过拟合”。拥有一个与训练集不同的测试集，让我们检查模型在训练集和测试集上的性能是否大致相同。
- en: 'To do this, a simple yet important function provided by scikit-learn is `train_test_split`:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，scikit-learn 提供了一个简单但重要的函数 `train_test_split`：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The idea then is to use `data_train` and `target_train` to train our model and
    test its performance on unseen data using `data_test` and `target_test`.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这个思路是使用 `data_train` 和 `target_train` 来训练我们的模型，并使用 `data_test` 和 `target_test`
    来测试模型在未见数据上的表现。
- en: Column transformer/preprocessor
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 列转换器/预处理器
- en: '**Often, the raw input data is not very well formatted and needs some kind
    of preprocessing steps before actually going into a typical model**. For example,
    if the input data contains a categorical column stored as a string column, and
    the model only uses numerical inputs, we need to convert this string column into
    a numerical column (that encodes the same information) for the model to leverage
    the information of this feature.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**通常，原始输入数据格式不是很好，需要进行一些预处理步骤，然后才能进入典型模型**。例如，如果输入数据包含一个以字符串形式存储的分类列，而模型只使用数值输入，我们需要将这个字符串列转换为数值列（编码相同的信息），以便模型能够利用该特征的信息。'
- en: Another typical example is when several numerical features live on very different
    scales and/or units. Models usually benefit from having data with the same scales-
    meaning having more or less the same mean and or variation scale around their
    mean.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个典型的例子是当几个数值特征具有非常不同的尺度和/或单位时。模型通常会从具有相同尺度的数据中受益——即具有或多或少相同的均值和/或围绕其均值的变化尺度。
- en: Once those preprocessing steps are applied, the transformed data is sent to
    the actual model.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦应用了这些预处理步骤，转换后的数据就会被送到实际模型中。
- en: To achieve these preprocessing steps, scikit-learn proposes some useful tools.
    The first are the preprocessing functions (actually stored in classes), that help
    improve the scales of each feature or encode a categorical feature into numerical
    format.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这些预处理步骤，scikit-learn提供了一些有用的工具。第一个是预处理函数（实际上存储在类中），它们有助于改善每个特征的尺度或将分类特征编码为数值格式。
- en: 'Once instantiated, those objects can be used to preprocess the data:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦实例化，这些对象可以用于预处理数据：
- en: '[PRE1]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now let’s review the `ColumnTransformer` class: it allows you to specify the
    mapping between some columns with some preprocessors. The basic example is to
    map numerical columns to a standard scaler and map categorical columns to a one-hot
    encoder. So let''s say we have a list of numerical columns and a list of categorical
    columns, we create a new preprocessor object like this:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们回顾一下`ColumnTransformer`类：它允许你指定一些列与一些预处理器之间的映射。基本的例子是将数值列映射到标准化器，并将分类列映射到独热编码器。所以假设我们有一组数值列和一组分类列，我们可以这样创建一个新的预处理器对象：
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This way, `preprocessor` is now a new preprocessor like `StandardScaler` in
    the sense that it has a fit/transform API. We can use this new preprocessor as
    a global preprocessor for our model, that can be applied directly to the full
    data matrix. Note that the `make_column_transformer` does the same thing, without
    having to specify the names for each preprocessor.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，`preprocessor`现在是一个新的预处理器，就像`StandardScaler`一样，它具有fit/transform API。我们可以将这个新的预处理器作为我们模型的全局预处理器，直接应用于整个数据矩阵。注意，`make_column_transformer`也做了相同的事情，而不需要为每个预处理器指定名称。
- en: 'But what if we don’t know the names of the columns in the data matrix beforehand?
    or what if we don’t want to review all the columns and just make a mapping based
    on their dtypes? For this, we can use the `make_column_selector` helper function,
    that basically creates filters to extract columns for a whole data matrix, to
    map a preprocessor in a `ColumnTransformer`:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果我们事先不知道数据矩阵中列的名称怎么办？或者我们不想查看所有列，而是仅根据它们的数据类型进行映射呢？为此，我们可以使用`make_column_selector`辅助函数，它基本上创建了用于提取整个数据矩阵列的过滤器，以便在`ColumnTransformer`中映射预处理器：
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This way, we created pretty much the same `ColumnTransformer` preprocessor object,
    but with no assumption on the columns' names.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，我们创建了几乎相同的`ColumnTransformer`预处理器对象，但不需要假设列名。
- en: Pipeline
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流水线
- en: 'We now have all the tools to define a pipeline: **a pipeline is basically the
    concatenation of various processors**. Since we already have some preprocessor,
    we just need to add a predictive model, like a linear regression or support vector
    classifier.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们拥有了定义流水线的所有工具：**流水线基本上是各种处理器的串联**。既然我们已经有了一些预处理器，我们只需要添加一个预测模型，比如线性回归或支持向量分类器。
- en: 'For this, I’d recommend using the `Pipeline` constructor:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我建议使用`Pipeline`构造函数：
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The newly created pipeline object, again, exposes the fit/transform API (like
    the preprocessor we saw above, and also like the LinearRegression() instance).
    We can use this to train and test the performance of our model (the pipeline)
    on our splitted data:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 新创建的流水线对象再次暴露了fit/transform API（就像我们上面看到的预处理器一样，也像LinearRegression()实例）。我们可以用它来训练和测试我们模型（流水线）在拆分数据上的表现：
- en: '[PRE5]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Cross-validation
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交叉验证
- en: The final subject I want to introduce for this first module is cross-validation.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我想在这个第一模块中介绍的最终主题是交叉验证。
- en: Remember in the beginning when we split the input data into a train set and
    a test set? Well, the actual split might seem kinda arbitrary. What if, by luck
    or bad luck, the data was split in a particular way that would be advantageous
    or disadvantageous for the performance of the model?
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 还记得一开始我们将输入数据拆分成训练集和测试集吗？实际上，这个拆分可能显得有些任意。如果由于运气好或运气不好，数据以某种特定的方式划分，对模型性能有利或不利，会怎么样？
- en: 'To circumvent this risk, we can use what is called **cross-validation: the
    idea is to split the data in different ways and train and test the model for each
    of them. The overall performance of the model is given by the mean of the performance
    of each split**. For example, the first split will use the first 75% entries to
    train and the last 25% to test the model. Starting over, the second split will
    use the 25%-100% entries to train and the first 25% entries to test. And so on.
    For each split, the model is fitted and tested from the beginning.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为了规避这个风险，我们可以使用所谓的 **交叉验证：其思想是将数据以不同的方式划分，并对每个划分训练和测试模型。模型的总体性能由每个划分性能的平均值给出**。例如，第一个划分将使用前
    75% 的条目进行训练，最后 25% 的条目进行测试。重新开始，第二个划分将使用 25%-100% 的条目进行训练，前 25% 的条目进行测试。依此类推。对于每个划分，模型都从头开始拟合和测试。
- en: '[PRE6]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The output is a dictionary that contains a lot of information, including the
    test-score and model, for each split of the data. Note that there are several
    approaches to split the data, including random split or the most common KFold
    that splits the data into continuous subgroups.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是一个字典，其中包含大量信息，包括每个数据划分的测试分数和模型。请注意，有多种数据划分方法，包括随机划分或最常见的 KFold，将数据划分为连续子组。
- en: Complete working example
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 完整的工作示例
- en: Let’s review all we saw in a full example using the iris toy dataset.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用 iris 玩具数据集回顾一下我们看到的所有内容。
- en: In the example below, we create 5 pipelines based on 5 classification type of
    models, namely logistic regression, decision tree, random forest, support vector,
    and K-nearest neighbors. The idea here is not to understand how each of these
    models works, but rather see the overall process of creating a pipeline that include
    preprocessors and models, and how to compute their performance in a robust way.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们创建了 5 个基于 5 种分类模型的管道，即逻辑回归、决策树、随机森林、支持向量机和 K 最近邻。这里的想法不是了解每个模型如何工作，而是查看创建包含预处理器和模型的管道的整体过程，以及如何以稳健的方式计算它们的性能。
- en: 'Here, instead of using the `Pipeline` constructor that can seem a bit verbose,
    we use the helper function `make_pipeline`. Also, instead of just specifying the
    number of splits for the cross-validation, we explicitely specify the kind of
    folds we want to use: here 10-fold randomized splits.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用辅助函数 `make_pipeline` 代替可能显得有点冗长的 `Pipeline` 构造函数。此外，我们不仅仅指定交叉验证的分割数量，而是明确指定我们希望使用的折叠类型：这里是
    10 折随机分割。
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Takeaway
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重点
- en: 'In this first post, we saw :'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在这第一篇文章中，我们看到：
- en: what it means to **split the data in a training and test sets**, why we do this,
    and how
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这意味着什么 **将数据分为训练集和测试集**，我们为什么要这样做，以及如何做
- en: how to create **column transformer/preprocessor**, that are used to apply transformations
    to the input features
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何创建 **列变换器/预处理器**，用于对输入特征应用转换
- en: the concept of pipeline, which means to concatenate various steps like preprocessor
    and model, in order to create complex models from basic tools
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管道的概念，意味着将各种步骤（如预处理器和模型）连接在一起，以便从基本工具中创建复杂模型
- en: 'and finaly what is cross-validation: why and how we must evaluate our model
    performance in a robust way'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最终，什么是交叉验证：我们为什么以及如何以一种稳健的方式评估模型性能
- en: 'Now, please give this post:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，请给这篇帖子：
- en: 1 clap if it was just ok (meh!)
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果只是一般般，给 1 个掌声（一般般！）
- en: 10 claps if you think it was clearly written (noice!)
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你觉得写得很清楚，给 10 个掌声（很棒！）
- en: 50 claps if it was very clear and interesting (daaaamn!)
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果它非常清楚和有趣，给 50 个掌声（真是太棒了！）
- en: 'You might like some of my other posts, make sure to check them out:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会喜欢我的一些其他帖子，确保查看它们：
- en: '![Yoann Mocquin](../Images/234a99f243ff3c70fd90170ddde8659d.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![Yoann Mocquin](../Images/234a99f243ff3c70fd90170ddde8659d.png)'
- en: '[Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----f31b3964a3b4--------------------------------)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----f31b3964a3b4--------------------------------)'
- en: Scientific/numerical python
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 科学/数值 Python
- en: '[View list](https://mocquin.medium.com/list/scientificnumerical-python-9ce115122ab6?source=post_page-----f31b3964a3b4--------------------------------)3
    stories![Ironicaly, an array of containers](../Images/4ecd0326a3efdda93947f60872018d41.png)![](../Images/f11076a724463f7b11d819d95bcf0ea4.png)![](../Images/e340b22f444d2bd311537341cf1a105a.png)![Yoann
    Mocquin](../Images/234a99f243ff3c70fd90170ddde8659d.png)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----f31b3964a3b4--------------------------------)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Data science and Machine Learning
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://mocquin.medium.com/list/data-science-and-machine-learning-ba3fb2206051?source=post_page-----f31b3964a3b4--------------------------------)3
    stories![](../Images/c078e74fd67e0141c2b54b82823c78d4.png)![](../Images/79988eda04a078da9373f03d7db51c51.png)![](../Images/6a5966e529bf4ba9b16c592fec7b591a.png)![Yoann
    Mocquin](../Images/234a99f243ff3c70fd90170ddde8659d.png)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----f31b3964a3b4--------------------------------)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: Fourier-transforms for time-series
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://mocquin.medium.com/list/fouriertransforms-for-timeseries-ed423e3f38ad?source=post_page-----f31b3964a3b4--------------------------------)4
    stories![](../Images/86efd63d329650eb9b6d7c33625d6884.png)![](../Images/c693e4e596df5c1a8ef1b0fb3777d7ac.png)![](../Images/b6bc5330fb2d92bc3aad36f5bbc950da.png)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
