["```py\nnode_df = node_df.reset_index()\n\nmerge_df = node_df.reset_index().set_index('Name').rename(\n    columns={'index':'Name1_idx'})\nedge_df = pd.merge(edge_df,merge_df['Name1_idx'],\n                   how='left',left_on='Name1',right_index=True)\n\nmerge_df = merge_df.rename(columns={'Name1_idx':'Name2_idx'})\nedge_df = pd.merge(edge_df,merge_df['Name2_idx'],\n                   how='left',left_on='Name2',right_index=True)\n```", "```py\nimport tensorflow_gnn as tfgnn\n\ngraph_tensor = tfgnn.GraphTensor.from_pieces(\n    node_sets = {\n        \"People\": tfgnn.NodeSet.from_fields(\n            sizes = [len(node_df)],\n            features ={\n                'Age': np.array(node_df['Age'],\n                                dtype='int32').reshape(len(node_df),1)})},\n    edge_sets ={\n        \"Contact\": tfgnn.EdgeSet.from_fields(\n            sizes = [len(edge_df)],\n            features = {\n                'Is-friend': np.array(edge_df['Is-friend'],\n                                      dtype='int32').reshape(len(edge_df),1)},\n            adjacency = tfgnn.Adjacency.from_indices(\n                source = (\"People\", np.array(edge_df['Name1_idx'], dtype='int32')),\n                target = (\"People\", np.array(edge_df['Name2_idx'], dtype='int32'))))\n  })\n```", "```py\ngraph_tensor = tfgnn.GraphTensor.from_pieces(\n    context_spec = tfgnn.ContextSpec.from_field_specs(\n        features_spec ={\n            \"score\": [[0.84]]\n        }),\n    node_sets = {\n        \"People\": tfgnn.NodeSet.from_fields(\n            sizes = [len(node_df)],\n            features ={\n                'Age': np.array(node_df['Age'],\n                                dtype='int32').reshape(len(node_df),1)}),\n        \"Movies\": tfgnn.NodeSet.from_fields(\n            sizes = [len(movie_df)],\n            features ={\n                'Name': np.array(movie_df['Name'],\n                                 dtype='string').reshape(len(movie_df),1),\n                'Length': np.array(movie_df['Length'],\n                                   dtype='float32').reshape(len(movie_df),1)})},\n    edge_sets ={\n        \"Contact\": tfgnn.EdgeSet.from_fields(\n            sizes = [len(edge_df)],\n            features = {\n                'Is-friend': np.array(edge_df['Is-friend'],\n                                      dtype='int32').reshape(len(edge_df),1)},\n            adjacency = tfgnn.Adjacency.from_indices(\n                source = (\"People\", np.array(edge_df['Name1_idx'], dtype='int32')),\n                target = (\"People\", np.array(edge_df['Name2_idx'], dtype='int32')))),\n        'Watched': tfgnn.EdgeSet.from_fields(\n            sizes = [len(watched_df)],\n            features = {},\n            adjacency = tfgnn.Adjacency.from_indices(\n                source = (\"People\", np.array(watched_df['Name_idx'], dtype='int32')),\n                target = (\"Movies\", np.array(watched_df['Movie_idx'], dtype='int32'))))\n  })\n```", "```py\nimport urllib.request\nimport io\nimport zipfile\nimport networkx as nx\n\nurl = \"http://www-personal.umich.edu/~mejn/netdata/football.zip\"\nsock = urllib.request.urlopen(url)  # open URL\ns = io.BytesIO(sock.read())  # read into BytesIO \"file\"\nsock.close()\n\nzf = zipfile.ZipFile(s)  # zipfile object\ntxt = zf.read(\"football.txt\").decode()  # read info file\ngml = zf.read(\"football.gml\").decode()  # read gml data\n# throw away bogus first line with # from mejn files\ngml = gml.split(\"\\n\")[1:]\nG = nx.parse_gml(gml)  # parse gml data\nprint(txt)\n```", "```py\ncmap = {0:'#bd2309', 1:'#bbb12d',2:'#1480fa',3:'#14fa2f',4:'#faf214',\n        5:'#2edfea',6:'#ea2ec4',7:'#ea2e40',8:'#577a4d',9:'#2e46c0',\n        10:'#f59422',11:'#8086d9'}\n\ncolors = [cmap[G.nodes[n]['value']] for n in G.nodes()]\npos = nx.spring_layout(G, seed=1987)\n\nnx.draw_networkx_edges(G, pos, alpha=0.2)\nnx.draw_networkx_nodes(G, pos, nodelist=G.nodes(),\n                       node_color=colors, node_size=100)\n```", "```py\nnode_data = G.nodes(data=True)\nedge_data = G.edges(data=True)\n```", "```py\nnode_df = pd.DataFrame.from_dict(dict(G.nodes(data=True)), orient='index')\nnode_df.index.name = 'school'\nnode_df.columns = ['conference']\n\nedge_df = nx.to_pandas_edgelist(G)\n```", "```py\nfrom sklearn.model_selection import train_test_split\n\nnode_train, node_test = train_test_split(node_df,test_size=0.15,random_state=42)\nedge_train = edge_df.loc[~((edge_df['source'].isin(node_test.index)) | (edge_df['target'].isin(node_test.index)))]\nedge_test = edge_df.loc[(edge_df['source'].isin(node_test.index)) | (edge_df['target'].isin(node_test.index))]\n```", "```py\ndef bidirectional(edge_df):\n    reverse_df = edge_df.rename(columns={'source':'target','target':'source'})\n    reverse_df = reverse_df[edge_df.columns]\n    reverse_df = pd.concat([edge_df, reverse_df], ignore_index=True, axis=0)\n    return reverse_df\n\ndef create_adj_id(node_df,edge_df):\n    node_df = node_df.reset_index().reset_index()\n    edge_df = pd.merge(edge_df,node_df[['school','index']].rename(columns={\"index\":\"source_id\"}),\n                       how='left',left_on='source',right_on='school').drop(columns=['school'])\n    edge_df = pd.merge(edge_df,node_df[['school','index']].rename(columns={\"index\":\"target_id\"}),\n                       how='left',left_on='target',right_on='school').drop(columns=['school'])\n\n    edge_df.dropna(inplace=True)\n    return node_df, edge_df\n\nedge_full_adj = bidirectional(edge_df)\nedge_train_adj = bidirectional(edge_train)\n\nnode_full_adj,edge_full_adj = create_adj_id(node_df,edge_full_adj)\nnode_train_adj,edge_train_adj = create_adj_id(node_train,edge_train_adj)\n```", "```py\ndef create_graph_tensor(node_df,edge_df):\n    graph_tensor = tfgnn.GraphTensor.from_pieces(\n        node_sets = {\n            \"schools\": tfgnn.NodeSet.from_fields(\n                sizes = [len(node_df)],\n                features ={\n                    'Latitude': np.array(node_df['Latitude'], dtype='float32').reshape(len(node_df),1),\n                    'Longitude': np.array(node_df['Longitude'], dtype='float32').reshape(len(node_df),1),\n                    'Rank': np.array(node_df['Rank'], dtype='int32').reshape(len(node_df),1),\n                    'Wins': np.array(node_df['Wins'], dtype='int32').reshape(len(node_df),1),\n                    'Conf_wins': np.array(node_df['Conf_wins'], dtype='int32').reshape(len(node_df),1),\n                    'conference': np.array(node_df.iloc[:,-12:], dtype='int32'),\n                }),\n        },\n        edge_sets ={\n            \"games\": tfgnn.EdgeSet.from_fields(\n                sizes = [len(edge_df)],\n                features = {\n                    'name_sim_score': np.array(edge_df['name_sim_score'], dtype='float32').reshape(len(edge_df),1),\n                    'euclidean_dist': np.array(edge_df['euclidean_dist'], dtype='float32').reshape(len(edge_df),1),\n                    'conference_game': np.array(edge_df['conference_game'], dtype='int32').reshape(len(edge_df),1)\n                },\n                adjacency = tfgnn.Adjacency.from_indices(\n                    source = (\"schools\", np.array(edge_df['source_id'], dtype='int32')),\n                    target = (\"schools\", np.array(edge_df['target_id'], dtype='int32')),\n                )),\n        })\n    return graph_tensor\n\nfull_tensor = create_graph_tensor(node_full_adj,edge_full_adj)\ntrain_tensor = create_graph_tensor(node_train_adj,edge_train_adj)\n```", "```py\ndef node_batch_merge(graph):\n    graph = graph.merge_batch_to_components()\n    node_features = graph.node_sets['schools'].get_features_dict()\n    edge_features = graph.edge_sets['games'].get_features_dict()\n\n    label = node_features.pop('conference')\n    _ = edge_features.pop('conference_game')\n\n    new_graph = graph.replace_features(\n        node_sets={'schools':node_features},\n        edge_sets={'games':edge_features})\n    return new_graph, label\n```", "```py\ndef edge_batch_merge(graph):\n    graph = graph.merge_batch_to_components()\n    node_features = graph.node_sets['schools'].get_features_dict()\n    edge_features = graph.edge_sets['games'].get_features_dict()\n\n    _ = node_features.pop('conference')\n    label = edge_features.pop('conference_game')\n\n    new_graph = graph.replace_features(\n        node_sets={'schools':node_features},\n        edge_sets={'games':edge_features})\n    return new_graph, label\n```", "```py\ndef create_dataset(graph,function):\n    dataset = tf.data.Dataset.from_tensors(graph)\n    dataset = dataset.batch(32)\n    return dataset.map(function)\n\n#Node Datasets\nfull_node_dataset = create_dataset(full_tensor,node_batch_merge)\ntrain_node_dataset = create_dataset(train_tensor,node_batch_merge)\n\n#Edge Datasets\nfull_edge_dataset = create_dataset(full_tensor,edge_batch_merge)\ntrain_edge_dataset = create_dataset(train_tensor,edge_batch_merge)\n```", "```py\ngraph_spec = train_node_dataset.element_spec[0]\ninput_graph = tf.keras.layers.Input(type_spec=graph_spec)\n```", "```py\ndef set_initial_node_state(node_set, node_set_name):\n    features = [\n        tf.keras.layers.Dense(32,activation=\"relu\")(node_set['Latitude']),\n        tf.keras.layers.Dense(32,activation=\"relu\")(node_set['Longitude']),\n        tf.keras.layers.Dense(32,activation=\"relu\")(node_set['Rank']),\n        tf.keras.layers.Dense(32,activation=\"relu\")(node_set['Wins']),\n        tf.keras.layers.Dense(32,activation=\"relu\")(node_set['Conf_wins'])\n    ]\n    return tf.keras.layers.Concatenate()(features)\n\ndef set_initial_edge_state(edge_set, edge_set_name):\n    features = [\n        tf.keras.layers.Dense(32,activation=\"relu\")(edge_set['name_sim_score']),\n        tf.keras.layers.Dense(32,activation=\"relu\")(edge_set['euclidean_dist'])\n    ]\n    return tf.keras.layers.Concatenate()(features)\n\ngraph = tfgnn.keras.layers.MapFeatures(\n    node_sets_fn=set_initial_node_state,\n    edge_sets_fn=set_initial_edge_state\n)(input_graph)\n```", "```py\n# Examples, do not use for this problem\ndef set_initial_node_state(node_set, node_set_name):\n    if node_set_name == \"node_1\":\n        return tf.keras.layers.Embedding(115,3)(node_set['id'])\n    elif node_set_name == \"node_2\":\n        return tfgnn.keras.layers.MakeEmptyFeature()(node_set)\n\ngraph = tfgnn.keras.layers.MapFeatures(\n    node_sets_fn=set_initial_node_state)(input_graph)\n```", "```py\ndef dense_layer(self,units=64,l2_reg=0.1,dropout=0.25,activation='relu'):\n    regularizer = tf.keras.regularizers.l2(l2_reg)\n    return tf.keras.Sequential([\n        tf.keras.layers.Dense(units,\n                              kernel_regularizer=regularizer,\n                              bias_regularizer=regularizer),\n        tf.keras.layers.Dropout(dropout)])\n```", "```py\ngraph_updates = 3 # tunable parameter\nfor i in range(graph_updates):\n    graph = tfgnn.keras.layers.GraphUpdate(\n        node_sets = {\n            'schools': tfgnn.keras.layers.NodeSetUpdate({\n                'games': tfgnn.keras.layers.SimpleConv(\n                    message_fn = dense_layer(32),\n                    reduce_type=\"sum\",\n                    sender_edge_feature = tfgnn.HIDDEN_STATE,\n                    receiver_tag=tfgnn.TARGET)},\n                tfgnn.keras.layers.NextStateFromConcat(\n                    dense_layer(64)))})(graph) #start here\n\n    logits = tf.keras.layers.Dense(12,activation='softmax')(graph.node_sets[\"schools\"][tfgnn.HIDDEN_STATE])\n\nnode_model = tf.keras.Model(input_graph, logits)\n```", "```py\nnode_model.compile(\n    tf.keras.optimizers.Adam(learning_rate=0.01),\n    loss = 'categorical_crossentropy',\n    metrics = ['categorical_accuracy']\n)\n\nnode_model.summary()\n```", "```py\nes = tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss',mode='min',verbose=1,\n        patience=10,restore_best_weights=True)\n\nnode_model.fit(train_node_dataset.repeat(),\n               validation_data=full_node_dataset,\n               steps_per_epoch=10,\n               epochs=1000,\n               callbacks=[es])\n```", "```py\ndef evaluate_node():\n    ### Add raw prediction ####\n    yhat = node_model.predict(full_node_dataset)\n    yhat_df = node_full_adj.set_index('school').iloc[:,-12:].copy()\n    yhat_df.iloc[:,:] = yhat\n\n    ### Classify max of softmax output ###\n    yhat_df = yhat_df.apply(lambda x: x == x.max(), axis=1).astype(int)\n\n    ### Merge output back to single column ###\n    yhat_df = yhat_df.dot(yhat_df.columns).to_frame().rename(columns={0:'conf_yhat'})\n    yhat_df = yhat_df['conf_yhat'].str.replace('conf_', '').astype(int).to_frame()\n    yhat_df['conf_actual'] = node_full_adj['conference']\n\n    ### Filter down to test nodes ###\n    yhat_df = yhat_df.loc[yhat_df.index.isin(params['testset'].index)]\n\n    ### Calculate accuracy ###\n    yhat_df['Accuracy'] = yhat_df['conf_yhat']==yhat_df['conf_actual']\n    return yhat_df['Accuracy'].mean()\n```", "```py\n### Change to train_edge_dataset ###\ngraph_spec = train_edge_dataset.element_spec[0]\ninput_graph = tf.keras.layers.Input(type_spec=graph_spec)\ngraph = tfgnn.keras.layers.MapFeatures(\n    node_sets_fn=set_initial_node_state,\n    edge_sets_fn=set_initial_edge_state\n)(input_graph)\n```", "```py\ngraph_updates = 3\nfor i in range(graph_updates):\n    graph = tfgnn.keras.layers.GraphUpdate(\n        edge_sets = {'games': tfgnn.keras.layers.EdgeSetUpdate(\n            next_state = tfgnn.keras.layers.NextStateFromConcat(\n                dense_layer(64,activation='relu')))},\n        node_sets = {\n            'schools': tfgnn.keras.layers.NodeSetUpdate({\n                'games': tfgnn.keras.layers.Pool(\n                    tag=tfgnn.TARGET,\n                    reduce_type=\"sum\",\n                    feature_name = tfgnn.HIDDEN_STATE)},\n                tfgnn.keras.layers.NextStateFromConcat(\n                    dense_layer(64)))})(graph)\n\n    logits = tf.keras.layers.Dense(1,activation='sigmoid')(graph.edge_sets['games'][tfgnn.HIDDEN_STATE])\n\nedge_model = tf.keras.Model(input_graph, logits)\n```", "```py\nedge_model.compile(\n    tf.keras.optimizers.Adam(learning_rate=0.01),\n    loss = 'binary_crossentropy',\n    metrics = ['Accuracy']\n)\n\nedge_model.summary()\n```", "```py\nedge_model.fit(train_edge_dataset.repeat(),\n               validation_data=full_edge_dataset,\n               steps_per_epoch=10,\n               epochs=1000,\n               callbacks=[es])\n\nyhat = edge_model.predict(full_edge_dataset)\nyhat_df = edge_full_adj.copy().set_index(['source','target'])\nyhat_df['conf_game_yhat'] = yhat.round(0)\nyhat_df = yhat_df.loc[yhat_df.index.isin(\n    edge_test.set_index(['source','target']).index)]\nyhat_df['loss'] = abs(yhat_df['conference_game'] - yhat_df['conf_game_yhat'])\nloss = yhat_df['loss'].mean()\nprint(\"edge accuracy:\",1 - loss)\n```", "```py\ngraph_tensor = tfgnn.GraphTensor.from_pieces(\n    context = tfgnn.Context.from_fields(\n        features ={\n            <context_feature>\n        }),\n    node_sets = {\n        ...\n```", "```py\ndef node_batch_merge(graph):\n    graph = graph.merge_batch_to_components()\n    context_features = graph.context.get_features_dict()\n    label = context_features.pop('<context_feature>')\n    new_graph = graph.replace_features(\n        context=context_features)\n    return new_graph, label\n```", "```py\ndef set_initial_context_state(context):\n    return tf.keras.layers.Dense(32,activation=\"relu\")(context['<context_feature>'])\n\ngraph = tfgnn.keras.layers.MapFeatures(\n    context_fn=set_initial_context_state,\n    node_sets_fn=set_initial_node_state,\n    edge_sets_fn=set_initial_edge_state\n)(input_graph)\n```", "```py\ngraph = tfgnn.keras.layers.GraphUpdate(\n    node_sets ={...},\n    context = tfgnn.keras.layers.ContextUpdate({\n        'schools': tfgnn.keras.layers.Pool(tfgnn.CONTEXT, \"mean\")},\n        tfgnn.keras.layers.NextStateFromConcat(tf.keras.layers.Dense(128))))\n```", "```py\nlogits = tfgnn.keras.layers.Pool(tfgnn.CONTEXT, \"mean\",\n                                 node_set_name=\"schools\")(graph)\n```", "```py\ngraph_spec = tfgnn.GraphTensorSpec.from_piece_specs(\n    context_spec = tfgnn.ContextSpec.from_field_specs(\n        features_spec ={\n            #Added as an example for context problems\n            #\"conf_rank\": tf.TensorSpec(shape=(None,1), dtype=tf.float32),\n        }),\n    node_sets_spec={\n        'schools':\n            tfgnn.NodeSetSpec.from_field_specs(\n                features_spec={\n                    'Latitude': tf.TensorSpec((None, 1), tf.float32),\n                    'Longitude': tf.TensorSpec((None, 1), tf.float32),\n                    'Rank': tf.TensorSpec((None, 1), tf.int32),\n                    'Wins': tf.TensorSpec((None, 1), tf.int32),\n                    'Conf_wins': tf.TensorSpec((None, 1), tf.int32),\n                    'conference': tf.TensorSpec((None, 12), tf.int32)\n                },\n                sizes_spec=tf.TensorSpec((1,), tf.int32))\n    },\n    edge_sets_spec={\n        'games':\n            tfgnn.EdgeSetSpec.from_field_specs(\n                features_spec={\n                    'name_sim_score': tf.TensorSpec((None, 1), tf.float32),\n                    'euclidean_dist': tf.TensorSpec((None, 1), tf.float32),\n                    'conference_game': tf.TensorSpec((None, 1), tf.int32)\n                },\n                sizes_spec=tf.TensorSpec((1,), tf.int32),\n                adjacency_spec=tfgnn.AdjacencySpec.from_incident_node_sets(\n                    'schools', 'schools'))\n    })\n```", "```py\ngraph_spec.is_compatible_with(full_tensor)\n```", "```py\nrandom_graph = tfgnn.random_graph_tensor(graph_spec)\n```", "```py\nprint(\"Nodes:\",random_graph.node_sets['schools'].features)\nprint(\"Edges:\",random_graph.edge_sets['games'].features)\nprint(\"Context:\",random_graph.context.features)\n```", "```py\nclass GCNN:\n    def __init__(self,params):\n        self.params = params\n\n    def set_initial_node_state(self, node_set, node_set_name):\n        features = [\n            tf.keras.layers.Dense(self.params['feature_dim'],activation=\"relu\")(node_set['Latitude']),\n            tf.keras.layers.Dense(self.params['feature_dim'],activation=\"relu\")(node_set['Longitude']),\n            tf.keras.layers.Dense(self.params['feature_dim'],activation=\"relu\")(node_set['Rank']),\n            tf.keras.layers.Dense(self.params['feature_dim'],activation=\"relu\")(node_set['Wins']),\n            tf.keras.layers.Dense(self.params['feature_dim'],activation=\"relu\")(node_set['Conf_wins'])\n        ]\n        return tf.keras.layers.Concatenate()(features)\n\n    def set_initial_edge_state(self, edge_set, edge_set_name):\n        features = [\n            tf.keras.layers.Dense(self.params['feature_dim'],activation=\"relu\")(edge_set['name_sim_score']),\n            tf.keras.layers.Dense(self.params['feature_dim'],activation=\"relu\")(edge_set['euclidean_dist'])\n        ]\n        return tf.keras.layers.Concatenate()(features)\n\n    def dense_layer(self,units=64):\n        regularizer = tf.keras.regularizers.l2(self.params['l2_reg'])\n        return tf.keras.Sequential([\n            tf.keras.layers.Dense(units,\n                                  kernel_regularizer=regularizer,\n                                  bias_regularizer=regularizer,\n                                  activation='relu'),\n            tf.keras.layers.Dropout(self.params['dropout'])])\n\n    def build_model(self):\n        input_graph = tf.keras.layers.Input(type_spec=self.params['trainset'].element_spec[0])\n        graph = tfgnn.keras.layers.MapFeatures(\n            node_sets_fn=self.set_initial_node_state,\n            edge_sets_fn=self.set_initial_edge_state\n        )(input_graph)\n\n        if self.params['loss']=='categorical_crossentropy':\n            for i in range(self.params['graph_updates']):\n                graph = tfgnn.keras.layers.GraphUpdate(\n                    node_sets = {\n                        'schools': tfgnn.keras.layers.NodeSetUpdate({\n                            'games': tfgnn.keras.layers.SimpleConv(\n                                message_fn = self.dense_layer(self.params['message_dim']),\n                                reduce_type=\"sum\",\n                                receiver_tag=tfgnn.TARGET)},\n                            tfgnn.keras.layers.NextStateFromConcat(\n                                self.dense_layer(self.params['next_state_dim'])))})(graph)\n            logits = tf.keras.layers.Dense(12,activation='softmax')(graph.node_sets['schools'][tfgnn.HIDDEN_STATE])\n        else:\n            for i in range(self.params['graph_updates']):\n                graph = tfgnn.keras.layers.GraphUpdate(\n                    edge_sets = {'games': tfgnn.keras.layers.EdgeSetUpdate(\n                        next_state = tfgnn.keras.layers.NextStateFromConcat(\n                            self.dense_layer(self.params['next_state_dim'])))},\n                    node_sets = {\n                        'schools': tfgnn.keras.layers.NodeSetUpdate({\n                            'games': tfgnn.keras.layers.SimpleConv(\n                                message_fn = self.dense_layer(self.params['message_dim']),\n                                reduce_type=\"sum\",\n                                receiver_tag=tfgnn.TARGET)},\n                            tfgnn.keras.layers.NextStateFromConcat(\n                                self.dense_layer(self.params['next_state_dim'])))})(graph)\n            logits = tf.keras.layers.Dense(1,activation='sigmoid')(graph.edge_sets['games'][tfgnn.HIDDEN_STATE])\n        return tf.keras.Model(input_graph, logits)\n\n    def train_model(self,trial=True):\n        model = self.build_model()\n\n        model.compile(tf.keras.optimizers.Adam(learning_rate=self.params['learning_rate']),\n                      loss=self.params['loss'],\n                      metrics=['Accuracy'])\n\n        callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                      mode='min',\n                                                      verbose=1,\n                                                      patience=self.params['patience'],\n                                                      restore_best_weights=True)]\n\n        model.fit(self.params['trainset'].repeat(),\n                  validation_data=self.params['full_dataset'],\n                  steps_per_epoch=self.params['steps_per_epoch'],\n                  epochs=self.params['epochs'],\n                  verbose=0,\n                  callbacks = callbacks)\n\n        loss = self.evaluate_model(model,trial=trial)\n\n        if trial == True:\n            sys.stdout.flush()\n            hypt_params = {\n                'graph_updates':self.params['graph_updates'],\n                'feature_dim':self.params['feature_dim'],\n                'next_state_dim':self.params['next_state_dim'],\n                'message_dim':self.params['message_dim'],\n                'l2_reg':self.params['l2_reg'],\n                'dropout':self.params['dropout'],\n                'learning_rate':self.params['learning_rate']}\n            print(hypt_params,'loss:',loss)\n            return {'loss': loss, 'status': STATUS_OK}\n        else:\n            print('loss:',loss)\n            return model\n\n    def evaluate_model(self,model,trial=True):\n        if self.params['loss'] == 'categorical_crossentropy':\n            yhat = model.predict(full_node_dataset)\n            yhat_df = node_full_adj.set_index('school').iloc[:,-12:].copy()\n            yhat_df.iloc[:,:] = yhat\n            yhat_df = yhat_df.apply(lambda x: x == x.max(), axis=1).astype(int)\n            yhat_df = yhat_df.dot(yhat_df.columns).to_frame().rename(columns={0:'conf_yhat'})\n            yhat_df = yhat_df['conf_yhat'].str.replace('conf_', '').astype(int).to_frame()\n            yhat_df['conf_actual'] = node_full_adj.set_index('school')['conference']\n            yhat_df = yhat_df.loc[yhat_df.index.isin(node_test.index)]\n            yhat_df['Accuracy'] = yhat_df['conf_yhat']==yhat_df['conf_actual']\n            loss = 1 - yhat_df['Accuracy'].mean()\n        else:\n            yhat = model.predict(full_edge_dataset)\n            yhat_df = edge_full_adj.copy().set_index(['source','target'])\n            yhat_df['conf_game_yhat'] = yhat.round(0)\n            yhat_df = yhat_df.loc[yhat_df.index.isin(\n                edge_test.set_index(['source','target']).index)]\n            yhat_df['loss'] = abs(yhat_df['conference_game'] - yhat_df['conf_game_yhat'])\n            loss = yhat_df['loss'].mean()\n        return loss\n```", "```py\nparams = {\n    ### Tuning parameters ###\n    'graph_updates': hp.choice('graph_updates',[2,3,4]),\n    'feature_dim': hp.choice('feature_dim',[16,32,64,128]),\n    'message_dim': hp.choice('message_dim',[16,32,64,128]),\n    'next_state_dim': hp.choice('next_state_dim',[16,32,64,128]),\n    'l2_reg': hp.uniform('l2_reg',0.0,0.3),\n    'dropout': hp.choice('dropout',[0,0.125,0.25,0.375,0.5]),\n    'learning_rate': hp.uniform('learning_rate',0.0,0.1),\n\n    ### Static parameters ###\n    'loss': 'categorical_crossentropy',\n    'epochs': 1000,\n    'steps_per_epoch':10, ### This could also be a tuned parameter\n    'patience':10,\n    'trainset':train_node_dataset,\n    'full_dataset':full_node_dataset\n}\n```", "```py\nfrom hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n\ndef tune_model(params):\n    return GCNN(params).train_model()\n\nbest = fmin(tune_model, params, algo=tpe.suggest, \n            max_evals=100, trials=Trials())\n```", "```py\n### Perameters from my hyperopt run ###\nbest = {'graph_updates': 4,\n        'feature_dim': 64,\n        'next_state_dim': 32,\n        'message_dim': 128,\n        'l2_reg': 0.095,\n        'dropout': 0,\n        'learning_rate': 0.0025\n}\n\nnode_params = params\nfor param, value in best.items():\n    node_params[param] = value\n\nnode_model = GCNN(node_params).train_model(trial=False)\n```", "```py\nparams['loss'] = 'binary_crossentropy'\nparams['trainset'] = train_edge_dataset\nparams['full_dataset'] = full_edge_dataset\n\nbest = fmin(tune_model, params, algo=tpe.suggest, \n            max_evals=100, trials=Trials())\n```", "```py\n### Perameters from my hyperopt run ###\nbest = {'graph_updates': 4,\n        'feature_dim': 64,\n        'next_state_dim': 32,\n        'message_dim': 128,\n        'l2_reg': 0.095,\n        'dropout': 0,\n        'learning_rate': 0.0025\n}\n\nedge_params = params\nfor param, value in best.items():\n    edge_params[param] = value\n\nedge_model = GCNN(edge_params).train_model(trial=False)\n```"]