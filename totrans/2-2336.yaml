- en: 'What Is Learning to Rank: A Beginner’s Guide to Learning to Rank Methods'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/what-is-learning-to-rank-a-beginners-guide-to-learning-to-rank-methods-23bbb99ef38c](https://towardsdatascience.com/what-is-learning-to-rank-a-beginners-guide-to-learning-to-rank-methods-23bbb99ef38c)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A guide on how to approach LTR problems in Machine Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://ransakaravihara.medium.com/?source=post_page-----23bbb99ef38c--------------------------------)[![Ransaka
    Ravihara](../Images/ac09746938c10ad8f157d46ea0de27ca.png)](https://ransakaravihara.medium.com/?source=post_page-----23bbb99ef38c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----23bbb99ef38c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----23bbb99ef38c--------------------------------)
    [Ransaka Ravihara](https://ransakaravihara.medium.com/?source=post_page-----23bbb99ef38c--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----23bbb99ef38c--------------------------------)
    ·7 min read·Jan 17, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/456cdb5d1bd66cb4e9b4db863ebc6e2e.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by Possessed Photography on Unsplash
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This article will discuss what exactly a Learning to Rank is. Before diving
    deep into the inner workings, let’s quickly catch up on the basic concepts required
    to understand.
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s discover the Learning to Rank’s central intuition. In machine learning,
    Learning to Rank (LTR) belongs to supervised machine learning, where we need a
    historical dataset to train the model. But when I started learning about the Learning
    to Rank concept, my first confusion was how I discriminated between traditional
    machine learning and LTR. Because if we are building a classification or regression
    model, our dependent and independent variables are pretty simple and make more
    sense. If we need to predict loan default for the given customer, we must plug
    specific feature vectors into the model learned function *f(x).* It will return
    a single value or class probability for the customer being defaulted. But in the
    Learning to Rank model, this is quite different and confusing.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a simple example.
  prefs: []
  type: TYPE_NORMAL
- en: User *A* navigates to a website and inputs a query *q.* In this scenario, our
    system returned some documents, in other words, search results, like the one below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9d911ca7509a46afd36433e96969ece6.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: If we have a good ranking model, the relevance *(r)* of these results should
    be *r(d1) > r(d2) > r(d3).* Behind the scene, our model should return the relevance
    score for each document related to this query. Hence our model should learn a
    function that takes the query and document as a parameter and produce the relevance
    score for that particular query-document pair. Then we can do some computations
    and sort the documents in such a way high relevant documents receive a higher
    rank.
  prefs: []
  type: TYPE_NORMAL
- en: Pointwise Ranking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s discuss the one way that we can achieve this. First thing first, we need
    data. For simplicity, assume a hypothetical scenario where we have two queries,
    *q1, q2,* and their associated list of documents [*d1,d2,d3], [d5,d6,d7],* respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9c8e1368802e9d79c34ff6bce3ed168a.png)![](../Images/40b4d1ab11536a7e205fcfcbe0e4c511.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Generally, we know that *d1,d2,* and *d3* documents are relevant for *q1* but
    not *q2,* and the other way around. So we can populate the sample as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '*sample 1 : d1,q1; label :1'
  prefs: []
  type: TYPE_NORMAL
- en: 'sample 2 : d2,q1; label :1'
  prefs: []
  type: TYPE_NORMAL
- en: 'sample 3 : d3,q1; label :1'
  prefs: []
  type: TYPE_NORMAL
- en: 'sample 4 : d4,q2; label :1'
  prefs: []
  type: TYPE_NORMAL
- en: 'sample 5: d5,q2; label :1'
  prefs: []
  type: TYPE_NORMAL
- en: 'sample 6: d6,q2; label :1*'
  prefs: []
  type: TYPE_NORMAL
- en: If you look at the above data, this problem is now simplified into a traditional
    classification/regression problem where we have a one-to-one mapping between inputs
    (*query* and *document* pair) and *labels.*
  prefs: []
  type: TYPE_NORMAL
- en: Additional Fact
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: To solve this problem using machine learning you may perform feature engineering
    on query data and document data then feed it into the model and finally get predictions.
    Some ideal yet simple feature engineering would be retreving the number of times
    john and sushi appear in the query and document.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Believing or not, just now, you learned one of the three types of Learning to
    Rank methods called ***pointwise ranking***.
  prefs: []
  type: TYPE_NORMAL
- en: The pointwise ranking is finding the function that returns each document’s relevance
    given a query. It is named pointwise because each document is scored independently
    with the ground truth target values, just like traditional regression and classification
    tasks.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let’s discuss the pros and cons of the pointwise ranking method. One advantage
    is its simplicity. But this simplicity comes with significant drawbacks. Such
    as,
  prefs: []
  type: TYPE_NORMAL
- en: Each instance is treated as an isolated point.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Explicit pointwise labels are required to create the training dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To overcome these challenges, we can use the ***Pairwise Ranking*** method.
  prefs: []
  type: TYPE_NORMAL
- en: Pairwise Ranking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here, the goal is to define a ranking function to score each document based
    on a given query. The documents are then ranked in descending order of these scores,
    representing the relative relevance of the documents to the query.
  prefs: []
  type: TYPE_NORMAL
- en: In the learning process, several queries are provided, each with a pair of relevant
    documents. A ranking function is created using this training data so that the
    model can predict the relevant documents for future queries.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let’s take the previous *sushi recipe* example. Instead of considering one document
    for each query, like *pointwise ranking,* we are now considering two documents
    per query. For example, we know *d1,d2,* and *d3* are relevant to *q1\.* In this
    case, all possible query document pairs should be as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '*sample 1: q1, (d1,d2)'
  prefs: []
  type: TYPE_NORMAL
- en: 'sample 2: q1, (d1,d3)'
  prefs: []
  type: TYPE_NORMAL
- en: 'sample 3: q1, (d2,d3)*'
  prefs: []
  type: TYPE_NORMAL
- en: Where *(di,dj)* denotes the order of documents *i* and *j.* If we have explicit
    labels for how documents *i* and *j* should rank, we can derive labels for *(di,dj).*
    Assume document *j* has a relevance score of 3(highly relevant) and document *i*
    have a relevance score of 0 (less relevant) concerning the query *q.* In our optimum
    rankings, document *i* should rank higher than document *j*. Again this is simplified
    as a traditional classification task. But unlike ***pointwise ranking,*** this
    method considers the ranking position.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b935a09bd5d8f19bbb2a26562a897157.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: The pairwise loss function used in lambdarank objective in LightGBM. Using the
    LightGBM python library, we can train this state-of-art LTR method with few lines
    of code.
  prefs: []
  type: TYPE_NORMAL
- en: Since we can simplify this into a classification task, we can use its known
    methodologies. It also takes the document order into the model. This has a few
    drawbacks as well. Even though learning considers the order of document pairs
    objective is not explicitly set to order the document; instead, it tries to reduce
    the classification error of document pairs. Furthermore, training can be very
    costly when the dataset contains large document and query pairs. Document count
    varies from query to query; this lead model is biased towards queries with large
    document pairs.
  prefs: []
  type: TYPE_NORMAL
- en: Listwise Ranking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Researchers have introduced a novel listwise approach to overcome a few of the
    observed significant drawbacks in LTR.
  prefs: []
  type: TYPE_NORMAL
- en: In this approach, instead of considering pairs of documents, the list of ranked
    documents is taken into account, along with their relevance labels.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: To get the relevance label per each document in the query, we can use human
    annotators or the number of clicks received for a particular document.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/45463bf6e8bb01711c5f53a6466f24a0.png)![](../Images/eb7a36a6ef71771a8377e3b38f209906.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: We must add features based on query and document pairs in the learning phase.
    If *i represents the query’s index* and *j* represents the document’s index, we
    can define the feature vector as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2b311b863a90fb3765ebd5be0b43726b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: With that, we can define the features for each document-query pair along with
    the ground truth labels.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f577aff276c78b31a4d995a945c24cc7.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we can denote training instance as,
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9042e9f7454d97dcd166f25485bf3766.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: where *m* is the number of queries in the dataset. Finally, Create a ranking
    function *f*, which outputs a score for each feature vector, *x_ij*. Then obtain
    a list of scores, *z_i,*
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ed3ef4d21694f9be99fe41ff64b30f89.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: The goal of learning is to minimize the total losses with respect to the training
    data. When a ranking applies, we can use a trained function to assign scores to
    new documents based on their feature vectors. The documents are then ranked in
    descending order of the scores.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to this learning process, it can learn relationships between items in
    a list, such as co-occurrence or dependencies. With this plus point, It expects
    a large amount of labeled data to learn the relationships between items in a list;
    thus, It can be computationally expensive to train and optimize. Furthermore,
    listwise can be a problem for new or niche domains with little or no labeled data
    available.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s summarize what we have learned in this article.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/01c7baa01935bca340a3c5770baeb483.png)'
  prefs: []
  type: TYPE_IMG
- en: comparison of LTR methods | Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: '*Next in the Series:* [*How to evaluate a Learning to Rank Model*](https://medium.com/towards-data-science/how-to-evaluate-learning-to-rank-models-d12cadb99d47)'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/how-to-evaluate-learning-to-rank-models-d12cadb99d47?source=post_page-----23bbb99ef38c--------------------------------)
    [## How to evaluate Learning to Rank Models'
  prefs: []
  type: TYPE_NORMAL
- en: A practical guide on how to evaluate LTR models in Machine Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/how-to-evaluate-learning-to-rank-models-d12cadb99d47?source=post_page-----23bbb99ef38c--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for Reading!
  prefs: []
  type: TYPE_NORMAL
- en: '***References:***'
  prefs: []
  type: TYPE_NORMAL
- en: '[*From RankNet to LambdaRank to LambdaMART*](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Learning to Rank: From Pairwise Approach to Listwise Approach*](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2007-40.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
