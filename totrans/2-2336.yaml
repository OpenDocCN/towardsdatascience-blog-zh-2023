- en: 'What Is Learning to Rank: A Beginner’s Guide to Learning to Rank Methods'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是学习排名：学习排名方法的初学者指南
- en: 原文：[https://towardsdatascience.com/what-is-learning-to-rank-a-beginners-guide-to-learning-to-rank-methods-23bbb99ef38c](https://towardsdatascience.com/what-is-learning-to-rank-a-beginners-guide-to-learning-to-rank-methods-23bbb99ef38c)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/what-is-learning-to-rank-a-beginners-guide-to-learning-to-rank-methods-23bbb99ef38c](https://towardsdatascience.com/what-is-learning-to-rank-a-beginners-guide-to-learning-to-rank-methods-23bbb99ef38c)
- en: A guide on how to approach LTR problems in Machine Learning
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于如何处理机器学习中的LTR问题的指南
- en: '[](https://ransakaravihara.medium.com/?source=post_page-----23bbb99ef38c--------------------------------)[![Ransaka
    Ravihara](../Images/ac09746938c10ad8f157d46ea0de27ca.png)](https://ransakaravihara.medium.com/?source=post_page-----23bbb99ef38c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----23bbb99ef38c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----23bbb99ef38c--------------------------------)
    [Ransaka Ravihara](https://ransakaravihara.medium.com/?source=post_page-----23bbb99ef38c--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ransakaravihara.medium.com/?source=post_page-----23bbb99ef38c--------------------------------)[![Ransaka
    Ravihara](../Images/ac09746938c10ad8f157d46ea0de27ca.png)](https://ransakaravihara.medium.com/?source=post_page-----23bbb99ef38c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----23bbb99ef38c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----23bbb99ef38c--------------------------------)
    [Ransaka Ravihara](https://ransakaravihara.medium.com/?source=post_page-----23bbb99ef38c--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----23bbb99ef38c--------------------------------)
    ·7 min read·Jan 17, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----23bbb99ef38c--------------------------------)
    ·7分钟阅读·2023年1月17日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/456cdb5d1bd66cb4e9b4db863ebc6e2e.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/456cdb5d1bd66cb4e9b4db863ebc6e2e.png)'
- en: Photo by Possessed Photography on Unsplash
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于 Possessed Photography，来自 Unsplash
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: This article will discuss what exactly a Learning to Rank is. Before diving
    deep into the inner workings, let’s quickly catch up on the basic concepts required
    to understand.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本文将讨论学习排名究竟是什么。在深入了解内部工作之前，让我们快速了解一下理解所需的基本概念。
- en: First, let’s discover the Learning to Rank’s central intuition. In machine learning,
    Learning to Rank (LTR) belongs to supervised machine learning, where we need a
    historical dataset to train the model. But when I started learning about the Learning
    to Rank concept, my first confusion was how I discriminated between traditional
    machine learning and LTR. Because if we are building a classification or regression
    model, our dependent and independent variables are pretty simple and make more
    sense. If we need to predict loan default for the given customer, we must plug
    specific feature vectors into the model learned function *f(x).* It will return
    a single value or class probability for the customer being defaulted. But in the
    Learning to Rank model, this is quite different and confusing.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们探究学习排名的核心直觉。在机器学习中，学习排名（LTR）属于监督学习，我们需要历史数据集来训练模型。但当我开始了解学习排名的概念时，我的第一个困惑是如何区分传统机器学习和LTR。因为如果我们构建分类或回归模型，我们的因变量和自变量都很简单且更有意义。如果我们需要预测给定客户的贷款违约情况，我们必须将特定的特征向量输入到模型学习的函数
    *f(x)* 中。它会返回客户违约的单一值或类别概率。但在学习排名模型中，这完全不同且令人困惑。
- en: Let’s take a simple example.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们举个简单的例子。
- en: User *A* navigates to a website and inputs a query *q.* In this scenario, our
    system returned some documents, in other words, search results, like the one below.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 用户 *A* 访问一个网站并输入查询 *q*。在这种情况下，我们的系统返回了一些文档，换句话说，就是搜索结果，如下所示。
- en: '![](../Images/9d911ca7509a46afd36433e96969ece6.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9d911ca7509a46afd36433e96969ece6.png)'
- en: Image by Author
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图片作者
- en: If we have a good ranking model, the relevance *(r)* of these results should
    be *r(d1) > r(d2) > r(d3).* Behind the scene, our model should return the relevance
    score for each document related to this query. Hence our model should learn a
    function that takes the query and document as a parameter and produce the relevance
    score for that particular query-document pair. Then we can do some computations
    and sort the documents in such a way high relevant documents receive a higher
    rank.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有一个好的排序模型，这些结果的相关性*(r)*应该是 *r(d1) > r(d2) > r(d3)*。在幕后，我们的模型应该为每个与该查询相关的文档返回相关性分数。因此，我们的模型应该学习一个函数，该函数以查询和文档作为参数，并为特定的查询-文档对生成相关性分数。然后我们可以进行一些计算，并以这种方式对文档进行排序，使得高度相关的文档获得更高的排名。
- en: Pointwise Ranking
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逐点排序
- en: Let’s discuss the one way that we can achieve this. First thing first, we need
    data. For simplicity, assume a hypothetical scenario where we have two queries,
    *q1, q2,* and their associated list of documents [*d1,d2,d3], [d5,d6,d7],* respectively.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一下实现这一点的一种方法。首先，我们需要数据。为了简化，假设一个假设场景，其中我们有两个查询，*q1, q2*，以及它们各自的文档列表 [*d1,d2,d3],
    [d5,d6,d7]*。
- en: '![](../Images/9c8e1368802e9d79c34ff6bce3ed168a.png)![](../Images/40b4d1ab11536a7e205fcfcbe0e4c511.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9c8e1368802e9d79c34ff6bce3ed168a.png)![](../Images/40b4d1ab11536a7e205fcfcbe0e4c511.png)'
- en: Image by Author
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: Generally, we know that *d1,d2,* and *d3* documents are relevant for *q1* but
    not *q2,* and the other way around. So we can populate the sample as follows.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们知道 *d1,d2* 和 *d3* 文档对 *q1* 是相关的，但对 *q2* 不相关，反之亦然。因此我们可以按如下方式填充样本。
- en: '*sample 1 : d1,q1; label :1'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*示例 1: d1,q1; 标签 :1'
- en: 'sample 2 : d2,q1; label :1'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '示例 2: d2,q1; 标签 :1'
- en: 'sample 3 : d3,q1; label :1'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '示例 3: d3,q1; 标签 :1'
- en: 'sample 4 : d4,q2; label :1'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '示例 4: d4,q2; 标签 :1'
- en: 'sample 5: d5,q2; label :1'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '示例 5: d5,q2; 标签 :1'
- en: 'sample 6: d6,q2; label :1*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '示例 6: d6,q2; 标签 :1*'
- en: If you look at the above data, this problem is now simplified into a traditional
    classification/regression problem where we have a one-to-one mapping between inputs
    (*query* and *document* pair) and *labels.*
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看上述数据，这个问题现在被简化为一个传统的分类/回归问题，其中输入（*查询*和*文档*对）与*标签*之间存在一对一的映射关系。
- en: Additional Fact
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 附加信息
- en: ''
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: To solve this problem using machine learning you may perform feature engineering
    on query data and document data then feed it into the model and finally get predictions.
    Some ideal yet simple feature engineering would be retreving the number of times
    john and sushi appear in the query and document.
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 要使用机器学习解决这个问题，你可以对查询数据和文档数据进行特征工程，然后将其输入到模型中，最终得到预测。一些理想且简单的特征工程是获取 john 和 sushi
    在查询和文档中出现的次数。
- en: Believing or not, just now, you learned one of the three types of Learning to
    Rank methods called ***pointwise ranking***.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 信不信由你，你刚刚学会了一种叫做***逐点排序***的学习排序方法。
- en: The pointwise ranking is finding the function that returns each document’s relevance
    given a query. It is named pointwise because each document is scored independently
    with the ground truth target values, just like traditional regression and classification
    tasks.
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 逐点排序是找到一个函数，该函数在给定查询的情况下返回每个文档的相关性。之所以称为逐点排序，是因为每个文档都根据真实目标值独立评分，就像传统的回归和分类任务一样。
- en: Let’s discuss the pros and cons of the pointwise ranking method. One advantage
    is its simplicity. But this simplicity comes with significant drawbacks. Such
    as,
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一下逐点排序方法的优缺点。一方面，它的优点是简单。但这种简单性也带来了显著的缺陷，例如，
- en: Each instance is treated as an isolated point.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个实例被视为一个孤立的点。
- en: Explicit pointwise labels are required to create the training dataset.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显式的逐点标签是创建训练数据集所必需的。
- en: To overcome these challenges, we can use the ***Pairwise Ranking*** method.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这些挑战，我们可以使用***对偶排序***方法。
- en: Pairwise Ranking
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对偶排序
- en: Here, the goal is to define a ranking function to score each document based
    on a given query. The documents are then ranked in descending order of these scores,
    representing the relative relevance of the documents to the query.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，目标是定义一个排序函数，以根据给定的查询对每个文档进行评分。然后将文档按照这些分数的降序排列，表示文档与查询的相对相关性。
- en: In the learning process, several queries are provided, each with a pair of relevant
    documents. A ranking function is created using this training data so that the
    model can predict the relevant documents for future queries.
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在学习过程中，提供多个查询，每个查询都有一对相关文档。使用这些训练数据创建一个排序函数，以便模型可以预测未来查询的相关文档。
- en: Let’s take the previous *sushi recipe* example. Instead of considering one document
    for each query, like *pointwise ranking,* we are now considering two documents
    per query. For example, we know *d1,d2,* and *d3* are relevant to *q1\.* In this
    case, all possible query document pairs should be as follows.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以之前的*sushi recipe* 示例为例。与*点对点排序*方法不同，我们现在考虑每个查询的两个文档。例如，我们知道*d1, d2* 和*d3*
    与*q1*相关。在这种情况下，所有可能的查询文档对应如下。
- en: '*sample 1: q1, (d1,d2)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '*示例 1: q1, (d1,d2)'
- en: 'sample 2: q1, (d1,d3)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '示例 2: q1, (d1,d3)'
- en: 'sample 3: q1, (d2,d3)*'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '示例 3: q1, (d2,d3)*'
- en: Where *(di,dj)* denotes the order of documents *i* and *j.* If we have explicit
    labels for how documents *i* and *j* should rank, we can derive labels for *(di,dj).*
    Assume document *j* has a relevance score of 3(highly relevant) and document *i*
    have a relevance score of 0 (less relevant) concerning the query *q.* In our optimum
    rankings, document *i* should rank higher than document *j*. Again this is simplified
    as a traditional classification task. But unlike ***pointwise ranking,*** this
    method considers the ranking position.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 其中*(di,dj)*表示文档*i*和*j*的顺序。如果我们对文档*i*和*j* 应该如何排序有明确的标签，我们可以推导出*(di,dj)*的标签。假设文档*j*的相关性评分为3（高度相关），而文档*i*的相关性评分为0（较少相关），对于查询*q*。在我们的最佳排名中，文档*i*
    应该排在文档*j* 之前。再次，这被简化为传统的分类任务。但不同于***点对点排序***，这种方法考虑了排名位置。
- en: '![](../Images/b935a09bd5d8f19bbb2a26562a897157.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b935a09bd5d8f19bbb2a26562a897157.png)'
- en: Image by Author
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: The pairwise loss function used in lambdarank objective in LightGBM. Using the
    LightGBM python library, we can train this state-of-art LTR method with few lines
    of code.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在LightGBM的lambdarank目标中使用的成对损失函数。使用LightGBM的Python库，我们可以用几行代码训练这种最先进的LTR方法。
- en: Since we can simplify this into a classification task, we can use its known
    methodologies. It also takes the document order into the model. This has a few
    drawbacks as well. Even though learning considers the order of document pairs
    objective is not explicitly set to order the document; instead, it tries to reduce
    the classification error of document pairs. Furthermore, training can be very
    costly when the dataset contains large document and query pairs. Document count
    varies from query to query; this lead model is biased towards queries with large
    document pairs.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们可以将其简化为分类任务，因此可以使用已知的方法论。它还将文档顺序纳入模型中。这也有一些缺点。尽管学习考虑了文档对的顺序，但目标并没有明确设置为对文档进行排序；相反，它试图减少文档对的分类错误。此外，当数据集中包含大量文档和查询对时，训练可能非常昂贵。文档的数量因查询而异，这导致模型对具有大量文档对的查询存在偏差。
- en: Listwise Ranking
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 列表排序
- en: Researchers have introduced a novel listwise approach to overcome a few of the
    observed significant drawbacks in LTR.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员引入了一种新颖的列表排序方法，以克服LTR中的一些显著缺点。
- en: In this approach, instead of considering pairs of documents, the list of ranked
    documents is taken into account, along with their relevance labels.
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在这种方法中，我们考虑的是文档的排序列表及其相关性标签，而不是文档对。
- en: To get the relevance label per each document in the query, we can use human
    annotators or the number of clicks received for a particular document.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得每个查询中文档的相关性标签，我们可以使用人工标注者或某个文档收到的点击次数。
- en: '![](../Images/45463bf6e8bb01711c5f53a6466f24a0.png)![](../Images/eb7a36a6ef71771a8377e3b38f209906.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/45463bf6e8bb01711c5f53a6466f24a0.png)![](../Images/eb7a36a6ef71771a8377e3b38f209906.png)'
- en: Image by Author
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: We must add features based on query and document pairs in the learning phase.
    If *i represents the query’s index* and *j* represents the document’s index, we
    can define the feature vector as follows.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习阶段，我们必须根据查询和文档对添加特征。如果*i* 代表查询的索引，*j* 代表文档的索引，我们可以定义特征向量如下。
- en: '![](../Images/2b311b863a90fb3765ebd5be0b43726b.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2b311b863a90fb3765ebd5be0b43726b.png)'
- en: Image by Author
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: With that, we can define the features for each document-query pair along with
    the ground truth labels.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，我们可以定义每个文档-查询对的特征以及真实标签。
- en: '![](../Images/f577aff276c78b31a4d995a945c24cc7.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f577aff276c78b31a4d995a945c24cc7.png)'
- en: Image by Author
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Finally, we can denote training instance as,
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以将训练实例表示为，
- en: '![](../Images/9042e9f7454d97dcd166f25485bf3766.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9042e9f7454d97dcd166f25485bf3766.png)'
- en: Image by Author
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: where *m* is the number of queries in the dataset. Finally, Create a ranking
    function *f*, which outputs a score for each feature vector, *x_ij*. Then obtain
    a list of scores, *z_i,*
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *m* 是数据集中查询的数量。最后，创建一个排名函数 *f*，它为每个特征向量 *x_ij* 输出一个分数。然后获取一个分数列表 *z_i*，
- en: '![](../Images/ed3ef4d21694f9be99fe41ff64b30f89.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ed3ef4d21694f9be99fe41ff64b30f89.png)'
- en: Image by Author
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: The goal of learning is to minimize the total losses with respect to the training
    data. When a ranking applies, we can use a trained function to assign scores to
    new documents based on their feature vectors. The documents are then ranked in
    descending order of the scores.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 学习的目标是最小化相对于训练数据的总损失。当应用排名时，我们可以使用训练好的函数根据特征向量给新文档分配分数。然后按分数的降序对文档进行排序。
- en: Thanks to this learning process, it can learn relationships between items in
    a list, such as co-occurrence or dependencies. With this plus point, It expects
    a large amount of labeled data to learn the relationships between items in a list;
    thus, It can be computationally expensive to train and optimize. Furthermore,
    listwise can be a problem for new or niche domains with little or no labeled data
    available.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 得益于这一学习过程，它可以学习列表中项目之间的关系，例如共现或依赖关系。凭借这一优点，它需要大量标记数据来学习列表中项目之间的关系；因此，训练和优化可能会计算量大。此外，listwise
    方法在新领域或标记数据稀缺的细分领域中可能存在问题。
- en: Let’s summarize what we have learned in this article.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一下我们在本文中学到的内容。
- en: '![](../Images/01c7baa01935bca340a3c5770baeb483.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01c7baa01935bca340a3c5770baeb483.png)'
- en: comparison of LTR methods | Image by Author
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: LTR 方法的比较 | 图片来源：作者
- en: '*Next in the Series:* [*How to evaluate a Learning to Rank Model*](https://medium.com/towards-data-science/how-to-evaluate-learning-to-rank-models-d12cadb99d47)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*系列中的下一篇文章：* [*如何评估学习排序模型*](https://medium.com/towards-data-science/how-to-evaluate-learning-to-rank-models-d12cadb99d47)'
- en: '[](/how-to-evaluate-learning-to-rank-models-d12cadb99d47?source=post_page-----23bbb99ef38c--------------------------------)
    [## How to evaluate Learning to Rank Models'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/how-to-evaluate-learning-to-rank-models-d12cadb99d47?source=post_page-----23bbb99ef38c--------------------------------)
    [## 如何评估学习排序模型'
- en: A practical guide on how to evaluate LTR models in Machine Learning
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关于如何评估机器学习中的 LTR 模型的实用指南
- en: towardsdatascience.com](/how-to-evaluate-learning-to-rank-models-d12cadb99d47?source=post_page-----23bbb99ef38c--------------------------------)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/how-to-evaluate-learning-to-rank-models-d12cadb99d47?source=post_page-----23bbb99ef38c--------------------------------)
- en: Thanks for Reading!
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读！
- en: '***References:***'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '***参考文献：***'
- en: '[*From RankNet to LambdaRank to LambdaMART*](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*从 RankNet 到 LambdaRank 再到 LambdaMART*](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf)'
- en: '[*Learning to Rank: From Pairwise Approach to Listwise Approach*](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2007-40.pdf)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*从 RankNet 到 LambdaRank 再到 LambdaMART*](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2007-40.pdf)'
