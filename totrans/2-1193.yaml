- en: How to identify bird species by their songs?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-identify-bird-species-by-their-songs-1a13b2b606ec](https://towardsdatascience.com/how-to-identify-bird-species-by-their-songs-1a13b2b606ec)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A Kick-off for Applying ML on Sounds
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@jacky.kaub?source=post_page-----1a13b2b606ec--------------------------------)[![Jacky
    Kaub](../Images/e66c699ee5a9d5bbd58a1a72d688234a.png)](https://medium.com/@jacky.kaub?source=post_page-----1a13b2b606ec--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1a13b2b606ec--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1a13b2b606ec--------------------------------)
    [Jacky Kaub](https://medium.com/@jacky.kaub?source=post_page-----1a13b2b606ec--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1a13b2b606ec--------------------------------)
    ·10 min read·May 22, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ece658a10d750c0d4ee2d4b907341888.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Jan Meeus](https://unsplash.com/@janmeeus?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Did you know that sounds can be transformed into images to feed standard Convolutional
    Networks in Machine Learning to tell what sounds are?
  prefs: []
  type: TYPE_NORMAL
- en: We’ll talk about the tools you need to quickly kick off a new sound classification
    task and give a big-picture view of how it all fits together.
  prefs: []
  type: TYPE_NORMAL
- en: About the data used in this article
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To illustrate sound classification, we will use bird sounds recorded from [https://xeno-canto.org/](https://xeno-canto.org/).
    Xeno-canto is a community-driven collection of bird sounds from around the world,
    including a large database of bird recordings.
  prefs: []
  type: TYPE_NORMAL
- en: Before using their data, you have to know that each recording may be under a
    different license and for this article, I picked records under the CC BY 4.0 license.
  prefs: []
  type: TYPE_NORMAL
- en: A bit of basic around sounds and signal processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A sound is the result of pressure waves from the air when an object vibrates.
    These pressure waves travel from the source to us. The ear then processes two
    parameters: the frequency of the pressure wave and its amplitude.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The frequency of the pressure wave received by the ear is translated to a pitch:
    the higher the frequency, the higher the pitch.'
  prefs: []
  type: TYPE_NORMAL
- en: The amplitude of the wave, on the other hand, is responsible for the intensity
    of the sound, and a big amplitude will create a louder noise.
  prefs: []
  type: TYPE_NORMAL
- en: Going through an example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Below is an example of [a bird call](https://xeno-canto.org/710407) recorded
    by [Camille Vacher](https://xeno-canto.org/contributor/LTIHWHLJQI) viewed as an
    air-pressure over time signal. We say that we visualize the wave in the “**time
    domain**” because we look at the evolution of the pressure wave over time. The
    signal has been truncated to keep only the first “pew” from the bird.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ccadef47e87fb06d59af5e319e37cb87.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Bird song](https://xeno-canto.org/710407) recorded by [Camille Vacher](https://xeno-canto.org/contributor/LTIHWHLJQI)
    ([**Creative Commons Attribution 4.0**](https://creativecommons.org/licenses/by/4.0/)),
    transcribed as an air pressure time series, Author Illustration'
  prefs: []
  type: TYPE_NORMAL
- en: 'And for reference, this is what we will actually hear:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Bird song](https://xeno-canto.org/710407) recorded by [Camille Vacher](https://xeno-canto.org/contributor/LTIHWHLJQI)
    ([**Creative Commons Attribution 4.0**](https://creativecommons.org/licenses/by/4.0/)),
    [Illustration by Mark S Jobling](https://commons.wikimedia.org/wiki/Category:Cettia_cetti?uselang=fr#/media/File:37-090505-cettis-warbler-at-Kalloni-east-river.jpg)
    (Wikipedia Common, [CC BY 3.0](https://creativecommons.org/licenses/by/3.0))'
  prefs: []
  type: TYPE_NORMAL
- en: 'For a human, the different characteristics of the sounds, and what we would
    like a bird song classifier to identify are:'
  prefs: []
  type: TYPE_NORMAL
- en: The duration of the call (Some birds produce longer sounds, while others produce
    shorter ones)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The pitch, and its evolution during the call
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The potential evolution of the amplitude in time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some features of the evolution of the frequencies/amplitudes of the call over
    time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s explore some of the characteristics of the bird call above.
  prefs: []
  type: TYPE_NORMAL
- en: Evolution of the frequency of the call
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we zoom in exactly at the beginning of the song, we can observe the change
    in the time series regime which highlight the main frequency of the bird sound
    at the beginning of the call.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/249d3929b51eea446e5e6fb692c14036.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Bird song](https://xeno-canto.org/710407) recorded by [Camille Vacher](https://xeno-canto.org/contributor/LTIHWHLJQI)
    ([**Creative Commons Attribution 4.0**](https://creativecommons.org/licenses/by/4.0/)),
    transcribed as an air pressure time series, Author Illustration'
  prefs: []
  type: TYPE_NORMAL
- en: If we look a bit further in the signal, we can see differences in the dominant
    frequency as well as a difference in the amplitude of the signal. Let’s have a
    look at 5 periods of oscillations of the signal above at two different timestamps.
    To calculate the frequency of the oscillation of the signal we simply look at
    the time elapsed between a full oscillation and invert it. We are averaging here
    over 5 periods to get a slightly more robust measure.
  prefs: []
  type: TYPE_NORMAL
- en: Around t=0.0918s, the frequency of oscillation is roughly 1/[(0.0922–0.0913)/5]
    ~ 5.55kHz.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6be1d3e0d02ad245ead4994086ef49ec.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Bird song](https://xeno-canto.org/710407) recorded by [Camille Vacher](https://xeno-canto.org/contributor/LTIHWHLJQI)
    ([**Creative Commons Attribution 4.0**](https://creativecommons.org/licenses/by/4.0/)),
    transcribed as an air pressure time series, Author Illustration'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, around 0.229s, the frequency is lower: 1/[(0.2295–0.2284)/5]
    ~ 4.55kHz. We can also notice that the amplitude of that second signal has an
    amplitude ~4 times higher than the previous one.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/044084e3c1782f13af91f993a2f0010e.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Bird song](https://xeno-canto.org/710407) recorded by [Camille Vacher](https://xeno-canto.org/contributor/LTIHWHLJQI)
    ([**Creative Commons Attribution 4.0**](https://creativecommons.org/licenses/by/4.0/)),
    transcribed as an air pressure time series, Author Illustration'
  prefs: []
  type: TYPE_NORMAL
- en: What about the tone color of the sound?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The frequency that we are observing above is not enough to fully characterize
    a bird song. Think of two instruments playing the same musical note: the main
    frequency of the air-pressure signal can be the same (same note, ergo same pitch),
    but your ear can still make the difference between the instruments.'
  prefs: []
  type: TYPE_NORMAL
- en: So far we have considered the sounds as a pure mono-frequency signal. In reality,
    a sound is made of an infinity of signals that add up to each other and give a
    particular tone color to the sound, which is also used by our brain to differentiate
    sounds from each other. Those other frequencies are often referred to as “harmonics”,
    and are particularly difficult to distinguish from our “temporal domain” representation.
  prefs: []
  type: TYPE_NORMAL
- en: 'One clue can still be identified: if our bird song was a perfectly monotonic
    sine, we should not see a variation in amplitude, as in the figure below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3688ff71426075f25fec4ba9edfbda0c.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of a mono-frequence periodic signal (f(t) = A * sin(2 pi f t) )
  prefs: []
  type: TYPE_NORMAL
- en: 'If we add to the previous time series another signal with a different frequency,
    we will observe a modulation of the amplitude while keeping the dominant frequency:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ad22b5e5b1fbb062063aac30f4753ba0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Adding up to period signals with different frequencies: (f(t) = A1 * sin(2
    pi f1 t) + A2 * sin(2 pi f2 t) ), Author Illustration'
  prefs: []
  type: TYPE_NORMAL
- en: 'The frequencies responsible for the modulation of the amplitude in the time
    domain are fundamental as they give a “color” to the sound. Going back to our
    example, those modulations can be observed when we look with the right level of
    detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/74f798762629569b0009eefa99134340.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Bird song](https://xeno-canto.org/710407) recorded by [Camille Vacher](https://xeno-canto.org/contributor/LTIHWHLJQI)
    ([**Creative Commons Attribution 4.0**](https://creativecommons.org/licenses/by/4.0/)),
    transcribed as an air pressure time series, Author Illustration'
  prefs: []
  type: TYPE_NORMAL
- en: From sound to image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Fourrier Transform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**The Fourier Transform** is a mathematical tool that helps us deconstruct
    a complex signal into a series of simpler sine and cosine waves, each characterized
    by a specific frequency and amplitude. Here is a simplified version of the Fourier
    Transform:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/16c099f1969a64d014bc7fc5c3dab707.png)'
  prefs: []
  type: TYPE_IMG
- en: A simplified version of the Fourier Transform, neglecting the phase information
  prefs: []
  type: TYPE_NORMAL
- en: In short, the Fourier Transform is simply telling us that any time series can
    be decomposed in a continuous sum (the integral of the formula) of primary sines/cosines
    with different amplitudes. This is exactly what we are looking for (because sound
    and frequencies spectrum are very closely related)
  prefs: []
  type: TYPE_NORMAL
- en: This method allows us to “break” the signal and identify each of its frequency
    components, providing a more thorough understanding of the overall sound.
  prefs: []
  type: TYPE_NORMAL
- en: The Fourier Transform for a mixture of two cosine signals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To make it more clear, let’s consider our previous example where we combined
    two periodic signals with different frequencies. The output, as we’ve observed,
    was a signal with a modulated amplitude.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/72c7afb0ca218cad31595a3a67dcc552.png)'
  prefs: []
  type: TYPE_IMG
- en: Adding up to period signals with different frequencies, Author Illustration
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind the Fourier Transform is simply to identify and represent the
    different components of our combined signal, which can later be represented on
    a diagram showing the amplitude and frequency of each primary cosine identified.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b7d6fcb46368393146e4432ad1c3e14a.png)'
  prefs: []
  type: TYPE_IMG
- en: The original signal is broken in primary cosines. Their amplitudes and frequencies
    are displayed in a diagram, Author Illustration
  prefs: []
  type: TYPE_NORMAL
- en: The resultant diagram showing the primary components of a complex signal with
    their frequencies and amplitudes is called a spectral diagram, and it contains
    the “features” composing our signal.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/07e5d3039606e5936d8850e043166474.png)'
  prefs: []
  type: TYPE_IMG
- en: The spectral diagram for our made-up example
  prefs: []
  type: TYPE_NORMAL
- en: 'What this diagram tells us is simply that our made-up periodic signal is composed
    of two “primary” cosine signals:'
  prefs: []
  type: TYPE_NORMAL
- en: One cosine at 2250Hz with an amplitude of 0.5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One cosine at 5500Hz with an amplitude of 1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The diagram is sufficient on its own to describe completely our main periodic
    signal: we jumped from the “time domain” to the “frequency domain”.'
  prefs: []
  type: TYPE_NORMAL
- en: Extending the concept with a real-life signal
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our bird call, however, is much more complex than this two-frequency time series.
    It can have an infinity of frequencies mixed together, each contributing to the
    call's unique tone color, and the frequency composition can evolve over time.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of applying the Fourier Transform to the whole signal, we will apply
    it only locally, at a scale that is small enough to have a “regular enough” signal,
    but long enough to have enough periods of oscillations.
  prefs: []
  type: TYPE_NORMAL
- en: For example, let’s zoom back to the signal at t=0.0918s and t=0.229s and have
    a look at the spectral diagram. The obtained Fourier Transforms are this time
    continuous but peak at certain frequencies, which match with the calculations
    made in the previous chapter of this article.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5d022311e319c1d2bc20458ff90cb8d5.png)'
  prefs: []
  type: TYPE_IMG
- en: Time Domain (left) and Spectral Diagram (right) (t=0.0918s), [Bird song](https://xeno-canto.org/710407)
    recorded by [Camille Vacher](https://xeno-canto.org/contributor/LTIHWHLJQI) ([**Creative
    Commons Attribution 4.0**](https://creativecommons.org/licenses/by/4.0/)), transcribed
    as an air pressure time series, Author Illustration
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fdd174be049b083c7acb74a79ce4d9d3.png)'
  prefs: []
  type: TYPE_IMG
- en: Time Domain (left) and Spectral Diagram (right) (t=0.229s), [Bird song](https://xeno-canto.org/710407)
    recorded by [Camille Vacher](https://xeno-canto.org/contributor/LTIHWHLJQI) ([**Creative
    Commons Attribution 4.0**](https://creativecommons.org/licenses/by/4.0/)), transcribed
    as an air pressure time series, Author Illustration
  prefs: []
  type: TYPE_NORMAL
- en: Secondly, we can determine with more detail the composition of each portion
    of signals. In particular, we see that the second slice is made of multiple frequency
    peaks and is “richer” from a harmonic point of view, giving us new information
    about the “color” we talked about earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Applying the Fourier Transform to a sub-part of the signal as we did above is
    usually referred to as **Short-Time Fourier Transform** **(SFTF)**, it’s a strong
    tool that will be particularly useful to describe the sound locally and follow
    its evolution over time.
  prefs: []
  type: TYPE_NORMAL
- en: From STFT to Spectrogram
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have now a tool that can be used to identify the different primary components
    (amplitudes/frequencies) from a slice of a temporal signal locally. We can now
    apply this method to the whole signal using a sliding window which will extract
    the features of the sound over time. Note that instead of showing the Spectral
    diagram as a Scatter Plot, we will now represent it using a Heatmap with the frequency
    axis displayed vertically and each pixel representing the intensity of that frequency.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1b65b1df0c0870704d533a7b9e0fe6c7.png)'
  prefs: []
  type: TYPE_IMG
- en: From Temporal Signal to STFT Heatmap, Author Illustration
  prefs: []
  type: TYPE_NORMAL
- en: Using this representation, we can now stack horizontally the STFTs calculated
    using the rolling window on the entire signal and visualize the evolution of the
    frequency spectrum over time through an image. The generated figure is called
    a **spectrogram.**
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/805930c598e14e939c1d21b976c37822.png)'
  prefs: []
  type: TYPE_IMG
- en: The birds call in the time domain, and the associated Spectrogram, [Bird song](https://xeno-canto.org/710407)
    recorded by [Camille Vacher](https://xeno-canto.org/contributor/LTIHWHLJQI) ([**Creative
    Commons Attribution 4.0**](https://creativecommons.org/licenses/by/4.0/)), transcribed
    as an air pressure time series, Author Illustration
  prefs: []
  type: TYPE_NORMAL
- en: In the spectrogram above, each column of pixels represents the STFT of a small
    portion of the signal centered on a given timestamp.
  prefs: []
  type: TYPE_NORMAL
- en: There are many types of spectrograms with different scales, and different hyper-parameters
    to apply the time-frequency transformation. Among them, we can mention the Log
    Frequency Power Spectrogram, the Constant-Q Transform (CQT), the Mel Spectrogram,
    etc… Each has its own subtilities but work on the same basis of extracting the
    frequency features and represent them in a (time x frequency heatmap) that can
    be interpreted as an image.
  prefs: []
  type: TYPE_NORMAL
- en: A few examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The advantage of the spectrogram is that it condensates all the important features
    of the sound in one simple image. Analyzing this image tells you about variations
    over time in amplitudes, pitch, and color of a sound, which is exactly what we
    (or an ML/DL algorithm) need to recognize its emitter.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s have a look at a few sounds with a 5s duration with their associated spectrogram.
  prefs: []
  type: TYPE_NORMAL
- en: '[The first sample](https://xeno-canto.org/794236) is a European Chaffinch,
    recorded by [**Benoît Van Hecke**](https://xeno-canto.org/contributor/IIGGEELDDD)'
  prefs: []
  type: TYPE_NORMAL
- en: '[European Chaffinch call](https://xeno-canto.org/794236), by [**Benoît Van
    Hecke**](https://xeno-canto.org/contributor/IIGGEELDDD), image from [Sébastien
    FAILLON](https://www.flickr.com/people/128090976@N08) ([Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Pinson_des_arbres_femelle_(19215641796).jpg))'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/41fdf550e9ed4ec96c8ebe34d95efce3.png)'
  prefs: []
  type: TYPE_IMG
- en: '[European Chaffinch call](https://xeno-canto.org/794236) in the time domain,
    and the associated Spectrogram, by [**Benoît Van Hecke**](https://xeno-canto.org/contributor/IIGGEELDDD)'
  prefs: []
  type: TYPE_NORMAL
- en: '[The second recording](https://xeno-canto.org/542842) is a European Robin by
    [**Benoît Van Hecke**](https://xeno-canto.org/contributor/IIGGEELDDD)'
  prefs: []
  type: TYPE_NORMAL
- en: '[European Robin call](https://xeno-canto.org/542842), by [**Benoît Van Hecke**](https://xeno-canto.org/contributor/IIGGEELDDD),
    image by [Sharp Photography, sharpphotography](http://www.sharpphotography.co.uk/)
    ([Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Pinson_des_arbres_femelle_(19215641796).jpg))'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8a9f10f8bcf062d542f05625bcdbfd5e.png)'
  prefs: []
  type: TYPE_IMG
- en: '[European Robin call](https://xeno-canto.org/542842) in the time domain, and
    the associated Spectrogram, by [**Benoît Van Hecke**](https://xeno-canto.org/contributor/IIGGEELDDD)'
  prefs: []
  type: TYPE_NORMAL
- en: One last with a 5s [record](https://xeno-canto.org/629038) of a Song Thrush,
    still by [**Benoît Van Hecke**](https://xeno-canto.org/contributor/IIGGEELDDD)
  prefs: []
  type: TYPE_NORMAL
- en: '[Song Thrush call](https://xeno-canto.org/629038), by [**Benoît Van Hecke**](https://xeno-canto.org/contributor/IIGGEELDDD),
    image by Tony Wills ([Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Pinson_des_arbres_femelle_(19215641796).jpg))'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e5f218af5479a5d7e97933751dfe68e4.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Song Thrush call](https://xeno-canto.org/629038), in the time domain, and
    the associated Spectrogram, by [**Benoît Van Hecke**](https://xeno-canto.org/contributor/IIGGEELDDD)'
  prefs: []
  type: TYPE_NORMAL
- en: Why Spectrograms + CNNs are more performant than LSTM on sounds classification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you never worked on a sound classification system before, you might have
    considered using a recurrent neural network like an LSTM to extract the relevant
    features from the sound time series directly.
  prefs: []
  type: TYPE_NORMAL
- en: This would be a bad idea, because even if those models are designed to extract
    temporal dependencies, they are not efficient at extracting frequency features
    which, as we saw, are crucial for the sound identification task. LSTM would also
    be computationally expensive and inefficient by nature (because the data is processed
    sequentially). This means much less data to process for a given amount of time
    in comparison to a standard CNN.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, converting the time series data into a spectrogram, which
    is essentially a visual representation of frequency information over time, allows
    us to use Convolutional Neural Networks (CNNs) which are designed for image data
    and are very effective at capturing spatial patterns, which in the case of a spectrogram,
    correspond to frequency patterns over time. This step can be seen as a natural
    “feature engineering” step, guaranteeing better efficiency for the sound classification
    task.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion & Further Challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article, we explored the mechanisms used to extract all the relevant
    features from a sound and transform a time series into an image.
  prefs: []
  type: TYPE_NORMAL
- en: We only covered the preliminary preprocessing steps, but even if the spectrogram
    is a powerful transformation it is not a silver bullet. There are still several
    challenges that would still need to be addressed.
  prefs: []
  type: TYPE_NORMAL
- en: One of the main challenges is the issue of weakly labeled data. In many cases,
    the exact time of the sound of interest within the recording is not known, and
    the label only indicates the presence of a sound somewhere in the recording.
  prefs: []
  type: TYPE_NORMAL
- en: Another challenge is the presence of background noise in the recordings. Techniques
    such as noise reduction or filtering can be used to mitigate this issue, but they
    also risk distorting the bird song and potentially losing important information.
    Other alternatives would include data augmentation technics specific to sound
    classification such as “Mix-up” (a method that creates new sounds as a linear
    combination of original samples) or adding new background noises.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the length of recordings can also be a problem, especially when coupled
    with the weakly labeled issue. While some sounds are only a few seconds long,
    others can last for minutes. This variation can make it difficult to standardize
    the input to the model, and can also affect the performance of the model, as it
    may be more difficult to accurately identify species from shorter recordings.
  prefs: []
  type: TYPE_NORMAL
- en: Despite these challenges, the use of spectrograms and Convolutional Neural Networks
    offers a promising approach to sound identifications, and I hope that this exploration
    will serve as a valuable starting point for those embarking on new machine learning
    projects in sound classification. With the right tools and understanding, we can
    navigate these challenges and unlock the vast potential of audio data.
  prefs: []
  type: TYPE_NORMAL
