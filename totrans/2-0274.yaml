- en: AI Training Outsourced to AI and Not Humans
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: äººå·¥æ™ºèƒ½åŸ¹è®­å¤–åŒ…ç»™äººå·¥æ™ºèƒ½è€Œéäººç±»
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/ai-training-outsourced-to-ai-and-not-humans-4ab616a2a84d](https://towardsdatascience.com/ai-training-outsourced-to-ai-and-not-humans-4ab616a2a84d)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/ai-training-outsourced-to-ai-and-not-humans-4ab616a2a84d](https://towardsdatascience.com/ai-training-outsourced-to-ai-and-not-humans-4ab616a2a84d)
- en: '![](../Images/36730c49324f68d38205c0e20c489a63.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/36730c49324f68d38205c0e20c489a63.png)'
- en: Photo by [davide ragusa](https://unsplash.com/@davideragusa?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”± [davide ragusa](https://unsplash.com/@davideragusa?utm_source=medium&utm_medium=referral)
    æä¾›ï¼Œæ¥æºäº [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: The Risk of Introducing Further Errors into Models
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¼•å…¥æ¨¡å‹è¿›ä¸€æ­¥é”™è¯¯çš„é£é™©
- en: '[](https://medium.com/@mastafa.foufa?source=post_page-----4ab616a2a84d--------------------------------)[![Mastafa
    Foufa](../Images/2e0b26ed83f04e943438afa1aab462a8.png)](https://medium.com/@mastafa.foufa?source=post_page-----4ab616a2a84d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4ab616a2a84d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4ab616a2a84d--------------------------------)
    [Mastafa Foufa](https://medium.com/@mastafa.foufa?source=post_page-----4ab616a2a84d--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mastafa.foufa?source=post_page-----4ab616a2a84d--------------------------------)[![Mastafa
    Foufa](../Images/2e0b26ed83f04e943438afa1aab462a8.png)](https://medium.com/@mastafa.foufa?source=post_page-----4ab616a2a84d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4ab616a2a84d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4ab616a2a84d--------------------------------)
    [Mastafa Foufa](https://medium.com/@mastafa.foufa?source=post_page-----4ab616a2a84d--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4ab616a2a84d--------------------------------)
    Â·11 min readÂ·Jul 18, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4ab616a2a84d--------------------------------)
    Â·11åˆ†é’Ÿé˜…è¯»Â·2023å¹´7æœˆ18æ—¥
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: â€œWe reran an abstract summarization task from the literature on Amazon Mechanical
    Turk and, through a combination of keystroke detection and synthetic text classification,
    estimate that 33â€“46% of crowd workers used LLMs when completing the task. Although
    generalization to other, less LLM friendly tasks is unclear, our results call
    for platforms, researchers, and crowd workers to find new ways to ensure that
    human data remain human, perhaps using the methodology proposed here as a stepping
    stone.â€ From [Veselovsky, V., Ribeiro, M.H. and West, R.](https://arxiv.org/pdf/2306.07899.pdf)
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œæˆ‘ä»¬åœ¨Amazon Mechanical Turkä¸Šé‡æ–°è¿›è¡Œäº†ä¸€ä¸ªæ–‡çŒ®ä¸­çš„æ‘˜è¦æ€»ç»“ä»»åŠ¡ï¼Œé€šè¿‡é”®å‡»æ£€æµ‹å’Œåˆæˆæ–‡æœ¬åˆ†ç±»çš„ç»“åˆï¼Œä¼°è®¡33%â€“46%çš„ä¼—åŒ…å·¥äººåœ¨å®Œæˆä»»åŠ¡æ—¶ä½¿ç”¨äº†LLMã€‚å°½ç®¡è¿™ä¸€ç»“æœæ˜¯å¦å¯ä»¥æ¨å¹¿åˆ°å…¶ä»–ä¸é‚£ä¹ˆå‹å¥½LLMçš„ä»»åŠ¡å°šä¸æ˜ç¡®ï¼Œä½†æˆ‘ä»¬çš„ç»“æœå‘¼åå¹³å°ã€ç ”ç©¶äººå‘˜å’Œä¼—åŒ…å·¥äººå¯»æ‰¾æ–°çš„æ–¹æ³•æ¥ç¡®ä¿äººç±»æ•°æ®ä¿æŒäººæ€§ï¼Œä¹Ÿè®¸å¯ä»¥å°†è¿™é‡Œæå‡ºçš„æ–¹æ³•ä½œä¸ºä¸€ä¸ªè¸è„šçŸ³ã€‚â€
    å¼•è‡ª [Veselovsky, V., Ribeiro, M.H. å’Œ West, R.](https://arxiv.org/pdf/2306.07899.pdf)
- en: Recently, a study by the **Swiss Federal Institute of Technology** (EPFL) found
    that between 33% and 46% of gig workers paid to train AI models [may be outsourcing
    their work to AI.](https://arxiv.org/pdf/2306.07899.pdf)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€è¿‘ï¼Œ**ç‘å£«è”é‚¦ç†å·¥å­¦é™¢**ï¼ˆEPFLï¼‰çš„ä¸€é¡¹ç ”ç©¶å‘ç°ï¼Œ33%åˆ°46%æ¥å—æŠ¥é…¬åŸ¹è®­AIæ¨¡å‹çš„ä¸´æ—¶å·¥å¯èƒ½æ­£åœ¨å°†ä»–ä»¬çš„å·¥ä½œå¤–åŒ…ç»™AIã€‚[è¯¦ç»†ä¿¡æ¯è¯·è§è¿™é‡Œã€‚](https://arxiv.org/pdf/2306.07899.pdf)
- en: The [MIT Technology Review](https://www.technologyreview.com/2023/06/22/1075405/the-people-paid-to-train-ai-are-outsourcing-their-work-to-ai/)
    discusses this research paper and explains how people who are paid to train AI
    are indeed **outsourcing their work to AI.** It explains that AI can now be used
    to create data sets and labels, tasks that are traditionally done by humans. It
    also discusses the implications of this trend, such as the potential for AI to
    learn from other AI which integrates further bias.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[MITç§‘æŠ€è¯„è®º](https://www.technologyreview.com/2023/06/22/1075405/the-people-paid-to-train-ai-are-outsourcing-their-work-to-ai/)
    è®¨è®ºäº†è¿™ç¯‡ç ”ç©¶è®ºæ–‡ï¼Œå¹¶è§£é‡Šäº†é‚£äº›è¢«æ”¯ä»˜æ¥åŸ¹è®­AIçš„äººç¡®å®åœ¨**å°†ä»–ä»¬çš„å·¥ä½œå¤–åŒ…ç»™AI**ã€‚æ–‡ç« è§£é‡Šäº†AIç°åœ¨å¯ä»¥ç”¨æ¥åˆ›å»ºæ•°æ®é›†å’Œæ ‡ç­¾ï¼Œè¿™äº›ä»»åŠ¡ä¼ ç»Ÿä¸Šæ˜¯ç”±äººç±»å®Œæˆçš„ã€‚å®ƒè¿˜è®¨è®ºäº†è¿™ä¸€è¶‹åŠ¿çš„å½±å“ï¼Œä¾‹å¦‚AIå¯èƒ½ä»å…¶ä»–AIä¸­å­¦ä¹ ï¼Œä»è€Œè¿›ä¸€æ­¥æ•´åˆåè§ã€‚'
- en: '![](../Images/ce3c81bb1e63ccc427699d5843cac623.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ce3c81bb1e63ccc427699d5843cac623.png)'
- en: '**Resource**: From [Veselovsky, V., Ribeiro, M.H. and West, R.](https://arxiv.org/pdf/2306.07899.pdf)
    A model to discriminate mTurks responses generated manually by a human and responses
    generated by an AI. The authors use a classifier (real vs AI-generated) on real
    MTurk responses (where workers may or may not have relied on LLMs), estimating
    the prevalence of LLM usage.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**èµ„æº**ï¼šæ¥è‡ª [Veselovsky, V., Ribeiro, M.H. å’Œ West, R.](https://arxiv.org/pdf/2306.07899.pdf)
    ä¸€ä¸ªæ¨¡å‹æ¥åŒºåˆ†ç”±äººå·¥ç”Ÿæˆçš„ mTurks å“åº”å’Œç”± AI ç”Ÿæˆçš„å“åº”ã€‚ä½œè€…ä½¿ç”¨ä¸€ä¸ªåˆ†ç±»å™¨ï¼ˆçœŸå® vs AI ç”Ÿæˆï¼‰å¯¹çœŸå®çš„ MTurk å“åº”è¿›è¡Œåˆ†ç±»ï¼ˆå·¥äººå¯èƒ½æˆ–å¯èƒ½æ²¡æœ‰ä¾èµ–äº
    LLMsï¼‰ï¼Œä¼°è®¡ LLM ä½¿ç”¨çš„æ™®åŠç‡ã€‚'
- en: How do we train AI systems?
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¦‚ä½•è®­ç»ƒ AI ç³»ç»Ÿï¼Ÿ
- en: AI systems can be seen as Machine learning models. In a supervised setting,
    such systems need gold standard labels to build qualitative training data. This
    can be done internally, especially in big tech companies like Microsoft or Google.
    Then, for complex tasks involving large datasets, data labeling can also be outsourced
    to vendors who are typically expected to be subject-matter experts.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: AI ç³»ç»Ÿå¯ä»¥è¢«è§†ä¸ºæœºå™¨å­¦ä¹ æ¨¡å‹ã€‚åœ¨ç›‘ç£ç¯å¢ƒä¸‹ï¼Œè¿™äº›ç³»ç»Ÿéœ€è¦é»„é‡‘æ ‡å‡†æ ‡ç­¾æ¥æ„å»ºé«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ã€‚è¿™å¯ä»¥åœ¨å†…éƒ¨å®Œæˆï¼Œç‰¹åˆ«æ˜¯åœ¨åƒå¾®è½¯æˆ–è°·æ­Œè¿™æ ·çš„ç§‘æŠ€å…¬å¸ä¸­ã€‚ç„¶åï¼Œå¯¹äºæ¶‰åŠå¤§å‹æ•°æ®é›†çš„å¤æ‚ä»»åŠ¡ï¼Œæ•°æ®æ ‡æ³¨ä¹Ÿå¯ä»¥å¤–åŒ…ç»™é€šå¸¸è¢«æœŸæœ›æˆä¸ºé¢†åŸŸä¸“å®¶çš„ä¾›åº”å•†ã€‚
- en: However, they can also be **online gig workers, with no particular expertise
    in the subject in question.** Indeed, you can find gig workers on platforms like
    [Mechanical Turk](https://www.mturk.com/) to complete tasks that are typically
    hard to automate.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œä»–ä»¬ä¹Ÿå¯ä»¥æ˜¯**åœ¨çº¿é›¶å·¥ï¼Œæ²¡æœ‰ç‰¹å®šçš„ä¸»é¢˜ä¸“ä¸šçŸ¥è¯†ã€‚** ç¡®å®ï¼Œä½ å¯ä»¥åœ¨åƒ [Mechanical Turk](https://www.mturk.com/)
    è¿™æ ·çš„å¹³å°ä¸Šæ‰¾åˆ°é›¶å·¥ï¼Œä»¥å®Œæˆé€šå¸¸éš¾ä»¥è‡ªåŠ¨åŒ–çš„ä»»åŠ¡ã€‚
- en: â€œ**Amazon** Mechanical Turk (MTurk) is a crowdsourcing marketplace that makes
    it easier for individuals and businesses to outsource their processes and jobs
    to a distributed workforce who can perform these tasks virtually. This could include
    anything from conducting simple data validation and research to more subjective
    tasks like survey participation, content moderation, and more. MTurk enables companies
    to harness the collective intelligence, skills, and insights from a global workforce
    to streamline business processes, augment data collection and analysis, and accelerate
    machine learning development.â€ from [https://www.mturk.com/](https://www.mturk.com/).
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œ**äºšé©¬é€Š** Mechanical Turk (MTurk) æ˜¯ä¸€ä¸ªä¼—åŒ…å¸‚åœºï¼Œä½¿ä¸ªäººå’Œä¼ä¸šæ›´å®¹æ˜“å°†ä»–ä»¬çš„è¿‡ç¨‹å’Œå·¥ä½œå¤–åŒ…ç»™å¯ä»¥è™šæ‹Ÿæ‰§è¡Œè¿™äº›ä»»åŠ¡çš„åˆ†å¸ƒå¼åŠ³åŠ¨åŠ›ã€‚è¿™å¯èƒ½åŒ…æ‹¬ä»è¿›è¡Œç®€å•çš„æ•°æ®éªŒè¯å’Œç ”ç©¶åˆ°æ›´ä¸»è§‚çš„ä»»åŠ¡ï¼Œå¦‚è°ƒæŸ¥å‚ä¸ã€å†…å®¹å®¡æŸ¥ç­‰ã€‚MTurk
    ä½¿å…¬å¸èƒ½å¤Ÿåˆ©ç”¨å…¨çƒåŠ³åŠ¨åŠ›çš„é›†ä½“æ™ºæ…§ã€æŠ€èƒ½å’Œè§è§£æ¥ä¼˜åŒ–ä¸šåŠ¡æµç¨‹ã€å¢å¼ºæ•°æ®æ”¶é›†å’Œåˆ†æï¼Œå¹¶åŠ é€Ÿæœºå™¨å­¦ä¹ å¼€å‘ã€‚â€ æ¥è‡ª [https://www.mturk.com/](https://www.mturk.com/)ã€‚
- en: Understanding why this can be harmful is key. For that, let us take the example
    of Chat GPT which leverages human labelers to get high performance.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: äº†è§£è¿™å¯èƒ½æœ‰å®³çš„åŸå› æ˜¯å…³é”®ã€‚ä¸ºæ­¤ï¼Œè®©æˆ‘ä»¬ä»¥ Chat GPT ä¸ºä¾‹ï¼Œå®ƒåˆ©ç”¨äººç±»æ ‡æ³¨å‘˜æ¥è·å¾—é«˜æ€§èƒ½ã€‚
- en: 'An example: Chat GPT'
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼šChat GPT
- en: Chat GPT is a good example of a model that required a lot of human labelers.
    In the figure below outlining the steps taken to train the OpenAI model, we can
    note the importance of the labeler who helps refine the prompts at training time.
    If Chat GPT is, in essence, another large language model relying on unlabeled
    data such as the Wikipedia corpus, it reached a unique performance due to human
    labelers demonstrating desired outputs behavior on sampled prompts. That way,
    the underlying model tries to approach the outputs given by the human label themself.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Chat GPT æ˜¯ä¸€ä¸ªéœ€è¦å¤§é‡äººå·¥æ ‡æ³¨å‘˜çš„æ¨¡å‹çš„è‰¯å¥½ç¤ºä¾‹ã€‚åœ¨ä¸‹å›¾ä¸­æ¦‚è¿°äº†è®­ç»ƒ OpenAI æ¨¡å‹æ‰€é‡‡å–çš„æ­¥éª¤ï¼Œæˆ‘ä»¬å¯ä»¥æ³¨æ„åˆ°æ ‡æ³¨å‘˜åœ¨è®­ç»ƒæ—¶å¸®åŠ©å®Œå–„æç¤ºçš„é‡è¦æ€§ã€‚å¦‚æœ
    Chat GPT æœ¬è´¨ä¸Šæ˜¯ä¾èµ–äºæœªæ ‡æ³¨æ•°æ®ï¼ˆå¦‚ç»´åŸºç™¾ç§‘è¯­æ–™åº“ï¼‰çš„å¦ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå®ƒç”±äºäººç±»æ ‡æ³¨å‘˜åœ¨é‡‡æ ·æç¤ºä¸Šå±•ç¤ºçš„æœŸæœ›è¾“å‡ºè¡Œä¸ºè€Œè¾¾åˆ°ç‹¬ç‰¹çš„æ€§èƒ½ã€‚è¿™æ ·ï¼ŒåŸºç¡€æ¨¡å‹å°è¯•æ¥è¿‘ç”±äººç±»æ ‡æ³¨å‘˜è‡ªèº«æä¾›çš„è¾“å‡ºã€‚
- en: '**To remember**. Chat GPT is a large language model because it uses a huge
    amount of text data to train a neural network that can generate coherent and diverse
    responses to natural language queries. A language model is a system that assigns
    probabilities to sequences of words or tokens, based on how likely they are to
    occur in a given context. A large language model can in particular capture complex
    and long-term dependencies among words.'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**è®°ä½**ã€‚Chat GPT æ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå› ä¸ºå®ƒä½¿ç”¨å¤§é‡æ–‡æœ¬æ•°æ®æ¥è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œè¯¥ç½‘ç»œå¯ä»¥ç”Ÿæˆå¯¹è‡ªç„¶è¯­è¨€æŸ¥è¯¢çš„è¿è´¯å’Œå¤šæ ·çš„å“åº”ã€‚è¯­è¨€æ¨¡å‹æ˜¯ä¸€ä¸ªç³»ç»Ÿï¼Œæ ¹æ®å•è¯æˆ–ç¬¦å·åºåˆ—åœ¨ç»™å®šä¸Šä¸‹æ–‡ä¸­å‘ç”Ÿçš„å¯èƒ½æ€§æ¥åˆ†é…æ¦‚ç‡ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ç‰¹åˆ«èƒ½å¤Ÿæ•æ‰å•è¯ä¹‹é—´å¤æ‚å’Œé•¿æœŸçš„ä¾èµ–å…³ç³»ã€‚'
- en: '![](../Images/6de821a143cf7799c8bd93c9d92dd89f.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6de821a143cf7799c8bd93c9d92dd89f.png)'
- en: '**Resource**: From [OpenAI](https://openai.com/blog/chatgpt).'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**èµ„æº**ï¼šæ¥è‡ª [OpenAI](https://openai.com/blog/chatgpt)ã€‚'
- en: In other words, one of the objective functions to optimize consists in reducing
    the distance between the AI output and the human output. That naturally assumes
    that the labeler holds the truth.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œå…¶ä¸­ä¸€ä¸ªç›®æ ‡å‡½æ•°æ˜¯å‡å°‘ AI è¾“å‡ºä¸äººç±»è¾“å‡ºä¹‹é—´çš„è·ç¦»ã€‚è¿™è‡ªç„¶å‡è®¾æ ‡æ³¨è€…æŒæ¡äº†çœŸç›¸ã€‚
- en: '![](../Images/106c05957484337c33e86656c4d4fa06.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/106c05957484337c33e86656c4d4fa06.png)'
- en: '**Resource**: From the **author**. Reducing the distance between AI predictions
    (purple Gaussian) and human predictions (orange Gaussian).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**èµ„æº**ï¼šæ¥è‡ª**ä½œè€…**ã€‚å‡å°‘ AI é¢„æµ‹ï¼ˆç´«è‰²é«˜æ–¯ï¼‰ä¸äººç±»é¢„æµ‹ï¼ˆæ©™è‰²é«˜æ–¯ï¼‰ä¹‹é—´çš„è·ç¦»ã€‚'
- en: Now, to mitigate the problem of relying on the labeler, we typically give clear
    instructions to define â€œwhat is goodâ€ and â€œwhat is badâ€.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œä¸ºäº†å‡è½»å¯¹æ ‡æ³¨è€…çš„ä¾èµ–é—®é¢˜ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šæä¾›æ˜ç¡®çš„æŒ‡ä»¤æ¥å®šä¹‰â€œä»€ä¹ˆæ˜¯å¥½çš„â€ä»¥åŠâ€œä»€ä¹ˆæ˜¯åçš„â€ã€‚
- en: Such labels are important because AI models are essentially mathematical functions
    that map some input data to some output data. That includes large language models
    like Chat GPT which essentially predict the next tokens (*output*), given a list
    of tokens (*input*).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ ·çš„æ ‡ç­¾å¾ˆé‡è¦ï¼Œå› ä¸º AI æ¨¡å‹æœ¬è´¨ä¸Šæ˜¯å°†æŸäº›è¾“å…¥æ•°æ®æ˜ å°„åˆ°æŸäº›è¾“å‡ºæ•°æ®çš„æ•°å­¦å‡½æ•°ã€‚è¿™åŒ…æ‹¬åƒ Chat GPT è¿™æ ·çš„åºå¤§è¯­è¨€æ¨¡å‹ï¼Œå®ƒæœ¬è´¨ä¸Šæ˜¯æ ¹æ®ä¸€ç³»åˆ—æ ‡è®°ï¼ˆ*è¾“å…¥*ï¼‰é¢„æµ‹ä¸‹ä¸€ä¸ªæ ‡è®°ï¼ˆ*è¾“å‡º*ï¼‰ã€‚
- en: Once the training data is built and made available, training a machine learning
    model in a supervised setting involves using an optimization algorithm, such as
    gradient descent, that iteratively updates the parameters of the model to minimize
    a loss function. Such loss function is a measure of how well the model fits the
    data, or how much error it makes on the predictions. Now, typically the optimization
    algorithm works by computing the gradient of the loss function with respect to
    the parameters of the model, which indicates the direction and magnitude of the
    change that would reduce the loss. The algorithm then updates the parameters by
    taking a small step in the opposite direction of the gradient, which is expected
    to lower the loss. This process is repeated until the loss reaches a minimum or
    a convergence criterion is met.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦è®­ç»ƒæ•°æ®æ„å»ºå¹¶å¯ç”¨ï¼Œåœ¨æœ‰ç›‘ç£çš„è®¾ç½®ä¸­è®­ç»ƒä¸€ä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹æ¶‰åŠä½¿ç”¨ä¼˜åŒ–ç®—æ³•ï¼Œä¾‹å¦‚æ¢¯åº¦ä¸‹é™ï¼Œè¯¥ç®—æ³•è¿­ä»£åœ°æ›´æ–°æ¨¡å‹çš„å‚æ•°ä»¥æœ€å°åŒ–æŸå¤±å‡½æ•°ã€‚æŸå¤±å‡½æ•°æ˜¯ä¸€ç§è¡¡é‡æ¨¡å‹æ‹Ÿåˆæ•°æ®çš„å¥½åæˆ–é¢„æµ‹è¯¯å·®çš„æ ‡å‡†ã€‚é€šå¸¸ï¼Œä¼˜åŒ–ç®—æ³•é€šè¿‡è®¡ç®—æŸå¤±å‡½æ•°ç›¸å¯¹äºæ¨¡å‹å‚æ•°çš„æ¢¯åº¦æ¥å·¥ä½œï¼Œè¿™è¡¨æ˜å‡å°‘æŸå¤±çš„å˜åŒ–æ–¹å‘å’Œå¹…åº¦ã€‚ç„¶åï¼Œç®—æ³•é€šè¿‡åœ¨æ¢¯åº¦çš„ç›¸åæ–¹å‘ä¸Šé‡‡å–å°æ­¥æ›´æ–°å‚æ•°ï¼Œé¢„è®¡è¿™å°†é™ä½æŸå¤±ã€‚è¿™ä¸ªè¿‡ç¨‹é‡å¤è¿›è¡Œï¼Œç›´åˆ°æŸå¤±è¾¾åˆ°æœ€å°å€¼æˆ–æ»¡è¶³æ”¶æ•›æ ‡å‡†ã€‚
- en: In other words, one can imagine that at each step, the model is predicting things
    that need to go in the direction of the human labeler, until a local optimum is
    found.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œå¯ä»¥æƒ³è±¡åœ¨æ¯ä¸€æ­¥ï¼Œæ¨¡å‹éƒ½åœ¨é¢„æµ‹éœ€è¦æœç€äººå·¥æ ‡æ³¨è€…çš„æ–¹å‘å‘å±•çš„äº‹ç‰©ï¼Œç›´åˆ°æ‰¾åˆ°ä¸€ä¸ªå±€éƒ¨æœ€ä¼˜è§£ã€‚
- en: There can also be a **regularization** mechanism to **prevent the model from
    overfitting data.** That can be roughly seen as a way to avoid having a model
    that memorizes everything by heart and cannot generalize to new unseen data. Ingesting
    noise as part of the training data is one way of adding regularization, equivalent
    to adding a penalty term to the loss function. However, ingesting noise should
    be negligible with respect to what is closest to the true underlying data.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿå¯ä»¥æœ‰ä¸€ä¸ª**æ­£åˆ™åŒ–**æœºåˆ¶æ¥**é˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆæ•°æ®**ã€‚è¿™å¯ä»¥ç²—ç•¥åœ°çœ‹ä½œæ˜¯ä¸€ç§é¿å…æ¨¡å‹æ­»è®°ç¡¬èƒŒæ‰€æœ‰æ•°æ®è€Œæ— æ³•å¯¹æ–°çš„æœªè§æ•°æ®è¿›è¡Œæ³›åŒ–çš„æ–¹æ³•ã€‚å°†å™ªå£°ä½œä¸ºè®­ç»ƒæ•°æ®çš„ä¸€éƒ¨åˆ†è¿›è¡Œå¤„ç†æ˜¯ä¸€ç§æ·»åŠ æ­£åˆ™åŒ–çš„æ–¹æ³•ï¼Œç›¸å½“äºåœ¨æŸå¤±å‡½æ•°ä¸­å¢åŠ æƒ©ç½šé¡¹ã€‚ç„¶è€Œï¼Œç›¸å¯¹äºæœ€æ¥è¿‘çœŸå®åº•å±‚æ•°æ®çš„éƒ¨åˆ†ï¼Œå™ªå£°çš„å½±å“åº”è¯¥æ˜¯å¾®ä¸è¶³é“çš„ã€‚
- en: As such, it is even more important to define what should be close to true gold
    data. For that, instructions given to labelers are equally important.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæ›´é‡è¦çš„æ˜¯å®šä¹‰ä»€ä¹ˆåº”è¯¥æ¥è¿‘çœŸå®çš„é»„é‡‘æ•°æ®ã€‚ä¸ºæ­¤ï¼Œç»™æ ‡æ³¨è€…çš„æŒ‡ä»¤åŒæ ·é‡è¦ã€‚
- en: To better understand the kind of instructions that are typically given, we can
    refer to â€œthe planâ€ designed by Open Assistant, an open-source competitor of Chat
    GPT. In the words of the authors, **OpenAssistant** is a **chat-based assistant**
    that understands **tasks**, can interact with **third-party systems**, and **retrieve
    information** dynamically to do so.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ›´å¥½åœ°ç†è§£é€šå¸¸ç»™å‡ºçš„æŒ‡ä»¤ç±»å‹ï¼Œæˆ‘ä»¬å¯ä»¥å‚è€ƒâ€œè®¡åˆ’â€ï¼Œè¿™æ˜¯ç”± Open Assistant è®¾è®¡çš„ï¼ŒOpen Assistant æ˜¯ Chat GPT
    çš„ä¸€ä¸ªå¼€æºç«äº‰è€…ã€‚æ ¹æ®ä½œè€…çš„æè¿°ï¼Œ**OpenAssistant** æ˜¯ä¸€ä¸ª**åŸºäºèŠå¤©çš„åŠ©æ‰‹**ï¼Œå®ƒèƒ½å¤Ÿç†è§£**ä»»åŠ¡**ï¼Œä¸**ç¬¬ä¸‰æ–¹ç³»ç»Ÿ**äº’åŠ¨ï¼Œå¹¶**åŠ¨æ€æ£€ç´¢ä¿¡æ¯**ä»¥å®Œæˆä»»åŠ¡ã€‚
- en: The [plan](https://github.com/LAION-AI/Open-Assistant) designed consists of
    3 key steps inspired by [InstructGPT](https://openai.com/blog/instruction-following/).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾è®¡çš„[è®¡åˆ’](https://github.com/LAION-AI/Open-Assistant)åŒ…æ‹¬å—[InstructGPT](https://openai.com/blog/instruction-following/)å¯å‘çš„3ä¸ªå…³é”®æ­¥éª¤ã€‚
- en: Collect high-quality human-generated Instruction-Fulfillment samples (prompt
    + response) via a crowdsourced process, with a leaderboard to motivate the community
    and swag for top contributors.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€šè¿‡ä¼—åŒ…è¿‡ç¨‹æ”¶é›†é«˜è´¨é‡çš„äººç±»ç”Ÿæˆçš„æŒ‡ä»¤å®Œæˆæ ·æœ¬ï¼ˆæç¤º+å›åº”ï¼‰ï¼Œè®¾ç½®æ’è¡Œæ¦œä»¥æ¿€åŠ±ç¤¾åŒºï¼Œå¹¶ä¸ºé¡¶çº§è´¡çŒ®è€…æä¾›å¥–åŠ±ã€‚
- en: Sample multiple completions for each prompt and have users rank them from best
    to worst.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹æ¯ä¸ªæç¤ºè¿›è¡Œå¤šæ ·åŒ–çš„å®Œæˆæ ·æœ¬ï¼Œå¹¶è®©ç”¨æˆ·æŒ‰ä»æœ€å¥½åˆ°æœ€å·®çš„é¡ºåºå¯¹å®ƒä»¬è¿›è¡Œæ’åã€‚
- en: Use the gathered ranking data to train a reward model, then use the prompts
    and reward model to train an RLHF.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ”¶é›†çš„æ’åæ•°æ®è®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼Œç„¶åä½¿ç”¨æç¤ºå’Œå¥–åŠ±æ¨¡å‹è®­ç»ƒRLHFã€‚
- en: Note that it is very challenging to have curated training data, even when outsourced
    to human labelers. Indeed, outsourcing requires awareness of many potential biases,
    especially when outsourcing is **free and open to any individual.**
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œå³ä½¿å¤–åŒ…ç»™äººç±»æ ‡æ³¨è€…ï¼Œæ‹¥æœ‰ç»è¿‡ç­›é€‰çš„è®­ç»ƒæ•°æ®ä¹Ÿéå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ç¡®å®ï¼Œå¤–åŒ…éœ€è¦æ„è¯†åˆ°è®¸å¤šæ½œåœ¨çš„åè§ï¼Œç‰¹åˆ«æ˜¯å½“å¤–åŒ…æ˜¯**å…è´¹å¹¶å¯¹ä»»ä½•ä¸ªäººå¼€æ”¾**æ—¶ã€‚
- en: The risks
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é£é™©
- en: â€œAgain this should happen crowd-sourced, e.g. we need to deal with **unreliable
    potentially malicious users.** At least **multiple votes by independent users
    have to be collected to measure the overall agreement.**â€ [OpenAI Assistant.](https://github.com/LAION-AI/Open-Assistant)
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œå†æ¬¡ï¼Œè¿™åº”è¯¥æ˜¯ä¼—åŒ…è¿›è¡Œçš„ï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬éœ€è¦å¤„ç†**ä¸å¯é ä¸”å¯èƒ½æ¶æ„çš„ç”¨æˆ·ã€‚** è‡³å°‘**éœ€è¦æ”¶é›†å¤šä¸ªç‹¬ç«‹ç”¨æˆ·çš„æŠ•ç¥¨ä»¥è¡¡é‡æ€»ä½“ä¸€è‡´æ€§ã€‚**â€ [OpenAI
    Assistant.](https://github.com/LAION-AI/Open-Assistant)
- en: '**The bias of representation of the underlying population of labelers.**'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ ‡æ³¨è€…åŸºç¡€äººç¾¤çš„ä»£è¡¨æ€§åè§ã€‚**'
- en: If labelers are all from the same demographic, the same ethnicity, age, gender,
    or socioeconomic status, they can end up ingesting heavy cultural bias within
    the models they are training. Hence, it is key to make sure the labelers are as
    diverse as possible from a set of key features to target, such as country, age,
    gender, etc.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ ‡æ³¨è€…éƒ½æ¥è‡ªç›¸åŒçš„äººå£ç»Ÿè®¡ç¾¤ä½“ã€ç§æ—ã€å¹´é¾„ã€æ€§åˆ«æˆ–ç¤¾ä¼šç»æµåœ°ä½ï¼Œä»–ä»¬å¯èƒ½ä¼šåœ¨è®­ç»ƒçš„æ¨¡å‹ä¸­å¸¦å…¥ä¸¥é‡çš„æ–‡åŒ–åè§ã€‚å› æ­¤ï¼Œç¡®ä¿æ ‡æ³¨è€…åœ¨å…³é”®ç‰¹å¾å¦‚å›½å®¶ã€å¹´é¾„ã€æ€§åˆ«ç­‰æ–¹é¢å°½å¯èƒ½å¤šæ ·åŒ–æ˜¯å…³é”®ã€‚
- en: This is something that big tech companies are very well aware of, hence they
    now integrate that at the very core of their recruiting. Engineers building products
    within those tech companies need to have a better view of the wide variety of
    end users, with different nationalities, genders, ages, ethnicities, etc. That
    way, when building a product and in particular when training an AI system, they
    are making sure they are not doing it from their perspective but also from the
    perspective of end users. However, given the inherent human bias, the best way
    to cope with that is to have a similar representation of the population of engineers
    building products as the population of end users.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¤§ç§‘æŠ€å…¬å¸éå¸¸æ¸…æ¥šçš„äº‹æƒ…ï¼Œå› æ­¤å®ƒä»¬ç°åœ¨å°†å…¶é›†æˆåˆ°æ‹›è˜çš„æ ¸å¿ƒã€‚é‚£äº›åœ¨è¿™äº›ç§‘æŠ€å…¬å¸ä¸­æ„å»ºäº§å“çš„å·¥ç¨‹å¸ˆéœ€è¦å¯¹å„ç§å„æ ·çš„ç»ˆç«¯ç”¨æˆ·æœ‰æ›´å¥½çš„äº†è§£ï¼ŒåŒ…æ‹¬ä¸åŒçš„å›½ç±ã€æ€§åˆ«ã€å¹´é¾„ã€ç§æ—ç­‰ã€‚è¿™æ ·ï¼Œåœ¨æ„å»ºäº§å“æ—¶ï¼Œç‰¹åˆ«æ˜¯åœ¨è®­ç»ƒAIç³»ç»Ÿæ—¶ï¼Œä»–ä»¬å°±èƒ½ç¡®ä¿ä¸æ˜¯ä»…ä»ä»–ä»¬è‡ªå·±çš„è§†è§’å‡ºå‘ï¼Œè€Œæ˜¯ä»ç»ˆç«¯ç”¨æˆ·çš„è§†è§’å‡ºå‘ã€‚ç„¶è€Œï¼Œé‰´äºå›ºæœ‰çš„äººç±»åè§ï¼Œåº”å¯¹è¿™ç§æƒ…å†µçš„æœ€ä½³æ–¹æ³•æ˜¯ç¡®ä¿æ„å»ºäº§å“çš„å·¥ç¨‹å¸ˆçš„äººå£ä»£è¡¨æ€§ä¸ç»ˆç«¯ç”¨æˆ·çš„ä»£è¡¨æ€§ç›¸ä¼¼ã€‚
- en: '**Malicious users**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ¶æ„ç”¨æˆ·**'
- en: The previous aspect is overall unintentional but there can be malicious intents
    too. In such cases, there is an even higher risk to create models that do not
    meet the expectations. Orchestrated attacks do exist, especially against big tech
    companies, and they can now happen during the training phase making even greater
    negative impacts on the AI systems of interest.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹‹å‰çš„æ–¹é¢æ€»ä½“ä¸Šæ˜¯æ— æ„çš„ï¼Œä½†ä¹Ÿå¯èƒ½å­˜åœ¨æ¶æ„æ„å›¾ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåˆ›å»ºä¸ç¬¦åˆé¢„æœŸçš„æ¨¡å‹çš„é£é™©æ›´é«˜ã€‚åè°ƒæ”»å‡»ç¡®å®å­˜åœ¨ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹å¤§ç§‘æŠ€å…¬å¸ï¼Œå®ƒä»¬ç°åœ¨å¯èƒ½åœ¨è®­ç»ƒé˜¶æ®µå‘ç”Ÿï¼Œå¯¹ç›®æ ‡AIç³»ç»Ÿé€ æˆæ›´å¤§çš„è´Ÿé¢å½±å“ã€‚
- en: '**Overall bad quality labels despite clear instructions**'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**å°½ç®¡æœ‰æ˜ç¡®çš„æŒ‡ç¤ºï¼Œä½†æ•´ä½“ä¸Šæ ‡ç­¾è´¨é‡å·®**'
- en: If instructions are always shared with labelers, there can be misalignment between
    the task and its execution. For example, in the figure below, one can note the
    instructions to summarize a text. They need to be as clear as possible, in a way
    that they align with the way data is processed and fed to the AI itself. However,
    despite that, we can find some bad quality human outputs.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæŒ‡ä»¤æ€»æ˜¯ä¸æ ‡æ³¨è€…å…±äº«ï¼Œä»»åŠ¡ä¸å…¶æ‰§è¡Œä¹‹é—´å¯èƒ½ä¼šå‡ºç°ä¸ä¸€è‡´ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸‹å›¾ä¸­ï¼Œå¯ä»¥æ³¨æ„åˆ°æ€»ç»“æ–‡æœ¬çš„æŒ‡ä»¤ã€‚å®ƒä»¬éœ€è¦å°½å¯èƒ½æ¸…æ™°ï¼Œä»¥ä¾¿ä¸æ•°æ®å¤„ç†å’Œä¼ é€’ç»™ AI
    çš„æ–¹å¼ä¿æŒä¸€è‡´ã€‚ç„¶è€Œï¼Œå°½ç®¡å¦‚æ­¤ï¼Œæˆ‘ä»¬ä»ç„¶å¯ä»¥å‘ç°ä¸€äº›è´¨é‡è¾ƒå·®çš„äººç±»è¾“å‡ºã€‚
- en: '![](../Images/21126fca206e3ef21ce825f764c0479a.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/21126fca206e3ef21ce825f764c0479a.png)'
- en: '**Resource**: Adapted from Figure 2, [https://arxiv.org/pdf/2306.07899.pdf](https://arxiv.org/pdf/2306.07899.pdf).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**èµ„æº**ï¼šæ”¹ç¼–è‡ªå›¾2ï¼Œ[https://arxiv.org/pdf/2306.07899.pdf](https://arxiv.org/pdf/2306.07899.pdf)ã€‚'
- en: This can constitute an actual risk, especially when there are time constraints
    to push an AI into production.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯èƒ½æ„æˆå®é™…é£é™©ï¼Œç‰¹åˆ«æ˜¯å½“æœ‰æ—¶é—´é™åˆ¶è¿«ä½¿ AI æ¨å‘ç”Ÿäº§æ—¶ã€‚
- en: For example, contractors improving **Google**â€™s Bard chatbot shared they have
    been asked to prioritize working fast over quality due to time constraints. Therefore,
    this could [potentially lead to inaccurate information being generated.](https://www.theregister.com/2023/06/21/google_bard_trainers/)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæ”¹è¿›**è°·æ­Œ** Bard èŠå¤©æœºå™¨äººçš„æ‰¿åŒ…å•†è¡¨ç¤ºï¼Œç”±äºæ—¶é—´é™åˆ¶ï¼Œä»–ä»¬è¢«è¦æ±‚ä¼˜å…ˆè€ƒè™‘å·¥ä½œé€Ÿåº¦è€Œéè´¨é‡ã€‚å› æ­¤ï¼Œè¿™å¯èƒ½[å¯¼è‡´ç”Ÿæˆä¸å‡†ç¡®çš„ä¿¡æ¯ã€‚](https://www.theregister.com/2023/06/21/google_bard_trainers/)
- en: â€œYou can be given just two minutes for something that would actually take 15
    minutes to verifyâ€ from [The Register.](https://www.theregister.com/2023/06/21/google_bard_trainers/)
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œä½ å¯èƒ½åªä¼šè¢«ç»™åˆ°ä¸¤åˆ†é’Ÿæ—¶é—´æ¥å®Œæˆå®é™…ä¸Šéœ€è¦15åˆ†é’Ÿæ¥éªŒè¯çš„ä»»åŠ¡â€æ¥è‡ª[The Registerã€‚](https://www.theregister.com/2023/06/21/google_bard_trainers/)
- en: A solution
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è§£å†³æ–¹æ¡ˆ
- en: 'In **computer vision**, a similar space as in NLP, we have already observed
    issues due to biased training data. Face-Depixelizer, a model based on â€œPULSE:
    Self-Supervised photo upsampling via latent space exploration of generative modelsâ€
    was released in 2020 and could output the original picture from a pixelized version
    of it. More rigorously, it would output the closest known de-pixelized picture.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 'åœ¨**è®¡ç®—æœºè§†è§‰**è¿™ä¸€ä¸è‡ªç„¶è¯­è¨€å¤„ç†ç›¸ä¼¼çš„é¢†åŸŸï¼Œæˆ‘ä»¬å·²ç»è§‚å¯Ÿåˆ°ç”±äºåè§è®­ç»ƒæ•°æ®è€Œäº§ç”Ÿçš„é—®é¢˜ã€‚Face-Depixelizer æ˜¯åŸºäºâ€œPULSE:
    Self-Supervised photo upsampling via latent space exploration of generative modelsâ€æ¨¡å‹çš„ï¼Œäº2020å¹´å‘å¸ƒï¼Œèƒ½å¤Ÿä»åƒç´ åŒ–ç‰ˆæœ¬ä¸­è¾“å‡ºåŸå§‹å›¾ç‰‡ã€‚æ›´ä¸¥æ ¼åœ°è¯´ï¼Œå®ƒä¼šè¾“å‡ºæœ€æ¥è¿‘çš„å·²çŸ¥å»åƒç´ åŒ–å›¾ç‰‡ã€‚'
- en: However, due to bias, involving the risks outlined above, it led to issues with
    black faces, which constitute in practice a subset unknown by the model.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œç”±äºåè§å’Œä¸Šè¿°é£é™©ï¼Œå¯¼è‡´äº†å¯¹é»‘äººé¢å­”çš„é—®é¢˜ï¼Œè¿™å®é™…ä¸Šæ„æˆäº†æ¨¡å‹æœªçŸ¥çš„å­é›†ã€‚
- en: '![](../Images/491d87ae686e56a6edfe6f6e526904d5.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/491d87ae686e56a6edfe6f6e526904d5.png)'
- en: '**Resource**: Generated by the **author**. PULSE gets a very distant picture
    as a reconstruction of the pixelized output. This is due to biased training data.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**èµ„æº**ï¼šç”±**ä½œè€…**ç”Ÿæˆã€‚PULSE è·å–äº†ä¸€ä¸ªéå¸¸è¿œçš„å›¾ç‰‡ä½œä¸ºåƒç´ åŒ–è¾“å‡ºçš„é‡å»ºã€‚è¿™æ˜¯ç”±äºåè§è®­ç»ƒæ•°æ®é€ æˆçš„ã€‚'
- en: In [an article I shared in TDS](https://medium.com/towards-data-science/the-danger-of-bias-in-ai-c3ce68eabbcc),
    I highlighted a great explanation of this phenomenon given by Yann Lecun. It demystifies
    the way AI works and how much it relies on training data. Hence, we understand
    the utmost importance of following clear instructions with the idea of having
    great quality training data.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨[æˆ‘åœ¨ TDS åˆ†äº«çš„ä¸€ç¯‡æ–‡ç« ä¸­](https://medium.com/towards-data-science/the-danger-of-bias-in-ai-c3ce68eabbcc)ï¼Œæˆ‘å¼ºè°ƒäº†
    Yann Lecun å¯¹è¿™ä¸€ç°è±¡çš„ç²¾å½©è§£é‡Šã€‚å®ƒæ­ç¤ºäº† AI çš„å·¥ä½œæ–¹å¼åŠå…¶å¯¹è®­ç»ƒæ•°æ®çš„ä¾èµ–ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ç†è§£éµå¾ªæ¸…æ™°æŒ‡ä»¤å’Œæ‹¥æœ‰é«˜è´¨é‡è®­ç»ƒæ•°æ®çš„æç«¯é‡è¦æ€§ã€‚
- en: '*Lecun explains in a tweet that â€œML systems are biased when data is biased.
    This face upsampling system makes everyone look white because the network was
    pretrained on FlickFaceHQ, which mainly contains white people pics. Train the*
    ***exact*** *same system on a dataset from Senegal and everyone will look African.â€*'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Lecun åœ¨æ¨ç‰¹ä¸Šè§£é‡Šè¯´ï¼šâ€œå½“æ•°æ®æœ‰åè§æ—¶ï¼Œæœºå™¨å­¦ä¹ ç³»ç»Ÿä¹Ÿä¼šæœ‰åè§ã€‚è¿™ä¸ªé¢å­”ä¸Šé‡‡æ ·ç³»ç»Ÿè®©æ¯ä¸ªäººçœ‹èµ·æ¥éƒ½æ˜¯ç™½äººï¼Œå› ä¸ºç½‘ç»œæ˜¯åœ¨ä¸»è¦åŒ…å«ç™½äººå›¾ç‰‡çš„ FlickFaceHQ
    ä¸Šè¿›è¡Œé¢„è®­ç»ƒçš„ã€‚å¯¹ä¸€ä¸ªæ¥è‡ªå¡å†…åŠ å°”çš„æ•°æ®é›†è¿›è¡Œ* ***å®Œå…¨ç›¸åŒçš„*** *è®­ç»ƒï¼Œå¤§å®¶éƒ½ä¼šçœ‹èµ·æ¥æ˜¯éæ´²äººã€‚â€*'
- en: '**Create a system by sampling high-quality training data**'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**é€šè¿‡é‡‡æ ·é«˜è´¨é‡è®­ç»ƒæ•°æ®æ¥åˆ›å»ºç³»ç»Ÿ**'
- en: One solution to avoid that, following Lecunâ€™s explanation is to have an objective
    system focusing on the quality of the training data. This system should make sure
    the quality is aligned with the task at hand. For example, with Face-Depixeliser,
    the training set should contain faces from the entire population, including back
    people.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: é¿å…è¿™ä¸€ç‚¹çš„ä¸€ä¸ªè§£å†³æ–¹æ¡ˆï¼ŒæŒ‰ç…§ Lecun çš„è§£é‡Šï¼Œæ˜¯æ‹¥æœ‰ä¸€ä¸ªä¸“æ³¨äºè®­ç»ƒæ•°æ®è´¨é‡çš„å®¢è§‚ç³»ç»Ÿã€‚è¿™ä¸ªç³»ç»Ÿåº”ç¡®ä¿è´¨é‡ä¸å½“å‰ä»»åŠ¡å¯¹é½ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨ Face-Depixeliser
    æ—¶ï¼Œè®­ç»ƒé›†åº”åŒ…å«æ¥è‡ªæ•´ä¸ªç¾¤ä½“çš„é¢å­”ï¼ŒåŒ…æ‹¬é»‘äººã€‚
- en: 'However, as I have outlined in another article, such a system is not easy to
    put in place. Indeed, evaluating that your dataset is diverse enough is not a
    trivial task at all in many cases. Though, one question to always have in mind
    could be as follows: â€œ**Is my data representing my population of interest?**â€.
    If I am interested in classifying cats and dogs, do I have enough diversity in
    the cats to show all the possible cat breeds? This is the same for new hires:
    if the company is defending diversity and inclusion, is the population of interest
    diverse enough in terms of age, education, gender, sexual preferences, etc?'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œæ­£å¦‚æˆ‘åœ¨å¦ä¸€ç¯‡æ–‡ç« ä¸­æ¦‚è¿°çš„é‚£æ ·ï¼Œè¿™æ ·çš„ç³»ç»Ÿå¹¶ä¸å®¹æ˜“å»ºç«‹ã€‚ç¡®å®ï¼Œè¯„ä¼°ä½ çš„æ•°æ®é›†æ˜¯å¦è¶³å¤Ÿå¤šæ ·åŒ–åœ¨è®¸å¤šæƒ…å†µä¸‹å¹¶éæ˜“äº‹ã€‚ä¸è¿‡ï¼Œä¸€ä¸ªå§‹ç»ˆè¦ç‰¢è®°çš„é—®é¢˜å¯èƒ½æ˜¯ï¼šâ€œ**æˆ‘çš„æ•°æ®æ˜¯å¦ä»£è¡¨äº†æˆ‘æ„Ÿå…´è¶£çš„ç¾¤ä½“ï¼Ÿ**â€å¦‚æœæˆ‘å¯¹åˆ†ç±»çŒ«å’Œç‹—æ„Ÿå…´è¶£ï¼Œæˆ‘æ˜¯å¦åœ¨çŒ«çš„æ ·æœ¬ä¸­æœ‰è¶³å¤Ÿçš„å¤šæ ·æ€§æ¥å±•ç¤ºæ‰€æœ‰å¯èƒ½çš„çŒ«å“ç§ï¼Ÿå¯¹äºæ–°å‘˜å·¥ä¹Ÿæ˜¯å¦‚æ­¤ï¼šå¦‚æœå…¬å¸å€¡å¯¼å¤šæ ·æ€§å’ŒåŒ…å®¹æ€§ï¼Œé‚£ä¹ˆæ„Ÿå…´è¶£çš„ç¾¤ä½“åœ¨å¹´é¾„ã€æ•™è‚²ã€æ€§åˆ«ã€æ€§å–å‘ç­‰æ–¹é¢æ˜¯å¦è¶³å¤Ÿå¤šæ ·åŒ–ï¼Ÿ
- en: A simplistic approach consists in having a system focusing on sampling accurately.
    Indeed, one could think of a Sampling Model as an important model in the ML pipeline.
    Such a model allows a better representation of the underlying population by correctly
    sampling from the source data. The figure below shows how it could be integrated
    into an ML pipeline.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ç§ç®€åŒ–çš„æ–¹æ³•æ˜¯æ‹¥æœ‰ä¸€ä¸ªä¸“æ³¨äºå‡†ç¡®é‡‡æ ·çš„ç³»ç»Ÿã€‚ç¡®å®ï¼Œäººä»¬å¯ä»¥å°†é‡‡æ ·æ¨¡å‹è§†ä¸º ML ç®¡é“ä¸­çš„ä¸€ä¸ªé‡è¦æ¨¡å‹ã€‚è¿™æ ·çš„æ¨¡å‹é€šè¿‡æ­£ç¡®åœ°ä»æºæ•°æ®ä¸­é‡‡æ ·ï¼Œå…è®¸å¯¹åŸºç¡€ç¾¤ä½“è¿›è¡Œæ›´å¥½çš„è¡¨å¾ã€‚ä¸‹å›¾å±•ç¤ºäº†å®ƒå¦‚ä½•è¢«é›†æˆåˆ°
    ML ç®¡é“ä¸­ã€‚
- en: '![](../Images/57d0b3ab2391bc61b95190be7f791d7b.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/57d0b3ab2391bc61b95190be7f791d7b.png)'
- en: '**Resource**: From the **author**. Simplistic (top) vs Intelligent Sampling
    Model (bottom). The first step in the above pipeline consists of random sampling
    from the source data and getting a classic 80% training data and 20% testing data.
    The first step in the bottom pipeline focuses on key features to help ensure diversity
    in your data. For example, gender could be a key feature based on the model represented
    in Figure 2\. Once we have provided a reasonable distribution of gender, we can
    then sample from this filtered dataset and get a training and a testing dataset.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**èµ„æº**ï¼šæ¥è‡ª**ä½œè€…**ã€‚ç®€åŒ–ï¼ˆé¡¶éƒ¨ï¼‰ä¸æ™ºèƒ½é‡‡æ ·æ¨¡å‹ï¼ˆåº•éƒ¨ï¼‰ã€‚ä¸Šé¢çš„ç®¡é“ä¸­çš„ç¬¬ä¸€æ­¥æ˜¯ä»æºæ•°æ®ä¸­éšæœºæŠ½æ ·ï¼Œå¹¶è·å–ç»å…¸çš„ 80% è®­ç»ƒæ•°æ®å’Œ 20%
    æµ‹è¯•æ•°æ®ã€‚åº•éƒ¨ç®¡é“ä¸­çš„ç¬¬ä¸€æ­¥åˆ™å…³æ³¨å…³é”®ç‰¹å¾ï¼Œä»¥å¸®åŠ©ç¡®ä¿æ•°æ®çš„å¤šæ ·æ€§ã€‚ä¾‹å¦‚ï¼Œæ€§åˆ«å¯èƒ½æ˜¯åŸºäºå›¾ 2 ä¸­æ‰€ç¤ºæ¨¡å‹çš„å…³é”®ç‰¹å¾ã€‚ä¸€æ—¦æˆ‘ä»¬æä¾›äº†åˆç†çš„æ€§åˆ«åˆ†å¸ƒï¼Œæˆ‘ä»¬å°±å¯ä»¥ä»è¿™ä¸ªè¿‡æ»¤åçš„æ•°æ®é›†ä¸­æŠ½æ ·ï¼Œå¹¶å¾—åˆ°ä¸€ä¸ªè®­ç»ƒæ•°æ®é›†å’Œä¸€ä¸ªæµ‹è¯•æ•°æ®é›†ã€‚'
- en: An â€œIntelligent Sampling Modelâ€ (ISM) can be seen as a function that takes key
    features such as gender and age, as well as the expected distribution of those
    features in the underlying population, into account. Then, based on that, the
    ISM can sample from the source data and make sure the expected distributions are
    closely represented in the sampled data. The figure below shows the generic idea
    behind ISM, for a simple use case.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: â€œæ™ºèƒ½é‡‡æ ·æ¨¡å‹â€ï¼ˆISMï¼‰å¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªè€ƒè™‘æ€§åˆ«å’Œå¹´é¾„ç­‰å…³é”®ç‰¹å¾ï¼Œä»¥åŠè¿™äº›ç‰¹å¾åœ¨åŸºç¡€äººå£ä¸­é¢„æœŸåˆ†å¸ƒçš„å‡½æ•°ã€‚ç„¶åï¼ŒåŸºäºæ­¤ï¼ŒISM å¯ä»¥ä»æºæ•°æ®ä¸­æŠ½æ ·ï¼Œå¹¶ç¡®ä¿é¢„æœŸçš„åˆ†å¸ƒåœ¨æŠ½æ ·æ•°æ®ä¸­å¾—åˆ°ç´§å¯†ä½“ç°ã€‚ä¸‹å›¾å±•ç¤ºäº†
    ISM çš„é€šç”¨æ€æƒ³ï¼Œç”¨äºä¸€ä¸ªç®€å•çš„ä½¿ç”¨æ¡ˆä¾‹ã€‚
- en: '![](../Images/f7783db3b398649acc9c9b17d1f578d4.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f7783db3b398649acc9c9b17d1f578d4.png)'
- en: '**Resource**: From the **author**. The generic idea behind ISM. ISM allows
    you to sample from source data following some predefined requirements based on
    key features such as Gender. In this example, the user sets a prior on the Gender
    and ISM makes sure such distribution is closely represented in its output. We
    go from a distribution of 70% male, 30% female to a distribution of 52% male and
    48% female.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**èµ„æº**ï¼šæ¥è‡ª**ä½œè€…**ã€‚ISM çš„é€šç”¨æ€æƒ³ã€‚ISM å…è®¸ä½ ä»æºæ•°æ®ä¸­æŠ½æ ·ï¼Œéµå¾ªåŸºäºæ€§åˆ«ç­‰å…³é”®ç‰¹å¾çš„æŸäº›é¢„å®šä¹‰è¦æ±‚ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œç”¨æˆ·å¯¹æ€§åˆ«è®¾ç½®äº†å…ˆéªŒï¼ŒISM
    ç¡®ä¿è¿™ç§åˆ†å¸ƒåœ¨è¾“å‡ºä¸­å¾—åˆ°äº†ç´§å¯†ä½“ç°ã€‚æˆ‘ä»¬å°†ä» 70% ç”·æ€§ï¼Œ30% å¥³æ€§çš„åˆ†å¸ƒï¼Œè½¬å˜ä¸º 52% ç”·æ€§å’Œ 48% å¥³æ€§çš„åˆ†å¸ƒã€‚'
- en: 2\. **Create a system to detect risks of AI-generated data**
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. **åˆ›å»ºä¸€ä¸ªæ£€æµ‹ AI ç”Ÿæˆæ•°æ®é£é™©çš„ç³»ç»Ÿ**
- en: '[Veselovsky, V., Ribeiro, M.H. and West, R.](https://arxiv.org/pdf/2306.07899.pdf)
    go into detail on architecting a model that is capable of detecting AI-generated
    training data. Their methodology for detecting synthetic text allows us to ensure
    that we can rely on the training data outsourced to humans.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[Veselovsky, V., Ribeiro, M.H. å’Œ West, R.](https://arxiv.org/pdf/2306.07899.pdf)è¯¦ç»†ä»‹ç»äº†æ„å»ºèƒ½å¤Ÿæ£€æµ‹AIç”Ÿæˆè®­ç»ƒæ•°æ®çš„æ¨¡å‹ã€‚ä»–ä»¬çš„æ£€æµ‹åˆæˆæ–‡æœ¬çš„æ–¹æ³•ä½¿æˆ‘ä»¬èƒ½å¤Ÿç¡®ä¿æˆ‘ä»¬å¯ä»¥ä¾èµ–äºå¤–åŒ…ç»™äººç±»çš„è®­ç»ƒæ•°æ®ã€‚'
- en: This classifier is an e5-base pre-trained model (Wang et al., 2022) fine-tuned
    on the specific dataset from MTurk. Its role is to classify whether a given text
    is generated from Chat GPT or an actual human.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥åˆ†ç±»å™¨æ˜¯ä¸€ä¸ªe5-baseé¢„è®­ç»ƒæ¨¡å‹ï¼ˆWangç­‰ï¼Œ2022ï¼‰ï¼Œç»è¿‡åœ¨MTurkç‰¹å®šæ•°æ®é›†ä¸Šçš„å¾®è°ƒã€‚å®ƒçš„ä½œç”¨æ˜¯åˆ†ç±»ç»™å®šçš„æ–‡æœ¬æ˜¯å¦ç”±Chat GPTç”Ÿæˆï¼Œè¿˜æ˜¯ç”±çœŸæ­£çš„äººç±»ç”Ÿæˆã€‚
- en: Surprisingly their research shows that it is not a negligible phenomenon as
    their classifier successfully detected a large amount of LLM-generated input.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œä»–ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼Œè¿™å¹¶ä¸æ˜¯ä¸€ä¸ªå¯ä»¥å¿½è§†çš„ç°è±¡ï¼Œå› ä¸ºä»–ä»¬çš„åˆ†ç±»å™¨æˆåŠŸåœ°æ£€æµ‹åˆ°äº†å¤§é‡ç”±LLMç”Ÿæˆçš„è¾“å…¥ã€‚
- en: â€œWe conclude that, although LLMs are still in their infancy, textual data collected
    via crowdsourcing is already produced to a large extent by machines, rather than
    by the hired human crowd workers.â€ [Veselovsky, V., Ribeiro, M.H. and West, R.](https://arxiv.org/pdf/2306.07899.pdf)
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œæˆ‘ä»¬å¾—å‡ºç»“è®ºï¼Œå°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»å¤„äºåˆæœŸé˜¶æ®µï¼Œä½†é€šè¿‡ä¼—åŒ…æ”¶é›†çš„æ–‡æœ¬æ•°æ®åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šæ˜¯ç”±æœºå™¨ç”Ÿæˆçš„ï¼Œè€Œéç”±é›‡ä½£çš„äººå·¥ä¼—åŒ…å·¥ä½œè€…ç”Ÿæˆçš„ã€‚â€ [Veselovsky,
    V., Ribeiro, M.H. å’Œ West, R.](https://arxiv.org/pdf/2306.07899.pdf)
- en: Conclusion
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: This article has shown that, in the quest to achieve the highest AI performance,
    a lot of companies delegate the training and enhancement of their AI models to
    vendors. But this can backfire, as some vendors may either do a **bad job** or
    **cheat by employing another AI to do the task**, due to various factors. This
    leads to many hazards, some of which we examined in this article. In essence,
    biasing our AI tools can have a **huge impact on our society, in ways we may not
    foresee, especially now given the current popularity of large language models.**
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç¯‡æ–‡ç« è¡¨æ˜ï¼Œåœ¨è¿½æ±‚æœ€é«˜äººå·¥æ™ºèƒ½æ€§èƒ½çš„è¿‡ç¨‹ä¸­ï¼Œè®¸å¤šå…¬å¸å°†å…¶äººå·¥æ™ºèƒ½æ¨¡å‹çš„è®­ç»ƒå’Œå¢å¼ºå·¥ä½œå§”æ‰˜ç»™ä¾›åº”å•†ã€‚ä½†è¿™å¯èƒ½ä¼šé€‚å¾—å…¶åï¼Œå› ä¸ºä¸€äº›ä¾›åº”å•†å¯èƒ½ä¼šç”±äºå„ç§å› ç´ è€Œ**åšå¾—å¾ˆç³Ÿ**æˆ–**é€šè¿‡ä½¿ç”¨å¦ä¸€ç§äººå·¥æ™ºèƒ½æ¥å®Œæˆä»»åŠ¡è¿›è¡Œä½œå¼Š**ã€‚è¿™å¸¦æ¥äº†è®¸å¤šé£é™©ï¼Œå…¶ä¸­ä¸€äº›åœ¨æœ¬æ–‡ä¸­è¿›è¡Œäº†æ¢è®¨ã€‚ä»æœ¬è´¨ä¸Šè®²ï¼Œåå‘æˆ‘ä»¬çš„äººå·¥æ™ºèƒ½å·¥å…·å¯èƒ½å¯¹æˆ‘ä»¬çš„ç¤¾ä¼šäº§ç”Ÿ**å·¨å¤§çš„å½±å“ï¼Œå¯èƒ½æ˜¯æˆ‘ä»¬æ— æ³•é¢„è§çš„ï¼Œç‰¹åˆ«æ˜¯åœ¨å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹æµè¡Œçš„æƒ…å†µä¸‹ã€‚**
- en: ğŸ‘‹ One last thing â€”want to connect?
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸ‘‹ æœ€åä¸€ç‚¹â€”â€”æƒ³è¦è”ç³»ä¸€ä¸‹å—ï¼Ÿ
- en: I am a Data Scientist at Microsoft and an ex-teacher at EPITA Paris. I have
    8 patents in AI and continuously push AI to the edge.
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æˆ‘æ˜¯å¾®è½¯çš„æ•°æ®ç§‘å­¦å®¶ï¼Œä¹Ÿæ˜¯å·´é»EPITAçš„å‰ä»»è®²å¸ˆã€‚æˆ‘æ‹¥æœ‰8é¡¹äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸“åˆ©ï¼Œå¹¶æŒç»­æ¨åŠ¨äººå·¥æ™ºèƒ½çš„å‰æ²¿å‘å±•ã€‚
- en: ''
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I would love you to be among my first1,000 followers.
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æˆ‘å¸Œæœ›ä½ èƒ½æˆä¸ºæˆ‘çš„å‰1,000åå…³æ³¨è€…ä¹‹ä¸€ã€‚
- en: '*Also, follow me on* [*LinkedIn*](https://www.linkedin.com/in/mastafa-foufa-666a1a109/)*.*'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ­¤å¤–ï¼Œè¯·åœ¨* [*LinkedIn*](https://www.linkedin.com/in/mastafa-foufa-666a1a109/)*
    ä¸Šå…³æ³¨æˆ‘ã€‚*'
