- en: Business Analytics with LangChain and LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/business-analytics-with-langchain-and-llms-c8e902446073](https://towardsdatascience.com/business-analytics-with-langchain-and-llms-c8e902446073)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: GENERATIVE AI
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A step-by-step tutorial on querying SQL databases with human language
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://tamimi-naser.medium.com/?source=post_page-----c8e902446073--------------------------------)[![Naser
    Tamimi](../Images/8d43c66ea3c0ef9b49c7d33dbc008c28.png)](https://tamimi-naser.medium.com/?source=post_page-----c8e902446073--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c8e902446073--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c8e902446073--------------------------------)
    [Naser Tamimi](https://tamimi-naser.medium.com/?source=post_page-----c8e902446073--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c8e902446073--------------------------------)
    ·7 min read·Dec 19, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5540ac3aed1e97360f2bf8286e9d3663.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
- en: Image by the author (generated via Midjourney)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Many businesses have a lot of proprietary data stored in their databases. If
    there’s a virtual agent that understands human language and can query these databases,
    it opens up big opportunities for these businesses. Think of customer service
    chatbots, they’re a common example. These agents can take customer requests, ask
    the database for information, and give the customer what they need.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: The benefit of such agents is not limited to external customer interactions.
    Many business owners or people in companies, even in tech companies, might not
    know SQL or similar languages, but they still need to ask the database for information.
    That’s where frameworks like LangChain come in. Such frameworks make it easy to
    create these helpful agents/applications. Agents that can talk to humans and at
    the same time, talk to databases, APIs, and more.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: LLM-backed Applications
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: LangChain is an open-source framework for building interactive applications
    using Large Language Models (LLMs). It’s a tool that helps LLMs connect with other
    sources of information and lets them talk to the world around them. One important
    concept in such frameworks is the Chain. Let’s take a look at this concept.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: What are Chains?
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Chains are advanced tools in this framework that combine LLMs with other tools
    to perform more complicated tasks. Specifically, chains are interfaces that use
    a sequence of LLMs along with other tools, such as SQL databases, API calls, bash
    operators, or math calculators, to complete a complex job. An example could be
    our application receiving input from a user and passing it to our LLM model; then,
    the LLM calls an API. The API responds to the LLM, and the LLM takes the response
    to perform another task, and so on. As you can see, it is a chain of inputs and
    outputs where, in many parts of this sequence, we have LLM models handling the
    situation.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Getting Our Hands Dirty
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now it’s time to get our hands dirty and start coding a simple LLM-backed application.
    For this application, we are going to make a simple Q&A agent that takes our question
    and queries a SQL database to find the answer for us.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Set Up A PostgreSQL Sample Database
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We use [DVD Rental Sample Database](https://www.postgresqltutorial.com/postgresql-getting-started/postgresql-sample-database/)
    from postgresqltutorial.com ([License Information](https://dev.mysql.com/doc/sakila/en/sakila-license.html)).
    To install the database on your local system, you need to have PostgreSQL installed.
    Simply type `*psql*`in your terminal and see if it runs.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Then you should follow the instructions [here](https://www.postgresqltutorial.com/postgresql-getting-started/load-postgresql-sample-database/).
    Here I walk through the database installation with you quickly.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: 'In your terminal launch PostgreSQL via:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You must substitute the `<USERNAME>` with your actual username. Then the system
    asks you about your password. Enter your password and you get into your Postgres
    database.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: First, we should create a database to load all the tables.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: After creating the database, you can check it by typing `*\list*` command, You
    should see your dvdrental database in the returned list. Then simply exit Postgres
    (via `\q`).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we need to download the tables and data. You can download everything as
    a tar file here: [Download DVD Rental Sample Database](https://www.postgresqltutorial.com/wp-content/uploads/2019/05/dvdrental.zip)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Go to the folder that you downloaded the tar file and using pg_restore, we can
    load the tables into our Postgres Database.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Before going further, let’s check if the tables are loaded. Launch Postgres
    via `psql -U <USERNAME>` and enter your password.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Then type the following commands to list tables inside the dvdrental database.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You must see a list of tables like this:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Set Up .env File
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After building the sample database, we need to create a `.env` file. We use
    this file to store our secrets and keys as well as environmental variables. Of
    course, we can put all that information in our code, but we must follow best engineering
    practices even for small projects. An accidental git push can expose our API keys
    and secrets to the public. Here is our `.env` file:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: As you see, you need to get your own OpenAI API key for this test. You can follow
    the instructions [here](https://medium.com/@rithin_9167/how-to-obtain-openai-api-key-30df0b8bd114)
    to obtain an API key from Open AI.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Creating a LangChain Application
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After saving your .env file in your project folder, we can start the actual
    code. First, we import the required libraries into our Python code.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: For this tutorial, I recommend using a Jupyter Notebook to test it step by step.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: We need to import the required libraries at the beginning.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Using load_dotenv(), we load the environment variables that we defined in the
    `.env` file. Now, safely we can access them in the code.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: For our chain, we need a language model with chat capabilities. For simplicity,
    we chose gpt-3.5-turbo from OpenAI which is accessible through the API. You can
    use any other public or private models.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In addition to a model, we need a SQL Database connection. That connection enables
    our chain to query against the database and get the results back. As mentioned
    before, we use a PostgreSQL Database, but according to LangChain, any SQL engine
    with a JDBC connection should be easy to use (e.g. MySQL, Presto, Databricks).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In case you are wondering about `sample_rows_in_table_info` parameter that we
    used in our SQL database connection, Rajkumar et. al showed in their paper ([https://arxiv.org/abs/2204.00498](https://arxiv.org/abs/2204.00498))
    that including a few sample rows from the table increases the performance of the
    model in creating mode affecting querying the data. In LangChain, simply you can
    set `sample_rows_in_table_info` and determine the number of sample rows from each
    table that will be appended to each table description.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: To test the SQL database connection, I printed the list of available tables
    using `db.get_usable_table_names()`. It should return the following list of tables
    for you too.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The next step is the most important one. With our LLM model and a SQL database
    connection, now we should be able to instantiate our chain. Before showing the
    instantiation, let’s get a little bit more sense about a chain.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Now, we are using an SQL chain from LangChain to get a human question, convert
    it to an SQL query, run it on the database, and retrieve the results.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Finally, we use the `run()` method to pass our input/question to the chain and
    get the final response back.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Now it is time to test our code. We start with a simple query that requires
    querying a single table.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The chain gets our human-style query and converts it into an SQL query first.
    Then using the SQL DB connection, it runs the SQL query on the database. The returned
    response provides context for the LLM and along with the human original query,
    triggers a response. In this case, you can see the final response:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: First, since the `verbose=True` (where we defined the db_chain) we get more
    information about the constructed SQL query and the returned SQL results. If you
    turn off the verbose, you only see the final results (highlighted with the boldface).
    The final answer shows correctly that the average length of films released in
    2006 is 115.272 minutes (you can verify it with your own SQL query on Postgres).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，由于 `verbose=True`（我们在其中定义了 db_chain），我们可以获得更多关于构建的 SQL 查询和返回的 SQL 结果的信息。如果你关闭
    verbose，你只能看到最终结果（用粗体标记）。最终答案正确显示了2006年上映的电影的平均时长是115.272分钟（你可以在 Postgres 上使用你自己的
    SQL 查询进行验证）。
- en: The second question is a little bit more complicated and requires joining three
    tables.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个问题稍微复杂一些，需要连接三个表。
- en: '[PRE15]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The question asks about the actor who played in movies that their total length
    is more than any other actors. This question requires joining three tables: actor,
    film_actor, and film. Here is the chain response:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题询问的是在电影总时长超过其他任何演员的演员。这个问题需要连接三个表：actor、film_actor 和 film。以下是链响应：
- en: '[PRE16]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: As you see, our super-simple LangChain application did a good job of understanding
    the relationships between these tables and constructing the SQL query.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们超简单的 LangChain 应用成功地理解了这些表之间的关系，并构建了 SQL 查询。
- en: Summary
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this article, we introduced a powerful open-source tool called LangChain
    that enables us to build LLM-based applications.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们介绍了一款强大的开源工具，叫做 LangChain，它使我们能够构建基于 LLM 的应用程序。
- en: Then we used SQLDatabaseChain to build an application that queries a SQL database
    based on user questions and returns the results.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用 SQLDatabaseChain 构建了一个应用程序，该应用程序根据用户的问题查询 SQL 数据库并返回结果。
- en: This simple Q&A application can be expanded into a more complex business analytics
    assistant that anyone inside a business can use daily to get the latest insights
    from the proprietary data.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的问答应用可以扩展成一个更复杂的业务分析助手，供企业内部的任何人每天使用，从专有数据中获取最新的洞察。
