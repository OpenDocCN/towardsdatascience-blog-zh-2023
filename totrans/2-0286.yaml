- en: An AI-Powered Analysis of our Postal Service Through Tweets
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é€šè¿‡æ¨æ–‡å¯¹æˆ‘ä»¬é‚®æ”¿æœåŠ¡çš„AIé©±åŠ¨åˆ†æ
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/an-ai-powered-analysis-of-our-postal-service-through-tweets-fa1764409905](https://towardsdatascience.com/an-ai-powered-analysis-of-our-postal-service-through-tweets-fa1764409905)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/an-ai-powered-analysis-of-our-postal-service-through-tweets-fa1764409905](https://towardsdatascience.com/an-ai-powered-analysis-of-our-postal-service-through-tweets-fa1764409905)
- en: Deciphering Customer Voices with AI
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç”¨AIè§£ç å®¢æˆ·å£°éŸ³
- en: Delving into Machine Learning, Topic Modeling, and Sentiment Analysis to Uncover
    Valuable Customer Perspectives
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ·±å…¥æ¢è®¨æœºå™¨å­¦ä¹ ã€ä¸»é¢˜å»ºæ¨¡å’Œæƒ…æ„Ÿåˆ†æï¼Œä»¥æ­ç¤ºæœ‰ä»·å€¼çš„å®¢æˆ·è§‚ç‚¹
- en: '[](https://johnadeojo.medium.com/?source=post_page-----fa1764409905--------------------------------)[![John
    Adeojo](../Images/f6460fae462b055d36dce16fefcd142c.png)](https://johnadeojo.medium.com/?source=post_page-----fa1764409905--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fa1764409905--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fa1764409905--------------------------------)
    [John Adeojo](https://johnadeojo.medium.com/?source=post_page-----fa1764409905--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://johnadeojo.medium.com/?source=post_page-----fa1764409905--------------------------------)[![John
    Adeojo](../Images/f6460fae462b055d36dce16fefcd142c.png)](https://johnadeojo.medium.com/?source=post_page-----fa1764409905--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fa1764409905--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fa1764409905--------------------------------)
    [John Adeojo](https://johnadeojo.medium.com/?source=post_page-----fa1764409905--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fa1764409905--------------------------------)
    Â·13 min readÂ·Mar 22, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fa1764409905--------------------------------)
    Â·13åˆ†é’Ÿé˜…è¯»Â·2023å¹´3æœˆ22æ—¥
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/3ca21fa5a67996b27ed77e77c334b936.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3ca21fa5a67996b27ed77e77c334b936.png)'
- en: 'Image by Author: AI generated sentiment and topic for #royalmail'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 'å›¾ç‰‡ä½œè€…ï¼šAIç”Ÿæˆçš„æƒ…æ„Ÿå’Œä¸»é¢˜åˆ†æ #royalmail'
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»‹ç»
- en: My partner and I usually experience an excellent postal service. Most of the
    time letters arrive to our home un-opened and delivered in a timely fashion. Thatâ€™s
    why when our post didnâ€™t arrive for a few weeks we thought it was quite strange.
    After some diligent web searching, we discovered the most likely cause to this
    service disruption was strikes. As a data scientist this whole episode got me
    thinkingâ€¦
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å’Œæˆ‘çš„æ­æ¡£é€šå¸¸ä½“éªŒåˆ°ä¼˜è´¨çš„é‚®æ”¿æœåŠ¡ã€‚å¤§å¤šæ•°æ—¶å€™ï¼Œä¿¡ä»¶ä¼šåŠæ—¶åˆ°è¾¾æˆ‘ä»¬å®¶ï¼Œå¹¶ä¸”æ²¡æœ‰è¢«æ‹†å¼€ã€‚å› æ­¤ï¼Œå½“æˆ‘ä»¬çš„é‚®ä»¶å‡ å‘¨æ²¡åˆ°æ—¶ï¼Œæˆ‘ä»¬è§‰å¾—éå¸¸å¥‡æ€ªã€‚åœ¨ç»è¿‡ä¸€ç•ªè®¤çœŸçš„ç½‘ç»œæœç´¢åï¼Œæˆ‘ä»¬å‘ç°è¿™æ¬¡æœåŠ¡ä¸­æ–­æœ€å¯èƒ½çš„åŸå› æ˜¯ç½¢å·¥ã€‚ä½œä¸ºæ•°æ®ç§‘å­¦å®¶ï¼Œè¿™æ•´ä¸ªäº‹ä»¶è®©æˆ‘å¼€å§‹æ€è€ƒâ€¦â€¦
- en: Is there a way to leverage online data to track these types of incidents?
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ˜¯å¦æœ‰åŠæ³•åˆ©ç”¨åœ¨çº¿æ•°æ®è¿½è¸ªè¿™äº›ç±»å‹çš„äº‹ä»¶ï¼Ÿ
- en: The answer to this question is yes, and I have already built a prototype which
    is available for you to play with. I recommend doing so before reading on as it
    will give you a feel for things before getting into the technical details.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹è¿™ä¸ªé—®é¢˜çš„å›ç­”æ˜¯è‚¯å®šçš„ï¼Œæˆ‘å·²ç»æ„å»ºäº†ä¸€ä¸ªåŸå‹ï¼Œä½ å¯ä»¥è¯•ç©ä¸€ä¸‹ã€‚æˆ‘å»ºè®®åœ¨ç»§ç»­é˜…è¯»ä¹‹å‰å…ˆè¯•ç”¨ä¸€ä¸‹ï¼Œè¿™æ ·å¯ä»¥è®©ä½ åœ¨è¿›å…¥æŠ€æœ¯ç»†èŠ‚ä¹‹å‰å¯¹äº‹ç‰©æœ‰ä¸€ä¸ªäº†è§£ã€‚
- en: ğŸŒ [Explore the m(app)](https://john-adeojo-royalmail-dash-scriptsstreamlitstreamlit-rm-o2f2wo.streamlit.app/)
    â€” This is best opened on a computer, although it will work on a mobile phone.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸŒ [æ¢ç´¢åº”ç”¨](https://john-adeojo-royalmail-dash-scriptsstreamlitstreamlit-rm-o2f2wo.streamlit.app/)
    â€” æœ€å¥½åœ¨ç”µè„‘ä¸Šæ‰“å¼€ï¼Œå°½ç®¡æ‰‹æœºä¹Ÿèƒ½ä½¿ç”¨ã€‚
- en: Iâ€™ll spend the remainder of this write up walking you through how I went about
    answering this question. This is pretty much an end to end machine learning project
    exploring aspects of software engineering, social media data mining, topic modelling,
    transformers, custom loss functions, transfer learning, and data visualisation.
    If that sounds interesting to you at all grab a snack or a drink and get comfortable
    because this might be quite a long one but hopefully worth the read.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†åœ¨è¿™ç¯‡æ–‡ç« çš„å‰©ä½™éƒ¨åˆ†å¸¦ä½ äº†è§£æˆ‘æ˜¯å¦‚ä½•å›ç­”è¿™ä¸ªé—®é¢˜çš„ã€‚è¿™å‡ ä¹æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„æœºå™¨å­¦ä¹ é¡¹ç›®ï¼Œæ¶‰åŠè½¯ä»¶å·¥ç¨‹ã€ç¤¾äº¤åª’ä½“æ•°æ®æŒ–æ˜ã€ä¸»é¢˜å»ºæ¨¡ã€å˜å‹å™¨ã€è‡ªå®šä¹‰æŸå¤±å‡½æ•°ã€è¿ç§»å­¦ä¹ å’Œæ•°æ®å¯è§†åŒ–ç­‰æ–¹é¢ã€‚å¦‚æœè¿™äº›å¯¹ä½ æœ‰å¸å¼•åŠ›ï¼Œæ‹¿ä¸ªå°åƒæˆ–é¥®æ–™ï¼Œåä¸‹æ¥ï¼Œå› ä¸ºè¿™å¯èƒ½ä¼šæ¯”è¾ƒé•¿ï¼Œä½†å¸Œæœ›å€¼å¾—ä¸€è¯»ã€‚
- en: '**Disclaimer***: This article is an independent analysis of tweets containing
    the #royalmail hashtag and is not affiliated with, endorsed, or sponsored by Royal
    Mail Group Ltd. The opinions and findings expressed within this article are solely
    those of the author and do not represent the views or official positions of Royal
    Mail Group Ltd or any of its subsidiaries.*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**å…è´£å£°æ˜**ï¼šæœ¬æ–‡æ˜¯å¯¹åŒ…å« #royalmail æ ‡ç­¾çš„æ¨æ–‡çš„ç‹¬ç«‹åˆ†æï¼Œä¸ Royal Mail Group Ltd æ²¡æœ‰ä»»ä½•å…³è”ã€è®¤å¯æˆ–èµåŠ©ã€‚æœ¬æ–‡ä¸­è¡¨è¾¾çš„è§‚ç‚¹å’Œå‘ç°ä»…ä»£è¡¨ä½œè€…ä¸ªäººè§‚ç‚¹ï¼Œä¸ä»£è¡¨
    Royal Mail Group Ltd æˆ–å…¶ä»»ä½•å­å…¬å¸çš„è§‚ç‚¹æˆ–å®˜æ–¹ç«‹åœºã€‚'
- en: Approach
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ–¹æ³•
- en: When seeking to understand what people think, Twitter is always a good starting
    point. Much of what people post on Twitter is public and easily accessible through
    their API. Itâ€™s the kind of no holds barred verbal arena you would expect to find
    plenty of insights on customer service. I got curious and conducted a quick twitter
    search myself starting simply with â€˜#royalmailâ€™. And voila! a tonne of tweets.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¯»æ±‚äº†è§£äººä»¬çš„æƒ³æ³•æ—¶ï¼ŒTwitter æ€»æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ã€‚äººä»¬åœ¨ Twitter ä¸Šå‘å¸ƒçš„å¤§éƒ¨åˆ†å†…å®¹æ˜¯å…¬å¼€çš„ï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡å…¶ API è½»æ¾è®¿é—®ã€‚è¿™æ˜¯ä½ å¯ä»¥æ‰¾åˆ°å¤§é‡å®¢æˆ·æœåŠ¡è§è§£çš„é‚£ç§ä¸å—é™åˆ¶çš„è¨€è¯­é¢†åŸŸã€‚æˆ‘æ„Ÿåˆ°å¥½å¥‡ï¼Œè‡ªå·±è¿›è¡Œäº†ä¸€ä¸ªç®€å•çš„
    Twitter æœç´¢ï¼Œä»â€˜#royalmailâ€™å¼€å§‹ã€‚ç§ï¼ä¸€å †æ¨æ–‡ã€‚
- en: With my data source identified, the next thing I did was to figure out how I
    would â€œmineâ€ issues raised from those tweets. Topic modelling came to mind immediately
    as something to try. I figured that using some kind of clustering on the tweets
    could reveal some latent topics. Iâ€™ll spend the remainder of the write up going
    into some technical details. This wonâ€™t be a step-by-step, but rather a peek over
    my shoulder and a window into my thought process in putting this project together.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡®å®šäº†æ•°æ®æºåï¼Œæˆ‘åšçš„ä¸‹ä¸€æ­¥æ˜¯æ‰¾å‡ºå¦‚ä½•â€œæŒ–æ˜â€é‚£äº›æ¨æ–‡ä¸­æå‡ºçš„é—®é¢˜ã€‚ä¸»é¢˜å»ºæ¨¡ç«‹å³æµ®ç°åœ¨è„‘æµ·ä¸­ã€‚æˆ‘è®¤ä¸ºå¯¹æ¨æ–‡è¿›è¡ŒæŸç§ç±»å‹çš„èšç±»å¯ä»¥æ­ç¤ºä¸€äº›æ½œåœ¨çš„ä¸»é¢˜ã€‚æˆ‘å°†èŠ±è´¹å‰©ä¸‹çš„ç¯‡å¹…æ·±å…¥ä¸€äº›æŠ€æœ¯ç»†èŠ‚ã€‚è¿™ä¸ä¼šæ˜¯é€æ­¥çš„è¿‡ç¨‹ï¼Œè€Œæ˜¯çª¥è§†æˆ‘çš„è‚©è†€ä»¥åŠå¯¹æˆ‘åœ¨è¿™ä¸ªé¡¹ç›®ä¸­æ€è€ƒè¿‡ç¨‹çš„çª—å£ã€‚
- en: Software Engineering
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è½¯ä»¶å·¥ç¨‹
- en: '**Development environment**: I do the majority of my ML projects in python
    so my preferred IDE is Jupyter labs. I find it useful to be able to quickly toggle
    between Jupyter notebooks, python scripts, and the terminal.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¼€å‘ç¯å¢ƒ**ï¼šæˆ‘å¤§å¤šæ•°çš„æœºå™¨å­¦ä¹ é¡¹ç›®éƒ½æ˜¯ç”¨ python å®Œæˆçš„ï¼Œæ‰€ä»¥æˆ‘åå¥½ä½¿ç”¨ Jupyter labsã€‚æˆ‘å‘ç°èƒ½å¤Ÿå¿«é€Ÿåˆ‡æ¢ Jupyter notebooksã€python
    è„šæœ¬å’Œç»ˆç«¯éå¸¸æœ‰ç”¨ã€‚'
- en: '**File structure**: This is a rather complex project, if I do say so myself.
    There are several processes to consider here and therefore itâ€™s not something
    that could just be done from the safety of a Jupyter notebook. Listing out all
    of these we have; data extraction, data processing, topic modeling, machine learning,
    and data visualisation. To help create some order I usually start by establishing
    an appropriate file structure. You can, and probably should leverage bash scripting
    to do this.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ–‡ä»¶ç»“æ„**ï¼šè¿™æ˜¯ä¸€ä¸ªç›¸å½“å¤æ‚çš„é¡¹ç›®ï¼Œå¦‚æœæˆ‘è¿™ä¹ˆè¯´çš„è¯ã€‚è¿™é‡Œæœ‰å‡ ä¸ªè¿‡ç¨‹éœ€è¦è€ƒè™‘ï¼Œå› æ­¤è¿™ä¸æ˜¯ä¸€ä¸ªå¯ä»¥ä»…ä» Jupyter notebook çš„å®‰å…¨ç¯å¢ƒä¸­å®Œæˆçš„ä»»åŠ¡ã€‚åˆ—å‡ºæ‰€æœ‰è¿™äº›è¿‡ç¨‹ï¼Œæˆ‘ä»¬æœ‰ï¼šæ•°æ®æå–ã€æ•°æ®å¤„ç†ã€ä¸»é¢˜å»ºæ¨¡ã€æœºå™¨å­¦ä¹ å’Œæ•°æ®å¯è§†åŒ–ã€‚ä¸ºäº†å¸®åŠ©åˆ›å»ºä¸€äº›ç§©åºï¼Œæˆ‘é€šå¸¸ä¼šå…ˆå»ºç«‹ä¸€ä¸ªåˆé€‚çš„æ–‡ä»¶ç»“æ„ã€‚ä½ å¯ä»¥ï¼Œä¹Ÿåº”è¯¥åˆ©ç”¨
    bash è„šæœ¬æ¥å®Œæˆè¿™ä¸ªä»»åŠ¡ã€‚'
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Modularisation**: I broke each process down into modules making it easy to
    re-use, adapt and tweak things for different use cases. Modules also help keep
    your code â€˜cleanâ€™. Without the modular approach I would have ended up with a Jupyter
    notebook or python script thousands of lines long, very unappealing and difficult
    to de-bug.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ¨¡å—åŒ–**ï¼šæˆ‘å°†æ¯ä¸ªè¿‡ç¨‹åˆ†è§£ä¸ºæ¨¡å—ï¼Œä½¿å…¶æ˜“äºé‡ç”¨ã€è°ƒæ•´å’Œä¿®æ”¹ä»¥é€‚åº”ä¸åŒçš„ä½¿ç”¨åœºæ™¯ã€‚æ¨¡å—è¿˜å¸®åŠ©ä¿æŒä»£ç çš„â€œå¹²å‡€â€ã€‚å¦‚æœæ²¡æœ‰æ¨¡å—åŒ–çš„æ–¹æ³•ï¼Œæˆ‘ä¼šå¾—åˆ°ä¸€ä¸ªé•¿è¾¾æ•°åƒè¡Œçš„
    Jupyter notebook æˆ– python è„šæœ¬ï¼Œéå¸¸ä¸å¸å¼•äººä¸”éš¾ä»¥è°ƒè¯•ã€‚'
- en: '**Version control**: With complex projects, you do not want to lose your progress,
    overwrite something important, or mess up beyond repair. GitHub is really the
    perfect solution for this as it makes it hard to mess up badly. I get started
    by creating a remote repo and cloning it to my local machine allowing me to sleep
    easy knowing all my hard work is backed up. GitHub desk top allows me to carefully
    track any changes before committing them back to the remote repository.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç‰ˆæœ¬æ§åˆ¶**ï¼šå¯¹äºå¤æ‚çš„é¡¹ç›®ï¼Œä½ ä¸æƒ³ä¸¢å¤±è¿›åº¦ã€è¦†ç›–é‡è¦å†…å®¹æˆ–æå¾—ä¸€å›¢ç³Ÿã€‚GitHub æ˜¯ä¸€ä¸ªå®Œç¾çš„è§£å†³æ–¹æ¡ˆï¼Œå› ä¸ºå®ƒä½¿å¾—æç ¸çš„å¯èƒ½æ€§å¾ˆå°ã€‚æˆ‘é¦–å…ˆåˆ›å»ºä¸€ä¸ªè¿œç¨‹ä»“åº“å¹¶å°†å…¶å…‹éš†åˆ°æœ¬åœ°æœºå™¨ä¸Šï¼Œè¿™æ ·æˆ‘å¯ä»¥å®‰å¿ƒåœ°çŸ¥é“æˆ‘æ‰€æœ‰çš„è¾›å‹¤å·¥ä½œéƒ½æœ‰å¤‡ä»½ã€‚GitHub
    desktop å…è®¸æˆ‘åœ¨æäº¤åˆ°è¿œç¨‹ä»“åº“ä¹‹å‰ä»”ç»†è·Ÿè¸ªä»»ä½•æ›´æ”¹ã€‚'
- en: '**Packages:** I leveraged a tonne of open source packages, Iâ€™ll list the key
    ones below and provide links.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**åŒ…ï¼š** æˆ‘åˆ©ç”¨äº†å¤§é‡çš„å¼€æºåŒ…ï¼Œä¸‹é¢æˆ‘å°†åˆ—å‡ºå…³é”®çš„åŒ…å¹¶æä¾›é“¾æ¥ã€‚'
- en: '[Transformers](https://huggingface.co/docs/transformers/installation): API
    for hugging face large language model.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Transformers](https://huggingface.co/docs/transformers/installation)ï¼šhugging
    face å¤§å‹è¯­è¨€æ¨¡å‹çš„ APIã€‚'
- en: '[Pytorch](https://pytorch.org/get-started/locally/): Framework for building
    and customising transformers.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Pytorch](https://pytorch.org/get-started/locally/)ï¼šç”¨äºæ„å»ºå’Œå®šåˆ¶å˜æ¢å™¨çš„æ¡†æ¶ã€‚'
- en: '[Streamlit](https://streamlit.io/): For building web applications.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Streamlit](https://streamlit.io/)ï¼šç”¨äºæ„å»º web åº”ç”¨ç¨‹åºã€‚'
- en: '[Scikit Learn](https://scikit-learn.org/stable/install.html): Framework for
    machine learning.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Scikit Learn](https://scikit-learn.org/stable/install.html)ï¼šæœºå™¨å­¦ä¹ æ¡†æ¶ã€‚'
- en: '[UMAP](https://umap-learn.readthedocs.io/en/latest/): Open source implementation
    of the UMAP algorithm.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UMAP](https://umap-learn.readthedocs.io/en/latest/)ï¼šUMAP ç®—æ³•çš„å¼€æºå®ç°ã€‚'
- en: '[HDBSCAN](https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html):
    Open source implementation of the HDSCAN algorithm.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[HDBSCAN](https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html)ï¼šHDSCAN
    ç®—æ³•çš„å¼€æºå®ç°ã€‚'
- en: '[Folium](https://python-visualization.github.io/folium/#:~:text=folium%20makes%20it%20easy%20to,as%20markers%20on%20the%20map.):
    For geographic data visualisation.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Folium](https://python-visualization.github.io/folium/#:~:text=folium%20makes%20it%20easy%20to,as%20markers%20on%20the%20map.)ï¼šç”¨äºåœ°ç†æ•°æ®å¯è§†åŒ–ã€‚'
- en: '[CUDA](https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/):
    Parallel computing platform for leveraging the power of your GPU.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CUDA](https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/)ï¼šåˆ©ç”¨
    GPU åŠŸèƒ½çš„å¹¶è¡Œè®¡ç®—å¹³å°ã€‚'
- en: '[Seaborn](https://seaborn.pydata.org/): A library for data visualisation in
    python.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Seaborn](https://seaborn.pydata.org/)ï¼šç”¨äº Python ä¸­æ•°æ®å¯è§†åŒ–çš„åº“ã€‚'
- en: '[Pandas](https://pandas.pydata.org/): A library for handling structured data.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Pandas](https://pandas.pydata.org/)ï¼šå¤„ç†ç»“æ„åŒ–æ•°æ®çš„åº“ã€‚'
- en: '[Numpy](https://numpy.org/): A library for performing numeric operations in
    python.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Numpy](https://numpy.org/)ï¼šåœ¨ Python ä¸­æ‰§è¡Œæ•°å€¼æ“ä½œçš„åº“ã€‚'
- en: '**Environment management**: Having access to a wealth of libraries on the internet
    is fantastic, but your environment can quickly run away with you. To manage this
    complexity I like to enforce upon myself a clean environment policy whenever I
    start a new project. Itâ€™s strictly one environment per project. I choose to use
    [Anaconda](https://www.anaconda.com/) as my choice of environment manager because
    of the flexibility it gives me.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç¯å¢ƒç®¡ç†**ï¼šè™½ç„¶äº’è”ç½‘æä¾›äº†ä¸°å¯Œçš„åº“ï¼Œä½†ç¯å¢ƒç®¡ç†å¾ˆå®¹æ˜“å˜å¾—æ··ä¹±ã€‚ä¸ºäº†ç®¡ç†è¿™ç§å¤æ‚æ€§ï¼Œæˆ‘å–œæ¬¢åœ¨å¼€å§‹æ–°é¡¹ç›®æ—¶æ‰§è¡Œå¹²å‡€ç¯å¢ƒæ”¿ç­–ã€‚æ¯ä¸ªé¡¹ç›®ä¸¥æ ¼ä¸€ä¸ªç¯å¢ƒã€‚æˆ‘é€‰æ‹©ä½¿ç”¨
    [Anaconda](https://www.anaconda.com/) ä½œä¸ºæˆ‘çš„ç¯å¢ƒç®¡ç†å™¨ï¼Œå› ä¸ºå®ƒæä¾›äº†å¾ˆå¤§çš„çµæ´»æ€§ã€‚'
- en: '*note: for the purposes of this project I did create separate environments
    and GitHub repositories for the streamlet web application and the topic modeling.*'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ³¨æ„ï¼šå‡ºäºè¿™ä¸ªé¡¹ç›®çš„ç›®çš„ï¼Œæˆ‘ç¡®å®ä¸º streamlit web åº”ç”¨ç¨‹åºå’Œä¸»é¢˜å»ºæ¨¡åˆ›å»ºäº†å•ç‹¬çš„ç¯å¢ƒå’Œ GitHub ä»“åº“ã€‚*'
- en: Data
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ•°æ®
- en: 'I used the Twitter API to extract around 30k publicly available tweets searching
    #royalmail. I want to stress here that only data that is publicly available can
    be extracted with the Twitter API alleviating some of the data privacy concerns
    one may have.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 'æˆ‘ä½¿ç”¨ Twitter API æå–äº†å¤§çº¦ 30k æ¡å…¬å¼€å¯ç”¨çš„æ¨æ–‡ï¼Œæœç´¢ #royalmailã€‚æˆ‘æƒ³å¼ºè°ƒçš„æ˜¯ï¼Œåªæœ‰å…¬å¼€çš„æ•°æ®æ‰èƒ½é€šè¿‡ Twitter
    API æå–ï¼Œè¿™å‡è½»äº†ä¸€äº›å¯èƒ½å­˜åœ¨çš„æ•°æ®éšç§é—®é¢˜ã€‚'
- en: Twitter data is incredibly messy and notoriously difficult to work with for
    any natural language processing (nlp) tasks. Itâ€™s social media data loaded with
    emojiâ€™s, grammatical inconsistencies, special characters, expletives, URLS, and
    every other hurdle that comes with free form text. I wrote my own custom scripts
    to clean the data for this particular project. It was primarily getting rid of
    URLs and annoying stop words. I have given a snippet for the â€œliteâ€ version, but
    I did also use a more heavy duty version during clustering.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Twitter æ•°æ®éå¸¸æ··ä¹±ï¼Œå¯¹äºä»»ä½•è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆnlpï¼‰ä»»åŠ¡éƒ½æå…¶å›°éš¾ã€‚å®ƒæ˜¯å……æ»¡è¡¨æƒ…ç¬¦å·ã€è¯­æ³•ä¸ä¸€è‡´ã€ç‰¹æ®Šå­—ç¬¦ã€è„è¯ã€ç½‘å€ä»¥åŠæ‰€æœ‰å…¶ä»–è‡ªç”±æ–‡æœ¬å¸¦æ¥çš„éšœç¢çš„ç¤¾äº¤åª’ä½“æ•°æ®ã€‚æˆ‘ä¸ºè¿™ä¸ªç‰¹å®šé¡¹ç›®ç¼–å†™äº†è‡ªå·±çš„è‡ªå®šä¹‰è„šæœ¬æ¥æ¸…ç†æ•°æ®ã€‚ä¸»è¦æ˜¯å»é™¤ç½‘å€å’Œçƒ¦äººçš„åœç”¨è¯ã€‚æˆ‘æä¾›äº†â€œç®€åŒ–â€ç‰ˆæœ¬çš„ä»£ç ç‰‡æ®µï¼Œä½†åœ¨èšç±»è¿‡ç¨‹ä¸­ä¹Ÿä½¿ç”¨äº†æ›´é«˜çº§çš„ç‰ˆæœ¬ã€‚
- en: Module for cleaning URLs from tweets
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºæ¸…ç†æ¨æ–‡ä¸­çš„ç½‘å€çš„æ¨¡å—
- en: '*Please note that this is within Twitters terms of service. They allow analysis,
    aggregation of publicly available data via* [*their API*](https://developer.twitter.com/en/developer-terms/agreement-and-policy)*.
    The data is permitted for both* [*non-commercial and commercial use*](https://developer.twitter.com/en/developer-terms/commercial-terms#:~:text=Know%20that%20if%20you%20are,access%20are%20available%20for%20free).&text=Your%20product%20or%20service%20is%20monetized%20if%20you%20earn%20money%20from%20it.)*.*'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*è¯·æ³¨æ„ï¼Œè¿™ç¬¦åˆ Twitter çš„æœåŠ¡æ¡æ¬¾ã€‚ä»–ä»¬å…è®¸é€šè¿‡* [*ä»–ä»¬çš„ API*](https://developer.twitter.com/en/developer-terms/agreement-and-policy)*å¯¹å…¬å¼€å¯ç”¨çš„æ•°æ®è¿›è¡Œåˆ†æå’Œèšåˆã€‚è¿™äº›æ•°æ®æ—¢å…è®¸ç”¨äº*
    [*éå•†ä¸šå’Œå•†ä¸šç”¨é€”*](https://developer.twitter.com/en/developer-terms/commercial-terms#:~:text=Know%20that%20if%20you%20are,access%20are%20available%20for%20free).&text=Your%20product%20or%20service%20is%20monetized%20if%20you%20earn%20money%20from%20it.)*ã€‚*'
- en: Topic Modelling
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸»é¢˜å»ºæ¨¡
- en: The topic modelling approach I used draws inspiration from BERT topicÂ¹. I had
    initially tried Latent Dirichlet Allocation , but struggled to get anything coherent.
    BERT topic was a great reference point, but I had noticed that it hadnâ€™t explicitly
    been designed to extract topics from messy Twitter data. Following many of the
    same logical steps as BERT topic, I adapted the approach a little bit for the
    task.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä½¿ç”¨çš„ä¸»é¢˜å»ºæ¨¡æ–¹æ³•å—åˆ° BERT ä¸»é¢˜Â¹ çš„å¯å‘ã€‚æˆ‘æœ€åˆå°è¯•äº†æ½œåœ¨ç‹„åˆ©å…‹é›·åˆ†é…ï¼ˆLatent Dirichlet Allocationï¼‰ï¼Œä½†éš¾ä»¥å¾—åˆ°è¿è´¯çš„ç»“æœã€‚BERT
    ä¸»é¢˜æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å‚è€ƒç‚¹ï¼Œä½†æˆ‘æ³¨æ„åˆ°å®ƒå¹¶æ²¡æœ‰ä¸“é—¨è®¾è®¡æ¥ä»æ··ä¹±çš„ Twitter æ•°æ®ä¸­æå–ä¸»é¢˜ã€‚æŒ‰ç…§ä¸ BERT ä¸»é¢˜ç±»ä¼¼çš„é€»è¾‘æ­¥éª¤ï¼Œæˆ‘å¯¹æ–¹æ³•è¿›è¡Œäº†ç¨å¾®çš„è°ƒæ•´ä»¥é€‚åº”è¿™ä¸ªä»»åŠ¡ã€‚
- en: At a high level BERT topic uses the BERT model to generate embeddings, performs
    dimensionality reduction and clustering to reveal latent topics in documents.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é«˜å±‚æ¬¡æ¥çœ‹ï¼ŒBERT ä¸»é¢˜ä½¿ç”¨ BERT æ¨¡å‹ç”ŸæˆåµŒå…¥ï¼Œè¿›è¡Œé™ç»´å’Œèšç±»ä»¥æ­ç¤ºæ–‡æ¡£ä¸­çš„æ½œåœ¨ä¸»é¢˜ã€‚
- en: My approach leveraged the twitter-xlm-roberta-baseÂ² model to generate embeddings.
    This transformer has been pretrained on twitter data and captures all the messy
    nuances, emojis and all. Embeddings, are simply a way to represent sentences in
    numeric form such that both syntactical and semantical information is preserved.
    Embeddings are learnt by transformers through self-attention. The amazing thing
    about all the recent innovation in the large language model space is that one
    can leverage state-of-the-art models to generate embeddings for oneâ€™s own purposes.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çš„åšæ³•åˆ©ç”¨äº† twitter-xlm-roberta-baseÂ² æ¨¡å‹æ¥ç”ŸæˆåµŒå…¥ã€‚è¿™ä¸ªå˜æ¢å™¨å·²ç»åœ¨ Twitter æ•°æ®ä¸Šè¿›è¡Œè¿‡é¢„è®­ç»ƒï¼Œæ•æ‰äº†æ‰€æœ‰å¤æ‚çš„ç»†å¾®å·®åˆ«ï¼ŒåŒ…æ‹¬è¡¨æƒ…ç¬¦å·ã€‚åµŒå…¥åªæ˜¯ä»¥æ•°å­—å½¢å¼è¡¨ç¤ºå¥å­çš„ä¸€ç§æ–¹å¼ï¼Œä»è€Œä¿ç•™äº†è¯­æ³•å’Œè¯­ä¹‰ä¿¡æ¯ã€‚åµŒå…¥æ˜¯é€šè¿‡è‡ªæ³¨æ„åŠ›æœºåˆ¶ç”±å˜æ¢å™¨å­¦ä¹ çš„ã€‚æ‰€æœ‰æœ€è¿‘çš„å¤§å‹è¯­è¨€æ¨¡å‹é¢†åŸŸçš„åˆ›æ–°ä»¤äººæƒŠå¹çš„æ˜¯ï¼Œäººä»¬å¯ä»¥åˆ©ç”¨æœ€å…ˆè¿›çš„æ¨¡å‹ä¸ºè‡ªå·±çš„ç›®çš„ç”ŸæˆåµŒå…¥ã€‚
- en: I used the UMAP algorithm to project the tweet embeddings into a two dimensional
    space and HDBSCAN to identify clusters. Treating each cluster as a document, I
    generated TF-IDF scores to extract a list of key words that roughly â€˜defineâ€™ each
    cluster forming my initial topics.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä½¿ç”¨ UMAP ç®—æ³•å°†æ¨æ–‡åµŒå…¥æŠ•å½±åˆ°äºŒç»´ç©ºé—´ä¸­ï¼Œå¹¶ä½¿ç”¨ HDBSCAN è¯†åˆ«ç°‡ã€‚å°†æ¯ä¸ªç°‡è§†ä¸ºä¸€ä¸ªæ–‡æ¡£ï¼Œæˆ‘ç”Ÿæˆäº† TF-IDF åˆ†æ•°ï¼Œä»¥æå–ä¸€ä¸ªå…³é”®å­—åˆ—è¡¨ï¼Œå¤§è‡´â€˜å®šä¹‰â€™æ¯ä¸ªç°‡ï¼Œä»è€Œå½¢æˆæˆ‘çš„åˆæ­¥ä¸»é¢˜ã€‚
- en: '*TF-IDF is a handy way to measure a wordâ€™s significance in a cluster, considering
    how often it appears in that specific cluster and how rare it is in a larger group
    of clusters. It helps identify words that are unique and meaningful in each cluster.*'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*TF-IDF æ˜¯ä¸€ç§ä¾¿æ·çš„æ–¹å¼æ¥è¡¡é‡ä¸€ä¸ªè¯åœ¨æŸä¸ªç°‡ä¸­çš„é‡è¦æ€§ï¼Œè€ƒè™‘å®ƒåœ¨è¯¥ç°‡ä¸­å‡ºç°çš„é¢‘ç‡ä»¥åŠå®ƒåœ¨æ›´å¤§ç°‡ç»„ä¸­çš„ç¨€æœ‰ç¨‹åº¦ã€‚å®ƒæœ‰åŠ©äºè¯†åˆ«æ¯ä¸ªç°‡ä¸­ç‹¬ç‰¹ä¸”æœ‰æ„ä¹‰çš„è¯ã€‚*'
- en: '*Some of these dimensionality reductions can be hard to make sense of at first.
    I found these resources useful for helping me get to grips with the algorithms.*'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*è¿™äº›é™ç»´æ–¹æ³•æœ‰æ—¶ä¸€å¼€å§‹å¯èƒ½éš¾ä»¥ç†è§£ã€‚æˆ‘å‘ç°è¿™äº›èµ„æºå¯¹å¸®åŠ©æˆ‘æŒæ¡ç®—æ³•å¾ˆæœ‰ç”¨ã€‚*'
- en: '[*Understanding UMAP*](https://pair-code.github.io/understanding-umap/) *â€”
    An excellent resource that helps you visualise and understand the impact of adjusting
    hyperparameters.*'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[*ç†è§£ UMAP*](https://pair-code.github.io/understanding-umap/) *â€” ä¸€ä¸ªå‡ºè‰²çš„èµ„æºï¼Œå¸®åŠ©ä½ å¯è§†åŒ–å’Œç†è§£è°ƒæ•´è¶…å‚æ•°çš„å½±å“ã€‚*'
- en: '[*HDBSCAN Documentation*](https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html)
    *â€” The most coherent explanation of HDBSCAN I could find was provided in the documentation
    itself.*'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[*HDBSCAN æ–‡æ¡£*](https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html)
    *â€” æˆ‘èƒ½æ‰¾åˆ°çš„å¯¹ HDBSCAN æœ€è¿è´¯çš„è§£é‡Šæ˜¯æ–‡æ¡£æœ¬èº«æä¾›çš„ã€‚*'
- en: Lastly, I tested the coherence of the topics generated by scoring the cosine
    similarity between the topics and the tweets themselves. This sounds rather formulaic
    on paper, but I can assure you this was no straight forward task. Unsupervised
    machine learning of this nature is just trial and error. It took me dozens of
    iterations and manual effort to find the right parameters to get coherent topics
    out of these tweets. So rather than going into the specifics of all the hyperparameters
    I used, I will just talk about the four critical ones that were really a make
    or break for this approach.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘é€šè¿‡å¯¹ä¸»é¢˜å’Œæ¨æ–‡æœ¬èº«ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦è¿›è¡Œè¯„åˆ†ï¼Œæµ‹è¯•ç”Ÿæˆä¸»é¢˜çš„è¿è´¯æ€§ã€‚è¿™åœ¨çº¸é¢ä¸Šçœ‹èµ·æ¥ç›¸å½“å…¬å¼åŒ–ï¼Œä½†æˆ‘å¯ä»¥ä¿è¯è¿™å¹¶éç®€å•çš„ä»»åŠ¡ã€‚è¿™ç§æ— ç›‘ç£æœºå™¨å­¦ä¹ çš„æ€§è´¨å°±æ˜¯åå¤è¯•éªŒã€‚æˆ‘èŠ±è´¹äº†å‡ åæ¬¡è¿­ä»£å’Œäººå·¥åŠªåŠ›æ¥æ‰¾åˆ°æ­£ç¡®çš„å‚æ•°ï¼Œä»¥ä»è¿™äº›æ¨æ–‡ä¸­æå–è¿è´¯çš„ä¸»é¢˜ã€‚å› æ­¤ï¼Œä¸å…¶è¯¦ç»†è®¨è®ºæˆ‘ä½¿ç”¨çš„æ‰€æœ‰è¶…å‚æ•°ï¼Œä¸å¦‚è°ˆè°ˆé‚£äº›å¯¹è¿™ç§æ–¹æ³•è‡³å…³é‡è¦çš„å››ä¸ªå…³é”®å‚æ•°ã€‚
- en: '**Distance metrics**: for topic modelling the distance metric is really the
    difference between forming coherent topics and just generating a random list of
    words. For both UMAP and HDBSCAN I chose cosine distance. The choice here was
    a no-brainer considering my objective, to model topics. Topics are semantically
    similar groups of text, and the best way to measure semantic similarity is cosine
    distance.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**è·ç¦»åº¦é‡**ï¼šåœ¨ä¸»é¢˜å»ºæ¨¡ä¸­ï¼Œè·ç¦»åº¦é‡å®é™…ä¸Šæ˜¯å½¢æˆè¿è´¯ä¸»é¢˜ä¸ä»…ç”Ÿæˆéšæœºå•è¯åˆ—è¡¨ä¹‹é—´çš„åŒºåˆ«ã€‚å¯¹äºUMAPå’ŒHDBSCANï¼Œæˆ‘é€‰æ‹©äº†ä½™å¼¦è·ç¦»ã€‚è€ƒè™‘åˆ°æˆ‘çš„ç›®æ ‡æ˜¯å»ºæ¨¡ä¸»é¢˜ï¼Œè¿™ä¸ªé€‰æ‹©æ¯«æ— ç–‘é—®æ˜¯æ­£ç¡®çš„ã€‚ä¸»é¢˜æ˜¯è¯­ä¹‰ä¸Šç›¸ä¼¼çš„æ–‡æœ¬ç¾¤ä½“ï¼Œè€Œè¡¡é‡è¯­ä¹‰ç›¸ä¼¼åº¦çš„æœ€ä½³æ–¹æ³•æ˜¯ä½™å¼¦è·ç¦»ã€‚'
- en: '**Number of words**: after generating the clusters I wanted to understand the
    â€œcontentsâ€ of those clusters through TF-IDF. The key metric of choice here is
    how many words to return for each cluster. This could range from one to the number
    of unique words in the whole corpus of text. Too many words, and your topics become
    incoherent, too few and you end up with poor coverage of your cluster. Selecting
    this was a matter of trial and error, after several iterations I landed on 4 words
    per topic.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**è¯æ±‡æ•°é‡**ï¼šç”Ÿæˆèšç±»åï¼Œæˆ‘å¸Œæœ›é€šè¿‡TF-IDFäº†è§£è¿™äº›èšç±»çš„â€œå†…å®¹â€ã€‚è¿™é‡Œé€‰æ‹©çš„å…³é”®æŒ‡æ ‡æ˜¯æ¯ä¸ªèšç±»è¿”å›å¤šå°‘ä¸ªå•è¯ã€‚è¿™å¯èƒ½ä»ä¸€ä¸ªå•è¯åˆ°æ•´ä¸ªæ–‡æœ¬è¯­æ–™åº“ä¸­å”¯ä¸€å•è¯çš„æ•°é‡ä¸ç­‰ã€‚å•è¯å¤ªå¤šï¼Œä½ çš„ä¸»é¢˜ä¼šå˜å¾—ä¸è¿è´¯ï¼›å•è¯å¤ªå°‘ï¼Œä½ çš„èšç±»è¦†ç›–ç‡ä¼šå¾ˆå·®ã€‚é€‰æ‹©è¿™ä¸ªæ•°é‡æ˜¯ä¸€ä¸ªåå¤è¯•éªŒçš„è¿‡ç¨‹ï¼Œç»è¿‡å‡ æ¬¡è¿­ä»£ï¼Œæˆ‘æœ€ç»ˆé€‰æ‹©äº†æ¯ä¸ªä¸»é¢˜4ä¸ªå•è¯ã€‚'
- en: '**Scoring**: Topic modelling isnâ€™t an exact science, so some manual intervention
    is required to make sure topics made sense. I could do this for a few hundred
    or even a few thousand tweets, but tens of thousands? Thatâ€™s not practically feasible.
    So I used a numeric â€œhackâ€ by scoring the cosine similarity between the TFIDF
    topics generated and the tweets themselves. Again this was a lot of trial and
    error but after several iterations I found an appropriate cut off for cosine similarity
    to be around 0.9\. This left me with around 3k from the original 30k that were
    fairly well categorised. Most importantly, it was a large enough sample size to
    do some supervised machine learning.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**è¯„åˆ†**ï¼šä¸»é¢˜å»ºæ¨¡ä¸æ˜¯ä¸€é—¨ç²¾ç¡®çš„ç§‘å­¦ï¼Œå› æ­¤éœ€è¦ä¸€äº›äººå·¥å¹²é¢„ä»¥ç¡®ä¿ä¸»é¢˜æœ‰æ„ä¹‰ã€‚æˆ‘å¯ä»¥å¯¹å‡ ç™¾ç”šè‡³å‡ åƒæ¡æ¨æ–‡è¿›è¡Œæ­¤æ“ä½œï¼Œä½†åå‡ ä¸‡æ¡å‘¢ï¼Ÿé‚£å°±ä¸åˆ‡å®é™…äº†ã€‚å› æ­¤ï¼Œæˆ‘ä½¿ç”¨äº†ä¸€ä¸ªæ•°å€¼ä¸Šçš„â€œé»‘å®¢â€æ–¹æ³•ï¼Œé€šè¿‡å¯¹ç”Ÿæˆçš„TFIDFä¸»é¢˜ä¸æ¨æ–‡æœ¬èº«ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦è¿›è¡Œè¯„åˆ†ã€‚è™½ç„¶è¿™æ¶‰åŠå¾ˆå¤šåå¤è¯•éªŒï¼Œä½†ç»è¿‡å‡ æ¬¡è¿­ä»£ï¼Œæˆ‘å‘ç°ä½™å¼¦ç›¸ä¼¼åº¦çš„é€‚å½“æˆªæ­¢å€¼å¤§çº¦ä¸º0.9ã€‚è¿™ä½¿å¾—åŸæœ¬30kæ¡æ¨æ–‡ä¸­å¤§çº¦æœ‰3kæ¡è¢«è¾ƒå¥½åœ°åˆ†ç±»ã€‚æœ€é‡è¦çš„æ˜¯ï¼Œè¿™æä¾›äº†ä¸€ä¸ªè¶³å¤Ÿå¤§çš„æ ·æœ¬é‡æ¥è¿›è¡Œä¸€äº›ç›‘ç£æœºå™¨å­¦ä¹ ã€‚'
- en: '**Topics in 2d:** UMAP provides a convenient way to visualise the topics. What
    we can see is that there is a mass of topics in the centre that have been clustered
    together with some smaller niche topics on the edge. It actually reminds me a
    bit of a galaxy. After doing some detective work (manual trawling through spreadsheets)
    I found this to make sense. The mass of topics in the centre are mainly around
    customer service, often complaints. What I thought was particularly fascinating
    was the modelâ€™s ability to actually isolate very niche areas. These included politics,
    economics, employment, and philately (which isnâ€™t some minor celebrity, but the
    collection of stamps!). Of course, topics returned by TFIDF were no where near
    this coherent, but I was able to identify 6 well categorised topics from the analysis.
    My final 6 topics were customer service, politics, royal reply, jobs, financial
    news, and philately.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**äºŒç»´ä¸»é¢˜ï¼š** UMAP æä¾›äº†ä¸€ç§æ–¹ä¾¿çš„æ–¹å¼æ¥å¯è§†åŒ–ä¸»é¢˜ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œä¸­å¿ƒæœ‰ä¸€å¤§å—ä¸»é¢˜è¢«èšé›†åœ¨ä¸€èµ·ï¼Œè€Œä¸€äº›è¾ƒå°çš„åˆ©åŸºä¸»é¢˜åˆ™åœ¨è¾¹ç¼˜ã€‚è¿™å®é™…ä¸Šè®©æˆ‘æƒ³èµ·äº†ä¸€ä¸ªæ˜Ÿç³»ã€‚ç»è¿‡ä¸€äº›ä¾¦æŸ¥å·¥ä½œï¼ˆæ‰‹åŠ¨æµè§ˆç”µå­è¡¨æ ¼ï¼‰ï¼Œæˆ‘å‘ç°è¿™ç¡®å®æœ‰æ„ä¹‰ã€‚ä¸­å¿ƒçš„å¤§å—ä¸»é¢˜ä¸»è¦å›´ç»•å®¢æˆ·æœåŠ¡ï¼Œé€šå¸¸æ˜¯æŠ•è¯‰ã€‚æˆ‘è®¤ä¸ºç‰¹åˆ«å¸å¼•äººçš„æ˜¯æ¨¡å‹èƒ½å¤Ÿå®é™…éš”ç¦»å‡ºéå¸¸åˆ©åŸºçš„é¢†åŸŸã€‚è¿™äº›é¢†åŸŸåŒ…æ‹¬æ”¿æ²»ã€ç»æµã€å°±ä¸šå’Œé›†é‚®ï¼ˆè¿™ä¸æ˜¯æŸä¸ªå°æ˜æ˜Ÿï¼Œè€Œæ˜¯é›†é‚®ï¼ï¼‰ã€‚å½“ç„¶ï¼ŒTF-IDF
    è¿”å›çš„ä¸»é¢˜è¿œæ²¡æœ‰è¿™ä¹ˆä¸€è‡´ï¼Œä½†æˆ‘èƒ½å¤Ÿä»åˆ†æä¸­è¯†åˆ«å‡º 6 ä¸ªè‰¯å¥½åˆ†ç±»çš„ä¸»é¢˜ã€‚æˆ‘æœ€ç»ˆçš„ 6 ä¸ªä¸»é¢˜æ˜¯å®¢æˆ·æœåŠ¡ã€æ”¿æ²»ã€çš‡å®¶å›å¤ã€å·¥ä½œã€è´¢ç»æ–°é—»å’Œé›†é‚®ã€‚'
- en: '**List of four words topics generated by TF-IDF on the clusters and taking
    the 0.9+ cosine similarity to tweets.**'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**TF-IDF åœ¨é›†ç¾¤ä¸Šç”Ÿæˆçš„å››ä¸ªè¯æ±‡ä¸»é¢˜åˆ—è¡¨ï¼Œå¹¶è€ƒè™‘äº†ä¸æ¨æ–‡çš„ 0.9+ ä½™å¼¦ç›¸ä¼¼åº¦ã€‚**'
- en: 'apprenticeship, jinglejobs, job, label: **Jobs**'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­¦å¾’ï¼Œå¹¿å‘Šå·¥ä½œï¼Œå·¥ä½œï¼Œæ ‡ç­¾ï¼š**å·¥ä½œ**
- en: 'biggest, boss, revolt, year: **Politics**'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€å¤§ï¼Œè€æ¿ï¼Œå›ä¹±ï¼Œå¹´ï¼š**æ”¿æ²»**
- en: 'birth, reply, royalletters, royalreply: **Royal Reply**'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡ºç”Ÿï¼Œå›å¤ï¼Œçš‡å®¶ä¿¡ä»¶ï¼Œçš‡å®¶å›å¤ï¼š**çš‡å®¶å›å¤**
- en: 'collecting, pack, philatelist, philately: **Philately**'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ”¶é›†ï¼ŒåŒ…è£…ï¼Œé›†é‚®çˆ±å¥½è€…ï¼Œé›†é‚®ï¼š**é›†é‚®**
- en: 'declares, plc, position, short: **Financial News**'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å£°æ˜ï¼Œè‚¡ä»½å…¬å¸ï¼ŒèŒä½ï¼Œç®€çŸ­ï¼š**è´¢ç»æ–°é—»**
- en: 'definitive, philatelist, philately, presentation: **Philately**'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¡®å®šçš„ï¼Œé›†é‚®çˆ±å¥½è€…ï¼Œé›†é‚®ï¼Œæ¼”ç¤ºï¼š**é›†é‚®**
- en: 'driving, infoapply, job, office: **Jobs**'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é©¾é©¶ï¼Œä¿¡æ¯ç”³è¯·ï¼Œå·¥ä½œï¼ŒåŠå…¬å®¤ï¼š**å·¥ä½œ**
- en: 'driving, job, sm1jobs, suttonjobs: **Jobs**'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é©¾é©¶ï¼Œå·¥ä½œï¼Œsm1jobsï¼Œsuttonjobsï¼š**å·¥ä½œ**
- en: 'ftse, rmg, share, stock: **Financial News**'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FTSEï¼ŒRMGï¼Œè‚¡ç¥¨ï¼Œè‚¡æ¯ï¼š**è´¢ç»æ–°é—»**
- en: 'germany, royal, royalletter, royalreply: **Royal Reply**'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¾·å›½ï¼Œçš‡å®¶ï¼Œçš‡å®¶ä¿¡ä»¶ï¼Œçš‡å®¶å›å¤ï¼š**çš‡å®¶å›å¤**
- en: 'gradjobs, graduatescheme, jobsearch, listen: **Jobs**'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¯•ä¸šå·¥ä½œï¼Œæ¯•ä¸šç”Ÿè®¡åˆ’ï¼Œæ±‚èŒï¼Œæ”¶å¬ï¼š**å·¥ä½œ**
- en: 'labour, libdems, tory, uk: **Politics**'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ³å·¥ï¼Œè‡ªç”±æ°‘ä¸»å…šï¼Œä¿å®ˆå…šï¼Œè‹±å›½ï¼š**æ”¿æ²»**
- en: 'letter, mail, service, strike: **Customer Service**'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¿¡ä»¶ï¼Œé‚®ä»¶ï¼ŒæœåŠ¡ï¼Œç½¢å·¥ï¼š**å®¢æˆ·æœåŠ¡**
- en: 'luxembourg, royal, royalletter, royalreply: **Royal Reply**'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¢æ£®å ¡ï¼Œçš‡å®¶ï¼Œçš‡å®¶ä¿¡ä»¶ï¼Œçš‡å®¶å›å¤ï¼š**çš‡å®¶å›å¤**
- en: 'new, profit, shareholder, world: **Financial News**'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ–°ï¼Œåˆ©æ¶¦ï¼Œè‚¡ä¸œï¼Œä¸–ç•Œï¼š**è´¢ç»æ–°é—»**
- en: 'plc, position, reduced, wace: **Financial News**'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è‚¡ä»½å…¬å¸ï¼ŒèŒä½ï¼Œå‡å°‘ï¼ŒWACEï¼š**è´¢ç»æ–°é—»**
- en: '![](../Images/8bc6976977c0bb1f8442f12aae195bf2.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8bc6976977c0bb1f8442f12aae195bf2.png)'
- en: 'Image by Author: A 2d representation of the embedding after applying UMAP'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…å›¾ç‰‡ï¼šåº”ç”¨ UMAP åçš„åµŒå…¥äºŒç»´è¡¨ç¤º
- en: '![](../Images/8bd6950f177d003c98cf88bfbe2c538b.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8bd6950f177d003c98cf88bfbe2c538b.png)'
- en: 'Image by Author: A view of the the topics after applying HDBSCAN. Yellow mass
    is customer service related'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…å›¾ç‰‡ï¼šåº”ç”¨ HDBSCAN åçš„ä¸»é¢˜è§†å›¾ã€‚é»„è‰²åŒºåŸŸæ˜¯ä¸å®¢æˆ·æœåŠ¡ç›¸å…³
- en: '*The topic modelling was fiddly and definitely not something you want to rely
    on continuously for generating insights. As far as Iâ€™m concerned it should be
    an exercise that you conduct once every few months or so (depending on the fidelity
    of your data), just in case anything new comes up.*'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*ä¸»é¢˜å»ºæ¨¡ç¹çï¼Œç»å¯¹ä¸æ˜¯ä½ æƒ³æŒç»­ä¾èµ–ä»¥ç”Ÿæˆæ´è§çš„ä¸œè¥¿ã€‚å°±æˆ‘è€Œè¨€ï¼Œè¿™åº”è¯¥æ˜¯ä½ æ¯éš”å‡ ä¸ªæœˆè¿›è¡Œä¸€æ¬¡çš„ç»ƒä¹ ï¼ˆå–å†³äºæ•°æ®çš„ä¿çœŸåº¦ï¼‰ï¼Œä»¥é˜²å‡ºç°ä»»ä½•æ–°æƒ…å†µã€‚*'
- en: Transfer Learning
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è½¬ç§»å­¦ä¹ 
- en: Having performed the arduous task of topic modelling, I had some labels and
    a decent sized data set of just under 3k observations for training a model. Leveraging
    a pretrained transformer means not having to train from scratch, not having to
    build my own architecture and harnessing the power of the modelâ€™s existing knowledge.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å®Œæˆè‰°å·¨çš„ä¸»é¢˜å»ºæ¨¡ä»»åŠ¡åï¼Œæˆ‘è·å¾—äº†ä¸€äº›æ ‡ç­¾å’Œä¸€ä¸ªæ¥è¿‘ 3k è§‚å¯Ÿæ•°æ®çš„åˆé€‚æ•°æ®é›†ï¼Œç”¨äºè®­ç»ƒæ¨¡å‹ã€‚åˆ©ç”¨é¢„è®­ç»ƒçš„å˜æ¢å™¨æ„å‘³ç€ä¸å¿…ä»å¤´å¼€å§‹è®­ç»ƒï¼Œä¹Ÿä¸éœ€è¦æ„å»ºè‡ªå·±çš„æ¶æ„ï¼Œèƒ½å¤Ÿåˆ©ç”¨æ¨¡å‹ç°æœ‰çŸ¥è¯†çš„åŠ›é‡ã€‚
- en: Data Splitting
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ•°æ®æ‹†åˆ†
- en: 'I proceeded with the standard Train, Validation, and Test splits with 80% of
    the observations being allocated to train. See script below:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä½¿ç”¨æ ‡å‡†çš„è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ‹†åˆ†ï¼Œ80% çš„è§‚å¯Ÿæ•°æ®ç”¨äºè®­ç»ƒã€‚è¯·å‚è§ä¸‹é¢çš„è„šæœ¬ï¼š
- en: Data splitting script
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®æ‹†åˆ†è„šæœ¬
- en: Implementing focal loss with a custom trainer
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å®ç°è‡ªå®šä¹‰è®­ç»ƒå™¨çš„ç„¦ç‚¹æŸå¤±
- en: Model training turned out to be less straight forward than I had anticipated,
    and this wasnâ€™t because of the hardware requirements but rather the data itself.
    What I was dealing with was a highly imbalanced multiclass classification problem.
    Customer service observations were at least ten times as prominent in the data
    set than the next most prominent class. This caused the model performance to be
    overwhelmed by the customer service class leading to low recall and precision
    for the less prominent classes.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹è®­ç»ƒç»“æœæ¯”æˆ‘é¢„æœŸçš„è¦å¤æ‚ï¼Œè¿™å¹¶ä¸æ˜¯å› ä¸ºç¡¬ä»¶è¦æ±‚ï¼Œè€Œæ˜¯æ•°æ®æœ¬èº«ã€‚æˆ‘è¦å¤„ç†çš„æ˜¯ä¸€ä¸ªé«˜åº¦ä¸å¹³è¡¡çš„å¤šç±»åˆ†ç±»é—®é¢˜ã€‚å®¢æˆ·æœåŠ¡è§‚å¯Ÿåœ¨æ•°æ®é›†ä¸­è‡³å°‘æ¯”ä¸‹ä¸€ä¸ªæœ€çªå‡ºç±»åˆ«å¤šåå€ã€‚è¿™å¯¼è‡´æ¨¡å‹æ€§èƒ½è¢«å®¢æˆ·æœåŠ¡ç±»åˆ«æ‰€å‹å€’ï¼Œä»è€Œå¯¼è‡´å…¶ä»–ä¸çªå‡ºç±»åˆ«çš„å¬å›ç‡å’Œç²¾ç¡®åº¦è¾ƒä½ã€‚
- en: I started with something simple initially applying class weights and cross entropy
    loss, but this didnâ€™t do the trick. After a quick google search I discovered that
    the loss function focal loss has been used successfully to solve class imbalance.
    Focal loss reshapes the cross entropy loss to â€œdown-weightâ€ the loss assigned
    to well classified examplesÂ³.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æœ€åˆä»ç®€å•çš„ç±»æƒé‡å’Œäº¤å‰ç†µæŸå¤±å¼€å§‹ï¼Œä½†è¿™æ²¡æœ‰å¥æ•ˆã€‚ç»è¿‡å¿«é€Ÿçš„Googleæœç´¢ï¼Œæˆ‘å‘ç°ç„¦ç‚¹æŸå¤±å‡½æ•°åœ¨è§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ä¸Šå–å¾—äº†æˆåŠŸã€‚ç„¦ç‚¹æŸå¤±é‡æ–°å¡‘é€ äº†äº¤å‰ç†µæŸå¤±ï¼Œä»¥â€œé™ä½â€åˆ†é…ç»™åˆ†ç±»è‰¯å¥½ç¤ºä¾‹çš„æŸå¤±Â³ã€‚
- en: '*The original paper on focal loss focussed on computer vision tasks where images
    had shallow depth of field. The image below is an example of shallow depth of
    field, the foreground is prominent but the background very low res. This type
    of extreme imbalance between foreground and background is analogous to the imbalance
    I had to deal with to classify the tweets.*'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '*ç„¦ç‚¹æŸå¤±çš„åŸå§‹è®ºæ–‡å…³æ³¨äºè®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼Œå…¶ä¸­å›¾åƒå…·æœ‰æµ…æ™¯æ·±ã€‚ä¸‹é¢çš„å›¾åƒæ˜¯æµ…æ™¯æ·±çš„ä¸€ä¸ªä¾‹å­ï¼Œå‰æ™¯çªå‡ºä½†èƒŒæ™¯åˆ†è¾¨ç‡å¾ˆä½ã€‚è¿™ç§æç«¯çš„å‰æ™¯ä¸èƒŒæ™¯ä¹‹é—´çš„ä¸å¹³è¡¡ç±»ä¼¼äºæˆ‘åœ¨åˆ†ç±»æ¨æ–‡æ—¶éœ€è¦å¤„ç†çš„ä¸å¹³è¡¡ã€‚*'
- en: '![](../Images/00dea754e944d517bbed76b7eeea6859.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/00dea754e944d517bbed76b7eeea6859.png)'
- en: Photo by [Raphael Wild](https://unsplash.com/@veloradio?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ç…§ç‰‡ç”±[Raphael Wild](https://unsplash.com/@veloradio?utm_source=medium&utm_medium=referral)æ‹æ‘„ï¼Œå‘å¸ƒäº[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Below I have laid out my implementation of focal loss within a custom trainer
    object.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢æ˜¯æˆ‘åœ¨è‡ªå®šä¹‰è®­ç»ƒå™¨å¯¹è±¡ä¸­å®ç°ç„¦ç‚¹æŸå¤±çš„è¿‡ç¨‹ã€‚
- en: '*note that the class weights (alpha) are hard coded. You will need to adjust
    these if you want to use this for you own purposes.*'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ³¨æ„ï¼Œç±»æƒé‡ï¼ˆalphaï¼‰æ˜¯ç¡¬ç¼–ç çš„ã€‚å¦‚æœä½ æƒ³ç”¨äºè‡ªå·±çš„ç›®çš„ï¼Œéœ€è¦è°ƒæ•´è¿™äº›æƒé‡ã€‚*'
- en: Implementation of the focal loss. Custom trainer is just standard trainer with
    added focal loss
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¦ç‚¹æŸå¤±çš„å®ç°ã€‚è‡ªå®šä¹‰è®­ç»ƒå™¨åªæ˜¯æ ‡å‡†è®­ç»ƒå™¨åŠ ä¸Šäº†ç„¦ç‚¹æŸå¤±
- en: Model Training
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¨¡å‹è®­ç»ƒ
- en: After a bit of customisation I was able to fit a model (and in under 7 minutes
    thanks to my GPU and CUDA). Focal loss vs. time gives us some evidence that the
    model was close to converging.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿›è¡Œäº†ä¸€äº›è‡ªå®šä¹‰è°ƒæ•´åï¼Œæˆ‘æˆåŠŸåœ°æ‹Ÿåˆäº†ä¸€ä¸ªæ¨¡å‹ï¼ˆå¾—ç›Šäºæˆ‘çš„GPUå’ŒCUDAï¼Œæ—¶é—´ä¸åˆ°7åˆ†é’Ÿï¼‰ã€‚Focal lossä¸æ—¶é—´çš„å…³ç³»ç»™æˆ‘ä»¬æä¾›äº†ä¸€äº›è¯æ®ï¼Œè¡¨æ˜æ¨¡å‹æ¥è¿‘æ”¶æ•›ã€‚
- en: '![](../Images/0a714d949b1f46e3251ba33e5b444f62.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0a714d949b1f46e3251ba33e5b444f62.png)'
- en: 'Image by Author: Focal loss vs time step'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„å›¾åƒï¼šFocal lossä¸æ—¶é—´æ­¥é•¿çš„å…³ç³»
- en: Model training script. Notice the customer trainer is imported and implemented
    here.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹è®­ç»ƒè„šæœ¬ã€‚æ³¨æ„è¿™é‡Œå¯¼å…¥å¹¶å®ç°äº†å®¢æˆ·è‡ªå®šä¹‰çš„è®­ç»ƒå™¨ã€‚
- en: Model Performance
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¨¡å‹æ€§èƒ½
- en: The model was assessed on the test data set which included 525 randomly selected
    labelled examples. The performance appears impressive, with fairly high precision
    and recall across all classes. I would caveat that test performance is probably
    optimistic due to the small sample size and there is likely to be more variance
    in the nature of these tweets outside of our sample. However, we are dealing with
    a relatively narrow domain (#royalmail) so variance is likely to be narrower than
    it would be for something more general purpose.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹åœ¨åŒ…æ‹¬525ä¸ªéšæœºé€‰æ‹©çš„æ ‡è®°æ ·æœ¬çš„æµ‹è¯•æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚æ€§èƒ½è¡¨ç°ä»¤äººå°è±¡æ·±åˆ»ï¼Œå„ç±»çš„ç²¾ç¡®åº¦å’Œå¬å›ç‡éƒ½ç›¸å½“é«˜ã€‚æˆ‘éœ€è¦å¼ºè°ƒçš„æ˜¯ï¼Œç”±äºæ ·æœ¬é‡è¾ƒå°ï¼Œæµ‹è¯•æ€§èƒ½å¯èƒ½è¿‡äºä¹è§‚ï¼Œå¹¶ä¸”æ ·æœ¬ä¹‹å¤–çš„æ¨æ–‡æ€§è´¨å¯èƒ½æœ‰æ›´å¤šå˜åŒ–ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å¤„ç†çš„æ˜¯ä¸€ä¸ªç›¸å¯¹ç‹­çª„çš„é¢†åŸŸï¼ˆ#royalmailï¼‰ï¼Œå› æ­¤å˜åŒ–å¯èƒ½æ¯”æ›´é€šç”¨çš„é¢†åŸŸè¦å°ã€‚
- en: '![](../Images/b42ce43a03c1d467a4a40e164bf175a4.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b42ce43a03c1d467a4a40e164bf175a4.png)'
- en: 'Image by Author: confusion matrix (test dataset)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„å›¾åƒï¼šæ··æ·†çŸ©é˜µï¼ˆæµ‹è¯•æ•°æ®é›†ï¼‰
- en: '![](../Images/387cd526d73841e894dd49cb85406f8f.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/387cd526d73841e894dd49cb85406f8f.png)'
- en: 'Image by Author: model performance metrics on Test'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„å›¾åƒï¼šæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½æŒ‡æ ‡
- en: Geographic Visualisation
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åœ°ç†å¯è§†åŒ–
- en: To effectively visualize the wealth of information I gathered, I decided to
    create a sentiment map. By utilizing my trained model, I generated topics for
    tweets posted between January and March 2023\. Additionally, I employed the pretrained
    `[twitter-roberta-base-sentiment](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest)`
    model from Cardiff NLP to assess the sentiment of each tweet. To build the final
    web application, I used Streamlit.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æœ‰æ•ˆåœ°å¯è§†åŒ–æˆ‘æ”¶é›†çš„å¤§é‡ä¿¡æ¯ï¼Œæˆ‘å†³å®šåˆ›å»ºä¸€ä¸ªæƒ…æ„Ÿåœ°å›¾ã€‚é€šè¿‡åˆ©ç”¨æˆ‘è®­ç»ƒçš„æ¨¡å‹ï¼Œæˆ‘ä¸º2023å¹´1æœˆè‡³3æœˆä¹‹é—´çš„æ¨æ–‡ç”Ÿæˆäº†è¯é¢˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä½¿ç”¨äº†æ¥è‡ªCardiff
    NLPçš„é¢„è®­ç»ƒ `[twitter-roberta-base-sentiment](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest)`
    æ¨¡å‹æ¥è¯„ä¼°æ¯æ¡æ¨æ–‡çš„æƒ…æ„Ÿã€‚ä¸ºäº†æ„å»ºæœ€ç»ˆçš„ç½‘ç»œåº”ç”¨ç¨‹åºï¼Œæˆ‘ä½¿ç”¨äº†Streamlitã€‚
- en: script for generating the Streamlit web application
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ç”ŸæˆStreamlitç½‘ç»œåº”ç”¨ç¨‹åºçš„è„šæœ¬
- en: Business Applications
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å•†ä¸šåº”ç”¨
- en: 'The current app serves as a basic prototype, but it can be expanded to uncover
    more profound insights. Iâ€™ll briefly discuss a few potential extensions below:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å‰çš„åº”ç”¨ç¨‹åºä½œä¸ºä¸€ä¸ªåŸºæœ¬åŸå‹å­˜åœ¨ï¼Œä½†å¯ä»¥æ‰©å±•ä»¥æ­ç¤ºæ›´æ·±åˆ»çš„è§è§£ã€‚æˆ‘å°†åœ¨ä¸‹é¢ç®€è¦è®¨è®ºä¸€äº›æ½œåœ¨çš„æ‰©å±•ï¼š
- en: '**Temporal Filtering**: Incorporate a date range filter, allowing users to
    explore tweets within specific time periods. This can help identify trends and
    changes in sentiment over time.'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ—¶é—´è¿‡æ»¤**ï¼šåŠ å…¥æ—¥æœŸèŒƒå›´è¿‡æ»¤å™¨ï¼Œå…è®¸ç”¨æˆ·åœ¨ç‰¹å®šæ—¶é—´æ®µå†…æµè§ˆæ¨æ–‡ã€‚è¿™æœ‰åŠ©äºè¯†åˆ«è¶‹åŠ¿å’Œæƒ…æ„Ÿéšæ—¶é—´çš„å˜åŒ–ã€‚'
- en: '**Interactive Visualizations**: Implement interactive charts and visualizations
    that enable users to explore relationships between sentiment, topics, and other
    factors in the dataset.'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**äº’åŠ¨å¯è§†åŒ–**ï¼šå®ç°äº’åŠ¨å›¾è¡¨å’Œå¯è§†åŒ–å·¥å…·ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿæ¢ç´¢æ•°æ®é›†ä¸­æƒ…æ„Ÿã€è¯é¢˜å’Œå…¶ä»–å› ç´ ä¹‹é—´çš„å…³ç³»ã€‚'
- en: '**Real-time Data**: Connect the app to live Twitter data, enabling real-time
    analysis and visualization of sentiment and topics as they emerge.'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å®æ—¶æ•°æ®**ï¼šå°†åº”ç”¨ç¨‹åºè¿æ¥åˆ°å®æ—¶Twitteræ•°æ®ï¼Œå¯ç”¨å®æ—¶åˆ†æå’Œå¯è§†åŒ–æƒ…æ„ŸåŠè¯é¢˜ã€‚'
- en: '**Advanced Filtering**: Provide more advanced filtering options, such as filtering
    by user, hashtag, or keyword, to allow for more targeted analysis of specific
    conversations and trends.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**é«˜çº§è¿‡æ»¤**ï¼šæä¾›æ›´å¤šé«˜çº§è¿‡æ»¤é€‰é¡¹ï¼Œå¦‚æŒ‰ç”¨æˆ·ã€è¯é¢˜æ ‡ç­¾æˆ–å…³é”®å­—è¿‡æ»¤ï¼Œä»¥ä¾¿å¯¹ç‰¹å®šå¯¹è¯å’Œè¶‹åŠ¿è¿›è¡Œæ›´æœ‰é’ˆå¯¹æ€§çš„åˆ†æã€‚'
- en: By extending the app with these features, you can provide users with a more
    powerful and insightful tool for exploring and understanding sentiment and topics
    in tweets.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡æ‰©å±•åº”ç”¨ç¨‹åºè¿™äº›åŠŸèƒ½ï¼Œä½ å¯ä»¥ä¸ºç”¨æˆ·æä¾›ä¸€ä¸ªæ›´å¼ºå¤§ã€æ›´æœ‰æ´å¯ŸåŠ›çš„å·¥å…·ï¼Œä»¥æ¢ç´¢å’Œç†è§£æ¨æ–‡ä¸­çš„æƒ…æ„Ÿå’Œè¯é¢˜ã€‚
- en: '[GitHub Repo](https://github.com/john-adeojo/twitter_issues_dashboard)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[GitHub ä»“åº“](https://github.com/john-adeojo/twitter_issues_dashboard)'
- en: Thanks for reading!
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢é˜…è¯»ï¼
- en: '[](https://medium.com/@johnadeojo/membership?source=post_page-----fa1764409905--------------------------------)
    [## Join Medium with my referral link - John Adeojo'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@johnadeojo/membership?source=post_page-----fa1764409905--------------------------------)
    [## é€šè¿‡æˆ‘çš„æ¨èé“¾æ¥åŠ å…¥ Medium - John Adeojo'
- en: I share data science projects, experiences, and expertise to assist you on your
    journey You can sign up to medium viaâ€¦
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æˆ‘åˆ†äº«æ•°æ®ç§‘å­¦é¡¹ç›®ã€ç»éªŒå’Œä¸“ä¸šçŸ¥è¯†ï¼Œä»¥å¸®åŠ©ä½ åœ¨æ—…ç¨‹ä¸­ã€‚ä½ å¯ä»¥é€šè¿‡â€¦æ³¨å†ŒMediumã€‚
- en: medium.com](https://medium.com/@johnadeojo/membership?source=post_page-----fa1764409905--------------------------------)
    [](https://www.john-adeojo.com/?source=post_page-----fa1764409905--------------------------------)
    [## Home | John Adeojo
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[medium.com](https://medium.com/@johnadeojo/membership?source=post_page-----fa1764409905--------------------------------)
    [](https://www.john-adeojo.com/?source=post_page-----fa1764409905--------------------------------)
    [## ä¸»é¡µ | John Adeojo'
- en: About Me An experienced data scientist and machine learning (ML) expert specialising
    in building bespoke ML poweredâ€¦
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å…³äºæˆ‘ ä¸€åç»éªŒä¸°å¯Œçš„æ•°æ®ç§‘å­¦å®¶å’Œæœºå™¨å­¦ä¹ ï¼ˆMLï¼‰ä¸“å®¶ï¼Œä¸“æ³¨äºæ„å»ºå®šåˆ¶çš„MLè§£å†³æ–¹æ¡ˆâ€¦
- en: www.john-adeojo.com](https://www.john-adeojo.com/?source=post_page-----fa1764409905--------------------------------)
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.john-adeojo.com](https://www.john-adeojo.com/?source=post_page-----fa1764409905--------------------------------)'
- en: Citations
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¼•ç”¨
- en: '[1]Grootendorst, M. (2022). *BERTopic: Neural topic modeling with a class-based
    TF-IDF procedure*. Paperswithcode.com. [https://paperswithcode.com/paper/bertopic-neural-topic-modeling-with-a-class](https://paperswithcode.com/paper/bertopic-neural-topic-modeling-with-a-class)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]Grootendorst, M. (2022). *BERTopic: ä½¿ç”¨åŸºäºç±»çš„TF-IDFç¨‹åºè¿›è¡Œç¥ç»ä¸»é¢˜å»ºæ¨¡*. Paperswithcode.com.
    [https://paperswithcode.com/paper/bertopic-neural-topic-modeling-with-a-class](https://paperswithcode.com/paper/bertopic-neural-topic-modeling-with-a-class)'
- en: '[2]Barbieri, F., Anke, L. E., & Camacho-Collados, J. (2022). *XLM-T: Multilingual
    Language Models in Twitter for Sentiment Analysis and Beyond*. Paperswithcode.com.
    [https://arxiv.org/abs/2104.12250](https://arxiv.org/abs/2104.12250)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[2]Barbieri, F., Anke, L. E., & Camacho-Collados, J. (2022). *XLM-T: å¤šè¯­è¨€è¯­è¨€æ¨¡å‹åœ¨Twitterä¸Šçš„æƒ…æ„Ÿåˆ†æåŠæ›´å¤š*.
    Paperswithcode.com. [https://arxiv.org/abs/2104.12250](https://arxiv.org/abs/2104.12250)'
- en: '[3]Lin, T.-Y., Goyal, P., Girshick, R., He, K. and Dollar, P. (2018). Focal
    Loss for Dense Object Detection. *Facebook AI Research (FAIR)*. [online] Available
    at: [https://arxiv.org/pdf/1708.02002.pdf](https://arxiv.org/pdf/1708.02002.pdf)
    [Accessed 21 Mar. 2023].'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[3]Lin, T.-Y., Goyal, P., Girshick, R., He, K. å’Œ Dollar, P. (2018). Focal Loss
    for Dense Object Detection. *Facebook AI Research (FAIR)*. [åœ¨çº¿] å¯ç”¨ç½‘å€: [https://arxiv.org/pdf/1708.02002.pdf](https://arxiv.org/pdf/1708.02002.pdf)
    [è®¿é—®äº 2023 å¹´ 3 æœˆ 21 æ—¥]ã€‚'
