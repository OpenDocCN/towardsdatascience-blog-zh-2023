- en: 'Beyond Precision and Recall: A Deep Dive Deep into the Tversky Index'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/beyond-precision-and-recall-a-deep-dive-deep-into-the-tversky-index-2b377c2c30b7](https://towardsdatascience.com/beyond-precision-and-recall-a-deep-dive-deep-into-the-tversky-index-2b377c2c30b7)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Exploring an alternative classification metric
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://mikhailklassen.medium.com/?source=post_page-----2b377c2c30b7--------------------------------)[![Mikhail
    Klassen](../Images/9c4a6cc856fd4061f682e95a1c145c36.png)](https://mikhailklassen.medium.com/?source=post_page-----2b377c2c30b7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2b377c2c30b7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2b377c2c30b7--------------------------------)
    [Mikhail Klassen](https://mikhailklassen.medium.com/?source=post_page-----2b377c2c30b7--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2b377c2c30b7--------------------------------)
    ·7 min read·Sep 2, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/007d37c92072ebd8b214107ae1e5014e.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Ricardo Arce](https://unsplash.com/@jrarce?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: In the world of data science, metrics are the compass that guide our models
    to success. While many are familiar with the classic measures of precision and
    recall, there are actually a wide range of other options that are worth exploring.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we’ll dive into the Tversky index. This metric, a generalization
    of the Dice and Jaccard coefficients, can be extremely useful when trying to balance
    precision and recall against each other. When implemented as a loss function for
    neural networks, it can be a powerful way to deal with class imbalances.
  prefs: []
  type: TYPE_NORMAL
- en: A quick refresher on precision and recall
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine you are a detective tasked with capturing criminals in your town. In
    truth, there are 10 criminals roaming the streets.
  prefs: []
  type: TYPE_NORMAL
- en: In your first month, you bring in 8 suspects you assume to be criminals. Only
    4 of them end up being guilty, while the other 4 are innocent.
  prefs: []
  type: TYPE_NORMAL
- en: If you were a machine learning model, you’d be evaluated against your precision
    and recall.
  prefs: []
  type: TYPE_NORMAL
- en: '**Precision** asks: “of all those you caught, how many were criminals?”'
  prefs: []
  type: TYPE_NORMAL
- en: '**Recall** asks: “of all the criminals in the town, how many did you catch?”'
  prefs: []
  type: TYPE_NORMAL
- en: '**Precision** is a metric that captures how accurate your predictions are,
    not counting how many true positives you miss (false negatives). **Recall** measures
    how many of the true positives you capture, irrespective of how many false positives
    you get.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/86e004501ee6e7e2cca31918adf79448.png)'
  prefs: []
  type: TYPE_IMG
- en: How do your detective skills rate against these metrics?
  prefs: []
  type: TYPE_NORMAL
- en: precision = 4 / (4 + 4) = 0.5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: recall = 4 / (4 + 6) = 0.4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Balancing precision and recall: the F1 metric'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In an ideal world, your classifier has both high precision and high recall.
    As a measure of how well your classifier is doing against both, the F1 statistic
    measures the harmonic mean between the two:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7780f4c972fd0400459e034122a091b8.png)'
  prefs: []
  type: TYPE_IMG
- en: This metric is also sometimes called the Dice similarity coefficient (DSC).
  prefs: []
  type: TYPE_NORMAL
- en: 'Measuring similarity another way: the Jaccard coefficient'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another way of measuring the similarity between two sets is the **Jaccard similarity
    coefficient**, which is often used in computer vision applications where the goal
    is to identify objects.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/93776d9f2a4381aa34277c333f838c81.png)'
  prefs: []
  type: TYPE_IMG
- en: 'An object-detection algorithm predicts a bounding box around a stop sign (red).
    Human annotators have labeled the desired bounding region (green). Credit: [Adrian
    Rosebrock](http://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/),
    [CC BY-SA 4.0](https://commons.wikimedia.org/w/index.php?curid=57718561)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Jaccard coefficient measures the ratio of the intersection of the two sets
    and their union:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f36d0ce33b094ef866693b6e7fe8a613.png)'
  prefs: []
  type: TYPE_IMG
- en: Depicted visually, the intersection-over-union (IoU) is
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/68c50f484216e713a23508d0a3663211.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The Jaccard similarity coefficient is also known as the intersection-over-union
    (IoU). Credit: [Adrian Rosebrock](http://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/),
    [CC BY-SA 4.0](https://commons.wikimedia.org/w/index.php?curid=57718561)'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the Tversky index
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Tversky index is a generalization of the Dice coefficient (F1 metric) and
    the Jaccard coefficient and is also used to compare the similarity of two sets,
    *X* and *Y*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The index can be formulated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/057b8fea01957d2c7a78a331d79a27d1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If the language of set theory isn’t all that familiar, let’s break it down:'
  prefs: []
  type: TYPE_NORMAL
- en: '*| X* ∩ *Y |* represents the number of common elements between sets *X* and
    *Y*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*| X* ∖ *Y |* represents the number of elements that are in *X* but not in
    *Y*. It is called the relative complement of *Y* in *X.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*| Y* ∖ *X |* represents the number of elements that are in *Y* but not in
    *X*. It is called the relative complement of *X* in *Y*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*α* and *β* are parameters that determine the relative importance of false
    positives and false negatives, respectively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The parameters *α* and *β* are important. If we set *α* = *β* = 0.5, we get
    back the Dice coefficient. If we set *α* = *β* = 1.0, we get the Jaccard coefficient.
    In general, we keep *α* + *β* = 1, and this allows us to shift the weight between
    false negatives and false positives.
  prefs: []
  type: TYPE_NORMAL
- en: True positives, false positives, and false negatives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let’s talk about it in the context of classification. Let’s assume *X*
    is the ground truth and *Y* is our prediction. In such a scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: '*X* ∩ *Y*: True positives (items correctly predicted as positive)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*X* ∖ *Y*: False negatives (items that were positive but predicted as negative)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Y* ∖ *X*: False positives (items that were negative but predicted as positive)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How does it relate to precision and recall?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s go back to our definitions of precision and recall:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/86e004501ee6e7e2cca31918adf79448.png)'
  prefs: []
  type: TYPE_IMG
- en: Precision is the fraction of true positive predictions among all the predicted
    positives. It tells us how many of the predicted positive instances are actually
    positive.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Recall, also known as the sensitivity or true positive rate (TPR), is the fraction
    of true positive predictions among all the actual positives. It tells us how many
    of the actual positive instances were correctly predicted by the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With these interpretations in mind, let’s link the Tversky index to precision
    and recall.
  prefs: []
  type: TYPE_NORMAL
- en: 'When *α* = 1 and *β* = 0:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/26e20271cd771050d2d74030b938560b.png)'
  prefs: []
  type: TYPE_IMG
- en: This is the definition of **Recall**.
  prefs: []
  type: TYPE_NORMAL
- en: 'When *α* = 0 and *β* = 1:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/54c843a0469ca561246e2a39d7138141.png)'
  prefs: []
  type: TYPE_IMG
- en: This is the definition of **Precision**.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, by tweaking the parameters *α* and *β*, the Tversky index can reflect
    either precision or recall, or any weighted mix of both. This makes the Tversky
    index a flexible metric, allowing one to prioritize recall over precision or vice-versa
    depending on the application’s needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Applied to neural networks: the Tversky loss'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Tverksy index can be used as a loss function in machine learning applications.
    In neural networks performing classification tasks, such as semantic image segmentation,
    we can use the Tversky index to define a loss function. This is an alternative
    to the usual categorical cross-entropy that is typically employed.
  prefs: []
  type: TYPE_NORMAL
- en: Since the optimizer always tries to minimize the loss, the Tversky Loss (TL)
    is just defined as
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1e9158bdf335ef2345f444aab5f7769e.png)'
  prefs: []
  type: TYPE_IMG
- en: where TI is the Tversky index.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, it can be defined as
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/331b239fc8608147d12c3cb29f5c8244.png)'
  prefs: []
  type: TYPE_IMG
- en: Here it will always assume a value between 0 and 1\. Thus, as the loss approaches
    0, our classifier approaches perfect accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: The advantage of using the Tversky Loss is that we can tweak the *α* and *β*
    parameters in order to favor recall or precision.
  prefs: []
  type: TYPE_NORMAL
- en: The Focal Tversky loss
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Focal Tversky loss is an advanced loss function designed to address class imbalance
    issues in segmentation tasks, especially in medical imaging. It is defined as
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eea60aa8fc5ea3310d1e73e726d248dd.png)'
  prefs: []
  type: TYPE_IMG
- en: By incorporating both the Tversky index, which is a generalization of the Dice
    coefficient that weighs false positives and false negatives differently, and a
    focal modulation (γ)to give more importance to hard-to-segment instances, this
    loss function becomes more sensitive to small and ambiguous structures.
  prefs: []
  type: TYPE_NORMAL
- en: In scenarios where certain regions or classes are underrepresented or where
    certain misclassifications are costlier than others, standard loss functions like
    categorical cross-entropy may not perform optimally. Under such circumstances,
    a researcher might choose Focal Tversky loss as it prioritizes the learning of
    challenging and rare regions, offering better segmentation performance in the
    presence of imbalances and subtle features.
  prefs: []
  type: TYPE_NORMAL
- en: 'For more on the Focal Tversky loss, check out this other article from Towards
    Data Science:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/dealing-with-class-imbalanced-image-datasets-1cbd17de76b5?source=post_page-----2b377c2c30b7--------------------------------)
    [## Dealing with class imbalanced image datasets using the Focal Tversky Loss'
  prefs: []
  type: TYPE_NORMAL
- en: A comparison of losses in class imbalanced problems and why the Focal Tversky
    Loss might be the best option for you
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/dealing-with-class-imbalanced-image-datasets-1cbd17de76b5?source=post_page-----2b377c2c30b7--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the landscape of classification metrics, the Tversky Index emerges as a versatile
    and adaptable tool. By bridging the gap between traditional metrics like the Dice
    and Jaccard coefficients, it offers data scientists a more nuanced tool to evaluate
    their models. Its flexibility in balancing false positives and false negatives
    through the α and β parameters ensures that it can be tailored to specific needs.
    As a loss function in neural networks, particularly with a focal parameter, it
    becomes a powerful tool for training deep neural networks as well.
  prefs: []
  type: TYPE_NORMAL
