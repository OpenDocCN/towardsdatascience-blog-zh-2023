- en: Naive Bayes Classifier from Scratch, with Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»å¤´å¼€å§‹çš„æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼Œä½¿ç”¨Python
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/naive-bayes-classifier-from-scratch-with-python-942708211470](https://towardsdatascience.com/naive-bayes-classifier-from-scratch-with-python-942708211470)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/naive-bayes-classifier-from-scratch-with-python-942708211470](https://towardsdatascience.com/naive-bayes-classifier-from-scratch-with-python-942708211470)
- en: From theory to practice with Bayes Theorem
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»ç†è®ºåˆ°å®è·µï¼Œè¿ç”¨è´å¶æ–¯å®šç†
- en: '[](https://piero-paialunga.medium.com/?source=post_page-----942708211470--------------------------------)[![Piero
    Paialunga](../Images/de2185596a49484698733e85114dd1ff.png)](https://piero-paialunga.medium.com/?source=post_page-----942708211470--------------------------------)[](https://towardsdatascience.com/?source=post_page-----942708211470--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----942708211470--------------------------------)
    [Piero Paialunga](https://piero-paialunga.medium.com/?source=post_page-----942708211470--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://piero-paialunga.medium.com/?source=post_page-----942708211470--------------------------------)[![Piero
    Paialunga](../Images/de2185596a49484698733e85114dd1ff.png)](https://piero-paialunga.medium.com/?source=post_page-----942708211470--------------------------------)[](https://towardsdatascience.com/?source=post_page-----942708211470--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----942708211470--------------------------------)
    [Piero Paialunga](https://piero-paialunga.medium.com/?source=post_page-----942708211470--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----942708211470--------------------------------)
    Â·10 min readÂ·Jan 4, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page-----942708211470--------------------------------)
    Â·é˜…è¯»æ—¶é—´10åˆ†é’ŸÂ·2023å¹´1æœˆ4æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/0861ef7d4e87fc5bedc5552305cb25bc.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0861ef7d4e87fc5bedc5552305cb25bc.png)'
- en: Photo by [Joel Abraham](https://unsplash.com/@joe_27?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/8RRYJg26Wr4?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±[Joel Abraham](https://unsplash.com/@joe_27?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)æ‹æ‘„ï¼Œå›¾ç‰‡æ¥æºäº[Unsplash](https://unsplash.com/photos/8RRYJg26Wr4?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: 'Math and Physics are full of theorems, equations, principles, axioms, and corollaries.
    When I started studying Physics I remembered I got to the point where all the
    courses I studied had the same structures:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°å­¦å’Œç‰©ç†å……æ»¡äº†å®šç†ã€æ–¹ç¨‹ã€åŸç†ã€å…¬ç†å’Œæ¨è®ºã€‚å½“æˆ‘å¼€å§‹å­¦ä¹ ç‰©ç†æ—¶ï¼Œæˆ‘è®°å¾—æˆ‘è¾¾åˆ°äº†æ‰€æœ‰è¯¾ç¨‹éƒ½å…·æœ‰ç›¸åŒç»“æ„çš„é˜¶æ®µï¼š
- en: A. Defining the **fundamental assumptions**
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: A. å®šä¹‰**åŸºæœ¬å‡è®¾**
- en: B. Using math to build the next â€œ**brick of the wall**â€
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: B. ä½¿ç”¨æ•°å­¦æ„å»ºä¸‹ä¸€ä¸ªâ€œ**ç –å—**â€
- en: C. **Stacking one brick on top of the other** until the whole pieces come together
    into an elegant, beautiful, model of a portion of the world
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: C. **ä¸€å—å—åœ°å åŠ **ï¼Œç›´åˆ°æ‰€æœ‰éƒ¨åˆ†æ±‡èšæˆä¸€ä¸ªä¼˜é›…ã€ç¾ä¸½çš„ä¸–ç•Œæ¨¡å‹
- en: 'Letâ€™s take the first course I ever did in physics: **calculus.**'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»æˆ‘å­¦ä¹ è¿‡çš„ç¬¬ä¸€é—¨ç‰©ç†è¯¾ç¨‹å¼€å§‹ï¼š**å¾®ç§¯åˆ†**ã€‚
- en: 1\. You start with the fundamental assumptions of **sets** and **numbers**.
    You start defining natural, integer, real, and complex numbers.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. ä½ ä»**é›†åˆ**å’Œ**æ•°å­—**çš„åŸºæœ¬å‡è®¾å¼€å§‹ã€‚ä½ å¼€å§‹å®šä¹‰è‡ªç„¶æ•°ã€æ•´æ•°ã€å®æ•°å’Œå¤æ•°ã€‚
- en: 2\. From there you start defining **functions** that are nothing but a **map**
    from space A (letâ€™s say N-dimensional real space) to space B (letâ€™s say a 1D real
    space).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. ä»è¿™é‡Œå¼€å§‹ï¼Œä½ å®šä¹‰çš„**å‡½æ•°**ä¸è¿‡æ˜¯ä»ç©ºé—´Aï¼ˆå‡è®¾æ˜¯Nç»´å®æ•°ç©ºé—´ï¼‰åˆ°ç©ºé—´Bï¼ˆå‡è®¾æ˜¯1ç»´å®æ•°ç©ºé—´ï¼‰çš„**æ˜ å°„**ã€‚
- en: 3\. Then you start with the **study** of the functions. So you start analyzing
    their minima, maxima, and saddle points. You accidentally (*ops!*) get to know
    the concept of **â€œderivative**â€.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. ç„¶åä½ å¼€å§‹**ç ”ç©¶**å‡½æ•°ã€‚äºæ˜¯ä½ å¼€å§‹åˆ†æå®ƒä»¬çš„æœ€å°å€¼ã€æœ€å¤§å€¼å’Œéç‚¹ã€‚ä½ å¶ç„¶ï¼ˆ*å“¦ï¼*ï¼‰äº†è§£äº†**â€œå¯¼æ•°â€**çš„æ¦‚å¿µã€‚
- en: 4\. Then you see how you can **integrate** a function, that is the opposite
    of the **derivative**.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. ç„¶åä½ çœ‹çœ‹å¦‚ä½•**ç§¯åˆ†**ä¸€ä¸ªå‡½æ•°ï¼Œé‚£æ˜¯**å¯¼æ•°**çš„åè¿‡ç¨‹ã€‚
- en: 5\. Then you combine these things with **differential equations.**
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. ç„¶åä½ å°†è¿™äº›ä¸**å¾®åˆ†æ–¹ç¨‹**ç»“åˆèµ·æ¥ã€‚
- en: 'Donâ€™t get me wrong: that process is **amazing**. I loved to see how far human
    logic can bring you. I loved to see that very complex natural events can be derived
    by starting from very simple concepts that evolve into way deeper implications.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è¦è¯¯è§£æˆ‘ï¼šè¿™ä¸ªè¿‡ç¨‹æ˜¯**æƒŠäººçš„**ã€‚æˆ‘å–œæ¬¢çœ‹åˆ°äººç±»é€»è¾‘èƒ½å¸¦ä½ å¤šè¿œã€‚æˆ‘å–œæ¬¢çœ‹åˆ°éå¸¸å¤æ‚çš„è‡ªç„¶äº‹ä»¶å¯ä»¥é€šè¿‡ä»éå¸¸ç®€å•çš„æ¦‚å¿µå¼€å§‹é€æ­¥æ¨å¯¼å‡ºæ›´æ·±çš„å«ä¹‰ã€‚
- en: Another valuable science lesson is the fact that a theorem that is originally
    applied to **â€œAâ€** can also be applied to â€œBâ€, â€œCâ€, â€œDâ€ and â€œEâ€.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªå®è´µçš„ç§‘å­¦è¯¾ç¨‹æ˜¯ï¼Œæœ€åˆåº”ç”¨äº**â€œAâ€**çš„å®šç†ï¼Œä¹Ÿå¯ä»¥åº”ç”¨äºâ€œBâ€ã€â€œCâ€ã€â€œDâ€å’Œâ€œEâ€ã€‚
- en: The fascinating aspect is that the field â€œAâ€ and the other fields (B, C, D,
    and E) donâ€™t have to be related.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¤äººç€è¿·çš„æ–¹é¢åœ¨äºï¼Œé¢†åŸŸâ€œAâ€å’Œå…¶ä»–é¢†åŸŸï¼ˆBã€Cã€Då’ŒEï¼‰ä¸å¿…ç›¸å…³ã€‚
- en: Possibly the **greatest example** of that is **Bayesâ€™ Theorem**.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å¯èƒ½**æœ€å¥½çš„ä¾‹å­**å°±æ˜¯**è´å¶æ–¯å®šç†**ã€‚
- en: Bayesâ€™ theorem is something that is, in a certain way, an elementary and obvious
    concept. The incredibly cool thing is that we can build some very interesting
    algorithms by stressing the idea behind Bayesâ€™ Theorem and applying it to Machine
    Learning. This tool is called the **Naive Bayes Classifier**
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: è´å¶æ–¯å®šç†åœ¨æŸç§ç¨‹åº¦ä¸Šæ˜¯ä¸€ä¸ªåŸºç¡€ä¸”æ˜¾è€Œæ˜“è§çš„æ¦‚å¿µã€‚ä»¤äººéš¾ä»¥ç½®ä¿¡çš„é…·äº‹æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å¼ºè°ƒè´å¶æ–¯å®šç†èƒŒåçš„ç†å¿µå¹¶å°†å…¶åº”ç”¨äºæœºå™¨å­¦ä¹ æ¥æ„å»ºä¸€äº›éå¸¸æœ‰è¶£çš„ç®—æ³•ã€‚è¿™ä¸ªå·¥å…·è¢«ç§°ä¸º**æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨**ã€‚
- en: 'In this article:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼š
- en: We will give a brief introduction to **Bayesâ€™ theorem**. We will explain what
    it is, why it is important, and how it can be applied to **Machine Learning**
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ç®€è¦ä»‹ç»**è´å¶æ–¯å®šç†**ã€‚æˆ‘ä»¬å°†è§£é‡Šå®ƒæ˜¯ä»€ä¹ˆï¼Œä¸ºä»€ä¹ˆé‡è¦ï¼Œä»¥åŠå®ƒå¦‚ä½•åº”ç”¨äº**æœºå™¨å­¦ä¹ **ã€‚
- en: We will see an application of the Bayes theorem in a made-up **classification
    task.**
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†çœ‹åˆ°è´å¶æ–¯å®šç†åœ¨ä¸€ä¸ªè™šæ„çš„**åˆ†ç±»ä»»åŠ¡**ä¸­çš„åº”ç”¨ã€‚
- en: We will see a leveled-up version of the Bayes theorem using the so-called **Gaussian
    Naive Bayes classifier.**
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†çœ‹åˆ°ä¸€ä¸ªå‡çº§ç‰ˆçš„è´å¶æ–¯å®šç†ï¼Œä½¿ç”¨æ‰€è°“çš„**é«˜æ–¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨**ã€‚
- en: Iâ€™m so excited. Letâ€™s start this!
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘éå¸¸å…´å¥‹ã€‚è®©æˆ‘ä»¬å¼€å§‹å§ï¼
- en: 1\. About the Bayes Theorem
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. å…³äºè´å¶æ–¯å®šç†
- en: 'There was one definition of the Bayes Theorem that has really stuck in my brain:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰ä¸€ä¸ªå…³äºè´å¶æ–¯å®šç†çš„å®šä¹‰ä¸€ç›´æ·±æ·±åœ°å°åœ¨æˆ‘çš„è„‘æµ·é‡Œï¼š
- en: â€œThe Bayes Theorem is that theorem that proves that just because your car is
    blue it doesnâ€™t mean that all the cars of the world are blue **but** if all the
    cars of the world are blue **then** your car must be blueâ€
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œè´å¶æ–¯å®šç†æ˜¯è¿™æ ·çš„å®šç†ï¼Œå®ƒè¯æ˜äº†ä»…ä»…å› ä¸ºä½ çš„è½¦æ˜¯è“è‰²çš„ï¼Œå¹¶ä¸æ„å‘³ç€å…¨ä¸–ç•Œçš„è½¦éƒ½æ˜¯è“è‰²çš„**ä½†**å¦‚æœå…¨ä¸–ç•Œçš„è½¦éƒ½æ˜¯è“è‰²çš„**é‚£ä¹ˆ**ä½ çš„è½¦å¿…é¡»æ˜¯è“è‰²çš„ã€‚â€
- en: If you read this [article](https://medium.com/towards-data-science/from-theory-to-practice-with-bayesian-neural-network-using-python-9262b611b825)
    about Bayesian Neural Networks you probably recognize it is the same definition
    but I swear I didnâ€™t use the same definition twice **because Iâ€™m lazy!** I meanâ€¦
    I **am lazy** but that is not the reason.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ é˜…è¯»äº†è¿™ç¯‡[æ–‡ç« ](https://medium.com/towards-data-science/from-theory-to-practice-with-bayesian-neural-network-using-python-9262b611b825)å…³äºè´å¶æ–¯ç¥ç»ç½‘ç»œï¼Œä½ å¯èƒ½ä¼šè®¤è¯†åˆ°è¿™ä¸ä¹‹å‰çš„å®šä¹‰ç›¸åŒï¼Œä½†æˆ‘å‘èª“æˆ‘æ²¡æœ‰å› ä¸º**æ‡’æƒ°**è€Œé‡å¤ä½¿ç”¨åŒä¸€å®šä¹‰ï¼æˆ‘çš„æ„æ€æ˜¯â€¦â€¦æˆ‘**ç¡®å®å¾ˆæ‡’**ï¼Œä½†è¿™ä¸æ˜¯åŸå› ã€‚
- en: I use that definition because it helps us understand that **event A given a
    condition of event B** does not have the same probability of happening as **event
    B given the condition of event A**.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä½¿ç”¨é‚£ä¸ªå®šä¹‰æ˜¯å› ä¸ºå®ƒå¸®åŠ©æˆ‘ä»¬ç†è§£**äº‹ä»¶Aåœ¨äº‹ä»¶Bçš„æ¡ä»¶ä¸‹**çš„å‘ç”Ÿæ¦‚ç‡ä¸**äº‹ä»¶Båœ¨äº‹ä»¶Açš„æ¡ä»¶ä¸‹**çš„å‘ç”Ÿæ¦‚ç‡æ˜¯ä¸ä¸€æ ·çš„ã€‚
- en: Let me do another example to overcome my laziness.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘åšä¸€ä¸ªæ–°çš„ä¾‹å­æ¥å…‹æœæˆ‘çš„æ‡’æƒ°ã€‚
- en: Letâ€™s say we have two bowls
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æœ‰ä¸¤ä¸ªç¢—
- en: '![](../Images/2bf3a6d955208812a1c85bdc730b0ca1.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2bf3a6d955208812a1c85bdc730b0ca1.png)'
- en: Now, letâ€™s say that these two bowls are full of **basketball** and **football**
    (itâ€™s called **football**, not *soccer*) **balls**.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œå‡è®¾è¿™ä¸¤ä¸ªç¢—é‡Œæ»¡æ˜¯**ç¯®çƒ**å’Œ**è¶³çƒ**ï¼ˆç§°ä¸º**è¶³çƒ**ï¼Œä¸æ˜¯*è¶³çƒ*ï¼‰**çƒ**ã€‚
- en: '![](../Images/afcf95d180c1f284ac39be7064deb4aa.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/afcf95d180c1f284ac39be7064deb4aa.png)'
- en: Image by author
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…å›¾ç‰‡
- en: 'Now, letâ€™s say that I ask you that question:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œå‡è®¾æˆ‘é—®ä½ è¿™ä¸ªé—®é¢˜ï¼š
- en: â€œ **KNOWING** that I picked a ball from the **blue** bowl, what is the probability
    that I picked a **football** ball â€
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œ**çŸ¥é“**æˆ‘ä»**è“è‰²**ç¢—é‡ŒæŒ‘äº†ä¸€ä¸ªçƒï¼ŒæŒ‘åˆ°ä¸€ä¸ª**è¶³çƒ**çƒçš„æ¦‚ç‡æ˜¯å¤šå°‘ã€‚â€
- en: 'Well, the answer is very simple. The probability is **1,** because, on the
    **blue bowl**, I only have football balls. Now letâ€™s say that I pick a bowl randomly
    with equal probability (0.5 probability of picking the white bowl and 0.5 probability
    of picking the blue bowl). Let me ask you this question:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ï¼Œç­”æ¡ˆå¾ˆç®€å•ã€‚æ¦‚ç‡æ˜¯**1**ï¼Œå› ä¸ºåœ¨**è“è‰²ç¢—**é‡Œï¼Œæˆ‘åªæœ‰è¶³çƒçƒã€‚ç°åœ¨å‡è®¾æˆ‘éšæœºæŒ‘é€‰ä¸€ä¸ªç¢—ï¼ˆæŒ‘é€‰ç™½è‰²ç¢—å’ŒæŒ‘é€‰è“è‰²ç¢—çš„æ¦‚ç‡éƒ½æ˜¯0.5ï¼‰ã€‚è®©æˆ‘é—®ä½ è¿™ä¸ªé—®é¢˜ï¼š
- en: â€œ KNOWING that I picked a football ball, what is the probability that I picked
    that ball from the blue bowl? â€
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œçŸ¥é“æˆ‘æŒ‘äº†ä¸€ä¸ªè¶³çƒï¼Œé€‰æ‹©è¿™ä¸ªçƒæ¥è‡ªè“è‰²ç¢—çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿâ€
- en: As you can see, the question is kind of the same but event A **(I picked a football
    ball)** and event B **(I picked the blue bowl)** have the opposite order.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä½ æ‰€è§ï¼Œé—®é¢˜æœ‰ç‚¹ç±»ä¼¼ï¼Œä½†äº‹ä»¶A**ï¼ˆæˆ‘æŒ‘äº†ä¸€ä¸ªè¶³çƒï¼‰**å’Œäº‹ä»¶B**ï¼ˆæˆ‘æŒ‘äº†è“è‰²ç¢—ï¼‰**çš„é¡ºåºæ­£å¥½ç›¸åã€‚
- en: Now, I think that you kind of guessed that the answer is not the same, because
    I could pick the football ball from the white bowl rather than the blue one. I
    also think you kind of guessed that this probability is still high though because
    I only have one football ball in the white bowl.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘æƒ³ä½ å¯èƒ½å·²ç»çŒœåˆ°ç­”æ¡ˆå¹¶ä¸ç›¸åŒï¼Œå› ä¸ºæˆ‘å¯èƒ½ä»ç™½è‰²ç¢—ä¸­è€Œä¸æ˜¯è“è‰²ç¢—ä¸­æå–äº†è¶³çƒã€‚æˆ‘ä¹Ÿè®¤ä¸ºä½ å¯èƒ½çŒœåˆ°è¿™ä¸ªæ¦‚ç‡ä»ç„¶å¾ˆé«˜ï¼Œå› ä¸ºæˆ‘åœ¨ç™½è‰²ç¢—ä¸­åªæœ‰ä¸€ä¸ªè¶³çƒã€‚
- en: Letâ€™s do the experiment in **Python**.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åœ¨**Python**ä¸­è¿›è¡Œå®éªŒã€‚
- en: 'I can go into the line-by-line detail of it but Iâ€™d find that pretty boring.
    What Iâ€™m doing here is nothing but setting the situation of bowls and balls like
    we did before and then running the probabilistic experiment **N** times. At the
    end of these N iterations, we will have N results. Then we will have to compute
    our probability as a **frequentist** probability. In this case, we will compute:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¯ä»¥é€è¡Œè¯¦ç»†è§£é‡Šï¼Œä½†æˆ‘è§‰å¾—é‚£æ ·å¾ˆæ— èŠã€‚æˆ‘æ‰€åšçš„ä»…ä»…æ˜¯è®¾ç½®ç¢—å’Œçƒçš„æƒ…å†µï¼Œå°±åƒä¹‹å‰ä¸€æ ·ï¼Œç„¶åè¿è¡Œæ¦‚ç‡å®éªŒ**N**æ¬¡ã€‚åœ¨è¿™Næ¬¡è¿­ä»£ç»“æŸæ—¶ï¼Œæˆ‘ä»¬å°†å¾—åˆ°Nä¸ªç»“æœã€‚ç„¶åæˆ‘ä»¬éœ€è¦å°†æ¦‚ç‡è®¡ç®—ä¸º**é¢‘ç‡ä¸»ä¹‰**æ¦‚ç‡ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†è®¡ç®—ï¼š
- en: '![](../Images/f459332f8822862dff2f032a5591fc02.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f459332f8822862dff2f032a5591fc02.png)'
- en: Image by author
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: Now we know that if we run N = infinite times in the same experiments we will
    converge to the analytical result, so we will iteratively increase N and see if
    it converges to whatever result.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬çŸ¥é“ï¼Œå¦‚æœæˆ‘ä»¬åœ¨ç›¸åŒçš„å®éªŒä¸­è¿è¡ŒN = æ— é™æ¬¡ï¼Œæˆ‘ä»¬å°†æ”¶æ•›åˆ°åˆ†æç»“æœï¼Œå› æ­¤æˆ‘ä»¬å°†è¿­ä»£åœ°å¢åŠ Nï¼Œçœ‹çœ‹å®ƒæ˜¯å¦æ”¶æ•›åˆ°ä»»ä½•ç»“æœã€‚
- en: As you see, we did 20,50,70,â€¦, 1M iterations.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä½ æ‰€è§ï¼Œæˆ‘ä»¬è¿›è¡Œäº†20,50,70,â€¦, 1Mæ¬¡è¿­ä»£ã€‚
- en: What is the result of this?
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç»“æœæ˜¯ä»€ä¹ˆï¼Ÿ
- en: '![](../Images/4acb4532e62a463ddd147c98b424ee0f.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4acb4532e62a463ddd147c98b424ee0f.png)'
- en: Image by author
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: Mhhh, so it seems like there is indeed an analytical result right? Letâ€™s find
    out.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ï¼Œçœ‹æ¥ç¡®å®å­˜åœ¨ä¸€ä¸ªåˆ†æç»“æœï¼Œå¯¹å—ï¼Ÿè®©æˆ‘ä»¬æ¥çœ‹çœ‹ã€‚
- en: 'So, Bayesâ€™ theorem tells us that:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œè´å¶æ–¯å®šç†å‘Šè¯‰æˆ‘ä»¬ï¼š
- en: '![](../Images/fa169e5da4f72824d0578b42efb59a8c.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fa169e5da4f72824d0578b42efb59a8c.png)'
- en: Image by author
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: So the probability that an extracted football **comes from the** **blue bowl**
    is equal to the probability of extracting a football **from the blue bowl (***notice
    the difference! this is the probability of extracting a football GIVEN THE FACT
    THAT YOU PICKED THE BLUE BOWL***)** multiplied by the probability of extracting
    from a **blue bowl** divided by the probability of extracting a **football.**
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæå–åˆ°çš„è¶³çƒ**æ¥è‡ª** **è“è‰²ç¢—**çš„æ¦‚ç‡ç­‰äºæå–ä¸€ä¸ªè¶³çƒ**ä»è“è‰²ç¢—ï¼ˆ***æ³¨æ„åŒºåˆ«ï¼è¿™æ˜¯åœ¨ä½ é€‰æ‹©äº†è“è‰²ç¢—çš„å‰æä¸‹æå–ä¸€ä¸ªè¶³çƒçš„æ¦‚ç‡***)**çš„æ¦‚ç‡ä¹˜ä»¥ä»**è“è‰²ç¢—**æå–çš„æ¦‚ç‡ï¼Œé™¤ä»¥æå–**è¶³çƒ**çš„æ¦‚ç‡ã€‚
- en: 'We know that:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çŸ¥é“ï¼š
- en: '![](../Images/892214e9bd65def6210abb0c518d9a89.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/892214e9bd65def6210abb0c518d9a89.png)'
- en: Image by author
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: Cause there are only the football balls in the blue bowl. We also assume that
    we are picking one of the two bowls with equal probabilities.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºè“è‰²ç¢—ä¸­åªæœ‰è¶³çƒã€‚æˆ‘ä»¬è¿˜å‡è®¾æˆ‘ä»¬ä»¥ç›¸ç­‰çš„æ¦‚ç‡é€‰æ‹©ä¸¤ä¸ªç¢—ä¸­çš„ä¸€ä¸ªã€‚
- en: 'So we had:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬æœ‰ï¼š
- en: '![](../Images/b85721a4bdb0281539ddc20e47419030.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b85721a4bdb0281539ddc20e47419030.png)'
- en: Image by author
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: 'Now, the probability of picking the football is the sum of picking the football
    from the white bowl and picking the football from the blue bowl. Like:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæå–è¶³çƒçš„æ¦‚ç‡æ˜¯ä»ç™½è‰²ç¢—ä¸­æå–è¶³çƒçš„æ¦‚ç‡å’Œä»è“è‰²ç¢—ä¸­æå–è¶³çƒçš„æ¦‚ç‡ä¹‹å’Œã€‚ä¾‹å¦‚ï¼š
- en: '![](../Images/275360dfbea41ddf2cf3724a1f3ba07b.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/275360dfbea41ddf2cf3724a1f3ba07b.png)'
- en: Image by author
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: 'So we have:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬æœ‰ï¼š
- en: '![](../Images/5a1be32fe9e16aca21b91b0fb4c868e5.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5a1be32fe9e16aca21b91b0fb4c868e5.png)'
- en: Image by author
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: 'Because:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºï¼š
- en: '![](../Images/9bb8fb6dd963118c53306a973f8fdbdc.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9bb8fb6dd963118c53306a973f8fdbdc.png)'
- en: Image by author
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: 'So we have:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬æœ‰ï¼š
- en: '![](../Images/d766e8f77c3353591b0f6a136adec5f0.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d766e8f77c3353591b0f6a136adec5f0.png)'
- en: Image by author
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: 'And if we plot 5/6 in the previous plot we made we get that:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬åœ¨ä¹‹å‰ç»˜åˆ¶çš„å›¾ä¸Šç»˜åˆ¶5/6ï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°ï¼š
- en: '![](../Images/e0e6ea52c1030a0858d9948170b1778f.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e0e6ea52c1030a0858d9948170b1778f.png)'
- en: Image by author
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: We did the math right ğŸ˜„
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„æ•°å­¦è®¡ç®—æ˜¯æ­£ç¡®çš„ ğŸ˜„
- en: 'Ok so at this point I am positive you are all thinking:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ï¼Œè¿™æ—¶æˆ‘ç›¸ä¿¡ä½ ä»¬éƒ½åœ¨æƒ³ï¼š
- en: â€œWhat does it have to do with Machine Learning at all?â€
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œè¿™ä¸æœºå™¨å­¦ä¹ æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿâ€
- en: Letâ€™s find out ğŸ˜
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ¥çœ‹çœ‹ ğŸ˜
- en: 2\. Naive Bayes Classifier
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨
- en: The Naive Bayes Classifier is the **Naive** application of the **Bayes** theorem
    to a Machine Learning **classifier:** as simple as that.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨æ˜¯**æœ´ç´ **åœ°å°†**è´å¶æ–¯**å®šç†åº”ç”¨äºæœºå™¨å­¦ä¹ **åˆ†ç±»å™¨**çš„è¿‡ç¨‹ï¼šå°±æ˜¯è¿™ä¹ˆç®€å•ã€‚
- en: Letâ€™s say we have a certain binary classification problem (class 1 and class
    2). You have N instances and each instance has its label Y.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªç‰¹å®šçš„äºŒåˆ†ç±»é—®é¢˜ï¼ˆç±»åˆ«1å’Œç±»åˆ«2ï¼‰ã€‚ä½ æœ‰Nä¸ªå®ä¾‹ï¼Œæ¯ä¸ªå®ä¾‹éƒ½æœ‰å…¶æ ‡ç­¾Yã€‚
- en: 'The so-called **prior probability** is defined as the following:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€è°“çš„**å…ˆéªŒæ¦‚ç‡**å®šä¹‰å¦‚ä¸‹ï¼š
- en: '![](../Images/460ebdeba045701844437988f87531ad.png)![](../Images/b18459c6bed99eb5547dc9465b76c857.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/460ebdeba045701844437988f87531ad.png)![](../Images/b18459c6bed99eb5547dc9465b76c857.png)'
- en: Image by author
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: 'Now what we really want to know is: given a certain instance, what is the probability
    that **that** instance belongs to class 1? What is the probability that belongs
    to class 2?'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬çœŸæ­£æƒ³çŸ¥é“çš„æ˜¯ï¼šç»™å®šä¸€ä¸ªç‰¹å®šçš„å®ä¾‹ï¼Œ**é‚£ä¸ª**å®ä¾‹å±äºç±»åˆ«1çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿå±äºç±»åˆ«2çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ
- en: 'So what we are interested in is, given an instance x:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬æ„Ÿå…´è¶£çš„æ˜¯ï¼Œç»™å®šä¸€ä¸ªå®ä¾‹xï¼š
- en: '![](../Images/4b2b4c09fb6a56faf101fa56aaa206b1.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b2b4c09fb6a56faf101fa56aaa206b1.png)'
- en: Image by author
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: 'In a binary dataset, we have that the sum of these two quantities is 1, so
    we actually only need one of these two quantities. Now this quantity might look
    a mystery, but the other one:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨äºŒå…ƒæ•°æ®é›†ä¸­ï¼Œæˆ‘ä»¬çŸ¥é“è¿™ä¸¤ä¸ªæ•°é‡çš„æ€»å’Œæ˜¯1ï¼Œå› æ­¤å®é™…ä¸Šæˆ‘ä»¬åªéœ€è¦å…¶ä¸­ä¸€ä¸ªã€‚ç°åœ¨è¿™ä¸ªæ•°é‡å¯èƒ½çœ‹èµ·æ¥æœ‰äº›ç¥ç§˜ï¼Œä½†å¦ä¸€ä¸ªï¼š
- en: '![](../Images/1bdd6071c51410a6d69c978afbdc80cb.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1bdd6071c51410a6d69c978afbdc80cb.png)'
- en: Image by author
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: can be computed very easily (remember the bowl/balls example!).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ä»¥éå¸¸å®¹æ˜“åœ°è®¡ç®—ï¼ˆè®°ä½ç¢—/çƒçš„ä¾‹å­ï¼ï¼‰ã€‚
- en: It is also very easy to compute the probability of P(x), in the same way, that
    we computed P(class 1) and P(class 2).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: è®¡ç®—P(x)çš„æ¦‚ç‡ä¹Ÿéå¸¸ç®€å•ï¼Œå°±åƒæˆ‘ä»¬è®¡ç®—P(class 1)å’ŒP(class 2)ä¸€æ ·ã€‚
- en: 'So we can actually compute:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å®é™…ä¸Šå¯ä»¥è®¡ç®—ï¼š
- en: '![](../Images/b2b0804ee2a11f067702b9768a38167c.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b2b0804ee2a11f067702b9768a38167c.png)'
- en: Image by author
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: All of this looks good. Now I think you might have an understanding of why we
    called it **naive**. It is Naive because it is nothing more than counting the
    occurrences and using Bayesian logic to infer the prediction.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸€åˆ‡çœ‹èµ·æ¥éƒ½å¾ˆå¥½ã€‚ç°åœ¨æˆ‘æƒ³ä½ å¯èƒ½å·²ç»ç†è§£äº†æˆ‘ä»¬ä¸ºä»€ä¹ˆç§°ä¹‹ä¸º**æœ´ç´ **ã€‚å®ƒä¹‹æ‰€ä»¥æœ´ç´ ï¼Œæ˜¯å› ä¸ºå®ƒä¸è¿‡æ˜¯è®¡æ•°å‡ºç°æ¬¡æ•°å¹¶ä½¿ç”¨è´å¶æ–¯é€»è¾‘æ¥æ¨æ–­é¢„æµ‹ã€‚
- en: Letâ€™s apply it to a toy dataset. We have these two classes and two features
    generated using [sklearn.datasets](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html)
    library.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å°†å…¶åº”ç”¨åˆ°ä¸€ä¸ªç©å…·æ•°æ®é›†ä¸Šã€‚æˆ‘ä»¬æœ‰è¿™ä¸¤ä¸ªç±»åˆ«å’Œä¸¤ä¸ªç‰¹å¾ï¼Œæ˜¯ä½¿ç”¨[sklearn.datasets](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html)åº“ç”Ÿæˆçš„ã€‚
- en: Fantastic.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: å¤ªæ£’äº†ã€‚
- en: 'So:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼š
- en: '![](../Images/9797c30b7c7147eed0a7fd9ebc110595.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9797c30b7c7147eed0a7fd9ebc110595.png)'
- en: Image by author
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: Because we have two dimensions.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºæˆ‘ä»¬æœ‰ä¸¤ä¸ªç»´åº¦ã€‚
- en: '**Given the class 0**, we can easily compute what is the probability of a given
    area (a small area around a 2D point).'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç»™å®šç±»åˆ«0**ï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾è®¡ç®—ç»™å®šåŒºåŸŸï¼ˆ2Dç‚¹å‘¨å›´çš„å°åŒºåŸŸï¼‰çš„æ¦‚ç‡ã€‚'
- en: 'So:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼š
- en: We know how to compute the **posterior** probability, that is P(Y|X)
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çŸ¥é“å¦‚ä½•è®¡ç®—**åéªŒ**æ¦‚ç‡ï¼Œå³P(Y|X)
- en: We have our set of Y and X
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰æˆ‘ä»¬çš„Yå’ŒXé›†åˆ
- en: We can apply the rule to the **training set**, and we can **predict** our test
    set results
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å°†è§„åˆ™åº”ç”¨äº**è®­ç»ƒé›†**ï¼Œå¹¶ä¸”å¯ä»¥**é¢„æµ‹**æµ‹è¯•é›†çš„ç»“æœã€‚
- en: Letâ€™s do it!
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¼€å§‹å§ï¼
- en: '**Train-Test split**:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è®­ç»ƒ-æµ‹è¯•åˆ†å‰²**ï¼š'
- en: '2\. **Importing** and **fitting the Naive Bayes Classifier**:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. **å¯¼å…¥**å’Œ**æ‹Ÿåˆæœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨**ï¼š
- en: Note that we are adding a bias to our data (x). This is because the Bayes classifier
    we are using considers our x_1 feature as a **categorical** feature and we consider
    these features as numerical ones. A more rigorous approach is using the *LabelEncoder()*feature,
    but in this specific case, it is exactly equivalent.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œæˆ‘ä»¬å¯¹æ•°æ®ï¼ˆxï¼‰æ·»åŠ äº†ä¸€ä¸ªåç½®ã€‚è¿™æ˜¯å› ä¸ºæˆ‘ä»¬ä½¿ç”¨çš„è´å¶æ–¯åˆ†ç±»å™¨å°†x_1ç‰¹å¾è§†ä¸º**åˆ†ç±»**ç‰¹å¾ï¼Œè€Œæˆ‘ä»¬å°†è¿™äº›ç‰¹å¾è§†ä¸ºæ•°å€¼ç‰¹å¾ã€‚ä¸€ç§æ›´ä¸¥æ ¼çš„æ–¹æ³•æ˜¯ä½¿ç”¨*LabelEncoder()*ç‰¹å¾ï¼Œä½†åœ¨è¿™ä¸ªç‰¹å®šæƒ…å†µä¸‹ï¼Œå®ƒä»¬æ˜¯å®Œå…¨ç­‰ä»·çš„ã€‚
- en: '3\. **Testing the performance**:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. **æµ‹è¯•æ€§èƒ½**ï¼š
- en: The performance, in this very simple toy example, is obviously (almost) perfect.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªéå¸¸ç®€å•çš„ç©å…·ç¤ºä¾‹ä¸­ï¼Œæ€§èƒ½æ˜¾ç„¶æ˜¯ï¼ˆå‡ ä¹ï¼‰å®Œç¾çš„ã€‚
- en: 3\. Gaussian Naive Bayes Classifier
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. é«˜æ–¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨
- en: You probably have had enough of me talking, I am sorry for that.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½å·²ç»å¬å¤Ÿäº†æˆ‘è®²çš„å†…å®¹ï¼Œæˆ‘å¯¹æ­¤æ„Ÿåˆ°æŠ±æ­‰ã€‚
- en: I just want to close this article by talking about the Gaussian Naive Bayes.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åªæ˜¯æƒ³é€šè¿‡è°ˆè®ºé«˜æ–¯æœ´ç´ è´å¶æ–¯æ¥ç»“æŸè¿™ç¯‡æ–‡ç« ã€‚
- en: In the previous example, we consider the features to be **categorical.** But
    what happens when they are not?
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å‰é¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†ç‰¹å¾è§†ä¸º**åˆ†ç±»**çš„ã€‚ä½†å¦‚æœå®ƒä»¬ä¸æ˜¯å‘¢ï¼Ÿ
- en: 'Well, we have to assume a certain distribution of the likelihood: **P(Y|X)**.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ï¼Œæˆ‘ä»¬å¿…é¡»å‡è®¾ä¸€ä¸ªç‰¹å®šçš„å¯èƒ½æ€§åˆ†å¸ƒï¼š**P(Y|X)**ã€‚
- en: '![](../Images/8522e72ad44166c55c56dd2c7b450e92.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8522e72ad44166c55c56dd2c7b450e92.png)'
- en: Image by author
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: So it is called **gaussian** Naive Bayes because the likelihood is considered
    to be gaussian, as you see above. The mean (mu_y) and variance (sigma_y squared)
    are computed by computing the mean and variance of the classes.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å®ƒå«åš**é«˜æ–¯**æœ´ç´ è´å¶æ–¯ï¼Œå› ä¸ºå¦‚ä¸Šæ‰€è§ï¼Œä¼¼ç„¶è¢«è®¤ä¸ºæ˜¯é«˜æ–¯çš„ã€‚å‡å€¼ï¼ˆmu_yï¼‰å’Œæ–¹å·®ï¼ˆsigma_yå¹³æ–¹ï¼‰æ˜¯é€šè¿‡è®¡ç®—ç±»åˆ«çš„å‡å€¼å’Œæ–¹å·®å¾—åˆ°çš„ã€‚
- en: Notice that now we donâ€™t need to add the Bias to our data anymore.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œç°åœ¨æˆ‘ä»¬ä¸å†éœ€è¦åœ¨æ•°æ®ä¸­æ·»åŠ åå·®ã€‚
- en: These are the results
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ˜¯ç»“æœ
- en: 4\. Wrapping it up
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4. æ€»ç»“
- en: 'In this article we:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬ï¼š
- en: '**Acknowledge the existence of Bayesâ€™ Theorem**. We had an intuitive introduction
    to it and we did a very simple controlled case to see how it works.'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ‰¿è®¤è´å¶æ–¯å®šç†çš„å­˜åœ¨**ã€‚æˆ‘ä»¬å¯¹å®ƒè¿›è¡Œäº†ç›´è§‚çš„ä»‹ç»ï¼Œå¹¶è¿›è¡Œäº†ä¸€ä¸ªéå¸¸ç®€å•çš„å—æ§æ¡ˆä¾‹æ¥æŸ¥çœ‹å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚'
- en: '**Saw how Bayesâ€™ Theorem can be applied to Machine Learning**. What is Y, what
    is X, and how we can put them into the Bayesâ€™ Formula to get some predictions
    in a **classification task**.'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**äº†è§£è´å¶æ–¯å®šç†å¦‚ä½•åº”ç”¨äºæœºå™¨å­¦ä¹ **ã€‚ä»€ä¹ˆæ˜¯Yï¼Œä»€ä¹ˆæ˜¯Xï¼Œæˆ‘ä»¬å¦‚ä½•å°†å®ƒä»¬æ”¾å…¥è´å¶æ–¯å…¬å¼ä¸­ä»¥åœ¨**åˆ†ç±»ä»»åŠ¡**ä¸­è¿›è¡Œä¸€äº›é¢„æµ‹ã€‚'
- en: We made up our own dataset and we used the **Categorial Naive Bayes** class
    of **sklearn** to do a toy classification task. It worked almost perfectly but
    had the problem of working only with categorical features.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è‡ªå·±åˆ›å»ºäº†ä¸€ä¸ªæ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨**Categorial Naive Bayes**ç±»ï¼ˆæ¥è‡ª**sklearn**ï¼‰è¿›è¡Œäº†ä¸€é¡¹ç©å…·åˆ†ç±»ä»»åŠ¡ã€‚å®ƒå‡ ä¹å®Œç¾åœ°å·¥ä½œï¼Œä½†æœ‰ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯åªèƒ½å¤„ç†åˆ†ç±»ç‰¹å¾ã€‚
- en: We saw how to extend the Categorical Naive Bayes into **Gaussian Naive Bayes.**
    The Gaussian Naive Bayes, as we saw above, uses a Gaussian Likelihood to work.
    This Gaussian Likelihood works with noncategorical features as well.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬äº†è§£äº†å¦‚ä½•å°†åˆ†ç±»æœ´ç´ è´å¶æ–¯æ‰©å±•ä¸º**Gaussian Naive Bayes**ã€‚æ­£å¦‚æˆ‘ä»¬æ‰€è§ï¼ŒGaussian Naive Bayesä½¿ç”¨é«˜æ–¯ä¼¼ç„¶æ¥å·¥ä½œã€‚è¿™ç§é«˜æ–¯ä¼¼ç„¶ä¹Ÿé€‚ç”¨äºéåˆ†ç±»ç‰¹å¾ã€‚
- en: The Bayes Theorem is applied in Machine Learning in a lot of other ways, like
    the Bayesian Neural Networks or the Bayesian Ridge Regression. I feel that this
    is a very cool introductive example of what the application of the Bayes Theorem
    can do in a classification problem. I had a lot of fun writing it and I really
    hope you loved it! ğŸ¥°
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: è´å¶æ–¯å®šç†åœ¨æœºå™¨å­¦ä¹ ä¸­ä»¥å¤šç§æ–¹å¼åº”ç”¨ï¼Œå¦‚è´å¶æ–¯ç¥ç»ç½‘ç»œæˆ–è´å¶æ–¯å²­å›å½’ã€‚æˆ‘è§‰å¾—è¿™æ˜¯ä¸€ä¸ªå¾ˆé…·çš„å…¥é—¨ç¤ºä¾‹ï¼Œå±•ç¤ºäº†è´å¶æ–¯å®šç†åœ¨åˆ†ç±»é—®é¢˜ä¸­çš„åº”ç”¨ã€‚æˆ‘å†™è¿™ç¯‡æ–‡ç« éå¸¸å¼€å¿ƒï¼Œå¸Œæœ›ä½ ä»¬å–œæ¬¢å®ƒï¼ğŸ¥°
- en: 5\. Conclusions
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5. ç»“è®º
- en: 'If you liked the article and you want to know more about machine learning,
    or you just want to ask me something, you can:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œæƒ³äº†è§£æ›´å¤šå…³äºæœºå™¨å­¦ä¹ çš„å†…å®¹ï¼Œæˆ–è€…åªæ˜¯æƒ³é—®æˆ‘ä¸€äº›é—®é¢˜ï¼Œä½ å¯ä»¥ï¼š
- en: A. Follow me on [**Linkedin**](https://www.linkedin.com/in/pieropaialunga/),
    where I publish all my stories
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: A. åœ¨ [**Linkedin**](https://www.linkedin.com/in/pieropaialunga/) ä¸Šå…³æ³¨æˆ‘ï¼Œæˆ‘ä¼šå‘å¸ƒæˆ‘çš„æ‰€æœ‰æ•…äº‹ã€‚
- en: B. Subscribe to my [**newsletter**](https://piero-paialunga.medium.com/subscribe).
    It will keep you updated about new stories and give you the chance to text me
    to receive all the corrections or doubts you may have.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: B. è®¢é˜…æˆ‘çš„ [**æ–°é—»é€šè®¯**](https://piero-paialunga.medium.com/subscribe)ã€‚å®ƒå°†è®©ä½ äº†è§£æ–°æ•…äº‹ï¼Œå¹¶ç»™ä½ æœºä¼šé€šè¿‡çŸ­ä¿¡ä¸æˆ‘è”ç³»ï¼Œè·å–ä½ å¯èƒ½æœ‰çš„æ‰€æœ‰æ›´æ­£æˆ–ç–‘é—®ã€‚
- en: C. Become a [**referred member**](https://piero-paialunga.medium.com/membership),
    so you wonâ€™t have any â€œmaximum number of stories for the monthâ€ and you can read
    whatever I (and thousands of other Machine Learning and Data Science top writers)
    write about the newest technology available.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: C. æˆä¸º [**ä¼šå‘˜**](https://piero-paialunga.medium.com/membership)ï¼Œè¿™æ ·ä½ å°±æ²¡æœ‰â€œæ¯æœˆæœ€å¤§æ•…äº‹æ•°â€çš„é™åˆ¶ï¼Œå¯ä»¥é˜…è¯»æˆ‘ï¼ˆå’Œå…¶ä»–æ•°åƒåæœºå™¨å­¦ä¹ å’Œæ•°æ®ç§‘å­¦é¡¶çº§ä½œè€…ï¼‰å…³äºæœ€æ–°æŠ€æœ¯çš„æ‰€æœ‰æ–‡ç« ã€‚
