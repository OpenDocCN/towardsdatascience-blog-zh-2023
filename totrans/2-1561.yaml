- en: Naive Bayes Classifier from Scratch, with Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从头开始的朴素贝叶斯分类器，使用Python
- en: 原文：[https://towardsdatascience.com/naive-bayes-classifier-from-scratch-with-python-942708211470](https://towardsdatascience.com/naive-bayes-classifier-from-scratch-with-python-942708211470)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/naive-bayes-classifier-from-scratch-with-python-942708211470](https://towardsdatascience.com/naive-bayes-classifier-from-scratch-with-python-942708211470)
- en: From theory to practice with Bayes Theorem
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从理论到实践，运用贝叶斯定理
- en: '[](https://piero-paialunga.medium.com/?source=post_page-----942708211470--------------------------------)[![Piero
    Paialunga](../Images/de2185596a49484698733e85114dd1ff.png)](https://piero-paialunga.medium.com/?source=post_page-----942708211470--------------------------------)[](https://towardsdatascience.com/?source=post_page-----942708211470--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----942708211470--------------------------------)
    [Piero Paialunga](https://piero-paialunga.medium.com/?source=post_page-----942708211470--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://piero-paialunga.medium.com/?source=post_page-----942708211470--------------------------------)[![Piero
    Paialunga](../Images/de2185596a49484698733e85114dd1ff.png)](https://piero-paialunga.medium.com/?source=post_page-----942708211470--------------------------------)[](https://towardsdatascience.com/?source=post_page-----942708211470--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----942708211470--------------------------------)
    [Piero Paialunga](https://piero-paialunga.medium.com/?source=post_page-----942708211470--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----942708211470--------------------------------)
    ·10 min read·Jan 4, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----942708211470--------------------------------)
    ·阅读时间10分钟·2023年1月4日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/0861ef7d4e87fc5bedc5552305cb25bc.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0861ef7d4e87fc5bedc5552305cb25bc.png)'
- en: Photo by [Joel Abraham](https://unsplash.com/@joe_27?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/8RRYJg26Wr4?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 由[Joel Abraham](https://unsplash.com/@joe_27?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)拍摄，图片来源于[Unsplash](https://unsplash.com/photos/8RRYJg26Wr4?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: 'Math and Physics are full of theorems, equations, principles, axioms, and corollaries.
    When I started studying Physics I remembered I got to the point where all the
    courses I studied had the same structures:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 数学和物理充满了定理、方程、原理、公理和推论。当我开始学习物理时，我记得我达到了所有课程都具有相同结构的阶段：
- en: A. Defining the **fundamental assumptions**
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: A. 定义**基本假设**
- en: B. Using math to build the next “**brick of the wall**”
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: B. 使用数学构建下一个“**砖块**”
- en: C. **Stacking one brick on top of the other** until the whole pieces come together
    into an elegant, beautiful, model of a portion of the world
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: C. **一块块地叠加**，直到所有部分汇聚成一个优雅、美丽的世界模型
- en: 'Let’s take the first course I ever did in physics: **calculus.**'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从我学习过的第一门物理课程开始：**微积分**。
- en: 1\. You start with the fundamental assumptions of **sets** and **numbers**.
    You start defining natural, integer, real, and complex numbers.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 你从**集合**和**数字**的基本假设开始。你开始定义自然数、整数、实数和复数。
- en: 2\. From there you start defining **functions** that are nothing but a **map**
    from space A (let’s say N-dimensional real space) to space B (let’s say a 1D real
    space).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 从这里开始，你定义的**函数**不过是从空间A（假设是N维实数空间）到空间B（假设是1维实数空间）的**映射**。
- en: 3\. Then you start with the **study** of the functions. So you start analyzing
    their minima, maxima, and saddle points. You accidentally (*ops!*) get to know
    the concept of **“derivative**”.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 然后你开始**研究**函数。于是你开始分析它们的最小值、最大值和鞍点。你偶然（*哦！*）了解了**“导数”**的概念。
- en: 4\. Then you see how you can **integrate** a function, that is the opposite
    of the **derivative**.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 然后你看看如何**积分**一个函数，那是**导数**的反过程。
- en: 5\. Then you combine these things with **differential equations.**
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. 然后你将这些与**微分方程**结合起来。
- en: 'Don’t get me wrong: that process is **amazing**. I loved to see how far human
    logic can bring you. I loved to see that very complex natural events can be derived
    by starting from very simple concepts that evolve into way deeper implications.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 不要误解我：这个过程是**惊人的**。我喜欢看到人类逻辑能带你多远。我喜欢看到非常复杂的自然事件可以通过从非常简单的概念开始逐步推导出更深的含义。
- en: Another valuable science lesson is the fact that a theorem that is originally
    applied to **“A”** can also be applied to “B”, “C”, “D” and “E”.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个宝贵的科学课程是，最初应用于**“A”**的定理，也可以应用于“B”、“C”、“D”和“E”。
- en: The fascinating aspect is that the field “A” and the other fields (B, C, D,
    and E) don’t have to be related.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 令人着迷的方面在于，领域“A”和其他领域（B、C、D和E）不必相关。
- en: Possibly the **greatest example** of that is **Bayes’ Theorem**.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 可能**最好的例子**就是**贝叶斯定理**。
- en: Bayes’ theorem is something that is, in a certain way, an elementary and obvious
    concept. The incredibly cool thing is that we can build some very interesting
    algorithms by stressing the idea behind Bayes’ Theorem and applying it to Machine
    Learning. This tool is called the **Naive Bayes Classifier**
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理在某种程度上是一个基础且显而易见的概念。令人难以置信的酷事是，我们可以通过强调贝叶斯定理背后的理念并将其应用于机器学习来构建一些非常有趣的算法。这个工具被称为**朴素贝叶斯分类器**。
- en: 'In this article:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中：
- en: We will give a brief introduction to **Bayes’ theorem**. We will explain what
    it is, why it is important, and how it can be applied to **Machine Learning**
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将简要介绍**贝叶斯定理**。我们将解释它是什么，为什么重要，以及它如何应用于**机器学习**。
- en: We will see an application of the Bayes theorem in a made-up **classification
    task.**
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将看到贝叶斯定理在一个虚构的**分类任务**中的应用。
- en: We will see a leveled-up version of the Bayes theorem using the so-called **Gaussian
    Naive Bayes classifier.**
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将看到一个升级版的贝叶斯定理，使用所谓的**高斯朴素贝叶斯分类器**。
- en: I’m so excited. Let’s start this!
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我非常兴奋。让我们开始吧！
- en: 1\. About the Bayes Theorem
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 关于贝叶斯定理
- en: 'There was one definition of the Bayes Theorem that has really stuck in my brain:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个关于贝叶斯定理的定义一直深深地印在我的脑海里：
- en: “The Bayes Theorem is that theorem that proves that just because your car is
    blue it doesn’t mean that all the cars of the world are blue **but** if all the
    cars of the world are blue **then** your car must be blue”
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “贝叶斯定理是这样的定理，它证明了仅仅因为你的车是蓝色的，并不意味着全世界的车都是蓝色的**但**如果全世界的车都是蓝色的**那么**你的车必须是蓝色的。”
- en: If you read this [article](https://medium.com/towards-data-science/from-theory-to-practice-with-bayesian-neural-network-using-python-9262b611b825)
    about Bayesian Neural Networks you probably recognize it is the same definition
    but I swear I didn’t use the same definition twice **because I’m lazy!** I mean…
    I **am lazy** but that is not the reason.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你阅读了这篇[文章](https://medium.com/towards-data-science/from-theory-to-practice-with-bayesian-neural-network-using-python-9262b611b825)关于贝叶斯神经网络，你可能会认识到这与之前的定义相同，但我发誓我没有因为**懒惰**而重复使用同一定义！我的意思是……我**确实很懒**，但这不是原因。
- en: I use that definition because it helps us understand that **event A given a
    condition of event B** does not have the same probability of happening as **event
    B given the condition of event A**.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用那个定义是因为它帮助我们理解**事件A在事件B的条件下**的发生概率与**事件B在事件A的条件下**的发生概率是不一样的。
- en: Let me do another example to overcome my laziness.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我做一个新的例子来克服我的懒惰。
- en: Let’s say we have two bowls
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有两个碗
- en: '![](../Images/2bf3a6d955208812a1c85bdc730b0ca1.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2bf3a6d955208812a1c85bdc730b0ca1.png)'
- en: Now, let’s say that these two bowls are full of **basketball** and **football**
    (it’s called **football**, not *soccer*) **balls**.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设这两个碗里满是**篮球**和**足球**（称为**足球**，不是*足球*）**球**。
- en: '![](../Images/afcf95d180c1f284ac39be7064deb4aa.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/afcf95d180c1f284ac39be7064deb4aa.png)'
- en: Image by author
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图片
- en: 'Now, let’s say that I ask you that question:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设我问你这个问题：
- en: “ **KNOWING** that I picked a ball from the **blue** bowl, what is the probability
    that I picked a **football** ball ”
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “**知道**我从**蓝色**碗里挑了一个球，挑到一个**足球**球的概率是多少。”
- en: 'Well, the answer is very simple. The probability is **1,** because, on the
    **blue bowl**, I only have football balls. Now let’s say that I pick a bowl randomly
    with equal probability (0.5 probability of picking the white bowl and 0.5 probability
    of picking the blue bowl). Let me ask you this question:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，答案很简单。概率是**1**，因为在**蓝色碗**里，我只有足球球。现在假设我随机挑选一个碗（挑选白色碗和挑选蓝色碗的概率都是0.5）。让我问你这个问题：
- en: “ KNOWING that I picked a football ball, what is the probability that I picked
    that ball from the blue bowl? ”
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “知道我挑了一个足球，选择这个球来自蓝色碗的概率是多少？”
- en: As you can see, the question is kind of the same but event A **(I picked a football
    ball)** and event B **(I picked the blue bowl)** have the opposite order.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，问题有点类似，但事件A**（我挑了一个足球）**和事件B**（我挑了蓝色碗）**的顺序正好相反。
- en: Now, I think that you kind of guessed that the answer is not the same, because
    I could pick the football ball from the white bowl rather than the blue one. I
    also think you kind of guessed that this probability is still high though because
    I only have one football ball in the white bowl.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我想你可能已经猜到答案并不相同，因为我可能从白色碗中而不是蓝色碗中提取了足球。我也认为你可能猜到这个概率仍然很高，因为我在白色碗中只有一个足球。
- en: Let’s do the experiment in **Python**.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在**Python**中进行实验。
- en: 'I can go into the line-by-line detail of it but I’d find that pretty boring.
    What I’m doing here is nothing but setting the situation of bowls and balls like
    we did before and then running the probabilistic experiment **N** times. At the
    end of these N iterations, we will have N results. Then we will have to compute
    our probability as a **frequentist** probability. In this case, we will compute:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以逐行详细解释，但我觉得那样很无聊。我所做的仅仅是设置碗和球的情况，就像之前一样，然后运行概率实验**N**次。在这N次迭代结束时，我们将得到N个结果。然后我们需要将概率计算为**频率主义**概率。在这种情况下，我们将计算：
- en: '![](../Images/f459332f8822862dff2f032a5591fc02.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f459332f8822862dff2f032a5591fc02.png)'
- en: Image by author
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Now we know that if we run N = infinite times in the same experiments we will
    converge to the analytical result, so we will iteratively increase N and see if
    it converges to whatever result.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道，如果我们在相同的实验中运行N = 无限次，我们将收敛到分析结果，因此我们将迭代地增加N，看看它是否收敛到任何结果。
- en: As you see, we did 20,50,70,…, 1M iterations.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们进行了20,50,70,…, 1M次迭代。
- en: What is the result of this?
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果是什么？
- en: '![](../Images/4acb4532e62a463ddd147c98b424ee0f.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4acb4532e62a463ddd147c98b424ee0f.png)'
- en: Image by author
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Mhhh, so it seems like there is indeed an analytical result right? Let’s find
    out.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，看来确实存在一个分析结果，对吗？让我们来看看。
- en: 'So, Bayes’ theorem tells us that:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，贝叶斯定理告诉我们：
- en: '![](../Images/fa169e5da4f72824d0578b42efb59a8c.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fa169e5da4f72824d0578b42efb59a8c.png)'
- en: Image by author
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: So the probability that an extracted football **comes from the** **blue bowl**
    is equal to the probability of extracting a football **from the blue bowl (***notice
    the difference! this is the probability of extracting a football GIVEN THE FACT
    THAT YOU PICKED THE BLUE BOWL***)** multiplied by the probability of extracting
    from a **blue bowl** divided by the probability of extracting a **football.**
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，提取到的足球**来自** **蓝色碗**的概率等于提取一个足球**从蓝色碗（***注意区别！这是在你选择了蓝色碗的前提下提取一个足球的概率***)**的概率乘以从**蓝色碗**提取的概率，除以提取**足球**的概率。
- en: 'We know that:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道：
- en: '![](../Images/892214e9bd65def6210abb0c518d9a89.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/892214e9bd65def6210abb0c518d9a89.png)'
- en: Image by author
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Cause there are only the football balls in the blue bowl. We also assume that
    we are picking one of the two bowls with equal probabilities.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 因为蓝色碗中只有足球。我们还假设我们以相等的概率选择两个碗中的一个。
- en: 'So we had:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们有：
- en: '![](../Images/b85721a4bdb0281539ddc20e47419030.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b85721a4bdb0281539ddc20e47419030.png)'
- en: Image by author
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'Now, the probability of picking the football is the sum of picking the football
    from the white bowl and picking the football from the blue bowl. Like:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，提取足球的概率是从白色碗中提取足球的概率和从蓝色碗中提取足球的概率之和。例如：
- en: '![](../Images/275360dfbea41ddf2cf3724a1f3ba07b.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/275360dfbea41ddf2cf3724a1f3ba07b.png)'
- en: Image by author
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'So we have:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们有：
- en: '![](../Images/5a1be32fe9e16aca21b91b0fb4c868e5.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5a1be32fe9e16aca21b91b0fb4c868e5.png)'
- en: Image by author
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'Because:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 因为：
- en: '![](../Images/9bb8fb6dd963118c53306a973f8fdbdc.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9bb8fb6dd963118c53306a973f8fdbdc.png)'
- en: Image by author
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'So we have:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们有：
- en: '![](../Images/d766e8f77c3353591b0f6a136adec5f0.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d766e8f77c3353591b0f6a136adec5f0.png)'
- en: Image by author
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'And if we plot 5/6 in the previous plot we made we get that:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在之前绘制的图上绘制5/6，我们会得到：
- en: '![](../Images/e0e6ea52c1030a0858d9948170b1778f.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e0e6ea52c1030a0858d9948170b1778f.png)'
- en: Image by author
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: We did the math right 😄
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数学计算是正确的 😄
- en: 'Ok so at this point I am positive you are all thinking:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，这时我相信你们都在想：
- en: “What does it have to do with Machine Learning at all?”
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “这与机器学习有什么关系？”
- en: Let’s find out 😏
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看 😏
- en: 2\. Naive Bayes Classifier
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 朴素贝叶斯分类器
- en: The Naive Bayes Classifier is the **Naive** application of the **Bayes** theorem
    to a Machine Learning **classifier:** as simple as that.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯分类器是**朴素**地将**贝叶斯**定理应用于机器学习**分类器**的过程：就是这么简单。
- en: Let’s say we have a certain binary classification problem (class 1 and class
    2). You have N instances and each instance has its label Y.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个特定的二分类问题（类别1和类别2）。你有N个实例，每个实例都有其标签Y。
- en: 'The so-called **prior probability** is defined as the following:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 所谓的**先验概率**定义如下：
- en: '![](../Images/460ebdeba045701844437988f87531ad.png)![](../Images/b18459c6bed99eb5547dc9465b76c857.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/460ebdeba045701844437988f87531ad.png)![](../Images/b18459c6bed99eb5547dc9465b76c857.png)'
- en: Image by author
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'Now what we really want to know is: given a certain instance, what is the probability
    that **that** instance belongs to class 1? What is the probability that belongs
    to class 2?'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们真正想知道的是：给定一个特定的实例，**那个**实例属于类别1的概率是多少？属于类别2的概率是多少？
- en: 'So what we are interested in is, given an instance x:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们感兴趣的是，给定一个实例x：
- en: '![](../Images/4b2b4c09fb6a56faf101fa56aaa206b1.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b2b4c09fb6a56faf101fa56aaa206b1.png)'
- en: Image by author
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'In a binary dataset, we have that the sum of these two quantities is 1, so
    we actually only need one of these two quantities. Now this quantity might look
    a mystery, but the other one:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在二元数据集中，我们知道这两个数量的总和是1，因此实际上我们只需要其中一个。现在这个数量可能看起来有些神秘，但另一个：
- en: '![](../Images/1bdd6071c51410a6d69c978afbdc80cb.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1bdd6071c51410a6d69c978afbdc80cb.png)'
- en: Image by author
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: can be computed very easily (remember the bowl/balls example!).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 可以非常容易地计算（记住碗/球的例子！）。
- en: It is also very easy to compute the probability of P(x), in the same way, that
    we computed P(class 1) and P(class 2).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 计算P(x)的概率也非常简单，就像我们计算P(class 1)和P(class 2)一样。
- en: 'So we can actually compute:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们实际上可以计算：
- en: '![](../Images/b2b0804ee2a11f067702b9768a38167c.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b2b0804ee2a11f067702b9768a38167c.png)'
- en: Image by author
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: All of this looks good. Now I think you might have an understanding of why we
    called it **naive**. It is Naive because it is nothing more than counting the
    occurrences and using Bayesian logic to infer the prediction.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这一切看起来都很好。现在我想你可能已经理解了我们为什么称之为**朴素**。它之所以朴素，是因为它不过是计数出现次数并使用贝叶斯逻辑来推断预测。
- en: Let’s apply it to a toy dataset. We have these two classes and two features
    generated using [sklearn.datasets](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html)
    library.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将其应用到一个玩具数据集上。我们有这两个类别和两个特征，是使用[sklearn.datasets](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html)库生成的。
- en: Fantastic.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了。
- en: 'So:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 所以：
- en: '![](../Images/9797c30b7c7147eed0a7fd9ebc110595.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9797c30b7c7147eed0a7fd9ebc110595.png)'
- en: Image by author
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Because we have two dimensions.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们有两个维度。
- en: '**Given the class 0**, we can easily compute what is the probability of a given
    area (a small area around a 2D point).'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '**给定类别0**，我们可以轻松计算给定区域（2D点周围的小区域）的概率。'
- en: 'So:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 所以：
- en: We know how to compute the **posterior** probability, that is P(Y|X)
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们知道如何计算**后验**概率，即P(Y|X)
- en: We have our set of Y and X
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们有我们的Y和X集合
- en: We can apply the rule to the **training set**, and we can **predict** our test
    set results
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以将规则应用于**训练集**，并且可以**预测**测试集的结果。
- en: Let’s do it!
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: '**Train-Test split**:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练-测试分割**：'
- en: '2\. **Importing** and **fitting the Naive Bayes Classifier**:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. **导入**和**拟合朴素贝叶斯分类器**：
- en: Note that we are adding a bias to our data (x). This is because the Bayes classifier
    we are using considers our x_1 feature as a **categorical** feature and we consider
    these features as numerical ones. A more rigorous approach is using the *LabelEncoder()*feature,
    but in this specific case, it is exactly equivalent.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们对数据（x）添加了一个偏置。这是因为我们使用的贝叶斯分类器将x_1特征视为**分类**特征，而我们将这些特征视为数值特征。一种更严格的方法是使用*LabelEncoder()*特征，但在这个特定情况下，它们是完全等价的。
- en: '3\. **Testing the performance**:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. **测试性能**：
- en: The performance, in this very simple toy example, is obviously (almost) perfect.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个非常简单的玩具示例中，性能显然是（几乎）完美的。
- en: 3\. Gaussian Naive Bayes Classifier
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 高斯朴素贝叶斯分类器
- en: You probably have had enough of me talking, I am sorry for that.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经听够了我讲的内容，我对此感到抱歉。
- en: I just want to close this article by talking about the Gaussian Naive Bayes.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我只是想通过谈论高斯朴素贝叶斯来结束这篇文章。
- en: In the previous example, we consider the features to be **categorical.** But
    what happens when they are not?
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们将特征视为**分类**的。但如果它们不是呢？
- en: 'Well, we have to assume a certain distribution of the likelihood: **P(Y|X)**.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，我们必须假设一个特定的可能性分布：**P(Y|X)**。
- en: '![](../Images/8522e72ad44166c55c56dd2c7b450e92.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8522e72ad44166c55c56dd2c7b450e92.png)'
- en: Image by author
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: So it is called **gaussian** Naive Bayes because the likelihood is considered
    to be gaussian, as you see above. The mean (mu_y) and variance (sigma_y squared)
    are computed by computing the mean and variance of the classes.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 所以它叫做**高斯**朴素贝叶斯，因为如上所见，似然被认为是高斯的。均值（mu_y）和方差（sigma_y平方）是通过计算类别的均值和方差得到的。
- en: Notice that now we don’t need to add the Bias to our data anymore.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，现在我们不再需要在数据中添加偏差。
- en: These are the results
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是结果
- en: 4\. Wrapping it up
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4. 总结
- en: 'In this article we:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们：
- en: '**Acknowledge the existence of Bayes’ Theorem**. We had an intuitive introduction
    to it and we did a very simple controlled case to see how it works.'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**承认贝叶斯定理的存在**。我们对它进行了直观的介绍，并进行了一个非常简单的受控案例来查看它是如何工作的。'
- en: '**Saw how Bayes’ Theorem can be applied to Machine Learning**. What is Y, what
    is X, and how we can put them into the Bayes’ Formula to get some predictions
    in a **classification task**.'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**了解贝叶斯定理如何应用于机器学习**。什么是Y，什么是X，我们如何将它们放入贝叶斯公式中以在**分类任务**中进行一些预测。'
- en: We made up our own dataset and we used the **Categorial Naive Bayes** class
    of **sklearn** to do a toy classification task. It worked almost perfectly but
    had the problem of working only with categorical features.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们自己创建了一个数据集，并使用**Categorial Naive Bayes**类（来自**sklearn**）进行了一项玩具分类任务。它几乎完美地工作，但有一个问题，就是只能处理分类特征。
- en: We saw how to extend the Categorical Naive Bayes into **Gaussian Naive Bayes.**
    The Gaussian Naive Bayes, as we saw above, uses a Gaussian Likelihood to work.
    This Gaussian Likelihood works with noncategorical features as well.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们了解了如何将分类朴素贝叶斯扩展为**Gaussian Naive Bayes**。正如我们所见，Gaussian Naive Bayes使用高斯似然来工作。这种高斯似然也适用于非分类特征。
- en: The Bayes Theorem is applied in Machine Learning in a lot of other ways, like
    the Bayesian Neural Networks or the Bayesian Ridge Regression. I feel that this
    is a very cool introductive example of what the application of the Bayes Theorem
    can do in a classification problem. I had a lot of fun writing it and I really
    hope you loved it! 🥰
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理在机器学习中以多种方式应用，如贝叶斯神经网络或贝叶斯岭回归。我觉得这是一个很酷的入门示例，展示了贝叶斯定理在分类问题中的应用。我写这篇文章非常开心，希望你们喜欢它！🥰
- en: 5\. Conclusions
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5. 结论
- en: 'If you liked the article and you want to know more about machine learning,
    or you just want to ask me something, you can:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这篇文章，想了解更多关于机器学习的内容，或者只是想问我一些问题，你可以：
- en: A. Follow me on [**Linkedin**](https://www.linkedin.com/in/pieropaialunga/),
    where I publish all my stories
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: A. 在 [**Linkedin**](https://www.linkedin.com/in/pieropaialunga/) 上关注我，我会发布我的所有故事。
- en: B. Subscribe to my [**newsletter**](https://piero-paialunga.medium.com/subscribe).
    It will keep you updated about new stories and give you the chance to text me
    to receive all the corrections or doubts you may have.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: B. 订阅我的 [**新闻通讯**](https://piero-paialunga.medium.com/subscribe)。它将让你了解新故事，并给你机会通过短信与我联系，获取你可能有的所有更正或疑问。
- en: C. Become a [**referred member**](https://piero-paialunga.medium.com/membership),
    so you won’t have any “maximum number of stories for the month” and you can read
    whatever I (and thousands of other Machine Learning and Data Science top writers)
    write about the newest technology available.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: C. 成为 [**会员**](https://piero-paialunga.medium.com/membership)，这样你就没有“每月最大故事数”的限制，可以阅读我（和其他数千名机器学习和数据科学顶级作者）关于最新技术的所有文章。
