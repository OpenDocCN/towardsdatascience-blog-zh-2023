# RAG 的未被揭示的一面：解决领域特定搜索中的挑战

> 原文：[https://towardsdatascience.com/the-untold-side-of-rag-addressing-its-challenges-in-domain-specific-searches-808956e3ecc8](https://towardsdatascience.com/the-untold-side-of-rag-addressing-its-challenges-in-domain-specific-searches-808956e3ecc8)

## 通过混合搜索、层级排名和讲师嵌入，解决我们 RAG 设置中类似的领域特定文档问题。

[](https://agustinus-nalwan.medium.com/?source=post_page-----808956e3ecc8--------------------------------)[![Agustinus Nalwan](../Images/7c5ade9ab8bca1d27a317b5c09d1b734.png)](https://agustinus-nalwan.medium.com/?source=post_page-----808956e3ecc8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----808956e3ecc8--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----808956e3ecc8--------------------------------) [Agustinus Nalwan](https://agustinus-nalwan.medium.com/?source=post_page-----808956e3ecc8--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----808956e3ecc8--------------------------------) ·29 分钟阅读·2023 年 10 月 18 日

--

![](../Images/4e2dd6573d0b19b4a98e8fb5dbae636d.png)

生成式 AI 增强的搜索技术（图像由 MidJourney 生成）

[Carsales](https://www.carsales.com.au/) 作为领先的汽车平台，服务于澳大利亚、智利、韩国和美国的汽车和生活方式车辆市场。我们的目标是重新定义汽车买卖体验，树立无与伦比的标准。为此，我们的一个关键功能是一个全面的搜索工具，能够扫描数万篇与汽车相关的编辑文章。我们目前集成了 Google 搜索——专门为我们的编辑内容量身定制并通过 iframe 展示——结果虽然不错，但主要依赖于词汇（关键词）关联，有时忽略了搜索查询的真实本质或语义。

![](../Images/95dce076f1586ea6916a057ff1db4e15.png)

使用现有的 Google 搜索结果

例如，搜索“Toyota Corolla 2020 年气囊数量？”会返回包含“Toyota Corolla 和气囊”字样的任何文章等。然而，这些文章大多讨论的是气囊召回，而非实际的气囊数量。商业方面有强烈需求，不仅要从技术上提升这个工具，还要重新设计其界面，使其更加无缝地集成到我们的网站中，超越仅仅是一个 Google 搜索结果的 iframe。

在2023年7月，我们举办了我们的全球黑客马拉松之一。这项活动通常会吸引来自各部门的参与者，组建团队，提出创意，并在紧张的三天内将这些创意转化为可用的原型。随着大型语言模型（LLMs）的日益重要，我们确定了一个理想的项目：使用LLM改进我们的搜索工具。更棒的是，我们赢得了这次黑客马拉松！感谢我们了不起的团队，他们为此付出了极大的努力！

在本文中，我们将首先概述我们项目的基本概念。之后，我们将谈论我们的初步RAG方法。随后，我们将重点讨论在确保准确和相关的文档检索及生成直接答案中面临的挑战。然后，我们将讨论我们实施的解决方案来应对文档检索难题。不过，我们将把直接答案生成的讨论留到下一篇文章中，以保持本文的简洁。

# 概念

我们设想的模型是简单明了的。我们希望在收到搜索查询后得到两方面的结果：

+   相关文档：虽然这与我们现有的功能相似，但我们的目标是通过检索与查询意图相符的文档（基于意义的匹配），而不仅仅是基于词汇的匹配（直接词匹配），来提高其效能。

+   直接回答：每当查询以问题的形式提出并且我们的系统可以从编辑资源中得出答案时，我们希望呈现这一直接答案。这个新颖的功能有望显著丰富用户互动。

![](../Images/411946cf07ccf38b02e7bb45e172b31e.png)

使用我们概念化的RAG方法的搜索结果

在利用大型语言模型（LLMs）进行文档检索并通过组织的知识库提供直接答案时，通常有两种方法：

+   微调LLM：这涉及到使用您组织独特的知识库（在我们的情况下是我们的编辑文章集合）来精炼基础LLM。这确保了LLM可以准确回答与这些文章相关的问题。

+   检索增强生成（RAG）：在这里，策略是将上下文相关的编辑文章与提出的问题一同提供给LLM，使其能够生成准确的回答。

微调直接将知识融入模型中，减少了对LLM的大量提示的依赖。然而，这也带来了挑战：需要不断更新LLM以包含新的或修订的文章，并且运行微调模型的操作成本显著增加——可能是基础LLM的十倍。鉴于这些，大多数人，包括我们，都更倾向于RAG方法。

# 检索增强生成

检索增强生成（RAG）可能听起来很复杂，但其原理很简单。想象一下将我们的查询分成三个部分：首先，问题本身，例如“丰田卡罗拉混合动力 2020 的燃油消耗是多少？”其次，给 LLM 的指令，使用我们接下来提供的文档来构建回答。最后，是可能找到答案的文档上下文。

![](../Images/68298f348f487fbde220ff4092889fef.png)

RAG 简述

从本质上讲，这就是 RAG 的核心。自然地，你可能会想知道我们如何从我们库中的成千上万篇文章中筛选出相关的文章作为文档上下文来回答提出的问题。

为什么不把所有的文章都包含在文档上下文中呢？考虑到 45,000 篇文章，每篇文章有 10,000 字，总计 4.5 亿字。最新的 LLM Claude 2 仅支持 100,000 令牌的窗口。即使未来的模型扩展了容量，相关的成本和处理时间也将是巨大的。我们的目标是根据与查询的相关性对文章进行排名。文章内容与查询越相似，它越可能包含答案。因此，我们选择最相关的 X 篇文章作为我们的文档上下文。这就是为什么我们需要向量数据库的原因。

# 向量数据库和密集嵌入

向量数据库本质上存储的是向量，这些向量是浮点数的数组。那么这如何解决我们的挑战呢？进入密集嵌入，这是一种 NLP 技术，它将文本（我们的文档）转换为向量形式。这种向量通常更有效地 encapsulates 文本的语义本质，从而允许更准确地比较两段文本之间的相似性。

在密集嵌入出现之前，我们通过计算文档之间的常见词汇来衡量文档的相似性。让我们用一个例子来说明。给定问题“丰田卡罗拉 2020 有多少个气囊？”，以下哪一句话与其更为贴近？

***丰田卡罗拉 2020*** *由于* ***气囊*** *线圈以及* ***其他*** *诸多问题而被召回。*

***丰田卡罗拉 2020*** *配备了七个* ***气囊*** *和一个备份摄像头。*

使用简单的词匹配，第一个句子有六个常见术语，看起来更像是问题。然而，本质上，第二个句子虽然只有四个匹配的术语，但更相关，因为它涉及到关于气囊数量的查询。即使排除停用词（have 和 many），它们仍然都有四个匹配的术语。

当我们使用密集嵌入技术将问题和两个句子转换为向量并将它们可视化到二维平面上时，第二个句子与问题的接近度变得显而易见，特别是在基于余弦距离（向量之间的角度）评估相似性时。

利用这一能力，我们可以将所有文档与给定问题相关联，只选择最相似的四篇文章作为 LLM 的上下文，而不是筛选整个 45,000 篇文档。向量大小可以根据使用的密集嵌入方法而有所不同。最初，我们使用了 OpenAI 的 text-embedding-ada-002，这种方法生成了 1536 的向量大小。

这是该过程的一个详细说明：

起初，在索引阶段，我们使用密集嵌入方法将所有文章转换为向量表示，并将这些向量保存在像 Pinecone 这样的向量数据库中。当需要推断时，我们也将提出的问题转换为查询向量，使用相同的嵌入技术。这个查询向量随后被输入到 Pinecone 中，Pinecone 检索出四篇最相关的文章。Pinecone 无缝地计算查询向量与我们存储的所有文档向量之间的余弦距离，以返回最相关的四篇文档。接下来，我们将这些选定文章的内容作为文档上下文提供给 LLM，连同原始问题和一个生成回答的指示。

![](../Images/4b13f0fd8a0f4a3b55ea8c2b6692de8e.png)

RAG 架构

本质上，这捕捉了增强检索生成（RAG）的精髓。大多数 RAG 实现包括某些改进，以提高所选文档的相关性，从而影响最终答案的准确性，接下来我会讨论这一点。

## 切分我们的文档

典型的编辑文章可能长达 10,000 字。发送四篇最相关的文档作为上下文，可能意味着处理多达 40,000 字的内容，这可能是一个资源密集型的任务，特别是在频繁调用的情况下。例如，丰田卡罗拉 2020 年的编辑评论可能涉及从安全特性和定价到燃油效率的各个方面，这些信息分布在不同的段落中。往往，特定问题的答案可以仅定位于这几段内容。这就避免了传输整个文章进行处理的必要。

实际意义是什么？与其将整个文档转换为向量，不如将其分割成较小的块（通常为一到两个段落）并将这些块转换为密集向量——这个过程被称为“文档切分”。

有趣的是，文档切分不仅能节省我们的处理时间，还能提高文档检索的准确性。你会问怎么做？

以丰田卡罗拉混合动力轿车评论的一段为例：

> 新款丰田卡罗拉满足了很多要求。值得一提的是，这款四门车型比其五门掀背车长 255 毫米，车长为 4630 毫米。
> 
> 车内配备了许多有用的功能，如全系标配的 Apple CarPlay 和 Android Auto，并显示在一块 8 英寸的触摸屏上。所有车型还标配自适应雷达巡航控制。
> 
> 尽管动力不足，这款混合动力Corolla轿车却非常省油。声称的燃油经济性为3.5L/100，这使它成为该国第二高效的丰田车辆。

如观察所示，第一个段落讨论了汽车的尺寸，第二个段落详细说明了数字设备的功能，而第三个段落则专注于燃油效率。

如果我们将这些段落分别分成不同的密集向量，我们将生成三个独特的文档向量，这些向量位于不同的嵌入空间，每个向量象征着不同的主题。

假设查询是“Toyota Corolla的尺寸是多少？”。第一个段落变成最相关的文档。对于类似“CarPlay是否可用？”的问题，第二个段落优先考虑。

然而，将所有三个段落合并成一个密集向量会产生一个更为泛化的向量，这可能无法有效地指向特定的主题。嵌入文档越大，向量越被稀释，最终无法准确捕捉特定主题。随着时间的推移，由于密集向量包含了许多重叠的主题，如安全性或内部特征，其独特性减少，从而降低了文档检索的精度。

![](../Images/1aee999dd192bb43d19445c41774ae4d.png)

随着文档块变大，密集嵌入失去了其特异性

鉴于这些因素，我们将文档划分为块，每块包含300个标记。此外，我们还使用了Langchain框架中的RecursiveCharacterTextSplitter技术。

这种方法对文本进行层次化分类：首先优先考虑段落，然后是句子，最后是单个单词。我们的目标是尽可能在300个标记的范围内保留整个段落。如果不能，则将其分解为句子，然后是单词。将段落分成不同的块可能会导致丢失与当前主题相关的重要背景。

为了增强每个段落内的上下文连续性，我们确保后续段落与前面的段落重叠100个标记。这种策略确保了当一个长段落被分成多个段落时，这些段落之间的共享词语有助于减少潜在的上下文丢失。

例如，考虑下面的段落。

> 在其他地方，备受期待的Model S更新借鉴了较小的Tesla Model 3和即将推出的Tesla Model Y的内部元素，包括更新的17.0英寸中央触摸屏显示器，具备卫星导航、互联网功能，以及大量游戏、视频流媒体和特斯拉备受推崇的“复活节彩蛋”。

当段落被分成两个独立的部分而没有任何重叠内容时，后续部分将失去对讨论的具体车型的参考。

> 块 1：
> 
> 另外，期待已久的Model S改款借鉴了较小的**特斯拉Model 3**和即将推出的**特斯拉Model Y**的内饰元素，包括更新的17.0英寸中控触摸屏

块2：

> 中控触摸屏具备卫星导航、互联网功能，并且有大量游戏和视频流服务。

由于内容重叠（用粗体标出），上下文现在得到更好的保留。

> 块1：
> 
> 另外，期待已久的Model S改款借鉴了较小的**特斯拉Model 3**和即将推出的**特斯拉Model Y**的内饰元素，包括更新的17.0英寸中控触摸屏，具备卫星导航、互联网功能，并且有大量游戏和视频流服务。
> 
> 块2：
> 
> **特斯拉Model 3**和即将推出的**特斯拉Model Y**的内饰元素，包括更新的17.0英寸中控触摸屏，具备卫星导航、互联网功能，并且有大量游戏和视频流服务。

## 注入高级上下文

在我们的编辑文章中，段落通常省略了对具体车型的明确提及。这通常是因为从文章标题或早期段落中可以隐含得出。以以下第二段为例。虽然读者从之前的上下文中知道这是关于**丰田卡罗拉2020混合动力轿车**的，但该特定型号在段落中并未明确提及。设想有20篇不同的文章段落，每篇文章都讨论了不同的汽车但都提到了像**Apple CarPlay**和**Android Auto**这样的共同特性。当每个段落变成单独的文档块时，它们的密集向量嵌入可能会非常相似。因此，如果用户问：“丰田卡罗拉2020混合动力轿车是否配备了**Apple CarPlay**和**Android Auto**？”，查询向量可能与这20个文档块中的任何一个相似，导致检索困难。

> 新款**丰田卡罗拉**满足了很多要求。值得一提的是，这款四门轿车比它的五门掀背车长了255毫米，总长度为4630毫米。
> 
> 内部配备了许多实用功能，如覆盖整个系列的**Apple CarPlay**和**Android Auto**，并显示在一个8英寸的触摸屏显示器上。自适应雷达巡航控制也是所有车型的标准配置。
> 
> 虽然动力不是很强劲，但混合动力卡罗拉轿车非常省油。宣称的燃油经济性为3.5L/100公里，使其成为在这个国家中第二高效的丰田车型。

为了应对这一挑战，我们在每个文档块的开头加入文章标题，通常会说明汽车的品牌、型号和发布年份。这一整合确保了密集向量嵌入反映这一关键信息。

> 标题：**丰田卡罗拉2020混合动力轿车评测**
> 
> 新款**丰田卡罗拉**满足了很多要求。值得一提的是，这款四门轿车比它的五门掀背车长了255毫米，总长度为4630毫米。
> 
> 标题：**丰田卡罗拉2020混合动力轿车评测**
> 
> 内部配备了许多实用功能，如覆盖整个系列的**Apple CarPlay**和**Android Auto**，并显示在一个8英寸的触摸屏显示器上。自适应雷达巡航控制也是所有车型的标准配置。
> 
> 标题：2020年丰田卡罗拉混合动力轿车评测
> 
> 尽管起步加速不算迅猛，但混合动力卡罗拉轿车却极其省油。宣称的燃油经济性为3.5L/100公里，使其成为在本国可用的第二节能的丰田车辆。

## 采用单样本学习

大型语言模型（LLMs）在没有直接培训的任务上表现优异。将指令与示例配对通常会产生更好的结果。执行没有示例的任务称为零样本学习，而有示例的任务称为单样本学习。遵循常见的RAG方法论，我们使用单样本学习，提供一个示例。

## 引入源文章引用

我们的下一个目标是显示答案的来源。引用来源通过提供可追溯的参考来提升用户体验，促进更深入的探索和验证。这种透明度增强了用户信任，使他们能够验证答案，从而提高我们平台的信心。此外，这可以减少大型语言模型如LLMs中常见的“幻觉”问题，这些模型有时会提供错误的答案。通过让LLMs引用来源文章，我们避免了错误回答，因为它们不能引用不存在的来源。这类似于人类行为：人们在没有可验证来源的情况下会犹豫回答。以下是我们的用户提示，基于[Langchain](https://www.langchain.com/)模板，指导LLM在SOURCES字段中包含来源。请确保你在回答中始终返回一个“SOURCES”部分。

我们在{question}占位符中注入了实际问题，并在{document-context}占位符中注入了我们的四个主要文档块及其来源。

[PRE0]

在实施我们的系统后，我们迫不及待地将RAG投入测试，期待与LLM的首次互动。然而，一旦初期的热情消退，我们发现了一些问题，主要涉及两个方面：文档检索的质量和生成的直接回答的准确性。这在我们几乎一半的测试案例中发生了。

说实话，直接回答相关的大部分问题源于所选文档作为上下文的质量不够充分。然而，本文将专注于文档检索挑战及我们解决这些挑战的策略。敬请关注即将发布的文章，深入探讨答案生成的复杂性。

# 问题

## 与年份不相关的汽车文章排名较高

当我们用查询“2018年马自达CX-9评测”搜索Pinecone数据库时，系统返回了三个文档片段。令人惊讶的是，前两个结果来自马自达CX-9 2019年和2017年评测文章，而2018年评测（我们实际的目标）仅排名第三。

> (1) 标题：2019年马自达CX-9：视频评测
> 
> 马自达 CX-9 已经成为 Carsales 办公室的最爱。它获得了我们 2016 年年度汽车奖，并且在大多数多车比较中仍能排在前列。2019 年，CX-9 进行了更新，马自达表示，它已经解决了之前存在的一些小问题…
> 
> (2) 标题: 马自达 CX-9 2017 年评测
> 
> CX-9 型号，仅次于 Azami，GT 版本无论内外都相当豪华。二十英寸的轮毂、镀铬装饰、无钥匙进入和 LED 行车灯赋予我们的“魂红”版外观高贵…
> 
> (3) 标题: 马自达 CX-9 2018 年评测 — 澳大利亚
> 
> 马自达 CX-9 系列中有一款新车型。顶级的 CX-9 Azami LE 本月将在澳大利亚上市，配备了更多的设备、技术，并且重要的是，增加了奢华感。它成为了 2019 年款马自达 CX-9 系列的亮点…

对于查询“马自达 CX-9 2019 年油耗是多少？”，系统未能提供关于马自达 CX-9 2019 年款油耗的具体结果。所有返回的文档都是不同年份的。第一个是 2010 年款的文档。讨论马自达 CX-9 2019 年油耗的文档标题为“马自达 CX-8 与马自达 CX-9 2019 年比较”。这个文档竟然排名第六，这意味着它没有作为文档上下文提供给 LLM 生成直接答案。

> (1) 标题: 马自达 CX-9 现在更瘦、更轻、更亮
> 
> 马自达正逐年降低 CX-9 型号的综合循环油耗。三年前发布时，CX-9 的油耗为 13.0L/100km。去年的一次升级将这一数据减少到 12.2L/100km，而昨天宣布的另一项升级正式将油耗再次降低至 11.3L/100km…
> 
> (2) 标题: 马自达 CX-9 2016 年评测
> 
> 170kW、2.5 升四缸涡轮增压汽油发动机，配合六速自动变速器。没有手动选项或柴油动力系统，这也得归功于该车重心放在开发美国市场。尽管如此，这款汽油发动机仍然能够在其尺寸的车辆中实现令人印象深刻的燃油经济性，承诺综合循环油耗为 8.8L/100km…
> 
> (3) 标题: 马自达 CX-9 2018 年评测
> 
> 油耗也是一个持续考虑的因素，我们已经行驶了数千公里，大多数情况下车上有两个人，油耗读数仍然徘徊在 10.0L/100km 左右。注意：这一最新的油耗数据比 CX-9 的两驱版本略高，后者的平均油耗为 9.2L/100km，这一数据来源于行程计算机和我们自己的独立测试。两者都高于其官方数据…
> 
> …
> 
> (6) 标题: 马自达 CX-8 与马自达 CX-9 2019 年比较
> 
> 马自达CX-9是一款评价非常高的车辆，曾获carsales.com.au年度汽车奖以及其他多个奖项。但它仅配备了170kW/420Nm的2.5升四缸涡轮增压汽油发动机，搭配六速自动变速器。再加上全轮驱动——正如我们在这次测试中自然地做的——整车重量达到1924公斤。但马自达仍然声称其合理的油耗为8.8L/100km。我们将在高速公路、小道和泥土路上进行测试…

## 文档检索未返回优先考虑文章时效性的文章

进一步检查显示，我们的文档检索系统忽略了文章的时效性，常常忽视优先考虑更新内容。

例如，搜索“丰田卡罗拉”会得到2010年和2013年的文章作为前几个结果。令人惊讶的是，关于丰田卡罗拉2020年的更相关文章，由于其时效性，应该更受关注，却被排在了第15位。

> (1) 标题：丰田公布下一代卡罗拉轿车
> 
> 额外的轮胎隔音。美国市场的标准配置包括八个安全气囊、蓝牙、空调、玻璃内置收音机天线、60/40分割后座靠背以及LED近光灯和日间行车灯——丰田称这是小型车市场中的首创…
> 
> (2) 标题：丰田卡罗拉：2013年小型车大测试
> 
> 丰田卡罗拉Ascent Sport（掀背车）我们喜欢的：材料质量有所提升 性能敏锐 价值令人印象深刻 不喜欢的：平坦的仪表板设计 繁琐的触摸屏 没有后座通风口 路上表现 当丰田章男在2009年掌控全球最大的汽车公司时，他设定了一个目标，即注入…
> 
> …
> 
> (15) 标题：丰田卡罗拉轿车2020年评测
> 
> 丰田卡罗拉是全球销量最高的汽车之一——但大多数人想到（并购买）的是掀背车。卡罗拉轿车一直有些，嗯，被遗忘。但现在风向有所改变。全新的设计、更高的配置水平、更具吸引力的驾驶体验…

## 特定汽车品牌型号的文章排名高于通用文章

经过进一步分析，可以明显看出，像“什么是混合动力车？”这样的查询，结果很混杂。返回的第一篇文档是通用的，第二篇则介于两者之间，而第三篇和第四篇专门讨论本田混合动力车。对于此类查询，大多数人更倾向于阅读广泛讨论混合动力车概念、优点和缺点的内容，而不是特定汽车品牌或型号的具体信息。显然，我们的系统未能完全满足这些期望。

> (1) 标题：什么是混合动力车？
> 
> 在动物世界中，混合体是指两种不同物种或品种之间的杂交。在汽车世界中，这个术语已经演变为定义一种既由电动机驱动又由内燃机驱动的汽车。电动机承担了大部分工作，但在混合动力车的最初概念中…
> 
> (2) 标题：混合动力车即将蓬勃发展
> 
> 它是一款混合动力车。然而，它不是普通的混合动力车，如普锐斯或思域。这是一款配备汽油V6发动机和传统后驱的汽车，具有现代外观和高科技、符合人体工程学的设计。丰田产品开发和工程经理Doug Soden预计，澳大利亚的混合动力车销量可能会 …
> 
> (3) 标题：本田混合动力车是一款不错的运动型车
> 
> 2007年2月23日。混合动力技术在即将召开的日内瓦车展上，霍多纳展示了一款体育车原型（如图），将混合动力技术与性能爱好者相结合。小型混合动力运动概念车使用了先进的混合动力技术 …
> 
> (4) 标题：本田思域（2001-）
> 
> 未来50–100年。燃料电池是当前的未来趋势，但可负担的商业化仍然至少需要20年，因此在此期间，许多汽车制造商正走向混合动力路线。混合动力车本质上是由小型汽油发动机和额外的电动机驱动的传统汽车，电动机由可充电电池供电 …

## 关于错误模型的文章正在被返回

在搜索“Mazda CX-9 2023 评测”时，系统主要检索到了关于Mazda CX-8的文章，这是一个错误的模型，尽管这些文章来自2023年。一篇关于Mazda CX-9的2021年文章被藏在结果的更远处，排名第五。一般来说，用户期望看到与他们搜索的特定品牌和型号相关的文章，即使是来自前一年，而不是关于查询年份的完全不同模型的内容。

> (1) 标题：Mazda CX-8 2023 评测
> 
> 自2018年上市以来，Mazda CX-8三排家庭SUV一直是CX系列中更受欢迎车型的配角。但随着CX-9在年底前停产以及一系列全新、更昂贵的SUV即将首发，是时候让CX-8登上聚光灯，显然成为了马自达最实惠的家庭车 …
> 
> (2) 标题：Mazda CX-8 2023 视频评测
> 
> Mazda CX-8 在Mazda全面的CX系列SUV中销售成绩一直处于末尾。但在高端车型正在进行全新一代换代的同时，获奖的CX-9也被停产，CX-8现在显然成为了品牌的三排七座价格引领者 …
> 
> …
> 
> (5) 标题：Mazda CX-9 2021 评测
> 
> 悬挂系统在调校上充分考虑了乘客的舒适度（对有孩子在车上睡觉时很好）。在隔离测试中，CX-9 在乘坐舒适性方面难以挑剔，但正如我们最近与起亚索伦托的比较所证明的那样，马自达在这一领域已经不再是领先者 …

总结一下我们文档检索系统的问题：

+   当查询未指定车型年份时，较新的文章不会被优先考虑。

+   系统经常根据查询中提到的年份匹配文章，即使这会牺牲对车型的匹配度。

+   对于广泛的查询，系统有时会优先考虑特定品牌型号的文章，而非一般文章。

+   系统无法对不同车型年份查询的相关文章进行准确排名。

认识到这些问题至关重要，这表明我们离终点还远。

经过一个集中的分析阶段，跨越了周末和深夜，我们已经锁定了主要问题。

我们的库中充满了关于相同品牌和型号的编辑文章，但来自不同年份，例如 2018 年、2019 年和 2021 年的马自达 CX-9 评测。这些文章的结构布局相似。某些部分讨论燃油效率，而其他部分则侧重于安全性或内部空间。当查询“马自达 CX-9 2019 年燃油效率？”时，会出现多个文档块，每个块都来自不同年份的马自达 CX-9 文章，涉及燃油效率。值得注意的是，每个文档块都标注了其原始文章的标题和年份。因此，可以预期“马自达 CX-8 v 马自达 CX-9 2019 比较”的密集向量与查询的密集向量相比，更加相似于“马自达 CX-9 2016 年评测”的密集向量。

然而，现实并非如此。年份仅仅是大约 300 个内容 token 中的一个单词，并没有发挥应有的作用。在评估更广泛的内容时，第一篇文章似乎比第二篇更侧重于燃油效率。密集嵌入过程未能识别年份在汽车领域中的关键作用。例如，不同年份对应着车辆的不同型号，因此在密集嵌入向量创建过程中，年份应当具有更大的权重。这一困境被标记为领域超出上下文挑战。利用基于通用数据集设计的基础嵌入模型，意味着它忽视了汽车领域的具体细节。

> (1) 标题：马自达 CX-9 2016 年评测
> 
> 170kW，2.5 升四缸涡轮增压汽油发动机配合六速自动变速器。没有手动选项或柴油动力系统，感谢开发此车型的重心在于美国市场，因此缺乏燃料选择。尽管如此，汽油发动机仍然能够为其大小的车辆提供令人印象深刻的燃油经济性，承诺的综合循环燃油消耗为 8.8L/100km …
> 
> (2) 标题：马自达 CX-8 v 马自达 CX-9 2019 比较
> 
> 马自达 CX-9 是一款评价非常高的车辆，曾获得 carsales.com.au 年度汽车奖和其他多个奖项。但它仅配备了 170kW/420Nm 的 2.5 升四缸涡轮增压汽油发动机，并与六速自动变速器配对。加上全轮驱动——正如我们在测试中所做的——你会发现其整备质量达到 1924 公斤。但马自达仍声称其油耗为 8.8L/100km。我们将在高速公路、小路和泥土路上进行测试……

正是这个问题导致“2023 年马自达 CX-8 评测”在查询“2023 年马自达 CX-9 评测”时排名高于“2021 年马自达 CX-9 评测”。我们的标准模型未能将车型匹配优先于年份匹配，从而导致了这种差异。

一个更简单的类比是考虑“炸鸡”更类似于“鸡汤”还是“炒饭”。答案取决于上下文。如果关注的是配料，“炸鸡”与“鸡汤”更为相似。但从准备的角度来看，它更接近于“炒饭”。这样的解释是领域中心的。

许多 RAG 设置可能会绕过我们面临的挑战，因为他们的索引文章与我们的并不相似。例如，对于客户支持用例，大多数文章有不同的主题，比如“如何重置我的密码”或“如何更改我的电子邮件地址”。

解决这个问题可能需要定制我们的嵌入模型，使用以汽车为重点的数据集。然而，微调存在挑战。我们需要正样本（两个相似的句子）和负样本（两个不同的句子）数据集，这是一项巨大的工作。考虑到我们使用的是 OpenAI 的 text-embedding-ada-002 模型，微调甚至不是一个选项，因为他们尚未提供这一服务。

# 解决方案

我们的探索使我们找到了一种更有前景的解决方案，融合了四种策略：

+   混合搜索（结合稠密和稀疏嵌入）

+   层次文档排名

+   教学稠密嵌入

+   年份提升。

## 混合搜索（结合稠密和稀疏嵌入）

我们解决方案的关键在于稠密和稀疏嵌入的融合，即“混合搜索”。稀疏嵌入本质上类似于传统的关键词或词汇匹配。令人惊讶的是，这正是我们最初希望用稠密嵌入取代的传统方法。

让我们进一步讨论一下这种稀疏嵌入。

在密集嵌入的领域，每个文档块都被封装在一个 1536 维浮点向量中。然而，稀疏嵌入则将这些文档块呈现在一个扩展的维度空间中， resulting in a considerably expansive vector. 从本质上讲，基本的稀疏嵌入是一个向量，其中每个槽位代表词汇表中的一个独特词汇。如果一个词在文档块中出现，则向量中的对应槽位标记为 1；如果没有出现，则保持为 0。为了优化这一点，通常会排除“is”，“and”，“what”等停用词，以简化词汇表的大小。在我们的应用中，我们处理的词汇表大约包含 50,000 个词，相当于一个同样大小的向量。

此外，它们主要的零填充特性优化了存储和计算，因为大多数条目（为零）可以在计算过程中有效地压缩或跳过。计算两个稀疏嵌入向量之间相似度的方式与两个密集嵌入向量相似，利用的是余弦距离。

超越这种基本方法，我们遇到了像 [BM25 排名](https://medium.com/@evertongomede/understanding-the-bm25-ranking-algorithm-19f6d45c6ce) 算法这样的复杂技术。虽然 BM25 的基本思想建立在广泛使用的 TF-IDF（词频-逆文档频率）方法之上——该方法根据术语在文档中的频率相对于所有文档中的频率来强调术语的重要性——BM25 对其进行了改进。BM25 不只是简单地分配二进制值或原始词频，而是为文档块中的每个术语确定一个权重。这个权重受到术语频率和逆文档频率的影响，量化了术语的相关性，使 BM25 在捕捉术语在上下文中的重要性方面更加细致。

稀疏嵌入的吸引力在于它们的准确性；它们在基于文档和查询之间的精确词对词匹配进行文档排名时表现出色。例如，使用稀疏嵌入时，查询“**Mazda CX-9 2019** 的燃油效率是多少？”相比于“**Mazda CX-9** 2016 评测”，会为“Mazda CX8 v **Mazda CX-9 2019** 比较”排名更高。这是因为前者有三个完全匹配的独特词汇，而后者只有两个。

然而，我们不能完全用稀疏嵌入来取代我们的密集嵌入。这样做会使我们回到最初面临的搜索系统挑战，主要是忽视语义意义。虽然密集嵌入在根据语义意义评估文档块方面表现出色，但在通过精确词匹配进行排名时却不尽如人意。相反，稀疏嵌入优先考虑精确的词匹配，但可能忽略更广泛的语义背景。因此，为了利用两种方法的优势，结合它们是至关重要的。这种融合确保了一个更全面和有效的搜索系统。

我们根据两个不同分数的加权平均值来确定文档的排名。初始分数使用与密集嵌入的余弦距离，这是一种我们之前采用的方法。同时，次级分数使用与 BM25 稀疏嵌入的余弦距离。

我们使用以下公式计算最终分数，用于文档排名：

> hybrid_score = 0.75 * dense_score + 0.25 * sparse_score

sparse_score 倾向于选择那些与查询匹配的词语出现频率较高的文档。幸运的是，Pinecone 本地支持这种混合搜索机制。我们的责任是输入密集向量和稀疏向量。通过分配权重，我们强调密集/语义匹配，而不是稀疏/关键词匹配，如 0.75 对 0.25 的比例所示，这样我们可以检索到前 x 个相关的文档片段。

## 分层文档排名

我们的次级方法涉及一个两层的排名系统。最初，分数是基于文档片段中的内容，使用我们的混合搜索公式进行计算。随后，这些分数会得到提升，提升的分数是根据文档标题使用相同公式确定的。

理由是什么？标题虽然简洁，但通常包含了关键的信息，例如汽车的品牌、型号和生产年份，基本上是内容的浓缩总结。因此，仅根据标题对文档进行排名，比仅根据内容排名更有效，这种情况大约发生一半的时间，尤其是在稀疏嵌入的情况下。考虑查询，“**Mazda CX-9 2019** 的燃油效率是多少？”一篇标题为“**Mazda CX-9 2019** 评测”的文章将会胜过“**Mazda CX-9** 2018 评测”，因为前者有更多的匹配术语。

为了整合这一点，我们的公式进行了修改：

> final_score = 0.5 * title_hybrid_score + content_hybrid_score

多亏了这些改进，我们已经观察到文档检索结果相关性的显著提升。例如，查询“**Mazda CX-9 2019** 的燃油效率是多少？”现在最终返回了来自文章“Mazda CX-8 与 Mazda CX-9 2019 比较”的正确文档片段，这归功于稀疏嵌入。

> (1) 标题：Mazda CX-8 与 Mazda CX-9 2019 比较
> 
> Mazda CX-9 是一款评价非常高的车辆，曾获得 carsales.com.au 年度汽车奖以及其他多个奖项。但它只配备了 170kW/420Nm 的 2.5 升四缸涡轮增压汽油发动机，搭配六速自动变速器。再加上全轮驱动——我们在这次测试中自然也用了——你会看到一个重达 1924 公斤的车重。但 Mazda 仍然声称其合理的 8.8L/100km 的燃油消耗数据。我们将在高速公路、小路和泥泞道路上对其进行测试……

但是，仍然存在一个挑战：我们的文档检索系统并没有优先考虑基于汽车品牌/型号的匹配，而是基于型号年份的匹配。

## Instructor Large Dense Embedding

问题源于我们的嵌入模型缺乏汽车行业的特定领域知识，这对于理解基于品牌/型号的匹配比基于生产年份的匹配更重要。

我们的解决方案？过渡到[Instructor Large Embedding](https://instructor-embedding.github.io/)模型。这个最先进的模型提供了一个独特的优势：可以通过简单的文本提示轻松定制到特定领域或任务。除了定制能力外，该模型本身在嵌入质量上也更为优越。

仅通过向Instructor Large模型提供提示“为检索相关文档生成汽车评论文章问题”，它就能够巧妙地优化我们在汽车评论领域的嵌入。这一过程类似于为特定领域微调嵌入模型，但避免了相关成本。因此，我们的嵌入现在能巧妙地将汽车品牌和型号的属性置于生产年份之上。

以下代码展示了Instructor Large嵌入在我们特定需求中的优越性，相较于OpenAI的text-embedding-ada-002。

[PRE1]

我们展示了两种不同的嵌入方法，任务是为这三句话生成稠密表示：

+   Mazda CX-9 2018 Review

+   Mazda CX-8 2018 Review

+   Mazda CX-9 2017 Review

接下来，我们制作了这些句子之间的相似度矩阵（基于余弦距离评分）。text-embedding-ada-002的结果显示，“Mazda CX-9 2018 Review”与“Mazda CX-8 2018 Review”的相似度高于与“Mazda CX-9 2017 Review”的相似度，这不是预期的结果。

![](../Images/cb86616fe61807feff25b91f0a5ec150.png)

text-embedding-ada-002的相似度矩阵（绿色为好，红色为差）

相反，使用Instructor Large模型而不使用自定义提示时，“Mazda CX-9 2018 Review”的稠密嵌入与“Mazda CX-9 2017 Review”的相似度高于与“Mazda CX-8 2018 Review”的相似度——这是预期的结果。

![](../Images/34bd64772a61a0aea493c0cf3f0d318c.png)

Instructor Large的相似度矩阵，未使用自定义提示（绿色为好，红色为差）

当我们加入自定义提示“为检索相关文档生成汽车评论文章问题”时，稠密向量的相似度矩阵显示了改善的结果。你是否注意到“Mazda CX-9 2018 Review”和“Mazda CX-8 2018 Review”之间的相似度评分下降了0.2%，而“Mazda CX-9 2018 Review”和“Mazda CX-9 2017 Review”之间的评分保持不变？

![](../Images/dfa9535853e376a0a962a005f4b4bc2b.png)

Instructor Large的相似度矩阵，使用自定义提示（绿色为好，红色为差）

此外，虽然text-embedding-ada-002由于其对Azure的外部API调用需要1秒钟的完成时间，但Instructor Large的速度较快，在一个合适规模的EC2实例上完成时间不到150毫秒。这显著提升了我们的整体搜索响应时间。

## 年份提升

还有一个最后的挑战：当查询没有指定特定汽车模型年份时，我们的文档检索系统没有优先考虑近期文章。解决这个问题很简单。我们决定给较新的文档分配额外的分数。通过精心设计，我们制定了一个二次函数，为较新的文章添加一个轻微的额外分数，随着文章的年龄增加，这个分数逐渐减少。值得注意的是，我们细致地设计了这个函数，以确保近期性的加分不会超过文档和查询之间年份匹配的相关性。这样，即使查询中提到特定年份，我们也避免了一直偏向较新的文章。

通过这些调整，我们成功解决了绝大多数文档检索问题！下面，您将找到最终的架构图。

![](../Images/9411d7aff3d44194ae803eeb42b94331.png)

我们最终改进的RAG架构

# 结论

我们有效解决了大部分文档检索难题。在我们的离线测试中，40%的结果更倾向于我们的新解决方案而不是现有的Google搜索。我们现在正在将这项技术集成到我们的前端用户体验中，准备进行A/B测试，以真正评估这次改进的搜索与现有版本的效率。如前所述，我们也曾面临直接答案的质量问题。虽然我们找到了一个解决方案，但我会在即将发布的博客文章中*深入探讨*这些细节。

我想传达的一个关键见解是，尽管检索增强生成（RAG）具有巨大的潜力，但它并不是很多文章和帖子所暗示的万能解药，尤其是在最常见的设置下。混合搜索和我们已涵盖的一些其他技术突显出作为增强相关文档检索的有效方法。不断发展的开发和研究领域承诺进一步完善这种方法，使其在未来变得更加稳健。

请通过[linkedin](https://www.linkedin.com/in/agustinus-nalwan/)与我联系。

所有图片，除非另有说明，均由作者提供。

本文中使用的编辑内容在网上公开可用，并且由Carsales拥有。
