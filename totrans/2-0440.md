# 使用Redshift Serverless和Kinesis构建流数据管道

> 原文：[https://towardsdatascience.com/building-a-streaming-data-pipeline-with-redshift-serverless-and-kinesis-04e09d7e85b2](https://towardsdatascience.com/building-a-streaming-data-pipeline-with-redshift-serverless-and-kinesis-04e09d7e85b2)

## 面向初学者的完整教程

[](https://mshakhomirov.medium.com/?source=post_page-----04e09d7e85b2--------------------------------)[![💡Mike Shakhomirov](../Images/bc6895c7face3244d488feb97ba0f68e.png)](https://mshakhomirov.medium.com/?source=post_page-----04e09d7e85b2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----04e09d7e85b2--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----04e09d7e85b2--------------------------------) [💡Mike Shakhomirov](https://mshakhomirov.medium.com/?source=post_page-----04e09d7e85b2--------------------------------)

·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----04e09d7e85b2--------------------------------) ·阅读时间9分钟·2023年10月6日

--

![](../Images/d1700c0485714244a17aec09305461e6.png)

图片由[Sebastian Pandelache](https://unsplash.com/@pandelache?utm_source=medium&utm_medium=referral)拍摄，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

在本文中，我将讨论最受欢迎的数据管道设计模式之一——事件流。除了其他好处，它还支持超快的数据分析，我们可以创建实时更新结果的报告仪表盘。我将演示如何通过构建一个使用AWS Kinesis和Redshift的流数据管道来实现这一点，并且可以通过几次点击使用基础设施即代码进行部署。我们将使用AWS CloudFormation来描述我们的数据平台架构并简化部署过程。

想象一下，作为数据工程师，你的任务是创建一个将服务器事件流与数据仓库解决方案（Redshift）连接起来的数据管道，以便转换数据并创建分析仪表盘。

![](../Images/19d9e86d0773049b03bcd3c4ea66b9ab.png)

管道基础设施。图片来源：作者。

> 什么是数据管道？
> 
> 它是一个数据处理步骤的序列。由于这些阶段之间的***逻辑数据流连接***，每个阶段生成一个**输出**，作为下一个阶段的**输入**。

我之前在这篇文章中写过相关内容：

[](/data-pipeline-design-patterns-100afa4b93e3?source=post_page-----04e09d7e85b2--------------------------------) [## 数据管道设计模式

### 选择合适的架构及示例

towardsdatascience.com](/data-pipeline-design-patterns-100afa4b93e3?source=post_page-----04e09d7e85b2--------------------------------)

例如，事件数据可以由后端的源创建，使用 Kinesis Firehose 或 Kafka 流构建事件流。然后它可以馈送到多个不同的消费者或目的地。

流式处理是企业数据的“必备”解决方案，因其流数据处理能力。它能够实现实时数据分析。

在我们的用例场景中，我们可以设置一个**ELT 流式**数据管道到 AWS Redshift。AWS Firehose 流可以提供这种无缝集成，当数据流被直接上传到数据仓库表时。然后，数据可以被转换以使用 AWS Quicksight 作为 BI 工具来创建报告，例如。

![](../Images/90a8cb4b073924f3113fce5df13ab20c.png)

添加了 BI 组件。图片来源于作者。

> 本教程假设学习者熟悉 AWS CLI 并且具有基本的 Python 知识。

## 工作流程

1\. 首先，我们将使用 AWS CloudFormation 创建 Kinesis 数据流。

2\. 我们将使用 AWS Lambda 向此事件流发送示例数据事件。

3\. 最后，我们将配置 AWS Redshift 集群并测试我们的流式管道。

## 创建 AWS Kinesis 数据流

AWS Kinesis Data Streams 是一个 Amazon Kinesis 实时数据流解决方案。它提供了出色的可扩展性和耐用性，数据流可以被任何消费者访问。

我们可以使用 CloudFormation 模板来创建它。下面的命令行脚本将触发 AWS CLI 命令进行部署：

[PRE0]

并且模板 kinesis-data-stream.yaml 将如下所示：

[PRE1]

非常简单。如果一切顺利，我们将看到我们的 Kinesis 流被部署：

![](../Images/0f33f2db4f4b45e501787735db96cb76.png)

流已创建。图片来源于作者。

## 2\. 创建 AWS Lambda 函数以模拟事件流

现在我们希望将一些事件发送到我们的 Kinesis 数据流。为此，我们可以创建一个无服务器应用程序，例如 AWS Lambda。我们将使用`boto3`库（AWS 的 Python SDK）来构建一个数据连接器与 AWS Kinesis 进行数据源连接。

![](../Images/611621ecd4f8ba97807a73dcbfff5e82.png)

本地运行应用以模拟事件流。图片来源于作者。

我们的应用程序文件夹结构可以如下所示：

[PRE2]

我们的`app.py`必须能够向 Kinesis 数据流发送事件：

[PRE3]

我们希望添加一个帮助函数来生成一些随机事件数据。例如：

[PRE4]

我们可以使用`python-lambda-local`库本地运行和测试 AWS Lambda，方法如下：

[PRE5]

`env.json` 只是一个事件负载，用于本地运行 Lambda。

`config/staging.yaml` 可以包含我们应用程序未来可能需要的任何环境特定设置。例如：

[PRE6]

如果你需要使用`requirements.txt`，它可以如下所示：

[PRE7]

在你的命令行中运行这个：

[PRE8]

这种方法很有用，因为我们可能希望将无服务器应用程序部署到云中并进行调度。我们可以使用 CloudFormation 模板来实现这一点。我之前在这里写过：

[## Infrastructure as Code for Beginners](https://levelup.gitconnected.com/infrastructure-as-code-for-beginners-a4e36c805316?source=post_page-----04e09d7e85b2--------------------------------)

### 使用这些模板像专业人士一样部署数据管道

[levelup.gitconnected.com](https://levelup.gitconnected.com/infrastructure-as-code-for-beginners-a4e36c805316?source=post_page-----04e09d7e85b2--------------------------------)

当我们使用 CloudFormation 模板时，应用程序可以通过类似的 shell 脚本进行部署：

[PRE9]

这是一个灵活的设置，允许我们创建强大的 CI/CD 管道。我记得我在下面的帖子中创建了一个。

[## Continuous Integration and Deployment for Data Platforms

### 数据工程师和 ML Ops 的 CI/CD

[towardsdatascience.com](/continuous-integration-and-deployment-for-data-platforms-817bf1b6bed1?source=post_page-----04e09d7e85b2--------------------------------)

## 创建 Redshift Serverless 资源

现在我们需要为我们的流数据管道创建 Redshift Serverless 集群。我们可以手动或使用 CloudFormation 模板配置 Redshift Workgroup、创建 Namespace 和其他所需资源。

Redshift Serverless 仅仅是一个数据仓库解决方案。它可以执行任何规模的分析工作负载，无需数据仓库基础设施管理。Redshift 运行迅速，并能在几秒钟内从巨量数据中生成洞察。它会自动扩展，为即使是最苛刻的应用程序提供快速性能。

![](../Images/9e11cbe2d920bab18ad3e3c56a7a0a94.png)

例子视图显示了我们应用程序的事件。图像来源于作者。

在我们的案例中，我们可以使用 CloudFormation 模板定义来部署 Redshift 资源。

[PRE10]

所以如果我们在命令行中运行这段代码，它将部署这个堆栈：

[PRE11]

通常，我们希望在私有子网中部署数据库。然而，在开发的早期阶段，你可能希望从开发机器直接访问 Redshift。

> 这不推荐用于生产环境，但在这种开发情况下，你可以先将 Redshift 放入我们的 `default` VPC 子网。
> 
> 现在，当所有所需的管道资源成功配置后，我们可以连接我们的 Kinesis 流和 Redshift 数据仓库。

然后我们可以使用 SQL 语句在 Redshift 中创建 `kinesis_data` 模式：

[PRE12]

这段 SQL 的第一部分将设置 AWS Kinesis 作为数据源。第二部分将创建一个包含我们应用程序事件数据的视图。

确保创建一个具有 `AmazonRedshiftAllCommandsFullAccess` AWS 管理策略的 AWS Redshift 角色。

[PRE13]

就这样。一切准备好运行应用程序以模拟事件数据流。这些事件会立即出现在我们刚刚创建的 Redshift 视图中：

![](../Images/611621ecd4f8ba97807a73dcbfff5e82.png)

应用程序在本地运行。图像来源于作者。

![](../Images/9e11cbe2d920bab18ad3e3c56a7a0a94.png)

示例视图显示了来自我们应用程序的事件。图片由作者提供。

# 结论

我们创建了一个简单而可靠的流数据管道，从使用 AWS Lambda 创建的无服务器应用程序到 AWS Redshift 数据仓库，在那里数据实时转化和摄取。它能够轻松捕获、处理和存储任何规模的数据流。对于任何机器学习（ML）管道都非常适用，其中模型用于检查数据并预测推理端点，因为数据流向其目标。

我们使用基础设施即代码来部署数据管道资源。这是部署不同数据环境中资源的首选方法。

# 推荐阅读

[/continuous-integration-and-deployment-for-data-platforms-817bf1b6bed1?source=post_page-----04e09d7e85b2--------------------------------) [## 数据平台的持续集成和部署

### 数据工程师和 ML 运维的 CI/CD

[Towards Data Science](/continuous-integration-and-deployment-for-data-platforms-817bf1b6bed1?source=post_page-----04e09d7e85b2--------------------------------) [/data-platform-architecture-types-f255ac6e0b7?source=post_page-----04e09d7e85b2--------------------------------) [## 数据平台架构类型

### 它能多大程度上满足你的业务需求？选择的困境。

[Towards Data Science](/data-platform-architecture-types-f255ac6e0b7?source=post_page-----04e09d7e85b2--------------------------------) [https://levelup.gitconnected.com/infrastructure-as-code-for-beginners-a4e36c805316?source=post_page-----04e09d7e85b2--------------------------------) [## 初学者的基础设施即代码

### 使用这些模板像专业人士一样部署数据管道

[LevelUp](https://levelup.gitconnected.com/infrastructure-as-code-for-beginners-a4e36c805316?source=post_page-----04e09d7e85b2--------------------------------)
