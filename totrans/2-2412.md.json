["```py\nfrom ultralytics import YOLO\nimport cv2\nimport time\n\nmodel = YOLO('yolov8n.pt')\n\nimg = cv2.imread('test.jpg')\n\n# First run to 'warm-up' the model\nmodel.predict(source=img, save=False, save_txt=False, conf=0.5, verbose=False)\n\n# Second run\nt_start = time.monotonic()\nresults = model.predict(source=img, save=False, save_txt=False, conf=0.5, verbose=False)\ndt = time.monotonic() - t_start\nprint(\"dT:\", dt)\n\n# Show results\nboxes = results[0].boxes\nnames = model.names\nconfidence, class_ids = boxes.conf, boxes.cls.int()\nrects = boxes.xyxy.int()\nfor ind in range(boxes.shape[0]):\n    print(\"Rect:\", names[class_ids[ind].item()], confidence[ind].item(), rects[ind].tolist())\n```", "```py\nERROR: Cannot install ultralytics\n\nThe conflict is caused by:\n    ultralytics 8.0.124 depends on torch>=1.7.0\n```", "```py\nyolo export model=yolov8n.pt imgsz=640 format=onnx opset=12\n```", "```py\nscp yolov8n.onnx pi@raspberrypi:/home/pi/Documents/YOLO\n```", "```py\nimport cv2\nimport time\n\nmodel: cv2.dnn.Net = cv2.dnn.readNetFromONNX(\"yolov8n.onnx\")\nnames = \"person;bicycle;car;motorbike;aeroplane;bus;train;truck;boat;traffic light;fire hydrant;stop sign;parking meter;bench;bird;\" \\\n        \"cat;dog;horse;sheep;cow;elephant;bear;zebra;giraffe;backpack;umbrella;handbag;tie;suitcase;frisbee;skis;snowboard;sports ball;kite;\" \\\n        \"baseball bat;baseball glove;skateboard;surfboard;tennis racket;bottle;wine glass;cup;fork;knife;spoon;bowl;banana;apple;sandwich;\" \\\n        \"orange;broccoli;carrot;hot dog;pizza;donut;cake;chair;sofa;pottedplant;bed;diningtable;toilet;tvmonitor;laptop;mouse;remote;keyboard;\" \\\n        \"cell phone;microwave;oven;toaster;sink;refrigerator;book;clock;vase;scissors;teddy bear;hair dryer;toothbrush\".split(\";\")\n\nimg = cv2.imread('test.jpg')\nheight, width, _ = img.shape\nlength = max((height, width))\nimage = np.zeros((length, length, 3), np.uint8)\nimage[0:height, 0:width] = img\nscale = length / 640\n\n# First run to 'warm-up' the model\nblob = cv2.dnn.blobFromImage(image, scalefactor=1 / 255, size=(640, 640), swapRB=True)\nmodel.setInput(blob)\nmodel.forward()\n\n# Second run\nt1 = time.monotonic()\nblob = cv2.dnn.blobFromImage(image, scalefactor=1 / 255, size=(640, 640), swapRB=True)\nmodel.setInput(blob)\noutputs = model.forward()\nprint(\"dT:\", time.monotonic() - t1)\n\n# Show results\noutputs = np.array([cv2.transpose(outputs[0])])\nrows = outputs.shape[1]\n\nboxes = []\nscores = []\nclass_ids = []\noutput = outputs[0]\nfor i in range(rows):\n    classes_scores = output[i][4:]\n    minScore, maxScore, minClassLoc, (x, maxClassIndex) = cv2.minMaxLoc(classes_scores)\n    if maxScore >= 0.25:\n        box = [output[i][0] - 0.5 * output[i][2], output[i][1] - 0.5 * output[i][3],\n               output[i][2], output[i][3]]\n        boxes.append(box)\n        scores.append(maxScore)\n        class_ids.append(maxClassIndex)\n\nresult_boxes = cv2.dnn.NMSBoxes(boxes, scores, 0.25, 0.45, 0.5)\nfor index in result_boxes:\n    box = boxes[index]\n    box_out = [round(box[0]*scale), round(box[1]*scale),\n               round((box[0] + box[2])*scale), round((box[1] + box[3])*scale)]\n    print(\"Rect:\", names[class_ids[index]], scores[index], box_out)\n```", "```py\nsudo apt update\nsudo apt install g++ cmake libavcodec-dev libavformat-dev libswscale-dev libgstreamer-plugins-base1.0-dev libgstreamer1.0-dev \nsudo apt install libgtk2.0-dev libcanberra-gtk* libgtk-3-dev libpng-dev libjpeg-dev libtiff-dev\nsudo apt install libxvidcore-dev libx264-dev libgtk-3-dev libgstreamer1.0-dev gstreamer1.0-gtk3\n\nwget https://github.com/opencv/opencv/archive/refs/tags/4.7.0.tar.gz\ntar -xvzf 4.7.0.tar.gz\nrm 4.7.0.tar.gz\ncd opencv-4.7.0\nmkdir build && cd build\n\ncmake -D WITH_QT=OFF -D WITH_VTK=OFF -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D WITH_FFMPEG=ON -D PYTHON3_PACKAGES_PATH=/usr/lib/python3/dist-packages -D BUILD_EXAMPLES=OFF ..\nmake -j2 && sudo make install && sudo ldconfig\n```", "```py\n#include <opencv2/opencv.hpp>\n#include <vector>\n#include <ctime>\n#include \"inference.h\"\n\nint main(int argc, char **argv) {\n    Inference inf(\"yolov8n.onnx\", cv::Size(640, 640), \"\", false);\n\n    cv::Mat frame = cv::imread(\"test.jpg\");\n\n    // First run to 'warm-up' the model\n    inf.runInference(frame);\n\n    // Second run\n    const clock_t begin_time = clock();\n\n    std::vector<Detection> output = inf.runInference(frame);\n\n    printf(\"dT: %f\\n\",  float(clock() - begin_time)/CLOCKS_PER_SEC);\n\n    // Show results\n    for (auto &detection : output) {\n        cv::Rect box = detection.box;\n\n        printf(\"Rect: %s %f: %d %d %d %d\\n\", detection.className.c_str(), detection.confidence,\n                                             box.x, box.y, box.width, box.height);        \n    }\n\n    return 0;\n}\n```", "```py\nc++ yolo1.cpp inference.cpp -I/usr/local/include/opencv4 -L/usr/local/lib -lopencv_core -lopencv_dnn -lopencv_imgcodecs -lopencv_imgproc -O3 -o yolo1\n```"]