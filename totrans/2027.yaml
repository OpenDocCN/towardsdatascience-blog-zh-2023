- en: The Infinite Babel Library of LLMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-infinite-babel-library-of-llms-90e203b2f6b0](https://towardsdatascience.com/the-infinite-babel-library-of-llms-90e203b2f6b0)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '| ARTIFICIAL INTELLIGENCE | FUTURE |TRANSFORMERS |'
  prefs:
  - PREF_H2
  type: TYPE_TB
- en: 'Open-source, data, and attention: How the future of LLMs will change'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://salvatore-raieli.medium.com/?source=post_page-----90e203b2f6b0--------------------------------)[![Salvatore
    Raieli](../Images/6bb4520e2df40d20283e7283141b5e06.png)](https://salvatore-raieli.medium.com/?source=post_page-----90e203b2f6b0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----90e203b2f6b0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----90e203b2f6b0--------------------------------)
    [Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page-----90e203b2f6b0--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----90e203b2f6b0--------------------------------)
    ·16 min read·May 8, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/662b901cf99f5b6eb661b1c961669369.png)'
  prefs: []
  type: TYPE_IMG
- en: image by the author using OpenAI DALL-E
  prefs: []
  type: TYPE_NORMAL
- en: “‘[The Godfather of A.I.’ Leaves Google and Warns of Danger Ahead](https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html)”,
    is the title of the New York Times. How we can know if LMs are a threat to humanity
    if they are not open-source? What is actually happening? How the world of language
    models is on the brink of Changement.
  prefs: []
  type: TYPE_NORMAL
- en: The calling for the open-source crusade
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/6d9b96a4ae8fdb8e31a90144a6a87261.png)'
  prefs: []
  type: TYPE_IMG
- en: image by [Nik Shuliahin](https://unsplash.com/it/@tjump) on Unsplash.com
  prefs: []
  type: TYPE_NORMAL
- en: A short while ago [GPT-4](https://openai.com/research/gpt-4) was revealed to
    the public, and I think we all went to read the technical report and were disappointed.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7a0bed6c4021763586fbc5da9961724a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Technical report GPT-4\. screenshot by the author, image source: [here](https://arxiv.org/pdf/2303.08774.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Recently, [Nature also addressed the issue](https://www.nature.com/articles/d41586-023-01295-4):
    we need [large language models](https://en.wikipedia.org/wiki/Large_language_model)
    (LLMs) to be open-source.'
  prefs: []
  type: TYPE_NORMAL
- en: Many of the LLMs are proprietary, not released, and we don’t know what data
    they were trained on. This does not allow them to be inspected and tested for
    limitations, especially with regard to bias.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, sharing information and code with ChatGPT is at risk of leakage
    [as discovered by Samsung](https://gizmodo.com/chatgpt-ai-samsung-employees-leak-data-1850307376).
    Not to mention that some states believe that data storage by [these companies
    violates the GDPR](https://blog.davidlibeau.fr/chatgpt-will-probably-never-comply-with-gdpr/).
  prefs: []
  type: TYPE_NORMAL
- en: This is why we need LLMs to be open-source, and there should be more investment
    in the development of new LLMs, such as the [BLOOM](https://pub.towardsai.net/a-new-bloom-in-ai-why-the-bloom-model-can-be-a-gamechanger-380a15b1fba7)
    consortium (a 170 B parameter LLM that was developed by an academic consortium).
  prefs: []
  type: TYPE_NORMAL
- en: There has often been sensationalism in recent months, both about the real capabilities
    of these LLMs and the risks of artificial intelligence. If researchers cannot
    test the models, they cannot really assess their capabilities, and the same for
    analyzing the risks. In addition, an open-source model is much more transparent
    and the community can also try to identify the source of problematic behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, it is not a demand by academia, institution are alarmed by AI. European
    Union is discussing these days the EU AI act that can reshape the future of LLMs.
    At the same time, the [White House is pushing tech CEO](https://www.nytimes.com/2023/05/04/technology/us-ai-research-regulation.html?utm_source=tldrai)
    to limit the risk of AI. Thus, open source could be actually a future requirement
    for language models.
  prefs: []
  type: TYPE_NORMAL
- en: Why ChatGPT is that good?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/318475e0d08ae720f761191b50879a3f.png)'
  prefs: []
  type: TYPE_IMG
- en: We have all heard about ChatGPT, and how it seemed revolutionary. But how was
    it trained?
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/data-driven-fiction/everything-but-everything-you-need-to-know-about-chatgpt-546af7153ee2?source=post_page-----90e203b2f6b0--------------------------------)
    [## Everything but everything you need to know about ChatGPT'
  prefs: []
  type: TYPE_NORMAL
- en: what is known, the latest news, what it is impacting, and what is changing.
    all in one article
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/data-driven-fiction/everything-but-everything-you-need-to-know-about-chatgpt-546af7153ee2?source=post_page-----90e203b2f6b0--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Let us start with the fact that ChatGPT was trained on the basis of an LLM (GPT
    3.5 to be precise). Typically, these GPT-like language models are trained using
    the prediction of the [next token in a sequence](https://en.wikipedia.org/wiki/Language_model)
    (from a sequence of tokens w, the model must predict the next token w+1).
  prefs: []
  type: TYPE_NORMAL
- en: 'The model typically is a transformer: consisting of an encoder that receives
    input as a sequence and a decoder that generates the output sequence. The heart
    of this system is [multi-head self-attention](https://en.wikipedia.org/wiki/Attention_(machine_learning)),
    which allows the model to learn information about the context and dependencies
    between the various parts of the sequence.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b2da300060a6991f8bfb378428c961b5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/pdf/1706.03762.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[GPT-3](https://en.wikipedia.org/wiki/GPT-3) was trained with this principle
    (like the other models in the Generative Pre-training Transformer, GPT, family),
    only with many more parameters and much more data (570 GB of data and 176 B of
    parameters).'
  prefs: []
  type: TYPE_NORMAL
- en: '[GPT3](https://en.wikipedia.org/wiki/GPT-3) has tremendous capabilities however
    when it comes to generating text it often hallucinates, lacks helpfulness, is
    uninterpretable, and often contains biases. This means that the model is not aligned
    with what we expect from a model that generates text like a human'
  prefs: []
  type: TYPE_NORMAL
- en: How do we obtain ChatGPT from GPT-3?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The process is called [Reinforcement Learning from Human Feedback](https://huggingface.co/blog/rlhf)
    (RHLF), and was described by the authors in this article:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://arxiv.org/abs/2203.02155?source=post_page-----90e203b2f6b0--------------------------------)
    [## Training language models to follow instructions with human feedback'
  prefs: []
  type: TYPE_NORMAL
- en: Making language models bigger does not inherently make them better at following
    a user's intent. For example, large…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: arxiv.org](https://arxiv.org/abs/2203.02155?source=post_page-----90e203b2f6b0--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'Here I will describe it very generally and succinctly. Specifically, it consists
    of three steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Supervised fine-tuning**, is the first step in which the LLM is fine-tuned
    to learn a supervised policy (baseline model or SFT model).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Mimic human preferences**, in this step, the annotators must vote on a set
    of outputs from the baseline model. This curated dataset is used to train a new
    model, the reward model.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[**Proximal Policy Optimization (PPO)**](/proximal-policy-optimization-ppo-explained-abed1952457b?gi=9f8ba523b43c),
    here the reward model is used to fine-tune the SFT model and obtain the policy
    model'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/3e1261510ad93d65caeb90c9526f8059.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/pdf/2203.02155.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: To prepare for the first step OpenAI collected a series of prompts and asked
    human annotators to write down the expected response (12–15 K prompts). Some of
    these prompts were collected from GPT-3 users, so probably what one writes on
    ChatGPT will be used for the next model.
  prefs: []
  type: TYPE_NORMAL
- en: The authors used as a model GPT-3.5 that had already been fine-tuned on programming
    code, this also explains the code capabilities of ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: Now this step however is not exactly scalable since it is supervised learning.
    In any case, the model thus obtained is not yet aligned.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/da31c4b18f10f3ac161b16a6c788db60.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/pdf/2203.02155.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: The annotators noted a range of responses from the SFT model, according to how
    desirable such a response is (from worst to best). We now have a much larger dataset
    (10 x) and provide the SFT model responses to the new model, which must rank in
    order of preference.
  prefs: []
  type: TYPE_NORMAL
- en: During this stage, the model is learning a general policy about the data, and
    how to maximize its reward (when he is able to rank well the outputs).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/74cd14b951a1055a96b3f03687234a47.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/pdf/2203.02155.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: So we have the SFT model, and we use its weights to initialize a new PPO model.
    This model is fine-tuned using Proximal Policy Optimization (PPO).
  prefs: []
  type: TYPE_NORMAL
- en: In other words, we use a reinforcement learning algorithm. The PPO model receives
    a random prompt and responds to the prompt, after which it receives a penalty
    or reward. Instead of classical [Q-learning](https://it.wikipedia.org/wiki/Q-learning),
    here the model policy is updated to each response (the model learns directly from
    experience, on policy).
  prefs: []
  type: TYPE_NORMAL
- en: In addition, the authors use the per-token [Kullback-Leibler (KL)](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence)
    penalty to make the model’s response distribution similar to that of the SFT model.
    This is because we want to optimize the model with the RL (due to the reward model)
    but we still do not want it to forget what it learned in step 1, which are prompts
    curated by humans.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the model is evaluated on three aspects: helpfulness, truthfulness,
    and harmlessness. After all, these were exactly the aspects we wanted to optimize.'
  prefs: []
  type: TYPE_NORMAL
- en: A curious note is that the model when evaluated on classic benchmarks (question
    answering, summarization, classification) has lower performance than GPT-3\. This
    is the cost of alignment.
  prefs: []
  type: TYPE_NORMAL
- en: Alpaca, a revolutionary animal
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/46194285bf0755a3f0a2eb2df10dab3c.png)'
  prefs: []
  type: TYPE_IMG
- en: image by [Dong Cheng](https://unsplash.com/it/@dongcheng) on Unsplash
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned there is a real need to study the behavior of these models and
    this is only possible if they are open source. On the other hand, any LM can be
    aligned using RHLF.
  prefs: []
  type: TYPE_NORMAL
- en: RHLF is much less expensive and computationally intensive than training a model
    from scratch. On the other hand, it requires that there be annotators (you do
    indeed need a dataset with instructions). **But can’t these steps be automated?**
  prefs: []
  type: TYPE_NORMAL
- en: The first step was [Self-instruct](https://arxiv.org/pdf/2212.10560.pdf), in
    this 2022 article, the authors propose a semi-automated method. In fact, the general
    idea is to start with a set of manually-written instructions. This set of instructions
    serves both as seeds and to be sure that most [NLP](https://en.wikipedia.org/wiki/Natural_language_processing)
    tasks are covered.
  prefs: []
  type: TYPE_NORMAL
- en: Starting then with only 175 instructions prompted the model to generate the
    dataset (50k instructions). The dataset was then used for instruction tuning.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3614a712dd4be63ad2280e789d181ed2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A high-level overview of SELF-INSTRUCT. image source: [here](https://arxiv.org/pdf/2212.10560.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: Having a method needed only a model. ChatGPT is based on OpenAI GPT-3.5, but
    can’t a smaller model be used? **Does it necessarily need more than 100 B parameters?**
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, the Stanford researchers used LLaMA and specifically the 7B version
    and 52 K instructions generated following the self-instruct method (instructions
    generated using OpenAI’s text-davinci-003). The real value of Alpaca is that the
    authors simplified the pipeline and greatly reduced costs in a way that any academic
    lab could replicate the process (which is in [this repository](https://github.com/tatsu-lab/stanford_alpaca)).
    As in fact stated:'
  prefs: []
  type: TYPE_NORMAL
- en: For our initial run, fine-tuning a 7B LLaMA model took 3 hours on 8 80GB A100s,
    which costs less than $100 on most cloud compute providers. ([source](https://crfm.stanford.edu/2023/03/13/alpaca.html))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The initial model evaluation showed that Alpaca is almost good at GPT-3.5 (in
    some cases even exceeding it). This may seem surprising given that this is a model
    that is 20 times smaller. On the other hand, the model behaved like GPT in a series
    of inputs (so the training acts as a kind of knowledge distillation). On the other
    hand, the model has the same limitations as typical language models, showing hallucinations,
    toxicity, and stereotypes.
  prefs: []
  type: TYPE_NORMAL
- en: Alpaca then demonstrates that any academic laboratory can train its own version
    of ChatGPT (using [LLaMA](https://medium.com/mlearning-ai/metas-llama-a-small-language-model-beating-giants-5065948e0b7f),
    which is available only for research). On the other hand, any company using another
    model can align and create its own version of ChatGPT. In addition, similar models
    could still even be deployed on [cell phones](https://twitter.com/thiteanish/status/1635188333705043969)
    or [Raspberry Pi computers](https://msproul.github.io/AlpacaPi/).
  prefs: []
  type: TYPE_NORMAL
- en: The authors released a demo, but it was [shut down](https://www.theregister.com/2023/03/21/stanford_ai_alpaca_taken_offline/)
    after a short time (as a matter of security). Also, although one had to apply
    to use LLaMA (and access the model weights), a few days later the model [was leaked
    online](https://www.theverge.com/2023/3/8/23629362/meta-ai-language-model-llama-leak-online-misuse).
  prefs: []
  type: TYPE_NORMAL
- en: Are LLMs at the border of a revolution?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/b409e6e6cbb3677fc3eb3fe8c02c99f3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/pdf/2304.13712.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: It seems like it has been years since ChatGPT was released but instead, it was
    only a few months. Up to that time we were talking about the power law, how it
    was necessary for a model to have more parameters, more data, and more training
    in order to allow for the origin of emergent behaviors.
  prefs: []
  type: TYPE_NORMAL
- en: These ideas led to the idea that we could define a kind of [Moore’s law](https://en.wikipedia.org/wiki/Moore%27s_law)
    for language models. In a sense, in recent years we have seen almost an exponential
    law (we have gone from 1.5 B parameters for GPT-2 to 175 B for GPT-3).
  prefs: []
  type: TYPE_NORMAL
- en: What has changed?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The first blow to this doctrine could be called, the arrival of [Chinchilla](https://en.wikipedia.org/wiki/Chinchilla_AI).
    DeepMind’s model showed that it is not only a matter of data quantity but also
    of data quality. Second, META’s LLaMA showed that even smaller models using a
    curated data set can achieve similar if not better results than huge models.
  prefs: []
  type: TYPE_NORMAL
- en: It is not just a matter of models. The data is the other issue. Humans do not
    produce enough data, probably not enough data to support any GPT-5 according to
    when required by the power law. Second, the data will not be as accessible as
    before.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, Reddit (a popular data resource) has announced that [AI developers
    will have to pay](https://www.reddit.com/r/reddit/comments/12qwagm/an_update_regarding_reddits_api/)
    to access its content. Even [Wikipedia has thought the same](https://voicebot.ai/2021/03/17/wikipedia-will-start-charging-tech-giants-and-their-voice-assistants-for-data-access/)
    and now [StackOverflow](https://www.zdnet.com/article/stack-overflow-joins-reddit-and-twitter-in-charging-ai-companies-for-training-data/)
    is moving in the same way, it will require companies to pay.
  prefs: []
  type: TYPE_NORMAL
- en: “Community platforms that fuel LLMs absolutely should be compensated for their
    contributions so that companies like us can reinvest back into our communities
    to continue to make them thrive,” Stack Overflow’s Chandrasekar says. “We’re very
    supportive of Reddit’s approach.” ([source](https://www.wired.com/story/stack-overflow-will-charge-ai-giants-for-training-data/))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: And even if one manages to get the data, it may not be safe the same for a company.
    [Getty has sued an AI art generator](https://www.theverge.com/2023/2/6/23587393/ai-art-copyright-lawsuit-getty-images-stable-diffusion),
    but the artists themselves have also filed lawsuits. Not to mention, that programmers
    have done the same [with GitHub Copilot](https://www.euronews.com/culture/2023/03/27/from-lawsuits-to-tech-hacks-heres-how-artists-are-fighting-back-against-ai-image-generatio)
    which has been trained with code in the repositories. In addition, the music industry
    (notoriously litigious) has [spoken out against AI-generated music](https://www.ft.com/content/aec1679b-5a34-4dad-9fc9-f4d8cdd124b9)
    and urged against streaming services. If even AI companies [appeal to fair use](https://www.theverge.com/2023/1/28/23575919/microsoft-openai-github-dismiss-copilot-ai-copyright-lawsuit),
    it is by no means a given that they will have the same access to data in the future.
  prefs: []
  type: TYPE_NORMAL
- en: There is another factor to consider, apart from extending models by hetero modality,
    the transformer architecture has not changed since 2017\. All language models
    are based on the dogma that only multi-head self-attention is needed and nothing
    more. Until recently Sam Altman was convinced that the scalability of the architecture
    was the key to AGI. But as he said at a recent [MIT event](https://www.imaginationinaction.co/),
    the key to AGI is not in more layers and more parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e452bf39507b9ec47868c33d02c1b4a7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://arxiv.org/pdf/1706.03762.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The transformer has definite limitations and this is reflected in the LMs:
    hallucinations, toxicity, and bias. Modern LLMs are not capable of critical thinking.
    Techniques such as chain of thoughts and prompt engineering serve as patches to
    try to mitigate the problem.'
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, multi-head self-attention has been shown to be capable of solving
    RNN-derived problems and allowing behaviors to emerge as in-context learning has
    a quadratic cost. Recently, it has been seen that one cannot replace self-attention
    with non-quadratic variants of attention without losing expressiveness. However,
    work such as [Spike-GPT](https://levelup.gitconnected.com/spikegpt-a-260-m-only-parameters-lm-not-afraid-of-competition-e262431d67aa)
    and [Hyena](https://levelup.gitconnected.com/welcome-back-80s-transformers-could-be-blown-away-by-convolution-21ff15f6d1cc)
    show that less expensive alternatives not based on self-attention exist and allow
    for comparable results in the construction of language models.
  prefs: []
  type: TYPE_NORMAL
- en: Also as shown aligning a model using RHLF has a cost with respect to performance
    in the various tasks. Therefore, LMs will not replace the “expert model” but in
    the future will perhaps be orchestrators of other models (as for example suggested
    by [HuggingGPT](https://levelup.gitconnected.com/hugginggpt-give-your-chatbot-an-ai-army-cfadf5647f98)).
  prefs: []
  type: TYPE_NORMAL
- en: You cannot stop Open-source and why it is always winning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/3a6b25bb1fc139ea22e046a0242924a8.png)'
  prefs: []
  type: TYPE_IMG
- en: image by [Steven Lelham](https://unsplash.com/it/@slelham)
  prefs: []
  type: TYPE_NORMAL
- en: is MidJourney or DALL-E better? it is difficult perhaps to say. What is certain
    is that stable diffusion is the winning technology. Stable diffusion by the fact
    that it has been open-source has spawned so many applications and has been the
    inspiration for so much derivative research (ControlNet, synthetic data for medical
    imaging, parallels to the brain).
  prefs: []
  type: TYPE_NORMAL
- en: Through the work of the community, Stable diffusion in its various versions
    has been improved and there are endless variations. On the other hand, there is
    no application of DALL-E that does not have a counterpart based on stable diffusion
    (but the reverse is true).
  prefs: []
  type: TYPE_NORMAL
- en: Why then has the same not happened for language models?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: So far the main problem is that training a language model was a prohibitive
    undertaking. BigScience’s BLOOM is indeed a huge consortium. But LLaMA has shown
    that much smaller models can compete with monsters of more than 100 B parameters.
    Alpaca showed that LM alignment can also be done with little cost (less than $1,000
    total cost). These are the elements that allowed Simon Willson to say “[Large
    language models are having their Stable Diffusion moment.](https://simonwillison.net/2023/Mar/11/llama/)”
  prefs: []
  type: TYPE_NORMAL
- en: 'From Alpaca to the present day, a lot of models have come out that [are open-source](https://twitter.com/dctanner/status/1643263959263322115).
    Not only has [Stability AI released a number of models](https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models)
    that are competitive with giants and can be used by everyone, but other companies
    have also released chatbots and models. In just a few weeks we have seen: [Dolly](https://github.com/databrickslabs/dolly),
    [HuggingChat](https://huggingface.co/chat/), Koala, and many more'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2dc4d41faad26b91c012f8ac3afb3148.png)'
  prefs: []
  type: TYPE_IMG
- en: 'screenshots by the author. image source: [here](https://huggingface.co/chat/)'
  prefs: []
  type: TYPE_NORMAL
- en: Now, some of the models mentioned are yes open-source however they are for non-commercial
    use. although they are open to academic research this means that they cannot be
    exploited by interested companies.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is only part of the story. In fact, there are already models on HuggingFace
    that can be easily trained (models, datasets, and pipelines) and there are to
    date several models that are commercially available (to date [more than 10](https://github.com/eugeneyan/open-llms)):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d374e3ba279d7afd606a009bf17ab876.png)'
  prefs: []
  type: TYPE_IMG
- en: 'screenshot by the author. source: [here](https://github.com/eugeneyan/open-llms)'
  prefs: []
  type: TYPE_NORMAL
- en: Open-source model, private data, and new applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/6138c6a0e3c35ffb7b83692a0a099541.png)'
  prefs: []
  type: TYPE_IMG
- en: image by [Muhammad Zaqy Al Fattah](https://unsplash.com/it/@dizzydizz) on Unsplash
  prefs: []
  type: TYPE_NORMAL
- en: Dario Amodei, [CEO of Anthropic is seeking billions](https://venturebeat.com/ai/as-anthropic-seeks-billions-to-take-on-openai-industrial-capture-is-nigh-or-is-it/)
    to beat OpenAI on the bigger model of the world. However, the rest of the world
    is moving in another direction. For example, Bloomberg, which is not a known player
    in AI [has released a LLM for finance](https://arxiv.org/abs/2303.17564v1) (trained
    on 363 billion tokens from finance sources).
  prefs: []
  type: TYPE_NORMAL
- en: Why do we want an LLM for finance? Why do not use just ChatGPT?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Google MedPalm showed that a generalist model has poor performance compared
    to a model that is fine-tuned on a specific topic (in this case it was datasets
    of medical, scientific, and so on articles).
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning an LLM is clearly expensive. Especially if we are talking about
    models with hundreds of billions of parameters. Smaller models are much less expensive,
    however still not indifferent. META’s LLaMA with being open-source has partly
    solved this problem. In fact, the authors of [LLaMA-Adapter showed that only 1.2
    million parameters](https://arxiv.org/pdf/2303.16199.pdf) need to be added in
    order to do fine-tuning (the training took less than an hour).
  prefs: []
  type: TYPE_NORMAL
- en: While it is true that LLaMA is not commercially available, there are many other
    models that are available (from small to large). What will obviously enable a
    successful application in a given field is data.
  prefs: []
  type: TYPE_NORMAL
- en: '[As Samsung discovered unpleasantly](https://www.engadget.com/three-samsung-employees-reportedly-leaked-sensitive-data-to-chatgpt-190221114.html?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAJvMJ0sb8_IHUybp8w3JmFkI5VkTKP1MgcrB9zWTaUKcBrEm8Fs-D18iKE4b9jOIFn_s-1p86ZmF0fG3V-LEFDiHRvBAlqBIDOMFFraTYxYbXzdcBNMfh8ppicFde-u_RCNbZLZGq7cgfor-7u9h-MLCn1cxhNHMVug6WJrcutz0),
    it is a risk to use ChatGPT inside a company. Even if [ChatGPT now allows people
    to disable chat history or decline to use their data](https://arstechnica.com/information-technology/2023/04/chatgpt-users-can-now-opt-out-of-chat-history-and-model-training/)
    to train the model, companies will consider it risky to concede their data.'
  prefs: []
  type: TYPE_NORMAL
- en: Many companies will consider it possible to train their own chatbot, a model
    that is fine-tuned on their own corporate data and will remain internal. After
    all, the technology is available and affordable even for companies with small
    budgets. Moreover, the low cost allows them to be able to fine-tune regularly
    as new data arrives or if a better open-source model is released. Companies that
    now have the data will be much more reluctant to grant it.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, we have seen how important is to have quality data. Data in medicine
    and many other fields are difficult to collect (expensive, regulated, scarce)
    and companies that possess them have a vantage. OpenAI could spend billions trying
    to collect for example medical data, but beyond the cost, patient recruitment
    requires years and an established network (which it has not). Companies that have
    the data now will be more restrictive in sharing these data with models that can
    store what they are exposed.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1d2779573a760ce361c54cce016342cf.png)'
  prefs: []
  type: TYPE_IMG
- en: image by [Petrebels](https://unsplash.com/it/@petrebels) on Unsplash
  prefs: []
  type: TYPE_NORMAL
- en: In addition, works such as HuggingGPT and [AudioGPT](https://github.com/AIGC-Audio/AudioGPT)
    are showing the LLM is an interface for the user to interact with expert models
    (text-to-image, audio model, and much more). In the last years, many companies
    have hired data scientists and have developed different specialized models for
    their needs (pharmaceutical companies' models for drug discovery and design, manufacturing
    companies for component design and predictive maintenance, and so on). Thus, now
    data scientists can instruct LLMs to connect with their previously trained models
    and allow internal non-technical users to interact with them through textual prompts.
  prefs: []
  type: TYPE_NORMAL
- en: There is also another element that points toward such a scenario, the regulations
    on generative AI are unclear (for example, Google has not released its generative
    music model for fear of copyright infringement). In addition to the copyright
    issue, questions about liability remain open. Therefore, many companies may internalize
    the technology and create their own AI assistant in the coming months.
  prefs: []
  type: TYPE_NORMAL
- en: Parting thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/19a35058c4bd9cf5b03a62422a64c50e.png)'
  prefs: []
  type: TYPE_IMG
- en: image by [Saif71.com](https://unsplash.com/it/@saif71) on Unsplash.com
  prefs: []
  type: TYPE_NORMAL
- en: 'Dr. Hinton said that when people used to ask him how he could work on technology
    that was potentially dangerous, he would paraphrase Robert Oppenheimer, who led
    the U.S. effort to build the atomic bomb: “When you see something that is technically
    sweet, you go ahead and do it.”'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: He does not say that anymore. ([source](https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Hinton recently stated that we need to discuss the risks of artificial intelligence.
    But we cannot study the risks of a bomb exploding if it is inside a black box.
    That is why it is increasingly urgent for models to be Open source.
  prefs: []
  type: TYPE_NORMAL
- en: LLMs are in a phase of change anyway. Creating bigger and bigger models is unsustainable
    and does not give the same advantage as it once did. The future of the next LLMs
    will lie in data and probably in new architectures no longer based on self-attention.
  prefs: []
  type: TYPE_NORMAL
- en: However, data will not be as accessible as it once was; companies are beginning
    to stop access to it. [Microsoft says it is willing to allow companies](https://www.cnbc.com/2023/02/07/microsoft-will-offer-chatgpt-tech-for-companies-to-customize-source.html)
    to create their own version of ChatGPT. But companies will be skeptical.
  prefs: []
  type: TYPE_NORMAL
- en: Some companies fear for their business (it seems ChatGPT has already claimed
    [its first victim](https://www.greatandhra.com/articles/special-articles/edtech-firm-says-chatgpt-killing-its-business-128974)),
    and others are afraid of data leakage. Or simplyment the technology is finally
    within reach of almost all companies, and each will create a chatbot tailored
    to its needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'In conclusion, we can see different trends (which in part they already happening):'
  prefs: []
  type: TYPE_NORMAL
- en: A mounting fear of AI is pushing for open-source models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is leading to an increasing publication of open-source LLMs models. Which
    in turn, it is showing you can use smaller models and reduce the cost of their
    alignment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLM models are a threat to different businesses and companies fear that these
    models could menace their business. Thus, different companies are reducing access
    to their data or asking for payment from AI companies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction in cost, fear of competition, a new relevance for proprietary data,
    and the new availability of open-source models are leading companies to train
    their own chatbots on their own data using open-source models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**What do you think about the future of LLMs? Let me know in the comments**'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have found this interesting:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*You can look for my other articles, you can also* [***subscribe***](https://salvatore-raieli.medium.com/subscribe)
    *to get notified when I publish articles, you can* [***become a Medium member***](https://medium.com/@salvatore-raieli/membership)
    *to access all its stories (affiliate links of the platform for which I get small
    revenues without cost to you) and you can also connect or reach me on*[***LinkedIn***](https://www.linkedin.com/in/salvatore-raieli/)***.***'
  prefs: []
  type: TYPE_NORMAL
- en: '*Here is the link to my GitHub repository, where I am planning to collect code
    and many resources related to machine learning, artificial intelligence, and more.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/SalvatoreRa/tutorial?source=post_page-----90e203b2f6b0--------------------------------)
    [## GitHub - SalvatoreRa/tutorial: Tutorials on machine learning, artificial intelligence,
    data science…'
  prefs: []
  type: TYPE_NORMAL
- en: Tutorials on machine learning, artificial intelligence, data science with math
    explanation and reusable code (in python…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/SalvatoreRa/tutorial?source=post_page-----90e203b2f6b0--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '*or you may be interested in one of my recent articles:*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://levelup.gitconnected.com/welcome-back-80s-transformers-could-be-blown-away-by-convolution-21ff15f6d1cc?source=post_page-----90e203b2f6b0--------------------------------)
    [## Welcome Back 80s: Transformers Could Be Blown Away by Convolution'
  prefs: []
  type: TYPE_NORMAL
- en: The Hyena model shows how convolution could be faster than self-attention
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'levelup.gitconnected.com](https://levelup.gitconnected.com/welcome-back-80s-transformers-could-be-blown-away-by-convolution-21ff15f6d1cc?source=post_page-----90e203b2f6b0--------------------------------)
    [](https://levelup.gitconnected.com/meta-dino-how-self-supervised-learning-is-changing-computer-vision-1666a5e43dbb?source=post_page-----90e203b2f6b0--------------------------------)
    [## META DINO: how self-supervised learning is changing computer vision'
  prefs: []
  type: TYPE_NORMAL
- en: 'Curated data, visual features, and knowledge distillation: the foundations
    of next computer vision models'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'levelup.gitconnected.com](https://levelup.gitconnected.com/meta-dino-how-self-supervised-learning-is-changing-computer-vision-1666a5e43dbb?source=post_page-----90e203b2f6b0--------------------------------)
    [](https://levelup.gitconnected.com/looking-into-your-eyes-how-google-ai-model-can-predict-your-age-from-the-eye-857979339da9?source=post_page-----90e203b2f6b0--------------------------------)
    [## Looking into Your Eyes: How Google AI Model Can Predict Your Age from the
    Eye'
  prefs: []
  type: TYPE_NORMAL
- en: The new model can unlock secrets of aging by analyzing eye photos
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'levelup.gitconnected.com](https://levelup.gitconnected.com/looking-into-your-eyes-how-google-ai-model-can-predict-your-age-from-the-eye-857979339da9?source=post_page-----90e203b2f6b0--------------------------------)
    [](https://levelup.gitconnected.com/the-mechanical-symphony-will-ai-displace-the-human-workforce-9baeb786efa4?source=post_page-----90e203b2f6b0--------------------------------)
    [## The Mechanical Symphony: Will AI Displace the Human Workforce?'
  prefs: []
  type: TYPE_NORMAL
- en: 'GPT-4 shows impressive skills: what will be the impact on the labor market?'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/the-mechanical-symphony-will-ai-displace-the-human-workforce-9baeb786efa4?source=post_page-----90e203b2f6b0--------------------------------)
  prefs: []
  type: TYPE_NORMAL
