- en: ChatGPT and the Future (Present) We’re Facing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/chatgpt-and-the-future-present-were-facing-9f2a1cfab0e9](https://towardsdatascience.com/chatgpt-and-the-future-present-were-facing-9f2a1cfab0e9)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Opinion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 2023 will be much more intense and overwhelming than 2022, so tighten your seatbelts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://albertoromgar.medium.com/?source=post_page-----9f2a1cfab0e9--------------------------------)[![Alberto
    Romero](../Images/371e7fae482e9cc764de077a09500d8e.png)](https://albertoromgar.medium.com/?source=post_page-----9f2a1cfab0e9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9f2a1cfab0e9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9f2a1cfab0e9--------------------------------)
    [Alberto Romero](https://albertoromgar.medium.com/?source=post_page-----9f2a1cfab0e9--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9f2a1cfab0e9--------------------------------)
    ·10 min read·Feb 2, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/927f6f493c472e595a970f0c616d9257.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Credit: Midjourney'
  prefs: []
  type: TYPE_NORMAL
- en: Until ChatGPT stops being the most important news on AI I guess we’re stuck
    talking about it… Just kidding, I’ll make sure to interweave other topics, or
    else we may burn out.
  prefs: []
  type: TYPE_NORMAL
- en: There’s still a lot to talk about ChatGPT’s immediate and long-term implications.
    I’ve written about [what ChatGPT is](https://thealgorithmicbridge.substack.com/p/chatgpt-is-the-worlds-best-chatbot)
    and [how to get the most out of it](https://thealgorithmicbridge.substack.com/p/how-to-get-the-most-out-of-chatgpt),
    about [the challenge to identify its outputs](https://thealgorithmicbridge.substack.com/p/openai-has-the-key-to-identify-chatgpts),
    and [the threat it poses to Google and traditional search engines](https://thealgorithmicbridge.substack.com/p/microsoft-vs-google-will-language),
    but I’ve yet to touch on how the risks and harms that [some foresaw](https://garymarcus.substack.com/p/ais-jurassic-park-moment)
    are already taking shape in the real world.
  prefs: []
  type: TYPE_NORMAL
- en: Two months after its release, we can all agree that ChatGPT has reached the
    mainstream and has taken AI as a field with it. As an anecdote, a friend who knows
    nothing about AI came to me talking about ChatGPT *before* I told him about it.
    That was a first time for me — and I’m not the only one.
  prefs: []
  type: TYPE_NORMAL
- en: 'That’s the reason why it’s urgent to talk about the consequences of AI: ChatGPT
    has reached people much faster than any resources on how to use it well or how
    it definitely shouldn’t be used. The number of people using AI tools today is
    larger than ever before (not only ChatGPT; Midjourney has almost 10M members in
    the Discord server), which implies that more people than ever before will *misuse*
    them.'
  prefs: []
  type: TYPE_NORMAL
- en: In contrast to my predictive/speculative essays, this one isn’t about things
    that *could* *happen* but about things that *are happening*. I’ll zoom in on ChatGPT
    because it’s what the world is talking about, but most of what follows could apply,
    with adequate translation, to other types of generative AI.
  prefs: []
  type: TYPE_NORMAL
- en: '*This article is a selection from* [***The Algorithmic Bridge***](https://thealgorithmicbridge.substack.com/subscribe?)*,
    an educational newsletter whose purpose is to bridge the gap between AI, algorithms,
    and people. It will help you understand the impact AI has in your life and develop
    the tools to better navigate the future.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://thealgorithmicbridge.substack.com/subscribe?source=post_page-----9f2a1cfab0e9--------------------------------)
    [## The Algorithmic Bridge'
  prefs: []
  type: TYPE_NORMAL
- en: Bridging the gap between algorithms and people. A newsletter about the AI that
    matters to you. Click to read The…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: thealgorithmicbridge.substack.com](https://thealgorithmicbridge.substack.com/subscribe?source=post_page-----9f2a1cfab0e9--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT harms are no longer hypothetical
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'On January 6, security research group Check Point Research (CPR) published
    a terrifying article entitled “[OpwnAI: Cybercriminals Starting to Use ChatGPT](https://research.checkpoint.com/2023/opwnai-cybercriminals-starting-to-use-chatgpt/).”
    Although not surprising, I wasn’t expecting it so soon.'
  prefs: []
  type: TYPE_NORMAL
- en: CPR had [previously studied](https://research.checkpoint.com/2022/opwnai-ai-that-can-save-the-day-or-hack-it-away/)
    how malicious hackers, scammers, and cybercriminals could exploit ChatGPT. They
    demonstrated how the chatbot can “create a full infection flow, from spear-phishing
    to running a reverse shell” and how it can generate scripts to run dynamically,
    adapting to the environment.
  prefs: []
  type: TYPE_NORMAL
- en: Despite OpenAI’s guardrails, which appeared as an orange warning notification
    when CPR forced ChatGPT to do something against the usage policy, the research
    group had no problem generating a simple phishing email. “Complicated attack processes
    can also be automated as well, using the LLMs APIs to generate other malicious
    artifacts,” they concluded.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/256d6ea6cdf1b7ff1bd59f78a82e82bb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Basic phishing email generated by ChatGPT. Credit: [CPR](https://research.checkpoint.com/2022/opwnai-ai-that-can-save-the-day-or-hack-it-away/)
    (with permission)'
  prefs: []
  type: TYPE_NORMAL
- en: CPR researchers weren’t satisfied with proof that ChatGPT could do this *hypothetically*
    (one of the common criticisms skeptics receive is that the potential risks they
    warn about never materialize into real-world harm). They wanted to find real instances
    of people misusing it in similar ways. And they found it.
  prefs: []
  type: TYPE_NORMAL
- en: CPR analyzed “several major underground hacker communities” and found at least
    [three concrete examples of cyber criminals using ChatGPT](https://research.checkpoint.com/2023/opwnai-cybercriminals-starting-to-use-chatgpt/)
    in ways that not only violate the ToS but that could become harmful in a direct
    and measurable way.
  prefs: []
  type: TYPE_NORMAL
- en: First, an info stealer. In a thread entitled “ChatGPT — Benefits of Malware,”
    a user shared experiments where he “recreated many malware strains.” As CPR noted,
    the OP’s other posts revealed that “this individual [aims] to show less technically
    capable cybercriminals how to utilize ChatGPT for malicious purposes.”
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/59aafd8d416e98226ce27e0f1be527e6.png)'
  prefs: []
  type: TYPE_IMG
- en: '“Cybercriminal showing how he created infostealer using ChatGPT.” Credit: [CPR](https://research.checkpoint.com/2023/opwnai-cybercriminals-starting-to-use-chatgpt/)
    (with permission)'
  prefs: []
  type: TYPE_NORMAL
- en: Second, an encryption tool. A user by the name “USDoD” published a Python script
    with “encryption and decryption functions.” CPR concluded that the “script can
    easily be modified to encrypt someone’s machine completely without any user interaction.”
    While USDoD has “limited technical skills,” he is “engaged in a variety of illicit
    activities.”
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/792b3b5c72c4a2c46912b222ad6067b0.png)'
  prefs: []
  type: TYPE_IMG
- en: '“Cybercriminal dubbed USDoD posts multi-layer encryption tool.” Credit: [CPR](https://research.checkpoint.com/2023/opwnai-cybercriminals-starting-to-use-chatgpt/)
    (with permission)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The last example is fraud activity. The title of the post is quite telling:
    “Abusing ChatGPT to create Dark Web Marketplaces scripts.” CPR writes: “The cybercriminals
    published a piece of code that uses third-party API to get up-to-date cryptocurrency
    … prices as part of the Dark Web market payment system.”'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a6224c6f694115ad9a08977e2655678e.png)'
  prefs: []
  type: TYPE_IMG
- en: '“Threat actor using ChatGPT to create DarkWeb Market scripts.” Credit: [CPR](https://research.checkpoint.com/2023/opwnai-cybercriminals-starting-to-use-chatgpt/)
    (with permission)'
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s clear that ChatGPT being free to use and highly intuitive is an attractor
    for cybercriminals, including those with low technical skills. As Sergey Shykevich,
    Threat Intelligence Group Manager at Check Point explains:'
  prefs: []
  type: TYPE_NORMAL
- en: '*“Just as ChatGPT can be used for good to assist developers in writing code,
    it can also be used for malicious purposes. Although the tools that we analyze
    in this report are pretty basic, it’s only a matter of time until more sophisticated
    threat actors enhance the way they use AI-based tools.”*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'ChatGPT being a driver of security issues online isn’t a hypothesis exacerbated
    by fearmongerers but a reality that’s hard to deny. For those who use the argument
    that this was possible before ChatGPT, two things: First, ChatGPT can bridge the
    technical gap. Second, scale matters a lot here — ChatGPT can automatically write
    a script in seconds.'
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI shouldn’t have set ChatGPT free — so soon
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cybersecurity, disinformation, plagiarism… Many people have repeatedly warned
    about the problems ChatGPT-like AIs can cause. Now malicious users start to abound.
  prefs: []
  type: TYPE_NORMAL
- en: Someone could still try to make the case in favor of ChatGPT. Maybe it’s not
    *that* problematic — the upsides can compensate for the downsides — but *maybe*
    it is. And a “maybe” should suffice for us to think twice. OpenAI lowered its
    guard when GPT-2 turned out to be “harmless” (they saw “[no strong evidence of
    misuse so far](https://openai.com/blog/gpt-2-1-5b-release/)”), and they never
    raised it back again.
  prefs: []
  type: TYPE_NORMAL
- en: I agree with Scott Alexander that “[perhaps it is a bad thing that the world’s
    leading AI companies cannot control their AIs](https://astralcodexten.substack.com/p/perhaps-it-is-a-bad-thing-that-the).”
    Perhaps reinforcement learning through human feedback isn’t good enough. Perhaps
    companies should find better ways to exert control over their models if they’re
    going to unleash them in the wild. Perhaps GPT-2 wasn’t so dangerous but a couple
    of iterations later we’ve got something to worry about. And if not, we’ll have
    it in a couple more.
  prefs: []
  type: TYPE_NORMAL
- en: I’m not saying OpenAI hasn’t tried — they have (they’ve even been criticized
    for being too conservative). What I’m arguing is that, if we perpetuate this mindset
    of “I’ve tried to make it right so I now have the green light to release my AI”
    into the short-term future, we’ll encounter more and more downsides that no upside
    would make up for.
  prefs: []
  type: TYPE_NORMAL
- en: 'One question has been bothering me for a few weeks: If OpenAI is so worried
    about doing things right, why didn’t they set up [the watermarking scheme](https://thealgorithmicbridge.substack.com/i/89278939/openais-plan-to-identify-chatgpts-outputs)
    to identify ChatGPT’s outputs *before* releasing the model to the public? Scott
    Aaronson is still trying to make it work — *a month* *after* the model went completely
    viral.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Source](https://twitter.com/TheWeatherStn/status/1610313487540195331)'
  prefs: []
  type: TYPE_NORMAL
- en: I don’t think a watermark would’ve solved the fundamental problems this technology
    entails, but it’d have helped by giving time. Time for people to adapt, for scientists
    to find solutions to the most pressing issues, and for regulators to come up with
    relevant legislation.
  prefs: []
  type: TYPE_NORMAL
- en: GPT detectors are the last (healthy) frontier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Due to OpenAI’s inaction, we’re left with shy attempts at building GPT detectors
    that could provide people with a means to avoid AI disinformation, scams, or phishing
    attacks. Some have tried to repurpose [a 3-year-old GPT-2 detector](https://openai-openai-detector.hf.space/)
    for ChatGPT but [it doesn’t work](https://twitter.com/JanelleCShane/status/1601729685385535488).
    Others, like [Edward Tian](https://twitter.com/edward_the6), a CS and journalism
    senior at Princeton University, have developed systems from the ground-up, specifically
    targeted to ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: '[Source](https://twitter.com/edward_the6/status/1610067688449007618)'
  prefs: []
  type: TYPE_NORMAL
- en: As of now, 10,000+ people have tested GPTZero, me included ([here’s the demo](https://etedward-gptzero-main-zqgfwb.streamlit.app/).
    Tian is building a product for which [3K+ teachers have already subscribed](https://gptzero.substack.com/p/gptzero-update-v2)).
    I confess that I’ve managed to fool it just once (and only because ChatGPT misspelled
    a word) but haven’t tried too hard either.
  prefs: []
  type: TYPE_NORMAL
- en: The detector is quite simple; it evaluates the “perplexity” and “burstiness”
    of a chunk of text. Perplexity measures how much a sentence “surprises” the detector
    (i.e. to what degree the distribution of output words doesn’t match what it’s
    expected from a language model) and burstiness measures the constancy of perplexity
    across sentences. Simply put, GPTZero leverages the fact that humans tend to write
    much more weirdly than AIs — which becomes apparent as soon as you read a page
    of AI-generated text. It’s so dull…
  prefs: []
  type: TYPE_NORMAL
- en: 'At a [<2% false positive rate](https://gptzero.substack.com/p/gptzero-update-v1),
    GPTZero is the best detector out there. Tian is proud: “Humans deserve to know
    when the writing isn’t human,” [he told the Daily Beast](https://www.thedailybeast.com/princeton-student-edward-tian-built-gptzero-to-detect-ai-written-essays).
    I agree — even if ChatGPT doesn’t plagiarize, it’s morally wrong for people to
    claim they’re authors of something ChatGPT wrote.'
  prefs: []
  type: TYPE_NORMAL
- en: But I know it isn’t infallible. A few changes to the output (e.g. misspelling
    a word or interleaving your own) may be enough to trick the system. Asking ChatGPT
    to avoid repeating words works just fine, [as Yennie Jun shows here](https://blog.yenniejun.com/p/using-ai-to-improve-ai-generated).
    And finally, GPTZero may become obsolete soon because new language models appear
    every few weeks — AnthropicAI has unofficially announced Claude which, as evidenced
    [by Riley Goodside’s analyses](https://twitter.com/goodside/status/1611309175828520962),
    is better than ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: And [GPT-4](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley)
    is around the corner.
  prefs: []
  type: TYPE_NORMAL
- en: This is a cat-and-mouse game, as some people like to call it — and the mouse
    is always one step ahead.
  prefs: []
  type: TYPE_NORMAL
- en: 'Banning ChatGPT: A bad solution'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If detectors worked just fine, many people would get angry. Most want to use
    ChatGPT without barriers. Students, for instance, wouldn’t be able to cheat in
    written essays because an AI-savvy professor may be aware of the existence of
    a detector ([it has already happened](https://www.facebook.com/title17/posts/pfbid0DSWaYQVwJxcgSGosS88h7kZn6dA7bmw5ziuRQ5br2JMJcAHCi5Up7EJbJKdgwEZwl)).
    The fact that 3K+ teachers have signed up for Tian’s incoming product says it
    all.
  prefs: []
  type: TYPE_NORMAL
- en: 'But, because detectors aren’t sufficiently reliable, those who don’t want to
    face the uncertainty of having to guess whether some written deliverable is or
    isn’t ChatGPT’s product have taken the most conservative solution: Banning ChatGPT.'
  prefs: []
  type: TYPE_NORMAL
- en: The Guardian reported on Friday that “[New York City schools have banned ChatGPT](https://www.theguardian.com/us-news/2023/jan/06/new-york-city-schools-ban-ai-chatbot-chatgpt).”
    Jenna Lyle, a department spokesperson, cites “concerns about negative impacts
    on student learning, and concerns regarding the safety and accuracy of contents”
    as the reasons for the decision. Although I understand the teachers’ point of
    view, I don’t think this is a wise approach — it may be the easier choice, but
    it isn’t the right one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Stability.ai’s David Ha tweeted this when the news came out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Source](https://twitter.com/hardmaru/status/1611014829950799878)'
  prefs: []
  type: TYPE_NORMAL
- en: I acknowledge ([and have done it before](https://thealgorithmicbridge.substack.com/i/74599448/kids-are-using-ai-to-write-essays-and-get-straight-as-can-education-keep-up-with-ai-progress))
    the problems schools face (e.g. widespread undetectable plagiarism) but I have
    to agree with Ha.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the dilemma: This technology isn’t going away. It’s a part of the future
    — a big part, probably — and it’s super important that students (and you, me,
    and everyone else) learn about it. Banning ChatGPT from schools isn’t a solution.
    As Ha’s Tweet implies, it could be more harmful to ban it than to allow it.'
  prefs: []
  type: TYPE_NORMAL
- en: Yet, students who use it to cheat on exams or to write essays would waste their
    teachers’ time and effort as well as hinder their development without realizing
    it. As Lyle says, ChatGPT may prevent students from learning “critical-thinking
    and problem-solving skills.”
  prefs: []
  type: TYPE_NORMAL
- en: What’s the solution that I (and many others) foresee? The education system will
    have to adapt. Although harder, this is the better solution. Given how broken
    the schooling system is, it may very well be a win-win situation for students
    and teachers. Of course, it goes without saying that until that happens it’s better
    that teachers have access to a reliable detector — but let’s not use that as an
    excuse to avoid adapting education to these changing times.
  prefs: []
  type: TYPE_NORMAL
- en: The education system has *a lot* of room for improvement. If it hasn’t changed
    in so many years it’s because there weren’t strong-enough incentives to do so.
    ChatGPT gives us a reason to reimagine education, the only piece that’s missing
    in this puzzle is the willingness of those who decide.
  prefs: []
  type: TYPE_NORMAL
- en: AI is the new internet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It really feels like it. Some have compared AI to [fire or electricity](https://www.cnbc.com/2018/02/01/google-ceo-sundar-pichai-ai-is-more-important-than-fire-electricity.html)
    but those inventions integrated slowly into society and are too far back in time.
    We don’t know how that felt. AI is more like the internet, it’s going to transform
    the world. Very fast.
  prefs: []
  type: TYPE_NORMAL
- en: I’ve tried to capture in this essay a future that’s already more of a present
    than a future. One thing is that AIs like GPT-3 or DALL-E exist, and a very different
    thing is that everyone in the world is aware of them. Those hypotheticals (e.g.
    disinformation, cyber hacking, plagiarism, etc.) are no longer. It’s happening
    here and now and we are going to see more desperate measures to stop them (e.g.
    building scrappy detectors or banning AI).
  prefs: []
  type: TYPE_NORMAL
- en: We have to assume some things will change forever. But, in some cases, we may
    have to defend our position (like artists are doing with text-to-image or minorities
    have done before with classification systems). Regardless of who you are, AI will
    get to you in one way or the other. You better be ready.
  prefs: []
  type: TYPE_NORMAL
- en: '*Subscribe to* [**The Algorithmic Bridge**](https://thealgorithmicbridge.substack.com/)*.
    Bridging the gap between algorithms and people. A newsletter about the AI that
    matters to your life.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*You can also support my work on Medium directly and get unlimited access by
    becoming a member using my referral link* [**here**](https://albertoromgar.medium.com/membership)!
    *:)*'
  prefs: []
  type: TYPE_NORMAL
