- en: Introduction to Logistic Regression in PySpark
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PySpark 中的逻辑回归简介
- en: 原文：[https://towardsdatascience.com/introduction-to-logistic-regression-in-pyspark-9f894299c32d](https://towardsdatascience.com/introduction-to-logistic-regression-in-pyspark-9f894299c32d)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/introduction-to-logistic-regression-in-pyspark-9f894299c32d](https://towardsdatascience.com/introduction-to-logistic-regression-in-pyspark-9f894299c32d)
- en: Tutorial to run your first classification model in Databricks
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Databricks 中运行第一个分类模型的教程
- en: '[](https://gustavorsantos.medium.com/?source=post_page-----9f894299c32d--------------------------------)[![Gustavo
    Santos](../Images/a19a9f4525cdeb6e7a76cd05246aa622.png)](https://gustavorsantos.medium.com/?source=post_page-----9f894299c32d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9f894299c32d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9f894299c32d--------------------------------)
    [Gustavo Santos](https://gustavorsantos.medium.com/?source=post_page-----9f894299c32d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://gustavorsantos.medium.com/?source=post_page-----9f894299c32d--------------------------------)[![Gustavo
    Santos](../Images/a19a9f4525cdeb6e7a76cd05246aa622.png)](https://gustavorsantos.medium.com/?source=post_page-----9f894299c32d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9f894299c32d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9f894299c32d--------------------------------)
    [Gustavo Santos](https://gustavorsantos.medium.com/?source=post_page-----9f894299c32d--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9f894299c32d--------------------------------)
    ·10 min read·Nov 4, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9f894299c32d--------------------------------)
    ·10 min 阅读·2023 年 11 月 4 日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/2728b2918920168e3a496a57722adcf0.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2728b2918920168e3a496a57722adcf0.png)'
- en: Photo by [Ibrahim Rifath](https://unsplash.com/@ripeyyy_?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/stacked-round-gold-colored-coins-on-white-surface-OApHds2yEGQ?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Ibrahim Rifath](https://unsplash.com/@ripeyyy_?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    提供，来源于 [Unsplash](https://unsplash.com/photos/stacked-round-gold-colored-coins-on-white-surface-OApHds2yEGQ?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Big Data. Large datasets. Cloud…
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据。大数据集。云……
- en: Those words are everywhere, following us around and in the thoughts of clients,
    interviewers, managers and directors. As data gets more and more abundant, datasets
    only increase in size in a manner that, sometimes, it is not possible to run a
    machine learning model in a local environment — in a single machine, in other
    words.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这些词无处不在，跟随我们，出现在客户、面试官、经理和主管的思维中。随着数据越来越丰富，数据集的规模也不断扩大，有时在本地环境中运行机器学习模型是不可能的——换句话说，就是在单台机器上。
- en: This matter requires us to adapt and find other solutions, such as modeling
    with Spark, which is one of the most used technologies for Big Data. Spark accepts
    languages such as SQL, Python, Scala, R and it has its own methods and attributes,
    including its own Machine Learning library [MLlib]. When you work with Python
    in Spark, it is called *PySpark*, for example.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题要求我们适应并找到其他解决方案，例如使用 Spark 建模，这是最常用的大数据技术之一。Spark 接受 SQL、Python、Scala、R
    等语言，并具有自己的方法和属性，包括自己的机器学习库 [MLlib]。例如，当你在 Spark 中使用 Python 时，这叫做 *PySpark*。
- en: Furthermore, there’s a platform called *Databricks* that wraps Spark in a very
    well created layer that enables data scientists to work on it just like Anaconda.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有一个平台叫做 *Databricks*，它将 Spark 包装在一个非常好的层中，使数据科学家可以像使用 Anaconda 一样使用它。
- en: When we’re creating a ML model in Databricks, it also accepts Scikit Learn models,
    but since we’re more interested in Big Data, this tutorial is all created using
    **Spark’s MLlib**, which is more suited for large datasets and also this way we
    add a new tool to our skill set.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Databricks 中创建机器学习模型时，它也接受 Scikit Learn 模型，但由于我们更关注大数据，本教程完全使用 **Spark 的 MLlib**
    创建，这更适合大数据集，同时也为我们的技能库添加了一种新工具。
- en: Let’s go.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 开始吧。
- en: Dataset
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集
- en: 'The dataset for this exercise is already inside Databricks. It’s one of the
    UCI datasets, **Adults**, that is an extract from a Census and labeled with individuals
    that earn less or more than $50k per year. The data is publicly available under
    Creative Commons License in this address: [https://archive.ics.uci.edu/dataset/2/adult](https://archive.ics.uci.edu/dataset/2/adult)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习的数据集已经在Databricks中。这是一个UCI数据集中的**成人**数据，提取自人口普查，并标记为年收入低于或高于$50k。数据在以下地址以创作共享许可证公开提供：[https://archive.ics.uci.edu/dataset/2/adult](https://archive.ics.uci.edu/dataset/2/adult)
- en: Our tutorial is to build a binary classifier that tells whether a person makes
    less or more than $50k of income in a year.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的教程是构建一个二元分类器，用于判断一个人年收入是否高于或低于$50k。
- en: '![](../Images/c7c84317730b74f4856d047dc7873036.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c7c84317730b74f4856d047dc7873036.png)'
- en: Extract of the dataset. Image by the author.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集摘录。图片由作者提供。
- en: Coding
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编码
- en: In this section, let’s go over each step of our model.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将详细介绍我们模型的每一个步骤。
- en: Here are the modules we need to import.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们需要导入的模块。
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: And loading the dataset.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 以及加载数据集。
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Preparing the Data
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备数据
- en: First, we need to prepare the data. Although this is not the core subject of
    this tutorial, we still need to get rid of null values, for example, so that’s
    what we will do.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要准备数据。虽然这不是本教程的核心内容，但我们仍需处理空值，例如，这就是我们要做的。
- en: It is known from the dataset documentation that the NA values are actually marked
    as “ ?”. We will just go ahead and drop them because there aren’t too many null
    values, so it won’t affect our model’s performance. Therefore, here’s how to get
    rid of them. Any of these columns where we find a “?”, we drop it.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据集文档中得知，NA值实际上标记为“ ?”。我们将直接去掉它们，因为空值不多，因此不会影响我们模型的性能。因此，处理方法如下。任何列中出现“ ?”，我们都会去掉。
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Nice. Now let’s choose the best variables to use in our model.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 很好。现在让我们选择模型中使用的最佳变量。
- en: Feature Engineering
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征工程
- en: Since we have both categorical and numerical variables, the first step is to
    split them in separate datasets to be able to use the `UnivariateFeatureSelector`
    from Spark. This method uses Chi² test to select the best categorical variables
    with categorical labels and ANOVA to select numerical variables with categorical
    label, which are both of our cases.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们有分类变量和数值变量，第一步是将它们分开成不同的数据集，以便使用Spark的`UnivariateFeatureSelector`。该方法使用Chi²检验选择具有分类标签的最佳分类变量，使用ANOVA选择具有分类标签的数值变量，这两种情况都适用。
- en: Let’s first select the best categorical vars. We start by isolating the categorical
    variables. Then we use `RFormula` function to create a vectorized version of our
    dataset
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 首先选择最佳的分类变量。我们从隔离分类变量开始。然后我们使用`RFormula`函数创建数据集的向量化版本。
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The resultant `vector_df` looks like this. Notice the last columns `features`
    and `label`. Those are the ones needed as input to the variable selector.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 结果`vector_df`看起来是这样的。注意最后几列`features`和`label`。这些是变量选择器所需的输入。
- en: '![](../Images/12dc25072f659987585fab60ac055ba9.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/12dc25072f659987585fab60ac055ba9.png)'
- en: Vectorized version of the dataset. Image by the author.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的向量化版本。图片由作者提供。
- en: Then we create an instance of the selector, inputting the `features` and the
    `label`, as mentioned previously. We then set the feature and label types and
    define how many “best” variables to fetch and fit it to the vectorized version
    of the data.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们创建一个选择器实例，输入`features`和`label`，如前所述。接着，我们设置特征和标签类型，并定义要提取多少个“最佳”变量，并将其拟合到数据的向量化版本中。
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The same procedure can be done for the numerical features.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数值特征，步骤是相同的。
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Ok. This is our final dataset.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。这是我们的最终数据集。
- en: '[PRE6]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/49f419193f59a703b62243b5240e2148.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/49f419193f59a703b62243b5240e2148.png)'
- en: Data with only the selected variables. Image by the author.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 只有选定变量的数据。图片由作者提供。
- en: As we have categorical variables, we will have to create dummy variables, since
    the Logistic Regression model in Spark MLlib requires only numbers as input. Let’s
    see how to do that next.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们有分类变量，我们将不得不创建虚拟变量，因为Spark MLlib中的逻辑回归模型只接受数字输入。接下来，我们来看看如何做到这一点。
- en: Transforming the Data
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转换数据
- en: Dummy variables are a way to transform categories in numbers for ML input. So,
    there are different ways to do that. The one applied here is [One Hot Encoding](https://en.wikipedia.org/wiki/One-hot)
    for multiclass variables.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟变量是一种将类别转换为数字以用于机器学习输入的方式。因此，有不同的方法来实现这一点。这里应用的方法是针对多类变量的[独热编码](https://en.wikipedia.org/wiki/One-hot)。
- en: This process will be applied only for categories, naturally, since the numbers
    are already…well…numbers.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程将只应用于类别，因为数字已经是…好吧…数字。
- en: To make it easier to work with the transformation, we will take advantage of
    the `Pipeline` method, which takes a list of steps and perform them all at once.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使转换工作更方便，我们将利用 `Pipeline` 方法，该方法接受一个步骤列表并一次性执行所有步骤。
- en: So we start by listing our selected categorical variables, then we create an
    empty list to store the stages to be performed by the Pipeline. Next comes a loop
    that takes each of the variables in the `cat_cols` list and pass it through the
    `StringIndexer` function to index the categories. The `OneHotEncoder` makes the
    final transformation.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们从列出我们选择的分类变量开始，然后创建一个空列表来存储 Pipeline 将要执行的阶段。接下来是一个循环，它将 `cat_cols` 列表中的每个变量传递给
    `StringIndexer` 函数以进行类别索引。`OneHotEncoder` 进行最终转换。
- en: 'This is what the `StringIndexer` does:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是 `StringIndexer` 所做的：
- en: '![](../Images/d6b4c4183f5c942d0652d9edab9433db.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d6b4c4183f5c942d0652d9edab9433db.png)'
- en: String Indexer applied to a variable. Image by the author.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 应用于变量的字符串索引器。图片来源于作者。
- en: And here is the code to create the loop.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是创建循环的代码。
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Next step is to encode the label. A simple string indexer in this case will
    do just fine, since it is a binary label. We can use `StringIndexer` and add the
    instance to the Pipeline stages.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是编码标签。在这种情况下，简单的字符串索引器就足够了，因为这是一个二分类标签。我们可以使用 `StringIndexer` 并将实例添加到 Pipeline
    阶段。
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Lastly, we will add both numerical and categorical variables together. We can
    just add the string ‘classVec’ to each one hot encoded variable and put all the
    columns names as input for the `VectorAssembler` , and add that to the Pipeline
    `stages` list.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将数值和分类变量一起添加。我们只需将字符串 'classVec' 添加到每个独热编码变量，并将所有列名作为 `VectorAssembler`
    的输入，然后将其添加到 Pipeline 的 `stages` 列表中。
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Finally, we run the Pipeline transformations all at once.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们一次性运行 Pipeline 转换。
- en: '[PRE10]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The result, if you’d like to see, looks like this.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想查看结果，结果看起来是这样的。
- en: '![](../Images/6714a34c6b9c2d14328eaa4c7e4488c7.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6714a34c6b9c2d14328eaa4c7e4488c7.png)'
- en: Transformed data. Image by the author.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 转换后的数据。图片来源于作者。
- en: This data is now ready for input to the Logistic Regression Model.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据现在已准备好输入到逻辑回归模型中。
- en: Model Training
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型训练
- en: Before modeling, let’s split the data in train and test sets.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在建模之前，让我们将数据拆分为训练集和测试集。
- en: '[PRE11]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now we can fit the model to the training set.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将模型拟合到训练集。
- en: '[PRE12]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: And creating some predictions.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 并创建一些预测。
- en: '[PRE13]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The output looks like this.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 输出看起来是这样的。
- en: '![](../Images/c0dafe21566ab2355ba97146776d4fc4.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c0dafe21566ab2355ba97146776d4fc4.png)'
- en: Predictions from the LR model from MLlib. Image by the author.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 MLlib 的 LR 模型预测。图片来源于作者。
- en: Evaluating
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估
- en: To evaluate our model, we use the `BinaryClassificationEvaluator` function.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估我们的模型，我们使用 `BinaryClassificationEvaluator` 函数。
- en: Our model’s accuracy is 85%, which is apparently fair.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们模型的准确率是 85%，这显然是公平的。
- en: '[PRE14]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This is the Confusion Matrix.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是混淆矩阵。
- en: '[PRE15]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](../Images/91d785147c4531f5bdf572da1ef443db.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/91d785147c4531f5bdf572da1ef443db.png)'
- en: Confusion Matrix of the model. Image by the author.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的混淆矩阵。图片来源于作者。
- en: Here we already see that the **recall** is low. Or, *out of the actual people
    making >50k, how much I am getting right*. It’s almost a guess, with a poor 48%
    of correct predictions. The rate of true negatives is high, though, with 93%.
    However, that’s not all merit of our model, since the classes are unbalanced,
    with 75% of the observations labeled as class 0 (<50k).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们已经看到**召回率**很低。或者说，*实际收入超过 50k 的人中，我正确预测了多少*。几乎是猜测，正确预测率只有 48%。尽管如此，真负率很高，为
    93%。然而，这并不是我们模型的全部优点，因为类别不平衡，其中 75% 的观察被标记为类 0（<50k）。
- en: '[PRE16]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Let’s try to improve this model.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试改进这个模型。
- en: One way to do that is to use the Cross Validation method. We first create a
    parameters grid, using the code below.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一种方法是使用交叉验证方法。我们首先创建一个参数网格，使用下面的代码。
- en: '[PRE17]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Then we can train the models and print the best parameters.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以训练模型并打印最佳参数。
- en: '[PRE18]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We can use the best model to predict or create a new one, if you want.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用最佳模型进行预测，或者如果你愿意，可以创建一个新模型。
- en: '[PRE19]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![](../Images/18e4b7a5b87fa22276bedf9afe883118.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/18e4b7a5b87fa22276bedf9afe883118.png)'
- en: Tuned model. Image by the author.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 调优后的模型。图片来源于作者。
- en: We were able to improve the model a little. The hyperparameter that brings the
    most changes is the `threshold`, which moves the cutoff away from the 50% probability
    cut for classification. Once we looked at the first model, clearly it was not
    giving us good True Positive rates. So when we move the classification cutoff
    to a number smaller than 50%, it means that we are making it “easier” to classify
    observations as positive. On the other hand, this change comes with the cost of
    increasing the False Positives, but we are ok with that for now. Here are the
    new metrics.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能够稍微改进模型。带来最大变化的超参数是`threshold`，它将分类的截止点从50%的概率切换开。查看第一个模型后，我们明显发现它的真正阳性率不高。因此，当我们将分类截止点调整到低于50%的数值时，这意味着我们让分类观察为正样本变得“更容易”。另一方面，这种改变会增加假阳性率，但我们现在可以接受这种情况。以下是新的指标。
- en: 'Precision: 0.63'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '精确度: 0.63'
- en: 'Recall: 0.62'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '召回率: 0.62'
- en: 'Specificity: 0.88'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '特异性: 0.88'
- en: We can also look at the “ROC” metric.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以查看“ROC”指标。
- en: '[PRE20]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![](../Images/2b27e312a83e2d8e516c7a7eb5b0118e.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2b27e312a83e2d8e516c7a7eb5b0118e.png)'
- en: ROC Curve for the model. Image by the author.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的 ROC 曲线。图片由作者提供。
- en: With that, we end this tutorial.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 到此，我们结束本教程。
- en: Before You Go
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 离开前
- en: In this tutorial, we went over how to create a Logistic Regression model using
    MLlib from Spark. That tool allows one to take advantage of cluster computing
    power and dealing with Big Data.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们介绍了如何使用 Spark 的 MLlib 创建逻辑回归模型。这个工具可以利用集群计算能力处理大数据。
- en: It is important to know how to make a couple of transformations, like transforming
    the dataset to a vector to input to the algorithm.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 了解如何进行一些转换，比如将数据集转换为输入算法的向量，是非常重要的。
- en: 'Here is the full code of this exercise:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这是本练习的完整代码：
- en: '[](https://github.com/gurezende/Studying/blob/master/PySpark/101_MyLearning%20ML%20on%20DataBricks.ipynb?source=post_page-----9f894299c32d--------------------------------)
    [## Studying/PySpark/101_MyLearning ML on DataBricks.ipynb at master · gurezende/Studying'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/gurezende/Studying/blob/master/PySpark/101_MyLearning%20ML%20on%20DataBricks.ipynb?source=post_page-----9f894299c32d--------------------------------)
    [## Studying/PySpark/101_MyLearning ML on DataBricks.ipynb at master · gurezende/Studying'
- en: This is a repository with my tests and studies of new packages - Studying/PySpark/101_MyLearning
    ML on DataBricks.ipynb…
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 这是一个包含我对新软件包测试和研究的代码库 - Studying/PySpark/101_MyLearning ML on DataBricks.ipynb……
- en: github.com](https://github.com/gurezende/Studying/blob/master/PySpark/101_MyLearning%20ML%20on%20DataBricks.ipynb?source=post_page-----9f894299c32d--------------------------------)
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/gurezende/Studying/blob/master/PySpark/101_MyLearning%20ML%20on%20DataBricks.ipynb?source=post_page-----9f894299c32d--------------------------------)
- en: We can use Scikit Learn in Databricks as well, but knowing MLlib, which is a
    Spark module seems more appropriate to deal with Big Data.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以在 Databricks 中使用 Scikit Learn，但了解 MLlib，这一 Spark 模块，似乎更适合处理大数据。
- en: If you liked this content, don’t forget to follow me here and on [LinkedIn](https://www.linkedin.com/in/gurezende/).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这些内容，不要忘记在这里以及在 [LinkedIn](https://www.linkedin.com/in/gurezende/) 上关注我。
- en: '[](https://gustavorsantos.medium.com/?source=post_page-----9f894299c32d--------------------------------)
    [## Gustavo Santos - Medium'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://gustavorsantos.medium.com/?source=post_page-----9f894299c32d--------------------------------)
    [## Gustavo Santos - Medium'
- en: Read writing from Gustavo Santos on Medium. Data Scientist. I extract insights
    from data to help people and companies…
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Medium 上阅读 Gustavo Santos 的文章。数据科学家。我从数据中提取见解，帮助个人和公司……
- en: gustavorsantos.medium.com](https://gustavorsantos.medium.com/?source=post_page-----9f894299c32d--------------------------------)
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: gustavorsantos.medium.com](https://gustavorsantos.medium.com/?source=post_page-----9f894299c32d--------------------------------)
- en: Reference
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考
- en: '[## Extracting, transforming and selecting features'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 提取、转换和选择特征'
- en: 'This section covers algorithms for working with features, roughly divided into
    these groups: Extraction: Extracting…'
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本节涵盖了处理特征的算法，大致分为以下几组：提取：提取……
- en: spark.apache.org](https://spark.apache.org/docs/latest/ml-features.html?source=post_page-----9f894299c32d--------------------------------#stringindexer)  [##
    One-hot - Wikipedia
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: spark.apache.org](https://spark.apache.org/docs/latest/ml-features.html?source=post_page-----9f894299c32d--------------------------------#stringindexer)  [##
    One-hot - Wikipedia
- en: From Wikipedia, the free encyclopedia In digital circuits and machine learning,
    a one-hot is a group of bits among…
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 来自维基百科，自由百科全书 在数字电路和机器学习中，one-hot 是一组位……
- en: en.wikipedia.org](https://en.wikipedia.org/wiki/One-hot?source=post_page-----9f894299c32d--------------------------------)
    [](https://docs.databricks.com/en/machine-learning/train-model/mllib.html?source=post_page-----9f894299c32d--------------------------------)
    [## Use Apache Spark MLlib on Databricks
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[en.wikipedia.org](https://en.wikipedia.org/wiki/One-hot?source=post_page-----9f894299c32d--------------------------------)
    [](https://docs.databricks.com/en/machine-learning/train-model/mllib.html?source=post_page-----9f894299c32d--------------------------------)
    [## 在 Databricks 上使用 Apache Spark MLlib'
- en: Learn how to train machine learning models using the Apache Spark MLlib Pipelines
    API in Databricks. Classification…
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 学习如何在 Databricks 中使用 Apache Spark MLlib Pipelines API 训练机器学习模型。分类…
- en: docs.databricks.com](https://docs.databricks.com/en/machine-learning/train-model/mllib.html?source=post_page-----9f894299c32d--------------------------------)
    [](https://docs.databricks.com/en/_extras/notebooks/source/binary-classification.html?source=post_page-----9f894299c32d--------------------------------)
    [## Use Apache Spark MLlib on Databricks
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[docs.databricks.com](https://docs.databricks.com/en/machine-learning/train-model/mllib.html?source=post_page-----9f894299c32d--------------------------------)
    [](https://docs.databricks.com/en/_extras/notebooks/source/binary-classification.html?source=post_page-----9f894299c32d--------------------------------)
    [## 在 Databricks 上使用 Apache Spark MLlib'
- en: Learn how to train machine learning models using the Apache Spark MLlib Pipelines
    API in Databricks. Classification…
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 学习如何在 Databricks 中使用 Apache Spark MLlib Pipelines API 训练机器学习模型。分类…
- en: docs.databricks.com](https://docs.databricks.com/en/_extras/notebooks/source/binary-classification.html?source=post_page-----9f894299c32d--------------------------------)  [##
    LogisticRegression - PySpark 3.5.0 documentation
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[docs.databricks.com](https://docs.databricks.com/en/_extras/notebooks/source/binary-classification.html?source=post_page-----9f894299c32d--------------------------------)
    [## LogisticRegression - PySpark 3.5.0 文档'
- en: setParams(self, *, featuresCol="features", labelCol="label", predictionCol="prediction",
    maxIter=100, regParam=0.0…
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: setParams(self, *, featuresCol="features", labelCol="label", predictionCol="prediction",
    maxIter=100, regParam=0.0…
- en: spark.apache.org](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.LogisticRegression.html?source=post_page-----9f894299c32d--------------------------------)
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[spark.apache.org](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.LogisticRegression.html?source=post_page-----9f894299c32d--------------------------------)'
