- en: 'BigQuery Best Practices: Unleash the Full Potential of Your Data Warehouse'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BigQuery æœ€ä½³å®è·µï¼šé‡Šæ”¾æ•°æ®ä»“åº“çš„å…¨éƒ¨æ½œåŠ›
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/bigquery-best-practices-unleash-the-full-potential-of-your-data-warehouse-334a0a9adef2](https://towardsdatascience.com/bigquery-best-practices-unleash-the-full-potential-of-your-data-warehouse-334a0a9adef2)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/bigquery-best-practices-unleash-the-full-potential-of-your-data-warehouse-334a0a9adef2](https://towardsdatascience.com/bigquery-best-practices-unleash-the-full-potential-of-your-data-warehouse-334a0a9adef2)
- en: Supercharge your BigQuery experience with these 6 best practices
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç”¨è¿™6ä¸ªæœ€ä½³å®è·µè¶…çº§æå‡ä½ çš„ BigQuery ä½“éªŒ
- en: '[](https://niczky12.medium.com/?source=post_page-----334a0a9adef2--------------------------------)[![Bence
    Komarniczky](../Images/d4de94667bcac6d9001390515592eab9.png)](https://niczky12.medium.com/?source=post_page-----334a0a9adef2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----334a0a9adef2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----334a0a9adef2--------------------------------)
    [Bence Komarniczky](https://niczky12.medium.com/?source=post_page-----334a0a9adef2--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://niczky12.medium.com/?source=post_page-----334a0a9adef2--------------------------------)[![Bence
    Komarniczky](../Images/d4de94667bcac6d9001390515592eab9.png)](https://niczky12.medium.com/?source=post_page-----334a0a9adef2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----334a0a9adef2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----334a0a9adef2--------------------------------)
    [Bence Komarniczky](https://niczky12.medium.com/?source=post_page-----334a0a9adef2--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----334a0a9adef2--------------------------------)
    Â·5 min readÂ·Jun 1, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----334a0a9adef2--------------------------------)
    Â·5åˆ†é’Ÿé˜…è¯»Â·2023å¹´6æœˆ1æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/597078e5659914a67c73196ce9a38721.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/597078e5659914a67c73196ce9a38721.png)'
- en: Photo by [charlesdeluvio](https://unsplash.com/@charlesdeluvio?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ç…§ç‰‡ç”± [charlesdeluvio](https://unsplash.com/@charlesdeluvio?utm_source=medium&utm_medium=referral)
    æä¾›ï¼Œæ¥æºäº [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Google BigQuery, a powerful serverless data warehouse, has become a cornerstone
    of data analysis and machine learning pipelines for many organizations. To harness
    its full potential and ensure an efficient, cost-effective experience, itâ€™s crucial
    to follow some best practices. In this article, weâ€™ll delve into **six essential
    best practices that will help you optimize your BigQuery performance and usage**.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Google BigQuery æ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ— æœåŠ¡å™¨æ•°æ®ä»“åº“ï¼Œå·²ç»æˆä¸ºè®¸å¤šç»„ç»‡æ•°æ®åˆ†æå’Œæœºå™¨å­¦ä¹ ç®¡é“çš„åŸºçŸ³ã€‚ä¸ºäº†å……åˆ†å‘æŒ¥å…¶æ½œåŠ›å¹¶ç¡®ä¿é«˜æ•ˆä¸”å…·æœ‰æˆæœ¬æ•ˆç›Šçš„ä½“éªŒï¼Œéµå¾ªä¸€äº›æœ€ä½³å®è·µè‡³å…³é‡è¦ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨**å…­ä¸ªå…³é”®æœ€ä½³å®è·µï¼Œå¸®åŠ©ä½ ä¼˜åŒ–
    BigQuery çš„æ€§èƒ½å’Œä½¿ç”¨**ã€‚
- en: 1 Keep an Eye on Cost Estimates
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 å…³æ³¨æˆæœ¬ä¼°ç®—
- en: BigQueryâ€™s pricing model is based on the amount of data processed by your queries.
    Before running complex or large-scale queries, itâ€™s wise to review the cost estimates
    to ensure you stay within your budget. By understanding the cost implications
    of your queries, you can make informed decisions and avoid unexpected billing
    surprises.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: BigQuery çš„å®šä»·æ¨¡å‹åŸºäºä½ æŸ¥è¯¢å¤„ç†çš„æ•°æ®é‡ã€‚åœ¨è¿è¡Œå¤æ‚æˆ–å¤§è§„æ¨¡æŸ¥è¯¢ä¹‹å‰ï¼Œæ˜æ™ºçš„åšæ³•æ˜¯æŸ¥çœ‹æˆæœ¬ä¼°ç®—ï¼Œä»¥ç¡®ä¿ä½ ä¿æŒåœ¨é¢„ç®—èŒƒå›´å†…ã€‚é€šè¿‡äº†è§£æŸ¥è¯¢çš„æˆæœ¬å½±å“ï¼Œä½ å¯ä»¥åšå‡ºæ˜æ™ºçš„å†³ç­–ï¼Œé¿å…æ„å¤–çš„è´¦å•æƒŠå–œã€‚
- en: Never select more columns than needed. BigQuery will push down your selections
    to the very beginning of computing if it can, but if you do `select *` youâ€™re
    shooting yourself in the foot as BigQuery would need to take all the columns for
    your query and that costs money.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è¦é€‰æ‹©è¶…è¿‡éœ€è¦çš„åˆ—ã€‚å¦‚æœå¯èƒ½çš„è¯ï¼ŒBigQuery ä¼šå°†ä½ çš„é€‰æ‹©æ¨åˆ°è®¡ç®—çš„æœ€å‰é¢ï¼Œä½†å¦‚æœä½ ä½¿ç”¨`select *`ï¼Œä½ å°±æ˜¯åœ¨è‡ªæ˜åŸå¢“ï¼Œå› ä¸º BigQuery
    éœ€è¦å¤„ç†æŸ¥è¯¢ä¸­çš„æ‰€æœ‰åˆ—ï¼Œè¿™ä¼šäº§ç”Ÿé¢å¤–çš„è´¹ç”¨ã€‚
- en: Before you press `RUN`, take a peak at the top right corner and save yourself
    some ğŸ’°.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä½ æŒ‰ä¸‹ `RUN` ä¹‹å‰ï¼Œç„ä¸€çœ¼å³ä¸Šè§’ï¼Œä¸ºè‡ªå·±èŠ‚çœä¸€äº›ğŸ’°ã€‚
- en: '![](../Images/489339e51fadd22e5c2fed735b0ef4c8.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/489339e51fadd22e5c2fed735b0ef4c8.png)'
- en: Youâ€™ll be looking for the number of GB/MB processed by the query â€” screenshot
    by author
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ éœ€è¦æŸ¥çœ‹æŸ¥è¯¢å¤„ç†çš„ GB/MB æ•°é‡ â€” ä½œè€…æˆªå›¾
- en: 2 Sampling for Machine Learning
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2 æœºå™¨å­¦ä¹ çš„æŠ½æ ·
- en: Machine Learning in BigQuery costs 50x more ($250/TB vs $5/TB) than querying
    so it is especially important to **reduce the amount of data youâ€™re working with**.
    By sampling your data, you can significantly reduce the amount of data processed,
    leading to faster model training and reduced costs. Use BigQueryâ€™s `FARM_FINGERPRINT()`
    function to generate reproducible random samples for your machine-learning pipelines.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: BigQuery ä¸­çš„æœºå™¨å­¦ä¹ æˆæœ¬æ˜¯æŸ¥è¯¢çš„ 50 å€ï¼ˆ$250/TB å¯¹æ¯” $5/TBï¼‰ï¼Œå› æ­¤**å‡å°‘ä½ å¤„ç†çš„æ•°æ®é‡**å°¤ä¸ºé‡è¦ã€‚é€šè¿‡å¯¹æ•°æ®è¿›è¡ŒæŠ½æ ·ï¼Œä½ å¯ä»¥æ˜¾è‘—å‡å°‘å¤„ç†çš„æ•°æ®é‡ï¼Œä»è€ŒåŠ å¿«æ¨¡å‹è®­ç»ƒå¹¶é™ä½æˆæœ¬ã€‚ä½¿ç”¨
    BigQuery çš„ `FARM_FINGERPRINT()` å‡½æ•°ç”Ÿæˆå¯å¤ç°çš„éšæœºæ ·æœ¬ï¼Œä»¥ç”¨äºä½ çš„æœºå™¨å­¦ä¹ ç®¡é“ã€‚
- en: 'Check out this article on how to do ML in BigQuery and do reproducible sampling:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹è¿™ç¯‡æ–‡ç« äº†è§£å¦‚ä½•åœ¨ BigQuery ä¸­è¿›è¡Œæœºå™¨å­¦ä¹ å’Œå¯å¤ç°çš„æŠ½æ ·ï¼š
- en: '[](/end-to-end-bigquery-machine-learning-e7e6e2e83b34?source=post_page-----334a0a9adef2--------------------------------)
    [## End-to-End BigQuery Machine Learning'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/end-to-end-bigquery-machine-learning-e7e6e2e83b34?source=post_page-----334a0a9adef2--------------------------------)
    [## ç«¯åˆ°ç«¯ BigQuery æœºå™¨å­¦ä¹ '
- en: Use Google Cloud BigQuery to compete in a Kaggle competition
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Google Cloud BigQuery å‚åŠ  Kaggle æ¯”èµ›
- en: towardsdatascience.com](/end-to-end-bigquery-machine-learning-e7e6e2e83b34?source=post_page-----334a0a9adef2--------------------------------)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/end-to-end-bigquery-machine-learning-e7e6e2e83b34?source=post_page-----334a0a9adef2--------------------------------)'
- en: 3 Utilize Parquet for Data Uploads
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3 åˆ©ç”¨ Parquet è¿›è¡Œæ•°æ®ä¸Šä¼ 
- en: When uploading data to BigQuery, consider using the Parquet file format. Parquet
    is a columnar storage format optimized for analytical workloads, offering improved
    compression and encoding schemes. Uploading data in Parquet format can lead to
    **reduced headaches and faster load times** as all your column information is
    embedded in your files.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å°†æ•°æ®ä¸Šä¼ åˆ° BigQuery æ—¶ï¼Œè€ƒè™‘ä½¿ç”¨ Parquet æ–‡ä»¶æ ¼å¼ã€‚Parquet æ˜¯ä¸€ç§åˆ—å¼å­˜å‚¨æ ¼å¼ï¼Œé’ˆå¯¹åˆ†æå·¥ä½œè´Ÿè½½è¿›è¡Œäº†ä¼˜åŒ–ï¼Œæä¾›äº†æ›´å¥½çš„å‹ç¼©å’Œç¼–ç æ–¹æ¡ˆã€‚ä»¥
    Parquet æ ¼å¼ä¸Šä¼ æ•°æ®å¯ä»¥**å‡å°‘éº»çƒ¦å’ŒåŠ å¿«åŠ è½½æ—¶é—´**ï¼Œå› ä¸ºæ‰€æœ‰åˆ—ä¿¡æ¯éƒ½åµŒå…¥åœ¨æ–‡ä»¶ä¸­ã€‚
- en: 'Hereâ€™s how you can load files into BigQuery and why parquet is faster:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯å¦‚ä½•å°†æ–‡ä»¶åŠ è½½åˆ° BigQuery ä»¥åŠä¸ºä½• Parquet æ›´å¿«ï¼š
- en: '[](/loading-files-into-bigquery-6de1ff63df35?source=post_page-----334a0a9adef2--------------------------------)
    [## Loading files into BigQuery'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/loading-files-into-bigquery-6de1ff63df35?source=post_page-----334a0a9adef2--------------------------------)
    [## å°†æ–‡ä»¶åŠ è½½åˆ° BigQuery'
- en: Using Python to ingest Parquet and CSV files into GCP BigQuery
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Python å°† Parquet å’Œ CSV æ–‡ä»¶å¯¼å…¥ GCP BigQuery
- en: towardsdatascience.com](/loading-files-into-bigquery-6de1ff63df35?source=post_page-----334a0a9adef2--------------------------------)
    [](/load-files-faster-into-bigquery-94355c4c086a?source=post_page-----334a0a9adef2--------------------------------)
    [## Load files faster into BigQuery
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/loading-files-into-bigquery-6de1ff63df35?source=post_page-----334a0a9adef2--------------------------------)
    [](/load-files-faster-into-bigquery-94355c4c086a?source=post_page-----334a0a9adef2--------------------------------)
    [## æ›´å¿«åœ°å°†æ–‡ä»¶åŠ è½½åˆ° BigQuery'
- en: Benchmarking CSV, GZIP, AVRO and PARQUET file types for ingestion
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¯¹ CSVã€GZIPã€AVRO å’Œ PARQUET æ–‡ä»¶ç±»å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•
- en: towardsdatascience.com](/load-files-faster-into-bigquery-94355c4c086a?source=post_page-----334a0a9adef2--------------------------------)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/load-files-faster-into-bigquery-94355c4c086a?source=post_page-----334a0a9adef2--------------------------------)'
- en: 4 Generate Arrays for More Powerful Experimentations
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 ç”Ÿæˆæ•°ç»„ä»¥è¿›è¡Œæ›´å¼ºå¤§çš„å®éªŒ
- en: BigQuery allows you to **generate arrays for quick and cheap experimentation
    by querying your data multiple times**. Use the `GENERATE_ARRAY()` and `UNNEST()`
    functions to cross-join your data for testing parameters.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: BigQuery å…è®¸ä½ **é€šè¿‡å¤šæ¬¡æŸ¥è¯¢æ•°æ®ç”Ÿæˆæ•°ç»„ä»¥è¿›è¡Œå¿«é€Ÿä¸”å»‰ä»·çš„å®éªŒ**ã€‚ä½¿ç”¨ `GENERATE_ARRAY()` å’Œ `UNNEST()` å‡½æ•°å¯¹æ•°æ®è¿›è¡Œäº¤å‰è¿æ¥ä»¥æµ‹è¯•å‚æ•°ã€‚
- en: For example, if you have a TB of data, but you want to test 100 different parameters
    for an experiment, donâ€™t query your data 100 times as that would mean you query
    100TB resulting in a bill of $500! Instead, **if you cross-join your data with
    your 100 parameters, youâ€™ll only incur costs for querying that single TB**, so
    your bill is $5.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå¦‚æœä½ æœ‰ä¸€ TB çš„æ•°æ®ï¼Œä½†ä½ æƒ³æµ‹è¯• 100 ä¸ªä¸åŒçš„å®éªŒå‚æ•°ï¼Œä¸è¦å¯¹æ•°æ®è¿›è¡Œ 100 æ¬¡æŸ¥è¯¢ï¼Œå› ä¸ºé‚£æ ·ä¼šæŸ¥è¯¢ 100TB æ•°æ®ï¼Œè´¦å•å°†é«˜è¾¾ 500
    ç¾å…ƒï¼ç›¸åï¼Œ**å¦‚æœä½ å°†æ•°æ®ä¸ 100 ä¸ªå‚æ•°è¿›è¡Œäº¤å‰è¿æ¥ï¼Œä½ åªä¼šä¸ºæŸ¥è¯¢é‚£ä¸€ TB æ•°æ®è€Œäº§ç”Ÿè´¹ç”¨**ï¼Œæ‰€ä»¥è´¦å•æ˜¯ 5 ç¾å…ƒã€‚
- en: 'Hereâ€™s a made-up example for finding the optimal values for the `min_price`,
    `min_quantity`, and `max_delivery_time` parameters that maximize the profit margin
    while meeting customer expectations:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªè™šæ‹Ÿçš„ç¤ºä¾‹ï¼Œç”¨äºå¯»æ‰¾ `min_price`ã€`min_quantity` å’Œ `max_delivery_time` å‚æ•°çš„æœ€ä½³å€¼ï¼Œä»¥åœ¨æ»¡è¶³å®¢æˆ·æœŸæœ›çš„åŒæ—¶æœ€å¤§åŒ–åˆ©æ¶¦ï¼š
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'And if you want a more sophisticated example, check this article out:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³è¦ä¸€ä¸ªæ›´å¤æ‚çš„ç¤ºä¾‹ï¼Œå¯ä»¥æŸ¥çœ‹è¿™ç¯‡æ–‡ç« ï¼š
- en: '[](/advanced-random-sampling-in-bigquery-sql-7d4483b580bb?source=post_page-----334a0a9adef2--------------------------------)
    [## Advanced Random Sampling in BigQuery SQL'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/advanced-random-sampling-in-bigquery-sql-7d4483b580bb?source=post_page-----334a0a9adef2--------------------------------)
    [## BigQuery SQL ä¸­çš„é«˜çº§éšæœºé‡‡æ ·'
- en: Learn how to sample rows from BigQuery tables in a reproducible manner
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å­¦ä¹ å¦‚ä½•ä»¥å¯é‡ç°çš„æ–¹å¼ä» BigQuery è¡¨ä¸­é‡‡æ ·è¡Œ
- en: towardsdatascience.com](/advanced-random-sampling-in-bigquery-sql-7d4483b580bb?source=post_page-----334a0a9adef2--------------------------------)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/advanced-random-sampling-in-bigquery-sql-7d4483b580bb?source=post_page-----334a0a9adef2--------------------------------)
- en: 5 Harness the Power of WITH Statements
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 åˆ©ç”¨ `WITH` è¯­å¥çš„å¼ºå¤§åŠŸèƒ½
- en: BigQueryâ€™s `WITH` statement, also known as **Common Table Expressions** (CTEs),
    can make your queries more readable and maintainable. By using `WITH` statements,
    you can **break down complex queries into smaller, reusable components, making
    it easier to understand and debug your queries**. Additionally, CTEs can improve
    performance by preventing the same subquery from being executed multiple times.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: BigQuery çš„ `WITH` è¯­å¥ï¼Œä¹Ÿç§°ä¸º**å…¬å…±è¡¨è¡¨è¾¾å¼**ï¼ˆCTEï¼‰ï¼Œå¯ä»¥ä½¿ä½ çš„æŸ¥è¯¢æ›´åŠ å¯è¯»å’Œæ˜“äºç»´æŠ¤ã€‚é€šè¿‡ä½¿ç”¨ `WITH` è¯­å¥ï¼Œä½ å¯ä»¥**å°†å¤æ‚çš„æŸ¥è¯¢åˆ†è§£æˆæ›´å°çš„ã€å¯é‡ç”¨çš„ç»„ä»¶ï¼Œä½¿ç†è§£å’Œè°ƒè¯•æŸ¥è¯¢å˜å¾—æ›´å®¹æ˜“**ã€‚æ­¤å¤–ï¼ŒCTE
    è¿˜èƒ½é€šè¿‡é˜²æ­¢ç›¸åŒçš„å­æŸ¥è¯¢è¢«å¤šæ¬¡æ‰§è¡Œæ¥æé«˜æ€§èƒ½ã€‚
- en: 'You can use as many of these as you like, and you can even create new CTEs
    from already-defined CTEs:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥æ ¹æ®éœ€è¦ä½¿ç”¨è¿™äº›åŠŸèƒ½ï¼Œå¹¶ä¸”ä½ ç”šè‡³å¯ä»¥ä»å·²ç»å®šä¹‰çš„ CTE åˆ›å»ºæ–°çš„ CTEï¼š
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 6 Leverage Arguments in Custom Functions
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6 åœ¨è‡ªå®šä¹‰å‡½æ•°ä¸­åˆ©ç”¨å‚æ•°
- en: When creating custom functions in BigQuery, make use of arguments to create
    reusable and flexible functions. **You can build modular and easily maintainable
    code by passing arguments to your functions**. This practice leads to cleaner
    and more efficient code, streamlining your development process.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ BigQuery ä¸­åˆ›å»ºè‡ªå®šä¹‰å‡½æ•°æ—¶ï¼Œåˆ©ç”¨å‚æ•°æ¥åˆ›å»ºå¯é‡ç”¨å’Œçµæ´»çš„å‡½æ•°ã€‚**é€šè¿‡å‘å‡½æ•°ä¼ é€’å‚æ•°ï¼Œä½ å¯ä»¥æ„å»ºæ¨¡å—åŒ–å’Œæ˜“äºç»´æŠ¤çš„ä»£ç **ã€‚è¿™ç§åšæ³•èƒ½å¤Ÿä½¿ä»£ç æ›´ç®€æ´ã€æ›´é«˜æ•ˆï¼Œä»è€Œç®€åŒ–å¼€å‘è¿‡ç¨‹ã€‚
- en: 'Want to learn about BigQuery custom functions? Glad you asked, check this out:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³äº†è§£ BigQuery è‡ªå®šä¹‰å‡½æ•°å—ï¼Ÿå¾ˆé«˜å…´ä½ é—®äº†ï¼Œçœ‹çœ‹è¿™ä¸ªï¼š
- en: '[](/bigquery-udfs-complete-guide-181cbdaea55b?source=post_page-----334a0a9adef2--------------------------------)
    [## BigQuery UDFs Complete Guide'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/bigquery-udfs-complete-guide-181cbdaea55b?source=post_page-----334a0a9adef2--------------------------------)
    [## BigQuery UDFs å®Œæ•´æŒ‡å—'
- en: Everything you need to know about Google Cloud BigQueryâ€™s User-Defined Functions
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å…³äº Google Cloud BigQuery ç”¨æˆ·å®šä¹‰å‡½æ•°çš„æ‰€æœ‰ä¿¡æ¯
- en: towardsdatascience.com](/bigquery-udfs-complete-guide-181cbdaea55b?source=post_page-----334a0a9adef2--------------------------------)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/bigquery-udfs-complete-guide-181cbdaea55b?source=post_page-----334a0a9adef2--------------------------------)
- en: 'Want to deploy a bunch of these using CI/CD pipelines on GitHub? Look no more:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³åœ¨ GitHub ä¸Šé€šè¿‡ CI/CD ç®¡é“éƒ¨ç½²è¿™äº›åŠŸèƒ½ï¼Ÿåˆ«å†æ‰¾äº†ï¼š
- en: '[](https://levelup.gitconnected.com/deploying-bigquery-custom-functions-with-github-actions-d76c118e0abf?source=post_page-----334a0a9adef2--------------------------------)
    [## Deploying BigQuery Custom Functions with GitHub Actions'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://levelup.gitconnected.com/deploying-bigquery-custom-functions-with-github-actions-d76c118e0abf?source=post_page-----334a0a9adef2--------------------------------)
    [## ä½¿ç”¨ GitHub Actions éƒ¨ç½² BigQuery è‡ªå®šä¹‰å‡½æ•°'
- en: Streamline your BigQuery custom functions deployment with the power of GitHub
    Actions automation.
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åˆ©ç”¨ GitHub Actions è‡ªåŠ¨åŒ–æ¥ç®€åŒ–ä½ çš„ BigQuery è‡ªå®šä¹‰å‡½æ•°éƒ¨ç½²ã€‚
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/deploying-bigquery-custom-functions-with-github-actions-d76c118e0abf?source=post_page-----334a0a9adef2--------------------------------)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: levelup.gitconnected.com](https://levelup.gitconnected.com/deploying-bigquery-custom-functions-with-github-actions-d76c118e0abf?source=post_page-----334a0a9adef2--------------------------------)
- en: Happy Querying!
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æŸ¥è¯¢æ„‰å¿«ï¼
- en: Mastering these best practices will help you take full advantage of BigQueryâ€™s
    features while maintaining cost efficiency and improving performance. By monitoring
    cost estimates, using data sampling with `FARM_FINGERPRINT()`, embracing Parquet,
    generating arrays, utilizing `WITH` statements, and employing arguments in custom
    functions, you'll be well-equipped to tackle any BigQuery challenge with confidence.
    Happy querying! ğŸ’»
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: æŒæ¡è¿™äº›æœ€ä½³å®è·µå°†å¸®åŠ©ä½ å……åˆ†åˆ©ç”¨ BigQuery çš„åŠŸèƒ½ï¼ŒåŒæ—¶ä¿æŒæˆæœ¬æ•ˆç›Šå¹¶æå‡æ€§èƒ½ã€‚é€šè¿‡ç›‘æ§æˆæœ¬ä¼°ç®—ã€ä½¿ç”¨ `FARM_FINGERPRINT()`
    è¿›è¡Œæ•°æ®é‡‡æ ·ã€ä½¿ç”¨ Parquet æ ¼å¼ã€ç”Ÿæˆæ•°ç»„ã€åˆ©ç”¨ `WITH` è¯­å¥ä»¥åŠåœ¨è‡ªå®šä¹‰å‡½æ•°ä¸­ä½¿ç”¨å‚æ•°ï¼Œä½ å°†èƒ½å¤Ÿè‡ªä¿¡åœ°åº”å¯¹ä»»ä½• BigQuery æŒ‘æˆ˜ã€‚æŸ¥è¯¢æ„‰å¿«ï¼ğŸ’»
