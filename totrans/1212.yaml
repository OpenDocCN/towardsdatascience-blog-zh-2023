- en: How to Measure the Carbon Footprint using Python and Vertex AI Pipelines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/how-to-mesure-the-carbon-footprint-using-vertex-ai-pipelines-3d6bc9695e7b](https://towardsdatascience.com/how-to-mesure-the-carbon-footprint-using-vertex-ai-pipelines-3d6bc9695e7b)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A step-by-step guide on tracking carbon emissions using Vertex AI Pipelines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@anna.bildea?source=post_page-----3d6bc9695e7b--------------------------------)[![Ana
    Bildea, PhD](../Images/60567c2b09bd0be5b25e508905dfe4c6.png)](https://medium.com/@anna.bildea?source=post_page-----3d6bc9695e7b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3d6bc9695e7b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3d6bc9695e7b--------------------------------)
    [Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----3d6bc9695e7b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3d6bc9695e7b--------------------------------)
    ¬∑9 min read¬∑Jan 31, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6f604577434a098bfe1758e826444eb3.png)'
  prefs: []
  type: TYPE_IMG
- en: image generated by the Author with Midjourney.
  prefs: []
  type: TYPE_NORMAL
- en: Motivation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Machine learning has become a regular part of our daily lives, therefore it
    is time to consider its potential impacts on the environment. Otherwise, Mother
    Nature might just give us an ‚Äò*I told you so‚Äô* in the form of natural disasters
    leading to severe human suffering. One way we can help combat climate change is
    by starting to measure and reduce the carbon footprint of our machine-learning
    models. The carbon footprint measures the total greenhouse gas emissions caused
    by services, products, persons, organizations, or events. In the case of machine
    learning, it includes the energy required to train and run models, as well as
    the energy used by the hardware on which they‚Äôre running.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I will provide feedback on two open-source Python libraries,
    [CodeCarbon](https://pypi.org/project/codecarbon/) and [CarbonTracker](https://github.com/lfwa/carbontracker),
    which are able to estimate the carbon footprint. I will also include a step-by-step
    guide for using them in Vertex AI pipelines. Lastly, I will list practical considerations
    for reducing the carbon footprint. So, let‚Äôs start doing our part in saving the
    planet before it‚Äôs too late! üíö
  prefs: []
  type: TYPE_NORMAL
- en: I. Carbon Footprint in Python üìó
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Two of the most popular libraries for measuring the carbon footprint in Python
    are [CodeCarbon](https://pypi.org/project/codecarbon/) and [CarbonTracker](https://github.com/lfwa/carbontracker).
    The truth is that we do not have many open-source alternatives. But I believe
    we will have more options available once the community begins to integrate carbon
    footprint into the machine learning systems.
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs say a few words about the libraries.
  prefs: []
  type: TYPE_NORMAL
- en: CodeCarbon
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is an open-source Python library that estimates the CO2 produced while running
    the code. The project was initiated by Yoshua Bengio. One of the things I appreciate
    most about it is that is very easy to use, has good documentation, and nice [Dashboard](https://dashboard.codecarbon.io/).
    The estimation is done by measuring the power consumption of the total GPUs, CPUs,
    and RAM. Then it applies the [regional carbon intensity of electricity](https://ourworldindata.org/grapher/carbon-intensity-electricity)
    of your [cloud](https://github.com/mlco2/codecarbon/blob/master/codecarbon/data/cloud/impact.csv)
    provider or [country](https://github.com/mlco2/codecarbon/blob/master/codecarbon/data/private_infra/eu-carbon-intensity-electricity.csv)
    if you are using a local machine or on-premise cluster. Refer to the table below
    to see the carbon intensity across various energy sources.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e20e8c07b5ad541c58a06916294dd5b6.png)'
  prefs: []
  type: TYPE_IMG
- en: '@[CodeCarbon](https://mlco2.github.io/codecarbon/methodology.html#) source'
  prefs: []
  type: TYPE_NORMAL
- en: 'The carbon dioxide emissions estimation (CO‚ÇÇeq) is calculated as below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Note that CodeCarbon uses a world average of [**475 gCO2.eq/KWh**](https://www.iea.org/reports/global-energy-co2-status-report-2019/emissions)
    when the carbon intensity is not available. The emissions are saved into a CSV
    file named `emissions.csv.`
  prefs: []
  type: TYPE_NORMAL
- en: In terms of supported infrastructure, it is compatible with NVIDIA GPUs that
    support [NVIDIA Management Library (NVML](https://developer.nvidia.com/nvidia-management-library-nvml))
    and Intel CPUs that [support Intel RAPL](http://web.eece.maine.edu/~vweaver/projects/rapl/rapl_support.html)
    . If your CPU is not on the [list of supported CPUs](https://github.com/mlco2/codecarbon/blob/master/codecarbon/data/hardware/cpu_power.csv)
    then it will estimate the power consumption of the CPUs as 50% of their thermal
    design power(TDP) using a default TDP average of 85W.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install it use pip:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'It supports two modes: `online mode` or `offline mode` .'
  prefs: []
  type: TYPE_NORMAL
- en: '`The Online mode` needs an internet connection to retrieve your geographical
    location. See below an example of using it with or without a decorator:'
  prefs: []
  type: TYPE_NORMAL
- en: '`The Offline mode` can be used when your setup doesn‚Äôt have access to the internet.
    It requires specifying the 3-letter alphabet ISO Code of the country. You can
    find a list of country **ISO** codes on [Wikipedia](https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes).'
  prefs: []
  type: TYPE_NORMAL
- en: CarbonTracker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[CarbonTracker](https://arxiv.org/abs/2007.03051) is an open-source library
    aiming to estimate the carbon footprint of training a deep learning model by measuring
    the power consumption of the hardware used for training. Currently, it supports
    GPU, CPU, and DRAM components. It is compatible with NVIDIA GPUs that support
    [NVIDIA Management Library (NVML](https://developer.nvidia.com/nvidia-management-library-nvml),
    Intel CPUs that support [Intel RAP](http://web.eece.maine.edu/~vweaver/projects/rapl/rapl_support.html)L,
    Slurm, and Google Colab / Jupyter Notebook. It is easy to use but unfortunately,
    the documentation is limited.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To estimate the carbon footprint it uses the formula :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The `Energy Consumption`is computed based on PUE (Power Usage Effectiveness),
    a metric used to measure the energy efficiency of data centers. It is calculated
    by dividing the total amount of energy used by a data center by the energy used
    by the IT equipment (e.g. servers, storage, etc.).
  prefs: []
  type: TYPE_NORMAL
- en: It uses the same `Carbon Intensity` per [cloud](https://github.com/mlco2/codecarbon/blob/master/codecarbon/data/cloud/impact.csv)
    or [country](https://github.com/mlco2/codecarbon/blob/master/codecarbon/data/private_infra/eu-carbon-intensity-electricity.csv)
    as `codecarbon.` It applies a world average of [**475 gCO2.eq/KWh**](https://www.iea.org/reports/global-energy-co2-status-report-2019/emissions)when
    the carbon intensity is not available.
  prefs: []
  type: TYPE_NORMAL
- en: 'Can be installed with pip:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The usage is simple as you can see in the example below:'
  prefs: []
  type: TYPE_NORMAL
- en: 'It has also the capability to gather and store logs in a defined directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have an idea about CodeCarbon and CarbonTracker we are going to
    use them in a Vertex AI Pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: II. Case study with Vertex AI Pipelinesüë∑
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The fun part begins right now üòÑ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before proceeding with the Vertex AI Pipelines, I invite you to read [**my article**](https://medium.com/towards-data-science/how-to-set-up-custom-vertex-ai-pipelines-step-by-step-467487f81cad)
    which shows how to use Vertex AI Pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, I will demonstrate how to track the carbon footprint in two scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Supervised machine learning with CodeCarbon only (CarbonTracker supports
    only deep learning).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2\. Deep learning with CodeCarbon & CarbonTracker.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*1\. Carbon Footprint on supervised machine learning on CPU*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are going to track the carbon emissions while training a Random Forest algorithm
    to **‚Äú*Predict the wine quality*‚Äù.** The data is downloaded from [UCI Machine
    Learning Repository](https://archive.ics.uci.edu/ml/datasets/wine+quality) @source
    [Cortez et al., 2009]. Check the section [The Use Case](https://medium.com/towards-data-science/how-to-set-up-custom-vertex-ai-pipelines-step-by-step-467487f81cad)
    in my article for more details on the dataset. The notebook is available on [GitHub](https://github.com/anabild/mlops/tree/main/notebook).
  prefs: []
  type: TYPE_NORMAL
- en: 'To measure the carbon emissions during training we need to modify the `train_winequality`
    custom Kubeflow component in the notebook as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Add `codecarbon`to `packages_to_install`list.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add a metric to track the value of the CO2 estimations `kpi_co2:Output[Metrics].`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Import `OfflineEmissionsTracker` to use the offline mode (no internet connection
    on the setup).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate the codecarbon tracker `tracker = OfflineEmissionsTracker(country_iso_code=‚ÄùBEL‚Äù).`
    BEL stands for Belgium. Pay attention that the country should match the selected
    Google Cloud region, `europe-west1` in our case.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Start tracking with `tracker.start().`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Start training the model using .fit() method.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stop tracking with `tracker.stop()`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Log the emissions `kpi_co2.log_metric(‚Äúemissions‚Äù, float(emissions)).`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See below my example.
  prefs: []
  type: TYPE_NORMAL
- en: Once you update the `train_winequality` component and run again the notebook
    you should see the `kpi_co2` metric artifact on the pipeline graph.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/472f269f1a098b40451796a2a78c2caa.png)'
  prefs: []
  type: TYPE_IMG
- en: image by the author
  prefs: []
  type: TYPE_NORMAL
- en: Then, go under the NODE INFO tab to check the value of the estimation of the
    CO2 emissions in kg/kWh.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1fb66273dede602228515c1be85dc6bd.png)'
  prefs: []
  type: TYPE_IMG
- en: ‚ùóÔ∏è Be aware that to create a Vertex AI Pipeline without monitoring until completion
    you can use **submit** instead of **run**.
  prefs: []
  type: TYPE_NORMAL
- en: Now let‚Äôs do the exercise using a deep-learning algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. Carbon Footprint using deep learning on GPU**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, we are going to train a deep-learning model using [Keras](https://keras.io/)
    (open-source Python deep-learning library) and [Tensorflow](https://www.tensorflow.org/)
    (open-source machine learning framework). The goal is to determine if a photo
    includes any of the labels listed in Table 1\. To achieve this we perform image
    classification using a custom *Convolutional Neural Networks* (CNN) architecture.
  prefs: []
  type: TYPE_NORMAL
- en: '**2.1 Data description**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We use the Fashion-MNIST held by Zalando SE dataset available in Keras licensed
    under the [MIT license](https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE).
    It includes 60,000 images for training and 10.000 for testing. Each image is a
    28x28 grayscale of 10 different fashion categories labeled with one of the 10
    classes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8726bb05aeb51ca2fd2d1963e3ac4a9e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 1: Contains the labels of the photos.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Set up the environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Vertex AI Workbench
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python 3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubeflow pipeline components
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pre-build images using NVIDIA TESLA T4 GPU
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tensorflow 2.11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Codecarbon
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CarbonTracker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then install Google Cloud Pipeline Components and TensorFlow with pip.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Import the libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Define global variables.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 Create a custom deep-learning component
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I‚Äôll be using as base image the `tf-gpu.2‚Äì11:latest` pre-built docker image
    that contains TensorFlow and GPU in Artifact Registry. See the available pre-built
    images for [prediction](https://console.cloud.google.com/artifacts/docker/vertex-ai/europe/prediction)
    and [training](https://console.cloud.google.com/artifacts/docker/vertex-ai/europe/training)
    in Europe. Note that Google released pre-build images also the [Container Registry.](https://console.cloud.google.com/gcr/images/deeplearning-platform-release/GLOBAL)
  prefs: []
  type: TYPE_NORMAL
- en: 'To enable `codecarbon` and `carbontracker` we are going to proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Add `codecarbon and carbontracker`to `packages_to_install`list.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add metric to track the estimations `kpi_co2:Output[Metrics].`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Import CarbonTracker and the log parser.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define a directory to redirect the logs of the `carbontracker` e.g `DIR_LOG="log"`
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load train images and rescale them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use `keras.Sequential` API to define the layers of your CNN.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compile the model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Start `codecarbon` and specify the ISO code NLD for Netherlands region.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specifythe number of epochs and the log directory for carbontracker `carbontracker
    = CarbonTracker(epochs=epochs, log_dir=‚Äù./‚Äù+DIR_LOG+‚Äù/‚Äù).`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Start carbontracker `carbontracker.epoch_start().`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fit model on the training data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Stop carbontracker : `carbontracker.epoch_end()` & codecarbon `codecarbon.stop().`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Log the emissions values and save the model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2.4 Evaluate the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The evaluation component relies on a pre-compiled GPU Tensorflow 2.11 base image.
  prefs: []
  type: TYPE_NORMAL
- en: It takes in input the trained model. Then it loads the `fashion.mist` test dataset.
    It resizes and reshapes the test images, evaluates the model, and computes the
    accuracy, loss, and confusion matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 2.5 Create and submit the pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The pipeline facilitates the orchestration of a serverless workflow. Our pipeline
    has two steps training (deep_learning_mist_task) and evaluation (model _evaluation_task).
    It takes as input a few parameters like the learning_rate, the number of epochs,
    the batch_size, the API endpoint, the project id, and the serving URI.
  prefs: []
  type: TYPE_NORMAL
- en: 'To specify the machine configuration for a pipeline step use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The available values for GPU_TYPE are:'
  prefs: []
  type: TYPE_NORMAL
- en: NVIDIA_TESLA_A100,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NVIDIA_TESLA_K80,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NVIDIA_TESLA_P4,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NVIDIA_TESLA_P100,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NVIDIA_TESLA_T4,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NVIDIA_TESLA_V10.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The GPU_LIMIT is a positive number indicating the GPU limit.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the pipeline is executed you should see the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3b69ee5a1987773220d77ba6dbc929ca.png)'
  prefs: []
  type: TYPE_IMG
- en: image by the Author
  prefs: []
  type: TYPE_NORMAL
- en: Go to the ***Summary*** tab to see the estimation of the CO2 emissions during
    training.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/03640f96a2246f6a34e2668a7c9a9617.png)'
  prefs: []
  type: TYPE_IMG
- en: image by the Author
  prefs: []
  type: TYPE_NORMAL
- en: We can notice that the CO2 estimations are different because the energy consumption
    formula differs between the two libraries. To be honest, I prefer Codecarbon as
    it has more compatibility and better documentation.
  prefs: []
  type: TYPE_NORMAL
- en: III. Few practices to reduce Carbon Footprint üí°
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I suggest taking into account some practical considerations while designing
    AI algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Consider integrating carbon footprint into the **entire lifecycle of a machine
    learning model**, from data collection to model deployment.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Look for machines equipped with appropriate processors** (CPU/GPU/TPU)s that
    fit your use case.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Choose a cloud region with a low carbon footprint.** For instance, Google
    Cloud Platform indicates for each available region if it is low CO2.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Integrate carbon footprint trackers** in your ML ecosystem.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Select efficient model architecture**s. Have a look at [sparse models](https://ai.googleblog.com/2021/03/constructing-transformers-for-longer.html)
    that may reduce energy consumption.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Encourage teams to use the cloud**, as it has been shown to be [more energy-efficient](https://www.morganclaypool.com/doi/10.2200/S00874ED3V01Y201809CAC046).'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Use pre-built models** as much as possible rather than training from scratch.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Share datasets, feature stores, and pre-build** specialized models across
    the organization.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Key takeaways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In conclusion, I recommend using Codecarbon as it performs well on both machine
    learning (CPUs) and deep learning algorithms (GPUs) and has more infrastructure
    compatibility. Regarding CarbonTraker, I encountered difficulties with getting
    it to run on Google Cloud CPUs getting CPUs unsupported errors, leading to wasted
    time. If you plan to use a GPU keep in mind to verify the GPU [availabilit](https://cloud.google.com/compute/docs/gpus/gpu-regions-zones)y
    before using it. Additionally, I strongly suggest checking t[he GPU pricing](https://cloud.google.com/compute/gpus-pricing#gpu-pricing)
    to aim for lower costs. Lastly, it‚Äôs important to remember that reducing carbon
    footprint in machine learning is a continuous process and new techniques and technologies
    are being constantly developed to address it. Make sure to keep track of updates
    regarding carbon footprint reduction strategies.
  prefs: []
  type: TYPE_NORMAL
- en: The notebooks are available on my [GitHub](https://github.com/anabild/mlops/tree/main/notebook)
    account.
  prefs: []
  type: TYPE_NORMAL
- en: I hope you enjoyed the article.
  prefs: []
  type: TYPE_NORMAL
- en: Thank you for reading!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Don‚Äôt forget to [subscribe](https://medium.com/subscribe/@anna.bildea) if you
    want to get my future stories in your inbox.
  prefs: []
  type: TYPE_NORMAL
- en: '*If you enjoy reading my story and want to support me as a writer, consider
    signing up to become a Medium member and gain access to thousands of Data Engineering
    and Data Science articles.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/@anna.bildea/membership?source=post_page-----3d6bc9695e7b--------------------------------)
    [## Join Medium with my referral link ‚Äî Bildea Ana'
  prefs: []
  type: TYPE_NORMAL
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every story‚Ä¶
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@anna.bildea/membership?source=post_page-----3d6bc9695e7b--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '*Find me on* [*LinkedIn*](https://www.linkedin.com/in/ana-bildea-phd-2339b728/)
    *and* [Twitter](https://twitter.com/AnaBildea)!'
  prefs: []
  type: TYPE_NORMAL
- en: See my collection of MLops articles
  prefs: []
  type: TYPE_NORMAL
- en: '![Ana Bildea, PhD](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----3d6bc9695e7b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: MLOps - AI in Production
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://medium.com/@anna.bildea/list/mlops-ai-in-production-04b6c81c50c8?source=post_page-----3d6bc9695e7b--------------------------------)4
    stories![](../Images/8fbedcb9f3f75894caff649172adece1.png)![](../Images/d5014b3b3843fc4b2172bef517cccaa4.png)![](../Images/2dba051abf51711268415c3f1e055a60.png)'
  prefs: []
  type: TYPE_NORMAL
