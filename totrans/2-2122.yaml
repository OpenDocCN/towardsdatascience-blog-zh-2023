- en: Top 4 Plots in Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/top-4-plots-in-machine-learning-b5796ba73e8d](https://towardsdatascience.com/top-4-plots-in-machine-learning-b5796ba73e8d)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: MACHINE LEARNING | PLOTS | PYTHON
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A practical guide to the most important visualisations to master machine learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://david-farrugia.medium.com/?source=post_page-----b5796ba73e8d--------------------------------)[![David
    Farrugia](../Images/082ed61e24c7c26a4ae1c77343a87824.png)](https://david-farrugia.medium.com/?source=post_page-----b5796ba73e8d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b5796ba73e8d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b5796ba73e8d--------------------------------)
    [David Farrugia](https://david-farrugia.medium.com/?source=post_page-----b5796ba73e8d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b5796ba73e8d--------------------------------)
    ·6 min read·Jun 16, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/034e80631806f2605e38af6eaaf3986a.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Firmbee.com](https://unsplash.com/@firmbee?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: In the dynamic world of machine learning, visualisations play a vital role.
    They are the silent narrators of the complex stories that data tells.
  prefs: []
  type: TYPE_NORMAL
- en: Especially in the world of machine learning, data visualisation plays an even
    more critical role to further enable us to understand the underlying structures
    of our models and aid us in better interpreting the quality of our results.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we’ll dive into five crucial plots that any machine learning
    enthusiast must know.
  prefs: []
  type: TYPE_NORMAL
- en: 'Plot 1: Elbow Curve'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Elbow Curve is an excellent tool used to determine the optimal number of
    clusters in a clustering algorithm such as K-Means.
  prefs: []
  type: TYPE_NORMAL
- en: As the name implies, the plot often has a sharp bend (i.e., the elbow), which
    indicates the ‘*sweet-spot*’ where adding more clusters leads to worse cluster
    separation and inferior results.
  prefs: []
  type: TYPE_NORMAL
- en: This plot is indispensable for ensuring that we’re extracting meaningful clusters
    from our data, without over-fitting or under-fitting.
  prefs: []
  type: TYPE_NORMAL
- en: In unsupervised algorithms that require us to specify a pre-determined number
    of clusters (such as K-Means), the elbow method is vital to help us identify the
    optimal number of clusters to select.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a simple Python code snippet to generate an elbow curve:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b31d089c8f0f81bc089287be67c84ebf.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: In the above plot, we can see that we are plotting the distortion against the
    number of clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Distortion is the euclidean of square distances between the specific data point
    and its cluster’s centre. It is also common to use the inertia instead (i.e, the
    sum of square distances).
  prefs: []
  type: TYPE_NORMAL
- en: The goal here is to pick the perfect trade-off.
  prefs: []
  type: TYPE_NORMAL
- en: We want a low distortion/inertia value for tight intra-cluster similarity. But
    at the same time, we want every individual cluster to be as unique as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the perfect scenario would be a very low intra-cluster similarity
    but a very high inter-cluster similarity.
  prefs: []
  type: TYPE_NORMAL
- en: We try to approximate this sweet-spot by taking the point at the sharp bend.
    In the above plot, we can either go with 3 or 4 clusters.
  prefs: []
  type: TYPE_NORMAL
- en: The sharp bend point ensures that we have a low distortion value without having
    a saturated number of clusters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Plot 2: AUROC Curve'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Area Under the Receiver Operating Characteristic (AUROC) Curve is a fundamental
    plot mainly used in binary classification tasks.
  prefs: []
  type: TYPE_NORMAL
- en: It measures the entire two-dimensional area underneath the entire ROC curve,
    which plots true positive rate (sensitivity) against false positive rate (1-specificity)
    for different threshold values.
  prefs: []
  type: TYPE_NORMAL
- en: AUROC values range from 0.5 (essentially a random model) to 1.0 (perfectly discriminative
    model), helping us quantify model performance irrespective of the threshold.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/447d9d9e9cf70b75e51ff37cdeaf0883.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: In the above plot, we see our baseline (the black dotted line).
  prefs: []
  type: TYPE_NORMAL
- en: Any model should ideally be as far away from the baseline as possible and towards
    the upper half of the plot (i.e., high true positive rate but low false positive
    rate).
  prefs: []
  type: TYPE_NORMAL
- en: 'Plot 3: Cumulative Explained Variance'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Cumulative Explained Variance plot is crucial in Principal Component Analysis
    (PCA) — a technique used for dimensionality reduction.
  prefs: []
  type: TYPE_NORMAL
- en: This plot helps us determine the number of components we should choose to retain
    while still preserving a substantial portion of the original variance.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/fbefd2eae6d1a8ad555e26dfc8de405f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: There is no specific value to pick here, but a typical rule of thumb is to try
    to retain at least an explained variance ratio of 0.8.
  prefs: []
  type: TYPE_NORMAL
- en: This process would be similar to that of the elbow method in Plot 1\. We run
    various steps each time incrementing the number of principal components.
  prefs: []
  type: TYPE_NORMAL
- en: Then, using the explained variance plot, we can determine the minimum number
    of principal components needed to retain the original variance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Plot 4: Precision-Recall Curve'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Precision-Recall Curve is another essential tool for binary classification
    tasks, similar to the AUROC.
  prefs: []
  type: TYPE_NORMAL
- en: It illustrates the trade-off between **precision** (*the ability of the classifier
    not to label a negative sample as positive*) and **recall** (*the ability of the
    classifier to find all the positive samples*).
  prefs: []
  type: TYPE_NORMAL
- en: This plot is especially useful when dealing with imbalanced datasets.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/554bf830721d24368fda27d2ed4f2769.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Concluding Remarks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In conclusion, these four plots serve as powerful tools in a data scientist’s
    arsenal.
  prefs: []
  type: TYPE_NORMAL
- en: By using these visualisations wisely, you can extract meaningful insights from
    your data, diagnose the performance of your models, and effectively communicate
    your findings.
  prefs: []
  type: TYPE_NORMAL
- en: Mastering these plots not only aids in understanding the data at hand but also
    in making sound decisions regarding model selection and hyper-parameter tuning.
    So, keep these visualisation tools handy, and let your machine learning story
    unfold.
  prefs: []
  type: TYPE_NORMAL
- en: '**Did you enjoy this post? For $5/month, you can become a member to unlock
    unlimited access to Medium. You will be directly supporting me and all your other
    favourite writers on Medium. So huge thanks for that!**'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://david-farrugia.medium.com/membership?source=post_page-----b5796ba73e8d--------------------------------)
    [## Join Medium with my referral link - David Farrugia'
  prefs: []
  type: TYPE_NORMAL
- en: Get exclusive access to all my ⚡premium⚡ content and all over Medium without
    limits. Support my work by buying me a…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: david-farrugia.medium.com](https://david-farrugia.medium.com/membership?source=post_page-----b5796ba73e8d--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Want to Get in Touch?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I would love to hear your thoughts on the topic, or anything AI and Data.
  prefs: []
  type: TYPE_NORMAL
- en: Drop me an email at ***davidfarrugia53@gmail.com*** should you wish to get in
    touch.
  prefs: []
  type: TYPE_NORMAL
- en: '[Linkedin](https://www.linkedin.com/in/david-farrugia/)'
  prefs: []
  type: TYPE_NORMAL
