- en: How to Train the LILT Model on Invoices and Run Inference
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-train-the-lilt-model-on-invoices-and-run-inference-8fd6b3cfae1b](https://towardsdatascience.com/how-to-train-the-lilt-model-on-invoices-and-run-inference-8fd6b3cfae1b)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A Step-by-Step Tutorial
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://walidamamou.medium.com/?source=post_page-----8fd6b3cfae1b--------------------------------)[![Walid
    Amamou](../Images/c5ae089c59a5ff070f0f90ad63ee3817.png)](https://walidamamou.medium.com/?source=post_page-----8fd6b3cfae1b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8fd6b3cfae1b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8fd6b3cfae1b--------------------------------)
    [Walid Amamou](https://walidamamou.medium.com/?source=post_page-----8fd6b3cfae1b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8fd6b3cfae1b--------------------------------)
    ·5 min read·Jan 3, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f78a852d92471c06d30e5522584f4505.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [**Zinkevych_D**](https://elements.envato.com/user/Zinkevych_D)from
    [Envanto](https://elements.envato.com/close-up-of-an-invoice-being-signed-HL7W2QD)
  prefs: []
  type: TYPE_NORMAL
- en: In the realm of document understanding, deep learning models have played a significant
    role. These models are able to accurately interpret the content and structure
    of documents, making them valuable tools for tasks such as invoice processing,
    resume parsing, and contract analysis. Another important benefit of deep learning
    models for document understanding is their ability to learn and adapt over time.
    As new types of documents are encountered, these models can continue to learn
    and improve their performance, making them highly scalable and efficient for tasks
    such as document classification and information extraction.
  prefs: []
  type: TYPE_NORMAL
- en: One of these models is the LILT model (Language-Independent Layout Transformer),
    a deep learning model developed for the task of document layout analysis. Unlike
    it’s layoutLM predecessor, LILT is originally designed to be language-independent,
    meaning it can analyze documents in any language while achieving superior performance
    compared to other existing models in many downstream tasks application. Furthermore,
    the model has the MIT license, which means it can be used commercially unlike
    the latest layoutLM v3 and layoutXLM. Therefore, it is worthwhile to create a
    tutorial on how to fine-tune this model as it has the potential to be widely used
    for a wide range of document understanding tasks.
  prefs: []
  type: TYPE_NORMAL
- en: In this tutorial, we will discuss this novel model architecture and show how
    to fine-tune it on invoice extraction. We will then use it to run inference on
    a new set of invoices.
  prefs: []
  type: TYPE_NORMAL
- en: 'LILT Model Architecture:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the key advantages of using the LILT model is its ability to handle multi-language
    document understanding with state-of-the-art performance. The authors achieved
    this by separating the text and layout embedding into their corresponding transformer
    architecture and using a bi-directional attention complementation mechanism (BiACM)
    to enable cross-modality interaction between the two types of data. The encoded
    text and layout features are then concatenated and additional heads are added,
    allowing the model to be used for either self-supervised pre-training or downstream
    fine-tuning. This approach is different from the layoutXLM model, which involves
    collecting and pre-processing a large dataset of multilingual documents.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/80a1dfef3ac7ef69893a1ca01e382149.png)'
  prefs: []
  type: TYPE_IMG
- en: LILT Model Architecture. [Source](https://arxiv.org/pdf/2202.13669.pdf)
  prefs: []
  type: TYPE_NORMAL
- en: The key novelty in this model is the use of the BiACM to capture the cross-interaction
    between the text and layout features during the encoding process. Simply concatenating
    the text and layout model output results in worse performance, suggesting that
    cross-interaction during the encoding pipeline is key to the success of this model.
    For more in-depth details, read the [original article](https://arxiv.org/pdf/2202.13669.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: 'Model Fine-tuning:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Similar to my previous articles on how to [fine-tune the layoutLM model](https://medium.com/towards-data-science/fine-tuning-layoutlm-v3-for-invoice-processing-e64f8d2c87cf),
    we will use the same dataset to fine-tune the LILT model. The data was obtained
    by manually labeling 220 invoices using [UBIAI](https://ubiai.tools) text annotation
    tool. More details about the labeling process can be found in this [link](https://medium.com/towards-data-science/how-to-annotate-pdfs-and-scanned-images-for-nlp-applications-f7b7b1db5c4a).
    For an in-depth video tutorial, checkout the link below:'
  prefs: []
  type: TYPE_NORMAL
- en: LILT Tutorial
  prefs: []
  type: TYPE_NORMAL
- en: 'To train the model, we first pre-pre-process the data output from UBIAI to
    get it ready for model training. These steps are the same as in the previous notebook
    training the layoutLM model, here is the notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://colab.research.google.com/drive/1RQwdD86PUfrsL2GAJkl2o-zAb0CjT1N1?usp=sharing&authuser=2&source=post_page-----8fd6b3cfae1b--------------------------------#scrollTo=iInYrU6DpD5p)
    [## Google Colaboratory'
  prefs: []
  type: TYPE_NORMAL
- en: Edit description
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: colab.research.google.com](https://colab.research.google.com/drive/1RQwdD86PUfrsL2GAJkl2o-zAb0CjT1N1?usp=sharing&authuser=2&source=post_page-----8fd6b3cfae1b--------------------------------#scrollTo=iInYrU6DpD5p)
  prefs: []
  type: TYPE_NORMAL
- en: 'We download the LILT model from Huggingface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'For this model training, we use the following hyperparameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To train the model, simply run trainer.train() command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cb180a75e6c077e3640da1a3545a721d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Model Training In Progress.'
  prefs: []
  type: TYPE_NORMAL
- en: 'On GPU, training takes approximately 1h. After training, we evaluate the model
    by running trainer.evaluate():'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We get a precision, recall and F-1 score of 0.63, 0.74 and 0.68 respectively.
    The LILT model evaluation F-1 score of 0.68 indicates that the model is performing
    well in terms of its ability to accurately classify and predict outcomes with
    a moderate to good accuracy. It is worth noting, however, that there is always
    room for improvement, and it is beneficial to continue labeling more data in order
    to further increase its performance. Overall, the LILT model evaluation F-1 score
    of 0.68 is a positive result and suggests that the model is performing well in
    its intended task.
  prefs: []
  type: TYPE_NORMAL
- en: In order to assess the model performance on unseen data, we run inference on
    a new invoice.
  prefs: []
  type: TYPE_NORMAL
- en: 'We make sure to save the model so we can use it for inference later on using
    this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Model Inference:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To test the model on a new invoice, we run the inference script below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://colab.research.google.com/drive/1om_xsTuuwOXzrldhkQj76HXSQkLYftRz?usp=sharing&source=post_page-----8fd6b3cfae1b--------------------------------)
    [## Google Colaboratory'
  prefs: []
  type: TYPE_NORMAL
- en: Edit description
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: colab.research.google.com](https://colab.research.google.com/drive/1om_xsTuuwOXzrldhkQj76HXSQkLYftRz?usp=sharing&source=post_page-----8fd6b3cfae1b--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'Below is the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b13a558feb2c6205e1b2c1356f2557a7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: LILT output on invoice 1'
  prefs: []
  type: TYPE_NORMAL
- en: 'The LILT model correctly identified a wide range of entities, including seller
    names, invoice numbers, and total amounts. Let’s try out a couple more invoices:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/50a46c6abf6d0520ca68f0e058cbaeb0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: LILT output on invoice 2'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9c92e307369f4cd2a32d2f48003c33f7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: LILT output on invoice 3'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the LILT model was able to handle a variety of different formats
    with different context with a relatively good accuracy although it made few mistakes.
    Overall, the LILT model performed well and its predictions were similar to those
    produced by layoutlm v3 highlighting its effectiveness for document understanding
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In conclusion, the LILT model has proven to be effective for document understanding
    tasks. Unlike the layoutLM v3 model, the LILT model is MIT licensed which allows
    for widespread commercial adoption and use by researchers and developers, making
    it a desirable choice for many projects. As a next step, we can improve the model
    performance by labeling and improving the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to efficiently and easily create your own training dataset, checkout
    [UBIAI’s OCR annotation feature](https://ubiai.tools/Signup) for free.
  prefs: []
  type: TYPE_NORMAL
- en: Follow us on Twitter [@UBIAI5](https://twitter.com/UBIAI5) or [subscribe here](https://walidamamou.medium.com/subscribe)!
  prefs: []
  type: TYPE_NORMAL
