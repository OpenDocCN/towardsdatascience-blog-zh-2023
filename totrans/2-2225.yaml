- en: Unlocking the Power of Text Data with LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åˆ©ç”¨LLMsè§£é”æ–‡æœ¬æ•°æ®çš„åŠ›é‡
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/unlocking-the-power-of-text-data-with-llms-3ddcd063274a](https://towardsdatascience.com/unlocking-the-power-of-text-data-with-llms-3ddcd063274a)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/unlocking-the-power-of-text-data-with-llms-3ddcd063274a](https://towardsdatascience.com/unlocking-the-power-of-text-data-with-llms-3ddcd063274a)
- en: DATA SCIENCE LAB
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ•°æ®ç§‘å­¦å®éªŒå®¤
- en: 'Learn how to handle text data with LLMs: a step-by-step guide for newbies'
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å­¦ä¹ å¦‚ä½•ä½¿ç”¨LLMså¤„ç†æ–‡æœ¬æ•°æ®ï¼šæ–°æ‰‹é€æ­¥æŒ‡å—
- en: '[](https://medium.com/@sofia-rosa?source=post_page-----3ddcd063274a--------------------------------)[![Sofia
    Rosa](../Images/fe74364da94c392f0eb99f7d528dba66.png)](https://medium.com/@sofia-rosa?source=post_page-----3ddcd063274a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3ddcd063274a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3ddcd063274a--------------------------------)
    [Sofia Rosa](https://medium.com/@sofia-rosa?source=post_page-----3ddcd063274a--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@sofia-rosa?source=post_page-----3ddcd063274a--------------------------------)[![Sofia
    Rosa](../Images/fe74364da94c392f0eb99f7d528dba66.png)](https://medium.com/@sofia-rosa?source=post_page-----3ddcd063274a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3ddcd063274a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3ddcd063274a--------------------------------)
    [Sofia Rosa](https://medium.com/@sofia-rosa?source=post_page-----3ddcd063274a--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3ddcd063274a--------------------------------)
    Â·11 min readÂ·Oct 23, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3ddcd063274a--------------------------------)
    Â·11åˆ†é’Ÿé˜…è¯»Â·2023å¹´10æœˆ23æ—¥
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/68220afffe74dde11a7fa11e5b938296.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/68220afffe74dde11a7fa11e5b938296.png)'
- en: Image generated by the author using Midjourney
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…ä½¿ç”¨Midjourneyç”Ÿæˆçš„å›¾åƒ
- en: Customer reviews, employee surveys, and social media posts can be incredibly
    powerful in **revealing peopleâ€™s attitudes** toward a specific product or service.
    However, most data analysts do very little with this type of data. *Why, you ask?*
    Generating insights from text data is **no easy task** and can leave even the
    most experienced data analysts scratching their heads for days.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: å®¢æˆ·è¯„è®ºã€å‘˜å·¥è°ƒæŸ¥å’Œç¤¾äº¤åª’ä½“å¸–å­åœ¨**æ­ç¤ºäººä»¬å¯¹ç‰¹å®šäº§å“æˆ–æœåŠ¡çš„æ€åº¦**æ–¹é¢å¯èƒ½éå¸¸æœ‰åŠ›ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°æ•°æ®åˆ†æå¸ˆå¯¹è¿™ç§ç±»å‹çš„æ•°æ®å‡ ä¹ä¸åšä»»ä½•å¤„ç†ã€‚*ä½ é—®ä¸ºä»€ä¹ˆï¼Ÿ*
    ä»æ–‡æœ¬æ•°æ®ä¸­ç”Ÿæˆè§è§£**å¹¶éæ˜“äº‹**ï¼Œå³ä½¿æ˜¯æœ€æœ‰ç»éªŒçš„æ•°æ®åˆ†æå¸ˆä¹Ÿå¯èƒ½ä¸ºæ­¤è‹¦æ¼æ•°å¤©ã€‚
- en: This is where Large Language Models (LLMs) come to the rescue. They can help
    carry out tasks such as translation, summarization, sentiment analysis, and much
    more. **But what is an LLM, exactly?** To simplify things, you can think of an
    LLM as a *parrot*. Just like a parrot repeats what it hears at home, an LLM imitates
    human language. A key difference is that LLMs have been trained on a huge volume
    of data â€” far beyond what a parrot would learn in its cage! This is why LLMs have
    the ability to generate coherent and contextually relevant text without the occasional
    nonsense of a parrot. ğŸ¦œ
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ´¾ä¸Šç”¨åœºçš„æ—¶å€™ã€‚å®ƒä»¬å¯ä»¥å¸®åŠ©æ‰§è¡Œç¿»è¯‘ã€æ€»ç»“ã€æƒ…æ„Ÿåˆ†æç­‰ä»»åŠ¡ã€‚**ä½†ç©¶ç«Ÿä»€ä¹ˆæ˜¯LLMï¼Ÿ** ç®€è€Œè¨€ä¹‹ï¼Œä½ å¯ä»¥æŠŠLLMæƒ³è±¡æˆä¸€åª*é¹¦é¹‰*ã€‚å°±åƒé¹¦é¹‰é‡å¤å®ƒåœ¨å®¶å¬åˆ°çš„ä¸œè¥¿ä¸€æ ·ï¼ŒLLMæ¨¡ä»¿äººç±»è¯­è¨€ã€‚ä¸€ä¸ªå…³é”®çš„åŒºåˆ«æ˜¯ï¼ŒLLMså·²ç»åœ¨å¤§é‡æ•°æ®ä¸Šè¿›è¡Œè¿‡è®­ç»ƒâ€”â€”è¿œè¿œè¶…è¿‡äº†é¹¦é¹‰åœ¨ç¬¼å­é‡Œèƒ½å­¦åˆ°çš„ä¸œè¥¿ï¼è¿™å°±æ˜¯LLMsèƒ½å¤Ÿç”Ÿæˆè¿è´¯ä¸”ä¸ä¸Šä¸‹æ–‡ç›¸å…³çš„æ–‡æœ¬ï¼Œè€Œä¸æ˜¯åƒé¹¦é¹‰é‚£æ ·å¶å°”è¯´äº›æ— ç¨½ä¹‹è°ˆçš„åŸå› ã€‚ğŸ¦œ
- en: In this article, weâ€™ll explore how LLMs work and how they make it **easier than
    ever** for data analysts to extract insights from text data. There are multiple
    LLMs now available via APIs, each with different capabilities and price points.
    Weâ€™ll be using GPT-3 via OpenAI API. At the time of writing, OpenAI charges for
    API usage based on the number of requests made and the number of tokens generated.
    The total cost for this tutorial amounted to $0.2.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨LLMså¦‚ä½•å·¥ä½œï¼Œä»¥åŠå®ƒä»¬å¦‚ä½•ä½¿æ•°æ®åˆ†æå¸ˆ**æ¯”ä»¥å¾€æ›´å®¹æ˜“**ä»æ–‡æœ¬æ•°æ®ä¸­æå–è§è§£ã€‚ç›®å‰æœ‰å¤šç§LLMsé€šè¿‡APIæä¾›ï¼Œæ¯ç§LLMå…·æœ‰ä¸åŒçš„åŠŸèƒ½å’Œä»·æ ¼ã€‚æˆ‘ä»¬å°†ä½¿ç”¨OpenAI
    APIä¸­çš„GPT-3ã€‚åœ¨æ’°å†™æ—¶ï¼ŒOpenAIæ ¹æ®è¯·æ±‚æ¬¡æ•°å’Œç”Ÿæˆçš„ä»¤ç‰Œæ•°é‡æ”¶è´¹ã€‚æ­¤æ¬¡æ•™ç¨‹çš„æ€»è´¹ç”¨ä¸º$0.2ã€‚
- en: Time to dig in!
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨å¼€å§‹æ·±å…¥æ¢ç´¢å§ï¼
- en: Table of Contents
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç›®å½•
- en: 'â–¹ [Step 1: Downloading the Data](#9da9)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: â–¹ [ç¬¬1æ­¥ï¼šä¸‹è½½æ•°æ®](#9da9)
- en: 'â–¹ [Step 2: Reading the Data](#4faf)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: â–¹ [ç¬¬2æ­¥ï¼šè¯»å–æ•°æ®](#4faf)
- en: 'â–¹ [Step 3: Data Pre-Processing](#6da6)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: â–¹ [ç¬¬3æ­¥ï¼šæ•°æ®é¢„å¤„ç†](#6da6)
- en: 'â–¹ [Step 3a: Dealing with NaN Values](#185d)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: â–¹ [ç¬¬3aæ­¥ï¼šå¤„ç†NaNå€¼](#185d)
- en: 'â–¹ [Step 3b: Transforming Text for GPT-3](#3fc1)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: â–¹ [ç¬¬3bæ­¥ï¼šä¸ºGPT-3è½¬æ¢æ–‡æœ¬](#3fc1)
- en: 'â–¹ [Step 3c: Counting Tokens](#dcd3)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: â–¹ [ç¬¬3cæ­¥ï¼šè®¡ç®—ä»¤ç‰Œ](#dcd3)
- en: 'â–¹ [Step 4: Setting Up an OpenAI Account](#078a)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: â–¹ [ç¬¬4æ­¥ï¼šè®¾ç½®OpenAIè´¦æˆ·](#078a)
- en: 'â–¹ [Step 5: Working with GPT-3](#d5e3)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: â–¹ [ç¬¬ 5 æ­¥ï¼šä½¿ç”¨ GPT-3](#d5e3)
- en: 'â–¹ [Step 6: Summarizing the Results](#7746)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: â–¹ [ç¬¬ 6 æ­¥ï¼šæ€»ç»“ç»“æœ](#7746)
- en: Prerequisites
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å…ˆå†³æ¡ä»¶
- en: 'To follow along in this tutorial, you will need to have the following:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è·Ÿéšæœ¬æ•™ç¨‹ï¼Œä½ éœ€è¦å…·å¤‡ä»¥ä¸‹å†…å®¹ï¼š
- en: Working knowledge of Python
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python çš„åŸºç¡€çŸ¥è¯†
- en: Python 3 environment
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3 ç¯å¢ƒ
- en: OpenAI API key (*see step 4*)
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI API å¯†é’¥ï¼ˆ*è§ç¬¬ 4 æ­¥*ï¼‰
- en: 'Step 1: Downloading the Data'
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€æ­¥ï¼šä¸‹è½½æ•°æ®
- en: The dataset weâ€™ll use is an industry-wide survey conducted by [Kaggle](https://www.kaggle.com/datasets/kaggle/kaggle-survey-2017)
    in 2017 aimed at uncovering new trends in machine learning and data science. For
    this tutorial, weâ€™ll only be using the **freeformResponses** csv file, which contains
    open-ended answers to Kaggleâ€™s questions.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨çš„æ•°æ®é›†æ˜¯ [Kaggle](https://www.kaggle.com/datasets/kaggle/kaggle-survey-2017)
    åœ¨ 2017 å¹´è¿›è¡Œçš„ä¸€é¡¹è¡Œä¸šè°ƒæŸ¥ï¼Œæ—¨åœ¨æ­ç¤ºæœºå™¨å­¦ä¹ å’Œæ•°æ®ç§‘å­¦çš„æ–°è¶‹åŠ¿ã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä»…ä½¿ç”¨ **freeformResponses** csv æ–‡ä»¶ï¼Œè¯¥æ–‡ä»¶åŒ…å«å¯¹
    Kaggle é—®é¢˜çš„å¼€æ”¾å¼å›ç­”ã€‚
- en: '![](../Images/41572fcfc0635ecc0dcf149d13da712e.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/41572fcfc0635ecc0dcf149d13da712e.png)'
- en: Snippet of the freeformResponses csv file
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: freeformResponses csv æ–‡ä»¶çš„ç‰‡æ®µ
- en: 'Step 2: Reading the Data'
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬äºŒæ­¥ï¼šè¯»å–æ•°æ®
- en: Next, weâ€™ll read the csv file into a dataframe and focus on the column â€œ**PersonalProjectsChallengeFreeForm**â€.
    This column contains challenges people face when using public datasets for their
    personal projects. Kaggle, as a platform for data science and machine learning,
    can use these insights to improve its services (e.g., by developing relevant content,
    tutorials, and resources that specifically address these challenges).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æŠŠ csv æ–‡ä»¶è¯»å–åˆ°æ•°æ®æ¡†ä¸­ï¼Œå¹¶é‡ç‚¹å…³æ³¨â€œ**PersonalProjectsChallengeFreeForm**â€åˆ—ã€‚è¯¥åˆ—åŒ…å«äººä»¬åœ¨ä½¿ç”¨å…¬å…±æ•°æ®é›†è¿›è¡Œä¸ªäººé¡¹ç›®æ—¶é¢ä¸´çš„æŒ‘æˆ˜ã€‚ä½œä¸ºæ•°æ®ç§‘å­¦å’Œæœºå™¨å­¦ä¹ å¹³å°ï¼ŒKaggle
    å¯ä»¥åˆ©ç”¨è¿™äº›è§è§£æ¥æ”¹è¿›å…¶æœåŠ¡ï¼ˆä¾‹å¦‚ï¼Œé€šè¿‡å¼€å‘ç›¸å…³å†…å®¹ã€æ•™ç¨‹å’Œä¸“é—¨è§£å†³è¿™äº›æŒ‘æˆ˜çš„èµ„æºï¼‰ã€‚
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/67c1d6d1a364e3c77d43d5429f108e74.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/67c1d6d1a364e3c77d43d5429f108e74.png)'
- en: Output
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡º
- en: 'Step 3: Data Pre-Processing'
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬ä¸‰æ­¥ï¼šæ•°æ®é¢„å¤„ç†
- en: Data pre-processing involves a series of steps to clean and prepare the data
    for analysis. GPT-3 can handle relatively clean and structured text data without
    the need for extensive pre-processing. However, for complex or non-standard data,
    some extra pre-processing may be necessary to ensure the best results when leveraging
    GPT-3\. This is something to keep in mind if your text contains multiple languages,
    spelling errors, or domain-specific terms.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®é¢„å¤„ç†æ¶‰åŠä¸€ç³»åˆ—æ­¥éª¤ï¼Œä»¥æ¸…ç†å’Œå‡†å¤‡æ•°æ®ä»¥è¿›è¡Œåˆ†æã€‚GPT-3 å¯ä»¥å¤„ç†ç›¸å¯¹å¹²å‡€å’Œç»“æ„åŒ–çš„æ–‡æœ¬æ•°æ®ï¼Œè€Œæ— éœ€ extensive é¢„å¤„ç†ã€‚ç„¶è€Œï¼Œå¯¹äºå¤æ‚æˆ–éæ ‡å‡†çš„æ•°æ®ï¼Œå¯èƒ½éœ€è¦ä¸€äº›é¢å¤–çš„é¢„å¤„ç†ï¼Œä»¥ç¡®ä¿åœ¨åˆ©ç”¨
    GPT-3 æ—¶è·å¾—æœ€ä½³ç»“æœã€‚å¦‚æœä½ çš„æ–‡æœ¬åŒ…å«å¤šç§è¯­è¨€ã€æ‹¼å†™é”™è¯¯æˆ–é¢†åŸŸç‰¹å®šæœ¯è¯­ï¼Œéœ€è¦ç‰¹åˆ«æ³¨æ„è¿™ä¸€ç‚¹ã€‚
- en: '**Step 3a: Dealing with NaN Values**'
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç¬¬ 3a æ­¥ï¼šå¤„ç† NaN å€¼**'
- en: Weâ€™ll start by dealing with NaN (Not A Number) values. NaN values represent
    missing or undefined values with very distinct properties, making it important
    to detect them early on using the `isna()` function. Once identified, we can take
    appropriate measures to handle them effectively.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†é¦–å…ˆå¤„ç† NaNï¼ˆéæ•°å­—ï¼‰å€¼ã€‚NaN å€¼è¡¨ç¤ºç¼ºå¤±æˆ–æœªå®šä¹‰çš„å€¼ï¼Œå…·æœ‰éå¸¸ç‹¬ç‰¹çš„å±æ€§ï¼Œå› æ­¤åœ¨æ—©æœŸä½¿ç”¨ `isna()` å‡½æ•°æ£€æµ‹å®ƒä»¬æ˜¯å¾ˆé‡è¦çš„ã€‚ä¸€æ—¦è¯†åˆ«å‡ºè¿™äº›å€¼ï¼Œæˆ‘ä»¬å¯ä»¥é‡‡å–é€‚å½“çš„æªæ–½æœ‰æ•ˆåœ°å¤„ç†å®ƒä»¬ã€‚
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/875549df74f51394a4397baefe276963.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/875549df74f51394a4397baefe276963.png)'
- en: Output
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡º
- en: There are 13,214 NaN values (80% of all responses!), meaning that these people
    did not provide an answer to the question. The simplest approach is to remove
    all the entries that contain NaN values using the `dropna()` function. However,
    depending on your specific use case, you might prefer to handle NaN values differently,
    such as by replacing them with specific values.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰ 13,214 ä¸ª NaN å€¼ï¼ˆå æ‰€æœ‰å“åº”çš„ 80%ï¼ï¼‰ï¼Œè¿™æ„å‘³ç€è¿™äº›äººæ²¡æœ‰å›ç­”é—®é¢˜ã€‚æœ€ç®€å•çš„æ–¹æ³•æ˜¯ä½¿ç”¨ `dropna()` å‡½æ•°åˆ é™¤æ‰€æœ‰åŒ…å« NaN
    å€¼çš„æ¡ç›®ã€‚ç„¶è€Œï¼Œæ ¹æ®ä½ çš„å…·ä½“ä½¿ç”¨æƒ…å†µï¼Œä½ å¯èƒ½æ›´æ„¿æ„ä»¥å…¶ä»–æ–¹å¼å¤„ç† NaN å€¼ï¼Œä¾‹å¦‚é€šè¿‡ç”¨ç‰¹å®šå€¼æ›¿æ¢å®ƒä»¬ã€‚
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/0a874a59394c34dcfad442f6f3ce3cc6.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0a874a59394c34dcfad442f6f3ce3cc6.png)'
- en: Output
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡º
- en: For demo purposes, weâ€™ll work with only the first 500 (non-null) responses from
    the survey.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæ¼”ç¤ºç›®çš„ï¼Œæˆ‘ä»¬å°†ä»…ä½¿ç”¨è°ƒæŸ¥ä¸­çš„å‰ 500 æ¡ï¼ˆéç©ºï¼‰å“åº”ã€‚
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Step 3b: Transforming Text for GPT-3**'
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç¬¬ 3b æ­¥ï¼šä¸º GPT-3 è½¬æ¢æ–‡æœ¬**'
- en: Next, weâ€™ll transform the text data into a format suitable for GPT-3\. Weâ€™ll
    extract all the values from the â€œ**PersonalProjectsChallengeFreeForm**â€ column
    and store them in the â€œ**challenges**â€ list. This transformation begins with the
    use of the `squeeze()` function, which converts the dataframe into a pandas series.
    Subsequently, the `tolist()` function converts this series into a list.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æŠŠæ–‡æœ¬æ•°æ®è½¬æ¢ä¸ºé€‚åˆGPT-3çš„æ ¼å¼ã€‚æˆ‘ä»¬å°†ä»â€œ**PersonalProjectsChallengeFreeForm**â€åˆ—ä¸­æå–æ‰€æœ‰å€¼ï¼Œå¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨â€œ**challenges**â€åˆ—è¡¨ä¸­ã€‚è¿™ä¸€è½¬æ¢ä»ä½¿ç”¨`
    squeeze()`å‡½æ•°å¼€å§‹ï¼Œè¯¥å‡½æ•°å°†æ•°æ®æ¡†è½¬æ¢ä¸ºpandasç³»åˆ—ã€‚éšåï¼Œ`tolist()`å‡½æ•°å°†è¿™ä¸ªç³»åˆ—è½¬æ¢ä¸ºåˆ—è¡¨ã€‚
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/a171aaf6a16d20293a9be13953e7a3d2.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a171aaf6a16d20293a9be13953e7a3d2.png)'
- en: Output
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡º
- en: In this example, â€œ**challenges**â€ is a list where each element represents a
    response from the original survey. Weâ€™ll provide this text as input to GPT-3.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œâ€œ**challenges**â€æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ ä»£è¡¨åŸå§‹è°ƒæŸ¥çš„ä¸€ä¸ªå›åº”ã€‚æˆ‘ä»¬å°†æŠŠè¿™ä¸ªæ–‡æœ¬ä½œä¸ºè¾“å…¥æä¾›ç»™GPT-3ã€‚
- en: 'Step 3c: Counting Tokens'
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¬¬3cæ­¥ï¼šè®¡ç®—tokens
- en: 'Our text is almost ready for GPT-3\. Before we proceed, itâ€™s important that
    we understand how GPT-3 works with text. Initially, it performs **tokenization**,
    which involves splitting the text into smaller units known as *tokens*. Tokens
    are units of text, such as sentences, words, numbers, or even punctuation marks.
    For example, the phrase â€œ**hello friend!**â€ can be split into three tokens: â€œ**hello**â€,
    â€œ **friend**â€ and â€œ**!**â€.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„æ–‡æœ¬å‡ ä¹å‡†å¤‡å¥½ç”¨äºGPT-3äº†ã€‚åœ¨æˆ‘ä»¬ç»§ç»­ä¹‹å‰ï¼Œäº†è§£GPT-3å¦‚ä½•å¤„ç†æ–‡æœ¬æ˜¯å¾ˆé‡è¦çš„ã€‚æœ€åˆï¼Œå®ƒæ‰§è¡Œ**åˆ†è¯**ï¼Œè¿™æ¶‰åŠå°†æ–‡æœ¬æ‹†åˆ†æˆç§°ä¸º*tokens*çš„æ›´å°å•å…ƒã€‚Tokensæ˜¯æ–‡æœ¬å•å…ƒï¼Œä¾‹å¦‚å¥å­ã€å•è¯ã€æ•°å­—ï¼Œç”šè‡³æ ‡ç‚¹ç¬¦å·ã€‚ä¾‹å¦‚ï¼ŒçŸ­è¯­â€œ**hello
    friend!**â€å¯ä»¥æ‹†åˆ†ä¸ºä¸‰ä¸ªtokensï¼šâ€œ**hello**â€ã€â€œ**friend**â€å’Œâ€œ**!**â€ã€‚
- en: '![](../Images/5d87ea48d166eb2b3e14498d29a7bc3c.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d87ea48d166eb2b3e14498d29a7bc3c.png)'
- en: Example of tokenization
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†è¯ç¤ºä¾‹
- en: 'After tokenization, GPT-3 proceeds to **encoding**, which means it converts
    these tokens into token numbers. In our example, the three tokens â€œhelloâ€, â€œ friendâ€
    and â€œ!â€ can be converted into three token numbers: â€œ**15339**â€, â€œ **4333**â€ and
    â€œ**0**â€.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åˆ†è¯ä¹‹åï¼ŒGPT-3ç»§ç»­è¿›è¡Œ**ç¼–ç **ï¼Œè¿™æ„å‘³ç€å®ƒå°†è¿™äº›tokensè½¬æ¢ä¸ºtokenæ•°å­—ã€‚åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œä¸‰ä¸ªtokensâ€œhelloâ€ã€â€œ friendâ€å’Œâ€œ!â€å¯ä»¥è½¬æ¢ä¸ºä¸‰ä¸ªtokenæ•°å­—ï¼šâ€œ**15339**â€ã€â€œ**4333**â€å’Œâ€œ**0**â€ã€‚
- en: '![](../Images/41e738312bfeae289cab399a8f7ded85.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/41e738312bfeae289cab399a8f7ded85.png)'
- en: Example of encoding
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼–ç ç¤ºä¾‹
- en: By determining the number of tokens in our text, weâ€™ll know whether the text
    is too long for the model to process as well as how much an OpenAI API call will
    cost (as API calls are billed based on the number of tokens sent in your input
    plus the number of tokens that GPT returns in the output).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ç¡®å®šæ–‡æœ¬ä¸­çš„tokensæ•°é‡ï¼Œæˆ‘ä»¬å°†çŸ¥é“æ–‡æœ¬æ˜¯å¦è¿‡é•¿è€Œæ— æ³•è¢«æ¨¡å‹å¤„ç†ï¼Œä»¥åŠOpenAI APIè°ƒç”¨çš„è´¹ç”¨ï¼ˆAPIè°ƒç”¨çš„è´¹ç”¨æ˜¯æ ¹æ®è¾“å…¥ä¸­å‘é€çš„tokensæ•°é‡ä»¥åŠGPTè¿”å›çš„tokensæ•°é‡æ¥è®¡è´¹çš„ï¼‰ã€‚
- en: To do this, weâ€™ll install a library called `tiktoken` and import the necessary
    module `encoding_for_model`. Since different LLMs use different methods for encoding
    text, weâ€™ll need to specify the model weâ€™ll be using, which is â€œ**gpt-3.5-turbo-16k**â€.
    For each sentence, weâ€™ll then tokenize and encode the text.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†å®‰è£…ä¸€ä¸ªåä¸º`tiktoken`çš„åº“ï¼Œå¹¶å¯¼å…¥å¿…è¦çš„æ¨¡å—`encoding_for_model`ã€‚ç”±äºä¸åŒçš„LLMä½¿ç”¨ä¸åŒçš„æ–¹æ³•å¯¹æ–‡æœ¬è¿›è¡Œç¼–ç ï¼Œæˆ‘ä»¬éœ€è¦æŒ‡å®šæˆ‘ä»¬å°†ä½¿ç”¨çš„æ¨¡å‹ï¼Œå³â€œ**gpt-3.5-turbo-16k**â€ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†å¯¹æ¯ä¸ªå¥å­è¿›è¡Œåˆ†è¯å’Œç¼–ç ã€‚
- en: '[PRE5]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/2b234c7df476c123b2c699fe72675fa6.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2b234c7df476c123b2c699fe72675fa6.png)'
- en: Output
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡º
- en: The last step is to count the tokens, which can be accomplished by determining
    the length of the list â€œ**num_tokens**â€.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åä¸€æ­¥æ˜¯è®¡ç®—tokensï¼Œè¿™å¯ä»¥é€šè¿‡ç¡®å®šåˆ—è¡¨â€œ**num_tokens**â€çš„é•¿åº¦æ¥å®Œæˆã€‚
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/33a8968b910758874a33ed159bbed6ea.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/33a8968b910758874a33ed159bbed6ea.png)'
- en: Output
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡º
- en: To estimate the total cost based on our input, we can refer to [the pricing
    documentation](https://openai.com/pricing). In our case, 4629 tokens would translate
    to a cost of $0.01.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æ ¹æ®æˆ‘ä»¬çš„è¾“å…¥ä¼°ç®—æ€»è´¹ç”¨ï¼Œæˆ‘ä»¬å¯ä»¥å‚è€ƒ[å®šä»·æ–‡æ¡£](https://openai.com/pricing)ã€‚åœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹ï¼Œ4629ä¸ªtokenså°†è½¬æ¢ä¸º0.01ç¾å…ƒçš„è´¹ç”¨ã€‚
- en: 'Step 4: Setting Up an OpenAI Account'
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬4æ­¥ï¼šè®¾ç½®OpenAIè´¦æˆ·
- en: Our text is finally ready for GPT-3 (weâ€™re getting closer to the good stuff!).
    To work with GPT-3, weâ€™ll be using the OpenAI API. Make sure that you have an
    OpenAI account set up to access the OpenAI API. If you donâ€™t already have an account,
    follow the steps below to create one.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„æ–‡æœ¬ç»ˆäºå‡†å¤‡å¥½ç”¨äºGPT-3äº†ï¼ˆæˆ‘ä»¬ç¦»å¥½ä¸œè¥¿è¶Šæ¥è¶Šè¿‘äº†ï¼ï¼‰ã€‚è¦ä½¿ç”¨GPT-3ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨OpenAI APIã€‚ç¡®ä¿ä½ å·²ç»è®¾ç½®äº†OpenAIè´¦æˆ·ä»¥è®¿é—®OpenAI
    APIã€‚å¦‚æœä½ è¿˜æ²¡æœ‰è´¦æˆ·ï¼Œè¯·æŒ‰ç…§ä¸‹é¢çš„æ­¥éª¤åˆ›å»ºä¸€ä¸ªã€‚
- en: To kick things off, head to the [OpenAI](http://platform.openai.com) website
    and click on the â€œ**Sign Up**â€ button in the top right corner of the page. Fill
    in the form with your email address, create a password, and provide any other
    necessary info. Then, hit the â€œ**Create Account**â€ button. Keep an eye on your
    inbox as youâ€™ll receive a confirmation email. Click the link in the email to verify
    your account. Once thatâ€™s done, youâ€™re all set to log in.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œè®¿é—® [OpenAI](http://platform.openai.com) ç½‘ç«™ï¼Œå¹¶ç‚¹å‡»é¡µé¢å³ä¸Šè§’çš„â€œ**æ³¨å†Œ**â€æŒ‰é’®ã€‚å¡«å†™è¡¨å•ï¼Œè¾“å…¥ä½ çš„ç”µå­é‚®ä»¶åœ°å€ï¼Œåˆ›å»ºä¸€ä¸ªå¯†ç ï¼Œå¹¶æä¾›å…¶ä»–å¿…è¦çš„ä¿¡æ¯ã€‚ç„¶åï¼Œç‚¹å‡»â€œ**åˆ›å»ºè´¦æˆ·**â€æŒ‰é’®ã€‚è¯·ç•™æ„ä½ çš„æ”¶ä»¶ç®±ï¼Œä½ ä¼šæ”¶åˆ°ä¸€å°ç¡®è®¤é‚®ä»¶ã€‚ç‚¹å‡»é‚®ä»¶ä¸­çš„é“¾æ¥æ¥éªŒè¯ä½ çš„è´¦æˆ·ã€‚å®Œæˆè¿™äº›æ­¥éª¤åï¼Œä½ å°±å¯ä»¥ç™»å½•äº†ã€‚
- en: With your account created, the next step is funding it. Remember, as you use
    the API, youâ€™ll be billed for your usage. Simply go to â€œ**Manage Account**â€ and
    find the â€œ**Billing**â€ tab. There, you can add your payment card details and specify
    the initial amount you want to put in your account.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: è´¦æˆ·åˆ›å»ºåï¼Œä¸‹ä¸€æ­¥æ˜¯ä¸ºå…¶å……å€¼ã€‚è¯·è®°ä½ï¼Œåœ¨ä½¿ç”¨ API æ—¶ï¼Œä½ ä¼šä¸ºä½¿ç”¨é‡ä»˜è´¹ã€‚åªéœ€å‰å¾€â€œ**ç®¡ç†è´¦æˆ·**â€å¹¶æ‰¾åˆ°â€œ**è´¦å•**â€æ ‡ç­¾ã€‚åœ¨é‚£é‡Œï¼Œä½ å¯ä»¥æ·»åŠ ä½ çš„æ”¯ä»˜å¡è¯¦ç»†ä¿¡æ¯ï¼Œå¹¶æŒ‡å®šä½ å¸Œæœ›åœ¨è´¦æˆ·ä¸­å­˜å…¥çš„åˆå§‹é‡‘é¢ã€‚
- en: The final important step is to generate your API Key, which serves as a private
    access key to the API. You can create it in the â€œ**API Keys**â€ tab. Keep this
    key safe because it canâ€™t be recovered if lost. However, if it slips through the
    cracks, you do have the option to create a new one.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ç»ˆçš„é‡è¦æ­¥éª¤æ˜¯ç”Ÿæˆä½ çš„ API å¯†é’¥ï¼Œå®ƒä½œä¸ºå¯¹ API çš„ç§å¯†è®¿é—®å¯†é’¥ã€‚ä½ å¯ä»¥åœ¨â€œ**API å¯†é’¥**â€æ ‡ç­¾ä¸­åˆ›å»ºå®ƒã€‚è¯·å¦¥å–„ä¿ç®¡æ­¤å¯†é’¥ï¼Œå› ä¸ºå¦‚æœä¸¢å¤±æ— æ³•æ¢å¤ã€‚ä¸è¿‡ï¼Œå¦‚æœä¸å¹¸ä¸¢å¤±ï¼Œä½ å¯ä»¥é€‰æ‹©åˆ›å»ºä¸€ä¸ªæ–°çš„å¯†é’¥ã€‚
- en: 'Step 5: Working with GPT-3'
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬ 5 æ­¥ï¼šä½¿ç”¨ GPT-3
- en: Now that we have access to GPT-3 through the OpenAI API, we can send a request
    containing the input and API key. In return, weâ€™ll get a response containing the
    GPT-3 output.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»é€šè¿‡ OpenAI API è®¿é—®äº† GPT-3ï¼Œæˆ‘ä»¬å¯ä»¥å‘é€åŒ…å«è¾“å…¥å’Œ API å¯†é’¥çš„è¯·æ±‚ã€‚ä½œä¸ºå›æŠ¥ï¼Œæˆ‘ä»¬å°†è·å¾—åŒ…å« GPT-3 è¾“å‡ºçš„å“åº”ã€‚
- en: '![](../Images/82f40db52b0c5e1a5f1156a2861255ee.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/82f40db52b0c5e1a5f1156a2861255ee.png)'
- en: Using GPT-3 via the OpenAI API
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ GPT-3 é€šè¿‡ OpenAI API
- en: First, weâ€™ll install a library called `openai`. Then, weâ€™ll set up the API key
    to authenticate our requests.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬å°†å®‰è£…ä¸€ä¸ªåä¸º `openai` çš„åº“ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†è®¾ç½® API å¯†é’¥ä»¥éªŒè¯æˆ‘ä»¬çš„è¯·æ±‚ã€‚
- en: '[PRE7]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Weâ€™ll send our text to GPT-3 and ask it to summarise the main topics, which
    are then stored in the â€œ**response**â€ variable.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æ–‡æœ¬å‘é€ç»™ GPT-3 å¹¶è¦æ±‚å…¶æ€»ç»“ä¸»è¦è¯é¢˜ï¼Œè¿™äº›è¯é¢˜éšåå­˜å‚¨åœ¨â€œ**response**â€å˜é‡ä¸­ã€‚
- en: 'ğŸ’¡ **Note**: *This code is a simplified example, and you can adapt it for various
    tasks by adjusting the user message and system message according to your specific
    needs.*'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ’¡ **æ³¨æ„**ï¼š*è¿™æ®µä»£ç æ˜¯ä¸€ä¸ªç®€åŒ–çš„ç¤ºä¾‹ï¼Œä½ å¯ä»¥æ ¹æ®å…·ä½“éœ€æ±‚è°ƒæ•´ç”¨æˆ·æ¶ˆæ¯å’Œç³»ç»Ÿæ¶ˆæ¯ï¼Œä»¥é€‚åº”å„ç§ä»»åŠ¡ã€‚*
- en: '[PRE8]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Letâ€™s go through the code step by step:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä¸€æ­¥æ­¥åˆ†æä»£ç ï¼š
- en: '`response = ai.ChatCompletion.create(`: This line initiates a request to GPT-3
    and assigns the response to the variable â€œ**response**â€.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`response = ai.ChatCompletion.create(`ï¼šè¿™ä¸€è¡Œå‘èµ·ä¸€ä¸ªè¯·æ±‚åˆ° GPT-3ï¼Œå¹¶å°†å“åº”èµ‹å€¼ç»™å˜é‡â€œ**response**â€ã€‚'
- en: '`model = ''gpt-3.5-turbo-16k''`: This parameter specifies which GPT-3 model
    to use.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model = ''gpt-3.5-turbo-16k''`ï¼šè¿™ä¸ªå‚æ•°æŒ‡å®šä½¿ç”¨å“ªä¸ª GPT-3 æ¨¡å‹ã€‚'
- en: '`messages = [ ... ]`: This section defines a list of messages for which GPT-3
    will create a response. Each message has a role (e.g., system or user) and content.
    The system message helps set the *behavior* of GPT-3\. For example, we can say:
    â€œYouâ€™re a helpful assistant. Your task is to analyze a set of reviewsâ€. The user
    message, on the other hand, provides *instructions* for the task. For example,
    we can say: â€œBelow is a set of reviews. Please, identify the main topics mentioned
    in these commentsâ€.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`messages = [ ... ]`ï¼šè¿™ä¸€éƒ¨åˆ†å®šä¹‰äº†ä¸€ç³»åˆ—æ¶ˆæ¯ï¼ŒGPT-3 å°†ä¸ºè¿™äº›æ¶ˆæ¯ç”Ÿæˆå“åº”ã€‚æ¯æ¡æ¶ˆæ¯éƒ½æœ‰ä¸€ä¸ªè§’è‰²ï¼ˆä¾‹å¦‚ç³»ç»Ÿæˆ–ç”¨æˆ·ï¼‰å’Œå†…å®¹ã€‚ç³»ç»Ÿæ¶ˆæ¯æœ‰åŠ©äºè®¾ç½®
    GPT-3 çš„*è¡Œä¸º*ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥è¯´ï¼šâ€œä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æä¸€ç»„è¯„è®ºâ€ã€‚è€Œç”¨æˆ·æ¶ˆæ¯åˆ™æä¾›*æŒ‡ç¤º*ä»¥å®Œæˆä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥è¯´ï¼šâ€œä¸‹é¢æ˜¯ä¸€ç»„è¯„è®ºã€‚è¯·è¯†åˆ«è¿™äº›è¯„è®ºä¸­æåˆ°çš„ä¸»è¦è¯é¢˜â€ã€‚'
- en: '`temperature = 0`: This parameter influences the randomness of the responses.
    You can think of it as a way to control how creative and unpredictable the responses
    are. Setting it to 0 means that youâ€™ll get the same output every time you ask,
    almost like a broken record. On the other hand, setting it to a higher value (e.g.,
    0.8) means that youâ€™ll get a fresh output.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`temperature = 0`ï¼šè¿™ä¸ªå‚æ•°å½±å“å“åº”çš„éšæœºæ€§ã€‚ä½ å¯ä»¥å°†å…¶è§†ä¸ºæ§åˆ¶å“åº”çš„åˆ›æ„æ€§å’Œä¸å¯é¢„æµ‹æ€§çš„æ–¹å¼ã€‚å°†å…¶è®¾ç½®ä¸º 0 æ„å‘³ç€ä½ æ¯æ¬¡æé—®éƒ½ä¼šå¾—åˆ°ç›¸åŒçš„è¾“å‡ºï¼Œå‡ ä¹åƒæ˜¯åæ‰çš„å”±ç‰‡ã€‚å¦ä¸€æ–¹é¢ï¼Œå°†å…¶è®¾ç½®ä¸ºè¾ƒé«˜çš„å€¼ï¼ˆä¾‹å¦‚
    0.8ï¼‰åˆ™æ„å‘³ç€ä½ å°†è·å¾—æ–°çš„è¾“å‡ºã€‚'
- en: '`max_tokens = 6000`: This parameter specifies the maximum number of tokens
    the response can contain. Setting it to 6000 ensures that the response doesn''t
    exceed this length. If the response exceeds this limit, it will be truncated.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_tokens = 6000`ï¼šæ­¤å‚æ•°æŒ‡å®šäº†å“åº”å¯ä»¥åŒ…å«çš„æœ€å¤§ä»¤ç‰Œæ•°ã€‚å°†å…¶è®¾ç½®ä¸º6000å¯ç¡®ä¿å“åº”ä¸ä¼šè¶…è¿‡æ­¤é•¿åº¦ã€‚å¦‚æœå“åº”è¶…å‡ºæ­¤é™åˆ¶ï¼Œå®ƒå°†è¢«æˆªæ–­ã€‚'
- en: After receiving a response from GPT-3, weâ€™ll return the content (excluding any
    additional meta-information).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ”¶åˆ°GPT-3çš„å“åº”åï¼Œæˆ‘ä»¬å°†è¿”å›å†…å®¹ï¼ˆä¸åŒ…æ‹¬ä»»ä½•é¢å¤–çš„å…ƒä¿¡æ¯ï¼‰ã€‚
- en: '[PRE9]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'GPT-3 returned five topics:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3è¿”å›äº†äº”ä¸ªè¯é¢˜ï¼š
- en: 'â€œ**1\. Data cleaning and preparation**: Many reviews mention the challenge
    of cleaning and preparing the data for analysis. This includes dealing with missing
    values, formatting issues, unstructured data, and the need for data wrangling.'
  id: totrans-96
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**1\. æ•°æ®æ¸…ç†å’Œå‡†å¤‡**ï¼šè®¸å¤šè¯„è®ºæåˆ°æ¸…ç†å’Œå‡†å¤‡æ•°æ®è¿›è¡Œåˆ†æçš„æŒ‘æˆ˜ã€‚è¿™åŒ…æ‹¬å¤„ç†ç¼ºå¤±å€¼ã€æ ¼å¼é—®é¢˜ã€éç»“æ„åŒ–æ•°æ®å’Œæ•°æ®æ•´ç†çš„éœ€æ±‚ã€‚'
- en: ''
  id: totrans-97
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**2\. Data quality and documentation**: Several reviews highlight the poor
    quality of the data, including lack of documentation, incorrect documentation,
    and unreliable data. Issues with data completeness, accuracy, and reliability
    are also mentioned.'
  id: totrans-98
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**2\. æ•°æ®è´¨é‡å’Œæ–‡æ¡£**ï¼šä¸€äº›è¯„è®ºå¼ºè°ƒäº†æ•°æ®è´¨é‡å·®çš„é—®é¢˜ï¼ŒåŒ…æ‹¬ç¼ºä¹æ–‡æ¡£ã€ä¸æ­£ç¡®çš„æ–‡æ¡£å’Œä¸å¯é çš„æ•°æ®ã€‚è¿˜æåˆ°äº†æ•°æ®å®Œæ•´æ€§ã€å‡†ç¡®æ€§å’Œå¯é æ€§çš„é—®é¢˜ã€‚'
- en: ''
  id: totrans-99
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**3\. Finding and accessing relevant datasets**: Many reviewers express difficulties
    in finding the right datasets for their projects. This includes challenges in
    finding datasets that match specific requirements, lack of availability, limited
    size or relevance of public datasets, and the need to collect personal data.'
  id: totrans-100
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**3\. å¯»æ‰¾å’Œè®¿é—®ç›¸å…³æ•°æ®é›†**ï¼šè®¸å¤šè¯„è®ºè€…è¡¨è¾¾äº†åœ¨ä¸ºä»–ä»¬çš„é¡¹ç›®å¯»æ‰¾åˆé€‚æ•°æ®é›†æ–¹é¢çš„å›°éš¾ã€‚è¿™åŒ…æ‹¬æ‰¾åˆ°ç¬¦åˆç‰¹å®šè¦æ±‚çš„æ•°æ®é›†çš„æŒ‘æˆ˜ã€å¯ç”¨æ€§ä¸è¶³ã€å…¬å…±æ•°æ®é›†çš„è§„æ¨¡æˆ–ç›¸å…³æ€§æœ‰é™ä»¥åŠæ”¶é›†ä¸ªäººæ•°æ®çš„éœ€æ±‚ã€‚'
- en: ''
  id: totrans-101
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**4\. Connectivity and data fusion**: Some reviews mention challenges related
    to data connectivity and fusion, such as integrating data from different sources,
    dealing with inconsistent formats, and merging datasets.'
  id: totrans-102
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**4\. è¿æ¥æ€§å’Œæ•°æ®èåˆ**ï¼šä¸€äº›è¯„è®ºæåˆ°ä¸æ•°æ®è¿æ¥æ€§å’Œèåˆç›¸å…³çš„æŒ‘æˆ˜ï¼Œä¾‹å¦‚æ•´åˆæ¥è‡ªä¸åŒæ¥æºçš„æ•°æ®ã€å¤„ç†ä¸ä¸€è‡´çš„æ ¼å¼å’Œåˆå¹¶æ•°æ®é›†ã€‚'
- en: ''
  id: totrans-103
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**5\. Computing power and scalability**: A few reviews mention challenges related
    to computing power and scalability, particularly when working with large datasets
    or when processing data on a single machine.â€™,'
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**5\. è®¡ç®—èƒ½åŠ›å’Œå¯æ‰©å±•æ€§**ï¼šä¸€äº›è¯„è®ºæåˆ°ä¸è®¡ç®—èƒ½åŠ›å’Œå¯æ‰©å±•æ€§ç›¸å…³çš„æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†å¤§å‹æ•°æ®é›†æˆ–åœ¨å•å°æœºå™¨ä¸Šå¤„ç†æ•°æ®æ—¶ã€‚'
- en: â€˜These topics reflect common challenges faced by individuals when working with
    data, including issues related to data quality, data preparation, dataset availability,
    and technical limitations.â€
  id: totrans-105
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¿™äº›è¯é¢˜åæ˜ äº†ä¸ªäººåœ¨å¤„ç†æ•°æ®æ—¶é¢ä¸´çš„å¸¸è§æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬æ•°æ®è´¨é‡ã€æ•°æ®å‡†å¤‡ã€æ•°æ®é›†å¯ç”¨æ€§å’ŒæŠ€æœ¯é™åˆ¶çš„é—®é¢˜ã€‚
- en: 'ğŸ’¡ **Note**: *While GPT-3 is powerful as it is, you can often achieve better
    results by fine-tuning the model with your training data.*'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ’¡ **æ³¨æ„**ï¼š*è™½ç„¶GPT-3æœ¬èº«å¾ˆå¼ºå¤§ï¼Œä½†é€šè¿‡ç”¨ä½ çš„è®­ç»ƒæ•°æ®å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œé€šå¸¸å¯ä»¥è·å¾—æ›´å¥½çš„ç»“æœã€‚*
- en: 'Step 6: Summarizing the Results'
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬6æ­¥ï¼šæ€»ç»“ç»“æœ
- en: These topics reflect common challenges faced by individuals when working with
    data, including issues related to data preparation, data quality, reliability,
    and scalability. A company like Kaggle can leverage these insights to develop
    educational material that specifically addresses these challenges, thereby providing
    valuable support for their community.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›è¯é¢˜åæ˜ äº†ä¸ªäººåœ¨å¤„ç†æ•°æ®æ—¶é¢ä¸´çš„å¸¸è§æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬æ•°æ®å‡†å¤‡ã€æ•°æ®è´¨é‡ã€å¯é æ€§å’Œå¯æ‰©å±•æ€§ç›¸å…³çš„é—®é¢˜ã€‚åƒKaggleè¿™æ ·çš„å…¬å¸å¯ä»¥åˆ©ç”¨è¿™äº›è§è§£æ¥å¼€å‘ä¸“é—¨è§£å†³è¿™äº›æŒ‘æˆ˜çš„æ•™è‚²ææ–™ï¼Œä»è€Œä¸ºä»–ä»¬çš„ç¤¾åŒºæä¾›å®è´µçš„æ”¯æŒã€‚
- en: Conclusion
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: In this article, weâ€™ve explored the significant potential of LLMs in extracting
    insights from text data. Weâ€™ve discussed how LLMs work and how they can be a game-changer
    for data analysts dealing with text data. You now have the knowledge to apply
    these concepts to your own text analysis tasks.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä»æ–‡æœ¬æ•°æ®ä¸­æå–æ´å¯ŸåŠ›æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚æˆ‘ä»¬è®¨è®ºäº†LLMsæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œä»¥åŠå®ƒä»¬å¦‚ä½•æˆä¸ºå¤„ç†æ–‡æœ¬æ•°æ®çš„æ•°æ®åˆ†æå¸ˆçš„æ¸¸æˆè§„åˆ™æ”¹å˜è€…ã€‚ç°åœ¨ä½ æœ‰äº†å°†è¿™äº›æ¦‚å¿µåº”ç”¨äºä½ è‡ªå·±æ–‡æœ¬åˆ†æä»»åŠ¡çš„çŸ¥è¯†ã€‚
- en: I hope you found this article helpful. If you have any questions or thoughts,
    Iâ€™ll be happy to read them in the comments!
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›ä½ å‘ç°è¿™ç¯‡æ–‡ç« å¯¹ä½ æœ‰å¸®åŠ©ã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–æƒ³æ³•ï¼Œæˆ‘å¾ˆä¹æ„åœ¨è¯„è®ºä¸­é˜…è¯»å®ƒä»¬ï¼
