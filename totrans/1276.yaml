- en: How Useful is F-test in Linear Regression?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-useful-is-f-test-in-linear-regression-db4fd35b740f](https://towardsdatascience.com/how-useful-is-f-test-in-linear-regression-db4fd35b740f)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@jaekim8080?source=post_page-----db4fd35b740f--------------------------------)[![Jae
    Kim](../Images/34716958ecfe8c0540f5cf5c1640d587.png)](https://medium.com/@jaekim8080?source=post_page-----db4fd35b740f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----db4fd35b740f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----db4fd35b740f--------------------------------)
    [Jae Kim](https://medium.com/@jaekim8080?source=post_page-----db4fd35b740f--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----db4fd35b740f--------------------------------)
    ·8 min read·Apr 29, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Not very much, but we can improve it.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dd0b6417c98f50de2f898ff4447538ba.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Greg Rakozy](https://unsplash.com/@grakozy?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: The F-test statistic for joint significance of the slope coefficients of a regression
    is routinely reported in regression outputs, along with other key statistics such
    as R² and t-ratio values.
  prefs: []
  type: TYPE_NORMAL
- en: The question is whether it is useful or informative as a key statistic. Does
    it add any value to your regression results? While it is routinely reported, one
    may observe that the F-statistic almost always rejects H0 in practical applications.
    What does it tell us about the goodness-of-fit of a regression? You will often
    find the value of R² very low, but the F-test says the model has an explanatory
    power with statistical significance. Isn’t this a conflicting outcome? How can
    we reconcile this?
  prefs: []
  type: TYPE_NORMAL
- en: In this post, I explain the problems associated with the F-test and how it can
    be modified so that it can serve as a useful tool. I should like to thank Venkat
    Raman for his [LinkedIn post](https://www.linkedin.com/posts/venkat-raman-analytics_statistics-datascience-datascientists-activity-7053981090830594048-COe0?utm_source=share&utm_medium=member_desktop)
    that has motivated this article. The R code, data, and a supporting document are
    available from [here](https://github.com/jh8080/Ftest/tree/main).
  prefs: []
  type: TYPE_NORMAL
- en: 'The contents are as below:'
  prefs: []
  type: TYPE_NORMAL
- en: What is the F-test in linear regression?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Critical values in response to sample size (T) and the number of explanatory
    variables (K)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: F-statistics in response to T and K
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Example
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why is this phenomenon happening?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can the F-test be modified?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1\. What is the F-test in linear regression?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Consider a linear regression model
  prefs: []
  type: TYPE_NORMAL
- en: 'Equation (1): Image created by the author'
  prefs: []
  type: TYPE_NORMAL
- en: where *Y* is the dependent variable, *X*’s are the independent variables, and
    *u* is the error term that follows a normal distribution with 0 mean and a fixed
    variance. The null hypotheses of the test is
  prefs: []
  type: TYPE_NORMAL
- en: Image created by the author
  prefs: []
  type: TYPE_NORMAL
- en: against H1 that at least one of these β’s ≠ 0\. Let P² be the population value
    of the coefficient of determination while R² is its sample estimator.
  prefs: []
  type: TYPE_NORMAL
- en: · Under H0, the *X* variables have no explanatory power for *Y* and P² = 0.
  prefs: []
  type: TYPE_NORMAL
- en: · Under H1, at least of one of *X*’s have explanatory power for *Y* and P² >
    0.
  prefs: []
  type: TYPE_NORMAL
- en: It is well-known that R² is an increasing function of K. That is, it increases
    as more explanatory variables are added to the model.
  prefs: []
  type: TYPE_NORMAL
- en: The F-test statistic is written as
  prefs: []
  type: TYPE_NORMAL
- en: 'Equation (2): Image created by the author'
  prefs: []
  type: TYPE_NORMAL
- en: where SSR0 is the residual sum of squares under H0 and SSR1 is the same under
    H1, while T is the sample size. The F-test statistic can also be written in terms
    of R², as given above.
  prefs: []
  type: TYPE_NORMAL
- en: The statistic follows the (central) F-distribution with (K, T-K-1) degrees of
    freedom, denoted as F(K, T-K-1). The null hypothesis is rejected at the α-level
    of significance, if F > Fc(α) where Fc(α) is the α-level critical value from F(K,
    T-K-1).
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Critical values in response to K and T
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let us first see how the critical value Fc(α) changes in response to the values
    of sample size and the number of explanatory variables.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e4b4907a829cea9bcfeca8770d6a4e98.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Image created by the author'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1 above shows that the 5% critical value declines as the value of K or
    as the value of T increases. This means that, with a larger sample size or a larger
    number of explanatory variables, the bar to reject H0 gets lower. Note that this
    property is also evident for other α-level critical values.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. F-test statistic in response to T and K
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is clear from its formula given in Equation (2) above that the value of F-
    statistic is determined by T, K, and R². More specifically,
  prefs: []
  type: TYPE_NORMAL
- en: the F-statistic is an increasing function of T, given a fixed value of K, as
    long as the value of R² does not decrease with T;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: when R² value decreases with T, the F-statistic still increases with T, if the
    effect of increasing T outpaces that of decreasing R²/(1-R²);
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the F-statistic is an increasing function of K, given a fixed value of T, because
    the value of R² always increases with the value of K as stated above.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The above observations indicate that it is highly likely in practice that the
    F-statistic is an increasing function of T and K. However, the F-critical values
    declines with the increasing values of T and K, as reported in Figure 1\. Hence,
    in modern days where the value of T and K are large, it is frequently the case
    that F > Fc(α), often rejecting the null hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. An example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I consider the data set with sunspot numbers (*Y*) and stock returns of different
    stock markets (*X*1, …, *XK*), daily from January 1988 to February 2016 (7345
    observations). This is intended to be a non-sense regression for a relationship
    with little economic justification. If the F-test is useful and effective, it
    should almost always fail to reject H0, while the value of R² is expected to be
    close to 0.
  prefs: []
  type: TYPE_NORMAL
- en: The stock returns are from 24 stock markets (K = 24), including Amsterdam, Athens,
    Bangkok, Brussels, Buenos Aires, Copenhagen, Dublin, Helsinki, Istanbul, Kuala
    Lumpur, London, Madrid, Manila, New York, Oslo, Paris, Rio de Janeiro, Santiago,
    Singapore, Stockholm, Sydney, Taipei, Vienna, and Zurich.
  prefs: []
  type: TYPE_NORMAL
- en: I run the regression of Y on (X1, …, XK), by progressively increasing the sample
    size and the number of stock markets, i.e., increasing the value of T and K. That
    is, the first regression starts with (T = 50, K =1), and then (T = 50, K =2),
    …, (T = 50, K = 24), followed by (T = 198, K =1), …, (T = 198, K = 24), and so
    on, and the process continues until the last set of regressions with (T = 7345,
    K = 1), …, (T = 7345, K = 24).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a85c48d8597212045e41f4cbe6333dd4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Numbers in Legends are the K values, Image created by the author'
  prefs: []
  type: TYPE_NORMAL
- en: As we can from Figure 2 above, the value of F-test statistic in general increases
    with sample size, for most of the values of K. They are larger than the 5% critical
    values Fc (which are well below 2 in most cases), rejecting H0 in most cases.
    In contrast, the values of R² approach 0 as the sample size increases, for all
    K values.
  prefs: []
  type: TYPE_NORMAL
- en: This means that R² is telling us effectively that the regression model is meaningless,
    but the F-test is doing otherwise by failing to reject H0 in most cases. Two key
    statistics show two conflicting outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Why is this phenomenon happening?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This does not mean that the theory of F-test developed by Ronald Fisher is
    wrong. The theory is correct, but it works only *when H0 is true exactly and literally*.
    That is, when P² = 0 or all slope coefficients are 0, *exactly* without any deviations.
    However, such a situation will not occur in the real world where researchers use
    observational data: the values of R² can get close to 0, but it cannot be zero
    exactly. Hence, the theory works only in statistical textbooks or computationally
    under a controlled Monte Carlo experiment.'
  prefs: []
  type: TYPE_NORMAL
- en: We should also remember that the F-test was developed in the 1920’s where the
    values of T and K were as small as 20 and 3, respectively. The values of T and
    K we encounter in the modern days were something unimaginable then.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. How can the F-test be modified?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The main problems with the F-test are identified above:'
  prefs: []
  type: TYPE_NORMAL
- en: the critical value of the test decreases while the test statistic increases,
    in response to increasing values of T and K.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'As mentioned above, this occurs because the F-test is for H0: P² = 0, but its
    sample estimate R² will never get to 0 exactly and literally. As a result, the
    F-test statistic increases with sample size in general, even if R² decreases to
    a practically negligible value.'
  prefs: []
  type: TYPE_NORMAL
- en: 'How do we fix this? In fact, the solution is quite simple. Instead of testing
    for H0: P² = 0 as in the conventional F-test, we should test for a one-tailed
    test of the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: 'H0: P² ≤ P0; H1: P² > P0'
  prefs: []
  type: TYPE_NORMAL
- en: This is based on the argument that, for a model to be statistically important,
    its R² value should be at least P0\. Suppose P0 is set at 0.05\. Under H0, any
    R² value less than 0.05 is practically negligible and the model is regarded as
    being substantively unimportant. The researcher can choose other values of P0,
    depending on the context of the research.
  prefs: []
  type: TYPE_NORMAL
- en: 'Under H0: P² ≤ P0, the F-statistic follows a non-central F-distribution F(K,T-K-1;
    λ) where λ is the non-centrality parameters given by'
  prefs: []
  type: TYPE_NORMAL
- en: Image created by the author
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, when P0 = 0 as in the conventional F-test, the value of λ = 0 and
    F-statistic follows the central F-distribution F(K,T-K-1). As it clear from the
    above expression that λ is an increasing function of sample size T for P0 > 0\.
    As a result, the critical value Fc(α) is also an increasing function of sample
    size.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3c7c47837698d89b8251833d1a339356.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Image created by the author'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3 above illustrates the non-central distributions F(K,T-K-1:λ) when K
    = 5 and P0 = 0.05, under a range of increasing values of T from 100 to 2000\.
    The increasing value of λ pushes the distributions away from 0, as well as their
    5% critical values.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/51e03f2afae7f00171e3c0cefa6f786a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Image created by the author'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4 above demonstrates the property as a function of T and K when P0 =
    0.05\. For example, when T = 1000 and K = 25, Fc(α) = 4.27; and when T = 2000
    and K = 25, Fc(α) =6.74, where α = 0.05.
  prefs: []
  type: TYPE_NORMAL
- en: Further details of this test can be found in the working paper (currently under
    review for publication) whose pdf copy is available from [here](https://github.com/jh8080/Ftest/tree/main).
  prefs: []
  type: TYPE_NORMAL
- en: 'Getting back to our example for the sunspot regression, a test for H0: P² ≤
    0.05; H1: P² > 0.05 can be conducted. The results of the selected cases are summarized
    as below, where α = 0.05:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/94cb0f7fcccf2e38e482e14c59d179bc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Selected Cases from the Sunspot Regression: Image created by the author'
  prefs: []
  type: TYPE_NORMAL
- en: 'Except when T = 50, the F-statistics are greater than the critical values from
    the central F-distributions, which means that H0: P² = 0 is rejected at the 5%
    level of significance, despite negligible R² values. However, the F-statistics
    are less than the critical values from the non-central F-distributions, which
    means that H0: P² ≤ 0.05 cannot be rejected at the 5% level of significance, consistent
    with negligible R² values.'
  prefs: []
  type: TYPE_NORMAL
- en: To conclude, the F-test has serious issues as a means of testing for the goodness-of-fit
    of a regression model, especially when the sample size or the number of explanatory
    variables is large. It often conflicts with low R² values, indicative of the negligible
    effect of the model. Hence, as in the present form, the F-test is not useful as
    a test for goodness-of-fit. However, with a simple modification, the test can
    become useful, which has been introduced in this post with an example.
  prefs: []
  type: TYPE_NORMAL
