- en: 'YOLO-NAS: How to Achieve the Best Performance on Object Detection Tasks'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/yolo-nas-how-to-achieve-the-best-performance-on-object-detection-tasks-6b95347908d4](https://towardsdatascience.com/yolo-nas-how-to-achieve-the-best-performance-on-object-detection-tasks-6b95347908d4)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A foundational model generated through neural architecture search, innovative
    quantization blocks, and a robust pre-training paradigm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://thomasdorfer.medium.com/?source=post_page-----6b95347908d4--------------------------------)[![Thomas
    A Dorfer](../Images/9258a1735cee805f1d9b02e2adf01096.png)](https://thomasdorfer.medium.com/?source=post_page-----6b95347908d4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6b95347908d4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6b95347908d4--------------------------------)
    [Thomas A Dorfer](https://thomasdorfer.medium.com/?source=post_page-----6b95347908d4--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6b95347908d4--------------------------------)
    ·7 min read·May 19, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/25a5a1f2e9fb6454fa899c6b66c2c7b3.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Anubhav Saxena](https://unsplash.com/@anubhav) on [Unsplash](https://unsplash.com/photos/RA5ntyyDHlw).
    Processed with YOLO-NAS-L by the author.
  prefs: []
  type: TYPE_NORMAL
- en: In the domain of object detection, YOLO (**Y**ou **O**nly **L**ook **O**nce)
    has become a household name. Since the [release](https://arxiv.org/abs/1506.02640)
    of the first model in 2015, the YOLO family has been growing steadily, with each
    new model outperforming its predecessor in mean average precision (mAP) and inference
    latency.
  prefs: []
  type: TYPE_NORMAL
- en: 'Two weeks ago, the YOLO family has welcomed yet another member: [YOLO-NAS](https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md),
    a novel and foundational model developed by the deep learning company [Deci](https://deci.ai/).'
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we’ll explore its advantages over previous YOLO models and
    demonstrate how it can be used for your own object detection tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'YOLO-NAS: What’s New?'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While previous YOLO models were leading in innovation and performance when it
    comes to object detection, they did have some limitations. One of the main issues
    was the lack of proper quantization support, which aims to decrease the model’s
    memory and computation requirements. Another issue was the insufficient trade-off
    between accuracy and latency, whereby an improvement in one often resulted in
    a considerable decline in the other.
  prefs: []
  type: TYPE_NORMAL
- en: By leveraging a concept called **neural architecture search (NAS)**, researchers
    at Deci addressed these limitations head-on. Essentially, the concept of NAS can
    be considered a makeover for a trained deep learning model.
  prefs: []
  type: TYPE_NORMAL
- en: Traditionally, neural network architectures were manually designed by human
    experts based on their experience and intuition. However, this process, which
    involves the exploration of vast design spaces of possible architectures, has
    always been very time-consuming and cumbersome.
  prefs: []
  type: TYPE_NORMAL
- en: '**NAS**, on the other hand, automatically re-designs the model’s architecture
    in order to boost its performance when it comes to things like speed, memory usage,
    and throughput. It typically involves a search space that defines the set of possible
    architectural choices, such as the number of layers, layer types, kernel sizes,
    and connectivity patterns. The search algorithm then assesses different architectures
    by training and evaluating them on a given task and dataset. Based on these evaluations,
    the algorithm iteratively explores and refines the architecture space, ultimately
    returning the one that yields the best performance.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8ffbda473f7f6b1ff153e596571ee018.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Google DeepMind](https://unsplash.com/@deepmind) on [Unsplash](https://unsplash.com/photos/Krw-2KP7bOE)
  prefs: []
  type: TYPE_NORMAL
- en: In order to perform NAS, Deci leveraged its proprietary [AutoNAC](https://deci.ai/deep-learning-glossary/automated-neural-architecture-construction-autonac/)
    technology, which is an optimization engine that redesigns a model’s architecture
    to squeeze out maximum inference performance for a specific piece of hardware
    while at the same time preserving accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Aside from NAS, another major improvement of this new YOLO member involves the
    usage of **quantization**. Quantization, in this context, refers to the conversion
    of the neural network’s weights, biases, and activations from floating point values
    to integer values (INT-8), thus making the model more efficient.
  prefs: []
  type: TYPE_NORMAL
- en: 'This effort is two-fold: (1) The model uses quantization-friendly blocks that
    combine the advantages of re-parameterization and INT-8 quantization. These blocks
    use a methodology proposed by [Chu et al. (2022)](https://arxiv.org/pdf/2212.01593.pdf),
    which redesigns the blocks so that the weight and activation distributions they
    generate are advantageous for quantization. (2) The authors utilize a hybrid quantization
    method, which selectively quantizes specific layers of the model, thus minimizing
    information loss and striking a balance between latency and accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: The results of this novel methodology speak for themselves. As can be seen in
    the graph below, the quantized, medium-sized model, *YOLO-NAS-INT8-M*, demonstrates
    a 50% improvement in inference latency, while at the same time sporting a 1 mAP
    increase in accuracy compared to the latest state-of-the-art model.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/05179e7654f1412702e9ec890fc1b888.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [Deci-AI](https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md).
    License: [Apache License 2.0](https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.md)'
  prefs: []
  type: TYPE_NORMAL
- en: 'At the time of writing, three models of YOLO-NAS have been released: small,
    medium, and large, each with a quantized INT-8 counterpart.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/03ad61150761e4ca0f0a09d9e2c5a467.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [Deci-AI](https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md).
    License: [Apache License 2.0](https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.md)'
  prefs: []
  type: TYPE_NORMAL
- en: Not surprisingly, the quantized versions experience a slight drop in precision.
    However, due to the employment of these novel quantization-friendly blocks as
    well as selective quantization, this precision drop remains relatively small.
    In addition, the upside here considerably outweighs the downside, with significant
    improvements being observed in inference latency.
  prefs: []
  type: TYPE_NORMAL
- en: YOLO-NAS also comes **pre-trained** on the COCO, Objects365, and Roboflow 100
    datasets, which makes it extremely suitable for downstream object detection tasks.
  prefs: []
  type: TYPE_NORMAL
- en: The pre-training regimen leveraged a concept known as **knowledge-distillation**,
    which allows the model to learn from its own predictions, rather than relying
    solely on external, labeled data, in order to improve performance. In this paradigm,
    a teacher model generates predictions on the training data, which then serve as
    guidance (or soft targets) for the student model. The student model is trained
    using both the original labeled data and the soft targets generated by the teacher
    model. It essentially tries to mimic the teacher model’s predictions while also
    adjusting its parameters to match the original labeled data. Overall, this approach
    allows the model to generalize better, reduce overfitting, and achieve higher
    accuracy, especially when labeled data is not abundantly available.
  prefs: []
  type: TYPE_NORMAL
- en: The training process was further enhanced through the incorporation of **distribution
    focal loss (DFL).** DFL is a loss function that extends the concept of focal loss,
    which addresses the issue of class imbalance by assigning higher weights to hard-to-classify
    samples. In the context of object detection, DFL is used in the training process
    by learning box regression as a classification task. It discretizes bounding box
    predictions into limited options and predicts distributions over these options.
    The final predictions are then obtained by combining these distributions using
    weighted sums. By considering the class distribution and adjusting the loss function
    accordingly, the model is able to increase its detection accuracy for underrepresented
    classes.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, YOLO-NAS has been made available under an open source license with
    pre-trained weights available for research use on Deci’s PyTorch-based computer
    vision library called [SuperGradients](https://github.com/Deci-AI/super-gradients).
  prefs: []
  type: TYPE_NORMAL
- en: How To Use YOLO-NAS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to use YOLO-NAS for inference, we need to install the `super_gradients`
    package first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To set ourselves up for the inference task, let’s take a sample image that
    we’re going to call `image.jpg`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f40b27aca75577921c73a4eb3aa0915d.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [krakenimages](https://unsplash.com/@krakenimages) on [Unsplash](https://unsplash.com/photos/376KN_ISplE)
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to perform inference, we can use the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: First, we need to import `torch` and `models` from the `super_gradients` library.
    Then, we declare a variable `device`, which is set to use the first available
    GPU (if one is available), or, otherwise, is set to use the CPU.
  prefs: []
  type: TYPE_NORMAL
- en: Subsequently, we are specifying that we’d like to use the small version of the
    model, YOLO-NAS-S, and the pre-trained weights from the COCO dataset. Furthermore,
    we’re saving the output image with the detected objects as `image_yolo.jpg`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our output image looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a31bef37532fca8a76b5a5db986ae6fb.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [krakenimages](https://unsplash.com/@krakenimages) on [Unsplash](https://unsplash.com/photos/376KN_ISplE).
    Processed with YOLO-NAS-S by the author.
  prefs: []
  type: TYPE_NORMAL
- en: We can see various objects being detected spanning a wide range of confidence
    levels. The model is mostly confident for objects in focus, such as the two persons,
    cups, and the laptop. However, we also observe some misclassifications, probably
    due to the objects being out of focus. This includes a penholder being misclassified
    as a potted plant, and a pen being misclassified as a toothbrush. Amazingly, we
    can also see that the model accurately detects objects that are only partially
    visible, such as the chairs that the persons are sitting on, where only the backrest
    is visible.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, it is worth mentioning that object detection can be performed in exactly
    the same way with videos by simply changing the input parameter of the `predict()`
    call to the corresponding video file.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The YOLO family has grown by yet another member, YOLO-NAS, which is proudly
    outperforming its younger siblings like YOLOv6, YOLOv7, and YOLOv8.
  prefs: []
  type: TYPE_NORMAL
- en: Through an innovative combination of neural architecture search, quantization
    support, and a robust pre-training procedure that includes knowledge-distillation
    and distribution focal loss, YOLO-NAS achieves remarkable trade-offs between precision
    and inference latency.
  prefs: []
  type: TYPE_NORMAL
- en: Considering the rapid pace at which the landscape of computer vision and object
    detection keeps evolving, it is highly likely that another YOLO model will soon
    come to see the light of day.
  prefs: []
  type: TYPE_NORMAL
- en: More Resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[YOLO-NAS by Deci Achieves State-of-the-Art Performance on Object Detection
    Using Neural Architecture Search](https://deci.ai/blog/YOLO-NAS-object-detection-foundation-model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[super-gradients/YOLONAS.md at master · Deci-AI/super-gradients · GitHub](https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liked this article?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s connect! You can find me on [Twitter](https://twitter.com/ThomasADorfer),
    [LinkedIn](https://www.linkedin.com/in/thomasdorfer/) and [Substack](https://thomasdorfer.substack.com/).
  prefs: []
  type: TYPE_NORMAL
- en: If you like to support my writing, you can do so through a [Medium Membership](https://thomasdorfer.medium.com/membership),
    which provides you access to all my stories as well as those of thousands of other
    writers on Medium.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/@thomasdorfer/membership?source=post_page-----6b95347908d4--------------------------------)
    [## Join Medium with my referral link - Thomas A Dorfer'
  prefs: []
  type: TYPE_NORMAL
- en: Read every story from Thomas A Dorfer (and thousands of other writers on Medium).
    Your membership fee directly supports…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@thomasdorfer/membership?source=post_page-----6b95347908d4--------------------------------)
  prefs: []
  type: TYPE_NORMAL
