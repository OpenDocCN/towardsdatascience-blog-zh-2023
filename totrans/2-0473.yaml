- en: 'CatBoost Regression: Break It Down For Me'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/catboost-regression-break-it-down-for-me-16ed8c6c1eca](https://towardsdatascience.com/catboost-regression-break-it-down-for-me-16ed8c6c1eca)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A comprehensive (and illustrated) breakdown of the inner workings of CatBoost
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@shreya.rao?source=post_page-----16ed8c6c1eca--------------------------------)[![Shreya
    Rao](../Images/03f13be6f5f67783d32f0798f09a4f86.png)](https://medium.com/@shreya.rao?source=post_page-----16ed8c6c1eca--------------------------------)[](https://towardsdatascience.com/?source=post_page-----16ed8c6c1eca--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----16ed8c6c1eca--------------------------------)
    [Shreya Rao](https://medium.com/@shreya.rao?source=post_page-----16ed8c6c1eca--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----16ed8c6c1eca--------------------------------)
    ·14 min read·Sep 2, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: CatBoost, short for Categorical Boosting, is a powerful machine learning algorithm
    that excels in handling categorical features and producing accurate predictions.
    Traditionally, dealing with categorical data is pretty tricky— requiring one-hot
    encoding, label encoding, or some other preprocessing technique that can distort
    the data’s inherent structure. To tackle this issue, CatBoost employs its own
    built-in encoding system called **Ordered Target Encoding**.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see how CatBoost works in practice by building a model to predict how
    someone might rate the book *Murder, She Texted* based on their average book rating
    on [Goodreads](https://www.goodreads.com/) and their favorite genre.
  prefs: []
  type: TYPE_NORMAL
- en: We asked 6 people to rate *Murder, She Texted* and collected the other relevant
    information about them.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c55b6b7914e005d3d922bd1388c2897e.png)'
  prefs: []
  type: TYPE_IMG
- en: This is our current training dataset, which we will use to train (duh) the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: Shuffle the dataset and Encode the Categorical Data Using **Ordered
    Target Encoding**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The way we preprocess categorical data is central to the CatBoost algorithm.
    In this case, we only have one categorical column — *Favorite Genre*. This column
    is encoded (aka converted to a discrete integer) and the way it is done varies
    depending on whether it is a Regression or Classification problem. Since we are
    dealing with a Regression problem (because the variable we want to predict *Murder,
    She Texted Rating* is continuous) we follow the following steps.
  prefs: []
  type: TYPE_NORMAL
- en: '1 — Shuffle the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02ccf72943f10da4bb7ec83c01983c9a.png)'
  prefs: []
  type: TYPE_IMG
- en: '2 — Put the continuous target variable into discrete **buckets**: Since we
    have very little data here, we’ll create 2 buckets of the same size to categorize
    the target. (Learn more about how to create buckets [here](https://catboost.ai/en/docs/concepts/quantization#quantization)).'
  prefs: []
  type: TYPE_NORMAL
- en: We put the 3 smallest values of *Murder, She Texted Rating* in bucket 0 and
    the rest in bucket 1.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0f4a3126a14fd8497cb31a269510d9d6.png)'
  prefs: []
  type: TYPE_IMG
- en: '3 — Enocde the categorical column using a formula: Ordered Target Encoding
    pretends like it is receiving the data sequentially, one row at a time, and uses
    this formula to encode the values in *Favorite Genre*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2d56794b724c0d5ba210738cac7dbe0b.png)'
  prefs: []
  type: TYPE_IMG
- en: curCount = the number of people we’ve seen before who have the same *Favorite
    Genre* and are in *Rating Bucket* 1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: prior = constant value that is user defined; let’s set it to 0.05 in our case
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: maxCount = the number of people we’ve seen before that have the same *Favorite
    Genre*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'NOTE: If we have more data, we’ll have more buckets. And we use a different
    formula to encode categorical data. Read more [here](https://catboost.ai/en/docs/concepts/algorithm-main-stages_cat-to-numberic).'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Using this formula, let’s encode the first row. Since it’s the first row, we
    are assuming no data came before it and this row is the only information we have.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/174d3ab1af213a8adbeeed740a0813e4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here:'
  prefs: []
  type: TYPE_NORMAL
- en: curCount = the number of people we’ve seen before with *Rating Bucket* 1 and
    whose *Favorite Genre* is Mystery = 0
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: maxCount = number of people we’ve seen whose *Favorite Genre* is Mystery = 0
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/9fb65207d90bd1fcf4fcf48b643dad3f.png)'
  prefs: []
  type: TYPE_IMG
- en: So, the encoded value of Mystery in the first row is 0.05.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9795a2c74524ecb105bdd016fd491cd2.png)'
  prefs: []
  type: TYPE_IMG
- en: Now for the second row, we assume the only data we have are the first 2 rows.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1c751310778245c4a274b985c96612ff.png)'
  prefs: []
  type: TYPE_IMG
- en: curCount = the number of people we’ve seen before with *Rating Bucket* 1, and
    whose *Favorite Genre* is Romance = 0
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: maxCount = number of people we’ve seen whose *Favorite Genre* is Romance = 0
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/9fb65207d90bd1fcf4fcf48b643dad3f.png)'
  prefs: []
  type: TYPE_IMG
- en: Similar to the first row, the encoded value for the second row is 0.05.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b6f7671b1ac8f12379905d2f8cea4179.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For the third row:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2cbee4234edaaf7c76e6b4778325a9d3.png)'
  prefs: []
  type: TYPE_IMG
- en: curCount = the number of people we’ve seen before who were in Rating Bucket
    1, and whose *Favorite Genre* is Mystery = 0
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: maxCount = number of people we’ve seen whose *Favorite Genre* is Mystery = 1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/409cb30218c155c4830f2b314eb71574.png)![](../Images/2aa547853d29b41deb21a2bf8a82c94a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, if we do this encoding on the remaining rows, we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/10d86e8ec9402e1c178d66fb72194878.png)'
  prefs: []
  type: TYPE_IMG
- en: And that’s how we encode the categorical variables.
  prefs: []
  type: TYPE_NORMAL
- en: '*For now we can ignore* Favorite Genre *and* *only consider* Encoded Favorite
    Genre*.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/21320ee5485dd467020e897543f7e5b5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Step 2: Make an Initial Prediction and Calculate Residuals'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CatBoost starts by making an initial *Murder, She Texted Rating* prediction
    of 0 for all rows.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8747b4f8eeb4b88cfead29e1a783cf14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then we calculate something called *Residuals* using this formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c6bd701d470fd6eae8b4b258cd9dfdf8.png)![](../Images/a41ea969c224c398b316e1aaba0bd77b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Step 3: Build a CatBoost Tree'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have the *Residuals*, we can start to build a CatBoost tree. It
    might be useful to read my previous article on [Decision Trees](https://medium.com/towards-artificial-intelligence/decision-tree-classification-explain-it-to-me-like-im-10-59a53c0b338f)
    and [XGBoost](/xgboost-regression-explain-it-to-me-like-im-10-2cf324b0bbdb) to
    give you some context on decision trees.
  prefs: []
  type: TYPE_NORMAL
- en: Find a root node
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We determine the best threshold for the tree's root (first split) by comparing
    how well the tree splits using *Favorite Genre* (encoded) vs. *Average Goodreads
    Rating* as a root node.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to identify candidate nodes for splitting the tree based on
    *Favorite Genre*. To do this, we must sort the values of *Favorite Genre* in ascending
    order:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5a6c438f0d3125de551c4aed441a40bf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then we calculate the average values of the adjacent values in *Favorite Genre*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/796720c7845e64378510fcbbb335075e.png)'
  prefs: []
  type: TYPE_IMG
- en: Our candidate values for *Favorite Genre* splits are these averages — 0.0375,
    0.05, 0.2875, and 0.525.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first candidate we try is *Favorite Genre* < 0.0375:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9bdb564e41316c713a7195889703ef2f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The leaves of the tree are green. CatBoost initializes something called the
    ***Output*** of the leaves of the split to be 0:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/42d7021ec137fbb16a3f12aea41a96ab.png)'
  prefs: []
  type: TYPE_IMG
- en: If *Favorite Genre* is less than 0.0375, we end up in the left leaf; otherwise,
    we end up in the right leaf. **When each row of data is run down the tree, its
    *Residuals* are put in the leaves.**
  prefs: []
  type: TYPE_NORMAL
- en: So running the first row down the tree…
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1b875d99ecf6d9107f3bff61c90c2a02.png)'
  prefs: []
  type: TYPE_IMG
- en: '…we put its *Residual* in the right leaf because *Favorite Genre* is 0.05,
    which is greater than 0.0375:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ca72d1f992c33cb4b1af5c6e9a3e9b7b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then we keep track of the ***Leaf Output*** for that row:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fb75c779519cdfd4743056f14b1a7826.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Then we update the value of the *Output* in the tree to the average of the
    *Residual* values in the leaf**. In this case, since there is only one *Residua*l
    in the leaf, the *Output* is 3.5.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b932a580dc8e30883590848321f71c49.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now running the second row down the tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a7eb2b6e489293b8603db9c07c0092d9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We put its *Residual* in the right leaf too because 0.05 > 0.0375:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7e2b3bdd0c16bd6df682293ba3fc52f5.png)'
  prefs: []
  type: TYPE_IMG
- en: the Residual ends up in the right leaf
  prefs: []
  type: TYPE_NORMAL
- en: 'We store the *Leaf Output* value:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/41541c18516b2910614038ce7c834704.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And we update the *Output* value by taking the average of the two *Residuals*
    in the leaf:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5d555d4f7cf7fef58404281f60c22368.png)'
  prefs: []
  type: TYPE_IMG
- en: 'right output: 3.5 => 3'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s pass the third row down the tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1ab28b48f6daeb1f9fbf54c630cc098e.png)'
  prefs: []
  type: TYPE_IMG
- en: the Residual ends up in the left leaf because Favorite Genre = 0.025 < 0.0375
  prefs: []
  type: TYPE_NORMAL
- en: 'Keep track of the Leaf Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/62764dc182503cf534b4235e21ba9b00.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And update the *Output* value of the leaf:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ab01c17043a1ff7df275f99f9eb7fa62.png)'
  prefs: []
  type: TYPE_IMG
- en: 'left output: 0 => 4'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, let's run the last 3 rows down the tree. We end up with this tree…
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1c90b4f76df8c5bbf7490fc7369ebf96.png)'
  prefs: []
  type: TYPE_IMG
- en: '…and this table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6b3595ec9b2a061597dea373c0e428b7.png)'
  prefs: []
  type: TYPE_IMG
- en: final table with the leaf output values stored
  prefs: []
  type: TYPE_NORMAL
- en: Quantify how “good” this root node is
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'CatBoost quantifies how good the split is by calculating the **Cosine Similarity**
    between the *Leaf Output* column and the *Residuals.* The formula for Cosine Similarity
    is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b758000f9b4ccdd9a13b7c8a8cbe34b2.png)'
  prefs: []
  type: TYPE_IMG
- en: where A and B are just two columns we’re trying to compare.
  prefs: []
  type: TYPE_NORMAL
- en: So to calculate the Cosine Similarity of *Residuals* and *Leaf Output* column…
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7fede8d0042253d68388c8f642b4cabd.png)'
  prefs: []
  type: TYPE_IMG
- en: '…we put the corresponding values in the formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e6991312e230417efe561eb29e8bc54b.png)'
  prefs: []
  type: TYPE_IMG
- en: And we find Cosine Similarity = 0.786\. Thus, the Cosine Similarity for the
    threshold *Favorite Genre* < 0.0375 is 0.786.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now using the same process as above, we build a tree using the second candidate
    for root threshold: *Favorite Genre* < 0.05\. If we repeat the same process, we
    end up with this tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0a6e5c34e3f81e3e8795109bc5f34afc.png)'
  prefs: []
  type: TYPE_IMG
- en: '…and this table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6b3595ec9b2a061597dea373c0e428b7.png)'
  prefs: []
  type: TYPE_IMG
- en: '…with Cosine Similarity:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e6991312e230417efe561eb29e8bc54b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'NOTE: This is the same value as what we got using the threshold Favorite Genre
    < 0.0375 because the Residuals land up in the same leaves.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Let’s try the next root threshold candidate: *Favorite Genre* < 0.2875\. We
    get the tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0bfa58a56ee63c5503c54eaf09a5e06c.png)'
  prefs: []
  type: TYPE_IMG
- en: '…and this table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/314ee4a554be4df79d2cac63f5698d87.png)'
  prefs: []
  type: TYPE_IMG
- en: …and with Cosine Similarity of *Residuals* and *Leaf Outputs* = 0.84\. Here
    because the Cosine Similarity is greater than that of the other 2 thresholds,
    we conclude that *Favorite Genre* < 0.2875 is a better root split than *Favorite
    Genre* < 0.0375 and *Favorite Genre* < 0.05.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we for the last split: *Favorite Genre* < 0.525\. We get a Cosine Similarity
    of 0.84, which leads us to conclude that the splits on 0.2875 and 0.525 perform
    similarly.'
  prefs: []
  type: TYPE_NORMAL
- en: '**But remember we only tested *Favorite Genre* candidates.** Next, we need
    to test *Average Goodreads Rating* root candidates. And to do that, we need to
    identify our candidates for *Average Goodreads Rating* splits by arranging the
    columns in ascending order and calculating the adjacent averages.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/41539fdbfb4b69ad185af39079f62eef.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For each average, we build a tree and calculate the Cosine Similarity between
    *Leaf Outputs* and *Residuals*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3f0b9ad16151c29c7f41dc34a0a9025c.png)![](../Images/bba15e4479a706106ae39ec5d56f256c.png)'
  prefs: []
  type: TYPE_IMG
- en: Comparing the Cosine Similarity values of all candidate root nodes, we find
    that the Cosine Similarity of *Average Goodreads Rating* < 3.65 has the highest
    value of 0.87\. ***So we choose this to be our root node split***
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fb93d8b8c5e712f4662c12e27ed9b4da.png)'
  prefs: []
  type: TYPE_IMG
- en: After obtaining the root node, we can expand the tree by adding new branches.
    To do this, we follow a similar process as before, but instead of selecting a
    root node, we select a branch that splits off from the leaves. And the split that
    has the highest Cosine Similarity values is chosen.
  prefs: []
  type: TYPE_NORMAL
- en: The caveat with CatBoost trees is that they are **symmetric**, meaning each
    branch on the same level uses the exact same threshold.
  prefs: []
  type: TYPE_NORMAL
- en: 'NOTE: If you’re curious about why we build symmetric trees, you can read about
    it here.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'So an example of one will be:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/507a5887462399a52ce966d0b725e512.png)'
  prefs: []
  type: TYPE_IMG
- en: In this case, both the nodes at the same level use the same split.
  prefs: []
  type: TYPE_NORMAL
- en: '**Since we have so little data let’s just stick to building trees of *depth*
    1.**'
  prefs: []
  type: TYPE_NORMAL
- en: 'NOTE: Tree depth is a parameter in the model that we can tune mainly to avoid
    overfitting. In most cases, the optimal depth ranges from 4 to 10 and values in
    the range from 6 to 10 are recommended.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: And just like that, we have our first tree!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fb93d8b8c5e712f4662c12e27ed9b4da.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Step 4: Make New Predictions'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now we make new predictions using the old predictions and this formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/99fb411bfaa145d53d7c84f3629377d5.png)'
  prefs: []
  type: TYPE_IMG
- en: Learning Rate is another parameter we can tune to avoid overfitting. Read more
    about it [here](https://catboost.ai/en/docs/concepts/parameter-tuning#learning-rate).
    For now, let’s set it to 0.1.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let’s go back to our table.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d075595c7df737e2682dd53565f7846d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Using the formula, we can calculate the new predictions. For the first row,
    the new prediction will be:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02271e7805d5148232a2ef8e5916a429.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, if we calculate the new predictions for the rest of the rows we
    get:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7d63ed1ceb790270c0f6daf906398519.png)'
  prefs: []
  type: TYPE_IMG
- en: We can see that our new predictions are not very accurate as they still differ
    significantly from the actual rating of *Murder, She Texted*. However, they are
    an improvement from the old predictions of all zeros.
  prefs: []
  type: TYPE_NORMAL
- en: Our next step is to build a new tree. But before doing that let’s quickly clean
    up our noisy dataset a bit so it's easier to work with. We can ignore the old
    predictions, *Residual* column*,* and *Leaf Output* column…
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/53f928b746767db6e48d196b68d88361.png)'
  prefs: []
  type: TYPE_IMG
- en: …rename the New Prediction column to just Prediction (because it's not new anymore)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fde9138a3fa83550f4cda02ed9880093.png)'
  prefs: []
  type: TYPE_IMG
- en: '…and replace the values of *Encoded Favorite Genre* with our original *Favorite
    Genre*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4abfda0867ff7456ad5b5d5dd5510708.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Step 5: Build a New Tree Using Steps 1–4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now we repeat the same process that we did to build our first tree to build
    a second one.
  prefs: []
  type: TYPE_NORMAL
- en: Using **Step 1**, we shuffle the dataset…
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c83e5aea29777c5e33adc2d86bc5e666.png)'
  prefs: []
  type: TYPE_IMG
- en: '…and encode the categorical data (aka *Favorite Genre*) using ordered target
    encoding:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f049664482780c62269ae8a5e4b4ae17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Following **Step 2**, since we already have our prediction, we don’t need to
    make initial predictions. All we do is calculate *Residuals* using the same formula
    we saw above:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c6bd701d470fd6eae8b4b258cd9dfdf8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We get the following *Residuals*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9dfbc683d842378fe8af9f32ced84236.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then we build our second CatBoost tree using **Step 3**. Let’s assume after
    testing all the *Encoded Favorite Genre* and *Average Goodreads Rating* candidates,
    we find the perfect root node to be *Encoded Favorite Genre* < 0.288\. Since the
    tree has a depth of 1, as previously set, we end up with a tree like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/385ce155f75ddaf83bf30ef920f2bb5e.png)'
  prefs: []
  type: TYPE_IMG
- en: '…and an updated table with *Leaf Outputs*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0e2356c3dcce2c3f6878bd2624d69eca.png)'
  prefs: []
  type: TYPE_IMG
- en: Finally, using **Step 4**, we make new predictions. So using this formula…
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e51bae503102a30335792b46a038d7c8.png)'
  prefs: []
  type: TYPE_IMG
- en: '…we get new predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/11c92f867be7ef476a1b2257f7526ed7.png)'
  prefs: []
  type: TYPE_IMG
- en: We can see here that the new predictions are slightly better than the old ones.
    And if we continue this process and continue building more trees, our predictions
    get better and better.
  prefs: []
  type: TYPE_NORMAL
- en: 'NOTE: We continue building trees until our predictions are good, or until we
    hit the [number of trees](https://catboost.ai/en/docs/concepts/parameter-tuning#trees-number)
    parameter value, which we can set.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Making Predictions with Our CatBoost Trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s assume we finished our model building process with just these 2 trees
    we have above. (by default CatBoost builds 1000). We now have a CatBoost model
    (obviously this isn’t going to be close to a good one because we only have 2 trees)
    with which we can start making predictions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c66ca15a7158e1905443bb054a305f75.png)![](../Images/4e50dbaa79bc535b8ab600ae46a5dce1.png)'
  prefs: []
  type: TYPE_IMG
- en: Now using our model, we want to predict how these 2 people are going to rate
    *Murder, She Texted*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/10b9ef99a8857830a7043297cef4a0e7.png)'
  prefs: []
  type: TYPE_IMG
- en: To begin, we need to encode the categorical data — *Favorite Genre*. The process
    of encoding new data is similar to how we encoded the training data; the only
    difference is that we use the entire training dataset for encoding.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7dbaa66e0419d5e90a96994fd0f1b5c5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Assign *Murder, She Texted Rating* to the same Rating Buckets we used before:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c4103a4f4674cbe3224526772d650db4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now we use this same formula as above to do the encoding:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f00774f8ae88fdff2c6e5f5fe27e1de8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'However, we use the entire training dataset instead of doing it sequentially
    as we did during the training process. So for instance, the encoding for *Favorite
    Genre* Mystery will be:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6c95bf934515217ab774f8e5268f21c3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, the encoding for the other *Favorite Genre*’s are:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/be385c4c6161a16d6264e3f2ab69d660.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We substitute the encoded values in the new dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/56b3f0578bd11aeee67e0c34b366270a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'So now for the first person, we go back to our trees and pass the data down
    them:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a72f9274575a8c90784790d854dcc4b0.png)![](../Images/b59d60cb740b98379db4bccba8eb2199.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then we use this formula to make our prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/06c17cc32df80ac060ead79bc18ec843.png)'
  prefs: []
  type: TYPE_IMG
- en: 'So our prediction is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0f4ea8b76f9bcb57185cf725e8f2fef6.png)'
  prefs: []
  type: TYPE_IMG
- en: Granted, this is a terrible prediction. But remember this is a pretty terrible
    model. The more trees we have, the better our model is going to perform.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, for the second person:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bf079eb8c12398b3f4fe66b42d8402b8.png)'
  prefs: []
  type: TYPE_IMG
- en: And that’s about it. That’s how we build CatBoost trees and use them to make
    predictions on new data!
  prefs: []
  type: TYPE_NORMAL
- en: Unless otherwise noted, all images are by the author
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You can connect with me on [LinkedIn](https://www.linkedin.com/in/shreyarao24/)
    or email me at *shreya.statistics@gmail.com* to send me questions and suggestions
    for any other algorithms that you want illustrated!
  prefs: []
  type: TYPE_NORMAL
