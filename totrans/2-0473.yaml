- en: 'CatBoost Regression: Break It Down For Me'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/catboost-regression-break-it-down-for-me-16ed8c6c1eca](https://towardsdatascience.com/catboost-regression-break-it-down-for-me-16ed8c6c1eca)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A comprehensive (and illustrated) breakdown of the inner workings of CatBoost
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@shreya.rao?source=post_page-----16ed8c6c1eca--------------------------------)[![Shreya
    Rao](../Images/03f13be6f5f67783d32f0798f09a4f86.png)](https://medium.com/@shreya.rao?source=post_page-----16ed8c6c1eca--------------------------------)[](https://towardsdatascience.com/?source=post_page-----16ed8c6c1eca--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----16ed8c6c1eca--------------------------------)
    [Shreya Rao](https://medium.com/@shreya.rao?source=post_page-----16ed8c6c1eca--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----16ed8c6c1eca--------------------------------)
    ·14 min read·Sep 2, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: CatBoost, short for Categorical Boosting, is a powerful machine learning algorithm
    that excels in handling categorical features and producing accurate predictions.
    Traditionally, dealing with categorical data is pretty tricky— requiring one-hot
    encoding, label encoding, or some other preprocessing technique that can distort
    the data’s inherent structure. To tackle this issue, CatBoost employs its own
    built-in encoding system called **Ordered Target Encoding**.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see how CatBoost works in practice by building a model to predict how
    someone might rate the book *Murder, She Texted* based on their average book rating
    on [Goodreads](https://www.goodreads.com/) and their favorite genre.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: We asked 6 people to rate *Murder, She Texted* and collected the other relevant
    information about them.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c55b6b7914e005d3d922bd1388c2897e.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
- en: This is our current training dataset, which we will use to train (duh) the data.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: Shuffle the dataset and Encode the Categorical Data Using **Ordered
    Target Encoding**'
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The way we preprocess categorical data is central to the CatBoost algorithm.
    In this case, we only have one categorical column — *Favorite Genre*. This column
    is encoded (aka converted to a discrete integer) and the way it is done varies
    depending on whether it is a Regression or Classification problem. Since we are
    dealing with a Regression problem (because the variable we want to predict *Murder,
    She Texted Rating* is continuous) we follow the following steps.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '1 — Shuffle the dataset:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02ccf72943f10da4bb7ec83c01983c9a.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
- en: '2 — Put the continuous target variable into discrete **buckets**: Since we
    have very little data here, we’ll create 2 buckets of the same size to categorize
    the target. (Learn more about how to create buckets [here](https://catboost.ai/en/docs/concepts/quantization#quantization)).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: We put the 3 smallest values of *Murder, She Texted Rating* in bucket 0 and
    the rest in bucket 1.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0f4a3126a14fd8497cb31a269510d9d6.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
- en: '3 — Enocde the categorical column using a formula: Ordered Target Encoding
    pretends like it is receiving the data sequentially, one row at a time, and uses
    this formula to encode the values in *Favorite Genre*:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2d56794b724c0d5ba210738cac7dbe0b.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
- en: curCount = the number of people we’ve seen before who have the same *Favorite
    Genre* and are in *Rating Bucket* 1
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: prior = constant value that is user defined; let’s set it to 0.05 in our case
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: maxCount = the number of people we’ve seen before that have the same *Favorite
    Genre*
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'NOTE: If we have more data, we’ll have more buckets. And we use a different
    formula to encode categorical data. Read more [here](https://catboost.ai/en/docs/concepts/algorithm-main-stages_cat-to-numberic).'
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Using this formula, let’s encode the first row. Since it’s the first row, we
    are assuming no data came before it and this row is the only information we have.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/174d3ab1af213a8adbeeed740a0813e4.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
- en: 'Here:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: curCount = the number of people we’ve seen before with *Rating Bucket* 1 and
    whose *Favorite Genre* is Mystery = 0
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: maxCount = number of people we’ve seen whose *Favorite Genre* is Mystery = 0
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/9fb65207d90bd1fcf4fcf48b643dad3f.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
- en: So, the encoded value of Mystery in the first row is 0.05.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9795a2c74524ecb105bdd016fd491cd2.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
- en: Now for the second row, we assume the only data we have are the first 2 rows.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1c751310778245c4a274b985c96612ff.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
- en: curCount = the number of people we’ve seen before with *Rating Bucket* 1, and
    whose *Favorite Genre* is Romance = 0
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: maxCount = number of people we’ve seen whose *Favorite Genre* is Romance = 0
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/9fb65207d90bd1fcf4fcf48b643dad3f.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
- en: Similar to the first row, the encoded value for the second row is 0.05.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b6f7671b1ac8f12379905d2f8cea4179.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
- en: 'For the third row:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2cbee4234edaaf7c76e6b4778325a9d3.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
- en: curCount = the number of people we’ve seen before who were in Rating Bucket
    1, and whose *Favorite Genre* is Mystery = 0
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: maxCount = number of people we’ve seen whose *Favorite Genre* is Mystery = 1
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/409cb30218c155c4830f2b314eb71574.png)![](../Images/2aa547853d29b41deb21a2bf8a82c94a.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, if we do this encoding on the remaining rows, we get:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/10d86e8ec9402e1c178d66fb72194878.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: And that’s how we encode the categorical variables.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '*For now we can ignore* Favorite Genre *and* *only consider* Encoded Favorite
    Genre*.*'
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/21320ee5485dd467020e897543f7e5b5.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
- en: 'Step 2: Make an Initial Prediction and Calculate Residuals'
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CatBoost starts by making an initial *Murder, She Texted Rating* prediction
    of 0 for all rows.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8747b4f8eeb4b88cfead29e1a783cf14.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
- en: 'Then we calculate something called *Residuals* using this formula:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c6bd701d470fd6eae8b4b258cd9dfdf8.png)![](../Images/a41ea969c224c398b316e1aaba0bd77b.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c6bd701d470fd6eae8b4b258cd9dfdf8.png)![](../Images/a41ea969c224c398b316e1aaba0bd77b.png)'
- en: 'Step 3: Build a CatBoost Tree'
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3步：构建CatBoost树
- en: Now that we have the *Residuals*, we can start to build a CatBoost tree. It
    might be useful to read my previous article on [Decision Trees](https://medium.com/towards-artificial-intelligence/decision-tree-classification-explain-it-to-me-like-im-10-59a53c0b338f)
    and [XGBoost](/xgboost-regression-explain-it-to-me-like-im-10-2cf324b0bbdb) to
    give you some context on decision trees.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了*残差*，可以开始构建CatBoost树了。阅读我之前的文章[决策树](https://medium.com/towards-artificial-intelligence/decision-tree-classification-explain-it-to-me-like-im-10-59a53c0b338f)和[XGBoost](/xgboost-regression-explain-it-to-me-like-im-10-2cf324b0bbdb)可能会对你理解决策树有所帮助。
- en: Find a root node
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查找根节点
- en: We determine the best threshold for the tree's root (first split) by comparing
    how well the tree splits using *Favorite Genre* (encoded) vs. *Average Goodreads
    Rating* as a root node.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过比较使用*最喜欢的类型*（编码）与*平均Goodreads评分*作为根节点的效果，确定树根（第一次拆分）的最佳阈值。
- en: 'First, we need to identify candidate nodes for splitting the tree based on
    *Favorite Genre*. To do this, we must sort the values of *Favorite Genre* in ascending
    order:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要根据*最喜欢的类型*确定拆分树的候选节点。为此，我们必须将*最喜欢的类型*的值按升序排序：
- en: '![](../Images/5a6c438f0d3125de551c4aed441a40bf.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5a6c438f0d3125de551c4aed441a40bf.png)'
- en: 'Then we calculate the average values of the adjacent values in *Favorite Genre*:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们计算*最喜欢的类型*中相邻值的平均值：
- en: '![](../Images/796720c7845e64378510fcbbb335075e.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/796720c7845e64378510fcbbb335075e.png)'
- en: Our candidate values for *Favorite Genre* splits are these averages — 0.0375,
    0.05, 0.2875, and 0.525.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的*最喜欢的类型*拆分候选值是这些平均值——0.0375、0.05、0.2875和0.525。
- en: 'The first candidate we try is *Favorite Genre* < 0.0375:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尝试的第一个候选是*最喜欢的类型* < 0.0375：
- en: '![](../Images/9bdb564e41316c713a7195889703ef2f.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9bdb564e41316c713a7195889703ef2f.png)'
- en: 'The leaves of the tree are green. CatBoost initializes something called the
    ***Output*** of the leaves of the split to be 0:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 树的叶节点是绿色的。CatBoost初始化了一个叫做***输出***的东西，将拆分的叶节点设置为0：
- en: '![](../Images/42d7021ec137fbb16a3f12aea41a96ab.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/42d7021ec137fbb16a3f12aea41a96ab.png)'
- en: If *Favorite Genre* is less than 0.0375, we end up in the left leaf; otherwise,
    we end up in the right leaf. **When each row of data is run down the tree, its
    *Residuals* are put in the leaves.**
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果*最喜欢的类型*小于0.0375，我们会落在左叶节点；否则，我们会落在右叶节点。**当每行数据传递到树中时，其*残差*被放入叶节点。**
- en: So running the first row down the tree…
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 所以将第一行数据传递到树中……
- en: '![](../Images/1b875d99ecf6d9107f3bff61c90c2a02.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1b875d99ecf6d9107f3bff61c90c2a02.png)'
- en: '…we put its *Residual* in the right leaf because *Favorite Genre* is 0.05,
    which is greater than 0.0375:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ……我们将其*残差*放入右叶节点，因为*最喜欢的类型*为0.05，大于0.0375：
- en: '![](../Images/ca72d1f992c33cb4b1af5c6e9a3e9b7b.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ca72d1f992c33cb4b1af5c6e9a3e9b7b.png)'
- en: 'Then we keep track of the ***Leaf Output*** for that row:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们跟踪该行的***叶节点输出***：
- en: '![](../Images/fb75c779519cdfd4743056f14b1a7826.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fb75c779519cdfd4743056f14b1a7826.png)'
- en: '**Then we update the value of the *Output* in the tree to the average of the
    *Residual* values in the leaf**. In this case, since there is only one *Residua*l
    in the leaf, the *Output* is 3.5.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**然后我们将树中*输出*的值更新为叶节点中*残差*值的平均值**。在这种情况下，由于叶节点中只有一个*残差*，*输出*为3.5。'
- en: '![](../Images/b932a580dc8e30883590848321f71c49.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b932a580dc8e30883590848321f71c49.png)'
- en: 'Now running the second row down the tree:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在将第二行数据传递到树中：
- en: '![](../Images/a7eb2b6e489293b8603db9c07c0092d9.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a7eb2b6e489293b8603db9c07c0092d9.png)'
- en: 'We put its *Residual* in the right leaf too because 0.05 > 0.0375:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也将其*残差*放入右叶节点，因为0.05 > 0.0375：
- en: '![](../Images/7e2b3bdd0c16bd6df682293ba3fc52f5.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7e2b3bdd0c16bd6df682293ba3fc52f5.png)'
- en: the Residual ends up in the right leaf
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 残差最终落在右叶节点
- en: 'We store the *Leaf Output* value:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们存储*叶节点输出*值：
- en: '![](../Images/41541c18516b2910614038ce7c834704.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/41541c18516b2910614038ce7c834704.png)'
- en: 'And we update the *Output* value by taking the average of the two *Residuals*
    in the leaf:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们通过计算叶节点中两个*残差*的平均值来更新*输出*值：
- en: '![](../Images/5d555d4f7cf7fef58404281f60c22368.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d555d4f7cf7fef58404281f60c22368.png)'
- en: 'right output: 3.5 => 3'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 正确输出：3.5 => 3
- en: 'Now let’s pass the third row down the tree:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们传递第三行数据：
- en: '![](../Images/1ab28b48f6daeb1f9fbf54c630cc098e.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1ab28b48f6daeb1f9fbf54c630cc098e.png)'
- en: the Residual ends up in the left leaf because Favorite Genre = 0.025 < 0.0375
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 残差最终落在左叶节点，因为*最喜欢的类型* = 0.025 < 0.0375
- en: 'Keep track of the Leaf Output:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪叶节点输出：
- en: '![](../Images/62764dc182503cf534b4235e21ba9b00.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/62764dc182503cf534b4235e21ba9b00.png)'
- en: 'And update the *Output* value of the leaf:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 更新叶节点的*输出*值：
- en: '![](../Images/ab01c17043a1ff7df275f99f9eb7fa62.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ab01c17043a1ff7df275f99f9eb7fa62.png)'
- en: 'left output: 0 => 4'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧输出：0 => 4
- en: Finally, let's run the last 3 rows down the tree. We end up with this tree…
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们将最后三行运行在树上。我们得到这棵树…
- en: '![](../Images/1c90b4f76df8c5bbf7490fc7369ebf96.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1c90b4f76df8c5bbf7490fc7369ebf96.png)'
- en: '…and this table:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: …以及这张表：
- en: '![](../Images/6b3595ec9b2a061597dea373c0e428b7.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6b3595ec9b2a061597dea373c0e428b7.png)'
- en: final table with the leaf output values stored
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 存储了叶节点输出值的最终表
- en: Quantify how “good” this root node is
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 量化这个根节点的“好坏”
- en: 'CatBoost quantifies how good the split is by calculating the **Cosine Similarity**
    between the *Leaf Output* column and the *Residuals.* The formula for Cosine Similarity
    is:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: CatBoost 通过计算 *叶节点输出* 列和 *残差* 之间的 **余弦相似度** 来量化划分的好坏。余弦相似度的公式是：
- en: '![](../Images/b758000f9b4ccdd9a13b7c8a8cbe34b2.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b758000f9b4ccdd9a13b7c8a8cbe34b2.png)'
- en: where A and B are just two columns we’re trying to compare.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 A 和 B 只是我们试图比较的两列。
- en: So to calculate the Cosine Similarity of *Residuals* and *Leaf Output* column…
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 所以要计算 *残差* 和 *叶节点输出* 列的余弦相似度…
- en: '![](../Images/7fede8d0042253d68388c8f642b4cabd.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7fede8d0042253d68388c8f642b4cabd.png)'
- en: '…we put the corresponding values in the formula:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: …我们将相应的值代入公式：
- en: '![](../Images/e6991312e230417efe561eb29e8bc54b.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e6991312e230417efe561eb29e8bc54b.png)'
- en: And we find Cosine Similarity = 0.786\. Thus, the Cosine Similarity for the
    threshold *Favorite Genre* < 0.0375 is 0.786.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现余弦相似度为0.786。因此，阈值 *Favorite Genre* < 0.0375 的余弦相似度为0.786。
- en: 'Now using the same process as above, we build a tree using the second candidate
    for root threshold: *Favorite Genre* < 0.05\. If we repeat the same process, we
    end up with this tree:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在使用与上述相同的过程，我们构建一个使用第二个候选根阈值的树：*Favorite Genre* < 0.05。重复相同的过程，我们得到这棵树：
- en: '![](../Images/0a6e5c34e3f81e3e8795109bc5f34afc.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0a6e5c34e3f81e3e8795109bc5f34afc.png)'
- en: '…and this table:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: …以及这张表：
- en: '![](../Images/6b3595ec9b2a061597dea373c0e428b7.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6b3595ec9b2a061597dea373c0e428b7.png)'
- en: '…with Cosine Similarity:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: …余弦相似度为：
- en: '![](../Images/e6991312e230417efe561eb29e8bc54b.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e6991312e230417efe561eb29e8bc54b.png)'
- en: 'NOTE: This is the same value as what we got using the threshold Favorite Genre
    < 0.0375 because the Residuals land up in the same leaves.'
  id: totrans-114
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意：这与我们使用阈值 Favorite Genre < 0.0375 得到的值相同，因为残差落在相同的叶节点中。
- en: 'Let’s try the next root threshold candidate: *Favorite Genre* < 0.2875\. We
    get the tree:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试下一个根阈值候选项：*Favorite Genre* < 0.2875。我们得到的树是：
- en: '![](../Images/0bfa58a56ee63c5503c54eaf09a5e06c.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0bfa58a56ee63c5503c54eaf09a5e06c.png)'
- en: '…and this table:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: …以及这张表：
- en: '![](../Images/314ee4a554be4df79d2cac63f5698d87.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/314ee4a554be4df79d2cac63f5698d87.png)'
- en: …and with Cosine Similarity of *Residuals* and *Leaf Outputs* = 0.84\. Here
    because the Cosine Similarity is greater than that of the other 2 thresholds,
    we conclude that *Favorite Genre* < 0.2875 is a better root split than *Favorite
    Genre* < 0.0375 and *Favorite Genre* < 0.05.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: …并且*残差*和*叶节点输出*的余弦相似度为0.84。在这里，由于余弦相似度大于其他两个阈值的相似度，我们得出结论：*Favorite Genre* <
    0.2875 是比 *Favorite Genre* < 0.0375 和 *Favorite Genre* < 0.05 更好的根节点划分。
- en: 'Now, we for the last split: *Favorite Genre* < 0.525\. We get a Cosine Similarity
    of 0.84, which leads us to conclude that the splits on 0.2875 and 0.525 perform
    similarly.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们来进行最后的划分：*Favorite Genre* < 0.525。我们得到余弦相似度为0.84，这使我们得出结论：0.2875 和 0.525
    的划分效果相似。
- en: '**But remember we only tested *Favorite Genre* candidates.** Next, we need
    to test *Average Goodreads Rating* root candidates. And to do that, we need to
    identify our candidates for *Average Goodreads Rating* splits by arranging the
    columns in ascending order and calculating the adjacent averages.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '**但请记住，我们只测试了 *Favorite Genre* 的候选项。** 接下来，我们需要测试 *Average Goodreads Rating*
    的根节点候选项。为此，我们需要通过将列按升序排列并计算相邻的平均值来确定 *Average Goodreads Rating* 的划分候选项。'
- en: '![](../Images/41539fdbfb4b69ad185af39079f62eef.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/41539fdbfb4b69ad185af39079f62eef.png)'
- en: 'For each average, we build a tree and calculate the Cosine Similarity between
    *Leaf Outputs* and *Residuals*:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每一个平均值，我们构建一棵树并计算 *叶节点输出* 和 *残差* 之间的余弦相似度：
- en: '![](../Images/3f0b9ad16151c29c7f41dc34a0a9025c.png)![](../Images/bba15e4479a706106ae39ec5d56f256c.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3f0b9ad16151c29c7f41dc34a0a9025c.png)![](../Images/bba15e4479a706106ae39ec5d56f256c.png)'
- en: Comparing the Cosine Similarity values of all candidate root nodes, we find
    that the Cosine Similarity of *Average Goodreads Rating* < 3.65 has the highest
    value of 0.87\. ***So we choose this to be our root node split***
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 比较所有候选根节点的余弦相似度值，我们发现*Average Goodreads Rating* < 3.65 的余弦相似度最高，为0.87。***所以我们选择这个作为我们的根节点分割***
- en: '![](../Images/fb93d8b8c5e712f4662c12e27ed9b4da.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fb93d8b8c5e712f4662c12e27ed9b4da.png)'
- en: After obtaining the root node, we can expand the tree by adding new branches.
    To do this, we follow a similar process as before, but instead of selecting a
    root node, we select a branch that splits off from the leaves. And the split that
    has the highest Cosine Similarity values is chosen.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 获得根节点后，我们可以通过添加新分支来扩展树。为此，我们遵循与之前类似的过程，但不是选择根节点，而是选择从叶子处分裂出来的分支。选择具有最高余弦相似度值的分割。
- en: The caveat with CatBoost trees is that they are **symmetric**, meaning each
    branch on the same level uses the exact same threshold.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: CatBoost树的一个注意事项是它们是**对称**的，意味着同一层上的每个分支使用相同的阈值。
- en: 'NOTE: If you’re curious about why we build symmetric trees, you can read about
    it here.'
  id: totrans-129
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意：如果你对为什么要构建对称树感到好奇，你可以在这里阅读更多内容。
- en: 'So an example of one will be:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 一个示例是：
- en: '![](../Images/507a5887462399a52ce966d0b725e512.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/507a5887462399a52ce966d0b725e512.png)'
- en: In this case, both the nodes at the same level use the same split.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，同一层的两个节点使用相同的分割。
- en: '**Since we have so little data let’s just stick to building trees of *depth*
    1.**'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '**由于我们数据很少，最好只构建*深度*为1的树。**'
- en: 'NOTE: Tree depth is a parameter in the model that we can tune mainly to avoid
    overfitting. In most cases, the optimal depth ranges from 4 to 10 and values in
    the range from 6 to 10 are recommended.'
  id: totrans-134
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意：树的深度是我们可以调整的模型参数，主要用于避免过拟合。在大多数情况下，最佳深度范围是4到10，建议使用6到10的值。
- en: And just like that, we have our first tree!
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样，我们有了第一棵树！
- en: '![](../Images/fb93d8b8c5e712f4662c12e27ed9b4da.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fb93d8b8c5e712f4662c12e27ed9b4da.png)'
- en: 'Step 4: Make New Predictions'
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 步骤4：进行新的预测
- en: 'Now we make new predictions using the old predictions and this formula:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用旧的预测和这个公式进行新的预测：
- en: '![](../Images/99fb411bfaa145d53d7c84f3629377d5.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/99fb411bfaa145d53d7c84f3629377d5.png)'
- en: Learning Rate is another parameter we can tune to avoid overfitting. Read more
    about it [here](https://catboost.ai/en/docs/concepts/parameter-tuning#learning-rate).
    For now, let’s set it to 0.1.
  id: totrans-140
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 学习率是另一个我们可以调整以避免过拟合的参数。有关更多信息，请阅读[这里](https://catboost.ai/en/docs/concepts/parameter-tuning#learning-rate)。现在，让我们将其设置为0.1。
- en: Let’s go back to our table.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到我们的表格。
- en: '![](../Images/d075595c7df737e2682dd53565f7846d.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d075595c7df737e2682dd53565f7846d.png)'
- en: 'Using the formula, we can calculate the new predictions. For the first row,
    the new prediction will be:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 使用公式，我们可以计算新的预测。对于第一行，新预测将是：
- en: '![](../Images/02271e7805d5148232a2ef8e5916a429.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02271e7805d5148232a2ef8e5916a429.png)'
- en: 'Similarly, if we calculate the new predictions for the rest of the rows we
    get:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，如果我们计算其余行的新预测值，我们得到：
- en: '![](../Images/7d63ed1ceb790270c0f6daf906398519.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7d63ed1ceb790270c0f6daf906398519.png)'
- en: We can see that our new predictions are not very accurate as they still differ
    significantly from the actual rating of *Murder, She Texted*. However, they are
    an improvement from the old predictions of all zeros.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到我们的新预测不够准确，因为它们与*Murder, She Texted*的实际评分仍然有显著差异。然而，相比于之前全为零的预测，已有所改善。
- en: Our next step is to build a new tree. But before doing that let’s quickly clean
    up our noisy dataset a bit so it's easier to work with. We can ignore the old
    predictions, *Residual* column*,* and *Leaf Output* column…
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的下一步是构建一棵新树。但在此之前，让我们先快速清理一下嘈杂的数据集，以便更容易处理。我们可以忽略旧的预测、*残差*列和*叶子输出*列…
- en: '![](../Images/53f928b746767db6e48d196b68d88361.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/53f928b746767db6e48d196b68d88361.png)'
- en: …rename the New Prediction column to just Prediction (because it's not new anymore)
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: …将“新预测”列重命名为“预测”（因为它不再是新的了）
- en: '![](../Images/fde9138a3fa83550f4cda02ed9880093.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fde9138a3fa83550f4cda02ed9880093.png)'
- en: '…and replace the values of *Encoded Favorite Genre* with our original *Favorite
    Genre*:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: …并将*编码的最喜欢的类型*的值替换为我们原始的*最喜欢的类型*：
- en: '![](../Images/4abfda0867ff7456ad5b5d5dd5510708.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4abfda0867ff7456ad5b5d5dd5510708.png)'
- en: 'Step 5: Build a New Tree Using Steps 1–4'
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 步骤5：使用步骤1-4构建新树
- en: Now we repeat the same process that we did to build our first tree to build
    a second one.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们重复构建第一棵树时所做的相同步骤来构建第二棵树。
- en: Using **Step 1**, we shuffle the dataset…
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**步骤1**，我们打乱数据集…
- en: '![](../Images/c83e5aea29777c5e33adc2d86bc5e666.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c83e5aea29777c5e33adc2d86bc5e666.png)'
- en: '…and encode the categorical data (aka *Favorite Genre*) using ordered target
    encoding:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: …并使用有序目标编码对类别数据（即*最喜欢的类型*）进行编码：
- en: '![](../Images/f049664482780c62269ae8a5e4b4ae17.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f049664482780c62269ae8a5e4b4ae17.png)'
- en: 'Following **Step 2**, since we already have our prediction, we don’t need to
    make initial predictions. All we do is calculate *Residuals* using the same formula
    we saw above:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 按照**步骤 2**，因为我们已经有了预测，所以不需要进行初步预测。我们只需使用上述相同的公式计算*残差*：
- en: '![](../Images/c6bd701d470fd6eae8b4b258cd9dfdf8.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c6bd701d470fd6eae8b4b258cd9dfdf8.png)'
- en: 'We get the following *Residuals*:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下*残差*：
- en: '![](../Images/9dfbc683d842378fe8af9f32ced84236.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9dfbc683d842378fe8af9f32ced84236.png)'
- en: 'Then we build our second CatBoost tree using **Step 3**. Let’s assume after
    testing all the *Encoded Favorite Genre* and *Average Goodreads Rating* candidates,
    we find the perfect root node to be *Encoded Favorite Genre* < 0.288\. Since the
    tree has a depth of 1, as previously set, we end up with a tree like this:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用**步骤 3**构建第二棵 CatBoost 树。假设在测试所有*编码后的最喜欢类型*和*平均 Goodreads 评分*候选项后，我们找到的最佳根节点是*编码后的最喜欢类型*
    < 0.288。由于树的深度为 1，如之前设置的，我们最终得到这样的树：
- en: '![](../Images/385ce155f75ddaf83bf30ef920f2bb5e.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/385ce155f75ddaf83bf30ef920f2bb5e.png)'
- en: '…and an updated table with *Leaf Outputs*:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: …以及带有*叶节点输出*的更新表：
- en: '![](../Images/0e2356c3dcce2c3f6878bd2624d69eca.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0e2356c3dcce2c3f6878bd2624d69eca.png)'
- en: Finally, using **Step 4**, we make new predictions. So using this formula…
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用**步骤 4**，我们进行新的预测。使用这个公式…
- en: '![](../Images/e51bae503102a30335792b46a038d7c8.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e51bae503102a30335792b46a038d7c8.png)'
- en: '…we get new predictions:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: …我们得到新的预测：
- en: '![](../Images/11c92f867be7ef476a1b2257f7526ed7.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/11c92f867be7ef476a1b2257f7526ed7.png)'
- en: We can see here that the new predictions are slightly better than the old ones.
    And if we continue this process and continue building more trees, our predictions
    get better and better.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，新预测稍微比旧的预测更好。如果我们继续这个过程并构建更多的树，我们的预测会越来越好。
- en: 'NOTE: We continue building trees until our predictions are good, or until we
    hit the [number of trees](https://catboost.ai/en/docs/concepts/parameter-tuning#trees-number)
    parameter value, which we can set.'
  id: totrans-173
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意：我们继续构建树，直到我们的预测足够好，或者直到达到我们可以设置的[树的数量](https://catboost.ai/en/docs/concepts/parameter-tuning#trees-number)参数值。
- en: Making Predictions with Our CatBoost Trees
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用我们的 CatBoost 树进行预测
- en: Let’s assume we finished our model building process with just these 2 trees
    we have above. (by default CatBoost builds 1000). We now have a CatBoost model
    (obviously this isn’t going to be close to a good one because we only have 2 trees)
    with which we can start making predictions.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们用上面这两棵树完成了模型构建过程。（默认情况下，CatBoost 构建 1000 棵树）。我们现在有一个 CatBoost 模型（显然，由于我们只有
    2 棵树，它不会接近一个好的模型），我们可以开始进行预测。
- en: '![](../Images/c66ca15a7158e1905443bb054a305f75.png)![](../Images/4e50dbaa79bc535b8ab600ae46a5dce1.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c66ca15a7158e1905443bb054a305f75.png)![](../Images/4e50dbaa79bc535b8ab600ae46a5dce1.png)'
- en: Now using our model, we want to predict how these 2 people are going to rate
    *Murder, She Texted*.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在使用我们的模型，我们想要预测这两个人会如何评分*Murder, She Texted*。
- en: '![](../Images/10b9ef99a8857830a7043297cef4a0e7.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/10b9ef99a8857830a7043297cef4a0e7.png)'
- en: To begin, we need to encode the categorical data — *Favorite Genre*. The process
    of encoding new data is similar to how we encoded the training data; the only
    difference is that we use the entire training dataset for encoding.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要对类别数据进行编码——*最喜欢的类型*。编码新数据的过程类似于我们编码训练数据的方式；唯一的区别是我们使用整个训练数据集进行编码。
- en: '![](../Images/7dbaa66e0419d5e90a96994fd0f1b5c5.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7dbaa66e0419d5e90a96994fd0f1b5c5.png)'
- en: 'Assign *Murder, She Texted Rating* to the same Rating Buckets we used before:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 将*Murder, She Texted Rating*分配到之前使用的相同评分桶中：
- en: '![](../Images/c4103a4f4674cbe3224526772d650db4.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c4103a4f4674cbe3224526772d650db4.png)'
- en: 'Now we use this same formula as above to do the encoding:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用上述相同的公式进行编码：
- en: '![](../Images/f00774f8ae88fdff2c6e5f5fe27e1de8.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f00774f8ae88fdff2c6e5f5fe27e1de8.png)'
- en: 'However, we use the entire training dataset instead of doing it sequentially
    as we did during the training process. So for instance, the encoding for *Favorite
    Genre* Mystery will be:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们使用整个训练数据集，而不是像训练过程中那样按顺序处理。例如，*最喜欢的类型*为神秘剧的编码将是：
- en: '![](../Images/6c95bf934515217ab774f8e5268f21c3.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6c95bf934515217ab774f8e5268f21c3.png)'
- en: 'Similarly, the encoding for the other *Favorite Genre*’s are:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，其他*最喜欢的类型*的编码是：
- en: '![](../Images/be385c4c6161a16d6264e3f2ab69d660.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/be385c4c6161a16d6264e3f2ab69d660.png)'
- en: 'We substitute the encoded values in the new dataset:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在新数据集中替换了编码值：
- en: '![](../Images/56b3f0578bd11aeee67e0c34b366270a.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/56b3f0578bd11aeee67e0c34b366270a.png)'
- en: 'So now for the first person, we go back to our trees and pass the data down
    them:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 现在对于第一个人，我们回到我们的树，并将数据传递下去：
- en: '![](../Images/a72f9274575a8c90784790d854dcc4b0.png)![](../Images/b59d60cb740b98379db4bccba8eb2199.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a72f9274575a8c90784790d854dcc4b0.png)![](../Images/b59d60cb740b98379db4bccba8eb2199.png)'
- en: 'Then we use this formula to make our prediction:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用这个公式来进行预测：
- en: '![](../Images/06c17cc32df80ac060ead79bc18ec843.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/06c17cc32df80ac060ead79bc18ec843.png)'
- en: 'So our prediction is:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们的预测是：
- en: '![](../Images/0f4ea8b76f9bcb57185cf725e8f2fef6.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0f4ea8b76f9bcb57185cf725e8f2fef6.png)'
- en: Granted, this is a terrible prediction. But remember this is a pretty terrible
    model. The more trees we have, the better our model is going to perform.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这是一个糟糕的预测。但请记住，这是一个相当糟糕的模型。我们拥有的树越多，我们的模型表现就会越好。
- en: 'Similarly, for the second person:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，对于第二个人：
- en: '![](../Images/bf079eb8c12398b3f4fe66b42d8402b8.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bf079eb8c12398b3f4fe66b42d8402b8.png)'
- en: And that’s about it. That’s how we build CatBoost trees and use them to make
    predictions on new data!
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 就这些了。这就是我们如何构建CatBoost树并利用它们对新数据进行预测！
- en: Unless otherwise noted, all images are by the author
  id: totrans-201
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 除非另有说明，所有图片均由作者提供
- en: You can connect with me on [LinkedIn](https://www.linkedin.com/in/shreyarao24/)
    or email me at *shreya.statistics@gmail.com* to send me questions and suggestions
    for any other algorithms that you want illustrated!
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过[LinkedIn](https://www.linkedin.com/in/shreyarao24/)与我联系，或者通过*shreya.statistics@gmail.com*发送电子邮件给我，提出问题和建议，尤其是对任何你希望我讲解的其他算法！
