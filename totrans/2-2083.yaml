- en: The Urgent Need for Responsible Use of Generative AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式人工智能负责任使用的紧迫性
- en: 原文：[https://towardsdatascience.com/the-urgent-need-for-responsible-use-of-generative-ai-d3134605267f](https://towardsdatascience.com/the-urgent-need-for-responsible-use-of-generative-ai-d3134605267f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-urgent-need-for-responsible-use-of-generative-ai-d3134605267f](https://towardsdatascience.com/the-urgent-need-for-responsible-use-of-generative-ai-d3134605267f)
- en: Why scale, personalisation, unclear provenance, and diffusion of AI-generated
    content require us to act now
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么规模、个性化、来源不明和生成内容的传播要求我们立即行动
- en: '[](https://heiko-hotz.medium.com/?source=post_page-----d3134605267f--------------------------------)[![Heiko
    Hotz](../Images/d08394d46d41d5cd9e76557a463be95e.png)](https://heiko-hotz.medium.com/?source=post_page-----d3134605267f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d3134605267f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d3134605267f--------------------------------)
    [Heiko Hotz](https://heiko-hotz.medium.com/?source=post_page-----d3134605267f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://heiko-hotz.medium.com/?source=post_page-----d3134605267f--------------------------------)[![Heiko
    Hotz](../Images/d08394d46d41d5cd9e76557a463be95e.png)](https://heiko-hotz.medium.com/?source=post_page-----d3134605267f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d3134605267f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d3134605267f--------------------------------)
    [Heiko Hotz](https://heiko-hotz.medium.com/?source=post_page-----d3134605267f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d3134605267f--------------------------------)
    ·6 min read·Aug 7, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d3134605267f--------------------------------)
    ·阅读时间 6 分钟·2023年8月7日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/f73c65500922a3b7db0293a32e36c03e.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f73c65500922a3b7db0293a32e36c03e.png)'
- en: Photo by [Google DeepMind](https://unsplash.com/@googledeepmind?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Google DeepMind](https://unsplash.com/@googledeepmind?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: What is this about?
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 这是什么内容？
- en: “Why do you think responsible Generative AI (GenAI) is important and urgent?”
    This is a question being posed today by policymakers, researchers, journalists,
    and concerned citizens alike. Rapid progress in GenAI has captured public imagination,
    but also raised pressing ethical questions. Models like ChatGPT, Bard, and Stable
    Diffusion showcase the creative potential of the technology — but in the wrong
    hands, these same capabilities could foster disinformation and manipulation at
    unprecedented scale. Unlike previous technologies, GenAI enables the creation
    of highly personalised, context-specific synthetic media that is difficult to
    verify as fake. This poses novel societal risks and complex governance challenges.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: “你认为负责任的生成式人工智能（GenAI）为什么重要且紧迫？”这是政策制定者、研究人员、记者和关注的公民们今天提出的问题。生成式人工智能的快速进展吸引了公众的想象力，但也提出了紧迫的伦理问题。像
    ChatGPT、Bard 和 Stable Diffusion 这样的模型展示了技术的创造潜力——但在错误的手中，这些相同的能力可能会在前所未有的规模上滋生虚假信息和操控。与以往的技术不同，生成式人工智能使得创造高度个性化、特定背景的合成媒体成为可能，这些媒体很难被验证为虚假。这带来了新的社会风险和复杂的治理挑战。
- en: In this blog post I will dive into four aspects (Scale & Speed, Personalisation,
    Provenance, Diffusion) that distinguish this new age of GenAI from previous times
    and highlight why this now is the right time to look into the ethical and responsible
    use of AI. In this piece, I aim to answer the question “Why now?” by highlighting
    the critical aspects. Potential solutions will be explored in a subsequent article.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我将深入探讨四个方面（规模与速度、个性化、来源不明、传播）来区分这个新纪元的生成式人工智能（GenAI）与以往的时代，并强调为什么现在是关注人工智能伦理和负责任使用的正确时机。在这篇文章中，我旨在通过突出关键方面来回答“为什么是现在？”这个问题。潜在的解决方案将在随后的文章中探讨。
- en: Why is it important?
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么这很重要？
- en: Responsible GenAI is not just a hypothetical concern relevant to tech experts.
    It’s an issue that affects all of us as citizens navigating an increasingly complex
    information ecosystem. How can we maintain trust and connection in a world where
    our eyes and ears can be deceived? If anyone can produce compelling yet completely
    fabricated realities, how does society arrive at shared truths? Unchecked, the
    misuse of GenAI threatens foundational values like honesty, empathy, and human
    dignity. But if we act collectively and quickly to implement ethical AI design,
    we can instead realise generative technology’s immense potential for creativity,
    connection, and social good. By speaking up and spreading awareness, we can influence
    the trajectory of AI in a more aligned direction.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 负责任的GenAI不仅仅是一个与技术专家相关的假设性问题。这是一个影响我们所有公民的问题，我们在日益复杂的信息生态系统中航行。我们如何在一个我们的眼睛和耳朵可能被欺骗的世界中保持信任和联系？如果任何人都可以制作引人注目却完全虚假的现实，社会如何达成共享的真理？如果不加以控制，GenAI的滥用将威胁到诚信、同情和人类尊严等基础价值观。但如果我们迅速而集体地实施伦理AI设计，我们可以实现生成技术在创造力、联系和社会公益方面的巨大潜力。通过发声和传播意识，我们可以影响AI的发展方向。
- en: Scale and Speed
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 规模和速度
- en: Generative models enable creation of realistic fakes at staggering scale, with
    unprecedented speed and ease. A single person can generate endless customised
    audio, video, images and text just with simple prompts and clicks. This introduces
    an entirely new level of efficiency and throughput for manufacturing manipulated
    content. Teams of human trolls cannot compete with AI systems that churn out endless
    tailored fakes around the clock. With enough computing power, bad actors could
    flood social networks and completely dominate authentic voices via sheer artificial
    volume. As generative models become more accessible and convincing, orchestrating
    mass-scale misinformation campaigns no longer requires much expertise or resources.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型使得以惊人的规模、前所未有的速度和简易性创建逼真的虚假内容成为可能。一个人只需简单的提示和点击即可生成无尽的定制音频、视频、图像和文本。这引入了制造操控内容的全新效率和产量水平。人类团队无法与全天候生成无尽定制虚假内容的AI系统竞争。只要有足够的计算能力，恶意行为者就可以通过纯粹的人工虚假量淹没社交网络，完全主导真实的声音。随着生成模型变得更易获得和更具说服力，组织大规模虚假信息活动不再需要太多专业知识或资源。
- en: This is not a new phenomenon, of course. Twitter bots, for example, have been
    around for quite some time, and they roughly account for [25% of all tweets](https://www.businessinsider.com/twitter-bots-comprise-less-than-5-but-tweet-more-2022-9),
    namely [~215 million tweets per day](https://www.businessdit.com/number-of-tweets-per-day/).
    But as GenAI improves, distinguishing between bot-generated and human content
    will become increasingly challenging.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这当然不是一个新现象。例如，Twitter机器人已经存在相当长时间，它们大约占所有推文的[25%](https://www.businessinsider.com/twitter-bots-comprise-less-than-5-but-tweet-more-2022-9)，即[每天约2.15亿条推文](https://www.businessdit.com/number-of-tweets-per-day/)。但随着GenAI的进步，区分机器人生成内容和人类内容将变得越来越具有挑战性。
- en: Personalisation
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 个性化
- en: GenAI can craft content tailored precisely to exploit an individual’s vulnerabilities
    and experiences. This enables psychological manipulation more powerful than blanket
    misinformation. Hyper-targeted fakes designed to resonate with personal context
    subvert human discourse by destroying notions of shared truth and reality. When
    any person can be fed their own unique set of AI-fabricated “facts”, how can society
    arrive at consensus? Such personalisation risks driving polarisation and tribalism,
    eroding empathy and connection between groups.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI可以制作精准利用个体脆弱性和经历的内容。这使得心理操控比泛泛的虚假信息更为强大。设计得极具个人背景共鸣的虚假信息通过破坏共享的真理和现实观念来颠覆人类话语。当任何人都可以被灌输自己独特的一套AI制造的“事实”时，社会如何达成共识？这种个性化风险会导致两极化和部落主义，侵蚀群体之间的同情心和联系。
- en: 'This, of course, is a hot topic in light of the upcoming 2024 US election.
    For example, in May 2023, [Donald Trump shared a doctored video of CNN anchor
    Anderson Cooper](https://news.yahoo.com/trump-shares-fake-video-anderson-145621081.html)
    on his social media platform Truth Social. Reuters puts it poignantly [when they
    say](https://www.reuters.com/article/usa-election-ai-idCAKBN2XL0IS):'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这当然是在即将到来的2024年美国大选背景下的热门话题。例如，在2023年5月，[特朗普在他的社交媒体平台Truth Social上分享了一段伪造的视频](https://news.yahoo.com/trump-shares-fake-video-anderson-145621081.html)，该视频中是CNN主播安德森·库珀。路透社深刻地[指出](https://www.reuters.com/article/usa-election-ai-idCAKBN2XL0IS)：
- en: Welcome to America’s 2024 presidential race, where reality is up for grabs.
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 欢迎来到美国2024年总统竞选，这里的现实似乎变得难以把握。
- en: Provenance
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 来源
- en: Unlike earlier technologies such as Photoshop, verifying generative fakes through
    forensic analysis is extremely challenging. The obfuscated provenance grants bad
    actors plausible deniability and freedom to erode notions of objective truth.
    Even diligent individuals cannot realistically verify provenance of all generative
    content they encounter. This asymmetry enables misinformation even when generative
    content is not convincingly realistic upon close inspection.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 与早期的Photoshop等技术不同，通过法医分析验证生成伪造品极为困难。模糊的来源使恶意行为者获得了似是而非的辩解权和侵蚀客观真理的自由。即使是尽职尽责的人也难以实际验证他们遇到的所有生成内容的来源。这种不对称性使得即使生成内容在仔细检查时不够逼真，也能传播虚假信息。
- en: In 2022, [a deepfake video](https://www.npr.org/2022/03/16/1087062648/deepfake-video-zelenskyy-experts-war-manipulation-ukraine-russia)
    was created that appeared to show Ukrainian President Volodymyr Zelenskyy surrendering
    to Russian forces. The video was shared widely on social media, and it led to
    some people believing that Zelenskyy had actually surrendered. The obfuscated
    provenance of the video made it difficult to determine whether it was real or
    fake, and even diligent individuals would have had a hard time verifying its provenance.
    The ambiguity of the video’s origin allowed it to circulate widely, even if some
    might find its authenticity questionable upon detailed viewing.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在2022年，[一段深度伪造的视频](https://www.npr.org/2022/03/16/1087062648/deepfake-video-zelenskyy-experts-war-manipulation-ukraine-russia)被制作出来，似乎显示了乌克兰总统泽连斯基向俄罗斯军队投降。这段视频在社交媒体上广泛传播，导致一些人相信泽连斯基实际上已经投降。视频模糊的来源使得判断其真实性变得困难，即使是尽职尽责的人也很难验证其来源。视频来源的模糊性使得它能够广泛传播，即使有些人可能会在详细查看时质疑其真实性。
- en: Diffusion
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩散
- en: Once highly realistic fakes are produced by generative models, they can spread
    rapidly via social networks, messaging apps, and other digital platforms.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦由生成模型制作的高度逼真的伪造品出现，它们可以通过社交网络、消息应用和其他数字平台迅速传播。
- en: 'While this connects to the “Scale and Speed” section, it’s crucial to look
    at this from a different perspective: Deepfakes are often designed to be emotionally
    engaging. They may show people doing or saying things that are shocking, scandalous,
    or otherwise attention-grabbing. This makes them more likely to be shared on social
    media, where people are constantly looking for new and interesting content. The
    more people who see a deepfake, the more likely it is that someone will believe
    it is real. Even though each individual fake may not fool careful scrutiny, at
    scale the sheer volume of diffusion can overwhelm efforts to track and counter
    misinformation. Virality gives generative fakes a reach and impact that are challenging
    to rein in once they are out “in the wild”. Platforms already struggle with moderating
    simpler forms of misinformation — content created by GenAI raises the bar even
    higher.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这与“规模与速度”部分相关，但从不同角度看这个问题至关重要：深度伪造通常设计得很具情感吸引力。它们可能展示令人震惊、丑闻性的或其他引人注目的内容。这使得它们更容易在社交媒体上被分享，在那里，人们不断寻找新的有趣内容。看到深度伪造的人越多，越有可能有人相信它是真的。即使每个单独的伪造品可能无法欺骗仔细的审查，但大规模传播的数量会压倒追踪和反击虚假信息的努力。病毒式传播赋予生成伪造品一种难以控制的传播范围和影响力。一旦它们“在野外”传播，平台已经难以处理更简单的虚假信息——由生成AI创建的内容则更高难度。
- en: 'To give a concrete example: In March 2023, an AI-generated photo of Pope Francis
    went viral on social media with [one tweet](https://twitter.com/singareddynm/status/1639655045875507201)
    amassing nearly 21 million views — it even received the nickname [“Balenciaga
    Pope”](https://www.forbes.com/sites/danidiplacido/2023/03/27/why-did-balenciaga-pope-go-viral/).
    According to the [New York Post](https://nypost.com/2023/05/11/google-to-label-ai-generated-images-as-viral-trump-deepfake/)
    the artist who created the image did not enjoy the publicity at all, quite the
    opposite:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 举一个具体的例子：在2023年3月，一张AI生成的教皇方济各的照片在社交媒体上病毒式传播，[一条推文](https://twitter.com/singareddynm/status/1639655045875507201)获得了近2100万次观看——它甚至获得了[“巴伦西亚教皇”](https://www.forbes.com/sites/danidiplacido/2023/03/27/why-did-balenciaga-pope-go-viral/)的昵称。根据[纽约邮报](https://nypost.com/2023/05/11/google-to-label-ai-generated-images-as-viral-trump-deepfake/)的报道，创作该图像的艺术家对这些关注并不感兴趣，恰恰相反：
- en: Pablo Xavier, the AI artist who allegedly generated the image, claimed that
    he “didn’t want it [the pictures] to blow up like that” and admitted it’s “definitely
    scary” that “people are running with it and thought it was real without questioning
    it.”
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 被指生成该图片的AI艺术家Pablo Xavier表示，他“并不希望[这些图片]如此轰动”，并承认“人们在不加质疑的情况下认为它是真的，这确实令人害怕。”
- en: Conclusion
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: These unprecedented capabilities — scale & speed, personalisation, obfuscated
    provenance, and diffusion — fundamentally transform the nature of misinformation
    in a way that demands urgent debate. How do we deal with a technology that enables
    gaslighting people en masse and destroying consensus reality? What governance
    is needed to maintain trust and truth in online discourse? Can we rein in harmful
    applications of GenAI while nurturing beneficial ones? There are no easy answers,
    but having earnest discussions now is critical to steer this technology toward
    ethical outcomes.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这些前所未有的能力——规模与速度、个性化、模糊来源和扩散——从根本上改变了虚假信息的性质，迫切需要辩论。我们如何应对一种能够大规模操控人们并摧毁共识现实的技术？需要什么治理措施才能在在线话语中保持信任和真相？我们能否遏制生成AI的有害应用，同时培养有益的应用？没有简单的答案，但现在进行诚恳的讨论对将这项技术引向伦理结果至关重要。
- en: The stakes could not be higher when it comes to preserving human agency, dignity,
    and our shared reality in an AI-driven world. As generative models become more
    powerful and accessible, we need ethical guardrails and smart governance to prevent
    dystopian outcomes. There is urgency to act quickly and thoughtfully — before
    hypothetical risks become reality through automation and diffusion of AI manipulation.
    The window to shape the future of GenAI in a just, beneficial direction is now.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个由人工智能驱动的世界中，维护人类自主权、尊严和我们共享的现实是至关重要的。随着生成模型变得越来越强大和易于获得，我们需要伦理性护栏和智能治理，以防止反乌托邦的结果。必须迅速而深思熟虑地采取行动——在假设性风险通过自动化和人工智能操控扩散成现实之前。现在是塑造生成AI未来的最佳时机，以实现公正和有益的方向。
- en: Heiko Hotz
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Heiko Hotz
- en: 👋 Follow me on [Medium](https://heiko-hotz.medium.com/) and [LinkedIn](https://www.linkedin.com/in/heikohotz/)
    to read more about Generative AI, Machine Learning, and Natural Language Processing.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 👋 在[Medium](https://heiko-hotz.medium.com/)和[LinkedIn](https://www.linkedin.com/in/heikohotz/)关注我，阅读更多关于生成AI、机器学习和自然语言处理的内容。
- en: 👥 If you’re based in London join one of our [NLP London Meetups](https://www.meetup.com/nlp_london/).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 👥 如果你在伦敦，请加入我们的[NLP London Meetups](https://www.meetup.com/nlp_london/)。
- en: 📔 My thoughts on AI News on [😇 Naughty Neural](https://naughtyneural.net/).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 📔 我对AI新闻的看法在[😇 Naughty Neural](https://naughtyneural.net/)。
- en: '![](../Images/33b1525d9317ce4918a46789999f97ee.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/33b1525d9317ce4918a46789999f97ee.png)'
- en: Image by author
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
