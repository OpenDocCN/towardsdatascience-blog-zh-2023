# ToolFormer：指导AI模型使用外部工具

> 原文：[https://towardsdatascience.com/toolformer-guiding-ai-models-to-use-external-tools-37e4227996f1](https://towardsdatascience.com/toolformer-guiding-ai-models-to-use-external-tools-37e4227996f1)

## Meta的LLM自学调用外部API

[](https://medium.com/@nikoskafritsas?source=post_page-----37e4227996f1--------------------------------)[![Nikos Kafritsas](../Images/de965cfcd8fbd8e1baf849017d365cbb.png)](https://medium.com/@nikoskafritsas?source=post_page-----37e4227996f1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----37e4227996f1--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----37e4227996f1--------------------------------) [Nikos Kafritsas](https://medium.com/@nikoskafritsas?source=post_page-----37e4227996f1--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----37e4227996f1--------------------------------) ·阅读时长14分钟·2023年10月23日

--

![](../Images/180485d9bb3167a1e863f926c118935d.png)

作者使用Midjourney创建的图像

**现在尘埃落定，LLMs的弱点已被揭示。**

即便是强大的GPT-4在数学运算方面也有困难。

此外，训练截止时间是每个LLM的固有弱点。它们在回答新事物时会遇到困难。

一个临时解决方案是使用外部插件（例如ChatGPT插件）。然而，用户仍需手动指定某些操作，这些插件有时也不够可靠。

如果有一个模型知道自己的弱点，并且经过训练可以在不确定时**本地**调用最佳外部工具，那会怎么样？

这就是Meta所做的，通过创建**ToolFormer[1]**。在这篇文章中，我们讨论：

+   什么是ToolFormer，为什么它是一个突破？

+   模型如何运作。

+   ToolFormer的方法论如何应用于任何LLM。

+   为什么人工智能研究朝着ToolFormer的愿景发展。

让我们深入了解一下。

# 大型语言模型的弱点

在开始描述ToolFormer之前，让我们探讨一下现代LLMs面临的问题：

+   **时间进展：** 每个LLM都有一个训练截止日期。因此，它们无法访问最新信息和最近事件。

+   **不准确的事实：** LLMs以编造事实、地点、事件、产品，甚至研究论文而闻名。

+   **算术运算：** LLMs在数学计算方面存在困难。

+   **稀有语言：** LLMs无法处理资源匮乏的语言，通常是由于缺乏训练数据。

显然，这些问题与语言机制无关。理想的解决方案是将文本生成与外部工具结合起来。

这就引出了ToolFormer。

# 什么是ToolFormer？

> ToolFormer是一个LLM，经过训练以决定何时调用哪些API，以及传递哪些参数来调用它们。

ToolFormer令人惊叹的原因是：

+   **两全其美：** ToolFormer是一种LLM，类似于GPT-3。但在不确定的情况下，它会学习调用外部API，从而避免常见错误。

+   **可移植性：** 训练ToolFormer的方法可以应用于任何LLM。

+   **卓越性能：** ToolFormer虽然体积较小，但其性能超过了更大的模型，如OPT和GPT-3。

+   **开源：** 尽管Meta尚未发布原始版本，但社区已经创建了[一些很棒的开源实现](https://github.com/xrsrke/toolformer)。

ToolFormer提供以下工具。这些工具在**图1**中展示：

![](../Images/774f968cd54d92335dba8f79c75c1d56.png)

**图1：** ToolFormer自主调用外部API以获取准确的信息并完成输出文本（突出显示）。从上到下，API包括：问答系统、计算器、机器翻译系统和维基百科搜索引擎。 ([来源](https://arxiv.org/pdf/2302.04761.pdf))

根据**图1**，ToolFormer提供：

+   **QA：** 一个问答系统

+   **计算器**

+   **MT：** 一个机器翻译系统

+   **WikiSearch：** 一个维基百科搜索引擎API

+   **日历：** 一个返回当前日期的日历API（**图1**中未显示）

**ToolFormer如何生成文本** 在每种情况下，模型决定调用哪个API以及使用什么参数。像`**QA**`和`**Calculator**`这样的工具名称是特殊的标记。

![](../Images/d6abda84152483aabd12c17572da1263.png)

如果模型生成`**Calculator**(400/1400)`，那么模型准备调用**Calculator API**，参数为`(400/1400)`。

`**->**`标记表示模型接下来期望API调用的响应。

当发生这种情况时，解码（推断）被中断，模型将相应API的答案放入其中。然后，解码继续进行（如有必要），直到答案完整（*…通过测试。*）。

# ToolFormer的构建方法

是时候深入技术细节了。

ToolFormer的关键创新不是基础的预训练模型，而是用于训练的数据集，特别是作者增强数据集的**独特方式**。

从根本上说，ToolFormer是一个**GPT-J**预训练模型：

> ToolFormer，一个小型的预训练**GPT-J** 6.7B模型，在众多任务上优于更大的GPT-3和OPT。

作者使用了CCNet训练数据集的一个子集（简称**C**）。然后，他们通过API调用增强了这个数据集，并称之为**C***。

![](../Images/4df20583ef9593c2e37d622a69e4bb2c.png)

**图2：** 针对QA工具的训练示例增强（作者图片）

> 将C增强为C*的过程是ToolFormer的真正创新；这个数据集可以用来教任何模型如何有效地使用API调用。

然而，增强训练数据集并不是一件容易的事。我们将在接下来讨论这一点。

# 增强训练数据集

这是最关键的部分。作者在这里有三个目标：

1.  **无人工干预。** 我们不期望有人手动执行**图 2**中显示的过程。

1.  **高质量数据：** 增强应对模型有意义且有帮助。例如，增强：**匹兹堡也被称为 [QA: (*匹兹堡的特点是什么？* -*> 钢铁*)] 钢铁城** 是错误的且不具意义。

1.  **无损广泛性：** 使用新数据集，ToolFormer 仍将作为 LLM 运行（能够最佳预测下一个词）。

现在，是时候放大**图 2**并揭示数据集**C**和数据集**C***之间的中间步骤了。

更详细的视图见**图 3：**

![](../Images/8fac962f59a9d4e0c8511b9351428cf8.png)

**图 3：** 对 QA 工具的训练示例`**x**`进行增强的全部 3 个步骤。 ([来源](https://arxiv.org/pdf/2302.04761.pdf))

有 3 个步骤——让我们逐一分解它们。给定一个句子`**x**`，我们有：

+   **采样 API 调用：** 采样句子`**x**`中可能用于 API 调用的位置`**i**`。然后，生成样本候选 API 调用 **[**`**c1**`**,**`**c2**`**..**`**ck**`**]**

+   **执行 API 调用：** 执行这些 API 调用，并获取响应 **[**`**r1**`**,**`**r2**`**..**`**rk**`**]**

+   **过滤 API 调用：** 不是所有的对 (`ci`-> `ri`) 都是有用或正确的。我们过滤掉那些不会降低下一个令牌的损失函数 L 的 API 调用。

如果你没有完全理解这些步骤，不用担心。在下一部分，我们将深入探讨每一步。

# 步骤 1：采样 API 调用

在这一步，我们从数据集**C**生成可能的 API 调用。

先决条件是 i) 无人工干预和 ii) API 调用应尽可能有意义。

自动化此任务的最佳方法是让 GPT-J 模型自行进行标注！

具体来说，我们将编写一个包含指令和几个示例的提示`P(x)`——并鼓励模型为句子`**x**`标注 API 调用。对于 QA 工具，作者使用了以下提示：

![](../Images/06e38268a69aa487779eb41d57f1b8b3.png)

**图 4：** 生成 QA 工具 API 调用的提示 P(x) 示例。 ([来源](https://arxiv.org/pdf/2302.04761.pdf))

> **注意：** 在提示中包含几个示例以帮助模型更好地理解给定任务的过程称为***上下文学习。***

但请记住，语言模型容易产生幻觉或错误——这就是为什么我们需要**步骤 3**中的过滤过程。

接下来，让我们检验一下**步骤 1**在实践中的运作方式：

+   我们将使用**图 4**中的提示`P(x)`来标注句子`**x**`并生成一些候选 API 调用。

+   让我们尝试句子`**x**`= **匹兹堡也被称为钢铁城。**

![](../Images/755138fc16feccfd26552786bdd678cd.png)

**图 5：** 使用句子`**x**`=**匹兹堡也被称为钢铁城。** 作为输入的候选 API 调用示例。（作者提供的图像）

我们得到了 3 个注释句子作为输出。显然，只有第二个候选 API 调用在这里是有意义的。

这一步的目的是在没有人工干预的情况下生成多个注释句子。我们稍后会解决如何筛选出不正确的句子。

> **注意：** 作者在这里也施加了最小的过滤过程，以节省成本。有关更多信息，请查看文章末尾的**附录**。

# 步骤 2：执行 API 调用

这很简单——根据**步骤 1**中的候选调用，我们请求 API 响应：

![](../Images/52f9439b605ad59c9ff52722f7364d92.png)

**图 6：** 在步骤 2 中，我们获取每个候选调用的响应，关于 QA 工具（图片由作者提供）

实际上，并不是所有情况下都有实际的 API——除了**计算器**和**日历**情况，这些是简单的脚本。

对于其他情况，作者使用了专门的语言模型。例如，对于 QA 工具，他们使用 Atlas（Izacard 等，2022），这是一个在自然问题上微调的检索增强型语言模型。

可以查看论文以获取每个工具的更多详细信息。

# 步骤 3：过滤 API 调用

虽然**步骤 1**生成了大量 API 调用，但**步骤 3**只保留了有意义的调用。

> 有意义的 API 调用：**那些** **提高模型调用外部 API 的能力**。

这一改进通过一个损失函数和一个公式来衡量——称为**有用性比率**。

整个过程展示在**图 7**中：

目标是检查以下示例是否足够有意义以包含在增强**C***数据集中：

![](../Images/1343abd93ade940fa614900934b827cb.png)

**图 7：** 有用性比率决定了一个增强候选句子是否对模型有用（图片由作者提供）

让我们分析一下发生了什么：

我们计算每个案例的*负对数似然*，作为短语**“钢铁城”**的前缀：

+   **无 API：** 我们计算`p(钢铁城 | **匹兹堡也被称为** )`。在这里，我们对模型的帮助不大——这就是损失高的原因。

+   **仅输入：** 我们计算`p(钢铁城 | **匹兹堡也被称为[QA(“匹兹堡还有什么名字？“)->?]** )`

+   **完整的 API：** 我们计算`p(钢铁城 | **匹兹堡也被称为[QA(“匹兹堡还有什么名字？“)->钢铁城]** )`

完整的 API 案例最有帮助。此外，前缀包含了正确的答案‘**钢铁城**’。这就是我们在这里获得最低损失的原因！

然而，我们必须量化一个注释的有用性。这里引入了***有用性比率***。比率越高，注释对训练 ToolFormer 的帮助越大。

在**图 7**中，我们达到了高的有用性比率，因此我们的注释示例`[**匹兹堡也被称为[QA … 城市]**]`进入了增强数据集**C*。

## 有用性比率的作用

现在，考虑一下：

像 GPT-4 这样更强大的模型可能知道 Pittsburgh 也被称为“钢铁之城”。在这种情况下，**No API** 的损失会较低，并且与 **Full API** 的情况几乎相似。这会导致有用性比例接近 0。

但由于 GPT-J 是较小的模型，它不知道答案。

因此，GPT-J 模型通过对注释示例 `**Pittsburgh is..city**` 进行微调受益，而 **GPT-4** 则不受益。可能，GPT-4 需要更复杂的示例。

> 因此，ToolFormer 的训练过程可以应用于任何语言模型——得益于 3 步流程和有用性比例公式。

## 一个拒绝示例

请记住，对于我们的情况，我们采样了 3 次 API 调用（**图 5**）。只有第 2 次是有意义的——其他 2 次应被拒绝。

让我们看一个拒绝示例。我们将使用以下 API 调用作为示例（**图 5** 中的第 1 个）：

`Pittsburgh 也被称为 **[QA（Pittsburgh 属于哪个州？）-> Pensylvania]** 钢铁之城**。**`

![](../Images/1897151bb19ad6d1206ad48acd2f6bfc.png)

**图 8：** 在这里，注释示例对我们的模型没有帮助（作者提供的图像）

在这里，我们为一个完全无关的问题发出 API 调用——“*Pittsburgh 属于哪个州*”。这对我们的模型回答“*Pittsburgh 还有什么别名*”没有帮助。

因此，我们得到较高的损失，这意味着负有用性比例。因此，该注释的 API 调用未被插入 **C*** 数据集中。

## 有用性比例的阈值 τf

到目前为止一切顺利，但一个示例的有用性比例应达到多高才能被认为有意义——并符合进入 C* 的条件？

作者通过实验找到这个阈值 `τf`——考虑到不同有用性比例下 **C*** 中每个类别的训练示例数量。结果如 **图 9** 所示：

![](../Images/833a96c425054100381372709c5813af.png)

**图 9：** 不同有用性比例阈值下 **C∗** 中具有 API 调用的示例数量。

显然，通过增加阈值 `τf`，进入 **C* 的示例数量会减少。

然而，**机器翻译** 和 **计算器** 示例比其他类别少。因此，为了避免严重的不平衡，作者设定：

+   对于 **QA**、**Wiki 搜索** 和 **日历**，`τf = 1`

+   对于 **机器翻译** 和 **计算器**，`τf = 0.5`

# 最终步骤：微调 ToolFormer

增强数据集 **C*** 现在已经准备好了。

我们对 **C*** 微调 GPT-J——然后，瞧，我们得到了 **ToolFormer！**

微调是简单的。作者使用 ***困惑度*** 作为微调目标。

> **困惑度** 是评估语言模型不确定性的标准指标。例如，困惑度为 32 意味着模型在预测下一个词时的确定性相当于抛一个 32 面的骰子。因此，值越低越好。

# 评估

接下来，作者评估 ToolFormer。

总体而言，作者使用了以下模型：

+   **GPT-J：** 原始的 GPT-J 预训练模型。

+   **GPT-J on C：** 这里，GPT-J 在 **C** 数据集（没有 API 调用的数据集）上进行了微调。

+   **ToolFormer：** GPT-J 模型在 **C** 数据集上进行了微调。

+   **ToolFormer（禁用）：** ToolFormer，但使用 API 调用已被禁用。（这是通过将推理过程中生成 `**[**` 令牌的概率设置为零来实现的）

目标是评估模型在每个单独任务中的表现：QA、计算器、日历等。我们开始吧：

# QA 评估（LAMA 基准）

作者在 [LAMA 基准](https://github.com/facebookresearch/LAMA) 的 3 个子集上评估了 ToolFormer：

*SQuAD*、*Google-RE* 和 *T-REx*。

对于这些子集，每项任务都是用缺失的事实来完成一个简短的陈述——例如`相对论的理论是由 ___ 发展起来的`，模型应该填写正确的事实。

该基准测试的结果显示在 **图 10** 中。

> **注意：** 以下的性能评分代表了每个数据集评估的不同指标。为了避免细节问题，考虑到 **分数越高越好**。这在本文中的其他基准测试中也适用。

![](../Images/118bc395fb10e87ed755288b753f5b96.png)

**图 10：** ToolFormer 在 LAMA 基准上的表现。 ([来源](https://arxiv.org/pdf/2302.04761.pdf))

结果特别有趣：ToolFormer 在所有基准测试中都**超越**了更大的 OPT 和 GPT-3。

ToolFormer 的力量来自于其在挑战性情况下调用外部 API 的能力。

具体来说，模型决定在 **98.1%** 的情况下调用 QA API。只有极少数的例子中，它使用了其他工具 **(0.7%)** 或根本不使用任何工具 **(1.2%)**。

# 计算器评估（数学基准）

![](../Images/e7165f857045bdb8928835b11d9bc8f4.png)

**图 11：** ToolFormer 在数学基准测试中的表现。 ([来源](https://arxiv.org/pdf/2302.04761.pdf))

+   ToolFormer 再次大幅超越 OPT 和 GPT-3。

+   模型在 97.9% 的情况下决定调用计算器 API。

# 维基搜索评估（搜索基准）

在这里，ToolFormer **不是最好的模型：**

![](../Images/7d4774b195d4404259186f446533bfa2.png)

**图 12：** ToolFormer 在搜索基准测试中的表现。 ([来源](https://arxiv.org/pdf/2302.04761.pdf))

ToolFormer 超越了 OPT，但输给了 GPT-3。作者提供了以下原因：

+   ToolFormer 仅在 **Wikipedia** 上进行 Wiki 工具搜索，而不是整个 Web（GPT-3 在大量在线内容上进行了训练）。

+   如果 ToolFormer 能够调用 QA 工具，它将超越 GPT-3。作者故意禁用了 QA 工具——因为用于训练 QA 系统的数据集与这些基准中的数据可能存在重叠。

+   在 **Wiki Tool** 之上需要一个额外的层——以重新表述返回的结果并提供更清晰的答案。

# 翻译评估（MLQA 基准）

在这里，结果非常有趣：

![](../Images/3f5cf87ad826a54e8fd97641da4b10d1.png)

**图 13:** ToolFormer 在翻译基准测试中的表现。 ([来源](https://arxiv.org/pdf/2302.04761.pdf))

ToolFormer 在所有语言中（除了与 GPT-3 的中文）都轻松超越了 OPT 和 GPT-3。

然而，ToolFormer 被原始的 GPT-J 超越。作者解释这是因为 GPT-J 也在多语言数据上进行了预训练——而 **C** 只有很少的多语言示例。

# **日历评估（时间数据集）**

最后，我们评估了 ToolFormer 提取日期和最新信息的能力。

作者使用了 2 个数据集：

+   **TempLAMA**: 包含随时间变化的遮蔽数据（例如，“基利安·姆巴佩为 ___ 球队效力”）

+   **DATESET:** 包含有关日期的随机查询（例如：“30 天前是星期几？”）

**图 14** 显示了结果：

![](../Images/76744b4e274f4bddabbbd5d2f8e2a285.png)

**图 14:** ToolFormer 在时间基准测试中的表现。 ([来源](https://arxiv.org/pdf/2302.04761.pdf))

再次，ToolFormer 超越了更大的模型。在 **DATESET** 中差异巨大——这是预期中的，因为找出日期是大型语言模型的固有弱点。

# **扩展法则**

训练大型语言模型的一个重要部分是训练模型是否遵循扩展法则。

> 扩展法则是描述语言模型参数大小、令牌（数据集大小）、训练时间和性能之间关系的经验法则。

扩展法则首次在 [2] 中提出，但后来在 [3] 中重新审视，Deepmind 的研究人员发现许多语言模型显著欠训练。

在这里，作者探索了 ToolFormer 的扩展能力，与基准测试中的其他模型进行比较。结果见 **图 15:**

![](../Images/059a380ad0f792baf659516cbd0affc4.png)

**图 15:** ToolFormer 与 GPT3 在 LAMA、数学和 QA 基准测试中的表现，按模型大小划分。虽然 API 调用对最小模型没有帮助，但较大的模型学会了如何有效利用它们 ([来源](https://arxiv.org/pdf/2302.04761.pdf))

显然，ToolFormer 展现出了优良的扩展性——遵循扩展法则。

较小的模型（少于 775M 参数）实现了类似的性能——它们通过调用外部 API 并没有获得优势。参数大小超过 775M 后，ToolFormer 开始显著扩展。

# **解码策略**

ToolFormer 的一个有趣之处在于作者如何实施解码策略。

实际上，`**[**` 是一个特殊的令牌——表示 API 调用的开始。

在词生成过程中，语言模型计算词汇表中每个令牌的概率，并生成 **概率最高的那个**（我大致解释一下）。这称为贪婪解码。

作者通过实验发现，如果在前 `**k**=10` 个最可能的令牌中生成 `**[**`，而不是在最可能的令牌（`k=1`）中生成，ToolFormer 的表现更好。

参数 `**k=10**` 是通过实验发现的。结果见 **图 16:**

![](../Images/08ac48f2e95b50b4c858e2c91229567c.png)

**图16：** ToolFormer在T-REx的LAMA和WebQS子集上的结果，展示了不同k值在解码过程中使用的情况。（[来源](https://arxiv.org/pdf/2302.04761.pdf)）

显然，当`**k**=10`时，模型的表现最好，平均而言。**图16**仅显示了2个数据集。然而，这种模式在其他基准测试中也适用。

# 工具LLMs生态系统

ToolFormer使用外部API来解决数学和推理问题。但这些问题也可以通过其他方法解决。

最流行的方法称为**“思维链”**[4]：

> 在“思维链”中，LLM学会将提示分解为中间步骤——逐步解决每个步骤后再给出最终答案。

在这里，我们不调用外部API。而是教模型将提示分解为更小的部分——这有助于模型进行算术任务。一个示例显示在**图17**中：

![](../Images/0a5fcd3a9b57b307071ccdd89af506b2.png)

**图17：** 使用思维链提示（右）模型可以找出正确答案。思维链推理过程用绿色突出显示[[Wei et al.](https://arxiv.org/pdf/2201.11903.pdf)]

**“思维链”**范式在最新的研究中得到了改进。

**程序辅助语言模型**（PAL）**[5]**通过将提示分解为文本中间步骤和Python代码（**图18**）获得了更好的结果：

![](../Images/9c4ecec1f8d7bf9dd83b8a6bacc7e907.png)

**图18：** **思维链**（左）给出了错误的答案，而**PAL**（右）是正确的。PAL结合了思维链推理（用蓝色标记）和编程注释（用粉色标记）[[Luyu Gao et al.]](https://arxiv.org/pdf/2211.10435.pdf)

最后，我们可以使用LangChain，一个用于LLMs的应用框架。Langchain使用代理与各种搜索API集成，能够在网络上进行搜索。**图19**展示了SerpAPI工具：

![](../Images/e6bf672cea31edf8bbe011451479ff8e.png)

**图19：** 我们可以指示语言模型使用API进行网络搜索，并将搜索结果整合到提示中，从而获得正确的答案。（[来源](https://python.langchain.com/docs/integrations/tools/serpapi)）

**ToolFormer和Langchain代理之间有什么区别？**

+   Langchain代理首先必须使用适当的API（由人类指定），然后将结果与提示结合以获得正确答案。

+   相比之下，ToolFormer被**明确训练**用于调用和整合API工具（无需人工干预）。

# 结语

本文探讨了ToolFormer，这是一种能够调用外部工具的模型。

从本质上讲，ToolFormer是一个可以教任何LLM调用外部API的过程。

随着LLMS的采用，调用外部资源的必要性将变得显而易见。即使是ChatGPT现在也允许用户用来自网络的搜索结果丰富他的提示。

# 感谢阅读！

我每月撰写一次对有影响力的 AI 论文的深入分析。

**保持联系！**

+   在 [Linkedin](https://www.linkedin.com/in/nikos-kafritsas-b3699180/) 上关注我！

+   订阅我的新闻通讯，[**AI Horizon Forecast**](https://aihorizonforecast.substack.com)！

[](https://aihorizonforecast.substack.com/?source=post_page-----37e4227996f1--------------------------------) [## AI Horizon Forecast | Nikos Kafritsas | Substack

### 以清晰明了的方式解释复杂的 AI 模型。专注于时间序列和最新的 AI 研究。点击阅读 AI…

[aihorizonforecast.substack.com](https://aihorizonforecast.substack.com/?source=post_page-----37e4227996f1--------------------------------)

# 附录

> 作者还在数据增强过程的第一步上施加了最小化筛选过程，以节省成本。例如，没有用特殊标记 `***[QA..***` 等注释的句子会被拒绝进入下一步。
> 
> 此外，作者计算了句子中最可能引发 API 调用的位置。符号`***[***`***,*** `***]***`也是特殊标记，表示 API 调用的开始和结束。
> 
> 因此，作者计算了位置 `***i***`，其中标记 `***[***` 出现的概率最高。因此，只有在 API 调用的开始（标记 `***[***`）生成在最可能位置 `***i***` 的句子会被传递到下一步。

# 参考文献

[1] Timo Schick 等人 [*Toolformer: Language Models Can Teach Themselves to Use Tools*](https://arxiv.org/pdf/2302.04761.pdf)

[2] Jared Kaplan 等人 [*Scaling Laws for Neural Language Models*](https://arxiv.org/pdf/2001.08361.pdf)

[3] Jordan Hoffmann 等人 [*Training Compute-Optimal Large Language Models*](https://arxiv.org/pdf/2203.15556.pdf)

[4] Jason Wei 等人 [*Chain-of-Thought Prompting Elicits Reasoning in Large Language Models*](https://arxiv.org/pdf/2201.11903.pdf) *(2023年1月)*

[5] Luyu Gao 等人 [*PAL: Program-aided Language Models*](https://arxiv.org/pdf/2211.10435.pdf) *(2023年1月)*
