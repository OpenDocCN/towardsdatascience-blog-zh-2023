- en: Tuning RL HyperParameters with Hydra's Optuna sweeper
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/easily-tune-rl-hyperparameters-with-hydras-optuna-sweeper-1cb816db302](https://towardsdatascience.com/easily-tune-rl-hyperparameters-with-hydras-optuna-sweeper-1cb816db302)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Configure your Stable-Baselines3 tuning pipeline with ease using Hydra and Optuna
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://marc-velay.medium.com/?source=post_page-----1cb816db302--------------------------------)[![Marc
    Velay](../Images/ef35818b774bacf6739cfdd51d851549.png)](https://marc-velay.medium.com/?source=post_page-----1cb816db302--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1cb816db302--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1cb816db302--------------------------------)
    [Marc Velay](https://marc-velay.medium.com/?source=post_page-----1cb816db302--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1cb816db302--------------------------------)
    ·8 min read·Feb 1, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement Learning (RL) agents are very susceptible to their hyperparameters.
    The same agent can go from utterly worthless after training to the top of the
    leaderboard with the correct hyperparameters! Yet finding the correct combination
    can be very time-consuming or even futile without the right tools. The main goal
    of this article is to share with you *how* you can tune your RL hyperparameters
    through some theory and application.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: 'You can catch the code for this project on my [GitHub](https://github.com/Marc-Velay/hydra_optuna_tutorial):
    fork me!'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/287f7595e51b7ca3130686d9eb26f4db.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
- en: Photo by [Leonel Fernandez](https://unsplash.com/@leonelfdez?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reinforcement Learning is a type of Machine Learning that involves training
    agents to interact with an environment. Agents make sequences of actions, following
    strategies that dictate how they should react in each situation. They aim to maximize
    the rewards they accumulate by interacting with the environment and slowly learning
    the best actions from experience. In a [previous post](https://velaylearning.com/markov-decision-process-in-plain-english/),
    I go into more depth about the concepts of Reinforcement Learning.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: RL algorithms rely on MANY hyperparameters, some for learning, some for the
    underlying Neural Networks. There are many levers to make learning more stable,
    faster, or save some memory. Just by looking at a widespread [implementation of
    SAC](https://stable-baselines3.readthedocs.io/en/master/modules/sac.html), from
    stable-baselines3, they have 25 parameters, most of which depend on your own use
    case and contribute to the success of optimizing a strategy.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: This difficulty is attracting a lot of attention, with recent popular answers
    to the problem from the likes of [Google's research team](https://github.com/google-research/tuning_playbook).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这个难题吸引了很多关注，最近来自 [Google 的研究团队](https://github.com/google-research/tuning_playbook)
    的热门答案对此进行了探讨。
- en: The breadth of the search space requires you to systematically sweep the combinations
    of hyperparameters to find the best combination to optimize the agent's performance.
    This is done by training the agent with a set of hyperparameters and evaluating
    the average reward obtained from validation episodes. The sweep requires knowing
    the useful range or values of all parameters, creating the agent and its models,
    and then training them enough to see if learning converges.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索空间的广度要求你系统地遍历超参数的组合，以找到优化代理性能的最佳组合。这通过使用一组超参数训练代理，并评估从验证回合中获得的平均奖励来完成。扫频需要知道所有参数的有效范围或值，创建代理及其模型，然后进行足够的训练，以查看学习是否收敛。
- en: '![](../Images/77aeb4319101b87d3c473b267d54189d.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/77aeb4319101b87d3c473b267d54189d.png)'
- en: Two combinations of HPs lead to very different outcomes, image by the author.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 两种超参数组合导致截然不同的结果，作者提供了图像。
- en: With such a complex setup, you can not hard-code parameters in your python code.
    It would help if you had a modular framework to handle configurations and, for
    a cherry on top, that abstracts the sweeping procedure.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 由于设置如此复杂，你不能在 Python 代码中硬编码参数。你需要一个模块化框架来处理配置，并且最好能抽象出整个过程。
- en: Introducing Hydra
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入 Hydra
- en: '[Hydra](https://hydra.cc/) is a library from the Facebook Research team designed
    for managing complex applications, including Machine Learning pipelines. It shines
    in its configuration flexibility and modularity. By design, you separate the different
    components and can switch them out from yaml config files. It has made it much
    easier to experiment with different learning algorithms, models, settings, and
    environments. Storing my setup in static config files means I can share them with
    my team, and they can repeat the experiment in the same conditions.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[Hydra](https://hydra.cc/) 是 Facebook Research 团队设计的一个库，用于管理复杂的应用程序，包括机器学习管道。它在配置灵活性和模块化方面表现出色。通过设计，你可以分离不同的组件，并从
    yaml 配置文件中替换它们。这使得实验不同的学习算法、模型、设置和环境变得更容易。将我的设置存储在静态配置文件中意味着我可以与团队共享，它们可以在相同条件下重复实验。'
- en: Hydra uses a combination of command line options, hierarchical configuration
    files, and some code to manage the components of your pipeline.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Hydra 使用命令行选项、层级配置文件和一些代码的组合来管理你的管道组件。
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: While the command line can go into a lot of [depth](https://hydra.cc/docs/advanced/hydra-command-line-flags/)
    and has a broad scope, I'll focus on a few ideas. The above command is similar
    to launching your regular ML training script but has a few more parameters. I
    can specify which configuration files I want to use from the command line. These
    are caught in the main function.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管命令行可以深入到很多 [细节](https://hydra.cc/docs/advanced/hydra-command-line-flags/)
    并具有广泛的范围，但我会集中讨论几个想法。上述命令类似于启动常规的 ML 训练脚本，但有更多的参数。我可以从命令行指定要使用哪些配置文件。这些参数会在主函数中捕获。
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'I assume that there is a "configs" folder at the root of my project, specified
    by "config_path" in the Hydra decorator. It contains yaml files describing my
    experiment (default.yaml) and folders for agent and environment configurations.
    These hierarchical files are called from the root and can be passed as attributes:
    in default.yaml, the desired agent is passed as "agent: ddpg" and the content
    of ddpg.yaml is added as a dict to the run''s config.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '我假设在我的项目根目录下有一个由 Hydra 装饰器指定的 "configs" 文件夹。它包含描述我的实验的 yaml 文件（default.yaml）以及用于代理和环境配置的文件夹。这些层级文件从根目录调用，并可以作为属性传递：在
    default.yaml 中，所需的代理被传递为 "agent: ddpg"，ddpg.yaml 的内容作为字典添加到运行的配置中。'
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The base setup to run the experiment in the main config file, called by the
    decorator, only has links to other yaml files containing model and environment
    values.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 运行实验的基本设置在主配置文件中，由装饰器调用，只包含指向其他 yaml 文件的链接，这些文件包含模型和环境值。
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let''s look at the values in ddpg.yaml:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看一下 ddpg.yaml 中的值：
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We access these values in our code as "cfg.agent.*". We can train our model
    using those hyperparameters, with a small setup to translate them into the expected
    parameters for Stable-Baselines3 (SB3).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在代码中通过 "cfg.agent.*" 访问这些值。我们可以使用这些超参数训练我们的模型，并做一些小的设置将其转换为 Stable-Baselines3
    (SB3) 所期望的参数。
- en: 'The parameters are simple floats and strings, while SB3 expects classes or
    instantiated objects. We use some dictionaries to solve this translation. Let''s
    take the example of the model''s activation and noise functions:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 参数是简单的浮点数和字符串，而SB3期望的是类或实例化的对象。我们使用一些字典来解决这种转换。以模型的激活函数和噪声函数为例：
- en: '[PRE6]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Having boilerplate code that translates discrete choices into the expected implementation
    allows us to prepare a broad array of options we can select from. This makes sweeping
    hyperparameters directly from the Hydra configurations easier, especially with
    the hypra-optuna-sweeper plug-in.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有将离散选择转化为预期实现的模板代码，使我们能够准备一系列广泛的选项供选择。这使得从Hydra配置中直接进行超参数调整变得更加容易，特别是使用hypra-optuna-sweeper插件。
- en: Hydra's Optuna Sweeper
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hydra的Optuna Sweeper
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Optuna is an excellent library for automatic parameter optimization. It relies
    on very few components: parameter iteration and evaluation. Optuna gives you a
    set of values to test and expects a score as output, using your pipeline as a
    black box.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Optuna是一个出色的自动参数优化库。它依赖于非常少的组件：参数迭代和评估。Optuna提供了一组值供测试，并期望输出一个分数，使用你的管道作为一个黑箱。
- en: Under the hood, the library uses a few tricks to suggest parameters it estimates
    will have a better outcome, allowing you to save time compared to basic grid searches.
    The usual approach requires implementing Optuna's trials right into your main
    training function, handling search spaces, trials, and pruning yourself. With
    the Hydra approach, most things are abstracted, with only knobs to tune.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在底层，该库使用了一些技巧来建议它估计将有更好结果的参数，使你能够比基本的网格搜索节省时间。通常的方法需要将Optuna的试验直接实现到你的主要训练函数中，自行处理搜索空间、试验和修剪。通过Hydra的方法，大多数事情都是抽象的，只需调整一些参数即可。
- en: 'One of Optuna''s key features is running searches in parallel, which Hydra
    enhances. The two libraries work hand-in-hand: Optuna selects hyperparameters
    to trial, and Hydra efficiently sets up your pipeline. Let''s see how to combine
    the two in your code.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Optuna的一个关键特性是并行运行搜索，Hydra对此进行了增强。这两个库密切配合：Optuna选择要试验的超参数，而Hydra高效地设置你的管道。让我们看看如何在你的代码中结合这两个库。
- en: 'The main changes occur in your Hydra configs, default.yaml:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的变化发生在你的Hydra配置文件default.yaml中：
- en: '[PRE8]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'And you now need to configure your hyperparameters'' search spaces in "agent/search_spaces/ddpg.yaml":'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你需要在"agent/search_spaces/ddpg.yaml"中配置你的超参数搜索空间。
- en: '[PRE9]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Let's walk through those two config files. In the main file, we have added the
    link to the file containing the space Optuna can sweep for each hyperparameter.
    In our case, "${agent}" means that our file has the same name as the agent's configuration
    file, defined above.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看这两个配置文件。在主文件中，我们添加了指向Optuna可以为每个超参数进行调整的空间文件的链接。在我们的例子中，"${agent}"意味着我们的文件与上面定义的代理配置文件同名。
- en: We have a few options to specify which range of values we want to explore for
    each hyperparameter.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有几个选项可以指定我们希望探索的每个超参数的值范围。
- en: '[PRE10]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Choice allows us to select discrete options from a fixed list of values. This
    is perfect for textual or restricting options.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 选择允许我们从固定的值列表中选择离散选项。这对于文本或限制选项非常合适。
- en: The next range specifier is the classic linear interval. A random value will
    be picked inside the interval.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个范围说明符是经典的线性区间。一个随机值将在该区间内被选取。
- en: Finally, when sampling from intervals ranging through multiple orders of magnitude,
    it is interesting to use logarithmic distributions. This is not included by default
    in the hydra-optuna-sweeper plug-in, but you can tag it as such.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，当从跨越多个数量级的区间中抽样时，使用对数分布是有趣的。这在hydra-optuna-sweeper插件中默认不包含，但你可以将其标记为如此。
- en: You can find more use cases directly from the [documentation](https://hydra.cc/docs/1.2/plugins/optuna_sweeper/#search-space-configuration),
    along with some examples.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以直接从[文档](https://hydra.cc/docs/1.2/plugins/optuna_sweeper/#search-space-configuration)中找到更多用例，以及一些示例。
- en: The next step is to specify which sweeper we want Hydra to use. There are plug-ins
    for the Ax, Nevergrad, and Optuna sweepers. We then need to define some custom
    parameters for Optuna, such as the best direction to optimize for our problem.
    In the case of RL, we often desire to maximize rewards. For classic ML problems,
    we'd often want to minimize errors.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是指定我们希望Hydra使用哪个sweeper。对于Ax、Nevergrad和Optuna sweepers有插件。然后我们需要为Optuna定义一些自定义参数，例如优化我们问题的最佳方向。在RL的情况下，我们通常希望最大化奖励。对于经典的机器学习问题，我们通常希望最小化误差。
- en: The number of trials we explore is the total set of hyperparameters we desire
    to test. In this case, we only run 20 combinations for a quick sweep, with a single
    job at a time. The selection of hyperparameters from the sweep will override the
    ones specified in the agent/ddpg.yaml file.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f1dec45cbea8d63b2a603de07b39478a.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
- en: Launching an Optuna trial with sampled hyperparameters, image by author
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: 'This concludes the first component from Optuna: the parameter iteration. Now,
    we need to evaluate it. For this, we exploit Stable-Baseline3''s Callbacks. We
    define "TrialEvalCallback" to run validation sets every N timestep, getting our
    agent''s average performance at a given time.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7a1ecfa1dd40406334e95ad36e505232.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
- en: TrialEvalCallback output during training, image by author
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Once training ends, we return the best average performance our agent has reached
    from the function decorated by Hydra's main. At the end of the sweep, Hydra outputs
    the set of hyperparameters with the best evaluation. Bellow is the best set from
    a sweep of DDPG over the pendulum environment.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ade0cf23770160b1a8dfb5a6c026438f.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
- en: Best hyperparameters found for the Pendulum environment, image by author
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: As an added benefit, SB3 comes with a quick built-in implementation of TensorBoard.
    From the TB dashboard, we can see the combination's relative performance throughout
    their training phases. The best hyperparameters are selected from average performance
    over validation episodes, but you may be interested in further details. Some sets
    may reach plateaus, while others swing back and forth from good to bad.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/75ae92ce145898cd8cbdd06fdc2a7724.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
- en: Multirun comparison inside a sweep, in TensorBoard, image by author
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: In conclusion, we have used Hydra to greatly simplify setting up our Stable-Baselines3
    agent, adding some flexibility and the ability to quickly change components directly
    from yaml files. The added benefit is that you can save past experiments and rerun
    them with the same hyperparameters, or share them with your team.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: While Optuna is traditionally run directly from your main training script, the
    hydra-optuna-sweeper takes the approach of abstracting it. You can launch your
    hyperparameter sweep from your pre-existing configuration, by specifying the search
    spaces alongside your agent parameters. Optuna takes care of the rest, so you
    can focus on your use case.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: I hope you'll have fun with hydra-optuna-sweeper! Find the whole project on
    my [GitHub](https://github.com/Marc-Velay/hydra_optuna_tutorial). Reach out to
    me on [Twitter](https://twitter.com/marc_velay) or [LinkedIn](https://www.linkedin.com/in/marc-velay/).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
