- en: Tuning RL HyperParameters with Hydra's Optuna sweeper
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Hydra 的 Optuna 调优器来调节 RL 超参数
- en: 原文：[https://towardsdatascience.com/easily-tune-rl-hyperparameters-with-hydras-optuna-sweeper-1cb816db302](https://towardsdatascience.com/easily-tune-rl-hyperparameters-with-hydras-optuna-sweeper-1cb816db302)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/easily-tune-rl-hyperparameters-with-hydras-optuna-sweeper-1cb816db302](https://towardsdatascience.com/easily-tune-rl-hyperparameters-with-hydras-optuna-sweeper-1cb816db302)
- en: Configure your Stable-Baselines3 tuning pipeline with ease using Hydra and Optuna
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Hydra 和 Optuna 轻松配置你的 Stable-Baselines3 调优流程
- en: '[](https://marc-velay.medium.com/?source=post_page-----1cb816db302--------------------------------)[![Marc
    Velay](../Images/ef35818b774bacf6739cfdd51d851549.png)](https://marc-velay.medium.com/?source=post_page-----1cb816db302--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1cb816db302--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1cb816db302--------------------------------)
    [Marc Velay](https://marc-velay.medium.com/?source=post_page-----1cb816db302--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://marc-velay.medium.com/?source=post_page-----1cb816db302--------------------------------)[![Marc
    Velay](../Images/ef35818b774bacf6739cfdd51d851549.png)](https://marc-velay.medium.com/?source=post_page-----1cb816db302--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1cb816db302--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1cb816db302--------------------------------)
    [Marc Velay](https://marc-velay.medium.com/?source=post_page-----1cb816db302--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1cb816db302--------------------------------)
    ·8 min read·Feb 1, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1cb816db302--------------------------------)
    ·阅读时间 8 分钟 ·2023 年 2 月 1 日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Reinforcement Learning (RL) agents are very susceptible to their hyperparameters.
    The same agent can go from utterly worthless after training to the top of the
    leaderboard with the correct hyperparameters! Yet finding the correct combination
    can be very time-consuming or even futile without the right tools. The main goal
    of this article is to share with you *how* you can tune your RL hyperparameters
    through some theory and application.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习 (RL) 代理对其超参数非常敏感。相同的代理在训练后可能完全无用，但使用正确的超参数后却能登上排行榜的顶端！然而，找到正确的组合可能非常耗时，甚至在没有合适工具的情况下徒劳无功。本文的主要目标是通过一些理论和应用与您分享
    *如何* 调节您的 RL 超参数。
- en: 'You can catch the code for this project on my [GitHub](https://github.com/Marc-Velay/hydra_optuna_tutorial):
    fork me!'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在我的 [GitHub](https://github.com/Marc-Velay/hydra_optuna_tutorial) 上获取此项目的代码：快来
    fork 吧！
- en: '![](../Images/287f7595e51b7ca3130686d9eb26f4db.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/287f7595e51b7ca3130686d9eb26f4db.png)'
- en: Photo by [Leonel Fernandez](https://unsplash.com/@leonelfdez?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Leonel Fernandez](https://unsplash.com/@leonelfdez?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) 提供
- en: Introduction
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Reinforcement Learning is a type of Machine Learning that involves training
    agents to interact with an environment. Agents make sequences of actions, following
    strategies that dictate how they should react in each situation. They aim to maximize
    the rewards they accumulate by interacting with the environment and slowly learning
    the best actions from experience. In a [previous post](https://velaylearning.com/markov-decision-process-in-plain-english/),
    I go into more depth about the concepts of Reinforcement Learning.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习是一种机器学习类型，涉及训练代理与环境进行互动。代理执行一系列动作，遵循策略来决定在每种情况下如何反应。它们旨在通过与环境互动来最大化它们累积的奖励，并通过经验慢慢学习最佳动作。在
    [上一篇文章](https://velaylearning.com/markov-decision-process-in-plain-english/) 中，我更深入地探讨了强化学习的概念。
- en: RL algorithms rely on MANY hyperparameters, some for learning, some for the
    underlying Neural Networks. There are many levers to make learning more stable,
    faster, or save some memory. Just by looking at a widespread [implementation of
    SAC](https://stable-baselines3.readthedocs.io/en/master/modules/sac.html), from
    stable-baselines3, they have 25 parameters, most of which depend on your own use
    case and contribute to the success of optimizing a strategy.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: RL 算法依赖于许多超参数，一些用于学习，一些用于基础神经网络。有许多杠杆可以使学习更稳定、更快，或者节省内存。仅查看稳定基线3的 [SAC 实现](https://stable-baselines3.readthedocs.io/en/master/modules/sac.html)，他们有
    25 个参数，其中大多数取决于你的使用案例，并有助于优化策略的成功。
- en: This difficulty is attracting a lot of attention, with recent popular answers
    to the problem from the likes of [Google's research team](https://github.com/google-research/tuning_playbook).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这个难题吸引了很多关注，最近来自 [Google 的研究团队](https://github.com/google-research/tuning_playbook)
    的热门答案对此进行了探讨。
- en: The breadth of the search space requires you to systematically sweep the combinations
    of hyperparameters to find the best combination to optimize the agent's performance.
    This is done by training the agent with a set of hyperparameters and evaluating
    the average reward obtained from validation episodes. The sweep requires knowing
    the useful range or values of all parameters, creating the agent and its models,
    and then training them enough to see if learning converges.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索空间的广度要求你系统地遍历超参数的组合，以找到优化代理性能的最佳组合。这通过使用一组超参数训练代理，并评估从验证回合中获得的平均奖励来完成。扫频需要知道所有参数的有效范围或值，创建代理及其模型，然后进行足够的训练，以查看学习是否收敛。
- en: '![](../Images/77aeb4319101b87d3c473b267d54189d.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/77aeb4319101b87d3c473b267d54189d.png)'
- en: Two combinations of HPs lead to very different outcomes, image by the author.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 两种超参数组合导致截然不同的结果，作者提供了图像。
- en: With such a complex setup, you can not hard-code parameters in your python code.
    It would help if you had a modular framework to handle configurations and, for
    a cherry on top, that abstracts the sweeping procedure.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 由于设置如此复杂，你不能在 Python 代码中硬编码参数。你需要一个模块化框架来处理配置，并且最好能抽象出整个过程。
- en: Introducing Hydra
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入 Hydra
- en: '[Hydra](https://hydra.cc/) is a library from the Facebook Research team designed
    for managing complex applications, including Machine Learning pipelines. It shines
    in its configuration flexibility and modularity. By design, you separate the different
    components and can switch them out from yaml config files. It has made it much
    easier to experiment with different learning algorithms, models, settings, and
    environments. Storing my setup in static config files means I can share them with
    my team, and they can repeat the experiment in the same conditions.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[Hydra](https://hydra.cc/) 是 Facebook Research 团队设计的一个库，用于管理复杂的应用程序，包括机器学习管道。它在配置灵活性和模块化方面表现出色。通过设计，你可以分离不同的组件，并从
    yaml 配置文件中替换它们。这使得实验不同的学习算法、模型、设置和环境变得更容易。将我的设置存储在静态配置文件中意味着我可以与团队共享，它们可以在相同条件下重复实验。'
- en: Hydra uses a combination of command line options, hierarchical configuration
    files, and some code to manage the components of your pipeline.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Hydra 使用命令行选项、层级配置文件和一些代码的组合来管理你的管道组件。
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: While the command line can go into a lot of [depth](https://hydra.cc/docs/advanced/hydra-command-line-flags/)
    and has a broad scope, I'll focus on a few ideas. The above command is similar
    to launching your regular ML training script but has a few more parameters. I
    can specify which configuration files I want to use from the command line. These
    are caught in the main function.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管命令行可以深入到很多 [细节](https://hydra.cc/docs/advanced/hydra-command-line-flags/)
    并具有广泛的范围，但我会集中讨论几个想法。上述命令类似于启动常规的 ML 训练脚本，但有更多的参数。我可以从命令行指定要使用哪些配置文件。这些参数会在主函数中捕获。
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'I assume that there is a "configs" folder at the root of my project, specified
    by "config_path" in the Hydra decorator. It contains yaml files describing my
    experiment (default.yaml) and folders for agent and environment configurations.
    These hierarchical files are called from the root and can be passed as attributes:
    in default.yaml, the desired agent is passed as "agent: ddpg" and the content
    of ddpg.yaml is added as a dict to the run''s config.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '我假设在我的项目根目录下有一个由 Hydra 装饰器指定的 "configs" 文件夹。它包含描述我的实验的 yaml 文件（default.yaml）以及用于代理和环境配置的文件夹。这些层级文件从根目录调用，并可以作为属性传递：在
    default.yaml 中，所需的代理被传递为 "agent: ddpg"，ddpg.yaml 的内容作为字典添加到运行的配置中。'
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The base setup to run the experiment in the main config file, called by the
    decorator, only has links to other yaml files containing model and environment
    values.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 运行实验的基本设置在主配置文件中，由装饰器调用，只包含指向其他 yaml 文件的链接，这些文件包含模型和环境值。
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let''s look at the values in ddpg.yaml:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看一下 ddpg.yaml 中的值：
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We access these values in our code as "cfg.agent.*". We can train our model
    using those hyperparameters, with a small setup to translate them into the expected
    parameters for Stable-Baselines3 (SB3).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在代码中通过 "cfg.agent.*" 访问这些值。我们可以使用这些超参数训练我们的模型，并做一些小的设置将其转换为 Stable-Baselines3
    (SB3) 所期望的参数。
- en: 'The parameters are simple floats and strings, while SB3 expects classes or
    instantiated objects. We use some dictionaries to solve this translation. Let''s
    take the example of the model''s activation and noise functions:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 参数是简单的浮点数和字符串，而SB3期望的是类或实例化的对象。我们使用一些字典来解决这种转换。以模型的激活函数和噪声函数为例：
- en: '[PRE6]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Having boilerplate code that translates discrete choices into the expected implementation
    allows us to prepare a broad array of options we can select from. This makes sweeping
    hyperparameters directly from the Hydra configurations easier, especially with
    the hypra-optuna-sweeper plug-in.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有将离散选择转化为预期实现的模板代码，使我们能够准备一系列广泛的选项供选择。这使得从Hydra配置中直接进行超参数调整变得更加容易，特别是使用hypra-optuna-sweeper插件。
- en: Hydra's Optuna Sweeper
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hydra的Optuna Sweeper
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Optuna is an excellent library for automatic parameter optimization. It relies
    on very few components: parameter iteration and evaluation. Optuna gives you a
    set of values to test and expects a score as output, using your pipeline as a
    black box.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Optuna是一个出色的自动参数优化库。它依赖于非常少的组件：参数迭代和评估。Optuna提供了一组值供测试，并期望输出一个分数，使用你的管道作为一个黑箱。
- en: Under the hood, the library uses a few tricks to suggest parameters it estimates
    will have a better outcome, allowing you to save time compared to basic grid searches.
    The usual approach requires implementing Optuna's trials right into your main
    training function, handling search spaces, trials, and pruning yourself. With
    the Hydra approach, most things are abstracted, with only knobs to tune.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在底层，该库使用了一些技巧来建议它估计将有更好结果的参数，使你能够比基本的网格搜索节省时间。通常的方法需要将Optuna的试验直接实现到你的主要训练函数中，自行处理搜索空间、试验和修剪。通过Hydra的方法，大多数事情都是抽象的，只需调整一些参数即可。
- en: 'One of Optuna''s key features is running searches in parallel, which Hydra
    enhances. The two libraries work hand-in-hand: Optuna selects hyperparameters
    to trial, and Hydra efficiently sets up your pipeline. Let''s see how to combine
    the two in your code.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Optuna的一个关键特性是并行运行搜索，Hydra对此进行了增强。这两个库密切配合：Optuna选择要试验的超参数，而Hydra高效地设置你的管道。让我们看看如何在你的代码中结合这两个库。
- en: 'The main changes occur in your Hydra configs, default.yaml:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的变化发生在你的Hydra配置文件default.yaml中：
- en: '[PRE8]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'And you now need to configure your hyperparameters'' search spaces in "agent/search_spaces/ddpg.yaml":'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你需要在"agent/search_spaces/ddpg.yaml"中配置你的超参数搜索空间。
- en: '[PRE9]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Let's walk through those two config files. In the main file, we have added the
    link to the file containing the space Optuna can sweep for each hyperparameter.
    In our case, "${agent}" means that our file has the same name as the agent's configuration
    file, defined above.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看这两个配置文件。在主文件中，我们添加了指向Optuna可以为每个超参数进行调整的空间文件的链接。在我们的例子中，"${agent}"意味着我们的文件与上面定义的代理配置文件同名。
- en: We have a few options to specify which range of values we want to explore for
    each hyperparameter.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有几个选项可以指定我们希望探索的每个超参数的值范围。
- en: '[PRE10]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Choice allows us to select discrete options from a fixed list of values. This
    is perfect for textual or restricting options.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 选择允许我们从固定的值列表中选择离散选项。这对于文本或限制选项非常合适。
- en: The next range specifier is the classic linear interval. A random value will
    be picked inside the interval.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个范围说明符是经典的线性区间。一个随机值将在该区间内被选取。
- en: Finally, when sampling from intervals ranging through multiple orders of magnitude,
    it is interesting to use logarithmic distributions. This is not included by default
    in the hydra-optuna-sweeper plug-in, but you can tag it as such.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，当从跨越多个数量级的区间中抽样时，使用对数分布是有趣的。这在hydra-optuna-sweeper插件中默认不包含，但你可以将其标记为如此。
- en: You can find more use cases directly from the [documentation](https://hydra.cc/docs/1.2/plugins/optuna_sweeper/#search-space-configuration),
    along with some examples.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以直接从[文档](https://hydra.cc/docs/1.2/plugins/optuna_sweeper/#search-space-configuration)中找到更多用例，以及一些示例。
- en: The next step is to specify which sweeper we want Hydra to use. There are plug-ins
    for the Ax, Nevergrad, and Optuna sweepers. We then need to define some custom
    parameters for Optuna, such as the best direction to optimize for our problem.
    In the case of RL, we often desire to maximize rewards. For classic ML problems,
    we'd often want to minimize errors.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是指定我们希望Hydra使用哪个sweeper。对于Ax、Nevergrad和Optuna sweepers有插件。然后我们需要为Optuna定义一些自定义参数，例如优化我们问题的最佳方向。在RL的情况下，我们通常希望最大化奖励。对于经典的机器学习问题，我们通常希望最小化误差。
- en: The number of trials we explore is the total set of hyperparameters we desire
    to test. In this case, we only run 20 combinations for a quick sweep, with a single
    job at a time. The selection of hyperparameters from the sweep will override the
    ones specified in the agent/ddpg.yaml file.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探索的试验次数是我们希望测试的超参数总集合。在这种情况下，我们只运行 20 种组合进行快速 sweep，每次一个作业。来自 sweep 的超参数选择将覆盖
    agent/ddpg.yaml 文件中指定的超参数。
- en: '![](../Images/f1dec45cbea8d63b2a603de07b39478a.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f1dec45cbea8d63b2a603de07b39478a.png)'
- en: Launching an Optuna trial with sampled hyperparameters, image by author
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 启动一个带有采样超参数的 Optuna 实验，由作者提供的图片
- en: 'This concludes the first component from Optuna: the parameter iteration. Now,
    we need to evaluate it. For this, we exploit Stable-Baseline3''s Callbacks. We
    define "TrialEvalCallback" to run validation sets every N timestep, getting our
    agent''s average performance at a given time.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这结束了 Optuna 的第一个组件：参数迭代。现在，我们需要对其进行评估。为此，我们利用 Stable-Baseline3 的回调函数。我们定义了“TrialEvalCallback”，以每
    N 步运行验证集，获取我们代理在特定时间的平均表现。
- en: '![](../Images/7a1ecfa1dd40406334e95ad36e505232.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a1ecfa1dd40406334e95ad36e505232.png)'
- en: TrialEvalCallback output during training, image by author
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 训练期间的 TrialEvalCallback 输出，由作者提供的图片
- en: Once training ends, we return the best average performance our agent has reached
    from the function decorated by Hydra's main. At the end of the sweep, Hydra outputs
    the set of hyperparameters with the best evaluation. Bellow is the best set from
    a sweep of DDPG over the pendulum environment.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练结束，我们将返回从 Hydra 主函数装饰的函数中获得的最佳平均表现。在 sweep 结束时，Hydra 输出具有最佳评估的超参数集。以下是对
    pendulum 环境进行 DDPG sweep 时得到的最佳超参数集。
- en: '![](../Images/ade0cf23770160b1a8dfb5a6c026438f.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ade0cf23770160b1a8dfb5a6c026438f.png)'
- en: Best hyperparameters found for the Pendulum environment, image by author
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为 Pendulum 环境找到的最佳超参数，由作者提供的图片
- en: As an added benefit, SB3 comes with a quick built-in implementation of TensorBoard.
    From the TB dashboard, we can see the combination's relative performance throughout
    their training phases. The best hyperparameters are selected from average performance
    over validation episodes, but you may be interested in further details. Some sets
    may reach plateaus, while others swing back and forth from good to bad.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 作为额外的好处，SB3 配备了快速内置的 TensorBoard 实现。在 TB 仪表盘中，我们可以看到不同组合在训练阶段的相对表现。最佳超参数是从验证集的平均表现中选择的，但你可能对进一步的细节感兴趣。有些组合可能达到平台期，而其他则从好到坏波动。
- en: '![](../Images/75ae92ce145898cd8cbdd06fdc2a7724.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75ae92ce145898cd8cbdd06fdc2a7724.png)'
- en: Multirun comparison inside a sweep, in TensorBoard, image by author
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TensorBoard 中的多次运行比较，由作者提供的图片
- en: In conclusion, we have used Hydra to greatly simplify setting up our Stable-Baselines3
    agent, adding some flexibility and the ability to quickly change components directly
    from yaml files. The added benefit is that you can save past experiments and rerun
    them with the same hyperparameters, or share them with your team.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们使用 Hydra 大大简化了设置 Stable-Baselines3 代理的过程，增加了灵活性，并能够直接从 yaml 文件中快速更改组件。额外的好处是你可以保存过去的实验并使用相同的超参数重新运行，或与团队分享。
- en: While Optuna is traditionally run directly from your main training script, the
    hydra-optuna-sweeper takes the approach of abstracting it. You can launch your
    hyperparameter sweep from your pre-existing configuration, by specifying the search
    spaces alongside your agent parameters. Optuna takes care of the rest, so you
    can focus on your use case.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Optuna 通常直接从你的主要训练脚本运行，但 hydra-optuna-sweeper 采取了抽象的方法。你可以从现有配置中启动超参数搜索，通过指定搜索空间和代理参数。Optuna
    处理其余部分，你可以专注于你的用例。
- en: I hope you'll have fun with hydra-optuna-sweeper! Find the whole project on
    my [GitHub](https://github.com/Marc-Velay/hydra_optuna_tutorial). Reach out to
    me on [Twitter](https://twitter.com/marc_velay) or [LinkedIn](https://www.linkedin.com/in/marc-velay/).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你在使用 hydra-optuna-sweeper 时能玩得开心！你可以在我的 [GitHub](https://github.com/Marc-Velay/hydra_optuna_tutorial)
    上找到整个项目。可以通过 [Twitter](https://twitter.com/marc_velay) 或 [LinkedIn](https://www.linkedin.com/in/marc-velay/)
    联系我。
