["```py\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport tensorflow as tf\nimport tensorflow_probability as tfp\ntfd = tfp.distributions\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import datasets, model_selection\nfrom sklearn.datasets import load_wine\n```", "```py\ndataset = load_wine(as_frame=True)\ndataset = pd.concat((dataset['data'], dataset['target']), axis=1)\nsns.pairplot(dataset[['alcohol','alcalinity_of_ash', 'flavanoids', 'color_intensity', 'hue', 'target']],hue='target');\n```", "```py\nsns.jointplot(x='alcohol',y='hue', hue='target', data=dataset);\n```", "```py\ndata = dataset[['alcohol', 'hue']].to_numpy()\ntargets = dataset[['target']].to_numpy()\n\nlabel_colors = ['darkred', 'peachpuff', 'black']\nx_train, x_test, y_train, y_test = model_selection.train_test_split(data, targets, test_size=0.2)\n```", "```py\ndef prior_fn(y):\n    n_classes = np.unique(y).shape[0]\n    counts = np.zeros(n_classes)\n    for c_k in range(n_classes):\n        counts[c_k] = np.sum(np.where(y==c_k, 1, 0))\n        priors = counts/np.sum(counts)\n    dist = tfd.Categorical(probs=priors)\n    return dist\n\nprior = prior_fn(y_train)\nprior\n\n<tfp.distributions.Categorical 'Categorical' batch_shape=[] event_shape=[] dtype=int32>\n```", "```py\nplt.bar([0, 1, 2], prior.probs.numpy(), color=label_colors)\nplt.xlabel(\"Class\")\nplt.ylabel(\"Prior probability\")\nplt.title(\"Class prior distribution\")\nplt.xticks([0, 1, 2],)\nplt.show()\n```", "```py\ndef class_conditionals_fn(x, y):\n    n_classes = np.unique(y).shape[0]\n    n_features = x.shape[1]\n    counts = np.zeros(n_classes)\n    mean_feature_given_class = []\n    std_feature_given_class = []\n    for c_k in range(n_classes):\n        mean_feature_given_class.append(np.mean(x[np.squeeze(y==c_k)], axis=0))\n        std_feature_given_class.append(np.std(x[np.squeeze(y==c_k)], axis=0))\n\n    class_cond = tfd.MultivariateNormalDiag(loc = np.asarray(mean_feature_given_class).reshape(n_classes, n_features),\n                             scale_diag=np.asarray(std_feature_given_class).reshape(n_classes, n_features))\n\n    return class_cond\n\nclass_conditionals = class_conditionals_fn(x_train, y_train)\nclass_conditionals\n\n<tfp.distributions.MultivariateNormalDiag 'MultivariateNormalDiag' batch_shape=[3] event_shape=[2] dtype=float64>\n```", "```py\ndef contour_plot(x0_range, x1_range, prob_fn, batch_shape, colors, levels=None, num_points=100):\n    x0 = np.linspace(x0_range[0], x0_range[1], num_points)\n    x1 = np.linspace(x1_range[0], x1_range[1], num_points)\n    X0, X1= np.meshgrid(x0, x1)\n    Z = prob_fn(np.expand_dims(np.array([X0.ravel(), X1.ravel()]).T, 1))\n    Z = np.array(Z).T.reshape(batch_shape, *X0.shape)\n    for batch in np.arange(batch_shape):\n        if levels:\n            plt.contourf(X0, X1, Z[batch], alpha=0.2, colors=colors, levels=levels)\n        else:\n            plt.contour(X0, X1, Z[batch], colors=colors[batch], alpha=0.3)\n\nplt.figure(figsize=(10, 6))\nplot_data(x_train, y_train, alpha=0.3)\nx0_min, x0_max = x_train[:, 0].min()-0.2, x_train[:, 0].max()+0.2\nx1_min, x1_max = x_train[:, 1].min()-0.2, x_train[:, 1].max()+0.2\ncontour_plot((x0_min, x0_max), (x1_min, x1_max), class_conditionals.prob, 3, label_colors)\nplt.title(\"Training set with class-conditional density contours\")\nplt.show()\n```", "```py\ndef predict_class(prior, class_conditionals, x):\n    log_prob_list = []\n    for sample in x:\n        cond_probs = class_conditionals.log_prob(sample)\n        joint_likelihood = tf.add(prior.probs.numpy(), cond_probs)\n        norm_factor = tf.math.reduce_logsumexp(joint_likelihood, axis=-1, keepdims=True)\n        log_prob = joint_likelihood - norm_factor\n        log_prob_list.append(log_prob)\n    return np.argmax(np.asarray(log_prob_list), axis=-1)\n\npredictions = predict_class(prior, class_conditionals, x_test)\n```", "```py\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Test accuracy: {:.4f}\".format(accuracy))\n\nTest accuracy: 0.9167\n```", "```py\nplt.figure(figsize=(10, 6))\nplot_data(x_train, y_train)\nx0_min, x0_max = x_train[:, 0].min()-0.2, x_train[:, 0].max()+0.2\nx1_min, x1_max = x_train[:, 1].min()-0.2, x_train[:, 1].max()+0.2\ncontour_plot((x0_min, x0_max), (x1_min, x1_max), \n             lambda x: predict_class(prior, class_conditionals, x), \n             1, label_colors, levels=[-0.5, 0.5, 1.5, 2.5, 3.5],\n             num_points=200)\nplt.title(\"Training set with decision regions\")\nplt.show()\n```"]