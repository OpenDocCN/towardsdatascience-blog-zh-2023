- en: 'Causal Python: Five Novel Causal Ideas At NeurIPS 2023'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/causal-python-five-novel-causal-ideas-at-neurips-2023-13bb68c5ed56](https://towardsdatascience.com/causal-python-five-novel-causal-ideas-at-neurips-2023-13bb68c5ed56)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: New exciting ideas that marry causality with generative modeling, conformal
    prediction and topology.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://aleksander-molak.medium.com/?source=post_page-----13bb68c5ed56--------------------------------)[![Aleksander
    Molak](../Images/7fca5018f6ce88297fae31cef1fe0e6c.png)](https://aleksander-molak.medium.com/?source=post_page-----13bb68c5ed56--------------------------------)[](https://towardsdatascience.com/?source=post_page-----13bb68c5ed56--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----13bb68c5ed56--------------------------------)
    [Aleksander Molak](https://aleksander-molak.medium.com/?source=post_page-----13bb68c5ed56--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----13bb68c5ed56--------------------------------)
    ·7 min read·Sep 24, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e58678914a0248374537c9066bfa9234.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [**Pixabay** at **Pexels.com**](https://www.pexels.com/photo/binocular-blue-sky-daylight-discovery-221538/)
  prefs: []
  type: TYPE_NORMAL
- en: NeurIPS is considered one of the most important and prestigious conferences
    on artificial intelligence and machine learning globally due to its rigorous paper
    review process and high quality of accepted research.
  prefs: []
  type: TYPE_NORMAL
- en: With its multidisciplinary focus, the conference covers an extensive range of
    topics related to developing intelligent systems and machine learning algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: The number of causality-related papers accepted at NeurIPS grew exponentially
    over the last couple of years.
  prefs: []
  type: TYPE_NORMAL
- en: In this article we introduce five causal papers accepted at the 2023 edition
    of the conference that drew my attention as bringing important new insights to
    the field.
  prefs: []
  type: TYPE_NORMAL
- en: Note that this is a subjective and certainly an incomplete list. One of the
    reasons for this is that at the time of writing NeurIPS still hasn’t published
    the full list of papers accepted at the conference.
  prefs: []
  type: TYPE_NORMAL
- en: That said, I am convinced that the ideas presented in the papers introduced
    below have a chance to move our field forward.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start!
  prefs: []
  type: TYPE_NORMAL
- en: Conformal meta-learners
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Conformal prediction is a family of uncertainty quantification techniques originally
    proposed by Vladimir Vovk.
  prefs: []
  type: TYPE_NORMAL
- en: Conformal prediction is model-free (no distributional assumptions are needed)
    and provides frequentist coverage guarantees. In other words, it guarantees that
    the true outcome will fall into the prediction intervals (or sets) with high probability
    under the *exchangeability* assumption¹.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cf4e6ae535cd22c446a29f0b4f86af65.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 1.** Depiction of conformal meta-learners. Source: [https://bit.ly/44Z9U9L](https://bit.ly/44Z9U9L)'
  prefs: []
  type: TYPE_NORMAL
- en: In their new paper **Conformal Meta-learners for Predictive Inference of Individual
    Treatment Effects** just accepted at NeurIPS 2022, Ahmed Alaa and colleagues propose
    a new framework for conformal meta-learners.
  prefs: []
  type: TYPE_NORMAL
- en: Their approach enables direct inference on the target parameter (individualized
    treatment effect; **ITE**), an important improvement over previous methods.
  prefs: []
  type: TYPE_NORMAL
- en: The authors evaluate the method’s performance in a series of experiments using
    synthetic and semi-synthetic data and measure the performance in terms of achieved
    coverage, root mean squared error and interval length.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions? Conformalized *DR-learner** achieves superior performance in most
    settings.
  prefs: []
  type: TYPE_NORMAL
- en: One of the limitations of the framework is that it requires the propensity score
    to be known, which may be limiting in some cases.
  prefs: []
  type: TYPE_NORMAL
- en: This work opens an exciting new direction for combining causal methods with
    the coverage guarantees offered by conformal predictors.
  prefs: []
  type: TYPE_NORMAL
- en: 🟡 Read the [**paper**](https://bit.ly/44Z9U9L)
  prefs: []
  type: TYPE_NORMAL
- en: 🟡 Check the [**code**](https://bit.ly/3LBpwsX)
  prefs: []
  type: TYPE_NORMAL
- en: '* Looking to learn about meta-learners and DR-learner? Check chapters 9 and
    10 of [Causal Inference and Discovery in Python](https://amzn.to/3EQeRH9) or take
    a look the book’s free [GitHub repo here](https://bit.ly/3t3dulL).'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Causal normalizing flows
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Normalizing flows is a class of neural models that can express complex distributions
    by transforming simple ones.
  prefs: []
  type: TYPE_NORMAL
- en: In particular, autoregressive normalizing flows estimate the distribution of
    variable X as a function of the variables preceding it. If we want to express
    one variable as a function of the variables preceding it, we first need to order
    these variables somehow.
  prefs: []
  type: TYPE_NORMAL
- en: Note that this setting resembles **structural causal models** (**SCM**s), where
    each variable is expressed as a function of its parents.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4b32075445e5c4acd50adb95152542a8.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 2\.** Example of the linear SCM written (a) in its usual recursive'
  prefs: []
  type: TYPE_NORMAL
- en: formulation; (b) without recursions, with each step made explicit; (c) without
    recursions, as a single
  prefs: []
  type: TYPE_NORMAL
- en: 'function; and (d) writing u as a function of x. Source: [https://bit.ly/3ZvwbuD](https://bit.ly/3ZvwbuD)'
  prefs: []
  type: TYPE_NORMAL
- en: Normalizing flows has been previously used for causal discovery (e.g. **CAREFL**
    (Khemakhem et al., 2021) used in **DECI** (Geffner et al., 2022); see Molak (2023),
    chapter 13 for details).
  prefs: []
  type: TYPE_NORMAL
- en: 'In their new paper **Causal Normalizing Flows: From Theory to Practice***,*
    Adrián Javaloy and colleagues have taken these ideas to the next level. They show
    that causal models can be identified from observational data, given causal ordering
    and recovered using normalizing flows.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, they propose an implementation of *do*-operator in causal normalizing
    flows that allow us to answer interventional and counterfactual queries.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, they demonstrate the effectiveness of their method on mixed (continuous/discrete)
    data with an incomplete graph.
  prefs: []
  type: TYPE_NORMAL
- en: What an exciting time to be alive!
  prefs: []
  type: TYPE_NORMAL
- en: 🟡 Read the [**paper**](https://bit.ly/3ZvwbuD)
  prefs: []
  type: TYPE_NORMAL
- en: 🟡 Check the [**code**](https://bit.ly/3PQuBAe)
  prefs: []
  type: TYPE_NORMAL
- en: '[](/beyond-the-basics-level-up-your-causal-discovery-skills-in-python-now-2023-cabe0b938715?source=post_page-----13bb68c5ed56--------------------------------)
    [## Causal Python — Level Up Your Causal Discovery Skills in Python (2023)'
  prefs: []
  type: TYPE_NORMAL
- en: …and unlock the potential of the best Causal Discovery package in Python!
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/beyond-the-basics-level-up-your-causal-discovery-skills-in-python-now-2023-cabe0b938715?source=post_page-----13bb68c5ed56--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Generative models for partial counterfactual identification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Counterfactuals are placed on the third rung of the Pearl’s *Ladder of Causation*.
  prefs: []
  type: TYPE_NORMAL
- en: This makes them the most difficult to work with as we need a very rich description
    of the **structural causal model** (**SCM**) of interest in order to address counterfactual
    queries.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7debb32ab53ec76a7ec7e8eb80e14bab.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 3\.** Symbolic representation of the Pearlian ladder of causation.
    Counterfactual queries require the richest representation of the SCM. Source:
    [https://bit.ly/45UzGgx](https://bit.ly/45UzGgx)'
  prefs: []
  type: TYPE_NORMAL
- en: So-called *symbolic identifiability* is not always available and other assumptions
    that can make answering counterfactual queries feasible (e.g. monotonicity) might
    be difficult to meet in certain scenarios or only work in discrete cases.
  prefs: []
  type: TYPE_NORMAL
- en: The new paper, **Partial Counterfactual Identification of Continuous Outcomes
    with a Curvature Sensitivity Model** by Valentyn Melnychuk and colleagues presents
    a novel approach that goes beyond these limitations.
  prefs: []
  type: TYPE_NORMAL
- en: The authors take the topological perspective (for earlier works see e.g. Ibeling
    & Icard, 2021) on this challenge and propose a Curvature Sensitivity Model (**CSM**)
    that allows for partial counterfactual identification
  prefs: []
  type: TYPE_NORMAL
- en: of continuous outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, the method enables us to find informative bounds for counterfactual
    queries under continuous outcomes when we don’t have full information about the
    data generating process.
  prefs: []
  type: TYPE_NORMAL
- en: The authors suggest that the assumptions the solution relies on should be realistic
    for a broad category of use cases, from physics to medicine, and that the method
    has a potential to be relevant for decision-making in safety-critical settings.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a side note: the proposed method also relies on normalizing flows.'
  prefs: []
  type: TYPE_NORMAL
- en: 🟡 Read the [**paper**](https://bit.ly/45UzGgx)
  prefs: []
  type: TYPE_NORMAL
- en: 🟡 Check the [**code**](https://bit.ly/3t65znM)
  prefs: []
  type: TYPE_NORMAL
- en: Passive data, active causal strategies and language models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you follow me on [LinkedIn](https://bit.ly/3RycjoP) or [Twitter/X](https://bit.ly/3rzaY6i),
    you may remember a [post](https://bit.ly/46pTI2c) about this paper.
  prefs: []
  type: TYPE_NORMAL
- en: Actually, this paper was one of the papers that inspired me and my colleagues
    to organize the **AAAI 2024** [workshop on large language models and causality](https://bit.ly/3rj5f4K).
  prefs: []
  type: TYPE_NORMAL
- en: But, to the point!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1ef8b1135f6c0a3ded5c07a16f18ce68.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 4.** The causal DAG environment and experimental results. (a) The
    constraints imposed on'
  prefs: []
  type: TYPE_NORMAL
- en: the causal DAG structures when creating the training dataset, and when evaluating
    the agent on test
  prefs: []
  type: TYPE_NORMAL
- en: structures. During training, D is not allowed to be an ancestor of E (even indirectly),
    though they
  prefs: []
  type: TYPE_NORMAL
- en: may be correlated due to confounding variables. In evaluation environments,
    D is the most impactful
  prefs: []
  type: TYPE_NORMAL
- en: ancestor of E (see text). (b) Rewards obtained by the agent when evaluated in
    interactive settings, as a
  prefs: []
  type: TYPE_NORMAL
- en: percentage of the optimal rewards. In both evaluation settings, the agent still
    achieves close to optimal
  prefs: []
  type: TYPE_NORMAL
- en: reward. © Analyzing the agent’s behavior in more detail, by plotting the proportion
    of the agent’s
  prefs: []
  type: TYPE_NORMAL
- en: actions that match the optimal behavior, or baselines based on heuristics from
    the interventions or
  prefs: []
  type: TYPE_NORMAL
- en: correlational statistics. The agent matches the optimal strategy significantly
    more closely than it
  prefs: []
  type: TYPE_NORMAL
- en: 'matches the heuristic baselines. Source: [https://bit.ly/3Rt4cd3](https://bit.ly/3Rt4cd3)'
  prefs: []
  type: TYPE_NORMAL
- en: In their paper **Passive Learning of Active Causal Strategies in Agents and
    Language Models**, DeepMind’s Andrew Lampinen and colleagues demonstrate that
    agents and (large) language models (**LLM**s) can learn active causal strategies
    from passive (observational) data.
  prefs: []
  type: TYPE_NORMAL
- en: These strategies can generalize to out-of-distribution data (!), but *only*
    under certain conditions.
  prefs: []
  type: TYPE_NORMAL
- en: As the authors propose, the agents “*acquire generalizable strategies for discovering
    and exploiting causal structures, as long as they can intervene at test time*”.
  prefs: []
  type: TYPE_NORMAL
- en: In-prompt explanations are *critical* for enabling generalization in LLMs. This
    work does not imply passive learning surpasses active learning or solves confounding
    in LLMs entirely. However, it marks an important step toward expanding language
    models’ causal capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: I can’t wait to see more research continuing down this exciting path!
  prefs: []
  type: TYPE_NORMAL
- en: 🟡 Read the [**paper**](https://bit.ly/3Rt4cd3)
  prefs: []
  type: TYPE_NORMAL
- en: Generalized sensitivity analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sensitivity analysis is instrumental for causal analysts whenever we cannot
    exclude the possibility of the existence of hidden confounding.
  prefs: []
  type: TYPE_NORMAL
- en: Traditional methods for sensitivity analysis often come with limitations (e.g.
    they assume a linear model or a single binary treatment).
  prefs: []
  type: TYPE_NORMAL
- en: In their new paper*,* **Sharp Bounds for Generalized Causal Sensitivity Analysis***,*
    Dennis Frauen and colleagues propose a novel unified
  prefs: []
  type: TYPE_NORMAL
- en: framework for causal sensitivity analysis under unobserved confounding.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bafae26b34a4921edd63a954bbfd49c8.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 5.** Bounding interventional distributions under the proposed model.
    Source: [https://bit.ly/3PLVBkl](https://bit.ly/3PLVBkl)'
  prefs: []
  type: TYPE_NORMAL
- en: The framework provides us with sharp bounds for a spectrum of causal effects,
    including (conditional) average treatment effects (**CATE**), effects for mediation,
    path analysis, and distributional effects.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, the proposed approach works with discrete, continuous, and time-varying
    treatments.
  prefs: []
  type: TYPE_NORMAL
- en: Best part? The paper comes with a rich code repo.
  prefs: []
  type: TYPE_NORMAL
- en: 'To cite [Károly Zsolnai-Fehér](https://users.cg.tuwien.ac.at/zsolnai/):'
  prefs: []
  type: TYPE_NORMAL
- en: '*What a time to be alive!*'
  prefs: []
  type: TYPE_NORMAL
- en: 🟡 Read the [**paper**](https://bit.ly/3PLVBkl)
  prefs: []
  type: TYPE_NORMAL
- en: 🟡 Check the [**code**](https://bit.ly/3rp0UNg)
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://causalpython.io/?source=post_page-----13bb68c5ed56--------------------------------)
    [## Causal Python || Your go-to resource for learning about Causality in Python'
  prefs: []
  type: TYPE_NORMAL
- en: Free weekly emails on causality and machine learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: causalpython.io](https://causalpython.io/?source=post_page-----13bb68c5ed56--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Footnotes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ¹ Here ***exchangeability*** has a different meaning than in the potential outcomes
    framework. We can think of it as a milder version of the IID assumption. See [here](https://bit.ly/3rtcjvB)
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Geffner, T., Antorán, J., Foster, A., Gong, W., Ma, C., Kıcıman, E., Sharma,
    A., Lamb, A., Kukla, M., Pawlowski, N., Allamanis, M., & Zhang, C. (2022). Deep
    End-to-end Causal Inference. *arXiv.*
  prefs: []
  type: TYPE_NORMAL
- en: Ibeling, D., Icard, T. (2021). A Topological Perspective on Causal Inference.
    *35th Conference on Neural Information Processing Systems*.
  prefs: []
  type: TYPE_NORMAL
- en: Khemakhem, I., Monti, R., Leech, R. &amp; Hyvarinen, A. (2021). Causal Autoregressive
    Flows . *Proceedings of The 24th International Conference on Artificial Intelligence
    and Statistics*, in *Proceedings of Machine Learning Research*, 130, 3520–3528\.
    [https://proceedings.mlr.press/v130/khemakhem21a.html](https://proceedings.mlr.press/v130/khemakhem21a.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'Molak, A. (2023). *Causal Inference and Discovery in Python: Unlock the secrets
    of modern causal machine learning with DoWhy, EconML, PyTorch and more*. Packt
    Publishing.'
  prefs: []
  type: TYPE_NORMAL
