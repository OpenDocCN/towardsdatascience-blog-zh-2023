# RAG与微调——哪种是提升你的LLM应用的最佳工具？

> 原文：[https://towardsdatascience.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7](https://towardsdatascience.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7)

## 为你的用例选择正确方法的权威指南

[](https://heiko-hotz.medium.com/?source=post_page-----94654b1eaba7--------------------------------)[![Heiko Hotz](../Images/d08394d46d41d5cd9e76557a463be95e.png)](https://heiko-hotz.medium.com/?source=post_page-----94654b1eaba7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----94654b1eaba7--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----94654b1eaba7--------------------------------) [Heiko Hotz](https://heiko-hotz.medium.com/?source=post_page-----94654b1eaba7--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----94654b1eaba7--------------------------------) ·19分钟阅读·2023年8月24日

--

![](../Images/f87aad7c078e00a5f9db9a00ad4debad.png)

作者提供的图片

# 前言

随着对大型语言模型（LLMs）兴趣的浪潮涌动，许多开发者和组织忙于构建利用其强大功能的应用。然而，当现成的预训练LLMs未能如预期般表现时，如何提升LLM应用性能的问题就会浮现。最终，我们会问自己：我们应该使用[检索增强生成](https://arxiv.org/abs/2005.11401)（RAG）还是模型微调来改善结果？

在深入探讨之前，让我们揭开这两种方法的神秘面纱：

**RAG**：这种方法将检索（或搜索）的力量集成到LLM文本生成中。它结合了一个检索系统，该系统从大规模语料库中获取相关文档片段，以及一个LLM，该LLM使用这些片段中的信息生成答案。实质上，RAG帮助模型“查找”外部信息以改进其响应。

![](../Images/37f3ba773a6c401ffdd3eead8bdf76b7.png)

作者提供的图片

**微调**：这是将预训练LLM进一步在一个较小的特定数据集上进行训练的过程，以便将其适应于特定任务或提升其性能。通过微调，我们根据我们的数据调整模型的权重，使其更加符合我们应用的独特需求。

![](../Images/f8686a451839dd8611ecc0de7f592cb4.png)

作者提供的图片

RAG和微调都是提升基于LLM的应用性能的强大工具，但它们针对优化过程的不同方面，这在选择其中一个时至关重要。

之前，我经常建议组织在深入微调之前先尝试 RAG。这是基于我对这两种方法虽然实现了类似结果但在复杂性、成本和质量上有所不同的看法。我甚至曾用类似的图表来说明这一点：

![](../Images/96b1f7fd587d026b3ca2d92f3424c3a5.png)

作者提供的图片

在这个图表中，各种因素如复杂性、成本和质量沿着单一维度表示。要点是什么？RAG 更简单且成本更低，但其质量可能无法匹配。我的建议通常是：从 RAG 开始，评估其性能，如果发现不足，则转向微调。

然而，我的观点已经有所变化。我认为将 RAG 和微调视为实现相同结果的两种技术，这种看法过于简化，因为一种技术更便宜、复杂度更低而已。它们本质上是不同的——而不是*共线*，而是*正交*——且满足 LLM 应用的不同需求。

> 为了更清楚地说明这一点，可以考虑一个简单的现实世界类比：当被问到“我应该用刀子还是勺子来吃饭？”时，最合逻辑的反问是：“你在吃什么？”我问过朋友和家人，每个人本能地回答了这个反问，这表明他们并不认为刀子和勺子是可以互换的，或者其中一种是另一种的低级变体。

# 这是什么内容？

在这篇博客中，我们将深入探讨区分 RAG 和微调的各种维度，这些维度在我看来对于确定特定任务的最佳技术至关重要。此外，我们将查看一些最受欢迎的 LLM 应用场景，并使用第一部分确定的维度来识别哪种技术最适合哪些用例。在博客的最后部分，我们将识别在构建 LLM 应用时应考虑的其他方面。每一个方面可能都值得单独撰写博客，因此在本篇博客中我们只能简要提及。

# 你为什么要关心这个？

选择适合调整大型语言模型的技术对 NLP 应用的成功有重大影响。选择错误的方法可能导致：

+   在你的具体任务上，模型表现不佳，导致输出不准确。

+   如果技术未针对你的使用案例进行优化，模型训练和推理的计算成本会增加。

+   如果需要以后转向不同的技术，则会增加额外的开发和迭代时间。

+   部署应用程序并让其面向用户的延迟。

+   如果选择了过于复杂的适配方法，则可能缺乏模型解释性。

+   由于大小或计算约束，难以将模型部署到生产环境中。

RAG 和微调之间的细微差别涵盖了模型架构、数据需求、计算复杂性等多个方面。**忽视这些细节可能会破坏你的项目时间表和预算。**

本博客旨在通过清晰地阐述何时使用每种技术来防止浪费努力。通过这些见解，你可以从第一天起就以正确的适应方法迅速开展工作。详细的比较将使你能够做出最佳的技术选择，以实现你的商业和 AI 目标。**本指南将帮助你选择合适的工具，为你的项目成功奠定基础。**

那么，让我们深入探讨吧！

# **提升性能的关键考虑因素**

在选择 RAG 还是微调之前，我们应该评估 LLM 项目的需求，并在一些维度上提出几个问题。

## 我们的用例是否需要访问外部数据源？

在选择对 LLM 进行微调还是使用 RAG 时，一个关键的考虑因素是应用程序是否需要访问外部数据源。如果答案是肯定的，RAG 可能是更好的选择。

RAG 系统的定义是通过在生成回应之前从知识来源检索相关信息，以增强 LLM 的能力。这使得这种技术非常适合需要查询数据库、文档或其他结构化/非结构化数据存储的应用程序。检索器和生成器组件可以被优化以利用这些外部来源。

相比之下，虽然可以对 LLM 进行微调以学习一些外部知识，但这需要来自目标领域的大量标注数据集。随着基础数据的变化，这些数据集必须不断更新，使得它不适用于频繁变化的数据源。微调过程也没有明确建模在查询外部知识时涉及的检索和推理步骤。

总结来说，如果我们的应用程序需要利用外部数据源，使用 RAG 系统可能会比单纯依靠微调“内置”所需知识更有效和可扩展。

## 我们是否需要修改模型的行为、写作风格或领域特定知识？

另一个非常重要的方面是我们需要模型在多大程度上调整其行为、写作风格或为领域特定应用量身定制其回应。

微调在将 LLM 的行为适应于特定的细微差别、语气或术语方面表现出色。如果我们希望模型听起来更像医学专业人员、用诗意的风格写作，或使用特定行业的术语，在领域特定数据上进行微调可以实现这些定制。这种影响模型行为的能力对于需要与特定风格或领域专长一致的应用程序至关重要。

RAG虽然在整合外部知识方面强大，但主要关注信息检索，并不会根据检索到的信息自我调整语言风格或领域特定性。它将从外部数据源中提取相关内容，但可能不会展现出微调模型所能提供的定制化细微差别或领域专业知识。

因此，如果我们的应用程序需要特定的写作风格或深度对齐于特定领域的术语和惯例，微调提供了实现这种对齐的更直接途径。它提供了深入的定制，使得内容真正与特定受众或专业领域产生共鸣，确保生成的内容感觉真实且信息丰富。

## 快速回顾

这两个方面是决定使用哪种方法来提升LLM应用性能时最重要的方面。有趣的是，我认为它们是正交的，可以独立使用（也可以组合使用）。

![](../Images/0223fdf1d85e8e9c749b8759307f0c1e.png)

图片由作者提供

但在深入使用案例之前，我们还应该考虑几个关键方面来选择方法：

## 抑制幻觉有多重要？

LLM的一个缺点是它们有产生幻觉的倾向——编造没有现实依据的事实或细节。这在准确性和真实性至关重要的应用中可能会非常有问题。

微调可以在一定程度上帮助减少幻觉，通过将模型基于特定领域的训练数据。然而，当面对不熟悉的输入时，模型仍可能会编造响应。需要对新数据进行再训练以持续最小化虚假伪造。

相比之下，RAG系统本质上较不容易产生幻觉，因为它们将每个响应基于检索到的证据。检索器在生成器构造答案之前会从外部知识源中识别相关事实。这一步骤充当了一个事实检查机制，减少了模型虚构的能力。生成器被限制在基于检索到的上下文合成响应。

因此，在需要抑制虚假信息和想象性伪造至关重要的应用中，RAG系统提供了内建机制来最小化幻觉。生成响应之前的证据检索使RAG在确保输出真实准确方面具有优势。

## 有多少标记好的训练数据可用？

在决定RAG和微调之间时，一个关键因素是我们手头上是否有大量的领域或任务特定的标记训练数据。

对 LLM 进行微调以适应特定任务或领域严重依赖于可用标注数据的质量和数量。丰富的数据集可以帮助模型深入理解特定领域的细微差别、复杂性和独特模式，从而生成更准确和上下文相关的回应。然而，如果我们使用的是有限的数据集，微调的改善可能会很小。在某些情况下，稀少的数据集甚至可能导致过拟合，模型在训练数据上表现良好，但在未见或现实世界输入中表现不佳。

相反，RAG 系统独立于训练数据，因为它们利用外部知识源来检索相关信息。即使我们没有广泛的标注数据集，RAG 系统仍然可以通过访问和整合外部数据源的见解来有效地工作。检索和生成的结合确保了系统保持知情，即使在领域特定的训练数据稀缺时。

实质上，如果我们拥有大量标注数据，能够捕捉领域的复杂性，微调可以提供更加定制化和精细化的模型行为。但在数据有限的情况下，RAG 系统提供了一个稳健的替代方案，通过其检索能力确保应用保持数据驱动和上下文相关。

## 数据的静态/动态特性如何？

在选择 RAG 和微调时，另一个需要考虑的基本方面是我们数据的动态特性。数据更新的频率如何？对于模型保持最新状态的重要性如何？

对特定数据集进行 LLM 微调意味着模型的知识成为训练时数据的静态快照。如果数据经常更新、变化或扩展，这会迅速使模型过时。为了保持 LLM 在这种动态环境中的时效性，我们必须频繁地重新训练模型，这个过程既耗时又资源密集。此外，每次迭代都需要仔细监控，以确保更新后的模型在不同场景中仍表现良好，并且没有出现新的偏见或理解上的漏洞。

相对而言，RAG 系统在动态数据环境中天生具有优势。它们的检索机制不断查询外部源，确保用于生成回应的信息是最新的。随着外部知识库或数据库的更新，RAG 系统无缝地整合这些变化，保持其相关性而无需频繁的模型重新训练。

总结来说，如果我们在应对快速发展的数据环境，RAG 提供了一种与传统微调难以匹敌的灵活性。通过始终连接到最新的数据，RAG 确保生成的回应与当前的信息状态保持一致，使其成为动态数据场景的理想选择。

## 我们的LLM应用需要多透明/可解释？

最后一个要考虑的方面是我们需要对模型决策过程的洞察程度。

微调LLM虽然极具威力，但像一个黑箱一样运行，使得其响应背后的推理更为不透明。随着模型从数据集中内化信息，识别每个响应背后的确切来源或推理变得困难。这可能会使开发者或用户难以信任模型的输出，特别是在需要理解答案背后“为什么”的关键应用中。

RAG系统提供了一种在纯粹微调模型中通常找不到的透明度。鉴于RAG的两步性质——检索和生成——用户可以窥见其过程。检索组件允许检查哪些外部文档或数据点被选择为相关。这提供了可以评估的具体证据或参考，以理解响应的基础。追溯模型答案到特定数据源的能力在需要高度责任感或需要验证生成内容准确性的应用中非常宝贵。

本质上，如果透明性和解释模型响应基础的能力是优先事项，RAG提供了明确的优势。通过将响应生成分解为不同阶段并允许洞察其数据检索，RAG促进了对其输出的更大信任和理解。

## 总结

在考虑这些维度时，选择RAG和微调变得更为直观。如果我们倾向于访问外部知识并重视透明性，RAG是我们的首选。另一方面，如果我们处理的是稳定的标注数据，并且目标是更紧密地调整模型以满足特定需求，微调则是更好的选择。

![](../Images/d7d7d86c38b86d9425b094c82fab1746.png)

作者提供的图片

在接下来的部分，我们将看到如何根据这些标准评估流行的LLM使用案例。

# 使用案例

让我们看看一些流行的使用案例，以及上述框架如何用于选择正确的方法：

## **总结（在专业领域和/或特定风格中）**

**1\. 是否需要外部知识？** 对于以之前的总结风格进行总结的任务，主要数据来源将是之前的总结本身。如果这些总结包含在静态数据集中，则无需持续的外部数据检索。然而，如果存在一个动态的总结数据库，经常更新且目标是不断地将风格与最新条目对齐，RAG可能会在这里发挥作用。

**2\. 是否需要模型适应？** 这个用例的核心在于适应专业领域和/或特定写作风格。微调特别擅长捕捉风格细微差别、语调变化和特定领域的词汇，使其成为这一维度的最佳选择。

**3\. 是否至关重要的是最小化虚构？** 在大多数大型语言模型应用中，包括总结，虚构都是一个问题。然而，在这个用例中，被总结的文本通常作为上下文提供。这使得虚构问题相较于其他用例的关注度较低。源文本限制了模型，减少了虚构的可能性。因此，尽管事实准确性总是值得追求，但在总结中压制虚构的优先级较低，因为有上下文作为基础。

**4\. 是否有训练数据？** 如果有大量标记或结构化的先前总结，模型可以从中学习，那么微调将是一个非常有吸引力的选择。另一方面，如果数据集有限，而我们依赖外部数据库来进行风格对齐，RAG 可能会发挥作用，尽管它的主要强项不是风格适应。

**5\. 数据的动态性如何？** 如果先前总结的数据库是静态的或更新不频繁，那么微调模型的知识可能会在较长时间内保持相关。然而，如果总结更新频繁，并且需要模型不断地与最新的风格变化保持一致，RAG 可能由于其动态数据检索能力而具有优势。

**6\. 是否需要透明性/可解释性？** 这里的主要目标是风格上的一致性，因此某种特定总结风格背后的“原因”可能不像其他用例那样关键。不过，如果需要追溯并了解哪些先前的总结影响了特定输出，RAG提供了更多的透明度。尽管如此，这对该用例来说可能是次要问题。

> **推荐：** 对于这个用例，***微调*** 似乎是更合适的选择。主要目标是风格一致性，这是微调擅长的一个维度。如果有足够多的先前总结用于训练，微调一个大型语言模型将允许对所需风格进行深度适应，捕捉领域的细微差别和复杂性。然而，如果总结数据库极其动态，并且追溯影响具有价值，可以探索混合方法或倾向于 RAG。

## 关于组织知识的问答系统（即外部数据）

**1\. 是否需要外部知识？** 依赖于组织知识库的问答系统本质上需要访问外部数据，在这种情况下，即组织的内部数据库和文档存储。系统的有效性取决于其从这些来源中提取和检索相关信息的能力。鉴于此，RAG在这一维度上更为合适，因为它设计用来通过从知识来源中检索相关数据来增强LLM的能力。

**2\. 是否需要模型调整？** 根据组织和其领域的不同，模型可能需要与特定术语、语调或惯例保持一致。虽然RAG主要关注信息检索，但微调可以帮助LLM调整其回应，以适应公司的内部用语或其领域的细微差别。因此，在这一维度上，根据具体需求，微调可能会发挥作用。

**3\. 是否至关重要以减少幻觉？** 幻觉在这种用例中是一个主要关注点，因为LLM的知识截止点。如果模型无法根据其训练数据回答问题，它几乎肯定会（部分或完全）编造一个合理但不正确的答案。

**4\. 是否有可用的训练数据？** 如果组织有结构化和标记化的历史问答数据集，这可以增强微调方法。然而，并非所有内部数据库都已标记或结构化用于训练目的。在数据未被整齐标记或主要关注于检索准确相关答案的情况下，RAG能够访问外部数据源而无需大量标记数据集，使其成为一个令人信服的选择。

**5\. 数据的动态性如何？** 组织内部的数据库和文档存储可以是高度动态的，经常更新、更改或添加。如果这种动态性是组织知识库的特征，RAG则具有明显的优势。它不断查询外部来源，确保其回答基于最新的数据。微调则需要定期重新训练以跟上这些变化，这可能不切实际。

**6\. 是否需要透明度/可解释性？** 对于内部应用，特别是在金融、医疗或法律等行业，理解答案背后的推理或来源可能至关重要。由于RAG提供了检索和生成的两步过程，它本质上提供了更清晰的洞察力，显示了哪些文档或数据点影响了特定的答案。这种可追溯性对内部利益相关者来说非常宝贵，他们可能需要验证或进一步调查某些答案的来源。

> **建议：** 对于这种使用场景，***RAG 系统***似乎是更合适的选择。鉴于需要动态访问组织不断发展的内部数据库以及可能需要回答过程中的透明度，RAG 提供的功能与这些需求相契合。然而，如果对模型的语言风格或领域特定细节有重大关注，则可以考虑结合微调的元素。

## 客户支持自动化（即提供即时响应的自动聊天机器人或帮助台解决方案）

**1\. 是否需要外部知识？** 客户支持通常需要访问外部数据，特别是处理产品详细信息、账户特定信息或故障排除数据库时。虽然许多查询可以通过一般知识来解决，但有些可能需要从公司数据库或产品 FAQ 中提取数据。在这里，RAG 从外部来源检索相关信息的能力将非常有益。然而，值得注意的是，许多客户支持互动也基于预定义的脚本或知识，这些可以通过微调的模型有效解决。

**2\. 是否需要模型适配？** 客户互动需要特定的语调、礼貌和清晰度，并且可能还需要公司特有的术语。微调特别有助于确保语言模型适应公司的声音、品牌和特定术语，从而确保一致且符合品牌的客户体验。

**3\. 是否必须尽量减少幻觉？** 对于客户支持聊天机器人来说，避免虚假信息对于维持用户信任至关重要。仅靠微调会使模型在面对不熟悉的查询时容易出现幻觉。相比之下，RAG 系统通过基于检索到的证据来抑制虚构。这种对获取事实的依赖使 RAG 聊天机器人能够减少有害的虚假信息，并在准确性至关重要的情况下为用户提供可靠的信息。

**4\. 是否有训练数据可用？** 如果公司有客户互动的历史记录，这些数据对于微调非常宝贵。以前客户查询及其解决方案的丰富数据集可以用来训练模型，以便未来处理类似的互动。如果这样的数据有限，RAG 可以通过从外部来源（如产品文档）检索答案来提供备用方案。

**5\. 数据的动态性如何？** 客户支持可能需要处理有关新产品、更新的政策或变化的服务条款的查询。在产品阵容、软件版本或公司政策频繁更新的情况下，RAG 动态从最新文档或数据库中提取信息的能力具有优势。另一方面，对于更静态的知识领域，微调可能就足够了。

**6\. 是否需要透明度/可解释性？** 虽然在某些领域透明度很重要，但在客户支持中，主要关注的是准确、快速和礼貌的响应。然而，对于内部监控、质量保证或处理客户争议，了解答案来源的可追溯性可能是有益的。在这种情况下，RAG的检索机制提供了额外的透明度。

> **推荐：** 对于客户支持自动化，***混合方法***可能是最佳选择。调整可以确保聊天机器人符合公司的品牌、语气和一般知识，处理大部分典型的客户查询。RAG可以作为补充系统，处理更动态或特定的查询，确保聊天机器人可以从最新的公司文档或数据库中提取信息，从而减少虚假信息的生成。通过整合这两种方法，公司可以提供全面、及时和品牌一致的客户支持体验。

![](../Images/e04eeb1b4c15cc73fbee2c7dee229e7c.png)

作者图片

# 需要考虑的额外方面

如上所述，决定RAG和调整（或两者结合）时还有其他因素需要考虑。我们无法深入探讨这些因素，因为它们都具有多面性，并没有像上述某些方面那样明确的答案（例如，如果没有训练数据，调整根本不可能）。但这并不意味着我们应忽视它们：

## 可扩展性

随着组织的成长及需求的演变，所用方法的可扩展性如何？由于RAG系统具有模块化特性，可能提供更直接的可扩展性，尤其是当知识库增长时。另一方面，频繁调整模型以适应扩展的数据集可能计算量巨大。

## 延迟和实时要求

如果应用程序需要实时或近实时的响应，请考虑每种方法引入的延迟。RAG系统涉及在生成响应前检索数据，相比于基于内在知识生成响应的调整后的LLM，可能会引入更多的延迟。

## 维护和支持

从长远角度考虑。哪个系统更符合组织提供一致维护和支持的能力？RAG可能需要维护数据库和检索机制，而调整则需要持续的重新训练，特别是数据或需求发生变化时。

## 鲁棒性和可靠性

每种方法对不同类型输入的鲁棒性如何？尽管RAG系统可以从外部知识源中提取信息，可能处理各种问题，而经过良好调整的模型在某些领域可能提供更多的一致性。

## 伦理和隐私问题

从外部数据库存储和检索数据可能引发隐私问题，特别是当数据敏感时。另一方面，尽管微调模型不查询实时数据库，但它仍可能基于其训练数据产生输出，这可能有其自身的伦理影响。

## 与现有系统的集成

组织可能已经有某些基础设施到位。RAG 或微调与现有系统（无论是数据库、云基础设施还是用户界面）的兼容性可以影响选择。

## 用户体验

考虑最终用户及其需求。如果他们需要详细的、基于参考的答案，RAG 可能更为合适。如果他们重视速度和领域特定的专业知识，微调模型可能更适合。

## 成本

微调可能会变得非常昂贵，特别是对于非常大的模型。然而，在过去几个月中，由于像[QLoRA](https://github.com/artidoro/qlora)这样的参数高效技术，成本已大幅下降。设置 RAG 可能需要大额的初始投资——包括集成、数据库访问，甚至可能还有许可费用——但还需要考虑对外部知识库的定期维护。

## 复杂性

微调可能会迅速变得复杂。虽然许多提供商现在提供一键微调，只需提供训练数据，但跟踪模型版本并确保新模型在各方面仍表现良好是具有挑战性的。另一方面，RAG 也可能迅速变得复杂。涉及多个组件的设置，确保数据库保持最新，并确保各个部分——如检索和生成——恰到好处地配合在一起。

# 结论

正如我们所探讨的，选择 RAG 还是微调需要对 LLM 应用的独特需求和优先级进行细致的评估。没有一种放之四海而皆准的解决方案；成功在于将优化方法与任务的具体要求对齐。通过评估关键标准——对外部数据的需求、模型行为的调整、训练数据的可用性、数据动态、结果透明度等——组织可以做出明智的决策，确定最佳前进路径。在某些情况下，利用 RAG 和微调的混合方法可能是最优的。

关键在于避免假设某种方法在所有情况下都是优越的。像任何工具一样，它们的适用性取决于具体的任务。方法和目标的不匹配可能会阻碍进展，而正确的方法则会加速进展。在组织评估提升 LLM 应用的选项时，必须抵制过度简化的倾向，不应将 RAG 和微调视为可以互换的工具，而是要选择能够使模型充分发挥其能力并与用例需求对齐的工具。这些方法所解锁的可能性令人惊叹，但仅有可能性是不够的——执行才是关键。工具已经在这里——现在让我们开始使用它们。

# 海科·霍茨

👋 关注我在[Medium](https://heiko-hotz.medium.com/)和[LinkedIn](https://www.linkedin.com/in/heikohotz/)上的动态，阅读更多关于生成式AI、机器学习和自然语言处理的内容。

👥 如果你在伦敦，可以加入我们的[NLP London Meetups](https://www.meetup.com/nlp_london/)。

📔 我对AI新闻的想法见[😇 Naughty Neural](https://naughtyneural.net/)。

![](../Images/af8595174a18a825043bfa43302463d2.png)

作者提供的图片
