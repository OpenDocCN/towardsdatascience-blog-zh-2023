- en: Carbon Emissions of an ML Engineering Team
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/carbon-emissions-of-an-ml-engineering-team-ce170bd4fae9](https://towardsdatascience.com/carbon-emissions-of-an-ml-engineering-team-ce170bd4fae9)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The hidden cost of development that really matter
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@teosiyang?source=post_page-----ce170bd4fae9--------------------------------)[![Jake
    Teo](../Images/9687f43822fab69befb750a8ec58516d.png)](https://medium.com/@teosiyang?source=post_page-----ce170bd4fae9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ce170bd4fae9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ce170bd4fae9--------------------------------)
    [Jake Teo](https://medium.com/@teosiyang?source=post_page-----ce170bd4fae9--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ce170bd4fae9--------------------------------)
    ·9 min read·Oct 16, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Everybody is aware of the climate crisis due to global warming as a result of
    human activities. To prevent its catastrophic consequences [1], the world needs
    to reduce our greenhouse gas emissions drastically, with many countries setting
    a target of net zero emissions by 2050.
  prefs: []
  type: TYPE_NORMAL
- en: The technology boom of AI in recent years has also raised concerns about its
    environmental cost. If we only look at its direct contributions, this will come
    through the use of electricity to train and power models. For example, training
    ChatGPT-3 with its 175 billion parameters generated a whopping 502 tonnes of carbon
    equivalent emissions (tCO2e) [2]. The new kid on the block Llama2 outputs a similar
    539 tCO2e for training its family of four models [3]. For context, each of these
    is equivalent to the emissions of a passenger taking a one-way flight from New
    York to San Francisco 500 times.
  prefs: []
  type: TYPE_NORMAL
- en: I work in a machine learning engineering team, and this question also nudged
    me constantly. How much carbon emissions do we contribute through electricity
    consumption? Are there ways to reduce it? And here starts a first attempt at carbon
    accounting ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a849f3ef32d0a93e1c7acdfa9bb2bc17.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Chris LeBoutillier](https://unsplash.com/@chrisleboutillier?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '**Methods**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is no single and direct way to measure our electricity consumption and
    consequently our carbon impact. This is due to the variety of platforms and services
    we use. I will not dive deep into the technical implementations, but at a high
    level, it consists of three methods.
  prefs: []
  type: TYPE_NORMAL
- en: '**Provided**: The exact carbon emission figures are already computed for us.
    This was given by our cloud service provider (CSP).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Tools**: We used a few software tools like Powermetics, Nvidia-SMI, and Turbostat
    to measure power in Watts, which tracks the CPU and GPU compute for our laptops
    and on-premise server.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Self-Calculated**: When the above is not possible, we use proxy methods to
    calculate. This consists of recording the duration of the compute, estimating
    the percentage utilisation of the chip(s), as well as finding the thermal design
    power (TDP) of each chip type to calculate the power consumed. The rest of the
    platforms are calculated this way.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For the latter two methods, power is then converted into energy (kWh), and where
    available, the Power Usage Efficiency (PUE) of the supporting data centres are
    used to obtain a more accurate energy consumption. The Grid Emission Factor (in
    kgCO2e/kWh) of the country or region is then finally used to compute the greenhouse
    gas emissions.
  prefs: []
  type: TYPE_NORMAL
- en: '**Results & Thoughts**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The results are displayed in the pie chart below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6df4af38265170bbd72e27bf57cce2fd.png)'
  prefs: []
  type: TYPE_IMG
- en: Carbon emissions of each platform we used extrapolated for the whole of 2023\.
    Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: It isn’t particularly surprising on the ranking of the platforms in terms of
    carbon usage, but I was surprised with the percentages. I did not expect our development
    laptops and CICD service, with very heavy usage, to produce only a minuscule of
    carbon. While on the next extreme, I also did not expect our on-premise server
    for development and model training to burn x3 more carbon compared to our cloud
    usage.
  prefs: []
  type: TYPE_NORMAL
- en: In hindsight, we have recently switched to the latest Apple Silicon M2 chip
    for our laptops which is well-known to be highly efficient. Our CICD platform,
    while having thousands of minutes of pipeline runtime, uses the lowest compute
    chips, and is essentially serverless, only running when necessary.
  prefs: []
  type: TYPE_NORMAL
- en: For our on-premise server, we discovered that idle Nvidia GPU chips still consume
    significant electricity, resulting in a bloated electricity consumption. We will
    need to investigate if there were any misconfigurations, and if not, whether there
    is any way to better manage them.
  prefs: []
  type: TYPE_NORMAL
- en: '**Green Computing**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have a better awareness of our carbon usage, how can we truly transform
    our development team to adopt more green solutions?
  prefs: []
  type: TYPE_NORMAL
- en: The term green computing has been out there for a while, and it has been organised
    or classified in different forms, but I feel that the six broad themes below will
    help my team manage the green transition with better clarity.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cd273f318f90ee2b585bc5325fb76778.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Ash from Modern Afflatus](https://unsplash.com/@modernafflatusphotography?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. Green AI**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This refers to finding ways to **more efficiently train and infer models with
    little or acceptable loss in quality**. It would basically translate to faster
    training and inference time, as well as smaller model sizes, using less compute
    power. The use of more complex neural networks demands ever larger datasets and
    increasingly advanced, prohibitively expensive and energy-hungry GPU chips.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, this has also been a hotbed for the latest optimisation research. In
    the past few years, I heard from my data scientist colleagues from using more
    efficient architectures in each domain, transfer-learning, compression techniques
    like quantisation or knowledge distillation, [ONNX](https://onnx.ai), to using
    [deepspeed](https://github.com/microsoft/DeepSpeed), [PEFT](https://github.com/huggingface/peft)
    and others in today’s era of large language models. No doubt we will need to keep
    up with the latest implementations the open-source world comes up with as their
    benefits have proven to be significant.
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. Green Apps**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Models are useless without the code that builds around them to process the data,
    train the model, and ultimately serve them. Fundamental understanding of **time
    and space complexities**, the algorithms to implement, and also the various pre-built
    functions to apply them is required. Profilers to find bottlenecks in latency
    and memory should also be used.
  prefs: []
  type: TYPE_NORMAL
- en: Another important software engineering skill to build green apps is to understand
    how **tasks and processes are managed, executed, and coordinated**. This requires
    a firm grasp of concepts like parallelism, concurrency, asynchrony, multi-processing
    and threading, queuing, I/O and CPU limiting tasks.
  prefs: []
  type: TYPE_NORMAL
- en: To take a step further, the **programming language** used also comes into play.
    Python has emerged to be one of the top languages used in data science and general
    programming due to its widespread support and ease of use. However, as an interpreted
    language, it is significantly inferior compared to its compiled cousins like Go
    in terms of energy and speed (about x20) [4]. It is thus worth investing the effort
    to learn a second compiled language to cater for some jobs that require heavy
    processing.
  prefs: []
  type: TYPE_NORMAL
- en: '**3\. Green Servers**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To train and serve ML applications, compute power is required. This is provided
    by servers hosted either on-premise or in the cloud. If possible, going cloud
    is the best way to stay green since CSPs are incentivised to run their data centres
    efficiently, and you have the flexibility to switch resources based on project
    demands. Either way, we should ensure two key factors; choose the **right hardware**
    for the task, and use the **compute only when required**.
  prefs: []
  type: TYPE_NORMAL
- en: Major CSPs all have a diverse selection of servers to choose from. E.g., AWS
    has seven instance families each having a range of different chips, memory and
    other specifications, enough to cater for all scenarios like GPU, CPU, memory-intensive
    processes, or even ARM or x86 architecture. We should choose those that best maximise
    our use case so that compute is efficiently allocated through its hardware specifications.
  prefs: []
  type: TYPE_NORMAL
- en: How do we compute only when required? For a start, stock-take and turn off any
    resources that are not in use. You will be surprised how many idle services are
    left from legacy projects. In terms of architecture design, we can choose to use
    serverless compute like AWS lambda which only uses the resource when there is
    traffic, or provide a basic long-live compute with horizontal scaling that responds
    automatically to increased load.
  prefs: []
  type: TYPE_NORMAL
- en: '**4\. Green Storage**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Storage comes in many forms, e.g. object, block and file storage, container
    registries and databases. We can use two general guides to manage storage efficiently;
    **reduce the storage size** and **choose the right storage type**.
  prefs: []
  type: TYPE_NORMAL
- en: Storage size of data can be reduced simply by compression, some of the common
    ones being [gzip](https://www.gnu.org/software/gzip/) or for archival `tar.gz`,
    which can reduce the size by half. Using a more efficient data structure can also
    be a better alternative. Using a columnar format like [parquet](/csv-files-for-storage-no-thanks-theres-a-better-option-72c78a414d1d)
    not only occupies less space (>50%), but also enables faster queries (x30) due
    to the nature of its columnar structure.
  prefs: []
  type: TYPE_NORMAL
- en: Taking the example of object storage, there are storage classes that use less
    energy. In AWS S3, we can choose to keep less important data in one zone rather
    than replicate it across zones. For infrequently access, long-term storage, we
    can place them in “cold storage” (S3 glacier), where tape drives which consume
    a lot less energy compared to SSDs and HDDs are used. Lifecycle policies can also
    be set to automate transit between storage classes or even delete the data when
    a project reaches its conclusion.
  prefs: []
  type: TYPE_NORMAL
- en: '**5\. Green Transfers**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data needs to be transmitted to and fro between servers, storage and other devices.
    Network communication requires energy too, to support a complex weave of networking
    devices, data centers, transmission infrastructure and end-user devices. For developers
    like us, we can reduce our carbon impact through the use of **efficient transfer
    protocols**, as well as the **reducing the frequency and distance of transfers**.
  prefs: []
  type: TYPE_NORMAL
- en: Where possible, the http/2 transfer protocol with the gRCP framework should
    be considered, since it can transmit in a more compact binary format rather than
    the traditional text (JSON) payloads in http/1\. Of course with that comes lower
    latency and energy used.
  prefs: []
  type: TYPE_NORMAL
- en: Bringing data closer to the source of usage, and scheduling their transfers
    can also decrease the energy required. For example, dependencies required to run
    our automated test cases can be cached and rebuilt only when new changes are detected.
    Images do not need to be pulled from Dockerhub every time; we can store them in
    our CSP’s registry and only update them periodically when new patches are available.
  prefs: []
  type: TYPE_NORMAL
- en: '**6\. Green Templates**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This refers to the **reusability and repeatability** of efficient code, infrastructure
    and processes. In essence, this is an indirect form of reducing electricity consumption,
    since the actual implementations are from the previous five themes. However, I
    consider this as the most important one since it is the sum of the team knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: It can come in the form of documentation or playbooks that set the standards
    for the team functions and how projects are executed, or cookie-cutter templates
    for repositories, CICD pipelines, infrastructure setups (e.g., Terraform) and
    configurations (e.g., Ansible).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/626caa5ca6f83abf2162ff397acff147.png)'
  prefs: []
  type: TYPE_IMG
- en: Decision quadrant to prioritise high-impact and easy-to-implement solutions.
    Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Within each of the six themes, I have given some examples, but that is only
    the tip of the iceberg. The recommendations to implement within each theme are
    numerous and daunting. However, a progressive transition can be done by placing
    each of them in a decision quadrant through estimations of how difficult they
    are to implement in our existing workflows as well as if their impacts are significant
    and synergistic. This will provide some guidance on which ones to prioritise.
  prefs: []
  type: TYPE_NORMAL
- en: '**Design Principles**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This transformation is neither straightforward nor easy. Even for passionate
    tree-hugging developers like us who care, we still need to prioritise our business
    needs. One way we can deal with this is **not to think of sustainability and carbon
    efficiency in ML development as antagonistic or mutually exclusive to other needs**.
    This will ensure that you are still aligned to business goals and also get easier
    buy-in with management who are always pressured with delivery.
  prefs: []
  type: TYPE_NORMAL
- en: We can visualise this as a Venn diagram using AWS’s six design pillars of its
    [Well-Architected Framework](https://aws.amazon.com/architecture/well-architected/?wa-lens-whitepapers.sort-by=item.additionalFields.sortDate&wa-lens-whitepapers.sort-order=desc&wa-guidance-whitepapers.sort-by=item.additionalFields.sortDate&wa-guidance-whitepapers.sort-order=desc),
    where functional or business needs overlap with sustainability.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ba1e5b364e7c079b85b26117f459e50b.png)'
  prefs: []
  type: TYPE_IMG
- en: Reimagining the Well-Architected Framework. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, if you think about it, there are more often than not, synergistic
    impacts. Let’s take some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: Compressing your data storage can reduce x2 size and results in terms of cost
    savings and bandwidth, and also less energy to store and transfer them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quantisation of neural network models has better performance in terms of faster
    inference, and hence consuming less energy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removing unused dependencies in your docker images will improve security through
    the reduction of potentially exploitable surface area, increase the speed of deployment
    with its smaller size, and reduce the energy to store and transfer them to and
    from your registry.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All-in-all, this was a good kickstart of our journey to reduce our carbon impact
    in the engineering team. There will be a lot more work to identify, quantify,
    standardise and educate each recommendation that falls under each theme of green
    computing.
  prefs: []
  type: TYPE_NORMAL
- en: I would like to hear about your journey in measuring and reducing your carbon
    footprint in your development team. Please share in the comments below!
  prefs: []
  type: TYPE_NORMAL
- en: '***Acknowledgements****: This carbon accounting attempt is a personal project
    done together with my peers,* [*Yang Kewen*](https://medium.com/u/a874892260e0?source=post_page-----ce170bd4fae9--------------------------------)
    *and* [*Chong-Yaw Wee*](https://medium.com/u/13e5c1d5b037?source=post_page-----ce170bd4fae9--------------------------------)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: '***Disclaimer****: Opinions and recommendations expressed here are done in
    the author’s personal capacity.*'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] UN Environment Programme. Facts about the climate emergency. [https://www.unep.org/facts-about-climate-emergency](https://www.unep.org/facts-about-climate-emergency)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] Standfort University. Artificial Intelligence Index Report 2023\. Chapter
    2, Technical Performance. [https://aiindex.stanford.edu/report/](https://aiindex.stanford.edu/report/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] Touvron, et. al. 2023\. Llama 2: Open Foundation and Fine-Tuned Chat Models.
    *arXiv:2307.09288\.* [https://browse.arxiv.org/pdf/2307.09288.pdf](https://browse.arxiv.org/pdf/2307.09288.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] Pereira, et. al. 2017\. Energy efficiency across programming languages:
    how do energy, time, and memory relate? *Proceedings of the 10th ACM SIGPLAN International
    Conference on Software Language Engineering*. pp 256–267.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
