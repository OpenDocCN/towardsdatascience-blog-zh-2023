# 机器学习与优化算法的结合

> 原文：[https://towardsdatascience.com/a-marriage-of-machine-learning-and-optimization-algorithms-e6c680454f06](https://towardsdatascience.com/a-marriage-of-machine-learning-and-optimization-algorithms-e6c680454f06)

## 模式检测和模式利用如何将彼此提升到一个新的层次

[](https://wvheeswijk.medium.com/?source=post_page-----e6c680454f06--------------------------------)[![Wouter van Heeswijk, PhD](../Images/9c996bccd6fdfb6d9aa8b50b93338eb9.png)](https://wvheeswijk.medium.com/?source=post_page-----e6c680454f06--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e6c680454f06--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e6c680454f06--------------------------------) [Wouter van Heeswijk, PhD](https://wvheeswijk.medium.com/?source=post_page-----e6c680454f06--------------------------------)

·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e6c680454f06--------------------------------) ·阅读时间 12 分钟·2023年12月2日

--

![](../Images/a9b9c8c0940005f58cb100e812a31d72.png)

我们不应将基准优化和机器学习算法相互比较，而应考虑它们如何相互加强 [图片由 [Wedding Dreamz](https://unsplash.com/@wedding_dreamz?utm_source=medium&utm_medium=referral) 提供，在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) 上]

尽管我们大多数人看不到，但优化算法（OAs）无处不在。它们为我们的超市规划货架，为机场制定航班时间表，并为我们提供前往度假目的地的最短路线。**特别是精确算法在利用已知结构方面表现优异** — 例如，凸结构 — 即使在具有众多约束的大型决策空间中也能找到解决方案。在过去几十年中，硬件和算法的改进相结合，带来了数百万倍的速度提升。一个可能在90年代需要几个月才能完成的规划任务，如今可能只需一秒钟。

同样，机器学习（ML）在过去十年左右取得了惊人的进展。MuZero 展现了在不知道游戏规则的情况下学习超人类游戏策略的能力，图神经网络学习了人眼无法感知的复杂关系，而变换器（Transformers）催生了 ChatGPT 及其竞争对手。**这些算法的共同点在于它们都能够从环境中检测模式**，无论是文本数据库还是视频游戏。新颖且极其复杂的架构不断被引入，通常解决新的问题并提供无与伦比的性能。尽管取得了诸多成功和突破，对于许多现实世界的问题，端到端的机器学习仍难以取得竞争性结果。定制的优化算法通常仍然优于机器学习，但可能需要大量的计算时间。

这两种方法并不需要竞争。有趣的是，**优化算法擅长于*利用*模式，而机器学习则在*检测*模式方面表现出色。** 不如将它们作为补充的两个部分结合起来，而不是对比它们的优劣，是否更有意义？

在合并优化和机器学习时，通常归结为**统计学习被用来以某种形式改进优化例程**。这样，我们可以通过利用学到的模式来加速搜索。这种集成解决方案的开发近年来已成为一个新兴的研究领域，未来有许多令人兴奋的可能性。

# 我们如何将机器学习和优化算法结合起来？

我们已经确定了优化算法擅长利用结构，而机器学习擅长检测结构，因此它们之间存在自然的协同效应。然而，具体来说，什么构成了优化算法与机器学习之间的结合？广义上，我们可以将其分类为以下四个类别：

> **I.** **优化算法（OA）为机器学习（ML）提供输入。** 优化算法可能提供一个启发式解决方案，该方案可以通过机器学习进一步改进，或者它可能在算法管道中执行计算密集型的预处理步骤。
> 
> **II. 机器学习（ML）为优化算法（OA）提供输入。** 例如，机器学习可以建议一个用于热启动的起始解决方案，或者学习问题结构供优化算法利用。
> 
> **III.** **机器学习（ML）用于加速优化算法（OA）。** 机器学习可以用于迭代检测结构，帮助优化算法更快地找到解决方案。
> 
> **IV.** **优化算法（OA）解决机器学习中的子例程。** 像树搜索或动作空间评估这样的例程可以通过优化算法高效执行。

让我们对此进行一些实际的解释。由于数据记录和利用的增加，算法管道变得越来越复杂。它们通常由多个任务组成，有些更适合优化算法，有些则更适合机器学习。因此，一个范式向另一个范式提供输入已经变得非常自然。

此外，公司通常会重复解决特定问题的变体。例如，运输公司可能每天解决一次车辆路径问题，处理在客户、时间窗口和负载大小方面变量但可比的实例。如果通用求解器能够利用这些相似性，优化算法的运行效率将会提高。

最后，由于机器学习作为端到端的范式通常尚未与优化算法相竞争，因此优化某些子程序往往会有所帮助。这通常会加速机器学习算法并增强其竞争力。

一般来说，当以下情况成立时，结合优化算法和机器学习是有意义的：

+   优化算法（或人类专家）在合理的时间内提供解决方案的速度太慢。

+   启发式解决方案仍有改进的空间，或者尚不清楚它们实际效果如何（好或差）。

+   仍需识别良好的解决方案。

+   需要一种快速的近似解决方案。

+   算法流程涉及模式检测和模式探索的元素。

我们将优化算法和机器学习进行背景化处理，然后提供一些说明性的例子。

# 优化算法

有必要简要介绍优化算法。为了与机器学习集成一致，我们粗略地将其分类为**精确算法（最优解但速度较慢）**和**启发式方法（次优解但更快）**。

## 精确算法

精确算法是用于优化问题的强大技术，能够在可行的解决方案空间内找到**可证明的最优解**。通常，问题被表述为**数学规划**（例如，线性或二次规划），可以使用如 CPLEX、SCIP 或 Gurobi 等优化软件进行求解。这些求解器系统地探索解决方案空间，并保证找到最佳解。

尽管现成的方案功能强大，但可以处理的解决方案空间是有限的。对于非常大的问题，我们通常需要投入大量设计工作来设计**分支、定价和/或裁剪方案**，以减少搜索复杂性并有效地导航解决方案空间，同时保留最优性保证。

## 启发式方法

启发式方法提供了一种替代问题解决方案，**以牺牲最优性保证换取计算效率**。启发式方法特别适用于大规模或复杂问题，这些问题在合理的时间框架内寻找最优解是不切实际的。

基本启发式方法提供快速的**经验规则解决方案**。它们通常会产生次优结果，但通常会在有限的计算时间内返回不错的解决方案。例子包括最近邻插入或2-opt交换。

元启发式方法采用更高层次的**指导搜索解决方案的策略**，通常包含随机性和适应性元素。例子包括遗传算法、模拟退火和粒子群优化。元启发式方法在调整工作和运行时间方面更为密集，但通常能提供比基本启发式方法更优的结果。

# 机器学习

我们讨论了两种机器学习范式；演示学习和经验学习。尽管**与现有分类（无论是监督学习还是强化学习）密切相关**，我们在这里旨在更多地连接到优化背景。

## 演示学习

演示学习通过最小化提供的专家策略与预测策略之间的距离（监督学习）来进行。它可以被视为一个**师生模型**，其中学生（机器学习模型）旨在模仿老师（例如，精确算法、量身定制的启发式方法或人工制定的解决方案）。需要注意的是，这种学习形式因此需要某种形式的理论或经验知识。

机器学习模型预测的解决方案与已知专家解决方案之间的差异允许计算损失函数，算法随后旨在最小化这个损失函数。如果机器学习算法展示了许多**高质量解决方案的例子**，我们希望它最终能够复制这些解决方案。

演示学习的缺点在于它**无法超越专家策略**。如果专家策略是次优的，那么预测的策略也是如此。因此，演示学习只有在获取原始解决方案花费时间过长且希望在较短时间内获得相同解决方案时才有意义。然而，如果生成示例解决方案需要过长时间，这个想法也会失败。这使得演示学习处于一种相对尴尬的境地。

> 演示学习是一种**模仿学习**。我们尝试更快地再现专家提供的相同决策。

![](../Images/55f40c53f950c314c07bb614ff28d44a.png)

在演示学习中，机器学习算法旨在尽可能接近专家解决方案[照片来源于[Andre Mouton](https://unsplash.com/@andremouton?utm_source=medium&utm_medium=referral)于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)]

## 经验学习

与演示学习相对，经验学习利用通过部署策略获得的观察数据，旨在改进这些策略。这种学习形式通常与强化学习（RL）相关联，**通过观察从环境中获得的奖励迭代执行和改进策略**。

与示范学习相比，**经验学习不需要关于解决方案质量或结构的先验知识**。缺点是——在其最纯粹的形式下——它**不利用有关环境的信息**，仅通过状态、动作和奖励与环境进行交互。与经验学习相关的常见问题包括陷入局部最优、需要适当地定义奖励以及广泛探索解决方案空间。

> 经验学习利用来自环境的反馈信号，以便随着时间的推移改进其决策政策。

![](../Images/c12e61460615fc47c93f3297103f50ad.png)

在经验学习中，ML算法旨在通过与环境的交互来改进其决策政策 [照片由 [Alex Kondratiev](https://unsplash.com/@alexkondratiev?utm_source=medium&utm_medium=referral) 提供，在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) 上]

请注意，这两种学习形式都有显著的缺点，这在一定程度上解释了为什么**端到端机器学习在现实世界问题上仍然面临困难**。因此，OA和ML的集成确实是互利的。

当然，可以在一个单一的流程中应用这两种学习形式，或者说这可能更为优越。一个例子是（i）通过示范学习生成初始解决方案，（ii）通过优化求解器进行改进，以及（iii）利用经验学习来指导对最优解决方案的搜索。

# MO-OA 示例

接下来是一些具体的例子。以下是基于学术研究的三个代表性例子。

## I. 学习分支

也许最为研究透彻的例子是集成了OA和ML的分支学习，或者更具体地说，是利用ML来指导分支限界算法。对于那些不熟悉这个概念的人：**分支限界通过系统地探索一个非常大的搜索树来解决整数问题**，根据既定的界限修剪那些已被证明是次优或不太有希望的分支。如果子问题的松弛解不包含最优解，那么它的相邻整数也不会包含。

尽管分支限界是一个著名的算法，用于在大动作空间中寻找最优解，但在幕后仍然会做出一些相当**基本的启发式选择**：

+   **变量选择**：*下一步要分支的变量*。一个常见的决策规则是简单地选择最“接近0.5”的变量进行分支。

+   **节点选择**：*首先处理当前开放的节点中的哪个*。极端的做法是总是探索最有希望的节点（最优先）或总是完全探索一个节点的子树（深度优先）。

![](../Images/be1c69afb096d40365c90a3a67b1b5af.png)

分支限界过程的例子。选择下一个要探索的节点和要分支的变量通常基于启发式规则 [图片来自 [WikiMedia](https://commons.wikimedia.org/wiki/File:Microsoft_Edge_1_27_2020_1_35_41_AM_(2).png)]

说实话，这种简化并未能公正地反映多年来开发出的更复杂的启发式算法。然而，尽管有最终找到最优解决方案的保证，实际**搜索过程并没有像预期的那样智能**，这是通用求解器的代价。

鉴于**树搜索是顺序的且高度动态**，用动态学习基础的规则替代静态启发式规则似乎是合理的。例如，节点、分支和树的动态特征可以设计用来预测合适的变量和节点，其值由机器学习进行学习。

过去几年提出了许多解决方案，从离线示范学习到在线经验学习。一个直观的例子是[上置信界](https://medium.com/towards-data-science/seven-exploration-strategies-in-reinforcement-learning-you-should-know-8eca7dec503b)，**基于节点的感知价值和访问次数来平衡探索和利用**。

学习分支的例子说明了机器学习可以在精确算法的背景下应用，可能会**加快搜索过程**，**而不牺牲** **最优性保证**。

> 基于 Lodi & Zarpellon (2017) 和 Balcan 等 (2018) 的示例

## II. 使用 GNN 进行路由学习

路由问题的实例通常通过图表示。客户位置和旅行距离是这些图中明显的属性，但节点和弧线可以有各种标签，例如时间窗口和交通密度。图神经网络（GNNs）是一种强大的技术，用于**嵌入并有意义地表示这些图**在问题背景中。

![](../Images/b21c261c272dd47e01255bda6b1390d5.png)

车辆路由问题是一个经典的组合优化问题，随着节点数量的增加，规模呈指数爆炸增长 [图片来自 [WikiMedia](https://en.wikipedia.org/wiki/Vehicle_routing_problem#/media/File:Figure_illustrating_the_vehicle_routing_problem.png)]

传统上，路线是使用精确求解器（例如 Concorde TSP Solver）或元启发式算法（例如混合遗传搜索）生成的。然而，这些求解器需要相当**长的运行时间**，精确算法在面对大型实例时完全无法提供解决方案。

与其每次遇到新的问题实例时运行优化算法数小时，不如通过检测其解决方案中的模式来学习复制它们。这个例子是一种**示范学习**，试图最小化计算密集型最优解决方案与机器学习生成的解决方案之间的性能差距。在这个过程中会有一定的质量损失，但解决方案可以在更友好的时间框架内生成。

通过对解决方案运行GNNs，可以估计**边被纳入解决方案的概率**。随后，构建一个稀疏的热图，保留最有前景的边。根据这个热图，运行一个动态规划子程序进行逐步构建路线。如果某条路线被其他路线主导，可以进行剪枝。

> 基于Kool等人（2019）和Kool等人（2022）的示例

## III. 大动作空间的数学编程

在这个最终案例中，数学编程作为强化学习中的一个子程序被部署，目的是处理大动作空间。

组合优化问题有迅速**规模爆炸**的趋势，例如，访问一组节点的序列数是节点的阶乘。它们通常需要处理**许多约束**，如卡车的容量和最大驾驶时间或客户节点的时间窗口。枚举所有动作并进行可行性检查变得非常繁琐。

如果问题结构允许，**一阶决策问题可以被形式化为线性规划**。这种程序可以非常高效地解决，大大扩展了传统RL算法——依赖于明确枚举——所能处理的动作空间大小。

![](../Images/e86df850a3efd84b0ca5578b4ab7acb8.png)

线性规划可以高效地探索带约束的大动作空间 [图片来源 [WikiMedia](https://commons.wikimedia.org/wiki/File:Linear_optimization_in_a_2-dimensional_polytope.svg)]

OA与ML的整合并未止步于此。接下来，考虑Q值的近似。在许多现代RL应用中，这通常通过[**深度Q网络**](https://medium.com/towards-data-science/a-minimal-working-example-for-deep-q-learning-in-tensorflow-2-0-e0ca8a944d5e)来完成，该网络通过定义在其输入上执行非线性变换。然而，ReLU激活函数可以通过分段线性函数嵌入到目标函数中，支持一组附加约束。

另一个OA层？我们可以施加领域限制和**局部分支**来控制动作空间，仅探索我们怀疑（基于Q值）最佳动作所在的邻域。

> 基于Van Heeswijk, W.J.A. & La Poutré（2020）和Akkerman等人（2023）的示例

正如你所见，机器学习与优化算法的整合机会广阔而多样。这已经是一个活跃的研究领域，潜力尚未完全释放。

# **总结**

+   机器学习和优化算法在计算时间、性能保证、知识利用等方面都有缺陷。鉴于这两种范式的性质，它们可能自然互补。

+   机器学习专注于**模式检测**，优化算法专注于模式**利用**。它们可以结合起来构建强大的算法管道。

+   在实践中，公司通常会重复解决单一问题，并且这些问题的变异性相对有限。**从解决方案数据中提取模式**（即统计学习）可以提升现有的精确方法或启发式方法。

+   机器学习可以以**示范学习**的形式使用（在极短时间内近似优化算法的解决方案）或**经验学习**的形式使用（与环境互动以迭代地增强策略）。

*你可能还会喜欢以下文章：*

[](/using-linear-programming-to-boost-your-reinforcement-learning-algorithms-994977665902?source=post_page-----e6c680454f06--------------------------------) [## 使用线性规划来提升强化学习算法

### 在强化学习中，大规模和高维的动作空间通常是计算瓶颈。制定……

towardsdatascience.com](/using-linear-programming-to-boost-your-reinforcement-learning-algorithms-994977665902?source=post_page-----e6c680454f06--------------------------------) [](/five-ways-to-handle-large-action-spaces-in-reinforcement-learning-8ba6b6ca7472?source=post_page-----e6c680454f06--------------------------------) [## 五种处理强化学习中大规模动作空间的方法

### 动作空间，特别是在组合优化问题中，可能会变得庞大不便。本文讨论了……

towardsdatascience.com](/five-ways-to-handle-large-action-spaces-in-reinforcement-learning-8ba6b6ca7472?source=post_page-----e6c680454f06--------------------------------)

*对于那些对组合优化中的机器学习感兴趣的人，我热情推荐以下由Andrea Lodi教授做的主题演讲：*

# 参考文献

Akkerman, F., Luy, J., Van Heeswijk, W.J.A., & Schiffer, M. (2023). 通过动态邻域构造处理大规模离散动作空间。*arXiv预印本arXiv:2305.19891*。

Balcan, M. F., Dick, T., Sandholm, T., & Vitercik, E. (2018年7月). 学习分支。见 *国际机器学习会议* （第344–353页）。PMLR.

Khalil, E., Le Bodic, P., Song, L., Nemhauser, G., & Dilkina, B. (2016年2月). 在混合整数规划中学习分支。见 *人工智能协会会议论文集*（第30卷，第1号）。

Kool, W., Van Hoof, H., & Welling, M. (2019). 注意，学习解决路线问题！国际学习表示大会2019。

Kool, W., Van Hoof, H., Gromicho, J., & Welling, M. (2022年6月). 针对车辆路线问题的深度策略动态规划。在 *国际约束编程、人工智能和运筹学整合会议* （第190–213页）。Cham: Springer International Publishing.

Lodi, A., & Zarpellon, G. (2017). 关于学习和分支的综述。*Top*, *25*, 207–236.

Parmentier, A. 和 T’kindt, V.（2023）。基于结构学习的启发式方法解决具有释放时间和完成时间总和的单台机器调度问题。*欧洲运筹学期刊*，*305*(3)，1032–1041。

Santana, Í., Lodi, A., 和 Vidal, T.（2023年5月）。车辆路径中的局部搜索和交叉的神经网络：可能的过度杀伤？在*约束编程、人工智能与运筹学集成国际会议*（第184–199页）。Cham：Springer Nature Switzerland。

Van Heeswijk, W.J.A. van 和 La Poutré, H.L.（2020年12月）。线性离散动作空间中的深度强化学习。在*2020年冬季模拟会议（WSC）*（第1063–1074页）。IEEE。

Vazacopoulos, A.（2020）。使用 Python 结合机器学习和数学优化集成。通过 [LinkedIn](https://www.linkedin.com/pulse/combining-machine-learning-mathematical-optimization-vazacopoulos/)。
