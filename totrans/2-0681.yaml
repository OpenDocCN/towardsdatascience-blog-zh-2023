- en: Decision Tree Regressor — A Visual Guide with Scikit Learn
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树回归器——Scikit Learn 的可视化指南
- en: 原文：[https://towardsdatascience.com/decision-tree-regressor-a-visual-guide-with-scikit-learn-2aa9e01f5d7f](https://towardsdatascience.com/decision-tree-regressor-a-visual-guide-with-scikit-learn-2aa9e01f5d7f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/decision-tree-regressor-a-visual-guide-with-scikit-learn-2aa9e01f5d7f](https://towardsdatascience.com/decision-tree-regressor-a-visual-guide-with-scikit-learn-2aa9e01f5d7f)
- en: '![](../Images/1c7a634936cbcb80db53a4f5a26d81d1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1c7a634936cbcb80db53a4f5a26d81d1.png)'
- en: Photo by [niko photos](https://unsplash.com/@niko_photos?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [niko photos](https://unsplash.com/@niko_photos?utm_source=medium&utm_medium=referral)
    提供，发布在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Understanding Decision Trees without Math
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无需数学知识了解决策树
- en: '[](https://medium.com/@angela.shi?source=post_page-----2aa9e01f5d7f--------------------------------)[![Angela
    and Kezhan Shi](../Images/a89d678f2f3887c0c2ff3928f9d767b4.png)](https://medium.com/@angela.shi?source=post_page-----2aa9e01f5d7f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2aa9e01f5d7f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2aa9e01f5d7f--------------------------------)
    [Angela and Kezhan Shi](https://medium.com/@angela.shi?source=post_page-----2aa9e01f5d7f--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@angela.shi?source=post_page-----2aa9e01f5d7f--------------------------------)[![Angela
    and Kezhan Shi](../Images/a89d678f2f3887c0c2ff3928f9d767b4.png)](https://medium.com/@angela.shi?source=post_page-----2aa9e01f5d7f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2aa9e01f5d7f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2aa9e01f5d7f--------------------------------)
    [Angela and Kezhan Shi](https://medium.com/@angela.shi?source=post_page-----2aa9e01f5d7f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2aa9e01f5d7f--------------------------------)
    ·5 min read·Mar 27, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2aa9e01f5d7f--------------------------------)
    ·5 分钟阅读·2023年3月27日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: In this article, we will implement the DecisionTreeRegressor from scikit-learn
    in python to visualize how this model works. We will not use any mathematical
    terms, but we will use visualization to demonstrate how a decision tree regressor
    works, and the impact of some hyperparameters.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将使用 Python 中的 scikit-learn 实现 DecisionTreeRegressor，以可视化该模型的工作原理。我们不会使用任何数学术语，而是通过可视化来展示决策树回归器的工作原理及一些超参数的影响。
- en: For the context, a Decision Tree Regressor tries to predict a continuous target
    variable by cutting the feature variables into small zones, and each zone will
    have one prediction. We will begin with one continuous variable and then two continuous
    variables. We will not use categorical variables since for decision trees, continuous
    variables are ultimately treated like categorical data when the splits are made.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个背景下，决策树回归器通过将特征变量切分成小区域来预测一个连续的目标变量，每个区域将有一个预测值。我们将从一个连续变量开始，然后是两个连续变量。我们不会使用分类变量，因为对于决策树，当进行切分时，连续变量最终会像分类数据一样处理。
- en: 'We will mainly study the impact of two hyperparameters that can be quite intuitive
    to understand: max depth and min_samples_leaf. Other hyperparameters are similar,
    the main idea is to limit the size of the rules.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将主要研究两个直观易懂的超参数的影响：max depth 和 min_samples_leaf。其他超参数类似，主要思想是限制规则的大小。
- en: One Non-Linear variable
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个非线性变量
- en: Let’s use some simple data, with only feature variable x.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用一些简单的数据，只有特征变量 x。
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: And we can visualize the data in an (x,y) plot
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在一个 (x,y) 图中可视化数据
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'And in the following image, for the first cut, we can visually guess two possible
    splits as shown below:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，对于第一次切分，我们可以直观地猜测出两种可能的分割，如下所示：
- en: '![](../Images/b58bce69f055039ca6a6f37874b689b1.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b58bce69f055039ca6a6f37874b689b1.png)'
- en: Decision tree regressor visualization — image by author
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树回归器可视化——作者提供的图像
- en: 'Now, the Decision Tree Regressor model determines exactly which split is better.
    Let’s specify the argument max_depth=1, to get only one split:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，决策树回归器模型准确地决定了哪个分割更好。我们指定参数 max_depth=1，以仅获得一个分割：
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/97af2310fceac27e1a94629d551e194f.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97af2310fceac27e1a94629d551e194f.png)'
- en: Decision tree regressor visualization — image by author
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树回归器可视化——作者提供的图像
- en: 'If we decide to get 4 regions, we can try max_depth=2, and we get:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们决定得到 4 个区域，我们可以尝试 max_depth=2，并得到：
- en: '![](../Images/5d66c6e3292184eaccdcec67b5e190ad.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d66c6e3292184eaccdcec67b5e190ad.png)'
- en: Decision tree regressor visualization — image by author
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树回归器可视化 — 作者提供的图片
- en: 'We can then visualize how the max_depth hyperparameter impacts the final model
    with the image below:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以通过下面的图片可视化 `max_depth` 超参数对最终模型的影响：
- en: '![](../Images/ce425193980e93660c02103190c00dbc.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ce425193980e93660c02103190c00dbc.png)'
- en: Decision tree regressor visualization — image by author
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树回归器可视化 — 作者提供的图片
- en: We can also plot the same with another hyperparameter min_samples_leaf, which
    is the minimum number of observations that should be in the final regions (that
    we call leaves because at the end of a tree’s ramification, we find leaves!)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以用另一个超参数 `min_samples_leaf` 绘制相同的图形，它是最终区域（我们称之为叶子，因为在树的分支末端，我们找到叶子）的最小观察数。
- en: '![](../Images/d58646d30f99a295c1f1ef77d0073a20.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d58646d30f99a295c1f1ef77d0073a20.png)'
- en: Decision tree regressor visualization — image by author
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树回归器可视化 — 作者提供的图片
- en: One “Linear” Feature
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个“线性”特征
- en: Decision Tree Regressor is a non-linear regressor. We can see how it behaves/models
    the data from the previous examples. What happens to “linear” data?
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树回归器是一个非线性回归器。我们可以从之前的示例中看到它如何表现/建模数据。对于“线性”数据会发生什么呢？
- en: 'Let’s take this simple example of perfectly linear data:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以这个完美线性数据的简单例子开始：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You can see that the relationship is very simple: y = x!'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到关系非常简单：y = x！
- en: If we use the classic decision tree visualization, you may immediately see how
    the model behaves.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用经典的决策树可视化，你可以立即看到模型的表现。
- en: '![](../Images/0ea68877d86d3bc534a1c0ec93e4f674.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0ea68877d86d3bc534a1c0ec93e4f674.png)'
- en: Now, we can create the same plot below. And sometimes people are surprised to
    SEE that a Decision Tree divides the perfect line into regions and gives a few
    values for the predictions, even for a linear dataset.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以创建下面相同的图形。有时，人们会惊讶地看到决策树将完美的线分割成区域，并为预测提供几个值，即使对于线性数据集也是如此。
- en: '![](../Images/92b8a490a9d1f32e66712b9c5ba74f35.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/92b8a490a9d1f32e66712b9c5ba74f35.png)'
- en: Then people would comment by saying that the model is not adapted at all for
    this dataset, and we should not use it.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 然后人们会评论说这个模型根本不适合这个数据集，我们不应该使用它。
- en: Now, the truth is that you can not know the behavior of the dataset in advance.
    And that is what the No Free Lunch Theory is all about.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，事实是你无法提前知道数据集的行为。这就是“无免费午餐定理”的全部内容。
- en: And in practice, you can apply several models such as linear regression and
    decision trees. If there is one model that is significant more performant than
    another, then you can conclude about the linear vs. non-linear behavior of the
    data.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际操作中，你可以应用几种模型，如线性回归和决策树。如果有一个模型显著优于另一个模型，那么你可以对数据的线性与非线性行为做出结论。
- en: Two continuous features
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 两个连续特征
- en: For two continuous variables, we have to create a 3D plot.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对于两个连续变量，我们需要创建一个 3D 图。
- en: First, let’s generate some data.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们生成一些数据。
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Then can create the model:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 然后可以创建模型：
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Finally, we can create the 3D plot with plotly
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用 Plotly 创建 3D 图。
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can compare different values of depth as shown in the image below:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以比较不同深度的值，如下图所示：
- en: '![](../Images/09ea949b7b5c69c74fc3f7487fef5f52.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/09ea949b7b5c69c74fc3f7487fef5f52.png)'
- en: Decision tree regressor visualization — image by author
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树回归器可视化 — 作者提供的图片
- en: If you create a plot with python, you can manipulate it to see the visualization
    from different angles.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你用 Python 创建一个图形，你可以操控它以从不同角度查看可视化效果。
- en: Conclusion
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Visualizing the prediction of a model for simple datasets is an excellent way
    to understand how the models work.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化模型对简单数据集的预测是理解模型如何工作的一个极好的方法。
- en: In the case of decision trees, they already are quite intuitive to understand
    with the visualization of the rules in form of a tree. The classic visualization
    with x,y (and z) can be complementary.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于决策树来说，它们通过树状规则的可视化已经相当直观。经典的 x, y（和 z）可视化可以作为补充。
- en: We also can SEE that the model is highly non-linear. And the dataset does not
    need any scaling.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以看到模型是高度非线性的。而且数据集不需要任何缩放。
- en: 'I write about machine learning and data science and I explain complex concepts
    in a clear way. Please follow me with the link below and get full access to my
    articles: [https://medium.com/@angela.shi/membership](https://medium.com/@angela.shi/membership)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我写关于机器学习和数据科学的文章，并以清晰的方式解释复杂的概念。请通过下面的链接关注我并获取我的文章完整访问权限：[https://medium.com/@angela.shi/membership](https://medium.com/@angela.shi/membership)
