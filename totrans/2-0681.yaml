- en: Decision Tree Regressor — A Visual Guide with Scikit Learn
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树回归器——Scikit Learn 的可视化指南
- en: 原文：[https://towardsdatascience.com/decision-tree-regressor-a-visual-guide-with-scikit-learn-2aa9e01f5d7f](https://towardsdatascience.com/decision-tree-regressor-a-visual-guide-with-scikit-learn-2aa9e01f5d7f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/decision-tree-regressor-a-visual-guide-with-scikit-learn-2aa9e01f5d7f](https://towardsdatascience.com/decision-tree-regressor-a-visual-guide-with-scikit-learn-2aa9e01f5d7f)
- en: '![](../Images/1c7a634936cbcb80db53a4f5a26d81d1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1c7a634936cbcb80db53a4f5a26d81d1.png)'
- en: Photo by [niko photos](https://unsplash.com/@niko_photos?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [niko photos](https://unsplash.com/@niko_photos?utm_source=medium&utm_medium=referral)
    提供，发布在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Understanding Decision Trees without Math
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无需数学知识了解决策树
- en: '[](https://medium.com/@angela.shi?source=post_page-----2aa9e01f5d7f--------------------------------)[![Angela
    and Kezhan Shi](../Images/a89d678f2f3887c0c2ff3928f9d767b4.png)](https://medium.com/@angela.shi?source=post_page-----2aa9e01f5d7f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2aa9e01f5d7f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2aa9e01f5d7f--------------------------------)
    [Angela and Kezhan Shi](https://medium.com/@angela.shi?source=post_page-----2aa9e01f5d7f--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@angela.shi?source=post_page-----2aa9e01f5d7f--------------------------------)[![Angela
    and Kezhan Shi](../Images/a89d678f2f3887c0c2ff3928f9d767b4.png)](https://medium.com/@angela.shi?source=post_page-----2aa9e01f5d7f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2aa9e01f5d7f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2aa9e01f5d7f--------------------------------)
    [Angela and Kezhan Shi](https://medium.com/@angela.shi?source=post_page-----2aa9e01f5d7f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2aa9e01f5d7f--------------------------------)
    ·5 min read·Mar 27, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2aa9e01f5d7f--------------------------------)
    ·5 分钟阅读·2023年3月27日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: In this article, we will implement the DecisionTreeRegressor from scikit-learn
    in python to visualize how this model works. We will not use any mathematical
    terms, but we will use visualization to demonstrate how a decision tree regressor
    works, and the impact of some hyperparameters.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将使用 Python 中的 scikit-learn 实现 DecisionTreeRegressor，以可视化该模型的工作原理。我们不会使用任何数学术语，而是通过可视化来展示决策树回归器的工作原理及一些超参数的影响。
- en: For the context, a Decision Tree Regressor tries to predict a continuous target
    variable by cutting the feature variables into small zones, and each zone will
    have one prediction. We will begin with one continuous variable and then two continuous
    variables. We will not use categorical variables since for decision trees, continuous
    variables are ultimately treated like categorical data when the splits are made.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个背景下，决策树回归器通过将特征变量切分成小区域来预测一个连续的目标变量，每个区域将有一个预测值。我们将从一个连续变量开始，然后是两个连续变量。我们不会使用分类变量，因为对于决策树，当进行切分时，连续变量最终会像分类数据一样处理。
- en: 'We will mainly study the impact of two hyperparameters that can be quite intuitive
    to understand: max depth and min_samples_leaf. Other hyperparameters are similar,
    the main idea is to limit the size of the rules.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将主要研究两个直观易懂的超参数的影响：max depth 和 min_samples_leaf。其他超参数类似，主要思想是限制规则的大小。
- en: One Non-Linear variable
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个非线性变量
- en: Let’s use some simple data, with only feature variable x.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用一些简单的数据，只有特征变量 x。
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: And we can visualize the data in an (x,y) plot
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在一个 (x,y) 图中可视化数据
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'And in the following image, for the first cut, we can visually guess two possible
    splits as shown below:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，对于第一次切分，我们可以直观地猜测出两种可能的分割，如下所示：
- en: '![](../Images/b58bce69f055039ca6a6f37874b689b1.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b58bce69f055039ca6a6f37874b689b1.png)'
- en: Decision tree regressor visualization — image by author
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树回归器可视化——作者提供的图像
- en: 'Now, the Decision Tree Regressor model determines exactly which split is better.
    Let’s specify the argument max_depth=1, to get only one split:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，决策树回归器模型准确地决定了哪个分割更好。我们指定参数 max_depth=1，以仅获得一个分割：
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/97af2310fceac27e1a94629d551e194f.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97af2310fceac27e1a94629d551e194f.png)'
- en: Decision tree regressor visualization — image by author
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树回归器可视化——作者提供的图像
- en: 'If we decide to get 4 regions, we can try max_depth=2, and we get:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们决定得到 4 个区域，我们可以尝试 max_depth=2，并得到：
- en: '![](../Images/5d66c6e3292184eaccdcec67b5e190ad.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d66c6e3292184eaccdcec67b5e190ad.png)'
- en: Decision tree regressor visualization — image by author
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: 'We can then visualize how the max_depth hyperparameter impacts the final model
    with the image below:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ce425193980e93660c02103190c00dbc.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
- en: Decision tree regressor visualization — image by author
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: We can also plot the same with another hyperparameter min_samples_leaf, which
    is the minimum number of observations that should be in the final regions (that
    we call leaves because at the end of a tree’s ramification, we find leaves!)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d58646d30f99a295c1f1ef77d0073a20.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
- en: Decision tree regressor visualization — image by author
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: One “Linear” Feature
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Decision Tree Regressor is a non-linear regressor. We can see how it behaves/models
    the data from the previous examples. What happens to “linear” data?
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take this simple example of perfectly linear data:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You can see that the relationship is very simple: y = x!'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: If we use the classic decision tree visualization, you may immediately see how
    the model behaves.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0ea68877d86d3bc534a1c0ec93e4f674.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
- en: Now, we can create the same plot below. And sometimes people are surprised to
    SEE that a Decision Tree divides the perfect line into regions and gives a few
    values for the predictions, even for a linear dataset.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/92b8a490a9d1f32e66712b9c5ba74f35.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
- en: Then people would comment by saying that the model is not adapted at all for
    this dataset, and we should not use it.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Now, the truth is that you can not know the behavior of the dataset in advance.
    And that is what the No Free Lunch Theory is all about.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: And in practice, you can apply several models such as linear regression and
    decision trees. If there is one model that is significant more performant than
    another, then you can conclude about the linear vs. non-linear behavior of the
    data.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Two continuous features
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For two continuous variables, we have to create a 3D plot.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s generate some data.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Then can create the model:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Finally, we can create the 3D plot with plotly
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can compare different values of depth as shown in the image below:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/09ea949b7b5c69c74fc3f7487fef5f52.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
- en: Decision tree regressor visualization — image by author
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: If you create a plot with python, you can manipulate it to see the visualization
    from different angles.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Visualizing the prediction of a model for simple datasets is an excellent way
    to understand how the models work.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: In the case of decision trees, they already are quite intuitive to understand
    with the visualization of the rules in form of a tree. The classic visualization
    with x,y (and z) can be complementary.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: We also can SEE that the model is highly non-linear. And the dataset does not
    need any scaling.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: 'I write about machine learning and data science and I explain complex concepts
    in a clear way. Please follow me with the link below and get full access to my
    articles: [https://medium.com/@angela.shi/membership](https://medium.com/@angela.shi/membership)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
