["```py\nimport numpy as np\n\nP = np.asarray([[0.3, 0.5, 0.75], [0.1, 0.1, 0.1], [0.6, 0.4, 0.15]])\n\nprint(f\"Transition matrix P: {P}\")\n\n# Generate random initial distribution (normalize to obtain valid distribution).\npi = np.random.rand(3)\npi /= np.sum(pi)\n\nprint(f\"Initial distribution pi_0: {pi}\")\n\nfor i in range(30):\n    pi = np.matmul(P, pi)\n    if i % 5 == 0:\n        print(f\"Distribution after i steps: {pi}\")\n```", "```py\nDistribution after i steps: [0.51555326 0.1 0.38444674]\nDistribution after i steps: [0.499713 0.1 0.400287]\nDistribution after i steps: [0.5000053 0.1 0.3999947]\nDistribution after i steps: [0.4999999 0.1 0.4000001]\nDistribution after i steps: [0.5 0.1 0.4]\nDistribution after i steps: [0.5 0.1 0.4]\n```", "```py\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats\n\nNUM_SAMPLES = 10000\n\n# Target distribution\nf = scipy.stats.norm(5, 2)\n\n# Plot target distribution\nx = np.linspace(-5, 15, 5000)\nplt.plot(x, f.pdf(x))\n\n# Step 1\nx = np.random.uniform(-2, 2)\n\n# Proposal distribution\nq = scipy.stats.norm(0, 1)\n\nsamples = []\n\nfor i in range(NUM_SAMPLES):\n    # Step 2\n    y = x + q.rvs()\n    # Step 3\n    p = min(f.pdf(y) / f.pdf(x) * q.pdf(x - y) / q.pdf(y - x), 1)\n    # Step 4\n    u = np.random.uniform(0, 1)\n    # Step 5\n    x = y if u <= p else x\n    samples.append(x)\n\nplt.hist(samples, density=True, bins=30)\nplt.show()\n```", "```py\nfrom typing import Any\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport numpy.typing as npt\nimport scipy.stats\n\nMEAN = np.asarray([0, 0])\nVARIANCE = np.asarray([[0.25, 0.3], [0.3, 1]])\n\ndef plot_multivariate(\n    mean: npt.NDArray[np.float32], variance: npt.NDArray[np.float32]\n) -> None:\n    multivariate_normal = scipy.stats.multivariate_normal(mean, variance)\n\n    num_ticks = 100\n    min_axis_value = -5\n    max_axis_value = 5\n\n    x = np.linspace(min_axis_value, max_axis_value, num_ticks)\n    y = np.linspace(min_axis_value, max_axis_value, num_ticks)\n\n    X, Y = np.meshgrid(x, y)\n    pos = np.array([X.flatten(), Y.flatten()]).T\n\n    fig = plt.figure()\n    ax = fig.add_subplot(projection=\"3d\")\n    ax.plot_surface(\n        X,\n        Y,\n        multivariate_normal.pdf(pos).reshape((100, 100)),\n        cmap=\"viridis\",\n        linewidth=0,\n    )\n\n    plt.show()\n\nplot_multivariate(MEAN, VARIANCE)\n```", "```py\ndef get_cond_distr_x(\n    mean: npt.NDArray[np.float32], variance: npt.NDArray[np.float32], y: float\n) -> Any:\n    mean = mean[0] + variance[0, 1] * 1 / variance[1, 1] * (y - mean[1])\n    var = variance[0, 0] - variance[0, 1] * 1 / variance[1, 1] * variance[1, 0]\n    return scipy.stats.norm(mean, var)\n\ndef get_cond_distr_y(\n    mean: npt.NDArray[np.float32], variance: npt.NDArray[np.float32], x: float\n) -> Any:\n    mean = mean[1] + variance[1, 0] * 1 / variance[0, 0] * (x - mean[0])\n    var = variance[1, 1] - variance[1, 0] * 1 / variance[0, 0] * variance[0, 1]\n    return scipy.stats.norm(mean, var)\n\ndef gibbs_sampling(\n    mean: npt.NDArray[np.float32],\n    variance: npt.NDArray[np.float32],\n    num_samples: int = 50000,\n) -> npt.NDArray[np.float32]:\n    xs = []\n    ys = []\n\n    x = 0\n    for i in range(num_samples):\n        y = get_cond_distr_y(mean, variance, x).rvs()\n        x = get_cond_distr_x(mean, variance, y).rvs()\n        xs.append(x)\n        ys.append(y)\n\n    return np.stack((xs, ys)).transpose(1, 0)\n\nsampled_points = gibbs_sampling(MEAN, VARIANCE)\n```", "```py\ndef draw_3d_hist(points: npt.NDArray[np.float32]) -> None:\n    # Taken from https://matplotlib.org/stable/gallery/mplot3d/hist3d.html.\n    fig = plt.figure()\n    ax = fig.add_subplot(projection=\"3d\")\n    hist, xedges, yedges = np.histogram2d(\n        points[:, 0], points[:, 1], bins=50, range=[[-5, 5], [-5, 5]]\n    )\n\n    # Construct arrays for the anchor positions of the 16 bars.\n    xpos, ypos = np.meshgrid(\n        xedges[:-1] + 0.25, yedges[:-1] + 0.25, indexing=\"ij\"\n    )\n    xpos = xpos.ravel()\n    ypos = ypos.ravel()\n    zpos = 0\n\n    # Construct arrays with the dimensions for the bars.\n    dx = dy = 0.5 * np.ones_like(zpos)\n    dz = hist.ravel()\n\n    ax.bar3d(xpos, ypos, zpos, dx, dy, dz, zsort=\"average\")\n\n    plt.show()\n\ndraw_3d_hist(sampled_points)\n```", "```py\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats\n\nNUM_THROWS = 100  # Number of coin tosses\nTHETA_TRUE = 0.3  # True probability for landing heads\nTHETA_PRIOR = 0.5  # Prior estimate for heads probability\nNUM_SAMPLES = 100000  # Number of MCMC steps\n\n# Define the unfair coin and generate data from it\nunfair_coin = scipy.stats.bernoulli(THETA_TRUE)\nD = np.asarray([unfair_coin.rvs() for _ in range(NUM_THROWS)])\n\n# Define prior distribution\nprior = scipy.stats.norm(THETA_PRIOR)\n\ndef likelihood_ratio(theta_1, theta_2):\n    return (theta_1 / theta_2) ** np.sum(D == 1) * (\n        (1 - theta_1) / (1 - theta_2)\n    ) ** np.sum(D == 0)\n\ndef norm_ratio(theta_1, theta_2):\n    return prior.pdf(theta_1) / prior.pdf(theta_2)\n\n# Step 1\nx = np.random.uniform(0, 1)\n\n# Proposal distribution\nq = scipy.stats.norm(0, 0.1)\n\nsamples = []\n\nfor i in range(NUM_SAMPLES):\n    # Step 2\n    y = x + q.rvs()\n    # Step 3\n    ratio = likelihood_ratio(y, x) * norm_ratio(y, x)\n    p = min(ratio * q.pdf(x - y) / q.pdf(y - x), 1)\n    # Step 4\n    u = np.random.uniform(0, 1)\n    # Step 5\n    x = y if u <= p and 0 <= y <= 1 else x\n    samples.append(x)\n\nplt.hist(samples, density=True, bins=100)\nplt.show()\n```"]