# 回归评估指标的全面概述

> 原文：[https://towardsdatascience.com/a-comprehensive-overview-of-regression-evaluation-metrics-6264af0926db](https://towardsdatascience.com/a-comprehensive-overview-of-regression-evaluation-metrics-6264af0926db)

![](../Images/77a024aef30e9daead7e900ad76280bf.png)

图片由作者使用来自 [icons8](https://icons8.com/) 的图标创建

## 对常用回归评估指标及其在各种场景中的实际应用进行广泛参考

[](https://eryk-lewinson.medium.com/?source=post_page-----6264af0926db--------------------------------)[![Eryk Lewinson](../Images/56e09e19c0bbfecc582da58761d15078.png)](https://eryk-lewinson.medium.com/?source=post_page-----6264af0926db--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6264af0926db--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6264af0926db--------------------------------) [Eryk Lewinson](https://eryk-lewinson.medium.com/?source=post_page-----6264af0926db--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6264af0926db--------------------------------) ·阅读时间 15 分钟·2023年5月1日

--

作为数据科学家，评估机器学习模型的性能是你工作的重要方面。为了有效地做到这一点，你可以利用各种统计指标，每个指标都有其独特的优点和缺点。通过深入理解这些指标，你不仅可以更好地选择优化模型的最佳指标，还能向业务利益相关者解释你的选择及其影响。

在本文中，我重点介绍了用于评估回归问题的指标，这些问题预测数值——如房价或公司下月销售预测。由于回归分析被视为数据科学的基础，理解其细微差别是至关重要的。

# 残差的快速概述

残差是大多数指标的基本构建块。简单来说，残差是实际值与预测值之间的差异。

[PRE0]

下图展示了目标变量(*y*)与单个特征(*x*)之间的关系。蓝色点代表观测值。红线是机器学习模型的拟合结果，在这种情况下是线性回归。橙色线条表示观测值与这些观测的预测之间的差异。因此，可以为数据集中每个观测值（无论是训练集还是测试集）计算残差。

![](../Images/356b81e83a3513f71b5a25e3e422e269.png)

*图 1\. 具有一个特征的线性模型中的残差示例*

# 回归评估指标

本节讨论了一些最受欢迎的回归评估指标，这些指标可以帮助你评估模型的有效性。

## 偏差

最简单的误差度量是残差的总和，有时称为偏差。由于残差可以是正值（预测值小于实际值）和负值（预测值大于实际值），偏差通常告诉我们预测值是否高于或低于实际值。

然而，由于对立符号的残差相互抵消，我们可能会得到一个产生非常低偏差预测的模型，而其准确性却非常差。

另外，我们可以计算平均残差，或称为*均值偏差误差*（MBE）。

## R平方

下一个指标可能是你在学习回归模型时首先遇到的，特别是在统计学或计量经济学课程中。*R平方*（R²），也称为决定系数，表示模型解释的方差比例。更准确地说，R² 对应于因变量（目标）方差的程度可以由自变量（特征）解释。

以下公式用于计算 R²。

![](../Images/bec0d09162fb4bcbdcfa481c3c1c8a01.png)

其中：

+   RSS 是残差平方和，即残差平方的总和。这个值捕捉了模型的预测误差。

+   TSS 是总平方和。为了计算这个值，我们首先假设一个简单模型，其中每个观测值的预测值是所有观察实际值的均值。TSS 与因变量的方差成正比，因为 TSS/N 是*y* 的实际方差，其中 *N* 是观察次数。也就是说，我们可以将 TSS 看作是简单均值模型无法解释的方差。

实际上，我们是在比较一个模型的拟合程度（如图2中的红线所示）与一个简单均值模型的拟合程度（如图中绿色线所示）。

![](../Images/3710edf168b1704dd64a2052e0ed0a76.png)

*图2\. 比较线性模型与简单均值基准的拟合情况*

了解了 R² 的组成部分后，我们可以看到 RSS/TSS 代表了目标总方差中模型无法解释的部分。

在使用 R² 时需要注意一些额外的点。

首先，R² 是一个相对度量，即它可以用于与在相同数据集上训练的其他模型进行比较。更高的值表示拟合更好。

R² 也可以用来粗略估计模型的整体表现。然而，在使用 R² 进行这种评估时，我们应该小心：

+   首先，不同领域（社会科学、生物学、金融等）对 R² 的不同值有不同的好坏标准。

+   其次，R² 并没有给出任何偏差的度量，因此我们可能会有一个高 R² 值的过拟合（高度偏差）模型。因此，我们还应该查看其他指标，以便更好地理解模型的表现。

R² 的一个潜在缺点是它假设每个特征都有助于解释目标的变异，但这并不总是正确的。因此，如果我们继续向使用普通最小二乘法 (OLS) 估计的线性模型中添加特征，R² 的值可能会增加或保持不变，但从不会减少。

为什么？按设计，OLS 估计最小化 RSS。假设一个带有附加特征的模型没有提高第一个模型的 R² 值。在这种情况下，OLS 估计技术会将该特征的系数设为零（或一些统计上不显著的值）。这实际上将我们带回到初始模型。在最坏的情况下，我们可能得到的是起始点的评分。

解决前述问题的方法是调整后的 R²，它额外惩罚了添加那些对预测目标无用的特征。如果由于添加新特征导致的 R² 增加不够显著，调整后的 R² 值会下降。

最后一项，我们讨论 R² 值范围的常见误解。如果使用 OLS 拟合线性模型，则 R² 的范围是 0 到 1。这是因为使用 OLS 估计（最小化 RSS）时，一般属性是 *RSS ≤ TSS*。在最坏的情况下，OLS 估计将导致获得均值模型。在这种情况下，RSS 等于 TSS，R² 的最小值为 0。另一方面，最佳情况是 RSS = 0 和 R² = 1。

在非线性模型的情况下，R² 可能为负。由于这些模型的拟合过程不是基于迭代最小化 RSS，因此拟合模型的 RSS 可能大于 TSS。换句话说，模型的预测比简单均值模型更差。更多信息，请参见 [R squared 何时为负？](https://stats.stackexchange.com/questions/12900/when-is-r-squared-negative)

*附加说明*：使用 R²，我们可以评估我们的模型相比于简单均值模型在数据拟合上的提升。我们可以将正的 R² 值理解为提升基线模型性能的能力——类似于技能评分。例如，40% 的 R² 表示我们的模型将均方误差减少了 40%，相对于基线均值模型。

## 均方误差

*均方误差* (MSE) 是最常见的评价指标之一。如以下公式所示，MSE 与残差平方和密切相关。不同之处在于，我们现在关注的是平均误差，而不是总误差。

![](../Images/b217c2e88140bbd58b0c959ca54381d9.png)

在使用 MSE 时需要考虑以下几点：

+   MSE 使用均值（而不是总和）来使指标独立于数据集大小。

+   由于残差被平方，MSE 对大误差施加了显著更重的惩罚。其中一些可能是离群值，因此 MSE 对其存在不鲁棒。

+   由于度量指标是通过平方、求和和常数（1/N）表示的，它是可导的。这对优化算法非常有用。

+   在优化 MSE（将其导数设为 0）时，模型的目标是使预测的总和等于实际值的总和。也就是说，这会导致预测在平均上是正确的。因此，它们是无偏的。

+   MSE 不以原始单位进行测量，这可能使其更难解释。

+   MSE 是一个依赖于尺度的度量指标，即误差以基础数据的单位表示（尽管实际上需要平方根才能以相同尺度表示）。因此，这些度量指标不能用于比较不同数据集之间的性能。

## 均方根误差

*均方根误差*（RMSE）与 MSE 紧密相关，因为它只是后者的平方根。通过平方我们将度量指标恢复到目标变量的尺度，因此更容易解释和理解。然而，一个经常被忽视的事实是，虽然 RMSE 与目标在同一尺度上，但 RMSE 为 10 实际上并不意味着我们的平均偏差为 10 个单位。

![](../Images/75d46b7d334fbaf5d13c5cde45b72546.png)

除了尺度之外，RMSE 具有与 MSE 相同的属性。实际上，在训练模型时优化 RMSE 会得到与优化 MSE 时相同的模型。

## 平均绝对误差

计算*平均绝对误差*（MAE）的公式类似于 MSE 公式。我们只需将平方替换为绝对值即可。

![](../Images/75977f451d32d69c2454441c5fac56c8.png)

MAE 的特点包括：

+   由于没有平方，该度量指标以与目标变量相同的尺度表示，从而更易于解释。

+   所有误差都被平等对待，因此该度量对离群值具有鲁棒性。

+   绝对值忽略了误差的方向，因此低估 = 高估。

+   类似于 MSE 和 RMSE，MAE 也依赖于尺度，因此我们不能在不同的数据集之间进行比较。

+   当你优化 MAE 时，预测值必须比实际值高出多少倍，就必须低多少倍。这意味着我们实际上是在寻找中位数，即将数据集分成两个相等部分的值。

+   由于公式包含绝对值，MAE 不容易求导。

## 平均绝对百分比误差

*平均绝对百分比误差*（MAPE）是商业领域最受欢迎的指标之一。这是因为它以百分比表示，使其更易于理解和解释。

![](../Images/6695b92fcc981929de25eb03c7d683fb.png)

为了使度量指标更易读，我们可以将其乘以 100% 以将数字表示为百分比。

需要考虑的事项：

+   MAPE 表达为百分比，这使得它成为一个尺度独立的指标。它可以用来比较不同尺度上的预测。

+   MAPE 可以超过 100%。

+   当实际值为零时，MAPE 是未定义的（除以零）。此外，当实际值非常接近零时，它可以取到极端值。

+   MAPE 是不对称的，对负误差（即预测值高于实际值）施加的惩罚比对正误差更重。这是因为百分比误差对过低的预测不能超过 100%。而对过高的预测则没有上限。因此，优化 MAPE 会倾向于选择那些低估预测值的模型，而不是高估预测值的模型。

+   Hyndman（2021）详细阐述了 MAPE 的一个常被忽视的假设，即变量的测量单位有一个有意义的零值。因此，预测需求并使用 MAPE 不会引发警报。然而，当预测温度（特别是摄氏温度）时，我们会遇到这个问题。因为温度有一个任意的零点，在这种情况下谈论百分比是不合适的。

+   MAPE 并非在所有情况下都可微分，这可能导致在使用它作为优化标准时出现问题。

+   由于 MAPE 是一个相对指标，相同的误差可能会导致不同的损失，具体取决于实际值。例如，对于预测值为 60 和实际值为 100，MAPE 将是 40%。而对于预测值为 60 和实际值为 20，名义误差仍为 40，但在相对尺度上则是 300%。

+   不幸的是，MAPE 无法很好地区分重要与不重要的内容。假设我们正在进行需求预测，在几个月的时间范围内，我们对两个不同产品的 MAPE 都为 10%。结果发现第一个产品每月平均销售 100 万个单位，而另一个产品仅销售 100 个。这两者的 MAPE 都为 10%。当对所有产品进行汇总时，这两个产品的贡献是相同的，这可能远非理想。在这种情况下，考虑加权 MAPE（wMAPE）是有意义的。

## 对称平均绝对百分比误差

在讨论 MAPE 时，我提到它的一个潜在缺陷是其不对称性（未限制高于实际值的预测）。*对称平均绝对百分比误差*（sMAPE）是一个相关指标，旨在解决这个问题。

![](../Images/2515d0171cb1876af60e131a9fb6b0a6.png)

使用 sMAPE 时需考虑的要点：

+   它表示为一个有界百分比，即具有较低（0%）和较高（200%）的界限。

+   当实际值和预测值都非常接近零时，该指标仍然不稳定。这时，我们会面临除以一个非常接近零的数字的问题。

+   0% 到 200% 的范围并不直观。分母中的除以二常常被省略。

+   无论实际值还是预测值为 0，sMAPE 都会自动达到上限值。

+   sMAPE 包含与 MAPE 相同的假设，即有意义的零值。

+   在修正无界的不对称性时，sMAPE 引入了另一种微妙的不对称性，这是由公式的分母造成的。设想两种情况。在第一种情况下，我们有 A = 100 和 F = 120。sMAPE 为 18.2%。现在类似的情况，我们有 A = 100 和 F = 80，sMAPE 为 22.2%。因此，sMAPE 倾向于对低估进行比高估更严厉的惩罚。

+   sMAPE 可能是最具争议的误差指标之一，尤其是在时间序列预测中。这是因为文献中至少有几种不同版本的这个指标，每一种都有细微的差异，这些差异会影响其属性。最后，这个指标的名称暗示了没有不对称性，但实际上并非如此。

# 其他回归评估指标

我没有描述所有可能的回归评估指标，因为有几十种（如果不是上百种）。这里有一些其他的指标可以在评估模型时考虑：

+   *均方对数误差*（MSLE）是 MSE 的一个相关指标，区别在于我们在计算平方误差之前对实际值和预测值取对数。对两个元素进行对数变换的结果是测量实际值与预测值之间的比例或相对差异，同时忽略数据的规模。这就是为什么 MSLE 减少了异常值对最终得分的影响。MSLE 还对低估进行了更严厉的惩罚。

+   *均方根对数误差*（RMSLE）是一个对 MSLE 取平方根的指标。它具有与 MSLE 相同的属性。

+   *赤池信息量准则*（AIC）和 *贝叶斯信息量准则*（BIC）是信息准则的例子。它们用于在良好的拟合度和模型复杂性之间找到平衡。如果我们从一个简单的模型开始，拥有少量参数，然后逐步增加参数，我们的模型可能会更好地拟合训练数据。然而，这也会增加模型的复杂性，并有过拟合的风险。另一方面，如果我们从许多参数开始，并系统地删除一些参数，模型会变得更简单。与此同时，我们减少了过拟合的风险，但可能会牺牲性能（拟合优度）。AIC 和 BIC 的区别在于对复杂性的惩罚权重。请记住，将信息准则用于不同的数据集或同一数据集的不同子样本（但观察数量不同）是不有效的。

# 何时使用每种评估指标

与大多数数据科学问题一样，没有单一的最佳指标来评估回归模型的性能。为特定用例选择的指标将取决于用于训练模型的数据、我们试图解决的业务案例等等。因此，我们可能会在模型训练中使用单一的优化指标，但在向利益相关者报告时，数据科学家通常会呈现多个指标的选择。

在选择指标时，请考虑以下几个问题：

+   你是否预期数据集中会有频繁的异常值？如果是这样，你希望如何考虑这些异常值？

+   在业务中，对于过度预测还是不足预测更有偏好？

+   你需要一个依赖于尺度的指标还是一个独立于尺度的指标？

我认为探索一些示例数据以全面理解这些指标的细微差别是有用的。虽然大多数指标都可以在`scikit-learn`的`metrics`模块中找到，但对于这个特定的任务，传统的电子表格可能是更合适的工具。

以下示例包含五个观察值。表1展示了实际值、预测值以及用于计算大多数考虑的指标的一些指标。

![](../Images/28e8794d3ab108b4fe3f61d7ebde8c36.png)

*表1\. 对五个观察值计算性能指标的示例*

前三行包含了实际值与预测值之间的绝对差为20的情景。前两行显示了实际值相同的情况下的过度预测和不足预测。第三行显示了实际值较小的情况下的过度预测。在这些行中，很容易观察到MAPE和sMAPE的特性。

![](../Images/d34d552c080b4dc1d936c99bfe079a2c.png)

*表2\. 使用表1中的值计算的性能指标*

表1中的第五行包含了一个比实际值小8倍的预测。为了实验的目的，将该预测值替换为比实际值高8倍的预测。表3包含了修订后的观察数据。

![](../Images/da10e3c33b6639ce067b85532a2cc7bd.png)

*表3\. 修改单个观察值为更极端情况后的性能指标*

![](../Images/2cdc6584f9ba1f6961e7bb65ddbd8c33.png)

*表4\. 使用表3中的修改值计算的性能指标*

基本上，所有指标的大小都爆炸性增长，这在直观上是合理的。sMAPE则保持不变。

我强烈建议你尝试这些示例，以更全面地了解不同情境如何影响评估指标。这种实验应该让你在决定优化哪个指标及其选择后果时更加自信。这些练习还可能帮助你向利益相关者解释你的选择。

# 总结

在这篇文章中，我介绍了一些最受欢迎的回归评估指标。如文中所述，每种指标都有其优缺点。数据科学家需要理解这些优缺点，并决定哪一种（或多种）适用于特定的用例。提到的指标也可以应用于纯回归任务——例如根据与经验相关的特征预测薪资——也可以应用于时间序列预测领域。

一如既往，任何建设性的反馈都非常欢迎。你可以在[Twitter](https://twitter.com/erykml1)上或在评论区联系我。

*喜欢这篇文章？成为Medium会员，继续通过无缝阅读学习。如果你使用* [*这个链接*](https://eryk-lewinson.medium.com/membership) *成为会员，你将以零额外成本支持我。提前感谢，期待见到你！*

你也可能对以下内容感兴趣：

[](/dealing-with-outliers-using-three-robust-linear-regression-models-544cfbd00767?source=post_page-----6264af0926db--------------------------------) [## 使用三种稳健线性回归模型处理异常值

### 通过Huber、RANSAC和Theil-Sen回归算法的实际示例

towardsdatascience.com](/dealing-with-outliers-using-three-robust-linear-regression-models-544cfbd00767?source=post_page-----6264af0926db--------------------------------) [](/verifying-the-assumptions-of-linear-regression-in-python-and-r-f4cd2907d4c0?source=post_page-----6264af0926db--------------------------------) [## 验证线性回归假设：Python和R

### 深入探讨高斯-马尔可夫定理及其他线性回归假设！

towardsdatascience.com](/verifying-the-assumptions-of-linear-regression-in-python-and-r-f4cd2907d4c0?source=post_page-----6264af0926db--------------------------------) [](/interpreting-the-coefficients-of-linear-regression-cc31d4c6f235?source=post_page-----6264af0926db--------------------------------) [## 解释线性回归的系数

### 了解如何正确解释线性回归结果——包括变量变换的情况

towardsdatascience.com](/interpreting-the-coefficients-of-linear-regression-cc31d4c6f235?source=post_page-----6264af0926db--------------------------------) [](/choosing-the-correct-error-metric-mape-vs-smape-5328dec53fac?source=post_page-----6264af0926db--------------------------------) [## 选择正确的误差度量：MAPE与sMAPE

### 两种流行误差度量的利弊

towardsdatascience.com](/choosing-the-correct-error-metric-mape-vs-smape-5328dec53fac?source=post_page-----6264af0926db--------------------------------)

# 参考文献

Jadon, A., Patil, A., & Jadon, S. (2022). 回归基础损失函数在时间序列预测中的全面调查。*arXiv预印本 arXiv:2211.02989*。

Hyndman, R. J. (2006). 重新审视间歇需求的预测准确度度量。*Foresight: The International Journal of Applied Forecasting*, *4*(4), 43–46。

Hyndman, R. J., & Koehler, A. B. (2006). 重新审视预测准确度的度量。*International journal of forecasting*, *22*(4), 679–688。

Hyndman, R.J., & Athanasopoulos, G. (2021) *Forecasting: principles and practice*, 第3版, OTexts: Melbourne, Australia. OTexts.com/fpp3。

除非另有说明，所有图片均由作者提供。

*最初发布于* [*NVIDIA的开发者博客*](https://developer.nvidia.com/blog/a-comprehensive-overview-of-regression-evaluation-metrics/) *2023年4月20日*
