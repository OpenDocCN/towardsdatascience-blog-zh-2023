- en: Streamlining Repetitive Tasks During Exploratory Data Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/streamlining-repetitive-tasks-during-exploratory-data-analysis-46a40fe1d588](https://towardsdatascience.com/streamlining-repetitive-tasks-during-exploratory-data-analysis-46a40fe1d588)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Automation in Data Science
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An invitation to identify your repetitive EDA tasks and create an automated
    workflow, illustrated through an example utility.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@christabellecp?source=post_page-----46a40fe1d588--------------------------------)[![Christabelle
    Pabalan](../Images/24187865b6e9d03ae1aabf873ce1e67c.png)](https://medium.com/@christabellecp?source=post_page-----46a40fe1d588--------------------------------)[](https://towardsdatascience.com/?source=post_page-----46a40fe1d588--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----46a40fe1d588--------------------------------)
    [Christabelle Pabalan](https://medium.com/@christabellecp?source=post_page-----46a40fe1d588--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----46a40fe1d588--------------------------------)
    ·7 min read·Oct 24, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e5031188e988019bb8a2ffc2e978e858.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author (DALL-E Generated)
  prefs: []
  type: TYPE_NORMAL
- en: 'Programming Principle: Automate the Mundane'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: They often say lazy programmers make the best programmers. However, it’s more
    accurate to say that programmers who don’t have the patience for repetitive workflows
    will take the upfront investment of time to automate whatever they can so they
    can avoid such tasks. In short, the best programmers don’t patiently repeat mundane
    tasks — they automate them. Skilled programmers are “lazy” because they invest
    time upfront to create tools that will save them effort down the road. This may
    mean learning keyboard shortcuts, creating custom modules, or finding smart software
    to automate workflows.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a post titled, “*Why Good Programmers are Lazy and Dumb*,” Philipp Lenssen
    states:'
  prefs: []
  type: TYPE_NORMAL
- en: “Only a lazy programmer will avoid writing monotonous, repetitive code — thus
    avoiding redundancy, the enemy of software maintenance and flexible refactoring
    […] for a lazy programmer to be a good programmer, he (or she) also must be incredibly
    *unlazy* when it comes to learning how to *stay* lazy — that is, which software
    tools make his work easier, which approaches avoid redundancy, and how he can
    make his work be maintained and refactored easily.”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Nobody enjoys tedious and monotonous tasks and if anyone should find themselves
    repeating the same functions across projects, this overarching frustration should
    start to creep in to haunt them and whisper, “*package them into a module.”*
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f41e17bd46b6462380c7e6d015f0701d.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: '**The Repetitive Nature of EDA**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One area where these whispers have come up to haunt me is during the exploratory
    data analysis phase.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exploratory data analysis (EDA)** involves using statistical techniques and
    visualizations to study your data, understand its structure, identify patterns,
    and detect any irregularities or outliers. Often, identical analyses and visuals
    are needed for new datasets, therefore, EDA can benefit largely from automation.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Limits of Full Automation**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: However, I’d been deterred each time during my prior attempts because complete
    automation is hindered by the unique challenges of each dataset, such as determining
    encoding strategies and ensuring correct data types. The interplay between the
    data cleaning process and data analysis is a repetitive one, therefore, it can
    be difficult to standardize entirely.
  prefs: []
  type: TYPE_NORMAL
- en: '**A Modular Approach**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To address this limitation, I created a utility that assumes the data has already
    been minimally processed with the correct data types. It also necessitates defining
    the numerical columns, categorical columns, and the target column (it assumes
    we’re working with a classification task).
  prefs: []
  type: TYPE_NORMAL
- en: What does it contain?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: High-level statistics for both numerical and categorical data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Statistical tests of significance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A correlation heatmap
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Category averages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data distribution visualizations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The function also offers flexibility with optional parameters to enable or disable
    any of the functionalities above.
  prefs: []
  type: TYPE_NORMAL
- en: This article aims to demonstrate the value of creating customized EDA utilities.
    While the example focuses on automated summaries and visualizations, the key is
    to identify your pain points around repetitive EDA work and codify your own repetitive
    workflows. Rather than including the full code, I will focus on demonstrating
    the key capabilities and sample outputs of the utility.
  prefs: []
  type: TYPE_NORMAL
- en: The Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The dataset was uploaded to [Kaggle](https://www.kaggle.com/datasets/teamincribo/stroke-prediction)
    for the purpose of examining the factors that may be predictive of whether or
    not a patient will get diagnosed with having a stroke.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/903f5a05e2b1af50ad8c9254aa8f0788.png)'
  prefs: []
  type: TYPE_IMG
- en: Five Randomly Sampled Observations from the Dataset. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: '**Light Pre-processing and Feature Engineering**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'I began the process by:'
  prefs: []
  type: TYPE_NORMAL
- en: Extracting HDL and LDL cholesterol values from ‘Cholesterol Levels’
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating binary indicator columns for each symptom
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Converting both categorical columns and the target column into numerical codes
    through label encoding
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Sample of Lightly Pre-processed Data**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e5883ca955fbdb1bffd36896c342fe98.png)'
  prefs: []
  type: TYPE_IMG
- en: 5 Randomly Sampled Observations of the Dataset After Feature Engineering. Image
    by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'From here, there are two steps I need to take:'
  prefs: []
  type: TYPE_NORMAL
- en: Define the numerical, categorical, and target columns
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run `summary()` and input which functions I’d like to see
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary()
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Define Numerical, Categorical, and Target Columns
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In this article, I’ve included the larger utility `summary()` and excluded
    the helper functions: `calculate_entropy()` , `statistical_tests()` , `plot_distribution_plots()`
    , `plot_correlation_heatmap()` , `calculate_categorical_summary` , `calculate_numerical_summary()`
    .'
  prefs: []
  type: TYPE_NORMAL
- en: '**Summary() Implementation**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '**Categorical and Numerical Summaries**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The utility generates two statistical summaries — one for categorical variables
    and one for numerical variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **categorical summary** provides high-level insight into each category,
    including:'
  prefs: []
  type: TYPE_NORMAL
- en: Number of unique values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The most frequent value and its frequency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Percentage of missing values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Entropy — a measure of randomness in the distribution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The **numerical summary** calculates common descriptive stats like:'
  prefs: []
  type: TYPE_NORMAL
- en: Number of unique values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Percentage of missing values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of outliers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Central tendency measures (mean, median)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dispersion measures (standard deviation, min/max)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This breakdown serves as a rapid evaluation of the distribution and integrity
    of both categorical and numerical data. These summaries effectively pinpoint areas
    warranting deeper exploration, such as notable instances of missing data or significant
    outliers. Collectively, they offer a comprehensive snapshot of the dataset’s fundamental
    characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, below, it’s evident that there are four outliers in the blood
    pressure data, with half of the population having a history of stroke, and 75%
    of the patients exhibiting high blood pressure.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a69696285941fc426eadeca2147a192d.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Statistical Tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **statistical test summary** includes statistical test results to evaluate
    the relationship between each feature and the target variable. The utility runs
    a **chi-squared test for categorical variables** and a **two-tailed t-test for
    numerical variables** to assess the relationship between each feature and the
    target.
  prefs: []
  type: TYPE_NORMAL
- en: However, these tests have limitations. They detect linear correlations but can
    miss non-linear associations or complex interactions between variables. The results
    provide a starting point for identifying potentially predictive features, but
    further analysis is needed to uncover nuanced relationships. Therefore, the automatic
    tests accelerate initial feature screening but should be combined with deeper
    techniques like multivariate modeling and ensemble methods to derive further insights.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1abc5234ce86e89fc9ff55a3c5b07b2e.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Correlation Heatmap
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This visualization highlights the Spearman correlation between numerical variables,
    ordinal variables, and the target variable. This measure of correlation was chosen
    because it is more robust for capturing various types of relationships. Unlike
    Pearson’s correlation, Spearman’s is non-parametric, making it suitable for ordinal,
    categorical, or non-linear relationships.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/88523ee5d5350c3be2eef513faef1ebb.png)'
  prefs: []
  type: TYPE_IMG
- en: Spearman Correlation Heatmap. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Plots
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For distribution visualizations, `summary()` will return barplots for categorical
    variables and histograms and boxplots for numerical variables. The distribution
    visualizations can reveal where data should be separated and treated differently
    and may highlight quality assurance (QA) issues or anomalies.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0f0ef7cd80427831da5eaa8790fe3d74.png)'
  prefs: []
  type: TYPE_IMG
- en: Barplots for Categorical Data. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/22e8546b42e34f9d287de48917b511f6.png)'
  prefs: []
  type: TYPE_IMG
- en: Histograms, Boxplot, and Boxplot with No Outliers for Numerical Data. Image
    by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Concluding Remarks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This article demonstrated a sample EDA utility focused on the automated generation
    of statistical summaries, visualizations, and basic feature analysis. While not
    comprehensive, it allows rapid exploration of new datasets and surfaces insights
    to guide more targeted analysis. With some customization, these utilities can
    be adapted to suit the typical exploratory workflow for different domains or business
    contexts.
  prefs: []
  type: TYPE_NORMAL
- en: The key is identifying redundancies in your process and taking time upfront
    to codify your workflow. This compounds over time, allowing you to focus cognitive
    resources on higher-value areas like domain knowledge, feature engineering, and
    modeling. In short — create your utilities, automate the repetition, and let automation
    handle the grunt work so you can focus on the art.
  prefs: []
  type: TYPE_NORMAL
