# 如何赢得新加坡的GPT-4提示工程竞赛

> 原文：[https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41](https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41)

## 深入探讨我学习到的利用大型语言模型（LLMs）力量的策略

[](https://medium.com/@sheilateozy?source=post_page-----34c195a93d41--------------------------------)[![Sheila Teo](../Images/de3e697ba84d4896bdd869a9367049f4.png)](https://medium.com/@sheilateozy?source=post_page-----34c195a93d41--------------------------------)[](https://towardsdatascience.com/?source=post_page-----34c195a93d41--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----34c195a93d41--------------------------------) [Sheila Teo](https://medium.com/@sheilateozy?source=post_page-----34c195a93d41--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----34c195a93d41--------------------------------) ·阅读时长23分钟·2023年12月29日

--

![](../Images/e3d144bfda2cf4174c5722eadb21c101.png)

庆祝一个里程碑——真正的胜利是无价的学习体验！

上个月，我荣幸地赢得了新加坡首届GPT-4提示工程竞赛，该竞赛汇聚了超过400位极具才华的参与者，由新加坡政府技术局（GovTech）组织。

提示工程是一门结合了艺术和科学的学科——它既需要技术理解，也需要创造力和战略思维。这是我在过程中学习到的提示工程策略的汇编，这些策略能推动任何LLM做你需要的事，甚至更多！

> **作者注释：** 在撰写这篇文章时，我力求避免传统提示工程技术的过度讨论和文献记录。我的目标是通过实验带来新见解，并从个人角度理解和处理某些技术。希望你喜欢阅读这篇文章！

**本文涵盖了以下内容，** 🔵 **指代初学者友好的提示技术，而** 🔴 **指代高级策略：**

**1\. [**🔵**]** [**使用CO-STAR框架构建提示**](#10b2)

**2\. [**🔵**]** [**使用分隔符对提示进行分段**](#8f6a)

**3\. [**🔴**]** [**创建带有LLM保护措施的系统提示**](#1cfa)

**4\. [**🔴**]** [**仅使用LLMs分析数据集，无需插件或代码**](#183c) **—

通过实际例子分析真实的Kaggle数据集，使用GPT-4**

# 1\. [🔵] 使用CO-STAR框架构建提示

有效的提示结构对于从LLM获得最佳响应至关重要。CO-STAR框架，由新加坡GovTech的数据科学与人工智能团队提出，是一个便于结构化提示的实用模板。它考虑了所有影响LLM响应效果和相关性的关键方面，从而产生更优的响应。

![](../Images/bd99b52e9b4a0277b316f505d1d048ab.png)

CO-STAR框架 — 作者提供的图像

这就是它的工作原理：

## **(C) 上下文：提供任务的背景信息**

这帮助LLM理解正在讨论的具体场景，确保其响应相关。

## **(O) 目标：定义你希望LLM执行的任务**

明确你的目标有助于LLM将响应集中在满足那个特定目标上。

## **(S) 风格：指定你希望LLM使用的写作风格**

这可能是某个著名人士的写作风格，或是某个职业领域的专家，比如业务分析专家或首席执行官。这**g**指导LLM以与你的需求一致的方式和措辞作出回应。

## **(T) 语气：设定响应的态度**

这确保了LLM的响应能够与所需的情感或情绪背景相契合。示例包括正式、幽默、富有同情心等。

## **(A) 受众：确定响应的目标人群**

针对特定受众调整LLM的响应，例如领域专家、初学者、儿童等，可以确保其在所需的上下文中适当且易于理解。

## **(R) 响应：提供响应格式**

这确保了LLM的输出格式完全符合你对后续任务的要求。举例来说，包括列表、JSON、专业报告等。对于大多数在LLM响应上进行程序化操作以便后续处理的LLM应用来说，JSON输出格式是理想的。

## CO-STAR的实际应用

这是一个CO-STAR框架有用的真实世界示例。假设你是一名社交媒体经理，需要帮助撰写一个Facebook帖子来宣传公司新产品。

一个没有CO-STAR的简单提示可能看起来像这样：

> 撰写一个Facebook帖子来宣传我公司的新产品。我的公司名为Alpha，产品叫做Beta，是一种全新的超快速吹风机。

这是来自GPT-4的输出：

> 介绍Alpha的革命性Beta吹风机！
> 
> - 告别漫长乏味的吹干头发时光！Alpha自豪地推出Beta，我们最新的头发护理技术创新。
> 
> - 超快速干发：Beta设计用来将你的吹干时间缩短一半，得益于其先进而强大的马达。更快准备好，享受更多做你喜欢的事情的时间！
> 
> 立即购买：[产品页面链接]

尽管足够，但这个输出过于通用，缺乏与公司受众产生共鸣所需的具体细微差别和针对性吸引力。

这是一个使用CO-STAR模板的示例，它提醒您在提示中整合任务的其他方面，特别是前一个简洁提示中缺失的`STYLE`、`TONE`和`AUDIENCE`方面：

> # CONTEXT #
> # 
> 我想宣传我公司的新产品。我们公司的名字是Alpha，产品叫Beta，是一种全新的超快速吹风机。
> 
> # OBJECTIVE #
> # 
> 为我创建一个Facebook帖子，旨在促使人们点击产品链接购买。
> 
> # STYLE #
> # 
> 参考那些成功广告类似产品的公司，例如Dyson，来模仿写作风格。
> 
> # TONE #
> # 
> 说服力强的
> 
> # AUDIENCE #
> # 
> 我公司在Facebook上的受众群体通常是老年人。请根据这个受众的需求调整您的帖子，关注他们通常关注的护发产品特点。
> 
> # RESPONSE #
> # 
> 简洁且有影响力的Facebook帖子。

通过应用CO-STAR，GPT-4的响应变得更具针对性和有效性：

> 以Alpha Beta为您的选择——智者一代的超快速吹风机。
> 
> 重新发现简单有效的护发乐趣，尽在Alpha Beta。我们的最新创新不仅仅是一款吹风机；它承诺迅速、温和地护理您的头发。
> 
> 可靠的发型护理，适合那些欣赏生活精致事物的人。
> 
> - 易于使用且直观：告别复杂的设备。Alpha Beta是
> 
> 为舒适和简约而打造，完美适合那些重视简洁明了的人。
> 
> 无忧技术。
> 
> - 节省时间的技术：我们理解您的时间非常宝贵。这就是为什么Alpha Beta显著缩短了干发时间，让您有更多时间享受生活的乐趣。
> 
> 用Alpha Beta让每一天都成为美发好日子。体验
> 
> 今天就拥抱优雅与简约。
> 
> [您的产品链接]

CO-STAR框架引导您以结构化的方式提供有关任务的所有关键信息给LLM，确保对您的需求进行量身定制和优化的响应。

# 2\. [🔵] 使用分隔符分段提示

![](../Images/025cf4035267e5d16e3da44d19ab52e4.png)

由DALL·E 3生成的图像

分隔符是特殊标记，帮助LLM区分提示中应该作为一个单元处理的部分。这一点很重要，因为您的整个提示以一个长序列的标记到达LLM。分隔符通过将提示的特定部分围起来，提供结构，让这些部分被单独处理。

值得注意的是，分隔符对于简单任务的LLM响应质量可能没有影响。然而，任务越复杂，分隔符在分段上的使用对LLM响应的影响就越大。

## 分隔符作为特殊字符

分隔符可以是任何通常不会一起出现的特殊字符序列，例如：

+   ###

+   ===

+   >>>

特殊字符的数量和类型不重要，只要它们足够唯一，以便LLM将它们理解为内容分隔符，而不是普通标点符号。

下面是一个使用这种分隔符在提示中如何使用的示例：

> 将<<<CONVERSATIONS>>>中的每段对话的情感进行分类为
> 
> ‘正面’或‘负面’。给出情感分类结果，不加其他前言文本。
> 
> ###
> 
> 示例对话
> 
> [客服]: 早上好，今天我能怎么帮助您？
> 
> [客户]: 这个产品太糟糕了，和宣传的完全不一样！
> 
> [客户]: 我非常失望，并且要求全额退款。
> 
> [客服]: 早上好，我今天怎么帮您？
> 
> [客户]: 嗨，我只是想说我对你们的服务印象非常深刻。
> 
> 产品超出了我的预期！
> 
> ###
> 
> 示例输出
> 
> 负面
> 
> 正面
> 
> ###
> 
> <<<
> 
> [客服]: 你好！欢迎来到我们的支持中心。我今天怎么帮您？
> 
> [客户]: 嗨！我只是想告诉你，我收到了订单，
> 
> 太棒了！
> 
> [客服]: 很高兴听到这个消息！我们很高兴你对购买的商品感到满意。
> 
> 还有其他需要我帮助的吗？
> 
> [客户]: 不，就这样了。只是想给些正面反馈。谢谢
> 
> 感谢你们的出色服务！
> 
> [客服]: 你好，谢谢你联系我。我今天怎么帮您？
> 
> [客户]: 我对最近的购买非常失望。它根本不是我期待的。
> 
> [客服]: 听到这个消息我很遗憾。您能提供更多细节吗，这样我可以帮助您？
> 
> [客户]: 产品质量差，而且到货很晚。我对此次体验非常
> 
> 不满意。
> 
> >>>

上面，示例使用分隔符`###`分段，章节标题为`示例对话`和`示例输出`，以大写字母区分。前言说明了需要分类的对话被分段在`<<<CONVERSATIONS>>>`中，这些对话随后在提示底部给出，没有任何解释文本，但LLM理解这些是它应该分类的对话，因为分隔符`<<<`和`>>>`的存在。

这是GPT-4的输出，情感分类结果没有其他前言文本输出，如我们所要求的：

> 正面
> 
> 负面

## 作为XML标签的分隔符

另一种使用分隔符的方法是将它们作为XML标签。XML标签是用尖括号括起来的标签，包括开标签和闭标签。例如，`<tag>`和`</tag>`。这种方法有效，因为LLMs已经在大量的XML格式的网页内容上进行了训练，并学会了理解其格式。

以上是使用XML标签作为分隔符结构化的相同提示：

> 将以下对话的情感分类为‘正面’或‘负面’，按照给出的示例。给出情感分类结果，不加其他前言文本。
> 
> 前言文本。
> 
> <classes>
> 
> 正面
> 
> 负面
> 
> </classes>
> 
> <example-conversations>
> 
> [客服]: 早上好，今天我能怎么帮助您？
> 
> [客户]: 这个产品太糟糕了，完全不像宣传的那样！
> 
> [客户]: 我非常失望，期待全额退款。
> 
> [客服]: 早上好，今天我能帮你做什么？
> 
> [客户]: 你好，我只是想说我对你的产品真的很满意
> 
> 产品。它超出了我的期望！
> 
> </example-conversations>
> 
> <example-classes>
> 
> 消极
> 
> 积极
> 
> </example-classes>
> 
> <conversations>
> 
> [客服]: 你好！欢迎来到我们的支持中心。我今天能帮你做什么？
> 
> [客户]: 你好！我只是想告诉你我收到了我的订单，
> 
> 太棒了！
> 
> [客服]: 很高兴听到这个消息！我们很高兴你对购买的商品满意。
> 
> 还有其他我可以帮助你的吗？
> 
> [客户]: 不，这就是全部了。只是想给点积极的反馈。谢谢
> 
> 感谢你们的优质服务！
> 
> [客服]: 你好，谢谢你联系我们。我今天能为你提供什么帮助？
> 
> [客户]: 我对最近的购买感到非常失望。这不是我
> 
> 完全没有达到预期。
> 
> [客服]: 很抱歉听到这个消息。你能提供更多细节吗，我
> 
> 能帮忙吗？
> 
> [客户]: 产品质量差，而且到货迟了。我真的很
> 
> 对这次体验不满意。
> 
> </conversations>

使用相同名词来描述XML标签是有益的，如你在说明中所用的词汇。我们在上述提示中给出的说明是：

> 将以下对话的情感分类为两类之一，使用给出的示例。仅给出情感分类，不要附加其他
> 
> 引言文本。

我们使用了名词`conversations`、`classes`和`examples`。因此，我们作为分隔符使用的XML标签是`<conversations>`、`<classes>`、`<example-conversations>`和`<example-classes>`。这确保了LLM理解你的指示与用作分隔符的XML标签之间的关系。

再次，通过使用分隔符将指示分段，以清晰且结构化的方式确保GPT-4以你期望的方式做出回应：

> 积极
> 
> 消极

# 3\. [🔴] 使用LLM保护措施创建系统提示

> *在深入之前，需要注意的是，这一部分仅适用于具有系统提示功能的LLM，与本文其他部分适用于任何LLM不同。最显著的具备这一功能的LLM当然是ChatGPT，因此我们将以ChatGPT作为本部分的示例。*

![](../Images/5c8994667f14d073488eff303e0299a5.png)

由DALL·E 3生成的图像

## 系统提示的术语

首先，让我们理清术语：关于ChatGPT，存在大量资源几乎可以互换使用这三个术语：“系统提示”、“系统消息”和“自定义说明”。这让许多人（包括我！）感到困惑，以至于OpenAI发布了一篇[文章](https://help.openai.com/en/articles/8234522-chat-completions-api-system-message-vs-custom-instructions-in-ui)来解释这些术语。这里是一个简要总结：

+   “系统提示”与“系统消息”是用于与ChatGPT通过其聊天补全API进行程序化交互的术语。

+   另一方面，“自定义指令”是指在通过[https://chat.openai.com/](https://chat.openai.com/)的用户界面与ChatGPT进行交互时使用的术语。

![](../Images/3178e113fd74493ba540882728925eb1.png)

图片来自[企业DNA博客](https://blog.enterprisedna.co/chatgpt-custom-instructions/)

总的来说，这三个术语指的是同一件事，所以不要让术语困惑你！接下来，本节将使用“系统提示”一词。现在，让我们深入探讨！

## 什么是系统提示？

> 系统提示是一个额外的提示，其中提供了关于LLM应该如何行为的指令。它被认为是额外的，因为它在你对LLM的“正常”提示（更广为人知的是用户提示）之外。

在聊天中，每次你提供新的提示时，系统提示就像一个过滤器，LLM会在回应你的新提示之前自动应用它。这意味着系统提示在LLM在聊天中回应时会被考虑在内。

## 什么时候应该使用系统提示？

你可能会问的第一个问题是：为什么我应该在系统提示中提供指令，而不是在与LLM进行进一步对话之前，将其提供在新聊天的第一个提示中？

答案是因为LLM的对话记忆有其限制。在后续情况下，随着对话的进行，LLM可能会“忘记”你提供给聊天的第一个提示，使这些指令变得过时。

另一方面，当在系统提示中提供指令时，这些系统提示指令会与每个新的提示一起自动被考虑在内。这确保了即使对话持续进行，无论聊天多长，这些指令仍然会被LLM接收。

总结：

> 使用系统提示提供你希望LLM在整个聊天过程中记住的指令。

## 系统提示应该包括什么？

系统提示中的指令通常包括以下类别：

+   任务定义，使LLM始终记住在整个聊天过程中它需要做什么。

+   输出格式，使得LLM始终记住应该如何响应。

+   保护措施，使得LLM始终记住如何***不***响应。保护措施是LLM治理的新兴领域，指的是LLM被允许操作的配置边界。

例如，系统提示可能看起来像这样：

> 你将使用以下文本回答问题：[插入文本]。
> 
> 你将以这种格式回应：{“问题”: “答案”}。
> 
> 如果文本中没有足够的信息来回答问题，请不要编造信息，直接回答“NA”。
> 
> 你只允许回答与 [插入范围] 相关的问题。绝不要回答与年龄、性别和宗教等人口统计信息相关的问题。

每部分对应的类别如下：

![](../Images/ffe6e00bfff2c55a5394244852fb387f.png)

拆解系统提示 — 作者提供的图像

## 那么在“正常”的聊天提示中该包括什么呢？

现在你可能会想：这听起来像是系统提示中已经给出了很多信息。那么，我在“正常”提示（更常见的用户提示）中该放什么呢？

系统提示概述了当前任务的总体情况。在上述系统提示示例中，任务被定义为仅使用特定的文本进行问答，并且 LLM 被指示以格式 `{"Question": "Answer"}` 回复。

> 你将使用以下文本回答问题：[插入文本]。
> 
> 你将以 JSON 对象的格式回应，格式为：{“Question”: “Answer”}。

在这种情况下，每个用户提示将只是你希望使用文本回答的问题。例如，用户提示可能是 `"这段文本讲了什么？"`。然后，LLM 将回应 `{"这段文本讲了什么？": "这段文本讲的是..."}`。

但让我们进一步概括这个任务示例。在实际应用中，你更可能有多个文本片段需要提问，而不仅仅是一个。在这种情况下，我们可以将上述系统提示的第一行从

> 你将使用以下文本回答问题：[插入文本]。

到

> 你将使用提供的文本回答问题。

现在，每个用户提示将包括进行问答的文本和待回答的问题，例如：

> <text>
> 
> [插入文本]
> 
> </text>
> 
> <question>
> 
> [插入问题]
> 
> </question>

这里，我们还使用 XML 标签作为分隔符，以便以结构化的方式向 LLM 提供所需的两部分信息。XML 标签中使用的名词 `text` 和 `question` 与系统提示中使用的名词对应，以便 LLM 理解标签与系统提示指令的关系。

总结来说，系统提示应该给出整体任务的指示，而每个用户提示应该提供任务执行所需的具体细节。在这种情况下，例如，这些具体细节是文本和问题。

## 附录：使 LLM 防护措施动态化

上述内容通过系统提示中的几句话添加了防护措施。这些防护措施被固定下来，在整个聊天过程中不会改变。如果你希望在对话的不同阶段设置不同的防护措施，该怎么办？

对于 ChatGPT 用户界面的用户来说，目前没有简单的方法来做到这一点。然而，如果你以编程方式与 ChatGPT 交互，你是幸运的！对构建有效 LLM 保护措施的关注日益增加，已经开发出允许你以编程方式设置更详细和动态保护措施的开源包。

一个值得注意的是 [NeMo Guardrails](https://github.com/NVIDIA/NeMo-Guardrails)，由 NVIDIA 团队开发，它允许你配置用户和 LLM 之间的预期对话流程，从而在聊天的不同点设置不同的保护措施，使得随着聊天的进展，保护措施能够动态调整。我绝对推荐你去看看！

# 4. [🔴] 仅使用 LLMs 分析数据集，而不使用插件或代码

![](../Images/fd1fcab529f980a2706fdf3f7f653364.png)

图片由 DALL·E 3 生成

你可能听说过 OpenAI 在 ChatGPT GPT-4 中的高级数据分析插件，该插件对高级（付费）账户开放。它允许用户将数据集上传到 ChatGPT，并直接在数据集上运行代码，从而实现准确的数据分析。

但你知道吗，你并*不总是*需要这样的插件来使用 LLMs 进行良好的数据集分析？让我们首先了解**仅**使用 LLMs 分析数据集的优势和局限性。

## LLMs **不**擅长的数据集分析类型

正如你可能已经知道的那样，LLMs 在执行准确的数学计算方面存在限制，使得它们不适合进行需要精确定量分析的数据集任务，例如：

+   **描述性统计：** 定量总结数字列，通过均值或方差等指标。

+   **相关性分析：** 获取列之间的精确相关系数。

+   **统计分析：** 例如，通过假设检验来确定数据点组之间是否存在统计显著差异。

+   **机器学习：** 对数据集进行预测建模，例如使用线性回归、梯度提升树或神经网络。

对数据集执行这样的定量任务就是 OpenAI 高级数据分析插件存在的原因，这样编程语言可以介入，在数据集上运行代码来完成这些任务。

**那么，为什么有人会希望仅使用 LLMs 而不使用这样的插件来分析数据集呢？**

## LLMs 擅长的各种数据集分析类型

LLMs 在识别模式和趋势方面表现出色。这种能力源于它们在各种庞大数据上的广泛训练，使它们能够辨别那些可能不立即显现的复杂模式。

这使得它们非常适合基于数据集中的模式发现的任务，例如：

+   **异常检测：** 根据一个或多个列值识别偏离常规的异常数据点。

+   **聚类：** 将具有相似特征的数据点在列中分组。

+   **跨列关系：** 识别列之间的综合趋势。

+   **文本分析**（针对基于文本的列）：根据主题或情感进行分类。

+   **趋势分析**（针对有时间维度的数据集）：识别列中的模式、季节性变化或趋势。

对于这种基于模式的任务，单独使用LLMs可能比使用代码在更短的时间内产生更好的结果！让我们通过一个示例来充分说明这一点。

## 使用仅有LLMs分析Kaggle数据集

我们将使用一个流行的实际世界的[Kaggle数据集](https://www.kaggle.com/datasets/imakash3011/customer-personality-analysis)，这是一个针对客户个性分析的数据集，公司希望对客户群体进行细分，以更好地理解客户。

为了便于稍后的LLM分析验证，我们将数据集子集化为50行，并仅保留最相关的列。之后，分析的数据集如下，其中每一行代表一个客户，列显示客户信息：

![](../Images/10b1099060c23e9f80b3a101d54f3118.png)

数据集的前3行 — 作者提供的图像

假设你在公司的营销团队工作。你的任务是利用这个客户信息数据集来指导营销工作。这是一个两步的任务：首先，使用数据集生成有意义的客户群体。接下来，生成如何针对每个群体进行最佳营销的想法。现在这是一个实际的商业问题，其中LLMs在步骤1中的模式发现能力可以真正发挥作用。

让我们为这个任务制定如下提示，使用4种提示工程技术（[稍后更多内容！](#544b)）：

1\. 将复杂任务分解为简单步骤

2\. 参考每一步的中间输出

3\. 格式化LLM的回应

4\. 将指令与数据集分开

> ***系统提示：***
> 
> 我希望你充当数据科学家来分析数据集。不要编造数据集之外的信息。对于我要求的每个分析，提供确切和明确的答案，不要提供代码或指令以在其他平台上进行分析。
> 
> ***提示：*** # 背景 #
> 
> 我销售葡萄酒。我有一个包含客户信息的数据集：[出生年份、婚姻状况、收入、子女数量、距上次购买的天数、花费金额]。
> 
> #############
> 
> # 目标 #
> # 
> 我希望你使用数据集将我的客户分成不同的群体，然后给我一些关于如何针对每个群体进行营销的建议。请按照这个逐步过程操作，不要使用代码：
> 
> 1\. CLUSTERS：使用数据集的列将数据集的行进行聚类，使得同一簇中的客户具有相似的列值，而不同簇中的客户具有明显不同的列值。确保每一行仅属于1个簇。
> 
> 对于每个找到的簇，
> 
> 2\. CLUSTER_INFORMATION：根据数据集的列描述簇。
> 
> 3\. CLUSTER_NAME: 解释[CLUSTER_INFORMATION]以获得此集群中客户组的简短名称。
> 
> 4\. 营销想法: 为这个客户组生成营销产品的创意。
> 
> 5\. 理由: 解释为什么[MARKETING_IDEAS]对这个客户组是相关和有效的。
> 
> #############
> 
> # 风格 #
> # 
> 商业分析报告
> 
> #############
> 
> # 语气 #
> # 
> 专业，技术
> 
> #############
> 
> # 受众 #
> # 
> 我的商业伙伴。说服他们你的营销策略经过深思熟虑，并且完全有数据支持。
> 
> #############
> 
> # 响应: MARKDOWN报告 #
> # 
> <对于[CLUSTERS]中的每个集群>
> 
> — 客户组: [CLUSTER_NAME]
> 
> — 档案: [CLUSTER_INFORMATION]
> 
> — 营销想法: [MARKETING_IDEAS]
> 
> — 理由: [RATIONALE]
> 
> <附录>
> 
> 给出每个集群的行号列表的表格，以支持你的分析。使用这些表头: [[CLUSTER_NAME], 行号列表]。
> 
> #############
> 
> # 开始分析 #
> # 
> 如果你明白了，请告诉我你的数据集。

以下是GPT-4的回复，我们继续将数据集以CSV字符串形式传递给它。

![](../Images/41b331eb50c1c587106885a5a8a2e554.png)

GPT-4的回应 — 作者图像

随后，GPT-4以我们要求的markdown报告格式回复其分析：

![](../Images/9b662789708c2ba99967f8042f1f0bf4.png)

GPT-4的回应 — 作者图像

![](../Images/630b5b08acae3579883773f2217e864f.png)

GPT-4的回应 — 作者图像

![](../Images/eb8c2214d556638a8b914878221cfa8c.png)

GPT-4的回应 — 作者图像

## 验证LLM的分析

为了简洁起见，我们将选择LLM生成的2个客户组进行验证——例如，年轻家庭和有眼光的热衷者。

**年轻家庭**

- LLM综合的档案: 1980年后出生，已婚或同居，中等到低收入，有孩子，频繁的小额购买。

- LLM将这些行聚类到此组中: 3, 4, 7, 10, 16, 20

- 深入数据集，这些行的完整数据是：

![](../Images/96d9b6705cfa46c152dd0bc560aa8d44.png)

年轻家庭的完整数据 — 作者图像

这与LLM识别出的档案完全对应。它甚至能够在没有我们预处理的情况下，将包含空值的行进行聚类！

**有眼光的热衷者** - LLM综合的档案: 年龄跨度大，婚姻状态各异，高收入，子女情况多样，购买支出高。

- LLM将这些行聚类到此组中: 2, 5, 18, 29, 34, 36

- 深入数据集，这些行的完整数据是：

![](../Images/cb695fe43331bca45ce5a43ff9cce210.png)

有眼光的热衷者的完整数据 — 作者图像

这再次与LLM识别出的档案非常一致！

这个例子展示了LLM在模式发现、解释和提炼多维数据集为有意义见解的能力，同时确保其分析深深根植于数据集的事实真相中。

## 如果我们使用**ChatGPT的高级数据分析插件**会怎么样呢？

为了完整性，我尝试使用相同的提示进行相同的任务，但要求ChatGPT使用代码执行分析，从而激活其高级数据分析插件。 这个想法是让插件直接在数据集上运行像K-Means这样的聚类算法，以获得每个客户组，然后综合每个簇的概况，以提供营销策略。

然而，尽管数据集只有50行，但多次尝试仍导致以下错误消息且没有输出：

![](../Images/87f95711bb7c47e601cd621bcdae6ebc.png)

尝试1中的错误和无输出 — 作者提供的图片

![](../Images/1723f538ec254c5084688bc3ac641f5d.png)

尝试2中的错误和无输出 — 作者提供的图片

目前使用高级数据分析插件时，执行数据集上的简单任务，例如计算描述性统计数据或创建图表，可以很容易地实现，但更多需要计算算法的高级任务有时可能会由于计算限制或其他原因导致错误和无输出。

## 那么……何时使用LLMs来分析数据集？

答案是取决于分析的类型。

对于需要精确数学计算或复杂规则处理的任务，传统编程方法仍然更优。

对于基于模式识别的任务，使用传统编程和算法方法可能会具有挑战性或耗时。 然而，LLMs在这些任务中表现优异，甚至可以提供额外的输出，例如支持其分析的附件，以及以Markdown格式提供的完整分析报告。

> 从根本上说，是否使用LLMs取决于手头任务的性质，平衡LLMs在模式识别中的优势与传统编程技术提供的精确性和特异性。

## 现在回到提示工程！

在本节结束之前，让我们回到用于生成此数据集分析的提示，并分解所使用的关键提示工程技术：

> ***提示:***
> 
> # 背景 #
> # 
> 我卖酒。我有一个关于客户的信息数据集：[出生年份、婚姻状况、收入、子女数量、距离上次购买的天数、消费金额]。
> 
> #############
> 
> # 目标 #
> # 
> 我希望你使用数据集对我的客户进行分组，然后给我一些关于如何针对每个组进行营销的想法。请使用此逐步过程，并且不要使用代码：
> 
> 1\. CLUSTERS: 使用数据集的列对数据集的行进行聚类，以便在同一簇中的客户具有相似的列值，而在不同簇中的客户具有明显不同的列值。确保每行只属于一个簇。
> 
> 对于每个找到的簇，
> 
> 2\. CLUSTER_INFORMATION: 根据数据集列描述簇。
> 
> 3\. CLUSTER_NAME: 解释[CLUSTER_INFORMATION]以获得此簇中客户组的简短名称。
> 
> 4\. 营销创意：生成营销我的产品到该客户群体的想法。
> 
> 5\. 理由：解释为什么[MARKETING_IDEAS]对该客户群体是相关和有效的。
> 
> #############
> 
> # 风格 #
> # 
> 商业分析报告
> 
> #############
> 
> # 语气 #
> # 
> 专业，技术
> 
> #############
> 
> # 受众 #
> # 
> 我的商业伙伴。说服他们你的营销策略经过深思熟虑，并且完全有数据支持。
> 
> #############
> 
> # 响应：MARKDOWN报告 #
> # 
> <对于[CLUSTERS]中的每个集群>
> 
> — 客户群体：[CLUSTER_NAME]
> 
> — 个人资料：[CLUSTER_INFORMATION]
> 
> — 营销创意：[MARKETING_IDEAS]
> 
> — 理由：[RATIONALE]
> 
> <附录>
> 
> 提供每个集群所属行号的表格，以支持你的分析。使用以下表头：[[CLUSTER_NAME]，行号列表]。
> 
> #############
> 
> # 开始分析 #
> # 
> 如果你理解了，请告诉我你的数据集。

**技巧 1：将复杂任务拆分成简单步骤** LLM擅长执行简单任务，但对复杂任务不那么擅长。因此，对于像这样的复杂任务，将任务拆分成简单的逐步指令是很重要的。关键是给LLM你自己会采取的步骤来执行任务。

在这个例子中，步骤如下：

> 使用这个逐步过程，不要使用代码：
> 
> 1\. 集群：使用数据集的列对数据集的行进行聚类，使得同一集群内的客户具有相似的列值，而不同集群的客户具有明显不同的列值。确保每行仅属于一个集群。
> 
> 对于每个找到的集群，
> 
> 2\. 集群信息：根据数据集列描述集群。
> 
> 3\. 集群名称：解释[CLUSTER_INFORMATION]以获得该集群中客户群体的短名称。
> 
> 4\. 营销创意：生成营销我的产品到该客户群体的想法。
> 
> 5\. 理由：解释为什么[MARKETING_IDEAS]对该客户群体是相关和有效的。

与简单地将总体任务交给LLM不同，即“将客户分组，然后给出如何对每个组进行营销的想法”。

使用逐步指令，LLM更有可能提供正确的结果。

**技巧 2：引用每一步的中间输出** 在向LLM提供逐步过程时，我们将每一步的中间输出命名为大写的`VARIABLE_NAME`，即`CLUSTERS`、`CLUSTER_INFORMATION`、`CLUSTER_NAME`、`MARKETING_IDEAS`和`RATIONALE`。

使用大写字母来区分这些变量名和给出的指令内容。这些中间输出稍后可以使用方括号 `[VARIABLE_NAME]` 进行引用。

**技巧 3：格式化LLM的响应** 在这里，我们要求使用markdown报告格式，这可以美化LLM的响应。中间输出的变量名在这里再次派上用场，用以指定报告的结构。

> # 响应：MARKDOWN报告 #
> # 
> <对 [CLUSTERS] 中的每个集群>
> 
> — 客户组: [CLUSTER_NAME]
> 
> — 资料: [CLUSTER_INFORMATION]
> 
> — 营销点子: [MARKETING_IDEAS]
> 
> — 理由: [RATIONALE]
> 
> <附录>
> 
> 给出每个集群的行号列表的表格，以备份你的分析。使用以下表头: [[CLUSTER_NAME], 行列表]。

实际上，你甚至可以随后要求 ChatGPT 将报告提供为可下载的文件，从而使你能够在编写最终报告时以其回应为基础。

![](../Images/eee147c9f813e63af74d1c8fca52ca94.png)

保存 GPT-4 的回应为文件 — 作者提供的图片

**技术 4: 将任务指令与数据集分开**

你会注意到我们在第一次提示中从未将数据集提供给 LLM。相反，提示只提供了数据集分析的任务指令，底部添加了这些内容：

> # 开始分析 #
> # 
> 如果你理解了，请向我索取我的数据集。

ChatGPT 随后回应说它理解了，我们将数据集以 CSV 字符串的形式传递给它：

![](../Images/41b331eb50c1c587106885a5a8a2e554.png)

GPT-4 的回应 — 作者提供的图片

**但为什么要将指令与数据集分开？**

这样做有助于 LLM 保持对每项内容的清晰理解，降低遗漏信息的可能性，尤其是在像这样具有较长指令的复杂任务中。你可能经历过 LLM 在较长提示中“偶然忘记”某些指令的情况 — 例如，你要求 100 字的回应，而 LLM 回答了更长的段落。通过首先接收指令，然后再接收数据集，LLM 可以先消化它应做的事情，然后再在接收到的数据集上执行。

然而，请注意，这种指令与数据集的分离仅能通过聊天 LLM 实现，因为它们保持对话记忆，而完成功能的 LLM 则没有。

# 结束语

在本文结束之前，我想分享一些关于这段不可思议旅程的个人反思。

首先，衷心感谢新加坡 GovTech 组织了这样一个令人惊叹的竞赛。如果你对 GovTech 如何组织这次首创竞赛的机制感兴趣 — 请查看由首席组织者 Nicole Lee 撰写的 [这篇文章](https://go.gov.sg/how-govtech-designed-promptroyale2023)！

![](../Images/6ef5e352181db119e7eb5653313852da.png)

决赛中的现场对决！

其次，向我的其他了不起的竞争者们致以大声的感谢，他们每个人都带来了特别的东西，使得竞赛既丰富又具有挑战性！我永远不会忘记决赛的场景，我们在舞台上奋力拼搏，现场观众为我们加油 — 这是我将永远珍视的经历。

对我来说，这不仅仅是一场竞赛；这是对才华、创造力和学习精神的庆祝。我对接下来会发生的事情感到无比兴奋！

我在写这个的时候非常开心，如果你读得也开心，我会非常感激你花一点时间点赞并关注一下！

下次见！

Sheila
