- en: Four Common Mistakes When A/B Testing and How to Solve Them
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/four-common-mistakes-when-a-b-testing-and-how-to-solve-them-384072b57d75](https://towardsdatascience.com/four-common-mistakes-when-a-b-testing-and-how-to-solve-them-384072b57d75)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Enhance Your A/B Testing Skills: Addressing Four Key Errors for Better Results'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://terenceshin.medium.com/?source=post_page-----384072b57d75--------------------------------)[![Terence
    Shin, MSc, MBA](../Images/cab8b414fe319b6b65ad71a24bbc1dfc.png)](https://terenceshin.medium.com/?source=post_page-----384072b57d75--------------------------------)[](https://towardsdatascience.com/?source=post_page-----384072b57d75--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----384072b57d75--------------------------------)
    [Terence Shin, MSc, MBA](https://terenceshin.medium.com/?source=post_page-----384072b57d75--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----384072b57d75--------------------------------)
    ·7 min read·Jun 29, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/909720c0f939dfbc701dde079094506a.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Oscar Ivan Esquivel Arteaga](https://unsplash.com/@oscaresquivel?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/iT15xdxmLxw?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: A/B testing is like Jenga, a delicate balance of interconnected pieces that
    form the foundation of a successful experiment. Just like in the game of Jenga,
    where removing the wrong block can cause the entire tower to crumble, A/B testing
    relies on multiple components working together. Each piece represents a crucial
    element of the test, and if any of them fail, the integrity of the experiment
    can be compromised, leading to inaccurate results or missed opportunities.
  prefs: []
  type: TYPE_NORMAL
- en: And in my experiences, I’ve seen such great experiment ideas crumble because
    of very common mistakes that many data scientists commit, myself included! And
    so, I want to cover with you four of the most common mistakes when A/B testing
    (and how to solve them!).
  prefs: []
  type: TYPE_NORMAL
- en: '*If you’re not familiar with A/B testing and you’re interested in pursuing
    a career in data science, I strongly recommend you at least familiarize yourself
    with the concept.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*You can check out my below if you’d like a primer on A/B testing:*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/a-simple-guide-to-a-b-testing-for-data-science-73d08bdd0076?source=post_page-----384072b57d75--------------------------------)
    [## A Simple Guide to A/B Testing for Data Science'
  prefs: []
  type: TYPE_NORMAL
- en: One of the most important statistical methods for data scientists
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/a-simple-guide-to-a-b-testing-for-data-science-73d08bdd0076?source=post_page-----384072b57d75--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: With that said, let’s dive into it!
  prefs: []
  type: TYPE_NORMAL
- en: 'Problem #1: Setting the statistical power too low.'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To recap, statistical power represents the probability of correctly detecting
    a true effect, or more accurately speaking, it is the *conditional* probability
    of rejecting the null hypothesis given that it is false. Statistical power is
    inversely related to the probability of committing a Type 2 error (false negative).
  prefs: []
  type: TYPE_NORMAL
- en: Generally, it’s common practice to set the power at 80% when conducting a study.
    Given its definition, this means that if you set the power at 80%, you would fail
    to reject the null hypothesis given that it is false 20% of the time. In simpler
    terms, if there were true effects in 100 conducted experiments, you would only
    detect 80 out of the 100.
  prefs: []
  type: TYPE_NORMAL
- en: '**Why is this a problem?**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In a business, especially a tech company, one of the main goals is to learn,
    build, and iterate as quickly as possible. One of the reasons that large tech
    companies, like Airbnb and Uber, are able to grow so fast and maintain their market
    share is because of their ability to constantly evolve.
  prefs: []
  type: TYPE_NORMAL
- en: When you set the statistical power to 80%, that equates to 20% of true effects
    that were not captured, which means 20% fewer iterations. Now compound that over,
    say 10 years, and you can understand the impact that this may have.
  prefs: []
  type: TYPE_NORMAL
- en: What’s the solution?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The obvious answer to this is to increase the statistical power. How you go
    about doing so is not so obvious — **statistical power is directly related to
    several other experimental parameters**, meaning there are several ways to increase
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Increase the sample size.** The main way to improve statistical power is
    to increase the sample size. By increasing the sample size, the variability in
    the data decreases which results in narrower confidence intervals and more accurate
    estimation. This is why if you use a power analysis tool like Evan Miller’s A/B
    test calculator, setting a higher power results in a bigger recommended sample
    size.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adjust the alpha**. Power and alpha are inversely related, and this makes
    clear sense if you think about it. If you lowered the alpha from 0.05 to 0.01,
    the threshold for rejecting the null hypothesis becomes more stringent, which
    makes it harder to reject, which results in lower statistical power. The same
    could be said for the opposite — if your alpha is too low, by increasing the alpha,
    you’re more likely to reject the null and have higher statistical power.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decrease the effect size (minimum detectable effect)**. By decreasing the
    effect size, the statistical power of a test is enhanced because it results in
    an increased ability to detect smaller effects. That being said, it’s not always
    advisable to decrease the effect size, which leads me to my next point!'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Problem #2: Setting the minimum detectable effect (MDE) too low.'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The minimum detectable effect (MDE) represents the smallest effect size that
    an experiment can detect reliably. If the observed effect size falls below the
    MDE, it suggests that the effect is so small that it could be due to random variation
    or noise in the data rather than a genuine, meaningful effect.
  prefs: []
  type: TYPE_NORMAL
- en: If that’s the case then why *wouldn’t* you want to set the MDE as low as possible?
    This is where the idea of **statistical significance vs practical significance**
    comes into play — while **statistical significance** focuses on the probability
    that an effect is not due to random chance, **practical significance** takes into
    account the magnitude and implications of the effect in practical terms.
  prefs: []
  type: TYPE_NORMAL
- en: To give an example, I conducted a pricing experiment at KOHO to determine price
    elasticity for a given product. The end result was *statistically significant*
    in that the reduction in price resulted in an increase in product adoption. However,
    reducing the price as much as we did was not *practically significant* because
    despite the increased number of users that subscribed, the price reduction ultimately
    led to a lower profit overall.
  prefs: []
  type: TYPE_NORMAL
- en: What’s the solution?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You should choose an MDE based on practical effect sizes that are relevant to
    the context and align with the objectives of the experiment. This ensures that
    the detected effects are both statistically significant and practically meaningful,
    while also optimizing resource allocation and avoiding the risk of false negatives.
  prefs: []
  type: TYPE_NORMAL
- en: 'Problem #3: Conducting too many hypothesis tests.'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Too often have I seen dozens and dozens of A/B tests (hypothesis tests) conducted
    on virtually the same thing, like testing several price points for a given product,
    testing various website configurations, and testing multiple marketing campaigns.
  prefs: []
  type: TYPE_NORMAL
- en: '**Why is this a problem?**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The problem with this is that as you conduct more hypothesis tests, you’re more
    likely to obtain statistically significant results by chance. Statistically speaking,
    this is because of the alpha that is set when A/B testing. The alpha represents
    the probability of rejecting the null hypothesis when it is true, so if we set
    it to 0.05 then 5 out of 100 true tested hypotheses will be rejected.
  prefs: []
  type: TYPE_NORMAL
- en: What’s the solution?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The solution to this is to control for false discoveries (false positives),
    and there are several methods to achieve this. The most common technique is the
    **Bonferroni Correction**, which simply adjusts the significance level (alpha)
    by dividing it by the number of tests being performed. For example, if you are
    conducting 10 hypothesis tests and want to maintain an overall alpha of 0.05,
    you would divide 0.05 by 10, resulting in an adjusted alpha of 0.005 for each
    test. This correction ensures a more stringent criterion for declaring statistical
    significance, reducing the chances of false positives.
  prefs: []
  type: TYPE_NORMAL
- en: 'Problem #4: Not accounting for Survivorship Bias.'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another problem I see is that survivorship bias is not often adjusted for in
    the experimental design.
  prefs: []
  type: TYPE_NORMAL
- en: '**Why is this a problem?**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Survivorship bias** and **user tenure** have a strong relationship. Consider
    this: unengaged or unprofitable users are unlikely to have a long tenure with
    a company — users that don’t find value in a product are unlikely to stay as long
    with a company. Therefore, it’s important to account for the potential differences
    in behavior between users of different tenures.'
  prefs: []
  type: TYPE_NORMAL
- en: When splitting your control and test groups, failing to account for user tenure
    can skew your results *if* there are significant differences in behavior. One
    group may have a higher average user tenure, which can impact factors like profitability
    and engagement. In other words, not accounting for user tenure can introduce confounding
    variables and hinder the analysis of the specific cause-and-effect relationship
    of interest.
  prefs: []
  type: TYPE_NORMAL
- en: What’s the solution?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Stratified sampling** can be used to address the issue of user tenure skewing
    A/B test results when not controlled for. This involves stratifying (or partitioning)
    the population into specific segments and then randomly sampling each group individually.
    It can be done by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define User Tenure Groups: Divide your user population into distinct groups
    based on their tenure with the company. For example, you could create groups such
    as “New Users” (short tenure), “Mid-Term Users” (moderate tenure), and “Long-Term
    Users” (extended tenure).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Determine Sample Sizes: Determine the sample size you want for each tenure
    group. The sample sizes can be proportional to the size of each group in the overall
    user population or based on specific considerations, such as the importance of
    each group or desired statistical power.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Random Sampling within Each Group: Randomly select users from each tenure group
    to form the control group and the test group for your A/B test. Ensure that the
    selection is representative of the users in each group, preserving the proportions
    of users with different tenure levels.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Conduct your A/B Test: By stratify sampling, you’ll reduce bias in your experiment
    and set yourself up for more reliable results. You can now properly conduct your
    experiment in a manner that will control for variables other than the variable
    of interest.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After reading this, you should know four common A/B testing errors and how
    to solve them — specifically, you should know how to account for:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting the statistical power too low
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Setting the minimum detectable effect (MDE) too low
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Conducting too many hypothesis tests
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Not accounting for Survivorship Bias
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Considering these errors will certainly improve the validity and reliability
    of your A/B tests, enabling meaningful insights and informed decision-making.
  prefs: []
  type: TYPE_NORMAL
- en: Now go out there and see what you can discover!
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for Reading!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*If you enjoyed this article,* [***subscribe and become a member today***](https://terenceshin.medium.com/membership)*to
    never miss another article on data science guides, tricks and tips, life lessons,
    and more!*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://terenceshin.medium.com/membership?source=post_page-----384072b57d75--------------------------------)
    [## Join Medium with my referral link - Terence Shin'
  prefs: []
  type: TYPE_NORMAL
- en: 'Unlock Exclusive Insights and Stay Ahead: Subscribe to Experience a World of
    Knowledge. Discover a Treasure Trove of…'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: terenceshin.medium.com](https://terenceshin.medium.com/membership?source=post_page-----384072b57d75--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '**Not sure what to read next? I’ve picked another article for you:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://terenceshin.medium.com/all-machine-learning-algorithms-you-should-know-for-2023-843dba11419c?source=post_page-----384072b57d75--------------------------------)
    [## All Machine Learning Algorithms You Should Know for 2023'
  prefs: []
  type: TYPE_NORMAL
- en: Intuitive explanations of the most popular machine learning models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: terenceshin.medium.com](https://terenceshin.medium.com/all-machine-learning-algorithms-you-should-know-for-2023-843dba11419c?source=post_page-----384072b57d75--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '**or you can check out my Medium page:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://terenceshin.medium.com/?source=post_page-----384072b57d75--------------------------------)
    [## Terence Shin - Medium'
  prefs: []
  type: TYPE_NORMAL
- en: Read writing from Terence Shin on Medium. Data Science @ KOHO, Saturn Cloud
    | MSc, MBA |…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: terenceshin.medium.com](https://terenceshin.medium.com/?source=post_page-----384072b57d75--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Terence Shin
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[*Subscribe and become a member*](https://terenceshin.medium.com/membership)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Follow me on Medium*](https://medium.com/@terenceshin)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Follow me on LinkedIn*](https://www.linkedin.com/in/terenceshin/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
