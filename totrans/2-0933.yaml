- en: From Causal Trees to Forests
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从因果树到森林
- en: 原文：[https://towardsdatascience.com/from-causal-trees-to-forests-43c4536f1481](https://towardsdatascience.com/from-causal-trees-to-forests-43c4536f1481)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/from-causal-trees-to-forests-43c4536f1481](https://towardsdatascience.com/from-causal-trees-to-forests-43c4536f1481)
- en: '[CAUSAL DATA SCIENCE](https://towardsdatascience.com/tagged/causal-data-science)'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[因果数据科学](https://towardsdatascience.com/tagged/causal-data-science)'
- en: '*How to use random forests to do policy targeting*'
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*如何使用随机森林进行政策定位*'
- en: '[](https://medium.com/@matteo.courthoud?source=post_page-----43c4536f1481--------------------------------)[![Matteo
    Courthoud](../Images/d873eab35a0cf9fc696658c0bee16b33.png)](https://medium.com/@matteo.courthoud?source=post_page-----43c4536f1481--------------------------------)[](https://towardsdatascience.com/?source=post_page-----43c4536f1481--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----43c4536f1481--------------------------------)
    [Matteo Courthoud](https://medium.com/@matteo.courthoud?source=post_page-----43c4536f1481--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@matteo.courthoud?source=post_page-----43c4536f1481--------------------------------)[![Matteo
    Courthoud](../Images/d873eab35a0cf9fc696658c0bee16b33.png)](https://medium.com/@matteo.courthoud?source=post_page-----43c4536f1481--------------------------------)[](https://towardsdatascience.com/?source=post_page-----43c4536f1481--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----43c4536f1481--------------------------------)
    [Matteo Courthoud](https://medium.com/@matteo.courthoud?source=post_page-----43c4536f1481--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----43c4536f1481--------------------------------)
    ·13 min read·Feb 20, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----43c4536f1481--------------------------------)
    ·13分钟阅读·2023年2月20日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/2977138a8f4b861a47fb69dc54222ec5.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2977138a8f4b861a47fb69dc54222ec5.png)'
- en: Cover, image by Author
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 封面，图片由作者提供
- en: In my [previous blog post](https://medium.com/towards-data-science/understanding-causal-trees-920177462149),
    we have seen how to use **causal trees** to estimate the heterogeneous treatment
    effects of a policy. If you haven’t read it, I recommend reading that first since
    we will take that article's content for granted and start from there.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在我[之前的博客文章](https://medium.com/towards-data-science/understanding-causal-trees-920177462149)中，我们已经探讨了如何使用**因果树**来估计政策的异质性处理效应。如果你还没有阅读，我建议先阅读那篇文章，因为我们将以那篇文章的内容为基础，从那里开始。
- en: 'Why heterogenous treatment effects (HTE)? First of all, the estimation of heterogeneous
    treatment effects allows us to select which users (patients, users, customers,
    … ) to offer treatment (a drug, ad, product, …), depending on their expected outcome
    of interest (a disease, firm revenue, customer satisfaction, …). In other words,
    estimating HTE allows us to do **targeting**. In fact, as we will see later in
    the article, a treatment can be ineffective or even counterproductive on average
    while bringing positive benefits to a subset of the users. The opposite can also
    be true: a drug can be effective on average, but its effectiveness can be improved
    if we identify users on whom it has side effects.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么要关注异质性处理效应（HTE）？首先，异质性处理效应的估计使我们能够选择哪些用户（患者、用户、客户等）接受治疗（药物、广告、产品等），这取决于他们预期的结果（疾病、公司收入、客户满意度等）。换句话说，估计HTE使我们能够进行**定位**。实际上，正如我们在文章后面将看到的，一个治疗在平均情况下可能无效或甚至适得其反，但对某一子集的用户却带来积极的效果。相反的情况也可能成立：一种药物在平均情况下有效，但如果我们识别出有副作用的用户，其效果可能会得到改善。
- en: 'In this article, we will explore an extension of causal trees: causal forests.
    Exactly as random forests extend regression trees by averaging multiple bootstrapped
    trees together, causal forests extend causal trees. The main difference comes
    from the inference perspective, which is less straightforward. We are also going
    to see how to compare the outputs of different HTE estimation algorithms and how
    to use them for **policy targeting**.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将深入探讨因果树的扩展：因果森林。正如随机森林通过平均多个自助抽样的树来扩展回归树一样，因果森林扩展了因果树。主要的不同之处在于推断的角度，这并不那么直接。我们还将了解如何比较不同的HTE估计算法的输出，并如何将它们用于**政策定位**。
- en: Online Discounts
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在线折扣
- en: 'For the rest of the article, we resume the toy example used in the [causal
    trees article](https://medium.com/towards-data-science/understanding-causal-trees-920177462149):
    we assume we are an **online store,** and we are interested in understanding whether
    offering discounts to new customers increases their expenditure in the store.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在文章的其余部分，我们继续使用[因果树文章](https://medium.com/towards-data-science/understanding-causal-trees-920177462149)中的玩具示例：我们假设我们是一个**在线商店**，并且我们希望了解是否向新客户提供折扣会增加他们在商店中的支出。
- en: '![](../Images/ed7548888ecdeef65e055e84fdc01a30.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ed7548888ecdeef65e055e84fdc01a30.png)'
- en: Image, generated by Author using [NightCafé](https://creator.nightcafe.studio/)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图片，由作者使用[NightCafé](https://creator.nightcafe.studio/)生成
- en: 'To understand whether the discount is cost-effective, we have run the following
    randomized experiment or **A/B test**: every time a new customer browses our online
    store, we randomly assign it to a treatment condition. To treated users we offer
    the discount, to control users we do not. I import the data-generating process
    `dgp_online_discounts()` from `[src.dgp](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/dgp.py)`.
    I also import some plotting functions and libraries from `[src.utils](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/utils.py)`.
    To include not only code but also data and tables, I use [Deepnote](https://deepnote.com/),
    a Jupyter-like web-based collaborative notebook environment.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解折扣是否具有成本效益，我们进行了一项随机实验或**A/B测试**：每当新客户浏览我们的在线商店时，我们会随机分配其到一个处理条件。对于处理用户，我们提供折扣；对于对照用户，则不提供。我从`[src.dgp](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/dgp.py)`导入数据生成过程`dgp_online_discounts()`。我还从`[src.utils](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/utils.py)`导入了一些绘图函数和库。为了包含代码、数据和表格，我使用了[Deepnote](https://deepnote.com/)，这是一个类似Jupyter的基于网页的协作笔记本环境。
- en: We have data on 100.000 online cstore visitors, for whom we observe the `time`
    of the day they accessed the website, the `device` they use, their `browser`,
    and their geographical `region`. We also see whether they were offered the `discount`,
    our treatment, and what is their `spend`, the outcome of interest.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有关于100,000名在线商店访客的数据，我们观察他们访问网站的`时间`、使用的`设备`、他们的`浏览器`和他们的地理`区域`。我们还看到他们是否获得了`折扣`（我们的处理）以及他们的`支出`（我们关注的结果）。
- en: Since the treatment was randomly assigned, we can use a simple **difference-in-means**
    estimator to estimate the treatment effect. We expect the treatment and control
    group to be similar, except for the `discount`, therefore we can causally attribute
    any difference in `spend` to the `discount`.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 由于处理是随机分配的，我们可以使用简单的**均值差异**估计量来估计处理效果。我们预计处理组和对照组在除`折扣`之外是相似的，因此我们可以将`支出`中的任何差异归因于`折扣`。
- en: 'The discount seems to be effective: on average the spending in the treatment
    group increases by 1.95$. But are all customers equally affected?'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 折扣似乎是有效的：在处理组中，平均支出增加了1.95美元。但是所有客户的影响是否相同？
- en: To answer this question, we would like to estimate **heterogeneous treatment
    effects**, possibly at the individual level.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这个问题，我们希望估计**异质性处理效果**，可能是在个体层面上。
- en: Causal Forests
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 因果森林
- en: There are many different options to compute heterogeneous treatment effects.
    The simplest one is to interact with the outcome of interest with a dimension
    of heterogeneity. The problem with this approach is which variable to pick. Sometimes
    we have prior information that might guide our actions; for example, we might
    know that `mobile` users on average spend more than `desktop` users. Other times,
    we might be interested in one dimension for business reasons; for example, we
    might want to invest more in a certain `region`. However, when we do not extra
    information we would like this process to be data-driven.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 计算异质性处理效果有很多不同的选项。最简单的一种方法是将关注的结果与异质性维度交互。这个方法的问题在于选择哪个变量。有时我们有先验信息可以指导我们的行动；例如，我们可能知道`移动`用户的平均支出高于`桌面`用户。其他时候，我们可能出于商业原因对某个维度感兴趣；例如，我们可能希望在某个`区域`投资更多。然而，当我们没有额外信息时，我们希望这个过程是数据驱动的。
- en: 'In the [previous article](https://medium.com/towards-data-science/understanding-causal-trees-920177462149),
    we explored one data-driven approach to estimate heterogeneous treatment effects:
    **causal trees**. We will now expand them to causal forests. However, before we
    start, we have to give an introduction to its non-causal cousin: random forests.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在[上一篇文章](https://medium.com/towards-data-science/understanding-causal-trees-920177462149)中，我们探讨了一种数据驱动的方法来估计异质治疗效果：**因果树**。我们将扩展到因果森林。然而，在开始之前，我们必须介绍一下它的非因果兄弟：随机森林。
- en: '![](../Images/a7c8260b130c889ad9e94c2e15171116.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a7c8260b130c889ad9e94c2e15171116.png)'
- en: Image, generated by Author using [NightCafé](https://creator.nightcafe.studio/)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图片，由作者使用[NightCafé](https://creator.nightcafe.studio/)生成
- en: '[**Random Forests**](https://en.wikipedia.org/wiki/Random_forest), as the name
    suggests, are an extension of regression trees, adding two separate sources of
    randomness on top of them. In particular, a random forest algorithm takes the
    predictions of many different regression trees, each trained on a bootstrapped
    sample of the data, and averages them together. This procedure is generally known
    as [**bagging**](https://en.wikipedia.org/wiki/Bootstrap_aggregating), bootstrap-aggregating,
    and can be applied to any prediction algorithm and is not specific to Random Forest.
    The additional source of randomness comes from feature selection since at each
    split, only a random subset of all the features *X* is considered for the optimal
    split.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[**随机森林**](https://en.wikipedia.org/wiki/Random_forest)，顾名思义，是回归树的扩展，在其基础上增加了两个独立的随机性来源。具体而言，随机森林算法利用许多不同回归树的预测结果，每棵回归树都是在数据的自助样本上训练的，并将这些预测结果进行平均。这一过程通常被称为[**袋装法**](https://en.wikipedia.org/wiki/Bootstrap_aggregating)，自助聚合，并可以应用于任何预测算法，并非随机森林所特有。额外的随机性来源来自于特征选择，因为在每次分裂时，只考虑所有特征*X*的随机子集进行最优分裂。'
- en: These two extra sources of randomness are extremely important and contribute
    to the superior performance of random forests. First of all, bagging allows random
    forests to **produce smoother** predictions than regression trees by averaging
    multiple discrete predictions. Random feature selection instead allows random
    forests to **explore the feature space** more in-depth, allowing them to discover
    more interactions than simple regression trees. In fact, there might be interactions
    between variables that are on their own not very predictive (and therefore would
    not generate splits) but together very powerful.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个额外的随机性来源极为重要，有助于随机森林的优越性能。首先，袋装法使随机森林通过对多个离散预测进行平均，**产生更平滑**的预测。随机特征选择则允许随机森林**更深入地探索特征空间**，使其能发现比简单回归树更多的交互作用。事实上，变量之间可能存在单独来看预测能力不强（因此不会产生分裂），但一起来看却非常强大的交互作用。
- en: 'Causal Forests are the equivalent of random forests, but for the estimation
    of heterogeneous treatment effects, exactly as for causal trees and regression
    trees. Exactly as for Causal Trees, we have a fundamental problem: we are interested
    in predicting an object that we do not observe: the individual treatment effects
    *τᵢ*. The solution is to create an auxiliary outcome variable *Y** whose expected
    value for every single observation is exactly the treatment effect.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 因果森林是随机森林的等效方法，但用于估计异质治疗效果，正如因果树和回归树一样。与因果树一样，我们面临一个基本问题：我们感兴趣的是预测一个我们无法观察到的对象：个体治疗效果*τᵢ*。解决方案是创建一个辅助结果变量*Y**，其对每个观测值的期望值恰好就是治疗效果。
- en: '![](../Images/8c6ee904e46dcad7945f99fe47a9c19b.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8c6ee904e46dcad7945f99fe47a9c19b.png)'
- en: Auxiliary outcome variable, image by Author
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 辅助结果变量，由作者提供的图片
- en: If you want to know more details on why this variable is unbiased for the individual
    treatment effect, have a look at my [previous post](/920177462149) where I go
    more in detail. In short, you can interpret *Yᵢ** as the difference-in-means estimator
    for a single observation.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于为什么这个变量对个体治疗效果是无偏的细节，可以查看我的[上一篇文章](/920177462149)，在其中我会详细讲解。简而言之，你可以将*Yᵢ**解释为单个观测值的均值差异估计量。
- en: Once we have an outcome variable, there are still a couple of things we need
    to do in order to use Random Forests to estimate heterogeneous treatment effects.
    First, we need to build trees that have an equal number of treated and control
    units in each leaf. Second, we need to use different samples to build the tree
    and evaluate it, i.e. compute the average outcome per leaf. This procedure is
    often referred to as **honest trees** and it’s extremely helpful for inference
    since we can treat the sample of each leaf as independent from the tree structure.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了结果变量，还有几件事需要做，以便使用随机森林来估计异质性处理效果。首先，我们需要构建在每个叶子中有相同数量的处理和对照单位的树。其次，我们需要使用不同的样本来构建和评估树，即计算每个叶子的平均结果。这个过程通常被称为**诚实树**，它对于推断非常有帮助，因为我们可以将每个叶子的样本视为与树结构独立。
- en: Before we go into the estimation, let’s first generate dummy variables for our
    categorical variables, `device`, `browser` and `region`.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入估计之前，我们首先为分类变量`device`、`browser`和`region`生成虚拟变量。
- en: We can now estimate the heterogeneous treatment effects using the Random Forest
    algorithm. Luckily, we don’t have to do all this by hand, but there is a great
    implementation of Causal Trees and Forests in Microsoft’s [EconML](https://econml.azurewebsites.net/)
    package. We will use the `CausalForestDML` function.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用随机森林算法来估计异质性处理效果。幸运的是，我们不需要手动完成所有这些操作，微软的[EconML](https://econml.azurewebsites.net/)包中有一个很好的因果树和森林实现。我们将使用`CausalForestDML`函数。
- en: Differently from Causal Trees, Causal Forests are harder to interpret since
    we cannot visualize every single tree. We can use the `SingleTreeCateInterpreter`
    function to plot an equivalent representation of the Causal Forest algorithm.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 与因果树不同，因果森林更难解释，因为我们不能可视化每一棵树。我们可以使用`SingleTreeCateInterpreter`函数来绘制因果森林算法的等效表示。
- en: '![](../Images/b8388c2ff1a8cbb3c211d77f83de704b.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b8388c2ff1a8cbb3c211d77f83de704b.png)'
- en: Causal Forest model representation, image by Author
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 因果森林模型表示，作者提供的图像
- en: We can interpret the tree diagram exactly as for the Causal Tree model. On the
    top, we can see the average $Y^*$ in the data, 1.917$. Starting from there, the
    data gets split into different branches according to the rules highlighted at
    the top of each node. For example, the first node splits the data into two groups
    of size 46,878$ and 53,122$ depending on whether the `time` is later than 11.295\.
    At the bottom, we have our final partitions with the predicted values. For example,
    the leftmost leaf contains 40,191$ observation with `time` earlier than 11.295
    and non-Safari `browser`, for which we predict a spend of 0.264$. Darker node
    colors indicate higher prediction values.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像解释因果树模型一样解释树状图。在顶部，我们可以看到数据中的平均$Y^*$，1.917$。从那里开始，数据根据每个节点顶部突出显示的规则被分成不同的分支。例如，第一个节点根据`time`是否晚于11.295$将数据分成两个组，分别为46,878$和53,122$。在底部，我们有最终的分区及预测值。例如，最左侧的叶子包含40,191$的观察，其中`time`早于11.295$且`browser`非Safari，我们预测支出为0.264$。节点颜色越深表示预测值越高。
- en: The problem with this representation is that, differently from the case of Causal
    Trees, it is only an interpretation of the model. Since Causal Forests are made
    of many bootstrapped trees, there is no way to directly inspect each decision
    tree. One way to understand which feature is most important in determining the
    tree split is the so-called [feature importance](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表示的问题在于，与因果树的情况不同，它只是模型的一个解释。由于因果森林由许多自助抽样树组成，因此无法直接检查每棵决策树。理解哪个特征在决定树的分裂时最重要的一种方法是所谓的[特征重要性](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html)。
- en: '![](../Images/4231943452c929d60065ca79cf577212.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4231943452c929d60065ca79cf577212.png)'
- en: Clearly `time` is the first dimension of heterogeneity, followed by `device`
    (mobile in particular) and `browser` (safari in particular). Other dimensions
    do not matter much.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，`time`是异质性的第一个维度，其次是`device`（特别是移动设备）和`browser`（特别是Safari）。其他维度不太重要。
- en: Let’s now check the model performance.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们检查模型性能。
- en: Performance
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能
- en: Normally, we would not be able to directly assess the model performance since,
    differently from standard machine learning setups, we do not observe the ground
    truth. Therefore, we cannot use a test set to compute a measure of the model's
    accuracy. However, in our case, we control the data-generating process and therefore
    we have access to the ground truth. Let’s start by analyzing how well the model
    estimates heterogeneous treatment effects along the **categorical** **dimensions**
    of the data, `device`, `browser` and `region`.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们无法直接评估模型性能，因为与标准机器学习设置不同，我们无法观察到真实情况。因此，我们不能使用测试集来计算模型的准确性度量。然而，在我们的案例中，我们控制数据生成过程，因此可以访问真实情况。让我们从分析模型如何沿数据的**分类**
    **维度**（如`device`、`browser`和`region`）估计异质处理效果开始。
- en: For each categorical variable, we plot the actual and estimated average treatment
    effect.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个分类变量，我们绘制了实际和估计的平均处理效果。
- en: '![](../Images/cb17be601a029225777fc1fd7fd3ddd0.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cb17be601a029225777fc1fd7fd3ddd0.png)'
- en: True and estimated treatment effects for each categorical value, image by Author
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 每个分类值的真实和估计的处理效果，图片由作者提供
- en: The Causal Forest algorithm is pretty good at predicting the treatment effects
    related to the categorical variables. As for Causal Trees, this is expected since
    the algorithm has a very discrete nature. However, differently from Causal Trees,
    the predictions are more nuanced.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 因果森林算法在预测与分类变量相关的处理效果方面非常有效。至于因果树，由于算法具有非常离散的特性，这种情况是预期中的。然而，与因果树不同的是，预测结果更为细致。
- en: 'We can now do a more relevant test: how well the algorithm performs with a
    continuous variable such as `time`? First, let''s again isolate the predicted
    treatment effects on `time` and ignore the other covariates.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以进行更相关的测试：算法在处理连续变量如`time`时表现如何？首先，让我们再次隔离`time`上的预测处理效果，忽略其他协变量。
- en: We can now replicate the previous figure, but for the `time` dimension. We plot
    the average true and estimated treatment effect for each time of the day.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以复制之前的图，但应用于`time`维度。我们绘制了每天每个时段的真实和估计的处理效果的平均值。
- en: '![](../Images/8306233b0ad9f2190ffaae1ac541bc7d.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8306233b0ad9f2190ffaae1ac541bc7d.png)'
- en: True and estimated treatment effects along the time dimension, image by Author
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 随时间维度的真实和估计的处理效果，图片由作者提供
- en: 'We can now fully appreciate the difference between Causal Trees and Forests:
    while, in the case of Causal Trees, the estimates were essentially a very coarse
    step function, we can now see how Causal Forests produce **smoother estimates**.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以完全理解因果树和森林之间的差异：在因果树的情况下，估计结果基本上是非常粗略的阶跃函数，而我们现在可以看到因果森林如何产生**更平滑的估计**。
- en: We have now explored the model, it’s time to use it!
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经探索了模型，是时候使用它了！
- en: Policy Targeting
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 政策目标定位
- en: Suppose that we were considering offering a 4$ discount to new customers that
    visit our online store.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们考虑向访问我们在线商店的新客户提供4$的折扣。
- en: For which customers is the discount effective? We have estimated an average
    treatment effect of 1.9492$ which means that the discount is not really profitable
    on average. However, we are now able to target single individuals and we can offer
    the discount only to a subset of the incoming customers. We will now explore how
    to do **policy targeting** and in order to get a better understanding of the quality
    of the targeting, we will use the Causal Tree model as a reference point.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 折扣对哪些客户有效？我们估计了1.9492$的平均处理效果，这意味着折扣在平均情况下并不真的有利可图。然而，我们现在能够针对单个个体，只对来访客户的子集提供折扣。我们将探讨如何进行**政策目标定位**，并为了更好地理解定位的质量，我们将使用因果树模型作为参考点。
- en: We build a Causal Tree using the same `CausalForestDML` function but restricting
    the number of estimators and the forest size to 1.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用相同的`CausalForestDML`函数构建一个因果树，但将估算器数量和森林大小限制为1。
- en: 'Next, we split the dataset into a train and a test set. The idea is very similar
    to [**cross-validation**](https://en.wikipedia.org/wiki/Cross-validation_(statistics)):
    we use the training set to train the model — in our case the estimator for the
    heterogeneous treatment effects — and the test set to assess its quality. The
    main difference is that we do not observe the true outcome in the test dataset.
    But we can still use the train-test split to compare in-sample predictions with
    out-of-sample predictions.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将数据集拆分为训练集和测试集。这个想法与[**交叉验证**](https://en.wikipedia.org/wiki/Cross-validation_(statistics))非常相似：我们使用训练集来训练模型——在我们的例子中是用于异质处理效应的估计器——并使用测试集来评估其质量。主要区别在于我们无法在测试数据集中观察到真实结果。但我们仍然可以使用训练-测试拆分来比较样本内预测与样本外预测。
- en: We put 80% of all observations in the training set and 20% in the test set.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将80%的所有观察值放入训练集中，将20%放入测试集中。
- en: First, let’s retrain the models only on the training sample.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们只在训练样本上重新训练模型。
- en: 'Now we can decide on a targeting policy, i.e. decide to which customers we
    offer the discount. The answer seems simple: we offer the discount to all the
    customers for whom we anticipate a treatment effect larger than the cost, 4$.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以决定一个目标政策，即决定向哪些客户提供折扣。答案似乎很简单：我们向所有我们预计治疗效应大于成本4美元的客户提供折扣。
- en: 'A visualization tool that allows us to understand on whom the treatment is
    effective and how, is the so-called **Treatment Operative Characteristic (TOC)**
    curve. The name is remindful of the much more famous [receiver operating characteristic
    (ROC)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) curve
    that plots the true positive rate against the false positive rate for different
    thresholds of a binary classifier. The idea is similar: we plot the average treatment
    effect for different shares of the treated population. At one extreme, when all
    customers are treated, the curve takes value equal to the average treatment effect,
    while at the other extreme, when only one customer is treated, the curve takes
    value equal to the maximum treatment effect.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 一个允许我们理解处理效果及其方式的可视化工具是所谓的**处理操作特征（TOC）**曲线。这个名字让人联想到更著名的[接收者操作特征（ROC）](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)曲线，该曲线绘制了不同阈值下的真正例率与假正例率。其想法类似：我们绘制不同处理人口份额下的平均处理效应。在一个极端情况下，当所有客户都被处理时，曲线取值等于平均处理效应，而在另一个极端情况下，当仅一个客户被处理时，曲线取值等于最大处理效应。
- en: Now let’s compute the curve.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们计算曲线。
- en: Now we can plot the Treatment Operating Characteristic curves for the two CATE
    estimators.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以绘制两个CATE估计器的处理操作特征曲线。
- en: '![](../Images/75492db64e02a7aaf8e5321873415718.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75492db64e02a7aaf8e5321873415718.png)'
- en: Treatment Operating Characteristic curves, image by Author
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 处理操作特征曲线，图像由作者提供
- en: As expected, the TOC curve is decreasing for both estimators since the average
    effect decreases as we increase the share of treated customers. In other words,
    the more selective we are in releasing discounts, the higher the effect of the
    coupon, per customer. I have also plotted a horizontal line with the discount
    cost so that we can interpret the shaded area below the TOC curve and above the
    cost line as the **expected profits**.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，由于我们增加了处理客户的比例，TOC曲线对于两个估计器都是递减的。换句话说，我们在释放折扣时越有选择性，每个客户的优惠效果越高。我还绘制了一条与折扣成本水平相同的水平线，以便我们可以将TOC曲线下方且成本线以上的阴影区域解释为**预期利润**。
- en: The two algorithms predict a similar share of treated, around 20%, with the
    Causal Forest algorithm targeting slightly more customers. However, they predict
    very different profits. The Causal Tree algorithm predicts a small and constant
    margin, while the Causal Forest algorithm predicts a larger and steeper margin.
    Which algorithm is more accurate?
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个算法预测的处理份额相似，约为20%，其中因果森林算法针对的客户稍多。然而，它们预测的利润却大相径庭。因果树算法预测了一个小且恒定的利润差距，而因果森林算法预测了一个更大且更陡的利润差距。哪个算法更准确？
- en: 'In order to compare them, we can evaluate them in the test set. We take the
    model trained on the training set, we predict the treatment effects and we compare
    them with the predictions from a model trained on the test set. Note that, differently
    from machine learning standard testing procedures, there is a substantial **difference**:
    in our case, we cannot evaluate our predictions against the ground truth, since
    the treatment effects are not observed. We can only compare two predictions with
    each other.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较这两者，我们可以在测试集上进行评估。我们使用在训练集上训练的模型来预测处理效应，并与在测试集上训练的模型的预测结果进行比较。请注意，与机器学习标准测试程序不同的是，在我们的案例中，我们无法将预测结果与真实值进行评估，因为处理效应没有被观测到。我们只能相互比较两个预测结果。
- en: '![](../Images/45afc1cc609a1662db0f68ac767314eb.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/45afc1cc609a1662db0f68ac767314eb.png)'
- en: It seems that the Causal Tree model performs better than the Causal Forest model,
    with a total net effect of 8,386$$ against 4,948$$. From the plot, we can also
    understand the source of the discrepancy. The Causal Forest algorithm tends to
    be more restrictive and treats fewer customers, making no false positives but
    also having a lot of false negatives. On the other hand, the Causal Tree algorithm
    is much more generous and distributes the `discount` to many more new customers.
    This translates into both more true positives but also false positives. The net
    effect seems to favor the causal tree algorithm.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来因果树模型比因果森林模型表现更好，总净效应为8,386$$，而因果森林为4,948$$。从图中我们还可以理解差异的来源。因果森林算法趋向于更为严格，并且处理的客户较少，虽然没有假阳性，但也有很多假阴性。另一方面，因果树算法则更为宽松，将`折扣`分发给更多的新客户。这导致了更多的真正阳性，但也有假阳性。净效应似乎偏向于因果树算法。
- en: Normally, we would stop here since there is not much more we can do. However,
    in our case, we have access to the **true data-generating process**. Therefore
    we can check the ground-truth accuracy of the two algorithms.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，我们会在这里停止，因为我们不能做更多的事情。然而，在我们的案例中，我们可以访问**真实数据生成过程**。因此，我们可以检查这两种算法的真实准确性。
- en: First, let’s compare them in terms of the prediction error of the treatment
    effects. For each algorithm, we compute the [mean squared error](https://en.wikipedia.org/wiki/Mean_squared_error)
    of the treatment effects.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们从处理效应的预测误差方面进行比较。对于每种算法，我们计算处理效应的[均方误差](https://en.wikipedia.org/wiki/Mean_squared_error)。
- en: The Random Forest model better predicts the average treatment effect, with a
    mean squared error of 0.5555$ instead of 0.9035$.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林模型更好地预测了平均处理效应，其均方误差为0.5555$，而不是0.9035$。
- en: Does this map into **better targeting**? We can now replicate the same barplot
    we did above, to understand how well the two algorithms perform in terms of policy
    targeting.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这是否意味着**更好的目标定位**？我们现在可以重复之前的条形图，以了解这两种算法在政策定位方面的表现。
- en: '![](../Images/5f0a129b28a67b7fd07b9cc3f8e6f972.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5f0a129b28a67b7fd07b9cc3f8e6f972.png)'
- en: The plot is very similar, but the result differs substantially. In fact, the
    Causal Forest algorithm now outperforms the Causal Tree algorithm with a total
    effect of 10,395$ compared to 8,828$. Why this sudden difference?
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图形非常相似，但结果差异很大。实际上，因果森林算法现在的总效应为10,395$，而因果树算法为8,828$。为何会有这种突如其来的差异？
- en: To better understand the source of the discrepancy let’s plot the TOC based
    on the ground truth.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解差异的来源，让我们根据真实情况绘制TOC图。
- en: '![](../Images/db212fd08f5e3be45d93e17a4b364a10.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/db212fd08f5e3be45d93e17a4b364a10.png)'
- en: Treatment Operating Characteristic curves, image by Author
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 处理操作特征曲线，图片由作者提供
- en: As we can see, the TOC is very skewed and there exist a few customers with very
    high average treatment effects. The Random Forest algorithm is better able to
    identify them and therefore is overall more effective, despite targeting fewer
    customers.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，TOC非常偏斜，并且存在一些具有非常高平均处理效应的客户。随机森林算法更能识别这些客户，因此总体上更有效，尽管其目标客户较少。
- en: Conclusion
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'In this post, we have seen a very powerful algorithm for the estimation of
    heterogeneous treatment effects: C**ausal Forests**. Causal Forests are built
    on the same principle as Causal Trees, but benefit from a much deeper exploration
    of the parameter space and bagging.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们看到了一种用于估计异质性处理效应的非常强大的算法：**因果森林**。因果森林建立在因果树的相同原理基础上，但受益于对参数空间的更深入探索和袋装方法。
- en: We have also seen how to use the estimates of the heterogeneous treatment effects
    to perform policy **targeting**. By identifying users with the highest treatment
    effects, we are able to make profitable a policy that wouldn’t be otherwise. We
    have also seen how the objective of policy targeting might differ from the objective
    of heterogeneous treatment effect estimation since the tails of the distribution
    might be more relevant than the average.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还看到了如何利用异质治疗效应的估计来进行政策**定位**。通过识别具有最高治疗效应的用户，我们能够使本来无法获利的政策变得有利可图。我们还看到，政策定位的目标可能与异质治疗效应估计的目标不同，因为分布的尾部可能比平均值更相关。
- en: References
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: S. Athey, G. Imbens, [Recursive partitioning for heterogeneous causal effects](https://www.pnas.org/doi/abs/10.1073/pnas.1510489113)
    (2016), *PNAS*.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S. Athey, G. Imbens, [异质因果效应的递归分割](https://www.pnas.org/doi/abs/10.1073/pnas.1510489113)
    (2016), *美国国家科学院院刊*。
- en: S. Wager, S. Athey, [Estimation and Inference of Heterogeneous Treatment Effects
    using Random Forests](https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1319839)
    (2018), *Journal of the American Statistical Association*.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S. Wager, S. Athey, [使用随机森林估计和推断异质治疗效应](https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1319839)
    (2018), *美国统计协会期刊*。
- en: S. Athey, J. Tibshirani, S. Wager, [Generalized Random Forests](https://projecteuclid.org/journals/annals-of-statistics/volume-47/issue-2/Generalized-random-forests/10.1214/18-AOS1709.full)
    (2019). *The Annals of Statistics*.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S. Athey, J. Tibshirani, S. Wager, [广义随机森林](https://projecteuclid.org/journals/annals-of-statistics/volume-47/issue-2/Generalized-random-forests/10.1214/18-AOS1709.full)
    (2019). *统计年鉴*。
- en: M. Oprescu, V. Syrgkanis, Z. Wu, [Orthogonal Random Forest for Causal Inference](http://proceedings.mlr.press/v97/oprescu19a.html?ref=https%3A%2F%2Fgithubhelp.com)
    (2019). *Proceedings of the 36th International Conference on Machine Learning*.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: M. Oprescu, V. Syrgkanis, Z. Wu, [因果推断的正交随机森林](http://proceedings.mlr.press/v97/oprescu19a.html?ref=https%3A%2F%2Fgithubhelp.com)
    (2019). *第36届国际机器学习会议论文集*。
- en: Related Articles
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关文章
- en: '[DAGs and Control Variables](/b63dc69e3d8c)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DAGs 和控制变量](/b63dc69e3d8c)'
- en: '[Matching, Weighting, or Regression?](/99bf5cffa0d9)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[匹配、加权还是回归？](/99bf5cffa0d9)'
- en: '[Understanding Meta Learners](/8a9c1e340832)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解元学习器](/8a9c1e340832)'
- en: '[Understanding AIPW, the Doubly-Robust Estimator](/ed4097dab27a)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解 AIPW，双重稳健估计量](/ed4097dab27a)'
- en: '[Understanding Causal Trees](/920177462149)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解因果树](/920177462149)'
- en: Code
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: 'You can find the original Jupyter Notebook here:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到原始 Jupyter Notebook：
- en: '[https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/causal_forests.ipynb](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/causal_forests.ipynb)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/causal_forests.ipynb](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/causal_forests.ipynb)'
- en: Thank you for reading!
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 感谢阅读！
- en: '*I really appreciate it!* 🤗 *If you liked the post and would like to see more,
    consider* [***following me***](https://medium.com/@matteo.courthoud)*. I post
    once a week on topics related to causal inference and data analysis. I try to
    keep my posts simple but precise, always providing code, examples, and simulations.*'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*我非常感激！* 🤗 *如果你喜欢这篇文章并希望看到更多，请考虑* [***关注我***](https://medium.com/@matteo.courthoud)*。我每周发布一次关于因果推断和数据分析的内容。我尽量使我的帖子既简单又准确，始终提供代码、示例和模拟。*'
- en: '*Also, a small* ***disclaimer****: I write to learn so mistakes are the norm,
    even though I try my best. Please, when you spot them, let me know. I also appreciate
    suggestions on new topics!*'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '*另外，* ***免责声明****: 我写作是为了学习，因此错误是常有的事，尽管我尽力而为。如果你发现错误，请告诉我。我也欢迎对新话题的建议！*'
