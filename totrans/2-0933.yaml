- en: From Causal Trees to Forests
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»å› æœæ ‘åˆ°æ£®æ—
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/from-causal-trees-to-forests-43c4536f1481](https://towardsdatascience.com/from-causal-trees-to-forests-43c4536f1481)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/from-causal-trees-to-forests-43c4536f1481](https://towardsdatascience.com/from-causal-trees-to-forests-43c4536f1481)
- en: '[CAUSAL DATA SCIENCE](https://towardsdatascience.com/tagged/causal-data-science)'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[å› æœæ•°æ®ç§‘å­¦](https://towardsdatascience.com/tagged/causal-data-science)'
- en: '*How to use random forests to do policy targeting*'
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*å¦‚ä½•ä½¿ç”¨éšæœºæ£®æ—è¿›è¡Œæ”¿ç­–å®šä½*'
- en: '[](https://medium.com/@matteo.courthoud?source=post_page-----43c4536f1481--------------------------------)[![Matteo
    Courthoud](../Images/d873eab35a0cf9fc696658c0bee16b33.png)](https://medium.com/@matteo.courthoud?source=post_page-----43c4536f1481--------------------------------)[](https://towardsdatascience.com/?source=post_page-----43c4536f1481--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----43c4536f1481--------------------------------)
    [Matteo Courthoud](https://medium.com/@matteo.courthoud?source=post_page-----43c4536f1481--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@matteo.courthoud?source=post_page-----43c4536f1481--------------------------------)[![Matteo
    Courthoud](../Images/d873eab35a0cf9fc696658c0bee16b33.png)](https://medium.com/@matteo.courthoud?source=post_page-----43c4536f1481--------------------------------)[](https://towardsdatascience.com/?source=post_page-----43c4536f1481--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----43c4536f1481--------------------------------)
    [Matteo Courthoud](https://medium.com/@matteo.courthoud?source=post_page-----43c4536f1481--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----43c4536f1481--------------------------------)
    Â·13 min readÂ·Feb 20, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----43c4536f1481--------------------------------)
    Â·13åˆ†é’Ÿé˜…è¯»Â·2023å¹´2æœˆ20æ—¥
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/2977138a8f4b861a47fb69dc54222ec5.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2977138a8f4b861a47fb69dc54222ec5.png)'
- en: Cover, image by Author
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å°é¢ï¼Œå›¾ç‰‡ç”±ä½œè€…æä¾›
- en: In my [previous blog post](https://medium.com/towards-data-science/understanding-causal-trees-920177462149),
    we have seen how to use **causal trees** to estimate the heterogeneous treatment
    effects of a policy. If you havenâ€™t read it, I recommend reading that first since
    we will take that article's content for granted and start from there.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘[ä¹‹å‰çš„åšå®¢æ–‡ç« ](https://medium.com/towards-data-science/understanding-causal-trees-920177462149)ä¸­ï¼Œæˆ‘ä»¬å·²ç»æ¢è®¨äº†å¦‚ä½•ä½¿ç”¨**å› æœæ ‘**æ¥ä¼°è®¡æ”¿ç­–çš„å¼‚è´¨æ€§å¤„ç†æ•ˆåº”ã€‚å¦‚æœä½ è¿˜æ²¡æœ‰é˜…è¯»ï¼Œæˆ‘å»ºè®®å…ˆé˜…è¯»é‚£ç¯‡æ–‡ç« ï¼Œå› ä¸ºæˆ‘ä»¬å°†ä»¥é‚£ç¯‡æ–‡ç« çš„å†…å®¹ä¸ºåŸºç¡€ï¼Œä»é‚£é‡Œå¼€å§‹ã€‚
- en: 'Why heterogenous treatment effects (HTE)? First of all, the estimation of heterogeneous
    treatment effects allows us to select which users (patients, users, customers,
    â€¦ ) to offer treatment (a drug, ad, product, â€¦), depending on their expected outcome
    of interest (a disease, firm revenue, customer satisfaction, â€¦). In other words,
    estimating HTE allows us to do **targeting**. In fact, as we will see later in
    the article, a treatment can be ineffective or even counterproductive on average
    while bringing positive benefits to a subset of the users. The opposite can also
    be true: a drug can be effective on average, but its effectiveness can be improved
    if we identify users on whom it has side effects.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆè¦å…³æ³¨å¼‚è´¨æ€§å¤„ç†æ•ˆåº”ï¼ˆHTEï¼‰ï¼Ÿé¦–å…ˆï¼Œå¼‚è´¨æ€§å¤„ç†æ•ˆåº”çš„ä¼°è®¡ä½¿æˆ‘ä»¬èƒ½å¤Ÿé€‰æ‹©å“ªäº›ç”¨æˆ·ï¼ˆæ‚£è€…ã€ç”¨æˆ·ã€å®¢æˆ·ç­‰ï¼‰æ¥å—æ²»ç–—ï¼ˆè¯ç‰©ã€å¹¿å‘Šã€äº§å“ç­‰ï¼‰ï¼Œè¿™å–å†³äºä»–ä»¬é¢„æœŸçš„ç»“æœï¼ˆç–¾ç—…ã€å…¬å¸æ”¶å…¥ã€å®¢æˆ·æ»¡æ„åº¦ç­‰ï¼‰ã€‚æ¢å¥è¯è¯´ï¼Œä¼°è®¡HTEä½¿æˆ‘ä»¬èƒ½å¤Ÿè¿›è¡Œ**å®šä½**ã€‚å®é™…ä¸Šï¼Œæ­£å¦‚æˆ‘ä»¬åœ¨æ–‡ç« åé¢å°†çœ‹åˆ°çš„ï¼Œä¸€ä¸ªæ²»ç–—åœ¨å¹³å‡æƒ…å†µä¸‹å¯èƒ½æ— æ•ˆæˆ–ç”šè‡³é€‚å¾—å…¶åï¼Œä½†å¯¹æŸä¸€å­é›†çš„ç”¨æˆ·å´å¸¦æ¥ç§¯æçš„æ•ˆæœã€‚ç›¸åçš„æƒ…å†µä¹Ÿå¯èƒ½æˆç«‹ï¼šä¸€ç§è¯ç‰©åœ¨å¹³å‡æƒ…å†µä¸‹æœ‰æ•ˆï¼Œä½†å¦‚æœæˆ‘ä»¬è¯†åˆ«å‡ºæœ‰å‰¯ä½œç”¨çš„ç”¨æˆ·ï¼Œå…¶æ•ˆæœå¯èƒ½ä¼šå¾—åˆ°æ”¹å–„ã€‚
- en: 'In this article, we will explore an extension of causal trees: causal forests.
    Exactly as random forests extend regression trees by averaging multiple bootstrapped
    trees together, causal forests extend causal trees. The main difference comes
    from the inference perspective, which is less straightforward. We are also going
    to see how to compare the outputs of different HTE estimation algorithms and how
    to use them for **policy targeting**.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨å› æœæ ‘çš„æ‰©å±•ï¼šå› æœæ£®æ—ã€‚æ­£å¦‚éšæœºæ£®æ—é€šè¿‡å¹³å‡å¤šä¸ªè‡ªåŠ©æŠ½æ ·çš„æ ‘æ¥æ‰©å±•å›å½’æ ‘ä¸€æ ·ï¼Œå› æœæ£®æ—æ‰©å±•äº†å› æœæ ‘ã€‚ä¸»è¦çš„ä¸åŒä¹‹å¤„åœ¨äºæ¨æ–­çš„è§’åº¦ï¼Œè¿™å¹¶ä¸é‚£ä¹ˆç›´æ¥ã€‚æˆ‘ä»¬è¿˜å°†äº†è§£å¦‚ä½•æ¯”è¾ƒä¸åŒçš„HTEä¼°è®¡ç®—æ³•çš„è¾“å‡ºï¼Œå¹¶å¦‚ä½•å°†å®ƒä»¬ç”¨äº**æ”¿ç­–å®šä½**ã€‚
- en: Online Discounts
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åœ¨çº¿æŠ˜æ‰£
- en: 'For the rest of the article, we resume the toy example used in the [causal
    trees article](https://medium.com/towards-data-science/understanding-causal-trees-920177462149):
    we assume we are an **online store,** and we are interested in understanding whether
    offering discounts to new customers increases their expenditure in the store.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ–‡ç« çš„å…¶ä½™éƒ¨åˆ†ï¼Œæˆ‘ä»¬ç»§ç»­ä½¿ç”¨[å› æœæ ‘æ–‡ç« ](https://medium.com/towards-data-science/understanding-causal-trees-920177462149)ä¸­çš„ç©å…·ç¤ºä¾‹ï¼šæˆ‘ä»¬å‡è®¾æˆ‘ä»¬æ˜¯ä¸€ä¸ª**åœ¨çº¿å•†åº—**ï¼Œå¹¶ä¸”æˆ‘ä»¬å¸Œæœ›äº†è§£æ˜¯å¦å‘æ–°å®¢æˆ·æä¾›æŠ˜æ‰£ä¼šå¢åŠ ä»–ä»¬åœ¨å•†åº—ä¸­çš„æ”¯å‡ºã€‚
- en: '![](../Images/ed7548888ecdeef65e055e84fdc01a30.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ed7548888ecdeef65e055e84fdc01a30.png)'
- en: Image, generated by Author using [NightCafÃ©](https://creator.nightcafe.studio/)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ï¼Œç”±ä½œè€…ä½¿ç”¨[NightCafÃ©](https://creator.nightcafe.studio/)ç”Ÿæˆ
- en: 'To understand whether the discount is cost-effective, we have run the following
    randomized experiment or **A/B test**: every time a new customer browses our online
    store, we randomly assign it to a treatment condition. To treated users we offer
    the discount, to control users we do not. I import the data-generating process
    `dgp_online_discounts()` from `[src.dgp](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/dgp.py)`.
    I also import some plotting functions and libraries from `[src.utils](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/utils.py)`.
    To include not only code but also data and tables, I use [Deepnote](https://deepnote.com/),
    a Jupyter-like web-based collaborative notebook environment.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†äº†è§£æŠ˜æ‰£æ˜¯å¦å…·æœ‰æˆæœ¬æ•ˆç›Šï¼Œæˆ‘ä»¬è¿›è¡Œäº†ä¸€é¡¹éšæœºå®éªŒæˆ–**A/Bæµ‹è¯•**ï¼šæ¯å½“æ–°å®¢æˆ·æµè§ˆæˆ‘ä»¬çš„åœ¨çº¿å•†åº—æ—¶ï¼Œæˆ‘ä»¬ä¼šéšæœºåˆ†é…å…¶åˆ°ä¸€ä¸ªå¤„ç†æ¡ä»¶ã€‚å¯¹äºå¤„ç†ç”¨æˆ·ï¼Œæˆ‘ä»¬æä¾›æŠ˜æ‰£ï¼›å¯¹äºå¯¹ç…§ç”¨æˆ·ï¼Œåˆ™ä¸æä¾›ã€‚æˆ‘ä»`[src.dgp](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/dgp.py)`å¯¼å…¥æ•°æ®ç”Ÿæˆè¿‡ç¨‹`dgp_online_discounts()`ã€‚æˆ‘è¿˜ä»`[src.utils](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/utils.py)`å¯¼å…¥äº†ä¸€äº›ç»˜å›¾å‡½æ•°å’Œåº“ã€‚ä¸ºäº†åŒ…å«ä»£ç ã€æ•°æ®å’Œè¡¨æ ¼ï¼Œæˆ‘ä½¿ç”¨äº†[Deepnote](https://deepnote.com/)ï¼Œè¿™æ˜¯ä¸€ä¸ªç±»ä¼¼Jupyterçš„åŸºäºç½‘é¡µçš„åä½œç¬”è®°æœ¬ç¯å¢ƒã€‚
- en: We have data on 100.000 online cstore visitors, for whom we observe the `time`
    of the day they accessed the website, the `device` they use, their `browser`,
    and their geographical `region`. We also see whether they were offered the `discount`,
    our treatment, and what is their `spend`, the outcome of interest.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰å…³äº100,000ååœ¨çº¿å•†åº—è®¿å®¢çš„æ•°æ®ï¼Œæˆ‘ä»¬è§‚å¯Ÿä»–ä»¬è®¿é—®ç½‘ç«™çš„`æ—¶é—´`ã€ä½¿ç”¨çš„`è®¾å¤‡`ã€ä»–ä»¬çš„`æµè§ˆå™¨`å’Œä»–ä»¬çš„åœ°ç†`åŒºåŸŸ`ã€‚æˆ‘ä»¬è¿˜çœ‹åˆ°ä»–ä»¬æ˜¯å¦è·å¾—äº†`æŠ˜æ‰£`ï¼ˆæˆ‘ä»¬çš„å¤„ç†ï¼‰ä»¥åŠä»–ä»¬çš„`æ”¯å‡º`ï¼ˆæˆ‘ä»¬å…³æ³¨çš„ç»“æœï¼‰ã€‚
- en: Since the treatment was randomly assigned, we can use a simple **difference-in-means**
    estimator to estimate the treatment effect. We expect the treatment and control
    group to be similar, except for the `discount`, therefore we can causally attribute
    any difference in `spend` to the `discount`.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºå¤„ç†æ˜¯éšæœºåˆ†é…çš„ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç®€å•çš„**å‡å€¼å·®å¼‚**ä¼°è®¡é‡æ¥ä¼°è®¡å¤„ç†æ•ˆæœã€‚æˆ‘ä»¬é¢„è®¡å¤„ç†ç»„å’Œå¯¹ç…§ç»„åœ¨é™¤`æŠ˜æ‰£`ä¹‹å¤–æ˜¯ç›¸ä¼¼çš„ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥å°†`æ”¯å‡º`ä¸­çš„ä»»ä½•å·®å¼‚å½’å› äº`æŠ˜æ‰£`ã€‚
- en: 'The discount seems to be effective: on average the spending in the treatment
    group increases by 1.95$. But are all customers equally affected?'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æŠ˜æ‰£ä¼¼ä¹æ˜¯æœ‰æ•ˆçš„ï¼šåœ¨å¤„ç†ç»„ä¸­ï¼Œå¹³å‡æ”¯å‡ºå¢åŠ äº†1.95ç¾å…ƒã€‚ä½†æ˜¯æ‰€æœ‰å®¢æˆ·çš„å½±å“æ˜¯å¦ç›¸åŒï¼Ÿ
- en: To answer this question, we would like to estimate **heterogeneous treatment
    effects**, possibly at the individual level.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¸Œæœ›ä¼°è®¡**å¼‚è´¨æ€§å¤„ç†æ•ˆæœ**ï¼Œå¯èƒ½æ˜¯åœ¨ä¸ªä½“å±‚é¢ä¸Šã€‚
- en: Causal Forests
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å› æœæ£®æ—
- en: There are many different options to compute heterogeneous treatment effects.
    The simplest one is to interact with the outcome of interest with a dimension
    of heterogeneity. The problem with this approach is which variable to pick. Sometimes
    we have prior information that might guide our actions; for example, we might
    know that `mobile` users on average spend more than `desktop` users. Other times,
    we might be interested in one dimension for business reasons; for example, we
    might want to invest more in a certain `region`. However, when we do not extra
    information we would like this process to be data-driven.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: è®¡ç®—å¼‚è´¨æ€§å¤„ç†æ•ˆæœæœ‰å¾ˆå¤šä¸åŒçš„é€‰é¡¹ã€‚æœ€ç®€å•çš„ä¸€ç§æ–¹æ³•æ˜¯å°†å…³æ³¨çš„ç»“æœä¸å¼‚è´¨æ€§ç»´åº¦äº¤äº’ã€‚è¿™ä¸ªæ–¹æ³•çš„é—®é¢˜åœ¨äºé€‰æ‹©å“ªä¸ªå˜é‡ã€‚æœ‰æ—¶æˆ‘ä»¬æœ‰å…ˆéªŒä¿¡æ¯å¯ä»¥æŒ‡å¯¼æˆ‘ä»¬çš„è¡ŒåŠ¨ï¼›ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯èƒ½çŸ¥é“`ç§»åŠ¨`ç”¨æˆ·çš„å¹³å‡æ”¯å‡ºé«˜äº`æ¡Œé¢`ç”¨æˆ·ã€‚å…¶ä»–æ—¶å€™ï¼Œæˆ‘ä»¬å¯èƒ½å‡ºäºå•†ä¸šåŸå› å¯¹æŸä¸ªç»´åº¦æ„Ÿå…´è¶£ï¼›ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›åœ¨æŸä¸ª`åŒºåŸŸ`æŠ•èµ„æ›´å¤šã€‚ç„¶è€Œï¼Œå½“æˆ‘ä»¬æ²¡æœ‰é¢å¤–ä¿¡æ¯æ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›è¿™ä¸ªè¿‡ç¨‹æ˜¯æ•°æ®é©±åŠ¨çš„ã€‚
- en: 'In the [previous article](https://medium.com/towards-data-science/understanding-causal-trees-920177462149),
    we explored one data-driven approach to estimate heterogeneous treatment effects:
    **causal trees**. We will now expand them to causal forests. However, before we
    start, we have to give an introduction to its non-causal cousin: random forests.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨[ä¸Šä¸€ç¯‡æ–‡ç« ](https://medium.com/towards-data-science/understanding-causal-trees-920177462149)ä¸­ï¼Œæˆ‘ä»¬æ¢è®¨äº†ä¸€ç§æ•°æ®é©±åŠ¨çš„æ–¹æ³•æ¥ä¼°è®¡å¼‚è´¨æ²»ç–—æ•ˆæœï¼š**å› æœæ ‘**ã€‚æˆ‘ä»¬å°†æ‰©å±•åˆ°å› æœæ£®æ—ã€‚ç„¶è€Œï¼Œåœ¨å¼€å§‹ä¹‹å‰ï¼Œæˆ‘ä»¬å¿…é¡»ä»‹ç»ä¸€ä¸‹å®ƒçš„éå› æœå…„å¼Ÿï¼šéšæœºæ£®æ—ã€‚
- en: '![](../Images/a7c8260b130c889ad9e94c2e15171116.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a7c8260b130c889ad9e94c2e15171116.png)'
- en: Image, generated by Author using [NightCafÃ©](https://creator.nightcafe.studio/)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ï¼Œç”±ä½œè€…ä½¿ç”¨[NightCafÃ©](https://creator.nightcafe.studio/)ç”Ÿæˆ
- en: '[**Random Forests**](https://en.wikipedia.org/wiki/Random_forest), as the name
    suggests, are an extension of regression trees, adding two separate sources of
    randomness on top of them. In particular, a random forest algorithm takes the
    predictions of many different regression trees, each trained on a bootstrapped
    sample of the data, and averages them together. This procedure is generally known
    as [**bagging**](https://en.wikipedia.org/wiki/Bootstrap_aggregating), bootstrap-aggregating,
    and can be applied to any prediction algorithm and is not specific to Random Forest.
    The additional source of randomness comes from feature selection since at each
    split, only a random subset of all the features *X* is considered for the optimal
    split.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[**éšæœºæ£®æ—**](https://en.wikipedia.org/wiki/Random_forest)ï¼Œé¡¾åæ€ä¹‰ï¼Œæ˜¯å›å½’æ ‘çš„æ‰©å±•ï¼Œåœ¨å…¶åŸºç¡€ä¸Šå¢åŠ äº†ä¸¤ä¸ªç‹¬ç«‹çš„éšæœºæ€§æ¥æºã€‚å…·ä½“è€Œè¨€ï¼Œéšæœºæ£®æ—ç®—æ³•åˆ©ç”¨è®¸å¤šä¸åŒå›å½’æ ‘çš„é¢„æµ‹ç»“æœï¼Œæ¯æ£µå›å½’æ ‘éƒ½æ˜¯åœ¨æ•°æ®çš„è‡ªåŠ©æ ·æœ¬ä¸Šè®­ç»ƒçš„ï¼Œå¹¶å°†è¿™äº›é¢„æµ‹ç»“æœè¿›è¡Œå¹³å‡ã€‚è¿™ä¸€è¿‡ç¨‹é€šå¸¸è¢«ç§°ä¸º[**è¢‹è£…æ³•**](https://en.wikipedia.org/wiki/Bootstrap_aggregating)ï¼Œè‡ªåŠ©èšåˆï¼Œå¹¶å¯ä»¥åº”ç”¨äºä»»ä½•é¢„æµ‹ç®—æ³•ï¼Œå¹¶ééšæœºæ£®æ—æ‰€ç‰¹æœ‰ã€‚é¢å¤–çš„éšæœºæ€§æ¥æºæ¥è‡ªäºç‰¹å¾é€‰æ‹©ï¼Œå› ä¸ºåœ¨æ¯æ¬¡åˆ†è£‚æ—¶ï¼Œåªè€ƒè™‘æ‰€æœ‰ç‰¹å¾*X*çš„éšæœºå­é›†è¿›è¡Œæœ€ä¼˜åˆ†è£‚ã€‚'
- en: These two extra sources of randomness are extremely important and contribute
    to the superior performance of random forests. First of all, bagging allows random
    forests to **produce smoother** predictions than regression trees by averaging
    multiple discrete predictions. Random feature selection instead allows random
    forests to **explore the feature space** more in-depth, allowing them to discover
    more interactions than simple regression trees. In fact, there might be interactions
    between variables that are on their own not very predictive (and therefore would
    not generate splits) but together very powerful.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸¤ä¸ªé¢å¤–çš„éšæœºæ€§æ¥æºæä¸ºé‡è¦ï¼Œæœ‰åŠ©äºéšæœºæ£®æ—çš„ä¼˜è¶Šæ€§èƒ½ã€‚é¦–å…ˆï¼Œè¢‹è£…æ³•ä½¿éšæœºæ£®æ—é€šè¿‡å¯¹å¤šä¸ªç¦»æ•£é¢„æµ‹è¿›è¡Œå¹³å‡ï¼Œ**äº§ç”Ÿæ›´å¹³æ»‘**çš„é¢„æµ‹ã€‚éšæœºç‰¹å¾é€‰æ‹©åˆ™å…è®¸éšæœºæ£®æ—**æ›´æ·±å…¥åœ°æ¢ç´¢ç‰¹å¾ç©ºé—´**ï¼Œä½¿å…¶èƒ½å‘ç°æ¯”ç®€å•å›å½’æ ‘æ›´å¤šçš„äº¤äº’ä½œç”¨ã€‚äº‹å®ä¸Šï¼Œå˜é‡ä¹‹é—´å¯èƒ½å­˜åœ¨å•ç‹¬æ¥çœ‹é¢„æµ‹èƒ½åŠ›ä¸å¼ºï¼ˆå› æ­¤ä¸ä¼šäº§ç”Ÿåˆ†è£‚ï¼‰ï¼Œä½†ä¸€èµ·æ¥çœ‹å´éå¸¸å¼ºå¤§çš„äº¤äº’ä½œç”¨ã€‚
- en: 'Causal Forests are the equivalent of random forests, but for the estimation
    of heterogeneous treatment effects, exactly as for causal trees and regression
    trees. Exactly as for Causal Trees, we have a fundamental problem: we are interested
    in predicting an object that we do not observe: the individual treatment effects
    *Ï„áµ¢*. The solution is to create an auxiliary outcome variable *Y** whose expected
    value for every single observation is exactly the treatment effect.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å› æœæ£®æ—æ˜¯éšæœºæ£®æ—çš„ç­‰æ•ˆæ–¹æ³•ï¼Œä½†ç”¨äºä¼°è®¡å¼‚è´¨æ²»ç–—æ•ˆæœï¼Œæ­£å¦‚å› æœæ ‘å’Œå›å½’æ ‘ä¸€æ ·ã€‚ä¸å› æœæ ‘ä¸€æ ·ï¼Œæˆ‘ä»¬é¢ä¸´ä¸€ä¸ªåŸºæœ¬é—®é¢˜ï¼šæˆ‘ä»¬æ„Ÿå…´è¶£çš„æ˜¯é¢„æµ‹ä¸€ä¸ªæˆ‘ä»¬æ— æ³•è§‚å¯Ÿåˆ°çš„å¯¹è±¡ï¼šä¸ªä½“æ²»ç–—æ•ˆæœ*Ï„áµ¢*ã€‚è§£å†³æ–¹æ¡ˆæ˜¯åˆ›å»ºä¸€ä¸ªè¾…åŠ©ç»“æœå˜é‡*Y**ï¼Œå…¶å¯¹æ¯ä¸ªè§‚æµ‹å€¼çš„æœŸæœ›å€¼æ°å¥½å°±æ˜¯æ²»ç–—æ•ˆæœã€‚
- en: '![](../Images/8c6ee904e46dcad7945f99fe47a9c19b.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8c6ee904e46dcad7945f99fe47a9c19b.png)'
- en: Auxiliary outcome variable, image by Author
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: è¾…åŠ©ç»“æœå˜é‡ï¼Œç”±ä½œè€…æä¾›çš„å›¾ç‰‡
- en: If you want to know more details on why this variable is unbiased for the individual
    treatment effect, have a look at my [previous post](/920177462149) where I go
    more in detail. In short, you can interpret *Yáµ¢** as the difference-in-means estimator
    for a single observation.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äºä¸ºä»€ä¹ˆè¿™ä¸ªå˜é‡å¯¹ä¸ªä½“æ²»ç–—æ•ˆæœæ˜¯æ— åçš„ç»†èŠ‚ï¼Œå¯ä»¥æŸ¥çœ‹æˆ‘çš„[ä¸Šä¸€ç¯‡æ–‡ç« ](/920177462149)ï¼Œåœ¨å…¶ä¸­æˆ‘ä¼šè¯¦ç»†è®²è§£ã€‚ç®€è€Œè¨€ä¹‹ï¼Œä½ å¯ä»¥å°†*Yáµ¢**è§£é‡Šä¸ºå•ä¸ªè§‚æµ‹å€¼çš„å‡å€¼å·®å¼‚ä¼°è®¡é‡ã€‚
- en: Once we have an outcome variable, there are still a couple of things we need
    to do in order to use Random Forests to estimate heterogeneous treatment effects.
    First, we need to build trees that have an equal number of treated and control
    units in each leaf. Second, we need to use different samples to build the tree
    and evaluate it, i.e. compute the average outcome per leaf. This procedure is
    often referred to as **honest trees** and itâ€™s extremely helpful for inference
    since we can treat the sample of each leaf as independent from the tree structure.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æˆ‘ä»¬æœ‰äº†ç»“æœå˜é‡ï¼Œè¿˜æœ‰å‡ ä»¶äº‹éœ€è¦åšï¼Œä»¥ä¾¿ä½¿ç”¨éšæœºæ£®æ—æ¥ä¼°è®¡å¼‚è´¨æ€§å¤„ç†æ•ˆæœã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦æ„å»ºåœ¨æ¯ä¸ªå¶å­ä¸­æœ‰ç›¸åŒæ•°é‡çš„å¤„ç†å’Œå¯¹ç…§å•ä½çš„æ ‘ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ä¸åŒçš„æ ·æœ¬æ¥æ„å»ºå’Œè¯„ä¼°æ ‘ï¼Œå³è®¡ç®—æ¯ä¸ªå¶å­çš„å¹³å‡ç»“æœã€‚è¿™ä¸ªè¿‡ç¨‹é€šå¸¸è¢«ç§°ä¸º**è¯šå®æ ‘**ï¼Œå®ƒå¯¹äºæ¨æ–­éå¸¸æœ‰å¸®åŠ©ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥å°†æ¯ä¸ªå¶å­çš„æ ·æœ¬è§†ä¸ºä¸æ ‘ç»“æ„ç‹¬ç«‹ã€‚
- en: Before we go into the estimation, letâ€™s first generate dummy variables for our
    categorical variables, `device`, `browser` and `region`.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿›å…¥ä¼°è®¡ä¹‹å‰ï¼Œæˆ‘ä»¬é¦–å…ˆä¸ºåˆ†ç±»å˜é‡`device`ã€`browser`å’Œ`region`ç”Ÿæˆè™šæ‹Ÿå˜é‡ã€‚
- en: We can now estimate the heterogeneous treatment effects using the Random Forest
    algorithm. Luckily, we donâ€™t have to do all this by hand, but there is a great
    implementation of Causal Trees and Forests in Microsoftâ€™s [EconML](https://econml.azurewebsites.net/)
    package. We will use the `CausalForestDML` function.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å¯ä»¥ä½¿ç”¨éšæœºæ£®æ—ç®—æ³•æ¥ä¼°è®¡å¼‚è´¨æ€§å¤„ç†æ•ˆæœã€‚å¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä»¬ä¸éœ€è¦æ‰‹åŠ¨å®Œæˆæ‰€æœ‰è¿™äº›æ“ä½œï¼Œå¾®è½¯çš„[EconML](https://econml.azurewebsites.net/)åŒ…ä¸­æœ‰ä¸€ä¸ªå¾ˆå¥½çš„å› æœæ ‘å’Œæ£®æ—å®ç°ã€‚æˆ‘ä»¬å°†ä½¿ç”¨`CausalForestDML`å‡½æ•°ã€‚
- en: Differently from Causal Trees, Causal Forests are harder to interpret since
    we cannot visualize every single tree. We can use the `SingleTreeCateInterpreter`
    function to plot an equivalent representation of the Causal Forest algorithm.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å› æœæ ‘ä¸åŒï¼Œå› æœæ£®æ—æ›´éš¾è§£é‡Šï¼Œå› ä¸ºæˆ‘ä»¬ä¸èƒ½å¯è§†åŒ–æ¯ä¸€æ£µæ ‘ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`SingleTreeCateInterpreter`å‡½æ•°æ¥ç»˜åˆ¶å› æœæ£®æ—ç®—æ³•çš„ç­‰æ•ˆè¡¨ç¤ºã€‚
- en: '![](../Images/b8388c2ff1a8cbb3c211d77f83de704b.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b8388c2ff1a8cbb3c211d77f83de704b.png)'
- en: Causal Forest model representation, image by Author
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å› æœæ£®æ—æ¨¡å‹è¡¨ç¤ºï¼Œä½œè€…æä¾›çš„å›¾åƒ
- en: We can interpret the tree diagram exactly as for the Causal Tree model. On the
    top, we can see the average $Y^*$ in the data, 1.917$. Starting from there, the
    data gets split into different branches according to the rules highlighted at
    the top of each node. For example, the first node splits the data into two groups
    of size 46,878$ and 53,122$ depending on whether the `time` is later than 11.295\.
    At the bottom, we have our final partitions with the predicted values. For example,
    the leftmost leaf contains 40,191$ observation with `time` earlier than 11.295
    and non-Safari `browser`, for which we predict a spend of 0.264$. Darker node
    colors indicate higher prediction values.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åƒè§£é‡Šå› æœæ ‘æ¨¡å‹ä¸€æ ·è§£é‡Šæ ‘çŠ¶å›¾ã€‚åœ¨é¡¶éƒ¨ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ•°æ®ä¸­çš„å¹³å‡$Y^*$ï¼Œ1.917$ã€‚ä»é‚£é‡Œå¼€å§‹ï¼Œæ•°æ®æ ¹æ®æ¯ä¸ªèŠ‚ç‚¹é¡¶éƒ¨çªå‡ºæ˜¾ç¤ºçš„è§„åˆ™è¢«åˆ†æˆä¸åŒçš„åˆ†æ”¯ã€‚ä¾‹å¦‚ï¼Œç¬¬ä¸€ä¸ªèŠ‚ç‚¹æ ¹æ®`time`æ˜¯å¦æ™šäº11.295$å°†æ•°æ®åˆ†æˆä¸¤ä¸ªç»„ï¼Œåˆ†åˆ«ä¸º46,878$å’Œ53,122$ã€‚åœ¨åº•éƒ¨ï¼Œæˆ‘ä»¬æœ‰æœ€ç»ˆçš„åˆ†åŒºåŠé¢„æµ‹å€¼ã€‚ä¾‹å¦‚ï¼Œæœ€å·¦ä¾§çš„å¶å­åŒ…å«40,191$çš„è§‚å¯Ÿï¼Œå…¶ä¸­`time`æ—©äº11.295$ä¸”`browser`éSafariï¼Œæˆ‘ä»¬é¢„æµ‹æ”¯å‡ºä¸º0.264$ã€‚èŠ‚ç‚¹é¢œè‰²è¶Šæ·±è¡¨ç¤ºé¢„æµ‹å€¼è¶Šé«˜ã€‚
- en: The problem with this representation is that, differently from the case of Causal
    Trees, it is only an interpretation of the model. Since Causal Forests are made
    of many bootstrapped trees, there is no way to directly inspect each decision
    tree. One way to understand which feature is most important in determining the
    tree split is the so-called [feature importance](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªè¡¨ç¤ºçš„é—®é¢˜åœ¨äºï¼Œä¸å› æœæ ‘çš„æƒ…å†µä¸åŒï¼Œå®ƒåªæ˜¯æ¨¡å‹çš„ä¸€ä¸ªè§£é‡Šã€‚ç”±äºå› æœæ£®æ—ç”±è®¸å¤šè‡ªåŠ©æŠ½æ ·æ ‘ç»„æˆï¼Œå› æ­¤æ— æ³•ç›´æ¥æ£€æŸ¥æ¯æ£µå†³ç­–æ ‘ã€‚ç†è§£å“ªä¸ªç‰¹å¾åœ¨å†³å®šæ ‘çš„åˆ†è£‚æ—¶æœ€é‡è¦çš„ä¸€ç§æ–¹æ³•æ˜¯æ‰€è°“çš„[ç‰¹å¾é‡è¦æ€§](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html)ã€‚
- en: '![](../Images/4231943452c929d60065ca79cf577212.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4231943452c929d60065ca79cf577212.png)'
- en: Clearly `time` is the first dimension of heterogeneity, followed by `device`
    (mobile in particular) and `browser` (safari in particular). Other dimensions
    do not matter much.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¾ç„¶ï¼Œ`time`æ˜¯å¼‚è´¨æ€§çš„ç¬¬ä¸€ä¸ªç»´åº¦ï¼Œå…¶æ¬¡æ˜¯`device`ï¼ˆç‰¹åˆ«æ˜¯ç§»åŠ¨è®¾å¤‡ï¼‰å’Œ`browser`ï¼ˆç‰¹åˆ«æ˜¯Safariï¼‰ã€‚å…¶ä»–ç»´åº¦ä¸å¤ªé‡è¦ã€‚
- en: Letâ€™s now check the model performance.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬æ£€æŸ¥æ¨¡å‹æ€§èƒ½ã€‚
- en: Performance
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ€§èƒ½
- en: Normally, we would not be able to directly assess the model performance since,
    differently from standard machine learning setups, we do not observe the ground
    truth. Therefore, we cannot use a test set to compute a measure of the model's
    accuracy. However, in our case, we control the data-generating process and therefore
    we have access to the ground truth. Letâ€™s start by analyzing how well the model
    estimates heterogeneous treatment effects along the **categorical** **dimensions**
    of the data, `device`, `browser` and `region`.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæˆ‘ä»¬æ— æ³•ç›´æ¥è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œå› ä¸ºä¸æ ‡å‡†æœºå™¨å­¦ä¹ è®¾ç½®ä¸åŒï¼Œæˆ‘ä»¬æ— æ³•è§‚å¯Ÿåˆ°çœŸå®æƒ…å†µã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä¸èƒ½ä½¿ç”¨æµ‹è¯•é›†æ¥è®¡ç®—æ¨¡å‹çš„å‡†ç¡®æ€§åº¦é‡ã€‚ç„¶è€Œï¼Œåœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä»¬æ§åˆ¶æ•°æ®ç”Ÿæˆè¿‡ç¨‹ï¼Œå› æ­¤å¯ä»¥è®¿é—®çœŸå®æƒ…å†µã€‚è®©æˆ‘ä»¬ä»åˆ†ææ¨¡å‹å¦‚ä½•æ²¿æ•°æ®çš„**åˆ†ç±»**
    **ç»´åº¦**ï¼ˆå¦‚`device`ã€`browser`å’Œ`region`ï¼‰ä¼°è®¡å¼‚è´¨å¤„ç†æ•ˆæœå¼€å§‹ã€‚
- en: For each categorical variable, we plot the actual and estimated average treatment
    effect.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ªåˆ†ç±»å˜é‡ï¼Œæˆ‘ä»¬ç»˜åˆ¶äº†å®é™…å’Œä¼°è®¡çš„å¹³å‡å¤„ç†æ•ˆæœã€‚
- en: '![](../Images/cb17be601a029225777fc1fd7fd3ddd0.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cb17be601a029225777fc1fd7fd3ddd0.png)'
- en: True and estimated treatment effects for each categorical value, image by Author
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªåˆ†ç±»å€¼çš„çœŸå®å’Œä¼°è®¡çš„å¤„ç†æ•ˆæœï¼Œå›¾ç‰‡ç”±ä½œè€…æä¾›
- en: The Causal Forest algorithm is pretty good at predicting the treatment effects
    related to the categorical variables. As for Causal Trees, this is expected since
    the algorithm has a very discrete nature. However, differently from Causal Trees,
    the predictions are more nuanced.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: å› æœæ£®æ—ç®—æ³•åœ¨é¢„æµ‹ä¸åˆ†ç±»å˜é‡ç›¸å…³çš„å¤„ç†æ•ˆæœæ–¹é¢éå¸¸æœ‰æ•ˆã€‚è‡³äºå› æœæ ‘ï¼Œç”±äºç®—æ³•å…·æœ‰éå¸¸ç¦»æ•£çš„ç‰¹æ€§ï¼Œè¿™ç§æƒ…å†µæ˜¯é¢„æœŸä¸­çš„ã€‚ç„¶è€Œï¼Œä¸å› æœæ ‘ä¸åŒçš„æ˜¯ï¼Œé¢„æµ‹ç»“æœæ›´ä¸ºç»†è‡´ã€‚
- en: 'We can now do a more relevant test: how well the algorithm performs with a
    continuous variable such as `time`? First, let''s again isolate the predicted
    treatment effects on `time` and ignore the other covariates.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å¯ä»¥è¿›è¡Œæ›´ç›¸å…³çš„æµ‹è¯•ï¼šç®—æ³•åœ¨å¤„ç†è¿ç»­å˜é‡å¦‚`time`æ—¶è¡¨ç°å¦‚ä½•ï¼Ÿé¦–å…ˆï¼Œè®©æˆ‘ä»¬å†æ¬¡éš”ç¦»`time`ä¸Šçš„é¢„æµ‹å¤„ç†æ•ˆæœï¼Œå¿½ç•¥å…¶ä»–åå˜é‡ã€‚
- en: We can now replicate the previous figure, but for the `time` dimension. We plot
    the average true and estimated treatment effect for each time of the day.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥å¤åˆ¶ä¹‹å‰çš„å›¾ï¼Œä½†åº”ç”¨äº`time`ç»´åº¦ã€‚æˆ‘ä»¬ç»˜åˆ¶äº†æ¯å¤©æ¯ä¸ªæ—¶æ®µçš„çœŸå®å’Œä¼°è®¡çš„å¤„ç†æ•ˆæœçš„å¹³å‡å€¼ã€‚
- en: '![](../Images/8306233b0ad9f2190ffaae1ac541bc7d.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8306233b0ad9f2190ffaae1ac541bc7d.png)'
- en: True and estimated treatment effects along the time dimension, image by Author
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: éšæ—¶é—´ç»´åº¦çš„çœŸå®å’Œä¼°è®¡çš„å¤„ç†æ•ˆæœï¼Œå›¾ç‰‡ç”±ä½œè€…æä¾›
- en: 'We can now fully appreciate the difference between Causal Trees and Forests:
    while, in the case of Causal Trees, the estimates were essentially a very coarse
    step function, we can now see how Causal Forests produce **smoother estimates**.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å¯ä»¥å®Œå…¨ç†è§£å› æœæ ‘å’Œæ£®æ—ä¹‹é—´çš„å·®å¼‚ï¼šåœ¨å› æœæ ‘çš„æƒ…å†µä¸‹ï¼Œä¼°è®¡ç»“æœåŸºæœ¬ä¸Šæ˜¯éå¸¸ç²—ç•¥çš„é˜¶è·ƒå‡½æ•°ï¼Œè€Œæˆ‘ä»¬ç°åœ¨å¯ä»¥çœ‹åˆ°å› æœæ£®æ—å¦‚ä½•äº§ç”Ÿ**æ›´å¹³æ»‘çš„ä¼°è®¡**ã€‚
- en: We have now explored the model, itâ€™s time to use it!
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å·²ç»æ¢ç´¢äº†æ¨¡å‹ï¼Œæ˜¯æ—¶å€™ä½¿ç”¨å®ƒäº†ï¼
- en: Policy Targeting
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ”¿ç­–ç›®æ ‡å®šä½
- en: Suppose that we were considering offering a 4$ discount to new customers that
    visit our online store.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬è€ƒè™‘å‘è®¿é—®æˆ‘ä»¬åœ¨çº¿å•†åº—çš„æ–°å®¢æˆ·æä¾›4$çš„æŠ˜æ‰£ã€‚
- en: For which customers is the discount effective? We have estimated an average
    treatment effect of 1.9492$ which means that the discount is not really profitable
    on average. However, we are now able to target single individuals and we can offer
    the discount only to a subset of the incoming customers. We will now explore how
    to do **policy targeting** and in order to get a better understanding of the quality
    of the targeting, we will use the Causal Tree model as a reference point.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: æŠ˜æ‰£å¯¹å“ªäº›å®¢æˆ·æœ‰æ•ˆï¼Ÿæˆ‘ä»¬ä¼°è®¡äº†1.9492$çš„å¹³å‡å¤„ç†æ•ˆæœï¼Œè¿™æ„å‘³ç€æŠ˜æ‰£åœ¨å¹³å‡æƒ…å†µä¸‹å¹¶ä¸çœŸçš„æœ‰åˆ©å¯å›¾ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬ç°åœ¨èƒ½å¤Ÿé’ˆå¯¹å•ä¸ªä¸ªä½“ï¼Œåªå¯¹æ¥è®¿å®¢æˆ·çš„å­é›†æä¾›æŠ˜æ‰£ã€‚æˆ‘ä»¬å°†æ¢è®¨å¦‚ä½•è¿›è¡Œ**æ”¿ç­–ç›®æ ‡å®šä½**ï¼Œå¹¶ä¸ºäº†æ›´å¥½åœ°ç†è§£å®šä½çš„è´¨é‡ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å› æœæ ‘æ¨¡å‹ä½œä¸ºå‚è€ƒç‚¹ã€‚
- en: We build a Causal Tree using the same `CausalForestDML` function but restricting
    the number of estimators and the forest size to 1.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨ç›¸åŒçš„`CausalForestDML`å‡½æ•°æ„å»ºä¸€ä¸ªå› æœæ ‘ï¼Œä½†å°†ä¼°ç®—å™¨æ•°é‡å’Œæ£®æ—å¤§å°é™åˆ¶ä¸º1ã€‚
- en: 'Next, we split the dataset into a train and a test set. The idea is very similar
    to [**cross-validation**](https://en.wikipedia.org/wiki/Cross-validation_(statistics)):
    we use the training set to train the model â€” in our case the estimator for the
    heterogeneous treatment effects â€” and the test set to assess its quality. The
    main difference is that we do not observe the true outcome in the test dataset.
    But we can still use the train-test split to compare in-sample predictions with
    out-of-sample predictions.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ•°æ®é›†æ‹†åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚è¿™ä¸ªæƒ³æ³•ä¸[**äº¤å‰éªŒè¯**](https://en.wikipedia.org/wiki/Cross-validation_(statistics))éå¸¸ç›¸ä¼¼ï¼šæˆ‘ä»¬ä½¿ç”¨è®­ç»ƒé›†æ¥è®­ç»ƒæ¨¡å‹â€”â€”åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­æ˜¯ç”¨äºå¼‚è´¨å¤„ç†æ•ˆåº”çš„ä¼°è®¡å™¨â€”â€”å¹¶ä½¿ç”¨æµ‹è¯•é›†æ¥è¯„ä¼°å…¶è´¨é‡ã€‚ä¸»è¦åŒºåˆ«åœ¨äºæˆ‘ä»¬æ— æ³•åœ¨æµ‹è¯•æ•°æ®é›†ä¸­è§‚å¯Ÿåˆ°çœŸå®ç»“æœã€‚ä½†æˆ‘ä»¬ä»ç„¶å¯ä»¥ä½¿ç”¨è®­ç»ƒ-æµ‹è¯•æ‹†åˆ†æ¥æ¯”è¾ƒæ ·æœ¬å†…é¢„æµ‹ä¸æ ·æœ¬å¤–é¢„æµ‹ã€‚
- en: We put 80% of all observations in the training set and 20% in the test set.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†80%çš„æ‰€æœ‰è§‚å¯Ÿå€¼æ”¾å…¥è®­ç»ƒé›†ä¸­ï¼Œå°†20%æ”¾å…¥æµ‹è¯•é›†ä¸­ã€‚
- en: First, letâ€™s retrain the models only on the training sample.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œè®©æˆ‘ä»¬åªåœ¨è®­ç»ƒæ ·æœ¬ä¸Šé‡æ–°è®­ç»ƒæ¨¡å‹ã€‚
- en: 'Now we can decide on a targeting policy, i.e. decide to which customers we
    offer the discount. The answer seems simple: we offer the discount to all the
    customers for whom we anticipate a treatment effect larger than the cost, 4$.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥å†³å®šä¸€ä¸ªç›®æ ‡æ”¿ç­–ï¼Œå³å†³å®šå‘å“ªäº›å®¢æˆ·æä¾›æŠ˜æ‰£ã€‚ç­”æ¡ˆä¼¼ä¹å¾ˆç®€å•ï¼šæˆ‘ä»¬å‘æ‰€æœ‰æˆ‘ä»¬é¢„è®¡æ²»ç–—æ•ˆåº”å¤§äºæˆæœ¬4ç¾å…ƒçš„å®¢æˆ·æä¾›æŠ˜æ‰£ã€‚
- en: 'A visualization tool that allows us to understand on whom the treatment is
    effective and how, is the so-called **Treatment Operative Characteristic (TOC)**
    curve. The name is remindful of the much more famous [receiver operating characteristic
    (ROC)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) curve
    that plots the true positive rate against the false positive rate for different
    thresholds of a binary classifier. The idea is similar: we plot the average treatment
    effect for different shares of the treated population. At one extreme, when all
    customers are treated, the curve takes value equal to the average treatment effect,
    while at the other extreme, when only one customer is treated, the curve takes
    value equal to the maximum treatment effect.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå…è®¸æˆ‘ä»¬ç†è§£å¤„ç†æ•ˆæœåŠå…¶æ–¹å¼çš„å¯è§†åŒ–å·¥å…·æ˜¯æ‰€è°“çš„**å¤„ç†æ“ä½œç‰¹å¾ï¼ˆTOCï¼‰**æ›²çº¿ã€‚è¿™ä¸ªåå­—è®©äººè”æƒ³åˆ°æ›´è‘—åçš„[æ¥æ”¶è€…æ“ä½œç‰¹å¾ï¼ˆROCï¼‰](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)æ›²çº¿ï¼Œè¯¥æ›²çº¿ç»˜åˆ¶äº†ä¸åŒé˜ˆå€¼ä¸‹çš„çœŸæ­£ä¾‹ç‡ä¸å‡æ­£ä¾‹ç‡ã€‚å…¶æƒ³æ³•ç±»ä¼¼ï¼šæˆ‘ä»¬ç»˜åˆ¶ä¸åŒå¤„ç†äººå£ä»½é¢ä¸‹çš„å¹³å‡å¤„ç†æ•ˆåº”ã€‚åœ¨ä¸€ä¸ªæç«¯æƒ…å†µä¸‹ï¼Œå½“æ‰€æœ‰å®¢æˆ·éƒ½è¢«å¤„ç†æ—¶ï¼Œæ›²çº¿å–å€¼ç­‰äºå¹³å‡å¤„ç†æ•ˆåº”ï¼Œè€Œåœ¨å¦ä¸€ä¸ªæç«¯æƒ…å†µä¸‹ï¼Œå½“ä»…ä¸€ä¸ªå®¢æˆ·è¢«å¤„ç†æ—¶ï¼Œæ›²çº¿å–å€¼ç­‰äºæœ€å¤§å¤„ç†æ•ˆåº”ã€‚
- en: Now letâ€™s compute the curve.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬è®¡ç®—æ›²çº¿ã€‚
- en: Now we can plot the Treatment Operating Characteristic curves for the two CATE
    estimators.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥ç»˜åˆ¶ä¸¤ä¸ªCATEä¼°è®¡å™¨çš„å¤„ç†æ“ä½œç‰¹å¾æ›²çº¿ã€‚
- en: '![](../Images/75492db64e02a7aaf8e5321873415718.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75492db64e02a7aaf8e5321873415718.png)'
- en: Treatment Operating Characteristic curves, image by Author
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: å¤„ç†æ“ä½œç‰¹å¾æ›²çº¿ï¼Œå›¾åƒç”±ä½œè€…æä¾›
- en: As expected, the TOC curve is decreasing for both estimators since the average
    effect decreases as we increase the share of treated customers. In other words,
    the more selective we are in releasing discounts, the higher the effect of the
    coupon, per customer. I have also plotted a horizontal line with the discount
    cost so that we can interpret the shaded area below the TOC curve and above the
    cost line as the **expected profits**.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚é¢„æœŸçš„é‚£æ ·ï¼Œç”±äºæˆ‘ä»¬å¢åŠ äº†å¤„ç†å®¢æˆ·çš„æ¯”ä¾‹ï¼ŒTOCæ›²çº¿å¯¹äºä¸¤ä¸ªä¼°è®¡å™¨éƒ½æ˜¯é€’å‡çš„ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬åœ¨é‡Šæ”¾æŠ˜æ‰£æ—¶è¶Šæœ‰é€‰æ‹©æ€§ï¼Œæ¯ä¸ªå®¢æˆ·çš„ä¼˜æƒ æ•ˆæœè¶Šé«˜ã€‚æˆ‘è¿˜ç»˜åˆ¶äº†ä¸€æ¡ä¸æŠ˜æ‰£æˆæœ¬æ°´å¹³ç›¸åŒçš„æ°´å¹³çº¿ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥å°†TOCæ›²çº¿ä¸‹æ–¹ä¸”æˆæœ¬çº¿ä»¥ä¸Šçš„é˜´å½±åŒºåŸŸè§£é‡Šä¸º**é¢„æœŸåˆ©æ¶¦**ã€‚
- en: The two algorithms predict a similar share of treated, around 20%, with the
    Causal Forest algorithm targeting slightly more customers. However, they predict
    very different profits. The Causal Tree algorithm predicts a small and constant
    margin, while the Causal Forest algorithm predicts a larger and steeper margin.
    Which algorithm is more accurate?
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸¤ä¸ªç®—æ³•é¢„æµ‹çš„å¤„ç†ä»½é¢ç›¸ä¼¼ï¼Œçº¦ä¸º20%ï¼Œå…¶ä¸­å› æœæ£®æ—ç®—æ³•é’ˆå¯¹çš„å®¢æˆ·ç¨å¤šã€‚ç„¶è€Œï¼Œå®ƒä»¬é¢„æµ‹çš„åˆ©æ¶¦å´å¤§ç›¸å¾„åº­ã€‚å› æœæ ‘ç®—æ³•é¢„æµ‹äº†ä¸€ä¸ªå°ä¸”æ’å®šçš„åˆ©æ¶¦å·®è·ï¼Œè€Œå› æœæ£®æ—ç®—æ³•é¢„æµ‹äº†ä¸€ä¸ªæ›´å¤§ä¸”æ›´é™¡çš„åˆ©æ¶¦å·®è·ã€‚å“ªä¸ªç®—æ³•æ›´å‡†ç¡®ï¼Ÿ
- en: 'In order to compare them, we can evaluate them in the test set. We take the
    model trained on the training set, we predict the treatment effects and we compare
    them with the predictions from a model trained on the test set. Note that, differently
    from machine learning standard testing procedures, there is a substantial **difference**:
    in our case, we cannot evaluate our predictions against the ground truth, since
    the treatment effects are not observed. We can only compare two predictions with
    each other.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ¯”è¾ƒè¿™ä¸¤è€…ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œè¯„ä¼°ã€‚æˆ‘ä»¬ä½¿ç”¨åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒçš„æ¨¡å‹æ¥é¢„æµ‹å¤„ç†æ•ˆåº”ï¼Œå¹¶ä¸åœ¨æµ‹è¯•é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹çš„é¢„æµ‹ç»“æœè¿›è¡Œæ¯”è¾ƒã€‚è¯·æ³¨æ„ï¼Œä¸æœºå™¨å­¦ä¹ æ ‡å‡†æµ‹è¯•ç¨‹åºä¸åŒçš„æ˜¯ï¼Œåœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä»¬æ— æ³•å°†é¢„æµ‹ç»“æœä¸çœŸå®å€¼è¿›è¡Œè¯„ä¼°ï¼Œå› ä¸ºå¤„ç†æ•ˆåº”æ²¡æœ‰è¢«è§‚æµ‹åˆ°ã€‚æˆ‘ä»¬åªèƒ½ç›¸äº’æ¯”è¾ƒä¸¤ä¸ªé¢„æµ‹ç»“æœã€‚
- en: '![](../Images/45afc1cc609a1662db0f68ac767314eb.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/45afc1cc609a1662db0f68ac767314eb.png)'
- en: It seems that the Causal Tree model performs better than the Causal Forest model,
    with a total net effect of 8,386$$ against 4,948$$. From the plot, we can also
    understand the source of the discrepancy. The Causal Forest algorithm tends to
    be more restrictive and treats fewer customers, making no false positives but
    also having a lot of false negatives. On the other hand, the Causal Tree algorithm
    is much more generous and distributes the `discount` to many more new customers.
    This translates into both more true positives but also false positives. The net
    effect seems to favor the causal tree algorithm.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: çœ‹èµ·æ¥å› æœæ ‘æ¨¡å‹æ¯”å› æœæ£®æ—æ¨¡å‹è¡¨ç°æ›´å¥½ï¼Œæ€»å‡€æ•ˆåº”ä¸º8,386$$ï¼Œè€Œå› æœæ£®æ—ä¸º4,948$$ã€‚ä»å›¾ä¸­æˆ‘ä»¬è¿˜å¯ä»¥ç†è§£å·®å¼‚çš„æ¥æºã€‚å› æœæ£®æ—ç®—æ³•è¶‹å‘äºæ›´ä¸ºä¸¥æ ¼ï¼Œå¹¶ä¸”å¤„ç†çš„å®¢æˆ·è¾ƒå°‘ï¼Œè™½ç„¶æ²¡æœ‰å‡é˜³æ€§ï¼Œä½†ä¹Ÿæœ‰å¾ˆå¤šå‡é˜´æ€§ã€‚å¦ä¸€æ–¹é¢ï¼Œå› æœæ ‘ç®—æ³•åˆ™æ›´ä¸ºå®½æ¾ï¼Œå°†`æŠ˜æ‰£`åˆ†å‘ç»™æ›´å¤šçš„æ–°å®¢æˆ·ã€‚è¿™å¯¼è‡´äº†æ›´å¤šçš„çœŸæ­£é˜³æ€§ï¼Œä½†ä¹Ÿæœ‰å‡é˜³æ€§ã€‚å‡€æ•ˆåº”ä¼¼ä¹åå‘äºå› æœæ ‘ç®—æ³•ã€‚
- en: Normally, we would stop here since there is not much more we can do. However,
    in our case, we have access to the **true data-generating process**. Therefore
    we can check the ground-truth accuracy of the two algorithms.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¼šåœ¨è¿™é‡Œåœæ­¢ï¼Œå› ä¸ºæˆ‘ä»¬ä¸èƒ½åšæ›´å¤šçš„äº‹æƒ…ã€‚ç„¶è€Œï¼Œåœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è®¿é—®**çœŸå®æ•°æ®ç”Ÿæˆè¿‡ç¨‹**ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥æ£€æŸ¥è¿™ä¸¤ç§ç®—æ³•çš„çœŸå®å‡†ç¡®æ€§ã€‚
- en: First, letâ€™s compare them in terms of the prediction error of the treatment
    effects. For each algorithm, we compute the [mean squared error](https://en.wikipedia.org/wiki/Mean_squared_error)
    of the treatment effects.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œè®©æˆ‘ä»¬ä»å¤„ç†æ•ˆåº”çš„é¢„æµ‹è¯¯å·®æ–¹é¢è¿›è¡Œæ¯”è¾ƒã€‚å¯¹äºæ¯ç§ç®—æ³•ï¼Œæˆ‘ä»¬è®¡ç®—å¤„ç†æ•ˆåº”çš„[å‡æ–¹è¯¯å·®](https://en.wikipedia.org/wiki/Mean_squared_error)ã€‚
- en: The Random Forest model better predicts the average treatment effect, with a
    mean squared error of 0.5555$ instead of 0.9035$.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: éšæœºæ£®æ—æ¨¡å‹æ›´å¥½åœ°é¢„æµ‹äº†å¹³å‡å¤„ç†æ•ˆåº”ï¼Œå…¶å‡æ–¹è¯¯å·®ä¸º0.5555$ï¼Œè€Œä¸æ˜¯0.9035$ã€‚
- en: Does this map into **better targeting**? We can now replicate the same barplot
    we did above, to understand how well the two algorithms perform in terms of policy
    targeting.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¦æ„å‘³ç€**æ›´å¥½çš„ç›®æ ‡å®šä½**ï¼Ÿæˆ‘ä»¬ç°åœ¨å¯ä»¥é‡å¤ä¹‹å‰çš„æ¡å½¢å›¾ï¼Œä»¥äº†è§£è¿™ä¸¤ç§ç®—æ³•åœ¨æ”¿ç­–å®šä½æ–¹é¢çš„è¡¨ç°ã€‚
- en: '![](../Images/5f0a129b28a67b7fd07b9cc3f8e6f972.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5f0a129b28a67b7fd07b9cc3f8e6f972.png)'
- en: The plot is very similar, but the result differs substantially. In fact, the
    Causal Forest algorithm now outperforms the Causal Tree algorithm with a total
    effect of 10,395$ compared to 8,828$. Why this sudden difference?
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾å½¢éå¸¸ç›¸ä¼¼ï¼Œä½†ç»“æœå·®å¼‚å¾ˆå¤§ã€‚å®é™…ä¸Šï¼Œå› æœæ£®æ—ç®—æ³•ç°åœ¨çš„æ€»æ•ˆåº”ä¸º10,395$ï¼Œè€Œå› æœæ ‘ç®—æ³•ä¸º8,828$ã€‚ä¸ºä½•ä¼šæœ‰è¿™ç§çªå¦‚å…¶æ¥çš„å·®å¼‚ï¼Ÿ
- en: To better understand the source of the discrepancy letâ€™s plot the TOC based
    on the ground truth.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ›´å¥½åœ°ç†è§£å·®å¼‚çš„æ¥æºï¼Œè®©æˆ‘ä»¬æ ¹æ®çœŸå®æƒ…å†µç»˜åˆ¶TOCå›¾ã€‚
- en: '![](../Images/db212fd08f5e3be45d93e17a4b364a10.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/db212fd08f5e3be45d93e17a4b364a10.png)'
- en: Treatment Operating Characteristic curves, image by Author
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: å¤„ç†æ“ä½œç‰¹å¾æ›²çº¿ï¼Œå›¾ç‰‡ç”±ä½œè€…æä¾›
- en: As we can see, the TOC is very skewed and there exist a few customers with very
    high average treatment effects. The Random Forest algorithm is better able to
    identify them and therefore is overall more effective, despite targeting fewer
    customers.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬æ‰€è§ï¼ŒTOCéå¸¸åæ–œï¼Œå¹¶ä¸”å­˜åœ¨ä¸€äº›å…·æœ‰éå¸¸é«˜å¹³å‡å¤„ç†æ•ˆåº”çš„å®¢æˆ·ã€‚éšæœºæ£®æ—ç®—æ³•æ›´èƒ½è¯†åˆ«è¿™äº›å®¢æˆ·ï¼Œå› æ­¤æ€»ä½“ä¸Šæ›´æœ‰æ•ˆï¼Œå°½ç®¡å…¶ç›®æ ‡å®¢æˆ·è¾ƒå°‘ã€‚
- en: Conclusion
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: 'In this post, we have seen a very powerful algorithm for the estimation of
    heterogeneous treatment effects: C**ausal Forests**. Causal Forests are built
    on the same principle as Causal Trees, but benefit from a much deeper exploration
    of the parameter space and bagging.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†ä¸€ç§ç”¨äºä¼°è®¡å¼‚è´¨æ€§å¤„ç†æ•ˆåº”çš„éå¸¸å¼ºå¤§çš„ç®—æ³•ï¼š**å› æœæ£®æ—**ã€‚å› æœæ£®æ—å»ºç«‹åœ¨å› æœæ ‘çš„ç›¸åŒåŸç†åŸºç¡€ä¸Šï¼Œä½†å—ç›Šäºå¯¹å‚æ•°ç©ºé—´çš„æ›´æ·±å…¥æ¢ç´¢å’Œè¢‹è£…æ–¹æ³•ã€‚
- en: We have also seen how to use the estimates of the heterogeneous treatment effects
    to perform policy **targeting**. By identifying users with the highest treatment
    effects, we are able to make profitable a policy that wouldnâ€™t be otherwise. We
    have also seen how the objective of policy targeting might differ from the objective
    of heterogeneous treatment effect estimation since the tails of the distribution
    might be more relevant than the average.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜çœ‹åˆ°äº†å¦‚ä½•åˆ©ç”¨å¼‚è´¨æ²»ç–—æ•ˆåº”çš„ä¼°è®¡æ¥è¿›è¡Œæ”¿ç­–**å®šä½**ã€‚é€šè¿‡è¯†åˆ«å…·æœ‰æœ€é«˜æ²»ç–—æ•ˆåº”çš„ç”¨æˆ·ï¼Œæˆ‘ä»¬èƒ½å¤Ÿä½¿æœ¬æ¥æ— æ³•è·åˆ©çš„æ”¿ç­–å˜å¾—æœ‰åˆ©å¯å›¾ã€‚æˆ‘ä»¬è¿˜çœ‹åˆ°ï¼Œæ”¿ç­–å®šä½çš„ç›®æ ‡å¯èƒ½ä¸å¼‚è´¨æ²»ç–—æ•ˆåº”ä¼°è®¡çš„ç›®æ ‡ä¸åŒï¼Œå› ä¸ºåˆ†å¸ƒçš„å°¾éƒ¨å¯èƒ½æ¯”å¹³å‡å€¼æ›´ç›¸å…³ã€‚
- en: References
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: S. Athey, G. Imbens, [Recursive partitioning for heterogeneous causal effects](https://www.pnas.org/doi/abs/10.1073/pnas.1510489113)
    (2016), *PNAS*.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S. Athey, G. Imbens, [å¼‚è´¨å› æœæ•ˆåº”çš„é€’å½’åˆ†å‰²](https://www.pnas.org/doi/abs/10.1073/pnas.1510489113)
    (2016), *ç¾å›½å›½å®¶ç§‘å­¦é™¢é™¢åˆŠ*ã€‚
- en: S. Wager, S. Athey, [Estimation and Inference of Heterogeneous Treatment Effects
    using Random Forests](https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1319839)
    (2018), *Journal of the American Statistical Association*.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S. Wager, S. Athey, [ä½¿ç”¨éšæœºæ£®æ—ä¼°è®¡å’Œæ¨æ–­å¼‚è´¨æ²»ç–—æ•ˆåº”](https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1319839)
    (2018), *ç¾å›½ç»Ÿè®¡åä¼šæœŸåˆŠ*ã€‚
- en: S. Athey, J. Tibshirani, S. Wager, [Generalized Random Forests](https://projecteuclid.org/journals/annals-of-statistics/volume-47/issue-2/Generalized-random-forests/10.1214/18-AOS1709.full)
    (2019). *The Annals of Statistics*.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S. Athey, J. Tibshirani, S. Wager, [å¹¿ä¹‰éšæœºæ£®æ—](https://projecteuclid.org/journals/annals-of-statistics/volume-47/issue-2/Generalized-random-forests/10.1214/18-AOS1709.full)
    (2019). *ç»Ÿè®¡å¹´é‰´*ã€‚
- en: M. Oprescu, V. Syrgkanis, Z. Wu, [Orthogonal Random Forest for Causal Inference](http://proceedings.mlr.press/v97/oprescu19a.html?ref=https%3A%2F%2Fgithubhelp.com)
    (2019). *Proceedings of the 36th International Conference on Machine Learning*.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: M. Oprescu, V. Syrgkanis, Z. Wu, [å› æœæ¨æ–­çš„æ­£äº¤éšæœºæ£®æ—](http://proceedings.mlr.press/v97/oprescu19a.html?ref=https%3A%2F%2Fgithubhelp.com)
    (2019). *ç¬¬36å±Šå›½é™…æœºå™¨å­¦ä¹ ä¼šè®®è®ºæ–‡é›†*ã€‚
- en: Related Articles
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç›¸å…³æ–‡ç« 
- en: '[DAGs and Control Variables](/b63dc69e3d8c)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DAGs å’Œæ§åˆ¶å˜é‡](/b63dc69e3d8c)'
- en: '[Matching, Weighting, or Regression?](/99bf5cffa0d9)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[åŒ¹é…ã€åŠ æƒè¿˜æ˜¯å›å½’ï¼Ÿ](/99bf5cffa0d9)'
- en: '[Understanding Meta Learners](/8a9c1e340832)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ç†è§£å…ƒå­¦ä¹ å™¨](/8a9c1e340832)'
- en: '[Understanding AIPW, the Doubly-Robust Estimator](/ed4097dab27a)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ç†è§£ AIPWï¼ŒåŒé‡ç¨³å¥ä¼°è®¡é‡](/ed4097dab27a)'
- en: '[Understanding Causal Trees](/920177462149)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ç†è§£å› æœæ ‘](/920177462149)'
- en: Code
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»£ç 
- en: 'You can find the original Jupyter Notebook here:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°åŸå§‹ Jupyter Notebookï¼š
- en: '[https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/causal_forests.ipynb](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/causal_forests.ipynb)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/causal_forests.ipynb](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/causal_forests.ipynb)'
- en: Thank you for reading!
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢é˜…è¯»ï¼
- en: '*I really appreciate it!* ğŸ¤— *If you liked the post and would like to see more,
    consider* [***following me***](https://medium.com/@matteo.courthoud)*. I post
    once a week on topics related to causal inference and data analysis. I try to
    keep my posts simple but precise, always providing code, examples, and simulations.*'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*æˆ‘éå¸¸æ„Ÿæ¿€ï¼* ğŸ¤— *å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« å¹¶å¸Œæœ›çœ‹åˆ°æ›´å¤šï¼Œè¯·è€ƒè™‘* [***å…³æ³¨æˆ‘***](https://medium.com/@matteo.courthoud)*ã€‚æˆ‘æ¯å‘¨å‘å¸ƒä¸€æ¬¡å…³äºå› æœæ¨æ–­å’Œæ•°æ®åˆ†æçš„å†…å®¹ã€‚æˆ‘å°½é‡ä½¿æˆ‘çš„å¸–å­æ—¢ç®€å•åˆå‡†ç¡®ï¼Œå§‹ç»ˆæä¾›ä»£ç ã€ç¤ºä¾‹å’Œæ¨¡æ‹Ÿã€‚*'
- en: '*Also, a small* ***disclaimer****: I write to learn so mistakes are the norm,
    even though I try my best. Please, when you spot them, let me know. I also appreciate
    suggestions on new topics!*'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '*å¦å¤–ï¼Œ* ***å…è´£å£°æ˜****: æˆ‘å†™ä½œæ˜¯ä¸ºäº†å­¦ä¹ ï¼Œå› æ­¤é”™è¯¯æ˜¯å¸¸æœ‰çš„äº‹ï¼Œå°½ç®¡æˆ‘å°½åŠ›è€Œä¸ºã€‚å¦‚æœä½ å‘ç°é”™è¯¯ï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚æˆ‘ä¹Ÿæ¬¢è¿å¯¹æ–°è¯é¢˜çš„å»ºè®®ï¼*'
