["```py\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessor import StandardScaler\n\npipeline = Pipeline(\n    steps=[\n    \"standard_scaler\", StandardScaler(with_mean=True), # has with_mean/with_std hyperparameters\n    \"linear_regression\", LinearRegression(fit_intercept=True), # has fit_intercept \n ]\n)\n# This pipeline's hyperparameters set is the union of the hyperparameters of each step of the pipeline\n```", "```py\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\npipeline = Pipeline(\n    steps=[\n        ('preprocessor', StandardScaler()),\n        ('lin_reg', LinearRegression())\n    ]\n)\npipeline.get_params()\n```", "```py\n{\n 'memory': None,\n 'steps': [\n ('preprocessor', StandardScaler()),\n ('lin_reg', LinearRegression())\n ],\n 'verbose': False,\n 'preprocessor': StandardScaler(),\n 'lin_reg': LinearRegression(),\n 'preprocessor__copy': True,\n 'preprocessor__with_mean': True,\n 'preprocessor__with_std': True,\n 'lin_reg__copy_X': True,\n 'lin_reg__fit_intercept': True,\n 'lin_reg__n_jobs': None,\n 'lin_reg__positive': False\n}\n```", "```py\n# to change 2 parameters at once\npipeline.set_params(lin_reg__fit_intercept=False, preprocessor__with_std=False)\n# to change the scaler step completly\npipeline.set_params(preprocessor=MinMaxScaler())\npipeline.get_params()\n```", "```py\n{\n 'memory': None,\n 'steps': [\n     ('preprocessor', MinMaxScaler()), \n     ('lin_reg', LinearRegression())\n ],\n 'verbose': False,\n 'preprocessor': MinMaxScaler(),\n 'lin_reg': LinearRegression(),\n 'preprocessor__clip': False,\n 'preprocessor__copy': True,\n 'preprocessor__feature_range': (0, 1),\n 'lin_reg__copy_X': True,\n 'lin_reg__fit_intercept': True,\n 'lin_reg__n_jobs': None,\n 'lin_reg__positive': False\n}\n```", "```py\npipeline = Pipeline(\n     [('preprocessor', StandardScaler()),\n      ('lin_reg', LinearRegression())]\n)\nX_train, X_test, y_train, y_test = train_test_split(X, y)\nfor with_mean in [True, False]:\n    pipeline.set_params(preprocessor__with_mean=with_mean)\n    pipeline.fit(X_train, y_train)\n    print(f\"with_mean={with_mean}: score={pipeline.score(X_test, y_test)}\")\n# we can then identify the best value for with_mean\n```", "```py\nfor with_mean in [True, False]:\n    pipeline.set_params(preprocessor__with_mean=with_mean)\n    cv_results = cross_validation(pipeline, X, y)\n    print(f\"with_mean={with_mean}: score={cv_results['test_score']}\")\n# we can then identify the best value for with_mean, with more certainty about our choice\n```", "```py\nfor with_mean in [True, False]:\n    for with_std in [True, False]:\n        pipeline.set_params(preprocessor__with_mean=with_mean, preprocessor__with_std=with_std)\n        cv_results = cross_validation(pipeline, X, y)\n        print(f\"with_mean={with_mean}/with_std={with_std}: score={cv_results['test_score']}\")\n# we can then identify the best value for (with_mean, with_std)\n```", "```py\nparam_grid = {\n    \"preprocessor__with_mean\":[True, False],\n    \"preprocessor__with_std\":[True, False],\n}\nmodel_grid_search = GridSearchCV(pipeline, param_grid=param_grid)\n```", "```py\n# fit the gridsearch model\nmodel_grid_search.fit(X_train, y_train)\n# use the best model found\nmodel_grid_search.score(X_test, y_test)\nmodel_grid_search.predict(X_new)\n# or inspect the results of the grid search\nmodel_grid_search.cv_results_\n```", "```py\nparam_grid = [\n    {\n        \"preprocessor\":StandardScaler(), \n        \"preprocessor__with_mean\":[True, False], \n        \"preprocessor__with_std\":[True, False],\n    },\n    {\n        \"preprocessor\":MinMaxScaler(), \n        \"preprocessor__feature_range\":[(0, 1), (0, 0.5), (0.25, 0.75)],\n    },\n]\n# This grid search will try the StandardScaler with all combinations of with_mean/with_std AND the MinMaxScaler with 3 different ranges\nmodel_grid_search = GridSearchCV(pipeline, param_grid=param_grid)\n```", "```py\nfrom sklearn.model_selection import RandomizedSearchCV\nparam_grid = {\n    'C': uniform(0,1000).rvs(100),\n    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n    'gamma': ['scale', 'auto'] + list(uniform(0,1).rvs(10))\n}\nrandom_search_model = RandomizedSearchCV(pipeline, param_grid=param_grid, n_iter=1000)\n# fit the gridsearch model\nrandom_search_model.fit(X_train, y_train)\n# use the best model found\nrandom_search_model.score(X_test, y_test)\nrandom_search_model.predict(X_new)\n# or inspect the results of the grid search\nrandom_search_model.cv_results_\n```", "```py\n# nested-cross validation pattern: \ncv_results = cross_validate(\n    model_grid_search, X, y,\n)\n```"]