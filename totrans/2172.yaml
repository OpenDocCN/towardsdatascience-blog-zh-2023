- en: 'Uncovering Anomalies with Variational Autoencoders (VAE): A Deep Dive into
    the World of Unsupervised Learning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/uncovering-anomalies-with-variational-autoencoders-vae-a-deep-dive-into-the-world-of-1b2bce47e2e9](https://towardsdatascience.com/uncovering-anomalies-with-variational-autoencoders-vae-a-deep-dive-into-the-world-of-1b2bce47e2e9)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An example use case of using Variational Autoencoders (VAE) to detect anomalies
    in all types of data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@will.badr?source=post_page-----1b2bce47e2e9--------------------------------)[![Will
    Badr](../Images/46a4737eaedc1cb30f4f11ceb8373528.png)](https://medium.com/@will.badr?source=post_page-----1b2bce47e2e9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1b2bce47e2e9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1b2bce47e2e9--------------------------------)
    [Will Badr](https://medium.com/@will.badr?source=post_page-----1b2bce47e2e9--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1b2bce47e2e9--------------------------------)
    ·9 min read·Jan 17, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d0d9e1cf8a587f22677aba93c805486f.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: In an earlier [post](https://medium.com/p/3e5c6f017726), I explained what autoencoders
    are, what they are used for and how to leverage them in training an anomaly detection
    model. As a reminder, autoencoders are a type of neural network that are commonly
    used for dimensionality reduction and learning features. They are also commonly
    used for anomaly detection, as they can learn to reconstruct normal data, but
    may struggle to reconstruct anomalous or outlier data.
  prefs: []
  type: TYPE_NORMAL
- en: 'An autoencoder network consists of two components: an encoder and a decoder.
    The encoder maps the input data to a lower-dimensional latent space, and the decoder
    maps the latent representation back to the original input space. During training,
    the autoencoder is trained to reconstruct the input data as accurately as possible.'
  prefs: []
  type: TYPE_NORMAL
- en: To use an autoencoder for anomaly detection, the autoencoder is first trained
    on a dataset of *normal, non-anomalous* data. Once trained, the autoencoder can
    be used to reconstruct new data samples. If a new data sample is significantly
    different from the normal data that the autoencoder was trained on, it may be
    reconstructed poorly, indicating that it is potentially anomalous.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I will focus on using a variation of the autoencoder network
    called Variational Autoencoders (VAEs) to detect anomalies and what makes it different
    from regular autoencoders in detecting anomalies.
  prefs: []
  type: TYPE_NORMAL
- en: VAEs are a type of neural network architecture that is used for generative modeling.
    They are unique in that they are able to learn a compact, latent and compressed
    representation of a given dataset and then generate new samples from that representation.
  prefs: []
  type: TYPE_NORMAL
- en: One of the key feature of VAEs is that they are designed to be able to learn
    a probabilistic model of the data, which means that they can be used to generate
    new samples that are similar to the training data, but not necessarily identical.
    This allows VAEs to be used for tasks such as image generation, text generation,
    and other types of data generation.
  prefs: []
  type: TYPE_NORMAL
- en: You might still be wondering, what does a generative model have to do with the
    anomaly detection task! To answer this question, let’s review what anomaly detection
    is. Anomaly detection is the task of identifying unusual or unexpected patterns
    in a dataset, any pattern that deviates from what is normal. Since VAEs have the
    ability to learn a probabilistic model of the data, this allows them to generate
    new samples from the latent space. These new samples are drawn from the same probability
    distribution of the original data you used to train the model which makes it more
    robust and tolerant to variations in the data than regular autoencoders. This
    can be very useful for detecting anomalies in data that has a clear normal behavior.
  prefs: []
  type: TYPE_NORMAL
- en: VAE Network Structure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/081602edef181d2b836838e5476558f9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [https://commons.wikimedia.org/wiki/File:Reparameterized_Variational_Autoencoder.png](https://commons.wikimedia.org/wiki/File:Reparameterized_Variational_Autoencoder.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'VAE networks are typically composed of multiple components:'
  prefs: []
  type: TYPE_NORMAL
- en: '**An Encoder:** The encoder is a neural network that maps the input data to
    a lower-dimensional latent space. The encoder is typically parameterized by a
    set of weights and biases that are learned during training.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Latent space:** The latent space is the lower-dimensional space that the
    encoder maps the input data to. This latent space typically has a continuous structure,
    which means that the dimensions of the latent space can only take on any real
    value within a certain range. This is in contrast to a discrete latent space,
    which would only allow for a finite set of values for each dimension. This allows
    for more flexibility and expressive power in the VAE model. It allows the VAE
    to capture subtle variations and nuances in the input data, then generate new
    data samples that are close to the training data but not necessarily identical
    to it. This enables the VAE to capture the uncertainty and variability in the
    data and to generate new samples that are diverse and varied (Hence the name **Variational**
    autoencoder)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Decoder:** The decoder is a neural network that maps the latent representation
    above back to the original input space. The decoder is also typically parameterized
    by a set of weights and biases that are learned during training.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Reconstruction loss:** The reconstruction loss measures how well the decoder
    is able to reconstruct the input data from the latent representation. This loss
    is typically used to train the model.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'So far, the 4 components above are similar to the ones from the regular autoencoders.
    VAEs have two extra components:'
  prefs: []
  type: TYPE_NORMAL
- en: 5\. **A Prior:** The prior is a probabilistic distribution that is used to model
    the latent space. In VAEs, the prior is often assumed to be a standard normal
    distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. **A Posterior:** The posterior is the distribution that models the latent
    variables given the input data. The posterior is typically approximated using
    a function that is parameterized by the encoder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you know what involves a VAE network, let’s implement a base version
    of it using PyTorch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Let me explain each section in the code snippet above:'
  prefs: []
  type: TYPE_NORMAL
- en: The encoder and decoder are the same like the regular autoencoder. The encoder
    goes from the input dimension size (*input_dim*) to a small number of dimensions/compressed
    representation (*latent_dim*) then the decoder uncompresses it back to the original
    input dimensions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fc_mu`: is a fully connected layer that maps the intermediate representation
    of the input data produced by the encoder to the mean of the posterior distribution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fc_logvar`: is also a fully connected layer that maps the intermediate representation
    of the input data to the log variance of the posterior distribution. The posterior
    distribution is then used to model the latent variables given the input data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reparameterize()` The mean and log variance of the posterior that we generate
    from the fully connected layers are used to sample latent variables using this
    function. It allows the VAE to be trained using gradient-based optimization methods.
    It is also being referred to as the **reparameterization trick**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we defined the model and optimizer, let’s need to define the loss function
    and training function. The loss function in our case will be a combination of
    two different losses. The reconstruction loss that measures the difference between
    the input and output; the KL divergence loss. **The KL divergence loss** is used
    to encourage the posterior distribution to be similar to the prior distribution,
    which helps to prevent overfitting and ensure that the latent variables capture
    the underlying structure and variability of the input data.
  prefs: []
  type: TYPE_NORMAL
- en: '*Still doesn’t make sense? Let’s break it down even further:*'
  prefs: []
  type: TYPE_NORMAL
- en: The prior distribution refers to the distribution of the latent variables before
    they are conditioned on the input data. The prior distribution is typically assumed
    to be a standard normal distribution, which represents the belief that the latent
    variables are independent and have a simple distribution. The posterior distribution
    refers to the distribution of the latent variables after they are conditioned
    on the input data. The posterior distribution is modeled using the mean and log
    variance of the latent variables produced by the encoder.
  prefs: []
  type: TYPE_NORMAL
- en: 'The prior distribution is used as a regularization term in the VAE, as it encourages
    the posterior distribution of the latent variables (given the input data) to be
    similar to the prior distribution. This helps to prevent overfitting and ensure
    that the latent variables capture the underlying structure and variability of
    the input data, rather than just memorizing the training data. We simply use KL
    divergence loss to achieve this. It is calculated as the sum of the element-wise
    divergence between the posterior and prior distributions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The negative sign above is included to ensure that the loss is always non-negative,
    as the KL divergence is a non-negative measure of the difference between two distributions.
    The factor of 0.5 is included for computational convenience, as it allows the
    loss to be calculated using the mean and log variance of the latent variables,
    rather than the probability densities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the training code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: After instantiating the model, we pass in the data and the model will return
    three parameters. The reconstructed output, the mu and logvar parameters. We then
    use the mu and logvar to calculate the KL divergence loss. The total loss will
    be the sum of the reconstruction loss and KL divergence loss. Hence we calculate
    the gradients w.r.t the *total_loss* variable
  prefs: []
  type: TYPE_NORMAL
- en: 'AutoEncoders vs Variational AutoEncoders (VAE):'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The main difference between VAE and the regular autoencoders is the addition
    of the latent space and the use of the variational lower bound as the objective
    function, , which consists of two terms: the reconstruction loss and the KL divergence
    between the approximate posterior distribution over the latent space and the prior
    distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: In a regular autoencoder, the encoder network maps the input data to a latent
    representation, and the decoder network maps the latent representation back to
    the original data. The objective function is typically the reconstruction loss,
    which measures the difference between the input data and the reconstructed data.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a VAE, the encoder network still maps the input data to a latent representation,
    but the latent representation is split into two parts: a mean vector and a log
    variance vector. These two vectors are used to define a Gaussian distribution
    over the latent space, which allows the VAE to generate new samples from the latent
    space by sampling from this distribution. The decoder network is then used to
    map these latent samples back to the original data space.'
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, the main differences between a VAE and a regular autoencoder are
    the use of a latent space with a probabilistic interpretation, and the use of
    the variational lower bound as the objective function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Disadvantages of VAEs:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that explored the benefits and advantages of VAEs, particularly in the
    anomaly detection domain, let’s explore some of its disadvantages:'
  prefs: []
  type: TYPE_NORMAL
- en: VAEs may not be as effective for data that is highly variable or has multiple
    modes of normal behavior.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VAEs can also be sensitive to the different choices of hyperparameters, such
    as the latent dimension and the learning rate, which can make them difficult to
    optimize.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VAEs can be computationally expensive to train, as they require sampling from
    the latent space and back-propagating through the sampling process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VAEs may struggle to capture complex relationships between the input data and
    the latent variables, particularly when the data is highly structured or correlated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VAEs may produce blurry or low-quality reconstructions, particularly when the
    latent dimension is small or the training data is noisy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In conclusion, VAEs are a powerful and flexible tool for learning the underlying
    structure and variability of a dataset, and for generating new samples. However,
    they also have some limitations and challenges that should be considered when
    deciding whether to use a VAE for a particular task.
  prefs: []
  type: TYPE_NORMAL
