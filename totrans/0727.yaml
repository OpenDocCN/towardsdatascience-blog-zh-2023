- en: Detecting Power Laws in Real-world Data with Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/detecting-power-laws-in-real-world-data-with-python-b464190fade6](https://towardsdatascience.com/detecting-power-laws-in-real-world-data-with-python-b464190fade6)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Breaking down a Maximum Likelihood-based approach with example code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://shawhin.medium.com/?source=post_page-----b464190fade6--------------------------------)[![Shaw
    Talebi](../Images/1449cc7c08890e2078f9e5d07897e3df.png)](https://shawhin.medium.com/?source=post_page-----b464190fade6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b464190fade6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b464190fade6--------------------------------)
    [Shaw Talebi](https://shawhin.medium.com/?source=post_page-----b464190fade6--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b464190fade6--------------------------------)
    ¬∑10 min read¬∑Nov 24, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ba666f53ff8d436d975c6890cecc0147.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Luke Chesser](https://unsplash.com/@lukechesser?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: This is the 2nd article in a series about Power Laws and Fat Tails. In the previous
    post, I gave a [beginner-friendly introduction](https://medium.com/towards-data-science/pareto-power-laws-and-fat-tails-0355a187ee6a)
    to power laws and presented 3 problems with our standard statistical tools in
    analyzing them. While awareness can help us avoid these problems, it is not always
    clear what distribution some given data follow in practice. In this article, I
    will describe how to objectively detect Power Laws from real-world data and share
    a concrete example with social media data.
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: If you are unfamiliar with terms like Power Law distribution or Fat
    Tail, review the* [*first article*](https://medium.com/towards-data-science/pareto-power-laws-and-fat-tails-0355a187ee6a)
    *of this series as a primer.*'
  prefs: []
  type: TYPE_NORMAL
- en: Power Laws Break STAT 101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the [previous article](https://medium.com/towards-data-science/pareto-power-laws-and-fat-tails-0355a187ee6a),
    we focused on two types of distributions: the Gaussian distribution and the Power
    Law distribution. We saw that these distributions had diametrically opposite statistical
    properties. Namely, **Power Laws are driven by rare events, while Gaussians are
    not**.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/036b5fe909121e6989afb9a5cf1e73fe.png)'
  prefs: []
  type: TYPE_IMG
- en: Example Gaussian and Power Law distributions, respectively. Image by author
  prefs: []
  type: TYPE_NORMAL
- en: This rare-event-driven property raised [3 problems](/pareto-power-laws-and-fat-tails-0355a187ee6a)
    with many of our favorite statistical tools (e.g. mean, standard deviation, regression,
    etc.) in analyzing Power Laws. The takeaway was that if data are Gaussian-like,
    one can use common approaches like regression and computing expectation values
    without worry. However, if data are more **Power Law-like**, **these techniques
    can give incorrect and misleading results**.
  prefs: []
  type: TYPE_NORMAL
- en: We also saw a third (more mischievous) distribution that could resemble both
    a Gaussian and a Power Law (despite their opposite properties) called a **Log
    Normal distribution**.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/58ae20e9ef5a1d06ba0875c31b297730.png)'
  prefs: []
  type: TYPE_IMG
- en: The (mischievous) Log Normal distribution appears both Guassian-like and Power
    Law-like. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: This ambiguity presents challenges for practitioners in deciding the *best*
    way to analyze a given dataset. To help overcome these challenges, it can be advantageous
    to determine whether data fit a Power Law, Log Normal, or some other type of distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '**Log-Log Approach**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A popular way of fitting a Power Law to real-world data is what I‚Äôll call the
    ‚ÄúLog-Log approach‚Äù [1]. The idea comes from **taking the logarithm of the Power
    Law‚Äôs probability density function (PDF)**, as derived below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6266a7f20b2223fb76b7132c4287c240.png)'
  prefs: []
  type: TYPE_IMG
- en: Taking the log of Power Law probability distribution function [2]. Image by
    author.
  prefs: []
  type: TYPE_NORMAL
- en: The above derivation translates the Power Law‚Äôs PDF definition into a linear
    equation, as shown in the figure below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8fdabd1010c01d2a8a00a0ab50aeba1b.png)'
  prefs: []
  type: TYPE_IMG
- en: Highlight the linear form of the log(PDF). Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: This implies that the **histogram of data following a power law will follow
    a straight line**. In practice, what this looks like is generating a histogram
    for some data and plotting it on a log-log plot [1]. One might go even further
    and perform a linear regression to estimate the distribution‚Äôs Œ± value (here,
    Œ± = -m+1).
  prefs: []
  type: TYPE_NORMAL
- en: However, there are significant limitations to this approach. These are described
    in reference [1] and summarized below.
  prefs: []
  type: TYPE_NORMAL
- en: Slope (hence Œ±) estimations are subject to systematic errors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression errors can be hard to estimate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fit can look good even if the distribution does not follow a Power Law
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fits may not obey basic conditions for probability distributions e.g. normalization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Maximum Likelihood Approach**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While the Log-Log approach is simple to implement, its limitations make it less
    than optimal. Instead, we can turn to a more mathematically sound approach via
    **Maximum Likelihood**, a widely used statistical **method for inferring the *best*
    parameters for a model given some data**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Maximum Likelihood consists of 2 key steps. **Step 1**: obtain a likelihood
    function. **Step 2**: maximize the likelihood with respect to your model parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1: Write Likelihood Function**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Likelihood** is a special type of probability. Put simply, it **quantifies
    the probability of our data given a particular model**. We can express it as the
    joint probability over all our observed data [3]. In the case of a Pareto distribution,
    we can write this as follows.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e15afb52edfa66ae51e2ff07bbde4ca4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Likelihood function for Pareto distribution (i.e. a special type of Power Law)
    [4]. ***Note****: when working with Likelihood functions, observations (i.e. x_i)
    are fixed while model parameters are what vary.* Image by author.'
  prefs: []
  type: TYPE_NORMAL
- en: To make maximizing the likelihood a little easier, it is customary to work with
    the log-likelihood (they are maximized by the same value of Œ±).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c6c07b28dee7db6b09c9dc46294396e3.png)'
  prefs: []
  type: TYPE_IMG
- en: Log-likelihood derivation [4]. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 2: Maximize Likelihood**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With a (log) likelihood function in hand, we can now frame the task of determining
    the best choice of parameters as an optimization problem. To find the optimal
    Œ± value based on our data, this boils down to setting the derivative of *l(Œ±)*
    with respect to Œ± equal to zero and then solving for Œ±. A derivation of this is
    given below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5ca97eece8ca99946e4e1303bd89c3d8.png)'
  prefs: []
  type: TYPE_IMG
- en: Derivation of max likelihood estimator for Œ± [4]. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: This provides us with the so-called **Maximum Likelihood estimator** for Œ±.
    With this, we can plug in observed values of x to estimate a Pareto distribution‚Äôs
    Œ± value.
  prefs: []
  type: TYPE_NORMAL
- en: With the theoretical foundation set, let‚Äôs see what this looks like when applied
    to real-world data (from my social media accounts).
  prefs: []
  type: TYPE_NORMAL
- en: '**Example code: Fitting Power Laws to Social Media Data**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One domain in which fat-tailed data are prevalent is social media. For instance,
    a small percentage of creators get the bulk of the attention, a minority of Medium
    blogs get the majority of reads, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Here we will use the [*powerlaw*](https://pypi.org/project/powerlaw/) Python
    library to determine whether data from my various social media channels (i.e.
    Medium, YouTube, LinkedIn) *truly* follow a Power Law distribution. The data and
    code for these examples are available on the [GitHub repository](https://github.com/ShawhinT/YouTube-Blog/tree/main/power-laws/2-detecting-powerlaws).
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/ShawhinT/YouTube-Blog/tree/main/power-laws/2-detecting-powerlaws?source=post_page-----b464190fade6--------------------------------)
    [## YouTube-Blog/power-laws/2-detecting-powerlaws at main ¬∑ ShawhinT/YouTube-Blog'
  prefs: []
  type: TYPE_NORMAL
- en: Codes to complement YouTube videos and blog posts on Medium. - YouTube-Blog/power-laws/2-detecting-powerlaws
    at main ¬∑‚Ä¶
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/ShawhinT/YouTube-Blog/tree/main/power-laws/2-detecting-powerlaws?source=post_page-----b464190fade6--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '**Artificial Data**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before applying the Maximum Likelihood-based approach to messy data from the
    real world, let‚Äôs see what happens when we apply this technique to artificial
    data (*truly*) generated from Pareto and Log Normal distributions, respectively.
    This will help ground our expectations before using the approach on data in which
    we do not know the ‚Äútrue‚Äù underlying distribution class.
  prefs: []
  type: TYPE_NORMAL
- en: First, we import some helpful libraries.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Next, let‚Äôs generate data from Pareto and Log Normal distributions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: To get a sense of what these data look like, it‚Äôs helpful to plot histograms.
    Here, I plot a histogram of each sample's raw values and the log of the raw values.
    This latter distribution makes it easier to distinguish between Power Law and
    Log Normal data visually.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/df3a966cea2e93a4809dc94d6dc565e3.png)'
  prefs: []
  type: TYPE_IMG
- en: Histograms of data from Power Law distribution. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/77f704298163217ee86572ff06f27fe2.png)'
  prefs: []
  type: TYPE_IMG
- en: Histograms of data from Log Normal distribution. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see from the above histograms, the distributions of raw values look
    qualitatively similar for both distributions. However, we can see a **stark difference
    in the log distributions**. Namely, the log Power Law distribution is highly skewed
    and not mean-centered, while the log of the Log Normal distribution is reminiscent
    of a Gaussian distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can use the *powerlaw* library to fit a Power Law to each sample and
    estimate values for Œ± and x_min. Here‚Äôs what that looks like for our Power Law
    sample.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The fit does a decent job at estimating the true parameter values (i.e. a=3,
    x_min=1), as seen by the alpha and x_min values printed above. The value p above
    quantifies the quality of the fit. A higher p means a better fit *(more on this
    value in section 4.1 of ref [1])*.
  prefs: []
  type: TYPE_NORMAL
- en: We can do a similar thing for the Log Normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the Log Normal sample also fits a Power Law distribution well
    (p=0.999). Notice, however, that the x_min value is far in the tail. While this
    may be helpful for some use cases, it doesn't tell us much about the distribution
    that best fits all the data in the sample.
  prefs: []
  type: TYPE_NORMAL
- en: To overcome this, we can manually set the x_min value to the sample minimum
    and redo the fit.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The .Fit() method also automatically generates estimates for a Log Normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The estimated Log Normal parameter values are close to the actual values (mu=10,
    sigma=1), so the fit did a good job once again!
  prefs: []
  type: TYPE_NORMAL
- en: However, by fixing x_min, we lost our quality metric p (*for whatever reason,
    the method doesn‚Äôt generate values for it when x_min is provided*). So this begs
    the question, *which distribution parameters should I go with? The Power Law or
    Log Normal?*
  prefs: []
  type: TYPE_NORMAL
- en: To answer this question, we can compare the Power Law fit to other candidate
    distributions via **Log-likelihood ratios (R)**. A positive R implies the Power
    Law is a better fit, while a negative R implies the alternative distribution is
    better. Additionally, each comparison gives us a significance value (p). This
    is demonstrated in the code block below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: As shown above, every alternative distribution is preferred over the Power Law
    when including all the data in the Log Normal sample. Additionally, based on the
    likelihood ratios, the lognormal and lognormal_positive fits work best.
  prefs: []
  type: TYPE_NORMAL
- en: Real-world Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we‚Äôve applied the *powerlaw* library to data where we know the ground
    truth let‚Äôs try it on data for which the underlying distribution is unknown.
  prefs: []
  type: TYPE_NORMAL
- en: We will follow a similar procedure as we did above but with data from the real
    world. Here, we will analyze the following data. Monthly followers gained on my
    **Medium** profile, earnings across all my **YouTube** videos, and daily impressions
    on my **LinkedIn** posts for the past year.
  prefs: []
  type: TYPE_NORMAL
- en: We‚Äôll start by plotting histograms.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c6f1b93d5bce6020817c85f4614546f9.png)'
  prefs: []
  type: TYPE_IMG
- en: Medium followers gained histograms. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ee4b687061d2e1fd21c6acb676dc8ea5.png)'
  prefs: []
  type: TYPE_IMG
- en: YouTube video earnings histograms. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1bbd897528f57b6f247f33ee6223bb66.png)'
  prefs: []
  type: TYPE_IMG
- en: LinkedIn daily impressions histograms. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Two things jump out to me from these plots. **One**, all three look more like
    the Log Normal histograms than the Power Law histograms we saw before. **Two**,
    the Medium and YouTube distributions are sparse, meaning they may have insufficient
    data for drawing strong conclusions.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we‚Äôll apply the Power Law fit to all three distributions while setting
    x_min as the smallest value in each sample. The results of this are printed below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4ff5e7785f19531920114442aa606f0b.png)'
  prefs: []
  type: TYPE_IMG
- en: Power Law and Log Normal parameter estimates for empirical data. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: To determine which distribution is best, we can again do head-to-head comparisons
    of the Power Law fit to some alternatives. These results are given below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1363f6506cb15952f63a9e9b41cd45ad.png)'
  prefs: []
  type: TYPE_IMG
- en: Fit comparisons of Power Law and alternative distributions. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Using the rule of thumb significance cutoff of p<0.1 we can draw the following
    conclusions. Medium followers and LinkedIn impressions best fit a Log Normal distribution,
    while a Power Law best represents YouTube earnings.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, since the Medium followers and YouTube earrings data here is limited
    (N<100), we should take any conclusions from those data with a grain of salt.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many standard statistical tools break down when applied to data following a
    Power Law distribution. Accordingly, detecting Power Laws in empirical data can
    help practitioners avoid incorrect analyses and misleading conclusions.
  prefs: []
  type: TYPE_NORMAL
- en: However, Power Laws are an extreme case of the more general phenomenon of **fat
    tails**. In the [next article](/4-ways-to-quantify-fat-tails-with-python-10ce62c0ada1)
    of this series, we will take this work one step further and quantify fat-tailedness
    for any given dataset via 4 handy heuristics.
  prefs: []
  type: TYPE_NORMAL
- en: '**üëâ More on Power Laws & Fat Tails**: [Introduction](/pareto-power-laws-and-fat-tails-0355a187ee6a)
    | [Quantifying Fat Tails](/4-ways-to-quantify-fat-tails-with-python-10ce62c0ada1)'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/4-ways-to-quantify-fat-tails-with-python-10ce62c0ada1?source=post_page-----b464190fade6--------------------------------)
    [## 4 Ways to Quantify Fat Tails with Python'
  prefs: []
  type: TYPE_NORMAL
- en: Intuition and Example Code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/4-ways-to-quantify-fat-tails-with-python-10ce62c0ada1?source=post_page-----b464190fade6--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Connect**: [My website](https://shawhintalebi.com/) | [Book a call](https://calendly.com/shawhintalebi)
    | [Ask me anything](https://shawhintalebi.com/contact/)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Socials**: [YouTube üé•](https://www.youtube.com/channel/UCa9gErQ9AE5jT2DZLjXBIdA)
    | [LinkedIn](https://www.linkedin.com/in/shawhintalebi/) | [Twitter](https://twitter.com/ShawhinT)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Support**: [Buy me a coffee](https://www.buymeacoffee.com/shawhint) ‚òïÔ∏è'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://shawhin.medium.com/subscribe?source=post_page-----b464190fade6--------------------------------)
    [## Get FREE access to every new story I write'
  prefs: []
  type: TYPE_NORMAL
- en: Get FREE access to every new story I write P.S. I do not share your email with
    anyone By signing up, you will create a‚Ä¶
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: shawhin.medium.com](https://shawhin.medium.com/subscribe?source=post_page-----b464190fade6--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '[1] arXiv:0706.1062 [physics.data-an]'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] arXiv:2001.10488 [stat.OT]'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] [https://en.wikipedia.org/wiki/Likelihood_function](https://en.wikipedia.org/wiki/Likelihood_function)'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] [https://en.wikipedia.org/wiki/Pareto_distribution](https://en.wikipedia.org/wiki/Pareto_distribution)'
  prefs: []
  type: TYPE_NORMAL
