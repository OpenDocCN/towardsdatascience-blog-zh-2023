["```py\nimport seaborn as sns \n\ndiamonds = sns.load_dataset(\"diamonds\")\ndiamonds.head()\n```", "```py\nimport numpy as np\nfrom sklearn.preprocessing import OrdinalEncoder\n\n# Extract feature and target arrays\nX, y = diamonds.drop(\"carat\", axis=1), diamonds[\"carat\"]\n# Select categorical column names\ncats = X.select_dtypes(exclude=np.number).columns.tolist()\n\n# Encode categoricals\nX.loc[:, cats] = OrdinalEncoder().fit_transform(X[cats])\n```", "```py\n# Import LOF\nfrom pyod.models.lof import LOF\n\n# Initialize\nlof = LOF(n_neighbors=30).fit(X)\n\n# Extract inlier/outlier labels\nlabels = lof.labels_\noutliers_X_lof = X[labels == 1]\n```", "```py\nnum_outliers = len(outliers_X_lof)\nprint(f\"The number of outliers: {num_outliers}\")\nprint(f\"Percentage of outliers: {num_outliers / len(X):.3f}\")\n```", "```py\nThe number of outliers: 5394\nPercentage of outliers: 0.100\n```", "```py\nfrom pyod.models.iforest import IForest\n\niforest = IForest(n_estimators=500).fit(X)\n\nlabels = iforest.labels_\noutliers_X_iforest = X[labels == 1]\n\nnum_outliers = len(outliers_X_iforest)\nprint(f\"The number of outliers: {num_outliers}\")\nprint(f\"Percentage of outliers: {num_outliers / len(X):.3f}\")\n```", "```py\nThe number of outliers: 5394\nPercentage of outliers: 0.100\n```", "```py\niforest = IForest().fit(X)\n\niforest.decision_scores_[:10]\n```", "```py\narray([-0.03364944,  0.0287027 ,  0.07729889, -0.06363647, -0.03095093,\n        0.05240712,  0.0230652 , -0.02713253,  0.06674287,  0.03475134])\n```", "```py\nfrom pyod.models.iforest import IForest\n\niforest = IForest(n_estimators=1000).fit(X)\n\nprobs = iforest.predict_proba(X)\nprobs[:5]\n```", "```py\narray([[0.6309838 , 0.3690162 ],\n       [0.48315014, 0.51684986],\n       [0.3044389 , 0.6955611 ],\n       [0.73513599, 0.26486401],\n       [0.59298752, 0.40701248]])\n```", "```py\nfrom sklearn.preprocessing import minmax_scale\n\n# Create an empty array with two columns\nprobs = np.empty((len(X), 2))\n\n# The second column is outlier probabilities\nprobs[:, 1] = minmax_scale(iforest.decision_scores_)\n\n# The first column is inlier probabilities\nprobs[:, 0] = 1 - probs[:, 1]\n\n# Check if the probs match\nprobs[:5] == iforest.predict_proba(X)[:5]\n```", "```py\narray([[ True,  True],\n       [ True,  True],\n       [ True,  True],\n       [ True,  True],\n       [ True,  True]])\n```", "```py\n# Set a confidence threshold\nthreshold = 0.9\n\n# Create a mask that returns True if probs over threshold\nis_outlier = probs[:, 1] > threshold\noutliers_X_probs = X[is_outlier]\n\n# Count up the outliers\nnum_outliers = len(outliers_X_probs)\nprint(f\"The number of outliers: {num_outliers}\")\nprint(f\"Percentage of outliers: {num_outliers / len(X):.4f}\")\n```", "```py\nThe number of outliers: 12\nPercentage of outliers: 0.0002\n```"]