- en: How to design an MLOps architecture in AWS?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何在AWS中设计MLOps架构？
- en: 原文：[https://towardsdatascience.com/how-to-design-an-mlops-architecture-in-aws-67ee9843a430](https://towardsdatascience.com/how-to-design-an-mlops-architecture-in-aws-67ee9843a430)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-design-an-mlops-architecture-in-aws-67ee9843a430](https://towardsdatascience.com/how-to-design-an-mlops-architecture-in-aws-67ee9843a430)
- en: A guide for developers and architects especially those who are not specialized
    in machine learning to design an MLOps architecture for their organization
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为开发人员和架构师提供的指南，特别是那些未专门从事机器学习的人员，帮助他们为组织设计MLOps架构
- en: '[](https://medium.com/@harminder1?source=post_page-----67ee9843a430--------------------------------)[![Harminder
    Singh](../Images/e02deb224f2943feefe2d075d196c4e8.png)](https://medium.com/@harminder1?source=post_page-----67ee9843a430--------------------------------)[](https://towardsdatascience.com/?source=post_page-----67ee9843a430--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----67ee9843a430--------------------------------)
    [Harminder Singh](https://medium.com/@harminder1?source=post_page-----67ee9843a430--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@harminder1?source=post_page-----67ee9843a430--------------------------------)[![Harminder
    Singh](../Images/e02deb224f2943feefe2d075d196c4e8.png)](https://medium.com/@harminder1?source=post_page-----67ee9843a430--------------------------------)[](https://towardsdatascience.com/?source=post_page-----67ee9843a430--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----67ee9843a430--------------------------------)
    [哈明德·辛格](https://medium.com/@harminder1?source=post_page-----67ee9843a430--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----67ee9843a430--------------------------------)
    ·8 min read·Apr 14, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[数据科学之路](https://towardsdatascience.com/?source=post_page-----67ee9843a430--------------------------------)
    ·阅读时长8分钟·2023年4月14日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '**Introduction**'
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**介绍**'
- en: According to Gartner’s findings, only 53% of machine learning (ML) projects
    progress from proof of concept (POC) to production. Often there is a misalignment
    between the strategic objectives of the company and machine learning models built
    by data scientists. There might be a lack of communication between DevOps, security,
    legal, IT and the data scientist that causes challenges to pushing the model into
    production. Finally, the team might find it difficult to maintain the models in
    production while pushing out new models. It has led to the rise of MLOps which
    brings the principles of DevOps, such as continuous integration and continuous
    delivery (CI/CD), automation, and collaboration to the machine learning lifecycle
    — development, deployment and monitoring.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Gartner的研究，仅53%的机器学习（ML）项目从概念验证（POC）阶段推进到生产阶段。公司战略目标与数据科学家构建的机器学习模型之间通常存在不一致。DevOps、安全、法律、IT和数据科学家之间的沟通可能不足，这会给将模型推向生产带来挑战。最后，团队可能发现维护生产中的模型以及推出新模型是困难的。这导致了MLOps的兴起，将DevOps的原则，如持续集成和持续交付（CI/CD）、自动化和协作，带入机器学习生命周期——开发、部署和监控。
- en: 'In this article, I will dive into the following :'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我将深入探讨以下内容：
- en: Various steps in the machine learning process
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习过程中的各个步骤
- en: Different MLOps components and explain why they are necessary without diving
    too much into the details that only data scientists need to know
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍不同的MLOps组件，并解释它们为何必要，而不深入讲解只有数据科学家需要了解的细节
- en: MLOps architecture diagrams based on the size and maturity of the organization
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据组织的规模和成熟度，提供MLOps架构图
- en: General suggestions on starting the MLOps journey
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于开始MLOps旅程的一般建议
- en: '**Typical Machine-learning process**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**典型的机器学习过程**'
- en: Let’s start first by understanding the steps involved in the machine learning
    process.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们了解机器学习过程中的各个步骤。
- en: '![](../Images/0e9c0f800f602be9bd960c2f4ee405cf.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0e9c0f800f602be9bd960c2f4ee405cf.png)'
- en: '**Machine learning process** — Image by Author'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习过程** — 作者提供的图片'
- en: 'A machine learning process has the following components:'
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习过程包括以下组件：
- en: '**Business Problem and Machine learning problem statement:** We start the process
    by identifying the business problem and agreeing that machine learning is the
    right solution for the problem. The proposed machine-learning solution should
    produce a measurable business outcome.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**业务问题和机器学习问题陈述：** 我们通过识别业务问题并确认机器学习是解决该问题的正确方案来开始过程。提出的机器学习解决方案应产生可衡量的业务成果。'
- en: '**Data Collection, Integration and Cleaning:** In this step, data scientists/data
    engineers collect data, integrate it with different sources, and clean & transform
    it to make it consumption ready. Data engineers/scientists might also divide the
    data into three datasets — Training, validation, and testing using a ratio of
    80–10–10 or 60–20–20\. Training datasets are used directly for training the model,
    validation sets are the unseen examples to evaluate the model’s performance, and
    testing sets are another set of unseen records to check the real-life model’s
    performance.'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据收集、整合和清理：** 在这一步中，数据科学家/数据工程师收集数据，将其与不同来源整合，并清理和转换以使其准备好供使用。数据工程师/科学家可能还会将数据划分为三组数据集——训练集、验证集和测试集，使用80–10–10或60–20–20的比例。训练集直接用于训练模型，验证集用于评估模型性能的未见示例，测试集则是另一组未见记录，用于检查模型在现实生活中的表现。'
- en: '**Data analysis and Visualization:** Data scientists then perform exploratory
    analysis(EDA) to understand the structure and quality of the data. This step is
    necessary to understand the data discrepancies, patterns and formation of new
    hypotheses.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据分析和可视化：** 数据科学家随后进行探索性分析（EDA）以理解数据的结构和质量。这一步是了解数据差异、模式以及形成新假设所必需的。'
- en: '**Feature engineering**: In this step, data is selected, combined, and manipulated
    to create new variables using statistical or machine learning approaches. For
    example — doing log transform or scaling, or normalization. Together all-new features
    contribute towards improving model performance.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**特征工程**：在这一步中，数据被选择、组合和处理，以使用统计或机器学习方法创建新变量。例如——进行对数变换、缩放或标准化。所有新特征共同有助于提高模型性能。'
- en: '**Model training and parameter tuning**: Once the new features are available,
    data scientists train various ML models, and hyperparameters are tuned to meet
    the desired SLA metrics.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型训练和参数调优**：一旦新特征可用，数据科学家将训练各种机器学习模型，并调优超参数以满足所需的服务水平协议指标。'
- en: '**Model Evaluation and Deployment:** In this step, the model with the best
    accuracy among all the other models is selected and deployed to production. Deployment
    of the model means that the model is ready for consumption(prediction).'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型评估和部署：** 在这一步中，从所有其他模型中选择准确度最高的模型，并将其部署到生产环境中。模型部署意味着模型已准备好进行预测。'
- en: '**Monitoring and debugging:** The machine learning model is out of date as
    soon as you deploy it to the real world. The model must be regularly re-trained
    with updated data.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**监控和调试：** 机器学习模型一旦部署到真实世界中，就会变得过时。模型必须定期使用更新的数据重新训练。'
- en: Every data scientist will more or less follow this process and perform most
    of the above steps manually if they are new to their machine learning journey.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 每个数据科学家在机器学习旅程初期或多或少都会遵循这一过程，并手动执行大多数上述步骤。
- en: To illustrate what I mean, let us look at the architecture diagram without MLOps.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明我的意思，让我们看看没有 MLOps 的架构图。
- en: '![](../Images/a2f26d4517828ff9dbffb9a8a3905d43.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a2f26d4517828ff9dbffb9a8a3905d43.png)'
- en: '**Machine learning architecture without MLOps** - Image by Author'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**没有 MLOps 的机器学习架构** - 作者提供的图片'
- en: Here we have a pretty standard data science setup. The data scientists have
    been given access to the AWS account within the sage maker studio in which they
    can use Jupytor notebook to develop their models. They start by pulling data from
    various data sources, such as S3 or athena, and then use different machine-learning
    techniques to create a model. Then the model is stored in S3 as a model artifact
    and deployed as a sage maker endpoint. The endpoint is available to the world
    through an API gateway.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个相当标准的数据科学设置。数据科学家可以访问 AWS 账户中的 SageMaker Studio，他们可以使用 Jupyter Notebook
    来开发模型。他们从各种数据源，如 S3 或 Athena，拉取数据，然后使用不同的机器学习技术创建模型。然后模型作为模型工件存储在 S3 中，并部署为 SageMaker
    终端节点。通过 API 网关，终端节点对外界开放。
- en: '**Challenges of machine learning project without MLOps**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**没有 MLOps 的机器学习项目挑战**'
- en: 'While this looks good for doing proof of concept, this setup has the following
    challenges:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这种设置适合做概念验证，但它面临以下挑战：
- en: '**Changes rely on manual labour:** Any changes in the machine learning model
    require manual changes by the data scientists. It might involve re-running the
    Jupyter notebook cells or updating the sage maker endpoint with the latest version
    of the model. It becomes cumbersome and difficult to scale if the code extends
    over multiple Jupyter notebooks.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**变更依赖人工劳动：** 机器学习模型的任何更改都需要数据科学家进行人工修改。这可能涉及重新运行 Jupyter notebook 单元格或使用最新版本的模型更新
    SageMaker 端点。如果代码扩展到多个 Jupyter notebooks，变更变得繁琐且难以扩展。'
- en: '**No versioning of the code:** The code that the data scientists produce sits
    in the Jupyter notebooks. These notebooks are difficult to version and automate.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**没有代码版本控制：** 数据科学家产生的代码存在于 Jupyter notebooks 中。这些笔记本难以进行版本控制和自动化。'
- en: '**No feedback loop:** There is no automatic feedback loop in the process. If
    the quality of the model deteriorates, you will only find out through complaints
    from disgruntled customers.'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**没有反馈循环：** 过程中的自动反馈循环不存在。如果模型质量恶化，你只会通过不满客户的投诉才会发现。'
- en: These are some of the challenges which can be avoided by using MLOps.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是使用 MLOps 可以避免的一些挑战。
- en: MLOps architecture for small teams(1–3 data scientists)
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 小团队（1–3 名数据科学家）的 MLOps 架构
- en: MLOps can be complicated, and you don’t have to adopt all the features immediately.
    You can start with a minimal MLOps setup and gradually adopt more as your team
    grows or matures.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps 可能会很复杂，你不必立即采用所有功能。你可以从最小的 MLOps 设置开始，并随着团队的增长或成熟逐步采用更多功能。
- en: Let’s take the same machine learning setup explained above and introduce elements
    of MLOps in it. The architecture diagram described below is suitable for a small
    company or a team of 1–3 data scientists
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以上述相同的机器学习设置为例，并在其中引入 MLOps 元素。下图所述的架构图适用于小公司或 1–3 人的数据科学团队。
- en: '![](../Images/dc548873abe517513fb6c73f5f6cedf7.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc548873abe517513fb6c73f5f6cedf7.png)'
- en: '**MLOps architecture for small teams** - Image by Author'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**小团队的 MLOps 架构** - 图片来源于作者'
- en: In this architecture
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在此架构中
- en: Data scientists start with the sage maker notebook instance and perform the
    version control of the code, using code commit or any git-based code repository,
    and the environment for training machine learning model using docker containers,
    stored in elastic container registry(ECR). By versioning the code, environment
    and model artifacts, you improve the ability to reproduce the model and encourage
    collaboration among the team.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据科学家从 SageMaker notebook 实例开始，使用代码提交或任何基于 git 的代码库进行代码的版本控制，并使用 docker 容器在
    elastic container registry（ECR）中存储训练机器学习模型的环境。通过对代码、环境和模型工件进行版本控制，你可以提高模型的重现能力，并鼓励团队之间的合作。
- en: You can use step functions or any other workflow tool, such as Airflow or sage
    maker pipelines, to automate the re-training of the model. The re-train pipeline
    built by the data scientists will use version code and environment to perform
    data pre-processing, model training, and model verification and save model artifacts
    in S3\. The pipeline can utilize various services, such as glue jobs, EMR jobs,
    and lambda, to complete its flow and can be automated using scheduled-based event
    rules inside the event bridge.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用步骤函数或其他工作流工具，如 Airflow 或 SageMaker 管道，来自动化模型的再训练。数据科学家构建的再训练管道将使用版本代码和环境进行数据预处理、模型训练和模型验证，并将模型工件保存在
    S3 中。管道可以利用各种服务，如 glue jobs、EMR jobs 和 lambda，来完成其流程，并可以使用基于时间的事件规则在事件桥中进行自动化。
- en: The model and its versioning are further managed through the model registry
    service like the sage maker model registry. The sage maker model registry stores
    the model and its metadata, such as hyperparameters, evaluation metrics, and bias
    & explainability reports, and allows one to view, compare, and approve or reject
    the model. The actual model artifacts are stored in the S3, and the model registry
    service sits at the top as an additional layer.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型及其版本管理通过模型注册服务（如 SageMaker 模型注册表）进一步管理。SageMaker 模型注册表存储模型及其元数据，如超参数、评估指标以及偏差和解释性报告，并允许查看、比较和批准或拒绝模型。实际的模型工件存储在
    S3 中，模型注册服务作为附加层位于顶部。
- en: Finally, the deployment of the model is automated using the lambda function,
    which is triggered as soon as the model is approved in the sage maker model registry.
    The lambda will fetch the approved model from S3 and update the version in the
    sage maker endpoints without downtime. These sage maker endpoints are connected
    to lambda and API gateway to serve the consumer application and have an auto-scaling
    group attached to handle an unexpected spike in requests. You can further improve
    the deployment process by using canary deployment. It means a small number of
    user requests will be diverted to the new model first, and any error will trigger
    a cloud watch alarm to inform the data scientists. Over time, the number of requests
    sent to the new model will increase until the new model gets 100% of the traffic.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，模型的部署通过 Lambda 函数自动化，该函数在模型在 Sage Maker 模型注册表中获得批准后立即触发。Lambda 会从 S3 中提取批准的模型，并在
    Sage Maker 端点中更新版本而不发生停机。这些 Sage Maker 端点连接到 Lambda 和 API Gateway 以服务消费者应用程序，并附加有自动扩展组以应对请求的意外激增。你可以通过使用
    Canary 部署进一步改进部署过程。这意味着少量用户请求将首先转发到新模型，任何错误将触发 Cloud Watch 警报以通知数据科学家。随着时间的推移，发送到新模型的请求数量将增加，直到新模型获得
    100% 的流量。
- en: This architecture versions the code & model and automates the re-training and
    deployment. It provides scalability of the auto-scaling of the sage maker endpoints
    and flexibility of the canary deployments. However, when the data scientists team
    grows, we can introduce a few more elements of MLOps.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这种架构对代码和模型进行版本管理，并自动化重新训练和部署。它提供了 Sage Maker 端点的自动扩展性和 Canary 部署的灵活性。然而，当数据科学家团队扩大时，我们可以引入更多
    MLOps 元素。
- en: MLOps architecture for medium and large teams
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 中型和大型团队的 MLOps 架构
- en: This MLOps extends the small MLOps architecture, and expands into multi-account
    setup with emphasis on the quality check of the model running in the production.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这种 MLOps 扩展了小型 MLOps 架构，并扩展到多账户设置，强调生产中模型的质量检查。
- en: '![](../Images/6988a2334b825dac692707a8af2bcc9e.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6988a2334b825dac692707a8af2bcc9e.png)'
- en: '**MLOps architecture for medium and large teams** — Image by Author'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**中型和大型团队的 MLOps 架构** — 作者图像'
- en: 'In this architecture:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在此架构中：
- en: Data scientists adopt a multi-account approach in which they develop the model
    in the development account.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据科学家采用多账户方法，在开发账户中开发模型。
- en: As in a small MLOps setup, data scientists start with the sage maker notebook
    and perform versioning of the code with code commit and versioning of the environment
    with ECR. Then they create a re-training pipeline using a step function, which
    has steps for model training, verification and artefact saving in S3\. The versioning
    of the model is done by the sage maker model registry, which allows the user to
    accept or reject the model.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在小型 MLOps 设置中，数据科学家从 Sage Maker Notebook 开始，使用 Code Commit 对代码进行版本管理，并通过 ECR
    对环境进行版本管理。然后，他们使用 Step Function 创建一个重新训练的流水线，该流水线包括模型训练、验证和在 S3 中保存工件的步骤。模型的版本管理由
    Sage Maker 模型注册表完成，该注册表允许用户接受或拒绝模型。
- en: The deployment steps of the model include sage maker endpoints and autoscaling
    groups, which are connected to lambda and API gateway to allow users to submit
    inference requests. However, these component services sit in different AWS accounts.
    A multi-account strategy is recommended because it provides a way to separate
    business units, easily define restrictions for production loads and provide a
    fine-grained view of the cost incurred by each component of the architecture.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型的部署步骤包括 Sage Maker 端点和自动扩展组，这些端点和组连接到 Lambda 和 API Gateway 以允许用户提交推断请求。然而，这些组件服务位于不同的
    AWS 账户中。推荐使用多账户策略，因为它提供了一种分离业务单元、轻松定义生产负载限制并提供每个架构组件成本细化视图的方式。
- en: The multiple-account strategy involves setting up a staging account alongside
    the production account. A new model is first deployed to the staging account,
    tested and then deployed to the production account. This deployment must happen
    automatically via the code pipeline in the development account. The code pipeline
    is automatically triggered by the event generated when a model version is approved
    in the model registry.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 多账户策略包括在生产账户旁边设置一个暂存账户。新的模型首先部署到暂存账户，进行测试，然后部署到生产账户。此部署必须通过开发账户中的代码流水线自动进行。代码流水线由模型版本在模型注册表中获得批准时生成的事件自动触发。
- en: It is imperative to monitor changes in the behaviour or accuracy of the models
    running in production. We have enabled data capture on the endpoints of the staging
    and production accounts. It captures the incoming requests and outgoing inference
    results in S3 buckets. This captured data usually needs to be combined with labels
    or other data on the development account, so we have used S3 replication to move
    the data onto an S3 bucket in the development account. Now to tell whether the
    behaviour of the model or data has changed, we need something to compare against.
    This is where the model baseline comes in. During the training process we can
    generate a baseline dataset which records the expected behaviour of the data and
    the model. We can use the sage maker model monitor to compare the two datasets
    and generate the report.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 监控生产环境中模型行为或准确性的变化是至关重要的。我们已在预发布和生产账户的端点启用了数据捕获功能。它将传入的请求和传出的推断结果捕获到S3桶中。这些捕获的数据通常需要与开发账户上的标签或其他数据结合，因此我们使用S3复制将数据转移到开发账户中的S3桶里。现在，为了判断模型或数据的行为是否发生了变化，我们需要一些对比的基准。这时，模型基线就发挥作用了。在训练过程中，我们可以生成一个基线数据集，记录数据和模型的预期行为。我们可以使用SageMaker模型监控器来比较这两个数据集并生成报告。
- en: The final step in this architecture is to take action based on the model report.
    When a significant change is detected, we can send an event to trigger the re-training
    of the pipeline.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个架构的最终步骤是根据模型报告采取行动。当检测到显著变化时，我们可以发送事件以触发管道的重新训练。
- en: Departing Thoughts
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 离开的思考
- en: MLOps is a journey. You don’t have to immediately use all of the features from
    the complicated architectural design. You can start with basic steps to integrate
    with versioning and automation. Explore all the features that I have presented
    above and categorise them according to the needs of your business and then start
    adopting them when they are needed. The architecture designs described above are
    not the only way to implement MLOps, but I hope they will provide some inspiration
    to you as an architect.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps是一个旅程。你不必立即使用复杂架构设计中的所有功能。你可以从基本步骤开始，集成版本控制和自动化。探索我上述介绍的所有功能，并根据你的业务需求对它们进行分类，然后在需要时开始采用这些功能。上述架构设计并不是实现MLOps的唯一方法，但我希望它们能为你作为架构师提供一些灵感。
- en: If you found my article helpful, please leave me a comment.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你觉得我的文章对你有帮助，请给我留言。
