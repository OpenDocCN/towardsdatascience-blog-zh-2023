- en: Exploring a greedy solution to the stock cutting problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-bad-is-being-greedy-cdec75ce52a6](https://towardsdatascience.com/how-bad-is-being-greedy-cdec75ce52a6)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Creating a quick estimation to the stock cutting solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@jarom.hulet?source=post_page-----cdec75ce52a6--------------------------------)[![Jarom
    Hulet](../Images/0fdeb1a2df90cccdd8f2f4b84d5e54eb.png)](https://medium.com/@jarom.hulet?source=post_page-----cdec75ce52a6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cdec75ce52a6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cdec75ce52a6--------------------------------)
    [Jarom Hulet](https://medium.com/@jarom.hulet?source=post_page-----cdec75ce52a6--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cdec75ce52a6--------------------------------)
    ·7 min read·Aug 3, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Contents
  prefs: []
  type: TYPE_NORMAL
- en: Motivation of the stock cutting problem
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Quick overview of NP-Hard problems
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Encoding the stock cutting problem into Python
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The greedy algorithm
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Comparison to exhaustive search in low n-space
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Comparison to random search in higher n-space
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Motivation of the stock cutting problem**'
  prefs: []
  type: TYPE_NORMAL
- en: I’m a data scientist by trade. While my data science skills are very important
    at work (by definition), I find that data science concepts help solve a lot of
    problems outside of work too!
  prefs: []
  type: TYPE_NORMAL
- en: One of the ways that my DS skills come in handy is in my hobby as a DIYer/maker.
    A common challenge is knowing how to plan for cutting material. I have a list
    of cuts I need to make from multiple pieces of same-sized material from the store.
    How does one plan the cuts in a way to waste as little as possible? This challenge
    is known as the ‘Stock Cutting Problem.’ As it turns out, this can be a really
    hard problem to solve, NP-Hard in fact!
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I’ll explore a ‘short-cut’ (pun intended) to solving this problem
    and analyze how this method compares to the long way.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/caa0f14bb735ef86d7b0cb579cd80b61.png)'
  prefs: []
  type: TYPE_IMG
- en: White oak top, steel base table I made last year — image by author
  prefs: []
  type: TYPE_NORMAL
- en: '**Quick overview of NP-Hard problems**'
  prefs: []
  type: TYPE_NORMAL
- en: I’m not going to go into very much depth about NP-Hard problems here, but I
    do want to give some intuition on it. What makes an optimization problem hard
    is typically the size of its solution space. Meaning how many possible solutions
    do you need to explore to find the best one? The difficulty of a problem is usually
    assessed by how fast the solution space grows as the problem size grows.
  prefs: []
  type: TYPE_NORMAL
- en: For the ‘Stock Cutting Problem,’ the problem gets bigger, *much bigger* as you
    add more cuts. See how fast the solution space grows below!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c73fc6e412c472b7510e0fa48856af55.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: The solution space grows factorially, meaning that the total number of solutions
    that must be searched to be sure of the optimal answer is n!, which as you see,
    gets big really, really fast.
  prefs: []
  type: TYPE_NORMAL
- en: NP stands for ‘non-deterministic polynomial,’ which means that the problem grows
    faster than any polynomial function. There are tons of resources that dive deeper
    into the NP/NP-hard problems. This is all I will discuss here.
  prefs: []
  type: TYPE_NORMAL
- en: '**Encoding the stock cutting problem into Python**'
  prefs: []
  type: TYPE_NORMAL
- en: The stock cutting problem essentially boils down to an ordering problem. You
    make the cuts in a specific order, and when you run out of length on a piece of
    stock, you start cutting (still in order) on the next piece of stock.
  prefs: []
  type: TYPE_NORMAL
- en: 'A visualization explains this best. Let’s say we have this order of cuts :
    [4'', 2'', 1'', 2'', 2'', 1''], and we have stock sizes of 5''. The waste calculation
    looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4342c4196943f2f7eb7bda65abdfbcfd.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Here we have a total waste of 4'.
  prefs: []
  type: TYPE_NORMAL
- en: 'But, if we change the order (keeping all of the same cuts), we can get different
    levels of waste. Let’s try [4'', 1'', 2'', 2'', 1'', 2'']:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2628df3b9d055812d911a170c04f4c32.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Here, we only get 3' of waste — simply changing the order reduced our waste!
    This is the whole idea of this optimization problem. We want to find which order
    of the cuts is best.
  prefs: []
  type: TYPE_NORMAL
- en: Now, to encode this into a Python script, we need (1) functions to calculate
    the waste of each order, and (2) an algorithm to sort lists into optimal orders.
  prefs: []
  type: TYPE_NORMAL
- en: 'The function to calculate waste just replicates the logic outlined above. Here
    is the Python code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We’ll cover the algorithm we need in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: '**The greedy algorithm**'
  prefs: []
  type: TYPE_NORMAL
- en: The greedy algorithm is extremely simple, just find the biggest piece that fits
    on what is left of the current stock you are working on.
  prefs: []
  type: TYPE_NORMAL
- en: Using the previous example, we’ll say we want to make these cuts [4', 2', 1',
    2', 2', 1'] and we need a greedy algorithm to optimize the order.
  prefs: []
  type: TYPE_NORMAL
- en: We first start with the longest cut that fits on our current piece of stock.
    Since we haven’t made any cuts, our current stock piece is 5'. 4' is the longest
    cut we have and it fits on a 5' of remaining stock. The next longest cut is 2',
    since we only have 1' of stock left, it is too long. We go to the next longest
    cut, which is 1'. This fits in the remaining stock, so our next cut is 1'. The
    algorithm follows this pattern until there are no more cuts left.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is what that algorithm looks like in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**Comparison to exhaustive search in low n-space**'
  prefs: []
  type: TYPE_NORMAL
- en: We are saving ourselves a ton of time by using an approximation of the optimal
    solution via the greedy algorithm, but how good is that approximation? An exhaustive
    search of the solution space gives the global optimal solution — which is our
    gold standard. Let’s compare the greedy algorithm’s solution to the global optimal
    solutions for scenarios with just a few cuts (remember that to find the global
    optimal with a lot of cuts is really hard).
  prefs: []
  type: TYPE_NORMAL
- en: 'I randomly created 250 cut lists for cut sizes ranging from 2–10 cuts. Each
    cut was between 0 and 1 and the stock size was set to 1.1\. Below is the performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4a00607ae60097207fccb13665eafacd.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, as ’n’ increases, the greedy performance gets worse relative
    to global optimum, but stays relatively close and highly correlated.
  prefs: []
  type: TYPE_NORMAL
- en: '**Comparison to random search in higher n-space**'
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, we have a major blind spot… That is, we don’t know the global
    optimum in higher n-space. Now, we get into the business of comparing different
    types of heuristics (algorithms designed to approximate global optimums). How
    does the greedy algorithm hold up against a random search of the solution space?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/afa9178a5b22b28e3fe9bbc59de50f81.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: We can see that, as the number of cuts gets larger, the random search gets much
    worse. This makes sense because the random search is randomly selecting 500 solutions
    and picking the best one — as the solution space explodes, the probability percentage
    of the solution space we randomly search gets smaller and smaller. We now can
    see that the greedy solution is much better than just randomly looking at potential
    solutions.
  prefs: []
  type: TYPE_NORMAL
- en: '**Conclusions**'
  prefs: []
  type: TYPE_NORMAL
- en: It seems that the greedy solution to the stock cutting problem is a reasonable,
    very fast way to find a pretty good solution. For my purposes, this is sufficient.
    I only do a few projects a year and they are typically small. However, for applications
    such as manufacturing plants, more complicated and intensive approaches will likely
    have a significant dollar impact to the company. You can look into ‘mixed integer
    linear programming’ (MILP) which is another way of searching for better optimal
    solutions.
  prefs: []
  type: TYPE_NORMAL
- en: If I were to go more into depth on this problem, I would compare the greedy
    approach to better meta heuristic algorithms (random search is probably the worst
    one ) such as various versions of hill-climb, tabu search or simulated annealing.
    For now I’ll leave it here however, I have another table to make!
  prefs: []
  type: TYPE_NORMAL
- en: For all of the code used in this article, see this [repo](https://github.com/jaromhulet/stock_cutting.git).
  prefs: []
  type: TYPE_NORMAL
