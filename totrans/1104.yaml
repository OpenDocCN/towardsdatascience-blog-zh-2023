- en: How to Auto-Generate a Summary from Long Youtube Videos Using AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/how-to-auto-generate-a-summary-from-long-youtube-videos-using-ai-a2a542b6698d](https://towardsdatascience.com/how-to-auto-generate-a-summary-from-long-youtube-videos-using-ai-a2a542b6698d)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A step-by-step guide to resume a talk by Stephen Wolfram using Whisper and BART
    models on your local PC
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)[![Ana
    Bildea, PhD](../Images/60567c2b09bd0be5b25e508905dfe4c6.png)](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a2a542b6698d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a2a542b6698d--------------------------------)
    [Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a2a542b6698d--------------------------------)
    ¬∑7 min read¬∑Apr 14, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/73936710bcb5eeef18ac5b7cbe3fa600.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by the author
  prefs: []
  type: TYPE_NORMAL
- en: Motivation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In today‚Äôs rapidly changing world, staying informed and inspired can be challenging,
    especially when time is short. Personally, I am a huge fan of YouTube podcasts
    and talks. The podcasts and the talks are goldmines of knowledge, fully packed
    with insights from the brightest minds across various fields. However, due to
    time constraints, it‚Äôs not possible for me to watch every interesting video since
    they typically exceed one hour in length. This led me to wonder: what if I could
    create an end-to-end solution to extract automatically the main highlights? As
    a result, I started exploring AI-generative solutions to help me get auto summaries
    of some of the podcasts/talks I missed.'
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I discuss the end-to-end solution on a local PC. First, I will
    cover the transcription process of one of [Stephen Wolfram's talks about ChatGPT,
    AI, and AGI](https://www.youtube.com/watch?v=szxiPMyuMGY) available on Youtube*,*
    using the open-source [Whisper Model](https://huggingface.co/openai/whisper-medium)
    available on [HuggingFace Hub](https://huggingface.co/). Then, I will demonstrate
    how to summarize long text using the open-source [BART](https://arxiv.org/abs/1910.13461)
    model.
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs see how to achieve this.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind, it is crucial to verify that the copyright/licence permits downloading
    the content before you proceed with the download.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A bit of context
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[**Whisper**](https://cdn.openai.com/papers/whisper.pdf)is an open-source automatic
    speech recognition model, trained on 680,000 hours of multilingual data gathered
    from the internet. It relies on an end-to-end encoder-decoder [Transformer](https://arxiv.org/abs/1706.03762)
    architecture.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[**BART**](https://arxiv.org/abs/1910.13461) is a transformer-based seq2seq
    model that combines a bidirectional (BERT-style) encoder with an autoregressive
    (GPT-style) decoder. It‚Äôs pre-trained by randomly adding noise and learning to
    rebuild the original content.It performs well on tacks such as summmarization
    and translation.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[**HuggingFace transformers**](https://huggingface.co/docs/transformers/index)
    library provides a user-friendly solution to use and customize models. Additionally,
    it comes with APIs you can use to fine-tune the models to better fit your data.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[**PyTube**](https://github.com/pytube/pytube) is a depenency-free Python library
    for downloading and streaming YouTube videos.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[**NLTK**](https://www.nltk.org/)is a Natural Language Toolkit standard Python
    library widely used for natural language processing(NLP) tasks.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The end-to-end process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The process contains four main steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Set up the environment
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '2\. Download the YouTube video : PyTube'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '3\. Transcribe the audio: Whisper'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '4\. Summarize the generated text: BART'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/89c729e6ad301d77e5fd22684596eeaa.png)'
  prefs: []
  type: TYPE_IMG
- en: image by the author
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Set up the environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'My environment setup looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Jupyter Notebook** running in a virtual environment with Python 3.10'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Models***:* [OpenAI Whisper](https://github.com/openai/whisper), [BART](https://huggingface.co/facebook/bart-large-cnn)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Libraries**: [pytube](https://pypi.org/project/pytube/), [transformers](https://huggingface.co/docs/transformers/index),
    [unstructured](https://pypi.org/project/unstructured/), ffmpeg-python'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1.1 Install the libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Several remarks:'
  prefs: []
  type: TYPE_NORMAL
- en: '**üëâ** Ô∏èPlease be aware that you need `!` only if you install the libraries
    from a notebook cell.'
  prefs: []
  type: TYPE_NORMAL
- en: '**üëâ** Install the latest update of the Whisper model directly from GitHub.'
  prefs: []
  type: TYPE_NORMAL
- en: '**üëâ Troubleshoot PyTube.** In case you run into the following error `"pytube:
    AttributeError: ‚ÄòNoneType‚Äô object has no attribute ‚Äòspan‚Äô cipher.p"` y go to `{home}/.local/lib/{your_pythonversion:
    ex. python3.10}/site-packages/pytube/cipher.py Line 411` and replace the value
    of the`transform_plan_raw` variable as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 1.2 Import the libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 1\. Download the YouTube video
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let‚Äôs get the summary of the following talk ‚Äú[*ChatGPT, AI, and AGI with Stephen
    Wolfram*](https://www.youtube.com/watch?v=szxiPMyuMGY) *(*Founder & CEO of Wolfram
    Research*)*‚Äù *available* on YouTube ([Creative Commons Attribution license (reuse
    allowed)](https://www.youtube.com/t/creative_commons)).
  prefs: []
  type: TYPE_NORMAL
- en: To download locally the video as an audio file we use the YouTube class of the
    PyTube library. Make sure to provide a valid URL.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Transcribe the audio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once we have downloaded the audio locally, we should see a file called `demo.mp3`.
    To transcribe the audio, we load the `medium Whisper multilingual model`, which
    has 769 million parameters and is available in either English or a multilingual
    format. You can review the list of [language models available](https://github.com/openai/whisper#available-models-and-languages)
    and choose the more convenient one for your setup. For more accuracy, you can
    use `the large Whisper multilingual model`.
  prefs: []
  type: TYPE_NORMAL
- en: The resulting concatenated string will be stored in the `result[‚Äòtext‚Äô]` variable,
    which is saved locally in `demo.txt` file.
  prefs: []
  type: TYPE_NORMAL
- en: ‚ùóÔ∏è It‚Äôs important to note that the transcription process may take over an hour,
    depending on your PC‚Äôs configuration. To test the demo, you may choose a shorter
    video.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Summarize the generated text
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Because of the model‚Äôs incapacity to handle multiple tokens at once, it‚Äôs important
    to split the text into smaller segments, each containing a maximum of 4000 tokens.
    To do this, we can use the `punkt` pre-trained sentence tokenizer model, which
    is part of the Natural Language Toolkit (NLTK) library and is effective in processing
    natural language. Once we‚Äôve divided the text into smaller sentence chunks, we
    can store them in the `text_chunks` variable for further use.
  prefs: []
  type: TYPE_NORMAL
- en: We use sentence tokenization to prevent any loss of information
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Divide the large text into chunks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here‚Äôs the code that can be used to do the work.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code consists of two functions: `read_file()` that reads the `demo.txt`
    file and `split_text_into_chunks()` that splits the text into chunks.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Text Summarization with BART
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To summarize the text we use the `HuggingFace Transformers`library and the pre-trained
    multilingual BART-large model, `[facebook/bart-large-cnn](https://huggingface.co/facebook/bart-large-cnn)`
    fine-tuned on the CNN Daily Mail dataset. The Transformers library by Hugging
    Face offers many ready-to-use models for various tasks like text, images, or sounds.
    For instance, it provides an easy-to-use text summarization pipeline for the BART
    model:`pipeline("summarization", model="facebook/bart-large-cnn").` This makes
    it easy and user-friendly.
  prefs: []
  type: TYPE_NORMAL
- en: The code for performing the summarization is provided below.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, the code creates an instance of the BART summarizer, generates a summary
    for the given text chunks, and saves it to`summary_demo.txt` file only if the
    summary is successfully generated. If the summary has more than 5000 characters
    we will proceed by applying once gain the Bart summarizer. The output is saved
    in the `short_summary_demo.txt` file.
  prefs: []
  type: TYPE_NORMAL
- en: '**Here is the summary:**'
  prefs: []
  type: TYPE_NORMAL
- en: The Wolfram language could be the basis for a more systematic exploration of
    the nature and the depths of large language models. It‚Äôs a precise computational
    language, but it talks about the real world. There‚Äôs not a lot of boilerplate
    in LLM. Chat GPT is showing us, I think, an important piece of science. We‚Äôve
    automated out the boilerplate. My guess is that increasingly as people use it
    for real, they‚Äôll just edit the code. And it will have done a large part of the
    work in making the initial five lines of code. There are more regularities to
    describe meaning. It‚Äôs really a question of where the boundaries are between what
    the LLM can produce, what we can catch with our natural language understanding
    system. We‚Äôve had billions of years to evolve, to deal with the way that nature
    is. Microsoft Research published a 154-page analysis of GPT-4 where they conclude,
    and it is in the title of their paper, they are seeing glimpses of AGI. The computational
    universe of possible things you can do is very big. We humans care about only
    a small fraction of that. The question is to connect those things that are out
    in the computational universe with things that we humans are interested in. In
    1900, people would not have been surprised to think that space would be discrete.
    One of the things that I‚Äôm sort of hoping for in the not too distant future is
    we‚Äôll actually find a phenomenon that is kind of like the Brownian motion of space
    and where we‚Äôll be able to see, we can tell that it‚Äôs discrete.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Key takeaways
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The tutorial is part of a personal side project focused on exploring generative
    AI tools.
  prefs: []
  type: TYPE_NORMAL
- en: To conclude, the Whisper model gave excellent results on all tested videos.
    Although it occasionally misidentified product or person names, I am quite happy
    with the outcome and will definitely keep using it.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the BART model offers a trustworthy open-source option for
    summarization. Its summaries are quite effective. I compared it to the [T5 model
    from Google Research](https://huggingface.co/docs/transformers/model_doc/t5) and
    BART‚Äôs summaries were superior. Indeed, it may not always capture all the key
    facts, but it delivers good results, so I‚Äôll continue using it for my personal
    summary tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Overall AI-generative solutions like Whisper and BART help me efficiently extract
    important insights from long podcasts and talks. This way I can stay informed
    even when I am running out of spare time.
  prefs: []
  type: TYPE_NORMAL
- en: I hope that you enjoyed the article.
  prefs: []
  type: TYPE_NORMAL
- en: Thank you for reading!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Don‚Äôt forget to [subscribe](https://medium.com/subscribe/@anna.bildea) if you
    want to get my future stories in your inbox.
  prefs: []
  type: TYPE_NORMAL
- en: '*If you enjoy reading my story and want to support me as a writer, consider
    signing up to become a Medium member and gain access to thousands of Data Engineering
    and Data Science articles.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/@anna.bildea/membership?source=post_page-----a2a542b6698d--------------------------------)
    [## Join Medium with my referral link ‚Äî Bildea Ana'
  prefs: []
  type: TYPE_NORMAL
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every story‚Ä¶
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@anna.bildea/membership?source=post_page-----a2a542b6698d--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '*Find me on* [*LinkedIn*](https://www.linkedin.com/in/ana-bildea-phd-2339b728/)
    *and* [Twitter](https://twitter.com/AnaBildea)!'
  prefs: []
  type: TYPE_NORMAL
- en: See my collection of Generative AI, MLOps, and Responsible AI articles
  prefs: []
  type: TYPE_NORMAL
- en: '![Ana Bildea, PhD](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://medium.com/@anna.bildea/list/generative-ai-30d313b29b80?source=post_page-----a2a542b6698d--------------------------------)11
    stories![](../Images/df56a4e1a4785f73007a1ba8d1191b78.png)![](../Images/b6a7ab27a61a2cd49de8c07ee38f5999.png)![](../Images/8c3c51cf26b3db2c54205da85ad9fe2e.png)![Ana
    Bildea, PhD](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Responsible AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://medium.com/@anna.bildea/list/responsible-ai-10009e82f412?source=post_page-----a2a542b6698d--------------------------------)1
    story![](../Images/46a362cef2c3ddcc9e9a1134400f8a6d.png)![Ana Bildea, PhD](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: MLOps - AI in Production
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://medium.com/@anna.bildea/list/mlops-ai-in-production-04b6c81c50c8?source=post_page-----a2a542b6698d--------------------------------)4
    stories![](../Images/8fbedcb9f3f75894caff649172adece1.png)![](../Images/d5014b3b3843fc4b2172bef517cccaa4.png)![](../Images/2dba051abf51711268415c3f1e055a60.png)'
  prefs: []
  type: TYPE_NORMAL
