- en: How To Forecast Time-Series Using Autoregression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-forecast-time-series-using-autoregression-1d45db71683](https://towardsdatascience.com/how-to-forecast-time-series-using-autoregression-1d45db71683)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Tutorial on how to forecast using an autoregressive model in Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@egorhowell?source=post_page-----1d45db71683--------------------------------)[![Egor
    Howell](../Images/1f796e828f1625440467d01dcc3e40cd.png)](https://medium.com/@egorhowell?source=post_page-----1d45db71683--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1d45db71683--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1d45db71683--------------------------------)
    [Egor Howell](https://medium.com/@egorhowell?source=post_page-----1d45db71683--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1d45db71683--------------------------------)
    ·7 min read·Jan 17, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/081074115ceaa168aa8c4a20d048276e.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Aron Visuals](https://unsplash.com/@aronvisuals?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Background
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Forecasting is a wide domain with many models available to simulate your time
    series. In my previous posts, we covered some [basic forecasting models](https://medium.com/towards-data-science/basic-forecasting-techniques-ef4295248e46)
    and explored the popular family of [exponential smoothing models](https://medium.com/towards-data-science/forecasting-with-simple-exponential-smoothing-dd8f8470a14c).
  prefs: []
  type: TYPE_NORMAL
- en: In this post, we will start our journey into another family of forecasting models
    beginning with [autoregression](https://en.wikipedia.org/wiki/Autoregressive_model).
    We will go over the necessary theory and background needed to forecast with this
    model and then dive into a tutorial with Python.
  prefs: []
  type: TYPE_NORMAL
- en: Supplemental Video.
  prefs: []
  type: TYPE_NORMAL
- en: What Is Autoregression?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Autoregression is when you forecast a time series using some linear weighted
    combination of the previous values (lags) of that time series. As we are regressing
    a target value against itself, it is called *auto*-regression.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mathematically, we can write autoregression as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c89fcef7348c5e8fd54582102b3ddbaf.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation generated by author in LaTeX.
  prefs: []
  type: TYPE_NORMAL
- en: Where ***y*** is the time series we are forecasting at various time steps, ***ϕ***
    are the fitted coefficients of the lagsfor the time series, ***ε*** is the [error
    term](https://en.wikipedia.org/wiki/White_noise) (typically [**normally distributed**](https://en.wikipedia.org/wiki/Normal_distribution))
    and ***p*** is the number of lagged components included in the model, this is
    also known as the ***order.***
  prefs: []
  type: TYPE_NORMAL
- en: 'A few well known models pop out of this autoregression equation:'
  prefs: []
  type: TYPE_NORMAL
- en: If we have no coefficients or they are all zero, then this is just [***white
    noise***](https://en.wikipedia.org/wiki/White_noise)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we only have ***ϕ_1 = 1*** and the other coefficients are zero, then this
    is a [***random walk***](https://en.wikipedia.org/wiki/Random_walk).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Requirements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To build an autoregressive model, it is recommended to have a [***stationary***](https://en.wikipedia.org/wiki/Stationary_process)time
    series. Stationarity means the time series doesn’t exhibit any long term trend
    or obvious seasonality. The reason we need stationarity it to ensure the statistical
    properties of the time series is consistent through time, rendering it easier
    to model (explained in more detail later).
  prefs: []
  type: TYPE_NORMAL
- en: 'Stationarity can be achieved by stabilising the trend through [***differencing***](https://otexts.com/fpp2/stationarity.html)and
    stabilising the variance through a [***Logarithm or Box-Cox transform***](https://en.wikipedia.org/wiki/Power_transform).
    If you want to learn more about stationarity and these transformations, checkout
    my previous articles on these subjects below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/time-series-stationarity-simply-explained-125269968154?source=post_page-----1d45db71683--------------------------------)
    [## Time-Series Stationarity Simply Explained'
  prefs: []
  type: TYPE_NORMAL
- en: A simple and intuitive explanation for the need of stationarity in time-series
    modelling.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/time-series-stationarity-simply-explained-125269968154?source=post_page-----1d45db71683--------------------------------)
    [](/box-cox-transform-for-time-series-cc45f26082c6?source=post_page-----1d45db71683--------------------------------)
    [## Box-Cox Transform for Time Series
  prefs: []
  type: TYPE_NORMAL
- en: How to create a stationary time series using the Box-Cox transformation.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/box-cox-transform-for-time-series-cc45f26082c6?source=post_page-----1d45db71683--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: You can also do a statistical test for stationarity. The most popular one is
    the [***Augmented Dickey-Fuller***](https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test)
    ***(ADF)*** test, where the null hypothesis is that the data is **not** stationary.
  prefs: []
  type: TYPE_NORMAL
- en: Estimation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The need for stationarity becomes clearer when we are training the model. Stationary
    data has constant statistical properties such as mean and variance. Therefore,
    all the data points belong to the same statistical probability distribution that
    we can base our model on. Furthermore, the forecasts are treated as random variables
    and will belong to the same distribution as the training data (lags). It basically
    **guarantees the data in the future will be somewhat like the past.**
  prefs: []
  type: TYPE_NORMAL
- en: See this [statsexchange](https://stats.stackexchange.com/questions/19715/why-does-a-time-series-have-to-be-stationary)
    thread for multiple and thorough reasons for the stationarity requirement for
    autoregressive modelling.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As the stationary data belongs to some distribution (typically the normal distribution),
    we often estimate the coefficients and parameters of the autoregressive model
    using [***Maximum Likelihood Estimation (MLE)***](/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1).
    MLE deduces the optimal values of the parameters and coefficients that produce
    the highest probability of obtaining our time series data. The MLE for normally
    distributed data, is the same result as carrying [**ordinary least squares**](https://en.wikipedia.org/wiki/Ordinary_least_squares).
    Therefore, least squares is also frequently used.
  prefs: []
  type: TYPE_NORMAL
- en: Link [here](/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1)
    for a great and thorough explanation of MLE.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: There are also other methods of selecting the best parameters and coefficients
    such as [***Akaike’s Information Criterion (AIC)***](https://en.wikipedia.org/wiki/Akaike_information_criterion),[***Bayesian
    Information Criterion***](https://en.wikipedia.org/wiki/Bayesian_information_criterion)and[***Hannan–Quinn
    Information Criterion (HQIC)***](https://en.wikipedia.org/wiki/Hannan%E2%80%93Quinn_information_criterion).
  prefs: []
  type: TYPE_NORMAL
- en: Order Selection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before fitting and estimating the model, we need to know how many lags (the
    order), ***p***, to include. One way of doing this is through plotting the [**partial
    autocorrelation function (PACF)**](https://online.stat.psu.edu/stat510/lesson/2/2.2)of
    the time series. This measures how much certain lags **directly** correlate with
    each other. Hence, we can deduce which lags are most [***statistically significant***](https://en.wikipedia.org/wiki/Statistical_significance)
    and remove the ones that are not when constructing our model. We will go over
    how to carry out this process in the Python tutorial later in the article.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to learn more about the PACF, checkout my previous article on it
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/partial-autocorrelation-for-time-series-481a9cfa7526?source=post_page-----1d45db71683--------------------------------)
    [## Partial Autocorrelation for Time Series Analysis'
  prefs: []
  type: TYPE_NORMAL
- en: Describing what partial autocorrelation is and its importance in time series
    analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/partial-autocorrelation-for-time-series-481a9cfa7526?source=post_page-----1d45db71683--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: However, another more thorough technique is to simply iterate over all the possible
    combinations of lag components and choose the model with the best score on the
    AIC. This is analogous to regular hyperparameter tuning and definitely the more
    robust method, but is subject to computational constraints of course.
  prefs: []
  type: TYPE_NORMAL
- en: Python Walkthrough
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now go over a simple autoregressive modelling walkthrough in Python
    using the US airline passenger dataset!
  prefs: []
  type: TYPE_NORMAL
- en: Data [from Kaggle](https://www.kaggle.com/datasets/ashfakyeafi/air-passenger-data-for-time-series-analysis)
    with a CC0 licence.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s first plot our time series:'
  prefs: []
  type: TYPE_NORMAL
- en: GitHub Gist by author.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/87f5dd5f5d2da117e26234afff4d36d3.png)'
  prefs: []
  type: TYPE_IMG
- en: Plot generated by author in Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'The time series has a clear trend and obvious yearly seasonality that is increasing
    through time. Therefore, we need to make it stationary by carrying out differencing
    and applying the Box-Cox transform:'
  prefs: []
  type: TYPE_NORMAL
- en: GitHub Gist by author.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/292a8d8d14a569b5a44375d2d96cc7b4.png)'
  prefs: []
  type: TYPE_IMG
- en: Plot generated by author in Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'The time series now looks stationary, however we can confirm it in a more quantitive
    way using the ADF test we described earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: GitHub Gist by author.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9ec36c714586d235d65add659d6b8dab.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by author in Python.
  prefs: []
  type: TYPE_NORMAL
- en: The `P-Value` is below **5%**, so there is reason to reject the null hypothesis
    and we can say that the time series is satisfactory stationary. To make it even
    more stationary, we could have carried out second order differencing and seasonal
    differencing.
  prefs: []
  type: TYPE_NORMAL
- en: Modelling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We begin the modelling phase by plotting the PACF to see which lags are statistically
    significant:'
  prefs: []
  type: TYPE_NORMAL
- en: GitHub Gist by author.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e95c33edafdb5b80a2f102aa3498b711.png)'
  prefs: []
  type: TYPE_IMG
- en: Plot generated by author in Python.
  prefs: []
  type: TYPE_NORMAL
- en: The lags outside the blue shaded region are classed as significantly significant
    and should be included as the features for our autoregressive model. From the
    above plot, it seems lags 1, 2, 4, 7, 8, 9, 10, 11, 12 and 13 are significant.
    Notice how lag 12 has the largest peak. This is because our time series is indexed
    by month and has a yearly seasonality, hence lag 12 is an exact year difference.
  prefs: []
  type: TYPE_NORMAL
- en: However, for building our model we will use the recommended approach of simply
    iterating over all the possible combinations of lags and choose the best model
    from that analysis. As our dataset is quite small, this is easily computationally
    feasible.
  prefs: []
  type: TYPE_NORMAL
- en: GitHub Gist by author.
  prefs: []
  type: TYPE_NORMAL
- en: Here we use the statsmodels `ar_select_order` to determine the optimal number
    of lags to include in the autoregressive model. In this case, we have set our
    model to try combinations up to lag 15\. The model is then fit with the results
    from the `ar_select_order` using the `AutoReg` class from statsmodels.
  prefs: []
  type: TYPE_NORMAL
- en: Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The forecasts produced from this fitted model is for the differenced and Box-Cox
    transformed time series that we produced earlier. Therefore, we have to un-difference
    and apply the inverse Box-Cox transform to the predictions to acquire the actual
    airline passenger forecasted volumes:'
  prefs: []
  type: TYPE_NORMAL
- en: GitHub Gist by author.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8579774a2852090f5847f0f09575d159.png)'
  prefs: []
  type: TYPE_IMG
- en: Plot generated by author in Python.
  prefs: []
  type: TYPE_NORMAL
- en: '**The forecasts look great!**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Our autoregressive model forecasts have adequately captured the trend and seasonality
    in the time series. However, the seasonality was captured as a result of the model
    having an order (lags) of 13\. This means it includes all the lags in the past
    year (one for each month) to forecast, which leads it easily pick-up the seasonality
    due to how regular it is.
  prefs: []
  type: TYPE_NORMAL
- en: Summary and Further Thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this post, we have dived into the common forecasting model of autoregression.
    This is just like linear regression, but the features are just previous values
    of the target at various time steps. To use autoregression, your data must be
    stationary which means it needs to have a constant mean and variance. Forecasting
    with autoregression is very easy and can be done through the statsmodels Python
    package.
  prefs: []
  type: TYPE_NORMAL
- en: 'Full code used in this article can be found at my GitHub here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/egorhowell/Medium-Articles/blob/main/Time%20Series/ARIMA/autoregression.py?source=post_page-----1d45db71683--------------------------------)
    [## Medium-Articles/autoregression.py at main · egorhowell/Medium-Articles'
  prefs: []
  type: TYPE_NORMAL
- en: Code I use in my medium blog/articles. Contribute to egorhowell/Medium-Articles
    development by creating an account on…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/egorhowell/Medium-Articles/blob/main/Time%20Series/ARIMA/autoregression.py?source=post_page-----1d45db71683--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Another Thing!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I have a free newsletter, [**Dishing the Data**](https://dishingthedata.substack.com/),
    where I share weekly tips for becoming a better Data Scientist. There is no “fluff”
    or “clickbait,” just pure actionable insights from a practicing Data Scientist.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://newsletter.egorhowell.com/?source=post_page-----1d45db71683--------------------------------)
    [## Dishing The Data | Egor Howell | Substack'
  prefs: []
  type: TYPE_NORMAL
- en: How To Become A Better Data Scientist. Click to read Dishing The Data, by Egor
    Howell, a Substack publication with…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: newsletter.egorhowell.com](https://newsletter.egorhowell.com/?source=post_page-----1d45db71683--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Connect With Me!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[**YouTube**](https://www.youtube.com/@egorhowell)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**LinkedIn**](https://www.linkedin.com/in/egor-howell-092a721b3/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Twitter**](https://twitter.com/EgorHowell)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**GitHub**](https://github.com/egorhowell)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: References and Further Reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Forecasting: Principles and Practice:* [https://otexts.com/fpp2/](https://otexts.com/fpp3/accuracy.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
