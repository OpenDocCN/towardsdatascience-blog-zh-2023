- en: How to Measure and Improve the Diversity of Forecasting Ensembles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-measure-and-improve-the-diversity-of-forecasting-ensembles-2ec899014d6](https://towardsdatascience.com/how-to-measure-and-improve-the-diversity-of-forecasting-ensembles-2ec899014d6)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Using the Bias-Variance-Covariance decomposition to analyze forecasting ensembles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://vcerq.medium.com/?source=post_page-----2ec899014d6--------------------------------)[![Vitor
    Cerqueira](../Images/9e52f462c6bc20453d3ea273eb52114b.png)](https://vcerq.medium.com/?source=post_page-----2ec899014d6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2ec899014d6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2ec899014d6--------------------------------)
    [Vitor Cerqueira](https://vcerq.medium.com/?source=post_page-----2ec899014d6--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2ec899014d6--------------------------------)
    ·5 min read·Jan 31, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d94f4cf481cefb4c8be97700d5b30f16.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [henry perks](https://unsplash.com/@hjkp?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: In this article, you’ll learn about the bias-variance-covariance decomposition.
  prefs: []
  type: TYPE_NORMAL
- en: The error of a regression model can be analyzed with the bias-variance trade-off.
    For ensembles, this error can be further decomposed with a covariance term.
  prefs: []
  type: TYPE_NORMAL
- en: Here’s how you can use this decomposition to improve a forecasting ensemble.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Diversity among individual models is a key ingredient for building successful
    ensembles](https://medium.com/towards-data-science/introduction-to-forecasting-ensembles-f63877a2498).'
  prefs: []
  type: TYPE_NORMAL
- en: Each model should make accurate forecasts. But, these forecasts should also
    be different from other models. Thus, combined predictions reduce the impact of
    individual errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'This leads us to two questions:'
  prefs: []
  type: TYPE_NORMAL
- en: How do we measure ensemble diversity?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do we introduce diversity in an ensemble?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let’s dive into these questions.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring Diversity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The [bias-variance trade-off](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)
    is a standard way of analyzing regression models. Bias relates to the average
    distance between predictions and actual values. Variance relates to the variability
    of forecasts on different samples.
  prefs: []
  type: TYPE_NORMAL
- en: Low bias means high variance, and vice-versa. This trade-off is related to the
    complexity of models. Increasingly complex models tend to have a lower bias (but
    higher variance).
  prefs: []
  type: TYPE_NORMAL
- en: 'A forecasting ensemble is also a regression model. It can be decomposed into
    these two terms. But, it is better analyzed using a three-way decomposition: the
    bias-variance-covariance decomposition.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This decomposition is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9b3271c2f80ab92a67e2d8e7e3ba1b01.png)'
  prefs: []
  type: TYPE_IMG
- en: The terms in the equation above are the average **bias**, average **var**iance,
    and average **covar**iance of an ensemble with *M* models.
  prefs: []
  type: TYPE_NORMAL
- en: We already know what the bias and variance terms are. Besides these, the expected
    error of an ensemble depends on a covariance term. Covariance measures how a pair
    of models change together. Thus, it is a good way to quantify diversity. Larger
    values in covariance (i.e. lower diversity) lead to a larger expected error.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can think of this as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: expected error = average bias + average variance - diversity
  prefs: []
  type: TYPE_NORMAL
- en: So, ensemble diversity directly impacts its expected forecasting performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how you can code this decomposition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You can find more details about the bias-variance-covariance decomposition in
    reference [1].
  prefs: []
  type: TYPE_NORMAL
- en: Creating Diverse Ensembles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/824f30893b63861cbb7964846e43cce6.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Franki Chamaki](https://unsplash.com/@franki?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: The bias-variance-covariance decomposition shows the importance of encouraging
    diversity in ensembles. How can you do that?
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are three possible approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: Manipulating the training data;
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using different algorithms or configurations;
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pruning the ensemble.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Manipulating the training data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some of the most successful ensemble methods follow this approach. For example,
    bagging and boosting.
  prefs: []
  type: TYPE_NORMAL
- en: Bagging is an ensemble of decision trees. For each tree, the available data
    is resampled with a bootstrapping technique. So, you get different training sets
    for each tree, thereby introducing diversity. Random Forests also do bootstrapping,
    and more. They add randomness to the way explanatory variables are used. This
    further increases diversity among trees.
  prefs: []
  type: TYPE_NORMAL
- en: Boosting also changes the input data, but in a different way. One key aspect
    is that the models are trained sequentially. After each iteration, the training
    instances are re-weighted according to previous errors.
  prefs: []
  type: TYPE_NORMAL
- en: Using different algorithms or configurations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Varying the algorithm is a quick and easy way of improving ensemble diversity.
  prefs: []
  type: TYPE_NORMAL
- en: Different methods (say, a decision tree and linear regression) have different
    assumptions about the data. This leads to models that perform differently.
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble Pruning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another way of improving diversity is by [ensemble pruning](https://medium.com/towards-data-science/introduction-to-forecasting-ensembles-f63877a2498).
  prefs: []
  type: TYPE_NORMAL
- en: Pruning refers to the process of removing unwanted models from the ensemble.
    In this case, you would discard highly correlated models. This results not only
    in better diversity but also lower costs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Case Study: Decomposition of a Random Forest'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s use the bias-variance-covariance decomposition to analyze the error of
    a Random Forest.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we’ll use a time series about sunspots.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0670aaa0a6b51386eb1d61e2c54e2af4.png)'
  prefs: []
  type: TYPE_IMG
- en: Monthly sunspots time series [3]. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can train a Random Forest for forecasting as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s a sample of the forecasts:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e04aa6305a326853f8067dce489cd6d6.png)'
  prefs: []
  type: TYPE_IMG
- en: Sample of the forecasts of the trees of a Random Forest. The combined forecast
    is in bold navy blue. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how the error breaks into each term:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b85f13ae6d682aa170e78129f6df5e15.png)'
  prefs: []
  type: TYPE_IMG
- en: Bias, variance, and covariance terms (log scaled). Image by author
  prefs: []
  type: TYPE_NORMAL
- en: You can use this information to guide the development of an ensemble.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, most of the expected error is due to the covariance term. You
    can reduce it by improving the diversity of the ensemble. We explored three approaches
    to do this. For example, you could try to prune the ensemble by removing correlated
    trees.
  prefs: []
  type: TYPE_NORMAL
- en: Key Takeaways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The expected error of a forecasting ensemble can be decomposed into three parts:
    bias, variance, and covariance;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The covariance term measures the diversity in the ensemble;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This decomposition is valuable for guiding the development of an ensemble;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many ways of improving ensemble diversity. These include manipulating
    the training data, using different algorithms, or ensemble pruning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thanks for reading, and see you in the next story!
  prefs: []
  type: TYPE_NORMAL
- en: Related Articles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Introduction to Forecasting Ensembles](/introduction-to-forecasting-ensembles-f63877a2498)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Combine the Forecasts of an Ensemble](/how-to-combine-the-forecasts-of-an-ensemble-11022e5cac25)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Dynamic Forecast Combination using R from Python](https://medium.com/towards-data-science/dynamic-forecast-combination-using-r-from-python-afcdf6adf85b)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Brown, G., Wyatt, J., Harris, R., & Yao, X. (2005). Diversity creation
    methods: a survey and categorisation. *Information fusion*, *6*(1), 5–20.'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] Brown, Gavin, et al. “Managing diversity in regression ensembles.” *Journal
    of machine learning research* 6.9 (2005).'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] [Sunspots time series. GPL-3 License](https://www.rdocumentation.org/packages/datasets/versions/3.6.1/topics/sunspots)'
  prefs: []
  type: TYPE_NORMAL
