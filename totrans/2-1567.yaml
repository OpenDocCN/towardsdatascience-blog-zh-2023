- en: Natural Language Fundamentals — Intro & Language Model Implementation of Sentiment
    Analysis, Machine Translation and Named-Entity Recognition
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自然语言基础——情感分析、机器翻译和命名实体识别的介绍与语言模型实现
- en: 原文：[https://towardsdatascience.com/natural-language-fundamentals-intro-implementation-of-sentiment-analysis-machine-translation-c79662e52624](https://towardsdatascience.com/natural-language-fundamentals-intro-implementation-of-sentiment-analysis-machine-translation-c79662e52624)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/natural-language-fundamentals-intro-implementation-of-sentiment-analysis-machine-translation-c79662e52624](https://towardsdatascience.com/natural-language-fundamentals-intro-implementation-of-sentiment-analysis-machine-translation-c79662e52624)
- en: Multilingual language modeling in the Natural Language space
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自然语言领域的多语言建模
- en: '[](https://medium.com/@fmnobar?source=post_page-----c79662e52624--------------------------------)[![Farzad
    Mahmoodinobar](../Images/2d75209693b712300e6f0796bd2487d0.png)](https://medium.com/@fmnobar?source=post_page-----c79662e52624--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c79662e52624--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c79662e52624--------------------------------)
    [Farzad Mahmoodinobar](https://medium.com/@fmnobar?source=post_page-----c79662e52624--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@fmnobar?source=post_page-----c79662e52624--------------------------------)[![Farzad
    Mahmoodinobar](../Images/2d75209693b712300e6f0796bd2487d0.png)](https://medium.com/@fmnobar?source=post_page-----c79662e52624--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c79662e52624--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c79662e52624--------------------------------)
    [Farzad Mahmoodinobar](https://medium.com/@fmnobar?source=post_page-----c79662e52624--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c79662e52624--------------------------------)
    ·9 min read·Mar 20, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c79662e52624--------------------------------)
    ·阅读时间 9 分钟·2023 年 3 月 20 日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/93e4900e458bc59ccf6ab8f6b69ece8c.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/93e4900e458bc59ccf6ab8f6b69ece8c.png)'
- en: Photo by [RetroSupply](https://unsplash.com/@retrosupply) from [Unsplash](https://unsplash.com/photos/kZvmEpyfiJs)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [RetroSupply](https://unsplash.com/@retrosupply) 提供，来自 [Unsplash](https://unsplash.com/photos/kZvmEpyfiJs)
- en: We humans use words, sounds, gestures and symbols to convey complex concepts
    and abstracts to each other in different forms such as speech, writing and signs.
    With the advent of computers and in order to take advantage of these powerful
    machines, we had to come up with ways for computers to understand human communications
    and the existing corpus of knowledge. Hence, the Natural Language Processing (NLP),
    Understanding (NLU) and Generation (NLG) branches of Artificial Intelligence were
    born. Boundaries of these three areas are sometimes unclear and the overall Natural
    Language space encompasses various applications in today’s Computer and Data Science
    world. Probably the most common of such applications are (I) Sentiment Analysis,
    (II) Machine Translation and (III) Named-Entity Recognition (NER), which we will
    define and implement in this post.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们人类使用语言、声音、手势和符号，以不同的形式（如演讲、写作和标志）传达复杂的概念和抽象。随着计算机的出现，为了利用这些强大的机器，我们不得不想出让计算机理解人类交流和现有知识库的方法。因此，自然语言处理（NLP）、理解（NLU）和生成（NLG）这三个人工智能的分支应运而生。这三个领域的界限有时并不清晰，而整体自然语言空间涵盖了当今计算机和数据科学世界中的各种应用。最常见的应用包括（I）情感分析，（II）机器翻译和（III）命名实体识别（NER），我们将在本文中对这些应用进行定义和实现。
- en: '[](https://medium.com/@fmnobar/membership?source=post_page-----c79662e52624--------------------------------)
    [## Join Medium with my referral link'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@fmnobar/membership?source=post_page-----c79662e52624--------------------------------)
    [## 通过我的推荐链接加入 Medium'
- en: Read every story from Farzad (and other writers on Medium). Your membership
    fee directly supports Farzad and other…
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 阅读 Farzad（以及 Medium 上其他作者）的每一个故事。您的会员费用直接支持 Farzad 和其他人……
- en: medium.com](https://medium.com/@fmnobar/membership?source=post_page-----c79662e52624--------------------------------)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@fmnobar/membership?source=post_page-----c79662e52624--------------------------------)
- en: In order to implement these three tasks, we will leverage existing “Pre-Trained
    Language Models”. Therefore, let’s first understand what language modeling is.
    I do recommend glancing through the “Language Modeling” section but if you are
    mainly interested in the application and/or implementation, feel free to skip
    it.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这三项任务，我们将利用现有的“预训练语言模型”。因此，让我们首先了解什么是语言建模。我建议浏览一下“语言建模”部分，但如果你主要对应用和/或实现感兴趣，可以跳过这部分。
- en: Language Modeling
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语言建模
- en: 'Language modeling encompasses various methods that use statistics and probability,
    combined with machine learning architectures (such as and especially deep neural
    networks) to determine the likelihood of a sequence of words occurring in a string,
    such as a sentence. Based on the calculated probability, certain decisions can
    be made — for example, a model can generate a string/response to a user-provided
    prompt (such as ChatGPT), perform a text classification to determine whether a
    word in question is a noun, a verb, etc. Thanks to the large corpora of textual
    data available all around us these days, such language models are usually trained
    on vast amounts of textual data. Consequently, such models are also referred to
    as Large Language Models. At this point you may be wondering how this is relevant
    to our post — we are just getting there. These pre-trained language models then
    can be further trained (i.e. fine-tuned) to perform specific tasks, such as sentiment
    analysis, machine translation and named-entity recognition, which we will explore
    in further detail today. Going deeper into the architecture and training strategies
    of language models is beyond the intent of this post, but if you are interested
    in that topic, feel free to visit the post below:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 语言建模包括使用统计和概率的方法，结合机器学习架构（如特别是深度神经网络）来确定一串文字中词语序列出现的可能性，例如一个句子。基于计算出的概率，可以做出某些决策——例如，一个模型可以生成对用户提供的提示的字符串/响应（如ChatGPT），执行文本分类以确定某个词是否为名词、动词等。由于如今我们周围有大量的文本数据，这些语言模型通常在大量文本数据上进行训练。因此，这些模型也被称为大语言模型。此时你可能会想这与我们的帖子有何关联——我们正要到达这里。这些预训练的语言模型可以进一步训练（即微调）以执行特定任务，如情感分析、机器翻译和命名实体识别，我们今天将详细探讨这些任务。深入了解语言模型的架构和训练策略超出了本文的意图，但如果你对这一主题感兴趣，可以访问以下帖子：
- en: '[](https://medium.com/@fmnobar/intro-to-pre-trained-models-in-nlp-6bf7490a49fa?source=post_page-----c79662e52624--------------------------------)
    [## Pre-Trained Models in NLP'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 预训练模型在自然语言处理中的应用](https://medium.com/@fmnobar/intro-to-pre-trained-models-in-nlp-6bf7490a49fa?source=post_page-----c79662e52624--------------------------------)'
- en: Fundamentals of Pre-Trained Models and their down-stream tasks.
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预训练模型基础及其下游任务。
- en: medium.com](https://medium.com/@fmnobar/intro-to-pre-trained-models-in-nlp-6bf7490a49fa?source=post_page-----c79662e52624--------------------------------)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[medium.com](https://medium.com/@fmnobar/intro-to-pre-trained-models-in-nlp-6bf7490a49fa?source=post_page-----c79662e52624--------------------------------)'
- en: Now that we are familiar with what Natural Language space and Language Modeling
    are, let’s go to the fun part of using these models!
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们对自然语言领域和语言建模有所了解，接下来就进入使用这些模型的有趣部分吧！
- en: 1\. Sentiment Analysis
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1. 情感分析
- en: Task of identifying the sentiment of a piece of text, such as whether it is
    positive, negative, or neutral, is called Sentiment Analysis. It is used in applications
    such as social media monitoring, customer feedback analysis, and product review
    analysis. As you can imagine, this one is quite useful for a lot of companies.
    For example, a large online retail company would not be able to dedicate the human
    resources required to manually read all the comments about various products. Instead,
    they can run a Sentiment Analysis model on the reviews and analyze the results,
    saving time and money in the process. Next, let’s see how we can implement this.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 识别文本情感的任务，例如判断它是积极的、消极的还是中立的，称为情感分析。它被用于社交媒体监控、客户反馈分析和产品评论分析等应用中。可以想象，这对许多公司来说非常有用。例如，一家大型在线零售公司无法分配足够的人力资源来手动阅读关于各种产品的所有评论。相反，他们可以对评论运行情感分析模型，并分析结果，从而节省时间和成本。接下来，让我们看看如何实现这一点。
- en: 1.1\. Sentiment Analysis — Implementation
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1. 情感分析 — 实现
- en: 'In this example, we first load a pre-trained langugae model from the Transformers
    library. Then, we use the model to generate sentiment from the input sentence.
    Finally, we test it on two different sentences, one positive and one negative,
    to verify model’s performance. Below are the two sentences that we will be using:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们首先从Transformers库中加载一个预训练的语言模型。接着，我们使用模型从输入句子中生成情感分析。最后，我们在两个不同的句子上测试它，一个是积极的，另一个是消极的，以验证模型的性能。以下是我们将使用的两个句子：
- en: '`I loved this movie!`, which we expect to be classified as a “Positive” sentiment
    by the model'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`I loved this movie!`，我们期望模型将其分类为“积极”情感'
- en: '`I did not like this movie.`, which we expect to be classified as a “Negative”
    sentiment by the model'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`I did not like this movie.`，我们期望模型将其分类为“消极”情感'
- en: Let’s see how it works!
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它是如何工作的！
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Results:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/a7b2a502990181b233f5a8c4829fa741.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a7b2a502990181b233f5a8c4829fa741.png)'
- en: 'Results look pretty good and as we expected. If you are interested in a more
    in-depth look at Sentiment Analysis, the following post is for you:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 结果看起来非常好，如我们所期待的。如果你对情感分析有更深入的兴趣，以下帖子适合你：
- en: '[](/sentiment-analysis-intro-and-implementation-ddf648f79327?source=post_page-----c79662e52624--------------------------------)
    [## Sentiment Analysis — Intro and Implementation'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 情感分析——简介与实现](/sentiment-analysis-intro-and-implementation-ddf648f79327?source=post_page-----c79662e52624--------------------------------)'
- en: Sentiment Analysis using NLTK, scikit-learn and TextBlob
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用NLTK、scikit-learn和TextBlob进行情感分析
- en: towardsdatascience.com](/sentiment-analysis-intro-and-implementation-ddf648f79327?source=post_page-----c79662e52624--------------------------------)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/sentiment-analysis-intro-and-implementation-ddf648f79327?source=post_page-----c79662e52624--------------------------------)'
- en: Let’s talk about Machine Translation next.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们讨论机器翻译。
- en: 2\. Machine Translation
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2. 机器翻译
- en: Task of using computers to translate text from one language to another is called
    Machine Translation. The most well-known example for most users is Google Translate
    — what Google Translate does is called Machine Translation! Applications are plentiful.
    For example, one can read and understand information in other languages.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 使用计算机将文本从一种语言翻译到另一种语言的任务称为机器翻译。对大多数用户来说，最著名的例子是Google翻译——Google翻译所做的就是机器翻译！应用非常广泛。例如，人们可以阅读和理解其他语言的信息。
- en: 2.1\. Machine Translation — Implementation
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1. 机器翻译——实现
- en: 'To implement Machine Translation, we are going to use mBART-50, developed by
    [Facebook AI](https://arxiv.org/pdf/2008.00401.pdf), from the [Transformers](https://huggingface.co/docs/transformers/index)
    library, which is a pre-trained language model for Machine Translation. The steps
    are very similar to what we did in the Sentiment Analysis and are as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现机器翻译，我们将使用由[Facebook AI](https://arxiv.org/pdf/2008.00401.pdf)开发的mBART-50，它来自[Transformers](https://huggingface.co/docs/transformers/index)库，这是一个用于机器翻译的预训练语言模型。步骤与我们在情感分析中做的非常相似，具体如下：
- en: 'Install Transformers as follows: `pip install transformers`'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按如下方式安装Transformers：`pip install transformers`
- en: Import the library
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入库
- en: Load the pre-trained model
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载预训练模型
- en: Run example sentences through the model and return the results
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过模型运行示例句子并返回结果
- en: What is interesting about mBART-50 is that it is a multilingual Machine Translation
    model, meaning it can translate to and from different languages. Let’s test this
    capability in action, where we translate one sentence to 6 different languages,
    using one model!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: mBART-50的有趣之处在于它是一个多语言机器翻译模型，这意味着它可以进行不同语言之间的翻译。让我们测试一下这个功能，将一个句子翻译成6种不同的语言，使用一个模型！
- en: '**Pro Tip:** I emphasized the multilingual nature of this language model because
    historically, Neural Machine Translation models used to be able to translate only
    from one specific language to another specific language. For example, we would
    need to train one specific model for translation from English to French and train
    a separate model to translate from English to German. On the other hand, these
    multilingual machine translation models can translate from many languages to many
    languages using one single model, which is quite impressive!'
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**提示：** 我强调了这个语言模型的多语言特性，因为历史上，神经机器翻译模型只能从一种特定语言翻译到另一种特定语言。例如，我们需要为从英语到法语的翻译训练一个特定的模型，并为从英语到德语的翻译训练另一个模型。另一方面，这些多语言机器翻译模型可以使用一个模型在多种语言之间进行翻译，这非常令人印象深刻！'
- en: 'In the following code block, we import the libraries, load the models and then
    create the `translator` function, which accepts three arguments: (1) A sentence
    (`source_sentence`), (2) The language of the provided sentence (`source_language`)
    and (3) The language that we would like the sentence to be translated to (`target_language`).
    Then `translator` returns the translation as instructed.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码块中，我们导入库，加载模型，然后创建 `translator` 函数，该函数接受三个参数：（1）一个句子（`source_sentence`），（2）提供的句子的语言（`source_language`）以及（3）我们希望翻译成的语言（`target_language`）。然后
    `translator` 按照指示返回翻译结果。
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Next, let’s test our function by translating `Multilingual machine translation
    is impressive!` to French, Spanish, Italian, German, Simplified Chinese and Japanese.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们通过将 `Multilingual machine translation is impressive!` 翻译成法语、西班牙语、意大利语、德语、简体中文和日语来测试我们的函数。
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Results:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/33ff48d10d8bc93efc50209423b753b2.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/33ff48d10d8bc93efc50209423b753b2.png)'
- en: And we see the translations in the target languages in the results! I do not
    personally speak any of these languages but I verified them using Google Translate
    and the translations seem accurate!
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在结果中看到目标语言的翻译！我个人不讲这些语言，但我使用 Google 翻译验证了这些翻译，结果似乎是准确的！
- en: Last but not least, let’s look at Named-Entity Recognition.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，让我们看一下命名实体识别。
- en: 3\. Named-Entity Recognition (NER)
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 命名实体识别（NER）
- en: 'Task of identifying and categorizing named entities in text and categorizing
    them into pre-defined classes is called Named-Entity Recognition or NER for short.
    Some examples of these categories are: person names, locations, dates, organizations,
    numbers, etc. You may be wondering why we would need such a model. NER has many
    applications in the Natural Language space. For example, Visa, American Express,
    Amazon, etc. can use NER to identify and black-out sensitive information in a
    customer communication to protect customers’ sensitive information, such as date
    of birth and credit card information. Another application for social media companies
    such as Meta is identifying locations and individual names in comments/posts and
    using them for content recommendation.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 识别和分类文本中的命名实体，并将其分类到预定义类别中的任务称为命名实体识别，简称 NER。这些类别的一些示例包括：人名、地点、日期、组织、数字等。你可能会想，为什么我们需要这样的模型。NER
    在自然语言领域有许多应用。例如，Visa、美国运通、亚马逊等可以使用 NER 识别和屏蔽客户通信中的敏感信息，以保护客户的敏感信息，如出生日期和信用卡信息。另一种应用是社交媒体公司（如
    Meta）识别评论/帖子中的地点和个人姓名，并将其用于内容推荐。
- en: Now that we understand what NER is, let’s implement it and look at the results.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们了解了 NER 的基本概念，让我们实现它并查看结果。
- en: 3.1\. NER — Implementation
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.1\. NER — 实现
- en: 'In this example, we are going to use [spaCy](https://spacy.io) pre-trained
    model for NER. The implementation is pretty straightforward. We will follow these
    steps:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用 [spaCy](https://spacy.io) 的预训练模型进行命名实体识别（NER）。实现过程非常简单。我们将按照以下步骤进行：
- en: Install and download the required data
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装并下载所需的数据
- en: Import the library
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入库
- en: Load the pre-trained tasks, inclusive of NER
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载预训练任务，包括 NER
- en: Run an example sentence through the model and return the results
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过模型运行一个示例句子并返回结果
- en: 'If you need to install spaCy and download the data, you can use the following
    commands ([source](https://spacy.io/usage/models)):'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要安装 spaCy 并下载数据，你可以使用以下命令 ([source](https://spacy.io/usage/models))：
- en: '[PRE3]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'I ran the installation above using the Command Line Interface. It is as simple
    as (I) opening the Terminal and then (II) running the above two lines. If you
    need a more detailed Command Line tutorial, feel free to check out the following:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我通过命令行界面完成了上述安装。操作步骤很简单：（I）打开终端，然后（II）运行上述两行命令。如果你需要更详细的命令行教程，请随时查看以下内容：
- en: '[](/command-line-interface-cli-tutorial-how-advanced-users-interact-with-computers-28cf88f81ce?source=post_page-----c79662e52624--------------------------------)
    [## Command Line Interface (CLI) Tutorial — How Advanced Users Interact with Computers'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/command-line-interface-cli-tutorial-how-advanced-users-interact-with-computers-28cf88f81ce?source=post_page-----c79662e52624--------------------------------)
    [## 命令行界面（CLI）教程 — 高级用户如何与计算机互动'
- en: A CLI intro to increase productivity in interacting with computers
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CLI 入门以提高与计算机互动的生产力
- en: towardsdatascience.com](/command-line-interface-cli-tutorial-how-advanced-users-interact-with-computers-28cf88f81ce?source=post_page-----c79662e52624--------------------------------)
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/command-line-interface-cli-tutorial-how-advanced-users-interact-with-computers-28cf88f81ce?source=post_page-----c79662e52624--------------------------------)
- en: Next, let’s implement and apply NER to the following sentence:`Farzad wrote
    this Medium article in March 2023, using an Apple laptop, on a Jupyter notebook!`
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们对以下句子实施和应用命名实体识别（NER）：`Farzad wrote this Medium article in March 2023,
    using an Apple laptop, on a Jupyter notebook!`
- en: '[PRE4]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Results:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/24a127a3d560d0fab77ace3d9ff9e0d7.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/24a127a3d560d0fab77ace3d9ff9e0d7.png)'
- en: That’s quite interesting! Let’s talk about the results. The first line identified
    the nouns — I do not personally agree with all of them but still, that is quite
    impressive! The second line has correctly identified “write” and “use” as verbs
    and the third block has identified “Medium” as a location, “March 2023” as a date,
    “Apple” as an organization (this one is interesting since apple could also be
    the name of a fruit but the model recognized the company name, presumably based
    on the context of the sentence) and “Jupyter” as a person (this one needs some
    improvement). There are ways to further train these pre-trained models to ensure
    NER works more accurately for every use case but the point we wanted to articulate
    here was to showcase how these pre-trained language models can be used to accomplish
    complicated tasks such as NER with a reasonable level of accuracy.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常有趣！让我们来谈谈结果。第一行识别了名词——我个人不完全同意所有这些，但仍然，这非常令人印象深刻！第二行正确地识别了“write”和“use”作为动词，第三块识别了“Medium”作为地点，“March
    2023”作为日期，“Apple”作为组织（这一点很有趣，因为apple也可能是水果的名称，但模型根据句子的上下文识别了公司名称）和“Jupyter”作为一个人（这一点需要一些改进）。有方法进一步训练这些预训练模型，以确保NER在每个使用场景中更准确，但我们想要表达的重点是展示这些预训练语言模型如何以合理的准确性完成复杂任务，如NER。
- en: Conclusion
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this post, we briefly walked through the world of Natural Language Processing
    (NLP), Understanding (NLU) and Generation (NLG) and tried to understand their
    importance by introducing and implementing some of the most common tasks within
    the Natural Language space, using language modeling. We then moved on to the introduction
    and language model implementation of (I) Sentiment Analysis, (II) Machine Translation
    and (III) Named-Entity Recognition (NER) and looked at the impressive results
    of these powerful pre-trained language models in multiple languages.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们简要地介绍了自然语言处理（NLP）、理解（NLU）和生成（NLG）的世界，并通过引入和实施自然语言领域中的一些常见任务，使用语言建模来理解它们的重要性。然后，我们介绍了（I）情感分析，（II）机器翻译和（III）命名实体识别（NER）的语言模型实现，并查看了这些强大的预训练语言模型在多种语言中的令人印象深刻的结果。
- en: Thanks for Reading!
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 感谢阅读！
- en: If you found this post helpful, please [follow me on Medium](https://medium.com/@fmnobar)
    and subscribe to receive my latest posts!
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你觉得这篇文章对你有帮助，请[关注我在 Medium](https://medium.com/@fmnobar)并订阅以接收我最新的文章！
- en: '*(All images, unless otherwise noted, are by the author.)*'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*(所有图片，除非另有说明，均由作者提供。)*'
