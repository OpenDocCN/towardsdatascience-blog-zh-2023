- en: Beginner’s Guide to Linear Regression with PySpark
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PySpark线性回归初学者指南
- en: 原文：[https://towardsdatascience.com/beginners-guide-to-linear-regression-with-pyspark-bfc39b45a9e9](https://towardsdatascience.com/beginners-guide-to-linear-regression-with-pyspark-bfc39b45a9e9)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/beginners-guide-to-linear-regression-with-pyspark-bfc39b45a9e9](https://towardsdatascience.com/beginners-guide-to-linear-regression-with-pyspark-bfc39b45a9e9)
- en: A step-by-step tutorial on building a linear regression model with PySpark code
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用PySpark代码构建线性回归模型的逐步教程
- en: '[](https://medium.com/@yazihejazi?source=post_page-----bfc39b45a9e9--------------------------------)[![Yasmine
    Hejazi](../Images/1c280c78e49f62345b3cd0c30b185482.png)](https://medium.com/@yazihejazi?source=post_page-----bfc39b45a9e9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bfc39b45a9e9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bfc39b45a9e9--------------------------------)
    [Yasmine Hejazi](https://medium.com/@yazihejazi?source=post_page-----bfc39b45a9e9--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@yazihejazi?source=post_page-----bfc39b45a9e9--------------------------------)[![Yasmine
    Hejazi](../Images/1c280c78e49f62345b3cd0c30b185482.png)](https://medium.com/@yazihejazi?source=post_page-----bfc39b45a9e9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bfc39b45a9e9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bfc39b45a9e9--------------------------------)
    [Yasmine Hejazi](https://medium.com/@yazihejazi?source=post_page-----bfc39b45a9e9--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bfc39b45a9e9--------------------------------)
    ·5 min read·Jan 11, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----bfc39b45a9e9--------------------------------)
    ·阅读时间5分钟·2023年1月11日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/aa8d595a8c5e4b04bbfacc0474adb58d.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aa8d595a8c5e4b04bbfacc0474adb58d.png)'
- en: Photo by [eskay lim](https://unsplash.com/@eskaylim?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[eskay lim](https://unsplash.com/@eskaylim?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: PySpark is a Python API for Apache Spark. It allows us to code in a high level
    coding language while reaping the benefits of distributed computing. With in-memory
    computation, distributed processing using parallelize, and native machine learning
    libraries, we unlock great data processing efficiency that is essential for data
    scaling.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: PySpark是Apache Spark的Python API。它允许我们在高层次的编程语言中编写代码，同时享受分布式计算的好处。通过内存计算、使用并行化的分布式处理和原生机器学习库，我们可以解锁对数据处理的极大效率，这对数据扩展至关重要。
- en: This tutorial will go step-by-step on how to create a PySpark linear regression
    model using [Diamonds data](https://ggplot2.tidyverse.org/reference/diamonds.html)
    found on [ggplot2](https://ggplot2.tidyverse.org/reference/#data). Databricks
    hosts this dataset on [Databricks Utilities (](https://docs.databricks.com/dev-tools/databricks-utils.html)`[dbutils](https://docs.databricks.com/dev-tools/databricks-utils.html)`[)](https://docs.databricks.com/dev-tools/databricks-utils.html)
    so that it can easily be loaded. This data has both numerical and categorical
    features that we can utilize to build our model. We will handle how to preprocess
    the data so that we can simply train our model and create our predictions. And
    we’ll do this without touching Pandas!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程将逐步讲解如何使用[Diamonds数据](https://ggplot2.tidyverse.org/reference/diamonds.html)创建PySpark线性回归模型，该数据来自[ggplot2](https://ggplot2.tidyverse.org/reference/#data)。Databricks在[Databricks
    Utilities (](https://docs.databricks.com/dev-tools/databricks-utils.html)`[dbutils](https://docs.databricks.com/dev-tools/databricks-utils.html)`[)](https://docs.databricks.com/dev-tools/databricks-utils.html)上托管此数据集，以便轻松加载。该数据包含数值和分类特征，我们可以利用这些特征来构建我们的模型。我们将处理如何预处理数据，以便我们可以简单地训练模型并生成预测。我们将实现这一点而无需接触Pandas！
- en: '![](../Images/712aad12eeba673e8726d581a96c4995.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/712aad12eeba673e8726d581a96c4995.png)'
- en: Photo by [Tahlia Doyle](https://unsplash.com/@tahliaclaire?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Tahlia Doyle](https://unsplash.com/@tahliaclaire?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: If you are already familiar with coding linear regression in Pandas, the process
    is similar. The regression model will be predicting the **price** of a diamond.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经熟悉在Pandas中进行线性回归，过程是类似的。回归模型将预测钻石的**价格**。
- en: Data Pre-Processing
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据预处理
- en: First, let’s load the data. We’ll be using the `diamonds` dataset to predict
    the price of a diamond based on its characteristics. A description of each variable
    can be found [here](https://ggplot2.tidyverse.org/reference/diamonds.html).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们加载数据。我们将使用`diamonds`数据集来根据特征预测钻石的价格。每个变量的描述可以在[这里](https://ggplot2.tidyverse.org/reference/diamonds.html)找到。
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/d90228d00c6b9949dc3daed72c3cf1b9.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d90228d00c6b9949dc3daed72c3cf1b9.png)'
- en: Photo by Author
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 作者拍摄的照片
- en: To get our data ready for machine learning, we first need to create a vector
    of numerical features to use as input for our model. This means that if we have
    categorical variables, we need to one-hot encode them into numerical features;
    then, we put all of the features into one vector.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备我们的数据进行机器学习，我们首先需要创建一个数值特征向量，作为模型的输入。这意味着，如果我们有类别变量，我们需要将它们一热编码成数值特征；然后，将所有特征放入一个向量中。
- en: The MLlib library is a wrapper over PySpark that supports many machine learning
    algorithms for classification, regression, clustering, dimensionality reduction,
    and more. This library will really help with our data processing and machine learning
    needs!
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: MLlib库是一个对PySpark的封装，支持许多用于分类、回归、聚类、降维等的机器学习算法。这个库将大大帮助我们的数据处理和机器学习需求！
- en: Preprocess Categorical Features
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预处理类别特征
- en: '[StringIndexer](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.StringIndexer.html):
    This is essentially assigning a numeric value to each category (i.e.; Fair: 0,
    Ideal: 1, Good: 2, Very Good: 3, Premium: 4)'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[StringIndexer](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.StringIndexer.html)：这基本上是为每个类别分配一个数值（例如：Fair:
    0, Ideal: 1, Good: 2, Very Good: 3, Premium: 4）'
- en: '[OneHotEncoder](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.OneHotEncoder.html):
    This converts categories into binary vectors. The result is a SparseVector that
    indicates which index from StringIndexer has the one-hot value of 1.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[OneHotEncoder](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.OneHotEncoder.html)：这个工具将类别转换为二进制向量。结果是一个SparseVector，指示StringIndexer中哪个索引具有一热值1。'
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Assemble Feature Vector
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 汇总特征向量
- en: In PySpark, we need to combine all of our features into one vector column. The
    feature vector column will serve as inputs to our machine-learning models. PySpark
    lets us easily create this vector using [VectorAssembler](https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.ml.feature.VectorAssembler.html).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在PySpark中，我们需要将所有特征合并成一个向量列。特征向量列将作为我们机器学习模型的输入。PySpark允许我们使用[VectorAssembler](https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.ml.feature.VectorAssembler.html)轻松创建这个向量。
- en: You’ll need to combine numerical features and the categorical sparse vector
    features from before into one vector.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要将之前的数值特征和类别稀疏向量特征合并成一个向量。
- en: Then, we can run the stages as a pipeline. This runs the data through all the
    feature transformations we’ve defined so far.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以将这些阶段作为管道运行。这会将数据通过到目前为止定义的所有特征转换。
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Train-test Split
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练-测试拆分
- en: Randomly split the dataset into train and test sets.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 随机将数据集拆分为训练集和测试集。
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Post-split Data Processing
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 拆分后的数据处理
- en: In linear regression, it is often recommended to standardize your features.
    PySpark’s [StandardScaler](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.StandardScaler.html)
    achieves this by removing the mean (set to zero) and scaling to unit variance.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性回归中，通常建议对特征进行标准化。PySpark的[StandardScaler](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.StandardScaler.html)通过去除均值（设为零）并缩放到单位方差来实现这一点。
- en: First, fit StandardScaler onto the training data. Then, use the scaler to transform
    the train and test data. The reason why you should fit on the train data is to
    [avoid data leakage](https://machinelearningmastery.com/data-preparation-without-data-leakage/)
    — when applying your model to the real world, you won’t know the distribution
    of your test data yet.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，将StandardScaler拟合到训练数据上。然后，使用缩放器对训练数据和测试数据进行转换。你应该在训练数据上进行拟合的原因是[避免数据泄漏](https://machinelearningmastery.com/data-preparation-without-data-leakage/)——当将模型应用于实际世界时，你还不知道测试数据的分布。
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Build and Train Model
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建和训练模型
- en: 'We can import from MLlib to start building our model ([pyspark.ml.regression.**LinearRegression**](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html)).
    We can start with the default parameter values and adjust these during model tuning.
    The default for some parameters to pay attention to are: `maxIter=100`, `regParam=0.0`,
    `elasticNetParam=0.0`, `loss=''squaredError’`. Then call `fit()` to fit the model
    to the training data.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从 MLlib 导入以开始构建我们的模型 ([pyspark.ml.regression.**LinearRegression**](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html))。我们可以从默认参数值开始，并在模型调优过程中调整这些值。需要注意的一些默认参数是：`maxIter=100`，`regParam=0.0`，`elasticNetParam=0.0`，`loss='squaredError’`。然后调用
    `fit()` 将模型拟合到训练数据上。
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Evaluate Model
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估模型
- en: First, we need to develop predictions from our data using our new model. To
    get predictions, call `transform()`.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要使用新模型从数据中生成预测。要获取预测，请调用 `transform()`。
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Why should you also fit your model on the train data?** Comparing your model
    evaluations on both the train and test data can help you identify if you’re overfitting
    or underfitting on your train data. If the evaluations for train and test are
    both similar, you may be underfitting. If your test evaluation is much lower than
    your train evaluation, you may be overfitting.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**为什么你还需要在训练数据上拟合你的模型？** 对比模型在训练数据和测试数据上的评估可以帮助你识别是否存在过拟合或欠拟合。如果训练和测试的评估结果相似，你可能存在欠拟合。如果测试评估结果远低于训练评估，你可能存在过拟合。'
- en: 'To evaluate your model, PySpark has [RegressionEvaluator](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.RegressionEvaluator.html)
    at your service. You can choose whichever evaluation metric is most appropriate
    for your use case:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 要评估模型，PySpark 提供了 [RegressionEvaluator](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.RegressionEvaluator.html)。你可以选择最适合你用例的评估指标：
- en: RMSE — Root mean squared error (Default)
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RMSE — 均方根误差（默认）
- en: MSE — Mean squared error
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MSE — 均方误差
- en: R2 — R-squared
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: R2 — 决定系数
- en: MAE — Mean absolute error
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MAE — 平均绝对误差
- en: Var — Explained variance
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Var — 解释方差
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Train R2: 0.9204 | Test R2: 0.9142'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '训练 R2: 0.9204 | 测试 R2: 0.9142'
- en: Analyze Feature Weights
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析特征权重
- en: To pull out the linear regression weights and coefficients, run the following
    code.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 要提取线性回归的权重和系数，请运行以下代码。
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: It may be more helpful to match the weights to the feature names and plot them.
    This view is especially of high interest to key stakeholders who want to understand
    key drivers of the model.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 将权重与特征名称匹配并绘制它们可能更有帮助。这种视图对希望了解模型关键驱动因素的主要利益相关者特别重要。
- en: '[PRE9]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Above produces a Pandas dataframe containing the feature names and weights.
    Now let’s plot the weights.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 上述操作生成了包含特征名称和权重的 Pandas 数据框。现在让我们绘制这些权重。
- en: '[PRE10]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](../Images/de201556cccebf06e2cd9cf9e3d7d354.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/de201556cccebf06e2cd9cf9e3d7d354.png)'
- en: Photo by Author
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 作者照片
- en: Summary
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'Steps for implementing linear regression with PySpark:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 PySpark 实现线性回归的步骤：
- en: One-hot encode categorical features using StringIndexer and OneHotEncoder
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 StringIndexer 和 OneHotEncoder 对分类特征进行独热编码
- en: Create input feature vector column using VectorAssembler
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 VectorAssembler 创建输入特征向量列
- en: Split data into train and test
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分割为训练集和测试集
- en: Scale data using StandardScaler
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 StandardScaler 进行数据缩放
- en: Initialize and fit LinearRegression model on train data
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化并在训练数据上拟合 LinearRegression 模型
- en: Transform model on test data to make predictions
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试数据上转换模型以进行预测
- en: Evaluate model with RegressionEvaluator
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 RegressionEvaluator 评估模型
- en: Analyze feature weights to understand and improve model
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分析特征权重以理解和改进模型
