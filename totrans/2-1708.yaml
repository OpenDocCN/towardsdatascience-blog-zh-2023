- en: 'PyCon gems: A Curated Selection of Exceptional Talks from PyCon DE 2023'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyCon珍品：精选PyCon DE 2023中卓越讲座的精选集
- en: 原文：[https://towardsdatascience.com/pycon-gems-a-curated-selection-of-exceptional-talks-from-pycon-de-2023-84461368df18](https://towardsdatascience.com/pycon-gems-a-curated-selection-of-exceptional-talks-from-pycon-de-2023-84461368df18)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/pycon-gems-a-curated-selection-of-exceptional-talks-from-pycon-de-2023-84461368df18](https://towardsdatascience.com/pycon-gems-a-curated-selection-of-exceptional-talks-from-pycon-de-2023-84461368df18)
- en: '![](../Images/3b400df4d0a02d493062a5da3a1a77eb.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3b400df4d0a02d493062a5da3a1a77eb.png)'
- en: Image by the author.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: LLMs in isolation are not the future.
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单独的LLM不是未来。
- en: '[](https://medium.com/@mary.newhauser?source=post_page-----84461368df18--------------------------------)[![Mary
    Newhauser](../Images/7f0d7287f7b735bb9391858f1fc641ee.png)](https://medium.com/@mary.newhauser?source=post_page-----84461368df18--------------------------------)[](https://towardsdatascience.com/?source=post_page-----84461368df18--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----84461368df18--------------------------------)
    [Mary Newhauser](https://medium.com/@mary.newhauser?source=post_page-----84461368df18--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mary.newhauser?source=post_page-----84461368df18--------------------------------)[![Mary
    Newhauser](../Images/7f0d7287f7b735bb9391858f1fc641ee.png)](https://medium.com/@mary.newhauser?source=post_page-----84461368df18--------------------------------)[](https://towardsdatascience.com/?source=post_page-----84461368df18--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----84461368df18--------------------------------)
    [Mary Newhauser](https://medium.com/@mary.newhauser?source=post_page-----84461368df18--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----84461368df18--------------------------------)
    ·8 min read·May 2, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----84461368df18--------------------------------)
    ·8分钟阅读·2023年5月2日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: The excitement and tension in the air were palpable as crowds lined up only
    to be turned away as conference rooms filled to capacity at PyCon DE 2023 in mid-April
    in Berlin. The release of ChatGPT mere months before set off an AI frenzy, sparking
    a tsunami of innovation and collaboration to develop the first fully open source
    state-of-the-art instruction-following LLM. During the three days of the conference,
    alone, the open source world announced the release of [LLaVA](https://llava-vl.github.io/),
    [StableLM](https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models),
    and the [RedPajama](https://www.together.xyz/blog/redpajama) dataset.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在2023年4月中旬的柏林PyCon DE 2023大会上，空气中的兴奋和紧张气氛十分明显，会议室座无虚席，观众排队却被拒之门外。几个月前ChatGPT的发布引发了AI狂潮，激发了一场创新和合作的浪潮，致力于开发第一个完全开源的最先进指令跟随大型语言模型。在会议的三天里，开源世界宣布了[LLaVA](https://llava-vl.github.io/)、[StableLM](https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models)和[RedPajama](https://www.together.xyz/blog/redpajama)数据集的发布。
- en: 'If I could summarize [PyCon DE 2023](https://2023.pycon.de/) in one sentence,
    I would say: “LLMs in isolation are not the future.”'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我用一句话总结[PyCon DE 2023](https://2023.pycon.de/)，那就是：“单独的LLM不是未来。”
- en: To summarize talks by Erin Mikail Staples of [Label Studio](https://labelstud.io/)
    and Ines Montani of [Explosion](https://explosion.ai/), LLMs perform better on
    downstream tasks when they are used with task-specific data. Furthermore, the
    most prevalent conversations among attendees were OpenAI’s [intrusive data collection
    policies](https://www.wired.com/story/italy-ban-chatgpt-privacy-gdpr/), which
    prohibit many companies and even entire industries from using [ChatGPT](https://openai.com/blog/chatgpt)
    and [GPT-4](https://openai.com/product/gpt-4) for commercial purposes.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 总结[Label Studio](https://labelstud.io/)的Erin Mikail Staples和[Explosion](https://explosion.ai/)的Ines
    Montani的讲座，LLM在与特定任务的数据一起使用时在下游任务中表现更好。此外，与会者中最普遍的讨论话题是OpenAI的[侵入性数据收集政策](https://www.wired.com/story/italy-ban-chatgpt-privacy-gdpr/)，这些政策禁止许多公司甚至整个行业将[ChatGPT](https://openai.com/blog/chatgpt)和[GPT-4](https://openai.com/product/gpt-4)用于商业目的。
- en: LLMs in isolation are not the future.
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 单独的LLM不是未来。
- en: The purpose of this article is to give you an overview of my favorite talks
    at this year’s PyCon DE. Below I summarize my top five favorite talks, and include
    links to the program descriptions, slides, and code, when available. All talks
    from the conference were recorded and will be fully accessible to the public once
    they are uploaded.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的目的是概述我在今年 PyCon DE 上最喜欢的演讲。以下是我最喜欢的五个演讲的总结，并包含了程序描述、幻灯片和代码的链接（如果有的话）。大会上的所有演讲都被录制下来，并将在上传后完全公开访问。
- en: '[Improving machine learning from human feedback](https://github.com/heartexlabs/RLHF)'
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[从人类反馈中改进机器学习](https://github.com/heartexlabs/RLHF)'
- en: (Erin Mikail Sharples, [Label Studio](https://labelstud.io/))
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: (Erin Mikail Sharples, [Label Studio](https://labelstud.io/))
- en: Models trained on enormous datasets, like ChatGPT, impose internet-scale biases
    on downstream tasks. Prompt engineering, the process of iteratively selecting
    and designing prompts to elicit a desired response from a generative language
    model, while popular, simply adapts to a model’s known limitations. Fortunately,
    there’s a better alternative for addressing bias in LLMs.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 训练于巨大数据集上的模型，例如 ChatGPT，会在下游任务中引入互联网规模的偏见。虽然提示工程，即迭代选择和设计提示以引发生成语言模型的期望响应，是一种流行的方法，但它只是适应了模型的已知局限性。幸运的是，还有更好的替代方案来解决
    LLM 中的偏见问题。
- en: In this talk, [Reinforcement Learning from Human Feedback](https://openai.com/research/learning-from-human-preferences)
    (RLHF) is the guest star. RLHF is a process by which a model iteratively learns
    from feedback provided by a human in order to improve model performance. RLHF
    gives you finer control over LLMs, aligning model output with your specific needs
    and use case while also reducing the bias associated with LLMs. Label Studio is
    an open source data labeling platform with a user-friendly UI and Python client
    that allows you to incorporate RLHF into your own machine learning workflows.
    RLHF not only improves accuracy on downstream tasks, but it also increases truthfulness
    and reduces toxicity at minimal cost.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次演讲中，[从人类反馈中进行强化学习](https://openai.com/research/learning-from-human-preferences)（RLHF）是明星话题。RLHF
    是一种模型通过迭代从人类提供的反馈中学习，以提高模型性能的过程。RLHF 使你能更精确地控制 LLM，将模型输出与特定需求和使用场景对齐，同时减少 LLM
    相关的偏见。Label Studio 是一个开源数据标注平台，具有用户友好的界面和 Python 客户端，允许你将 RLHF 集成到自己的机器学习工作流中。RLHF
    不仅提高了下游任务的准确性，还增加了真实性，减少了毒性，成本极低。
- en: I enjoyed this talk particularly because it demystified the concept of RLHF,
    a method that played a critical role in the development of ChatGPT. Furthermore,
    Label Studio demonstrates that RLHF is a powerful and practical open source tool
    that can be added to your current workflow with ease.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我特别喜欢这次演讲，因为它揭示了 RLHF 的概念，这是一种在 ChatGPT 开发中发挥了关键作用的方法。此外，Label Studio 展示了 RLHF
    是一个强大而实用的开源工具，可以轻松地添加到你当前的工作流中。
- en: 'GitHub: [heartexlabs/RLHF](https://github.com/heartexlabs/RLHF)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 'GitHub: [heartexlabs/RLHF](https://github.com/heartexlabs/RLHF)'
- en: 'Notebook: [RLHF_with_Custom_Datasets.ipynb](https://github.com/heartexlabs/RLHF/blob/master/tutorials/RLHF_with_Custom_Datasets.ipynb)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 'Notebook: [RLHF_with_Custom_Datasets.ipynb](https://github.com/heartexlabs/RLHF/blob/master/tutorials/RLHF_with_Custom_Datasets.ipynb)'
- en: '[](https://labelstud.io/?source=post_page-----84461368df18--------------------------------)
    [## Open Source Data Labeling | Label Studio'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://labelstud.io/?source=post_page-----84461368df18--------------------------------)
    [## 开源数据标注 | Label Studio'
- en: The most flexible data annotation tool. Quickly installable. Build custom UIs
    or use pre-built labeling templates…
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最灵活的数据注释工具。可以快速安装。构建自定义 UI 或使用预构建的标注模板……
- en: labelstud.io](https://labelstud.io/?source=post_page-----84461368df18--------------------------------)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: labelstud.io](https://labelstud.io/?source=post_page-----84461368df18--------------------------------)
- en: '[Incorporating GPT-3 into practical NLP workflows](https://pretalx.com/pyconde-pydata-berlin-2023/talk/77MWVW/)'
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[将 GPT-3 纳入实用的 NLP 工作流](https://pretalx.com/pyconde-pydata-berlin-2023/talk/77MWVW/)'
- en: (Ines Montani, [Explosion](https://explosion.ai/))
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: (Ines Montani, [Explosion](https://explosion.ai/))
- en: When I first tried out ChatGPT, I seriously wondered how open source NLP libraries
    could compete with the might of OpenAI. Ines Montani argues that LLMs complement,
    rather than replace, existing machine learning workflows.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当我第一次尝试 ChatGPT 时，我真的怀疑开源 NLP 库如何与 OpenAI 的强大相比。Ines Montani 认为 LLM 是对现有机器学习工作流的补充，而不是替代。
- en: 'Explosion has released a repository of recipes that enable users to leverage
    the power of OpenAI models alongside human feedback collected via their enterprise
    annotation tool, Prodigy. The pipeline works like this:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Explosion 发布了一个配方库，使用户能够利用 OpenAI 模型的强大功能，并结合通过其企业注释工具 Prodigy 收集的人工反馈。这个流程是这样的：
- en: Prompt GPT-3.5 (ChatGPT’s base model) with a task.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给 GPT-3.5（ChatGPT 的基础模型）设置任务。
- en: Retrieve the response and treat it as a zero- or few-shot classification.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检索响应并将其视为零-shot 或少-shot 分类。
- en: Have a human decision-maker mark the response as accurate or inaccurate.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让人工决策者标记响应是否准确。
- en: Use the resulting annotations to train or evaluate your task-specific model.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用生成的注释来训练或评估你的任务特定模型。
- en: If I still needed convincing that RLHF was the way of the future, this talk
    did it. As in the talk I outlined above, Ines demonstrates that incorporating
    human feedback into NLP workflows results in better performance on downstream
    tasks than using LLMs in isolation. And given my own experience with using ChatGPT,
    I don’t doubt these claims for a second. While I’ve found it to perform broad
    tasks well, I definitely would not trust ChatGPT or GPT-4 unequivocably with sensitive
    tasks that require subject matter expertise.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我仍然需要说服自己 RLHF 是未来的最终方向，这次讲座做到了。在我上面提到的讲座中，Ines 展示了将人工反馈纳入 NLP 工作流比单独使用 LLMs
    可以获得更好的下游任务性能。鉴于我自己使用 ChatGPT 的经验，我对这些说法毫不怀疑。虽然我发现它在执行广泛任务时表现良好，但我绝对不会毫无保留地信任
    ChatGPT 或 GPT-4 处理需要专业知识的敏感任务。
- en: '[Slides](https://speakerdeck.com/inesmontani/incorporating-llms-into-practical-nlp-workflows)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[幻灯片](https://speakerdeck.com/inesmontani/incorporating-llms-into-practical-nlp-workflows)'
- en: 'GitHub: [explosion/prodigy-openai-recipes](https://github.com/explosion/prodigy-openai-recipes)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 'GitHub: [explosion/prodigy-openai-recipes](https://github.com/explosion/prodigy-openai-recipes)'
- en: '[](https://explosion.ai/?source=post_page-----84461368df18--------------------------------)
    [## Explosion · Makers of spaCy, Prodigy, and other AI and NLP developer tools'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[## Explosion · spaCy、Prodigy 及其他 AI 和 NLP 开发工具的制造商](https://explosion.ai/?source=post_page-----84461368df18--------------------------------)'
- en: Explosion is a software company specializing in developer tools for Artificial
    Intelligence and Natural Language…
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Explosion 是一家专注于人工智能和自然语言处理开发工具的软件公司……
- en: explosion.ai](https://explosion.ai/?source=post_page-----84461368df18--------------------------------)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[Explosion.ai](https://explosion.ai/?source=post_page-----84461368df18--------------------------------)'
- en: '[Methods for Text Style Transfer: Text Detoxification Case](https://pretalx.com/pyconde-pydata-berlin-2023/talk/UECWHD/)'
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[文本风格迁移的方法：文本解毒案例](https://pretalx.com/pyconde-pydata-berlin-2023/talk/UECWHD/)'
- en: (Daryna Dementieva, Technical University of Munich)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: （达琳娜·德门捷娃，慕尼黑工业大学）
- en: 'GitHub: [dardem/text_detoxification](https://github.com/dardem/text_detoxification)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 'GitHub: [dardem/text_detoxification](https://github.com/dardem/text_detoxification)'
- en: 'Publication: [ParaDetox: Detoxification with Parallel Data](https://aclanthology.org/2022.acl-long.469.pdf)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '发表文献：[ParaDetox: 利用平行数据进行解毒](https://aclanthology.org/2022.acl-long.469.pdf)'
- en: Global adoption of the internet has provided a platform for individuals to share
    information, ideas, and opinions with an ever-growing audience. [Research](https://www.nature.com/articles/s41599-020-00550-7)
    conducted in 2020 even found that Facebook’s Feed recommendation algorithm priveleged
    incendiary content, as they tended to increase user engagement on the platform.
    And while hate speech and toxic text detection has been the subject of much research,
    less has work been done to actually detoxify such text.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网的全球普及为个人提供了一个与不断增长的观众分享信息、想法和观点的平台。2020年的[研究](https://www.nature.com/articles/s41599-020-00550-7)甚至发现，Facebook的
    Feed 推荐算法优先推送煽动性内容，因为这些内容通常会增加用户在平台上的参与度。尽管仇恨言论和有毒文本检测已成为许多研究的主题，但对实际解毒此类文本的工作却较少。
- en: In this talk, Daryna introduces ParaDetox, a novel pipeline and set of parallel
    datasets trained on parallel toxic and detoxified datasets that use Text Style
    Transfer (TST) to detoxify toxic text. Treated as a seq2seq text generation task,
    the first step in ParaDetox is to curate pairs of datasets of toxic text and detoxified
    text. These parallel datasets are then used to train a language model that automatically
    detoxifies text inputs. ParaDetox models that can detoxify Russian and English
    text, as well as the parallel datasets used to train the models are currently
    hosted on the [HuggingFace Hub](https://huggingface.co/s-nlp).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个讲座中，Daryna 介绍了 ParaDetox，这是一个新颖的管道和一组平行数据集，这些数据集基于平行的有毒和去毒化数据集进行训练，并使用文本风格转换（TST）来去毒化有毒文本。将其视为一个
    seq2seq 文本生成任务，ParaDetox 的第一步是策划有毒文本和去毒化文本的数据集对。这些平行数据集随后用于训练一个语言模型，该模型可以自动去毒化文本输入。目前，ParaDetox
    模型可以去毒化俄语和英语文本，及用于训练模型的平行数据集，均托管在 [HuggingFace Hub](https://huggingface.co/s-nlp)。
- en: Before the widespread use of generative text models, like ChatGPT, by the public,
    we only had to worry about toxic text that was produced by humans on the internet.
    Now, however, we need to worry about both humans and machines generated toxic,
    harmful, and hateful text. ParaDetox also uses a creative approach to solve an
    age-old problem with the use of parallel corpora. This method is yet another powerful
    example of leveraging LLMs *and* human input to create an effective solution to
    a downstream task.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成文本模型（如 ChatGPT）被公众广泛使用之前，我们只需担心互联网中由人类产生的有害文本。然而，现在我们需要担心人类和机器生成的有毒、有害和仇恨的文本。ParaDetox
    还使用了一种创新的方法，通过使用平行语料库来解决这个古老的问题。这种方法是另一个强大的例子，展示了如何利用 LLMs *和* 人类输入来创建有效的下游任务解决方案。
- en: '[](https://github.com/s-nlp/paradetox?source=post_page-----84461368df18--------------------------------)
    [## GitHub - s-nlp/paradetox: Data and info for the paper "ParaDetox: Detoxification
    with Parallel…'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/s-nlp/paradetox?source=post_page-----84461368df18--------------------------------)
    [## GitHub - s-nlp/paradetox: 论文“ParaDetox: 使用平行语料库进行去毒化”的数据和信息…'
- en: This repository contains information about Paradetox dataset -- the first parallel
    corpus for the detoxification task…
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 这个仓库包含了有关 Paradetox 数据集的信息——这是第一个用于去毒化任务的平行语料库……
- en: github.com](https://github.com/s-nlp/paradetox?source=post_page-----84461368df18--------------------------------)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/s-nlp/paradetox?source=post_page-----84461368df18--------------------------------)'
- en: '[Actionable machine learning in the browser with PyScript](https://pretalx.com/pyconde-pydata-berlin-2023/talk/9Q38VT/)'
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[在浏览器中使用 PyScript 实现可操作的机器学习](https://pretalx.com/pyconde-pydata-berlin-2023/talk/9Q38VT/)'
- en: (Valerio Maggio, [Anaconda](https://www.anaconda.com/))
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: （Valerio Maggio, [Anaconda](https://www.anaconda.com/))
- en: If you’re used to primarily using Jupyter notebooks for end-to-end data science
    projects, you might be scared of deploying your first web app. PyScript aims to
    change this, by providing an easy framework for coders of all skill levels to
    create dynamic Python web applications. According to Valerio, *“you can program
    Python code in the browser with no installation whatsoever.”*
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你习惯于主要使用 Jupyter 笔记本进行端到端的数据科学项目，你可能会对部署第一个 Web 应用感到害怕。PyScript 旨在改变这种情况，通过提供一个简单的框架，让所有技能水平的编码者都能创建动态的
    Python Web 应用。根据 Valerio 的说法，*“你可以在浏览器中编写 Python 代码，无需任何安装。”*
- en: PyScript is built on top of [Pyodide](https://github.com/pyodide/pyodide), which
    provides access to the full PyData Stack (minus a few unsupported modules) immediately
    available in the browser. Unlike PHP, PyScript is a client-side technology, meaning
    there is no server or installation of any kind required. It can be used to share
    interactive dashboards, visualize data, and create client-side Python web apps.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: PyScript 基于 [Pyodide](https://github.com/pyodide/pyodide)，它在浏览器中提供了完整的 PyData
    Stack（减去一些不支持的模块）。与 PHP 不同，PyScript 是一种客户端技术，这意味着不需要服务器或任何形式的安装。它可以用于共享互动仪表板、可视化数据和创建客户端
    Python Web 应用。
- en: Although PyScript applications may not be as advanced as those developed with
    Streamlit or Gradio, they present a user-friendly opportunity for data scientists
    to familiarize themselves and build confidence with web app deployment. As someone
    who is ashamedly allergic to programming languages that are not Python or R, PyScript
    had me at “deployment is as simple as ‘deploying’ an HTML file.”
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 PyScript 应用程序可能不如使用 Streamlit 或 Gradio 开发的应用程序那么先进，但它们为数据科学家提供了一个用户友好的机会，让他们熟悉并增强对
    Web 应用部署的信心。作为一个对非 Python 或 R 编程语言感到羞愧过敏的人，PyScript 让我着迷于“部署就像‘部署’一个 HTML 文件一样简单”。
- en: '[Slides](https://speakerdeck.com/leriomaggio/actionable-machine-learning-in-the-browser-with-pyscript)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[幻灯片](https://speakerdeck.com/leriomaggio/actionable-machine-learning-in-the-browser-with-pyscript)'
- en: 'GitHub: [pyscript/pyscript](https://github.com/pyscript/pyscript)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 'GitHub: [pyscript/pyscript](https://github.com/pyscript/pyscript)'
- en: '[](https://pyscript.net/?source=post_page-----84461368df18--------------------------------)
    [## Pyscript.net'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pyscript.net/?source=post_page-----84461368df18--------------------------------)
    [## Pyscript.net'
- en: Wouldn't it be cool... to run Python... in your browser? ...| print('Now you
    can!') | | | Click here for example…
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 难道不酷吗……在你的浏览器中运行Python…… | print('现在你可以了！') | | | 点击这里查看示例……
- en: pyscript.net](https://pyscript.net/?source=post_page-----84461368df18--------------------------------)
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: pyscript.net](https://pyscript.net/?source=post_page-----84461368df18--------------------------------)
- en: '[How are we managing? Data teams IRL](https://pretalx.com/pyconde-pydata-berlin-2023/talk/MBH7GB/)'
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[我们如何管理？现实中的数据团队](https://pretalx.com/pyconde-pydata-berlin-2023/talk/MBH7GB/)'
- en: (Noa Tamir)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: (Noa Tamir)
- en: While talking about management is admittedly less sexy than talking about the
    latest SOTA machine learning model, package, or platform, this keynote was well
    attended, and for good reason. Although the role of data scientist has been around
    for 15 years now, most of our conferences address the management of processes
    and platforms but neglect to focus on the management of people.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管谈论管理显然不如谈论最新的SOTA机器学习模型、包或平台那样性感，但这场主题演讲受到了很好的关注，原因也很充分。虽然数据科学家这一角色已经存在了15年，但我们的大多数会议讨论的是过程和平台的管理，而忽视了对人员管理的关注。
- en: In this talk, Noa explains that data-driven work is probabilistic, meaning it’s
    difficult to manage and requires different management techniques than non data-driven
    work. The rapid development of new machine learning techniques and technologies
    presents unique challenges to managers of data teams. And as the field has evolved
    over the years, so have the roles in data-driven teams. We have a hard time understanding
    the nuances in job titles and descriptions, which makes it harder to hire the
    right people for the right role and can also negatively impact job satisfaction
    and career development for employees.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次演讲中，Noa解释了数据驱动工作的概率性，这意味着它很难管理，并且需要与非数据驱动工作不同的管理技术。新机器学习技术和科技的快速发展给数据团队的管理者带来了独特的挑战。随着这一领域的演变，数据驱动团队的角色也在变化。我们很难理解职位名称和描述中的细微差别，这使得招聘合适的人才更加困难，也可能对员工的工作满意度和职业发展产生负面影响。
- en: Good managers can mitigate these consequences by building a shared understanding
    and communicating specific definitions of data roles with current and potential
    employees. Managers can also support their employees by helping them develop as
    either specialists or generalists, both of which bring value to data teams.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 优秀的管理者可以通过建立共同的理解和与现有及潜在员工沟通数据角色的具体定义来减轻这些后果。管理者还可以通过帮助员工发展成为专才或通才来支持他们，这两者都为数据团队带来了价值。
- en: Noa’s talk succinctly described the challenges facing data teams in a way that
    was honest and validating. They gave practical advice for data team managers while
    also underscoring the fact that we work in a new, rapidly changing field and that
    we’re all still learning.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Noa的演讲简洁地描述了数据团队面临的挑战，既诚实又具有验证性。他们为数据团队管理者提供了实际的建议，同时强调了我们工作在一个新的、快速变化的领域中，我们都还在学习。
- en: '[Slides](https://speakerdeck.com/noatamir/how-are-we-managing-data-teams-management-irl)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[幻灯片](https://speakerdeck.com/noatamir/how-are-we-managing-data-teams-management-irl)'
- en: Both highly motivating and overwhelming, PyCon DE 2023 was truly an outstanding
    conference. In addition to selecting captivating and pertinent presentations and
    workshops, the organizers did a wonderful job of fostering a safe and inclusive
    atmosphere.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: PyCon DE 2023既充满了动力又令人不知所措，确实是一场出色的会议。除了挑选引人入胜且相关的演讲和工作坊外，组织者还很好地营造了一个安全包容的氛围。
- en: This year, I was relieved to hear that despite the all the hype surrounding
    LLMs, humans are still playing essential roles in creating valuable data solutions.
    It’s hard to imagine what the state of AI will look like a year from now, but
    one thing I do know is that I’ll be right back in Berlin for PyCon DE 2024.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 今年，我很高兴地听到，尽管围绕LLMs有很多炒作，但人类在创造有价值的数据解决方案方面仍然发挥着重要作用。很难想象一年来人工智能的状态会是什么样，但我知道的一件事是，我将在2024年再次回到柏林参加PyCon
    DE。
- en: '*P.S. I’ll include the link to access the recordings of the conference as soon
    as it’s posted.*'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '*附言：我会在会议记录发布后尽快附上访问链接。*'
- en: '*If you’d like to stay up-to-date on the latest data science trends, technologies,
    and packages, consider becoming a Medium member. You’ll get unlimited access to
    articles and blogs like Towards Data Science and you’ll be supporting my writing.
    (I earn a small commission for each membership).*'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你想跟上最新的数据科学趋势、技术和软件包，可以考虑成为Medium会员。你将获得对《Towards Data Science》等文章和博客的无限访问，并且你将支持我的写作。（我从每个会员订阅中赚取少量佣金）。*'
- en: '[](https://medium.com/@mary.newhauser/membership?source=post_page-----84461368df18--------------------------------)
    [## Join Medium with my referral link - Mary Newhauser'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 通过我的推荐链接加入Medium - Mary Newhauser](https://medium.com/@mary.newhauser/membership?source=post_page-----84461368df18--------------------------------)'
- en: Get access to unlimited Medium articles for $5 per month 🤗 Your membership fee
    directly supports Mary Newhauser and…
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 每月$5即可访问无限Medium文章 🤗 你的会员费直接支持Mary Newhauser和…
- en: medium.com](https://medium.com/@mary.newhauser/membership?source=post_page-----84461368df18--------------------------------)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[Medium会员](https://medium.com/@mary.newhauser/membership?source=post_page-----84461368df18--------------------------------)'
- en: Want to connect?
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 想要联系一下？
- en: 📖 Follow me on [Medium](https://medium.com/@mary.newhauser)
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 📖 在[Medium](https://medium.com/@mary.newhauser)上关注我
- en: 💌 [Subscribe](https://medium.com/@mary.newhauser/subscribe) to get an email
    whenever I publish
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 💌 [订阅](https://medium.com/@mary.newhauser/subscribe)以便在我发布新内容时收到邮件
- en: 🖌️ Check out my generative AI [blog](https://www.gptechblog.com/)
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 🖌️ 查看我的生成式AI[博客](https://www.gptechblog.com/)
- en: 🔗 Take a look at my [portfolio](https://www.datascienceportfol.io/marynewhauser)
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 🔗 看看我的[作品集](https://www.datascienceportfol.io/marynewhauser)
- en: 👩‍🏫 I’m also a data science [coach](https://www.datajump.co/)!
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 👩‍🏫 我还是一名数据科学[教练](https://www.datajump.co/)！
- en: 'I’ve also written:'
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我还写过：
- en: '[](/gpt-4-vs-chatgpt-an-exploration-of-training-performance-capabilities-and-limitations-35c990c133c5?source=post_page-----84461368df18--------------------------------)
    [## GPT-4 vs. ChatGPT: An Exploration of Training, Performance, Capabilities,
    and Limitations'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[## GPT-4与ChatGPT：训练、性能、能力和局限性的探讨](https://towardsdatascience.com/gpt-4-vs-chatgpt-an-exploration-of-training-performance-capabilities-and-limitations-35c990c133c5?source=post_page-----84461368df18--------------------------------)'
- en: GPT-4 is an improvement but temper your expectations.
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GPT-4是一次改进，但要调整你的期望。
- en: towardsdatascience.com](/gpt-4-vs-chatgpt-an-exploration-of-training-performance-capabilities-and-limitations-35c990c133c5?source=post_page-----84461368df18--------------------------------)
    [](/the-ultimate-reference-for-clean-pandas-code-413df676e63c?source=post_page-----84461368df18--------------------------------)
    [## The ultimate reference for clean Pandas code
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 最终的Pandas代码清理参考](https://towardsdatascience.com/gpt-4-vs-chatgpt-an-exploration-of-training-performance-capabilities-and-limitations-35c990c133c5?source=post_page-----84461368df18--------------------------------)
    [## 清洁文本数据的干净方法'
- en: A clean way to clean text data.
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 清洁文本数据的干净方法。
- en: towardsdatascience.com](/the-ultimate-reference-for-clean-pandas-code-413df676e63c?source=post_page-----84461368df18--------------------------------)
    [](/making-the-jump-from-data-analyst-to-data-scientist-in-2023-74e2cf7fc139?source=post_page-----84461368df18--------------------------------)
    [## Making the Jump from Data Analyst to Data Scientist in 2023
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 2023年从数据分析师转型为数据科学家的路径](https://towardsdatascience.com/the-ultimate-reference-for-clean-pandas-code-413df676e63c?source=post_page-----84461368df18--------------------------------)
    [## 从数据分析师到数据科学家的转型'
- en: The skills and resources you need to transition from a data analyst to data
    scientist position.
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从数据分析师转型为数据科学家的技能和资源。
- en: towardsdatascience.com](/making-the-jump-from-data-analyst-to-data-scientist-in-2023-74e2cf7fc139?source=post_page-----84461368df18--------------------------------)
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[## GPT-4与ChatGPT的比较：训练、性能、能力和局限性探讨](https://towardsdatascience.com/making-the-jump-from-data-analyst-to-data-scientist-in-2023-74e2cf7fc139?source=post_page-----84461368df18--------------------------------)'
- en: References
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料
- en: (1) H. Liu, C. Li, Q. Wu, Y. J. Lee, [Visual Instruction Tuning](https://llava-vl.github.io/)
    (2023).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: (1) H. Liu, C. Li, Q. Wu, Y. J. Lee，[视觉指令调优](https://llava-vl.github.io/) (2023)。
- en: (2) Stability AI, [Stability AI Launches the First of its StableLM Suite of
    Language Models](https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models)
    (2023).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: (2) Stability AI，[Stability AI推出首款StableLM语言模型套件](https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models)
    (2023)。
- en: (3) Together, [RedPajama, a project to create leading open-source models, starts
    by reproducing LLaMA training dataset of over 1.2 trillion tokens](https://www.together.xyz/blog/redpajama)
    (2023).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: (3) 一起，[RedPajama，一个创建领先开源模型的项目，首先通过重现LLaMA训练数据集的1.2万亿个标记开始](https://www.together.xyz/blog/redpajama)
    (2023)。
- en: (4) PYSV E.V., [PyCon DE & PyData Berlin 2023](https://2023.pycon.de/) (2023).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: (4) PYSV E.V., [PyCon DE & PyData Berlin 2023](https://2023.pycon.de/)（2023）。
- en: (5) M. Burgess, [ChatGPT Has a Big Privacy Problem](https://www.wired.com/story/italy-ban-chatgpt-privacy-gdpr/)
    (2023).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: (5) M. Burgess，[ChatGPT 面临严重的隐私问题](https://www.wired.com/story/italy-ban-chatgpt-privacy-gdpr/)（2023）。
- en: (6) OpenAI, [Introducing ChatGPT](https://openai.com/blog/chatgpt) (2023).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: (6) OpenAI，[介绍ChatGPT](https://openai.com/blog/chatgpt)（2023）。
- en: (7) OpenAI, [GPT-4 is OpenAI’s most advanced system, producing safer and more
    useful responses](https://openai.com/product/gpt-4) (2023).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: (7) OpenAI，[GPT-4是OpenAI最先进的系统，能够产生更安全、更有用的回应](https://openai.com/product/gpt-4)（2023）。
- en: (8) OpenAI, [Learning from human preferences](https://openai.com/research/learning-from-human-preferences)
    (2023).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: (8) OpenAI，[从人类偏好中学习](https://openai.com/research/learning-from-human-preferences)（2023）。
- en: (9) Heartex Labs, [heartexlabs/RLHF](https://github.com/heartexlabs/RLHF) (2023).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: (9) Heartex Labs，[heartexlabs/RLHF](https://github.com/heartexlabs/RLHF)（2023）。
- en: (10) Heartex Labs, [Implementing RLHF with Custom Datasets](https://github.com/heartexlabs/RLHF/blob/master/tutorials/RLHF_with_Custom_Datasets.ipynb)
    (2023).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: (10) Heartex Labs，[使用自定义数据集实现RLHF](https://github.com/heartexlabs/RLHF/blob/master/tutorials/RLHF_with_Custom_Datasets.ipynb)（2023）。
- en: (11) I. Montani, [Incorporating LLMs into practical NLP workflows](https://speakerdeck.com/inesmontani/incorporating-llms-into-practical-nlp-workflows)
    (2023).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: (11) I. Montani，[将LLMs融入实际NLP工作流程](https://speakerdeck.com/inesmontani/incorporating-llms-into-practical-nlp-workflows)（2023）。
- en: (12) Explosion, [explosion/prodigy-openai-recipes](https://github.com/explosion/prodigy-openai-recipes)
    (2023).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: (12) Explosion，[explosion/prodigy-openai-recipes](https://github.com/explosion/prodigy-openai-recipes)（2023）。
- en: (13) D. Dementieva, [dardem/text_detoxification](https://github.com/dardem/text_detoxification)
    (2023).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: (13) D. Dementieva，[dardem/text_detoxification](https://github.com/dardem/text_detoxification)（2023）。
- en: '(14) V. Logacheva1, D. Dementieva1, S. Ustyantsev, D. Moskovskiy, D. Dale,
    I. Krotova, N. Semenov, and A. Panchenko, [ParaDetox: Detoxification with Parallel
    Data](https://aclanthology.org/2022.acl-long.469.pdf) (2022).'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: (14) V. Logacheva1, D. Dementieva1, S. Ustyantsev, D. Moskovskiy, D. Dale, I.
    Krotova, N. Semenov, 和 A. Panchenko，[ParaDetox：使用平行数据进行去毒化](https://aclanthology.org/2022.acl-long.469.pdf)（2022）。
- en: '(15) L. Munn, [Angry by design: toxic communication and technical architectures](https://www.nature.com/articles/s41599-020-00550-7)
    (2020).'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: (15) L. Munn，[设计中的愤怒：有毒沟通与技术架构](https://www.nature.com/articles/s41599-020-00550-7)（2020）。
- en: (16) V. Maggio, [Actionable Machine Learning in the Browser with PyScript](https://speakerdeck.com/leriomaggio/actionable-machine-learning-in-the-browser-with-pyscript)
    (2023).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: (16) V. Maggio，[使用PyScript在浏览器中进行可操作的机器学习](https://speakerdeck.com/leriomaggio/actionable-machine-learning-in-the-browser-with-pyscript)（2023）。
- en: (17) PyScript, [pyscript/pyscript](https://github.com/pyscript/pyscript) (2023).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: (17) PyScript，[pyscript/pyscript](https://github.com/pyscript/pyscript)（2023）。
- en: (18) N. Tamir, [How Are We Managing? Data Teams Management IRL](https://speakerdeck.com/noatamir/how-are-we-managing-data-teams-management-irl)
    (2023).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: (18) N. Tamir，[我们如何管理？数据团队管理现实](https://speakerdeck.com/noatamir/how-are-we-managing-data-teams-management-irl)（2023）。
