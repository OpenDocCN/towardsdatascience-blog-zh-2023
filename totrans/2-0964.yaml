- en: Generative Q&A With GPT 3.5 and Long-Term Memory
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用GPT 3.5和长期记忆的生成式问答
- en: 原文：[https://towardsdatascience.com/generative-question-answering-with-long-term-memory-c280e237b144](https://towardsdatascience.com/generative-question-answering-with-long-term-memory-c280e237b144)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/generative-question-answering-with-long-term-memory-c280e237b144](https://towardsdatascience.com/generative-question-answering-with-long-term-memory-c280e237b144)
- en: Exploring the new world of retrieval-augmented ML
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索增强检索的机器学习新世界
- en: '[](https://jamescalam.medium.com/?source=post_page-----c280e237b144--------------------------------)[![James
    Briggs](../Images/cb34b7011748e4d8607b7ff4a8510a93.png)](https://jamescalam.medium.com/?source=post_page-----c280e237b144--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c280e237b144--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c280e237b144--------------------------------)
    [James Briggs](https://jamescalam.medium.com/?source=post_page-----c280e237b144--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://jamescalam.medium.com/?source=post_page-----c280e237b144--------------------------------)[![James
    Briggs](../Images/cb34b7011748e4d8607b7ff4a8510a93.png)](https://jamescalam.medium.com/?source=post_page-----c280e237b144--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c280e237b144--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c280e237b144--------------------------------)
    [James Briggs](https://jamescalam.medium.com/?source=post_page-----c280e237b144--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c280e237b144--------------------------------)
    ·6 min read·Feb 17, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c280e237b144--------------------------------)
    ·6分钟阅读·2023年2月17日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c5e51b39e15d83cb4ab0c9ed3580abef.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c5e51b39e15d83cb4ab0c9ed3580abef.png)'
- en: Photo by [Bret Kavanaugh](https://unsplash.com/@bretkavanaugh?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral). *Originally
    published at* [*pinecone.io*](https://www.pinecone.io/learn/openai-gen-qa/), where
    the author is employed*.*
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Bret Kavanaugh](https://unsplash.com/@bretkavanaugh?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) 提供。*最初发布于*
    [*pinecone.io*](https://www.pinecone.io/learn/openai-gen-qa/)，作者在该网站工作*。
- en: Generative AI sparked several *“wow”* moments in 2022\. From generative art
    tools like OpenAI’s DALL-E 2, Midjourney, and Stable Diffusion, to the next generation
    of **L**arge **L**anguage **M**odels like OpenAI’s GPT-3.5 generation models,
    BLOOM, and chatbots like LaMDA and ChatGPT.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能在2022年激发了几次*“哇”*的时刻。从像OpenAI的DALL-E 2、Midjourney和Stable Diffusion这样的生成艺术工具，到像OpenAI的GPT-3.5这一代模型、BLOOM以及LaMDA和ChatGPT这样的聊天机器人。
- en: 'It’s hardly surprising that Generative AI is experiencing a boom in interest
    and innovation [1]. Yet, this marks *just* the first year of widespread adoption
    of generative AI: The early days of a new field poised to disrupt how we interact
    with machines.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能（Generative AI）正经历兴趣和创新的蓬勃发展，这并不令人惊讶[1]。然而，这仅仅是生成式人工智能广泛应用的第一年：这是一个新兴领域的早期阶段，准备颠覆我们与机器互动的方式。
- en: One of the most thought-provoking use cases belongs to **G**enerative **Q**uestion-
    **A**nswering (GQA). Using GQA, we can sculpt human-like interaction with machines
    for information retrieval (IR).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最具启发性的用例之一属于**G**enerative **Q**uestion-**A**nswering（GQA）。通过使用GQA，我们可以为信息检索（IR）塑造类人互动。
- en: We all use IR systems every day. Google search indexes the web and retrieves
    relevant information to your search terms. Netflix uses your behavior and history
    on the platform to recommend new TV shows and movies, and Amazon does the same
    with products [2].
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们每天都在使用信息检索系统。谷歌搜索对网络进行索引，并根据你的搜索词检索相关信息。Netflix利用你在平台上的行为和历史推荐新的电视节目和电影，而亚马逊在产品方面也有类似的做法[2]。
- en: These applications of IR are world-changing. Yet, they may be little more than
    a faint echo of what we will see in the coming months and years with the combination
    of IR and GQA.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这些信息检索（IR）的应用具有改变世界的潜力。然而，它们可能仅仅是我们在未来几个月和几年中看到的IR与生成式问答（GQA）结合的微弱回响。
- en: Imagine a Google that can answer your queries with an intelligent and insightful
    summary based on the top 20 pages — highlighting key points and information sources.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，一个谷歌可以基于前20页的智能和深刻的摘要回答你的查询——突出关键点和信息来源。
- en: The technology available today already makes this possible and surprisingly
    easy. This article will look at retrieval-augmented GQA and how to implement it
    with Pinecone and OpenAI.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 现有技术已经使这变得可能且出乎意料的简单。本文将探讨增强检索的GQA及其如何与Pinecone和OpenAI一起实现。
- en: The most straightforward GQA system requires nothing more than a user text query
    and a large language model (LLM).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 最直接的 GQA 系统只需要用户文本查询和一个大型语言模型（LLM）。
- en: '![](../Images/34a8a8de6ed776b5238ad9f1c343327e.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/34a8a8de6ed776b5238ad9f1c343327e.png)'
- en: Simplest GQA system.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的 GQA 系统。
- en: We can access one of the most advanced LLMs in the world via [OpenAI](https://platform.openai.com).
    To start, we sign up for an [API key](https://beta.openai.com).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过 [OpenAI](https://platform.openai.com) 访问世界上最先进的 LLM 之一。首先，我们需要注册一个 [API
    密钥](https://beta.openai.com)。
- en: '![](../Images/1c3298a93f8d1045bacd636fe8acf1d2.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1c3298a93f8d1045bacd636fe8acf1d2.png)'
- en: After signing up for an account, API keys can be created by clicking on your
    account (top-right) > View API keys > Create new secret key.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 注册账户后，可以通过点击你的账户（右上角）> 查看 API 密钥 > 创建新秘密密钥来创建 API 密钥。
- en: Then we switch to a Python file or notebook, install some prerequisites, and
    initialize our connection to OpenAI.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们切换到 Python 文件或笔记本，安装一些先决条件，并初始化与 OpenAI 的连接。
- en: 'From here, we can use the OpenAI completion endpoint to ask a question like
    *“who was the 12th person on the moon and when did they land?”*:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，我们可以使用 OpenAI 完成端点来询问类似于 *“谁是第十二位登月者，他们何时着陆？”* 的问题：
- en: We get an accurate answer immediately. Yet, this question is relatively easy,
    what happens if we ask about a lesser-known topic?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们立即得到一个准确的答案。然而，这个问题相对简单，如果我们问一个鲜为人知的话题会发生什么呢？
- en: Although this answer is technically correct, it isn’t an answer. It tells us
    to use a supervised training method and learn the relationship between sentences.
    Both of these facts are true but do not answer the original question.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个答案在技术上是正确的，但它并不是一个真正的答案。它告诉我们使用监督学习方法来学习句子之间的关系。这两个事实都是正确的，但并没有回答原始问题。
- en: There are two options for allowing our LLM to better understand the topic and,
    more precisely, answer the question.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种方法可以让我们的 LLM 更好地理解主题，并更准确地回答问题。
- en: We fine-tune the LLM on text data covering the domain of fine-tuning sentence
    transformers.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们对包含微调句子转换器领域的文本数据进行 LLM 微调。
- en: We use *retrieval-augmented generation*, meaning we add an information retrieval
    component to our GQA process. Adding a retrieval step allows us to retrieve relevant
    information and feed this into the LLM as a *secondary source* of information.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用*检索增强生成*，即我们在 GQA 过程中添加一个信息检索组件。添加检索步骤可以让我们检索相关信息，并将其作为*二级信息来源*输入到 LLM 中。
- en: In the following sections, we will outline how to implement option **two**.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将概述如何实现**第二**种选择。
- en: Building a Knowledge Base
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建知识库
- en: With option **two** of implementing retrieval, we need an external “*knowledge
    base”*. A knowledge base acts as the place where we store information and as the
    system that effectively retrieves this information.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 实现检索的**第二**种选择，我们需要一个外部的“*知识库*”。知识库既是存储信息的地方，又是有效检索这些信息的系统。
- en: A knowledge base is a store of information that can act as an external reference
    for GQA models. We can think of it as the *“long-term memory”* for AI systems.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 知识库是一个信息存储库，可以作为 GQA 模型的外部参考。我们可以将其视为 AI 系统的*“长期记忆”*。
- en: We refer to knowledge bases that can enable the retrieval of semantically relevant
    information as *vector databases*.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将可以检索语义相关信息的知识库称为*向量数据库*。
- en: A vector database stores vector representations of information encoded using
    specific ML models. These models have an “understanding” of language and can encode
    passages with similar meanings into a similar vector space and dissimilar passages
    into a dissimilar vector space.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 向量数据库存储使用特定 ML 模型编码的信息的向量表示。这些模型对语言有一定的“理解”，可以将具有相似含义的段落编码到相似的向量空间，将不相似的段落编码到不同的向量空间。
- en: '![](../Images/2946718bf57e92359f02796ef22df104.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2946718bf57e92359f02796ef22df104.png)'
- en: 'We can achieve this with OpenAI via the embed endpoint:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过 OpenAI 的嵌入端点实现这一点：
- en: We’ll need to repeat this embedding process over many records that will act
    as our pipeline’s external source of information. These records still need to
    be downloaded and prepared for embedding.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要对许多记录重复执行嵌入过程，这些记录将作为我们管道的外部信息来源。这些记录仍需下载并准备好以进行嵌入。
- en: Data Preparation
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据准备
- en: 'The dataset we will use in our knowledge base is the `jamescalam/youtube-transcriptions`
    dataset hosted on Hugging Face *Datasets*. It contains transcribed audio from
    several ML and tech YouTube channels. We download it with the following:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在知识库中使用的数据集是托管在Hugging Face *Datasets*上的`jamescalam/youtube-transcriptions`数据集。它包含来自几个ML和技术YouTube频道的音频转录。我们用以下方式下载它：
- en: The dataset contains many small snippets of text data. We need to merge several
    snippets to create more substantial chunks of text that contain more meaningful
    information.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包含许多小的文本片段。我们需要合并几个片段，以创建包含更多有意义信息的更大文本块。
- en: With the text chunks created, we can begin initializing our knowledge base and
    populating it with our data.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 创建文本块后，我们可以开始初始化我们的知识库，并用数据填充它。
- en: Creating the Vector Database
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建向量数据库
- en: The vector database is the storage and retrieval component in our pipeline.
    We use Pinecone as our vector database. For this, we need to [sign up for a free
    API key](https://app.pinecone.io/) and enter it below, where we create the index
    for storing our data.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 向量数据库是我们管道中的存储和检索组件。我们使用Pinecone作为我们的向量数据库。为此，我们需要[注册一个免费的API密钥](https://app.pinecone.io/)，并在下面输入它，以创建用于存储数据的索引。
- en: 'Then we embed and index a dataset like so:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们这样嵌入和索引数据集：
- en: We’re ready to combine OpenAI’s `Completion` and `Embedding` endpoints with
    our Pinecone vector database to create a retrieval-augmented GQA system.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们准备将OpenAI的`Completion`和`Embedding`端点与我们的Pinecone向量数据库结合，创建一个检索增强GQA系统。
- en: OP Stack
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OP Stack
- en: The OpenAI Pinecone (OP) stack is an increasingly popular choice for building
    high-performance AI apps, including retrieval-augmented GQA.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI Pinecone（OP）技术栈是构建高性能AI应用（包括检索增强GQA）的越来越受欢迎的选择。
- en: 'Our pipeline during *query time* consists of the following:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*查询时间*的管道包括以下内容：
- en: OpenAI `Embedding` endpoint to create vector representations of each query.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: OpenAI `Embedding`端点用于创建每个查询的向量表示。
- en: Pinecone vector database to search for relevant passages from the database of
    previously indexed contexts.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pinecone向量数据库用于从以前索引的上下文数据库中搜索相关的段落。
- en: OpenAI `Completion` endpoint to generate a natural language answer considering
    the retrieved contexts.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: OpenAI `Completion`端点用于生成自然语言答案，考虑到检索到的上下文。
- en: '![](../Images/5cafc844cc7581526b3e836707a46da5.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5cafc844cc7581526b3e836707a46da5.png)'
- en: We start by encoding queries using the same encoder model to create a query
    vector `xq`.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先使用相同的编码器模型对查询进行编码，以创建查询向量`xq`。
- en: The query vector `xq` is used to query Pinecone via `index.query`, and previously
    indexed passage vectors are compared to find the most similar matches - returned
    in `res` above.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 查询向量`xq`用于通过`index.query`查询Pinecone，并与之前索引的段落向量进行比较，以找到最相似的匹配项——在上面的`res`中返回。
- en: Using these returned contexts, we can construct a prompt instructing the generative
    LLM to answer the question based on the retrieved contexts. To keep things simple,
    we will do all this in a function called `retrieve`.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些返回的上下文，我们可以构建一个提示，指示生成LLM根据检索到的上下文回答问题。为了简单起见，我们将在一个名为`retrieve`的函数中完成所有这些工作。
- en: Note that the generated *expanded query* (`query_with_contexts`) has been shortened
    for readability.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，为了可读性，生成的*扩展查询*（`query_with_contexts`）已被缩短。
- en: From `retrieve`, we produce a longer prompt ( `query_with_contexts`) containing
    some instructions, the contexts, and the original question.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 从`retrieve`中，我们生成一个更长的提示（`query_with_contexts`），其中包含一些指令、上下文和原始问题。
- en: The prompt is then fed into the generative LLM via OpenAI’s `Completion` endpoint.
    As before, we use the `complete` function to handle everything.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，提示通过OpenAI的`Completion`端点输入生成LLM。像以前一样，我们使用`complete`函数处理所有内容。
- en: Because of the additional *“source knowledge”* (information fed directly into
    the model), we have eliminated the hallucinations of the LLM — producing accurate
    answers to our question.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 由于额外的*“源知识”*（直接输入模型的信息），我们消除了LLM的幻觉——生成了准确的回答。
- en: Beyond providing more factual answers, we also have the *sources* of information
    from Pinecone used to generate our answer. Adding this to downstream tools or
    apps can help improve user trust in the system. Allowing users to confirm the
    reliability of the information being presented to them.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 除了提供更多的事实性回答外，我们还有Pinecone提供的*信息来源*用于生成我们的回答。将其添加到下游工具或应用中可以帮助提高用户对系统的信任，让用户确认所提供信息的可靠性。
- en: That’s it for this walkthrough of retrieval-augmented **G**enerative **Q**uestion
    **A**nswering (GQA) systems.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是关于检索增强型**生成式问答**（GQA）系统的演示。
- en: As demonstrated, LLMs alone work incredibly well but struggle with more niche
    or specific questions. This often leads to *hallucinations* that are rarely obvious
    and likely to go undetected by system users.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所示，单独使用大型语言模型（LLMs）效果非常好，但在面对更小众或具体的问题时却常常表现不佳。这通常会导致*幻觉*，这些幻觉不易被发现，且可能会被系统用户忽视。
- en: By adding a *“long-term memory”* component to our GQA system, we benefit from
    an external knowledge base to improve system factuality and user trust in generated
    outputs.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 通过为我们的GQA系统添加*“长期记忆”*组件，我们可以利用外部知识库来提高系统的准确性和用户对生成内容的信任。
- en: Naturally, there is vast potential for this type of technology. Despite being
    a new technology, we are already seeing its use in [YouChat](https://blog.you.com/introducing-youchat-the-ai-search-assistant-that-lives-in-your-search-engine-eff7badcd655),
    several [podcast search apps](https://huberman.rile.yt), and rumors of its upcoming
    use as a challenger to Google itself [3].
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 自然，这类技术具有广泛的潜力。尽管它是一项新技术，但我们已经在[YouChat](https://blog.you.com/introducing-youchat-the-ai-search-assistant-that-lives-in-your-search-engine-eff7badcd655)、一些[播客搜索应用](https://huberman.rile.yt)中看到它的应用，并且有传闻称它将成为对抗谷歌的挑战者[3]。
- en: There is potential for disruption in any place where the need for information
    exists, and retrieval-augmented GQA represents one of the best opportunities for
    taking advantage of the outdated information retrieval systems in use today.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 任何需要信息的地方都有可能出现颠覆，而检索增强型GQA代表了利用当前过时信息检索系统的最佳机会之一。
- en: '[1] E. Griffith, C. Metz, [A New Area of A.I. Booms, Even Amid the Tech Gloom](https://www.nytimes.com/2023/01/07/technology/generative-ai-chatgpt-investments.html)
    (2023), NYTimes'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] E. Griffith, C. Metz, [《人工智能的新领域蓬勃发展，即使在技术低迷时》](https://www.nytimes.com/2023/01/07/technology/generative-ai-chatgpt-investments.html)（2023），纽约时报'
- en: '[2] G. Linden, B. Smith, J. York, [Amazon.com Recommendations: Item-to-Item
    Collaborative Filtering](https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf)
    (2003), IEEE'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] G. Linden, B. Smith, J. York, [《亚马逊推荐：物品间协作过滤》](https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf)（2003），IEEE'
- en: '[3] T. Warren, [Microsoft to challenge Google by integrating ChatGPT with Bing
    search](https://www.theverge.com/2023/1/4/23538552/microsoft-bing-chatgpt-search-google-competition)
    (2023), The Verge'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] T. Warren, [《微软通过将ChatGPT与Bing搜索整合来挑战谷歌》](https://www.theverge.com/2023/1/4/23538552/microsoft-bing-chatgpt-search-google-competition)（2023），The
    Verge'
- en: '*Originally published at* [*https://www.pinecone.io*](https://www.pinecone.io/learn/openai-gen-qa/)*.*'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*最初发表于* [*https://www.pinecone.io*](https://www.pinecone.io/learn/openai-gen-qa/)
    *。*'
- en: '**All images by the author except where stated otherwise*'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**所有图片均为作者提供，除非另有说明**'
