- en: 'Using ChatGPT as a Creative Writing Partner — Part 1: Prose'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/using-chatgpt-as-a-creative-writing-partner-part-1-prose-dc9a9994d41f](https://towardsdatascience.com/using-chatgpt-as-a-creative-writing-partner-part-1-prose-dc9a9994d41f)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How the latest language model from OpenAI can help write poetry, fiction, and
    screenplays
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://robgon.medium.com/?source=post_page-----dc9a9994d41f--------------------------------)[![Robert
    A. Gonsalves](../Images/96b4da0f602a1cd9d1e1d2917868cbee.png)](https://robgon.medium.com/?source=post_page-----dc9a9994d41f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dc9a9994d41f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dc9a9994d41f--------------------------------)
    [Robert A. Gonsalves](https://robgon.medium.com/?source=post_page-----dc9a9994d41f--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----dc9a9994d41f--------------------------------)
    ·15 min read·Jan 4, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c9f6f24f0cb3dc4b5201c051ddc61997.png)'
  prefs: []
  type: TYPE_IMG
- en: '**“an illustration of a woman typing on a laptop with a helpful toy robot,”**
    Image created using an AI image creation program, Midjourney, and edited by the
    author'
  prefs: []
  type: TYPE_NORMAL
- en: If you have been reading my posts on Medium, you will know that I have been
    writing about creative uses of AI since August 2020\. I often write about generating
    digital art, but I occasionally write about using AI for other creative purposes,
    like writing prose and composing music. When I heard that OpenAI released a new
    language model called ChatGPT [1], I jumped right in and tested it for creative
    writing.
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is the first of a three-part series on using ChatGPT as a writing partner.
    The series will cover writing prose, [composing music](/using-chatgpt-as-a-creative-writing-partner-part-2-music-d2fd7501c268),
    and creating picture books.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this article, I will review some background info on ChatGPT and then show
    the results of my experiments in generating text for various creative projects:'
  prefs: []
  type: TYPE_NORMAL
- en: Writing Haikus
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Creating plot summaries for new novels
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Creating new screenplays for TV shows and movies
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I’ll finish by giving you my general observations on using the model with some
    possible next steps for future exploration.
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ChatGPT is the latest text generation model from OpenAI. They offer the system
    as a “Free Research Preview.” You can sign in with an email account or use an
    existing Google or Microsoft account. When you sign in, you see the home screen
    with examples, capabilities, and limitations.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eac1f8c878767369af2b409a55acdfa0.png)'
  prefs: []
  type: TYPE_IMG
- en: '**ChatGPT User Interface**, Image by Author'
  prefs: []
  type: TYPE_NORMAL
- en: To start a thread, I asked a question like this.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/263633d3e46a017a0012627ee862e121.png)'
  prefs: []
  type: TYPE_IMG
- en: '**ChatGPT Answers a Question**, Image by Author'
  prefs: []
  type: TYPE_NORMAL
- en: Note I used the same question in my [AI 8 Ball](https://medium.com/towards-data-science/building-an-ai-8-ball-with-roberta-2bfbf6f5519b)
    project from 2020\. You can see above that ChatGPT is familiar with Mattel’s Magic
    8-Ball, and started the answer using one of the 20 canned responses. But ChatGPT
    went further to give some background info, which was nice. When I hit the **Try
    again** button, it generated similar text. But I used the cool new feature and
    asked the system a follow-up question.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/70e1d2c75cb3db7ee061228a4ff8ebbd.png)'
  prefs: []
  type: TYPE_IMG
- en: '**ChatGPT Answers a Follow-up Question**, Image by Author'
  prefs: []
  type: TYPE_NORMAL
- en: Notice how ChatGPT remembered the context from the first question, so it knew
    what “it” meant and answered appropriately. It answered as the Magic 8-Ball would
    have and provided some helpful background information.
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI added a nice feature of keeping a history of your prior chat sessions.
    This allowed me to pick up where I left off to continue the chat thread if needed.
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT Origins
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ChatGPT is based on the GPT-3 large language model from OpenAI [2]. The model
    is huge. It has 175 billion artificial neurons and was trained on about 500 billion
    pieces of text gathered on the web.
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI further trained GPT-3 to create a model called InstructGPT that tries
    to follow the users’ intentions when generating text [3].
  prefs: []
  type: TYPE_NORMAL
- en: Starting with a set of [human]-written prompts and prompts submitted through
    the OpenAI API, we collect a dataset of labeler demonstrations of the desired
    model behavior, which we use to fine-tune GPT-3 using supervised learning. We
    then collect a dataset of rankings of model outputs, which we use to further fine-tune
    this supervised model using reinforcement learning from human feedback. We call
    the resulting models InstructGPT. - Long Ouyang et al. from OpenAI
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ChatGPT is OpenAI’s sibling model to InstructGPT, which was trained to work
    interactively with users [1].
  prefs: []
  type: TYPE_NORMAL
- en: We’ve trained a model called ChatGPT which interacts in a conversational way.
    The dialogue format makes it possible for ChatGPT to answer followup questions,
    admit its mistakes, challenge incorrect premises, and reject inappropriate requests.
    - OpenAI
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Societal Bias in Language Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Note that, like most large language models, InstructGPT and ChatGTP both suffer
    from exposure to implicit social bias and toxicity in the original training data.
    To combat this, OpenAI actively worked to “align” the models to be helpful, honest,
    and harmless [3].
  prefs: []
  type: TYPE_NORMAL
- en: We make progress on aligning language models by training them to act in accordance
    with the user’s intention. This encompasses both explicit intentions such as following
    instructions and implicit intentions such as staying truthful, and not being biased,
    toxic, or otherwise harmful. — Long Ouyang et al. from OpenAI
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: However, the authors state that the new model shows only small improvements
    in toxicity over GPT-3, but no improvement in bias.
  prefs: []
  type: TYPE_NORMAL
- en: How OpenAI Fine-tuned ChatGPT
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here are the steps OpenAI used for training their latest system. PPO stands
    for Proximal Policy Optimization [4], a new form of reinforcement learning for
    improved outputs.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/07f9f062b2248abd1fbf1ae03700e525.png)![](../Images/00a7bdff71120a9586f45cbc0ac93c27.png)![](../Images/22e0f37c7b3dced6018998fb9d557ae8.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Diagram Showing Supervised Fine-tuning, Reward Model Training, and Reinforcement
    Learning via Proximal Policy Optimization**, Source [OpenAI](https://arxiv.org/pdf/2203.02155.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: The “labelers” are actual humans that created ideal outputs in Step 1 and scored
    samples of generated text in Step 2 that were used to train a Reward Model (RM.)
    In Step 3, the RM was used to predict which output the labelers would prefer,
    and the results were used to refine the GPT-3 model using the PPO algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Writing Haikus
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/4db69736a32c0a5fd428069ccfeb3286.png)'
  prefs: []
  type: TYPE_IMG
- en: “**golden leaves drift down, Autumn breeze blows through the town, nature’s
    tapestry**,” Midjourney Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: My first experiment with ChatGPT was creating Haikus, a form of poetry that
    originated in Japan. As I discussed in a [previous post](/deep-haiku-teaching-gpt-j-to-compose-with-syllable-patterns-5234bca9701),
    language models seem to have difficulty generating prose with a set meter, like
    the 5–7–5 syllable structure typically used for Haikus. I noticed a distinct improvement
    with ChatGPT, however. You can see this in my interaction below, with the responses
    in italics.
  prefs: []
  type: TYPE_NORMAL
- en: '*Write a Haiku about Autumn.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Leaves falling softly down
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Autumn breeze rustles through town
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Nature’s tapestry.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*This is good, but use five syllables in the first line. The second and third
    lines are fine.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Golden leaves drift down
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Autumn breeze blows through the town
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Nature’s tapestry
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The Haiku is pretty good! The imagery of leaves falling down and the autumn
    breeze blowing through the town captures the feeling of the changing of the seasons.
    But notice how the first attempt has a 6–7–5 syllable scheme. I then prompted
    it to refine the first line, and, sure enough, it created the second attempt with
    a 5–7–5 scheme, and it retained the essence of the thought.
  prefs: []
  type: TYPE_NORMAL
- en: Here are a couple of additional examples.
  prefs: []
  type: TYPE_NORMAL
- en: '*Write a Haiku about laughter.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Laughter like a bell
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Ringing out across the land
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Bringing joy to all.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Write a Haiku about the Python programming language.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Python, serpent-like
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Slithering through code with grace
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Power in simplicity.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*This is good, but use five syllables in the last line. The first and second
    lines are OK.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Python, serpent-like
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Slithering through code with grace
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Power in its ease.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The one about laughter was pretty good with the metaphor about ringing a bell.
    And it hit the expected 5–7–5 count for syllables in a Haiku. The one about Python,
    is good, too, continuing with the analogy with a snake. It came out initially
    with a 5–7–7 scheme, but when I prompted it, ChatGPT generated one with the correct
    syllable count and kept the original meaning intact.
  prefs: []
  type: TYPE_NORMAL
- en: Next, I’ll share the results of using the system to create new titles and plots
    for novels.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/079e82ebec2d9b9fa6ff20ee83ae47bc.png)'
  prefs: []
  type: TYPE_IMG
- en: “**stack of books on a desk with a pen and pad of paper,”** Midjourney Image
    by Author
  prefs: []
  type: TYPE_NORMAL
- en: Creating Titles and Plots for Novels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Similar to my [PlotJam project](/got-writers-block-it-s-plotjam-to-the-rescue-e555db9f3272),
    where I used a fine-tuned GPT-2 model, I asked ChatGPT to generate new titles
    and plot summaries for novels in a given genre. Here are the results.
  prefs: []
  type: TYPE_NORMAL
- en: '*Create a title and plot summary for a new historical fiction novel.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Title: “The Last Stand at Little Bighorn”'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Plot summary: In the summer of 1876, a band of Lakota Sioux and Cheyenne warriors,
    led by the legendary chiefs Sitting Bull and Crazy Horse, make their last stand
    against the advancing U.S. Army at the Battle of Little Bighorn. As the two sides
    clash in a brutal and bloody fight to the death, the young warrior White Buffalo
    must choose between his loyalty to his tribe and his love for a white woman named
    Sarah, who has come to the battlefield as a nurse for the wounded soldiers. With
    the fate of the Sioux nation hanging in the balance, White Buffalo must navigate
    the complex and dangerous world of warfare, honor, and love to find his own path.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*The setting is OK, but the plot seems a bit corny. Try again with a new type
    of struggle for the White Buffalo character.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Title: “The Last Stand at Little Bighorn”'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Plot summary: […] As the two sides clash in a brutal and bloody battle, the
    young warrior White Buffalo must confront his own personal struggles and doubts.
    Torn between his loyalty to his tribe and his desire for peace, White Buffalo
    must find a way to reconcile his beliefs and his actions in order to defend his
    people and their way of life. Amidst the chaos and violence of the battle, White
    Buffalo must make difficult choices that will shape the future of his tribe and
    his own destiny.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: All right, not bad. I like that the story seems to be told from the perspective
    of one of the Native Americans. But, as you can see, I had to steer the system
    away from the clichéd “Romeo and Juliet” plot for the second iteration. I deleted
    the repeated part in the second plot summary for readability. As they say in “the
    biz,” ChatGPT is OK with taking notes.
  prefs: []
  type: TYPE_NORMAL
- en: Here’s another example with three rounds of interaction.
  prefs: []
  type: TYPE_NORMAL
- en: '*Create a title and plot summary for a new science fiction novel.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Title: “The Last Sentinel”'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Plot Summary: In a distant future, humanity has spread out across the galaxy
    and established a number of colonies on other planets. However, a great threat
    looms on the horizon in the form of a hostile alien race known as the Xarga. As
    the last remaining sentinel, a lone soldier named Jake must embark on a mission
    to discover the source of the Xarga and find a way to stop them before they wipe
    out all of humanity. Along the way, Jake must overcome incredible odds and make
    difficult choices in order to save the human race.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*OK, but use a more futuristic name for Jake.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Title: “The Last Sentinel”'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Plot Summary: […] As the last remaining sentinel, a lone soldier named Jaxon
    must embark on a mission to discover the source of the Xarga and find a way to
    stop them before they wipe out all of humanity. Along the way, Jaxon must overcome
    incredible odds and make difficult choices in order to save the human race.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*OK, explain briefly how Jaxon stops the Xarga.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As the last remaining sentinel, Jaxon is the only hope for humanity in their
    battle against the Xarga. After traveling across the galaxy and facing many challenges
    along the way, Jaxon finally reaches the source of the Xarga threat. There, he
    discovers that the Xarga are controlled by a single, central intelligence. Jaxon
    uses his advanced technology and combat skills to defeat this central intelligence,
    thereby freeing the Xarga from its control and ending the threat to humanity.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is a good start, too. However, the summary hints at a lot of action and
    suspense, but it’s missing some important details of what the book is really about,
    who the main character is, and the motivation driving the protagonist. As a side
    note, I think it’s funny that ChatGPT thinks it can make a name seem more futuristic
    by adding the letter “X.” And I like that a “single, central intelligence controls
    the Xarga.” ChatGPT seems to be following that old piece of advice for new authors,
    “Write what you know.” 🙂
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d7cf3ab77dae914a22e309d99cadfc70.png)'
  prefs: []
  type: TYPE_IMG
- en: '**“movie set with a script on a table and coffee,”** Midjourney Image by Author,
    based on a Photo by [Jakob Owens](https://unsplash.com/@jakobowens1) on [Unsplash](https://unsplash.com/@jakobowens1)'
  prefs: []
  type: TYPE_NORMAL
- en: Writing Screenplays
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I found that ChatGPT can be a good writing partner for creating screenplays.
    Similar to what I did with my [GreenLit](/greenlit-using-gpt-j-with-multi-task-learning-to-create-new-screenplays-54a2d04f761c)
    project, I experimented with the new model for creating a title, plot summary,
    and the first page of a script for a show given a genre. Here’s the initial interaction.
  prefs: []
  type: TYPE_NORMAL
- en: '*Create five titles and plot summaries for a new streaming series about a bank
    heist.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The Heist” — When a group of skilled thieves team up to pull off the perfect
    bank heist, they quickly realize that the real challenge is getting out alive
    with the loot. As the police close in and the stakes get higher, the team must
    rely on their expertise and trust in one another to outwit the authorities and
    make a clean getaway.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “Inside Job” — When a group of disgruntled former employees hatch a plan to
    rob the bank where they used to work, they enlist the help of a seasoned thief
    to pull off the heist. As they dig deeper into the bank’s operations, they uncover
    a web of corruption and greed that puts them in the crosshairs of both the law
    and their former employers.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The Bank Job” — When a group of friends decide to rob a local bank in order
    to pay off their debts and start anew, they quickly realize that their amateur
    heist skills are no match for the security measures in place. As they struggle
    to outsmart the bank’s high-tech defenses, they must also navigate a series of
    double crosses and personal betrayals that threaten to derail their plans.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The Perfect Score” — When a group of brilliant students decide to pull off
    the perfect bank heist in order to finance their education, they quickly discover
    that their elaborate plan is much more difficult to execute than they anticipated.
    As they navigate the challenges of pulling off the heist and evading the authorities,
    they must also confront their own personal demons and insecurities in order to
    succeed.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The Big Score” — When a group of seasoned thieves come together to plan the
    heist of a lifetime, they quickly realize that pulling off the job will require
    more than just their expertise. As they work to gather the resources and personnel
    needed to carry out the heist, they must also navigate a series of personal and
    professional setbacks that threaten to derail their plans.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: These are good, but most of them are fairly generic. They seem like they have
    all been done many times before. It’s almost as if ChatGPT wants to play it safe
    and not go out on a limb with an odd take on a story idea. However, I did like
    the one about the group of students/thieves because it took on an interesting
    angle. But it needed a unique title.
  prefs: []
  type: TYPE_NORMAL
- en: '*The Perfect Score looks good, but suggest some titles that haven’t been used
    before. Lean into the student angle. And just the titles, please.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Here are five potential new titles for a streaming series about a bank heist
    featuring students:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The Student Heist”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The Class of Crime”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The Grades of Greed”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The Academic Heist”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The Campus Caper”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: These were all pretty good, but bland. And not too surprisingly, they all start
    with the article “the.” Note that if I didn’t ask for just the titles, it would
    have created new plot summaries.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, I liked “The Grades of Greed” the best, but mostly for the alliteration.
    I then requested ChatGPT to write the first page of the script, after I decided
    to ditch the “the” in the title.
  prefs: []
  type: TYPE_NORMAL
- en: '*These are pretty good. Let’s go with Grades of Greed without the “the.” Please
    write the first page of the script.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Sure! Here is the first page of the script for “Grades of Greed”:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'FADE IN:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: INT. UNIVERSITY LIBRARY — DAY
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We see a close-up of a student’s face, deep in concentration as they study.
    They are surrounded by stacks of books and notes.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'CUT TO:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: INT. UNIVERSITY CAFETERIA — DAY
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We see a group of four students, JESSICA, MIKE, AMY, and NICK, sitting at a
    table together. They all look stressed and tired.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'JESSICA: (frustrated) I can’t believe we have midterms next week. I’m never
    going to be able to afford tuition if I don’t get at least a B+ in Calculus.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'MIKE: (sarcastically) Oh yeah, because that’s the only thing standing between
    us and financial stability.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'AMY: (serious) Actually, Mike, it’s a lot more expensive to repeat a class.
    If we don’t pass, we’ll have to pay for it again next semester.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'NICK: (determined) Well, we can’t let that happen. We need to find a solution.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'JESSICA: (sarcastically) Yeah, like robbing a bank.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The group falls silent for a moment before breaking out into laughter.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: FADE TO BLACK.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: OK, not bad. The dialog seems natural, albeit in a bit of a rush to move the
    plot along. I liked the way the system added emotional cues for the characters’
    lines. This brought some nice color to the script.
  prefs: []
  type: TYPE_NORMAL
- en: However, the characters are a bit bland, as it seemed to only have a bunch of
    white kids in the story based on their first names. This is probably because of
    the societal bias in language models, as I mentioned above. But the system knew
    what to do when I asked it.
  prefs: []
  type: TYPE_NORMAL
- en: '*This is great! But try something similar with a more ethnically diverse group
    of characters.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Sure! Here is the revised first page of the script for “Grades of Greed” featuring
    a more ethnically diverse group of characters:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'FADE IN:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: INT. UNIVERSITY LIBRARY — DAY
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We see a close-up of a student’s face, deep in concentration as they study.
    They are surrounded by stacks of books and notes.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'CUT TO:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: INT. UNIVERSITY CAFETERIA — DAY
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We see a group of four students, TARA, JAVIER, AISHA, and KEN, sitting at a
    table together. They all look stressed and tired.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'TARA: (frustrated) I can’t believe we have midterms next week. I’m never going
    to be able to afford tuition if I don’t get at least a B+ in Calculus.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'JAVIER: (sarcastically) Oh yeah, because that’s the only thing standing between
    us and financial stability.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'AISHA: (serious) Actually, Javier, it’s a lot more expensive to repeat a class.
    If we don’t pass, we’ll have to pay for it again next semester.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'KEN: (determined) Well, we can’t let that happen. We need to find a solution.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'TARA: (sarcastically) Yeah, like robbing a bank.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The group falls silent for a moment before breaking out into laughter.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: FADE TO BLACK.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Sure enough, the system changed the names to have a wider cultural representation.
    I then asked it to tell me what it had in mind for their last names.
  prefs: []
  type: TYPE_NORMAL
- en: '*Thanks. For the credit roll, what are their full names?*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Sure! Here are the full names for the characters in the revised version of
    the script:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: TARA — Tara Patel
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: JAVIER — Javier Rodriguez
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: AISHA — Aisha Khan
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: KEN — Ken Tanaka
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Nice! I’ll send this off to both Netflix and Amazon studios to see if I can
    start a bidding war to fund the project. 😀
  prefs: []
  type: TYPE_NORMAL
- en: Discussion and Next Steps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you saw in my interactions above, ChatGPT may not be able to create good
    long-form prose all on its own, but it works well as an interactive writing partner.
    The system is quite knowledgeable and is a helpful collaborator. When prompted,
    it will create many examples of what you may be looking for, although many of
    its ideas are bland and generic. It takes some work to draw out any interesting
    thoughts, but it can be done.
  prefs: []
  type: TYPE_NORMAL
- en: In the past, when I used large language models like GPT-3, GPT-J, BLOOM, etc.,
    for creative writing, I found that I had to generate many versions of the text
    and then “cherry-pick” the best ones. Even then, the prose didn’t have a well-defined
    beginning, middle, or end. The system just rambled on, and I had to decide when
    to cut it off. ChatGPT, however, seems to respond well to prompts and produce
    nicely composed stretches of text. I found that I rarely used the “spinny” regenerate
    button. Instead, I gave some notes back, and it almost always did what I wanted
    to improve the text.
  prefs: []
  type: TYPE_NORMAL
- en: As you saw in my screenwriting example above, I used a top-down writing process,
    starting with the title and plot, and then moving on to write the dialog and stage
    directions. It would probably be helpful to get ChatGPT to write up and refine
    character sketches for the principals in the story and then map out the storyline
    broken down into acts and scenes. This would help the system create a more cohesive
    narrative over the course of the screenplay.
  prefs: []
  type: TYPE_NORMAL
- en: As I mentioned at the head of this article, my next posts will be on [using
    ChatGTP for creating music](/using-chatgpt-as-a-creative-writing-partner-part-2-music-d2fd7501c268),
    with help from Band in a Box, and writing children’s picture books, with support
    from Midjourney.
  prefs: []
  type: TYPE_NORMAL
- en: More on ChatGPT as a Creative Writing Partner
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here are the next two articles in this series.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/using-chatgpt-as-a-creative-writing-partner-part-2-music-d2fd7501c268?source=post_page-----dc9a9994d41f--------------------------------)
    [## Using ChatGPT as a Creative Writing Partner — Part 2: Music'
  prefs: []
  type: TYPE_NORMAL
- en: How the latest language model from OpenAI can help you compose chords for new
    songs, with music by Band-in-a-Box
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'towardsdatascience.com](/using-chatgpt-as-a-creative-writing-partner-part-2-music-d2fd7501c268?source=post_page-----dc9a9994d41f--------------------------------)
    [](/using-chatgpt-as-a-creative-writing-partner-part-3-picture-books-4f45e5dfe8dd?source=post_page-----dc9a9994d41f--------------------------------)
    [## Using ChatGPT as a Creative Writing Partner — Part 3: Picture Books'
  prefs: []
  type: TYPE_NORMAL
- en: How the latest language model from OpenAI can help you write children’s books
    and create illustrations with Midjourney
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/using-chatgpt-as-a-creative-writing-partner-part-3-picture-books-4f45e5dfe8dd?source=post_page-----dc9a9994d41f--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I want to thank Jennifer Lim and Oliver Strimpel for their help with this project.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] J. Schulman et al., [ChatGPT: Optimizing Language Models for Dialogue](https://openai.com/blog/chatgpt/)
    (2020)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] T. Brown et al., [Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165.pdf)
    (2020)'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] L. Ouyang et al., [Training language models to follow instructions with
    human feedback](https://arxiv.org/pdf/2203.02155.pdf) (2020)'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] J. Schulman et al., [Proximal Policy Optimization Algorithms](https://arxiv.org/pdf/1707.06347.pdf)
    (2017)'
  prefs: []
  type: TYPE_NORMAL
