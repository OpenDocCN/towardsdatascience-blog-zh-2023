- en: Cracking Open the OpenAI (Python) API
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç ´è§£OpenAIï¼ˆPythonï¼‰API
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971](https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971](https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971)
- en: '**A complete beginner-friendly introduction with example code**'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ä¸€ä¸ªå®Œæ•´çš„åˆå­¦è€…å‹å¥½ä»‹ç»ï¼Œé™„ç¤ºä¾‹ä»£ç **'
- en: '[](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)[![Shaw
    Talebi](../Images/1449cc7c08890e2078f9e5d07897e3df.png)](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)[](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)
    [Shaw Talebi](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)[![Shaw
    Talebi](../Images/1449cc7c08890e2078f9e5d07897e3df.png)](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)[](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)
    [Shaw Talebi](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)
    Â·12 min readÂ·Jul 21, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒäº[Towards Data Science](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)
    Â·é˜…è¯»æ—¶é—´12åˆ†é’ŸÂ·2023å¹´7æœˆ21æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/2c856f26ccf574ede1e5d700f75668e9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2c856f26ccf574ede1e5d700f75668e9.png)'
- en: Photo by [Martin Sanchez](https://unsplash.com/@martinsanchez?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±[Martin Sanchez](https://unsplash.com/@martinsanchez?utm_source=medium&utm_medium=referral)æä¾›ï¼Œæ¥æºäº[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: This is the 2nd article in a [series](/a-practical-introduction-to-llms-65194dda1148)
    on using Large Language Models (LLMs) in practice. Here I present a beginner-friendly
    introduction to the OpenAI API. This allows you to go beyond restrictive chat
    interfaces like ChatGPT and to get more out of LLMs for your unique use cases.
    Python example code is provided below and at the [GitHub repository](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/openai-api).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å…³äºåœ¨å®è·µä¸­ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„[ç³»åˆ—æ–‡ç« ](/a-practical-introduction-to-llms-65194dda1148)çš„ç¬¬äºŒç¯‡ã€‚è¿™é‡Œæˆ‘æä¾›äº†ä¸€ä¸ªé€‚åˆåˆå­¦è€…çš„OpenAI
    APIä»‹ç»ã€‚è¿™ä½¿ä½ èƒ½å¤Ÿè¶…è¶ŠåƒChatGPTè¿™æ ·çš„é™åˆ¶æ€§èŠå¤©ç•Œé¢ï¼Œå¹¶ä¸ºä½ çš„ç‹¬ç‰¹ç”¨ä¾‹æ›´å¥½åœ°åˆ©ç”¨LLMsã€‚ä¸‹é¢æä¾›äº†Pythonç¤ºä¾‹ä»£ç å’Œ[GitHubä»“åº“](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/openai-api)ã€‚
- en: 'Table of Contents:'
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç›®å½•ï¼š
- en: Whatâ€™s an API?
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯APIï¼Ÿ
- en: OpenAIâ€™s (Python) API
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: OpenAIçš„ï¼ˆPythonï¼‰API
- en: Getting Started (4 Steps)
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¼€å§‹ä½¿ç”¨ï¼ˆ4ä¸ªæ­¥éª¤ï¼‰
- en: Example Code
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ä»£ç 
- en: In the [first article](/a-practical-introduction-to-llms-65194dda1148) of this
    series, I described [**Prompt Engineering**](/cracking-open-the-openai-python-api-230e4cae7971)
    as the **most accessible way to use LLMs** in practice. The easiest (and most
    popular) way to do this is via tools like ChatGPT, which provide an intuitive,
    no-cost, and no-code way to interact with an LLM.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨[ç¬¬ä¸€ç¯‡æ–‡ç« ](/a-practical-introduction-to-llms-65194dda1148)ä¸­ï¼Œæˆ‘æè¿°äº†[**æç¤ºå·¥ç¨‹**](/cracking-open-the-openai-python-api-230e4cae7971)ä½œä¸º**ä½¿ç”¨LLMsçš„æœ€ä¾¿æ·æ–¹æ³•**ã€‚æœ€ç®€å•ï¼ˆä¹Ÿæ˜¯æœ€æµè¡Œï¼‰çš„æ–¹æ³•æ˜¯é€šè¿‡åƒChatGPTè¿™æ ·çš„å·¥å…·ï¼Œå®ƒä»¬æä¾›äº†ç›´è§‚ã€æ— éœ€æˆæœ¬å’Œæ— éœ€ç¼–ç çš„LLMäº¤äº’æ–¹å¼ã€‚
- en: '[](/a-practical-introduction-to-llms-65194dda1148?source=post_page-----230e4cae7971--------------------------------)
    [## A Practical Introduction to LLMs'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/a-practical-introduction-to-llms-65194dda1148?source=post_page-----230e4cae7971--------------------------------)
    [## LLMsçš„å®ç”¨å…¥é—¨'
- en: 3 levels of using LLMs in practice
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å®è·µä¸­ä½¿ç”¨LLMsçš„3ä¸ªå±‚æ¬¡
- en: towardsdatascience.com](/a-practical-introduction-to-llms-65194dda1148?source=post_page-----230e4cae7971--------------------------------)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/a-practical-introduction-to-llms-65194dda1148?source=post_page-----230e4cae7971--------------------------------)
- en: However, this **ease of use comes at a cost**. Namely, the chat UI is restrictive
    and does not translate well to many practical use cases e.g. building your own
    customer support bot, real-time sentiment analysis of customer reviews, etc.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¿™ç§**ä½¿ç”¨ç®€ä¾¿æ€§æ˜¯æœ‰ä»£ä»·çš„**ã€‚å³èŠå¤©ç•Œé¢å…·æœ‰é™åˆ¶ï¼Œä¸”ä¸é€‚ç”¨äºè®¸å¤šå®é™…åº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚æ„å»ºè‡ªå·±çš„å®¢æˆ·æ”¯æŒæœºå™¨äººã€å®æ—¶åˆ†æå®¢æˆ·è¯„è®ºæƒ…æ„Ÿç­‰ã€‚
- en: In these cases, we can take Prompt Engineering one step further and interact
    with LLMs *programmatically*. One way we can do this is via an API.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥å°†æç¤ºå·¥ç¨‹è¿›ä¸€æ­¥æ¨è¿›ï¼Œé€šè¿‡*ç¼–ç¨‹æ–¹å¼*ä¸LLMsäº’åŠ¨ã€‚å®ç°è¿™ä¸€ç‚¹çš„ä¸€ç§æ–¹æ³•æ˜¯é€šè¿‡APIã€‚
- en: '**1) Whatâ€™s an API?**'
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**1) ä»€ä¹ˆæ˜¯APIï¼Ÿ**'
- en: An **application programming interface (API)** allows you to interact with a
    remote application programmatically. While this might sound technical and scary,
    the idea is super simple. Consider the following analogy.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**åº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£ï¼ˆAPIï¼‰**å…è®¸ä½ ä»¥ç¼–ç¨‹æ–¹å¼ä¸è¿œç¨‹åº”ç”¨ç¨‹åºè¿›è¡Œäº¤äº’ã€‚è™½ç„¶è¿™å¯èƒ½å¬èµ·æ¥æŠ€æœ¯æ€§å¾ˆå¼ºä¸”æœ‰äº›å“äººï¼Œä½†å…¶å®éå¸¸ç®€å•ã€‚è€ƒè™‘ä»¥ä¸‹ç±»æ¯”ã€‚'
- en: Imagine you have an intense craving for the [pupusas](https://en.wikipedia.org/wiki/Pupusa)
    you ate during that summer in El Salvador. Unfortunately, youâ€™re back at home
    and donâ€™t know where to find good Salvadoran food. Lucky for you, however, you
    have a super-foodie friend that knows every restaurant in town.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³è±¡ä¸€ä¸‹ä½ å¯¹åœ¨è¨å°”ç“¦å¤šé‚£ä¸ªå¤å¤©åƒçš„[æ™®æ™®è¨](https://en.wikipedia.org/wiki/Pupusa)äº§ç”Ÿäº†å¼ºçƒˆçš„æ¸´æœ›ã€‚ä¸å¹¸çš„æ˜¯ï¼Œä½ å›åˆ°äº†å®¶é‡Œï¼Œä¸çŸ¥é“åœ¨å“ªé‡Œå¯ä»¥æ‰¾åˆ°å¥½çš„è¨å°”ç“¦å¤šé£Ÿç‰©ã€‚ç„¶è€Œï¼Œä½ æœ‰ä¸€ä¸ªè¶…çº§åƒè´§æœ‹å‹ï¼Œä»–çŸ¥é“åŸé‡Œæ¯ä¸€å®¶é¤é¦†ã€‚
- en: So, you send your friend the text.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œä½ ç»™ä½ çš„æœ‹å‹å‘äº†çŸ­ä¿¡ã€‚
- en: â€œAny good pupusa spots in town?â€
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œåŸé‡Œæœ‰å¥½çš„æ™®æ™®è¨åº—å—ï¼Ÿâ€
- en: Then, a couple of minutes later, you get the response.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œå‡ åˆ†é’Ÿåï¼Œä½ ä¼šæ”¶åˆ°å›å¤ã€‚
- en: â€œYes! Flavors of El Salvador has the best pupusas!â€
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œæ˜¯çš„ï¼è¨å°”ç“¦å¤šé£å‘³çš„é¤å…æœ‰æœ€æ£’çš„æ™®æ™®è¨ï¼â€
- en: While this may seem irrelevant to APIs, this is essentially how they work. You
    send a **request** to a remote application i.e. text your super-foodie friend.
    Then, the remote application sends back a **response** i.e. the text back from
    your friend.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶è¿™ä¼¼ä¹ä¸ API æ— å…³ï¼Œä½†è¿™åŸºæœ¬ä¸Šå°±æ˜¯å®ƒä»¬çš„å·¥ä½œåŸç†ã€‚ä½ å‘è¿œç¨‹åº”ç”¨ç¨‹åºå‘é€ä¸€ä¸ª**è¯·æ±‚**ï¼Œå³ç»™ä½ çš„è¶…çº§åƒè´§æœ‹å‹å‘çŸ­ä¿¡ã€‚ç„¶åï¼Œè¿œç¨‹åº”ç”¨ç¨‹åºä¼šè¿”å›ä¸€ä¸ª**å“åº”**ï¼Œå³ä½ æœ‹å‹çš„å›å¤ã€‚
- en: '![](../Images/d55d67b38e544c96a386e920f92da133.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d55d67b38e544c96a386e920f92da133.png)'
- en: A visual analogy of how APIs work. Image by author.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: API å·¥ä½œçš„å¯è§†åŒ–ç±»æ¯”ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: The difference between an API and the above analogy is instead of sending the
    request with your phoneâ€™s texting app, you use your favorite programming language
    e.g. Python, JavaScript, Ruby, Java, etc. This is great if you are developing
    software where some external information is required because the information retrieval
    can be automated.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: API ä¸ä¸Šè¿°ç±»æ¯”ä¹‹é—´çš„åŒºåˆ«åœ¨äºï¼Œä½ ä¸æ˜¯ç”¨æ‰‹æœºçš„çŸ­ä¿¡åº”ç”¨å‘é€è¯·æ±‚ï¼Œè€Œæ˜¯ä½¿ç”¨ä½ å–œæ¬¢çš„ç¼–ç¨‹è¯­è¨€ï¼Œä¾‹å¦‚ Pythonã€JavaScriptã€Rubyã€Java
    ç­‰ã€‚å¦‚æœä½ æ­£åœ¨å¼€å‘éœ€è¦å¤–éƒ¨ä¿¡æ¯çš„è½¯ä»¶ï¼Œè¿™éå¸¸å¥½ï¼Œå› ä¸ºä¿¡æ¯æ£€ç´¢å¯ä»¥è‡ªåŠ¨åŒ–ã€‚
- en: '**2) OpenAIâ€™s (Python) API**'
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**2) OpenAI çš„ï¼ˆPythonï¼‰API**'
- en: We can use APIs to interact with Large Language Models. A popular one is OpenAIâ€™s
    API, where instead of typing prompts into the ChatGPT web interface, you can send
    them to and from OpenAI using Python.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ API ä¸å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œäº¤äº’ã€‚ä¸€ä¸ªæµè¡Œçš„ API æ˜¯ OpenAI çš„ APIï¼Œä½ å¯ä»¥ä½¿ç”¨ Python å‘ OpenAI å‘é€å’Œæ¥æ”¶æç¤ºï¼Œè€Œä¸æ˜¯åœ¨
    ChatGPT ç½‘ç»œç•Œé¢ä¸­è¾“å…¥æç¤ºã€‚
- en: '![](../Images/49422df67ac7d25c8846a1ee770af4ad.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/49422df67ac7d25c8846a1ee770af4ad.png)'
- en: Visualization of how API calls to OpenAI works. Image by author.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: API è°ƒç”¨åˆ° OpenAI çš„å¯è§†åŒ–ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: This gives virtually anyone access to state-of-the-art LLMs (and other ML models)
    without having to provision the computational resources needed to run them. The
    downside, of course, is OpenAI doesnâ€™t do this as a charity. Each API call costs
    money, but more on that in a bit.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä½¿å¾—å‡ ä¹ä»»ä½•äººéƒ½å¯ä»¥è®¿é—®æœ€å…ˆè¿›çš„LLMï¼ˆå’Œå…¶ä»–MLæ¨¡å‹ï¼‰ï¼Œè€Œæ— éœ€æä¾›è¿è¡Œå®ƒä»¬æ‰€éœ€çš„è®¡ç®—èµ„æºã€‚å½“ç„¶ï¼Œç¼ºç‚¹æ˜¯ OpenAI å¹¶ä¸æ˜¯å‡ºäºæ…ˆå–„ç›®çš„æä¾›è¿™äº›æœåŠ¡ã€‚æ¯æ¬¡
    API è°ƒç”¨éƒ½ä¼šæ”¶è´¹ï¼Œä½†ç¨åä¼šè¯¦ç»†è¯´æ˜ã€‚
- en: Some **notable features** of the API (not available with ChatGPT) are listed
    below.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: API çš„ä¸€äº›**æ˜¾è‘—ç‰¹æ€§**ï¼ˆChatGPT ä¸æä¾›ï¼‰å¦‚ä¸‹ã€‚
- en: '**Customizable system message** (this is set to something like â€œ*I am ChatGPT,
    a large language model trained by OpenAI, based on the GPT-3.5 architecture. My
    knowledge is based on information available up until September 2021\. Todayâ€™s
    date is July 13, 2023.*â€ for ChatGPT)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¯å®šåˆ¶çš„ç³»ç»Ÿæ¶ˆæ¯**ï¼ˆå¯¹äº ChatGPTï¼Œè¿™è®¾ç½®ä¸ºç±»ä¼¼äºâ€œ*æˆ‘æ˜¯ ChatGPTï¼Œä¸€ä¸ªç”± OpenAI è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº GPT-3.5
    æ¶æ„ã€‚æˆ‘çš„çŸ¥è¯†åŸºäºæˆªè‡³ 2021 å¹´ 9 æœˆçš„ä¿¡æ¯ã€‚ä»Šå¤©çš„æ—¥æœŸæ˜¯ 2023 å¹´ 7 æœˆ 13 æ—¥ã€‚*â€çš„å†…å®¹ï¼‰'
- en: '**Adjust input parameters** such as maximum response length, number of responses,
    and temperature (i.e. the â€œrandomnessâ€ of the response).'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è°ƒæ•´è¾“å…¥å‚æ•°**ï¼Œå¦‚æœ€å¤§å“åº”é•¿åº¦ã€å“åº”æ•°é‡å’Œæ¸©åº¦ï¼ˆå³å“åº”çš„â€œéšæœºæ€§â€ï¼‰ã€‚'
- en: Include **images** and **other file types** in prompts
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æç¤ºä¸­**åŒ…å«å›¾åƒ**å’Œ**å…¶ä»–æ–‡ä»¶ç±»å‹**ã€‚
- en: Extract helpful word **embeddings** for downstream tasks
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æå–å¯¹ä¸‹æ¸¸ä»»åŠ¡æœ‰å¸®åŠ©çš„è¯è¯­**åµŒå…¥**ã€‚
- en: '**Input audio** for transcription or translation'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¾“å…¥éŸ³é¢‘**ä»¥è¿›è¡Œè½¬å½•æˆ–ç¿»è¯‘ã€‚'
- en: Model **fine-tuning** functionality
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹**å¾®è°ƒ**åŠŸèƒ½
- en: The OpenAI API has [several models](https://platform.openai.com/docs/models)
    from which to choose. The *best* model to pick will depend on your particular
    use case. Below is a list of the current models available [[1](https://platform.openai.com/docs/models)].
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI API æä¾›äº†[å¤šä¸ªæ¨¡å‹](https://platform.openai.com/docs/models)ä¾›é€‰æ‹©ã€‚é€‰æ‹©å“ªä¸ª*æœ€ä½³*æ¨¡å‹å–å†³äºä½ çš„å…·ä½“ç”¨ä¾‹ã€‚ä¸‹é¢æ˜¯å½“å‰å¯ç”¨æ¨¡å‹çš„åˆ—è¡¨[[1](https://platform.openai.com/docs/models)]ã€‚
- en: '![](../Images/98ce3333b2824ace053715e0867ed296.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
- en: List of available models via the OpenAI API as of Jul 2023\. Image by author.
    [[1](https://platform.openai.com/docs/models)]
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '***Note****: Each item listed above is accompanied by a set of models which
    vary in size and cost. Check* [*documentation*](https://platform.openai.com/docs/models)
    *for the most recent information.*'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '**Pricing & Tokens**'
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While the OpenAI API gives developers easy access to SOTA ML models, one obvious
    downside is that it **costs money**. Pricing is done on a per-token basis (no,
    I donâ€™t mean NFTs or something you use at the arcade).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '**Tokens**, in the context of LLMs, are essentially **a set of numbers representing
    a set of words and characters**. For example, â€œTheâ€ could be a token, â€œ endâ€ (with
    the space) could be another, and â€œ.â€ another.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Thus, the text â€œThe End.â€ would consist of 3 tokens say (73, 102, 6).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1f13c26b8c5b663dd2903f54a9249d13.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
- en: Toy example showing one possible token mapping between text and integers. Image
    by author.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: This is a critical step because **LLMs (i.e. neural networks) do not â€œunderstandâ€
    text directly**. The text must be converted into a numerical representation so
    that the model can perform mathematical operations on the input. Hence, the tokenization
    step.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: The price of an API call depends on the number of tokens used in the prompt
    and the model being prompted. The price per model is available on [OpenAIâ€™s website](https://openai.com/pricing).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '**3) Getting Started (4 Steps)**'
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have a basic understanding of the OpenAI API letâ€™s see how to use
    it. Before we can start coding, we need to set up four things.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '**3.1) Make an Account (you get a $5 API credit for 1st three months)**'
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To make an account go to the [OpenAI API Overview page](https://platform.openai.com/overview),
    and click â€œSign Upâ€ in the top right corner
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Note* â€” If youâ€™ve used ChatGPT before, then you probably already have an OpenAI
    account. If so, click â€œLog inâ€'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**3.2) Add Payment Method**'
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If your account is more than 3 months old or the free $5 API credit is not enough
    for you, you will need to add a payment method before making API calls.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click your profile image and select the manage account option.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then add a payment method by clicking the â€œBillingâ€ tab and then â€œPayment methodsâ€.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**3.3) Set Usage Limits**'
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next, I recommend setting usage limits so that you **avoid being billed more
    than you budget for**.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To do this, go to the â€œUsage limitsâ€ under the â€œBillingâ€ tab. Here you can set
    a â€œSoftâ€ and â€œHardâ€ limit.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you hit your monthly **soft limit,** OpenAI will send you an **email notification**.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you hit your **hard limit,** any additional API **requests will be denied**
    (thus, you wonâ€™t be charged more than this).
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**3.4) Get API Secret Key**'
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Click on â€œView API keysâ€
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If this is your first time, you will need to make a new secret key. To do this,
    click â€œCreate new secret keyâ€
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, you can give your key a custom name. Here I used â€œmy-first-keyâ€.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, click â€œCreate secret keyâ€
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**4) Example Code: Chat Completion API**'
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With all the setup done, we are (finally) ready to make our first API call.
    Here we will use the [openai Python library](https://github.com/openai/openai-python),
    which makes integrating OpenAIâ€™s models into your Python code super easy. You
    can download the package via [pip](https://pypi.org/project/openai/)*.* The below
    example code (and bonus code) is available on the [GitHub repo](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/openai-api)
    for this article.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '***A quick note on Completions API deprecations* â€”** OpenAI is moving away
    from the freeform prompt paradigm and toward chat-based API calls. According to
    a blog from OpenAI, the chat-based paradigm provides better responses, given its
    structured prompt interface, compared to the previous paradigm [[2](https://openai.com/blog/gpt-4-api-general-availability)].'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: While older OpenAI (GPT-3) models are still available via the â€œfreeformâ€ paradigm,
    the more recent (and powerful) models (i.e. GPT-3.5-turbo and GPT-4) are only
    available via chat-based calls.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Letâ€™s start with a super simple API call. Here we will pass **two inputs** into
    the ***openai.ChatCompletions.create()*** method i.e. **model** and **messages**.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '**model** â€” defines the name of the language model we want to use (we can choose
    from the models listed earlier in the article.)'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**messages** â€” sets the â€œprecedingâ€ chat dialogue as a list of dictionaries.
    The dictionaries have two key-value pairs (e.g. {â€œroleâ€: â€œuserâ€, â€œcontentâ€: â€œListen
    to yourâ€}.) **First**, â€œroleâ€ defines *who is talking* (e.g. â€œroleâ€:â€userâ€). This
    can either be the â€œuserâ€, â€œassistantâ€, or â€œsystemâ€. **Second**, â€œcontentâ€ defines
    *what the role is saying* (e.g. â€œcontentâ€: â€œListen to yourâ€). While this may feel
    more restrictive than a freeform prompt interface, we can get creative with input
    messages to optimize responses for a particular use case (more on this later).'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is what our first API call looks like in Python.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The API response is stored in the *chat_completion* variable. Printing *chat_completion*,
    we see that it is like a dictionary consisting of 6 key-value pairs.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The meaning of each field is listed below.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '**â€˜Idâ€™** = unique ID for the API response'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**â€˜Objectâ€™** = name of API object that sent the response'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**â€˜Createdâ€™** = unix timestamp of when the API request was processed'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**â€˜Modelâ€™** = name of the model used'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**â€˜Choicesâ€™** = model response formatted in JSON (i.e. dictionary-like)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**â€˜Usageâ€™** = token count meta-data formatted in JSON (i.e. dictionary-like)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, the main thing we care about here is the â€˜**Choices**â€™ field since
    this is **where the model response is stored**. In this case, we see the â€œassistantâ€
    role responds with the message *â€œ****heart.â€***
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Yay! We made our 1st API call. Now letâ€™s start playing with the model input
    parameters.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: max_tokens
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, we can set the **maximum number of tokens** allowed in the model response
    using the *max_tokens* input parameter. This can be helpful for many reasons depending
    on the use case. In this case, I just want a one-word response, so Iâ€™ll set it
    to 1 token.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: n
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next, we can set the **number of responses** we would like to receive from the
    model. Again, this can be helpful for many reasons depending on the use case.
    For example, if we want to generate a set of responses from which we can select
    the one we like best.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Notice that **not all the completions are identical**. This may be a good thing
    or a bad thing based on the use case (e.g. creative use cases vs. process automation
    use cases). Therefore, it can be advantageous to adjust the *diversity* of chat
    completions for a given prompt.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: temperature
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It turns out we can do this by tuning the **temperature** parameter. Put simply,
    this **adjusts the â€œrandomnessâ€ of chat completions**.Values for this parameter
    **range from 0 to 2**, where 0 makes completions more predictable, and 2 makes
    them less predictable [[3](https://platform.openai.com/docs/api-reference/chat/create)].
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Conceptually, we can think of temp=0 will default to the most likely next word
    while temp=2 will enable completions that are relatively unlikely. Letâ€™s see what
    this looks like.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As expected, when temp=0, all 5 completions are identical and produce something
    â€œvery likely.â€ Now letâ€™s see what happens when we **turn up the temperature**.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Again, as expected, the chat completions with temp=2 were much more diverse
    and â€œout of pocket.â€
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: 'messages roles: Lyric Completion Assistant'
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finally, we can leverage the different roles in this chat-based prompting paradigm
    to adjust the language model responses even further.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall from earlier that we can include content from 3 different roles in our
    prompts: **system**, **user**, and **assistant**. The **system** message **sets
    the context (or task) for model completions** *e.g. â€œYou are a friendly chatbot
    that does not want to destroy all humansâ€ or â€œSummarize user prompts in max 10
    wordsâ€.*'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '**User** and **assistant** messages can be used in at least two ways. **One**,
    to generate examples for **in-context learning**, and **two**, to store and update
    **conversation history** for a real-time chatbot. Here we will use both ways to
    create a lyric completion assistant.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: We start by making the **system message** *â€œI am Roxette lyric completion assistant.
    When given a line from a song, I will provide the next line in the song.â€* Then,
    provide **two examples of** **user and assistant messages**. Followed by the same
    **user prompt** used in the preceding examples i.e.*â€œListen to yourâ€.*
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Hereâ€™s what that looks like in code.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Comparing the output to the [actual lyrics](https://www.azlyrics.com/lyrics/roxette/listentoyourheart.html)
    to the hit Roxette song, we see they are an exact match. This is due to the combination
    of all the different inputs we provided to the model.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 'To see what this looks like when we â€œ*crank the temperature*,â€ check out the
    bonus code on [GitHub](https://github.com/ShawhinT/YouTube-Blog/blob/main/LLMs/openai-api/openai-api-demo.ipynb).
    (Warning: it gets weird)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here I gave a beginner-friendly guide to the OpenAI Python API with example
    code. The biggest upside of using OpenAIâ€™s API is you can work with powerful LLMs
    without worrying about provisioning computational resources. The **downsides**,
    however, are **API calls cost money** and potential **security concerns** of sharing
    some types of data with a 3rd party (OpenAI).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: To avoid these downsides, we can turn to open-source LLM solutions. This will
    be the focus of the [next article](https://medium.com/towards-data-science/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)
    in this series, where weâ€™ll explore the Hugging Face Transformers library.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: 'ğŸ‘‰ **More on LLMs**: [Introduction](/a-practical-introduction-to-llms-65194dda1148)
    | [Hugging Face Transformers](https://medium.com/towards-data-science/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)
    | [Prompt Engineering](https://medium.com/towards-data-science/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f)
    | [Fine-tuning](https://medium.com/towards-data-science/fine-tuning-large-language-models-llms-23473d763b91)
    | [Build an LLM](/how-to-build-an-llm-from-scratch-8c477768f1f9) | [QLoRA](/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32)
    | [RAG](https://medium.com/towards-data-science/how-to-improve-llms-with-rag-abdc132f76ac)
    | [Text Embeddings](/text-embeddings-classification-and-semantic-search-8291746220be)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '![Shaw Talebi](../Images/02eefb458c6eeff7cd29d40c212e3b22.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
- en: '[Shaw Talebi](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Large Language Models (LLMs)
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://shawhin.medium.com/list/large-language-models-llms-8e009ae3054c?source=post_page-----230e4cae7971--------------------------------)13
    stories![](../Images/82e865594c68f5307e75665842d197bb.png)![](../Images/b9436354721f807e0390b5e301be2119.png)![](../Images/59c8db581de77a908457dec8981f3c37.png)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Resources
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Connect**: [My website](https://shawhintalebi.com/) | [Book a call](https://calendly.com/shawhintalebi)
    | [Ask me anything](https://shawhintalebi.com/contact/)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '**Socials**: [YouTube ğŸ¥](https://www.youtube.com/channel/UCa9gErQ9AE5jT2DZLjXBIdA)
    | [LinkedIn](https://www.linkedin.com/in/shawhintalebi/) | [Twitter](https://twitter.com/ShawhinT)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '**Support**: [Buy me a coffee](https://www.buymeacoffee.com/shawhint) â˜•ï¸'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://shawhin.medium.com/subscribe?source=post_page-----230e4cae7971--------------------------------)
    [## Get FREE access to every new story I write'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Get FREE access to every new story I write P.S. I do not share your email with
    anyone By signing up, you will create aâ€¦
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: shawhin.medium.com](https://shawhin.medium.com/subscribe?source=post_page-----230e4cae7971--------------------------------)
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '[1] [OpenAI Models documentation](https://platform.openai.com/docs/models)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '[2] [GPT-4 Availability & Completions API Deprecation](https://openai.com/blog/gpt-4-api-general-availability)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '[3] Temperature definition from [API reference](https://platform.openai.com/docs/api-reference/chat/create)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
