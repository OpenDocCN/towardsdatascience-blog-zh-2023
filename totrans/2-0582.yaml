- en: Cracking Open the OpenAI (Python) API
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 破解OpenAI（Python）API
- en: 原文：[https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971](https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971](https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971)
- en: '**A complete beginner-friendly introduction with example code**'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**一个完整的初学者友好介绍，附示例代码**'
- en: '[](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)[![Shaw
    Talebi](../Images/1449cc7c08890e2078f9e5d07897e3df.png)](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)[](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)
    [Shaw Talebi](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)[![Shaw
    Talebi](../Images/1449cc7c08890e2078f9e5d07897e3df.png)](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)[](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)
    [Shaw Talebi](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)
    ·12 min read·Jul 21, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)
    ·阅读时间12分钟·2023年7月21日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/2c856f26ccf574ede1e5d700f75668e9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2c856f26ccf574ede1e5d700f75668e9.png)'
- en: Photo by [Martin Sanchez](https://unsplash.com/@martinsanchez?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Martin Sanchez](https://unsplash.com/@martinsanchez?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: This is the 2nd article in a [series](/a-practical-introduction-to-llms-65194dda1148)
    on using Large Language Models (LLMs) in practice. Here I present a beginner-friendly
    introduction to the OpenAI API. This allows you to go beyond restrictive chat
    interfaces like ChatGPT and to get more out of LLMs for your unique use cases.
    Python example code is provided below and at the [GitHub repository](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/openai-api).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这是关于在实践中使用大型语言模型（LLMs）的[系列文章](/a-practical-introduction-to-llms-65194dda1148)的第二篇。这里我提供了一个适合初学者的OpenAI
    API介绍。这使你能够超越像ChatGPT这样的限制性聊天界面，并为你的独特用例更好地利用LLMs。下面提供了Python示例代码和[GitHub仓库](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/openai-api)。
- en: 'Table of Contents:'
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目录：
- en: What’s an API?
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是API？
- en: OpenAI’s (Python) API
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: OpenAI的（Python）API
- en: Getting Started (4 Steps)
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开始使用（4个步骤）
- en: Example Code
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 示例代码
- en: In the [first article](/a-practical-introduction-to-llms-65194dda1148) of this
    series, I described [**Prompt Engineering**](/cracking-open-the-openai-python-api-230e4cae7971)
    as the **most accessible way to use LLMs** in practice. The easiest (and most
    popular) way to do this is via tools like ChatGPT, which provide an intuitive,
    no-cost, and no-code way to interact with an LLM.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第一篇文章](/a-practical-introduction-to-llms-65194dda1148)中，我描述了[**提示工程**](/cracking-open-the-openai-python-api-230e4cae7971)作为**使用LLMs的最便捷方法**。最简单（也是最流行）的方法是通过像ChatGPT这样的工具，它们提供了直观、无需成本和无需编码的LLM交互方式。
- en: '[](/a-practical-introduction-to-llms-65194dda1148?source=post_page-----230e4cae7971--------------------------------)
    [## A Practical Introduction to LLMs'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/a-practical-introduction-to-llms-65194dda1148?source=post_page-----230e4cae7971--------------------------------)
    [## LLMs的实用入门'
- en: 3 levels of using LLMs in practice
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实践中使用LLMs的3个层次
- en: towardsdatascience.com](/a-practical-introduction-to-llms-65194dda1148?source=post_page-----230e4cae7971--------------------------------)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/a-practical-introduction-to-llms-65194dda1148?source=post_page-----230e4cae7971--------------------------------)
- en: However, this **ease of use comes at a cost**. Namely, the chat UI is restrictive
    and does not translate well to many practical use cases e.g. building your own
    customer support bot, real-time sentiment analysis of customer reviews, etc.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种**使用简便性是有代价的**。即聊天界面具有限制，且不适用于许多实际应用场景，例如构建自己的客户支持机器人、实时分析客户评论情感等。
- en: In these cases, we can take Prompt Engineering one step further and interact
    with LLMs *programmatically*. One way we can do this is via an API.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，我们可以将提示工程进一步推进，通过*编程方式*与LLMs互动。实现这一点的一种方法是通过API。
- en: '**1) What’s an API?**'
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**1) 什么是API？**'
- en: An **application programming interface (API)** allows you to interact with a
    remote application programmatically. While this might sound technical and scary,
    the idea is super simple. Consider the following analogy.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**应用程序编程接口（API）**允许你以编程方式与远程应用程序进行交互。虽然这可能听起来技术性很强且有些吓人，但其实非常简单。考虑以下类比。'
- en: Imagine you have an intense craving for the [pupusas](https://en.wikipedia.org/wiki/Pupusa)
    you ate during that summer in El Salvador. Unfortunately, you’re back at home
    and don’t know where to find good Salvadoran food. Lucky for you, however, you
    have a super-foodie friend that knows every restaurant in town.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下你对在萨尔瓦多那个夏天吃的[普普萨](https://en.wikipedia.org/wiki/Pupusa)产生了强烈的渴望。不幸的是，你回到了家里，不知道在哪里可以找到好的萨尔瓦多食物。然而，你有一个超级吃货朋友，他知道城里每一家餐馆。
- en: So, you send your friend the text.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，你给你的朋友发了短信。
- en: “Any good pupusa spots in town?”
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “城里有好的普普萨店吗？”
- en: Then, a couple of minutes later, you get the response.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，几分钟后，你会收到回复。
- en: “Yes! Flavors of El Salvador has the best pupusas!”
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “是的！萨尔瓦多风味的餐厅有最棒的普普萨！”
- en: While this may seem irrelevant to APIs, this is essentially how they work. You
    send a **request** to a remote application i.e. text your super-foodie friend.
    Then, the remote application sends back a **response** i.e. the text back from
    your friend.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这似乎与 API 无关，但这基本上就是它们的工作原理。你向远程应用程序发送一个**请求**，即给你的超级吃货朋友发短信。然后，远程应用程序会返回一个**响应**，即你朋友的回复。
- en: '![](../Images/d55d67b38e544c96a386e920f92da133.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d55d67b38e544c96a386e920f92da133.png)'
- en: A visual analogy of how APIs work. Image by author.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: API 工作的可视化类比。图片由作者提供。
- en: The difference between an API and the above analogy is instead of sending the
    request with your phone’s texting app, you use your favorite programming language
    e.g. Python, JavaScript, Ruby, Java, etc. This is great if you are developing
    software where some external information is required because the information retrieval
    can be automated.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: API 与上述类比之间的区别在于，你不是用手机的短信应用发送请求，而是使用你喜欢的编程语言，例如 Python、JavaScript、Ruby、Java
    等。如果你正在开发需要外部信息的软件，这非常好，因为信息检索可以自动化。
- en: '**2) OpenAI’s (Python) API**'
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**2) OpenAI 的（Python）API**'
- en: We can use APIs to interact with Large Language Models. A popular one is OpenAI’s
    API, where instead of typing prompts into the ChatGPT web interface, you can send
    them to and from OpenAI using Python.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 API 与大型语言模型进行交互。一个流行的 API 是 OpenAI 的 API，你可以使用 Python 向 OpenAI 发送和接收提示，而不是在
    ChatGPT 网络界面中输入提示。
- en: '![](../Images/49422df67ac7d25c8846a1ee770af4ad.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/49422df67ac7d25c8846a1ee770af4ad.png)'
- en: Visualization of how API calls to OpenAI works. Image by author.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: API 调用到 OpenAI 的可视化。图片由作者提供。
- en: This gives virtually anyone access to state-of-the-art LLMs (and other ML models)
    without having to provision the computational resources needed to run them. The
    downside, of course, is OpenAI doesn’t do this as a charity. Each API call costs
    money, but more on that in a bit.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得几乎任何人都可以访问最先进的LLM（和其他ML模型），而无需提供运行它们所需的计算资源。当然，缺点是 OpenAI 并不是出于慈善目的提供这些服务。每次
    API 调用都会收费，但稍后会详细说明。
- en: Some **notable features** of the API (not available with ChatGPT) are listed
    below.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: API 的一些**显著特性**（ChatGPT 不提供）如下。
- en: '**Customizable system message** (this is set to something like “*I am ChatGPT,
    a large language model trained by OpenAI, based on the GPT-3.5 architecture. My
    knowledge is based on information available up until September 2021\. Today’s
    date is July 13, 2023.*” for ChatGPT)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可定制的系统消息**（对于 ChatGPT，这设置为类似于“*我是 ChatGPT，一个由 OpenAI 训练的大型语言模型，基于 GPT-3.5
    架构。我的知识基于截至 2021 年 9 月的信息。今天的日期是 2023 年 7 月 13 日。*”的内容）'
- en: '**Adjust input parameters** such as maximum response length, number of responses,
    and temperature (i.e. the “randomness” of the response).'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**调整输入参数**，如最大响应长度、响应数量和温度（即响应的“随机性”）。'
- en: Include **images** and **other file types** in prompts
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在提示中**包含图像**和**其他文件类型**。
- en: Extract helpful word **embeddings** for downstream tasks
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取对下游任务有帮助的词语**嵌入**。
- en: '**Input audio** for transcription or translation'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入音频**以进行转录或翻译。'
- en: Model **fine-tuning** functionality
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型**微调**功能
- en: The OpenAI API has [several models](https://platform.openai.com/docs/models)
    from which to choose. The *best* model to pick will depend on your particular
    use case. Below is a list of the current models available [[1](https://platform.openai.com/docs/models)].
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI API 提供了[多个模型](https://platform.openai.com/docs/models)供选择。选择哪个*最佳*模型取决于你的具体用例。下面是当前可用模型的列表[[1](https://platform.openai.com/docs/models)]。
- en: '![](../Images/98ce3333b2824ace053715e0867ed296.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/98ce3333b2824ace053715e0867ed296.png)'
- en: List of available models via the OpenAI API as of Jul 2023\. Image by author.
    [[1](https://platform.openai.com/docs/models)]
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 列出了截至 2023 年 7 月的 OpenAI API 可用模型。图像由作者提供。[[1](https://platform.openai.com/docs/models)]
- en: '***Note****: Each item listed above is accompanied by a set of models which
    vary in size and cost. Check* [*documentation*](https://platform.openai.com/docs/models)
    *for the most recent information.*'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '***注意***：上述每项内容都有一组模型，模型的大小和成本各不相同。查看* [*文档*](https://platform.openai.com/docs/models)
    *获取最新信息。*'
- en: '**Pricing & Tokens**'
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**定价与 Token**'
- en: While the OpenAI API gives developers easy access to SOTA ML models, one obvious
    downside is that it **costs money**. Pricing is done on a per-token basis (no,
    I don’t mean NFTs or something you use at the arcade).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 OpenAI API 为开发者提供了对最先进机器学习模型的便捷访问，但一个明显的缺点是**需要付费**。定价是按 token 计算的（不，我不是指
    NFTs 或其他你在游戏厅用的东西）。
- en: '**Tokens**, in the context of LLMs, are essentially **a set of numbers representing
    a set of words and characters**. For example, “The” could be a token, “ end” (with
    the space) could be another, and “.” another.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**Token**，在 LLM 的上下文中，本质上是**代表一组单词和字符的一组数字**。例如，“The” 可能是一个 token，“ end”（带空格）可能是另一个，"."
    也是一个。'
- en: Thus, the text “The End.” would consist of 3 tokens say (73, 102, 6).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，文本 “The End.” 将由 3 个 token 组成，例如（73, 102, 6）。
- en: '![](../Images/1f13c26b8c5b663dd2903f54a9249d13.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1f13c26b8c5b663dd2903f54a9249d13.png)'
- en: Toy example showing one possible token mapping between text and integers. Image
    by author.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个玩具示例，展示了文本与整数之间的一种可能的 token 映射。图像由作者提供。
- en: This is a critical step because **LLMs (i.e. neural networks) do not “understand”
    text directly**. The text must be converted into a numerical representation so
    that the model can perform mathematical operations on the input. Hence, the tokenization
    step.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个关键步骤，因为**LLM（即神经网络）不直接“理解”文本**。文本必须转换为数字表示，以便模型可以对输入执行数学操作。因此，需要进行 token
    化步骤。
- en: The price of an API call depends on the number of tokens used in the prompt
    and the model being prompted. The price per model is available on [OpenAI’s website](https://openai.com/pricing).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: API 调用的价格取决于提示中使用的 token 数量和所调用的模型。每个模型的价格可以在 [OpenAI 的网站](https://openai.com/pricing)
    上找到。
- en: '**3) Getting Started (4 Steps)**'
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**3) 开始使用（4 步骤）**'
- en: Now that we have a basic understanding of the OpenAI API let’s see how to use
    it. Before we can start coding, we need to set up four things.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对 OpenAI API 有了基本了解，让我们看看如何使用它。在开始编码之前，我们需要设置四件事。
- en: '**3.1) Make an Account (you get a $5 API credit for 1st three months)**'
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**3.1) 创建账户（前 3 个月有 $5 的 API 额度）**'
- en: To make an account go to the [OpenAI API Overview page](https://platform.openai.com/overview),
    and click “Sign Up” in the top right corner
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要创建账户，请访问 [OpenAI API 概览页面](https://platform.openai.com/overview)，并点击右上角的“注册”
- en: '*Note* — If you’ve used ChatGPT before, then you probably already have an OpenAI
    account. If so, click “Log in”'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*注意* — 如果你以前使用过 ChatGPT，那么你可能已经有一个 OpenAI 帐户。如果是，请点击“登录”'
- en: '**3.2) Add Payment Method**'
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**3.2) 添加支付方式**'
- en: If your account is more than 3 months old or the free $5 API credit is not enough
    for you, you will need to add a payment method before making API calls.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你的账户已经超过 3 个月，或者免费的 $5 API 额度不够用，你需要在调用 API 之前添加支付方式。
- en: Click your profile image and select the manage account option.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击你的头像并选择管理账户选项。
- en: Then add a payment method by clicking the “Billing” tab and then “Payment methods”.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后点击“账单”标签，再点击“支付方式”来添加支付方式。
- en: '**3.3) Set Usage Limits**'
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**3.3) 设置使用限制**'
- en: Next, I recommend setting usage limits so that you **avoid being billed more
    than you budget for**.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我建议设置使用限制，以**避免被账单超出预算**。
- en: To do this, go to the “Usage limits” under the “Billing” tab. Here you can set
    a “Soft” and “Hard” limit.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为此，请转到“账单”标签下的“使用限制”。在这里你可以设置“软限制”和“硬限制”。
- en: If you hit your monthly **soft limit,** OpenAI will send you an **email notification**.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你达到每月的**软限制**，OpenAI 会向你发送**电子邮件通知**。
- en: If you hit your **hard limit,** any additional API **requests will be denied**
    (thus, you won’t be charged more than this).
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你达到了**硬限制**，任何额外的 API **请求将被拒绝**（因此，你不会被额外收费）。
- en: '**3.4) Get API Secret Key**'
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**3.4) 获取 API 秘钥**'
- en: Click on “View API keys”
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“查看 API 密钥”
- en: If this is your first time, you will need to make a new secret key. To do this,
    click “Create new secret key”
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果这是你第一次使用，你需要创建一个新的秘钥。为此，点击“创建新的秘钥”
- en: Next, you can give your key a custom name. Here I used “my-first-key”.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，你可以给你的密钥一个自定义名称。我在这里使用了“my-first-key”。
- en: Then, click “Create secret key”
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，点击“创建密钥”
- en: '**4) Example Code: Chat Completion API**'
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**4) 示例代码：聊天完成 API**'
- en: With all the setup done, we are (finally) ready to make our first API call.
    Here we will use the [openai Python library](https://github.com/openai/openai-python),
    which makes integrating OpenAI’s models into your Python code super easy. You
    can download the package via [pip](https://pypi.org/project/openai/)*.* The below
    example code (and bonus code) is available on the [GitHub repo](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/openai-api)
    for this article.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 所有设置完成后，我们（终于）准备好进行第一次 API 调用。这里我们将使用 [openai Python 库](https://github.com/openai/openai-python)，它使将
    OpenAI 的模型集成到你的 Python 代码中变得非常简单。你可以通过 [pip](https://pypi.org/project/openai/)
    下载这个包。下面的示例代码（以及额外代码）可以在 [GitHub 仓库](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/openai-api)中找到。
- en: '***A quick note on Completions API deprecations* —** OpenAI is moving away
    from the freeform prompt paradigm and toward chat-based API calls. According to
    a blog from OpenAI, the chat-based paradigm provides better responses, given its
    structured prompt interface, compared to the previous paradigm [[2](https://openai.com/blog/gpt-4-api-general-availability)].'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '***关于 Completions API 废弃的快速说明* —** OpenAI 正在从自由形式的提示范式转向基于聊天的 API 调用。根据 OpenAI
    的博客，基于聊天的范式提供了更好的响应，鉴于其结构化提示界面，相比于以前的范式 [[2](https://openai.com/blog/gpt-4-api-general-availability)]。'
- en: While older OpenAI (GPT-3) models are still available via the “freeform” paradigm,
    the more recent (and powerful) models (i.e. GPT-3.5-turbo and GPT-4) are only
    available via chat-based calls.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然旧版 OpenAI（GPT-3）模型仍然可以通过“自由形式”范式使用，但更近期（和更强大的）模型（即 GPT-3.5-turbo 和 GPT-4）只能通过基于聊天的调用获得。
- en: Let’s start with a super simple API call. Here we will pass **two inputs** into
    the ***openai.ChatCompletions.create()*** method i.e. **model** and **messages**.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个超级简单的 API 调用开始。这里我们将**两个输入**传递给***openai.ChatCompletions.create()*** 方法，即**model**和**messages**。
- en: '**model** — defines the name of the language model we want to use (we can choose
    from the models listed earlier in the article.)'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**model** — 定义了我们想要使用的语言模型的名称（我们可以从本文前面列出的模型中选择。）'
- en: '**messages** — sets the “preceding” chat dialogue as a list of dictionaries.
    The dictionaries have two key-value pairs (e.g. {“role”: “user”, “content”: “Listen
    to your”}.) **First**, “role” defines *who is talking* (e.g. “role”:”user”). This
    can either be the “user”, “assistant”, or “system”. **Second**, “content” defines
    *what the role is saying* (e.g. “content”: “Listen to your”). While this may feel
    more restrictive than a freeform prompt interface, we can get creative with input
    messages to optimize responses for a particular use case (more on this later).'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**消息** — 将“前面的”聊天对话设置为字典列表。这些字典有两个键值对（例如 {“role”: “user”, “content”: “Listen
    to your”}）。**首先**，“role”定义了*谁在讲话*（例如 “role”:”user”）。这可以是“用户”、“助手”或“系统”。**其次**，“content”定义了*角色在说什么*（例如
    “content”: “Listen to your”）。虽然这可能比自由形式的提示界面更具限制性，但我们可以通过创意输入消息来优化特定用例的响应（稍后会详细说明）。'
- en: This is what our first API call looks like in Python.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们第一次在 Python 中调用 API 的样子。
- en: '[PRE0]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The API response is stored in the *chat_completion* variable. Printing *chat_completion*,
    we see that it is like a dictionary consisting of 6 key-value pairs.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: API 响应存储在*chat_completion*变量中。打印*chat_completion*，我们看到它像一个包含 6 个键值对的字典。
- en: '[PRE1]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The meaning of each field is listed below.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 每个字段的含义列在下面。
- en: '**‘Id’** = unique ID for the API response'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**‘Id’** = API 响应的唯一 ID'
- en: '**‘Object’** = name of API object that sent the response'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**‘Object’** = 发送响应的 API 对象的名称'
- en: '**‘Created’** = unix timestamp of when the API request was processed'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**‘Created’** = 处理 API 请求时的 Unix 时间戳'
- en: '**‘Model’** = name of the model used'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**‘Model’** = 使用的模型名称'
- en: '**‘Choices’** = model response formatted in JSON (i.e. dictionary-like)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**‘Choices’** = 模型响应格式为 JSON（即类似字典的形式）'
- en: '**‘Usage’** = token count meta-data formatted in JSON (i.e. dictionary-like)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**‘Usage’** = 以 JSON 格式（即类似字典的形式）显示的令牌计数元数据'
- en: However, the main thing we care about here is the ‘**Choices**’ field since
    this is **where the model response is stored**. In this case, we see the “assistant”
    role responds with the message *“****heart.”***
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们在这里最关心的是‘**Choices**’字段，因为这是**模型响应存储的位置**。在这种情况下，我们看到“助手”角色用消息*“****heart.”*作出响应。
- en: Yay! We made our 1st API call. Now let’s start playing with the model input
    parameters.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了！我们完成了第一次 API 调用。现在，让我们开始调整模型输入参数。
- en: max_tokens
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: max_tokens
- en: First, we can set the **maximum number of tokens** allowed in the model response
    using the *max_tokens* input parameter. This can be helpful for many reasons depending
    on the use case. In this case, I just want a one-word response, so I’ll set it
    to 1 token.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们可以使用*max_tokens*输入参数设置模型响应中允许的**最大令牌数**。这在许多情况下都可能是有帮助的。在这种情况下，我只想要一个单词的响应，因此我将其设置为1个令牌。
- en: '[PRE2]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: n
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: n
- en: Next, we can set the **number of responses** we would like to receive from the
    model. Again, this can be helpful for many reasons depending on the use case.
    For example, if we want to generate a set of responses from which we can select
    the one we like best.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以设置我们希望从模型中接收的**响应数量**。这在许多情况下都可能是有帮助的。例如，如果我们希望生成一组响应，从中选择我们最喜欢的一个。
- en: '[PRE3]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Notice that **not all the completions are identical**. This may be a good thing
    or a bad thing based on the use case (e.g. creative use cases vs. process automation
    use cases). Therefore, it can be advantageous to adjust the *diversity* of chat
    completions for a given prompt.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到**并非所有的完成都是相同的**。这可能是好事也可能是坏事，具体取决于使用案例（例如创意使用案例与过程自动化使用案例）。因此，为给定的提示调整聊天完成的*多样性*可能是有利的。
- en: temperature
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: temperature
- en: It turns out we can do this by tuning the **temperature** parameter. Put simply,
    this **adjusts the “randomness” of chat completions**.Values for this parameter
    **range from 0 to 2**, where 0 makes completions more predictable, and 2 makes
    them less predictable [[3](https://platform.openai.com/docs/api-reference/chat/create)].
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，我们可以通过调整**温度**参数来实现这一点。简而言之，这**调整了聊天完成的“随机性”**。此参数的值**范围从0到2**，其中0使完成更可预测，而2则使其不那么可预测[[3](https://platform.openai.com/docs/api-reference/chat/create)]。
- en: Conceptually, we can think of temp=0 will default to the most likely next word
    while temp=2 will enable completions that are relatively unlikely. Let’s see what
    this looks like.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 从概念上讲，我们可以认为temp=0将默认生成最可能的下一个词，而temp=2将生成相对不太可能的完成。让我们看看这是什么样的。
- en: '[PRE4]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As expected, when temp=0, all 5 completions are identical and produce something
    “very likely.” Now let’s see what happens when we **turn up the temperature**.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，当temp=0时，所有5个完成是相同的，并产生“非常可能”的结果。现在让我们看看当我们**提高温度**时会发生什么。
- en: '[PRE5]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Again, as expected, the chat completions with temp=2 were much more diverse
    and “out of pocket.”
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 再次如预期的那样，temp=2时的聊天完成更加多样化，且“出乎意料”。
- en: 'messages roles: Lyric Completion Assistant'
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 消息角色：歌词完成助手
- en: Finally, we can leverage the different roles in this chat-based prompting paradigm
    to adjust the language model responses even further.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以利用这种基于聊天的提示范式中的不同角色来进一步调整语言模型的响应。
- en: 'Recall from earlier that we can include content from 3 different roles in our
    prompts: **system**, **user**, and **assistant**. The **system** message **sets
    the context (or task) for model completions** *e.g. “You are a friendly chatbot
    that does not want to destroy all humans” or “Summarize user prompts in max 10
    words”.*'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾一下，我们可以在提示中包含来自3个不同角色的内容：**系统**、**用户**和**助手**。**系统**消息**设置了模型完成的上下文（或任务）**
    *例如“你是一个友好的聊天机器人，不想摧毁所有人类”或“将用户提示总结为最多10个词”。*
- en: '**User** and **assistant** messages can be used in at least two ways. **One**,
    to generate examples for **in-context learning**, and **two**, to store and update
    **conversation history** for a real-time chatbot. Here we will use both ways to
    create a lyric completion assistant.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**用户**和**助手**消息可以至少以两种方式使用。**一种**，生成**上下文学习**的示例；**另一种**，存储和更新**对话历史**以供实时聊天机器人使用。这里我们将使用这两种方式来创建一个歌词完成助手。'
- en: We start by making the **system message** *“I am Roxette lyric completion assistant.
    When given a line from a song, I will provide the next line in the song.”* Then,
    provide **two examples of** **user and assistant messages**. Followed by the same
    **user prompt** used in the preceding examples i.e.*“Listen to your”.*
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先设置**系统消息**为 *“我是Roxette歌词完成助手。当给出一行歌词时，我将提供歌曲中的下一行。”* 然后，提供**两个用户和助手消息的示例**。接着使用与之前示例中相同的**用户提示**即
    *“听听你的”*。
- en: Here’s what that looks like in code.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这在代码中是这样的。
- en: '[PRE6]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Comparing the output to the [actual lyrics](https://www.azlyrics.com/lyrics/roxette/listentoyourheart.html)
    to the hit Roxette song, we see they are an exact match. This is due to the combination
    of all the different inputs we provided to the model.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 比较与[实际歌词](https://www.azlyrics.com/lyrics/roxette/listentoyourheart.html)的输出，我们看到它们完全匹配。这是由于我们提供给模型的所有不同输入的组合。
- en: 'To see what this looks like when we “*crank the temperature*,” check out the
    bonus code on [GitHub](https://github.com/ShawhinT/YouTube-Blog/blob/main/LLMs/openai-api/openai-api-demo.ipynb).
    (Warning: it gets weird)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看当我们“*增加温度*”时的效果，请查看 [GitHub](https://github.com/ShawhinT/YouTube-Blog/blob/main/LLMs/openai-api/openai-api-demo.ipynb)
    上的附加代码。 (警告：会变得有些奇怪)
- en: Conclusion
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Here I gave a beginner-friendly guide to the OpenAI Python API with example
    code. The biggest upside of using OpenAI’s API is you can work with powerful LLMs
    without worrying about provisioning computational resources. The **downsides**,
    however, are **API calls cost money** and potential **security concerns** of sharing
    some types of data with a 3rd party (OpenAI).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我提供了一个适合初学者的 OpenAI Python API 指南，其中包含示例代码。使用 OpenAI 的 API 最大的好处是你可以使用强大的
    LLMs，而不必担心计算资源的配置。然而，**缺点**是 **API 调用需要付费**，以及与第三方（OpenAI）共享某些类型数据的潜在 **安全问题**。
- en: To avoid these downsides, we can turn to open-source LLM solutions. This will
    be the focus of the [next article](https://medium.com/towards-data-science/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)
    in this series, where we’ll explore the Hugging Face Transformers library.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这些缺点，我们可以转向开源的 LLM 解决方案。这将是本系列中 [下一篇文章](https://medium.com/towards-data-science/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)
    的重点，我们将在其中探索 Hugging Face Transformers 库。
- en: '👉 **More on LLMs**: [Introduction](/a-practical-introduction-to-llms-65194dda1148)
    | [Hugging Face Transformers](https://medium.com/towards-data-science/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)
    | [Prompt Engineering](https://medium.com/towards-data-science/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f)
    | [Fine-tuning](https://medium.com/towards-data-science/fine-tuning-large-language-models-llms-23473d763b91)
    | [Build an LLM](/how-to-build-an-llm-from-scratch-8c477768f1f9) | [QLoRA](/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32)
    | [RAG](https://medium.com/towards-data-science/how-to-improve-llms-with-rag-abdc132f76ac)
    | [Text Embeddings](/text-embeddings-classification-and-semantic-search-8291746220be)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '👉 **更多关于 LLMs 的内容**: [简介](/a-practical-introduction-to-llms-65194dda1148) |
    [Hugging Face Transformers](https://medium.com/towards-data-science/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)
    | [Prompt Engineering](https://medium.com/towards-data-science/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f)
    | [微调](https://medium.com/towards-data-science/fine-tuning-large-language-models-llms-23473d763b91)
    | [构建 LLM](/how-to-build-an-llm-from-scratch-8c477768f1f9) | [QLoRA](/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32)
    | [RAG](https://medium.com/towards-data-science/how-to-improve-llms-with-rag-abdc132f76ac)
    | [文本嵌入](/text-embeddings-classification-and-semantic-search-8291746220be)'
- en: '![Shaw Talebi](../Images/02eefb458c6eeff7cd29d40c212e3b22.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![Shaw Talebi](../Images/02eefb458c6eeff7cd29d40c212e3b22.png)'
- en: '[Shaw Talebi](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[Shaw Talebi](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)'
- en: Large Language Models (LLMs)
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）
- en: '[View list](https://shawhin.medium.com/list/large-language-models-llms-8e009ae3054c?source=post_page-----230e4cae7971--------------------------------)13
    stories![](../Images/82e865594c68f5307e75665842d197bb.png)![](../Images/b9436354721f807e0390b5e301be2119.png)![](../Images/59c8db581de77a908457dec8981f3c37.png)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://shawhin.medium.com/list/large-language-models-llms-8e009ae3054c?source=post_page-----230e4cae7971--------------------------------)13篇故事![](../Images/82e865594c68f5307e75665842d197bb.png)![](../Images/b9436354721f807e0390b5e301be2119.png)![](../Images/59c8db581de77a908457dec8981f3c37.png)'
- en: Resources
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源
- en: '**Connect**: [My website](https://shawhintalebi.com/) | [Book a call](https://calendly.com/shawhintalebi)
    | [Ask me anything](https://shawhintalebi.com/contact/)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**联系**: [我的网站](https://shawhintalebi.com/) | [预约电话](https://calendly.com/shawhintalebi)
    | [问我任何问题](https://shawhintalebi.com/contact/)'
- en: '**Socials**: [YouTube 🎥](https://www.youtube.com/channel/UCa9gErQ9AE5jT2DZLjXBIdA)
    | [LinkedIn](https://www.linkedin.com/in/shawhintalebi/) | [Twitter](https://twitter.com/ShawhinT)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**社交媒体**: [YouTube 🎥](https://www.youtube.com/channel/UCa9gErQ9AE5jT2DZLjXBIdA)
    | [LinkedIn](https://www.linkedin.com/in/shawhintalebi/) | [Twitter](https://twitter.com/ShawhinT)'
- en: '**Support**: [Buy me a coffee](https://www.buymeacoffee.com/shawhint) ☕️'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**支持**: [请我喝咖啡](https://www.buymeacoffee.com/shawhint) ☕️'
- en: '[](https://shawhin.medium.com/subscribe?source=post_page-----230e4cae7971--------------------------------)
    [## Get FREE access to every new story I write'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shawhin.medium.com/subscribe?source=post_page-----230e4cae7971--------------------------------)
    [## 免费获取我写的每一篇新故事'
- en: Get FREE access to every new story I write P.S. I do not share your email with
    anyone By signing up, you will create a…
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 免费获取我写的每一篇新故事 P.S. 我不会将你的电子邮件分享给任何人 注册后，你将创建一个…
- en: shawhin.medium.com](https://shawhin.medium.com/subscribe?source=post_page-----230e4cae7971--------------------------------)
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: shawhin.medium.com](https://shawhin.medium.com/subscribe?source=post_page-----230e4cae7971--------------------------------)
- en: '[1] [OpenAI Models documentation](https://platform.openai.com/docs/models)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [OpenAI 模型文档](https://platform.openai.com/docs/models)'
- en: '[2] [GPT-4 Availability & Completions API Deprecation](https://openai.com/blog/gpt-4-api-general-availability)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [GPT-4 可用性与完成 API 废弃](https://openai.com/blog/gpt-4-api-general-availability)'
- en: '[3] Temperature definition from [API reference](https://platform.openai.com/docs/api-reference/chat/create)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] 温度定义来自于 [API 参考](https://platform.openai.com/docs/api-reference/chat/create)'
