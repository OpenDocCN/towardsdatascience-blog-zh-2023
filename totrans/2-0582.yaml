- en: Cracking Open the OpenAI (Python) API
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 破解OpenAI（Python）API
- en: 原文：[https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971](https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971](https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971)
- en: '**A complete beginner-friendly introduction with example code**'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**一个完整的初学者友好介绍，附示例代码**'
- en: '[](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)[![Shaw
    Talebi](../Images/1449cc7c08890e2078f9e5d07897e3df.png)](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)[](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)
    [Shaw Talebi](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)[![Shaw
    Talebi](../Images/1449cc7c08890e2078f9e5d07897e3df.png)](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)[](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)
    [Shaw Talebi](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)
    ·12 min read·Jul 21, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)
    ·阅读时间12分钟·2023年7月21日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/2c856f26ccf574ede1e5d700f75668e9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2c856f26ccf574ede1e5d700f75668e9.png)'
- en: Photo by [Martin Sanchez](https://unsplash.com/@martinsanchez?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Martin Sanchez](https://unsplash.com/@martinsanchez?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: This is the 2nd article in a [series](/a-practical-introduction-to-llms-65194dda1148)
    on using Large Language Models (LLMs) in practice. Here I present a beginner-friendly
    introduction to the OpenAI API. This allows you to go beyond restrictive chat
    interfaces like ChatGPT and to get more out of LLMs for your unique use cases.
    Python example code is provided below and at the [GitHub repository](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/openai-api).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这是关于在实践中使用大型语言模型（LLMs）的[系列文章](/a-practical-introduction-to-llms-65194dda1148)的第二篇。这里我提供了一个适合初学者的OpenAI
    API介绍。这使你能够超越像ChatGPT这样的限制性聊天界面，并为你的独特用例更好地利用LLMs。下面提供了Python示例代码和[GitHub仓库](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/openai-api)。
- en: 'Table of Contents:'
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目录：
- en: What’s an API?
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是API？
- en: OpenAI’s (Python) API
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: OpenAI的（Python）API
- en: Getting Started (4 Steps)
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开始使用（4个步骤）
- en: Example Code
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 示例代码
- en: In the [first article](/a-practical-introduction-to-llms-65194dda1148) of this
    series, I described [**Prompt Engineering**](/cracking-open-the-openai-python-api-230e4cae7971)
    as the **most accessible way to use LLMs** in practice. The easiest (and most
    popular) way to do this is via tools like ChatGPT, which provide an intuitive,
    no-cost, and no-code way to interact with an LLM.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第一篇文章](/a-practical-introduction-to-llms-65194dda1148)中，我描述了[**提示工程**](/cracking-open-the-openai-python-api-230e4cae7971)作为**使用LLMs的最便捷方法**。最简单（也是最流行）的方法是通过像ChatGPT这样的工具，它们提供了直观、无需成本和无需编码的LLM交互方式。
- en: '[](/a-practical-introduction-to-llms-65194dda1148?source=post_page-----230e4cae7971--------------------------------)
    [## A Practical Introduction to LLMs'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/a-practical-introduction-to-llms-65194dda1148?source=post_page-----230e4cae7971--------------------------------)
    [## LLMs的实用入门'
- en: 3 levels of using LLMs in practice
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实践中使用LLMs的3个层次
- en: towardsdatascience.com](/a-practical-introduction-to-llms-65194dda1148?source=post_page-----230e4cae7971--------------------------------)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/a-practical-introduction-to-llms-65194dda1148?source=post_page-----230e4cae7971--------------------------------)
- en: However, this **ease of use comes at a cost**. Namely, the chat UI is restrictive
    and does not translate well to many practical use cases e.g. building your own
    customer support bot, real-time sentiment analysis of customer reviews, etc.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种**使用简便性是有代价的**。即聊天界面具有限制，且不适用于许多实际应用场景，例如构建自己的客户支持机器人、实时分析客户评论情感等。
- en: In these cases, we can take Prompt Engineering one step further and interact
    with LLMs *programmatically*. One way we can do this is via an API.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，我们可以将提示工程进一步推进，通过*编程方式*与LLMs互动。实现这一点的一种方法是通过API。
- en: '**1) What’s an API?**'
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**1) 什么是API？**'
- en: An **application programming interface (API)** allows you to interact with a
    remote application programmatically. While this might sound technical and scary,
    the idea is super simple. Consider the following analogy.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**应用程序编程接口（API）**允许你以编程方式与远程应用程序进行交互。虽然这可能听起来技术性很强且有些吓人，但其实非常简单。考虑以下类比。'
- en: Imagine you have an intense craving for the [pupusas](https://en.wikipedia.org/wiki/Pupusa)
    you ate during that summer in El Salvador. Unfortunately, you’re back at home
    and don’t know where to find good Salvadoran food. Lucky for you, however, you
    have a super-foodie friend that knows every restaurant in town.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下你对在萨尔瓦多那个夏天吃的[普普萨](https://en.wikipedia.org/wiki/Pupusa)产生了强烈的渴望。不幸的是，你回到了家里，不知道在哪里可以找到好的萨尔瓦多食物。然而，你有一个超级吃货朋友，他知道城里每一家餐馆。
- en: So, you send your friend the text.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，你给你的朋友发了短信。
- en: “Any good pupusa spots in town?”
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “城里有好的普普萨店吗？”
- en: Then, a couple of minutes later, you get the response.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，几分钟后，你会收到回复。
- en: “Yes! Flavors of El Salvador has the best pupusas!”
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “是的！萨尔瓦多风味的餐厅有最棒的普普萨！”
- en: While this may seem irrelevant to APIs, this is essentially how they work. You
    send a **request** to a remote application i.e. text your super-foodie friend.
    Then, the remote application sends back a **response** i.e. the text back from
    your friend.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这似乎与 API 无关，但这基本上就是它们的工作原理。你向远程应用程序发送一个**请求**，即给你的超级吃货朋友发短信。然后，远程应用程序会返回一个**响应**，即你朋友的回复。
- en: '![](../Images/d55d67b38e544c96a386e920f92da133.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d55d67b38e544c96a386e920f92da133.png)'
- en: A visual analogy of how APIs work. Image by author.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: API 工作的可视化类比。图片由作者提供。
- en: The difference between an API and the above analogy is instead of sending the
    request with your phone’s texting app, you use your favorite programming language
    e.g. Python, JavaScript, Ruby, Java, etc. This is great if you are developing
    software where some external information is required because the information retrieval
    can be automated.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: API 与上述类比之间的区别在于，你不是用手机的短信应用发送请求，而是使用你喜欢的编程语言，例如 Python、JavaScript、Ruby、Java
    等。如果你正在开发需要外部信息的软件，这非常好，因为信息检索可以自动化。
- en: '**2) OpenAI’s (Python) API**'
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**2) OpenAI 的（Python）API**'
- en: We can use APIs to interact with Large Language Models. A popular one is OpenAI’s
    API, where instead of typing prompts into the ChatGPT web interface, you can send
    them to and from OpenAI using Python.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 API 与大型语言模型进行交互。一个流行的 API 是 OpenAI 的 API，你可以使用 Python 向 OpenAI 发送和接收提示，而不是在
    ChatGPT 网络界面中输入提示。
- en: '![](../Images/49422df67ac7d25c8846a1ee770af4ad.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/49422df67ac7d25c8846a1ee770af4ad.png)'
- en: Visualization of how API calls to OpenAI works. Image by author.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: API 调用到 OpenAI 的可视化。图片由作者提供。
- en: This gives virtually anyone access to state-of-the-art LLMs (and other ML models)
    without having to provision the computational resources needed to run them. The
    downside, of course, is OpenAI doesn’t do this as a charity. Each API call costs
    money, but more on that in a bit.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得几乎任何人都可以访问最先进的LLM（和其他ML模型），而无需提供运行它们所需的计算资源。当然，缺点是 OpenAI 并不是出于慈善目的提供这些服务。每次
    API 调用都会收费，但稍后会详细说明。
- en: Some **notable features** of the API (not available with ChatGPT) are listed
    below.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: API 的一些**显著特性**（ChatGPT 不提供）如下。
- en: '**Customizable system message** (this is set to something like “*I am ChatGPT,
    a large language model trained by OpenAI, based on the GPT-3.5 architecture. My
    knowledge is based on information available up until September 2021\. Today’s
    date is July 13, 2023.*” for ChatGPT)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可定制的系统消息**（对于 ChatGPT，这设置为类似于“*我是 ChatGPT，一个由 OpenAI 训练的大型语言模型，基于 GPT-3.5
    架构。我的知识基于截至 2021 年 9 月的信息。今天的日期是 2023 年 7 月 13 日。*”的内容）'
- en: '**Adjust input parameters** such as maximum response length, number of responses,
    and temperature (i.e. the “randomness” of the response).'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**调整输入参数**，如最大响应长度、响应数量和温度（即响应的“随机性”）。'
- en: Include **images** and **other file types** in prompts
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在提示中**包含图像**和**其他文件类型**。
- en: Extract helpful word **embeddings** for downstream tasks
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取对下游任务有帮助的词语**嵌入**。
- en: '**Input audio** for transcription or translation'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入音频**以进行转录或翻译。'
- en: Model **fine-tuning** functionality
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型**微调**功能
- en: The OpenAI API has [several models](https://platform.openai.com/docs/models)
    from which to choose. The *best* model to pick will depend on your particular
    use case. Below is a list of the current models available [[1](https://platform.openai.com/docs/models)].
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI API 提供了[多个模型](https://platform.openai.com/docs/models)供选择。选择哪个*最佳*模型取决于你的具体用例。下面是当前可用模型的列表[[1](https://platform.openai.com/docs/models)]。
- en: '![](../Images/98ce3333b2824ace053715e0867ed296.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
- en: List of available models via the OpenAI API as of Jul 2023\. Image by author.
    [[1](https://platform.openai.com/docs/models)]
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '***Note****: Each item listed above is accompanied by a set of models which
    vary in size and cost. Check* [*documentation*](https://platform.openai.com/docs/models)
    *for the most recent information.*'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '**Pricing & Tokens**'
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While the OpenAI API gives developers easy access to SOTA ML models, one obvious
    downside is that it **costs money**. Pricing is done on a per-token basis (no,
    I don’t mean NFTs or something you use at the arcade).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '**Tokens**, in the context of LLMs, are essentially **a set of numbers representing
    a set of words and characters**. For example, “The” could be a token, “ end” (with
    the space) could be another, and “.” another.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Thus, the text “The End.” would consist of 3 tokens say (73, 102, 6).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1f13c26b8c5b663dd2903f54a9249d13.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
- en: Toy example showing one possible token mapping between text and integers. Image
    by author.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: This is a critical step because **LLMs (i.e. neural networks) do not “understand”
    text directly**. The text must be converted into a numerical representation so
    that the model can perform mathematical operations on the input. Hence, the tokenization
    step.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: The price of an API call depends on the number of tokens used in the prompt
    and the model being prompted. The price per model is available on [OpenAI’s website](https://openai.com/pricing).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '**3) Getting Started (4 Steps)**'
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have a basic understanding of the OpenAI API let’s see how to use
    it. Before we can start coding, we need to set up four things.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '**3.1) Make an Account (you get a $5 API credit for 1st three months)**'
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To make an account go to the [OpenAI API Overview page](https://platform.openai.com/overview),
    and click “Sign Up” in the top right corner
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Note* — If you’ve used ChatGPT before, then you probably already have an OpenAI
    account. If so, click “Log in”'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**3.2) Add Payment Method**'
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If your account is more than 3 months old or the free $5 API credit is not enough
    for you, you will need to add a payment method before making API calls.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click your profile image and select the manage account option.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then add a payment method by clicking the “Billing” tab and then “Payment methods”.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**3.3) Set Usage Limits**'
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next, I recommend setting usage limits so that you **avoid being billed more
    than you budget for**.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To do this, go to the “Usage limits” under the “Billing” tab. Here you can set
    a “Soft” and “Hard” limit.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you hit your monthly **soft limit,** OpenAI will send you an **email notification**.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you hit your **hard limit,** any additional API **requests will be denied**
    (thus, you won’t be charged more than this).
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**3.4) Get API Secret Key**'
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Click on “View API keys”
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If this is your first time, you will need to make a new secret key. To do this,
    click “Create new secret key”
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, you can give your key a custom name. Here I used “my-first-key”.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, click “Create secret key”
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**4) Example Code: Chat Completion API**'
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With all the setup done, we are (finally) ready to make our first API call.
    Here we will use the [openai Python library](https://github.com/openai/openai-python),
    which makes integrating OpenAI’s models into your Python code super easy. You
    can download the package via [pip](https://pypi.org/project/openai/)*.* The below
    example code (and bonus code) is available on the [GitHub repo](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/openai-api)
    for this article.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '***A quick note on Completions API deprecations* —** OpenAI is moving away
    from the freeform prompt paradigm and toward chat-based API calls. According to
    a blog from OpenAI, the chat-based paradigm provides better responses, given its
    structured prompt interface, compared to the previous paradigm [[2](https://openai.com/blog/gpt-4-api-general-availability)].'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: While older OpenAI (GPT-3) models are still available via the “freeform” paradigm,
    the more recent (and powerful) models (i.e. GPT-3.5-turbo and GPT-4) are only
    available via chat-based calls.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with a super simple API call. Here we will pass **two inputs** into
    the ***openai.ChatCompletions.create()*** method i.e. **model** and **messages**.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '**model** — defines the name of the language model we want to use (we can choose
    from the models listed earlier in the article.)'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**messages** — sets the “preceding” chat dialogue as a list of dictionaries.
    The dictionaries have two key-value pairs (e.g. {“role”: “user”, “content”: “Listen
    to your”}.) **First**, “role” defines *who is talking* (e.g. “role”:”user”). This
    can either be the “user”, “assistant”, or “system”. **Second**, “content” defines
    *what the role is saying* (e.g. “content”: “Listen to your”). While this may feel
    more restrictive than a freeform prompt interface, we can get creative with input
    messages to optimize responses for a particular use case (more on this later).'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is what our first API call looks like in Python.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The API response is stored in the *chat_completion* variable. Printing *chat_completion*,
    we see that it is like a dictionary consisting of 6 key-value pairs.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The meaning of each field is listed below.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '**‘Id’** = unique ID for the API response'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**‘Object’** = name of API object that sent the response'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**‘Created’** = unix timestamp of when the API request was processed'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**‘Model’** = name of the model used'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**‘Choices’** = model response formatted in JSON (i.e. dictionary-like)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**‘Usage’** = token count meta-data formatted in JSON (i.e. dictionary-like)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, the main thing we care about here is the ‘**Choices**’ field since
    this is **where the model response is stored**. In this case, we see the “assistant”
    role responds with the message *“****heart.”***
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Yay! We made our 1st API call. Now let’s start playing with the model input
    parameters.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: max_tokens
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, we can set the **maximum number of tokens** allowed in the model response
    using the *max_tokens* input parameter. This can be helpful for many reasons depending
    on the use case. In this case, I just want a one-word response, so I’ll set it
    to 1 token.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: n
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next, we can set the **number of responses** we would like to receive from the
    model. Again, this can be helpful for many reasons depending on the use case.
    For example, if we want to generate a set of responses from which we can select
    the one we like best.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Notice that **not all the completions are identical**. This may be a good thing
    or a bad thing based on the use case (e.g. creative use cases vs. process automation
    use cases). Therefore, it can be advantageous to adjust the *diversity* of chat
    completions for a given prompt.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: temperature
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It turns out we can do this by tuning the **temperature** parameter. Put simply,
    this **adjusts the “randomness” of chat completions**.Values for this parameter
    **range from 0 to 2**, where 0 makes completions more predictable, and 2 makes
    them less predictable [[3](https://platform.openai.com/docs/api-reference/chat/create)].
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Conceptually, we can think of temp=0 will default to the most likely next word
    while temp=2 will enable completions that are relatively unlikely. Let’s see what
    this looks like.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As expected, when temp=0, all 5 completions are identical and produce something
    “very likely.” Now let’s see what happens when we **turn up the temperature**.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Again, as expected, the chat completions with temp=2 were much more diverse
    and “out of pocket.”
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: 'messages roles: Lyric Completion Assistant'
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finally, we can leverage the different roles in this chat-based prompting paradigm
    to adjust the language model responses even further.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall from earlier that we can include content from 3 different roles in our
    prompts: **system**, **user**, and **assistant**. The **system** message **sets
    the context (or task) for model completions** *e.g. “You are a friendly chatbot
    that does not want to destroy all humans” or “Summarize user prompts in max 10
    words”.*'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '**User** and **assistant** messages can be used in at least two ways. **One**,
    to generate examples for **in-context learning**, and **two**, to store and update
    **conversation history** for a real-time chatbot. Here we will use both ways to
    create a lyric completion assistant.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: We start by making the **system message** *“I am Roxette lyric completion assistant.
    When given a line from a song, I will provide the next line in the song.”* Then,
    provide **two examples of** **user and assistant messages**. Followed by the same
    **user prompt** used in the preceding examples i.e.*“Listen to your”.*
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Here’s what that looks like in code.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Comparing the output to the [actual lyrics](https://www.azlyrics.com/lyrics/roxette/listentoyourheart.html)
    to the hit Roxette song, we see they are an exact match. This is due to the combination
    of all the different inputs we provided to the model.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 'To see what this looks like when we “*crank the temperature*,” check out the
    bonus code on [GitHub](https://github.com/ShawhinT/YouTube-Blog/blob/main/LLMs/openai-api/openai-api-demo.ipynb).
    (Warning: it gets weird)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here I gave a beginner-friendly guide to the OpenAI Python API with example
    code. The biggest upside of using OpenAI’s API is you can work with powerful LLMs
    without worrying about provisioning computational resources. The **downsides**,
    however, are **API calls cost money** and potential **security concerns** of sharing
    some types of data with a 3rd party (OpenAI).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: To avoid these downsides, we can turn to open-source LLM solutions. This will
    be the focus of the [next article](https://medium.com/towards-data-science/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)
    in this series, where we’ll explore the Hugging Face Transformers library.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '👉 **More on LLMs**: [Introduction](/a-practical-introduction-to-llms-65194dda1148)
    | [Hugging Face Transformers](https://medium.com/towards-data-science/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)
    | [Prompt Engineering](https://medium.com/towards-data-science/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f)
    | [Fine-tuning](https://medium.com/towards-data-science/fine-tuning-large-language-models-llms-23473d763b91)
    | [Build an LLM](/how-to-build-an-llm-from-scratch-8c477768f1f9) | [QLoRA](/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32)
    | [RAG](https://medium.com/towards-data-science/how-to-improve-llms-with-rag-abdc132f76ac)
    | [Text Embeddings](/text-embeddings-classification-and-semantic-search-8291746220be)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '![Shaw Talebi](../Images/02eefb458c6eeff7cd29d40c212e3b22.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
- en: '[Shaw Talebi](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Large Language Models (LLMs)
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://shawhin.medium.com/list/large-language-models-llms-8e009ae3054c?source=post_page-----230e4cae7971--------------------------------)13
    stories![](../Images/82e865594c68f5307e75665842d197bb.png)![](../Images/b9436354721f807e0390b5e301be2119.png)![](../Images/59c8db581de77a908457dec8981f3c37.png)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Resources
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Connect**: [My website](https://shawhintalebi.com/) | [Book a call](https://calendly.com/shawhintalebi)
    | [Ask me anything](https://shawhintalebi.com/contact/)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '**Socials**: [YouTube 🎥](https://www.youtube.com/channel/UCa9gErQ9AE5jT2DZLjXBIdA)
    | [LinkedIn](https://www.linkedin.com/in/shawhintalebi/) | [Twitter](https://twitter.com/ShawhinT)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '**Support**: [Buy me a coffee](https://www.buymeacoffee.com/shawhint) ☕️'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://shawhin.medium.com/subscribe?source=post_page-----230e4cae7971--------------------------------)
    [## Get FREE access to every new story I write'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Get FREE access to every new story I write P.S. I do not share your email with
    anyone By signing up, you will create a…
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: shawhin.medium.com](https://shawhin.medium.com/subscribe?source=post_page-----230e4cae7971--------------------------------)
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '[1] [OpenAI Models documentation](https://platform.openai.com/docs/models)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '[2] [GPT-4 Availability & Completions API Deprecation](https://openai.com/blog/gpt-4-api-general-availability)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '[3] Temperature definition from [API reference](https://platform.openai.com/docs/api-reference/chat/create)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
