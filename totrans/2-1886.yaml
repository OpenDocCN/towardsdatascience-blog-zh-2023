- en: Solve a mystery box like a data scientist
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åƒæ•°æ®ç§‘å­¦å®¶ä¸€æ ·è§£å†³ç¥ç§˜ç›’å­
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/solve-a-mystery-box-like-a-data-scientist-f9ee9570ba52](https://towardsdatascience.com/solve-a-mystery-box-like-a-data-scientist-f9ee9570ba52)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/solve-a-mystery-box-like-a-data-scientist-f9ee9570ba52](https://towardsdatascience.com/solve-a-mystery-box-like-a-data-scientist-f9ee9570ba52)
- en: Get data, train ViT, minimize problem; and way too overkill
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è·å–æ•°æ®ï¼Œè®­ç»ƒ ViTï¼Œæœ€å°åŒ–é—®é¢˜ï¼›å®åœ¨æ˜¯è¿‡åº¦å¤„ç†
- en: '[](https://dennisbakhuis.medium.com/?source=post_page-----f9ee9570ba52--------------------------------)[![Dennis
    Bakhuis](../Images/4dc6dca031cdedbb044a1d0a6b142186.png)](https://dennisbakhuis.medium.com/?source=post_page-----f9ee9570ba52--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f9ee9570ba52--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f9ee9570ba52--------------------------------)
    [Dennis Bakhuis](https://dennisbakhuis.medium.com/?source=post_page-----f9ee9570ba52--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dennisbakhuis.medium.com/?source=post_page-----f9ee9570ba52--------------------------------)[![Dennis
    Bakhuis](../Images/4dc6dca031cdedbb044a1d0a6b142186.png)](https://dennisbakhuis.medium.com/?source=post_page-----f9ee9570ba52--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f9ee9570ba52--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f9ee9570ba52--------------------------------)
    [Dennis Bakhuis](https://dennisbakhuis.medium.com/?source=post_page-----f9ee9570ba52--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f9ee9570ba52--------------------------------)
    Â·17 min readÂ·Jan 13, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f9ee9570ba52--------------------------------)
    Â·é˜…è¯»æ—¶é—´17åˆ†é’ŸÂ·2023å¹´1æœˆ13æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/b9a4946ac13a6d2ed63ff0370c95ba55.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b9a4946ac13a6d2ed63ff0370c95ba55.png)'
- en: 'Figure 1: A mystery box, the process of collecting data, and eventually an
    open lock.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾1ï¼šä¸€ä¸ªç¥ç§˜ç›’å­ã€æ•°æ®æ”¶é›†è¿‡ç¨‹ï¼Œä»¥åŠæœ€ç»ˆæ‰“å¼€çš„é”ã€‚
- en: What happens when a data scientist gets a riddle in form of a box? Of course
    he will (try) approach it as a data problem. In this article I will describe the
    whole process, and to be honest, it was not as easy as I thought. As with many
    problems, you can get completely lost and only by talking to a couple of friends,
    I got back on track again.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä¸€ä¸ªæ•°æ®ç§‘å­¦å®¶å¾—åˆ°ä¸€ä¸ªä»¥ç›’å­å½¢å¼å‡ºç°çš„è°œé¢˜æ—¶ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿå½“ç„¶ï¼Œä»–ä¼šï¼ˆå°è¯•ï¼‰å°†å…¶ä½œä¸ºæ•°æ®é—®é¢˜æ¥è§£å†³ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†æè¿°æ•´ä¸ªè¿‡ç¨‹ï¼Œå¦ç™½è¯´ï¼Œè¿™å¹¶ä¸åƒæˆ‘æƒ³è±¡çš„é‚£ä¹ˆå®¹æ˜“ã€‚ä¸è®¸å¤šé—®é¢˜ä¸€æ ·ï¼Œä½ å¯èƒ½ä¼šå®Œå…¨è¿·å¤±ï¼Œåªæœ‰é€šè¿‡ä¸å‡ ä¸ªæœ‹å‹äº¤è°ˆï¼Œæˆ‘æ‰å¾—ä»¥é‡æ–°å›åˆ°æ­£è½¨ã€‚
- en: As a data scientist, I like to approach this problem in a data manner. I realize
    that this method is far from the most obvious solution. But it was a very fun
    endeavor. Collecting too much data, train a transformer model to extract values
    from a video, and eventually use a `minimizer` to find the solution. This article
    is a summary of this (mostly) fun journey!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºä¸€ä¸ªæ•°æ®ç§‘å­¦å®¶ï¼Œæˆ‘å–œæ¬¢ä»¥æ•°æ®çš„æ–¹å¼æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚æˆ‘æ„è¯†åˆ°è¿™ç§æ–¹æ³•è¿œéæœ€æ˜æ˜¾çš„è§£å†³æ–¹æ¡ˆã€‚ä½†è¿™æ˜¯ä¸€ä¸ªéå¸¸æœ‰è¶£çš„å°è¯•ã€‚æ”¶é›†è¿‡å¤šçš„æ•°æ®ï¼Œè®­ç»ƒä¸€ä¸ªå˜å‹å™¨æ¨¡å‹ä»è§†é¢‘ä¸­æå–å€¼ï¼Œæœ€åä½¿ç”¨
    `minimizer` æ‰¾åˆ°è§£å†³æ–¹æ¡ˆã€‚æœ¬æ–‡æ˜¯è¿™ä¸ªï¼ˆå¤§éƒ¨åˆ†ï¼‰æœ‰è¶£æ—…ç¨‹çš„æ€»ç»“ï¼
- en: 'I have divided this article in a couple of (for me) logical steps. Feel free
    to skip to parts you like:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†è¿™ç¯‡æ–‡ç« åˆ†æˆäº†å‡ ä¸ªï¼ˆå¯¹æˆ‘è€Œè¨€ï¼‰é€»è¾‘æ­¥éª¤ã€‚ä½ å¯ä»¥éšæ„è·³è¿‡ä½ å–œæ¬¢çš„éƒ¨åˆ†ï¼š
- en: What is this â€œmystery boxâ€ youâ€™re talking about
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½ æåˆ°çš„è¿™ä¸ªâ€œç¥ç§˜ç›’å­â€æ˜¯ä»€ä¹ˆï¼Ÿ
- en: A formal problem description
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ­£å¼çš„é—®é¢˜æè¿°
- en: Collecting the required data
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ”¶é›†æ‰€éœ€çš„æ•°æ®
- en: Processing the data goodness (label, train, inference)
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¤„ç†æ•°æ®çš„å–„æ„ï¼ˆæ ‡è®°ã€è®­ç»ƒã€æ¨æ–­ï¼‰
- en: Analyze the dataset and find the goal
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ†ææ•°æ®é›†å¹¶æ‰¾åˆ°ç›®æ ‡
- en: Going to the location
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å‰å¾€ä½ç½®
- en: '*All images in this article have been taken or are generated by me unless stated
    otherwise in the separate captions (which is none in this article).*'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*é™¤éåœ¨å•ç‹¬çš„è¯´æ˜ä¸­å¦æœ‰è¯´æ˜ï¼ˆåœ¨æœ¬æ–‡ä¸­æ²¡æœ‰ï¼‰ï¼Œå¦åˆ™æœ¬æ–‡ä¸­çš„æ‰€æœ‰å›¾åƒå‡ç”±æˆ‘æ‹æ‘„æˆ–ç”Ÿæˆã€‚*'
- en: '[All code](https://github.com/dennisbakhuis/mystery_box) for this project is
    shared in Notebooks and is available on my [Github account](https://github.com/dennisbakhuis).
    If you have any comments or questions, I like to hear them through [LinkedIn](https://linkedin.com/in/dennisbakhuis).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ­¤é¡¹ç›®çš„æ‰€æœ‰ä»£ç ](https://github.com/dennisbakhuis/mystery_box)éƒ½åœ¨ Notebooks ä¸­å…±äº«ï¼Œå¹¶ä¸”å¯ä»¥åœ¨æˆ‘çš„
    [Github è´¦å·](https://github.com/dennisbakhuis)ä¸Šæ‰¾åˆ°ã€‚å¦‚æœä½ æœ‰ä»»ä½•è¯„è®ºæˆ–é—®é¢˜ï¼Œæˆ‘å¾ˆä¹æ„é€šè¿‡ [LinkedIn](https://linkedin.com/in/dennisbakhuis)å¬å–ã€‚'
- en: What is this â€œmystery boxâ€ youâ€™re talking about?
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½ æåˆ°çš„è¿™ä¸ªâ€œç¥ç§˜ç›’å­â€æ˜¯ä»€ä¹ˆï¼Ÿ
- en: For my birthday my friend Sander gave me a mysterious box and with the big grin
    on his face, this would keep me busy for a while.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ç”Ÿæ—¥é‚£å¤©ï¼Œæˆ‘çš„æœ‹å‹ Sander ç»™äº†æˆ‘ä¸€ä¸ªç¥ç§˜çš„ç›’å­ï¼Œä»–è„¸ä¸Šå¸¦ç€å¤§å¤§çš„ç¬‘å®¹ï¼Œè¿™å°†è®©æˆ‘å¿™ä¸Šä¸€æ®µæ—¶é—´ã€‚
- en: The mystery box immediately looked very intriguing (see figure 1). It was clear
    that the box was created by Sander himself as it had the very distinct fused deposition
    modeling (FDM) printing pattern. The front showed a common LCD screen and a red
    button. On the left side, a relatively large padlock was visible. This is one
    of these code padlocks that required a four digit code to open. The padlock keeps
    a sliding lid from opening at the bottom of the box. On the right side is a small
    excess compartment that holds a 9 volt battery. Pretty smart to have the battery
    outside so that it can be exchanged when the power is getting low.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ç¥ç§˜ç›’å­ç«‹åˆ»çœ‹èµ·æ¥éå¸¸å¼•äººå…¥èƒœï¼ˆè§å›¾ 1ï¼‰ã€‚æ˜¾ç„¶ï¼Œè¿™ä¸ªç›’å­æ˜¯ç”± Sander äº²è‡ªåˆ¶ä½œçš„ï¼Œå› ä¸ºå®ƒå…·æœ‰éå¸¸æ˜æ˜¾çš„ç†”èæ²‰ç§¯å»ºæ¨¡ï¼ˆFDMï¼‰æ‰“å°å›¾æ¡ˆã€‚æ­£é¢å±•ç¤ºäº†ä¸€ä¸ªå¸¸è§çš„
    LCD å±å¹•å’Œä¸€ä¸ªçº¢è‰²æŒ‰é’®ã€‚å·¦ä¾§æœ‰ä¸€ä¸ªç›¸å¯¹è¾ƒå¤§çš„æŒ‚é”ã€‚è¿™æ˜¯ä¸€ä¸ªéœ€è¦å››ä½æ•°å­—ä»£ç æ‰èƒ½æ‰“å¼€çš„æŒ‚é”ã€‚æŒ‚é”é˜²æ­¢ç›’å­åº•éƒ¨çš„æ»‘ç›–æ‰“å¼€ã€‚å³ä¾§æ˜¯ä¸€ä¸ªå°çš„å¤šä½™ç©ºé—´ï¼Œç”¨æ¥æ”¾ç½®ä¸€ä¸ª
    9 ä¼ç‰¹çš„ç”µæ± ã€‚ç”µæ± å¤–ç½®æ˜¯ç›¸å½“èªæ˜çš„ï¼Œè¿™æ ·å½“ç”µé‡ä½æ—¶å¯ä»¥æ›´æ¢ã€‚
- en: '![](../Images/64fec328a8b6c2848e19b61816d78386.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/64fec328a8b6c2848e19b61816d78386.png)'
- en: 'Figure 2: This is the mystery box: a 3D printed device with a screen, a button,
    and a padlock.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 2ï¼šè¿™æ˜¯ç¥ç§˜ç›’å­ï¼šä¸€ä¸ªå¸¦æœ‰å±å¹•ã€æŒ‰é’®å’ŒæŒ‚é”çš„ 3D æ‰“å°è®¾å¤‡ã€‚
- en: From a creators point of view, the mystery box has a quite interesting design.
    The top side (as seen in figure 2) was used as base during printing as this side
    is much coarser than the others. This makes the excess battery holder also printable
    without support. Still, I am not completely sure how the hole for the LCD screen
    is created. The most simple method would be to print light supports which are
    cut away. For the ledges that are used for the padlock, the remains of the printing
    support are still visible. All with all, a nice project to keep your printer running
    for at least 8 hours.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ä»åˆ›é€ è€…çš„è§’åº¦æ¥çœ‹ï¼Œç¥ç§˜ç›’å­æœ‰ä¸€ä¸ªç›¸å½“æœ‰è¶£çš„è®¾è®¡ã€‚é¡¶é¢ï¼ˆå¦‚å›¾ 2 æ‰€ç¤ºï¼‰åœ¨æ‰“å°è¿‡ç¨‹ä¸­ä½œä¸ºåŸºç¡€ä½¿ç”¨ï¼Œå› ä¸ºè¿™ä¸ªé¢æ¯”å…¶ä»–é¢ç²—ç³™å¾—å¤šã€‚è¿™ä½¿å¾—å¤šä½™çš„ç”µæ± æ¶ä¹Ÿå¯ä»¥åœ¨æ²¡æœ‰æ”¯æ’‘çš„æƒ…å†µä¸‹æ‰“å°ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæˆ‘è¿˜æ˜¯ä¸å®Œå…¨ç¡®å®š
    LCD å±å¹•çš„å­”æ˜¯å¦‚ä½•åˆ›å»ºçš„ã€‚æœ€ç®€å•çš„æ–¹æ³•æ˜¯æ‰“å°è½»è´¨æ”¯æ’‘ï¼Œç„¶ååˆ‡é™¤ã€‚ç”¨äºæŒ‚é”çš„å°é˜¶ä¸Šçš„æ‰“å°æ”¯æ’‘æ®‹ç•™ç‰©ä»ç„¶å¯è§ã€‚æ€»ä½“æ¥è¯´ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸é”™çš„é¡¹ç›®ï¼Œå¯ä»¥è®©ä½ çš„æ‰“å°æœºè¿è¡Œè‡³å°‘
    8 å°æ—¶ã€‚
- en: 'The red button is a kind of toggle press button. When pressing you hear it
    latch and the LCD screen turns on. After a few seconds the box greets you with
    â€œHi!!!â€ a classical gag at the [Physics of Fluids research group](https://pof.tnw.utwente.nl/).
    The next couple of messages shown on the screen are in Dutch. For an overview
    of the screens see figure 3\. Here are some quick translations:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: çº¢è‰²æŒ‰é’®æ˜¯ä¸€ç§åˆ‡æ¢æŒ‰é”®ã€‚æŒ‰ä¸‹æ—¶ä½ ä¼šå¬åˆ°å®ƒå¡æ‰£çš„å£°éŸ³ï¼ŒLCD å±å¹•ä¼šäº®èµ·ã€‚å‡ ç§’é’Ÿåï¼Œç›’å­ä¼šç”¨â€œHi!!!â€å‘ä½ æ‰“æ‹›å‘¼ï¼Œè¿™æ˜¯åœ¨[æµä½“ç‰©ç†ç ”ç©¶ç»„](https://pof.tnw.utwente.nl/)çš„ç»å…¸æç¬‘æ–¹å¼ã€‚æ¥ä¸‹æ¥å‡ æ¡å±å¹•ä¸Šçš„ä¿¡æ¯æ˜¯è·å…°è¯­ã€‚æœ‰å…³å±å¹•çš„æ¦‚è¿°è¯·å‚è§å›¾
    3ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¿«é€Ÿç¿»è¯‘ï¼š
- en: Hi!!! -> <low pitched voice> Hi </low pitched voice>
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Hi!!! -> <ä½éŸ³è°ƒçš„å£°éŸ³> Hi </ä½éŸ³è°ƒçš„å£°éŸ³>
- en: Van harte gefeliciteerd! -> Sincere gratulations!
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Van harte gefeliciteerd! -> çœŸè¯šçš„ç¥è´ºï¼
- en: Vind de twee punten en ga -> find the two coordinates and go
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Vind de twee punten en ga -> æ‰¾åˆ°ä¸¤ä¸ªåæ ‡å¹¶å‰å¾€
- en: naar het midden van de puntenâ€¦ -> to the center of the coordinatesâ€¦
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: naar het midden van de puntenâ€¦ -> åˆ°åæ ‡çš„ä¸­å¿ƒâ€¦
- en: Zoekt gpsâ€¦ Een momentâ€¦ -> Searching gpsâ€¦ One momentâ€¦
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Zoekt gpsâ€¦ Een momentâ€¦ -> æ­£åœ¨æœç´¢ GPSâ€¦ è¯·ç¨ç­‰â€¦
- en: Afstand(p1)-Afstand(p2)=1048m -> Distance(p1)-Distance(p2)=1048m
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Afstand(p1)-Afstand(p2)=1048m -> è·ç¦»(p1)-è·ç¦»(p2)=1048m
- en: '![](../Images/a85c19a920176ede8eda0d9d89fa108d.png)![](../Images/10368af95b1b1e248cbbd335ed33d8da.png)![](../Images/44ad73d3fed17db0650ba714b8e1f176.png)![](../Images/0cd976e47b101c9f15fcead048fbe269.png)![](../Images/eefa6f7b926a318d23cc38f9e52f75eb.png)![](../Images/acb403272a2e6c5765a23f65180e27e1.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a85c19a920176ede8eda0d9d89fa108d.png)![](../Images/10368af95b1b1e248cbbd335ed33d8da.png)![](../Images/44ad73d3fed17db0650ba714b8e1f176.png)![](../Images/0cd976e47b101c9f15fcead048fbe269.png)![](../Images/eefa6f7b926a318d23cc38f9e52f75eb.png)![](../Images/acb403272a2e6c5765a23f65180e27e1.png)'
- en: 'Figure 3: Turning on the device shows various messages in Dutch, including
    a couple of hints.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 3ï¼šæ‰“å¼€è®¾å¤‡ä¼šæ˜¾ç¤ºå„ç§è·å…°è¯­ä¿¡æ¯ï¼ŒåŒ…æ‹¬å‡ ä¸ªæç¤ºã€‚
- en: After the two hint screens, the system is busy with searching for a GPS signal.
    This process, the so called â€˜time to first fixâ€™ (TTFF) can be lengthy as the device
    always has to do a so called â€œcold bootâ€. This can take up to five minutes according
    to the standard.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸¤ä¸ªæç¤ºå±å¹•ä¹‹åï¼Œç³»ç»Ÿæ­£åœ¨å¿™äºæœç´¢ GPS ä¿¡å·ã€‚è¿™ä¸ªè¿‡ç¨‹ï¼Œå³æ‰€è°“çš„â€œç¬¬ä¸€æ¬¡å®šä½æ—¶é—´â€ï¼ˆTTFFï¼‰ï¼Œå¯èƒ½å¾ˆé•¿ï¼Œå› ä¸ºè®¾å¤‡æ€»æ˜¯éœ€è¦è¿›è¡Œæ‰€è°“çš„â€œå†·å¯åŠ¨â€ã€‚æ ¹æ®æ ‡å‡†ï¼Œè¿™å¯èƒ½éœ€è¦é•¿è¾¾äº”åˆ†é’Ÿã€‚
- en: 'Finally, after a GPS fix, the box comes into its main operation screen that
    shows us its only output: the distance to point 1 minus the distance to point
    2 which is a integer value in meters.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œåœ¨ GPS å›ºå®šåï¼Œç›’å­è¿›å…¥ä¸»æ“ä½œç•Œé¢ï¼Œæ˜¾ç¤ºå®ƒå”¯ä¸€çš„è¾“å‡ºï¼šç‚¹ 1 åˆ°ç‚¹ 2 çš„è·ç¦»å·®ï¼Œä»¥ç±³ä¸ºå•ä½çš„æ•´æ•°å€¼ã€‚
- en: 'Sander also gave some additional clarification of the unit. The unit outputs
    a value which is the difference between two distances: d1 and d2\. These distances
    are the distance between the current location of the box and two unknown coordinates.
    The goal is to find the coordinate exactly between these two unknown coordinates.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æ¡‘å¾·è¿˜å¯¹å•ä½åšäº†ä¸€äº›é¢å¤–çš„è¯´æ˜ã€‚è¯¥å•ä½è¾“å‡ºä¸€ä¸ªå€¼ï¼Œè¯¥å€¼æ˜¯ä¸¤è·ç¦»*d1*å’Œ*d2*ä¹‹é—´çš„å·®å€¼ã€‚è¿™äº›è·ç¦»æ˜¯å½“å‰ç®±å­ä½ç½®ä¸ä¸¤ä¸ªæœªçŸ¥åæ ‡ä¹‹é—´çš„è·ç¦»ã€‚ç›®æ ‡æ˜¯æ‰¾åˆ°æ­£å¥½ä½äºè¿™ä¸¤ä¸ªæœªçŸ¥åæ ‡ä¹‹é—´çš„åæ ‡ã€‚
- en: This all sounds easy but lets have a look at a more formal description.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¬èµ·æ¥å¾ˆç®€å•ï¼Œä½†è®©æˆ‘ä»¬çœ‹çœ‹æ›´æ­£å¼çš„æè¿°ã€‚
- en: A formal problem description
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ­£å¼é—®é¢˜æè¿°
- en: The goal of the puzzle is to bring it to a specific location. If this location
    is correct, the box will show the code for the padlock. What makes this problem
    challenging is that the mystery box does not show the distance to that specific
    location.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è°œé¢˜çš„ç›®æ ‡æ˜¯å°†å…¶å¸¦åˆ°ä¸€ä¸ªç‰¹å®šçš„ä½ç½®ã€‚å¦‚æœè¿™ä¸ªä½ç½®æ˜¯æ­£ç¡®çš„ï¼Œç®±å­å°†æ˜¾ç¤ºå‡ºå¯†ç é”çš„ä»£ç ã€‚è¿™ä¸ªé—®é¢˜çš„æŒ‘æˆ˜åœ¨äºç¥ç§˜ç®±å­ä¸ä¼šæ˜¾ç¤ºåˆ°é‚£ä¸ªç‰¹å®šä½ç½®çš„è·ç¦»ã€‚
- en: The goal location *G* is exactly in the center of a line between two for us
    unknown coordinates *p1* and *p2*. The distances *d1* and *d2* are the distance
    between the current box location *B* and the coordinates *p1* and *p2*. What the
    box outputs on the screen is the difference between *d1* and *d2* which we will
    call *A*. Figure 4 shows a simplified schematic of the problem.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®æ ‡ä½ç½®*G*æ­£å¥½ä½äºä¸¤ä¸ªæœªçŸ¥åæ ‡*p1*å’Œ*p2*ä¹‹é—´çš„ä¸­ç‚¹ã€‚è·ç¦»*d1*å’Œ*d2*æ˜¯å½“å‰ç®±å­ä½ç½®*B*ä¸åæ ‡*p1*å’Œ*p2*ä¹‹é—´çš„è·ç¦»ã€‚ç®±å­åœ¨å±å¹•ä¸Šæ˜¾ç¤ºçš„æ˜¯*d1*å’Œ*d2*ä¹‹é—´çš„å·®å€¼ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸º*A*ã€‚å›¾4å±•ç¤ºäº†é—®é¢˜çš„ç®€åŒ–ç¤ºæ„å›¾ã€‚
- en: '![](../Images/a00e990bae292802ad00d1ee586501e1.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a00e990bae292802ad00d1ee586501e1.png)'
- en: 'Figure 4: A simple problem overview. The goal G is exactly between unknown
    coordinates p1 and p2\. The only information the box returns is A which is the
    difference between distances d1 and d2\. The distances d1 and d2 are respectively
    the distance between the current box location B and coordinates p1 and p2 respectively.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾4ï¼šä¸€ä¸ªç®€å•çš„é—®é¢˜æ¦‚è¿°ã€‚ç›®æ ‡*G*æ­£å¥½ä½äºæœªçŸ¥åæ ‡*p1*å’Œ*p2*ä¹‹é—´ã€‚ç®±å­è¿”å›çš„å”¯ä¸€ä¿¡æ¯æ˜¯*A*ï¼Œå³è·ç¦»*d1*å’Œ*d2*ä¹‹é—´çš„å·®å€¼ã€‚è·ç¦»*d1*å’Œ*d2*åˆ†åˆ«æ˜¯å½“å‰ç®±å­ä½ç½®*B*ä¸åæ ‡*p1*å’Œ*p2*ä¹‹é—´çš„è·ç¦»ã€‚
- en: The schematic in figure 4 shows that we have a vector problem. If we would assume
    a 2d problem space, we need two values for each coordinate to uniquely identify
    a location in the problem space.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾4ä¸­çš„ç¤ºæ„å›¾æ˜¾ç¤ºæˆ‘ä»¬æœ‰ä¸€ä¸ªå‘é‡é—®é¢˜ã€‚å¦‚æœæˆ‘ä»¬å‡è®¾ä¸€ä¸ªäºŒç»´é—®é¢˜ç©ºé—´ï¼Œæˆ‘ä»¬éœ€è¦æ¯ä¸ªåæ ‡ä¸¤ä¸ªå€¼æ¥å”¯ä¸€æ ‡è¯†é—®é¢˜ç©ºé—´ä¸­çš„ä¸€ä¸ªä½ç½®ã€‚
- en: There exists a point on which the difference *A* is zero. This is when the distance
    *d1* is equal to *d2*. In a 2d space this results in a line that is perpendicular
    to the line between *p1* and *p2* (see Figure 5). So technically, if we find two
    different locations on which A is equal to zero, we could connect those points
    and know that the goal is on that line.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å­˜åœ¨ä¸€ä¸ªç‚¹ï¼Œä½¿å¾—å·®å€¼*A*ä¸ºé›¶ã€‚è¿™æ˜¯å½“è·ç¦»*d1*ç­‰äº*d2*æ—¶ã€‚åœ¨äºŒç»´ç©ºé—´ä¸­ï¼Œè¿™ä¼šå¯¼è‡´ä¸€æ¡å‚ç›´äº*p1*å’Œ*p2*ä¹‹é—´çº¿çš„çº¿ï¼ˆè§å›¾5ï¼‰ã€‚æ‰€ä»¥ä»æŠ€æœ¯ä¸Šè®²ï¼Œå¦‚æœæˆ‘ä»¬æ‰¾åˆ°ä¸¤ä¸ªä¸åŒçš„ä½ç½®ï¼Œä½¿å¾—*A*ä¸ºé›¶ï¼Œæˆ‘ä»¬å¯ä»¥è¿æ¥è¿™äº›ç‚¹å¹¶çŸ¥é“ç›®æ ‡åœ¨é‚£æ¡çº¿ä¸Šã€‚
- en: '![](../Images/e1766d9c18cb777a4a72e1e4eda3fd9e.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e1766d9c18cb777a4a72e1e4eda3fd9e.png)'
- en: 'Figure 5: When A is equal to zero, d1 and d2 are equal. There exists a line
    perpendicular to the goal coordinate for which A is equal to zero. We could find
    this line if we find two different locations for which A is zero.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾5ï¼šå½“*A*ç­‰äºé›¶æ—¶ï¼Œ*d1*å’Œ*d2*ç›¸ç­‰ã€‚å­˜åœ¨ä¸€æ¡ä¸ç›®æ ‡åæ ‡å‚ç›´çš„çº¿ï¼Œä½¿å¾—*A*ç­‰äºé›¶ã€‚å¦‚æœæˆ‘ä»¬æ‰¾åˆ°ä¸¤ä¸ªä¸åŒçš„ä½ç½®ï¼Œä½¿å¾—*A*ä¸ºé›¶ï¼Œæˆ‘ä»¬å¯ä»¥æ‰¾åˆ°è¿™æ¡çº¿ã€‚
- en: To solve the equation we could try to solve a system of equations (four unknowns
    requires four equations) but our problem is non-linear. This makes some nasty
    equations when trying to isolate terms in the equation (Equation 1). In the equation
    *x* and *y* are the two dimensions of the current box location coordinate. Maybe
    not the most elegant but the equation can be solved numerically by minimizing
    an error function. This is exactly what we are doing in machine learning with
    gradient descent and the more recent forward-forward method.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: è¦è§£è¿™ä¸ªæ–¹ç¨‹ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•è§£ä¸€ä¸ªæ–¹ç¨‹ç»„ï¼ˆå››ä¸ªæœªçŸ¥æ•°éœ€è¦å››ä¸ªæ–¹ç¨‹ï¼‰ï¼Œä½†æˆ‘ä»¬çš„é—®é¢˜æ˜¯éçº¿æ€§çš„ã€‚è¿™ä¼šåœ¨è¯•å›¾å­¤ç«‹æ–¹ç¨‹ä¸­çš„é¡¹æ—¶äº§ç”Ÿä¸€äº›å¤æ‚çš„æ–¹ç¨‹ï¼ˆæ–¹ç¨‹1ï¼‰ã€‚åœ¨æ–¹ç¨‹ä¸­ï¼Œ*x*å’Œ*y*æ˜¯å½“å‰ç®±å­ä½ç½®åæ ‡çš„ä¸¤ä¸ªç»´åº¦ã€‚ä¹Ÿè®¸ä¸æ˜¯æœ€ä¼˜é›…çš„ï¼Œä½†è¿™ä¸ªæ–¹ç¨‹å¯ä»¥é€šè¿‡æœ€å°åŒ–è¯¯å·®å‡½æ•°æ¥æ•°å€¼æ±‚è§£ã€‚è¿™æ­£æ˜¯æˆ‘ä»¬åœ¨æœºå™¨å­¦ä¹ ä¸­ä½¿ç”¨æ¢¯åº¦ä¸‹é™å’Œæ›´ç°ä»£çš„å‰å‘å‰å‘æ–¹æ³•æ‰€åšçš„ã€‚
- en: '![](../Images/12531c0988a6e241316ff91965638518.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/12531c0988a6e241316ff91965638518.png)'
- en: 'Equation 1: Difference of distances equation for the simplified case.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹1ï¼šç®€åŒ–æƒ…å†µä¸‹çš„è·ç¦»å·®æ–¹ç¨‹ã€‚
- en: Until now we have described the problem that is only valid within the flat earth
    society. We used straight lines for our distances and this would mean that we
    need to dig tunnels in our spherical world. Instead of calculating distances on
    a plane, we need to calculate distances on the surface of a sphere. I have updated
    the problem schematic in Figure 6.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ç›´åˆ°ç°åœ¨ï¼Œæˆ‘ä»¬æè¿°çš„é—®é¢˜ä»…åœ¨å¹³é¢åœ°çƒå­¦ä¼šå†…æœ‰æ•ˆã€‚æˆ‘ä»¬ç”¨ç›´çº¿æ¥è¡¨ç¤ºè·ç¦»ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬éœ€è¦åœ¨çƒé¢ä¸–ç•Œä¸­æŒ–æ˜éš§é“ã€‚ä¸å…¶åœ¨å¹³é¢ä¸Šè®¡ç®—è·ç¦»ï¼Œæˆ‘ä»¬éœ€è¦åœ¨çƒé¢ä¸Šè®¡ç®—è·ç¦»ã€‚æˆ‘å·²ç»æ›´æ–°äº†å›¾
    6 ä¸­çš„é—®é¢˜ç¤ºæ„å›¾ã€‚
- en: Until now we have described the problem that is only valid within the flat earth
    society.
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç›´åˆ°ç°åœ¨ï¼Œæˆ‘ä»¬æè¿°çš„é—®é¢˜ä»…åœ¨å¹³é¢åœ°çƒå­¦ä¼šå†…æœ‰æ•ˆã€‚
- en: '![](../Images/3dd6d149f8d5390e3d7e37297a44954a.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3dd6d149f8d5390e3d7e37297a44954a.png)'
- en: 'Figure 6: We are not living a a flat earth. The problem is actually on the
    surface of a sphere.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 6ï¼šæˆ‘ä»¬å¹¶ä¸ç”Ÿæ´»åœ¨å¹³é¢åœ°çƒä¸Šã€‚é—®é¢˜å®é™…ä¸Šæ˜¯åœ¨çƒé¢ä¸Šã€‚
- en: 'Calculating the distance between two points of the surface of a sphere is far
    from trivial. This involves applying [the great circle distance formula](https://en.wikipedia.org/wiki/Great-circle_distance),
    which looks rather messy. Luckily, the people invented a new trigonometric function
    to make it look much more elegant: [the Haversine formula](https://en.wikipedia.org/wiki/Haversine_formula).
    If you like a good read on the problem here is a great article on [the underground
    mathematics](https://undergroundmathematics.org/trigonometry-compound-angles/the-great-circle-distance).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: è®¡ç®—çƒé¢ä¸Šä¸¤ç‚¹ä¹‹é—´çš„è·ç¦»è¿œéç®€å•ã€‚è¿™æ¶‰åŠåº”ç”¨[å¤§åœ†è·ç¦»å…¬å¼](https://en.wikipedia.org/wiki/Great-circle_distance)ï¼Œè¿™çœ‹èµ·æ¥ç›¸å½“å¤æ‚ã€‚å¹¸è¿çš„æ˜¯ï¼Œäººä»¬å‘æ˜äº†ä¸€ç§æ–°çš„ä¸‰è§’å‡½æ•°ï¼Œä½¿å…¶çœ‹èµ·æ¥æ›´ä¸ºä¼˜é›…ï¼š[å“ˆå¼—è¾›å…¬å¼](https://en.wikipedia.org/wiki/Haversine_formula)ã€‚å¦‚æœä½ å–œæ¬¢å¯¹è¿™ä¸ªé—®é¢˜çš„æ·±å…¥é˜…è¯»ï¼Œè¿™é‡Œæœ‰ä¸€ç¯‡å…³äº[åœ°ä¸‹æ•°å­¦](https://undergroundmathematics.org/trigonometry-compound-angles/the-great-circle-distance)çš„å¥½æ–‡ç« ã€‚
- en: Using the Haversine formula to calculate a single distance is quite doable,
    however, our mystery box outputs the difference between two distances *A*. This
    makes the final equation to solve extremely nasty and I think that numerically
    solving the equation makes the most sense.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å“ˆå¼—è¾›å…¬å¼æ¥è®¡ç®—å•ä¸ªè·ç¦»æ˜¯ç›¸å½“å¯è¡Œçš„ï¼Œç„¶è€Œï¼Œæˆ‘ä»¬çš„ç¥ç§˜ç®±å­è¾“å‡ºçš„æ˜¯ä¸¤ä¸ªè·ç¦» *A* ä¹‹é—´çš„å·®å€¼ã€‚è¿™ä½¿å¾—æœ€ç»ˆçš„æ–¹ç¨‹å¼æå…¶å¤æ‚ï¼Œæˆ‘è®¤ä¸ºä»æ•°å€¼ä¸Šè§£å†³è¿™ä¸ªæ–¹ç¨‹æœ€ä¸ºåˆç†ã€‚
- en: But before we can solve anything, we need acquire data. In the next section
    Iâ€™ll the describe elaborate setup.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†åœ¨æˆ‘ä»¬è§£å†³ä»»ä½•é—®é¢˜ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦è·å–æ•°æ®ã€‚åœ¨ä¸‹ä¸€éƒ¨åˆ†ï¼Œæˆ‘å°†è¯¦ç»†æè¿°è®¾ç½®è¿‡ç¨‹ã€‚
- en: Collecting the required data
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ”¶é›†æ‰€éœ€çš„æ•°æ®
- en: The biggest problem when trying to approach a physical riddle as a data problem
    is that there is most probably no data. This means that we need to collect our
    own data. From my experience as a physicist, collecting data is no easy task.
    A lot of things can (and probably will) go wrong. To be honest, I have probably
    biked more than 80km for this project.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å°è¯•å°†ç‰©ç†è°œé¢˜ä½œä¸ºæ•°æ®é—®é¢˜æ¥è§£å†³æ—¶ï¼Œæœ€å¤§çš„é—®é¢˜æ˜¯å¾ˆå¯èƒ½æ²¡æœ‰æ•°æ®ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬éœ€è¦æ”¶é›†è‡ªå·±çš„æ•°æ®ã€‚æ ¹æ®æˆ‘çš„ç‰©ç†å­¦ç»éªŒï¼Œæ”¶é›†æ•°æ®å¹¶éæ˜“äº‹ã€‚å¾ˆå¤šäº‹æƒ…å¯èƒ½ä¼šï¼ˆå¹¶ä¸”å¯èƒ½ç¡®å®ä¼šï¼‰å‡ºé”™ã€‚è€å®è¯´ï¼Œä¸ºäº†è¿™ä¸ªé¡¹ç›®ï¼Œæˆ‘å¯èƒ½å·²ç»éª‘äº†è¶…è¿‡
    80 å…¬é‡Œã€‚
- en: A lot of things can (and probably will) go wrong.
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å¾ˆå¤šäº‹æƒ…å¯èƒ½ä¼šï¼ˆä¸”å¯èƒ½ç¡®å®ä¼šï¼‰å‡ºç°é—®é¢˜ã€‚
- en: There are multiple ways we can approach the data collection. First, we could
    just move around by bike ğŸš´ (we are in ğŸ‡³ğŸ‡± so yes we ğŸš´ ğŸ˜ƒ), and stop to write down
    the current latitude and longitude and the output of the box *A*. Technically,
    a few points would suffice but where is the fun in that.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡å¤šç§æ–¹å¼æ¥æ”¶é›†æ•°æ®ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¯ä»¥éª‘è‡ªè¡Œè½¦ ğŸš´ï¼ˆæˆ‘ä»¬åœ¨ ğŸ‡³ğŸ‡±ï¼Œæ‰€ä»¥æ˜¯çš„ï¼Œæˆ‘ä»¬ğŸš´ ğŸ˜ƒï¼‰ï¼Œå¹¶åœä¸‹æ¥è®°å½•å½“å‰çš„çº¬åº¦å’Œç»åº¦ä»¥åŠç®±å­ *A* çš„è¾“å‡ºã€‚ä»æŠ€æœ¯ä¸Šè®²ï¼Œå‡ ä¸ªç‚¹å°±è¶³å¤Ÿäº†ï¼Œä½†è¿™æ ·åšæ²¡ä»€ä¹ˆè¶£å‘³ã€‚
- en: Instead of doing all this manual work, why not do some classic *over-engineering*
    and get a video of the mystery box output and match that to the data of a GPS
    logger. To do this, we need to build some kind of contraption that fixes a camera
    in front of the LCD screen of the box. The most straight forward way I could think
    of is strapping my mobile phone to some sort of container that has the minimum
    distance required to get a sharp image with the camera. A plastic box just had
    the right dimensions so I could put the box in the box and create some box-ception
    (we have to go deeper). The camera need to be sturdy such that the movement between
    camera and LCD screen was at a minimum. This calls for some serious duct-tape.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å…¶åšè¿™äº›æ‰‹åŠ¨å·¥ä½œï¼Œä¸ºä»€ä¹ˆä¸åšä¸€äº›ç»å…¸çš„*è¿‡åº¦å·¥ç¨‹*ï¼Œè·å–ç¥ç§˜ç®±è¾“å‡ºçš„è§†é¢‘ï¼Œå¹¶å°†å…¶ä¸GPSè®°å½•å™¨çš„æ•°æ®åŒ¹é…ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦åˆ¶ä½œä¸€ç§è£…ç½®ï¼Œå°†ç›¸æœºå›ºå®šåœ¨ç®±å­LCDå±å¹•å‰é¢ã€‚æˆ‘æƒ³åˆ°çš„æœ€ç›´æ¥çš„æ–¹æ³•æ˜¯å°†æ‰‹æœºç»‘åœ¨æŸç§å®¹å™¨ä¸Šï¼Œè¿™æ ·å¯ä»¥åœ¨ç›¸æœºä¸Šè·å¾—æ¸…æ™°çš„å›¾åƒã€‚ä¸€ä¸ªå¡‘æ–™ç›’å­åˆšå¥½æœ‰åˆé€‚çš„å°ºå¯¸ï¼Œå› æ­¤æˆ‘å¯ä»¥å°†ç®±å­æ”¾åœ¨ç›’å­é‡Œï¼Œåˆ¶é€ ä¸€äº›ç®±å­å¥—ç®±ï¼ˆæˆ‘ä»¬è¦æ›´æ·±å…¥ï¼‰ã€‚ç›¸æœºéœ€è¦ç¨³å›ºï¼Œä»¥ä¾¿ç›¸æœºå’ŒLCDå±å¹•ä¹‹é—´çš„ç§»åŠ¨æœ€å°åŒ–ã€‚è¿™éœ€è¦ä¸€äº›ä¸¥è‚ƒçš„èƒ¶å¸¦ã€‚
- en: Now we have a solution to record the box output as a movie. The regular camera
    app of my phone was not great so I used an app called [HD Camera](https://play.google.com/store/apps/details?id=photo.android.hd.camera&hl=en&gl=US).
    To get the current location we need a GPS logger. For this I downloaded [GPS logger](https://play.google.com/store/apps/details?id=eu.basicairdata.graziano.gpslogger&hl=en&gl=US)
    from the Playstore. With these two apps install I am ready to collect some data.
    The whole setup is shown in Figure 7.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰äº†è®°å½•ç®±å­è¾“å‡ºä¸ºç”µå½±çš„è§£å†³æ–¹æ¡ˆã€‚æˆ‘æ‰‹æœºçš„å¸¸è§„ç›¸æœºåº”ç”¨æ•ˆæœä¸å¥½ï¼Œæ‰€ä»¥æˆ‘ä½¿ç”¨äº†ä¸€ä¸ªåä¸º[HD Camera](https://play.google.com/store/apps/details?id=photo.android.hd.camera&hl=en&gl=US)çš„åº”ç”¨ç¨‹åºã€‚è¦è·å–å½“å‰ä½ç½®ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªGPSè®°å½•å™¨ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»Playstoreä¸‹è½½äº†[GPS
    logger](https://play.google.com/store/apps/details?id=eu.basicairdata.graziano.gpslogger&hl=en&gl=US)ã€‚å®‰è£…äº†è¿™ä¸¤ä¸ªåº”ç”¨ç¨‹åºåï¼Œæˆ‘å‡†å¤‡å¥½æ”¶é›†ä¸€äº›æ•°æ®ã€‚æ•´ä¸ªè®¾ç½®å¦‚å›¾7æ‰€ç¤ºã€‚
- en: '![](../Images/72f886aa8131325f28f5df6cdfaa7214.png)![](../Images/74de9ef9a4e9648aa7f541fd56b5880b.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/72f886aa8131325f28f5df6cdfaa7214.png)![](../Images/74de9ef9a4e9648aa7f541fd56b5880b.png)'
- en: 'Figure 7: Setup for collecting data. The mystery box is box-ceptioned into
    another box. On top of the box a mobile phone is strapped such that the camera
    has clear view of the LCD screen. The mobile phone as two apps active, a camera
    app and a GPS logger. The GPS logger is in floating app mode such that it keeps
    being active and not turned off by the phones power saving settings.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾7ï¼šæ•°æ®æ”¶é›†çš„è®¾ç½®ã€‚ç¥ç§˜ç®±å­è¢«ç›’å­å¥—ç®±ã€‚ç›’å­ä¸Šé¢ç»‘ç€ä¸€ä¸ªæ‰‹æœºï¼Œä»¥ä¾¿ç›¸æœºèƒ½æ¸…æ™°åœ°çœ‹åˆ°LCDå±å¹•ã€‚æ‰‹æœºä¸Šæœ‰ä¸¤ä¸ªæ´»åŠ¨åº”ç”¨ï¼Œä¸€ä¸ªç›¸æœºåº”ç”¨å’Œä¸€ä¸ªGPSè®°å½•å™¨ã€‚GPSè®°å½•å™¨å¤„äºæµ®åŠ¨åº”ç”¨æ¨¡å¼ï¼Œä»¥ä¾¿ä¿æŒæ´»åŠ¨çŠ¶æ€ï¼Œä¸è¢«æ‰‹æœºçš„çœç”µè®¾ç½®å…³é—­ã€‚
- en: 'I have already mentioned the many things that can go wrong when doing experiments.
    Here are my confessions of my many mistakes:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å·²ç»æåˆ°è¿‡åœ¨åšå®éªŒæ—¶å¯èƒ½å‡ºé”™çš„å¾ˆå¤šäº‹æƒ…ã€‚ä»¥ä¸‹æ˜¯æˆ‘çŠ¯ä¸‹çš„è®¸å¤šé”™è¯¯çš„è‡ªç™½ï¼š
- en: During my first ride the battery died. When still recording while the phone
    dies, you lose the recording. This made me add a descent power bank to the setup.
    ( ğŸš´ ~12 km).
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨ç¬¬ä¸€æ¬¡éª‘è¡Œæ—¶ç”µæ± è€—å°½äº†ã€‚å½“æ‰‹æœºåœ¨ç”µé‡è€—å°½æ—¶ä»åœ¨å½•åˆ¶æ—¶ï¼Œä½ ä¼šä¸¢å¤±å½•éŸ³ã€‚è¿™è®©æˆ‘ä¸ºè®¾å¤‡æ·»åŠ äº†ä¸€ä¸ªé¢å¤–çš„ç§»åŠ¨ç”µæºã€‚ï¼ˆ ğŸš´ ~12 kmï¼‰ã€‚
- en: Next ride my storage was full. I did not see the error message until late in
    the ride. ( ğŸš´ ~10 km).
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€æ¬¡éª‘è¡Œæ—¶æˆ‘çš„å­˜å‚¨æ»¡äº†ã€‚æˆ‘ç›´åˆ°éª‘è¡Œå¿«ç»“æŸæ—¶æ‰çœ‹åˆ°é”™è¯¯ä¿¡æ¯ã€‚ï¼ˆ ğŸš´ ~10 kmï¼‰ã€‚
- en: During another ride, I did not liked the lighting due to the sun. ( ğŸš´ ~9 km).
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨å¦ä¸€æ¬¡éª‘è¡Œä¸­ï¼Œç”±äºé˜³å…‰æˆ‘ä¸å–œæ¬¢å…‰çº¿ã€‚ï¼ˆ ğŸš´ ~9 kmï¼‰ã€‚
- en: Now I liked the footage but somehow I did not have any GPS data. ( ğŸš´ ~9 km).
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘å–œæ¬¢è¿™äº›å½±åƒï¼Œä½†ä¸çŸ¥ä¸ºä½•æ²¡æœ‰GPSæ•°æ®ã€‚ï¼ˆ ğŸš´ ~9 kmï¼‰ã€‚
- en: Again, no GPS data. but I suspect some battery saving issue. ( ğŸš´ ~9 km).
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å†æ¬¡ï¼Œæ²¡æœ‰GPSæ•°æ®ã€‚ä½†æˆ‘æ€€ç–‘æ˜¯ä¸€äº›ç”µæ± èŠ‚çœé—®é¢˜ã€‚ï¼ˆ ğŸš´ ~9 kmï¼‰ã€‚
- en: I made the GPS logger foreground and HD Camera background. Now I had GPS data
    but somehow, the camera App stopped. ( ğŸš´ ~9 km).
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘æŠŠGPSè®°å½•å™¨è®¾ç½®ä¸ºå‰å°ï¼ŒHDç›¸æœºè®¾ç½®ä¸ºåå°ã€‚ç°åœ¨æˆ‘æœ‰äº†GPSæ•°æ®ï¼Œä½†ä¸çŸ¥ä¸ºä½•ï¼Œç›¸æœºåº”ç”¨åœæ­¢äº†ã€‚ï¼ˆ ğŸš´ ~9 kmï¼‰ã€‚
- en: After making the GPS logger app a floating app (some multi-task magic) I got
    both, GPS and image data. ( ğŸš´ ~9 km).
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨å°†GPSè®°å½•å™¨åº”ç”¨è®¾ç½®ä¸ºæµ®åŠ¨åº”ç”¨ç¨‹åºï¼ˆä¸€äº›å¤šä»»åŠ¡é­”æ³•ï¼‰åï¼Œæˆ‘å¾—åˆ°äº†GPSå’Œå›¾åƒæ•°æ®ã€‚ï¼ˆ ğŸš´ ~9 kmï¼‰ã€‚
- en: I deleted my repository, including all recordings. ( ğŸš´ ~9 km).
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘åˆ é™¤äº†æˆ‘çš„ä»£ç åº“ï¼ŒåŒ…æ‹¬æ‰€æœ‰å½•éŸ³ã€‚ï¼ˆ ğŸš´ ~9 kmï¼‰ã€‚
- en: '![](../Images/1ac68dfbce9f423eef306d7a331e9224.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1ac68dfbce9f423eef306d7a331e9224.png)'
- en: 'Figure 8: The setup in my bike crate.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾8ï¼šæˆ‘è‡ªè¡Œè½¦ç®±ä¸­çš„è®¾ç½®ã€‚
- en: So in total I biked almost 80 km to get useful footage accompanied by GPS data.
    Next, we are going to investigate this two data sources and combine them such
    that we have *A = f(x,y)*.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æ€»çš„æ¥è¯´ï¼Œæˆ‘éª‘è¡Œäº†å°†è¿‘80å…¬é‡Œï¼Œè·å–äº†æœ‰ç”¨çš„å½±åƒå’ŒGPSæ•°æ®ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ·±å…¥ç ”ç©¶è¿™ä¸¤ä¸ªæ•°æ®æºï¼Œå¹¶å°†å®ƒä»¬ç»“åˆèµ·æ¥ï¼Œä»¥ä¾¿æˆ‘ä»¬æœ‰* A = f(x,y)*ã€‚
- en: Processing the data goodness
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¤„ç†æ•°æ®çš„å¥½å¤„
- en: Now that we have two data sources, we need to massage them into something useful.
    We will first transform the GPS data into our default DataFrame. Next, we will
    convert the video of 4.7GB also into a table of *A* values. This will be some
    decent data reduction ğŸ˜ƒ.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰äº†ä¸¤ä¸ªæ•°æ®æºï¼Œæˆ‘ä»¬éœ€è¦å°†å®ƒä»¬å¤„ç†æˆæœ‰ç”¨çš„ä¸œè¥¿ã€‚æˆ‘ä»¬å°†é¦–å…ˆæŠŠ GPS æ•°æ®è½¬æ¢ä¸ºé»˜è®¤çš„ DataFrameã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è¿˜å°†æŠŠ 4.7GB çš„è§†é¢‘è½¬æ¢ä¸º
    *A* å€¼çš„è¡¨æ ¼ã€‚è¿™å°†æ˜¯ä¸€äº›ç›¸å½“ä¸é”™çš„æ•°æ®ç¼©å‡ ğŸ˜ƒã€‚
- en: Converting GPS logger data
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è½¬æ¢ GPS è®°å½•æ•°æ®
- en: 'While the camera on the phone recorded the changing values of the LCD screen,
    the GPS logger app recorded the current latitude and longitude values. These are
    stored with a recording rate of 1Hz in a so called GPX file, for which a nifty
    library in Python exists. It is conveniently called `gpxpy` and after a pip install
    the data can be loaded in a bliss:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æ‰‹æœºä¸Šçš„ç›¸æœºè®°å½• LCD å±å¹•çš„å˜åŒ–å€¼æ—¶ï¼ŒGPS è®°å½•å™¨åº”ç”¨ç¨‹åºè®°å½•äº†å½“å‰çš„çº¬åº¦å’Œç»åº¦å€¼ã€‚è¿™äº›å€¼ä»¥ 1Hz çš„è®°å½•é€Ÿç‡å­˜å‚¨åœ¨ä¸€ä¸ªæ‰€è°“çš„ GPX æ–‡ä»¶ä¸­ï¼ŒPython
    ä¸­æœ‰ä¸€ä¸ªå·§å¦™çš„åº“å¯ä»¥å¤„ç†è¿™äº›æ–‡ä»¶ã€‚å®ƒæ–¹ä¾¿åœ°å«åš `gpxpy`ï¼Œå®‰è£…åæ•°æ®å¯ä»¥è½»æ¾åŠ è½½ï¼š
- en: 'Code 1: Importing the GPS data and creating a DataFrame. Easy as pie!'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç  1ï¼šå¯¼å…¥ GPS æ•°æ®å¹¶åˆ›å»º DataFrameã€‚ç®€ç›´æ˜¯å°èœä¸€ç¢Ÿï¼
- en: '![](../Images/958214377ec9021b3ac2acb9aa876e7a.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/958214377ec9021b3ac2acb9aa876e7a.png)'
- en: 'Output 1: Sample of the newly created dataset.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡º 1ï¼šæ–°åˆ›å»ºæ•°æ®é›†çš„ç¤ºä¾‹ã€‚
- en: 'Now we have a DataFrame with 2133 measurements that include latitude, longitude,
    elevation, and time. To check if these coordinates make any sense we could simply
    create a parametric plot using Matplotlib. However, there is another great library
    in Python specifically for maps called `folium`. Lets visualize what I have biked:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰ä¸€ä¸ªåŒ…å« 2133 ä¸ªæµ‹é‡å€¼çš„ DataFrameï¼Œå…¶ä¸­åŒ…æ‹¬çº¬åº¦ã€ç»åº¦ã€æµ·æ‹”å’Œæ—¶é—´ã€‚ä¸ºäº†æ£€æŸ¥è¿™äº›åæ ‡æ˜¯å¦åˆç†ï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°ä½¿ç”¨ Matplotlib
    åˆ›å»ºä¸€ä¸ªå‚æ•°å›¾ã€‚ç„¶è€Œï¼ŒPython è¿˜æœ‰å¦ä¸€ä¸ªä¸“é—¨ç”¨äºåœ°å›¾çš„ä¼˜ç§€åº“ï¼Œå«åš `folium`ã€‚è®©æˆ‘ä»¬å¯è§†åŒ–ä¸€ä¸‹æˆ‘éª‘è¡Œçš„è·¯çº¿ï¼š
- en: 'Code 2: visualizing the GPS coordinates using Folium.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç  2ï¼šä½¿ç”¨ Folium å¯è§†åŒ– GPS åæ ‡ã€‚
- en: '![](../Images/354671e85a07cc33269963801d004edc.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/354671e85a07cc33269963801d004edc.png)'
- en: 'Output 2: A map of the beautiful Enschede and the exact route I biked.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡º 2ï¼šç¾ä¸½çš„æ©æ–¯èµ«å¾·åœ°å›¾å’Œæˆ‘éª‘è¡Œçš„ç¡®åˆ‡è·¯çº¿ã€‚
- en: In the beautiful Folium map where we use â€œtamen watercolorâ€ tiles we see exactly
    the ring that I biked to collect the data. Before we store the DataFrame to disk,
    we need fix the timezone in the time column. Currently, the timezone is set to
    â€œzâ€ and I am not sure what that is. To remove any complications, lets localize
    the time.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¾ä¸½çš„ Folium åœ°å›¾ä¸Šï¼Œæˆ‘ä»¬ä½¿ç”¨äº†â€œtamen watercolorâ€å›¾å—ï¼Œæ­£å¥½æ˜¾ç¤ºäº†æˆ‘éª‘è¡Œä»¥æ”¶é›†æ•°æ®çš„è·¯å¾„ã€‚åœ¨å°† DataFrame å­˜å‚¨åˆ°ç£ç›˜ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦ä¿®æ­£æ—¶é—´åˆ—ä¸­çš„æ—¶åŒºã€‚ç›®å‰ï¼Œæ—¶åŒºè®¾ç½®ä¸ºâ€œzâ€ï¼Œæˆ‘ä¸ç¡®å®šè¿™æ˜¯ä»€ä¹ˆã€‚ä¸ºäº†é¿å…ä»»ä½•å¤æ‚æ€§ï¼Œæˆ‘ä»¬éœ€è¦æœ¬åœ°åŒ–æ—¶é—´ã€‚
- en: 'Code 3: Correct time and store DataFrame into a Parquet file.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç  3ï¼šä¿®æ­£æ—¶é—´å¹¶å°† DataFrame å­˜å‚¨ä¸º Parquet æ–‡ä»¶ã€‚
- en: The GPS data is ready to be used. Next, we need to process the video footage
    into something useful.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: GPS æ•°æ®å·²ç»å‡†å¤‡å¥½ä½¿ç”¨äº†ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å°†è§†é¢‘é•œå¤´å¤„ç†æˆæœ‰ç”¨çš„å†…å®¹ã€‚
- en: Creating training set for image detector
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆ›å»ºå›¾åƒæ£€æµ‹å™¨çš„è®­ç»ƒé›†
- en: We have a video that shows all output of the mystery box during the bike ride.
    We need to extract the *A* value from each frame and its corresponding time. Using
    this time, we can link the *A* value to its GPS location. To extract the *A* value,
    we will train a [DONUT based model](https://arxiv.org/abs/2111.15664). This is
    an end-to-end based model and does not need any optical character recognition
    (OCR). To train a model we need a labeled dataset. First, lets inspect the video
    data using [OpenCV](https://pypi.org/project/opencv-python/).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰ä¸€ä¸ªè§†é¢‘å±•ç¤ºäº†éª‘è¡Œè¿‡ç¨‹ä¸­ç¥ç§˜ç›’å­çš„æ‰€æœ‰è¾“å‡ºã€‚æˆ‘ä»¬éœ€è¦ä»æ¯ä¸€å¸§ä¸­æå– *A* å€¼åŠå…¶å¯¹åº”çš„æ—¶é—´ã€‚åˆ©ç”¨è¿™äº›æ—¶é—´ï¼Œæˆ‘ä»¬å¯ä»¥å°† *A* å€¼ä¸å…¶ GPS ä½ç½®é“¾æ¥èµ·æ¥ã€‚ä¸ºäº†æå–
    *A* å€¼ï¼Œæˆ‘ä»¬å°†è®­ç»ƒä¸€ä¸ª [åŸºäº DONUT çš„æ¨¡å‹](https://arxiv.org/abs/2111.15664)ã€‚è¿™æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„æ¨¡å‹ï¼Œä¸éœ€è¦ä»»ä½•å…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOCRï¼‰ã€‚ä¸ºäº†è®­ç»ƒæ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ ‡æ³¨å¥½çš„æ•°æ®é›†ã€‚é¦–å…ˆï¼Œè®©æˆ‘ä»¬ä½¿ç”¨
    [OpenCV](https://pypi.org/project/opencv-python/) æ£€æŸ¥è§†é¢‘æ•°æ®ã€‚
- en: 'Code 4: Import video as stream and check frame rate.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç  4ï¼šå°†è§†é¢‘ä½œä¸ºæµå¯¼å…¥å¹¶æ£€æŸ¥å¸§ç‡ã€‚
- en: The video was record with a frame rate of 30 frames per second. The duration
    of the video is about 35 minutes so this would mean more than 63k frames. This
    is a bit much, especially due to most GPS sensors for Arduino have a update frequency
    > 1Hz. Therefore, lets only select one frame each second and put them into a regular
    list.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥è§†é¢‘çš„å¸§ç‡ä¸ºæ¯ç§’ 30 å¸§ã€‚è§†é¢‘çš„æŒç»­æ—¶é—´å¤§çº¦ä¸º 35 åˆ†é’Ÿï¼Œå› æ­¤æ€»å¸§æ•°ä¼šè¶…è¿‡ 63kã€‚è¿™æœ‰ç‚¹å¤šï¼Œç‰¹åˆ«æ˜¯å› ä¸ºå¤§å¤šæ•° Arduino çš„ GPS ä¼ æ„Ÿå™¨æ›´æ–°é¢‘ç‡å¤§äº
    1Hzã€‚å› æ­¤ï¼Œæˆ‘ä»¬åªé€‰æ‹©æ¯ç§’ä¸€å¸§ï¼Œå¹¶å°†å®ƒä»¬æ”¾å…¥ä¸€ä¸ªå¸¸è§„åˆ—è¡¨ä¸­ã€‚
- en: 'Code 5: Extract frames from video at a frame rate of 1 FPS.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç  5ï¼šä»¥æ¯ç§’ 1 å¸§çš„å¸§ç‡ä»è§†é¢‘ä¸­æå–å¸§ã€‚
- en: '![](../Images/63438b1f42ff406aeab82accb94a088e.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63438b1f42ff406aeab82accb94a088e.png)'
- en: 'Output 3: a single frame from the video (left) and the final pre-processed
    frame (right).'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡º 3ï¼šè§†é¢‘ä¸­çš„å•å¸§ï¼ˆå·¦ï¼‰å’Œæœ€ç»ˆé¢„å¤„ç†çš„å¸§ï¼ˆå³ï¼‰ã€‚
- en: We have extracted 2119 frames which is already quite a reduction of the original
    63k we started with. When looking at the frame in Output 3 (left) we see that
    a lot of pixel in the frame are not very interesting to us. In our preprocessing
    we will crop the image such that we are only left with the A value. We will also
    reduce the image to black and white which might help with contrast problems later.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»æå–äº†2119å¸§ï¼Œè¿™å·²ç»æ˜¯ä»æœ€åˆçš„63kå¸§ä¸­å‡å°‘äº†ç›¸å½“å¤šã€‚å½“æŸ¥çœ‹è¾“å‡º3ï¼ˆå·¦ä¾§ï¼‰çš„å¸§æ—¶ï¼Œæˆ‘ä»¬å‘ç°å¸§ä¸­çš„è®¸å¤šåƒç´ å¯¹æˆ‘ä»¬å¹¶ä¸ç‰¹åˆ«æœ‰è¶£ã€‚åœ¨é¢„å¤„ç†è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†è£å‰ªå›¾åƒï¼Œä»…ä¿ç•™Aå€¼ã€‚æˆ‘ä»¬è¿˜ä¼šå°†å›¾åƒè½¬æ¢ä¸ºé»‘ç™½ï¼Œè¿™å¯èƒ½æœ‰åŠ©äºåç»­çš„å¯¹æ¯”åº¦é—®é¢˜ã€‚
- en: 'Code 6: preprocess images such that we isolate the A value.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç 6ï¼šé¢„å¤„ç†å›¾åƒï¼Œä»¥ä¾¿æˆ‘ä»¬å­¤ç«‹Aå€¼ã€‚
- en: Now we only need to save the list. This is a relatively easy task to parallelize
    as it is not depended of the previous input, therefore, we use `[joblib](https://joblib.readthedocs.io/en/latest/parallel.html)`
    for this step.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬åªéœ€è¦ä¿å­˜åˆ—è¡¨ã€‚è¿™æ˜¯ä¸€ä¸ªç›¸å¯¹å®¹æ˜“å¹¶è¡ŒåŒ–çš„ä»»åŠ¡ï¼Œå› ä¸ºå®ƒä¸ä¾èµ–äºä¹‹å‰çš„è¾“å…¥ï¼Œå› æ­¤æˆ‘ä»¬ä½¿ç”¨`[joblib](https://joblib.readthedocs.io/en/latest/parallel.html)`æ¥å®Œæˆè¿™ä¸€æ­¥ã€‚
- en: 'Code 7: Store the images, parallel of course!'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç 7ï¼šå­˜å‚¨å›¾åƒï¼Œå½“ç„¶è¦å¹¶è¡Œå¤„ç†ï¼
- en: We now have a dataset, but it is not yet labeled. To label, I have created a
    tool to label data in Jupyter Lab (or Notebook) which is called `[Pigeon-XT](https://github.com/dennisbakhuis/pigeonXT)`.
    It is the extended version of the Pigeon labeling tool created by Anastasis Germanidis.
    We will label 250 examples, which took me about 15 minutes.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨æœ‰äº†ä¸€ä¸ªæ•°æ®é›†ï¼Œä½†å®ƒå°šæœªæ ‡è®°ã€‚ä¸ºäº†æ ‡è®°ï¼Œæˆ‘åˆ›å»ºäº†ä¸€ä¸ªå·¥å…·ï¼Œç”¨äºåœ¨Jupyter Labï¼ˆæˆ–Notebookï¼‰ä¸­æ ‡è®°æ•°æ®ï¼Œç§°ä¸º`[Pigeon-XT](https://github.com/dennisbakhuis/pigeonXT)`ã€‚è¿™æ˜¯Anastasis
    Germanidisåˆ›å»ºçš„Pigeonæ ‡è®°å·¥å…·çš„æ‰©å±•ç‰ˆæœ¬ã€‚æˆ‘ä»¬å°†æ ‡è®°250ä¸ªç¤ºä¾‹ï¼Œè¿™èŠ±äº†æˆ‘å¤§çº¦15åˆ†é’Ÿã€‚
- en: 'Code 8: Label the data comfortably in our Jupyter Notebook.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç 8ï¼šåœ¨æˆ‘ä»¬çš„Jupyter Notebookä¸­èˆ’é€‚åœ°æ ‡è®°æ•°æ®ã€‚
- en: Now we have a labeled dataset. It is small, about 10% of the complete dataset,
    but we should be able to train a model that we can use to fill in the missing
    portion of the set. To make our life easier we can use the `[datasets](https://github.com/huggingface/datasets)`
    library from ğŸ¤— Huggingface. We can import our data with minor adjustments as an
    Imagefolder dataset.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰äº†ä¸€ä¸ªæ ‡è®°çš„æ•°æ®é›†ã€‚è™½ç„¶å®ƒå¾ˆå°ï¼Œå¤§çº¦å å®Œæ•´æ•°æ®é›†çš„10%ï¼Œä½†æˆ‘ä»¬åº”è¯¥èƒ½å¤Ÿè®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œç”¨æ¥å¡«è¡¥æ•°æ®é›†çš„ç¼ºå¤±éƒ¨åˆ†ã€‚ä¸ºäº†è®©æˆ‘ä»¬çš„å·¥ä½œæ›´è½»æ¾ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ğŸ¤—
    Huggingfaceçš„`[datasets](https://github.com/huggingface/datasets)`åº“ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€äº›å°è°ƒæ•´å°†æ•°æ®å¯¼å…¥ä¸ºImagefolderæ•°æ®é›†ã€‚
- en: 'Code 9: Create a Huggingface datasets dataset object.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç 9ï¼šåˆ›å»ºä¸€ä¸ªHuggingfaceæ•°æ®é›†å¯¹è±¡ã€‚
- en: '![](../Images/3727d04be9fa2c29c6e6abe8ac2f6eb5.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3727d04be9fa2c29c6e6abe8ac2f6eb5.png)'
- en: 'Output 4: the dataset object makes handling the data very easy. Maybe it would
    even be better doing the transform using its .map() function.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡º4ï¼šæ•°æ®é›†å¯¹è±¡ä½¿æ•°æ®å¤„ç†å˜å¾—éå¸¸å®¹æ˜“ã€‚ä¹Ÿè®¸ä½¿ç”¨å…¶.map()å‡½æ•°è¿›è¡Œè½¬æ¢ä¼šæ›´å¥½ã€‚
- en: Last but not least, we need to save the dataset. What is nice, is to share your
    dataset on the Huggingface hub. This is extremely easy using the `[huggingface_hub](https://github.com/huggingface/huggingface_hub)`
    package. For this you also need an account on the hub. The amazing thing about
    sharing on the hub is that you can now download this dataset without doing all
    the processing I did above.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åä½†åŒæ ·é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬éœ€è¦ä¿å­˜æ•°æ®é›†ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼Œå¯ä»¥åœ¨Huggingfaceä¸­å¿ƒå…±äº«ä½ çš„æ•°æ®é›†ã€‚ä½¿ç”¨`[huggingface_hub](https://github.com/huggingface/huggingface_hub)`åŒ…éå¸¸ç®€å•ã€‚ä¸ºæ­¤ï¼Œä½ è¿˜éœ€è¦ä¸€ä¸ªä¸­å¿ƒçš„è´¦æˆ·ã€‚åœ¨ä¸­å¿ƒå…±äº«çš„ç¥å¥‡ä¹‹å¤„åœ¨äºï¼Œä½ ç°åœ¨å¯ä»¥ä¸‹è½½è¿™ä¸ªæ•°æ®é›†ï¼Œè€Œæ— éœ€è¿›è¡Œæˆ‘ä¸Šé¢åšçš„æ‰€æœ‰å¤„ç†ã€‚
- en: 'Code 10: Save the dataset and push the it to the Huggingface hub.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç 10ï¼šä¿å­˜æ•°æ®é›†å¹¶å°†å…¶æ¨é€åˆ°Huggingfaceä¸­å¿ƒã€‚
- en: Now we have everything to train a model to infere the missing labels. Lets do
    some training ğŸ”¥ğŸ”¥ğŸ”¥!
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æ‹¥æœ‰äº†è®­ç»ƒæ¨¡å‹ä»¥æ¨æ–­ç¼ºå¤±æ ‡ç­¾çš„æ‰€æœ‰æ¡ä»¶ã€‚è®©æˆ‘ä»¬å¼€å§‹è®­ç»ƒå§ğŸ”¥ğŸ”¥ğŸ”¥ï¼
- en: Training a ğŸ© DONUT model
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®­ç»ƒä¸€ä¸ªğŸ© DONUTæ¨¡å‹
- en: 'We can finally start with training our model. We will be training a [DONUT](https://arxiv.org/abs/2111.15664)
    based model created by [Naver AI Lab](https://naverlabs.com/). DONUT is a true
    end-to-end model. You input an image and you will get a JSON object with key-value
    pairs out. The most amazing part is that it can do this without OCR. Previous
    state of the art methods such as [LayoutLM](https://arxiv.org/abs/2204.08387)
    use a two-step approach: first use OCR to extract all text and their locations
    and second, input an image and text data in a model to extract information.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç»ˆäºå¯ä»¥å¼€å§‹è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹äº†ã€‚æˆ‘ä»¬å°†è®­ç»ƒä¸€ä¸ªåŸºäº[DONUT](https://arxiv.org/abs/2111.15664)çš„æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç”±[Naver
    AI Lab](https://naverlabs.com/)åˆ›å»ºã€‚DONUTæ˜¯ä¸€ä¸ªçœŸæ­£çš„ç«¯åˆ°ç«¯æ¨¡å‹ã€‚ä½ è¾“å…¥ä¸€å¼ å›¾åƒï¼Œå®ƒå°†è¾“å‡ºä¸€ä¸ªåŒ…å«é”®å€¼å¯¹çš„JSONå¯¹è±¡ã€‚æœ€ä»¤äººæƒŠå¹çš„æ˜¯ï¼Œå®ƒå¯ä»¥åœ¨æ²¡æœ‰OCRçš„æƒ…å†µä¸‹å®Œæˆè¿™ä¸€åˆ‡ã€‚ä¹‹å‰çš„æœ€æ–°æ–¹æ³•ï¼Œå¦‚[LayoutLM](https://arxiv.org/abs/2204.08387)ï¼Œä½¿ç”¨äº†ä¸¤æ­¥æ³•ï¼šé¦–å…ˆä½¿ç”¨OCRæå–æ‰€æœ‰æ–‡æœ¬åŠå…¶ä½ç½®ï¼Œå…¶æ¬¡ï¼Œå°†å›¾åƒå’Œæ–‡æœ¬æ•°æ®è¾“å…¥æ¨¡å‹ä»¥æå–ä¿¡æ¯ã€‚
- en: The problem with extracting information from documents is that a lot of information
    is encoded in the layout. The human brain understands the relation between data
    when it is presented as a header, in a table, or as a caption. Using OCR methods,
    this information is lost. Methods like LayoutLM use the image to bring back the
    layout information. DONUT can do this in one go and has OCR build in. From what
    I have seen it works quite good but is very sensitive to changes in documents.
    When a document has minor layout changes, but still the same information to extract,
    DONUT fails quite easily.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æ–‡æ¡£ä¸­æå–ä¿¡æ¯çš„é—®é¢˜åœ¨äºï¼Œå¾ˆå¤šä¿¡æ¯è¢«ç¼–ç åœ¨å¸ƒå±€ä¸­ã€‚äººè„‘èƒ½å¤Ÿç†è§£ä»¥æ ‡é¢˜ã€è¡¨æ ¼æˆ–æ ‡é¢˜çš„å½¢å¼å‘ˆç°çš„æ•°æ®ä¹‹é—´çš„å…³ç³»ã€‚ä½¿ç”¨ OCR æ–¹æ³•ï¼Œè¿™äº›ä¿¡æ¯ä¼šä¸¢å¤±ã€‚åƒ LayoutLM
    è¿™æ ·çš„æ–¹å¼åˆ©ç”¨å›¾åƒæ¢å¤å¸ƒå±€ä¿¡æ¯ã€‚DONUT å¯ä»¥ä¸€æ¬¡æ€§å®Œæˆè¿™é¡¹å·¥ä½œï¼Œå¹¶ä¸”å†…ç½®äº† OCRã€‚ä»æˆ‘æ‰€çœ‹åˆ°çš„ï¼Œå®ƒçš„æ•ˆæœè¿˜ä¸é”™ï¼Œä½†å¯¹æ–‡æ¡£ä¸­çš„å˜åŒ–éå¸¸æ•æ„Ÿã€‚å½“æ–‡æ¡£æœ‰å¾®å°çš„å¸ƒå±€å˜åŒ–ï¼Œä½†è¦æå–çš„ä¿¡æ¯ä»ç„¶ç›¸åŒæ—¶ï¼ŒDONUT
    å®¹æ˜“å¤±è´¥ã€‚
- en: Our images are not really documents, but they have very clear text and are from
    a layout point of view very constant. Therefore, DONUT would be a great (and overkill)
    method to extract the *A* value. I followed the same procedure as CloveAI team
    did in their [repository](https://github.com/clovaai/donut). [Philipp Schmid](https://www.linkedin.com/in/philipp-schmid-a6a2bb196/)
    wrote a [great article](https://www.philschmid.de/fine-tuning-donut) on how to
    train your own DONUT type model. First we need to prepare our dataset for the
    specific DONUT inputs of the model.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„å›¾åƒå®é™…ä¸Šä¸æ˜¯æ–‡æ¡£ï¼Œä½†å®ƒä»¬æ–‡æœ¬éå¸¸æ¸…æ™°ï¼Œä»å¸ƒå±€çš„è§’åº¦æ¥çœ‹ä¹Ÿéå¸¸ä¸€è‡´ã€‚å› æ­¤ï¼ŒDONUT å°†æ˜¯ä¸€ä¸ªæå¥½çš„ï¼ˆç”šè‡³æœ‰äº›è¿‡åº¦ï¼‰æå– *A* å€¼çš„æ–¹æ³•ã€‚æˆ‘æŒ‰ç…§
    CloveAI å›¢é˜Ÿåœ¨ä»–ä»¬çš„ [ä»£ç åº“](https://github.com/clovaai/donut) ä¸­æ‰€åšçš„ç›¸åŒæ­¥éª¤è¿›è¡Œæ“ä½œã€‚[Philipp Schmid](https://www.linkedin.com/in/philipp-schmid-a6a2bb196/)
    å†™äº†ä¸€ç¯‡ [å¾ˆæ£’çš„æ–‡ç« ](https://www.philschmid.de/fine-tuning-donut) ä»‹ç»äº†å¦‚ä½•è®­ç»ƒè‡ªå·±çš„ DONUT ç±»å‹æ¨¡å‹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä¸ºæ¨¡å‹çš„ç‰¹å®š
    DONUT è¾“å…¥å‡†å¤‡æ•°æ®é›†ã€‚
- en: 'Code 11: converting the JSON objects to tokens DONUT expects.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç  11ï¼šå°† JSON å¯¹è±¡è½¬æ¢ä¸º DONUT æœŸæœ›çš„ä»¤ç‰Œã€‚
- en: Now that the data is in the form expected by DONUT we need to tokenize the data.
    This is a step common to transformer language models such as GPT<n> and BERT but
    now also used for images in Vision Transformers (ViT).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ•°æ®å·²ç¬¦åˆ DONUT çš„é¢„æœŸæ ¼å¼ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ•°æ®è¿›è¡Œåˆ†è¯ã€‚è¿™æ˜¯ä¸€ä¸ªä¸ GPT<n> å’Œ BERT ç­‰è½¬æ¢å™¨è¯­è¨€æ¨¡å‹å…±åŒçš„æ­¥éª¤ï¼Œä½†ç°åœ¨ä¹Ÿç”¨äºè§†è§‰è½¬æ¢å™¨ï¼ˆViTï¼‰ä¸­çš„å›¾åƒã€‚
- en: 'Code 12: tokenize the data for input into the model.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç  12ï¼šä¸ºæ¨¡å‹è¾“å…¥å¯¹æ•°æ®è¿›è¡Œåˆ†è¯ã€‚
- en: Now we have everything ready to do some actual training ğŸ”¥. Nowadays, this is
    incredibly easy as you do not have to write your training loop anymore. While
    I first was a bit sad as it felt quite cool to write the loop, it was quite repetitive.
    Huggingface gives you the trainer object and it is just perfect for the job.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»å‡†å¤‡å¥½è¿›è¡Œå®é™…è®­ç»ƒäº† ğŸ”¥ã€‚å¦‚ä»Šï¼Œè¿™éå¸¸ç®€å•ï¼Œå› ä¸ºä½ ä¸å†éœ€è¦ç¼–å†™è®­ç»ƒå¾ªç¯äº†ã€‚è™½ç„¶æˆ‘èµ·åˆæœ‰äº›éš¾è¿‡ï¼Œå› ä¸ºç¼–å†™å¾ªç¯æ„Ÿè§‰å¾ˆé…·ï¼Œä½†å®ƒå…¶å®éå¸¸é‡å¤ã€‚Huggingface
    æä¾›äº†è®­ç»ƒå™¨å¯¹è±¡ï¼Œå®ƒéå¸¸é€‚åˆè¿™é¡¹å·¥ä½œã€‚
- en: 'Code 13: the complete code for the training loop has simplified a lot!'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç  13ï¼šè®­ç»ƒå¾ªç¯çš„å®Œæ•´ä»£ç å·²ç»ç®€åŒ–äº†å¾ˆå¤šï¼
- en: '![](../Images/01876e94ee685cff3e3f7af27f891153.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01876e94ee685cff3e3f7af27f891153.png)'
- en: 'Output 5: training in progress.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡º 5ï¼šè®­ç»ƒè¿›è¡Œä¸­ã€‚
- en: 'After evaluation of the test dataset we get an evaluation loss of 0.007 which
    is pretty descent. From our 38 test examples 37 were detected correctly. The one
    that is incorrect was missing one digit: 059 instead of 1059\. 37/38 makes an
    accuracy of 97% which is probably enough to label the complete set. Before we
    start inferring the missing values, lets save the model and also push it to the
    hub.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æµ‹è¯•æ•°æ®é›†çš„è¯„ä¼°åï¼Œæˆ‘ä»¬å¾—åˆ°äº† 0.007 çš„è¯„ä¼°æŸå¤±ï¼Œè¿™ç›¸å½“ä¸é”™ã€‚åœ¨æˆ‘ä»¬ 38 ä¸ªæµ‹è¯•æ ·æœ¬ä¸­ï¼Œæœ‰ 37 ä¸ªè¢«æ­£ç¡®æ£€æµ‹å‡ºæ¥ã€‚å”¯ä¸€ä¸€ä¸ªä¸æ­£ç¡®çš„æ˜¯å°‘äº†ä¸€ä¸ªæ•°å­—ï¼š059
    è€Œä¸æ˜¯ 1059ã€‚37/38 çš„å‡†ç¡®ç‡ä¸º 97%ï¼Œè¿™å¯èƒ½è¶³ä»¥æ ‡è®°å®Œæ•´çš„é›†åˆã€‚åœ¨æˆ‘ä»¬å¼€å§‹æ¨æ–­ç¼ºå¤±å€¼ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆä¿å­˜æ¨¡å‹å¹¶å°†å…¶æ¨é€åˆ°ä¸­å¿ƒã€‚
- en: 'Code 14: save the model and push it to the hub.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç  14ï¼šä¿å­˜æ¨¡å‹å¹¶å°†å…¶æ¨é€åˆ°ä¸­å¿ƒã€‚
- en: Now lets do some inferring on the missing labels.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬å¯¹ç¼ºå¤±çš„æ ‡ç­¾è¿›è¡Œä¸€äº›æ¨æ–­ã€‚
- en: Use model to infer missing data
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ¨¡å‹æ¨æ–­ç¼ºå¤±æ•°æ®
- en: 'Finally we can use our model to infere the labels. The images are already prepared
    so we can simply use those. The time of each frame is encoded in its filename
    in seconds. There will be a small mismatch as the frame rate is not exactly 30
    frames per second but the difference will be small. Lets first create a function
    to do the inference for us:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ç»ˆï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡å‹æ¥æ¨æ–­æ ‡ç­¾ã€‚å›¾åƒå·²ç»å‡†å¤‡å¥½ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨å®ƒä»¬ã€‚æ¯ä¸ªå¸§çš„æ—¶é—´ä»¥ç§’ä¸ºå•ä½ç¼–ç åœ¨å…¶æ–‡ä»¶åä¸­ã€‚ç”±äºå¸§ç‡ä¸æ˜¯ç²¾ç¡®çš„æ¯ç§’ 30
    å¸§ï¼Œå› æ­¤ä¼šæœ‰å°çš„åå·®ï¼Œä½†å·®å¼‚ä¼šå¾ˆå°ã€‚è®©æˆ‘ä»¬é¦–å…ˆåˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥ä¸ºæˆ‘ä»¬è¿›è¡Œæ¨æ–­ï¼š
- en: 'Code 15: code for inferring an image.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç  15ï¼šæ¨æ–­å›¾åƒçš„ä»£ç ã€‚
- en: We could now do inference on each image one by one, however, that would take
    about an hour. Lets do this in parallel but this is far from trivial. For simple
    things, `joblib` is great. However, when using models, serializing large models
    for each iteration makes it slower then doing them just one-by-one. To solve this
    problem I wrote `[tqdm_batch](https://github.com/dennisbakhuis/tqdm_batch)` a
    while ago.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å¯ä»¥å¯¹æ¯å¼ å›¾ç‰‡é€ä¸€è¿›è¡Œæ¨æ–­ï¼Œä½†è¿™å°†èŠ±è´¹å¤§çº¦ä¸€ä¸ªå°æ—¶ã€‚è®©æˆ‘ä»¬å¹¶è¡Œå¤„ç†ï¼Œä½†è¿™è¿œéç®€å•ã€‚å¯¹äºç®€å•çš„ä»»åŠ¡ï¼Œ`joblib` å¾ˆæ£’ã€‚ç„¶è€Œï¼Œåœ¨ä½¿ç”¨æ¨¡å‹æ—¶ï¼Œä¸ºæ¯æ¬¡è¿­ä»£åºåˆ—åŒ–å¤§å‹æ¨¡å‹ä¼šæ¯”é€ä¸ªå¤„ç†æ›´æ…¢ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä¹‹å‰ç¼–å†™äº†
    `[tqdm_batch](https://github.com/dennisbakhuis/tqdm_batch)`ã€‚
- en: Parallel jobs are not trivial. Read my [article](/parallel-batch-processing-in-python-8dcce607d226)ğŸƒğŸ»ğŸ’¨!
  id: totrans-129
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å¹¶è¡Œä½œä¸šå¹¶éæ˜“äº‹ã€‚é˜…è¯»æˆ‘çš„ [æ–‡ç« ](/parallel-batch-processing-in-python-8dcce607d226)ğŸƒğŸ»ğŸ’¨ï¼
- en: 'Code 16: parallelize the inference step and divide the work between four workers.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç  16ï¼šå¹¶è¡ŒåŒ–æ¨æ–­æ­¥éª¤ï¼Œå¹¶å°†å·¥ä½œåˆ†é…ç»™å››ä¸ªå·¥ä½œè€…ã€‚
- en: '![](../Images/427bcf6a9366233992535bfc7428cb41.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/427bcf6a9366233992535bfc7428cb41.png)'
- en: 'Output 6: running 4 workers in parallel using tqdm_batch.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡º 6ï¼šä½¿ç”¨ tqdm_batch è¿è¡Œ 4 ä¸ªå·¥ä½œè€…å¹¶è¡Œå¤„ç†ã€‚
- en: Now that we have our A values from the box, we can build our final dataset and
    combine it with GPS data. As always, the prediction was not perfect and we have
    to do some massaging. As a data scientist you actual are an data masseuse.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰äº†æ¥è‡ªç›’å­çš„ A å€¼ï¼Œæˆ‘ä»¬å¯ä»¥æ„å»ºæœ€ç»ˆçš„æ•°æ®é›†å¹¶å°†å…¶ä¸ GPS æ•°æ®ç»“åˆèµ·æ¥ã€‚åƒå¾€å¸¸ä¸€æ ·ï¼Œé¢„æµ‹å¹¶ä¸å®Œç¾ï¼Œæˆ‘ä»¬éœ€è¦åšä¸€äº›è°ƒæ•´ã€‚ä½œä¸ºæ•°æ®ç§‘å­¦å®¶ï¼Œä½ å®é™…ä¸Šæ˜¯ä¸€ä¸ªæ•°æ®æŒ‰æ‘©å¸ˆã€‚
- en: 'Code 15: basic cleaning of or dataset.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç  15ï¼šå¯¹æ•°æ®é›†è¿›è¡ŒåŸºæœ¬æ¸…ç†ã€‚
- en: Almost there, the only problem are the wrongly detected A values. These can
    be filtered using a rolling filter. We will remove values that have a greater
    difference than 5 meter (arbitrary small number) from the moving average and interpolate
    them with the values left.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: å‡ ä¹å®Œæˆäº†ï¼Œå”¯ä¸€çš„é—®é¢˜æ˜¯é”™è¯¯æ£€æµ‹åˆ°çš„ A å€¼ã€‚è¿™äº›å¯ä»¥ä½¿ç”¨æ»šåŠ¨æ»¤æ³¢å™¨è¿›è¡Œè¿‡æ»¤ã€‚æˆ‘ä»¬å°†åˆ é™¤ä¸ç§»åŠ¨å¹³å‡å€¼å·®å¼‚è¶…è¿‡ 5 ç±³ï¼ˆä»»æ„å°æ•°ï¼‰çš„å€¼ï¼Œå¹¶ç”¨å‰©ä½™å€¼è¿›è¡Œæ’å€¼ã€‚
- en: 'Code 16: filtering the noisy data using a moving average filter and an interpolate.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç  16ï¼šä½¿ç”¨ç§»åŠ¨å¹³å‡è¿‡æ»¤å™¨å’Œæ’å€¼æ¥è¿‡æ»¤å™ªå£°æ•°æ®ã€‚
- en: '![](../Images/a7371184d7dcaeb9a64007b84af971b1.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a7371184d7dcaeb9a64007b84af971b1.png)'
- en: 'Output 7: final result after applying the filter. Pretty neat!'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡º 7ï¼šåº”ç”¨è¿‡æ»¤å™¨åçš„æœ€ç»ˆç»“æœã€‚ç›¸å½“ä¸é”™ï¼
- en: This filtering looks pretty neat. Now we are ready to combine this dataset with
    our previously recorded GPS data.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªè¿‡æ»¤æ•ˆæœç›¸å½“ä¸é”™ã€‚ç°åœ¨æˆ‘ä»¬å‡†å¤‡å°†è¿™ä¸ªæ•°æ®é›†ä¸ä¹‹å‰è®°å½•çš„ GPS æ•°æ®ç»“åˆèµ·æ¥ã€‚
- en: Combining the image and GPS data
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç»“åˆå›¾åƒå’Œ GPS æ•°æ®
- en: Combining the A value to the GPS data should not be much of a problem. For each
    row in the GPS dataset we will look for the closest match in time and use the
    A value of that row.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: å°† A å€¼ä¸ GPS æ•°æ®ç»“åˆåº”è¯¥ä¸æˆé—®é¢˜ã€‚å¯¹äº GPS æ•°æ®é›†ä¸­çš„æ¯ä¸€è¡Œï¼Œæˆ‘ä»¬å°†å¯»æ‰¾æ—¶é—´ä¸Šæœ€æ¥è¿‘çš„åŒ¹é…ï¼Œå¹¶ä½¿ç”¨è¯¥è¡Œçš„ A å€¼ã€‚
- en: 'Code 17: Adding the *A* value to the gps dataset.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç  17ï¼šå°† *A* å€¼æ·»åŠ åˆ° GPS æ•°æ®é›†ä¸­ã€‚
- en: This is it! So much effort which was probably never really needed. But we used
    machine learning and that is the only thing that matters!
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: å°±è¿™äº›äº†ï¼ä»˜å‡ºäº†å¾ˆå¤šåŠªåŠ›ï¼Œå¯èƒ½å…¶å®å¹¶ä¸å¿…è¦ã€‚ä½†æˆ‘ä»¬ä½¿ç”¨äº†æœºå™¨å­¦ä¹ ï¼Œè¿™æ‰æ˜¯æœ€é‡è¦çš„ï¼
- en: we used machine learning and that is the only thing that matters!
  id: totrans-144
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨äº†æœºå™¨å­¦ä¹ ï¼Œè¿™æ‰æ˜¯æœ€é‡è¦çš„ï¼
- en: Next, we will use this dataset and try to find the goal coordinate.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è¿™ä¸ªæ•°æ®é›†å¹¶å°è¯•æ‰¾åˆ°ç›®æ ‡åæ ‡ã€‚
- en: Analyze the dataset and find the goal
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åˆ†ææ•°æ®é›†å¹¶æ‰¾åˆ°ç›®æ ‡
- en: As previously discussed, we will try to find the two unknown locations *p1*
    and *p2*. If we know these two points, we will also know the goals location which
    should be exactly between those points. To find the locations, we will use the
    `[minimize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize)`
    form `[Scipy](https://scipy.org/)`. While I could write my own Haversine function
    I will just use the `[haversine](https://github.com/mapado/haversine)` package.
    To use `minimize` we need to write an error function. This function will calculate
    the difference between the known *A* and the calculated A for all our values in
    the dataset and sum the absolute differences. The minimize function should minimize
    this error.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å‰æ‰€è¿°ï¼Œæˆ‘ä»¬å°†å°è¯•æ‰¾åˆ°ä¸¤ä¸ªæœªçŸ¥ä½ç½® *p1* å’Œ *p2*ã€‚å¦‚æœæˆ‘ä»¬çŸ¥é“è¿™ä¸¤ä¸ªç‚¹ï¼Œæˆ‘ä»¬ä¹Ÿå°†çŸ¥é“ç›®æ ‡ä½ç½®ï¼Œå®ƒåº”è¯¥æ­£å¥½åœ¨è¿™ä¸¤ä¸ªç‚¹ä¹‹é—´ã€‚ä¸ºäº†æ‰¾åˆ°è¿™äº›ä½ç½®ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨
    `[minimize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize)`
    æ¥è‡ª `[Scipy](https://scipy.org/)`ã€‚è™½ç„¶æˆ‘å¯ä»¥è‡ªå·±ç¼–å†™ Haversine å‡½æ•°ï¼Œä½†æˆ‘å°†ç›´æ¥ä½¿ç”¨ `[haversine](https://github.com/mapado/haversine)`
    åŒ…ã€‚è¦ä½¿ç”¨ `minimize`ï¼Œæˆ‘ä»¬éœ€è¦ç¼–å†™ä¸€ä¸ªè¯¯å·®å‡½æ•°ã€‚è¿™ä¸ªå‡½æ•°å°†è®¡ç®—å·²çŸ¥çš„ *A* å’Œè®¡ç®—å‡ºçš„ A ä¹‹é—´çš„å·®å¼‚ï¼Œå¹¶å¯¹æ•°æ®é›†ä¸­çš„æ‰€æœ‰å€¼æ±‚ç»å¯¹å·®å¼‚çš„æ€»å’Œã€‚æœ€å°åŒ–å‡½æ•°åº”è¯¥æœ€å°åŒ–è¿™ä¸ªè¯¯å·®ã€‚
- en: 'Code 18: lets minimize this shit.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç  18ï¼šè®©æˆ‘ä»¬æœ€å°åŒ–è¿™ä¸ªé—®é¢˜ã€‚
- en: '![](../Images/6a1c1bd318ca766a86d5c51dd0240e0b.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a1c1bd318ca766a86d5c51dd0240e0b.png)'
- en: 'Output 8: The final solution (green) is exactly between points p1 and p2 (blue).
    The goal is also on the perpendicular line of my found zero points.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡º 8ï¼šæœ€ç»ˆè§£å†³æ–¹æ¡ˆï¼ˆç»¿è‰²ï¼‰æ­£å¥½ä½äºç‚¹ p1 å’Œ p2ï¼ˆè“è‰²ï¼‰ä¹‹é—´ã€‚ç›®æ ‡ä¹Ÿåœ¨æˆ‘æ‰¾åˆ°çš„é›¶ç‚¹çš„å‚ç›´çº¿ä¸Šã€‚
- en: This is it, I have found the location. The goal is exactly between points p1
    and p2\. This point also connects to a perpendicular line between my previously
    found zero points. But the biggest hint is that the goal location is a [BBQ restaurant](https://marcook.nl/).
    Sander and I are very fond of burgers and this place has a great selection of
    those.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: å°±æ˜¯è¿™æ ·ï¼Œæˆ‘æ‰¾åˆ°äº†ä½ç½®ã€‚ç›®æ ‡æ­£å¥½ä½äºç‚¹ p1 å’Œ p2 ä¹‹é—´ã€‚è¿™ä¸ªç‚¹ä¹Ÿè¿æ¥åˆ°æˆ‘ä¹‹å‰æ‰¾åˆ°çš„é›¶ç‚¹ä¹‹é—´çš„å‚ç›´çº¿ä¸Šã€‚ä½†æœ€å¤§çš„æç¤ºæ˜¯ç›®æ ‡ä½ç½®æ˜¯ä¸€å®¶ [BBQ é¤å…](https://marcook.nl/)ã€‚æ¡‘å¾·å’Œæˆ‘éƒ½å¾ˆå–œæ¬¢æ±‰å ¡ï¼Œè€Œè¿™ä¸ªåœ°æ–¹æœ‰å¾ˆæ£’çš„é€‰æ‹©ã€‚
- en: '![](../Images/0987263246d81a45b333f840195534f8.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0987263246d81a45b333f840195534f8.png)'
- en: 'Output 9: The difference between my found coordinate and the actual goal is
    93 meters.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡º 9ï¼šæˆ‘æ‰¾åˆ°çš„åæ ‡ä¸å®é™…ç›®æ ‡ä¹‹é—´çš„å·®å¼‚æ˜¯ 93 ç±³ã€‚
- en: The deviation from the actual point and the one I found is 93 meters. This could
    have many reasons. First, the extracted A value only has round numbers. While
    this has an effect, I suspect that this is only a minor effect which should negligible
    when averaging over a larger dataset. Of course, the filtering (smoothing) has
    an effect. Maybe there is some noise added on purpose, not sure if I could have
    noticed that. Anyhow, I am pretty happy with the result.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ç‚¹ä¸æˆ‘æ‰¾åˆ°çš„ç‚¹ä¹‹é—´çš„åå·®æ˜¯ 93 ç±³ã€‚è¿™å¯èƒ½æœ‰å¾ˆå¤šåŸå› ã€‚é¦–å…ˆï¼Œæå–çš„ A å€¼åªæœ‰æ•´æ•°ã€‚è¿™ç¡®å®æœ‰å½±å“ï¼Œä½†æˆ‘æ€€ç–‘è¿™åªæ˜¯ä¸€ä¸ªè¾ƒå°çš„å½±å“ï¼Œå¹³å‡åœ¨è¾ƒå¤§çš„æ•°æ®é›†ä¸Šåº”è¯¥å¯ä»¥å¿½ç•¥ã€‚å½“ç„¶ï¼Œè¿‡æ»¤ï¼ˆå¹³æ»‘ï¼‰ä¹Ÿæœ‰å½±å“ã€‚ä¹Ÿè®¸æ•…æ„æ·»åŠ äº†ä¸€äº›å™ªå£°ï¼Œä¸ç¡®å®šæˆ‘æ˜¯å¦èƒ½æ³¨æ„åˆ°ã€‚æ€»ä¹‹ï¼Œæˆ‘å¯¹ç»“æœç›¸å½“æ»¡æ„ã€‚
- en: Going to the location
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‰å¾€ä½ç½®
- en: It took quite some time but now I am finally certain where to location is. I
    took the car and drove to Marcook, a BBQ restaurant just outside of Enschede.
    If I would turn on the mystery box in that location it should show me the code
    to unlock its mysteries.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: èŠ±äº†ç›¸å½“é•¿çš„æ—¶é—´ï¼Œä½†ç°åœ¨æˆ‘ç»ˆäºç¡®å®šäº†ä½ç½®ã€‚æˆ‘å¼€è½¦å»äº† Marcookï¼Œä¸€å®¶ä½äºæ©æ–¯èµ«å¾·å¤–çš„çƒ§çƒ¤é¤å…ã€‚å¦‚æœæˆ‘åœ¨é‚£ä¸ªä½ç½®æ‰“å¼€ç¥ç§˜ç›’å­ï¼Œå®ƒåº”è¯¥ä¼šæ˜¾ç¤ºè§£é”å…¶è°œå›¢çš„ä»£ç ã€‚
- en: '![](../Images/9aed31317a2c5f446f5c0642f045d5f7.png)![](../Images/212bb3e05852d0b2e28b7cc236b3b814.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9aed31317a2c5f446f5c0642f045d5f7.png)![](../Images/212bb3e05852d0b2e28b7cc236b3b814.png)'
- en: 'Figure 9: the mystery box unlocks all its mysteries.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 9ï¼šç¥ç§˜ç›’å­è§£é”äº†æ‰€æœ‰çš„è°œå›¢ã€‚
- en: 'Indeed, after waiting a couple of minutes to get a GPS fix the box almost instantly
    responded with â€˜proficiatâ€™. Congratulations for making it this far. The next screen
    of the device shows the code: 7631.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: çš„ç¡®ï¼Œç­‰å¾…äº†å‡ åˆ†é’Ÿä»¥è·å¾— GPS å®šä½åï¼Œç›’å­å‡ ä¹ç«‹åˆ»å›åº”äº†â€˜proficiatâ€™ã€‚ç¥è´ºä½ èµ°åˆ°è¿™ä¸€æ­¥ã€‚è®¾å¤‡çš„ä¸‹ä¸€ä¸ªå±å¹•æ˜¾ç¤ºä»£ç ï¼š7631ã€‚
- en: To be honest, this was not an easy challenge. But it was a fun journey and in
    the end we are gonna eat some burgers. Can hardly get any better.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: è€å®è¯´ï¼Œè¿™ä¸æ˜¯ä¸€ä¸ªç®€å•çš„æŒ‘æˆ˜ã€‚ä½†è¿™æ˜¯ä¸€æ¬¡æœ‰è¶£çš„æ—…ç¨‹ï¼Œæœ€åæˆ‘ä»¬ä¼šåƒä¸€äº›æ±‰å ¡ã€‚å‡ ä¹æ²¡ä»€ä¹ˆèƒ½æ¯”è¿™æ›´å¥½ã€‚
- en: All code for this project is on [Github](https://github.com/dennisbakhuis/mystery_box).
    Most of the smaller datasets are included in the Git repository however the larger
    video is shared through my Dropbox. The dataset used for the ViT training, the
    DONUT processor, and the DONUT model are also shared on the ğŸ¤— [Huggingface hub](https://huggingface.co/bakhuisdennis).
    If you have any questions, feel free to contact me on [LinkedIn](https://linkedin.com/in/dennisbakhuis).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤é¡¹ç›®çš„æ‰€æœ‰ä»£ç éƒ½åœ¨ [Github](https://github.com/dennisbakhuis/mystery_box) ä¸Šã€‚å¤§éƒ¨åˆ†è¾ƒå°çš„æ•°æ®é›†åŒ…å«åœ¨
    Git ä»“åº“ä¸­ï¼Œä½†è¾ƒå¤§çš„è§†é¢‘é€šè¿‡æˆ‘çš„ Dropbox å…±äº«ã€‚ç”¨äº ViT è®­ç»ƒçš„ datasetã€DONUT å¤„ç†å™¨å’Œ DONUT æ¨¡å‹ä¹Ÿåœ¨ ğŸ¤— [Huggingface
    hub](https://huggingface.co/bakhuisdennis) ä¸Šå…±äº«ã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜ï¼Œæ¬¢è¿é€šè¿‡ [LinkedIn](https://linkedin.com/in/dennisbakhuis)
    è”ç³»æˆ‘ã€‚
- en: Last but not least, I want to thank ğŸ™ *Sander* for the fun experience. I am
    sorry I took so long, but I guess I over-killed it a bit. It sure was fun! Burgers?
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åä½†åŒæ ·é‡è¦çš„æ˜¯ï¼Œæˆ‘è¦æ„Ÿè°¢ ğŸ™ *æ¡‘å¾·* ç»™äºˆçš„æœ‰è¶£ä½“éªŒã€‚å¯¹ä¸èµ·æˆ‘èŠ±äº†è¿™ä¹ˆé•¿æ—¶é—´ï¼Œä½†æˆ‘æƒ³æˆ‘æœ‰ç‚¹è¿‡åº¦äº†ã€‚è¿™ç¡®å®å¾ˆæœ‰è¶£ï¼æ±‰å ¡ï¼Ÿ
