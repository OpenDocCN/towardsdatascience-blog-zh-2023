- en: Data Modelling For Data Engineers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ•°æ®å·¥ç¨‹å¸ˆçš„æ•°æ®å»ºæ¨¡
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/data-modelling-for-data-engineers-93d058efa302](https://towardsdatascience.com/data-modelling-for-data-engineers-93d058efa302)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/data-modelling-for-data-engineers-93d058efa302](https://towardsdatascience.com/data-modelling-for-data-engineers-93d058efa302)
- en: The definitive guide for beginners
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆå­¦è€…çš„ç»ˆææŒ‡å—
- en: '[](https://mshakhomirov.medium.com/?source=post_page-----93d058efa302--------------------------------)[![ğŸ’¡Mike
    Shakhomirov](../Images/bc6895c7face3244d488feb97ba0f68e.png)](https://mshakhomirov.medium.com/?source=post_page-----93d058efa302--------------------------------)[](https://towardsdatascience.com/?source=post_page-----93d058efa302--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----93d058efa302--------------------------------)
    [ğŸ’¡Mike Shakhomirov](https://mshakhomirov.medium.com/?source=post_page-----93d058efa302--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://mshakhomirov.medium.com/?source=post_page-----93d058efa302--------------------------------)[![ğŸ’¡Mike
    Shakhomirov](../Images/bc6895c7face3244d488feb97ba0f68e.png)](https://mshakhomirov.medium.com/?source=post_page-----93d058efa302--------------------------------)[](https://towardsdatascience.com/?source=post_page-----93d058efa302--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----93d058efa302--------------------------------)
    [ğŸ’¡Mike Shakhomirov](https://mshakhomirov.medium.com/?source=post_page-----93d058efa302--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----93d058efa302--------------------------------)
    Â·9 min readÂ·Dec 3, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----93d058efa302--------------------------------)
    Â·é˜…è¯»æ—¶é—´ 9 åˆ†é’ŸÂ·2023å¹´12æœˆ3æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/38909e6454cd7c166ad2897c1828b42d.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/38909e6454cd7c166ad2897c1828b42d.png)'
- en: Photo by [Sebastian Svenson](https://unsplash.com/@sebastiansvenson?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[Sebastian Svenson](https://unsplash.com/@sebastiansvenson?utm_source=medium&utm_medium=referral)
    åœ¨ [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Data modelling is an essential part of data engineering. In this story, I would
    like to talk about different data models, the role of SQL in data transformation
    and the data enrichment process. SQL is a powerful tool that helps to manipulate
    data. With data transformation pipelines we can transform and enrich data loaded
    into our data platform. We will discuss various methods of data manipulation,
    scheduling and incremental table updates. In order to make this process efficient
    we would want to know a few essential things about data modelling first.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å»ºæ¨¡æ˜¯æ•°æ®å·¥ç¨‹çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚åœ¨è¿™ä¸ªæ•…äº‹ä¸­ï¼Œæˆ‘æƒ³è®¨è®ºä¸åŒçš„æ•°æ®æ¨¡å‹ã€SQLåœ¨æ•°æ®è½¬æ¢ä¸­çš„ä½œç”¨ä»¥åŠæ•°æ®å¢å¼ºè¿‡ç¨‹ã€‚SQLæ˜¯ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·ï¼Œå¸®åŠ©æ“ä½œæ•°æ®ã€‚é€šè¿‡æ•°æ®è½¬æ¢ç®¡é“ï¼Œæˆ‘ä»¬å¯ä»¥è½¬æ¢å’Œå¢å¼ºåŠ è½½åˆ°æ•°æ®å¹³å°ä¸­çš„æ•°æ®ã€‚æˆ‘ä»¬å°†è®¨è®ºå„ç§æ•°æ®æ“ä½œæ–¹æ³•ã€è°ƒåº¦å’Œå¢é‡è¡¨æ›´æ–°ã€‚ä¸ºäº†ä½¿è¿™ä¸ªè¿‡ç¨‹é«˜æ•ˆï¼Œæˆ‘ä»¬éœ€è¦é¦–å…ˆäº†è§£ä¸€äº›å…³äºæ•°æ®å»ºæ¨¡çš„åŸºæœ¬çŸ¥è¯†ã€‚
- en: What is data modelling?
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯æ•°æ®å»ºæ¨¡ï¼Ÿ
- en: A **data model** aims to organise elements of your data and standardise how
    the data elements relate to one another.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ•°æ®æ¨¡å‹**æ—¨åœ¨ç»„ç»‡æ•°æ®å…ƒç´ å¹¶æ ‡å‡†åŒ–æ•°æ®å…ƒç´ ä¹‹é—´çš„å…³ç³»ã€‚'
- en: '**Data Models** ensure the quality of the data, semantic configurations and
    consistency in naming conventions. It helps to design the database ***conceptually***
    and create logical connections between data elements, i.e. primary and foreign
    keys, tables, etc.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ•°æ®æ¨¡å‹**ç¡®ä¿æ•°æ®çš„è´¨é‡ã€è¯­ä¹‰é…ç½®å’Œå‘½åä¸€è‡´æ€§ã€‚å®ƒæœ‰åŠ©äºä»***æ¦‚å¿µä¸Š***è®¾è®¡æ•°æ®åº“ï¼Œå¹¶åœ¨æ•°æ®å…ƒç´ ä¹‹é—´å»ºç«‹é€»è¾‘è¿æ¥ï¼Œä¾‹å¦‚ä¸»é”®å’Œå¤–é”®ã€è¡¨æ ¼ç­‰ã€‚'
- en: Good and thorough **data model design** is crucial if you need the most reliable
    and cost-effective data transformation for your data platform. It guarantees that
    the data is processed without delays and unnecessary steps.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ éœ€è¦æœ€å¯é å’Œå…·æœ‰æˆæœ¬æ•ˆç›Šçš„æ•°æ®è½¬æ¢ï¼Œè‰¯å¥½è€Œå…¨é¢çš„**æ•°æ®æ¨¡å‹è®¾è®¡**æ˜¯è‡³å…³é‡è¦çš„ã€‚å®ƒä¿è¯æ•°æ®å¤„ç†æ²¡æœ‰å»¶è¿Ÿå’Œä¸å¿…è¦çš„æ­¥éª¤ã€‚
- en: Companies use a procedure known as **dimensional data modelling** to process
    data. **Source** â€” **Production** â€” **Analytics** level split between schemas
    (datasets) enables effective data governance and makes sure our data is ready
    for business intelligence and machine learning.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å…¬å¸ä½¿ç”¨ä¸€ç§ç§°ä¸º**ç»´åº¦æ•°æ®å»ºæ¨¡**çš„ç¨‹åºæ¥å¤„ç†æ•°æ®ã€‚**æ¥æº** â€” **ç”Ÿäº§** â€” **åˆ†æ**çº§åˆ«åœ¨æ¨¡å¼ï¼ˆæ•°æ®é›†ï¼‰ä¹‹é—´çš„åˆ’åˆ†å®ç°äº†æœ‰æ•ˆçš„æ•°æ®æ²»ç†ï¼Œå¹¶ç¡®ä¿æˆ‘ä»¬çš„æ•°æ®ä¸ºä¸šåŠ¡æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ åšå¥½å‡†å¤‡ã€‚
- en: Any measurable information is being stored in **fact tables**, i.e. ***transactions,
    sessions, requests, etc.***
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä»»ä½•å¯è¡¡é‡çš„ä¿¡æ¯éƒ½å­˜å‚¨åœ¨**äº‹å®è¡¨**ä¸­ï¼Œå³***äº‹åŠ¡ã€ä¼šè¯ã€è¯·æ±‚ç­‰***ã€‚
- en: '**Foreign keys** are used in the fact tables, and they are connected to Dimension
    Tables. **Dimension Tables** have descriptive data that is linked to the Fact
    Table, i.e. ***brand, product type/code, country, etc.***'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¤–é”®** ç”¨äºäº‹å®è¡¨ä¸­ï¼Œå¹¶ä¸”å®ƒä»¬ä¸ç»´åº¦è¡¨ç›¸è¿æ¥ã€‚**ç»´åº¦è¡¨** æ‹¥æœ‰ä¸äº‹å®è¡¨ç›¸å…³çš„æè¿°æ€§æ•°æ®ï¼Œä¾‹å¦‚ ***å“ç‰Œã€äº§å“ç±»å‹/ä»£ç ã€å›½å®¶ç­‰ã€‚***'
- en: '**Dimensions and Facts** based on business requirements are being tied into
    the **Schema**.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®ä¸šåŠ¡éœ€æ±‚ï¼Œ**ç»´åº¦å’Œäº‹å®** è¢«æ•´åˆåˆ° **æ¨¡å¼** ä¸­ã€‚
- en: The two most popular schema types are **Star and Snowflake.** Not to say that
    these are the most frequent questions during data engineering job interviews [1].
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€å—æ¬¢è¿çš„ä¸¤ç§æ¨¡å¼ç±»å‹æ˜¯ **æ˜Ÿå‹æ¨¡å¼å’Œé›ªèŠ±æ¨¡å¼**ã€‚å¹¶ä¸”è¿™äº›ä¹Ÿæ˜¯æ•°æ®å·¥ç¨‹å¸ˆé¢è¯•ä¸­æœ€å¸¸è§çš„é—®é¢˜ä¹‹ä¸€ [1]ã€‚
- en: '[](/data-engineering-interview-questions-fdef62e46505?source=post_page-----93d058efa302--------------------------------)
    [## Data Engineering Interview Questions'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/data-engineering-interview-questions-fdef62e46505?source=post_page-----93d058efa302--------------------------------)
    [## æ•°æ®å·¥ç¨‹é¢è¯•é—®é¢˜]'
- en: Tips to prepare for a job interview
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å‡†å¤‡å·¥ä½œé¢è¯•çš„æç¤º
- en: towardsdatascience.com](/data-engineering-interview-questions-fdef62e46505?source=post_page-----93d058efa302--------------------------------)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/data-engineering-interview-questions-fdef62e46505?source=post_page-----93d058efa302--------------------------------)'
- en: '**Star Schema**: The Star Schema is the Schema with a **highly denormalised**
    structure. This is very common in modern data warehouses where data is repeated
    in many tables. Each Dimension represents one Dimension Table. Dimension Tables
    have foreign keys that are joined with the Fact Tables to get the results. Data
    redundancy is high, but due to the simplicity of the schema design, it can offer
    performance benefits. It is more denormalised; It means fewer joins between tables,
    and therefore, it is optimised for querying.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ˜Ÿå‹æ¨¡å¼**ï¼šæ˜Ÿå‹æ¨¡å¼æ˜¯ä¸€ä¸ªå…·æœ‰**é«˜åº¦éè§„èŒƒåŒ–**ç»“æ„çš„æ¨¡å¼ã€‚è¿™åœ¨ç°ä»£æ•°æ®ä»“åº“ä¸­éå¸¸å¸¸è§ï¼Œæ•°æ®ä¼šåœ¨å¤šä¸ªè¡¨ä¸­é‡å¤ã€‚æ¯ä¸ªç»´åº¦ä»£è¡¨ä¸€ä¸ªç»´åº¦è¡¨ã€‚ç»´åº¦è¡¨å…·æœ‰ä¸äº‹å®è¡¨è¿æ¥çš„å¤–é”®ï¼Œä»¥è·å–ç»“æœã€‚æ•°æ®å†—ä½™è¾ƒé«˜ï¼Œä½†ç”±äºæ¨¡å¼è®¾è®¡çš„ç®€å•æ€§ï¼Œå®ƒå¯ä»¥æä¾›æ€§èƒ½ä¸Šçš„å¥½å¤„ã€‚å®ƒæ›´ä¸ºéè§„èŒƒåŒ–ï¼›è¿™æ„å‘³ç€è¡¨ä¹‹é—´çš„è¿æ¥è¾ƒå°‘ï¼Œå› æ­¤å®ƒåœ¨æŸ¥è¯¢æ—¶è¡¨ç°æ›´ä¼˜ã€‚'
- en: '![](../Images/9b14f90ff13ea78dd0d641f374a68a32.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9b14f90ff13ea78dd0d641f374a68a32.png)'
- en: Star Schema example. Image by author.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜Ÿå‹æ¨¡å¼ç¤ºä¾‹ã€‚ä½œè€…æä¾›çš„å›¾ç‰‡ã€‚
- en: '**Snowflake Schema**: Snowflake schema extends Star schema with more normalised
    dimensional tables. This Schema uses less disk space as all the tables are normalised
    and split down into further dimension tables. It is easy to add Dimensions to
    this Schema, and the data redundancy is also less because of the complex Schema
    design.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é›ªèŠ±æ¨¡å¼**ï¼šé›ªèŠ±æ¨¡å¼æ‰©å±•äº†æ˜Ÿå‹æ¨¡å¼ï¼Œå…·æœ‰æ›´å¤šè§„èŒƒåŒ–çš„ç»´åº¦è¡¨ã€‚æ­¤æ¨¡å¼ä½¿ç”¨è¾ƒå°‘çš„ç£ç›˜ç©ºé—´ï¼Œå› ä¸ºæ‰€æœ‰è¡¨éƒ½ç»è¿‡è§„èŒƒåŒ–ï¼Œå¹¶æ‹†åˆ†æˆè¿›ä¸€æ­¥çš„ç»´åº¦è¡¨ã€‚æ·»åŠ ç»´åº¦åˆ°æ­¤æ¨¡å¼ä¸­å¾ˆå®¹æ˜“ï¼Œè€Œä¸”ç”±äºå¤æ‚çš„æ¨¡å¼è®¾è®¡ï¼Œæ•°æ®å†—ä½™ä¹Ÿè¾ƒå°‘ã€‚'
- en: '![](../Images/8adb908d8436beaba878067695fffce1.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8adb908d8436beaba878067695fffce1.png)'
- en: Snowflake Schema example. Image by author.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: é›ªèŠ±æ¨¡å¼ç¤ºä¾‹ã€‚ä½œè€…æä¾›çš„å›¾ç‰‡ã€‚
- en: '**Galaxy Schema**: Similar to the schemas stated above, a galaxy schema has
    several fact tables from **more than one-dimensional models**.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ˜Ÿç³»æ¨¡å¼**ï¼šç±»ä¼¼äºä¸Šè¿°æ¨¡å¼ï¼Œæ˜Ÿç³»æ¨¡å¼å…·æœ‰æ¥è‡ª **å¤šä¸ªç»´åº¦æ¨¡å‹** çš„å¤šä¸ªäº‹å®è¡¨ã€‚'
- en: Relational, Dimensional and Multi-dimensional data modelling
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…³ç³»å‹ã€ç»´åº¦å‹å’Œå¤šç»´æ•°æ®å»ºæ¨¡
- en: Pure **relational data modelling** is often seen in OLTP data pipelines and
    relational (transactional) databases feeding data into the application. In this
    scenario data transaction speed and size is crucial. In this case, we would want
    to apply a highly-normalised data schema design. Data is always up-to-date but
    running reports might become a challenging task due to a high number of joins
    on various dimension tables.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: çº¯ç²¹çš„ **å…³ç³»å‹æ•°æ®å»ºæ¨¡** é€šå¸¸å‡ºç°åœ¨OLTPæ•°æ®ç®¡é“å’Œå‘åº”ç”¨ç¨‹åºæä¾›æ•°æ®çš„å…³ç³»ï¼ˆäº‹åŠ¡ï¼‰æ•°æ®åº“ä¸­ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ•°æ®äº‹åŠ¡é€Ÿåº¦å’Œå¤§å°è‡³å…³é‡è¦ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›åº”ç”¨é«˜åº¦è§„èŒƒåŒ–çš„æ•°æ®æ¨¡å¼è®¾è®¡ã€‚æ•°æ®æ€»æ˜¯æœ€æ–°çš„ï¼Œä½†ç”±äºåœ¨å„ç§ç»´åº¦è¡¨ä¸Šçš„è¿æ¥æ¬¡æ•°è¾ƒå¤šï¼Œè¿è¡ŒæŠ¥å‘Šå¯èƒ½æˆä¸ºä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚
- en: '**Dimensional modelling** as a process aims to ensure the most efficient data
    storage structure and faster data transformation for large amounts of data. The
    reason we would want to do this is simple â€” a more performant data platform with
    easy management and data governance. For instance, Snowflake schema helps to reduce
    data redundancy which is opposite to Star schema and is more suitable for OLAP
    analytics and reporting (no need to perform expensive joins).'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç»´åº¦å»ºæ¨¡** ä½œä¸ºä¸€ä¸ªè¿‡ç¨‹ï¼Œæ—¨åœ¨ç¡®ä¿æœ€æœ‰æ•ˆçš„æ•°æ®å­˜å‚¨ç»“æ„ä»¥åŠæ›´å¿«çš„æ•°æ®è½¬æ¢ï¼Œä»¥å¤„ç†å¤§é‡æ•°æ®ã€‚æˆ‘ä»¬å¸Œæœ›è¿™æ ·åšçš„åŸå› å¾ˆç®€å•â€”â€”æä¾›ä¸€ä¸ªæ›´é«˜æ•ˆçš„æ•°æ®å¹³å°ï¼Œä¾¿äºç®¡ç†å’Œæ•°æ®æ²»ç†ã€‚ä¾‹å¦‚ï¼Œé›ªèŠ±æ¨¡å¼æœ‰åŠ©äºå‡å°‘æ•°æ®å†—ä½™ï¼Œè¿™ä¸æ˜Ÿå‹æ¨¡å¼ç›¸åï¼Œæ›´é€‚åˆç”¨äºOLAPåˆ†æå’ŒæŠ¥å‘Šï¼ˆæ— éœ€æ‰§è¡Œæ˜‚è´µçš„è¿æ¥æ“ä½œï¼‰ã€‚'
- en: The **Multi-Dimensional Data Model** represents data in **cubes**.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/238f2155f5f94f08b9e98346270ad4b9.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
- en: Data points (values) in a three-dimensional data cube. Image by author.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: It adds complexity but also makes data structure more efficient for complex
    reporting. Data is stored in aggregated cubes (tables) which adds more capabilities
    for users to perform robust OLAP data transformations, i.e. pivoting, drill-down
    features, and advanced dashboarding with multiple dimensions simultaneously. Often
    it is not necessary to aggregate and preserve the data. We can define the data
    model as a **cube** using SQL with ROLLUP [2].
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: The ROLLUP function is used to perform aggregation at multiple levels. This
    is useful when you have to work with dimension graphs.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/866e98ef7b2cc52b52fefcdbf67e3bd9.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
- en: Image by author
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Consider this SQL below. It provides input data and a required SQL transformation
    to create a multi-dimensional data model.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Any dataset we create as a custom SQL query can be considered as a dimensional
    model.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '[](/advanced-sql-techniques-for-beginners-211851a28488?source=post_page-----93d058efa302--------------------------------)
    [## Advanced SQL techniques for beginners'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: On a scale from 1 to 10 how good are your data warehousing skills?
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/advanced-sql-techniques-for-beginners-211851a28488?source=post_page-----93d058efa302--------------------------------)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Dimensional and multi-dimensional models are very often seen in data warehouse
    solutions. The dimensional data model makes schemas simple and more clear for
    business users.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: How to create a dimensional model?
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To introduce a dimensional model element into our data platform design we create
    dimensional models. It can be a schema or a database or even a part of our data
    platform in the data lake that can describe various business processes defined
    by many fact tables. Letâ€™s consider a single business process with two fact tables.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we would want to **identify a business process** we need to transform
    into our data model and define the **granularity** of each fact table. Letâ€™s imagine
    itâ€™s an in-app store purchase with the following data in fact table rows for a
    payment transaction:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Granularity** refers to the level of information stored in our table. For
    example, in our example, the in-app payments are recorded with each transaction;
    hence, the granularity is **transaction-level** which can be easily transformed
    into **daily**. It is important that the fact tables in our dimensional model
    are consistent with the granularity specified. It means we would want to load
    atomic data into the same dimensional structures.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: 'Typically we would want to **transform and incrementally update** data like
    so:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Next, we need to define **the dimensions** for each fact table. In our case,
    we have ***payment transactions*** as facts. These **facts** can contain such
    useful data as the total number of items sold, currency exchange rates, total
    revenue, tax, etc. Further **dimensions** will provide context for our in-app
    purchase data, i.e. **time, product and user** dimension data. Each dimension
    can help to answer important business questions. *For instance, we might want
    to know which is the best-selling product or what was the average spend among
    users.*
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦ä¸ºæ¯ä¸ªäº‹å®è¡¨å®šä¹‰**ç»´åº¦**ã€‚åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œ**æ”¯ä»˜äº¤æ˜“**ä½œä¸ºäº‹å®ã€‚è¿™äº›**äº‹å®**å¯ä»¥åŒ…å«æœ‰ç”¨çš„æ•°æ®ï¼Œä¾‹å¦‚é”€å”®çš„æ€»æ•°é‡ã€è´§å¸å…‘æ¢ç‡ã€æ€»æ”¶å…¥ã€ç¨æ”¶ç­‰ã€‚è¿›ä¸€æ­¥çš„**ç»´åº¦**å°†ä¸ºæˆ‘ä»¬çš„åº”ç”¨å†…è´­ä¹°æ•°æ®æä¾›èƒŒæ™¯ï¼Œå³**æ—¶é—´ã€äº§å“å’Œç”¨æˆ·**ç»´åº¦æ•°æ®ã€‚æ¯ä¸ªç»´åº¦éƒ½å¯ä»¥å¸®åŠ©å›ç­”é‡è¦çš„ä¸šåŠ¡é—®é¢˜ã€‚*ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯èƒ½æƒ³çŸ¥é“å“ªä¸ªæ˜¯æœ€ç•…é”€çš„äº§å“ï¼Œæˆ–è€…ç”¨æˆ·çš„å¹³å‡èŠ±è´¹æ˜¯å¤šå°‘ã€‚*
- en: Each in-app payment transaction will have foreign keys describing fact-to-dimension
    relationships and point to a relevant product, time of purchase or user profile.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªåº”ç”¨å†…æ”¯ä»˜äº¤æ˜“å°†æ‹¥æœ‰æè¿°äº‹å®ä¸ç»´åº¦å…³ç³»çš„å¤–é”®ï¼Œå¹¶æŒ‡å‘ç›¸å…³çš„äº§å“ã€è´­ä¹°æ—¶é—´æˆ–ç”¨æˆ·èµ„æ–™ã€‚
- en: Next, we would want to define **hierarchies. Hierarchies** help business users
    to understand different levels of **granularity** of our dataset. It also helps
    with navigation and advanced reporting features, i.e. drill down. For example,
    the product dimension might have a **hierarchy** that goes from `category` to
    `type` to `id` to `sub_id`.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¸Œæœ›å®šä¹‰**å±‚çº§**ã€‚å±‚çº§æœ‰åŠ©äºä¸šåŠ¡ç”¨æˆ·ç†è§£æ•°æ®é›†çš„ä¸åŒ**ç²’åº¦**çº§åˆ«ã€‚å®ƒè¿˜å¸®åŠ©å¯¼èˆªå’Œé«˜çº§æŠ¥å‘ŠåŠŸèƒ½ï¼Œå³é’»å–ã€‚ä¾‹å¦‚ï¼Œäº§å“ç»´åº¦å¯èƒ½å…·æœ‰ä¸€ä¸ª**å±‚çº§**ï¼Œä»`ç±»åˆ«`åˆ°`ç±»å‹`å†åˆ°`ID`å’Œ`å­ID`ã€‚
- en: We would want to use some calculations in our model called **Measures**. Measures
    are what we calculate using our fact table to generate data insights. It can be
    total `revenue`, `net revenue`, `tax amount`, etc.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¸Œæœ›åœ¨æ¨¡å‹ä¸­ä½¿ç”¨ä¸€äº›ç§°ä¸º**åº¦é‡**çš„è®¡ç®—ã€‚åº¦é‡æ˜¯æˆ‘ä»¬ä½¿ç”¨äº‹å®è¡¨è®¡ç®—ä»¥ç”Ÿæˆæ•°æ®æ´å¯Ÿçš„å†…å®¹ã€‚å¯ä»¥æ˜¯æ€»`æ”¶å…¥`ã€`å‡€æ”¶å…¥`ã€`ç¨é¢`ç­‰ã€‚
- en: 'With this multi-dimensional model businesses could answer some crucial questions:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨è¿™ä¸ªå¤šç»´æ¨¡å‹ï¼Œä¼ä¸šå¯ä»¥å›ç­”ä¸€äº›å…³é”®é—®é¢˜ï¼š
- en: What was our total revenue for each product in the last year or month?
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å»å¹´æˆ–ä¸Šä¸ªæœˆæˆ‘ä»¬æ¯ä¸ªäº§å“çš„æ€»æ”¶å…¥æ˜¯å¤šå°‘ï¼Ÿ
- en: Users with what reputation level spend more?
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…·æœ‰ä½•ç§å£°èª‰çº§åˆ«çš„ç”¨æˆ·èŠ±è´¹æ›´å¤šï¼Ÿ
- en: Which product was the best-selling one?
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å“ªä¸ªäº§å“æ˜¯æœ€ç•…é”€çš„ï¼Ÿ
- en: How revenue this year can be compared to the same period last year?â€
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»Šå¹´çš„æ”¶å…¥å¦‚ä½•ä¸å»å¹´åŒæœŸç›¸æ¯”ï¼Ÿ
- en: Finally, we would want to verify our data model with users.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬å¸Œæœ›é€šè¿‡ç”¨æˆ·éªŒè¯æˆ‘ä»¬çš„æ•°æ®æ¨¡å‹ã€‚
- en: Benefits of Dimensional Modeling
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç»´åº¦å»ºæ¨¡çš„å¥½å¤„
- en: '**Flexibility.** A dimensional modelling framework extends the data warehousing
    process. The design is highly adaptable to accommodate new business requirements
    or to alter the central repository. To represent updated business processes, new
    entities may be added to the model or the layout of existing ones might be adjusted.
    Dimensional models can handle these changes with ease. More columns can be added
    to dimension tables without disrupting current business intelligence applications
    that use the original tables.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**çµæ´»æ€§ã€‚** ä¸€ä¸ªç»´åº¦å»ºæ¨¡æ¡†æ¶æ‰©å±•äº†æ•°æ®ä»“åº“çš„è¿‡ç¨‹ã€‚è¯¥è®¾è®¡é«˜åº¦é€‚åº”ä»¥é€‚åº”æ–°çš„ä¸šåŠ¡éœ€æ±‚æˆ–æ›´æ”¹ä¸­å¤®ä»“åº“ã€‚ä¸ºäº†è¡¨ç¤ºæ›´æ–°åçš„ä¸šåŠ¡æµç¨‹ï¼Œå¯ä»¥å‘æ¨¡å‹ä¸­æ·»åŠ æ–°å®ä½“æˆ–è°ƒæ•´ç°æœ‰å®ä½“çš„å¸ƒå±€ã€‚ç»´åº¦æ¨¡å‹å¯ä»¥è½»æ¾å¤„ç†è¿™äº›å˜åŒ–ã€‚å¯ä»¥å‘ç»´åº¦è¡¨ä¸­æ·»åŠ æ›´å¤šåˆ—ï¼Œè€Œä¸ä¼šå¹²æ‰°ä½¿ç”¨åŸå§‹è¡¨çš„å½“å‰å•†ä¸šæ™ºèƒ½åº”ç”¨ç¨‹åºã€‚'
- en: '**Multi-dimensional Analytics:** Like it was demonstrated in the previous example
    we can use extra dimensions to create better graphs and more complex charts. Hierarchies
    help to understand data and analyse it simultaneously with drill-down features
    added to reporting dashboards. It is optimised for business intelligence (BI)
    needs and is easy to understand. Modern BI tools have built-in AI capabilities
    natively designed to understand dimension structure and data [3].'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¤šç»´åˆ†æï¼š** æ­£å¦‚å‰é¢çš„ç¤ºä¾‹æ‰€ç¤ºï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨é¢å¤–çš„ç»´åº¦æ¥åˆ›å»ºæ›´å¥½çš„å›¾è¡¨å’Œæ›´å¤æ‚çš„å›¾å½¢ã€‚å±‚çº§ç»“æ„æœ‰åŠ©äºç†è§£æ•°æ®ï¼Œå¹¶åŒæ—¶è¿›è¡Œåˆ†æï¼ŒæŠ¥å‘Šä»ªè¡¨æ¿ä¸­è¿˜å¢åŠ äº†é’»å–åŠŸèƒ½ã€‚å®ƒé’ˆå¯¹å•†ä¸šæ™ºèƒ½ï¼ˆBIï¼‰éœ€æ±‚è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå¹¶ä¸”æ˜“äºç†è§£ã€‚ç°ä»£
    BI å·¥å…·å†…ç½®äº†åŸç”Ÿè®¾è®¡çš„ AI åŠŸèƒ½ï¼Œä»¥ç†è§£ç»´åº¦ç»“æ„å’Œæ•°æ®[3]ã€‚'
- en: '[](/artificial-intelligence-in-analytics-f11d2deafdf0?source=post_page-----93d058efa302--------------------------------)
    [## Artificial Intelligence in Analytics'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/artificial-intelligence-in-analytics-f11d2deafdf0?source=post_page-----93d058efa302--------------------------------)
    [## åˆ†æä¸­çš„äººå·¥æ™ºèƒ½'
- en: AI-powered Business Intelligence. A hype or reality?
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AI é©±åŠ¨çš„å•†ä¸šæ™ºèƒ½ã€‚æ˜¯ç‚’ä½œè¿˜æ˜¯ç°å®ï¼Ÿ
- en: towardsdatascience.com](/artificial-intelligence-in-analytics-f11d2deafdf0?source=post_page-----93d058efa302--------------------------------)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/artificial-intelligence-in-analytics-f11d2deafdf0?source=post_page-----93d058efa302--------------------------------)
- en: '**Improved query speed:** Multi-dimensional tables are often denormalised and
    bring all the performance benefits of star schema design. Opposite to Snowflake
    schema, it enables **faster data retrieval** with fewer `join` operations.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ”¹è¿›çš„æŸ¥è¯¢é€Ÿåº¦ï¼š** å¤šç»´è¡¨é€šå¸¸æ˜¯éè§„èŒƒåŒ–çš„ï¼Œå¹¶å¸¦æ¥æ˜Ÿå‹æ¶æ„è®¾è®¡çš„æ‰€æœ‰æ€§èƒ½ä¼˜åŠ¿ã€‚ä¸é›ªèŠ±æ¶æ„ç›¸å¯¹ï¼Œå®ƒé€šè¿‡å‡å°‘`join`æ“ä½œå®ç°**æ›´å¿«çš„æ•°æ®æ£€ç´¢**ã€‚'
- en: Limitations of dimensional data modelling
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç»´åº¦æ•°æ®å»ºæ¨¡çš„å±€é™æ€§
- en: While dimensional modelling is a strong technique for OLAP purposes, it does
    have certain limits, and in some cases, it may not be the best option.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡ç»´åº¦å»ºæ¨¡æ˜¯OLAPç”¨é€”çš„å¼ºå¤§æŠ€æœ¯ï¼Œä½†å®ƒç¡®å®æœ‰ä¸€å®šçš„é™åˆ¶ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¯èƒ½ä¸æ˜¯æœ€ä½³é€‰æ‹©ã€‚
- en: '**Data changes frequently:** As dimensional datasets are often denormalised
    data redundancy is high here. Denormalised datasets might struggle with the requirements
    of real-time modifications. An OLTP approach may be more suited to such a scenario.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ•°æ®ç»å¸¸å˜åŒ–ï¼š** ç”±äºç»´åº¦æ•°æ®é›†é€šå¸¸æ˜¯éè§„èŒƒåŒ–çš„ï¼Œè¿™é‡Œçš„æ•°æ®å†—ä½™è¾ƒé«˜ã€‚éè§„èŒƒåŒ–çš„æ•°æ®é›†å¯èƒ½åœ¨å®æ—¶ä¿®æ”¹çš„éœ€æ±‚ä¸‹è¡¨ç°ä¸ä½³ã€‚OLTPæ–¹æ³•å¯èƒ½æ›´é€‚åˆè¿™ç§æƒ…å†µã€‚'
- en: '**Unstructured data:** Dimensional data modelling wonâ€™t perform well on **sparse
    and unstructured data.** Wherever we have limited fact data that can be tied to
    dimensions it might be inefficient, i.e. documents and text data. Document oriented
    database solution might be a better choice in this case.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**éç»“æ„åŒ–æ•°æ®ï¼š** ç»´åº¦æ•°æ®å»ºæ¨¡åœ¨**ç¨€ç–å’Œéç»“æ„åŒ–æ•°æ®**ä¸Šè¡¨ç°ä¸ä½³ã€‚å¯¹äºæœ‰é™çš„äº‹å®æ•°æ®ï¼Œè¿™äº›æ•°æ®å¯ä»¥ä¸ç»´åº¦å…³è”ï¼Œå¯èƒ½ä¼šä½æ•ˆï¼Œä¾‹å¦‚æ–‡æ¡£å’Œæ–‡æœ¬æ•°æ®ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé¢å‘æ–‡æ¡£çš„æ•°æ®åº“è§£å†³æ–¹æ¡ˆå¯èƒ½æ˜¯æ›´å¥½çš„é€‰æ‹©ã€‚'
- en: '**Storage:** Denormalised datasets require more storage space compared to OLTP
    schemas.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**å­˜å‚¨ï¼š** éè§„èŒƒåŒ–çš„æ•°æ®é›†éœ€è¦æ¯”OLTPæ¨¡å¼æ›´å¤šçš„å­˜å‚¨ç©ºé—´ã€‚'
- en: Conclusion
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: Because of the benefits it provides, dimensional modelling is still the most
    often used data modelling approach for developing business data warehouses. It
    yields better reporting capabilities with multi-dimensional analysis, optimised
    query performance with fewer joins and faster data retrieval. Dimensional modelling
    makes the data warehousing design process more flexible and highly adaptable.
    It also has a certain limitation which makes it incompatible with unstructured
    datasets and OLTP pipelines due to a high requirement for data redundancy of the
    latter. Overall multi-domensional modelling is a great technique for OLAP and
    reporting which enables better query performance.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºå…¶æä¾›çš„å¥½å¤„ï¼Œç»´åº¦å»ºæ¨¡ä»ç„¶æ˜¯å¼€å‘ä¸šåŠ¡æ•°æ®ä»“åº“æ—¶æœ€å¸¸ç”¨çš„æ•°æ®å»ºæ¨¡æ–¹æ³•ã€‚å®ƒé€šè¿‡å¤šç»´åˆ†ææä¾›æ›´å¥½çš„æŠ¥å‘Šèƒ½åŠ›ï¼Œé€šè¿‡å‡å°‘è”æ¥ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½å¹¶åŠ å¿«æ•°æ®æ£€ç´¢ã€‚ç»´åº¦å»ºæ¨¡ä½¿æ•°æ®ä»“åº“è®¾è®¡è¿‡ç¨‹æ›´çµæ´»ï¼Œæ›´å…·é€‚åº”æ€§ã€‚å®ƒä¹Ÿæœ‰ä¸€å®šçš„å±€é™æ€§ï¼Œä½¿å…¶ä¸éç»“æ„åŒ–æ•°æ®é›†å’ŒOLTPç®¡é“ä¸å…¼å®¹ï¼Œå› ä¸ºåè€…å¯¹æ•°æ®å†—ä½™çš„è¦æ±‚è¾ƒé«˜ã€‚æ€»ä½“è€Œè¨€ï¼Œå¤šç»´å»ºæ¨¡æ˜¯ä¸€ä¸ªå‡ºè‰²çš„OLAPå’ŒæŠ¥å‘ŠæŠ€æœ¯ï¼Œèƒ½å¤Ÿæä¾›æ›´å¥½çš„æŸ¥è¯¢æ€§èƒ½ã€‚
- en: Recommended read
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¨èé˜…è¯»
- en: '[1] [https://medium.com/towards-data-science/data-engineering-interview-questions-fdef62e46505](https://medium.com/towards-data-science/data-engineering-interview-questions-fdef62e46505)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [https://medium.com/towards-data-science/data-engineering-interview-questions-fdef62e46505](https://medium.com/towards-data-science/data-engineering-interview-questions-fdef62e46505)'
- en: '[2] [https://medium.com/towards-data-science/advanced-sql-techniques-for-beginners-211851a28488](https://medium.com/towards-data-science/advanced-sql-techniques-for-beginners-211851a28488)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [https://medium.com/towards-data-science/advanced-sql-techniques-for-beginners-211851a28488](https://medium.com/towards-data-science/advanced-sql-techniques-for-beginners-211851a28488)'
- en: '[3] [https://medium.com/towards-data-science/artificial-intelligence-in-analytics-f11d2deafdf0](https://medium.com/towards-data-science/artificial-intelligence-in-analytics-f11d2deafdf0)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [https://medium.com/towards-data-science/artificial-intelligence-in-analytics-f11d2deafdf0](https://medium.com/towards-data-science/artificial-intelligence-in-analytics-f11d2deafdf0)'
- en: '[4] [https://towardsdatascience.com/modern-data-engineering-e202776fb9a9](/modern-data-engineering-e202776fb9a9)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [https://towardsdatascience.com/modern-data-engineering-e202776fb9a9](/modern-data-engineering-e202776fb9a9)'
- en: '[5] [https://towardsdatascience.com/how-to-become-a-data-engineer-c0319cb226c2](/how-to-become-a-data-engineer-c0319cb226c2)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] [https://towardsdatascience.com/how-to-become-a-data-engineer-c0319cb226c2](/how-to-become-a-data-engineer-c0319cb226c2)'
