- en: Java and Data Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/java-and-data-engineering-f0e0a145cb52](https://towardsdatascience.com/java-and-data-engineering-f0e0a145cb52)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: DATA ENGINEERING
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Java Juggernaut: The key to data engineering mastery'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://tamimi-naser.medium.com/?source=post_page-----f0e0a145cb52--------------------------------)[![Naser
    Tamimi](../Images/8d43c66ea3c0ef9b49c7d33dbc008c28.png)](https://tamimi-naser.medium.com/?source=post_page-----f0e0a145cb52--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f0e0a145cb52--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f0e0a145cb52--------------------------------)
    [Naser Tamimi](https://tamimi-naser.medium.com/?source=post_page-----f0e0a145cb52--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f0e0a145cb52--------------------------------)
    ·4 min read·Nov 11, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/beb492e0841f67c958a6cbd9ba1cd4b5.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Zhen H](https://unsplash.com/@zhenh2424?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Data Engineering and Programming Skills
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we think about data engineering, the first programming skills that usually
    come to mind are SQL and maybe Python. SQL is this well-known language for querying
    data, deeply ingrained in the world of data and pipelines. Python, on the other
    hand, has become quite powerful in data science and is now making its mark in
    the evolving field of data engineering. But, is this common belief accurate? Are
    SQL and Python really the most important programming skills for Data Engineers?
    In this article, I’ll share my experiences on this topic, aiming to help young
    professionals figure out the best skills to make the most of their time and energy.
  prefs: []
  type: TYPE_NORMAL
- en: Why Java and Scala?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In today’s data engineering, we handle a massive amount of data. The main job
    is figuring out how to gather, change, and store this huge load of data every
    day, hour, or even in real-time. What makes it trickier is making sure different
    data services can smoothly run on various systems without worrying about what’s
    happening underneath.
  prefs: []
  type: TYPE_NORMAL
- en: In the last 15 years, smart folks have come up with distributed computing frameworks
    to deal with this data overload. Hadoop and Spark are two big names in this game.
    Because both these frameworks are mainly built using JVM (Java Virtual Machine)
    languages (Hadoop uses Java, and Spark uses Scala), many data and software experts
    believe that Java and Scala are the way forward in data engineering.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, the ability of JVM applications to be portable makes them an excellent
    choice for data applications operating across diverse systems and environments.
    You can develop data pipelines that seamlessly run on various cloud and local
    setups, allowing you to scale your systems up or down without concerns about the
    underlying infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: How does a data pipeline look like in a JVM-based applications?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we’ve explored the benefits of Java and Scala, or more broadly, JVM-based
    data applications, in handling big data, the next logical question is: what do
    these applications, or simply data pipelines, look like? This section aims to
    provide an overview of the architecture of such applications.'
  prefs: []
  type: TYPE_NORMAL
- en: To begin, it’s essential to develop a data pipeline in Java or Scala. Typically,
    multiple related data pipelines can coexist within the same Java or Scala project.
    For effective project management, tools like Apache Maven can be employed. Maven
    simplifies the creation, management, and building of Java applications, making
    the process more efficient and reliable.
  prefs: []
  type: TYPE_NORMAL
- en: In these projects, a data pipeline often comprises one or more Java or Scala
    classes. Spark is commonly integrated into these classes for tasks such as reading
    (or extracting), transforming, and writing (or loading) data. While data can be
    read from and written to various sources, Hive tables are often the natural choices.
    Standard transformations are encapsulated in common classes, making them reusable
    across different pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: This code shows a basic data pipeline in Spark Scala.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Ultimately, the goal is to build a Java application typically in the form of
    a jar file. This jar file, along with appropriate arguments, can be invoked using
    job and workflow management systems like Apache Airflow. This enables the execution
    of specific data pipelines at scheduled intervals, contributing to an organized
    and automated data processing workflow.
  prefs: []
  type: TYPE_NORMAL
- en: Here’s a simple example demonstrating how to execute a data pipeline, represented
    as a class, from the command line.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: More advanced practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As previously mentioned, data pipelines, now encapsulated in jar files, typically
    require scheduled execution, especially for batch processing, or activation based
    on triggered events, commonly for real-time processing. Apache Airflow serves
    as a robust solution for orchestrating these jar files and task classes, facilitating
    the execution of jobs on a regular schedule. Alternatively, jar files can be triggered
    using tools like AWS Lambda for irregular schedules and real-time processing.
  prefs: []
  type: TYPE_NORMAL
- en: This is an example of an Apache Airflow DAG designed to execute a Java class
    daily.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Moreover, Continuous Integration/Continuous Deployment (CI/CD) tools, including
    Jenkins, GitHub Actions, Spinnaker, among others, offer a seamless way to develop
    and deploy pipelines across various environments from development to testing and
    production environments. This ensures a smooth and automated transition of pipelines
    throughout the development lifecycle.
  prefs: []
  type: TYPE_NORMAL
- en: At the end …
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We explored the evolving landscape of data engineering and the essential programming
    skills required in this field. While SQL and Python have traditionally been associated
    with data engineering, the focus is shifting towards Java and Scala, particularly
    in the context of handling massive amounts of data through distributed computing
    frameworks like Hadoop and Spark.
  prefs: []
  type: TYPE_NORMAL
- en: Again, we emphasized the importance of JVM (Java Virtual Machine) languages
    due to their portability, making them suitable for developing data applications
    that seamlessly run across diverse systems and environments. It delves into the
    architecture of JVM-based data applications, illustrating the development of data
    pipelines using Java or Scala, with Apache Maven aiding project management.
  prefs: []
  type: TYPE_NORMAL
