- en: 'Causal Diagram: Confronting the Achilles’ Heel in Observational Data'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/causal-diagram-confronting-the-achilles-heel-in-observational-data-a69cdb1c4818](https://towardsdatascience.com/causal-diagram-confronting-the-achilles-heel-in-observational-data-a69cdb1c4818)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/78fda415395cbc77039ad581796f620e.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: Photo by [Андрей Сизов](https://unsplash.com/@alpridephoto?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: “The Book of Why” Chapters 3&4, a Read with Me series
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://zzhu17.medium.com/?source=post_page-----a69cdb1c4818--------------------------------)[![Zijing
    Zhu, PhD](../Images/436b22e28798b87261c4814a7e2b20e3.png)](https://zzhu17.medium.com/?source=post_page-----a69cdb1c4818--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a69cdb1c4818--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a69cdb1c4818--------------------------------)
    [Zijing Zhu, PhD](https://zzhu17.medium.com/?source=post_page-----a69cdb1c4818--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a69cdb1c4818--------------------------------)
    ·13 min read·Nov 23, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: In my previous two articles, I [kicked off](https://medium.com/towards-data-science/read-with-me-a-causality-book-club-edd7085d6ae6)
    the “Read with Me” series and finished reading the [first two chapters](/data-tells-us-what-and-we-always-seek-for-why-66da7dc3f24d)
    from “[The Book of Why](https://www.amazon.com/Book-Why-Science-Cause-Effect/dp/046509760X)”
    by Judea Pearl. These articles discuss the necessity of introducing causality
    in enabling human-like decision-making and emphasize the Ladder of Causation that
    sets up the foundation for future discussions. In this article, we will explore
    the keyholes that open the door from the first to the second rung of the ladder
    of causation, allowing us to move beyond probability and into causal thinking.
    We will go from Bayes’s rule to the Bayesian network to, finally, the causal diagrams.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: From Bayes’s rule to inverse probability
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As a fan of detective novels, my favorite series is Sherlock Holmes. I still
    remember all these days and nights I read them without noticing time passing by.
    Years later, lots of the case details had already disappeared from my memories,
    but I still remember the famous quotes like everyone else:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '**When you have eliminated the impossible, whatever remains, however improbable,
    must be the truth.**'
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Translating this quote into the field of statistics, there are two types of
    probabilities — — forward probability and inverse probability. Based on Sherlock
    Holmes’s deductive reasoning, detective work is just finding the murderer with
    the highest inverse probability.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2e09cf5270e74fe8472500b80556712e.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
- en: Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: 'Going from forward probability to inverse probability, we are not only just
    flipping the variables sequentially but also enforcing a causal relationship.
    As briefly discussed in the previous article, Bayes’s rule provides a bridge that
    connects objective data (evidence) with subjective opinions (prior belief). Based
    on Bayes’s rule, we can calculate conditional probabilities from any two variables.
    For any variable A and B, given that B has happened, the probability of A happening
    is:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The belief that A happens will be updated based on the probability of B happening.
    The less likely B happens, P(B) gets smaller, the more belief I have for A to
    happen. Since P(B) is smaller or equal to 1, P(A|B) is always greater than or
    equal to P(A&B). This is saying that the belief a person attributes to A after
    discovering B is never lower than the degree of belief that a person attributes
    to A and B before discovering B. Note the conditional probability here applies
    to all variable relationships, even the non-causal ones. However, the inverse
    probability only applies to the causal relationship.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Assume the two events are ***Cause*** and ***Evidence.*** Forward probability
    represents the probability of ***Evidence*** given the probability of ***Cause***.
    Inverse probability, on the other hand, starts from the result and shows the probability
    of ***Cause*** given the probability of ***Evidence***. If we can identify the
    causal relationship between ***Cause*** and ***Evidence***, then we can deduct
    the probability of Cause based on what we observe, which is more applicable in
    solving real-world problems.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ab77ee07e8ccc5a21b6355b16574507d.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
- en: Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: In the book, Pearl gives an application in estimating what is the probability
    of having breast cancer given that the mammogram test comes out positive, i.e.,
    what is **P(disease|test)**? First of all, there is a clear causal relationship
    where breast cancer is a cause, and the mammogram test results are the evidence.
    When we see a positive test result, it doesn’t mean this patient has cancer for
    sure because no test is 100% accurate. However, we can deduct the probability
    of this patient having breast cancer based on the test quality, which is defined
    as the sensitivity of the test **P(test| disease)**. The test sensitivity is actually
    the forward probability, which is applicable to the general population.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, individual-specific information can also improve our estimation
    of the inverse probability for each patient. For example, if this patient is from
    a family with several family members diagnosed with breast cancer, then a positive
    test result will be more trustworthy than a patient without family cancer history.
    This patient-specific information is added as a prior in the final formula that
    indicates how to update prior (the probability of having breast cancer) given
    the evidence (observing a positive test result):'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，个体特定的信息也可以改善我们对每个患者的逆概率估计。例如，如果这位患者来自一个有多个家庭成员被诊断为乳腺癌的家庭，那么阳性测试结果将比没有家族癌症史的患者更可信。这些患者特定的信息作为先验被添加到最终公式中，该公式指示如何根据证据（观察到的阳性测试结果）更新先验（患乳腺癌的概率）：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In mathematical terms, it is:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学术语中，它是：
- en: '![](../Images/d4112d3febadef0bee18db6526f7f6ae.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d4112d3febadef0bee18db6526f7f6ae.png)'
- en: 'Using both conditional probability and likelihood ratios, we can update beliefs
    in both directions. If we have new information from the cause, we can update our
    belief in evidence through conditional probability:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用条件概率和似然比，我们可以在两个方向上更新信念。如果我们从原因处获得新的信息，我们可以通过条件概率来更新对证据的信念：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: P(T| D) changes because of the changes in P(D). If we have new information from
    the evidence, conditional probability is not correct since testing positive does
    not make you have breast cancer. causal relationship is reversed. However, we
    could use the **likelihood ratio** of the evidence to update our belief.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: P(T| D)的变化是由于P(D)的变化。如果我们从证据中获得新的信息，条件概率是不正确的，因为测试结果为阳性并不意味着你有乳腺癌。因果关系被逆转。然而，我们可以使用**似然比**来更新我们的信念。
- en: So far, we have only discussed two causally connected variables, but this rule
    can be applied across a whole causal network, with the parent node indicating
    the cause and the child node showing the evidence. The child node will update
    its belief by applying conditional probability, and the parent node update its
    beliefs by multiplying the likelihood ratios. Applying these two rules in the
    whole network is called ***belief propagation***. With these rules, we go beyond
    Bayes’ rule to understand both how a cause affects the generation of evidence
    and how observing evidence helps us deduce causes.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只讨论了两个因果相关的变量，但这个规则可以应用于整个因果网络，其中父节点表示原因，子节点表示证据。子节点通过应用条件概率来更新其信念，而父节点通过乘以似然比来更新其信念。在整个网络中应用这两个规则称为***信念传播***。通过这些规则，我们超越了贝叶斯规则，理解了原因如何影响证据的生成，以及观察证据如何帮助我们推断原因。
- en: Confounders, the Achilles’ heel in nonexperimental studies
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混淆因素，非实验研究中的阿喀琉斯之踵
- en: Belief propagation helps us understand the interactions among variables if we
    can identify the causal relationship correctly. In the real world, going beyond
    two variables, we will need to expand the causal relationship to a causal diagram
    to derive causal impact systematically. But before we move toward the causal diagram,
    which is the core of this book, let’s briefly discuss what has been preventing
    us from deriving causality from observational data, which are called confounders.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 信念传播帮助我们理解变量之间的相互作用，前提是我们能够正确识别因果关系。在现实世界中，超越两个变量，我们需要将因果关系扩展到因果图，以系统地推导因果影响。但在我们进入因果图（本书的核心内容）之前，让我们简要讨论一下是什么阻碍了我们从观察数据中推导因果关系，这些被称为混淆因素。
- en: “Confounding” means “mixing” in English. It is the variable that is correlated
    with both X and Y. Note the correlation could be both causal and non-causal. Moreover,
    in the graph below, I didn’t specify arrows between X&Z and Y&Z since, in the
    causal case, X, Y, and Z can all be either the cause or the result, establishing
    different causal diagrams that we will discuss in the next section. The left panel
    shows how having a confounder Z introduces a spurious correlation between X and
    Y.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: “Confounding”在英语中意为“混淆”。它是与X和Y都有相关性的变量。请注意，这种相关性可能是因果的，也可能是非因果的。此外，在下图中，我没有指定X&Z和Y&Z之间的箭头，因为在因果情况下，X、Y和Z都可以是原因或结果，从而建立不同的因果图，这将在下一节中讨论。左侧面板显示了引入混淆变量Z如何在X和Y之间产生虚假的相关性。
- en: '![](../Images/c7f05f86f9428c92722b1f771a9331a0.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c7f05f86f9428c92722b1f771a9331a0.png)'
- en: Image by author
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: In the right panel, if there is a causal relationship between X and Y, a confounder
    Z that affects both the cause X and the result Y will introduce confounding bias
    if not treating probably. We will not be able to disentangle the true causal effect
    of X on Y if we do not exclude the impact induced by confounders.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: In experimental studies, the randomness in assigning subjects to treatment and
    control groups would resolve the confounder bias from the source (more to this
    in the last section). However, conducting experiments to study the causal effects
    is not always practical and ethical, in which cases, we will have no choice but
    to try deriving the true cause impact from observational data. Unlike experimental
    data, confounders exist in observational data because there are always factors
    that affect both the cause and the result.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, to study whether smoking causes lung cancer, one of the confounders
    is age. Different age groups have very different smoking rates, and the older,
    the higher chance of getting lung cancer. We will have to control age, and other
    confounders before getting the true causal impact. The common method statisticians
    and social scientists use to combat confounder bias is to “control” as many confounders
    as possible in their models. There are several issues with this method:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '**Not all confounders are measurable:** Intuitively, we can figure out what
    might be confounders in a causal relationship we are interested in. However, it
    is not always possible to quantify these variables or find a suitable proxy to
    include them in the model. For example, when studying whether higher education
    causes higher income, one of the confounders can be “ambition.” Ambitious people
    will be more likely to be motivated to get higher education and higher-paying
    jobs, but how can we quantify this subjective variable in observational studies?'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Omitted variables:** No matter how many variables we try to include in the
    studies, it is still very likely we do not include all the necessary and correct
    confounders or their proxies in our models, thus making the causal impact biased.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Control confounders induce biases:** On the other hand, in practice, statisticians
    who, in order to make sure there are no confounders left behind, will include
    as many variables as possible in the model to ensure a debiased estimation. However,
    this ***overcontrolling*** can actually cause biases instead. As written by a
    political blogger named [Ezra Klein](https://www.vox.com/2014/12/1/7311417/race-law-controls):'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “You see it all the time in studies. ‘We controlled for…’ And then the list
    starts. The longer the better, Income. Age. Race. Religion. Height. Hair color.
    Sexual preference. Crossfit attendance. Love of parents. Coke or Pepsi. The more
    things you can control for, the stronger your study is — — or, at least, the stronger
    your study seems. Controls give the feeling of specificity, of precision…. But
    sometimes, you can control for too much. Sometimes you end up controlling for
    the thing you are trying to measure.”
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Ultimately, when solving confounders bias, we face so many issues because it
    is a Rung 2 question that requires us to study causal relationships among variables.
    Thus, a Rung 1 solution that does not involve causal structures like drawing a
    causal diagram will not be enough. In the next section, we will see how utilizing
    causal diagrams can help us define confounders and control confounders in a systematic
    and trustworthy way.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Establish causal diagrams, the keyholes to causality
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Three Basic Structures
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To understand what is a causal diagram, we can start with the fundamental building
    blocks for all networks. There are three basic types of junctions that characterize
    any pattern of arrows in the network:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f8ae1e7ad86bb9784767d85efda9adee.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
- en: Table by author
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: The three basic types exist both in the Bayesian network and causal diagram.
    Applying Bayes’s rule across variables constructs a **Bayesian network**, which
    is nothing more than a compact representation of a huge probability table. If
    we see the chain structure A -> B -> C in a Bayesian network, the missing arrow
    between A and C means A and C are independent once we know the value of B. If
    the same chain structure is observed in a causal diagram, in addition to the same
    independence we will observe between A and C if we control B, we are also adding
    the causality flow through the arrow. This structure shows C is caused by B, B
    is caused by A, and A is external. If we change the structure to C -> B -> A,
    or to the fork structure A <- B -> C, we will see the exact same independence
    between A and C, holding B constant, but the causal structure has changed drastically.
    In other words, data can’t tell us everything. No matter how large the data, we
    cannot distinguish **A -> B -> C**, **C -> B -> A**, and **A <- B -> C** without
    adding subjective causal assumptions.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, moving from the Bayesian network to a causal diagram, we are also
    transforming the Rung 1 probability thinking to Rung 2 and Rung 3 causal thinking.
    Instead of using the probabilistic expression “once we know the value of B,” we
    can instead say “once we hold B constant,” the same as moving from “seeing B’”
    to “intervening B.” In the later section, we will see this difference comes from
    the **P(Y|X)** and **P(Y| *do*(X))**. Bayesian networks can only tell us how likely
    one event is, given that we observe another event. However, causal diagrams can
    answer interventional and counterfactual questions.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: The back-door criterion
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Causal diagrams not only transform us into causal thinking but also equips us
    with a trustworthy tool to find and verify causal effect among observational data.
    As mentioned in the previous chapter, identifying the right confounders is the
    main challenge. To solve this issue, Pearl introduces the ***do-operator*** and
    the ***back-door criterion***.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a869ae073c902440dfc71bf3fef7de66.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
- en: Photo by [Dima Pechurin](https://unsplash.com/@pechka?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: The key is to figure out the causal diagrams, and the do-operator erases all
    the arrows that come into X, thus preventing any information about X from flowing
    in the noncausal direction. While P(Y| X) shows the causal effect with confounding
    bias, the probability P(Y| *do*(X)) shows the true causal impact. It means holding
    other confounders constant by blocking their information flows, how will Y change
    if I change X? Based on different causal structures, we need to control or not
    control different variables to block information flows.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5e6b1fee4f804e3635ede20077ee2495.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
- en: Table by author
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to get P(Y| *do*(X)), we need to ensure the information flow from
    X to Y only comes directly from X to Y. In order to achieve this goal, we need
    to block every noncausal path between X and Y without perturbing any causal paths.
    These noncausal paths are called the back-door path to X, which is any path from
    X to Y that starts with an arrow pointing into X. It is easier to understand this
    concept with the five following examples:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ad795670aa9534a799f3b76ae9cec5e8.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
- en: Table by author, typo in Game2, if you control D, then we can control A **or
    D** to block the path.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: 'By specifying the causal diagrams, we have transformed the process of controlling
    as many confounders as possible into identifying the backdoor paths and figuring
    out how to block them efficiently. As mentioned in the notes, it is not always
    the case to control as many variables as possible to ensure a true causal effect.
    In fact, controlling the wrong variables can:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: Reduce or block the causal path between X and Y. For example, in Game 1, we
    will block the causal path between X and Y if we control for A, and partially
    block it if we control for B, the descendant of A.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduce collider bias for X and Y. For example, in Game 4, controlling B will
    make X and Y dependent when there is no causal relationship. Game 4 is also called
    the “M bias” because of it’s shape.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Control the right confounder, not as many as possible. For example, in Game
    5, we can choose to control B and A in the same time, or just control C to achieve
    the same result.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of the diagrams can be found with real world examples. For instance, in
    Game 1 represents a medical application that estimate the effect of smoking (X)
    on misscarriages (Y). A is an underlying abnormality that is induced by smoking,
    which is unobservable since we don’t know which specific abnormality is induced
    through smoking. B is a history of previous miscarriages. It is very tempting
    to include miscarriage history into the model, but from the causal diagram, we
    can see if we do that, it will partial inactivating the mechanism through which
    smoking contributes to miscarriages, thus underestimate the true causal impact.
    There are a lot more real world applications in these two chapters in Pearl’s
    book. Even though the causal diagram can get too complicated to have the human
    brains figuring out the backdoor paths, don’t forget we will always have computer
    algorithms that are experts in cracking these types of problems.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 每一个图示都可以在现实世界的例子中找到。例如，在游戏1中表示一个医学应用，估计吸烟（X）对流产（Y）的影响。A 是由吸烟引起的潜在异常，因为我们不知道具体是什么异常被吸烟引起，所以它是不可观察的。B
    是之前流产的历史。将流产历史包含到模型中是非常诱人的，但从因果图中可以看出，如果这样做，会部分失效吸烟对流产的机制，从而低估真正的因果影响。Pearl 的书中的这两章还有更多现实世界的应用。即使因果图可能变得过于复杂，使人脑无法找到后门路径，不要忘记我们总是可以依靠计算机算法来破解这些类型的问题。
- en: Why do randomized controlled trials(RCT) work?
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么随机对照试验（RCT）有效？
- en: 'We have enough discussion using causal diagrams for the non-experimental studies.
    How can we use the causal diagram and the backdoor criterior to explain why RCT
    works for deriving unbiased causal impact? Let’s see an example where we try to
    figure out how does different fertillizer affect soil yield. In real world, farmer
    decide which fertilizer to use based on a lot of factors, like soil fertility,
    texture, which also affect yield. We can show it in a causal diagram:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经使用因果图讨论了足够的非实验性研究。我们如何使用因果图和后门准则来解释为什么 RCT 能够得出无偏的因果影响？让我们看看一个例子，尝试找出不同肥料如何影响土壤产量。在现实世界中，农民根据许多因素决定使用哪种肥料，比如土壤肥力、土壤纹理，这些因素也会影响产量。我们可以在因果图中展示：
- en: '![](../Images/e1063ff03440b02ff41214a31383fe96.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e1063ff03440b02ff41214a31383fe96.png)'
- en: Image by author
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'All the orange lines shows the confounding relationships that bias the causal
    impact from fertilizer to yield. To fix that, we will need to control all these
    confounders in the model. Note it may not be possible because the “Other” factor
    here can be hard to name and quantify. However, if now we design a experiment
    that will decide which feritlizer to use for each plot purely on drawing random
    cards. Now the causal diagram becomes something like this:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的橙色线条展示了偏倚肥料对产量因果影响的混杂关系。为了解决这个问题，我们需要在模型中控制所有这些混杂因素。请注意，这可能不太可能，因为这里的“其他”因素可能很难命名和量化。然而，如果现在我们设计一个实验，仅通过抽取随机卡片来决定每块土地使用哪种肥料。现在因果图变成了这样的：
- en: '![](../Images/cb03de7bfaf18459d7fc0c3545609359.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cb03de7bfaf18459d7fc0c3545609359.png)'
- en: Image by author
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: By adding the random card to the diagram, we can remove all the confounding
    orange lines from the previous diagram because which fertilizer we use doesn’t
    depend on any of these variables anymore. It is purely a randomized decision only
    affected by the random card draw. The backdoor critierion has met to estimate
    the causal impact of fertilizer and yield.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在图示中添加随机卡片，我们可以去除之前图示中的所有混杂橙色线条，因为我们使用哪种肥料不再依赖于这些变量。它纯粹是一个仅受随机卡片抽取影响的随机决策。后门准则已经满足了用来估计肥料和产量的因果影响。
- en: 'That’s all I want to share from Chapter 3 and 4 of “The Book of Why” by Judea
    Pearl, which completes the third article in this “Read with Me” series. I hope
    this article is helpful to you. If you haven’t read the first two articles, check
    them out here:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我想分享的关于 Judea Pearl 的《为什么书》第三章和第四章的内容，这也完成了本系列“与我一起阅读”的第三篇文章。希望这篇文章对你有帮助。如果你还没阅读前两篇文章，可以在这里查看：
- en: '[](/read-with-me-a-causality-book-club-edd7085d6ae6?source=post_page-----a69cdb1c4818--------------------------------)
    [## Read with Me: A Causality Book Club'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/read-with-me-a-causality-book-club-edd7085d6ae6?source=post_page-----a69cdb1c4818--------------------------------)
    [## 与我一起阅读：因果关系书籍俱乐部'
- en: Starting from a cat story…
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从一个猫的故事开始……
- en: towardsdatascience.com](/read-with-me-a-causality-book-club-edd7085d6ae6?source=post_page-----a69cdb1c4818--------------------------------)
    [](/data-tells-us-what-and-we-always-seek-for-why-66da7dc3f24d?source=post_page-----a69cdb1c4818--------------------------------)
    [## Data Tells Us “What” and We Always Seek for “Why”
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: “The Book of Why” Chapters 1&2, a Read with Me series
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/data-tells-us-what-and-we-always-seek-for-why-66da7dc3f24d?source=post_page-----a69cdb1c4818--------------------------------)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are interested, [subscribe to my email list](https://zzhu17.medium.com/subscribe)
    to join the biweekly discussions that will become more and more technical:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '[**Chapter5&6:Why Understanding the Data-Generation Process Is More Important
    Than the Data Itself**](https://medium.com/towards-data-science/why-understanding-the-data-generation-process-is-more-important-than-the-data-itself-f1b3b847e662)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Chapter7&8 You Can’t Step in the Same River Twice**](https://medium.com/towards-data-science/you-cant-step-in-the-same-river-twice-cfacf7cee305)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Chapter9&10 What Makes A Strong AI**](https://medium.com/towards-data-science/what-makes-a-strong-ai-012315722793)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Bonus: How is Causal Inference Difference in Academia and Industry?**](/how-is-causal-inference-different-in-academia-and-industry-fb5afd12e2e7)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are much more details and example that Pearl has shown in the book. As
    always, I highly encourage you to read, think and share what’s your main takeaways
    either here or at your [own blog post](https://youtu.be/oFDl0-SKAL8?si=r1QiRIizhDBdvX-A).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: 'Thanks for reading. If you like this article, don’t forget to:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '***Check my recent articles about*** [***the 4Ds in data storytelling: making
    art out of science***](https://medium.com/towards-data-science/the-4ds-in-data-storytelling-making-art-out-of-science-c4998ed7875e);[***continuous
    learning in data science***](/continuous-learning-a-data-scientists-odyssey-8d3006c2ce01)***;***
    [***how I become a data scientist***](/how-i-became-a-data-scientist-7f5b10606612)***;***'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***Check my*** [***other articles***](https://zzhu17.medium.com/my-blog-posts-gallery-ac6e01fe5cc3)
    ***on different topics like*** [***data science interview preparation***](https://zzhu17.medium.com/list/data-science-interview-preparation-bfb0986a61a3)***;***
    [***causal inference***](/causal-inference-what-why-and-how-d7336b0081ec)***;***'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[***Subscribe***](https://zzhu17.medium.com/subscribe) ***to my email list;***'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[***Sign up for medium membership***](https://zzhu17.medium.com/membership)***;***'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***Or follow me on*** [***YouTube***](https://youtube.com/channel/UCMs6go1pvY5OOy1DXVtMo5A)
    ***and watch my most recent YouTube video about other books I read:***'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reference
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[***The Book of Why***](https://www.amazon.com/Book-Why-Science-Cause-Effect/dp/046509760X)
    ***by Judea Pearl***'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
