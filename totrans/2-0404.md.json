["```py\n# CONNECTING TO S3 BUCKET\nimport os\nimport io\nimport boto3\nimport awswrangler as wr\nimport pandas as pd\n\nboto3.setup_default_session(aws_access_key_id = 'your_access_key',\n                            aws_secret_access_key = 'your_secret_access_key')\n\nbucket = 'coding-tutorials'\n```", "```py\nprint('--BOTO3--') \n# BOTO3 - Preferred Method\nclient = boto3.client('s3')\n\nfor obj in client.list_objects(Bucket=bucket)['Contents']:\n    print('File Name:', obj['Key'], 'Size:', round(obj['Size']/ (1024*1024), 2), 'MB')\n\nprint('----') \n# BOTO3 - Alternative Method\nresource = boto3.resource('s3')\n\nfor obj in resource.Bucket(bucket).objects.all():\n    print('File Name:', obj.key, 'Size:', round(obj.size/ (1024*1024), 2), 'MB')\n```", "```py\nprint('--AWS_WRANGLER--') \n# AWS WRANGLER\n\nfor obj in wr.s3.list_objects(\"s3://coding-tutorials/\"):\n    print('File Name:', obj.replace('s3://coding-tutorials/', ''))\n\nprint('----') \nfor obj, size in wr.s3.size_objects(\"s3://coding-tutorials/\").items():\n    print('File Name:', obj.replace('s3://coding-tutorials/', '') , 'Size:', round(size/ (1024*1024), 2), 'MB')\n```", "```py\nobject_key = 'account_balances_jan2023.parquet'\n\n# BOTO3\nprint('--BOTO3--') \nclient = boto3.client('s3')\ntry:\n    client.head_object(Bucket=bucket, Key = object_key)\n    print(f\"The object exists in the bucket {bucket}.\")\nexcept client.exceptions.NoSuchKey:\n    print(f\"The object does not exist in the bucket {bucket}.\")\n```", "```py\n# AWS WRANGLER\nprint('--AWS_WRANGLER--') \ntry:\n    wr.s3.does_object_exist(f's3://{bucket}/{object_key}')\n    print(f\"The object exists in the bucket {bucket}.\")\nexcept:\n    print(f\"The object does not exist in the bucket {bucket}.\")\n```", "```py\nobject_key = 'account_balances_jan2023.parquet'\n\n# BOTO3\nclient = boto3.client('s3')\nclient.download_file(bucket, object_key, 'tmp/account_balances_jan2023_v2.parquet')\n\n# AWS WRANGLER\nwr.s3.download(path=f's3://{bucket}/{object_key}', local_file='tmp/account_balances_jan2023_v3.parquet')\n```", "```py\nobject_key_1 = 'account_balances_apr2023.parquet'\nobject_key_2 = 'account_balances_may2023.parquet'\n\nfile_path_1 = os.path.dirname(os.path.realpath(object_key_1)) + '/' + object_key_1\nfile_path_2 = os.path.dirname(os.path.realpath(object_key_2)) + '/' + object_key_2\n\n# BOTO3\nclient = boto3.client('s3')\nclient.upload_file(file_path_1, bucket, object_key_1)\n\n# AWS WRANGLER\nwr.s3.upload(local_file=file_path_2, path=f's3://{bucket}/{object_key_2}')\n```", "```py\n#SINGLE OBJECT\nobject_key = ‘account_balances_jan2023.parquet’\n\n#MULTIPLE OBJECTS\nobject_keys = [‘account_balances_jan2023.parquet’, \n               ‘account_balances_feb2023.parquet’, \n               ‘account_balances_mar2023.parquet’]\n```", "```py\n# BOTO3\nprint('--BOTO3--')\nclient = boto3.client('s3')\n\n# Delete Single object\nresponse = client.delete_object(Bucket=bucket, Key=object_key)\ndeletion_date = response['ResponseMetadata']['HTTPHeaders']['date']\n\nif response['ResponseMetadata']['HTTPStatusCode'] == 204:\n    print(f'Object {object_key} deleted successfully on {deletion_date}.')\nelse:\n    print(f'Object could not be deleted.')\n\n# Delete Multiple Objects\nobjects = [{'Key': key} for key in object_keys]\n\nresponse = client.delete_objects(Bucket=bucket, Delete={'Objects': objects})\ndeletion_date = response['ResponseMetadata']['HTTPHeaders']['date']\n\nif len(object_keys) == len(response['Deleted']):\n    print(f'All objects were deleted successfully on {deletion_date}')\nelse:\n    print(f'Object could not be deleted.')\n```", "```py\n# AWS WRANGLER\nprint('--AWS_WRANGLER--')\n# Delete Single object\nwr.s3.delete_objects(path=f's3://{bucket}/{object_key}')\n\n# Delete Multiple Objects\ntry:\n    wr.s3.delete_objects(path=[f's3://{bucket}/{key}' for key in object_keys])\n    print('All objects deleted successfully.')\nexcept:\n    print(f'Objects could not be deleted.')\n```", "```py\nobject_key_1 = 'account_balances_june2023.parquet'\n\n# RUN THE GENERATOR.PY SCRIPT\n\ndf.to_parquet(object_key_1)\n\n# BOTO3\nclient = boto3.client('s3')\n\n# Upload the Parquet file to S3\nwith open(object_key_1, 'rb') as file:\n    client.upload_fileobj(file, bucket, object_key_1)\n```", "```py\nobject_key_2 = 'account_balances_july2023.parquet'\n\n# AWS WRANGLER   \nwr.s3.to_parquet(df=df, \n                 path=f's3://{bucket}/{object_key_2}', \n                 compression = 'gzip', \n                 partition_cols = ['COMPANY_CODE'], \n                 dataset=True)\n```", "```py\nobject_key = 'account_balances_may2023.parquet'\n\n# BOTO3\nclient = boto3.client('s3')\n\n# Read the Parquet file\nresponse = client.get_object(Bucket=bucket, Key=object_key)\nparquet_object = response['Body'].read()\n\ndf = pd.read_parquet(io.BytesIO(parquet_object))\ndf.head()\n```", "```py\n# AWS WRANGLER\ndf = wr.s3.read_parquet(path=f's3://{bucket}/{object_key}')\ndf.head()\n\n# wr.s3.read_csv()\n# wr.s3.read_json()\n# wr.s3.read_parquet_table()\n# wr.s3.read_deltalake()\n```", "```py\nobject_key = 'account_balances_may2023.parquet'\nquery = \"\"\"SELECT * FROM s3object s \n           WHERE AS_OF_DATE > CAST('2023-05-13T' AS TIMESTAMP)\"\"\"\n```", "```py\n# BOTO3\nclient = boto3.client('s3')\n\nresp = client.select_object_content(\n        Bucket=bucket,\n        Key=object_key,\n        Expression= query,\n        ExpressionType='SQL',\n        InputSerialization={\"Parquet\": {}},\n        OutputSerialization={'JSON': {}},\n)\n\nrecords = []\n\n# Process the response\nfor event in resp['Payload']:\n    if 'Records' in event:\n        records.append(event['Records']['Payload'].decode('utf-8'))\n\n# Concatenate the JSON records into a single string\njson_string = ''.join(records)\n\n# Load the JSON data into a Pandas DataFrame\ndf = pd.read_json(json_string, lines=True)\n\n# Print the DataFrame\ndf.head() \n```", "```py\n# AWS WRANGLER\ndf = wr.s3.select_query(\n        sql=query,\n        path=f's3://{bucket}/{object_key}',\n        input_serialization=\"Parquet\",\n        input_serialization_params={}\n)\ndf.head()\n```"]