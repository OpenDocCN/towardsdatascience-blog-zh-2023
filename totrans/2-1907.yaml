- en: How I Achieved Top 10% in Europe’s Largest Machine Learning Competition with
    Stacked Ensembles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/stacked-ensembles-for-advanced-predictive-modeling-with-h2o-ai-and-optuna-8c339f8fb602](https://towardsdatascience.com/stacked-ensembles-for-advanced-predictive-modeling-with-h2o-ai-and-optuna-8c339f8fb602)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A conceptual and hands-on coding guide to training Stacked Ensembles with H2O.ai
    and Optuna
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@sheilateozy?source=post_page-----8c339f8fb602--------------------------------)[![Sheila
    Teo](../Images/de3e697ba84d4896bdd869a9367049f4.png)](https://medium.com/@sheilateozy?source=post_page-----8c339f8fb602--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8c339f8fb602--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8c339f8fb602--------------------------------)
    [Sheila Teo](https://medium.com/@sheilateozy?source=post_page-----8c339f8fb602--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8c339f8fb602--------------------------------)
    ·13 min read·Dec 18, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4aa1fd2dabd2834494a342ca18c09ddd.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by DALL·E 3
  prefs: []
  type: TYPE_NORMAL
- en: We all know that ensemble models outperform any singular model at predictive
    modeling. You’ve probably heard all about Bagging and Boosting as common ensemble
    methods, with Random Forests and Gradient Boosting Machines as respective examples.
  prefs: []
  type: TYPE_NORMAL
- en: But what about ensembling different models together under a separate higher-level
    model? This is where stacked ensembles comes in. **This article is step-by-step
    guide on how to train stacked ensembles using the popular machine learning library,
    H2O.**
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate the power of stacked ensembles, I will provide a walk-through
    of my full code for training a stacked ensemble of 40 Deep Neural Network, XGBoost
    and LightGBM models for the prediction task posed in the 2023 Cloudflight Coding
    Competition (AI Category), one of the largest coding competitions in Europe, where
    I placed top 10% on the competition leaderboard within a training time of 1 hour!
  prefs: []
  type: TYPE_NORMAL
- en: '**This guide will cover:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[**What are stacked ensembles and how do they work?**](#97e3)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[**How to train stacked ensembles with H2O.ai**](#ee48) **—'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With a full code walk-through in Python**
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[**Comparing the performance of a stacked ensemble versus standalone models**](#f414)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 1\. What are Stacked Ensembles and how do they work?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A stacked ensemble combines predictions from multiple models through another,
    higher-level model, with the aim being to increase overall predictive performance
    by capitalizing on the unique strengths of each constituent model. It involves
    2 stages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Stage 1: Multiple Base Models**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, multiple base models are independently trained on the same training dataset.
    These models should ideally be diverse, ranging from simple linear regressions
    to complex deep learning models. The key is that they should differ from each
    other in some way, either in terms of using a different algorithm or using the
    same algorithm but with different hyperparameter settings.
  prefs: []
  type: TYPE_NORMAL
- en: '**The more diverse the base models are, the more powerful the eventual stacked
    ensemble.** This is because different models are able to capture different patterns
    in the data. For example, a tree-based model might be good at capturing non-linear
    relationships, while a linear model excels at understanding linear trends. When
    these diverse base models are combined, the stacked ensemble can then leverage
    the different strengths of each base model, increasing predictive performance.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Stage 2: One Meta-Model'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After all the base models are trained, each base model’s predictions for the
    target is used as a feature for training a higher-level model, termed a meta-model.
    This means that the meta-model is not trained on the original dataset’s features,
    but instead on the predictions of the base models. If there are `n` base models,
    there are `n` predictions generated, and these are the `n` features used for training
    the meta-model.
  prefs: []
  type: TYPE_NORMAL
- en: While the training features differ between the base models and the meta-model,
    the target however stays the same, which is the original target from the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The meta-model learns how to best combine the predictions from the base models
    to make a final, more accurate prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Detailed Steps for Training a Stacked Ensemble
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**For each base model:**'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Pick an algorithm (eg. Random Forest).
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Use cross-validation to obtain the best set of hyperparameters for the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Obtain cross-validation predictions for the target in the training set.
    These will be used to train the meta-model subsequently.
  prefs: []
  type: TYPE_NORMAL
- en: '*To illustrate this, say a Random Forest algorithm was chosen in Step 1, and
    its optimal hyperparameters were determined as* `*h*` *in Step 2.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*The cross-validation predictions are obtained through the following, assuming
    5-fold cross-validation:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 1\. Train a Random Forest with hyperparamters* `*h*` *on Folds 1–4.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 2\. Used the trained Random Forest to make predictions for Fold 5\. These are
    the cross-validation predictions for Fold 5.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 3\. Repeat the above to obtain cross-validation predictions for each fold. After
    which, cross-validation predictions for the target will be obtained for the entire
    training set.*
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**For the meta-model:**'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Obtain the features for training the meta-model. These are the predictions
    of each of the base models.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Obtain the target for training the meta-model. This is the original target
    from the training set.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Pick an algorithm (eg. Linear Regression).
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Use cross-validation to obtain the best set of hyperparameters for the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'And voila! You now have:'
  prefs: []
  type: TYPE_NORMAL
- en: '- Multiple base models that are trained with optimal hyperparameters'
  prefs: []
  type: TYPE_NORMAL
- en: '- One meta-model that is also trained with optimal hyperparameters'
  prefs: []
  type: TYPE_NORMAL
- en: Which means you have successfully trained a stacked ensemble!
  prefs: []
  type: TYPE_NORMAL
- en: 2\. How to Train Stacked Ensembles with H2O.ai
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, let’s jump into coding it out!
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned, this section covers my full code for training a stacked ensemble
    for the prediction task posed in the 2023 Cloudflight Coding Competition (AI Category),
    which is a regression task using tabular data. Within the competition’s time constraints,
    I created a stacked ensemble from 40 base models of 3 algorithm types — Deep Neural
    Network, XGBoost, and LightGBM, with these specific algorithms chosen as they
    often achieve superior performance in practice.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1\. Data Preparation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, let’s import the necessary libraries.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: And initialize the H2O cluster.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Next, load in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Before moving on to model building using H2O, let’s first understand the following
    traits of H2O models:'
  prefs: []
  type: TYPE_NORMAL
- en: H2O models cannot take in Pandas DataFrame objects, so `data` must be converted
    from a Pandas DataFrame to its H2O equivalent, which is a H2OFrame.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: H2O models can encode categorical features automatically, which is great as
    it takes this preprocessing step out of our hands. To ensure that such features
    are understood by the models to be categorical, they must be explicitly converted
    into the factor (categorical) data type.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Now we can proceed to split our dataset into train (90%) and validation (10%)
    sets, using the `split_frame()` method of H2OFrame objects.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Lastly, let’s obtain the features and target for modelling. Unlike Scikit-Learn
    models which take as input the *values* of the features and the target, H2O models
    take as input the *names* of the features and the target.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Now, let the model training fun begin!
  prefs: []
  type: TYPE_NORMAL
- en: 2.2\. Training Deep Neural Networks (DNN) as Base Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s start by training the DNNs that will form our set of base models for the
    stacked ensemble, using H2O’s `H2ODeepLearningEstimator`.
  prefs: []
  type: TYPE_NORMAL
- en: '**Aside: Why train DNNs in H2O, instead of Tensorflow, Keras, or PyTorch?**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Before jumping into the code for this, you might be wondering why I chose
    to train DNNs using H2O’s* `*H2ODeepLearningEstimator*`*, as opposed to using
    Tensorflow, Keras, or PyTorch, which are the common libraries used to build DNNs.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*The straightforward answer is that building a stacked ensemble in H2O uses
    the* `*H2OStackedEnsembleEstimator*`*, which can only accept base models that
    are part of the H2O model family. However, the more critical reason is that H2O’s*
    `*H2ODeepLearningEstimator*` *enables far easier tuning of DNNs than these other
    frameworks, and here’s why.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*In TensorFlow, Keras, or PyTorch, regularization effects like dropout layers
    must be manually added into the model architecture, such as using* `*keras.layers.Dropout()*`*.
    This allows for greater customization, but also requires more detailed knowledge
    and effort. For example, you have to decide where and how many times to include
    the* `*keras.layers.Dropout()*` *layer within your model architecture.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*On the other hand, H2O''s* `*H2ODeepLearningEstimator*` *is more abstracted
    and accessible to the layman. Regularization can be enabled in a straightforward
    manner through model hyperparameters, reducing the need for manual setup of these
    components as layers. Furthermore, the* default *model hyperparameters already
    includes regularization. The common feature preprocessing steps, such as scaling
    of numerical features and encoding of categorical features, are also included
    as model hyperparameters for automatic feature preprocessing. These enable the
    tuning of DNNs to be a far more straightforward and easy process, without having
    to dive into the complexities of deep learning model architecture. In the context
    of a time crunch in the competition, this was extremely useful for me!*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: But which set of hyperparameters should we train `H2ODeepLearningEstimator`
    with? This is where *optuna* comes in. *Optuna* is a hyperparameter optimization
    framework, similar to the traditional grid search and random search approaches,
    but better in that it employs a more sophisticated approach.
  prefs: []
  type: TYPE_NORMAL
- en: Grid search systematically explores a predefined range of hyperparameter values,
    while random search selects random combinations within these specified limits.
    However, *optuna* uses Bayesian optimization to learn from previous searches to
    propose better-performing hyperparameter sets in each subsequent search, increasing
    the efficiency of its search for the optimal model hyperparameters. This is especially
    effective in complex and large hyperparameter spaces where traditional search
    methods can be prohibitively time-consuming and may eventually still fail to locate
    the optimal set of hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s get into the code. We’ll use *optuna* to tune the hyperparameters
    of H2O’s `H2ODeepLearningEstimator`, and keep track of all the trained models
    inside the list `dnn_models`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Above, an *optuna* study is created to search for the best set of `H2ODeepLearningEstimator`
    hyperparameters that minimizes the cross-validation RMSE (as this is a regression
    task), with the optimization process running for 20 trials using the parameter
    `n_trials=20`. This means that 20 DNNs are trained and stored in the list `dnn_models`
    for usage as base models for the stacked ensemble later on, each with a different
    set of hyperparameters. In the interest of time under the competition’s time constraints,
    I chose to train 20 DNNs, but you can set `n_trials` to be however many DNNs you
    wish to train for your stacked ensemble.
  prefs: []
  type: TYPE_NORMAL
- en: Importantly, the `H2ODeepLearningEstimator` must be trained with `keep_cross_validation_predictions=True`,
    as these cross-validation predictions will be used as features for training the
    meta-model later.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3\. Training XGBoost and LightGBM as Base Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next, let’s train the XGBoost and LightGBM models that will also form our set
    of base models for the stacked ensemble. We’ll again use *optuna* to tune the
    hyperparameters of H2O’s `H2OXGBoostEstimator`, and keep track of all the trained
    models inside the list `xgboost_lightgbm_models`.
  prefs: []
  type: TYPE_NORMAL
- en: Before diving into the code for this, we must first understand that `H2OXGBoostEstimator`
    is the integration of the XGBoost framework from the popular *xgboost* library
    into H2O. On the other hand, H2O does not integrate the *lightgbm* library. However,
    it does provide a method for emulating the LightGBM framework using a certain
    set of parameters within `H2OXGBoostEstimator`- and this is exactly what we will
    implement in order to train both XGBoost and LightGBM models using `H2OXGBoostEstimator`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Similarly, 20 XGBoost and LightGBM models are trained and stored in the list
    `xgboost_lightgbm_models` for usage as base models for the stacked ensemble later
    on, each with a different set of hyperparameters. You can set `n_trials` to be
    however many XGBoost/LightGBM models you wish to train for your stacked ensemble.
  prefs: []
  type: TYPE_NORMAL
- en: Importantly, the `H2OXGBoostEstimator` must also be trained with `keep_cross_validation_predictions=True`,
    as these cross-validation predictions will be used as features for training the
    meta-model later.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4\. Training the Meta-Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will use *all* of the Deep Neural Network, XGBoost and LightGBM models trained
    above as base models. However, this does not mean that all of them will be used
    in the stacked ensemble, as we will perform automatic base model selection when
    tuning our meta-model (more on this later)!
  prefs: []
  type: TYPE_NORMAL
- en: Recall that we had stored each trained base model inside the lists `dnn_models`
    (20 models) and `xgboost_lightgbm_models` (20 models), giving a total of 40 base
    models for our stacked ensemble. Let’s combine them into a final list of base
    models, `base_models`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we are ready to train the meta-model using these base models. But first,
    we have to decide on the meta-model algorithm, where a few concepts come into
    play:'
  prefs: []
  type: TYPE_NORMAL
- en: Most academic papers on stacked ensembles recommend choosing a **simple** linear-based
    algorithm for the meta-model. This is to avoid the meta-model overfitting to the
    predictions from the base models.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: H2O recommends the usage of a Generalized Linear Model (GLM) over a Linear Regression
    (for regression tasks) or Logistic Regression (for classification tasks). This
    is because the GLM is a flexible linear model that does not impose the key assumptions
    of normality and homoscedasticity that the latter do, allowing it to model the
    true behavior of the target values better, since such assumptions can be difficult
    to be met in practice. Further explanations on this can be found in [this academic
    thesis](https://github.com/ledell/phd-thesis/blob/main/ledell-phd-thesis.pdf),
    on which H2O’s work was based upon.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As such, we will instantiate the meta-model using `H2OStackedEnsembleEstimator`
    with `metalearner_algorithm='glm'`, and use *optuna* to tune the hyperparameters
    of the GLM meta-model to optimize performance.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the cross-validation predictions of each base model were not explicitly
    passed into `H2OStackedEnsembleEstimator`. This is because H2O does this automatically
    under the hood, making things easier for us! All we had to do was set `keep_cross_validation_predictions=True`
    when training our base models previously, and instantiate `H2OStackedEnsembleEstimator`
    with the parameter `base_models=base_models`.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can finally build the `best_ensemble` model, using the optimal hyperparameters
    found by *optuna*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: And voila, we have successfully trained a stacked ensemble in H2O! Let’s take
    a look at it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/f03397fcef61f99f6cb428a7698d2f5d.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the stacked ensemble uses only 16 out of the 40 base models we passed
    to it, of which 3 are XGBoost/LightGBM and 13 are Deep Neural Networks. This is
    due to the hyperparameter `alpha` that we tuned for the GLM meta-model, which
    represents the distribution of regularization between L1 (LASSO) and L2 (Ridge).
    A value of `1` entails only L1 regularization, while a value of `0` entails only
    L2 regularization.
  prefs: []
  type: TYPE_NORMAL
- en: As reflected above, its optimal value was found to be `alpha=0.16`, thus a mix
    of L1 and L2 was employed. Some of the base models’ predictions had their coefficients
    in the regression set to `0` under L1 regularization, meaning that these base
    models were not used in the stacked ensemble at all, therefore fewer than 40 base
    models ended up being used.
  prefs: []
  type: TYPE_NORMAL
- en: The key takeaway here is that our setup above also performs automatic selection
    of which base models to use for optimal performance, through the meta-model’s
    regularization hyperparameters, instead of simply using all 40 base models provided.
  prefs: []
  type: TYPE_NORMAL
- en: '3\. Comparing Performance: Stacked Ensemble Versus Standalone Base Models'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To demonstrate the power of stacked ensembles, let’s use it to generate predictions
    for the validation set, which was held out from the beginning. The RMSE figures
    below are specific only to the dataset I am using, but feel free to run this article’s
    codes on your own dataset too, and see the difference in model performance for
    yourself!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The stacked ensemble produces an RMSE of 0.31 on the validation set.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s dig into the performance of each of the base models on this same
    validation set.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/853f94aa62127c3dce0a3c3c83c84219.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Compared to the stacked ensemble which achieved an RMSE of 0.31, the best-performing
    standalone base model achieved an RMSE of 0.35.
  prefs: []
  type: TYPE_NORMAL
- en: This means that Stacking was able to improve predictive performance by 11% on
    unseen data!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Now that you’ve witnessed the power of stacked ensembles, it’s your turn to
    try them out!
  prefs: []
  type: TYPE_NORMAL
- en: I had a lot of fun writing this, and if you had fun reading, I would really
    appreciate if you took a second to leave some claps and a follow!
  prefs: []
  type: TYPE_NORMAL
- en: See you in the next one!
  prefs: []
  type: TYPE_NORMAL
- en: Sheila
  prefs: []
  type: TYPE_NORMAL
