["```py\n#Imports\n\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\n#Load the dataset\nX,y = fetch_openml(\"titanic\", version = 1, as_frame=True, return_X_y=True)\n\n#Create the OneHotEncoding for the categorical variable 'sex'\n\ncategorical_feature = [\"sex\"]\ncategorical_transformer = Pipeline(\n    steps = [\n        (\"encoder\",OneHotEncoder(drop=\"first\"))\n    ])\npreprocessor = ColumnTransformer(\n    transformers = [\n        (\"categorical\", categorical_transformer, categorical_feature)\n    ])\n\n#Creating the Pipeline, with preprocessing and the Random Forest Classifier\nclf = Pipeline(\n    steps = [\n        (\"preprocessor\", preprocessor), \n        (\"classifier\", RandomForestClassifier())\n    ]\n)\n\n#Select only age and sex as predictors\nX = X[[\"age\",\"sex\"]]\n\n#Drop rows with missing values\nX = X.dropna()\n\n#Keep only observations corresponding to rows without missing values\ny = y[X.index]\n\n#Create Train/Test Split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n\n#Fit the Pipeline\nclf.fit(X_train, y_train)\n\n#Score the Pipeline\ny_pred = clf.predict(X_test)\nprint(classification_report(y_test, y_pred))\n```", "```py\n precision    recall  f1-score   support\n\n           0       0.85      0.84      0.85       159\n           1       0.76      0.77      0.76       103\n\n    accuracy                           0.81       262\n   macro avg       0.80      0.80      0.80       262\nweighted avg       0.81      0.81      0.81       262\n```", "```py\nfrom pandas import DataFrame\n\n# Create a DataFrame with all possible ages\nages = DataFrame({'age':range(1,80,1)})\n\n# Create a DataFrame with all possible sexes\nsexes = DataFrame({'sex':[\"male\",\"female\"]})    \n\n# Create a DataFrame with all possible combinations. \ncombinations = ages.merge(sexes, how='cross')\n\n# Predict survival for combinations\ncombiations[\"predicted_survival\"] = clf.predict(combinations)\n\n# Plot the Heatmap\nsns.heatmap(pd.pivot_table(results, values=\"predicted_survival\", index=[\"age\"],columns=[\"sex\"]), annot=True)\n```", "```py\nfrom joblib import dump\ndump(clf, \"randomforest.joblib\")\n```", "```py\nSexValues = DATATABLE(\"Sex Values\",String,{{\"male\"},{\"female\"}})\n```", "```py\n# The following code to create a dataframe and remove duplicated rows is always executed and acts as a preamble for your script: \n\n# dataset = pandas.DataFrame(Sex Values, Age Value)\n# dataset = dataset.drop_duplicates()\n\n# Paste or type your script code here:\n\n# Imports\nfrom joblib import load\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nimport pandas as pd\nimport matplotlib.pyplot as plt \n\n# Loading the serialized Pipeline - Make sure to point it to where you serialized the pipeline\nclf = load(r\"\\randomforest.joblib\")\n\n# Rename the dataset with the Parameter names to match the original column names. \ndataset = dataset.rename(columns={\"Age Value\":\"age\", \"Sex Values\":\"sex\"})\n\n# Make the predictions\ndataset[\"PredictedSurvival\"] = clf.predict(dataset)\n\n# Output the predictions\nfig = plt.figure()\nax = fig.add_subplot()\nax.axis([0, 1, 0, 1])\nplt.grid(False)\nplt.axis('off')\nax.text(0, 0.8, \"submitted age: \" + str(dataset.iloc[0,0]), fontsize=25)\nax.text(0, 0.6, \"submitted sex: \" + str(dataset.iloc[0,1]), fontsize=25)\nax.text(0, 0.2, \"predicted survival: \" + str(dataset.iloc[0,2]), fontsize=30)\nplt.show()\n```"]