- en: Bad machine learning models can still be well-calibrated
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸è‰¯çš„æœºå™¨å­¦ä¹ æ¨¡å‹ä»ç„¶å¯ä»¥è¢«è‰¯å¥½æ ¡å‡†
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/bad-machine-learning-models-can-still-be-well-calibrated-7a856346fdf2](https://towardsdatascience.com/bad-machine-learning-models-can-still-be-well-calibrated-7a856346fdf2)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/bad-machine-learning-models-can-still-be-well-calibrated-7a856346fdf2](https://towardsdatascience.com/bad-machine-learning-models-can-still-be-well-calibrated-7a856346fdf2)
- en: Machine Learning
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ 
- en: You donâ€™t need a perfect oracle to get your probabilities right.
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½ ä¸éœ€è¦ä¸€ä¸ªå®Œç¾çš„ç¥è°•æ¥æ­£ç¡®åœ°ç¡®å®šä½ çš„æ¦‚ç‡ã€‚
- en: '[](https://michaloleszak.medium.com/?source=post_page-----7a856346fdf2--------------------------------)[![MichaÅ‚
    Oleszak](../Images/61b32e70cec4ba54612a8ca22e977176.png)](https://michaloleszak.medium.com/?source=post_page-----7a856346fdf2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7a856346fdf2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7a856346fdf2--------------------------------)
    [MichaÅ‚ Oleszak](https://michaloleszak.medium.com/?source=post_page-----7a856346fdf2--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://michaloleszak.medium.com/?source=post_page-----7a856346fdf2--------------------------------)[![MichaÅ‚
    Oleszak](../Images/61b32e70cec4ba54612a8ca22e977176.png)](https://michaloleszak.medium.com/?source=post_page-----7a856346fdf2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7a856346fdf2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7a856346fdf2--------------------------------)
    [MichaÅ‚ Oleszak](https://michaloleszak.medium.com/?source=post_page-----7a856346fdf2--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7a856346fdf2--------------------------------)
    Â·11 min readÂ·Feb 13, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7a856346fdf2--------------------------------)
    Â·11 min readÂ·2023å¹´2æœˆ13æ—¥
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/e7631602da782fdb4e815070633580b0.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e7631602da782fdb4e815070633580b0.png)'
- en: Machine learning models are often evaluated based on their performance, measured
    by how close some metric is to zero or one (depending on the metric) but this
    is not the only factor that determines their usefulness. In some cases, a model
    that is not very accurate overall can still be well-calibrated and find a useful
    application. In this article, we will explore the difference between good calibration
    and good performance and when one might be preferred over the other. Letâ€™s dive
    in!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ æ¨¡å‹é€šå¸¸æ ¹æ®å…¶æ€§èƒ½è¿›è¡Œè¯„ä¼°ï¼Œè¿™ç§æ€§èƒ½æ˜¯é€šè¿‡æŸäº›æŒ‡æ ‡æ¥è¿‘é›¶æˆ–ä¸€ï¼ˆå…·ä½“å–å†³äºæŒ‡æ ‡ï¼‰æ¥è¡¡é‡çš„ï¼Œä½†è¿™å¹¶ä¸æ˜¯å†³å®šå…¶æœ‰ç”¨æ€§çš„å”¯ä¸€å› ç´ ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä¸€ä¸ªæ•´ä½“å‡†ç¡®åº¦ä¸é«˜çš„æ¨¡å‹ä»ç„¶å¯ä»¥å¾ˆå¥½åœ°è¿›è¡Œæ ¡å‡†ï¼Œå¹¶æ‰¾åˆ°æœ‰ç”¨çš„åº”ç”¨åœºæ™¯ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨è‰¯å¥½æ ¡å‡†ä¸è‰¯å¥½æ€§èƒ½ä¹‹é—´çš„åŒºåˆ«ï¼Œä»¥åŠä½•æ—¶ä¸€ç§å¯èƒ½ä¼˜äºå¦ä¸€ç§ã€‚è®©æˆ‘ä»¬æ·±å…¥äº†è§£å§ï¼
- en: '![](../Images/75d563ec9011ce2508cbf4feb267de73.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75d563ec9011ce2508cbf4feb267de73.png)'
- en: Probability calibration
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¦‚ç‡æ ¡å‡†
- en: Probability calibration in its strong definition is the degree to which the
    probabilities predicted by a classification model match the true frequencies of
    the target classes in a dataset. A [well-calibrated model](https://medium.com/towards-data-science/calibrating-classifiers-559abc30711a)
    produces predictions that are, on aggregate, closely aligned with the actual outcomes.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æ¦‚ç‡æ ¡å‡†çš„å¼ºå®šä¹‰æ˜¯åˆ†ç±»æ¨¡å‹é¢„æµ‹çš„æ¦‚ç‡ä¸æ•°æ®é›†ä¸­ç›®æ ‡ç±»çš„çœŸå®é¢‘ç‡ä¹‹é—´çš„åŒ¹é…ç¨‹åº¦ã€‚ä¸€ä¸ª[è‰¯å¥½æ ¡å‡†çš„æ¨¡å‹](https://medium.com/towards-data-science/calibrating-classifiers-559abc30711a)ä¼šç”Ÿæˆåœ¨æ€»ä½“ä¸Šä¸å®é™…ç»“æœç´§å¯†å¯¹é½çš„é¢„æµ‹ã€‚
- en: What this means in practice is that if we make a lot of predictions with a perfectly
    calibrated binary classification model, and then consider only those for which
    the model predicted a 70% probability of the positive class, then the model should
    be correct 70% of the time. Similarly, if we only consider the examples for which
    our model predicted a 10% probability of the positive class, the ground truth
    will turn out to indeed be positive in one-tenth of the cases.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šï¼Œè¿™æ„å‘³ç€å¦‚æœæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå®Œç¾æ ¡å‡†çš„äºŒåˆ†ç±»æ¨¡å‹è¿›è¡Œå¤§é‡é¢„æµ‹ï¼Œç„¶ååªè€ƒè™‘é‚£äº›æ¨¡å‹é¢„æµ‹ä¸º70%æ¦‚ç‡ä¸ºæ­£ç±»çš„æƒ…å†µï¼Œé‚£ä¹ˆæ¨¡å‹åº”è¯¥åœ¨70%çš„æ—¶é—´é‡Œæ˜¯æ­£ç¡®çš„ã€‚åŒæ ·ï¼Œå¦‚æœæˆ‘ä»¬åªè€ƒè™‘æ¨¡å‹é¢„æµ‹ä¸º10%æ¦‚ç‡ä¸ºæ­£ç±»çš„ä¾‹å­ï¼Œå®é™…æƒ…å†µå°†åœ¨ååˆ†ä¹‹ä¸€çš„æ¡ˆä¾‹ä¸­ç¡®å®ä¸ºæ­£ç±»ã€‚
- en: A well-calibrated model produces predictions that are closely aligned with the
    actual outcomes on aggregate.
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªè‰¯å¥½æ ¡å‡†çš„æ¨¡å‹ä¼šç”Ÿæˆåœ¨æ€»ä½“ä¸Šä¸å®é™…ç»“æœç´§å¯†å¯¹é½çš„é¢„æµ‹ã€‚
- en: A model with strong calibration guarantees that its predictions satisfy the
    frequentist definition of probability ([as opposed to the Bayesian one](/the-gentlest-of-introductions-to-bayesian-data-analysis-74df448da25))
    which states that *an eventâ€™s probability is the limit of its relative frequency
    in many trials.*
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå¼ºæ ¡å‡†çš„æ¨¡å‹ä¿è¯å…¶é¢„æµ‹æ»¡è¶³é¢‘ç‡ä¸»ä¹‰çš„æ¦‚ç‡å®šä¹‰ï¼ˆ[è€Œéè´å¶æ–¯çš„å®šä¹‰](/the-gentlest-of-introductions-to-bayesian-data-analysis-74df448da25)ï¼‰ï¼Œå³*äº‹ä»¶çš„æ¦‚ç‡æ˜¯å…¶åœ¨å¤šæ¬¡è¯•éªŒä¸­çš„ç›¸å¯¹é¢‘ç‡çš„æé™*ã€‚
- en: Consider the probability of rolling a six with a dice. This probability amounts
    to 1/6 because in many rolls, or trials, you would get a six once every six rolls,
    on average. And the more times you roll, the closer the frequency of sixes will
    be to 1/6\. In this context, what does it *mean* when a binary classification
    model outputs a probability of 90% for an event? It means that if it does this
    many times, in approximately 9 out of 10 cases the event will indeed occur.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘æ·éª°å­æ—¶æ·å‡ºå…­çš„æ¦‚ç‡ã€‚è¿™ä¸ªæ¦‚ç‡ä¸º1/6ï¼Œå› ä¸ºåœ¨å¤šæ¬¡æ·éª°å­ä¸­ï¼Œä½ å¹³å‡æ¯å…­æ¬¡æ·ä¸€æ¬¡å°±ä¼šå¾—åˆ°ä¸€ä¸ªå…­ã€‚æ¬¡æ•°è¶Šå¤šï¼Œå…­çš„é¢‘ç‡å°±è¶Šæ¥è¿‘1/6ã€‚åœ¨è¿™ä¸ªèƒŒæ™¯ä¸‹ï¼Œå½“äºŒå…ƒåˆ†ç±»æ¨¡å‹è¾“å‡º90%çš„äº‹ä»¶æ¦‚ç‡æ—¶ï¼Œè¿™æ„å‘³ç€å¦‚æœå®ƒå¤šæ¬¡è¿™æ ·åšï¼Œå¤§çº¦åœ¨10æ¬¡ä¸­çš„9æ¬¡æƒ…å†µä¸‹äº‹ä»¶ç¡®å®ä¼šå‘ç”Ÿã€‚
- en: Most machine learning models are ill-calibrated and the reasons depend on the
    learning algorithm. Tree-based ensembles such as random forests generate their
    predictions by averaging individual trees, which makes it unlikely to obtain probabilities
    near zero and one since there is always some variance in the treesâ€™ predictions.
    As a result, we see probabilistic overestimates near zero and underestimates near
    one. Many other models optimize for and are scored by binary metrics. Accuracy
    only looks at whether we are right or wrong, disregarding certainty. Gini-impurity
    used by decision trees to decide on splits optimizes for being as accurate as
    possible as quickly as possible.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å¤šæ•°æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ ¡å‡†ä¸ä½³ï¼Œå…¶åŸå› å–å†³äºå­¦ä¹ ç®—æ³•ã€‚åŸºäºæ ‘çš„é›†æˆæ–¹æ³•ï¼Œå¦‚éšæœºæ£®æ—ï¼Œé€šè¿‡å¯¹å•æ£µæ ‘çš„é¢„æµ‹è¿›è¡Œå¹³å‡æ¥ç”Ÿæˆé¢„æµ‹ï¼Œè¿™ä½¿å¾—è·å¾—æ¥è¿‘é›¶å’Œä¸€çš„æ¦‚ç‡ä¸å¤ªå¯èƒ½ï¼Œå› ä¸ºæ ‘çš„é¢„æµ‹æ€»æ˜¯å­˜åœ¨ä¸€å®šçš„æ–¹å·®ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çœ‹åˆ°æ¥è¿‘é›¶çš„æ¦‚ç‡è¢«é«˜ä¼°ï¼Œæ¥è¿‘ä¸€çš„æ¦‚ç‡è¢«ä½ä¼°ã€‚è®¸å¤šå…¶ä»–æ¨¡å‹ä¼˜åŒ–å¹¶é€šè¿‡äºŒå…ƒæŒ‡æ ‡è¿›è¡Œè¯„åˆ†ã€‚å‡†ç¡®ç‡åªå…³æ³¨æˆ‘ä»¬æ˜¯å¦æ­£ç¡®ï¼Œè€Œå¿½ç•¥äº†ç¡®å®šæ€§ã€‚å†³ç­–æ ‘ç”¨äºå†³å®šåˆ†è£‚çš„åŸºå°¼ä¸çº¯åº¦ä¼˜åŒ–çš„æ˜¯å°½å¯èƒ½å¿«åœ°è¾¾åˆ°å°½å¯èƒ½å‡†ç¡®çš„ç»“æœã€‚
- en: The consequence of this is that while the scores produced by most machine learning
    models preserve order (the higher the number, the more likely the positive class),
    they cannot be interpreted as frequentist probabilities.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ç»“æœæ˜¯ï¼Œå°½ç®¡å¤§å¤šæ•°æœºå™¨å­¦ä¹ æ¨¡å‹ç”Ÿæˆçš„åˆ†æ•°ä¿æŒäº†é¡ºåºï¼ˆæ•°å­—è¶Šé«˜ï¼Œæ­£ç±»çš„å¯èƒ½æ€§è¶Šå¤§ï¼‰ï¼Œä½†è¿™äº›åˆ†æ•°ä¸èƒ½è¢«è§£é‡Šä¸ºé¢‘ç‡ä¸»ä¹‰çš„æ¦‚ç‡ã€‚
- en: '[There are simple methods to calibrate them](https://medium.com/towards-data-science/calibrating-classifiers-559abc30711a),
    and good calibration is undoubtedly a desired trait for a model to feature, but
    as we will soon see, it is not a required condition for the model to be useful,
    and sometimes we might even want the model not to be calibrated!'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœ‰ä¸€äº›ç®€å•çš„æ–¹æ³•å¯ä»¥æ ¡å‡†å®ƒä»¬](https://medium.com/towards-data-science/calibrating-classifiers-559abc30711a)ï¼Œè‰¯å¥½çš„æ ¡å‡†æ— ç–‘æ˜¯æ¨¡å‹åº”å…·å¤‡çš„ä¸€ä¸ªç†æƒ³ç‰¹å¾ï¼Œä½†æ­£å¦‚æˆ‘ä»¬å¾ˆå¿«ä¼šçœ‹åˆ°çš„ï¼Œå®ƒä¸æ˜¯æ¨¡å‹æœ‰ç”¨çš„å¿…è¦æ¡ä»¶ï¼Œæœ‰æ—¶æˆ‘ä»¬ç”šè‡³å¯èƒ½å¸Œæœ›æ¨¡å‹æ²¡æœ‰ç»è¿‡æ ¡å‡†ï¼'
- en: '![](../Images/75d563ec9011ce2508cbf4feb267de73.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75d563ec9011ce2508cbf4feb267de73.png)'
- en: Do you even need calibration?
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½ çœŸçš„éœ€è¦æ ¡å‡†å—ï¼Ÿ
- en: 'When training a classification model, you need to ask yourself a crucial question:
    do you actually *need* the model to be well-calibrated? The answer will depend
    on how the model will be used. Letâ€™s take a look at some examples.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è®­ç»ƒåˆ†ç±»æ¨¡å‹æ—¶ï¼Œä½ éœ€è¦é—®è‡ªå·±ä¸€ä¸ªå…³é”®é—®é¢˜ï¼šä½ æ˜¯å¦*éœ€è¦*æ¨¡å‹è‰¯å¥½çš„æ ¡å‡†ï¼Ÿç­”æ¡ˆå°†å–å†³äºæ¨¡å‹çš„ä½¿ç”¨æ–¹å¼ã€‚è®©æˆ‘ä»¬çœ‹ä¸€äº›ä¾‹å­ã€‚
- en: 'Calibration is everything: credit line assignment'
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ ¡å‡†æ˜¯å…³é”®ï¼šä¿¡ç”¨é¢åº¦åˆ†é…
- en: In some scenarios, good calibration is indispensable. Think about a bank deciding
    how much credit to grant a customer. Letâ€™s assume here that we are only considering
    loan applicants who have already been screened and assessed as low-risk and eligible
    for a loan (we will talk more about this screening process in a second). It is
    decided that the loans will be granted to them. The question is how much money
    can we lend each of them?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œè‰¯å¥½çš„æ ¡å‡†æ˜¯ä¸å¯æˆ–ç¼ºçš„ã€‚è€ƒè™‘ä¸€ä¸‹é“¶è¡Œå¦‚ä½•å†³å®šç»™å®¢æˆ·æˆäºˆå¤šå°‘ä¿¡ç”¨é¢åº¦ã€‚å‡è®¾æˆ‘ä»¬åªè€ƒè™‘é‚£äº›å·²ç»è¢«ç­›é€‰å’Œè¯„ä¼°ä¸ºä½é£é™©ä¸”ç¬¦åˆè´·æ¬¾æ¡ä»¶çš„ç”³è¯·è€…ï¼ˆæˆ‘ä»¬å°†åœ¨ç¨åè®¨è®ºè¿™ä¸€ç­›é€‰è¿‡ç¨‹ï¼‰ã€‚å†³å®šå°†è´·æ¬¾æˆäºˆä»–ä»¬ã€‚é—®é¢˜æ˜¯æˆ‘ä»¬å¯ä»¥å€Ÿç»™æ¯ä¸ªäººå¤šå°‘é’±ï¼Ÿ
- en: To answer it, the bank would need to know the exact probability of default for
    each customer, for different loan amounts. Knowing how likely different scenarios
    are, the bank will be able to predict the monetary impact from all loans, both
    paid back and defaulted, and make the optimal decision. To achieve their goal,
    they need a very well-calibrated model.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è¦å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œé“¶è¡Œéœ€è¦çŸ¥é“æ¯ä¸ªå®¢æˆ·åœ¨ä¸åŒè´·æ¬¾é‡‘é¢ä¸‹çš„ç¡®åˆ‡è¿çº¦æ¦‚ç‡ã€‚äº†è§£ä¸åŒæƒ…æ™¯çš„å¯èƒ½æ€§ï¼Œé“¶è¡Œå°†èƒ½å¤Ÿé¢„æµ‹æ‰€æœ‰è´·æ¬¾ï¼ˆæ— è®ºæ˜¯å·²å¿è¿˜è¿˜æ˜¯è¿çº¦ï¼‰çš„è´§å¸å½±å“ï¼Œå¹¶åšå‡ºæœ€ä½³å†³ç­–ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œä»–ä»¬éœ€è¦ä¸€ä¸ªç»è¿‡ç²¾ç¡®æ ¡å‡†çš„æ¨¡å‹ã€‚
- en: Notice how we donâ€™t really care about the modelâ€™s accuracy *per se*. Accuracy
    is all about being on the correct side of the prediction threshold; from its point
    of view, there is no difference between predicting 51% and 99% as long as the
    loan defaults; the prediction is just as correct in both cases. But for the bank,
    and for the loan applicant themselves, this is a huge difference. Getting the
    probability right is whatâ€™s important here.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæˆ‘ä»¬å¹¶ä¸çœŸæ­£å…³å¿ƒæ¨¡å‹çš„å‡†ç¡®æ€§*æœ¬èº«*ã€‚å‡†ç¡®æ€§å…³ä¹äºé¢„æµ‹é˜ˆå€¼çš„æ­£ç¡®ä¾§é¢ï¼›ä»å®ƒçš„è§’åº¦æ¥çœ‹ï¼Œé¢„æµ‹51%å’Œ99%æ²¡æœ‰åŒºåˆ«ï¼Œåªè¦è´·æ¬¾è¿çº¦ï¼›åœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼Œé¢„æµ‹éƒ½æ˜¯æ­£ç¡®çš„ã€‚ä½†å¯¹é“¶è¡Œä»¥åŠè´·æ¬¾ç”³è¯·è€…è€Œè¨€ï¼Œè¿™ä¹‹é—´æœ‰ç€å·¨å¤§çš„å·®å¼‚ã€‚è¿™é‡Œé‡è¦çš„æ˜¯è·å–æ­£ç¡®çš„æ¦‚ç‡ã€‚
- en: 'Calibration is everything: model performance estimation'
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ ¡å‡†è‡³å…³é‡è¦ï¼šæ¨¡å‹æ€§èƒ½ä¼°è®¡
- en: Sometimes, good model calibration is a prerequisite for a given application.
    Think about estimating the modelâ€™s performance in production without knowing the
    ground truth targets. One approach to solve this challenging task for classification
    models is NannyMLâ€™s [Confidence-Based Performance Estimation (CBPE) algorithm](https://medium.com/towards-artificial-intelligence/estimating-model-performance-without-ground-truth-453b850dad9a).
    In a nutshell, the idea behind this approach is to estimate the elements of the
    confusion matrix based on the expected error rates, which we know assuming the
    model is well-calibrated.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰æ—¶å€™ï¼Œè‰¯å¥½çš„æ¨¡å‹æ ¡å‡†æ˜¯æŸäº›åº”ç”¨çš„å…ˆå†³æ¡ä»¶ã€‚æƒ³è±¡ä¸€ä¸‹åœ¨ä¸çŸ¥é“çœŸå®ç›®æ ‡çš„æƒ…å†µä¸‹ä¼°è®¡æ¨¡å‹åœ¨ç”Ÿäº§ä¸­çš„æ€§èƒ½ã€‚è§£å†³è¿™ä¸ªåˆ†ç±»æ¨¡å‹çš„æŒ‘æˆ˜æ€§ä»»åŠ¡çš„ä¸€ç§æ–¹æ³•æ˜¯ NannyML
    çš„ [åŸºäºç½®ä¿¡åº¦çš„æ€§èƒ½ä¼°è®¡ï¼ˆCBPEï¼‰ç®—æ³•](https://medium.com/towards-artificial-intelligence/estimating-model-performance-without-ground-truth-453b850dad9a)ã€‚ç®€è€Œè¨€ä¹‹ï¼Œè¿™ç§æ–¹æ³•çš„æ ¸å¿ƒæ€æƒ³æ˜¯æ ¹æ®æœŸæœ›çš„é”™è¯¯ç‡æ¥ä¼°è®¡æ··æ·†çŸ©é˜µçš„å…ƒç´ ï¼Œå‰ææ˜¯æˆ‘ä»¬çŸ¥é“æ¨¡å‹ç»è¿‡è‰¯å¥½çš„æ ¡å‡†ã€‚
- en: So, if we want to monitor the modelâ€™s performance in production and we donâ€™t
    immediately have ground truth targets, we need our model to be calibrated. And
    yet again, the model does not need to be of great accuracy. As long as its predictions
    are well-calibrated, it is good to go.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬æƒ³ç›‘æ§æ¨¡å‹åœ¨ç”Ÿäº§ä¸­çš„è¡¨ç°è€Œæ²¡æœ‰ç«‹å³è·å¾—çœŸå®ç›®æ ‡ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ¨¡å‹è¿›è¡Œæ ¡å‡†ã€‚ç„¶è€Œï¼Œæ¨¡å‹çš„å‡†ç¡®æ€§å¹¶ä¸éœ€è¦å¾ˆé«˜ï¼Œåªè¦å®ƒçš„é¢„æµ‹ç»è¿‡è‰¯å¥½çš„æ ¡å‡†ï¼Œå°±å¯ä»¥ä½¿ç”¨ã€‚
- en: 'We donâ€™t need calibration: ranking problems'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸éœ€è¦æ ¡å‡†ï¼šæ’åºé—®é¢˜
- en: There are situations, however, in which the modelâ€™s calibration does not really
    matter much. These include all sorts of ranking problems, for instance.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œæœ‰äº›æƒ…å†µä¸‹ï¼Œæ¨¡å‹çš„æ ¡å‡†å¹¶ä¸é‚£ä¹ˆé‡è¦ã€‚ä¾‹å¦‚ï¼Œæ‰€æœ‰ç±»å‹çš„æ’åºé—®é¢˜ã€‚
- en: Think about models that rank news article titles in terms of quality or relevance
    to the userâ€™s search query. If the goal is to select one or more articles to show
    the user, we donâ€™t really care about the exact probability that each of them is
    high-quality and relevant; rather, we care about the order of scores produced
    by the model. That is, we want to be sure that what we show the user is better
    than what we donâ€™t show, and that the best news sit on top of the results list.
    In this setting, calibrating the model does not make much sense.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³æƒ³é‚£äº›æ ¹æ®è´¨é‡æˆ–ä¸ç”¨æˆ·æœç´¢æŸ¥è¯¢çš„ç›¸å…³æ€§å¯¹æ–°é—»æ–‡ç« æ ‡é¢˜è¿›è¡Œæ’åçš„æ¨¡å‹ã€‚å¦‚æœç›®æ ‡æ˜¯é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªæ–‡ç« å±•ç¤ºç»™ç”¨æˆ·ï¼Œæˆ‘ä»¬å¹¶ä¸å…³å¿ƒæ¯ç¯‡æ–‡ç« æ˜¯å¦å…·æœ‰é«˜è´¨é‡å’Œç›¸å…³æ€§çš„ç¡®åˆ‡æ¦‚ç‡ï¼›ç›¸åï¼Œæˆ‘ä»¬å…³å¿ƒçš„æ˜¯æ¨¡å‹äº§ç”Ÿçš„åˆ†æ•°çš„æ’åºã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬å¸Œæœ›ç¡®ä¿å±•ç¤ºç»™ç”¨æˆ·çš„å†…å®¹ä¼˜äºæœªå±•ç¤ºçš„å†…å®¹ï¼Œå¹¶ä¸”æœ€å¥½çš„æ–°é—»æ’åœ¨ç»“æœåˆ—è¡¨çš„é¡¶éƒ¨ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ ¡å‡†æ¨¡å‹å¹¶æ²¡æœ‰å¤ªå¤§æ„ä¹‰ã€‚
- en: 'We donâ€™t need calibration: granting loans'
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸éœ€è¦æ ¡å‡†ï¼šæˆäºˆè´·æ¬¾
- en: Another example of a scenario in which calibration is not that important is
    screening for granting a loan which we have already mentioned.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªæ ¡å‡†ä¸é‚£ä¹ˆé‡è¦çš„åœºæ™¯æ˜¯æˆ‘ä»¬ä¹‹å‰æåˆ°çš„è´·æ¬¾æˆäºˆç­›é€‰ã€‚
- en: The goal here is to predict which applicants will pay their loans back. In this
    binary classification problem, the bank is mostly interested in the accuracy of
    the modelâ€™s classification rather than the probabilities it produces.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„ç›®æ ‡æ˜¯é¢„æµ‹å“ªäº›ç”³è¯·è€…ä¼šå¿è¿˜è´·æ¬¾ã€‚åœ¨è¿™ä¸ªäºŒåˆ†ç±»é—®é¢˜ä¸­ï¼Œé“¶è¡Œä¸»è¦å…³æ³¨æ¨¡å‹åˆ†ç±»çš„å‡†ç¡®æ€§ï¼Œè€Œä¸æ˜¯å®ƒäº§ç”Ÿçš„æ¦‚ç‡ã€‚
- en: Depending on how the model will be used, good calibration may be either indispensable
    or rather unnecessary.
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ ¹æ®æ¨¡å‹çš„ä½¿ç”¨æ–¹å¼ï¼Œè‰¯å¥½çš„æ ¡å‡†å¯èƒ½æ˜¯å¿…ä¸å¯å°‘çš„ï¼Œä¹Ÿå¯èƒ½æ˜¯ç›¸å¯¹ä¸å¿…è¦çš„ã€‚
- en: Letâ€™s now take a look at some models that are poor in terms of performance,
    but their good calibration renders them very useful for their intended purposes.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ä¸€äº›åœ¨æ€§èƒ½æ–¹é¢è¾ƒå·®çš„æ¨¡å‹ï¼Œä½†å®ƒä»¬çš„è‰¯å¥½æ ¡å‡†ä½¿å…¶åœ¨é¢„æœŸçš„ç”¨é€”ä¸Šéå¸¸æœ‰ç”¨ã€‚
- en: '![](../Images/75d563ec9011ce2508cbf4feb267de73.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75d563ec9011ce2508cbf4feb267de73.png)'
- en: A story of a poor, well-calibrated model
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæ ¡å‡†è‰¯å¥½çš„å·®æ¨¡å‹çš„æ•…äº‹
- en: Letâ€™s consider two different models. First, we will look at one where good performance
    is hard to get, but good calibration ensures the model provides value. Second,
    we will consider a model theoretically incapable of good performance, but well-calibrated
    and thus useful.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è€ƒè™‘ä¸¤ä¸ªä¸åŒçš„æ¨¡å‹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†æŸ¥çœ‹ä¸€ä¸ªåœ¨æ€§èƒ½ä¸Šéš¾ä»¥è·å¾—è‰¯å¥½è¡¨ç°çš„æ¨¡å‹ï¼Œä½†è‰¯å¥½çš„æ ¡å‡†ç¡®ä¿äº†æ¨¡å‹æä¾›äº†ä»·å€¼ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å°†è€ƒè™‘ä¸€ä¸ªç†è®ºä¸Šæ— æ³•è·å¾—è‰¯å¥½è¡¨ç°çš„æ¨¡å‹ï¼Œä½†å®ƒç»è¿‡è‰¯å¥½æ ¡å‡†ï¼Œå› æ­¤ä»ç„¶æœ‰ç”¨ã€‚
- en: When itâ€™s hard to get a good performance
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å½“å¾ˆéš¾è·å¾—è‰¯å¥½è¡¨ç°æ—¶
- en: Some time ago, I have been training models to predict the results of football
    (a.k.a. soccer) matches with the goal of getting rich quickly and effortlessly
    by betting at a bookie. Predicting a match result accurately is an impossible
    task â€” there are too many hidden factors involved such as luck and the playersâ€™
    disposition of the day. But guess what, getting accurate predictions is not what
    we need! Just like in the credit line assignment and performance estimation examples,
    here too, the game is all about getting the probabilities right.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ®µæ—¶é—´ä¹‹å‰ï¼Œæˆ‘ä¸€ç›´åœ¨è®­ç»ƒæ¨¡å‹æ¥é¢„æµ‹è¶³çƒï¼ˆä¹Ÿå°±æ˜¯è¶³çƒæ¯”èµ›ï¼‰çš„ç»“æœï¼Œç›®æ ‡æ˜¯é€šè¿‡åœ¨åšå½©å…¬å¸ä¸‹æ³¨å¿«é€Ÿä¸”è½»æ¾åœ°è‡´å¯Œã€‚å‡†ç¡®é¢„æµ‹æ¯”èµ›ç»“æœæ˜¯ä¸€é¡¹ä¸å¯èƒ½å®Œæˆçš„ä»»åŠ¡â€”â€”æ¶‰åŠåˆ°çš„éšè—å› ç´ å¤ªå¤šï¼Œä¾‹å¦‚è¿æ°”å’Œçƒå‘˜å½“å¤©çš„çŠ¶æ€ã€‚ä½†ä½ çŒœæ€ä¹ˆç€ï¼Œå‡†ç¡®çš„é¢„æµ‹å¹¶ä¸æ˜¯æˆ‘ä»¬éœ€è¦çš„ï¼å°±åƒåœ¨ä¿¡ç”¨é¢åº¦åˆ†é…å’Œç»©æ•ˆè¯„ä¼°çš„ä¾‹å­ä¸­ä¸€æ ·ï¼Œè¿™é‡Œä¹Ÿæ˜¯ï¼Œæ¸¸æˆçš„å…³é”®åœ¨äºè·å¾—æ­£ç¡®çš„æ¦‚ç‡ã€‚
- en: Consider this binary random forest classifier trained to predict whether the
    home team will win the game. It was trained on a couple of seasons of the English
    Premier League matches, and the feature set included the [ELO ratings](https://en.wikipedia.org/wiki/Elo_rating_system)
    of both teams as well as many different statistics summing up how good each team
    was in the recent games with respect to attack and defense.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘è¿™ä¸ªäºŒå…ƒéšæœºæ£®æ—åˆ†ç±»å™¨ï¼Œå®ƒè¢«è®­ç»ƒæ¥é¢„æµ‹ä¸»é˜Ÿæ˜¯å¦ä¼šèµ¢å¾—æ¯”èµ›ã€‚å®ƒæ˜¯åœ¨å‡ ä¸ªèµ›å­£çš„è‹±è¶…è”èµ›æ¯”èµ›ä¸Šè®­ç»ƒçš„ï¼Œç‰¹å¾é›†åŒ…æ‹¬äº†ä¸¤ä¸ªé˜Ÿä¼çš„[ELO è¯„åˆ†](https://en.wikipedia.org/wiki/Elo_rating_system)ä»¥åŠè®¸å¤šä¸åŒçš„ç»Ÿè®¡æ•°æ®ï¼Œæ±‡æ€»äº†æ¯ä¸ªçƒé˜Ÿåœ¨è¿‘æœŸæ¯”èµ›ä¸­çš„è¿›æ”»å’Œé˜²å®ˆè¡¨ç°ã€‚
- en: The modelâ€™s test accuracy was 63%. This is certainly better than a dummy model
    which always predicts the home team to win; such a model would score 46% as the
    hosts tend to win almost half of the games. That said, 63% does not seem to be
    a great result.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹çš„æµ‹è¯•å‡†ç¡®ç‡ä¸º63%ã€‚è¿™è‚¯å®šæ¯”ä¸€ä¸ªæ€»æ˜¯é¢„æµ‹ä¸»é˜Ÿè·èƒœçš„è™šæ‹Ÿæ¨¡å‹è¦å¥½ï¼›è¿™æ ·çš„æ¨¡å‹ä¼šå¾—åˆ°46%çš„å‡†ç¡®ç‡ï¼Œå› ä¸ºä¸»é˜Ÿå‡ ä¹èµ¢å¾—äº†åŠæ•°çš„æ¯”èµ›ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œ63%ä¼¼ä¹ä¸æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ç»“æœã€‚
- en: Letâ€™s take a look at the modelâ€™s calibration plot. The horizontal axis shows
    the probabilities produced by the model for the test set, binned into 10 equal-width
    bins. For each, the actual frequency of home wins is shown on the vertical axis.
    A perfectly calibrated model would produce a straight diagonal line.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹æ¨¡å‹çš„æ ¡å‡†å›¾ã€‚æ°´å¹³è½´æ˜¾ç¤ºäº†æ¨¡å‹ä¸ºæµ‹è¯•é›†äº§ç”Ÿçš„æ¦‚ç‡ï¼Œåˆ†ä¸º10ä¸ªç­‰å®½çš„åŒºé—´ã€‚å¯¹äºæ¯ä¸€ä¸ªåŒºé—´ï¼Œä¸»é˜Ÿè·èƒœçš„å®é™…é¢‘ç‡æ˜¾ç¤ºåœ¨å‚ç›´è½´ä¸Šã€‚ä¸€ä¸ªå®Œå…¨æ ¡å‡†çš„æ¨¡å‹å°†äº§ç”Ÿä¸€æ¡å®Œç¾çš„å¯¹è§’çº¿ã€‚
- en: '![](../Images/2eac88bc7a58b8857662544e077fa1d5.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2eac88bc7a58b8857662544e077fa1d5.png)'
- en: Football predictorâ€™s calibration curves. Image by the author.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: è¶³çƒé¢„æµ‹å™¨çš„æ ¡å‡†æ›²çº¿ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: 'The original model, shown in blue, is very poorly calibrated at more extreme
    probabilities: a prediction of 90% has only a 30% chance of being correct! Hence,
    I decided to calibrate it using one of the most popular techniques: [fitting a
    logistic regressor on top of the modelâ€™s outputs](/calibrating-classifiers-559abc30711a).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: åŸå§‹æ¨¡å‹ï¼Œæ˜¾ç¤ºä¸ºè“è‰²ï¼Œåœ¨æ›´æç«¯çš„æ¦‚ç‡ä¸‹æ ¡å‡†æ•ˆæœå¾ˆå·®ï¼š90%çš„é¢„æµ‹ä»…æœ‰30%çš„æ­£ç¡®ç‡ï¼å› æ­¤ï¼Œæˆ‘å†³å®šä½¿ç”¨æœ€æµè¡Œçš„æŠ€æœ¯ä¹‹ä¸€æ¥è¿›è¡Œæ ¡å‡†ï¼š[åœ¨æ¨¡å‹è¾“å‡ºä¸Šæ‹Ÿåˆé€»è¾‘å›å½’å™¨](/calibrating-classifiers-559abc30711a)ã€‚
- en: The resulting model, shown in green, seems to be much better calibrated. You
    will surely notice, too, that it does not produce extreme probabilities anymore.
    As far as accuracy is concerned, it dropped by one percentage point, to 62%. So,
    we managed to improve the modelâ€™s calibration at the cost of accuracy. How is
    this useful?
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœæ¨¡å‹ï¼Œæ˜¾ç¤ºä¸ºç»¿è‰²ï¼Œä¼¼ä¹æ ¡å‡†æ•ˆæœå¥½å¾—å¤šã€‚ä½ ä¹Ÿä¼šæ³¨æ„åˆ°ï¼Œå®ƒä¸å†äº§ç”Ÿæç«¯æ¦‚ç‡ã€‚è‡³äºå‡†ç¡®ç‡ï¼Œå®ƒä¸‹é™äº†ä¸€ä¸ªç™¾åˆ†ç‚¹ï¼Œé™è‡³62%ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æˆåŠŸåœ°æé«˜äº†æ¨¡å‹çš„æ ¡å‡†æ°´å¹³ï¼Œä½†å‡†ç¡®ç‡æœ‰æ‰€ä¸‹é™ã€‚è¿™æœ‰ä»€ä¹ˆç”¨å‘¢ï¼Ÿ
- en: 'Consider the following strategy: we will only bet on matches in which the model
    is the most certain that the home team will win, so the ones for which it produces
    a prediction of 70%. Thanks to reasonably good calibration, we know the model
    will be correct in 70% of such cases. For simplicity, assume we are betting $100
    on each game separately.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘ä»¥ä¸‹ç­–ç•¥ï¼šæˆ‘ä»¬åªå¯¹æ¨¡å‹æœ€ç¡®å®šä¸»é˜Ÿä¼šèµ¢çš„æ¯”èµ›è¿›è¡ŒæŠ•æ³¨ï¼Œå³æ¨¡å‹é¢„æµ‹ä¸»é˜Ÿèƒœç‡ä¸º70%çš„æ¯”èµ›ã€‚å¾—ç›Šäºåˆç†çš„æ ¡å‡†ï¼Œæˆ‘ä»¬çŸ¥é“æ¨¡å‹åœ¨è¿™ç§æƒ…å†µä¸‹çš„æ­£ç¡®ç‡ä¸º70%ã€‚ä¸ºäº†ç®€åŒ–èµ·è§ï¼Œå‡è®¾æˆ‘ä»¬å¯¹æ¯åœºæ¯”èµ›åˆ†åˆ«æŠ•æ³¨$100ã€‚
- en: 'Out of 100 games, we will miss 30, which will yield us a loss of $3000\. But
    we will win the remaining 70 bets, and the cash prize will be `70 * 100 * (odds
    â€” 1)`(we subtract 1 to take into account that we need to spend $7000 on the coupons
    in the first place). We can solve this equation to find such bookieâ€™s odds for
    which we break even:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨100åœºæ¯”èµ›ä¸­ï¼Œæˆ‘ä»¬å°†é”™è¿‡30åœºï¼Œé€ æˆ$3000çš„æŸå¤±ã€‚ä½†æˆ‘ä»¬å°†èµ¢å¾—å‰©ä¸‹çš„70åœºæ¯”èµ›ï¼Œç°é‡‘å¥–åŠ±ä¸º`70 * 100 * (èµ”ç‡ â€” 1)`ï¼ˆæˆ‘ä»¬å‡å»1æ˜¯ä¸ºäº†è€ƒè™‘åˆ°æˆ‘ä»¬æœ€åˆéœ€è¦èŠ±è´¹$7000è´­ä¹°å½©ç¥¨ï¼‰ã€‚æˆ‘ä»¬å¯ä»¥è§£è¿™ä¸ªæ–¹ç¨‹ï¼Œæ‰¾åˆ°ä¸€ä¸ªåšå½©å…¬å¸èµ”ç‡ï¼Œä½¿å¾—æˆ‘ä»¬æ”¶æ”¯å¹³è¡¡ï¼š
- en: '[PRE0]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: There we go! We can bet on all matches for which the model produces a 70% prediction
    and for which the bookie offers odds higher than 1.42 (disregarding the tax).
    We can, of course, compute the odds for other predicted probabilities in a similar
    fashion. Assuming the modelâ€™s calibration will stay good in the future (and this
    is a strong assumption!), this strategy should yield quite profitable in the long
    run. And all that despite the poor 62% accuracy!
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å°±è¿™æ ·ï¼æˆ‘ä»¬å¯ä»¥å¯¹æ¨¡å‹é¢„æµ‹ä¸º70%çš„æ‰€æœ‰æ¯”èµ›è¿›è¡ŒæŠ•æ³¨ï¼Œå¹¶ä¸”åœ¨è¿™äº›æ¯”èµ›ä¸­ï¼Œåšå½©å…¬å¸æä¾›çš„èµ”ç‡éœ€é«˜äº1.42ï¼ˆä¸è€ƒè™‘ç¨ï¼‰ã€‚å½“ç„¶ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä»¥ç±»ä¼¼çš„æ–¹å¼è®¡ç®—å…¶ä»–é¢„æµ‹æ¦‚ç‡çš„èµ”ç‡ã€‚å‡è®¾æ¨¡å‹çš„æ ¡å‡†åœ¨æœªæ¥ä¿æŒè‰¯å¥½ï¼ˆè¿™æ˜¯ä¸€é¡¹å¼ºå‡è®¾ï¼ï¼‰ï¼Œè¿™ç§ç­–ç•¥åº”è¯¥åœ¨é•¿æœŸå†…ç›¸å½“æœ‰åˆ©ã€‚å°½ç®¡å‡†ç¡®ç‡åªæœ‰62%ï¼Œä½†è¿™ä»ç„¶æœ‰æ•ˆï¼
- en: When itâ€™s impossible to get a good performance
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å½“æ— æ³•è·å¾—è‰¯å¥½çš„æ€§èƒ½æ—¶
- en: Now consider an attempt to predict dice rolls. Our model should produce a probability
    of the die facing up six after it has been rolled. We assume that the die is just
    a regular, board game-type, six-sided, fair die.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è€ƒè™‘é¢„æµ‹æ·éª°å­çš„å°è¯•ã€‚æˆ‘ä»¬çš„æ¨¡å‹åº”è¯¥ç»™å‡ºéª°å­æ·å‡ºå…­çš„æ¦‚ç‡ã€‚æˆ‘ä»¬å‡è®¾éª°å­æ˜¯æ™®é€šçš„å…­é¢å…¬å¹³éª°å­ã€‚
- en: 'Rolling such a die is a completely stochastic process and the chance of each
    side facing up is the same: â…™. In other words, the data classes are completely
    inseparable: it is not feasible to build an accurate model. What model can we
    have then?'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: æ·éª°å­æ˜¯ä¸€ä¸ªå®Œå…¨éšæœºçš„è¿‡ç¨‹ï¼Œæ¯ä¸€é¢æœä¸Šçš„æœºä¼šæ˜¯ç›¸åŒçš„ï¼šâ…™ã€‚æ¢å¥è¯è¯´ï¼Œæ•°æ®ç±»åˆ«æ˜¯å®Œå…¨ä¸å¯åˆ†çš„ï¼šå»ºç«‹ä¸€ä¸ªå‡†ç¡®çš„æ¨¡å‹æ˜¯ä¸åˆ‡å®é™…çš„ã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬å¯ä»¥æ‹¥æœ‰ä»€ä¹ˆæ¨¡å‹å‘¢ï¼Ÿ
- en: 'Consider these two competing approaches. Model A is a dummy binary classifier
    that always predicts with full confidence that the rolled number is not a six;
    that is, it predicts a six 0% of the time and a not-six 100% of the time. Model
    B also never predicts a six but the probabilities it outputs are different: it
    always predicts a six with the probability of â…™ and a not-six with the probability
    of â…š.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘è¿™ä¸¤ç§ç«äº‰æ–¹æ³•ã€‚æ¨¡å‹Aæ˜¯ä¸€ä¸ªè™šæ‹Ÿçš„äºŒå…ƒåˆ†ç±»å™¨ï¼Œå®ƒæ€»æ˜¯å…¨ä¿¡å¿ƒåœ°é¢„æµ‹æ·å‡ºçš„æ•°å­—ä¸æ˜¯å…­ï¼›ä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒ0%çš„æ—¶é—´é¢„æµ‹å…­ï¼Œ100%çš„æ—¶é—´é¢„æµ‹ä¸æ˜¯å…­ã€‚æ¨¡å‹Bä¹Ÿä»ä¸é¢„æµ‹å…­ï¼Œä½†å®ƒè¾“å‡ºçš„æ¦‚ç‡ä¸åŒï¼šå®ƒæ€»æ˜¯ä»¥â…™çš„æ¦‚ç‡é¢„æµ‹å…­ï¼Œä»¥â…šçš„æ¦‚ç‡é¢„æµ‹ä¸æ˜¯å…­ã€‚
- en: 'In the long run, both models feature the same accuracy: they are correct 5
    out of 6 times. And this is as good as any model can get. However, an important
    fact differentiates between the two models: model B is perfectly calibrated while
    model A is not calibrated at all.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é•¿è¿œæ¥çœ‹ï¼Œè¿™ä¸¤ä¸ªæ¨¡å‹çš„å‡†ç¡®ç‡ç›¸åŒï¼šå®ƒä»¬çš„æ­£ç¡®ç‡ä¸º5/6ã€‚è¿™æ˜¯ä»»ä½•æ¨¡å‹èƒ½è¾¾åˆ°çš„æœ€å¥½æ°´å¹³ã€‚ç„¶è€Œï¼Œä¸€ä¸ªé‡è¦çš„äº‹å®åŒºåˆ†äº†è¿™ä¸¤ä¸ªæ¨¡å‹ï¼šæ¨¡å‹Bçš„æ ¡å‡†éå¸¸å®Œç¾ï¼Œè€Œæ¨¡å‹Aæ ¹æœ¬æ²¡æœ‰æ ¡å‡†ã€‚
- en: 'As far as calibration is concerned, the two models couldnâ€™t be more different.
    How about the usefulness of the two models? Model A doesnâ€™t really deliver any
    value. Model B, on the other hand, allows us to accurately predict the target
    frequency in the long run. It also allows us to run simulations to answer more
    complex questions such as: what is the probability of rolling four not-six and
    seven sixes in 11 rolls? Once again, despite the poor predictive performance,
    good calibration yields the model useful!'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å°±æ ¡å‡†è€Œè¨€ï¼Œè¿™ä¸¤ä¸ªæ¨¡å‹æˆªç„¶ä¸åŒã€‚é‚£ä¹ˆï¼Œè¿™ä¸¤ä¸ªæ¨¡å‹çš„æœ‰ç”¨æ€§å¦‚ä½•ï¼Ÿæ¨¡å‹Aå®é™…ä¸Šæ²¡æœ‰æä¾›ä»»ä½•ä»·å€¼ã€‚å¦ä¸€æ–¹é¢ï¼Œæ¨¡å‹Bå…è®¸æˆ‘ä»¬åœ¨é•¿æœŸå†…å‡†ç¡®é¢„æµ‹ç›®æ ‡é¢‘ç‡ã€‚å®ƒè¿˜å…è®¸æˆ‘ä»¬è¿›è¡Œæ¨¡æ‹Ÿï¼Œä»¥å›ç­”æ›´å¤æ‚çš„é—®é¢˜ï¼Œä¾‹å¦‚ï¼šåœ¨11æ¬¡æ·éª°ä¸­ï¼Œæ·å‡ºå››æ¬¡ä¸æ˜¯å…­å’Œä¸ƒæ¬¡å…­çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿå°½ç®¡é¢„æµ‹æ€§èƒ½ä¸ä½³ï¼Œä½†è‰¯å¥½çš„æ ¡å‡†ä½¿æ¨¡å‹ä¾ç„¶æœ‰ç”¨ï¼
- en: '![](../Images/75d563ec9011ce2508cbf4feb267de73.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75d563ec9011ce2508cbf4feb267de73.png)'
- en: Takeaways
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è¦ç‚¹
- en: Well-calibrated models produce predictions that are closely aligned with the
    frequency of the actual outcomes on aggregate. Most models are ill-calibrated
    because of the way they learn, but there are simple methods to fix this.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ¡å‡†è‰¯å¥½çš„æ¨¡å‹äº§ç”Ÿçš„é¢„æµ‹ä¸å®é™…ç»“æœçš„é¢‘ç‡é«˜åº¦ä¸€è‡´ã€‚å¤§å¤šæ•°æ¨¡å‹ç”±äºå­¦ä¹ æ–¹å¼çš„ä¸åŒè€Œæ ¡å‡†ä¸ä½³ï¼Œä½†æœ‰ä¸€äº›ç®€å•çš„æ–¹æ³•å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚
- en: For some applications, like assigning credit lines or CBPE estimation, good
    calibration is essential (in fact, more important than the performance metrics
    themselves). For others, such as granting loans or ranking problems, not very
    much so; here, correct rank ordering and performance are what matters.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºä¸€äº›åº”ç”¨åœºæ™¯ï¼Œå¦‚åˆ†é…ä¿¡ç”¨é¢åº¦æˆ– CBPE ä¼°è®¡ï¼Œè‰¯å¥½çš„æ ¡å‡†è‡³å…³é‡è¦ï¼ˆäº‹å®ä¸Šï¼Œæ¯”æ€§èƒ½æŒ‡æ ‡æœ¬èº«æ›´é‡è¦ï¼‰ã€‚å¯¹äºå…¶ä»–æƒ…å†µï¼Œæ¯”å¦‚è´·æ¬¾å‘æ”¾æˆ–æ’åºé—®é¢˜ï¼Œè¿™ä¸€ç‚¹åˆ™ä¸é‚£ä¹ˆé‡è¦ï¼›åœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œæ­£ç¡®çš„æ’åºå’Œæ€§èƒ½æ‰æ˜¯å…³é”®ã€‚
- en: Inaccurate models can be pretty useful provided they are well-calibrated; sometimes
    getting the probabilities right is all we can do.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸å‡†ç¡®çš„æ¨¡å‹åœ¨ç»è¿‡è‰¯å¥½æ ¡å‡†åå¯èƒ½ä¼šéå¸¸æœ‰ç”¨ï¼›æœ‰æ—¶ï¼Œç¡®ä¿æ¦‚ç‡çš„æ­£ç¡®æ€§å°±æ˜¯æˆ‘ä»¬èƒ½åšåˆ°çš„å…¨éƒ¨ã€‚
- en: '*This article was also published on the* [*NannyML blog*](https://www.nannyml.com/blog/probability-calibration)*.*'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '*è¿™ç¯‡æ–‡ç« ä¹Ÿå‘è¡¨åœ¨* [*NannyML åšå®¢*](https://www.nannyml.com/blog/probability-calibration)*ä¸Šã€‚*'
- en: '![](../Images/75d563ec9011ce2508cbf4feb267de73.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75d563ec9011ce2508cbf4feb267de73.png)'
- en: Thanks for reading!
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢é˜…è¯»ï¼
- en: If you liked this post, why donâ€™t you [**subscribe for email updates**](https://michaloleszak.medium.com/subscribe)
    on my new articles? And by [**becoming a Medium member**](https://michaloleszak.medium.com/membership),
    you can support my writing and get unlimited access to all stories by other authors
    and yours truly.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œä¸ºä»€ä¹ˆä¸[**è®¢é˜…ç”µå­é‚®ä»¶æ›´æ–°**](https://michaloleszak.medium.com/subscribe)ä»¥è·å–æˆ‘æœ€æ–°çš„æ–‡ç« å‘¢ï¼Ÿé€šè¿‡[**æˆä¸º
    Medium ä¼šå‘˜**](https://michaloleszak.medium.com/membership)ï¼Œä½ å¯ä»¥æ”¯æŒæˆ‘çš„å†™ä½œå¹¶æ— é™åˆ¶åœ°è®¿é—®å…¶ä»–ä½œè€…åŠæˆ‘è‡ªå·±çš„æ‰€æœ‰æ•…äº‹ã€‚
- en: Want to always keep your finger on the pulse of the increasingly faster-developing
    field of machine learning and AI? Check out my new newsletter, [**AI Pulse**](https://pulseofai.substack.com/).
    Need consulting? You can ask me anything or book me for a 1:1 [**here**](https://topmate.io/michaloleszak).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³è¦æ—¶åˆ»æŒæ¡æœºå™¨å­¦ä¹ å’Œ AI å¿«é€Ÿå‘å±•çš„é¢†åŸŸçš„åŠ¨æ€å—ï¼ŸæŸ¥çœ‹æˆ‘çš„æ–°é€šè®¯ï¼Œ[**AI Pulse**](https://pulseofai.substack.com/)ã€‚éœ€è¦å’¨è¯¢ï¼Ÿä½ å¯ä»¥åœ¨[**è¿™é‡Œ**](https://topmate.io/michaloleszak)é—®æˆ‘ä»»ä½•é—®é¢˜æˆ–é¢„çº¦ä¸€å¯¹ä¸€æœåŠ¡ã€‚
- en: 'You can also try one of [my other articles](https://michaloleszak.github.io/blog/).
    Canâ€™t choose? Pick one of these:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¹Ÿå¯ä»¥å°è¯•ä¸€ä¸‹[æˆ‘çš„å…¶ä»–æ–‡ç« ](https://michaloleszak.github.io/blog/)ã€‚æ— æ³•é€‰æ‹©ï¼ŸæŒ‘ä¸€ä¸ªçœ‹çœ‹å§ï¼š
- en: '[](/calibrating-classifiers-559abc30711a?source=post_page-----7a856346fdf2--------------------------------)
    [## Calibrating classifiers'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/calibrating-classifiers-559abc30711a?source=post_page-----7a856346fdf2--------------------------------)
    [## æ ¡å‡†åˆ†ç±»å™¨'
- en: Are you sure your model returns probabilities? ğŸ²
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½ ç¡®å®šä½ çš„æ¨¡å‹è¿”å›çš„æ˜¯æ¦‚ç‡å—ï¼Ÿ ğŸ²
- en: towardsdatascience.com](/calibrating-classifiers-559abc30711a?source=post_page-----7a856346fdf2--------------------------------)
    [](https://pub.towardsai.net/estimating-model-performance-without-ground-truth-453b850dad9a?source=post_page-----7a856346fdf2--------------------------------)
    [## Estimating Model Performance without Ground Truth
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/calibrating-classifiers-559abc30711a?source=post_page-----7a856346fdf2--------------------------------)
    [](https://pub.towardsai.net/estimating-model-performance-without-ground-truth-453b850dad9a?source=post_page-----7a856346fdf2--------------------------------)
    [## æ— éœ€çœŸå®æ•°æ®ä¼°è®¡æ¨¡å‹æ€§èƒ½
- en: Itâ€™s possible, as long as you keep your probabilities calibrated
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åªè¦ä¿æŒä½ çš„æ¦‚ç‡æ ¡å‡†ï¼Œè¿™æ˜¯å¯èƒ½çš„ã€‚
- en: pub.towardsai.net](https://pub.towardsai.net/estimating-model-performance-without-ground-truth-453b850dad9a?source=post_page-----7a856346fdf2--------------------------------)
    [](/feature-selection-methods-and-how-to-choose-them-1e7469100e7e?source=post_page-----7a856346fdf2--------------------------------)
    [## Feature Selection Methods and How to Choose Them
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: pub.towardsai.net](https://pub.towardsai.net/estimating-model-performance-without-ground-truth-453b850dad9a?source=post_page-----7a856346fdf2--------------------------------)
    [](/feature-selection-methods-and-how-to-choose-them-1e7469100e7e?source=post_page-----7a856346fdf2--------------------------------)
    [## ç‰¹å¾é€‰æ‹©æ–¹æ³•åŠå¦‚ä½•é€‰æ‹©å®ƒä»¬
- en: The why, the how, and the when of feature selection, plus some handy tricks
    and tips
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç‰¹å¾é€‰æ‹©çš„åŸå› ã€æ–¹æ³•å’Œæ—¶æœºï¼Œä»¥åŠä¸€äº›å®ç”¨çš„æŠ€å·§å’Œå»ºè®®
- en: towardsdatascience.com](/feature-selection-methods-and-how-to-choose-them-1e7469100e7e?source=post_page-----7a856346fdf2--------------------------------)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/feature-selection-methods-and-how-to-choose-them-1e7469100e7e?source=post_page-----7a856346fdf2--------------------------------)
