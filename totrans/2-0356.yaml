- en: Bad machine learning models can still be well-calibrated
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不良的机器学习模型仍然可以被良好校准
- en: 原文：[https://towardsdatascience.com/bad-machine-learning-models-can-still-be-well-calibrated-7a856346fdf2](https://towardsdatascience.com/bad-machine-learning-models-can-still-be-well-calibrated-7a856346fdf2)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/bad-machine-learning-models-can-still-be-well-calibrated-7a856346fdf2](https://towardsdatascience.com/bad-machine-learning-models-can-still-be-well-calibrated-7a856346fdf2)
- en: Machine Learning
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习
- en: You don’t need a perfect oracle to get your probabilities right.
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你不需要一个完美的神谕来正确地确定你的概率。
- en: '[](https://michaloleszak.medium.com/?source=post_page-----7a856346fdf2--------------------------------)[![Michał
    Oleszak](../Images/61b32e70cec4ba54612a8ca22e977176.png)](https://michaloleszak.medium.com/?source=post_page-----7a856346fdf2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7a856346fdf2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7a856346fdf2--------------------------------)
    [Michał Oleszak](https://michaloleszak.medium.com/?source=post_page-----7a856346fdf2--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://michaloleszak.medium.com/?source=post_page-----7a856346fdf2--------------------------------)[![Michał
    Oleszak](../Images/61b32e70cec4ba54612a8ca22e977176.png)](https://michaloleszak.medium.com/?source=post_page-----7a856346fdf2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7a856346fdf2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7a856346fdf2--------------------------------)
    [Michał Oleszak](https://michaloleszak.medium.com/?source=post_page-----7a856346fdf2--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7a856346fdf2--------------------------------)
    ·11 min read·Feb 13, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7a856346fdf2--------------------------------)
    ·11 min read·2023年2月13日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/e7631602da782fdb4e815070633580b0.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e7631602da782fdb4e815070633580b0.png)'
- en: Machine learning models are often evaluated based on their performance, measured
    by how close some metric is to zero or one (depending on the metric) but this
    is not the only factor that determines their usefulness. In some cases, a model
    that is not very accurate overall can still be well-calibrated and find a useful
    application. In this article, we will explore the difference between good calibration
    and good performance and when one might be preferred over the other. Let’s dive
    in!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型通常根据其性能进行评估，这种性能是通过某些指标接近零或一（具体取决于指标）来衡量的，但这并不是决定其有用性的唯一因素。在某些情况下，一个整体准确度不高的模型仍然可以很好地进行校准，并找到有用的应用场景。在本文中，我们将探讨良好校准与良好性能之间的区别，以及何时一种可能优于另一种。让我们深入了解吧！
- en: '![](../Images/75d563ec9011ce2508cbf4feb267de73.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75d563ec9011ce2508cbf4feb267de73.png)'
- en: Probability calibration
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概率校准
- en: Probability calibration in its strong definition is the degree to which the
    probabilities predicted by a classification model match the true frequencies of
    the target classes in a dataset. A [well-calibrated model](https://medium.com/towards-data-science/calibrating-classifiers-559abc30711a)
    produces predictions that are, on aggregate, closely aligned with the actual outcomes.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 概率校准的强定义是分类模型预测的概率与数据集中目标类的真实频率之间的匹配程度。一个[良好校准的模型](https://medium.com/towards-data-science/calibrating-classifiers-559abc30711a)会生成在总体上与实际结果紧密对齐的预测。
- en: What this means in practice is that if we make a lot of predictions with a perfectly
    calibrated binary classification model, and then consider only those for which
    the model predicted a 70% probability of the positive class, then the model should
    be correct 70% of the time. Similarly, if we only consider the examples for which
    our model predicted a 10% probability of the positive class, the ground truth
    will turn out to indeed be positive in one-tenth of the cases.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这意味着如果我们使用一个完美校准的二分类模型进行大量预测，然后只考虑那些模型预测为70%概率为正类的情况，那么模型应该在70%的时间里是正确的。同样，如果我们只考虑模型预测为10%概率为正类的例子，实际情况将在十分之一的案例中确实为正类。
- en: A well-calibrated model produces predictions that are closely aligned with the
    actual outcomes on aggregate.
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一个良好校准的模型会生成在总体上与实际结果紧密对齐的预测。
- en: A model with strong calibration guarantees that its predictions satisfy the
    frequentist definition of probability ([as opposed to the Bayesian one](/the-gentlest-of-introductions-to-bayesian-data-analysis-74df448da25))
    which states that *an event’s probability is the limit of its relative frequency
    in many trials.*
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一个强校准的模型保证其预测满足频率主义的概率定义（[而非贝叶斯的定义](/the-gentlest-of-introductions-to-bayesian-data-analysis-74df448da25)），即*事件的概率是其在多次试验中的相对频率的极限*。
- en: Consider the probability of rolling a six with a dice. This probability amounts
    to 1/6 because in many rolls, or trials, you would get a six once every six rolls,
    on average. And the more times you roll, the closer the frequency of sixes will
    be to 1/6\. In this context, what does it *mean* when a binary classification
    model outputs a probability of 90% for an event? It means that if it does this
    many times, in approximately 9 out of 10 cases the event will indeed occur.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑掷骰子时掷出六的概率。这个概率为1/6，因为在多次掷骰子中，你平均每六次掷一次就会得到一个六。次数越多，六的频率就越接近1/6。在这个背景下，当二元分类模型输出90%的事件概率时，这意味着如果它多次这样做，大约在10次中的9次情况下事件确实会发生。
- en: Most machine learning models are ill-calibrated and the reasons depend on the
    learning algorithm. Tree-based ensembles such as random forests generate their
    predictions by averaging individual trees, which makes it unlikely to obtain probabilities
    near zero and one since there is always some variance in the trees’ predictions.
    As a result, we see probabilistic overestimates near zero and underestimates near
    one. Many other models optimize for and are scored by binary metrics. Accuracy
    only looks at whether we are right or wrong, disregarding certainty. Gini-impurity
    used by decision trees to decide on splits optimizes for being as accurate as
    possible as quickly as possible.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数机器学习模型的校准不佳，其原因取决于学习算法。基于树的集成方法，如随机森林，通过对单棵树的预测进行平均来生成预测，这使得获得接近零和一的概率不太可能，因为树的预测总是存在一定的方差。因此，我们看到接近零的概率被高估，接近一的概率被低估。许多其他模型优化并通过二元指标进行评分。准确率只关注我们是否正确，而忽略了确定性。决策树用于决定分裂的基尼不纯度优化的是尽可能快地达到尽可能准确的结果。
- en: The consequence of this is that while the scores produced by most machine learning
    models preserve order (the higher the number, the more likely the positive class),
    they cannot be interpreted as frequentist probabilities.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 其结果是，尽管大多数机器学习模型生成的分数保持了顺序（数字越高，正类的可能性越大），但这些分数不能被解释为频率主义的概率。
- en: '[There are simple methods to calibrate them](https://medium.com/towards-data-science/calibrating-classifiers-559abc30711a),
    and good calibration is undoubtedly a desired trait for a model to feature, but
    as we will soon see, it is not a required condition for the model to be useful,
    and sometimes we might even want the model not to be calibrated!'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[有一些简单的方法可以校准它们](https://medium.com/towards-data-science/calibrating-classifiers-559abc30711a)，良好的校准无疑是模型应具备的一个理想特征，但正如我们很快会看到的，它不是模型有用的必要条件，有时我们甚至可能希望模型没有经过校准！'
- en: '![](../Images/75d563ec9011ce2508cbf4feb267de73.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75d563ec9011ce2508cbf4feb267de73.png)'
- en: Do you even need calibration?
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你真的需要校准吗？
- en: 'When training a classification model, you need to ask yourself a crucial question:
    do you actually *need* the model to be well-calibrated? The answer will depend
    on how the model will be used. Let’s take a look at some examples.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练分类模型时，你需要问自己一个关键问题：你是否*需要*模型良好的校准？答案将取决于模型的使用方式。让我们看一些例子。
- en: 'Calibration is everything: credit line assignment'
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 校准是关键：信用额度分配
- en: In some scenarios, good calibration is indispensable. Think about a bank deciding
    how much credit to grant a customer. Let’s assume here that we are only considering
    loan applicants who have already been screened and assessed as low-risk and eligible
    for a loan (we will talk more about this screening process in a second). It is
    decided that the loans will be granted to them. The question is how much money
    can we lend each of them?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，良好的校准是不可或缺的。考虑一下银行如何决定给客户授予多少信用额度。假设我们只考虑那些已经被筛选和评估为低风险且符合贷款条件的申请者（我们将在稍后讨论这一筛选过程）。决定将贷款授予他们。问题是我们可以借给每个人多少钱？
- en: To answer it, the bank would need to know the exact probability of default for
    each customer, for different loan amounts. Knowing how likely different scenarios
    are, the bank will be able to predict the monetary impact from all loans, both
    paid back and defaulted, and make the optimal decision. To achieve their goal,
    they need a very well-calibrated model.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 要回答这个问题，银行需要知道每个客户在不同贷款金额下的确切违约概率。了解不同情景的可能性，银行将能够预测所有贷款（无论是已偿还还是违约）的货币影响，并做出最佳决策。为了实现这一目标，他们需要一个经过精确校准的模型。
- en: Notice how we don’t really care about the model’s accuracy *per se*. Accuracy
    is all about being on the correct side of the prediction threshold; from its point
    of view, there is no difference between predicting 51% and 99% as long as the
    loan defaults; the prediction is just as correct in both cases. But for the bank,
    and for the loan applicant themselves, this is a huge difference. Getting the
    probability right is what’s important here.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们并不真正关心模型的准确性*本身*。准确性关乎于预测阈值的正确侧面；从它的角度来看，预测51%和99%没有区别，只要贷款违约；在这两种情况下，预测都是正确的。但对银行以及贷款申请者而言，这之间有着巨大的差异。这里重要的是获取正确的概率。
- en: 'Calibration is everything: model performance estimation'
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 校准至关重要：模型性能估计
- en: Sometimes, good model calibration is a prerequisite for a given application.
    Think about estimating the model’s performance in production without knowing the
    ground truth targets. One approach to solve this challenging task for classification
    models is NannyML’s [Confidence-Based Performance Estimation (CBPE) algorithm](https://medium.com/towards-artificial-intelligence/estimating-model-performance-without-ground-truth-453b850dad9a).
    In a nutshell, the idea behind this approach is to estimate the elements of the
    confusion matrix based on the expected error rates, which we know assuming the
    model is well-calibrated.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，良好的模型校准是某些应用的先决条件。想象一下在不知道真实目标的情况下估计模型在生产中的性能。解决这个分类模型的挑战性任务的一种方法是 NannyML
    的 [基于置信度的性能估计（CBPE）算法](https://medium.com/towards-artificial-intelligence/estimating-model-performance-without-ground-truth-453b850dad9a)。简而言之，这种方法的核心思想是根据期望的错误率来估计混淆矩阵的元素，前提是我们知道模型经过良好的校准。
- en: So, if we want to monitor the model’s performance in production and we don’t
    immediately have ground truth targets, we need our model to be calibrated. And
    yet again, the model does not need to be of great accuracy. As long as its predictions
    are well-calibrated, it is good to go.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们想监控模型在生产中的表现而没有立即获得真实目标，我们需要对模型进行校准。然而，模型的准确性并不需要很高，只要它的预测经过良好的校准，就可以使用。
- en: 'We don’t need calibration: ranking problems'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们不需要校准：排序问题
- en: There are situations, however, in which the model’s calibration does not really
    matter much. These include all sorts of ranking problems, for instance.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有些情况下，模型的校准并不那么重要。例如，所有类型的排序问题。
- en: Think about models that rank news article titles in terms of quality or relevance
    to the user’s search query. If the goal is to select one or more articles to show
    the user, we don’t really care about the exact probability that each of them is
    high-quality and relevant; rather, we care about the order of scores produced
    by the model. That is, we want to be sure that what we show the user is better
    than what we don’t show, and that the best news sit on top of the results list.
    In this setting, calibrating the model does not make much sense.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 想想那些根据质量或与用户搜索查询的相关性对新闻文章标题进行排名的模型。如果目标是选择一个或多个文章展示给用户，我们并不关心每篇文章是否具有高质量和相关性的确切概率；相反，我们关心的是模型产生的分数的排序。也就是说，我们希望确保展示给用户的内容优于未展示的内容，并且最好的新闻排在结果列表的顶部。在这种情况下，校准模型并没有太大意义。
- en: 'We don’t need calibration: granting loans'
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们不需要校准：授予贷款
- en: Another example of a scenario in which calibration is not that important is
    screening for granting a loan which we have already mentioned.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个校准不那么重要的场景是我们之前提到的贷款授予筛选。
- en: The goal here is to predict which applicants will pay their loans back. In this
    binary classification problem, the bank is mostly interested in the accuracy of
    the model’s classification rather than the probabilities it produces.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的目标是预测哪些申请者会偿还贷款。在这个二分类问题中，银行主要关注模型分类的准确性，而不是它产生的概率。
- en: Depending on how the model will be used, good calibration may be either indispensable
    or rather unnecessary.
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 根据模型的使用方式，良好的校准可能是必不可少的，也可能是相对不必要的。
- en: Let’s now take a look at some models that are poor in terms of performance,
    but their good calibration renders them very useful for their intended purposes.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看一些在性能方面较差的模型，但它们的良好校准使其在预期的用途上非常有用。
- en: '![](../Images/75d563ec9011ce2508cbf4feb267de73.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75d563ec9011ce2508cbf4feb267de73.png)'
- en: A story of a poor, well-calibrated model
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个校准良好的差模型的故事
- en: Let’s consider two different models. First, we will look at one where good performance
    is hard to get, but good calibration ensures the model provides value. Second,
    we will consider a model theoretically incapable of good performance, but well-calibrated
    and thus useful.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑两个不同的模型。首先，我们将查看一个在性能上难以获得良好表现的模型，但良好的校准确保了模型提供了价值。其次，我们将考虑一个理论上无法获得良好表现的模型，但它经过良好校准，因此仍然有用。
- en: When it’s hard to get a good performance
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 当很难获得良好表现时
- en: Some time ago, I have been training models to predict the results of football
    (a.k.a. soccer) matches with the goal of getting rich quickly and effortlessly
    by betting at a bookie. Predicting a match result accurately is an impossible
    task — there are too many hidden factors involved such as luck and the players’
    disposition of the day. But guess what, getting accurate predictions is not what
    we need! Just like in the credit line assignment and performance estimation examples,
    here too, the game is all about getting the probabilities right.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一段时间之前，我一直在训练模型来预测足球（也就是足球比赛）的结果，目标是通过在博彩公司下注快速且轻松地致富。准确预测比赛结果是一项不可能完成的任务——涉及到的隐藏因素太多，例如运气和球员当天的状态。但你猜怎么着，准确的预测并不是我们需要的！就像在信用额度分配和绩效评估的例子中一样，这里也是，游戏的关键在于获得正确的概率。
- en: Consider this binary random forest classifier trained to predict whether the
    home team will win the game. It was trained on a couple of seasons of the English
    Premier League matches, and the feature set included the [ELO ratings](https://en.wikipedia.org/wiki/Elo_rating_system)
    of both teams as well as many different statistics summing up how good each team
    was in the recent games with respect to attack and defense.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这个二元随机森林分类器，它被训练来预测主队是否会赢得比赛。它是在几个赛季的英超联赛比赛上训练的，特征集包括了两个队伍的[ELO 评分](https://en.wikipedia.org/wiki/Elo_rating_system)以及许多不同的统计数据，汇总了每个球队在近期比赛中的进攻和防守表现。
- en: The model’s test accuracy was 63%. This is certainly better than a dummy model
    which always predicts the home team to win; such a model would score 46% as the
    hosts tend to win almost half of the games. That said, 63% does not seem to be
    a great result.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的测试准确率为63%。这肯定比一个总是预测主队获胜的虚拟模型要好；这样的模型会得到46%的准确率，因为主队几乎赢得了半数的比赛。也就是说，63%似乎不是一个很好的结果。
- en: Let’s take a look at the model’s calibration plot. The horizontal axis shows
    the probabilities produced by the model for the test set, binned into 10 equal-width
    bins. For each, the actual frequency of home wins is shown on the vertical axis.
    A perfectly calibrated model would produce a straight diagonal line.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看模型的校准图。水平轴显示了模型为测试集产生的概率，分为10个等宽的区间。对于每一个区间，主队获胜的实际频率显示在垂直轴上。一个完全校准的模型将产生一条完美的对角线。
- en: '![](../Images/2eac88bc7a58b8857662544e077fa1d5.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2eac88bc7a58b8857662544e077fa1d5.png)'
- en: Football predictor’s calibration curves. Image by the author.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 足球预测器的校准曲线。图片由作者提供。
- en: 'The original model, shown in blue, is very poorly calibrated at more extreme
    probabilities: a prediction of 90% has only a 30% chance of being correct! Hence,
    I decided to calibrate it using one of the most popular techniques: [fitting a
    logistic regressor on top of the model’s outputs](/calibrating-classifiers-559abc30711a).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 原始模型，显示为蓝色，在更极端的概率下校准效果很差：90%的预测仅有30%的正确率！因此，我决定使用最流行的技术之一来进行校准：[在模型输出上拟合逻辑回归器](/calibrating-classifiers-559abc30711a)。
- en: The resulting model, shown in green, seems to be much better calibrated. You
    will surely notice, too, that it does not produce extreme probabilities anymore.
    As far as accuracy is concerned, it dropped by one percentage point, to 62%. So,
    we managed to improve the model’s calibration at the cost of accuracy. How is
    this useful?
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 结果模型，显示为绿色，似乎校准效果好得多。你也会注意到，它不再产生极端概率。至于准确率，它下降了一个百分点，降至62%。因此，我们成功地提高了模型的校准水平，但准确率有所下降。这有什么用呢？
- en: 'Consider the following strategy: we will only bet on matches in which the model
    is the most certain that the home team will win, so the ones for which it produces
    a prediction of 70%. Thanks to reasonably good calibration, we know the model
    will be correct in 70% of such cases. For simplicity, assume we are betting $100
    on each game separately.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下策略：我们只对模型最确定主队会赢的比赛进行投注，即模型预测主队胜率为70%的比赛。得益于合理的校准，我们知道模型在这种情况下的正确率为70%。为了简化起见，假设我们对每场比赛分别投注$100。
- en: 'Out of 100 games, we will miss 30, which will yield us a loss of $3000\. But
    we will win the remaining 70 bets, and the cash prize will be `70 * 100 * (odds
    — 1)`(we subtract 1 to take into account that we need to spend $7000 on the coupons
    in the first place). We can solve this equation to find such bookie’s odds for
    which we break even:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在100场比赛中，我们将错过30场，造成$3000的损失。但我们将赢得剩下的70场比赛，现金奖励为`70 * 100 * (赔率 — 1)`（我们减去1是为了考虑到我们最初需要花费$7000购买彩票）。我们可以解这个方程，找到一个博彩公司赔率，使得我们收支平衡：
- en: '[PRE0]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: There we go! We can bet on all matches for which the model produces a 70% prediction
    and for which the bookie offers odds higher than 1.42 (disregarding the tax).
    We can, of course, compute the odds for other predicted probabilities in a similar
    fashion. Assuming the model’s calibration will stay good in the future (and this
    is a strong assumption!), this strategy should yield quite profitable in the long
    run. And all that despite the poor 62% accuracy!
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！我们可以对模型预测为70%的所有比赛进行投注，并且在这些比赛中，博彩公司提供的赔率需高于1.42（不考虑税）。当然，我们也可以以类似的方式计算其他预测概率的赔率。假设模型的校准在未来保持良好（这是一项强假设！），这种策略应该在长期内相当有利。尽管准确率只有62%，但这仍然有效！
- en: When it’s impossible to get a good performance
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 当无法获得良好的性能时
- en: Now consider an attempt to predict dice rolls. Our model should produce a probability
    of the die facing up six after it has been rolled. We assume that the die is just
    a regular, board game-type, six-sided, fair die.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在考虑预测掷骰子的尝试。我们的模型应该给出骰子掷出六的概率。我们假设骰子是普通的六面公平骰子。
- en: 'Rolling such a die is a completely stochastic process and the chance of each
    side facing up is the same: ⅙. In other words, the data classes are completely
    inseparable: it is not feasible to build an accurate model. What model can we
    have then?'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 掷骰子是一个完全随机的过程，每一面朝上的机会是相同的：⅙。换句话说，数据类别是完全不可分的：建立一个准确的模型是不切实际的。那么，我们可以拥有什么模型呢？
- en: 'Consider these two competing approaches. Model A is a dummy binary classifier
    that always predicts with full confidence that the rolled number is not a six;
    that is, it predicts a six 0% of the time and a not-six 100% of the time. Model
    B also never predicts a six but the probabilities it outputs are different: it
    always predicts a six with the probability of ⅙ and a not-six with the probability
    of ⅚.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这两种竞争方法。模型A是一个虚拟的二元分类器，它总是全信心地预测掷出的数字不是六；也就是说，它0%的时间预测六，100%的时间预测不是六。模型B也从不预测六，但它输出的概率不同：它总是以⅙的概率预测六，以⅚的概率预测不是六。
- en: 'In the long run, both models feature the same accuracy: they are correct 5
    out of 6 times. And this is as good as any model can get. However, an important
    fact differentiates between the two models: model B is perfectly calibrated while
    model A is not calibrated at all.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 从长远来看，这两个模型的准确率相同：它们的正确率为5/6。这是任何模型能达到的最好水平。然而，一个重要的事实区分了这两个模型：模型B的校准非常完美，而模型A根本没有校准。
- en: 'As far as calibration is concerned, the two models couldn’t be more different.
    How about the usefulness of the two models? Model A doesn’t really deliver any
    value. Model B, on the other hand, allows us to accurately predict the target
    frequency in the long run. It also allows us to run simulations to answer more
    complex questions such as: what is the probability of rolling four not-six and
    seven sixes in 11 rolls? Once again, despite the poor predictive performance,
    good calibration yields the model useful!'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 就校准而言，这两个模型截然不同。那么，这两个模型的有用性如何？模型A实际上没有提供任何价值。另一方面，模型B允许我们在长期内准确预测目标频率。它还允许我们进行模拟，以回答更复杂的问题，例如：在11次掷骰中，掷出四次不是六和七次六的概率是多少？尽管预测性能不佳，但良好的校准使模型依然有用！
- en: '![](../Images/75d563ec9011ce2508cbf4feb267de73.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75d563ec9011ce2508cbf4feb267de73.png)'
- en: Takeaways
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 要点
- en: Well-calibrated models produce predictions that are closely aligned with the
    frequency of the actual outcomes on aggregate. Most models are ill-calibrated
    because of the way they learn, but there are simple methods to fix this.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 校准良好的模型产生的预测与实际结果的频率高度一致。大多数模型由于学习方式的不同而校准不佳，但有一些简单的方法可以解决这个问题。
- en: For some applications, like assigning credit lines or CBPE estimation, good
    calibration is essential (in fact, more important than the performance metrics
    themselves). For others, such as granting loans or ranking problems, not very
    much so; here, correct rank ordering and performance are what matters.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于一些应用场景，如分配信用额度或 CBPE 估计，良好的校准至关重要（事实上，比性能指标本身更重要）。对于其他情况，比如贷款发放或排序问题，这一点则不那么重要；在这些场景中，正确的排序和性能才是关键。
- en: Inaccurate models can be pretty useful provided they are well-calibrated; sometimes
    getting the probabilities right is all we can do.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不准确的模型在经过良好校准后可能会非常有用；有时，确保概率的正确性就是我们能做到的全部。
- en: '*This article was also published on the* [*NannyML blog*](https://www.nannyml.com/blog/probability-calibration)*.*'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '*这篇文章也发表在* [*NannyML 博客*](https://www.nannyml.com/blog/probability-calibration)*上。*'
- en: '![](../Images/75d563ec9011ce2508cbf4feb267de73.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75d563ec9011ce2508cbf4feb267de73.png)'
- en: Thanks for reading!
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读！
- en: If you liked this post, why don’t you [**subscribe for email updates**](https://michaloleszak.medium.com/subscribe)
    on my new articles? And by [**becoming a Medium member**](https://michaloleszak.medium.com/membership),
    you can support my writing and get unlimited access to all stories by other authors
    and yours truly.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这篇文章，为什么不[**订阅电子邮件更新**](https://michaloleszak.medium.com/subscribe)以获取我最新的文章呢？通过[**成为
    Medium 会员**](https://michaloleszak.medium.com/membership)，你可以支持我的写作并无限制地访问其他作者及我自己的所有故事。
- en: Want to always keep your finger on the pulse of the increasingly faster-developing
    field of machine learning and AI? Check out my new newsletter, [**AI Pulse**](https://pulseofai.substack.com/).
    Need consulting? You can ask me anything or book me for a 1:1 [**here**](https://topmate.io/michaloleszak).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 想要时刻掌握机器学习和 AI 快速发展的领域的动态吗？查看我的新通讯，[**AI Pulse**](https://pulseofai.substack.com/)。需要咨询？你可以在[**这里**](https://topmate.io/michaloleszak)问我任何问题或预约一对一服务。
- en: 'You can also try one of [my other articles](https://michaloleszak.github.io/blog/).
    Can’t choose? Pick one of these:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以尝试一下[我的其他文章](https://michaloleszak.github.io/blog/)。无法选择？挑一个看看吧：
- en: '[](/calibrating-classifiers-559abc30711a?source=post_page-----7a856346fdf2--------------------------------)
    [## Calibrating classifiers'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/calibrating-classifiers-559abc30711a?source=post_page-----7a856346fdf2--------------------------------)
    [## 校准分类器'
- en: Are you sure your model returns probabilities? 🎲
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你确定你的模型返回的是概率吗？ 🎲
- en: towardsdatascience.com](/calibrating-classifiers-559abc30711a?source=post_page-----7a856346fdf2--------------------------------)
    [](https://pub.towardsai.net/estimating-model-performance-without-ground-truth-453b850dad9a?source=post_page-----7a856346fdf2--------------------------------)
    [## Estimating Model Performance without Ground Truth
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/calibrating-classifiers-559abc30711a?source=post_page-----7a856346fdf2--------------------------------)
    [](https://pub.towardsai.net/estimating-model-performance-without-ground-truth-453b850dad9a?source=post_page-----7a856346fdf2--------------------------------)
    [## 无需真实数据估计模型性能
- en: It’s possible, as long as you keep your probabilities calibrated
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 只要保持你的概率校准，这是可能的。
- en: pub.towardsai.net](https://pub.towardsai.net/estimating-model-performance-without-ground-truth-453b850dad9a?source=post_page-----7a856346fdf2--------------------------------)
    [](/feature-selection-methods-and-how-to-choose-them-1e7469100e7e?source=post_page-----7a856346fdf2--------------------------------)
    [## Feature Selection Methods and How to Choose Them
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: pub.towardsai.net](https://pub.towardsai.net/estimating-model-performance-without-ground-truth-453b850dad9a?source=post_page-----7a856346fdf2--------------------------------)
    [](/feature-selection-methods-and-how-to-choose-them-1e7469100e7e?source=post_page-----7a856346fdf2--------------------------------)
    [## 特征选择方法及如何选择它们
- en: The why, the how, and the when of feature selection, plus some handy tricks
    and tips
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征选择的原因、方法和时机，以及一些实用的技巧和建议
- en: towardsdatascience.com](/feature-selection-methods-and-how-to-choose-them-1e7469100e7e?source=post_page-----7a856346fdf2--------------------------------)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/feature-selection-methods-and-how-to-choose-them-1e7469100e7e?source=post_page-----7a856346fdf2--------------------------------)
