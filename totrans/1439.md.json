["```py\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.applications import resnet50\nfrom tensorflow.keras import backend\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\n```", "```py\n#model = tf.keras.applications.ResNet50()\ntf.keras.backend.set_learning_phase(0)\nmodel = resnet50.ResNet50()\n\n# Load the image file, resizing it to 224x224 pixels (required by this model)\nimg = image.load_img(\"dog.jpg\", target_size=(224, 224))\n# Convert the image to a numpy array\nx = image.img_to_array(img)\n# Add a forth dimension since Keras expects a list of images\nx = np.expand_dims(x, axis=0)\n\n# Scale the input image to the range used in the trained network\nx = resnet50.preprocess_input(x)\n\nprint(\"predicting model\")\npredictions = model.predict(x)\npredicted_classes = resnet50.decode_predictions(predictions, top=9)\nprint(predicted_classes)\n```", "```py\nexport_dir = \"00001\"\ntf.keras.backend.set_learning_phase(0)\nmodel = tf.keras.applications.ResNet50()\n\nif not os.path.exists(export_dir):\n    os.makedirs(export_dir)\n    print(\"Directory \", export_dir, \" Created \")\nelse:\n    print(\"Directory \", export_dir, \" already exists\")\n# Save to SavedModel\nmodel.save(export_dir, save_format=\"tf\", include_optimizer=False)\n```", "```py\n!tar -cvpzf model.tar.gz ./00001\n\n#upload data to S3\nmodel_url = sagemaker_session.upload_data(\n    path=\"model.tar.gz\", key_prefix=\"resnet-model-data\"\n)\n```", "```py\nimport json\npayload = json.dumps(x.tolist())\npayload_archive_name = \"payload.tar.gz\"\n\nwith open(\"payload.json\", \"w\") as outfile:\n    outfile.write(payload)\n\n#create payload tarball\n!tar -cvzf {payload_archive_name} payload.json\n\n#upload sample payload to S3\nsample_payload_url = sagemaker_session.upload_data(\n    path=payload_archive_name, key_prefix=\"resnet-payload\"\n)\n```", "```py\nimport sagemaker\nfrom sagemaker.model import Model\nfrom sagemaker import image_uris\n\nmodel = Model(\n    model_data=model_url,\n    role=role,\n    image_uri = sagemaker.image_uris.retrieve(framework=\"tensorflow\", region=region, version=\"2.1\", py_version=\"py3\", \n                                              image_scope='inference', instance_type=\"ml.m5.xlarge\"),\n    sagemaker_session=sagemaker_session\n    )\n```", "```py\nmodel_package = model.register(\n    content_types=[\"application/json\"],\n    response_types=[\"application/json\"],\n    model_package_group_name=model_package_group_name,\n    image_uri=model.image_uri,\n    approval_status=\"Approved\",\n    framework=\"TENSORFLOW\"\n)\n```", "```py\nmodel_package.right_size(\n    sample_payload_url=sample_payload_url,\n    supported_content_types=[\"application/json\"],\n    supported_instance_types=[\"ml.c5.xlarge\", \"ml.c5.9xlarge\", \"ml.c5.18xlarge\", \"ml.m5d.24xlarge\"],\n    framework=\"TENSORFLOW\",\n)\n```", "```py\nfrom sagemaker.parameter import CategoricalParameter \nfrom sagemaker.inference_recommender.inference_recommender_mixin import (  \n    Phase,  \n    ModelLatencyThreshold \n) \n\nhyperparameter_ranges = [ \n    { \n        \"instance_types\": CategoricalParameter([\"ml.m5.xlarge\", \"ml.g4dn.xlarge\"]), \n        'OMP_NUM_THREADS': CategoricalParameter(['1', '2', '3']), \n    } \n] \n```", "```py\nphases = [ \n    Phase(duration_in_seconds=120, initial_number_of_users=2, spawn_rate=2), \n    Phase(duration_in_seconds=120, initial_number_of_users=6, spawn_rate=2) \n]\n```", "```py\nmodel_latency_thresholds = [ \n    ModelLatencyThreshold(percentile=\"P95\", value_in_milliseconds=300) \n]\n```", "```py\nmodel_package.right_size( \n    sample_payload_url=sample_payload_url, \n    supported_content_types=[\"application/json\"], \n    framework=\"TENSORFLOW\", \n    job_duration_in_seconds=3600, \n    hyperparameter_ranges=hyperparameter_ranges, \n    phases=phases, # TrafficPattern \n    max_invocations=100, # StoppingConditions \n    model_latency_thresholds=model_latency_thresholds\n)\n```"]