- en: Enhance Content Moderation for ChatGPT with OpenAI’s Moderation API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/enhance-content-moderation-with-openais-moderation-api-bb0b865d883b](https://towardsdatascience.com/enhance-content-moderation-with-openais-moderation-api-bb0b865d883b)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Seamlessly integrate a moderation endpoint into your pipelines with ChatGPT
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://idilismiguzel.medium.com/?source=post_page-----bb0b865d883b--------------------------------)[![Idil
    Ismiguzel](../Images/6846628535770a9f3e13ebb555e82abd.png)](https://idilismiguzel.medium.com/?source=post_page-----bb0b865d883b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bb0b865d883b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bb0b865d883b--------------------------------)
    [Idil Ismiguzel](https://idilismiguzel.medium.com/?source=post_page-----bb0b865d883b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bb0b865d883b--------------------------------)
    ·6 min read·Jul 7, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c439a81f26c9a857d503a1d983e4752a.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Joshua Kettle](https://unsplash.com/@joshuakettle?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'Disclaimer: This article is focused on checking content compliance with moderation
    guidelines. As a result, there may be references to content involving violence,
    self-harm, hate, and sexual violence.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: With the rise of prompt engineering and remarkable achievements of Large Language
    Models in generating responses to our inquiries, chatbots like ChatGPT are becoming
    an integral part of our daily lives, and the applications we create. Whether you’re
    using AI models for personal purposes or leveraging their capabilities to develop
    advanced systems, it is important to make sure you use AI models in generating
    content that follows specific moderation guidelines and rules. ⚠️
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we will concentrate on OpenAI’s moderation endpoint, a great
    feature for checking content compliance with OpenAI’s usage policies. We’ll explore
    how to integrate moderation API into our systems that use ChatGPT and verify both
    inputs and outputs to ensure they meet desired guidelines.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re new to prompt engineering, I highly recommend checking out my article
    on [mastering prompt engineering](https://medium.com/towards-data-science/mastering-prompt-engineering-to-unleash-chatgpts-potential-9578a3fe799c)
    before diving in. It will provide you with insights to enhance your understanding.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/mastering-prompt-engineering-to-unleash-chatgpts-potential-9578a3fe799c?source=post_page-----bb0b865d883b--------------------------------)
    [## Mastering Prompt Engineering to Unleash ChatGPT’s Potential'
  prefs: []
  type: TYPE_NORMAL
- en: Explore best practices and enhance your prompts for better results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/mastering-prompt-engineering-to-unleash-chatgpts-potential-9578a3fe799c?source=post_page-----bb0b865d883b--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: What is content moderation?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Content moderation is the practice of reviewing and monitoring user-generated
    content to ensure it meets specific standards and guidelines. This involves removing
    inappropriate content and enforcing community guidelines to maintain a safe and
    respectful environment.
  prefs: []
  type: TYPE_NORMAL
- en: Any system that leverages large language models and relies on user-generated
    or AI-generated content, should perform content moderation and automate the process
    of identifying and filtering out inappropriate or offensive content.
  prefs: []
  type: TYPE_NORMAL
- en: What is moderation endpoint?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The moderation endpoint is freely accessible for monitoring both the inputs
    and outputs of OpenAI APIs. It utilizes specific categories to assign a category
    result based on the corresponding category score.
  prefs: []
  type: TYPE_NORMAL
- en: Below is a list of categories and subcategories used by the model to classify
    content. Subcategories like `“Hate/threatening”` exist to enable more precise
    moderation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The moderation output returns three variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '`category flags:` These are boolean flags assigned to each category and subcategory,
    indicating their presence or absence in the content.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`category scores` Each category and subcategory is assigned a score between
    0 and 1, representing the confidence level. A score closer to 1 indicates higher
    confidence in the presence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`flagged:` This variable is set to True if the input is identified as content
    that violates guidelines, and False otherwise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s learn how we can do content moderation on a given text.
  prefs: []
  type: TYPE_NORMAL
- en: How to use moderation API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To use moderation endpoint, you must log into your OpenAI account and generate
    your API key by navigating to the “View API Keys” section from the right top corner.
    Once you created your API key, you need to store it in a safe place and not display
    it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: After setting this up, we can call `openai.Moderation.create()` and give the
    input content that we want to run content moderation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/c6b3099af566d3b6c1db67f10b2fdff9.png)'
  prefs: []
  type: TYPE_IMG
- en: Output of content moderation
  prefs: []
  type: TYPE_NORMAL
- en: The content moderation output indicates that the overall text has been flagged
    as violating guidelines, as evidenced by the `flagged=True.` Specifically, `Self-harm/intent`
    subcategory has been identified as `True`. Furthermore, category scores reveal
    high confidence levels, with `self-harm=0.99` and `self-harm/intent=0.99.`
  prefs: []
  type: TYPE_NORMAL
- en: How to integrate content moderation checks into the pipeline?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, we will write a helper function that takes our prompt and returns a completion
    for that prompt.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s create a function that incorporates content moderation.
  prefs: []
  type: TYPE_NORMAL
- en: First, it will perform moderation checks on the prompt, and if the prompt violates
    guidelines, it will return “We cannot provide a response to this request.”
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the prompt passes moderation checks, it will generate a response using the
    `get_completion` helper function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the response is generated, it will undergo content moderation checks. If
    the response passes these checks, it will be displayed to the user. However, if
    the response violates guidelines, it will return “We cannot provide a response
    to this request.”
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Let’s run it with our test prompt.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Prompt flagged by Moderation API because it does not comply with the content
    policy.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Sorry, we cannot provide a response to this request.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The moderation check has effectively identified that the prompt contains text
    that does not adhere to the guidelines. Now, let’s proceed to test another example.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Prompt passed content moderation check.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: GPT’s response passed content moderation check.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I’m not a certified nutritionist or healthcare professional, but I can provide
    some general tips that may help you with weight loss…
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Excellent! The prompt as well as GPT’s response have successfully passed the
    moderation checks, and the response can now be displayed to the user.
  prefs: []
  type: TYPE_NORMAL
- en: What is next?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have learned how to reduce violations and unsafe content in our application,
    but achieving 100% compliance can still be challenging…
  prefs: []
  type: TYPE_NORMAL
- en: As an extra step, you may consider developing an additional layer of content
    filtering that is tailored specifically for your use case. This might be based
    on the original moderation but you can adjust the category score thresholds to
    better suit your needs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Furthermore, OpenAI recommends the practice of “red-teaming” your application
    whenever feasible to ensure its resilience against adversarial input. It is also
    crucial to extensively test the system with diverse inputs and user behaviors.
    Additionally, involving human reviewers in the loop to review the generated outputs
    before deploying the system into production is a valuable consideration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition, it is recommended to keep the input token length limited to improve
    accuracy of the moderation classifier. Similarly, limiting output token length
    can reduce the likelihood of generating problematic content.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By implementing these strategies, you can further strengthen content moderation,
    enhance overall robustness, and maintain a safer output in your application. You
    can read the full list of safety best practices [here](https://platform.openai.com/docs/guides/safety-best-practices).
  prefs: []
  type: TYPE_NORMAL
- en: One final point to consider is that the moderation API is continually evolving
    and improving. Consequently, your results may vary as the API undergoes changes.
    Additionally, it’s important to note that support for non-English languages is
    currently limited.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article, we explored the concept of content moderation within the framework
    of complying with usage policies. We also discovered how we can leverage the moderation
    API to evaluate user-generated prompts and GPT-generated responses, ensuring they
    align with the rules and guidelines. We also discussed recommended next steps
    and safety best practices to consider before deploying our systems into production.
  prefs: []
  type: TYPE_NORMAL
- en: I hope this tutorial has inspired you to utilize large language models while
    prioritizing the creation of a safe and respectful environment. As you may have
    noticed, with just a few simple functions, we were able to effectively identify
    violations within the provided content and improve our system.
  prefs: []
  type: TYPE_NORMAL
- en: 🍓 If you enjoy reading articles like this and wish to support my writing, you
    may consider [becoming a Medium member](https://idilismiguzel.medium.com/membership)!
    Medium members get full access to articles from all writers and if you use [my
    referral link](https://idilismiguzel.medium.com/membership), you will be directly
    supporting my writing.
  prefs: []
  type: TYPE_NORMAL
- en: 🍓 If you are already a member and interested to read my articles, you can [subscribe
    to be notified](https://medium.com/subscribe/@idilismiguzel) or [follow me on
    Medium](https://idilismiguzel.medium.com/). Let me know if you have any questions
    or suggestions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Additional resources I recommend after this article:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned earlier, I recommend checking out my article on prompt engineering.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/mastering-prompt-engineering-to-unleash-chatgpts-potential-9578a3fe799c?source=post_page-----bb0b865d883b--------------------------------)
    [## Mastering Prompt Engineering to Unleash ChatGPT’s Potential'
  prefs: []
  type: TYPE_NORMAL
- en: Explore best practices and enhance your prompts for better results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/mastering-prompt-engineering-to-unleash-chatgpts-potential-9578a3fe799c?source=post_page-----bb0b865d883b--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs: []
  type: TYPE_NORMAL
- en: '[OpenAI usage policies](https://openai.com/policies/usage-policies)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[OpenAI moderation endpoint](https://platform.openai.com/docs/guides/moderation/overview)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[OpenAI safety best practices](https://platform.openai.com/docs/guides/safety-best-practices)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Header Photo by [Joshua Kettle](https://unsplash.com/@joshuakettle?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
