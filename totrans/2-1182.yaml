- en: How to Find the Best Theoretical Distribution for Your Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-find-the-best-theoretical-distribution-for-your-data-a26e5673b4bd](https://towardsdatascience.com/how-to-find-the-best-theoretical-distribution-for-your-data-a26e5673b4bd)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Knowing the underlying data distribution is an essential step for data modeling
    and has many applications, such as anomaly detection, synthetic data creation,
    and data compression.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://erdogant.medium.com/?source=post_page-----a26e5673b4bd--------------------------------)[![Erdogan
    Taskesen](../Images/8e62cdae0502687710d8ae4bbcd8966e.png)](https://erdogant.medium.com/?source=post_page-----a26e5673b4bd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a26e5673b4bd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a26e5673b4bd--------------------------------)
    [Erdogan Taskesen](https://erdogant.medium.com/?source=post_page-----a26e5673b4bd--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a26e5673b4bd--------------------------------)
    ·19 min read·Feb 3, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/88e75fd6c664a30e948bcf9ad06e421d.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing the underlying (probability) distribution of your data has many modeling
    advantages. The easiest manner to determine the underlying distribution is by
    visually inspecting the random variable(s) using a histogram. With the candidate
    distribution, various plots can be created such as the Probability Distribution
    Function plot (PDF/CDF), and the QQ plot. However, to determine the exact distribution
    parameters (e.g., loc, scale), it is essential to use quantitative methods. In
    this blog, I will describe *why it is important to determine the underlying probability
    distribution for your data set. What the differences are between parametric and
    non-parametric distributions. How to determine the best fit using a quantitative
    approach and how to confirm it using visual inspections.* Analyses are performed
    using the *distfit* library, and a notebook is accompanied for easy access and
    experimenting.
  prefs: []
  type: TYPE_NORMAL
- en: '*If you find this article helpful, you are welcome to* [*follow me*](https://erdogant.medium.com/subscribe)
    *because I write more about Data Science. If you are thinking of taking a Medium
    membership, you can support my work a bit by using my referral link. It is the
    same price as a coffee but this allows you to read unlimited articles every month.*'
  prefs: []
  type: TYPE_NORMAL
- en: The importance of distribution fitting and Probability Density Functions.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '***The probability density function*** is a fundamental concept in statistics.
    Briefly, *for a given random variable X, we aim to specify the function f that
    gives a natural description of the distribution of X. See also the terminology
    section at the bottom for more about probability density functions.* Although
    there is a lot of great material that describes these concepts [1]*,* it can remain
    challenging to understand why it is important to know the underlying data distribution
    for your data set. Let me try to explain the importance with a small analogy.
    *Suppose you need to go from location A to B, which type of car would you prefer?*
    The answer is straightforward. You will likely start with exploring the terrain.
    With that information, you can then select the best-suited car (sports car, four-wheel
    drive, etc). Logically, a sports car is better suited for smooth, flat terrain,
    while a four-wheel drive is better suited for rough, hilly terrain. In other words,
    without the exploratory analysis of the terrain, it can be hard to select the
    best possible car. ***However, such an exploratory step is easily forgotten or
    neglected in data modeling.***'
  prefs: []
  type: TYPE_NORMAL
- en: Before making modeling decisions, you need to know the underlying data distribution.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: When it comes to data, it is important to explore the fundamental characteristics
    of the data too, such as skewness, kurtosis, outliers, distribution shape, univariate,
    bimodal, etc. Based on these characteristics it is easier to decide which models
    are best to use because most models have prerequisites for the data. As an example,
    a well-known and popular technique is Principal Component Analysis (PCA). This
    method computes the covariance matrix and requires the data to be multivariate
    normal for the PCA to be valid. In addition, a PCA is also known to be sensitive
    to outliers. Thus, before doing a PCA step, you need to know whether your data
    needs a (log)normalization or whether outliers need to be removed. More details
    about PCA can be found [here](/what-are-pca-loadings-and-biplots-9a7897f2e559)
    [2].
  prefs: []
  type: TYPE_NORMAL
- en: Histograms can build a sense of intuition.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The histogram is a well-known plot in data analysis which is a graphical representation
    of the distribution of the dataset. The histogram summarizes the number of observations
    that fall within the bins. With libraries such as `matplotlib hist()` it is straightforward
    to make a visual inspection of the data. Changing the range of the number of bins
    will help to identify whether the density looks like a common probability distribution
    by the shape of the histogram. An inspection will also give hints whether the
    data is symmetric or skewed and whether it has multiple peaks or outliers. In
    most cases, you will observe a distribution shape as depicted in Figure 1.
  prefs: []
  type: TYPE_NORMAL
- en: '***The bell shape*** of the Normal distribution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***The descending or ascending shape*** of an Exponential or Pareto distribution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***The flat shape*** of the Uniform distribution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***The complex shape*** that does not fit any of the theoretical distributions
    (e.g, multiple peaks).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/5c878e2d91f9d023650ec749040482de.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1\. The common distribution types. Figures are created using the distfit
    library and can be further explored in the Colab notebook (link at the bottom).
    (image by the author).
  prefs: []
  type: TYPE_NORMAL
- en: In case you find distributions with multiple peaks (bimodal or multimodal),
    the peaks should not disappear with different numbers of bins. Bimodal distributions
    usually hint toward mixed populations. In addition, if you observe large spikes
    in density for a given value or a small range of values, it may point toward possible
    outliers. Outliers are expected to be far away from the rest of the density.
  prefs: []
  type: TYPE_NORMAL
- en: A histogram is a great manner to inspect a relatively small number of samples
    (random variables, or data points). However, when the number of samples increase
    or more than two histograms are plotted, the visuals can become troublesome, and
    a visual comparison with a theoretical distribution difficult to judge. Instead,
    a Cumulative Distribution Function (CDF) plot or Quantile-Quantile plot (QQ plot)
    can be more insightful. But these plots require a candidate theoretical distribution(s)
    that best matches (or fits) with the empirical data distribution. So let’s determine
    the best theoretical distribution in the next section! *See also the terminology
    section at the bottom for more information about random variables and theoretical
    distributions.*
  prefs: []
  type: TYPE_NORMAL
- en: Four steps to determine the theoretical distribution.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A PDF fit for an empirical data distribution can be discovered in four steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Compute density and weights from a histogram.** The first step is to flatten
    the data into an array and create the histogram by grouping observations into
    bins and counting the number of events in each bin. The choice of the number of
    bins is important as it controls the coarseness of the distribution. Experimenting
    with different bin sizes can provide multiple perspectives on the same data. In
    *distfit*, the bin width can be manually defined or mathematically determined
    on the observations themselves. The latter option is the default.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Estimate the distribution parameters from the data.** In a parametric approach,
    the next step is to estimate the shape, location, and scale parameters based on
    the (selected) theoretical distribution(s). This typically involves methods such
    as maximum likelihood estimation (MLE) to determine the values of the parameters
    that best fit the data. For example, if the normal distribution is chosen, the
    MLE method will estimate the mean and standard deviation of the data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Check the goodness-of-fit**. Once the parameters have been estimated, the
    fit of the theoretical distribution is evaluated. This can be done using a goodness-of-fit
    test. Popular statistical tests are *Residual Sum of Squares (RSS, also named
    SSE), Wasserstein, Kolmogorov-Smirnov, and the Energy test (also available in
    distfit)*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Selection of best theoretical distribution.** At this point, theoretical
    distributions are tested and scored using the goodness-of-fit test statistic.
    The scores can now be sorted and the theoretical distribution with the best score
    can be selected.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As a final step, the model can be validated using methods such as cross-validation,
    bootstrapping, or a holdout dataset. It is essential to check if the model is
    generalizing well and also to check if the assumptions such as independence and
    normality are met. Once the theoretical distribution has been fitted and validated,
    it can be used in many applications (keep on reading in the section below).
  prefs: []
  type: TYPE_NORMAL
- en: Distribution fitting has great benefits when working in the field of data science.
    It is not only to better understand, explore, and prepare the data but also to
    bring fast and lightweight solutions.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The distfit library finds the best fit for your data.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '***Distfit***is a python package for *probability density fitting* of univariate
    distributions for random variables. It can find the best fit for parametric, non-parametric,
    and discrete distributions. In addition, it provides visual insights for better
    decision-making using various plots. A summary of the most important functionalities:'
  prefs: []
  type: TYPE_NORMAL
- en: With the distfit library it is easy to find the best theoretical distribution
    with only a few lines of code.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Finds the best fit** for *parametric, non-parametric, and discrete distributions.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prediction** of outliers/novelties for (new) unseen samples [[10]](/outlier-detection-using-distribution-fitting-in-univariate-data-sets-ac8b7a14d40e).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generates synthetic data** based on the fitted distribution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Plots:** Histograms, Probability Density Function plots, Cumulative Density
    Function plots (CDF), Histograms, Quantile-Quantile plots (QQ-plot), Probability
    plots, and Summary plots.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Saving and loading** models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Installation** is straightforward and can be done from PyPi.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: How to identify the best fit using parametric fitting?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With parametric fitting, we make assumptions about the parameters of the population
    distribution from the input data. Or in other words, the shape of the histogram
    should match any of the known theoretical distributions. The ***advantage*** of
    parametric fitting is that it is computationally efficient and the results are
    easy to interpret. The ***disadvantage*** is that it can be sensitive to outliers
    when having a low number of samples. The *distfit* library can determine the best
    fit across 89 theoretical distributions which are utilized from the *scipy* library.
    To score the fit, there are four ***goodness-of-fit*** statistical tests; *Residual
    Sum of Squares (RSS or SSE), Wasserstein, Kolmogorov-Smirnov (KS), and Energy*.
    For each fitted theoretical distribution, the loc, scale, and arg parameters are
    returned, such as mean and standard deviation for normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the best matching theoretical distribution for your data set requires
    a goodness-of-fit statistical test.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In the following example, we will generate data from the normal distribution
    with `mean=2` and `standard deviation=4`. We will use *distfit* to estimate these
    two parameters from the data itself. If you already know the family of distributions
    (e.g., bell-shape), you can specify a subset of distributions. The default is
    a subset of common distributions (as depicted in Figure 1). *Note that due to
    the stochastic component, results can differ from what I am showing when repeating
    the experiment.*
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The best fit that is detected (i.e., with the lowest RSS score) is the `loggamma`
    distribution. The results of the best fit are stored `dfit.model` but we can also
    inspect the fit for all other PDFs as depicted in `dfit.summary` (see code section
    below) and create a plot (Figure 2).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/fd5776a05784387f5612c73344cd2dc6.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2\. PDFs are sorted on the goodness-of-fit scoring test. (image by the
    author)
  prefs: []
  type: TYPE_NORMAL
- en: '**But why did the normal distribution not have the lowest Residual Sum of Squares
    despite we generated random normal data?**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Well, first of all, our input data set will always be a finite list that is
    bound within a (narrow) range. In contradition, the theoretical (normal) distribution
    goes to infinity in both directions. Secondly, all statistical analyses are based
    on models, and all models are merely simplifications of the real world. Or in
    other words, to approximate the theoretical distributions, we need to use multiple
    statistical tests, each with its own (dis)advantages. Finally, some distributions
    have a very flexible character for which the (log)gamma is a clear example. For
    a large k, the gamma distribution converges to normal distribution [4].
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The result is that the top 7 distributions have a similar and low RSS score,
    among them the normal distribution. We can see in the summary statistics that
    the estimated parameters for the normal distribution are `loc=2.036` and `scale=3.97`,
    which is very close to our initially generated random sample population (`mean=2`,
    `std=4`). All things considered, A very good result.
  prefs: []
  type: TYPE_NORMAL
- en: Bootstrapping for more confidence.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can further validate our fitted model using a bootstrapping approach and
    the Kolmogorov-Smirnov (KS) test to assess the goodness of fit [9]. If the model
    is overfitting, the KS test will reveal a significant difference between the bootstrapped
    samples and the original data, indicating that the model is not representative
    of the underlying distribution. In *distfit*, the `n_bootst` parameter can be
    set during initialization or afterward (see code section).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/ee1e1d06985f73ff5ebfa8a0cdb4e71b.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2B. Bootstrap results. PDFs are sorted on the bootstrap score and the
    goodness of fit test. (image by the author)
  prefs: []
  type: TYPE_NORMAL
- en: The plot contains on the left axes the goodness of fit test and on the right
    axes (orange line) the bootstrap result. The bootstrap score is a value between
    [0, 1] and depicts the fit-success ratio for the number of bootstraps and the
    PDF. In addition, the green and red dots depict whether there was a significant
    difference between the bootstrapped samples and the original data. The bootstrap
    test now excludes a few more PDFs that showed no stable results.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is good to realize now that the statistical tests only help you to look
    in the right direction, and that ***choosing the best model is not only a statistical
    question; it is also a modeling decision*** *[5]****.*** Think about this: the
    `loggamma` distributions are heavily right-tailed, while the `normal` distribution
    is symmetrical (both tails are similar). This can make a huge difference when
    using confidence intervals and predicting outliers in the tails. Choose your distribution
    wisely so that it matches the application.'
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the best model is not a statistical question; it is a modeling decision.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Plots guide towards a better decision.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A best practice is to use both statistics and a visual curation to decide what
    the best distribution fit is. Using the PDF/CDF and QQ plots can be some of the
    best tools to guide those decisions. As an example, Figure 2 illustrates the goodness-of-fit
    test statistics for which the first 7 PDFs have a very similar and low RSS score.
    The `dweibull` distribution is ranked number 8, with also a low RSS score. However,
    a visual inspection will learn us that, despite having a relatively low RSS score,
    it is not a good fit after all.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start plotting the empirical data using a histogram and the PDF*.* These
    plots will help to visually guide whether a distribution is a good fit. We can
    see in Figure 3 the PDF (left) with the confidence intervals and on the right
    side the CDF plot. The confidence intervals are automatically set to 95% CII but
    can be changed using the `alpha` parameter during initialization. When using the
    plot functionality, it automatically shows the histogram in bars and with a line,
    PDF/CDF, and confidence intervals. All these properties can be manually customized
    (see code section below).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/1b5de20e931be2604de625409e4946f3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3\. In both panels is shown the Empirical data distribution with the
    confidence intervals. Left panel: Histogram with PDF. Right panel: CDF. (image
    by the author)'
  prefs: []
  type: TYPE_NORMAL
- en: We can also plot all other estimated theoretical distributions with the `n_top`
    parameter. A visual inspection confirms that the top 8 distributions have a very
    close fit with the empirical data with few exceptions. *Note that the bootstrap
    approach revealed that not all fits were stable.* The distributions in the legend
    of the plot are ranked from best fit (highest) to worst fit (lowest). Here we
    can see that the`dweibull` distribution has a very poor fit with two peaks in
    the middle. Using only the RSS score would have been difficult to judge whether
    or not to use this distribution. The distributions `uniform`, `exponent`, and
    `pareto` readily showed a poor RSS score and is now confirmed using the plot.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/3d3b292cd542e10a9ee75f3eb400542b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4\. left: PDF, and right: CDF. All fitted theoretical distributions
    are shown in different colors. (image by the author)'
  prefs: []
  type: TYPE_NORMAL
- en: Quantile-Quantile plot.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There is one more plot that we can inspect, which is the QQ plot. The QQ plot
    compares the empirical probability distributions vs. the theoretical probability
    distributions by plotting their quantiles against each other. If the two distributions
    are equal then the points on the QQ-plot will perfectly lie on a straight line
    `y = x`. We can make the QQ-plot using the `qqplot` function (Figure 5). The left
    panel shows the best fit, and the right panel includes all fitted theoretical
    distributions. More details on how to interpret the QQ plot can be found in this
    blog [3].
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/77cdd694f8964fa9afc95df5a8e7c31f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5\. Left panel: Comparison between empirical distribution vs. best theoretical
    distribution. Right panel: Comparison between empirical distribution vs. all other
    theoretical distributions. (image by the author)'
  prefs: []
  type: TYPE_NORMAL
- en: Identify the best distribution fit using non-parametric fitting.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Non-parametric Density Estimation is when the population sample is “*distribution-free"*
    meaning that data do not resemble a common theoretical distribution. In *distfit*,
    two non-parametric methods are implemented for non-parametric density fitting:
    the ***quantile*** and ***percentile*** methods. Both methods assume that the
    data does not follow a specific probability distribution. In the case of the *quantile
    method*, the quantiles of the data are modeled which can be useful for data with
    skewed distributions. In the case of the *percentile method*, the percentiles
    are modeled which can be useful when data contains multiple peaks. In both methods,
    the *advantage* is that it is robust to outliers and does not make assumptions
    about the underlying distribution. In the code section below we initialize using
    the method `method=''quantile''` or `method=''percentile''`. All functionalities,
    such as predicting, and plotting can be used in the same manner as shown in the
    previous code sections.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Identify the best distribution for discrete data.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In case the random variables are discrete, the *distift library* contains the
    option for ***discrete fitting.*** The best fit is derived using the binomial
    distribution. The questions can be summarized as follows: given a list of nonnegative
    integers, can we fit a probability distribution for a discrete distribution, and
    compare the quality of the fit? For discrete quantities, the correct term is Probability
    Mass Function (PMF). As far as discrete distributions go, the PMF for one list
    of integers is of the form P(k) and can only be fitted to the binomial distribution,
    with suitable values for `n` and `p`, and this method is implemented in *distfit*.
    See the code section below where a discrete dataset is created with `n=8` and
    `p=0.5`. The random variables are given as input to *distfit* which detected the
    parameters `n=8` and `p=0.501366`, indicating a very good fit.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Plot the results with the `plot` functionality.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/1339c5e518c284cf21766c01752e2316.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7\. The top figure shows the input data (black dots), and the fitted
    distribution (blue line). The detected parameters (n=8 and p=0.501366) are very
    well fitted, given that the generated random variables (n=8, p=0.5). The red vertical
    bars are the confidence intervals that are set to 0.05 (default). The bottom figure
    shows the RSS score over n scans. The best fit is detected with the lowest RSS.
    (image by the author)
  prefs: []
  type: TYPE_NORMAL
- en: Applications of distribution fitting.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Knowing the underlying distribution in your data set is key in many applications.
    I will summarize a few.
  prefs: []
  type: TYPE_NORMAL
- en: '**Anomaly/novelty detection** is a clear application of density estimation.
    This can be achieved by calculating the confidence intervals given the distribution
    and parameters. The *distfit* library computes the confidence intervals, together
    with the probability of a sample being an outlier/novelty given the fitted distribution.
    A small example is shown in the code section below but follow the link for a deep
    dive.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](/outlier-detection-using-distribution-fitting-in-univariate-data-sets-ac8b7a14d40e?source=post_page-----a26e5673b4bd--------------------------------)
    [## Outlier Detection Using Distribution Fitting in Univariate Datasets'
  prefs: []
  type: TYPE_NORMAL
- en: Learn how to detect outliers using Probability Density Functions for fast and
    lightweight models and explainable…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/outlier-detection-using-distribution-fitting-in-univariate-data-sets-ac8b7a14d40e?source=post_page-----a26e5673b4bd--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '**Synthetic data**: Probability distribution fitting can be used to generate
    synthetic data that mimics real-world data. By fitting a probability distribution
    using real-world data, it is possible to generate synthetic data that can be used
    to test hypotheses and evaluate the performance of algorithms. The code section
    below shows a small example of how to generate random variables from a normal
    distribution by estimating the distribution parameters. In-depth details can be
    found in this blog:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](/step-by-step-guide-to-generate-synthetic-data-by-sampling-from-univariate-distributions-6b0be4221cb1?source=post_page-----a26e5673b4bd--------------------------------)
    [## Step-by-Step Guide to Generate Synthetic Data by Sampling From Univariate
    Distributions.'
  prefs: []
  type: TYPE_NORMAL
- en: Learn how to create synthetic data in case your project runs low on data or
    use it for simulations.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/step-by-step-guide-to-generate-synthetic-data-by-sampling-from-univariate-distributions-6b0be4221cb1?source=post_page-----a26e5673b4bd--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '**Optimization and compression**: Probability distribution fitting can be used
    to optimize various parameters of a probability distribution, such as the mean
    and variance, to best fit the data. Finding the best parameters can help to better
    understand the data. In addition, if hundreds of thousands of observations can
    be described with only the loc, scale, and arg parameters, it is a very strong
    compression of the data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**An informal investigation** of the properties of the input dataset is a very
    natural use of density estimates. Density estimates can give valuable indications
    of skewness and multimodality in the data. In some cases, they will yield conclusions
    that may then be regarded as self-evidently true, while in others, they will point
    the way to further analysis and data collection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Testing hypotheses**: Probability distribution fitting can be used to test
    hypotheses about the underlying probability distribution of a data set. For example,
    one can use a goodness-of-fit test to compare the data to a normal distribution
    or a chi-squared test to compare the data to a Poisson distribution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Modeling**: Probability distribution fitting can be used to model complex
    systems such as weather patterns, stock market trends, biology, population dynamics,
    and predictive maintenance. By fitting a probability distribution to historical
    data, it is possible to extract valuable insights and create a model that can
    be used to make predictions about future behavior.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Final words.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I touched on the concepts of probability density fitting for parametric, non-parametric,
    and discrete random variables. With the *distfit* library, it is straightforward
    to detect the best theoretical distribution among 89 theoretical distributions.
    It pipelines the process of density estimation of histograms, estimating the distribution
    parameters, testing for the goodness of fit, and returning the parameters for
    the best-fitted distribution. The best fit can be explored with various plot functionalities,
    such as Histograms, CDF/PDF plots, and QQ plots. All plots can be customized and
    easily combined. In addition, predictions can be made on new unseen samples. Another
    functionality is the creation of synthetic data using the fitted model parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing distribution fitting has great benefits when working in the field of
    data science. It is not only to better understand, explore, and prepare the data
    but also to bring fast and lightweight solutions. It is good to realize that the
    statistical tests only help you to look in the right direction and that *choosing
    the best model is not a statistical question; it is a modeling decision.* *Choose
    your model wisely.*
  prefs: []
  type: TYPE_NORMAL
- en: '*Be Safe. Stay Frosty.*'
  prefs: []
  type: TYPE_NORMAL
- en: '***Cheers E.***'
  prefs: []
  type: TYPE_NORMAL
- en: '*If you find this article helpful, you are welcome to* [*follow me*](https://erdogant.medium.com/subscribe)
    *because I write more about Data Science. If you are thinking of taking a Medium
    membership, you can support my work a bit by using my referral link. It is the
    same price as a coffee but this allows you to read unlimited articles every month.*'
  prefs: []
  type: TYPE_NORMAL
- en: Software
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Distfit Github/Documentation](https://erdogant.github.io/distfit/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Colab Notebook examples](https://erdogant.github.io/distfit/pages/html/Documentation.html#colab-notebook)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s connect!
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Let’s connect on LinkedIn](https://www.linkedin.com/in/erdogant/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Follow me on Github](https://github.com/erdogant)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Follow me on Medium](https://erdogant.medium.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Terminology.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Definitions/terminology in this blog:'
  prefs: []
  type: TYPE_NORMAL
- en: '**“Random variables** are variables whose value is unknown or a function that
    assigns values to each of an experiment’s outcomes. A random variable can be either
    discrete (having specific values) or continuous (any value in a continuous range)”
    [1]. It can be a single column in your data set for a specific feature, such as
    human height. It can also be your entire data set that is measured with a sensor
    and contains thousands of features.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Probability density function** (PDF) is a statistical expression that defines
    a [probability distribution](https://www.investopedia.com/terms/p/probabilitydistribution.asp)
    (the likelihood of an outcome) for a continuous random variable [1, 6]. The normal
    distribution is a common example of a PDF (the well-known bell-shaped curve).
    The term PDF is sometimes also described as “distribution function” of “probability
    function”.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Theoretical distribution** is a form of a PDF. Examples of theoretical distributions
    are the Normal, Binomial, Exponential, Poisson etc distributions [7]. The distfit
    library contains 89 theoretical distributions.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**A Empirical distribution** (or data distribution) is a frequency based distributions
    of observed random variables (the input data) [8]. A histogram is commonly used
    to visualize the emperical distribution.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*W. Kenton,* [*The Basics of Probability Density Function (PDF), With an Example*](https://www.investopedia.com/terms/p/pdf.asp)*,
    2022, Investopedia.*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*E. Taskesen,* [*What are PCA loadings and how to effectively use Biplots*](/what-are-pca-loadings-and-biplots-9a7897f2e559)?
    *Medium 2022.*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*P. Varshney,* [*Q-Q Plots Explained*](/q-q-plots-explained-5aa8495426c0)*,
    Medium 2020.*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[*Gamma Distribution*](https://en.wikipedia.org/wiki/Gamma_distribution)*,
    Wikipedia.*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*A. Downey,* [*Are your data normal? Hint: no.*](http://allendowney.blogspot.com/2013/08/are-my-data-normal.html)
    *2018, Blog.*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[*Probability Density Function*](https://en.wikipedia.org/wiki/Probability_density_function)*,
    Wikipedia.*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[*List of Probability Distributions*](https://en.wikipedia.org/wiki/List_of_probability_distributions)*,
    Wikipedia*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[*Empirical Distribution Function*](https://en.wikipedia.org/wiki/Empirical_distribution_function)*,
    Wikipedia*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*G. Jogesh Babu, Eric D. Feigelson,* [*Astrostatistics: Goodness-of-Fit and
    All That!*](https://articles.adsabs.harvard.edu/pdf/2006ASPC..351..127B)*, ASP
    Conference Series, Vol. 351, 2006*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: E. Taskesen, [*Outlier Detection Using Distribution Fitting in Univariate Datasets*](/outlier-detection-using-distribution-fitting-in-univariate-data-sets-ac8b7a14d40e),
    Medium 2023
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: E. Taskesen, [*Step-by-Step Guide to Generate Synthetic Data by Sampling From
    Univariate Distributions*](/step-by-step-guide-to-generate-synthetic-data-by-sampling-from-univariate-distributions-6b0be4221cb1),
    Medium 2023
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
