- en: Stress-Test Your NLP Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**压力测试**你的NLP模型'
- en: 原文：[https://towardsdatascience.com/stress-test-for-your-nlp-models-94dba45b6d83](https://towardsdatascience.com/stress-test-for-your-nlp-models-94dba45b6d83)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/stress-test-for-your-nlp-models-94dba45b6d83](https://towardsdatascience.com/stress-test-for-your-nlp-models-94dba45b6d83)
- en: Metrics don’t show the actual performance of NLP models. Learn how to thoroughly
    test your models and fix the annotation artifacts.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指标无法显示NLP模型的实际性能。学习如何彻底测试你的模型并修复注释伪影。
- en: '[](https://prosperous-silver-alpaca.medium.com/?source=post_page-----94dba45b6d83--------------------------------)[![Alexander
    Biryukov](../Images/ad35544b7be340297c1676df19436416.png)](https://prosperous-silver-alpaca.medium.com/?source=post_page-----94dba45b6d83--------------------------------)[](https://towardsdatascience.com/?source=post_page-----94dba45b6d83--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----94dba45b6d83--------------------------------)
    [Alexander Biryukov](https://prosperous-silver-alpaca.medium.com/?source=post_page-----94dba45b6d83--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://prosperous-silver-alpaca.medium.com/?source=post_page-----94dba45b6d83--------------------------------)[![Alexander
    Biryukov](../Images/ad35544b7be340297c1676df19436416.png)](https://prosperous-silver-alpaca.medium.com/?source=post_page-----94dba45b6d83--------------------------------)[](https://towardsdatascience.com/?source=post_page-----94dba45b6d83--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----94dba45b6d83--------------------------------)
    [Alexander Biryukov](https://prosperous-silver-alpaca.medium.com/?source=post_page-----94dba45b6d83--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----94dba45b6d83--------------------------------)
    ·9 min read·Jan 30, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----94dba45b6d83--------------------------------)
    ·阅读时间9分钟·2023年1月30日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Dataset artifacts are one of the problems in Natural Language Processing (NLP)
    that affect models’ performance in the real world. Even though pre-trained models
    can perform well on benchmark datasets, they show poor performance in other settings.
    *Those failures are due to dataset artifacts or annotation artifacts* — *spurious
    correlations, which a language model learns during training*[1]*.*
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集伪影是自然语言处理（NLP）中的一个问题，会影响模型在实际环境中的表现。尽管预训练模型在基准数据集上表现良好，但在其他环境中表现却很差。*这些失败是由于数据集伪影或注释伪影*
    —— *是语言模型在训练过程中学到的* [1] *的虚假相关性*。
- en: '![](../Images/63a1dfef8ca9af14ff29d43f75aaff89.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63a1dfef8ca9af14ff29d43f75aaff89.png)'
- en: Photo by [Nathan Dumlao](https://unsplash.com/ko/@nate_dumlao?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 由 [Nathan Dumlao](https://unsplash.com/ko/@nate_dumlao?utm_source=medium&utm_medium=referral)
    摄影，图片来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: It turns out there is a whole bunch of artifacts your model can absorb while
    being trained thanks to the dataset peculiarities and the biases brought in by
    annotators. Why are artifacts bad? Basically, they are providing your model with
    shortcuts to memorize some causalities which are actually false instead of learning
    correct “reasoning”. For example, if a dataset consists of many examples where
    a male character is a doctor, then a model will give more probability to men rather
    than women to be doctors while conducting inference. It is also possible to construct
    some adversarial examples where the model achieves surprisingly low performance.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，模型在训练过程中会吸收大量伪影，这些伪影源于数据集的特殊性和注释者带来的偏见。伪影为何有害？基本上，它们为你的模型提供了记忆一些实际是虚假的因果关系的捷径，而不是学习正确的“推理”。例如，如果一个数据集中有很多男性角色是医生的例子，那么模型在推断时会更倾向于男性成为医生，而不是女性。也可能构造一些对抗性示例，使得模型的表现出乎意料地低。
- en: Your job as a data scientist is to eliminate as many artifacts as possible and
    to increase the overall performance of your model at the same time.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家的你，工作是尽可能消除伪影，同时提高模型的整体性能。
- en: Find them all!
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 找出所有这些伪影！
- en: 'First of all, you have to know your enemy. So you need to find the artifacts.
    To find the artifacts we need to define what we are looking for. So, to summarise,
    we can list the following artifacts, even though the list is not exhaustive:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要了解你的敌人。因此，你需要找到这些伪影。为了找到这些伪影，我们需要定义我们要寻找的东西。总而言之，我们可以列出以下伪影，尽管这份列表并不详尽：
- en: a model does not understand comparisons
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型无法理解比较。
- en: a model does not understand intensifiers
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型无法理解强化词。
- en: a model does not understand taxonomy (synonyms, antonyms, etc.)
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个模型无法理解分类（同义词、反义词等）
- en: a model does not have the robustness to typos, irrelevant changes, etc.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个模型对拼写错误、无关的变化等缺乏鲁棒性
- en: a model cannot handle named entities appropriately
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个模型无法适当地处理命名实体
- en: a model demonstrates unfairness to some minorities or genders
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个模型对某些少数群体或性别表现出不公平
- en: a model does not understand an order of events
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个模型无法理解事件的顺序
- en: a model cannot handle negations appropriately
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个模型无法适当地处理否定
- en: a model does not understand coreference
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个模型无法理解共指
- en: a model does not understand roles such as agent, object, etc.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个模型无法理解角色如代理、对象等
- en: a model is not robust to some trigger words (some words combinations “hack”
    your model to show some unwished results)
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个模型对某些触发词不够鲁棒（某些词组“破解”你的模型，使其显示一些不希望看到的结果）
- en: a model cannot handle adversarial examples (the adversarial examples are created
    by adding distracting sentences to the input paragraph, but they neither contradict
    the correct answer nor confuse humans)
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个模型无法处理对抗样本（对抗样本是通过在输入段落中添加干扰句子创建的，但它们既不与正确答案矛盾，也不会混淆人类）
- en: and others…
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以及其他……
- en: Now as we know their faces, we want to find artifacts. While looking at datasets
    or annotating them you may figure out some of the artifacts, but there is no better
    way to find them all rather than train a baseline model and do some tests. Luckily
    there is just a perfect tool for that — CheckList [2]. It is not a panacea, but
    it is a huge deal as it helps to analyze most of the artifacts listed above.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在既然我们知道了它们的面貌，我们想找出伪影。在查看数据集或标注它们时，你可能会发现一些伪影，但没有比训练一个基准模型并进行一些测试更好的方法来找到它们。幸运的是，有一个完美的工具——CheckList
    [2]。它不是灵丹妙药，但它非常有用，因为它帮助分析了上述大多数伪影。
- en: Check-up for artifacts
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 伪影检查
- en: Tools and instruments
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工具和仪器
- en: Thanks to the authors there is a great open-source tool that is ready to use
    out of the box for some datasets (such as SQuAD, QQP, and others). Let’s take
    a closer look.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了作者，有一个很棒的开源工具可以即刻用于一些数据集（如 SQuAD、QQP 等）。让我们仔细看看。
- en: 'The CheckList is a testing suite that is inspired by unit testing from software
    development. The authors created a bunch of scripts that generate a number of
    tests with special “templates” such as:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: CheckList 是一个测试套件，灵感来源于软件开发中的单元测试。作者创建了一些脚本，这些脚本生成了许多带有特殊“模板”的测试，例如：
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This template will return a bunch of contexts, questions, and answers that
    will be used to test your model:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模板将返回一堆上下文、问题和答案，这些将用于测试你的模型：
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Using this tool you can generate any amount of such examples. The great thing
    about it is that you can customize the test suites provided to add or edit any
    particular template.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个工具，你可以生成任何数量的此类示例。它的优点在于你可以自定义提供的测试套件，以添加或编辑任何特定的模板。
- en: Moreover, once you have set up your test templates and prepared your test suit,
    you run the test and get a pretty neat summary, which you can even visualize with
    a widget (does not work in Colab). The tool is pretty easy to follow, and it is
    pretty well documented. So spend some time checking it out.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一旦你设置好测试模板并准备好测试套件，你可以运行测试并获得一个相当整洁的总结，你甚至可以用小部件可视化这个总结（在 Colab 中不起作用）。这个工具使用起来相当简单，而且文档也很完善。所以花些时间去了解一下吧。
- en: Testing results
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试结果
- en: So what are the results presented by a model? The authors themselves conducted
    a whole bunch of tests over most of the popular state-of-the-art models in 2019
    and found out that all of them are pretty biased and have lots of artifacts.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 那么模型呈现了什么结果呢？作者们在2019年对大多数流行的最先进模型进行了大量测试，发现它们都有偏见并存在许多伪影。
- en: 'Authors summarised results of the CheckList tests on the following models (ordered
    as on a Figure from left to right):'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 作者总结了在以下模型上的 CheckList 测试结果（按图中从左到右的顺序排列）：
- en: Microsoft’s Text Analytics
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Microsoft 的文本分析
- en: Google Cloud’s Natural Language
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google Cloud 的自然语言
- en: Amazon’s Comprehend
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon 的 Comprehend
- en: BERT-base
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BERT-base
- en: RoBERTa-base
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RoBERTa-base
- en: According to the paper the tested models’ failure rates are pretty high at least
    on several tests. They terribly fail with most of the tests realted to negation
    processing, work pretty bad with changes of sentiment over time and comparison
    of two statements. Interestingly, particularly BERT-based models also fail to
    classify neutral sentiment sentences. So, it turns out that most NLP models are
    vulnerable to artifacts even though being trained on huge amounts of data.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 根据论文，测试模型的失败率在几个测试中都相当高。它们在大多数与否定处理相关的测试中表现糟糕，在情感随时间变化和两个陈述的比较中表现不佳。有趣的是，特别是BERT基础的模型也未能正确分类中性情感句子。因此，事实证明，即使在大量数据上训练，大多数NLP模型也容易受到伪影的影响。
- en: For the sake of example, I and my colleague Derrick Xu conducted similar tests
    on the SQuAD-trained ELECTRA-small model. As expected we got even worse results
    (Figure 1). Even though the model itself achieved an OK F1 score of 86.3 and an
    Exact match score of 78.5, it had lots of biases, which you can see in Figure
    1.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以示例为例，我和我的同事Derrick Xu对SQuAD训练的ELECTRA-small模型进行了类似的测试。正如预期的那样，我们得到了更差的结果（图1）。尽管模型本身获得了86.3的F1分数和78.5的准确匹配分数，但它存在许多偏差，这可以在图1中看到。
- en: '![](../Images/1b9578adbe1aeb0d398d8f5ed0468f94.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1b9578adbe1aeb0d398d8f5ed0468f94.png)'
- en: Figure 1\. Test results for ELECTRA-small model trained on SQuAD dataset.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图1. 针对SQuAD数据集训练的ELECTRA-small模型的测试结果。
- en: We also conducted the adversarial evaluation by evaluating the baseline QA model
    with the adversarial AddOneSent dataset (see Figure 2).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还通过使用对抗性AddOneSent数据集（见图2）评估了基线QA模型的对抗性表现。
- en: F1 score dropped from 86% to 49.6%, and exact match dropped from 78% to 42.1%
    comparing to performance on the SQuAD development set.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 与在SQuAD开发集上的性能相比，F1分数从86%降至49.6%，准确匹配分数从78%降至42.1%。
- en: '![](../Images/0e34c007ab6c299cee62e83fa44583b9.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0e34c007ab6c299cee62e83fa44583b9.png)'
- en: 'Figure 2: Example of the model’s prediction failure on the example from SQuAD
    dataset. Adversarial sentence and erroneous predicted answer are indicated in
    red. The original phrase and correct answers are indicated in blue'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：模型在SQuAD数据集示例上的预测失败示例。对抗性句子和错误预测的答案以红色标记。原始短语和正确答案以蓝色标记。
- en: So, besides fixing for general linguistic capabilities, found using CheckList,
    we also sought to improve the model’s performance on adversarial examples.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，除了修复通用语言能力（使用CheckList发现），我们还寻求提高模型在对抗性示例上的表现。
- en: Now fix them!
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 现在修复它们！
- en: 'There are a few methods to fight annotation artifacts:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以对抗标注伪影：
- en: Retraining on hard subsets of data or data where the gold label distribution
    is ambiguous. It is suggested to use dataset cartography [3] or any other approach
    to find such examples.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对难度较大的数据子集或黄金标签分布模糊的数据进行重新训练。建议使用数据集制图[3]或其他任何方法来寻找这些示例。
- en: 'Ensemble-based debiasing: use a weak model to learn the correlations, then
    train your model to learn the residual of that model [4] or otherwise remove it
    from output distribution. That will make your main model extra-trained on hard
    examples.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于集成的去偏差：使用一个弱模型学习相关性，然后训练你的模型学习该模型的残差[4]，或者将其从输出分布中移除。这将使你的主要模型在困难示例上进行额外训练。
- en: And other methods…
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 还有其他方法……
- en: Basically, all of the methods boil down to model retraining on the data which
    is hard for the model to infer. So the simplest method would be to generate that
    data and retrain your model. That actually works pretty well.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，所有的方法都归结为对模型难以推断的数据进行重新训练。所以最简单的方法就是生成这些数据并重新训练你的模型。这实际上效果很好。
- en: Luckily you don’t have to write up all the extra data by hand. You have CheckList
    generating tools set up. So, all you need is to set up the templates and you are
    good to go.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，你不必手动编写所有额外的数据。你已经设置了CheckList生成工具。因此，你只需要设置模板即可开始使用。
- en: To fix our ELECTRA-small model we used the CheckList tool too. Here is an example
    code to generate extra data for comparison capability improvements.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了修复我们的ELECTRA-small模型，我们也使用了CheckList工具。以下是生成额外数据以改进比较能力的示例代码。
- en: '[PRE2]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Then just dump the data you get and concatenate it with the original training
    data. In our case that was SQuAD train data. Do not forget to shuffle your new
    data with the original one to avoid the skewness of the training data.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 然后只需将获得的数据倒入并与原始训练数据连接。在我们的案例中，这些数据是SQuAD训练数据。不要忘记将新数据与原始数据混合，以避免训练数据的偏斜。
- en: We repeated the generation for several capabilities for this model. In the end,
    we achieved about a 30% extension of the original SQuAD train data. We also included
    some adversarial data, which is also one of the methods to fight artifacts. Liu
    et al. (2019) [5] found that the models’ (i.e. BiDAF, QANet) performance increases
    when retraining them using 500 or more adversarial examples from the challenge
    dataset. So we included around 750 adversarial examples to our extended dataset
    as well, shuffled the whole dataset, and retrained the model.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为该模型重复生成了几个能力的数据。最终，我们实现了对原始 SQuAD 训练数据的大约 30% 扩展。我们还包含了一些对抗数据，这也是对抗伪影的方法之一。刘等人（2019）[5]
    发现，当使用来自挑战数据集的 500 个或更多对抗示例重新训练模型（即 BiDAF，QANet）时，模型性能会提高。因此，我们也将大约 750 个对抗示例包含到扩展数据集中，对整个数据集进行混洗，并重新训练了模型。
- en: We conducted the same CheckList tests as before and here is what we have got.
    The results are presented in Figure 3.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了与之前相同的 CheckList 测试，以下是我们得到的结果。结果如图 3 所示。
- en: '![](../Images/82006ca0f1437976d75d5fa823b46577.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/82006ca0f1437976d75d5fa823b46577.png)'
- en: Figure 3\. CheckList tests results on the retrained model in comparison with
    the baseline model (ELECTRA-small trained on SQuAD dataset).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3\. CheckList 测试结果在重新训练模型与基线模型（在 SQuAD 数据集上训练的 ELECTRA-small）之间的比较。
- en: So, as you may see the results are not perfect. We have obviously decreased
    the model’s performance on some of the capabilities, but mainly those, for which
    the data was not generated to retrain. For the capabilities where we have augmented
    the data, we got a significant increase in performance (decrease in failure rates).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，结果并不完美。我们显然降低了模型在某些能力上的表现，但主要是那些数据未生成用于重新训练的能力。对于那些我们已增强数据的能力，性能显著提升（失败率降低）。
- en: However, some of the results are not that stable. There was probably not enough
    data to improve the performance on negations capability (even though we did target
    that capability) as well as for coreference and temporal capabilities.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有些结果并不那么稳定。可能没有足够的数据来提高对否定能力（尽管我们确实针对了这一能力）、核心指代和时间能力的表现。
- en: At the same time, we managed to simultaneously increase performance on the adversarial
    dataset (Figure 4) and compensate for the performance drop from adversarial retraining
    on the original dev dataset.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，我们成功地提高了对抗数据集上的性能（图 4），并弥补了对抗重新训练在原始开发数据集上带来的性能下降。
- en: 'In terms of the overall final metrics testing on the original dev dataset showed
    us the following results: the exact match grew from 78.5 **to 78.7** and the F1
    score dropped from 86.3 **to 86.2**. That is actually a good result as in line
    with Liu et al (2019) findings retraining on adversarial data leads to a significant
    drop in the performance of the retrained QA model on the original dev dataset
    (in our case it led to a drop in exact match to 74.2 and F1 81.9), thus adversarial
    training alone does not look very attractive. Though combing it with other artifact
    fighting techniques, like CheckList generated data augmentation in our case, one
    can achieve much better performance and significantly improve performance on adversarial
    data.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 就最终整体指标而言，原始开发数据集上的测试结果显示：精确匹配度从 78.5 **提升至 78.7**，F1 分数从 86.3 **下降至 86.2**。这实际上是一个好结果，因为根据刘等人（2019）的研究，使用对抗数据进行重新训练会导致原始开发数据集上重新训练的
    QA 模型性能显著下降（在我们的案例中，精确匹配度下降至 74.2，F1 分数为 81.9），因此单独进行对抗训练看起来并不太有吸引力。然而，与其他伪影处理技术（如在我们案例中的
    CheckList 生成数据增强）结合使用，可以获得更好的性能，并显著提高对抗数据上的表现。
- en: '![](../Images/1e567a80efa038fb512bff8844976fc1.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e567a80efa038fb512bff8844976fc1.png)'
- en: Figure 4\. Performance of the retrained models on SQuAD adversarial datasets.
    Improvements comparing to the baseline model are highlighted in green.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4\. 重新训练模型在 SQuAD 对抗数据集上的表现。与基线模型相比的改进用绿色突出显示。
- en: To conclude, we approximately kept the same overall metrics while improving
    some of the model’s capabilities and fighting artifacts.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们在提高模型能力和解决伪影问题的同时，整体指标大致保持不变。
- en: To sum up
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: The CheckList + adversarial training is just one of the methods to analyze and
    fix annotation artifacts. In order to significantly improve a model’s performance
    alongside artifacts elimination, you have to use several approaches at once.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: CheckList + 对抗训练只是分析和修复标注伪影的方法之一。为了显著提升模型性能并消除伪影，你必须同时使用几种方法。
- en: However, I cannot stress enough that you have to think about the artifacts and
    fight them. That is an important step towards the NLP models which are more robust
    and fair as well as less biased!
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我不能过分强调，你必须考虑这些文档并与之抗争。这是朝着更强健、公平且减少偏见的自然语言处理模型迈出的重要一步！
- en: References
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: This article is brought to you by me and [Derrick Xu](https://www.linkedin.com/in/derrick-xu/).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 本文由我和[Derrick Xu](https://www.linkedin.com/in/derrick-xu/)共同提供。
- en: All images are by the author unless noted otherwise.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，否则所有图片均由作者提供。
- en: '[1] Gururangan, S., Swayamdipta, S., Levy, O., Schwartz, R., Bowman, S. R.,
    & Smith, N. A. (2018). Annotation artifacts in natural language inference data.
    *arXiv preprint arXiv:1803.02324*.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Gururangan, S., Swayamdipta, S., Levy, O., Schwartz, R., Bowman, S. R.,
    & Smith, N. A. (2018). 自然语言推理数据中的注释伪影。*arXiv预印本 arXiv:1803.02324*。'
- en: '[2] Ribeiro, M. T., Wu, T., Guestrin, C., & Singh, S. (2020). Beyond accuracy:
    Behavioral testing of NLP models with CheckList. *arXiv preprint arXiv:2005.04118*'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Ribeiro, M. T., Wu, T., Guestrin, C., & Singh, S. (2020). 超越准确性：使用CheckList对NLP模型进行行为测试。*arXiv预印本
    arXiv:2005.04118*'
- en: '[3] Swayamdipta, S., Schwartz, R., Lourie, N., Wang, Y., Hajishirzi, H., Smith,
    N. A., & Choi, Y. (2020). Dataset cartography: Mapping and diagnosing datasets
    with training dynamics. *arXiv preprint arXiv:2009.10795*.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Swayamdipta, S., Schwartz, R., Lourie, N., Wang, Y., Hajishirzi, H., Smith,
    N. A., & Choi, Y. (2020). 数据集制图：通过训练动态映射和诊断数据集。*arXiv预印本 arXiv:2009.10795*。'
- en: '[4] He, H., Zha, S., & Wang, H. (2019). Unlearn dataset bias in natural language
    inference by fitting the residual. *arXiv preprint arXiv:1908.10763*.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] He, H., Zha, S., & Wang, H. (2019). 通过拟合残差来消除自然语言推理中的数据集偏差。*arXiv预印本 arXiv:1908.10763*。'
- en: '[5] Liu, N. F., Schwartz, R., & Smith, N. A. (2019). Inoculation by fine-tuning:
    A method for analyzing challenge datasets. *arXiv preprint arXiv:1904.02668*.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Liu, N. F., Schwartz, R., & Smith, N. A. (2019). 通过微调进行免疫：分析挑战数据集的方法。*arXiv预印本
    arXiv:1904.02668*。'
