["```py\n## for data\nimport pandas as pd  #1.1.5\nimport numpy as np  #1.21.0\n\n## for plotting\nimport matplotlib.pyplot as plt  #3.3.2\n\n## for text\nimport wikipediaapi  #0.5.8\nimport nltk  #3.8.1\nimport re   \n\n## for nlp\nimport spacy  #3.5.0\nfrom spacy import displacy\nimport textacy  #0.12.0\n\n## for graph\nimport networkx as nx  #3.0 (also pygraphviz==1.10)\n\n## for timeline\nimport dateparser #1.1.7\n```", "```py\ntopic = \"Russo-Ukrainian War\"\n\nwiki = wikipediaapi.Wikipedia('en')\npage = wiki.page(topic)\ntxt = page.text[:page.text.find(\"See also\")]\ntxt[0:500] + \" ...\"\n```", "```py\n#python -m spacy download en_core_web_sm\n\nnlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(txt)\n```", "```py\n# from text to a list of sentences\nlst_docs = [sent for sent in doc.sents]\nprint(\"tot sentences:\", len(lst_docs))\n```", "```py\n# take a sentence\ni = 3\nlst_docs[i]\n```", "```py\nfor token in lst_docs[i]:\n    print(token.text, \"-->\", \"pos: \"+token.pos_, \"|\", \"dep: \"+token.dep_, \"\")\n```", "```py\nfrom spacy import displacy\n\ndisplacy.render(lst_docs[i], style=\"dep\", options={\"distance\":100})\n```", "```py\nfor tag in lst_docs[i].ents:\n    print(tag.text, f\"({tag.label_})\") \n```", "```py\ndisplacy.render(lst_docs[i], style=\"ent\")\n```", "```py\ndef extract_entities(doc):\n    a, b, prev_dep, prev_txt, prefix, modifier = \"\", \"\", \"\", \"\", \"\", \"\"\n    for token in doc:\n        if token.dep_ != \"punct\":\n            ## prexif --> prev_compound + compound\n            if token.dep_ == \"compound\":\n                prefix = prev_txt +\" \"+ token.text if prev_dep == \"compound\" else token.text\n\n            ## modifier --> prev_compound + %mod\n            if token.dep_.endswith(\"mod\") == True:\n                modifier = prev_txt +\" \"+ token.text if prev_dep == \"compound\" else token.text\n\n            ## subject --> modifier + prefix + %subj\n            if token.dep_.find(\"subj\") == True:\n                a = modifier +\" \"+ prefix + \" \"+ token.text\n                prefix, modifier, prev_dep, prev_txt = \"\", \"\", \"\", \"\"\n\n            ## if object --> modifier + prefix + %obj\n            if token.dep_.find(\"obj\") == True:\n                b = modifier +\" \"+ prefix +\" \"+ token.text\n\n            prev_dep, prev_txt = token.dep_, token.text\n\n    # clean\n    a = \" \".join([i for i in a.split()])\n    b = \" \".join([i for i in b.split()])\n    return (a.strip(), b.strip())\n\n# The relation extraction requires the rule-based matching tool, \n# an improved version of regular expressions on raw text.\ndef extract_relation(doc, nlp):\n    matcher = spacy.matcher.Matcher(nlp.vocab)\n    p1 = [{'DEP':'ROOT'}, \n          {'DEP':'prep', 'OP':\"?\"},\n          {'DEP':'agent', 'OP':\"?\"},\n          {'POS':'ADJ', 'OP':\"?\"}] \n    matcher.add(key=\"matching_1\", patterns=[p1]) \n    matches = matcher(doc)\n    k = len(matches) - 1\n    span = doc[matches[k][1]:matches[k][2]] \n    return span.text\n```", "```py\n## extract entities\nlst_entities = [extract_entities(i) for i in lst_docs]\n\n## example\nlst_entities[i]\n```", "```py\n## extract relations\nlst_relations = [extract_relation(i,nlp) for i in lst_docs]\n\n## example\nlst_relations[i]\n```", "```py\n## extract attributes (NER)\nlst_attr = []\nfor x in lst_docs:\n    attr = \"\"\n    for tag in x.ents:\n        attr = attr+tag.text if tag.label_==\"DATE\" else attr+\"\"\n    lst_attr.append(attr)\n\n## example\nlst_attr[i]\n```", "```py\n## extract entities and relations\ndic = {\"id\":[], \"text\":[], \"entity\":[], \"relation\":[], \"object\":[]}\n\nfor n,sentence in enumerate(lst_docs):\n    lst_generators = list(textacy.extract.subject_verb_object_triples(sentence))  \n    for sent in lst_generators:\n        subj = \"_\".join(map(str, sent.subject))\n        obj  = \"_\".join(map(str, sent.object))\n        relation = \"_\".join(map(str, sent.verb))\n        dic[\"id\"].append(n)\n        dic[\"text\"].append(sentence.text)\n        dic[\"entity\"].append(subj)\n        dic[\"object\"].append(obj)\n        dic[\"relation\"].append(relation)\n\n## create dataframe\ndtf = pd.DataFrame(dic)\n\n## example\ndtf[dtf[\"id\"]==i]\n```", "```py\n## extract attributes\nattribute = \"DATE\"\ndic = {\"id\":[], \"text\":[], attribute:[]}\n\nfor n,sentence in enumerate(lst_docs):\n    lst = list(textacy.extract.entities(sentence, include_types={attribute}))\n    if len(lst) > 0:\n        for attr in lst:\n            dic[\"id\"].append(n)\n            dic[\"text\"].append(sentence.text)\n            dic[attribute].append(str(attr))\n    else:\n        dic[\"id\"].append(n)\n        dic[\"text\"].append(sentence.text)\n        dic[attribute].append(np.nan)\n\ndtf_att = pd.DataFrame(dic)\ndtf_att = dtf_att[~dtf_att[attribute].isna()]\n\n## example\ndtf_att[dtf_att[\"id\"]==i]\n```", "```py\n## create full graph\nG = nx.from_pandas_edgelist(dtf, source=\"entity\", target=\"object\", \n                            edge_attr=\"relation\", \n                            create_using=nx.DiGraph())\n\n## plot\nplt.figure(figsize=(15,10))\n\npos = nx.spring_layout(G, k=1)\nnode_color = \"skyblue\"\nedge_color = \"black\"\n\nnx.draw(G, pos=pos, with_labels=True, node_color=node_color, \n        edge_color=edge_color, cmap=plt.cm.Dark2, \n        node_size=2000, connectionstyle='arc3,rad=0.1')\n\nnx.draw_networkx_edge_labels(G, pos=pos, label_pos=0.5, \n                         edge_labels=nx.get_edge_attributes(G,'relation'),\n                         font_size=12, font_color='black', alpha=0.6)\nplt.show()\n```", "```py\ndtf[\"entity\"].value_counts().head()\n```", "```py\n## filter\nf = \"Russia\"\ntmp = dtf[(dtf[\"entity\"]==f) | (dtf[\"object\"]==f)]\n\n## create small graph\nG = nx.from_pandas_edgelist(tmp, source=\"entity\", target=\"object\", \n                            edge_attr=\"relation\", \n                            create_using=nx.DiGraph())\n\n## plot\nplt.figure(figsize=(15,10))\n\npos = nx.nx_agraph.graphviz_layout(G, prog=\"neato\")\nnode_color = [\"red\" if node==f else \"skyblue\" for node in G.nodes]\nedge_color = [\"red\" if edge[0]==f else \"black\" for edge in G.edges]\n\nnx.draw(G, pos=pos, with_labels=True, node_color=node_color, \n        edge_color=edge_color, cmap=plt.cm.Dark2, \n        node_size=2000, node_shape=\"o\", connectionstyle='arc3,rad=0.1')\n\nnx.draw_networkx_edge_labels(G, pos=pos, label_pos=0.5, \n                        edge_labels=nx.get_edge_attributes(G,'relation'),\n                        font_size=12, font_color='black', alpha=0.6)\nplt.show()\n```", "```py\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure(figsize=(15,10))\nax = fig.add_subplot(111, projection=\"3d\")\npos = nx.spring_layout(G, k=2.5, dim=3)\n\nnodes = np.array([pos[v] for v in sorted(G) if v!=f])\ncenter_node = np.array([pos[v] for v in sorted(G) if v==f])\n\nedges = np.array([(pos[u],pos[v]) for u,v in G.edges() if v!=f])\ncenter_edges = np.array([(pos[u],pos[v]) for u,v in G.edges() if v==f])\n\nax.scatter(*nodes.T, s=200, ec=\"w\", c=\"skyblue\", alpha=0.5)\nax.scatter(*center_node.T, s=200, c=\"red\", alpha=0.5)\n\nfor link in edges:\n    ax.plot(*link.T, color=\"grey\", lw=0.5)\nfor link in center_edges:\n    ax.plot(*link.T, color=\"red\", lw=0.5)\n\nfor v in sorted(G):\n    ax.text(*pos[v].T, s=v)\nfor u,v in G.edges():\n    attr = nx.get_edge_attributes(G, \"relation\")[(u,v)]\n    ax.text(*((pos[u]+pos[v])/2).T, s=attr)\n\nax.set(xlabel=None, ylabel=None, zlabel=None, \n       xticklabels=[], yticklabels=[], zticklabels=[])\nax.grid(False)\nfor dim in (ax.xaxis, ax.yaxis, ax.zaxis):\n    dim.set_ticks([])\nplt.show()\n```", "```py\ndef utils_parsetime(txt):\n    x = re.match(r'.*([1-3][0-9]{3})', txt) #<--check if there is a year\n    if x is not None:\n        try:\n            dt = dateparser.parse(txt)\n        except:\n            dt = np.nan\n    else:\n        dt = np.nan\n    return dt\n```", "```py\ndtf_att[\"dt\"] = dtf_att[\"date\"].apply(lambda x: utils_parsetime(x))\n\n## example\ndtf_att[dtf_att[\"id\"]==i]\n```", "```py\ntmp = dtf.copy()\ntmp[\"y\"] = tmp[\"entity\"]+\" \"+tmp[\"relation\"]+\" \"+tmp[\"object\"]\n\ndtf_att = dtf_att.merge(tmp[[\"id\",\"y\"]], how=\"left\", on=\"id\")\ndtf_att = dtf_att[~dtf_att[\"y\"].isna()].sort_values(\"dt\", \n                 ascending=True).drop_duplicates(\"y\", keep='first')\ndtf_att.head()\n```", "```py\ndates = dtf_att[\"dt\"].values\nnames = dtf_att[\"y\"].values\nl = [10,-10, 8,-8, 6,-6, 4,-4, 2,-2]\nlevels = np.tile(l, int(np.ceil(len(dates)/len(l))))[:len(dates)]\n\nfig, ax = plt.subplots(figsize=(20,10))\nax.set(title=topic, yticks=[], yticklabels=[])\n\nax.vlines(dates, ymin=0, ymax=levels, color=\"tab:red\")\nax.plot(dates, np.zeros_like(dates), \"-o\", color=\"k\", markerfacecolor=\"w\")\n\nfor d,l,r in zip(dates,levels,names):\n    ax.annotate(r, xy=(d,l), xytext=(-3, np.sign(l)*3), \n                textcoords=\"offset points\",\n                horizontalalignment=\"center\",\n                verticalalignment=\"bottom\" if l>0 else \"top\")\n\nplt.xticks(rotation=90) \nplt.show()\n```", "```py\nyyyy = \"2022\"\ndates = dtf_att[dtf_att[\"dt\"]>yyyy][\"dt\"].values\nnames = dtf_att[dtf_att[\"dt\"]>yyyy][\"y\"].values\nl = [10,-10, 8,-8, 6,-6, 4,-4, 2,-2]\nlevels = np.tile(l, int(np.ceil(len(dates)/len(l))))[:len(dates)]\n\nfig, ax = plt.subplots(figsize=(20,10))\nax.set(title=topic, yticks=[], yticklabels=[])\n\nax.vlines(dates, ymin=0, ymax=levels, color=\"tab:red\")\nax.plot(dates, np.zeros_like(dates), \"-o\", color=\"k\", markerfacecolor=\"w\")\n\nfor d,l,r in zip(dates,levels,names):\n    ax.annotate(r, xy=(d,l), xytext=(-3, np.sign(l)*3), \n                textcoords=\"offset points\",\n                horizontalalignment=\"center\",\n                verticalalignment=\"bottom\" if l>0 else \"top\")\n\nplt.xticks(rotation=90) \nplt.show()\n```"]