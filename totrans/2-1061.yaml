- en: How Data Leakage affects model performance claims
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-data-leakage-affects-model-performance-claims-841eb01276bb](https://towardsdatascience.com/how-data-leakage-affects-model-performance-claims-841eb01276bb)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@georgiadeaconu?source=post_page-----841eb01276bb--------------------------------)[![Georgia
    Deaconu](../Images/39ba1bea77aa46bb39b2975108c3adaa.png)](https://medium.com/@georgiadeaconu?source=post_page-----841eb01276bb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----841eb01276bb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----841eb01276bb--------------------------------)
    [Georgia Deaconu](https://medium.com/@georgiadeaconu?source=post_page-----841eb01276bb--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----841eb01276bb--------------------------------)
    ·4 min read·Jan 2, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: This year has seen [several](https://www.science.org/doi/10.1126/science.abi6983)
    [important](https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe)
    [scientific advancements](https://www.nature.com/articles/s41586-021-04086-x.pdf)
    enabled by [machine learning driven research](https://www.deepmind.com/blog/accelerating-fusion-science-through-learned-plasma-control).
    Along with the enthusiasm came also some worry related to the [reproducibility
    issues encountered in ML-based science](https://arxiv.org/pdf/2207.07048.pdf).
    Several methodological problems have been identified, out of which data leakage
    seems to be the most widespread. Generally, data leakage can skew results and
    lead to overly optimistic conclusions.
  prefs: []
  type: TYPE_NORMAL
- en: There are several different ways in which data leakage can occur. The objective
    of this post is to present some of the most commonly encountered types, along
    with a few tips about how to identify and mitigate them.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a384eb770d0aa46df6ec4405d4a75f92.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by the author using dreamstudio.ai
  prefs: []
  type: TYPE_NORMAL
- en: '*Data leakage* can be defined as an artificial relationship between the target
    variable and its predictors which is unwillingly introduced through the data collection
    method or the pre-processing strategy.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The main sources of data leakage I will try to exemplify are:'
  prefs: []
  type: TYPE_NORMAL
- en: The improper separation between training and test datasets
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The usage of features that are not legitimate (proxy variables)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The test set is not drawn from the distribution of interest
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 1\. The improper separation between training and test datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data scientists know that they need to divide their input data into train and
    test sets, only train their model using the training set and compute evaluation
    metrics only on the test set. This is a textbook error that most people know to
    avoid. However, the initial exploratory analysis is often performed on the complete
    data set. If this initial analysis also involves pre-processing and data cleaning
    steps, it can be a source of data leakage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pre-processing steps that can introduce data leakage:'
  prefs: []
  type: TYPE_NORMAL
- en: performing missing values imputation or scaling before splitting the two sets.
    By using the complete data set to compute imputation parameters (mean, standard
    deviation, etc.), some information that shouldn’t be available to the model during
    its training is introduced in the training set
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[performing under/oversampling before splitting the two sets](/why-we-need-to-deal-with-imbalanced-classes-ec0dc1a7b803)
    also leads to an improper separation between the training and test sets (oversampled
    data from the training set would be present in the test set leading to optimistic
    conclusions)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: not removing duplicates from the data set before splitting. In this case, the
    same values could be part of the training and test sets after splitting, leading
    to optimistic evaluation metrics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2\. The usage of features that are not legitimate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is considered data leakage also when the data set contains features that
    should not legitimately be used in modeling. An intuitive example would be if
    one of the features is a proxy for the outcome variable.
  prefs: []
  type: TYPE_NORMAL
- en: The [Seattle Building Energy Benchmarking data set](https://data.seattle.gov/dataset/2015-Building-Energy-Benchmarking/h7rm-fz6m)
    contains an example of such a variable. Seattle’s objective was to predict a building’s
    energy performance based on characteristics that are already publicly available,
    such as building surface, building type, property usage, date when it was built,
    etc. Their dataset also contains the Electricity and Natural Gas consumption values,
    along with the target variables Site Energy Use and GHG Emissions. Electricity
    and Natural Gas consumption values are highly correlated with the target variable,
    including them in the features when building a prediction model would yield very
    accurate results.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0a951a3d8dfe8351a6de41ec78f051fa.png)'
  prefs: []
  type: TYPE_IMG
- en: Correlation between some features and the target variables (Image by the author)
  prefs: []
  type: TYPE_NORMAL
- en: 'However, these features are just *proxies for the output variable.* They do
    not actually explain anything that common sense does not already tell us: buildings
    that use a lot of electricity will have a high energy usage overall.'
  prefs: []
  type: TYPE_NORMAL
- en: If the Electricity usage values are available at the prediction time, then the
    prediction of Site Energy Use becomes a trivial task and there is no actual need
    to build a model.
  prefs: []
  type: TYPE_NORMAL
- en: The example given here is simple but, in general, the judgment of whether to
    use a particular feature or not requires domain knowledge and can be problem specific.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. The test set is not drawn from the distribution of interest
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This particular source of data leakage can be a bit harder to exemplify but
    can be intuitively explained. We can divide it into several sub-categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Temporal leakage](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html):
    if a model is used to make predictions about the future, then the test set should
    not contain any data that pre-dates the training set (the model would be built
    based on *data from the future*)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Non-independence between train and test samples: this problem arises more in
    the medical domain, where several samples are collected from the same patients
    over some period of time This issue can be handled by using specific methods such
    as [block cross-validation](https://neptune.ai/blog/cross-validation-mistakes),
    but it is a [difficult problem in the generic case](https://arxiv.org/abs/2002.05193)
    since all the underlying dependencies in the data might be known'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sampling bias: choosing a non-representative subset of the dataset for evaluation.
    An example of such bias would be choosing only cases with extreme depression to
    evaluate the effectiveness of an anti-depressive drug and make claims about the
    drug''s effectiveness for treating depression in general'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data leakage can be introduced at various stages of the modeling pipeline and
    detecting it might not be obvious. The pre-processing steps and the test/train
    split method will depend on the characteristics of the dataset and might require
    specific domain knowledge. As a general rule, if the obtained results are too
    good to be true then there is a high chance of data leakage.
  prefs: []
  type: TYPE_NORMAL
