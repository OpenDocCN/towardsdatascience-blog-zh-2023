- en: Interpreting Machine Learning Models Using Data-Centric Explainable AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用数据中心可解释人工智能解释机器学习模型
- en: 原文：[https://towardsdatascience.com/interpreting-machine-learning-models-using-data-centric-explainable-ai-8415be070416](https://towardsdatascience.com/interpreting-machine-learning-models-using-data-centric-explainable-ai-8415be070416)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/interpreting-machine-learning-models-using-data-centric-explainable-ai-8415be070416](https://towardsdatascience.com/interpreting-machine-learning-models-using-data-centric-explainable-ai-8415be070416)
- en: Learn about data-centric explanation and its different types in this article
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在本文中了解数据中心解释及其不同类型
- en: '[](https://adib0073.medium.com/?source=post_page-----8415be070416--------------------------------)[![Aditya
    Bhattacharya](../Images/d0f79ad4a85330c58327aea499b7eea0.png)](https://adib0073.medium.com/?source=post_page-----8415be070416--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8415be070416--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8415be070416--------------------------------)
    [Aditya Bhattacharya](https://adib0073.medium.com/?source=post_page-----8415be070416--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://adib0073.medium.com/?source=post_page-----8415be070416--------------------------------)[![Aditya
    Bhattacharya](../Images/d0f79ad4a85330c58327aea499b7eea0.png)](https://adib0073.medium.com/?source=post_page-----8415be070416--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8415be070416--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8415be070416--------------------------------)
    [Aditya Bhattacharya](https://adib0073.medium.com/?source=post_page-----8415be070416--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8415be070416--------------------------------)
    ·8 min read·Feb 26, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[数据科学前沿](https://towardsdatascience.com/?source=post_page-----8415be070416--------------------------------)
    ·8分钟阅读·2023年2月26日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/64e9edc18d4081642554bc54fda2e7a9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/64e9edc18d4081642554bc54fda2e7a9.png)'
- en: 'Source: [Pixabay](https://pixabay.com/illustrations/charts-tables-graph-statistics-6246450/)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[Pixabay](https://pixabay.com/illustrations/charts-tables-graph-statistics-6246450/)
- en: '[**Explainable AI (XAI)**](https://amzn.to/3cY4c2h) is an emerging concept
    that aims to bridge the gap between AI and end-users, thereby increasing AI adoption.
    XAI can make AI/ML models more transparent, trustworthy, and understandable. It
    is a necessity, especially for critical domains such as healthcare, finance, and
    law enforcement.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[**可解释人工智能（XAI）**](https://amzn.to/3cY4c2h)是一个新兴概念，旨在弥合人工智能与终端用户之间的差距，从而增加人工智能的采纳。XAI可以使人工智能/机器学习模型更加透明、可信和易于理解。特别是在医疗保健、金融和执法等关键领域，这一点尤为必要。'
- en: 'To get an introduction to XAI, the following 45 minutes presentation of mine
    from the **AI Accelerator Festival APAC, 2021** will be very helpful:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 若要了解XAI的介绍，我在**2021年AI加速器节亚太区**的45分钟演讲将非常有帮助：
- en: '[Popular XAI methods](https://amzn.to/3J2QNnz), such as LIME, SHAP, Saliency
    Maps, etc., are [**model-centric explanation methods**](https://amzn.to/3J2QNnz).
    These methods approximate the important features used by machine learning models
    to generate predictions. However, due to the inductive bias of ML models, an estimation
    of important features considered by the predictive models might not always be
    correct. Consequently, model-centric feature importance methods may not be very
    useful always.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[流行的XAI方法](https://amzn.to/3J2QNnz)，如LIME、SHAP、显著性图等，是[**以模型为中心的解释方法**](https://amzn.to/3J2QNnz)。这些方法近似于机器学习模型用于生成预测的重要特征。然而，由于机器学习模型的归纳偏差，预测模型考虑的重要特征的估计可能并不总是准确。因此，以模型为中心的特征重要性方法可能并不总是非常有用。'
- en: Additionally, considering the principles of Data-Centric AI, the quality of
    ML models is only as good as the quality of the data used to train them. Data
    quality issues caused due to correlated features, data drifts, outliers, skewed
    data, and so on can impact the performance of the trained ML models. Yet, non-technical
    consumers of AI hardly have an awareness of the *goodness* of the datasets used
    to train ML models. Hence, [**Data-Centric Explainable AI (DCXAI)**](https://amzn.to/3J2QNnz)
    is a better choice instead of model-centric explanations when potential data issues
    in datasets are detected during the training and inference of ML models.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，考虑到数据中心人工智能的原则，机器学习模型的质量仅取决于用于训练它们的数据的质量。由于相关特征、数据漂移、离群值、数据偏斜等引起的数据质量问题会影响训练后的机器学习模型的性能。然而，非技术用户通常对训练机器学习模型所用数据集的*好坏*没有足够的意识。因此，[**数据中心可解释人工智能（DCXAI）**](https://amzn.to/3J2QNnz)在训练和推理过程中检测到数据集潜在数据问题时，比以模型为中心的解释更为合适。
- en: 'If you are interested to know how Data-Centric Explainable AI can be leveraged
    to explain ML models for a high stake domain, such as healthcare, please take
    a look at my research publication — [Directive Explanations for Monitoring the
    Risk of Diabetes Onset: Introducing Directive Data-Centric Explanations and Combinations
    to Support What-If Explorations](https://arxiv.org/abs/2302.10671).'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你有兴趣了解如何利用以数据为中心的可解释人工智能（DCXAI）来解释机器学习模型在高风险领域（如医疗保健）的应用，请查看我的研究出版物——[糖尿病发病风险监测的指令性解释：介绍指令性数据中心解释和支持“假设”探索的组合](https://arxiv.org/abs/2302.10671)。
- en: I will also refer to some of the concepts about data-centric explanations discussed
    in my book [**Applied Machine Learning Explainability Techniques**](https://amzn.to/3cY4c2h)**.**
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我还会参考书中讨论的一些关于数据中心解释的概念，[**应用机器学习可解释性技术**](https://amzn.to/3cY4c2h)**。**
- en: '[](https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&pd_rd_w=Wr6SJ&content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_r=6P2PM599T97MRG7NZD9J&pd_rd_wg=m4qUW&pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&linkCode=li3&tag=adib0073-20&linkId=35506e1847de5c011fc57aa66c2b1d8e&language=en_US&ref_=as_li_ss_il&source=post_page-----8415be070416--------------------------------)
    [## Applied Machine Learning Explainability Techniques: Make ML models explainable
    and trustworthy for…'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[**应用机器学习可解释性技术**](https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&pd_rd_w=Wr6SJ&content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_r=6P2PM599T97MRG7NZD9J&pd_rd_wg=m4qUW&pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&linkCode=li3&tag=adib0073-20&linkId=35506e1847de5c011fc57aa66c2b1d8e&language=en_US&ref_=as_li_ss_il&source=post_page-----8415be070416--------------------------------)
    [## 应用机器学习可解释性技术：使机器学习模型变得可解释且值得信赖…](https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&pd_rd_w=Wr6SJ&content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_r=6P2PM599T97MRG7NZD9J&pd_rd_wg=m4qUW&pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&linkCode=li3&tag=adib0073-20&linkId=35506e1847de5c011fc57aa66c2b1d8e&language=en_US&ref_=as_li_ss_il&source=post_page-----8415be070416--------------------------------)'
- en: 'Applied Machine Learning Explainability Techniques: Make ML models explainable
    and trustworthy for practical…'
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 应用机器学习可解释性技术：使机器学习模型在实际应用中变得可解释且值得信赖…
- en: www.amazon.com](https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&pd_rd_w=Wr6SJ&content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_r=6P2PM599T97MRG7NZD9J&pd_rd_wg=m4qUW&pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&linkCode=li3&tag=adib0073-20&linkId=35506e1847de5c011fc57aa66c2b1d8e&language=en_US&ref_=as_li_ss_il&source=post_page-----8415be070416--------------------------------)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.amazon.com](https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&pd_rd_w=Wr6SJ&content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_r=6P2PM599T97MRG7NZD9J&pd_rd_wg=m4qUW&pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&linkCode=li3&tag=adib0073-20&linkId=35506e1847de5c011fc57aa66c2b1d8e&language=en_US&ref_=as_li_ss_il&source=post_page-----8415be070416--------------------------------)'
- en: '**What is Data-Centric Explainable AI (DCXAI)?**'
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**什么是以数据为中心的可解释人工智能（DCXAI）？**'
- en: As discussed in my book **Applied Machine Learning Explainability Techniques**,
    Data-Centric Explainable AI (DCXAI) is an XAI method that explains how an ML model
    can behave by generating insights about the underlying dataset used to train them.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如我在书中**应用机器学习可解释性技术**中讨论的，以数据为中心的可解释人工智能（DCXAI）是一种XAI方法，通过生成关于用于训练模型的底层数据集的见解来解释机器学习模型的行为。
- en: '![](../Images/0edf5ed26dfba88ff72e9855d353598f.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0edf5ed26dfba88ff72e9855d353598f.png)'
- en: 'Source: [Pixabay](https://pixabay.com/illustrations/graph-charts-stats-data-metrics-6249047/)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[Pixabay](https://pixabay.com/illustrations/graph-charts-stats-data-metrics-6249047/)
- en: Examples of data-centric explanation approaches include summarizing datasets
    using common statistical methods like mean, mode, and variance, visualizing the
    data distributions to compare feature values to those across the remaining dataset,
    and observing changes in model predictions through what-if analysis to probe into
    the sensitivity of the features. Additionally, data-centric explanations include
    data-driven rule-based approaches that are commonly adopted in decision support
    systems. Furthermore, DCXAI includes creating more awareness about the data quality
    by sharing more insights about the various data issues, such as data drift, skewed
    data, outliers, correlated features and etc., that can impact the overall performance
    of the ML models.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 数据中心解释方法的例子包括使用均值、众数和方差等常见统计方法总结数据集，视觉化数据分布以比较特征值与其余数据集中的特征值，以及通过假设分析观察模型预测的变化以探究特征的敏感性。此外，数据中心解释还包括在决策支持系统中常采用的数据驱动规则方法。此外，DCXAI还包括通过分享有关各种数据问题（如数据漂移、数据偏斜、离群值、相关特征等）更多见解来提高对数据质量的认识，这些问题会影响机器学习模型的整体性能。
- en: Why DCXAI instead of other XAI methods?
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么选择DCXAI而不是其他XAI方法？
- en: More recently, due to the failure of ML models trained on biased, inconsistent,
    and poor-quality data, the ML research community is exploring data-centric approaches
    for training ML models instead of solely relying on hyperparameter tuning and
    exploring different ML algorithms. If the data is consistent, unambiguous, balanced,
    and available in sufficient quantity, ML models can be trained faster with higher
    accuracy and faster deployment for any production-level system.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，由于基于偏见、不一致和低质量数据训练的机器学习模型的失败，机器学习研究社区正在探索以数据为中心的训练方法，而不仅仅依赖于超参数调优和探索不同的机器学习算法。如果数据是一致的、明确的、平衡的，并且数量充足，则机器学习模型可以更快地训练，并在任何生产级系统中更快地部署。
- en: Unfortunately, all AI and ML systems that exist in production today are not
    in alignment with the principles of data-centric AI. Consequently, there can be
    severe issues with the underlying data that seldom get detected but eventually
    lead to the failure of ML systems. That is why **DCXAI** is important to inspect
    and evaluate the quality of the data being used.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，目前所有生产环境中的人工智能和机器学习系统都未能与以数据为中心的人工智能原则对齐。因此，底层数据可能存在严重问题，这些问题很少被检测到，但最终会导致机器学习系统的失败。这就是为什么**数据中心化解释性人工智能（DCXAI）**在检查和评估所使用数据质量方面如此重要。
- en: '[](https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&pd_rd_w=Wr6SJ&content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_r=6P2PM599T97MRG7NZD9J&pd_rd_wg=m4qUW&pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&linkCode=li3&tag=adib0073-20&linkId=35506e1847de5c011fc57aa66c2b1d8e&language=en_US&ref_=as_li_ss_il&source=post_page-----8415be070416--------------------------------)
    [## Applied Machine Learning Explainability Techniques: Make ML models explainable
    and trustworthy for…'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 应用机器学习解释性技术：使机器学习模型对实践中的应用具有可解释性和可信度…](https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&pd_rd_w=Wr6SJ&content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_r=6P2PM599T97MRG7NZD9J&pd_rd_wg=m4qUW&pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&linkCode=li3&tag=adib0073-20&linkId=35506e1847de5c011fc57aa66c2b1d8e&language=en_US&ref_=as_li_ss_il&source=post_page-----8415be070416--------------------------------)'
- en: 'Applied Machine Learning Explainability Techniques: Make ML models explainable
    and trustworthy for practical…'
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 应用机器学习解释性技术：使机器学习模型对实践中的应用具有可解释性和可信度……
- en: www.amazon.com](https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&pd_rd_w=Wr6SJ&content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_r=6P2PM599T97MRG7NZD9J&pd_rd_wg=m4qUW&pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&linkCode=li3&tag=adib0073-20&linkId=35506e1847de5c011fc57aa66c2b1d8e&language=en_US&ref_=as_li_ss_il&source=post_page-----8415be070416--------------------------------)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.amazon.com](https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&pd_rd_w=Wr6SJ&content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_r=6P2PM599T97MRG7NZD9J&pd_rd_wg=m4qUW&pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&linkCode=li3&tag=adib0073-20&linkId=35506e1847de5c011fc57aa66c2b1d8e&language=en_US&ref_=as_li_ss_il&source=post_page-----8415be070416--------------------------------)'
- en: Different approaches of DCXAI
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据中心化解释性人工智能（DCXAI）的不同方法
- en: 'There can be different approaches to data-centric explanations, which can be
    further categorized by the following types:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 数据中心化解释的不同方法可以进一步按以下类型分类：
- en: '**Generating insights about the training data** — Exploratory Data Analysis
    (EDA) is an important practice conducted by all data scientists and ML experts
    before building ML models. However, every insight generated from EDA is very rarely
    communicated to the non-technical consumers of ML models. So, one of the approaches
    of DCXAI is to communicate the insights generated to the end-users to explain
    the potential behavior of ML models. This is particularly useful for domain experts
    who may not have ML knowledge but are experts in their own domains.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成关于训练数据的洞察** —— 探索性数据分析（EDA）是所有数据科学家和机器学习专家在构建机器学习模型之前进行的重要实践。然而，从EDA中生成的洞察很少传达给非技术性的机器学习模型使用者。因此，DCXAI的一种方法是将生成的洞察传达给最终用户，以解释机器学习模型的潜在行为。这对那些可能没有机器学习知识但在自己领域内是专家的领域专家尤其有用。'
- en: Moreover, visualization of the data distribution can indicate how well the dataset
    is balanced. It can also show the presence of skewness and outliers in training
    data which can affect the model. Generating insights by building data profiles
    through statistical measures can also be very useful for local as well as global
    explanations.
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此外，数据分布的可视化可以指示数据集的平衡程度。它还可以显示训练数据中存在的偏斜和异常值，这可能影响模型。通过统计措施构建数据档案以生成洞察，也对局部和全局解释非常有用。
- en: '**Highlighting the data quality** — Most of the time, the poor performance
    of ML models is related to the poor quality of data used to train them. However,
    the information on data quality is rarely communicated to end-users. Consequently,
    when ML models fail to generate good predictions, end-users are never aware of
    the issues in the dataset. So, DCXAI involves explaining about the data quality
    by communicating about the potential data issues such as data drifts, correlated
    features, class imbalance, biased datasets and etc.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强调数据质量**——大多数情况下，机器学习模型的表现不佳与用于训练它们的数据质量差有关。然而，数据质量的信息很少传达给最终用户。因此，当机器学习模型未能生成良好的预测时，最终用户通常不知道数据集中的问题。因此，DCXAI涉及通过传达潜在的数据问题，如数据漂移、相关特征、类别不平衡、偏差数据集等，来解释数据质量。'
- en: It is indeed true that some of these data issues are complicated to understand
    as these are technical concepts. But when presented using simplified and interactive
    visualizations, it creates awareness about the data quality, which highlights
    the true reason for the failure of ML models.
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确实，一些数据问题复杂难懂，因为这些是技术概念。但是，当通过简化和交互式可视化呈现时，它会提高对数据质量的认识，从而突出机器学习模型失败的真正原因。
- en: '**Estimating data forecastability** — Sometimes, datasets are too noisy. Getting
    beyond a certain amount of accuracy is always difficult with such a dataset. Then,
    how do we gain the trust of our end users if we know that the trained model is
    not extremely accurate in making the correct predictions? I would say that the
    best way to gain trust is by being transparent and clearly communicating what
    is feasible. So, measuring **data forecastability** and communicating the model’s
    efficiency to end users helps to set the right expectation. Data forecastability
    is an estimation of the model’s performance using the underlying data.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**估计数据预测能力**——有时，数据集过于嘈杂。对于这样的数据集，超越一定的准确度总是困难的。那么，如果我们知道训练好的模型在做出正确预测时并不极其准确，我们如何赢得最终用户的信任？我认为，获得信任的最佳方法是保持透明，明确沟通可行的内容。因此，测量**数据预测能力**并向最终用户传达模型的效率有助于设定正确的期望。数据预测能力是对模型性能的估计，基于底层数据。'
- en: For example, we have a model to predict the stock price of a particular company.
    The stock price data that is being modeled by the ML algorithm can predict the
    stock price with a maximum of 60% accuracy. Beyond that point, it is not practically
    possible to generate a more accurate outcome using the given dataset. But let’s
    say that if other external factors are considered to supplement the current data,
    the model’s accuracy can be boosted. This proves that it is not the ML algorithm
    that is limiting the performance of the system, but rather the dataset that is
    used for modeling does not have sufficient information to get a better model performance.
    Hence, it is a limitation of the dataset that can be estimated by measure of data
    forecastability. It is better to perform data forecastability at a granular level
    to give additional insights about the performance of the ML model at different
    values of demographic variables, as illustrated by the following diagram.
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，我们有一个模型来预测某公司股票的价格。由机器学习算法建模的股票价格数据最多可以预测60%的准确率。超出这一点，使用给定的数据集生成更准确的结果在实践中是不可能的。但假设考虑其他外部因素来补充当前数据，模型的准确性可以提高。这证明了不是机器学习算法限制了系统的性能，而是用于建模的数据集没有足够的信息来获得更好的模型性能。因此，这是数据集的一个限制，可以通过数据预测能力的度量来估计。最好在更详细的层面上进行数据预测能力的评估，以提供有关机器学习模型在不同人口统计变量值下性能的额外洞察，如下图所示。
- en: '![](../Images/31cf969163572ef30585ca03a20caa18.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/31cf969163572ef30585ca03a20caa18.png)'
- en: Data forecastability estimate for different demographic variables (image by
    author)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 不同人口统计变量的数据预测估计（图像来源于作者）
- en: Benefit of DCXAI
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DCXAI的好处
- en: Now that we have understood the different approaches of DCXAI, let us also summarize
    its benefits as presented in the following points.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了DCXAI的不同方法，让我们总结一下它的好处，如下所示。
- en: Easy detection of biased and unfair data.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容易检测到有偏见和不公平的数据。
- en: Creating awareness about issues with data quality, purity, and integrity to
    explain the failure of ML models.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高对数据质量、纯洁性和完整性问题的认识，以解释ML模型的失败。
- en: DCXAI is more simple to understand for non-technical consumers of ML than other
    popular model-centric explanation methods such as LIME, SHAP, and saliency maps.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于非技术型的ML消费者，DCXAI比其他流行的模型中心解释方法如LIME、SHAP和显著性图更容易理解。
- en: Domain experts tend to have more trust in DCXAI than LIME and SHAP, as DCXAI
    creates more transparency about the datasets used to train ML models. They can
    use DCXAI to justify the model generated predictions by referring to the underlying
    training data.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 领域专家往往比LIME和SHAP更信任DCXAI，因为DCXAI能更透明地展示用于训练ML模型的数据集。他们可以利用DCXAI通过参考底层训练数据来证明模型生成的预测。
- en: '[](https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&pd_rd_w=Wr6SJ&content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_r=6P2PM599T97MRG7NZD9J&pd_rd_wg=m4qUW&pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&linkCode=li3&tag=adib0073-20&linkId=35506e1847de5c011fc57aa66c2b1d8e&language=en_US&ref_=as_li_ss_il&source=post_page-----8415be070416--------------------------------)
    [## Applied Machine Learning Explainability Techniques: Make ML models explainable
    and trustworthy for…'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[## Applied Machine Learning Explainability Techniques: Make ML models explainable
    and trustworthy for…](https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&pd_rd_w=Wr6SJ&content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_r=6P2PM599T97MRG7NZD9J&pd_rd_wg=m4qUW&pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&linkCode=li3&tag=adib0073-20&linkId=35506e1847de5c011fc57aa66c2b1d8e&language=en_US&ref_=as_li_ss_il&source=post_page-----8415be070416--------------------------------)'
- en: 'Applied Machine Learning Explainability Techniques: Make ML models explainable
    and trustworthy for practical…'
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Applied Machine Learning Explainability Techniques: Make ML models explainable
    and trustworthy for practical…'
- en: www.amazon.com](https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&pd_rd_w=Wr6SJ&content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_r=6P2PM599T97MRG7NZD9J&pd_rd_wg=m4qUW&pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&linkCode=li3&tag=adib0073-20&linkId=35506e1847de5c011fc57aa66c2b1d8e&language=en_US&ref_=as_li_ss_il&source=post_page-----8415be070416--------------------------------)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[Applied Machine Learning Explainability Techniques: Make ML models explainable
    and trustworthy for…](https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&pd_rd_w=Wr6SJ&content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_r=6P2PM599T97MRG7NZD9J&pd_rd_wg=m4qUW&pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&linkCode=li3&tag=adib0073-20&linkId=35506e1847de5c011fc57aa66c2b1d8e&language=en_US&ref_=as_li_ss_il&source=post_page-----8415be070416--------------------------------)'
- en: Making DCXAI more actionable through Directive Data-Centric Explanations
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过指令性数据中心解释使DCXAI更加可操作
- en: In my recent research publication — [Directive Explanations for Monitoring the
    Risk of Diabetes Onset](https://arxiv.org/pdf/2302.10671.pdf), I presented about
    an elaborate user-centered design process for an XAI dashboard that includes DCXAI.
    We have further made DCXAI more actionable by making the following adaptions to
    tailor these explanations for healthcare experts -
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在我最近的研究出版物——[监测糖尿病发病风险的指令性解释](https://arxiv.org/pdf/2302.10671.pdf)中，我介绍了一种详细的以用户为中心的设计过程，用于包含DCXAI的XAI仪表板。我们通过对这些解释进行以下调整，使DCXAI变得更加可操作，以便为医疗专家量身定制——
- en: Provided interactive visual explanations for exploring what-if scenarios.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供交互式视觉解释，以探索假设场景。
- en: Considering only actionable feature variables instead of non-actionable features.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只考虑可操作的特征变量，而不是不可操作的特征。
- en: Providing explicit visual indicators that enable users to explore the system
    to understand the working of the ML models.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供明确的视觉指示，帮助用户探索系统，以理解ML模型的工作原理。
- en: Obtaining local explanations with a global perspective.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从全球视角获得局部解释。
- en: With these additional modifications to traditional data-centric explanation
    approaches, we have designed and developed **Visually Directive Data-Centric Explanations**.
    You can find out more about this research study in the [research paper](https://arxiv.org/abs/2302.10671).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对传统数据中心解释方法进行这些附加修改，我们设计并开发了**视觉指令性数据中心解释**。你可以在[研究论文](https://arxiv.org/abs/2302.10671)中了解更多关于这项研究的内容。
- en: '[](https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&pd_rd_w=Wr6SJ&content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_r=6P2PM599T97MRG7NZD9J&pd_rd_wg=m4qUW&pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&linkCode=li3&tag=adib0073-20&linkId=35506e1847de5c011fc57aa66c2b1d8e&language=en_US&ref_=as_li_ss_il&source=post_page-----8415be070416--------------------------------)
    [## Applied Machine Learning Explainability Techniques: Make ML models explainable
    and trustworthy for…'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&pd_rd_w=Wr6SJ&content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_r=6P2PM599T97MRG7NZD9J&pd_rd_wg=m4qUW&pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&linkCode=li3&tag=adib0073-20&linkId=35506e1847de5c011fc57aa66c2b1d8e&language=en_US&ref_=as_li_ss_il&source=post_page-----8415be070416--------------------------------)
    [## 应用机器学习解释性技术：使机器学习模型在实践中可解释且值得信赖]'
- en: 'Applied Machine Learning Explainability Techniques: Make ML models explainable
    and trustworthy for practical…'
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 应用机器学习解释性技术：使机器学习模型在实践中可解释且值得信赖
- en: www.amazon.com](https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&pd_rd_w=Wr6SJ&content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_r=6P2PM599T97MRG7NZD9J&pd_rd_wg=m4qUW&pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&linkCode=li3&tag=adib0073-20&linkId=35506e1847de5c011fc57aa66c2b1d8e&language=en_US&ref_=as_li_ss_il&source=post_page-----8415be070416--------------------------------)
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.amazon.com](https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&pd_rd_w=Wr6SJ&content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&pf_rd_r=6P2PM599T97MRG7NZD9J&pd_rd_wg=m4qUW&pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&linkCode=li3&tag=adib0073-20&linkId=35506e1847de5c011fc57aa66c2b1d8e&language=en_US&ref_=as_li_ss_il&source=post_page-----8415be070416--------------------------------)'
- en: Summary
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this article, we have covered Data-Centric Explainable AI (DCXAI) and its
    various approaches. We have also covered how DCXAI is different from other XAI
    methods, such as LIME, SHAP, etc., which provide model-centric explanations. We
    have discussed about the different approaches to provide data-centric explanations.
    Additionally, we have discussed the benefits of DCXAI and how DCXAI can be further
    modified to generate more actionable explanations for domain experts and lay users.
    You can learn more about data-centric explanations from my book [Applied Machine
    Learning Explainability Techniques](https://amzn.to/3cY4c2h) and take a look at
    code examples presented in the [GitHub repo](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/)
    from the book.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们介绍了数据中心可解释AI（DCXAI）及其各种方法。我们还讨论了DCXAI与其他XAI方法（如LIME、SHAP等）的不同之处，这些方法提供的是模型中心的解释。我们探讨了提供数据中心解释的不同方法。此外，我们还讨论了DCXAI的好处，以及如何进一步修改DCXAI以生成更具可操作性的解释，供领域专家和普通用户使用。你可以通过我的书[应用机器学习解释性技术](https://amzn.to/3cY4c2h)了解更多关于数据中心解释的内容，并查看书中提供的[GitHub代码示例](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/)。
- en: 'Other XAI stories on TDS by the author:'
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 作者在TDS上的其他XAI故事：
- en: '[Explainable AI with TCAV from Google AI](/explainable-ai-with-tcav-from-google-ai-5408adf905e)'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[谷歌AI的可解释AI与TCAV](/explainable-ai-with-tcav-from-google-ai-5408adf905e)'
- en: '[Essential Explainable AI Python frameworks that you should know about](/essential-explainable-ai-python-frameworks-that-you-should-know-about-84d5063b75e9)'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[你应该了解的关键可解释AI Python框架](/essential-explainable-ai-python-frameworks-that-you-should-know-about-84d5063b75e9)'
- en: '[Explainable Machine Learning for Models Trained on Text Data: Combining SHAP
    with Transformer Models](/explainable-machine-learning-for-models-trained-on-text-data-combining-shap-with-transformer-5095ea7f3a8)'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[基于文本数据训练的模型的可解释机器学习：将SHAP与Transformer模型结合](/explainable-machine-learning-for-models-trained-on-text-data-combining-shap-with-transformer-5095ea7f3a8)'
- en: '[EUCA — An effective XAI framework to bring artificial intelligence closer
    to end-users](/euca-an-effective-xai-framework-to-bring-artificial-intelligence-closer-to-end-users-74bb0136ffb1)'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[EUCA——一个有效的XAI框架，将人工智能带到更接近终端用户](/euca-an-effective-xai-framework-to-bring-artificial-intelligence-closer-to-end-users-74bb0136ffb1)'
- en: '[Understand the Workings of SHAP and Shapley Values Used in Explainable AI](/understand-the-working-of-shap-based-on-shapley-values-used-in-xai-in-the-most-simple-way-d61e4947aa4e)'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[理解基于Shapley值的SHAP及其在可解释AI中的工作原理](/understand-the-working-of-shap-based-on-shapley-values-used-in-xai-in-the-most-simple-way-d61e4947aa4e)'
- en: '[How to Explain Image Classifiers Using LIME](/how-to-explain-image-classifiers-using-lime-e364097335b4)'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[如何使用LIME解释图像分类器](/how-to-explain-image-classifiers-using-lime-e364097335b4)'
- en: '**References**:'
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**参考资料**：'
- en: '[Directive Explanations for Monitoring the Risk of Diabetes Onset: Introducing
    Directive Data-Centric Explanations and Combinations to Support What-If Explorations](https://arxiv.org/abs/2302.10671)'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[监测糖尿病发病风险的指令性解释：介绍指令性数据中心解释和组合以支持假设探索](https://arxiv.org/abs/2302.10671)'
- en: '[Applied Machine Learning Explainability Techniques](https://amzn.to/3cY4c2h)'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[应用机器学习解释技术](https://amzn.to/3cY4c2h)'
- en: GitHub repo from the book Applied Machine Learning Explainability Techniques
    — [https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/)
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 书籍《应用机器学习解释技术》的 GitHub 仓库 — [https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/)
