- en: Top 5 Python Libraries for Extracting Text from Images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/top-5-python-libraries-for-extracting-text-from-images-c29863b2f3d](https://towardsdatascience.com/top-5-python-libraries-for-extracting-text-from-images-c29863b2f3d)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Understand and master OCR tools for text localization and recognition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://eugenia-anello.medium.com/?source=post_page-----c29863b2f3d--------------------------------)[![Eugenia
    Anello](../Images/537f444252cdc60709e7a19e37734c7b.png)](https://eugenia-anello.medium.com/?source=post_page-----c29863b2f3d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c29863b2f3d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c29863b2f3d--------------------------------)
    [Eugenia Anello](https://eugenia-anello.medium.com/?source=post_page-----c29863b2f3d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c29863b2f3d--------------------------------)
    ·7 min read·Jul 25, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/27d080f5ac1e997ff423101454b24b11.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Anna Sullivan](https://unsplash.com/@aesullivan2010) on [Unsplash](https://unsplash.com/photos/NFS3ekDQnlg)
  prefs: []
  type: TYPE_NORMAL
- en: Optical Character Recognition is an old, but still challenging problem that
    involves the detection and recognition of text from unstructured data, including
    images and PDF documents. It has cool applications in banking, e-commerce and
    content moderation in social media.
  prefs: []
  type: TYPE_NORMAL
- en: But as with everything topic in data science, there is a huge amount of resources
    when trying to learn how to solve the OCR task. This is why I am writing this
    tutorial, which can help you on getting started.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I am going to show some Python libraries that can allow you
    to fastly extract text from images without struggling too much. The explanation
    of the libraries is followed by a practical example. The dataset used is taken
    from [Kaggle](https://www.kaggle.com/datasets/robikscube/textocr-text-extraction-from-images-dataset?select=annot.csv).
    To simplify the concepts, I am just using an image of the film Rush.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get started!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b9cc6d407101e37a297043f4ad5d2c71.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from textOCR dataset. [Source](https://textvqa.org/textocr/download/).
  prefs: []
  type: TYPE_NORMAL
- en: '**Table of contents:**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**pytesseract**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**EasyOCR**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Keras-OCR**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**TrOCR**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**docTR**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 1\. pytesseract
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It is one of the most popular Python libraries for optical character recognition.
    It uses [Google’s Tesseract-OCR Engine](https://github.com/tesseract-ocr/tesseract)
    to extract text from images. There are multiple languages supported. Check [here](https://tesseract-ocr.github.io/tessdoc/Data-Files-in-different-versions.html)
    if you want to see if your language is supported. You just need a few lines of
    code to convert the image into text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/961750fc5f45797f9df4614b37ee09b9.png)'
  prefs: []
  type: TYPE_IMG
- en: We can also try the bounding box coordinates for each item detected from the
    image.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can notice, it estimates the bounding box for each character, not each
    word! In case, we want to extract the box for each word, there is another method
    that should be used instead of image_to_boxes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/50af5ba434e31508367cb9b7bb7a5b37.png)'
  prefs: []
  type: TYPE_IMG
- en: Illustration by Author
  prefs: []
  type: TYPE_NORMAL
- en: The result returned is not so perfect. For example, it interpreted “AFILM” as
    a unique word. Moreover, it didn’t detect and recognize all the words from the
    input image.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. EasyOCR
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/94667884ab1bf6bdb533ff145606d4fa.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot from [web demo](https://huggingface.co/spaces/tomofi/EasyOCR)
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s the turn of another open-source Python library: EasyOCR. Similarly to
    pytesseract, it supports [80+ languages](https://www.jaided.ai/easyocr/). You
    can try it fastly and easily without writing any code from a web demo. It uses
    the [CRAFT](https://arxiv.org/abs/1904.01941) algorithm to detect the text and
    the [CRNN](https://arxiv.org/abs/1507.05717) as recognition model. Moreover, these
    models are implemented using Pytorch.'
  prefs: []
  type: TYPE_NORMAL
- en: If you work on Google Colab, I recommend you set up the GPU, which helps speed
    up this framework.
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the following code lines to exploit this tool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b7b7cd05858ec97007ffd7c80728edb4.png)'
  prefs: []
  type: TYPE_IMG
- en: Illustration by Author
  prefs: []
  type: TYPE_NORMAL
- en: Without any effort, we have detected and recognized the text using EasyOCR.
    The results are much better compared to pytesseract. For each text detected, we
    also have the bounding box and the confidence level.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Keras-OCR
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Keras-OCR is another open-source library specialized in optical character recognition.
    As EasyOCR, it exploits the CRAFT detection model and the CRNN recognition model
    for solving the task. The difference from EasyOCR is that it’s implemented with
    Keras, instead of Pytorch. The only bad point of Keras-OCR is that it ignores
    non-English language.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the output of the first word extracted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'To visualize all the results, we convert the output into a Pandas Dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/da3f5a9147ea4923272c55d8b3f4fec4.png)'
  prefs: []
  type: TYPE_IMG
- en: Illustration by Author
  prefs: []
  type: TYPE_NORMAL
- en: Magically, we can see that we have a much clearer and more precise results.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. TrOCR
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'TrOCR is a generative image model, based on transformers, that detect the text
    from the images. It is composed of an **encoder** and a **decoder**: TrOCR uses
    a pre-trained image transformer as an encoder and a pre-trained text transformer
    as a decoder. For additional details, take a look at the [paper](https://arxiv.org/abs/2109.10282).
    There is also good documentation of the library on [Hugging Face’s platform](https://huggingface.co/docs/transformers/model_doc/trocr).'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we load the pre-trained models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Before passing the image, we need to resize and normalize it. Once the image
    has been transformed, we can extract the text using the `.generate()` method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Different from the previous libraries, it returns a meaningless number. Why?
    TrOCR just includes the recognition model, not the detection model. For solving
    the OCR task, there is the need to first detect the objects within the image and,
    then, extract the text from the input. Since it just focuses on the last step,
    it doesn’t reach good performances.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make it work well, it would be better to crop specific portions of the image
    using a bounding box, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/109b701db42b9c00d5de74714fab079a.png)'
  prefs: []
  type: TYPE_IMG
- en: Illustration by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we try to apply again the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/cf10f4aa586b1f234e6ed3a4210b0818.png)'
  prefs: []
  type: TYPE_IMG
- en: Illustration by Author
  prefs: []
  type: TYPE_NORMAL
- en: This is much better! This operation can be repeated for every word/phrase contained
    within the image.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. docTR
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, we are covering the last Python package for text detection and recognition
    from documents: docTR. It can interpret the document as a PDF or an image and,
    then, pass it to the two stage-approach. In docTR, there is the text detection
    model ([DBNet](https://mindee.github.io/doctr/latest/modules/models.html#doctr-models-detection)
    or [LinkNet](https://mindee.github.io/doctr/latest/modules/models.html#doctr-models-detection))
    followed by the [CRNN](https://mindee.github.io/doctr/latest//modules/models.html#doctr-models-recognition)
    model for text recognition. This library requires both Pytorch and Tensorflow
    installed since the implementation is done with both these deep learning frameworks.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'After, we import the relevant libraries for using docTR and load the model,
    which is a two-step approach. Indeed, we need to specify the DBNet with ResNet-50
    Backbone and CRNN with a VGG-16 backbone for text detection and text recognition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can finally read the file, use the pre-trained model and export the
    output as a nested dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the very long output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'For better visualization, it’s better to a double for loop and takes only the
    information we are interested in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/0689b763e189b58a6ad6656532af751b.png)'
  prefs: []
  type: TYPE_IMG
- en: Illustration by Author
  prefs: []
  type: TYPE_NORMAL
- en: That’s great! docTR is another good option to extract valuable information from
    images or PDFs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Final thoughts:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: These are five Python libraries that can be useful for your OCR project. Each
    of these tools has different advantages and disadvantages. Surely, the first thing
    to choosing one of these packages is to consider the language of the data you
    are analyzing. If you consider non-English languages, EasyOCR is probably the
    best choice for language covering and performances. If you have other suggestions,
    comment here. I hope that you have found useful this article for getting started
    with OCR. If you want to look at the complete output returned by these OCR models,
    the GitHub code is [here](https://github.com/eugeniaring/Medium-Articles/blob/main/CV/OCR_libraries.ipynb).
    Have a nice day!
  prefs: []
  type: TYPE_NORMAL
- en: '*Disclaimer: This data set is licensed under Attribution 4.0 International
    (*[*CC by 4.0*](https://textvqa.org/textocr/download/)*)*'
  prefs: []
  type: TYPE_NORMAL
- en: Did you like my article? [*Become a member*](https://eugenia-anello.medium.com/membership)
    *and get unlimited access to new data science posts every day! It’s an indirect
    way of supporting me without any extra cost to you. If you are already a member,*
    [*subscribe*](https://eugenia-anello.medium.com/subscribe) *to get emails whenever
    I publish new data science and Python guides!*
  prefs: []
  type: TYPE_NORMAL
