["```py\nfrom tensorflow.python.keras import Input\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, ConfusionMatrixDisplay, f1_score\nfrom sklearn.model_selection import train_test_split\nimport os\n```", "```py\nfrom numpy.random import seed\nseed(1)\n\nfrom tensorflow import random, config\nrandom.set_seed(1)\nconfig.experimental.enable_op_determinism()\n\nimport random\nrandom.seed(2)\n```", "```py\n# read dataset:\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n```", "```py\nprint(f\"The training data shape: {x_train.shape}, its label shape: {y_train.shape}\")\nprint(f\"The test data shape: {x_test.shape}, its label shape: {y_test.shape}\")\n```", "```py\nThe training data shape: (60000, 28, 28), its label shape: (60000,)\nThe test data shape: (10000, 28, 28), its label shape: (10000,)\n```", "```py\nprint(\"Minimum value:\", np.min(x_train[0]))\nprint(\"Maximum value:\", np.max(x_train[0]))\n```", "```py\nMinimum value: 0\nMaximum value: 255\n```", "```py\n# Display bars:\nfig, axs = plt.subplots(1, 2)\nunique, counts = np.unique(y_train, return_counts=True)\naxs[0].bar(unique, counts, width=0.4)\naxs[0].set_title('Train set')\nunique, counts = np.unique(y_test, return_counts=True)\naxs[1].bar(unique, counts, width=0.4)\naxs[1].set_title('Test set')\nplt.show()\n```", "```py\n# Scale images to the [0, 1] range:\nx_train = x_train.astype(\"float32\") / 255\nx_test = x_test.astype(\"float32\") / 255\n```", "```py\n# Data reshaping : from 2D image to row image\nx_train = x_train.reshape((x_train.shape[0], x_train.shape[1] * x_train.shape[2]))\nx_test = x_test.reshape((x_test.shape[0], x_test.shape[1] * x_test.shape[2]))\n```", "```py\n# One-hot encoding:\ny_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n```", "```py\nx_train = np.expand_dims(x_train, -1)\nx_test = np.expand_dims(x_test, -1)\nprint(f\"The training data shape: {x_train.shape}, its label shape: {y_train.shape}\")\nprint(f\"The test data shape: {x_test.shape}, its label shape: {y_test.shape}\")\n```", "```py\nThe training data shape: (60000, 28, 28, 1), its label shape: (60000, 10)\nThe test data shape: (10000, 28, 28, 1), its label shape: (10000, 10)\n```", "```py\n# Split dataset:\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3, random_state=42)\n```", "```py\n# Create model:\nmodel = Sequential()\nmodel.add(Input(shape=(train_x.shape[1],)))\nmodel.add(Dense(224, activation='sigmoid'))\nmodel.add(Dense(224, activation='sigmoid'))\nmodel.add(Dense(224, activation='sigmoid'))\nmodel.add(Dense(224, activation='sigmoid'))\nmodel.add(Dense(224, activation='sigmoid'))\nmodel.add(Dense(1, activation='relu'))\nprint(model.summary())\n```", "```py\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 224)               175840    \n_________________________________________________________________\ndense_1 (Dense)              (None, 224)               50400     \n_________________________________________________________________\ndense_2 (Dense)              (None, 224)               50400     \n_________________________________________________________________\ndense_3 (Dense)              (None, 224)               50400     \n_________________________________________________________________\ndense_4 (Dense)              (None, 224)               50400     \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 225       \n=================================================================\nTotal params: 377,665\nTrainable params: 377,665\nNon-trainable params: 0\n_________________________________________________________________\n```", "```py\nkeras.layers.Dropout(rate, **kwargs)\n```", "```py\n# Create model:\nmodel = Sequential()\nmodel.add(Input(shape=(train_x.shape[1],)))\nmodel.add(Dense(224, activation='relu'))\nmodel.add(Dropout(rate=0.4))\nmodel.add(Dense(224, activation='relu'))\nmodel.add(Dropout(rate=0.4))\nmodel.add(Dense(10, activation='softmax'))\nprint(model.summary())\n```", "```py\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 224)               175840    \n_________________________________________________________________\ndropout (Dropout)            (None, 224)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 224)               50400     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 224)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                2250      \n=================================================================\nTotal params: 228,490\nTrainable params: 228,490\nNon-trainable params: 0\n_________________________________________________________________\n```", "```py\nkeras.layers.Conv2D(\n    filters,\n    kernel_size,\n    **kwargs\n)\n```", "```py\nkeras.layers.MaxPooling2D(\n    pool_size=(2, 2), **kwargs\n)\n```", "```py\n# Create model:\nmodel = Sequential()\nmodel.add(Input(shape=(28, 28, 1)))\nmodel.add(Conv2D(32, kernel_size=3, activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(64, kernel_size=3, activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(n_labels, activation=\"softmax\"))\nprint(model.summary())\n```", "```py\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 26, 26, 32)        320       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 1600)              0         \n_________________________________________________________________\ndropout (Dropout)            (None, 1600)              0         \n_________________________________________________________________\ndense (Dense)                (None, 10)                16010     \n=================================================================\nTotal params: 34,826\nTrainable params: 34,826\nNon-trainable params: 0\n_________________________________________________________________\n```", "```py\n# Train:\nloss = 'mae'\nmetric = 'mse'\nepochs = 200\nmodel.compile(loss=loss, optimizer='adam', metrics=[metric])\nhistory = model.fit(x_train, y_train, epochs=epochs, batch_size=128, verbose=1, validation_data=(x_val, y_val))\n```", "```py\nEpoch 200/200\n329/329 [==============================] - 1s 2ms/step - loss: 0.0188 - mse: 0.0525 - val_loss: 0.0946 - val_mse: 0.3838\n```", "```py\n# Train:\nloss = 'categorical_crossentropy'\nmetric = 'accuracy'\nepochs = 20\nmodel.compile(loss=loss, optimizer='adam', metrics=[metric])\nhistory = model.fit(x_train, y_train, epochs=epochs, batch_size=128, verbose=1, validation_data=(x_val, y_val))\n```", "```py\nEpoch 20/20\n329/329 [==============================] - 1s 2ms/step - loss: 0.0469 - accuracy: 0.9838 - val_loss: 0.0868 - val_accuracy: 0.9769\n```", "```py\n# Train:\nloss = 'categorical_crossentropy'\nmetric = 'accuracy'\nepochs = 15\nmodel.compile(loss=loss, optimizer='adam', metrics=[metric])\nhistory = model.fit(x_train, y_train, epochs=epochs, batch_size=128, verbose=1, validation_data=(x_val, y_val))\n```", "```py\nEpoch 15/15\n329/329 [==============================] - 4s 14ms/step - loss: 0.0340 - accuracy: 0.9892 - val_loss: 0.0371 - val_accuracy: 0.9893\n```", "```py\nModel.predict(x)\n```", "```py\nx = np.expand_dims(x_train[0], 0)\n```", "```py\ny = model.predict(x)[0]\n```", "```py\nprint(y)\ny = np.clip(y, 0, 9)\nprint(y)\ny = np.rint(y)\nprint(y)\n```", "```py\n[6.9955063]\n[6.9955063]\n[7.]\n```", "```py\nprint(y)\ny = np.argmax(y)\nprint(y)\n```", "```py\n[4.8351421e-07 2.1228843e-04 2.9102326e-04 2.4277648e-04 9.7677308e-05\n 6.5721008e-07 9.9738841e-08 9.9599850e-01 3.5152045e-06 3.1529362e-03]\n7\n```", "```py\n# Display loss:\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Single output model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'])\nplt.show()\n# Display metric:\nplt.plot(history.history[metric])\nplt.plot(history.history[f'val_{metric}'])\nplt.title(f'Single output model {metric}')\nplt.ylabel(metric)\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'])\nplt.show()\n```", "```py\n# Evaluation:\ntest_results = model.evaluate(x_test, y_test, verbose=1)\nprint(f'Test set: - loss: {test_results[0]} - {metric}: {test_results[1]}')\n```", "```py\nTest set: - loss: 0.09854138642549515 - mse: 0.4069458544254303\n```", "```py\nTest set: - loss: 0.08896738290786743 - accuracy: 0.9793999791145325\n```", "```py\nTest set: - loss: 0.02704194374382496 - accuracy: 0.9908000230789185\n```", "```py\n# Classificati evaluation with output one-hot encoding:\npred_train = np.argmax(model.predict(x_train), axis=1)\npred_val = np.argmax(model.predict(x_val), axis=1)\npred_test = np.argmax(model.predict(x_test), axis=1)\nyy_train = np.argmax(y_train, axis=1)\nyy_val = np.argmax(y_val, axis=1)\nyy_test = np.argmax(y_test, axis=1)\nprint(\"Displaying other metrics:\")\nprint(\"\\t\\tAccuracy (%)\\tPrecision (%)\\tRecall (%)\")\nprint(\n    f\"Train:\\t{round(accuracy_score(yy_train, pred_train, normalize=True) * 100, 2)}\\t\\t\\t\"\n    f\"{round(precision_score(yy_train, pred_train, average='macro') * 100, 2)}\\t\\t\\t\"\n    f\"{round(recall_score(yy_train, pred_train, average='macro') * 100, 2)}\")\nprint(\n    f\"Val :\\t{round(accuracy_score(yy_val, pred_val, normalize=True) * 100, 2)}\\t\\t\\t\"\n    f\"{round(precision_score(yy_val, pred_val, average='macro') * 100, 2)}\\t\\t\\t\"\n    f\"{round(recall_score(yy_val, pred_val, average='macro') * 100, 2)}\")\nprint(\n    f\"Test:\\t{round(accuracy_score(yy_test, pred_test, normalize=True) * 100, 2)}\\t\\t\\t\"\n    f\"{round(precision_score(yy_test, pred_test, average='macro') * 100, 2)}\\t\\t\\t\"\n    f\"{round(recall_score(yy_test, pred_test, average='macro') * 100, 2)}\")\n```", "```py\nDisplaying other metrics:\n  Accuracy (%) Precision (%) Recall (%) F-measure (%)\nTrain: 99.67   99.67   99.67   99.67\nVal : 97.02   96.99   97.0   96.99\nTest: 97.14   97.1   97.11   97.11\n```", "```py\nDisplaying other metrics:\n  Accuracy (%) Precision (%) Recall (%) F-measure (%)\nTrain: 99.86   99.86   99.86   99.86\nVal : 97.98   97.98   97.95   97.96\nTest: 97.94   97.94   97.91   97.92\n```", "```py\nDisplaying other metrics:\n    Accuracy (%) Precision (%) Recall (%) F-measure (%)\nTrain: 99.55   99.56   99.54   99.55\nVal : 98.93   98.93   98.92   98.92\nTest: 99.08   99.09   99.07   99.08\n```", "```py\n# Confusion matrix:\nConfusionMatrixDisplay.from_predictions(yy_val, pred_val, normalize='true')\nplt.savefig('output/conv/confmat.png', bbox_inches='tight')\nplt.show()\n```", "```py\n# create an array of the misclassified indexes\nmisclass_indexes = np.where(yy_test != pred_test)[0]\n# display the 5 worst classifications\nfig, axs = plt.subplots(2, 5, figsize=(12, 6))\naxs = axs.flat\nfor i in range(10):\n    if i < len(misclass_indexes):\n        axs[i].imshow(x_test[misclass_indexes[i]], cmap='gray')\n        axs[i].set_title(\"True: {}\\nPred: {}\".format(yy_test[misclass_indexes[i]],\n                                                     pred_test[misclass_indexes[i]]))\n        axs[i].axis('off')\n# plt.show()\nplt.show()\n```"]