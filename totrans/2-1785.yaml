- en: 'Retro Data Science: Testing the First Versions of YOLO'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/retro-data-science-testing-the-first-versions-of-yolo-799b9c1835d7](https://towardsdatascience.com/retro-data-science-testing-the-first-versions-of-yolo-799b9c1835d7)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let's travel 8 years back in time
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://dmitryelj.medium.com/?source=post_page-----799b9c1835d7--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page-----799b9c1835d7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----799b9c1835d7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----799b9c1835d7--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page-----799b9c1835d7--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----799b9c1835d7--------------------------------)
    ·8 min read·Jun 22, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6868311449632a8f33870a1ec215e355.png)'
  prefs: []
  type: TYPE_IMG
- en: Objects detection with YOLO, Image by author
  prefs: []
  type: TYPE_NORMAL
- en: The world of data science is constantly changing. Often, we cannot see these
    changes just because they are going slowly, but after some time, it is easy to
    watch back and see that the landscape became drastically different. Tools and
    libraries, which were at the cutting edge of progress only 10 years ago, can be
    completely forgotten today.
  prefs: []
  type: TYPE_NORMAL
- en: YOLO (You Only Look Once) is a popular object detection library. Its first version
    was released a pretty long time ago, in 2015\. YOLO was working fast, it provided
    good results, and the pre-trained models were publicly available. The model quickly
    became popular, and the project is still actively improving nowadays. This gives
    us the opportunity to see how data science tools and libraries have evolved over
    the years. In this article, I will test different YOLO versions, from the very
    first V1 up to the latest V8.
  prefs: []
  type: TYPE_NORMAL
- en: 'For further testing, I will use this image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c80b38ffa792b0fd9df9cd624b0d83d4.png)'
  prefs: []
  type: TYPE_IMG
- en: Test image, made by author
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get started.
  prefs: []
  type: TYPE_NORMAL
- en: YOLO V1..V3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The very first paper, “You Only Look Once: Unified, Real-Time Object Detection,”
    about YOLO [was released in 2015](https://arxiv.org/abs/1506.02640). And surprisingly,
    YOLO v1 is still [available for download](https://pjreddie.com/darknet/yolov1/).
    As Mr.Redmon, one of the authors of the original paper, [wrote](https://pjreddie.com/darknet/yolov1/),
    he is keeping this version “for historical purposes”, and this is really nice
    indeed. But can we run it today? The model is distributed in the form of two files.
    The configuration file “`yolo.cfg`" contains details about the neural network
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: And the second file “`yolov1.weights`", as the name suggests, contains the weights
    of the pre-trained model.
  prefs: []
  type: TYPE_NORMAL
- en: This type of format is not from PyTorch or Keras. It turned out that the model
    was created using **Darknet**, an open-source neural network framework written
    in C. This project is still [available on GitHub](https://github.com/pjreddie/darknet),
    but it looks abandoned. At the moment of writing this article, there are 164 pull
    requests and 1794 open issues; the last commits were made in 2018, and later only
    README.md was changed (well, this is probably how the death of the project looks
    in the modern digital world).
  prefs: []
  type: TYPE_NORMAL
- en: 'The original Darknet project is abandoned; this is bad news. The good news
    is that the *readNetFromDarknet* method is still available in OpenCV, and it is
    [present](https://docs.opencv.org/5.x/d6/d0f/group__dnn.html) even in the latest
    OpenCV versions. So, we can easily try to load the original YOLO v1 model using
    the modern Python environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Alas, it did not work; I only got an error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'It turned out that “yolo.cfg” has a layer named “local”, which is not supported
    by OpenCV, and I don’t know if there is a workaround for that. Anyway, the [YOLO
    v2 config](https://pjreddie.com/darknet/yolov2/) does not have this layer anymore,
    and this model can be successfully loaded in OpenCV:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the model is not as easy as we might expect. First, we need to find the
    output layers of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we need to load the image and convert it into binary format, which the
    model can understand:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can run forward propagation. A “forward” method will run the calculations
    and return the requested layer outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Making the forward propagation is straightforward, but parsing the output can
    be a bit tricky. The model is producing 85-dimensional feature vectors as an output,
    where the first 4 digits represent object rectangles, the 5th digit is a probability
    of the presence of an object, and the last 80 digits contain the probability information
    for the 80 categories the model was trained on. Having this information, we can
    draw the labels over the original image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Here I use *np.argmax* to find the class ID with the maximum probability. The
    YOLO model was trained using the [COCO](https://cocodataset.org/) (Common Objects
    in Context, Creative Commons Attribution 4.0 License) dataset, and for simplicity
    reasons, I placed all 80 label names directly in the code. I also used the OpenCV
    [NMSBoxes](https://docs.opencv.org/4.7.0/d6/d0f/group__dnn.html#ga9d118d70a1659af729d01b10233213ee)
    method to combine embedded rectangles together.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final result looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1fc1bfd1fb37ff086f372456ea726128.png)'
  prefs: []
  type: TYPE_IMG
- en: YOLO v2 results, Image by author
  prefs: []
  type: TYPE_NORMAL
- en: We successfully ran a model released in 2016 in a modern environment!
  prefs: []
  type: TYPE_NORMAL
- en: 'The next version, YOLO v3, was released two years later, in 2018, and we can
    also run it using the same code (the weights and config files [are available online](https://pjreddie.com/darknet/yolo/)).
    As the authors [wrote in the paper](https://arxiv.org/abs/1804.02767), the new
    model is more accurate, and we can easily verify this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9d0b929f5bdc80b6c4ecca60c513ce1c.png)'
  prefs: []
  type: TYPE_IMG
- en: YOLO v3 results, Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, a V3 model was able to find more objects on the same image. Those readers
    who are interested in technical details can read this [TDS article](/yolo-v3-object-detection-53fb7d3bfe6b)
    written in 2018.
  prefs: []
  type: TYPE_NORMAL
- en: YOLO V5..V7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we can see, the model loaded with the *readNetFromDarknet* method works,
    but the required code is pretty “low-level” and cumbersome. OpenCV developers
    decided to make life easier, and in 2019, a new [*DetectionModel*](https://docs.opencv.org/4.1.2/d3/df1/classcv_1_1dnn_1_1DetectionModel.html)class
    was added to version 4.1.2\. We can load the YOLO model this way; the general
    logic remains the same, but the required amount of code is much smaller. The model
    directly returns class IDs, confidence values, and rectangles in one method call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, all the low-level code needed for extracting boxes and confidence
    values from the model output is not needed anymore.
  prefs: []
  type: TYPE_NORMAL
- en: 'The result of running YOLO v7 is, in general, the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6ec0648d9b747deb482d6832dc877002.png)'
  prefs: []
  type: TYPE_IMG
- en: YOLO v7 results, Image by author
  prefs: []
  type: TYPE_NORMAL
- en: YOLO V8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The [8th version](https://github.com/ultralytics/ultralytics) was released
    in 2023, so I cannot consider it “retro”, at least at the moment of writing this
    text. But just to compare the results, let’s see the code required nowadays to
    run YOLO:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the code became even more compact. We don’t need to take care
    of dataset label names (the model provides a “names” property) or how to draw
    rectangles and labels on the image (there is a special *BoxAnnotator* class for
    that). We even don’t need to download model weights anymore; the library will
    do it automatically for us. Compared to 2016, the program from 2023 “shrunk” from
    about 50 to about 5 lines of code! It is obviously a nice improvement, and modern
    developers don’t need to know about forward propagation or the output level format
    anymore. The model just works as a black box with some “magic” inside. Is it good
    or bad? I don’t know :)
  prefs: []
  type: TYPE_NORMAL
- en: 'As for the result itself, it’s pretty accurate:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a034b88e25cc58d7056f681b6e27d499.png)'
  prefs: []
  type: TYPE_IMG
- en: YOLO v8 results, Image by author
  prefs: []
  type: TYPE_NORMAL
- en: The model works well, and at least on my computer, the calculation speed improved
    compared to v7, maybe because of the better use of the GPU.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this article, we were able to test almost all YOLO models, made from 2016
    up to 2023\. At first glance, attempts to run a model, released almost 10 years
    ago, may look like a waste of time. But as for me, I learned a lot while doing
    these tests:'
  prefs: []
  type: TYPE_NORMAL
- en: It was interesting to see how popular data science tools and libraries have
    evolved over the years. The trend of moving from low-level code to high-level
    methods, which do everything and even download the pre-trained model before execution
    (at least for now, without asking for a subscription key yet, but who knows what
    will be next 10 years later?), looks clear. Is it good or bad? This is an interesting
    and open question.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It was important to know that OpenCV is “natively” capable of running deep learning
    models. This allows using neural network models not only in large frameworks like
    PyTorch or Keras but also in pure Python or even C++ applications. Not every application
    is running in a cloud with virtually unlimited resources. The IoT market is growing,
    and this is especially important for running neural networks on low-power devices
    like robots, surveillance cameras, or smart doorbells.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next article, I will test it in more detail and show how YOLO v8 runs
    on a low-powered board like a Raspberry Pi, and we will be able to test both Python
    and C++ versions. Stay tuned.
  prefs: []
  type: TYPE_NORMAL
- en: If you enjoyed this story, feel free [to subscribe](https://medium.com/@dmitryelj/membership)
    to Medium, and you will get notifications when my new articles will be published,
    as well as full access to thousands of stories from other authors.
  prefs: []
  type: TYPE_NORMAL
