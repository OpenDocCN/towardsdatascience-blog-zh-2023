- en: How Few-Shot Learning is Automating Document Labeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-few-shot-learning-is-automating-document-labeling-43f9868c0f74](https://towardsdatascience.com/how-few-shot-learning-is-automating-document-labeling-43f9868c0f74)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Leveraging GPT Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://walidamamou.medium.com/?source=post_page-----43f9868c0f74--------------------------------)[![Walid
    Amamou](../Images/c5ae089c59a5ff070f0f90ad63ee3817.png)](https://walidamamou.medium.com/?source=post_page-----43f9868c0f74--------------------------------)[](https://towardsdatascience.com/?source=post_page-----43f9868c0f74--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----43f9868c0f74--------------------------------)
    [Walid Amamou](https://walidamamou.medium.com/?source=post_page-----43f9868c0f74--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----43f9868c0f74--------------------------------)
    ·5 min read·Apr 7, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6ec1bdbc7b5261ca7850c4adbf1af6e4.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [DeepMind](https://unsplash.com/@deepmind?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/Vqm8hzQIzic?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: Manual document labeling is a time-consuming and tedious process that often
    requires significant resources and can be prone to errors. However, recent advancements
    in machine learning, particularly the technique known as few-shot learning, are
    making it easier to automate the labeling process. Large Language Models (LLMs)
    in particular are excellent few shot learners thanks for their emergent capability
    in context learning.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we’ll take a closer look at how few-shot learning is transforming
    document labeling, specifically for Named Entity Recognition which is the most
    important task in document processing. We will show how the [UBIAI](https://ubiai.tools)’s
    platform is making it easier than ever to automate this critical task using few
    shot labeling techniques.
  prefs: []
  type: TYPE_NORMAL
- en: What is Few-Shot Learning?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Few-shot learning is a machine learning technique that enables models to learn
    a given task with only a few labeled examples. Without modifying its weights,
    the model can be tuned to perform a specific task by including concatenated training
    examples of these tasks in its input and asking the model to predict the output
    of a target text. Here is an example of few shot learning for the task of Named
    Entity Recognition (NER) using 3 examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The prompt typically begins by instructing the model to perform a specific task,
    such as “Extract entities from the following sentences without altering the original
    words.” Notice, we’ve added the instruction “without changing the original words”
    to prevent the LLM from hallucinating random texts, which it is notoriously known
    for. This has proven critical in obtaining consistent responses from the model.
  prefs: []
  type: TYPE_NORMAL
- en: The few-shot learning phenomenon has been extensively studied in this [article](https://arxiv.org/abs/2303.07895),
    which I highly recommend. Essentially, the paper demonstrates that, under mild
    assumptions, the pretraining distribution of the model is a mixture of latent
    tasks that can be efficiently learned through in-context learning. In this case,
    in-context learning is more about identifying the task than about learning it
    by adjusting the model weights.
  prefs: []
  type: TYPE_NORMAL
- en: Few-shot Labeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Few-shot learning has an excellent practical application in the data labeling
    space, often referred as few-shot labeling. In this case, we provide the model
    few labeled examples and ask it to predict the labels of the subsequent documents.
    However, integrating this capability in a functional data labeling platform is
    easier said than done, here are few challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: LLMs are inherently text generators and tend to generate variable output. Prompt
    engineering is critical to make them create predictable output that can be later
    used to auto-label the data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Token limitation: LLMs such as OpenAI’s GPT-3 is limited to 4000 tokens per
    request which limits the length of documents that can be sent at once. Chunking
    and splitting the data before sending the request becomes essential.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Span offset calculation: After receiving the output from the model, we need
    to search its occurrence in the document and label it correctly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Few Shot Labeling with UBIAI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ve recently added few shot labeling capability by integrating [OpenAI’s GPT-3
    Davinci](https://platform.openai.com/docs/models/gpt-3) with [UBIAI annotation
    tool](https://ubiai.tools). The tool currently support few-shot NER task for unstructured
    and semi-structured documents such as PDFs and scanned images.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started:'
  prefs: []
  type: TYPE_NORMAL
- en: Simply label 1–5 examples
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enable few-shot GPT model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run prediction on a new unlabeled document
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here is an example of few shot NER on job description with 5 examples provided:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7d8f055d072d89a4e75d697c6971f880.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Few Shot NER on unstructured text'
  prefs: []
  type: TYPE_NORMAL
- en: The GPT model accurately predicts most entities with just five in-context examples.
    Because LLMs are trained on vast amounts of data, this few-shot learning approach
    can be applied to various domains, such as legal, healthcare, HR, insurance documents,
    etc., making it an extremely powerful tool.
  prefs: []
  type: TYPE_NORMAL
- en: However, the most surprising aspect of few-shot learning is its adaptability
    to semi-structured documents with limited context. In the example below, I provided
    GPT with only one labeled OCR’d invoice example and asked it to label the next.
    The model surprisingly predicted many entities accurately. With even more examples,
    the model does an exceptional job of generalizing to semi-structured documents
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eca7b6c115a052f7f414c0eec993e0fe.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Few Shot NER on PDF'
  prefs: []
  type: TYPE_NORMAL
- en: 'For an in-depth tutorial of the few-shot labeling feature, checkout the video
    below:'
  prefs: []
  type: TYPE_NORMAL
- en: UBIAI’s Few Shot Labeling Tutorial
  prefs: []
  type: TYPE_NORMAL
- en: 'Conclusion:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Few-shot learning is revolutionizing the document labeling process. By integrating
    few-shot labeling capabilities into functional data labeling platforms, such as
    UBIAI’s annotation tool, it is now possible to automate critical tasks like Named
    Entity Recognition (NER) in unstructured and semi-structured documents. This does
    not imply that LLMs will replace human labelers anytime soon. Instead, they augment
    their capabilities by making them more efficient. With the power of few-shot learning,
    LLMs can label vast amounts of data and apply to multiple domains, such as legal,
    healthcare, HR, and insurance documents, to train smaller and more accurate specialized
    models that can be efficiently deployed.
  prefs: []
  type: TYPE_NORMAL
- en: We’re currently adding support for few-shot relation extraction and document
    classification, stay tuned!
  prefs: []
  type: TYPE_NORMAL
- en: Follow us on Twitter [@UBIAI5](https://twitter.com/UBIAI5) or [subscribe here](https://walidamamou.medium.com/subscribe)!
  prefs: []
  type: TYPE_NORMAL
