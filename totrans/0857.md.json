["```py\nimport rioxarray\n\nfile_path  = \"GHS_POP_E2030_GLOBE_R2023A_54009_100_V1_0/GHS_POP_E2030_GLOBE_R2023A_54009_100_V1_0.tif\" \n\ndata_array = rioxarray.open_rasterio(file_path, chunks=True, lock=False)\ndata_array\n```", "```py\n# WARNING: THIS CODE BLOCK WILL MOST LIKELY CAUSE A MEMORY OVERFLOW ERROR\n\nimport datashader as ds\nimport xarray as xr\nfrom colorcet import palette\nfrom datashader import transfer_functions as tf\n\n# prepare to plot\ndata_array_p = xr.DataArray(data_array)[0]\ndata_array_p = data_array_p.where(data_array_p > 0)\ndata_array_p = data_array_p.compute()\n\n# get the image size\nsize = 1200\nasp  = data_array_p.shape[0] / data_array_p.shape[1]\n\n# create the data shader canvas\ncvs = ds.Canvas(plot_width=size, plot_height=int(asp*size))\nraster = cvs.raster(data_array_p)\n\n# draw the image\ncmap = palette[\"fire\"]\nimg = tf.shade(raster, how=\"eq_hist\", cmap=cmap)\nimg\n```", "```py\nimport datashader as ds\nimport xarray as xr\nfrom colorcet import palette\nfrom datashader import transfer_functions as tf\nimport numpy as np\n\n# crop the data array\ndata_array_c = data_array.rio.clip_box(minx=-1_000_000.0, miny=4_250_000.0, maxx=2_500_000.0, maxy=7_750_000.0)\ndata_array_c = xr.DataArray(data_array_c)\n\n# prepare to plot\ndata_array_c = xr.DataArray(data_array_c)[0]\ndata_array_c = data_array_c.where(data_array_c > 0)\ndata_array_c = data_array_c.compute()\ndata_array_c = np.flip(data_array_c, 0)\n\n# get the image size\nsize = 1200\nasp  = data_array_c.shape[0] / data_array_c.shape[1]\n\n# create the data shader canvas\ncvs = ds.Canvas(plot_width=size, plot_height=int(asp*size))\nraster = cvs.raster(data_array_c)\n\n# draw the image\ncmap = palette[\"fire\"]\nimg = tf.shade(raster, how=\"eq_hist\", cmap=cmap)\nimg = tf.set_background(img, \"black\")\n\nimg\n```", "```py\n# create the data shader canvas\ncvs = ds.Canvas(plot_width=size, plot_height=int(asp*size))\nraster = cvs.raster(data_array_c)\n\n# draw the image\ncmap = palette[\"bmw\"]\nimg = tf.shade(raster, how=\"eq_hist\", cmap=cmap)\nimg = tf.set_background(img, \"black\")\n\nimg\n```", "```py\n# a quick way to down-sample the data\ndownsampling_factor = 20\n\ndownsampled_data_array = data_array.coarsen(x=downsampling_factor, y=downsampling_factor).mean()\ndownsampled_data_array\n```", "```py\nminx = float(data_array.x.min().values)\nmaxx = float(data_array.x.max().values)\nminy = float(data_array.y.min().values)\nmaxy = float(data_array.y.max().values)\n\nN = 10\nxstep = (maxx-minx) / N\nystep = (maxy-miny) / N\n\nxsteps = list(np.arange(minx, maxx, xstep)) \nysteps = list(np.arange(miny, maxy, ystep))\n```", "```py\nimport os\nfoldout = 'world_map_image_segments'\nif not os.path.exists(foldout):\n    os.makedirs(foldout)\n\nfor idx_x, x_coord in enumerate(xsteps):\n    for idx_y, y_coord in enumerate(ysteps):\n\n        if not os.path.exists(foldout+'/'+str(idx_x)+'_'+str(idx_y)+'.png'):\n\n            data_array_c = data_array.rio.clip_box( minx=x_coord,  miny=y_coord,  maxx=x_coord+xstep, maxy=y_coord+ystep)\n            data_array_c = xr.DataArray(data_array_c)[0]\n            data_array_c = data_array_c.fillna(0)\n            data_array_c = data_array_c.where(data_array_c > 0)\n            data_array_c = data_array_c.compute()\n            data_array_c = np.flip(data_array_c, 0)\n\n            size = 2000\n            asp  = data_array_c.shape[0] / data_array_c.shape[1]\n\n            cvs = ds.Canvas(plot_width=size, plot_height=int(asp*size))\n            raster = cvs.raster(data_array_c)\n\n            cmap = palette[\"fire\"]\n            img = tf.shade(raster, how=\"eq_hist\", cmap=cmap)\n            img = tf.set_background(img, \"black\")\n\n            pil_image = img.to_pil()\n            pil_image.save(foldout+'/'+str(idx_x)+'_'+str(idx_y)+ '.png')\n            print('SAVED: ', x_coord, y_coord, y_coord+xstep,y_coord+ystep) \n```", "```py\nfrom PIL import Image\n\ndef find_dimensions(image_dir):\n    max_x = 0\n    max_y = 0\n\n    for filename in os.listdir(image_dir):\n        if filename.endswith(\".png\"):\n            x, y = map(int, os.path.splitext(filename)[0].split(\"_\"))\n            max_x = max(max_x, x)\n            max_y = max(max_y, y)\n\n    return max_x + 1, max_y + 1 \n\nimage_dir = foldout\nsegment_width = size\nsegment_height = int(asp*size)\n\n# Determine the dimensions of the large image\nlarge_image_width, large_image_height = find_dimensions(image_dir)\n\n# Create an empty large image (white background)\nlarge_image = Image.new(\"RGB\", (large_image_width * segment_width, large_image_height * segment_height), \"black\")\n\n# Loop through the individual image segments and paste them into the large image\nfor filename in sorted(os.listdir(image_dir)):\n    if filename.endswith(\".png\"):\n        x, y = map(int, os.path.splitext(filename)[0].split(\"_\"))\n        segment_image = Image.open(os.path.join(image_dir, filename))\n        x_offset = x * segment_width\n        y_offset = large_image_height * segment_height-1*y * segment_height\n        large_image.paste(segment_image, (x_offset, y_offset))\n\n# Save the merged large image\nlarge_image.save(\"global_population_map.png\") \n```", "```py\n# parse the data\ndata_file = 'deu_ppp_2020_constrained.tif'\ndata_array = rioxarray.open_rasterio(data_file, chunks=True, lock=False)\n\n# prepare the data\ndata_array = xr.DataArray(data_array)[0]\ndata_array = data_array.where(data_array > 0)\ndata_array = data_array.compute()\ndata_array = np.flip(data_array, 0)\n\n# get the image size\nsize = 1200\nasp  = data_array.shape[0] / data_array.shape[1]\n\n# create the data shader canvas\ncvs = ds.Canvas(plot_width=size, plot_height=int(asp*size))\nraster = cvs.raster(data_array)\n\n# draw the image\ncmap = palette[\"fire\"]\nimg = tf.shade(raster, how=\"eq_hist\", cmap=cmap)\nimg = tf.set_background(img, \"black\")\nimg\n```", "```py\nfrom shapely.ops import cascaded_union\nimport geopandas as gpd\n\nadmin = gpd.read_file('tufts-berlin-bezirke-boroughs01-geojson.json')\nadmin = gpd.GeoDataFrame(cascaded_union(admin.geometry.to_list()), columns = ['geometry']).head(1)\n\nadmin.plot()\n```", "```py\nimport pandas as pd\n\ndf_berlin = pd.DataFrame(data_array.to_series(), columns = ['population']).dropna()\n```", "```py\nfrom shapely.geometry import Point\n\n# find the limiting bounding box for easier coodinate-selection\nminx, miny, maxx, maxy = admin.bounds.T[0].to_list()\n\npoints = []\npopulation = df_berlin.population.to_list()\nindicies   = list(df_berlin.index)\n\n# create Point geometries from the points falling into this bounding box\ngeodata = []\nfor ijk, (lon, lat) in enumerate(indicies):\n    if minx <= lat <= maxx and miny <= lon <= maxy:   \n        geodata.append({'geometry' : Point(lat, lon), 'population' : population[ijk]})\n\n# build a GeoDataFrame\ngdf_berlin = gpd.GeoDataFrame(geodata)\ngdf_berlin = gpd.overlay(gdf_berlin, admin)\n```", "```py\nimport matplotlib.pyplot as plt\n\nf, ax = plt.subplots(1,1,figsize=(15,15))\n\nadmin.plot(ax=ax, color = 'k', edgecolor = 'orange', linewidth = 3)\n\ngdf_berlin.plot(column = 'population', \n                cmap = 'inferno', \n                ax=ax, \n                alpha = 0.9, \n                markersize = 0.25)\n\nax.axis('off')\nf.patch.set_facecolor('black')\n```"]