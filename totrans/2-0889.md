# 寻找改进的改写

> 原文：[https://towardsdatascience.com/finding-improved-rephrasings-b5fb002ac811](https://towardsdatascience.com/finding-improved-rephrasings-b5fb002ac811)

## 使用带有机器学习元素的Trie

[](https://jagota-arun.medium.com/?source=post_page-----b5fb002ac811--------------------------------)[![Arun Jagota](../Images/3c3eb142f671b5fb933c2826d8ed78d9.png)](https://jagota-arun.medium.com/?source=post_page-----b5fb002ac811--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b5fb002ac811--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b5fb002ac811--------------------------------) [Arun Jagota](https://jagota-arun.medium.com/?source=post_page-----b5fb002ac811--------------------------------)

·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----b5fb002ac811--------------------------------) ·19分钟阅读·2023年4月19日

--

![](../Images/b2d3d765f44d8d3e011a1660ef32353e.png)

图片由[Nile](https://pixabay.com/users/nile-598962/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=623167)提供，[Pixabay](https://pixabay.com/)上可见

表达得好需要付出努力。幸运的是，体现现代自然语言处理的聊天机器人，如ChatGPT，非常有帮助。

在这篇文章中，我们将使用适当增强的Trie来建模这个问题。这个Trie将自动检测在语料库中重复出现的短词序列，并且以无监督的方式进行。随后，它还将从标注的数据集（尴尬短语、改进短语对）中学习常见的“尴尬短语”模式。

对于小型但细微的改写问题版本，我们将展示通过在学习到的Trie上进行适当的模糊搜索，可以直接找到改进的表达方式。

对于更复杂的版本的问题，我们描述了一种使用Trie作为特征提取器的变体。这些特征可以集成到任何先进的神经语言模型中。

对于这个用途，Trie需要进行特定的预处理和预训练。我们也将描述这两个步骤。

这种方法——本身——是…

+   **易于理解**，无需具备神经网络或自然语言处理的背景知识。

+   **作为概念验证**容易实现。

+   **独立有效**于检测短小的尴尬短语并建议改写。

也许更重要的是，如上所述，这种方法允许将基于Trie的特征添加到现代神经网络模型中，这些特征建模了在语料库中重复出现的短序列，因此可能携带独特的语义。

本文中使用的单词序列示例，包括尴尬的短语和改进后的短语，都是ChatGPT在响应单个提示时提供的：

> 给我一些尴尬的短语示例，长度为两到四个词。

然后我选择了一个展示了本文方法所涉及的所有场景的子集。我将它们分配到本文的各个部分。这种分配是因为不同的表述展示了本文方法中的不同机制。

本文的最后部分列出了所有尴尬的表述及其改进后的表述。包括在ChatGPT的回复中未使用的那些，因为它们是其回复的一部分。

**初步观点：问题框定为搜索**

考虑*她做饭好*，我们希望更好地表达。假设我们有一个丰富且庞大的优质句子语料库进行学习。想象一下搜索以*她做饭*开头的句子。通过分析这些句子，我们可能会得出*她做饭*更好地表述为*她做饭*或*她做过饭*。

现在考虑第三个词*good*。语料库中可能没有与短语*(cooks|cooked) good*匹配的句子。

另一方面，我们可能会找到几个包含短语*做饭很好*的句子。凭借*well*和*good*足够相似的额外知识，我们可能会倾向于建议*她做饭很好*作为更好的整体改写。我们可能从哪里获得这样的知识？词嵌入。

（我们在[http://vectors.nlpl.eu/explore/embeddings/en/#](http://vectors.nlpl.eu/explore/embeddings/en/#)输入了*good*，最强的“语义关联”是*well*，得分为0.829。）

让我们将上述内容以流程的形式表达。

1.  在我们的句子语料库中搜索那些以*她做饭*开头的句子。得到的最佳匹配是*她做饭*和*她做过饭*。

1.  将匹配项替换到探测器中，即得到*她做饭/做过饭好*。

1.  接下来，搜索我们包含*做饭/做过饭好*的句子语料库。得到*做饭很好*作为一个好的匹配。在将其评分为好的匹配时，还要利用*good*和*well*是语义关联的这一点，这可以通过比较它们的词嵌入来揭示。

1.  将匹配项替换到转换输入的相关部分。我们得到*她做饭很好*。

步骤1和3中的搜索需要有一定的模糊性，以找到不完全匹配。这些匹配项随后需要进一步后处理，以便提取它们之间的统计共性。

此外，请注意以下几点。在第1步中，第三个词*good*没有作用。这需要在预处理、搜索本身或结果的后处理过程中以某种方式发现。

同样，在第3步中，必须以某种方式忽略词*她*。为什么？因为使用*cooks/cooked good*作为探测器而不是*她做饭/做过饭好*将更倾向于更好地概括。即使语料库中没有以*她做饭很好*开头的句子，最终的改写也可能会被建议。

上面两个段落讨论的要点可以用*注意力*机制来重新框定，这在大型语言模型中至关重要。

**顺序特性**

上述方法本质上是顺序的。我们从探针开始，检查其部分，适当地转换，然后重复。

**在Trie上搜索**

到目前为止，我们已经多次使用了“在句子语料库上搜索”这个术语。我们现在深入探讨一下如何进行这样的搜索。

我们将把句子语料库导入到一种叫做Trie的树数据结构中，然后在其上进行搜索。

那么，什么是Trie？我们将通过一个示例来说明它，而不是给出定义。

![](../Images/dcb2e822725c43265176594d335affa9.png)

图1：表示两个单词序列的Trie。（作者提供。）

上述示例中的Trie表示以下两个句子的单词序列：*狗追猫* 和 *新工作很好*。

现在想象一下短语*新工作好*。我们可以直观地看到，这个短语映射到从Trie的根开始的路径，该路径标记为*新工作很好*。

这种映射也被称为*对齐*，可以在下方表示。

[PRE0]

在这种方法中，找到表述的更好重述的问题变成了在Trie中找到与表述对齐的路径的问题。

让我们从更简单的情况开始，当存在从Trie的根开始的路径完全表示输入时。在图1中的Trie中，*新工作很好* 是这样一个输入的例子。

很容易看出，我们可以通过基于输入中的令牌进行从左到右的扫描来找到表示输入的路径。

现在考虑一个不太干净的探针：*新工作好*。在图1的Trie中没有完全对应于这个探针的路径。

处理第一个单词*The*缺失的一种方式是向Trie中添加跳过弧。下面是我们第一个图的一个版本，添加了几个跳过弧。

![](../Images/e41b970eec85d11631b458fd91ab0710.png)

图2：添加了一些跳过弧的Trie。（作者提供。）

跳过弧使我们能够找到路径，其中某些元素在探针中缺失，但代价是消耗更多的空间并且搜索时间更长。

现在假设我们还知道一个*新工作好*的良好重述。我们可以将原始表述和改进的重述对视为一个标记实例。此外，假设我们以某种方式将重述与探针对齐，如下所示。

[PRE1]

现在我们有了一个标记的数据集，并且进入了监督学习的领域。

标记可能会产生显著的成本。那么，在我们的设置中，标签实际上能给我们带来什么？它们告诉我们在哪里添加跳过弧。

在这个特定的示例中，我们将在图2所示的位置添加两个跳过弧。

人们可能会问，为什么要使用跳过弧？为什么不直接进行前瞻搜索？

如果我们想处理多个连续缺失的标记怎么办？这是很可能的——我们很快会看到一个例子。我们需要一些大于1的正整数*k*的前瞻。*k*的值应该是多少？如果*k*仅比1稍大，我们不能处理许多连续缺失的标记，这种情况在现实中是很可能发生的。如果我们使用一个大的*k*，前瞻搜索可能会遇到组合爆炸，即不可扩展。这是因为我们必须搜索所有距离当前节点*k*范围内的可能后代。这些后代的数量可能随着*k*的增大而呈超指数增长。

跳跃弧的使用避免了这种组合爆炸。

对齐版本的标注实例精确地揭示了我们应该添加的跳跃弧。如下面的示例所示，有时我们想要学习跳过多个标记。

[PRE2]

从这点出发，我们可以学会将跳跃弧从Trie节点[*I*, *will*, *go*]添加到节点[*I*, *will*, *go*, *to*, *the*]。这个跳跃弧将允许我们处理原始表述中相对于上述改进表述中缺失的*to the*。

好吧，因此*I go store*将映射到从根节点发出的Trie上的特定路径。从这条路径中，我们需要读取序列[*I*, ***will***, *go*, ***to the***, *store*]。问题是，我们如何得到粗体部分？

我们可以做的一件事是为表示被跳过的标记序列的跳跃弧分配一个标签。当我们首次创建跳跃弧时，我们知道这个标记序列，因此可以立即设置标签。与主弧不同，跳跃弧的标签仅在构建改进的表述时使用，而不是在查找期间使用。正如我们所知，查找是跳跃。

**这是半监督学习**

好吧，我们已经看到在标注数据集上的训练是有价值的。我们还意识到，建立一个标签覆盖大多数干净句子的标注数据集可能是不可行的，比如维基百科。

我们如何利用大量语料库而不必从中推导出足够丰富的标注实例？简单。

+   从语料库中学习Trie减去跳跃连接。这是无监督学习。

+   从可能更小的标注数据集中学习跳跃连接。这是监督学习。

后者的基本假设是学习跳跃连接的问题具有普适性。我们确实在之前讨论的一个例子中看到了这种普适性。即使从一个标注实例中，我们也可以学会处理一个以*The dog*开头的句子在被损坏版本中*The*的缺失。

**跳跃弧越接近根节点的泛化能力越强**

看图2。最接近Trie根节点的跳跃弧从根节点开始，跳过了*The*。这使得它能够考虑到任何以*The*开头的干净句子在任何被损坏版本中*The*的缺失。

现在考虑跳过句子中*新工作是*的*是*的跳过弧。这适用于更有限的句子集。

**替代弧及其学习**

为了激励这一点，我们将发现我们在帖子中覆盖的第一个重述示例是有用的。这涉及将*她做饭好*重述为*她做饭好*。

好的，所以我们从根节点开始，越过标记为*她*的弧。我们现在在节点[*她*]上，但它没有子节点[*她*，*做饭*]。最接近的子节点是[*她*，*做饭*]。我们可以通过模糊匹配*做饭*和*做饭*来找到这个子节点。我们应该记住，如果当前节点有许多子节点，找到最佳匹配的子节点可能需要时间。

对于这种模糊匹配的一种替代方法是从标记数据集中学习替代弧。

想象以下标记实例出现在监督训练集中。

[PRE3]

我们可以想象从这个标记实例中学习，以添加我们所称的*替代弧*。这些在我们的示例中如下所示。

![](../Images/5d8b5a193694eaba8860486f231813b4.png)

图3：添加了学习到的替代弧的Trie。（作者提供。）

虽然图3没有显示这一点，但替代弧需要与主弧区分开，因为它们的使用方式略有不同。

在处理输入时，替代弧可能会被遍历。例如，在输入*她做饭好*时，我们会遍历标记为[*她*，*做饭*，*好*]的路径，其中第二个和第三个弧是替代弧。

从结果路径中得出的输出涉及将路径中的替代弧上的标签替换为对应的主弧。在我们的例子中，[*她*，*做饭*，*好*] 会被替换为 [*她*，*做饭*，*好*]。

**替代弧与令牌的模糊匹配**

正如我们在前一节中讨论的那样，只有在我们处于正确的左侧上下文时，令牌才会被模糊匹配。例如，考虑*她做饭好*，假设我们在节点*她做饭*。从这个节点发出的弧有一个标签*好*。我们仅在这个左侧上下文*她做饭*中将*好*与*好*匹配。这减少了假阳性的风险。

这意味着，使用模糊令牌匹配而不是替代弧不会增加风险。使用替代弧主要有助于加快匹配速度，当节点有许多子节点时尤其如此。模糊匹配替代方案要求我们找到来自父节点的所有弧上的标签，并将每个标签一个接一个地匹配到输入中的下一个令牌。

模糊匹配和替代弧都不一定假设匹配的令牌在词汇上相似，仅仅是它们在标记实例中对齐。

作为示例，考虑对齐情况

[PRE4]

*律师*和*法律顾问*即使没有词汇上的相似性也是对齐的。

**自弧及其学习**

考虑表达方式*You Like What*及其改进的重述*What Do You Like*。重述涉及重新排列单词。我们希望继续利用字典树，而不是设计新的机制来处理单词顺序的重新排列。

想象一下，我们有一个标记和对齐的实例来表示这一对。

[PRE5]

我们可以通过跳跃弧来建模改进的重述中的*What do*。要建模原始重述中的*what*，我们将使用自我弧的概念。

下面是建模这种情况的字典树的一部分。

![](../Images/df9101caacff0e75687bc9d167eb3cba.png)

图 4：具有自我弧（和跳跃弧）的字典树。（作者提供。）

让我们走查一下如何处理输入[*you*, *like*, *what*]。我们将从根节点开始，走跳跃弧，然后走标记为*you*和*like*的弧，最后走标记为*what*的自我弧。我们将连接路径上前三个弧的标签。我们将省略第四个弧的标签，因为我们知道它是自我弧。

**减少构建标记和对齐实例的工作量**

正如我们所见，标记的实例，即原始表达方式与改进的重述对齐的实例，在学习准确的重述建议模型中发挥着重要作用。我们标记实例的数据集越丰富，学习到的模型质量就越好。

鉴于此，我们可以减少构建标记实例的工作量吗？答案是可以。

以下我们提出一种方法，这种方法涉及将一个数据集中的序列（其中可能有许多尴尬的表达方式）对齐到一个在主要干净句子语料库上训练的字典树。接着，我们将描述如何利用某些经过充分论证的语言特征来增强这种方法。

**用干净的字典树对齐不良序列**

首先，假设我们有两个数据集，一个是相对干净的句子，另一个是质量较差的表达方式。想象一下，从第一个数据集中，我们按照前面描述的方式学习字典树。（这个字典树只有主要弧。）

现在考虑一个来自第二个数据集的实例——一个相对较差的实例。想象一下在当前字典树中找到一条从根节点开始并且与实例足够匹配的路径。通过这条路径结合实例，我们可以推导出我们所寻求的标记实例。

模糊匹配器需要如何工作？它需要使用前瞻操作来允许路径上的标记在探测器中缺失。它还需要使用模糊标记匹配来允许替换。

让我们说明这个过程。考虑下面的字典树。

![](../Images/c7343d1e097505ad58f2829c9185019d.png)

图 5：用于说明模糊匹配的字典树。（作者提供。）

现在考虑探测器*Me go store*。假设我们知道*me*和*I*是语义关联词。我们将利用这一知识将*me*与*I*对齐，然后进行一次前瞻，对齐*go*与*go*，再进行一次前瞻，最后对齐*store*与*store*。我们得到了所需的对齐。

如果我们认为这发生在离线训练阶段，那么模糊匹配甚至不需要进一步优化速度。前瞻可能需要时间，但这没关系。

有人可能会问，为什么不在推断时直接使用这种模糊匹配过程，而完全放弃监督训练？有两个原因。

首先，模糊匹配器可能运行较慢，因为它可能需要进行前瞻。一个慢的模糊匹配器在训练过程中比在推断过程中更可接受。

其次，允许从标记实例中学习允许将人工策划的标记实例与使用模糊匹配器自动生成的实例混合在一起。实际上，它甚至允许人工策划者丢弃那些被认为质量较低的自动生成实例。这可能仍然减少了获得一个同等丰富的数据集的整体努力，因为它自动化了发现过程。只要通过这种自动化过程找到的足够多的标记实例足够好，那么其好处可能会超过检测和标记假阳性的成本。

**利用语言特征**

这是基于这样的观察：在某些词性中，词语在不良表述中缺失的可能性比其他词性更高。例如，冠词或介词。以下是一些示例。

> 曝露阳光
> 
> 他是律师

我们将这融入到我们将不良序列与干净Trie对齐的方法中，如下所示。

在第一步中，我们将不良序列与干净的Trie对齐。在这个过程中，不良序列*x*与Trie上的路径*y*对齐。对于*y*中的词序列，我们现在得到它们的词性。对齐现在不仅揭示了相对于*y*来说可能在*x*中缺失的词，还揭示了它们的词性。我们现在可以辨别出某些词性是否比其他词性更可能缺失。

在第2步中，我们穷举地列出Trie上的所有根到叶子路径，这可以通过深度优先或广度优先搜索等方式完成，并添加跳过弧以跳过在我们最易跳过的词性列表中的词。

让我们用一个简单的例子来说明。

比如我们将*He is lawyer*与*He is a lawyer*对齐。我们发现前者缺少一个冠词，在这种情况下是*a*。重复这个过程于许多不良序列应该能够辨别出冠词比其他一些词性更倾向于缺失。

**更细粒度的变体**

到目前为止，我们考虑的词序列用于输入Trie的都是语料库中的句子。这种选择是为了方便，因为将文本分割成句子相对容易。

在这一部分，我们考虑一个更细粒度的变体，其中我们输入到Trie中的词序列不一定是完整的句子，而是以某种主导顺序出现的词序列。

这种更细粒度的Trie有潜力建议句子中嵌入的较短单词序列的改进表述。

这是一个例子。没有人将*skin cancer*写作*cancer skin*。如果我们能够发现前者是这两个词的主导顺序，我们就可以检测到这种顺序的违规，并建议重新表述。

更为可信的情况是，当句子中的单词*of the*被错误地调换位置时，例如*The top* ***the of*** *mountain*。

此外，也许更重要的是，这种更细粒度的Trie可以作为现代神经语言模型中的特征提取器，用于处理更复杂的拗口表述问题。实际上，对于大型语言模型适用的任何推断问题，包括语言生成，都是如此。

无论Trie是直接使用还是作为特征提取器，都需要解决一个新问题。即发现以某种主导顺序出现的单词序列。这个问题在我们的第一个Trie中不存在，因为句子被视为单词序列。

首先，以下术语将有所帮助。

**可排序的袋子**

如果一个单词多重集具有主导排序，我们将称之为可排序的袋子。

我们使用*multiset*这个术语而不是*set*，以允许同一个词出现多次。

例如，多重集{*the*, *of*}有一个主导排序[*of, the*]。

请注意，可排序的袋子与显著短语不同。前者只关心主导排序；后者还需要考虑显著性，即该短语传达的意义大于其部分之和。

**从句子语料库中发现可排序的袋子**

好了，现在让我们讨论如何从句子语料库中发现可排序的袋子。我们假设语料库中的所有句子都已经被分词为单词。

从这个语料库中，设想从所有长度至少为二的令牌序列中派生出一个数据集*D*1。接下来，我们将根据以下方式从*D*1构建一个新的数据集*D*2。实际上，我们将把*D*2解释为一个带标签的数据集。

对于每一个*D*1中的序列*y*，在*D*2中将有一个序列*x*，其中*x*是通过对*y*的单词进行词典顺序排序得到的。*x*在*D*2中的标签将是*y*。也就是说，我们用观察到的特定排序*y*来标记*y*的单词多重集。

下面是一个在*D*2中的实例示例。

> x = [cancer, skin], y = [skin, cancer]

我们将从*D*2中的所有*x*构建一个Trie。对于*D*2中的任何一对(*x*, *y*)，我们将把*y*作为卫星数据附加到Trie中*x*结束的节点上。

一旦Trie构建完成，我们将把Trie中各节点上的卫星数据压缩为两个属性。

1.  作为标签的不同排序数量即在该节点结束的*x*。

1.  对于以 *x* 结尾的节点，这是一种关于所有排序的概率分布。为了紧凑地表示这种分布，我们将以如下所述的方式对排序进行编码。

我们将第一个属性——不同排序的数量——称为 *支持度*。

当然，这个 Trie 可能非常庞大。但这对我们来说不是问题。

**利用 Trie 发现顺序不当的子序列**

考虑一个词序列，其中某些子序列的排序不当。例如 *The top* ***the of*** *mountain*。

我们将通过枚举所有长度至少为 2 的子序列，按词典顺序对每个这样的序列进行排序，查找 Trie 中的该序列，并检查末尾节点是否具有揭示主要排序的卫星数据，从而发现不当措辞（如果有的话）。

**示例**

例如，一旦 Trie 构建完成，假设路径 [*cancer*, *skin*] 上的最右节点具有卫星数据 (520, [*skin*, *cancer*] → 1)。这仅表示包 {*cancer*, *skin*} 在数据集中被观察到 520 次，每次的排序为 [*skin*, *cancer*]。

**在神经语言模型中使用可排序包 Trie 作为特征提取器**

一旦可排序的包 Trie 构建完成，我们可以将其用作特征提取器，如下所示。

首先，让我们为 Trie 中的每条路径分配一个唯一的标识符。这个标识符将作为与该路径关联的特征值。

我们将一个词序列作为输入，并将其分割为 Trie 中的一系列最大路径，每个路径都是具有一定最小支持度的主要排序。为了涵盖所有情况，我们将由单个词组成的词序列定义为具有上述最小支持度的主要排序。

我们现在用它们的标识符替换这个序列中的路径。这样我们就得到了一个特征序列。对于这个序列中表示单词的路径，我们可以附加额外的特征，例如词嵌入。

让我们在下面的示例中说明这个过程。

考虑

> 曝露在阳光下会导致皮肤癌

想象一下，使用可排序包 Trie，我们将其分割为

> exposure → to → sunlight, causes, skin → cancer

其在我们用 ids 替换路径后变为

> pid1, pid(causes), pid2

从为我们的基于 Trie 的方法添加价值的角度来看，这一好处是显而易见的。现代神经语言模型具有令人印象深刻的能力。

在我们在此帖子中讨论的特定用例背景下，这将允许它们检测在较长文本部分（如段落或甚至多页）中需要改进的措辞。可能需要考虑长距离交互的措辞。

从为现代神经语言模型添加价值的角度来看，Trie 基础的特征将进一步丰富这些模型。基本的直觉是，某些短的词序列在文本中重复出现频繁，并且隐含地编码了特定的语义。

基于Trie的方法可以从语料库中自动发现这些序列，因此可以用于分析由这些序列的某些排列组成的更长序列。

让我们用一个简单的例子来说明。考虑

> **exposure to sunlight** 导致 **skin cancer**

在这里，我们认为加粗的子序列是主导排序，并在我们的Trie中进行了表示。

我们可以想象，利用Trie的神经语言模型可以很容易地预测 *exposure to sunlight causes* 后面应该跟着 *skin cancer*。

现在假设我们有一个标记的数据集，其中包含语义上等价的表述。作为这个数据集中的一个实例，考虑

[PRE6]

从许多形式为 {*X causes Y*, *Y is caused by X*} 的实例中，并假设 *X* 和 *Y* 在Trie中被表示为主导排序路径，我们可以识别出这两者的语义等价性，并在某些推理或生成中使用这种学习。例如，如果我们被要求以不同的方式重新表达 *X causes Y*，我们可以回答 *Y is caused by X*。

**总结**

在这篇文章中，我们讨论了发现尴尬表述——即词序列的排列——并提出改进方案的问题。

我们使用Trie对这个问题进行了建模。这个Trie可以以无监督的方式自动检测出语料库中重复出现的短词序列。Trie中的一个监督机制还从标记数据集（包括（awkward phrasing, improved phrasing）对）中学习某些常见的“尴尬表述”模式。

对于小规模但细微的表述重述问题，我们展示了可以通过在学习到的Trie上进行适当的模糊搜索直接找到改进的表述。

对于问题的更详细版本，我们描述了一个变体，使用Trie提取高级重复特征，特别是短的重复词序列。我们推测为什么在最先进的神经语言模型中使用这些特征可以提高其准确性，并简化其训练。为此用途，需要对Trie进行某些预处理和预训练。我们也描述了这两者。

**ChatGPT中的短语**

以下是ChatGPT在回复提示时提供的尴尬表述及其改进版本

> 给我一些长度为两到四个单词的尴尬表述的例子

在回复中，ChatGPT将改进后的表述与尴尬的表述分开了。我为了读者的方便，将这些进行了对齐。

+   “Me go store.” 我要去商店

+   “You like what?” 你喜欢什么？

+   “Dog chase cat.” 狗在追猫。

+   “He no here.” 他不在这里。

+   “She cook good.” 她是个好厨师。

+   “Big house him.” 他有一栋大房子

+   “Funny joke that.” 那是个有趣的笑话

+   “Rain make wet.” 雨使一切变得湿润。

+   “Car go fast.” 这辆车正在快速行驶。

+   “New job good.” 新工作很好。

**进一步阅读**

1.  [https://en.wikipedia.org/wiki/Sequence_alignment](https://en.wikipedia.org/wiki/Sequence_alignment)

1.  [https://en.wikipedia.org/wiki/Trie](https://en.wikipedia.org/wiki/Trie)
