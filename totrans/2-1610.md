# 机器学习风险管理中的组织过程

> 原文：[https://towardsdatascience.com/organizational-processes-for-machine-learning-risk-management-14f4444dd07f](https://towardsdatascience.com/organizational-processes-for-machine-learning-risk-management-14f4444dd07f)

## 负责任的人工智能

## *组织过程是机器学习系统可靠性的一个关键非技术性决定因素。*

[](https://pandeyparul.medium.com/?source=post_page-----14f4444dd07f--------------------------------)[![Parul Pandey](../Images/760b72a4feacfad6fc4224835c2e1f19.png)](https://pandeyparul.medium.com/?source=post_page-----14f4444dd07f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----14f4444dd07f--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----14f4444dd07f--------------------------------) [Parul Pandey](https://pandeyparul.medium.com/?source=post_page-----14f4444dd07f--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----14f4444dd07f--------------------------------) ·7分钟阅读·2023年9月23日

--

![](../Images/6f17ca9325b10e97b1e4f7c65396c676.png)

作者提供的图片

在我们关于机器学习风险管理的持续系列中，我们已经研究了一些确保机器学习（ML）系统可信赖性的关键元素。在我们的第一篇文章中，我们详细讨论了 [**机器学习风险管理中的文化能力**](/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf?sk=8ed4f0c5e9624e21d9f6dae9017d5bed)**t**。其中提供的见解为我们当前的探索奠定了基础，因此，我强烈建议你在继续阅读本文章之前先阅读那部分内容。

[](/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf?source=post_page-----14f4444dd07f--------------------------------) [## 机器学习风险管理中的文化能力

### 组织的文化是负责任的人工智能的一个重要方面。

towardsdatascience.com](/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf?source=post_page-----14f4444dd07f--------------------------------)

在这篇第二篇文章中，我们将重点转向机器学习系统背景下的另一个重要元素：**组织过程**。虽然技术细节常常掩盖了这些过程，但它们是确保机器学习模型安全性和性能的关键。正如我们认识到文化能力的重要性一样，我们现在承认组织过程是构建机器学习系统可靠性的基础基石。

本文讨论了组织过程在机器学习风险管理（MRM）领域中的重要作用。整篇文章强调了从业者必须认真考虑、记录和主动解决其ML系统中已知或可预见的故障模式的关键性。

# 1️. *预测失败模式*

在机器学习（ML）系统中识别和解决可能出现的问题至关重要，但将这一理念付诸实践需要时间和精力。然而，近年来，能够帮助ML系统设计师更系统地预测问题的资源显著增加。通过仔细整理潜在问题，使得在现实世界中让ML系统变得更强大、更安全变得更容易。在这种背景下，可以探索以下策略：

## **从过去的失败中学习**

就像交通专业人员调查和编目事件以防止未来的发生一样，ML研究人员和组织也开始收集和分析A.I.事件。[**A.I.事件数据库**](https://incidentdatabase.ai/)是一个重要的存储库，允许用户搜索事件并获得宝贵的见解。开发ML系统时，咨询此资源至关重要。

> 如果类似的方法在过去曾导致事件，这就作为一个强烈的警告信号，表明新系统也可能存在风险，需要仔细考虑。

![](../Images/ca438fee401ddf54467264085c27b526.png)

通过编目事件防止现实世界中的人工智能失败重复发生：人工智能事件数据库 | 来源: [https://arxiv.org/pdf/2011.08512.pdf](https://arxiv.org/pdf/2011.08512.pdf)

## **解决*想象力失败***

![](../Images/81f296fe49ada9a1879b9e79680e678c.png)

克服人工智能系统开发和部署中的想象力失败 | 来源: [https://arxiv.org/pdf/2011.13416.pdf](https://arxiv.org/pdf/2011.13416.pdf)

通常，人工智能（A.I.）事件源于ML系统操作中未预见或理解不足的背景和细节。论文中概述的结构化方法[克服人工智能系统开发和部署中的想象力失败](https://arxiv.org/pdf/2011.13416.pdf)提供了对这些具有挑战性的未来风险进行假设的方法，并考虑了**谁**（包括投资者、客户和易受害者）、**什么**（涵盖福祉、机会和尊严）、**何时**（包括即时、频繁和长期情境）以及**如何**（涉及行动和信念改变）等方面。

> *虽然人工智能事件可能会对组织造成尴尬、昂贵，甚至非法的后果，但预见性可以缓解许多已知事件，可能会导致系统的改进。在这种情况下，实施的暂时延迟远远低于由于系统缺陷发布给组织和公众带来的潜在伤害。*

# 2\. 模型风险管理流程

![](../Images/7b4207ae290dab7f3c97c3ad8024a2cd.png)

***21页的S.R. 11–7模型风险管理指南的快照。该文档可免费公开访问 |*** *来源:* [https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf](https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf)

机器学习风险管理（MRM）构成了一个全面的框架和一系列程序，旨在识别、评估、缓解和监控与开发、部署和操作机器学习系统相关的风险。这些元素是治理结构的重要组成部分，特别是在美国联邦储备系统的[**模型风险管理监督指南（S.R. 11–07）**](https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf)的背景下，该指南监督用于重要消费者金融应用的预测模型。

> 文档是合规性变得具体的地方，使从业者承担责任并指导他们构建稳健的模型

虽然较大的组织可能更容易实现完整的MRM，但较小的组织也可以提取有价值的见解。本节将MRM程序分解为更小、更易管理的组件，使其更易于理解和使用。

## 1\. 风险分级

在评估机器学习系统部署中的风险时，常见的方法涉及计算***重要性***，考虑伤害的可能性和预期损失。高重要性的应用程序需要更多的关注。有效的治理适当地将资源分配给高、中和低风险的系统。例如，最近发布的[Anthropic A.I.负责任的扩展政策](https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf)引入了人工智能安全级别（ASL）的概念，这一概念在一定程度上受到美国政府生物安全等级（BSL）标准的启发，用于管理危险的生物材料。以下是一个快照：

![](../Images/5ccd0ed5e761e5b7ed5f122e78eb3305.png)

来自Anthropic的RSP快照 | 来源：[https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf](https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf)

## 2\. 模型文档

MRM 标准要求全面的系统文档，以满足多个目的，包括利益相关者责任、持续维护和事件响应。系统间的标准化文档简化了审计和审查流程，使其成为合规性的关键方面。文档模板指导数据科学家和工程师在模型开发过程中，确保所有必要步骤都得到执行，以构建可靠的模型。不完整的文档表明训练过程存在不足，因为大多数模板要求从业人员填写每个部分。此外，在最终模型文档中包括姓名和联系信息，有助于促进问责制。

![](../Images/1aba70f788f661e75a31bb5cb22babbc.png)

*MRM 文档中典型部分的粗略组合以及附件中推荐的* [*欧盟人工智能法案*](https://eur-lex.europa.eu/legal-content/EN/TXT/?qid=1623335154975&uri=CELEX%3A52021PC0206) *| 图片由作者提供*

详尽的模型文档可能令人望而却步；较小的组织可以选择像数据表这样的简单框架，模型卡可以帮助较小的组织实现这些目标。

![](../Images/2f426bcc44d64d2d794cb7ec03cc971a.png)![](../Images/cb9e0a734a53bcad1744cfd60e983a79.png)

L: **数据集数据表**：来源：[https://arxiv.org/pdf/1803.09010.pdf](https://arxiv.org/pdf/1803.09010.pdf) | R: **模型监控卡**：来源：[https://arxiv.org/pdf/1810.03993.pdf](https://arxiv.org/pdf/1810.03993.pdf)

## 3\. 模型监控

机器学习（ML）安全的基础在于 ML 系统在现实世界环境中的固有不可预测性，因此需要对这些系统进行持续监控，从部署到退役。一个主要关注点是 **输入漂移**，当现实世界情况与静态训练数据发生偏差时，例如市场波动、监管变化或意外事件（如疫情）时，输入漂移会出现。这种偏差可能对系统功能构成威胁。

![](../Images/e2abd24be1bc0362670cd4b5f2a8667f.png)

**研究与生产中的机器学习。** | 幻灯片来自于‘安全可靠的机器学习：防止和识别故障’，在 ICLR-2019 上展示，可在 [https://slideslive.com/38915708/safe-and-reliable-machine-learning-preventing-and-identifying-failures](https://slideslive.com/38915708/safe-and-reliable-machine-learning-preventing-and-identifying-failures) 查阅，采用 CCO 许可协议

高效的 ML 系统通过仔细监控数据和模型质量的变化来降低这些风险。这种监控不仅关注性能，还会查看异常数据或预测、安全问题和公平性问题。这有助于确保在不断变化的操作环境中进行全面的风险管理。

## 4\. 模型清单

MRM 的核心是**模型清单**——全面的数据库，列出组织中所有的机器学习系统，并连接到监控策略、审计结果、系统维护记录和事件响应计划等重要资源。

任何部署机器学习的组织都应该能够回答像这样简单明了的问题：

![](../Images/123759f71b67dccacaf128b5dc13a17b.png)

任何部署机器学习的组织都应该能够回答这些简单明了的问题 | 图片来源：作者

对于任何重视利用机器学习的组织而言，维护一个强大的模型清单不仅是一个良好的实践——而是必不可少的。

## *5. 系统验证和过程审计*

传统 MRM 实践的一个重要方面是，在机器学习系统发布之前，它会经过两个主要评估。首先，专家测试其技术部分，查找并修复问题。接着，一个团队确保系统遵循所有规则和指南，包括其设计和未来计划。如果这些系统有重大更新，还会再次审查。有些小公司可能觉得只能进行部分检查，但基本的想法是要有外部的人员来测试，确保它符合所有规则，并在使用重要系统之前获得批准。

> 在机器学习中，有效的 MRM（模型风险管理）意味着双重审查。

## *6. 变更管理*

机器学习系统像其他复杂的软件一样，拥有各种组件，如后台代码、API 和用户界面。一个组件的变化可能会影响其他组件。数据模式的变化、新的隐私法律以及对第三方软件的依赖等挑战使得管理这些变化变得至关重要。在关键机器学习系统的早期阶段，规划这些变化是必要的。如果没有这种规划，可能会发生错误，例如未经许可使用数据或系统不匹配，并且这些错误可能在问题出现之前未被察觉。

# 结论

从 [文化能力](/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf?sk=8ed4f0c5e9624e21d9f6dae9017d5bed) 到组织流程，我们探讨了确保机器学习系统安全性和性能的各种方面。正如我们所看到的，预测失败模式、细致的模型风险管理和警惕的监控是这一路径中的关键支柱。构建强健的模型、维护全面的清单和拥抱变更管理是实现负责任的人工智能的关键步骤。这些基础要素不仅确保了机器学习系统的安全性和性能，还赢得了用户和利益相关者的信任。

***> 阅读本系列中的下一篇文章 >***

[](/bridging-domains-infusing-financial-privacy-and-software-best-practices-into-ml-risk-management-3de1fa1e6dd2?source=post_page-----14f4444dd07f--------------------------------) [## 跨领域桥接：将金融、隐私和软件最佳实践融入机器学习风险管理

### 理解超越传统模型风险管理的策略

[向数据科学迈进](https://towardsdatascience.com/bridging-domains-infusing-financial-privacy-and-software-best-practices-into-ml-risk-management-3de1fa1e6dd2?source=post_page-----14f4444dd07f--------------------------------)

# 参考资料与进一步阅读

+   [通过记录事件防止现实世界中重复的人工智能失败：人工智能事件数据库](https://arxiv.org/pdf/2011.08512.pdf)

+   [克服人工智能驱动系统开发和部署中的想象力失败](https://arxiv.org/pdf/2011.13416.pdf)

+   [高风险应用中的机器学习，第1章 — 机器学习风险管理的组织流程](https://www.amazon.in/Machine-Learning-High-Risk-Applications-Responsible/dp/1098102436)

+   [欧盟人工智能法案](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52021PC0206)

+   [S.R. 11–7 模型风险管理指南](https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf)
