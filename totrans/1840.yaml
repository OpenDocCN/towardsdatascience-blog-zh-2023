- en: SHAP for Binary and Multiclass Target Variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/shap-for-binary-and-multiclass-target-variables-ff2f43de0cf4](https://towardsdatascience.com/shap-for-binary-and-multiclass-target-variables-ff2f43de0cf4)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A guide to the code and interpreting SHAP plots when your model predicts a categorical
    target variable
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://conorosullyds.medium.com/?source=post_page-----ff2f43de0cf4--------------------------------)[![Conor
    O''Sullivan](../Images/2dc50a24edb12e843651d01ed48a3c3f.png)](https://conorosullyds.medium.com/?source=post_page-----ff2f43de0cf4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ff2f43de0cf4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ff2f43de0cf4--------------------------------)
    [Conor O''Sullivan](https://conorosullyds.medium.com/?source=post_page-----ff2f43de0cf4--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ff2f43de0cf4--------------------------------)
    ·9 min read·Sep 4, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b06abc866e3a7134fc4fddbaa12d53a3.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Nika Benedictova](https://unsplash.com/@nika_benedictova?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'SHAP values give the contribution of a model feature to a prediction. This
    is also true when we use SHAP for classification. Except, for **binary target
    variables,** we interpret these values in terms of **log odds**. For **multiclass
    targets**, we use **softmax**. We will:'
  prefs: []
  type: TYPE_NORMAL
- en: Discuss these interpretations in more depth
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Give the code for displaying SHAP plots for classification problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explore new ways of aggregating SHAP values for multiclass targets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can also watch this video on the topic:'
  prefs: []
  type: TYPE_NORMAL
- en: Previous SHAP tutorial
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We continue on from a previous [SHAP tutorial](/introduction-to-shap-with-python-d27edc23c454).
    It goes into depth on SHAP plots for a continuous target variable. You will see
    that these plots and their insights are similar for categorical target variables.
    You can also find the full project on [GitHub](https://github.com/conorosully/SHAP-tutorial).
  prefs: []
  type: TYPE_NORMAL
- en: '[](/introduction-to-shap-with-python-d27edc23c454?source=post_page-----ff2f43de0cf4--------------------------------)
    [## Introduction to SHAP with Python'
  prefs: []
  type: TYPE_NORMAL
- en: 'How to create and interpret SHAP plots: waterfall, force, mean SHAP, beeswarm
    and dependence'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/introduction-to-shap-with-python-d27edc23c454?source=post_page-----ff2f43de0cf4--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: To summarise, we used SHAP to explain a model built using the [abalone dataset](https://archive.ics.uci.edu/ml/datasets/abalone).
    This has **4,177** instances and you can see examples of the features below. We
    use the **8** features to predict y — the number of **rings** in the abalone’s
    shell. The rings are related to the age of the abalone. In this tutorial, we will
    bin y into different groups to create binary and multiclass target variables.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4799522c7ec972bf1d1bb49fa9d3bcd5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'X feature matrix (source: [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/abalone))
    (licence: CC0: Public Domain)'
  prefs: []
  type: TYPE_NORMAL
- en: Binary target variable
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the continuous target variable, we saw that each instance had 8 SHAP values
    — one for every model feature. As seen in **Figure 1**, if we sum these and the
    average prediction **E[f(x)]** we get the prediction for that instance **f(x)**.
    For binary target variables, we have the same property. The difference is we interpret
    the values in terms of log odds of a *positive* prediction.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1cbd2c5718130eba5887e9d805533d6b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: interpreting SHAP values in terms of log-odds (source: author)'
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand this let’s dive into a SHAP plot. We start by creating a binary
    target variable (line 2). We create two groups based on y:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1** if the abalone has an above-average number of rings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**0** otherwise'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We use this target variable and the 8 features to train an **XGBoost classifier**
    (lines 2–3). This model had an accuracy of **96.6%.**
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We now calculate the SHAP values (lines 2–3). We output the shape of this object
    (line 5) which gives **(4177, 8)**. So, just like the continuous target, we have
    one SHAP value per prediction and feature. Later, we will see how this is different
    for a multiclass target.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We display a waterfall plot for the first instance (line 6). We can see the
    result in **Figure 2**. Notice the code is the same as for the continuous variable.
    Except for the numbers, the waterfall plot also looks similar.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Now **E[f(x)] = -0.789** gives the average predicted log odds across all 4,177
    abalones. That is the log odds of a positive (1) prediction. For this specific
    abalone, the model predicted a probability of **0.3958** that it had an above-average
    number of rings (i.e. **P = 0.3958**). This gives us a predicted log odds of **f(x)
    = ln(0.3958/(1–0.3958)) = -0.423.**
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/544e0423a692d47a2dae1d6122db6b84.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: waterfall plot with a binary target variable (source: author)'
  prefs: []
  type: TYPE_NORMAL
- en: So, the SHAP values give the difference between the predicted log odds and the
    average predicted log odds. Positive SHAP values increase the log odds. For example,
    shucked weight increased the log odds by **1.32**. In other words, this feature
    has increased the probability that the model will predict an above-average number
    of rings. Similarly, negative values decrease the log odds.
  prefs: []
  type: TYPE_NORMAL
- en: We can also aggregate these values in the same way as before. The good news
    is the interpretations of the plots like the beeswarm or mean SHAP will be the
    same. Just remember that we are dealing with log odds. Now let’s see how this
    interpretation changes for multiclass target variables.
  prefs: []
  type: TYPE_NORMAL
- en: Multiclass target variable
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We start by creating a new target variable (**y_cat**) with 3 categories — young
    (0), medium (1) and old (2). As before, we train an XGBoost classifier to predict
    this target variable (lines 5–6).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: For this model, we can no longer talk about a “positive prediction”. We can
    see this if we output the predicted probability for the first instance (line 2).
    This gives us **[0.2562, 0.1571, 0.5866]**. In this case, the 3rd probability
    is the highest and so the abalone is predicted to be old (2). What this means
    for SHAP, is we can no longer only consider values for the positive class.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We can see this when we calculate the SHAP values (lines 2–3). The code is the
    same as for the binary model. Yet, when we output the shape (line 5) we get **(4177,
    8, 3)**. We now have one SHAP value for every instance, feature and *class*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: As a result, we have to display the SHAP values for each class in separate waterfall
    plots. We do this for the first instance in the code below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**Figure 3** gives the waterfall plot for class 0\. The values explain how
    each feature has contributed to the model prediction *for this class*. That is
    compared to the average prediction for this class. We saw that the probability
    for this class was relatively low (i.e. **0.2562**). We can see that the shucked
    weight feature has made the most significant contribution to this low probability.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/121bedc604cfe7ada1261f23304a1dbd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: waterfall plot for class 0 (source: author)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 4** gives the output for the other classes. You will notice that **f(x)
    = 1.211** is the largest for class 2\. This makes sense as we saw the probability
    for this class was also the largest (**0.5866)**. When analysing the SHAP values
    for this instance, it may make sense to focus on this waterfall plot. It is the
    class prediction for this abalone.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/037fb033008728d69202eb3cde2651c0.png)![](../Images/c3444e802e8381e160d964070139bbd5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: waterfall plot for classes 1 and 2 (source: author)'
  prefs: []
  type: TYPE_NORMAL
- en: Interpreting values with Softmax
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we are now dealing with multiple classes, **f(x)** is given in terms of softmax.
    We can convert softmax values to probability using the function below. **fx**
    gives the three f(x) values in the above waterfall plots. The result is **[0.2562,
    0.1571, 0.5866]**. The same predicted probabilities we saw for instance 0!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Aggregating multiclass SHAP values
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: These SHAP values can be aggregated using any of the SHAP plots. However, like
    the waterfall, there will be individual plots for each class. Analysing these
    can be tedious. Especially if you have many categories in your target variable.
    So we’ll end by discussing some other approaches to aggregation.
  prefs: []
  type: TYPE_NORMAL
- en: The first is a version of the mean SHAP plot. We calculate the absolute mean
    of the shap values for each class separately (lines 2–4). We then create a bar
    chart with one bar for each class and feature.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: We can see the output in **Figure 5**. One thing to mention is that each bar
    gives the average over all the predictions. Yet, the actual predicted class will
    be different in each case. So, you may end up skewing the means with SHAP values
    that do not explain the predicted class. This is potentially why we are seeing
    smaller means for the medium class.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b45c9a3d850d68a1e192e1fd0dcb13f0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: mean SHAP for each class in a multiclass target variable (source:
    author)'
  prefs: []
  type: TYPE_NORMAL
- en: To get around this, we can focus on the SHAP values for the predicted class.
    We start by getting the predicted class for each instance (line 2). We create
    a new set of shap values (**new_shap_values**). This is done by looping over the
    original values and only selecting the set that corresponds to the prediction
    for that instance (lines 5–7).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We then replace the SHAP values in the original object (line 2). Now, if we
    output the shape we get (4177, 8). In other words, we are back to one set of SHAP
    values per instance.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: A benefit of this approach is it is easy to use the built-in SHAP plots. For
    example, the mean SHAP plot in **Figure 6**. We can interpret these values as
    the average contribution of a feature to the predicted class.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/37bebcf87340eb6d41798e45371d8fbf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: mean SHAP for predicted class in a multiclass target variable (source:
    author)'
  prefs: []
  type: TYPE_NORMAL
- en: We can also use the beeswarm. Yet, notice we do not see a clear relationship
    between the SHAP values and feature values. This is because the features will
    have different relationships depending on the predicted class. Older abalone will
    be bigger. So, for example, large shell weights will lead to a higher probability
    of an old (2) prediction. The opposite is true for young (0) predictions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/2194302f628562be28ab5e4cb04c7681.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: beeswarm for multiclass target variable (source: author)'
  prefs: []
  type: TYPE_NORMAL
- en: So hopefully is clear how to interpret SHAP values for binary and multiclass
    target variables. Yet, you may be wondering why they are given in terms of log
    odds and softmax. It may make more sense to interpret them both in terms of probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: This comes from the way SHAP values are calculated. That is simultaneously by
    a linear model. If we had to predict a binary or multiclass variable with a linear
    model we would use logistic or softmax regression respectively. These link functions
    are differentiable and they allow us to formulate model predictions as a linear
    equation of parameters and features. Likewise, these properties are used to estimate
    SHAP values efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: 'Learn more about shap:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/new-shap-plots-violin-and-heatmap-20f647313b64?source=post_page-----ff2f43de0cf4--------------------------------)
    [## New SHAP Plots: Violin and Heatmap'
  prefs: []
  type: TYPE_NORMAL
- en: What the plots in SHAP version 0.42.1 can tell you about your model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/new-shap-plots-violin-and-heatmap-20f647313b64?source=post_page-----ff2f43de0cf4--------------------------------)
    [](/the-limitations-of-shap-703f34061d86?source=post_page-----ff2f43de0cf4--------------------------------)
    [## The Limitations of SHAP
  prefs: []
  type: TYPE_NORMAL
- en: How SHAP is impacted by feature dependencies, causal inference and human biases
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/the-limitations-of-shap-703f34061d86?source=post_page-----ff2f43de0cf4--------------------------------)
    [](/using-shap-to-debug-a-pytorch-image-regression-model-4b562ddef30d?source=post_page-----ff2f43de0cf4--------------------------------)
    [## Using SHAP to Debug a PyTorch Image Regression Model
  prefs: []
  type: TYPE_NORMAL
- en: Using DeepShap to understand and improve the model powering an autonomous car
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/using-shap-to-debug-a-pytorch-image-regression-model-4b562ddef30d?source=post_page-----ff2f43de0cf4--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: I hope you enjoyed this article! You can support me by becoming one of my [**referred
    members**](https://conorosullyds.medium.com/membership) **:)**
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://conorosullyds.medium.com/membership?source=post_page-----ff2f43de0cf4--------------------------------)
    [## Join Medium with my referral link — Conor O’Sullivan'
  prefs: []
  type: TYPE_NORMAL
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every story…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: conorosullyds.medium.com](https://conorosullyds.medium.com/membership?source=post_page-----ff2f43de0cf4--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '| [Twitter](https://twitter.com/conorosullyDS) | [YouTube](https://www.youtube.com/channel/UChsoWqJbEjBwrn00Zvghi4w)
    | [Newsletter](https://mailchi.mp/aa82a5ce1dc0/signup) — sign up for FREE access
    to a [Python SHAP course](https://adataodyssey.com/courses/shap-with-python/)'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Stackoverflow **How to interpret base_value of multi-class classification problem
    when using SHAP?**[https://stackoverflow.com/questions/65029216/how-to-interpret-base-value-of-multi-class-classification-problem-when-using-sha/65034362#65034362](https://stackoverflow.com/questions/65029216/how-to-interpret-base-value-of-multi-class-classification-problem-when-using-sha/65034362#65034362)
  prefs: []
  type: TYPE_NORMAL
