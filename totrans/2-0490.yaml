- en: Chat with Your Dataset using Bayesian Inferences.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/chat-with-your-dataset-using-bayesian-inferences-bfd4dc7f8dcd](https://towardsdatascience.com/chat-with-your-dataset-using-bayesian-inferences-bfd4dc7f8dcd)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The ability to ask questions to your data set has always been an intriguing
    prospect. You will be surprised how easy it is to learn a local Bayesian model
    that can be used to interrogate your data set.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://erdogant.medium.com/?source=post_page-----bfd4dc7f8dcd--------------------------------)[![Erdogan
    Taskesen](../Images/8e62cdae0502687710d8ae4bbcd8966e.png)](https://erdogant.medium.com/?source=post_page-----bfd4dc7f8dcd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bfd4dc7f8dcd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bfd4dc7f8dcd--------------------------------)
    [Erdogan Taskesen](https://erdogant.medium.com/?source=post_page-----bfd4dc7f8dcd--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bfd4dc7f8dcd--------------------------------)
    ·13 min read·Nov 13, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cd3cbd949d64dc93de294b51ab286416.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Vadim Bogulov](https://unsplash.com/pt-br/@franku84?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/MfBnqUOz_qY?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: With the rise of chatGPT-like models, it has become accessible for a broader
    audience to analyze your own data set and, so to speak, “*ask questions*”. Although
    this is great, such an approach has also disadvantages when using it as an analytical
    step in automated pipelines. This is especially the case when the outcome of models
    can have a significant impact. To maintain control and ensure results are accurate
    we can also use Bayesian inferences to talk to our data set. *In this blog, we
    will go through the steps on how to learn a Bayesian model and apply do-calculus
    on the data science salary data set. I will demonstrate how to create a model
    that allows you to “ask questions” to your data set and maintain control. You
    will be surprised by the ease of creating such a model using the* [*bnlearn library*](https://erdogant.github.io/bnlearn/pages/html/index.html)*.*
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Extracting valuable insights from data sets is an ongoing challenge for data
    scientists and analysts. ChatGPT-like models have made it easier to interactively
    analyze data sets but at the same time, it can become less transparent and even
    unknown why choices are made. Relying on such black-box approaches is far from
    ideal in automated analytical pipelines. Creating transparent models is especially
    important when the outcome of a model is impactful on the actions that are taken.
  prefs: []
  type: TYPE_NORMAL
- en: The ability to communicate effectively with data sets has always been an intriguing
    prospect for researchers and practitioners alike.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In the next sections, I will first introduce the [*bnlearn library*](https://erdogant.github.io/bnlearn/pages/html/index.html)
    *[1]* on how to learn causal networks. Then I will demonstrate how to learn causal
    networks using a mixed data set, and how to apply do-calculus to effectively query
    the data set. *Let’s see how Bayesian inference can help us to interact with our
    data sets!*
  prefs: []
  type: TYPE_NORMAL
- en: '*If you find this article helpful, you are welcome to* [*follow me*](https://erdogant.medium.com/subscribe)
    *because I write more about Bayesian learning. If you are thinking of taking a
    Medium membership, you can support my work a bit by using my referral link. It
    is the same price as a coffee but this allows you to read unlimited articles every
    month.*'
  prefs: []
  type: TYPE_NORMAL
- en: The Bnlearn library
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '***Bnlearn*** is a powerful Python package that provides a comprehensive set
    of functions for causal analysis using Bayesian Networks. It can handle both discrete,
    mixed, and continuous data sets, and offers a wide range of user-friendly functionalities
    for causal learning, including *structure learning, parameter learning, and making
    inferences* [1–3]. Before we can make inferences, we need to understand structure
    learning and parameter learning because it relies on both learnings***.***'
  prefs: []
  type: TYPE_NORMAL
- en: '**Learning the causal structure** of a data set is one of the great features
    of *bnlearn*. Structure learning eliminates the need for prior knowledge or assumptions
    about the underlying relationships between variables. There are three approaches
    in *bnlearn* to learn a causal model and capture the dependencies between variables.
    Structure learning will result in a so-called **D**irected **A**cyclic **G**raph
    or DAG). Although all three techniques will result in a causal DAG, some can handle
    a large number of features while others have higher accuracy. ***Read more details
    regarding structure learning in the*** [***underneath blog***](/a-step-by-step-guide-in-detecting-causal-relationships-using-bayesian-structure-learning-in-python-c20c6b31cee5).'
  prefs: []
  type: TYPE_NORMAL
- en: '*Score-based structure learning: Using scoring functions BIC, BDeu, k2, bds,
    aic, in combination with search strategies such as exhaustivesearch, hillclimbsearch,
    chow-liu, Tree-augmented Naive Bayes (TAN), NaiveBayesian.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Constraint-based structure learning (PC): Using statistics such chi-square
    test to test for edge strengths prior the modeling.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Hybrid structure learning: (the combination of both techniques)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Score-based, Constraint-based, and Hybrid structure learning*. Although all
    three techniques will result in a causal DAG, some can handle a large number of
    features while others have higher accuracy. ***Read more details regarding structure
    learning in the underneath blog [2]***.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](/a-step-by-step-guide-in-detecting-causal-relationships-using-bayesian-structure-learning-in-python-c20c6b31cee5?source=post_page-----bfd4dc7f8dcd--------------------------------)
    [## A Step-by-Step Guide in detecting causal relationships using Bayesian Structure
    Learning in Python.'
  prefs: []
  type: TYPE_NORMAL
- en: The starters guide to effectively determine causality across variables.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/a-step-by-step-guide-in-detecting-causal-relationships-using-bayesian-structure-learning-in-python-c20c6b31cee5?source=post_page-----bfd4dc7f8dcd--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '**Parameter learning** is the second important part of Bayesian network analysis,
    and *bnlearn* excels in this area as well. By leveraging a set of data samples
    and a (pre-determined) DAG we can estimate the Conditional Probability Distributions
    or Tables (CPDs or CPTs). ***For more details about parameter learning, I recommend
    the*** [***following blog***](/a-step-by-step-guide-in-designing-knowledge-driven-models-using-bayesian-theorem-7433f6fd64be)***:***'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/a-step-by-step-guide-in-designing-knowledge-driven-models-using-bayesian-theorem-7433f6fd64be?source=post_page-----bfd4dc7f8dcd--------------------------------)
    [## A step-by-step guide in designing knowledge-driven models using Bayesian theorem.'
  prefs: []
  type: TYPE_NORMAL
- en: In case you don’t have data but there is experts knowledge. A starters guide
    to convert knowledge into computer-aided…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/a-step-by-step-guide-in-designing-knowledge-driven-models-using-bayesian-theorem-7433f6fd64be?source=post_page-----bfd4dc7f8dcd--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '*Bnlearn* also provided a plethora of functions and helper utilities to assist
    users throughout the analysis process. These include data set transformation functions,
    topological ordering derivation, graph comparison tools, insightful interactive
    plotting capabilities, and more. The *bnlearn* library supports loading bif files,
    converting directed graphs to undirected ones, and performing statistical tests
    for assessing independence among variables. In case you want to see how *bnlearn*
    performs compared to other causal libraries, [***this blog is for you***](/the-power-of-bayesian-causal-inference-a-comparative-analysis-of-libraries-to-reveal-hidden-d91e8306e25e):'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/the-power-of-bayesian-causal-inference-a-comparative-analysis-of-libraries-to-reveal-hidden-d91e8306e25e?source=post_page-----bfd4dc7f8dcd--------------------------------)
    [## The Power of Bayesian Causal Inference: A Comparative Analysis of Libraries
    to Reveal Hidden…'
  prefs: []
  type: TYPE_NORMAL
- en: 'Reveal the hidden causal variables in your data set by using the best-suited
    Bayesian causal inference library: a…'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/the-power-of-bayesian-causal-inference-a-comparative-analysis-of-libraries-to-reveal-hidden-d91e8306e25e?source=post_page-----bfd4dc7f8dcd--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will jump into making inferences using do-calculus with
    hands-on examples. This allows us to ask questions to our data set. *As mentioned
    earlier, structure learning and parameter learning form the basis.*
  prefs: []
  type: TYPE_NORMAL
- en: Interrogating data sets requires making inferences using do-calculus.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When we make **inferences using do-calculus**, it basically means that we can
    query the data set and “*ask questions*” to the data. To do this, we need two
    main ingredients: **the DAG** and **the CPTs** that are assigned to each node
    in the graph. The CPTs contain the probabilities of each variable and capture
    the causal relationships given to its parents. *Let’s move on and create an example
    where we can see how it really works.*'
  prefs: []
  type: TYPE_NORMAL
- en: Application with the Data Science Salary Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For demonstration, we will use the [data science salary data set](https://ai-jobs.net/salaries/download/)
    that is derived from ai-jobs.net [5]. The salary data set is collected worldwide
    and contains 11 features for 4134 samples. If we load the data, we can explore
    the columns and set features as continuous or category. Note that the model complexity
    increases with the number of categories which means that more data and computation
    time is required to determine a causal DAG.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Complexity is a major limitation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When features contain many categories, the complexity grows exponentially with
    the number of parent nodes associated with that table. In other words, when you
    increase the number of categories, it requires a lot more data to gain reliable
    results. Think about it like this: when you split the data into categories, the
    number of samples within a single category will become smaller after each split.
    The low number of samples per category directly affects the statistical power.
    In our example, we have a feature `job_title` that contains 99 unique titles for
    which 14 job titles (such as *data scientists*) contain 25 samples or more. The
    remaining 85 job titles are either unique or seen only a few times. To make sure
    this feature is not removed by the model because lack of statistical power, we
    need to aggregate some of the job titles. In the code section below we will aggregate
    job titles into 7 main categories. This results in categories that have enough
    samples for Bayesian modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The next pre-processing step is to rename some of the feature names. In addition,
    we will also add a new feature that describes whether the company was located
    in *USA* or *Europe*, and remove some redundant variables, such as `salary_currency`
    and `salary`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: As a final step, we need to discretize `salary_in_usd` which can be done manually
    or using the `discretizer` function in *bnlearn*. For demonstration purposes,
    let’s do both. For the latter case, we assume that salary depends on `experience_level`
    and on the `country`. Read more in this blog [6] for more details. Based on these
    input variables, the salary is then partitioned into bins (see code section below).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The Final DataFrame
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The final data frame has 10 features with 4134 samples. Each feature is a categorical
    feature with two or multiple states. This data frame is going to be the input
    to learn the structure and determine the causal DAG.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Bayesian Structure Learning to estimate the DAG.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At this point, we have pre-processed the data set and we are ready to learn
    the causal structure. There are six algorithms implemented in *bnlearn* that can
    help with this task. We need to choose a method for which we do not need to have
    a target variable, and it needs to handle many categories. The available search
    strategies are:'
  prefs: []
  type: TYPE_NORMAL
- en: '***The hillclimbsearch*** algorithm is a heuristic search method. It starts
    with an empty network and iteratively adds or removes edges based on a scoring
    metric. The algorithm explores different network structures and selects the one
    with the highest score.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***The exhaustivesearch*** performs an exhaustive search over all possible
    network structures to find the optimal Bayesian network. It evaluates and scores
    each structure based on a specified scoring metric. While this method guarantees
    finding the best network structure, it can be computationally expensive for large
    networks due to the exponential growth of possibilities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***The constraintsearch*** incorporates user-specified constraints or expert
    knowledge into the structure learning process of a Bayesian network. It uses these
    constraints to guide the search and restrict the space of possible network structures,
    ensuring that the learned network adheres to the specified constraints.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***The chow-liu*** algorithm is a method for learning the structure of a tree-structured
    Bayesian network. It calculates the mutual information between each pair of variables
    and constructs a tree by greedily selecting the edges that maximize the total
    mutual information of the network. This algorithm is efficient and widely used
    for learning the structure of discrete Bayesian networks but requires setting
    a **root node**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***The naivebayes*** algorithm assumes that all features in a dataset are conditionally
    independent given the class variable. It learns the conditional probability distribution
    of each feature given the class and uses Bayes theorem to calculate the posterior
    probability of the class given the features. Despite its naive assumption, this
    algorithm is often used in classification tasks and can be efficient for large
    datasets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***The TAN*** (Tree-Augmented Naive Bayes) algorithm is an extension of the
    naive Bayes algorithm that allows for dependencies among the features, given the
    class variable. It learns a tree structure that connects the features and uses
    this structure to model the conditional dependencies. TAN combines the simplicity
    of naive Bayes with some modeling power, making it a popular choice for classification
    tasks with correlated features. This method requires setting a **class node**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The scoring types *BIC, K2, BDS, AIC, and BDEU* are used to evaluate and compare
    different network structures. As an example, *BIC* balances the model complexity
    and data fit, while the others consider different types of prior probabilities.
    In addition, the `independence test` prunes the spurious edges from the model.
    In our use case, I will use the `hillclimbsearch` method with scoring type `BIC`
    for structure learning. We will *not* define a target value but let the b*nlearn*
    decide the entire causal structure of the data itself.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/6dd42db64479512bf238fd10face2ed9.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1\. After structure learning, the following causal DAG is learned.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6ae6eb059c7bad22e2beafc663f1d90d.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2\. An interactive plot of the causal DAG.
  prefs: []
  type: TYPE_NORMAL
- en: Chat With Your Data Set.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the learned **DAG** (Figures 1 and 2), we can estimate the conditional
    probability distributions (CPTs, see code section below), and make inferences
    using *do-calculus*. *Let’s* *start asking questions. Note that the results can
    (slightly) change based on the stochastic components in the model.*
  prefs: []
  type: TYPE_NORMAL
- en: Question 1.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is the probability of a job title given that you work in a large comany?
    `*P(job_title | company_size=Large (>250))*`
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*After running the code section below we can see that engineer scientist is
    the most likely outcome* `*(P=0.34)*` *followed by data scientist* `*(P=0.26)*`*.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Question 2.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is the probability of a salary range given a full time employment type,
    partially remote work, have the data science function at entry level and live
    in germany (DE)?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*In the results below we can see our five salary categories for which the strongest
    posterior probability* `*P=0.7*` *is a salary of <80K under these conditions.
    Note that other salaries also occur but they happen less frequently.*'
  prefs: []
  type: TYPE_NORMAL
- en: By changing the variables and evidence we can ask all kinds of questions. For
    example, we can now change experience level, residence, job title, etc, and determine
    how the probabilities are changing.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Final words.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this blog, we learned how to create a Bayesian model and how to ask questions
    to a mixed data set using inferences with do-calculus. With the use of *bnlearn*
    it becomes straightforward to setup such models and the models offer understandable
    and explainable results that can be easily embedded in data science pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: '*Be Safe. Stay Frosty.*'
  prefs: []
  type: TYPE_NORMAL
- en: '***Cheers E.***'
  prefs: []
  type: TYPE_NORMAL
- en: '*If you find this article helpful, you are welcome to* [*follow me*](https://erdogant.medium.com/subscribe)
    *because I write more about Bayesian learning. If you are thinking of taking a
    Medium membership, you can support my work a bit by using my referral link. It
    is the same price as a coffee but this allows you to read unlimited articles every
    month.*'
  prefs: []
  type: TYPE_NORMAL
- en: Software
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Bnlearn [Colab Notebook examples](https://erdogant.github.io/distfit/pages/html/Documentation.html#colab-notebook)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Comparison PDF file between eight Bayesian causality libraries.](https://erdogant.gumroad.com/l/Comparison_python_libraries_bayesian_causality?layout=profile)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s connect!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Let’s connect on LinkedIn](https://www.linkedin.com/in/erdogant/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Follow me on Github](https://github.com/erdogant)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Follow me on Medium](https://erdogant.medium.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Taskesen, E. (2020). [*Learning Bayesian Networks with the bnlearn Python Package.*](https://erdogant.github.io/bnlearn)
    (Version 0.3.22) [Computer software].
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Taskesen E, [*A Step-by-Step Guide in detecting causal relationships using Bayesian
    Structure Learning in Python*](/a-step-by-step-guide-in-detecting-causal-relationships-using-bayesian-structure-learning-in-python-c20c6b31cee5),
    Medium, 2021
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Taskesen E, [*A step-by-step guide in designing knowledge-driven models using
    Bayesian theorem*](/a-step-by-step-guide-in-designing-knowledge-driven-models-using-bayesian-theorem-7433f6fd64be),
    Medium, 2021
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Taskesen, E. (2020). [*The Power of Bayesian Causal Inference: A Comparative
    Analysis of Libraries to Reveal Hidden Causality in Your Dataset*](/the-power-of-bayesian-causal-inference-a-comparative-analysis-of-libraries-to-reveal-hidden-d91e8306e25e),
    Medium 2023.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://ai-jobs.net/salaries/download/](https://ai-jobs.net/salaries/download/)
    ([CC0: Public Domain](https://creativecommons.org/publicdomain/zero/1.0/))'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Kay H. et al, [*Inferring causal impact using Bayesian structural time-series
    models*](https://research.google/pubs/pub41854/), 2015, Annals of Applied Statistics
    (247–274, vol9)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Taskesen, E (2023), [*Create and Explore the Landscape of Roles and Salaries
    in Data Science*](/create-and-explore-the-landscape-of-roles-and-salaries-in-data-science-926092f616ca)*.*
    Medium.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
