["```py\nimport numpy as np\nimport torch\n\n# 3-dim action space\nparam1_space = np.linspace(start=0.1, stop=0.9, num=17)\nparam2_space = np.linspace(start=0.1, stop=0.9, num=17)\nparam3_space = np.linspace(start=0, stop=160, num=17)\n\n# Define action space\nparam1_space = torch.from_numpy(param1_space)\nparam2_space = torch.from_numpy(param2_space)\nparam3_space = torch.from_numpy(param3_space)\n```", "```py\n# Grasshopper reward computation code\ntry:\n    from ladybug_rhino.grasshopper import all_required_inputs\nexcept ImportError as e:\n    raise ImportError('\\nFailed to import ladybug_rhino:\\n\\t{}'.format(e))\n\nif all_required_inputs(ghenv.Component):\n    reward = 0\n    reward -= Soil_volume / 1000\n    done = False\n\n    bInter_relationList = [list(i) for i in bInter_relation.Branches]\n\n    if len(bInter_relationList[0]) > 1:\n        for i in bInter_relationList[0]:\n            # building mass is inside some previously placed one\n            if i == 0:\n                reward -= 5\n            # building mass intersects with some previously placed one\n            elif i == 1:\n                reward -= 5\n        # compensate for self-intersection\n        reward += 5\n```", "```py\n# Define Socket connection between Grasshopper and RL agent in Python\nimport socket\n\nHOST = '127.0.0.1'\ntimeout = 20\n\ndef done_from_gh_client(socket):\n    socket.listen()\n    conn, _ = socket.accept()\n    with conn:\n        return_byt = conn.recv(5000)\n    return_str = return_byt.decode() \n\n    return eval(return_str)\n\ndef reward_from_gh_client(socket):\n    socket.listen()\n    conn, _ = socket.accept()\n    with conn:\n        return_byt = conn.recv(5000)\n    return_str = return_byt.decode()\n    if return_str == 'None':\n        return_float = 0\n    else:\n        return_float = float(return_str) \n\n    return return_float\n\ndef fp_from_gh_client(socket):\n    socket.listen()\n    conn, _ = socket.accept()\n    with conn:\n        return_byt = conn.recv(5000)\n    fp = return_byt.decode()\n\n    return fp\n\ndef send_ep_count_to_gh_client(socket, message):\n    message_str = str(message)\n    message_byt = message_str.encode()\n\n    socket.listen()\n    conn, _ = socket.accept()\n    with conn:\n        conn.send(message_byt)\n\ndef send_to_gh_client(socket, message):\n    message_str = ''\n    for item in message:\n        listToStr = ' '.join(map(str, item))\n        message_str = message_str + listToStr + '\\n'\n\n    message_byt = message_str.encode()\n    socket.listen()\n    conn, _ = socket.accept()\n    with conn:\n        conn.send(message_byt)\n```", "```py\nimport torch \nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.distributions import Categorical\n\n# Actor Critic Model Architecture\ndef enc_block(in_c, out_c, BN=True):\n    if BN:\n        conv = nn.Sequential(\n            nn.Conv2d(in_c, out_c, kernel_size=4, stride=2, \n                      padding=1, bias=True),\n            nn.BatchNorm2d(out_c),\n            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        return conv\n    else:\n        conv = nn.Sequential(\n            nn.Conv2d(in_c, out_c, kernel_size=4, stride=2, \n                      padding=1, bias=True),\n            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n        )\n        return conv\n\nclass GRUpolicy(nn.Module):\n    def __init__(self, n_gru_layers, hidden_size, lin_size1, lin_size2, \n                  enc_size1, enc_size2, enc_size3):\n        super(GRUpolicy, self).__init__()\n\n        #critic\n        self.critic_enc1 = enc_block(3, enc_size1, BN=False)\n        self.critic_enc2 = enc_block(enc_size1, enc_size2, BN=True)\n        self.critic_enc3 = enc_block(enc_size2, enc_size3, BN=True)\n        self.critic_enc4 = enc_block(enc_size3, 128, BN=True)\n\n        self.critic_linear1 = nn.Linear(512, lin_size1)\n        self.critic_linear2 = nn.Linear(lin_size1, lin_size2)\n        self.critic_linear3 = nn.Linear(lin_size2, 1)\n\n        # actor\n        self.gru1 = nn.GRU(4, hidden_size, n_gru_layers, batch_first=True)\n        self.gru2 = nn.GRU(4, hidden_size, n_gru_layers, batch_first=True)\n        self.gru3 = nn.GRU(4, hidden_size, n_gru_layers, batch_first=True)\n        self.actor_linear = nn.Linear(hidden_size, 17)\n\n    def forward(self, state):\n        state = Variable(state.unsqueeze(0))\n\n        # critic\n        enc = self.critic_enc1(state)\n        enc = self.critic_enc2(enc)\n        enc = self.critic_enc3(enc)\n        enc = self.critic_enc4(enc)\n\n        value = F.relu(self.critic_linear1(torch.flatten(enc)))\n        value = F.relu(self.critic_linear2(value))\n        value = self.critic_linear3(value)\n\n        # actor\n        seq = torch.reshape(enc, (1, 128, 4))\n\n        out1, h_1 = self.gru1(seq)\n        out_s1 = torch.squeeze(out1[:, -1, :])\n        out_l1 = self.actor_linear(out_s1)\n        prob1 = F.softmax(out_l1, dim=-1)\n        dist1 = Categorical(prob1)\n\n        out2, h_2 = self.gru2(seq, h_1)  \n        out_s2 = torch.squeeze(out2[:, -1, :])\n        out_l2 = self.actor_linear(out_s2)\n        prob2 = F.softmax(out_l2, dim=-1)\n        dist2 = Categorical(prob2)\n\n        out3, _ = self.gru3(seq, h_2)\n        out_s3 = torch.squeeze(out3[:, -1, :])\n        out_l3 = self.actor_linear(out_s3)\n        prob3 = F.softmax(out_l3, dim=-1)\n        dist3 = Categorical(prob3)\n\n        return value, dist1, dist2, dist3 \n\n# Set device\nis_cuda = torch.cuda.is_available()\ndevice = torch.device('cuda' if is_cuda else 'cpu')\nprint(f'Used Device: {device}')\n\n# Initialize DRL model\nactorcritic = GRUpolicy(config.n_gru_layers, config.hidden_size, \n                        config.lin_size1, config.lin_size2, \n                        config.enc_size1, config.enc_size2, \n                        config.enc_size3).to(device)\n\n# Initialize optimizer \nac_optimizer = optim.Adam(actorcritic.parameters(), lr=config.lr, weight_decay = 1e-6)\n```", "```py\n# model forward pass\nvalue, dist1, dist2, dist3 = actorcritic.forward(state) \n\n# get action from probability distributions\nparam1 = param1_space[dist1.sample()]\nparam2 = param2_space[dist2.sample()]\nparam3 = param3_space[dist3.sample()] \n\naction = [param1, param2, param3]\n```", "```py\n# Send action through socket\nwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n    s.bind((HOST, 8080))\n    s.settimeout(timeout)\n    send_to_gh_client(s, action)\n\n# Send episode count through socket\nwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n    s.bind((HOST, 8083))\n    s.settimeout(timeout)\n    send_ep_count_to_gh_client(s, episode)\n\n####### Awaiting Grasshopper script response #######\n\n# Receive observation from Grasshopper Client\nwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n    s.bind((HOST, 8084))\n    s.settimeout(timeout)\n    fp = fp_from_gh_client(s)\n\n# Receive Reward from Grasshopper Client\nwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n    s.bind((HOST, 8081))\n    s.settimeout(timeout)\n    reward = reward_from_gh_client(s)\n\n# Receive done from Grasshopper Client\nwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n    s.bind((HOST, 8082))\n    s.settimeout(timeout)\n    done = done_from_gh_client(s)\n```", "```py\n# compute loss functions\nreturns = []\nfor t in reversed(range(len(rewards))):\n    Qval = rewards[t] + config.gamma * Qval\n    returns.insert(0, Qval)\n\nreturns = torch.cat(returns).detach()\nvalues = torch.cat(values)\nlog_probs = torch.cat(log_probs)\n\nadvantage = returns - values\n\nactor_loss = -(log_probs * advantage.detach()).mean() \ncritic_loss = 0.5 * advantage.pow(2).mean() \nac_loss = actor_loss + critic_loss - config.beta * entropy\n\n# update actor critic\nac_optimizer.zero_grad()\nac_loss.backward()\nac_optimizer.step()\n```"]