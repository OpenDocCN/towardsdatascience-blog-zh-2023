# 长短期结合：基于比例的相关性以捕捉文档语义端到端

> 原文：[https://towardsdatascience.com/the-long-and-short-of-it-proportion-based-relevance-to-capture-document-semantics-end-to-end-f5a755e5a82f](https://towardsdatascience.com/the-long-and-short-of-it-proportion-based-relevance-to-capture-document-semantics-end-to-end-f5a755e5a82f)

[](https://medium.com/@alcarazanthony1?source=post_page-----f5a755e5a82f--------------------------------)[![Anthony Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----f5a755e5a82f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f5a755e5a82f--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f5a755e5a82f--------------------------------) [安东尼·阿尔卡拉斯](https://medium.com/@alcarazanthony1?source=post_page-----f5a755e5a82f--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f5a755e5a82f--------------------------------) ·阅读时间5分钟·2023年11月25日

--

*本文的语法、流畅性和可读性由人工智能软件增强。*

当前主流的搜索方法通常依赖于关键词匹配或向量空间相似性来估算查询与文档之间的相关性。然而，当使用整个文件、论文甚至书籍作为搜索查询时，这些技术会遇到困难。

![](../Images/88c8318af5222375bec03ff04d3b5364.png)

与Dall-E 3的趣味互动

**基于关键词的检索**

虽然关键词搜索在短时间查询中表现出色，但它们未能捕捉到对长篇内容至关重要的语义。一个正确讨论“云平台”的文档可能会完全被一个寻求“AWS”专业知识的查询遗漏。确切的术语匹配在长篇文本中经常面临词汇不匹配问题。

**向量相似性搜索**

现代向量嵌入模型如BERT将意义压缩为数百个数值维度，准确估算语义相似性。然而，具有自注意力的变换器架构因计算量激增而无法扩展到512–1024个标记以上。

没有完全处理文档的能力，结果的“词袋”部分嵌入丢失了在各部分间交织的意义细微差别。背景在抽象中丢失了。

巨大的计算复杂度也限制了在大多数实际语料库上的微调，从而限制了准确性。无监督学习提供了一个替代方案，但仍缺乏可靠的技术。

在一篇 [最新论文](https://arxiv.org/pdf/2303.01200.pdf) 中，研究人员通过重新构思超长查询和文档的相关性，解决了这些问题。他们的创新解锁了AI文档搜索的新潜力。

# 长文档的问题

目前主流的搜索范式对于输入文本达到数千字的查询效果不佳。面临的主要问题包括：

+   **像 BERT 这样的变换器**具有二次自注意力复杂度，使得处理超出 512–1024 令牌的序列变得不可行。它们的稀疏注意力替代方案在准确性上有所妥协。

+   **词汇模型**基于精确的术语重叠进行匹配，无法推断长文本中至关重要的语义相似性。

+   大多数领域集合缺乏标注训练数据，需采用 **无监督或最少调优的方法**。

+   涵盖多个子主题的长文档需要能够 **将文档结构因素纳入相关性判断** 的模型。

RPRS 方法旨在解决当前检索架构中的这些弱点。

# 介绍 RPRS 模型

RPRS 模型通过计算长查询文档与候选文档之间句子的比例匹配来计算相关性。

关键洞察是，包含与查询中句子相似的句子比例较高的文档通常更相关。

该方法包含 3 个关键阶段：

## 1. 句子编码

+   使用 SBERT 将查询和候选文档中的句子编码为向量 —— 一种高效的变换器架构用于句子嵌入。

+   SBERT 避免了二次复杂度，使得可以处理完整的文档长度。

## 2. 最相关的句子集

+   对于每个查询句子，基于向量嵌入找到最相似的 k 个候选文档句子。

+   确定每个查询句子最相关的文档句子集。

## 3. 基于比例的相关性评分

+   定义查询比例 (QP) —— 查询句子与文档句子相似的相对比例

+   定义文档比例 (DP) —— 与查询句子相似的文档句子的相对比例

+   结合 QP 和 DP 来计算最终的相关性评分，估计文本之间的相互关联性。

比例相关性的概念内在地考虑了长文本中的文档结构。

另一个扩展名为 RPRS w/freq 额外考虑了 *术语频率* 和 *长度归一化*，受到 BM25 的启发，以处理重复和长度偏差。

# 比例相关性公式

RPRS 方法的核心是一个简单而强大的相关性评分公式，用于计算查询文档 `q` 和候选文档 `d` 之间的相关性：

[PRE0]

其中：

+   `QP(q, d)` 是 **查询比例**

+   `DP(q, d)` 是 **文档比例**

+   `RPRS_q(d)` 是 **比例相关性评分**

这些比例因素旨在从两个角度量化查询与候选文档文本之间的相互关联性。

# 查询比例

查询比例确定查询内容中有多少百分比与文档的某些部分相似。

对于查询 `q` 中的每个句子 `q_s`：

+   从文档 `d` 中检索前 `n` 个最相似的句子 `d_si`

+   计算 # 查询句子中至少有 1 个相似的 `d_si`

+   除以查询句子的总数

[PRE1]

更高的 QP 表示查询中的更多内容在文档中找到了匹配。

## 文档比例

文档比例反过来决定了文档中有多少百分比与查询的某个部分相似。

对于文档 `d` 中的每个句子 `d_s`：

+   检查 `d_s` 是否出现在任何 `q_s` 的前 `n` 个匹配 `d_si` 中

+   计算与某些 `q_s` 匹配的文档句子数量

+   除以文档句子的总数

[PRE2]

更高的 DP 表示文档内容中有更多的内容与查询匹配。

## 结合因素

比例相关性评分简单地是查询比例和文档比例的乘积：

[PRE3]

净效果是奖励最大限度地覆盖查询的文档，同时被查询最大限度地覆盖——表明从两个角度来看都具有全面的语义相似性。

# 在法律、专利和维基百科数据集上的结果

研究人员在五个长文档数据集上全面评估了 RPRS，这些数据集涵盖了法律案件检索、专利搜索和维基百科文档相似性任务，包含数千个单词。

在所有数据集上，RPRS 显著超越了之前的最先进技术以及词汇和神经基线，同时仅使用了 3 个调整参数，展示了其有效性。组件重要性分析进一步验证了比例评分方法。

该方法结合了通过向量嵌入进行的语义匹配能力和跨句子的主题相关性的直观概念，提供了可解释的高准确性检索。

# 解决长期存在的局限性

RPRS 模型突显了经典检索中的关键思想与现代 NLP 表示相结合，可以在挑战性领域（如搜索法律文献和科学文献）推动边界，这些领域迄今为止一直抵抗高性能自动化。

这样做也将神经搜索范式的范围扩展到超长文本，其中大多数成熟模型目前面临限制。更广泛地说，围绕复杂文档集合设计基于相关性的基本原则架构仍然是搜索技术中一个富有创新性的领域。

论文提供了一个有说服力的适应蓝图，但仍有很大空间可供与大型语言模型、可解释性以及商业文档搜索解决方案的用户体验进步进行整合。
