- en: Five Things GenAI Can and Canâ€™t Do
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: äº”ä»¶äº‹ GenAI èƒ½åšå’Œä¸èƒ½åšçš„äº‹æƒ…
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/five-things-genai-can-and-cant-do-d8117aad82f4](https://towardsdatascience.com/five-things-genai-can-and-cant-do-d8117aad82f4)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/five-things-genai-can-and-cant-do-d8117aad82f4](https://towardsdatascience.com/five-things-genai-can-and-cant-do-d8117aad82f4)
- en: An introductory guide for business leaders as to what Generative AI can or cannot
    do
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸ºå•†ä¸šé¢†è¢–æä¾›çš„å…³äºç”Ÿæˆå‹AIèƒ½åšæˆ–ä¸èƒ½åšçš„ä»‹ç»æ€§æŒ‡å—
- en: '[](https://dkhundley.medium.com/?source=post_page-----d8117aad82f4--------------------------------)[![David
    Hundley](../Images/1779ef96ec3d338f8fe4a9567ba7b194.png)](https://dkhundley.medium.com/?source=post_page-----d8117aad82f4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d8117aad82f4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d8117aad82f4--------------------------------)
    [David Hundley](https://dkhundley.medium.com/?source=post_page-----d8117aad82f4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dkhundley.medium.com/?source=post_page-----d8117aad82f4--------------------------------)[![David
    Hundley](../Images/1779ef96ec3d338f8fe4a9567ba7b194.png)](https://dkhundley.medium.com/?source=post_page-----d8117aad82f4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d8117aad82f4--------------------------------)[![æ•°æ®ç§‘å­¦çš„å‰æ²¿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d8117aad82f4--------------------------------)
    [David Hundley](https://dkhundley.medium.com/?source=post_page-----d8117aad82f4--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d8117aad82f4--------------------------------)
    Â·11 min readÂ·Oct 7, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [æ•°æ®ç§‘å­¦çš„å‰æ²¿](https://towardsdatascience.com/?source=post_page-----d8117aad82f4--------------------------------)
    Â·11åˆ†é’Ÿé˜…è¯»Â·2023å¹´10æœˆ7æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/eb063b6b18c957526b4addb9f73e4feb.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eb063b6b18c957526b4addb9f73e4feb.png)'
- en: Cover photo created by the author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å°é¢ç…§ç‰‡ç”±ä½œè€…åˆ›ä½œ
- en: Itâ€™s hard to believe that itâ€™s still not quite been a year since ChatGPTâ€™s launch,
    and we have seen Generative AI (GenAI) take the world by storm. From large language
    models (LLMs) to stable diffusion models for image generation, it is really quite
    remarkable what this new technology can do. A friend described it to me as the
    first time AI has felt tangible to them, as if what we only dreamed about through
    science fiction has now become reality.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: éš¾ä»¥ç½®ä¿¡çš„æ˜¯ï¼Œè‡ªChatGPTå‘å¸ƒä»¥æ¥è¿˜ä¸åˆ°ä¸€å¹´ï¼Œæˆ‘ä»¬å·²ç»çœ‹åˆ°ç”Ÿæˆå‹AIï¼ˆGenAIï¼‰å¸­å·äº†æ•´ä¸ªä¸–ç•Œã€‚ä»å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åˆ°ç¨³å®šæ‰©æ•£æ¨¡å‹ç”¨äºå›¾åƒç”Ÿæˆï¼Œè¿™é¡¹æ–°æŠ€æœ¯æ‰€èƒ½åšçš„ç¡®å®ä»¤äººæƒŠå¹ã€‚ä¸€ä½æœ‹å‹å‘Šè¯‰æˆ‘ï¼Œè¿™æ˜¯AIç¬¬ä¸€æ¬¡è®©ä»–ä»¬æ„Ÿåˆ°è§¦æ‰‹å¯åŠï¼Œå°±åƒæˆ‘ä»¬é€šè¿‡ç§‘å¹»å°è¯´æ¢¦æƒ³åˆ°çš„ä¸œè¥¿ç°åœ¨å·²ç»å˜æˆç°å®ã€‚
- en: Naturally, this has given business leaders pause to wonder what GenAI can or
    canâ€™t do to transform their business processes. There are certainly many cool
    things you can do with GenAI, but there are also some misconceptions floating
    around out there that business leaders should be cautious about. The focus of
    this post is to share with you some of the core things that GenAI can do while
    also tempering oneâ€™s expectations to caution on what it cannot do.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªç„¶åœ°ï¼Œè¿™è®©å•†ä¸šé¢†è¢–ä»¬å¼€å§‹æ€è€ƒGenAIèƒ½æˆ–ä¸èƒ½åšä»€ä¹ˆæ¥è½¬å˜ä»–ä»¬çš„ä¸šåŠ¡æµç¨‹ã€‚ç¡®å®ï¼Œä½ å¯ä»¥ç”¨GenAIåšå¾ˆå¤šé…·çš„äº‹æƒ…ï¼Œä½†ä¹Ÿæœ‰ä¸€äº›æµä¼ çš„è¯¯è§£ï¼Œå•†ä¸šé¢†è¢–ä»¬åº”è¯¥å°å¿ƒã€‚æœ¬æ–‡çš„é‡ç‚¹æ˜¯ä¸æ‚¨åˆ†äº«GenAIèƒ½å¤Ÿåšçš„ä¸€äº›æ ¸å¿ƒäº‹æƒ…ï¼ŒåŒæ—¶ä¹Ÿæé†’å¯¹å…¶ä¸èƒ½åšçš„äº‹æƒ…ä¿æŒé€‚å½“çš„æœŸæœ›ã€‚
- en: 'Can #1: GenAI can summarize a lot of information.'
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'èƒ½åšçš„ #1ï¼šGenAIå¯ä»¥æ€»ç»“å¤§é‡ä¿¡æ¯ã€‚'
- en: Perhaps one of the most classic use cases Iâ€™m hearing across all industries
    is the ability to use large language models (LLM) in particular to condense a
    lot of information into something far more digestible. For example, you can take
    a transcribed dialogue from a meeting and use GenAI to summarize the information
    into a few key bullets. Additionally, you can take a large legal document and
    have an LLM pull out the most relevant bits of information. Of course, you should
    always be cautious to verify that the output of the LLM is correct, but this can
    save a ton of time in many different business contexts. I highly expect this to
    continue to gain traction in more and more industries over time.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿè®¸æˆ‘å¬åˆ°çš„æ‰€æœ‰è¡Œä¸šä¸­æœ€ç»å…¸çš„ç”¨ä¾‹ä¹‹ä¸€æ˜¯ï¼Œç‰¹åˆ«æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å°†å¤§é‡ä¿¡æ¯å‹ç¼©æˆæ›´æ˜“äºæ¶ˆåŒ–çš„å†…å®¹ã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥å°†ä¼šè®®çš„è½¬å½•å¯¹è¯äº¤ç»™GenAIï¼Œæ€»ç»“æˆå‡ ä¸ªå…³é”®è¦ç‚¹ã€‚æ­¤å¤–ï¼Œä½ å¯ä»¥å°†ä¸€ä»½å¤§å‹æ³•å¾‹æ–‡ä»¶äº¤ç»™LLMï¼Œè®©å®ƒæå–å‡ºæœ€ç›¸å…³çš„ä¿¡æ¯ã€‚å½“ç„¶ï¼Œä½ åº”è¯¥å§‹ç»ˆå°å¿ƒæ ¸å®LLMçš„è¾“å‡ºæ˜¯å¦æ­£ç¡®ï¼Œä½†è¿™åœ¨è®¸å¤šä¸åŒçš„ä¸šåŠ¡ç¯å¢ƒä¸­å¯ä»¥èŠ‚çœå¤§é‡æ—¶é—´ã€‚æˆ‘é«˜åº¦é¢„æœŸè¿™å°†åœ¨æ›´å¤šè¡Œä¸šä¸­æŒç»­è·å¾—å…³æ³¨ã€‚
- en: 'Canâ€™t #1: GenAI canâ€™t ever be certain about anything.'
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'ä¸èƒ½åšçš„ #1ï¼šGenAIæ°¸è¿œæ— æ³•å¯¹ä»»ä½•äº‹æƒ…æœ‰ç¡®åˆ‡çš„ç¡®å®šæ€§ã€‚'
- en: Perhaps one of the greatest misconceptions about LLMs is that they can think.
    In reality, LLMs are simply word prediction machines, albeit these models are
    so interestingly precise that it almost appears as if they are emulating true
    consciousness. Because LLMs act on probabilities between words, it can never be
    truly certain of its final output. Ironically however, it always will produce
    a very confident output. We refer to these confident but false statements as **hallucinations**.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿè®¸å…³äº LLM çš„æœ€å¤§è¯¯è§£ä¹‹ä¸€æ˜¯å®ƒä»¬èƒ½å¤Ÿæ€è€ƒã€‚å®é™…ä¸Šï¼ŒLLM åªæ˜¯é¢„æµ‹è¯æ±‡çš„æœºå™¨ï¼Œå°½ç®¡è¿™äº›æ¨¡å‹çš„ç²¾ç¡®åº¦éå¸¸é«˜ï¼Œä»¥è‡³äºçœ‹èµ·æ¥å®ƒä»¬ä¼¼ä¹åœ¨æ¨¡æ‹ŸçœŸæ­£çš„æ„è¯†ã€‚ç”±äº
    LLM æ˜¯åŸºäºè¯æ±‡ä¹‹é—´çš„æ¦‚ç‡è¿›è¡Œæ“ä½œçš„ï¼Œå®ƒæ°¸è¿œä¸èƒ½çœŸæ­£ç¡®å®šæœ€ç»ˆè¾“å‡ºã€‚ç„¶è€Œï¼Œå…·æœ‰è®½åˆºæ„å‘³çš„æ˜¯ï¼Œå®ƒæ€»æ˜¯ä¼šäº§ç”Ÿéå¸¸è‡ªä¿¡çš„è¾“å‡ºã€‚æˆ‘ä»¬å°†è¿™äº›è‡ªä¿¡ä½†é”™è¯¯çš„é™ˆè¿°ç§°ä¸º**è™šæ„**ã€‚
- en: 'Consider the following sentence: â€œI like to drink ______ in the morning.â€ If
    you were to answer this as a human, you might scratch your head. We can fairly
    ascertain that the blank is a liquid of some sort, but what liquid is it precisely?
    Coffee? Tea? Water? Just like a human, the LLM also canâ€™t be certain of the answer;
    however, unlike the human, the LLM wonâ€™t tell you, â€œI donâ€™t know.â€ Instead, it
    will confidently give an answer, except you and I know that the LLM canâ€™t possibly
    be certain of the answer. Letâ€™s actually see how ChatGPT attempts to fill in this
    blank.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘ä»¥ä¸‹å¥å­ï¼šâ€œI like to drink ______ in the morningã€‚â€å¦‚æœä½ ä½œä¸ºä¸€ä¸ªäººæ¥å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œå¯èƒ½ä¼šæŒ å¤´ã€‚æˆ‘ä»¬å¯ä»¥ç›¸å½“ç¡®å®šç©ºç™½å¤„æ˜¯æŸç§æ¶²ä½“ï¼Œä½†å…·ä½“æ˜¯ä»€ä¹ˆæ¶²ä½“å‘¢ï¼Ÿå’–å•¡ï¼ŸèŒ¶ï¼Ÿæ°´ï¼Ÿå°±åƒäººç±»ä¸€æ ·ï¼ŒLLM
    ä¹Ÿä¸èƒ½ç¡®å®šç­”æ¡ˆï¼›ç„¶è€Œï¼Œä¸åŒäºäººç±»ï¼ŒLLM ä¸ä¼šå‘Šè¯‰ä½ â€œæˆ‘ä¸çŸ¥é“â€ã€‚ç›¸åï¼Œå®ƒä¼šè‡ªä¿¡åœ°ç»™å‡ºä¸€ä¸ªç­”æ¡ˆï¼Œå°½ç®¡ä½ å’Œæˆ‘çŸ¥é“ LLM ä¸èƒ½çœŸæ­£ç¡®å®šç­”æ¡ˆã€‚è®©æˆ‘ä»¬å®é™…çœ‹çœ‹ ChatGPT
    å¦‚ä½•å°è¯•å¡«è¡¥è¿™ä¸ªç©ºç™½ã€‚
- en: '![](../Images/b97a5c187eb6db0b62d7b5965afad3f7.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b97a5c187eb6db0b62d7b5965afad3f7.png)'
- en: Screenshot of ChatGPT for iPad captured by the author
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±ä½œè€…æ‹æ‘„çš„ iPad ä¸Š ChatGPT çš„æˆªå›¾
- en: As you can see, ChatGPT confidently fills in the blank as â€œcoffeeâ€, yet it gives
    no indication that maybe it filled it in incorrectly. Again, we refer to this
    overly confident â€œguessâ€ as a hallucination, but we can diminish these hallucinations
    with the next bulletâ€¦
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä½ æ‰€è§ï¼ŒChatGPT è‡ªä¿¡åœ°å°†ç©ºç™½å¡«ä¸ºâ€œcoffeeâ€ï¼Œä½†å®ƒæ²¡æœ‰è¡¨æ˜ä¹Ÿè®¸å¡«é”™äº†ã€‚æˆ‘ä»¬å†æ¬¡å°†è¿™ç§è¿‡åº¦è‡ªä¿¡çš„â€œçŒœæµ‹â€ç§°ä¸ºè™šæ„ï¼Œä½†æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹ä¸€ä¸ªè¦ç‚¹æ¥å‡å°‘è¿™äº›è™šæ„â€¦â€¦
- en: 'Can #2: GenAI can give more informed answers with an augmented context.'
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '#2ï¼šGenAI å¯ä»¥é€šè¿‡å¢å¼ºçš„ä¸Šä¸‹æ–‡æä¾›æ›´æœ‰æ ¹æ®çš„ç­”æ¡ˆã€‚'
- en: 'In the previous point, we noted that an LLM canâ€™t be particularly sure how
    to fill the blank in for the following sentence: â€œI like to drink ______ in the
    morning.â€ We can, however, augment the knowledge of the LLM by providing it additional
    context. In the GenAI community, we refer to this as **retrieval augmented generation
    (RAG)**. If we were to ask the LLM to fill in the blank above without any additional
    context, it will definitely give us an answer, but that answer may be hallucinated.
    Now, letâ€™s say we gave the LLM some additional context. Letâ€™s alter what we might
    input to the LLM with the following:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å‰ä¸€ç‚¹ä¸­ï¼Œæˆ‘ä»¬æåˆ° LLM å¯¹ä»¥ä¸‹å¥å­ä¸­çš„ç©ºç™½å¡«å……æ²¡æœ‰ç‰¹åˆ«ç¡®å®šæ€§ï¼šâ€œI like to drink ______ in the morningã€‚â€ç„¶è€Œï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æä¾›é¢å¤–çš„ä¸Šä¸‹æ–‡æ¥å¢å¼º
    LLM çš„çŸ¥è¯†ã€‚åœ¨ GenAI ç¤¾åŒºï¼Œæˆ‘ä»¬å°†æ­¤ç§°ä¸º**æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰**ã€‚å¦‚æœæˆ‘ä»¬è¦æ±‚ LLM åœ¨æ²¡æœ‰ä»»ä½•é¢å¤–ä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹å¡«å……ä¸Šè¿°ç©ºç™½ï¼Œå®ƒè‚¯å®šä¼šç»™å‡ºä¸€ä¸ªç­”æ¡ˆï¼Œä½†é‚£ä¸ªç­”æ¡ˆå¯èƒ½æ˜¯è™šæ„çš„ã€‚ç°åœ¨ï¼Œå‡è®¾æˆ‘ä»¬ç»™
    LLM ä¸€äº›é¢å¤–çš„ä¸Šä¸‹æ–‡ã€‚è®©æˆ‘ä»¬ä¿®æ”¹è¾“å…¥ç»™ LLM çš„å†…å®¹å¦‚ä¸‹ï¼š
- en: 'My name is David Hundley. I like to drink a cold brew coffee from Starbucks
    each morning. Using this information, please fill in the blank in the following
    sentence: â€œI like to drink ______ in the morning.â€'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æˆ‘çš„åå­—æ˜¯ David Hundleyã€‚æˆ‘å–œæ¬¢æ¯å¤©æ—©æ™¨å–ä¸€æ¯ Starbucks çš„å†·èƒå’–å•¡ã€‚ä½¿ç”¨è¿™äº›ä¿¡æ¯ï¼Œè¯·å¡«è¡¥ä»¥ä¸‹å¥å­ä¸­çš„ç©ºç™½ï¼šâ€œI like to
    drink ______ in the morningã€‚â€
- en: Now that the LLM has been provided some very specific context, it can sufficiently
    fill in the blank. Testing this out in ChatGPT, youâ€™ll see that we receive the
    precisely correct answer.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼ŒLLM å·²ç»è·å¾—äº†ä¸€äº›éå¸¸å…·ä½“çš„ä¸Šä¸‹æ–‡ï¼Œå®ƒå¯ä»¥å……åˆ†å¡«è¡¥ç©ºç™½ã€‚åœ¨ ChatGPT ä¸­æµ‹è¯•æ—¶ï¼Œä½ ä¼šçœ‹åˆ°æˆ‘ä»¬æ”¶åˆ°çš„æ˜¯ç²¾ç¡®çš„æ­£ç¡®ç­”æ¡ˆã€‚
- en: '![](../Images/6e1baeab36c1aa690118aea930ee7cf1.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6e1baeab36c1aa690118aea930ee7cf1.png)'
- en: Screenshot of ChatGPT for iPad captured by the author
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±ä½œè€…æ‹æ‘„çš„ iPad ä¸Š ChatGPT çš„æˆªå›¾
- en: Of course, this still does not make the output of an LLM completely surefire
    in its response. Remember, the LLM is assessing probabilities between words. In
    the RAG process, we are simply augmenting the probability of producing an output
    with a more correct answer. This doesnâ€™t boost the probability of certainty to
    100%, but it definitely can help quite a bit!
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œè¿™ä»ç„¶ä¸ä¼šä½¿ LLM çš„è¾“å‡ºå®Œå…¨å¯é ã€‚è¯·è®°ä½ï¼ŒLLM åœ¨è¯„ä¼°è¯æ±‡ä¹‹é—´çš„æ¦‚ç‡ã€‚åœ¨ RAG è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬åªæ˜¯é€šè¿‡æ›´æ­£ç¡®çš„ç­”æ¡ˆå¢å¼ºäº†è¾“å‡ºçš„æ¦‚ç‡ã€‚è¿™å¹¶ä¸ä¼šå°†ç¡®å®šæ€§çš„æ¦‚ç‡æå‡åˆ°
    100%ï¼Œä½†ç¡®å®å¯ä»¥æä¾›å¾ˆå¤§å¸®åŠ©ï¼
- en: 'Canâ€™t #2: GenAI canâ€™t figure out new things on itâ€™s own.'
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'æ— æ³•è§£å†³ #2ï¼šGenAI ä¸èƒ½è‡ªå·±è§£å†³æ–°é—®é¢˜ã€‚'
- en: While the RAG process can go a long way to help GenAI provide a more precise
    answer, the RAG process is not one that is automatic. In other words, GenAI technologies
    like LLMs donâ€™t have the ability to go learning things for itself. These GenAI
    models are trained on information provided to it at a snapshot in time, almost
    as if its knowledge is frozen to that fixed date. When we provide additional context
    to the LLM, the context can be helpful to produce a more precise output, but **this
    RAG context is NOT actually altering the underlying model itself**.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡ RAG è¿‡ç¨‹å¯ä»¥åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå¸®åŠ© GenAI æä¾›æ›´ç²¾ç¡®çš„å›ç­”ï¼Œä½† RAG è¿‡ç¨‹å¹¶ä¸æ˜¯è‡ªåŠ¨çš„ã€‚æ¢å¥è¯è¯´ï¼Œåƒ LLMs è¿™æ ·çš„ GenAI æŠ€æœ¯æ²¡æœ‰è‡ªæˆ‘å­¦ä¹ çš„èƒ½åŠ›ã€‚è¿™äº›
    GenAI æ¨¡å‹æ˜¯åœ¨æŸä¸€æ—¶é—´ç‚¹æä¾›çš„ä¿¡æ¯ä¸Šè¿›è¡Œè®­ç»ƒçš„ï¼Œå‡ ä¹å°±åƒå®ƒä»¬çš„çŸ¥è¯†è¢«å†»ç»“åœ¨é‚£ä¸ªå›ºå®šæ—¥æœŸã€‚å½“æˆ‘ä»¬å‘ LLM æä¾›é¢å¤–çš„ä¸Šä¸‹æ–‡æ—¶ï¼Œè¿™äº›ä¸Šä¸‹æ–‡å¯ä»¥å¸®åŠ©ç”Ÿæˆæ›´ç²¾ç¡®çš„è¾“å‡ºï¼Œä½†**è¿™ä¸ª
    RAG ä¸Šä¸‹æ–‡å®é™…ä¸Šå¹¶ä¸ä¼šæ”¹å˜åŸºç¡€æ¨¡å‹æœ¬èº«**ã€‚
- en: The reason I bring this up is while the RAG process can be great, itâ€™s not like
    you can tell GenAI itself to go find that information for itself. Even in the
    cases like Bing Chat where it appears that the LLM is searching the internet,
    it is not actually the model that is crawling the internet. **Rather, the information
    is being brought to the LLM, and the LLM is making sense of what is brought to
    it.** Weâ€™ve not yet reached that Skynet-like level of superintelligence where
    these AI models can figure things out for themselves. ğŸ¤–
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æåˆ°è¿™ä¸€ç‚¹çš„åŸå› æ˜¯ï¼Œå°½ç®¡ RAG è¿‡ç¨‹å¯èƒ½å¾ˆæœ‰ç”¨ï¼Œä½†ä½ ä¸èƒ½è®© GenAI è‡ªè¡Œå»å¯»æ‰¾è¿™äº›ä¿¡æ¯ã€‚å³ä½¿åƒ Bing Chat è¿™æ ·çš„æ¡ˆä¾‹ä¸­ï¼ŒLLM ä¼¼ä¹åœ¨æœç´¢äº’è”ç½‘ï¼Œä½†å®é™…ä¸Šå¹¶ä¸æ˜¯æ¨¡å‹åœ¨çˆ¬å–äº’è”ç½‘ã€‚**è€Œæ˜¯ä¿¡æ¯è¢«å¸¦åˆ°
    LLMï¼ŒLLM åœ¨ç†è§£è¿™äº›å¸¦æ¥çš„ä¿¡æ¯ã€‚** æˆ‘ä»¬è¿˜æ²¡æœ‰è¾¾åˆ°é‚£ç§åƒå¤©ç½‘ä¸€æ ·çš„è¶…çº§æ™ºèƒ½æ°´å¹³ï¼Œèƒ½å¤Ÿè®©è¿™äº› AI æ¨¡å‹è‡ªå·±è§£å†³é—®é¢˜ã€‚ğŸ¤–
- en: 'Can #3: GenAI can be a great coding assistant.'
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'å¯ä»¥è§£å†³ #3ï¼šGenAI å¯ä»¥æ˜¯ä¸€ä¸ªå¾ˆæ£’çš„ç¼–ç åŠ©æ‰‹ã€‚'
- en: Pay close attention to the phrasing on this particular one. Iâ€™m very intentional
    about the word â€œcanâ€ with this point. Itâ€™s no secret that people have found ways
    to leverage LLMs for coding purposes, and to be perfectly clear, LLMs can be great
    for helping to write code. Whether it be autofilling common tasks or helping to
    debug errors, GenAI can be a very useful tool when it comes to coding.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·ç‰¹åˆ«æ³¨æ„è¿™ä¸€ç‚¹çš„æªè¾ã€‚æˆ‘åœ¨è¿™ä¸ªç‚¹ä¸Šå¯¹â€œèƒ½â€è¿™ä¸ªè¯éå¸¸è®²ç©¶ã€‚äººä»¬å·²ç»å‘ç°äº†åˆ©ç”¨ LLM è¿›è¡Œç¼–ç çš„æ–¹å¼ï¼Œè¿™å¹¶ä¸æ˜¯ä»€ä¹ˆç§˜å¯†ã€‚æ˜ç¡®æ¥è¯´ï¼ŒLLM åœ¨å¸®åŠ©ç¼–å†™ä»£ç æ–¹é¢å¯ä»¥éå¸¸å‡ºè‰²ã€‚æ— è®ºæ˜¯è‡ªåŠ¨å¡«å……å¸¸è§ä»»åŠ¡è¿˜æ˜¯å¸®åŠ©è°ƒè¯•é”™è¯¯ï¼ŒGenAI
    åœ¨ç¼–ç æ—¶å¯ä»¥æ˜¯ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„å·¥å…·ã€‚
- en: The thing isâ€¦ LLMs arenâ€™t perfect in this task. In addition to being limited
    by being trained on information at a snapshot in time, my personal experience
    is that the LLMs tend to hallucinate quite a bit when asked to write code for
    very nuanced situations. **Remember, LLMs are only as good as the context you
    provide it.** If you have an error that stems from something related to your very
    specific system, the LLM canâ€™t be aware of your systemâ€™s details and will thus
    ultimately hallucinate the answer. This isnâ€™t to say that GenAI canâ€™t be helpful
    for writing code, but I would view it more as an assistant than anything.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: é—®é¢˜åœ¨äºâ€¦â€¦ LLM åœ¨è¿™ä¸ªä»»åŠ¡ä¸Šå¹¶ä¸å®Œç¾ã€‚é™¤äº†å—é™äºåœ¨æŸä¸€æ—¶é—´ç‚¹çš„è®­ç»ƒä¿¡æ¯å¤–ï¼Œæ ¹æ®æˆ‘çš„ä¸ªäººç»éªŒï¼ŒLLM åœ¨è¢«è¦æ±‚ç¼–å†™éå¸¸ç»†è‡´çš„ä»£ç æ—¶ï¼Œå¾€å¾€ä¼šå‡ºç°å¹»è§‰ç°è±¡ã€‚**è¯·è®°ä½ï¼ŒLLM
    ä»…èƒ½æ ¹æ®ä½ æä¾›çš„ä¸Šä¸‹æ–‡æ¥å·¥ä½œã€‚** å¦‚æœä½ æœ‰ä¸€ä¸ªæºäºä½ éå¸¸ç‰¹å®šç³»ç»Ÿçš„é”™è¯¯ï¼ŒLLM æ— æ³•äº†è§£ä½ ç³»ç»Ÿçš„ç»†èŠ‚ï¼Œå› æ­¤æœ€ç»ˆä¼šäº§ç”Ÿå¹»è§‰æ€§çš„ç­”æ¡ˆã€‚è¿™å¹¶ä¸æ˜¯è¯´ GenAI
    æ— æ³•åœ¨ç¼–å†™ä»£ç æ—¶æä¾›å¸®åŠ©ï¼Œä½†æˆ‘è®¤ä¸ºå®ƒæ›´åƒæ˜¯ä¸€ä¸ªåŠ©æ‰‹ã€‚
- en: 'Canâ€™t #3: GenAI canâ€™t be certain if another piece of content was created by
    GenAI.'
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'æ— æ³•è§£å†³ #3ï¼šGenAI æ— æ³•ç¡®å®šå¦ä¸€æ®µå†…å®¹æ˜¯å¦ç”± GenAI åˆ›å»ºã€‚'
- en: This is one of those points where researchers have waffled back and forth. In
    fact, OpenAI at one point released a tool to help teachers determine if a piece
    of homework was created using ChatGPT. Eventually, OpenAI retracted this tool,
    and if you understand the underlying math and architecture of these GenAI solutions,
    I would contest that weâ€™re quickly getting to a point where this will literally
    be impossible.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªç ”ç©¶äººå‘˜æ¥å›æ‘‡æ‘†çš„ç‚¹ã€‚å®é™…ä¸Šï¼ŒOpenAI æ›¾ç»å‘å¸ƒè¿‡ä¸€ä¸ªå·¥å…·ï¼Œä»¥å¸®åŠ©æ•™å¸ˆåˆ¤æ–­ä½œä¸šæ˜¯å¦æ˜¯ä½¿ç”¨ ChatGPT åˆ›å»ºçš„ã€‚æœ€ç»ˆï¼ŒOpenAI æ”¶å›äº†è¿™ä¸ªå·¥å…·ï¼Œå¦‚æœä½ äº†è§£è¿™äº›
    GenAI è§£å†³æ–¹æ¡ˆçš„åŸºç¡€æ•°å­¦å’Œæ¶æ„ï¼Œæˆ‘è®¤ä¸ºæˆ‘ä»¬å¾ˆå¿«å°†è¾¾åˆ°ä¸€ä¸ªè¿™ç§äº‹æƒ…å®é™…ä¸Šæ˜¯ä¸å¯èƒ½çš„é˜¶æ®µã€‚
- en: Consider the most advanced LLMs on the market right now, including OpenAIâ€™s
    GPT-4 and Anthropicâ€™s Claude 2\. These LLMs can produce outputs that appear extremely
    human-like, and this is because the underlying architecture is able to assess
    the probabilities between words with a staggering level of precision. Carefully
    treading the line between actual and artificial consciousness, one canâ€™t help
    but wonder if human speech can also be predicted as probabilities between words.
    At that point, the end results of an LLM and a human are probabilistically indistinguishable,
    so no tool would be able to definitively say, â€œThis was made by GenAI; this was
    made by a human.â€
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘ä¸€ä¸‹å½“å‰å¸‚åœºä¸Šæœ€å…ˆè¿›çš„ LLMï¼ŒåŒ…æ‹¬ OpenAI çš„ GPT-4 å’Œ Anthropic çš„ Claude 2ã€‚è¿™äº› LLM å¯ä»¥ç”Ÿæˆçœ‹èµ·æ¥éå¸¸äººæ€§åŒ–çš„è¾“å‡ºï¼Œè¿™æ˜¯å› ä¸ºå…¶åŸºç¡€æ¶æ„èƒ½å¤Ÿä»¥ä»¤äººéœ‡æƒŠçš„ç²¾åº¦è¯„ä¼°å•è¯ä¹‹é—´çš„æ¦‚ç‡ã€‚åœ¨å®é™…ä¸äººå·¥æ„è¯†ä¹‹é—´å°å¿ƒç¿¼ç¿¼åœ°è¸©çº¿æ—¶ï¼Œäººä»¬ä¸ç¦æƒ³çŸ¥é“ï¼Œæ˜¯å¦ä¹Ÿå¯ä»¥å°†äººç±»è¯­è¨€é¢„æµ‹ä¸ºå•è¯ä¹‹é—´çš„æ¦‚ç‡ã€‚åœ¨é‚£ç§æƒ…å†µä¸‹ï¼ŒLLM
    å’Œäººç±»çš„æœ€ç»ˆç»“æœåœ¨æ¦‚ç‡ä¸Šæ˜¯æ— æ³•åŒºåˆ†çš„ï¼Œå› æ­¤æ²¡æœ‰å·¥å…·èƒ½å¤Ÿæ˜ç¡®åœ°è¯´ï¼Œâ€œè¿™æ˜¯ç”± GenAI åˆ¶ä½œçš„ï¼›è¿™æ˜¯ç”±äººç±»åˆ¶ä½œçš„ã€‚â€
- en: '**All that to say, donâ€™t fall for a tool that says it can distinguish what
    is generated by AI versus what is not.** Perhaps with more primitive GenAI solutions,
    it can do some level of assessment there, but we have arguably already surpassed
    that point of distinguishability with LLMs like GPT-4.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ€»ä¹‹ï¼Œä¸è¦è¢«é‚£äº›å£°ç§°å¯ä»¥åŒºåˆ†ç”± AI ç”Ÿæˆçš„å†…å®¹å’Œé AI ç”Ÿæˆçš„å†…å®¹çš„å·¥å…·æ‰€è¿·æƒ‘ã€‚** ä¹Ÿè®¸åœ¨æ›´åŸå§‹çš„ GenAI è§£å†³æ–¹æ¡ˆä¸­ï¼Œå®ƒå¯ä»¥è¿›è¡Œä¸€å®šç¨‹åº¦çš„è¯„ä¼°ï¼Œä½†æˆ‘ä»¬å¯ä»¥è¯´ï¼Œåƒ
    GPT-4 è¿™æ ·çš„ LLM å·²ç»è¶…è¶Šäº†è¿™ç§åŒºåˆ†çš„ç¨‹åº¦ã€‚'
- en: 'Can #4: GenAI can be helped along by other software processes.'
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'å¯ä»¥ #4ï¼šGenAI å¯ä»¥é€šè¿‡å…¶ä»–è½¯ä»¶è¿‡ç¨‹è·å¾—å¸®åŠ©ã€‚'
- en: While most people are more familiar with interacting with LLMs through a user
    interface like ChatGPT, almost all the major GenAI players offer programmatic
    solutions through things like APIs. This means we can engineer GenAI technology
    into new and existing software processes. In fact, most GenAI startups are doing
    precisely this. Specifically, many GenAI startups are using APIs from providers
    like OpenAI or Anthropic as a backend â€œengineâ€ to support their GenAI needs. (Which
    is why you should also be careful who your company chooses to do business with,
    as they are probably interacting with a 4th party behind the scenes!)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å¤§å¤šæ•°äººæ›´ç†Ÿæ‚‰é€šè¿‡åƒ ChatGPT è¿™æ ·çš„ç”¨æˆ·ç•Œé¢ä¸ LLM äº’åŠ¨ï¼Œä½†å‡ ä¹æ‰€æœ‰ä¸»è¦çš„ GenAI å‚ä¸è€…éƒ½é€šè¿‡ API ç­‰æ–¹å¼æä¾›ç¼–ç¨‹è§£å†³æ–¹æ¡ˆã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥å°†
    GenAI æŠ€æœ¯åµŒå…¥åˆ°æ–°çš„å’Œç°æœ‰çš„è½¯ä»¶è¿‡ç¨‹ä¸­ã€‚äº‹å®ä¸Šï¼Œå¤§å¤šæ•° GenAI åˆåˆ›å…¬å¸æ­£åœ¨åšçš„æ­£æ˜¯è¿™ä¸€ç‚¹ã€‚å…·ä½“æ¥è¯´ï¼Œè®¸å¤š GenAI åˆåˆ›å…¬å¸ä½¿ç”¨åƒ OpenAI
    æˆ– Anthropic è¿™æ ·çš„æä¾›å•†çš„ API ä½œä¸ºåç«¯â€œå¼•æ“â€æ¥æ”¯æŒä»–ä»¬çš„ GenAI éœ€æ±‚ã€‚ï¼ˆè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆä½ åº”è¯¥å°å¿ƒä½ çš„å…¬å¸é€‰æ‹©ä¸è°åˆä½œï¼Œå› ä¸ºä»–ä»¬å¯èƒ½åœ¨å¹•åä¸ç¬¬å››æ–¹äº’åŠ¨ï¼ï¼‰
- en: Again, **it canâ€™t be overstated that GenAI should *always* be tempered for hallucinations**.
    While GenAI can produce snippets of code to do things like query specific information
    from a database, I personally would never rely on an LLM for a task like this.
    Because we canâ€™t have 100% certainty that the code would be correct, it would
    be imprudent to rely on GenAI this way. This isnâ€™t to say you should never incorporate
    GenAI into your software systems! There are still great use cases where you can
    leverage GenAI in a programmatic solution in a way that is still beneficial while
    also still being cautious.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡å¼ºè°ƒï¼Œ**GenAI åº”è¯¥*å§‹ç»ˆ*å°å¿ƒå¹»è§‰**ã€‚è™½ç„¶ GenAI å¯ä»¥ç”Ÿæˆä»£ç ç‰‡æ®µä»¥æ‰§è¡Œå¦‚ä»æ•°æ®åº“æŸ¥è¯¢ç‰¹å®šä¿¡æ¯ç­‰ä»»åŠ¡ï¼Œä½†æˆ‘ä¸ªäººç»ä¸ä¼šä¾èµ– LLM æ¥å®Œæˆè¿™æ ·çš„ä»»åŠ¡ã€‚å› ä¸ºæˆ‘ä»¬ä¸èƒ½ç™¾åˆ†ä¹‹ç™¾ç¡®å®šä»£ç çš„æ­£ç¡®æ€§ï¼Œæ‰€ä»¥ä¾èµ–
    GenAI æ˜¯ä¸æ˜æ™ºçš„ã€‚è¿™å¹¶ä¸æ˜¯è¯´ä½ åº”è¯¥å®Œå…¨ä¸å°† GenAI ç»“åˆåˆ°ä½ çš„è½¯ä»¶ç³»ç»Ÿä¸­ï¼ä»ç„¶æœ‰å¾ˆå¥½çš„ç”¨ä¾‹ï¼Œä½ å¯ä»¥ä»¥ä»ç„¶æœ‰ç›Šä¸”ä¿æŒè°¨æ…çš„æ–¹å¼åœ¨ç¼–ç¨‹è§£å†³æ–¹æ¡ˆä¸­åˆ©ç”¨
    GenAIã€‚
- en: 'Canâ€™t #4: GenAI canâ€™t properly cite its own source information.'
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'ä¸èƒ½ #4ï¼šGenAI æ— æ³•æ­£ç¡®å¼•ç”¨å…¶è‡ªèº«çš„ä¿¡æ¯æ¥æºã€‚'
- en: This is a question Iâ€™m asked pretty frequently, and if youâ€™ve been paying close
    attention this far, youâ€™ll understand why this isnâ€™t possible. Though LLMs are
    trained on information at a snapshot in time, itâ€™s not as if it is tying all the
    probabilities between words back to specific sources. What the LLM is only storing
    is referred to what is known as **weights and biases**. Without going too deep
    into the underlying architecture of LLMs, LLMs are essentially comprised of tons
    of mathematical operations, and at the time of training, these weights and biases
    are updated to more closely align to the information it is being trained on. (Actually,
    if I were to deeply explain the architecture of an LLM, youâ€™d be astounded that
    the math is rudimentary enough that it almost seems magical that LLMs can do as
    much as they can!)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ç»å¸¸è¢«é—®åˆ°çš„é—®é¢˜ï¼Œå¦‚æœä½ åˆ°ç°åœ¨ä¸ºæ­¢éƒ½åœ¨è®¤çœŸå¬è®²ï¼Œä½ ä¼šæ˜ç™½ä¸ºä»€ä¹ˆè¿™æ˜¯ä¸å¯èƒ½çš„ã€‚å°½ç®¡LLMæ˜¯åœ¨æŸä¸€æ—¶é—´ç‚¹ä¸Šçš„ä¿¡æ¯ä¸Šè¿›è¡Œè®­ç»ƒçš„ï¼Œä½†å¹¶ä¸æ˜¯è¯´å®ƒå°†æ‰€æœ‰è¯è¯­ä¹‹é—´çš„æ¦‚ç‡è”ç³»åˆ°å…·ä½“çš„æ¥æºã€‚LLMæ‰€å­˜å‚¨çš„ä»…ä»…æ˜¯è¢«ç§°ä¸º**æƒé‡å’Œåå·®**çš„ä¸œè¥¿ã€‚æ— éœ€æ·±å…¥LLMçš„åº•å±‚æ¶æ„ï¼ŒLLMæœ¬è´¨ä¸Šç”±å¤§é‡æ•°å­¦æ“ä½œç»„æˆï¼Œåœ¨è®­ç»ƒæ—¶ï¼Œè¿™äº›æƒé‡å’Œåå·®ä¼šæ›´æ–°ä»¥æ›´è´´è¿‘å®ƒæ‰€è®­ç»ƒçš„ä¿¡æ¯ã€‚ï¼ˆå®é™…ä¸Šï¼Œå¦‚æœæˆ‘è¯¦ç»†è§£é‡ŠLLMçš„æ¶æ„ï¼Œä½ ä¼šæƒŠè®¶äºæ•°å­¦çš„åŸºç¡€åˆ°å‡ ä¹ä»¤äººæ„Ÿåˆ°ç¥å¥‡çš„ç¨‹åº¦ï¼ŒLLMèƒ½å¤Ÿåšå¾—å¦‚æ­¤ä¹‹å¤šï¼ï¼‰
- en: Thatâ€™s all there is to an LLM. **Thereâ€™s no direct tie back to the source information,
    so if you were to ask it to cite its own source, you would receive a hallucination
    at best**. I actually believe specific LLMs like ChatGPT have been fine tuned
    to say that its not possible to reveal its sources, which I would say is a better
    response than a hallucinated one. But itâ€™s not impossible to receive a hallucinated
    response. Thereâ€™s [the infamous scenario](https://www.pymnts.com/artificial-intelligence-2/2023/attorneys-face-sanctions-after-citing-information-hallucinated-by-chatgpt/)
    where a lawyer used an LLM to cite a source in a legal case, and it was discovered
    that the cited source was hallucinated and ultimately fake. Be careful you donâ€™t
    also fall into this same trap!
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯LLMçš„å…¨éƒ¨å†…å®¹ã€‚**æ²¡æœ‰ç›´æ¥è”ç³»åˆ°æºä¿¡æ¯ï¼Œå› æ­¤å¦‚æœä½ è¦æ±‚å®ƒå¼•ç”¨è‡ªå·±çš„æ¥æºï¼Œä½ æœ€å¤šåªèƒ½å¾—åˆ°è™šå‡çš„å›ç­”**ã€‚æˆ‘å®é™…ä¸Šç›¸ä¿¡åƒChatGPTè¿™æ ·çš„ç‰¹å®šLLMå·²ç»è¢«å¾®è°ƒï¼Œä»¥è¡¨ç¤ºä¸å¯èƒ½æ­ç¤ºå…¶æ¥æºï¼Œæˆ‘è®¤ä¸ºè¿™æ¯”è™šå‡çš„å›ç­”è¦å¥½ã€‚ä½†æ˜¯ï¼Œè·å¾—è™šå‡å›ç­”å¹¶éä¸å¯èƒ½ã€‚æœ‰[é‚£ä¸ªè‡­åæ˜­è‘—çš„æ¡ˆä¾‹](https://www.pymnts.com/artificial-intelligence-2/2023/attorneys-face-sanctions-after-citing-information-hallucinated-by-chatgpt/)ï¼Œä¸€åå¾‹å¸ˆä½¿ç”¨LLMåœ¨æ³•å¾‹æ¡ˆä»¶ä¸­å¼•ç”¨äº†ä¸€ä¸ªæ¥æºï¼Œç»“æœå‘ç°è¯¥æ¥æºæ˜¯è™šå‡çš„ï¼Œæœ€ç»ˆæ˜¯å‡çš„ã€‚å°å¿ƒä¸è¦é™·å…¥åŒæ ·çš„é™·é˜±ï¼
- en: 'Can #5: GenAI can be a fantastic way to augment your own knowledge.'
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¯ä»¥#5ï¼šGenAIå¯ä»¥æå¤§åœ°å¢å¼ºä½ çš„çŸ¥è¯†ã€‚
- en: Similar to the point where GenAI can be a good assistant at writing code, GenAI
    can also simply be a good assistant at any knowledge task. I personally use LLMs
    like ChatGPT as a sort of â€œsearch engineâ€ for general knowledge questions. For
    example, it is excellent at providing definitions to words, and it is great to
    receive more elaborative answers as you follow up with additional questions. Itâ€™s
    like interacting with a very knowledgeable friend. While internet search engines
    can provide the most up-to-date and relevant information, the back-and-forth of
    a conversation flow is unmatched by a barebones search engine.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸GenAIå¯ä»¥ä½œä¸ºç¼–å†™ä»£ç çš„è‰¯å¥½åŠ©æ‰‹çš„è§‚ç‚¹ç±»ä¼¼ï¼ŒGenAIä¹Ÿå¯ä»¥æˆä¸ºä»»ä½•çŸ¥è¯†ä»»åŠ¡çš„å¥½åŠ©æ‰‹ã€‚æˆ‘ä¸ªäººå°†LLMï¼ˆå¦‚ChatGPTï¼‰ç”¨ä½œä¸€ç§â€œæœç´¢å¼•æ“â€æ¥å›ç­”ä¸€èˆ¬çŸ¥è¯†é—®é¢˜ã€‚ä¾‹å¦‚ï¼Œå®ƒåœ¨æä¾›è¯æ±‡å®šä¹‰æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå¹¶ä¸”åœ¨ä½ ç»§ç»­æå‡ºé¢å¤–é—®é¢˜æ—¶ï¼Œå®ƒèƒ½ç»™å‡ºæ›´è¯¦å°½çš„å›ç­”ã€‚å°±åƒå’Œä¸€ä¸ªéå¸¸æœ‰çŸ¥è¯†çš„æœ‹å‹äº’åŠ¨ä¸€æ ·ã€‚è™½ç„¶äº’è”ç½‘æœç´¢å¼•æ“å¯ä»¥æä¾›æœ€æ–°å’Œæœ€ç›¸å…³çš„ä¿¡æ¯ï¼Œä½†å¯¹è¯çš„äº’åŠ¨æµç¨‹æ˜¯åŸºæœ¬æœç´¢å¼•æ“æ— æ³•æ¯”æ‹Ÿçš„ã€‚
- en: Of course, I shouldnâ€™t have to remind you by this point to be careful for hallucinations.
    While LLMs might be more helpful about historical events and locations like Ancient
    Rome, youâ€™ll certainly receive a hallucinated answer if you asked it what todayâ€™s
    weather is. If it does provide back a correct answer, this would again be because
    the LLM is being augmented in a RAG manner, NOT because the LLM was able to derive
    that information itself. Also, beware of using LLMs for math problems specifically.
    Remember, these LLMs are trained to look for probabilities between words, so thereâ€™s
    not any mathematical computation being done when a math problem is given to it.
    In recent months, popular LLMs like ChatGPT have been seemingly augmented to handle
    math problems better, but it is unclear how they are doing this. In any case,
    I would still try to avoid doing complex math problems with an LLM.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œæˆ‘ä¸åº”è¯¥å†æé†’ä½ æ³¨æ„å¹»è§‰ã€‚è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯èƒ½åœ¨å†å²äº‹ä»¶å’Œåœ°ç‚¹å¦‚å¤ç½—é©¬æ–¹é¢æ›´ä¸ºæœ‰ç”¨ï¼Œä½†å¦‚æœä½ é—®å®ƒä»Šå¤©çš„å¤©æ°”ï¼Œå®ƒè‚¯å®šä¼šç»™å‡ºä¸€ä¸ªè™šå‡çš„ç­”æ¡ˆã€‚å¦‚æœå®ƒæä¾›äº†æ­£ç¡®çš„ç­”æ¡ˆï¼Œé‚£æ˜¯å› ä¸ºLLMä»¥RAGæ–¹å¼è¢«å¢å¼ºï¼Œè€Œä¸æ˜¯å› ä¸ºLLMèƒ½è‡ªè¡Œå¾—å‡ºè¿™äº›ä¿¡æ¯ã€‚å¦å¤–ï¼Œç‰¹åˆ«è¦å°å¿ƒä½¿ç”¨LLMè§£å†³æ•°å­¦é—®é¢˜ã€‚è®°ä½ï¼Œè¿™äº›LLMæ˜¯é€šè¿‡å¯»æ‰¾å•è¯ä¹‹é—´çš„æ¦‚ç‡æ¥è¿›è¡Œè®­ç»ƒçš„ï¼Œæ‰€ä»¥åœ¨é¢å¯¹æ•°å­¦é—®é¢˜æ—¶ï¼Œå¹¶æ²¡æœ‰è¿›è¡Œå®é™…çš„æ•°å­¦è®¡ç®—ã€‚æœ€è¿‘å‡ ä¸ªæœˆï¼ŒåƒChatGPTè¿™æ ·çš„æµè¡ŒLLMä¼¼ä¹è¢«å¢å¼ºä»¥æ›´å¥½åœ°å¤„ç†æ•°å­¦é—®é¢˜ï¼Œä½†ä¸æ¸…æ¥šå®ƒä»¬æ˜¯å¦‚ä½•åšåˆ°çš„ã€‚åœ¨ä»»ä½•æƒ…å†µä¸‹ï¼Œæˆ‘ä»ç„¶å»ºè®®å°½é‡é¿å…ç”¨LLMè§£å†³å¤æ‚çš„æ•°å­¦é—®é¢˜ã€‚
- en: 'Canâ€™t #5: GenAI canâ€™t take your job. (â€¦Yet?)'
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'æ— æ³•åšåˆ° #5ï¼šGenAIæ— æ³•å–ä»£ä½ çš„å·¥ä½œã€‚ï¼ˆâ€¦è¿˜æ²¡æœ‰ï¼Ÿï¼‰'
- en: 'Ah yes, the big question on everybodyâ€™s mind! Actually, I guess if Iâ€™m being
    totally honest, GenAI can be used to reduce a human workforce, but weâ€™re definitely
    not at the point where itâ€™s going to eliminate most peopleâ€™s jobs. If you paid
    close attention to the sections in this post around information retrieval, youâ€™ll
    recognize GenAIâ€™s biggest â€œflawâ€ preventing it from taking everybodyâ€™s jobs: **GenAI
    has no way to proactively learn for itself**. GenAI canâ€™t talk to your CEO and
    tease out whatâ€™s in their head. GenAI canâ€™t jump in your skull to understand all
    the little nuances of the website youâ€™ve dreamed in your imagination. In this
    way, I consider GenAI to be like a totally naive genius: you can get it to do
    a lot, but you have to be upfront and extremely specific with it to get the most
    ideal results.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å•Šï¼Œæ˜¯çš„ï¼Œå¤§å®¶æœ€å…³å¿ƒçš„é—®é¢˜ï¼å…¶å®ï¼Œå¦‚æœæˆ‘å®Œå…¨è¯šå®çš„è¯ï¼ŒGenAIå¯ä»¥ç”¨æ¥å‡å°‘äººåŠ›ï¼Œä½†æˆ‘ä»¬ç»å¯¹è¿˜æœªè¾¾åˆ°å®ƒä¼šå–ä»£å¤§å¤šæ•°äººå·¥ä½œçš„åœ°æ­¥ã€‚å¦‚æœä½ ä»”ç»†é˜…è¯»äº†æœ¬å¸–å…³äºä¿¡æ¯æ£€ç´¢çš„éƒ¨åˆ†ï¼Œä½ ä¼šå‘ç°GenAIæ— æ³•å–ä»£æ‰€æœ‰äººçš„å·¥ä½œçš„æœ€å¤§â€œç¼ºé™·â€ï¼š**GenAIæ— æ³•ä¸»åŠ¨è‡ªå­¦**ã€‚GenAIæ— æ³•ä¸æ‚¨çš„CEOäº¤è°ˆå¹¶äº†è§£ä»–ä»¬è„‘ä¸­çš„æƒ³æ³•ã€‚GenAIæ— æ³•è¿›å…¥ä½ çš„è„‘è¢‹ï¼Œç†è§£ä½ åœ¨æƒ³è±¡ä¸­æ„å»ºçš„ç½‘ç«™çš„æ‰€æœ‰ç»†å¾®å·®åˆ«ã€‚ä»¥è¿™ç§æ–¹å¼ï¼Œæˆ‘è®¤ä¸ºGenAIå°±åƒä¸€ä¸ªå®Œå…¨å¤©çœŸçš„å¤©æ‰ï¼šä½ å¯ä»¥è®©å®ƒåšå¾ˆå¤šäº‹ï¼Œä½†ä½ å¿…é¡»ç›´æ¥è€Œæå…¶å…·ä½“åœ°ä¸å®ƒæ²Ÿé€šï¼Œä»¥è·å¾—æœ€ç†æƒ³çš„ç»“æœã€‚
- en: 'The natural follow up question is: will AI ever get to the point where it can
    do these things? We refer to this next level of superintelligence as **artificial
    general intelligence (AGI)**, and it is why AI safety advocates are raising concern
    with AI progress. The goal is to safely align human interests with AI interests.
    Without dwelling on this topic further, the point is we are not at that point
    today, and it really is unknown at point we will hit the singularity â€” the point
    at which we do reach AGI. If you understand the history of AI research, youâ€™ll
    quickly learn humanity isnâ€™t very good at predicting this point. ğŸ˜‚'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªç„¶çš„åç»­é—®é¢˜æ˜¯ï¼šAIæ˜¯å¦ä¼šè¾¾åˆ°èƒ½å¤Ÿå®Œæˆè¿™äº›äº‹æƒ…çš„ç¨‹åº¦ï¼Ÿæˆ‘ä»¬å°†è¿™ä¸€è¶…çº§æ™ºèƒ½çš„ä¸‹ä¸€ä¸ªå±‚æ¬¡ç§°ä¸º**äººå·¥é€šç”¨æ™ºèƒ½ï¼ˆAGIï¼‰**ï¼Œè¿™ä¹Ÿæ˜¯AIå®‰å…¨å€¡å¯¼è€…å¯¹AIè¿›å±•è¡¨ç¤ºå…³æ³¨çš„åŸå› ã€‚ç›®æ ‡æ˜¯å®‰å…¨åœ°ä½¿äººç±»åˆ©ç›Šä¸AIåˆ©ç›Šå¯¹é½ã€‚ä¸å†æ·±å…¥è®¨è®ºè¿™ä¸€è¯é¢˜ï¼Œé‡ç‚¹æ˜¯æˆ‘ä»¬ä»Šå¤©è¿˜æœªè¾¾åˆ°è¿™ä¸€ç‚¹ï¼Œä¹ŸçœŸçš„ä¸æ¸…æ¥šæˆ‘ä»¬ä½•æ—¶ä¼šåˆ°è¾¾å¥‡ç‚¹â€”â€”å³æˆ‘ä»¬è¾¾åˆ°AGIçš„é‚£ä¸€ç‚¹ã€‚å¦‚æœä½ äº†è§£AIç ”ç©¶çš„å†å²ï¼Œä½ ä¼šå¾ˆå¿«å‘ç°äººç±»åœ¨é¢„æµ‹è¿™ä¸€ç‚¹ä¸Šå¹¶ä¸æ“…é•¿ã€‚
    ğŸ˜‚
- en: 'I hope you walk away from this post with a much better idea of what GenAI may
    or may not be good for. It is a truly astounding technology, but itâ€™s not good
    for everything. One final point I should also highlight: **GenAI is not the only
    AI**. GenAI in its current form has been around as early as 2017, but weâ€™ve had
    many other forms of AI that can still suitably get the job done. Just as you wouldnâ€™t
    rent a car to walk ten feet, you should always attempt to rightsize the solution
    to meet the business need. GenAI is just another tool in our toolbox, albeit a
    very cool tool! ğŸ˜ƒ'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¸Œæœ›ä½ èƒ½ä»è¿™ç¯‡æ–‡ç« ä¸­æ›´å¥½åœ°äº†è§£GenAIå¯èƒ½çš„ä¼˜ç¼ºç‚¹ã€‚è¿™æ˜¯ä¸€é¡¹çœŸæ­£ä»¤äººæƒŠå¹çš„æŠ€æœ¯ï¼Œä½†å¹¶ä¸æ˜¯é€‚ç”¨äºæ‰€æœ‰æƒ…å†µã€‚æˆ‘è¿˜è¦å¼ºè°ƒçš„ä¸€ç‚¹æ˜¯ï¼š**GenAIå¹¶ä¸æ˜¯å”¯ä¸€çš„AI**ã€‚GenAIçš„å½“å‰å½¢å¼æœ€æ—©å‡ºç°åœ¨2017å¹´ï¼Œä½†æˆ‘ä»¬è¿˜æœ‰è®¸å¤šå…¶ä»–å½¢å¼çš„AIä¹Ÿèƒ½æœ‰æ•ˆå®Œæˆä»»åŠ¡ã€‚å°±åƒä½ ä¸ä¼šç§Ÿè½¦èµ°åè‹±å°ºä¸€æ ·ï¼Œä½ åº”è¯¥å§‹ç»ˆå°è¯•è°ƒæ•´è§£å†³æ–¹æ¡ˆä»¥æ»¡è¶³ä¸šåŠ¡éœ€æ±‚ã€‚GenAIåªæ˜¯æˆ‘ä»¬å·¥å…·ç®±ä¸­çš„å¦ä¸€ä¸ªå·¥å…·ï¼Œå°½ç®¡æ˜¯ä¸€ä¸ªéå¸¸é…·çš„å·¥å…·ï¼
    ğŸ˜ƒ
