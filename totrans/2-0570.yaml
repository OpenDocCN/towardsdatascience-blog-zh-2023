- en: Cook your First U-Net in PyTorch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 PyTorch 中制作你的第一个 U-Net
- en: 原文：[https://towardsdatascience.com/cook-your-first-u-net-in-pytorch-b3297a844cf3](https://towardsdatascience.com/cook-your-first-u-net-in-pytorch-b3297a844cf3)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/cook-your-first-u-net-in-pytorch-b3297a844cf3](https://towardsdatascience.com/cook-your-first-u-net-in-pytorch-b3297a844cf3)
- en: A magic recipe to empower your image segmentation projects
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一份提升你图像分割项目的魔法配方
- en: '[](https://mostafawael.medium.com/?source=post_page-----b3297a844cf3--------------------------------)[![Mostafa
    Wael](../Images/bf0a052c6446eb3d133e67453ae38143.png)](https://mostafawael.medium.com/?source=post_page-----b3297a844cf3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b3297a844cf3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b3297a844cf3--------------------------------)
    [Mostafa Wael](https://mostafawael.medium.com/?source=post_page-----b3297a844cf3--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://mostafawael.medium.com/?source=post_page-----b3297a844cf3--------------------------------)[![Mostafa
    Wael](../Images/bf0a052c6446eb3d133e67453ae38143.png)](https://mostafawael.medium.com/?source=post_page-----b3297a844cf3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b3297a844cf3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b3297a844cf3--------------------------------)
    [Mostafa Wael](https://mostafawael.medium.com/?source=post_page-----b3297a844cf3--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b3297a844cf3--------------------------------)
    ·6 min read·May 12, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b3297a844cf3--------------------------------)
    ·6 分钟阅读·2023年5月12日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c1de747dfac6df8728f9837b2c6bed9d.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c1de747dfac6df8728f9837b2c6bed9d.png)'
- en: Photo by [Stefan C. Asafti](https://unsplash.com/@stefanasafti?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/x5jilo3ck3o?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Stefan C. Asafti](https://unsplash.com/@stefanasafti?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    在 [Unsplash](https://unsplash.com/photos/x5jilo3ck3o?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    上提供
- en: 'U-Net is a deep learning architecture used for semantic segmentation tasks
    in image analysis. It was introduced by Olaf Ronneberger, Philipp Fischer, and
    Thomas Brox in a paper titled “[U-Net: Convolutional Networks for Biomedical Image
    Segmentation](https://papers.labml.ai/paper/2e48c3ffdc8311eba3db37f65e372566)”.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 'U-Net 是一种用于图像分析中语义分割任务的深度学习架构。它由 Olaf Ronneberger、Philipp Fischer 和 Thomas
    Brox 在题为 “[U-Net: Convolutional Networks for Biomedical Image Segmentation](https://papers.labml.ai/paper/2e48c3ffdc8311eba3db37f65e372566)”
    的论文中提出。'
- en: It is particularly effective for biomedical image segmentation tasks because
    it can handle images of arbitrary size and produces smooth, high-quality segmentation
    masks with sharp object boundaries. It has since been widely adopted in many other
    image segmentation tasks, such as in satellite and aerial imagery analysis, as
    well as in natural image segmentation.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 它对生物医学图像分割任务特别有效，因为它能够处理任意大小的图像，并生成平滑、高质量的分割掩膜和清晰的物体边界。此后，它已广泛应用于许多其他图像分割任务，如卫星和航拍图像分析，以及自然图像分割。
- en: In this tutorial, we will learn more about U-Net and how it works, and we will
    cook our own implementation recipe using PyTorch. So, let’s go!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将深入了解 U-Net 及其工作原理，并用 PyTorch 制作我们自己的实现配方。那么，开始吧！
- en: How does it work?
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的？
- en: 'The U-Net architecture consists of two parts: an encoder and a decoder.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: U-Net 架构由两部分组成：编码器和解码器。
- en: '![](../Images/302f2b53c15c476ff36507d93dc9f5e3.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/302f2b53c15c476ff36507d93dc9f5e3.png)'
- en: '[U-Net: Convolutional Networks for Biomedical Image Segmentation](https://paperswithcode.com/paper/u-net-convolutional-networks-for-biomedical)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[U-Net: Convolutional Networks for Biomedical Image Segmentation](https://paperswithcode.com/paper/u-net-convolutional-networks-for-biomedical)'
- en: Encoder(Contraction Path)
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编码器（收缩路径）
- en: The encoder is a series of **convolutional** and **pooling** layers that progressively
    **downsample** the input image to extract features at multiple scales.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器是一系列**卷积**和**池化**层，这些层逐步**下采样**输入图像，以在多个尺度上提取特征。
- en: In the Encoder, the size of the image is gradually reduced while the depth gradually
    increases. This basically means the network **learns the “WHAT”** information
    in the image, however, it has **lost the “WHERE”** information.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在编码器中，图像的大小逐渐减少，而深度逐渐增加。这基本上意味着网络**学习了图像中的“WHAT”**信息，但**丧失了“WHERE”**信息。
- en: Decoder(Expansion Path)
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解码器（扩展路径）
- en: The decoder consists of a series of **convolutional** and **upsampling** layers
    that upsample the feature maps to the original input image size while also incorporating
    the high-resolution features from the encoder. This allows the decoder to produce
    segmentation masks that have the same size as the original input image.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器由一系列 **卷积** 和 **上采样** 层组成，这些层将特征图上采样到原始输入图像的大小，同时结合来自编码器的高分辨率特征。这使得解码器能够生成与原始输入图像大小相同的分割掩膜。
- en: You can learn more about the upsampling and the transposed convolution from
    this great [article](/transposed-convolution-demystified-84ca81b4baba).
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你可以从这篇精彩的 [文章](/transposed-convolution-demystified-84ca81b4baba) 中了解更多关于上采样和转置卷积的内容。
- en: In the Decoder, the size of the image gradually increases while the depth gradually
    decreases. This basically means the network **learns the “WHERE”** information
    in the image, by gradually applying up-sampling.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在解码器中，图像的大小逐渐增加，而深度逐渐减少。这基本上意味着网络通过逐渐应用上采样来 **学习图像中的“WHERE”** 信息。
- en: Final Layer
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最终层
- en: At the final layer, a 1x1 convolution is used to map each 64-component feature
    vector to the desired number of classes.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在最终层，使用1x1卷积将每个64维特征向量映射到所需的类别数。
- en: Our cooking recipe!
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们的烹饪食谱！
- en: We will do a very straightforward implementation, it will be good to put the
    above image in front of you while coding.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将进行一个非常直接的实现，编码时最好将上述图片放在你面前。
- en: Imports
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导入
- en: First, the necessary modules are imported from the `torch` and `torchvision`
    packages, including the `nn` module for building neural networks and the pre-trained
    models provided in `torchvision.models`. The `relu` function is also imported
    from `torch.nn.functional`.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，从 `torch` 和 `torchvision` 包中导入必要的模块，包括用于构建神经网络的 `nn` 模块和 `torchvision.models`
    提供的预训练模型。 `relu` 函数也从 `torch.nn.functional` 导入。
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: UNet Class
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: UNet 类
- en: Then, a custom class `UNet` is defined as a subclass of `nn.Module`. The `__init__`
    method initializes the architecture of the U-Net by defining the layers for both
    the encoder and decoder parts of the network. The argument `n_class` specifies
    the number of classes for the segmentation task.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，定义了一个自定义类 `UNet`，作为 `nn.Module` 的子类。 `__init__` 方法通过定义编码器和解码器部分的层来初始化U-Net的架构。参数
    `n_class` 指定了分割任务的类别数。
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In the U-Net paper they used 0 padding and applied post-processing teachiques
    to restore the original size of the image, however here, we uses 1 padding so
    that final feature map is not cropped and to eliminate any need to apply post-processing
    to our output image.
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在U-Net论文中，他们使用了0填充，并应用了后处理技术以恢复图像的原始大小，而在这里，我们使用1填充，这样最终的特征图不会被裁剪，也不需要对输出图像进行后处理。
- en: Forward Method
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前向方法
- en: The `forward` method specifies how the input is processed through the network.
    The input image is first passed through the encoder layers to extract the features.
    Then, the decoder layers are used to upsample the features to the original image
    size while concatenating the corresponding encoder feature maps. Finally, the
    output layer uses a 1x1 convolutional layer to map the features to the desired
    number of output classes.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`forward` 方法指定了输入如何通过网络进行处理。输入图像首先通过编码器层提取特征。然后，解码器层用于将特征上采样到原始图像大小，同时连接相应的编码器特征图。最后，输出层使用1x1卷积层将特征映射到所需的输出类别数。'
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '*Don’t forget to hit the* ***Clap*** *and* ***Follow*** *buttons to help me
    write more articles like this.*'
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*不要忘记点击* ***Clap*** *和* ***Follow*** *按钮，以帮助我写更多这样的文章。*'
- en: That it is!
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 就这样！
- en: Congratulations on successfully implementing your first U-Net model in PyTorch!
    By following this recipe, you have gained the knowledge to implement U-Net and
    can now apply it to any image segmentation problem you may encounter in the future.
    However, verifying the sizes and channel numbers is important to ensure compatibility.
    The U-Net architecture is a powerful tool in your arsenal that can be applied
    to various tasks, including medical imaging and autonomous driving. So, go ahead
    and grab any image segmentation dataset from the internet and start testing your
    code!
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你成功实现了第一个 PyTorch 中的 U-Net 模型！通过遵循这个食谱，你已经掌握了实现 U-Net 的知识，现在可以将其应用于你未来可能遇到的任何图像分割问题。然而，验证尺寸和通道数以确保兼容性是重要的。U-Net
    架构是你工具库中的一个强大工具，可以应用于各种任务，包括医学成像和自动驾驶。所以，快去从互联网上获取任何图像分割数据集，并开始测试你的代码吧！
- en: For convenience, I have added a [simple test script in this repository](https://github.com/Mostafa-wael/U-Net-in-PyTorch/blob/main/test.py).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便，我在[这个仓库中添加了一个简单的测试脚本](https://github.com/Mostafa-wael/U-Net-in-PyTorch/blob/main/test.py)。
- en: The script generates random images and masks and trains the U-net model to segment
    the images. It has a function called `generate_random_data()` that creates input
    images and their corresponding masks with geometric shapes like triangles, circles,
    squares, and crosses. The U-net model is trained using these random images and
    masks. The trained model is then tested on new random images and the segmentation
    results are plotted using the `plot_img_array()` function. The script uses PyTorch
    to train the U-net model and also uses various functions to add shapes to the
    input images and masks.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本生成随机图像和掩膜，并训练U-net模型进行图像分割。它有一个名为`generate_random_data()`的函数，创建具有几何形状（如三角形、圆形、正方形和十字形）的输入图像及其对应的掩膜。U-net模型使用这些随机图像和掩膜进行训练。训练好的模型随后在新的随机图像上进行测试，分割结果使用`plot_img_array()`函数绘制。该脚本使用PyTorch来训练U-net模型，并使用各种函数向输入图像和掩膜中添加形状。
- en: 'consider downloading it and running the tests using this snippet:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 请考虑下载并使用以下代码片段运行测试：
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/535b89fef06b03ab927b6ff48e175ed2.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/535b89fef06b03ab927b6ff48e175ed2.png)'
- en: Expected Test Output(By me).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 预期的测试输出（由我提供）。
- en: Final Thoughts
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后的想法
- en: In conclusion, the U-Net architecture has become incredibly popular in the computer
    vision community due to its effectiveness in solving various image segmentation
    tasks. Its unique design, which includes a contracting path followed by an expanding
    path, allows it to capture both local and global features of an image while preserving
    spatial information.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，U-Net架构因其在解决各种图像分割任务中的有效性而在计算机视觉社区中变得非常流行。它独特的设计，包括一个收缩路径和一个扩展路径，使其能够同时捕捉图像的局部和全局特征，同时保留空间信息。
- en: Moreover, the flexibility of the U-Net architecture makes it possible to modify
    and improve the network to suit specific needs. Researchers have proposed various
    modifications to the original U-Net architecture, including changing the convolutional
    layers, incorporating attention mechanisms, and adding skip connections, among
    others. These modifications have resulted in improved performance and better segmentation
    results in various applications.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，U-Net架构的灵活性使得修改和改进网络以适应特定需求成为可能。研究人员提出了对原始U-Net架构的各种修改，包括改变卷积层、引入注意力机制以及添加跳跃连接等。这些修改在各种应用中提高了性能和分割结果。
- en: Overall, the U-Net architecture has proven to be a reliable and versatile solution
    for image segmentation tasks. As computer vision continues to advance, it’s likely
    that we’ll see further innovations and modifications to the U-Net architecture
    to improve its performance and make it even more effective in solving real-world
    problems.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，U-Net架构已被证明是一个可靠且多功能的图像分割任务解决方案。随着计算机视觉的不断进步，我们可能会看到U-Net架构的进一步创新和改进，以提升其性能，使其在解决现实世界问题时更加有效。
- en: Don’t hesitate to share your thoughts with me!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 不要犹豫与我分享你的想法！
- en: '*I don’t receive Medium stipends as Egypt isn’t supported. If you enjoy my
    content, please consider* [*buying me a coffee*](https://ko-fi.com/mostafawael#)
    *☕ to encourage more posts. Thank you!*'
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*我没有获得Medium的补助，因为埃及不支持。如果你喜欢我的内容，请考虑* [*请我喝咖啡*](https://ko-fi.com/mostafawael#)
    *☕ 来鼓励我发表更多帖子。谢谢！*'
