- en: How to Choose the Best Evaluation Metric for Regression Problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-choose-the-best-evaluation-metric-for-regression-problems-b9f2e60e25ef](https://towardsdatascience.com/how-to-choose-the-best-evaluation-metric-for-regression-problems-b9f2e60e25ef)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A comprehensive guide covering the most commonly used evaluation metrics used
    in regression and their utility in different scenarios
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://thomasdorfer.medium.com/?source=post_page-----b9f2e60e25ef--------------------------------)[![Thomas
    A Dorfer](../Images/9258a1735cee805f1d9b02e2adf01096.png)](https://thomasdorfer.medium.com/?source=post_page-----b9f2e60e25ef--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b9f2e60e25ef--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b9f2e60e25ef--------------------------------)
    [Thomas A Dorfer](https://thomasdorfer.medium.com/?source=post_page-----b9f2e60e25ef--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b9f2e60e25ef--------------------------------)
    ·8 min read·Apr 24, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4b48546699f3d72533764bcbc8a23988.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the Author.
  prefs: []
  type: TYPE_NORMAL
- en: Before building a regression model, it’s worth taking a moment to carefully
    think about how to evaluate it. A variety of factors will fall into that decision,
    including whether or not large errors should be punished more than small ones,
    or how comprehensible and intuitive the metric needs to be for stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: This article will cover the most commonly used evaluation metrics for regression
    problems. For each metric, we’ll go through an example use case as well, which
    will provide you with the information necessary to help you choose among them.
  prefs: []
  type: TYPE_NORMAL
- en: Regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A regression problem is a supervised machine learning problem and characterized
    by the prediction of a continuous numerical output variable based on one or more
    input variables.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine a regression model that aims to predict housing prices based on various
    features such as the number of bedrooms and bathrooms, square footage, location,
    and so on. Since we have various evaluation metrics at our disposal, it matters
    that we choose the one that aligns best with our goals.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, if we choose a metric that considerably amplifies — and thus punishes
    — large errors, it could mean that even a single such large error can greatly
    increase the overall error measure of our model, making it seem like the model
    is performing poorly. However, a single large error may not be as important as
    many smaller errors. Therefore, choosing a metric that places equal weight on
    all errors may be more appropriate if the goal is to accurately predict housing
    prices, rather than minimizing the overall error.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now explore some commonly used evaluation metrics and discuss their utility
    in various scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation Metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Mean Absolute Error (MAE)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The mean absolute error, or MAE, is a popular metric for regression problems
    because the units of the error actually match the ones of the target variable.
    For instance, if the target variable is in *$USD*, the error is also in *$USD*.
  prefs: []
  type: TYPE_NORMAL
- en: The ***mean absolute error*** measures the average absolute difference between
    the predicted and actual values.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'It is calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b9c67dd1e22cbb75ec8906ff5dc8023f.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *y* represents the actual value, *ŷ* represents the predicted value, and
    *n* corresponds to the number of observations in the data.
  prefs: []
  type: TYPE_NORMAL
- en: It is a particularly useful metric when our goal is to evaluate the performance
    of a regression model in a way that places equal weights on all errors, regardless
    of their magnitude.
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate this, let’s take a look at the table below, which shows some contrived
    data on actual and predicted values as well as the corresponding MAE. Note that
    the absolute error is always positive, regardless of whether the predicted value
    is higher or lower than the actual value. Moreover, in order to emphasize the
    linear growth of the absolute error, I fixed the actual value at 200 and linearly
    increased the error of the predictions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/403732d2310c532279c984f2338c15aa.png)'
  prefs: []
  type: TYPE_IMG
- en: Table by the Author.
  prefs: []
  type: TYPE_NORMAL
- en: Based on this data, we can calculate the MAE using the above formula and we
    would obtain a result of $40.
  prefs: []
  type: TYPE_NORMAL
- en: The MAE is a very interpretable metric for providing an understanding of how
    far off the predictions are from the actual values. In addition, it is more robust
    to outliers as it doesn’t amplify large errors by, say, squaring them. This is
    particularly useful in situations where large errors are not significantly more
    important than smaller ones.
  prefs: []
  type: TYPE_NORMAL
- en: '*Example:* This was already hinted at above, but the MAE can be an intuitive
    metric for predicting housing prices. By measuring the mean absolute difference
    between actual and predicted values, it provides a more relatable metric that
    allows us to understand how much the predictions deviate on average. Other examples
    include predicting student exam scores, demand forecasting for products, or predicting
    the length of patients’ hospital stays.'
  prefs: []
  type: TYPE_NORMAL
- en: Mean Squared Error (MSE)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The mean squared error, or MSE, is frequently used when the goal is to penalize
    larger errors more than smaller ones.
  prefs: []
  type: TYPE_NORMAL
- en: The ***mean squared error*** measures the average squared difference between
    the predicted and actual values.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'It is calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/517262c15724a591dd5b781d4e371f28.png)'
  prefs: []
  type: TYPE_IMG
- en: It is commonly used when the goal is to emphasize larger errors as the MSE squares
    the difference between actual and predicted values. To illustrate this further,
    take a look at the actual and predicted values below and observe the accelerated
    growth of the squared error with increasing deviations of the predictions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e8c4eb34a34b733b8182bdcb4080e42f.png)'
  prefs: []
  type: TYPE_IMG
- en: Table by the Author.
  prefs: []
  type: TYPE_NORMAL
- en: The MSE here would be 2400 *$ squared* — a rather unintuitive unit that can
    often lead to confusion among stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: Compared to the absolute error, which increases linearly with increasing deviations,
    the squared error increases non-linearly and much more rapidly, thus placing a
    higher weight on larger errors.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a40978162aa579fb9a372654d275985d.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the Author.
  prefs: []
  type: TYPE_NORMAL
- en: '*Example:* The MSE can be applied to stock price prediction tasks with the
    goal of minimizing the overall prediction error. In this case, interpretability
    may not be as important as accuracy. Furthermore, the fact that it penalizes large
    errors more is critical here, as these can often result in significant financial
    losses.'
  prefs: []
  type: TYPE_NORMAL
- en: Root Mean Squared Error (RMSE)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The root mean squared error, or RMSE, like the MSE, is a popular metric when
    the goal is to penalize larger errors more than smaller ones. In addition, it’s
    a more intuitive metric because its unit is the same as that of the target variable.
    In other words, if the target variable is in *$USD*, the RMSE is in *$USD* as
    well.
  prefs: []
  type: TYPE_NORMAL
- en: The ***root mean squared error*** measures the square root of the average squared
    difference between the predicted and actual values. More simply, it is the square
    root of the MSE.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'It is calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f129028f0cb3b2a5a477dee3be36c9ea.png)'
  prefs: []
  type: TYPE_IMG
- en: Based on the previous section, we know that the MSE of our sample data is 2400
    *$ squared*. Therefore, the RMSE is simply the square root of that, which is $48.99.
  prefs: []
  type: TYPE_NORMAL
- en: '*Example:* The RMSE is often applied in weather forecasting, where the target
    variable is typically some measure of temperature or precipitation. In this scenario,
    placing more weight on larger errors is beneficial because it emphasizes the importance
    of accurately predicting extreme weather events, which can have a great impact
    not only on our decision of whether to bring an umbrella or not, but also on infrastructure,
    transportation, and agriculture. Moreover, obtaining an error measure in the same
    unit as the target variable leads to a more intuitive understanding of the model’s
    accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: R-Squared (R2)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The R-squared metric, or R2, provides an indication of how well a regression
    model fits the data.
  prefs: []
  type: TYPE_NORMAL
- en: '***R-squared***, also known as the ***coefficient of determination***, represents
    the proportion of the variance in the target variable that is explained by the
    predictors.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'It is calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/061150f991fcaa29ca7bfd16042ee6a1.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *SSR* stands for the sum of squared residuals, *SST* stands for total
    sum of squares, and ȳ represents the mean value of the sample.
  prefs: []
  type: TYPE_NORMAL
- en: The metric ranges from 0 to 1, whereby 0 indicates that the model explains none
    of the variance in the target (dependent) variable, whereas 1 indicates that the
    model explains all of its variance. Thus, we can conclude that the higher the
    R-squared metric, the better the model fits the underlying data.
  prefs: []
  type: TYPE_NORMAL
- en: Using our sample data from above, our R-squared score would actually be a `NaN`
    value since our *actual* values are constant, resulting in an *SST* of 0.
  prefs: []
  type: TYPE_NORMAL
- en: I should also point out that in practice, it is possible for the R-squared to
    be negative as well. This occurs when the model performs worse than a simple horizontal
    line (i.e. the mean of the target variable). In other words, it means that the
    model’s predictions are even worse than simply using the mean of the target variable
    as a prediction for all observations.
  prefs: []
  type: TYPE_NORMAL
- en: '*Example:* The R-squared is often used as an evaluation metric in marketing
    campaigns, where companies can measure their effectiveness by analyzing the relationship
    between the amount of money spent on advertising and the resulting increase in
    sales revenue. A high R-squared would indicate that there is a strong relationship
    between money spent on advertising and sales revenue, meaning that the marketing
    campaign is quite effective in driving sales.'
  prefs: []
  type: TYPE_NORMAL
- en: Mean Absolute Percentage Error (MAPE)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The mean absolute percentage error, or MAPE, is often used to measure the accuracy
    of a forecasting model.
  prefs: []
  type: TYPE_NORMAL
- en: The ***mean absolute percentage error*** measures the average absolute percentage
    difference between the predicted value and the actual value.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'It is calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6bca2827a158699042910da744e3873c.png)'
  prefs: []
  type: TYPE_IMG
- en: The output of the MAPE is non-negative, with 0 being the best possible value,
    indicating that the model is making perfect predictions with no errors.
  prefs: []
  type: TYPE_NORMAL
- en: With our sample data from above, the MAPE would yield a value of 0.2, suggesting
    that, on average, the predictions are off by 20%.
  prefs: []
  type: TYPE_NORMAL
- en: '*Example:* The MAPE metric is often applied in the domain of finance, where
    predicting percentage changes is considered more important than predicting absolute
    values. For instance, predicting stock prices or exchange rates involves predicting
    percentage changes rather than absolute values, in which case MAPE can serve as
    a suitable evaluation metric.'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is often recommended to use multiple metrics to evaluate a regression model
    as each metric has its own strengths and weaknesses. This approach can provide
    us with a more holistic overview of the model’s performance across different aspects,
    such as accuracy, robustness, and consistency.
  prefs: []
  type: TYPE_NORMAL
- en: The MAE and RMSE score may be preferred if the error metric should have the
    same units as the target variable. However, the RMSE, and therefore also the MSE,
    are more sensitive to outliers compared to the MAE. The R-squared metric is useful
    for evaluating the overall fit of the model to the underlying data, but it doesn’t
    provide any information on individual predictions. Lastly, the MAPE is an easily
    interpretable metric and is therefore often used for forecasting problems, as
    it provides an indication of how far off the predictions are in percentage terms.
  prefs: []
  type: TYPE_NORMAL
- en: The decision of which evaluation metric(s) to choose for a given regression
    problem will ultimately depend on many factors, including the particular problem
    at hand, whether it’s important to penalize larger errors more than smaller ones,
    or the interpretability of the metric in case it needs to be easily explainable
    to stakeholders or managers.
  prefs: []
  type: TYPE_NORMAL
- en: Liked this article?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s connect! You can find me on [Twitter](https://twitter.com/ThomasADorfer),
    [LinkedIn](https://www.linkedin.com/in/thomasdorfer/) and [Substack](https://thomasdorfer.substack.com/).
  prefs: []
  type: TYPE_NORMAL
- en: If you like to support my writing, you can do so through a [Medium Membership](https://thomasdorfer.medium.com/membership),
    which provides you access to all my stories as well as those of thousands of other
    writers on Medium.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/@thomasdorfer/membership?source=post_page-----b9f2e60e25ef--------------------------------)
    [## Join Medium with my referral link - Thomas A Dorfer'
  prefs: []
  type: TYPE_NORMAL
- en: Read every story from Thomas A Dorfer (and thousands of other writers on Medium).
    Your membership fee directly supports…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@thomasdorfer/membership?source=post_page-----b9f2e60e25ef--------------------------------)
  prefs: []
  type: TYPE_NORMAL
