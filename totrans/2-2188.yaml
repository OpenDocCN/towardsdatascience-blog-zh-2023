- en: Understanding Intersection Over Union for Object Detection (Code)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/understanding-intersection-over-union-for-object-detection-code-9a691c72d83a](https://towardsdatascience.com/understanding-intersection-over-union-for-object-detection-code-9a691c72d83a)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Evaluation of object detection models boils down to one thing: determining
    if a detection is valid or not'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@kiprono_65591?source=post_page-----9a691c72d83a--------------------------------)[![Kiprono
    Elijah Koech](../Images/b0b5a59f8cb25a721c7565b6426288fe.png)](https://medium.com/@kiprono_65591?source=post_page-----9a691c72d83a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9a691c72d83a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9a691c72d83a--------------------------------)
    [Kiprono Elijah Koech](https://medium.com/@kiprono_65591?source=post_page-----9a691c72d83a--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9a691c72d83a--------------------------------)
    ·7 min read·Oct 7, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/96c9fc1ed064608c5a9f4def1073800c.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Vardan Papikyan](https://unsplash.com/@varpap?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Determining whether detection is valid requires understanding the **Intersection
    over Union metric (IoU)**.
  prefs: []
  type: TYPE_NORMAL
- en: 'This article covers the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Basics of IoU — **What is IoU**?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**How to compute (theoretically and in Python code) IoU for a single pair**
    of detection and ground truth bounding boxes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Computing IoU for multiple sets** of predicted and ground truth bounding
    boxes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How **to interpret IoU value**?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is Intersection over Union (IoU)?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: IoU is a core metric for the evaluation of object detection models. It measures
    the accuracy of the object detector by evaluating the degree of overlap between
    the detection box and the ground truth box.
  prefs: []
  type: TYPE_NORMAL
- en: A **ground truth box** or **label** is an annotated box showing where the object
    is (the annotation is often done by hand, and the ground truth box is considered
    the object's actual position).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **detection box** or **predicted bounding box** is the prediction from the
    object detector.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Formally, **IoU** is the area of intersection between the ground truth (*gt*)
    and predicted box (*pd*) divided by the union of the two boxes.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1778fb071c4b2768007bc323908dce10.png)'
  prefs: []
  type: TYPE_IMG
- en: Definition of IoU (Image by Author).
  prefs: []
  type: TYPE_NORMAL
- en: 'Example 1: Computing IoU for a Single Pair of Detection and Ground Truth'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's start off with a simple example. Computing IoU for one detection and a
    ground truth.
  prefs: []
  type: TYPE_NORMAL
- en: To do that, we will need the top-left (x1, y1) and bottom-right (x2, y2) coordinates
    of the two boxes.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the Figure below (right), we have two bounding boxes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Predicted bounding box (p-box):** (px1, py1, px2, py2) = (859, 31, 1002,
    176)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ground truth bounding box (t-box):** (tx1, ty1, tx2, ty2) = (860, 68, 976,
    184)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/26ad71d5e6c7d8c6dd89e1c1ef09d5fa.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Left: Image with 14 ground truths (blue boxes) and 12 predictions (red boxes).
    Right: a zoom-in to a single pair of ground truth and predicted box (Annotations
    done by author and the orchard image sourced from [https://zenodo.org/record/3712808](https://zenodo.org/record/3712808)).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Important:** In computer vision, the convention is that:'
  prefs: []
  type: TYPE_NORMAL
- en: The **x-axis** is the horizontal dimension of an image, with *increasing values
    from left to right* and
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **y-axis** is the vertical dimension of an image with *increasing values
    from top to bottom* (this is not the case for a standard Cartesian system)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Step 1: Calculating the area of the two boxes'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This Step calculates the area of the predicted box and ground truth. It is just
    the length multiplied by the width.
  prefs: []
  type: TYPE_NORMAL
- en: '***predicted_area*** *= (1002–859) * (176–31) = 20735* ***ground_truth_area***
    *= (976–860) * (184–68) = 13456*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 2: Find the intersection points'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This Step is for finding the top-left(A) and bottom-right(B) coordinates for
    the intersection area.
  prefs: []
  type: TYPE_NORMAL
- en: 'That can be found by:'
  prefs: []
  type: TYPE_NORMAL
- en: top_left = max(px1, tx1), max(py1, ty2)
  prefs: []
  type: TYPE_NORMAL
- en: bottom_right = min(px2, tx2), min(py2, ty2)
  prefs: []
  type: TYPE_NORMAL
- en: In our case,
  prefs: []
  type: TYPE_NORMAL
- en: '***top_left (A)*** *= max(859, 860), max(31, 68) = (860, 68)* ***bottom_right
    (B)*** *= min(1002, 976), min(176, 184) = (976, 176)*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bcd4457113e113023ada5650e86ca180.png)'
  prefs: []
  type: TYPE_IMG
- en: Showing the intersection region between two boxes (Image by Author).
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 3: Compute Intersection Area'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since we have the intersection points, we can easily compute the area of the
    intersection rectangle as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '***intersection_area*** *= (976–860) * (176–68) = 12528*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 4: Calculate the IoU value'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: IoU = intersection_area / union_area,
  prefs: []
  type: TYPE_NORMAL
- en: where *union_area* is the sum of the areas of the two boxes subtract the intersection
    area. That is,
  prefs: []
  type: TYPE_NORMAL
- en: '***union_area = (area of ground truth + area of predicted box)-intersection_area***
    *= (20735+13456) — 12528 = 21663*'
  prefs: []
  type: TYPE_NORMAL
- en: Therefore,
  prefs: []
  type: TYPE_NORMAL
- en: '***IoU = 12528/21664 = 0.578286558***'
  prefs: []
  type: TYPE_NORMAL
- en: Let's put that into Python code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following code can be used to compute IoU for a single pair of ground truth
    and predicted box. After the code snippet, let's break down the ideas used.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Let's call the compute_iou() function the second time with non-overlapping boxes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Breaking down the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[NumPy Vectorization](https://www.programiz.com/python-programming/numpy/vectorization)
    allows us to implement operations like `np.prod()`, `np.maximum()`, `np.minimum()`,
    `np.clip()`, `addition` and `subtraction` on the arrays without the need to loop
    through the array elements or index to a single element.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`np.clip()` function limits or "clips" the values in an array within a specified
    range. In our case, `np.clip(bottom_right — top_left, a_min=0, a_max=None)` ensures
    that the resulting width and height values of the intersection are non-negative
    by setting negative values to 0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Example 2: Computing IoU for Multiple Pairs of Ground Truth and Predicted Boxes'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this example, we want to calculate IoU values for all ground-truth and predicted
    box pairs in the Figure below (far left).
  prefs: []
  type: TYPE_NORMAL
- en: The image contains 12 predictions (red boxes) and 14 ground truths (blue boxes)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a89060008a87ea1d83729bcfa05c8a9c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Left: An image with ground truths and detections plotted, Middle: Predictions
    and Right: Ground truths (Annotations done by author and the orchard image sourced
    from [https://zenodo.org/record/3712808](https://zenodo.org/record/3712808)).'
  prefs: []
  type: TYPE_NORMAL
- en: Computing IoUs for all pairs of detections and ground truths can be done easily
    by modifying the initial code, as shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '**Output (formatted for better viewing):**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cc93e4054584356fabcfecec4beda629.png)'
  prefs: []
  type: TYPE_IMG
- en: Output of compute_ious() function (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: 'The output shows that:'
  prefs: []
  type: TYPE_NORMAL
- en: One detection (Index 12) did not overlap any ground truth.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 3 ground truths with no overlap with any detection — ground truths at indices
    7, 11 and 13.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are 11 detections with IoU>50% with ground truths.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s also break down a piece of the code that may not be super clear:'
  prefs: []
  type: TYPE_NORMAL
- en: In the code above, the use of `None` in the indexing operations is a technique
    in NumPy to introduce new axes or dimensions to the array. It is often used to
    broadcast arrays of different shapes together to perform element-wise operations
    or to enable certain calculations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interpretation of IoU Values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: IoU value lies in the range [0, 1] where 0 means no overlap between two boxes
    being checked and 1 indicates a perfect overlap.
  prefs: []
  type: TYPE_NORMAL
- en: Based on your application, you can set an IoU threshold to determine what good
    detection means.
  prefs: []
  type: TYPE_NORMAL
- en: I hope this article made the concept IoU concept clearer.
  prefs: []
  type: TYPE_NORMAL
- en: All the best!
  prefs: []
  type: TYPE_NORMAL
