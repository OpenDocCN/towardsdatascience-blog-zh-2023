- en: Understanding the Importance of Diversity in Ensemble Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/understanding-the-importance-of-diversity-in-ensemble-learning-34fb58fd2ed0](https://towardsdatascience.com/understanding-the-importance-of-diversity-in-ensemble-learning-34fb58fd2ed0)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The role of diversity in improving ensemble performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://donatoriccio.medium.com/?source=post_page-----34fb58fd2ed0--------------------------------)[![Donato
    Riccio](../Images/0af2a026e72a023db4635522cbca50eb.png)](https://donatoriccio.medium.com/?source=post_page-----34fb58fd2ed0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----34fb58fd2ed0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----34fb58fd2ed0--------------------------------)
    [Donato Riccio](https://donatoriccio.medium.com/?source=post_page-----34fb58fd2ed0--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----34fb58fd2ed0--------------------------------)
    ·9 min read·Jan 2, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dab0c86b9beea259e2d15c4ae808d51d.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Mulyadi](https://unsplash.com/@mullyadii?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble learning is a machine learning technique that combines multiple models
    to achieve better results. It is only in recent years, with the increasing computing
    speed, that ensemble learning became one of the most effective techniques for
    tackling difficult problems in the machine learning domain. This approach is used
    in most of the winning solutions for machine learning competitions, with prizes
    up to 100,000 dollars.
  prefs: []
  type: TYPE_NORMAL
- en: How do we select the best ensemble members, to combine them in a single, more
    powerful model? In this article, we’ll explore how to choose models to ensemble
    and how to aggregate them.
  prefs: []
  type: TYPE_NORMAL
- en: '**What is diversity?**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ensemble learning is based on the concept of combining multiple models, called
    *weak learners*. The name comes from the idea that individual ensemble members
    don’t need to be very accurate. As long as they are a little bit better than a
    random model, combining them is beneficial. Diversity is an important concept
    in ensemble learning, and refers to the idea that the individual models prediction
    in an ensemble should be **as different from each other as possible.** This is
    because different models are likely to make different types of errors. By combining
    the predictions of a diverse set of models, we can reduce the overall error of
    the ensemble.
  prefs: []
  type: TYPE_NORMAL
- en: '**How can we increase diversity?**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Over the years, several ensemble learning algorithms were developed. Each one
    has a unique way to achieve diversity. These approaches include:'
  prefs: []
  type: TYPE_NORMAL
- en: Training each model on a **different subset of the training data.** When samples
    are drown with replacement, it’s known as **bagging**. When sampling is performed
    without replacement, it’s called **pasting**. It can also help to reduce the variance
    of the ensemble’s predictions, which can improve its generalization. The idea
    of diversity in bagging has been further developed in **Random Forest** and **Extremely
    Randomized Trees**. The first that achieves diversity by choosing a **random number
    of features** available to the trees at each split, while the latter employs a
    **random split** in order to lower the correlation between trees in the ensemble.
  prefs: []
  type: TYPE_NORMAL
- en: Training each model using a **different set of features.** An ensemble can be
    trained using different combinations of the available features or different transformations
    of the original features. This can help to capture different aspects of the data,
    leading to improved performance.
  prefs: []
  type: TYPE_NORMAL
- en: Training **each model using a different type of algorithm.** This is the approach
    used in **voting** and **stacking** meta-models. By using different algorithms,
    the individual models in the ensemble can capture different patterns in the data
    and make different types of errors.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7e568ea704605381e5de71ae88ddb2f0.png)'
  prefs: []
  type: TYPE_IMG
- en: Voting ensembles. It’s important to include diverse ensemble members. [1]
  prefs: []
  type: TYPE_NORMAL
- en: However, diverse predictions are not always better.
  prefs: []
  type: TYPE_NORMAL
- en: '**Good and Bad diversity**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In a majority vote ensemble, the concept of *wasted* votes can be used to understand
    the diversity of the ensemble. If the ensemble is already correct, low disagreement
    among the classifiers indicates that several votes have been wasted, as the same
    correct decision would have been made regardless of the individual classifiers
    votes. This is known as **good diversity**, as it measures disagreement where
    the ensemble is already correct. More disagreement in this situation means fewer
    wasted votes. In contrast, **bad diversity** measures disagreement where the ensemble
    is incorrect. In this case, any disagreement represents a wasted vote, as the
    individual classifier did not contribute to the correct decision made by the ensemble.
    To maximize the efficiency of the ensemble, it is important to increase good diversity
    and decrease bad diversity, which can be achieved by reducing the number of wasted
    votes.
  prefs: []
  type: TYPE_NORMAL
- en: Another way to think about this is from the accuracy perspective. For example,
    suppose that the decision tree model tends to be very good at identifying dogs,
    but has trouble with cats. The logistic regression model, on the other hand, is
    better at identifying cats but has trouble with dogs. Each of these algorithms
    has its own strengths and weaknesses, and will make different types of errors
    on the data. By combining the predictions of these two models, we can create an
    ensemble that is more accurate overall than either individual model. This is an
    example of **good diversity**. We could add a third model, bad at both classifying
    cats and dogs. The third model would increase the ensemble’s diversity without
    bringing any benefits. This is considered **bad diversity.** [2]
  prefs: []
  type: TYPE_NORMAL
- en: '**How can we measure diversity?**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s call ***f₁, f₂, … fₙ*** the predictions of different models in an ensemble.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two types of diversity measures: pairwise and global. Pairwise metrics
    need to be computed for every pair of ***fᵢ, fⱼ*.** In the end, you’ll get a ***n*x*n***
    matrix. Global ones are computed on the whole matrix of predictions, and they
    are represented by a single value. The following list is by no means exhaustive,
    you can find more measures in the paper by Kuncheva, in the references.'
  prefs: []
  type: TYPE_NORMAL
- en: In the formulas, 0 means that the prediction is wrong, and 1 that is correct.
    For example, ***N⁰¹*** means the number of times where the first classifier is
    correct, and the second is wrong.
  prefs: []
  type: TYPE_NORMAL
- en: '**Pearson correlation coefficient** The simplest way to compute similarity
    in an ensemble is to use Pearson correlation coefficient. If the predictions from
    two models are very correlated, it means that they are very similar. The maximum
    diversity is obtained when **ρᵢⱼ** = 0, while two classifiers that produce the
    exact same outputs will have **ρᵢⱼ** = 1\. It’s possible to compute the correlation
    coefficient when the predictions are probabilities, like in soft voting ensembles.'
  prefs: []
  type: TYPE_NORMAL
- en: The following metrics are used on binary class predictions.
  prefs: []
  type: TYPE_NORMAL
- en: '**Disagreement** As the name suggests, it’s how much disagreement there is
    between the predictions. It is calculated by dividing the number of times the
    predictions differ by the total number of predictions made. Disagreement takes
    values between 0 (there are no prediction that differ) and 1 (every prediction
    differs).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6dda48c6898fea53e2ce9afd9032c975.png)'
  prefs: []
  type: TYPE_IMG
- en: Disagreement measure. [2]
  prefs: []
  type: TYPE_NORMAL
- en: '**Yule’s Q** Yule’s Q has values between -1 and 1\. This metric adds an important
    information: positive values indicate that models are classifying the *same* objects
    correctly, while those who are wrong on different objects will have negative Q
    values. The value of 0 suggests that the predictions are independent.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/998accb7bc085fe11babb8fa26d2d4ff.png)'
  prefs: []
  type: TYPE_IMG
- en: Yule’s Q. [2]
  prefs: []
  type: TYPE_NORMAL
- en: '**Entropy** The following measure is a global metric. It’s computed on the
    whole matrix of predictions. Entropy is based on the idea that when disagreement
    is the maximum, half of the predictions are zero, while the other half are one.
    In the following formula, L is the total number of ensemble members, and *l* is
    the total number of classifiers that correctly classify an instance z*ⱼ.*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fa6d2be519d578a8225102e55dac5a6b.png)'
  prefs: []
  type: TYPE_IMG
- en: Entropy for binary predictions. [2]
  prefs: []
  type: TYPE_NORMAL
- en: '**Python implementation**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Building a voting classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s now compare two ensembles to evaluate how diverse their members are. For
    the following examples I used [pycaML](https://pypi.org/project/pycaML/), which
    allows to train and compare models and ensembles with few lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: I choose 9 models for the first ensemble, and 10 models for the second one.
    Every models is trained with default parameters. The [dataset](https://archive.ics.uci.edu/ml/datasets/diabetes)
    is available in the UCI repository.
  prefs: []
  type: TYPE_NORMAL
- en: '**Model comparison** For having a baseline to compare the ensemble with, the
    following figure shows the 10 best performing models. We’ll focus on the F1 score.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/66223cd711a87a7f65f2ed4bfa4deba9.png)'
  prefs: []
  type: TYPE_IMG
- en: 10 best performing models on the diabetes dataset, generated with pycaML. Image
    by author.
  prefs: []
  type: TYPE_NORMAL
- en: The prediction matrix can be computed as follows. In the end, we’ll have a 154x19
    matrix, where each row is an instance of the test set, and every column is a model.
    After obtaining the matrix, we can split it in two ensembles to compare them.
    The first one contains the odd indexed models, while the second one the even indexed
    models.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Looking at the disagreement matrix for ensemble 1, it seems that Perceptron
    is the model that disagrees the most with the others. On the other hand, there
    is little disagreement between boosting models.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/82eb081f10c8ba4a579ef01fc1e1a943.png)'
  prefs: []
  type: TYPE_IMG
- en: Disagreement matrix for ensemble 1\. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble 2 contains different models. Overall, it seems that disagreement is
    pretty low. The member with the highest disagreement is Passive Aggressive Classifier.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/09a8430841010c5bb47963d02f7be570.png)'
  prefs: []
  type: TYPE_IMG
- en: Disagreement matrix for ensemble 2\. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Since Ensemble 1 has higher entropy, it means that the diversity is higher.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/281a275728aa29d0b855d8e0d89905ed.png)'
  prefs: []
  type: TYPE_IMG
- en: Entropy scores. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now build the final model by taking the majority vote (mode). This meta-model
    is called hard voting. The two ensembles are evaluated using the same metric as
    before, F1 score.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/519b7ab3e40e2308a67e1a29b53243a1.png)'
  prefs: []
  type: TYPE_IMG
- en: Results after evaluating the models. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we show that higher diversity (ensemble 1) leads to a better ensemble
    model. The best model found in the comparison is Extra Trees, with a F1 score
    of 0.71\. The final model performs better than the best model trained on the dataset
    by a considerable margin, reaching a score of 0.764.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ensemble learning is a powerful machine learning technique that involves training
    multiple models and combining their predictions to achieve improved performance.
    We found that as the diversity of the models in the ensemble increased, the performance
    of the ensemble also increased.
  prefs: []
  type: TYPE_NORMAL
- en: This finding highlights the value of diversity in ensemble learning. When building
    an ensemble, it’s important to consider diversity among the models in order to
    achieve the best possible performance.
  prefs: []
  type: TYPE_NORMAL
- en: So, the next time you’re working on a machine learning project and considering
    using an ensemble, remember to prioritize diversity among the models. It could
    make all the difference in the final performance of your model.
  prefs: []
  type: TYPE_NORMAL
- en: '*Enjoyed this article? Get weekly data science interview questions delivered
    to your inbox by subscribing to my newsletter,* [*The Data Interview*](https://thedatainterview.substack.com/)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Also, you can find me on* [*LinkedIn*](https://www.linkedin.com/in/driccio/)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Géron, A. (2019). Hands-on machine learning with Scikit-Learn, Keras and
    TensorFlow: concepts, tools, and techniques to build intelligent systems (2nd
    ed.). O’Reilly.'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] Kuncheva, L.I., Whitaker, C.J. Measures of Diversity in Classifier Ensembles
    and Their Relationship with the Ensemble Accuracy. *Machine Learning* **51**,
    181–207 (2003). [https://doi.org/10.1023/A:1022859003006](https://doi.org/10.1023/A:1022859003006)'
  prefs: []
  type: TYPE_NORMAL
