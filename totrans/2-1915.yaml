- en: 'Stepping Stones to Understanding: Knowledge Graphs as Scaffolds for Interpretable
    Chain-of-Thought Reasoning with LLMs'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/stepping-stones-to-understanding-knowledge-graphs-as-scaffolds-for-interpretable-chain-of-thought-2b9139c28c60](https://towardsdatascience.com/stepping-stones-to-understanding-knowledge-graphs-as-scaffolds-for-interpretable-chain-of-thought-2b9139c28c60)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@alcarazanthony1?source=post_page-----2b9139c28c60--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----2b9139c28c60--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2b9139c28c60--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2b9139c28c60--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----2b9139c28c60--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2b9139c28c60--------------------------------)
    ·7 min read·Nov 21, 2023
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '*Artificial intelligence software was used to enhance the grammar, flow, and
    readability of this article’s text.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Large language models (LLMs), trained on vast volumes of text data, has sparked
    a revolution in AI. Their ability to generate remarkably eloquent, coherent language
    simply from a short text prompt has opened up new horizons across domains from
    creative writing to conversational assistants.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: However, mastery of linguistic expression alone does not equate true intelligence.
    LLMs still lack semantic understanding of concepts and logical reasoning abilities
    required for situational comprehension and complex problem solving. Their knowledge
    remains confined to superficial patterns discerned from training corpora rather
    than grounded facts about the real world.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: As we pose more open-ended, multifaceted questions to these models, their limitations
    become increasingly apparent. They cannot logically synthesize details from different
    documents or make inferences spanning multiple steps to derive answers.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Once queries start departing from the distribution of training data, hallucinated
    or contradictory responses start emerging.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: To address these pitfalls, the AI community has pivoted focus toward retrieval
    augmented generative (RAG) frameworks. These systems aim to synergize the linguistic
    prowess of language models with fast, targeted access to external knowledge sources
    that can ground them in factual context instead of hallucinations.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Most existing architectures retrieve supplementary information using semantic
    similarity over vector representations of passages from text corpora. However,
    this struggles with fuzzy relevance between retrieved passages and actual query
    context. Key details get lost when condensing passages to singular opaque vectors
    devoid of contextual links. Deriving coherent narratives tying disparate facts
    through logical reasoning remains arduous.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 目前大多数现有架构使用语义相似性从文本语料库的向量表示中检索补充信息。然而，这在检索的段落与实际查询上下文之间的模糊相关性上存在困难。当将段落浓缩为单一不透明的向量时，关键信息容易丢失，缺乏上下文链接。通过逻辑推理将离散事实结合成连贯叙事仍然很艰难。
- en: This underscores the need for incorporating structured knowledge sources that
    encapsulate real-world entities and relationships between them. Knowledge graphs
    meet this need — encoding facts as interconnected nodes and edges that can be
    traversed along explanatory pathways. However, effectively grounding free-form
    reasoning of language models upon structured graphs presents interfacing challenges.
    Creatively bridging neural approaches with symbolic representations remains an
    open problem.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这强调了纳入封装现实世界实体及其之间关系的结构化知识源的必要性。知识图谱满足了这一需求——将事实编码为可以沿解释路径遍历的互联节点和边。然而，有效地将语言模型的自由形式推理建立在结构化图谱上存在接口挑战。创造性地将神经方法与符号表示桥接仍然是一个未解问题。
- en: An emerging technique that offers promise in this direction is chain-of-thought
    (CoT) prompting. CoT nudges language models to reveal their reasoning in step-by-step
    inferential chains. Each connection becomes plainly visible, enhancing transparency.
    However, coherence rapidly falls apart over long histories in purely free-form
    linguistic spaces. Knowledge graphs could provide the missing scaffolding to give
    structure to these unraveling reasoning trajectories.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一种在这一方向上展现出希望的新兴技术是思维链（CoT）提示。CoT促使语言模型以逐步推理链条的形式展示其推理过程。每一个连接变得清晰可见，增强了透明度。然而，在完全自由形式的语言空间中，长时间的历史往往会迅速破裂。知识图谱可能提供缺失的支撑结构，以给这些逐渐展开的推理轨迹提供结构。
- en: Explicitly tracing CoT steps along knowledge graph pathways may enable logically
    sound reasoning firmly grounded in chains of facts. However, finding the right
    alignments between unstructured neural outputs and structured symbolic knowledge
    remains an open challenge. Innovations in this direction offer hope for blending
    strengths of both approaches — symbolic representations with sound deductive chains
    anchored to real-world entities connected fluidly through vector spaces allowing
    efficient statistical inference.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 明确地沿知识图谱路径追踪CoT步骤可能会实现基于事实链条的逻辑推理。然而，找到非结构化神经输出与结构化符号知识之间的正确对齐仍然是一个未解的挑战。在这方面的创新为融合两种方法的优点提供了希望——将符号表示与基于真实世界实体的可靠推理链条结合，通过向量空间流畅地连接，从而实现高效的统计推断。
- en: The rest of the article will explore this promising intersection of knowledge
    graphs and CoT reasoning within LLMs for more robust situational intelligence.
    We delve into techniques leveraging each approach’s complementary strengths while
    mitigating their weaknesses in isolation.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 文章的其余部分将探讨知识图谱与CoT推理在大型语言模型中的有前景的交集，以实现更稳健的情境智能。我们将深入研究利用每种方法的互补优势，同时减轻它们在孤立状态下的缺陷的技术。
- en: I. Knowledge Graphs for Robust Few-Shot Learning
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: I. 知识图谱用于稳健的少样本学习
- en: '[](https://ai.plainenglish.io/new-research-proves-knowledge-graphs-drastically-improve-accuracy-of-large-language-models-on-0f1dbcc08d61?source=post_page-----2b9139c28c60--------------------------------)
    [## New Research Proves Knowledge Graphs Drastically Improve Accuracy of Large
    Language Models on…'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ai.plainenglish.io/new-research-proves-knowledge-graphs-drastically-improve-accuracy-of-large-language-models-on-0f1dbcc08d61?source=post_page-----2b9139c28c60--------------------------------)
    [## 新研究证明知识图谱显著提高大型语言模型的准确性]'
- en: Natural language interfaces to databases have long been a holy grail of both
    industry and academia. Recently, advances…
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自然语言接口到数据库一直是工业界和学术界的圣杯。最近，进展……
- en: ai.plainenglish.io](https://ai.plainenglish.io/new-research-proves-knowledge-graphs-drastically-improve-accuracy-of-large-language-models-on-0f1dbcc08d61?source=post_page-----2b9139c28c60--------------------------------)
    [](/vector-search-is-not-all-you-need-ecd0f16ad65e?source=post_page-----2b9139c28c60--------------------------------)
    [## Vector Search Is Not All You Need
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[ai.plainenglish.io](https://ai.plainenglish.io/new-research-proves-knowledge-graphs-drastically-improve-accuracy-of-large-language-models-on-0f1dbcc08d61?source=post_page-----2b9139c28c60--------------------------------)
    [](/vector-search-is-not-all-you-need-ecd0f16ad65e?source=post_page-----2b9139c28c60--------------------------------)
    [## 向量搜索并非你所需的一切'
- en: Introduction
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 介绍
- en: towardsdatascience.com](/vector-search-is-not-all-you-need-ecd0f16ad65e?source=post_page-----2b9139c28c60--------------------------------)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/vector-search-is-not-all-you-need-ecd0f16ad65e?source=post_page-----2b9139c28c60--------------------------------)'
- en: Most existing RAG systems rely solely on passage embeddings for semantic similarity
    matching. However, these struggle with fuzzy relevance and inability to jointly
    analyze connected facts scattered across passages. Knowledge graphs address this
    by retaining symbolic facts and relationships enabling explainable multi-hop reasoning.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的大多数RAG系统仅依赖于段落嵌入进行语义相似性匹配。然而，这些系统在处理模糊相关性和无法联合分析分散在多个段落中的连接事实方面存在困难。知识图谱通过保留符号事实和关系来解决这些问题，从而支持可解释的多跳推理。
- en: Diverse Graph Algorithms for Versatile Reasoning
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多样的图算法用于多用途推理
- en: 'Knowledge graphs equip us with an entire new repertoire of algorithms optimized
    for different reasoning modalities:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱为我们提供了一整套新的算法，优化用于不同的推理模式：
- en: Graph traversal algorithms like Personalized PageRank allow flexible associative
    reasoning by analyzing indirect connections between entities. This supports deducing
    new relations from inference chains spanning multiple edges.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 像个性化PageRank这样的图遍历算法通过分析实体之间的间接连接来支持灵活的关联推理。这支持从跨多个边的推理链中推导出新的关系。
- en: Algorithms tuned for search (e.g. Approximate Nearest Neighbors) allow efficiently
    querying facts related to specific entities. This aids precise factual retrieval.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为搜索优化的算法（例如，近似最近邻）可以高效查询与特定实体相关的事实。这有助于精确的事实检索。
- en: Graph summarization algorithms can concisely distill subgraphs with the most
    pertinent information to simplify reasoning. This reduces noise and improves focus.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图总结算法可以简明地提炼出包含最相关信息的子图，以简化推理。这减少了噪音并提高了焦点。
- en: Optimized Knowledge Graph Embeddings
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化的知识图谱嵌入
- en: 'In addition, knowledge graph elements like entities, relations and text can
    be encoded into vector spaces as well, enabling mathematical operations:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，知识图谱中的元素如实体、关系和文本也可以编码到向量空间中，从而支持数学操作：
- en: Transitive embeddings improve deductive reasoning across multi-hop inference
    chains by maintaining equivalence across composition of relations.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 传递性嵌入通过在关系组成中保持等价性来改善跨多跳推理链的演绎推理。
- en: Hierarchical embeddings encode taxonomy hierarchies between entities, allowing
    inheritance-based reasoning. This inherits facts from ancestral classes.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 层次嵌入编码了实体之间的分类层级，允许基于继承的推理。这从祖先类继承事实。
- en: Contextual embeddings from large transformer language models capture semantic
    nuances in textual attributes of entities and relations.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大型变换器语言模型中的上下文嵌入捕捉了实体和关系文本属性中的语义细微差别。
- en: The partnerships between rich symbolic representations and flexible vector spaces
    provide the best foundations for few-shot learning — neatly structured knowledge
    to scaffold explicit logical deductions explicated through dynamically fluid vectors
    spaces that distill salient patterns.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 丰富的符号表示与灵活的向量空间之间的合作为少量学习提供了最佳基础——结构化的知识用于支撑显式逻辑推理，通过动态流畅的向量空间提炼出显著的模式。
- en: II. Augmenting Chain-of-Thought with Structured Knowledge Graphs
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: II. 用结构化知识图谱增强思维链
- en: '[](/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a?source=post_page-----2b9139c28c60--------------------------------)
    [## Achieving Structured Reasoning with LLMs in Chaotic Contexts with Thread of
    Thought Prompting and…'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a?source=post_page-----2b9139c28c60--------------------------------)
    [## 在混乱的背景下通过思维链提示实现LLMs的结构化推理和…'
- en: Large language models (LLMs) demonstrated impressive few-shot learning capabilities,
    rapidly adapting to new tasks with…
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）展示了令人印象深刻的少量学习能力，能够快速适应新任务……
- en: 'towardsdatascience.com](/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a?source=post_page-----2b9139c28c60--------------------------------)
    [](https://arxiv.org/abs/2308.09687?source=post_page-----2b9139c28c60--------------------------------)
    [## Graph of Thoughts: Solving Elaborate Problems with Large Language Models'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a?source=post_page-----2b9139c28c60--------------------------------)
    [](https://arxiv.org/abs/2308.09687?source=post_page-----2b9139c28c60--------------------------------)
    [## 思维图：使用大型语言模型解决复杂问题'
- en: 'We introduce Graph of Thoughts (GoT): a framework that advances prompting capabilities
    in large language models (LLMs)…'
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我们介绍了Graph of Thoughts（GoT）：一个提升大型语言模型（LLMs）提示能力的框架…
- en: 'arxiv.org](https://arxiv.org/abs/2308.09687?source=post_page-----2b9139c28c60--------------------------------)
    [](https://arxiv.org/abs/2310.01061?source=post_page-----2b9139c28c60--------------------------------)
    [## Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 图上的推理：可信且可解释的大型语言模型推理](https://arxiv.org/abs/2308.09687?source=post_page-----2b9139c28c60--------------------------------)
    [](https://arxiv.org/abs/2310.01061?source=post_page-----2b9139c28c60--------------------------------)'
- en: Large language models (LLMs) have demonstrated impressive reasoning abilities
    in complex tasks. However, they lack…
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在复杂任务中展示了令人印象深刻的推理能力。然而，它们缺乏…
- en: arxiv.org](https://arxiv.org/abs/2310.01061?source=post_page-----2b9139c28c60--------------------------------)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[arxiv.org](https://arxiv.org/abs/2310.01061?source=post_page-----2b9139c28c60--------------------------------)'
- en: Chain-of-thought (CoT) prompting guides language models to reveal their reasoning
    in explanatory chains of inferential steps. However, as inferences span longerhistories,
    coherence often unravels in free-form linguistic space. Knowledge graphs can provide
    missing structure.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 链式推理（CoT）提示指导语言模型通过解释性推理步骤链展示其推理过程。然而，当推理跨越更长的历史时，一致性通常会在自由形式的语言空间中解构。知识图谱可以提供缺失的结构。
- en: Explicitly Encoding Concepts and Relations
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 显式编码概念和关系
- en: Knowledge graphs encode concepts as interlinked symbolic nodes, capturing relations
    between them. Traversing explanatory pathways over this explicit network can scaffold
    CoT reasoning. Recent approaches like Graph-of-Thoughts (GoT) explore assembling
    situational graphs to model evolving CoT steps.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱将概念编码为相互链接的符号节点，捕捉它们之间的关系。通过这个明确的网络遍历解释路径可以支撑链式推理。像Graph-of-Thoughts（GoT）这样的近期方法探索组装情境图来建模不断演变的链式推理步骤。
- en: 'Beyond just modeling, the structured representations can participate in steering
    the reasoning:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 超越建模，结构化表示可以参与引导推理：
- en: 'Querying Ontologies: Initial ontology queries establishing definitions and
    high-level context can frame the reasoning.'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查询本体：初始本体查询建立定义和高层次背景，可以框定推理。
- en: 'Traversing Relations: Graph algorithms can gather connected facts relevant
    for each CoT step.'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历关系：图算法可以收集与每个CoT步骤相关的连接事实。
- en: 'Updating Representations: Embeddings encode extracted details, focussing attention.'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新表示：嵌入编码提取的细节，集中注意力。
- en: Coordinating Hybrid Reasoning
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 协调混合推理
- en: 'Integrating neural CoT prompting with structured knowledge graphs requires
    coordinating distributed reasoning modules:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 将神经CoT提示与结构化知识图谱整合需要协调分布式推理模块：
- en: 'Manager: Sequences module execution, balancing language model requests with
    retrieval.'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 管理者：排序模块执行，平衡语言模型请求与检索。
- en: 'Prompter: Elicits free-form rationales from language models through CoT prompting.'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提示者：通过CoT提示从语言模型中引出自由形式的理由。
- en: 'Retriever: Gathers pertinent graph details using algorithms like Personalized
    PageRank.'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检索器：使用个性化PageRank等算法收集相关的图形细节。
- en: 'Parser: Transforms retrieved facts to natural language or vectors.'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解析器：将检索到的事实转换为自然语言或向量。
- en: 'Scorer: Assesses relevance of retrieved facts for current context.'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评分器：评估检索到的事实在当前上下文中的相关性。
- en: 'Fuser: Combines salient knowledge with updated prompt for next round.'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 融合器：将显著知识与更新提示结合，为下一轮准备。
- en: The modular architecture allows combining strengths of neural and symbolic approaches.
    The language model thinks fluidly while the graph preserves logic — each compensating
    for the other’s limitations.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 模块化架构允许结合神经和符号方法的优点。语言模型思维流畅，而图形保留逻辑——彼此弥补对方的局限性。
- en: Choreographing Hybrid Reasoning
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编排混合推理
- en: 'Orchestrating the staged interplay between structured knowledge and fluid vector
    inferences is key to unlocking new reasoning capabilities combining:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 协调结构化知识与流体向量推断之间的分阶段互动是解锁结合以下内容的新推理能力的关键：
- en: Interpretability of explicit symbolic modeling with scalable pattern recognition
    using embeddings.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用嵌入的可扩展模式识别来解释显式符号建模的可解释性。
- en: Logical soundness of axiomatic knowledge with adaptive improvisation of neural
    approaches.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 公理知识的逻辑合理性与神经方法的自适应即兴发挥。
- en: Explainability afforded by graph traversals with efficient computation via vectors.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图谱遍历提供的可解释性与向量的高效计算。
- en: Innovations on this synthesis promise more reliable, versatile and transparent
    reasoning than possible with either approach in isolation. The partnerships open
    new frontiers for situated intelligence.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这种综合方法的创新承诺比单独使用任何一种方法提供更可靠、多功能和透明的推理。这些合作伙伴关系为情境智能开辟了新前沿。
- en: III. Current Gaps and Future Directions
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: III. 当前差距与未来方向
- en: '[](/knowledge-graph-transformers-architecting-dynamic-reasoning-for-evolving-knowledge-712e056725e0?source=post_page-----2b9139c28c60--------------------------------)
    [## Knowledge Graph Transformers: Architecting Dynamic Reasoning for Evolving
    Knowledge'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 知识图谱转换器：为演变中的知识构建动态推理](https://knowledge-graph-transformers-architecting-dynamic-reasoning-for-evolving-knowledge-712e056725e0?source=post_page-----2b9139c28c60--------------------------------)'
- en: Knowledge graphs, which represent facts as interconnected entities, have emerged
    as a pivotal technique for enhancing…
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 知识图谱通过表示事实为相互连接的实体，已成为增强的关键技术...
- en: towardsdatascience.com](/knowledge-graph-transformers-architecting-dynamic-reasoning-for-evolving-knowledge-712e056725e0?source=post_page-----2b9139c28c60--------------------------------)
    [](https://ai.plainenglish.io/unlocking-the-power-of-graphs-for-ai-reasoning-378c7e9dac02?source=post_page-----2b9139c28c60--------------------------------)
    [## Unlocking the Power of Graphs for AI Reasoning
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 解锁图谱在 AI 推理中的力量](https://ai.plainenglish.io/unlocking-the-power-of-graphs-for-ai-reasoning-378c7e9dac02?source=post_page-----2b9139c28c60--------------------------------)'
- en: Graphs are ubiquitous in the modern data-driven business world.
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图谱在现代数据驱动的商业世界中无处不在。
- en: ai.plainenglish.io](https://ai.plainenglish.io/unlocking-the-power-of-graphs-for-ai-reasoning-378c7e9dac02?source=post_page-----2b9139c28c60--------------------------------)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[解锁图谱在 AI 推理中的力量](https://ai.plainenglish.io/unlocking-the-power-of-graphs-for-ai-reasoning-378c7e9dac02?source=post_page-----2b9139c28c60--------------------------------)'
- en: 'While knowledge graphs offer promise for grounding reasoning, realizing their
    full potential has obstacles like sub-optimal construction, alignment, personalization
    and handling evolution:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管知识图谱有助于支撑推理，但要实现其全部潜力面临如次优构建、对齐、个性化及处理演变等障碍：
- en: Comprehensive, High-fidelity Knowledge Graphs
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 综合的高保真知识图谱
- en: Manually curating extensive high-quality knowledge graphs spanning diverse nuanced
    domains poses scaling bottlenecks. Meanwhile open-source graphs suffer from sparsity,
    inconsistency and noise issues ill-suited for supporting sound deductive chains.
    Clean ontological knowledge combined with noisy web extractions brings integration
    difficulties.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 手动策划涵盖多样化领域的广泛高质量知识图谱会遇到扩展瓶颈。同时，开源图谱存在稀疏、不一致和噪音问题，不适合支持健全的推理链。清晰的本体知识与嘈杂的网络提取结合带来了整合难题。
- en: Smoothly Integrating Vector and Symbolic Spaces
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 平滑集成向量和符号空间
- en: Bridging the symbolic structure of knowledge graphs with latent vector spaces
    of language models to enable seamless exchange of information is non-trivial.
    Simple approaches like direct vector lookups struggle to adequately capture symbolic
    semantics. More advanced techniques like graph neural networks show promise for
    elegantly grounding graphs within language model vector spaces to enable tightly
    coupled reasoning. But research remains nascent.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 将知识图谱的符号结构与语言模型的潜在向量空间桥接，以实现信息的无缝交换并非易事。像直接向量查找这样的简单方法难以充分捕捉符号语义。更先进的技术如图神经网络展现了优雅地将图谱嵌入语言模型向量空间的潜力，从而实现紧密耦合的推理。但研究仍处于起步阶段。
- en: Personalized and Current Temporal Graphs
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 个性化和当前时态图谱
- en: Static knowledge graphs poorly reflect individual users’ unique contexts, hindering
    personalized reasoning aligned with personal world knowledge. Constructing customizable
    user-specific knowledge graphs remains prohibitively expensive. Meanwhile, static
    graphs also grow obsolete, failing to track constantly shifting real-world states
    and events critical for contemporary reasoning. Dynamic graphs accurately mirroring
    our ephemeral environments are pivotal.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 静态知识图谱无法有效反映个体用户的独特背景，限制了与个人世界知识对齐的个性化推理。构建可定制的用户特定知识图谱依然成本过高。同时，静态图谱也会逐渐过时，无法跟踪不断变化的现实世界状态和事件，这些对当代推理至关重要。准确反映我们短暂环境的动态图谱至关重要。
- en: Exploring Innovations to Overcome Limitations
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索克服限制的创新
- en: Nevertheless innovations hold promise in mitigating these limitations through
    fusion techniques combining curated and extracted knowledge, improved grounding
    algorithms deeply intertwining symbolic and neural reasoning, customizable dynamic
    graph construction aided by smart assistants, and stream learning continuously
    updating representations — all coming together to realize the symbiotic potential
    of integrated reasoning.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，创新技术通过融合技术结合策划和提取的知识、改进的基础算法深度结合符号和神经推理、智能助手辅助的可定制动态图谱构建以及持续更新表示的流学习，展现了缓解这些限制的潜力——这些都共同实现了综合推理的共生潜力。
- en: 'Sources :'
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资料来源：
- en: '[](https://arxiv.org/abs/2311.11797?source=post_page-----2b9139c28c60--------------------------------)
    [## Igniting Language Intelligence: The Hitchhiker''s Guide From Chain-of-Thought
    Reasoning to Language…'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 激发语言智能：从链式思维推理到语言的指南…](https://arxiv.org/abs/2311.11797?source=post_page-----2b9139c28c60--------------------------------)'
- en: Large language models (LLMs) have dramatically enhanced the field of language
    intelligence, as demonstrably evidenced…
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）显著提升了语言智能领域，这一点通过…
- en: arxiv.org](https://arxiv.org/abs/2311.11797?source=post_page-----2b9139c28c60--------------------------------)
    ![](../Images/183c5b218b071fc0f3327c8bfceeec2b.png)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[arxiv.org](https://arxiv.org/abs/2311.11797?source=post_page-----2b9139c28c60--------------------------------)
    ![](../Images/183c5b218b071fc0f3327c8bfceeec2b.png)'
- en: Image by the author
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
